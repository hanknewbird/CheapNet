2023-02-06 11:46:53 | Start | Model starts training!!!

2023-02-06 11:46:57 | Train | Epoch[001/600] Iteration[001/030] Train loss: 0.8956
2023-02-06 11:46:57 | Train | Epoch[001/600] Iteration[002/030] Train loss: 0.8739
2023-02-06 11:46:57 | Train | Epoch[001/600] Iteration[003/030] Train loss: 0.8591
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[004/030] Train loss: 0.8474
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[005/030] Train loss: 0.8383
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[006/030] Train loss: 0.8330
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[007/030] Train loss: 0.8278
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[008/030] Train loss: 0.8207
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[009/030] Train loss: 0.8139
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[010/030] Train loss: 0.8073
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[011/030] Train loss: 0.8013
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[012/030] Train loss: 0.7954
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[013/030] Train loss: 0.7893
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[014/030] Train loss: 0.7843
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[015/030] Train loss: 0.7789
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[016/030] Train loss: 0.7739
2023-02-06 11:46:58 | Train | Epoch[001/600] Iteration[017/030] Train loss: 0.7692
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[018/030] Train loss: 0.7646
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[019/030] Train loss: 0.7602
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[020/030] Train loss: 0.7561
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[021/030] Train loss: 0.7522
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[022/030] Train loss: 0.7483
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[023/030] Train loss: 0.7447
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[024/030] Train loss: 0.7414
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[025/030] Train loss: 0.7379
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[026/030] Train loss: 0.7348
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[027/030] Train loss: 0.7317
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[028/030] Train loss: 0.7288
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[029/030] Train loss: 0.7260
2023-02-06 11:46:59 | Train | Epoch[001/600] Iteration[030/030] Train loss: 0.7233
2023-02-06 11:47:00 | Valid | Epoch[001/600] Iteration[001/008] Valid loss: 0.6417
2023-02-06 11:47:00 | Valid | Epoch[001/600] Iteration[002/008] Valid loss: 0.6417
2023-02-06 11:47:00 | Valid | Epoch[001/600] Iteration[003/008] Valid loss: 0.6411
2023-02-06 11:47:00 | Valid | Epoch[001/600] Iteration[004/008] Valid loss: 0.6412
2023-02-06 11:47:00 | Valid | Epoch[001/600] Iteration[005/008] Valid loss: 0.6406
2023-02-06 11:47:00 | Valid | Epoch[001/600] Iteration[006/008] Valid loss: 0.6401
2023-02-06 11:47:00 | Valid | Epoch[001/600] Iteration[007/008] Valid loss: 0.6393
2023-02-06 11:47:00 | Valid | Epoch[001/600] Iteration[008/008] Valid loss: 0.6392
2023-02-06 11:47:00 | Valid | Epoch[001/600] MIou: 0.717512737467912
2023-02-06 11:47:00 | Valid | Epoch[001/600] Pixel Accuracy: 0.9461771647135416
2023-02-06 11:47:00 | Valid | Epoch[001/600] Mean Pixel Accuracy: 0.7797840577559653
2023-02-06 11:47:00 | Stage | Epoch[001/600] Train loss:0.7233
2023-02-06 11:47:00 | Stage | Epoch[001/600] Valid loss:0.6392
2023-02-06 11:47:00 | Stage | Epoch[001/600] LR:0.01

2023-02-06 11:47:00 | Train | Epoch[002/600] Iteration[001/030] Train loss: 0.6437
2023-02-06 11:47:00 | Train | Epoch[002/600] Iteration[002/030] Train loss: 0.6422
2023-02-06 11:47:00 | Train | Epoch[002/600] Iteration[003/030] Train loss: 0.6426
2023-02-06 11:47:00 | Train | Epoch[002/600] Iteration[004/030] Train loss: 0.6408
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[005/030] Train loss: 0.6394
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[006/030] Train loss: 0.6384
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[007/030] Train loss: 0.6374
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[008/030] Train loss: 0.6362
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[009/030] Train loss: 0.6352
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[010/030] Train loss: 0.6342
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[011/030] Train loss: 0.6331
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[012/030] Train loss: 0.6321
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[013/030] Train loss: 0.6314
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[014/030] Train loss: 0.6305
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[015/030] Train loss: 0.6297
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[016/030] Train loss: 0.6289
2023-02-06 11:47:01 | Train | Epoch[002/600] Iteration[017/030] Train loss: 0.6283
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[018/030] Train loss: 0.6276
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[019/030] Train loss: 0.6270
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[020/030] Train loss: 0.6262
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[021/030] Train loss: 0.6254
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[022/030] Train loss: 0.6248
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[023/030] Train loss: 0.6241
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[024/030] Train loss: 0.6235
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[025/030] Train loss: 0.6227
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[026/030] Train loss: 0.6221
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[027/030] Train loss: 0.6215
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[028/030] Train loss: 0.6211
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[029/030] Train loss: 0.6207
2023-02-06 11:47:02 | Train | Epoch[002/600] Iteration[030/030] Train loss: 0.6202
2023-02-06 11:47:03 | Valid | Epoch[002/600] Iteration[001/008] Valid loss: 0.6309
2023-02-06 11:47:03 | Valid | Epoch[002/600] Iteration[002/008] Valid loss: 0.6307
2023-02-06 11:47:03 | Valid | Epoch[002/600] Iteration[003/008] Valid loss: 0.6306
2023-02-06 11:47:03 | Valid | Epoch[002/600] Iteration[004/008] Valid loss: 0.6305
2023-02-06 11:47:03 | Valid | Epoch[002/600] Iteration[005/008] Valid loss: 0.6304
2023-02-06 11:47:03 | Valid | Epoch[002/600] Iteration[006/008] Valid loss: 0.6304
2023-02-06 11:47:03 | Valid | Epoch[002/600] Iteration[007/008] Valid loss: 0.6303
2023-02-06 11:47:03 | Valid | Epoch[002/600] Iteration[008/008] Valid loss: 0.6302
2023-02-06 11:47:03 | Valid | Epoch[002/600] MIou: 0.6538780038963224
2023-02-06 11:47:03 | Valid | Epoch[002/600] Pixel Accuracy: 0.9425773620605469
2023-02-06 11:47:03 | Valid | Epoch[002/600] Mean Pixel Accuracy: 0.6842010717571753
2023-02-06 11:47:03 | Stage | Epoch[002/600] Train loss:0.6202
2023-02-06 11:47:03 | Stage | Epoch[002/600] Valid loss:0.6302
2023-02-06 11:47:03 | Stage | Epoch[002/600] LR:0.01

2023-02-06 11:47:03 | Train | Epoch[003/600] Iteration[001/030] Train loss: 0.6050
2023-02-06 11:47:03 | Train | Epoch[003/600] Iteration[002/030] Train loss: 0.6057
2023-02-06 11:47:03 | Train | Epoch[003/600] Iteration[003/030] Train loss: 0.6047
2023-02-06 11:47:03 | Train | Epoch[003/600] Iteration[004/030] Train loss: 0.6036
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[005/030] Train loss: 0.6033
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[006/030] Train loss: 0.6025
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[007/030] Train loss: 0.6019
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[008/030] Train loss: 0.6019
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[009/030] Train loss: 0.6014
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[010/030] Train loss: 0.6011
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[011/030] Train loss: 0.6009
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[012/030] Train loss: 0.6002
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[013/030] Train loss: 0.5996
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[014/030] Train loss: 0.5996
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[015/030] Train loss: 0.5993
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[016/030] Train loss: 0.5988
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[017/030] Train loss: 0.5983
2023-02-06 11:47:04 | Train | Epoch[003/600] Iteration[018/030] Train loss: 0.5981
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[019/030] Train loss: 0.5975
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[020/030] Train loss: 0.5972
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[021/030] Train loss: 0.5969
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[022/030] Train loss: 0.5964
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[023/030] Train loss: 0.5959
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[024/030] Train loss: 0.5954
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[025/030] Train loss: 0.5949
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[026/030] Train loss: 0.5947
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[027/030] Train loss: 0.5943
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[028/030] Train loss: 0.5940
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[029/030] Train loss: 0.5935
2023-02-06 11:47:05 | Train | Epoch[003/600] Iteration[030/030] Train loss: 0.5932
2023-02-06 11:47:06 | Valid | Epoch[003/600] Iteration[001/008] Valid loss: 0.6018
2023-02-06 11:47:06 | Valid | Epoch[003/600] Iteration[002/008] Valid loss: 0.6005
2023-02-06 11:47:06 | Valid | Epoch[003/600] Iteration[003/008] Valid loss: 0.5997
2023-02-06 11:47:06 | Valid | Epoch[003/600] Iteration[004/008] Valid loss: 0.5997
2023-02-06 11:47:06 | Valid | Epoch[003/600] Iteration[005/008] Valid loss: 0.5987
2023-02-06 11:47:06 | Valid | Epoch[003/600] Iteration[006/008] Valid loss: 0.5986
2023-02-06 11:47:06 | Valid | Epoch[003/600] Iteration[007/008] Valid loss: 0.5981
2023-02-06 11:47:06 | Valid | Epoch[003/600] Iteration[008/008] Valid loss: 0.5976
2023-02-06 11:47:06 | Valid | Epoch[003/600] MIou: 0.8189397661811515
2023-02-06 11:47:06 | Valid | Epoch[003/600] Pixel Accuracy: 0.9688453674316406
2023-02-06 11:47:06 | Valid | Epoch[003/600] Mean Pixel Accuracy: 0.8495676716860092
2023-02-06 11:47:06 | Stage | Epoch[003/600] Train loss:0.5932
2023-02-06 11:47:06 | Stage | Epoch[003/600] Valid loss:0.5976
2023-02-06 11:47:06 | Stage | Epoch[003/600] LR:0.01

2023-02-06 11:47:06 | Train | Epoch[004/600] Iteration[001/030] Train loss: 0.5796
2023-02-06 11:47:06 | Train | Epoch[004/600] Iteration[002/030] Train loss: 0.5812
2023-02-06 11:47:06 | Train | Epoch[004/600] Iteration[003/030] Train loss: 0.5805
2023-02-06 11:47:06 | Train | Epoch[004/600] Iteration[004/030] Train loss: 0.5802
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[005/030] Train loss: 0.5794
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[006/030] Train loss: 0.5795
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[007/030] Train loss: 0.5791
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[008/030] Train loss: 0.5786
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[009/030] Train loss: 0.5783
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[010/030] Train loss: 0.5779
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[011/030] Train loss: 0.5776
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[012/030] Train loss: 0.5771
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[013/030] Train loss: 0.5767
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[014/030] Train loss: 0.5767
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[015/030] Train loss: 0.5763
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[016/030] Train loss: 0.5760
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[017/030] Train loss: 0.5760
2023-02-06 11:47:07 | Train | Epoch[004/600] Iteration[018/030] Train loss: 0.5755
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[019/030] Train loss: 0.5751
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[020/030] Train loss: 0.5747
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[021/030] Train loss: 0.5744
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[022/030] Train loss: 0.5744
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[023/030] Train loss: 0.5743
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[024/030] Train loss: 0.5741
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[025/030] Train loss: 0.5737
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[026/030] Train loss: 0.5735
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[027/030] Train loss: 0.5733
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[028/030] Train loss: 0.5729
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[029/030] Train loss: 0.5726
2023-02-06 11:47:08 | Train | Epoch[004/600] Iteration[030/030] Train loss: 0.5722
2023-02-06 11:47:09 | Valid | Epoch[004/600] Iteration[001/008] Valid loss: 0.6450
2023-02-06 11:47:09 | Valid | Epoch[004/600] Iteration[002/008] Valid loss: 0.6503
2023-02-06 11:47:09 | Valid | Epoch[004/600] Iteration[003/008] Valid loss: 0.6503
2023-02-06 11:47:09 | Valid | Epoch[004/600] Iteration[004/008] Valid loss: 0.6500
2023-02-06 11:47:09 | Valid | Epoch[004/600] Iteration[005/008] Valid loss: 0.6482
2023-02-06 11:47:09 | Valid | Epoch[004/600] Iteration[006/008] Valid loss: 0.6457
2023-02-06 11:47:09 | Valid | Epoch[004/600] Iteration[007/008] Valid loss: 0.6452
2023-02-06 11:47:09 | Valid | Epoch[004/600] Iteration[008/008] Valid loss: 0.6482
2023-02-06 11:47:09 | Valid | Epoch[004/600] MIou: 0.5509878207065317
2023-02-06 11:47:09 | Valid | Epoch[004/600] Pixel Accuracy: 0.8062718709309896
2023-02-06 11:47:09 | Valid | Epoch[004/600] Mean Pixel Accuracy: 0.8865822821245856
2023-02-06 11:47:09 | Stage | Epoch[004/600] Train loss:0.5722
2023-02-06 11:47:09 | Stage | Epoch[004/600] Valid loss:0.6482
2023-02-06 11:47:09 | Stage | Epoch[004/600] LR:0.01

2023-02-06 11:47:09 | Train | Epoch[005/600] Iteration[001/030] Train loss: 0.5605
2023-02-06 11:47:09 | Train | Epoch[005/600] Iteration[002/030] Train loss: 0.5615
2023-02-06 11:47:09 | Train | Epoch[005/600] Iteration[003/030] Train loss: 0.5623
2023-02-06 11:47:09 | Train | Epoch[005/600] Iteration[004/030] Train loss: 0.5614
2023-02-06 11:47:09 | Train | Epoch[005/600] Iteration[005/030] Train loss: 0.5611
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[006/030] Train loss: 0.5607
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[007/030] Train loss: 0.5607
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[008/030] Train loss: 0.5602
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[009/030] Train loss: 0.5597
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[010/030] Train loss: 0.5593
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[011/030] Train loss: 0.5590
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[012/030] Train loss: 0.5590
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[013/030] Train loss: 0.5590
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[014/030] Train loss: 0.5586
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[015/030] Train loss: 0.5582
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[016/030] Train loss: 0.5578
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[017/030] Train loss: 0.5572
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[018/030] Train loss: 0.5569
2023-02-06 11:47:10 | Train | Epoch[005/600] Iteration[019/030] Train loss: 0.5565
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[020/030] Train loss: 0.5561
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[021/030] Train loss: 0.5556
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[022/030] Train loss: 0.5551
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[023/030] Train loss: 0.5548
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[024/030] Train loss: 0.5545
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[025/030] Train loss: 0.5542
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[026/030] Train loss: 0.5538
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[027/030] Train loss: 0.5534
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[028/030] Train loss: 0.5530
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[029/030] Train loss: 0.5530
2023-02-06 11:47:11 | Train | Epoch[005/600] Iteration[030/030] Train loss: 0.5525
2023-02-06 11:47:12 | Valid | Epoch[005/600] Iteration[001/008] Valid loss: 0.5516
2023-02-06 11:47:12 | Valid | Epoch[005/600] Iteration[002/008] Valid loss: 0.5515
2023-02-06 11:47:12 | Valid | Epoch[005/600] Iteration[003/008] Valid loss: 0.5507
2023-02-06 11:47:12 | Valid | Epoch[005/600] Iteration[004/008] Valid loss: 0.5499
2023-02-06 11:47:12 | Valid | Epoch[005/600] Iteration[005/008] Valid loss: 0.5500
2023-02-06 11:47:12 | Valid | Epoch[005/600] Iteration[006/008] Valid loss: 0.5496
2023-02-06 11:47:12 | Valid | Epoch[005/600] Iteration[007/008] Valid loss: 0.5503
2023-02-06 11:47:12 | Valid | Epoch[005/600] Iteration[008/008] Valid loss: 0.5501
2023-02-06 11:47:12 | Valid | Epoch[005/600] MIou: 0.8595282880309238
2023-02-06 11:47:12 | Valid | Epoch[005/600] Pixel Accuracy: 0.9707908630371094
2023-02-06 11:47:12 | Valid | Epoch[005/600] Mean Pixel Accuracy: 0.9730778444139287
2023-02-06 11:47:12 | Stage | Epoch[005/600] Train loss:0.5525
2023-02-06 11:47:12 | Stage | Epoch[005/600] Valid loss:0.5501
2023-02-06 11:47:12 | Stage | Epoch[005/600] LR:0.01

2023-02-06 11:47:12 | Train | Epoch[006/600] Iteration[001/030] Train loss: 0.5449
2023-02-06 11:47:12 | Train | Epoch[006/600] Iteration[002/030] Train loss: 0.5429
2023-02-06 11:47:12 | Train | Epoch[006/600] Iteration[003/030] Train loss: 0.5443
2023-02-06 11:47:12 | Train | Epoch[006/600] Iteration[004/030] Train loss: 0.5442
2023-02-06 11:47:12 | Train | Epoch[006/600] Iteration[005/030] Train loss: 0.5427
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[006/030] Train loss: 0.5420
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[007/030] Train loss: 0.5425
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[008/030] Train loss: 0.5418
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[009/030] Train loss: 0.5417
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[010/030] Train loss: 0.5411
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[011/030] Train loss: 0.5411
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[012/030] Train loss: 0.5403
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[013/030] Train loss: 0.5397
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[014/030] Train loss: 0.5391
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[015/030] Train loss: 0.5386
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[016/030] Train loss: 0.5381
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[017/030] Train loss: 0.5379
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[018/030] Train loss: 0.5373
2023-02-06 11:47:13 | Train | Epoch[006/600] Iteration[019/030] Train loss: 0.5370
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[020/030] Train loss: 0.5366
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[021/030] Train loss: 0.5362
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[022/030] Train loss: 0.5360
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[023/030] Train loss: 0.5357
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[024/030] Train loss: 0.5354
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[025/030] Train loss: 0.5349
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[026/030] Train loss: 0.5347
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[027/030] Train loss: 0.5342
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[028/030] Train loss: 0.5338
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[029/030] Train loss: 0.5334
2023-02-06 11:47:14 | Train | Epoch[006/600] Iteration[030/030] Train loss: 0.5331
2023-02-06 11:47:15 | Valid | Epoch[006/600] Iteration[001/008] Valid loss: 0.5293
2023-02-06 11:47:15 | Valid | Epoch[006/600] Iteration[002/008] Valid loss: 0.5296
2023-02-06 11:47:15 | Valid | Epoch[006/600] Iteration[003/008] Valid loss: 0.5281
2023-02-06 11:47:15 | Valid | Epoch[006/600] Iteration[004/008] Valid loss: 0.5274
2023-02-06 11:47:15 | Valid | Epoch[006/600] Iteration[005/008] Valid loss: 0.5273
2023-02-06 11:47:15 | Valid | Epoch[006/600] Iteration[006/008] Valid loss: 0.5269
2023-02-06 11:47:15 | Valid | Epoch[006/600] Iteration[007/008] Valid loss: 0.5274
2023-02-06 11:47:15 | Valid | Epoch[006/600] Iteration[008/008] Valid loss: 0.5269
2023-02-06 11:47:15 | Valid | Epoch[006/600] MIou: 0.8892955309087061
2023-02-06 11:47:15 | Valid | Epoch[006/600] Pixel Accuracy: 0.9784406026204427
2023-02-06 11:47:15 | Valid | Epoch[006/600] Mean Pixel Accuracy: 0.9738269105683477
2023-02-06 11:47:15 | Stage | Epoch[006/600] Train loss:0.5331
2023-02-06 11:47:15 | Stage | Epoch[006/600] Valid loss:0.5269
2023-02-06 11:47:15 | Stage | Epoch[006/600] LR:0.01

2023-02-06 11:47:15 | Train | Epoch[007/600] Iteration[001/030] Train loss: 0.5201
2023-02-06 11:47:15 | Train | Epoch[007/600] Iteration[002/030] Train loss: 0.5217
2023-02-06 11:47:15 | Train | Epoch[007/600] Iteration[003/030] Train loss: 0.5223
2023-02-06 11:47:15 | Train | Epoch[007/600] Iteration[004/030] Train loss: 0.5227
2023-02-06 11:47:15 | Train | Epoch[007/600] Iteration[005/030] Train loss: 0.5224
2023-02-06 11:47:15 | Train | Epoch[007/600] Iteration[006/030] Train loss: 0.5220
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[007/030] Train loss: 0.5218
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[008/030] Train loss: 0.5214
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[009/030] Train loss: 0.5207
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[010/030] Train loss: 0.5204
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[011/030] Train loss: 0.5203
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[012/030] Train loss: 0.5200
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[013/030] Train loss: 0.5195
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[014/030] Train loss: 0.5188
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[015/030] Train loss: 0.5187
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[016/030] Train loss: 0.5183
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[017/030] Train loss: 0.5180
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[018/030] Train loss: 0.5178
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[019/030] Train loss: 0.5175
2023-02-06 11:47:16 | Train | Epoch[007/600] Iteration[020/030] Train loss: 0.5170
2023-02-06 11:47:17 | Train | Epoch[007/600] Iteration[021/030] Train loss: 0.5165
2023-02-06 11:47:17 | Train | Epoch[007/600] Iteration[022/030] Train loss: 0.5162
2023-02-06 11:47:17 | Train | Epoch[007/600] Iteration[023/030] Train loss: 0.5159
2023-02-06 11:47:17 | Train | Epoch[007/600] Iteration[024/030] Train loss: 0.5156
2023-02-06 11:47:17 | Train | Epoch[007/600] Iteration[025/030] Train loss: 0.5154
2023-02-06 11:47:17 | Train | Epoch[007/600] Iteration[026/030] Train loss: 0.5153
2023-02-06 11:47:17 | Train | Epoch[007/600] Iteration[027/030] Train loss: 0.5148
2023-02-06 11:47:17 | Train | Epoch[007/600] Iteration[028/030] Train loss: 0.5144
2023-02-06 11:47:17 | Train | Epoch[007/600] Iteration[029/030] Train loss: 0.5140
2023-02-06 11:47:17 | Train | Epoch[007/600] Iteration[030/030] Train loss: 0.5137
2023-02-06 11:47:18 | Valid | Epoch[007/600] Iteration[001/008] Valid loss: 0.5271
2023-02-06 11:47:18 | Valid | Epoch[007/600] Iteration[002/008] Valid loss: 0.5259
2023-02-06 11:47:18 | Valid | Epoch[007/600] Iteration[003/008] Valid loss: 0.5246
2023-02-06 11:47:18 | Valid | Epoch[007/600] Iteration[004/008] Valid loss: 0.5241
2023-02-06 11:47:18 | Valid | Epoch[007/600] Iteration[005/008] Valid loss: 0.5241
2023-02-06 11:47:18 | Valid | Epoch[007/600] Iteration[006/008] Valid loss: 0.5230
2023-02-06 11:47:18 | Valid | Epoch[007/600] Iteration[007/008] Valid loss: 0.5246
2023-02-06 11:47:18 | Valid | Epoch[007/600] Iteration[008/008] Valid loss: 0.5248
2023-02-06 11:47:18 | Valid | Epoch[007/600] MIou: 0.8447867931155187
2023-02-06 11:47:18 | Valid | Epoch[007/600] Pixel Accuracy: 0.9665565490722656
2023-02-06 11:47:18 | Valid | Epoch[007/600] Mean Pixel Accuracy: 0.9737241660088932
2023-02-06 11:47:18 | Stage | Epoch[007/600] Train loss:0.5137
2023-02-06 11:47:18 | Stage | Epoch[007/600] Valid loss:0.5248
2023-02-06 11:47:18 | Stage | Epoch[007/600] LR:0.01

2023-02-06 11:47:18 | Train | Epoch[008/600] Iteration[001/030] Train loss: 0.5048
2023-02-06 11:47:18 | Train | Epoch[008/600] Iteration[002/030] Train loss: 0.5024
2023-02-06 11:47:18 | Train | Epoch[008/600] Iteration[003/030] Train loss: 0.5003
2023-02-06 11:47:18 | Train | Epoch[008/600] Iteration[004/030] Train loss: 0.5004
2023-02-06 11:47:18 | Train | Epoch[008/600] Iteration[005/030] Train loss: 0.4999
2023-02-06 11:47:18 | Train | Epoch[008/600] Iteration[006/030] Train loss: 0.4999
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[007/030] Train loss: 0.4999
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[008/030] Train loss: 0.5004
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[009/030] Train loss: 0.5005
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[010/030] Train loss: 0.5005
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[011/030] Train loss: 0.5004
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[012/030] Train loss: 0.5001
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[013/030] Train loss: 0.4997
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[014/030] Train loss: 0.4995
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[015/030] Train loss: 0.4992
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[016/030] Train loss: 0.4989
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[017/030] Train loss: 0.4985
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[018/030] Train loss: 0.4980
2023-02-06 11:47:19 | Train | Epoch[008/600] Iteration[019/030] Train loss: 0.4981
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[020/030] Train loss: 0.4980
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[021/030] Train loss: 0.4975
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[022/030] Train loss: 0.4970
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[023/030] Train loss: 0.4969
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[024/030] Train loss: 0.4965
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[025/030] Train loss: 0.4961
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[026/030] Train loss: 0.4958
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[027/030] Train loss: 0.4954
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[028/030] Train loss: 0.4951
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[029/030] Train loss: 0.4950
2023-02-06 11:47:20 | Train | Epoch[008/600] Iteration[030/030] Train loss: 0.4947
2023-02-06 11:47:21 | Valid | Epoch[008/600] Iteration[001/008] Valid loss: 0.5101
2023-02-06 11:47:21 | Valid | Epoch[008/600] Iteration[002/008] Valid loss: 0.5120
2023-02-06 11:47:21 | Valid | Epoch[008/600] Iteration[003/008] Valid loss: 0.5123
2023-02-06 11:47:21 | Valid | Epoch[008/600] Iteration[004/008] Valid loss: 0.5117
2023-02-06 11:47:21 | Valid | Epoch[008/600] Iteration[005/008] Valid loss: 0.5121
2023-02-06 11:47:21 | Valid | Epoch[008/600] Iteration[006/008] Valid loss: 0.5118
2023-02-06 11:47:21 | Valid | Epoch[008/600] Iteration[007/008] Valid loss: 0.5114
2023-02-06 11:47:21 | Valid | Epoch[008/600] Iteration[008/008] Valid loss: 0.5120
2023-02-06 11:47:21 | Valid | Epoch[008/600] MIou: 0.7209950371949687
2023-02-06 11:47:21 | Valid | Epoch[008/600] Pixel Accuracy: 0.9538930257161459
2023-02-06 11:47:21 | Valid | Epoch[008/600] Mean Pixel Accuracy: 0.745398871584919
2023-02-06 11:47:21 | Stage | Epoch[008/600] Train loss:0.4947
2023-02-06 11:47:21 | Stage | Epoch[008/600] Valid loss:0.5120
2023-02-06 11:47:21 | Stage | Epoch[008/600] LR:0.01

2023-02-06 11:47:21 | Train | Epoch[009/600] Iteration[001/030] Train loss: 0.4813
2023-02-06 11:47:21 | Train | Epoch[009/600] Iteration[002/030] Train loss: 0.4850
2023-02-06 11:47:21 | Train | Epoch[009/600] Iteration[003/030] Train loss: 0.4856
2023-02-06 11:47:21 | Train | Epoch[009/600] Iteration[004/030] Train loss: 0.4852
2023-02-06 11:47:21 | Train | Epoch[009/600] Iteration[005/030] Train loss: 0.4846
2023-02-06 11:47:21 | Train | Epoch[009/600] Iteration[006/030] Train loss: 0.4835
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[007/030] Train loss: 0.4837
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[008/030] Train loss: 0.4841
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[009/030] Train loss: 0.4837
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[010/030] Train loss: 0.4829
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[011/030] Train loss: 0.4823
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[012/030] Train loss: 0.4818
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[013/030] Train loss: 0.4814
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[014/030] Train loss: 0.4810
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[015/030] Train loss: 0.4809
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[016/030] Train loss: 0.4809
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[017/030] Train loss: 0.4804
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[018/030] Train loss: 0.4804
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[019/030] Train loss: 0.4801
2023-02-06 11:47:22 | Train | Epoch[009/600] Iteration[020/030] Train loss: 0.4799
2023-02-06 11:47:23 | Train | Epoch[009/600] Iteration[021/030] Train loss: 0.4795
2023-02-06 11:47:23 | Train | Epoch[009/600] Iteration[022/030] Train loss: 0.4792
2023-02-06 11:47:23 | Train | Epoch[009/600] Iteration[023/030] Train loss: 0.4787
2023-02-06 11:47:23 | Train | Epoch[009/600] Iteration[024/030] Train loss: 0.4783
2023-02-06 11:47:23 | Train | Epoch[009/600] Iteration[025/030] Train loss: 0.4780
2023-02-06 11:47:23 | Train | Epoch[009/600] Iteration[026/030] Train loss: 0.4775
2023-02-06 11:47:23 | Train | Epoch[009/600] Iteration[027/030] Train loss: 0.4773
2023-02-06 11:47:23 | Train | Epoch[009/600] Iteration[028/030] Train loss: 0.4771
2023-02-06 11:47:23 | Train | Epoch[009/600] Iteration[029/030] Train loss: 0.4767
2023-02-06 11:47:23 | Train | Epoch[009/600] Iteration[030/030] Train loss: 0.4763
2023-02-06 11:47:24 | Valid | Epoch[009/600] Iteration[001/008] Valid loss: 0.7129
2023-02-06 11:47:24 | Valid | Epoch[009/600] Iteration[002/008] Valid loss: 0.7139
2023-02-06 11:47:24 | Valid | Epoch[009/600] Iteration[003/008] Valid loss: 0.7178
2023-02-06 11:47:24 | Valid | Epoch[009/600] Iteration[004/008] Valid loss: 0.7201
2023-02-06 11:47:24 | Valid | Epoch[009/600] Iteration[005/008] Valid loss: 0.7235
2023-02-06 11:47:24 | Valid | Epoch[009/600] Iteration[006/008] Valid loss: 0.7201
2023-02-06 11:47:24 | Valid | Epoch[009/600] Iteration[007/008] Valid loss: 0.7257
2023-02-06 11:47:24 | Valid | Epoch[009/600] Iteration[008/008] Valid loss: 0.7304
2023-02-06 11:47:24 | Valid | Epoch[009/600] MIou: 0.5570517996632491
2023-02-06 11:47:24 | Valid | Epoch[009/600] Pixel Accuracy: 0.8104731241861979
2023-02-06 11:47:24 | Valid | Epoch[009/600] Mean Pixel Accuracy: 0.8951558559467006
2023-02-06 11:47:24 | Stage | Epoch[009/600] Train loss:0.4763
2023-02-06 11:47:24 | Stage | Epoch[009/600] Valid loss:0.7304
2023-02-06 11:47:24 | Stage | Epoch[009/600] LR:0.01

2023-02-06 11:47:24 | Train | Epoch[010/600] Iteration[001/030] Train loss: 0.4620
2023-02-06 11:47:24 | Train | Epoch[010/600] Iteration[002/030] Train loss: 0.4626
2023-02-06 11:47:24 | Train | Epoch[010/600] Iteration[003/030] Train loss: 0.4649
2023-02-06 11:47:24 | Train | Epoch[010/600] Iteration[004/030] Train loss: 0.4651
2023-02-06 11:47:24 | Train | Epoch[010/600] Iteration[005/030] Train loss: 0.4650
2023-02-06 11:47:24 | Train | Epoch[010/600] Iteration[006/030] Train loss: 0.4653
2023-02-06 11:47:24 | Train | Epoch[010/600] Iteration[007/030] Train loss: 0.4654
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[008/030] Train loss: 0.4647
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[009/030] Train loss: 0.4644
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[010/030] Train loss: 0.4643
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[011/030] Train loss: 0.4639
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[012/030] Train loss: 0.4635
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[013/030] Train loss: 0.4633
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[014/030] Train loss: 0.4630
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[015/030] Train loss: 0.4625
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[016/030] Train loss: 0.4623
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[017/030] Train loss: 0.4620
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[018/030] Train loss: 0.4617
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[019/030] Train loss: 0.4617
2023-02-06 11:47:25 | Train | Epoch[010/600] Iteration[020/030] Train loss: 0.4615
2023-02-06 11:47:26 | Train | Epoch[010/600] Iteration[021/030] Train loss: 0.4613
2023-02-06 11:47:26 | Train | Epoch[010/600] Iteration[022/030] Train loss: 0.4609
2023-02-06 11:47:26 | Train | Epoch[010/600] Iteration[023/030] Train loss: 0.4607
2023-02-06 11:47:26 | Train | Epoch[010/600] Iteration[024/030] Train loss: 0.4606
2023-02-06 11:47:26 | Train | Epoch[010/600] Iteration[025/030] Train loss: 0.4602
2023-02-06 11:47:26 | Train | Epoch[010/600] Iteration[026/030] Train loss: 0.4598
2023-02-06 11:47:26 | Train | Epoch[010/600] Iteration[027/030] Train loss: 0.4595
2023-02-06 11:47:26 | Train | Epoch[010/600] Iteration[028/030] Train loss: 0.4591
2023-02-06 11:47:26 | Train | Epoch[010/600] Iteration[029/030] Train loss: 0.4588
2023-02-06 11:47:26 | Train | Epoch[010/600] Iteration[030/030] Train loss: 0.4584
2023-02-06 11:47:26 | Valid | Epoch[010/600] Iteration[001/008] Valid loss: 0.4610
2023-02-06 11:47:27 | Valid | Epoch[010/600] Iteration[002/008] Valid loss: 0.4620
2023-02-06 11:47:27 | Valid | Epoch[010/600] Iteration[003/008] Valid loss: 0.4615
2023-02-06 11:47:27 | Valid | Epoch[010/600] Iteration[004/008] Valid loss: 0.4606
2023-02-06 11:47:27 | Valid | Epoch[010/600] Iteration[005/008] Valid loss: 0.4607
2023-02-06 11:47:27 | Valid | Epoch[010/600] Iteration[006/008] Valid loss: 0.4605
2023-02-06 11:47:27 | Valid | Epoch[010/600] Iteration[007/008] Valid loss: 0.4605
2023-02-06 11:47:27 | Valid | Epoch[010/600] Iteration[008/008] Valid loss: 0.4605
2023-02-06 11:47:27 | Valid | Epoch[010/600] MIou: 0.8730811440922535
2023-02-06 11:47:27 | Valid | Epoch[010/600] Pixel Accuracy: 0.978661855061849
2023-02-06 11:47:27 | Valid | Epoch[010/600] Mean Pixel Accuracy: 0.8923846948149383
2023-02-06 11:47:27 | Stage | Epoch[010/600] Train loss:0.4584
2023-02-06 11:47:27 | Stage | Epoch[010/600] Valid loss:0.4605
2023-02-06 11:47:27 | Stage | Epoch[010/600] LR:0.01

2023-02-06 11:47:27 | Train | Epoch[011/600] Iteration[001/030] Train loss: 0.4473
2023-02-06 11:47:27 | Train | Epoch[011/600] Iteration[002/030] Train loss: 0.4474
2023-02-06 11:47:27 | Train | Epoch[011/600] Iteration[003/030] Train loss: 0.4464
2023-02-06 11:47:27 | Train | Epoch[011/600] Iteration[004/030] Train loss: 0.4467
2023-02-06 11:47:27 | Train | Epoch[011/600] Iteration[005/030] Train loss: 0.4470
2023-02-06 11:47:27 | Train | Epoch[011/600] Iteration[006/030] Train loss: 0.4483
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[007/030] Train loss: 0.4482
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[008/030] Train loss: 0.4482
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[009/030] Train loss: 0.4479
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[010/030] Train loss: 0.4476
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[011/030] Train loss: 0.4469
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[012/030] Train loss: 0.4461
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[013/030] Train loss: 0.4459
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[014/030] Train loss: 0.4457
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[015/030] Train loss: 0.4451
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[016/030] Train loss: 0.4447
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[017/030] Train loss: 0.4444
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[018/030] Train loss: 0.4441
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[019/030] Train loss: 0.4440
2023-02-06 11:47:28 | Train | Epoch[011/600] Iteration[020/030] Train loss: 0.4443
2023-02-06 11:47:29 | Train | Epoch[011/600] Iteration[021/030] Train loss: 0.4441
2023-02-06 11:47:29 | Train | Epoch[011/600] Iteration[022/030] Train loss: 0.4436
2023-02-06 11:47:29 | Train | Epoch[011/600] Iteration[023/030] Train loss: 0.4434
2023-02-06 11:47:29 | Train | Epoch[011/600] Iteration[024/030] Train loss: 0.4431
2023-02-06 11:47:29 | Train | Epoch[011/600] Iteration[025/030] Train loss: 0.4428
2023-02-06 11:47:29 | Train | Epoch[011/600] Iteration[026/030] Train loss: 0.4426
2023-02-06 11:47:29 | Train | Epoch[011/600] Iteration[027/030] Train loss: 0.4423
2023-02-06 11:47:29 | Train | Epoch[011/600] Iteration[028/030] Train loss: 0.4419
2023-02-06 11:47:29 | Train | Epoch[011/600] Iteration[029/030] Train loss: 0.4418
2023-02-06 11:47:29 | Train | Epoch[011/600] Iteration[030/030] Train loss: 0.4416
2023-02-06 11:47:30 | Valid | Epoch[011/600] Iteration[001/008] Valid loss: 0.4676
2023-02-06 11:47:30 | Valid | Epoch[011/600] Iteration[002/008] Valid loss: 0.4667
2023-02-06 11:47:30 | Valid | Epoch[011/600] Iteration[003/008] Valid loss: 0.4665
2023-02-06 11:47:30 | Valid | Epoch[011/600] Iteration[004/008] Valid loss: 0.4663
2023-02-06 11:47:30 | Valid | Epoch[011/600] Iteration[005/008] Valid loss: 0.4670
2023-02-06 11:47:30 | Valid | Epoch[011/600] Iteration[006/008] Valid loss: 0.4659
2023-02-06 11:47:30 | Valid | Epoch[011/600] Iteration[007/008] Valid loss: 0.4684
2023-02-06 11:47:30 | Valid | Epoch[011/600] Iteration[008/008] Valid loss: 0.4688
2023-02-06 11:47:30 | Valid | Epoch[011/600] MIou: 0.8476178438088303
2023-02-06 11:47:30 | Valid | Epoch[011/600] Pixel Accuracy: 0.9671198527018229
2023-02-06 11:47:30 | Valid | Epoch[011/600] Mean Pixel Accuracy: 0.9778951288588733
2023-02-06 11:47:30 | Stage | Epoch[011/600] Train loss:0.4416
2023-02-06 11:47:30 | Stage | Epoch[011/600] Valid loss:0.4688
2023-02-06 11:47:30 | Stage | Epoch[011/600] LR:0.01

2023-02-06 11:47:30 | Train | Epoch[012/600] Iteration[001/030] Train loss: 0.4336
2023-02-06 11:47:30 | Train | Epoch[012/600] Iteration[002/030] Train loss: 0.4331
2023-02-06 11:47:30 | Train | Epoch[012/600] Iteration[003/030] Train loss: 0.4318
2023-02-06 11:47:30 | Train | Epoch[012/600] Iteration[004/030] Train loss: 0.4315
2023-02-06 11:47:30 | Train | Epoch[012/600] Iteration[005/030] Train loss: 0.4307
2023-02-06 11:47:30 | Train | Epoch[012/600] Iteration[006/030] Train loss: 0.4306
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[007/030] Train loss: 0.4305
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[008/030] Train loss: 0.4303
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[009/030] Train loss: 0.4298
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[010/030] Train loss: 0.4291
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[011/030] Train loss: 0.4288
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[012/030] Train loss: 0.4292
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[013/030] Train loss: 0.4291
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[014/030] Train loss: 0.4302
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[015/030] Train loss: 0.4298
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[016/030] Train loss: 0.4294
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[017/030] Train loss: 0.4289
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[018/030] Train loss: 0.4288
2023-02-06 11:47:31 | Train | Epoch[012/600] Iteration[019/030] Train loss: 0.4283
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[020/030] Train loss: 0.4279
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[021/030] Train loss: 0.4277
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[022/030] Train loss: 0.4274
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[023/030] Train loss: 0.4270
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[024/030] Train loss: 0.4265
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[025/030] Train loss: 0.4261
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[026/030] Train loss: 0.4262
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[027/030] Train loss: 0.4260
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[028/030] Train loss: 0.4257
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[029/030] Train loss: 0.4254
2023-02-06 11:47:32 | Train | Epoch[012/600] Iteration[030/030] Train loss: 0.4251
2023-02-06 11:47:33 | Valid | Epoch[012/600] Iteration[001/008] Valid loss: 0.5691
2023-02-06 11:47:33 | Valid | Epoch[012/600] Iteration[002/008] Valid loss: 0.5648
2023-02-06 11:47:33 | Valid | Epoch[012/600] Iteration[003/008] Valid loss: 0.5675
2023-02-06 11:47:33 | Valid | Epoch[012/600] Iteration[004/008] Valid loss: 0.5696
2023-02-06 11:47:33 | Valid | Epoch[012/600] Iteration[005/008] Valid loss: 0.5694
2023-02-06 11:47:33 | Valid | Epoch[012/600] Iteration[006/008] Valid loss: 0.5628
2023-02-06 11:47:33 | Valid | Epoch[012/600] Iteration[007/008] Valid loss: 0.5662
2023-02-06 11:47:33 | Valid | Epoch[012/600] Iteration[008/008] Valid loss: 0.5734
2023-02-06 11:47:33 | Valid | Epoch[012/600] MIou: 0.733275371320087
2023-02-06 11:47:33 | Valid | Epoch[012/600] Pixel Accuracy: 0.9259910583496094
2023-02-06 11:47:33 | Valid | Epoch[012/600] Mean Pixel Accuracy: 0.9561069102073009
2023-02-06 11:47:33 | Stage | Epoch[012/600] Train loss:0.4251
2023-02-06 11:47:33 | Stage | Epoch[012/600] Valid loss:0.5734
2023-02-06 11:47:33 | Stage | Epoch[012/600] LR:0.01

2023-02-06 11:47:33 | Train | Epoch[013/600] Iteration[001/030] Train loss: 0.4124
2023-02-06 11:47:33 | Train | Epoch[013/600] Iteration[002/030] Train loss: 0.4142
2023-02-06 11:47:33 | Train | Epoch[013/600] Iteration[003/030] Train loss: 0.4143
2023-02-06 11:47:33 | Train | Epoch[013/600] Iteration[004/030] Train loss: 0.4143
2023-02-06 11:47:33 | Train | Epoch[013/600] Iteration[005/030] Train loss: 0.4138
2023-02-06 11:47:33 | Train | Epoch[013/600] Iteration[006/030] Train loss: 0.4152
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[007/030] Train loss: 0.4143
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[008/030] Train loss: 0.4146
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[009/030] Train loss: 0.4142
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[010/030] Train loss: 0.4138
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[011/030] Train loss: 0.4143
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[012/030] Train loss: 0.4140
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[013/030] Train loss: 0.4139
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[014/030] Train loss: 0.4134
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[015/030] Train loss: 0.4136
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[016/030] Train loss: 0.4131
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[017/030] Train loss: 0.4127
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[018/030] Train loss: 0.4123
2023-02-06 11:47:34 | Train | Epoch[013/600] Iteration[019/030] Train loss: 0.4125
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[020/030] Train loss: 0.4122
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[021/030] Train loss: 0.4120
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[022/030] Train loss: 0.4119
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[023/030] Train loss: 0.4116
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[024/030] Train loss: 0.4115
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[025/030] Train loss: 0.4113
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[026/030] Train loss: 0.4108
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[027/030] Train loss: 0.4105
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[028/030] Train loss: 0.4102
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[029/030] Train loss: 0.4098
2023-02-06 11:47:35 | Train | Epoch[013/600] Iteration[030/030] Train loss: 0.4095
2023-02-06 11:47:36 | Valid | Epoch[013/600] Iteration[001/008] Valid loss: 0.4328
2023-02-06 11:47:36 | Valid | Epoch[013/600] Iteration[002/008] Valid loss: 0.4352
2023-02-06 11:47:36 | Valid | Epoch[013/600] Iteration[003/008] Valid loss: 0.4366
2023-02-06 11:47:36 | Valid | Epoch[013/600] Iteration[004/008] Valid loss: 0.4360
2023-02-06 11:47:36 | Valid | Epoch[013/600] Iteration[005/008] Valid loss: 0.4375
2023-02-06 11:47:36 | Valid | Epoch[013/600] Iteration[006/008] Valid loss: 0.4374
2023-02-06 11:47:36 | Valid | Epoch[013/600] Iteration[007/008] Valid loss: 0.4375
2023-02-06 11:47:36 | Valid | Epoch[013/600] Iteration[008/008] Valid loss: 0.4390
2023-02-06 11:47:36 | Valid | Epoch[013/600] MIou: 0.5580829819381434
2023-02-06 11:47:36 | Valid | Epoch[013/600] Pixel Accuracy: 0.926855723063151
2023-02-06 11:47:36 | Valid | Epoch[013/600] Mean Pixel Accuracy: 0.5953211214671504
2023-02-06 11:47:36 | Stage | Epoch[013/600] Train loss:0.4095
2023-02-06 11:47:36 | Stage | Epoch[013/600] Valid loss:0.4390
2023-02-06 11:47:36 | Stage | Epoch[013/600] LR:0.01

2023-02-06 11:47:36 | Train | Epoch[014/600] Iteration[001/030] Train loss: 0.4003
2023-02-06 11:47:36 | Train | Epoch[014/600] Iteration[002/030] Train loss: 0.4033
2023-02-06 11:47:36 | Train | Epoch[014/600] Iteration[003/030] Train loss: 0.4021
2023-02-06 11:47:36 | Train | Epoch[014/600] Iteration[004/030] Train loss: 0.4010
2023-02-06 11:47:36 | Train | Epoch[014/600] Iteration[005/030] Train loss: 0.3996
2023-02-06 11:47:36 | Train | Epoch[014/600] Iteration[006/030] Train loss: 0.3991
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[007/030] Train loss: 0.3980
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[008/030] Train loss: 0.3978
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[009/030] Train loss: 0.3976
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[010/030] Train loss: 0.3970
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[011/030] Train loss: 0.3970
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[012/030] Train loss: 0.3975
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[013/030] Train loss: 0.3973
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[014/030] Train loss: 0.3969
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[015/030] Train loss: 0.3968
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[016/030] Train loss: 0.3964
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[017/030] Train loss: 0.3962
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[018/030] Train loss: 0.3959
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[019/030] Train loss: 0.3957
2023-02-06 11:47:37 | Train | Epoch[014/600] Iteration[020/030] Train loss: 0.3955
2023-02-06 11:47:38 | Train | Epoch[014/600] Iteration[021/030] Train loss: 0.3953
2023-02-06 11:47:38 | Train | Epoch[014/600] Iteration[022/030] Train loss: 0.3951
2023-02-06 11:47:38 | Train | Epoch[014/600] Iteration[023/030] Train loss: 0.3950
2023-02-06 11:47:38 | Train | Epoch[014/600] Iteration[024/030] Train loss: 0.3946
2023-02-06 11:47:38 | Train | Epoch[014/600] Iteration[025/030] Train loss: 0.3945
2023-02-06 11:47:38 | Train | Epoch[014/600] Iteration[026/030] Train loss: 0.3944
2023-02-06 11:47:38 | Train | Epoch[014/600] Iteration[027/030] Train loss: 0.3941
2023-02-06 11:47:38 | Train | Epoch[014/600] Iteration[028/030] Train loss: 0.3938
2023-02-06 11:47:38 | Train | Epoch[014/600] Iteration[029/030] Train loss: 0.3934
2023-02-06 11:47:38 | Train | Epoch[014/600] Iteration[030/030] Train loss: 0.3930
2023-02-06 11:47:38 | Valid | Epoch[014/600] Iteration[001/008] Valid loss: 0.4260
2023-02-06 11:47:39 | Valid | Epoch[014/600] Iteration[002/008] Valid loss: 0.4267
2023-02-06 11:47:39 | Valid | Epoch[014/600] Iteration[003/008] Valid loss: 0.4282
2023-02-06 11:47:39 | Valid | Epoch[014/600] Iteration[004/008] Valid loss: 0.4276
2023-02-06 11:47:39 | Valid | Epoch[014/600] Iteration[005/008] Valid loss: 0.4291
2023-02-06 11:47:39 | Valid | Epoch[014/600] Iteration[006/008] Valid loss: 0.4288
2023-02-06 11:47:39 | Valid | Epoch[014/600] Iteration[007/008] Valid loss: 0.4288
2023-02-06 11:47:39 | Valid | Epoch[014/600] Iteration[008/008] Valid loss: 0.4302
2023-02-06 11:47:39 | Valid | Epoch[014/600] MIou: 0.5810602831739334
2023-02-06 11:47:39 | Valid | Epoch[014/600] Pixel Accuracy: 0.9302864074707031
2023-02-06 11:47:39 | Valid | Epoch[014/600] Mean Pixel Accuracy: 0.617128533423647
2023-02-06 11:47:39 | Stage | Epoch[014/600] Train loss:0.3930
2023-02-06 11:47:39 | Stage | Epoch[014/600] Valid loss:0.4302
2023-02-06 11:47:39 | Stage | Epoch[014/600] LR:0.01

2023-02-06 11:47:39 | Train | Epoch[015/600] Iteration[001/030] Train loss: 0.3849
2023-02-06 11:47:39 | Train | Epoch[015/600] Iteration[002/030] Train loss: 0.3833
2023-02-06 11:47:39 | Train | Epoch[015/600] Iteration[003/030] Train loss: 0.3833
2023-02-06 11:47:39 | Train | Epoch[015/600] Iteration[004/030] Train loss: 0.3838
2023-02-06 11:47:39 | Train | Epoch[015/600] Iteration[005/030] Train loss: 0.3831
2023-02-06 11:47:39 | Train | Epoch[015/600] Iteration[006/030] Train loss: 0.3843
2023-02-06 11:47:39 | Train | Epoch[015/600] Iteration[007/030] Train loss: 0.3841
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[008/030] Train loss: 0.3839
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[009/030] Train loss: 0.3840
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[010/030] Train loss: 0.3832
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[011/030] Train loss: 0.3828
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[012/030] Train loss: 0.3822
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[013/030] Train loss: 0.3818
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[014/030] Train loss: 0.3817
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[015/030] Train loss: 0.3816
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[016/030] Train loss: 0.3814
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[017/030] Train loss: 0.3810
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[018/030] Train loss: 0.3808
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[019/030] Train loss: 0.3803
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[020/030] Train loss: 0.3800
2023-02-06 11:47:40 | Train | Epoch[015/600] Iteration[021/030] Train loss: 0.3798
2023-02-06 11:47:41 | Train | Epoch[015/600] Iteration[022/030] Train loss: 0.3797
2023-02-06 11:47:41 | Train | Epoch[015/600] Iteration[023/030] Train loss: 0.3796
2023-02-06 11:47:41 | Train | Epoch[015/600] Iteration[024/030] Train loss: 0.3794
2023-02-06 11:47:41 | Train | Epoch[015/600] Iteration[025/030] Train loss: 0.3792
2023-02-06 11:47:41 | Train | Epoch[015/600] Iteration[026/030] Train loss: 0.3792
2023-02-06 11:47:41 | Train | Epoch[015/600] Iteration[027/030] Train loss: 0.3787
2023-02-06 11:47:41 | Train | Epoch[015/600] Iteration[028/030] Train loss: 0.3784
2023-02-06 11:47:41 | Train | Epoch[015/600] Iteration[029/030] Train loss: 0.3785
2023-02-06 11:47:41 | Train | Epoch[015/600] Iteration[030/030] Train loss: 0.3782
2023-02-06 11:47:41 | Valid | Epoch[015/600] Iteration[001/008] Valid loss: 0.4121
2023-02-06 11:47:41 | Valid | Epoch[015/600] Iteration[002/008] Valid loss: 0.4127
2023-02-06 11:47:41 | Valid | Epoch[015/600] Iteration[003/008] Valid loss: 0.4143
2023-02-06 11:47:41 | Valid | Epoch[015/600] Iteration[004/008] Valid loss: 0.4142
2023-02-06 11:47:42 | Valid | Epoch[015/600] Iteration[005/008] Valid loss: 0.4153
2023-02-06 11:47:42 | Valid | Epoch[015/600] Iteration[006/008] Valid loss: 0.4149
2023-02-06 11:47:42 | Valid | Epoch[015/600] Iteration[007/008] Valid loss: 0.4147
2023-02-06 11:47:42 | Valid | Epoch[015/600] Iteration[008/008] Valid loss: 0.4160
2023-02-06 11:47:42 | Valid | Epoch[015/600] MIou: 0.5211181745172161
2023-02-06 11:47:42 | Valid | Epoch[015/600] Pixel Accuracy: 0.9207356770833334
2023-02-06 11:47:42 | Valid | Epoch[015/600] Mean Pixel Accuracy: 0.5611933154063833
2023-02-06 11:47:42 | Stage | Epoch[015/600] Train loss:0.3782
2023-02-06 11:47:42 | Stage | Epoch[015/600] Valid loss:0.4160
2023-02-06 11:47:42 | Stage | Epoch[015/600] LR:0.01

2023-02-06 11:47:42 | Train | Epoch[016/600] Iteration[001/030] Train loss: 0.3668
2023-02-06 11:47:42 | Train | Epoch[016/600] Iteration[002/030] Train loss: 0.3666
2023-02-06 11:47:42 | Train | Epoch[016/600] Iteration[003/030] Train loss: 0.3661
2023-02-06 11:47:42 | Train | Epoch[016/600] Iteration[004/030] Train loss: 0.3671
2023-02-06 11:47:42 | Train | Epoch[016/600] Iteration[005/030] Train loss: 0.3676
2023-02-06 11:47:42 | Train | Epoch[016/600] Iteration[006/030] Train loss: 0.3672
2023-02-06 11:47:42 | Train | Epoch[016/600] Iteration[007/030] Train loss: 0.3684
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[008/030] Train loss: 0.3686
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[009/030] Train loss: 0.3686
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[010/030] Train loss: 0.3682
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[011/030] Train loss: 0.3678
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[012/030] Train loss: 0.3679
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[013/030] Train loss: 0.3677
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[014/030] Train loss: 0.3673
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[015/030] Train loss: 0.3670
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[016/030] Train loss: 0.3668
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[017/030] Train loss: 0.3664
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[018/030] Train loss: 0.3661
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[019/030] Train loss: 0.3664
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[020/030] Train loss: 0.3663
2023-02-06 11:47:43 | Train | Epoch[016/600] Iteration[021/030] Train loss: 0.3664
2023-02-06 11:47:44 | Train | Epoch[016/600] Iteration[022/030] Train loss: 0.3661
2023-02-06 11:47:44 | Train | Epoch[016/600] Iteration[023/030] Train loss: 0.3657
2023-02-06 11:47:44 | Train | Epoch[016/600] Iteration[024/030] Train loss: 0.3653
2023-02-06 11:47:44 | Train | Epoch[016/600] Iteration[025/030] Train loss: 0.3651
2023-02-06 11:47:44 | Train | Epoch[016/600] Iteration[026/030] Train loss: 0.3649
2023-02-06 11:47:44 | Train | Epoch[016/600] Iteration[027/030] Train loss: 0.3648
2023-02-06 11:47:44 | Train | Epoch[016/600] Iteration[028/030] Train loss: 0.3646
2023-02-06 11:47:44 | Train | Epoch[016/600] Iteration[029/030] Train loss: 0.3644
2023-02-06 11:47:44 | Train | Epoch[016/600] Iteration[030/030] Train loss: 0.3642
2023-02-06 11:47:44 | Valid | Epoch[016/600] Iteration[001/008] Valid loss: 0.3682
2023-02-06 11:47:44 | Valid | Epoch[016/600] Iteration[002/008] Valid loss: 0.3666
2023-02-06 11:47:44 | Valid | Epoch[016/600] Iteration[003/008] Valid loss: 0.3656
2023-02-06 11:47:45 | Valid | Epoch[016/600] Iteration[004/008] Valid loss: 0.3650
2023-02-06 11:47:45 | Valid | Epoch[016/600] Iteration[005/008] Valid loss: 0.3653
2023-02-06 11:47:45 | Valid | Epoch[016/600] Iteration[006/008] Valid loss: 0.3648
2023-02-06 11:47:45 | Valid | Epoch[016/600] Iteration[007/008] Valid loss: 0.3662
2023-02-06 11:47:45 | Valid | Epoch[016/600] Iteration[008/008] Valid loss: 0.3658
2023-02-06 11:47:45 | Valid | Epoch[016/600] MIou: 0.9203842690949746
2023-02-06 11:47:45 | Valid | Epoch[016/600] Pixel Accuracy: 0.985388437906901
2023-02-06 11:47:45 | Valid | Epoch[016/600] Mean Pixel Accuracy: 0.9774682039574552
2023-02-06 11:47:45 | Stage | Epoch[016/600] Train loss:0.3642
2023-02-06 11:47:45 | Stage | Epoch[016/600] Valid loss:0.3658
2023-02-06 11:47:45 | Stage | Epoch[016/600] LR:0.01

2023-02-06 11:47:45 | Train | Epoch[017/600] Iteration[001/030] Train loss: 0.3597
2023-02-06 11:47:45 | Train | Epoch[017/600] Iteration[002/030] Train loss: 0.3578
2023-02-06 11:47:45 | Train | Epoch[017/600] Iteration[003/030] Train loss: 0.3571
2023-02-06 11:47:45 | Train | Epoch[017/600] Iteration[004/030] Train loss: 0.3562
2023-02-06 11:47:45 | Train | Epoch[017/600] Iteration[005/030] Train loss: 0.3552
2023-02-06 11:47:45 | Train | Epoch[017/600] Iteration[006/030] Train loss: 0.3549
2023-02-06 11:47:45 | Train | Epoch[017/600] Iteration[007/030] Train loss: 0.3558
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[008/030] Train loss: 0.3557
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[009/030] Train loss: 0.3558
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[010/030] Train loss: 0.3555
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[011/030] Train loss: 0.3550
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[012/030] Train loss: 0.3546
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[013/030] Train loss: 0.3540
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[014/030] Train loss: 0.3540
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[015/030] Train loss: 0.3542
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[016/030] Train loss: 0.3542
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[017/030] Train loss: 0.3538
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[018/030] Train loss: 0.3537
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[019/030] Train loss: 0.3535
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[020/030] Train loss: 0.3532
2023-02-06 11:47:46 | Train | Epoch[017/600] Iteration[021/030] Train loss: 0.3530
2023-02-06 11:47:47 | Train | Epoch[017/600] Iteration[022/030] Train loss: 0.3527
2023-02-06 11:47:47 | Train | Epoch[017/600] Iteration[023/030] Train loss: 0.3526
2023-02-06 11:47:47 | Train | Epoch[017/600] Iteration[024/030] Train loss: 0.3523
2023-02-06 11:47:47 | Train | Epoch[017/600] Iteration[025/030] Train loss: 0.3519
2023-02-06 11:47:47 | Train | Epoch[017/600] Iteration[026/030] Train loss: 0.3516
2023-02-06 11:47:47 | Train | Epoch[017/600] Iteration[027/030] Train loss: 0.3516
2023-02-06 11:47:47 | Train | Epoch[017/600] Iteration[028/030] Train loss: 0.3513
2023-02-06 11:47:47 | Train | Epoch[017/600] Iteration[029/030] Train loss: 0.3511
2023-02-06 11:47:47 | Train | Epoch[017/600] Iteration[030/030] Train loss: 0.3508
2023-02-06 11:47:47 | Valid | Epoch[017/600] Iteration[001/008] Valid loss: 0.3487
2023-02-06 11:47:47 | Valid | Epoch[017/600] Iteration[002/008] Valid loss: 0.3486
2023-02-06 11:47:47 | Valid | Epoch[017/600] Iteration[003/008] Valid loss: 0.3481
2023-02-06 11:47:47 | Valid | Epoch[017/600] Iteration[004/008] Valid loss: 0.3473
2023-02-06 11:47:48 | Valid | Epoch[017/600] Iteration[005/008] Valid loss: 0.3474
2023-02-06 11:47:48 | Valid | Epoch[017/600] Iteration[006/008] Valid loss: 0.3473
2023-02-06 11:47:48 | Valid | Epoch[017/600] Iteration[007/008] Valid loss: 0.3472
2023-02-06 11:47:48 | Valid | Epoch[017/600] Iteration[008/008] Valid loss: 0.3468
2023-02-06 11:47:48 | Valid | Epoch[017/600] MIou: 0.896296879552733
2023-02-06 11:47:48 | Valid | Epoch[017/600] Pixel Accuracy: 0.982794443766276
2023-02-06 11:47:48 | Valid | Epoch[017/600] Mean Pixel Accuracy: 0.9087383290458662
2023-02-06 11:47:48 | Stage | Epoch[017/600] Train loss:0.3508
2023-02-06 11:47:48 | Stage | Epoch[017/600] Valid loss:0.3468
2023-02-06 11:47:48 | Stage | Epoch[017/600] LR:0.01

2023-02-06 11:47:48 | Train | Epoch[018/600] Iteration[001/030] Train loss: 0.3420
2023-02-06 11:47:48 | Train | Epoch[018/600] Iteration[002/030] Train loss: 0.3458
2023-02-06 11:47:48 | Train | Epoch[018/600] Iteration[003/030] Train loss: 0.3464
2023-02-06 11:47:48 | Train | Epoch[018/600] Iteration[004/030] Train loss: 0.3445
2023-02-06 11:47:48 | Train | Epoch[018/600] Iteration[005/030] Train loss: 0.3434
2023-02-06 11:47:48 | Train | Epoch[018/600] Iteration[006/030] Train loss: 0.3425
2023-02-06 11:47:48 | Train | Epoch[018/600] Iteration[007/030] Train loss: 0.3420
2023-02-06 11:47:48 | Train | Epoch[018/600] Iteration[008/030] Train loss: 0.3422
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[009/030] Train loss: 0.3421
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[010/030] Train loss: 0.3422
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[011/030] Train loss: 0.3417
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[012/030] Train loss: 0.3419
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[013/030] Train loss: 0.3417
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[014/030] Train loss: 0.3414
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[015/030] Train loss: 0.3410
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[016/030] Train loss: 0.3406
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[017/030] Train loss: 0.3405
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[018/030] Train loss: 0.3407
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[019/030] Train loss: 0.3403
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[020/030] Train loss: 0.3401
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[021/030] Train loss: 0.3398
2023-02-06 11:47:49 | Train | Epoch[018/600] Iteration[022/030] Train loss: 0.3394
2023-02-06 11:47:50 | Train | Epoch[018/600] Iteration[023/030] Train loss: 0.3392
2023-02-06 11:47:50 | Train | Epoch[018/600] Iteration[024/030] Train loss: 0.3389
2023-02-06 11:47:50 | Train | Epoch[018/600] Iteration[025/030] Train loss: 0.3387
2023-02-06 11:47:50 | Train | Epoch[018/600] Iteration[026/030] Train loss: 0.3385
2023-02-06 11:47:50 | Train | Epoch[018/600] Iteration[027/030] Train loss: 0.3384
2023-02-06 11:47:50 | Train | Epoch[018/600] Iteration[028/030] Train loss: 0.3381
2023-02-06 11:47:50 | Train | Epoch[018/600] Iteration[029/030] Train loss: 0.3379
2023-02-06 11:47:50 | Train | Epoch[018/600] Iteration[030/030] Train loss: 0.3378
2023-02-06 11:47:50 | Valid | Epoch[018/600] Iteration[001/008] Valid loss: 0.3651
2023-02-06 11:47:50 | Valid | Epoch[018/600] Iteration[002/008] Valid loss: 0.3629
2023-02-06 11:47:50 | Valid | Epoch[018/600] Iteration[003/008] Valid loss: 0.3631
2023-02-06 11:47:50 | Valid | Epoch[018/600] Iteration[004/008] Valid loss: 0.3623
2023-02-06 11:47:50 | Valid | Epoch[018/600] Iteration[005/008] Valid loss: 0.3631
2023-02-06 11:47:50 | Valid | Epoch[018/600] Iteration[006/008] Valid loss: 0.3626
2023-02-06 11:47:50 | Valid | Epoch[018/600] Iteration[007/008] Valid loss: 0.3648
2023-02-06 11:47:51 | Valid | Epoch[018/600] Iteration[008/008] Valid loss: 0.3651
2023-02-06 11:47:51 | Valid | Epoch[018/600] MIou: 0.8884173183499904
2023-02-06 11:47:51 | Valid | Epoch[018/600] Pixel Accuracy: 0.9779141743977865
2023-02-06 11:47:51 | Valid | Epoch[018/600] Mean Pixel Accuracy: 0.980993957663761
2023-02-06 11:47:51 | Stage | Epoch[018/600] Train loss:0.3378
2023-02-06 11:47:51 | Stage | Epoch[018/600] Valid loss:0.3651
2023-02-06 11:47:51 | Stage | Epoch[018/600] LR:0.01

2023-02-06 11:47:51 | Train | Epoch[019/600] Iteration[001/030] Train loss: 0.3298
2023-02-06 11:47:51 | Train | Epoch[019/600] Iteration[002/030] Train loss: 0.3309
2023-02-06 11:47:51 | Train | Epoch[019/600] Iteration[003/030] Train loss: 0.3325
2023-02-06 11:47:51 | Train | Epoch[019/600] Iteration[004/030] Train loss: 0.3319
2023-02-06 11:47:51 | Train | Epoch[019/600] Iteration[005/030] Train loss: 0.3310
2023-02-06 11:47:51 | Train | Epoch[019/600] Iteration[006/030] Train loss: 0.3313
2023-02-06 11:47:51 | Train | Epoch[019/600] Iteration[007/030] Train loss: 0.3307
2023-02-06 11:47:51 | Train | Epoch[019/600] Iteration[008/030] Train loss: 0.3300
2023-02-06 11:47:51 | Train | Epoch[019/600] Iteration[009/030] Train loss: 0.3303
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[010/030] Train loss: 0.3300
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[011/030] Train loss: 0.3298
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[012/030] Train loss: 0.3297
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[013/030] Train loss: 0.3295
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[014/030] Train loss: 0.3291
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[015/030] Train loss: 0.3287
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[016/030] Train loss: 0.3289
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[017/030] Train loss: 0.3285
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[018/030] Train loss: 0.3281
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[019/030] Train loss: 0.3279
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[020/030] Train loss: 0.3278
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[021/030] Train loss: 0.3276
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[022/030] Train loss: 0.3273
2023-02-06 11:47:52 | Train | Epoch[019/600] Iteration[023/030] Train loss: 0.3271
2023-02-06 11:47:53 | Train | Epoch[019/600] Iteration[024/030] Train loss: 0.3268
2023-02-06 11:47:53 | Train | Epoch[019/600] Iteration[025/030] Train loss: 0.3267
2023-02-06 11:47:53 | Train | Epoch[019/600] Iteration[026/030] Train loss: 0.3264
2023-02-06 11:47:53 | Train | Epoch[019/600] Iteration[027/030] Train loss: 0.3261
2023-02-06 11:47:53 | Train | Epoch[019/600] Iteration[028/030] Train loss: 0.3257
2023-02-06 11:47:53 | Train | Epoch[019/600] Iteration[029/030] Train loss: 0.3254
2023-02-06 11:47:53 | Train | Epoch[019/600] Iteration[030/030] Train loss: 0.3252
2023-02-06 11:47:53 | Valid | Epoch[019/600] Iteration[001/008] Valid loss: 0.4782
2023-02-06 11:47:53 | Valid | Epoch[019/600] Iteration[002/008] Valid loss: 0.4772
2023-02-06 11:47:53 | Valid | Epoch[019/600] Iteration[003/008] Valid loss: 0.4792
2023-02-06 11:47:53 | Valid | Epoch[019/600] Iteration[004/008] Valid loss: 0.4810
2023-02-06 11:47:53 | Valid | Epoch[019/600] Iteration[005/008] Valid loss: 0.4832
2023-02-06 11:47:53 | Valid | Epoch[019/600] Iteration[006/008] Valid loss: 0.4808
2023-02-06 11:47:53 | Valid | Epoch[019/600] Iteration[007/008] Valid loss: 0.4866
2023-02-06 11:47:53 | Valid | Epoch[019/600] Iteration[008/008] Valid loss: 0.4891
2023-02-06 11:47:54 | Valid | Epoch[019/600] MIou: 0.7970341195007615
2023-02-06 11:47:54 | Valid | Epoch[019/600] Pixel Accuracy: 0.9510930379231771
2023-02-06 11:47:54 | Valid | Epoch[019/600] Mean Pixel Accuracy: 0.9713242943731752
2023-02-06 11:47:54 | Stage | Epoch[019/600] Train loss:0.3252
2023-02-06 11:47:54 | Stage | Epoch[019/600] Valid loss:0.4891
2023-02-06 11:47:54 | Stage | Epoch[019/600] LR:0.01

2023-02-06 11:47:54 | Train | Epoch[020/600] Iteration[001/030] Train loss: 0.3235
2023-02-06 11:47:54 | Train | Epoch[020/600] Iteration[002/030] Train loss: 0.3192
2023-02-06 11:47:54 | Train | Epoch[020/600] Iteration[003/030] Train loss: 0.3186
2023-02-06 11:47:54 | Train | Epoch[020/600] Iteration[004/030] Train loss: 0.3185
2023-02-06 11:47:54 | Train | Epoch[020/600] Iteration[005/030] Train loss: 0.3180
2023-02-06 11:47:54 | Train | Epoch[020/600] Iteration[006/030] Train loss: 0.3182
2023-02-06 11:47:54 | Train | Epoch[020/600] Iteration[007/030] Train loss: 0.3172
2023-02-06 11:47:54 | Train | Epoch[020/600] Iteration[008/030] Train loss: 0.3176
2023-02-06 11:47:54 | Train | Epoch[020/600] Iteration[009/030] Train loss: 0.3175
2023-02-06 11:47:54 | Train | Epoch[020/600] Iteration[010/030] Train loss: 0.3175
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[011/030] Train loss: 0.3171
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[012/030] Train loss: 0.3170
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[013/030] Train loss: 0.3171
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[014/030] Train loss: 0.3167
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[015/030] Train loss: 0.3164
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[016/030] Train loss: 0.3161
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[017/030] Train loss: 0.3160
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[018/030] Train loss: 0.3158
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[019/030] Train loss: 0.3153
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[020/030] Train loss: 0.3155
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[021/030] Train loss: 0.3152
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[022/030] Train loss: 0.3150
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[023/030] Train loss: 0.3146
2023-02-06 11:47:55 | Train | Epoch[020/600] Iteration[024/030] Train loss: 0.3144
2023-02-06 11:47:56 | Train | Epoch[020/600] Iteration[025/030] Train loss: 0.3142
2023-02-06 11:47:56 | Train | Epoch[020/600] Iteration[026/030] Train loss: 0.3143
2023-02-06 11:47:56 | Train | Epoch[020/600] Iteration[027/030] Train loss: 0.3140
2023-02-06 11:47:56 | Train | Epoch[020/600] Iteration[028/030] Train loss: 0.3137
2023-02-06 11:47:56 | Train | Epoch[020/600] Iteration[029/030] Train loss: 0.3139
2023-02-06 11:47:56 | Train | Epoch[020/600] Iteration[030/030] Train loss: 0.3138
2023-02-06 11:47:56 | Valid | Epoch[020/600] Iteration[001/008] Valid loss: 0.6900
2023-02-06 11:47:56 | Valid | Epoch[020/600] Iteration[002/008] Valid loss: 0.6702
2023-02-06 11:47:56 | Valid | Epoch[020/600] Iteration[003/008] Valid loss: 0.6784
2023-02-06 11:47:56 | Valid | Epoch[020/600] Iteration[004/008] Valid loss: 0.6849
2023-02-06 11:47:56 | Valid | Epoch[020/600] Iteration[005/008] Valid loss: 0.6861
2023-02-06 11:47:56 | Valid | Epoch[020/600] Iteration[006/008] Valid loss: 0.6752
2023-02-06 11:47:56 | Valid | Epoch[020/600] Iteration[007/008] Valid loss: 0.6828
2023-02-06 11:47:56 | Valid | Epoch[020/600] Iteration[008/008] Valid loss: 0.6940
2023-02-06 11:47:56 | Valid | Epoch[020/600] MIou: 0.6489911850767665
2023-02-06 11:47:56 | Valid | Epoch[020/600] Pixel Accuracy: 0.8802693684895834
2023-02-06 11:47:56 | Valid | Epoch[020/600] Mean Pixel Accuracy: 0.9334427628955198
2023-02-06 11:47:56 | Stage | Epoch[020/600] Train loss:0.3138
2023-02-06 11:47:56 | Stage | Epoch[020/600] Valid loss:0.6940
2023-02-06 11:47:56 | Stage | Epoch[020/600] LR:0.01

2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[001/030] Train loss: 0.3123
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[002/030] Train loss: 0.3107
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[003/030] Train loss: 0.3101
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[004/030] Train loss: 0.3084
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[005/030] Train loss: 0.3080
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[006/030] Train loss: 0.3072
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[007/030] Train loss: 0.3075
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[008/030] Train loss: 0.3070
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[009/030] Train loss: 0.3066
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[010/030] Train loss: 0.3062
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[011/030] Train loss: 0.3058
2023-02-06 11:47:57 | Train | Epoch[021/600] Iteration[012/030] Train loss: 0.3059
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[013/030] Train loss: 0.3058
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[014/030] Train loss: 0.3058
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[015/030] Train loss: 0.3054
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[016/030] Train loss: 0.3050
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[017/030] Train loss: 0.3047
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[018/030] Train loss: 0.3046
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[019/030] Train loss: 0.3043
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[020/030] Train loss: 0.3039
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[021/030] Train loss: 0.3037
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[022/030] Train loss: 0.3034
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[023/030] Train loss: 0.3032
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[024/030] Train loss: 0.3030
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[025/030] Train loss: 0.3029
2023-02-06 11:47:58 | Train | Epoch[021/600] Iteration[026/030] Train loss: 0.3027
2023-02-06 11:47:59 | Train | Epoch[021/600] Iteration[027/030] Train loss: 0.3025
2023-02-06 11:47:59 | Train | Epoch[021/600] Iteration[028/030] Train loss: 0.3024
2023-02-06 11:47:59 | Train | Epoch[021/600] Iteration[029/030] Train loss: 0.3023
2023-02-06 11:47:59 | Train | Epoch[021/600] Iteration[030/030] Train loss: 0.3022
2023-02-06 11:47:59 | Valid | Epoch[021/600] Iteration[001/008] Valid loss: 0.3498
2023-02-06 11:47:59 | Valid | Epoch[021/600] Iteration[002/008] Valid loss: 0.3482
2023-02-06 11:47:59 | Valid | Epoch[021/600] Iteration[003/008] Valid loss: 0.3497
2023-02-06 11:47:59 | Valid | Epoch[021/600] Iteration[004/008] Valid loss: 0.3497
2023-02-06 11:47:59 | Valid | Epoch[021/600] Iteration[005/008] Valid loss: 0.3513
2023-02-06 11:47:59 | Valid | Epoch[021/600] Iteration[006/008] Valid loss: 0.3505
2023-02-06 11:47:59 | Valid | Epoch[021/600] Iteration[007/008] Valid loss: 0.3507
2023-02-06 11:47:59 | Valid | Epoch[021/600] Iteration[008/008] Valid loss: 0.3519
2023-02-06 11:47:59 | Valid | Epoch[021/600] MIou: 0.5616050896995992
2023-02-06 11:47:59 | Valid | Epoch[021/600] Pixel Accuracy: 0.9274470011393229
2023-02-06 11:47:59 | Valid | Epoch[021/600] Mean Pixel Accuracy: 0.5985627300107713
2023-02-06 11:47:59 | Stage | Epoch[021/600] Train loss:0.3022
2023-02-06 11:47:59 | Stage | Epoch[021/600] Valid loss:0.3519
2023-02-06 11:47:59 | Stage | Epoch[021/600] LR:0.01

2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[001/030] Train loss: 0.2932
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[002/030] Train loss: 0.2973
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[003/030] Train loss: 0.2977
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[004/030] Train loss: 0.2961
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[005/030] Train loss: 0.2965
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[006/030] Train loss: 0.2973
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[007/030] Train loss: 0.2966
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[008/030] Train loss: 0.2964
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[009/030] Train loss: 0.2963
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[010/030] Train loss: 0.2957
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[011/030] Train loss: 0.2956
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[012/030] Train loss: 0.2955
2023-02-06 11:48:00 | Train | Epoch[022/600] Iteration[013/030] Train loss: 0.2950
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[014/030] Train loss: 0.2945
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[015/030] Train loss: 0.2942
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[016/030] Train loss: 0.2939
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[017/030] Train loss: 0.2935
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[018/030] Train loss: 0.2933
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[019/030] Train loss: 0.2931
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[020/030] Train loss: 0.2927
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[021/030] Train loss: 0.2925
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[022/030] Train loss: 0.2922
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[023/030] Train loss: 0.2920
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[024/030] Train loss: 0.2918
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[025/030] Train loss: 0.2920
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[026/030] Train loss: 0.2917
2023-02-06 11:48:01 | Train | Epoch[022/600] Iteration[027/030] Train loss: 0.2918
2023-02-06 11:48:02 | Train | Epoch[022/600] Iteration[028/030] Train loss: 0.2917
2023-02-06 11:48:02 | Train | Epoch[022/600] Iteration[029/030] Train loss: 0.2914
2023-02-06 11:48:02 | Train | Epoch[022/600] Iteration[030/030] Train loss: 0.2912
2023-02-06 11:48:02 | Valid | Epoch[022/600] Iteration[001/008] Valid loss: 0.2994
2023-02-06 11:48:02 | Valid | Epoch[022/600] Iteration[002/008] Valid loss: 0.2992
2023-02-06 11:48:02 | Valid | Epoch[022/600] Iteration[003/008] Valid loss: 0.2985
2023-02-06 11:48:02 | Valid | Epoch[022/600] Iteration[004/008] Valid loss: 0.2981
2023-02-06 11:48:02 | Valid | Epoch[022/600] Iteration[005/008] Valid loss: 0.2984
2023-02-06 11:48:02 | Valid | Epoch[022/600] Iteration[006/008] Valid loss: 0.2981
2023-02-06 11:48:02 | Valid | Epoch[022/600] Iteration[007/008] Valid loss: 0.2985
2023-02-06 11:48:02 | Valid | Epoch[022/600] Iteration[008/008] Valid loss: 0.2981
2023-02-06 11:48:02 | Valid | Epoch[022/600] MIou: 0.9179959631493759
2023-02-06 11:48:02 | Valid | Epoch[022/600] Pixel Accuracy: 0.9861704508463541
2023-02-06 11:48:02 | Valid | Epoch[022/600] Mean Pixel Accuracy: 0.9359177697395433
2023-02-06 11:48:02 | Stage | Epoch[022/600] Train loss:0.2912
2023-02-06 11:48:02 | Stage | Epoch[022/600] Valid loss:0.2981
2023-02-06 11:48:02 | Stage | Epoch[022/600] LR:0.01

2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[001/030] Train loss: 0.2823
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[002/030] Train loss: 0.2833
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[003/030] Train loss: 0.2837
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[004/030] Train loss: 0.2841
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[005/030] Train loss: 0.2841
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[006/030] Train loss: 0.2834
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[007/030] Train loss: 0.2845
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[008/030] Train loss: 0.2838
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[009/030] Train loss: 0.2837
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[010/030] Train loss: 0.2836
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[011/030] Train loss: 0.2840
2023-02-06 11:48:03 | Train | Epoch[023/600] Iteration[012/030] Train loss: 0.2836
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[013/030] Train loss: 0.2835
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[014/030] Train loss: 0.2834
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[015/030] Train loss: 0.2831
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[016/030] Train loss: 0.2831
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[017/030] Train loss: 0.2828
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[018/030] Train loss: 0.2827
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[019/030] Train loss: 0.2829
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[020/030] Train loss: 0.2831
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[021/030] Train loss: 0.2828
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[022/030] Train loss: 0.2828
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[023/030] Train loss: 0.2825
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[024/030] Train loss: 0.2822
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[025/030] Train loss: 0.2820
2023-02-06 11:48:04 | Train | Epoch[023/600] Iteration[026/030] Train loss: 0.2818
2023-02-06 11:48:05 | Train | Epoch[023/600] Iteration[027/030] Train loss: 0.2817
2023-02-06 11:48:05 | Train | Epoch[023/600] Iteration[028/030] Train loss: 0.2815
2023-02-06 11:48:05 | Train | Epoch[023/600] Iteration[029/030] Train loss: 0.2813
2023-02-06 11:48:05 | Train | Epoch[023/600] Iteration[030/030] Train loss: 0.2810
2023-02-06 11:48:05 | Valid | Epoch[023/600] Iteration[001/008] Valid loss: 0.3900
2023-02-06 11:48:05 | Valid | Epoch[023/600] Iteration[002/008] Valid loss: 0.3901
2023-02-06 11:48:05 | Valid | Epoch[023/600] Iteration[003/008] Valid loss: 0.3907
2023-02-06 11:48:05 | Valid | Epoch[023/600] Iteration[004/008] Valid loss: 0.3930
2023-02-06 11:48:05 | Valid | Epoch[023/600] Iteration[005/008] Valid loss: 0.3946
2023-02-06 11:48:05 | Valid | Epoch[023/600] Iteration[006/008] Valid loss: 0.3927
2023-02-06 11:48:05 | Valid | Epoch[023/600] Iteration[007/008] Valid loss: 0.3976
2023-02-06 11:48:05 | Valid | Epoch[023/600] Iteration[008/008] Valid loss: 0.3988
2023-02-06 11:48:05 | Valid | Epoch[023/600] MIou: 0.8329404906839519
2023-02-06 11:48:05 | Valid | Epoch[023/600] Pixel Accuracy: 0.9626795450846354
2023-02-06 11:48:05 | Valid | Epoch[023/600] Mean Pixel Accuracy: 0.9779336707791506
2023-02-06 11:48:05 | Stage | Epoch[023/600] Train loss:0.2810
2023-02-06 11:48:05 | Stage | Epoch[023/600] Valid loss:0.3988
2023-02-06 11:48:05 | Stage | Epoch[023/600] LR:0.01

2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[001/030] Train loss: 0.2832
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[002/030] Train loss: 0.2818
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[003/030] Train loss: 0.2793
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[004/030] Train loss: 0.2787
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[005/030] Train loss: 0.2775
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[006/030] Train loss: 0.2763
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[007/030] Train loss: 0.2758
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[008/030] Train loss: 0.2756
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[009/030] Train loss: 0.2754
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[010/030] Train loss: 0.2755
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[011/030] Train loss: 0.2750
2023-02-06 11:48:06 | Train | Epoch[024/600] Iteration[012/030] Train loss: 0.2748
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[013/030] Train loss: 0.2749
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[014/030] Train loss: 0.2747
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[015/030] Train loss: 0.2745
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[016/030] Train loss: 0.2742
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[017/030] Train loss: 0.2737
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[018/030] Train loss: 0.2736
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[019/030] Train loss: 0.2733
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[020/030] Train loss: 0.2731
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[021/030] Train loss: 0.2731
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[022/030] Train loss: 0.2729
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[023/030] Train loss: 0.2727
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[024/030] Train loss: 0.2725
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[025/030] Train loss: 0.2722
2023-02-06 11:48:07 | Train | Epoch[024/600] Iteration[026/030] Train loss: 0.2720
2023-02-06 11:48:08 | Train | Epoch[024/600] Iteration[027/030] Train loss: 0.2717
2023-02-06 11:48:08 | Train | Epoch[024/600] Iteration[028/030] Train loss: 0.2714
2023-02-06 11:48:08 | Train | Epoch[024/600] Iteration[029/030] Train loss: 0.2710
2023-02-06 11:48:08 | Train | Epoch[024/600] Iteration[030/030] Train loss: 0.2708
2023-02-06 11:48:08 | Valid | Epoch[024/600] Iteration[001/008] Valid loss: 0.3275
2023-02-06 11:48:08 | Valid | Epoch[024/600] Iteration[002/008] Valid loss: 0.3286
2023-02-06 11:48:08 | Valid | Epoch[024/600] Iteration[003/008] Valid loss: 0.3322
2023-02-06 11:48:08 | Valid | Epoch[024/600] Iteration[004/008] Valid loss: 0.3322
2023-02-06 11:48:08 | Valid | Epoch[024/600] Iteration[005/008] Valid loss: 0.3355
2023-02-06 11:48:08 | Valid | Epoch[024/600] Iteration[006/008] Valid loss: 0.3350
2023-02-06 11:48:08 | Valid | Epoch[024/600] Iteration[007/008] Valid loss: 0.3352
2023-02-06 11:48:08 | Valid | Epoch[024/600] Iteration[008/008] Valid loss: 0.3379
2023-02-06 11:48:08 | Valid | Epoch[024/600] MIou: 0.48491187755616444
2023-02-06 11:48:08 | Valid | Epoch[024/600] Pixel Accuracy: 0.9146830240885416
2023-02-06 11:48:08 | Valid | Epoch[024/600] Mean Pixel Accuracy: 0.5277809818562202
2023-02-06 11:48:08 | Stage | Epoch[024/600] Train loss:0.2708
2023-02-06 11:48:08 | Stage | Epoch[024/600] Valid loss:0.3379
2023-02-06 11:48:08 | Stage | Epoch[024/600] LR:0.01

2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[001/030] Train loss: 0.2658
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[002/030] Train loss: 0.2659
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[003/030] Train loss: 0.2665
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[004/030] Train loss: 0.2654
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[005/030] Train loss: 0.2661
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[006/030] Train loss: 0.2655
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[007/030] Train loss: 0.2657
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[008/030] Train loss: 0.2650
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[009/030] Train loss: 0.2646
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[010/030] Train loss: 0.2641
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[011/030] Train loss: 0.2641
2023-02-06 11:48:09 | Train | Epoch[025/600] Iteration[012/030] Train loss: 0.2639
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[013/030] Train loss: 0.2633
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[014/030] Train loss: 0.2635
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[015/030] Train loss: 0.2636
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[016/030] Train loss: 0.2635
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[017/030] Train loss: 0.2632
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[018/030] Train loss: 0.2629
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[019/030] Train loss: 0.2629
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[020/030] Train loss: 0.2627
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[021/030] Train loss: 0.2628
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[022/030] Train loss: 0.2626
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[023/030] Train loss: 0.2625
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[024/030] Train loss: 0.2624
2023-02-06 11:48:10 | Train | Epoch[025/600] Iteration[025/030] Train loss: 0.2622
2023-02-06 11:48:11 | Train | Epoch[025/600] Iteration[026/030] Train loss: 0.2620
2023-02-06 11:48:11 | Train | Epoch[025/600] Iteration[027/030] Train loss: 0.2624
2023-02-06 11:48:11 | Train | Epoch[025/600] Iteration[028/030] Train loss: 0.2622
2023-02-06 11:48:11 | Train | Epoch[025/600] Iteration[029/030] Train loss: 0.2620
2023-02-06 11:48:11 | Train | Epoch[025/600] Iteration[030/030] Train loss: 0.2617
2023-02-06 11:48:11 | Valid | Epoch[025/600] Iteration[001/008] Valid loss: 0.4868
2023-02-06 11:48:11 | Valid | Epoch[025/600] Iteration[002/008] Valid loss: 0.4627
2023-02-06 11:48:11 | Valid | Epoch[025/600] Iteration[003/008] Valid loss: 0.4609
2023-02-06 11:48:11 | Valid | Epoch[025/600] Iteration[004/008] Valid loss: 0.4606
2023-02-06 11:48:11 | Valid | Epoch[025/600] Iteration[005/008] Valid loss: 0.4637
2023-02-06 11:48:11 | Valid | Epoch[025/600] Iteration[006/008] Valid loss: 0.4553
2023-02-06 11:48:11 | Valid | Epoch[025/600] Iteration[007/008] Valid loss: 0.4668
2023-02-06 11:48:11 | Valid | Epoch[025/600] Iteration[008/008] Valid loss: 0.4722
2023-02-06 11:48:11 | Valid | Epoch[025/600] MIou: 0.7962617897367716
2023-02-06 11:48:11 | Valid | Epoch[025/600] Pixel Accuracy: 0.9509290059407552
2023-02-06 11:48:11 | Valid | Epoch[025/600] Mean Pixel Accuracy: 0.9700294458125462
2023-02-06 11:48:11 | Stage | Epoch[025/600] Train loss:0.2617
2023-02-06 11:48:11 | Stage | Epoch[025/600] Valid loss:0.4722
2023-02-06 11:48:11 | Stage | Epoch[025/600] LR:0.01

2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[001/030] Train loss: 0.2607
2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[002/030] Train loss: 0.2598
2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[003/030] Train loss: 0.2610
2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[004/030] Train loss: 0.2599
2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[005/030] Train loss: 0.2588
2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[006/030] Train loss: 0.2584
2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[007/030] Train loss: 0.2580
2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[008/030] Train loss: 0.2579
2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[009/030] Train loss: 0.2573
2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[010/030] Train loss: 0.2569
2023-02-06 11:48:12 | Train | Epoch[026/600] Iteration[011/030] Train loss: 0.2565
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[012/030] Train loss: 0.2569
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[013/030] Train loss: 0.2567
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[014/030] Train loss: 0.2563
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[015/030] Train loss: 0.2561
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[016/030] Train loss: 0.2559
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[017/030] Train loss: 0.2557
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[018/030] Train loss: 0.2554
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[019/030] Train loss: 0.2552
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[020/030] Train loss: 0.2550
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[021/030] Train loss: 0.2548
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[022/030] Train loss: 0.2547
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[023/030] Train loss: 0.2544
2023-02-06 11:48:13 | Train | Epoch[026/600] Iteration[024/030] Train loss: 0.2542
2023-02-06 11:48:14 | Train | Epoch[026/600] Iteration[025/030] Train loss: 0.2540
2023-02-06 11:48:14 | Train | Epoch[026/600] Iteration[026/030] Train loss: 0.2539
2023-02-06 11:48:14 | Train | Epoch[026/600] Iteration[027/030] Train loss: 0.2537
2023-02-06 11:48:14 | Train | Epoch[026/600] Iteration[028/030] Train loss: 0.2535
2023-02-06 11:48:14 | Train | Epoch[026/600] Iteration[029/030] Train loss: 0.2534
2023-02-06 11:48:14 | Train | Epoch[026/600] Iteration[030/030] Train loss: 0.2532
2023-02-06 11:48:14 | Valid | Epoch[026/600] Iteration[001/008] Valid loss: 0.5238
2023-02-06 11:48:14 | Valid | Epoch[026/600] Iteration[002/008] Valid loss: 0.4970
2023-02-06 11:48:14 | Valid | Epoch[026/600] Iteration[003/008] Valid loss: 0.4956
2023-02-06 11:48:14 | Valid | Epoch[026/600] Iteration[004/008] Valid loss: 0.5042
2023-02-06 11:48:14 | Valid | Epoch[026/600] Iteration[005/008] Valid loss: 0.5088
2023-02-06 11:48:14 | Valid | Epoch[026/600] Iteration[006/008] Valid loss: 0.5065
2023-02-06 11:48:14 | Valid | Epoch[026/600] Iteration[007/008] Valid loss: 0.5121
2023-02-06 11:48:14 | Valid | Epoch[026/600] Iteration[008/008] Valid loss: 0.5108
2023-02-06 11:48:14 | Valid | Epoch[026/600] MIou: 0.7843929419047853
2023-02-06 11:48:14 | Valid | Epoch[026/600] Pixel Accuracy: 0.9468256632486979
2023-02-06 11:48:14 | Valid | Epoch[026/600] Mean Pixel Accuracy: 0.96646793653417
2023-02-06 11:48:14 | Stage | Epoch[026/600] Train loss:0.2532
2023-02-06 11:48:14 | Stage | Epoch[026/600] Valid loss:0.5108
2023-02-06 11:48:14 | Stage | Epoch[026/600] LR:0.01

2023-02-06 11:48:15 | Train | Epoch[027/600] Iteration[001/030] Train loss: 0.2479
2023-02-06 11:48:15 | Train | Epoch[027/600] Iteration[002/030] Train loss: 0.2476
2023-02-06 11:48:15 | Train | Epoch[027/600] Iteration[003/030] Train loss: 0.2477
2023-02-06 11:48:15 | Train | Epoch[027/600] Iteration[004/030] Train loss: 0.2476
2023-02-06 11:48:15 | Train | Epoch[027/600] Iteration[005/030] Train loss: 0.2477
2023-02-06 11:48:15 | Train | Epoch[027/600] Iteration[006/030] Train loss: 0.2471
2023-02-06 11:48:15 | Train | Epoch[027/600] Iteration[007/030] Train loss: 0.2467
2023-02-06 11:48:15 | Train | Epoch[027/600] Iteration[008/030] Train loss: 0.2464
2023-02-06 11:48:15 | Train | Epoch[027/600] Iteration[009/030] Train loss: 0.2463
2023-02-06 11:48:15 | Train | Epoch[027/600] Iteration[010/030] Train loss: 0.2465
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[011/030] Train loss: 0.2464
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[012/030] Train loss: 0.2462
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[013/030] Train loss: 0.2462
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[014/030] Train loss: 0.2460
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[015/030] Train loss: 0.2461
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[016/030] Train loss: 0.2459
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[017/030] Train loss: 0.2458
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[018/030] Train loss: 0.2457
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[019/030] Train loss: 0.2457
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[020/030] Train loss: 0.2455
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[021/030] Train loss: 0.2452
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[022/030] Train loss: 0.2451
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[023/030] Train loss: 0.2450
2023-02-06 11:48:16 | Train | Epoch[027/600] Iteration[024/030] Train loss: 0.2451
2023-02-06 11:48:17 | Train | Epoch[027/600] Iteration[025/030] Train loss: 0.2449
2023-02-06 11:48:17 | Train | Epoch[027/600] Iteration[026/030] Train loss: 0.2447
2023-02-06 11:48:17 | Train | Epoch[027/600] Iteration[027/030] Train loss: 0.2445
2023-02-06 11:48:17 | Train | Epoch[027/600] Iteration[028/030] Train loss: 0.2444
2023-02-06 11:48:17 | Train | Epoch[027/600] Iteration[029/030] Train loss: 0.2442
2023-02-06 11:48:17 | Train | Epoch[027/600] Iteration[030/030] Train loss: 0.2440
2023-02-06 11:48:17 | Valid | Epoch[027/600] Iteration[001/008] Valid loss: 0.2941
2023-02-06 11:48:17 | Valid | Epoch[027/600] Iteration[002/008] Valid loss: 0.2905
2023-02-06 11:48:17 | Valid | Epoch[027/600] Iteration[003/008] Valid loss: 0.2884
2023-02-06 11:48:17 | Valid | Epoch[027/600] Iteration[004/008] Valid loss: 0.2878
2023-02-06 11:48:17 | Valid | Epoch[027/600] Iteration[005/008] Valid loss: 0.2871
2023-02-06 11:48:17 | Valid | Epoch[027/600] Iteration[006/008] Valid loss: 0.2855
2023-02-06 11:48:17 | Valid | Epoch[027/600] Iteration[007/008] Valid loss: 0.2867
2023-02-06 11:48:17 | Valid | Epoch[027/600] Iteration[008/008] Valid loss: 0.2867
2023-02-06 11:48:18 | Valid | Epoch[027/600] MIou: 0.9036213318387198
2023-02-06 11:48:18 | Valid | Epoch[027/600] Pixel Accuracy: 0.9817352294921875
2023-02-06 11:48:18 | Valid | Epoch[027/600] Mean Pixel Accuracy: 0.9757582469682258
2023-02-06 11:48:18 | Stage | Epoch[027/600] Train loss:0.2440
2023-02-06 11:48:18 | Stage | Epoch[027/600] Valid loss:0.2867
2023-02-06 11:48:18 | Stage | Epoch[027/600] LR:0.01

2023-02-06 11:48:18 | Train | Epoch[028/600] Iteration[001/030] Train loss: 0.2393
2023-02-06 11:48:18 | Train | Epoch[028/600] Iteration[002/030] Train loss: 0.2398
2023-02-06 11:48:18 | Train | Epoch[028/600] Iteration[003/030] Train loss: 0.2401
2023-02-06 11:48:18 | Train | Epoch[028/600] Iteration[004/030] Train loss: 0.2400
2023-02-06 11:48:18 | Train | Epoch[028/600] Iteration[005/030] Train loss: 0.2400
2023-02-06 11:48:18 | Train | Epoch[028/600] Iteration[006/030] Train loss: 0.2391
2023-02-06 11:48:18 | Train | Epoch[028/600] Iteration[007/030] Train loss: 0.2391
2023-02-06 11:48:18 | Train | Epoch[028/600] Iteration[008/030] Train loss: 0.2388
2023-02-06 11:48:18 | Train | Epoch[028/600] Iteration[009/030] Train loss: 0.2384
2023-02-06 11:48:18 | Train | Epoch[028/600] Iteration[010/030] Train loss: 0.2379
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[011/030] Train loss: 0.2379
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[012/030] Train loss: 0.2378
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[013/030] Train loss: 0.2376
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[014/030] Train loss: 0.2377
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[015/030] Train loss: 0.2377
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[016/030] Train loss: 0.2376
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[017/030] Train loss: 0.2375
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[018/030] Train loss: 0.2374
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[019/030] Train loss: 0.2371
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[020/030] Train loss: 0.2370
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[021/030] Train loss: 0.2368
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[022/030] Train loss: 0.2368
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[023/030] Train loss: 0.2365
2023-02-06 11:48:19 | Train | Epoch[028/600] Iteration[024/030] Train loss: 0.2364
2023-02-06 11:48:20 | Train | Epoch[028/600] Iteration[025/030] Train loss: 0.2365
2023-02-06 11:48:20 | Train | Epoch[028/600] Iteration[026/030] Train loss: 0.2362
2023-02-06 11:48:20 | Train | Epoch[028/600] Iteration[027/030] Train loss: 0.2361
2023-02-06 11:48:20 | Train | Epoch[028/600] Iteration[028/030] Train loss: 0.2361
2023-02-06 11:48:20 | Train | Epoch[028/600] Iteration[029/030] Train loss: 0.2359
2023-02-06 11:48:20 | Train | Epoch[028/600] Iteration[030/030] Train loss: 0.2357
2023-02-06 11:48:20 | Valid | Epoch[028/600] Iteration[001/008] Valid loss: 0.4449
2023-02-06 11:48:20 | Valid | Epoch[028/600] Iteration[002/008] Valid loss: 0.4214
2023-02-06 11:48:20 | Valid | Epoch[028/600] Iteration[003/008] Valid loss: 0.4166
2023-02-06 11:48:20 | Valid | Epoch[028/600] Iteration[004/008] Valid loss: 0.4158
2023-02-06 11:48:20 | Valid | Epoch[028/600] Iteration[005/008] Valid loss: 0.4139
2023-02-06 11:48:20 | Valid | Epoch[028/600] Iteration[006/008] Valid loss: 0.4108
2023-02-06 11:48:20 | Valid | Epoch[028/600] Iteration[007/008] Valid loss: 0.4179
2023-02-06 11:48:20 | Valid | Epoch[028/600] Iteration[008/008] Valid loss: 0.4214
2023-02-06 11:48:20 | Valid | Epoch[028/600] MIou: 0.8307308136790132
2023-02-06 11:48:20 | Valid | Epoch[028/600] Pixel Accuracy: 0.9620577494303385
2023-02-06 11:48:20 | Valid | Epoch[028/600] Mean Pixel Accuracy: 0.9769324963313495
2023-02-06 11:48:20 | Stage | Epoch[028/600] Train loss:0.2357
2023-02-06 11:48:20 | Stage | Epoch[028/600] Valid loss:0.4214
2023-02-06 11:48:20 | Stage | Epoch[028/600] LR:0.01

2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[001/030] Train loss: 0.2345
2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[002/030] Train loss: 0.2322
2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[003/030] Train loss: 0.2309
2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[004/030] Train loss: 0.2302
2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[005/030] Train loss: 0.2302
2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[006/030] Train loss: 0.2298
2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[007/030] Train loss: 0.2305
2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[008/030] Train loss: 0.2305
2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[009/030] Train loss: 0.2303
2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[010/030] Train loss: 0.2301
2023-02-06 11:48:21 | Train | Epoch[029/600] Iteration[011/030] Train loss: 0.2299
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[012/030] Train loss: 0.2300
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[013/030] Train loss: 0.2301
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[014/030] Train loss: 0.2300
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[015/030] Train loss: 0.2298
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[016/030] Train loss: 0.2299
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[017/030] Train loss: 0.2297
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[018/030] Train loss: 0.2293
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[019/030] Train loss: 0.2290
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[020/030] Train loss: 0.2287
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[021/030] Train loss: 0.2287
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[022/030] Train loss: 0.2286
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[023/030] Train loss: 0.2284
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[024/030] Train loss: 0.2282
2023-02-06 11:48:22 | Train | Epoch[029/600] Iteration[025/030] Train loss: 0.2280
2023-02-06 11:48:23 | Train | Epoch[029/600] Iteration[026/030] Train loss: 0.2280
2023-02-06 11:48:23 | Train | Epoch[029/600] Iteration[027/030] Train loss: 0.2279
2023-02-06 11:48:23 | Train | Epoch[029/600] Iteration[028/030] Train loss: 0.2277
2023-02-06 11:48:23 | Train | Epoch[029/600] Iteration[029/030] Train loss: 0.2275
2023-02-06 11:48:23 | Train | Epoch[029/600] Iteration[030/030] Train loss: 0.2278
2023-02-06 11:48:23 | Valid | Epoch[029/600] Iteration[001/008] Valid loss: 0.2390
2023-02-06 11:48:23 | Valid | Epoch[029/600] Iteration[002/008] Valid loss: 0.2375
2023-02-06 11:48:23 | Valid | Epoch[029/600] Iteration[003/008] Valid loss: 0.2366
2023-02-06 11:48:23 | Valid | Epoch[029/600] Iteration[004/008] Valid loss: 0.2358
2023-02-06 11:48:23 | Valid | Epoch[029/600] Iteration[005/008] Valid loss: 0.2356
2023-02-06 11:48:23 | Valid | Epoch[029/600] Iteration[006/008] Valid loss: 0.2356
2023-02-06 11:48:23 | Valid | Epoch[029/600] Iteration[007/008] Valid loss: 0.2358
2023-02-06 11:48:23 | Valid | Epoch[029/600] Iteration[008/008] Valid loss: 0.2355
2023-02-06 11:48:23 | Valid | Epoch[029/600] MIou: 0.9151509323841294
2023-02-06 11:48:23 | Valid | Epoch[029/600] Pixel Accuracy: 0.9857864379882812
2023-02-06 11:48:23 | Valid | Epoch[029/600] Mean Pixel Accuracy: 0.9303299800527505
2023-02-06 11:48:23 | Stage | Epoch[029/600] Train loss:0.2278
2023-02-06 11:48:23 | Stage | Epoch[029/600] Valid loss:0.2355
2023-02-06 11:48:23 | Stage | Epoch[029/600] LR:0.01

2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[001/030] Train loss: 0.2281
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[002/030] Train loss: 0.2262
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[003/030] Train loss: 0.2253
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[004/030] Train loss: 0.2254
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[005/030] Train loss: 0.2250
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[006/030] Train loss: 0.2244
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[007/030] Train loss: 0.2247
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[008/030] Train loss: 0.2248
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[009/030] Train loss: 0.2246
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[010/030] Train loss: 0.2246
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[011/030] Train loss: 0.2245
2023-02-06 11:48:24 | Train | Epoch[030/600] Iteration[012/030] Train loss: 0.2242
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[013/030] Train loss: 0.2241
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[014/030] Train loss: 0.2242
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[015/030] Train loss: 0.2239
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[016/030] Train loss: 0.2237
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[017/030] Train loss: 0.2234
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[018/030] Train loss: 0.2230
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[019/030] Train loss: 0.2229
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[020/030] Train loss: 0.2226
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[021/030] Train loss: 0.2224
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[022/030] Train loss: 0.2221
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[023/030] Train loss: 0.2219
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[024/030] Train loss: 0.2217
2023-02-06 11:48:25 | Train | Epoch[030/600] Iteration[025/030] Train loss: 0.2214
2023-02-06 11:48:26 | Train | Epoch[030/600] Iteration[026/030] Train loss: 0.2213
2023-02-06 11:48:26 | Train | Epoch[030/600] Iteration[027/030] Train loss: 0.2211
2023-02-06 11:48:26 | Train | Epoch[030/600] Iteration[028/030] Train loss: 0.2208
2023-02-06 11:48:26 | Train | Epoch[030/600] Iteration[029/030] Train loss: 0.2207
2023-02-06 11:48:26 | Train | Epoch[030/600] Iteration[030/030] Train loss: 0.2205
2023-02-06 11:48:26 | Valid | Epoch[030/600] Iteration[001/008] Valid loss: 0.2357
2023-02-06 11:48:26 | Valid | Epoch[030/600] Iteration[002/008] Valid loss: 0.2338
2023-02-06 11:48:26 | Valid | Epoch[030/600] Iteration[003/008] Valid loss: 0.2337
2023-02-06 11:48:26 | Valid | Epoch[030/600] Iteration[004/008] Valid loss: 0.2330
2023-02-06 11:48:26 | Valid | Epoch[030/600] Iteration[005/008] Valid loss: 0.2330
2023-02-06 11:48:26 | Valid | Epoch[030/600] Iteration[006/008] Valid loss: 0.2330
2023-02-06 11:48:26 | Valid | Epoch[030/600] Iteration[007/008] Valid loss: 0.2333
2023-02-06 11:48:26 | Valid | Epoch[030/600] Iteration[008/008] Valid loss: 0.2333
2023-02-06 11:48:26 | Valid | Epoch[030/600] MIou: 0.9194221995575371
2023-02-06 11:48:26 | Valid | Epoch[030/600] Pixel Accuracy: 0.9863103230794271
2023-02-06 11:48:26 | Valid | Epoch[030/600] Mean Pixel Accuracy: 0.9405154056723596
2023-02-06 11:48:26 | Stage | Epoch[030/600] Train loss:0.2205
2023-02-06 11:48:26 | Stage | Epoch[030/600] Valid loss:0.2333
2023-02-06 11:48:26 | Stage | Epoch[030/600] LR:0.01

2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[001/030] Train loss: 0.2121
2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[002/030] Train loss: 0.2140
2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[003/030] Train loss: 0.2160
2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[004/030] Train loss: 0.2175
2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[005/030] Train loss: 0.2174
2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[006/030] Train loss: 0.2167
2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[007/030] Train loss: 0.2162
2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[008/030] Train loss: 0.2157
2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[009/030] Train loss: 0.2152
2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[010/030] Train loss: 0.2149
2023-02-06 11:48:27 | Train | Epoch[031/600] Iteration[011/030] Train loss: 0.2146
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[012/030] Train loss: 0.2146
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[013/030] Train loss: 0.2144
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[014/030] Train loss: 0.2144
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[015/030] Train loss: 0.2147
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[016/030] Train loss: 0.2148
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[017/030] Train loss: 0.2147
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[018/030] Train loss: 0.2145
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[019/030] Train loss: 0.2145
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[020/030] Train loss: 0.2144
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[021/030] Train loss: 0.2143
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[022/030] Train loss: 0.2141
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[023/030] Train loss: 0.2140
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[024/030] Train loss: 0.2140
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[025/030] Train loss: 0.2139
2023-02-06 11:48:28 | Train | Epoch[031/600] Iteration[026/030] Train loss: 0.2138
2023-02-06 11:48:29 | Train | Epoch[031/600] Iteration[027/030] Train loss: 0.2136
2023-02-06 11:48:29 | Train | Epoch[031/600] Iteration[028/030] Train loss: 0.2135
2023-02-06 11:48:29 | Train | Epoch[031/600] Iteration[029/030] Train loss: 0.2134
2023-02-06 11:48:29 | Train | Epoch[031/600] Iteration[030/030] Train loss: 0.2135
2023-02-06 11:48:29 | Valid | Epoch[031/600] Iteration[001/008] Valid loss: 0.3351
2023-02-06 11:48:29 | Valid | Epoch[031/600] Iteration[002/008] Valid loss: 0.3204
2023-02-06 11:48:29 | Valid | Epoch[031/600] Iteration[003/008] Valid loss: 0.3224
2023-02-06 11:48:29 | Valid | Epoch[031/600] Iteration[004/008] Valid loss: 0.3229
2023-02-06 11:48:29 | Valid | Epoch[031/600] Iteration[005/008] Valid loss: 0.3247
2023-02-06 11:48:29 | Valid | Epoch[031/600] Iteration[006/008] Valid loss: 0.3230
2023-02-06 11:48:29 | Valid | Epoch[031/600] Iteration[007/008] Valid loss: 0.3271
2023-02-06 11:48:29 | Valid | Epoch[031/600] Iteration[008/008] Valid loss: 0.3277
2023-02-06 11:48:29 | Valid | Epoch[031/600] MIou: 0.8576424765240542
2023-02-06 11:48:29 | Valid | Epoch[031/600] Pixel Accuracy: 0.9698270161946615
2023-02-06 11:48:29 | Valid | Epoch[031/600] Mean Pixel Accuracy: 0.9806702170892201
2023-02-06 11:48:29 | Stage | Epoch[031/600] Train loss:0.2135
2023-02-06 11:48:29 | Stage | Epoch[031/600] Valid loss:0.3277
2023-02-06 11:48:29 | Stage | Epoch[031/600] LR:0.01

2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[001/030] Train loss: 0.2104
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[002/030] Train loss: 0.2099
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[003/030] Train loss: 0.2095
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[004/030] Train loss: 0.2095
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[005/030] Train loss: 0.2092
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[006/030] Train loss: 0.2095
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[007/030] Train loss: 0.2095
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[008/030] Train loss: 0.2101
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[009/030] Train loss: 0.2098
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[010/030] Train loss: 0.2096
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[011/030] Train loss: 0.2095
2023-02-06 11:48:30 | Train | Epoch[032/600] Iteration[012/030] Train loss: 0.2095
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[013/030] Train loss: 0.2093
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[014/030] Train loss: 0.2093
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[015/030] Train loss: 0.2091
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[016/030] Train loss: 0.2089
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[017/030] Train loss: 0.2087
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[018/030] Train loss: 0.2085
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[019/030] Train loss: 0.2083
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[020/030] Train loss: 0.2082
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[021/030] Train loss: 0.2080
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[022/030] Train loss: 0.2080
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[023/030] Train loss: 0.2082
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[024/030] Train loss: 0.2080
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[025/030] Train loss: 0.2079
2023-02-06 11:48:31 | Train | Epoch[032/600] Iteration[026/030] Train loss: 0.2079
2023-02-06 11:48:32 | Train | Epoch[032/600] Iteration[027/030] Train loss: 0.2078
2023-02-06 11:48:32 | Train | Epoch[032/600] Iteration[028/030] Train loss: 0.2077
2023-02-06 11:48:32 | Train | Epoch[032/600] Iteration[029/030] Train loss: 0.2075
2023-02-06 11:48:32 | Train | Epoch[032/600] Iteration[030/030] Train loss: 0.2073
2023-02-06 11:48:32 | Valid | Epoch[032/600] Iteration[001/008] Valid loss: 0.2199
2023-02-06 11:48:32 | Valid | Epoch[032/600] Iteration[002/008] Valid loss: 0.2186
2023-02-06 11:48:32 | Valid | Epoch[032/600] Iteration[003/008] Valid loss: 0.2178
2023-02-06 11:48:32 | Valid | Epoch[032/600] Iteration[004/008] Valid loss: 0.2168
2023-02-06 11:48:32 | Valid | Epoch[032/600] Iteration[005/008] Valid loss: 0.2170
2023-02-06 11:48:32 | Valid | Epoch[032/600] Iteration[006/008] Valid loss: 0.2166
2023-02-06 11:48:32 | Valid | Epoch[032/600] Iteration[007/008] Valid loss: 0.2167
2023-02-06 11:48:32 | Valid | Epoch[032/600] Iteration[008/008] Valid loss: 0.2168
2023-02-06 11:48:32 | Valid | Epoch[032/600] MIou: 0.9015053880088696
2023-02-06 11:48:32 | Valid | Epoch[032/600] Pixel Accuracy: 0.9835408528645834
2023-02-06 11:48:32 | Valid | Epoch[032/600] Mean Pixel Accuracy: 0.9165415771029589
2023-02-06 11:48:32 | Stage | Epoch[032/600] Train loss:0.2073
2023-02-06 11:48:32 | Stage | Epoch[032/600] Valid loss:0.2168
2023-02-06 11:48:32 | Stage | Epoch[032/600] LR:0.01

2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[001/030] Train loss: 0.2035
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[002/030] Train loss: 0.2022
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[003/030] Train loss: 0.2019
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[004/030] Train loss: 0.2022
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[005/030] Train loss: 0.2031
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[006/030] Train loss: 0.2029
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[007/030] Train loss: 0.2032
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[008/030] Train loss: 0.2030
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[009/030] Train loss: 0.2028
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[010/030] Train loss: 0.2029
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[011/030] Train loss: 0.2026
2023-02-06 11:48:33 | Train | Epoch[033/600] Iteration[012/030] Train loss: 0.2030
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[013/030] Train loss: 0.2026
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[014/030] Train loss: 0.2025
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[015/030] Train loss: 0.2023
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[016/030] Train loss: 0.2024
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[017/030] Train loss: 0.2022
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[018/030] Train loss: 0.2021
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[019/030] Train loss: 0.2020
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[020/030] Train loss: 0.2018
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[021/030] Train loss: 0.2017
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[022/030] Train loss: 0.2014
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[023/030] Train loss: 0.2013
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[024/030] Train loss: 0.2012
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[025/030] Train loss: 0.2011
2023-02-06 11:48:34 | Train | Epoch[033/600] Iteration[026/030] Train loss: 0.2009
2023-02-06 11:48:35 | Train | Epoch[033/600] Iteration[027/030] Train loss: 0.2008
2023-02-06 11:48:35 | Train | Epoch[033/600] Iteration[028/030] Train loss: 0.2006
2023-02-06 11:48:35 | Train | Epoch[033/600] Iteration[029/030] Train loss: 0.2004
2023-02-06 11:48:35 | Train | Epoch[033/600] Iteration[030/030] Train loss: 0.2004
2023-02-06 11:48:35 | Valid | Epoch[033/600] Iteration[001/008] Valid loss: 0.3038
2023-02-06 11:48:35 | Valid | Epoch[033/600] Iteration[002/008] Valid loss: 0.2932
2023-02-06 11:48:35 | Valid | Epoch[033/600] Iteration[003/008] Valid loss: 0.2902
2023-02-06 11:48:35 | Valid | Epoch[033/600] Iteration[004/008] Valid loss: 0.2895
2023-02-06 11:48:35 | Valid | Epoch[033/600] Iteration[005/008] Valid loss: 0.2891
2023-02-06 11:48:35 | Valid | Epoch[033/600] Iteration[006/008] Valid loss: 0.2859
2023-02-06 11:48:35 | Valid | Epoch[033/600] Iteration[007/008] Valid loss: 0.2890
2023-02-06 11:48:35 | Valid | Epoch[033/600] Iteration[008/008] Valid loss: 0.2913
2023-02-06 11:48:35 | Valid | Epoch[033/600] MIou: 0.8626750620548784
2023-02-06 11:48:35 | Valid | Epoch[033/600] Pixel Accuracy: 0.9713223775227865
2023-02-06 11:48:35 | Valid | Epoch[033/600] Mean Pixel Accuracy: 0.9789559428459438
2023-02-06 11:48:35 | Stage | Epoch[033/600] Train loss:0.2004
2023-02-06 11:48:35 | Stage | Epoch[033/600] Valid loss:0.2913
2023-02-06 11:48:35 | Stage | Epoch[033/600] LR:0.01

2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[001/030] Train loss: 0.1959
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[002/030] Train loss: 0.1964
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[003/030] Train loss: 0.1954
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[004/030] Train loss: 0.1955
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[005/030] Train loss: 0.1956
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[006/030] Train loss: 0.1954
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[007/030] Train loss: 0.1954
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[008/030] Train loss: 0.1950
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[009/030] Train loss: 0.1949
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[010/030] Train loss: 0.1948
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[011/030] Train loss: 0.1947
2023-02-06 11:48:36 | Train | Epoch[034/600] Iteration[012/030] Train loss: 0.1947
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[013/030] Train loss: 0.1950
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[014/030] Train loss: 0.1949
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[015/030] Train loss: 0.1949
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[016/030] Train loss: 0.1949
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[017/030] Train loss: 0.1952
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[018/030] Train loss: 0.1952
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[019/030] Train loss: 0.1951
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[020/030] Train loss: 0.1950
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[021/030] Train loss: 0.1948
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[022/030] Train loss: 0.1946
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[023/030] Train loss: 0.1944
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[024/030] Train loss: 0.1943
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[025/030] Train loss: 0.1942
2023-02-06 11:48:37 | Train | Epoch[034/600] Iteration[026/030] Train loss: 0.1940
2023-02-06 11:48:38 | Train | Epoch[034/600] Iteration[027/030] Train loss: 0.1939
2023-02-06 11:48:38 | Train | Epoch[034/600] Iteration[028/030] Train loss: 0.1937
2023-02-06 11:48:38 | Train | Epoch[034/600] Iteration[029/030] Train loss: 0.1940
2023-02-06 11:48:38 | Train | Epoch[034/600] Iteration[030/030] Train loss: 0.1941
2023-02-06 11:48:38 | Valid | Epoch[034/600] Iteration[001/008] Valid loss: 1.1005
2023-02-06 11:48:38 | Valid | Epoch[034/600] Iteration[002/008] Valid loss: 1.0826
2023-02-06 11:48:38 | Valid | Epoch[034/600] Iteration[003/008] Valid loss: 1.1212
2023-02-06 11:48:38 | Valid | Epoch[034/600] Iteration[004/008] Valid loss: 1.1378
2023-02-06 11:48:38 | Valid | Epoch[034/600] Iteration[005/008] Valid loss: 1.1617
2023-02-06 11:48:38 | Valid | Epoch[034/600] Iteration[006/008] Valid loss: 1.1313
2023-02-06 11:48:38 | Valid | Epoch[034/600] Iteration[007/008] Valid loss: 1.1688
2023-02-06 11:48:38 | Valid | Epoch[034/600] Iteration[008/008] Valid loss: 1.2076
2023-02-06 11:48:38 | Valid | Epoch[034/600] MIou: 0.774174186542862
2023-02-06 11:48:38 | Valid | Epoch[034/600] Pixel Accuracy: 0.9426689147949219
2023-02-06 11:48:38 | Valid | Epoch[034/600] Mean Pixel Accuracy: 0.9678353218938989
2023-02-06 11:48:38 | Stage | Epoch[034/600] Train loss:0.1941
2023-02-06 11:48:38 | Stage | Epoch[034/600] Valid loss:1.2076
2023-02-06 11:48:38 | Stage | Epoch[034/600] LR:0.01

2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[001/030] Train loss: 0.1916
2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[002/030] Train loss: 0.1911
2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[003/030] Train loss: 0.1921
2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[004/030] Train loss: 0.1930
2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[005/030] Train loss: 0.1932
2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[006/030] Train loss: 0.1928
2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[007/030] Train loss: 0.1921
2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[008/030] Train loss: 0.1914
2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[009/030] Train loss: 0.1912
2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[010/030] Train loss: 0.1911
2023-02-06 11:48:39 | Train | Epoch[035/600] Iteration[011/030] Train loss: 0.1914
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[012/030] Train loss: 0.1911
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[013/030] Train loss: 0.1907
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[014/030] Train loss: 0.1903
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[015/030] Train loss: 0.1903
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[016/030] Train loss: 0.1899
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[017/030] Train loss: 0.1898
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[018/030] Train loss: 0.1895
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[019/030] Train loss: 0.1894
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[020/030] Train loss: 0.1893
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[021/030] Train loss: 0.1892
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[022/030] Train loss: 0.1893
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[023/030] Train loss: 0.1890
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[024/030] Train loss: 0.1889
2023-02-06 11:48:40 | Train | Epoch[035/600] Iteration[025/030] Train loss: 0.1888
2023-02-06 11:48:41 | Train | Epoch[035/600] Iteration[026/030] Train loss: 0.1886
2023-02-06 11:48:41 | Train | Epoch[035/600] Iteration[027/030] Train loss: 0.1884
2023-02-06 11:48:41 | Train | Epoch[035/600] Iteration[028/030] Train loss: 0.1883
2023-02-06 11:48:41 | Train | Epoch[035/600] Iteration[029/030] Train loss: 0.1881
2023-02-06 11:48:41 | Train | Epoch[035/600] Iteration[030/030] Train loss: 0.1881
2023-02-06 11:48:41 | Valid | Epoch[035/600] Iteration[001/008] Valid loss: 0.2179
2023-02-06 11:48:41 | Valid | Epoch[035/600] Iteration[002/008] Valid loss: 0.2194
2023-02-06 11:48:41 | Valid | Epoch[035/600] Iteration[003/008] Valid loss: 0.2218
2023-02-06 11:48:41 | Valid | Epoch[035/600] Iteration[004/008] Valid loss: 0.2203
2023-02-06 11:48:41 | Valid | Epoch[035/600] Iteration[005/008] Valid loss: 0.2222
2023-02-06 11:48:41 | Valid | Epoch[035/600] Iteration[006/008] Valid loss: 0.2218
2023-02-06 11:48:41 | Valid | Epoch[035/600] Iteration[007/008] Valid loss: 0.2213
2023-02-06 11:48:41 | Valid | Epoch[035/600] Iteration[008/008] Valid loss: 0.2233
2023-02-06 11:48:41 | Valid | Epoch[035/600] MIou: 0.6563364212080169
2023-02-06 11:48:41 | Valid | Epoch[035/600] Pixel Accuracy: 0.9432195027669271
2023-02-06 11:48:41 | Valid | Epoch[035/600] Mean Pixel Accuracy: 0.6857333473772874
2023-02-06 11:48:41 | Stage | Epoch[035/600] Train loss:0.1881
2023-02-06 11:48:41 | Stage | Epoch[035/600] Valid loss:0.2233
2023-02-06 11:48:41 | Stage | Epoch[035/600] LR:0.01

2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[001/030] Train loss: 0.1830
2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[002/030] Train loss: 0.1859
2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[003/030] Train loss: 0.1845
2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[004/030] Train loss: 0.1840
2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[005/030] Train loss: 0.1848
2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[006/030] Train loss: 0.1850
2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[007/030] Train loss: 0.1852
2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[008/030] Train loss: 0.1851
2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[009/030] Train loss: 0.1848
2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[010/030] Train loss: 0.1846
2023-02-06 11:48:42 | Train | Epoch[036/600] Iteration[011/030] Train loss: 0.1843
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[012/030] Train loss: 0.1841
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[013/030] Train loss: 0.1843
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[014/030] Train loss: 0.1840
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[015/030] Train loss: 0.1842
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[016/030] Train loss: 0.1839
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[017/030] Train loss: 0.1839
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[018/030] Train loss: 0.1837
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[019/030] Train loss: 0.1836
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[020/030] Train loss: 0.1834
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[021/030] Train loss: 0.1831
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[022/030] Train loss: 0.1832
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[023/030] Train loss: 0.1831
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[024/030] Train loss: 0.1831
2023-02-06 11:48:43 | Train | Epoch[036/600] Iteration[025/030] Train loss: 0.1830
2023-02-06 11:48:44 | Train | Epoch[036/600] Iteration[026/030] Train loss: 0.1830
2023-02-06 11:48:44 | Train | Epoch[036/600] Iteration[027/030] Train loss: 0.1831
2023-02-06 11:48:44 | Train | Epoch[036/600] Iteration[028/030] Train loss: 0.1830
2023-02-06 11:48:44 | Train | Epoch[036/600] Iteration[029/030] Train loss: 0.1830
2023-02-06 11:48:44 | Train | Epoch[036/600] Iteration[030/030] Train loss: 0.1829
2023-02-06 11:48:44 | Valid | Epoch[036/600] Iteration[001/008] Valid loss: 0.2817
2023-02-06 11:48:44 | Valid | Epoch[036/600] Iteration[002/008] Valid loss: 0.2626
2023-02-06 11:48:44 | Valid | Epoch[036/600] Iteration[003/008] Valid loss: 0.2562
2023-02-06 11:48:44 | Valid | Epoch[036/600] Iteration[004/008] Valid loss: 0.2530
2023-02-06 11:48:44 | Valid | Epoch[036/600] Iteration[005/008] Valid loss: 0.2525
2023-02-06 11:48:44 | Valid | Epoch[036/600] Iteration[006/008] Valid loss: 0.2494
2023-02-06 11:48:44 | Valid | Epoch[036/600] Iteration[007/008] Valid loss: 0.2530
2023-02-06 11:48:44 | Valid | Epoch[036/600] Iteration[008/008] Valid loss: 0.2547
2023-02-06 11:48:44 | Valid | Epoch[036/600] MIou: 0.8903900169295109
2023-02-06 11:48:44 | Valid | Epoch[036/600] Pixel Accuracy: 0.9784940083821615
2023-02-06 11:48:44 | Valid | Epoch[036/600] Mean Pixel Accuracy: 0.9787511086600145
2023-02-06 11:48:44 | Stage | Epoch[036/600] Train loss:0.1829
2023-02-06 11:48:44 | Stage | Epoch[036/600] Valid loss:0.2547
2023-02-06 11:48:44 | Stage | Epoch[036/600] LR:0.01

2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[001/030] Train loss: 0.1800
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[002/030] Train loss: 0.1819
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[003/030] Train loss: 0.1803
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[004/030] Train loss: 0.1802
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[005/030] Train loss: 0.1790
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[006/030] Train loss: 0.1791
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[007/030] Train loss: 0.1791
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[008/030] Train loss: 0.1792
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[009/030] Train loss: 0.1793
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[010/030] Train loss: 0.1792
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[011/030] Train loss: 0.1791
2023-02-06 11:48:45 | Train | Epoch[037/600] Iteration[012/030] Train loss: 0.1789
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[013/030] Train loss: 0.1791
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[014/030] Train loss: 0.1790
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[015/030] Train loss: 0.1791
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[016/030] Train loss: 0.1789
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[017/030] Train loss: 0.1786
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[018/030] Train loss: 0.1787
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[019/030] Train loss: 0.1786
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[020/030] Train loss: 0.1785
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[021/030] Train loss: 0.1784
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[022/030] Train loss: 0.1783
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[023/030] Train loss: 0.1780
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[024/030] Train loss: 0.1780
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[025/030] Train loss: 0.1778
2023-02-06 11:48:46 | Train | Epoch[037/600] Iteration[026/030] Train loss: 0.1777
2023-02-06 11:48:47 | Train | Epoch[037/600] Iteration[027/030] Train loss: 0.1777
2023-02-06 11:48:47 | Train | Epoch[037/600] Iteration[028/030] Train loss: 0.1776
2023-02-06 11:48:47 | Train | Epoch[037/600] Iteration[029/030] Train loss: 0.1775
2023-02-06 11:48:47 | Train | Epoch[037/600] Iteration[030/030] Train loss: 0.1774
2023-02-06 11:48:47 | Valid | Epoch[037/600] Iteration[001/008] Valid loss: 0.5608
2023-02-06 11:48:47 | Valid | Epoch[037/600] Iteration[002/008] Valid loss: 0.5388
2023-02-06 11:48:47 | Valid | Epoch[037/600] Iteration[003/008] Valid loss: 0.5548
2023-02-06 11:48:47 | Valid | Epoch[037/600] Iteration[004/008] Valid loss: 0.5603
2023-02-06 11:48:47 | Valid | Epoch[037/600] Iteration[005/008] Valid loss: 0.5695
2023-02-06 11:48:47 | Valid | Epoch[037/600] Iteration[006/008] Valid loss: 0.5533
2023-02-06 11:48:47 | Valid | Epoch[037/600] Iteration[007/008] Valid loss: 0.5621
2023-02-06 11:48:47 | Valid | Epoch[037/600] Iteration[008/008] Valid loss: 0.5690
2023-02-06 11:48:47 | Valid | Epoch[037/600] MIou: 0.8408057686837374
2023-02-06 11:48:47 | Valid | Epoch[037/600] Pixel Accuracy: 0.9655329386393229
2023-02-06 11:48:47 | Valid | Epoch[037/600] Mean Pixel Accuracy: 0.9713671926211003
2023-02-06 11:48:47 | Stage | Epoch[037/600] Train loss:0.1774
2023-02-06 11:48:47 | Stage | Epoch[037/600] Valid loss:0.5690
2023-02-06 11:48:47 | Stage | Epoch[037/600] LR:0.01

2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[001/030] Train loss: 0.1714
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[002/030] Train loss: 0.1754
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[003/030] Train loss: 0.1762
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[004/030] Train loss: 0.1757
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[005/030] Train loss: 0.1755
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[006/030] Train loss: 0.1756
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[007/030] Train loss: 0.1753
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[008/030] Train loss: 0.1755
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[009/030] Train loss: 0.1754
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[010/030] Train loss: 0.1749
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[011/030] Train loss: 0.1748
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[012/030] Train loss: 0.1744
2023-02-06 11:48:48 | Train | Epoch[038/600] Iteration[013/030] Train loss: 0.1740
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[014/030] Train loss: 0.1739
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[015/030] Train loss: 0.1736
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[016/030] Train loss: 0.1735
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[017/030] Train loss: 0.1735
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[018/030] Train loss: 0.1734
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[019/030] Train loss: 0.1732
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[020/030] Train loss: 0.1731
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[021/030] Train loss: 0.1732
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[022/030] Train loss: 0.1730
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[023/030] Train loss: 0.1728
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[024/030] Train loss: 0.1728
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[025/030] Train loss: 0.1727
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[026/030] Train loss: 0.1726
2023-02-06 11:48:49 | Train | Epoch[038/600] Iteration[027/030] Train loss: 0.1725
2023-02-06 11:48:50 | Train | Epoch[038/600] Iteration[028/030] Train loss: 0.1724
2023-02-06 11:48:50 | Train | Epoch[038/600] Iteration[029/030] Train loss: 0.1724
2023-02-06 11:48:50 | Train | Epoch[038/600] Iteration[030/030] Train loss: 0.1723
2023-02-06 11:48:50 | Valid | Epoch[038/600] Iteration[001/008] Valid loss: 0.2552
2023-02-06 11:48:50 | Valid | Epoch[038/600] Iteration[002/008] Valid loss: 0.2419
2023-02-06 11:48:50 | Valid | Epoch[038/600] Iteration[003/008] Valid loss: 0.2376
2023-02-06 11:48:50 | Valid | Epoch[038/600] Iteration[004/008] Valid loss: 0.2364
2023-02-06 11:48:50 | Valid | Epoch[038/600] Iteration[005/008] Valid loss: 0.2370
2023-02-06 11:48:50 | Valid | Epoch[038/600] Iteration[006/008] Valid loss: 0.2341
2023-02-06 11:48:50 | Valid | Epoch[038/600] Iteration[007/008] Valid loss: 0.2376
2023-02-06 11:48:50 | Valid | Epoch[038/600] Iteration[008/008] Valid loss: 0.2387
2023-02-06 11:48:50 | Valid | Epoch[038/600] MIou: 0.8876056797487346
2023-02-06 11:48:50 | Valid | Epoch[038/600] Pixel Accuracy: 0.9776954650878906
2023-02-06 11:48:50 | Valid | Epoch[038/600] Mean Pixel Accuracy: 0.9814126857778425
2023-02-06 11:48:50 | Stage | Epoch[038/600] Train loss:0.1723
2023-02-06 11:48:50 | Stage | Epoch[038/600] Valid loss:0.2387
2023-02-06 11:48:50 | Stage | Epoch[038/600] LR:0.01

2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[001/030] Train loss: 0.1687
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[002/030] Train loss: 0.1680
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[003/030] Train loss: 0.1691
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[004/030] Train loss: 0.1691
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[005/030] Train loss: 0.1688
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[006/030] Train loss: 0.1688
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[007/030] Train loss: 0.1694
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[008/030] Train loss: 0.1689
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[009/030] Train loss: 0.1693
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[010/030] Train loss: 0.1691
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[011/030] Train loss: 0.1689
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[012/030] Train loss: 0.1686
2023-02-06 11:48:51 | Train | Epoch[039/600] Iteration[013/030] Train loss: 0.1684
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[014/030] Train loss: 0.1684
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[015/030] Train loss: 0.1680
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[016/030] Train loss: 0.1678
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[017/030] Train loss: 0.1680
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[018/030] Train loss: 0.1679
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[019/030] Train loss: 0.1678
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[020/030] Train loss: 0.1681
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[021/030] Train loss: 0.1680
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[022/030] Train loss: 0.1678
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[023/030] Train loss: 0.1678
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[024/030] Train loss: 0.1677
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[025/030] Train loss: 0.1676
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[026/030] Train loss: 0.1675
2023-02-06 11:48:52 | Train | Epoch[039/600] Iteration[027/030] Train loss: 0.1675
2023-02-06 11:48:53 | Train | Epoch[039/600] Iteration[028/030] Train loss: 0.1673
2023-02-06 11:48:53 | Train | Epoch[039/600] Iteration[029/030] Train loss: 0.1671
2023-02-06 11:48:53 | Train | Epoch[039/600] Iteration[030/030] Train loss: 0.1670
2023-02-06 11:48:53 | Valid | Epoch[039/600] Iteration[001/008] Valid loss: 0.7018
2023-02-06 11:48:53 | Valid | Epoch[039/600] Iteration[002/008] Valid loss: 0.6529
2023-02-06 11:48:53 | Valid | Epoch[039/600] Iteration[003/008] Valid loss: 0.6649
2023-02-06 11:48:53 | Valid | Epoch[039/600] Iteration[004/008] Valid loss: 0.6687
2023-02-06 11:48:53 | Valid | Epoch[039/600] Iteration[005/008] Valid loss: 0.6848
2023-02-06 11:48:53 | Valid | Epoch[039/600] Iteration[006/008] Valid loss: 0.6676
2023-02-06 11:48:53 | Valid | Epoch[039/600] Iteration[007/008] Valid loss: 0.6974
2023-02-06 11:48:53 | Valid | Epoch[039/600] Iteration[008/008] Valid loss: 0.7258
2023-02-06 11:48:53 | Valid | Epoch[039/600] MIou: 0.792414296931584
2023-02-06 11:48:53 | Valid | Epoch[039/600] Pixel Accuracy: 0.9495035807291666
2023-02-06 11:48:53 | Valid | Epoch[039/600] Mean Pixel Accuracy: 0.9701272968635213
2023-02-06 11:48:53 | Stage | Epoch[039/600] Train loss:0.1670
2023-02-06 11:48:53 | Stage | Epoch[039/600] Valid loss:0.7258
2023-02-06 11:48:53 | Stage | Epoch[039/600] LR:0.01

2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[001/030] Train loss: 0.1634
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[002/030] Train loss: 0.1636
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[003/030] Train loss: 0.1658
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[004/030] Train loss: 0.1650
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[005/030] Train loss: 0.1656
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[006/030] Train loss: 0.1651
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[007/030] Train loss: 0.1650
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[008/030] Train loss: 0.1652
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[009/030] Train loss: 0.1650
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[010/030] Train loss: 0.1648
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[011/030] Train loss: 0.1646
2023-02-06 11:48:54 | Train | Epoch[040/600] Iteration[012/030] Train loss: 0.1642
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[013/030] Train loss: 0.1642
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[014/030] Train loss: 0.1643
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[015/030] Train loss: 0.1642
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[016/030] Train loss: 0.1639
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[017/030] Train loss: 0.1637
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[018/030] Train loss: 0.1636
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[019/030] Train loss: 0.1635
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[020/030] Train loss: 0.1633
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[021/030] Train loss: 0.1631
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[022/030] Train loss: 0.1630
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[023/030] Train loss: 0.1630
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[024/030] Train loss: 0.1628
2023-02-06 11:48:55 | Train | Epoch[040/600] Iteration[025/030] Train loss: 0.1627
2023-02-06 11:48:56 | Train | Epoch[040/600] Iteration[026/030] Train loss: 0.1626
2023-02-06 11:48:56 | Train | Epoch[040/600] Iteration[027/030] Train loss: 0.1624
2023-02-06 11:48:56 | Train | Epoch[040/600] Iteration[028/030] Train loss: 0.1622
2023-02-06 11:48:56 | Train | Epoch[040/600] Iteration[029/030] Train loss: 0.1621
2023-02-06 11:48:56 | Train | Epoch[040/600] Iteration[030/030] Train loss: 0.1619
2023-02-06 11:48:56 | Valid | Epoch[040/600] Iteration[001/008] Valid loss: 0.2435
2023-02-06 11:48:56 | Valid | Epoch[040/600] Iteration[002/008] Valid loss: 0.2322
2023-02-06 11:48:56 | Valid | Epoch[040/600] Iteration[003/008] Valid loss: 0.2316
2023-02-06 11:48:56 | Valid | Epoch[040/600] Iteration[004/008] Valid loss: 0.2318
2023-02-06 11:48:56 | Valid | Epoch[040/600] Iteration[005/008] Valid loss: 0.2338
2023-02-06 11:48:56 | Valid | Epoch[040/600] Iteration[006/008] Valid loss: 0.2345
2023-02-06 11:48:56 | Valid | Epoch[040/600] Iteration[007/008] Valid loss: 0.2394
2023-02-06 11:48:56 | Valid | Epoch[040/600] Iteration[008/008] Valid loss: 0.2388
2023-02-06 11:48:56 | Valid | Epoch[040/600] MIou: 0.8906021197148091
2023-02-06 11:48:56 | Valid | Epoch[040/600] Pixel Accuracy: 0.9785232543945312
2023-02-06 11:48:56 | Valid | Epoch[040/600] Mean Pixel Accuracy: 0.9792744212366916
2023-02-06 11:48:56 | Stage | Epoch[040/600] Train loss:0.1619
2023-02-06 11:48:56 | Stage | Epoch[040/600] Valid loss:0.2388
2023-02-06 11:48:56 | Stage | Epoch[040/600] LR:0.01

2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[001/030] Train loss: 0.1588
2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[002/030] Train loss: 0.1579
2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[003/030] Train loss: 0.1573
2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[004/030] Train loss: 0.1583
2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[005/030] Train loss: 0.1579
2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[006/030] Train loss: 0.1579
2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[007/030] Train loss: 0.1576
2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[008/030] Train loss: 0.1576
2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[009/030] Train loss: 0.1579
2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[010/030] Train loss: 0.1578
2023-02-06 11:48:57 | Train | Epoch[041/600] Iteration[011/030] Train loss: 0.1578
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[012/030] Train loss: 0.1578
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[013/030] Train loss: 0.1576
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[014/030] Train loss: 0.1575
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[015/030] Train loss: 0.1577
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[016/030] Train loss: 0.1578
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[017/030] Train loss: 0.1580
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[018/030] Train loss: 0.1580
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[019/030] Train loss: 0.1579
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[020/030] Train loss: 0.1578
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[021/030] Train loss: 0.1577
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[022/030] Train loss: 0.1577
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[023/030] Train loss: 0.1577
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[024/030] Train loss: 0.1577
2023-02-06 11:48:58 | Train | Epoch[041/600] Iteration[025/030] Train loss: 0.1576
2023-02-06 11:48:59 | Train | Epoch[041/600] Iteration[026/030] Train loss: 0.1577
2023-02-06 11:48:59 | Train | Epoch[041/600] Iteration[027/030] Train loss: 0.1576
2023-02-06 11:48:59 | Train | Epoch[041/600] Iteration[028/030] Train loss: 0.1576
2023-02-06 11:48:59 | Train | Epoch[041/600] Iteration[029/030] Train loss: 0.1576
2023-02-06 11:48:59 | Train | Epoch[041/600] Iteration[030/030] Train loss: 0.1575
2023-02-06 11:48:59 | Valid | Epoch[041/600] Iteration[001/008] Valid loss: 1.6359
2023-02-06 11:48:59 | Valid | Epoch[041/600] Iteration[002/008] Valid loss: 1.5795
2023-02-06 11:48:59 | Valid | Epoch[041/600] Iteration[003/008] Valid loss: 1.6106
2023-02-06 11:48:59 | Valid | Epoch[041/600] Iteration[004/008] Valid loss: 1.6592
2023-02-06 11:48:59 | Valid | Epoch[041/600] Iteration[005/008] Valid loss: 1.6769
2023-02-06 11:48:59 | Valid | Epoch[041/600] Iteration[006/008] Valid loss: 1.6274
2023-02-06 11:48:59 | Valid | Epoch[041/600] Iteration[007/008] Valid loss: 1.6747
2023-02-06 11:48:59 | Valid | Epoch[041/600] Iteration[008/008] Valid loss: 1.7590
2023-02-06 11:48:59 | Valid | Epoch[041/600] MIou: 0.6639357420728715
2023-02-06 11:48:59 | Valid | Epoch[041/600] Pixel Accuracy: 0.8895924886067709
2023-02-06 11:48:59 | Valid | Epoch[041/600] Mean Pixel Accuracy: 0.9379457811251982
2023-02-06 11:48:59 | Stage | Epoch[041/600] Train loss:0.1575
2023-02-06 11:48:59 | Stage | Epoch[041/600] Valid loss:1.7590
2023-02-06 11:48:59 | Stage | Epoch[041/600] LR:0.01

2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[001/030] Train loss: 0.1525
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[002/030] Train loss: 0.1556
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[003/030] Train loss: 0.1559
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[004/030] Train loss: 0.1559
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[005/030] Train loss: 0.1558
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[006/030] Train loss: 0.1554
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[007/030] Train loss: 0.1552
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[008/030] Train loss: 0.1548
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[009/030] Train loss: 0.1553
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[010/030] Train loss: 0.1550
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[011/030] Train loss: 0.1551
2023-02-06 11:49:00 | Train | Epoch[042/600] Iteration[012/030] Train loss: 0.1551
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[013/030] Train loss: 0.1552
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[014/030] Train loss: 0.1552
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[015/030] Train loss: 0.1553
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[016/030] Train loss: 0.1554
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[017/030] Train loss: 0.1551
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[018/030] Train loss: 0.1550
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[019/030] Train loss: 0.1548
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[020/030] Train loss: 0.1548
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[021/030] Train loss: 0.1545
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[022/030] Train loss: 0.1544
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[023/030] Train loss: 0.1543
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[024/030] Train loss: 0.1542
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[025/030] Train loss: 0.1541
2023-02-06 11:49:01 | Train | Epoch[042/600] Iteration[026/030] Train loss: 0.1539
2023-02-06 11:49:02 | Train | Epoch[042/600] Iteration[027/030] Train loss: 0.1539
2023-02-06 11:49:02 | Train | Epoch[042/600] Iteration[028/030] Train loss: 0.1538
2023-02-06 11:49:02 | Train | Epoch[042/600] Iteration[029/030] Train loss: 0.1536
2023-02-06 11:49:02 | Train | Epoch[042/600] Iteration[030/030] Train loss: 0.1535
2023-02-06 11:49:02 | Valid | Epoch[042/600] Iteration[001/008] Valid loss: 0.2499
2023-02-06 11:49:02 | Valid | Epoch[042/600] Iteration[002/008] Valid loss: 0.2490
2023-02-06 11:49:02 | Valid | Epoch[042/600] Iteration[003/008] Valid loss: 0.2465
2023-02-06 11:49:02 | Valid | Epoch[042/600] Iteration[004/008] Valid loss: 0.2450
2023-02-06 11:49:02 | Valid | Epoch[042/600] Iteration[005/008] Valid loss: 0.2469
2023-02-06 11:49:02 | Valid | Epoch[042/600] Iteration[006/008] Valid loss: 0.2454
2023-02-06 11:49:02 | Valid | Epoch[042/600] Iteration[007/008] Valid loss: 0.2483
2023-02-06 11:49:02 | Valid | Epoch[042/600] Iteration[008/008] Valid loss: 0.2540
2023-02-06 11:49:02 | Valid | Epoch[042/600] MIou: 0.8633537913130607
2023-02-06 11:49:02 | Valid | Epoch[042/600] Pixel Accuracy: 0.9719022115071615
2023-02-06 11:49:02 | Valid | Epoch[042/600] Mean Pixel Accuracy: 0.9718689736069683
2023-02-06 11:49:02 | Stage | Epoch[042/600] Train loss:0.1535
2023-02-06 11:49:02 | Stage | Epoch[042/600] Valid loss:0.2540
2023-02-06 11:49:02 | Stage | Epoch[042/600] LR:0.01

2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[001/030] Train loss: 0.1515
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[002/030] Train loss: 0.1500
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[003/030] Train loss: 0.1500
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[004/030] Train loss: 0.1503
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[005/030] Train loss: 0.1512
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[006/030] Train loss: 0.1517
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[007/030] Train loss: 0.1519
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[008/030] Train loss: 0.1515
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[009/030] Train loss: 0.1514
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[010/030] Train loss: 0.1516
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[011/030] Train loss: 0.1512
2023-02-06 11:49:03 | Train | Epoch[043/600] Iteration[012/030] Train loss: 0.1511
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[013/030] Train loss: 0.1511
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[014/030] Train loss: 0.1510
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[015/030] Train loss: 0.1510
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[016/030] Train loss: 0.1509
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[017/030] Train loss: 0.1508
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[018/030] Train loss: 0.1506
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[019/030] Train loss: 0.1505
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[020/030] Train loss: 0.1504
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[021/030] Train loss: 0.1504
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[022/030] Train loss: 0.1503
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[023/030] Train loss: 0.1502
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[024/030] Train loss: 0.1500
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[025/030] Train loss: 0.1499
2023-02-06 11:49:04 | Train | Epoch[043/600] Iteration[026/030] Train loss: 0.1498
2023-02-06 11:49:05 | Train | Epoch[043/600] Iteration[027/030] Train loss: 0.1496
2023-02-06 11:49:05 | Train | Epoch[043/600] Iteration[028/030] Train loss: 0.1496
2023-02-06 11:49:05 | Train | Epoch[043/600] Iteration[029/030] Train loss: 0.1495
2023-02-06 11:49:05 | Train | Epoch[043/600] Iteration[030/030] Train loss: 0.1493
2023-02-06 11:49:05 | Valid | Epoch[043/600] Iteration[001/008] Valid loss: 0.2224
2023-02-06 11:49:05 | Valid | Epoch[043/600] Iteration[002/008] Valid loss: 0.2230
2023-02-06 11:49:05 | Valid | Epoch[043/600] Iteration[003/008] Valid loss: 0.2211
2023-02-06 11:49:05 | Valid | Epoch[043/600] Iteration[004/008] Valid loss: 0.2212
2023-02-06 11:49:05 | Valid | Epoch[043/600] Iteration[005/008] Valid loss: 0.2206
2023-02-06 11:49:05 | Valid | Epoch[043/600] Iteration[006/008] Valid loss: 0.2201
2023-02-06 11:49:05 | Valid | Epoch[043/600] Iteration[007/008] Valid loss: 0.2233
2023-02-06 11:49:05 | Valid | Epoch[043/600] Iteration[008/008] Valid loss: 0.2246
2023-02-06 11:49:05 | Valid | Epoch[043/600] MIou: 0.8869738773195137
2023-02-06 11:49:05 | Valid | Epoch[043/600] Pixel Accuracy: 0.9777781168619791
2023-02-06 11:49:05 | Valid | Epoch[043/600] Mean Pixel Accuracy: 0.97601799016053
2023-02-06 11:49:05 | Stage | Epoch[043/600] Train loss:0.1493
2023-02-06 11:49:05 | Stage | Epoch[043/600] Valid loss:0.2246
2023-02-06 11:49:05 | Stage | Epoch[043/600] LR:0.01

2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[001/030] Train loss: 0.1450
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[002/030] Train loss: 0.1464
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[003/030] Train loss: 0.1457
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[004/030] Train loss: 0.1456
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[005/030] Train loss: 0.1456
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[006/030] Train loss: 0.1452
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[007/030] Train loss: 0.1455
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[008/030] Train loss: 0.1455
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[009/030] Train loss: 0.1451
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[010/030] Train loss: 0.1454
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[011/030] Train loss: 0.1453
2023-02-06 11:49:06 | Train | Epoch[044/600] Iteration[012/030] Train loss: 0.1453
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[013/030] Train loss: 0.1452
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[014/030] Train loss: 0.1458
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[015/030] Train loss: 0.1456
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[016/030] Train loss: 0.1457
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[017/030] Train loss: 0.1457
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[018/030] Train loss: 0.1458
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[019/030] Train loss: 0.1458
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[020/030] Train loss: 0.1459
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[021/030] Train loss: 0.1457
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[022/030] Train loss: 0.1456
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[023/030] Train loss: 0.1455
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[024/030] Train loss: 0.1455
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[025/030] Train loss: 0.1456
2023-02-06 11:49:07 | Train | Epoch[044/600] Iteration[026/030] Train loss: 0.1456
2023-02-06 11:49:08 | Train | Epoch[044/600] Iteration[027/030] Train loss: 0.1454
2023-02-06 11:49:08 | Train | Epoch[044/600] Iteration[028/030] Train loss: 0.1454
2023-02-06 11:49:08 | Train | Epoch[044/600] Iteration[029/030] Train loss: 0.1455
2023-02-06 11:49:08 | Train | Epoch[044/600] Iteration[030/030] Train loss: 0.1455
2023-02-06 11:49:08 | Valid | Epoch[044/600] Iteration[001/008] Valid loss: 0.3293
2023-02-06 11:49:08 | Valid | Epoch[044/600] Iteration[002/008] Valid loss: 0.3323
2023-02-06 11:49:08 | Valid | Epoch[044/600] Iteration[003/008] Valid loss: 0.3231
2023-02-06 11:49:08 | Valid | Epoch[044/600] Iteration[004/008] Valid loss: 0.3233
2023-02-06 11:49:08 | Valid | Epoch[044/600] Iteration[005/008] Valid loss: 0.3229
2023-02-06 11:49:08 | Valid | Epoch[044/600] Iteration[006/008] Valid loss: 0.3222
2023-02-06 11:49:08 | Valid | Epoch[044/600] Iteration[007/008] Valid loss: 0.3272
2023-02-06 11:49:08 | Valid | Epoch[044/600] Iteration[008/008] Valid loss: 0.3392
2023-02-06 11:49:08 | Valid | Epoch[044/600] MIou: 0.8441825768797737
2023-02-06 11:49:08 | Valid | Epoch[044/600] Pixel Accuracy: 0.9663009643554688
2023-02-06 11:49:08 | Valid | Epoch[044/600] Mean Pixel Accuracy: 0.9749151847656539
2023-02-06 11:49:08 | Stage | Epoch[044/600] Train loss:0.1455
2023-02-06 11:49:08 | Stage | Epoch[044/600] Valid loss:0.3392
2023-02-06 11:49:08 | Stage | Epoch[044/600] LR:0.01

2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[001/030] Train loss: 0.1422
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[002/030] Train loss: 0.1445
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[003/030] Train loss: 0.1444
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[004/030] Train loss: 0.1450
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[005/030] Train loss: 0.1443
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[006/030] Train loss: 0.1443
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[007/030] Train loss: 0.1439
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[008/030] Train loss: 0.1436
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[009/030] Train loss: 0.1435
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[010/030] Train loss: 0.1437
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[011/030] Train loss: 0.1434
2023-02-06 11:49:09 | Train | Epoch[045/600] Iteration[012/030] Train loss: 0.1432
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[013/030] Train loss: 0.1430
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[014/030] Train loss: 0.1428
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[015/030] Train loss: 0.1426
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[016/030] Train loss: 0.1424
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[017/030] Train loss: 0.1422
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[018/030] Train loss: 0.1421
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[019/030] Train loss: 0.1422
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[020/030] Train loss: 0.1421
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[021/030] Train loss: 0.1420
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[022/030] Train loss: 0.1420
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[023/030] Train loss: 0.1420
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[024/030] Train loss: 0.1419
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[025/030] Train loss: 0.1417
2023-02-06 11:49:10 | Train | Epoch[045/600] Iteration[026/030] Train loss: 0.1418
2023-02-06 11:49:11 | Train | Epoch[045/600] Iteration[027/030] Train loss: 0.1417
2023-02-06 11:49:11 | Train | Epoch[045/600] Iteration[028/030] Train loss: 0.1417
2023-02-06 11:49:11 | Train | Epoch[045/600] Iteration[029/030] Train loss: 0.1417
2023-02-06 11:49:11 | Train | Epoch[045/600] Iteration[030/030] Train loss: 0.1416
2023-02-06 11:49:11 | Valid | Epoch[045/600] Iteration[001/008] Valid loss: 0.1792
2023-02-06 11:49:11 | Valid | Epoch[045/600] Iteration[002/008] Valid loss: 0.1780
2023-02-06 11:49:11 | Valid | Epoch[045/600] Iteration[003/008] Valid loss: 0.1823
2023-02-06 11:49:11 | Valid | Epoch[045/600] Iteration[004/008] Valid loss: 0.1813
2023-02-06 11:49:11 | Valid | Epoch[045/600] Iteration[005/008] Valid loss: 0.1839
2023-02-06 11:49:11 | Valid | Epoch[045/600] Iteration[006/008] Valid loss: 0.1835
2023-02-06 11:49:11 | Valid | Epoch[045/600] Iteration[007/008] Valid loss: 0.1832
2023-02-06 11:49:11 | Valid | Epoch[045/600] Iteration[008/008] Valid loss: 0.1855
2023-02-06 11:49:11 | Valid | Epoch[045/600] MIou: 0.672020034273269
2023-02-06 11:49:11 | Valid | Epoch[045/600] Pixel Accuracy: 0.945624033610026
2023-02-06 11:49:11 | Valid | Epoch[045/600] Mean Pixel Accuracy: 0.7008645270327245
2023-02-06 11:49:11 | Stage | Epoch[045/600] Train loss:0.1416
2023-02-06 11:49:11 | Stage | Epoch[045/600] Valid loss:0.1855
2023-02-06 11:49:11 | Stage | Epoch[045/600] LR:0.01

2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[001/030] Train loss: 0.1375
2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[002/030] Train loss: 0.1381
2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[003/030] Train loss: 0.1390
2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[004/030] Train loss: 0.1387
2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[005/030] Train loss: 0.1383
2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[006/030] Train loss: 0.1385
2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[007/030] Train loss: 0.1386
2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[008/030] Train loss: 0.1383
2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[009/030] Train loss: 0.1381
2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[010/030] Train loss: 0.1382
2023-02-06 11:49:12 | Train | Epoch[046/600] Iteration[011/030] Train loss: 0.1383
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[012/030] Train loss: 0.1383
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[013/030] Train loss: 0.1383
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[014/030] Train loss: 0.1383
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[015/030] Train loss: 0.1382
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[016/030] Train loss: 0.1380
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[017/030] Train loss: 0.1379
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[018/030] Train loss: 0.1378
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[019/030] Train loss: 0.1376
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[020/030] Train loss: 0.1375
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[021/030] Train loss: 0.1375
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[022/030] Train loss: 0.1375
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[023/030] Train loss: 0.1375
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[024/030] Train loss: 0.1376
2023-02-06 11:49:13 | Train | Epoch[046/600] Iteration[025/030] Train loss: 0.1376
2023-02-06 11:49:14 | Train | Epoch[046/600] Iteration[026/030] Train loss: 0.1375
2023-02-06 11:49:14 | Train | Epoch[046/600] Iteration[027/030] Train loss: 0.1374
2023-02-06 11:49:14 | Train | Epoch[046/600] Iteration[028/030] Train loss: 0.1374
2023-02-06 11:49:14 | Train | Epoch[046/600] Iteration[029/030] Train loss: 0.1372
2023-02-06 11:49:14 | Train | Epoch[046/600] Iteration[030/030] Train loss: 0.1372
2023-02-06 11:49:14 | Valid | Epoch[046/600] Iteration[001/008] Valid loss: 0.2347
2023-02-06 11:49:14 | Valid | Epoch[046/600] Iteration[002/008] Valid loss: 0.2233
2023-02-06 11:49:14 | Valid | Epoch[046/600] Iteration[003/008] Valid loss: 0.2167
2023-02-06 11:49:14 | Valid | Epoch[046/600] Iteration[004/008] Valid loss: 0.2144
2023-02-06 11:49:14 | Valid | Epoch[046/600] Iteration[005/008] Valid loss: 0.2147
2023-02-06 11:49:14 | Valid | Epoch[046/600] Iteration[006/008] Valid loss: 0.2122
2023-02-06 11:49:14 | Valid | Epoch[046/600] Iteration[007/008] Valid loss: 0.2165
2023-02-06 11:49:14 | Valid | Epoch[046/600] Iteration[008/008] Valid loss: 0.2188
2023-02-06 11:49:14 | Valid | Epoch[046/600] MIou: 0.8881914770039325
2023-02-06 11:49:14 | Valid | Epoch[046/600] Pixel Accuracy: 0.9779090881347656
2023-02-06 11:49:14 | Valid | Epoch[046/600] Mean Pixel Accuracy: 0.9798371962214824
2023-02-06 11:49:14 | Stage | Epoch[046/600] Train loss:0.1372
2023-02-06 11:49:14 | Stage | Epoch[046/600] Valid loss:0.2188
2023-02-06 11:49:14 | Stage | Epoch[046/600] LR:0.01

2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[001/030] Train loss: 0.1367
2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[002/030] Train loss: 0.1359
2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[003/030] Train loss: 0.1351
2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[004/030] Train loss: 0.1358
2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[005/030] Train loss: 0.1350
2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[006/030] Train loss: 0.1344
2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[007/030] Train loss: 0.1341
2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[008/030] Train loss: 0.1340
2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[009/030] Train loss: 0.1337
2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[010/030] Train loss: 0.1339
2023-02-06 11:49:15 | Train | Epoch[047/600] Iteration[011/030] Train loss: 0.1338
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[012/030] Train loss: 0.1341
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[013/030] Train loss: 0.1343
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[014/030] Train loss: 0.1347
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[015/030] Train loss: 0.1346
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[016/030] Train loss: 0.1346
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[017/030] Train loss: 0.1345
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[018/030] Train loss: 0.1345
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[019/030] Train loss: 0.1345
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[020/030] Train loss: 0.1344
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[021/030] Train loss: 0.1345
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[022/030] Train loss: 0.1345
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[023/030] Train loss: 0.1344
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[024/030] Train loss: 0.1344
2023-02-06 11:49:16 | Train | Epoch[047/600] Iteration[025/030] Train loss: 0.1345
2023-02-06 11:49:17 | Train | Epoch[047/600] Iteration[026/030] Train loss: 0.1345
2023-02-06 11:49:17 | Train | Epoch[047/600] Iteration[027/030] Train loss: 0.1343
2023-02-06 11:49:17 | Train | Epoch[047/600] Iteration[028/030] Train loss: 0.1343
2023-02-06 11:49:17 | Train | Epoch[047/600] Iteration[029/030] Train loss: 0.1343
2023-02-06 11:49:17 | Train | Epoch[047/600] Iteration[030/030] Train loss: 0.1343
2023-02-06 11:49:17 | Valid | Epoch[047/600] Iteration[001/008] Valid loss: 0.2310
2023-02-06 11:49:17 | Valid | Epoch[047/600] Iteration[002/008] Valid loss: 0.2162
2023-02-06 11:49:17 | Valid | Epoch[047/600] Iteration[003/008] Valid loss: 0.2167
2023-02-06 11:49:17 | Valid | Epoch[047/600] Iteration[004/008] Valid loss: 0.2148
2023-02-06 11:49:17 | Valid | Epoch[047/600] Iteration[005/008] Valid loss: 0.2202
2023-02-06 11:49:17 | Valid | Epoch[047/600] Iteration[006/008] Valid loss: 0.2242
2023-02-06 11:49:17 | Valid | Epoch[047/600] Iteration[007/008] Valid loss: 0.2279
2023-02-06 11:49:17 | Valid | Epoch[047/600] Iteration[008/008] Valid loss: 0.2265
2023-02-06 11:49:17 | Valid | Epoch[047/600] MIou: 0.7921867529207353
2023-02-06 11:49:17 | Valid | Epoch[047/600] Pixel Accuracy: 0.9623794555664062
2023-02-06 11:49:17 | Valid | Epoch[047/600] Mean Pixel Accuracy: 0.8409540344937654
2023-02-06 11:49:17 | Stage | Epoch[047/600] Train loss:0.1343
2023-02-06 11:49:17 | Stage | Epoch[047/600] Valid loss:0.2265
2023-02-06 11:49:17 | Stage | Epoch[047/600] LR:0.01

2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[001/030] Train loss: 0.1322
2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[002/030] Train loss: 0.1309
2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[003/030] Train loss: 0.1316
2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[004/030] Train loss: 0.1313
2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[005/030] Train loss: 0.1312
2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[006/030] Train loss: 0.1310
2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[007/030] Train loss: 0.1310
2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[008/030] Train loss: 0.1312
2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[009/030] Train loss: 0.1312
2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[010/030] Train loss: 0.1309
2023-02-06 11:49:18 | Train | Epoch[048/600] Iteration[011/030] Train loss: 0.1307
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[012/030] Train loss: 0.1306
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[013/030] Train loss: 0.1308
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[014/030] Train loss: 0.1308
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[015/030] Train loss: 0.1310
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[016/030] Train loss: 0.1308
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[017/030] Train loss: 0.1306
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[018/030] Train loss: 0.1304
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[019/030] Train loss: 0.1303
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[020/030] Train loss: 0.1303
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[021/030] Train loss: 0.1305
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[022/030] Train loss: 0.1305
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[023/030] Train loss: 0.1304
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[024/030] Train loss: 0.1306
2023-02-06 11:49:19 | Train | Epoch[048/600] Iteration[025/030] Train loss: 0.1307
2023-02-06 11:49:20 | Train | Epoch[048/600] Iteration[026/030] Train loss: 0.1307
2023-02-06 11:49:20 | Train | Epoch[048/600] Iteration[027/030] Train loss: 0.1306
2023-02-06 11:49:20 | Train | Epoch[048/600] Iteration[028/030] Train loss: 0.1307
2023-02-06 11:49:20 | Train | Epoch[048/600] Iteration[029/030] Train loss: 0.1307
2023-02-06 11:49:20 | Train | Epoch[048/600] Iteration[030/030] Train loss: 0.1306
2023-02-06 11:49:20 | Valid | Epoch[048/600] Iteration[001/008] Valid loss: 0.1626
2023-02-06 11:49:20 | Valid | Epoch[048/600] Iteration[002/008] Valid loss: 0.1543
2023-02-06 11:49:20 | Valid | Epoch[048/600] Iteration[003/008] Valid loss: 0.1523
2023-02-06 11:49:20 | Valid | Epoch[048/600] Iteration[004/008] Valid loss: 0.1508
2023-02-06 11:49:20 | Valid | Epoch[048/600] Iteration[005/008] Valid loss: 0.1510
2023-02-06 11:49:20 | Valid | Epoch[048/600] Iteration[006/008] Valid loss: 0.1496
2023-02-06 11:49:20 | Valid | Epoch[048/600] Iteration[007/008] Valid loss: 0.1514
2023-02-06 11:49:20 | Valid | Epoch[048/600] Iteration[008/008] Valid loss: 0.1513
2023-02-06 11:49:20 | Valid | Epoch[048/600] MIou: 0.9279179250991841
2023-02-06 11:49:20 | Valid | Epoch[048/600] Pixel Accuracy: 0.9872029622395834
2023-02-06 11:49:20 | Valid | Epoch[048/600] Mean Pixel Accuracy: 0.9690055604222653
2023-02-06 11:49:20 | Stage | Epoch[048/600] Train loss:0.1306
2023-02-06 11:49:20 | Stage | Epoch[048/600] Valid loss:0.1513
2023-02-06 11:49:20 | Stage | Epoch[048/600] LR:0.01

2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[001/030] Train loss: 0.1313
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[002/030] Train loss: 0.1293
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[003/030] Train loss: 0.1298
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[004/030] Train loss: 0.1292
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[005/030] Train loss: 0.1296
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[006/030] Train loss: 0.1298
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[007/030] Train loss: 0.1296
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[008/030] Train loss: 0.1295
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[009/030] Train loss: 0.1299
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[010/030] Train loss: 0.1296
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[011/030] Train loss: 0.1293
2023-02-06 11:49:21 | Train | Epoch[049/600] Iteration[012/030] Train loss: 0.1294
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[013/030] Train loss: 0.1299
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[014/030] Train loss: 0.1298
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[015/030] Train loss: 0.1299
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[016/030] Train loss: 0.1297
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[017/030] Train loss: 0.1295
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[018/030] Train loss: 0.1294
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[019/030] Train loss: 0.1293
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[020/030] Train loss: 0.1292
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[021/030] Train loss: 0.1290
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[022/030] Train loss: 0.1290
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[023/030] Train loss: 0.1291
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[024/030] Train loss: 0.1290
2023-02-06 11:49:22 | Train | Epoch[049/600] Iteration[025/030] Train loss: 0.1288
2023-02-06 11:49:23 | Train | Epoch[049/600] Iteration[026/030] Train loss: 0.1288
2023-02-06 11:49:23 | Train | Epoch[049/600] Iteration[027/030] Train loss: 0.1287
2023-02-06 11:49:23 | Train | Epoch[049/600] Iteration[028/030] Train loss: 0.1287
2023-02-06 11:49:23 | Train | Epoch[049/600] Iteration[029/030] Train loss: 0.1288
2023-02-06 11:49:23 | Train | Epoch[049/600] Iteration[030/030] Train loss: 0.1289
2023-02-06 11:49:23 | Valid | Epoch[049/600] Iteration[001/008] Valid loss: 5.1155
2023-02-06 11:49:23 | Valid | Epoch[049/600] Iteration[002/008] Valid loss: 5.3516
2023-02-06 11:49:23 | Valid | Epoch[049/600] Iteration[003/008] Valid loss: 5.4676
2023-02-06 11:49:23 | Valid | Epoch[049/600] Iteration[004/008] Valid loss: 5.5723
2023-02-06 11:49:23 | Valid | Epoch[049/600] Iteration[005/008] Valid loss: 5.5076
2023-02-06 11:49:23 | Valid | Epoch[049/600] Iteration[006/008] Valid loss: 5.3042
2023-02-06 11:49:23 | Valid | Epoch[049/600] Iteration[007/008] Valid loss: 5.2768
2023-02-06 11:49:23 | Valid | Epoch[049/600] Iteration[008/008] Valid loss: 5.5269
2023-02-06 11:49:23 | Valid | Epoch[049/600] MIou: 0.3439393281147492
2023-02-06 11:49:23 | Valid | Epoch[049/600] Pixel Accuracy: 0.5610186258951823
2023-02-06 11:49:23 | Valid | Epoch[049/600] Mean Pixel Accuracy: 0.7577914058484395
2023-02-06 11:49:23 | Stage | Epoch[049/600] Train loss:0.1289
2023-02-06 11:49:23 | Stage | Epoch[049/600] Valid loss:5.5269
2023-02-06 11:49:23 | Stage | Epoch[049/600] LR:0.01

2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[001/030] Train loss: 0.1297
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[002/030] Train loss: 0.1280
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[003/030] Train loss: 0.1274
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[004/030] Train loss: 0.1271
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[005/030] Train loss: 0.1269
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[006/030] Train loss: 0.1264
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[007/030] Train loss: 0.1265
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[008/030] Train loss: 0.1269
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[009/030] Train loss: 0.1269
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[010/030] Train loss: 0.1267
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[011/030] Train loss: 0.1266
2023-02-06 11:49:24 | Train | Epoch[050/600] Iteration[012/030] Train loss: 0.1269
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[013/030] Train loss: 0.1268
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[014/030] Train loss: 0.1268
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[015/030] Train loss: 0.1268
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[016/030] Train loss: 0.1270
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[017/030] Train loss: 0.1269
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[018/030] Train loss: 0.1269
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[019/030] Train loss: 0.1267
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[020/030] Train loss: 0.1267
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[021/030] Train loss: 0.1266
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[022/030] Train loss: 0.1265
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[023/030] Train loss: 0.1265
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[024/030] Train loss: 0.1265
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[025/030] Train loss: 0.1264
2023-02-06 11:49:25 | Train | Epoch[050/600] Iteration[026/030] Train loss: 0.1262
2023-02-06 11:49:26 | Train | Epoch[050/600] Iteration[027/030] Train loss: 0.1260
2023-02-06 11:49:26 | Train | Epoch[050/600] Iteration[028/030] Train loss: 0.1259
2023-02-06 11:49:26 | Train | Epoch[050/600] Iteration[029/030] Train loss: 0.1259
2023-02-06 11:49:26 | Train | Epoch[050/600] Iteration[030/030] Train loss: 0.1259
2023-02-06 11:49:26 | Valid | Epoch[050/600] Iteration[001/008] Valid loss: 0.3495
2023-02-06 11:49:26 | Valid | Epoch[050/600] Iteration[002/008] Valid loss: 0.3176
2023-02-06 11:49:26 | Valid | Epoch[050/600] Iteration[003/008] Valid loss: 0.3087
2023-02-06 11:49:26 | Valid | Epoch[050/600] Iteration[004/008] Valid loss: 0.2937
2023-02-06 11:49:26 | Valid | Epoch[050/600] Iteration[005/008] Valid loss: 0.2997
2023-02-06 11:49:26 | Valid | Epoch[050/600] Iteration[006/008] Valid loss: 0.3320
2023-02-06 11:49:26 | Valid | Epoch[050/600] Iteration[007/008] Valid loss: 0.3602
2023-02-06 11:49:26 | Valid | Epoch[050/600] Iteration[008/008] Valid loss: 0.3514
2023-02-06 11:49:26 | Valid | Epoch[050/600] MIou: 0.8061623438771233
2023-02-06 11:49:26 | Valid | Epoch[050/600] Pixel Accuracy: 0.960198720296224
2023-02-06 11:49:26 | Valid | Epoch[050/600] Mean Pixel Accuracy: 0.9052017563308512
2023-02-06 11:49:26 | Stage | Epoch[050/600] Train loss:0.1259
2023-02-06 11:49:26 | Stage | Epoch[050/600] Valid loss:0.3514
2023-02-06 11:49:26 | Stage | Epoch[050/600] LR:0.01

2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[001/030] Train loss: 0.1247
2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[002/030] Train loss: 0.1233
2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[003/030] Train loss: 0.1232
2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[004/030] Train loss: 0.1231
2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[005/030] Train loss: 0.1228
2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[006/030] Train loss: 0.1224
2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[007/030] Train loss: 0.1226
2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[008/030] Train loss: 0.1225
2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[009/030] Train loss: 0.1229
2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[010/030] Train loss: 0.1228
2023-02-06 11:49:27 | Train | Epoch[051/600] Iteration[011/030] Train loss: 0.1227
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[012/030] Train loss: 0.1228
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[013/030] Train loss: 0.1227
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[014/030] Train loss: 0.1226
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[015/030] Train loss: 0.1226
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[016/030] Train loss: 0.1225
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[017/030] Train loss: 0.1227
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[018/030] Train loss: 0.1227
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[019/030] Train loss: 0.1225
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[020/030] Train loss: 0.1223
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[021/030] Train loss: 0.1222
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[022/030] Train loss: 0.1222
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[023/030] Train loss: 0.1221
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[024/030] Train loss: 0.1222
2023-02-06 11:49:28 | Train | Epoch[051/600] Iteration[025/030] Train loss: 0.1221
2023-02-06 11:49:29 | Train | Epoch[051/600] Iteration[026/030] Train loss: 0.1220
2023-02-06 11:49:29 | Train | Epoch[051/600] Iteration[027/030] Train loss: 0.1220
2023-02-06 11:49:29 | Train | Epoch[051/600] Iteration[028/030] Train loss: 0.1219
2023-02-06 11:49:29 | Train | Epoch[051/600] Iteration[029/030] Train loss: 0.1218
2023-02-06 11:49:29 | Train | Epoch[051/600] Iteration[030/030] Train loss: 0.1218
2023-02-06 11:49:29 | Valid | Epoch[051/600] Iteration[001/008] Valid loss: 0.1273
2023-02-06 11:49:29 | Valid | Epoch[051/600] Iteration[002/008] Valid loss: 0.1252
2023-02-06 11:49:29 | Valid | Epoch[051/600] Iteration[003/008] Valid loss: 0.1253
2023-02-06 11:49:29 | Valid | Epoch[051/600] Iteration[004/008] Valid loss: 0.1243
2023-02-06 11:49:29 | Valid | Epoch[051/600] Iteration[005/008] Valid loss: 0.1247
2023-02-06 11:49:29 | Valid | Epoch[051/600] Iteration[006/008] Valid loss: 0.1243
2023-02-06 11:49:29 | Valid | Epoch[051/600] Iteration[007/008] Valid loss: 0.1240
2023-02-06 11:49:29 | Valid | Epoch[051/600] Iteration[008/008] Valid loss: 0.1240
2023-02-06 11:49:29 | Valid | Epoch[051/600] MIou: 0.9040567950566489
2023-02-06 11:49:29 | Valid | Epoch[051/600] Pixel Accuracy: 0.9840965270996094
2023-02-06 11:49:29 | Valid | Epoch[051/600] Mean Pixel Accuracy: 0.9155472027014859
2023-02-06 11:49:29 | Stage | Epoch[051/600] Train loss:0.1218
2023-02-06 11:49:29 | Stage | Epoch[051/600] Valid loss:0.1240
2023-02-06 11:49:29 | Stage | Epoch[051/600] LR:0.01

2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[001/030] Train loss: 0.1195
2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[002/030] Train loss: 0.1186
2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[003/030] Train loss: 0.1183
2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[004/030] Train loss: 0.1185
2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[005/030] Train loss: 0.1187
2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[006/030] Train loss: 0.1184
2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[007/030] Train loss: 0.1180
2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[008/030] Train loss: 0.1178
2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[009/030] Train loss: 0.1176
2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[010/030] Train loss: 0.1177
2023-02-06 11:49:30 | Train | Epoch[052/600] Iteration[011/030] Train loss: 0.1178
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[012/030] Train loss: 0.1179
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[013/030] Train loss: 0.1180
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[014/030] Train loss: 0.1187
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[015/030] Train loss: 0.1186
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[016/030] Train loss: 0.1186
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[017/030] Train loss: 0.1185
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[018/030] Train loss: 0.1186
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[019/030] Train loss: 0.1186
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[020/030] Train loss: 0.1186
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[021/030] Train loss: 0.1187
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[022/030] Train loss: 0.1185
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[023/030] Train loss: 0.1185
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[024/030] Train loss: 0.1185
2023-02-06 11:49:31 | Train | Epoch[052/600] Iteration[025/030] Train loss: 0.1185
2023-02-06 11:49:32 | Train | Epoch[052/600] Iteration[026/030] Train loss: 0.1185
2023-02-06 11:49:32 | Train | Epoch[052/600] Iteration[027/030] Train loss: 0.1185
2023-02-06 11:49:32 | Train | Epoch[052/600] Iteration[028/030] Train loss: 0.1186
2023-02-06 11:49:32 | Train | Epoch[052/600] Iteration[029/030] Train loss: 0.1186
2023-02-06 11:49:32 | Train | Epoch[052/600] Iteration[030/030] Train loss: 0.1185
2023-02-06 11:49:32 | Valid | Epoch[052/600] Iteration[001/008] Valid loss: 0.1535
2023-02-06 11:49:32 | Valid | Epoch[052/600] Iteration[002/008] Valid loss: 0.1472
2023-02-06 11:49:32 | Valid | Epoch[052/600] Iteration[003/008] Valid loss: 0.1455
2023-02-06 11:49:32 | Valid | Epoch[052/600] Iteration[004/008] Valid loss: 0.1450
2023-02-06 11:49:32 | Valid | Epoch[052/600] Iteration[005/008] Valid loss: 0.1459
2023-02-06 11:49:32 | Valid | Epoch[052/600] Iteration[006/008] Valid loss: 0.1457
2023-02-06 11:49:32 | Valid | Epoch[052/600] Iteration[007/008] Valid loss: 0.1474
2023-02-06 11:49:32 | Valid | Epoch[052/600] Iteration[008/008] Valid loss: 0.1474
2023-02-06 11:49:32 | Valid | Epoch[052/600] MIou: 0.9272229737646545
2023-02-06 11:49:32 | Valid | Epoch[052/600] Pixel Accuracy: 0.9870198567708334
2023-02-06 11:49:32 | Valid | Epoch[052/600] Mean Pixel Accuracy: 0.9705217380829613
2023-02-06 11:49:32 | Stage | Epoch[052/600] Train loss:0.1185
2023-02-06 11:49:32 | Stage | Epoch[052/600] Valid loss:0.1474
2023-02-06 11:49:32 | Stage | Epoch[052/600] LR:0.01

2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[001/030] Train loss: 0.1211
2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[002/030] Train loss: 0.1196
2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[003/030] Train loss: 0.1182
2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[004/030] Train loss: 0.1174
2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[005/030] Train loss: 0.1169
2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[006/030] Train loss: 0.1165
2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[007/030] Train loss: 0.1165
2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[008/030] Train loss: 0.1166
2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[009/030] Train loss: 0.1168
2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[010/030] Train loss: 0.1171
2023-02-06 11:49:33 | Train | Epoch[053/600] Iteration[011/030] Train loss: 0.1169
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[012/030] Train loss: 0.1171
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[013/030] Train loss: 0.1171
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[014/030] Train loss: 0.1170
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[015/030] Train loss: 0.1167
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[016/030] Train loss: 0.1166
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[017/030] Train loss: 0.1166
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[018/030] Train loss: 0.1164
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[019/030] Train loss: 0.1164
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[020/030] Train loss: 0.1162
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[021/030] Train loss: 0.1162
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[022/030] Train loss: 0.1163
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[023/030] Train loss: 0.1162
2023-02-06 11:49:34 | Train | Epoch[053/600] Iteration[024/030] Train loss: 0.1161
2023-02-06 11:49:35 | Train | Epoch[053/600] Iteration[025/030] Train loss: 0.1160
2023-02-06 11:49:35 | Train | Epoch[053/600] Iteration[026/030] Train loss: 0.1160
2023-02-06 11:49:35 | Train | Epoch[053/600] Iteration[027/030] Train loss: 0.1160
2023-02-06 11:49:35 | Train | Epoch[053/600] Iteration[028/030] Train loss: 0.1161
2023-02-06 11:49:35 | Train | Epoch[053/600] Iteration[029/030] Train loss: 0.1160
2023-02-06 11:49:35 | Train | Epoch[053/600] Iteration[030/030] Train loss: 0.1159
2023-02-06 11:49:35 | Valid | Epoch[053/600] Iteration[001/008] Valid loss: 0.1295
2023-02-06 11:49:35 | Valid | Epoch[053/600] Iteration[002/008] Valid loss: 0.1283
2023-02-06 11:49:35 | Valid | Epoch[053/600] Iteration[003/008] Valid loss: 0.1288
2023-02-06 11:49:35 | Valid | Epoch[053/600] Iteration[004/008] Valid loss: 0.1277
2023-02-06 11:49:35 | Valid | Epoch[053/600] Iteration[005/008] Valid loss: 0.1281
2023-02-06 11:49:35 | Valid | Epoch[053/600] Iteration[006/008] Valid loss: 0.1275
2023-02-06 11:49:35 | Valid | Epoch[053/600] Iteration[007/008] Valid loss: 0.1271
2023-02-06 11:49:35 | Valid | Epoch[053/600] Iteration[008/008] Valid loss: 0.1273
2023-02-06 11:49:35 | Valid | Epoch[053/600] MIou: 0.8789636480214935
2023-02-06 11:49:35 | Valid | Epoch[053/600] Pixel Accuracy: 0.9799855550130209
2023-02-06 11:49:35 | Valid | Epoch[053/600] Mean Pixel Accuracy: 0.8913749675682301
2023-02-06 11:49:35 | Stage | Epoch[053/600] Train loss:0.1159
2023-02-06 11:49:35 | Stage | Epoch[053/600] Valid loss:0.1273
2023-02-06 11:49:35 | Stage | Epoch[053/600] LR:0.01

2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[001/030] Train loss: 0.1124
2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[002/030] Train loss: 0.1124
2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[003/030] Train loss: 0.1120
2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[004/030] Train loss: 0.1123
2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[005/030] Train loss: 0.1122
2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[006/030] Train loss: 0.1127
2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[007/030] Train loss: 0.1126
2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[008/030] Train loss: 0.1134
2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[009/030] Train loss: 0.1131
2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[010/030] Train loss: 0.1134
2023-02-06 11:49:36 | Train | Epoch[054/600] Iteration[011/030] Train loss: 0.1136
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[012/030] Train loss: 0.1137
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[013/030] Train loss: 0.1136
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[014/030] Train loss: 0.1136
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[015/030] Train loss: 0.1136
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[016/030] Train loss: 0.1135
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[017/030] Train loss: 0.1134
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[018/030] Train loss: 0.1134
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[019/030] Train loss: 0.1133
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[020/030] Train loss: 0.1132
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[021/030] Train loss: 0.1131
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[022/030] Train loss: 0.1131
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[023/030] Train loss: 0.1131
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[024/030] Train loss: 0.1130
2023-02-06 11:49:37 | Train | Epoch[054/600] Iteration[025/030] Train loss: 0.1130
2023-02-06 11:49:38 | Train | Epoch[054/600] Iteration[026/030] Train loss: 0.1133
2023-02-06 11:49:38 | Train | Epoch[054/600] Iteration[027/030] Train loss: 0.1134
2023-02-06 11:49:38 | Train | Epoch[054/600] Iteration[028/030] Train loss: 0.1135
2023-02-06 11:49:38 | Train | Epoch[054/600] Iteration[029/030] Train loss: 0.1135
2023-02-06 11:49:38 | Train | Epoch[054/600] Iteration[030/030] Train loss: 0.1134
2023-02-06 11:49:38 | Valid | Epoch[054/600] Iteration[001/008] Valid loss: 0.2899
2023-02-06 11:49:38 | Valid | Epoch[054/600] Iteration[002/008] Valid loss: 0.2568
2023-02-06 11:49:38 | Valid | Epoch[054/600] Iteration[003/008] Valid loss: 0.2477
2023-02-06 11:49:38 | Valid | Epoch[054/600] Iteration[004/008] Valid loss: 0.2498
2023-02-06 11:49:38 | Valid | Epoch[054/600] Iteration[005/008] Valid loss: 0.2549
2023-02-06 11:49:38 | Valid | Epoch[054/600] Iteration[006/008] Valid loss: 0.2469
2023-02-06 11:49:38 | Valid | Epoch[054/600] Iteration[007/008] Valid loss: 0.2507
2023-02-06 11:49:38 | Valid | Epoch[054/600] Iteration[008/008] Valid loss: 0.2486
2023-02-06 11:49:38 | Valid | Epoch[054/600] MIou: 0.9059100907195032
2023-02-06 11:49:38 | Valid | Epoch[054/600] Pixel Accuracy: 0.9823290506998698
2023-02-06 11:49:38 | Valid | Epoch[054/600] Mean Pixel Accuracy: 0.9737386619703603
2023-02-06 11:49:38 | Stage | Epoch[054/600] Train loss:0.1134
2023-02-06 11:49:38 | Stage | Epoch[054/600] Valid loss:0.2486
2023-02-06 11:49:38 | Stage | Epoch[054/600] LR:0.01

2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[001/030] Train loss: 0.1102
2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[002/030] Train loss: 0.1143
2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[003/030] Train loss: 0.1133
2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[004/030] Train loss: 0.1131
2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[005/030] Train loss: 0.1123
2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[006/030] Train loss: 0.1123
2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[007/030] Train loss: 0.1122
2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[008/030] Train loss: 0.1122
2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[009/030] Train loss: 0.1121
2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[010/030] Train loss: 0.1120
2023-02-06 11:49:39 | Train | Epoch[055/600] Iteration[011/030] Train loss: 0.1120
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[012/030] Train loss: 0.1118
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[013/030] Train loss: 0.1120
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[014/030] Train loss: 0.1119
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[015/030] Train loss: 0.1117
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[016/030] Train loss: 0.1115
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[017/030] Train loss: 0.1116
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[018/030] Train loss: 0.1115
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[019/030] Train loss: 0.1115
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[020/030] Train loss: 0.1114
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[021/030] Train loss: 0.1113
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[022/030] Train loss: 0.1111
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[023/030] Train loss: 0.1110
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[024/030] Train loss: 0.1113
2023-02-06 11:49:40 | Train | Epoch[055/600] Iteration[025/030] Train loss: 0.1113
2023-02-06 11:49:41 | Train | Epoch[055/600] Iteration[026/030] Train loss: 0.1113
2023-02-06 11:49:41 | Train | Epoch[055/600] Iteration[027/030] Train loss: 0.1113
2023-02-06 11:49:41 | Train | Epoch[055/600] Iteration[028/030] Train loss: 0.1113
2023-02-06 11:49:41 | Train | Epoch[055/600] Iteration[029/030] Train loss: 0.1111
2023-02-06 11:49:41 | Train | Epoch[055/600] Iteration[030/030] Train loss: 0.1111
2023-02-06 11:49:41 | Valid | Epoch[055/600] Iteration[001/008] Valid loss: 0.3125
2023-02-06 11:49:41 | Valid | Epoch[055/600] Iteration[002/008] Valid loss: 0.2812
2023-02-06 11:49:41 | Valid | Epoch[055/600] Iteration[003/008] Valid loss: 0.2731
2023-02-06 11:49:41 | Valid | Epoch[055/600] Iteration[004/008] Valid loss: 0.2715
2023-02-06 11:49:41 | Valid | Epoch[055/600] Iteration[005/008] Valid loss: 0.2776
2023-02-06 11:49:41 | Valid | Epoch[055/600] Iteration[006/008] Valid loss: 0.2728
2023-02-06 11:49:41 | Valid | Epoch[055/600] Iteration[007/008] Valid loss: 0.2747
2023-02-06 11:49:41 | Valid | Epoch[055/600] Iteration[008/008] Valid loss: 0.2689
2023-02-06 11:49:41 | Valid | Epoch[055/600] MIou: 0.90514101529577
2023-02-06 11:49:41 | Valid | Epoch[055/600] Pixel Accuracy: 0.9825642903645834
2023-02-06 11:49:41 | Valid | Epoch[055/600] Mean Pixel Accuracy: 0.9625311966592173
2023-02-06 11:49:41 | Stage | Epoch[055/600] Train loss:0.1111
2023-02-06 11:49:41 | Stage | Epoch[055/600] Valid loss:0.2689
2023-02-06 11:49:41 | Stage | Epoch[055/600] LR:0.01

2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[001/030] Train loss: 0.1107
2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[002/030] Train loss: 0.1100
2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[003/030] Train loss: 0.1106
2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[004/030] Train loss: 0.1104
2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[005/030] Train loss: 0.1099
2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[006/030] Train loss: 0.1105
2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[007/030] Train loss: 0.1102
2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[008/030] Train loss: 0.1099
2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[009/030] Train loss: 0.1097
2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[010/030] Train loss: 0.1098
2023-02-06 11:49:42 | Train | Epoch[056/600] Iteration[011/030] Train loss: 0.1096
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[012/030] Train loss: 0.1095
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[013/030] Train loss: 0.1098
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[014/030] Train loss: 0.1097
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[015/030] Train loss: 0.1095
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[016/030] Train loss: 0.1093
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[017/030] Train loss: 0.1091
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[018/030] Train loss: 0.1089
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[019/030] Train loss: 0.1089
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[020/030] Train loss: 0.1087
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[021/030] Train loss: 0.1085
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[022/030] Train loss: 0.1089
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[023/030] Train loss: 0.1087
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[024/030] Train loss: 0.1087
2023-02-06 11:49:43 | Train | Epoch[056/600] Iteration[025/030] Train loss: 0.1086
2023-02-06 11:49:44 | Train | Epoch[056/600] Iteration[026/030] Train loss: 0.1086
2023-02-06 11:49:44 | Train | Epoch[056/600] Iteration[027/030] Train loss: 0.1085
2023-02-06 11:49:44 | Train | Epoch[056/600] Iteration[028/030] Train loss: 0.1084
2023-02-06 11:49:44 | Train | Epoch[056/600] Iteration[029/030] Train loss: 0.1083
2023-02-06 11:49:44 | Train | Epoch[056/600] Iteration[030/030] Train loss: 0.1082
2023-02-06 11:49:44 | Valid | Epoch[056/600] Iteration[001/008] Valid loss: 0.1296
2023-02-06 11:49:44 | Valid | Epoch[056/600] Iteration[002/008] Valid loss: 0.1278
2023-02-06 11:49:44 | Valid | Epoch[056/600] Iteration[003/008] Valid loss: 0.1284
2023-02-06 11:49:44 | Valid | Epoch[056/600] Iteration[004/008] Valid loss: 0.1272
2023-02-06 11:49:44 | Valid | Epoch[056/600] Iteration[005/008] Valid loss: 0.1274
2023-02-06 11:49:44 | Valid | Epoch[056/600] Iteration[006/008] Valid loss: 0.1268
2023-02-06 11:49:44 | Valid | Epoch[056/600] Iteration[007/008] Valid loss: 0.1268
2023-02-06 11:49:44 | Valid | Epoch[056/600] Iteration[008/008] Valid loss: 0.1275
2023-02-06 11:49:44 | Valid | Epoch[056/600] MIou: 0.8222943215234726
2023-02-06 11:49:44 | Valid | Epoch[056/600] Pixel Accuracy: 0.9706598917643229
2023-02-06 11:49:44 | Valid | Epoch[056/600] Mean Pixel Accuracy: 0.8385371371884272
2023-02-06 11:49:44 | Stage | Epoch[056/600] Train loss:0.1082
2023-02-06 11:49:44 | Stage | Epoch[056/600] Valid loss:0.1275
2023-02-06 11:49:44 | Stage | Epoch[056/600] LR:0.01

2023-02-06 11:49:45 | Train | Epoch[057/600] Iteration[001/030] Train loss: 0.1050
2023-02-06 11:49:45 | Train | Epoch[057/600] Iteration[002/030] Train loss: 0.1075
2023-02-06 11:49:45 | Train | Epoch[057/600] Iteration[003/030] Train loss: 0.1061
2023-02-06 11:49:45 | Train | Epoch[057/600] Iteration[004/030] Train loss: 0.1062
2023-02-06 11:49:45 | Train | Epoch[057/600] Iteration[005/030] Train loss: 0.1057
2023-02-06 11:49:45 | Train | Epoch[057/600] Iteration[006/030] Train loss: 0.1054
2023-02-06 11:49:45 | Train | Epoch[057/600] Iteration[007/030] Train loss: 0.1059
2023-02-06 11:49:45 | Train | Epoch[057/600] Iteration[008/030] Train loss: 0.1059
2023-02-06 11:49:45 | Train | Epoch[057/600] Iteration[009/030] Train loss: 0.1059
2023-02-06 11:49:45 | Train | Epoch[057/600] Iteration[010/030] Train loss: 0.1064
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[011/030] Train loss: 0.1063
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[012/030] Train loss: 0.1063
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[013/030] Train loss: 0.1061
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[014/030] Train loss: 0.1062
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[015/030] Train loss: 0.1062
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[016/030] Train loss: 0.1060
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[017/030] Train loss: 0.1060
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[018/030] Train loss: 0.1059
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[019/030] Train loss: 0.1059
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[020/030] Train loss: 0.1058
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[021/030] Train loss: 0.1058
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[022/030] Train loss: 0.1058
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[023/030] Train loss: 0.1059
2023-02-06 11:49:46 | Train | Epoch[057/600] Iteration[024/030] Train loss: 0.1058
2023-02-06 11:49:47 | Train | Epoch[057/600] Iteration[025/030] Train loss: 0.1058
2023-02-06 11:49:47 | Train | Epoch[057/600] Iteration[026/030] Train loss: 0.1057
2023-02-06 11:49:47 | Train | Epoch[057/600] Iteration[027/030] Train loss: 0.1056
2023-02-06 11:49:47 | Train | Epoch[057/600] Iteration[028/030] Train loss: 0.1055
2023-02-06 11:49:47 | Train | Epoch[057/600] Iteration[029/030] Train loss: 0.1054
2023-02-06 11:49:47 | Train | Epoch[057/600] Iteration[030/030] Train loss: 0.1054
2023-02-06 11:49:47 | Valid | Epoch[057/600] Iteration[001/008] Valid loss: 0.1558
2023-02-06 11:49:47 | Valid | Epoch[057/600] Iteration[002/008] Valid loss: 0.1452
2023-02-06 11:49:47 | Valid | Epoch[057/600] Iteration[003/008] Valid loss: 0.1457
2023-02-06 11:49:47 | Valid | Epoch[057/600] Iteration[004/008] Valid loss: 0.1438
2023-02-06 11:49:47 | Valid | Epoch[057/600] Iteration[005/008] Valid loss: 0.1454
2023-02-06 11:49:47 | Valid | Epoch[057/600] Iteration[006/008] Valid loss: 0.1429
2023-02-06 11:49:47 | Valid | Epoch[057/600] Iteration[007/008] Valid loss: 0.1418
2023-02-06 11:49:47 | Valid | Epoch[057/600] Iteration[008/008] Valid loss: 0.1405
2023-02-06 11:49:48 | Valid | Epoch[057/600] MIou: 0.8817503267624549
2023-02-06 11:49:48 | Valid | Epoch[057/600] Pixel Accuracy: 0.9797414143880209
2023-02-06 11:49:48 | Valid | Epoch[057/600] Mean Pixel Accuracy: 0.9081698364056372
2023-02-06 11:49:48 | Stage | Epoch[057/600] Train loss:0.1054
2023-02-06 11:49:48 | Stage | Epoch[057/600] Valid loss:0.1405
2023-02-06 11:49:48 | Stage | Epoch[057/600] LR:0.01

2023-02-06 11:49:48 | Train | Epoch[058/600] Iteration[001/030] Train loss: 0.1050
2023-02-06 11:49:48 | Train | Epoch[058/600] Iteration[002/030] Train loss: 0.1027
2023-02-06 11:49:48 | Train | Epoch[058/600] Iteration[003/030] Train loss: 0.1031
2023-02-06 11:49:48 | Train | Epoch[058/600] Iteration[004/030] Train loss: 0.1033
2023-02-06 11:49:48 | Train | Epoch[058/600] Iteration[005/030] Train loss: 0.1040
2023-02-06 11:49:48 | Train | Epoch[058/600] Iteration[006/030] Train loss: 0.1039
2023-02-06 11:49:48 | Train | Epoch[058/600] Iteration[007/030] Train loss: 0.1039
2023-02-06 11:49:48 | Train | Epoch[058/600] Iteration[008/030] Train loss: 0.1038
2023-02-06 11:49:48 | Train | Epoch[058/600] Iteration[009/030] Train loss: 0.1039
2023-02-06 11:49:48 | Train | Epoch[058/600] Iteration[010/030] Train loss: 0.1038
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[011/030] Train loss: 0.1037
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[012/030] Train loss: 0.1035
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[013/030] Train loss: 0.1036
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[014/030] Train loss: 0.1035
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[015/030] Train loss: 0.1035
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[016/030] Train loss: 0.1035
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[017/030] Train loss: 0.1034
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[018/030] Train loss: 0.1035
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[019/030] Train loss: 0.1034
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[020/030] Train loss: 0.1033
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[021/030] Train loss: 0.1034
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[022/030] Train loss: 0.1032
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[023/030] Train loss: 0.1031
2023-02-06 11:49:49 | Train | Epoch[058/600] Iteration[024/030] Train loss: 0.1030
2023-02-06 11:49:50 | Train | Epoch[058/600] Iteration[025/030] Train loss: 0.1030
2023-02-06 11:49:50 | Train | Epoch[058/600] Iteration[026/030] Train loss: 0.1030
2023-02-06 11:49:50 | Train | Epoch[058/600] Iteration[027/030] Train loss: 0.1028
2023-02-06 11:49:50 | Train | Epoch[058/600] Iteration[028/030] Train loss: 0.1028
2023-02-06 11:49:50 | Train | Epoch[058/600] Iteration[029/030] Train loss: 0.1027
2023-02-06 11:49:50 | Train | Epoch[058/600] Iteration[030/030] Train loss: 0.1027
2023-02-06 11:49:50 | Valid | Epoch[058/600] Iteration[001/008] Valid loss: 0.1679
2023-02-06 11:49:50 | Valid | Epoch[058/600] Iteration[002/008] Valid loss: 0.1734
2023-02-06 11:49:50 | Valid | Epoch[058/600] Iteration[003/008] Valid loss: 0.1813
2023-02-06 11:49:50 | Valid | Epoch[058/600] Iteration[004/008] Valid loss: 0.1808
2023-02-06 11:49:50 | Valid | Epoch[058/600] Iteration[005/008] Valid loss: 0.1856
2023-02-06 11:49:50 | Valid | Epoch[058/600] Iteration[006/008] Valid loss: 0.1843
2023-02-06 11:49:50 | Valid | Epoch[058/600] Iteration[007/008] Valid loss: 0.1831
2023-02-06 11:49:50 | Valid | Epoch[058/600] Iteration[008/008] Valid loss: 0.1891
2023-02-06 11:49:51 | Valid | Epoch[058/600] MIou: 0.5843860196685406
2023-02-06 11:49:51 | Valid | Epoch[058/600] Pixel Accuracy: 0.9310188293457031
2023-02-06 11:49:51 | Valid | Epoch[058/600] Mean Pixel Accuracy: 0.6199214614832386
2023-02-06 11:49:51 | Stage | Epoch[058/600] Train loss:0.1027
2023-02-06 11:49:51 | Stage | Epoch[058/600] Valid loss:0.1891
2023-02-06 11:49:51 | Stage | Epoch[058/600] LR:0.01

2023-02-06 11:49:51 | Train | Epoch[059/600] Iteration[001/030] Train loss: 0.1029
2023-02-06 11:49:51 | Train | Epoch[059/600] Iteration[002/030] Train loss: 0.1031
2023-02-06 11:49:51 | Train | Epoch[059/600] Iteration[003/030] Train loss: 0.1022
2023-02-06 11:49:51 | Train | Epoch[059/600] Iteration[004/030] Train loss: 0.1020
2023-02-06 11:49:51 | Train | Epoch[059/600] Iteration[005/030] Train loss: 0.1016
2023-02-06 11:49:51 | Train | Epoch[059/600] Iteration[006/030] Train loss: 0.1012
2023-02-06 11:49:51 | Train | Epoch[059/600] Iteration[007/030] Train loss: 0.1012
2023-02-06 11:49:51 | Train | Epoch[059/600] Iteration[008/030] Train loss: 0.1014
2023-02-06 11:49:51 | Train | Epoch[059/600] Iteration[009/030] Train loss: 0.1011
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[010/030] Train loss: 0.1010
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[011/030] Train loss: 0.1013
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[012/030] Train loss: 0.1013
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[013/030] Train loss: 0.1012
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[014/030] Train loss: 0.1013
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[015/030] Train loss: 0.1014
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[016/030] Train loss: 0.1013
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[017/030] Train loss: 0.1013
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[018/030] Train loss: 0.1014
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[019/030] Train loss: 0.1013
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[020/030] Train loss: 0.1013
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[021/030] Train loss: 0.1014
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[022/030] Train loss: 0.1013
2023-02-06 11:49:52 | Train | Epoch[059/600] Iteration[023/030] Train loss: 0.1013
2023-02-06 11:49:53 | Train | Epoch[059/600] Iteration[024/030] Train loss: 0.1013
2023-02-06 11:49:53 | Train | Epoch[059/600] Iteration[025/030] Train loss: 0.1013
2023-02-06 11:49:53 | Train | Epoch[059/600] Iteration[026/030] Train loss: 0.1012
2023-02-06 11:49:53 | Train | Epoch[059/600] Iteration[027/030] Train loss: 0.1012
2023-02-06 11:49:53 | Train | Epoch[059/600] Iteration[028/030] Train loss: 0.1011
2023-02-06 11:49:53 | Train | Epoch[059/600] Iteration[029/030] Train loss: 0.1010
2023-02-06 11:49:53 | Train | Epoch[059/600] Iteration[030/030] Train loss: 0.1010
2023-02-06 11:49:53 | Valid | Epoch[059/600] Iteration[001/008] Valid loss: 0.3281
2023-02-06 11:49:53 | Valid | Epoch[059/600] Iteration[002/008] Valid loss: 0.3067
2023-02-06 11:49:53 | Valid | Epoch[059/600] Iteration[003/008] Valid loss: 0.2891
2023-02-06 11:49:53 | Valid | Epoch[059/600] Iteration[004/008] Valid loss: 0.2910
2023-02-06 11:49:53 | Valid | Epoch[059/600] Iteration[005/008] Valid loss: 0.2886
2023-02-06 11:49:53 | Valid | Epoch[059/600] Iteration[006/008] Valid loss: 0.2812
2023-02-06 11:49:53 | Valid | Epoch[059/600] Iteration[007/008] Valid loss: 0.2918
2023-02-06 11:49:53 | Valid | Epoch[059/600] Iteration[008/008] Valid loss: 0.2971
2023-02-06 11:49:54 | Valid | Epoch[059/600] MIou: 0.8870627161918165
2023-02-06 11:49:54 | Valid | Epoch[059/600] Pixel Accuracy: 0.977575937906901
2023-02-06 11:49:54 | Valid | Epoch[059/600] Mean Pixel Accuracy: 0.9810743482664404
2023-02-06 11:49:54 | Stage | Epoch[059/600] Train loss:0.1010
2023-02-06 11:49:54 | Stage | Epoch[059/600] Valid loss:0.2971
2023-02-06 11:49:54 | Stage | Epoch[059/600] LR:0.01

2023-02-06 11:49:54 | Train | Epoch[060/600] Iteration[001/030] Train loss: 0.1004
2023-02-06 11:49:54 | Train | Epoch[060/600] Iteration[002/030] Train loss: 0.1017
2023-02-06 11:49:54 | Train | Epoch[060/600] Iteration[003/030] Train loss: 0.1015
2023-02-06 11:49:54 | Train | Epoch[060/600] Iteration[004/030] Train loss: 0.1016
2023-02-06 11:49:54 | Train | Epoch[060/600] Iteration[005/030] Train loss: 0.1010
2023-02-06 11:49:54 | Train | Epoch[060/600] Iteration[006/030] Train loss: 0.1005
2023-02-06 11:49:54 | Train | Epoch[060/600] Iteration[007/030] Train loss: 0.1008
2023-02-06 11:49:54 | Train | Epoch[060/600] Iteration[008/030] Train loss: 0.1006
2023-02-06 11:49:54 | Train | Epoch[060/600] Iteration[009/030] Train loss: 0.1004
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[010/030] Train loss: 0.1002
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[011/030] Train loss: 0.1003
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[012/030] Train loss: 0.1001
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[013/030] Train loss: 0.1001
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[014/030] Train loss: 0.1001
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[015/030] Train loss: 0.0999
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[016/030] Train loss: 0.0999
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[017/030] Train loss: 0.0998
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[018/030] Train loss: 0.0996
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[019/030] Train loss: 0.0994
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[020/030] Train loss: 0.0994
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[021/030] Train loss: 0.0994
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[022/030] Train loss: 0.0994
2023-02-06 11:49:55 | Train | Epoch[060/600] Iteration[023/030] Train loss: 0.0994
2023-02-06 11:49:56 | Train | Epoch[060/600] Iteration[024/030] Train loss: 0.0993
2023-02-06 11:49:56 | Train | Epoch[060/600] Iteration[025/030] Train loss: 0.0993
2023-02-06 11:49:56 | Train | Epoch[060/600] Iteration[026/030] Train loss: 0.0994
2023-02-06 11:49:56 | Train | Epoch[060/600] Iteration[027/030] Train loss: 0.0993
2023-02-06 11:49:56 | Train | Epoch[060/600] Iteration[028/030] Train loss: 0.0993
2023-02-06 11:49:56 | Train | Epoch[060/600] Iteration[029/030] Train loss: 0.0992
2023-02-06 11:49:56 | Train | Epoch[060/600] Iteration[030/030] Train loss: 0.0992
2023-02-06 11:49:56 | Valid | Epoch[060/600] Iteration[001/008] Valid loss: 0.8367
2023-02-06 11:49:56 | Valid | Epoch[060/600] Iteration[002/008] Valid loss: 0.7827
2023-02-06 11:49:56 | Valid | Epoch[060/600] Iteration[003/008] Valid loss: 0.7973
2023-02-06 11:49:56 | Valid | Epoch[060/600] Iteration[004/008] Valid loss: 0.8161
2023-02-06 11:49:56 | Valid | Epoch[060/600] Iteration[005/008] Valid loss: 0.8394
2023-02-06 11:49:56 | Valid | Epoch[060/600] Iteration[006/008] Valid loss: 0.8098
2023-02-06 11:49:56 | Valid | Epoch[060/600] Iteration[007/008] Valid loss: 0.8434
2023-02-06 11:49:56 | Valid | Epoch[060/600] Iteration[008/008] Valid loss: 0.8619
2023-02-06 11:49:57 | Valid | Epoch[060/600] MIou: 0.8134220279768243
2023-02-06 11:49:57 | Valid | Epoch[060/600] Pixel Accuracy: 0.9566065470377604
2023-02-06 11:49:57 | Valid | Epoch[060/600] Mean Pixel Accuracy: 0.974215263754761
2023-02-06 11:49:57 | Stage | Epoch[060/600] Train loss:0.0992
2023-02-06 11:49:57 | Stage | Epoch[060/600] Valid loss:0.8619
2023-02-06 11:49:57 | Stage | Epoch[060/600] LR:0.01

2023-02-06 11:49:57 | Train | Epoch[061/600] Iteration[001/030] Train loss: 0.0987
2023-02-06 11:49:57 | Train | Epoch[061/600] Iteration[002/030] Train loss: 0.0976
2023-02-06 11:49:57 | Train | Epoch[061/600] Iteration[003/030] Train loss: 0.0974
2023-02-06 11:49:57 | Train | Epoch[061/600] Iteration[004/030] Train loss: 0.0968
2023-02-06 11:49:57 | Train | Epoch[061/600] Iteration[005/030] Train loss: 0.0973
2023-02-06 11:49:57 | Train | Epoch[061/600] Iteration[006/030] Train loss: 0.0972
2023-02-06 11:49:57 | Train | Epoch[061/600] Iteration[007/030] Train loss: 0.0970
2023-02-06 11:49:57 | Train | Epoch[061/600] Iteration[008/030] Train loss: 0.0971
2023-02-06 11:49:57 | Train | Epoch[061/600] Iteration[009/030] Train loss: 0.0970
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[010/030] Train loss: 0.0971
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[011/030] Train loss: 0.0971
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[012/030] Train loss: 0.0973
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[013/030] Train loss: 0.0974
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[014/030] Train loss: 0.0973
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[015/030] Train loss: 0.0973
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[016/030] Train loss: 0.0973
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[017/030] Train loss: 0.0974
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[018/030] Train loss: 0.0972
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[019/030] Train loss: 0.0970
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[020/030] Train loss: 0.0970
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[021/030] Train loss: 0.0969
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[022/030] Train loss: 0.0968
2023-02-06 11:49:58 | Train | Epoch[061/600] Iteration[023/030] Train loss: 0.0967
2023-02-06 11:49:59 | Train | Epoch[061/600] Iteration[024/030] Train loss: 0.0966
2023-02-06 11:49:59 | Train | Epoch[061/600] Iteration[025/030] Train loss: 0.0967
2023-02-06 11:49:59 | Train | Epoch[061/600] Iteration[026/030] Train loss: 0.0967
2023-02-06 11:49:59 | Train | Epoch[061/600] Iteration[027/030] Train loss: 0.0967
2023-02-06 11:49:59 | Train | Epoch[061/600] Iteration[028/030] Train loss: 0.0968
2023-02-06 11:49:59 | Train | Epoch[061/600] Iteration[029/030] Train loss: 0.0969
2023-02-06 11:49:59 | Train | Epoch[061/600] Iteration[030/030] Train loss: 0.0968
2023-02-06 11:49:59 | Valid | Epoch[061/600] Iteration[001/008] Valid loss: 0.1277
2023-02-06 11:49:59 | Valid | Epoch[061/600] Iteration[002/008] Valid loss: 0.1156
2023-02-06 11:49:59 | Valid | Epoch[061/600] Iteration[003/008] Valid loss: 0.1132
2023-02-06 11:49:59 | Valid | Epoch[061/600] Iteration[004/008] Valid loss: 0.1117
2023-02-06 11:49:59 | Valid | Epoch[061/600] Iteration[005/008] Valid loss: 0.1118
2023-02-06 11:49:59 | Valid | Epoch[061/600] Iteration[006/008] Valid loss: 0.1115
2023-02-06 11:49:59 | Valid | Epoch[061/600] Iteration[007/008] Valid loss: 0.1139
2023-02-06 11:49:59 | Valid | Epoch[061/600] Iteration[008/008] Valid loss: 0.1129
2023-02-06 11:50:00 | Valid | Epoch[061/600] MIou: 0.9394171628817085
2023-02-06 11:50:00 | Valid | Epoch[061/600] Pixel Accuracy: 0.989471435546875
2023-02-06 11:50:00 | Valid | Epoch[061/600] Mean Pixel Accuracy: 0.9701319411412699
2023-02-06 11:50:00 | Stage | Epoch[061/600] Train loss:0.0968
2023-02-06 11:50:00 | Stage | Epoch[061/600] Valid loss:0.1129
2023-02-06 11:50:00 | Stage | Epoch[061/600] LR:0.01

2023-02-06 11:50:00 | Train | Epoch[062/600] Iteration[001/030] Train loss: 0.0963
2023-02-06 11:50:00 | Train | Epoch[062/600] Iteration[002/030] Train loss: 0.0946
2023-02-06 11:50:00 | Train | Epoch[062/600] Iteration[003/030] Train loss: 0.0952
2023-02-06 11:50:00 | Train | Epoch[062/600] Iteration[004/030] Train loss: 0.0948
2023-02-06 11:50:00 | Train | Epoch[062/600] Iteration[005/030] Train loss: 0.0950
2023-02-06 11:50:00 | Train | Epoch[062/600] Iteration[006/030] Train loss: 0.0956
2023-02-06 11:50:00 | Train | Epoch[062/600] Iteration[007/030] Train loss: 0.0955
2023-02-06 11:50:00 | Train | Epoch[062/600] Iteration[008/030] Train loss: 0.0952
2023-02-06 11:50:00 | Train | Epoch[062/600] Iteration[009/030] Train loss: 0.0951
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[010/030] Train loss: 0.0957
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[011/030] Train loss: 0.0958
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[012/030] Train loss: 0.0957
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[013/030] Train loss: 0.0957
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[014/030] Train loss: 0.0960
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[015/030] Train loss: 0.0959
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[016/030] Train loss: 0.0959
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[017/030] Train loss: 0.0959
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[018/030] Train loss: 0.0959
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[019/030] Train loss: 0.0959
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[020/030] Train loss: 0.0959
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[021/030] Train loss: 0.0958
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[022/030] Train loss: 0.0958
2023-02-06 11:50:01 | Train | Epoch[062/600] Iteration[023/030] Train loss: 0.0960
2023-02-06 11:50:02 | Train | Epoch[062/600] Iteration[024/030] Train loss: 0.0959
2023-02-06 11:50:02 | Train | Epoch[062/600] Iteration[025/030] Train loss: 0.0957
2023-02-06 11:50:02 | Train | Epoch[062/600] Iteration[026/030] Train loss: 0.0956
2023-02-06 11:50:02 | Train | Epoch[062/600] Iteration[027/030] Train loss: 0.0956
2023-02-06 11:50:02 | Train | Epoch[062/600] Iteration[028/030] Train loss: 0.0955
2023-02-06 11:50:02 | Train | Epoch[062/600] Iteration[029/030] Train loss: 0.0954
2023-02-06 11:50:02 | Train | Epoch[062/600] Iteration[030/030] Train loss: 0.0952
2023-02-06 11:50:02 | Valid | Epoch[062/600] Iteration[001/008] Valid loss: 0.1233
2023-02-06 11:50:02 | Valid | Epoch[062/600] Iteration[002/008] Valid loss: 0.1171
2023-02-06 11:50:02 | Valid | Epoch[062/600] Iteration[003/008] Valid loss: 0.1174
2023-02-06 11:50:02 | Valid | Epoch[062/600] Iteration[004/008] Valid loss: 0.1154
2023-02-06 11:50:02 | Valid | Epoch[062/600] Iteration[005/008] Valid loss: 0.1159
2023-02-06 11:50:02 | Valid | Epoch[062/600] Iteration[006/008] Valid loss: 0.1159
2023-02-06 11:50:02 | Valid | Epoch[062/600] Iteration[007/008] Valid loss: 0.1169
2023-02-06 11:50:03 | Valid | Epoch[062/600] Iteration[008/008] Valid loss: 0.1158
2023-02-06 11:50:03 | Valid | Epoch[062/600] MIou: 0.9145549415554648
2023-02-06 11:50:03 | Valid | Epoch[062/600] Pixel Accuracy: 0.9853795369466146
2023-02-06 11:50:03 | Valid | Epoch[062/600] Mean Pixel Accuracy: 0.9390337137753493
2023-02-06 11:50:03 | Stage | Epoch[062/600] Train loss:0.0952
2023-02-06 11:50:03 | Stage | Epoch[062/600] Valid loss:0.1158
2023-02-06 11:50:03 | Stage | Epoch[062/600] LR:0.01

2023-02-06 11:50:03 | Train | Epoch[063/600] Iteration[001/030] Train loss: 0.0912
2023-02-06 11:50:03 | Train | Epoch[063/600] Iteration[002/030] Train loss: 0.0930
2023-02-06 11:50:03 | Train | Epoch[063/600] Iteration[003/030] Train loss: 0.0934
2023-02-06 11:50:03 | Train | Epoch[063/600] Iteration[004/030] Train loss: 0.0930
2023-02-06 11:50:03 | Train | Epoch[063/600] Iteration[005/030] Train loss: 0.0929
2023-02-06 11:50:03 | Train | Epoch[063/600] Iteration[006/030] Train loss: 0.0931
2023-02-06 11:50:03 | Train | Epoch[063/600] Iteration[007/030] Train loss: 0.0928
2023-02-06 11:50:03 | Train | Epoch[063/600] Iteration[008/030] Train loss: 0.0935
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[009/030] Train loss: 0.0935
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[010/030] Train loss: 0.0934
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[011/030] Train loss: 0.0934
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[012/030] Train loss: 0.0934
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[013/030] Train loss: 0.0933
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[014/030] Train loss: 0.0934
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[015/030] Train loss: 0.0933
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[016/030] Train loss: 0.0933
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[017/030] Train loss: 0.0931
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[018/030] Train loss: 0.0931
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[019/030] Train loss: 0.0930
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[020/030] Train loss: 0.0929
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[021/030] Train loss: 0.0930
2023-02-06 11:50:04 | Train | Epoch[063/600] Iteration[022/030] Train loss: 0.0929
2023-02-06 11:50:05 | Train | Epoch[063/600] Iteration[023/030] Train loss: 0.0929
2023-02-06 11:50:05 | Train | Epoch[063/600] Iteration[024/030] Train loss: 0.0928
2023-02-06 11:50:05 | Train | Epoch[063/600] Iteration[025/030] Train loss: 0.0927
2023-02-06 11:50:05 | Train | Epoch[063/600] Iteration[026/030] Train loss: 0.0927
2023-02-06 11:50:05 | Train | Epoch[063/600] Iteration[027/030] Train loss: 0.0927
2023-02-06 11:50:05 | Train | Epoch[063/600] Iteration[028/030] Train loss: 0.0926
2023-02-06 11:50:05 | Train | Epoch[063/600] Iteration[029/030] Train loss: 0.0927
2023-02-06 11:50:05 | Train | Epoch[063/600] Iteration[030/030] Train loss: 0.0926
2023-02-06 11:50:05 | Valid | Epoch[063/600] Iteration[001/008] Valid loss: 0.4422
2023-02-06 11:50:05 | Valid | Epoch[063/600] Iteration[002/008] Valid loss: 0.3911
2023-02-06 11:50:05 | Valid | Epoch[063/600] Iteration[003/008] Valid loss: 0.3777
2023-02-06 11:50:05 | Valid | Epoch[063/600] Iteration[004/008] Valid loss: 0.3776
2023-02-06 11:50:05 | Valid | Epoch[063/600] Iteration[005/008] Valid loss: 0.3851
2023-02-06 11:50:05 | Valid | Epoch[063/600] Iteration[006/008] Valid loss: 0.3780
2023-02-06 11:50:05 | Valid | Epoch[063/600] Iteration[007/008] Valid loss: 0.3948
2023-02-06 11:50:05 | Valid | Epoch[063/600] Iteration[008/008] Valid loss: 0.3950
2023-02-06 11:50:06 | Valid | Epoch[063/600] MIou: 0.8548035701451063
2023-02-06 11:50:06 | Valid | Epoch[063/600] Pixel Accuracy: 0.9690055847167969
2023-02-06 11:50:06 | Valid | Epoch[063/600] Mean Pixel Accuracy: 0.980973239425718
2023-02-06 11:50:06 | Stage | Epoch[063/600] Train loss:0.0926
2023-02-06 11:50:06 | Stage | Epoch[063/600] Valid loss:0.3950
2023-02-06 11:50:06 | Stage | Epoch[063/600] LR:0.01

2023-02-06 11:50:06 | Train | Epoch[064/600] Iteration[001/030] Train loss: 0.0922
2023-02-06 11:50:06 | Train | Epoch[064/600] Iteration[002/030] Train loss: 0.0925
2023-02-06 11:50:06 | Train | Epoch[064/600] Iteration[003/030] Train loss: 0.0921
2023-02-06 11:50:06 | Train | Epoch[064/600] Iteration[004/030] Train loss: 0.0914
2023-02-06 11:50:06 | Train | Epoch[064/600] Iteration[005/030] Train loss: 0.0920
2023-02-06 11:50:06 | Train | Epoch[064/600] Iteration[006/030] Train loss: 0.0915
2023-02-06 11:50:06 | Train | Epoch[064/600] Iteration[007/030] Train loss: 0.0918
2023-02-06 11:50:06 | Train | Epoch[064/600] Iteration[008/030] Train loss: 0.0917
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[009/030] Train loss: 0.0919
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[010/030] Train loss: 0.0919
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[011/030] Train loss: 0.0918
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[012/030] Train loss: 0.0917
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[013/030] Train loss: 0.0917
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[014/030] Train loss: 0.0918
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[015/030] Train loss: 0.0918
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[016/030] Train loss: 0.0918
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[017/030] Train loss: 0.0919
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[018/030] Train loss: 0.0917
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[019/030] Train loss: 0.0916
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[020/030] Train loss: 0.0914
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[021/030] Train loss: 0.0914
2023-02-06 11:50:07 | Train | Epoch[064/600] Iteration[022/030] Train loss: 0.0913
2023-02-06 11:50:08 | Train | Epoch[064/600] Iteration[023/030] Train loss: 0.0912
2023-02-06 11:50:08 | Train | Epoch[064/600] Iteration[024/030] Train loss: 0.0911
2023-02-06 11:50:08 | Train | Epoch[064/600] Iteration[025/030] Train loss: 0.0910
2023-02-06 11:50:08 | Train | Epoch[064/600] Iteration[026/030] Train loss: 0.0909
2023-02-06 11:50:08 | Train | Epoch[064/600] Iteration[027/030] Train loss: 0.0909
2023-02-06 11:50:08 | Train | Epoch[064/600] Iteration[028/030] Train loss: 0.0908
2023-02-06 11:50:08 | Train | Epoch[064/600] Iteration[029/030] Train loss: 0.0907
2023-02-06 11:50:08 | Train | Epoch[064/600] Iteration[030/030] Train loss: 0.0906
2023-02-06 11:50:08 | Valid | Epoch[064/600] Iteration[001/008] Valid loss: 0.3130
2023-02-06 11:50:08 | Valid | Epoch[064/600] Iteration[002/008] Valid loss: 0.2629
2023-02-06 11:50:08 | Valid | Epoch[064/600] Iteration[003/008] Valid loss: 0.2561
2023-02-06 11:50:08 | Valid | Epoch[064/600] Iteration[004/008] Valid loss: 0.2541
2023-02-06 11:50:08 | Valid | Epoch[064/600] Iteration[005/008] Valid loss: 0.2607
2023-02-06 11:50:08 | Valid | Epoch[064/600] Iteration[006/008] Valid loss: 0.2568
2023-02-06 11:50:08 | Valid | Epoch[064/600] Iteration[007/008] Valid loss: 0.2603
2023-02-06 11:50:09 | Valid | Epoch[064/600] Iteration[008/008] Valid loss: 0.2541
2023-02-06 11:50:09 | Valid | Epoch[064/600] MIou: 0.9043488196197602
2023-02-06 11:50:09 | Valid | Epoch[064/600] Pixel Accuracy: 0.9820365905761719
2023-02-06 11:50:09 | Valid | Epoch[064/600] Mean Pixel Accuracy: 0.9720752216648905
2023-02-06 11:50:09 | Stage | Epoch[064/600] Train loss:0.0906
2023-02-06 11:50:09 | Stage | Epoch[064/600] Valid loss:0.2541
2023-02-06 11:50:09 | Stage | Epoch[064/600] LR:0.01

2023-02-06 11:50:09 | Train | Epoch[065/600] Iteration[001/030] Train loss: 0.0869
2023-02-06 11:50:09 | Train | Epoch[065/600] Iteration[002/030] Train loss: 0.0874
2023-02-06 11:50:09 | Train | Epoch[065/600] Iteration[003/030] Train loss: 0.0875
2023-02-06 11:50:09 | Train | Epoch[065/600] Iteration[004/030] Train loss: 0.0887
2023-02-06 11:50:09 | Train | Epoch[065/600] Iteration[005/030] Train loss: 0.0885
2023-02-06 11:50:09 | Train | Epoch[065/600] Iteration[006/030] Train loss: 0.0885
2023-02-06 11:50:09 | Train | Epoch[065/600] Iteration[007/030] Train loss: 0.0883
2023-02-06 11:50:09 | Train | Epoch[065/600] Iteration[008/030] Train loss: 0.0882
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[009/030] Train loss: 0.0883
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[010/030] Train loss: 0.0883
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[011/030] Train loss: 0.0883
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[012/030] Train loss: 0.0882
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[013/030] Train loss: 0.0882
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[014/030] Train loss: 0.0882
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[015/030] Train loss: 0.0884
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[016/030] Train loss: 0.0884
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[017/030] Train loss: 0.0886
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[018/030] Train loss: 0.0887
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[019/030] Train loss: 0.0888
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[020/030] Train loss: 0.0888
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[021/030] Train loss: 0.0888
2023-02-06 11:50:10 | Train | Epoch[065/600] Iteration[022/030] Train loss: 0.0887
2023-02-06 11:50:11 | Train | Epoch[065/600] Iteration[023/030] Train loss: 0.0887
2023-02-06 11:50:11 | Train | Epoch[065/600] Iteration[024/030] Train loss: 0.0887
2023-02-06 11:50:11 | Train | Epoch[065/600] Iteration[025/030] Train loss: 0.0888
2023-02-06 11:50:11 | Train | Epoch[065/600] Iteration[026/030] Train loss: 0.0888
2023-02-06 11:50:11 | Train | Epoch[065/600] Iteration[027/030] Train loss: 0.0887
2023-02-06 11:50:11 | Train | Epoch[065/600] Iteration[028/030] Train loss: 0.0887
2023-02-06 11:50:11 | Train | Epoch[065/600] Iteration[029/030] Train loss: 0.0887
2023-02-06 11:50:11 | Train | Epoch[065/600] Iteration[030/030] Train loss: 0.0887
2023-02-06 11:50:11 | Valid | Epoch[065/600] Iteration[001/008] Valid loss: 0.2720
2023-02-06 11:50:11 | Valid | Epoch[065/600] Iteration[002/008] Valid loss: 0.2211
2023-02-06 11:50:11 | Valid | Epoch[065/600] Iteration[003/008] Valid loss: 0.2165
2023-02-06 11:50:11 | Valid | Epoch[065/600] Iteration[004/008] Valid loss: 0.2140
2023-02-06 11:50:11 | Valid | Epoch[065/600] Iteration[005/008] Valid loss: 0.2141
2023-02-06 11:50:12 | Valid | Epoch[065/600] Iteration[006/008] Valid loss: 0.2077
2023-02-06 11:50:12 | Valid | Epoch[065/600] Iteration[007/008] Valid loss: 0.2168
2023-02-06 11:50:12 | Valid | Epoch[065/600] Iteration[008/008] Valid loss: 0.2175
2023-02-06 11:50:12 | Valid | Epoch[065/600] MIou: 0.8938602841870626
2023-02-06 11:50:12 | Valid | Epoch[065/600] Pixel Accuracy: 0.9792048136393229
2023-02-06 11:50:12 | Valid | Epoch[065/600] Mean Pixel Accuracy: 0.9818428384086075
2023-02-06 11:50:12 | Stage | Epoch[065/600] Train loss:0.0887
2023-02-06 11:50:12 | Stage | Epoch[065/600] Valid loss:0.2175
2023-02-06 11:50:12 | Stage | Epoch[065/600] LR:0.01

2023-02-06 11:50:12 | Train | Epoch[066/600] Iteration[001/030] Train loss: 0.0873
2023-02-06 11:50:12 | Train | Epoch[066/600] Iteration[002/030] Train loss: 0.0895
2023-02-06 11:50:12 | Train | Epoch[066/600] Iteration[003/030] Train loss: 0.0891
2023-02-06 11:50:12 | Train | Epoch[066/600] Iteration[004/030] Train loss: 0.0887
2023-02-06 11:50:12 | Train | Epoch[066/600] Iteration[005/030] Train loss: 0.0887
2023-02-06 11:50:12 | Train | Epoch[066/600] Iteration[006/030] Train loss: 0.0890
2023-02-06 11:50:12 | Train | Epoch[066/600] Iteration[007/030] Train loss: 0.0885
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[008/030] Train loss: 0.0880
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[009/030] Train loss: 0.0877
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[010/030] Train loss: 0.0876
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[011/030] Train loss: 0.0872
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[012/030] Train loss: 0.0870
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[013/030] Train loss: 0.0869
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[014/030] Train loss: 0.0871
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[015/030] Train loss: 0.0871
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[016/030] Train loss: 0.0871
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[017/030] Train loss: 0.0871
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[018/030] Train loss: 0.0872
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[019/030] Train loss: 0.0871
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[020/030] Train loss: 0.0870
2023-02-06 11:50:13 | Train | Epoch[066/600] Iteration[021/030] Train loss: 0.0872
2023-02-06 11:50:14 | Train | Epoch[066/600] Iteration[022/030] Train loss: 0.0872
2023-02-06 11:50:14 | Train | Epoch[066/600] Iteration[023/030] Train loss: 0.0871
2023-02-06 11:50:14 | Train | Epoch[066/600] Iteration[024/030] Train loss: 0.0870
2023-02-06 11:50:14 | Train | Epoch[066/600] Iteration[025/030] Train loss: 0.0869
2023-02-06 11:50:14 | Train | Epoch[066/600] Iteration[026/030] Train loss: 0.0868
2023-02-06 11:50:14 | Train | Epoch[066/600] Iteration[027/030] Train loss: 0.0868
2023-02-06 11:50:14 | Train | Epoch[066/600] Iteration[028/030] Train loss: 0.0868
2023-02-06 11:50:14 | Train | Epoch[066/600] Iteration[029/030] Train loss: 0.0868
2023-02-06 11:50:14 | Train | Epoch[066/600] Iteration[030/030] Train loss: 0.0868
2023-02-06 11:50:14 | Valid | Epoch[066/600] Iteration[001/008] Valid loss: 0.1324
2023-02-06 11:50:15 | Valid | Epoch[066/600] Iteration[002/008] Valid loss: 0.1161
2023-02-06 11:50:15 | Valid | Epoch[066/600] Iteration[003/008] Valid loss: 0.1173
2023-02-06 11:50:15 | Valid | Epoch[066/600] Iteration[004/008] Valid loss: 0.1136
2023-02-06 11:50:15 | Valid | Epoch[066/600] Iteration[005/008] Valid loss: 0.1151
2023-02-06 11:50:15 | Valid | Epoch[066/600] Iteration[006/008] Valid loss: 0.1134
2023-02-06 11:50:15 | Valid | Epoch[066/600] Iteration[007/008] Valid loss: 0.1121
2023-02-06 11:50:15 | Valid | Epoch[066/600] Iteration[008/008] Valid loss: 0.1106
2023-02-06 11:50:15 | Valid | Epoch[066/600] MIou: 0.9136441604316727
2023-02-06 11:50:15 | Valid | Epoch[066/600] Pixel Accuracy: 0.9854024251302084
2023-02-06 11:50:15 | Valid | Epoch[066/600] Mean Pixel Accuracy: 0.9328326320153715
2023-02-06 11:50:15 | Stage | Epoch[066/600] Train loss:0.0868
2023-02-06 11:50:15 | Stage | Epoch[066/600] Valid loss:0.1106
2023-02-06 11:50:15 | Stage | Epoch[066/600] LR:0.01

2023-02-06 11:50:15 | Train | Epoch[067/600] Iteration[001/030] Train loss: 0.0849
2023-02-06 11:50:15 | Train | Epoch[067/600] Iteration[002/030] Train loss: 0.0850
2023-02-06 11:50:15 | Train | Epoch[067/600] Iteration[003/030] Train loss: 0.0851
2023-02-06 11:50:15 | Train | Epoch[067/600] Iteration[004/030] Train loss: 0.0849
2023-02-06 11:50:15 | Train | Epoch[067/600] Iteration[005/030] Train loss: 0.0850
2023-02-06 11:50:15 | Train | Epoch[067/600] Iteration[006/030] Train loss: 0.0851
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[007/030] Train loss: 0.0852
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[008/030] Train loss: 0.0855
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[009/030] Train loss: 0.0854
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[010/030] Train loss: 0.0856
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[011/030] Train loss: 0.0854
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[012/030] Train loss: 0.0853
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[013/030] Train loss: 0.0853
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[014/030] Train loss: 0.0855
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[015/030] Train loss: 0.0853
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[016/030] Train loss: 0.0852
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[017/030] Train loss: 0.0855
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[018/030] Train loss: 0.0854
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[019/030] Train loss: 0.0854
2023-02-06 11:50:16 | Train | Epoch[067/600] Iteration[020/030] Train loss: 0.0853
2023-02-06 11:50:17 | Train | Epoch[067/600] Iteration[021/030] Train loss: 0.0854
2023-02-06 11:50:17 | Train | Epoch[067/600] Iteration[022/030] Train loss: 0.0852
2023-02-06 11:50:17 | Train | Epoch[067/600] Iteration[023/030] Train loss: 0.0852
2023-02-06 11:50:17 | Train | Epoch[067/600] Iteration[024/030] Train loss: 0.0851
2023-02-06 11:50:17 | Train | Epoch[067/600] Iteration[025/030] Train loss: 0.0851
2023-02-06 11:50:17 | Train | Epoch[067/600] Iteration[026/030] Train loss: 0.0851
2023-02-06 11:50:17 | Train | Epoch[067/600] Iteration[027/030] Train loss: 0.0851
2023-02-06 11:50:17 | Train | Epoch[067/600] Iteration[028/030] Train loss: 0.0850
2023-02-06 11:50:17 | Train | Epoch[067/600] Iteration[029/030] Train loss: 0.0849
2023-02-06 11:50:17 | Train | Epoch[067/600] Iteration[030/030] Train loss: 0.0848
2023-02-06 11:50:17 | Valid | Epoch[067/600] Iteration[001/008] Valid loss: 0.1676
2023-02-06 11:50:18 | Valid | Epoch[067/600] Iteration[002/008] Valid loss: 0.1464
2023-02-06 11:50:18 | Valid | Epoch[067/600] Iteration[003/008] Valid loss: 0.1425
2023-02-06 11:50:18 | Valid | Epoch[067/600] Iteration[004/008] Valid loss: 0.1390
2023-02-06 11:50:18 | Valid | Epoch[067/600] Iteration[005/008] Valid loss: 0.1393
2023-02-06 11:50:18 | Valid | Epoch[067/600] Iteration[006/008] Valid loss: 0.1375
2023-02-06 11:50:18 | Valid | Epoch[067/600] Iteration[007/008] Valid loss: 0.1413
2023-02-06 11:50:18 | Valid | Epoch[067/600] Iteration[008/008] Valid loss: 0.1404
2023-02-06 11:50:18 | Valid | Epoch[067/600] MIou: 0.9182079404403196
2023-02-06 11:50:18 | Valid | Epoch[067/600] Pixel Accuracy: 0.9848213195800781
2023-02-06 11:50:18 | Valid | Epoch[067/600] Mean Pixel Accuracy: 0.9807008151132742
2023-02-06 11:50:18 | Stage | Epoch[067/600] Train loss:0.0848
2023-02-06 11:50:18 | Stage | Epoch[067/600] Valid loss:0.1404
2023-02-06 11:50:18 | Stage | Epoch[067/600] LR:0.01

2023-02-06 11:50:18 | Train | Epoch[068/600] Iteration[001/030] Train loss: 0.0844
2023-02-06 11:50:18 | Train | Epoch[068/600] Iteration[002/030] Train loss: 0.0840
2023-02-06 11:50:18 | Train | Epoch[068/600] Iteration[003/030] Train loss: 0.0833
2023-02-06 11:50:18 | Train | Epoch[068/600] Iteration[004/030] Train loss: 0.0832
2023-02-06 11:50:18 | Train | Epoch[068/600] Iteration[005/030] Train loss: 0.0831
2023-02-06 11:50:18 | Train | Epoch[068/600] Iteration[006/030] Train loss: 0.0836
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[007/030] Train loss: 0.0837
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[008/030] Train loss: 0.0835
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[009/030] Train loss: 0.0837
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[010/030] Train loss: 0.0836
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[011/030] Train loss: 0.0838
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[012/030] Train loss: 0.0839
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[013/030] Train loss: 0.0838
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[014/030] Train loss: 0.0836
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[015/030] Train loss: 0.0835
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[016/030] Train loss: 0.0834
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[017/030] Train loss: 0.0833
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[018/030] Train loss: 0.0834
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[019/030] Train loss: 0.0833
2023-02-06 11:50:19 | Train | Epoch[068/600] Iteration[020/030] Train loss: 0.0834
2023-02-06 11:50:20 | Train | Epoch[068/600] Iteration[021/030] Train loss: 0.0834
2023-02-06 11:50:20 | Train | Epoch[068/600] Iteration[022/030] Train loss: 0.0835
2023-02-06 11:50:20 | Train | Epoch[068/600] Iteration[023/030] Train loss: 0.0834
2023-02-06 11:50:20 | Train | Epoch[068/600] Iteration[024/030] Train loss: 0.0834
2023-02-06 11:50:20 | Train | Epoch[068/600] Iteration[025/030] Train loss: 0.0833
2023-02-06 11:50:20 | Train | Epoch[068/600] Iteration[026/030] Train loss: 0.0833
2023-02-06 11:50:20 | Train | Epoch[068/600] Iteration[027/030] Train loss: 0.0832
2023-02-06 11:50:20 | Train | Epoch[068/600] Iteration[028/030] Train loss: 0.0833
2023-02-06 11:50:20 | Train | Epoch[068/600] Iteration[029/030] Train loss: 0.0833
2023-02-06 11:50:20 | Train | Epoch[068/600] Iteration[030/030] Train loss: 0.0832
2023-02-06 11:50:21 | Valid | Epoch[068/600] Iteration[001/008] Valid loss: 0.2975
2023-02-06 11:50:21 | Valid | Epoch[068/600] Iteration[002/008] Valid loss: 0.2441
2023-02-06 11:50:21 | Valid | Epoch[068/600] Iteration[003/008] Valid loss: 0.2390
2023-02-06 11:50:21 | Valid | Epoch[068/600] Iteration[004/008] Valid loss: 0.2388
2023-02-06 11:50:21 | Valid | Epoch[068/600] Iteration[005/008] Valid loss: 0.2404
2023-02-06 11:50:21 | Valid | Epoch[068/600] Iteration[006/008] Valid loss: 0.2338
2023-02-06 11:50:21 | Valid | Epoch[068/600] Iteration[007/008] Valid loss: 0.2448
2023-02-06 11:50:21 | Valid | Epoch[068/600] Iteration[008/008] Valid loss: 0.2429
2023-02-06 11:50:21 | Valid | Epoch[068/600] MIou: 0.8869020216765566
2023-02-06 11:50:21 | Valid | Epoch[068/600] Pixel Accuracy: 0.9775543212890625
2023-02-06 11:50:21 | Valid | Epoch[068/600] Mean Pixel Accuracy: 0.9806630171460886
2023-02-06 11:50:21 | Stage | Epoch[068/600] Train loss:0.0832
2023-02-06 11:50:21 | Stage | Epoch[068/600] Valid loss:0.2429
2023-02-06 11:50:21 | Stage | Epoch[068/600] LR:0.01

2023-02-06 11:50:21 | Train | Epoch[069/600] Iteration[001/030] Train loss: 0.0817
2023-02-06 11:50:21 | Train | Epoch[069/600] Iteration[002/030] Train loss: 0.0817
2023-02-06 11:50:21 | Train | Epoch[069/600] Iteration[003/030] Train loss: 0.0814
2023-02-06 11:50:21 | Train | Epoch[069/600] Iteration[004/030] Train loss: 0.0833
2023-02-06 11:50:21 | Train | Epoch[069/600] Iteration[005/030] Train loss: 0.0836
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[006/030] Train loss: 0.0830
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[007/030] Train loss: 0.0829
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[008/030] Train loss: 0.0826
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[009/030] Train loss: 0.0828
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[010/030] Train loss: 0.0824
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[011/030] Train loss: 0.0824
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[012/030] Train loss: 0.0824
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[013/030] Train loss: 0.0823
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[014/030] Train loss: 0.0824
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[015/030] Train loss: 0.0824
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[016/030] Train loss: 0.0824
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[017/030] Train loss: 0.0823
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[018/030] Train loss: 0.0823
2023-02-06 11:50:22 | Train | Epoch[069/600] Iteration[019/030] Train loss: 0.0822
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[020/030] Train loss: 0.0822
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[021/030] Train loss: 0.0821
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[022/030] Train loss: 0.0821
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[023/030] Train loss: 0.0822
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[024/030] Train loss: 0.0821
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[025/030] Train loss: 0.0821
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[026/030] Train loss: 0.0821
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[027/030] Train loss: 0.0820
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[028/030] Train loss: 0.0819
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[029/030] Train loss: 0.0819
2023-02-06 11:50:23 | Train | Epoch[069/600] Iteration[030/030] Train loss: 0.0820
2023-02-06 11:50:24 | Valid | Epoch[069/600] Iteration[001/008] Valid loss: 0.0995
2023-02-06 11:50:24 | Valid | Epoch[069/600] Iteration[002/008] Valid loss: 0.0984
2023-02-06 11:50:24 | Valid | Epoch[069/600] Iteration[003/008] Valid loss: 0.0998
2023-02-06 11:50:24 | Valid | Epoch[069/600] Iteration[004/008] Valid loss: 0.0983
2023-02-06 11:50:24 | Valid | Epoch[069/600] Iteration[005/008] Valid loss: 0.0986
2023-02-06 11:50:24 | Valid | Epoch[069/600] Iteration[006/008] Valid loss: 0.0976
2023-02-06 11:50:24 | Valid | Epoch[069/600] Iteration[007/008] Valid loss: 0.0971
2023-02-06 11:50:24 | Valid | Epoch[069/600] Iteration[008/008] Valid loss: 0.0978
2023-02-06 11:50:24 | Valid | Epoch[069/600] MIou: 0.837975743603564
2023-02-06 11:50:24 | Valid | Epoch[069/600] Pixel Accuracy: 0.9732309977213541
2023-02-06 11:50:24 | Valid | Epoch[069/600] Mean Pixel Accuracy: 0.8532272740237236
2023-02-06 11:50:24 | Stage | Epoch[069/600] Train loss:0.0820
2023-02-06 11:50:24 | Stage | Epoch[069/600] Valid loss:0.0978
2023-02-06 11:50:24 | Stage | Epoch[069/600] LR:0.01

2023-02-06 11:50:24 | Train | Epoch[070/600] Iteration[001/030] Train loss: 0.0804
2023-02-06 11:50:24 | Train | Epoch[070/600] Iteration[002/030] Train loss: 0.0792
2023-02-06 11:50:24 | Train | Epoch[070/600] Iteration[003/030] Train loss: 0.0800
2023-02-06 11:50:24 | Train | Epoch[070/600] Iteration[004/030] Train loss: 0.0810
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[005/030] Train loss: 0.0807
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[006/030] Train loss: 0.0804
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[007/030] Train loss: 0.0802
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[008/030] Train loss: 0.0803
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[009/030] Train loss: 0.0805
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[010/030] Train loss: 0.0806
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[011/030] Train loss: 0.0805
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[012/030] Train loss: 0.0805
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[013/030] Train loss: 0.0807
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[014/030] Train loss: 0.0806
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[015/030] Train loss: 0.0806
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[016/030] Train loss: 0.0804
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[017/030] Train loss: 0.0807
2023-02-06 11:50:25 | Train | Epoch[070/600] Iteration[018/030] Train loss: 0.0807
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[019/030] Train loss: 0.0806
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[020/030] Train loss: 0.0804
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[021/030] Train loss: 0.0803
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[022/030] Train loss: 0.0803
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[023/030] Train loss: 0.0804
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[024/030] Train loss: 0.0804
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[025/030] Train loss: 0.0806
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[026/030] Train loss: 0.0806
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[027/030] Train loss: 0.0806
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[028/030] Train loss: 0.0805
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[029/030] Train loss: 0.0805
2023-02-06 11:50:26 | Train | Epoch[070/600] Iteration[030/030] Train loss: 0.0806
2023-02-06 11:50:27 | Valid | Epoch[070/600] Iteration[001/008] Valid loss: 0.9657
2023-02-06 11:50:27 | Valid | Epoch[070/600] Iteration[002/008] Valid loss: 0.8592
2023-02-06 11:50:27 | Valid | Epoch[070/600] Iteration[003/008] Valid loss: 0.8707
2023-02-06 11:50:27 | Valid | Epoch[070/600] Iteration[004/008] Valid loss: 0.8953
2023-02-06 11:50:27 | Valid | Epoch[070/600] Iteration[005/008] Valid loss: 0.9040
2023-02-06 11:50:27 | Valid | Epoch[070/600] Iteration[006/008] Valid loss: 0.8630
2023-02-06 11:50:27 | Valid | Epoch[070/600] Iteration[007/008] Valid loss: 0.9011
2023-02-06 11:50:27 | Valid | Epoch[070/600] Iteration[008/008] Valid loss: 0.9487
2023-02-06 11:50:27 | Valid | Epoch[070/600] MIou: 0.797487770579205
2023-02-06 11:50:27 | Valid | Epoch[070/600] Pixel Accuracy: 0.9514439900716146
2023-02-06 11:50:27 | Valid | Epoch[070/600] Mean Pixel Accuracy: 0.9692663252549154
2023-02-06 11:50:27 | Stage | Epoch[070/600] Train loss:0.0806
2023-02-06 11:50:27 | Stage | Epoch[070/600] Valid loss:0.9487
2023-02-06 11:50:27 | Stage | Epoch[070/600] LR:0.01

2023-02-06 11:50:27 | Train | Epoch[071/600] Iteration[001/030] Train loss: 0.0807
2023-02-06 11:50:27 | Train | Epoch[071/600] Iteration[002/030] Train loss: 0.0795
2023-02-06 11:50:27 | Train | Epoch[071/600] Iteration[003/030] Train loss: 0.0793
2023-02-06 11:50:27 | Train | Epoch[071/600] Iteration[004/030] Train loss: 0.0792
2023-02-06 11:50:27 | Train | Epoch[071/600] Iteration[005/030] Train loss: 0.0791
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[006/030] Train loss: 0.0792
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[007/030] Train loss: 0.0791
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[008/030] Train loss: 0.0791
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[009/030] Train loss: 0.0789
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[010/030] Train loss: 0.0791
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[011/030] Train loss: 0.0792
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[012/030] Train loss: 0.0791
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[013/030] Train loss: 0.0789
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[014/030] Train loss: 0.0791
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[015/030] Train loss: 0.0792
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[016/030] Train loss: 0.0791
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[017/030] Train loss: 0.0791
2023-02-06 11:50:28 | Train | Epoch[071/600] Iteration[018/030] Train loss: 0.0791
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[019/030] Train loss: 0.0791
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[020/030] Train loss: 0.0792
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[021/030] Train loss: 0.0791
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[022/030] Train loss: 0.0791
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[023/030] Train loss: 0.0790
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[024/030] Train loss: 0.0790
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[025/030] Train loss: 0.0790
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[026/030] Train loss: 0.0791
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[027/030] Train loss: 0.0791
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[028/030] Train loss: 0.0792
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[029/030] Train loss: 0.0793
2023-02-06 11:50:29 | Train | Epoch[071/600] Iteration[030/030] Train loss: 0.0794
2023-02-06 11:50:30 | Valid | Epoch[071/600] Iteration[001/008] Valid loss: 0.0944
2023-02-06 11:50:30 | Valid | Epoch[071/600] Iteration[002/008] Valid loss: 0.0889
2023-02-06 11:50:30 | Valid | Epoch[071/600] Iteration[003/008] Valid loss: 0.0880
2023-02-06 11:50:30 | Valid | Epoch[071/600] Iteration[004/008] Valid loss: 0.0862
2023-02-06 11:50:30 | Valid | Epoch[071/600] Iteration[005/008] Valid loss: 0.0859
2023-02-06 11:50:30 | Valid | Epoch[071/600] Iteration[006/008] Valid loss: 0.0857
2023-02-06 11:50:30 | Valid | Epoch[071/600] Iteration[007/008] Valid loss: 0.0862
2023-02-06 11:50:30 | Valid | Epoch[071/600] Iteration[008/008] Valid loss: 0.0860
2023-02-06 11:50:30 | Valid | Epoch[071/600] MIou: 0.9210101554912815
2023-02-06 11:50:30 | Valid | Epoch[071/600] Pixel Accuracy: 0.9867401123046875
2023-02-06 11:50:30 | Valid | Epoch[071/600] Mean Pixel Accuracy: 0.9367317772219712
2023-02-06 11:50:30 | Stage | Epoch[071/600] Train loss:0.0794
2023-02-06 11:50:30 | Stage | Epoch[071/600] Valid loss:0.0860
2023-02-06 11:50:30 | Stage | Epoch[071/600] LR:0.01

2023-02-06 11:50:30 | Train | Epoch[072/600] Iteration[001/030] Train loss: 0.0765
2023-02-06 11:50:30 | Train | Epoch[072/600] Iteration[002/030] Train loss: 0.0759
2023-02-06 11:50:30 | Train | Epoch[072/600] Iteration[003/030] Train loss: 0.0784
2023-02-06 11:50:30 | Train | Epoch[072/600] Iteration[004/030] Train loss: 0.0787
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[005/030] Train loss: 0.0779
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[006/030] Train loss: 0.0777
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[007/030] Train loss: 0.0776
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[008/030] Train loss: 0.0775
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[009/030] Train loss: 0.0776
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[010/030] Train loss: 0.0775
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[011/030] Train loss: 0.0777
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[012/030] Train loss: 0.0779
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[013/030] Train loss: 0.0780
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[014/030] Train loss: 0.0779
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[015/030] Train loss: 0.0780
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[016/030] Train loss: 0.0781
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[017/030] Train loss: 0.0780
2023-02-06 11:50:31 | Train | Epoch[072/600] Iteration[018/030] Train loss: 0.0778
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[019/030] Train loss: 0.0778
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[020/030] Train loss: 0.0777
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[021/030] Train loss: 0.0777
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[022/030] Train loss: 0.0776
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[023/030] Train loss: 0.0776
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[024/030] Train loss: 0.0776
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[025/030] Train loss: 0.0775
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[026/030] Train loss: 0.0776
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[027/030] Train loss: 0.0776
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[028/030] Train loss: 0.0776
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[029/030] Train loss: 0.0775
2023-02-06 11:50:32 | Train | Epoch[072/600] Iteration[030/030] Train loss: 0.0775
2023-02-06 11:50:33 | Valid | Epoch[072/600] Iteration[001/008] Valid loss: 0.0899
2023-02-06 11:50:33 | Valid | Epoch[072/600] Iteration[002/008] Valid loss: 0.0881
2023-02-06 11:50:33 | Valid | Epoch[072/600] Iteration[003/008] Valid loss: 0.0885
2023-02-06 11:50:33 | Valid | Epoch[072/600] Iteration[004/008] Valid loss: 0.0872
2023-02-06 11:50:33 | Valid | Epoch[072/600] Iteration[005/008] Valid loss: 0.0871
2023-02-06 11:50:33 | Valid | Epoch[072/600] Iteration[006/008] Valid loss: 0.0865
2023-02-06 11:50:33 | Valid | Epoch[072/600] Iteration[007/008] Valid loss: 0.0868
2023-02-06 11:50:33 | Valid | Epoch[072/600] Iteration[008/008] Valid loss: 0.0869
2023-02-06 11:50:33 | Valid | Epoch[072/600] MIou: 0.9061357982116874
2023-02-06 11:50:33 | Valid | Epoch[072/600] Pixel Accuracy: 0.9843826293945312
2023-02-06 11:50:33 | Valid | Epoch[072/600] Mean Pixel Accuracy: 0.9190395447400966
2023-02-06 11:50:33 | Stage | Epoch[072/600] Train loss:0.0775
2023-02-06 11:50:33 | Stage | Epoch[072/600] Valid loss:0.0869
2023-02-06 11:50:33 | Stage | Epoch[072/600] LR:0.01

2023-02-06 11:50:33 | Train | Epoch[073/600] Iteration[001/030] Train loss: 0.0758
2023-02-06 11:50:33 | Train | Epoch[073/600] Iteration[002/030] Train loss: 0.0761
2023-02-06 11:50:33 | Train | Epoch[073/600] Iteration[003/030] Train loss: 0.0754
2023-02-06 11:50:33 | Train | Epoch[073/600] Iteration[004/030] Train loss: 0.0762
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[005/030] Train loss: 0.0761
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[006/030] Train loss: 0.0764
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[007/030] Train loss: 0.0765
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[008/030] Train loss: 0.0768
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[009/030] Train loss: 0.0769
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[010/030] Train loss: 0.0768
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[011/030] Train loss: 0.0767
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[012/030] Train loss: 0.0770
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[013/030] Train loss: 0.0771
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[014/030] Train loss: 0.0772
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[015/030] Train loss: 0.0771
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[016/030] Train loss: 0.0770
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[017/030] Train loss: 0.0769
2023-02-06 11:50:34 | Train | Epoch[073/600] Iteration[018/030] Train loss: 0.0767
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[019/030] Train loss: 0.0767
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[020/030] Train loss: 0.0767
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[021/030] Train loss: 0.0771
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[022/030] Train loss: 0.0770
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[023/030] Train loss: 0.0769
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[024/030] Train loss: 0.0767
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[025/030] Train loss: 0.0767
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[026/030] Train loss: 0.0767
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[027/030] Train loss: 0.0767
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[028/030] Train loss: 0.0767
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[029/030] Train loss: 0.0766
2023-02-06 11:50:35 | Train | Epoch[073/600] Iteration[030/030] Train loss: 0.0766
2023-02-06 11:50:36 | Valid | Epoch[073/600] Iteration[001/008] Valid loss: 1.2514
2023-02-06 11:50:36 | Valid | Epoch[073/600] Iteration[002/008] Valid loss: 1.1927
2023-02-06 11:50:36 | Valid | Epoch[073/600] Iteration[003/008] Valid loss: 1.2485
2023-02-06 11:50:36 | Valid | Epoch[073/600] Iteration[004/008] Valid loss: 1.2830
2023-02-06 11:50:36 | Valid | Epoch[073/600] Iteration[005/008] Valid loss: 1.3103
2023-02-06 11:50:36 | Valid | Epoch[073/600] Iteration[006/008] Valid loss: 1.2720
2023-02-06 11:50:36 | Valid | Epoch[073/600] Iteration[007/008] Valid loss: 1.2922
2023-02-06 11:50:36 | Valid | Epoch[073/600] Iteration[008/008] Valid loss: 1.3383
2023-02-06 11:50:36 | Valid | Epoch[073/600] MIou: 0.7540467205724829
2023-02-06 11:50:36 | Valid | Epoch[073/600] Pixel Accuracy: 0.9372037251790365
2023-02-06 11:50:36 | Valid | Epoch[073/600] Mean Pixel Accuracy: 0.9418408708935071
2023-02-06 11:50:36 | Stage | Epoch[073/600] Train loss:0.0766
2023-02-06 11:50:36 | Stage | Epoch[073/600] Valid loss:1.3383
2023-02-06 11:50:36 | Stage | Epoch[073/600] LR:0.01

2023-02-06 11:50:36 | Train | Epoch[074/600] Iteration[001/030] Train loss: 0.0754
2023-02-06 11:50:36 | Train | Epoch[074/600] Iteration[002/030] Train loss: 0.0752
2023-02-06 11:50:36 | Train | Epoch[074/600] Iteration[003/030] Train loss: 0.0748
2023-02-06 11:50:36 | Train | Epoch[074/600] Iteration[004/030] Train loss: 0.0750
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[005/030] Train loss: 0.0751
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[006/030] Train loss: 0.0751
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[007/030] Train loss: 0.0749
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[008/030] Train loss: 0.0752
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[009/030] Train loss: 0.0754
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[010/030] Train loss: 0.0755
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[011/030] Train loss: 0.0761
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[012/030] Train loss: 0.0762
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[013/030] Train loss: 0.0759
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[014/030] Train loss: 0.0760
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[015/030] Train loss: 0.0758
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[016/030] Train loss: 0.0757
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[017/030] Train loss: 0.0759
2023-02-06 11:50:37 | Train | Epoch[074/600] Iteration[018/030] Train loss: 0.0759
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[019/030] Train loss: 0.0758
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[020/030] Train loss: 0.0757
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[021/030] Train loss: 0.0756
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[022/030] Train loss: 0.0756
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[023/030] Train loss: 0.0756
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[024/030] Train loss: 0.0756
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[025/030] Train loss: 0.0755
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[026/030] Train loss: 0.0755
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[027/030] Train loss: 0.0756
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[028/030] Train loss: 0.0755
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[029/030] Train loss: 0.0755
2023-02-06 11:50:38 | Train | Epoch[074/600] Iteration[030/030] Train loss: 0.0754
2023-02-06 11:50:39 | Valid | Epoch[074/600] Iteration[001/008] Valid loss: 0.1214
2023-02-06 11:50:39 | Valid | Epoch[074/600] Iteration[002/008] Valid loss: 0.1284
2023-02-06 11:50:39 | Valid | Epoch[074/600] Iteration[003/008] Valid loss: 0.1244
2023-02-06 11:50:39 | Valid | Epoch[074/600] Iteration[004/008] Valid loss: 0.1242
2023-02-06 11:50:39 | Valid | Epoch[074/600] Iteration[005/008] Valid loss: 0.1251
2023-02-06 11:50:39 | Valid | Epoch[074/600] Iteration[006/008] Valid loss: 0.1244
2023-02-06 11:50:39 | Valid | Epoch[074/600] Iteration[007/008] Valid loss: 0.1279
2023-02-06 11:50:39 | Valid | Epoch[074/600] Iteration[008/008] Valid loss: 0.1303
2023-02-06 11:50:39 | Valid | Epoch[074/600] MIou: 0.893214547172068
2023-02-06 11:50:39 | Valid | Epoch[074/600] Pixel Accuracy: 0.9804484049479166
2023-02-06 11:50:39 | Valid | Epoch[074/600] Mean Pixel Accuracy: 0.9484590157952923
2023-02-06 11:50:39 | Stage | Epoch[074/600] Train loss:0.0754
2023-02-06 11:50:39 | Stage | Epoch[074/600] Valid loss:0.1303
2023-02-06 11:50:39 | Stage | Epoch[074/600] LR:0.01

2023-02-06 11:50:39 | Train | Epoch[075/600] Iteration[001/030] Train loss: 0.0711
2023-02-06 11:50:39 | Train | Epoch[075/600] Iteration[002/030] Train loss: 0.0719
2023-02-06 11:50:39 | Train | Epoch[075/600] Iteration[003/030] Train loss: 0.0720
2023-02-06 11:50:39 | Train | Epoch[075/600] Iteration[004/030] Train loss: 0.0719
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[005/030] Train loss: 0.0720
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[006/030] Train loss: 0.0722
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[007/030] Train loss: 0.0727
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[008/030] Train loss: 0.0725
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[009/030] Train loss: 0.0730
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[010/030] Train loss: 0.0731
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[011/030] Train loss: 0.0731
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[012/030] Train loss: 0.0731
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[013/030] Train loss: 0.0735
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[014/030] Train loss: 0.0734
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[015/030] Train loss: 0.0733
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[016/030] Train loss: 0.0734
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[017/030] Train loss: 0.0733
2023-02-06 11:50:40 | Train | Epoch[075/600] Iteration[018/030] Train loss: 0.0733
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[019/030] Train loss: 0.0733
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[020/030] Train loss: 0.0736
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[021/030] Train loss: 0.0736
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[022/030] Train loss: 0.0736
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[023/030] Train loss: 0.0737
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[024/030] Train loss: 0.0737
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[025/030] Train loss: 0.0736
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[026/030] Train loss: 0.0737
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[027/030] Train loss: 0.0737
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[028/030] Train loss: 0.0736
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[029/030] Train loss: 0.0735
2023-02-06 11:50:41 | Train | Epoch[075/600] Iteration[030/030] Train loss: 0.0736
2023-02-06 11:50:42 | Valid | Epoch[075/600] Iteration[001/008] Valid loss: 0.2202
2023-02-06 11:50:42 | Valid | Epoch[075/600] Iteration[002/008] Valid loss: 0.2298
2023-02-06 11:50:42 | Valid | Epoch[075/600] Iteration[003/008] Valid loss: 0.2463
2023-02-06 11:50:42 | Valid | Epoch[075/600] Iteration[004/008] Valid loss: 0.2451
2023-02-06 11:50:42 | Valid | Epoch[075/600] Iteration[005/008] Valid loss: 0.2542
2023-02-06 11:50:42 | Valid | Epoch[075/600] Iteration[006/008] Valid loss: 0.2521
2023-02-06 11:50:42 | Valid | Epoch[075/600] Iteration[007/008] Valid loss: 0.2507
2023-02-06 11:50:42 | Valid | Epoch[075/600] Iteration[008/008] Valid loss: 0.2616
2023-02-06 11:50:42 | Valid | Epoch[075/600] MIou: 0.4581624518484703
2023-02-06 11:50:42 | Valid | Epoch[075/600] Pixel Accuracy: 0.9102363586425781
2023-02-06 11:50:42 | Valid | Epoch[075/600] Mean Pixel Accuracy: 0.5030691689310001
2023-02-06 11:50:42 | Stage | Epoch[075/600] Train loss:0.0736
2023-02-06 11:50:42 | Stage | Epoch[075/600] Valid loss:0.2616
2023-02-06 11:50:42 | Stage | Epoch[075/600] LR:0.01

2023-02-06 11:50:42 | Train | Epoch[076/600] Iteration[001/030] Train loss: 0.0714
2023-02-06 11:50:42 | Train | Epoch[076/600] Iteration[002/030] Train loss: 0.0716
2023-02-06 11:50:42 | Train | Epoch[076/600] Iteration[003/030] Train loss: 0.0721
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[004/030] Train loss: 0.0720
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[005/030] Train loss: 0.0727
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[006/030] Train loss: 0.0723
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[007/030] Train loss: 0.0723
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[008/030] Train loss: 0.0728
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[009/030] Train loss: 0.0727
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[010/030] Train loss: 0.0727
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[011/030] Train loss: 0.0724
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[012/030] Train loss: 0.0723
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[013/030] Train loss: 0.0724
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[014/030] Train loss: 0.0723
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[015/030] Train loss: 0.0722
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[016/030] Train loss: 0.0721
2023-02-06 11:50:43 | Train | Epoch[076/600] Iteration[017/030] Train loss: 0.0722
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[018/030] Train loss: 0.0725
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[019/030] Train loss: 0.0724
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[020/030] Train loss: 0.0725
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[021/030] Train loss: 0.0724
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[022/030] Train loss: 0.0723
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[023/030] Train loss: 0.0723
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[024/030] Train loss: 0.0722
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[025/030] Train loss: 0.0721
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[026/030] Train loss: 0.0722
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[027/030] Train loss: 0.0722
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[028/030] Train loss: 0.0723
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[029/030] Train loss: 0.0722
2023-02-06 11:50:44 | Train | Epoch[076/600] Iteration[030/030] Train loss: 0.0722
2023-02-06 11:50:45 | Valid | Epoch[076/600] Iteration[001/008] Valid loss: 0.2933
2023-02-06 11:50:45 | Valid | Epoch[076/600] Iteration[002/008] Valid loss: 0.2471
2023-02-06 11:50:45 | Valid | Epoch[076/600] Iteration[003/008] Valid loss: 0.2408
2023-02-06 11:50:45 | Valid | Epoch[076/600] Iteration[004/008] Valid loss: 0.2387
2023-02-06 11:50:45 | Valid | Epoch[076/600] Iteration[005/008] Valid loss: 0.2430
2023-02-06 11:50:45 | Valid | Epoch[076/600] Iteration[006/008] Valid loss: 0.2405
2023-02-06 11:50:45 | Valid | Epoch[076/600] Iteration[007/008] Valid loss: 0.2544
2023-02-06 11:50:45 | Valid | Epoch[076/600] Iteration[008/008] Valid loss: 0.2555
2023-02-06 11:50:45 | Valid | Epoch[076/600] MIou: 0.8773292247094373
2023-02-06 11:50:45 | Valid | Epoch[076/600] Pixel Accuracy: 0.9750773111979166
2023-02-06 11:50:45 | Valid | Epoch[076/600] Mean Pixel Accuracy: 0.9818060330053412
2023-02-06 11:50:45 | Stage | Epoch[076/600] Train loss:0.0722
2023-02-06 11:50:45 | Stage | Epoch[076/600] Valid loss:0.2555
2023-02-06 11:50:45 | Stage | Epoch[076/600] LR:0.01

2023-02-06 11:50:45 | Train | Epoch[077/600] Iteration[001/030] Train loss: 0.0715
2023-02-06 11:50:45 | Train | Epoch[077/600] Iteration[002/030] Train loss: 0.0717
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[003/030] Train loss: 0.0713
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[004/030] Train loss: 0.0710
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[005/030] Train loss: 0.0714
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[006/030] Train loss: 0.0711
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[007/030] Train loss: 0.0708
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[008/030] Train loss: 0.0706
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[009/030] Train loss: 0.0709
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[010/030] Train loss: 0.0709
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[011/030] Train loss: 0.0709
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[012/030] Train loss: 0.0707
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[013/030] Train loss: 0.0707
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[014/030] Train loss: 0.0709
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[015/030] Train loss: 0.0710
2023-02-06 11:50:46 | Train | Epoch[077/600] Iteration[016/030] Train loss: 0.0710
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[017/030] Train loss: 0.0709
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[018/030] Train loss: 0.0709
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[019/030] Train loss: 0.0709
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[020/030] Train loss: 0.0709
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[021/030] Train loss: 0.0710
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[022/030] Train loss: 0.0710
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[023/030] Train loss: 0.0709
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[024/030] Train loss: 0.0709
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[025/030] Train loss: 0.0708
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[026/030] Train loss: 0.0708
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[027/030] Train loss: 0.0707
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[028/030] Train loss: 0.0708
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[029/030] Train loss: 0.0709
2023-02-06 11:50:47 | Train | Epoch[077/600] Iteration[030/030] Train loss: 0.0708
2023-02-06 11:50:48 | Valid | Epoch[077/600] Iteration[001/008] Valid loss: 0.0996
2023-02-06 11:50:48 | Valid | Epoch[077/600] Iteration[002/008] Valid loss: 0.0931
2023-02-06 11:50:48 | Valid | Epoch[077/600] Iteration[003/008] Valid loss: 0.0955
2023-02-06 11:50:48 | Valid | Epoch[077/600] Iteration[004/008] Valid loss: 0.0926
2023-02-06 11:50:48 | Valid | Epoch[077/600] Iteration[005/008] Valid loss: 0.0927
2023-02-06 11:50:48 | Valid | Epoch[077/600] Iteration[006/008] Valid loss: 0.0920
2023-02-06 11:50:48 | Valid | Epoch[077/600] Iteration[007/008] Valid loss: 0.0929
2023-02-06 11:50:48 | Valid | Epoch[077/600] Iteration[008/008] Valid loss: 0.0920
2023-02-06 11:50:48 | Valid | Epoch[077/600] MIou: 0.9251346890285117
2023-02-06 11:50:48 | Valid | Epoch[077/600] Pixel Accuracy: 0.987219492594401
2023-02-06 11:50:48 | Valid | Epoch[077/600] Mean Pixel Accuracy: 0.9481037711634366
2023-02-06 11:50:48 | Stage | Epoch[077/600] Train loss:0.0708
2023-02-06 11:50:48 | Stage | Epoch[077/600] Valid loss:0.0920
2023-02-06 11:50:48 | Stage | Epoch[077/600] LR:0.01

2023-02-06 11:50:48 | Train | Epoch[078/600] Iteration[001/030] Train loss: 0.0694
2023-02-06 11:50:48 | Train | Epoch[078/600] Iteration[002/030] Train loss: 0.0684
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[003/030] Train loss: 0.0690
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[004/030] Train loss: 0.0692
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[005/030] Train loss: 0.0694
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[006/030] Train loss: 0.0699
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[007/030] Train loss: 0.0698
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[008/030] Train loss: 0.0696
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[009/030] Train loss: 0.0698
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[010/030] Train loss: 0.0698
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[011/030] Train loss: 0.0696
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[012/030] Train loss: 0.0696
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[013/030] Train loss: 0.0695
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[014/030] Train loss: 0.0695
2023-02-06 11:50:49 | Train | Epoch[078/600] Iteration[015/030] Train loss: 0.0694
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[016/030] Train loss: 0.0695
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[017/030] Train loss: 0.0694
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[018/030] Train loss: 0.0693
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[019/030] Train loss: 0.0693
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[020/030] Train loss: 0.0693
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[021/030] Train loss: 0.0692
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[022/030] Train loss: 0.0693
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[023/030] Train loss: 0.0694
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[024/030] Train loss: 0.0696
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[025/030] Train loss: 0.0696
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[026/030] Train loss: 0.0697
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[027/030] Train loss: 0.0697
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[028/030] Train loss: 0.0698
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[029/030] Train loss: 0.0698
2023-02-06 11:50:50 | Train | Epoch[078/600] Iteration[030/030] Train loss: 0.0697
2023-02-06 11:50:51 | Valid | Epoch[078/600] Iteration[001/008] Valid loss: 0.1152
2023-02-06 11:50:51 | Valid | Epoch[078/600] Iteration[002/008] Valid loss: 0.1207
2023-02-06 11:50:51 | Valid | Epoch[078/600] Iteration[003/008] Valid loss: 0.1257
2023-02-06 11:50:51 | Valid | Epoch[078/600] Iteration[004/008] Valid loss: 0.1231
2023-02-06 11:50:51 | Valid | Epoch[078/600] Iteration[005/008] Valid loss: 0.1252
2023-02-06 11:50:51 | Valid | Epoch[078/600] Iteration[006/008] Valid loss: 0.1253
2023-02-06 11:50:51 | Valid | Epoch[078/600] Iteration[007/008] Valid loss: 0.1250
2023-02-06 11:50:51 | Valid | Epoch[078/600] Iteration[008/008] Valid loss: 0.1291
2023-02-06 11:50:51 | Valid | Epoch[078/600] MIou: 0.7033454805406917
2023-02-06 11:50:51 | Valid | Epoch[078/600] Pixel Accuracy: 0.950225830078125
2023-02-06 11:50:51 | Valid | Epoch[078/600] Mean Pixel Accuracy: 0.7325663800605435
2023-02-06 11:50:51 | Stage | Epoch[078/600] Train loss:0.0697
2023-02-06 11:50:51 | Stage | Epoch[078/600] Valid loss:0.1291
2023-02-06 11:50:51 | Stage | Epoch[078/600] LR:0.01

2023-02-06 11:50:51 | Train | Epoch[079/600] Iteration[001/030] Train loss: 0.0685
2023-02-06 11:50:51 | Train | Epoch[079/600] Iteration[002/030] Train loss: 0.0683
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[003/030] Train loss: 0.0677
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[004/030] Train loss: 0.0677
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[005/030] Train loss: 0.0687
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[006/030] Train loss: 0.0684
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[007/030] Train loss: 0.0683
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[008/030] Train loss: 0.0683
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[009/030] Train loss: 0.0686
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[010/030] Train loss: 0.0686
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[011/030] Train loss: 0.0684
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[012/030] Train loss: 0.0685
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[013/030] Train loss: 0.0686
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[014/030] Train loss: 0.0686
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[015/030] Train loss: 0.0686
2023-02-06 11:50:52 | Train | Epoch[079/600] Iteration[016/030] Train loss: 0.0684
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[017/030] Train loss: 0.0683
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[018/030] Train loss: 0.0683
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[019/030] Train loss: 0.0683
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[020/030] Train loss: 0.0683
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[021/030] Train loss: 0.0682
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[022/030] Train loss: 0.0683
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[023/030] Train loss: 0.0682
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[024/030] Train loss: 0.0682
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[025/030] Train loss: 0.0682
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[026/030] Train loss: 0.0681
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[027/030] Train loss: 0.0681
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[028/030] Train loss: 0.0680
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[029/030] Train loss: 0.0681
2023-02-06 11:50:53 | Train | Epoch[079/600] Iteration[030/030] Train loss: 0.0680
2023-02-06 11:50:54 | Valid | Epoch[079/600] Iteration[001/008] Valid loss: 0.1734
2023-02-06 11:50:54 | Valid | Epoch[079/600] Iteration[002/008] Valid loss: 0.1443
2023-02-06 11:50:54 | Valid | Epoch[079/600] Iteration[003/008] Valid loss: 0.1373
2023-02-06 11:50:54 | Valid | Epoch[079/600] Iteration[004/008] Valid loss: 0.1357
2023-02-06 11:50:54 | Valid | Epoch[079/600] Iteration[005/008] Valid loss: 0.1363
2023-02-06 11:50:54 | Valid | Epoch[079/600] Iteration[006/008] Valid loss: 0.1320
2023-02-06 11:50:54 | Valid | Epoch[079/600] Iteration[007/008] Valid loss: 0.1369
2023-02-06 11:50:54 | Valid | Epoch[079/600] Iteration[008/008] Valid loss: 0.1366
2023-02-06 11:50:54 | Valid | Epoch[079/600] MIou: 0.9156861022545494
2023-02-06 11:50:54 | Valid | Epoch[079/600] Pixel Accuracy: 0.9843737284342448
2023-02-06 11:50:54 | Valid | Epoch[079/600] Mean Pixel Accuracy: 0.9774367354904735
2023-02-06 11:50:54 | Stage | Epoch[079/600] Train loss:0.0680
2023-02-06 11:50:54 | Stage | Epoch[079/600] Valid loss:0.1366
2023-02-06 11:50:54 | Stage | Epoch[079/600] LR:0.01

2023-02-06 11:50:54 | Train | Epoch[080/600] Iteration[001/030] Train loss: 0.0656
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[002/030] Train loss: 0.0661
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[003/030] Train loss: 0.0676
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[004/030] Train loss: 0.0671
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[005/030] Train loss: 0.0675
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[006/030] Train loss: 0.0677
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[007/030] Train loss: 0.0676
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[008/030] Train loss: 0.0674
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[009/030] Train loss: 0.0673
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[010/030] Train loss: 0.0670
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[011/030] Train loss: 0.0668
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[012/030] Train loss: 0.0669
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[013/030] Train loss: 0.0669
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[014/030] Train loss: 0.0671
2023-02-06 11:50:55 | Train | Epoch[080/600] Iteration[015/030] Train loss: 0.0669
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[016/030] Train loss: 0.0670
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[017/030] Train loss: 0.0670
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[018/030] Train loss: 0.0670
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[019/030] Train loss: 0.0671
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[020/030] Train loss: 0.0671
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[021/030] Train loss: 0.0671
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[022/030] Train loss: 0.0673
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[023/030] Train loss: 0.0673
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[024/030] Train loss: 0.0672
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[025/030] Train loss: 0.0673
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[026/030] Train loss: 0.0674
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[027/030] Train loss: 0.0675
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[028/030] Train loss: 0.0675
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[029/030] Train loss: 0.0674
2023-02-06 11:50:56 | Train | Epoch[080/600] Iteration[030/030] Train loss: 0.0675
2023-02-06 11:50:57 | Valid | Epoch[080/600] Iteration[001/008] Valid loss: 0.1767
2023-02-06 11:50:57 | Valid | Epoch[080/600] Iteration[002/008] Valid loss: 0.1484
2023-02-06 11:50:57 | Valid | Epoch[080/600] Iteration[003/008] Valid loss: 0.1475
2023-02-06 11:50:57 | Valid | Epoch[080/600] Iteration[004/008] Valid loss: 0.1407
2023-02-06 11:50:57 | Valid | Epoch[080/600] Iteration[005/008] Valid loss: 0.1420
2023-02-06 11:50:57 | Valid | Epoch[080/600] Iteration[006/008] Valid loss: 0.1392
2023-02-06 11:50:57 | Valid | Epoch[080/600] Iteration[007/008] Valid loss: 0.1385
2023-02-06 11:50:57 | Valid | Epoch[080/600] Iteration[008/008] Valid loss: 0.1367
2023-02-06 11:50:57 | Valid | Epoch[080/600] MIou: 0.8450307332004844
2023-02-06 11:50:57 | Valid | Epoch[080/600] Pixel Accuracy: 0.9729779561360677
2023-02-06 11:50:57 | Valid | Epoch[080/600] Mean Pixel Accuracy: 0.8797118314557106
2023-02-06 11:50:57 | Stage | Epoch[080/600] Train loss:0.0675
2023-02-06 11:50:57 | Stage | Epoch[080/600] Valid loss:0.1367
2023-02-06 11:50:57 | Stage | Epoch[080/600] LR:0.01

2023-02-06 11:50:57 | Train | Epoch[081/600] Iteration[001/030] Train loss: 0.0648
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[002/030] Train loss: 0.0656
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[003/030] Train loss: 0.0653
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[004/030] Train loss: 0.0661
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[005/030] Train loss: 0.0663
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[006/030] Train loss: 0.0661
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[007/030] Train loss: 0.0663
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[008/030] Train loss: 0.0665
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[009/030] Train loss: 0.0667
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[010/030] Train loss: 0.0666
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[011/030] Train loss: 0.0665
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[012/030] Train loss: 0.0666
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[013/030] Train loss: 0.0664
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[014/030] Train loss: 0.0664
2023-02-06 11:50:58 | Train | Epoch[081/600] Iteration[015/030] Train loss: 0.0666
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[016/030] Train loss: 0.0667
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[017/030] Train loss: 0.0666
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[018/030] Train loss: 0.0669
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[019/030] Train loss: 0.0669
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[020/030] Train loss: 0.0668
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[021/030] Train loss: 0.0668
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[022/030] Train loss: 0.0667
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[023/030] Train loss: 0.0668
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[024/030] Train loss: 0.0667
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[025/030] Train loss: 0.0667
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[026/030] Train loss: 0.0666
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[027/030] Train loss: 0.0665
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[028/030] Train loss: 0.0664
2023-02-06 11:50:59 | Train | Epoch[081/600] Iteration[029/030] Train loss: 0.0664
2023-02-06 11:51:00 | Train | Epoch[081/600] Iteration[030/030] Train loss: 0.0664
2023-02-06 11:51:00 | Valid | Epoch[081/600] Iteration[001/008] Valid loss: 0.6974
2023-02-06 11:51:00 | Valid | Epoch[081/600] Iteration[002/008] Valid loss: 0.6568
2023-02-06 11:51:00 | Valid | Epoch[081/600] Iteration[003/008] Valid loss: 0.6521
2023-02-06 11:51:00 | Valid | Epoch[081/600] Iteration[004/008] Valid loss: 0.6537
2023-02-06 11:51:00 | Valid | Epoch[081/600] Iteration[005/008] Valid loss: 0.6747
2023-02-06 11:51:00 | Valid | Epoch[081/600] Iteration[006/008] Valid loss: 0.6578
2023-02-06 11:51:00 | Valid | Epoch[081/600] Iteration[007/008] Valid loss: 0.6970
2023-02-06 11:51:00 | Valid | Epoch[081/600] Iteration[008/008] Valid loss: 0.7225
2023-02-06 11:51:00 | Valid | Epoch[081/600] MIou: 0.8379470522735732
2023-02-06 11:51:00 | Valid | Epoch[081/600] Pixel Accuracy: 0.9642473856608073
2023-02-06 11:51:00 | Valid | Epoch[081/600] Mean Pixel Accuracy: 0.9776224355968632
2023-02-06 11:51:00 | Stage | Epoch[081/600] Train loss:0.0664
2023-02-06 11:51:00 | Stage | Epoch[081/600] Valid loss:0.7225
2023-02-06 11:51:00 | Stage | Epoch[081/600] LR:0.01

2023-02-06 11:51:00 | Train | Epoch[082/600] Iteration[001/030] Train loss: 0.0640
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[002/030] Train loss: 0.0644
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[003/030] Train loss: 0.0651
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[004/030] Train loss: 0.0648
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[005/030] Train loss: 0.0650
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[006/030] Train loss: 0.0650
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[007/030] Train loss: 0.0651
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[008/030] Train loss: 0.0656
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[009/030] Train loss: 0.0654
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[010/030] Train loss: 0.0652
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[011/030] Train loss: 0.0651
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[012/030] Train loss: 0.0652
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[013/030] Train loss: 0.0654
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[014/030] Train loss: 0.0654
2023-02-06 11:51:01 | Train | Epoch[082/600] Iteration[015/030] Train loss: 0.0654
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[016/030] Train loss: 0.0653
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[017/030] Train loss: 0.0653
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[018/030] Train loss: 0.0653
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[019/030] Train loss: 0.0654
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[020/030] Train loss: 0.0653
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[021/030] Train loss: 0.0653
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[022/030] Train loss: 0.0653
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[023/030] Train loss: 0.0654
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[024/030] Train loss: 0.0653
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[025/030] Train loss: 0.0652
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[026/030] Train loss: 0.0651
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[027/030] Train loss: 0.0651
2023-02-06 11:51:02 | Train | Epoch[082/600] Iteration[028/030] Train loss: 0.0652
2023-02-06 11:51:03 | Train | Epoch[082/600] Iteration[029/030] Train loss: 0.0652
2023-02-06 11:51:03 | Train | Epoch[082/600] Iteration[030/030] Train loss: 0.0652
2023-02-06 11:51:03 | Valid | Epoch[082/600] Iteration[001/008] Valid loss: 0.5023
2023-02-06 11:51:03 | Valid | Epoch[082/600] Iteration[002/008] Valid loss: 0.4531
2023-02-06 11:51:03 | Valid | Epoch[082/600] Iteration[003/008] Valid loss: 0.4396
2023-02-06 11:51:03 | Valid | Epoch[082/600] Iteration[004/008] Valid loss: 0.4467
2023-02-06 11:51:03 | Valid | Epoch[082/600] Iteration[005/008] Valid loss: 0.4532
2023-02-06 11:51:03 | Valid | Epoch[082/600] Iteration[006/008] Valid loss: 0.4392
2023-02-06 11:51:03 | Valid | Epoch[082/600] Iteration[007/008] Valid loss: 0.4658
2023-02-06 11:51:03 | Valid | Epoch[082/600] Iteration[008/008] Valid loss: 0.4716
2023-02-06 11:51:03 | Valid | Epoch[082/600] MIou: 0.8523348102830266
2023-02-06 11:51:03 | Valid | Epoch[082/600] Pixel Accuracy: 0.9684778849283854
2023-02-06 11:51:03 | Valid | Epoch[082/600] Mean Pixel Accuracy: 0.9780201950810818
2023-02-06 11:51:03 | Stage | Epoch[082/600] Train loss:0.0652
2023-02-06 11:51:03 | Stage | Epoch[082/600] Valid loss:0.4716
2023-02-06 11:51:03 | Stage | Epoch[082/600] LR:0.01

2023-02-06 11:51:03 | Train | Epoch[083/600] Iteration[001/030] Train loss: 0.0675
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[002/030] Train loss: 0.0656
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[003/030] Train loss: 0.0649
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[004/030] Train loss: 0.0650
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[005/030] Train loss: 0.0651
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[006/030] Train loss: 0.0648
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[007/030] Train loss: 0.0649
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[008/030] Train loss: 0.0647
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[009/030] Train loss: 0.0648
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[010/030] Train loss: 0.0648
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[011/030] Train loss: 0.0645
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[012/030] Train loss: 0.0645
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[013/030] Train loss: 0.0642
2023-02-06 11:51:04 | Train | Epoch[083/600] Iteration[014/030] Train loss: 0.0642
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[015/030] Train loss: 0.0642
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[016/030] Train loss: 0.0641
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[017/030] Train loss: 0.0640
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[018/030] Train loss: 0.0639
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[019/030] Train loss: 0.0640
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[020/030] Train loss: 0.0641
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[021/030] Train loss: 0.0639
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[022/030] Train loss: 0.0640
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[023/030] Train loss: 0.0639
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[024/030] Train loss: 0.0639
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[025/030] Train loss: 0.0639
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[026/030] Train loss: 0.0640
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[027/030] Train loss: 0.0640
2023-02-06 11:51:05 | Train | Epoch[083/600] Iteration[028/030] Train loss: 0.0641
2023-02-06 11:51:06 | Train | Epoch[083/600] Iteration[029/030] Train loss: 0.0641
2023-02-06 11:51:06 | Train | Epoch[083/600] Iteration[030/030] Train loss: 0.0642
2023-02-06 11:51:06 | Valid | Epoch[083/600] Iteration[001/008] Valid loss: 0.0928
2023-02-06 11:51:06 | Valid | Epoch[083/600] Iteration[002/008] Valid loss: 0.0865
2023-02-06 11:51:06 | Valid | Epoch[083/600] Iteration[003/008] Valid loss: 0.0855
2023-02-06 11:51:06 | Valid | Epoch[083/600] Iteration[004/008] Valid loss: 0.0844
2023-02-06 11:51:06 | Valid | Epoch[083/600] Iteration[005/008] Valid loss: 0.0858
2023-02-06 11:51:06 | Valid | Epoch[083/600] Iteration[006/008] Valid loss: 0.0844
2023-02-06 11:51:06 | Valid | Epoch[083/600] Iteration[007/008] Valid loss: 0.0866
2023-02-06 11:51:06 | Valid | Epoch[083/600] Iteration[008/008] Valid loss: 0.0866
2023-02-06 11:51:06 | Valid | Epoch[083/600] MIou: 0.9215790971444611
2023-02-06 11:51:06 | Valid | Epoch[083/600] Pixel Accuracy: 0.9863611857096354
2023-02-06 11:51:06 | Valid | Epoch[083/600] Mean Pixel Accuracy: 0.9531418788376633
2023-02-06 11:51:06 | Stage | Epoch[083/600] Train loss:0.0642
2023-02-06 11:51:06 | Stage | Epoch[083/600] Valid loss:0.0866
2023-02-06 11:51:06 | Stage | Epoch[083/600] LR:0.01

2023-02-06 11:51:06 | Train | Epoch[084/600] Iteration[001/030] Train loss: 0.0633
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[002/030] Train loss: 0.0629
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[003/030] Train loss: 0.0627
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[004/030] Train loss: 0.0621
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[005/030] Train loss: 0.0621
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[006/030] Train loss: 0.0628
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[007/030] Train loss: 0.0626
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[008/030] Train loss: 0.0624
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[009/030] Train loss: 0.0624
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[010/030] Train loss: 0.0628
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[011/030] Train loss: 0.0629
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[012/030] Train loss: 0.0633
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[013/030] Train loss: 0.0633
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[014/030] Train loss: 0.0631
2023-02-06 11:51:07 | Train | Epoch[084/600] Iteration[015/030] Train loss: 0.0631
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[016/030] Train loss: 0.0631
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[017/030] Train loss: 0.0632
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[018/030] Train loss: 0.0636
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[019/030] Train loss: 0.0635
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[020/030] Train loss: 0.0634
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[021/030] Train loss: 0.0634
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[022/030] Train loss: 0.0633
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[023/030] Train loss: 0.0631
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[024/030] Train loss: 0.0632
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[025/030] Train loss: 0.0631
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[026/030] Train loss: 0.0632
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[027/030] Train loss: 0.0632
2023-02-06 11:51:08 | Train | Epoch[084/600] Iteration[028/030] Train loss: 0.0633
2023-02-06 11:51:09 | Train | Epoch[084/600] Iteration[029/030] Train loss: 0.0634
2023-02-06 11:51:09 | Train | Epoch[084/600] Iteration[030/030] Train loss: 0.0634
2023-02-06 11:51:09 | Valid | Epoch[084/600] Iteration[001/008] Valid loss: 0.0915
2023-02-06 11:51:09 | Valid | Epoch[084/600] Iteration[002/008] Valid loss: 0.0939
2023-02-06 11:51:09 | Valid | Epoch[084/600] Iteration[003/008] Valid loss: 0.0961
2023-02-06 11:51:09 | Valid | Epoch[084/600] Iteration[004/008] Valid loss: 0.0952
2023-02-06 11:51:09 | Valid | Epoch[084/600] Iteration[005/008] Valid loss: 0.0955
2023-02-06 11:51:09 | Valid | Epoch[084/600] Iteration[006/008] Valid loss: 0.0944
2023-02-06 11:51:09 | Valid | Epoch[084/600] Iteration[007/008] Valid loss: 0.0938
2023-02-06 11:51:09 | Valid | Epoch[084/600] Iteration[008/008] Valid loss: 0.0949
2023-02-06 11:51:09 | Valid | Epoch[084/600] MIou: 0.7767246817032651
2023-02-06 11:51:09 | Valid | Epoch[084/600] Pixel Accuracy: 0.9631525675455729
2023-02-06 11:51:09 | Valid | Epoch[084/600] Mean Pixel Accuracy: 0.7964060053747617
2023-02-06 11:51:09 | Stage | Epoch[084/600] Train loss:0.0634
2023-02-06 11:51:09 | Stage | Epoch[084/600] Valid loss:0.0949
2023-02-06 11:51:09 | Stage | Epoch[084/600] LR:0.01

2023-02-06 11:51:09 | Train | Epoch[085/600] Iteration[001/030] Train loss: 0.0623
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[002/030] Train loss: 0.0611
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[003/030] Train loss: 0.0609
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[004/030] Train loss: 0.0611
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[005/030] Train loss: 0.0609
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[006/030] Train loss: 0.0608
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[007/030] Train loss: 0.0609
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[008/030] Train loss: 0.0610
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[009/030] Train loss: 0.0612
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[010/030] Train loss: 0.0614
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[011/030] Train loss: 0.0616
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[012/030] Train loss: 0.0618
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[013/030] Train loss: 0.0618
2023-02-06 11:51:10 | Train | Epoch[085/600] Iteration[014/030] Train loss: 0.0619
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[015/030] Train loss: 0.0620
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[016/030] Train loss: 0.0620
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[017/030] Train loss: 0.0620
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[018/030] Train loss: 0.0620
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[019/030] Train loss: 0.0620
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[020/030] Train loss: 0.0619
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[021/030] Train loss: 0.0619
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[022/030] Train loss: 0.0619
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[023/030] Train loss: 0.0619
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[024/030] Train loss: 0.0618
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[025/030] Train loss: 0.0619
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[026/030] Train loss: 0.0619
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[027/030] Train loss: 0.0619
2023-02-06 11:51:11 | Train | Epoch[085/600] Iteration[028/030] Train loss: 0.0618
2023-02-06 11:51:12 | Train | Epoch[085/600] Iteration[029/030] Train loss: 0.0617
2023-02-06 11:51:12 | Train | Epoch[085/600] Iteration[030/030] Train loss: 0.0618
2023-02-06 11:51:12 | Valid | Epoch[085/600] Iteration[001/008] Valid loss: 0.1029
2023-02-06 11:51:12 | Valid | Epoch[085/600] Iteration[002/008] Valid loss: 0.0883
2023-02-06 11:51:12 | Valid | Epoch[085/600] Iteration[003/008] Valid loss: 0.0877
2023-02-06 11:51:12 | Valid | Epoch[085/600] Iteration[004/008] Valid loss: 0.0843
2023-02-06 11:51:12 | Valid | Epoch[085/600] Iteration[005/008] Valid loss: 0.0841
2023-02-06 11:51:12 | Valid | Epoch[085/600] Iteration[006/008] Valid loss: 0.0836
2023-02-06 11:51:12 | Valid | Epoch[085/600] Iteration[007/008] Valid loss: 0.0841
2023-02-06 11:51:12 | Valid | Epoch[085/600] Iteration[008/008] Valid loss: 0.0831
2023-02-06 11:51:12 | Valid | Epoch[085/600] MIou: 0.9342954938705544
2023-02-06 11:51:12 | Valid | Epoch[085/600] Pixel Accuracy: 0.9887720743815104
2023-02-06 11:51:12 | Valid | Epoch[085/600] Mean Pixel Accuracy: 0.9573075373110527
2023-02-06 11:51:12 | Stage | Epoch[085/600] Train loss:0.0618
2023-02-06 11:51:12 | Stage | Epoch[085/600] Valid loss:0.0831
2023-02-06 11:51:12 | Stage | Epoch[085/600] LR:0.01

2023-02-06 11:51:12 | Train | Epoch[086/600] Iteration[001/030] Train loss: 0.0598
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[002/030] Train loss: 0.0606
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[003/030] Train loss: 0.0620
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[004/030] Train loss: 0.0617
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[005/030] Train loss: 0.0617
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[006/030] Train loss: 0.0613
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[007/030] Train loss: 0.0612
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[008/030] Train loss: 0.0613
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[009/030] Train loss: 0.0617
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[010/030] Train loss: 0.0615
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[011/030] Train loss: 0.0613
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[012/030] Train loss: 0.0614
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[013/030] Train loss: 0.0613
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[014/030] Train loss: 0.0614
2023-02-06 11:51:13 | Train | Epoch[086/600] Iteration[015/030] Train loss: 0.0614
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[016/030] Train loss: 0.0615
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[017/030] Train loss: 0.0615
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[018/030] Train loss: 0.0615
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[019/030] Train loss: 0.0615
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[020/030] Train loss: 0.0615
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[021/030] Train loss: 0.0615
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[022/030] Train loss: 0.0615
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[023/030] Train loss: 0.0617
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[024/030] Train loss: 0.0618
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[025/030] Train loss: 0.0617
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[026/030] Train loss: 0.0617
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[027/030] Train loss: 0.0617
2023-02-06 11:51:14 | Train | Epoch[086/600] Iteration[028/030] Train loss: 0.0616
2023-02-06 11:51:15 | Train | Epoch[086/600] Iteration[029/030] Train loss: 0.0618
2023-02-06 11:51:15 | Train | Epoch[086/600] Iteration[030/030] Train loss: 0.0617
2023-02-06 11:51:15 | Valid | Epoch[086/600] Iteration[001/008] Valid loss: 4.9913
2023-02-06 11:51:15 | Valid | Epoch[086/600] Iteration[002/008] Valid loss: 4.9257
2023-02-06 11:51:15 | Valid | Epoch[086/600] Iteration[003/008] Valid loss: 5.1172
2023-02-06 11:51:15 | Valid | Epoch[086/600] Iteration[004/008] Valid loss: 5.2666
2023-02-06 11:51:15 | Valid | Epoch[086/600] Iteration[005/008] Valid loss: 5.3285
2023-02-06 11:51:15 | Valid | Epoch[086/600] Iteration[006/008] Valid loss: 5.1998
2023-02-06 11:51:15 | Valid | Epoch[086/600] Iteration[007/008] Valid loss: 5.2654
2023-02-06 11:51:15 | Valid | Epoch[086/600] Iteration[008/008] Valid loss: 5.4775
2023-02-06 11:51:15 | Valid | Epoch[086/600] MIou: 0.5249679215283874
2023-02-06 11:51:15 | Valid | Epoch[086/600] Pixel Accuracy: 0.7803726196289062
2023-02-06 11:51:15 | Valid | Epoch[086/600] Mean Pixel Accuracy: 0.8792073392086783
2023-02-06 11:51:15 | Stage | Epoch[086/600] Train loss:0.0617
2023-02-06 11:51:15 | Stage | Epoch[086/600] Valid loss:5.4775
2023-02-06 11:51:15 | Stage | Epoch[086/600] LR:0.01

2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[001/030] Train loss: 0.0598
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[002/030] Train loss: 0.0607
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[003/030] Train loss: 0.0602
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[004/030] Train loss: 0.0612
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[005/030] Train loss: 0.0614
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[006/030] Train loss: 0.0614
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[007/030] Train loss: 0.0615
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[008/030] Train loss: 0.0614
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[009/030] Train loss: 0.0615
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[010/030] Train loss: 0.0615
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[011/030] Train loss: 0.0614
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[012/030] Train loss: 0.0615
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[013/030] Train loss: 0.0616
2023-02-06 11:51:16 | Train | Epoch[087/600] Iteration[014/030] Train loss: 0.0616
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[015/030] Train loss: 0.0615
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[016/030] Train loss: 0.0614
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[017/030] Train loss: 0.0614
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[018/030] Train loss: 0.0613
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[019/030] Train loss: 0.0612
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[020/030] Train loss: 0.0612
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[021/030] Train loss: 0.0611
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[022/030] Train loss: 0.0610
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[023/030] Train loss: 0.0610
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[024/030] Train loss: 0.0611
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[025/030] Train loss: 0.0610
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[026/030] Train loss: 0.0611
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[027/030] Train loss: 0.0610
2023-02-06 11:51:17 | Train | Epoch[087/600] Iteration[028/030] Train loss: 0.0609
2023-02-06 11:51:18 | Train | Epoch[087/600] Iteration[029/030] Train loss: 0.0609
2023-02-06 11:51:18 | Train | Epoch[087/600] Iteration[030/030] Train loss: 0.0607
2023-02-06 11:51:18 | Valid | Epoch[087/600] Iteration[001/008] Valid loss: 0.0909
2023-02-06 11:51:18 | Valid | Epoch[087/600] Iteration[002/008] Valid loss: 0.0922
2023-02-06 11:51:18 | Valid | Epoch[087/600] Iteration[003/008] Valid loss: 0.0932
2023-02-06 11:51:18 | Valid | Epoch[087/600] Iteration[004/008] Valid loss: 0.0922
2023-02-06 11:51:18 | Valid | Epoch[087/600] Iteration[005/008] Valid loss: 0.0930
2023-02-06 11:51:18 | Valid | Epoch[087/600] Iteration[006/008] Valid loss: 0.0929
2023-02-06 11:51:18 | Valid | Epoch[087/600] Iteration[007/008] Valid loss: 0.0927
2023-02-06 11:51:18 | Valid | Epoch[087/600] Iteration[008/008] Valid loss: 0.0942
2023-02-06 11:51:18 | Valid | Epoch[087/600] MIou: 0.7703055505213773
2023-02-06 11:51:18 | Valid | Epoch[087/600] Pixel Accuracy: 0.9615071614583334
2023-02-06 11:51:18 | Valid | Epoch[087/600] Mean Pixel Accuracy: 0.7949373180497674
2023-02-06 11:51:18 | Stage | Epoch[087/600] Train loss:0.0607
2023-02-06 11:51:18 | Stage | Epoch[087/600] Valid loss:0.0942
2023-02-06 11:51:18 | Stage | Epoch[087/600] LR:0.01

2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[001/030] Train loss: 0.0597
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[002/030] Train loss: 0.0605
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[003/030] Train loss: 0.0597
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[004/030] Train loss: 0.0599
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[005/030] Train loss: 0.0596
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[006/030] Train loss: 0.0593
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[007/030] Train loss: 0.0595
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[008/030] Train loss: 0.0596
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[009/030] Train loss: 0.0595
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[010/030] Train loss: 0.0596
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[011/030] Train loss: 0.0594
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[012/030] Train loss: 0.0593
2023-02-06 11:51:19 | Train | Epoch[088/600] Iteration[013/030] Train loss: 0.0594
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[014/030] Train loss: 0.0594
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[015/030] Train loss: 0.0594
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[016/030] Train loss: 0.0593
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[017/030] Train loss: 0.0592
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[018/030] Train loss: 0.0592
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[019/030] Train loss: 0.0592
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[020/030] Train loss: 0.0592
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[021/030] Train loss: 0.0591
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[022/030] Train loss: 0.0590
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[023/030] Train loss: 0.0589
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[024/030] Train loss: 0.0590
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[025/030] Train loss: 0.0590
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[026/030] Train loss: 0.0589
2023-02-06 11:51:20 | Train | Epoch[088/600] Iteration[027/030] Train loss: 0.0591
2023-02-06 11:51:21 | Train | Epoch[088/600] Iteration[028/030] Train loss: 0.0590
2023-02-06 11:51:21 | Train | Epoch[088/600] Iteration[029/030] Train loss: 0.0590
2023-02-06 11:51:21 | Train | Epoch[088/600] Iteration[030/030] Train loss: 0.0591
2023-02-06 11:51:21 | Valid | Epoch[088/600] Iteration[001/008] Valid loss: 0.0810
2023-02-06 11:51:21 | Valid | Epoch[088/600] Iteration[002/008] Valid loss: 0.0808
2023-02-06 11:51:21 | Valid | Epoch[088/600] Iteration[003/008] Valid loss: 0.0787
2023-02-06 11:51:21 | Valid | Epoch[088/600] Iteration[004/008] Valid loss: 0.0772
2023-02-06 11:51:21 | Valid | Epoch[088/600] Iteration[005/008] Valid loss: 0.0776
2023-02-06 11:51:21 | Valid | Epoch[088/600] Iteration[006/008] Valid loss: 0.0774
2023-02-06 11:51:21 | Valid | Epoch[088/600] Iteration[007/008] Valid loss: 0.0784
2023-02-06 11:51:21 | Valid | Epoch[088/600] Iteration[008/008] Valid loss: 0.0789
2023-02-06 11:51:21 | Valid | Epoch[088/600] MIou: 0.9032975463856312
2023-02-06 11:51:21 | Valid | Epoch[088/600] Pixel Accuracy: 0.983374277750651
2023-02-06 11:51:21 | Valid | Epoch[088/600] Mean Pixel Accuracy: 0.9303293124560277
2023-02-06 11:51:21 | Stage | Epoch[088/600] Train loss:0.0591
2023-02-06 11:51:21 | Stage | Epoch[088/600] Valid loss:0.0789
2023-02-06 11:51:21 | Stage | Epoch[088/600] LR:0.01

2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[001/030] Train loss: 0.0626
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[002/030] Train loss: 0.0608
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[003/030] Train loss: 0.0596
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[004/030] Train loss: 0.0591
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[005/030] Train loss: 0.0587
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[006/030] Train loss: 0.0582
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[007/030] Train loss: 0.0586
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[008/030] Train loss: 0.0588
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[009/030] Train loss: 0.0587
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[010/030] Train loss: 0.0586
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[011/030] Train loss: 0.0585
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[012/030] Train loss: 0.0585
2023-02-06 11:51:22 | Train | Epoch[089/600] Iteration[013/030] Train loss: 0.0585
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[014/030] Train loss: 0.0584
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[015/030] Train loss: 0.0585
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[016/030] Train loss: 0.0584
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[017/030] Train loss: 0.0584
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[018/030] Train loss: 0.0584
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[019/030] Train loss: 0.0584
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[020/030] Train loss: 0.0584
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[021/030] Train loss: 0.0583
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[022/030] Train loss: 0.0583
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[023/030] Train loss: 0.0582
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[024/030] Train loss: 0.0581
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[025/030] Train loss: 0.0583
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[026/030] Train loss: 0.0583
2023-02-06 11:51:23 | Train | Epoch[089/600] Iteration[027/030] Train loss: 0.0583
2023-02-06 11:51:24 | Train | Epoch[089/600] Iteration[028/030] Train loss: 0.0583
2023-02-06 11:51:24 | Train | Epoch[089/600] Iteration[029/030] Train loss: 0.0583
2023-02-06 11:51:24 | Train | Epoch[089/600] Iteration[030/030] Train loss: 0.0583
2023-02-06 11:51:24 | Valid | Epoch[089/600] Iteration[001/008] Valid loss: 0.0712
2023-02-06 11:51:24 | Valid | Epoch[089/600] Iteration[002/008] Valid loss: 0.0687
2023-02-06 11:51:24 | Valid | Epoch[089/600] Iteration[003/008] Valid loss: 0.0692
2023-02-06 11:51:24 | Valid | Epoch[089/600] Iteration[004/008] Valid loss: 0.0680
2023-02-06 11:51:24 | Valid | Epoch[089/600] Iteration[005/008] Valid loss: 0.0681
2023-02-06 11:51:24 | Valid | Epoch[089/600] Iteration[006/008] Valid loss: 0.0675
2023-02-06 11:51:24 | Valid | Epoch[089/600] Iteration[007/008] Valid loss: 0.0674
2023-02-06 11:51:24 | Valid | Epoch[089/600] Iteration[008/008] Valid loss: 0.0675
2023-02-06 11:51:24 | Valid | Epoch[089/600] MIou: 0.8971599639921439
2023-02-06 11:51:24 | Valid | Epoch[089/600] Pixel Accuracy: 0.9829839070638021
2023-02-06 11:51:24 | Valid | Epoch[089/600] Mean Pixel Accuracy: 0.9084303355063155
2023-02-06 11:51:24 | Stage | Epoch[089/600] Train loss:0.0583
2023-02-06 11:51:24 | Stage | Epoch[089/600] Valid loss:0.0675
2023-02-06 11:51:24 | Stage | Epoch[089/600] LR:0.01

2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[001/030] Train loss: 0.0585
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[002/030] Train loss: 0.0579
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[003/030] Train loss: 0.0585
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[004/030] Train loss: 0.0582
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[005/030] Train loss: 0.0579
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[006/030] Train loss: 0.0586
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[007/030] Train loss: 0.0584
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[008/030] Train loss: 0.0582
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[009/030] Train loss: 0.0582
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[010/030] Train loss: 0.0581
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[011/030] Train loss: 0.0580
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[012/030] Train loss: 0.0580
2023-02-06 11:51:25 | Train | Epoch[090/600] Iteration[013/030] Train loss: 0.0579
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[014/030] Train loss: 0.0578
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[015/030] Train loss: 0.0577
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[016/030] Train loss: 0.0575
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[017/030] Train loss: 0.0576
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[018/030] Train loss: 0.0578
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[019/030] Train loss: 0.0577
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[020/030] Train loss: 0.0579
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[021/030] Train loss: 0.0579
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[022/030] Train loss: 0.0579
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[023/030] Train loss: 0.0579
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[024/030] Train loss: 0.0579
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[025/030] Train loss: 0.0578
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[026/030] Train loss: 0.0576
2023-02-06 11:51:26 | Train | Epoch[090/600] Iteration[027/030] Train loss: 0.0577
2023-02-06 11:51:27 | Train | Epoch[090/600] Iteration[028/030] Train loss: 0.0577
2023-02-06 11:51:27 | Train | Epoch[090/600] Iteration[029/030] Train loss: 0.0576
2023-02-06 11:51:27 | Train | Epoch[090/600] Iteration[030/030] Train loss: 0.0577
2023-02-06 11:51:27 | Valid | Epoch[090/600] Iteration[001/008] Valid loss: 0.6677
2023-02-06 11:51:27 | Valid | Epoch[090/600] Iteration[002/008] Valid loss: 0.5889
2023-02-06 11:51:27 | Valid | Epoch[090/600] Iteration[003/008] Valid loss: 0.5778
2023-02-06 11:51:27 | Valid | Epoch[090/600] Iteration[004/008] Valid loss: 0.5746
2023-02-06 11:51:27 | Valid | Epoch[090/600] Iteration[005/008] Valid loss: 0.5962
2023-02-06 11:51:27 | Valid | Epoch[090/600] Iteration[006/008] Valid loss: 0.5843
2023-02-06 11:51:27 | Valid | Epoch[090/600] Iteration[007/008] Valid loss: 0.6141
2023-02-06 11:51:27 | Valid | Epoch[090/600] Iteration[008/008] Valid loss: 0.6186
2023-02-06 11:51:27 | Valid | Epoch[090/600] MIou: 0.8601385337478769
2023-02-06 11:51:27 | Valid | Epoch[090/600] Pixel Accuracy: 0.9704704284667969
2023-02-06 11:51:27 | Valid | Epoch[090/600] Mean Pixel Accuracy: 0.981632549180015
2023-02-06 11:51:27 | Stage | Epoch[090/600] Train loss:0.0577
2023-02-06 11:51:27 | Stage | Epoch[090/600] Valid loss:0.6186
2023-02-06 11:51:27 | Stage | Epoch[090/600] LR:0.01

2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[001/030] Train loss: 0.0540
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[002/030] Train loss: 0.0552
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[003/030] Train loss: 0.0556
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[004/030] Train loss: 0.0557
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[005/030] Train loss: 0.0566
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[006/030] Train loss: 0.0565
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[007/030] Train loss: 0.0564
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[008/030] Train loss: 0.0564
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[009/030] Train loss: 0.0563
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[010/030] Train loss: 0.0563
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[011/030] Train loss: 0.0566
2023-02-06 11:51:28 | Train | Epoch[091/600] Iteration[012/030] Train loss: 0.0565
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[013/030] Train loss: 0.0566
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[014/030] Train loss: 0.0565
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[015/030] Train loss: 0.0565
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[016/030] Train loss: 0.0564
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[017/030] Train loss: 0.0565
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[018/030] Train loss: 0.0568
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[019/030] Train loss: 0.0567
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[020/030] Train loss: 0.0567
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[021/030] Train loss: 0.0566
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[022/030] Train loss: 0.0566
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[023/030] Train loss: 0.0566
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[024/030] Train loss: 0.0565
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[025/030] Train loss: 0.0566
2023-02-06 11:51:29 | Train | Epoch[091/600] Iteration[026/030] Train loss: 0.0567
2023-02-06 11:51:30 | Train | Epoch[091/600] Iteration[027/030] Train loss: 0.0567
2023-02-06 11:51:30 | Train | Epoch[091/600] Iteration[028/030] Train loss: 0.0567
2023-02-06 11:51:30 | Train | Epoch[091/600] Iteration[029/030] Train loss: 0.0567
2023-02-06 11:51:30 | Train | Epoch[091/600] Iteration[030/030] Train loss: 0.0566
2023-02-06 11:51:30 | Valid | Epoch[091/600] Iteration[001/008] Valid loss: 0.6716
2023-02-06 11:51:30 | Valid | Epoch[091/600] Iteration[002/008] Valid loss: 0.6403
2023-02-06 11:51:30 | Valid | Epoch[091/600] Iteration[003/008] Valid loss: 0.6434
2023-02-06 11:51:30 | Valid | Epoch[091/600] Iteration[004/008] Valid loss: 0.6473
2023-02-06 11:51:30 | Valid | Epoch[091/600] Iteration[005/008] Valid loss: 0.6657
2023-02-06 11:51:30 | Valid | Epoch[091/600] Iteration[006/008] Valid loss: 0.6466
2023-02-06 11:51:30 | Valid | Epoch[091/600] Iteration[007/008] Valid loss: 0.6786
2023-02-06 11:51:30 | Valid | Epoch[091/600] Iteration[008/008] Valid loss: 0.7015
2023-02-06 11:51:30 | Valid | Epoch[091/600] MIou: 0.8477572465106661
2023-02-06 11:51:30 | Valid | Epoch[091/600] Pixel Accuracy: 0.9671058654785156
2023-02-06 11:51:30 | Valid | Epoch[091/600] Mean Pixel Accuracy: 0.97876242595307
2023-02-06 11:51:30 | Stage | Epoch[091/600] Train loss:0.0566
2023-02-06 11:51:30 | Stage | Epoch[091/600] Valid loss:0.7015
2023-02-06 11:51:30 | Stage | Epoch[091/600] LR:0.01

2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[001/030] Train loss: 0.0573
2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[002/030] Train loss: 0.0587
2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[003/030] Train loss: 0.0577
2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[004/030] Train loss: 0.0574
2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[005/030] Train loss: 0.0570
2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[006/030] Train loss: 0.0564
2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[007/030] Train loss: 0.0562
2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[008/030] Train loss: 0.0562
2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[009/030] Train loss: 0.0561
2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[010/030] Train loss: 0.0560
2023-02-06 11:51:31 | Train | Epoch[092/600] Iteration[011/030] Train loss: 0.0558
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[012/030] Train loss: 0.0559
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[013/030] Train loss: 0.0558
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[014/030] Train loss: 0.0558
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[015/030] Train loss: 0.0558
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[016/030] Train loss: 0.0556
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[017/030] Train loss: 0.0555
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[018/030] Train loss: 0.0554
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[019/030] Train loss: 0.0553
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[020/030] Train loss: 0.0554
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[021/030] Train loss: 0.0553
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[022/030] Train loss: 0.0554
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[023/030] Train loss: 0.0553
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[024/030] Train loss: 0.0553
2023-02-06 11:51:32 | Train | Epoch[092/600] Iteration[025/030] Train loss: 0.0553
2023-02-06 11:51:33 | Train | Epoch[092/600] Iteration[026/030] Train loss: 0.0555
2023-02-06 11:51:33 | Train | Epoch[092/600] Iteration[027/030] Train loss: 0.0555
2023-02-06 11:51:33 | Train | Epoch[092/600] Iteration[028/030] Train loss: 0.0556
2023-02-06 11:51:33 | Train | Epoch[092/600] Iteration[029/030] Train loss: 0.0557
2023-02-06 11:51:33 | Train | Epoch[092/600] Iteration[030/030] Train loss: 0.0558
2023-02-06 11:51:33 | Valid | Epoch[092/600] Iteration[001/008] Valid loss: 0.1550
2023-02-06 11:51:33 | Valid | Epoch[092/600] Iteration[002/008] Valid loss: 0.1204
2023-02-06 11:51:33 | Valid | Epoch[092/600] Iteration[003/008] Valid loss: 0.1171
2023-02-06 11:51:33 | Valid | Epoch[092/600] Iteration[004/008] Valid loss: 0.1130
2023-02-06 11:51:33 | Valid | Epoch[092/600] Iteration[005/008] Valid loss: 0.1132
2023-02-06 11:51:33 | Valid | Epoch[092/600] Iteration[006/008] Valid loss: 0.1087
2023-02-06 11:51:33 | Valid | Epoch[092/600] Iteration[007/008] Valid loss: 0.1116
2023-02-06 11:51:33 | Valid | Epoch[092/600] Iteration[008/008] Valid loss: 0.1096
2023-02-06 11:51:33 | Valid | Epoch[092/600] MIou: 0.9305522873362645
2023-02-06 11:51:33 | Valid | Epoch[092/600] Pixel Accuracy: 0.9875640869140625
2023-02-06 11:51:33 | Valid | Epoch[092/600] Mean Pixel Accuracy: 0.9757791189029806
2023-02-06 11:51:33 | Stage | Epoch[092/600] Train loss:0.0558
2023-02-06 11:51:33 | Stage | Epoch[092/600] Valid loss:0.1096
2023-02-06 11:51:33 | Stage | Epoch[092/600] LR:0.01

2023-02-06 11:51:34 | Train | Epoch[093/600] Iteration[001/030] Train loss: 0.0585
2023-02-06 11:51:34 | Train | Epoch[093/600] Iteration[002/030] Train loss: 0.0573
2023-02-06 11:51:34 | Train | Epoch[093/600] Iteration[003/030] Train loss: 0.0565
2023-02-06 11:51:34 | Train | Epoch[093/600] Iteration[004/030] Train loss: 0.0561
2023-02-06 11:51:34 | Train | Epoch[093/600] Iteration[005/030] Train loss: 0.0560
2023-02-06 11:51:34 | Train | Epoch[093/600] Iteration[006/030] Train loss: 0.0558
2023-02-06 11:51:34 | Train | Epoch[093/600] Iteration[007/030] Train loss: 0.0559
2023-02-06 11:51:34 | Train | Epoch[093/600] Iteration[008/030] Train loss: 0.0557
2023-02-06 11:51:34 | Train | Epoch[093/600] Iteration[009/030] Train loss: 0.0556
2023-02-06 11:51:34 | Train | Epoch[093/600] Iteration[010/030] Train loss: 0.0555
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[011/030] Train loss: 0.0556
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[012/030] Train loss: 0.0555
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[013/030] Train loss: 0.0554
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[014/030] Train loss: 0.0552
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[015/030] Train loss: 0.0554
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[016/030] Train loss: 0.0553
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[017/030] Train loss: 0.0553
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[018/030] Train loss: 0.0552
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[019/030] Train loss: 0.0551
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[020/030] Train loss: 0.0552
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[021/030] Train loss: 0.0551
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[022/030] Train loss: 0.0551
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[023/030] Train loss: 0.0551
2023-02-06 11:51:35 | Train | Epoch[093/600] Iteration[024/030] Train loss: 0.0551
2023-02-06 11:51:36 | Train | Epoch[093/600] Iteration[025/030] Train loss: 0.0550
2023-02-06 11:51:36 | Train | Epoch[093/600] Iteration[026/030] Train loss: 0.0550
2023-02-06 11:51:36 | Train | Epoch[093/600] Iteration[027/030] Train loss: 0.0550
2023-02-06 11:51:36 | Train | Epoch[093/600] Iteration[028/030] Train loss: 0.0549
2023-02-06 11:51:36 | Train | Epoch[093/600] Iteration[029/030] Train loss: 0.0549
2023-02-06 11:51:36 | Train | Epoch[093/600] Iteration[030/030] Train loss: 0.0549
2023-02-06 11:51:36 | Valid | Epoch[093/600] Iteration[001/008] Valid loss: 0.0910
2023-02-06 11:51:36 | Valid | Epoch[093/600] Iteration[002/008] Valid loss: 0.0781
2023-02-06 11:51:36 | Valid | Epoch[093/600] Iteration[003/008] Valid loss: 0.0780
2023-02-06 11:51:36 | Valid | Epoch[093/600] Iteration[004/008] Valid loss: 0.0747
2023-02-06 11:51:36 | Valid | Epoch[093/600] Iteration[005/008] Valid loss: 0.0745
2023-02-06 11:51:36 | Valid | Epoch[093/600] Iteration[006/008] Valid loss: 0.0732
2023-02-06 11:51:36 | Valid | Epoch[093/600] Iteration[007/008] Valid loss: 0.0738
2023-02-06 11:51:36 | Valid | Epoch[093/600] Iteration[008/008] Valid loss: 0.0726
2023-02-06 11:51:37 | Valid | Epoch[093/600] MIou: 0.9303458099132262
2023-02-06 11:51:37 | Valid | Epoch[093/600] Pixel Accuracy: 0.9882863362630209
2023-02-06 11:51:37 | Valid | Epoch[093/600] Mean Pixel Accuracy: 0.9462871152404136
2023-02-06 11:51:37 | Stage | Epoch[093/600] Train loss:0.0549
2023-02-06 11:51:37 | Stage | Epoch[093/600] Valid loss:0.0726
2023-02-06 11:51:37 | Stage | Epoch[093/600] LR:0.01

2023-02-06 11:51:37 | Train | Epoch[094/600] Iteration[001/030] Train loss: 0.0557
2023-02-06 11:51:37 | Train | Epoch[094/600] Iteration[002/030] Train loss: 0.0546
2023-02-06 11:51:37 | Train | Epoch[094/600] Iteration[003/030] Train loss: 0.0543
2023-02-06 11:51:37 | Train | Epoch[094/600] Iteration[004/030] Train loss: 0.0548
2023-02-06 11:51:37 | Train | Epoch[094/600] Iteration[005/030] Train loss: 0.0550
2023-02-06 11:51:37 | Train | Epoch[094/600] Iteration[006/030] Train loss: 0.0546
2023-02-06 11:51:37 | Train | Epoch[094/600] Iteration[007/030] Train loss: 0.0544
2023-02-06 11:51:37 | Train | Epoch[094/600] Iteration[008/030] Train loss: 0.0552
2023-02-06 11:51:37 | Train | Epoch[094/600] Iteration[009/030] Train loss: 0.0548
2023-02-06 11:51:37 | Train | Epoch[094/600] Iteration[010/030] Train loss: 0.0547
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[011/030] Train loss: 0.0548
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[012/030] Train loss: 0.0547
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[013/030] Train loss: 0.0545
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[014/030] Train loss: 0.0543
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[015/030] Train loss: 0.0542
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[016/030] Train loss: 0.0542
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[017/030] Train loss: 0.0542
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[018/030] Train loss: 0.0541
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[019/030] Train loss: 0.0544
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[020/030] Train loss: 0.0544
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[021/030] Train loss: 0.0544
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[022/030] Train loss: 0.0544
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[023/030] Train loss: 0.0544
2023-02-06 11:51:38 | Train | Epoch[094/600] Iteration[024/030] Train loss: 0.0545
2023-02-06 11:51:39 | Train | Epoch[094/600] Iteration[025/030] Train loss: 0.0544
2023-02-06 11:51:39 | Train | Epoch[094/600] Iteration[026/030] Train loss: 0.0543
2023-02-06 11:51:39 | Train | Epoch[094/600] Iteration[027/030] Train loss: 0.0543
2023-02-06 11:51:39 | Train | Epoch[094/600] Iteration[028/030] Train loss: 0.0543
2023-02-06 11:51:39 | Train | Epoch[094/600] Iteration[029/030] Train loss: 0.0543
2023-02-06 11:51:39 | Train | Epoch[094/600] Iteration[030/030] Train loss: 0.0543
2023-02-06 11:51:39 | Valid | Epoch[094/600] Iteration[001/008] Valid loss: 0.2462
2023-02-06 11:51:39 | Valid | Epoch[094/600] Iteration[002/008] Valid loss: 0.2603
2023-02-06 11:51:39 | Valid | Epoch[094/600] Iteration[003/008] Valid loss: 0.2791
2023-02-06 11:51:39 | Valid | Epoch[094/600] Iteration[004/008] Valid loss: 0.2780
2023-02-06 11:51:39 | Valid | Epoch[094/600] Iteration[005/008] Valid loss: 0.2889
2023-02-06 11:51:39 | Valid | Epoch[094/600] Iteration[006/008] Valid loss: 0.2867
2023-02-06 11:51:39 | Valid | Epoch[094/600] Iteration[007/008] Valid loss: 0.2858
2023-02-06 11:51:39 | Valid | Epoch[094/600] Iteration[008/008] Valid loss: 0.2993
2023-02-06 11:51:40 | Valid | Epoch[094/600] MIou: 0.4556408486376226
2023-02-06 11:51:40 | Valid | Epoch[094/600] Pixel Accuracy: 0.9098154703776041
2023-02-06 11:51:40 | Valid | Epoch[094/600] Mean Pixel Accuracy: 0.5007391347196216
2023-02-06 11:51:40 | Stage | Epoch[094/600] Train loss:0.0543
2023-02-06 11:51:40 | Stage | Epoch[094/600] Valid loss:0.2993
2023-02-06 11:51:40 | Stage | Epoch[094/600] LR:0.01

2023-02-06 11:51:40 | Train | Epoch[095/600] Iteration[001/030] Train loss: 0.0540
2023-02-06 11:51:40 | Train | Epoch[095/600] Iteration[002/030] Train loss: 0.0548
2023-02-06 11:51:40 | Train | Epoch[095/600] Iteration[003/030] Train loss: 0.0542
2023-02-06 11:51:40 | Train | Epoch[095/600] Iteration[004/030] Train loss: 0.0536
2023-02-06 11:51:40 | Train | Epoch[095/600] Iteration[005/030] Train loss: 0.0537
2023-02-06 11:51:40 | Train | Epoch[095/600] Iteration[006/030] Train loss: 0.0541
2023-02-06 11:51:40 | Train | Epoch[095/600] Iteration[007/030] Train loss: 0.0543
2023-02-06 11:51:40 | Train | Epoch[095/600] Iteration[008/030] Train loss: 0.0550
2023-02-06 11:51:40 | Train | Epoch[095/600] Iteration[009/030] Train loss: 0.0548
2023-02-06 11:51:40 | Train | Epoch[095/600] Iteration[010/030] Train loss: 0.0546
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[011/030] Train loss: 0.0544
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[012/030] Train loss: 0.0544
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[013/030] Train loss: 0.0543
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[014/030] Train loss: 0.0543
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[015/030] Train loss: 0.0541
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[016/030] Train loss: 0.0541
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[017/030] Train loss: 0.0541
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[018/030] Train loss: 0.0540
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[019/030] Train loss: 0.0539
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[020/030] Train loss: 0.0538
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[021/030] Train loss: 0.0538
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[022/030] Train loss: 0.0537
2023-02-06 11:51:41 | Train | Epoch[095/600] Iteration[023/030] Train loss: 0.0537
2023-02-06 11:51:42 | Train | Epoch[095/600] Iteration[024/030] Train loss: 0.0537
2023-02-06 11:51:42 | Train | Epoch[095/600] Iteration[025/030] Train loss: 0.0536
2023-02-06 11:51:42 | Train | Epoch[095/600] Iteration[026/030] Train loss: 0.0537
2023-02-06 11:51:42 | Train | Epoch[095/600] Iteration[027/030] Train loss: 0.0537
2023-02-06 11:51:42 | Train | Epoch[095/600] Iteration[028/030] Train loss: 0.0536
2023-02-06 11:51:42 | Train | Epoch[095/600] Iteration[029/030] Train loss: 0.0535
2023-02-06 11:51:42 | Train | Epoch[095/600] Iteration[030/030] Train loss: 0.0536
2023-02-06 11:51:42 | Valid | Epoch[095/600] Iteration[001/008] Valid loss: 0.9371
2023-02-06 11:51:42 | Valid | Epoch[095/600] Iteration[002/008] Valid loss: 0.9116
2023-02-06 11:51:42 | Valid | Epoch[095/600] Iteration[003/008] Valid loss: 0.9193
2023-02-06 11:51:42 | Valid | Epoch[095/600] Iteration[004/008] Valid loss: 0.9360
2023-02-06 11:51:42 | Valid | Epoch[095/600] Iteration[005/008] Valid loss: 0.9593
2023-02-06 11:51:42 | Valid | Epoch[095/600] Iteration[006/008] Valid loss: 0.9357
2023-02-06 11:51:42 | Valid | Epoch[095/600] Iteration[007/008] Valid loss: 0.9769
2023-02-06 11:51:42 | Valid | Epoch[095/600] Iteration[008/008] Valid loss: 1.0155
2023-02-06 11:51:43 | Valid | Epoch[095/600] MIou: 0.8263549953058957
2023-02-06 11:51:43 | Valid | Epoch[095/600] Pixel Accuracy: 0.9607315063476562
2023-02-06 11:51:43 | Valid | Epoch[095/600] Mean Pixel Accuracy: 0.9760450247824058
2023-02-06 11:51:43 | Stage | Epoch[095/600] Train loss:0.0536
2023-02-06 11:51:43 | Stage | Epoch[095/600] Valid loss:1.0155
2023-02-06 11:51:43 | Stage | Epoch[095/600] LR:0.01

2023-02-06 11:51:43 | Train | Epoch[096/600] Iteration[001/030] Train loss: 0.0509
2023-02-06 11:51:43 | Train | Epoch[096/600] Iteration[002/030] Train loss: 0.0524
2023-02-06 11:51:43 | Train | Epoch[096/600] Iteration[003/030] Train loss: 0.0526
2023-02-06 11:51:43 | Train | Epoch[096/600] Iteration[004/030] Train loss: 0.0526
2023-02-06 11:51:43 | Train | Epoch[096/600] Iteration[005/030] Train loss: 0.0533
2023-02-06 11:51:43 | Train | Epoch[096/600] Iteration[006/030] Train loss: 0.0530
2023-02-06 11:51:43 | Train | Epoch[096/600] Iteration[007/030] Train loss: 0.0530
2023-02-06 11:51:43 | Train | Epoch[096/600] Iteration[008/030] Train loss: 0.0527
2023-02-06 11:51:43 | Train | Epoch[096/600] Iteration[009/030] Train loss: 0.0530
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[010/030] Train loss: 0.0533
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[011/030] Train loss: 0.0536
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[012/030] Train loss: 0.0537
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[013/030] Train loss: 0.0533
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[014/030] Train loss: 0.0533
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[015/030] Train loss: 0.0533
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[016/030] Train loss: 0.0534
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[017/030] Train loss: 0.0534
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[018/030] Train loss: 0.0533
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[019/030] Train loss: 0.0533
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[020/030] Train loss: 0.0531
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[021/030] Train loss: 0.0532
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[022/030] Train loss: 0.0531
2023-02-06 11:51:44 | Train | Epoch[096/600] Iteration[023/030] Train loss: 0.0531
2023-02-06 11:51:45 | Train | Epoch[096/600] Iteration[024/030] Train loss: 0.0532
2023-02-06 11:51:45 | Train | Epoch[096/600] Iteration[025/030] Train loss: 0.0531
2023-02-06 11:51:45 | Train | Epoch[096/600] Iteration[026/030] Train loss: 0.0530
2023-02-06 11:51:45 | Train | Epoch[096/600] Iteration[027/030] Train loss: 0.0530
2023-02-06 11:51:45 | Train | Epoch[096/600] Iteration[028/030] Train loss: 0.0530
2023-02-06 11:51:45 | Train | Epoch[096/600] Iteration[029/030] Train loss: 0.0529
2023-02-06 11:51:45 | Train | Epoch[096/600] Iteration[030/030] Train loss: 0.0529
2023-02-06 11:51:45 | Valid | Epoch[096/600] Iteration[001/008] Valid loss: 0.5812
2023-02-06 11:51:45 | Valid | Epoch[096/600] Iteration[002/008] Valid loss: 0.5168
2023-02-06 11:51:45 | Valid | Epoch[096/600] Iteration[003/008] Valid loss: 0.5222
2023-02-06 11:51:45 | Valid | Epoch[096/600] Iteration[004/008] Valid loss: 0.5230
2023-02-06 11:51:45 | Valid | Epoch[096/600] Iteration[005/008] Valid loss: 0.5400
2023-02-06 11:51:45 | Valid | Epoch[096/600] Iteration[006/008] Valid loss: 0.5270
2023-02-06 11:51:45 | Valid | Epoch[096/600] Iteration[007/008] Valid loss: 0.5573
2023-02-06 11:51:45 | Valid | Epoch[096/600] Iteration[008/008] Valid loss: 0.5663
2023-02-06 11:51:46 | Valid | Epoch[096/600] MIou: 0.8583395588076204
2023-02-06 11:51:46 | Valid | Epoch[096/600] Pixel Accuracy: 0.9700838724772135
2023-02-06 11:51:46 | Valid | Epoch[096/600] Mean Pixel Accuracy: 0.9796130471409831
2023-02-06 11:51:46 | Stage | Epoch[096/600] Train loss:0.0529
2023-02-06 11:51:46 | Stage | Epoch[096/600] Valid loss:0.5663
2023-02-06 11:51:46 | Stage | Epoch[096/600] LR:0.01

2023-02-06 11:51:46 | Train | Epoch[097/600] Iteration[001/030] Train loss: 0.0541
2023-02-06 11:51:46 | Train | Epoch[097/600] Iteration[002/030] Train loss: 0.0528
2023-02-06 11:51:46 | Train | Epoch[097/600] Iteration[003/030] Train loss: 0.0528
2023-02-06 11:51:46 | Train | Epoch[097/600] Iteration[004/030] Train loss: 0.0526
2023-02-06 11:51:46 | Train | Epoch[097/600] Iteration[005/030] Train loss: 0.0522
2023-02-06 11:51:46 | Train | Epoch[097/600] Iteration[006/030] Train loss: 0.0521
2023-02-06 11:51:46 | Train | Epoch[097/600] Iteration[007/030] Train loss: 0.0520
2023-02-06 11:51:46 | Train | Epoch[097/600] Iteration[008/030] Train loss: 0.0518
2023-02-06 11:51:46 | Train | Epoch[097/600] Iteration[009/030] Train loss: 0.0521
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[010/030] Train loss: 0.0521
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[011/030] Train loss: 0.0524
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[012/030] Train loss: 0.0525
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[013/030] Train loss: 0.0528
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[014/030] Train loss: 0.0527
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[015/030] Train loss: 0.0525
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[016/030] Train loss: 0.0524
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[017/030] Train loss: 0.0524
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[018/030] Train loss: 0.0523
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[019/030] Train loss: 0.0522
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[020/030] Train loss: 0.0522
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[021/030] Train loss: 0.0522
2023-02-06 11:51:47 | Train | Epoch[097/600] Iteration[022/030] Train loss: 0.0522
2023-02-06 11:51:48 | Train | Epoch[097/600] Iteration[023/030] Train loss: 0.0522
2023-02-06 11:51:48 | Train | Epoch[097/600] Iteration[024/030] Train loss: 0.0522
2023-02-06 11:51:48 | Train | Epoch[097/600] Iteration[025/030] Train loss: 0.0521
2023-02-06 11:51:48 | Train | Epoch[097/600] Iteration[026/030] Train loss: 0.0521
2023-02-06 11:51:48 | Train | Epoch[097/600] Iteration[027/030] Train loss: 0.0521
2023-02-06 11:51:48 | Train | Epoch[097/600] Iteration[028/030] Train loss: 0.0522
2023-02-06 11:51:48 | Train | Epoch[097/600] Iteration[029/030] Train loss: 0.0521
2023-02-06 11:51:48 | Train | Epoch[097/600] Iteration[030/030] Train loss: 0.0521
2023-02-06 11:51:48 | Valid | Epoch[097/600] Iteration[001/008] Valid loss: 0.1531
2023-02-06 11:51:48 | Valid | Epoch[097/600] Iteration[002/008] Valid loss: 0.1584
2023-02-06 11:51:48 | Valid | Epoch[097/600] Iteration[003/008] Valid loss: 0.1674
2023-02-06 11:51:48 | Valid | Epoch[097/600] Iteration[004/008] Valid loss: 0.1661
2023-02-06 11:51:48 | Valid | Epoch[097/600] Iteration[005/008] Valid loss: 0.1707
2023-02-06 11:51:48 | Valid | Epoch[097/600] Iteration[006/008] Valid loss: 0.1683
2023-02-06 11:51:48 | Valid | Epoch[097/600] Iteration[007/008] Valid loss: 0.1665
2023-02-06 11:51:49 | Valid | Epoch[097/600] Iteration[008/008] Valid loss: 0.1720
2023-02-06 11:51:49 | Valid | Epoch[097/600] MIou: 0.49215516477903387
2023-02-06 11:51:49 | Valid | Epoch[097/600] Pixel Accuracy: 0.9159075419108073
2023-02-06 11:51:49 | Valid | Epoch[097/600] Mean Pixel Accuracy: 0.5344647960692112
2023-02-06 11:51:49 | Stage | Epoch[097/600] Train loss:0.0521
2023-02-06 11:51:49 | Stage | Epoch[097/600] Valid loss:0.1720
2023-02-06 11:51:49 | Stage | Epoch[097/600] LR:0.01

2023-02-06 11:51:49 | Train | Epoch[098/600] Iteration[001/030] Train loss: 0.0519
2023-02-06 11:51:49 | Train | Epoch[098/600] Iteration[002/030] Train loss: 0.0498
2023-02-06 11:51:49 | Train | Epoch[098/600] Iteration[003/030] Train loss: 0.0497
2023-02-06 11:51:49 | Train | Epoch[098/600] Iteration[004/030] Train loss: 0.0502
2023-02-06 11:51:49 | Train | Epoch[098/600] Iteration[005/030] Train loss: 0.0505
2023-02-06 11:51:49 | Train | Epoch[098/600] Iteration[006/030] Train loss: 0.0508
2023-02-06 11:51:49 | Train | Epoch[098/600] Iteration[007/030] Train loss: 0.0510
2023-02-06 11:51:49 | Train | Epoch[098/600] Iteration[008/030] Train loss: 0.0512
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[009/030] Train loss: 0.0513
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[010/030] Train loss: 0.0513
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[011/030] Train loss: 0.0514
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[012/030] Train loss: 0.0512
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[013/030] Train loss: 0.0514
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[014/030] Train loss: 0.0515
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[015/030] Train loss: 0.0516
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[016/030] Train loss: 0.0515
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[017/030] Train loss: 0.0515
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[018/030] Train loss: 0.0514
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[019/030] Train loss: 0.0515
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[020/030] Train loss: 0.0516
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[021/030] Train loss: 0.0517
2023-02-06 11:51:50 | Train | Epoch[098/600] Iteration[022/030] Train loss: 0.0517
2023-02-06 11:51:51 | Train | Epoch[098/600] Iteration[023/030] Train loss: 0.0519
2023-02-06 11:51:51 | Train | Epoch[098/600] Iteration[024/030] Train loss: 0.0518
2023-02-06 11:51:51 | Train | Epoch[098/600] Iteration[025/030] Train loss: 0.0517
2023-02-06 11:51:51 | Train | Epoch[098/600] Iteration[026/030] Train loss: 0.0517
2023-02-06 11:51:51 | Train | Epoch[098/600] Iteration[027/030] Train loss: 0.0516
2023-02-06 11:51:51 | Train | Epoch[098/600] Iteration[028/030] Train loss: 0.0515
2023-02-06 11:51:51 | Train | Epoch[098/600] Iteration[029/030] Train loss: 0.0514
2023-02-06 11:51:51 | Train | Epoch[098/600] Iteration[030/030] Train loss: 0.0514
2023-02-06 11:51:51 | Valid | Epoch[098/600] Iteration[001/008] Valid loss: 0.0664
2023-02-06 11:51:51 | Valid | Epoch[098/600] Iteration[002/008] Valid loss: 0.0619
2023-02-06 11:51:51 | Valid | Epoch[098/600] Iteration[003/008] Valid loss: 0.0623
2023-02-06 11:51:51 | Valid | Epoch[098/600] Iteration[004/008] Valid loss: 0.0603
2023-02-06 11:51:51 | Valid | Epoch[098/600] Iteration[005/008] Valid loss: 0.0605
2023-02-06 11:51:51 | Valid | Epoch[098/600] Iteration[006/008] Valid loss: 0.0598
2023-02-06 11:51:52 | Valid | Epoch[098/600] Iteration[007/008] Valid loss: 0.0601
2023-02-06 11:51:52 | Valid | Epoch[098/600] Iteration[008/008] Valid loss: 0.0599
2023-02-06 11:51:52 | Valid | Epoch[098/600] MIou: 0.9102001462444929
2023-02-06 11:51:52 | Valid | Epoch[098/600] Pixel Accuracy: 0.9850591023763021
2023-02-06 11:51:52 | Valid | Epoch[098/600] Mean Pixel Accuracy: 0.9228098558722275
2023-02-06 11:51:52 | Stage | Epoch[098/600] Train loss:0.0514
2023-02-06 11:51:52 | Stage | Epoch[098/600] Valid loss:0.0599
2023-02-06 11:51:52 | Stage | Epoch[098/600] LR:0.01

2023-02-06 11:51:52 | Train | Epoch[099/600] Iteration[001/030] Train loss: 0.0518
2023-02-06 11:51:52 | Train | Epoch[099/600] Iteration[002/030] Train loss: 0.0504
2023-02-06 11:51:52 | Train | Epoch[099/600] Iteration[003/030] Train loss: 0.0507
2023-02-06 11:51:52 | Train | Epoch[099/600] Iteration[004/030] Train loss: 0.0501
2023-02-06 11:51:52 | Train | Epoch[099/600] Iteration[005/030] Train loss: 0.0504
2023-02-06 11:51:52 | Train | Epoch[099/600] Iteration[006/030] Train loss: 0.0507
2023-02-06 11:51:52 | Train | Epoch[099/600] Iteration[007/030] Train loss: 0.0506
2023-02-06 11:51:52 | Train | Epoch[099/600] Iteration[008/030] Train loss: 0.0505
2023-02-06 11:51:52 | Train | Epoch[099/600] Iteration[009/030] Train loss: 0.0504
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[010/030] Train loss: 0.0506
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[011/030] Train loss: 0.0505
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[012/030] Train loss: 0.0508
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[013/030] Train loss: 0.0507
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[014/030] Train loss: 0.0506
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[015/030] Train loss: 0.0507
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[016/030] Train loss: 0.0507
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[017/030] Train loss: 0.0508
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[018/030] Train loss: 0.0507
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[019/030] Train loss: 0.0509
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[020/030] Train loss: 0.0509
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[021/030] Train loss: 0.0509
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[022/030] Train loss: 0.0510
2023-02-06 11:51:53 | Train | Epoch[099/600] Iteration[023/030] Train loss: 0.0510
2023-02-06 11:51:54 | Train | Epoch[099/600] Iteration[024/030] Train loss: 0.0510
2023-02-06 11:51:54 | Train | Epoch[099/600] Iteration[025/030] Train loss: 0.0511
2023-02-06 11:51:54 | Train | Epoch[099/600] Iteration[026/030] Train loss: 0.0512
2023-02-06 11:51:54 | Train | Epoch[099/600] Iteration[027/030] Train loss: 0.0511
2023-02-06 11:51:54 | Train | Epoch[099/600] Iteration[028/030] Train loss: 0.0511
2023-02-06 11:51:54 | Train | Epoch[099/600] Iteration[029/030] Train loss: 0.0510
2023-02-06 11:51:54 | Train | Epoch[099/600] Iteration[030/030] Train loss: 0.0511
2023-02-06 11:51:54 | Valid | Epoch[099/600] Iteration[001/008] Valid loss: 0.1122
2023-02-06 11:51:54 | Valid | Epoch[099/600] Iteration[002/008] Valid loss: 0.1032
2023-02-06 11:51:54 | Valid | Epoch[099/600] Iteration[003/008] Valid loss: 0.1025
2023-02-06 11:51:54 | Valid | Epoch[099/600] Iteration[004/008] Valid loss: 0.0988
2023-02-06 11:51:54 | Valid | Epoch[099/600] Iteration[005/008] Valid loss: 0.0981
2023-02-06 11:51:54 | Valid | Epoch[099/600] Iteration[006/008] Valid loss: 0.0965
2023-02-06 11:51:55 | Valid | Epoch[099/600] Iteration[007/008] Valid loss: 0.0952
2023-02-06 11:51:55 | Valid | Epoch[099/600] Iteration[008/008] Valid loss: 0.0941
2023-02-06 11:51:55 | Valid | Epoch[099/600] MIou: 0.8544071283586943
2023-02-06 11:51:55 | Valid | Epoch[099/600] Pixel Accuracy: 0.9754956563313802
2023-02-06 11:51:55 | Valid | Epoch[099/600] Mean Pixel Accuracy: 0.8752560925977452
2023-02-06 11:51:55 | Stage | Epoch[099/600] Train loss:0.0511
2023-02-06 11:51:55 | Stage | Epoch[099/600] Valid loss:0.0941
2023-02-06 11:51:55 | Stage | Epoch[099/600] LR:0.01

2023-02-06 11:51:55 | Train | Epoch[100/600] Iteration[001/030] Train loss: 0.0520
2023-02-06 11:51:55 | Train | Epoch[100/600] Iteration[002/030] Train loss: 0.0519
2023-02-06 11:51:55 | Train | Epoch[100/600] Iteration[003/030] Train loss: 0.0524
2023-02-06 11:51:55 | Train | Epoch[100/600] Iteration[004/030] Train loss: 0.0523
2023-02-06 11:51:55 | Train | Epoch[100/600] Iteration[005/030] Train loss: 0.0524
2023-02-06 11:51:55 | Train | Epoch[100/600] Iteration[006/030] Train loss: 0.0522
2023-02-06 11:51:55 | Train | Epoch[100/600] Iteration[007/030] Train loss: 0.0518
2023-02-06 11:51:55 | Train | Epoch[100/600] Iteration[008/030] Train loss: 0.0524
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[009/030] Train loss: 0.0521
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[010/030] Train loss: 0.0521
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[011/030] Train loss: 0.0520
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[012/030] Train loss: 0.0519
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[013/030] Train loss: 0.0518
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[014/030] Train loss: 0.0517
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[015/030] Train loss: 0.0518
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[016/030] Train loss: 0.0517
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[017/030] Train loss: 0.0516
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[018/030] Train loss: 0.0516
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[019/030] Train loss: 0.0515
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[020/030] Train loss: 0.0515
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[021/030] Train loss: 0.0516
2023-02-06 11:51:56 | Train | Epoch[100/600] Iteration[022/030] Train loss: 0.0515
2023-02-06 11:51:57 | Train | Epoch[100/600] Iteration[023/030] Train loss: 0.0514
2023-02-06 11:51:57 | Train | Epoch[100/600] Iteration[024/030] Train loss: 0.0513
2023-02-06 11:51:57 | Train | Epoch[100/600] Iteration[025/030] Train loss: 0.0514
2023-02-06 11:51:57 | Train | Epoch[100/600] Iteration[026/030] Train loss: 0.0513
2023-02-06 11:51:57 | Train | Epoch[100/600] Iteration[027/030] Train loss: 0.0512
2023-02-06 11:51:57 | Train | Epoch[100/600] Iteration[028/030] Train loss: 0.0513
2023-02-06 11:51:57 | Train | Epoch[100/600] Iteration[029/030] Train loss: 0.0513
2023-02-06 11:51:57 | Train | Epoch[100/600] Iteration[030/030] Train loss: 0.0512
2023-02-06 11:51:57 | Valid | Epoch[100/600] Iteration[001/008] Valid loss: 0.1401
2023-02-06 11:51:57 | Valid | Epoch[100/600] Iteration[002/008] Valid loss: 0.1280
2023-02-06 11:51:57 | Valid | Epoch[100/600] Iteration[003/008] Valid loss: 0.1323
2023-02-06 11:51:57 | Valid | Epoch[100/600] Iteration[004/008] Valid loss: 0.1271
2023-02-06 11:51:57 | Valid | Epoch[100/600] Iteration[005/008] Valid loss: 0.1306
2023-02-06 11:51:57 | Valid | Epoch[100/600] Iteration[006/008] Valid loss: 0.1281
2023-02-06 11:51:58 | Valid | Epoch[100/600] Iteration[007/008] Valid loss: 0.1266
2023-02-06 11:51:58 | Valid | Epoch[100/600] Iteration[008/008] Valid loss: 0.1283
2023-02-06 11:51:58 | Valid | Epoch[100/600] MIou: 0.7316325821527037
2023-02-06 11:51:58 | Valid | Epoch[100/600] Pixel Accuracy: 0.9545911153157552
2023-02-06 11:51:58 | Valid | Epoch[100/600] Mean Pixel Accuracy: 0.7612343004766042
2023-02-06 11:51:58 | Stage | Epoch[100/600] Train loss:0.0512
2023-02-06 11:51:58 | Stage | Epoch[100/600] Valid loss:0.1283
2023-02-06 11:51:58 | Stage | Epoch[100/600] LR:0.01

2023-02-06 11:51:58 | Train | Epoch[101/600] Iteration[001/030] Train loss: 0.0514
2023-02-06 11:51:58 | Train | Epoch[101/600] Iteration[002/030] Train loss: 0.0505
2023-02-06 11:51:58 | Train | Epoch[101/600] Iteration[003/030] Train loss: 0.0499
2023-02-06 11:51:58 | Train | Epoch[101/600] Iteration[004/030] Train loss: 0.0498
2023-02-06 11:51:58 | Train | Epoch[101/600] Iteration[005/030] Train loss: 0.0497
2023-02-06 11:51:58 | Train | Epoch[101/600] Iteration[006/030] Train loss: 0.0493
2023-02-06 11:51:58 | Train | Epoch[101/600] Iteration[007/030] Train loss: 0.0497
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[008/030] Train loss: 0.0500
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[009/030] Train loss: 0.0497
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[010/030] Train loss: 0.0498
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[011/030] Train loss: 0.0497
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[012/030] Train loss: 0.0498
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[013/030] Train loss: 0.0500
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[014/030] Train loss: 0.0502
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[015/030] Train loss: 0.0500
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[016/030] Train loss: 0.0498
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[017/030] Train loss: 0.0497
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[018/030] Train loss: 0.0497
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[019/030] Train loss: 0.0496
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[020/030] Train loss: 0.0496
2023-02-06 11:51:59 | Train | Epoch[101/600] Iteration[021/030] Train loss: 0.0495
2023-02-06 11:52:00 | Train | Epoch[101/600] Iteration[022/030] Train loss: 0.0495
2023-02-06 11:52:00 | Train | Epoch[101/600] Iteration[023/030] Train loss: 0.0495
2023-02-06 11:52:00 | Train | Epoch[101/600] Iteration[024/030] Train loss: 0.0494
2023-02-06 11:52:00 | Train | Epoch[101/600] Iteration[025/030] Train loss: 0.0493
2023-02-06 11:52:00 | Train | Epoch[101/600] Iteration[026/030] Train loss: 0.0495
2023-02-06 11:52:00 | Train | Epoch[101/600] Iteration[027/030] Train loss: 0.0495
2023-02-06 11:52:00 | Train | Epoch[101/600] Iteration[028/030] Train loss: 0.0495
2023-02-06 11:52:00 | Train | Epoch[101/600] Iteration[029/030] Train loss: 0.0495
2023-02-06 11:52:00 | Train | Epoch[101/600] Iteration[030/030] Train loss: 0.0495
2023-02-06 11:52:00 | Valid | Epoch[101/600] Iteration[001/008] Valid loss: 0.1274
2023-02-06 11:52:00 | Valid | Epoch[101/600] Iteration[002/008] Valid loss: 0.1311
2023-02-06 11:52:00 | Valid | Epoch[101/600] Iteration[003/008] Valid loss: 0.1375
2023-02-06 11:52:00 | Valid | Epoch[101/600] Iteration[004/008] Valid loss: 0.1350
2023-02-06 11:52:01 | Valid | Epoch[101/600] Iteration[005/008] Valid loss: 0.1370
2023-02-06 11:52:01 | Valid | Epoch[101/600] Iteration[006/008] Valid loss: 0.1346
2023-02-06 11:52:01 | Valid | Epoch[101/600] Iteration[007/008] Valid loss: 0.1323
2023-02-06 11:52:01 | Valid | Epoch[101/600] Iteration[008/008] Valid loss: 0.1360
2023-02-06 11:52:01 | Valid | Epoch[101/600] MIou: 0.5783384130263209
2023-02-06 11:52:01 | Valid | Epoch[101/600] Pixel Accuracy: 0.9302635192871094
2023-02-06 11:52:01 | Valid | Epoch[101/600] Mean Pixel Accuracy: 0.6139393768742345
2023-02-06 11:52:01 | Stage | Epoch[101/600] Train loss:0.0495
2023-02-06 11:52:01 | Stage | Epoch[101/600] Valid loss:0.1360
2023-02-06 11:52:01 | Stage | Epoch[101/600] LR:0.01

2023-02-06 11:52:01 | Train | Epoch[102/600] Iteration[001/030] Train loss: 0.0467
2023-02-06 11:52:01 | Train | Epoch[102/600] Iteration[002/030] Train loss: 0.0480
2023-02-06 11:52:01 | Train | Epoch[102/600] Iteration[003/030] Train loss: 0.0479
2023-02-06 11:52:01 | Train | Epoch[102/600] Iteration[004/030] Train loss: 0.0477
2023-02-06 11:52:01 | Train | Epoch[102/600] Iteration[005/030] Train loss: 0.0475
2023-02-06 11:52:01 | Train | Epoch[102/600] Iteration[006/030] Train loss: 0.0477
2023-02-06 11:52:01 | Train | Epoch[102/600] Iteration[007/030] Train loss: 0.0476
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[008/030] Train loss: 0.0478
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[009/030] Train loss: 0.0480
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[010/030] Train loss: 0.0479
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[011/030] Train loss: 0.0479
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[012/030] Train loss: 0.0478
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[013/030] Train loss: 0.0479
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[014/030] Train loss: 0.0479
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[015/030] Train loss: 0.0481
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[016/030] Train loss: 0.0482
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[017/030] Train loss: 0.0484
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[018/030] Train loss: 0.0483
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[019/030] Train loss: 0.0484
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[020/030] Train loss: 0.0483
2023-02-06 11:52:02 | Train | Epoch[102/600] Iteration[021/030] Train loss: 0.0483
2023-02-06 11:52:03 | Train | Epoch[102/600] Iteration[022/030] Train loss: 0.0484
2023-02-06 11:52:03 | Train | Epoch[102/600] Iteration[023/030] Train loss: 0.0484
2023-02-06 11:52:03 | Train | Epoch[102/600] Iteration[024/030] Train loss: 0.0484
2023-02-06 11:52:03 | Train | Epoch[102/600] Iteration[025/030] Train loss: 0.0484
2023-02-06 11:52:03 | Train | Epoch[102/600] Iteration[026/030] Train loss: 0.0485
2023-02-06 11:52:03 | Train | Epoch[102/600] Iteration[027/030] Train loss: 0.0486
2023-02-06 11:52:03 | Train | Epoch[102/600] Iteration[028/030] Train loss: 0.0486
2023-02-06 11:52:03 | Train | Epoch[102/600] Iteration[029/030] Train loss: 0.0485
2023-02-06 11:52:03 | Train | Epoch[102/600] Iteration[030/030] Train loss: 0.0486
2023-02-06 11:52:03 | Valid | Epoch[102/600] Iteration[001/008] Valid loss: 0.5661
2023-02-06 11:52:03 | Valid | Epoch[102/600] Iteration[002/008] Valid loss: 0.5351
2023-02-06 11:52:03 | Valid | Epoch[102/600] Iteration[003/008] Valid loss: 0.5343
2023-02-06 11:52:03 | Valid | Epoch[102/600] Iteration[004/008] Valid loss: 0.5347
2023-02-06 11:52:03 | Valid | Epoch[102/600] Iteration[005/008] Valid loss: 0.5488
2023-02-06 11:52:04 | Valid | Epoch[102/600] Iteration[006/008] Valid loss: 0.5397
2023-02-06 11:52:04 | Valid | Epoch[102/600] Iteration[007/008] Valid loss: 0.5685
2023-02-06 11:52:04 | Valid | Epoch[102/600] Iteration[008/008] Valid loss: 0.5831
2023-02-06 11:52:04 | Valid | Epoch[102/600] MIou: 0.8606013206539804
2023-02-06 11:52:04 | Valid | Epoch[102/600] Pixel Accuracy: 0.9706281026204427
2023-02-06 11:52:04 | Valid | Epoch[102/600] Mean Pixel Accuracy: 0.9811232092973633
2023-02-06 11:52:04 | Stage | Epoch[102/600] Train loss:0.0486
2023-02-06 11:52:04 | Stage | Epoch[102/600] Valid loss:0.5831
2023-02-06 11:52:04 | Stage | Epoch[102/600] LR:0.01

2023-02-06 11:52:04 | Train | Epoch[103/600] Iteration[001/030] Train loss: 0.0468
2023-02-06 11:52:04 | Train | Epoch[103/600] Iteration[002/030] Train loss: 0.0474
2023-02-06 11:52:04 | Train | Epoch[103/600] Iteration[003/030] Train loss: 0.0480
2023-02-06 11:52:04 | Train | Epoch[103/600] Iteration[004/030] Train loss: 0.0476
2023-02-06 11:52:04 | Train | Epoch[103/600] Iteration[005/030] Train loss: 0.0476
2023-02-06 11:52:04 | Train | Epoch[103/600] Iteration[006/030] Train loss: 0.0477
2023-02-06 11:52:04 | Train | Epoch[103/600] Iteration[007/030] Train loss: 0.0478
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[008/030] Train loss: 0.0480
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[009/030] Train loss: 0.0479
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[010/030] Train loss: 0.0483
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[011/030] Train loss: 0.0483
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[012/030] Train loss: 0.0484
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[013/030] Train loss: 0.0484
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[014/030] Train loss: 0.0482
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[015/030] Train loss: 0.0480
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[016/030] Train loss: 0.0479
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[017/030] Train loss: 0.0481
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[018/030] Train loss: 0.0480
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[019/030] Train loss: 0.0481
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[020/030] Train loss: 0.0480
2023-02-06 11:52:05 | Train | Epoch[103/600] Iteration[021/030] Train loss: 0.0480
2023-02-06 11:52:06 | Train | Epoch[103/600] Iteration[022/030] Train loss: 0.0479
2023-02-06 11:52:06 | Train | Epoch[103/600] Iteration[023/030] Train loss: 0.0479
2023-02-06 11:52:06 | Train | Epoch[103/600] Iteration[024/030] Train loss: 0.0479
2023-02-06 11:52:06 | Train | Epoch[103/600] Iteration[025/030] Train loss: 0.0479
2023-02-06 11:52:06 | Train | Epoch[103/600] Iteration[026/030] Train loss: 0.0479
2023-02-06 11:52:06 | Train | Epoch[103/600] Iteration[027/030] Train loss: 0.0479
2023-02-06 11:52:06 | Train | Epoch[103/600] Iteration[028/030] Train loss: 0.0482
2023-02-06 11:52:06 | Train | Epoch[103/600] Iteration[029/030] Train loss: 0.0482
2023-02-06 11:52:06 | Train | Epoch[103/600] Iteration[030/030] Train loss: 0.0482
2023-02-06 11:52:07 | Valid | Epoch[103/600] Iteration[001/008] Valid loss: 0.2796
2023-02-06 11:52:07 | Valid | Epoch[103/600] Iteration[002/008] Valid loss: 0.2209
2023-02-06 11:52:07 | Valid | Epoch[103/600] Iteration[003/008] Valid loss: 0.2111
2023-02-06 11:52:07 | Valid | Epoch[103/600] Iteration[004/008] Valid loss: 0.2018
2023-02-06 11:52:07 | Valid | Epoch[103/600] Iteration[005/008] Valid loss: 0.2040
2023-02-06 11:52:07 | Valid | Epoch[103/600] Iteration[006/008] Valid loss: 0.1941
2023-02-06 11:52:07 | Valid | Epoch[103/600] Iteration[007/008] Valid loss: 0.2039
2023-02-06 11:52:07 | Valid | Epoch[103/600] Iteration[008/008] Valid loss: 0.1989
2023-02-06 11:52:07 | Valid | Epoch[103/600] MIou: 0.9193217751943046
2023-02-06 11:52:07 | Valid | Epoch[103/600] Pixel Accuracy: 0.9849802652994791
2023-02-06 11:52:07 | Valid | Epoch[103/600] Mean Pixel Accuracy: 0.9834448360230894
2023-02-06 11:52:07 | Stage | Epoch[103/600] Train loss:0.0482
2023-02-06 11:52:07 | Stage | Epoch[103/600] Valid loss:0.1989
2023-02-06 11:52:07 | Stage | Epoch[103/600] LR:0.01

2023-02-06 11:52:07 | Train | Epoch[104/600] Iteration[001/030] Train loss: 0.0466
2023-02-06 11:52:07 | Train | Epoch[104/600] Iteration[002/030] Train loss: 0.0471
2023-02-06 11:52:07 | Train | Epoch[104/600] Iteration[003/030] Train loss: 0.0480
2023-02-06 11:52:07 | Train | Epoch[104/600] Iteration[004/030] Train loss: 0.0483
2023-02-06 11:52:07 | Train | Epoch[104/600] Iteration[005/030] Train loss: 0.0483
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[006/030] Train loss: 0.0486
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[007/030] Train loss: 0.0483
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[008/030] Train loss: 0.0486
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[009/030] Train loss: 0.0486
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[010/030] Train loss: 0.0486
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[011/030] Train loss: 0.0484
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[012/030] Train loss: 0.0487
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[013/030] Train loss: 0.0484
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[014/030] Train loss: 0.0485
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[015/030] Train loss: 0.0486
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[016/030] Train loss: 0.0484
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[017/030] Train loss: 0.0483
2023-02-06 11:52:08 | Train | Epoch[104/600] Iteration[018/030] Train loss: 0.0481
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[019/030] Train loss: 0.0479
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[020/030] Train loss: 0.0480
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[021/030] Train loss: 0.0480
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[022/030] Train loss: 0.0479
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[023/030] Train loss: 0.0479
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[024/030] Train loss: 0.0480
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[025/030] Train loss: 0.0480
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[026/030] Train loss: 0.0480
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[027/030] Train loss: 0.0480
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[028/030] Train loss: 0.0479
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[029/030] Train loss: 0.0478
2023-02-06 11:52:09 | Train | Epoch[104/600] Iteration[030/030] Train loss: 0.0479
2023-02-06 11:52:10 | Valid | Epoch[104/600] Iteration[001/008] Valid loss: 0.2078
2023-02-06 11:52:10 | Valid | Epoch[104/600] Iteration[002/008] Valid loss: 0.1687
2023-02-06 11:52:10 | Valid | Epoch[104/600] Iteration[003/008] Valid loss: 0.1650
2023-02-06 11:52:10 | Valid | Epoch[104/600] Iteration[004/008] Valid loss: 0.1604
2023-02-06 11:52:10 | Valid | Epoch[104/600] Iteration[005/008] Valid loss: 0.1649
2023-02-06 11:52:10 | Valid | Epoch[104/600] Iteration[006/008] Valid loss: 0.1552
2023-02-06 11:52:10 | Valid | Epoch[104/600] Iteration[007/008] Valid loss: 0.1679
2023-02-06 11:52:10 | Valid | Epoch[104/600] Iteration[008/008] Valid loss: 0.1680
2023-02-06 11:52:10 | Valid | Epoch[104/600] MIou: 0.9088272275434804
2023-02-06 11:52:10 | Valid | Epoch[104/600] Pixel Accuracy: 0.9829368591308594
2023-02-06 11:52:10 | Valid | Epoch[104/600] Mean Pixel Accuracy: 0.9750808743768555
2023-02-06 11:52:10 | Stage | Epoch[104/600] Train loss:0.0479
2023-02-06 11:52:10 | Stage | Epoch[104/600] Valid loss:0.1680
2023-02-06 11:52:10 | Stage | Epoch[104/600] LR:0.01

2023-02-06 11:52:10 | Train | Epoch[105/600] Iteration[001/030] Train loss: 0.0453
2023-02-06 11:52:10 | Train | Epoch[105/600] Iteration[002/030] Train loss: 0.0451
2023-02-06 11:52:10 | Train | Epoch[105/600] Iteration[003/030] Train loss: 0.0459
2023-02-06 11:52:10 | Train | Epoch[105/600] Iteration[004/030] Train loss: 0.0460
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[005/030] Train loss: 0.0457
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[006/030] Train loss: 0.0459
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[007/030] Train loss: 0.0460
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[008/030] Train loss: 0.0461
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[009/030] Train loss: 0.0464
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[010/030] Train loss: 0.0465
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[011/030] Train loss: 0.0463
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[012/030] Train loss: 0.0462
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[013/030] Train loss: 0.0465
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[014/030] Train loss: 0.0464
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[015/030] Train loss: 0.0465
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[016/030] Train loss: 0.0464
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[017/030] Train loss: 0.0467
2023-02-06 11:52:11 | Train | Epoch[105/600] Iteration[018/030] Train loss: 0.0466
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[019/030] Train loss: 0.0466
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[020/030] Train loss: 0.0466
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[021/030] Train loss: 0.0467
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[022/030] Train loss: 0.0468
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[023/030] Train loss: 0.0468
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[024/030] Train loss: 0.0468
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[025/030] Train loss: 0.0469
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[026/030] Train loss: 0.0469
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[027/030] Train loss: 0.0470
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[028/030] Train loss: 0.0470
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[029/030] Train loss: 0.0471
2023-02-06 11:52:12 | Train | Epoch[105/600] Iteration[030/030] Train loss: 0.0471
2023-02-06 11:52:13 | Valid | Epoch[105/600] Iteration[001/008] Valid loss: 0.1057
2023-02-06 11:52:13 | Valid | Epoch[105/600] Iteration[002/008] Valid loss: 0.0838
2023-02-06 11:52:13 | Valid | Epoch[105/600] Iteration[003/008] Valid loss: 0.0859
2023-02-06 11:52:13 | Valid | Epoch[105/600] Iteration[004/008] Valid loss: 0.0809
2023-02-06 11:52:13 | Valid | Epoch[105/600] Iteration[005/008] Valid loss: 0.0804
2023-02-06 11:52:13 | Valid | Epoch[105/600] Iteration[006/008] Valid loss: 0.0783
2023-02-06 11:52:13 | Valid | Epoch[105/600] Iteration[007/008] Valid loss: 0.0804
2023-02-06 11:52:13 | Valid | Epoch[105/600] Iteration[008/008] Valid loss: 0.0793
2023-02-06 11:52:13 | Valid | Epoch[105/600] MIou: 0.9377785726581002
2023-02-06 11:52:13 | Valid | Epoch[105/600] Pixel Accuracy: 0.9891866048177084
2023-02-06 11:52:13 | Valid | Epoch[105/600] Mean Pixel Accuracy: 0.9685424394630531
2023-02-06 11:52:13 | Stage | Epoch[105/600] Train loss:0.0471
2023-02-06 11:52:13 | Stage | Epoch[105/600] Valid loss:0.0793
2023-02-06 11:52:13 | Stage | Epoch[105/600] LR:0.01

2023-02-06 11:52:13 | Train | Epoch[106/600] Iteration[001/030] Train loss: 0.0442
2023-02-06 11:52:13 | Train | Epoch[106/600] Iteration[002/030] Train loss: 0.0444
2023-02-06 11:52:13 | Train | Epoch[106/600] Iteration[003/030] Train loss: 0.0455
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[004/030] Train loss: 0.0457
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[005/030] Train loss: 0.0460
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[006/030] Train loss: 0.0462
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[007/030] Train loss: 0.0464
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[008/030] Train loss: 0.0463
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[009/030] Train loss: 0.0467
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[010/030] Train loss: 0.0470
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[011/030] Train loss: 0.0469
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[012/030] Train loss: 0.0470
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[013/030] Train loss: 0.0472
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[014/030] Train loss: 0.0472
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[015/030] Train loss: 0.0472
2023-02-06 11:52:14 | Train | Epoch[106/600] Iteration[016/030] Train loss: 0.0471
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[017/030] Train loss: 0.0473
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[018/030] Train loss: 0.0472
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[019/030] Train loss: 0.0471
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[020/030] Train loss: 0.0472
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[021/030] Train loss: 0.0472
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[022/030] Train loss: 0.0473
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[023/030] Train loss: 0.0471
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[024/030] Train loss: 0.0472
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[025/030] Train loss: 0.0472
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[026/030] Train loss: 0.0471
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[027/030] Train loss: 0.0471
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[028/030] Train loss: 0.0471
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[029/030] Train loss: 0.0471
2023-02-06 11:52:15 | Train | Epoch[106/600] Iteration[030/030] Train loss: 0.0471
2023-02-06 11:52:16 | Valid | Epoch[106/600] Iteration[001/008] Valid loss: 0.3999
2023-02-06 11:52:16 | Valid | Epoch[106/600] Iteration[002/008] Valid loss: 0.3357
2023-02-06 11:52:16 | Valid | Epoch[106/600] Iteration[003/008] Valid loss: 0.3324
2023-02-06 11:52:16 | Valid | Epoch[106/600] Iteration[004/008] Valid loss: 0.3249
2023-02-06 11:52:16 | Valid | Epoch[106/600] Iteration[005/008] Valid loss: 0.3362
2023-02-06 11:52:16 | Valid | Epoch[106/600] Iteration[006/008] Valid loss: 0.3201
2023-02-06 11:52:16 | Valid | Epoch[106/600] Iteration[007/008] Valid loss: 0.3371
2023-02-06 11:52:16 | Valid | Epoch[106/600] Iteration[008/008] Valid loss: 0.3371
2023-02-06 11:52:16 | Valid | Epoch[106/600] MIou: 0.8898399627927013
2023-02-06 11:52:16 | Valid | Epoch[106/600] Pixel Accuracy: 0.9781659444173177
2023-02-06 11:52:16 | Valid | Epoch[106/600] Mean Pixel Accuracy: 0.9832690801037978
2023-02-06 11:52:16 | Stage | Epoch[106/600] Train loss:0.0471
2023-02-06 11:52:16 | Stage | Epoch[106/600] Valid loss:0.3371
2023-02-06 11:52:16 | Stage | Epoch[106/600] LR:0.01

2023-02-06 11:52:16 | Train | Epoch[107/600] Iteration[001/030] Train loss: 0.0459
2023-02-06 11:52:16 | Train | Epoch[107/600] Iteration[002/030] Train loss: 0.0476
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[003/030] Train loss: 0.0469
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[004/030] Train loss: 0.0464
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[005/030] Train loss: 0.0462
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[006/030] Train loss: 0.0457
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[007/030] Train loss: 0.0456
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[008/030] Train loss: 0.0457
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[009/030] Train loss: 0.0455
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[010/030] Train loss: 0.0459
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[011/030] Train loss: 0.0458
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[012/030] Train loss: 0.0457
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[013/030] Train loss: 0.0457
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[014/030] Train loss: 0.0456
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[015/030] Train loss: 0.0455
2023-02-06 11:52:17 | Train | Epoch[107/600] Iteration[016/030] Train loss: 0.0455
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[017/030] Train loss: 0.0456
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[018/030] Train loss: 0.0457
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[019/030] Train loss: 0.0457
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[020/030] Train loss: 0.0457
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[021/030] Train loss: 0.0456
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[022/030] Train loss: 0.0457
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[023/030] Train loss: 0.0457
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[024/030] Train loss: 0.0457
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[025/030] Train loss: 0.0457
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[026/030] Train loss: 0.0457
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[027/030] Train loss: 0.0457
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[028/030] Train loss: 0.0458
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[029/030] Train loss: 0.0457
2023-02-06 11:52:18 | Train | Epoch[107/600] Iteration[030/030] Train loss: 0.0459
2023-02-06 11:52:19 | Valid | Epoch[107/600] Iteration[001/008] Valid loss: 0.1981
2023-02-06 11:52:19 | Valid | Epoch[107/600] Iteration[002/008] Valid loss: 0.1611
2023-02-06 11:52:19 | Valid | Epoch[107/600] Iteration[003/008] Valid loss: 0.1528
2023-02-06 11:52:19 | Valid | Epoch[107/600] Iteration[004/008] Valid loss: 0.1544
2023-02-06 11:52:19 | Valid | Epoch[107/600] Iteration[005/008] Valid loss: 0.1591
2023-02-06 11:52:19 | Valid | Epoch[107/600] Iteration[006/008] Valid loss: 0.1555
2023-02-06 11:52:19 | Valid | Epoch[107/600] Iteration[007/008] Valid loss: 0.1697
2023-02-06 11:52:19 | Valid | Epoch[107/600] Iteration[008/008] Valid loss: 0.1670
2023-02-06 11:52:19 | Valid | Epoch[107/600] MIou: 0.9089347468025306
2023-02-06 11:52:19 | Valid | Epoch[107/600] Pixel Accuracy: 0.982842763264974
2023-02-06 11:52:19 | Valid | Epoch[107/600] Mean Pixel Accuracy: 0.978491052721469
2023-02-06 11:52:19 | Stage | Epoch[107/600] Train loss:0.0459
2023-02-06 11:52:19 | Stage | Epoch[107/600] Valid loss:0.1670
2023-02-06 11:52:19 | Stage | Epoch[107/600] LR:0.01

2023-02-06 11:52:19 | Train | Epoch[108/600] Iteration[001/030] Train loss: 0.0456
2023-02-06 11:52:19 | Train | Epoch[108/600] Iteration[002/030] Train loss: 0.0476
2023-02-06 11:52:19 | Train | Epoch[108/600] Iteration[003/030] Train loss: 0.0475
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[004/030] Train loss: 0.0473
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[005/030] Train loss: 0.0471
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[006/030] Train loss: 0.0467
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[007/030] Train loss: 0.0467
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[008/030] Train loss: 0.0471
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[009/030] Train loss: 0.0467
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[010/030] Train loss: 0.0465
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[011/030] Train loss: 0.0462
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[012/030] Train loss: 0.0460
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[013/030] Train loss: 0.0459
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[014/030] Train loss: 0.0457
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[015/030] Train loss: 0.0455
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[016/030] Train loss: 0.0454
2023-02-06 11:52:20 | Train | Epoch[108/600] Iteration[017/030] Train loss: 0.0454
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[018/030] Train loss: 0.0453
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[019/030] Train loss: 0.0454
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[020/030] Train loss: 0.0454
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[021/030] Train loss: 0.0454
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[022/030] Train loss: 0.0453
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[023/030] Train loss: 0.0454
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[024/030] Train loss: 0.0453
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[025/030] Train loss: 0.0452
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[026/030] Train loss: 0.0453
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[027/030] Train loss: 0.0454
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[028/030] Train loss: 0.0455
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[029/030] Train loss: 0.0454
2023-02-06 11:52:21 | Train | Epoch[108/600] Iteration[030/030] Train loss: 0.0454
2023-02-06 11:52:22 | Valid | Epoch[108/600] Iteration[001/008] Valid loss: 0.1868
2023-02-06 11:52:22 | Valid | Epoch[108/600] Iteration[002/008] Valid loss: 0.1464
2023-02-06 11:52:22 | Valid | Epoch[108/600] Iteration[003/008] Valid loss: 0.1376
2023-02-06 11:52:22 | Valid | Epoch[108/600] Iteration[004/008] Valid loss: 0.1302
2023-02-06 11:52:22 | Valid | Epoch[108/600] Iteration[005/008] Valid loss: 0.1275
2023-02-06 11:52:22 | Valid | Epoch[108/600] Iteration[006/008] Valid loss: 0.1238
2023-02-06 11:52:22 | Valid | Epoch[108/600] Iteration[007/008] Valid loss: 0.1304
2023-02-06 11:52:22 | Valid | Epoch[108/600] Iteration[008/008] Valid loss: 0.1316
2023-02-06 11:52:22 | Valid | Epoch[108/600] MIou: 0.9215225861563903
2023-02-06 11:52:22 | Valid | Epoch[108/600] Pixel Accuracy: 0.9856160481770834
2023-02-06 11:52:22 | Valid | Epoch[108/600] Mean Pixel Accuracy: 0.9779990984460636
2023-02-06 11:52:22 | Stage | Epoch[108/600] Train loss:0.0454
2023-02-06 11:52:22 | Stage | Epoch[108/600] Valid loss:0.1316
2023-02-06 11:52:22 | Stage | Epoch[108/600] LR:0.01

2023-02-06 11:52:22 | Train | Epoch[109/600] Iteration[001/030] Train loss: 0.0426
2023-02-06 11:52:22 | Train | Epoch[109/600] Iteration[002/030] Train loss: 0.0437
2023-02-06 11:52:22 | Train | Epoch[109/600] Iteration[003/030] Train loss: 0.0468
2023-02-06 11:52:22 | Train | Epoch[109/600] Iteration[004/030] Train loss: 0.0461
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[005/030] Train loss: 0.0458
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[006/030] Train loss: 0.0453
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[007/030] Train loss: 0.0452
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[008/030] Train loss: 0.0454
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[009/030] Train loss: 0.0452
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[010/030] Train loss: 0.0452
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[011/030] Train loss: 0.0456
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[012/030] Train loss: 0.0456
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[013/030] Train loss: 0.0453
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[014/030] Train loss: 0.0456
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[015/030] Train loss: 0.0456
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[016/030] Train loss: 0.0456
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[017/030] Train loss: 0.0455
2023-02-06 11:52:23 | Train | Epoch[109/600] Iteration[018/030] Train loss: 0.0455
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[019/030] Train loss: 0.0455
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[020/030] Train loss: 0.0456
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[021/030] Train loss: 0.0456
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[022/030] Train loss: 0.0455
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[023/030] Train loss: 0.0455
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[024/030] Train loss: 0.0455
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[025/030] Train loss: 0.0454
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[026/030] Train loss: 0.0453
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[027/030] Train loss: 0.0454
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[028/030] Train loss: 0.0453
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[029/030] Train loss: 0.0453
2023-02-06 11:52:24 | Train | Epoch[109/600] Iteration[030/030] Train loss: 0.0452
2023-02-06 11:52:25 | Valid | Epoch[109/600] Iteration[001/008] Valid loss: 0.1012
2023-02-06 11:52:25 | Valid | Epoch[109/600] Iteration[002/008] Valid loss: 0.0774
2023-02-06 11:52:25 | Valid | Epoch[109/600] Iteration[003/008] Valid loss: 0.0714
2023-02-06 11:52:25 | Valid | Epoch[109/600] Iteration[004/008] Valid loss: 0.0677
2023-02-06 11:52:25 | Valid | Epoch[109/600] Iteration[005/008] Valid loss: 0.0668
2023-02-06 11:52:25 | Valid | Epoch[109/600] Iteration[006/008] Valid loss: 0.0649
2023-02-06 11:52:25 | Valid | Epoch[109/600] Iteration[007/008] Valid loss: 0.0668
2023-02-06 11:52:25 | Valid | Epoch[109/600] Iteration[008/008] Valid loss: 0.0661
2023-02-06 11:52:25 | Valid | Epoch[109/600] MIou: 0.9328382884456188
2023-02-06 11:52:25 | Valid | Epoch[109/600] Pixel Accuracy: 0.9884821573893229
2023-02-06 11:52:25 | Valid | Epoch[109/600] Mean Pixel Accuracy: 0.9575539767442588
2023-02-06 11:52:25 | Stage | Epoch[109/600] Train loss:0.0452
2023-02-06 11:52:25 | Stage | Epoch[109/600] Valid loss:0.0661
2023-02-06 11:52:25 | Stage | Epoch[109/600] LR:0.01

2023-02-06 11:52:25 | Train | Epoch[110/600] Iteration[001/030] Train loss: 0.0429
2023-02-06 11:52:25 | Train | Epoch[110/600] Iteration[002/030] Train loss: 0.0431
2023-02-06 11:52:25 | Train | Epoch[110/600] Iteration[003/030] Train loss: 0.0435
2023-02-06 11:52:25 | Train | Epoch[110/600] Iteration[004/030] Train loss: 0.0435
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[005/030] Train loss: 0.0435
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[006/030] Train loss: 0.0437
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[007/030] Train loss: 0.0443
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[008/030] Train loss: 0.0445
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[009/030] Train loss: 0.0444
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[010/030] Train loss: 0.0445
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[011/030] Train loss: 0.0445
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[012/030] Train loss: 0.0443
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[013/030] Train loss: 0.0444
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[014/030] Train loss: 0.0445
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[015/030] Train loss: 0.0445
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[016/030] Train loss: 0.0444
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[017/030] Train loss: 0.0442
2023-02-06 11:52:26 | Train | Epoch[110/600] Iteration[018/030] Train loss: 0.0444
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[019/030] Train loss: 0.0446
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[020/030] Train loss: 0.0446
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[021/030] Train loss: 0.0446
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[022/030] Train loss: 0.0447
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[023/030] Train loss: 0.0446
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[024/030] Train loss: 0.0446
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[025/030] Train loss: 0.0446
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[026/030] Train loss: 0.0445
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[027/030] Train loss: 0.0445
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[028/030] Train loss: 0.0445
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[029/030] Train loss: 0.0446
2023-02-06 11:52:27 | Train | Epoch[110/600] Iteration[030/030] Train loss: 0.0445
2023-02-06 11:52:28 | Valid | Epoch[110/600] Iteration[001/008] Valid loss: 0.0621
2023-02-06 11:52:28 | Valid | Epoch[110/600] Iteration[002/008] Valid loss: 0.0581
2023-02-06 11:52:28 | Valid | Epoch[110/600] Iteration[003/008] Valid loss: 0.0577
2023-02-06 11:52:28 | Valid | Epoch[110/600] Iteration[004/008] Valid loss: 0.0560
2023-02-06 11:52:28 | Valid | Epoch[110/600] Iteration[005/008] Valid loss: 0.0561
2023-02-06 11:52:28 | Valid | Epoch[110/600] Iteration[006/008] Valid loss: 0.0558
2023-02-06 11:52:28 | Valid | Epoch[110/600] Iteration[007/008] Valid loss: 0.0565
2023-02-06 11:52:28 | Valid | Epoch[110/600] Iteration[008/008] Valid loss: 0.0566
2023-02-06 11:52:28 | Valid | Epoch[110/600] MIou: 0.9043888166999468
2023-02-06 11:52:28 | Valid | Epoch[110/600] Pixel Accuracy: 0.9839935302734375
2023-02-06 11:52:28 | Valid | Epoch[110/600] Mean Pixel Accuracy: 0.9199986664982021
2023-02-06 11:52:28 | Stage | Epoch[110/600] Train loss:0.0445
2023-02-06 11:52:28 | Stage | Epoch[110/600] Valid loss:0.0566
2023-02-06 11:52:28 | Stage | Epoch[110/600] LR:0.01

2023-02-06 11:52:28 | Train | Epoch[111/600] Iteration[001/030] Train loss: 0.0429
2023-02-06 11:52:28 | Train | Epoch[111/600] Iteration[002/030] Train loss: 0.0427
2023-02-06 11:52:28 | Train | Epoch[111/600] Iteration[003/030] Train loss: 0.0427
2023-02-06 11:52:28 | Train | Epoch[111/600] Iteration[004/030] Train loss: 0.0424
2023-02-06 11:52:28 | Train | Epoch[111/600] Iteration[005/030] Train loss: 0.0428
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[006/030] Train loss: 0.0439
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[007/030] Train loss: 0.0440
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[008/030] Train loss: 0.0440
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[009/030] Train loss: 0.0441
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[010/030] Train loss: 0.0445
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[011/030] Train loss: 0.0446
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[012/030] Train loss: 0.0443
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[013/030] Train loss: 0.0442
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[014/030] Train loss: 0.0442
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[015/030] Train loss: 0.0442
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[016/030] Train loss: 0.0442
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[017/030] Train loss: 0.0442
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[018/030] Train loss: 0.0443
2023-02-06 11:52:29 | Train | Epoch[111/600] Iteration[019/030] Train loss: 0.0443
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[020/030] Train loss: 0.0441
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[021/030] Train loss: 0.0440
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[022/030] Train loss: 0.0441
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[023/030] Train loss: 0.0442
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[024/030] Train loss: 0.0441
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[025/030] Train loss: 0.0441
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[026/030] Train loss: 0.0441
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[027/030] Train loss: 0.0439
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[028/030] Train loss: 0.0439
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[029/030] Train loss: 0.0440
2023-02-06 11:52:30 | Train | Epoch[111/600] Iteration[030/030] Train loss: 0.0441
2023-02-06 11:52:31 | Valid | Epoch[111/600] Iteration[001/008] Valid loss: 0.0710
2023-02-06 11:52:31 | Valid | Epoch[111/600] Iteration[002/008] Valid loss: 0.0609
2023-02-06 11:52:31 | Valid | Epoch[111/600] Iteration[003/008] Valid loss: 0.0605
2023-02-06 11:52:31 | Valid | Epoch[111/600] Iteration[004/008] Valid loss: 0.0581
2023-02-06 11:52:31 | Valid | Epoch[111/600] Iteration[005/008] Valid loss: 0.0582
2023-02-06 11:52:31 | Valid | Epoch[111/600] Iteration[006/008] Valid loss: 0.0571
2023-02-06 11:52:31 | Valid | Epoch[111/600] Iteration[007/008] Valid loss: 0.0573
2023-02-06 11:52:31 | Valid | Epoch[111/600] Iteration[008/008] Valid loss: 0.0569
2023-02-06 11:52:31 | Valid | Epoch[111/600] MIou: 0.9057593410543354
2023-02-06 11:52:31 | Valid | Epoch[111/600] Pixel Accuracy: 0.9843254089355469
2023-02-06 11:52:31 | Valid | Epoch[111/600] Mean Pixel Accuracy: 0.9185452395150635
2023-02-06 11:52:31 | Stage | Epoch[111/600] Train loss:0.0441
2023-02-06 11:52:31 | Stage | Epoch[111/600] Valid loss:0.0569
2023-02-06 11:52:31 | Stage | Epoch[111/600] LR:0.01

2023-02-06 11:52:31 | Train | Epoch[112/600] Iteration[001/030] Train loss: 0.0402
2023-02-06 11:52:31 | Train | Epoch[112/600] Iteration[002/030] Train loss: 0.0415
2023-02-06 11:52:31 | Train | Epoch[112/600] Iteration[003/030] Train loss: 0.0431
2023-02-06 11:52:31 | Train | Epoch[112/600] Iteration[004/030] Train loss: 0.0429
2023-02-06 11:52:31 | Train | Epoch[112/600] Iteration[005/030] Train loss: 0.0426
2023-02-06 11:52:31 | Train | Epoch[112/600] Iteration[006/030] Train loss: 0.0425
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[007/030] Train loss: 0.0427
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[008/030] Train loss: 0.0428
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[009/030] Train loss: 0.0426
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[010/030] Train loss: 0.0429
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[011/030] Train loss: 0.0428
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[012/030] Train loss: 0.0428
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[013/030] Train loss: 0.0431
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[014/030] Train loss: 0.0431
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[015/030] Train loss: 0.0430
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[016/030] Train loss: 0.0430
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[017/030] Train loss: 0.0428
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[018/030] Train loss: 0.0428
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[019/030] Train loss: 0.0428
2023-02-06 11:52:32 | Train | Epoch[112/600] Iteration[020/030] Train loss: 0.0429
2023-02-06 11:52:33 | Train | Epoch[112/600] Iteration[021/030] Train loss: 0.0430
2023-02-06 11:52:33 | Train | Epoch[112/600] Iteration[022/030] Train loss: 0.0431
2023-02-06 11:52:33 | Train | Epoch[112/600] Iteration[023/030] Train loss: 0.0431
2023-02-06 11:52:33 | Train | Epoch[112/600] Iteration[024/030] Train loss: 0.0431
2023-02-06 11:52:33 | Train | Epoch[112/600] Iteration[025/030] Train loss: 0.0432
2023-02-06 11:52:33 | Train | Epoch[112/600] Iteration[026/030] Train loss: 0.0434
2023-02-06 11:52:33 | Train | Epoch[112/600] Iteration[027/030] Train loss: 0.0435
2023-02-06 11:52:33 | Train | Epoch[112/600] Iteration[028/030] Train loss: 0.0435
2023-02-06 11:52:33 | Train | Epoch[112/600] Iteration[029/030] Train loss: 0.0435
2023-02-06 11:52:33 | Train | Epoch[112/600] Iteration[030/030] Train loss: 0.0434
2023-02-06 11:52:33 | Valid | Epoch[112/600] Iteration[001/008] Valid loss: 0.0981
2023-02-06 11:52:34 | Valid | Epoch[112/600] Iteration[002/008] Valid loss: 0.0866
2023-02-06 11:52:34 | Valid | Epoch[112/600] Iteration[003/008] Valid loss: 0.0820
2023-02-06 11:52:34 | Valid | Epoch[112/600] Iteration[004/008] Valid loss: 0.0809
2023-02-06 11:52:34 | Valid | Epoch[112/600] Iteration[005/008] Valid loss: 0.0806
2023-02-06 11:52:34 | Valid | Epoch[112/600] Iteration[006/008] Valid loss: 0.0784
2023-02-06 11:52:34 | Valid | Epoch[112/600] Iteration[007/008] Valid loss: 0.0825
2023-02-06 11:52:34 | Valid | Epoch[112/600] Iteration[008/008] Valid loss: 0.0820
2023-02-06 11:52:34 | Valid | Epoch[112/600] MIou: 0.9131552991797041
2023-02-06 11:52:34 | Valid | Epoch[112/600] Pixel Accuracy: 0.9847920735677084
2023-02-06 11:52:34 | Valid | Epoch[112/600] Mean Pixel Accuracy: 0.9480566738564008
2023-02-06 11:52:34 | Stage | Epoch[112/600] Train loss:0.0434
2023-02-06 11:52:34 | Stage | Epoch[112/600] Valid loss:0.0820
2023-02-06 11:52:34 | Stage | Epoch[112/600] LR:0.01

2023-02-06 11:52:34 | Train | Epoch[113/600] Iteration[001/030] Train loss: 0.0462
2023-02-06 11:52:34 | Train | Epoch[113/600] Iteration[002/030] Train loss: 0.0517
2023-02-06 11:52:34 | Train | Epoch[113/600] Iteration[003/030] Train loss: 0.0481
2023-02-06 11:52:34 | Train | Epoch[113/600] Iteration[004/030] Train loss: 0.0463
2023-02-06 11:52:34 | Train | Epoch[113/600] Iteration[005/030] Train loss: 0.0454
2023-02-06 11:52:34 | Train | Epoch[113/600] Iteration[006/030] Train loss: 0.0451
2023-02-06 11:52:34 | Train | Epoch[113/600] Iteration[007/030] Train loss: 0.0452
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[008/030] Train loss: 0.0451
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[009/030] Train loss: 0.0450
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[010/030] Train loss: 0.0449
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[011/030] Train loss: 0.0445
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[012/030] Train loss: 0.0446
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[013/030] Train loss: 0.0444
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[014/030] Train loss: 0.0444
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[015/030] Train loss: 0.0444
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[016/030] Train loss: 0.0443
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[017/030] Train loss: 0.0443
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[018/030] Train loss: 0.0442
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[019/030] Train loss: 0.0441
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[020/030] Train loss: 0.0440
2023-02-06 11:52:35 | Train | Epoch[113/600] Iteration[021/030] Train loss: 0.0440
2023-02-06 11:52:36 | Train | Epoch[113/600] Iteration[022/030] Train loss: 0.0439
2023-02-06 11:52:36 | Train | Epoch[113/600] Iteration[023/030] Train loss: 0.0439
2023-02-06 11:52:36 | Train | Epoch[113/600] Iteration[024/030] Train loss: 0.0440
2023-02-06 11:52:36 | Train | Epoch[113/600] Iteration[025/030] Train loss: 0.0439
2023-02-06 11:52:36 | Train | Epoch[113/600] Iteration[026/030] Train loss: 0.0438
2023-02-06 11:52:36 | Train | Epoch[113/600] Iteration[027/030] Train loss: 0.0437
2023-02-06 11:52:36 | Train | Epoch[113/600] Iteration[028/030] Train loss: 0.0436
2023-02-06 11:52:36 | Train | Epoch[113/600] Iteration[029/030] Train loss: 0.0436
2023-02-06 11:52:36 | Train | Epoch[113/600] Iteration[030/030] Train loss: 0.0436
2023-02-06 11:52:36 | Valid | Epoch[113/600] Iteration[001/008] Valid loss: 0.0686
2023-02-06 11:52:36 | Valid | Epoch[113/600] Iteration[002/008] Valid loss: 0.0615
2023-02-06 11:52:36 | Valid | Epoch[113/600] Iteration[003/008] Valid loss: 0.0616
2023-02-06 11:52:36 | Valid | Epoch[113/600] Iteration[004/008] Valid loss: 0.0594
2023-02-06 11:52:37 | Valid | Epoch[113/600] Iteration[005/008] Valid loss: 0.0597
2023-02-06 11:52:37 | Valid | Epoch[113/600] Iteration[006/008] Valid loss: 0.0584
2023-02-06 11:52:37 | Valid | Epoch[113/600] Iteration[007/008] Valid loss: 0.0585
2023-02-06 11:52:37 | Valid | Epoch[113/600] Iteration[008/008] Valid loss: 0.0582
2023-02-06 11:52:37 | Valid | Epoch[113/600] MIou: 0.8932299556246539
2023-02-06 11:52:37 | Valid | Epoch[113/600] Pixel Accuracy: 0.9822349548339844
2023-02-06 11:52:37 | Valid | Epoch[113/600] Mean Pixel Accuracy: 0.9070549277489315
2023-02-06 11:52:37 | Stage | Epoch[113/600] Train loss:0.0436
2023-02-06 11:52:37 | Stage | Epoch[113/600] Valid loss:0.0582
2023-02-06 11:52:37 | Stage | Epoch[113/600] LR:0.01

2023-02-06 11:52:37 | Train | Epoch[114/600] Iteration[001/030] Train loss: 0.0435
2023-02-06 11:52:37 | Train | Epoch[114/600] Iteration[002/030] Train loss: 0.0428
2023-02-06 11:52:37 | Train | Epoch[114/600] Iteration[003/030] Train loss: 0.0424
2023-02-06 11:52:37 | Train | Epoch[114/600] Iteration[004/030] Train loss: 0.0416
2023-02-06 11:52:37 | Train | Epoch[114/600] Iteration[005/030] Train loss: 0.0418
2023-02-06 11:52:37 | Train | Epoch[114/600] Iteration[006/030] Train loss: 0.0416
2023-02-06 11:52:37 | Train | Epoch[114/600] Iteration[007/030] Train loss: 0.0418
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[008/030] Train loss: 0.0421
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[009/030] Train loss: 0.0419
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[010/030] Train loss: 0.0419
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[011/030] Train loss: 0.0422
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[012/030] Train loss: 0.0421
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[013/030] Train loss: 0.0421
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[014/030] Train loss: 0.0422
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[015/030] Train loss: 0.0422
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[016/030] Train loss: 0.0422
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[017/030] Train loss: 0.0424
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[018/030] Train loss: 0.0423
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[019/030] Train loss: 0.0423
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[020/030] Train loss: 0.0422
2023-02-06 11:52:38 | Train | Epoch[114/600] Iteration[021/030] Train loss: 0.0424
2023-02-06 11:52:39 | Train | Epoch[114/600] Iteration[022/030] Train loss: 0.0424
2023-02-06 11:52:39 | Train | Epoch[114/600] Iteration[023/030] Train loss: 0.0425
2023-02-06 11:52:39 | Train | Epoch[114/600] Iteration[024/030] Train loss: 0.0425
2023-02-06 11:52:39 | Train | Epoch[114/600] Iteration[025/030] Train loss: 0.0426
2023-02-06 11:52:39 | Train | Epoch[114/600] Iteration[026/030] Train loss: 0.0426
2023-02-06 11:52:39 | Train | Epoch[114/600] Iteration[027/030] Train loss: 0.0426
2023-02-06 11:52:39 | Train | Epoch[114/600] Iteration[028/030] Train loss: 0.0426
2023-02-06 11:52:39 | Train | Epoch[114/600] Iteration[029/030] Train loss: 0.0425
2023-02-06 11:52:39 | Train | Epoch[114/600] Iteration[030/030] Train loss: 0.0425
2023-02-06 11:52:39 | Valid | Epoch[114/600] Iteration[001/008] Valid loss: 0.3314
2023-02-06 11:52:39 | Valid | Epoch[114/600] Iteration[002/008] Valid loss: 0.2715
2023-02-06 11:52:39 | Valid | Epoch[114/600] Iteration[003/008] Valid loss: 0.2679
2023-02-06 11:52:39 | Valid | Epoch[114/600] Iteration[004/008] Valid loss: 0.2652
2023-02-06 11:52:40 | Valid | Epoch[114/600] Iteration[005/008] Valid loss: 0.2760
2023-02-06 11:52:40 | Valid | Epoch[114/600] Iteration[006/008] Valid loss: 0.2642
2023-02-06 11:52:40 | Valid | Epoch[114/600] Iteration[007/008] Valid loss: 0.2894
2023-02-06 11:52:40 | Valid | Epoch[114/600] Iteration[008/008] Valid loss: 0.2882
2023-02-06 11:52:40 | Valid | Epoch[114/600] MIou: 0.886876322337095
2023-02-06 11:52:40 | Valid | Epoch[114/600] Pixel Accuracy: 0.9776051839192709
2023-02-06 11:52:40 | Valid | Epoch[114/600] Mean Pixel Accuracy: 0.9793721553423773
2023-02-06 11:52:40 | Stage | Epoch[114/600] Train loss:0.0425
2023-02-06 11:52:40 | Stage | Epoch[114/600] Valid loss:0.2882
2023-02-06 11:52:40 | Stage | Epoch[114/600] LR:0.01

2023-02-06 11:52:40 | Train | Epoch[115/600] Iteration[001/030] Train loss: 0.0409
2023-02-06 11:52:40 | Train | Epoch[115/600] Iteration[002/030] Train loss: 0.0414
2023-02-06 11:52:40 | Train | Epoch[115/600] Iteration[003/030] Train loss: 0.0425
2023-02-06 11:52:40 | Train | Epoch[115/600] Iteration[004/030] Train loss: 0.0436
2023-02-06 11:52:40 | Train | Epoch[115/600] Iteration[005/030] Train loss: 0.0433
2023-02-06 11:52:40 | Train | Epoch[115/600] Iteration[006/030] Train loss: 0.0431
2023-02-06 11:52:40 | Train | Epoch[115/600] Iteration[007/030] Train loss: 0.0432
2023-02-06 11:52:40 | Train | Epoch[115/600] Iteration[008/030] Train loss: 0.0433
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[009/030] Train loss: 0.0431
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[010/030] Train loss: 0.0432
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[011/030] Train loss: 0.0431
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[012/030] Train loss: 0.0428
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[013/030] Train loss: 0.0427
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[014/030] Train loss: 0.0426
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[015/030] Train loss: 0.0427
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[016/030] Train loss: 0.0425
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[017/030] Train loss: 0.0425
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[018/030] Train loss: 0.0425
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[019/030] Train loss: 0.0425
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[020/030] Train loss: 0.0425
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[021/030] Train loss: 0.0424
2023-02-06 11:52:41 | Train | Epoch[115/600] Iteration[022/030] Train loss: 0.0422
2023-02-06 11:52:42 | Train | Epoch[115/600] Iteration[023/030] Train loss: 0.0422
2023-02-06 11:52:42 | Train | Epoch[115/600] Iteration[024/030] Train loss: 0.0422
2023-02-06 11:52:42 | Train | Epoch[115/600] Iteration[025/030] Train loss: 0.0422
2023-02-06 11:52:42 | Train | Epoch[115/600] Iteration[026/030] Train loss: 0.0422
2023-02-06 11:52:42 | Train | Epoch[115/600] Iteration[027/030] Train loss: 0.0421
2023-02-06 11:52:42 | Train | Epoch[115/600] Iteration[028/030] Train loss: 0.0422
2023-02-06 11:52:42 | Train | Epoch[115/600] Iteration[029/030] Train loss: 0.0422
2023-02-06 11:52:42 | Train | Epoch[115/600] Iteration[030/030] Train loss: 0.0421
2023-02-06 11:52:42 | Valid | Epoch[115/600] Iteration[001/008] Valid loss: 0.0804
2023-02-06 11:52:42 | Valid | Epoch[115/600] Iteration[002/008] Valid loss: 0.0827
2023-02-06 11:52:42 | Valid | Epoch[115/600] Iteration[003/008] Valid loss: 0.0867
2023-02-06 11:52:42 | Valid | Epoch[115/600] Iteration[004/008] Valid loss: 0.0843
2023-02-06 11:52:42 | Valid | Epoch[115/600] Iteration[005/008] Valid loss: 0.0852
2023-02-06 11:52:42 | Valid | Epoch[115/600] Iteration[006/008] Valid loss: 0.0840
2023-02-06 11:52:43 | Valid | Epoch[115/600] Iteration[007/008] Valid loss: 0.0827
2023-02-06 11:52:43 | Valid | Epoch[115/600] Iteration[008/008] Valid loss: 0.0845
2023-02-06 11:52:43 | Valid | Epoch[115/600] MIou: 0.7507942344829741
2023-02-06 11:52:43 | Valid | Epoch[115/600] Pixel Accuracy: 0.958886464436849
2023-02-06 11:52:43 | Valid | Epoch[115/600] Mean Pixel Accuracy: 0.7724338248336058
2023-02-06 11:52:43 | Stage | Epoch[115/600] Train loss:0.0421
2023-02-06 11:52:43 | Stage | Epoch[115/600] Valid loss:0.0845
2023-02-06 11:52:43 | Stage | Epoch[115/600] LR:0.01

2023-02-06 11:52:43 | Train | Epoch[116/600] Iteration[001/030] Train loss: 0.0418
2023-02-06 11:52:43 | Train | Epoch[116/600] Iteration[002/030] Train loss: 0.0417
2023-02-06 11:52:43 | Train | Epoch[116/600] Iteration[003/030] Train loss: 0.0426
2023-02-06 11:52:43 | Train | Epoch[116/600] Iteration[004/030] Train loss: 0.0419
2023-02-06 11:52:43 | Train | Epoch[116/600] Iteration[005/030] Train loss: 0.0421
2023-02-06 11:52:43 | Train | Epoch[116/600] Iteration[006/030] Train loss: 0.0422
2023-02-06 11:52:43 | Train | Epoch[116/600] Iteration[007/030] Train loss: 0.0418
2023-02-06 11:52:43 | Train | Epoch[116/600] Iteration[008/030] Train loss: 0.0420
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[009/030] Train loss: 0.0422
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[010/030] Train loss: 0.0421
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[011/030] Train loss: 0.0419
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[012/030] Train loss: 0.0421
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[013/030] Train loss: 0.0419
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[014/030] Train loss: 0.0419
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[015/030] Train loss: 0.0418
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[016/030] Train loss: 0.0420
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[017/030] Train loss: 0.0420
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[018/030] Train loss: 0.0421
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[019/030] Train loss: 0.0421
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[020/030] Train loss: 0.0421
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[021/030] Train loss: 0.0420
2023-02-06 11:52:44 | Train | Epoch[116/600] Iteration[022/030] Train loss: 0.0420
2023-02-06 11:52:45 | Train | Epoch[116/600] Iteration[023/030] Train loss: 0.0421
2023-02-06 11:52:45 | Train | Epoch[116/600] Iteration[024/030] Train loss: 0.0420
2023-02-06 11:52:45 | Train | Epoch[116/600] Iteration[025/030] Train loss: 0.0420
2023-02-06 11:52:45 | Train | Epoch[116/600] Iteration[026/030] Train loss: 0.0420
2023-02-06 11:52:45 | Train | Epoch[116/600] Iteration[027/030] Train loss: 0.0419
2023-02-06 11:52:45 | Train | Epoch[116/600] Iteration[028/030] Train loss: 0.0420
2023-02-06 11:52:45 | Train | Epoch[116/600] Iteration[029/030] Train loss: 0.0420
2023-02-06 11:52:45 | Train | Epoch[116/600] Iteration[030/030] Train loss: 0.0422
2023-02-06 11:52:45 | Valid | Epoch[116/600] Iteration[001/008] Valid loss: 0.0675
2023-02-06 11:52:45 | Valid | Epoch[116/600] Iteration[002/008] Valid loss: 0.0662
2023-02-06 11:52:45 | Valid | Epoch[116/600] Iteration[003/008] Valid loss: 0.0695
2023-02-06 11:52:45 | Valid | Epoch[116/600] Iteration[004/008] Valid loss: 0.0677
2023-02-06 11:52:45 | Valid | Epoch[116/600] Iteration[005/008] Valid loss: 0.0685
2023-02-06 11:52:45 | Valid | Epoch[116/600] Iteration[006/008] Valid loss: 0.0673
2023-02-06 11:52:46 | Valid | Epoch[116/600] Iteration[007/008] Valid loss: 0.0665
2023-02-06 11:52:46 | Valid | Epoch[116/600] Iteration[008/008] Valid loss: 0.0674
2023-02-06 11:52:46 | Valid | Epoch[116/600] MIou: 0.8165750509862482
2023-02-06 11:52:46 | Valid | Epoch[116/600] Pixel Accuracy: 0.969750722249349
2023-02-06 11:52:46 | Valid | Epoch[116/600] Mean Pixel Accuracy: 0.8328826155085346
2023-02-06 11:52:46 | Stage | Epoch[116/600] Train loss:0.0422
2023-02-06 11:52:46 | Stage | Epoch[116/600] Valid loss:0.0674
2023-02-06 11:52:46 | Stage | Epoch[116/600] LR:0.01

2023-02-06 11:52:46 | Train | Epoch[117/600] Iteration[001/030] Train loss: 0.0403
2023-02-06 11:52:46 | Train | Epoch[117/600] Iteration[002/030] Train loss: 0.0406
2023-02-06 11:52:46 | Train | Epoch[117/600] Iteration[003/030] Train loss: 0.0419
2023-02-06 11:52:46 | Train | Epoch[117/600] Iteration[004/030] Train loss: 0.0416
2023-02-06 11:52:46 | Train | Epoch[117/600] Iteration[005/030] Train loss: 0.0420
2023-02-06 11:52:46 | Train | Epoch[117/600] Iteration[006/030] Train loss: 0.0421
2023-02-06 11:52:46 | Train | Epoch[117/600] Iteration[007/030] Train loss: 0.0420
2023-02-06 11:52:46 | Train | Epoch[117/600] Iteration[008/030] Train loss: 0.0422
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[009/030] Train loss: 0.0423
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[010/030] Train loss: 0.0423
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[011/030] Train loss: 0.0424
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[012/030] Train loss: 0.0427
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[013/030] Train loss: 0.0425
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[014/030] Train loss: 0.0426
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[015/030] Train loss: 0.0425
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[016/030] Train loss: 0.0423
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[017/030] Train loss: 0.0423
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[018/030] Train loss: 0.0424
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[019/030] Train loss: 0.0424
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[020/030] Train loss: 0.0424
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[021/030] Train loss: 0.0425
2023-02-06 11:52:47 | Train | Epoch[117/600] Iteration[022/030] Train loss: 0.0425
2023-02-06 11:52:48 | Train | Epoch[117/600] Iteration[023/030] Train loss: 0.0423
2023-02-06 11:52:48 | Train | Epoch[117/600] Iteration[024/030] Train loss: 0.0423
2023-02-06 11:52:48 | Train | Epoch[117/600] Iteration[025/030] Train loss: 0.0422
2023-02-06 11:52:48 | Train | Epoch[117/600] Iteration[026/030] Train loss: 0.0421
2023-02-06 11:52:48 | Train | Epoch[117/600] Iteration[027/030] Train loss: 0.0420
2023-02-06 11:52:48 | Train | Epoch[117/600] Iteration[028/030] Train loss: 0.0420
2023-02-06 11:52:48 | Train | Epoch[117/600] Iteration[029/030] Train loss: 0.0420
2023-02-06 11:52:48 | Train | Epoch[117/600] Iteration[030/030] Train loss: 0.0420
2023-02-06 11:52:48 | Valid | Epoch[117/600] Iteration[001/008] Valid loss: 0.2499
2023-02-06 11:52:48 | Valid | Epoch[117/600] Iteration[002/008] Valid loss: 0.2591
2023-02-06 11:52:48 | Valid | Epoch[117/600] Iteration[003/008] Valid loss: 0.2398
2023-02-06 11:52:48 | Valid | Epoch[117/600] Iteration[004/008] Valid loss: 0.2359
2023-02-06 11:52:48 | Valid | Epoch[117/600] Iteration[005/008] Valid loss: 0.2275
2023-02-06 11:52:48 | Valid | Epoch[117/600] Iteration[006/008] Valid loss: 0.2305
2023-02-06 11:52:49 | Valid | Epoch[117/600] Iteration[007/008] Valid loss: 0.2376
2023-02-06 11:52:49 | Valid | Epoch[117/600] Iteration[008/008] Valid loss: 0.2457
2023-02-06 11:52:49 | Valid | Epoch[117/600] MIou: 0.8852462777169521
2023-02-06 11:52:49 | Valid | Epoch[117/600] Pixel Accuracy: 0.9775225321451823
2023-02-06 11:52:49 | Valid | Epoch[117/600] Mean Pixel Accuracy: 0.9722571006663563
2023-02-06 11:52:49 | Stage | Epoch[117/600] Train loss:0.0420
2023-02-06 11:52:49 | Stage | Epoch[117/600] Valid loss:0.2457
2023-02-06 11:52:49 | Stage | Epoch[117/600] LR:0.01

2023-02-06 11:52:49 | Train | Epoch[118/600] Iteration[001/030] Train loss: 0.0400
2023-02-06 11:52:49 | Train | Epoch[118/600] Iteration[002/030] Train loss: 0.0412
2023-02-06 11:52:49 | Train | Epoch[118/600] Iteration[003/030] Train loss: 0.0421
2023-02-06 11:52:49 | Train | Epoch[118/600] Iteration[004/030] Train loss: 0.0414
2023-02-06 11:52:49 | Train | Epoch[118/600] Iteration[005/030] Train loss: 0.0413
2023-02-06 11:52:49 | Train | Epoch[118/600] Iteration[006/030] Train loss: 0.0408
2023-02-06 11:52:49 | Train | Epoch[118/600] Iteration[007/030] Train loss: 0.0410
2023-02-06 11:52:49 | Train | Epoch[118/600] Iteration[008/030] Train loss: 0.0410
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[009/030] Train loss: 0.0409
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[010/030] Train loss: 0.0406
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[011/030] Train loss: 0.0405
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[012/030] Train loss: 0.0408
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[013/030] Train loss: 0.0408
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[014/030] Train loss: 0.0407
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[015/030] Train loss: 0.0406
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[016/030] Train loss: 0.0406
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[017/030] Train loss: 0.0405
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[018/030] Train loss: 0.0407
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[019/030] Train loss: 0.0405
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[020/030] Train loss: 0.0404
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[021/030] Train loss: 0.0406
2023-02-06 11:52:50 | Train | Epoch[118/600] Iteration[022/030] Train loss: 0.0406
2023-02-06 11:52:51 | Train | Epoch[118/600] Iteration[023/030] Train loss: 0.0406
2023-02-06 11:52:51 | Train | Epoch[118/600] Iteration[024/030] Train loss: 0.0405
2023-02-06 11:52:51 | Train | Epoch[118/600] Iteration[025/030] Train loss: 0.0406
2023-02-06 11:52:51 | Train | Epoch[118/600] Iteration[026/030] Train loss: 0.0405
2023-02-06 11:52:51 | Train | Epoch[118/600] Iteration[027/030] Train loss: 0.0405
2023-02-06 11:52:51 | Train | Epoch[118/600] Iteration[028/030] Train loss: 0.0405
2023-02-06 11:52:51 | Train | Epoch[118/600] Iteration[029/030] Train loss: 0.0406
2023-02-06 11:52:51 | Train | Epoch[118/600] Iteration[030/030] Train loss: 0.0406
2023-02-06 11:52:51 | Valid | Epoch[118/600] Iteration[001/008] Valid loss: 0.0608
2023-02-06 11:52:51 | Valid | Epoch[118/600] Iteration[002/008] Valid loss: 0.0579
2023-02-06 11:52:51 | Valid | Epoch[118/600] Iteration[003/008] Valid loss: 0.0575
2023-02-06 11:52:51 | Valid | Epoch[118/600] Iteration[004/008] Valid loss: 0.0557
2023-02-06 11:52:51 | Valid | Epoch[118/600] Iteration[005/008] Valid loss: 0.0551
2023-02-06 11:52:51 | Valid | Epoch[118/600] Iteration[006/008] Valid loss: 0.0547
2023-02-06 11:52:52 | Valid | Epoch[118/600] Iteration[007/008] Valid loss: 0.0551
2023-02-06 11:52:52 | Valid | Epoch[118/600] Iteration[008/008] Valid loss: 0.0551
2023-02-06 11:52:52 | Valid | Epoch[118/600] MIou: 0.8875439368344925
2023-02-06 11:52:52 | Valid | Epoch[118/600] Pixel Accuracy: 0.9813690185546875
2023-02-06 11:52:52 | Valid | Epoch[118/600] Mean Pixel Accuracy: 0.9000546270526106
2023-02-06 11:52:52 | Stage | Epoch[118/600] Train loss:0.0406
2023-02-06 11:52:52 | Stage | Epoch[118/600] Valid loss:0.0551
2023-02-06 11:52:52 | Stage | Epoch[118/600] LR:0.01

2023-02-06 11:52:52 | Train | Epoch[119/600] Iteration[001/030] Train loss: 0.0395
2023-02-06 11:52:52 | Train | Epoch[119/600] Iteration[002/030] Train loss: 0.0395
2023-02-06 11:52:52 | Train | Epoch[119/600] Iteration[003/030] Train loss: 0.0393
2023-02-06 11:52:52 | Train | Epoch[119/600] Iteration[004/030] Train loss: 0.0397
2023-02-06 11:52:52 | Train | Epoch[119/600] Iteration[005/030] Train loss: 0.0398
2023-02-06 11:52:52 | Train | Epoch[119/600] Iteration[006/030] Train loss: 0.0397
2023-02-06 11:52:52 | Train | Epoch[119/600] Iteration[007/030] Train loss: 0.0396
2023-02-06 11:52:52 | Train | Epoch[119/600] Iteration[008/030] Train loss: 0.0392
2023-02-06 11:52:52 | Train | Epoch[119/600] Iteration[009/030] Train loss: 0.0391
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[010/030] Train loss: 0.0393
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[011/030] Train loss: 0.0395
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[012/030] Train loss: 0.0395
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[013/030] Train loss: 0.0395
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[014/030] Train loss: 0.0395
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[015/030] Train loss: 0.0395
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[016/030] Train loss: 0.0395
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[017/030] Train loss: 0.0397
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[018/030] Train loss: 0.0397
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[019/030] Train loss: 0.0396
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[020/030] Train loss: 0.0399
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[021/030] Train loss: 0.0398
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[022/030] Train loss: 0.0399
2023-02-06 11:52:53 | Train | Epoch[119/600] Iteration[023/030] Train loss: 0.0400
2023-02-06 11:52:54 | Train | Epoch[119/600] Iteration[024/030] Train loss: 0.0401
2023-02-06 11:52:54 | Train | Epoch[119/600] Iteration[025/030] Train loss: 0.0400
2023-02-06 11:52:54 | Train | Epoch[119/600] Iteration[026/030] Train loss: 0.0400
2023-02-06 11:52:54 | Train | Epoch[119/600] Iteration[027/030] Train loss: 0.0400
2023-02-06 11:52:54 | Train | Epoch[119/600] Iteration[028/030] Train loss: 0.0401
2023-02-06 11:52:54 | Train | Epoch[119/600] Iteration[029/030] Train loss: 0.0401
2023-02-06 11:52:54 | Train | Epoch[119/600] Iteration[030/030] Train loss: 0.0401
2023-02-06 11:52:54 | Valid | Epoch[119/600] Iteration[001/008] Valid loss: 0.0606
2023-02-06 11:52:54 | Valid | Epoch[119/600] Iteration[002/008] Valid loss: 0.0605
2023-02-06 11:52:54 | Valid | Epoch[119/600] Iteration[003/008] Valid loss: 0.0625
2023-02-06 11:52:54 | Valid | Epoch[119/600] Iteration[004/008] Valid loss: 0.0608
2023-02-06 11:52:54 | Valid | Epoch[119/600] Iteration[005/008] Valid loss: 0.0612
2023-02-06 11:52:54 | Valid | Epoch[119/600] Iteration[006/008] Valid loss: 0.0609
2023-02-06 11:52:54 | Valid | Epoch[119/600] Iteration[007/008] Valid loss: 0.0604
2023-02-06 11:52:55 | Valid | Epoch[119/600] Iteration[008/008] Valid loss: 0.0615
2023-02-06 11:52:55 | Valid | Epoch[119/600] MIou: 0.8339846438825375
2023-02-06 11:52:55 | Valid | Epoch[119/600] Pixel Accuracy: 0.9725252787272135
2023-02-06 11:52:55 | Valid | Epoch[119/600] Mean Pixel Accuracy: 0.8501319994306986
2023-02-06 11:52:55 | Stage | Epoch[119/600] Train loss:0.0401
2023-02-06 11:52:55 | Stage | Epoch[119/600] Valid loss:0.0615
2023-02-06 11:52:55 | Stage | Epoch[119/600] LR:0.01

2023-02-06 11:52:55 | Train | Epoch[120/600] Iteration[001/030] Train loss: 0.0394
2023-02-06 11:52:55 | Train | Epoch[120/600] Iteration[002/030] Train loss: 0.0396
2023-02-06 11:52:55 | Train | Epoch[120/600] Iteration[003/030] Train loss: 0.0393
2023-02-06 11:52:55 | Train | Epoch[120/600] Iteration[004/030] Train loss: 0.0398
2023-02-06 11:52:55 | Train | Epoch[120/600] Iteration[005/030] Train loss: 0.0397
2023-02-06 11:52:55 | Train | Epoch[120/600] Iteration[006/030] Train loss: 0.0398
2023-02-06 11:52:55 | Train | Epoch[120/600] Iteration[007/030] Train loss: 0.0396
2023-02-06 11:52:55 | Train | Epoch[120/600] Iteration[008/030] Train loss: 0.0398
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[009/030] Train loss: 0.0399
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[010/030] Train loss: 0.0398
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[011/030] Train loss: 0.0397
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[012/030] Train loss: 0.0396
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[013/030] Train loss: 0.0398
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[014/030] Train loss: 0.0397
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[015/030] Train loss: 0.0396
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[016/030] Train loss: 0.0398
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[017/030] Train loss: 0.0397
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[018/030] Train loss: 0.0397
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[019/030] Train loss: 0.0398
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[020/030] Train loss: 0.0398
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[021/030] Train loss: 0.0399
2023-02-06 11:52:56 | Train | Epoch[120/600] Iteration[022/030] Train loss: 0.0398
2023-02-06 11:52:57 | Train | Epoch[120/600] Iteration[023/030] Train loss: 0.0399
2023-02-06 11:52:57 | Train | Epoch[120/600] Iteration[024/030] Train loss: 0.0399
2023-02-06 11:52:57 | Train | Epoch[120/600] Iteration[025/030] Train loss: 0.0400
2023-02-06 11:52:57 | Train | Epoch[120/600] Iteration[026/030] Train loss: 0.0400
2023-02-06 11:52:57 | Train | Epoch[120/600] Iteration[027/030] Train loss: 0.0401
2023-02-06 11:52:57 | Train | Epoch[120/600] Iteration[028/030] Train loss: 0.0401
2023-02-06 11:52:57 | Train | Epoch[120/600] Iteration[029/030] Train loss: 0.0401
2023-02-06 11:52:57 | Train | Epoch[120/600] Iteration[030/030] Train loss: 0.0402
2023-02-06 11:52:57 | Valid | Epoch[120/600] Iteration[001/008] Valid loss: 2.8153
2023-02-06 11:52:57 | Valid | Epoch[120/600] Iteration[002/008] Valid loss: 2.7567
2023-02-06 11:52:57 | Valid | Epoch[120/600] Iteration[003/008] Valid loss: 2.8768
2023-02-06 11:52:57 | Valid | Epoch[120/600] Iteration[004/008] Valid loss: 2.9892
2023-02-06 11:52:57 | Valid | Epoch[120/600] Iteration[005/008] Valid loss: 3.0460
2023-02-06 11:52:57 | Valid | Epoch[120/600] Iteration[006/008] Valid loss: 2.9857
2023-02-06 11:52:57 | Valid | Epoch[120/600] Iteration[007/008] Valid loss: 3.0500
2023-02-06 11:52:58 | Valid | Epoch[120/600] Iteration[008/008] Valid loss: 3.1886
2023-02-06 11:52:58 | Valid | Epoch[120/600] MIou: 0.7174931952669045
2023-02-06 11:52:58 | Valid | Epoch[120/600] Pixel Accuracy: 0.918298085530599
2023-02-06 11:52:58 | Valid | Epoch[120/600] Mean Pixel Accuracy: 0.9546366293563722
2023-02-06 11:52:58 | Stage | Epoch[120/600] Train loss:0.0402
2023-02-06 11:52:58 | Stage | Epoch[120/600] Valid loss:3.1886
2023-02-06 11:52:58 | Stage | Epoch[120/600] LR:0.01

2023-02-06 11:52:58 | Train | Epoch[121/600] Iteration[001/030] Train loss: 0.0424
2023-02-06 11:52:58 | Train | Epoch[121/600] Iteration[002/030] Train loss: 0.0413
2023-02-06 11:52:58 | Train | Epoch[121/600] Iteration[003/030] Train loss: 0.0405
2023-02-06 11:52:58 | Train | Epoch[121/600] Iteration[004/030] Train loss: 0.0404
2023-02-06 11:52:58 | Train | Epoch[121/600] Iteration[005/030] Train loss: 0.0407
2023-02-06 11:52:58 | Train | Epoch[121/600] Iteration[006/030] Train loss: 0.0406
2023-02-06 11:52:58 | Train | Epoch[121/600] Iteration[007/030] Train loss: 0.0402
2023-02-06 11:52:58 | Train | Epoch[121/600] Iteration[008/030] Train loss: 0.0403
2023-02-06 11:52:58 | Train | Epoch[121/600] Iteration[009/030] Train loss: 0.0406
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[010/030] Train loss: 0.0405
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[011/030] Train loss: 0.0402
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[012/030] Train loss: 0.0400
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[013/030] Train loss: 0.0401
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[014/030] Train loss: 0.0399
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[015/030] Train loss: 0.0398
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[016/030] Train loss: 0.0398
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[017/030] Train loss: 0.0398
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[018/030] Train loss: 0.0400
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[019/030] Train loss: 0.0399
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[020/030] Train loss: 0.0398
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[021/030] Train loss: 0.0398
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[022/030] Train loss: 0.0398
2023-02-06 11:52:59 | Train | Epoch[121/600] Iteration[023/030] Train loss: 0.0398
2023-02-06 11:53:00 | Train | Epoch[121/600] Iteration[024/030] Train loss: 0.0400
2023-02-06 11:53:00 | Train | Epoch[121/600] Iteration[025/030] Train loss: 0.0400
2023-02-06 11:53:00 | Train | Epoch[121/600] Iteration[026/030] Train loss: 0.0399
2023-02-06 11:53:00 | Train | Epoch[121/600] Iteration[027/030] Train loss: 0.0400
2023-02-06 11:53:00 | Train | Epoch[121/600] Iteration[028/030] Train loss: 0.0399
2023-02-06 11:53:00 | Train | Epoch[121/600] Iteration[029/030] Train loss: 0.0399
2023-02-06 11:53:00 | Train | Epoch[121/600] Iteration[030/030] Train loss: 0.0401
2023-02-06 11:53:00 | Valid | Epoch[121/600] Iteration[001/008] Valid loss: 0.8197
2023-02-06 11:53:00 | Valid | Epoch[121/600] Iteration[002/008] Valid loss: 0.7703
2023-02-06 11:53:00 | Valid | Epoch[121/600] Iteration[003/008] Valid loss: 0.7796
2023-02-06 11:53:00 | Valid | Epoch[121/600] Iteration[004/008] Valid loss: 0.7922
2023-02-06 11:53:00 | Valid | Epoch[121/600] Iteration[005/008] Valid loss: 0.8162
2023-02-06 11:53:00 | Valid | Epoch[121/600] Iteration[006/008] Valid loss: 0.7915
2023-02-06 11:53:01 | Valid | Epoch[121/600] Iteration[007/008] Valid loss: 0.8266
2023-02-06 11:53:01 | Valid | Epoch[121/600] Iteration[008/008] Valid loss: 0.8553
2023-02-06 11:53:01 | Valid | Epoch[121/600] MIou: 0.8446291367540115
2023-02-06 11:53:01 | Valid | Epoch[121/600] Pixel Accuracy: 0.9662132263183594
2023-02-06 11:53:01 | Valid | Epoch[121/600] Mean Pixel Accuracy: 0.9783034957580691
2023-02-06 11:53:01 | Stage | Epoch[121/600] Train loss:0.0401
2023-02-06 11:53:01 | Stage | Epoch[121/600] Valid loss:0.8553
2023-02-06 11:53:01 | Stage | Epoch[121/600] LR:0.01

2023-02-06 11:53:01 | Train | Epoch[122/600] Iteration[001/030] Train loss: 0.0390
2023-02-06 11:53:01 | Train | Epoch[122/600] Iteration[002/030] Train loss: 0.0384
2023-02-06 11:53:01 | Train | Epoch[122/600] Iteration[003/030] Train loss: 0.0391
2023-02-06 11:53:01 | Train | Epoch[122/600] Iteration[004/030] Train loss: 0.0396
2023-02-06 11:53:01 | Train | Epoch[122/600] Iteration[005/030] Train loss: 0.0390
2023-02-06 11:53:01 | Train | Epoch[122/600] Iteration[006/030] Train loss: 0.0390
2023-02-06 11:53:01 | Train | Epoch[122/600] Iteration[007/030] Train loss: 0.0392
2023-02-06 11:53:01 | Train | Epoch[122/600] Iteration[008/030] Train loss: 0.0398
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[009/030] Train loss: 0.0398
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[010/030] Train loss: 0.0403
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[011/030] Train loss: 0.0404
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[012/030] Train loss: 0.0404
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[013/030] Train loss: 0.0404
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[014/030] Train loss: 0.0403
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[015/030] Train loss: 0.0403
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[016/030] Train loss: 0.0404
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[017/030] Train loss: 0.0407
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[018/030] Train loss: 0.0406
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[019/030] Train loss: 0.0407
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[020/030] Train loss: 0.0406
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[021/030] Train loss: 0.0405
2023-02-06 11:53:02 | Train | Epoch[122/600] Iteration[022/030] Train loss: 0.0406
2023-02-06 11:53:03 | Train | Epoch[122/600] Iteration[023/030] Train loss: 0.0405
2023-02-06 11:53:03 | Train | Epoch[122/600] Iteration[024/030] Train loss: 0.0407
2023-02-06 11:53:03 | Train | Epoch[122/600] Iteration[025/030] Train loss: 0.0407
2023-02-06 11:53:03 | Train | Epoch[122/600] Iteration[026/030] Train loss: 0.0407
2023-02-06 11:53:03 | Train | Epoch[122/600] Iteration[027/030] Train loss: 0.0407
2023-02-06 11:53:03 | Train | Epoch[122/600] Iteration[028/030] Train loss: 0.0406
2023-02-06 11:53:03 | Train | Epoch[122/600] Iteration[029/030] Train loss: 0.0406
2023-02-06 11:53:03 | Train | Epoch[122/600] Iteration[030/030] Train loss: 0.0409
2023-02-06 11:53:03 | Valid | Epoch[122/600] Iteration[001/008] Valid loss: 0.1536
2023-02-06 11:53:03 | Valid | Epoch[122/600] Iteration[002/008] Valid loss: 0.1507
2023-02-06 11:53:03 | Valid | Epoch[122/600] Iteration[003/008] Valid loss: 0.1623
2023-02-06 11:53:03 | Valid | Epoch[122/600] Iteration[004/008] Valid loss: 0.1582
2023-02-06 11:53:03 | Valid | Epoch[122/600] Iteration[005/008] Valid loss: 0.1639
2023-02-06 11:53:03 | Valid | Epoch[122/600] Iteration[006/008] Valid loss: 0.1619
2023-02-06 11:53:03 | Valid | Epoch[122/600] Iteration[007/008] Valid loss: 0.1593
2023-02-06 11:53:04 | Valid | Epoch[122/600] Iteration[008/008] Valid loss: 0.1676
2023-02-06 11:53:04 | Valid | Epoch[122/600] MIou: 0.581273787127725
2023-02-06 11:53:04 | Valid | Epoch[122/600] Pixel Accuracy: 0.930517832438151
2023-02-06 11:53:04 | Valid | Epoch[122/600] Mean Pixel Accuracy: 0.6170147965383335
2023-02-06 11:53:04 | Stage | Epoch[122/600] Train loss:0.0409
2023-02-06 11:53:04 | Stage | Epoch[122/600] Valid loss:0.1676
2023-02-06 11:53:04 | Stage | Epoch[122/600] LR:0.01

2023-02-06 11:53:04 | Train | Epoch[123/600] Iteration[001/030] Train loss: 0.0408
2023-02-06 11:53:04 | Train | Epoch[123/600] Iteration[002/030] Train loss: 0.0401
2023-02-06 11:53:04 | Train | Epoch[123/600] Iteration[003/030] Train loss: 0.0397
2023-02-06 11:53:04 | Train | Epoch[123/600] Iteration[004/030] Train loss: 0.0394
2023-02-06 11:53:04 | Train | Epoch[123/600] Iteration[005/030] Train loss: 0.0390
2023-02-06 11:53:04 | Train | Epoch[123/600] Iteration[006/030] Train loss: 0.0394
2023-02-06 11:53:04 | Train | Epoch[123/600] Iteration[007/030] Train loss: 0.0396
2023-02-06 11:53:04 | Train | Epoch[123/600] Iteration[008/030] Train loss: 0.0398
2023-02-06 11:53:04 | Train | Epoch[123/600] Iteration[009/030] Train loss: 0.0397
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[010/030] Train loss: 0.0396
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[011/030] Train loss: 0.0397
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[012/030] Train loss: 0.0397
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[013/030] Train loss: 0.0399
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[014/030] Train loss: 0.0398
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[015/030] Train loss: 0.0395
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[016/030] Train loss: 0.0394
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[017/030] Train loss: 0.0394
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[018/030] Train loss: 0.0393
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[019/030] Train loss: 0.0396
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[020/030] Train loss: 0.0395
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[021/030] Train loss: 0.0393
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[022/030] Train loss: 0.0394
2023-02-06 11:53:05 | Train | Epoch[123/600] Iteration[023/030] Train loss: 0.0394
2023-02-06 11:53:06 | Train | Epoch[123/600] Iteration[024/030] Train loss: 0.0394
2023-02-06 11:53:06 | Train | Epoch[123/600] Iteration[025/030] Train loss: 0.0394
2023-02-06 11:53:06 | Train | Epoch[123/600] Iteration[026/030] Train loss: 0.0394
2023-02-06 11:53:06 | Train | Epoch[123/600] Iteration[027/030] Train loss: 0.0394
2023-02-06 11:53:06 | Train | Epoch[123/600] Iteration[028/030] Train loss: 0.0395
2023-02-06 11:53:06 | Train | Epoch[123/600] Iteration[029/030] Train loss: 0.0395
2023-02-06 11:53:06 | Train | Epoch[123/600] Iteration[030/030] Train loss: 0.0394
2023-02-06 11:53:06 | Valid | Epoch[123/600] Iteration[001/008] Valid loss: 0.0696
2023-02-06 11:53:06 | Valid | Epoch[123/600] Iteration[002/008] Valid loss: 0.0650
2023-02-06 11:53:06 | Valid | Epoch[123/600] Iteration[003/008] Valid loss: 0.0642
2023-02-06 11:53:06 | Valid | Epoch[123/600] Iteration[004/008] Valid loss: 0.0619
2023-02-06 11:53:06 | Valid | Epoch[123/600] Iteration[005/008] Valid loss: 0.0634
2023-02-06 11:53:06 | Valid | Epoch[123/600] Iteration[006/008] Valid loss: 0.0619
2023-02-06 11:53:06 | Valid | Epoch[123/600] Iteration[007/008] Valid loss: 0.0619
2023-02-06 11:53:06 | Valid | Epoch[123/600] Iteration[008/008] Valid loss: 0.0626
2023-02-06 11:53:07 | Valid | Epoch[123/600] MIou: 0.8586338989782982
2023-02-06 11:53:07 | Valid | Epoch[123/600] Pixel Accuracy: 0.976355234781901
2023-02-06 11:53:07 | Valid | Epoch[123/600] Mean Pixel Accuracy: 0.8768698384464599
2023-02-06 11:53:07 | Stage | Epoch[123/600] Train loss:0.0394
2023-02-06 11:53:07 | Stage | Epoch[123/600] Valid loss:0.0626
2023-02-06 11:53:07 | Stage | Epoch[123/600] LR:0.01

2023-02-06 11:53:07 | Train | Epoch[124/600] Iteration[001/030] Train loss: 0.0390
2023-02-06 11:53:07 | Train | Epoch[124/600] Iteration[002/030] Train loss: 0.0382
2023-02-06 11:53:07 | Train | Epoch[124/600] Iteration[003/030] Train loss: 0.0380
2023-02-06 11:53:07 | Train | Epoch[124/600] Iteration[004/030] Train loss: 0.0375
2023-02-06 11:53:07 | Train | Epoch[124/600] Iteration[005/030] Train loss: 0.0373
2023-02-06 11:53:07 | Train | Epoch[124/600] Iteration[006/030] Train loss: 0.0375
2023-02-06 11:53:07 | Train | Epoch[124/600] Iteration[007/030] Train loss: 0.0375
2023-02-06 11:53:07 | Train | Epoch[124/600] Iteration[008/030] Train loss: 0.0377
2023-02-06 11:53:07 | Train | Epoch[124/600] Iteration[009/030] Train loss: 0.0379
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[010/030] Train loss: 0.0379
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[011/030] Train loss: 0.0381
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[012/030] Train loss: 0.0381
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[013/030] Train loss: 0.0381
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[014/030] Train loss: 0.0383
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[015/030] Train loss: 0.0382
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[016/030] Train loss: 0.0382
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[017/030] Train loss: 0.0382
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[018/030] Train loss: 0.0381
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[019/030] Train loss: 0.0380
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[020/030] Train loss: 0.0382
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[021/030] Train loss: 0.0381
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[022/030] Train loss: 0.0382
2023-02-06 11:53:08 | Train | Epoch[124/600] Iteration[023/030] Train loss: 0.0382
2023-02-06 11:53:09 | Train | Epoch[124/600] Iteration[024/030] Train loss: 0.0381
2023-02-06 11:53:09 | Train | Epoch[124/600] Iteration[025/030] Train loss: 0.0383
2023-02-06 11:53:09 | Train | Epoch[124/600] Iteration[026/030] Train loss: 0.0383
2023-02-06 11:53:09 | Train | Epoch[124/600] Iteration[027/030] Train loss: 0.0385
2023-02-06 11:53:09 | Train | Epoch[124/600] Iteration[028/030] Train loss: 0.0384
2023-02-06 11:53:09 | Train | Epoch[124/600] Iteration[029/030] Train loss: 0.0385
2023-02-06 11:53:09 | Train | Epoch[124/600] Iteration[030/030] Train loss: 0.0385
2023-02-06 11:53:09 | Valid | Epoch[124/600] Iteration[001/008] Valid loss: 0.0564
2023-02-06 11:53:09 | Valid | Epoch[124/600] Iteration[002/008] Valid loss: 0.0545
2023-02-06 11:53:09 | Valid | Epoch[124/600] Iteration[003/008] Valid loss: 0.0565
2023-02-06 11:53:09 | Valid | Epoch[124/600] Iteration[004/008] Valid loss: 0.0549
2023-02-06 11:53:09 | Valid | Epoch[124/600] Iteration[005/008] Valid loss: 0.0553
2023-02-06 11:53:09 | Valid | Epoch[124/600] Iteration[006/008] Valid loss: 0.0547
2023-02-06 11:53:09 | Valid | Epoch[124/600] Iteration[007/008] Valid loss: 0.0546
2023-02-06 11:53:09 | Valid | Epoch[124/600] Iteration[008/008] Valid loss: 0.0552
2023-02-06 11:53:10 | Valid | Epoch[124/600] MIou: 0.8634797800338141
2023-02-06 11:53:10 | Valid | Epoch[124/600] Pixel Accuracy: 0.9773546854654948
2023-02-06 11:53:10 | Valid | Epoch[124/600] Mean Pixel Accuracy: 0.8782497809357863
2023-02-06 11:53:10 | Stage | Epoch[124/600] Train loss:0.0385
2023-02-06 11:53:10 | Stage | Epoch[124/600] Valid loss:0.0552
2023-02-06 11:53:10 | Stage | Epoch[124/600] LR:0.01

2023-02-06 11:53:10 | Train | Epoch[125/600] Iteration[001/030] Train loss: 0.0377
2023-02-06 11:53:10 | Train | Epoch[125/600] Iteration[002/030] Train loss: 0.0377
2023-02-06 11:53:10 | Train | Epoch[125/600] Iteration[003/030] Train loss: 0.0371
2023-02-06 11:53:10 | Train | Epoch[125/600] Iteration[004/030] Train loss: 0.0371
2023-02-06 11:53:10 | Train | Epoch[125/600] Iteration[005/030] Train loss: 0.0385
2023-02-06 11:53:10 | Train | Epoch[125/600] Iteration[006/030] Train loss: 0.0384
2023-02-06 11:53:10 | Train | Epoch[125/600] Iteration[007/030] Train loss: 0.0384
2023-02-06 11:53:10 | Train | Epoch[125/600] Iteration[008/030] Train loss: 0.0388
2023-02-06 11:53:10 | Train | Epoch[125/600] Iteration[009/030] Train loss: 0.0386
2023-02-06 11:53:10 | Train | Epoch[125/600] Iteration[010/030] Train loss: 0.0386
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[011/030] Train loss: 0.0387
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[012/030] Train loss: 0.0388
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[013/030] Train loss: 0.0389
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[014/030] Train loss: 0.0388
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[015/030] Train loss: 0.0388
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[016/030] Train loss: 0.0386
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[017/030] Train loss: 0.0385
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[018/030] Train loss: 0.0385
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[019/030] Train loss: 0.0387
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[020/030] Train loss: 0.0386
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[021/030] Train loss: 0.0387
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[022/030] Train loss: 0.0386
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[023/030] Train loss: 0.0385
2023-02-06 11:53:11 | Train | Epoch[125/600] Iteration[024/030] Train loss: 0.0385
2023-02-06 11:53:12 | Train | Epoch[125/600] Iteration[025/030] Train loss: 0.0385
2023-02-06 11:53:12 | Train | Epoch[125/600] Iteration[026/030] Train loss: 0.0384
2023-02-06 11:53:12 | Train | Epoch[125/600] Iteration[027/030] Train loss: 0.0384
2023-02-06 11:53:12 | Train | Epoch[125/600] Iteration[028/030] Train loss: 0.0384
2023-02-06 11:53:12 | Train | Epoch[125/600] Iteration[029/030] Train loss: 0.0384
2023-02-06 11:53:12 | Train | Epoch[125/600] Iteration[030/030] Train loss: 0.0386
2023-02-06 11:53:12 | Valid | Epoch[125/600] Iteration[001/008] Valid loss: 0.0693
2023-02-06 11:53:12 | Valid | Epoch[125/600] Iteration[002/008] Valid loss: 0.0596
2023-02-06 11:53:12 | Valid | Epoch[125/600] Iteration[003/008] Valid loss: 0.0584
2023-02-06 11:53:12 | Valid | Epoch[125/600] Iteration[004/008] Valid loss: 0.0566
2023-02-06 11:53:12 | Valid | Epoch[125/600] Iteration[005/008] Valid loss: 0.0566
2023-02-06 11:53:12 | Valid | Epoch[125/600] Iteration[006/008] Valid loss: 0.0552
2023-02-06 11:53:12 | Valid | Epoch[125/600] Iteration[007/008] Valid loss: 0.0566
2023-02-06 11:53:12 | Valid | Epoch[125/600] Iteration[008/008] Valid loss: 0.0562
2023-02-06 11:53:13 | Valid | Epoch[125/600] MIou: 0.9039056962792671
2023-02-06 11:53:13 | Valid | Epoch[125/600] Pixel Accuracy: 0.9838968912760416
2023-02-06 11:53:13 | Valid | Epoch[125/600] Mean Pixel Accuracy: 0.919958230526704
2023-02-06 11:53:13 | Stage | Epoch[125/600] Train loss:0.0386
2023-02-06 11:53:13 | Stage | Epoch[125/600] Valid loss:0.0562
2023-02-06 11:53:13 | Stage | Epoch[125/600] LR:0.01

2023-02-06 11:53:13 | Train | Epoch[126/600] Iteration[001/030] Train loss: 0.0401
2023-02-06 11:53:13 | Train | Epoch[126/600] Iteration[002/030] Train loss: 0.0390
2023-02-06 11:53:13 | Train | Epoch[126/600] Iteration[003/030] Train loss: 0.0375
2023-02-06 11:53:13 | Train | Epoch[126/600] Iteration[004/030] Train loss: 0.0376
2023-02-06 11:53:13 | Train | Epoch[126/600] Iteration[005/030] Train loss: 0.0377
2023-02-06 11:53:13 | Train | Epoch[126/600] Iteration[006/030] Train loss: 0.0373
2023-02-06 11:53:13 | Train | Epoch[126/600] Iteration[007/030] Train loss: 0.0373
2023-02-06 11:53:13 | Train | Epoch[126/600] Iteration[008/030] Train loss: 0.0372
2023-02-06 11:53:13 | Train | Epoch[126/600] Iteration[009/030] Train loss: 0.0375
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[010/030] Train loss: 0.0374
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[011/030] Train loss: 0.0373
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[012/030] Train loss: 0.0370
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[013/030] Train loss: 0.0372
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[014/030] Train loss: 0.0371
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[015/030] Train loss: 0.0371
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[016/030] Train loss: 0.0373
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[017/030] Train loss: 0.0372
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[018/030] Train loss: 0.0372
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[019/030] Train loss: 0.0373
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[020/030] Train loss: 0.0372
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[021/030] Train loss: 0.0372
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[022/030] Train loss: 0.0372
2023-02-06 11:53:14 | Train | Epoch[126/600] Iteration[023/030] Train loss: 0.0372
2023-02-06 11:53:15 | Train | Epoch[126/600] Iteration[024/030] Train loss: 0.0373
2023-02-06 11:53:15 | Train | Epoch[126/600] Iteration[025/030] Train loss: 0.0373
2023-02-06 11:53:15 | Train | Epoch[126/600] Iteration[026/030] Train loss: 0.0373
2023-02-06 11:53:15 | Train | Epoch[126/600] Iteration[027/030] Train loss: 0.0373
2023-02-06 11:53:15 | Train | Epoch[126/600] Iteration[028/030] Train loss: 0.0373
2023-02-06 11:53:15 | Train | Epoch[126/600] Iteration[029/030] Train loss: 0.0373
2023-02-06 11:53:15 | Train | Epoch[126/600] Iteration[030/030] Train loss: 0.0373
2023-02-06 11:53:15 | Valid | Epoch[126/600] Iteration[001/008] Valid loss: 0.8138
2023-02-06 11:53:15 | Valid | Epoch[126/600] Iteration[002/008] Valid loss: 0.7514
2023-02-06 11:53:15 | Valid | Epoch[126/600] Iteration[003/008] Valid loss: 0.7536
2023-02-06 11:53:15 | Valid | Epoch[126/600] Iteration[004/008] Valid loss: 0.7569
2023-02-06 11:53:15 | Valid | Epoch[126/600] Iteration[005/008] Valid loss: 0.7798
2023-02-06 11:53:15 | Valid | Epoch[126/600] Iteration[006/008] Valid loss: 0.7604
2023-02-06 11:53:15 | Valid | Epoch[126/600] Iteration[007/008] Valid loss: 0.7928
2023-02-06 11:53:15 | Valid | Epoch[126/600] Iteration[008/008] Valid loss: 0.8100
2023-02-06 11:53:16 | Valid | Epoch[126/600] MIou: 0.8560657764470043
2023-02-06 11:53:16 | Valid | Epoch[126/600] Pixel Accuracy: 0.969366709391276
2023-02-06 11:53:16 | Valid | Epoch[126/600] Mean Pixel Accuracy: 0.9809307910309475
2023-02-06 11:53:16 | Stage | Epoch[126/600] Train loss:0.0373
2023-02-06 11:53:16 | Stage | Epoch[126/600] Valid loss:0.8100
2023-02-06 11:53:16 | Stage | Epoch[126/600] LR:0.01

2023-02-06 11:53:16 | Train | Epoch[127/600] Iteration[001/030] Train loss: 0.0366
2023-02-06 11:53:16 | Train | Epoch[127/600] Iteration[002/030] Train loss: 0.0375
2023-02-06 11:53:16 | Train | Epoch[127/600] Iteration[003/030] Train loss: 0.0369
2023-02-06 11:53:16 | Train | Epoch[127/600] Iteration[004/030] Train loss: 0.0373
2023-02-06 11:53:16 | Train | Epoch[127/600] Iteration[005/030] Train loss: 0.0372
2023-02-06 11:53:16 | Train | Epoch[127/600] Iteration[006/030] Train loss: 0.0371
2023-02-06 11:53:16 | Train | Epoch[127/600] Iteration[007/030] Train loss: 0.0376
2023-02-06 11:53:16 | Train | Epoch[127/600] Iteration[008/030] Train loss: 0.0373
2023-02-06 11:53:16 | Train | Epoch[127/600] Iteration[009/030] Train loss: 0.0371
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[010/030] Train loss: 0.0372
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[011/030] Train loss: 0.0373
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[012/030] Train loss: 0.0371
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[013/030] Train loss: 0.0371
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[014/030] Train loss: 0.0373
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[015/030] Train loss: 0.0375
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[016/030] Train loss: 0.0375
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[017/030] Train loss: 0.0374
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[018/030] Train loss: 0.0375
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[019/030] Train loss: 0.0375
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[020/030] Train loss: 0.0374
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[021/030] Train loss: 0.0373
2023-02-06 11:53:17 | Train | Epoch[127/600] Iteration[022/030] Train loss: 0.0372
2023-02-06 11:53:18 | Train | Epoch[127/600] Iteration[023/030] Train loss: 0.0372
2023-02-06 11:53:18 | Train | Epoch[127/600] Iteration[024/030] Train loss: 0.0371
2023-02-06 11:53:18 | Train | Epoch[127/600] Iteration[025/030] Train loss: 0.0371
2023-02-06 11:53:18 | Train | Epoch[127/600] Iteration[026/030] Train loss: 0.0371
2023-02-06 11:53:18 | Train | Epoch[127/600] Iteration[027/030] Train loss: 0.0371
2023-02-06 11:53:18 | Train | Epoch[127/600] Iteration[028/030] Train loss: 0.0372
2023-02-06 11:53:18 | Train | Epoch[127/600] Iteration[029/030] Train loss: 0.0371
2023-02-06 11:53:18 | Train | Epoch[127/600] Iteration[030/030] Train loss: 0.0371
2023-02-06 11:53:18 | Valid | Epoch[127/600] Iteration[001/008] Valid loss: 0.0516
2023-02-06 11:53:18 | Valid | Epoch[127/600] Iteration[002/008] Valid loss: 0.0481
2023-02-06 11:53:18 | Valid | Epoch[127/600] Iteration[003/008] Valid loss: 0.0479
2023-02-06 11:53:18 | Valid | Epoch[127/600] Iteration[004/008] Valid loss: 0.0465
2023-02-06 11:53:18 | Valid | Epoch[127/600] Iteration[005/008] Valid loss: 0.0467
2023-02-06 11:53:18 | Valid | Epoch[127/600] Iteration[006/008] Valid loss: 0.0461
2023-02-06 11:53:18 | Valid | Epoch[127/600] Iteration[007/008] Valid loss: 0.0466
2023-02-06 11:53:19 | Valid | Epoch[127/600] Iteration[008/008] Valid loss: 0.0464
2023-02-06 11:53:19 | Valid | Epoch[127/600] MIou: 0.9107394700802863
2023-02-06 11:53:19 | Valid | Epoch[127/600] Pixel Accuracy: 0.9851582845052084
2023-02-06 11:53:19 | Valid | Epoch[127/600] Mean Pixel Accuracy: 0.9230419038026282
2023-02-06 11:53:19 | Stage | Epoch[127/600] Train loss:0.0371
2023-02-06 11:53:19 | Stage | Epoch[127/600] Valid loss:0.0464
2023-02-06 11:53:19 | Stage | Epoch[127/600] LR:0.01

2023-02-06 11:53:19 | Train | Epoch[128/600] Iteration[001/030] Train loss: 0.0371
2023-02-06 11:53:19 | Train | Epoch[128/600] Iteration[002/030] Train loss: 0.0378
2023-02-06 11:53:19 | Train | Epoch[128/600] Iteration[003/030] Train loss: 0.0370
2023-02-06 11:53:19 | Train | Epoch[128/600] Iteration[004/030] Train loss: 0.0362
2023-02-06 11:53:19 | Train | Epoch[128/600] Iteration[005/030] Train loss: 0.0362
2023-02-06 11:53:19 | Train | Epoch[128/600] Iteration[006/030] Train loss: 0.0363
2023-02-06 11:53:19 | Train | Epoch[128/600] Iteration[007/030] Train loss: 0.0365
2023-02-06 11:53:19 | Train | Epoch[128/600] Iteration[008/030] Train loss: 0.0364
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[009/030] Train loss: 0.0365
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[010/030] Train loss: 0.0362
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[011/030] Train loss: 0.0363
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[012/030] Train loss: 0.0363
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[013/030] Train loss: 0.0364
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[014/030] Train loss: 0.0366
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[015/030] Train loss: 0.0366
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[016/030] Train loss: 0.0367
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[017/030] Train loss: 0.0367
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[018/030] Train loss: 0.0368
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[019/030] Train loss: 0.0369
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[020/030] Train loss: 0.0370
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[021/030] Train loss: 0.0372
2023-02-06 11:53:20 | Train | Epoch[128/600] Iteration[022/030] Train loss: 0.0371
2023-02-06 11:53:21 | Train | Epoch[128/600] Iteration[023/030] Train loss: 0.0370
2023-02-06 11:53:21 | Train | Epoch[128/600] Iteration[024/030] Train loss: 0.0371
2023-02-06 11:53:21 | Train | Epoch[128/600] Iteration[025/030] Train loss: 0.0371
2023-02-06 11:53:21 | Train | Epoch[128/600] Iteration[026/030] Train loss: 0.0370
2023-02-06 11:53:21 | Train | Epoch[128/600] Iteration[027/030] Train loss: 0.0370
2023-02-06 11:53:21 | Train | Epoch[128/600] Iteration[028/030] Train loss: 0.0369
2023-02-06 11:53:21 | Train | Epoch[128/600] Iteration[029/030] Train loss: 0.0370
2023-02-06 11:53:21 | Train | Epoch[128/600] Iteration[030/030] Train loss: 0.0370
2023-02-06 11:53:21 | Valid | Epoch[128/600] Iteration[001/008] Valid loss: 0.0635
2023-02-06 11:53:21 | Valid | Epoch[128/600] Iteration[002/008] Valid loss: 0.0626
2023-02-06 11:53:21 | Valid | Epoch[128/600] Iteration[003/008] Valid loss: 0.0649
2023-02-06 11:53:21 | Valid | Epoch[128/600] Iteration[004/008] Valid loss: 0.0632
2023-02-06 11:53:21 | Valid | Epoch[128/600] Iteration[005/008] Valid loss: 0.0634
2023-02-06 11:53:21 | Valid | Epoch[128/600] Iteration[006/008] Valid loss: 0.0630
2023-02-06 11:53:22 | Valid | Epoch[128/600] Iteration[007/008] Valid loss: 0.0625
2023-02-06 11:53:22 | Valid | Epoch[128/600] Iteration[008/008] Valid loss: 0.0638
2023-02-06 11:53:22 | Valid | Epoch[128/600] MIou: 0.813719963205334
2023-02-06 11:53:22 | Valid | Epoch[128/600] Pixel Accuracy: 0.9692420959472656
2023-02-06 11:53:22 | Valid | Epoch[128/600] Mean Pixel Accuracy: 0.830656528046314
2023-02-06 11:53:22 | Stage | Epoch[128/600] Train loss:0.0370
2023-02-06 11:53:22 | Stage | Epoch[128/600] Valid loss:0.0638
2023-02-06 11:53:22 | Stage | Epoch[128/600] LR:0.01

2023-02-06 11:53:22 | Train | Epoch[129/600] Iteration[001/030] Train loss: 0.0376
2023-02-06 11:53:22 | Train | Epoch[129/600] Iteration[002/030] Train loss: 0.0367
2023-02-06 11:53:22 | Train | Epoch[129/600] Iteration[003/030] Train loss: 0.0377
2023-02-06 11:53:22 | Train | Epoch[129/600] Iteration[004/030] Train loss: 0.0369
2023-02-06 11:53:22 | Train | Epoch[129/600] Iteration[005/030] Train loss: 0.0363
2023-02-06 11:53:22 | Train | Epoch[129/600] Iteration[006/030] Train loss: 0.0368
2023-02-06 11:53:22 | Train | Epoch[129/600] Iteration[007/030] Train loss: 0.0364
2023-02-06 11:53:22 | Train | Epoch[129/600] Iteration[008/030] Train loss: 0.0369
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[009/030] Train loss: 0.0366
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[010/030] Train loss: 0.0365
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[011/030] Train loss: 0.0367
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[012/030] Train loss: 0.0365
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[013/030] Train loss: 0.0365
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[014/030] Train loss: 0.0365
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[015/030] Train loss: 0.0366
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[016/030] Train loss: 0.0366
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[017/030] Train loss: 0.0366
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[018/030] Train loss: 0.0365
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[019/030] Train loss: 0.0365
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[020/030] Train loss: 0.0364
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[021/030] Train loss: 0.0365
2023-02-06 11:53:23 | Train | Epoch[129/600] Iteration[022/030] Train loss: 0.0364
2023-02-06 11:53:24 | Train | Epoch[129/600] Iteration[023/030] Train loss: 0.0363
2023-02-06 11:53:24 | Train | Epoch[129/600] Iteration[024/030] Train loss: 0.0363
2023-02-06 11:53:24 | Train | Epoch[129/600] Iteration[025/030] Train loss: 0.0363
2023-02-06 11:53:24 | Train | Epoch[129/600] Iteration[026/030] Train loss: 0.0364
2023-02-06 11:53:24 | Train | Epoch[129/600] Iteration[027/030] Train loss: 0.0364
2023-02-06 11:53:24 | Train | Epoch[129/600] Iteration[028/030] Train loss: 0.0365
2023-02-06 11:53:24 | Train | Epoch[129/600] Iteration[029/030] Train loss: 0.0364
2023-02-06 11:53:24 | Train | Epoch[129/600] Iteration[030/030] Train loss: 0.0363
2023-02-06 11:53:24 | Valid | Epoch[129/600] Iteration[001/008] Valid loss: 0.4452
2023-02-06 11:53:24 | Valid | Epoch[129/600] Iteration[002/008] Valid loss: 0.3666
2023-02-06 11:53:24 | Valid | Epoch[129/600] Iteration[003/008] Valid loss: 0.3558
2023-02-06 11:53:24 | Valid | Epoch[129/600] Iteration[004/008] Valid loss: 0.3564
2023-02-06 11:53:24 | Valid | Epoch[129/600] Iteration[005/008] Valid loss: 0.3707
2023-02-06 11:53:24 | Valid | Epoch[129/600] Iteration[006/008] Valid loss: 0.3624
2023-02-06 11:53:25 | Valid | Epoch[129/600] Iteration[007/008] Valid loss: 0.3790
2023-02-06 11:53:25 | Valid | Epoch[129/600] Iteration[008/008] Valid loss: 0.3665
2023-02-06 11:53:25 | Valid | Epoch[129/600] MIou: 0.89790216363511
2023-02-06 11:53:25 | Valid | Epoch[129/600] Pixel Accuracy: 0.9800758361816406
2023-02-06 11:53:25 | Valid | Epoch[129/600] Mean Pixel Accuracy: 0.9842681143002867
2023-02-06 11:53:25 | Stage | Epoch[129/600] Train loss:0.0363
2023-02-06 11:53:25 | Stage | Epoch[129/600] Valid loss:0.3665
2023-02-06 11:53:25 | Stage | Epoch[129/600] LR:0.01

2023-02-06 11:53:25 | Train | Epoch[130/600] Iteration[001/030] Train loss: 0.0347
2023-02-06 11:53:25 | Train | Epoch[130/600] Iteration[002/030] Train loss: 0.0346
2023-02-06 11:53:25 | Train | Epoch[130/600] Iteration[003/030] Train loss: 0.0344
2023-02-06 11:53:25 | Train | Epoch[130/600] Iteration[004/030] Train loss: 0.0346
2023-02-06 11:53:25 | Train | Epoch[130/600] Iteration[005/030] Train loss: 0.0346
2023-02-06 11:53:25 | Train | Epoch[130/600] Iteration[006/030] Train loss: 0.0350
2023-02-06 11:53:25 | Train | Epoch[130/600] Iteration[007/030] Train loss: 0.0348
2023-02-06 11:53:25 | Train | Epoch[130/600] Iteration[008/030] Train loss: 0.0347
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[009/030] Train loss: 0.0346
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[010/030] Train loss: 0.0347
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[011/030] Train loss: 0.0354
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[012/030] Train loss: 0.0357
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[013/030] Train loss: 0.0356
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[014/030] Train loss: 0.0355
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[015/030] Train loss: 0.0356
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[016/030] Train loss: 0.0359
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[017/030] Train loss: 0.0362
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[018/030] Train loss: 0.0362
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[019/030] Train loss: 0.0362
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[020/030] Train loss: 0.0362
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[021/030] Train loss: 0.0362
2023-02-06 11:53:26 | Train | Epoch[130/600] Iteration[022/030] Train loss: 0.0363
2023-02-06 11:53:27 | Train | Epoch[130/600] Iteration[023/030] Train loss: 0.0364
2023-02-06 11:53:27 | Train | Epoch[130/600] Iteration[024/030] Train loss: 0.0364
2023-02-06 11:53:27 | Train | Epoch[130/600] Iteration[025/030] Train loss: 0.0364
2023-02-06 11:53:27 | Train | Epoch[130/600] Iteration[026/030] Train loss: 0.0365
2023-02-06 11:53:27 | Train | Epoch[130/600] Iteration[027/030] Train loss: 0.0364
2023-02-06 11:53:27 | Train | Epoch[130/600] Iteration[028/030] Train loss: 0.0364
2023-02-06 11:53:27 | Train | Epoch[130/600] Iteration[029/030] Train loss: 0.0363
2023-02-06 11:53:27 | Train | Epoch[130/600] Iteration[030/030] Train loss: 0.0364
2023-02-06 11:53:27 | Valid | Epoch[130/600] Iteration[001/008] Valid loss: 0.5997
2023-02-06 11:53:27 | Valid | Epoch[130/600] Iteration[002/008] Valid loss: 0.5280
2023-02-06 11:53:27 | Valid | Epoch[130/600] Iteration[003/008] Valid loss: 0.5289
2023-02-06 11:53:27 | Valid | Epoch[130/600] Iteration[004/008] Valid loss: 0.5289
2023-02-06 11:53:27 | Valid | Epoch[130/600] Iteration[005/008] Valid loss: 0.5473
2023-02-06 11:53:27 | Valid | Epoch[130/600] Iteration[006/008] Valid loss: 0.5336
2023-02-06 11:53:27 | Valid | Epoch[130/600] Iteration[007/008] Valid loss: 0.5610
2023-02-06 11:53:28 | Valid | Epoch[130/600] Iteration[008/008] Valid loss: 0.5599
2023-02-06 11:53:28 | Valid | Epoch[130/600] MIou: 0.8617200492111692
2023-02-06 11:53:28 | Valid | Epoch[130/600] Pixel Accuracy: 0.9709803263346354
2023-02-06 11:53:28 | Valid | Epoch[130/600] Mean Pixel Accuracy: 0.9803720762173618
2023-02-06 11:53:28 | Stage | Epoch[130/600] Train loss:0.0364
2023-02-06 11:53:28 | Stage | Epoch[130/600] Valid loss:0.5599
2023-02-06 11:53:28 | Stage | Epoch[130/600] LR:0.01

2023-02-06 11:53:28 | Train | Epoch[131/600] Iteration[001/030] Train loss: 0.0356
2023-02-06 11:53:28 | Train | Epoch[131/600] Iteration[002/030] Train loss: 0.0355
2023-02-06 11:53:28 | Train | Epoch[131/600] Iteration[003/030] Train loss: 0.0374
2023-02-06 11:53:28 | Train | Epoch[131/600] Iteration[004/030] Train loss: 0.0371
2023-02-06 11:53:28 | Train | Epoch[131/600] Iteration[005/030] Train loss: 0.0368
2023-02-06 11:53:28 | Train | Epoch[131/600] Iteration[006/030] Train loss: 0.0365
2023-02-06 11:53:28 | Train | Epoch[131/600] Iteration[007/030] Train loss: 0.0363
2023-02-06 11:53:28 | Train | Epoch[131/600] Iteration[008/030] Train loss: 0.0366
2023-02-06 11:53:28 | Train | Epoch[131/600] Iteration[009/030] Train loss: 0.0367
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[010/030] Train loss: 0.0368
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[011/030] Train loss: 0.0367
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[012/030] Train loss: 0.0365
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[013/030] Train loss: 0.0364
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[014/030] Train loss: 0.0364
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[015/030] Train loss: 0.0362
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[016/030] Train loss: 0.0361
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[017/030] Train loss: 0.0359
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[018/030] Train loss: 0.0359
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[019/030] Train loss: 0.0358
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[020/030] Train loss: 0.0359
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[021/030] Train loss: 0.0358
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[022/030] Train loss: 0.0357
2023-02-06 11:53:29 | Train | Epoch[131/600] Iteration[023/030] Train loss: 0.0356
2023-02-06 11:53:30 | Train | Epoch[131/600] Iteration[024/030] Train loss: 0.0356
2023-02-06 11:53:30 | Train | Epoch[131/600] Iteration[025/030] Train loss: 0.0355
2023-02-06 11:53:30 | Train | Epoch[131/600] Iteration[026/030] Train loss: 0.0356
2023-02-06 11:53:30 | Train | Epoch[131/600] Iteration[027/030] Train loss: 0.0356
2023-02-06 11:53:30 | Train | Epoch[131/600] Iteration[028/030] Train loss: 0.0359
2023-02-06 11:53:30 | Train | Epoch[131/600] Iteration[029/030] Train loss: 0.0359
2023-02-06 11:53:30 | Train | Epoch[131/600] Iteration[030/030] Train loss: 0.0358
2023-02-06 11:53:30 | Valid | Epoch[131/600] Iteration[001/008] Valid loss: 0.2300
2023-02-06 11:53:30 | Valid | Epoch[131/600] Iteration[002/008] Valid loss: 0.2365
2023-02-06 11:53:30 | Valid | Epoch[131/600] Iteration[003/008] Valid loss: 0.2531
2023-02-06 11:53:30 | Valid | Epoch[131/600] Iteration[004/008] Valid loss: 0.2520
2023-02-06 11:53:30 | Valid | Epoch[131/600] Iteration[005/008] Valid loss: 0.2605
2023-02-06 11:53:30 | Valid | Epoch[131/600] Iteration[006/008] Valid loss: 0.2580
2023-02-06 11:53:30 | Valid | Epoch[131/600] Iteration[007/008] Valid loss: 0.2549
2023-02-06 11:53:30 | Valid | Epoch[131/600] Iteration[008/008] Valid loss: 0.2659
2023-02-06 11:53:31 | Valid | Epoch[131/600] MIou: 0.4600137617771013
2023-02-06 11:53:31 | Valid | Epoch[131/600] Pixel Accuracy: 0.9105453491210938
2023-02-06 11:53:31 | Valid | Epoch[131/600] Mean Pixel Accuracy: 0.5047797378535528
2023-02-06 11:53:31 | Stage | Epoch[131/600] Train loss:0.0358
2023-02-06 11:53:31 | Stage | Epoch[131/600] Valid loss:0.2659
2023-02-06 11:53:31 | Stage | Epoch[131/600] LR:0.01

2023-02-06 11:53:31 | Train | Epoch[132/600] Iteration[001/030] Train loss: 0.0364
2023-02-06 11:53:31 | Train | Epoch[132/600] Iteration[002/030] Train loss: 0.0379
2023-02-06 11:53:31 | Train | Epoch[132/600] Iteration[003/030] Train loss: 0.0380
2023-02-06 11:53:31 | Train | Epoch[132/600] Iteration[004/030] Train loss: 0.0373
2023-02-06 11:53:31 | Train | Epoch[132/600] Iteration[005/030] Train loss: 0.0371
2023-02-06 11:53:31 | Train | Epoch[132/600] Iteration[006/030] Train loss: 0.0372
2023-02-06 11:53:31 | Train | Epoch[132/600] Iteration[007/030] Train loss: 0.0371
2023-02-06 11:53:31 | Train | Epoch[132/600] Iteration[008/030] Train loss: 0.0365
2023-02-06 11:53:31 | Train | Epoch[132/600] Iteration[009/030] Train loss: 0.0367
2023-02-06 11:53:31 | Train | Epoch[132/600] Iteration[010/030] Train loss: 0.0367
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[011/030] Train loss: 0.0364
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[012/030] Train loss: 0.0362
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[013/030] Train loss: 0.0361
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[014/030] Train loss: 0.0362
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[015/030] Train loss: 0.0362
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[016/030] Train loss: 0.0360
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[017/030] Train loss: 0.0360
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[018/030] Train loss: 0.0360
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[019/030] Train loss: 0.0358
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[020/030] Train loss: 0.0358
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[021/030] Train loss: 0.0359
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[022/030] Train loss: 0.0358
2023-02-06 11:53:32 | Train | Epoch[132/600] Iteration[023/030] Train loss: 0.0357
2023-02-06 11:53:33 | Train | Epoch[132/600] Iteration[024/030] Train loss: 0.0357
2023-02-06 11:53:33 | Train | Epoch[132/600] Iteration[025/030] Train loss: 0.0357
2023-02-06 11:53:33 | Train | Epoch[132/600] Iteration[026/030] Train loss: 0.0357
2023-02-06 11:53:33 | Train | Epoch[132/600] Iteration[027/030] Train loss: 0.0357
2023-02-06 11:53:33 | Train | Epoch[132/600] Iteration[028/030] Train loss: 0.0357
2023-02-06 11:53:33 | Train | Epoch[132/600] Iteration[029/030] Train loss: 0.0356
2023-02-06 11:53:33 | Train | Epoch[132/600] Iteration[030/030] Train loss: 0.0356
2023-02-06 11:53:33 | Valid | Epoch[132/600] Iteration[001/008] Valid loss: 0.0900
2023-02-06 11:53:33 | Valid | Epoch[132/600] Iteration[002/008] Valid loss: 0.0934
2023-02-06 11:53:33 | Valid | Epoch[132/600] Iteration[003/008] Valid loss: 0.0981
2023-02-06 11:53:33 | Valid | Epoch[132/600] Iteration[004/008] Valid loss: 0.0966
2023-02-06 11:53:33 | Valid | Epoch[132/600] Iteration[005/008] Valid loss: 0.0981
2023-02-06 11:53:33 | Valid | Epoch[132/600] Iteration[006/008] Valid loss: 0.0961
2023-02-06 11:53:33 | Valid | Epoch[132/600] Iteration[007/008] Valid loss: 0.0945
2023-02-06 11:53:33 | Valid | Epoch[132/600] Iteration[008/008] Valid loss: 0.0975
2023-02-06 11:53:33 | Valid | Epoch[132/600] MIou: 0.6998230271376294
2023-02-06 11:53:33 | Valid | Epoch[132/600] Pixel Accuracy: 0.9504432678222656
2023-02-06 11:53:33 | Valid | Epoch[132/600] Mean Pixel Accuracy: 0.7256543102113221
2023-02-06 11:53:33 | Stage | Epoch[132/600] Train loss:0.0356
2023-02-06 11:53:33 | Stage | Epoch[132/600] Valid loss:0.0975
2023-02-06 11:53:33 | Stage | Epoch[132/600] LR:0.01

2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[001/030] Train loss: 0.0342
2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[002/030] Train loss: 0.0347
2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[003/030] Train loss: 0.0341
2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[004/030] Train loss: 0.0340
2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[005/030] Train loss: 0.0343
2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[006/030] Train loss: 0.0345
2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[007/030] Train loss: 0.0351
2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[008/030] Train loss: 0.0348
2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[009/030] Train loss: 0.0349
2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[010/030] Train loss: 0.0347
2023-02-06 11:53:34 | Train | Epoch[133/600] Iteration[011/030] Train loss: 0.0345
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[012/030] Train loss: 0.0346
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[013/030] Train loss: 0.0346
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[014/030] Train loss: 0.0347
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[015/030] Train loss: 0.0348
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[016/030] Train loss: 0.0348
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[017/030] Train loss: 0.0349
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[018/030] Train loss: 0.0349
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[019/030] Train loss: 0.0348
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[020/030] Train loss: 0.0349
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[021/030] Train loss: 0.0350
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[022/030] Train loss: 0.0349
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[023/030] Train loss: 0.0349
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[024/030] Train loss: 0.0348
2023-02-06 11:53:35 | Train | Epoch[133/600] Iteration[025/030] Train loss: 0.0348
2023-02-06 11:53:36 | Train | Epoch[133/600] Iteration[026/030] Train loss: 0.0348
2023-02-06 11:53:36 | Train | Epoch[133/600] Iteration[027/030] Train loss: 0.0348
2023-02-06 11:53:36 | Train | Epoch[133/600] Iteration[028/030] Train loss: 0.0348
2023-02-06 11:53:36 | Train | Epoch[133/600] Iteration[029/030] Train loss: 0.0349
2023-02-06 11:53:36 | Train | Epoch[133/600] Iteration[030/030] Train loss: 0.0349
2023-02-06 11:53:36 | Valid | Epoch[133/600] Iteration[001/008] Valid loss: 0.0604
2023-02-06 11:53:36 | Valid | Epoch[133/600] Iteration[002/008] Valid loss: 0.0610
2023-02-06 11:53:36 | Valid | Epoch[133/600] Iteration[003/008] Valid loss: 0.0639
2023-02-06 11:53:36 | Valid | Epoch[133/600] Iteration[004/008] Valid loss: 0.0625
2023-02-06 11:53:36 | Valid | Epoch[133/600] Iteration[005/008] Valid loss: 0.0625
2023-02-06 11:53:36 | Valid | Epoch[133/600] Iteration[006/008] Valid loss: 0.0618
2023-02-06 11:53:36 | Valid | Epoch[133/600] Iteration[007/008] Valid loss: 0.0610
2023-02-06 11:53:36 | Valid | Epoch[133/600] Iteration[008/008] Valid loss: 0.0622
2023-02-06 11:53:36 | Valid | Epoch[133/600] MIou: 0.8154202237410476
2023-02-06 11:53:36 | Valid | Epoch[133/600] Pixel Accuracy: 0.9695523579915365
2023-02-06 11:53:36 | Valid | Epoch[133/600] Mean Pixel Accuracy: 0.8319049414552548
2023-02-06 11:53:36 | Stage | Epoch[133/600] Train loss:0.0349
2023-02-06 11:53:36 | Stage | Epoch[133/600] Valid loss:0.0622
2023-02-06 11:53:36 | Stage | Epoch[133/600] LR:0.01

2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[001/030] Train loss: 0.0323
2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[002/030] Train loss: 0.0324
2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[003/030] Train loss: 0.0329
2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[004/030] Train loss: 0.0344
2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[005/030] Train loss: 0.0346
2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[006/030] Train loss: 0.0346
2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[007/030] Train loss: 0.0345
2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[008/030] Train loss: 0.0346
2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[009/030] Train loss: 0.0344
2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[010/030] Train loss: 0.0343
2023-02-06 11:53:37 | Train | Epoch[134/600] Iteration[011/030] Train loss: 0.0344
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[012/030] Train loss: 0.0347
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[013/030] Train loss: 0.0345
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[014/030] Train loss: 0.0344
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[015/030] Train loss: 0.0346
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[016/030] Train loss: 0.0347
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[017/030] Train loss: 0.0348
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[018/030] Train loss: 0.0347
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[019/030] Train loss: 0.0346
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[020/030] Train loss: 0.0347
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[021/030] Train loss: 0.0347
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[022/030] Train loss: 0.0347
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[023/030] Train loss: 0.0348
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[024/030] Train loss: 0.0348
2023-02-06 11:53:38 | Train | Epoch[134/600] Iteration[025/030] Train loss: 0.0349
2023-02-06 11:53:39 | Train | Epoch[134/600] Iteration[026/030] Train loss: 0.0349
2023-02-06 11:53:39 | Train | Epoch[134/600] Iteration[027/030] Train loss: 0.0348
2023-02-06 11:53:39 | Train | Epoch[134/600] Iteration[028/030] Train loss: 0.0348
2023-02-06 11:53:39 | Train | Epoch[134/600] Iteration[029/030] Train loss: 0.0348
2023-02-06 11:53:39 | Train | Epoch[134/600] Iteration[030/030] Train loss: 0.0348
2023-02-06 11:53:39 | Valid | Epoch[134/600] Iteration[001/008] Valid loss: 0.2447
2023-02-06 11:53:39 | Valid | Epoch[134/600] Iteration[002/008] Valid loss: 0.1798
2023-02-06 11:53:39 | Valid | Epoch[134/600] Iteration[003/008] Valid loss: 0.1693
2023-02-06 11:53:39 | Valid | Epoch[134/600] Iteration[004/008] Valid loss: 0.1625
2023-02-06 11:53:39 | Valid | Epoch[134/600] Iteration[005/008] Valid loss: 0.1643
2023-02-06 11:53:39 | Valid | Epoch[134/600] Iteration[006/008] Valid loss: 0.1593
2023-02-06 11:53:39 | Valid | Epoch[134/600] Iteration[007/008] Valid loss: 0.1631
2023-02-06 11:53:39 | Valid | Epoch[134/600] Iteration[008/008] Valid loss: 0.1535
2023-02-06 11:53:39 | Valid | Epoch[134/600] MIou: 0.9349853586297954
2023-02-06 11:53:39 | Valid | Epoch[134/600] Pixel Accuracy: 0.9885953267415365
2023-02-06 11:53:39 | Valid | Epoch[134/600] Mean Pixel Accuracy: 0.9702527391703666
2023-02-06 11:53:39 | Stage | Epoch[134/600] Train loss:0.0348
2023-02-06 11:53:39 | Stage | Epoch[134/600] Valid loss:0.1535
2023-02-06 11:53:39 | Stage | Epoch[134/600] LR:0.01

2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[001/030] Train loss: 0.0324
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[002/030] Train loss: 0.0326
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[003/030] Train loss: 0.0337
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[004/030] Train loss: 0.0343
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[005/030] Train loss: 0.0353
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[006/030] Train loss: 0.0354
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[007/030] Train loss: 0.0352
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[008/030] Train loss: 0.0348
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[009/030] Train loss: 0.0346
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[010/030] Train loss: 0.0346
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[011/030] Train loss: 0.0345
2023-02-06 11:53:40 | Train | Epoch[135/600] Iteration[012/030] Train loss: 0.0346
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[013/030] Train loss: 0.0349
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[014/030] Train loss: 0.0349
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[015/030] Train loss: 0.0348
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[016/030] Train loss: 0.0347
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[017/030] Train loss: 0.0347
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[018/030] Train loss: 0.0348
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[019/030] Train loss: 0.0349
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[020/030] Train loss: 0.0348
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[021/030] Train loss: 0.0348
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[022/030] Train loss: 0.0349
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[023/030] Train loss: 0.0348
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[024/030] Train loss: 0.0347
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[025/030] Train loss: 0.0348
2023-02-06 11:53:41 | Train | Epoch[135/600] Iteration[026/030] Train loss: 0.0347
2023-02-06 11:53:42 | Train | Epoch[135/600] Iteration[027/030] Train loss: 0.0347
2023-02-06 11:53:42 | Train | Epoch[135/600] Iteration[028/030] Train loss: 0.0347
2023-02-06 11:53:42 | Train | Epoch[135/600] Iteration[029/030] Train loss: 0.0348
2023-02-06 11:53:42 | Train | Epoch[135/600] Iteration[030/030] Train loss: 0.0347
2023-02-06 11:53:42 | Valid | Epoch[135/600] Iteration[001/008] Valid loss: 1.6224
2023-02-06 11:53:42 | Valid | Epoch[135/600] Iteration[002/008] Valid loss: 1.4993
2023-02-06 11:53:42 | Valid | Epoch[135/600] Iteration[003/008] Valid loss: 1.5114
2023-02-06 11:53:42 | Valid | Epoch[135/600] Iteration[004/008] Valid loss: 1.5698
2023-02-06 11:53:42 | Valid | Epoch[135/600] Iteration[005/008] Valid loss: 1.6113
2023-02-06 11:53:42 | Valid | Epoch[135/600] Iteration[006/008] Valid loss: 1.5741
2023-02-06 11:53:42 | Valid | Epoch[135/600] Iteration[007/008] Valid loss: 1.6181
2023-02-06 11:53:42 | Valid | Epoch[135/600] Iteration[008/008] Valid loss: 1.6568
2023-02-06 11:53:42 | Valid | Epoch[135/600] MIou: 0.8146432876140236
2023-02-06 11:53:42 | Valid | Epoch[135/600] Pixel Accuracy: 0.9569625854492188
2023-02-06 11:53:42 | Valid | Epoch[135/600] Mean Pixel Accuracy: 0.974924535842848
2023-02-06 11:53:42 | Stage | Epoch[135/600] Train loss:0.0347
2023-02-06 11:53:42 | Stage | Epoch[135/600] Valid loss:1.6568
2023-02-06 11:53:42 | Stage | Epoch[135/600] LR:0.01

2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[001/030] Train loss: 0.0337
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[002/030] Train loss: 0.0335
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[003/030] Train loss: 0.0331
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[004/030] Train loss: 0.0336
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[005/030] Train loss: 0.0340
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[006/030] Train loss: 0.0340
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[007/030] Train loss: 0.0340
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[008/030] Train loss: 0.0340
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[009/030] Train loss: 0.0340
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[010/030] Train loss: 0.0340
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[011/030] Train loss: 0.0339
2023-02-06 11:53:43 | Train | Epoch[136/600] Iteration[012/030] Train loss: 0.0339
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[013/030] Train loss: 0.0338
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[014/030] Train loss: 0.0339
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[015/030] Train loss: 0.0340
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[016/030] Train loss: 0.0339
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[017/030] Train loss: 0.0340
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[018/030] Train loss: 0.0339
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[019/030] Train loss: 0.0338
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[020/030] Train loss: 0.0339
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[021/030] Train loss: 0.0339
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[022/030] Train loss: 0.0339
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[023/030] Train loss: 0.0339
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[024/030] Train loss: 0.0340
2023-02-06 11:53:44 | Train | Epoch[136/600] Iteration[025/030] Train loss: 0.0342
2023-02-06 11:53:45 | Train | Epoch[136/600] Iteration[026/030] Train loss: 0.0341
2023-02-06 11:53:45 | Train | Epoch[136/600] Iteration[027/030] Train loss: 0.0340
2023-02-06 11:53:45 | Train | Epoch[136/600] Iteration[028/030] Train loss: 0.0340
2023-02-06 11:53:45 | Train | Epoch[136/600] Iteration[029/030] Train loss: 0.0341
2023-02-06 11:53:45 | Train | Epoch[136/600] Iteration[030/030] Train loss: 0.0342
2023-02-06 11:53:45 | Valid | Epoch[136/600] Iteration[001/008] Valid loss: 0.2298
2023-02-06 11:53:45 | Valid | Epoch[136/600] Iteration[002/008] Valid loss: 0.1781
2023-02-06 11:53:45 | Valid | Epoch[136/600] Iteration[003/008] Valid loss: 0.1690
2023-02-06 11:53:45 | Valid | Epoch[136/600] Iteration[004/008] Valid loss: 0.1672
2023-02-06 11:53:45 | Valid | Epoch[136/600] Iteration[005/008] Valid loss: 0.1725
2023-02-06 11:53:45 | Valid | Epoch[136/600] Iteration[006/008] Valid loss: 0.1638
2023-02-06 11:53:45 | Valid | Epoch[136/600] Iteration[007/008] Valid loss: 0.1812
2023-02-06 11:53:45 | Valid | Epoch[136/600] Iteration[008/008] Valid loss: 0.1794
2023-02-06 11:53:45 | Valid | Epoch[136/600] MIou: 0.9129219336513466
2023-02-06 11:53:45 | Valid | Epoch[136/600] Pixel Accuracy: 0.9837748209635416
2023-02-06 11:53:45 | Valid | Epoch[136/600] Mean Pixel Accuracy: 0.9771963170029583
2023-02-06 11:53:45 | Stage | Epoch[136/600] Train loss:0.0342
2023-02-06 11:53:45 | Stage | Epoch[136/600] Valid loss:0.1794
2023-02-06 11:53:45 | Stage | Epoch[136/600] LR:0.01

2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[001/030] Train loss: 0.0354
2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[002/030] Train loss: 0.0343
2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[003/030] Train loss: 0.0341
2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[004/030] Train loss: 0.0335
2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[005/030] Train loss: 0.0331
2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[006/030] Train loss: 0.0331
2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[007/030] Train loss: 0.0333
2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[008/030] Train loss: 0.0336
2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[009/030] Train loss: 0.0336
2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[010/030] Train loss: 0.0334
2023-02-06 11:53:46 | Train | Epoch[137/600] Iteration[011/030] Train loss: 0.0332
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[012/030] Train loss: 0.0331
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[013/030] Train loss: 0.0331
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[014/030] Train loss: 0.0332
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[015/030] Train loss: 0.0333
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[016/030] Train loss: 0.0334
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[017/030] Train loss: 0.0336
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[018/030] Train loss: 0.0336
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[019/030] Train loss: 0.0337
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[020/030] Train loss: 0.0336
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[021/030] Train loss: 0.0337
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[022/030] Train loss: 0.0337
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[023/030] Train loss: 0.0337
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[024/030] Train loss: 0.0337
2023-02-06 11:53:47 | Train | Epoch[137/600] Iteration[025/030] Train loss: 0.0337
2023-02-06 11:53:48 | Train | Epoch[137/600] Iteration[026/030] Train loss: 0.0338
2023-02-06 11:53:48 | Train | Epoch[137/600] Iteration[027/030] Train loss: 0.0338
2023-02-06 11:53:48 | Train | Epoch[137/600] Iteration[028/030] Train loss: 0.0338
2023-02-06 11:53:48 | Train | Epoch[137/600] Iteration[029/030] Train loss: 0.0340
2023-02-06 11:53:48 | Train | Epoch[137/600] Iteration[030/030] Train loss: 0.0341
2023-02-06 11:53:48 | Valid | Epoch[137/600] Iteration[001/008] Valid loss: 0.1003
2023-02-06 11:53:48 | Valid | Epoch[137/600] Iteration[002/008] Valid loss: 0.0748
2023-02-06 11:53:48 | Valid | Epoch[137/600] Iteration[003/008] Valid loss: 0.0684
2023-02-06 11:53:48 | Valid | Epoch[137/600] Iteration[004/008] Valid loss: 0.0646
2023-02-06 11:53:48 | Valid | Epoch[137/600] Iteration[005/008] Valid loss: 0.0638
2023-02-06 11:53:48 | Valid | Epoch[137/600] Iteration[006/008] Valid loss: 0.0612
2023-02-06 11:53:48 | Valid | Epoch[137/600] Iteration[007/008] Valid loss: 0.0640
2023-02-06 11:53:48 | Valid | Epoch[137/600] Iteration[008/008] Valid loss: 0.0629
2023-02-06 11:53:48 | Valid | Epoch[137/600] MIou: 0.9405574944551602
2023-02-06 11:53:48 | Valid | Epoch[137/600] Pixel Accuracy: 0.9897689819335938
2023-02-06 11:53:48 | Valid | Epoch[137/600] Mean Pixel Accuracy: 0.9666560546775231
2023-02-06 11:53:48 | Stage | Epoch[137/600] Train loss:0.0341
2023-02-06 11:53:48 | Stage | Epoch[137/600] Valid loss:0.0629
2023-02-06 11:53:48 | Stage | Epoch[137/600] LR:0.01

2023-02-06 11:53:49 | Train | Epoch[138/600] Iteration[001/030] Train loss: 0.0298
2023-02-06 11:53:49 | Train | Epoch[138/600] Iteration[002/030] Train loss: 0.0315
2023-02-06 11:53:49 | Train | Epoch[138/600] Iteration[003/030] Train loss: 0.0322
2023-02-06 11:53:49 | Train | Epoch[138/600] Iteration[004/030] Train loss: 0.0330
2023-02-06 11:53:49 | Train | Epoch[138/600] Iteration[005/030] Train loss: 0.0324
2023-02-06 11:53:49 | Train | Epoch[138/600] Iteration[006/030] Train loss: 0.0321
2023-02-06 11:53:49 | Train | Epoch[138/600] Iteration[007/030] Train loss: 0.0320
2023-02-06 11:53:49 | Train | Epoch[138/600] Iteration[008/030] Train loss: 0.0323
2023-02-06 11:53:49 | Train | Epoch[138/600] Iteration[009/030] Train loss: 0.0324
2023-02-06 11:53:49 | Train | Epoch[138/600] Iteration[010/030] Train loss: 0.0325
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[011/030] Train loss: 0.0329
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[012/030] Train loss: 0.0329
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[013/030] Train loss: 0.0332
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[014/030] Train loss: 0.0331
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[015/030] Train loss: 0.0334
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[016/030] Train loss: 0.0334
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[017/030] Train loss: 0.0334
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[018/030] Train loss: 0.0335
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[019/030] Train loss: 0.0337
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[020/030] Train loss: 0.0337
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[021/030] Train loss: 0.0336
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[022/030] Train loss: 0.0337
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[023/030] Train loss: 0.0336
2023-02-06 11:53:50 | Train | Epoch[138/600] Iteration[024/030] Train loss: 0.0337
2023-02-06 11:53:51 | Train | Epoch[138/600] Iteration[025/030] Train loss: 0.0336
2023-02-06 11:53:51 | Train | Epoch[138/600] Iteration[026/030] Train loss: 0.0337
2023-02-06 11:53:51 | Train | Epoch[138/600] Iteration[027/030] Train loss: 0.0338
2023-02-06 11:53:51 | Train | Epoch[138/600] Iteration[028/030] Train loss: 0.0338
2023-02-06 11:53:51 | Train | Epoch[138/600] Iteration[029/030] Train loss: 0.0337
2023-02-06 11:53:51 | Train | Epoch[138/600] Iteration[030/030] Train loss: 0.0338
2023-02-06 11:53:51 | Valid | Epoch[138/600] Iteration[001/008] Valid loss: 0.7413
2023-02-06 11:53:51 | Valid | Epoch[138/600] Iteration[002/008] Valid loss: 0.6888
2023-02-06 11:53:51 | Valid | Epoch[138/600] Iteration[003/008] Valid loss: 0.6894
2023-02-06 11:53:51 | Valid | Epoch[138/600] Iteration[004/008] Valid loss: 0.6965
2023-02-06 11:53:51 | Valid | Epoch[138/600] Iteration[005/008] Valid loss: 0.7212
2023-02-06 11:53:51 | Valid | Epoch[138/600] Iteration[006/008] Valid loss: 0.6964
2023-02-06 11:53:51 | Valid | Epoch[138/600] Iteration[007/008] Valid loss: 0.7262
2023-02-06 11:53:51 | Valid | Epoch[138/600] Iteration[008/008] Valid loss: 0.7368
2023-02-06 11:53:51 | Valid | Epoch[138/600] MIou: 0.8644778147549365
2023-02-06 11:53:51 | Valid | Epoch[138/600] Pixel Accuracy: 0.9716911315917969
2023-02-06 11:53:51 | Valid | Epoch[138/600] Mean Pixel Accuracy: 0.9812129385791664
2023-02-06 11:53:52 | Stage | Epoch[138/600] Train loss:0.0338
2023-02-06 11:53:52 | Stage | Epoch[138/600] Valid loss:0.7368
2023-02-06 11:53:52 | Stage | Epoch[138/600] LR:0.01

2023-02-06 11:53:52 | Train | Epoch[139/600] Iteration[001/030] Train loss: 0.0369
2023-02-06 11:53:52 | Train | Epoch[139/600] Iteration[002/030] Train loss: 0.0350
2023-02-06 11:53:52 | Train | Epoch[139/600] Iteration[003/030] Train loss: 0.0341
2023-02-06 11:53:52 | Train | Epoch[139/600] Iteration[004/030] Train loss: 0.0347
2023-02-06 11:53:52 | Train | Epoch[139/600] Iteration[005/030] Train loss: 0.0342
2023-02-06 11:53:52 | Train | Epoch[139/600] Iteration[006/030] Train loss: 0.0336
2023-02-06 11:53:52 | Train | Epoch[139/600] Iteration[007/030] Train loss: 0.0333
2023-02-06 11:53:52 | Train | Epoch[139/600] Iteration[008/030] Train loss: 0.0332
2023-02-06 11:53:52 | Train | Epoch[139/600] Iteration[009/030] Train loss: 0.0334
2023-02-06 11:53:52 | Train | Epoch[139/600] Iteration[010/030] Train loss: 0.0334
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[011/030] Train loss: 0.0335
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[012/030] Train loss: 0.0335
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[013/030] Train loss: 0.0335
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[014/030] Train loss: 0.0335
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[015/030] Train loss: 0.0336
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[016/030] Train loss: 0.0335
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[017/030] Train loss: 0.0335
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[018/030] Train loss: 0.0337
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[019/030] Train loss: 0.0335
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[020/030] Train loss: 0.0336
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[021/030] Train loss: 0.0336
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[022/030] Train loss: 0.0337
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[023/030] Train loss: 0.0337
2023-02-06 11:53:53 | Train | Epoch[139/600] Iteration[024/030] Train loss: 0.0337
2023-02-06 11:53:54 | Train | Epoch[139/600] Iteration[025/030] Train loss: 0.0337
2023-02-06 11:53:54 | Train | Epoch[139/600] Iteration[026/030] Train loss: 0.0338
2023-02-06 11:53:54 | Train | Epoch[139/600] Iteration[027/030] Train loss: 0.0337
2023-02-06 11:53:54 | Train | Epoch[139/600] Iteration[028/030] Train loss: 0.0337
2023-02-06 11:53:54 | Train | Epoch[139/600] Iteration[029/030] Train loss: 0.0336
2023-02-06 11:53:54 | Train | Epoch[139/600] Iteration[030/030] Train loss: 0.0336
2023-02-06 11:53:54 | Valid | Epoch[139/600] Iteration[001/008] Valid loss: 0.0642
2023-02-06 11:53:54 | Valid | Epoch[139/600] Iteration[002/008] Valid loss: 0.0541
2023-02-06 11:53:54 | Valid | Epoch[139/600] Iteration[003/008] Valid loss: 0.0536
2023-02-06 11:53:54 | Valid | Epoch[139/600] Iteration[004/008] Valid loss: 0.0508
2023-02-06 11:53:54 | Valid | Epoch[139/600] Iteration[005/008] Valid loss: 0.0509
2023-02-06 11:53:54 | Valid | Epoch[139/600] Iteration[006/008] Valid loss: 0.0502
2023-02-06 11:53:54 | Valid | Epoch[139/600] Iteration[007/008] Valid loss: 0.0512
2023-02-06 11:53:54 | Valid | Epoch[139/600] Iteration[008/008] Valid loss: 0.0505
2023-02-06 11:53:54 | Valid | Epoch[139/600] MIou: 0.9140726428621448
2023-02-06 11:53:54 | Valid | Epoch[139/600] Pixel Accuracy: 0.985558827718099
2023-02-06 11:53:54 | Valid | Epoch[139/600] Mean Pixel Accuracy: 0.9307247944049056
2023-02-06 11:53:54 | Stage | Epoch[139/600] Train loss:0.0336
2023-02-06 11:53:54 | Stage | Epoch[139/600] Valid loss:0.0505
2023-02-06 11:53:54 | Stage | Epoch[139/600] LR:0.01

2023-02-06 11:53:55 | Train | Epoch[140/600] Iteration[001/030] Train loss: 0.0330
2023-02-06 11:53:55 | Train | Epoch[140/600] Iteration[002/030] Train loss: 0.0333
2023-02-06 11:53:55 | Train | Epoch[140/600] Iteration[003/030] Train loss: 0.0332
2023-02-06 11:53:55 | Train | Epoch[140/600] Iteration[004/030] Train loss: 0.0335
2023-02-06 11:53:55 | Train | Epoch[140/600] Iteration[005/030] Train loss: 0.0339
2023-02-06 11:53:55 | Train | Epoch[140/600] Iteration[006/030] Train loss: 0.0336
2023-02-06 11:53:55 | Train | Epoch[140/600] Iteration[007/030] Train loss: 0.0338
2023-02-06 11:53:55 | Train | Epoch[140/600] Iteration[008/030] Train loss: 0.0340
2023-02-06 11:53:55 | Train | Epoch[140/600] Iteration[009/030] Train loss: 0.0340
2023-02-06 11:53:55 | Train | Epoch[140/600] Iteration[010/030] Train loss: 0.0338
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[011/030] Train loss: 0.0338
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[012/030] Train loss: 0.0337
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[013/030] Train loss: 0.0340
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[014/030] Train loss: 0.0341
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[015/030] Train loss: 0.0342
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[016/030] Train loss: 0.0341
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[017/030] Train loss: 0.0341
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[018/030] Train loss: 0.0340
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[019/030] Train loss: 0.0340
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[020/030] Train loss: 0.0339
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[021/030] Train loss: 0.0338
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[022/030] Train loss: 0.0340
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[023/030] Train loss: 0.0340
2023-02-06 11:53:56 | Train | Epoch[140/600] Iteration[024/030] Train loss: 0.0340
2023-02-06 11:53:57 | Train | Epoch[140/600] Iteration[025/030] Train loss: 0.0341
2023-02-06 11:53:57 | Train | Epoch[140/600] Iteration[026/030] Train loss: 0.0341
2023-02-06 11:53:57 | Train | Epoch[140/600] Iteration[027/030] Train loss: 0.0341
2023-02-06 11:53:57 | Train | Epoch[140/600] Iteration[028/030] Train loss: 0.0342
2023-02-06 11:53:57 | Train | Epoch[140/600] Iteration[029/030] Train loss: 0.0343
2023-02-06 11:53:57 | Train | Epoch[140/600] Iteration[030/030] Train loss: 0.0342
2023-02-06 11:53:57 | Valid | Epoch[140/600] Iteration[001/008] Valid loss: 0.0839
2023-02-06 11:53:57 | Valid | Epoch[140/600] Iteration[002/008] Valid loss: 0.0757
2023-02-06 11:53:57 | Valid | Epoch[140/600] Iteration[003/008] Valid loss: 0.0731
2023-02-06 11:53:57 | Valid | Epoch[140/600] Iteration[004/008] Valid loss: 0.0705
2023-02-06 11:53:57 | Valid | Epoch[140/600] Iteration[005/008] Valid loss: 0.0715
2023-02-06 11:53:57 | Valid | Epoch[140/600] Iteration[006/008] Valid loss: 0.0689
2023-02-06 11:53:57 | Valid | Epoch[140/600] Iteration[007/008] Valid loss: 0.0711
2023-02-06 11:53:57 | Valid | Epoch[140/600] Iteration[008/008] Valid loss: 0.0698
2023-02-06 11:53:57 | Valid | Epoch[140/600] MIou: 0.8826115510739254
2023-02-06 11:53:57 | Valid | Epoch[140/600] Pixel Accuracy: 0.9801801045735677
2023-02-06 11:53:57 | Valid | Epoch[140/600] Mean Pixel Accuracy: 0.9030469203420782
2023-02-06 11:53:57 | Stage | Epoch[140/600] Train loss:0.0342
2023-02-06 11:53:57 | Stage | Epoch[140/600] Valid loss:0.0698
2023-02-06 11:53:57 | Stage | Epoch[140/600] LR:0.01

2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[001/030] Train loss: 0.0350
2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[002/030] Train loss: 0.0355
2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[003/030] Train loss: 0.0336
2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[004/030] Train loss: 0.0338
2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[005/030] Train loss: 0.0337
2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[006/030] Train loss: 0.0338
2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[007/030] Train loss: 0.0332
2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[008/030] Train loss: 0.0335
2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[009/030] Train loss: 0.0333
2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[010/030] Train loss: 0.0333
2023-02-06 11:53:58 | Train | Epoch[141/600] Iteration[011/030] Train loss: 0.0331
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[012/030] Train loss: 0.0330
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[013/030] Train loss: 0.0331
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[014/030] Train loss: 0.0331
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[015/030] Train loss: 0.0332
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[016/030] Train loss: 0.0332
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[017/030] Train loss: 0.0334
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[018/030] Train loss: 0.0334
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[019/030] Train loss: 0.0334
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[020/030] Train loss: 0.0334
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[021/030] Train loss: 0.0334
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[022/030] Train loss: 0.0333
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[023/030] Train loss: 0.0335
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[024/030] Train loss: 0.0336
2023-02-06 11:53:59 | Train | Epoch[141/600] Iteration[025/030] Train loss: 0.0336
2023-02-06 11:54:00 | Train | Epoch[141/600] Iteration[026/030] Train loss: 0.0336
2023-02-06 11:54:00 | Train | Epoch[141/600] Iteration[027/030] Train loss: 0.0337
2023-02-06 11:54:00 | Train | Epoch[141/600] Iteration[028/030] Train loss: 0.0337
2023-02-06 11:54:00 | Train | Epoch[141/600] Iteration[029/030] Train loss: 0.0336
2023-02-06 11:54:00 | Train | Epoch[141/600] Iteration[030/030] Train loss: 0.0336
2023-02-06 11:54:00 | Valid | Epoch[141/600] Iteration[001/008] Valid loss: 0.1855
2023-02-06 11:54:00 | Valid | Epoch[141/600] Iteration[002/008] Valid loss: 0.1970
2023-02-06 11:54:00 | Valid | Epoch[141/600] Iteration[003/008] Valid loss: 0.2145
2023-02-06 11:54:00 | Valid | Epoch[141/600] Iteration[004/008] Valid loss: 0.2119
2023-02-06 11:54:00 | Valid | Epoch[141/600] Iteration[005/008] Valid loss: 0.2204
2023-02-06 11:54:00 | Valid | Epoch[141/600] Iteration[006/008] Valid loss: 0.2170
2023-02-06 11:54:00 | Valid | Epoch[141/600] Iteration[007/008] Valid loss: 0.2151
2023-02-06 11:54:00 | Valid | Epoch[141/600] Iteration[008/008] Valid loss: 0.2263
2023-02-06 11:54:00 | Valid | Epoch[141/600] MIou: 0.46222325797257086
2023-02-06 11:54:00 | Valid | Epoch[141/600] Pixel Accuracy: 0.9109141031901041
2023-02-06 11:54:00 | Valid | Epoch[141/600] Mean Pixel Accuracy: 0.5068211575553647
2023-02-06 11:54:00 | Stage | Epoch[141/600] Train loss:0.0336
2023-02-06 11:54:00 | Stage | Epoch[141/600] Valid loss:0.2263
2023-02-06 11:54:00 | Stage | Epoch[141/600] LR:0.01

2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[001/030] Train loss: 0.0320
2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[002/030] Train loss: 0.0313
2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[003/030] Train loss: 0.0317
2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[004/030] Train loss: 0.0325
2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[005/030] Train loss: 0.0331
2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[006/030] Train loss: 0.0326
2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[007/030] Train loss: 0.0326
2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[008/030] Train loss: 0.0325
2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[009/030] Train loss: 0.0325
2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[010/030] Train loss: 0.0326
2023-02-06 11:54:01 | Train | Epoch[142/600] Iteration[011/030] Train loss: 0.0328
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[012/030] Train loss: 0.0326
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[013/030] Train loss: 0.0327
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[014/030] Train loss: 0.0327
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[015/030] Train loss: 0.0328
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[016/030] Train loss: 0.0330
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[017/030] Train loss: 0.0329
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[018/030] Train loss: 0.0330
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[019/030] Train loss: 0.0330
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[020/030] Train loss: 0.0330
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[021/030] Train loss: 0.0330
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[022/030] Train loss: 0.0329
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[023/030] Train loss: 0.0328
2023-02-06 11:54:02 | Train | Epoch[142/600] Iteration[024/030] Train loss: 0.0327
2023-02-06 11:54:03 | Train | Epoch[142/600] Iteration[025/030] Train loss: 0.0327
2023-02-06 11:54:03 | Train | Epoch[142/600] Iteration[026/030] Train loss: 0.0326
2023-02-06 11:54:03 | Train | Epoch[142/600] Iteration[027/030] Train loss: 0.0326
2023-02-06 11:54:03 | Train | Epoch[142/600] Iteration[028/030] Train loss: 0.0325
2023-02-06 11:54:03 | Train | Epoch[142/600] Iteration[029/030] Train loss: 0.0325
2023-02-06 11:54:03 | Train | Epoch[142/600] Iteration[030/030] Train loss: 0.0326
2023-02-06 11:54:03 | Valid | Epoch[142/600] Iteration[001/008] Valid loss: 0.0568
2023-02-06 11:54:03 | Valid | Epoch[142/600] Iteration[002/008] Valid loss: 0.0549
2023-02-06 11:54:03 | Valid | Epoch[142/600] Iteration[003/008] Valid loss: 0.0559
2023-02-06 11:54:03 | Valid | Epoch[142/600] Iteration[004/008] Valid loss: 0.0542
2023-02-06 11:54:03 | Valid | Epoch[142/600] Iteration[005/008] Valid loss: 0.0544
2023-02-06 11:54:03 | Valid | Epoch[142/600] Iteration[006/008] Valid loss: 0.0537
2023-02-06 11:54:03 | Valid | Epoch[142/600] Iteration[007/008] Valid loss: 0.0531
2023-02-06 11:54:03 | Valid | Epoch[142/600] Iteration[008/008] Valid loss: 0.0541
2023-02-06 11:54:03 | Valid | Epoch[142/600] MIou: 0.8410820199373539
2023-02-06 11:54:03 | Valid | Epoch[142/600] Pixel Accuracy: 0.9737561543782552
2023-02-06 11:54:03 | Valid | Epoch[142/600] Mean Pixel Accuracy: 0.8559316421658485
2023-02-06 11:54:03 | Stage | Epoch[142/600] Train loss:0.0326
2023-02-06 11:54:03 | Stage | Epoch[142/600] Valid loss:0.0541
2023-02-06 11:54:03 | Stage | Epoch[142/600] LR:0.01

2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[001/030] Train loss: 0.0295
2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[002/030] Train loss: 0.0303
2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[003/030] Train loss: 0.0305
2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[004/030] Train loss: 0.0306
2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[005/030] Train loss: 0.0314
2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[006/030] Train loss: 0.0313
2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[007/030] Train loss: 0.0313
2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[008/030] Train loss: 0.0312
2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[009/030] Train loss: 0.0314
2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[010/030] Train loss: 0.0314
2023-02-06 11:54:04 | Train | Epoch[143/600] Iteration[011/030] Train loss: 0.0315
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[012/030] Train loss: 0.0315
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[013/030] Train loss: 0.0317
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[014/030] Train loss: 0.0316
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[015/030] Train loss: 0.0316
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[016/030] Train loss: 0.0315
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[017/030] Train loss: 0.0316
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[018/030] Train loss: 0.0317
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[019/030] Train loss: 0.0318
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[020/030] Train loss: 0.0317
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[021/030] Train loss: 0.0318
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[022/030] Train loss: 0.0319
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[023/030] Train loss: 0.0319
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[024/030] Train loss: 0.0318
2023-02-06 11:54:05 | Train | Epoch[143/600] Iteration[025/030] Train loss: 0.0319
2023-02-06 11:54:06 | Train | Epoch[143/600] Iteration[026/030] Train loss: 0.0319
2023-02-06 11:54:06 | Train | Epoch[143/600] Iteration[027/030] Train loss: 0.0320
2023-02-06 11:54:06 | Train | Epoch[143/600] Iteration[028/030] Train loss: 0.0319
2023-02-06 11:54:06 | Train | Epoch[143/600] Iteration[029/030] Train loss: 0.0320
2023-02-06 11:54:06 | Train | Epoch[143/600] Iteration[030/030] Train loss: 0.0322
2023-02-06 11:54:06 | Valid | Epoch[143/600] Iteration[001/008] Valid loss: 0.0978
2023-02-06 11:54:06 | Valid | Epoch[143/600] Iteration[002/008] Valid loss: 0.0963
2023-02-06 11:54:06 | Valid | Epoch[143/600] Iteration[003/008] Valid loss: 0.1020
2023-02-06 11:54:06 | Valid | Epoch[143/600] Iteration[004/008] Valid loss: 0.1005
2023-02-06 11:54:06 | Valid | Epoch[143/600] Iteration[005/008] Valid loss: 0.1030
2023-02-06 11:54:06 | Valid | Epoch[143/600] Iteration[006/008] Valid loss: 0.1011
2023-02-06 11:54:06 | Valid | Epoch[143/600] Iteration[007/008] Valid loss: 0.0993
2023-02-06 11:54:06 | Valid | Epoch[143/600] Iteration[008/008] Valid loss: 0.1029
2023-02-06 11:54:06 | Valid | Epoch[143/600] MIou: 0.6958375667923724
2023-02-06 11:54:06 | Valid | Epoch[143/600] Pixel Accuracy: 0.9497591654459635
2023-02-06 11:54:06 | Valid | Epoch[143/600] Mean Pixel Accuracy: 0.7220953816699818
2023-02-06 11:54:06 | Stage | Epoch[143/600] Train loss:0.0322
2023-02-06 11:54:06 | Stage | Epoch[143/600] Valid loss:0.1029
2023-02-06 11:54:06 | Stage | Epoch[143/600] LR:0.01

2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[001/030] Train loss: 0.0299
2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[002/030] Train loss: 0.0303
2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[003/030] Train loss: 0.0309
2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[004/030] Train loss: 0.0321
2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[005/030] Train loss: 0.0319
2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[006/030] Train loss: 0.0324
2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[007/030] Train loss: 0.0323
2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[008/030] Train loss: 0.0322
2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[009/030] Train loss: 0.0322
2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[010/030] Train loss: 0.0321
2023-02-06 11:54:07 | Train | Epoch[144/600] Iteration[011/030] Train loss: 0.0320
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[012/030] Train loss: 0.0320
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[013/030] Train loss: 0.0321
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[014/030] Train loss: 0.0323
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[015/030] Train loss: 0.0324
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[016/030] Train loss: 0.0323
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[017/030] Train loss: 0.0324
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[018/030] Train loss: 0.0323
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[019/030] Train loss: 0.0325
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[020/030] Train loss: 0.0325
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[021/030] Train loss: 0.0324
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[022/030] Train loss: 0.0323
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[023/030] Train loss: 0.0323
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[024/030] Train loss: 0.0322
2023-02-06 11:54:08 | Train | Epoch[144/600] Iteration[025/030] Train loss: 0.0322
2023-02-06 11:54:09 | Train | Epoch[144/600] Iteration[026/030] Train loss: 0.0322
2023-02-06 11:54:09 | Train | Epoch[144/600] Iteration[027/030] Train loss: 0.0322
2023-02-06 11:54:09 | Train | Epoch[144/600] Iteration[028/030] Train loss: 0.0321
2023-02-06 11:54:09 | Train | Epoch[144/600] Iteration[029/030] Train loss: 0.0322
2023-02-06 11:54:09 | Train | Epoch[144/600] Iteration[030/030] Train loss: 0.0322
2023-02-06 11:54:09 | Valid | Epoch[144/600] Iteration[001/008] Valid loss: 0.3465
2023-02-06 11:54:09 | Valid | Epoch[144/600] Iteration[002/008] Valid loss: 0.3007
2023-02-06 11:54:09 | Valid | Epoch[144/600] Iteration[003/008] Valid loss: 0.2768
2023-02-06 11:54:09 | Valid | Epoch[144/600] Iteration[004/008] Valid loss: 0.2719
2023-02-06 11:54:09 | Valid | Epoch[144/600] Iteration[005/008] Valid loss: 0.2766
2023-02-06 11:54:09 | Valid | Epoch[144/600] Iteration[006/008] Valid loss: 0.2651
2023-02-06 11:54:09 | Valid | Epoch[144/600] Iteration[007/008] Valid loss: 0.2808
2023-02-06 11:54:09 | Valid | Epoch[144/600] Iteration[008/008] Valid loss: 0.2771
2023-02-06 11:54:09 | Valid | Epoch[144/600] MIou: 0.914735337868039
2023-02-06 11:54:09 | Valid | Epoch[144/600] Pixel Accuracy: 0.9840062459309896
2023-02-06 11:54:09 | Valid | Epoch[144/600] Mean Pixel Accuracy: 0.9824085761877919
2023-02-06 11:54:09 | Stage | Epoch[144/600] Train loss:0.0322
2023-02-06 11:54:09 | Stage | Epoch[144/600] Valid loss:0.2771
2023-02-06 11:54:09 | Stage | Epoch[144/600] LR:0.01

2023-02-06 11:54:10 | Train | Epoch[145/600] Iteration[001/030] Train loss: 0.0320
2023-02-06 11:54:10 | Train | Epoch[145/600] Iteration[002/030] Train loss: 0.0335
2023-02-06 11:54:10 | Train | Epoch[145/600] Iteration[003/030] Train loss: 0.0342
2023-02-06 11:54:10 | Train | Epoch[145/600] Iteration[004/030] Train loss: 0.0341
2023-02-06 11:54:10 | Train | Epoch[145/600] Iteration[005/030] Train loss: 0.0335
2023-02-06 11:54:10 | Train | Epoch[145/600] Iteration[006/030] Train loss: 0.0336
2023-02-06 11:54:10 | Train | Epoch[145/600] Iteration[007/030] Train loss: 0.0336
2023-02-06 11:54:10 | Train | Epoch[145/600] Iteration[008/030] Train loss: 0.0334
2023-02-06 11:54:10 | Train | Epoch[145/600] Iteration[009/030] Train loss: 0.0329
2023-02-06 11:54:10 | Train | Epoch[145/600] Iteration[010/030] Train loss: 0.0327
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[011/030] Train loss: 0.0325
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[012/030] Train loss: 0.0324
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[013/030] Train loss: 0.0323
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[014/030] Train loss: 0.0325
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[015/030] Train loss: 0.0325
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[016/030] Train loss: 0.0326
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[017/030] Train loss: 0.0327
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[018/030] Train loss: 0.0326
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[019/030] Train loss: 0.0326
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[020/030] Train loss: 0.0325
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[021/030] Train loss: 0.0323
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[022/030] Train loss: 0.0324
2023-02-06 11:54:11 | Train | Epoch[145/600] Iteration[023/030] Train loss: 0.0323
2023-02-06 11:54:12 | Train | Epoch[145/600] Iteration[024/030] Train loss: 0.0323
2023-02-06 11:54:12 | Train | Epoch[145/600] Iteration[025/030] Train loss: 0.0322
2023-02-06 11:54:12 | Train | Epoch[145/600] Iteration[026/030] Train loss: 0.0323
2023-02-06 11:54:12 | Train | Epoch[145/600] Iteration[027/030] Train loss: 0.0324
2023-02-06 11:54:12 | Train | Epoch[145/600] Iteration[028/030] Train loss: 0.0324
2023-02-06 11:54:12 | Train | Epoch[145/600] Iteration[029/030] Train loss: 0.0323
2023-02-06 11:54:12 | Train | Epoch[145/600] Iteration[030/030] Train loss: 0.0322
2023-02-06 11:54:12 | Valid | Epoch[145/600] Iteration[001/008] Valid loss: 0.2179
2023-02-06 11:54:12 | Valid | Epoch[145/600] Iteration[002/008] Valid loss: 0.1687
2023-02-06 11:54:12 | Valid | Epoch[145/600] Iteration[003/008] Valid loss: 0.1586
2023-02-06 11:54:12 | Valid | Epoch[145/600] Iteration[004/008] Valid loss: 0.1501
2023-02-06 11:54:12 | Valid | Epoch[145/600] Iteration[005/008] Valid loss: 0.1510
2023-02-06 11:54:12 | Valid | Epoch[145/600] Iteration[006/008] Valid loss: 0.1404
2023-02-06 11:54:12 | Valid | Epoch[145/600] Iteration[007/008] Valid loss: 0.1423
2023-02-06 11:54:12 | Valid | Epoch[145/600] Iteration[008/008] Valid loss: 0.1364
2023-02-06 11:54:13 | Valid | Epoch[145/600] MIou: 0.9348070078453228
2023-02-06 11:54:13 | Valid | Epoch[145/600] Pixel Accuracy: 0.988739013671875
2023-02-06 11:54:13 | Valid | Epoch[145/600] Mean Pixel Accuracy: 0.9627928950075171
2023-02-06 11:54:13 | Stage | Epoch[145/600] Train loss:0.0322
2023-02-06 11:54:13 | Stage | Epoch[145/600] Valid loss:0.1364
2023-02-06 11:54:13 | Stage | Epoch[145/600] LR:0.01

2023-02-06 11:54:13 | Train | Epoch[146/600] Iteration[001/030] Train loss: 0.0318
2023-02-06 11:54:13 | Train | Epoch[146/600] Iteration[002/030] Train loss: 0.0304
2023-02-06 11:54:13 | Train | Epoch[146/600] Iteration[003/030] Train loss: 0.0300
2023-02-06 11:54:13 | Train | Epoch[146/600] Iteration[004/030] Train loss: 0.0310
2023-02-06 11:54:13 | Train | Epoch[146/600] Iteration[005/030] Train loss: 0.0315
2023-02-06 11:54:13 | Train | Epoch[146/600] Iteration[006/030] Train loss: 0.0313
2023-02-06 11:54:13 | Train | Epoch[146/600] Iteration[007/030] Train loss: 0.0318
2023-02-06 11:54:13 | Train | Epoch[146/600] Iteration[008/030] Train loss: 0.0317
2023-02-06 11:54:13 | Train | Epoch[146/600] Iteration[009/030] Train loss: 0.0314
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[010/030] Train loss: 0.0316
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[011/030] Train loss: 0.0317
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[012/030] Train loss: 0.0316
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[013/030] Train loss: 0.0319
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[014/030] Train loss: 0.0319
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[015/030] Train loss: 0.0318
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[016/030] Train loss: 0.0317
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[017/030] Train loss: 0.0317
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[018/030] Train loss: 0.0319
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[019/030] Train loss: 0.0319
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[020/030] Train loss: 0.0320
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[021/030] Train loss: 0.0320
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[022/030] Train loss: 0.0319
2023-02-06 11:54:14 | Train | Epoch[146/600] Iteration[023/030] Train loss: 0.0319
2023-02-06 11:54:15 | Train | Epoch[146/600] Iteration[024/030] Train loss: 0.0320
2023-02-06 11:54:15 | Train | Epoch[146/600] Iteration[025/030] Train loss: 0.0321
2023-02-06 11:54:15 | Train | Epoch[146/600] Iteration[026/030] Train loss: 0.0320
2023-02-06 11:54:15 | Train | Epoch[146/600] Iteration[027/030] Train loss: 0.0320
2023-02-06 11:54:15 | Train | Epoch[146/600] Iteration[028/030] Train loss: 0.0320
2023-02-06 11:54:15 | Train | Epoch[146/600] Iteration[029/030] Train loss: 0.0320
2023-02-06 11:54:15 | Train | Epoch[146/600] Iteration[030/030] Train loss: 0.0320
2023-02-06 11:54:15 | Valid | Epoch[146/600] Iteration[001/008] Valid loss: 0.0585
2023-02-06 11:54:15 | Valid | Epoch[146/600] Iteration[002/008] Valid loss: 0.0506
2023-02-06 11:54:15 | Valid | Epoch[146/600] Iteration[003/008] Valid loss: 0.0500
2023-02-06 11:54:15 | Valid | Epoch[146/600] Iteration[004/008] Valid loss: 0.0479
2023-02-06 11:54:15 | Valid | Epoch[146/600] Iteration[005/008] Valid loss: 0.0480
2023-02-06 11:54:15 | Valid | Epoch[146/600] Iteration[006/008] Valid loss: 0.0472
2023-02-06 11:54:15 | Valid | Epoch[146/600] Iteration[007/008] Valid loss: 0.0475
2023-02-06 11:54:15 | Valid | Epoch[146/600] Iteration[008/008] Valid loss: 0.0471
2023-02-06 11:54:16 | Valid | Epoch[146/600] MIou: 0.9039800764260955
2023-02-06 11:54:16 | Valid | Epoch[146/600] Pixel Accuracy: 0.9840418497721354
2023-02-06 11:54:16 | Valid | Epoch[146/600] Mean Pixel Accuracy: 0.9165696679813797
2023-02-06 11:54:16 | Stage | Epoch[146/600] Train loss:0.0320
2023-02-06 11:54:16 | Stage | Epoch[146/600] Valid loss:0.0471
2023-02-06 11:54:16 | Stage | Epoch[146/600] LR:0.01

2023-02-06 11:54:16 | Train | Epoch[147/600] Iteration[001/030] Train loss: 0.0332
2023-02-06 11:54:16 | Train | Epoch[147/600] Iteration[002/030] Train loss: 0.0320
2023-02-06 11:54:16 | Train | Epoch[147/600] Iteration[003/030] Train loss: 0.0318
2023-02-06 11:54:16 | Train | Epoch[147/600] Iteration[004/030] Train loss: 0.0316
2023-02-06 11:54:16 | Train | Epoch[147/600] Iteration[005/030] Train loss: 0.0324
2023-02-06 11:54:16 | Train | Epoch[147/600] Iteration[006/030] Train loss: 0.0322
2023-02-06 11:54:16 | Train | Epoch[147/600] Iteration[007/030] Train loss: 0.0322
2023-02-06 11:54:16 | Train | Epoch[147/600] Iteration[008/030] Train loss: 0.0324
2023-02-06 11:54:16 | Train | Epoch[147/600] Iteration[009/030] Train loss: 0.0322
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[010/030] Train loss: 0.0319
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[011/030] Train loss: 0.0317
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[012/030] Train loss: 0.0316
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[013/030] Train loss: 0.0315
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[014/030] Train loss: 0.0314
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[015/030] Train loss: 0.0314
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[016/030] Train loss: 0.0313
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[017/030] Train loss: 0.0312
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[018/030] Train loss: 0.0311
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[019/030] Train loss: 0.0313
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[020/030] Train loss: 0.0314
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[021/030] Train loss: 0.0313
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[022/030] Train loss: 0.0312
2023-02-06 11:54:17 | Train | Epoch[147/600] Iteration[023/030] Train loss: 0.0312
2023-02-06 11:54:18 | Train | Epoch[147/600] Iteration[024/030] Train loss: 0.0312
2023-02-06 11:54:18 | Train | Epoch[147/600] Iteration[025/030] Train loss: 0.0313
2023-02-06 11:54:18 | Train | Epoch[147/600] Iteration[026/030] Train loss: 0.0313
2023-02-06 11:54:18 | Train | Epoch[147/600] Iteration[027/030] Train loss: 0.0314
2023-02-06 11:54:18 | Train | Epoch[147/600] Iteration[028/030] Train loss: 0.0316
2023-02-06 11:54:18 | Train | Epoch[147/600] Iteration[029/030] Train loss: 0.0316
2023-02-06 11:54:18 | Train | Epoch[147/600] Iteration[030/030] Train loss: 0.0316
2023-02-06 11:54:18 | Valid | Epoch[147/600] Iteration[001/008] Valid loss: 0.2164
2023-02-06 11:54:18 | Valid | Epoch[147/600] Iteration[002/008] Valid loss: 0.2183
2023-02-06 11:54:18 | Valid | Epoch[147/600] Iteration[003/008] Valid loss: 0.2292
2023-02-06 11:54:18 | Valid | Epoch[147/600] Iteration[004/008] Valid loss: 0.2292
2023-02-06 11:54:18 | Valid | Epoch[147/600] Iteration[005/008] Valid loss: 0.2323
2023-02-06 11:54:18 | Valid | Epoch[147/600] Iteration[006/008] Valid loss: 0.2307
2023-02-06 11:54:18 | Valid | Epoch[147/600] Iteration[007/008] Valid loss: 0.2287
2023-02-06 11:54:18 | Valid | Epoch[147/600] Iteration[008/008] Valid loss: 0.2352
2023-02-06 11:54:19 | Valid | Epoch[147/600] MIou: 0.45873383451623573
2023-02-06 11:54:19 | Valid | Epoch[147/600] Pixel Accuracy: 0.9103317260742188
2023-02-06 11:54:19 | Valid | Epoch[147/600] Mean Pixel Accuracy: 0.5035971223021583
2023-02-06 11:54:19 | Stage | Epoch[147/600] Train loss:0.0316
2023-02-06 11:54:19 | Stage | Epoch[147/600] Valid loss:0.2352
2023-02-06 11:54:19 | Stage | Epoch[147/600] LR:0.01

2023-02-06 11:54:19 | Train | Epoch[148/600] Iteration[001/030] Train loss: 0.0312
2023-02-06 11:54:19 | Train | Epoch[148/600] Iteration[002/030] Train loss: 0.0316
2023-02-06 11:54:19 | Train | Epoch[148/600] Iteration[003/030] Train loss: 0.0322
2023-02-06 11:54:19 | Train | Epoch[148/600] Iteration[004/030] Train loss: 0.0323
2023-02-06 11:54:19 | Train | Epoch[148/600] Iteration[005/030] Train loss: 0.0321
2023-02-06 11:54:19 | Train | Epoch[148/600] Iteration[006/030] Train loss: 0.0315
2023-02-06 11:54:19 | Train | Epoch[148/600] Iteration[007/030] Train loss: 0.0313
2023-02-06 11:54:19 | Train | Epoch[148/600] Iteration[008/030] Train loss: 0.0313
2023-02-06 11:54:19 | Train | Epoch[148/600] Iteration[009/030] Train loss: 0.0312
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[010/030] Train loss: 0.0312
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[011/030] Train loss: 0.0310
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[012/030] Train loss: 0.0309
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[013/030] Train loss: 0.0310
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[014/030] Train loss: 0.0309
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[015/030] Train loss: 0.0310
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[016/030] Train loss: 0.0311
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[017/030] Train loss: 0.0311
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[018/030] Train loss: 0.0310
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[019/030] Train loss: 0.0309
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[020/030] Train loss: 0.0310
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[021/030] Train loss: 0.0311
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[022/030] Train loss: 0.0311
2023-02-06 11:54:20 | Train | Epoch[148/600] Iteration[023/030] Train loss: 0.0312
2023-02-06 11:54:21 | Train | Epoch[148/600] Iteration[024/030] Train loss: 0.0311
2023-02-06 11:54:21 | Train | Epoch[148/600] Iteration[025/030] Train loss: 0.0310
2023-02-06 11:54:21 | Train | Epoch[148/600] Iteration[026/030] Train loss: 0.0310
2023-02-06 11:54:21 | Train | Epoch[148/600] Iteration[027/030] Train loss: 0.0311
2023-02-06 11:54:21 | Train | Epoch[148/600] Iteration[028/030] Train loss: 0.0312
2023-02-06 11:54:21 | Train | Epoch[148/600] Iteration[029/030] Train loss: 0.0312
2023-02-06 11:54:21 | Train | Epoch[148/600] Iteration[030/030] Train loss: 0.0314
2023-02-06 11:54:21 | Valid | Epoch[148/600] Iteration[001/008] Valid loss: 0.0637
2023-02-06 11:54:21 | Valid | Epoch[148/600] Iteration[002/008] Valid loss: 0.0627
2023-02-06 11:54:21 | Valid | Epoch[148/600] Iteration[003/008] Valid loss: 0.0652
2023-02-06 11:54:21 | Valid | Epoch[148/600] Iteration[004/008] Valid loss: 0.0639
2023-02-06 11:54:21 | Valid | Epoch[148/600] Iteration[005/008] Valid loss: 0.0647
2023-02-06 11:54:21 | Valid | Epoch[148/600] Iteration[006/008] Valid loss: 0.0638
2023-02-06 11:54:21 | Valid | Epoch[148/600] Iteration[007/008] Valid loss: 0.0627
2023-02-06 11:54:21 | Valid | Epoch[148/600] Iteration[008/008] Valid loss: 0.0640
2023-02-06 11:54:22 | Valid | Epoch[148/600] MIou: 0.8101393749960204
2023-02-06 11:54:22 | Valid | Epoch[148/600] Pixel Accuracy: 0.9686978658040365
2023-02-06 11:54:22 | Valid | Epoch[148/600] Mean Pixel Accuracy: 0.826870136617097
2023-02-06 11:54:22 | Stage | Epoch[148/600] Train loss:0.0314
2023-02-06 11:54:22 | Stage | Epoch[148/600] Valid loss:0.0640
2023-02-06 11:54:22 | Stage | Epoch[148/600] LR:0.01

2023-02-06 11:54:22 | Train | Epoch[149/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 11:54:22 | Train | Epoch[149/600] Iteration[002/030] Train loss: 0.0310
2023-02-06 11:54:22 | Train | Epoch[149/600] Iteration[003/030] Train loss: 0.0320
2023-02-06 11:54:22 | Train | Epoch[149/600] Iteration[004/030] Train loss: 0.0323
2023-02-06 11:54:22 | Train | Epoch[149/600] Iteration[005/030] Train loss: 0.0323
2023-02-06 11:54:22 | Train | Epoch[149/600] Iteration[006/030] Train loss: 0.0318
2023-02-06 11:54:22 | Train | Epoch[149/600] Iteration[007/030] Train loss: 0.0318
2023-02-06 11:54:22 | Train | Epoch[149/600] Iteration[008/030] Train loss: 0.0315
2023-02-06 11:54:22 | Train | Epoch[149/600] Iteration[009/030] Train loss: 0.0314
2023-02-06 11:54:22 | Train | Epoch[149/600] Iteration[010/030] Train loss: 0.0313
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[011/030] Train loss: 0.0312
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[012/030] Train loss: 0.0311
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[013/030] Train loss: 0.0310
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[014/030] Train loss: 0.0311
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[015/030] Train loss: 0.0311
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[016/030] Train loss: 0.0312
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[017/030] Train loss: 0.0311
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[018/030] Train loss: 0.0312
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[019/030] Train loss: 0.0312
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[020/030] Train loss: 0.0313
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[021/030] Train loss: 0.0314
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[022/030] Train loss: 0.0313
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[023/030] Train loss: 0.0313
2023-02-06 11:54:23 | Train | Epoch[149/600] Iteration[024/030] Train loss: 0.0312
2023-02-06 11:54:24 | Train | Epoch[149/600] Iteration[025/030] Train loss: 0.0314
2023-02-06 11:54:24 | Train | Epoch[149/600] Iteration[026/030] Train loss: 0.0313
2023-02-06 11:54:24 | Train | Epoch[149/600] Iteration[027/030] Train loss: 0.0312
2023-02-06 11:54:24 | Train | Epoch[149/600] Iteration[028/030] Train loss: 0.0312
2023-02-06 11:54:24 | Train | Epoch[149/600] Iteration[029/030] Train loss: 0.0311
2023-02-06 11:54:24 | Train | Epoch[149/600] Iteration[030/030] Train loss: 0.0312
2023-02-06 11:54:24 | Valid | Epoch[149/600] Iteration[001/008] Valid loss: 0.0525
2023-02-06 11:54:24 | Valid | Epoch[149/600] Iteration[002/008] Valid loss: 0.0481
2023-02-06 11:54:24 | Valid | Epoch[149/600] Iteration[003/008] Valid loss: 0.0489
2023-02-06 11:54:24 | Valid | Epoch[149/600] Iteration[004/008] Valid loss: 0.0472
2023-02-06 11:54:24 | Valid | Epoch[149/600] Iteration[005/008] Valid loss: 0.0474
2023-02-06 11:54:24 | Valid | Epoch[149/600] Iteration[006/008] Valid loss: 0.0465
2023-02-06 11:54:24 | Valid | Epoch[149/600] Iteration[007/008] Valid loss: 0.0462
2023-02-06 11:54:24 | Valid | Epoch[149/600] Iteration[008/008] Valid loss: 0.0464
2023-02-06 11:54:24 | Valid | Epoch[149/600] MIou: 0.8817679346558494
2023-02-06 11:54:24 | Valid | Epoch[149/600] Pixel Accuracy: 0.9804204305013021
2023-02-06 11:54:24 | Valid | Epoch[149/600] Mean Pixel Accuracy: 0.8945432915221613
2023-02-06 11:54:24 | Stage | Epoch[149/600] Train loss:0.0312
2023-02-06 11:54:24 | Stage | Epoch[149/600] Valid loss:0.0464
2023-02-06 11:54:24 | Stage | Epoch[149/600] LR:0.01

2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[001/030] Train loss: 0.0314
2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[002/030] Train loss: 0.0310
2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[003/030] Train loss: 0.0307
2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[004/030] Train loss: 0.0306
2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[005/030] Train loss: 0.0304
2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[006/030] Train loss: 0.0299
2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[007/030] Train loss: 0.0305
2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[008/030] Train loss: 0.0305
2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[009/030] Train loss: 0.0304
2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[010/030] Train loss: 0.0303
2023-02-06 11:54:25 | Train | Epoch[150/600] Iteration[011/030] Train loss: 0.0302
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[012/030] Train loss: 0.0302
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[013/030] Train loss: 0.0301
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[014/030] Train loss: 0.0302
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[015/030] Train loss: 0.0301
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[016/030] Train loss: 0.0303
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[017/030] Train loss: 0.0303
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[018/030] Train loss: 0.0302
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[019/030] Train loss: 0.0302
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[020/030] Train loss: 0.0302
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[021/030] Train loss: 0.0301
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[022/030] Train loss: 0.0302
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[023/030] Train loss: 0.0303
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[024/030] Train loss: 0.0303
2023-02-06 11:54:26 | Train | Epoch[150/600] Iteration[025/030] Train loss: 0.0303
2023-02-06 11:54:27 | Train | Epoch[150/600] Iteration[026/030] Train loss: 0.0304
2023-02-06 11:54:27 | Train | Epoch[150/600] Iteration[027/030] Train loss: 0.0306
2023-02-06 11:54:27 | Train | Epoch[150/600] Iteration[028/030] Train loss: 0.0306
2023-02-06 11:54:27 | Train | Epoch[150/600] Iteration[029/030] Train loss: 0.0306
2023-02-06 11:54:27 | Train | Epoch[150/600] Iteration[030/030] Train loss: 0.0305
2023-02-06 11:54:27 | Valid | Epoch[150/600] Iteration[001/008] Valid loss: 0.6757
2023-02-06 11:54:27 | Valid | Epoch[150/600] Iteration[002/008] Valid loss: 0.5744
2023-02-06 11:54:27 | Valid | Epoch[150/600] Iteration[003/008] Valid loss: 0.5704
2023-02-06 11:54:27 | Valid | Epoch[150/600] Iteration[004/008] Valid loss: 0.5741
2023-02-06 11:54:27 | Valid | Epoch[150/600] Iteration[005/008] Valid loss: 0.5977
2023-02-06 11:54:27 | Valid | Epoch[150/600] Iteration[006/008] Valid loss: 0.5895
2023-02-06 11:54:27 | Valid | Epoch[150/600] Iteration[007/008] Valid loss: 0.6162
2023-02-06 11:54:27 | Valid | Epoch[150/600] Iteration[008/008] Valid loss: 0.6008
2023-02-06 11:54:27 | Valid | Epoch[150/600] MIou: 0.8829992080619842
2023-02-06 11:54:27 | Valid | Epoch[150/600] Pixel Accuracy: 0.976434071858724
2023-02-06 11:54:27 | Valid | Epoch[150/600] Mean Pixel Accuracy: 0.9838135203598675
2023-02-06 11:54:27 | Stage | Epoch[150/600] Train loss:0.0305
2023-02-06 11:54:27 | Stage | Epoch[150/600] Valid loss:0.6008
2023-02-06 11:54:27 | Stage | Epoch[150/600] LR:0.01

2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[001/030] Train loss: 0.0284
2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[002/030] Train loss: 0.0303
2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[003/030] Train loss: 0.0301
2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[004/030] Train loss: 0.0309
2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[005/030] Train loss: 0.0306
2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[006/030] Train loss: 0.0302
2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[007/030] Train loss: 0.0304
2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[008/030] Train loss: 0.0301
2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[009/030] Train loss: 0.0305
2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[010/030] Train loss: 0.0304
2023-02-06 11:54:28 | Train | Epoch[151/600] Iteration[011/030] Train loss: 0.0307
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[012/030] Train loss: 0.0307
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[013/030] Train loss: 0.0307
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[014/030] Train loss: 0.0306
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[015/030] Train loss: 0.0306
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[016/030] Train loss: 0.0306
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[017/030] Train loss: 0.0306
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[018/030] Train loss: 0.0305
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[019/030] Train loss: 0.0304
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[020/030] Train loss: 0.0303
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[021/030] Train loss: 0.0301
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[022/030] Train loss: 0.0302
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[023/030] Train loss: 0.0303
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[024/030] Train loss: 0.0303
2023-02-06 11:54:29 | Train | Epoch[151/600] Iteration[025/030] Train loss: 0.0303
2023-02-06 11:54:30 | Train | Epoch[151/600] Iteration[026/030] Train loss: 0.0304
2023-02-06 11:54:30 | Train | Epoch[151/600] Iteration[027/030] Train loss: 0.0304
2023-02-06 11:54:30 | Train | Epoch[151/600] Iteration[028/030] Train loss: 0.0305
2023-02-06 11:54:30 | Train | Epoch[151/600] Iteration[029/030] Train loss: 0.0306
2023-02-06 11:54:30 | Train | Epoch[151/600] Iteration[030/030] Train loss: 0.0306
2023-02-06 11:54:30 | Valid | Epoch[151/600] Iteration[001/008] Valid loss: 0.6277
2023-02-06 11:54:30 | Valid | Epoch[151/600] Iteration[002/008] Valid loss: 0.6024
2023-02-06 11:54:30 | Valid | Epoch[151/600] Iteration[003/008] Valid loss: 0.6087
2023-02-06 11:54:30 | Valid | Epoch[151/600] Iteration[004/008] Valid loss: 0.6183
2023-02-06 11:54:30 | Valid | Epoch[151/600] Iteration[005/008] Valid loss: 0.6355
2023-02-06 11:54:30 | Valid | Epoch[151/600] Iteration[006/008] Valid loss: 0.6104
2023-02-06 11:54:30 | Valid | Epoch[151/600] Iteration[007/008] Valid loss: 0.6420
2023-02-06 11:54:30 | Valid | Epoch[151/600] Iteration[008/008] Valid loss: 0.6726
2023-02-06 11:54:30 | Valid | Epoch[151/600] MIou: 0.8703745548153305
2023-02-06 11:54:30 | Valid | Epoch[151/600] Pixel Accuracy: 0.9734064737955729
2023-02-06 11:54:30 | Valid | Epoch[151/600] Mean Pixel Accuracy: 0.9788143353250712
2023-02-06 11:54:30 | Stage | Epoch[151/600] Train loss:0.0306
2023-02-06 11:54:30 | Stage | Epoch[151/600] Valid loss:0.6726
2023-02-06 11:54:30 | Stage | Epoch[151/600] LR:0.01

2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[001/030] Train loss: 0.0293
2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[002/030] Train loss: 0.0311
2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[003/030] Train loss: 0.0323
2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[004/030] Train loss: 0.0323
2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[005/030] Train loss: 0.0321
2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[006/030] Train loss: 0.0317
2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[007/030] Train loss: 0.0318
2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[008/030] Train loss: 0.0314
2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[009/030] Train loss: 0.0312
2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[010/030] Train loss: 0.0311
2023-02-06 11:54:31 | Train | Epoch[152/600] Iteration[011/030] Train loss: 0.0309
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[012/030] Train loss: 0.0308
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[013/030] Train loss: 0.0308
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[014/030] Train loss: 0.0306
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[015/030] Train loss: 0.0305
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[016/030] Train loss: 0.0304
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[017/030] Train loss: 0.0304
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[018/030] Train loss: 0.0304
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[019/030] Train loss: 0.0304
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[020/030] Train loss: 0.0307
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[021/030] Train loss: 0.0307
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[022/030] Train loss: 0.0307
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[023/030] Train loss: 0.0307
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[024/030] Train loss: 0.0307
2023-02-06 11:54:32 | Train | Epoch[152/600] Iteration[025/030] Train loss: 0.0306
2023-02-06 11:54:33 | Train | Epoch[152/600] Iteration[026/030] Train loss: 0.0307
2023-02-06 11:54:33 | Train | Epoch[152/600] Iteration[027/030] Train loss: 0.0305
2023-02-06 11:54:33 | Train | Epoch[152/600] Iteration[028/030] Train loss: 0.0305
2023-02-06 11:54:33 | Train | Epoch[152/600] Iteration[029/030] Train loss: 0.0304
2023-02-06 11:54:33 | Train | Epoch[152/600] Iteration[030/030] Train loss: 0.0303
2023-02-06 11:54:33 | Valid | Epoch[152/600] Iteration[001/008] Valid loss: 0.0610
2023-02-06 11:54:33 | Valid | Epoch[152/600] Iteration[002/008] Valid loss: 0.0600
2023-02-06 11:54:33 | Valid | Epoch[152/600] Iteration[003/008] Valid loss: 0.0628
2023-02-06 11:54:33 | Valid | Epoch[152/600] Iteration[004/008] Valid loss: 0.0613
2023-02-06 11:54:33 | Valid | Epoch[152/600] Iteration[005/008] Valid loss: 0.0619
2023-02-06 11:54:33 | Valid | Epoch[152/600] Iteration[006/008] Valid loss: 0.0609
2023-02-06 11:54:33 | Valid | Epoch[152/600] Iteration[007/008] Valid loss: 0.0600
2023-02-06 11:54:33 | Valid | Epoch[152/600] Iteration[008/008] Valid loss: 0.0617
2023-02-06 11:54:33 | Valid | Epoch[152/600] MIou: 0.808012330408268
2023-02-06 11:54:33 | Valid | Epoch[152/600] Pixel Accuracy: 0.9683049519856771
2023-02-06 11:54:33 | Valid | Epoch[152/600] Mean Pixel Accuracy: 0.8253416968221572
2023-02-06 11:54:33 | Stage | Epoch[152/600] Train loss:0.0303
2023-02-06 11:54:33 | Stage | Epoch[152/600] Valid loss:0.0617
2023-02-06 11:54:33 | Stage | Epoch[152/600] LR:0.01

2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[001/030] Train loss: 0.0297
2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[002/030] Train loss: 0.0301
2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[003/030] Train loss: 0.0300
2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[004/030] Train loss: 0.0298
2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[005/030] Train loss: 0.0300
2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[006/030] Train loss: 0.0301
2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[007/030] Train loss: 0.0300
2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[008/030] Train loss: 0.0298
2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[009/030] Train loss: 0.0298
2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[010/030] Train loss: 0.0297
2023-02-06 11:54:34 | Train | Epoch[153/600] Iteration[011/030] Train loss: 0.0302
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[012/030] Train loss: 0.0302
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[013/030] Train loss: 0.0303
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[014/030] Train loss: 0.0302
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[015/030] Train loss: 0.0303
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[016/030] Train loss: 0.0302
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[017/030] Train loss: 0.0302
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[018/030] Train loss: 0.0303
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[019/030] Train loss: 0.0303
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[020/030] Train loss: 0.0302
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[021/030] Train loss: 0.0303
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[022/030] Train loss: 0.0302
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[023/030] Train loss: 0.0302
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[024/030] Train loss: 0.0302
2023-02-06 11:54:35 | Train | Epoch[153/600] Iteration[025/030] Train loss: 0.0302
2023-02-06 11:54:36 | Train | Epoch[153/600] Iteration[026/030] Train loss: 0.0303
2023-02-06 11:54:36 | Train | Epoch[153/600] Iteration[027/030] Train loss: 0.0304
2023-02-06 11:54:36 | Train | Epoch[153/600] Iteration[028/030] Train loss: 0.0303
2023-02-06 11:54:36 | Train | Epoch[153/600] Iteration[029/030] Train loss: 0.0303
2023-02-06 11:54:36 | Train | Epoch[153/600] Iteration[030/030] Train loss: 0.0303
2023-02-06 11:54:36 | Valid | Epoch[153/600] Iteration[001/008] Valid loss: 1.5231
2023-02-06 11:54:36 | Valid | Epoch[153/600] Iteration[002/008] Valid loss: 1.4936
2023-02-06 11:54:36 | Valid | Epoch[153/600] Iteration[003/008] Valid loss: 1.5351
2023-02-06 11:54:36 | Valid | Epoch[153/600] Iteration[004/008] Valid loss: 1.5778
2023-02-06 11:54:36 | Valid | Epoch[153/600] Iteration[005/008] Valid loss: 1.6120
2023-02-06 11:54:36 | Valid | Epoch[153/600] Iteration[006/008] Valid loss: 1.5822
2023-02-06 11:54:36 | Valid | Epoch[153/600] Iteration[007/008] Valid loss: 1.6346
2023-02-06 11:54:36 | Valid | Epoch[153/600] Iteration[008/008] Valid loss: 1.7108
2023-02-06 11:54:37 | Valid | Epoch[153/600] MIou: 0.8050115177944982
2023-02-06 11:54:37 | Valid | Epoch[153/600] Pixel Accuracy: 0.9538612365722656
2023-02-06 11:54:37 | Valid | Epoch[153/600] Mean Pixel Accuracy: 0.9723068743330046
2023-02-06 11:54:37 | Stage | Epoch[153/600] Train loss:0.0303
2023-02-06 11:54:37 | Stage | Epoch[153/600] Valid loss:1.7108
2023-02-06 11:54:37 | Stage | Epoch[153/600] LR:0.01

2023-02-06 11:54:37 | Train | Epoch[154/600] Iteration[001/030] Train loss: 0.0275
2023-02-06 11:54:37 | Train | Epoch[154/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 11:54:37 | Train | Epoch[154/600] Iteration[003/030] Train loss: 0.0276
2023-02-06 11:54:37 | Train | Epoch[154/600] Iteration[004/030] Train loss: 0.0281
2023-02-06 11:54:37 | Train | Epoch[154/600] Iteration[005/030] Train loss: 0.0281
2023-02-06 11:54:37 | Train | Epoch[154/600] Iteration[006/030] Train loss: 0.0287
2023-02-06 11:54:37 | Train | Epoch[154/600] Iteration[007/030] Train loss: 0.0290
2023-02-06 11:54:37 | Train | Epoch[154/600] Iteration[008/030] Train loss: 0.0292
2023-02-06 11:54:37 | Train | Epoch[154/600] Iteration[009/030] Train loss: 0.0293
2023-02-06 11:54:37 | Train | Epoch[154/600] Iteration[010/030] Train loss: 0.0293
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[011/030] Train loss: 0.0293
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[012/030] Train loss: 0.0294
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[013/030] Train loss: 0.0294
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[014/030] Train loss: 0.0294
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[015/030] Train loss: 0.0294
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[016/030] Train loss: 0.0293
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[017/030] Train loss: 0.0293
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[018/030] Train loss: 0.0293
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[019/030] Train loss: 0.0296
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[020/030] Train loss: 0.0296
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[021/030] Train loss: 0.0296
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[022/030] Train loss: 0.0296
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[023/030] Train loss: 0.0295
2023-02-06 11:54:38 | Train | Epoch[154/600] Iteration[024/030] Train loss: 0.0295
2023-02-06 11:54:39 | Train | Epoch[154/600] Iteration[025/030] Train loss: 0.0296
2023-02-06 11:54:39 | Train | Epoch[154/600] Iteration[026/030] Train loss: 0.0296
2023-02-06 11:54:39 | Train | Epoch[154/600] Iteration[027/030] Train loss: 0.0295
2023-02-06 11:54:39 | Train | Epoch[154/600] Iteration[028/030] Train loss: 0.0296
2023-02-06 11:54:39 | Train | Epoch[154/600] Iteration[029/030] Train loss: 0.0297
2023-02-06 11:54:39 | Train | Epoch[154/600] Iteration[030/030] Train loss: 0.0298
2023-02-06 11:54:39 | Valid | Epoch[154/600] Iteration[001/008] Valid loss: 0.7528
2023-02-06 11:54:39 | Valid | Epoch[154/600] Iteration[002/008] Valid loss: 0.6948
2023-02-06 11:54:39 | Valid | Epoch[154/600] Iteration[003/008] Valid loss: 0.7052
2023-02-06 11:54:39 | Valid | Epoch[154/600] Iteration[004/008] Valid loss: 0.7107
2023-02-06 11:54:39 | Valid | Epoch[154/600] Iteration[005/008] Valid loss: 0.7371
2023-02-06 11:54:39 | Valid | Epoch[154/600] Iteration[006/008] Valid loss: 0.7052
2023-02-06 11:54:39 | Valid | Epoch[154/600] Iteration[007/008] Valid loss: 0.7351
2023-02-06 11:54:39 | Valid | Epoch[154/600] Iteration[008/008] Valid loss: 0.7413
2023-02-06 11:54:40 | Valid | Epoch[154/600] MIou: 0.8793348118127733
2023-02-06 11:54:40 | Valid | Epoch[154/600] Pixel Accuracy: 0.9755223592122396
2023-02-06 11:54:40 | Valid | Epoch[154/600] Mean Pixel Accuracy: 0.9833060637342437
2023-02-06 11:54:40 | Stage | Epoch[154/600] Train loss:0.0298
2023-02-06 11:54:40 | Stage | Epoch[154/600] Valid loss:0.7413
2023-02-06 11:54:40 | Stage | Epoch[154/600] LR:0.01

2023-02-06 11:54:40 | Train | Epoch[155/600] Iteration[001/030] Train loss: 0.0335
2023-02-06 11:54:40 | Train | Epoch[155/600] Iteration[002/030] Train loss: 0.0325
2023-02-06 11:54:40 | Train | Epoch[155/600] Iteration[003/030] Train loss: 0.0327
2023-02-06 11:54:40 | Train | Epoch[155/600] Iteration[004/030] Train loss: 0.0315
2023-02-06 11:54:40 | Train | Epoch[155/600] Iteration[005/030] Train loss: 0.0308
2023-02-06 11:54:40 | Train | Epoch[155/600] Iteration[006/030] Train loss: 0.0316
2023-02-06 11:54:40 | Train | Epoch[155/600] Iteration[007/030] Train loss: 0.0318
2023-02-06 11:54:40 | Train | Epoch[155/600] Iteration[008/030] Train loss: 0.0317
2023-02-06 11:54:40 | Train | Epoch[155/600] Iteration[009/030] Train loss: 0.0313
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[010/030] Train loss: 0.0314
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[011/030] Train loss: 0.0315
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[012/030] Train loss: 0.0313
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[013/030] Train loss: 0.0312
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[014/030] Train loss: 0.0311
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[015/030] Train loss: 0.0311
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[016/030] Train loss: 0.0309
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[017/030] Train loss: 0.0308
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[018/030] Train loss: 0.0308
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[019/030] Train loss: 0.0307
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[020/030] Train loss: 0.0305
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[021/030] Train loss: 0.0306
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[022/030] Train loss: 0.0305
2023-02-06 11:54:41 | Train | Epoch[155/600] Iteration[023/030] Train loss: 0.0305
2023-02-06 11:54:42 | Train | Epoch[155/600] Iteration[024/030] Train loss: 0.0304
2023-02-06 11:54:42 | Train | Epoch[155/600] Iteration[025/030] Train loss: 0.0305
2023-02-06 11:54:42 | Train | Epoch[155/600] Iteration[026/030] Train loss: 0.0304
2023-02-06 11:54:42 | Train | Epoch[155/600] Iteration[027/030] Train loss: 0.0303
2023-02-06 11:54:42 | Train | Epoch[155/600] Iteration[028/030] Train loss: 0.0303
2023-02-06 11:54:42 | Train | Epoch[155/600] Iteration[029/030] Train loss: 0.0304
2023-02-06 11:54:42 | Train | Epoch[155/600] Iteration[030/030] Train loss: 0.0303
2023-02-06 11:54:42 | Valid | Epoch[155/600] Iteration[001/008] Valid loss: 0.0695
2023-02-06 11:54:42 | Valid | Epoch[155/600] Iteration[002/008] Valid loss: 0.0704
2023-02-06 11:54:42 | Valid | Epoch[155/600] Iteration[003/008] Valid loss: 0.0743
2023-02-06 11:54:42 | Valid | Epoch[155/600] Iteration[004/008] Valid loss: 0.0730
2023-02-06 11:54:42 | Valid | Epoch[155/600] Iteration[005/008] Valid loss: 0.0738
2023-02-06 11:54:42 | Valid | Epoch[155/600] Iteration[006/008] Valid loss: 0.0725
2023-02-06 11:54:42 | Valid | Epoch[155/600] Iteration[007/008] Valid loss: 0.0713
2023-02-06 11:54:42 | Valid | Epoch[155/600] Iteration[008/008] Valid loss: 0.0730
2023-02-06 11:54:43 | Valid | Epoch[155/600] MIou: 0.7908915311650124
2023-02-06 11:54:43 | Valid | Epoch[155/600] Pixel Accuracy: 0.9655138651529948
2023-02-06 11:54:43 | Valid | Epoch[155/600] Mean Pixel Accuracy: 0.8092498738702054
2023-02-06 11:54:43 | Stage | Epoch[155/600] Train loss:0.0303
2023-02-06 11:54:43 | Stage | Epoch[155/600] Valid loss:0.0730
2023-02-06 11:54:43 | Stage | Epoch[155/600] LR:0.01

2023-02-06 11:54:43 | Train | Epoch[156/600] Iteration[001/030] Train loss: 0.0303
2023-02-06 11:54:43 | Train | Epoch[156/600] Iteration[002/030] Train loss: 0.0305
2023-02-06 11:54:43 | Train | Epoch[156/600] Iteration[003/030] Train loss: 0.0305
2023-02-06 11:54:43 | Train | Epoch[156/600] Iteration[004/030] Train loss: 0.0301
2023-02-06 11:54:43 | Train | Epoch[156/600] Iteration[005/030] Train loss: 0.0300
2023-02-06 11:54:43 | Train | Epoch[156/600] Iteration[006/030] Train loss: 0.0297
2023-02-06 11:54:43 | Train | Epoch[156/600] Iteration[007/030] Train loss: 0.0293
2023-02-06 11:54:43 | Train | Epoch[156/600] Iteration[008/030] Train loss: 0.0293
2023-02-06 11:54:43 | Train | Epoch[156/600] Iteration[009/030] Train loss: 0.0294
2023-02-06 11:54:43 | Train | Epoch[156/600] Iteration[010/030] Train loss: 0.0291
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[011/030] Train loss: 0.0293
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[012/030] Train loss: 0.0294
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[013/030] Train loss: 0.0294
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[014/030] Train loss: 0.0294
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[015/030] Train loss: 0.0294
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[016/030] Train loss: 0.0294
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[017/030] Train loss: 0.0294
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[018/030] Train loss: 0.0294
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[019/030] Train loss: 0.0295
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[020/030] Train loss: 0.0295
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[021/030] Train loss: 0.0296
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[022/030] Train loss: 0.0297
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[023/030] Train loss: 0.0295
2023-02-06 11:54:44 | Train | Epoch[156/600] Iteration[024/030] Train loss: 0.0295
2023-02-06 11:54:45 | Train | Epoch[156/600] Iteration[025/030] Train loss: 0.0296
2023-02-06 11:54:45 | Train | Epoch[156/600] Iteration[026/030] Train loss: 0.0295
2023-02-06 11:54:45 | Train | Epoch[156/600] Iteration[027/030] Train loss: 0.0295
2023-02-06 11:54:45 | Train | Epoch[156/600] Iteration[028/030] Train loss: 0.0295
2023-02-06 11:54:45 | Train | Epoch[156/600] Iteration[029/030] Train loss: 0.0295
2023-02-06 11:54:45 | Train | Epoch[156/600] Iteration[030/030] Train loss: 0.0295
2023-02-06 11:54:45 | Valid | Epoch[156/600] Iteration[001/008] Valid loss: 0.0701
2023-02-06 11:54:45 | Valid | Epoch[156/600] Iteration[002/008] Valid loss: 0.0537
2023-02-06 11:54:45 | Valid | Epoch[156/600] Iteration[003/008] Valid loss: 0.0498
2023-02-06 11:54:45 | Valid | Epoch[156/600] Iteration[004/008] Valid loss: 0.0466
2023-02-06 11:54:45 | Valid | Epoch[156/600] Iteration[005/008] Valid loss: 0.0463
2023-02-06 11:54:45 | Valid | Epoch[156/600] Iteration[006/008] Valid loss: 0.0448
2023-02-06 11:54:45 | Valid | Epoch[156/600] Iteration[007/008] Valid loss: 0.0456
2023-02-06 11:54:45 | Valid | Epoch[156/600] Iteration[008/008] Valid loss: 0.0449
2023-02-06 11:54:45 | Valid | Epoch[156/600] MIou: 0.9217451494113427
2023-02-06 11:54:45 | Valid | Epoch[156/600] Pixel Accuracy: 0.9869003295898438
2023-02-06 11:54:45 | Valid | Epoch[156/600] Mean Pixel Accuracy: 0.9361921327952991
2023-02-06 11:54:45 | Stage | Epoch[156/600] Train loss:0.0295
2023-02-06 11:54:45 | Stage | Epoch[156/600] Valid loss:0.0449
2023-02-06 11:54:45 | Stage | Epoch[156/600] LR:0.01

2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[001/030] Train loss: 0.0293
2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[002/030] Train loss: 0.0297
2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[003/030] Train loss: 0.0304
2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[004/030] Train loss: 0.0299
2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[005/030] Train loss: 0.0291
2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[006/030] Train loss: 0.0288
2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[007/030] Train loss: 0.0292
2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[008/030] Train loss: 0.0294
2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[009/030] Train loss: 0.0295
2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[010/030] Train loss: 0.0293
2023-02-06 11:54:46 | Train | Epoch[157/600] Iteration[011/030] Train loss: 0.0290
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[012/030] Train loss: 0.0291
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[013/030] Train loss: 0.0291
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[014/030] Train loss: 0.0292
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[015/030] Train loss: 0.0293
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[016/030] Train loss: 0.0293
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[017/030] Train loss: 0.0293
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[018/030] Train loss: 0.0292
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[019/030] Train loss: 0.0292
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[020/030] Train loss: 0.0293
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[021/030] Train loss: 0.0292
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[022/030] Train loss: 0.0295
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[023/030] Train loss: 0.0296
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[024/030] Train loss: 0.0295
2023-02-06 11:54:47 | Train | Epoch[157/600] Iteration[025/030] Train loss: 0.0294
2023-02-06 11:54:48 | Train | Epoch[157/600] Iteration[026/030] Train loss: 0.0293
2023-02-06 11:54:48 | Train | Epoch[157/600] Iteration[027/030] Train loss: 0.0294
2023-02-06 11:54:48 | Train | Epoch[157/600] Iteration[028/030] Train loss: 0.0293
2023-02-06 11:54:48 | Train | Epoch[157/600] Iteration[029/030] Train loss: 0.0293
2023-02-06 11:54:48 | Train | Epoch[157/600] Iteration[030/030] Train loss: 0.0292
2023-02-06 11:54:48 | Valid | Epoch[157/600] Iteration[001/008] Valid loss: 0.2913
2023-02-06 11:54:48 | Valid | Epoch[157/600] Iteration[002/008] Valid loss: 0.2500
2023-02-06 11:54:48 | Valid | Epoch[157/600] Iteration[003/008] Valid loss: 0.2409
2023-02-06 11:54:48 | Valid | Epoch[157/600] Iteration[004/008] Valid loss: 0.2353
2023-02-06 11:54:48 | Valid | Epoch[157/600] Iteration[005/008] Valid loss: 0.2466
2023-02-06 11:54:48 | Valid | Epoch[157/600] Iteration[006/008] Valid loss: 0.2368
2023-02-06 11:54:48 | Valid | Epoch[157/600] Iteration[007/008] Valid loss: 0.2584
2023-02-06 11:54:48 | Valid | Epoch[157/600] Iteration[008/008] Valid loss: 0.2581
2023-02-06 11:54:48 | Valid | Epoch[157/600] MIou: 0.9049574925301143
2023-02-06 11:54:48 | Valid | Epoch[157/600] Pixel Accuracy: 0.9819068908691406
2023-02-06 11:54:48 | Valid | Epoch[157/600] Mean Pixel Accuracy: 0.9794222848434808
2023-02-06 11:54:48 | Stage | Epoch[157/600] Train loss:0.0292
2023-02-06 11:54:48 | Stage | Epoch[157/600] Valid loss:0.2581
2023-02-06 11:54:48 | Stage | Epoch[157/600] LR:0.01

2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[001/030] Train loss: 0.0291
2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[002/030] Train loss: 0.0287
2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[003/030] Train loss: 0.0288
2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[004/030] Train loss: 0.0282
2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[005/030] Train loss: 0.0283
2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[006/030] Train loss: 0.0280
2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[007/030] Train loss: 0.0280
2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[008/030] Train loss: 0.0278
2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[009/030] Train loss: 0.0279
2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 11:54:49 | Train | Epoch[158/600] Iteration[011/030] Train loss: 0.0281
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[012/030] Train loss: 0.0283
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[013/030] Train loss: 0.0283
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[014/030] Train loss: 0.0284
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[015/030] Train loss: 0.0283
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[016/030] Train loss: 0.0285
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[017/030] Train loss: 0.0287
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[018/030] Train loss: 0.0288
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[019/030] Train loss: 0.0288
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[020/030] Train loss: 0.0290
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[021/030] Train loss: 0.0290
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[022/030] Train loss: 0.0290
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[023/030] Train loss: 0.0289
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[024/030] Train loss: 0.0289
2023-02-06 11:54:50 | Train | Epoch[158/600] Iteration[025/030] Train loss: 0.0290
2023-02-06 11:54:51 | Train | Epoch[158/600] Iteration[026/030] Train loss: 0.0291
2023-02-06 11:54:51 | Train | Epoch[158/600] Iteration[027/030] Train loss: 0.0291
2023-02-06 11:54:51 | Train | Epoch[158/600] Iteration[028/030] Train loss: 0.0293
2023-02-06 11:54:51 | Train | Epoch[158/600] Iteration[029/030] Train loss: 0.0294
2023-02-06 11:54:51 | Train | Epoch[158/600] Iteration[030/030] Train loss: 0.0293
2023-02-06 11:54:51 | Valid | Epoch[158/600] Iteration[001/008] Valid loss: 0.4329
2023-02-06 11:54:51 | Valid | Epoch[158/600] Iteration[002/008] Valid loss: 0.3663
2023-02-06 11:54:51 | Valid | Epoch[158/600] Iteration[003/008] Valid loss: 0.3694
2023-02-06 11:54:51 | Valid | Epoch[158/600] Iteration[004/008] Valid loss: 0.3688
2023-02-06 11:54:51 | Valid | Epoch[158/600] Iteration[005/008] Valid loss: 0.3851
2023-02-06 11:54:51 | Valid | Epoch[158/600] Iteration[006/008] Valid loss: 0.3699
2023-02-06 11:54:51 | Valid | Epoch[158/600] Iteration[007/008] Valid loss: 0.3947
2023-02-06 11:54:51 | Valid | Epoch[158/600] Iteration[008/008] Valid loss: 0.3934
2023-02-06 11:54:51 | Valid | Epoch[158/600] MIou: 0.8932648659720019
2023-02-06 11:54:51 | Valid | Epoch[158/600] Pixel Accuracy: 0.9790547688802084
2023-02-06 11:54:51 | Valid | Epoch[158/600] Mean Pixel Accuracy: 0.9819949648556909
2023-02-06 11:54:51 | Stage | Epoch[158/600] Train loss:0.0293
2023-02-06 11:54:51 | Stage | Epoch[158/600] Valid loss:0.3934
2023-02-06 11:54:51 | Stage | Epoch[158/600] LR:0.01

2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[001/030] Train loss: 0.0259
2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[002/030] Train loss: 0.0283
2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[003/030] Train loss: 0.0286
2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[004/030] Train loss: 0.0287
2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[005/030] Train loss: 0.0293
2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[006/030] Train loss: 0.0292
2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[007/030] Train loss: 0.0299
2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[008/030] Train loss: 0.0298
2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[009/030] Train loss: 0.0297
2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[010/030] Train loss: 0.0297
2023-02-06 11:54:52 | Train | Epoch[159/600] Iteration[011/030] Train loss: 0.0297
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[012/030] Train loss: 0.0296
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[013/030] Train loss: 0.0295
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[014/030] Train loss: 0.0294
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[015/030] Train loss: 0.0295
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[016/030] Train loss: 0.0296
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[017/030] Train loss: 0.0295
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[018/030] Train loss: 0.0294
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[019/030] Train loss: 0.0294
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[020/030] Train loss: 0.0296
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[021/030] Train loss: 0.0295
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[022/030] Train loss: 0.0295
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[023/030] Train loss: 0.0295
2023-02-06 11:54:53 | Train | Epoch[159/600] Iteration[024/030] Train loss: 0.0293
2023-02-06 11:54:54 | Train | Epoch[159/600] Iteration[025/030] Train loss: 0.0293
2023-02-06 11:54:54 | Train | Epoch[159/600] Iteration[026/030] Train loss: 0.0292
2023-02-06 11:54:54 | Train | Epoch[159/600] Iteration[027/030] Train loss: 0.0293
2023-02-06 11:54:54 | Train | Epoch[159/600] Iteration[028/030] Train loss: 0.0293
2023-02-06 11:54:54 | Train | Epoch[159/600] Iteration[029/030] Train loss: 0.0292
2023-02-06 11:54:54 | Train | Epoch[159/600] Iteration[030/030] Train loss: 0.0292
2023-02-06 11:54:54 | Valid | Epoch[159/600] Iteration[001/008] Valid loss: 0.1217
2023-02-06 11:54:54 | Valid | Epoch[159/600] Iteration[002/008] Valid loss: 0.1174
2023-02-06 11:54:54 | Valid | Epoch[159/600] Iteration[003/008] Valid loss: 0.1222
2023-02-06 11:54:54 | Valid | Epoch[159/600] Iteration[004/008] Valid loss: 0.1216
2023-02-06 11:54:54 | Valid | Epoch[159/600] Iteration[005/008] Valid loss: 0.1231
2023-02-06 11:54:54 | Valid | Epoch[159/600] Iteration[006/008] Valid loss: 0.1217
2023-02-06 11:54:54 | Valid | Epoch[159/600] Iteration[007/008] Valid loss: 0.1206
2023-02-06 11:54:54 | Valid | Epoch[159/600] Iteration[008/008] Valid loss: 0.1233
2023-02-06 11:54:54 | Valid | Epoch[159/600] MIou: 0.6540902299083285
2023-02-06 11:54:54 | Valid | Epoch[159/600] Pixel Accuracy: 0.9428545633951823
2023-02-06 11:54:54 | Valid | Epoch[159/600] Mean Pixel Accuracy: 0.6836433006236889
2023-02-06 11:54:54 | Stage | Epoch[159/600] Train loss:0.0292
2023-02-06 11:54:54 | Stage | Epoch[159/600] Valid loss:0.1233
2023-02-06 11:54:54 | Stage | Epoch[159/600] LR:0.01

2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[001/030] Train loss: 0.0304
2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[002/030] Train loss: 0.0291
2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[003/030] Train loss: 0.0287
2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[004/030] Train loss: 0.0288
2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[005/030] Train loss: 0.0292
2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[006/030] Train loss: 0.0290
2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[007/030] Train loss: 0.0292
2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[008/030] Train loss: 0.0290
2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[009/030] Train loss: 0.0298
2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[010/030] Train loss: 0.0298
2023-02-06 11:54:55 | Train | Epoch[160/600] Iteration[011/030] Train loss: 0.0299
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[012/030] Train loss: 0.0300
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[013/030] Train loss: 0.0298
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[014/030] Train loss: 0.0296
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[015/030] Train loss: 0.0295
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[016/030] Train loss: 0.0296
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[017/030] Train loss: 0.0294
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[018/030] Train loss: 0.0294
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[019/030] Train loss: 0.0295
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[020/030] Train loss: 0.0296
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[021/030] Train loss: 0.0295
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[022/030] Train loss: 0.0295
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[023/030] Train loss: 0.0294
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[024/030] Train loss: 0.0294
2023-02-06 11:54:56 | Train | Epoch[160/600] Iteration[025/030] Train loss: 0.0293
2023-02-06 11:54:57 | Train | Epoch[160/600] Iteration[026/030] Train loss: 0.0292
2023-02-06 11:54:57 | Train | Epoch[160/600] Iteration[027/030] Train loss: 0.0293
2023-02-06 11:54:57 | Train | Epoch[160/600] Iteration[028/030] Train loss: 0.0291
2023-02-06 11:54:57 | Train | Epoch[160/600] Iteration[029/030] Train loss: 0.0291
2023-02-06 11:54:57 | Train | Epoch[160/600] Iteration[030/030] Train loss: 0.0291
2023-02-06 11:54:57 | Valid | Epoch[160/600] Iteration[001/008] Valid loss: 0.0690
2023-02-06 11:54:57 | Valid | Epoch[160/600] Iteration[002/008] Valid loss: 0.0692
2023-02-06 11:54:57 | Valid | Epoch[160/600] Iteration[003/008] Valid loss: 0.0726
2023-02-06 11:54:57 | Valid | Epoch[160/600] Iteration[004/008] Valid loss: 0.0709
2023-02-06 11:54:57 | Valid | Epoch[160/600] Iteration[005/008] Valid loss: 0.0718
2023-02-06 11:54:57 | Valid | Epoch[160/600] Iteration[006/008] Valid loss: 0.0707
2023-02-06 11:54:57 | Valid | Epoch[160/600] Iteration[007/008] Valid loss: 0.0694
2023-02-06 11:54:57 | Valid | Epoch[160/600] Iteration[008/008] Valid loss: 0.0721
2023-02-06 11:54:57 | Valid | Epoch[160/600] MIou: 0.7653196368524079
2023-02-06 11:54:57 | Valid | Epoch[160/600] Pixel Accuracy: 0.9612770080566406
2023-02-06 11:54:57 | Valid | Epoch[160/600] Mean Pixel Accuracy: 0.7858517296778231
2023-02-06 11:54:57 | Stage | Epoch[160/600] Train loss:0.0291
2023-02-06 11:54:57 | Stage | Epoch[160/600] Valid loss:0.0721
2023-02-06 11:54:57 | Stage | Epoch[160/600] LR:0.01

2023-02-06 11:54:58 | Train | Epoch[161/600] Iteration[001/030] Train loss: 0.0279
2023-02-06 11:54:58 | Train | Epoch[161/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 11:54:58 | Train | Epoch[161/600] Iteration[003/030] Train loss: 0.0283
2023-02-06 11:54:58 | Train | Epoch[161/600] Iteration[004/030] Train loss: 0.0285
2023-02-06 11:54:58 | Train | Epoch[161/600] Iteration[005/030] Train loss: 0.0292
2023-02-06 11:54:58 | Train | Epoch[161/600] Iteration[006/030] Train loss: 0.0294
2023-02-06 11:54:58 | Train | Epoch[161/600] Iteration[007/030] Train loss: 0.0294
2023-02-06 11:54:58 | Train | Epoch[161/600] Iteration[008/030] Train loss: 0.0299
2023-02-06 11:54:58 | Train | Epoch[161/600] Iteration[009/030] Train loss: 0.0299
2023-02-06 11:54:58 | Train | Epoch[161/600] Iteration[010/030] Train loss: 0.0295
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[011/030] Train loss: 0.0296
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[012/030] Train loss: 0.0295
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[013/030] Train loss: 0.0293
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[014/030] Train loss: 0.0291
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[015/030] Train loss: 0.0289
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[016/030] Train loss: 0.0288
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[017/030] Train loss: 0.0289
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[018/030] Train loss: 0.0290
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[019/030] Train loss: 0.0290
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[020/030] Train loss: 0.0290
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[021/030] Train loss: 0.0290
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[022/030] Train loss: 0.0290
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[023/030] Train loss: 0.0289
2023-02-06 11:54:59 | Train | Epoch[161/600] Iteration[024/030] Train loss: 0.0289
2023-02-06 11:55:00 | Train | Epoch[161/600] Iteration[025/030] Train loss: 0.0289
2023-02-06 11:55:00 | Train | Epoch[161/600] Iteration[026/030] Train loss: 0.0290
2023-02-06 11:55:00 | Train | Epoch[161/600] Iteration[027/030] Train loss: 0.0289
2023-02-06 11:55:00 | Train | Epoch[161/600] Iteration[028/030] Train loss: 0.0290
2023-02-06 11:55:00 | Train | Epoch[161/600] Iteration[029/030] Train loss: 0.0290
2023-02-06 11:55:00 | Train | Epoch[161/600] Iteration[030/030] Train loss: 0.0289
2023-02-06 11:55:00 | Valid | Epoch[161/600] Iteration[001/008] Valid loss: 0.0515
2023-02-06 11:55:00 | Valid | Epoch[161/600] Iteration[002/008] Valid loss: 0.0446
2023-02-06 11:55:00 | Valid | Epoch[161/600] Iteration[003/008] Valid loss: 0.0442
2023-02-06 11:55:00 | Valid | Epoch[161/600] Iteration[004/008] Valid loss: 0.0421
2023-02-06 11:55:00 | Valid | Epoch[161/600] Iteration[005/008] Valid loss: 0.0421
2023-02-06 11:55:00 | Valid | Epoch[161/600] Iteration[006/008] Valid loss: 0.0412
2023-02-06 11:55:00 | Valid | Epoch[161/600] Iteration[007/008] Valid loss: 0.0415
2023-02-06 11:55:00 | Valid | Epoch[161/600] Iteration[008/008] Valid loss: 0.0415
2023-02-06 11:55:00 | Valid | Epoch[161/600] MIou: 0.8996040734533935
2023-02-06 11:55:00 | Valid | Epoch[161/600] Pixel Accuracy: 0.9833285013834635
2023-02-06 11:55:00 | Valid | Epoch[161/600] Mean Pixel Accuracy: 0.9121640628162462
2023-02-06 11:55:01 | Stage | Epoch[161/600] Train loss:0.0289
2023-02-06 11:55:01 | Stage | Epoch[161/600] Valid loss:0.0415
2023-02-06 11:55:01 | Stage | Epoch[161/600] LR:0.01

2023-02-06 11:55:01 | Train | Epoch[162/600] Iteration[001/030] Train loss: 0.0257
2023-02-06 11:55:01 | Train | Epoch[162/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 11:55:01 | Train | Epoch[162/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 11:55:01 | Train | Epoch[162/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 11:55:01 | Train | Epoch[162/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 11:55:01 | Train | Epoch[162/600] Iteration[006/030] Train loss: 0.0264
2023-02-06 11:55:01 | Train | Epoch[162/600] Iteration[007/030] Train loss: 0.0265
2023-02-06 11:55:01 | Train | Epoch[162/600] Iteration[008/030] Train loss: 0.0270
2023-02-06 11:55:01 | Train | Epoch[162/600] Iteration[009/030] Train loss: 0.0273
2023-02-06 11:55:01 | Train | Epoch[162/600] Iteration[010/030] Train loss: 0.0272
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[014/030] Train loss: 0.0275
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[015/030] Train loss: 0.0274
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[016/030] Train loss: 0.0277
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[017/030] Train loss: 0.0277
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[018/030] Train loss: 0.0277
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[019/030] Train loss: 0.0276
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[020/030] Train loss: 0.0277
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[021/030] Train loss: 0.0278
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[022/030] Train loss: 0.0279
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[023/030] Train loss: 0.0279
2023-02-06 11:55:02 | Train | Epoch[162/600] Iteration[024/030] Train loss: 0.0279
2023-02-06 11:55:03 | Train | Epoch[162/600] Iteration[025/030] Train loss: 0.0281
2023-02-06 11:55:03 | Train | Epoch[162/600] Iteration[026/030] Train loss: 0.0282
2023-02-06 11:55:03 | Train | Epoch[162/600] Iteration[027/030] Train loss: 0.0281
2023-02-06 11:55:03 | Train | Epoch[162/600] Iteration[028/030] Train loss: 0.0280
2023-02-06 11:55:03 | Train | Epoch[162/600] Iteration[029/030] Train loss: 0.0281
2023-02-06 11:55:03 | Train | Epoch[162/600] Iteration[030/030] Train loss: 0.0280
2023-02-06 11:55:03 | Valid | Epoch[162/600] Iteration[001/008] Valid loss: 0.0510
2023-02-06 11:55:03 | Valid | Epoch[162/600] Iteration[002/008] Valid loss: 0.0465
2023-02-06 11:55:03 | Valid | Epoch[162/600] Iteration[003/008] Valid loss: 0.0459
2023-02-06 11:55:03 | Valid | Epoch[162/600] Iteration[004/008] Valid loss: 0.0440
2023-02-06 11:55:03 | Valid | Epoch[162/600] Iteration[005/008] Valid loss: 0.0442
2023-02-06 11:55:03 | Valid | Epoch[162/600] Iteration[006/008] Valid loss: 0.0435
2023-02-06 11:55:03 | Valid | Epoch[162/600] Iteration[007/008] Valid loss: 0.0438
2023-02-06 11:55:03 | Valid | Epoch[162/600] Iteration[008/008] Valid loss: 0.0441
2023-02-06 11:55:04 | Valid | Epoch[162/600] MIou: 0.8898189146822644
2023-02-06 11:55:04 | Valid | Epoch[162/600] Pixel Accuracy: 0.981652577718099
2023-02-06 11:55:04 | Valid | Epoch[162/600] Mean Pixel Accuracy: 0.9042113207864497
2023-02-06 11:55:04 | Stage | Epoch[162/600] Train loss:0.0280
2023-02-06 11:55:04 | Stage | Epoch[162/600] Valid loss:0.0441
2023-02-06 11:55:04 | Stage | Epoch[162/600] LR:0.01

2023-02-06 11:55:04 | Train | Epoch[163/600] Iteration[001/030] Train loss: 0.0293
2023-02-06 11:55:04 | Train | Epoch[163/600] Iteration[002/030] Train loss: 0.0298
2023-02-06 11:55:04 | Train | Epoch[163/600] Iteration[003/030] Train loss: 0.0306
2023-02-06 11:55:04 | Train | Epoch[163/600] Iteration[004/030] Train loss: 0.0299
2023-02-06 11:55:04 | Train | Epoch[163/600] Iteration[005/030] Train loss: 0.0298
2023-02-06 11:55:04 | Train | Epoch[163/600] Iteration[006/030] Train loss: 0.0294
2023-02-06 11:55:04 | Train | Epoch[163/600] Iteration[007/030] Train loss: 0.0291
2023-02-06 11:55:04 | Train | Epoch[163/600] Iteration[008/030] Train loss: 0.0289
2023-02-06 11:55:04 | Train | Epoch[163/600] Iteration[009/030] Train loss: 0.0286
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[010/030] Train loss: 0.0286
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[011/030] Train loss: 0.0285
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[012/030] Train loss: 0.0286
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[013/030] Train loss: 0.0284
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[014/030] Train loss: 0.0285
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[015/030] Train loss: 0.0284
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[016/030] Train loss: 0.0283
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[017/030] Train loss: 0.0284
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[018/030] Train loss: 0.0284
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[019/030] Train loss: 0.0285
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[020/030] Train loss: 0.0285
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[021/030] Train loss: 0.0286
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[022/030] Train loss: 0.0285
2023-02-06 11:55:05 | Train | Epoch[163/600] Iteration[023/030] Train loss: 0.0286
2023-02-06 11:55:06 | Train | Epoch[163/600] Iteration[024/030] Train loss: 0.0285
2023-02-06 11:55:06 | Train | Epoch[163/600] Iteration[025/030] Train loss: 0.0285
2023-02-06 11:55:06 | Train | Epoch[163/600] Iteration[026/030] Train loss: 0.0286
2023-02-06 11:55:06 | Train | Epoch[163/600] Iteration[027/030] Train loss: 0.0286
2023-02-06 11:55:06 | Train | Epoch[163/600] Iteration[028/030] Train loss: 0.0286
2023-02-06 11:55:06 | Train | Epoch[163/600] Iteration[029/030] Train loss: 0.0286
2023-02-06 11:55:06 | Train | Epoch[163/600] Iteration[030/030] Train loss: 0.0286
2023-02-06 11:55:06 | Valid | Epoch[163/600] Iteration[001/008] Valid loss: 0.0706
2023-02-06 11:55:06 | Valid | Epoch[163/600] Iteration[002/008] Valid loss: 0.0706
2023-02-06 11:55:06 | Valid | Epoch[163/600] Iteration[003/008] Valid loss: 0.0737
2023-02-06 11:55:06 | Valid | Epoch[163/600] Iteration[004/008] Valid loss: 0.0723
2023-02-06 11:55:06 | Valid | Epoch[163/600] Iteration[005/008] Valid loss: 0.0733
2023-02-06 11:55:06 | Valid | Epoch[163/600] Iteration[006/008] Valid loss: 0.0724
2023-02-06 11:55:07 | Valid | Epoch[163/600] Iteration[007/008] Valid loss: 0.0711
2023-02-06 11:55:07 | Valid | Epoch[163/600] Iteration[008/008] Valid loss: 0.0729
2023-02-06 11:55:07 | Valid | Epoch[163/600] MIou: 0.7692523637847266
2023-02-06 11:55:07 | Valid | Epoch[163/600] Pixel Accuracy: 0.9619369506835938
2023-02-06 11:55:07 | Valid | Epoch[163/600] Mean Pixel Accuracy: 0.7893910385190209
2023-02-06 11:55:07 | Stage | Epoch[163/600] Train loss:0.0286
2023-02-06 11:55:07 | Stage | Epoch[163/600] Valid loss:0.0729
2023-02-06 11:55:07 | Stage | Epoch[163/600] LR:0.01

2023-02-06 11:55:07 | Train | Epoch[164/600] Iteration[001/030] Train loss: 0.0271
2023-02-06 11:55:07 | Train | Epoch[164/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 11:55:07 | Train | Epoch[164/600] Iteration[003/030] Train loss: 0.0274
2023-02-06 11:55:07 | Train | Epoch[164/600] Iteration[004/030] Train loss: 0.0273
2023-02-06 11:55:07 | Train | Epoch[164/600] Iteration[005/030] Train loss: 0.0274
2023-02-06 11:55:07 | Train | Epoch[164/600] Iteration[006/030] Train loss: 0.0276
2023-02-06 11:55:07 | Train | Epoch[164/600] Iteration[007/030] Train loss: 0.0273
2023-02-06 11:55:07 | Train | Epoch[164/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[009/030] Train loss: 0.0273
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[010/030] Train loss: 0.0274
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[011/030] Train loss: 0.0278
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[012/030] Train loss: 0.0279
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[013/030] Train loss: 0.0278
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[014/030] Train loss: 0.0277
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[015/030] Train loss: 0.0277
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[016/030] Train loss: 0.0278
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[017/030] Train loss: 0.0279
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[018/030] Train loss: 0.0280
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[019/030] Train loss: 0.0281
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[020/030] Train loss: 0.0282
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[021/030] Train loss: 0.0283
2023-02-06 11:55:08 | Train | Epoch[164/600] Iteration[022/030] Train loss: 0.0283
2023-02-06 11:55:09 | Train | Epoch[164/600] Iteration[023/030] Train loss: 0.0282
2023-02-06 11:55:09 | Train | Epoch[164/600] Iteration[024/030] Train loss: 0.0281
2023-02-06 11:55:09 | Train | Epoch[164/600] Iteration[025/030] Train loss: 0.0280
2023-02-06 11:55:09 | Train | Epoch[164/600] Iteration[026/030] Train loss: 0.0280
2023-02-06 11:55:09 | Train | Epoch[164/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 11:55:09 | Train | Epoch[164/600] Iteration[028/030] Train loss: 0.0281
2023-02-06 11:55:09 | Train | Epoch[164/600] Iteration[029/030] Train loss: 0.0281
2023-02-06 11:55:09 | Train | Epoch[164/600] Iteration[030/030] Train loss: 0.0282
2023-02-06 11:55:09 | Valid | Epoch[164/600] Iteration[001/008] Valid loss: 1.4495
2023-02-06 11:55:09 | Valid | Epoch[164/600] Iteration[002/008] Valid loss: 1.3364
2023-02-06 11:55:09 | Valid | Epoch[164/600] Iteration[003/008] Valid loss: 1.3778
2023-02-06 11:55:09 | Valid | Epoch[164/600] Iteration[004/008] Valid loss: 1.4224
2023-02-06 11:55:09 | Valid | Epoch[164/600] Iteration[005/008] Valid loss: 1.4709
2023-02-06 11:55:09 | Valid | Epoch[164/600] Iteration[006/008] Valid loss: 1.4550
2023-02-06 11:55:10 | Valid | Epoch[164/600] Iteration[007/008] Valid loss: 1.5013
2023-02-06 11:55:10 | Valid | Epoch[164/600] Iteration[008/008] Valid loss: 1.5461
2023-02-06 11:55:10 | Valid | Epoch[164/600] MIou: 0.8047523456171015
2023-02-06 11:55:10 | Valid | Epoch[164/600] Pixel Accuracy: 0.953650156656901
2023-02-06 11:55:10 | Valid | Epoch[164/600] Mean Pixel Accuracy: 0.9736998880290545
2023-02-06 11:55:10 | Stage | Epoch[164/600] Train loss:0.0282
2023-02-06 11:55:10 | Stage | Epoch[164/600] Valid loss:1.5461
2023-02-06 11:55:10 | Stage | Epoch[164/600] LR:0.01

2023-02-06 11:55:10 | Train | Epoch[165/600] Iteration[001/030] Train loss: 0.0257
2023-02-06 11:55:10 | Train | Epoch[165/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 11:55:10 | Train | Epoch[165/600] Iteration[003/030] Train loss: 0.0281
2023-02-06 11:55:10 | Train | Epoch[165/600] Iteration[004/030] Train loss: 0.0280
2023-02-06 11:55:10 | Train | Epoch[165/600] Iteration[005/030] Train loss: 0.0282
2023-02-06 11:55:10 | Train | Epoch[165/600] Iteration[006/030] Train loss: 0.0279
2023-02-06 11:55:10 | Train | Epoch[165/600] Iteration[007/030] Train loss: 0.0277
2023-02-06 11:55:10 | Train | Epoch[165/600] Iteration[008/030] Train loss: 0.0280
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[009/030] Train loss: 0.0282
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[010/030] Train loss: 0.0284
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[011/030] Train loss: 0.0284
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[012/030] Train loss: 0.0283
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[013/030] Train loss: 0.0283
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[014/030] Train loss: 0.0282
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[015/030] Train loss: 0.0281
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[016/030] Train loss: 0.0281
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[017/030] Train loss: 0.0281
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[018/030] Train loss: 0.0283
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[019/030] Train loss: 0.0283
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[020/030] Train loss: 0.0284
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[021/030] Train loss: 0.0284
2023-02-06 11:55:11 | Train | Epoch[165/600] Iteration[022/030] Train loss: 0.0283
2023-02-06 11:55:12 | Train | Epoch[165/600] Iteration[023/030] Train loss: 0.0283
2023-02-06 11:55:12 | Train | Epoch[165/600] Iteration[024/030] Train loss: 0.0283
2023-02-06 11:55:12 | Train | Epoch[165/600] Iteration[025/030] Train loss: 0.0283
2023-02-06 11:55:12 | Train | Epoch[165/600] Iteration[026/030] Train loss: 0.0284
2023-02-06 11:55:12 | Train | Epoch[165/600] Iteration[027/030] Train loss: 0.0284
2023-02-06 11:55:12 | Train | Epoch[165/600] Iteration[028/030] Train loss: 0.0286
2023-02-06 11:55:12 | Train | Epoch[165/600] Iteration[029/030] Train loss: 0.0286
2023-02-06 11:55:12 | Train | Epoch[165/600] Iteration[030/030] Train loss: 0.0286
2023-02-06 11:55:12 | Valid | Epoch[165/600] Iteration[001/008] Valid loss: 2.0026
2023-02-06 11:55:12 | Valid | Epoch[165/600] Iteration[002/008] Valid loss: 1.9783
2023-02-06 11:55:12 | Valid | Epoch[165/600] Iteration[003/008] Valid loss: 2.0298
2023-02-06 11:55:12 | Valid | Epoch[165/600] Iteration[004/008] Valid loss: 2.1094
2023-02-06 11:55:12 | Valid | Epoch[165/600] Iteration[005/008] Valid loss: 2.1520
2023-02-06 11:55:12 | Valid | Epoch[165/600] Iteration[006/008] Valid loss: 2.1041
2023-02-06 11:55:12 | Valid | Epoch[165/600] Iteration[007/008] Valid loss: 2.1589
2023-02-06 11:55:13 | Valid | Epoch[165/600] Iteration[008/008] Valid loss: 2.2300
2023-02-06 11:55:13 | Valid | Epoch[165/600] MIou: 0.7928282894521012
2023-02-06 11:55:13 | Valid | Epoch[165/600] Pixel Accuracy: 0.9495315551757812
2023-02-06 11:55:13 | Valid | Epoch[165/600] Mean Pixel Accuracy: 0.9714805123015109
2023-02-06 11:55:13 | Stage | Epoch[165/600] Train loss:0.0286
2023-02-06 11:55:13 | Stage | Epoch[165/600] Valid loss:2.2300
2023-02-06 11:55:13 | Stage | Epoch[165/600] LR:0.01

2023-02-06 11:55:13 | Train | Epoch[166/600] Iteration[001/030] Train loss: 0.0266
2023-02-06 11:55:13 | Train | Epoch[166/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 11:55:13 | Train | Epoch[166/600] Iteration[003/030] Train loss: 0.0259
2023-02-06 11:55:13 | Train | Epoch[166/600] Iteration[004/030] Train loss: 0.0266
2023-02-06 11:55:13 | Train | Epoch[166/600] Iteration[005/030] Train loss: 0.0273
2023-02-06 11:55:13 | Train | Epoch[166/600] Iteration[006/030] Train loss: 0.0277
2023-02-06 11:55:13 | Train | Epoch[166/600] Iteration[007/030] Train loss: 0.0281
2023-02-06 11:55:13 | Train | Epoch[166/600] Iteration[008/030] Train loss: 0.0281
2023-02-06 11:55:13 | Train | Epoch[166/600] Iteration[009/030] Train loss: 0.0279
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[010/030] Train loss: 0.0277
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[011/030] Train loss: 0.0277
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[012/030] Train loss: 0.0278
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[013/030] Train loss: 0.0279
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[014/030] Train loss: 0.0277
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[015/030] Train loss: 0.0277
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[016/030] Train loss: 0.0276
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[017/030] Train loss: 0.0275
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[018/030] Train loss: 0.0274
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[019/030] Train loss: 0.0275
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[020/030] Train loss: 0.0274
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[021/030] Train loss: 0.0274
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[022/030] Train loss: 0.0276
2023-02-06 11:55:14 | Train | Epoch[166/600] Iteration[023/030] Train loss: 0.0275
2023-02-06 11:55:15 | Train | Epoch[166/600] Iteration[024/030] Train loss: 0.0275
2023-02-06 11:55:15 | Train | Epoch[166/600] Iteration[025/030] Train loss: 0.0274
2023-02-06 11:55:15 | Train | Epoch[166/600] Iteration[026/030] Train loss: 0.0274
2023-02-06 11:55:15 | Train | Epoch[166/600] Iteration[027/030] Train loss: 0.0274
2023-02-06 11:55:15 | Train | Epoch[166/600] Iteration[028/030] Train loss: 0.0275
2023-02-06 11:55:15 | Train | Epoch[166/600] Iteration[029/030] Train loss: 0.0275
2023-02-06 11:55:15 | Train | Epoch[166/600] Iteration[030/030] Train loss: 0.0276
2023-02-06 11:55:15 | Valid | Epoch[166/600] Iteration[001/008] Valid loss: 0.0477
2023-02-06 11:55:15 | Valid | Epoch[166/600] Iteration[002/008] Valid loss: 0.0427
2023-02-06 11:55:15 | Valid | Epoch[166/600] Iteration[003/008] Valid loss: 0.0431
2023-02-06 11:55:15 | Valid | Epoch[166/600] Iteration[004/008] Valid loss: 0.0416
2023-02-06 11:55:15 | Valid | Epoch[166/600] Iteration[005/008] Valid loss: 0.0418
2023-02-06 11:55:15 | Valid | Epoch[166/600] Iteration[006/008] Valid loss: 0.0408
2023-02-06 11:55:16 | Valid | Epoch[166/600] Iteration[007/008] Valid loss: 0.0405
2023-02-06 11:55:16 | Valid | Epoch[166/600] Iteration[008/008] Valid loss: 0.0406
2023-02-06 11:55:16 | Valid | Epoch[166/600] MIou: 0.8934881210808254
2023-02-06 11:55:16 | Valid | Epoch[166/600] Pixel Accuracy: 0.9823824564615885
2023-02-06 11:55:16 | Valid | Epoch[166/600] Mean Pixel Accuracy: 0.9048978144904909
2023-02-06 11:55:16 | Stage | Epoch[166/600] Train loss:0.0276
2023-02-06 11:55:16 | Stage | Epoch[166/600] Valid loss:0.0406
2023-02-06 11:55:16 | Stage | Epoch[166/600] LR:0.01

2023-02-06 11:55:16 | Train | Epoch[167/600] Iteration[001/030] Train loss: 0.0285
2023-02-06 11:55:16 | Train | Epoch[167/600] Iteration[002/030] Train loss: 0.0274
2023-02-06 11:55:16 | Train | Epoch[167/600] Iteration[003/030] Train loss: 0.0289
2023-02-06 11:55:16 | Train | Epoch[167/600] Iteration[004/030] Train loss: 0.0281
2023-02-06 11:55:16 | Train | Epoch[167/600] Iteration[005/030] Train loss: 0.0279
2023-02-06 11:55:16 | Train | Epoch[167/600] Iteration[006/030] Train loss: 0.0272
2023-02-06 11:55:16 | Train | Epoch[167/600] Iteration[007/030] Train loss: 0.0271
2023-02-06 11:55:16 | Train | Epoch[167/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[009/030] Train loss: 0.0272
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[010/030] Train loss: 0.0272
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[011/030] Train loss: 0.0272
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[012/030] Train loss: 0.0275
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[014/030] Train loss: 0.0274
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[015/030] Train loss: 0.0274
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[017/030] Train loss: 0.0274
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[018/030] Train loss: 0.0275
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[019/030] Train loss: 0.0275
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[020/030] Train loss: 0.0275
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 11:55:17 | Train | Epoch[167/600] Iteration[022/030] Train loss: 0.0277
2023-02-06 11:55:18 | Train | Epoch[167/600] Iteration[023/030] Train loss: 0.0277
2023-02-06 11:55:18 | Train | Epoch[167/600] Iteration[024/030] Train loss: 0.0277
2023-02-06 11:55:18 | Train | Epoch[167/600] Iteration[025/030] Train loss: 0.0277
2023-02-06 11:55:18 | Train | Epoch[167/600] Iteration[026/030] Train loss: 0.0277
2023-02-06 11:55:18 | Train | Epoch[167/600] Iteration[027/030] Train loss: 0.0276
2023-02-06 11:55:18 | Train | Epoch[167/600] Iteration[028/030] Train loss: 0.0276
2023-02-06 11:55:18 | Train | Epoch[167/600] Iteration[029/030] Train loss: 0.0276
2023-02-06 11:55:18 | Train | Epoch[167/600] Iteration[030/030] Train loss: 0.0275
2023-02-06 11:55:18 | Valid | Epoch[167/600] Iteration[001/008] Valid loss: 0.1623
2023-02-06 11:55:18 | Valid | Epoch[167/600] Iteration[002/008] Valid loss: 0.1571
2023-02-06 11:55:18 | Valid | Epoch[167/600] Iteration[003/008] Valid loss: 0.1395
2023-02-06 11:55:18 | Valid | Epoch[167/600] Iteration[004/008] Valid loss: 0.1370
2023-02-06 11:55:18 | Valid | Epoch[167/600] Iteration[005/008] Valid loss: 0.1323
2023-02-06 11:55:19 | Valid | Epoch[167/600] Iteration[006/008] Valid loss: 0.1320
2023-02-06 11:55:19 | Valid | Epoch[167/600] Iteration[007/008] Valid loss: 0.1390
2023-02-06 11:55:19 | Valid | Epoch[167/600] Iteration[008/008] Valid loss: 0.1419
2023-02-06 11:55:19 | Valid | Epoch[167/600] MIou: 0.9192023425832045
2023-02-06 11:55:19 | Valid | Epoch[167/600] Pixel Accuracy: 0.9852638244628906
2023-02-06 11:55:19 | Valid | Epoch[167/600] Mean Pixel Accuracy: 0.9732086594245074
2023-02-06 11:55:19 | Stage | Epoch[167/600] Train loss:0.0275
2023-02-06 11:55:19 | Stage | Epoch[167/600] Valid loss:0.1419
2023-02-06 11:55:19 | Stage | Epoch[167/600] LR:0.01

2023-02-06 11:55:19 | Train | Epoch[168/600] Iteration[001/030] Train loss: 0.0265
2023-02-06 11:55:19 | Train | Epoch[168/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 11:55:19 | Train | Epoch[168/600] Iteration[003/030] Train loss: 0.0276
2023-02-06 11:55:19 | Train | Epoch[168/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 11:55:19 | Train | Epoch[168/600] Iteration[005/030] Train loss: 0.0263
2023-02-06 11:55:19 | Train | Epoch[168/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 11:55:19 | Train | Epoch[168/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 11:55:19 | Train | Epoch[168/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[010/030] Train loss: 0.0264
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[011/030] Train loss: 0.0263
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[015/030] Train loss: 0.0268
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[016/030] Train loss: 0.0267
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[017/030] Train loss: 0.0269
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[019/030] Train loss: 0.0270
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[020/030] Train loss: 0.0269
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[021/030] Train loss: 0.0269
2023-02-06 11:55:20 | Train | Epoch[168/600] Iteration[022/030] Train loss: 0.0268
2023-02-06 11:55:21 | Train | Epoch[168/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 11:55:21 | Train | Epoch[168/600] Iteration[024/030] Train loss: 0.0271
2023-02-06 11:55:21 | Train | Epoch[168/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 11:55:21 | Train | Epoch[168/600] Iteration[026/030] Train loss: 0.0270
2023-02-06 11:55:21 | Train | Epoch[168/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 11:55:21 | Train | Epoch[168/600] Iteration[028/030] Train loss: 0.0271
2023-02-06 11:55:21 | Train | Epoch[168/600] Iteration[029/030] Train loss: 0.0271
2023-02-06 11:55:21 | Train | Epoch[168/600] Iteration[030/030] Train loss: 0.0271
2023-02-06 11:55:21 | Valid | Epoch[168/600] Iteration[001/008] Valid loss: 0.1219
2023-02-06 11:55:21 | Valid | Epoch[168/600] Iteration[002/008] Valid loss: 0.0889
2023-02-06 11:55:21 | Valid | Epoch[168/600] Iteration[003/008] Valid loss: 0.0834
2023-02-06 11:55:21 | Valid | Epoch[168/600] Iteration[004/008] Valid loss: 0.0768
2023-02-06 11:55:21 | Valid | Epoch[168/600] Iteration[005/008] Valid loss: 0.0755
2023-02-06 11:55:21 | Valid | Epoch[168/600] Iteration[006/008] Valid loss: 0.0715
2023-02-06 11:55:21 | Valid | Epoch[168/600] Iteration[007/008] Valid loss: 0.0731
2023-02-06 11:55:22 | Valid | Epoch[168/600] Iteration[008/008] Valid loss: 0.0709
2023-02-06 11:55:22 | Valid | Epoch[168/600] MIou: 0.9385117949105223
2023-02-06 11:55:22 | Valid | Epoch[168/600] Pixel Accuracy: 0.9894091288248698
2023-02-06 11:55:22 | Valid | Epoch[168/600] Mean Pixel Accuracy: 0.9650316579713867
2023-02-06 11:55:22 | Stage | Epoch[168/600] Train loss:0.0271
2023-02-06 11:55:22 | Stage | Epoch[168/600] Valid loss:0.0709
2023-02-06 11:55:22 | Stage | Epoch[168/600] LR:0.01

2023-02-06 11:55:22 | Train | Epoch[169/600] Iteration[001/030] Train loss: 0.0254
2023-02-06 11:55:22 | Train | Epoch[169/600] Iteration[002/030] Train loss: 0.0266
2023-02-06 11:55:22 | Train | Epoch[169/600] Iteration[003/030] Train loss: 0.0272
2023-02-06 11:55:22 | Train | Epoch[169/600] Iteration[004/030] Train loss: 0.0275
2023-02-06 11:55:22 | Train | Epoch[169/600] Iteration[005/030] Train loss: 0.0271
2023-02-06 11:55:22 | Train | Epoch[169/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 11:55:22 | Train | Epoch[169/600] Iteration[007/030] Train loss: 0.0279
2023-02-06 11:55:22 | Train | Epoch[169/600] Iteration[008/030] Train loss: 0.0275
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[009/030] Train loss: 0.0273
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[010/030] Train loss: 0.0276
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[011/030] Train loss: 0.0277
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[012/030] Train loss: 0.0277
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[013/030] Train loss: 0.0276
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[014/030] Train loss: 0.0278
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[015/030] Train loss: 0.0278
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[016/030] Train loss: 0.0278
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[017/030] Train loss: 0.0279
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[018/030] Train loss: 0.0279
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[019/030] Train loss: 0.0279
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[020/030] Train loss: 0.0278
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[021/030] Train loss: 0.0278
2023-02-06 11:55:23 | Train | Epoch[169/600] Iteration[022/030] Train loss: 0.0278
2023-02-06 11:55:24 | Train | Epoch[169/600] Iteration[023/030] Train loss: 0.0277
2023-02-06 11:55:24 | Train | Epoch[169/600] Iteration[024/030] Train loss: 0.0277
2023-02-06 11:55:24 | Train | Epoch[169/600] Iteration[025/030] Train loss: 0.0278
2023-02-06 11:55:24 | Train | Epoch[169/600] Iteration[026/030] Train loss: 0.0277
2023-02-06 11:55:24 | Train | Epoch[169/600] Iteration[027/030] Train loss: 0.0276
2023-02-06 11:55:24 | Train | Epoch[169/600] Iteration[028/030] Train loss: 0.0275
2023-02-06 11:55:24 | Train | Epoch[169/600] Iteration[029/030] Train loss: 0.0275
2023-02-06 11:55:24 | Train | Epoch[169/600] Iteration[030/030] Train loss: 0.0275
2023-02-06 11:55:24 | Valid | Epoch[169/600] Iteration[001/008] Valid loss: 0.0566
2023-02-06 11:55:24 | Valid | Epoch[169/600] Iteration[002/008] Valid loss: 0.0529
2023-02-06 11:55:24 | Valid | Epoch[169/600] Iteration[003/008] Valid loss: 0.0542
2023-02-06 11:55:24 | Valid | Epoch[169/600] Iteration[004/008] Valid loss: 0.0518
2023-02-06 11:55:24 | Valid | Epoch[169/600] Iteration[005/008] Valid loss: 0.0521
2023-02-06 11:55:24 | Valid | Epoch[169/600] Iteration[006/008] Valid loss: 0.0511
2023-02-06 11:55:24 | Valid | Epoch[169/600] Iteration[007/008] Valid loss: 0.0503
2023-02-06 11:55:24 | Valid | Epoch[169/600] Iteration[008/008] Valid loss: 0.0517
2023-02-06 11:55:25 | Valid | Epoch[169/600] MIou: 0.8355285450389915
2023-02-06 11:55:25 | Valid | Epoch[169/600] Pixel Accuracy: 0.9728660583496094
2023-02-06 11:55:25 | Valid | Epoch[169/600] Mean Pixel Accuracy: 0.8504651372898446
2023-02-06 11:55:25 | Stage | Epoch[169/600] Train loss:0.0275
2023-02-06 11:55:25 | Stage | Epoch[169/600] Valid loss:0.0517
2023-02-06 11:55:25 | Stage | Epoch[169/600] LR:0.01

2023-02-06 11:55:25 | Train | Epoch[170/600] Iteration[001/030] Train loss: 0.0286
2023-02-06 11:55:25 | Train | Epoch[170/600] Iteration[002/030] Train loss: 0.0270
2023-02-06 11:55:25 | Train | Epoch[170/600] Iteration[003/030] Train loss: 0.0276
2023-02-06 11:55:25 | Train | Epoch[170/600] Iteration[004/030] Train loss: 0.0273
2023-02-06 11:55:25 | Train | Epoch[170/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 11:55:25 | Train | Epoch[170/600] Iteration[006/030] Train loss: 0.0271
2023-02-06 11:55:25 | Train | Epoch[170/600] Iteration[007/030] Train loss: 0.0270
2023-02-06 11:55:25 | Train | Epoch[170/600] Iteration[008/030] Train loss: 0.0268
2023-02-06 11:55:25 | Train | Epoch[170/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 11:55:25 | Train | Epoch[170/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[012/030] Train loss: 0.0268
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[013/030] Train loss: 0.0267
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[015/030] Train loss: 0.0268
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[016/030] Train loss: 0.0269
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[018/030] Train loss: 0.0271
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[019/030] Train loss: 0.0272
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[020/030] Train loss: 0.0273
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[021/030] Train loss: 0.0274
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[022/030] Train loss: 0.0274
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[023/030] Train loss: 0.0274
2023-02-06 11:55:26 | Train | Epoch[170/600] Iteration[024/030] Train loss: 0.0273
2023-02-06 11:55:27 | Train | Epoch[170/600] Iteration[025/030] Train loss: 0.0274
2023-02-06 11:55:27 | Train | Epoch[170/600] Iteration[026/030] Train loss: 0.0274
2023-02-06 11:55:27 | Train | Epoch[170/600] Iteration[027/030] Train loss: 0.0274
2023-02-06 11:55:27 | Train | Epoch[170/600] Iteration[028/030] Train loss: 0.0276
2023-02-06 11:55:27 | Train | Epoch[170/600] Iteration[029/030] Train loss: 0.0276
2023-02-06 11:55:27 | Train | Epoch[170/600] Iteration[030/030] Train loss: 0.0276
2023-02-06 11:55:27 | Valid | Epoch[170/600] Iteration[001/008] Valid loss: 0.2871
2023-02-06 11:55:27 | Valid | Epoch[170/600] Iteration[002/008] Valid loss: 0.2438
2023-02-06 11:55:27 | Valid | Epoch[170/600] Iteration[003/008] Valid loss: 0.2330
2023-02-06 11:55:27 | Valid | Epoch[170/600] Iteration[004/008] Valid loss: 0.2314
2023-02-06 11:55:27 | Valid | Epoch[170/600] Iteration[005/008] Valid loss: 0.2329
2023-02-06 11:55:27 | Valid | Epoch[170/600] Iteration[006/008] Valid loss: 0.2228
2023-02-06 11:55:27 | Valid | Epoch[170/600] Iteration[007/008] Valid loss: 0.2374
2023-02-06 11:55:27 | Valid | Epoch[170/600] Iteration[008/008] Valid loss: 0.2340
2023-02-06 11:55:27 | Valid | Epoch[170/600] MIou: 0.9193080554344057
2023-02-06 11:55:27 | Valid | Epoch[170/600] Pixel Accuracy: 0.9850171407063802
2023-02-06 11:55:27 | Valid | Epoch[170/600] Mean Pixel Accuracy: 0.9821209243588593
2023-02-06 11:55:27 | Stage | Epoch[170/600] Train loss:0.0276
2023-02-06 11:55:27 | Stage | Epoch[170/600] Valid loss:0.2340
2023-02-06 11:55:27 | Stage | Epoch[170/600] LR:0.01

2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[001/030] Train loss: 0.0264
2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[004/030] Train loss: 0.0282
2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[007/030] Train loss: 0.0271
2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[009/030] Train loss: 0.0272
2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 11:55:28 | Train | Epoch[171/600] Iteration[011/030] Train loss: 0.0270
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[012/030] Train loss: 0.0270
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[014/030] Train loss: 0.0271
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[015/030] Train loss: 0.0276
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[017/030] Train loss: 0.0273
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[018/030] Train loss: 0.0275
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[020/030] Train loss: 0.0275
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[021/030] Train loss: 0.0275
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[022/030] Train loss: 0.0275
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[023/030] Train loss: 0.0275
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[024/030] Train loss: 0.0275
2023-02-06 11:55:29 | Train | Epoch[171/600] Iteration[025/030] Train loss: 0.0275
2023-02-06 11:55:30 | Train | Epoch[171/600] Iteration[026/030] Train loss: 0.0275
2023-02-06 11:55:30 | Train | Epoch[171/600] Iteration[027/030] Train loss: 0.0276
2023-02-06 11:55:30 | Train | Epoch[171/600] Iteration[028/030] Train loss: 0.0276
2023-02-06 11:55:30 | Train | Epoch[171/600] Iteration[029/030] Train loss: 0.0276
2023-02-06 11:55:30 | Train | Epoch[171/600] Iteration[030/030] Train loss: 0.0276
2023-02-06 11:55:30 | Valid | Epoch[171/600] Iteration[001/008] Valid loss: 0.1145
2023-02-06 11:55:30 | Valid | Epoch[171/600] Iteration[002/008] Valid loss: 0.1199
2023-02-06 11:55:30 | Valid | Epoch[171/600] Iteration[003/008] Valid loss: 0.1275
2023-02-06 11:55:30 | Valid | Epoch[171/600] Iteration[004/008] Valid loss: 0.1240
2023-02-06 11:55:30 | Valid | Epoch[171/600] Iteration[005/008] Valid loss: 0.1262
2023-02-06 11:55:30 | Valid | Epoch[171/600] Iteration[006/008] Valid loss: 0.1238
2023-02-06 11:55:30 | Valid | Epoch[171/600] Iteration[007/008] Valid loss: 0.1214
2023-02-06 11:55:30 | Valid | Epoch[171/600] Iteration[008/008] Valid loss: 0.1256
2023-02-06 11:55:30 | Valid | Epoch[171/600] MIou: 0.6067327696632554
2023-02-06 11:55:30 | Valid | Epoch[171/600] Pixel Accuracy: 0.9349861145019531
2023-02-06 11:55:30 | Valid | Epoch[171/600] Mean Pixel Accuracy: 0.6400836278139914
2023-02-06 11:55:30 | Stage | Epoch[171/600] Train loss:0.0276
2023-02-06 11:55:30 | Stage | Epoch[171/600] Valid loss:0.1256
2023-02-06 11:55:30 | Stage | Epoch[171/600] LR:0.01

2023-02-06 11:55:31 | Train | Epoch[172/600] Iteration[001/030] Train loss: 0.0272
2023-02-06 11:55:31 | Train | Epoch[172/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 11:55:31 | Train | Epoch[172/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 11:55:31 | Train | Epoch[172/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 11:55:31 | Train | Epoch[172/600] Iteration[005/030] Train loss: 0.0262
2023-02-06 11:55:31 | Train | Epoch[172/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 11:55:31 | Train | Epoch[172/600] Iteration[007/030] Train loss: 0.0271
2023-02-06 11:55:31 | Train | Epoch[172/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 11:55:31 | Train | Epoch[172/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 11:55:31 | Train | Epoch[172/600] Iteration[010/030] Train loss: 0.0269
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[011/030] Train loss: 0.0269
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[012/030] Train loss: 0.0268
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[013/030] Train loss: 0.0268
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[015/030] Train loss: 0.0265
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[018/030] Train loss: 0.0264
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[020/030] Train loss: 0.0266
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[021/030] Train loss: 0.0264
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[022/030] Train loss: 0.0264
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 11:55:32 | Train | Epoch[172/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 11:55:33 | Train | Epoch[172/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 11:55:33 | Train | Epoch[172/600] Iteration[026/030] Train loss: 0.0264
2023-02-06 11:55:33 | Train | Epoch[172/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 11:55:33 | Train | Epoch[172/600] Iteration[028/030] Train loss: 0.0264
2023-02-06 11:55:33 | Train | Epoch[172/600] Iteration[029/030] Train loss: 0.0264
2023-02-06 11:55:33 | Train | Epoch[172/600] Iteration[030/030] Train loss: 0.0264
2023-02-06 11:55:33 | Valid | Epoch[172/600] Iteration[001/008] Valid loss: 0.1300
2023-02-06 11:55:33 | Valid | Epoch[172/600] Iteration[002/008] Valid loss: 0.1008
2023-02-06 11:55:33 | Valid | Epoch[172/600] Iteration[003/008] Valid loss: 0.0965
2023-02-06 11:55:33 | Valid | Epoch[172/600] Iteration[004/008] Valid loss: 0.0969
2023-02-06 11:55:33 | Valid | Epoch[172/600] Iteration[005/008] Valid loss: 0.1011
2023-02-06 11:55:33 | Valid | Epoch[172/600] Iteration[006/008] Valid loss: 0.0936
2023-02-06 11:55:33 | Valid | Epoch[172/600] Iteration[007/008] Valid loss: 0.1028
2023-02-06 11:55:33 | Valid | Epoch[172/600] Iteration[008/008] Valid loss: 0.1011
2023-02-06 11:55:33 | Valid | Epoch[172/600] MIou: 0.9260737900460778
2023-02-06 11:55:33 | Valid | Epoch[172/600] Pixel Accuracy: 0.9869893391927084
2023-02-06 11:55:33 | Valid | Epoch[172/600] Mean Pixel Accuracy: 0.9630549102937868
2023-02-06 11:55:33 | Stage | Epoch[172/600] Train loss:0.0264
2023-02-06 11:55:33 | Stage | Epoch[172/600] Valid loss:0.1011
2023-02-06 11:55:33 | Stage | Epoch[172/600] LR:0.01

2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[001/030] Train loss: 0.0284
2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[002/030] Train loss: 0.0282
2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[004/030] Train loss: 0.0271
2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[005/030] Train loss: 0.0265
2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[006/030] Train loss: 0.0274
2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[007/030] Train loss: 0.0276
2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[008/030] Train loss: 0.0276
2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[009/030] Train loss: 0.0272
2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[010/030] Train loss: 0.0274
2023-02-06 11:55:34 | Train | Epoch[173/600] Iteration[011/030] Train loss: 0.0269
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[012/030] Train loss: 0.0268
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[013/030] Train loss: 0.0268
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[014/030] Train loss: 0.0266
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[015/030] Train loss: 0.0268
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[016/030] Train loss: 0.0268
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[018/030] Train loss: 0.0271
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[019/030] Train loss: 0.0270
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[020/030] Train loss: 0.0271
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[021/030] Train loss: 0.0271
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[022/030] Train loss: 0.0271
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[024/030] Train loss: 0.0270
2023-02-06 11:55:35 | Train | Epoch[173/600] Iteration[025/030] Train loss: 0.0270
2023-02-06 11:55:36 | Train | Epoch[173/600] Iteration[026/030] Train loss: 0.0271
2023-02-06 11:55:36 | Train | Epoch[173/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 11:55:36 | Train | Epoch[173/600] Iteration[028/030] Train loss: 0.0273
2023-02-06 11:55:36 | Train | Epoch[173/600] Iteration[029/030] Train loss: 0.0273
2023-02-06 11:55:36 | Train | Epoch[173/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 11:55:36 | Valid | Epoch[173/600] Iteration[001/008] Valid loss: 0.9292
2023-02-06 11:55:36 | Valid | Epoch[173/600] Iteration[002/008] Valid loss: 0.8669
2023-02-06 11:55:36 | Valid | Epoch[173/600] Iteration[003/008] Valid loss: 0.8973
2023-02-06 11:55:36 | Valid | Epoch[173/600] Iteration[004/008] Valid loss: 0.9301
2023-02-06 11:55:36 | Valid | Epoch[173/600] Iteration[005/008] Valid loss: 0.9510
2023-02-06 11:55:36 | Valid | Epoch[173/600] Iteration[006/008] Valid loss: 0.9295
2023-02-06 11:55:36 | Valid | Epoch[173/600] Iteration[007/008] Valid loss: 0.9648
2023-02-06 11:55:36 | Valid | Epoch[173/600] Iteration[008/008] Valid loss: 0.9924
2023-02-06 11:55:36 | Valid | Epoch[173/600] MIou: 0.8489162265326354
2023-02-06 11:55:36 | Valid | Epoch[173/600] Pixel Accuracy: 0.9674453735351562
2023-02-06 11:55:36 | Valid | Epoch[173/600] Mean Pixel Accuracy: 0.9787461389722815
2023-02-06 11:55:36 | Stage | Epoch[173/600] Train loss:0.0272
2023-02-06 11:55:36 | Stage | Epoch[173/600] Valid loss:0.9924
2023-02-06 11:55:36 | Stage | Epoch[173/600] LR:0.01

2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[001/030] Train loss: 0.0251
2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[005/030] Train loss: 0.0265
2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 11:55:37 | Train | Epoch[174/600] Iteration[011/030] Train loss: 0.0270
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[012/030] Train loss: 0.0270
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[016/030] Train loss: 0.0267
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[018/030] Train loss: 0.0269
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[021/030] Train loss: 0.0268
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[022/030] Train loss: 0.0269
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[023/030] Train loss: 0.0269
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[024/030] Train loss: 0.0269
2023-02-06 11:55:38 | Train | Epoch[174/600] Iteration[025/030] Train loss: 0.0269
2023-02-06 11:55:39 | Train | Epoch[174/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 11:55:39 | Train | Epoch[174/600] Iteration[027/030] Train loss: 0.0270
2023-02-06 11:55:39 | Train | Epoch[174/600] Iteration[028/030] Train loss: 0.0269
2023-02-06 11:55:39 | Train | Epoch[174/600] Iteration[029/030] Train loss: 0.0270
2023-02-06 11:55:39 | Train | Epoch[174/600] Iteration[030/030] Train loss: 0.0270
2023-02-06 11:55:39 | Valid | Epoch[174/600] Iteration[001/008] Valid loss: 0.0641
2023-02-06 11:55:39 | Valid | Epoch[174/600] Iteration[002/008] Valid loss: 0.0648
2023-02-06 11:55:39 | Valid | Epoch[174/600] Iteration[003/008] Valid loss: 0.0673
2023-02-06 11:55:39 | Valid | Epoch[174/600] Iteration[004/008] Valid loss: 0.0652
2023-02-06 11:55:39 | Valid | Epoch[174/600] Iteration[005/008] Valid loss: 0.0661
2023-02-06 11:55:39 | Valid | Epoch[174/600] Iteration[006/008] Valid loss: 0.0647
2023-02-06 11:55:39 | Valid | Epoch[174/600] Iteration[007/008] Valid loss: 0.0634
2023-02-06 11:55:39 | Valid | Epoch[174/600] Iteration[008/008] Valid loss: 0.0650
2023-02-06 11:55:39 | Valid | Epoch[174/600] MIou: 0.7945880433441337
2023-02-06 11:55:39 | Valid | Epoch[174/600] Pixel Accuracy: 0.9661293029785156
2023-02-06 11:55:39 | Valid | Epoch[174/600] Mean Pixel Accuracy: 0.812599868715138
2023-02-06 11:55:39 | Stage | Epoch[174/600] Train loss:0.0270
2023-02-06 11:55:39 | Stage | Epoch[174/600] Valid loss:0.0650
2023-02-06 11:55:39 | Stage | Epoch[174/600] LR:0.01

2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[001/030] Train loss: 0.0279
2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[002/030] Train loss: 0.0266
2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[003/030] Train loss: 0.0258
2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[004/030] Train loss: 0.0257
2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[005/030] Train loss: 0.0257
2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[006/030] Train loss: 0.0261
2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[007/030] Train loss: 0.0261
2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 11:55:40 | Train | Epoch[175/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[013/030] Train loss: 0.0270
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[014/030] Train loss: 0.0269
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[015/030] Train loss: 0.0269
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[016/030] Train loss: 0.0268
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[021/030] Train loss: 0.0268
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[022/030] Train loss: 0.0268
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[023/030] Train loss: 0.0268
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[024/030] Train loss: 0.0269
2023-02-06 11:55:41 | Train | Epoch[175/600] Iteration[025/030] Train loss: 0.0268
2023-02-06 11:55:42 | Train | Epoch[175/600] Iteration[026/030] Train loss: 0.0269
2023-02-06 11:55:42 | Train | Epoch[175/600] Iteration[027/030] Train loss: 0.0271
2023-02-06 11:55:42 | Train | Epoch[175/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 11:55:42 | Train | Epoch[175/600] Iteration[029/030] Train loss: 0.0271
2023-02-06 11:55:42 | Train | Epoch[175/600] Iteration[030/030] Train loss: 0.0270
2023-02-06 11:55:42 | Valid | Epoch[175/600] Iteration[001/008] Valid loss: 0.1530
2023-02-06 11:55:42 | Valid | Epoch[175/600] Iteration[002/008] Valid loss: 0.1585
2023-02-06 11:55:42 | Valid | Epoch[175/600] Iteration[003/008] Valid loss: 0.1675
2023-02-06 11:55:42 | Valid | Epoch[175/600] Iteration[004/008] Valid loss: 0.1658
2023-02-06 11:55:42 | Valid | Epoch[175/600] Iteration[005/008] Valid loss: 0.1716
2023-02-06 11:55:42 | Valid | Epoch[175/600] Iteration[006/008] Valid loss: 0.1680
2023-02-06 11:55:42 | Valid | Epoch[175/600] Iteration[007/008] Valid loss: 0.1672
2023-02-06 11:55:42 | Valid | Epoch[175/600] Iteration[008/008] Valid loss: 0.1754
2023-02-06 11:55:42 | Valid | Epoch[175/600] MIou: 0.5108063224153824
2023-02-06 11:55:42 | Valid | Epoch[175/600] Pixel Accuracy: 0.9190139770507812
2023-02-06 11:55:42 | Valid | Epoch[175/600] Mean Pixel Accuracy: 0.5516810186269424
2023-02-06 11:55:42 | Stage | Epoch[175/600] Train loss:0.0270
2023-02-06 11:55:42 | Stage | Epoch[175/600] Valid loss:0.1754
2023-02-06 11:55:42 | Stage | Epoch[175/600] LR:0.01

2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[001/030] Train loss: 0.0255
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[002/030] Train loss: 0.0283
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[004/030] Train loss: 0.0265
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[005/030] Train loss: 0.0260
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[007/030] Train loss: 0.0268
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[008/030] Train loss: 0.0266
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[011/030] Train loss: 0.0268
2023-02-06 11:55:43 | Train | Epoch[176/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[015/030] Train loss: 0.0265
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[016/030] Train loss: 0.0267
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[018/030] Train loss: 0.0266
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[020/030] Train loss: 0.0266
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[023/030] Train loss: 0.0266
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[024/030] Train loss: 0.0265
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[025/030] Train loss: 0.0265
2023-02-06 11:55:44 | Train | Epoch[176/600] Iteration[026/030] Train loss: 0.0264
2023-02-06 11:55:45 | Train | Epoch[176/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 11:55:45 | Train | Epoch[176/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 11:55:45 | Train | Epoch[176/600] Iteration[029/030] Train loss: 0.0265
2023-02-06 11:55:45 | Train | Epoch[176/600] Iteration[030/030] Train loss: 0.0265
2023-02-06 11:55:45 | Valid | Epoch[176/600] Iteration[001/008] Valid loss: 0.1248
2023-02-06 11:55:45 | Valid | Epoch[176/600] Iteration[002/008] Valid loss: 0.1462
2023-02-06 11:55:45 | Valid | Epoch[176/600] Iteration[003/008] Valid loss: 0.1318
2023-02-06 11:55:45 | Valid | Epoch[176/600] Iteration[004/008] Valid loss: 0.1302
2023-02-06 11:55:45 | Valid | Epoch[176/600] Iteration[005/008] Valid loss: 0.1294
2023-02-06 11:55:45 | Valid | Epoch[176/600] Iteration[006/008] Valid loss: 0.1283
2023-02-06 11:55:45 | Valid | Epoch[176/600] Iteration[007/008] Valid loss: 0.1313
2023-02-06 11:55:45 | Valid | Epoch[176/600] Iteration[008/008] Valid loss: 0.1385
2023-02-06 11:55:45 | Valid | Epoch[176/600] MIou: 0.8886046654063793
2023-02-06 11:55:45 | Valid | Epoch[176/600] Pixel Accuracy: 0.9797185262044271
2023-02-06 11:55:45 | Valid | Epoch[176/600] Mean Pixel Accuracy: 0.9411847721902005
2023-02-06 11:55:45 | Stage | Epoch[176/600] Train loss:0.0265
2023-02-06 11:55:45 | Stage | Epoch[176/600] Valid loss:0.1385
2023-02-06 11:55:45 | Stage | Epoch[176/600] LR:0.01

2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[001/030] Train loss: 0.0235
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[002/030] Train loss: 0.0249
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[007/030] Train loss: 0.0259
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[008/030] Train loss: 0.0259
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 11:55:46 | Train | Epoch[177/600] Iteration[013/030] Train loss: 0.0259
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[014/030] Train loss: 0.0259
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[021/030] Train loss: 0.0257
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[025/030] Train loss: 0.0258
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[026/030] Train loss: 0.0259
2023-02-06 11:55:47 | Train | Epoch[177/600] Iteration[027/030] Train loss: 0.0259
2023-02-06 11:55:48 | Train | Epoch[177/600] Iteration[028/030] Train loss: 0.0259
2023-02-06 11:55:48 | Train | Epoch[177/600] Iteration[029/030] Train loss: 0.0258
2023-02-06 11:55:48 | Train | Epoch[177/600] Iteration[030/030] Train loss: 0.0260
2023-02-06 11:55:48 | Valid | Epoch[177/600] Iteration[001/008] Valid loss: 0.2026
2023-02-06 11:55:48 | Valid | Epoch[177/600] Iteration[002/008] Valid loss: 0.2096
2023-02-06 11:55:48 | Valid | Epoch[177/600] Iteration[003/008] Valid loss: 0.2281
2023-02-06 11:55:48 | Valid | Epoch[177/600] Iteration[004/008] Valid loss: 0.2275
2023-02-06 11:55:48 | Valid | Epoch[177/600] Iteration[005/008] Valid loss: 0.2375
2023-02-06 11:55:48 | Valid | Epoch[177/600] Iteration[006/008] Valid loss: 0.2338
2023-02-06 11:55:48 | Valid | Epoch[177/600] Iteration[007/008] Valid loss: 0.2318
2023-02-06 11:55:48 | Valid | Epoch[177/600] Iteration[008/008] Valid loss: 0.2437
2023-02-06 11:55:48 | Valid | Epoch[177/600] MIou: 0.4933031378462293
2023-02-06 11:55:48 | Valid | Epoch[177/600] Pixel Accuracy: 0.9160957336425781
2023-02-06 11:55:48 | Valid | Epoch[177/600] Mean Pixel Accuracy: 0.5355256454694997
2023-02-06 11:55:48 | Stage | Epoch[177/600] Train loss:0.0260
2023-02-06 11:55:48 | Stage | Epoch[177/600] Valid loss:0.2437
2023-02-06 11:55:48 | Stage | Epoch[177/600] LR:0.01

2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[001/030] Train loss: 0.0277
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[002/030] Train loss: 0.0265
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[005/030] Train loss: 0.0260
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[007/030] Train loss: 0.0261
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[008/030] Train loss: 0.0258
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[011/030] Train loss: 0.0262
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 11:55:49 | Train | Epoch[178/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[015/030] Train loss: 0.0265
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[018/030] Train loss: 0.0266
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[019/030] Train loss: 0.0267
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[020/030] Train loss: 0.0267
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[021/030] Train loss: 0.0267
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[022/030] Train loss: 0.0266
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[023/030] Train loss: 0.0266
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[025/030] Train loss: 0.0265
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 11:55:50 | Train | Epoch[178/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 11:55:51 | Train | Epoch[178/600] Iteration[029/030] Train loss: 0.0268
2023-02-06 11:55:51 | Train | Epoch[178/600] Iteration[030/030] Train loss: 0.0267
2023-02-06 11:55:51 | Valid | Epoch[178/600] Iteration[001/008] Valid loss: 0.1417
2023-02-06 11:55:51 | Valid | Epoch[178/600] Iteration[002/008] Valid loss: 0.1470
2023-02-06 11:55:51 | Valid | Epoch[178/600] Iteration[003/008] Valid loss: 0.1584
2023-02-06 11:55:51 | Valid | Epoch[178/600] Iteration[004/008] Valid loss: 0.1549
2023-02-06 11:55:51 | Valid | Epoch[178/600] Iteration[005/008] Valid loss: 0.1598
2023-02-06 11:55:51 | Valid | Epoch[178/600] Iteration[006/008] Valid loss: 0.1568
2023-02-06 11:55:51 | Valid | Epoch[178/600] Iteration[007/008] Valid loss: 0.1540
2023-02-06 11:55:51 | Valid | Epoch[178/600] Iteration[008/008] Valid loss: 0.1623
2023-02-06 11:55:51 | Valid | Epoch[178/600] MIou: 0.5305325199125219
2023-02-06 11:55:51 | Valid | Epoch[178/600] Pixel Accuracy: 0.9222882588704427
2023-02-06 11:55:51 | Valid | Epoch[178/600] Mean Pixel Accuracy: 0.5698898438330331
2023-02-06 11:55:51 | Stage | Epoch[178/600] Train loss:0.0267
2023-02-06 11:55:51 | Stage | Epoch[178/600] Valid loss:0.1623
2023-02-06 11:55:51 | Stage | Epoch[178/600] LR:0.01

2023-02-06 11:55:51 | Train | Epoch[179/600] Iteration[001/030] Train loss: 0.0291
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[002/030] Train loss: 0.0276
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[003/030] Train loss: 0.0279
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[004/030] Train loss: 0.0263
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[005/030] Train loss: 0.0274
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[006/030] Train loss: 0.0272
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[007/030] Train loss: 0.0271
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 11:55:52 | Train | Epoch[179/600] Iteration[015/030] Train loss: 0.0263
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[017/030] Train loss: 0.0263
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[019/030] Train loss: 0.0264
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[020/030] Train loss: 0.0264
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[021/030] Train loss: 0.0264
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[023/030] Train loss: 0.0264
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[025/030] Train loss: 0.0263
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 11:55:53 | Train | Epoch[179/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 11:55:54 | Valid | Epoch[179/600] Iteration[001/008] Valid loss: 0.0605
2023-02-06 11:55:54 | Valid | Epoch[179/600] Iteration[002/008] Valid loss: 0.0603
2023-02-06 11:55:54 | Valid | Epoch[179/600] Iteration[003/008] Valid loss: 0.0632
2023-02-06 11:55:54 | Valid | Epoch[179/600] Iteration[004/008] Valid loss: 0.0620
2023-02-06 11:55:54 | Valid | Epoch[179/600] Iteration[005/008] Valid loss: 0.0627
2023-02-06 11:55:54 | Valid | Epoch[179/600] Iteration[006/008] Valid loss: 0.0620
2023-02-06 11:55:54 | Valid | Epoch[179/600] Iteration[007/008] Valid loss: 0.0611
2023-02-06 11:55:54 | Valid | Epoch[179/600] Iteration[008/008] Valid loss: 0.0623
2023-02-06 11:55:54 | Valid | Epoch[179/600] MIou: 0.8090979827714602
2023-02-06 11:55:54 | Valid | Epoch[179/600] Pixel Accuracy: 0.9685312906901041
2023-02-06 11:55:54 | Valid | Epoch[179/600] Mean Pixel Accuracy: 0.8258592114609715
2023-02-06 11:55:54 | Stage | Epoch[179/600] Train loss:0.0262
2023-02-06 11:55:54 | Stage | Epoch[179/600] Valid loss:0.0623
2023-02-06 11:55:54 | Stage | Epoch[179/600] LR:0.01

2023-02-06 11:55:54 | Train | Epoch[180/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 11:55:55 | Train | Epoch[180/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[027/030] Train loss: 0.0257
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[028/030] Train loss: 0.0256
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[029/030] Train loss: 0.0256
2023-02-06 11:55:56 | Train | Epoch[180/600] Iteration[030/030] Train loss: 0.0257
2023-02-06 11:55:57 | Valid | Epoch[180/600] Iteration[001/008] Valid loss: 1.4940
2023-02-06 11:55:57 | Valid | Epoch[180/600] Iteration[002/008] Valid loss: 1.3984
2023-02-06 11:55:57 | Valid | Epoch[180/600] Iteration[003/008] Valid loss: 1.4180
2023-02-06 11:55:57 | Valid | Epoch[180/600] Iteration[004/008] Valid loss: 1.4837
2023-02-06 11:55:57 | Valid | Epoch[180/600] Iteration[005/008] Valid loss: 1.5309
2023-02-06 11:55:57 | Valid | Epoch[180/600] Iteration[006/008] Valid loss: 1.4906
2023-02-06 11:55:57 | Valid | Epoch[180/600] Iteration[007/008] Valid loss: 1.5375
2023-02-06 11:55:57 | Valid | Epoch[180/600] Iteration[008/008] Valid loss: 1.5601
2023-02-06 11:55:57 | Valid | Epoch[180/600] MIou: 0.8371843030002397
2023-02-06 11:55:57 | Valid | Epoch[180/600] Pixel Accuracy: 0.9639422098795573
2023-02-06 11:55:57 | Valid | Epoch[180/600] Mean Pixel Accuracy: 0.9786720685023753
2023-02-06 11:55:57 | Stage | Epoch[180/600] Train loss:0.0257
2023-02-06 11:55:57 | Stage | Epoch[180/600] Valid loss:1.5601
2023-02-06 11:55:57 | Stage | Epoch[180/600] LR:0.01

2023-02-06 11:55:57 | Train | Epoch[181/600] Iteration[001/030] Train loss: 0.0297
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[003/030] Train loss: 0.0269
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 11:55:58 | Train | Epoch[181/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:55:59 | Train | Epoch[181/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 11:56:00 | Train | Epoch[181/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:56:00 | Valid | Epoch[181/600] Iteration[001/008] Valid loss: 0.1688
2023-02-06 11:56:00 | Valid | Epoch[181/600] Iteration[002/008] Valid loss: 0.1420
2023-02-06 11:56:00 | Valid | Epoch[181/600] Iteration[003/008] Valid loss: 0.1258
2023-02-06 11:56:00 | Valid | Epoch[181/600] Iteration[004/008] Valid loss: 0.1247
2023-02-06 11:56:00 | Valid | Epoch[181/600] Iteration[005/008] Valid loss: 0.1271
2023-02-06 11:56:00 | Valid | Epoch[181/600] Iteration[006/008] Valid loss: 0.1230
2023-02-06 11:56:00 | Valid | Epoch[181/600] Iteration[007/008] Valid loss: 0.1300
2023-02-06 11:56:00 | Valid | Epoch[181/600] Iteration[008/008] Valid loss: 0.1290
2023-02-06 11:56:00 | Valid | Epoch[181/600] MIou: 0.9318177941013785
2023-02-06 11:56:00 | Valid | Epoch[181/600] Pixel Accuracy: 0.9878031412760416
2023-02-06 11:56:00 | Valid | Epoch[181/600] Mean Pixel Accuracy: 0.9765509009984663
2023-02-06 11:56:00 | Stage | Epoch[181/600] Train loss:0.0252
2023-02-06 11:56:00 | Stage | Epoch[181/600] Valid loss:0.1290
2023-02-06 11:56:00 | Stage | Epoch[181/600] LR:0.01

2023-02-06 11:56:00 | Train | Epoch[182/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[002/030] Train loss: 0.0244
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[003/030] Train loss: 0.0237
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[004/030] Train loss: 0.0240
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[005/030] Train loss: 0.0237
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 11:56:01 | Train | Epoch[182/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[027/030] Train loss: 0.0257
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[028/030] Train loss: 0.0256
2023-02-06 11:56:02 | Train | Epoch[182/600] Iteration[029/030] Train loss: 0.0256
2023-02-06 11:56:03 | Train | Epoch[182/600] Iteration[030/030] Train loss: 0.0255
2023-02-06 11:56:03 | Valid | Epoch[182/600] Iteration[001/008] Valid loss: 0.2573
2023-02-06 11:56:03 | Valid | Epoch[182/600] Iteration[002/008] Valid loss: 0.2643
2023-02-06 11:56:03 | Valid | Epoch[182/600] Iteration[003/008] Valid loss: 0.2870
2023-02-06 11:56:03 | Valid | Epoch[182/600] Iteration[004/008] Valid loss: 0.2852
2023-02-06 11:56:03 | Valid | Epoch[182/600] Iteration[005/008] Valid loss: 0.2985
2023-02-06 11:56:03 | Valid | Epoch[182/600] Iteration[006/008] Valid loss: 0.2946
2023-02-06 11:56:03 | Valid | Epoch[182/600] Iteration[007/008] Valid loss: 0.2913
2023-02-06 11:56:03 | Valid | Epoch[182/600] Iteration[008/008] Valid loss: 0.3091
2023-02-06 11:56:03 | Valid | Epoch[182/600] MIou: 0.4623604032066149
2023-02-06 11:56:03 | Valid | Epoch[182/600] Pixel Accuracy: 0.9109369913736979
2023-02-06 11:56:03 | Valid | Epoch[182/600] Mean Pixel Accuracy: 0.5069478663644427
2023-02-06 11:56:03 | Stage | Epoch[182/600] Train loss:0.0255
2023-02-06 11:56:03 | Stage | Epoch[182/600] Valid loss:0.3091
2023-02-06 11:56:03 | Stage | Epoch[182/600] LR:0.01

2023-02-06 11:56:03 | Train | Epoch[183/600] Iteration[001/030] Train loss: 0.0243
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[002/030] Train loss: 0.0246
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[003/030] Train loss: 0.0246
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[007/030] Train loss: 0.0251
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 11:56:04 | Train | Epoch[183/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[027/030] Train loss: 0.0257
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[028/030] Train loss: 0.0256
2023-02-06 11:56:05 | Train | Epoch[183/600] Iteration[029/030] Train loss: 0.0255
2023-02-06 11:56:06 | Train | Epoch[183/600] Iteration[030/030] Train loss: 0.0257
2023-02-06 11:56:06 | Valid | Epoch[183/600] Iteration[001/008] Valid loss: 0.2116
2023-02-06 11:56:06 | Valid | Epoch[183/600] Iteration[002/008] Valid loss: 0.2162
2023-02-06 11:56:06 | Valid | Epoch[183/600] Iteration[003/008] Valid loss: 0.2341
2023-02-06 11:56:06 | Valid | Epoch[183/600] Iteration[004/008] Valid loss: 0.2349
2023-02-06 11:56:06 | Valid | Epoch[183/600] Iteration[005/008] Valid loss: 0.2448
2023-02-06 11:56:06 | Valid | Epoch[183/600] Iteration[006/008] Valid loss: 0.2418
2023-02-06 11:56:06 | Valid | Epoch[183/600] Iteration[007/008] Valid loss: 0.2410
2023-02-06 11:56:06 | Valid | Epoch[183/600] Iteration[008/008] Valid loss: 0.2516
2023-02-06 11:56:06 | Valid | Epoch[183/600] MIou: 0.4805049270286946
2023-02-06 11:56:06 | Valid | Epoch[183/600] Pixel Accuracy: 0.9139633178710938
2023-02-06 11:56:06 | Valid | Epoch[183/600] Mean Pixel Accuracy: 0.5237079271473769
2023-02-06 11:56:06 | Stage | Epoch[183/600] Train loss:0.0257
2023-02-06 11:56:06 | Stage | Epoch[183/600] Valid loss:0.2516
2023-02-06 11:56:06 | Stage | Epoch[183/600] LR:0.01

2023-02-06 11:56:06 | Train | Epoch[184/600] Iteration[001/030] Train loss: 0.0240
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[004/030] Train loss: 0.0258
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 11:56:07 | Train | Epoch[184/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:56:08 | Train | Epoch[184/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 11:56:09 | Train | Epoch[184/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 11:56:09 | Train | Epoch[184/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 11:56:09 | Valid | Epoch[184/600] Iteration[001/008] Valid loss: 0.0927
2023-02-06 11:56:09 | Valid | Epoch[184/600] Iteration[002/008] Valid loss: 0.0947
2023-02-06 11:56:09 | Valid | Epoch[184/600] Iteration[003/008] Valid loss: 0.0993
2023-02-06 11:56:09 | Valid | Epoch[184/600] Iteration[004/008] Valid loss: 0.0976
2023-02-06 11:56:09 | Valid | Epoch[184/600] Iteration[005/008] Valid loss: 0.0995
2023-02-06 11:56:09 | Valid | Epoch[184/600] Iteration[006/008] Valid loss: 0.0977
2023-02-06 11:56:09 | Valid | Epoch[184/600] Iteration[007/008] Valid loss: 0.0961
2023-02-06 11:56:09 | Valid | Epoch[184/600] Iteration[008/008] Valid loss: 0.1000
2023-02-06 11:56:09 | Valid | Epoch[184/600] MIou: 0.678075774296577
2023-02-06 11:56:09 | Valid | Epoch[184/600] Pixel Accuracy: 0.9468358357747396
2023-02-06 11:56:09 | Valid | Epoch[184/600] Mean Pixel Accuracy: 0.7056835940249757
2023-02-06 11:56:09 | Stage | Epoch[184/600] Train loss:0.0253
2023-02-06 11:56:09 | Stage | Epoch[184/600] Valid loss:0.1000
2023-02-06 11:56:09 | Stage | Epoch[184/600] LR:0.01

2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[001/030] Train loss: 0.0252
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[002/030] Train loss: 0.0252
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[004/030] Train loss: 0.0264
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[005/030] Train loss: 0.0266
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[007/030] Train loss: 0.0265
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 11:56:10 | Train | Epoch[185/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[016/030] Train loss: 0.0259
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[019/030] Train loss: 0.0258
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:56:11 | Train | Epoch[185/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:56:12 | Train | Epoch[185/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:56:12 | Train | Epoch[185/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 11:56:12 | Train | Epoch[185/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 11:56:12 | Valid | Epoch[185/600] Iteration[001/008] Valid loss: 0.1130
2023-02-06 11:56:12 | Valid | Epoch[185/600] Iteration[002/008] Valid loss: 0.0841
2023-02-06 11:56:12 | Valid | Epoch[185/600] Iteration[003/008] Valid loss: 0.0860
2023-02-06 11:56:12 | Valid | Epoch[185/600] Iteration[004/008] Valid loss: 0.0789
2023-02-06 11:56:12 | Valid | Epoch[185/600] Iteration[005/008] Valid loss: 0.0778
2023-02-06 11:56:12 | Valid | Epoch[185/600] Iteration[006/008] Valid loss: 0.0752
2023-02-06 11:56:12 | Valid | Epoch[185/600] Iteration[007/008] Valid loss: 0.0754
2023-02-06 11:56:12 | Valid | Epoch[185/600] Iteration[008/008] Valid loss: 0.0715
2023-02-06 11:56:12 | Valid | Epoch[185/600] MIou: 0.9320175268686892
2023-02-06 11:56:12 | Valid | Epoch[185/600] Pixel Accuracy: 0.988501230875651
2023-02-06 11:56:12 | Valid | Epoch[185/600] Mean Pixel Accuracy: 0.9504631322522799
2023-02-06 11:56:12 | Stage | Epoch[185/600] Train loss:0.0253
2023-02-06 11:56:12 | Stage | Epoch[185/600] Valid loss:0.0715
2023-02-06 11:56:12 | Stage | Epoch[185/600] LR:0.01

2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[001/030] Train loss: 0.0226
2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[003/030] Train loss: 0.0250
2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[005/030] Train loss: 0.0257
2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 11:56:13 | Train | Epoch[186/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 11:56:14 | Train | Epoch[186/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 11:56:15 | Train | Epoch[186/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 11:56:15 | Train | Epoch[186/600] Iteration[027/030] Train loss: 0.0257
2023-02-06 11:56:15 | Train | Epoch[186/600] Iteration[028/030] Train loss: 0.0258
2023-02-06 11:56:15 | Train | Epoch[186/600] Iteration[029/030] Train loss: 0.0258
2023-02-06 11:56:15 | Train | Epoch[186/600] Iteration[030/030] Train loss: 0.0257
2023-02-06 11:56:15 | Valid | Epoch[186/600] Iteration[001/008] Valid loss: 0.0683
2023-02-06 11:56:15 | Valid | Epoch[186/600] Iteration[002/008] Valid loss: 0.0622
2023-02-06 11:56:15 | Valid | Epoch[186/600] Iteration[003/008] Valid loss: 0.0610
2023-02-06 11:56:15 | Valid | Epoch[186/600] Iteration[004/008] Valid loss: 0.0591
2023-02-06 11:56:15 | Valid | Epoch[186/600] Iteration[005/008] Valid loss: 0.0592
2023-02-06 11:56:15 | Valid | Epoch[186/600] Iteration[006/008] Valid loss: 0.0580
2023-02-06 11:56:15 | Valid | Epoch[186/600] Iteration[007/008] Valid loss: 0.0587
2023-02-06 11:56:15 | Valid | Epoch[186/600] Iteration[008/008] Valid loss: 0.0579
2023-02-06 11:56:15 | Valid | Epoch[186/600] MIou: 0.8786434969259211
2023-02-06 11:56:15 | Valid | Epoch[186/600] Pixel Accuracy: 0.9795735677083334
2023-02-06 11:56:15 | Valid | Epoch[186/600] Mean Pixel Accuracy: 0.8980659761944193
2023-02-06 11:56:15 | Stage | Epoch[186/600] Train loss:0.0257
2023-02-06 11:56:15 | Stage | Epoch[186/600] Valid loss:0.0579
2023-02-06 11:56:15 | Stage | Epoch[186/600] LR:0.01

2023-02-06 11:56:16 | Train | Epoch[187/600] Iteration[001/030] Train loss: 0.0254
2023-02-06 11:56:16 | Train | Epoch[187/600] Iteration[002/030] Train loss: 0.0271
2023-02-06 11:56:16 | Train | Epoch[187/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 11:56:16 | Train | Epoch[187/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 11:56:16 | Train | Epoch[187/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 11:56:16 | Train | Epoch[187/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 11:56:16 | Train | Epoch[187/600] Iteration[007/030] Train loss: 0.0254
2023-02-06 11:56:16 | Train | Epoch[187/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 11:56:16 | Train | Epoch[187/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 11:56:16 | Train | Epoch[187/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:56:17 | Train | Epoch[187/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 11:56:18 | Train | Epoch[187/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 11:56:18 | Train | Epoch[187/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:56:18 | Train | Epoch[187/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:56:18 | Train | Epoch[187/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:56:18 | Train | Epoch[187/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 11:56:18 | Train | Epoch[187/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:56:18 | Valid | Epoch[187/600] Iteration[001/008] Valid loss: 0.3410
2023-02-06 11:56:18 | Valid | Epoch[187/600] Iteration[002/008] Valid loss: 0.3214
2023-02-06 11:56:18 | Valid | Epoch[187/600] Iteration[003/008] Valid loss: 0.3089
2023-02-06 11:56:18 | Valid | Epoch[187/600] Iteration[004/008] Valid loss: 0.3087
2023-02-06 11:56:18 | Valid | Epoch[187/600] Iteration[005/008] Valid loss: 0.3138
2023-02-06 11:56:18 | Valid | Epoch[187/600] Iteration[006/008] Valid loss: 0.3047
2023-02-06 11:56:18 | Valid | Epoch[187/600] Iteration[007/008] Valid loss: 0.3216
2023-02-06 11:56:18 | Valid | Epoch[187/600] Iteration[008/008] Valid loss: 0.3272
2023-02-06 11:56:18 | Valid | Epoch[187/600] MIou: 0.9008381193591839
2023-02-06 11:56:18 | Valid | Epoch[187/600] Pixel Accuracy: 0.9808756510416666
2023-02-06 11:56:18 | Valid | Epoch[187/600] Mean Pixel Accuracy: 0.9815057885450356
2023-02-06 11:56:18 | Stage | Epoch[187/600] Train loss:0.0252
2023-02-06 11:56:18 | Stage | Epoch[187/600] Valid loss:0.3272
2023-02-06 11:56:18 | Stage | Epoch[187/600] LR:0.01

2023-02-06 11:56:19 | Train | Epoch[188/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 11:56:19 | Train | Epoch[188/600] Iteration[002/030] Train loss: 0.0246
2023-02-06 11:56:19 | Train | Epoch[188/600] Iteration[003/030] Train loss: 0.0242
2023-02-06 11:56:19 | Train | Epoch[188/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 11:56:19 | Train | Epoch[188/600] Iteration[005/030] Train loss: 0.0237
2023-02-06 11:56:19 | Train | Epoch[188/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 11:56:19 | Train | Epoch[188/600] Iteration[007/030] Train loss: 0.0240
2023-02-06 11:56:19 | Train | Epoch[188/600] Iteration[008/030] Train loss: 0.0241
2023-02-06 11:56:19 | Train | Epoch[188/600] Iteration[009/030] Train loss: 0.0241
2023-02-06 11:56:19 | Train | Epoch[188/600] Iteration[010/030] Train loss: 0.0239
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[011/030] Train loss: 0.0239
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[012/030] Train loss: 0.0238
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[013/030] Train loss: 0.0239
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[014/030] Train loss: 0.0239
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[015/030] Train loss: 0.0239
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[016/030] Train loss: 0.0240
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[017/030] Train loss: 0.0241
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[018/030] Train loss: 0.0244
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:56:20 | Train | Epoch[188/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:56:21 | Train | Epoch[188/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 11:56:21 | Train | Epoch[188/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 11:56:21 | Train | Epoch[188/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 11:56:21 | Train | Epoch[188/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 11:56:21 | Train | Epoch[188/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 11:56:21 | Train | Epoch[188/600] Iteration[030/030] Train loss: 0.0248
2023-02-06 11:56:21 | Valid | Epoch[188/600] Iteration[001/008] Valid loss: 0.0498
2023-02-06 11:56:21 | Valid | Epoch[188/600] Iteration[002/008] Valid loss: 0.0458
2023-02-06 11:56:21 | Valid | Epoch[188/600] Iteration[003/008] Valid loss: 0.0472
2023-02-06 11:56:21 | Valid | Epoch[188/600] Iteration[004/008] Valid loss: 0.0451
2023-02-06 11:56:21 | Valid | Epoch[188/600] Iteration[005/008] Valid loss: 0.0450
2023-02-06 11:56:21 | Valid | Epoch[188/600] Iteration[006/008] Valid loss: 0.0438
2023-02-06 11:56:21 | Valid | Epoch[188/600] Iteration[007/008] Valid loss: 0.0432
2023-02-06 11:56:21 | Valid | Epoch[188/600] Iteration[008/008] Valid loss: 0.0435
2023-02-06 11:56:22 | Valid | Epoch[188/600] MIou: 0.8769063864249159
2023-02-06 11:56:22 | Valid | Epoch[188/600] Pixel Accuracy: 0.9796498616536459
2023-02-06 11:56:22 | Valid | Epoch[188/600] Mean Pixel Accuracy: 0.8893897622715113
2023-02-06 11:56:22 | Stage | Epoch[188/600] Train loss:0.0248
2023-02-06 11:56:22 | Stage | Epoch[188/600] Valid loss:0.0435
2023-02-06 11:56:22 | Stage | Epoch[188/600] LR:0.01

2023-02-06 11:56:22 | Train | Epoch[189/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 11:56:22 | Train | Epoch[189/600] Iteration[002/030] Train loss: 0.0233
2023-02-06 11:56:22 | Train | Epoch[189/600] Iteration[003/030] Train loss: 0.0231
2023-02-06 11:56:22 | Train | Epoch[189/600] Iteration[004/030] Train loss: 0.0237
2023-02-06 11:56:22 | Train | Epoch[189/600] Iteration[005/030] Train loss: 0.0238
2023-02-06 11:56:22 | Train | Epoch[189/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 11:56:22 | Train | Epoch[189/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 11:56:22 | Train | Epoch[189/600] Iteration[008/030] Train loss: 0.0241
2023-02-06 11:56:22 | Train | Epoch[189/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 11:56:22 | Train | Epoch[189/600] Iteration[010/030] Train loss: 0.0239
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[012/030] Train loss: 0.0241
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[013/030] Train loss: 0.0242
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[014/030] Train loss: 0.0243
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[015/030] Train loss: 0.0243
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[017/030] Train loss: 0.0243
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[018/030] Train loss: 0.0242
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[019/030] Train loss: 0.0242
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[020/030] Train loss: 0.0245
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[021/030] Train loss: 0.0244
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[022/030] Train loss: 0.0244
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[023/030] Train loss: 0.0244
2023-02-06 11:56:23 | Train | Epoch[189/600] Iteration[024/030] Train loss: 0.0243
2023-02-06 11:56:24 | Train | Epoch[189/600] Iteration[025/030] Train loss: 0.0244
2023-02-06 11:56:24 | Train | Epoch[189/600] Iteration[026/030] Train loss: 0.0246
2023-02-06 11:56:24 | Train | Epoch[189/600] Iteration[027/030] Train loss: 0.0245
2023-02-06 11:56:24 | Train | Epoch[189/600] Iteration[028/030] Train loss: 0.0245
2023-02-06 11:56:24 | Train | Epoch[189/600] Iteration[029/030] Train loss: 0.0246
2023-02-06 11:56:24 | Train | Epoch[189/600] Iteration[030/030] Train loss: 0.0246
2023-02-06 11:56:24 | Valid | Epoch[189/600] Iteration[001/008] Valid loss: 0.0657
2023-02-06 11:56:24 | Valid | Epoch[189/600] Iteration[002/008] Valid loss: 0.0514
2023-02-06 11:56:24 | Valid | Epoch[189/600] Iteration[003/008] Valid loss: 0.0495
2023-02-06 11:56:24 | Valid | Epoch[189/600] Iteration[004/008] Valid loss: 0.0453
2023-02-06 11:56:24 | Valid | Epoch[189/600] Iteration[005/008] Valid loss: 0.0459
2023-02-06 11:56:24 | Valid | Epoch[189/600] Iteration[006/008] Valid loss: 0.0447
2023-02-06 11:56:24 | Valid | Epoch[189/600] Iteration[007/008] Valid loss: 0.0443
2023-02-06 11:56:24 | Valid | Epoch[189/600] Iteration[008/008] Valid loss: 0.0435
2023-02-06 11:56:24 | Valid | Epoch[189/600] MIou: 0.9134578939036115
2023-02-06 11:56:24 | Valid | Epoch[189/600] Pixel Accuracy: 0.9855422973632812
2023-02-06 11:56:24 | Valid | Epoch[189/600] Mean Pixel Accuracy: 0.9275771752184157
2023-02-06 11:56:24 | Stage | Epoch[189/600] Train loss:0.0246
2023-02-06 11:56:24 | Stage | Epoch[189/600] Valid loss:0.0435
2023-02-06 11:56:24 | Stage | Epoch[189/600] LR:0.01

2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[002/030] Train loss: 0.0212
2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[004/030] Train loss: 0.0227
2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[005/030] Train loss: 0.0236
2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[007/030] Train loss: 0.0238
2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[010/030] Train loss: 0.0245
2023-02-06 11:56:25 | Train | Epoch[190/600] Iteration[011/030] Train loss: 0.0244
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[013/030] Train loss: 0.0244
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[014/030] Train loss: 0.0243
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[017/030] Train loss: 0.0246
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[020/030] Train loss: 0.0246
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 11:56:26 | Train | Epoch[190/600] Iteration[025/030] Train loss: 0.0246
2023-02-06 11:56:27 | Train | Epoch[190/600] Iteration[026/030] Train loss: 0.0246
2023-02-06 11:56:27 | Train | Epoch[190/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 11:56:27 | Train | Epoch[190/600] Iteration[028/030] Train loss: 0.0246
2023-02-06 11:56:27 | Train | Epoch[190/600] Iteration[029/030] Train loss: 0.0245
2023-02-06 11:56:27 | Train | Epoch[190/600] Iteration[030/030] Train loss: 0.0246
2023-02-06 11:56:27 | Valid | Epoch[190/600] Iteration[001/008] Valid loss: 0.0533
2023-02-06 11:56:27 | Valid | Epoch[190/600] Iteration[002/008] Valid loss: 0.0544
2023-02-06 11:56:27 | Valid | Epoch[190/600] Iteration[003/008] Valid loss: 0.0508
2023-02-06 11:56:27 | Valid | Epoch[190/600] Iteration[004/008] Valid loss: 0.0493
2023-02-06 11:56:27 | Valid | Epoch[190/600] Iteration[005/008] Valid loss: 0.0493
2023-02-06 11:56:27 | Valid | Epoch[190/600] Iteration[006/008] Valid loss: 0.0485
2023-02-06 11:56:27 | Valid | Epoch[190/600] Iteration[007/008] Valid loss: 0.0491
2023-02-06 11:56:27 | Valid | Epoch[190/600] Iteration[008/008] Valid loss: 0.0496
2023-02-06 11:56:27 | Valid | Epoch[190/600] MIou: 0.8869535774452468
2023-02-06 11:56:27 | Valid | Epoch[190/600] Pixel Accuracy: 0.9808578491210938
2023-02-06 11:56:27 | Valid | Epoch[190/600] Mean Pixel Accuracy: 0.9083269626008541
2023-02-06 11:56:27 | Stage | Epoch[190/600] Train loss:0.0246
2023-02-06 11:56:27 | Stage | Epoch[190/600] Valid loss:0.0496
2023-02-06 11:56:27 | Stage | Epoch[190/600] LR:0.01

2023-02-06 11:56:28 | Train | Epoch[191/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 11:56:28 | Train | Epoch[191/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 11:56:28 | Train | Epoch[191/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:56:28 | Train | Epoch[191/600] Iteration[004/030] Train loss: 0.0229
2023-02-06 11:56:28 | Train | Epoch[191/600] Iteration[005/030] Train loss: 0.0229
2023-02-06 11:56:28 | Train | Epoch[191/600] Iteration[006/030] Train loss: 0.0229
2023-02-06 11:56:28 | Train | Epoch[191/600] Iteration[007/030] Train loss: 0.0234
2023-02-06 11:56:28 | Train | Epoch[191/600] Iteration[008/030] Train loss: 0.0237
2023-02-06 11:56:28 | Train | Epoch[191/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 11:56:28 | Train | Epoch[191/600] Iteration[010/030] Train loss: 0.0236
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[011/030] Train loss: 0.0237
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[012/030] Train loss: 0.0237
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[013/030] Train loss: 0.0235
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[014/030] Train loss: 0.0235
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[015/030] Train loss: 0.0234
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[016/030] Train loss: 0.0233
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[017/030] Train loss: 0.0235
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[018/030] Train loss: 0.0236
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[019/030] Train loss: 0.0236
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[020/030] Train loss: 0.0238
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[021/030] Train loss: 0.0238
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[022/030] Train loss: 0.0238
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[023/030] Train loss: 0.0239
2023-02-06 11:56:29 | Train | Epoch[191/600] Iteration[024/030] Train loss: 0.0241
2023-02-06 11:56:30 | Train | Epoch[191/600] Iteration[025/030] Train loss: 0.0240
2023-02-06 11:56:30 | Train | Epoch[191/600] Iteration[026/030] Train loss: 0.0240
2023-02-06 11:56:30 | Train | Epoch[191/600] Iteration[027/030] Train loss: 0.0241
2023-02-06 11:56:30 | Train | Epoch[191/600] Iteration[028/030] Train loss: 0.0241
2023-02-06 11:56:30 | Train | Epoch[191/600] Iteration[029/030] Train loss: 0.0241
2023-02-06 11:56:30 | Train | Epoch[191/600] Iteration[030/030] Train loss: 0.0241
2023-02-06 11:56:30 | Valid | Epoch[191/600] Iteration[001/008] Valid loss: 0.0762
2023-02-06 11:56:30 | Valid | Epoch[191/600] Iteration[002/008] Valid loss: 0.0682
2023-02-06 11:56:30 | Valid | Epoch[191/600] Iteration[003/008] Valid loss: 0.0662
2023-02-06 11:56:30 | Valid | Epoch[191/600] Iteration[004/008] Valid loss: 0.0631
2023-02-06 11:56:30 | Valid | Epoch[191/600] Iteration[005/008] Valid loss: 0.0607
2023-02-06 11:56:30 | Valid | Epoch[191/600] Iteration[006/008] Valid loss: 0.0597
2023-02-06 11:56:30 | Valid | Epoch[191/600] Iteration[007/008] Valid loss: 0.0616
2023-02-06 11:56:30 | Valid | Epoch[191/600] Iteration[008/008] Valid loss: 0.0601
2023-02-06 11:56:31 | Valid | Epoch[191/600] MIou: 0.9289819363778999
2023-02-06 11:56:31 | Valid | Epoch[191/600] Pixel Accuracy: 0.9878654479980469
2023-02-06 11:56:31 | Valid | Epoch[191/600] Mean Pixel Accuracy: 0.9521806725802027
2023-02-06 11:56:31 | Stage | Epoch[191/600] Train loss:0.0241
2023-02-06 11:56:31 | Stage | Epoch[191/600] Valid loss:0.0601
2023-02-06 11:56:31 | Stage | Epoch[191/600] LR:0.01

2023-02-06 11:56:31 | Train | Epoch[192/600] Iteration[001/030] Train loss: 0.0231
2023-02-06 11:56:31 | Train | Epoch[192/600] Iteration[002/030] Train loss: 0.0228
2023-02-06 11:56:31 | Train | Epoch[192/600] Iteration[003/030] Train loss: 0.0224
2023-02-06 11:56:31 | Train | Epoch[192/600] Iteration[004/030] Train loss: 0.0225
2023-02-06 11:56:31 | Train | Epoch[192/600] Iteration[005/030] Train loss: 0.0226
2023-02-06 11:56:31 | Train | Epoch[192/600] Iteration[006/030] Train loss: 0.0229
2023-02-06 11:56:31 | Train | Epoch[192/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:56:31 | Train | Epoch[192/600] Iteration[008/030] Train loss: 0.0231
2023-02-06 11:56:31 | Train | Epoch[192/600] Iteration[009/030] Train loss: 0.0234
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[010/030] Train loss: 0.0233
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[011/030] Train loss: 0.0233
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[012/030] Train loss: 0.0235
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[013/030] Train loss: 0.0236
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[014/030] Train loss: 0.0235
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[015/030] Train loss: 0.0236
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[016/030] Train loss: 0.0237
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[017/030] Train loss: 0.0238
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[018/030] Train loss: 0.0238
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[019/030] Train loss: 0.0238
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[020/030] Train loss: 0.0238
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[021/030] Train loss: 0.0243
2023-02-06 11:56:32 | Train | Epoch[192/600] Iteration[022/030] Train loss: 0.0244
2023-02-06 11:56:33 | Train | Epoch[192/600] Iteration[023/030] Train loss: 0.0245
2023-02-06 11:56:33 | Train | Epoch[192/600] Iteration[024/030] Train loss: 0.0245
2023-02-06 11:56:33 | Train | Epoch[192/600] Iteration[025/030] Train loss: 0.0245
2023-02-06 11:56:33 | Train | Epoch[192/600] Iteration[026/030] Train loss: 0.0245
2023-02-06 11:56:33 | Train | Epoch[192/600] Iteration[027/030] Train loss: 0.0244
2023-02-06 11:56:33 | Train | Epoch[192/600] Iteration[028/030] Train loss: 0.0244
2023-02-06 11:56:33 | Train | Epoch[192/600] Iteration[029/030] Train loss: 0.0245
2023-02-06 11:56:33 | Train | Epoch[192/600] Iteration[030/030] Train loss: 0.0246
2023-02-06 11:56:33 | Valid | Epoch[192/600] Iteration[001/008] Valid loss: 0.3916
2023-02-06 11:56:33 | Valid | Epoch[192/600] Iteration[002/008] Valid loss: 0.3419
2023-02-06 11:56:33 | Valid | Epoch[192/600] Iteration[003/008] Valid loss: 0.3341
2023-02-06 11:56:33 | Valid | Epoch[192/600] Iteration[004/008] Valid loss: 0.3371
2023-02-06 11:56:33 | Valid | Epoch[192/600] Iteration[005/008] Valid loss: 0.3435
2023-02-06 11:56:33 | Valid | Epoch[192/600] Iteration[006/008] Valid loss: 0.3367
2023-02-06 11:56:33 | Valid | Epoch[192/600] Iteration[007/008] Valid loss: 0.3577
2023-02-06 11:56:33 | Valid | Epoch[192/600] Iteration[008/008] Valid loss: 0.3528
2023-02-06 11:56:34 | Valid | Epoch[192/600] MIou: 0.9042971238971294
2023-02-06 11:56:34 | Valid | Epoch[192/600] Pixel Accuracy: 0.9815889994303385
2023-02-06 11:56:34 | Valid | Epoch[192/600] Mean Pixel Accuracy: 0.9839775498989847
2023-02-06 11:56:34 | Stage | Epoch[192/600] Train loss:0.0246
2023-02-06 11:56:34 | Stage | Epoch[192/600] Valid loss:0.3528
2023-02-06 11:56:34 | Stage | Epoch[192/600] LR:0.01

2023-02-06 11:56:34 | Train | Epoch[193/600] Iteration[001/030] Train loss: 0.0255
2023-02-06 11:56:34 | Train | Epoch[193/600] Iteration[002/030] Train loss: 0.0235
2023-02-06 11:56:34 | Train | Epoch[193/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 11:56:34 | Train | Epoch[193/600] Iteration[004/030] Train loss: 0.0243
2023-02-06 11:56:34 | Train | Epoch[193/600] Iteration[005/030] Train loss: 0.0239
2023-02-06 11:56:34 | Train | Epoch[193/600] Iteration[006/030] Train loss: 0.0241
2023-02-06 11:56:34 | Train | Epoch[193/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 11:56:34 | Train | Epoch[193/600] Iteration[008/030] Train loss: 0.0239
2023-02-06 11:56:34 | Train | Epoch[193/600] Iteration[009/030] Train loss: 0.0238
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[010/030] Train loss: 0.0236
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[011/030] Train loss: 0.0241
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[012/030] Train loss: 0.0241
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[013/030] Train loss: 0.0242
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[014/030] Train loss: 0.0241
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[015/030] Train loss: 0.0241
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[018/030] Train loss: 0.0243
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[019/030] Train loss: 0.0242
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[020/030] Train loss: 0.0243
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[021/030] Train loss: 0.0244
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[022/030] Train loss: 0.0242
2023-02-06 11:56:35 | Train | Epoch[193/600] Iteration[023/030] Train loss: 0.0241
2023-02-06 11:56:36 | Train | Epoch[193/600] Iteration[024/030] Train loss: 0.0242
2023-02-06 11:56:36 | Train | Epoch[193/600] Iteration[025/030] Train loss: 0.0242
2023-02-06 11:56:36 | Train | Epoch[193/600] Iteration[026/030] Train loss: 0.0241
2023-02-06 11:56:36 | Train | Epoch[193/600] Iteration[027/030] Train loss: 0.0241
2023-02-06 11:56:36 | Train | Epoch[193/600] Iteration[028/030] Train loss: 0.0243
2023-02-06 11:56:36 | Train | Epoch[193/600] Iteration[029/030] Train loss: 0.0242
2023-02-06 11:56:36 | Train | Epoch[193/600] Iteration[030/030] Train loss: 0.0242
2023-02-06 11:56:36 | Valid | Epoch[193/600] Iteration[001/008] Valid loss: 0.0975
2023-02-06 11:56:36 | Valid | Epoch[193/600] Iteration[002/008] Valid loss: 0.0973
2023-02-06 11:56:36 | Valid | Epoch[193/600] Iteration[003/008] Valid loss: 0.1017
2023-02-06 11:56:36 | Valid | Epoch[193/600] Iteration[004/008] Valid loss: 0.0996
2023-02-06 11:56:36 | Valid | Epoch[193/600] Iteration[005/008] Valid loss: 0.1017
2023-02-06 11:56:36 | Valid | Epoch[193/600] Iteration[006/008] Valid loss: 0.0996
2023-02-06 11:56:36 | Valid | Epoch[193/600] Iteration[007/008] Valid loss: 0.0977
2023-02-06 11:56:36 | Valid | Epoch[193/600] Iteration[008/008] Valid loss: 0.1010
2023-02-06 11:56:37 | Valid | Epoch[193/600] MIou: 0.688629613499435
2023-02-06 11:56:37 | Valid | Epoch[193/600] Pixel Accuracy: 0.9485867818196615
2023-02-06 11:56:37 | Valid | Epoch[193/600] Mean Pixel Accuracy: 0.7153768179194413
2023-02-06 11:56:37 | Stage | Epoch[193/600] Train loss:0.0242
2023-02-06 11:56:37 | Stage | Epoch[193/600] Valid loss:0.1010
2023-02-06 11:56:37 | Stage | Epoch[193/600] LR:0.01

2023-02-06 11:56:37 | Train | Epoch[194/600] Iteration[001/030] Train loss: 0.0274
2023-02-06 11:56:37 | Train | Epoch[194/600] Iteration[002/030] Train loss: 0.0249
2023-02-06 11:56:37 | Train | Epoch[194/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 11:56:37 | Train | Epoch[194/600] Iteration[004/030] Train loss: 0.0239
2023-02-06 11:56:37 | Train | Epoch[194/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 11:56:37 | Train | Epoch[194/600] Iteration[006/030] Train loss: 0.0239
2023-02-06 11:56:37 | Train | Epoch[194/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 11:56:37 | Train | Epoch[194/600] Iteration[008/030] Train loss: 0.0235
2023-02-06 11:56:37 | Train | Epoch[194/600] Iteration[009/030] Train loss: 0.0237
2023-02-06 11:56:37 | Train | Epoch[194/600] Iteration[010/030] Train loss: 0.0235
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[011/030] Train loss: 0.0233
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[012/030] Train loss: 0.0235
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[013/030] Train loss: 0.0237
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[014/030] Train loss: 0.0237
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[015/030] Train loss: 0.0237
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[016/030] Train loss: 0.0240
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[017/030] Train loss: 0.0240
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[018/030] Train loss: 0.0241
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[019/030] Train loss: 0.0241
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[020/030] Train loss: 0.0241
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[021/030] Train loss: 0.0242
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[022/030] Train loss: 0.0241
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[023/030] Train loss: 0.0239
2023-02-06 11:56:38 | Train | Epoch[194/600] Iteration[024/030] Train loss: 0.0240
2023-02-06 11:56:39 | Train | Epoch[194/600] Iteration[025/030] Train loss: 0.0240
2023-02-06 11:56:39 | Train | Epoch[194/600] Iteration[026/030] Train loss: 0.0240
2023-02-06 11:56:39 | Train | Epoch[194/600] Iteration[027/030] Train loss: 0.0240
2023-02-06 11:56:39 | Train | Epoch[194/600] Iteration[028/030] Train loss: 0.0242
2023-02-06 11:56:39 | Train | Epoch[194/600] Iteration[029/030] Train loss: 0.0243
2023-02-06 11:56:39 | Train | Epoch[194/600] Iteration[030/030] Train loss: 0.0243
2023-02-06 11:56:39 | Valid | Epoch[194/600] Iteration[001/008] Valid loss: 0.0486
2023-02-06 11:56:39 | Valid | Epoch[194/600] Iteration[002/008] Valid loss: 0.0450
2023-02-06 11:56:39 | Valid | Epoch[194/600] Iteration[003/008] Valid loss: 0.0444
2023-02-06 11:56:39 | Valid | Epoch[194/600] Iteration[004/008] Valid loss: 0.0427
2023-02-06 11:56:39 | Valid | Epoch[194/600] Iteration[005/008] Valid loss: 0.0423
2023-02-06 11:56:39 | Valid | Epoch[194/600] Iteration[006/008] Valid loss: 0.0422
2023-02-06 11:56:39 | Valid | Epoch[194/600] Iteration[007/008] Valid loss: 0.0425
2023-02-06 11:56:39 | Valid | Epoch[194/600] Iteration[008/008] Valid loss: 0.0425
2023-02-06 11:56:39 | Valid | Epoch[194/600] MIou: 0.8901153198148055
2023-02-06 11:56:39 | Valid | Epoch[194/600] Pixel Accuracy: 0.9817148844401041
2023-02-06 11:56:39 | Valid | Epoch[194/600] Mean Pixel Accuracy: 0.9042011839175967
2023-02-06 11:56:39 | Stage | Epoch[194/600] Train loss:0.0243
2023-02-06 11:56:39 | Stage | Epoch[194/600] Valid loss:0.0425
2023-02-06 11:56:39 | Stage | Epoch[194/600] LR:0.01

2023-02-06 11:56:40 | Train | Epoch[195/600] Iteration[001/030] Train loss: 0.0232
2023-02-06 11:56:40 | Train | Epoch[195/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 11:56:40 | Train | Epoch[195/600] Iteration[003/030] Train loss: 0.0239
2023-02-06 11:56:40 | Train | Epoch[195/600] Iteration[004/030] Train loss: 0.0238
2023-02-06 11:56:40 | Train | Epoch[195/600] Iteration[005/030] Train loss: 0.0234
2023-02-06 11:56:40 | Train | Epoch[195/600] Iteration[006/030] Train loss: 0.0235
2023-02-06 11:56:40 | Train | Epoch[195/600] Iteration[007/030] Train loss: 0.0236
2023-02-06 11:56:40 | Train | Epoch[195/600] Iteration[008/030] Train loss: 0.0236
2023-02-06 11:56:40 | Train | Epoch[195/600] Iteration[009/030] Train loss: 0.0234
2023-02-06 11:56:40 | Train | Epoch[195/600] Iteration[010/030] Train loss: 0.0234
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[011/030] Train loss: 0.0237
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[012/030] Train loss: 0.0240
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[014/030] Train loss: 0.0240
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[015/030] Train loss: 0.0240
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[017/030] Train loss: 0.0243
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[018/030] Train loss: 0.0242
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[019/030] Train loss: 0.0241
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[020/030] Train loss: 0.0241
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[021/030] Train loss: 0.0240
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[022/030] Train loss: 0.0241
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[023/030] Train loss: 0.0242
2023-02-06 11:56:41 | Train | Epoch[195/600] Iteration[024/030] Train loss: 0.0242
2023-02-06 11:56:42 | Train | Epoch[195/600] Iteration[025/030] Train loss: 0.0242
2023-02-06 11:56:42 | Train | Epoch[195/600] Iteration[026/030] Train loss: 0.0241
2023-02-06 11:56:42 | Train | Epoch[195/600] Iteration[027/030] Train loss: 0.0241
2023-02-06 11:56:42 | Train | Epoch[195/600] Iteration[028/030] Train loss: 0.0241
2023-02-06 11:56:42 | Train | Epoch[195/600] Iteration[029/030] Train loss: 0.0240
2023-02-06 11:56:42 | Train | Epoch[195/600] Iteration[030/030] Train loss: 0.0241
2023-02-06 11:56:42 | Valid | Epoch[195/600] Iteration[001/008] Valid loss: 0.1935
2023-02-06 11:56:42 | Valid | Epoch[195/600] Iteration[002/008] Valid loss: 0.2026
2023-02-06 11:56:42 | Valid | Epoch[195/600] Iteration[003/008] Valid loss: 0.1825
2023-02-06 11:56:42 | Valid | Epoch[195/600] Iteration[004/008] Valid loss: 0.1792
2023-02-06 11:56:42 | Valid | Epoch[195/600] Iteration[005/008] Valid loss: 0.1842
2023-02-06 11:56:42 | Valid | Epoch[195/600] Iteration[006/008] Valid loss: 0.1819
2023-02-06 11:56:42 | Valid | Epoch[195/600] Iteration[007/008] Valid loss: 0.1870
2023-02-06 11:56:42 | Valid | Epoch[195/600] Iteration[008/008] Valid loss: 0.1930
2023-02-06 11:56:42 | Valid | Epoch[195/600] MIou: 0.9051695158982266
2023-02-06 11:56:42 | Valid | Epoch[195/600] Pixel Accuracy: 0.9824485778808594
2023-02-06 11:56:42 | Valid | Epoch[195/600] Mean Pixel Accuracy: 0.9658660888736192
2023-02-06 11:56:42 | Stage | Epoch[195/600] Train loss:0.0241
2023-02-06 11:56:42 | Stage | Epoch[195/600] Valid loss:0.1930
2023-02-06 11:56:42 | Stage | Epoch[195/600] LR:0.01

2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[001/030] Train loss: 0.0223
2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[004/030] Train loss: 0.0245
2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[005/030] Train loss: 0.0237
2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[008/030] Train loss: 0.0241
2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[010/030] Train loss: 0.0240
2023-02-06 11:56:43 | Train | Epoch[196/600] Iteration[011/030] Train loss: 0.0241
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[012/030] Train loss: 0.0240
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[013/030] Train loss: 0.0238
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[014/030] Train loss: 0.0237
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[015/030] Train loss: 0.0238
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[016/030] Train loss: 0.0239
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[018/030] Train loss: 0.0240
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[019/030] Train loss: 0.0240
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[020/030] Train loss: 0.0239
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[021/030] Train loss: 0.0240
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[022/030] Train loss: 0.0238
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[023/030] Train loss: 0.0239
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[024/030] Train loss: 0.0238
2023-02-06 11:56:44 | Train | Epoch[196/600] Iteration[025/030] Train loss: 0.0239
2023-02-06 11:56:45 | Train | Epoch[196/600] Iteration[026/030] Train loss: 0.0240
2023-02-06 11:56:45 | Train | Epoch[196/600] Iteration[027/030] Train loss: 0.0241
2023-02-06 11:56:45 | Train | Epoch[196/600] Iteration[028/030] Train loss: 0.0241
2023-02-06 11:56:45 | Train | Epoch[196/600] Iteration[029/030] Train loss: 0.0240
2023-02-06 11:56:45 | Train | Epoch[196/600] Iteration[030/030] Train loss: 0.0240
2023-02-06 11:56:45 | Valid | Epoch[196/600] Iteration[001/008] Valid loss: 0.1123
2023-02-06 11:56:45 | Valid | Epoch[196/600] Iteration[002/008] Valid loss: 0.0834
2023-02-06 11:56:45 | Valid | Epoch[196/600] Iteration[003/008] Valid loss: 0.0823
2023-02-06 11:56:45 | Valid | Epoch[196/600] Iteration[004/008] Valid loss: 0.0819
2023-02-06 11:56:45 | Valid | Epoch[196/600] Iteration[005/008] Valid loss: 0.0791
2023-02-06 11:56:45 | Valid | Epoch[196/600] Iteration[006/008] Valid loss: 0.0757
2023-02-06 11:56:45 | Valid | Epoch[196/600] Iteration[007/008] Valid loss: 0.0828
2023-02-06 11:56:45 | Valid | Epoch[196/600] Iteration[008/008] Valid loss: 0.0791
2023-02-06 11:56:45 | Valid | Epoch[196/600] MIou: 0.9324479818609839
2023-02-06 11:56:45 | Valid | Epoch[196/600] Pixel Accuracy: 0.988335927327474
2023-02-06 11:56:45 | Valid | Epoch[196/600] Mean Pixel Accuracy: 0.9603394955891653
2023-02-06 11:56:45 | Stage | Epoch[196/600] Train loss:0.0240
2023-02-06 11:56:45 | Stage | Epoch[196/600] Valid loss:0.0791
2023-02-06 11:56:45 | Stage | Epoch[196/600] LR:0.01

2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[002/030] Train loss: 0.0219
2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[003/030] Train loss: 0.0217
2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[004/030] Train loss: 0.0220
2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[005/030] Train loss: 0.0218
2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[006/030] Train loss: 0.0218
2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[007/030] Train loss: 0.0226
2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[008/030] Train loss: 0.0228
2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[009/030] Train loss: 0.0226
2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[010/030] Train loss: 0.0226
2023-02-06 11:56:46 | Train | Epoch[197/600] Iteration[011/030] Train loss: 0.0229
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[012/030] Train loss: 0.0230
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[013/030] Train loss: 0.0231
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[014/030] Train loss: 0.0233
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[015/030] Train loss: 0.0233
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[016/030] Train loss: 0.0233
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[017/030] Train loss: 0.0233
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[018/030] Train loss: 0.0232
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[019/030] Train loss: 0.0231
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[020/030] Train loss: 0.0232
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[021/030] Train loss: 0.0232
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[022/030] Train loss: 0.0234
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[023/030] Train loss: 0.0235
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[024/030] Train loss: 0.0237
2023-02-06 11:56:47 | Train | Epoch[197/600] Iteration[025/030] Train loss: 0.0238
2023-02-06 11:56:48 | Train | Epoch[197/600] Iteration[026/030] Train loss: 0.0237
2023-02-06 11:56:48 | Train | Epoch[197/600] Iteration[027/030] Train loss: 0.0238
2023-02-06 11:56:48 | Train | Epoch[197/600] Iteration[028/030] Train loss: 0.0238
2023-02-06 11:56:48 | Train | Epoch[197/600] Iteration[029/030] Train loss: 0.0239
2023-02-06 11:56:48 | Train | Epoch[197/600] Iteration[030/030] Train loss: 0.0238
2023-02-06 11:56:48 | Valid | Epoch[197/600] Iteration[001/008] Valid loss: 0.2490
2023-02-06 11:56:48 | Valid | Epoch[197/600] Iteration[002/008] Valid loss: 0.1902
2023-02-06 11:56:48 | Valid | Epoch[197/600] Iteration[003/008] Valid loss: 0.1871
2023-02-06 11:56:48 | Valid | Epoch[197/600] Iteration[004/008] Valid loss: 0.1829
2023-02-06 11:56:48 | Valid | Epoch[197/600] Iteration[005/008] Valid loss: 0.1880
2023-02-06 11:56:48 | Valid | Epoch[197/600] Iteration[006/008] Valid loss: 0.1818
2023-02-06 11:56:48 | Valid | Epoch[197/600] Iteration[007/008] Valid loss: 0.1917
2023-02-06 11:56:48 | Valid | Epoch[197/600] Iteration[008/008] Valid loss: 0.1843
2023-02-06 11:56:49 | Valid | Epoch[197/600] MIou: 0.9317960218000163
2023-02-06 11:56:49 | Valid | Epoch[197/600] Pixel Accuracy: 0.9877039591471354
2023-02-06 11:56:49 | Valid | Epoch[197/600] Mean Pixel Accuracy: 0.9803323715352124
2023-02-06 11:56:49 | Stage | Epoch[197/600] Train loss:0.0238
2023-02-06 11:56:49 | Stage | Epoch[197/600] Valid loss:0.1843
2023-02-06 11:56:49 | Stage | Epoch[197/600] LR:0.01

2023-02-06 11:56:49 | Train | Epoch[198/600] Iteration[001/030] Train loss: 0.0235
2023-02-06 11:56:49 | Train | Epoch[198/600] Iteration[002/030] Train loss: 0.0244
2023-02-06 11:56:49 | Train | Epoch[198/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 11:56:49 | Train | Epoch[198/600] Iteration[004/030] Train loss: 0.0236
2023-02-06 11:56:49 | Train | Epoch[198/600] Iteration[005/030] Train loss: 0.0232
2023-02-06 11:56:49 | Train | Epoch[198/600] Iteration[006/030] Train loss: 0.0229
2023-02-06 11:56:49 | Train | Epoch[198/600] Iteration[007/030] Train loss: 0.0233
2023-02-06 11:56:49 | Train | Epoch[198/600] Iteration[008/030] Train loss: 0.0233
2023-02-06 11:56:49 | Train | Epoch[198/600] Iteration[009/030] Train loss: 0.0235
2023-02-06 11:56:49 | Train | Epoch[198/600] Iteration[010/030] Train loss: 0.0234
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[011/030] Train loss: 0.0237
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[012/030] Train loss: 0.0236
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[013/030] Train loss: 0.0237
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[014/030] Train loss: 0.0236
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[015/030] Train loss: 0.0235
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[016/030] Train loss: 0.0236
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[017/030] Train loss: 0.0237
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[018/030] Train loss: 0.0236
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[019/030] Train loss: 0.0236
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[020/030] Train loss: 0.0238
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[021/030] Train loss: 0.0237
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[022/030] Train loss: 0.0237
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[023/030] Train loss: 0.0237
2023-02-06 11:56:50 | Train | Epoch[198/600] Iteration[024/030] Train loss: 0.0236
2023-02-06 11:56:51 | Train | Epoch[198/600] Iteration[025/030] Train loss: 0.0237
2023-02-06 11:56:51 | Train | Epoch[198/600] Iteration[026/030] Train loss: 0.0237
2023-02-06 11:56:51 | Train | Epoch[198/600] Iteration[027/030] Train loss: 0.0236
2023-02-06 11:56:51 | Train | Epoch[198/600] Iteration[028/030] Train loss: 0.0237
2023-02-06 11:56:51 | Train | Epoch[198/600] Iteration[029/030] Train loss: 0.0237
2023-02-06 11:56:51 | Train | Epoch[198/600] Iteration[030/030] Train loss: 0.0237
2023-02-06 11:56:51 | Valid | Epoch[198/600] Iteration[001/008] Valid loss: 0.1999
2023-02-06 11:56:51 | Valid | Epoch[198/600] Iteration[002/008] Valid loss: 0.1462
2023-02-06 11:56:51 | Valid | Epoch[198/600] Iteration[003/008] Valid loss: 0.1391
2023-02-06 11:56:51 | Valid | Epoch[198/600] Iteration[004/008] Valid loss: 0.1375
2023-02-06 11:56:51 | Valid | Epoch[198/600] Iteration[005/008] Valid loss: 0.1400
2023-02-06 11:56:51 | Valid | Epoch[198/600] Iteration[006/008] Valid loss: 0.1331
2023-02-06 11:56:51 | Valid | Epoch[198/600] Iteration[007/008] Valid loss: 0.1469
2023-02-06 11:56:51 | Valid | Epoch[198/600] Iteration[008/008] Valid loss: 0.1462
2023-02-06 11:56:52 | Valid | Epoch[198/600] MIou: 0.9277749545618292
2023-02-06 11:56:52 | Valid | Epoch[198/600] Pixel Accuracy: 0.986932118733724
2023-02-06 11:56:52 | Valid | Epoch[198/600] Mean Pixel Accuracy: 0.9780313555582283
2023-02-06 11:56:52 | Stage | Epoch[198/600] Train loss:0.0237
2023-02-06 11:56:52 | Stage | Epoch[198/600] Valid loss:0.1462
2023-02-06 11:56:52 | Stage | Epoch[198/600] LR:0.01

2023-02-06 11:56:52 | Train | Epoch[199/600] Iteration[001/030] Train loss: 0.0299
2023-02-06 11:56:52 | Train | Epoch[199/600] Iteration[002/030] Train loss: 0.0259
2023-02-06 11:56:52 | Train | Epoch[199/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 11:56:52 | Train | Epoch[199/600] Iteration[004/030] Train loss: 0.0250
2023-02-06 11:56:52 | Train | Epoch[199/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 11:56:52 | Train | Epoch[199/600] Iteration[006/030] Train loss: 0.0246
2023-02-06 11:56:52 | Train | Epoch[199/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 11:56:52 | Train | Epoch[199/600] Iteration[008/030] Train loss: 0.0247
2023-02-06 11:56:52 | Train | Epoch[199/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 11:56:52 | Train | Epoch[199/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[011/030] Train loss: 0.0239
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[012/030] Train loss: 0.0239
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[013/030] Train loss: 0.0240
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[014/030] Train loss: 0.0243
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[015/030] Train loss: 0.0242
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[017/030] Train loss: 0.0243
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[018/030] Train loss: 0.0244
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[019/030] Train loss: 0.0243
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[020/030] Train loss: 0.0242
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[021/030] Train loss: 0.0243
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[022/030] Train loss: 0.0243
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[023/030] Train loss: 0.0242
2023-02-06 11:56:53 | Train | Epoch[199/600] Iteration[024/030] Train loss: 0.0243
2023-02-06 11:56:54 | Train | Epoch[199/600] Iteration[025/030] Train loss: 0.0243
2023-02-06 11:56:54 | Train | Epoch[199/600] Iteration[026/030] Train loss: 0.0242
2023-02-06 11:56:54 | Train | Epoch[199/600] Iteration[027/030] Train loss: 0.0242
2023-02-06 11:56:54 | Train | Epoch[199/600] Iteration[028/030] Train loss: 0.0242
2023-02-06 11:56:54 | Train | Epoch[199/600] Iteration[029/030] Train loss: 0.0242
2023-02-06 11:56:54 | Train | Epoch[199/600] Iteration[030/030] Train loss: 0.0241
2023-02-06 11:56:54 | Valid | Epoch[199/600] Iteration[001/008] Valid loss: 0.0625
2023-02-06 11:56:54 | Valid | Epoch[199/600] Iteration[002/008] Valid loss: 0.0479
2023-02-06 11:56:54 | Valid | Epoch[199/600] Iteration[003/008] Valid loss: 0.0452
2023-02-06 11:56:54 | Valid | Epoch[199/600] Iteration[004/008] Valid loss: 0.0423
2023-02-06 11:56:54 | Valid | Epoch[199/600] Iteration[005/008] Valid loss: 0.0418
2023-02-06 11:56:54 | Valid | Epoch[199/600] Iteration[006/008] Valid loss: 0.0402
2023-02-06 11:56:54 | Valid | Epoch[199/600] Iteration[007/008] Valid loss: 0.0408
2023-02-06 11:56:54 | Valid | Epoch[199/600] Iteration[008/008] Valid loss: 0.0399
2023-02-06 11:56:55 | Valid | Epoch[199/600] MIou: 0.9236132874032442
2023-02-06 11:56:55 | Valid | Epoch[199/600] Pixel Accuracy: 0.9872182210286459
2023-02-06 11:56:55 | Valid | Epoch[199/600] Mean Pixel Accuracy: 0.9377617632204642
2023-02-06 11:56:55 | Stage | Epoch[199/600] Train loss:0.0241
2023-02-06 11:56:55 | Stage | Epoch[199/600] Valid loss:0.0399
2023-02-06 11:56:55 | Stage | Epoch[199/600] LR:0.01

2023-02-06 11:56:55 | Train | Epoch[200/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 11:56:55 | Train | Epoch[200/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 11:56:55 | Train | Epoch[200/600] Iteration[003/030] Train loss: 0.0218
2023-02-06 11:56:55 | Train | Epoch[200/600] Iteration[004/030] Train loss: 0.0223
2023-02-06 11:56:55 | Train | Epoch[200/600] Iteration[005/030] Train loss: 0.0236
2023-02-06 11:56:55 | Train | Epoch[200/600] Iteration[006/030] Train loss: 0.0236
2023-02-06 11:56:55 | Train | Epoch[200/600] Iteration[007/030] Train loss: 0.0233
2023-02-06 11:56:55 | Train | Epoch[200/600] Iteration[008/030] Train loss: 0.0235
2023-02-06 11:56:55 | Train | Epoch[200/600] Iteration[009/030] Train loss: 0.0233
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[010/030] Train loss: 0.0235
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[011/030] Train loss: 0.0239
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[012/030] Train loss: 0.0237
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[013/030] Train loss: 0.0234
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[014/030] Train loss: 0.0234
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[015/030] Train loss: 0.0234
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[016/030] Train loss: 0.0234
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[017/030] Train loss: 0.0236
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[018/030] Train loss: 0.0237
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[019/030] Train loss: 0.0238
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[020/030] Train loss: 0.0237
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[021/030] Train loss: 0.0236
2023-02-06 11:56:56 | Train | Epoch[200/600] Iteration[022/030] Train loss: 0.0237
2023-02-06 11:56:57 | Train | Epoch[200/600] Iteration[023/030] Train loss: 0.0237
2023-02-06 11:56:57 | Train | Epoch[200/600] Iteration[024/030] Train loss: 0.0238
2023-02-06 11:56:57 | Train | Epoch[200/600] Iteration[025/030] Train loss: 0.0237
2023-02-06 11:56:57 | Train | Epoch[200/600] Iteration[026/030] Train loss: 0.0237
2023-02-06 11:56:57 | Train | Epoch[200/600] Iteration[027/030] Train loss: 0.0237
2023-02-06 11:56:57 | Train | Epoch[200/600] Iteration[028/030] Train loss: 0.0236
2023-02-06 11:56:57 | Train | Epoch[200/600] Iteration[029/030] Train loss: 0.0237
2023-02-06 11:56:57 | Train | Epoch[200/600] Iteration[030/030] Train loss: 0.0237
2023-02-06 11:56:57 | Valid | Epoch[200/600] Iteration[001/008] Valid loss: 0.0687
2023-02-06 11:56:57 | Valid | Epoch[200/600] Iteration[002/008] Valid loss: 0.0515
2023-02-06 11:56:57 | Valid | Epoch[200/600] Iteration[003/008] Valid loss: 0.0475
2023-02-06 11:56:57 | Valid | Epoch[200/600] Iteration[004/008] Valid loss: 0.0441
2023-02-06 11:56:57 | Valid | Epoch[200/600] Iteration[005/008] Valid loss: 0.0429
2023-02-06 11:56:57 | Valid | Epoch[200/600] Iteration[006/008] Valid loss: 0.0412
2023-02-06 11:56:57 | Valid | Epoch[200/600] Iteration[007/008] Valid loss: 0.0422
2023-02-06 11:56:57 | Valid | Epoch[200/600] Iteration[008/008] Valid loss: 0.0412
2023-02-06 11:56:58 | Valid | Epoch[200/600] MIou: 0.9220143166709496
2023-02-06 11:56:58 | Valid | Epoch[200/600] Pixel Accuracy: 0.986975351969401
2023-02-06 11:56:58 | Valid | Epoch[200/600] Mean Pixel Accuracy: 0.9354408093557209
2023-02-06 11:56:58 | Stage | Epoch[200/600] Train loss:0.0237
2023-02-06 11:56:58 | Stage | Epoch[200/600] Valid loss:0.0412
2023-02-06 11:56:58 | Stage | Epoch[200/600] LR:0.01

2023-02-06 11:56:58 | Train | Epoch[201/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 11:56:58 | Train | Epoch[201/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:56:58 | Train | Epoch[201/600] Iteration[003/030] Train loss: 0.0224
2023-02-06 11:56:58 | Train | Epoch[201/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:56:58 | Train | Epoch[201/600] Iteration[005/030] Train loss: 0.0220
2023-02-06 11:56:58 | Train | Epoch[201/600] Iteration[006/030] Train loss: 0.0219
2023-02-06 11:56:58 | Train | Epoch[201/600] Iteration[007/030] Train loss: 0.0226
2023-02-06 11:56:58 | Train | Epoch[201/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:56:58 | Train | Epoch[201/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[010/030] Train loss: 0.0232
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[011/030] Train loss: 0.0232
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[012/030] Train loss: 0.0233
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[013/030] Train loss: 0.0231
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[014/030] Train loss: 0.0230
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[015/030] Train loss: 0.0230
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[016/030] Train loss: 0.0231
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[017/030] Train loss: 0.0232
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[018/030] Train loss: 0.0232
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[019/030] Train loss: 0.0232
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[020/030] Train loss: 0.0234
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[021/030] Train loss: 0.0234
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[022/030] Train loss: 0.0234
2023-02-06 11:56:59 | Train | Epoch[201/600] Iteration[023/030] Train loss: 0.0233
2023-02-06 11:57:00 | Train | Epoch[201/600] Iteration[024/030] Train loss: 0.0233
2023-02-06 11:57:00 | Train | Epoch[201/600] Iteration[025/030] Train loss: 0.0233
2023-02-06 11:57:00 | Train | Epoch[201/600] Iteration[026/030] Train loss: 0.0234
2023-02-06 11:57:00 | Train | Epoch[201/600] Iteration[027/030] Train loss: 0.0234
2023-02-06 11:57:00 | Train | Epoch[201/600] Iteration[028/030] Train loss: 0.0234
2023-02-06 11:57:00 | Train | Epoch[201/600] Iteration[029/030] Train loss: 0.0235
2023-02-06 11:57:00 | Train | Epoch[201/600] Iteration[030/030] Train loss: 0.0236
2023-02-06 11:57:00 | Valid | Epoch[201/600] Iteration[001/008] Valid loss: 0.3164
2023-02-06 11:57:00 | Valid | Epoch[201/600] Iteration[002/008] Valid loss: 0.3220
2023-02-06 11:57:00 | Valid | Epoch[201/600] Iteration[003/008] Valid loss: 0.3445
2023-02-06 11:57:00 | Valid | Epoch[201/600] Iteration[004/008] Valid loss: 0.3452
2023-02-06 11:57:00 | Valid | Epoch[201/600] Iteration[005/008] Valid loss: 0.3582
2023-02-06 11:57:00 | Valid | Epoch[201/600] Iteration[006/008] Valid loss: 0.3531
2023-02-06 11:57:00 | Valid | Epoch[201/600] Iteration[007/008] Valid loss: 0.3520
2023-02-06 11:57:00 | Valid | Epoch[201/600] Iteration[008/008] Valid loss: 0.3667
2023-02-06 11:57:01 | Valid | Epoch[201/600] MIou: 0.4565321521870969
2023-02-06 11:57:01 | Valid | Epoch[201/600] Pixel Accuracy: 0.9099642435709635
2023-02-06 11:57:01 | Valid | Epoch[201/600] Mean Pixel Accuracy: 0.5015627419786285
2023-02-06 11:57:01 | Stage | Epoch[201/600] Train loss:0.0236
2023-02-06 11:57:01 | Stage | Epoch[201/600] Valid loss:0.3667
2023-02-06 11:57:01 | Stage | Epoch[201/600] LR:0.01

2023-02-06 11:57:01 | Train | Epoch[202/600] Iteration[001/030] Train loss: 0.0219
2023-02-06 11:57:01 | Train | Epoch[202/600] Iteration[002/030] Train loss: 0.0227
2023-02-06 11:57:01 | Train | Epoch[202/600] Iteration[003/030] Train loss: 0.0231
2023-02-06 11:57:01 | Train | Epoch[202/600] Iteration[004/030] Train loss: 0.0228
2023-02-06 11:57:01 | Train | Epoch[202/600] Iteration[005/030] Train loss: 0.0235
2023-02-06 11:57:01 | Train | Epoch[202/600] Iteration[006/030] Train loss: 0.0236
2023-02-06 11:57:01 | Train | Epoch[202/600] Iteration[007/030] Train loss: 0.0233
2023-02-06 11:57:01 | Train | Epoch[202/600] Iteration[008/030] Train loss: 0.0238
2023-02-06 11:57:01 | Train | Epoch[202/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 11:57:01 | Train | Epoch[202/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[011/030] Train loss: 0.0238
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[012/030] Train loss: 0.0237
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[013/030] Train loss: 0.0237
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[014/030] Train loss: 0.0235
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[015/030] Train loss: 0.0241
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[016/030] Train loss: 0.0241
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[017/030] Train loss: 0.0240
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[018/030] Train loss: 0.0239
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[019/030] Train loss: 0.0239
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[020/030] Train loss: 0.0240
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[021/030] Train loss: 0.0241
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[022/030] Train loss: 0.0240
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[023/030] Train loss: 0.0239
2023-02-06 11:57:02 | Train | Epoch[202/600] Iteration[024/030] Train loss: 0.0241
2023-02-06 11:57:03 | Train | Epoch[202/600] Iteration[025/030] Train loss: 0.0241
2023-02-06 11:57:03 | Train | Epoch[202/600] Iteration[026/030] Train loss: 0.0240
2023-02-06 11:57:03 | Train | Epoch[202/600] Iteration[027/030] Train loss: 0.0240
2023-02-06 11:57:03 | Train | Epoch[202/600] Iteration[028/030] Train loss: 0.0240
2023-02-06 11:57:03 | Train | Epoch[202/600] Iteration[029/030] Train loss: 0.0239
2023-02-06 11:57:03 | Train | Epoch[202/600] Iteration[030/030] Train loss: 0.0239
2023-02-06 11:57:03 | Valid | Epoch[202/600] Iteration[001/008] Valid loss: 0.1279
2023-02-06 11:57:03 | Valid | Epoch[202/600] Iteration[002/008] Valid loss: 0.1328
2023-02-06 11:57:03 | Valid | Epoch[202/600] Iteration[003/008] Valid loss: 0.1416
2023-02-06 11:57:03 | Valid | Epoch[202/600] Iteration[004/008] Valid loss: 0.1391
2023-02-06 11:57:03 | Valid | Epoch[202/600] Iteration[005/008] Valid loss: 0.1433
2023-02-06 11:57:03 | Valid | Epoch[202/600] Iteration[006/008] Valid loss: 0.1404
2023-02-06 11:57:03 | Valid | Epoch[202/600] Iteration[007/008] Valid loss: 0.1380
2023-02-06 11:57:03 | Valid | Epoch[202/600] Iteration[008/008] Valid loss: 0.1441
2023-02-06 11:57:03 | Valid | Epoch[202/600] MIou: 0.570131483084961
2023-02-06 11:57:03 | Valid | Epoch[202/600] Pixel Accuracy: 0.9288978576660156
2023-02-06 11:57:03 | Valid | Epoch[202/600] Mean Pixel Accuracy: 0.6063790845992482
2023-02-06 11:57:03 | Stage | Epoch[202/600] Train loss:0.0239
2023-02-06 11:57:03 | Stage | Epoch[202/600] Valid loss:0.1441
2023-02-06 11:57:03 | Stage | Epoch[202/600] LR:0.01

2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[001/030] Train loss: 0.0235
2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[002/030] Train loss: 0.0247
2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[003/030] Train loss: 0.0240
2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[005/030] Train loss: 0.0239
2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[006/030] Train loss: 0.0237
2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[007/030] Train loss: 0.0241
2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[008/030] Train loss: 0.0238
2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[009/030] Train loss: 0.0237
2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[010/030] Train loss: 0.0236
2023-02-06 11:57:04 | Train | Epoch[203/600] Iteration[011/030] Train loss: 0.0235
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[012/030] Train loss: 0.0237
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[013/030] Train loss: 0.0237
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[014/030] Train loss: 0.0237
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[015/030] Train loss: 0.0236
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[016/030] Train loss: 0.0236
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[017/030] Train loss: 0.0235
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[018/030] Train loss: 0.0236
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[019/030] Train loss: 0.0236
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[020/030] Train loss: 0.0235
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[021/030] Train loss: 0.0235
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[022/030] Train loss: 0.0236
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[023/030] Train loss: 0.0235
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[024/030] Train loss: 0.0234
2023-02-06 11:57:05 | Train | Epoch[203/600] Iteration[025/030] Train loss: 0.0234
2023-02-06 11:57:06 | Train | Epoch[203/600] Iteration[026/030] Train loss: 0.0235
2023-02-06 11:57:06 | Train | Epoch[203/600] Iteration[027/030] Train loss: 0.0236
2023-02-06 11:57:06 | Train | Epoch[203/600] Iteration[028/030] Train loss: 0.0235
2023-02-06 11:57:06 | Train | Epoch[203/600] Iteration[029/030] Train loss: 0.0235
2023-02-06 11:57:06 | Train | Epoch[203/600] Iteration[030/030] Train loss: 0.0234
2023-02-06 11:57:06 | Valid | Epoch[203/600] Iteration[001/008] Valid loss: 0.0658
2023-02-06 11:57:06 | Valid | Epoch[203/600] Iteration[002/008] Valid loss: 0.0494
2023-02-06 11:57:06 | Valid | Epoch[203/600] Iteration[003/008] Valid loss: 0.0479
2023-02-06 11:57:06 | Valid | Epoch[203/600] Iteration[004/008] Valid loss: 0.0444
2023-02-06 11:57:06 | Valid | Epoch[203/600] Iteration[005/008] Valid loss: 0.0430
2023-02-06 11:57:06 | Valid | Epoch[203/600] Iteration[006/008] Valid loss: 0.0416
2023-02-06 11:57:06 | Valid | Epoch[203/600] Iteration[007/008] Valid loss: 0.0429
2023-02-06 11:57:06 | Valid | Epoch[203/600] Iteration[008/008] Valid loss: 0.0418
2023-02-06 11:57:06 | Valid | Epoch[203/600] MIou: 0.9270698585955923
2023-02-06 11:57:06 | Valid | Epoch[203/600] Pixel Accuracy: 0.9877573649088541
2023-02-06 11:57:06 | Valid | Epoch[203/600] Mean Pixel Accuracy: 0.9424140036197559
2023-02-06 11:57:06 | Stage | Epoch[203/600] Train loss:0.0234
2023-02-06 11:57:06 | Stage | Epoch[203/600] Valid loss:0.0418
2023-02-06 11:57:06 | Stage | Epoch[203/600] LR:0.01

2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[001/030] Train loss: 0.0268
2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[003/030] Train loss: 0.0239
2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[004/030] Train loss: 0.0233
2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[006/030] Train loss: 0.0223
2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[007/030] Train loss: 0.0225
2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[008/030] Train loss: 0.0227
2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[009/030] Train loss: 0.0230
2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[010/030] Train loss: 0.0229
2023-02-06 11:57:07 | Train | Epoch[204/600] Iteration[011/030] Train loss: 0.0229
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[012/030] Train loss: 0.0229
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[014/030] Train loss: 0.0229
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[015/030] Train loss: 0.0228
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[016/030] Train loss: 0.0228
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[017/030] Train loss: 0.0228
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[018/030] Train loss: 0.0228
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[019/030] Train loss: 0.0228
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[020/030] Train loss: 0.0229
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[021/030] Train loss: 0.0229
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[022/030] Train loss: 0.0230
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[023/030] Train loss: 0.0231
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[024/030] Train loss: 0.0230
2023-02-06 11:57:08 | Train | Epoch[204/600] Iteration[025/030] Train loss: 0.0232
2023-02-06 11:57:09 | Train | Epoch[204/600] Iteration[026/030] Train loss: 0.0231
2023-02-06 11:57:09 | Train | Epoch[204/600] Iteration[027/030] Train loss: 0.0230
2023-02-06 11:57:09 | Train | Epoch[204/600] Iteration[028/030] Train loss: 0.0230
2023-02-06 11:57:09 | Train | Epoch[204/600] Iteration[029/030] Train loss: 0.0231
2023-02-06 11:57:09 | Train | Epoch[204/600] Iteration[030/030] Train loss: 0.0231
2023-02-06 11:57:09 | Valid | Epoch[204/600] Iteration[001/008] Valid loss: 0.1905
2023-02-06 11:57:09 | Valid | Epoch[204/600] Iteration[002/008] Valid loss: 0.1975
2023-02-06 11:57:09 | Valid | Epoch[204/600] Iteration[003/008] Valid loss: 0.2132
2023-02-06 11:57:09 | Valid | Epoch[204/600] Iteration[004/008] Valid loss: 0.2111
2023-02-06 11:57:09 | Valid | Epoch[204/600] Iteration[005/008] Valid loss: 0.2196
2023-02-06 11:57:09 | Valid | Epoch[204/600] Iteration[006/008] Valid loss: 0.2152
2023-02-06 11:57:09 | Valid | Epoch[204/600] Iteration[007/008] Valid loss: 0.2128
2023-02-06 11:57:09 | Valid | Epoch[204/600] Iteration[008/008] Valid loss: 0.2230
2023-02-06 11:57:09 | Valid | Epoch[204/600] MIou: 0.4718169603507942
2023-02-06 11:57:09 | Valid | Epoch[204/600] Pixel Accuracy: 0.9125150044759115
2023-02-06 11:57:09 | Valid | Epoch[204/600] Mean Pixel Accuracy: 0.5156837348125414
2023-02-06 11:57:09 | Stage | Epoch[204/600] Train loss:0.0231
2023-02-06 11:57:09 | Stage | Epoch[204/600] Valid loss:0.2230
2023-02-06 11:57:09 | Stage | Epoch[204/600] LR:0.01

2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[001/030] Train loss: 0.0250
2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[002/030] Train loss: 0.0232
2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[003/030] Train loss: 0.0224
2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[005/030] Train loss: 0.0221
2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[006/030] Train loss: 0.0223
2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[007/030] Train loss: 0.0222
2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[008/030] Train loss: 0.0225
2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[009/030] Train loss: 0.0226
2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[010/030] Train loss: 0.0229
2023-02-06 11:57:10 | Train | Epoch[205/600] Iteration[011/030] Train loss: 0.0231
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[012/030] Train loss: 0.0232
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[013/030] Train loss: 0.0231
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[014/030] Train loss: 0.0229
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[015/030] Train loss: 0.0228
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[016/030] Train loss: 0.0230
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[017/030] Train loss: 0.0229
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[018/030] Train loss: 0.0229
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[019/030] Train loss: 0.0228
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[020/030] Train loss: 0.0227
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[021/030] Train loss: 0.0229
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[022/030] Train loss: 0.0230
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[023/030] Train loss: 0.0232
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[024/030] Train loss: 0.0232
2023-02-06 11:57:11 | Train | Epoch[205/600] Iteration[025/030] Train loss: 0.0232
2023-02-06 11:57:12 | Train | Epoch[205/600] Iteration[026/030] Train loss: 0.0233
2023-02-06 11:57:12 | Train | Epoch[205/600] Iteration[027/030] Train loss: 0.0233
2023-02-06 11:57:12 | Train | Epoch[205/600] Iteration[028/030] Train loss: 0.0233
2023-02-06 11:57:12 | Train | Epoch[205/600] Iteration[029/030] Train loss: 0.0233
2023-02-06 11:57:12 | Train | Epoch[205/600] Iteration[030/030] Train loss: 0.0234
2023-02-06 11:57:12 | Valid | Epoch[205/600] Iteration[001/008] Valid loss: 0.0902
2023-02-06 11:57:12 | Valid | Epoch[205/600] Iteration[002/008] Valid loss: 0.0940
2023-02-06 11:57:12 | Valid | Epoch[205/600] Iteration[003/008] Valid loss: 0.1007
2023-02-06 11:57:12 | Valid | Epoch[205/600] Iteration[004/008] Valid loss: 0.0970
2023-02-06 11:57:12 | Valid | Epoch[205/600] Iteration[005/008] Valid loss: 0.0997
2023-02-06 11:57:12 | Valid | Epoch[205/600] Iteration[006/008] Valid loss: 0.0975
2023-02-06 11:57:12 | Valid | Epoch[205/600] Iteration[007/008] Valid loss: 0.0954
2023-02-06 11:57:12 | Valid | Epoch[205/600] Iteration[008/008] Valid loss: 0.1005
2023-02-06 11:57:12 | Valid | Epoch[205/600] MIou: 0.648922119455656
2023-02-06 11:57:12 | Valid | Epoch[205/600] Pixel Accuracy: 0.9419911702473959
2023-02-06 11:57:12 | Valid | Epoch[205/600] Mean Pixel Accuracy: 0.6789079460707207
2023-02-06 11:57:12 | Stage | Epoch[205/600] Train loss:0.0234
2023-02-06 11:57:12 | Stage | Epoch[205/600] Valid loss:0.1005
2023-02-06 11:57:12 | Stage | Epoch[205/600] LR:0.01

2023-02-06 11:57:13 | Train | Epoch[206/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 11:57:13 | Train | Epoch[206/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:57:13 | Train | Epoch[206/600] Iteration[003/030] Train loss: 0.0227
2023-02-06 11:57:13 | Train | Epoch[206/600] Iteration[004/030] Train loss: 0.0225
2023-02-06 11:57:13 | Train | Epoch[206/600] Iteration[005/030] Train loss: 0.0227
2023-02-06 11:57:13 | Train | Epoch[206/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:57:13 | Train | Epoch[206/600] Iteration[007/030] Train loss: 0.0228
2023-02-06 11:57:13 | Train | Epoch[206/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:57:13 | Train | Epoch[206/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 11:57:13 | Train | Epoch[206/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[011/030] Train loss: 0.0229
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[012/030] Train loss: 0.0229
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[014/030] Train loss: 0.0227
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[015/030] Train loss: 0.0227
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[016/030] Train loss: 0.0225
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[017/030] Train loss: 0.0226
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[018/030] Train loss: 0.0226
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[019/030] Train loss: 0.0227
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[020/030] Train loss: 0.0230
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[021/030] Train loss: 0.0231
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[022/030] Train loss: 0.0232
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[023/030] Train loss: 0.0233
2023-02-06 11:57:14 | Train | Epoch[206/600] Iteration[024/030] Train loss: 0.0233
2023-02-06 11:57:15 | Train | Epoch[206/600] Iteration[025/030] Train loss: 0.0233
2023-02-06 11:57:15 | Train | Epoch[206/600] Iteration[026/030] Train loss: 0.0234
2023-02-06 11:57:15 | Train | Epoch[206/600] Iteration[027/030] Train loss: 0.0233
2023-02-06 11:57:15 | Train | Epoch[206/600] Iteration[028/030] Train loss: 0.0233
2023-02-06 11:57:15 | Train | Epoch[206/600] Iteration[029/030] Train loss: 0.0232
2023-02-06 11:57:15 | Train | Epoch[206/600] Iteration[030/030] Train loss: 0.0233
2023-02-06 11:57:15 | Valid | Epoch[206/600] Iteration[001/008] Valid loss: 0.0477
2023-02-06 11:57:15 | Valid | Epoch[206/600] Iteration[002/008] Valid loss: 0.0420
2023-02-06 11:57:15 | Valid | Epoch[206/600] Iteration[003/008] Valid loss: 0.0426
2023-02-06 11:57:15 | Valid | Epoch[206/600] Iteration[004/008] Valid loss: 0.0400
2023-02-06 11:57:15 | Valid | Epoch[206/600] Iteration[005/008] Valid loss: 0.0398
2023-02-06 11:57:15 | Valid | Epoch[206/600] Iteration[006/008] Valid loss: 0.0386
2023-02-06 11:57:15 | Valid | Epoch[206/600] Iteration[007/008] Valid loss: 0.0385
2023-02-06 11:57:15 | Valid | Epoch[206/600] Iteration[008/008] Valid loss: 0.0384
2023-02-06 11:57:16 | Valid | Epoch[206/600] MIou: 0.8996898355079108
2023-02-06 11:57:16 | Valid | Epoch[206/600] Pixel Accuracy: 0.9833488464355469
2023-02-06 11:57:16 | Valid | Epoch[206/600] Mean Pixel Accuracy: 0.9120928191949097
2023-02-06 11:57:16 | Stage | Epoch[206/600] Train loss:0.0233
2023-02-06 11:57:16 | Stage | Epoch[206/600] Valid loss:0.0384
2023-02-06 11:57:16 | Stage | Epoch[206/600] LR:0.01

2023-02-06 11:57:16 | Train | Epoch[207/600] Iteration[001/030] Train loss: 0.0231
2023-02-06 11:57:16 | Train | Epoch[207/600] Iteration[002/030] Train loss: 0.0226
2023-02-06 11:57:16 | Train | Epoch[207/600] Iteration[003/030] Train loss: 0.0221
2023-02-06 11:57:16 | Train | Epoch[207/600] Iteration[004/030] Train loss: 0.0223
2023-02-06 11:57:16 | Train | Epoch[207/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 11:57:16 | Train | Epoch[207/600] Iteration[006/030] Train loss: 0.0228
2023-02-06 11:57:16 | Train | Epoch[207/600] Iteration[007/030] Train loss: 0.0232
2023-02-06 11:57:16 | Train | Epoch[207/600] Iteration[008/030] Train loss: 0.0232
2023-02-06 11:57:16 | Train | Epoch[207/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 11:57:16 | Train | Epoch[207/600] Iteration[010/030] Train loss: 0.0227
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[011/030] Train loss: 0.0229
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[012/030] Train loss: 0.0227
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[014/030] Train loss: 0.0226
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[015/030] Train loss: 0.0227
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[016/030] Train loss: 0.0228
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[017/030] Train loss: 0.0226
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[018/030] Train loss: 0.0229
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[019/030] Train loss: 0.0229
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[020/030] Train loss: 0.0230
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[021/030] Train loss: 0.0230
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[022/030] Train loss: 0.0229
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[023/030] Train loss: 0.0228
2023-02-06 11:57:17 | Train | Epoch[207/600] Iteration[024/030] Train loss: 0.0228
2023-02-06 11:57:18 | Train | Epoch[207/600] Iteration[025/030] Train loss: 0.0228
2023-02-06 11:57:18 | Train | Epoch[207/600] Iteration[026/030] Train loss: 0.0228
2023-02-06 11:57:18 | Train | Epoch[207/600] Iteration[027/030] Train loss: 0.0229
2023-02-06 11:57:18 | Train | Epoch[207/600] Iteration[028/030] Train loss: 0.0229
2023-02-06 11:57:18 | Train | Epoch[207/600] Iteration[029/030] Train loss: 0.0229
2023-02-06 11:57:18 | Train | Epoch[207/600] Iteration[030/030] Train loss: 0.0230
2023-02-06 11:57:18 | Valid | Epoch[207/600] Iteration[001/008] Valid loss: 0.2092
2023-02-06 11:57:18 | Valid | Epoch[207/600] Iteration[002/008] Valid loss: 0.1523
2023-02-06 11:57:18 | Valid | Epoch[207/600] Iteration[003/008] Valid loss: 0.1464
2023-02-06 11:57:18 | Valid | Epoch[207/600] Iteration[004/008] Valid loss: 0.1386
2023-02-06 11:57:18 | Valid | Epoch[207/600] Iteration[005/008] Valid loss: 0.1366
2023-02-06 11:57:18 | Valid | Epoch[207/600] Iteration[006/008] Valid loss: 0.1315
2023-02-06 11:57:18 | Valid | Epoch[207/600] Iteration[007/008] Valid loss: 0.1389
2023-02-06 11:57:18 | Valid | Epoch[207/600] Iteration[008/008] Valid loss: 0.1316
2023-02-06 11:57:18 | Valid | Epoch[207/600] MIou: 0.9400586664003909
2023-02-06 11:57:18 | Valid | Epoch[207/600] Pixel Accuracy: 0.9894803365071615
2023-02-06 11:57:18 | Valid | Epoch[207/600] Mean Pixel Accuracy: 0.975456489087295
2023-02-06 11:57:18 | Stage | Epoch[207/600] Train loss:0.0230
2023-02-06 11:57:18 | Stage | Epoch[207/600] Valid loss:0.1316
2023-02-06 11:57:18 | Stage | Epoch[207/600] LR:0.01

2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[002/030] Train loss: 0.0216
2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[003/030] Train loss: 0.0218
2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[004/030] Train loss: 0.0219
2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[005/030] Train loss: 0.0224
2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[006/030] Train loss: 0.0221
2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[007/030] Train loss: 0.0226
2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[008/030] Train loss: 0.0223
2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[009/030] Train loss: 0.0220
2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[010/030] Train loss: 0.0222
2023-02-06 11:57:19 | Train | Epoch[208/600] Iteration[011/030] Train loss: 0.0223
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[012/030] Train loss: 0.0224
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[013/030] Train loss: 0.0222
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[014/030] Train loss: 0.0225
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[015/030] Train loss: 0.0224
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[016/030] Train loss: 0.0223
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[017/030] Train loss: 0.0222
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[018/030] Train loss: 0.0224
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[019/030] Train loss: 0.0224
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[020/030] Train loss: 0.0225
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[021/030] Train loss: 0.0225
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[022/030] Train loss: 0.0225
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[023/030] Train loss: 0.0225
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[024/030] Train loss: 0.0224
2023-02-06 11:57:20 | Train | Epoch[208/600] Iteration[025/030] Train loss: 0.0224
2023-02-06 11:57:21 | Train | Epoch[208/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:57:21 | Train | Epoch[208/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:57:21 | Train | Epoch[208/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:57:21 | Train | Epoch[208/600] Iteration[029/030] Train loss: 0.0226
2023-02-06 11:57:21 | Train | Epoch[208/600] Iteration[030/030] Train loss: 0.0227
2023-02-06 11:57:21 | Valid | Epoch[208/600] Iteration[001/008] Valid loss: 1.6736
2023-02-06 11:57:21 | Valid | Epoch[208/600] Iteration[002/008] Valid loss: 1.6411
2023-02-06 11:57:21 | Valid | Epoch[208/600] Iteration[003/008] Valid loss: 1.6539
2023-02-06 11:57:21 | Valid | Epoch[208/600] Iteration[004/008] Valid loss: 1.7171
2023-02-06 11:57:21 | Valid | Epoch[208/600] Iteration[005/008] Valid loss: 1.7464
2023-02-06 11:57:21 | Valid | Epoch[208/600] Iteration[006/008] Valid loss: 1.7108
2023-02-06 11:57:21 | Valid | Epoch[208/600] Iteration[007/008] Valid loss: 1.7698
2023-02-06 11:57:21 | Valid | Epoch[208/600] Iteration[008/008] Valid loss: 1.8266
2023-02-06 11:57:21 | Valid | Epoch[208/600] MIou: 0.8117881878506485
2023-02-06 11:57:21 | Valid | Epoch[208/600] Pixel Accuracy: 0.9560572306315104
2023-02-06 11:57:21 | Valid | Epoch[208/600] Mean Pixel Accuracy: 0.9741289120615186
2023-02-06 11:57:21 | Stage | Epoch[208/600] Train loss:0.0227
2023-02-06 11:57:21 | Stage | Epoch[208/600] Valid loss:1.8266
2023-02-06 11:57:21 | Stage | Epoch[208/600] LR:0.01

2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[002/030] Train loss: 0.0226
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[003/030] Train loss: 0.0216
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[005/030] Train loss: 0.0218
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[006/030] Train loss: 0.0217
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[007/030] Train loss: 0.0219
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[008/030] Train loss: 0.0223
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[009/030] Train loss: 0.0221
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[010/030] Train loss: 0.0226
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[011/030] Train loss: 0.0228
2023-02-06 11:57:22 | Train | Epoch[209/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[014/030] Train loss: 0.0228
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[015/030] Train loss: 0.0228
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[016/030] Train loss: 0.0228
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[017/030] Train loss: 0.0228
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[018/030] Train loss: 0.0228
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[019/030] Train loss: 0.0228
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[020/030] Train loss: 0.0227
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[021/030] Train loss: 0.0228
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[022/030] Train loss: 0.0228
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[023/030] Train loss: 0.0229
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[024/030] Train loss: 0.0228
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[025/030] Train loss: 0.0226
2023-02-06 11:57:23 | Train | Epoch[209/600] Iteration[026/030] Train loss: 0.0226
2023-02-06 11:57:24 | Train | Epoch[209/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:57:24 | Train | Epoch[209/600] Iteration[028/030] Train loss: 0.0226
2023-02-06 11:57:24 | Train | Epoch[209/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 11:57:24 | Train | Epoch[209/600] Iteration[030/030] Train loss: 0.0226
2023-02-06 11:57:24 | Valid | Epoch[209/600] Iteration[001/008] Valid loss: 0.0920
2023-02-06 11:57:24 | Valid | Epoch[209/600] Iteration[002/008] Valid loss: 0.0709
2023-02-06 11:57:24 | Valid | Epoch[209/600] Iteration[003/008] Valid loss: 0.0760
2023-02-06 11:57:24 | Valid | Epoch[209/600] Iteration[004/008] Valid loss: 0.0691
2023-02-06 11:57:24 | Valid | Epoch[209/600] Iteration[005/008] Valid loss: 0.0670
2023-02-06 11:57:24 | Valid | Epoch[209/600] Iteration[006/008] Valid loss: 0.0642
2023-02-06 11:57:24 | Valid | Epoch[209/600] Iteration[007/008] Valid loss: 0.0633
2023-02-06 11:57:24 | Valid | Epoch[209/600] Iteration[008/008] Valid loss: 0.0614
2023-02-06 11:57:24 | Valid | Epoch[209/600] MIou: 0.8863514476839942
2023-02-06 11:57:24 | Valid | Epoch[209/600] Pixel Accuracy: 0.9810574849446615
2023-02-06 11:57:24 | Valid | Epoch[209/600] Mean Pixel Accuracy: 0.9013607247562678
2023-02-06 11:57:24 | Stage | Epoch[209/600] Train loss:0.0226
2023-02-06 11:57:24 | Stage | Epoch[209/600] Valid loss:0.0614
2023-02-06 11:57:24 | Stage | Epoch[209/600] LR:0.01

2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[001/030] Train loss: 0.0249
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[002/030] Train loss: 0.0228
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[003/030] Train loss: 0.0229
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[004/030] Train loss: 0.0231
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[006/030] Train loss: 0.0227
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[007/030] Train loss: 0.0227
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[011/030] Train loss: 0.0228
2023-02-06 11:57:25 | Train | Epoch[210/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[014/030] Train loss: 0.0227
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[015/030] Train loss: 0.0225
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[016/030] Train loss: 0.0225
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[018/030] Train loss: 0.0226
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[019/030] Train loss: 0.0225
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[020/030] Train loss: 0.0224
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[021/030] Train loss: 0.0223
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[023/030] Train loss: 0.0224
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[024/030] Train loss: 0.0224
2023-02-06 11:57:26 | Train | Epoch[210/600] Iteration[025/030] Train loss: 0.0224
2023-02-06 11:57:27 | Train | Epoch[210/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:57:27 | Train | Epoch[210/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:57:27 | Train | Epoch[210/600] Iteration[028/030] Train loss: 0.0226
2023-02-06 11:57:27 | Train | Epoch[210/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 11:57:27 | Train | Epoch[210/600] Iteration[030/030] Train loss: 0.0226
2023-02-06 11:57:27 | Valid | Epoch[210/600] Iteration[001/008] Valid loss: 0.2462
2023-02-06 11:57:27 | Valid | Epoch[210/600] Iteration[002/008] Valid loss: 0.2577
2023-02-06 11:57:27 | Valid | Epoch[210/600] Iteration[003/008] Valid loss: 0.2348
2023-02-06 11:57:27 | Valid | Epoch[210/600] Iteration[004/008] Valid loss: 0.2338
2023-02-06 11:57:27 | Valid | Epoch[210/600] Iteration[005/008] Valid loss: 0.2362
2023-02-06 11:57:27 | Valid | Epoch[210/600] Iteration[006/008] Valid loss: 0.2331
2023-02-06 11:57:27 | Valid | Epoch[210/600] Iteration[007/008] Valid loss: 0.2415
2023-02-06 11:57:27 | Valid | Epoch[210/600] Iteration[008/008] Valid loss: 0.2468
2023-02-06 11:57:27 | Valid | Epoch[210/600] MIou: 0.9113367364716976
2023-02-06 11:57:27 | Valid | Epoch[210/600] Pixel Accuracy: 0.9834785461425781
2023-02-06 11:57:27 | Valid | Epoch[210/600] Mean Pixel Accuracy: 0.9755688228062509
2023-02-06 11:57:27 | Stage | Epoch[210/600] Train loss:0.0226
2023-02-06 11:57:27 | Stage | Epoch[210/600] Valid loss:0.2468
2023-02-06 11:57:27 | Stage | Epoch[210/600] LR:0.01

2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[005/030] Train loss: 0.0213
2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[007/030] Train loss: 0.0217
2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[008/030] Train loss: 0.0219
2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[009/030] Train loss: 0.0220
2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[010/030] Train loss: 0.0220
2023-02-06 11:57:28 | Train | Epoch[211/600] Iteration[011/030] Train loss: 0.0221
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[012/030] Train loss: 0.0221
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[013/030] Train loss: 0.0222
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[014/030] Train loss: 0.0222
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[015/030] Train loss: 0.0224
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[016/030] Train loss: 0.0224
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[018/030] Train loss: 0.0223
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[019/030] Train loss: 0.0224
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[020/030] Train loss: 0.0224
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[021/030] Train loss: 0.0224
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[022/030] Train loss: 0.0223
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[023/030] Train loss: 0.0223
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[024/030] Train loss: 0.0224
2023-02-06 11:57:29 | Train | Epoch[211/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:57:30 | Train | Epoch[211/600] Iteration[026/030] Train loss: 0.0223
2023-02-06 11:57:30 | Train | Epoch[211/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:57:30 | Train | Epoch[211/600] Iteration[028/030] Train loss: 0.0224
2023-02-06 11:57:30 | Train | Epoch[211/600] Iteration[029/030] Train loss: 0.0224
2023-02-06 11:57:30 | Train | Epoch[211/600] Iteration[030/030] Train loss: 0.0224
2023-02-06 11:57:30 | Valid | Epoch[211/600] Iteration[001/008] Valid loss: 0.2562
2023-02-06 11:57:30 | Valid | Epoch[211/600] Iteration[002/008] Valid loss: 0.1949
2023-02-06 11:57:30 | Valid | Epoch[211/600] Iteration[003/008] Valid loss: 0.1917
2023-02-06 11:57:30 | Valid | Epoch[211/600] Iteration[004/008] Valid loss: 0.1871
2023-02-06 11:57:30 | Valid | Epoch[211/600] Iteration[005/008] Valid loss: 0.1944
2023-02-06 11:57:30 | Valid | Epoch[211/600] Iteration[006/008] Valid loss: 0.1850
2023-02-06 11:57:30 | Valid | Epoch[211/600] Iteration[007/008] Valid loss: 0.2020
2023-02-06 11:57:30 | Valid | Epoch[211/600] Iteration[008/008] Valid loss: 0.1957
2023-02-06 11:57:30 | Valid | Epoch[211/600] MIou: 0.9294061900629033
2023-02-06 11:57:30 | Valid | Epoch[211/600] Pixel Accuracy: 0.9872283935546875
2023-02-06 11:57:30 | Valid | Epoch[211/600] Mean Pixel Accuracy: 0.9796398283403995
2023-02-06 11:57:30 | Stage | Epoch[211/600] Train loss:0.0224
2023-02-06 11:57:30 | Stage | Epoch[211/600] Valid loss:0.1957
2023-02-06 11:57:30 | Stage | Epoch[211/600] LR:0.01

2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[004/030] Train loss: 0.0217
2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[005/030] Train loss: 0.0217
2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[006/030] Train loss: 0.0220
2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[007/030] Train loss: 0.0229
2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[008/030] Train loss: 0.0230
2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[010/030] Train loss: 0.0226
2023-02-06 11:57:31 | Train | Epoch[212/600] Iteration[011/030] Train loss: 0.0226
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[012/030] Train loss: 0.0224
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[013/030] Train loss: 0.0224
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[014/030] Train loss: 0.0224
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[015/030] Train loss: 0.0224
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[016/030] Train loss: 0.0224
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[017/030] Train loss: 0.0225
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[018/030] Train loss: 0.0224
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[019/030] Train loss: 0.0224
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[020/030] Train loss: 0.0224
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[021/030] Train loss: 0.0225
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[022/030] Train loss: 0.0225
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[023/030] Train loss: 0.0226
2023-02-06 11:57:32 | Train | Epoch[212/600] Iteration[024/030] Train loss: 0.0227
2023-02-06 11:57:33 | Train | Epoch[212/600] Iteration[025/030] Train loss: 0.0227
2023-02-06 11:57:33 | Train | Epoch[212/600] Iteration[026/030] Train loss: 0.0226
2023-02-06 11:57:33 | Train | Epoch[212/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:57:33 | Train | Epoch[212/600] Iteration[028/030] Train loss: 0.0226
2023-02-06 11:57:33 | Train | Epoch[212/600] Iteration[029/030] Train loss: 0.0226
2023-02-06 11:57:33 | Train | Epoch[212/600] Iteration[030/030] Train loss: 0.0226
2023-02-06 11:57:33 | Valid | Epoch[212/600] Iteration[001/008] Valid loss: 0.0759
2023-02-06 11:57:33 | Valid | Epoch[212/600] Iteration[002/008] Valid loss: 0.0566
2023-02-06 11:57:33 | Valid | Epoch[212/600] Iteration[003/008] Valid loss: 0.0581
2023-02-06 11:57:33 | Valid | Epoch[212/600] Iteration[004/008] Valid loss: 0.0531
2023-02-06 11:57:33 | Valid | Epoch[212/600] Iteration[005/008] Valid loss: 0.0509
2023-02-06 11:57:33 | Valid | Epoch[212/600] Iteration[006/008] Valid loss: 0.0487
2023-02-06 11:57:33 | Valid | Epoch[212/600] Iteration[007/008] Valid loss: 0.0499
2023-02-06 11:57:33 | Valid | Epoch[212/600] Iteration[008/008] Valid loss: 0.0482
2023-02-06 11:57:34 | Valid | Epoch[212/600] MIou: 0.9299790004512785
2023-02-06 11:57:34 | Valid | Epoch[212/600] Pixel Accuracy: 0.9882062276204427
2023-02-06 11:57:34 | Valid | Epoch[212/600] Mean Pixel Accuracy: 0.9466425338191627
2023-02-06 11:57:34 | Stage | Epoch[212/600] Train loss:0.0226
2023-02-06 11:57:34 | Stage | Epoch[212/600] Valid loss:0.0482
2023-02-06 11:57:34 | Stage | Epoch[212/600] LR:0.01

2023-02-06 11:57:34 | Train | Epoch[213/600] Iteration[001/030] Train loss: 0.0205
2023-02-06 11:57:34 | Train | Epoch[213/600] Iteration[002/030] Train loss: 0.0233
2023-02-06 11:57:34 | Train | Epoch[213/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 11:57:34 | Train | Epoch[213/600] Iteration[004/030] Train loss: 0.0232
2023-02-06 11:57:34 | Train | Epoch[213/600] Iteration[005/030] Train loss: 0.0236
2023-02-06 11:57:34 | Train | Epoch[213/600] Iteration[006/030] Train loss: 0.0238
2023-02-06 11:57:34 | Train | Epoch[213/600] Iteration[007/030] Train loss: 0.0233
2023-02-06 11:57:34 | Train | Epoch[213/600] Iteration[008/030] Train loss: 0.0232
2023-02-06 11:57:34 | Train | Epoch[213/600] Iteration[009/030] Train loss: 0.0228
2023-02-06 11:57:34 | Train | Epoch[213/600] Iteration[010/030] Train loss: 0.0227
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[011/030] Train loss: 0.0226
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[012/030] Train loss: 0.0225
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[013/030] Train loss: 0.0225
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[014/030] Train loss: 0.0224
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[015/030] Train loss: 0.0223
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[016/030] Train loss: 0.0223
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[017/030] Train loss: 0.0222
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[018/030] Train loss: 0.0223
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[019/030] Train loss: 0.0222
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[020/030] Train loss: 0.0222
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[021/030] Train loss: 0.0222
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[022/030] Train loss: 0.0222
2023-02-06 11:57:35 | Train | Epoch[213/600] Iteration[023/030] Train loss: 0.0222
2023-02-06 11:57:36 | Train | Epoch[213/600] Iteration[024/030] Train loss: 0.0223
2023-02-06 11:57:36 | Train | Epoch[213/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:57:36 | Train | Epoch[213/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:57:36 | Train | Epoch[213/600] Iteration[027/030] Train loss: 0.0223
2023-02-06 11:57:36 | Train | Epoch[213/600] Iteration[028/030] Train loss: 0.0223
2023-02-06 11:57:36 | Train | Epoch[213/600] Iteration[029/030] Train loss: 0.0224
2023-02-06 11:57:36 | Train | Epoch[213/600] Iteration[030/030] Train loss: 0.0224
2023-02-06 11:57:36 | Valid | Epoch[213/600] Iteration[001/008] Valid loss: 0.0731
2023-02-06 11:57:36 | Valid | Epoch[213/600] Iteration[002/008] Valid loss: 0.0747
2023-02-06 11:57:36 | Valid | Epoch[213/600] Iteration[003/008] Valid loss: 0.0785
2023-02-06 11:57:36 | Valid | Epoch[213/600] Iteration[004/008] Valid loss: 0.0760
2023-02-06 11:57:36 | Valid | Epoch[213/600] Iteration[005/008] Valid loss: 0.0773
2023-02-06 11:57:36 | Valid | Epoch[213/600] Iteration[006/008] Valid loss: 0.0758
2023-02-06 11:57:36 | Valid | Epoch[213/600] Iteration[007/008] Valid loss: 0.0747
2023-02-06 11:57:36 | Valid | Epoch[213/600] Iteration[008/008] Valid loss: 0.0775
2023-02-06 11:57:37 | Valid | Epoch[213/600] MIou: 0.7423595580568085
2023-02-06 11:57:37 | Valid | Epoch[213/600] Pixel Accuracy: 0.9574699401855469
2023-02-06 11:57:37 | Valid | Epoch[213/600] Mean Pixel Accuracy: 0.76482021440177
2023-02-06 11:57:37 | Stage | Epoch[213/600] Train loss:0.0224
2023-02-06 11:57:37 | Stage | Epoch[213/600] Valid loss:0.0775
2023-02-06 11:57:37 | Stage | Epoch[213/600] LR:0.01

2023-02-06 11:57:37 | Train | Epoch[214/600] Iteration[001/030] Train loss: 0.0220
2023-02-06 11:57:37 | Train | Epoch[214/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:57:37 | Train | Epoch[214/600] Iteration[003/030] Train loss: 0.0213
2023-02-06 11:57:37 | Train | Epoch[214/600] Iteration[004/030] Train loss: 0.0224
2023-02-06 11:57:37 | Train | Epoch[214/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 11:57:37 | Train | Epoch[214/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:57:37 | Train | Epoch[214/600] Iteration[007/030] Train loss: 0.0226
2023-02-06 11:57:37 | Train | Epoch[214/600] Iteration[008/030] Train loss: 0.0224
2023-02-06 11:57:37 | Train | Epoch[214/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:57:37 | Train | Epoch[214/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[011/030] Train loss: 0.0231
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[012/030] Train loss: 0.0229
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[013/030] Train loss: 0.0229
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[014/030] Train loss: 0.0228
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[015/030] Train loss: 0.0230
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[016/030] Train loss: 0.0229
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[017/030] Train loss: 0.0229
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[018/030] Train loss: 0.0229
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[019/030] Train loss: 0.0228
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[020/030] Train loss: 0.0228
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[021/030] Train loss: 0.0228
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[022/030] Train loss: 0.0226
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[023/030] Train loss: 0.0225
2023-02-06 11:57:38 | Train | Epoch[214/600] Iteration[024/030] Train loss: 0.0225
2023-02-06 11:57:39 | Train | Epoch[214/600] Iteration[025/030] Train loss: 0.0225
2023-02-06 11:57:39 | Train | Epoch[214/600] Iteration[026/030] Train loss: 0.0225
2023-02-06 11:57:39 | Train | Epoch[214/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:57:39 | Train | Epoch[214/600] Iteration[028/030] Train loss: 0.0226
2023-02-06 11:57:39 | Train | Epoch[214/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 11:57:39 | Train | Epoch[214/600] Iteration[030/030] Train loss: 0.0224
2023-02-06 11:57:39 | Valid | Epoch[214/600] Iteration[001/008] Valid loss: 0.4057
2023-02-06 11:57:39 | Valid | Epoch[214/600] Iteration[002/008] Valid loss: 0.3516
2023-02-06 11:57:39 | Valid | Epoch[214/600] Iteration[003/008] Valid loss: 0.3639
2023-02-06 11:57:39 | Valid | Epoch[214/600] Iteration[004/008] Valid loss: 0.3633
2023-02-06 11:57:39 | Valid | Epoch[214/600] Iteration[005/008] Valid loss: 0.3725
2023-02-06 11:57:39 | Valid | Epoch[214/600] Iteration[006/008] Valid loss: 0.3535
2023-02-06 11:57:39 | Valid | Epoch[214/600] Iteration[007/008] Valid loss: 0.3622
2023-02-06 11:57:39 | Valid | Epoch[214/600] Iteration[008/008] Valid loss: 0.3474
2023-02-06 11:57:39 | Valid | Epoch[214/600] MIou: 0.9270839267227111
2023-02-06 11:57:39 | Valid | Epoch[214/600] Pixel Accuracy: 0.9868075052897135
2023-02-06 11:57:39 | Valid | Epoch[214/600] Mean Pixel Accuracy: 0.9773161346005332
2023-02-06 11:57:40 | Stage | Epoch[214/600] Train loss:0.0224
2023-02-06 11:57:40 | Stage | Epoch[214/600] Valid loss:0.3474
2023-02-06 11:57:40 | Stage | Epoch[214/600] LR:0.01

2023-02-06 11:57:40 | Train | Epoch[215/600] Iteration[001/030] Train loss: 0.0212
2023-02-06 11:57:40 | Train | Epoch[215/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:57:40 | Train | Epoch[215/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 11:57:40 | Train | Epoch[215/600] Iteration[004/030] Train loss: 0.0230
2023-02-06 11:57:40 | Train | Epoch[215/600] Iteration[005/030] Train loss: 0.0223
2023-02-06 11:57:40 | Train | Epoch[215/600] Iteration[006/030] Train loss: 0.0221
2023-02-06 11:57:40 | Train | Epoch[215/600] Iteration[007/030] Train loss: 0.0227
2023-02-06 11:57:40 | Train | Epoch[215/600] Iteration[008/030] Train loss: 0.0225
2023-02-06 11:57:40 | Train | Epoch[215/600] Iteration[009/030] Train loss: 0.0223
2023-02-06 11:57:40 | Train | Epoch[215/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[011/030] Train loss: 0.0230
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[012/030] Train loss: 0.0230
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[014/030] Train loss: 0.0228
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[016/030] Train loss: 0.0229
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[017/030] Train loss: 0.0231
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[018/030] Train loss: 0.0232
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[019/030] Train loss: 0.0231
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[020/030] Train loss: 0.0231
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[021/030] Train loss: 0.0230
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[022/030] Train loss: 0.0230
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[023/030] Train loss: 0.0231
2023-02-06 11:57:41 | Train | Epoch[215/600] Iteration[024/030] Train loss: 0.0229
2023-02-06 11:57:42 | Train | Epoch[215/600] Iteration[025/030] Train loss: 0.0229
2023-02-06 11:57:42 | Train | Epoch[215/600] Iteration[026/030] Train loss: 0.0229
2023-02-06 11:57:42 | Train | Epoch[215/600] Iteration[027/030] Train loss: 0.0229
2023-02-06 11:57:42 | Train | Epoch[215/600] Iteration[028/030] Train loss: 0.0229
2023-02-06 11:57:42 | Train | Epoch[215/600] Iteration[029/030] Train loss: 0.0229
2023-02-06 11:57:42 | Train | Epoch[215/600] Iteration[030/030] Train loss: 0.0230
2023-02-06 11:57:42 | Valid | Epoch[215/600] Iteration[001/008] Valid loss: 0.0682
2023-02-06 11:57:42 | Valid | Epoch[215/600] Iteration[002/008] Valid loss: 0.0569
2023-02-06 11:57:42 | Valid | Epoch[215/600] Iteration[003/008] Valid loss: 0.0526
2023-02-06 11:57:42 | Valid | Epoch[215/600] Iteration[004/008] Valid loss: 0.0491
2023-02-06 11:57:42 | Valid | Epoch[215/600] Iteration[005/008] Valid loss: 0.0482
2023-02-06 11:57:42 | Valid | Epoch[215/600] Iteration[006/008] Valid loss: 0.0470
2023-02-06 11:57:42 | Valid | Epoch[215/600] Iteration[007/008] Valid loss: 0.0491
2023-02-06 11:57:42 | Valid | Epoch[215/600] Iteration[008/008] Valid loss: 0.0481
2023-02-06 11:57:43 | Valid | Epoch[215/600] MIou: 0.9142663339574078
2023-02-06 11:57:43 | Valid | Epoch[215/600] Pixel Accuracy: 0.9855155944824219
2023-02-06 11:57:43 | Valid | Epoch[215/600] Mean Pixel Accuracy: 0.9331801559359478
2023-02-06 11:57:43 | Stage | Epoch[215/600] Train loss:0.0230
2023-02-06 11:57:43 | Stage | Epoch[215/600] Valid loss:0.0481
2023-02-06 11:57:43 | Stage | Epoch[215/600] LR:0.01

2023-02-06 11:57:43 | Train | Epoch[216/600] Iteration[001/030] Train loss: 0.0215
2023-02-06 11:57:43 | Train | Epoch[216/600] Iteration[002/030] Train loss: 0.0234
2023-02-06 11:57:43 | Train | Epoch[216/600] Iteration[003/030] Train loss: 0.0230
2023-02-06 11:57:43 | Train | Epoch[216/600] Iteration[004/030] Train loss: 0.0232
2023-02-06 11:57:43 | Train | Epoch[216/600] Iteration[005/030] Train loss: 0.0233
2023-02-06 11:57:43 | Train | Epoch[216/600] Iteration[006/030] Train loss: 0.0228
2023-02-06 11:57:43 | Train | Epoch[216/600] Iteration[007/030] Train loss: 0.0229
2023-02-06 11:57:43 | Train | Epoch[216/600] Iteration[008/030] Train loss: 0.0226
2023-02-06 11:57:43 | Train | Epoch[216/600] Iteration[009/030] Train loss: 0.0224
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[012/030] Train loss: 0.0222
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[013/030] Train loss: 0.0221
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[014/030] Train loss: 0.0220
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[015/030] Train loss: 0.0220
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[016/030] Train loss: 0.0219
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[017/030] Train loss: 0.0219
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[018/030] Train loss: 0.0219
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[019/030] Train loss: 0.0218
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[020/030] Train loss: 0.0219
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[021/030] Train loss: 0.0219
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:57:44 | Train | Epoch[216/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:57:45 | Train | Epoch[216/600] Iteration[024/030] Train loss: 0.0220
2023-02-06 11:57:45 | Train | Epoch[216/600] Iteration[025/030] Train loss: 0.0221
2023-02-06 11:57:45 | Train | Epoch[216/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:57:45 | Train | Epoch[216/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:57:45 | Train | Epoch[216/600] Iteration[028/030] Train loss: 0.0221
2023-02-06 11:57:45 | Train | Epoch[216/600] Iteration[029/030] Train loss: 0.0221
2023-02-06 11:57:45 | Train | Epoch[216/600] Iteration[030/030] Train loss: 0.0222
2023-02-06 11:57:45 | Valid | Epoch[216/600] Iteration[001/008] Valid loss: 0.1002
2023-02-06 11:57:45 | Valid | Epoch[216/600] Iteration[002/008] Valid loss: 0.1057
2023-02-06 11:57:45 | Valid | Epoch[216/600] Iteration[003/008] Valid loss: 0.1126
2023-02-06 11:57:45 | Valid | Epoch[216/600] Iteration[004/008] Valid loss: 0.1096
2023-02-06 11:57:45 | Valid | Epoch[216/600] Iteration[005/008] Valid loss: 0.1125
2023-02-06 11:57:45 | Valid | Epoch[216/600] Iteration[006/008] Valid loss: 0.1099
2023-02-06 11:57:45 | Valid | Epoch[216/600] Iteration[007/008] Valid loss: 0.1069
2023-02-06 11:57:45 | Valid | Epoch[216/600] Iteration[008/008] Valid loss: 0.1112
2023-02-06 11:57:46 | Valid | Epoch[216/600] MIou: 0.6633960335294833
2023-02-06 11:57:46 | Valid | Epoch[216/600] Pixel Accuracy: 0.9443995157877604
2023-02-06 11:57:46 | Valid | Epoch[216/600] Mean Pixel Accuracy: 0.6921961452364527
2023-02-06 11:57:46 | Stage | Epoch[216/600] Train loss:0.0222
2023-02-06 11:57:46 | Stage | Epoch[216/600] Valid loss:0.1112
2023-02-06 11:57:46 | Stage | Epoch[216/600] LR:0.01

2023-02-06 11:57:46 | Train | Epoch[217/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 11:57:46 | Train | Epoch[217/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:57:46 | Train | Epoch[217/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:57:46 | Train | Epoch[217/600] Iteration[004/030] Train loss: 0.0219
2023-02-06 11:57:46 | Train | Epoch[217/600] Iteration[005/030] Train loss: 0.0226
2023-02-06 11:57:46 | Train | Epoch[217/600] Iteration[006/030] Train loss: 0.0232
2023-02-06 11:57:46 | Train | Epoch[217/600] Iteration[007/030] Train loss: 0.0231
2023-02-06 11:57:46 | Train | Epoch[217/600] Iteration[008/030] Train loss: 0.0233
2023-02-06 11:57:46 | Train | Epoch[217/600] Iteration[009/030] Train loss: 0.0230
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[010/030] Train loss: 0.0231
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[011/030] Train loss: 0.0228
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[013/030] Train loss: 0.0225
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[014/030] Train loss: 0.0225
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[016/030] Train loss: 0.0226
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[017/030] Train loss: 0.0225
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[018/030] Train loss: 0.0226
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[019/030] Train loss: 0.0225
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[020/030] Train loss: 0.0227
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[021/030] Train loss: 0.0226
2023-02-06 11:57:47 | Train | Epoch[217/600] Iteration[022/030] Train loss: 0.0226
2023-02-06 11:57:48 | Train | Epoch[217/600] Iteration[023/030] Train loss: 0.0225
2023-02-06 11:57:48 | Train | Epoch[217/600] Iteration[024/030] Train loss: 0.0225
2023-02-06 11:57:48 | Train | Epoch[217/600] Iteration[025/030] Train loss: 0.0224
2023-02-06 11:57:48 | Train | Epoch[217/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:57:48 | Train | Epoch[217/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:57:48 | Train | Epoch[217/600] Iteration[028/030] Train loss: 0.0224
2023-02-06 11:57:48 | Train | Epoch[217/600] Iteration[029/030] Train loss: 0.0223
2023-02-06 11:57:48 | Train | Epoch[217/600] Iteration[030/030] Train loss: 0.0224
2023-02-06 11:57:48 | Valid | Epoch[217/600] Iteration[001/008] Valid loss: 0.0625
2023-02-06 11:57:48 | Valid | Epoch[217/600] Iteration[002/008] Valid loss: 0.0608
2023-02-06 11:57:48 | Valid | Epoch[217/600] Iteration[003/008] Valid loss: 0.0657
2023-02-06 11:57:48 | Valid | Epoch[217/600] Iteration[004/008] Valid loss: 0.0626
2023-02-06 11:57:48 | Valid | Epoch[217/600] Iteration[005/008] Valid loss: 0.0630
2023-02-06 11:57:48 | Valid | Epoch[217/600] Iteration[006/008] Valid loss: 0.0615
2023-02-06 11:57:48 | Valid | Epoch[217/600] Iteration[007/008] Valid loss: 0.0599
2023-02-06 11:57:49 | Valid | Epoch[217/600] Iteration[008/008] Valid loss: 0.0621
2023-02-06 11:57:49 | Valid | Epoch[217/600] MIou: 0.7953815968384664
2023-02-06 11:57:49 | Valid | Epoch[217/600] Pixel Accuracy: 0.9662424723307291
2023-02-06 11:57:49 | Valid | Epoch[217/600] Mean Pixel Accuracy: 0.8134926731857531
2023-02-06 11:57:49 | Stage | Epoch[217/600] Train loss:0.0224
2023-02-06 11:57:49 | Stage | Epoch[217/600] Valid loss:0.0621
2023-02-06 11:57:49 | Stage | Epoch[217/600] LR:0.01

2023-02-06 11:57:49 | Train | Epoch[218/600] Iteration[001/030] Train loss: 0.0219
2023-02-06 11:57:49 | Train | Epoch[218/600] Iteration[002/030] Train loss: 0.0224
2023-02-06 11:57:49 | Train | Epoch[218/600] Iteration[003/030] Train loss: 0.0208
2023-02-06 11:57:49 | Train | Epoch[218/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:57:49 | Train | Epoch[218/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:57:49 | Train | Epoch[218/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:57:49 | Train | Epoch[218/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 11:57:49 | Train | Epoch[218/600] Iteration[008/030] Train loss: 0.0215
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[010/030] Train loss: 0.0221
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[012/030] Train loss: 0.0224
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[013/030] Train loss: 0.0222
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[014/030] Train loss: 0.0220
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[015/030] Train loss: 0.0220
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[016/030] Train loss: 0.0220
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[018/030] Train loss: 0.0221
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[019/030] Train loss: 0.0220
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[020/030] Train loss: 0.0221
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[021/030] Train loss: 0.0221
2023-02-06 11:57:50 | Train | Epoch[218/600] Iteration[022/030] Train loss: 0.0222
2023-02-06 11:57:51 | Train | Epoch[218/600] Iteration[023/030] Train loss: 0.0222
2023-02-06 11:57:51 | Train | Epoch[218/600] Iteration[024/030] Train loss: 0.0224
2023-02-06 11:57:51 | Train | Epoch[218/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:57:51 | Train | Epoch[218/600] Iteration[026/030] Train loss: 0.0223
2023-02-06 11:57:51 | Train | Epoch[218/600] Iteration[027/030] Train loss: 0.0225
2023-02-06 11:57:51 | Train | Epoch[218/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:57:51 | Train | Epoch[218/600] Iteration[029/030] Train loss: 0.0226
2023-02-06 11:57:51 | Train | Epoch[218/600] Iteration[030/030] Train loss: 0.0226
2023-02-06 11:57:51 | Valid | Epoch[218/600] Iteration[001/008] Valid loss: 0.2822
2023-02-06 11:57:51 | Valid | Epoch[218/600] Iteration[002/008] Valid loss: 0.2325
2023-02-06 11:57:51 | Valid | Epoch[218/600] Iteration[003/008] Valid loss: 0.2336
2023-02-06 11:57:51 | Valid | Epoch[218/600] Iteration[004/008] Valid loss: 0.2222
2023-02-06 11:57:51 | Valid | Epoch[218/600] Iteration[005/008] Valid loss: 0.2269
2023-02-06 11:57:51 | Valid | Epoch[218/600] Iteration[006/008] Valid loss: 0.2121
2023-02-06 11:57:52 | Valid | Epoch[218/600] Iteration[007/008] Valid loss: 0.2181
2023-02-06 11:57:52 | Valid | Epoch[218/600] Iteration[008/008] Valid loss: 0.2075
2023-02-06 11:57:52 | Valid | Epoch[218/600] MIou: 0.9358028942595706
2023-02-06 11:57:52 | Valid | Epoch[218/600] Pixel Accuracy: 0.9886220296223959
2023-02-06 11:57:52 | Valid | Epoch[218/600] Mean Pixel Accuracy: 0.9760182238739936
2023-02-06 11:57:52 | Stage | Epoch[218/600] Train loss:0.0226
2023-02-06 11:57:52 | Stage | Epoch[218/600] Valid loss:0.2075
2023-02-06 11:57:52 | Stage | Epoch[218/600] LR:0.01

2023-02-06 11:57:52 | Train | Epoch[219/600] Iteration[001/030] Train loss: 0.0230
2023-02-06 11:57:52 | Train | Epoch[219/600] Iteration[002/030] Train loss: 0.0212
2023-02-06 11:57:52 | Train | Epoch[219/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:57:52 | Train | Epoch[219/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:57:52 | Train | Epoch[219/600] Iteration[005/030] Train loss: 0.0219
2023-02-06 11:57:52 | Train | Epoch[219/600] Iteration[006/030] Train loss: 0.0221
2023-02-06 11:57:52 | Train | Epoch[219/600] Iteration[007/030] Train loss: 0.0222
2023-02-06 11:57:52 | Train | Epoch[219/600] Iteration[008/030] Train loss: 0.0218
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[010/030] Train loss: 0.0216
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[012/030] Train loss: 0.0218
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[013/030] Train loss: 0.0218
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[014/030] Train loss: 0.0219
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[015/030] Train loss: 0.0220
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[016/030] Train loss: 0.0221
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[018/030] Train loss: 0.0223
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[019/030] Train loss: 0.0223
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[020/030] Train loss: 0.0223
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[021/030] Train loss: 0.0225
2023-02-06 11:57:53 | Train | Epoch[219/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:57:54 | Train | Epoch[219/600] Iteration[023/030] Train loss: 0.0224
2023-02-06 11:57:54 | Train | Epoch[219/600] Iteration[024/030] Train loss: 0.0223
2023-02-06 11:57:54 | Train | Epoch[219/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:57:54 | Train | Epoch[219/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:57:54 | Train | Epoch[219/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:57:54 | Train | Epoch[219/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:57:54 | Train | Epoch[219/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 11:57:54 | Train | Epoch[219/600] Iteration[030/030] Train loss: 0.0224
2023-02-06 11:57:54 | Valid | Epoch[219/600] Iteration[001/008] Valid loss: 0.1218
2023-02-06 11:57:54 | Valid | Epoch[219/600] Iteration[002/008] Valid loss: 0.0869
2023-02-06 11:57:54 | Valid | Epoch[219/600] Iteration[003/008] Valid loss: 0.0868
2023-02-06 11:57:54 | Valid | Epoch[219/600] Iteration[004/008] Valid loss: 0.0808
2023-02-06 11:57:54 | Valid | Epoch[219/600] Iteration[005/008] Valid loss: 0.0786
2023-02-06 11:57:55 | Valid | Epoch[219/600] Iteration[006/008] Valid loss: 0.0752
2023-02-06 11:57:55 | Valid | Epoch[219/600] Iteration[007/008] Valid loss: 0.0819
2023-02-06 11:57:55 | Valid | Epoch[219/600] Iteration[008/008] Valid loss: 0.0792
2023-02-06 11:57:55 | Valid | Epoch[219/600] MIou: 0.940360942968391
2023-02-06 11:57:55 | Valid | Epoch[219/600] Pixel Accuracy: 0.9896901448567709
2023-02-06 11:57:55 | Valid | Epoch[219/600] Mean Pixel Accuracy: 0.9685338853259414
2023-02-06 11:57:55 | Stage | Epoch[219/600] Train loss:0.0224
2023-02-06 11:57:55 | Stage | Epoch[219/600] Valid loss:0.0792
2023-02-06 11:57:55 | Stage | Epoch[219/600] LR:0.01

2023-02-06 11:57:55 | Train | Epoch[220/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 11:57:55 | Train | Epoch[220/600] Iteration[002/030] Train loss: 0.0224
2023-02-06 11:57:55 | Train | Epoch[220/600] Iteration[003/030] Train loss: 0.0230
2023-02-06 11:57:55 | Train | Epoch[220/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 11:57:55 | Train | Epoch[220/600] Iteration[005/030] Train loss: 0.0233
2023-02-06 11:57:55 | Train | Epoch[220/600] Iteration[006/030] Train loss: 0.0235
2023-02-06 11:57:55 | Train | Epoch[220/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:57:55 | Train | Epoch[220/600] Iteration[008/030] Train loss: 0.0234
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[009/030] Train loss: 0.0233
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[010/030] Train loss: 0.0231
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[011/030] Train loss: 0.0230
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[012/030] Train loss: 0.0228
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[013/030] Train loss: 0.0227
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[014/030] Train loss: 0.0228
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[016/030] Train loss: 0.0228
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[017/030] Train loss: 0.0226
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[018/030] Train loss: 0.0226
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[019/030] Train loss: 0.0226
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[020/030] Train loss: 0.0226
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[021/030] Train loss: 0.0226
2023-02-06 11:57:56 | Train | Epoch[220/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:57:57 | Train | Epoch[220/600] Iteration[023/030] Train loss: 0.0225
2023-02-06 11:57:57 | Train | Epoch[220/600] Iteration[024/030] Train loss: 0.0225
2023-02-06 11:57:57 | Train | Epoch[220/600] Iteration[025/030] Train loss: 0.0225
2023-02-06 11:57:57 | Train | Epoch[220/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:57:57 | Train | Epoch[220/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:57:57 | Train | Epoch[220/600] Iteration[028/030] Train loss: 0.0222
2023-02-06 11:57:57 | Train | Epoch[220/600] Iteration[029/030] Train loss: 0.0222
2023-02-06 11:57:57 | Train | Epoch[220/600] Iteration[030/030] Train loss: 0.0222
2023-02-06 11:57:57 | Valid | Epoch[220/600] Iteration[001/008] Valid loss: 0.0578
2023-02-06 11:57:57 | Valid | Epoch[220/600] Iteration[002/008] Valid loss: 0.0454
2023-02-06 11:57:57 | Valid | Epoch[220/600] Iteration[003/008] Valid loss: 0.0433
2023-02-06 11:57:57 | Valid | Epoch[220/600] Iteration[004/008] Valid loss: 0.0401
2023-02-06 11:57:57 | Valid | Epoch[220/600] Iteration[005/008] Valid loss: 0.0397
2023-02-06 11:57:57 | Valid | Epoch[220/600] Iteration[006/008] Valid loss: 0.0383
2023-02-06 11:57:57 | Valid | Epoch[220/600] Iteration[007/008] Valid loss: 0.0387
2023-02-06 11:57:58 | Valid | Epoch[220/600] Iteration[008/008] Valid loss: 0.0381
2023-02-06 11:57:58 | Valid | Epoch[220/600] MIou: 0.9136079939416437
2023-02-06 11:57:58 | Valid | Epoch[220/600] Pixel Accuracy: 0.985595703125
2023-02-06 11:57:58 | Valid | Epoch[220/600] Mean Pixel Accuracy: 0.9268773750788679
2023-02-06 11:57:58 | Stage | Epoch[220/600] Train loss:0.0222
2023-02-06 11:57:58 | Stage | Epoch[220/600] Valid loss:0.0381
2023-02-06 11:57:58 | Stage | Epoch[220/600] LR:0.01

2023-02-06 11:57:58 | Train | Epoch[221/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 11:57:58 | Train | Epoch[221/600] Iteration[002/030] Train loss: 0.0180
2023-02-06 11:57:58 | Train | Epoch[221/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:57:58 | Train | Epoch[221/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 11:57:58 | Train | Epoch[221/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:57:58 | Train | Epoch[221/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 11:57:58 | Train | Epoch[221/600] Iteration[007/030] Train loss: 0.0204
2023-02-06 11:57:58 | Train | Epoch[221/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[012/030] Train loss: 0.0219
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[013/030] Train loss: 0.0218
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[018/030] Train loss: 0.0214
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[019/030] Train loss: 0.0216
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[020/030] Train loss: 0.0216
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[021/030] Train loss: 0.0217
2023-02-06 11:57:59 | Train | Epoch[221/600] Iteration[022/030] Train loss: 0.0218
2023-02-06 11:58:00 | Train | Epoch[221/600] Iteration[023/030] Train loss: 0.0217
2023-02-06 11:58:00 | Train | Epoch[221/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:58:00 | Train | Epoch[221/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:58:00 | Train | Epoch[221/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 11:58:00 | Train | Epoch[221/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:58:00 | Train | Epoch[221/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:58:00 | Train | Epoch[221/600] Iteration[029/030] Train loss: 0.0217
2023-02-06 11:58:00 | Train | Epoch[221/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:58:00 | Valid | Epoch[221/600] Iteration[001/008] Valid loss: 0.0543
2023-02-06 11:58:00 | Valid | Epoch[221/600] Iteration[002/008] Valid loss: 0.0467
2023-02-06 11:58:00 | Valid | Epoch[221/600] Iteration[003/008] Valid loss: 0.0481
2023-02-06 11:58:00 | Valid | Epoch[221/600] Iteration[004/008] Valid loss: 0.0446
2023-02-06 11:58:00 | Valid | Epoch[221/600] Iteration[005/008] Valid loss: 0.0433
2023-02-06 11:58:00 | Valid | Epoch[221/600] Iteration[006/008] Valid loss: 0.0429
2023-02-06 11:58:01 | Valid | Epoch[221/600] Iteration[007/008] Valid loss: 0.0435
2023-02-06 11:58:01 | Valid | Epoch[221/600] Iteration[008/008] Valid loss: 0.0428
2023-02-06 11:58:01 | Valid | Epoch[221/600] MIou: 0.8982318345290656
2023-02-06 11:58:01 | Valid | Epoch[221/600] Pixel Accuracy: 0.9830360412597656
2023-02-06 11:58:01 | Valid | Epoch[221/600] Mean Pixel Accuracy: 0.912459828208009
2023-02-06 11:58:01 | Stage | Epoch[221/600] Train loss:0.0217
2023-02-06 11:58:01 | Stage | Epoch[221/600] Valid loss:0.0428
2023-02-06 11:58:01 | Stage | Epoch[221/600] LR:0.01

2023-02-06 11:58:01 | Train | Epoch[222/600] Iteration[001/030] Train loss: 0.0213
2023-02-06 11:58:01 | Train | Epoch[222/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:58:01 | Train | Epoch[222/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 11:58:01 | Train | Epoch[222/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:58:01 | Train | Epoch[222/600] Iteration[005/030] Train loss: 0.0209
2023-02-06 11:58:01 | Train | Epoch[222/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:58:01 | Train | Epoch[222/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:58:01 | Train | Epoch[222/600] Iteration[008/030] Train loss: 0.0215
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[009/030] Train loss: 0.0213
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[012/030] Train loss: 0.0213
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[013/030] Train loss: 0.0212
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[015/030] Train loss: 0.0212
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[016/030] Train loss: 0.0213
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[018/030] Train loss: 0.0212
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[019/030] Train loss: 0.0214
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[020/030] Train loss: 0.0214
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[021/030] Train loss: 0.0214
2023-02-06 11:58:02 | Train | Epoch[222/600] Iteration[022/030] Train loss: 0.0216
2023-02-06 11:58:03 | Train | Epoch[222/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 11:58:03 | Train | Epoch[222/600] Iteration[024/030] Train loss: 0.0217
2023-02-06 11:58:03 | Train | Epoch[222/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:58:03 | Train | Epoch[222/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:58:03 | Train | Epoch[222/600] Iteration[027/030] Train loss: 0.0218
2023-02-06 11:58:03 | Train | Epoch[222/600] Iteration[028/030] Train loss: 0.0219
2023-02-06 11:58:03 | Train | Epoch[222/600] Iteration[029/030] Train loss: 0.0219
2023-02-06 11:58:03 | Train | Epoch[222/600] Iteration[030/030] Train loss: 0.0219
2023-02-06 11:58:03 | Valid | Epoch[222/600] Iteration[001/008] Valid loss: 0.5181
2023-02-06 11:58:03 | Valid | Epoch[222/600] Iteration[002/008] Valid loss: 0.4595
2023-02-06 11:58:03 | Valid | Epoch[222/600] Iteration[003/008] Valid loss: 0.4653
2023-02-06 11:58:03 | Valid | Epoch[222/600] Iteration[004/008] Valid loss: 0.4629
2023-02-06 11:58:04 | Valid | Epoch[222/600] Iteration[005/008] Valid loss: 0.4775
2023-02-06 11:58:04 | Valid | Epoch[222/600] Iteration[006/008] Valid loss: 0.4605
2023-02-06 11:58:04 | Valid | Epoch[222/600] Iteration[007/008] Valid loss: 0.4835
2023-02-06 11:58:04 | Valid | Epoch[222/600] Iteration[008/008] Valid loss: 0.4755
2023-02-06 11:58:04 | Valid | Epoch[222/600] MIou: 0.8995743560594962
2023-02-06 11:58:04 | Valid | Epoch[222/600] Pixel Accuracy: 0.9805043538411459
2023-02-06 11:58:04 | Valid | Epoch[222/600] Mean Pixel Accuracy: 0.9834447871392697
2023-02-06 11:58:04 | Stage | Epoch[222/600] Train loss:0.0219
2023-02-06 11:58:04 | Stage | Epoch[222/600] Valid loss:0.4755
2023-02-06 11:58:04 | Stage | Epoch[222/600] LR:0.01

2023-02-06 11:58:04 | Train | Epoch[223/600] Iteration[001/030] Train loss: 0.0240
2023-02-06 11:58:04 | Train | Epoch[223/600] Iteration[002/030] Train loss: 0.0231
2023-02-06 11:58:04 | Train | Epoch[223/600] Iteration[003/030] Train loss: 0.0230
2023-02-06 11:58:04 | Train | Epoch[223/600] Iteration[004/030] Train loss: 0.0229
2023-02-06 11:58:04 | Train | Epoch[223/600] Iteration[005/030] Train loss: 0.0230
2023-02-06 11:58:04 | Train | Epoch[223/600] Iteration[006/030] Train loss: 0.0228
2023-02-06 11:58:04 | Train | Epoch[223/600] Iteration[007/030] Train loss: 0.0224
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[008/030] Train loss: 0.0221
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[009/030] Train loss: 0.0218
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[010/030] Train loss: 0.0219
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[011/030] Train loss: 0.0218
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[012/030] Train loss: 0.0219
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[013/030] Train loss: 0.0217
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[016/030] Train loss: 0.0217
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[017/030] Train loss: 0.0219
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[018/030] Train loss: 0.0217
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[019/030] Train loss: 0.0218
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[020/030] Train loss: 0.0218
2023-02-06 11:58:05 | Train | Epoch[223/600] Iteration[021/030] Train loss: 0.0219
2023-02-06 11:58:06 | Train | Epoch[223/600] Iteration[022/030] Train loss: 0.0219
2023-02-06 11:58:06 | Train | Epoch[223/600] Iteration[023/030] Train loss: 0.0218
2023-02-06 11:58:06 | Train | Epoch[223/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:58:06 | Train | Epoch[223/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:58:06 | Train | Epoch[223/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 11:58:06 | Train | Epoch[223/600] Iteration[027/030] Train loss: 0.0219
2023-02-06 11:58:06 | Train | Epoch[223/600] Iteration[028/030] Train loss: 0.0219
2023-02-06 11:58:06 | Train | Epoch[223/600] Iteration[029/030] Train loss: 0.0219
2023-02-06 11:58:06 | Train | Epoch[223/600] Iteration[030/030] Train loss: 0.0219
2023-02-06 11:58:06 | Valid | Epoch[223/600] Iteration[001/008] Valid loss: 0.0723
2023-02-06 11:58:06 | Valid | Epoch[223/600] Iteration[002/008] Valid loss: 0.0542
2023-02-06 11:58:06 | Valid | Epoch[223/600] Iteration[003/008] Valid loss: 0.0530
2023-02-06 11:58:07 | Valid | Epoch[223/600] Iteration[004/008] Valid loss: 0.0498
2023-02-06 11:58:07 | Valid | Epoch[223/600] Iteration[005/008] Valid loss: 0.0500
2023-02-06 11:58:07 | Valid | Epoch[223/600] Iteration[006/008] Valid loss: 0.0490
2023-02-06 11:58:07 | Valid | Epoch[223/600] Iteration[007/008] Valid loss: 0.0504
2023-02-06 11:58:07 | Valid | Epoch[223/600] Iteration[008/008] Valid loss: 0.0492
2023-02-06 11:58:07 | Valid | Epoch[223/600] MIou: 0.9062954887950565
2023-02-06 11:58:07 | Valid | Epoch[223/600] Pixel Accuracy: 0.9842249552408854
2023-02-06 11:58:07 | Valid | Epoch[223/600] Mean Pixel Accuracy: 0.9241457264690063
2023-02-06 11:58:07 | Stage | Epoch[223/600] Train loss:0.0219
2023-02-06 11:58:07 | Stage | Epoch[223/600] Valid loss:0.0492
2023-02-06 11:58:07 | Stage | Epoch[223/600] LR:0.01

2023-02-06 11:58:07 | Train | Epoch[224/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 11:58:07 | Train | Epoch[224/600] Iteration[002/030] Train loss: 0.0236
2023-02-06 11:58:07 | Train | Epoch[224/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 11:58:07 | Train | Epoch[224/600] Iteration[004/030] Train loss: 0.0225
2023-02-06 11:58:07 | Train | Epoch[224/600] Iteration[005/030] Train loss: 0.0220
2023-02-06 11:58:07 | Train | Epoch[224/600] Iteration[006/030] Train loss: 0.0220
2023-02-06 11:58:07 | Train | Epoch[224/600] Iteration[007/030] Train loss: 0.0222
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[008/030] Train loss: 0.0226
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[010/030] Train loss: 0.0230
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[011/030] Train loss: 0.0229
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[012/030] Train loss: 0.0229
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[014/030] Train loss: 0.0227
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[016/030] Train loss: 0.0226
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[017/030] Train loss: 0.0225
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[018/030] Train loss: 0.0225
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[019/030] Train loss: 0.0226
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[020/030] Train loss: 0.0226
2023-02-06 11:58:08 | Train | Epoch[224/600] Iteration[021/030] Train loss: 0.0226
2023-02-06 11:58:09 | Train | Epoch[224/600] Iteration[022/030] Train loss: 0.0225
2023-02-06 11:58:09 | Train | Epoch[224/600] Iteration[023/030] Train loss: 0.0226
2023-02-06 11:58:09 | Train | Epoch[224/600] Iteration[024/030] Train loss: 0.0226
2023-02-06 11:58:09 | Train | Epoch[224/600] Iteration[025/030] Train loss: 0.0225
2023-02-06 11:58:09 | Train | Epoch[224/600] Iteration[026/030] Train loss: 0.0225
2023-02-06 11:58:09 | Train | Epoch[224/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:58:09 | Train | Epoch[224/600] Iteration[028/030] Train loss: 0.0224
2023-02-06 11:58:09 | Train | Epoch[224/600] Iteration[029/030] Train loss: 0.0223
2023-02-06 11:58:09 | Train | Epoch[224/600] Iteration[030/030] Train loss: 0.0224
2023-02-06 11:58:09 | Valid | Epoch[224/600] Iteration[001/008] Valid loss: 0.0491
2023-02-06 11:58:09 | Valid | Epoch[224/600] Iteration[002/008] Valid loss: 0.0474
2023-02-06 11:58:09 | Valid | Epoch[224/600] Iteration[003/008] Valid loss: 0.0474
2023-02-06 11:58:10 | Valid | Epoch[224/600] Iteration[004/008] Valid loss: 0.0456
2023-02-06 11:58:10 | Valid | Epoch[224/600] Iteration[005/008] Valid loss: 0.0456
2023-02-06 11:58:10 | Valid | Epoch[224/600] Iteration[006/008] Valid loss: 0.0451
2023-02-06 11:58:10 | Valid | Epoch[224/600] Iteration[007/008] Valid loss: 0.0452
2023-02-06 11:58:10 | Valid | Epoch[224/600] Iteration[008/008] Valid loss: 0.0458
2023-02-06 11:58:10 | Valid | Epoch[224/600] MIou: 0.8632404765025505
2023-02-06 11:58:10 | Valid | Epoch[224/600] Pixel Accuracy: 0.9773000081380209
2023-02-06 11:58:10 | Valid | Epoch[224/600] Mean Pixel Accuracy: 0.8782767921882837
2023-02-06 11:58:10 | Stage | Epoch[224/600] Train loss:0.0224
2023-02-06 11:58:10 | Stage | Epoch[224/600] Valid loss:0.0458
2023-02-06 11:58:10 | Stage | Epoch[224/600] LR:0.01

2023-02-06 11:58:10 | Train | Epoch[225/600] Iteration[001/030] Train loss: 0.0208
2023-02-06 11:58:10 | Train | Epoch[225/600] Iteration[002/030] Train loss: 0.0205
2023-02-06 11:58:10 | Train | Epoch[225/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:58:10 | Train | Epoch[225/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:58:10 | Train | Epoch[225/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:58:10 | Train | Epoch[225/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[014/030] Train loss: 0.0210
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[016/030] Train loss: 0.0211
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[017/030] Train loss: 0.0210
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[018/030] Train loss: 0.0210
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[019/030] Train loss: 0.0210
2023-02-06 11:58:11 | Train | Epoch[225/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:58:12 | Train | Epoch[225/600] Iteration[021/030] Train loss: 0.0211
2023-02-06 11:58:12 | Train | Epoch[225/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:58:12 | Train | Epoch[225/600] Iteration[023/030] Train loss: 0.0211
2023-02-06 11:58:12 | Train | Epoch[225/600] Iteration[024/030] Train loss: 0.0211
2023-02-06 11:58:12 | Train | Epoch[225/600] Iteration[025/030] Train loss: 0.0211
2023-02-06 11:58:12 | Train | Epoch[225/600] Iteration[026/030] Train loss: 0.0212
2023-02-06 11:58:12 | Train | Epoch[225/600] Iteration[027/030] Train loss: 0.0211
2023-02-06 11:58:12 | Train | Epoch[225/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:58:12 | Train | Epoch[225/600] Iteration[029/030] Train loss: 0.0212
2023-02-06 11:58:12 | Train | Epoch[225/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 11:58:13 | Valid | Epoch[225/600] Iteration[001/008] Valid loss: 0.0589
2023-02-06 11:58:13 | Valid | Epoch[225/600] Iteration[002/008] Valid loss: 0.0496
2023-02-06 11:58:13 | Valid | Epoch[225/600] Iteration[003/008] Valid loss: 0.0529
2023-02-06 11:58:13 | Valid | Epoch[225/600] Iteration[004/008] Valid loss: 0.0486
2023-02-06 11:58:13 | Valid | Epoch[225/600] Iteration[005/008] Valid loss: 0.0478
2023-02-06 11:58:13 | Valid | Epoch[225/600] Iteration[006/008] Valid loss: 0.0463
2023-02-06 11:58:13 | Valid | Epoch[225/600] Iteration[007/008] Valid loss: 0.0451
2023-02-06 11:58:13 | Valid | Epoch[225/600] Iteration[008/008] Valid loss: 0.0452
2023-02-06 11:58:13 | Valid | Epoch[225/600] MIou: 0.8710910514673761
2023-02-06 11:58:13 | Valid | Epoch[225/600] Pixel Accuracy: 0.9787000020345052
2023-02-06 11:58:13 | Valid | Epoch[225/600] Mean Pixel Accuracy: 0.8838143231191711
2023-02-06 11:58:13 | Stage | Epoch[225/600] Train loss:0.0214
2023-02-06 11:58:13 | Stage | Epoch[225/600] Valid loss:0.0452
2023-02-06 11:58:13 | Stage | Epoch[225/600] LR:0.01

2023-02-06 11:58:13 | Train | Epoch[226/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 11:58:13 | Train | Epoch[226/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:58:13 | Train | Epoch[226/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:58:13 | Train | Epoch[226/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:58:13 | Train | Epoch[226/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[009/030] Train loss: 0.0211
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[012/030] Train loss: 0.0212
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[013/030] Train loss: 0.0210
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[016/030] Train loss: 0.0208
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[017/030] Train loss: 0.0208
2023-02-06 11:58:14 | Train | Epoch[226/600] Iteration[018/030] Train loss: 0.0210
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[019/030] Train loss: 0.0210
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[021/030] Train loss: 0.0210
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[022/030] Train loss: 0.0212
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[024/030] Train loss: 0.0212
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[025/030] Train loss: 0.0213
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[026/030] Train loss: 0.0213
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[027/030] Train loss: 0.0214
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[028/030] Train loss: 0.0213
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:58:15 | Train | Epoch[226/600] Iteration[030/030] Train loss: 0.0213
2023-02-06 11:58:16 | Valid | Epoch[226/600] Iteration[001/008] Valid loss: 0.0751
2023-02-06 11:58:16 | Valid | Epoch[226/600] Iteration[002/008] Valid loss: 0.0543
2023-02-06 11:58:16 | Valid | Epoch[226/600] Iteration[003/008] Valid loss: 0.0546
2023-02-06 11:58:16 | Valid | Epoch[226/600] Iteration[004/008] Valid loss: 0.0483
2023-02-06 11:58:16 | Valid | Epoch[226/600] Iteration[005/008] Valid loss: 0.0477
2023-02-06 11:58:16 | Valid | Epoch[226/600] Iteration[006/008] Valid loss: 0.0451
2023-02-06 11:58:16 | Valid | Epoch[226/600] Iteration[007/008] Valid loss: 0.0455
2023-02-06 11:58:16 | Valid | Epoch[226/600] Iteration[008/008] Valid loss: 0.0439
2023-02-06 11:58:16 | Valid | Epoch[226/600] MIou: 0.9301226509517497
2023-02-06 11:58:16 | Valid | Epoch[226/600] Pixel Accuracy: 0.9882634480794271
2023-02-06 11:58:16 | Valid | Epoch[226/600] Mean Pixel Accuracy: 0.9455200188086157
2023-02-06 11:58:16 | Stage | Epoch[226/600] Train loss:0.0213
2023-02-06 11:58:16 | Stage | Epoch[226/600] Valid loss:0.0439
2023-02-06 11:58:16 | Stage | Epoch[226/600] LR:0.01

2023-02-06 11:58:16 | Train | Epoch[227/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 11:58:16 | Train | Epoch[227/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 11:58:16 | Train | Epoch[227/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:58:16 | Train | Epoch[227/600] Iteration[004/030] Train loss: 0.0226
2023-02-06 11:58:16 | Train | Epoch[227/600] Iteration[005/030] Train loss: 0.0224
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[006/030] Train loss: 0.0222
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[007/030] Train loss: 0.0223
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[008/030] Train loss: 0.0220
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[009/030] Train loss: 0.0224
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[011/030] Train loss: 0.0222
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[012/030] Train loss: 0.0222
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[013/030] Train loss: 0.0220
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[014/030] Train loss: 0.0221
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[015/030] Train loss: 0.0219
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[016/030] Train loss: 0.0220
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[018/030] Train loss: 0.0219
2023-02-06 11:58:17 | Train | Epoch[227/600] Iteration[019/030] Train loss: 0.0218
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[020/030] Train loss: 0.0218
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[021/030] Train loss: 0.0219
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[022/030] Train loss: 0.0218
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[023/030] Train loss: 0.0218
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[027/030] Train loss: 0.0218
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[028/030] Train loss: 0.0219
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[029/030] Train loss: 0.0218
2023-02-06 11:58:18 | Train | Epoch[227/600] Iteration[030/030] Train loss: 0.0219
2023-02-06 11:58:18 | Valid | Epoch[227/600] Iteration[001/008] Valid loss: 0.0580
2023-02-06 11:58:19 | Valid | Epoch[227/600] Iteration[002/008] Valid loss: 0.0568
2023-02-06 11:58:19 | Valid | Epoch[227/600] Iteration[003/008] Valid loss: 0.0590
2023-02-06 11:58:19 | Valid | Epoch[227/600] Iteration[004/008] Valid loss: 0.0569
2023-02-06 11:58:19 | Valid | Epoch[227/600] Iteration[005/008] Valid loss: 0.0580
2023-02-06 11:58:19 | Valid | Epoch[227/600] Iteration[006/008] Valid loss: 0.0568
2023-02-06 11:58:19 | Valid | Epoch[227/600] Iteration[007/008] Valid loss: 0.0554
2023-02-06 11:58:19 | Valid | Epoch[227/600] Iteration[008/008] Valid loss: 0.0567
2023-02-06 11:58:19 | Valid | Epoch[227/600] MIou: 0.8250131834019403
2023-02-06 11:58:19 | Valid | Epoch[227/600] Pixel Accuracy: 0.9711265563964844
2023-02-06 11:58:19 | Valid | Epoch[227/600] Mean Pixel Accuracy: 0.840835267799918
2023-02-06 11:58:19 | Stage | Epoch[227/600] Train loss:0.0219
2023-02-06 11:58:19 | Stage | Epoch[227/600] Valid loss:0.0567
2023-02-06 11:58:19 | Stage | Epoch[227/600] LR:0.01

2023-02-06 11:58:19 | Train | Epoch[228/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 11:58:19 | Train | Epoch[228/600] Iteration[002/030] Train loss: 0.0219
2023-02-06 11:58:19 | Train | Epoch[228/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:58:19 | Train | Epoch[228/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:58:19 | Train | Epoch[228/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 11:58:19 | Train | Epoch[228/600] Iteration[006/030] Train loss: 0.0207
2023-02-06 11:58:19 | Train | Epoch[228/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[012/030] Train loss: 0.0215
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[014/030] Train loss: 0.0215
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[015/030] Train loss: 0.0214
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[016/030] Train loss: 0.0213
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[018/030] Train loss: 0.0212
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[019/030] Train loss: 0.0210
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:58:20 | Train | Epoch[228/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:58:21 | Train | Epoch[228/600] Iteration[022/030] Train loss: 0.0212
2023-02-06 11:58:21 | Train | Epoch[228/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:58:21 | Train | Epoch[228/600] Iteration[024/030] Train loss: 0.0213
2023-02-06 11:58:21 | Train | Epoch[228/600] Iteration[025/030] Train loss: 0.0213
2023-02-06 11:58:21 | Train | Epoch[228/600] Iteration[026/030] Train loss: 0.0213
2023-02-06 11:58:21 | Train | Epoch[228/600] Iteration[027/030] Train loss: 0.0213
2023-02-06 11:58:21 | Train | Epoch[228/600] Iteration[028/030] Train loss: 0.0214
2023-02-06 11:58:21 | Train | Epoch[228/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:58:21 | Train | Epoch[228/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 11:58:21 | Valid | Epoch[228/600] Iteration[001/008] Valid loss: 0.0694
2023-02-06 11:58:21 | Valid | Epoch[228/600] Iteration[002/008] Valid loss: 0.0509
2023-02-06 11:58:21 | Valid | Epoch[228/600] Iteration[003/008] Valid loss: 0.0473
2023-02-06 11:58:21 | Valid | Epoch[228/600] Iteration[004/008] Valid loss: 0.0431
2023-02-06 11:58:22 | Valid | Epoch[228/600] Iteration[005/008] Valid loss: 0.0425
2023-02-06 11:58:22 | Valid | Epoch[228/600] Iteration[006/008] Valid loss: 0.0406
2023-02-06 11:58:22 | Valid | Epoch[228/600] Iteration[007/008] Valid loss: 0.0413
2023-02-06 11:58:22 | Valid | Epoch[228/600] Iteration[008/008] Valid loss: 0.0401
2023-02-06 11:58:22 | Valid | Epoch[228/600] MIou: 0.9239082968741299
2023-02-06 11:58:22 | Valid | Epoch[228/600] Pixel Accuracy: 0.9872652689615885
2023-02-06 11:58:22 | Valid | Epoch[228/600] Mean Pixel Accuracy: 0.9381173272895835
2023-02-06 11:58:22 | Stage | Epoch[228/600] Train loss:0.0214
2023-02-06 11:58:22 | Stage | Epoch[228/600] Valid loss:0.0401
2023-02-06 11:58:22 | Stage | Epoch[228/600] LR:0.01

2023-02-06 11:58:22 | Train | Epoch[229/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:58:22 | Train | Epoch[229/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 11:58:22 | Train | Epoch[229/600] Iteration[003/030] Train loss: 0.0196
2023-02-06 11:58:22 | Train | Epoch[229/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:58:22 | Train | Epoch[229/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:58:22 | Train | Epoch[229/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:58:22 | Train | Epoch[229/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[013/030] Train loss: 0.0206
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[016/030] Train loss: 0.0208
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:58:23 | Train | Epoch[229/600] Iteration[021/030] Train loss: 0.0214
2023-02-06 11:58:24 | Train | Epoch[229/600] Iteration[022/030] Train loss: 0.0214
2023-02-06 11:58:24 | Train | Epoch[229/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 11:58:24 | Train | Epoch[229/600] Iteration[024/030] Train loss: 0.0212
2023-02-06 11:58:24 | Train | Epoch[229/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:58:24 | Train | Epoch[229/600] Iteration[026/030] Train loss: 0.0212
2023-02-06 11:58:24 | Train | Epoch[229/600] Iteration[027/030] Train loss: 0.0213
2023-02-06 11:58:24 | Train | Epoch[229/600] Iteration[028/030] Train loss: 0.0213
2023-02-06 11:58:24 | Train | Epoch[229/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:58:24 | Train | Epoch[229/600] Iteration[030/030] Train loss: 0.0212
2023-02-06 11:58:24 | Valid | Epoch[229/600] Iteration[001/008] Valid loss: 1.0856
2023-02-06 11:58:24 | Valid | Epoch[229/600] Iteration[002/008] Valid loss: 1.0733
2023-02-06 11:58:24 | Valid | Epoch[229/600] Iteration[003/008] Valid loss: 1.0970
2023-02-06 11:58:24 | Valid | Epoch[229/600] Iteration[004/008] Valid loss: 1.1297
2023-02-06 11:58:24 | Valid | Epoch[229/600] Iteration[005/008] Valid loss: 1.1641
2023-02-06 11:58:25 | Valid | Epoch[229/600] Iteration[006/008] Valid loss: 1.1364
2023-02-06 11:58:25 | Valid | Epoch[229/600] Iteration[007/008] Valid loss: 1.1858
2023-02-06 11:58:25 | Valid | Epoch[229/600] Iteration[008/008] Valid loss: 1.2248
2023-02-06 11:58:25 | Valid | Epoch[229/600] MIou: 0.8429959830335415
2023-02-06 11:58:25 | Valid | Epoch[229/600] Pixel Accuracy: 0.965674082438151
2023-02-06 11:58:25 | Valid | Epoch[229/600] Mean Pixel Accuracy: 0.9791104013306781
2023-02-06 11:58:25 | Stage | Epoch[229/600] Train loss:0.0212
2023-02-06 11:58:25 | Stage | Epoch[229/600] Valid loss:1.2248
2023-02-06 11:58:25 | Stage | Epoch[229/600] LR:0.01

2023-02-06 11:58:25 | Train | Epoch[230/600] Iteration[001/030] Train loss: 0.0250
2023-02-06 11:58:25 | Train | Epoch[230/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 11:58:25 | Train | Epoch[230/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 11:58:25 | Train | Epoch[230/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 11:58:25 | Train | Epoch[230/600] Iteration[005/030] Train loss: 0.0236
2023-02-06 11:58:25 | Train | Epoch[230/600] Iteration[006/030] Train loss: 0.0231
2023-02-06 11:58:25 | Train | Epoch[230/600] Iteration[007/030] Train loss: 0.0226
2023-02-06 11:58:25 | Train | Epoch[230/600] Iteration[008/030] Train loss: 0.0224
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[009/030] Train loss: 0.0224
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[011/030] Train loss: 0.0221
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[012/030] Train loss: 0.0221
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[013/030] Train loss: 0.0221
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[014/030] Train loss: 0.0221
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[015/030] Train loss: 0.0221
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[016/030] Train loss: 0.0221
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[017/030] Train loss: 0.0222
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[018/030] Train loss: 0.0222
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[019/030] Train loss: 0.0221
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[020/030] Train loss: 0.0220
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[021/030] Train loss: 0.0221
2023-02-06 11:58:26 | Train | Epoch[230/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:58:27 | Train | Epoch[230/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:58:27 | Train | Epoch[230/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:58:27 | Train | Epoch[230/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:58:27 | Train | Epoch[230/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:58:27 | Train | Epoch[230/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:58:27 | Train | Epoch[230/600] Iteration[028/030] Train loss: 0.0218
2023-02-06 11:58:27 | Train | Epoch[230/600] Iteration[029/030] Train loss: 0.0219
2023-02-06 11:58:27 | Train | Epoch[230/600] Iteration[030/030] Train loss: 0.0218
2023-02-06 11:58:27 | Valid | Epoch[230/600] Iteration[001/008] Valid loss: 0.0574
2023-02-06 11:58:27 | Valid | Epoch[230/600] Iteration[002/008] Valid loss: 0.0455
2023-02-06 11:58:27 | Valid | Epoch[230/600] Iteration[003/008] Valid loss: 0.0439
2023-02-06 11:58:27 | Valid | Epoch[230/600] Iteration[004/008] Valid loss: 0.0404
2023-02-06 11:58:27 | Valid | Epoch[230/600] Iteration[005/008] Valid loss: 0.0397
2023-02-06 11:58:27 | Valid | Epoch[230/600] Iteration[006/008] Valid loss: 0.0386
2023-02-06 11:58:27 | Valid | Epoch[230/600] Iteration[007/008] Valid loss: 0.0394
2023-02-06 11:58:27 | Valid | Epoch[230/600] Iteration[008/008] Valid loss: 0.0391
2023-02-06 11:58:28 | Valid | Epoch[230/600] MIou: 0.910531993828529
2023-02-06 11:58:28 | Valid | Epoch[230/600] Pixel Accuracy: 0.9850718180338541
2023-02-06 11:58:28 | Valid | Epoch[230/600] Mean Pixel Accuracy: 0.9243258771598029
2023-02-06 11:58:28 | Stage | Epoch[230/600] Train loss:0.0218
2023-02-06 11:58:28 | Stage | Epoch[230/600] Valid loss:0.0391
2023-02-06 11:58:28 | Stage | Epoch[230/600] LR:0.01

2023-02-06 11:58:28 | Train | Epoch[231/600] Iteration[001/030] Train loss: 0.0226
2023-02-06 11:58:28 | Train | Epoch[231/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:58:28 | Train | Epoch[231/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:58:28 | Train | Epoch[231/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:58:28 | Train | Epoch[231/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 11:58:28 | Train | Epoch[231/600] Iteration[006/030] Train loss: 0.0204
2023-02-06 11:58:28 | Train | Epoch[231/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:58:28 | Train | Epoch[231/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:58:28 | Train | Epoch[231/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:58:28 | Train | Epoch[231/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[011/030] Train loss: 0.0208
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[014/030] Train loss: 0.0210
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[015/030] Train loss: 0.0211
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[019/030] Train loss: 0.0210
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[020/030] Train loss: 0.0209
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[021/030] Train loss: 0.0209
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[022/030] Train loss: 0.0209
2023-02-06 11:58:29 | Train | Epoch[231/600] Iteration[023/030] Train loss: 0.0209
2023-02-06 11:58:30 | Train | Epoch[231/600] Iteration[024/030] Train loss: 0.0209
2023-02-06 11:58:30 | Train | Epoch[231/600] Iteration[025/030] Train loss: 0.0209
2023-02-06 11:58:30 | Train | Epoch[231/600] Iteration[026/030] Train loss: 0.0210
2023-02-06 11:58:30 | Train | Epoch[231/600] Iteration[027/030] Train loss: 0.0210
2023-02-06 11:58:30 | Train | Epoch[231/600] Iteration[028/030] Train loss: 0.0211
2023-02-06 11:58:30 | Train | Epoch[231/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 11:58:30 | Train | Epoch[231/600] Iteration[030/030] Train loss: 0.0212
2023-02-06 11:58:30 | Valid | Epoch[231/600] Iteration[001/008] Valid loss: 0.0512
2023-02-06 11:58:30 | Valid | Epoch[231/600] Iteration[002/008] Valid loss: 0.0442
2023-02-06 11:58:30 | Valid | Epoch[231/600] Iteration[003/008] Valid loss: 0.0442
2023-02-06 11:58:30 | Valid | Epoch[231/600] Iteration[004/008] Valid loss: 0.0416
2023-02-06 11:58:30 | Valid | Epoch[231/600] Iteration[005/008] Valid loss: 0.0417
2023-02-06 11:58:30 | Valid | Epoch[231/600] Iteration[006/008] Valid loss: 0.0405
2023-02-06 11:58:30 | Valid | Epoch[231/600] Iteration[007/008] Valid loss: 0.0400
2023-02-06 11:58:30 | Valid | Epoch[231/600] Iteration[008/008] Valid loss: 0.0402
2023-02-06 11:58:31 | Valid | Epoch[231/600] MIou: 0.8900297874220614
2023-02-06 11:58:31 | Valid | Epoch[231/600] Pixel Accuracy: 0.9818064371744791
2023-02-06 11:58:31 | Valid | Epoch[231/600] Mean Pixel Accuracy: 0.901791402258352
2023-02-06 11:58:31 | Stage | Epoch[231/600] Train loss:0.0212
2023-02-06 11:58:31 | Stage | Epoch[231/600] Valid loss:0.0402
2023-02-06 11:58:31 | Stage | Epoch[231/600] LR:0.01

2023-02-06 11:58:31 | Train | Epoch[232/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 11:58:31 | Train | Epoch[232/600] Iteration[002/030] Train loss: 0.0213
2023-02-06 11:58:31 | Train | Epoch[232/600] Iteration[003/030] Train loss: 0.0213
2023-02-06 11:58:31 | Train | Epoch[232/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:58:31 | Train | Epoch[232/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:58:31 | Train | Epoch[232/600] Iteration[006/030] Train loss: 0.0207
2023-02-06 11:58:31 | Train | Epoch[232/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:58:31 | Train | Epoch[232/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:58:31 | Train | Epoch[232/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[019/030] Train loss: 0.0210
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[021/030] Train loss: 0.0210
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[022/030] Train loss: 0.0209
2023-02-06 11:58:32 | Train | Epoch[232/600] Iteration[023/030] Train loss: 0.0210
2023-02-06 11:58:33 | Train | Epoch[232/600] Iteration[024/030] Train loss: 0.0211
2023-02-06 11:58:33 | Train | Epoch[232/600] Iteration[025/030] Train loss: 0.0211
2023-02-06 11:58:33 | Train | Epoch[232/600] Iteration[026/030] Train loss: 0.0213
2023-02-06 11:58:33 | Train | Epoch[232/600] Iteration[027/030] Train loss: 0.0214
2023-02-06 11:58:33 | Train | Epoch[232/600] Iteration[028/030] Train loss: 0.0214
2023-02-06 11:58:33 | Train | Epoch[232/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:58:33 | Train | Epoch[232/600] Iteration[030/030] Train loss: 0.0215
2023-02-06 11:58:33 | Valid | Epoch[232/600] Iteration[001/008] Valid loss: 0.0910
2023-02-06 11:58:33 | Valid | Epoch[232/600] Iteration[002/008] Valid loss: 0.0710
2023-02-06 11:58:33 | Valid | Epoch[232/600] Iteration[003/008] Valid loss: 0.0732
2023-02-06 11:58:33 | Valid | Epoch[232/600] Iteration[004/008] Valid loss: 0.0694
2023-02-06 11:58:33 | Valid | Epoch[232/600] Iteration[005/008] Valid loss: 0.0686
2023-02-06 11:58:33 | Valid | Epoch[232/600] Iteration[006/008] Valid loss: 0.0662
2023-02-06 11:58:33 | Valid | Epoch[232/600] Iteration[007/008] Valid loss: 0.0676
2023-02-06 11:58:33 | Valid | Epoch[232/600] Iteration[008/008] Valid loss: 0.0644
2023-02-06 11:58:34 | Valid | Epoch[232/600] MIou: 0.9128146818949336
2023-02-06 11:58:34 | Valid | Epoch[232/600] Pixel Accuracy: 0.985260009765625
2023-02-06 11:58:34 | Valid | Epoch[232/600] Mean Pixel Accuracy: 0.9321139668344081
2023-02-06 11:58:34 | Stage | Epoch[232/600] Train loss:0.0215
2023-02-06 11:58:34 | Stage | Epoch[232/600] Valid loss:0.0644
2023-02-06 11:58:34 | Stage | Epoch[232/600] LR:0.01

2023-02-06 11:58:34 | Train | Epoch[233/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 11:58:34 | Train | Epoch[233/600] Iteration[002/030] Train loss: 0.0219
2023-02-06 11:58:34 | Train | Epoch[233/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:58:34 | Train | Epoch[233/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:58:34 | Train | Epoch[233/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:58:34 | Train | Epoch[233/600] Iteration[006/030] Train loss: 0.0214
2023-02-06 11:58:34 | Train | Epoch[233/600] Iteration[007/030] Train loss: 0.0212
2023-02-06 11:58:34 | Train | Epoch[233/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:58:34 | Train | Epoch[233/600] Iteration[009/030] Train loss: 0.0211
2023-02-06 11:58:34 | Train | Epoch[233/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[011/030] Train loss: 0.0208
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[012/030] Train loss: 0.0208
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[015/030] Train loss: 0.0206
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[018/030] Train loss: 0.0208
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[019/030] Train loss: 0.0208
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[021/030] Train loss: 0.0209
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[022/030] Train loss: 0.0210
2023-02-06 11:58:35 | Train | Epoch[233/600] Iteration[023/030] Train loss: 0.0210
2023-02-06 11:58:36 | Train | Epoch[233/600] Iteration[024/030] Train loss: 0.0209
2023-02-06 11:58:36 | Train | Epoch[233/600] Iteration[025/030] Train loss: 0.0211
2023-02-06 11:58:36 | Train | Epoch[233/600] Iteration[026/030] Train loss: 0.0211
2023-02-06 11:58:36 | Train | Epoch[233/600] Iteration[027/030] Train loss: 0.0212
2023-02-06 11:58:36 | Train | Epoch[233/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:58:36 | Train | Epoch[233/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:58:36 | Train | Epoch[233/600] Iteration[030/030] Train loss: 0.0213
2023-02-06 11:58:36 | Valid | Epoch[233/600] Iteration[001/008] Valid loss: 1.7982
2023-02-06 11:58:36 | Valid | Epoch[233/600] Iteration[002/008] Valid loss: 1.7141
2023-02-06 11:58:36 | Valid | Epoch[233/600] Iteration[003/008] Valid loss: 1.7757
2023-02-06 11:58:36 | Valid | Epoch[233/600] Iteration[004/008] Valid loss: 1.8414
2023-02-06 11:58:36 | Valid | Epoch[233/600] Iteration[005/008] Valid loss: 1.8838
2023-02-06 11:58:36 | Valid | Epoch[233/600] Iteration[006/008] Valid loss: 1.8531
2023-02-06 11:58:36 | Valid | Epoch[233/600] Iteration[007/008] Valid loss: 1.9022
2023-02-06 11:58:36 | Valid | Epoch[233/600] Iteration[008/008] Valid loss: 1.9695
2023-02-06 11:58:37 | Valid | Epoch[233/600] MIou: 0.8071526181747146
2023-02-06 11:58:37 | Valid | Epoch[233/600] Pixel Accuracy: 0.9544563293457031
2023-02-06 11:58:37 | Valid | Epoch[233/600] Mean Pixel Accuracy: 0.9741239735067175
2023-02-06 11:58:37 | Stage | Epoch[233/600] Train loss:0.0213
2023-02-06 11:58:37 | Stage | Epoch[233/600] Valid loss:1.9695
2023-02-06 11:58:37 | Stage | Epoch[233/600] LR:0.01

2023-02-06 11:58:37 | Train | Epoch[234/600] Iteration[001/030] Train loss: 0.0213
2023-02-06 11:58:37 | Train | Epoch[234/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 11:58:37 | Train | Epoch[234/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:58:37 | Train | Epoch[234/600] Iteration[004/030] Train loss: 0.0201
2023-02-06 11:58:37 | Train | Epoch[234/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 11:58:37 | Train | Epoch[234/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:58:37 | Train | Epoch[234/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:58:37 | Train | Epoch[234/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:58:37 | Train | Epoch[234/600] Iteration[009/030] Train loss: 0.0209
2023-02-06 11:58:37 | Train | Epoch[234/600] Iteration[010/030] Train loss: 0.0209
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[013/030] Train loss: 0.0210
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[014/030] Train loss: 0.0208
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[016/030] Train loss: 0.0209
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[018/030] Train loss: 0.0210
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[020/030] Train loss: 0.0211
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[021/030] Train loss: 0.0211
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[022/030] Train loss: 0.0210
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[023/030] Train loss: 0.0211
2023-02-06 11:58:38 | Train | Epoch[234/600] Iteration[024/030] Train loss: 0.0212
2023-02-06 11:58:39 | Train | Epoch[234/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:58:39 | Train | Epoch[234/600] Iteration[026/030] Train loss: 0.0213
2023-02-06 11:58:39 | Train | Epoch[234/600] Iteration[027/030] Train loss: 0.0212
2023-02-06 11:58:39 | Train | Epoch[234/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:58:39 | Train | Epoch[234/600] Iteration[029/030] Train loss: 0.0211
2023-02-06 11:58:39 | Train | Epoch[234/600] Iteration[030/030] Train loss: 0.0211
2023-02-06 11:58:39 | Valid | Epoch[234/600] Iteration[001/008] Valid loss: 0.1537
2023-02-06 11:58:39 | Valid | Epoch[234/600] Iteration[002/008] Valid loss: 0.1056
2023-02-06 11:58:39 | Valid | Epoch[234/600] Iteration[003/008] Valid loss: 0.0983
2023-02-06 11:58:39 | Valid | Epoch[234/600] Iteration[004/008] Valid loss: 0.0893
2023-02-06 11:58:39 | Valid | Epoch[234/600] Iteration[005/008] Valid loss: 0.0870
2023-02-06 11:58:39 | Valid | Epoch[234/600] Iteration[006/008] Valid loss: 0.0820
2023-02-06 11:58:39 | Valid | Epoch[234/600] Iteration[007/008] Valid loss: 0.0862
2023-02-06 11:58:39 | Valid | Epoch[234/600] Iteration[008/008] Valid loss: 0.0832
2023-02-06 11:58:39 | Valid | Epoch[234/600] MIou: 0.9386809329172683
2023-02-06 11:58:39 | Valid | Epoch[234/600] Pixel Accuracy: 0.9895095825195312
2023-02-06 11:58:39 | Valid | Epoch[234/600] Mean Pixel Accuracy: 0.9620244238658845
2023-02-06 11:58:39 | Stage | Epoch[234/600] Train loss:0.0211
2023-02-06 11:58:39 | Stage | Epoch[234/600] Valid loss:0.0832
2023-02-06 11:58:39 | Stage | Epoch[234/600] LR:0.01

2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[001/030] Train loss: 0.0213
2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[005/030] Train loss: 0.0209
2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[008/030] Train loss: 0.0214
2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[010/030] Train loss: 0.0209
2023-02-06 11:58:40 | Train | Epoch[235/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[015/030] Train loss: 0.0211
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[018/030] Train loss: 0.0212
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[020/030] Train loss: 0.0214
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[021/030] Train loss: 0.0214
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[022/030] Train loss: 0.0215
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[024/030] Train loss: 0.0217
2023-02-06 11:58:41 | Train | Epoch[235/600] Iteration[025/030] Train loss: 0.0217
2023-02-06 11:58:42 | Train | Epoch[235/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 11:58:42 | Train | Epoch[235/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 11:58:42 | Train | Epoch[235/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:58:42 | Train | Epoch[235/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:58:42 | Train | Epoch[235/600] Iteration[030/030] Train loss: 0.0215
2023-02-06 11:58:42 | Valid | Epoch[235/600] Iteration[001/008] Valid loss: 0.2370
2023-02-06 11:58:42 | Valid | Epoch[235/600] Iteration[002/008] Valid loss: 0.1945
2023-02-06 11:58:42 | Valid | Epoch[235/600] Iteration[003/008] Valid loss: 0.1859
2023-02-06 11:58:42 | Valid | Epoch[235/600] Iteration[004/008] Valid loss: 0.1887
2023-02-06 11:58:42 | Valid | Epoch[235/600] Iteration[005/008] Valid loss: 0.1926
2023-02-06 11:58:42 | Valid | Epoch[235/600] Iteration[006/008] Valid loss: 0.1856
2023-02-06 11:58:42 | Valid | Epoch[235/600] Iteration[007/008] Valid loss: 0.2054
2023-02-06 11:58:42 | Valid | Epoch[235/600] Iteration[008/008] Valid loss: 0.2037
2023-02-06 11:58:42 | Valid | Epoch[235/600] MIou: 0.920351632079428
2023-02-06 11:58:42 | Valid | Epoch[235/600] Pixel Accuracy: 0.9852485656738281
2023-02-06 11:58:42 | Valid | Epoch[235/600] Mean Pixel Accuracy: 0.9819374422869129
2023-02-06 11:58:42 | Stage | Epoch[235/600] Train loss:0.0215
2023-02-06 11:58:42 | Stage | Epoch[235/600] Valid loss:0.2037
2023-02-06 11:58:42 | Stage | Epoch[235/600] LR:0.01

2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[006/030] Train loss: 0.0199
2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:58:43 | Train | Epoch[236/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[012/030] Train loss: 0.0208
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[013/030] Train loss: 0.0210
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[016/030] Train loss: 0.0208
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[017/030] Train loss: 0.0208
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[018/030] Train loss: 0.0207
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[019/030] Train loss: 0.0207
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[020/030] Train loss: 0.0207
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[022/030] Train loss: 0.0208
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[023/030] Train loss: 0.0208
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[024/030] Train loss: 0.0207
2023-02-06 11:58:44 | Train | Epoch[236/600] Iteration[025/030] Train loss: 0.0208
2023-02-06 11:58:45 | Train | Epoch[236/600] Iteration[026/030] Train loss: 0.0208
2023-02-06 11:58:45 | Train | Epoch[236/600] Iteration[027/030] Train loss: 0.0208
2023-02-06 11:58:45 | Train | Epoch[236/600] Iteration[028/030] Train loss: 0.0209
2023-02-06 11:58:45 | Train | Epoch[236/600] Iteration[029/030] Train loss: 0.0209
2023-02-06 11:58:45 | Train | Epoch[236/600] Iteration[030/030] Train loss: 0.0210
2023-02-06 11:58:45 | Valid | Epoch[236/600] Iteration[001/008] Valid loss: 0.2458
2023-02-06 11:58:45 | Valid | Epoch[236/600] Iteration[002/008] Valid loss: 0.2160
2023-02-06 11:58:45 | Valid | Epoch[236/600] Iteration[003/008] Valid loss: 0.2061
2023-02-06 11:58:45 | Valid | Epoch[236/600] Iteration[004/008] Valid loss: 0.2007
2023-02-06 11:58:45 | Valid | Epoch[236/600] Iteration[005/008] Valid loss: 0.2095
2023-02-06 11:58:45 | Valid | Epoch[236/600] Iteration[006/008] Valid loss: 0.2029
2023-02-06 11:58:45 | Valid | Epoch[236/600] Iteration[007/008] Valid loss: 0.2190
2023-02-06 11:58:45 | Valid | Epoch[236/600] Iteration[008/008] Valid loss: 0.2221
2023-02-06 11:58:45 | Valid | Epoch[236/600] MIou: 0.923344325961289
2023-02-06 11:58:45 | Valid | Epoch[236/600] Pixel Accuracy: 0.98590087890625
2023-02-06 11:58:45 | Valid | Epoch[236/600] Mean Pixel Accuracy: 0.9815921891220977
2023-02-06 11:58:45 | Stage | Epoch[236/600] Train loss:0.0210
2023-02-06 11:58:45 | Stage | Epoch[236/600] Valid loss:0.2221
2023-02-06 11:58:45 | Stage | Epoch[236/600] LR:0.01

2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[001/030] Train loss: 0.0219
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[005/030] Train loss: 0.0209
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[008/030] Train loss: 0.0218
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[009/030] Train loss: 0.0217
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[011/030] Train loss: 0.0210
2023-02-06 11:58:46 | Train | Epoch[237/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[014/030] Train loss: 0.0216
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[015/030] Train loss: 0.0215
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[018/030] Train loss: 0.0214
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[019/030] Train loss: 0.0212
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[021/030] Train loss: 0.0213
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[024/030] Train loss: 0.0213
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[025/030] Train loss: 0.0213
2023-02-06 11:58:47 | Train | Epoch[237/600] Iteration[026/030] Train loss: 0.0212
2023-02-06 11:58:48 | Train | Epoch[237/600] Iteration[027/030] Train loss: 0.0213
2023-02-06 11:58:48 | Train | Epoch[237/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:58:48 | Train | Epoch[237/600] Iteration[029/030] Train loss: 0.0212
2023-02-06 11:58:48 | Train | Epoch[237/600] Iteration[030/030] Train loss: 0.0213
2023-02-06 11:58:48 | Valid | Epoch[237/600] Iteration[001/008] Valid loss: 0.3225
2023-02-06 11:58:48 | Valid | Epoch[237/600] Iteration[002/008] Valid loss: 0.3052
2023-02-06 11:58:48 | Valid | Epoch[237/600] Iteration[003/008] Valid loss: 0.2883
2023-02-06 11:58:48 | Valid | Epoch[237/600] Iteration[004/008] Valid loss: 0.2942
2023-02-06 11:58:48 | Valid | Epoch[237/600] Iteration[005/008] Valid loss: 0.2974
2023-02-06 11:58:48 | Valid | Epoch[237/600] Iteration[006/008] Valid loss: 0.2887
2023-02-06 11:58:48 | Valid | Epoch[237/600] Iteration[007/008] Valid loss: 0.3077
2023-02-06 11:58:48 | Valid | Epoch[237/600] Iteration[008/008] Valid loss: 0.3101
2023-02-06 11:58:48 | Valid | Epoch[237/600] MIou: 0.9097168580984543
2023-02-06 11:58:48 | Valid | Epoch[237/600] Pixel Accuracy: 0.9829126993815104
2023-02-06 11:58:48 | Valid | Epoch[237/600] Mean Pixel Accuracy: 0.981579259391131
2023-02-06 11:58:48 | Stage | Epoch[237/600] Train loss:0.0213
2023-02-06 11:58:48 | Stage | Epoch[237/600] Valid loss:0.3101
2023-02-06 11:58:48 | Stage | Epoch[237/600] LR:0.01

2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[004/030] Train loss: 0.0216
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[005/030] Train loss: 0.0217
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[006/030] Train loss: 0.0215
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:58:49 | Train | Epoch[238/600] Iteration[013/030] Train loss: 0.0210
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[014/030] Train loss: 0.0210
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[015/030] Train loss: 0.0210
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[016/030] Train loss: 0.0209
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[017/030] Train loss: 0.0208
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[018/030] Train loss: 0.0207
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[019/030] Train loss: 0.0207
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[020/030] Train loss: 0.0209
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[021/030] Train loss: 0.0210
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[022/030] Train loss: 0.0209
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[023/030] Train loss: 0.0209
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[024/030] Train loss: 0.0209
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[025/030] Train loss: 0.0209
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[026/030] Train loss: 0.0210
2023-02-06 11:58:50 | Train | Epoch[238/600] Iteration[027/030] Train loss: 0.0209
2023-02-06 11:58:51 | Train | Epoch[238/600] Iteration[028/030] Train loss: 0.0210
2023-02-06 11:58:51 | Train | Epoch[238/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 11:58:51 | Train | Epoch[238/600] Iteration[030/030] Train loss: 0.0210
2023-02-06 11:58:51 | Valid | Epoch[238/600] Iteration[001/008] Valid loss: 0.0764
2023-02-06 11:58:51 | Valid | Epoch[238/600] Iteration[002/008] Valid loss: 0.0763
2023-02-06 11:58:51 | Valid | Epoch[238/600] Iteration[003/008] Valid loss: 0.0795
2023-02-06 11:58:51 | Valid | Epoch[238/600] Iteration[004/008] Valid loss: 0.0772
2023-02-06 11:58:51 | Valid | Epoch[238/600] Iteration[005/008] Valid loss: 0.0779
2023-02-06 11:58:51 | Valid | Epoch[238/600] Iteration[006/008] Valid loss: 0.0764
2023-02-06 11:58:51 | Valid | Epoch[238/600] Iteration[007/008] Valid loss: 0.0746
2023-02-06 11:58:51 | Valid | Epoch[238/600] Iteration[008/008] Valid loss: 0.0769
2023-02-06 11:58:51 | Valid | Epoch[238/600] MIou: 0.7569142028692694
2023-02-06 11:58:51 | Valid | Epoch[238/600] Pixel Accuracy: 0.959875742594401
2023-02-06 11:58:51 | Valid | Epoch[238/600] Mean Pixel Accuracy: 0.7782084632981552
2023-02-06 11:58:51 | Stage | Epoch[238/600] Train loss:0.0210
2023-02-06 11:58:51 | Stage | Epoch[238/600] Valid loss:0.0769
2023-02-06 11:58:51 | Stage | Epoch[238/600] LR:0.01

2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:58:52 | Train | Epoch[239/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[016/030] Train loss: 0.0208
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[017/030] Train loss: 0.0208
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[018/030] Train loss: 0.0208
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[019/030] Train loss: 0.0208
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[021/030] Train loss: 0.0209
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[024/030] Train loss: 0.0213
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[026/030] Train loss: 0.0212
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[027/030] Train loss: 0.0212
2023-02-06 11:58:53 | Train | Epoch[239/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:58:54 | Train | Epoch[239/600] Iteration[029/030] Train loss: 0.0212
2023-02-06 11:58:54 | Train | Epoch[239/600] Iteration[030/030] Train loss: 0.0212
2023-02-06 11:58:54 | Valid | Epoch[239/600] Iteration[001/008] Valid loss: 0.2699
2023-02-06 11:58:54 | Valid | Epoch[239/600] Iteration[002/008] Valid loss: 0.2237
2023-02-06 11:58:54 | Valid | Epoch[239/600] Iteration[003/008] Valid loss: 0.2221
2023-02-06 11:58:54 | Valid | Epoch[239/600] Iteration[004/008] Valid loss: 0.2205
2023-02-06 11:58:54 | Valid | Epoch[239/600] Iteration[005/008] Valid loss: 0.2292
2023-02-06 11:58:54 | Valid | Epoch[239/600] Iteration[006/008] Valid loss: 0.2245
2023-02-06 11:58:54 | Valid | Epoch[239/600] Iteration[007/008] Valid loss: 0.2422
2023-02-06 11:58:54 | Valid | Epoch[239/600] Iteration[008/008] Valid loss: 0.2377
2023-02-06 11:58:54 | Valid | Epoch[239/600] MIou: 0.9196156990550093
2023-02-06 11:58:54 | Valid | Epoch[239/600] Pixel Accuracy: 0.9850807189941406
2023-02-06 11:58:54 | Valid | Epoch[239/600] Mean Pixel Accuracy: 0.9822256148839937
2023-02-06 11:58:54 | Stage | Epoch[239/600] Train loss:0.0212
2023-02-06 11:58:54 | Stage | Epoch[239/600] Valid loss:0.2377
2023-02-06 11:58:54 | Stage | Epoch[239/600] LR:0.01

2023-02-06 11:58:54 | Train | Epoch[240/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 11:58:54 | Train | Epoch[240/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[005/030] Train loss: 0.0209
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[013/030] Train loss: 0.0210
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[014/030] Train loss: 0.0210
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[015/030] Train loss: 0.0210
2023-02-06 11:58:55 | Train | Epoch[240/600] Iteration[016/030] Train loss: 0.0208
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[018/030] Train loss: 0.0207
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[019/030] Train loss: 0.0208
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[021/030] Train loss: 0.0207
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[022/030] Train loss: 0.0206
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[023/030] Train loss: 0.0207
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[024/030] Train loss: 0.0208
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[025/030] Train loss: 0.0208
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[026/030] Train loss: 0.0208
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[027/030] Train loss: 0.0208
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[028/030] Train loss: 0.0209
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 11:58:56 | Train | Epoch[240/600] Iteration[030/030] Train loss: 0.0210
2023-02-06 11:58:57 | Valid | Epoch[240/600] Iteration[001/008] Valid loss: 0.0475
2023-02-06 11:58:57 | Valid | Epoch[240/600] Iteration[002/008] Valid loss: 0.0463
2023-02-06 11:58:57 | Valid | Epoch[240/600] Iteration[003/008] Valid loss: 0.0472
2023-02-06 11:58:57 | Valid | Epoch[240/600] Iteration[004/008] Valid loss: 0.0447
2023-02-06 11:58:57 | Valid | Epoch[240/600] Iteration[005/008] Valid loss: 0.0441
2023-02-06 11:58:57 | Valid | Epoch[240/600] Iteration[006/008] Valid loss: 0.0438
2023-02-06 11:58:57 | Valid | Epoch[240/600] Iteration[007/008] Valid loss: 0.0437
2023-02-06 11:58:57 | Valid | Epoch[240/600] Iteration[008/008] Valid loss: 0.0443
2023-02-06 11:58:57 | Valid | Epoch[240/600] MIou: 0.8662823841770054
2023-02-06 11:58:57 | Valid | Epoch[240/600] Pixel Accuracy: 0.9778760274251302
2023-02-06 11:58:57 | Valid | Epoch[240/600] Mean Pixel Accuracy: 0.8798805126720597
2023-02-06 11:58:57 | Stage | Epoch[240/600] Train loss:0.0210
2023-02-06 11:58:57 | Stage | Epoch[240/600] Valid loss:0.0443
2023-02-06 11:58:57 | Stage | Epoch[240/600] LR:0.01

2023-02-06 11:58:57 | Train | Epoch[241/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 11:58:57 | Train | Epoch[241/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 11:58:57 | Train | Epoch[241/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[012/030] Train loss: 0.0206
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[013/030] Train loss: 0.0206
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:58:58 | Train | Epoch[241/600] Iteration[016/030] Train loss: 0.0210
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[018/030] Train loss: 0.0208
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[023/030] Train loss: 0.0206
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[024/030] Train loss: 0.0206
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[025/030] Train loss: 0.0206
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[026/030] Train loss: 0.0206
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[027/030] Train loss: 0.0208
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[028/030] Train loss: 0.0208
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[029/030] Train loss: 0.0208
2023-02-06 11:58:59 | Train | Epoch[241/600] Iteration[030/030] Train loss: 0.0207
2023-02-06 11:59:00 | Valid | Epoch[241/600] Iteration[001/008] Valid loss: 0.0674
2023-02-06 11:59:00 | Valid | Epoch[241/600] Iteration[002/008] Valid loss: 0.0673
2023-02-06 11:59:00 | Valid | Epoch[241/600] Iteration[003/008] Valid loss: 0.0705
2023-02-06 11:59:00 | Valid | Epoch[241/600] Iteration[004/008] Valid loss: 0.0685
2023-02-06 11:59:00 | Valid | Epoch[241/600] Iteration[005/008] Valid loss: 0.0697
2023-02-06 11:59:00 | Valid | Epoch[241/600] Iteration[006/008] Valid loss: 0.0681
2023-02-06 11:59:00 | Valid | Epoch[241/600] Iteration[007/008] Valid loss: 0.0664
2023-02-06 11:59:00 | Valid | Epoch[241/600] Iteration[008/008] Valid loss: 0.0688
2023-02-06 11:59:00 | Valid | Epoch[241/600] MIou: 0.7872292817190464
2023-02-06 11:59:00 | Valid | Epoch[241/600] Pixel Accuracy: 0.96490478515625
2023-02-06 11:59:00 | Valid | Epoch[241/600] Mean Pixel Accuracy: 0.8059223949736591
2023-02-06 11:59:00 | Stage | Epoch[241/600] Train loss:0.0207
2023-02-06 11:59:00 | Stage | Epoch[241/600] Valid loss:0.0688
2023-02-06 11:59:00 | Stage | Epoch[241/600] LR:0.01

2023-02-06 11:59:00 | Train | Epoch[242/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 11:59:00 | Train | Epoch[242/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:59:00 | Train | Epoch[242/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:59:01 | Train | Epoch[242/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[025/030] Train loss: 0.0205
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[027/030] Train loss: 0.0207
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[028/030] Train loss: 0.0207
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[029/030] Train loss: 0.0207
2023-02-06 11:59:02 | Train | Epoch[242/600] Iteration[030/030] Train loss: 0.0207
2023-02-06 11:59:03 | Valid | Epoch[242/600] Iteration[001/008] Valid loss: 0.0610
2023-02-06 11:59:03 | Valid | Epoch[242/600] Iteration[002/008] Valid loss: 0.0520
2023-02-06 11:59:03 | Valid | Epoch[242/600] Iteration[003/008] Valid loss: 0.0575
2023-02-06 11:59:03 | Valid | Epoch[242/600] Iteration[004/008] Valid loss: 0.0529
2023-02-06 11:59:03 | Valid | Epoch[242/600] Iteration[005/008] Valid loss: 0.0519
2023-02-06 11:59:03 | Valid | Epoch[242/600] Iteration[006/008] Valid loss: 0.0504
2023-02-06 11:59:03 | Valid | Epoch[242/600] Iteration[007/008] Valid loss: 0.0490
2023-02-06 11:59:03 | Valid | Epoch[242/600] Iteration[008/008] Valid loss: 0.0496
2023-02-06 11:59:03 | Valid | Epoch[242/600] MIou: 0.8538816743542303
2023-02-06 11:59:03 | Valid | Epoch[242/600] Pixel Accuracy: 0.9758529663085938
2023-02-06 11:59:03 | Valid | Epoch[242/600] Mean Pixel Accuracy: 0.8679897504304057
2023-02-06 11:59:03 | Stage | Epoch[242/600] Train loss:0.0207
2023-02-06 11:59:03 | Stage | Epoch[242/600] Valid loss:0.0496
2023-02-06 11:59:03 | Stage | Epoch[242/600] LR:0.01

2023-02-06 11:59:03 | Train | Epoch[243/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 11:59:03 | Train | Epoch[243/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:59:03 | Train | Epoch[243/600] Iteration[003/030] Train loss: 0.0208
2023-02-06 11:59:03 | Train | Epoch[243/600] Iteration[004/030] Train loss: 0.0202
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[015/030] Train loss: 0.0206
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 11:59:04 | Train | Epoch[243/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[022/030] Train loss: 0.0206
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[023/030] Train loss: 0.0207
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[024/030] Train loss: 0.0208
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[025/030] Train loss: 0.0207
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[026/030] Train loss: 0.0208
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[027/030] Train loss: 0.0208
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[028/030] Train loss: 0.0207
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[029/030] Train loss: 0.0208
2023-02-06 11:59:05 | Train | Epoch[243/600] Iteration[030/030] Train loss: 0.0210
2023-02-06 11:59:06 | Valid | Epoch[243/600] Iteration[001/008] Valid loss: 0.1862
2023-02-06 11:59:06 | Valid | Epoch[243/600] Iteration[002/008] Valid loss: 0.1501
2023-02-06 11:59:06 | Valid | Epoch[243/600] Iteration[003/008] Valid loss: 0.1414
2023-02-06 11:59:06 | Valid | Epoch[243/600] Iteration[004/008] Valid loss: 0.1437
2023-02-06 11:59:06 | Valid | Epoch[243/600] Iteration[005/008] Valid loss: 0.1465
2023-02-06 11:59:06 | Valid | Epoch[243/600] Iteration[006/008] Valid loss: 0.1411
2023-02-06 11:59:06 | Valid | Epoch[243/600] Iteration[007/008] Valid loss: 0.1550
2023-02-06 11:59:06 | Valid | Epoch[243/600] Iteration[008/008] Valid loss: 0.1497
2023-02-06 11:59:06 | Valid | Epoch[243/600] MIou: 0.9332027143861163
2023-02-06 11:59:06 | Valid | Epoch[243/600] Pixel Accuracy: 0.9880205790201823
2023-02-06 11:59:06 | Valid | Epoch[243/600] Mean Pixel Accuracy: 0.9791749003034131
2023-02-06 11:59:06 | Stage | Epoch[243/600] Train loss:0.0210
2023-02-06 11:59:06 | Stage | Epoch[243/600] Valid loss:0.1497
2023-02-06 11:59:06 | Stage | Epoch[243/600] LR:0.01

2023-02-06 11:59:06 | Train | Epoch[244/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 11:59:06 | Train | Epoch[244/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:59:06 | Train | Epoch[244/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[004/030] Train loss: 0.0213
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[005/030] Train loss: 0.0213
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[007/030] Train loss: 0.0216
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[008/030] Train loss: 0.0214
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[009/030] Train loss: 0.0213
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[012/030] Train loss: 0.0215
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[013/030] Train loss: 0.0213
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[014/030] Train loss: 0.0214
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[015/030] Train loss: 0.0213
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:59:07 | Train | Epoch[244/600] Iteration[017/030] Train loss: 0.0213
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[018/030] Train loss: 0.0213
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[020/030] Train loss: 0.0211
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[022/030] Train loss: 0.0210
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[023/030] Train loss: 0.0209
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[024/030] Train loss: 0.0209
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[025/030] Train loss: 0.0208
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[026/030] Train loss: 0.0210
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[027/030] Train loss: 0.0209
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[028/030] Train loss: 0.0208
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[029/030] Train loss: 0.0208
2023-02-06 11:59:08 | Train | Epoch[244/600] Iteration[030/030] Train loss: 0.0207
2023-02-06 11:59:09 | Valid | Epoch[244/600] Iteration[001/008] Valid loss: 0.3688
2023-02-06 11:59:09 | Valid | Epoch[244/600] Iteration[002/008] Valid loss: 0.3151
2023-02-06 11:59:09 | Valid | Epoch[244/600] Iteration[003/008] Valid loss: 0.3081
2023-02-06 11:59:09 | Valid | Epoch[244/600] Iteration[004/008] Valid loss: 0.3041
2023-02-06 11:59:09 | Valid | Epoch[244/600] Iteration[005/008] Valid loss: 0.3143
2023-02-06 11:59:09 | Valid | Epoch[244/600] Iteration[006/008] Valid loss: 0.3008
2023-02-06 11:59:09 | Valid | Epoch[244/600] Iteration[007/008] Valid loss: 0.3219
2023-02-06 11:59:09 | Valid | Epoch[244/600] Iteration[008/008] Valid loss: 0.3229
2023-02-06 11:59:09 | Valid | Epoch[244/600] MIou: 0.9118612239133589
2023-02-06 11:59:09 | Valid | Epoch[244/600] Pixel Accuracy: 0.9833768208821615
2023-02-06 11:59:09 | Valid | Epoch[244/600] Mean Pixel Accuracy: 0.9821006601656994
2023-02-06 11:59:09 | Stage | Epoch[244/600] Train loss:0.0207
2023-02-06 11:59:09 | Stage | Epoch[244/600] Valid loss:0.3229
2023-02-06 11:59:09 | Stage | Epoch[244/600] LR:0.01

2023-02-06 11:59:09 | Train | Epoch[245/600] Iteration[001/030] Train loss: 0.0172
2023-02-06 11:59:09 | Train | Epoch[245/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 11:59:09 | Train | Epoch[245/600] Iteration[003/030] Train loss: 0.0183
2023-02-06 11:59:09 | Train | Epoch[245/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[006/030] Train loss: 0.0207
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[013/030] Train loss: 0.0206
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:59:10 | Train | Epoch[245/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[021/030] Train loss: 0.0207
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[022/030] Train loss: 0.0207
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[023/030] Train loss: 0.0207
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[024/030] Train loss: 0.0208
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[025/030] Train loss: 0.0206
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[026/030] Train loss: 0.0207
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[027/030] Train loss: 0.0206
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[028/030] Train loss: 0.0207
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[029/030] Train loss: 0.0207
2023-02-06 11:59:11 | Train | Epoch[245/600] Iteration[030/030] Train loss: 0.0207
2023-02-06 11:59:12 | Valid | Epoch[245/600] Iteration[001/008] Valid loss: 0.0516
2023-02-06 11:59:12 | Valid | Epoch[245/600] Iteration[002/008] Valid loss: 0.0481
2023-02-06 11:59:12 | Valid | Epoch[245/600] Iteration[003/008] Valid loss: 0.0464
2023-02-06 11:59:12 | Valid | Epoch[245/600] Iteration[004/008] Valid loss: 0.0443
2023-02-06 11:59:12 | Valid | Epoch[245/600] Iteration[005/008] Valid loss: 0.0434
2023-02-06 11:59:12 | Valid | Epoch[245/600] Iteration[006/008] Valid loss: 0.0428
2023-02-06 11:59:12 | Valid | Epoch[245/600] Iteration[007/008] Valid loss: 0.0434
2023-02-06 11:59:12 | Valid | Epoch[245/600] Iteration[008/008] Valid loss: 0.0430
2023-02-06 11:59:12 | Valid | Epoch[245/600] MIou: 0.8955168858019775
2023-02-06 11:59:12 | Valid | Epoch[245/600] Pixel Accuracy: 0.9825388590494791
2023-02-06 11:59:12 | Valid | Epoch[245/600] Mean Pixel Accuracy: 0.910981866073632
2023-02-06 11:59:12 | Stage | Epoch[245/600] Train loss:0.0207
2023-02-06 11:59:12 | Stage | Epoch[245/600] Valid loss:0.0430
2023-02-06 11:59:12 | Stage | Epoch[245/600] LR:0.01

2023-02-06 11:59:12 | Train | Epoch[246/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 11:59:12 | Train | Epoch[246/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 11:59:12 | Train | Epoch[246/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 11:59:12 | Train | Epoch[246/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[007/030] Train loss: 0.0190
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[010/030] Train loss: 0.0193
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[017/030] Train loss: 0.0196
2023-02-06 11:59:13 | Train | Epoch[246/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:59:14 | Train | Epoch[246/600] Iteration[030/030] Train loss: 0.0204
2023-02-06 11:59:15 | Valid | Epoch[246/600] Iteration[001/008] Valid loss: 0.0626
2023-02-06 11:59:15 | Valid | Epoch[246/600] Iteration[002/008] Valid loss: 0.0627
2023-02-06 11:59:15 | Valid | Epoch[246/600] Iteration[003/008] Valid loss: 0.0655
2023-02-06 11:59:15 | Valid | Epoch[246/600] Iteration[004/008] Valid loss: 0.0632
2023-02-06 11:59:15 | Valid | Epoch[246/600] Iteration[005/008] Valid loss: 0.0637
2023-02-06 11:59:15 | Valid | Epoch[246/600] Iteration[006/008] Valid loss: 0.0621
2023-02-06 11:59:15 | Valid | Epoch[246/600] Iteration[007/008] Valid loss: 0.0605
2023-02-06 11:59:15 | Valid | Epoch[246/600] Iteration[008/008] Valid loss: 0.0622
2023-02-06 11:59:15 | Valid | Epoch[246/600] MIou: 0.8009919312067066
2023-02-06 11:59:15 | Valid | Epoch[246/600] Pixel Accuracy: 0.9671847025553385
2023-02-06 11:59:15 | Valid | Epoch[246/600] Mean Pixel Accuracy: 0.8184996169328981
2023-02-06 11:59:15 | Stage | Epoch[246/600] Train loss:0.0204
2023-02-06 11:59:15 | Stage | Epoch[246/600] Valid loss:0.0622
2023-02-06 11:59:15 | Stage | Epoch[246/600] LR:0.01

2023-02-06 11:59:15 | Train | Epoch[247/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:59:15 | Train | Epoch[247/600] Iteration[002/030] Train loss: 0.0197
2023-02-06 11:59:15 | Train | Epoch[247/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[004/030] Train loss: 0.0190
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[012/030] Train loss: 0.0208
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:59:16 | Train | Epoch[247/600] Iteration[016/030] Train loss: 0.0209
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[018/030] Train loss: 0.0209
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[019/030] Train loss: 0.0209
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[021/030] Train loss: 0.0208
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[022/030] Train loss: 0.0208
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[023/030] Train loss: 0.0209
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[024/030] Train loss: 0.0209
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[025/030] Train loss: 0.0208
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[026/030] Train loss: 0.0208
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[027/030] Train loss: 0.0207
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[028/030] Train loss: 0.0206
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[029/030] Train loss: 0.0207
2023-02-06 11:59:17 | Train | Epoch[247/600] Iteration[030/030] Train loss: 0.0207
2023-02-06 11:59:18 | Valid | Epoch[247/600] Iteration[001/008] Valid loss: 0.0797
2023-02-06 11:59:18 | Valid | Epoch[247/600] Iteration[002/008] Valid loss: 0.0648
2023-02-06 11:59:18 | Valid | Epoch[247/600] Iteration[003/008] Valid loss: 0.0677
2023-02-06 11:59:18 | Valid | Epoch[247/600] Iteration[004/008] Valid loss: 0.0617
2023-02-06 11:59:18 | Valid | Epoch[247/600] Iteration[005/008] Valid loss: 0.0604
2023-02-06 11:59:18 | Valid | Epoch[247/600] Iteration[006/008] Valid loss: 0.0571
2023-02-06 11:59:18 | Valid | Epoch[247/600] Iteration[007/008] Valid loss: 0.0579
2023-02-06 11:59:18 | Valid | Epoch[247/600] Iteration[008/008] Valid loss: 0.0555
2023-02-06 11:59:18 | Valid | Epoch[247/600] MIou: 0.925085976601963
2023-02-06 11:59:18 | Valid | Epoch[247/600] Pixel Accuracy: 0.9873301188151041
2023-02-06 11:59:18 | Valid | Epoch[247/600] Mean Pixel Accuracy: 0.943865736367239
2023-02-06 11:59:18 | Stage | Epoch[247/600] Train loss:0.0207
2023-02-06 11:59:18 | Stage | Epoch[247/600] Valid loss:0.0555
2023-02-06 11:59:18 | Stage | Epoch[247/600] LR:0.01

2023-02-06 11:59:18 | Train | Epoch[248/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 11:59:18 | Train | Epoch[248/600] Iteration[002/030] Train loss: 0.0197
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[005/030] Train loss: 0.0193
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:59:19 | Train | Epoch[248/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[025/030] Train loss: 0.0205
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[027/030] Train loss: 0.0204
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[028/030] Train loss: 0.0205
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[029/030] Train loss: 0.0205
2023-02-06 11:59:20 | Train | Epoch[248/600] Iteration[030/030] Train loss: 0.0204
2023-02-06 11:59:21 | Valid | Epoch[248/600] Iteration[001/008] Valid loss: 0.0689
2023-02-06 11:59:21 | Valid | Epoch[248/600] Iteration[002/008] Valid loss: 0.0741
2023-02-06 11:59:21 | Valid | Epoch[248/600] Iteration[003/008] Valid loss: 0.0708
2023-02-06 11:59:21 | Valid | Epoch[248/600] Iteration[004/008] Valid loss: 0.0657
2023-02-06 11:59:21 | Valid | Epoch[248/600] Iteration[005/008] Valid loss: 0.0626
2023-02-06 11:59:21 | Valid | Epoch[248/600] Iteration[006/008] Valid loss: 0.0619
2023-02-06 11:59:21 | Valid | Epoch[248/600] Iteration[007/008] Valid loss: 0.0628
2023-02-06 11:59:21 | Valid | Epoch[248/600] Iteration[008/008] Valid loss: 0.0639
2023-02-06 11:59:21 | Valid | Epoch[248/600] MIou: 0.8973789349260657
2023-02-06 11:59:21 | Valid | Epoch[248/600] Pixel Accuracy: 0.9824918111165365
2023-02-06 11:59:21 | Valid | Epoch[248/600] Mean Pixel Accuracy: 0.921367060745976
2023-02-06 11:59:21 | Stage | Epoch[248/600] Train loss:0.0204
2023-02-06 11:59:21 | Stage | Epoch[248/600] Valid loss:0.0639
2023-02-06 11:59:21 | Stage | Epoch[248/600] LR:0.01

2023-02-06 11:59:21 | Train | Epoch[249/600] Iteration[001/030] Train loss: 0.0223
2023-02-06 11:59:21 | Train | Epoch[249/600] Iteration[002/030] Train loss: 0.0229
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[004/030] Train loss: 0.0217
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[005/030] Train loss: 0.0217
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:59:22 | Train | Epoch[249/600] Iteration[016/030] Train loss: 0.0204
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[018/030] Train loss: 0.0206
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[019/030] Train loss: 0.0207
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[021/030] Train loss: 0.0208
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[022/030] Train loss: 0.0208
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[023/030] Train loss: 0.0207
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[024/030] Train loss: 0.0207
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[025/030] Train loss: 0.0206
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[026/030] Train loss: 0.0206
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[027/030] Train loss: 0.0206
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[028/030] Train loss: 0.0206
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[029/030] Train loss: 0.0206
2023-02-06 11:59:23 | Train | Epoch[249/600] Iteration[030/030] Train loss: 0.0205
2023-02-06 11:59:24 | Valid | Epoch[249/600] Iteration[001/008] Valid loss: 0.0536
2023-02-06 11:59:24 | Valid | Epoch[249/600] Iteration[002/008] Valid loss: 0.0517
2023-02-06 11:59:24 | Valid | Epoch[249/600] Iteration[003/008] Valid loss: 0.0513
2023-02-06 11:59:24 | Valid | Epoch[249/600] Iteration[004/008] Valid loss: 0.0496
2023-02-06 11:59:24 | Valid | Epoch[249/600] Iteration[005/008] Valid loss: 0.0491
2023-02-06 11:59:24 | Valid | Epoch[249/600] Iteration[006/008] Valid loss: 0.0482
2023-02-06 11:59:24 | Valid | Epoch[249/600] Iteration[007/008] Valid loss: 0.0479
2023-02-06 11:59:24 | Valid | Epoch[249/600] Iteration[008/008] Valid loss: 0.0485
2023-02-06 11:59:24 | Valid | Epoch[249/600] MIou: 0.8618153419039032
2023-02-06 11:59:24 | Valid | Epoch[249/600] Pixel Accuracy: 0.97705078125
2023-02-06 11:59:24 | Valid | Epoch[249/600] Mean Pixel Accuracy: 0.8771633738484974
2023-02-06 11:59:24 | Stage | Epoch[249/600] Train loss:0.0205
2023-02-06 11:59:24 | Stage | Epoch[249/600] Valid loss:0.0485
2023-02-06 11:59:24 | Stage | Epoch[249/600] LR:0.01

2023-02-06 11:59:24 | Train | Epoch[250/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 11:59:24 | Train | Epoch[250/600] Iteration[002/030] Train loss: 0.0225
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[003/030] Train loss: 0.0224
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[004/030] Train loss: 0.0220
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[013/030] Train loss: 0.0206
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:59:25 | Train | Epoch[250/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[018/030] Train loss: 0.0208
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[020/030] Train loss: 0.0206
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[026/030] Train loss: 0.0205
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[027/030] Train loss: 0.0205
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[028/030] Train loss: 0.0204
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[029/030] Train loss: 0.0205
2023-02-06 11:59:26 | Train | Epoch[250/600] Iteration[030/030] Train loss: 0.0204
2023-02-06 11:59:27 | Valid | Epoch[250/600] Iteration[001/008] Valid loss: 0.2103
2023-02-06 11:59:27 | Valid | Epoch[250/600] Iteration[002/008] Valid loss: 0.1705
2023-02-06 11:59:27 | Valid | Epoch[250/600] Iteration[003/008] Valid loss: 0.1596
2023-02-06 11:59:27 | Valid | Epoch[250/600] Iteration[004/008] Valid loss: 0.1566
2023-02-06 11:59:27 | Valid | Epoch[250/600] Iteration[005/008] Valid loss: 0.1604
2023-02-06 11:59:27 | Valid | Epoch[250/600] Iteration[006/008] Valid loss: 0.1547
2023-02-06 11:59:27 | Valid | Epoch[250/600] Iteration[007/008] Valid loss: 0.1673
2023-02-06 11:59:27 | Valid | Epoch[250/600] Iteration[008/008] Valid loss: 0.1670
2023-02-06 11:59:27 | Valid | Epoch[250/600] MIou: 0.9281050899727915
2023-02-06 11:59:27 | Valid | Epoch[250/600] Pixel Accuracy: 0.9869524637858073
2023-02-06 11:59:27 | Valid | Epoch[250/600] Mean Pixel Accuracy: 0.9798495724474916
2023-02-06 11:59:27 | Stage | Epoch[250/600] Train loss:0.0204
2023-02-06 11:59:27 | Stage | Epoch[250/600] Valid loss:0.1670
2023-02-06 11:59:27 | Stage | Epoch[250/600] LR:0.01

2023-02-06 11:59:27 | Train | Epoch[251/600] Iteration[001/030] Train loss: 0.0251
2023-02-06 11:59:27 | Train | Epoch[251/600] Iteration[002/030] Train loss: 0.0227
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[003/030] Train loss: 0.0214
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[004/030] Train loss: 0.0215
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[005/030] Train loss: 0.0216
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:59:28 | Train | Epoch[251/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[027/030] Train loss: 0.0205
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[028/030] Train loss: 0.0205
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[029/030] Train loss: 0.0205
2023-02-06 11:59:29 | Train | Epoch[251/600] Iteration[030/030] Train loss: 0.0205
2023-02-06 11:59:30 | Valid | Epoch[251/600] Iteration[001/008] Valid loss: 0.1425
2023-02-06 11:59:30 | Valid | Epoch[251/600] Iteration[002/008] Valid loss: 0.1148
2023-02-06 11:59:30 | Valid | Epoch[251/600] Iteration[003/008] Valid loss: 0.1111
2023-02-06 11:59:30 | Valid | Epoch[251/600] Iteration[004/008] Valid loss: 0.1054
2023-02-06 11:59:30 | Valid | Epoch[251/600] Iteration[005/008] Valid loss: 0.1080
2023-02-06 11:59:30 | Valid | Epoch[251/600] Iteration[006/008] Valid loss: 0.1032
2023-02-06 11:59:30 | Valid | Epoch[251/600] Iteration[007/008] Valid loss: 0.1082
2023-02-06 11:59:30 | Valid | Epoch[251/600] Iteration[008/008] Valid loss: 0.1040
2023-02-06 11:59:30 | Valid | Epoch[251/600] MIou: 0.9251549670880945
2023-02-06 11:59:30 | Valid | Epoch[251/600] Pixel Accuracy: 0.9869461059570312
2023-02-06 11:59:30 | Valid | Epoch[251/600] Mean Pixel Accuracy: 0.9579334083678936
2023-02-06 11:59:30 | Stage | Epoch[251/600] Train loss:0.0205
2023-02-06 11:59:30 | Stage | Epoch[251/600] Valid loss:0.1040
2023-02-06 11:59:30 | Stage | Epoch[251/600] LR:0.01

2023-02-06 11:59:30 | Train | Epoch[252/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 11:59:30 | Train | Epoch[252/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[006/030] Train loss: 0.0199
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:59:31 | Train | Epoch[252/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:59:32 | Train | Epoch[252/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:59:33 | Valid | Epoch[252/600] Iteration[001/008] Valid loss: 0.0917
2023-02-06 11:59:33 | Valid | Epoch[252/600] Iteration[002/008] Valid loss: 0.0951
2023-02-06 11:59:33 | Valid | Epoch[252/600] Iteration[003/008] Valid loss: 0.1015
2023-02-06 11:59:33 | Valid | Epoch[252/600] Iteration[004/008] Valid loss: 0.0987
2023-02-06 11:59:33 | Valid | Epoch[252/600] Iteration[005/008] Valid loss: 0.1004
2023-02-06 11:59:33 | Valid | Epoch[252/600] Iteration[006/008] Valid loss: 0.0982
2023-02-06 11:59:33 | Valid | Epoch[252/600] Iteration[007/008] Valid loss: 0.0955
2023-02-06 11:59:33 | Valid | Epoch[252/600] Iteration[008/008] Valid loss: 0.0996
2023-02-06 11:59:33 | Valid | Epoch[252/600] MIou: 0.7052676819852631
2023-02-06 11:59:33 | Valid | Epoch[252/600] Pixel Accuracy: 0.9513460795084635
2023-02-06 11:59:33 | Valid | Epoch[252/600] Mean Pixel Accuracy: 0.7306522687916204
2023-02-06 11:59:33 | Stage | Epoch[252/600] Train loss:0.0201
2023-02-06 11:59:33 | Stage | Epoch[252/600] Valid loss:0.0996
2023-02-06 11:59:33 | Stage | Epoch[252/600] LR:0.01

2023-02-06 11:59:33 | Train | Epoch[253/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 11:59:33 | Train | Epoch[253/600] Iteration[002/030] Train loss: 0.0180
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[003/030] Train loss: 0.0187
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:59:34 | Train | Epoch[253/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[025/030] Train loss: 0.0206
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[026/030] Train loss: 0.0207
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[027/030] Train loss: 0.0207
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[028/030] Train loss: 0.0207
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[029/030] Train loss: 0.0208
2023-02-06 11:59:35 | Train | Epoch[253/600] Iteration[030/030] Train loss: 0.0208
2023-02-06 11:59:36 | Valid | Epoch[253/600] Iteration[001/008] Valid loss: 0.0708
2023-02-06 11:59:36 | Valid | Epoch[253/600] Iteration[002/008] Valid loss: 0.0523
2023-02-06 11:59:36 | Valid | Epoch[253/600] Iteration[003/008] Valid loss: 0.0508
2023-02-06 11:59:36 | Valid | Epoch[253/600] Iteration[004/008] Valid loss: 0.0462
2023-02-06 11:59:36 | Valid | Epoch[253/600] Iteration[005/008] Valid loss: 0.0460
2023-02-06 11:59:36 | Valid | Epoch[253/600] Iteration[006/008] Valid loss: 0.0439
2023-02-06 11:59:36 | Valid | Epoch[253/600] Iteration[007/008] Valid loss: 0.0459
2023-02-06 11:59:36 | Valid | Epoch[253/600] Iteration[008/008] Valid loss: 0.0451
2023-02-06 11:59:36 | Valid | Epoch[253/600] MIou: 0.9182793113166163
2023-02-06 11:59:36 | Valid | Epoch[253/600] Pixel Accuracy: 0.9862836201985677
2023-02-06 11:59:36 | Valid | Epoch[253/600] Mean Pixel Accuracy: 0.9341095333460125
2023-02-06 11:59:36 | Stage | Epoch[253/600] Train loss:0.0208
2023-02-06 11:59:36 | Stage | Epoch[253/600] Valid loss:0.0451
2023-02-06 11:59:36 | Stage | Epoch[253/600] LR:0.01

2023-02-06 11:59:36 | Train | Epoch[254/600] Iteration[001/030] Train loss: 0.0193
2023-02-06 11:59:36 | Train | Epoch[254/600] Iteration[002/030] Train loss: 0.0191
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[003/030] Train loss: 0.0193
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[004/030] Train loss: 0.0195
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:59:37 | Train | Epoch[254/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[029/030] Train loss: 0.0205
2023-02-06 11:59:38 | Train | Epoch[254/600] Iteration[030/030] Train loss: 0.0205
2023-02-06 11:59:39 | Valid | Epoch[254/600] Iteration[001/008] Valid loss: 0.1808
2023-02-06 11:59:39 | Valid | Epoch[254/600] Iteration[002/008] Valid loss: 0.1382
2023-02-06 11:59:39 | Valid | Epoch[254/600] Iteration[003/008] Valid loss: 0.1306
2023-02-06 11:59:39 | Valid | Epoch[254/600] Iteration[004/008] Valid loss: 0.1268
2023-02-06 11:59:39 | Valid | Epoch[254/600] Iteration[005/008] Valid loss: 0.1231
2023-02-06 11:59:39 | Valid | Epoch[254/600] Iteration[006/008] Valid loss: 0.1197
2023-02-06 11:59:39 | Valid | Epoch[254/600] Iteration[007/008] Valid loss: 0.1297
2023-02-06 11:59:39 | Valid | Epoch[254/600] Iteration[008/008] Valid loss: 0.1297
2023-02-06 11:59:39 | Valid | Epoch[254/600] MIou: 0.9344418255928814
2023-02-06 11:59:39 | Valid | Epoch[254/600] Pixel Accuracy: 0.9884045918782552
2023-02-06 11:59:39 | Valid | Epoch[254/600] Mean Pixel Accuracy: 0.9736795457870905
2023-02-06 11:59:39 | Stage | Epoch[254/600] Train loss:0.0205
2023-02-06 11:59:39 | Stage | Epoch[254/600] Valid loss:0.1297
2023-02-06 11:59:39 | Stage | Epoch[254/600] LR:0.01

2023-02-06 11:59:39 | Train | Epoch[255/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:59:39 | Train | Epoch[255/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[007/030] Train loss: 0.0204
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:59:40 | Train | Epoch[255/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[028/030] Train loss: 0.0204
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:59:41 | Train | Epoch[255/600] Iteration[030/030] Train loss: 0.0205
2023-02-06 11:59:42 | Valid | Epoch[255/600] Iteration[001/008] Valid loss: 0.1809
2023-02-06 11:59:42 | Valid | Epoch[255/600] Iteration[002/008] Valid loss: 0.1521
2023-02-06 11:59:42 | Valid | Epoch[255/600] Iteration[003/008] Valid loss: 0.1399
2023-02-06 11:59:42 | Valid | Epoch[255/600] Iteration[004/008] Valid loss: 0.1379
2023-02-06 11:59:42 | Valid | Epoch[255/600] Iteration[005/008] Valid loss: 0.1352
2023-02-06 11:59:42 | Valid | Epoch[255/600] Iteration[006/008] Valid loss: 0.1328
2023-02-06 11:59:42 | Valid | Epoch[255/600] Iteration[007/008] Valid loss: 0.1437
2023-02-06 11:59:42 | Valid | Epoch[255/600] Iteration[008/008] Valid loss: 0.1370
2023-02-06 11:59:42 | Valid | Epoch[255/600] MIou: 0.9362131170803297
2023-02-06 11:59:42 | Valid | Epoch[255/600] Pixel Accuracy: 0.988714853922526
2023-02-06 11:59:42 | Valid | Epoch[255/600] Mean Pixel Accuracy: 0.9755620063472394
2023-02-06 11:59:42 | Stage | Epoch[255/600] Train loss:0.0205
2023-02-06 11:59:42 | Stage | Epoch[255/600] Valid loss:0.1370
2023-02-06 11:59:42 | Stage | Epoch[255/600] LR:0.01

2023-02-06 11:59:42 | Train | Epoch[256/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 11:59:42 | Train | Epoch[256/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[003/030] Train loss: 0.0208
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[012/030] Train loss: 0.0212
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[013/030] Train loss: 0.0210
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[014/030] Train loss: 0.0208
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:59:43 | Train | Epoch[256/600] Iteration[016/030] Train loss: 0.0213
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[017/030] Train loss: 0.0214
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[019/030] Train loss: 0.0212
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[021/030] Train loss: 0.0214
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[022/030] Train loss: 0.0214
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[024/030] Train loss: 0.0214
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[025/030] Train loss: 0.0215
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[026/030] Train loss: 0.0215
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[027/030] Train loss: 0.0213
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[028/030] Train loss: 0.0213
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:59:44 | Train | Epoch[256/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 11:59:45 | Valid | Epoch[256/600] Iteration[001/008] Valid loss: 0.0682
2023-02-06 11:59:45 | Valid | Epoch[256/600] Iteration[002/008] Valid loss: 0.0519
2023-02-06 11:59:45 | Valid | Epoch[256/600] Iteration[003/008] Valid loss: 0.0482
2023-02-06 11:59:45 | Valid | Epoch[256/600] Iteration[004/008] Valid loss: 0.0439
2023-02-06 11:59:45 | Valid | Epoch[256/600] Iteration[005/008] Valid loss: 0.0425
2023-02-06 11:59:45 | Valid | Epoch[256/600] Iteration[006/008] Valid loss: 0.0416
2023-02-06 11:59:45 | Valid | Epoch[256/600] Iteration[007/008] Valid loss: 0.0431
2023-02-06 11:59:45 | Valid | Epoch[256/600] Iteration[008/008] Valid loss: 0.0425
2023-02-06 11:59:45 | Valid | Epoch[256/600] MIou: 0.9142494287483989
2023-02-06 11:59:45 | Valid | Epoch[256/600] Pixel Accuracy: 0.9856516520182291
2023-02-06 11:59:45 | Valid | Epoch[256/600] Mean Pixel Accuracy: 0.9290004825757355
2023-02-06 11:59:45 | Stage | Epoch[256/600] Train loss:0.0214
2023-02-06 11:59:45 | Stage | Epoch[256/600] Valid loss:0.0425
2023-02-06 11:59:45 | Stage | Epoch[256/600] LR:0.01

2023-02-06 11:59:45 | Train | Epoch[257/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 11:59:45 | Train | Epoch[257/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 11:59:45 | Train | Epoch[257/600] Iteration[003/030] Train loss: 0.0196
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:59:46 | Train | Epoch[257/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[022/030] Train loss: 0.0206
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[023/030] Train loss: 0.0206
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[024/030] Train loss: 0.0206
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[025/030] Train loss: 0.0205
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[026/030] Train loss: 0.0205
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[027/030] Train loss: 0.0206
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[028/030] Train loss: 0.0206
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[029/030] Train loss: 0.0206
2023-02-06 11:59:47 | Train | Epoch[257/600] Iteration[030/030] Train loss: 0.0207
2023-02-06 11:59:48 | Valid | Epoch[257/600] Iteration[001/008] Valid loss: 0.0462
2023-02-06 11:59:48 | Valid | Epoch[257/600] Iteration[002/008] Valid loss: 0.0449
2023-02-06 11:59:48 | Valid | Epoch[257/600] Iteration[003/008] Valid loss: 0.0472
2023-02-06 11:59:48 | Valid | Epoch[257/600] Iteration[004/008] Valid loss: 0.0453
2023-02-06 11:59:48 | Valid | Epoch[257/600] Iteration[005/008] Valid loss: 0.0457
2023-02-06 11:59:48 | Valid | Epoch[257/600] Iteration[006/008] Valid loss: 0.0447
2023-02-06 11:59:48 | Valid | Epoch[257/600] Iteration[007/008] Valid loss: 0.0442
2023-02-06 11:59:48 | Valid | Epoch[257/600] Iteration[008/008] Valid loss: 0.0450
2023-02-06 11:59:48 | Valid | Epoch[257/600] MIou: 0.8551005146027144
2023-02-06 11:59:48 | Valid | Epoch[257/600] Pixel Accuracy: 0.9760691324869791
2023-02-06 11:59:48 | Valid | Epoch[257/600] Mean Pixel Accuracy: 0.8688884425772967
2023-02-06 11:59:48 | Stage | Epoch[257/600] Train loss:0.0207
2023-02-06 11:59:48 | Stage | Epoch[257/600] Valid loss:0.0450
2023-02-06 11:59:48 | Stage | Epoch[257/600] LR:0.01

2023-02-06 11:59:48 | Train | Epoch[258/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 11:59:48 | Train | Epoch[258/600] Iteration[002/030] Train loss: 0.0179
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[003/030] Train loss: 0.0193
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[004/030] Train loss: 0.0189
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:59:49 | Train | Epoch[258/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[024/030] Train loss: 0.0206
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[025/030] Train loss: 0.0208
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[026/030] Train loss: 0.0208
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[027/030] Train loss: 0.0209
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[028/030] Train loss: 0.0210
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 11:59:50 | Train | Epoch[258/600] Iteration[030/030] Train loss: 0.0210
2023-02-06 11:59:51 | Valid | Epoch[258/600] Iteration[001/008] Valid loss: 0.1996
2023-02-06 11:59:51 | Valid | Epoch[258/600] Iteration[002/008] Valid loss: 0.1715
2023-02-06 11:59:51 | Valid | Epoch[258/600] Iteration[003/008] Valid loss: 0.1605
2023-02-06 11:59:51 | Valid | Epoch[258/600] Iteration[004/008] Valid loss: 0.1644
2023-02-06 11:59:51 | Valid | Epoch[258/600] Iteration[005/008] Valid loss: 0.1712
2023-02-06 11:59:51 | Valid | Epoch[258/600] Iteration[006/008] Valid loss: 0.1609
2023-02-06 11:59:51 | Valid | Epoch[258/600] Iteration[007/008] Valid loss: 0.1774
2023-02-06 11:59:51 | Valid | Epoch[258/600] Iteration[008/008] Valid loss: 0.1767
2023-02-06 11:59:51 | Valid | Epoch[258/600] MIou: 0.9173317503831263
2023-02-06 11:59:51 | Valid | Epoch[258/600] Pixel Accuracy: 0.9848543802897135
2023-02-06 11:59:51 | Valid | Epoch[258/600] Mean Pixel Accuracy: 0.9734908491655241
2023-02-06 11:59:51 | Stage | Epoch[258/600] Train loss:0.0210
2023-02-06 11:59:51 | Stage | Epoch[258/600] Valid loss:0.1767
2023-02-06 11:59:51 | Stage | Epoch[258/600] LR:0.01

2023-02-06 11:59:51 | Train | Epoch[259/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 11:59:51 | Train | Epoch[259/600] Iteration[002/030] Train loss: 0.0219
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[003/030] Train loss: 0.0216
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[004/030] Train loss: 0.0227
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[006/030] Train loss: 0.0225
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[008/030] Train loss: 0.0215
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[009/030] Train loss: 0.0211
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[014/030] Train loss: 0.0210
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:59:52 | Train | Epoch[259/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[018/030] Train loss: 0.0209
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[019/030] Train loss: 0.0210
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[020/030] Train loss: 0.0211
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[021/030] Train loss: 0.0209
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[022/030] Train loss: 0.0210
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[023/030] Train loss: 0.0209
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[024/030] Train loss: 0.0210
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[025/030] Train loss: 0.0211
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[026/030] Train loss: 0.0212
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[027/030] Train loss: 0.0212
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:59:53 | Train | Epoch[259/600] Iteration[030/030] Train loss: 0.0215
2023-02-06 11:59:54 | Valid | Epoch[259/600] Iteration[001/008] Valid loss: 0.1058
2023-02-06 11:59:54 | Valid | Epoch[259/600] Iteration[002/008] Valid loss: 0.0796
2023-02-06 11:59:54 | Valid | Epoch[259/600] Iteration[003/008] Valid loss: 0.0807
2023-02-06 11:59:54 | Valid | Epoch[259/600] Iteration[004/008] Valid loss: 0.0750
2023-02-06 11:59:54 | Valid | Epoch[259/600] Iteration[005/008] Valid loss: 0.0762
2023-02-06 11:59:54 | Valid | Epoch[259/600] Iteration[006/008] Valid loss: 0.0750
2023-02-06 11:59:54 | Valid | Epoch[259/600] Iteration[007/008] Valid loss: 0.0753
2023-02-06 11:59:54 | Valid | Epoch[259/600] Iteration[008/008] Valid loss: 0.0727
2023-02-06 11:59:54 | Valid | Epoch[259/600] MIou: 0.8730459626784457
2023-02-06 11:59:54 | Valid | Epoch[259/600] Pixel Accuracy: 0.9788004557291666
2023-02-06 11:59:54 | Valid | Epoch[259/600] Mean Pixel Accuracy: 0.8896964300736048
2023-02-06 11:59:54 | Stage | Epoch[259/600] Train loss:0.0215
2023-02-06 11:59:54 | Stage | Epoch[259/600] Valid loss:0.0727
2023-02-06 11:59:54 | Stage | Epoch[259/600] LR:0.01

2023-02-06 11:59:54 | Train | Epoch[260/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[002/030] Train loss: 0.0197
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:59:55 | Train | Epoch[260/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:59:56 | Train | Epoch[260/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:59:57 | Train | Epoch[260/600] Iteration[030/030] Train loss: 0.0204
2023-02-06 11:59:57 | Valid | Epoch[260/600] Iteration[001/008] Valid loss: 0.7775
2023-02-06 11:59:57 | Valid | Epoch[260/600] Iteration[002/008] Valid loss: 0.7166
2023-02-06 11:59:57 | Valid | Epoch[260/600] Iteration[003/008] Valid loss: 0.7331
2023-02-06 11:59:57 | Valid | Epoch[260/600] Iteration[004/008] Valid loss: 0.7560
2023-02-06 11:59:57 | Valid | Epoch[260/600] Iteration[005/008] Valid loss: 0.7836
2023-02-06 11:59:57 | Valid | Epoch[260/600] Iteration[006/008] Valid loss: 0.7567
2023-02-06 11:59:57 | Valid | Epoch[260/600] Iteration[007/008] Valid loss: 0.7916
2023-02-06 11:59:57 | Valid | Epoch[260/600] Iteration[008/008] Valid loss: 0.7932
2023-02-06 11:59:57 | Valid | Epoch[260/600] MIou: 0.8838288977032656
2023-02-06 11:59:57 | Valid | Epoch[260/600] Pixel Accuracy: 0.976654052734375
2023-02-06 11:59:57 | Valid | Epoch[260/600] Mean Pixel Accuracy: 0.9835920457694304
2023-02-06 11:59:57 | Stage | Epoch[260/600] Train loss:0.0204
2023-02-06 11:59:57 | Stage | Epoch[260/600] Valid loss:0.7932
2023-02-06 11:59:57 | Stage | Epoch[260/600] LR:0.01

2023-02-06 11:59:57 | Train | Epoch[261/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[010/030] Train loss: 0.0199
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:59:58 | Train | Epoch[261/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:59:59 | Train | Epoch[261/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 12:00:00 | Train | Epoch[261/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 12:00:00 | Valid | Epoch[261/600] Iteration[001/008] Valid loss: 0.2185
2023-02-06 12:00:00 | Valid | Epoch[261/600] Iteration[002/008] Valid loss: 0.1796
2023-02-06 12:00:00 | Valid | Epoch[261/600] Iteration[003/008] Valid loss: 0.1656
2023-02-06 12:00:00 | Valid | Epoch[261/600] Iteration[004/008] Valid loss: 0.1641
2023-02-06 12:00:00 | Valid | Epoch[261/600] Iteration[005/008] Valid loss: 0.1672
2023-02-06 12:00:00 | Valid | Epoch[261/600] Iteration[006/008] Valid loss: 0.1632
2023-02-06 12:00:00 | Valid | Epoch[261/600] Iteration[007/008] Valid loss: 0.1745
2023-02-06 12:00:00 | Valid | Epoch[261/600] Iteration[008/008] Valid loss: 0.1723
2023-02-06 12:00:00 | Valid | Epoch[261/600] MIou: 0.9264021532516831
2023-02-06 12:00:00 | Valid | Epoch[261/600] Pixel Accuracy: 0.9866180419921875
2023-02-06 12:00:00 | Valid | Epoch[261/600] Mean Pixel Accuracy: 0.9790507342303019
2023-02-06 12:00:00 | Stage | Epoch[261/600] Train loss:0.0201
2023-02-06 12:00:00 | Stage | Epoch[261/600] Valid loss:0.1723
2023-02-06 12:00:00 | Stage | Epoch[261/600] LR:0.01

2023-02-06 12:00:00 | Train | Epoch[262/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[003/030] Train loss: 0.0193
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[005/030] Train loss: 0.0188
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[007/030] Train loss: 0.0191
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 12:00:01 | Train | Epoch[262/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[027/030] Train loss: 0.0197
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 12:00:02 | Train | Epoch[262/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 12:00:03 | Train | Epoch[262/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 12:00:03 | Valid | Epoch[262/600] Iteration[001/008] Valid loss: 0.5816
2023-02-06 12:00:03 | Valid | Epoch[262/600] Iteration[002/008] Valid loss: 0.5088
2023-02-06 12:00:03 | Valid | Epoch[262/600] Iteration[003/008] Valid loss: 0.5098
2023-02-06 12:00:03 | Valid | Epoch[262/600] Iteration[004/008] Valid loss: 0.5169
2023-02-06 12:00:03 | Valid | Epoch[262/600] Iteration[005/008] Valid loss: 0.5366
2023-02-06 12:00:03 | Valid | Epoch[262/600] Iteration[006/008] Valid loss: 0.5184
2023-02-06 12:00:03 | Valid | Epoch[262/600] Iteration[007/008] Valid loss: 0.5478
2023-02-06 12:00:03 | Valid | Epoch[262/600] Iteration[008/008] Valid loss: 0.5473
2023-02-06 12:00:03 | Valid | Epoch[262/600] MIou: 0.8926722151728714
2023-02-06 12:00:03 | Valid | Epoch[262/600] Pixel Accuracy: 0.9788360595703125
2023-02-06 12:00:03 | Valid | Epoch[262/600] Mean Pixel Accuracy: 0.9838022562309179
2023-02-06 12:00:03 | Stage | Epoch[262/600] Train loss:0.0198
2023-02-06 12:00:03 | Stage | Epoch[262/600] Valid loss:0.5473
2023-02-06 12:00:03 | Stage | Epoch[262/600] LR:0.01

2023-02-06 12:00:03 | Train | Epoch[263/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 12:00:04 | Train | Epoch[263/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 12:00:05 | Train | Epoch[263/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 12:00:06 | Train | Epoch[263/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 12:00:06 | Valid | Epoch[263/600] Iteration[001/008] Valid loss: 0.2031
2023-02-06 12:00:06 | Valid | Epoch[263/600] Iteration[002/008] Valid loss: 0.1519
2023-02-06 12:00:06 | Valid | Epoch[263/600] Iteration[003/008] Valid loss: 0.1481
2023-02-06 12:00:06 | Valid | Epoch[263/600] Iteration[004/008] Valid loss: 0.1418
2023-02-06 12:00:06 | Valid | Epoch[263/600] Iteration[005/008] Valid loss: 0.1472
2023-02-06 12:00:06 | Valid | Epoch[263/600] Iteration[006/008] Valid loss: 0.1413
2023-02-06 12:00:06 | Valid | Epoch[263/600] Iteration[007/008] Valid loss: 0.1571
2023-02-06 12:00:06 | Valid | Epoch[263/600] Iteration[008/008] Valid loss: 0.1541
2023-02-06 12:00:06 | Valid | Epoch[263/600] MIou: 0.9314697019404825
2023-02-06 12:00:06 | Valid | Epoch[263/600] Pixel Accuracy: 0.9876963297526041
2023-02-06 12:00:06 | Valid | Epoch[263/600] Mean Pixel Accuracy: 0.9779695226920985
2023-02-06 12:00:06 | Stage | Epoch[263/600] Train loss:0.0199
2023-02-06 12:00:06 | Stage | Epoch[263/600] Valid loss:0.1541
2023-02-06 12:00:06 | Stage | Epoch[263/600] LR:0.01

2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[006/030] Train loss: 0.0182
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[007/030] Train loss: 0.0188
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[008/030] Train loss: 0.0188
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[009/030] Train loss: 0.0190
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[013/030] Train loss: 0.0191
2023-02-06 12:00:07 | Train | Epoch[264/600] Iteration[014/030] Train loss: 0.0191
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[015/030] Train loss: 0.0190
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[016/030] Train loss: 0.0190
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[017/030] Train loss: 0.0192
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[018/030] Train loss: 0.0193
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[019/030] Train loss: 0.0193
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[021/030] Train loss: 0.0193
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[022/030] Train loss: 0.0194
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[023/030] Train loss: 0.0193
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[024/030] Train loss: 0.0195
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[025/030] Train loss: 0.0194
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[026/030] Train loss: 0.0194
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[027/030] Train loss: 0.0194
2023-02-06 12:00:08 | Train | Epoch[264/600] Iteration[028/030] Train loss: 0.0195
2023-02-06 12:00:09 | Train | Epoch[264/600] Iteration[029/030] Train loss: 0.0196
2023-02-06 12:00:09 | Train | Epoch[264/600] Iteration[030/030] Train loss: 0.0197
2023-02-06 12:00:09 | Valid | Epoch[264/600] Iteration[001/008] Valid loss: 0.0803
2023-02-06 12:00:09 | Valid | Epoch[264/600] Iteration[002/008] Valid loss: 0.0811
2023-02-06 12:00:09 | Valid | Epoch[264/600] Iteration[003/008] Valid loss: 0.0866
2023-02-06 12:00:09 | Valid | Epoch[264/600] Iteration[004/008] Valid loss: 0.0843
2023-02-06 12:00:09 | Valid | Epoch[264/600] Iteration[005/008] Valid loss: 0.0858
2023-02-06 12:00:09 | Valid | Epoch[264/600] Iteration[006/008] Valid loss: 0.0841
2023-02-06 12:00:09 | Valid | Epoch[264/600] Iteration[007/008] Valid loss: 0.0819
2023-02-06 12:00:09 | Valid | Epoch[264/600] Iteration[008/008] Valid loss: 0.0853
2023-02-06 12:00:09 | Valid | Epoch[264/600] MIou: 0.7396729197718399
2023-02-06 12:00:09 | Valid | Epoch[264/600] Pixel Accuracy: 0.9570477803548177
2023-02-06 12:00:09 | Valid | Epoch[264/600] Mean Pixel Accuracy: 0.7622168410086021
2023-02-06 12:00:09 | Stage | Epoch[264/600] Train loss:0.0197
2023-02-06 12:00:09 | Stage | Epoch[264/600] Valid loss:0.0853
2023-02-06 12:00:09 | Stage | Epoch[264/600] LR:0.01

2023-02-06 12:00:09 | Train | Epoch[265/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[005/030] Train loss: 0.0188
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 12:00:10 | Train | Epoch[265/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[017/030] Train loss: 0.0196
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[022/030] Train loss: 0.0194
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 12:00:11 | Train | Epoch[265/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 12:00:12 | Train | Epoch[265/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 12:00:12 | Valid | Epoch[265/600] Iteration[001/008] Valid loss: 0.0668
2023-02-06 12:00:12 | Valid | Epoch[265/600] Iteration[002/008] Valid loss: 0.0647
2023-02-06 12:00:12 | Valid | Epoch[265/600] Iteration[003/008] Valid loss: 0.0611
2023-02-06 12:00:12 | Valid | Epoch[265/600] Iteration[004/008] Valid loss: 0.0577
2023-02-06 12:00:12 | Valid | Epoch[265/600] Iteration[005/008] Valid loss: 0.0551
2023-02-06 12:00:12 | Valid | Epoch[265/600] Iteration[006/008] Valid loss: 0.0537
2023-02-06 12:00:12 | Valid | Epoch[265/600] Iteration[007/008] Valid loss: 0.0547
2023-02-06 12:00:12 | Valid | Epoch[265/600] Iteration[008/008] Valid loss: 0.0539
2023-02-06 12:00:12 | Valid | Epoch[265/600] MIou: 0.9078219910583911
2023-02-06 12:00:12 | Valid | Epoch[265/600] Pixel Accuracy: 0.9844144185384115
2023-02-06 12:00:12 | Valid | Epoch[265/600] Mean Pixel Accuracy: 0.9274391207483169
2023-02-06 12:00:12 | Stage | Epoch[265/600] Train loss:0.0200
2023-02-06 12:00:12 | Stage | Epoch[265/600] Valid loss:0.0539
2023-02-06 12:00:12 | Stage | Epoch[265/600] LR:0.01

2023-02-06 12:00:12 | Train | Epoch[266/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[003/030] Train loss: 0.0188
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[005/030] Train loss: 0.0188
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[006/030] Train loss: 0.0189
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[007/030] Train loss: 0.0186
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[008/030] Train loss: 0.0188
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[009/030] Train loss: 0.0188
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[010/030] Train loss: 0.0189
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[011/030] Train loss: 0.0190
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[013/030] Train loss: 0.0193
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[014/030] Train loss: 0.0195
2023-02-06 12:00:13 | Train | Epoch[266/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[020/030] Train loss: 0.0196
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 12:00:14 | Train | Epoch[266/600] Iteration[029/030] Train loss: 0.0197
2023-02-06 12:00:15 | Train | Epoch[266/600] Iteration[030/030] Train loss: 0.0197
2023-02-06 12:00:15 | Valid | Epoch[266/600] Iteration[001/008] Valid loss: 0.0628
2023-02-06 12:00:15 | Valid | Epoch[266/600] Iteration[002/008] Valid loss: 0.0635
2023-02-06 12:00:15 | Valid | Epoch[266/600] Iteration[003/008] Valid loss: 0.0664
2023-02-06 12:00:15 | Valid | Epoch[266/600] Iteration[004/008] Valid loss: 0.0645
2023-02-06 12:00:15 | Valid | Epoch[266/600] Iteration[005/008] Valid loss: 0.0650
2023-02-06 12:00:15 | Valid | Epoch[266/600] Iteration[006/008] Valid loss: 0.0636
2023-02-06 12:00:15 | Valid | Epoch[266/600] Iteration[007/008] Valid loss: 0.0620
2023-02-06 12:00:15 | Valid | Epoch[266/600] Iteration[008/008] Valid loss: 0.0639
2023-02-06 12:00:15 | Valid | Epoch[266/600] MIou: 0.799026331791611
2023-02-06 12:00:15 | Valid | Epoch[266/600] Pixel Accuracy: 0.9668502807617188
2023-02-06 12:00:15 | Valid | Epoch[266/600] Mean Pixel Accuracy: 0.816787750817969
2023-02-06 12:00:15 | Stage | Epoch[266/600] Train loss:0.0197
2023-02-06 12:00:15 | Stage | Epoch[266/600] Valid loss:0.0639
2023-02-06 12:00:15 | Stage | Epoch[266/600] LR:0.01

2023-02-06 12:00:15 | Train | Epoch[267/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[003/030] Train loss: 0.0176
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[005/030] Train loss: 0.0188
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[006/030] Train loss: 0.0185
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[007/030] Train loss: 0.0189
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[008/030] Train loss: 0.0186
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[009/030] Train loss: 0.0186
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[010/030] Train loss: 0.0189
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[011/030] Train loss: 0.0192
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[013/030] Train loss: 0.0191
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[014/030] Train loss: 0.0190
2023-02-06 12:00:16 | Train | Epoch[267/600] Iteration[015/030] Train loss: 0.0191
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[016/030] Train loss: 0.0190
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[017/030] Train loss: 0.0192
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[018/030] Train loss: 0.0193
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[019/030] Train loss: 0.0192
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[020/030] Train loss: 0.0191
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[021/030] Train loss: 0.0191
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[022/030] Train loss: 0.0192
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[023/030] Train loss: 0.0192
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[024/030] Train loss: 0.0193
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[025/030] Train loss: 0.0193
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[026/030] Train loss: 0.0194
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[027/030] Train loss: 0.0195
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[028/030] Train loss: 0.0195
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[029/030] Train loss: 0.0196
2023-02-06 12:00:17 | Train | Epoch[267/600] Iteration[030/030] Train loss: 0.0196
2023-02-06 12:00:18 | Valid | Epoch[267/600] Iteration[001/008] Valid loss: 0.0520
2023-02-06 12:00:18 | Valid | Epoch[267/600] Iteration[002/008] Valid loss: 0.0512
2023-02-06 12:00:18 | Valid | Epoch[267/600] Iteration[003/008] Valid loss: 0.0532
2023-02-06 12:00:18 | Valid | Epoch[267/600] Iteration[004/008] Valid loss: 0.0509
2023-02-06 12:00:18 | Valid | Epoch[267/600] Iteration[005/008] Valid loss: 0.0508
2023-02-06 12:00:18 | Valid | Epoch[267/600] Iteration[006/008] Valid loss: 0.0496
2023-02-06 12:00:18 | Valid | Epoch[267/600] Iteration[007/008] Valid loss: 0.0488
2023-02-06 12:00:18 | Valid | Epoch[267/600] Iteration[008/008] Valid loss: 0.0499
2023-02-06 12:00:18 | Valid | Epoch[267/600] MIou: 0.833820368663468
2023-02-06 12:00:18 | Valid | Epoch[267/600] Pixel Accuracy: 0.9725507100423177
2023-02-06 12:00:18 | Valid | Epoch[267/600] Mean Pixel Accuracy: 0.8493153757980167
2023-02-06 12:00:18 | Stage | Epoch[267/600] Train loss:0.0196
2023-02-06 12:00:18 | Stage | Epoch[267/600] Valid loss:0.0499
2023-02-06 12:00:18 | Stage | Epoch[267/600] LR:0.01

2023-02-06 12:00:18 | Train | Epoch[268/600] Iteration[001/030] Train loss: 0.0176
2023-02-06 12:00:18 | Train | Epoch[268/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[003/030] Train loss: 0.0179
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[004/030] Train loss: 0.0182
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[005/030] Train loss: 0.0182
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[006/030] Train loss: 0.0182
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[007/030] Train loss: 0.0188
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[015/030] Train loss: 0.0192
2023-02-06 12:00:19 | Train | Epoch[268/600] Iteration[016/030] Train loss: 0.0193
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[017/030] Train loss: 0.0194
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[020/030] Train loss: 0.0196
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[024/030] Train loss: 0.0196
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 12:00:20 | Train | Epoch[268/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 12:00:21 | Valid | Epoch[268/600] Iteration[001/008] Valid loss: 0.1174
2023-02-06 12:00:21 | Valid | Epoch[268/600] Iteration[002/008] Valid loss: 0.0817
2023-02-06 12:00:21 | Valid | Epoch[268/600] Iteration[003/008] Valid loss: 0.0786
2023-02-06 12:00:21 | Valid | Epoch[268/600] Iteration[004/008] Valid loss: 0.0784
2023-02-06 12:00:21 | Valid | Epoch[268/600] Iteration[005/008] Valid loss: 0.0762
2023-02-06 12:00:21 | Valid | Epoch[268/600] Iteration[006/008] Valid loss: 0.0721
2023-02-06 12:00:21 | Valid | Epoch[268/600] Iteration[007/008] Valid loss: 0.0783
2023-02-06 12:00:21 | Valid | Epoch[268/600] Iteration[008/008] Valid loss: 0.0747
2023-02-06 12:00:21 | Valid | Epoch[268/600] MIou: 0.9330238854063698
2023-02-06 12:00:21 | Valid | Epoch[268/600] Pixel Accuracy: 0.9885482788085938
2023-02-06 12:00:21 | Valid | Epoch[268/600] Mean Pixel Accuracy: 0.9563539279514448
2023-02-06 12:00:21 | Stage | Epoch[268/600] Train loss:0.0200
2023-02-06 12:00:21 | Stage | Epoch[268/600] Valid loss:0.0747
2023-02-06 12:00:21 | Stage | Epoch[268/600] LR:0.01

2023-02-06 12:00:21 | Train | Epoch[269/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 12:00:21 | Train | Epoch[269/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[003/030] Train loss: 0.0175
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[006/030] Train loss: 0.0186
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[007/030] Train loss: 0.0189
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 12:00:22 | Train | Epoch[269/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 12:00:23 | Train | Epoch[269/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 12:00:24 | Valid | Epoch[269/600] Iteration[001/008] Valid loss: 0.0504
2023-02-06 12:00:24 | Valid | Epoch[269/600] Iteration[002/008] Valid loss: 0.0431
2023-02-06 12:00:24 | Valid | Epoch[269/600] Iteration[003/008] Valid loss: 0.0444
2023-02-06 12:00:24 | Valid | Epoch[269/600] Iteration[004/008] Valid loss: 0.0412
2023-02-06 12:00:24 | Valid | Epoch[269/600] Iteration[005/008] Valid loss: 0.0405
2023-02-06 12:00:24 | Valid | Epoch[269/600] Iteration[006/008] Valid loss: 0.0393
2023-02-06 12:00:24 | Valid | Epoch[269/600] Iteration[007/008] Valid loss: 0.0391
2023-02-06 12:00:24 | Valid | Epoch[269/600] Iteration[008/008] Valid loss: 0.0389
2023-02-06 12:00:24 | Valid | Epoch[269/600] MIou: 0.8974261595747139
2023-02-06 12:00:24 | Valid | Epoch[269/600] Pixel Accuracy: 0.9829724629720052
2023-02-06 12:00:24 | Valid | Epoch[269/600] Mean Pixel Accuracy: 0.9100091632234051
2023-02-06 12:00:24 | Stage | Epoch[269/600] Train loss:0.0203
2023-02-06 12:00:24 | Stage | Epoch[269/600] Valid loss:0.0389
2023-02-06 12:00:24 | Stage | Epoch[269/600] LR:0.01

2023-02-06 12:00:24 | Train | Epoch[270/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 12:00:24 | Train | Epoch[270/600] Iteration[002/030] Train loss: 0.0185
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[005/030] Train loss: 0.0187
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[012/030] Train loss: 0.0194
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[014/030] Train loss: 0.0191
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 12:00:25 | Train | Epoch[270/600] Iteration[016/030] Train loss: 0.0193
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[017/030] Train loss: 0.0194
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[018/030] Train loss: 0.0193
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[019/030] Train loss: 0.0193
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 12:00:26 | Train | Epoch[270/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 12:00:27 | Valid | Epoch[270/600] Iteration[001/008] Valid loss: 0.3460
2023-02-06 12:00:27 | Valid | Epoch[270/600] Iteration[002/008] Valid loss: 0.3152
2023-02-06 12:00:27 | Valid | Epoch[270/600] Iteration[003/008] Valid loss: 0.2990
2023-02-06 12:00:27 | Valid | Epoch[270/600] Iteration[004/008] Valid loss: 0.3081
2023-02-06 12:00:27 | Valid | Epoch[270/600] Iteration[005/008] Valid loss: 0.3128
2023-02-06 12:00:27 | Valid | Epoch[270/600] Iteration[006/008] Valid loss: 0.3068
2023-02-06 12:00:27 | Valid | Epoch[270/600] Iteration[007/008] Valid loss: 0.3326
2023-02-06 12:00:27 | Valid | Epoch[270/600] Iteration[008/008] Valid loss: 0.3268
2023-02-06 12:00:27 | Valid | Epoch[270/600] MIou: 0.9067956582690235
2023-02-06 12:00:27 | Valid | Epoch[270/600] Pixel Accuracy: 0.9822006225585938
2023-02-06 12:00:27 | Valid | Epoch[270/600] Mean Pixel Accuracy: 0.9829695440948083
2023-02-06 12:00:27 | Stage | Epoch[270/600] Train loss:0.0198
2023-02-06 12:00:27 | Stage | Epoch[270/600] Valid loss:0.3268
2023-02-06 12:00:27 | Stage | Epoch[270/600] LR:0.01

2023-02-06 12:00:27 | Train | Epoch[271/600] Iteration[001/030] Train loss: 0.0213
2023-02-06 12:00:27 | Train | Epoch[271/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[003/030] Train loss: 0.0205
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 12:00:28 | Train | Epoch[271/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 12:00:29 | Train | Epoch[271/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 12:00:30 | Valid | Epoch[271/600] Iteration[001/008] Valid loss: 0.6723
2023-02-06 12:00:30 | Valid | Epoch[271/600] Iteration[002/008] Valid loss: 0.5822
2023-02-06 12:00:30 | Valid | Epoch[271/600] Iteration[003/008] Valid loss: 0.5942
2023-02-06 12:00:30 | Valid | Epoch[271/600] Iteration[004/008] Valid loss: 0.6209
2023-02-06 12:00:30 | Valid | Epoch[271/600] Iteration[005/008] Valid loss: 0.6443
2023-02-06 12:00:30 | Valid | Epoch[271/600] Iteration[006/008] Valid loss: 0.6215
2023-02-06 12:00:30 | Valid | Epoch[271/600] Iteration[007/008] Valid loss: 0.6576
2023-02-06 12:00:30 | Valid | Epoch[271/600] Iteration[008/008] Valid loss: 0.6549
2023-02-06 12:00:30 | Valid | Epoch[271/600] MIou: 0.8844700037884916
2023-02-06 12:00:30 | Valid | Epoch[271/600] Pixel Accuracy: 0.9768880208333334
2023-02-06 12:00:30 | Valid | Epoch[271/600] Mean Pixel Accuracy: 0.9819960363638303
2023-02-06 12:00:30 | Stage | Epoch[271/600] Train loss:0.0203
2023-02-06 12:00:30 | Stage | Epoch[271/600] Valid loss:0.6549
2023-02-06 12:00:30 | Stage | Epoch[271/600] LR:0.01

2023-02-06 12:00:30 | Train | Epoch[272/600] Iteration[001/030] Train loss: 0.0192
2023-02-06 12:00:30 | Train | Epoch[272/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 12:00:30 | Train | Epoch[272/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[004/030] Train loss: 0.0191
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 12:00:31 | Train | Epoch[272/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 12:00:32 | Train | Epoch[272/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 12:00:33 | Valid | Epoch[272/600] Iteration[001/008] Valid loss: 0.4519
2023-02-06 12:00:33 | Valid | Epoch[272/600] Iteration[002/008] Valid loss: 0.3904
2023-02-06 12:00:33 | Valid | Epoch[272/600] Iteration[003/008] Valid loss: 0.3927
2023-02-06 12:00:33 | Valid | Epoch[272/600] Iteration[004/008] Valid loss: 0.3915
2023-02-06 12:00:33 | Valid | Epoch[272/600] Iteration[005/008] Valid loss: 0.4103
2023-02-06 12:00:33 | Valid | Epoch[272/600] Iteration[006/008] Valid loss: 0.3948
2023-02-06 12:00:33 | Valid | Epoch[272/600] Iteration[007/008] Valid loss: 0.4226
2023-02-06 12:00:33 | Valid | Epoch[272/600] Iteration[008/008] Valid loss: 0.4317
2023-02-06 12:00:33 | Valid | Epoch[272/600] MIou: 0.8975293602783276
2023-02-06 12:00:33 | Valid | Epoch[272/600] Pixel Accuracy: 0.9800885518391927
2023-02-06 12:00:33 | Valid | Epoch[272/600] Mean Pixel Accuracy: 0.9816945314625707
2023-02-06 12:00:33 | Stage | Epoch[272/600] Train loss:0.0202
2023-02-06 12:00:33 | Stage | Epoch[272/600] Valid loss:0.4317
2023-02-06 12:00:33 | Stage | Epoch[272/600] LR:0.01

2023-02-06 12:00:33 | Train | Epoch[273/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 12:00:33 | Train | Epoch[273/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 12:00:33 | Train | Epoch[273/600] Iteration[003/030] Train loss: 0.0196
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 12:00:34 | Train | Epoch[273/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 12:00:35 | Train | Epoch[273/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 12:00:36 | Valid | Epoch[273/600] Iteration[001/008] Valid loss: 0.1233
2023-02-06 12:00:36 | Valid | Epoch[273/600] Iteration[002/008] Valid loss: 0.0849
2023-02-06 12:00:36 | Valid | Epoch[273/600] Iteration[003/008] Valid loss: 0.0862
2023-02-06 12:00:36 | Valid | Epoch[273/600] Iteration[004/008] Valid loss: 0.0812
2023-02-06 12:00:36 | Valid | Epoch[273/600] Iteration[005/008] Valid loss: 0.0786
2023-02-06 12:00:36 | Valid | Epoch[273/600] Iteration[006/008] Valid loss: 0.0753
2023-02-06 12:00:36 | Valid | Epoch[273/600] Iteration[007/008] Valid loss: 0.0824
2023-02-06 12:00:36 | Valid | Epoch[273/600] Iteration[008/008] Valid loss: 0.0789
2023-02-06 12:00:36 | Valid | Epoch[273/600] MIou: 0.9397269117574122
2023-02-06 12:00:36 | Valid | Epoch[273/600] Pixel Accuracy: 0.9896354675292969
2023-02-06 12:00:36 | Valid | Epoch[273/600] Mean Pixel Accuracy: 0.9654287036514715
2023-02-06 12:00:36 | Stage | Epoch[273/600] Train loss:0.0198
2023-02-06 12:00:36 | Stage | Epoch[273/600] Valid loss:0.0789
2023-02-06 12:00:36 | Stage | Epoch[273/600] LR:0.01

2023-02-06 12:00:36 | Train | Epoch[274/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 12:00:36 | Train | Epoch[274/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 12:00:36 | Train | Epoch[274/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[007/030] Train loss: 0.0192
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[016/030] Train loss: 0.0193
2023-02-06 12:00:37 | Train | Epoch[274/600] Iteration[017/030] Train loss: 0.0192
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[018/030] Train loss: 0.0191
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[019/030] Train loss: 0.0192
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[020/030] Train loss: 0.0192
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[021/030] Train loss: 0.0193
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[022/030] Train loss: 0.0193
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[023/030] Train loss: 0.0192
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[024/030] Train loss: 0.0196
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[025/030] Train loss: 0.0195
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[026/030] Train loss: 0.0195
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[027/030] Train loss: 0.0194
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[028/030] Train loss: 0.0193
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[029/030] Train loss: 0.0193
2023-02-06 12:00:38 | Train | Epoch[274/600] Iteration[030/030] Train loss: 0.0194
2023-02-06 12:00:39 | Valid | Epoch[274/600] Iteration[001/008] Valid loss: 0.0525
2023-02-06 12:00:39 | Valid | Epoch[274/600] Iteration[002/008] Valid loss: 0.0499
2023-02-06 12:00:39 | Valid | Epoch[274/600] Iteration[003/008] Valid loss: 0.0534
2023-02-06 12:00:39 | Valid | Epoch[274/600] Iteration[004/008] Valid loss: 0.0505
2023-02-06 12:00:39 | Valid | Epoch[274/600] Iteration[005/008] Valid loss: 0.0508
2023-02-06 12:00:39 | Valid | Epoch[274/600] Iteration[006/008] Valid loss: 0.0495
2023-02-06 12:00:39 | Valid | Epoch[274/600] Iteration[007/008] Valid loss: 0.0481
2023-02-06 12:00:39 | Valid | Epoch[274/600] Iteration[008/008] Valid loss: 0.0492
2023-02-06 12:00:39 | Valid | Epoch[274/600] MIou: 0.8452988737388181
2023-02-06 12:00:39 | Valid | Epoch[274/600] Pixel Accuracy: 0.9744707743326823
2023-02-06 12:00:39 | Valid | Epoch[274/600] Mean Pixel Accuracy: 0.8595644087132783
2023-02-06 12:00:39 | Stage | Epoch[274/600] Train loss:0.0194
2023-02-06 12:00:39 | Stage | Epoch[274/600] Valid loss:0.0492
2023-02-06 12:00:39 | Stage | Epoch[274/600] LR:0.01

2023-02-06 12:00:39 | Train | Epoch[275/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 12:00:39 | Train | Epoch[275/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 12:00:39 | Train | Epoch[275/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[004/030] Train loss: 0.0201
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 12:00:40 | Train | Epoch[275/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 12:00:41 | Train | Epoch[275/600] Iteration[030/030] Train loss: 0.0197
2023-02-06 12:00:42 | Valid | Epoch[275/600] Iteration[001/008] Valid loss: 0.0767
2023-02-06 12:00:42 | Valid | Epoch[275/600] Iteration[002/008] Valid loss: 0.0574
2023-02-06 12:00:42 | Valid | Epoch[275/600] Iteration[003/008] Valid loss: 0.0580
2023-02-06 12:00:42 | Valid | Epoch[275/600] Iteration[004/008] Valid loss: 0.0525
2023-02-06 12:00:42 | Valid | Epoch[275/600] Iteration[005/008] Valid loss: 0.0516
2023-02-06 12:00:42 | Valid | Epoch[275/600] Iteration[006/008] Valid loss: 0.0488
2023-02-06 12:00:42 | Valid | Epoch[275/600] Iteration[007/008] Valid loss: 0.0481
2023-02-06 12:00:42 | Valid | Epoch[275/600] Iteration[008/008] Valid loss: 0.0465
2023-02-06 12:00:42 | Valid | Epoch[275/600] MIou: 0.9060549940876539
2023-02-06 12:00:42 | Valid | Epoch[275/600] Pixel Accuracy: 0.9844182332356771
2023-02-06 12:00:42 | Valid | Epoch[275/600] Mean Pixel Accuracy: 0.9176515294539758
2023-02-06 12:00:42 | Stage | Epoch[275/600] Train loss:0.0197
2023-02-06 12:00:42 | Stage | Epoch[275/600] Valid loss:0.0465
2023-02-06 12:00:42 | Stage | Epoch[275/600] LR:0.01

2023-02-06 12:00:42 | Train | Epoch[276/600] Iteration[001/030] Train loss: 0.0193
2023-02-06 12:00:42 | Train | Epoch[276/600] Iteration[002/030] Train loss: 0.0190
2023-02-06 12:00:42 | Train | Epoch[276/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 12:00:42 | Train | Epoch[276/600] Iteration[004/030] Train loss: 0.0198
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[006/030] Train loss: 0.0204
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[007/030] Train loss: 0.0204
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[014/030] Train loss: 0.0194
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[016/030] Train loss: 0.0193
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[017/030] Train loss: 0.0194
2023-02-06 12:00:43 | Train | Epoch[276/600] Iteration[018/030] Train loss: 0.0195
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[019/030] Train loss: 0.0193
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[022/030] Train loss: 0.0196
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 12:00:44 | Train | Epoch[276/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 12:00:45 | Valid | Epoch[276/600] Iteration[001/008] Valid loss: 0.0545
2023-02-06 12:00:45 | Valid | Epoch[276/600] Iteration[002/008] Valid loss: 0.0464
2023-02-06 12:00:45 | Valid | Epoch[276/600] Iteration[003/008] Valid loss: 0.0469
2023-02-06 12:00:45 | Valid | Epoch[276/600] Iteration[004/008] Valid loss: 0.0437
2023-02-06 12:00:45 | Valid | Epoch[276/600] Iteration[005/008] Valid loss: 0.0432
2023-02-06 12:00:45 | Valid | Epoch[276/600] Iteration[006/008] Valid loss: 0.0416
2023-02-06 12:00:45 | Valid | Epoch[276/600] Iteration[007/008] Valid loss: 0.0409
2023-02-06 12:00:45 | Valid | Epoch[276/600] Iteration[008/008] Valid loss: 0.0410
2023-02-06 12:00:45 | Valid | Epoch[276/600] MIou: 0.8832574821407421
2023-02-06 12:00:45 | Valid | Epoch[276/600] Pixel Accuracy: 0.9806849161783854
2023-02-06 12:00:45 | Valid | Epoch[276/600] Mean Pixel Accuracy: 0.8955573087274825
2023-02-06 12:00:45 | Stage | Epoch[276/600] Train loss:0.0198
2023-02-06 12:00:45 | Stage | Epoch[276/600] Valid loss:0.0410
2023-02-06 12:00:45 | Stage | Epoch[276/600] LR:0.01

2023-02-06 12:00:45 | Train | Epoch[277/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 12:00:45 | Train | Epoch[277/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 12:00:45 | Train | Epoch[277/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 12:00:45 | Train | Epoch[277/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[017/030] Train loss: 0.0196
2023-02-06 12:00:46 | Train | Epoch[277/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[021/030] Train loss: 0.0195
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[024/030] Train loss: 0.0196
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[027/030] Train loss: 0.0197
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[029/030] Train loss: 0.0196
2023-02-06 12:00:47 | Train | Epoch[277/600] Iteration[030/030] Train loss: 0.0196
2023-02-06 12:00:48 | Valid | Epoch[277/600] Iteration[001/008] Valid loss: 0.2155
2023-02-06 12:00:48 | Valid | Epoch[277/600] Iteration[002/008] Valid loss: 0.2209
2023-02-06 12:00:48 | Valid | Epoch[277/600] Iteration[003/008] Valid loss: 0.2392
2023-02-06 12:00:48 | Valid | Epoch[277/600] Iteration[004/008] Valid loss: 0.2362
2023-02-06 12:00:48 | Valid | Epoch[277/600] Iteration[005/008] Valid loss: 0.2447
2023-02-06 12:00:48 | Valid | Epoch[277/600] Iteration[006/008] Valid loss: 0.2400
2023-02-06 12:00:48 | Valid | Epoch[277/600] Iteration[007/008] Valid loss: 0.2365
2023-02-06 12:00:48 | Valid | Epoch[277/600] Iteration[008/008] Valid loss: 0.2474
2023-02-06 12:00:48 | Valid | Epoch[277/600] MIou: 0.4759096672342598
2023-02-06 12:00:48 | Valid | Epoch[277/600] Pixel Accuracy: 0.9131978352864584
2023-02-06 12:00:48 | Valid | Epoch[277/600] Mean Pixel Accuracy: 0.5194638809500345
2023-02-06 12:00:48 | Stage | Epoch[277/600] Train loss:0.0196
2023-02-06 12:00:48 | Stage | Epoch[277/600] Valid loss:0.2474
2023-02-06 12:00:48 | Stage | Epoch[277/600] LR:0.01

2023-02-06 12:00:48 | Train | Epoch[278/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 12:00:48 | Train | Epoch[278/600] Iteration[002/030] Train loss: 0.0212
2023-02-06 12:00:48 | Train | Epoch[278/600] Iteration[003/030] Train loss: 0.0212
2023-02-06 12:00:48 | Train | Epoch[278/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 12:00:49 | Train | Epoch[278/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[021/030] Train loss: 0.0194
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[022/030] Train loss: 0.0193
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[023/030] Train loss: 0.0193
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[024/030] Train loss: 0.0192
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[025/030] Train loss: 0.0193
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[026/030] Train loss: 0.0192
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[027/030] Train loss: 0.0192
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[028/030] Train loss: 0.0192
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[029/030] Train loss: 0.0194
2023-02-06 12:00:50 | Train | Epoch[278/600] Iteration[030/030] Train loss: 0.0193
2023-02-06 12:00:51 | Valid | Epoch[278/600] Iteration[001/008] Valid loss: 0.0526
2023-02-06 12:00:51 | Valid | Epoch[278/600] Iteration[002/008] Valid loss: 0.0507
2023-02-06 12:00:51 | Valid | Epoch[278/600] Iteration[003/008] Valid loss: 0.0528
2023-02-06 12:00:51 | Valid | Epoch[278/600] Iteration[004/008] Valid loss: 0.0504
2023-02-06 12:00:51 | Valid | Epoch[278/600] Iteration[005/008] Valid loss: 0.0502
2023-02-06 12:00:51 | Valid | Epoch[278/600] Iteration[006/008] Valid loss: 0.0493
2023-02-06 12:00:51 | Valid | Epoch[278/600] Iteration[007/008] Valid loss: 0.0481
2023-02-06 12:00:51 | Valid | Epoch[278/600] Iteration[008/008] Valid loss: 0.0495
2023-02-06 12:00:51 | Valid | Epoch[278/600] MIou: 0.8331304667756207
2023-02-06 12:00:51 | Valid | Epoch[278/600] Pixel Accuracy: 0.9724515279134115
2023-02-06 12:00:51 | Valid | Epoch[278/600] Mean Pixel Accuracy: 0.8484936640169927
2023-02-06 12:00:51 | Stage | Epoch[278/600] Train loss:0.0193
2023-02-06 12:00:51 | Stage | Epoch[278/600] Valid loss:0.0495
2023-02-06 12:00:51 | Stage | Epoch[278/600] LR:0.01

2023-02-06 12:00:51 | Train | Epoch[279/600] Iteration[001/030] Train loss: 0.0168
2023-02-06 12:00:51 | Train | Epoch[279/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:00:51 | Train | Epoch[279/600] Iteration[003/030] Train loss: 0.0172
2023-02-06 12:00:51 | Train | Epoch[279/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[009/030] Train loss: 0.0184
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[010/030] Train loss: 0.0185
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[011/030] Train loss: 0.0184
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[012/030] Train loss: 0.0184
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[013/030] Train loss: 0.0183
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[015/030] Train loss: 0.0184
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[017/030] Train loss: 0.0186
2023-02-06 12:00:52 | Train | Epoch[279/600] Iteration[018/030] Train loss: 0.0187
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[019/030] Train loss: 0.0188
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[020/030] Train loss: 0.0190
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[021/030] Train loss: 0.0191
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[022/030] Train loss: 0.0193
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[023/030] Train loss: 0.0192
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[024/030] Train loss: 0.0191
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[025/030] Train loss: 0.0191
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[026/030] Train loss: 0.0192
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[027/030] Train loss: 0.0193
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[028/030] Train loss: 0.0192
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[029/030] Train loss: 0.0192
2023-02-06 12:00:53 | Train | Epoch[279/600] Iteration[030/030] Train loss: 0.0192
2023-02-06 12:00:54 | Valid | Epoch[279/600] Iteration[001/008] Valid loss: 0.1761
2023-02-06 12:00:54 | Valid | Epoch[279/600] Iteration[002/008] Valid loss: 0.1338
2023-02-06 12:00:54 | Valid | Epoch[279/600] Iteration[003/008] Valid loss: 0.1297
2023-02-06 12:00:54 | Valid | Epoch[279/600] Iteration[004/008] Valid loss: 0.1234
2023-02-06 12:00:54 | Valid | Epoch[279/600] Iteration[005/008] Valid loss: 0.1241
2023-02-06 12:00:54 | Valid | Epoch[279/600] Iteration[006/008] Valid loss: 0.1183
2023-02-06 12:00:54 | Valid | Epoch[279/600] Iteration[007/008] Valid loss: 0.1298
2023-02-06 12:00:54 | Valid | Epoch[279/600] Iteration[008/008] Valid loss: 0.1278
2023-02-06 12:00:54 | Valid | Epoch[279/600] MIou: 0.9335553407310322
2023-02-06 12:00:54 | Valid | Epoch[279/600] Pixel Accuracy: 0.9881884256998698
2023-02-06 12:00:54 | Valid | Epoch[279/600] Mean Pixel Accuracy: 0.9752346161153744
2023-02-06 12:00:54 | Stage | Epoch[279/600] Train loss:0.0192
2023-02-06 12:00:54 | Stage | Epoch[279/600] Valid loss:0.1278
2023-02-06 12:00:54 | Stage | Epoch[279/600] LR:0.01

2023-02-06 12:00:54 | Train | Epoch[280/600] Iteration[001/030] Train loss: 0.0215
2023-02-06 12:00:54 | Train | Epoch[280/600] Iteration[002/030] Train loss: 0.0214
2023-02-06 12:00:54 | Train | Epoch[280/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 12:00:54 | Train | Epoch[280/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 12:00:54 | Train | Epoch[280/600] Iteration[005/030] Train loss: 0.0193
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[006/030] Train loss: 0.0190
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[008/030] Train loss: 0.0188
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[009/030] Train loss: 0.0191
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[010/030] Train loss: 0.0193
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[011/030] Train loss: 0.0190
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[014/030] Train loss: 0.0195
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 12:00:55 | Train | Epoch[280/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[026/030] Train loss: 0.0196
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 12:00:56 | Train | Epoch[280/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 12:00:57 | Valid | Epoch[280/600] Iteration[001/008] Valid loss: 0.1048
2023-02-06 12:00:57 | Valid | Epoch[280/600] Iteration[002/008] Valid loss: 0.1040
2023-02-06 12:00:57 | Valid | Epoch[280/600] Iteration[003/008] Valid loss: 0.0896
2023-02-06 12:00:57 | Valid | Epoch[280/600] Iteration[004/008] Valid loss: 0.0854
2023-02-06 12:00:57 | Valid | Epoch[280/600] Iteration[005/008] Valid loss: 0.0824
2023-02-06 12:00:57 | Valid | Epoch[280/600] Iteration[006/008] Valid loss: 0.0828
2023-02-06 12:00:57 | Valid | Epoch[280/600] Iteration[007/008] Valid loss: 0.0860
2023-02-06 12:00:57 | Valid | Epoch[280/600] Iteration[008/008] Valid loss: 0.0896
2023-02-06 12:00:57 | Valid | Epoch[280/600] MIou: 0.9084949990657558
2023-02-06 12:00:57 | Valid | Epoch[280/600] Pixel Accuracy: 0.984093983968099
2023-02-06 12:00:57 | Valid | Epoch[280/600] Mean Pixel Accuracy: 0.9401848771838879
2023-02-06 12:00:57 | Stage | Epoch[280/600] Train loss:0.0200
2023-02-06 12:00:57 | Stage | Epoch[280/600] Valid loss:0.0896
2023-02-06 12:00:57 | Stage | Epoch[280/600] LR:0.01

2023-02-06 12:00:57 | Train | Epoch[281/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 12:00:57 | Train | Epoch[281/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 12:00:57 | Train | Epoch[281/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 12:00:57 | Train | Epoch[281/600] Iteration[004/030] Train loss: 0.0179
2023-02-06 12:00:57 | Train | Epoch[281/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[006/030] Train loss: 0.0187
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[007/030] Train loss: 0.0188
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[008/030] Train loss: 0.0188
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[009/030] Train loss: 0.0187
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[010/030] Train loss: 0.0191
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[011/030] Train loss: 0.0189
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[012/030] Train loss: 0.0190
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[013/030] Train loss: 0.0190
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[014/030] Train loss: 0.0190
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[015/030] Train loss: 0.0191
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[016/030] Train loss: 0.0190
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[017/030] Train loss: 0.0192
2023-02-06 12:00:58 | Train | Epoch[281/600] Iteration[018/030] Train loss: 0.0192
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[019/030] Train loss: 0.0190
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[020/030] Train loss: 0.0189
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[021/030] Train loss: 0.0189
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[022/030] Train loss: 0.0192
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[023/030] Train loss: 0.0193
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[024/030] Train loss: 0.0193
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[025/030] Train loss: 0.0194
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[026/030] Train loss: 0.0194
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[027/030] Train loss: 0.0194
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[028/030] Train loss: 0.0194
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[029/030] Train loss: 0.0193
2023-02-06 12:00:59 | Train | Epoch[281/600] Iteration[030/030] Train loss: 0.0194
2023-02-06 12:01:00 | Valid | Epoch[281/600] Iteration[001/008] Valid loss: 0.2799
2023-02-06 12:01:00 | Valid | Epoch[281/600] Iteration[002/008] Valid loss: 0.2163
2023-02-06 12:01:00 | Valid | Epoch[281/600] Iteration[003/008] Valid loss: 0.2130
2023-02-06 12:01:00 | Valid | Epoch[281/600] Iteration[004/008] Valid loss: 0.2079
2023-02-06 12:01:00 | Valid | Epoch[281/600] Iteration[005/008] Valid loss: 0.2152
2023-02-06 12:01:00 | Valid | Epoch[281/600] Iteration[006/008] Valid loss: 0.2045
2023-02-06 12:01:00 | Valid | Epoch[281/600] Iteration[007/008] Valid loss: 0.2274
2023-02-06 12:01:00 | Valid | Epoch[281/600] Iteration[008/008] Valid loss: 0.2251
2023-02-06 12:01:00 | Valid | Epoch[281/600] MIou: 0.9245974252392776
2023-02-06 12:01:00 | Valid | Epoch[281/600] Pixel Accuracy: 0.9862353006998698
2023-02-06 12:01:00 | Valid | Epoch[281/600] Mean Pixel Accuracy: 0.9791637273396387
2023-02-06 12:01:00 | Stage | Epoch[281/600] Train loss:0.0194
2023-02-06 12:01:00 | Stage | Epoch[281/600] Valid loss:0.2251
2023-02-06 12:01:00 | Stage | Epoch[281/600] LR:0.01

2023-02-06 12:01:00 | Train | Epoch[282/600] Iteration[001/030] Train loss: 0.0220
2023-02-06 12:01:00 | Train | Epoch[282/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 12:01:00 | Train | Epoch[282/600] Iteration[003/030] Train loss: 0.0212
2023-02-06 12:01:00 | Train | Epoch[282/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[007/030] Train loss: 0.0200
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[012/030] Train loss: 0.0194
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[014/030] Train loss: 0.0195
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[017/030] Train loss: 0.0196
2023-02-06 12:01:01 | Train | Epoch[282/600] Iteration[018/030] Train loss: 0.0195
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[024/030] Train loss: 0.0196
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[025/030] Train loss: 0.0196
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[026/030] Train loss: 0.0194
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[027/030] Train loss: 0.0194
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[028/030] Train loss: 0.0193
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[029/030] Train loss: 0.0193
2023-02-06 12:01:02 | Train | Epoch[282/600] Iteration[030/030] Train loss: 0.0192
2023-02-06 12:01:03 | Valid | Epoch[282/600] Iteration[001/008] Valid loss: 0.0530
2023-02-06 12:01:03 | Valid | Epoch[282/600] Iteration[002/008] Valid loss: 0.0455
2023-02-06 12:01:03 | Valid | Epoch[282/600] Iteration[003/008] Valid loss: 0.0457
2023-02-06 12:01:03 | Valid | Epoch[282/600] Iteration[004/008] Valid loss: 0.0430
2023-02-06 12:01:03 | Valid | Epoch[282/600] Iteration[005/008] Valid loss: 0.0429
2023-02-06 12:01:03 | Valid | Epoch[282/600] Iteration[006/008] Valid loss: 0.0418
2023-02-06 12:01:03 | Valid | Epoch[282/600] Iteration[007/008] Valid loss: 0.0413
2023-02-06 12:01:03 | Valid | Epoch[282/600] Iteration[008/008] Valid loss: 0.0415
2023-02-06 12:01:03 | Valid | Epoch[282/600] MIou: 0.8777671742838336
2023-02-06 12:01:03 | Valid | Epoch[282/600] Pixel Accuracy: 0.9798049926757812
2023-02-06 12:01:03 | Valid | Epoch[282/600] Mean Pixel Accuracy: 0.8899378833178369
2023-02-06 12:01:03 | Stage | Epoch[282/600] Train loss:0.0192
2023-02-06 12:01:03 | Stage | Epoch[282/600] Valid loss:0.0415
2023-02-06 12:01:03 | Stage | Epoch[282/600] LR:0.01

2023-02-06 12:01:03 | Train | Epoch[283/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 12:01:03 | Train | Epoch[283/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 12:01:03 | Train | Epoch[283/600] Iteration[003/030] Train loss: 0.0188
2023-02-06 12:01:03 | Train | Epoch[283/600] Iteration[004/030] Train loss: 0.0182
2023-02-06 12:01:03 | Train | Epoch[283/600] Iteration[005/030] Train loss: 0.0182
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[006/030] Train loss: 0.0184
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[007/030] Train loss: 0.0186
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[008/030] Train loss: 0.0187
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[009/030] Train loss: 0.0189
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[010/030] Train loss: 0.0188
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[011/030] Train loss: 0.0190
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[012/030] Train loss: 0.0191
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[014/030] Train loss: 0.0195
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[018/030] Train loss: 0.0195
2023-02-06 12:01:04 | Train | Epoch[283/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[020/030] Train loss: 0.0196
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[024/030] Train loss: 0.0195
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[025/030] Train loss: 0.0195
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[026/030] Train loss: 0.0196
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[027/030] Train loss: 0.0196
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[028/030] Train loss: 0.0195
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[029/030] Train loss: 0.0196
2023-02-06 12:01:05 | Train | Epoch[283/600] Iteration[030/030] Train loss: 0.0195
2023-02-06 12:01:06 | Valid | Epoch[283/600] Iteration[001/008] Valid loss: 0.0559
2023-02-06 12:01:06 | Valid | Epoch[283/600] Iteration[002/008] Valid loss: 0.0466
2023-02-06 12:01:06 | Valid | Epoch[283/600] Iteration[003/008] Valid loss: 0.0532
2023-02-06 12:01:06 | Valid | Epoch[283/600] Iteration[004/008] Valid loss: 0.0487
2023-02-06 12:01:06 | Valid | Epoch[283/600] Iteration[005/008] Valid loss: 0.0482
2023-02-06 12:01:06 | Valid | Epoch[283/600] Iteration[006/008] Valid loss: 0.0462
2023-02-06 12:01:06 | Valid | Epoch[283/600] Iteration[007/008] Valid loss: 0.0453
2023-02-06 12:01:06 | Valid | Epoch[283/600] Iteration[008/008] Valid loss: 0.0451
2023-02-06 12:01:06 | Valid | Epoch[283/600] MIou: 0.8748058801113338
2023-02-06 12:01:06 | Valid | Epoch[283/600] Pixel Accuracy: 0.9792188008626302
2023-02-06 12:01:06 | Valid | Epoch[283/600] Mean Pixel Accuracy: 0.8890133425032053
2023-02-06 12:01:06 | Stage | Epoch[283/600] Train loss:0.0195
2023-02-06 12:01:06 | Stage | Epoch[283/600] Valid loss:0.0451
2023-02-06 12:01:06 | Stage | Epoch[283/600] LR:0.01

2023-02-06 12:01:06 | Train | Epoch[284/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 12:01:06 | Train | Epoch[284/600] Iteration[002/030] Train loss: 0.0180
2023-02-06 12:01:06 | Train | Epoch[284/600] Iteration[003/030] Train loss: 0.0180
2023-02-06 12:01:06 | Train | Epoch[284/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:01:06 | Train | Epoch[284/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[007/030] Train loss: 0.0174
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[008/030] Train loss: 0.0177
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[009/030] Train loss: 0.0180
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[010/030] Train loss: 0.0181
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[011/030] Train loss: 0.0182
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[012/030] Train loss: 0.0183
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[013/030] Train loss: 0.0184
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[015/030] Train loss: 0.0188
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[016/030] Train loss: 0.0190
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[017/030] Train loss: 0.0190
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[018/030] Train loss: 0.0191
2023-02-06 12:01:07 | Train | Epoch[284/600] Iteration[019/030] Train loss: 0.0192
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[021/030] Train loss: 0.0193
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[022/030] Train loss: 0.0193
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[023/030] Train loss: 0.0192
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[024/030] Train loss: 0.0192
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[025/030] Train loss: 0.0192
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[026/030] Train loss: 0.0192
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[027/030] Train loss: 0.0192
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[028/030] Train loss: 0.0191
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[029/030] Train loss: 0.0191
2023-02-06 12:01:08 | Train | Epoch[284/600] Iteration[030/030] Train loss: 0.0191
2023-02-06 12:01:09 | Valid | Epoch[284/600] Iteration[001/008] Valid loss: 0.0565
2023-02-06 12:01:09 | Valid | Epoch[284/600] Iteration[002/008] Valid loss: 0.0539
2023-02-06 12:01:09 | Valid | Epoch[284/600] Iteration[003/008] Valid loss: 0.0557
2023-02-06 12:01:09 | Valid | Epoch[284/600] Iteration[004/008] Valid loss: 0.0535
2023-02-06 12:01:09 | Valid | Epoch[284/600] Iteration[005/008] Valid loss: 0.0537
2023-02-06 12:01:09 | Valid | Epoch[284/600] Iteration[006/008] Valid loss: 0.0525
2023-02-06 12:01:09 | Valid | Epoch[284/600] Iteration[007/008] Valid loss: 0.0511
2023-02-06 12:01:09 | Valid | Epoch[284/600] Iteration[008/008] Valid loss: 0.0519
2023-02-06 12:01:09 | Valid | Epoch[284/600] MIou: 0.8437801758832938
2023-02-06 12:01:09 | Valid | Epoch[284/600] Pixel Accuracy: 0.9742329915364584
2023-02-06 12:01:09 | Valid | Epoch[284/600] Mean Pixel Accuracy: 0.8579880856425284
2023-02-06 12:01:09 | Stage | Epoch[284/600] Train loss:0.0191
2023-02-06 12:01:09 | Stage | Epoch[284/600] Valid loss:0.0519
2023-02-06 12:01:09 | Stage | Epoch[284/600] LR:0.01

2023-02-06 12:01:09 | Train | Epoch[285/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 12:01:09 | Train | Epoch[285/600] Iteration[002/030] Train loss: 0.0180
2023-02-06 12:01:09 | Train | Epoch[285/600] Iteration[003/030] Train loss: 0.0176
2023-02-06 12:01:09 | Train | Epoch[285/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:01:09 | Train | Epoch[285/600] Iteration[005/030] Train loss: 0.0179
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[006/030] Train loss: 0.0183
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[008/030] Train loss: 0.0186
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[009/030] Train loss: 0.0184
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[010/030] Train loss: 0.0181
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[011/030] Train loss: 0.0187
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[012/030] Train loss: 0.0188
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[013/030] Train loss: 0.0189
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[014/030] Train loss: 0.0190
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[015/030] Train loss: 0.0189
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[016/030] Train loss: 0.0188
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[017/030] Train loss: 0.0190
2023-02-06 12:01:10 | Train | Epoch[285/600] Iteration[018/030] Train loss: 0.0191
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[019/030] Train loss: 0.0191
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[020/030] Train loss: 0.0192
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[021/030] Train loss: 0.0192
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[022/030] Train loss: 0.0193
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[023/030] Train loss: 0.0194
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[024/030] Train loss: 0.0193
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[025/030] Train loss: 0.0196
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[026/030] Train loss: 0.0196
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[027/030] Train loss: 0.0197
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[029/030] Train loss: 0.0197
2023-02-06 12:01:11 | Train | Epoch[285/600] Iteration[030/030] Train loss: 0.0196
2023-02-06 12:01:12 | Valid | Epoch[285/600] Iteration[001/008] Valid loss: 0.0852
2023-02-06 12:01:12 | Valid | Epoch[285/600] Iteration[002/008] Valid loss: 0.0642
2023-02-06 12:01:12 | Valid | Epoch[285/600] Iteration[003/008] Valid loss: 0.0686
2023-02-06 12:01:12 | Valid | Epoch[285/600] Iteration[004/008] Valid loss: 0.0633
2023-02-06 12:01:12 | Valid | Epoch[285/600] Iteration[005/008] Valid loss: 0.0615
2023-02-06 12:01:12 | Valid | Epoch[285/600] Iteration[006/008] Valid loss: 0.0589
2023-02-06 12:01:12 | Valid | Epoch[285/600] Iteration[007/008] Valid loss: 0.0602
2023-02-06 12:01:12 | Valid | Epoch[285/600] Iteration[008/008] Valid loss: 0.0568
2023-02-06 12:01:12 | Valid | Epoch[285/600] MIou: 0.929334706472727
2023-02-06 12:01:12 | Valid | Epoch[285/600] Pixel Accuracy: 0.9880828857421875
2023-02-06 12:01:12 | Valid | Epoch[285/600] Mean Pixel Accuracy: 0.9465937612770061
2023-02-06 12:01:12 | Stage | Epoch[285/600] Train loss:0.0196
2023-02-06 12:01:12 | Stage | Epoch[285/600] Valid loss:0.0568
2023-02-06 12:01:12 | Stage | Epoch[285/600] LR:0.01

2023-02-06 12:01:12 | Train | Epoch[286/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 12:01:12 | Train | Epoch[286/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 12:01:12 | Train | Epoch[286/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 12:01:12 | Train | Epoch[286/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[009/030] Train loss: 0.0192
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[011/030] Train loss: 0.0192
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[013/030] Train loss: 0.0191
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[014/030] Train loss: 0.0192
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[016/030] Train loss: 0.0193
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[017/030] Train loss: 0.0193
2023-02-06 12:01:13 | Train | Epoch[286/600] Iteration[018/030] Train loss: 0.0191
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[019/030] Train loss: 0.0192
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[020/030] Train loss: 0.0193
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[021/030] Train loss: 0.0193
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[022/030] Train loss: 0.0195
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[023/030] Train loss: 0.0194
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[024/030] Train loss: 0.0194
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[025/030] Train loss: 0.0194
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[026/030] Train loss: 0.0194
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[027/030] Train loss: 0.0194
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[028/030] Train loss: 0.0195
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[029/030] Train loss: 0.0196
2023-02-06 12:01:14 | Train | Epoch[286/600] Iteration[030/030] Train loss: 0.0196
2023-02-06 12:01:15 | Valid | Epoch[286/600] Iteration[001/008] Valid loss: 0.3311
2023-02-06 12:01:15 | Valid | Epoch[286/600] Iteration[002/008] Valid loss: 0.2879
2023-02-06 12:01:15 | Valid | Epoch[286/600] Iteration[003/008] Valid loss: 0.2903
2023-02-06 12:01:15 | Valid | Epoch[286/600] Iteration[004/008] Valid loss: 0.2815
2023-02-06 12:01:15 | Valid | Epoch[286/600] Iteration[005/008] Valid loss: 0.2927
2023-02-06 12:01:15 | Valid | Epoch[286/600] Iteration[006/008] Valid loss: 0.2827
2023-02-06 12:01:15 | Valid | Epoch[286/600] Iteration[007/008] Valid loss: 0.3011
2023-02-06 12:01:15 | Valid | Epoch[286/600] Iteration[008/008] Valid loss: 0.3005
2023-02-06 12:01:15 | Valid | Epoch[286/600] MIou: 0.9192351107956586
2023-02-06 12:01:15 | Valid | Epoch[286/600] Pixel Accuracy: 0.9850107828776041
2023-02-06 12:01:15 | Valid | Epoch[286/600] Mean Pixel Accuracy: 0.9818067467209173
2023-02-06 12:01:15 | Stage | Epoch[286/600] Train loss:0.0196
2023-02-06 12:01:15 | Stage | Epoch[286/600] Valid loss:0.3005
2023-02-06 12:01:15 | Stage | Epoch[286/600] LR:0.01

2023-02-06 12:01:15 | Train | Epoch[287/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 12:01:15 | Train | Epoch[287/600] Iteration[002/030] Train loss: 0.0206
2023-02-06 12:01:15 | Train | Epoch[287/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 12:01:15 | Train | Epoch[287/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 12:01:15 | Train | Epoch[287/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[007/030] Train loss: 0.0200
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[014/030] Train loss: 0.0192
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[017/030] Train loss: 0.0196
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 12:01:16 | Train | Epoch[287/600] Iteration[019/030] Train loss: 0.0194
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[021/030] Train loss: 0.0194
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[022/030] Train loss: 0.0196
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 12:01:17 | Train | Epoch[287/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 12:01:18 | Valid | Epoch[287/600] Iteration[001/008] Valid loss: 0.0909
2023-02-06 12:01:18 | Valid | Epoch[287/600] Iteration[002/008] Valid loss: 0.0608
2023-02-06 12:01:18 | Valid | Epoch[287/600] Iteration[003/008] Valid loss: 0.0603
2023-02-06 12:01:18 | Valid | Epoch[287/600] Iteration[004/008] Valid loss: 0.0553
2023-02-06 12:01:18 | Valid | Epoch[287/600] Iteration[005/008] Valid loss: 0.0533
2023-02-06 12:01:18 | Valid | Epoch[287/600] Iteration[006/008] Valid loss: 0.0511
2023-02-06 12:01:18 | Valid | Epoch[287/600] Iteration[007/008] Valid loss: 0.0540
2023-02-06 12:01:18 | Valid | Epoch[287/600] Iteration[008/008] Valid loss: 0.0514
2023-02-06 12:01:18 | Valid | Epoch[287/600] MIou: 0.9196274342695945
2023-02-06 12:01:18 | Valid | Epoch[287/600] Pixel Accuracy: 0.9864896138509115
2023-02-06 12:01:18 | Valid | Epoch[287/600] Mean Pixel Accuracy: 0.9360297906237002
2023-02-06 12:01:18 | Stage | Epoch[287/600] Train loss:0.0200
2023-02-06 12:01:18 | Stage | Epoch[287/600] Valid loss:0.0514
2023-02-06 12:01:18 | Stage | Epoch[287/600] LR:0.01

2023-02-06 12:01:18 | Train | Epoch[288/600] Iteration[001/030] Train loss: 0.0195
2023-02-06 12:01:18 | Train | Epoch[288/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 12:01:18 | Train | Epoch[288/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 12:01:18 | Train | Epoch[288/600] Iteration[004/030] Train loss: 0.0185
2023-02-06 12:01:18 | Train | Epoch[288/600] Iteration[005/030] Train loss: 0.0184
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[010/030] Train loss: 0.0192
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[011/030] Train loss: 0.0191
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[016/030] Train loss: 0.0193
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[017/030] Train loss: 0.0192
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[018/030] Train loss: 0.0192
2023-02-06 12:01:19 | Train | Epoch[288/600] Iteration[019/030] Train loss: 0.0194
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 12:01:20 | Train | Epoch[288/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 12:01:21 | Valid | Epoch[288/600] Iteration[001/008] Valid loss: 1.0009
2023-02-06 12:01:21 | Valid | Epoch[288/600] Iteration[002/008] Valid loss: 0.9099
2023-02-06 12:01:21 | Valid | Epoch[288/600] Iteration[003/008] Valid loss: 0.9123
2023-02-06 12:01:21 | Valid | Epoch[288/600] Iteration[004/008] Valid loss: 0.9486
2023-02-06 12:01:21 | Valid | Epoch[288/600] Iteration[005/008] Valid loss: 0.9676
2023-02-06 12:01:21 | Valid | Epoch[288/600] Iteration[006/008] Valid loss: 0.9463
2023-02-06 12:01:21 | Valid | Epoch[288/600] Iteration[007/008] Valid loss: 0.9883
2023-02-06 12:01:21 | Valid | Epoch[288/600] Iteration[008/008] Valid loss: 1.0184
2023-02-06 12:01:21 | Valid | Epoch[288/600] MIou: 0.8472895391938969
2023-02-06 12:01:21 | Valid | Epoch[288/600] Pixel Accuracy: 0.9671058654785156
2023-02-06 12:01:21 | Valid | Epoch[288/600] Mean Pixel Accuracy: 0.9766003251674507
2023-02-06 12:01:21 | Stage | Epoch[288/600] Train loss:0.0198
2023-02-06 12:01:21 | Stage | Epoch[288/600] Valid loss:1.0184
2023-02-06 12:01:21 | Stage | Epoch[288/600] LR:0.01

2023-02-06 12:01:21 | Train | Epoch[289/600] Iteration[001/030] Train loss: 0.0161
2023-02-06 12:01:21 | Train | Epoch[289/600] Iteration[002/030] Train loss: 0.0165
2023-02-06 12:01:21 | Train | Epoch[289/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 12:01:21 | Train | Epoch[289/600] Iteration[004/030] Train loss: 0.0177
2023-02-06 12:01:21 | Train | Epoch[289/600] Iteration[005/030] Train loss: 0.0179
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[008/030] Train loss: 0.0184
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[009/030] Train loss: 0.0186
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[010/030] Train loss: 0.0189
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[011/030] Train loss: 0.0191
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[012/030] Train loss: 0.0191
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[013/030] Train loss: 0.0191
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[014/030] Train loss: 0.0189
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[015/030] Train loss: 0.0189
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[016/030] Train loss: 0.0190
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[017/030] Train loss: 0.0189
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[018/030] Train loss: 0.0193
2023-02-06 12:01:22 | Train | Epoch[289/600] Iteration[019/030] Train loss: 0.0192
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[020/030] Train loss: 0.0193
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[021/030] Train loss: 0.0193
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[022/030] Train loss: 0.0195
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 12:01:23 | Train | Epoch[289/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 12:01:24 | Valid | Epoch[289/600] Iteration[001/008] Valid loss: 0.0979
2023-02-06 12:01:24 | Valid | Epoch[289/600] Iteration[002/008] Valid loss: 0.0727
2023-02-06 12:01:24 | Valid | Epoch[289/600] Iteration[003/008] Valid loss: 0.0740
2023-02-06 12:01:24 | Valid | Epoch[289/600] Iteration[004/008] Valid loss: 0.0670
2023-02-06 12:01:24 | Valid | Epoch[289/600] Iteration[005/008] Valid loss: 0.0654
2023-02-06 12:01:24 | Valid | Epoch[289/600] Iteration[006/008] Valid loss: 0.0626
2023-02-06 12:01:24 | Valid | Epoch[289/600] Iteration[007/008] Valid loss: 0.0626
2023-02-06 12:01:24 | Valid | Epoch[289/600] Iteration[008/008] Valid loss: 0.0592
2023-02-06 12:01:24 | Valid | Epoch[289/600] MIou: 0.9136955274286357
2023-02-06 12:01:24 | Valid | Epoch[289/600] Pixel Accuracy: 0.9855791727701823
2023-02-06 12:01:24 | Valid | Epoch[289/600] Mean Pixel Accuracy: 0.9278827647327903
2023-02-06 12:01:24 | Stage | Epoch[289/600] Train loss:0.0200
2023-02-06 12:01:24 | Stage | Epoch[289/600] Valid loss:0.0592
2023-02-06 12:01:24 | Stage | Epoch[289/600] LR:0.01

2023-02-06 12:01:24 | Train | Epoch[290/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 12:01:24 | Train | Epoch[290/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 12:01:24 | Train | Epoch[290/600] Iteration[003/030] Train loss: 0.0188
2023-02-06 12:01:24 | Train | Epoch[290/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 12:01:24 | Train | Epoch[290/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 12:01:24 | Train | Epoch[290/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 12:01:25 | Train | Epoch[290/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 12:01:26 | Train | Epoch[290/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 12:01:26 | Train | Epoch[290/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 12:01:26 | Train | Epoch[290/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 12:01:26 | Train | Epoch[290/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 12:01:26 | Train | Epoch[290/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 12:01:26 | Train | Epoch[290/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 12:01:26 | Train | Epoch[290/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 12:01:26 | Train | Epoch[290/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 12:01:26 | Train | Epoch[290/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 12:01:26 | Train | Epoch[290/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 12:01:27 | Valid | Epoch[290/600] Iteration[001/008] Valid loss: 0.0541
2023-02-06 12:01:27 | Valid | Epoch[290/600] Iteration[002/008] Valid loss: 0.0507
2023-02-06 12:01:27 | Valid | Epoch[290/600] Iteration[003/008] Valid loss: 0.0524
2023-02-06 12:01:27 | Valid | Epoch[290/600] Iteration[004/008] Valid loss: 0.0502
2023-02-06 12:01:27 | Valid | Epoch[290/600] Iteration[005/008] Valid loss: 0.0497
2023-02-06 12:01:27 | Valid | Epoch[290/600] Iteration[006/008] Valid loss: 0.0488
2023-02-06 12:01:27 | Valid | Epoch[290/600] Iteration[007/008] Valid loss: 0.0489
2023-02-06 12:01:27 | Valid | Epoch[290/600] Iteration[008/008] Valid loss: 0.0496
2023-02-06 12:01:27 | Valid | Epoch[290/600] MIou: 0.8510428361211835
2023-02-06 12:01:27 | Valid | Epoch[290/600] Pixel Accuracy: 0.9753061930338541
2023-02-06 12:01:27 | Valid | Epoch[290/600] Mean Pixel Accuracy: 0.866516233289558
2023-02-06 12:01:27 | Stage | Epoch[290/600] Train loss:0.0201
2023-02-06 12:01:27 | Stage | Epoch[290/600] Valid loss:0.0496
2023-02-06 12:01:27 | Stage | Epoch[290/600] LR:0.01

2023-02-06 12:01:27 | Train | Epoch[291/600] Iteration[001/030] Train loss: 0.0212
2023-02-06 12:01:27 | Train | Epoch[291/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 12:01:27 | Train | Epoch[291/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 12:01:27 | Train | Epoch[291/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 12:01:27 | Train | Epoch[291/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 12:01:27 | Train | Epoch[291/600] Iteration[006/030] Train loss: 0.0189
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[007/030] Train loss: 0.0188
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 12:01:28 | Train | Epoch[291/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 12:01:29 | Train | Epoch[291/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 12:01:29 | Train | Epoch[291/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 12:01:29 | Train | Epoch[291/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 12:01:29 | Train | Epoch[291/600] Iteration[024/030] Train loss: 0.0195
2023-02-06 12:01:29 | Train | Epoch[291/600] Iteration[025/030] Train loss: 0.0194
2023-02-06 12:01:29 | Train | Epoch[291/600] Iteration[026/030] Train loss: 0.0193
2023-02-06 12:01:29 | Train | Epoch[291/600] Iteration[027/030] Train loss: 0.0193
2023-02-06 12:01:29 | Train | Epoch[291/600] Iteration[028/030] Train loss: 0.0194
2023-02-06 12:01:29 | Train | Epoch[291/600] Iteration[029/030] Train loss: 0.0194
2023-02-06 12:01:29 | Train | Epoch[291/600] Iteration[030/030] Train loss: 0.0194
2023-02-06 12:01:30 | Valid | Epoch[291/600] Iteration[001/008] Valid loss: 0.0635
2023-02-06 12:01:30 | Valid | Epoch[291/600] Iteration[002/008] Valid loss: 0.0528
2023-02-06 12:01:30 | Valid | Epoch[291/600] Iteration[003/008] Valid loss: 0.0526
2023-02-06 12:01:30 | Valid | Epoch[291/600] Iteration[004/008] Valid loss: 0.0487
2023-02-06 12:01:30 | Valid | Epoch[291/600] Iteration[005/008] Valid loss: 0.0480
2023-02-06 12:01:30 | Valid | Epoch[291/600] Iteration[006/008] Valid loss: 0.0463
2023-02-06 12:01:30 | Valid | Epoch[291/600] Iteration[007/008] Valid loss: 0.0454
2023-02-06 12:01:30 | Valid | Epoch[291/600] Iteration[008/008] Valid loss: 0.0453
2023-02-06 12:01:30 | Valid | Epoch[291/600] MIou: 0.8811138997669697
2023-02-06 12:01:30 | Valid | Epoch[291/600] Pixel Accuracy: 0.9803390502929688
2023-02-06 12:01:30 | Valid | Epoch[291/600] Mean Pixel Accuracy: 0.8934016599172895
2023-02-06 12:01:30 | Stage | Epoch[291/600] Train loss:0.0194
2023-02-06 12:01:30 | Stage | Epoch[291/600] Valid loss:0.0453
2023-02-06 12:01:30 | Stage | Epoch[291/600] LR:0.01

2023-02-06 12:01:30 | Train | Epoch[292/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 12:01:30 | Train | Epoch[292/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 12:01:30 | Train | Epoch[292/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 12:01:30 | Train | Epoch[292/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[006/030] Train loss: 0.0189
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[007/030] Train loss: 0.0192
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[009/030] Train loss: 0.0191
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[010/030] Train loss: 0.0191
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[011/030] Train loss: 0.0191
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[012/030] Train loss: 0.0191
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[013/030] Train loss: 0.0191
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[014/030] Train loss: 0.0190
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[015/030] Train loss: 0.0192
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[016/030] Train loss: 0.0192
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[017/030] Train loss: 0.0191
2023-02-06 12:01:31 | Train | Epoch[292/600] Iteration[018/030] Train loss: 0.0189
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[019/030] Train loss: 0.0190
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[020/030] Train loss: 0.0190
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[021/030] Train loss: 0.0189
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[022/030] Train loss: 0.0189
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[023/030] Train loss: 0.0189
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[024/030] Train loss: 0.0189
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[025/030] Train loss: 0.0189
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[026/030] Train loss: 0.0190
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[027/030] Train loss: 0.0191
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[028/030] Train loss: 0.0192
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[029/030] Train loss: 0.0192
2023-02-06 12:01:32 | Train | Epoch[292/600] Iteration[030/030] Train loss: 0.0192
2023-02-06 12:01:33 | Valid | Epoch[292/600] Iteration[001/008] Valid loss: 0.2086
2023-02-06 12:01:33 | Valid | Epoch[292/600] Iteration[002/008] Valid loss: 0.1547
2023-02-06 12:01:33 | Valid | Epoch[292/600] Iteration[003/008] Valid loss: 0.1475
2023-02-06 12:01:33 | Valid | Epoch[292/600] Iteration[004/008] Valid loss: 0.1383
2023-02-06 12:01:33 | Valid | Epoch[292/600] Iteration[005/008] Valid loss: 0.1345
2023-02-06 12:01:33 | Valid | Epoch[292/600] Iteration[006/008] Valid loss: 0.1299
2023-02-06 12:01:33 | Valid | Epoch[292/600] Iteration[007/008] Valid loss: 0.1401
2023-02-06 12:01:33 | Valid | Epoch[292/600] Iteration[008/008] Valid loss: 0.1355
2023-02-06 12:01:33 | Valid | Epoch[292/600] MIou: 0.9363160888301452
2023-02-06 12:01:33 | Valid | Epoch[292/600] Pixel Accuracy: 0.9887123107910156
2023-02-06 12:01:33 | Valid | Epoch[292/600] Mean Pixel Accuracy: 0.9765560625610958
2023-02-06 12:01:33 | Stage | Epoch[292/600] Train loss:0.0192
2023-02-06 12:01:33 | Stage | Epoch[292/600] Valid loss:0.1355
2023-02-06 12:01:33 | Stage | Epoch[292/600] LR:0.01

2023-02-06 12:01:33 | Train | Epoch[293/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 12:01:33 | Train | Epoch[293/600] Iteration[002/030] Train loss: 0.0173
2023-02-06 12:01:33 | Train | Epoch[293/600] Iteration[003/030] Train loss: 0.0175
2023-02-06 12:01:33 | Train | Epoch[293/600] Iteration[004/030] Train loss: 0.0182
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[005/030] Train loss: 0.0185
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[006/030] Train loss: 0.0187
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[007/030] Train loss: 0.0188
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[008/030] Train loss: 0.0185
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[009/030] Train loss: 0.0184
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[011/030] Train loss: 0.0187
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[012/030] Train loss: 0.0187
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[013/030] Train loss: 0.0188
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[014/030] Train loss: 0.0189
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[015/030] Train loss: 0.0189
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[016/030] Train loss: 0.0188
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[017/030] Train loss: 0.0187
2023-02-06 12:01:34 | Train | Epoch[293/600] Iteration[018/030] Train loss: 0.0188
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[019/030] Train loss: 0.0187
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[020/030] Train loss: 0.0186
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[021/030] Train loss: 0.0187
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[022/030] Train loss: 0.0188
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[023/030] Train loss: 0.0188
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[024/030] Train loss: 0.0187
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[027/030] Train loss: 0.0190
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[028/030] Train loss: 0.0189
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[029/030] Train loss: 0.0189
2023-02-06 12:01:35 | Train | Epoch[293/600] Iteration[030/030] Train loss: 0.0190
2023-02-06 12:01:36 | Valid | Epoch[293/600] Iteration[001/008] Valid loss: 0.1280
2023-02-06 12:01:36 | Valid | Epoch[293/600] Iteration[002/008] Valid loss: 0.1006
2023-02-06 12:01:36 | Valid | Epoch[293/600] Iteration[003/008] Valid loss: 0.0919
2023-02-06 12:01:36 | Valid | Epoch[293/600] Iteration[004/008] Valid loss: 0.0867
2023-02-06 12:01:36 | Valid | Epoch[293/600] Iteration[005/008] Valid loss: 0.0845
2023-02-06 12:01:36 | Valid | Epoch[293/600] Iteration[006/008] Valid loss: 0.0824
2023-02-06 12:01:36 | Valid | Epoch[293/600] Iteration[007/008] Valid loss: 0.0872
2023-02-06 12:01:36 | Valid | Epoch[293/600] Iteration[008/008] Valid loss: 0.0850
2023-02-06 12:01:36 | Valid | Epoch[293/600] MIou: 0.9386449461807418
2023-02-06 12:01:36 | Valid | Epoch[293/600] Pixel Accuracy: 0.9893773396809896
2023-02-06 12:01:36 | Valid | Epoch[293/600] Mean Pixel Accuracy: 0.9675947572075523
2023-02-06 12:01:36 | Stage | Epoch[293/600] Train loss:0.0190
2023-02-06 12:01:36 | Stage | Epoch[293/600] Valid loss:0.0850
2023-02-06 12:01:36 | Stage | Epoch[293/600] LR:0.01

2023-02-06 12:01:36 | Train | Epoch[294/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 12:01:36 | Train | Epoch[294/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 12:01:36 | Train | Epoch[294/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 12:01:36 | Train | Epoch[294/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[010/030] Train loss: 0.0192
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[011/030] Train loss: 0.0193
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[013/030] Train loss: 0.0190
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[014/030] Train loss: 0.0189
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[015/030] Train loss: 0.0189
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[016/030] Train loss: 0.0187
2023-02-06 12:01:37 | Train | Epoch[294/600] Iteration[017/030] Train loss: 0.0187
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[018/030] Train loss: 0.0190
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[019/030] Train loss: 0.0190
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[020/030] Train loss: 0.0189
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[021/030] Train loss: 0.0189
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[022/030] Train loss: 0.0188
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[023/030] Train loss: 0.0188
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[024/030] Train loss: 0.0188
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[026/030] Train loss: 0.0188
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[027/030] Train loss: 0.0189
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[028/030] Train loss: 0.0189
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[029/030] Train loss: 0.0189
2023-02-06 12:01:38 | Train | Epoch[294/600] Iteration[030/030] Train loss: 0.0191
2023-02-06 12:01:39 | Valid | Epoch[294/600] Iteration[001/008] Valid loss: 0.0617
2023-02-06 12:01:39 | Valid | Epoch[294/600] Iteration[002/008] Valid loss: 0.0483
2023-02-06 12:01:39 | Valid | Epoch[294/600] Iteration[003/008] Valid loss: 0.0482
2023-02-06 12:01:39 | Valid | Epoch[294/600] Iteration[004/008] Valid loss: 0.0438
2023-02-06 12:01:39 | Valid | Epoch[294/600] Iteration[005/008] Valid loss: 0.0421
2023-02-06 12:01:39 | Valid | Epoch[294/600] Iteration[006/008] Valid loss: 0.0402
2023-02-06 12:01:39 | Valid | Epoch[294/600] Iteration[007/008] Valid loss: 0.0392
2023-02-06 12:01:39 | Valid | Epoch[294/600] Iteration[008/008] Valid loss: 0.0387
2023-02-06 12:01:39 | Valid | Epoch[294/600] MIou: 0.9006281263073015
2023-02-06 12:01:39 | Valid | Epoch[294/600] Pixel Accuracy: 0.9835484822591146
2023-02-06 12:01:39 | Valid | Epoch[294/600] Mean Pixel Accuracy: 0.9118665025676642
2023-02-06 12:01:39 | Stage | Epoch[294/600] Train loss:0.0191
2023-02-06 12:01:39 | Stage | Epoch[294/600] Valid loss:0.0387
2023-02-06 12:01:39 | Stage | Epoch[294/600] LR:0.01

2023-02-06 12:01:39 | Train | Epoch[295/600] Iteration[001/030] Train loss: 0.0169
2023-02-06 12:01:39 | Train | Epoch[295/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:01:39 | Train | Epoch[295/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 12:01:39 | Train | Epoch[295/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[005/030] Train loss: 0.0190
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[006/030] Train loss: 0.0191
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[007/030] Train loss: 0.0191
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[008/030] Train loss: 0.0190
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[009/030] Train loss: 0.0190
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[010/030] Train loss: 0.0188
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[011/030] Train loss: 0.0189
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[012/030] Train loss: 0.0187
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[013/030] Train loss: 0.0185
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[015/030] Train loss: 0.0184
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[017/030] Train loss: 0.0185
2023-02-06 12:01:40 | Train | Epoch[295/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[019/030] Train loss: 0.0185
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[020/030] Train loss: 0.0185
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[021/030] Train loss: 0.0186
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[022/030] Train loss: 0.0187
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[023/030] Train loss: 0.0187
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[024/030] Train loss: 0.0187
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[025/030] Train loss: 0.0186
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[026/030] Train loss: 0.0188
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[027/030] Train loss: 0.0188
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[029/030] Train loss: 0.0188
2023-02-06 12:01:41 | Train | Epoch[295/600] Iteration[030/030] Train loss: 0.0188
2023-02-06 12:01:42 | Valid | Epoch[295/600] Iteration[001/008] Valid loss: 0.1207
2023-02-06 12:01:42 | Valid | Epoch[295/600] Iteration[002/008] Valid loss: 0.0791
2023-02-06 12:01:42 | Valid | Epoch[295/600] Iteration[003/008] Valid loss: 0.0726
2023-02-06 12:01:42 | Valid | Epoch[295/600] Iteration[004/008] Valid loss: 0.0705
2023-02-06 12:01:42 | Valid | Epoch[295/600] Iteration[005/008] Valid loss: 0.0678
2023-02-06 12:01:42 | Valid | Epoch[295/600] Iteration[006/008] Valid loss: 0.0632
2023-02-06 12:01:42 | Valid | Epoch[295/600] Iteration[007/008] Valid loss: 0.0682
2023-02-06 12:01:42 | Valid | Epoch[295/600] Iteration[008/008] Valid loss: 0.0651
2023-02-06 12:01:42 | Valid | Epoch[295/600] MIou: 0.9388477154240464
2023-02-06 12:01:42 | Valid | Epoch[295/600] Pixel Accuracy: 0.9895579020182291
2023-02-06 12:01:42 | Valid | Epoch[295/600] Mean Pixel Accuracy: 0.9613028066847202
2023-02-06 12:01:42 | Stage | Epoch[295/600] Train loss:0.0188
2023-02-06 12:01:42 | Stage | Epoch[295/600] Valid loss:0.0651
2023-02-06 12:01:42 | Stage | Epoch[295/600] LR:0.01

2023-02-06 12:01:42 | Train | Epoch[296/600] Iteration[001/030] Train loss: 0.0205
2023-02-06 12:01:42 | Train | Epoch[296/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 12:01:42 | Train | Epoch[296/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 12:01:42 | Train | Epoch[296/600] Iteration[004/030] Train loss: 0.0198
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[006/030] Train loss: 0.0191
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[007/030] Train loss: 0.0188
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[009/030] Train loss: 0.0191
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[012/030] Train loss: 0.0194
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[014/030] Train loss: 0.0194
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[017/030] Train loss: 0.0194
2023-02-06 12:01:43 | Train | Epoch[296/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[021/030] Train loss: 0.0195
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[022/030] Train loss: 0.0195
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[023/030] Train loss: 0.0195
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[024/030] Train loss: 0.0195
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[025/030] Train loss: 0.0195
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[026/030] Train loss: 0.0194
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[027/030] Train loss: 0.0194
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[028/030] Train loss: 0.0193
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[029/030] Train loss: 0.0193
2023-02-06 12:01:44 | Train | Epoch[296/600] Iteration[030/030] Train loss: 0.0194
2023-02-06 12:01:45 | Valid | Epoch[296/600] Iteration[001/008] Valid loss: 0.0673
2023-02-06 12:01:45 | Valid | Epoch[296/600] Iteration[002/008] Valid loss: 0.0507
2023-02-06 12:01:45 | Valid | Epoch[296/600] Iteration[003/008] Valid loss: 0.0476
2023-02-06 12:01:45 | Valid | Epoch[296/600] Iteration[004/008] Valid loss: 0.0436
2023-02-06 12:01:45 | Valid | Epoch[296/600] Iteration[005/008] Valid loss: 0.0422
2023-02-06 12:01:45 | Valid | Epoch[296/600] Iteration[006/008] Valid loss: 0.0406
2023-02-06 12:01:45 | Valid | Epoch[296/600] Iteration[007/008] Valid loss: 0.0421
2023-02-06 12:01:45 | Valid | Epoch[296/600] Iteration[008/008] Valid loss: 0.0410
2023-02-06 12:01:45 | Valid | Epoch[296/600] MIou: 0.9201230357998804
2023-02-06 12:01:45 | Valid | Epoch[296/600] Pixel Accuracy: 0.9866129557291666
2023-02-06 12:01:45 | Valid | Epoch[296/600] Mean Pixel Accuracy: 0.9351908971541656
2023-02-06 12:01:45 | Stage | Epoch[296/600] Train loss:0.0194
2023-02-06 12:01:45 | Stage | Epoch[296/600] Valid loss:0.0410
2023-02-06 12:01:45 | Stage | Epoch[296/600] LR:0.01

2023-02-06 12:01:45 | Train | Epoch[297/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 12:01:45 | Train | Epoch[297/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 12:01:45 | Train | Epoch[297/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 12:01:45 | Train | Epoch[297/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[007/030] Train loss: 0.0188
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[009/030] Train loss: 0.0190
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[010/030] Train loss: 0.0188
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[011/030] Train loss: 0.0189
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[012/030] Train loss: 0.0189
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[013/030] Train loss: 0.0189
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[014/030] Train loss: 0.0191
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[015/030] Train loss: 0.0189
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[016/030] Train loss: 0.0188
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[017/030] Train loss: 0.0189
2023-02-06 12:01:46 | Train | Epoch[297/600] Iteration[018/030] Train loss: 0.0189
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[019/030] Train loss: 0.0190
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[020/030] Train loss: 0.0190
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[021/030] Train loss: 0.0189
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[022/030] Train loss: 0.0189
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[023/030] Train loss: 0.0189
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[024/030] Train loss: 0.0189
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[027/030] Train loss: 0.0190
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[028/030] Train loss: 0.0192
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[029/030] Train loss: 0.0192
2023-02-06 12:01:47 | Train | Epoch[297/600] Iteration[030/030] Train loss: 0.0191
2023-02-06 12:01:48 | Valid | Epoch[297/600] Iteration[001/008] Valid loss: 0.1859
2023-02-06 12:01:48 | Valid | Epoch[297/600] Iteration[002/008] Valid loss: 0.1440
2023-02-06 12:01:48 | Valid | Epoch[297/600] Iteration[003/008] Valid loss: 0.1421
2023-02-06 12:01:48 | Valid | Epoch[297/600] Iteration[004/008] Valid loss: 0.1387
2023-02-06 12:01:48 | Valid | Epoch[297/600] Iteration[005/008] Valid loss: 0.1399
2023-02-06 12:01:48 | Valid | Epoch[297/600] Iteration[006/008] Valid loss: 0.1363
2023-02-06 12:01:48 | Valid | Epoch[297/600] Iteration[007/008] Valid loss: 0.1433
2023-02-06 12:01:48 | Valid | Epoch[297/600] Iteration[008/008] Valid loss: 0.1359
2023-02-06 12:01:48 | Valid | Epoch[297/600] MIou: 0.9374952827307563
2023-02-06 12:01:48 | Valid | Epoch[297/600] Pixel Accuracy: 0.9889119466145834
2023-02-06 12:01:48 | Valid | Epoch[297/600] Mean Pixel Accuracy: 0.9781367803147931
2023-02-06 12:01:48 | Stage | Epoch[297/600] Train loss:0.0191
2023-02-06 12:01:48 | Stage | Epoch[297/600] Valid loss:0.1359
2023-02-06 12:01:48 | Stage | Epoch[297/600] LR:0.01

2023-02-06 12:01:48 | Train | Epoch[298/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 12:01:48 | Train | Epoch[298/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 12:01:48 | Train | Epoch[298/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 12:01:48 | Train | Epoch[298/600] Iteration[004/030] Train loss: 0.0195
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[014/030] Train loss: 0.0195
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[017/030] Train loss: 0.0193
2023-02-06 12:01:49 | Train | Epoch[298/600] Iteration[018/030] Train loss: 0.0191
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[019/030] Train loss: 0.0193
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[021/030] Train loss: 0.0195
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[022/030] Train loss: 0.0195
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[023/030] Train loss: 0.0194
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[024/030] Train loss: 0.0194
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[025/030] Train loss: 0.0195
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[026/030] Train loss: 0.0195
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[027/030] Train loss: 0.0194
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[028/030] Train loss: 0.0194
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[029/030] Train loss: 0.0194
2023-02-06 12:01:50 | Train | Epoch[298/600] Iteration[030/030] Train loss: 0.0193
2023-02-06 12:01:51 | Valid | Epoch[298/600] Iteration[001/008] Valid loss: 0.7636
2023-02-06 12:01:51 | Valid | Epoch[298/600] Iteration[002/008] Valid loss: 0.7124
2023-02-06 12:01:51 | Valid | Epoch[298/600] Iteration[003/008] Valid loss: 0.7226
2023-02-06 12:01:51 | Valid | Epoch[298/600] Iteration[004/008] Valid loss: 0.7451
2023-02-06 12:01:51 | Valid | Epoch[298/600] Iteration[005/008] Valid loss: 0.7752
2023-02-06 12:01:51 | Valid | Epoch[298/600] Iteration[006/008] Valid loss: 0.7544
2023-02-06 12:01:51 | Valid | Epoch[298/600] Iteration[007/008] Valid loss: 0.7962
2023-02-06 12:01:51 | Valid | Epoch[298/600] Iteration[008/008] Valid loss: 0.8168
2023-02-06 12:01:51 | Valid | Epoch[298/600] MIou: 0.8697750945501133
2023-02-06 12:01:51 | Valid | Epoch[298/600] Pixel Accuracy: 0.9731775919596354
2023-02-06 12:01:51 | Valid | Epoch[298/600] Mean Pixel Accuracy: 0.9801468405542442
2023-02-06 12:01:51 | Stage | Epoch[298/600] Train loss:0.0193
2023-02-06 12:01:51 | Stage | Epoch[298/600] Valid loss:0.8168
2023-02-06 12:01:51 | Stage | Epoch[298/600] LR:0.01

2023-02-06 12:01:51 | Train | Epoch[299/600] Iteration[001/030] Train loss: 0.0175
2023-02-06 12:01:51 | Train | Epoch[299/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:01:51 | Train | Epoch[299/600] Iteration[003/030] Train loss: 0.0179
2023-02-06 12:01:51 | Train | Epoch[299/600] Iteration[004/030] Train loss: 0.0186
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[005/030] Train loss: 0.0187
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[006/030] Train loss: 0.0191
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[010/030] Train loss: 0.0192
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[011/030] Train loss: 0.0192
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[013/030] Train loss: 0.0190
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[014/030] Train loss: 0.0188
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[015/030] Train loss: 0.0190
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[016/030] Train loss: 0.0191
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[017/030] Train loss: 0.0190
2023-02-06 12:01:52 | Train | Epoch[299/600] Iteration[018/030] Train loss: 0.0189
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[019/030] Train loss: 0.0188
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[020/030] Train loss: 0.0187
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[021/030] Train loss: 0.0189
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[022/030] Train loss: 0.0189
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[023/030] Train loss: 0.0189
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[024/030] Train loss: 0.0189
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[025/030] Train loss: 0.0190
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[026/030] Train loss: 0.0190
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[027/030] Train loss: 0.0193
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[028/030] Train loss: 0.0192
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[029/030] Train loss: 0.0193
2023-02-06 12:01:53 | Train | Epoch[299/600] Iteration[030/030] Train loss: 0.0192
2023-02-06 12:01:54 | Valid | Epoch[299/600] Iteration[001/008] Valid loss: 0.5265
2023-02-06 12:01:54 | Valid | Epoch[299/600] Iteration[002/008] Valid loss: 0.4525
2023-02-06 12:01:54 | Valid | Epoch[299/600] Iteration[003/008] Valid loss: 0.4482
2023-02-06 12:01:54 | Valid | Epoch[299/600] Iteration[004/008] Valid loss: 0.4571
2023-02-06 12:01:54 | Valid | Epoch[299/600] Iteration[005/008] Valid loss: 0.4700
2023-02-06 12:01:54 | Valid | Epoch[299/600] Iteration[006/008] Valid loss: 0.4523
2023-02-06 12:01:54 | Valid | Epoch[299/600] Iteration[007/008] Valid loss: 0.4813
2023-02-06 12:01:54 | Valid | Epoch[299/600] Iteration[008/008] Valid loss: 0.4813
2023-02-06 12:01:54 | Valid | Epoch[299/600] MIou: 0.9004066604547689
2023-02-06 12:01:54 | Valid | Epoch[299/600] Pixel Accuracy: 0.980719248453776
2023-02-06 12:01:54 | Valid | Epoch[299/600] Mean Pixel Accuracy: 0.9829542171182452
2023-02-06 12:01:54 | Stage | Epoch[299/600] Train loss:0.0192
2023-02-06 12:01:54 | Stage | Epoch[299/600] Valid loss:0.4813
2023-02-06 12:01:54 | Stage | Epoch[299/600] LR:0.01

2023-02-06 12:01:54 | Train | Epoch[300/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 12:01:54 | Train | Epoch[300/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 12:01:54 | Train | Epoch[300/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 12:01:54 | Train | Epoch[300/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[006/030] Train loss: 0.0184
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[007/030] Train loss: 0.0186
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[009/030] Train loss: 0.0181
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[010/030] Train loss: 0.0183
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[011/030] Train loss: 0.0182
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[012/030] Train loss: 0.0183
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[013/030] Train loss: 0.0185
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[014/030] Train loss: 0.0187
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[015/030] Train loss: 0.0187
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[016/030] Train loss: 0.0186
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[017/030] Train loss: 0.0186
2023-02-06 12:01:55 | Train | Epoch[300/600] Iteration[018/030] Train loss: 0.0187
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[019/030] Train loss: 0.0186
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[020/030] Train loss: 0.0187
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[021/030] Train loss: 0.0186
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[022/030] Train loss: 0.0188
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[023/030] Train loss: 0.0188
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[024/030] Train loss: 0.0187
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[025/030] Train loss: 0.0187
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[026/030] Train loss: 0.0187
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[027/030] Train loss: 0.0187
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[029/030] Train loss: 0.0188
2023-02-06 12:01:56 | Train | Epoch[300/600] Iteration[030/030] Train loss: 0.0187
2023-02-06 12:01:57 | Valid | Epoch[300/600] Iteration[001/008] Valid loss: 0.0666
2023-02-06 12:01:57 | Valid | Epoch[300/600] Iteration[002/008] Valid loss: 0.0647
2023-02-06 12:01:57 | Valid | Epoch[300/600] Iteration[003/008] Valid loss: 0.0613
2023-02-06 12:01:57 | Valid | Epoch[300/600] Iteration[004/008] Valid loss: 0.0601
2023-02-06 12:01:57 | Valid | Epoch[300/600] Iteration[005/008] Valid loss: 0.0584
2023-02-06 12:01:57 | Valid | Epoch[300/600] Iteration[006/008] Valid loss: 0.0563
2023-02-06 12:01:57 | Valid | Epoch[300/600] Iteration[007/008] Valid loss: 0.0579
2023-02-06 12:01:57 | Valid | Epoch[300/600] Iteration[008/008] Valid loss: 0.0557
2023-02-06 12:01:57 | Valid | Epoch[300/600] MIou: 0.9010777504766426
2023-02-06 12:01:57 | Valid | Epoch[300/600] Pixel Accuracy: 0.9833628336588541
2023-02-06 12:01:57 | Valid | Epoch[300/600] Mean Pixel Accuracy: 0.9188277474436968
2023-02-06 12:01:57 | Stage | Epoch[300/600] Train loss:0.0187
2023-02-06 12:01:57 | Stage | Epoch[300/600] Valid loss:0.0557
2023-02-06 12:01:57 | Stage | Epoch[300/600] LR:0.01

2023-02-06 12:01:57 | Train | Epoch[301/600] Iteration[001/030] Train loss: 0.0175
2023-02-06 12:01:57 | Train | Epoch[301/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:01:57 | Train | Epoch[301/600] Iteration[003/030] Train loss: 0.0179
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[006/030] Train loss: 0.0178
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[007/030] Train loss: 0.0183
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[008/030] Train loss: 0.0184
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[009/030] Train loss: 0.0185
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[010/030] Train loss: 0.0183
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[011/030] Train loss: 0.0181
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[012/030] Train loss: 0.0181
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[013/030] Train loss: 0.0181
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[014/030] Train loss: 0.0182
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[015/030] Train loss: 0.0183
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 12:01:58 | Train | Epoch[301/600] Iteration[017/030] Train loss: 0.0182
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[022/030] Train loss: 0.0183
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[023/030] Train loss: 0.0185
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[024/030] Train loss: 0.0185
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[025/030] Train loss: 0.0185
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[026/030] Train loss: 0.0186
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[027/030] Train loss: 0.0187
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[028/030] Train loss: 0.0186
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[029/030] Train loss: 0.0187
2023-02-06 12:01:59 | Train | Epoch[301/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:02:00 | Valid | Epoch[301/600] Iteration[001/008] Valid loss: 0.4057
2023-02-06 12:02:00 | Valid | Epoch[301/600] Iteration[002/008] Valid loss: 0.3547
2023-02-06 12:02:00 | Valid | Epoch[301/600] Iteration[003/008] Valid loss: 0.3460
2023-02-06 12:02:00 | Valid | Epoch[301/600] Iteration[004/008] Valid loss: 0.3506
2023-02-06 12:02:00 | Valid | Epoch[301/600] Iteration[005/008] Valid loss: 0.3620
2023-02-06 12:02:00 | Valid | Epoch[301/600] Iteration[006/008] Valid loss: 0.3522
2023-02-06 12:02:00 | Valid | Epoch[301/600] Iteration[007/008] Valid loss: 0.3781
2023-02-06 12:02:00 | Valid | Epoch[301/600] Iteration[008/008] Valid loss: 0.3726
2023-02-06 12:02:00 | Valid | Epoch[301/600] MIou: 0.9117813009068942
2023-02-06 12:02:00 | Valid | Epoch[301/600] Pixel Accuracy: 0.9832865397135416
2023-02-06 12:02:00 | Valid | Epoch[301/600] Mean Pixel Accuracy: 0.9842765432857672
2023-02-06 12:02:00 | Stage | Epoch[301/600] Train loss:0.0186
2023-02-06 12:02:00 | Stage | Epoch[301/600] Valid loss:0.3726
2023-02-06 12:02:00 | Stage | Epoch[301/600] LR:0.01

2023-02-06 12:02:00 | Train | Epoch[302/600] Iteration[001/030] Train loss: 0.0159
2023-02-06 12:02:00 | Train | Epoch[302/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:02:00 | Train | Epoch[302/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[004/030] Train loss: 0.0172
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[006/030] Train loss: 0.0179
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[007/030] Train loss: 0.0177
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[008/030] Train loss: 0.0184
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[009/030] Train loss: 0.0180
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[010/030] Train loss: 0.0182
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[011/030] Train loss: 0.0183
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[012/030] Train loss: 0.0185
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[013/030] Train loss: 0.0185
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[014/030] Train loss: 0.0184
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[015/030] Train loss: 0.0186
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[016/030] Train loss: 0.0186
2023-02-06 12:02:01 | Train | Epoch[302/600] Iteration[017/030] Train loss: 0.0190
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[018/030] Train loss: 0.0190
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[019/030] Train loss: 0.0190
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[020/030] Train loss: 0.0190
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[021/030] Train loss: 0.0191
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[022/030] Train loss: 0.0191
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[023/030] Train loss: 0.0192
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[024/030] Train loss: 0.0192
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[025/030] Train loss: 0.0191
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[026/030] Train loss: 0.0191
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[027/030] Train loss: 0.0191
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[028/030] Train loss: 0.0191
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[029/030] Train loss: 0.0191
2023-02-06 12:02:02 | Train | Epoch[302/600] Iteration[030/030] Train loss: 0.0191
2023-02-06 12:02:03 | Valid | Epoch[302/600] Iteration[001/008] Valid loss: 0.1846
2023-02-06 12:02:03 | Valid | Epoch[302/600] Iteration[002/008] Valid loss: 0.1322
2023-02-06 12:02:03 | Valid | Epoch[302/600] Iteration[003/008] Valid loss: 0.1261
2023-02-06 12:02:03 | Valid | Epoch[302/600] Iteration[004/008] Valid loss: 0.1226
2023-02-06 12:02:03 | Valid | Epoch[302/600] Iteration[005/008] Valid loss: 0.1216
2023-02-06 12:02:03 | Valid | Epoch[302/600] Iteration[006/008] Valid loss: 0.1182
2023-02-06 12:02:03 | Valid | Epoch[302/600] Iteration[007/008] Valid loss: 0.1289
2023-02-06 12:02:03 | Valid | Epoch[302/600] Iteration[008/008] Valid loss: 0.1238
2023-02-06 12:02:03 | Valid | Epoch[302/600] MIou: 0.9336187225179887
2023-02-06 12:02:03 | Valid | Epoch[302/600] Pixel Accuracy: 0.9881477355957031
2023-02-06 12:02:03 | Valid | Epoch[302/600] Mean Pixel Accuracy: 0.9774314161279614
2023-02-06 12:02:03 | Stage | Epoch[302/600] Train loss:0.0191
2023-02-06 12:02:03 | Stage | Epoch[302/600] Valid loss:0.1238
2023-02-06 12:02:03 | Stage | Epoch[302/600] LR:0.01

2023-02-06 12:02:03 | Train | Epoch[303/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 12:02:03 | Train | Epoch[303/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 12:02:03 | Train | Epoch[303/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 12:02:04 | Train | Epoch[303/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[018/030] Train loss: 0.0194
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[019/030] Train loss: 0.0193
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[021/030] Train loss: 0.0194
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[022/030] Train loss: 0.0194
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[023/030] Train loss: 0.0193
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[024/030] Train loss: 0.0194
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[025/030] Train loss: 0.0194
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[026/030] Train loss: 0.0193
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[027/030] Train loss: 0.0194
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[028/030] Train loss: 0.0193
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[029/030] Train loss: 0.0193
2023-02-06 12:02:05 | Train | Epoch[303/600] Iteration[030/030] Train loss: 0.0194
2023-02-06 12:02:06 | Valid | Epoch[303/600] Iteration[001/008] Valid loss: 0.0485
2023-02-06 12:02:06 | Valid | Epoch[303/600] Iteration[002/008] Valid loss: 0.0435
2023-02-06 12:02:06 | Valid | Epoch[303/600] Iteration[003/008] Valid loss: 0.0442
2023-02-06 12:02:06 | Valid | Epoch[303/600] Iteration[004/008] Valid loss: 0.0414
2023-02-06 12:02:06 | Valid | Epoch[303/600] Iteration[005/008] Valid loss: 0.0411
2023-02-06 12:02:06 | Valid | Epoch[303/600] Iteration[006/008] Valid loss: 0.0402
2023-02-06 12:02:06 | Valid | Epoch[303/600] Iteration[007/008] Valid loss: 0.0399
2023-02-06 12:02:06 | Valid | Epoch[303/600] Iteration[008/008] Valid loss: 0.0401
2023-02-06 12:02:06 | Valid | Epoch[303/600] MIou: 0.8783374282957075
2023-02-06 12:02:06 | Valid | Epoch[303/600] Pixel Accuracy: 0.9798774719238281
2023-02-06 12:02:06 | Valid | Epoch[303/600] Mean Pixel Accuracy: 0.8908844084299561
2023-02-06 12:02:06 | Stage | Epoch[303/600] Train loss:0.0194
2023-02-06 12:02:06 | Stage | Epoch[303/600] Valid loss:0.0401
2023-02-06 12:02:06 | Stage | Epoch[303/600] LR:0.01

2023-02-06 12:02:06 | Train | Epoch[304/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 12:02:06 | Train | Epoch[304/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[003/030] Train loss: 0.0193
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[005/030] Train loss: 0.0181
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[006/030] Train loss: 0.0186
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[007/030] Train loss: 0.0185
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[008/030] Train loss: 0.0185
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[009/030] Train loss: 0.0186
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[010/030] Train loss: 0.0187
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[011/030] Train loss: 0.0184
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[012/030] Train loss: 0.0183
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[013/030] Train loss: 0.0185
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[015/030] Train loss: 0.0186
2023-02-06 12:02:07 | Train | Epoch[304/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[019/030] Train loss: 0.0186
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[020/030] Train loss: 0.0187
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[021/030] Train loss: 0.0188
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[022/030] Train loss: 0.0189
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[023/030] Train loss: 0.0188
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[024/030] Train loss: 0.0189
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[027/030] Train loss: 0.0189
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[029/030] Train loss: 0.0189
2023-02-06 12:02:08 | Train | Epoch[304/600] Iteration[030/030] Train loss: 0.0189
2023-02-06 12:02:09 | Valid | Epoch[304/600] Iteration[001/008] Valid loss: 0.0910
2023-02-06 12:02:09 | Valid | Epoch[304/600] Iteration[002/008] Valid loss: 0.0669
2023-02-06 12:02:09 | Valid | Epoch[304/600] Iteration[003/008] Valid loss: 0.0648
2023-02-06 12:02:09 | Valid | Epoch[304/600] Iteration[004/008] Valid loss: 0.0623
2023-02-06 12:02:09 | Valid | Epoch[304/600] Iteration[005/008] Valid loss: 0.0599
2023-02-06 12:02:09 | Valid | Epoch[304/600] Iteration[006/008] Valid loss: 0.0563
2023-02-06 12:02:09 | Valid | Epoch[304/600] Iteration[007/008] Valid loss: 0.0608
2023-02-06 12:02:09 | Valid | Epoch[304/600] Iteration[008/008] Valid loss: 0.0590
2023-02-06 12:02:09 | Valid | Epoch[304/600] MIou: 0.9273861001534504
2023-02-06 12:02:09 | Valid | Epoch[304/600] Pixel Accuracy: 0.9876708984375
2023-02-06 12:02:09 | Valid | Epoch[304/600] Mean Pixel Accuracy: 0.9478002620452464
2023-02-06 12:02:09 | Stage | Epoch[304/600] Train loss:0.0189
2023-02-06 12:02:09 | Stage | Epoch[304/600] Valid loss:0.0590
2023-02-06 12:02:09 | Stage | Epoch[304/600] LR:0.01

2023-02-06 12:02:09 | Train | Epoch[305/600] Iteration[001/030] Train loss: 0.0172
2023-02-06 12:02:09 | Train | Epoch[305/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[004/030] Train loss: 0.0191
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[005/030] Train loss: 0.0193
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[009/030] Train loss: 0.0191
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[010/030] Train loss: 0.0193
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[011/030] Train loss: 0.0190
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[013/030] Train loss: 0.0193
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[014/030] Train loss: 0.0191
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[015/030] Train loss: 0.0190
2023-02-06 12:02:10 | Train | Epoch[305/600] Iteration[016/030] Train loss: 0.0191
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[017/030] Train loss: 0.0192
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[018/030] Train loss: 0.0192
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[019/030] Train loss: 0.0191
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[020/030] Train loss: 0.0191
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[021/030] Train loss: 0.0191
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[022/030] Train loss: 0.0192
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[023/030] Train loss: 0.0193
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[024/030] Train loss: 0.0193
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[025/030] Train loss: 0.0193
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[026/030] Train loss: 0.0193
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[027/030] Train loss: 0.0192
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[028/030] Train loss: 0.0192
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[029/030] Train loss: 0.0192
2023-02-06 12:02:11 | Train | Epoch[305/600] Iteration[030/030] Train loss: 0.0191
2023-02-06 12:02:12 | Valid | Epoch[305/600] Iteration[001/008] Valid loss: 0.0564
2023-02-06 12:02:12 | Valid | Epoch[305/600] Iteration[002/008] Valid loss: 0.0520
2023-02-06 12:02:12 | Valid | Epoch[305/600] Iteration[003/008] Valid loss: 0.0536
2023-02-06 12:02:12 | Valid | Epoch[305/600] Iteration[004/008] Valid loss: 0.0508
2023-02-06 12:02:12 | Valid | Epoch[305/600] Iteration[005/008] Valid loss: 0.0508
2023-02-06 12:02:12 | Valid | Epoch[305/600] Iteration[006/008] Valid loss: 0.0496
2023-02-06 12:02:12 | Valid | Epoch[305/600] Iteration[007/008] Valid loss: 0.0480
2023-02-06 12:02:12 | Valid | Epoch[305/600] Iteration[008/008] Valid loss: 0.0492
2023-02-06 12:02:12 | Valid | Epoch[305/600] MIou: 0.841703805525403
2023-02-06 12:02:12 | Valid | Epoch[305/600] Pixel Accuracy: 0.9738896687825521
2023-02-06 12:02:12 | Valid | Epoch[305/600] Mean Pixel Accuracy: 0.8560874535063587
2023-02-06 12:02:12 | Stage | Epoch[305/600] Train loss:0.0191
2023-02-06 12:02:12 | Stage | Epoch[305/600] Valid loss:0.0492
2023-02-06 12:02:12 | Stage | Epoch[305/600] LR:0.01

2023-02-06 12:02:12 | Train | Epoch[306/600] Iteration[001/030] Train loss: 0.0181
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[011/030] Train loss: 0.0193
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[012/030] Train loss: 0.0190
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[013/030] Train loss: 0.0190
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[014/030] Train loss: 0.0189
2023-02-06 12:02:13 | Train | Epoch[306/600] Iteration[015/030] Train loss: 0.0190
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[016/030] Train loss: 0.0191
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[017/030] Train loss: 0.0190
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[018/030] Train loss: 0.0190
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[019/030] Train loss: 0.0189
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[020/030] Train loss: 0.0189
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[021/030] Train loss: 0.0188
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[022/030] Train loss: 0.0187
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[023/030] Train loss: 0.0188
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[024/030] Train loss: 0.0187
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[026/030] Train loss: 0.0187
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[027/030] Train loss: 0.0188
2023-02-06 12:02:14 | Train | Epoch[306/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 12:02:15 | Train | Epoch[306/600] Iteration[029/030] Train loss: 0.0187
2023-02-06 12:02:15 | Train | Epoch[306/600] Iteration[030/030] Train loss: 0.0188
2023-02-06 12:02:15 | Valid | Epoch[306/600] Iteration[001/008] Valid loss: 0.4696
2023-02-06 12:02:15 | Valid | Epoch[306/600] Iteration[002/008] Valid loss: 0.4060
2023-02-06 12:02:15 | Valid | Epoch[306/600] Iteration[003/008] Valid loss: 0.4217
2023-02-06 12:02:15 | Valid | Epoch[306/600] Iteration[004/008] Valid loss: 0.4128
2023-02-06 12:02:15 | Valid | Epoch[306/600] Iteration[005/008] Valid loss: 0.4317
2023-02-06 12:02:15 | Valid | Epoch[306/600] Iteration[006/008] Valid loss: 0.4124
2023-02-06 12:02:15 | Valid | Epoch[306/600] Iteration[007/008] Valid loss: 0.4369
2023-02-06 12:02:15 | Valid | Epoch[306/600] Iteration[008/008] Valid loss: 0.4426
2023-02-06 12:02:15 | Valid | Epoch[306/600] MIou: 0.9024569748387482
2023-02-06 12:02:15 | Valid | Epoch[306/600] Pixel Accuracy: 0.9812367757161459
2023-02-06 12:02:15 | Valid | Epoch[306/600] Mean Pixel Accuracy: 0.9819452159851831
2023-02-06 12:02:15 | Stage | Epoch[306/600] Train loss:0.0188
2023-02-06 12:02:15 | Stage | Epoch[306/600] Valid loss:0.4426
2023-02-06 12:02:15 | Stage | Epoch[306/600] LR:0.01

2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[009/030] Train loss: 0.0190
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[010/030] Train loss: 0.0188
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[011/030] Train loss: 0.0187
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[012/030] Train loss: 0.0187
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[013/030] Train loss: 0.0186
2023-02-06 12:02:16 | Train | Epoch[307/600] Iteration[014/030] Train loss: 0.0188
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[015/030] Train loss: 0.0188
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[016/030] Train loss: 0.0188
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[017/030] Train loss: 0.0188
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[018/030] Train loss: 0.0188
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[019/030] Train loss: 0.0189
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[020/030] Train loss: 0.0190
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[021/030] Train loss: 0.0189
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[022/030] Train loss: 0.0189
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[023/030] Train loss: 0.0189
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[024/030] Train loss: 0.0188
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[027/030] Train loss: 0.0189
2023-02-06 12:02:17 | Train | Epoch[307/600] Iteration[028/030] Train loss: 0.0189
2023-02-06 12:02:18 | Train | Epoch[307/600] Iteration[029/030] Train loss: 0.0189
2023-02-06 12:02:18 | Train | Epoch[307/600] Iteration[030/030] Train loss: 0.0189
2023-02-06 12:02:18 | Valid | Epoch[307/600] Iteration[001/008] Valid loss: 0.1201
2023-02-06 12:02:18 | Valid | Epoch[307/600] Iteration[002/008] Valid loss: 0.0860
2023-02-06 12:02:18 | Valid | Epoch[307/600] Iteration[003/008] Valid loss: 0.0838
2023-02-06 12:02:18 | Valid | Epoch[307/600] Iteration[004/008] Valid loss: 0.0749
2023-02-06 12:02:18 | Valid | Epoch[307/600] Iteration[005/008] Valid loss: 0.0716
2023-02-06 12:02:18 | Valid | Epoch[307/600] Iteration[006/008] Valid loss: 0.0669
2023-02-06 12:02:18 | Valid | Epoch[307/600] Iteration[007/008] Valid loss: 0.0679
2023-02-06 12:02:18 | Valid | Epoch[307/600] Iteration[008/008] Valid loss: 0.0640
2023-02-06 12:02:18 | Valid | Epoch[307/600] MIou: 0.93433102649319
2023-02-06 12:02:18 | Valid | Epoch[307/600] Pixel Accuracy: 0.9889399210611979
2023-02-06 12:02:18 | Valid | Epoch[307/600] Mean Pixel Accuracy: 0.9507105955594524
2023-02-06 12:02:18 | Stage | Epoch[307/600] Train loss:0.0189
2023-02-06 12:02:18 | Stage | Epoch[307/600] Valid loss:0.0640
2023-02-06 12:02:18 | Stage | Epoch[307/600] LR:0.01

2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[001/030] Train loss: 0.0203
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[007/030] Train loss: 0.0192
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[008/030] Train loss: 0.0189
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[009/030] Train loss: 0.0188
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[010/030] Train loss: 0.0188
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[011/030] Train loss: 0.0188
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[012/030] Train loss: 0.0188
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[013/030] Train loss: 0.0189
2023-02-06 12:02:19 | Train | Epoch[308/600] Iteration[014/030] Train loss: 0.0192
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[015/030] Train loss: 0.0191
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[016/030] Train loss: 0.0193
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[017/030] Train loss: 0.0193
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[018/030] Train loss: 0.0191
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[019/030] Train loss: 0.0192
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[020/030] Train loss: 0.0191
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[021/030] Train loss: 0.0190
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[022/030] Train loss: 0.0188
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[023/030] Train loss: 0.0188
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[024/030] Train loss: 0.0187
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[026/030] Train loss: 0.0188
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[027/030] Train loss: 0.0188
2023-02-06 12:02:20 | Train | Epoch[308/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 12:02:21 | Train | Epoch[308/600] Iteration[029/030] Train loss: 0.0190
2023-02-06 12:02:21 | Train | Epoch[308/600] Iteration[030/030] Train loss: 0.0189
2023-02-06 12:02:21 | Valid | Epoch[308/600] Iteration[001/008] Valid loss: 0.1449
2023-02-06 12:02:21 | Valid | Epoch[308/600] Iteration[002/008] Valid loss: 0.1491
2023-02-06 12:02:21 | Valid | Epoch[308/600] Iteration[003/008] Valid loss: 0.1610
2023-02-06 12:02:21 | Valid | Epoch[308/600] Iteration[004/008] Valid loss: 0.1555
2023-02-06 12:02:21 | Valid | Epoch[308/600] Iteration[005/008] Valid loss: 0.1591
2023-02-06 12:02:21 | Valid | Epoch[308/600] Iteration[006/008] Valid loss: 0.1560
2023-02-06 12:02:21 | Valid | Epoch[308/600] Iteration[007/008] Valid loss: 0.1525
2023-02-06 12:02:21 | Valid | Epoch[308/600] Iteration[008/008] Valid loss: 0.1596
2023-02-06 12:02:21 | Valid | Epoch[308/600] MIou: 0.5586035538690571
2023-02-06 12:02:21 | Valid | Epoch[308/600] Pixel Accuracy: 0.9269790649414062
2023-02-06 12:02:21 | Valid | Epoch[308/600] Mean Pixel Accuracy: 0.595756662771544
2023-02-06 12:02:21 | Stage | Epoch[308/600] Train loss:0.0189
2023-02-06 12:02:21 | Stage | Epoch[308/600] Valid loss:0.1596
2023-02-06 12:02:21 | Stage | Epoch[308/600] LR:0.01

2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[001/030] Train loss: 0.0161
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[002/030] Train loss: 0.0168
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[005/030] Train loss: 0.0180
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[006/030] Train loss: 0.0178
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[008/030] Train loss: 0.0182
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[009/030] Train loss: 0.0184
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[010/030] Train loss: 0.0182
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[011/030] Train loss: 0.0183
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[012/030] Train loss: 0.0186
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[013/030] Train loss: 0.0188
2023-02-06 12:02:22 | Train | Epoch[309/600] Iteration[014/030] Train loss: 0.0188
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[015/030] Train loss: 0.0189
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[016/030] Train loss: 0.0189
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[017/030] Train loss: 0.0189
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[018/030] Train loss: 0.0189
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[019/030] Train loss: 0.0188
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[020/030] Train loss: 0.0188
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[021/030] Train loss: 0.0188
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[022/030] Train loss: 0.0187
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[023/030] Train loss: 0.0187
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[024/030] Train loss: 0.0187
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[026/030] Train loss: 0.0188
2023-02-06 12:02:23 | Train | Epoch[309/600] Iteration[027/030] Train loss: 0.0189
2023-02-06 12:02:24 | Train | Epoch[309/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 12:02:24 | Train | Epoch[309/600] Iteration[029/030] Train loss: 0.0189
2023-02-06 12:02:24 | Train | Epoch[309/600] Iteration[030/030] Train loss: 0.0188
2023-02-06 12:02:24 | Valid | Epoch[309/600] Iteration[001/008] Valid loss: 0.1461
2023-02-06 12:02:24 | Valid | Epoch[309/600] Iteration[002/008] Valid loss: 0.1032
2023-02-06 12:02:24 | Valid | Epoch[309/600] Iteration[003/008] Valid loss: 0.1001
2023-02-06 12:02:24 | Valid | Epoch[309/600] Iteration[004/008] Valid loss: 0.0893
2023-02-06 12:02:24 | Valid | Epoch[309/600] Iteration[005/008] Valid loss: 0.0849
2023-02-06 12:02:24 | Valid | Epoch[309/600] Iteration[006/008] Valid loss: 0.0784
2023-02-06 12:02:24 | Valid | Epoch[309/600] Iteration[007/008] Valid loss: 0.0800
2023-02-06 12:02:24 | Valid | Epoch[309/600] Iteration[008/008] Valid loss: 0.0758
2023-02-06 12:02:24 | Valid | Epoch[309/600] MIou: 0.9385715437724744
2023-02-06 12:02:24 | Valid | Epoch[309/600] Pixel Accuracy: 0.9896011352539062
2023-02-06 12:02:24 | Valid | Epoch[309/600] Mean Pixel Accuracy: 0.9570404107727353
2023-02-06 12:02:24 | Stage | Epoch[309/600] Train loss:0.0188
2023-02-06 12:02:24 | Stage | Epoch[309/600] Valid loss:0.0758
2023-02-06 12:02:24 | Stage | Epoch[309/600] LR:0.01

2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[004/030] Train loss: 0.0195
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[007/030] Train loss: 0.0191
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[009/030] Train loss: 0.0191
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[010/030] Train loss: 0.0189
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[011/030] Train loss: 0.0189
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[012/030] Train loss: 0.0189
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[013/030] Train loss: 0.0190
2023-02-06 12:02:25 | Train | Epoch[310/600] Iteration[014/030] Train loss: 0.0188
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[015/030] Train loss: 0.0187
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[016/030] Train loss: 0.0190
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[017/030] Train loss: 0.0189
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[018/030] Train loss: 0.0191
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[019/030] Train loss: 0.0192
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[020/030] Train loss: 0.0191
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[021/030] Train loss: 0.0190
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[022/030] Train loss: 0.0190
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[023/030] Train loss: 0.0189
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[024/030] Train loss: 0.0188
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[027/030] Train loss: 0.0189
2023-02-06 12:02:26 | Train | Epoch[310/600] Iteration[028/030] Train loss: 0.0190
2023-02-06 12:02:27 | Train | Epoch[310/600] Iteration[029/030] Train loss: 0.0191
2023-02-06 12:02:27 | Train | Epoch[310/600] Iteration[030/030] Train loss: 0.0191
2023-02-06 12:02:27 | Valid | Epoch[310/600] Iteration[001/008] Valid loss: 0.9280
2023-02-06 12:02:27 | Valid | Epoch[310/600] Iteration[002/008] Valid loss: 0.8999
2023-02-06 12:02:27 | Valid | Epoch[310/600] Iteration[003/008] Valid loss: 0.9071
2023-02-06 12:02:27 | Valid | Epoch[310/600] Iteration[004/008] Valid loss: 0.9360
2023-02-06 12:02:27 | Valid | Epoch[310/600] Iteration[005/008] Valid loss: 0.9723
2023-02-06 12:02:27 | Valid | Epoch[310/600] Iteration[006/008] Valid loss: 0.9552
2023-02-06 12:02:27 | Valid | Epoch[310/600] Iteration[007/008] Valid loss: 1.0051
2023-02-06 12:02:27 | Valid | Epoch[310/600] Iteration[008/008] Valid loss: 1.0118
2023-02-06 12:02:27 | Valid | Epoch[310/600] MIou: 0.8587226407064591
2023-02-06 12:02:27 | Valid | Epoch[310/600] Pixel Accuracy: 0.9700546264648438
2023-02-06 12:02:27 | Valid | Epoch[310/600] Mean Pixel Accuracy: 0.9819809895738144
2023-02-06 12:02:27 | Stage | Epoch[310/600] Train loss:0.0191
2023-02-06 12:02:27 | Stage | Epoch[310/600] Valid loss:1.0118
2023-02-06 12:02:27 | Stage | Epoch[310/600] LR:0.01

2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[002/030] Train loss: 0.0184
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[003/030] Train loss: 0.0188
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[004/030] Train loss: 0.0182
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[005/030] Train loss: 0.0180
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[008/030] Train loss: 0.0187
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[009/030] Train loss: 0.0184
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[010/030] Train loss: 0.0184
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[011/030] Train loss: 0.0186
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[012/030] Train loss: 0.0186
2023-02-06 12:02:28 | Train | Epoch[311/600] Iteration[013/030] Train loss: 0.0186
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[014/030] Train loss: 0.0186
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[015/030] Train loss: 0.0186
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[016/030] Train loss: 0.0188
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[017/030] Train loss: 0.0187
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[018/030] Train loss: 0.0188
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[019/030] Train loss: 0.0188
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[020/030] Train loss: 0.0188
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[021/030] Train loss: 0.0187
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[022/030] Train loss: 0.0187
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[023/030] Train loss: 0.0187
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[024/030] Train loss: 0.0186
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[025/030] Train loss: 0.0187
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[026/030] Train loss: 0.0186
2023-02-06 12:02:29 | Train | Epoch[311/600] Iteration[027/030] Train loss: 0.0187
2023-02-06 12:02:30 | Train | Epoch[311/600] Iteration[028/030] Train loss: 0.0186
2023-02-06 12:02:30 | Train | Epoch[311/600] Iteration[029/030] Train loss: 0.0186
2023-02-06 12:02:30 | Train | Epoch[311/600] Iteration[030/030] Train loss: 0.0185
2023-02-06 12:02:30 | Valid | Epoch[311/600] Iteration[001/008] Valid loss: 0.0692
2023-02-06 12:02:30 | Valid | Epoch[311/600] Iteration[002/008] Valid loss: 0.0493
2023-02-06 12:02:30 | Valid | Epoch[311/600] Iteration[003/008] Valid loss: 0.0489
2023-02-06 12:02:30 | Valid | Epoch[311/600] Iteration[004/008] Valid loss: 0.0446
2023-02-06 12:02:30 | Valid | Epoch[311/600] Iteration[005/008] Valid loss: 0.0427
2023-02-06 12:02:30 | Valid | Epoch[311/600] Iteration[006/008] Valid loss: 0.0405
2023-02-06 12:02:30 | Valid | Epoch[311/600] Iteration[007/008] Valid loss: 0.0420
2023-02-06 12:02:30 | Valid | Epoch[311/600] Iteration[008/008] Valid loss: 0.0408
2023-02-06 12:02:30 | Valid | Epoch[311/600] MIou: 0.9224658186956809
2023-02-06 12:02:30 | Valid | Epoch[311/600] Pixel Accuracy: 0.9870313008626302
2023-02-06 12:02:30 | Valid | Epoch[311/600] Mean Pixel Accuracy: 0.9365177390530954
2023-02-06 12:02:30 | Stage | Epoch[311/600] Train loss:0.0185
2023-02-06 12:02:30 | Stage | Epoch[311/600] Valid loss:0.0408
2023-02-06 12:02:30 | Stage | Epoch[311/600] LR:0.01

2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[001/030] Train loss: 0.0149
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[003/030] Train loss: 0.0183
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[005/030] Train loss: 0.0178
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[008/030] Train loss: 0.0180
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[009/030] Train loss: 0.0179
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[010/030] Train loss: 0.0179
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[011/030] Train loss: 0.0181
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[012/030] Train loss: 0.0179
2023-02-06 12:02:31 | Train | Epoch[312/600] Iteration[013/030] Train loss: 0.0182
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[014/030] Train loss: 0.0181
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[017/030] Train loss: 0.0185
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[019/030] Train loss: 0.0185
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[020/030] Train loss: 0.0185
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[021/030] Train loss: 0.0186
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[022/030] Train loss: 0.0184
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[023/030] Train loss: 0.0185
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[024/030] Train loss: 0.0184
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[025/030] Train loss: 0.0186
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[026/030] Train loss: 0.0186
2023-02-06 12:02:32 | Train | Epoch[312/600] Iteration[027/030] Train loss: 0.0186
2023-02-06 12:02:33 | Train | Epoch[312/600] Iteration[028/030] Train loss: 0.0185
2023-02-06 12:02:33 | Train | Epoch[312/600] Iteration[029/030] Train loss: 0.0185
2023-02-06 12:02:33 | Train | Epoch[312/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:02:33 | Valid | Epoch[312/600] Iteration[001/008] Valid loss: 0.0727
2023-02-06 12:02:33 | Valid | Epoch[312/600] Iteration[002/008] Valid loss: 0.0544
2023-02-06 12:02:33 | Valid | Epoch[312/600] Iteration[003/008] Valid loss: 0.0523
2023-02-06 12:02:33 | Valid | Epoch[312/600] Iteration[004/008] Valid loss: 0.0472
2023-02-06 12:02:33 | Valid | Epoch[312/600] Iteration[005/008] Valid loss: 0.0450
2023-02-06 12:02:33 | Valid | Epoch[312/600] Iteration[006/008] Valid loss: 0.0428
2023-02-06 12:02:33 | Valid | Epoch[312/600] Iteration[007/008] Valid loss: 0.0432
2023-02-06 12:02:33 | Valid | Epoch[312/600] Iteration[008/008] Valid loss: 0.0418
2023-02-06 12:02:33 | Valid | Epoch[312/600] MIou: 0.9172607798561725
2023-02-06 12:02:33 | Valid | Epoch[312/600] Pixel Accuracy: 0.986175537109375
2023-02-06 12:02:33 | Valid | Epoch[312/600] Mean Pixel Accuracy: 0.9311905736186119
2023-02-06 12:02:33 | Stage | Epoch[312/600] Train loss:0.0186
2023-02-06 12:02:33 | Stage | Epoch[312/600] Valid loss:0.0418
2023-02-06 12:02:33 | Stage | Epoch[312/600] LR:0.01

2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[001/030] Train loss: 0.0166
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[002/030] Train loss: 0.0174
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[003/030] Train loss: 0.0193
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[004/030] Train loss: 0.0188
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[006/030] Train loss: 0.0179
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[007/030] Train loss: 0.0180
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[008/030] Train loss: 0.0177
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[009/030] Train loss: 0.0181
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[011/030] Train loss: 0.0180
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[012/030] Train loss: 0.0182
2023-02-06 12:02:34 | Train | Epoch[313/600] Iteration[013/030] Train loss: 0.0182
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[014/030] Train loss: 0.0183
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[015/030] Train loss: 0.0184
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[016/030] Train loss: 0.0184
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[018/030] Train loss: 0.0184
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[019/030] Train loss: 0.0187
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[020/030] Train loss: 0.0187
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[021/030] Train loss: 0.0186
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[022/030] Train loss: 0.0185
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[023/030] Train loss: 0.0187
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[024/030] Train loss: 0.0186
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[025/030] Train loss: 0.0185
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[026/030] Train loss: 0.0186
2023-02-06 12:02:35 | Train | Epoch[313/600] Iteration[027/030] Train loss: 0.0187
2023-02-06 12:02:36 | Train | Epoch[313/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 12:02:36 | Train | Epoch[313/600] Iteration[029/030] Train loss: 0.0188
2023-02-06 12:02:36 | Train | Epoch[313/600] Iteration[030/030] Train loss: 0.0188
2023-02-06 12:02:36 | Valid | Epoch[313/600] Iteration[001/008] Valid loss: 1.3761
2023-02-06 12:02:36 | Valid | Epoch[313/600] Iteration[002/008] Valid loss: 1.3314
2023-02-06 12:02:36 | Valid | Epoch[313/600] Iteration[003/008] Valid loss: 1.3747
2023-02-06 12:02:36 | Valid | Epoch[313/600] Iteration[004/008] Valid loss: 1.4309
2023-02-06 12:02:36 | Valid | Epoch[313/600] Iteration[005/008] Valid loss: 1.4744
2023-02-06 12:02:36 | Valid | Epoch[313/600] Iteration[006/008] Valid loss: 1.4431
2023-02-06 12:02:36 | Valid | Epoch[313/600] Iteration[007/008] Valid loss: 1.4934
2023-02-06 12:02:36 | Valid | Epoch[313/600] Iteration[008/008] Valid loss: 1.5295
2023-02-06 12:02:36 | Valid | Epoch[313/600] MIou: 0.835004020647637
2023-02-06 12:02:36 | Valid | Epoch[313/600] Pixel Accuracy: 0.963280995686849
2023-02-06 12:02:36 | Valid | Epoch[313/600] Mean Pixel Accuracy: 0.9785115320703461
2023-02-06 12:02:36 | Stage | Epoch[313/600] Train loss:0.0188
2023-02-06 12:02:36 | Stage | Epoch[313/600] Valid loss:1.5295
2023-02-06 12:02:36 | Stage | Epoch[313/600] LR:0.01

2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[001/030] Train loss: 0.0175
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[002/030] Train loss: 0.0171
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[003/030] Train loss: 0.0170
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[004/030] Train loss: 0.0172
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[006/030] Train loss: 0.0171
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[009/030] Train loss: 0.0174
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[010/030] Train loss: 0.0181
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[011/030] Train loss: 0.0182
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[012/030] Train loss: 0.0185
2023-02-06 12:02:37 | Train | Epoch[314/600] Iteration[013/030] Train loss: 0.0184
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[014/030] Train loss: 0.0184
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[015/030] Train loss: 0.0183
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[018/030] Train loss: 0.0184
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[020/030] Train loss: 0.0185
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[021/030] Train loss: 0.0184
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[022/030] Train loss: 0.0183
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[023/030] Train loss: 0.0184
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[024/030] Train loss: 0.0184
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[025/030] Train loss: 0.0185
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[026/030] Train loss: 0.0186
2023-02-06 12:02:38 | Train | Epoch[314/600] Iteration[027/030] Train loss: 0.0189
2023-02-06 12:02:39 | Train | Epoch[314/600] Iteration[028/030] Train loss: 0.0189
2023-02-06 12:02:39 | Train | Epoch[314/600] Iteration[029/030] Train loss: 0.0188
2023-02-06 12:02:39 | Train | Epoch[314/600] Iteration[030/030] Train loss: 0.0189
2023-02-06 12:02:39 | Valid | Epoch[314/600] Iteration[001/008] Valid loss: 0.0888
2023-02-06 12:02:39 | Valid | Epoch[314/600] Iteration[002/008] Valid loss: 0.0615
2023-02-06 12:02:39 | Valid | Epoch[314/600] Iteration[003/008] Valid loss: 0.0620
2023-02-06 12:02:39 | Valid | Epoch[314/600] Iteration[004/008] Valid loss: 0.0567
2023-02-06 12:02:39 | Valid | Epoch[314/600] Iteration[005/008] Valid loss: 0.0539
2023-02-06 12:02:39 | Valid | Epoch[314/600] Iteration[006/008] Valid loss: 0.0510
2023-02-06 12:02:39 | Valid | Epoch[314/600] Iteration[007/008] Valid loss: 0.0532
2023-02-06 12:02:39 | Valid | Epoch[314/600] Iteration[008/008] Valid loss: 0.0515
2023-02-06 12:02:39 | Valid | Epoch[314/600] MIou: 0.9275831869981895
2023-02-06 12:02:39 | Valid | Epoch[314/600] Pixel Accuracy: 0.9877853393554688
2023-02-06 12:02:39 | Valid | Epoch[314/600] Mean Pixel Accuracy: 0.9450226324171374
2023-02-06 12:02:39 | Stage | Epoch[314/600] Train loss:0.0189
2023-02-06 12:02:39 | Stage | Epoch[314/600] Valid loss:0.0515
2023-02-06 12:02:39 | Stage | Epoch[314/600] LR:0.01

2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[002/030] Train loss: 0.0178
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[003/030] Train loss: 0.0185
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[004/030] Train loss: 0.0198
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[008/030] Train loss: 0.0188
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[009/030] Train loss: 0.0187
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[011/030] Train loss: 0.0186
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[012/030] Train loss: 0.0185
2023-02-06 12:02:40 | Train | Epoch[315/600] Iteration[013/030] Train loss: 0.0184
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[014/030] Train loss: 0.0183
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[015/030] Train loss: 0.0183
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[019/030] Train loss: 0.0186
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[020/030] Train loss: 0.0186
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[021/030] Train loss: 0.0185
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[022/030] Train loss: 0.0186
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[023/030] Train loss: 0.0186
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[024/030] Train loss: 0.0186
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[025/030] Train loss: 0.0186
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[026/030] Train loss: 0.0186
2023-02-06 12:02:41 | Train | Epoch[315/600] Iteration[027/030] Train loss: 0.0186
2023-02-06 12:02:42 | Train | Epoch[315/600] Iteration[028/030] Train loss: 0.0186
2023-02-06 12:02:42 | Train | Epoch[315/600] Iteration[029/030] Train loss: 0.0185
2023-02-06 12:02:42 | Train | Epoch[315/600] Iteration[030/030] Train loss: 0.0185
2023-02-06 12:02:42 | Valid | Epoch[315/600] Iteration[001/008] Valid loss: 0.2805
2023-02-06 12:02:42 | Valid | Epoch[315/600] Iteration[002/008] Valid loss: 0.2275
2023-02-06 12:02:42 | Valid | Epoch[315/600] Iteration[003/008] Valid loss: 0.2201
2023-02-06 12:02:42 | Valid | Epoch[315/600] Iteration[004/008] Valid loss: 0.2163
2023-02-06 12:02:42 | Valid | Epoch[315/600] Iteration[005/008] Valid loss: 0.2186
2023-02-06 12:02:42 | Valid | Epoch[315/600] Iteration[006/008] Valid loss: 0.2112
2023-02-06 12:02:42 | Valid | Epoch[315/600] Iteration[007/008] Valid loss: 0.2248
2023-02-06 12:02:42 | Valid | Epoch[315/600] Iteration[008/008] Valid loss: 0.2203
2023-02-06 12:02:42 | Valid | Epoch[315/600] MIou: 0.9264649400051788
2023-02-06 12:02:42 | Valid | Epoch[315/600] Pixel Accuracy: 0.986535390218099
2023-02-06 12:02:42 | Valid | Epoch[315/600] Mean Pixel Accuracy: 0.9825749907515507
2023-02-06 12:02:42 | Stage | Epoch[315/600] Train loss:0.0185
2023-02-06 12:02:42 | Stage | Epoch[315/600] Valid loss:0.2203
2023-02-06 12:02:42 | Stage | Epoch[315/600] LR:0.01

2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[002/030] Train loss: 0.0180
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[003/030] Train loss: 0.0177
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[004/030] Train loss: 0.0182
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[005/030] Train loss: 0.0180
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[008/030] Train loss: 0.0182
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[009/030] Train loss: 0.0184
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[010/030] Train loss: 0.0183
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[011/030] Train loss: 0.0186
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[012/030] Train loss: 0.0188
2023-02-06 12:02:43 | Train | Epoch[316/600] Iteration[013/030] Train loss: 0.0189
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[014/030] Train loss: 0.0187
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[015/030] Train loss: 0.0186
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[018/030] Train loss: 0.0183
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[021/030] Train loss: 0.0185
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[022/030] Train loss: 0.0186
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[023/030] Train loss: 0.0185
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[024/030] Train loss: 0.0186
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[025/030] Train loss: 0.0186
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[026/030] Train loss: 0.0186
2023-02-06 12:02:44 | Train | Epoch[316/600] Iteration[027/030] Train loss: 0.0187
2023-02-06 12:02:45 | Train | Epoch[316/600] Iteration[028/030] Train loss: 0.0187
2023-02-06 12:02:45 | Train | Epoch[316/600] Iteration[029/030] Train loss: 0.0187
2023-02-06 12:02:45 | Train | Epoch[316/600] Iteration[030/030] Train loss: 0.0188
2023-02-06 12:02:45 | Valid | Epoch[316/600] Iteration[001/008] Valid loss: 0.1583
2023-02-06 12:02:45 | Valid | Epoch[316/600] Iteration[002/008] Valid loss: 0.1626
2023-02-06 12:02:45 | Valid | Epoch[316/600] Iteration[003/008] Valid loss: 0.1752
2023-02-06 12:02:45 | Valid | Epoch[316/600] Iteration[004/008] Valid loss: 0.1703
2023-02-06 12:02:45 | Valid | Epoch[316/600] Iteration[005/008] Valid loss: 0.1760
2023-02-06 12:02:45 | Valid | Epoch[316/600] Iteration[006/008] Valid loss: 0.1723
2023-02-06 12:02:45 | Valid | Epoch[316/600] Iteration[007/008] Valid loss: 0.1684
2023-02-06 12:02:45 | Valid | Epoch[316/600] Iteration[008/008] Valid loss: 0.1780
2023-02-06 12:02:45 | Valid | Epoch[316/600] MIou: 0.5216218066516338
2023-02-06 12:02:45 | Valid | Epoch[316/600] Pixel Accuracy: 0.9208196004231771
2023-02-06 12:02:45 | Valid | Epoch[316/600] Mean Pixel Accuracy: 0.5616579143730026
2023-02-06 12:02:45 | Stage | Epoch[316/600] Train loss:0.0188
2023-02-06 12:02:45 | Stage | Epoch[316/600] Valid loss:0.1780
2023-02-06 12:02:45 | Stage | Epoch[316/600] LR:0.01

2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[001/030] Train loss: 0.0193
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[007/030] Train loss: 0.0187
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[008/030] Train loss: 0.0187
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[009/030] Train loss: 0.0187
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[010/030] Train loss: 0.0187
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[011/030] Train loss: 0.0188
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[012/030] Train loss: 0.0188
2023-02-06 12:02:46 | Train | Epoch[317/600] Iteration[013/030] Train loss: 0.0189
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[014/030] Train loss: 0.0190
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[015/030] Train loss: 0.0189
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[016/030] Train loss: 0.0189
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[017/030] Train loss: 0.0190
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[018/030] Train loss: 0.0190
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[019/030] Train loss: 0.0189
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[020/030] Train loss: 0.0188
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[021/030] Train loss: 0.0188
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[022/030] Train loss: 0.0189
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[023/030] Train loss: 0.0191
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[024/030] Train loss: 0.0190
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[025/030] Train loss: 0.0190
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:02:47 | Train | Epoch[317/600] Iteration[027/030] Train loss: 0.0188
2023-02-06 12:02:48 | Train | Epoch[317/600] Iteration[028/030] Train loss: 0.0187
2023-02-06 12:02:48 | Train | Epoch[317/600] Iteration[029/030] Train loss: 0.0187
2023-02-06 12:02:48 | Train | Epoch[317/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:02:48 | Valid | Epoch[317/600] Iteration[001/008] Valid loss: 0.1312
2023-02-06 12:02:48 | Valid | Epoch[317/600] Iteration[002/008] Valid loss: 0.1364
2023-02-06 12:02:48 | Valid | Epoch[317/600] Iteration[003/008] Valid loss: 0.1461
2023-02-06 12:02:48 | Valid | Epoch[317/600] Iteration[004/008] Valid loss: 0.1429
2023-02-06 12:02:48 | Valid | Epoch[317/600] Iteration[005/008] Valid loss: 0.1463
2023-02-06 12:02:48 | Valid | Epoch[317/600] Iteration[006/008] Valid loss: 0.1435
2023-02-06 12:02:48 | Valid | Epoch[317/600] Iteration[007/008] Valid loss: 0.1402
2023-02-06 12:02:48 | Valid | Epoch[317/600] Iteration[008/008] Valid loss: 0.1459
2023-02-06 12:02:48 | Valid | Epoch[317/600] MIou: 0.6094250197323003
2023-02-06 12:02:48 | Valid | Epoch[317/600] Pixel Accuracy: 0.9354337056477865
2023-02-06 12:02:48 | Valid | Epoch[317/600] Mean Pixel Accuracy: 0.6425614889692942
2023-02-06 12:02:48 | Stage | Epoch[317/600] Train loss:0.0186
2023-02-06 12:02:48 | Stage | Epoch[317/600] Valid loss:0.1459
2023-02-06 12:02:48 | Stage | Epoch[317/600] LR:0.01

2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[002/030] Train loss: 0.0191
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[006/030] Train loss: 0.0183
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[007/030] Train loss: 0.0186
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[008/030] Train loss: 0.0184
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[009/030] Train loss: 0.0182
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[010/030] Train loss: 0.0181
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[011/030] Train loss: 0.0178
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:02:49 | Train | Epoch[318/600] Iteration[013/030] Train loss: 0.0179
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[014/030] Train loss: 0.0183
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[017/030] Train loss: 0.0187
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[018/030] Train loss: 0.0188
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[019/030] Train loss: 0.0189
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[020/030] Train loss: 0.0188
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[021/030] Train loss: 0.0189
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[022/030] Train loss: 0.0187
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[023/030] Train loss: 0.0188
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[024/030] Train loss: 0.0188
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:02:50 | Train | Epoch[318/600] Iteration[027/030] Train loss: 0.0190
2023-02-06 12:02:51 | Train | Epoch[318/600] Iteration[028/030] Train loss: 0.0190
2023-02-06 12:02:51 | Train | Epoch[318/600] Iteration[029/030] Train loss: 0.0190
2023-02-06 12:02:51 | Train | Epoch[318/600] Iteration[030/030] Train loss: 0.0190
2023-02-06 12:02:51 | Valid | Epoch[318/600] Iteration[001/008] Valid loss: 0.0700
2023-02-06 12:02:51 | Valid | Epoch[318/600] Iteration[002/008] Valid loss: 0.0703
2023-02-06 12:02:51 | Valid | Epoch[318/600] Iteration[003/008] Valid loss: 0.0788
2023-02-06 12:02:51 | Valid | Epoch[318/600] Iteration[004/008] Valid loss: 0.0752
2023-02-06 12:02:51 | Valid | Epoch[318/600] Iteration[005/008] Valid loss: 0.0755
2023-02-06 12:02:51 | Valid | Epoch[318/600] Iteration[006/008] Valid loss: 0.0738
2023-02-06 12:02:51 | Valid | Epoch[318/600] Iteration[007/008] Valid loss: 0.0716
2023-02-06 12:02:51 | Valid | Epoch[318/600] Iteration[008/008] Valid loss: 0.0742
2023-02-06 12:02:51 | Valid | Epoch[318/600] MIou: 0.7636805978440236
2023-02-06 12:02:51 | Valid | Epoch[318/600] Pixel Accuracy: 0.9609781901041666
2023-02-06 12:02:51 | Valid | Epoch[318/600] Mean Pixel Accuracy: 0.7845462017146917
2023-02-06 12:02:51 | Stage | Epoch[318/600] Train loss:0.0190
2023-02-06 12:02:51 | Stage | Epoch[318/600] Valid loss:0.0742
2023-02-06 12:02:51 | Stage | Epoch[318/600] LR:0.01

2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[002/030] Train loss: 0.0165
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[005/030] Train loss: 0.0179
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[006/030] Train loss: 0.0182
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[009/030] Train loss: 0.0183
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[010/030] Train loss: 0.0185
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[011/030] Train loss: 0.0184
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[012/030] Train loss: 0.0183
2023-02-06 12:02:52 | Train | Epoch[319/600] Iteration[013/030] Train loss: 0.0183
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[015/030] Train loss: 0.0188
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[016/030] Train loss: 0.0187
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[017/030] Train loss: 0.0186
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[018/030] Train loss: 0.0186
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[019/030] Train loss: 0.0186
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[020/030] Train loss: 0.0186
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[021/030] Train loss: 0.0186
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[022/030] Train loss: 0.0185
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[023/030] Train loss: 0.0185
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[024/030] Train loss: 0.0185
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[025/030] Train loss: 0.0185
2023-02-06 12:02:53 | Train | Epoch[319/600] Iteration[026/030] Train loss: 0.0185
2023-02-06 12:02:54 | Train | Epoch[319/600] Iteration[027/030] Train loss: 0.0184
2023-02-06 12:02:54 | Train | Epoch[319/600] Iteration[028/030] Train loss: 0.0185
2023-02-06 12:02:54 | Train | Epoch[319/600] Iteration[029/030] Train loss: 0.0186
2023-02-06 12:02:54 | Train | Epoch[319/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:02:54 | Valid | Epoch[319/600] Iteration[001/008] Valid loss: 0.1083
2023-02-06 12:02:54 | Valid | Epoch[319/600] Iteration[002/008] Valid loss: 0.0770
2023-02-06 12:02:54 | Valid | Epoch[319/600] Iteration[003/008] Valid loss: 0.0738
2023-02-06 12:02:54 | Valid | Epoch[319/600] Iteration[004/008] Valid loss: 0.0673
2023-02-06 12:02:54 | Valid | Epoch[319/600] Iteration[005/008] Valid loss: 0.0651
2023-02-06 12:02:54 | Valid | Epoch[319/600] Iteration[006/008] Valid loss: 0.0612
2023-02-06 12:02:54 | Valid | Epoch[319/600] Iteration[007/008] Valid loss: 0.0643
2023-02-06 12:02:54 | Valid | Epoch[319/600] Iteration[008/008] Valid loss: 0.0624
2023-02-06 12:02:54 | Valid | Epoch[319/600] MIou: 0.9359351573504985
2023-02-06 12:02:54 | Valid | Epoch[319/600] Pixel Accuracy: 0.9890797932942709
2023-02-06 12:02:54 | Valid | Epoch[319/600] Mean Pixel Accuracy: 0.957711270195347
2023-02-06 12:02:54 | Stage | Epoch[319/600] Train loss:0.0186
2023-02-06 12:02:54 | Stage | Epoch[319/600] Valid loss:0.0624
2023-02-06 12:02:54 | Stage | Epoch[319/600] LR:0.01

2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[001/030] Train loss: 0.0176
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[002/030] Train loss: 0.0173
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[008/030] Train loss: 0.0174
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[009/030] Train loss: 0.0176
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[010/030] Train loss: 0.0177
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[011/030] Train loss: 0.0176
2023-02-06 12:02:55 | Train | Epoch[320/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[013/030] Train loss: 0.0179
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[015/030] Train loss: 0.0181
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[016/030] Train loss: 0.0180
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[018/030] Train loss: 0.0183
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[020/030] Train loss: 0.0186
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[021/030] Train loss: 0.0185
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[022/030] Train loss: 0.0185
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[023/030] Train loss: 0.0185
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[024/030] Train loss: 0.0185
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[025/030] Train loss: 0.0186
2023-02-06 12:02:56 | Train | Epoch[320/600] Iteration[026/030] Train loss: 0.0186
2023-02-06 12:02:57 | Train | Epoch[320/600] Iteration[027/030] Train loss: 0.0190
2023-02-06 12:02:57 | Train | Epoch[320/600] Iteration[028/030] Train loss: 0.0190
2023-02-06 12:02:57 | Train | Epoch[320/600] Iteration[029/030] Train loss: 0.0191
2023-02-06 12:02:57 | Train | Epoch[320/600] Iteration[030/030] Train loss: 0.0189
2023-02-06 12:02:57 | Valid | Epoch[320/600] Iteration[001/008] Valid loss: 0.1408
2023-02-06 12:02:57 | Valid | Epoch[320/600] Iteration[002/008] Valid loss: 0.0986
2023-02-06 12:02:57 | Valid | Epoch[320/600] Iteration[003/008] Valid loss: 0.0891
2023-02-06 12:02:57 | Valid | Epoch[320/600] Iteration[004/008] Valid loss: 0.0856
2023-02-06 12:02:57 | Valid | Epoch[320/600] Iteration[005/008] Valid loss: 0.0828
2023-02-06 12:02:57 | Valid | Epoch[320/600] Iteration[006/008] Valid loss: 0.0786
2023-02-06 12:02:57 | Valid | Epoch[320/600] Iteration[007/008] Valid loss: 0.0847
2023-02-06 12:02:57 | Valid | Epoch[320/600] Iteration[008/008] Valid loss: 0.0811
2023-02-06 12:02:57 | Valid | Epoch[320/600] MIou: 0.9374254184081424
2023-02-06 12:02:57 | Valid | Epoch[320/600] Pixel Accuracy: 0.9891688028971354
2023-02-06 12:02:57 | Valid | Epoch[320/600] Mean Pixel Accuracy: 0.9663008087960205
2023-02-06 12:02:57 | Stage | Epoch[320/600] Train loss:0.0189
2023-02-06 12:02:57 | Stage | Epoch[320/600] Valid loss:0.0811
2023-02-06 12:02:57 | Stage | Epoch[320/600] LR:0.01

2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[001/030] Train loss: 0.0168
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[008/030] Train loss: 0.0177
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[009/030] Train loss: 0.0180
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[010/030] Train loss: 0.0179
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[011/030] Train loss: 0.0179
2023-02-06 12:02:58 | Train | Epoch[321/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[013/030] Train loss: 0.0178
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[014/030] Train loss: 0.0179
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[016/030] Train loss: 0.0181
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[017/030] Train loss: 0.0183
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[018/030] Train loss: 0.0183
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[020/030] Train loss: 0.0186
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[021/030] Train loss: 0.0188
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[022/030] Train loss: 0.0188
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[023/030] Train loss: 0.0188
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[024/030] Train loss: 0.0190
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[025/030] Train loss: 0.0190
2023-02-06 12:02:59 | Train | Epoch[321/600] Iteration[026/030] Train loss: 0.0193
2023-02-06 12:03:00 | Train | Epoch[321/600] Iteration[027/030] Train loss: 0.0194
2023-02-06 12:03:00 | Train | Epoch[321/600] Iteration[028/030] Train loss: 0.0194
2023-02-06 12:03:00 | Train | Epoch[321/600] Iteration[029/030] Train loss: 0.0193
2023-02-06 12:03:00 | Train | Epoch[321/600] Iteration[030/030] Train loss: 0.0193
2023-02-06 12:03:00 | Valid | Epoch[321/600] Iteration[001/008] Valid loss: 1.6351
2023-02-06 12:03:00 | Valid | Epoch[321/600] Iteration[002/008] Valid loss: 1.4999
2023-02-06 12:03:00 | Valid | Epoch[321/600] Iteration[003/008] Valid loss: 1.5387
2023-02-06 12:03:00 | Valid | Epoch[321/600] Iteration[004/008] Valid loss: 1.6371
2023-02-06 12:03:00 | Valid | Epoch[321/600] Iteration[005/008] Valid loss: 1.6985
2023-02-06 12:03:00 | Valid | Epoch[321/600] Iteration[006/008] Valid loss: 1.6640
2023-02-06 12:03:00 | Valid | Epoch[321/600] Iteration[007/008] Valid loss: 1.7178
2023-02-06 12:03:00 | Valid | Epoch[321/600] Iteration[008/008] Valid loss: 1.7385
2023-02-06 12:03:00 | Valid | Epoch[321/600] MIou: 0.830617262364746
2023-02-06 12:03:00 | Valid | Epoch[321/600] Pixel Accuracy: 0.9619636535644531
2023-02-06 12:03:00 | Valid | Epoch[321/600] Mean Pixel Accuracy: 0.9777430813560101
2023-02-06 12:03:00 | Stage | Epoch[321/600] Train loss:0.0193
2023-02-06 12:03:00 | Stage | Epoch[321/600] Valid loss:1.7385
2023-02-06 12:03:00 | Stage | Epoch[321/600] LR:0.01

2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[004/030] Train loss: 0.0191
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[005/030] Train loss: 0.0187
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[009/030] Train loss: 0.0186
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[010/030] Train loss: 0.0185
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[011/030] Train loss: 0.0184
2023-02-06 12:03:01 | Train | Epoch[322/600] Iteration[012/030] Train loss: 0.0184
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[013/030] Train loss: 0.0183
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[014/030] Train loss: 0.0186
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[015/030] Train loss: 0.0186
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[016/030] Train loss: 0.0187
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[017/030] Train loss: 0.0186
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[018/030] Train loss: 0.0186
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[019/030] Train loss: 0.0187
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[020/030] Train loss: 0.0187
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[021/030] Train loss: 0.0186
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[022/030] Train loss: 0.0187
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[023/030] Train loss: 0.0189
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[024/030] Train loss: 0.0190
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[025/030] Train loss: 0.0190
2023-02-06 12:03:02 | Train | Epoch[322/600] Iteration[026/030] Train loss: 0.0191
2023-02-06 12:03:03 | Train | Epoch[322/600] Iteration[027/030] Train loss: 0.0190
2023-02-06 12:03:03 | Train | Epoch[322/600] Iteration[028/030] Train loss: 0.0191
2023-02-06 12:03:03 | Train | Epoch[322/600] Iteration[029/030] Train loss: 0.0190
2023-02-06 12:03:03 | Train | Epoch[322/600] Iteration[030/030] Train loss: 0.0190
2023-02-06 12:03:03 | Valid | Epoch[322/600] Iteration[001/008] Valid loss: 0.0960
2023-02-06 12:03:03 | Valid | Epoch[322/600] Iteration[002/008] Valid loss: 0.0699
2023-02-06 12:03:03 | Valid | Epoch[322/600] Iteration[003/008] Valid loss: 0.0662
2023-02-06 12:03:03 | Valid | Epoch[322/600] Iteration[004/008] Valid loss: 0.0614
2023-02-06 12:03:03 | Valid | Epoch[322/600] Iteration[005/008] Valid loss: 0.0573
2023-02-06 12:03:03 | Valid | Epoch[322/600] Iteration[006/008] Valid loss: 0.0552
2023-02-06 12:03:03 | Valid | Epoch[322/600] Iteration[007/008] Valid loss: 0.0583
2023-02-06 12:03:03 | Valid | Epoch[322/600] Iteration[008/008] Valid loss: 0.0563
2023-02-06 12:03:03 | Valid | Epoch[322/600] MIou: 0.9283612312491842
2023-02-06 12:03:03 | Valid | Epoch[322/600] Pixel Accuracy: 0.9878946940104166
2023-02-06 12:03:03 | Valid | Epoch[322/600] Mean Pixel Accuracy: 0.9465664087331865
2023-02-06 12:03:03 | Stage | Epoch[322/600] Train loss:0.0190
2023-02-06 12:03:03 | Stage | Epoch[322/600] Valid loss:0.0563
2023-02-06 12:03:03 | Stage | Epoch[322/600] LR:0.01

2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[004/030] Train loss: 0.0182
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[005/030] Train loss: 0.0181
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[006/030] Train loss: 0.0183
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[008/030] Train loss: 0.0179
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[009/030] Train loss: 0.0181
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[010/030] Train loss: 0.0182
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[011/030] Train loss: 0.0185
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[012/030] Train loss: 0.0194
2023-02-06 12:03:04 | Train | Epoch[323/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 12:03:05 | Train | Epoch[323/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 12:03:06 | Train | Epoch[323/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 12:03:06 | Train | Epoch[323/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 12:03:06 | Train | Epoch[323/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 12:03:06 | Valid | Epoch[323/600] Iteration[001/008] Valid loss: 0.0857
2023-02-06 12:03:06 | Valid | Epoch[323/600] Iteration[002/008] Valid loss: 0.0609
2023-02-06 12:03:06 | Valid | Epoch[323/600] Iteration[003/008] Valid loss: 0.0588
2023-02-06 12:03:06 | Valid | Epoch[323/600] Iteration[004/008] Valid loss: 0.0526
2023-02-06 12:03:06 | Valid | Epoch[323/600] Iteration[005/008] Valid loss: 0.0500
2023-02-06 12:03:06 | Valid | Epoch[323/600] Iteration[006/008] Valid loss: 0.0471
2023-02-06 12:03:06 | Valid | Epoch[323/600] Iteration[007/008] Valid loss: 0.0488
2023-02-06 12:03:06 | Valid | Epoch[323/600] Iteration[008/008] Valid loss: 0.0467
2023-02-06 12:03:06 | Valid | Epoch[323/600] MIou: 0.92761963940863
2023-02-06 12:03:06 | Valid | Epoch[323/600] Pixel Accuracy: 0.9878565470377604
2023-02-06 12:03:06 | Valid | Epoch[323/600] Mean Pixel Accuracy: 0.9426777539077169
2023-02-06 12:03:06 | Stage | Epoch[323/600] Train loss:0.0200
2023-02-06 12:03:06 | Stage | Epoch[323/600] Valid loss:0.0467
2023-02-06 12:03:06 | Stage | Epoch[323/600] LR:0.01

2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[003/030] Train loss: 0.0196
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 12:03:07 | Train | Epoch[324/600] Iteration[014/030] Train loss: 0.0195
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[016/030] Train loss: 0.0192
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[017/030] Train loss: 0.0190
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[018/030] Train loss: 0.0190
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[019/030] Train loss: 0.0190
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[020/030] Train loss: 0.0190
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[021/030] Train loss: 0.0189
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[022/030] Train loss: 0.0189
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[023/030] Train loss: 0.0190
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[024/030] Train loss: 0.0188
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[027/030] Train loss: 0.0191
2023-02-06 12:03:08 | Train | Epoch[324/600] Iteration[028/030] Train loss: 0.0191
2023-02-06 12:03:09 | Train | Epoch[324/600] Iteration[029/030] Train loss: 0.0192
2023-02-06 12:03:09 | Train | Epoch[324/600] Iteration[030/030] Train loss: 0.0192
2023-02-06 12:03:09 | Valid | Epoch[324/600] Iteration[001/008] Valid loss: 0.2234
2023-02-06 12:03:09 | Valid | Epoch[324/600] Iteration[002/008] Valid loss: 0.1783
2023-02-06 12:03:09 | Valid | Epoch[324/600] Iteration[003/008] Valid loss: 0.1614
2023-02-06 12:03:09 | Valid | Epoch[324/600] Iteration[004/008] Valid loss: 0.1550
2023-02-06 12:03:09 | Valid | Epoch[324/600] Iteration[005/008] Valid loss: 0.1517
2023-02-06 12:03:09 | Valid | Epoch[324/600] Iteration[006/008] Valid loss: 0.1456
2023-02-06 12:03:09 | Valid | Epoch[324/600] Iteration[007/008] Valid loss: 0.1550
2023-02-06 12:03:09 | Valid | Epoch[324/600] Iteration[008/008] Valid loss: 0.1540
2023-02-06 12:03:09 | Valid | Epoch[324/600] MIou: 0.930570358209195
2023-02-06 12:03:09 | Valid | Epoch[324/600] Pixel Accuracy: 0.9875170389811198
2023-02-06 12:03:09 | Valid | Epoch[324/600] Mean Pixel Accuracy: 0.9777631888218188
2023-02-06 12:03:09 | Stage | Epoch[324/600] Train loss:0.0192
2023-02-06 12:03:09 | Stage | Epoch[324/600] Valid loss:0.1540
2023-02-06 12:03:09 | Stage | Epoch[324/600] LR:0.01

2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[001/030] Train loss: 0.0172
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[003/030] Train loss: 0.0163
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[006/030] Train loss: 0.0179
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[008/030] Train loss: 0.0180
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[009/030] Train loss: 0.0179
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[011/030] Train loss: 0.0179
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[012/030] Train loss: 0.0179
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[013/030] Train loss: 0.0182
2023-02-06 12:03:10 | Train | Epoch[325/600] Iteration[014/030] Train loss: 0.0183
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[015/030] Train loss: 0.0184
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[021/030] Train loss: 0.0184
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[022/030] Train loss: 0.0186
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[023/030] Train loss: 0.0186
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[024/030] Train loss: 0.0185
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[025/030] Train loss: 0.0184
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[026/030] Train loss: 0.0185
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[027/030] Train loss: 0.0185
2023-02-06 12:03:11 | Train | Epoch[325/600] Iteration[028/030] Train loss: 0.0186
2023-02-06 12:03:12 | Train | Epoch[325/600] Iteration[029/030] Train loss: 0.0186
2023-02-06 12:03:12 | Train | Epoch[325/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:03:12 | Valid | Epoch[325/600] Iteration[001/008] Valid loss: 0.5561
2023-02-06 12:03:12 | Valid | Epoch[325/600] Iteration[002/008] Valid loss: 0.4734
2023-02-06 12:03:12 | Valid | Epoch[325/600] Iteration[003/008] Valid loss: 0.4784
2023-02-06 12:03:12 | Valid | Epoch[325/600] Iteration[004/008] Valid loss: 0.5005
2023-02-06 12:03:12 | Valid | Epoch[325/600] Iteration[005/008] Valid loss: 0.5257
2023-02-06 12:03:12 | Valid | Epoch[325/600] Iteration[006/008] Valid loss: 0.5121
2023-02-06 12:03:12 | Valid | Epoch[325/600] Iteration[007/008] Valid loss: 0.5480
2023-02-06 12:03:12 | Valid | Epoch[325/600] Iteration[008/008] Valid loss: 0.5493
2023-02-06 12:03:12 | Valid | Epoch[325/600] MIou: 0.8914960237503613
2023-02-06 12:03:12 | Valid | Epoch[325/600] Pixel Accuracy: 0.9786148071289062
2023-02-06 12:03:12 | Valid | Epoch[325/600] Mean Pixel Accuracy: 0.9822476998912026
2023-02-06 12:03:12 | Stage | Epoch[325/600] Train loss:0.0186
2023-02-06 12:03:12 | Stage | Epoch[325/600] Valid loss:0.5493
2023-02-06 12:03:12 | Stage | Epoch[325/600] LR:0.01

2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[007/030] Train loss: 0.0183
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[008/030] Train loss: 0.0185
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[009/030] Train loss: 0.0184
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[010/030] Train loss: 0.0183
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[011/030] Train loss: 0.0181
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[012/030] Train loss: 0.0182
2023-02-06 12:03:13 | Train | Epoch[326/600] Iteration[013/030] Train loss: 0.0182
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[014/030] Train loss: 0.0181
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[015/030] Train loss: 0.0180
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[016/030] Train loss: 0.0180
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[017/030] Train loss: 0.0179
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[018/030] Train loss: 0.0179
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[019/030] Train loss: 0.0181
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[020/030] Train loss: 0.0181
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[021/030] Train loss: 0.0180
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[022/030] Train loss: 0.0180
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[023/030] Train loss: 0.0180
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[024/030] Train loss: 0.0181
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[025/030] Train loss: 0.0180
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[026/030] Train loss: 0.0181
2023-02-06 12:03:14 | Train | Epoch[326/600] Iteration[027/030] Train loss: 0.0181
2023-02-06 12:03:15 | Train | Epoch[326/600] Iteration[028/030] Train loss: 0.0182
2023-02-06 12:03:15 | Train | Epoch[326/600] Iteration[029/030] Train loss: 0.0181
2023-02-06 12:03:15 | Train | Epoch[326/600] Iteration[030/030] Train loss: 0.0182
2023-02-06 12:03:15 | Valid | Epoch[326/600] Iteration[001/008] Valid loss: 0.0634
2023-02-06 12:03:15 | Valid | Epoch[326/600] Iteration[002/008] Valid loss: 0.0605
2023-02-06 12:03:15 | Valid | Epoch[326/600] Iteration[003/008] Valid loss: 0.0641
2023-02-06 12:03:15 | Valid | Epoch[326/600] Iteration[004/008] Valid loss: 0.0617
2023-02-06 12:03:15 | Valid | Epoch[326/600] Iteration[005/008] Valid loss: 0.0628
2023-02-06 12:03:15 | Valid | Epoch[326/600] Iteration[006/008] Valid loss: 0.0621
2023-02-06 12:03:15 | Valid | Epoch[326/600] Iteration[007/008] Valid loss: 0.0605
2023-02-06 12:03:15 | Valid | Epoch[326/600] Iteration[008/008] Valid loss: 0.0617
2023-02-06 12:03:15 | Valid | Epoch[326/600] MIou: 0.8263959992345875
2023-02-06 12:03:15 | Valid | Epoch[326/600] Pixel Accuracy: 0.9713783264160156
2023-02-06 12:03:15 | Valid | Epoch[326/600] Mean Pixel Accuracy: 0.8418296149945148
2023-02-06 12:03:15 | Stage | Epoch[326/600] Train loss:0.0182
2023-02-06 12:03:15 | Stage | Epoch[326/600] Valid loss:0.0617
2023-02-06 12:03:15 | Stage | Epoch[326/600] LR:0.01

2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[005/030] Train loss: 0.0178
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[006/030] Train loss: 0.0177
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[007/030] Train loss: 0.0180
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[008/030] Train loss: 0.0179
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[009/030] Train loss: 0.0178
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[010/030] Train loss: 0.0179
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[011/030] Train loss: 0.0180
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[012/030] Train loss: 0.0179
2023-02-06 12:03:16 | Train | Epoch[327/600] Iteration[013/030] Train loss: 0.0179
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[014/030] Train loss: 0.0182
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[015/030] Train loss: 0.0183
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[016/030] Train loss: 0.0182
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[017/030] Train loss: 0.0183
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[018/030] Train loss: 0.0184
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[020/030] Train loss: 0.0183
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[021/030] Train loss: 0.0185
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[022/030] Train loss: 0.0184
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[023/030] Train loss: 0.0183
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[025/030] Train loss: 0.0183
2023-02-06 12:03:17 | Train | Epoch[327/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:03:18 | Train | Epoch[327/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 12:03:18 | Train | Epoch[327/600] Iteration[028/030] Train loss: 0.0183
2023-02-06 12:03:18 | Train | Epoch[327/600] Iteration[029/030] Train loss: 0.0186
2023-02-06 12:03:18 | Train | Epoch[327/600] Iteration[030/030] Train loss: 0.0187
2023-02-06 12:03:18 | Valid | Epoch[327/600] Iteration[001/008] Valid loss: 0.2005
2023-02-06 12:03:18 | Valid | Epoch[327/600] Iteration[002/008] Valid loss: 0.1437
2023-02-06 12:03:18 | Valid | Epoch[327/600] Iteration[003/008] Valid loss: 0.1346
2023-02-06 12:03:18 | Valid | Epoch[327/600] Iteration[004/008] Valid loss: 0.1283
2023-02-06 12:03:18 | Valid | Epoch[327/600] Iteration[005/008] Valid loss: 0.1259
2023-02-06 12:03:18 | Valid | Epoch[327/600] Iteration[006/008] Valid loss: 0.1183
2023-02-06 12:03:18 | Valid | Epoch[327/600] Iteration[007/008] Valid loss: 0.1293
2023-02-06 12:03:18 | Valid | Epoch[327/600] Iteration[008/008] Valid loss: 0.1257
2023-02-06 12:03:18 | Valid | Epoch[327/600] MIou: 0.9398621780308015
2023-02-06 12:03:18 | Valid | Epoch[327/600] Pixel Accuracy: 0.989434560139974
2023-02-06 12:03:18 | Valid | Epoch[327/600] Mean Pixel Accuracy: 0.9757800543767383
2023-02-06 12:03:18 | Stage | Epoch[327/600] Train loss:0.0187
2023-02-06 12:03:18 | Stage | Epoch[327/600] Valid loss:0.1257
2023-02-06 12:03:18 | Stage | Epoch[327/600] LR:0.01

2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[004/030] Train loss: 0.0189
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[005/030] Train loss: 0.0187
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[007/030] Train loss: 0.0189
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[008/030] Train loss: 0.0190
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[009/030] Train loss: 0.0189
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[010/030] Train loss: 0.0191
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[011/030] Train loss: 0.0189
2023-02-06 12:03:19 | Train | Epoch[328/600] Iteration[012/030] Train loss: 0.0191
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[013/030] Train loss: 0.0191
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[014/030] Train loss: 0.0188
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[015/030] Train loss: 0.0189
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[016/030] Train loss: 0.0188
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[017/030] Train loss: 0.0187
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[018/030] Train loss: 0.0187
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[019/030] Train loss: 0.0188
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[020/030] Train loss: 0.0188
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[021/030] Train loss: 0.0189
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[022/030] Train loss: 0.0189
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[023/030] Train loss: 0.0188
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[024/030] Train loss: 0.0189
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:03:20 | Train | Epoch[328/600] Iteration[026/030] Train loss: 0.0187
2023-02-06 12:03:21 | Train | Epoch[328/600] Iteration[027/030] Train loss: 0.0188
2023-02-06 12:03:21 | Train | Epoch[328/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 12:03:21 | Train | Epoch[328/600] Iteration[029/030] Train loss: 0.0189
2023-02-06 12:03:21 | Train | Epoch[328/600] Iteration[030/030] Train loss: 0.0188
2023-02-06 12:03:21 | Valid | Epoch[328/600] Iteration[001/008] Valid loss: 0.2554
2023-02-06 12:03:21 | Valid | Epoch[328/600] Iteration[002/008] Valid loss: 0.2586
2023-02-06 12:03:21 | Valid | Epoch[328/600] Iteration[003/008] Valid loss: 0.2779
2023-02-06 12:03:21 | Valid | Epoch[328/600] Iteration[004/008] Valid loss: 0.2758
2023-02-06 12:03:21 | Valid | Epoch[328/600] Iteration[005/008] Valid loss: 0.2846
2023-02-06 12:03:21 | Valid | Epoch[328/600] Iteration[006/008] Valid loss: 0.2801
2023-02-06 12:03:21 | Valid | Epoch[328/600] Iteration[007/008] Valid loss: 0.2765
2023-02-06 12:03:21 | Valid | Epoch[328/600] Iteration[008/008] Valid loss: 0.2880
2023-02-06 12:03:21 | Valid | Epoch[328/600] MIou: 0.4652253241718173
2023-02-06 12:03:21 | Valid | Epoch[328/600] Pixel Accuracy: 0.9114151000976562
2023-02-06 12:03:21 | Valid | Epoch[328/600] Mean Pixel Accuracy: 0.5095946725985161
2023-02-06 12:03:21 | Stage | Epoch[328/600] Train loss:0.0188
2023-02-06 12:03:21 | Stage | Epoch[328/600] Valid loss:0.2880
2023-02-06 12:03:21 | Stage | Epoch[328/600] LR:0.01

2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[002/030] Train loss: 0.0179
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[003/030] Train loss: 0.0180
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[004/030] Train loss: 0.0186
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[006/030] Train loss: 0.0184
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[007/030] Train loss: 0.0186
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[008/030] Train loss: 0.0187
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[009/030] Train loss: 0.0183
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[011/030] Train loss: 0.0184
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[012/030] Train loss: 0.0183
2023-02-06 12:03:22 | Train | Epoch[329/600] Iteration[013/030] Train loss: 0.0183
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[014/030] Train loss: 0.0182
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[016/030] Train loss: 0.0182
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[017/030] Train loss: 0.0182
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[018/030] Train loss: 0.0181
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[019/030] Train loss: 0.0181
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[020/030] Train loss: 0.0181
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[021/030] Train loss: 0.0180
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[022/030] Train loss: 0.0181
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[024/030] Train loss: 0.0182
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[025/030] Train loss: 0.0183
2023-02-06 12:03:23 | Train | Epoch[329/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:03:24 | Train | Epoch[329/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 12:03:24 | Train | Epoch[329/600] Iteration[028/030] Train loss: 0.0184
2023-02-06 12:03:24 | Train | Epoch[329/600] Iteration[029/030] Train loss: 0.0184
2023-02-06 12:03:24 | Train | Epoch[329/600] Iteration[030/030] Train loss: 0.0184
2023-02-06 12:03:24 | Valid | Epoch[329/600] Iteration[001/008] Valid loss: 0.0999
2023-02-06 12:03:24 | Valid | Epoch[329/600] Iteration[002/008] Valid loss: 0.0714
2023-02-06 12:03:24 | Valid | Epoch[329/600] Iteration[003/008] Valid loss: 0.0667
2023-02-06 12:03:24 | Valid | Epoch[329/600] Iteration[004/008] Valid loss: 0.0614
2023-02-06 12:03:24 | Valid | Epoch[329/600] Iteration[005/008] Valid loss: 0.0596
2023-02-06 12:03:24 | Valid | Epoch[329/600] Iteration[006/008] Valid loss: 0.0563
2023-02-06 12:03:24 | Valid | Epoch[329/600] Iteration[007/008] Valid loss: 0.0603
2023-02-06 12:03:24 | Valid | Epoch[329/600] Iteration[008/008] Valid loss: 0.0580
2023-02-06 12:03:24 | Valid | Epoch[329/600] MIou: 0.9398210096933316
2023-02-06 12:03:24 | Valid | Epoch[329/600] Pixel Accuracy: 0.989752451578776
2023-02-06 12:03:24 | Valid | Epoch[329/600] Mean Pixel Accuracy: 0.960946885000153
2023-02-06 12:03:24 | Stage | Epoch[329/600] Train loss:0.0184
2023-02-06 12:03:24 | Stage | Epoch[329/600] Valid loss:0.0580
2023-02-06 12:03:24 | Stage | Epoch[329/600] LR:0.01

2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[001/030] Train loss: 0.0162
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[004/030] Train loss: 0.0182
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[006/030] Train loss: 0.0176
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[007/030] Train loss: 0.0177
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[008/030] Train loss: 0.0179
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[009/030] Train loss: 0.0182
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[011/030] Train loss: 0.0184
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[012/030] Train loss: 0.0185
2023-02-06 12:03:25 | Train | Epoch[330/600] Iteration[013/030] Train loss: 0.0186
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[014/030] Train loss: 0.0184
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[015/030] Train loss: 0.0188
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[016/030] Train loss: 0.0188
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[017/030] Train loss: 0.0190
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[018/030] Train loss: 0.0191
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[019/030] Train loss: 0.0191
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[020/030] Train loss: 0.0193
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[021/030] Train loss: 0.0192
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[022/030] Train loss: 0.0192
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[023/030] Train loss: 0.0190
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[024/030] Train loss: 0.0190
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[025/030] Train loss: 0.0190
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:03:26 | Train | Epoch[330/600] Iteration[027/030] Train loss: 0.0190
2023-02-06 12:03:27 | Train | Epoch[330/600] Iteration[028/030] Train loss: 0.0189
2023-02-06 12:03:27 | Train | Epoch[330/600] Iteration[029/030] Train loss: 0.0189
2023-02-06 12:03:27 | Train | Epoch[330/600] Iteration[030/030] Train loss: 0.0190
2023-02-06 12:03:27 | Valid | Epoch[330/600] Iteration[001/008] Valid loss: 0.2887
2023-02-06 12:03:27 | Valid | Epoch[330/600] Iteration[002/008] Valid loss: 0.2962
2023-02-06 12:03:27 | Valid | Epoch[330/600] Iteration[003/008] Valid loss: 0.3205
2023-02-06 12:03:27 | Valid | Epoch[330/600] Iteration[004/008] Valid loss: 0.3161
2023-02-06 12:03:27 | Valid | Epoch[330/600] Iteration[005/008] Valid loss: 0.3283
2023-02-06 12:03:27 | Valid | Epoch[330/600] Iteration[006/008] Valid loss: 0.3232
2023-02-06 12:03:27 | Valid | Epoch[330/600] Iteration[007/008] Valid loss: 0.3199
2023-02-06 12:03:27 | Valid | Epoch[330/600] Iteration[008/008] Valid loss: 0.3360
2023-02-06 12:03:27 | Valid | Epoch[330/600] MIou: 0.46112611331697756
2023-02-06 12:03:27 | Valid | Epoch[330/600] Pixel Accuracy: 0.9107309977213541
2023-02-06 12:03:27 | Valid | Epoch[330/600] Mean Pixel Accuracy: 0.5058074870827408
2023-02-06 12:03:27 | Stage | Epoch[330/600] Train loss:0.0190
2023-02-06 12:03:27 | Stage | Epoch[330/600] Valid loss:0.3360
2023-02-06 12:03:27 | Stage | Epoch[330/600] LR:0.01

2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[003/030] Train loss: 0.0183
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[005/030] Train loss: 0.0179
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[006/030] Train loss: 0.0182
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[007/030] Train loss: 0.0186
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[009/030] Train loss: 0.0189
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[011/030] Train loss: 0.0187
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[012/030] Train loss: 0.0185
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[013/030] Train loss: 0.0185
2023-02-06 12:03:28 | Train | Epoch[331/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[015/030] Train loss: 0.0184
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[017/030] Train loss: 0.0185
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[021/030] Train loss: 0.0184
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[022/030] Train loss: 0.0183
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[023/030] Train loss: 0.0184
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[024/030] Train loss: 0.0184
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[025/030] Train loss: 0.0184
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[026/030] Train loss: 0.0184
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[027/030] Train loss: 0.0185
2023-02-06 12:03:29 | Train | Epoch[331/600] Iteration[028/030] Train loss: 0.0185
2023-02-06 12:03:30 | Train | Epoch[331/600] Iteration[029/030] Train loss: 0.0186
2023-02-06 12:03:30 | Train | Epoch[331/600] Iteration[030/030] Train loss: 0.0187
2023-02-06 12:03:30 | Valid | Epoch[331/600] Iteration[001/008] Valid loss: 0.0531
2023-02-06 12:03:30 | Valid | Epoch[331/600] Iteration[002/008] Valid loss: 0.0503
2023-02-06 12:03:30 | Valid | Epoch[331/600] Iteration[003/008] Valid loss: 0.0534
2023-02-06 12:03:30 | Valid | Epoch[331/600] Iteration[004/008] Valid loss: 0.0504
2023-02-06 12:03:30 | Valid | Epoch[331/600] Iteration[005/008] Valid loss: 0.0503
2023-02-06 12:03:30 | Valid | Epoch[331/600] Iteration[006/008] Valid loss: 0.0488
2023-02-06 12:03:30 | Valid | Epoch[331/600] Iteration[007/008] Valid loss: 0.0476
2023-02-06 12:03:30 | Valid | Epoch[331/600] Iteration[008/008] Valid loss: 0.0484
2023-02-06 12:03:30 | Valid | Epoch[331/600] MIou: 0.8512601388240228
2023-02-06 12:03:30 | Valid | Epoch[331/600] Pixel Accuracy: 0.9754358927408854
2023-02-06 12:03:30 | Valid | Epoch[331/600] Mean Pixel Accuracy: 0.8653321084207092
2023-02-06 12:03:30 | Stage | Epoch[331/600] Train loss:0.0187
2023-02-06 12:03:30 | Stage | Epoch[331/600] Valid loss:0.0484
2023-02-06 12:03:30 | Stage | Epoch[331/600] LR:0.01

2023-02-06 12:03:30 | Train | Epoch[332/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[003/030] Train loss: 0.0172
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[005/030] Train loss: 0.0188
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[006/030] Train loss: 0.0189
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[007/030] Train loss: 0.0189
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[008/030] Train loss: 0.0186
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[009/030] Train loss: 0.0187
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[010/030] Train loss: 0.0185
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[011/030] Train loss: 0.0187
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[012/030] Train loss: 0.0188
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[013/030] Train loss: 0.0189
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[014/030] Train loss: 0.0192
2023-02-06 12:03:31 | Train | Epoch[332/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[017/030] Train loss: 0.0193
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[018/030] Train loss: 0.0192
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[019/030] Train loss: 0.0192
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[022/030] Train loss: 0.0196
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[024/030] Train loss: 0.0195
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[025/030] Train loss: 0.0194
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[026/030] Train loss: 0.0193
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[027/030] Train loss: 0.0193
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[028/030] Train loss: 0.0193
2023-02-06 12:03:32 | Train | Epoch[332/600] Iteration[029/030] Train loss: 0.0192
2023-02-06 12:03:33 | Train | Epoch[332/600] Iteration[030/030] Train loss: 0.0192
2023-02-06 12:03:33 | Valid | Epoch[332/600] Iteration[001/008] Valid loss: 0.0691
2023-02-06 12:03:33 | Valid | Epoch[332/600] Iteration[002/008] Valid loss: 0.0509
2023-02-06 12:03:33 | Valid | Epoch[332/600] Iteration[003/008] Valid loss: 0.0565
2023-02-06 12:03:33 | Valid | Epoch[332/600] Iteration[004/008] Valid loss: 0.0498
2023-02-06 12:03:33 | Valid | Epoch[332/600] Iteration[005/008] Valid loss: 0.0477
2023-02-06 12:03:33 | Valid | Epoch[332/600] Iteration[006/008] Valid loss: 0.0452
2023-02-06 12:03:33 | Valid | Epoch[332/600] Iteration[007/008] Valid loss: 0.0453
2023-02-06 12:03:33 | Valid | Epoch[332/600] Iteration[008/008] Valid loss: 0.0440
2023-02-06 12:03:33 | Valid | Epoch[332/600] MIou: 0.9095949404621821
2023-02-06 12:03:33 | Valid | Epoch[332/600] Pixel Accuracy: 0.9849637349446615
2023-02-06 12:03:33 | Valid | Epoch[332/600] Mean Pixel Accuracy: 0.922098028827219
2023-02-06 12:03:33 | Stage | Epoch[332/600] Train loss:0.0192
2023-02-06 12:03:33 | Stage | Epoch[332/600] Valid loss:0.0440
2023-02-06 12:03:33 | Stage | Epoch[332/600] LR:0.01

2023-02-06 12:03:33 | Train | Epoch[333/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[002/030] Train loss: 0.0171
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[007/030] Train loss: 0.0182
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[008/030] Train loss: 0.0180
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[009/030] Train loss: 0.0180
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[010/030] Train loss: 0.0182
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[011/030] Train loss: 0.0182
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[013/030] Train loss: 0.0179
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[014/030] Train loss: 0.0181
2023-02-06 12:03:34 | Train | Epoch[333/600] Iteration[015/030] Train loss: 0.0181
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[016/030] Train loss: 0.0181
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[017/030] Train loss: 0.0182
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[019/030] Train loss: 0.0183
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[021/030] Train loss: 0.0185
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[022/030] Train loss: 0.0185
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[023/030] Train loss: 0.0186
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[024/030] Train loss: 0.0186
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[025/030] Train loss: 0.0185
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[028/030] Train loss: 0.0183
2023-02-06 12:03:35 | Train | Epoch[333/600] Iteration[029/030] Train loss: 0.0186
2023-02-06 12:03:36 | Train | Epoch[333/600] Iteration[030/030] Train loss: 0.0185
2023-02-06 12:03:36 | Valid | Epoch[333/600] Iteration[001/008] Valid loss: 0.0964
2023-02-06 12:03:36 | Valid | Epoch[333/600] Iteration[002/008] Valid loss: 0.0647
2023-02-06 12:03:36 | Valid | Epoch[333/600] Iteration[003/008] Valid loss: 0.0605
2023-02-06 12:03:36 | Valid | Epoch[333/600] Iteration[004/008] Valid loss: 0.0546
2023-02-06 12:03:36 | Valid | Epoch[333/600] Iteration[005/008] Valid loss: 0.0515
2023-02-06 12:03:36 | Valid | Epoch[333/600] Iteration[006/008] Valid loss: 0.0487
2023-02-06 12:03:36 | Valid | Epoch[333/600] Iteration[007/008] Valid loss: 0.0518
2023-02-06 12:03:36 | Valid | Epoch[333/600] Iteration[008/008] Valid loss: 0.0498
2023-02-06 12:03:36 | Valid | Epoch[333/600] MIou: 0.9350206130921099
2023-02-06 12:03:36 | Valid | Epoch[333/600] Pixel Accuracy: 0.989007314046224
2023-02-06 12:03:36 | Valid | Epoch[333/600] Mean Pixel Accuracy: 0.9533789332957772
2023-02-06 12:03:36 | Stage | Epoch[333/600] Train loss:0.0185
2023-02-06 12:03:36 | Stage | Epoch[333/600] Valid loss:0.0498
2023-02-06 12:03:36 | Stage | Epoch[333/600] LR:0.01

2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[004/030] Train loss: 0.0186
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[005/030] Train loss: 0.0184
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[006/030] Train loss: 0.0182
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[008/030] Train loss: 0.0189
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[009/030] Train loss: 0.0188
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[010/030] Train loss: 0.0190
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[011/030] Train loss: 0.0189
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[012/030] Train loss: 0.0187
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[013/030] Train loss: 0.0187
2023-02-06 12:03:37 | Train | Epoch[334/600] Iteration[014/030] Train loss: 0.0186
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[015/030] Train loss: 0.0185
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[017/030] Train loss: 0.0185
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[018/030] Train loss: 0.0184
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[019/030] Train loss: 0.0183
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[022/030] Train loss: 0.0183
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[025/030] Train loss: 0.0184
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[026/030] Train loss: 0.0185
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[027/030] Train loss: 0.0184
2023-02-06 12:03:38 | Train | Epoch[334/600] Iteration[028/030] Train loss: 0.0183
2023-02-06 12:03:39 | Train | Epoch[334/600] Iteration[029/030] Train loss: 0.0183
2023-02-06 12:03:39 | Train | Epoch[334/600] Iteration[030/030] Train loss: 0.0183
2023-02-06 12:03:39 | Valid | Epoch[334/600] Iteration[001/008] Valid loss: 0.0595
2023-02-06 12:03:39 | Valid | Epoch[334/600] Iteration[002/008] Valid loss: 0.0458
2023-02-06 12:03:39 | Valid | Epoch[334/600] Iteration[003/008] Valid loss: 0.0462
2023-02-06 12:03:39 | Valid | Epoch[334/600] Iteration[004/008] Valid loss: 0.0422
2023-02-06 12:03:39 | Valid | Epoch[334/600] Iteration[005/008] Valid loss: 0.0415
2023-02-06 12:03:39 | Valid | Epoch[334/600] Iteration[006/008] Valid loss: 0.0397
2023-02-06 12:03:39 | Valid | Epoch[334/600] Iteration[007/008] Valid loss: 0.0402
2023-02-06 12:03:39 | Valid | Epoch[334/600] Iteration[008/008] Valid loss: 0.0395
2023-02-06 12:03:39 | Valid | Epoch[334/600] MIou: 0.9076287281591999
2023-02-06 12:03:39 | Valid | Epoch[334/600] Pixel Accuracy: 0.9846267700195312
2023-02-06 12:03:39 | Valid | Epoch[334/600] Mean Pixel Accuracy: 0.9205432766865518
2023-02-06 12:03:39 | Stage | Epoch[334/600] Train loss:0.0183
2023-02-06 12:03:39 | Stage | Epoch[334/600] Valid loss:0.0395
2023-02-06 12:03:39 | Stage | Epoch[334/600] LR:0.01

2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[002/030] Train loss: 0.0178
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[005/030] Train loss: 0.0175
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[006/030] Train loss: 0.0177
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[007/030] Train loss: 0.0180
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[008/030] Train loss: 0.0180
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[009/030] Train loss: 0.0178
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[010/030] Train loss: 0.0176
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[011/030] Train loss: 0.0177
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 12:03:40 | Train | Epoch[335/600] Iteration[013/030] Train loss: 0.0180
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[015/030] Train loss: 0.0180
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[016/030] Train loss: 0.0179
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[017/030] Train loss: 0.0178
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[018/030] Train loss: 0.0178
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[019/030] Train loss: 0.0177
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[020/030] Train loss: 0.0177
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[021/030] Train loss: 0.0178
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[022/030] Train loss: 0.0180
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[023/030] Train loss: 0.0183
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[024/030] Train loss: 0.0182
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[025/030] Train loss: 0.0181
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[026/030] Train loss: 0.0181
2023-02-06 12:03:41 | Train | Epoch[335/600] Iteration[027/030] Train loss: 0.0181
2023-02-06 12:03:42 | Train | Epoch[335/600] Iteration[028/030] Train loss: 0.0182
2023-02-06 12:03:42 | Train | Epoch[335/600] Iteration[029/030] Train loss: 0.0183
2023-02-06 12:03:42 | Train | Epoch[335/600] Iteration[030/030] Train loss: 0.0183
2023-02-06 12:03:42 | Valid | Epoch[335/600] Iteration[001/008] Valid loss: 1.7872
2023-02-06 12:03:42 | Valid | Epoch[335/600] Iteration[002/008] Valid loss: 1.7344
2023-02-06 12:03:42 | Valid | Epoch[335/600] Iteration[003/008] Valid loss: 1.7691
2023-02-06 12:03:42 | Valid | Epoch[335/600] Iteration[004/008] Valid loss: 1.8462
2023-02-06 12:03:42 | Valid | Epoch[335/600] Iteration[005/008] Valid loss: 1.8973
2023-02-06 12:03:42 | Valid | Epoch[335/600] Iteration[006/008] Valid loss: 1.8769
2023-02-06 12:03:42 | Valid | Epoch[335/600] Iteration[007/008] Valid loss: 1.9374
2023-02-06 12:03:42 | Valid | Epoch[335/600] Iteration[008/008] Valid loss: 1.9940
2023-02-06 12:03:42 | Valid | Epoch[335/600] MIou: 0.80830103220898
2023-02-06 12:03:42 | Valid | Epoch[335/600] Pixel Accuracy: 0.9548390706380209
2023-02-06 12:03:42 | Valid | Epoch[335/600] Mean Pixel Accuracy: 0.9743280039729845
2023-02-06 12:03:42 | Stage | Epoch[335/600] Train loss:0.0183
2023-02-06 12:03:42 | Stage | Epoch[335/600] Valid loss:1.9940
2023-02-06 12:03:42 | Stage | Epoch[335/600] LR:0.01

2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[001/030] Train loss: 0.0181
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[005/030] Train loss: 0.0178
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[006/030] Train loss: 0.0182
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[007/030] Train loss: 0.0180
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[008/030] Train loss: 0.0182
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[009/030] Train loss: 0.0183
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[010/030] Train loss: 0.0184
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[011/030] Train loss: 0.0184
2023-02-06 12:03:43 | Train | Epoch[336/600] Iteration[012/030] Train loss: 0.0183
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[013/030] Train loss: 0.0181
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[014/030] Train loss: 0.0182
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[015/030] Train loss: 0.0181
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[016/030] Train loss: 0.0182
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[017/030] Train loss: 0.0183
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[021/030] Train loss: 0.0182
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[024/030] Train loss: 0.0182
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[025/030] Train loss: 0.0184
2023-02-06 12:03:44 | Train | Epoch[336/600] Iteration[026/030] Train loss: 0.0184
2023-02-06 12:03:45 | Train | Epoch[336/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 12:03:45 | Train | Epoch[336/600] Iteration[028/030] Train loss: 0.0184
2023-02-06 12:03:45 | Train | Epoch[336/600] Iteration[029/030] Train loss: 0.0185
2023-02-06 12:03:45 | Train | Epoch[336/600] Iteration[030/030] Train loss: 0.0185
2023-02-06 12:03:45 | Valid | Epoch[336/600] Iteration[001/008] Valid loss: 2.1959
2023-02-06 12:03:45 | Valid | Epoch[336/600] Iteration[002/008] Valid loss: 2.1107
2023-02-06 12:03:45 | Valid | Epoch[336/600] Iteration[003/008] Valid loss: 2.1696
2023-02-06 12:03:45 | Valid | Epoch[336/600] Iteration[004/008] Valid loss: 2.2684
2023-02-06 12:03:45 | Valid | Epoch[336/600] Iteration[005/008] Valid loss: 2.3342
2023-02-06 12:03:45 | Valid | Epoch[336/600] Iteration[006/008] Valid loss: 2.2868
2023-02-06 12:03:45 | Valid | Epoch[336/600] Iteration[007/008] Valid loss: 2.3481
2023-02-06 12:03:45 | Valid | Epoch[336/600] Iteration[008/008] Valid loss: 2.4218
2023-02-06 12:03:45 | Valid | Epoch[336/600] MIou: 0.7955844916191066
2023-02-06 12:03:45 | Valid | Epoch[336/600] Pixel Accuracy: 0.9504915873209635
2023-02-06 12:03:45 | Valid | Epoch[336/600] Mean Pixel Accuracy: 0.972109634457077
2023-02-06 12:03:45 | Stage | Epoch[336/600] Train loss:0.0185
2023-02-06 12:03:45 | Stage | Epoch[336/600] Valid loss:2.4218
2023-02-06 12:03:45 | Stage | Epoch[336/600] LR:0.01

2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[001/030] Train loss: 0.0148
2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[003/030] Train loss: 0.0179
2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[005/030] Train loss: 0.0179
2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[006/030] Train loss: 0.0183
2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[008/030] Train loss: 0.0179
2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[009/030] Train loss: 0.0183
2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[010/030] Train loss: 0.0185
2023-02-06 12:03:46 | Train | Epoch[337/600] Iteration[011/030] Train loss: 0.0185
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[012/030] Train loss: 0.0187
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[013/030] Train loss: 0.0188
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[014/030] Train loss: 0.0188
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[015/030] Train loss: 0.0186
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[016/030] Train loss: 0.0186
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[017/030] Train loss: 0.0186
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[019/030] Train loss: 0.0185
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[021/030] Train loss: 0.0184
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[022/030] Train loss: 0.0184
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[023/030] Train loss: 0.0183
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:03:47 | Train | Epoch[337/600] Iteration[025/030] Train loss: 0.0183
2023-02-06 12:03:48 | Train | Epoch[337/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:03:48 | Train | Epoch[337/600] Iteration[027/030] Train loss: 0.0184
2023-02-06 12:03:48 | Train | Epoch[337/600] Iteration[028/030] Train loss: 0.0184
2023-02-06 12:03:48 | Train | Epoch[337/600] Iteration[029/030] Train loss: 0.0185
2023-02-06 12:03:48 | Train | Epoch[337/600] Iteration[030/030] Train loss: 0.0184
2023-02-06 12:03:48 | Valid | Epoch[337/600] Iteration[001/008] Valid loss: 0.1338
2023-02-06 12:03:48 | Valid | Epoch[337/600] Iteration[002/008] Valid loss: 0.1367
2023-02-06 12:03:48 | Valid | Epoch[337/600] Iteration[003/008] Valid loss: 0.1460
2023-02-06 12:03:48 | Valid | Epoch[337/600] Iteration[004/008] Valid loss: 0.1429
2023-02-06 12:03:48 | Valid | Epoch[337/600] Iteration[005/008] Valid loss: 0.1460
2023-02-06 12:03:48 | Valid | Epoch[337/600] Iteration[006/008] Valid loss: 0.1432
2023-02-06 12:03:48 | Valid | Epoch[337/600] Iteration[007/008] Valid loss: 0.1398
2023-02-06 12:03:48 | Valid | Epoch[337/600] Iteration[008/008] Valid loss: 0.1456
2023-02-06 12:03:48 | Valid | Epoch[337/600] MIou: 0.6182067971309336
2023-02-06 12:03:48 | Valid | Epoch[337/600] Pixel Accuracy: 0.9368934631347656
2023-02-06 12:03:48 | Valid | Epoch[337/600] Mean Pixel Accuracy: 0.6506426952371567
2023-02-06 12:03:48 | Stage | Epoch[337/600] Train loss:0.0184
2023-02-06 12:03:48 | Stage | Epoch[337/600] Valid loss:0.1456
2023-02-06 12:03:48 | Stage | Epoch[337/600] LR:0.01

2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[006/030] Train loss: 0.0176
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[007/030] Train loss: 0.0175
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[008/030] Train loss: 0.0178
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[009/030] Train loss: 0.0173
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[010/030] Train loss: 0.0175
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[011/030] Train loss: 0.0174
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 12:03:49 | Train | Epoch[338/600] Iteration[013/030] Train loss: 0.0180
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[015/030] Train loss: 0.0181
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[016/030] Train loss: 0.0181
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[019/030] Train loss: 0.0183
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[020/030] Train loss: 0.0185
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[021/030] Train loss: 0.0185
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[022/030] Train loss: 0.0185
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[023/030] Train loss: 0.0185
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[024/030] Train loss: 0.0185
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[025/030] Train loss: 0.0185
2023-02-06 12:03:50 | Train | Epoch[338/600] Iteration[026/030] Train loss: 0.0184
2023-02-06 12:03:51 | Train | Epoch[338/600] Iteration[027/030] Train loss: 0.0184
2023-02-06 12:03:51 | Train | Epoch[338/600] Iteration[028/030] Train loss: 0.0184
2023-02-06 12:03:51 | Train | Epoch[338/600] Iteration[029/030] Train loss: 0.0184
2023-02-06 12:03:51 | Train | Epoch[338/600] Iteration[030/030] Train loss: 0.0183
2023-02-06 12:03:51 | Valid | Epoch[338/600] Iteration[001/008] Valid loss: 0.1159
2023-02-06 12:03:51 | Valid | Epoch[338/600] Iteration[002/008] Valid loss: 0.0775
2023-02-06 12:03:51 | Valid | Epoch[338/600] Iteration[003/008] Valid loss: 0.0709
2023-02-06 12:03:51 | Valid | Epoch[338/600] Iteration[004/008] Valid loss: 0.0654
2023-02-06 12:03:51 | Valid | Epoch[338/600] Iteration[005/008] Valid loss: 0.0613
2023-02-06 12:03:51 | Valid | Epoch[338/600] Iteration[006/008] Valid loss: 0.0566
2023-02-06 12:03:51 | Valid | Epoch[338/600] Iteration[007/008] Valid loss: 0.0615
2023-02-06 12:03:51 | Valid | Epoch[338/600] Iteration[008/008] Valid loss: 0.0596
2023-02-06 12:03:51 | Valid | Epoch[338/600] MIou: 0.928776427098861
2023-02-06 12:03:51 | Valid | Epoch[338/600] Pixel Accuracy: 0.987951914469401
2023-02-06 12:03:51 | Valid | Epoch[338/600] Mean Pixel Accuracy: 0.9474411422489446
2023-02-06 12:03:51 | Stage | Epoch[338/600] Train loss:0.0183
2023-02-06 12:03:51 | Stage | Epoch[338/600] Valid loss:0.0596
2023-02-06 12:03:51 | Stage | Epoch[338/600] LR:0.01

2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[001/030] Train loss: 0.0170
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[003/030] Train loss: 0.0175
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[006/030] Train loss: 0.0175
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[008/030] Train loss: 0.0179
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[009/030] Train loss: 0.0179
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[011/030] Train loss: 0.0182
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 12:03:52 | Train | Epoch[339/600] Iteration[013/030] Train loss: 0.0179
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[014/030] Train loss: 0.0181
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[017/030] Train loss: 0.0182
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[018/030] Train loss: 0.0183
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[019/030] Train loss: 0.0183
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[020/030] Train loss: 0.0183
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[021/030] Train loss: 0.0185
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[022/030] Train loss: 0.0184
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[023/030] Train loss: 0.0184
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[024/030] Train loss: 0.0184
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[025/030] Train loss: 0.0182
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[026/030] Train loss: 0.0182
2023-02-06 12:03:53 | Train | Epoch[339/600] Iteration[027/030] Train loss: 0.0182
2023-02-06 12:03:54 | Train | Epoch[339/600] Iteration[028/030] Train loss: 0.0181
2023-02-06 12:03:54 | Train | Epoch[339/600] Iteration[029/030] Train loss: 0.0181
2023-02-06 12:03:54 | Train | Epoch[339/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 12:03:54 | Valid | Epoch[339/600] Iteration[001/008] Valid loss: 0.0816
2023-02-06 12:03:54 | Valid | Epoch[339/600] Iteration[002/008] Valid loss: 0.0828
2023-02-06 12:03:54 | Valid | Epoch[339/600] Iteration[003/008] Valid loss: 0.0872
2023-02-06 12:03:54 | Valid | Epoch[339/600] Iteration[004/008] Valid loss: 0.0849
2023-02-06 12:03:54 | Valid | Epoch[339/600] Iteration[005/008] Valid loss: 0.0857
2023-02-06 12:03:54 | Valid | Epoch[339/600] Iteration[006/008] Valid loss: 0.0844
2023-02-06 12:03:54 | Valid | Epoch[339/600] Iteration[007/008] Valid loss: 0.0825
2023-02-06 12:03:54 | Valid | Epoch[339/600] Iteration[008/008] Valid loss: 0.0851
2023-02-06 12:03:54 | Valid | Epoch[339/600] MIou: 0.7511461122041645
2023-02-06 12:03:54 | Valid | Epoch[339/600] Pixel Accuracy: 0.9589436848958334
2023-02-06 12:03:54 | Valid | Epoch[339/600] Mean Pixel Accuracy: 0.772763277799325
2023-02-06 12:03:54 | Stage | Epoch[339/600] Train loss:0.0180
2023-02-06 12:03:54 | Stage | Epoch[339/600] Valid loss:0.0851
2023-02-06 12:03:54 | Stage | Epoch[339/600] LR:0.01

2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[001/030] Train loss: 0.0159
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[002/030] Train loss: 0.0161
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[004/030] Train loss: 0.0163
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[007/030] Train loss: 0.0169
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[008/030] Train loss: 0.0176
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[009/030] Train loss: 0.0174
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[010/030] Train loss: 0.0177
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[011/030] Train loss: 0.0175
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[012/030] Train loss: 0.0175
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[013/030] Train loss: 0.0175
2023-02-06 12:03:55 | Train | Epoch[340/600] Iteration[014/030] Train loss: 0.0177
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[015/030] Train loss: 0.0176
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[016/030] Train loss: 0.0176
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[017/030] Train loss: 0.0177
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[018/030] Train loss: 0.0177
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[019/030] Train loss: 0.0179
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[020/030] Train loss: 0.0178
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[021/030] Train loss: 0.0178
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[022/030] Train loss: 0.0178
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[023/030] Train loss: 0.0180
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[024/030] Train loss: 0.0181
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[025/030] Train loss: 0.0181
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[026/030] Train loss: 0.0181
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[027/030] Train loss: 0.0180
2023-02-06 12:03:56 | Train | Epoch[340/600] Iteration[028/030] Train loss: 0.0180
2023-02-06 12:03:57 | Train | Epoch[340/600] Iteration[029/030] Train loss: 0.0182
2023-02-06 12:03:57 | Train | Epoch[340/600] Iteration[030/030] Train loss: 0.0181
2023-02-06 12:03:57 | Valid | Epoch[340/600] Iteration[001/008] Valid loss: 0.1648
2023-02-06 12:03:57 | Valid | Epoch[340/600] Iteration[002/008] Valid loss: 0.1450
2023-02-06 12:03:57 | Valid | Epoch[340/600] Iteration[003/008] Valid loss: 0.1299
2023-02-06 12:03:57 | Valid | Epoch[340/600] Iteration[004/008] Valid loss: 0.1285
2023-02-06 12:03:57 | Valid | Epoch[340/600] Iteration[005/008] Valid loss: 0.1219
2023-02-06 12:03:57 | Valid | Epoch[340/600] Iteration[006/008] Valid loss: 0.1204
2023-02-06 12:03:57 | Valid | Epoch[340/600] Iteration[007/008] Valid loss: 0.1224
2023-02-06 12:03:57 | Valid | Epoch[340/600] Iteration[008/008] Valid loss: 0.1208
2023-02-06 12:03:57 | Valid | Epoch[340/600] MIou: 0.926781134173996
2023-02-06 12:03:57 | Valid | Epoch[340/600] Pixel Accuracy: 0.9871292114257812
2023-02-06 12:03:57 | Valid | Epoch[340/600] Mean Pixel Accuracy: 0.9631888542820988
2023-02-06 12:03:57 | Stage | Epoch[340/600] Train loss:0.0181
2023-02-06 12:03:57 | Stage | Epoch[340/600] Valid loss:0.1208
2023-02-06 12:03:57 | Stage | Epoch[340/600] LR:0.01

2023-02-06 12:03:57 | Train | Epoch[341/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[002/030] Train loss: 0.0168
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[003/030] Train loss: 0.0168
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[005/030] Train loss: 0.0178
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[006/030] Train loss: 0.0176
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[007/030] Train loss: 0.0180
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[009/030] Train loss: 0.0180
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[010/030] Train loss: 0.0177
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[011/030] Train loss: 0.0178
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[013/030] Train loss: 0.0181
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[014/030] Train loss: 0.0181
2023-02-06 12:03:58 | Train | Epoch[341/600] Iteration[015/030] Train loss: 0.0181
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[017/030] Train loss: 0.0183
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[018/030] Train loss: 0.0183
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[020/030] Train loss: 0.0182
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[021/030] Train loss: 0.0181
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[025/030] Train loss: 0.0182
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[026/030] Train loss: 0.0182
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[027/030] Train loss: 0.0181
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[028/030] Train loss: 0.0182
2023-02-06 12:03:59 | Train | Epoch[341/600] Iteration[029/030] Train loss: 0.0182
2023-02-06 12:04:00 | Train | Epoch[341/600] Iteration[030/030] Train loss: 0.0182
2023-02-06 12:04:00 | Valid | Epoch[341/600] Iteration[001/008] Valid loss: 0.1232
2023-02-06 12:04:00 | Valid | Epoch[341/600] Iteration[002/008] Valid loss: 0.0841
2023-02-06 12:04:00 | Valid | Epoch[341/600] Iteration[003/008] Valid loss: 0.0826
2023-02-06 12:04:00 | Valid | Epoch[341/600] Iteration[004/008] Valid loss: 0.0786
2023-02-06 12:04:00 | Valid | Epoch[341/600] Iteration[005/008] Valid loss: 0.0760
2023-02-06 12:04:00 | Valid | Epoch[341/600] Iteration[006/008] Valid loss: 0.0712
2023-02-06 12:04:00 | Valid | Epoch[341/600] Iteration[007/008] Valid loss: 0.0803
2023-02-06 12:04:00 | Valid | Epoch[341/600] Iteration[008/008] Valid loss: 0.0777
2023-02-06 12:04:00 | Valid | Epoch[341/600] MIou: 0.9355583743907081
2023-02-06 12:04:00 | Valid | Epoch[341/600] Pixel Accuracy: 0.9889170328776041
2023-02-06 12:04:00 | Valid | Epoch[341/600] Mean Pixel Accuracy: 0.9614894977511517
2023-02-06 12:04:00 | Stage | Epoch[341/600] Train loss:0.0182
2023-02-06 12:04:00 | Stage | Epoch[341/600] Valid loss:0.0777
2023-02-06 12:04:00 | Stage | Epoch[341/600] LR:0.01

2023-02-06 12:04:00 | Train | Epoch[342/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 12:04:00 | Train | Epoch[342/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[003/030] Train loss: 0.0193
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[007/030] Train loss: 0.0178
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[008/030] Train loss: 0.0175
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[009/030] Train loss: 0.0175
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[010/030] Train loss: 0.0176
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[011/030] Train loss: 0.0178
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[013/030] Train loss: 0.0178
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:04:01 | Train | Epoch[342/600] Iteration[015/030] Train loss: 0.0180
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[016/030] Train loss: 0.0179
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[017/030] Train loss: 0.0179
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[018/030] Train loss: 0.0179
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[019/030] Train loss: 0.0180
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[020/030] Train loss: 0.0180
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[021/030] Train loss: 0.0179
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[022/030] Train loss: 0.0179
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[023/030] Train loss: 0.0180
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[024/030] Train loss: 0.0180
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[025/030] Train loss: 0.0182
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[026/030] Train loss: 0.0181
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[027/030] Train loss: 0.0181
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[028/030] Train loss: 0.0181
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[029/030] Train loss: 0.0181
2023-02-06 12:04:02 | Train | Epoch[342/600] Iteration[030/030] Train loss: 0.0181
2023-02-06 12:04:03 | Valid | Epoch[342/600] Iteration[001/008] Valid loss: 0.3463
2023-02-06 12:04:03 | Valid | Epoch[342/600] Iteration[002/008] Valid loss: 0.2906
2023-02-06 12:04:03 | Valid | Epoch[342/600] Iteration[003/008] Valid loss: 0.2886
2023-02-06 12:04:03 | Valid | Epoch[342/600] Iteration[004/008] Valid loss: 0.2892
2023-02-06 12:04:03 | Valid | Epoch[342/600] Iteration[005/008] Valid loss: 0.2982
2023-02-06 12:04:03 | Valid | Epoch[342/600] Iteration[006/008] Valid loss: 0.2870
2023-02-06 12:04:03 | Valid | Epoch[342/600] Iteration[007/008] Valid loss: 0.3100
2023-02-06 12:04:03 | Valid | Epoch[342/600] Iteration[008/008] Valid loss: 0.3010
2023-02-06 12:04:03 | Valid | Epoch[342/600] MIou: 0.9189346768253566
2023-02-06 12:04:03 | Valid | Epoch[342/600] Pixel Accuracy: 0.984869639078776
2023-02-06 12:04:03 | Valid | Epoch[342/600] Mean Pixel Accuracy: 0.9843160804463725
2023-02-06 12:04:03 | Stage | Epoch[342/600] Train loss:0.0181
2023-02-06 12:04:03 | Stage | Epoch[342/600] Valid loss:0.3010
2023-02-06 12:04:03 | Stage | Epoch[342/600] LR:0.01

2023-02-06 12:04:03 | Train | Epoch[343/600] Iteration[001/030] Train loss: 0.0174
2023-02-06 12:04:03 | Train | Epoch[343/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[007/030] Train loss: 0.0192
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[009/030] Train loss: 0.0189
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[010/030] Train loss: 0.0189
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[011/030] Train loss: 0.0192
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 12:04:04 | Train | Epoch[343/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[017/030] Train loss: 0.0193
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[018/030] Train loss: 0.0192
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[019/030] Train loss: 0.0190
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[020/030] Train loss: 0.0188
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[021/030] Train loss: 0.0187
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[022/030] Train loss: 0.0190
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[023/030] Train loss: 0.0191
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[024/030] Train loss: 0.0190
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[025/030] Train loss: 0.0189
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[027/030] Train loss: 0.0189
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[028/030] Train loss: 0.0189
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[029/030] Train loss: 0.0188
2023-02-06 12:04:05 | Train | Epoch[343/600] Iteration[030/030] Train loss: 0.0187
2023-02-06 12:04:06 | Valid | Epoch[343/600] Iteration[001/008] Valid loss: 0.0562
2023-02-06 12:04:06 | Valid | Epoch[343/600] Iteration[002/008] Valid loss: 0.0546
2023-02-06 12:04:06 | Valid | Epoch[343/600] Iteration[003/008] Valid loss: 0.0624
2023-02-06 12:04:06 | Valid | Epoch[343/600] Iteration[004/008] Valid loss: 0.0588
2023-02-06 12:04:06 | Valid | Epoch[343/600] Iteration[005/008] Valid loss: 0.0596
2023-02-06 12:04:06 | Valid | Epoch[343/600] Iteration[006/008] Valid loss: 0.0583
2023-02-06 12:04:06 | Valid | Epoch[343/600] Iteration[007/008] Valid loss: 0.0568
2023-02-06 12:04:06 | Valid | Epoch[343/600] Iteration[008/008] Valid loss: 0.0581
2023-02-06 12:04:06 | Valid | Epoch[343/600] MIou: 0.8195099288376859
2023-02-06 12:04:06 | Valid | Epoch[343/600] Pixel Accuracy: 0.9702110290527344
2023-02-06 12:04:06 | Valid | Epoch[343/600] Mean Pixel Accuracy: 0.8358493415664556
2023-02-06 12:04:06 | Stage | Epoch[343/600] Train loss:0.0187
2023-02-06 12:04:06 | Stage | Epoch[343/600] Valid loss:0.0581
2023-02-06 12:04:06 | Stage | Epoch[343/600] LR:0.01

2023-02-06 12:04:06 | Train | Epoch[344/600] Iteration[001/030] Train loss: 0.0195
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[003/030] Train loss: 0.0196
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[004/030] Train loss: 0.0186
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[005/030] Train loss: 0.0180
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[008/030] Train loss: 0.0178
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[009/030] Train loss: 0.0176
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[011/030] Train loss: 0.0181
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[012/030] Train loss: 0.0184
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[013/030] Train loss: 0.0185
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 12:04:07 | Train | Epoch[344/600] Iteration[015/030] Train loss: 0.0188
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[016/030] Train loss: 0.0188
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[017/030] Train loss: 0.0188
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[018/030] Train loss: 0.0186
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[019/030] Train loss: 0.0186
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[020/030] Train loss: 0.0187
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[021/030] Train loss: 0.0188
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[022/030] Train loss: 0.0189
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[023/030] Train loss: 0.0187
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[024/030] Train loss: 0.0187
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[025/030] Train loss: 0.0187
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[026/030] Train loss: 0.0188
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[027/030] Train loss: 0.0189
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[028/030] Train loss: 0.0189
2023-02-06 12:04:08 | Train | Epoch[344/600] Iteration[029/030] Train loss: 0.0189
2023-02-06 12:04:09 | Train | Epoch[344/600] Iteration[030/030] Train loss: 0.0189
2023-02-06 12:04:09 | Valid | Epoch[344/600] Iteration[001/008] Valid loss: 0.0720
2023-02-06 12:04:09 | Valid | Epoch[344/600] Iteration[002/008] Valid loss: 0.0696
2023-02-06 12:04:09 | Valid | Epoch[344/600] Iteration[003/008] Valid loss: 0.0746
2023-02-06 12:04:09 | Valid | Epoch[344/600] Iteration[004/008] Valid loss: 0.0720
2023-02-06 12:04:09 | Valid | Epoch[344/600] Iteration[005/008] Valid loss: 0.0737
2023-02-06 12:04:09 | Valid | Epoch[344/600] Iteration[006/008] Valid loss: 0.0721
2023-02-06 12:04:09 | Valid | Epoch[344/600] Iteration[007/008] Valid loss: 0.0704
2023-02-06 12:04:09 | Valid | Epoch[344/600] Iteration[008/008] Valid loss: 0.0736
2023-02-06 12:04:09 | Valid | Epoch[344/600] MIou: 0.7696571664456353
2023-02-06 12:04:09 | Valid | Epoch[344/600] Pixel Accuracy: 0.9619267781575521
2023-02-06 12:04:09 | Valid | Epoch[344/600] Mean Pixel Accuracy: 0.7903428584631846
2023-02-06 12:04:09 | Stage | Epoch[344/600] Train loss:0.0189
2023-02-06 12:04:09 | Stage | Epoch[344/600] Valid loss:0.0736
2023-02-06 12:04:09 | Stage | Epoch[344/600] LR:0.01

2023-02-06 12:04:09 | Train | Epoch[345/600] Iteration[001/030] Train loss: 0.0151
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[002/030] Train loss: 0.0160
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[012/030] Train loss: 0.0172
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[013/030] Train loss: 0.0177
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[014/030] Train loss: 0.0181
2023-02-06 12:04:10 | Train | Epoch[345/600] Iteration[015/030] Train loss: 0.0180
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[016/030] Train loss: 0.0180
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[017/030] Train loss: 0.0183
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[020/030] Train loss: 0.0186
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[021/030] Train loss: 0.0186
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[022/030] Train loss: 0.0185
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[023/030] Train loss: 0.0183
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[025/030] Train loss: 0.0183
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[026/030] Train loss: 0.0184
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[027/030] Train loss: 0.0184
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[028/030] Train loss: 0.0185
2023-02-06 12:04:11 | Train | Epoch[345/600] Iteration[029/030] Train loss: 0.0185
2023-02-06 12:04:12 | Train | Epoch[345/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:04:12 | Valid | Epoch[345/600] Iteration[001/008] Valid loss: 0.0721
2023-02-06 12:04:12 | Valid | Epoch[345/600] Iteration[002/008] Valid loss: 0.0543
2023-02-06 12:04:12 | Valid | Epoch[345/600] Iteration[003/008] Valid loss: 0.0520
2023-02-06 12:04:12 | Valid | Epoch[345/600] Iteration[004/008] Valid loss: 0.0473
2023-02-06 12:04:12 | Valid | Epoch[345/600] Iteration[005/008] Valid loss: 0.0454
2023-02-06 12:04:12 | Valid | Epoch[345/600] Iteration[006/008] Valid loss: 0.0431
2023-02-06 12:04:12 | Valid | Epoch[345/600] Iteration[007/008] Valid loss: 0.0443
2023-02-06 12:04:12 | Valid | Epoch[345/600] Iteration[008/008] Valid loss: 0.0425
2023-02-06 12:04:12 | Valid | Epoch[345/600] MIou: 0.9275358409858929
2023-02-06 12:04:12 | Valid | Epoch[345/600] Pixel Accuracy: 0.9878616333007812
2023-02-06 12:04:12 | Valid | Epoch[345/600] Mean Pixel Accuracy: 0.9419006715388113
2023-02-06 12:04:12 | Stage | Epoch[345/600] Train loss:0.0186
2023-02-06 12:04:12 | Stage | Epoch[345/600] Valid loss:0.0425
2023-02-06 12:04:12 | Stage | Epoch[345/600] LR:0.01

2023-02-06 12:04:12 | Train | Epoch[346/600] Iteration[001/030] Train loss: 0.0155
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[003/030] Train loss: 0.0188
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[005/030] Train loss: 0.0190
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[006/030] Train loss: 0.0189
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[007/030] Train loss: 0.0185
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[008/030] Train loss: 0.0185
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[009/030] Train loss: 0.0184
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[011/030] Train loss: 0.0182
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[013/030] Train loss: 0.0180
2023-02-06 12:04:13 | Train | Epoch[346/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[015/030] Train loss: 0.0179
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[016/030] Train loss: 0.0178
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[017/030] Train loss: 0.0179
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[018/030] Train loss: 0.0181
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[019/030] Train loss: 0.0180
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[020/030] Train loss: 0.0181
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[021/030] Train loss: 0.0181
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[023/030] Train loss: 0.0183
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[024/030] Train loss: 0.0182
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[025/030] Train loss: 0.0183
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 12:04:14 | Train | Epoch[346/600] Iteration[028/030] Train loss: 0.0183
2023-02-06 12:04:15 | Train | Epoch[346/600] Iteration[029/030] Train loss: 0.0184
2023-02-06 12:04:15 | Train | Epoch[346/600] Iteration[030/030] Train loss: 0.0184
2023-02-06 12:04:15 | Valid | Epoch[346/600] Iteration[001/008] Valid loss: 0.1102
2023-02-06 12:04:15 | Valid | Epoch[346/600] Iteration[002/008] Valid loss: 0.0790
2023-02-06 12:04:15 | Valid | Epoch[346/600] Iteration[003/008] Valid loss: 0.0747
2023-02-06 12:04:15 | Valid | Epoch[346/600] Iteration[004/008] Valid loss: 0.0678
2023-02-06 12:04:15 | Valid | Epoch[346/600] Iteration[005/008] Valid loss: 0.0655
2023-02-06 12:04:15 | Valid | Epoch[346/600] Iteration[006/008] Valid loss: 0.0620
2023-02-06 12:04:15 | Valid | Epoch[346/600] Iteration[007/008] Valid loss: 0.0644
2023-02-06 12:04:15 | Valid | Epoch[346/600] Iteration[008/008] Valid loss: 0.0627
2023-02-06 12:04:15 | Valid | Epoch[346/600] MIou: 0.9331091314056268
2023-02-06 12:04:15 | Valid | Epoch[346/600] Pixel Accuracy: 0.9886016845703125
2023-02-06 12:04:15 | Valid | Epoch[346/600] Mean Pixel Accuracy: 0.9548742498159111
2023-02-06 12:04:15 | Stage | Epoch[346/600] Train loss:0.0184
2023-02-06 12:04:15 | Stage | Epoch[346/600] Valid loss:0.0627
2023-02-06 12:04:15 | Stage | Epoch[346/600] LR:0.01

2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[002/030] Train loss: 0.0185
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[005/030] Train loss: 0.0185
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[007/030] Train loss: 0.0190
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[008/030] Train loss: 0.0186
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[009/030] Train loss: 0.0187
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[011/030] Train loss: 0.0185
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[012/030] Train loss: 0.0184
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[013/030] Train loss: 0.0182
2023-02-06 12:04:16 | Train | Epoch[347/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[018/030] Train loss: 0.0184
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[020/030] Train loss: 0.0187
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[021/030] Train loss: 0.0187
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[022/030] Train loss: 0.0188
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[023/030] Train loss: 0.0187
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[024/030] Train loss: 0.0186
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[025/030] Train loss: 0.0186
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[026/030] Train loss: 0.0188
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[027/030] Train loss: 0.0188
2023-02-06 12:04:17 | Train | Epoch[347/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 12:04:18 | Train | Epoch[347/600] Iteration[029/030] Train loss: 0.0188
2023-02-06 12:04:18 | Train | Epoch[347/600] Iteration[030/030] Train loss: 0.0187
2023-02-06 12:04:18 | Valid | Epoch[347/600] Iteration[001/008] Valid loss: 0.1716
2023-02-06 12:04:18 | Valid | Epoch[347/600] Iteration[002/008] Valid loss: 0.1240
2023-02-06 12:04:18 | Valid | Epoch[347/600] Iteration[003/008] Valid loss: 0.1225
2023-02-06 12:04:18 | Valid | Epoch[347/600] Iteration[004/008] Valid loss: 0.1140
2023-02-06 12:04:18 | Valid | Epoch[347/600] Iteration[005/008] Valid loss: 0.1141
2023-02-06 12:04:18 | Valid | Epoch[347/600] Iteration[006/008] Valid loss: 0.1091
2023-02-06 12:04:18 | Valid | Epoch[347/600] Iteration[007/008] Valid loss: 0.1167
2023-02-06 12:04:18 | Valid | Epoch[347/600] Iteration[008/008] Valid loss: 0.1116
2023-02-06 12:04:18 | Valid | Epoch[347/600] MIou: 0.9397864460759882
2023-02-06 12:04:18 | Valid | Epoch[347/600] Pixel Accuracy: 0.9894510904947916
2023-02-06 12:04:18 | Valid | Epoch[347/600] Mean Pixel Accuracy: 0.9743435126599945
2023-02-06 12:04:18 | Stage | Epoch[347/600] Train loss:0.0187
2023-02-06 12:04:18 | Stage | Epoch[347/600] Valid loss:0.1116
2023-02-06 12:04:18 | Stage | Epoch[347/600] LR:0.01

2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[002/030] Train loss: 0.0173
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[003/030] Train loss: 0.0172
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[005/030] Train loss: 0.0179
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[007/030] Train loss: 0.0177
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[008/030] Train loss: 0.0177
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[009/030] Train loss: 0.0180
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[010/030] Train loss: 0.0181
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[011/030] Train loss: 0.0178
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:04:19 | Train | Epoch[348/600] Iteration[013/030] Train loss: 0.0179
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[014/030] Train loss: 0.0177
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[015/030] Train loss: 0.0176
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[016/030] Train loss: 0.0179
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[017/030] Train loss: 0.0179
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[018/030] Train loss: 0.0178
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[019/030] Train loss: 0.0179
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[020/030] Train loss: 0.0181
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[021/030] Train loss: 0.0181
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[022/030] Train loss: 0.0181
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[023/030] Train loss: 0.0181
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[024/030] Train loss: 0.0182
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[025/030] Train loss: 0.0182
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[026/030] Train loss: 0.0182
2023-02-06 12:04:20 | Train | Epoch[348/600] Iteration[027/030] Train loss: 0.0182
2023-02-06 12:04:21 | Train | Epoch[348/600] Iteration[028/030] Train loss: 0.0182
2023-02-06 12:04:21 | Train | Epoch[348/600] Iteration[029/030] Train loss: 0.0183
2023-02-06 12:04:21 | Train | Epoch[348/600] Iteration[030/030] Train loss: 0.0184
2023-02-06 12:04:21 | Valid | Epoch[348/600] Iteration[001/008] Valid loss: 0.1576
2023-02-06 12:04:21 | Valid | Epoch[348/600] Iteration[002/008] Valid loss: 0.1644
2023-02-06 12:04:21 | Valid | Epoch[348/600] Iteration[003/008] Valid loss: 0.1771
2023-02-06 12:04:21 | Valid | Epoch[348/600] Iteration[004/008] Valid loss: 0.1724
2023-02-06 12:04:21 | Valid | Epoch[348/600] Iteration[005/008] Valid loss: 0.1781
2023-02-06 12:04:21 | Valid | Epoch[348/600] Iteration[006/008] Valid loss: 0.1741
2023-02-06 12:04:21 | Valid | Epoch[348/600] Iteration[007/008] Valid loss: 0.1700
2023-02-06 12:04:21 | Valid | Epoch[348/600] Iteration[008/008] Valid loss: 0.1784
2023-02-06 12:04:21 | Valid | Epoch[348/600] MIou: 0.5462373758825491
2023-02-06 12:04:21 | Valid | Epoch[348/600] Pixel Accuracy: 0.9249191284179688
2023-02-06 12:04:21 | Valid | Epoch[348/600] Mean Pixel Accuracy: 0.5843592104260377
2023-02-06 12:04:21 | Stage | Epoch[348/600] Train loss:0.0184
2023-02-06 12:04:21 | Stage | Epoch[348/600] Valid loss:0.1784
2023-02-06 12:04:21 | Stage | Epoch[348/600] LR:0.01

2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[001/030] Train loss: 0.0152
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[002/030] Train loss: 0.0164
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[003/030] Train loss: 0.0180
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[005/030] Train loss: 0.0190
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[006/030] Train loss: 0.0187
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[008/030] Train loss: 0.0181
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[009/030] Train loss: 0.0178
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[010/030] Train loss: 0.0178
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[011/030] Train loss: 0.0180
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[012/030] Train loss: 0.0182
2023-02-06 12:04:22 | Train | Epoch[349/600] Iteration[013/030] Train loss: 0.0182
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[015/030] Train loss: 0.0180
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[016/030] Train loss: 0.0180
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[018/030] Train loss: 0.0181
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[019/030] Train loss: 0.0183
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[020/030] Train loss: 0.0185
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[021/030] Train loss: 0.0185
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[022/030] Train loss: 0.0184
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[023/030] Train loss: 0.0184
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[024/030] Train loss: 0.0185
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[025/030] Train loss: 0.0188
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[026/030] Train loss: 0.0188
2023-02-06 12:04:23 | Train | Epoch[349/600] Iteration[027/030] Train loss: 0.0187
2023-02-06 12:04:24 | Train | Epoch[349/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 12:04:24 | Train | Epoch[349/600] Iteration[029/030] Train loss: 0.0187
2023-02-06 12:04:24 | Train | Epoch[349/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:04:24 | Valid | Epoch[349/600] Iteration[001/008] Valid loss: 0.7494
2023-02-06 12:04:24 | Valid | Epoch[349/600] Iteration[002/008] Valid loss: 0.7196
2023-02-06 12:04:24 | Valid | Epoch[349/600] Iteration[003/008] Valid loss: 0.7304
2023-02-06 12:04:24 | Valid | Epoch[349/600] Iteration[004/008] Valid loss: 0.7536
2023-02-06 12:04:24 | Valid | Epoch[349/600] Iteration[005/008] Valid loss: 0.7742
2023-02-06 12:04:24 | Valid | Epoch[349/600] Iteration[006/008] Valid loss: 0.7506
2023-02-06 12:04:24 | Valid | Epoch[349/600] Iteration[007/008] Valid loss: 0.7888
2023-02-06 12:04:24 | Valid | Epoch[349/600] Iteration[008/008] Valid loss: 0.8147
2023-02-06 12:04:24 | Valid | Epoch[349/600] MIou: 0.8678945899316693
2023-02-06 12:04:24 | Valid | Epoch[349/600] Pixel Accuracy: 0.9726664225260416
2023-02-06 12:04:24 | Valid | Epoch[349/600] Mean Pixel Accuracy: 0.9802970320955133
2023-02-06 12:04:24 | Stage | Epoch[349/600] Train loss:0.0186
2023-02-06 12:04:24 | Stage | Epoch[349/600] Valid loss:0.8147
2023-02-06 12:04:24 | Stage | Epoch[349/600] LR:0.01

2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[001/030] Train loss: 0.0190
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[006/030] Train loss: 0.0177
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[007/030] Train loss: 0.0174
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[008/030] Train loss: 0.0175
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[009/030] Train loss: 0.0173
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[010/030] Train loss: 0.0183
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[011/030] Train loss: 0.0182
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[012/030] Train loss: 0.0182
2023-02-06 12:04:25 | Train | Epoch[350/600] Iteration[013/030] Train loss: 0.0184
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[015/030] Train loss: 0.0185
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[018/030] Train loss: 0.0183
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[019/030] Train loss: 0.0183
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[020/030] Train loss: 0.0183
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[022/030] Train loss: 0.0184
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[023/030] Train loss: 0.0184
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[024/030] Train loss: 0.0185
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[025/030] Train loss: 0.0185
2023-02-06 12:04:26 | Train | Epoch[350/600] Iteration[026/030] Train loss: 0.0185
2023-02-06 12:04:27 | Train | Epoch[350/600] Iteration[027/030] Train loss: 0.0185
2023-02-06 12:04:27 | Train | Epoch[350/600] Iteration[028/030] Train loss: 0.0187
2023-02-06 12:04:27 | Train | Epoch[350/600] Iteration[029/030] Train loss: 0.0186
2023-02-06 12:04:27 | Train | Epoch[350/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:04:27 | Valid | Epoch[350/600] Iteration[001/008] Valid loss: 0.1284
2023-02-06 12:04:27 | Valid | Epoch[350/600] Iteration[002/008] Valid loss: 0.0978
2023-02-06 12:04:27 | Valid | Epoch[350/600] Iteration[003/008] Valid loss: 0.0971
2023-02-06 12:04:27 | Valid | Epoch[350/600] Iteration[004/008] Valid loss: 0.0902
2023-02-06 12:04:27 | Valid | Epoch[350/600] Iteration[005/008] Valid loss: 0.0899
2023-02-06 12:04:27 | Valid | Epoch[350/600] Iteration[006/008] Valid loss: 0.0852
2023-02-06 12:04:27 | Valid | Epoch[350/600] Iteration[007/008] Valid loss: 0.0893
2023-02-06 12:04:27 | Valid | Epoch[350/600] Iteration[008/008] Valid loss: 0.0846
2023-02-06 12:04:27 | Valid | Epoch[350/600] MIou: 0.9411023656568538
2023-02-06 12:04:27 | Valid | Epoch[350/600] Pixel Accuracy: 0.9898579915364584
2023-02-06 12:04:27 | Valid | Epoch[350/600] Mean Pixel Accuracy: 0.9674024300177541
2023-02-06 12:04:27 | Stage | Epoch[350/600] Train loss:0.0186
2023-02-06 12:04:27 | Stage | Epoch[350/600] Valid loss:0.0846
2023-02-06 12:04:27 | Stage | Epoch[350/600] LR:0.01

2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[004/030] Train loss: 0.0185
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[005/030] Train loss: 0.0188
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[009/030] Train loss: 0.0188
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[011/030] Train loss: 0.0186
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[012/030] Train loss: 0.0186
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[013/030] Train loss: 0.0185
2023-02-06 12:04:28 | Train | Epoch[351/600] Iteration[014/030] Train loss: 0.0187
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[015/030] Train loss: 0.0186
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[016/030] Train loss: 0.0184
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[018/030] Train loss: 0.0183
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[020/030] Train loss: 0.0183
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[024/030] Train loss: 0.0181
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[025/030] Train loss: 0.0182
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[026/030] Train loss: 0.0182
2023-02-06 12:04:29 | Train | Epoch[351/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 12:04:30 | Train | Epoch[351/600] Iteration[028/030] Train loss: 0.0184
2023-02-06 12:04:30 | Train | Epoch[351/600] Iteration[029/030] Train loss: 0.0184
2023-02-06 12:04:30 | Train | Epoch[351/600] Iteration[030/030] Train loss: 0.0184
2023-02-06 12:04:30 | Valid | Epoch[351/600] Iteration[001/008] Valid loss: 0.1440
2023-02-06 12:04:30 | Valid | Epoch[351/600] Iteration[002/008] Valid loss: 0.1031
2023-02-06 12:04:30 | Valid | Epoch[351/600] Iteration[003/008] Valid loss: 0.0919
2023-02-06 12:04:30 | Valid | Epoch[351/600] Iteration[004/008] Valid loss: 0.0856
2023-02-06 12:04:30 | Valid | Epoch[351/600] Iteration[005/008] Valid loss: 0.0830
2023-02-06 12:04:30 | Valid | Epoch[351/600] Iteration[006/008] Valid loss: 0.0781
2023-02-06 12:04:30 | Valid | Epoch[351/600] Iteration[007/008] Valid loss: 0.0852
2023-02-06 12:04:30 | Valid | Epoch[351/600] Iteration[008/008] Valid loss: 0.0858
2023-02-06 12:04:30 | Valid | Epoch[351/600] MIou: 0.9348098615518265
2023-02-06 12:04:30 | Valid | Epoch[351/600] Pixel Accuracy: 0.9887123107910156
2023-02-06 12:04:30 | Valid | Epoch[351/600] Mean Pixel Accuracy: 0.963925843309033
2023-02-06 12:04:30 | Stage | Epoch[351/600] Train loss:0.0184
2023-02-06 12:04:30 | Stage | Epoch[351/600] Valid loss:0.0858
2023-02-06 12:04:30 | Stage | Epoch[351/600] LR:0.01

2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[003/030] Train loss: 0.0180
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[005/030] Train loss: 0.0180
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[006/030] Train loss: 0.0185
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[007/030] Train loss: 0.0187
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[009/030] Train loss: 0.0189
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[010/030] Train loss: 0.0188
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[011/030] Train loss: 0.0187
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[012/030] Train loss: 0.0188
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[013/030] Train loss: 0.0188
2023-02-06 12:04:31 | Train | Epoch[352/600] Iteration[014/030] Train loss: 0.0187
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[015/030] Train loss: 0.0187
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[016/030] Train loss: 0.0186
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[018/030] Train loss: 0.0184
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[020/030] Train loss: 0.0182
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[023/030] Train loss: 0.0184
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[024/030] Train loss: 0.0184
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[025/030] Train loss: 0.0184
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[027/030] Train loss: 0.0184
2023-02-06 12:04:32 | Train | Epoch[352/600] Iteration[028/030] Train loss: 0.0184
2023-02-06 12:04:33 | Train | Epoch[352/600] Iteration[029/030] Train loss: 0.0184
2023-02-06 12:04:33 | Train | Epoch[352/600] Iteration[030/030] Train loss: 0.0184
2023-02-06 12:04:33 | Valid | Epoch[352/600] Iteration[001/008] Valid loss: 0.1319
2023-02-06 12:04:33 | Valid | Epoch[352/600] Iteration[002/008] Valid loss: 0.0956
2023-02-06 12:04:33 | Valid | Epoch[352/600] Iteration[003/008] Valid loss: 0.0971
2023-02-06 12:04:33 | Valid | Epoch[352/600] Iteration[004/008] Valid loss: 0.0892
2023-02-06 12:04:33 | Valid | Epoch[352/600] Iteration[005/008] Valid loss: 0.0883
2023-02-06 12:04:33 | Valid | Epoch[352/600] Iteration[006/008] Valid loss: 0.0834
2023-02-06 12:04:33 | Valid | Epoch[352/600] Iteration[007/008] Valid loss: 0.0880
2023-02-06 12:04:33 | Valid | Epoch[352/600] Iteration[008/008] Valid loss: 0.0825
2023-02-06 12:04:33 | Valid | Epoch[352/600] MIou: 0.9415925962092961
2023-02-06 12:04:33 | Valid | Epoch[352/600] Pixel Accuracy: 0.9900067647298177
2023-02-06 12:04:33 | Valid | Epoch[352/600] Mean Pixel Accuracy: 0.9648529064323345
2023-02-06 12:04:33 | Stage | Epoch[352/600] Train loss:0.0184
2023-02-06 12:04:33 | Stage | Epoch[352/600] Valid loss:0.0825
2023-02-06 12:04:33 | Stage | Epoch[352/600] LR:0.01

2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[002/030] Train loss: 0.0184
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[005/030] Train loss: 0.0178
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[007/030] Train loss: 0.0182
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[008/030] Train loss: 0.0184
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[009/030] Train loss: 0.0183
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[010/030] Train loss: 0.0182
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[011/030] Train loss: 0.0180
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[013/030] Train loss: 0.0179
2023-02-06 12:04:34 | Train | Epoch[353/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[016/030] Train loss: 0.0181
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[018/030] Train loss: 0.0181
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[020/030] Train loss: 0.0182
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[021/030] Train loss: 0.0181
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[023/030] Train loss: 0.0181
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[024/030] Train loss: 0.0181
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[025/030] Train loss: 0.0186
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[026/030] Train loss: 0.0185
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[027/030] Train loss: 0.0184
2023-02-06 12:04:35 | Train | Epoch[353/600] Iteration[028/030] Train loss: 0.0186
2023-02-06 12:04:36 | Train | Epoch[353/600] Iteration[029/030] Train loss: 0.0185
2023-02-06 12:04:36 | Train | Epoch[353/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:04:36 | Valid | Epoch[353/600] Iteration[001/008] Valid loss: 0.0608
2023-02-06 12:04:36 | Valid | Epoch[353/600] Iteration[002/008] Valid loss: 0.0573
2023-02-06 12:04:36 | Valid | Epoch[353/600] Iteration[003/008] Valid loss: 0.0604
2023-02-06 12:04:36 | Valid | Epoch[353/600] Iteration[004/008] Valid loss: 0.0578
2023-02-06 12:04:36 | Valid | Epoch[353/600] Iteration[005/008] Valid loss: 0.0581
2023-02-06 12:04:36 | Valid | Epoch[353/600] Iteration[006/008] Valid loss: 0.0571
2023-02-06 12:04:36 | Valid | Epoch[353/600] Iteration[007/008] Valid loss: 0.0559
2023-02-06 12:04:36 | Valid | Epoch[353/600] Iteration[008/008] Valid loss: 0.0567
2023-02-06 12:04:36 | Valid | Epoch[353/600] MIou: 0.8431891132703306
2023-02-06 12:04:36 | Valid | Epoch[353/600] Pixel Accuracy: 0.9741299947102865
2023-02-06 12:04:36 | Valid | Epoch[353/600] Mean Pixel Accuracy: 0.8575193435458708
2023-02-06 12:04:36 | Stage | Epoch[353/600] Train loss:0.0186
2023-02-06 12:04:36 | Stage | Epoch[353/600] Valid loss:0.0567
2023-02-06 12:04:36 | Stage | Epoch[353/600] LR:0.01

2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[001/030] Train loss: 0.0145
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[005/030] Train loss: 0.0172
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[006/030] Train loss: 0.0178
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[008/030] Train loss: 0.0179
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[009/030] Train loss: 0.0177
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[010/030] Train loss: 0.0178
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[011/030] Train loss: 0.0180
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[012/030] Train loss: 0.0181
2023-02-06 12:04:37 | Train | Epoch[354/600] Iteration[013/030] Train loss: 0.0178
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[014/030] Train loss: 0.0178
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[017/030] Train loss: 0.0183
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[019/030] Train loss: 0.0181
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[020/030] Train loss: 0.0180
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[021/030] Train loss: 0.0181
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[022/030] Train loss: 0.0181
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[023/030] Train loss: 0.0180
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[024/030] Train loss: 0.0180
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[025/030] Train loss: 0.0181
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:04:38 | Train | Epoch[354/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 12:04:39 | Train | Epoch[354/600] Iteration[028/030] Train loss: 0.0184
2023-02-06 12:04:39 | Train | Epoch[354/600] Iteration[029/030] Train loss: 0.0185
2023-02-06 12:04:39 | Train | Epoch[354/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:04:39 | Valid | Epoch[354/600] Iteration[001/008] Valid loss: 1.9519
2023-02-06 12:04:39 | Valid | Epoch[354/600] Iteration[002/008] Valid loss: 1.9426
2023-02-06 12:04:39 | Valid | Epoch[354/600] Iteration[003/008] Valid loss: 2.0135
2023-02-06 12:04:39 | Valid | Epoch[354/600] Iteration[004/008] Valid loss: 2.0932
2023-02-06 12:04:39 | Valid | Epoch[354/600] Iteration[005/008] Valid loss: 2.1370
2023-02-06 12:04:39 | Valid | Epoch[354/600] Iteration[006/008] Valid loss: 2.0927
2023-02-06 12:04:39 | Valid | Epoch[354/600] Iteration[007/008] Valid loss: 2.1517
2023-02-06 12:04:39 | Valid | Epoch[354/600] Iteration[008/008] Valid loss: 2.2371
2023-02-06 12:04:39 | Valid | Epoch[354/600] MIou: 0.8004317510343268
2023-02-06 12:04:39 | Valid | Epoch[354/600] Pixel Accuracy: 0.9522018432617188
2023-02-06 12:04:39 | Valid | Epoch[354/600] Mean Pixel Accuracy: 0.972669235772043
2023-02-06 12:04:39 | Stage | Epoch[354/600] Train loss:0.0186
2023-02-06 12:04:39 | Stage | Epoch[354/600] Valid loss:2.2371
2023-02-06 12:04:39 | Stage | Epoch[354/600] LR:0.01

2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[004/030] Train loss: 0.0188
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[006/030] Train loss: 0.0190
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[007/030] Train loss: 0.0185
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[008/030] Train loss: 0.0182
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[009/030] Train loss: 0.0182
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[010/030] Train loss: 0.0182
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[011/030] Train loss: 0.0182
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[012/030] Train loss: 0.0182
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[013/030] Train loss: 0.0183
2023-02-06 12:04:40 | Train | Epoch[355/600] Iteration[014/030] Train loss: 0.0181
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[015/030] Train loss: 0.0184
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[016/030] Train loss: 0.0186
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[017/030] Train loss: 0.0186
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[019/030] Train loss: 0.0185
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[020/030] Train loss: 0.0186
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[021/030] Train loss: 0.0185
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[022/030] Train loss: 0.0185
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[023/030] Train loss: 0.0185
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[024/030] Train loss: 0.0186
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[025/030] Train loss: 0.0185
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[026/030] Train loss: 0.0184
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 12:04:41 | Train | Epoch[355/600] Iteration[028/030] Train loss: 0.0183
2023-02-06 12:04:42 | Train | Epoch[355/600] Iteration[029/030] Train loss: 0.0184
2023-02-06 12:04:42 | Train | Epoch[355/600] Iteration[030/030] Train loss: 0.0185
2023-02-06 12:04:42 | Valid | Epoch[355/600] Iteration[001/008] Valid loss: 0.1069
2023-02-06 12:04:42 | Valid | Epoch[355/600] Iteration[002/008] Valid loss: 0.1080
2023-02-06 12:04:42 | Valid | Epoch[355/600] Iteration[003/008] Valid loss: 0.1182
2023-02-06 12:04:42 | Valid | Epoch[355/600] Iteration[004/008] Valid loss: 0.1148
2023-02-06 12:04:42 | Valid | Epoch[355/600] Iteration[005/008] Valid loss: 0.1180
2023-02-06 12:04:42 | Valid | Epoch[355/600] Iteration[006/008] Valid loss: 0.1155
2023-02-06 12:04:42 | Valid | Epoch[355/600] Iteration[007/008] Valid loss: 0.1123
2023-02-06 12:04:42 | Valid | Epoch[355/600] Iteration[008/008] Valid loss: 0.1181
2023-02-06 12:04:42 | Valid | Epoch[355/600] MIou: 0.6385986836798379
2023-02-06 12:04:42 | Valid | Epoch[355/600] Pixel Accuracy: 0.9402618408203125
2023-02-06 12:04:42 | Valid | Epoch[355/600] Mean Pixel Accuracy: 0.6694548605657804
2023-02-06 12:04:42 | Stage | Epoch[355/600] Train loss:0.0185
2023-02-06 12:04:42 | Stage | Epoch[355/600] Valid loss:0.1181
2023-02-06 12:04:42 | Stage | Epoch[355/600] LR:0.01

2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[002/030] Train loss: 0.0167
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[006/030] Train loss: 0.0182
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[008/030] Train loss: 0.0187
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[009/030] Train loss: 0.0191
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[010/030] Train loss: 0.0191
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[011/030] Train loss: 0.0192
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[012/030] Train loss: 0.0194
2023-02-06 12:04:43 | Train | Epoch[356/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[014/030] Train loss: 0.0194
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[018/030] Train loss: 0.0194
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[019/030] Train loss: 0.0193
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[020/030] Train loss: 0.0192
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[021/030] Train loss: 0.0192
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[022/030] Train loss: 0.0192
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[023/030] Train loss: 0.0191
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[024/030] Train loss: 0.0191
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[025/030] Train loss: 0.0191
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[026/030] Train loss: 0.0190
2023-02-06 12:04:44 | Train | Epoch[356/600] Iteration[027/030] Train loss: 0.0190
2023-02-06 12:04:45 | Train | Epoch[356/600] Iteration[028/030] Train loss: 0.0189
2023-02-06 12:04:45 | Train | Epoch[356/600] Iteration[029/030] Train loss: 0.0190
2023-02-06 12:04:45 | Train | Epoch[356/600] Iteration[030/030] Train loss: 0.0189
2023-02-06 12:04:45 | Valid | Epoch[356/600] Iteration[001/008] Valid loss: 0.0610
2023-02-06 12:04:45 | Valid | Epoch[356/600] Iteration[002/008] Valid loss: 0.0613
2023-02-06 12:04:45 | Valid | Epoch[356/600] Iteration[003/008] Valid loss: 0.0648
2023-02-06 12:04:45 | Valid | Epoch[356/600] Iteration[004/008] Valid loss: 0.0629
2023-02-06 12:04:45 | Valid | Epoch[356/600] Iteration[005/008] Valid loss: 0.0636
2023-02-06 12:04:45 | Valid | Epoch[356/600] Iteration[006/008] Valid loss: 0.0625
2023-02-06 12:04:45 | Valid | Epoch[356/600] Iteration[007/008] Valid loss: 0.0618
2023-02-06 12:04:45 | Valid | Epoch[356/600] Iteration[008/008] Valid loss: 0.0633
2023-02-06 12:04:45 | Valid | Epoch[356/600] MIou: 0.8173205798380259
2023-02-06 12:04:45 | Valid | Epoch[356/600] Pixel Accuracy: 0.969824473063151
2023-02-06 12:04:45 | Valid | Epoch[356/600] Mean Pixel Accuracy: 0.8341088202739553
2023-02-06 12:04:45 | Stage | Epoch[356/600] Train loss:0.0189
2023-02-06 12:04:45 | Stage | Epoch[356/600] Valid loss:0.0633
2023-02-06 12:04:45 | Stage | Epoch[356/600] LR:0.01

2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[002/030] Train loss: 0.0183
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[003/030] Train loss: 0.0177
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[005/030] Train loss: 0.0174
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[006/030] Train loss: 0.0175
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[008/030] Train loss: 0.0178
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[009/030] Train loss: 0.0179
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[010/030] Train loss: 0.0182
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[011/030] Train loss: 0.0179
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[012/030] Train loss: 0.0183
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[013/030] Train loss: 0.0183
2023-02-06 12:04:46 | Train | Epoch[357/600] Iteration[014/030] Train loss: 0.0183
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[016/030] Train loss: 0.0181
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[018/030] Train loss: 0.0181
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[020/030] Train loss: 0.0183
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[021/030] Train loss: 0.0182
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[022/030] Train loss: 0.0181
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[023/030] Train loss: 0.0183
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[025/030] Train loss: 0.0183
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[027/030] Train loss: 0.0182
2023-02-06 12:04:47 | Train | Epoch[357/600] Iteration[028/030] Train loss: 0.0183
2023-02-06 12:04:48 | Train | Epoch[357/600] Iteration[029/030] Train loss: 0.0182
2023-02-06 12:04:48 | Train | Epoch[357/600] Iteration[030/030] Train loss: 0.0182
2023-02-06 12:04:48 | Valid | Epoch[357/600] Iteration[001/008] Valid loss: 1.0728
2023-02-06 12:04:48 | Valid | Epoch[357/600] Iteration[002/008] Valid loss: 1.0776
2023-02-06 12:04:48 | Valid | Epoch[357/600] Iteration[003/008] Valid loss: 1.1035
2023-02-06 12:04:48 | Valid | Epoch[357/600] Iteration[004/008] Valid loss: 1.1414
2023-02-06 12:04:48 | Valid | Epoch[357/600] Iteration[005/008] Valid loss: 1.1742
2023-02-06 12:04:48 | Valid | Epoch[357/600] Iteration[006/008] Valid loss: 1.1459
2023-02-06 12:04:48 | Valid | Epoch[357/600] Iteration[007/008] Valid loss: 1.1964
2023-02-06 12:04:48 | Valid | Epoch[357/600] Iteration[008/008] Valid loss: 1.2338
2023-02-06 12:04:48 | Valid | Epoch[357/600] MIou: 0.8484310383924494
2023-02-06 12:04:48 | Valid | Epoch[357/600] Pixel Accuracy: 0.9672228495279948
2023-02-06 12:04:48 | Valid | Epoch[357/600] Mean Pixel Accuracy: 0.9800377554347199
2023-02-06 12:04:48 | Stage | Epoch[357/600] Train loss:0.0182
2023-02-06 12:04:48 | Stage | Epoch[357/600] Valid loss:1.2338
2023-02-06 12:04:48 | Stage | Epoch[357/600] LR:0.01

2023-02-06 12:04:48 | Train | Epoch[358/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[003/030] Train loss: 0.0197
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[007/030] Train loss: 0.0192
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[008/030] Train loss: 0.0190
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[009/030] Train loss: 0.0189
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[010/030] Train loss: 0.0192
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[011/030] Train loss: 0.0191
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[014/030] Train loss: 0.0190
2023-02-06 12:04:49 | Train | Epoch[358/600] Iteration[015/030] Train loss: 0.0189
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[016/030] Train loss: 0.0190
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[017/030] Train loss: 0.0191
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[018/030] Train loss: 0.0192
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[019/030] Train loss: 0.0191
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[020/030] Train loss: 0.0190
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[021/030] Train loss: 0.0189
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[022/030] Train loss: 0.0189
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[023/030] Train loss: 0.0187
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[024/030] Train loss: 0.0185
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[025/030] Train loss: 0.0187
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[026/030] Train loss: 0.0187
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[027/030] Train loss: 0.0186
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[028/030] Train loss: 0.0186
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[029/030] Train loss: 0.0185
2023-02-06 12:04:50 | Train | Epoch[358/600] Iteration[030/030] Train loss: 0.0184
2023-02-06 12:04:51 | Valid | Epoch[358/600] Iteration[001/008] Valid loss: 0.0718
2023-02-06 12:04:51 | Valid | Epoch[358/600] Iteration[002/008] Valid loss: 0.0725
2023-02-06 12:04:51 | Valid | Epoch[358/600] Iteration[003/008] Valid loss: 0.0767
2023-02-06 12:04:51 | Valid | Epoch[358/600] Iteration[004/008] Valid loss: 0.0746
2023-02-06 12:04:51 | Valid | Epoch[358/600] Iteration[005/008] Valid loss: 0.0752
2023-02-06 12:04:51 | Valid | Epoch[358/600] Iteration[006/008] Valid loss: 0.0736
2023-02-06 12:04:51 | Valid | Epoch[358/600] Iteration[007/008] Valid loss: 0.0722
2023-02-06 12:04:51 | Valid | Epoch[358/600] Iteration[008/008] Valid loss: 0.0742
2023-02-06 12:04:51 | Valid | Epoch[358/600] MIou: 0.7835869037509277
2023-02-06 12:04:51 | Valid | Epoch[358/600] Pixel Accuracy: 0.9642664591471354
2023-02-06 12:04:51 | Valid | Epoch[358/600] Mean Pixel Accuracy: 0.8028831838539822
2023-02-06 12:04:51 | Stage | Epoch[358/600] Train loss:0.0184
2023-02-06 12:04:51 | Stage | Epoch[358/600] Valid loss:0.0742
2023-02-06 12:04:51 | Stage | Epoch[358/600] LR:0.01

2023-02-06 12:04:51 | Train | Epoch[359/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 12:04:51 | Train | Epoch[359/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[005/030] Train loss: 0.0181
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[006/030] Train loss: 0.0177
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[008/030] Train loss: 0.0181
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[009/030] Train loss: 0.0182
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[011/030] Train loss: 0.0183
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[012/030] Train loss: 0.0181
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[013/030] Train loss: 0.0183
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[014/030] Train loss: 0.0182
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:04:52 | Train | Epoch[359/600] Iteration[016/030] Train loss: 0.0181
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[020/030] Train loss: 0.0182
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[022/030] Train loss: 0.0183
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[023/030] Train loss: 0.0184
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[024/030] Train loss: 0.0184
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[025/030] Train loss: 0.0183
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[027/030] Train loss: 0.0185
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[028/030] Train loss: 0.0185
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[029/030] Train loss: 0.0185
2023-02-06 12:04:53 | Train | Epoch[359/600] Iteration[030/030] Train loss: 0.0185
2023-02-06 12:04:54 | Valid | Epoch[359/600] Iteration[001/008] Valid loss: 0.0521
2023-02-06 12:04:54 | Valid | Epoch[359/600] Iteration[002/008] Valid loss: 0.0468
2023-02-06 12:04:54 | Valid | Epoch[359/600] Iteration[003/008] Valid loss: 0.0568
2023-02-06 12:04:54 | Valid | Epoch[359/600] Iteration[004/008] Valid loss: 0.0523
2023-02-06 12:04:54 | Valid | Epoch[359/600] Iteration[005/008] Valid loss: 0.0518
2023-02-06 12:04:54 | Valid | Epoch[359/600] Iteration[006/008] Valid loss: 0.0497
2023-02-06 12:04:54 | Valid | Epoch[359/600] Iteration[007/008] Valid loss: 0.0486
2023-02-06 12:04:54 | Valid | Epoch[359/600] Iteration[008/008] Valid loss: 0.0480
2023-02-06 12:04:54 | Valid | Epoch[359/600] MIou: 0.8757382439550137
2023-02-06 12:04:54 | Valid | Epoch[359/600] Pixel Accuracy: 0.9793879191080729
2023-02-06 12:04:54 | Valid | Epoch[359/600] Mean Pixel Accuracy: 0.8896071943530737
2023-02-06 12:04:54 | Stage | Epoch[359/600] Train loss:0.0185
2023-02-06 12:04:54 | Stage | Epoch[359/600] Valid loss:0.0480
2023-02-06 12:04:54 | Stage | Epoch[359/600] LR:0.01

2023-02-06 12:04:54 | Train | Epoch[360/600] Iteration[001/030] Train loss: 0.0169
2023-02-06 12:04:54 | Train | Epoch[360/600] Iteration[002/030] Train loss: 0.0174
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[005/030] Train loss: 0.0167
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[013/030] Train loss: 0.0172
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[014/030] Train loss: 0.0174
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[015/030] Train loss: 0.0177
2023-02-06 12:04:55 | Train | Epoch[360/600] Iteration[016/030] Train loss: 0.0177
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[017/030] Train loss: 0.0177
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[018/030] Train loss: 0.0177
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[019/030] Train loss: 0.0178
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[020/030] Train loss: 0.0178
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[021/030] Train loss: 0.0178
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[022/030] Train loss: 0.0178
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[023/030] Train loss: 0.0178
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[024/030] Train loss: 0.0178
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[025/030] Train loss: 0.0177
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[026/030] Train loss: 0.0178
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[027/030] Train loss: 0.0178
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[028/030] Train loss: 0.0180
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 12:04:56 | Train | Epoch[360/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 12:04:57 | Valid | Epoch[360/600] Iteration[001/008] Valid loss: 0.0709
2023-02-06 12:04:57 | Valid | Epoch[360/600] Iteration[002/008] Valid loss: 0.0717
2023-02-06 12:04:57 | Valid | Epoch[360/600] Iteration[003/008] Valid loss: 0.0770
2023-02-06 12:04:57 | Valid | Epoch[360/600] Iteration[004/008] Valid loss: 0.0745
2023-02-06 12:04:57 | Valid | Epoch[360/600] Iteration[005/008] Valid loss: 0.0752
2023-02-06 12:04:57 | Valid | Epoch[360/600] Iteration[006/008] Valid loss: 0.0741
2023-02-06 12:04:57 | Valid | Epoch[360/600] Iteration[007/008] Valid loss: 0.0718
2023-02-06 12:04:57 | Valid | Epoch[360/600] Iteration[008/008] Valid loss: 0.0745
2023-02-06 12:04:57 | Valid | Epoch[360/600] MIou: 0.7752769141961189
2023-02-06 12:04:57 | Valid | Epoch[360/600] Pixel Accuracy: 0.962927500406901
2023-02-06 12:04:57 | Valid | Epoch[360/600] Mean Pixel Accuracy: 0.7949634808019539
2023-02-06 12:04:57 | Stage | Epoch[360/600] Train loss:0.0180
2023-02-06 12:04:57 | Stage | Epoch[360/600] Valid loss:0.0745
2023-02-06 12:04:57 | Stage | Epoch[360/600] LR:0.01

2023-02-06 12:04:57 | Train | Epoch[361/600] Iteration[001/030] Train loss: 0.0183
2023-02-06 12:04:57 | Train | Epoch[361/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 12:04:57 | Train | Epoch[361/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[006/030] Train loss: 0.0182
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[007/030] Train loss: 0.0185
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[008/030] Train loss: 0.0185
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[009/030] Train loss: 0.0184
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[011/030] Train loss: 0.0176
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[012/030] Train loss: 0.0182
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[013/030] Train loss: 0.0183
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[014/030] Train loss: 0.0184
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[015/030] Train loss: 0.0181
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[016/030] Train loss: 0.0180
2023-02-06 12:04:58 | Train | Epoch[361/600] Iteration[017/030] Train loss: 0.0180
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[018/030] Train loss: 0.0180
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[020/030] Train loss: 0.0183
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[021/030] Train loss: 0.0184
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[025/030] Train loss: 0.0183
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[027/030] Train loss: 0.0182
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[028/030] Train loss: 0.0182
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[029/030] Train loss: 0.0182
2023-02-06 12:04:59 | Train | Epoch[361/600] Iteration[030/030] Train loss: 0.0181
2023-02-06 12:05:00 | Valid | Epoch[361/600] Iteration[001/008] Valid loss: 0.1516
2023-02-06 12:05:00 | Valid | Epoch[361/600] Iteration[002/008] Valid loss: 0.1556
2023-02-06 12:05:00 | Valid | Epoch[361/600] Iteration[003/008] Valid loss: 0.1667
2023-02-06 12:05:00 | Valid | Epoch[361/600] Iteration[004/008] Valid loss: 0.1636
2023-02-06 12:05:00 | Valid | Epoch[361/600] Iteration[005/008] Valid loss: 0.1684
2023-02-06 12:05:00 | Valid | Epoch[361/600] Iteration[006/008] Valid loss: 0.1653
2023-02-06 12:05:00 | Valid | Epoch[361/600] Iteration[007/008] Valid loss: 0.1619
2023-02-06 12:05:00 | Valid | Epoch[361/600] Iteration[008/008] Valid loss: 0.1682
2023-02-06 12:05:00 | Valid | Epoch[361/600] MIou: 0.5706892527488576
2023-02-06 12:05:00 | Valid | Epoch[361/600] Pixel Accuracy: 0.9289906819661459
2023-02-06 12:05:00 | Valid | Epoch[361/600] Mean Pixel Accuracy: 0.6068929592138422
2023-02-06 12:05:00 | Stage | Epoch[361/600] Train loss:0.0181
2023-02-06 12:05:00 | Stage | Epoch[361/600] Valid loss:0.1682
2023-02-06 12:05:00 | Stage | Epoch[361/600] LR:0.01

2023-02-06 12:05:00 | Train | Epoch[362/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 12:05:00 | Train | Epoch[362/600] Iteration[002/030] Train loss: 0.0168
2023-02-06 12:05:00 | Train | Epoch[362/600] Iteration[003/030] Train loss: 0.0180
2023-02-06 12:05:00 | Train | Epoch[362/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[005/030] Train loss: 0.0184
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[006/030] Train loss: 0.0179
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[008/030] Train loss: 0.0180
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[009/030] Train loss: 0.0179
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[011/030] Train loss: 0.0178
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[013/030] Train loss: 0.0177
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[014/030] Train loss: 0.0177
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[015/030] Train loss: 0.0177
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[016/030] Train loss: 0.0178
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[017/030] Train loss: 0.0177
2023-02-06 12:05:01 | Train | Epoch[362/600] Iteration[018/030] Train loss: 0.0176
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[019/030] Train loss: 0.0178
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[020/030] Train loss: 0.0179
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[021/030] Train loss: 0.0179
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[022/030] Train loss: 0.0178
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[023/030] Train loss: 0.0178
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[024/030] Train loss: 0.0178
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[025/030] Train loss: 0.0177
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[026/030] Train loss: 0.0177
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[027/030] Train loss: 0.0176
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[028/030] Train loss: 0.0179
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 12:05:02 | Train | Epoch[362/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 12:05:03 | Valid | Epoch[362/600] Iteration[001/008] Valid loss: 0.0535
2023-02-06 12:05:03 | Valid | Epoch[362/600] Iteration[002/008] Valid loss: 0.0468
2023-02-06 12:05:03 | Valid | Epoch[362/600] Iteration[003/008] Valid loss: 0.0481
2023-02-06 12:05:03 | Valid | Epoch[362/600] Iteration[004/008] Valid loss: 0.0449
2023-02-06 12:05:03 | Valid | Epoch[362/600] Iteration[005/008] Valid loss: 0.0448
2023-02-06 12:05:03 | Valid | Epoch[362/600] Iteration[006/008] Valid loss: 0.0436
2023-02-06 12:05:03 | Valid | Epoch[362/600] Iteration[007/008] Valid loss: 0.0429
2023-02-06 12:05:03 | Valid | Epoch[362/600] Iteration[008/008] Valid loss: 0.0432
2023-02-06 12:05:03 | Valid | Epoch[362/600] MIou: 0.8701409588222329
2023-02-06 12:05:03 | Valid | Epoch[362/600] Pixel Accuracy: 0.9785448710123698
2023-02-06 12:05:03 | Valid | Epoch[362/600] Mean Pixel Accuracy: 0.882904795196657
2023-02-06 12:05:03 | Stage | Epoch[362/600] Train loss:0.0180
2023-02-06 12:05:03 | Stage | Epoch[362/600] Valid loss:0.0432
2023-02-06 12:05:03 | Stage | Epoch[362/600] LR:0.01

2023-02-06 12:05:03 | Train | Epoch[363/600] Iteration[001/030] Train loss: 0.0172
2023-02-06 12:05:03 | Train | Epoch[363/600] Iteration[002/030] Train loss: 0.0169
2023-02-06 12:05:03 | Train | Epoch[363/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[015/030] Train loss: 0.0171
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[016/030] Train loss: 0.0172
2023-02-06 12:05:04 | Train | Epoch[363/600] Iteration[017/030] Train loss: 0.0175
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[018/030] Train loss: 0.0178
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[019/030] Train loss: 0.0180
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[020/030] Train loss: 0.0179
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[021/030] Train loss: 0.0178
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[022/030] Train loss: 0.0181
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[023/030] Train loss: 0.0181
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[025/030] Train loss: 0.0184
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[026/030] Train loss: 0.0184
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[027/030] Train loss: 0.0184
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[028/030] Train loss: 0.0184
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[029/030] Train loss: 0.0184
2023-02-06 12:05:05 | Train | Epoch[363/600] Iteration[030/030] Train loss: 0.0187
2023-02-06 12:05:06 | Valid | Epoch[363/600] Iteration[001/008] Valid loss: 2.4361
2023-02-06 12:05:06 | Valid | Epoch[363/600] Iteration[002/008] Valid loss: 2.3661
2023-02-06 12:05:06 | Valid | Epoch[363/600] Iteration[003/008] Valid loss: 2.4468
2023-02-06 12:05:06 | Valid | Epoch[363/600] Iteration[004/008] Valid loss: 2.5634
2023-02-06 12:05:06 | Valid | Epoch[363/600] Iteration[005/008] Valid loss: 2.6428
2023-02-06 12:05:06 | Valid | Epoch[363/600] Iteration[006/008] Valid loss: 2.6077
2023-02-06 12:05:06 | Valid | Epoch[363/600] Iteration[007/008] Valid loss: 2.6765
2023-02-06 12:05:06 | Valid | Epoch[363/600] Iteration[008/008] Valid loss: 2.7563
2023-02-06 12:05:06 | Valid | Epoch[363/600] MIou: 0.7761364491372487
2023-02-06 12:05:06 | Valid | Epoch[363/600] Pixel Accuracy: 0.9433860778808594
2023-02-06 12:05:06 | Valid | Epoch[363/600] Mean Pixel Accuracy: 0.9685211670017515
2023-02-06 12:05:06 | Stage | Epoch[363/600] Train loss:0.0187
2023-02-06 12:05:06 | Stage | Epoch[363/600] Valid loss:2.7563
2023-02-06 12:05:06 | Stage | Epoch[363/600] LR:0.01

2023-02-06 12:05:06 | Train | Epoch[364/600] Iteration[001/030] Train loss: 0.0172
2023-02-06 12:05:06 | Train | Epoch[364/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 12:05:06 | Train | Epoch[364/600] Iteration[003/030] Train loss: 0.0188
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[004/030] Train loss: 0.0185
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[006/030] Train loss: 0.0187
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[007/030] Train loss: 0.0185
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[008/030] Train loss: 0.0185
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[009/030] Train loss: 0.0187
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[010/030] Train loss: 0.0187
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[011/030] Train loss: 0.0186
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[012/030] Train loss: 0.0188
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[013/030] Train loss: 0.0186
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[014/030] Train loss: 0.0182
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[016/030] Train loss: 0.0184
2023-02-06 12:05:07 | Train | Epoch[364/600] Iteration[017/030] Train loss: 0.0186
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[018/030] Train loss: 0.0184
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[020/030] Train loss: 0.0183
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[022/030] Train loss: 0.0184
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[023/030] Train loss: 0.0184
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[024/030] Train loss: 0.0185
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[025/030] Train loss: 0.0184
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[026/030] Train loss: 0.0184
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[027/030] Train loss: 0.0184
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[028/030] Train loss: 0.0185
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[029/030] Train loss: 0.0184
2023-02-06 12:05:08 | Train | Epoch[364/600] Iteration[030/030] Train loss: 0.0186
2023-02-06 12:05:09 | Valid | Epoch[364/600] Iteration[001/008] Valid loss: 1.4282
2023-02-06 12:05:09 | Valid | Epoch[364/600] Iteration[002/008] Valid loss: 1.3426
2023-02-06 12:05:09 | Valid | Epoch[364/600] Iteration[003/008] Valid loss: 1.3750
2023-02-06 12:05:09 | Valid | Epoch[364/600] Iteration[004/008] Valid loss: 1.4331
2023-02-06 12:05:09 | Valid | Epoch[364/600] Iteration[005/008] Valid loss: 1.4679
2023-02-06 12:05:09 | Valid | Epoch[364/600] Iteration[006/008] Valid loss: 1.4355
2023-02-06 12:05:09 | Valid | Epoch[364/600] Iteration[007/008] Valid loss: 1.4814
2023-02-06 12:05:09 | Valid | Epoch[364/600] Iteration[008/008] Valid loss: 1.5284
2023-02-06 12:05:09 | Valid | Epoch[364/600] MIou: 0.8363044003572923
2023-02-06 12:05:09 | Valid | Epoch[364/600] Pixel Accuracy: 0.9637476603190104
2023-02-06 12:05:09 | Valid | Epoch[364/600] Mean Pixel Accuracy: 0.9775696817391641
2023-02-06 12:05:09 | Stage | Epoch[364/600] Train loss:0.0186
2023-02-06 12:05:09 | Stage | Epoch[364/600] Valid loss:1.5284
2023-02-06 12:05:09 | Stage | Epoch[364/600] LR:0.01

2023-02-06 12:05:09 | Train | Epoch[365/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 12:05:09 | Train | Epoch[365/600] Iteration[002/030] Train loss: 0.0214
2023-02-06 12:05:09 | Train | Epoch[365/600] Iteration[003/030] Train loss: 0.0218
2023-02-06 12:05:09 | Train | Epoch[365/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[007/030] Train loss: 0.0200
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[009/030] Train loss: 0.0192
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[010/030] Train loss: 0.0193
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[015/030] Train loss: 0.0191
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[016/030] Train loss: 0.0190
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[017/030] Train loss: 0.0188
2023-02-06 12:05:10 | Train | Epoch[365/600] Iteration[018/030] Train loss: 0.0190
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[019/030] Train loss: 0.0190
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[020/030] Train loss: 0.0192
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[021/030] Train loss: 0.0191
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[022/030] Train loss: 0.0191
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[023/030] Train loss: 0.0191
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[024/030] Train loss: 0.0191
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[025/030] Train loss: 0.0191
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[026/030] Train loss: 0.0190
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[027/030] Train loss: 0.0189
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[028/030] Train loss: 0.0189
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[029/030] Train loss: 0.0189
2023-02-06 12:05:11 | Train | Epoch[365/600] Iteration[030/030] Train loss: 0.0189
2023-02-06 12:05:12 | Valid | Epoch[365/600] Iteration[001/008] Valid loss: 0.0668
2023-02-06 12:05:12 | Valid | Epoch[365/600] Iteration[002/008] Valid loss: 0.0645
2023-02-06 12:05:12 | Valid | Epoch[365/600] Iteration[003/008] Valid loss: 0.0667
2023-02-06 12:05:12 | Valid | Epoch[365/600] Iteration[004/008] Valid loss: 0.0649
2023-02-06 12:05:12 | Valid | Epoch[365/600] Iteration[005/008] Valid loss: 0.0654
2023-02-06 12:05:12 | Valid | Epoch[365/600] Iteration[006/008] Valid loss: 0.0643
2023-02-06 12:05:12 | Valid | Epoch[365/600] Iteration[007/008] Valid loss: 0.0628
2023-02-06 12:05:12 | Valid | Epoch[365/600] Iteration[008/008] Valid loss: 0.0646
2023-02-06 12:05:12 | Valid | Epoch[365/600] MIou: 0.8114172823663623
2023-02-06 12:05:12 | Valid | Epoch[365/600] Pixel Accuracy: 0.9688568115234375
2023-02-06 12:05:12 | Valid | Epoch[365/600] Mean Pixel Accuracy: 0.8285870011419554
2023-02-06 12:05:12 | Stage | Epoch[365/600] Train loss:0.0189
2023-02-06 12:05:12 | Stage | Epoch[365/600] Valid loss:0.0646
2023-02-06 12:05:12 | Stage | Epoch[365/600] LR:0.01

2023-02-06 12:05:12 | Train | Epoch[366/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 12:05:12 | Train | Epoch[366/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 12:05:12 | Train | Epoch[366/600] Iteration[003/030] Train loss: 0.0170
2023-02-06 12:05:12 | Train | Epoch[366/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[006/030] Train loss: 0.0179
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[007/030] Train loss: 0.0174
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[008/030] Train loss: 0.0175
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[009/030] Train loss: 0.0174
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[010/030] Train loss: 0.0174
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[011/030] Train loss: 0.0175
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[012/030] Train loss: 0.0174
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[013/030] Train loss: 0.0175
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[014/030] Train loss: 0.0172
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[015/030] Train loss: 0.0174
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[016/030] Train loss: 0.0175
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[017/030] Train loss: 0.0174
2023-02-06 12:05:13 | Train | Epoch[366/600] Iteration[018/030] Train loss: 0.0175
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[019/030] Train loss: 0.0177
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[020/030] Train loss: 0.0177
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[021/030] Train loss: 0.0177
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[022/030] Train loss: 0.0178
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[023/030] Train loss: 0.0178
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[024/030] Train loss: 0.0177
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[025/030] Train loss: 0.0177
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[026/030] Train loss: 0.0178
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[027/030] Train loss: 0.0179
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[028/030] Train loss: 0.0180
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[029/030] Train loss: 0.0181
2023-02-06 12:05:14 | Train | Epoch[366/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 12:05:15 | Valid | Epoch[366/600] Iteration[001/008] Valid loss: 0.0858
2023-02-06 12:05:15 | Valid | Epoch[366/600] Iteration[002/008] Valid loss: 0.0734
2023-02-06 12:05:15 | Valid | Epoch[366/600] Iteration[003/008] Valid loss: 0.0639
2023-02-06 12:05:15 | Valid | Epoch[366/600] Iteration[004/008] Valid loss: 0.0602
2023-02-06 12:05:15 | Valid | Epoch[366/600] Iteration[005/008] Valid loss: 0.0571
2023-02-06 12:05:15 | Valid | Epoch[366/600] Iteration[006/008] Valid loss: 0.0565
2023-02-06 12:05:15 | Valid | Epoch[366/600] Iteration[007/008] Valid loss: 0.0585
2023-02-06 12:05:15 | Valid | Epoch[366/600] Iteration[008/008] Valid loss: 0.0576
2023-02-06 12:05:15 | Valid | Epoch[366/600] MIou: 0.9149537007463603
2023-02-06 12:05:15 | Valid | Epoch[366/600] Pixel Accuracy: 0.9855868021647135
2023-02-06 12:05:15 | Valid | Epoch[366/600] Mean Pixel Accuracy: 0.9351911813553264
2023-02-06 12:05:15 | Stage | Epoch[366/600] Train loss:0.0180
2023-02-06 12:05:15 | Stage | Epoch[366/600] Valid loss:0.0576
2023-02-06 12:05:15 | Stage | Epoch[366/600] LR:0.01

2023-02-06 12:05:15 | Train | Epoch[367/600] Iteration[001/030] Train loss: 0.0152
2023-02-06 12:05:15 | Train | Epoch[367/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:05:15 | Train | Epoch[367/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:05:15 | Train | Epoch[367/600] Iteration[004/030] Train loss: 0.0163
2023-02-06 12:05:15 | Train | Epoch[367/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[015/030] Train loss: 0.0171
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[016/030] Train loss: 0.0171
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[017/030] Train loss: 0.0172
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[018/030] Train loss: 0.0172
2023-02-06 12:05:16 | Train | Epoch[367/600] Iteration[019/030] Train loss: 0.0174
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[020/030] Train loss: 0.0175
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[021/030] Train loss: 0.0176
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[022/030] Train loss: 0.0175
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[023/030] Train loss: 0.0176
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[024/030] Train loss: 0.0178
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[025/030] Train loss: 0.0177
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[026/030] Train loss: 0.0177
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[027/030] Train loss: 0.0178
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[028/030] Train loss: 0.0179
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[029/030] Train loss: 0.0179
2023-02-06 12:05:17 | Train | Epoch[367/600] Iteration[030/030] Train loss: 0.0179
2023-02-06 12:05:18 | Valid | Epoch[367/600] Iteration[001/008] Valid loss: 0.2467
2023-02-06 12:05:18 | Valid | Epoch[367/600] Iteration[002/008] Valid loss: 0.1869
2023-02-06 12:05:18 | Valid | Epoch[367/600] Iteration[003/008] Valid loss: 0.1878
2023-02-06 12:05:18 | Valid | Epoch[367/600] Iteration[004/008] Valid loss: 0.1813
2023-02-06 12:05:18 | Valid | Epoch[367/600] Iteration[005/008] Valid loss: 0.1804
2023-02-06 12:05:18 | Valid | Epoch[367/600] Iteration[006/008] Valid loss: 0.1720
2023-02-06 12:05:18 | Valid | Epoch[367/600] Iteration[007/008] Valid loss: 0.1798
2023-02-06 12:05:18 | Valid | Epoch[367/600] Iteration[008/008] Valid loss: 0.1693
2023-02-06 12:05:18 | Valid | Epoch[367/600] MIou: 0.9443453402933006
2023-02-06 12:05:18 | Valid | Epoch[367/600] Pixel Accuracy: 0.9902788798014323
2023-02-06 12:05:18 | Valid | Epoch[367/600] Mean Pixel Accuracy: 0.9773600514581645
2023-02-06 12:05:18 | Stage | Epoch[367/600] Train loss:0.0179
2023-02-06 12:05:18 | Stage | Epoch[367/600] Valid loss:0.1693
2023-02-06 12:05:18 | Stage | Epoch[367/600] LR:0.01

2023-02-06 12:05:18 | Train | Epoch[368/600] Iteration[001/030] Train loss: 0.0166
2023-02-06 12:05:18 | Train | Epoch[368/600] Iteration[002/030] Train loss: 0.0160
2023-02-06 12:05:18 | Train | Epoch[368/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:05:18 | Train | Epoch[368/600] Iteration[004/030] Train loss: 0.0172
2023-02-06 12:05:18 | Train | Epoch[368/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[006/030] Train loss: 0.0171
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[007/030] Train loss: 0.0169
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[012/030] Train loss: 0.0170
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[014/030] Train loss: 0.0172
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[015/030] Train loss: 0.0172
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[016/030] Train loss: 0.0172
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[017/030] Train loss: 0.0173
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[018/030] Train loss: 0.0172
2023-02-06 12:05:19 | Train | Epoch[368/600] Iteration[019/030] Train loss: 0.0172
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[020/030] Train loss: 0.0175
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[021/030] Train loss: 0.0177
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[022/030] Train loss: 0.0179
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[023/030] Train loss: 0.0179
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[024/030] Train loss: 0.0179
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[025/030] Train loss: 0.0179
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[026/030] Train loss: 0.0179
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[027/030] Train loss: 0.0180
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[028/030] Train loss: 0.0180
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 12:05:20 | Train | Epoch[368/600] Iteration[030/030] Train loss: 0.0181
2023-02-06 12:05:21 | Valid | Epoch[368/600] Iteration[001/008] Valid loss: 0.1014
2023-02-06 12:05:21 | Valid | Epoch[368/600] Iteration[002/008] Valid loss: 0.0718
2023-02-06 12:05:21 | Valid | Epoch[368/600] Iteration[003/008] Valid loss: 0.0706
2023-02-06 12:05:21 | Valid | Epoch[368/600] Iteration[004/008] Valid loss: 0.0630
2023-02-06 12:05:21 | Valid | Epoch[368/600] Iteration[005/008] Valid loss: 0.0600
2023-02-06 12:05:21 | Valid | Epoch[368/600] Iteration[006/008] Valid loss: 0.0555
2023-02-06 12:05:21 | Valid | Epoch[368/600] Iteration[007/008] Valid loss: 0.0559
2023-02-06 12:05:21 | Valid | Epoch[368/600] Iteration[008/008] Valid loss: 0.0534
2023-02-06 12:05:21 | Valid | Epoch[368/600] MIou: 0.932731646262841
2023-02-06 12:05:21 | Valid | Epoch[368/600] Pixel Accuracy: 0.9886601765950521
2023-02-06 12:05:21 | Valid | Epoch[368/600] Mean Pixel Accuracy: 0.9496184462862579
2023-02-06 12:05:21 | Stage | Epoch[368/600] Train loss:0.0181
2023-02-06 12:05:21 | Stage | Epoch[368/600] Valid loss:0.0534
2023-02-06 12:05:21 | Stage | Epoch[368/600] LR:0.01

2023-02-06 12:05:21 | Train | Epoch[369/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 12:05:21 | Train | Epoch[369/600] Iteration[002/030] Train loss: 0.0174
2023-02-06 12:05:21 | Train | Epoch[369/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:05:21 | Train | Epoch[369/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[005/030] Train loss: 0.0182
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[007/030] Train loss: 0.0182
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[008/030] Train loss: 0.0180
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[009/030] Train loss: 0.0178
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[011/030] Train loss: 0.0183
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[012/030] Train loss: 0.0183
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[013/030] Train loss: 0.0181
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[015/030] Train loss: 0.0181
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[016/030] Train loss: 0.0182
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[017/030] Train loss: 0.0182
2023-02-06 12:05:22 | Train | Epoch[369/600] Iteration[018/030] Train loss: 0.0181
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[019/030] Train loss: 0.0180
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[020/030] Train loss: 0.0182
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[021/030] Train loss: 0.0182
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[024/030] Train loss: 0.0180
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[025/030] Train loss: 0.0180
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[026/030] Train loss: 0.0182
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[027/030] Train loss: 0.0182
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[028/030] Train loss: 0.0180
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[029/030] Train loss: 0.0179
2023-02-06 12:05:23 | Train | Epoch[369/600] Iteration[030/030] Train loss: 0.0179
2023-02-06 12:05:24 | Valid | Epoch[369/600] Iteration[001/008] Valid loss: 0.0823
2023-02-06 12:05:24 | Valid | Epoch[369/600] Iteration[002/008] Valid loss: 0.0580
2023-02-06 12:05:24 | Valid | Epoch[369/600] Iteration[003/008] Valid loss: 0.0523
2023-02-06 12:05:24 | Valid | Epoch[369/600] Iteration[004/008] Valid loss: 0.0466
2023-02-06 12:05:24 | Valid | Epoch[369/600] Iteration[005/008] Valid loss: 0.0442
2023-02-06 12:05:24 | Valid | Epoch[369/600] Iteration[006/008] Valid loss: 0.0420
2023-02-06 12:05:24 | Valid | Epoch[369/600] Iteration[007/008] Valid loss: 0.0433
2023-02-06 12:05:24 | Valid | Epoch[369/600] Iteration[008/008] Valid loss: 0.0421
2023-02-06 12:05:24 | Valid | Epoch[369/600] MIou: 0.9229449884140465
2023-02-06 12:05:24 | Valid | Epoch[369/600] Pixel Accuracy: 0.987097422281901
2023-02-06 12:05:24 | Valid | Epoch[369/600] Mean Pixel Accuracy: 0.9374417482168282
2023-02-06 12:05:24 | Stage | Epoch[369/600] Train loss:0.0179
2023-02-06 12:05:24 | Stage | Epoch[369/600] Valid loss:0.0421
2023-02-06 12:05:24 | Stage | Epoch[369/600] LR:0.01

2023-02-06 12:05:24 | Train | Epoch[370/600] Iteration[001/030] Train loss: 0.0176
2023-02-06 12:05:24 | Train | Epoch[370/600] Iteration[002/030] Train loss: 0.0168
2023-02-06 12:05:24 | Train | Epoch[370/600] Iteration[003/030] Train loss: 0.0177
2023-02-06 12:05:24 | Train | Epoch[370/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[005/030] Train loss: 0.0174
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[008/030] Train loss: 0.0174
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[009/030] Train loss: 0.0173
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[011/030] Train loss: 0.0175
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[012/030] Train loss: 0.0175
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[013/030] Train loss: 0.0175
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[014/030] Train loss: 0.0174
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[015/030] Train loss: 0.0173
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[016/030] Train loss: 0.0174
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[017/030] Train loss: 0.0174
2023-02-06 12:05:25 | Train | Epoch[370/600] Iteration[018/030] Train loss: 0.0174
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[019/030] Train loss: 0.0173
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[020/030] Train loss: 0.0174
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[021/030] Train loss: 0.0175
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[022/030] Train loss: 0.0176
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[023/030] Train loss: 0.0175
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[024/030] Train loss: 0.0175
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[025/030] Train loss: 0.0174
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[026/030] Train loss: 0.0175
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[027/030] Train loss: 0.0177
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[028/030] Train loss: 0.0177
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[029/030] Train loss: 0.0179
2023-02-06 12:05:26 | Train | Epoch[370/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 12:05:27 | Valid | Epoch[370/600] Iteration[001/008] Valid loss: 0.3824
2023-02-06 12:05:27 | Valid | Epoch[370/600] Iteration[002/008] Valid loss: 0.3077
2023-02-06 12:05:27 | Valid | Epoch[370/600] Iteration[003/008] Valid loss: 0.3084
2023-02-06 12:05:27 | Valid | Epoch[370/600] Iteration[004/008] Valid loss: 0.3049
2023-02-06 12:05:27 | Valid | Epoch[370/600] Iteration[005/008] Valid loss: 0.3199
2023-02-06 12:05:27 | Valid | Epoch[370/600] Iteration[006/008] Valid loss: 0.3059
2023-02-06 12:05:27 | Valid | Epoch[370/600] Iteration[007/008] Valid loss: 0.3278
2023-02-06 12:05:27 | Valid | Epoch[370/600] Iteration[008/008] Valid loss: 0.3251
2023-02-06 12:05:27 | Valid | Epoch[370/600] MIou: 0.9139189377404056
2023-02-06 12:05:27 | Valid | Epoch[370/600] Pixel Accuracy: 0.9838167826334635
2023-02-06 12:05:27 | Valid | Epoch[370/600] Mean Pixel Accuracy: 0.982672186426758
2023-02-06 12:05:27 | Stage | Epoch[370/600] Train loss:0.0180
2023-02-06 12:05:27 | Stage | Epoch[370/600] Valid loss:0.3251
2023-02-06 12:05:27 | Stage | Epoch[370/600] LR:0.01

2023-02-06 12:05:27 | Train | Epoch[371/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 12:05:27 | Train | Epoch[371/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:05:27 | Train | Epoch[371/600] Iteration[003/030] Train loss: 0.0176
2023-02-06 12:05:27 | Train | Epoch[371/600] Iteration[004/030] Train loss: 0.0171
2023-02-06 12:05:27 | Train | Epoch[371/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[006/030] Train loss: 0.0171
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[007/030] Train loss: 0.0174
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[008/030] Train loss: 0.0176
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[009/030] Train loss: 0.0175
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[010/030] Train loss: 0.0174
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[011/030] Train loss: 0.0175
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[012/030] Train loss: 0.0174
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[013/030] Train loss: 0.0174
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[014/030] Train loss: 0.0174
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[015/030] Train loss: 0.0174
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[016/030] Train loss: 0.0176
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[017/030] Train loss: 0.0174
2023-02-06 12:05:28 | Train | Epoch[371/600] Iteration[018/030] Train loss: 0.0176
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[019/030] Train loss: 0.0178
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[020/030] Train loss: 0.0178
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[021/030] Train loss: 0.0178
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[022/030] Train loss: 0.0179
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[023/030] Train loss: 0.0181
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[024/030] Train loss: 0.0180
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[025/030] Train loss: 0.0179
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[026/030] Train loss: 0.0179
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[027/030] Train loss: 0.0180
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[028/030] Train loss: 0.0181
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[029/030] Train loss: 0.0182
2023-02-06 12:05:29 | Train | Epoch[371/600] Iteration[030/030] Train loss: 0.0181
2023-02-06 12:05:30 | Valid | Epoch[371/600] Iteration[001/008] Valid loss: 0.0930
2023-02-06 12:05:30 | Valid | Epoch[371/600] Iteration[002/008] Valid loss: 0.0719
2023-02-06 12:05:30 | Valid | Epoch[371/600] Iteration[003/008] Valid loss: 0.0713
2023-02-06 12:05:30 | Valid | Epoch[371/600] Iteration[004/008] Valid loss: 0.0682
2023-02-06 12:05:30 | Valid | Epoch[371/600] Iteration[005/008] Valid loss: 0.0666
2023-02-06 12:05:30 | Valid | Epoch[371/600] Iteration[006/008] Valid loss: 0.0636
2023-02-06 12:05:30 | Valid | Epoch[371/600] Iteration[007/008] Valid loss: 0.0662
2023-02-06 12:05:30 | Valid | Epoch[371/600] Iteration[008/008] Valid loss: 0.0635
2023-02-06 12:05:30 | Valid | Epoch[371/600] MIou: 0.9243483831484384
2023-02-06 12:05:30 | Valid | Epoch[371/600] Pixel Accuracy: 0.9871139526367188
2023-02-06 12:05:30 | Valid | Epoch[371/600] Mean Pixel Accuracy: 0.9463528560077987
2023-02-06 12:05:30 | Stage | Epoch[371/600] Train loss:0.0181
2023-02-06 12:05:30 | Stage | Epoch[371/600] Valid loss:0.0635
2023-02-06 12:05:30 | Stage | Epoch[371/600] LR:0.01

2023-02-06 12:05:30 | Train | Epoch[372/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 12:05:30 | Train | Epoch[372/600] Iteration[002/030] Train loss: 0.0167
2023-02-06 12:05:30 | Train | Epoch[372/600] Iteration[003/030] Train loss: 0.0187
2023-02-06 12:05:30 | Train | Epoch[372/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 12:05:30 | Train | Epoch[372/600] Iteration[005/030] Train loss: 0.0182
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[006/030] Train loss: 0.0178
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[008/030] Train loss: 0.0180
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[009/030] Train loss: 0.0182
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[010/030] Train loss: 0.0185
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[011/030] Train loss: 0.0184
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[012/030] Train loss: 0.0182
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[013/030] Train loss: 0.0182
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[014/030] Train loss: 0.0183
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[015/030] Train loss: 0.0181
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[016/030] Train loss: 0.0180
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[017/030] Train loss: 0.0182
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[018/030] Train loss: 0.0181
2023-02-06 12:05:31 | Train | Epoch[372/600] Iteration[019/030] Train loss: 0.0181
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[020/030] Train loss: 0.0181
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[021/030] Train loss: 0.0181
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[022/030] Train loss: 0.0181
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[023/030] Train loss: 0.0180
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[024/030] Train loss: 0.0180
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[025/030] Train loss: 0.0180
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[026/030] Train loss: 0.0180
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[027/030] Train loss: 0.0180
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[028/030] Train loss: 0.0179
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[029/030] Train loss: 0.0179
2023-02-06 12:05:32 | Train | Epoch[372/600] Iteration[030/030] Train loss: 0.0179
2023-02-06 12:05:33 | Valid | Epoch[372/600] Iteration[001/008] Valid loss: 0.1381
2023-02-06 12:05:33 | Valid | Epoch[372/600] Iteration[002/008] Valid loss: 0.1407
2023-02-06 12:05:33 | Valid | Epoch[372/600] Iteration[003/008] Valid loss: 0.1508
2023-02-06 12:05:33 | Valid | Epoch[372/600] Iteration[004/008] Valid loss: 0.1476
2023-02-06 12:05:33 | Valid | Epoch[372/600] Iteration[005/008] Valid loss: 0.1517
2023-02-06 12:05:33 | Valid | Epoch[372/600] Iteration[006/008] Valid loss: 0.1487
2023-02-06 12:05:33 | Valid | Epoch[372/600] Iteration[007/008] Valid loss: 0.1454
2023-02-06 12:05:33 | Valid | Epoch[372/600] Iteration[008/008] Valid loss: 0.1520
2023-02-06 12:05:33 | Valid | Epoch[372/600] MIou: 0.5922576455158844
2023-02-06 12:05:33 | Valid | Epoch[372/600] Pixel Accuracy: 0.9325790405273438
2023-02-06 12:05:33 | Valid | Epoch[372/600] Mean Pixel Accuracy: 0.6267580847259571
2023-02-06 12:05:33 | Stage | Epoch[372/600] Train loss:0.0179
2023-02-06 12:05:33 | Stage | Epoch[372/600] Valid loss:0.1520
2023-02-06 12:05:33 | Stage | Epoch[372/600] LR:0.01

2023-02-06 12:05:33 | Train | Epoch[373/600] Iteration[001/030] Train loss: 0.0169
2023-02-06 12:05:33 | Train | Epoch[373/600] Iteration[002/030] Train loss: 0.0161
2023-02-06 12:05:33 | Train | Epoch[373/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:05:33 | Train | Epoch[373/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:05:33 | Train | Epoch[373/600] Iteration[005/030] Train loss: 0.0175
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[007/030] Train loss: 0.0174
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[008/030] Train loss: 0.0173
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[009/030] Train loss: 0.0177
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[010/030] Train loss: 0.0178
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[011/030] Train loss: 0.0181
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[012/030] Train loss: 0.0179
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[013/030] Train loss: 0.0178
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[015/030] Train loss: 0.0180
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[016/030] Train loss: 0.0180
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[018/030] Train loss: 0.0181
2023-02-06 12:05:34 | Train | Epoch[373/600] Iteration[019/030] Train loss: 0.0179
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[020/030] Train loss: 0.0181
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[021/030] Train loss: 0.0182
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[025/030] Train loss: 0.0182
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[026/030] Train loss: 0.0182
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[027/030] Train loss: 0.0182
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[028/030] Train loss: 0.0181
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[029/030] Train loss: 0.0182
2023-02-06 12:05:35 | Train | Epoch[373/600] Iteration[030/030] Train loss: 0.0182
2023-02-06 12:05:36 | Valid | Epoch[373/600] Iteration[001/008] Valid loss: 0.2181
2023-02-06 12:05:36 | Valid | Epoch[373/600] Iteration[002/008] Valid loss: 0.1901
2023-02-06 12:05:36 | Valid | Epoch[373/600] Iteration[003/008] Valid loss: 0.1771
2023-02-06 12:05:36 | Valid | Epoch[373/600] Iteration[004/008] Valid loss: 0.1724
2023-02-06 12:05:36 | Valid | Epoch[373/600] Iteration[005/008] Valid loss: 0.1709
2023-02-06 12:05:36 | Valid | Epoch[373/600] Iteration[006/008] Valid loss: 0.1681
2023-02-06 12:05:36 | Valid | Epoch[373/600] Iteration[007/008] Valid loss: 0.1767
2023-02-06 12:05:36 | Valid | Epoch[373/600] Iteration[008/008] Valid loss: 0.1748
2023-02-06 12:05:36 | Valid | Epoch[373/600] MIou: 0.9313779770749733
2023-02-06 12:05:36 | Valid | Epoch[373/600] Pixel Accuracy: 0.9876861572265625
2023-02-06 12:05:36 | Valid | Epoch[373/600] Mean Pixel Accuracy: 0.9776278864477981
2023-02-06 12:05:36 | Stage | Epoch[373/600] Train loss:0.0182
2023-02-06 12:05:36 | Stage | Epoch[373/600] Valid loss:0.1748
2023-02-06 12:05:36 | Stage | Epoch[373/600] LR:0.01

2023-02-06 12:05:36 | Train | Epoch[374/600] Iteration[001/030] Train loss: 0.0190
2023-02-06 12:05:36 | Train | Epoch[374/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:05:36 | Train | Epoch[374/600] Iteration[003/030] Train loss: 0.0175
2023-02-06 12:05:36 | Train | Epoch[374/600] Iteration[004/030] Train loss: 0.0177
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[008/030] Train loss: 0.0173
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[009/030] Train loss: 0.0174
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[010/030] Train loss: 0.0174
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[011/030] Train loss: 0.0173
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[012/030] Train loss: 0.0174
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[013/030] Train loss: 0.0174
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[014/030] Train loss: 0.0175
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[015/030] Train loss: 0.0177
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[016/030] Train loss: 0.0178
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[017/030] Train loss: 0.0177
2023-02-06 12:05:37 | Train | Epoch[374/600] Iteration[018/030] Train loss: 0.0177
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[019/030] Train loss: 0.0176
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[020/030] Train loss: 0.0175
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[021/030] Train loss: 0.0177
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[022/030] Train loss: 0.0177
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[023/030] Train loss: 0.0177
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[024/030] Train loss: 0.0178
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[025/030] Train loss: 0.0180
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[026/030] Train loss: 0.0179
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[027/030] Train loss: 0.0181
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[028/030] Train loss: 0.0182
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[029/030] Train loss: 0.0183
2023-02-06 12:05:38 | Train | Epoch[374/600] Iteration[030/030] Train loss: 0.0182
2023-02-06 12:05:39 | Valid | Epoch[374/600] Iteration[001/008] Valid loss: 0.0937
2023-02-06 12:05:39 | Valid | Epoch[374/600] Iteration[002/008] Valid loss: 0.0679
2023-02-06 12:05:39 | Valid | Epoch[374/600] Iteration[003/008] Valid loss: 0.0698
2023-02-06 12:05:39 | Valid | Epoch[374/600] Iteration[004/008] Valid loss: 0.0678
2023-02-06 12:05:39 | Valid | Epoch[374/600] Iteration[005/008] Valid loss: 0.0650
2023-02-06 12:05:39 | Valid | Epoch[374/600] Iteration[006/008] Valid loss: 0.0609
2023-02-06 12:05:39 | Valid | Epoch[374/600] Iteration[007/008] Valid loss: 0.0671
2023-02-06 12:05:39 | Valid | Epoch[374/600] Iteration[008/008] Valid loss: 0.0645
2023-02-06 12:05:39 | Valid | Epoch[374/600] MIou: 0.9248314517899875
2023-02-06 12:05:39 | Valid | Epoch[374/600] Pixel Accuracy: 0.987250010172526
2023-02-06 12:05:39 | Valid | Epoch[374/600] Mean Pixel Accuracy: 0.944924947283829
2023-02-06 12:05:39 | Stage | Epoch[374/600] Train loss:0.0182
2023-02-06 12:05:39 | Stage | Epoch[374/600] Valid loss:0.0645
2023-02-06 12:05:39 | Stage | Epoch[374/600] LR:0.01

2023-02-06 12:05:39 | Train | Epoch[375/600] Iteration[001/030] Train loss: 0.0158
2023-02-06 12:05:39 | Train | Epoch[375/600] Iteration[002/030] Train loss: 0.0173
2023-02-06 12:05:39 | Train | Epoch[375/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:05:39 | Train | Epoch[375/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[005/030] Train loss: 0.0178
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[012/030] Train loss: 0.0173
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[013/030] Train loss: 0.0174
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[014/030] Train loss: 0.0174
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[015/030] Train loss: 0.0175
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[016/030] Train loss: 0.0176
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[017/030] Train loss: 0.0175
2023-02-06 12:05:40 | Train | Epoch[375/600] Iteration[018/030] Train loss: 0.0173
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[019/030] Train loss: 0.0173
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[020/030] Train loss: 0.0173
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[021/030] Train loss: 0.0175
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[022/030] Train loss: 0.0175
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[023/030] Train loss: 0.0176
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[024/030] Train loss: 0.0177
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[025/030] Train loss: 0.0175
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[026/030] Train loss: 0.0177
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[027/030] Train loss: 0.0179
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[028/030] Train loss: 0.0180
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[029/030] Train loss: 0.0181
2023-02-06 12:05:41 | Train | Epoch[375/600] Iteration[030/030] Train loss: 0.0181
2023-02-06 12:05:42 | Valid | Epoch[375/600] Iteration[001/008] Valid loss: 0.1302
2023-02-06 12:05:42 | Valid | Epoch[375/600] Iteration[002/008] Valid loss: 0.0962
2023-02-06 12:05:42 | Valid | Epoch[375/600] Iteration[003/008] Valid loss: 0.0862
2023-02-06 12:05:42 | Valid | Epoch[375/600] Iteration[004/008] Valid loss: 0.0799
2023-02-06 12:05:42 | Valid | Epoch[375/600] Iteration[005/008] Valid loss: 0.0768
2023-02-06 12:05:42 | Valid | Epoch[375/600] Iteration[006/008] Valid loss: 0.0749
2023-02-06 12:05:42 | Valid | Epoch[375/600] Iteration[007/008] Valid loss: 0.0799
2023-02-06 12:05:42 | Valid | Epoch[375/600] Iteration[008/008] Valid loss: 0.0789
2023-02-06 12:05:42 | Valid | Epoch[375/600] MIou: 0.9360331622341911
2023-02-06 12:05:42 | Valid | Epoch[375/600] Pixel Accuracy: 0.9889793395996094
2023-02-06 12:05:42 | Valid | Epoch[375/600] Mean Pixel Accuracy: 0.9627664765992507
2023-02-06 12:05:42 | Stage | Epoch[375/600] Train loss:0.0181
2023-02-06 12:05:42 | Stage | Epoch[375/600] Valid loss:0.0789
2023-02-06 12:05:42 | Stage | Epoch[375/600] LR:0.01

2023-02-06 12:05:42 | Train | Epoch[376/600] Iteration[001/030] Train loss: 0.0230
2023-02-06 12:05:42 | Train | Epoch[376/600] Iteration[002/030] Train loss: 0.0213
2023-02-06 12:05:42 | Train | Epoch[376/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 12:05:42 | Train | Epoch[376/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 12:05:42 | Train | Epoch[376/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[007/030] Train loss: 0.0192
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[009/030] Train loss: 0.0190
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[010/030] Train loss: 0.0190
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[011/030] Train loss: 0.0188
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[012/030] Train loss: 0.0187
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[013/030] Train loss: 0.0188
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[014/030] Train loss: 0.0186
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[015/030] Train loss: 0.0184
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[017/030] Train loss: 0.0186
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[018/030] Train loss: 0.0186
2023-02-06 12:05:43 | Train | Epoch[376/600] Iteration[019/030] Train loss: 0.0186
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[020/030] Train loss: 0.0185
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[021/030] Train loss: 0.0185
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[022/030] Train loss: 0.0186
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[023/030] Train loss: 0.0186
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[024/030] Train loss: 0.0186
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[025/030] Train loss: 0.0185
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[026/030] Train loss: 0.0184
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[028/030] Train loss: 0.0183
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[029/030] Train loss: 0.0182
2023-02-06 12:05:44 | Train | Epoch[376/600] Iteration[030/030] Train loss: 0.0182
2023-02-06 12:05:45 | Valid | Epoch[376/600] Iteration[001/008] Valid loss: 0.3777
2023-02-06 12:05:45 | Valid | Epoch[376/600] Iteration[002/008] Valid loss: 0.3178
2023-02-06 12:05:45 | Valid | Epoch[376/600] Iteration[003/008] Valid loss: 0.3190
2023-02-06 12:05:45 | Valid | Epoch[376/600] Iteration[004/008] Valid loss: 0.3162
2023-02-06 12:05:45 | Valid | Epoch[376/600] Iteration[005/008] Valid loss: 0.3301
2023-02-06 12:05:45 | Valid | Epoch[376/600] Iteration[006/008] Valid loss: 0.3162
2023-02-06 12:05:45 | Valid | Epoch[376/600] Iteration[007/008] Valid loss: 0.3347
2023-02-06 12:05:45 | Valid | Epoch[376/600] Iteration[008/008] Valid loss: 0.3341
2023-02-06 12:05:45 | Valid | Epoch[376/600] MIou: 0.912777362416883
2023-02-06 12:05:45 | Valid | Epoch[376/600] Pixel Accuracy: 0.9835497538248698
2023-02-06 12:05:45 | Valid | Epoch[376/600] Mean Pixel Accuracy: 0.9830643560835783
2023-02-06 12:05:45 | Stage | Epoch[376/600] Train loss:0.0182
2023-02-06 12:05:45 | Stage | Epoch[376/600] Valid loss:0.3341
2023-02-06 12:05:45 | Stage | Epoch[376/600] LR:0.01

2023-02-06 12:05:45 | Train | Epoch[377/600] Iteration[001/030] Train loss: 0.0158
2023-02-06 12:05:45 | Train | Epoch[377/600] Iteration[002/030] Train loss: 0.0156
2023-02-06 12:05:45 | Train | Epoch[377/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:05:45 | Train | Epoch[377/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:05:45 | Train | Epoch[377/600] Iteration[005/030] Train loss: 0.0178
2023-02-06 12:05:45 | Train | Epoch[377/600] Iteration[006/030] Train loss: 0.0176
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[007/030] Train loss: 0.0176
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[008/030] Train loss: 0.0178
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[009/030] Train loss: 0.0185
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[010/030] Train loss: 0.0185
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[011/030] Train loss: 0.0186
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[012/030] Train loss: 0.0187
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[013/030] Train loss: 0.0185
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[015/030] Train loss: 0.0183
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[016/030] Train loss: 0.0184
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[018/030] Train loss: 0.0189
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[019/030] Train loss: 0.0188
2023-02-06 12:05:46 | Train | Epoch[377/600] Iteration[020/030] Train loss: 0.0189
2023-02-06 12:05:47 | Train | Epoch[377/600] Iteration[021/030] Train loss: 0.0188
2023-02-06 12:05:47 | Train | Epoch[377/600] Iteration[022/030] Train loss: 0.0188
2023-02-06 12:05:47 | Train | Epoch[377/600] Iteration[023/030] Train loss: 0.0189
2023-02-06 12:05:47 | Train | Epoch[377/600] Iteration[024/030] Train loss: 0.0189
2023-02-06 12:05:47 | Train | Epoch[377/600] Iteration[025/030] Train loss: 0.0190
2023-02-06 12:05:47 | Train | Epoch[377/600] Iteration[026/030] Train loss: 0.0189
2023-02-06 12:05:47 | Train | Epoch[377/600] Iteration[027/030] Train loss: 0.0190
2023-02-06 12:05:47 | Train | Epoch[377/600] Iteration[028/030] Train loss: 0.0189
2023-02-06 12:05:47 | Train | Epoch[377/600] Iteration[029/030] Train loss: 0.0190
2023-02-06 12:05:47 | Train | Epoch[377/600] Iteration[030/030] Train loss: 0.0190
2023-02-06 12:05:48 | Valid | Epoch[377/600] Iteration[001/008] Valid loss: 0.5034
2023-02-06 12:05:48 | Valid | Epoch[377/600] Iteration[002/008] Valid loss: 0.4224
2023-02-06 12:05:48 | Valid | Epoch[377/600] Iteration[003/008] Valid loss: 0.4304
2023-02-06 12:05:48 | Valid | Epoch[377/600] Iteration[004/008] Valid loss: 0.4384
2023-02-06 12:05:48 | Valid | Epoch[377/600] Iteration[005/008] Valid loss: 0.4545
2023-02-06 12:05:48 | Valid | Epoch[377/600] Iteration[006/008] Valid loss: 0.4357
2023-02-06 12:05:48 | Valid | Epoch[377/600] Iteration[007/008] Valid loss: 0.4596
2023-02-06 12:05:48 | Valid | Epoch[377/600] Iteration[008/008] Valid loss: 0.4564
2023-02-06 12:05:48 | Valid | Epoch[377/600] MIou: 0.9064653867765831
2023-02-06 12:05:48 | Valid | Epoch[377/600] Pixel Accuracy: 0.9821421305338541
2023-02-06 12:05:48 | Valid | Epoch[377/600] Mean Pixel Accuracy: 0.9824872209060294
2023-02-06 12:05:48 | Stage | Epoch[377/600] Train loss:0.0190
2023-02-06 12:05:48 | Stage | Epoch[377/600] Valid loss:0.4564
2023-02-06 12:05:48 | Stage | Epoch[377/600] LR:0.01

2023-02-06 12:05:48 | Train | Epoch[378/600] Iteration[001/030] Train loss: 0.0168
2023-02-06 12:05:48 | Train | Epoch[378/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:05:48 | Train | Epoch[378/600] Iteration[003/030] Train loss: 0.0181
2023-02-06 12:05:48 | Train | Epoch[378/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:05:48 | Train | Epoch[378/600] Iteration[005/030] Train loss: 0.0187
2023-02-06 12:05:48 | Train | Epoch[378/600] Iteration[006/030] Train loss: 0.0184
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[007/030] Train loss: 0.0186
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[008/030] Train loss: 0.0187
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[009/030] Train loss: 0.0187
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[010/030] Train loss: 0.0183
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[011/030] Train loss: 0.0181
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[013/030] Train loss: 0.0179
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[015/030] Train loss: 0.0180
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[016/030] Train loss: 0.0180
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:05:49 | Train | Epoch[378/600] Iteration[019/030] Train loss: 0.0181
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[020/030] Train loss: 0.0182
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[021/030] Train loss: 0.0182
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[023/030] Train loss: 0.0181
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[024/030] Train loss: 0.0181
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[025/030] Train loss: 0.0179
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[026/030] Train loss: 0.0180
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[027/030] Train loss: 0.0180
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[028/030] Train loss: 0.0181
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[029/030] Train loss: 0.0181
2023-02-06 12:05:50 | Train | Epoch[378/600] Iteration[030/030] Train loss: 0.0181
2023-02-06 12:05:51 | Valid | Epoch[378/600] Iteration[001/008] Valid loss: 0.0507
2023-02-06 12:05:51 | Valid | Epoch[378/600] Iteration[002/008] Valid loss: 0.0492
2023-02-06 12:05:51 | Valid | Epoch[378/600] Iteration[003/008] Valid loss: 0.0520
2023-02-06 12:05:51 | Valid | Epoch[378/600] Iteration[004/008] Valid loss: 0.0493
2023-02-06 12:05:51 | Valid | Epoch[378/600] Iteration[005/008] Valid loss: 0.0496
2023-02-06 12:05:51 | Valid | Epoch[378/600] Iteration[006/008] Valid loss: 0.0486
2023-02-06 12:05:51 | Valid | Epoch[378/600] Iteration[007/008] Valid loss: 0.0478
2023-02-06 12:05:51 | Valid | Epoch[378/600] Iteration[008/008] Valid loss: 0.0490
2023-02-06 12:05:51 | Valid | Epoch[378/600] MIou: 0.8361637645230431
2023-02-06 12:05:51 | Valid | Epoch[378/600] Pixel Accuracy: 0.9729398091634115
2023-02-06 12:05:51 | Valid | Epoch[378/600] Mean Pixel Accuracy: 0.8514504041378061
2023-02-06 12:05:51 | Stage | Epoch[378/600] Train loss:0.0181
2023-02-06 12:05:51 | Stage | Epoch[378/600] Valid loss:0.0490
2023-02-06 12:05:51 | Stage | Epoch[378/600] LR:0.01

2023-02-06 12:05:51 | Train | Epoch[379/600] Iteration[001/030] Train loss: 0.0163
2023-02-06 12:05:51 | Train | Epoch[379/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 12:05:51 | Train | Epoch[379/600] Iteration[003/030] Train loss: 0.0173
2023-02-06 12:05:51 | Train | Epoch[379/600] Iteration[004/030] Train loss: 0.0177
2023-02-06 12:05:51 | Train | Epoch[379/600] Iteration[005/030] Train loss: 0.0178
2023-02-06 12:05:51 | Train | Epoch[379/600] Iteration[006/030] Train loss: 0.0179
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[009/030] Train loss: 0.0181
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[011/030] Train loss: 0.0181
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[012/030] Train loss: 0.0181
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[013/030] Train loss: 0.0182
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[015/030] Train loss: 0.0179
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[016/030] Train loss: 0.0179
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[017/030] Train loss: 0.0179
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[018/030] Train loss: 0.0180
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[019/030] Train loss: 0.0179
2023-02-06 12:05:52 | Train | Epoch[379/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 12:05:53 | Train | Epoch[379/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 12:05:53 | Train | Epoch[379/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:05:53 | Train | Epoch[379/600] Iteration[023/030] Train loss: 0.0181
2023-02-06 12:05:53 | Train | Epoch[379/600] Iteration[024/030] Train loss: 0.0181
2023-02-06 12:05:53 | Train | Epoch[379/600] Iteration[025/030] Train loss: 0.0181
2023-02-06 12:05:53 | Train | Epoch[379/600] Iteration[026/030] Train loss: 0.0181
2023-02-06 12:05:53 | Train | Epoch[379/600] Iteration[027/030] Train loss: 0.0181
2023-02-06 12:05:53 | Train | Epoch[379/600] Iteration[028/030] Train loss: 0.0181
2023-02-06 12:05:53 | Train | Epoch[379/600] Iteration[029/030] Train loss: 0.0182
2023-02-06 12:05:53 | Train | Epoch[379/600] Iteration[030/030] Train loss: 0.0182
2023-02-06 12:05:53 | Valid | Epoch[379/600] Iteration[001/008] Valid loss: 0.7793
2023-02-06 12:05:54 | Valid | Epoch[379/600] Iteration[002/008] Valid loss: 0.7014
2023-02-06 12:05:54 | Valid | Epoch[379/600] Iteration[003/008] Valid loss: 0.7295
2023-02-06 12:05:54 | Valid | Epoch[379/600] Iteration[004/008] Valid loss: 0.7769
2023-02-06 12:05:54 | Valid | Epoch[379/600] Iteration[005/008] Valid loss: 0.8023
2023-02-06 12:05:54 | Valid | Epoch[379/600] Iteration[006/008] Valid loss: 0.7721
2023-02-06 12:05:54 | Valid | Epoch[379/600] Iteration[007/008] Valid loss: 0.7991
2023-02-06 12:05:54 | Valid | Epoch[379/600] Iteration[008/008] Valid loss: 0.7832
2023-02-06 12:05:54 | Valid | Epoch[379/600] MIou: 0.8947989335759563
2023-02-06 12:05:54 | Valid | Epoch[379/600] Pixel Accuracy: 0.9793853759765625
2023-02-06 12:05:54 | Valid | Epoch[379/600] Mean Pixel Accuracy: 0.9829565586118846
2023-02-06 12:05:54 | Stage | Epoch[379/600] Train loss:0.0182
2023-02-06 12:05:54 | Stage | Epoch[379/600] Valid loss:0.7832
2023-02-06 12:05:54 | Stage | Epoch[379/600] LR:0.01

2023-02-06 12:05:54 | Train | Epoch[380/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 12:05:54 | Train | Epoch[380/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 12:05:54 | Train | Epoch[380/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 12:05:54 | Train | Epoch[380/600] Iteration[004/030] Train loss: 0.0182
2023-02-06 12:05:54 | Train | Epoch[380/600] Iteration[005/030] Train loss: 0.0179
2023-02-06 12:05:54 | Train | Epoch[380/600] Iteration[006/030] Train loss: 0.0185
2023-02-06 12:05:54 | Train | Epoch[380/600] Iteration[007/030] Train loss: 0.0185
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[009/030] Train loss: 0.0182
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[011/030] Train loss: 0.0178
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[013/030] Train loss: 0.0177
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[014/030] Train loss: 0.0178
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[015/030] Train loss: 0.0178
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[016/030] Train loss: 0.0179
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[017/030] Train loss: 0.0178
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[018/030] Train loss: 0.0178
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[019/030] Train loss: 0.0178
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[020/030] Train loss: 0.0177
2023-02-06 12:05:55 | Train | Epoch[380/600] Iteration[021/030] Train loss: 0.0180
2023-02-06 12:05:56 | Train | Epoch[380/600] Iteration[022/030] Train loss: 0.0178
2023-02-06 12:05:56 | Train | Epoch[380/600] Iteration[023/030] Train loss: 0.0178
2023-02-06 12:05:56 | Train | Epoch[380/600] Iteration[024/030] Train loss: 0.0178
2023-02-06 12:05:56 | Train | Epoch[380/600] Iteration[025/030] Train loss: 0.0179
2023-02-06 12:05:56 | Train | Epoch[380/600] Iteration[026/030] Train loss: 0.0179
2023-02-06 12:05:56 | Train | Epoch[380/600] Iteration[027/030] Train loss: 0.0181
2023-02-06 12:05:56 | Train | Epoch[380/600] Iteration[028/030] Train loss: 0.0181
2023-02-06 12:05:56 | Train | Epoch[380/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 12:05:56 | Train | Epoch[380/600] Iteration[030/030] Train loss: 0.0183
2023-02-06 12:05:56 | Valid | Epoch[380/600] Iteration[001/008] Valid loss: 0.0487
2023-02-06 12:05:56 | Valid | Epoch[380/600] Iteration[002/008] Valid loss: 0.0437
2023-02-06 12:05:56 | Valid | Epoch[380/600] Iteration[003/008] Valid loss: 0.0461
2023-02-06 12:05:56 | Valid | Epoch[380/600] Iteration[004/008] Valid loss: 0.0429
2023-02-06 12:05:57 | Valid | Epoch[380/600] Iteration[005/008] Valid loss: 0.0426
2023-02-06 12:05:57 | Valid | Epoch[380/600] Iteration[006/008] Valid loss: 0.0414
2023-02-06 12:05:57 | Valid | Epoch[380/600] Iteration[007/008] Valid loss: 0.0414
2023-02-06 12:05:57 | Valid | Epoch[380/600] Iteration[008/008] Valid loss: 0.0414
2023-02-06 12:05:57 | Valid | Epoch[380/600] MIou: 0.8809297473972977
2023-02-06 12:05:57 | Valid | Epoch[380/600] Pixel Accuracy: 0.9802335103352865
2023-02-06 12:05:57 | Valid | Epoch[380/600] Mean Pixel Accuracy: 0.8947258734450104
2023-02-06 12:05:57 | Stage | Epoch[380/600] Train loss:0.0183
2023-02-06 12:05:57 | Stage | Epoch[380/600] Valid loss:0.0414
2023-02-06 12:05:57 | Stage | Epoch[380/600] LR:0.01

2023-02-06 12:05:57 | Train | Epoch[381/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 12:05:57 | Train | Epoch[381/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 12:05:57 | Train | Epoch[381/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:05:57 | Train | Epoch[381/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:05:57 | Train | Epoch[381/600] Iteration[005/030] Train loss: 0.0181
2023-02-06 12:05:57 | Train | Epoch[381/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:05:57 | Train | Epoch[381/600] Iteration[007/030] Train loss: 0.0177
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[008/030] Train loss: 0.0175
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[009/030] Train loss: 0.0177
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[010/030] Train loss: 0.0178
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[011/030] Train loss: 0.0177
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[013/030] Train loss: 0.0178
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[015/030] Train loss: 0.0179
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[016/030] Train loss: 0.0180
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[017/030] Train loss: 0.0180
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[018/030] Train loss: 0.0179
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[019/030] Train loss: 0.0179
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[020/030] Train loss: 0.0179
2023-02-06 12:05:58 | Train | Epoch[381/600] Iteration[021/030] Train loss: 0.0179
2023-02-06 12:05:59 | Train | Epoch[381/600] Iteration[022/030] Train loss: 0.0178
2023-02-06 12:05:59 | Train | Epoch[381/600] Iteration[023/030] Train loss: 0.0178
2023-02-06 12:05:59 | Train | Epoch[381/600] Iteration[024/030] Train loss: 0.0178
2023-02-06 12:05:59 | Train | Epoch[381/600] Iteration[025/030] Train loss: 0.0178
2023-02-06 12:05:59 | Train | Epoch[381/600] Iteration[026/030] Train loss: 0.0180
2023-02-06 12:05:59 | Train | Epoch[381/600] Iteration[027/030] Train loss: 0.0180
2023-02-06 12:05:59 | Train | Epoch[381/600] Iteration[028/030] Train loss: 0.0179
2023-02-06 12:05:59 | Train | Epoch[381/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 12:05:59 | Train | Epoch[381/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 12:05:59 | Valid | Epoch[381/600] Iteration[001/008] Valid loss: 0.0476
2023-02-06 12:05:59 | Valid | Epoch[381/600] Iteration[002/008] Valid loss: 0.0431
2023-02-06 12:05:59 | Valid | Epoch[381/600] Iteration[003/008] Valid loss: 0.0476
2023-02-06 12:06:00 | Valid | Epoch[381/600] Iteration[004/008] Valid loss: 0.0442
2023-02-06 12:06:00 | Valid | Epoch[381/600] Iteration[005/008] Valid loss: 0.0441
2023-02-06 12:06:00 | Valid | Epoch[381/600] Iteration[006/008] Valid loss: 0.0425
2023-02-06 12:06:00 | Valid | Epoch[381/600] Iteration[007/008] Valid loss: 0.0427
2023-02-06 12:06:00 | Valid | Epoch[381/600] Iteration[008/008] Valid loss: 0.0430
2023-02-06 12:06:00 | Valid | Epoch[381/600] MIou: 0.8728189679031815
2023-02-06 12:06:00 | Valid | Epoch[381/600] Pixel Accuracy: 0.9789250691731771
2023-02-06 12:06:00 | Valid | Epoch[381/600] Mean Pixel Accuracy: 0.8865122610513709
2023-02-06 12:06:00 | Stage | Epoch[381/600] Train loss:0.0180
2023-02-06 12:06:00 | Stage | Epoch[381/600] Valid loss:0.0430
2023-02-06 12:06:00 | Stage | Epoch[381/600] LR:0.01

2023-02-06 12:06:00 | Train | Epoch[382/600] Iteration[001/030] Train loss: 0.0172
2023-02-06 12:06:00 | Train | Epoch[382/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:06:00 | Train | Epoch[382/600] Iteration[003/030] Train loss: 0.0179
2023-02-06 12:06:00 | Train | Epoch[382/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:06:00 | Train | Epoch[382/600] Iteration[005/030] Train loss: 0.0172
2023-02-06 12:06:00 | Train | Epoch[382/600] Iteration[006/030] Train loss: 0.0171
2023-02-06 12:06:00 | Train | Epoch[382/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[009/030] Train loss: 0.0175
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[010/030] Train loss: 0.0175
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[011/030] Train loss: 0.0180
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[012/030] Train loss: 0.0177
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[013/030] Train loss: 0.0180
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[014/030] Train loss: 0.0179
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[015/030] Train loss: 0.0183
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[016/030] Train loss: 0.0182
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[017/030] Train loss: 0.0182
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[018/030] Train loss: 0.0183
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[020/030] Train loss: 0.0182
2023-02-06 12:06:01 | Train | Epoch[382/600] Iteration[021/030] Train loss: 0.0181
2023-02-06 12:06:02 | Train | Epoch[382/600] Iteration[022/030] Train loss: 0.0181
2023-02-06 12:06:02 | Train | Epoch[382/600] Iteration[023/030] Train loss: 0.0181
2023-02-06 12:06:02 | Train | Epoch[382/600] Iteration[024/030] Train loss: 0.0180
2023-02-06 12:06:02 | Train | Epoch[382/600] Iteration[025/030] Train loss: 0.0180
2023-02-06 12:06:02 | Train | Epoch[382/600] Iteration[026/030] Train loss: 0.0179
2023-02-06 12:06:02 | Train | Epoch[382/600] Iteration[027/030] Train loss: 0.0180
2023-02-06 12:06:02 | Train | Epoch[382/600] Iteration[028/030] Train loss: 0.0180
2023-02-06 12:06:02 | Train | Epoch[382/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 12:06:02 | Train | Epoch[382/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 12:06:02 | Valid | Epoch[382/600] Iteration[001/008] Valid loss: 0.0499
2023-02-06 12:06:02 | Valid | Epoch[382/600] Iteration[002/008] Valid loss: 0.0474
2023-02-06 12:06:02 | Valid | Epoch[382/600] Iteration[003/008] Valid loss: 0.0505
2023-02-06 12:06:02 | Valid | Epoch[382/600] Iteration[004/008] Valid loss: 0.0480
2023-02-06 12:06:03 | Valid | Epoch[382/600] Iteration[005/008] Valid loss: 0.0482
2023-02-06 12:06:03 | Valid | Epoch[382/600] Iteration[006/008] Valid loss: 0.0472
2023-02-06 12:06:03 | Valid | Epoch[382/600] Iteration[007/008] Valid loss: 0.0463
2023-02-06 12:06:03 | Valid | Epoch[382/600] Iteration[008/008] Valid loss: 0.0476
2023-02-06 12:06:03 | Valid | Epoch[382/600] MIou: 0.8385126159237168
2023-02-06 12:06:03 | Valid | Epoch[382/600] Pixel Accuracy: 0.973351796468099
2023-02-06 12:06:03 | Valid | Epoch[382/600] Mean Pixel Accuracy: 0.8533000106383886
2023-02-06 12:06:03 | Stage | Epoch[382/600] Train loss:0.0180
2023-02-06 12:06:03 | Stage | Epoch[382/600] Valid loss:0.0476
2023-02-06 12:06:03 | Stage | Epoch[382/600] LR:0.01

2023-02-06 12:06:03 | Train | Epoch[383/600] Iteration[001/030] Train loss: 0.0166
2023-02-06 12:06:03 | Train | Epoch[383/600] Iteration[002/030] Train loss: 0.0165
2023-02-06 12:06:03 | Train | Epoch[383/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:06:03 | Train | Epoch[383/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:06:03 | Train | Epoch[383/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:06:03 | Train | Epoch[383/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 12:06:03 | Train | Epoch[383/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[008/030] Train loss: 0.0174
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[012/030] Train loss: 0.0170
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[014/030] Train loss: 0.0170
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[015/030] Train loss: 0.0171
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[016/030] Train loss: 0.0171
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[017/030] Train loss: 0.0173
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[018/030] Train loss: 0.0173
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[019/030] Train loss: 0.0175
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[020/030] Train loss: 0.0173
2023-02-06 12:06:04 | Train | Epoch[383/600] Iteration[021/030] Train loss: 0.0173
2023-02-06 12:06:05 | Train | Epoch[383/600] Iteration[022/030] Train loss: 0.0174
2023-02-06 12:06:05 | Train | Epoch[383/600] Iteration[023/030] Train loss: 0.0175
2023-02-06 12:06:05 | Train | Epoch[383/600] Iteration[024/030] Train loss: 0.0175
2023-02-06 12:06:05 | Train | Epoch[383/600] Iteration[025/030] Train loss: 0.0178
2023-02-06 12:06:05 | Train | Epoch[383/600] Iteration[026/030] Train loss: 0.0178
2023-02-06 12:06:05 | Train | Epoch[383/600] Iteration[027/030] Train loss: 0.0179
2023-02-06 12:06:05 | Train | Epoch[383/600] Iteration[028/030] Train loss: 0.0178
2023-02-06 12:06:05 | Train | Epoch[383/600] Iteration[029/030] Train loss: 0.0178
2023-02-06 12:06:05 | Train | Epoch[383/600] Iteration[030/030] Train loss: 0.0178
2023-02-06 12:06:05 | Valid | Epoch[383/600] Iteration[001/008] Valid loss: 0.0568
2023-02-06 12:06:05 | Valid | Epoch[383/600] Iteration[002/008] Valid loss: 0.0499
2023-02-06 12:06:05 | Valid | Epoch[383/600] Iteration[003/008] Valid loss: 0.0508
2023-02-06 12:06:06 | Valid | Epoch[383/600] Iteration[004/008] Valid loss: 0.0479
2023-02-06 12:06:06 | Valid | Epoch[383/600] Iteration[005/008] Valid loss: 0.0476
2023-02-06 12:06:06 | Valid | Epoch[383/600] Iteration[006/008] Valid loss: 0.0469
2023-02-06 12:06:06 | Valid | Epoch[383/600] Iteration[007/008] Valid loss: 0.0465
2023-02-06 12:06:06 | Valid | Epoch[383/600] Iteration[008/008] Valid loss: 0.0469
2023-02-06 12:06:06 | Valid | Epoch[383/600] MIou: 0.8621936435323704
2023-02-06 12:06:06 | Valid | Epoch[383/600] Pixel Accuracy: 0.977227528889974
2023-02-06 12:06:06 | Valid | Epoch[383/600] Mean Pixel Accuracy: 0.8756437016539513
2023-02-06 12:06:06 | Stage | Epoch[383/600] Train loss:0.0178
2023-02-06 12:06:06 | Stage | Epoch[383/600] Valid loss:0.0469
2023-02-06 12:06:06 | Stage | Epoch[383/600] LR:0.01

2023-02-06 12:06:06 | Train | Epoch[384/600] Iteration[001/030] Train loss: 0.0158
2023-02-06 12:06:06 | Train | Epoch[384/600] Iteration[002/030] Train loss: 0.0157
2023-02-06 12:06:06 | Train | Epoch[384/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:06:06 | Train | Epoch[384/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:06:06 | Train | Epoch[384/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 12:06:06 | Train | Epoch[384/600] Iteration[006/030] Train loss: 0.0179
2023-02-06 12:06:06 | Train | Epoch[384/600] Iteration[007/030] Train loss: 0.0176
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[008/030] Train loss: 0.0176
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[009/030] Train loss: 0.0178
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[011/030] Train loss: 0.0180
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[013/030] Train loss: 0.0178
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[014/030] Train loss: 0.0176
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[015/030] Train loss: 0.0178
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[016/030] Train loss: 0.0177
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[017/030] Train loss: 0.0178
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[018/030] Train loss: 0.0178
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[019/030] Train loss: 0.0177
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[020/030] Train loss: 0.0177
2023-02-06 12:06:07 | Train | Epoch[384/600] Iteration[021/030] Train loss: 0.0177
2023-02-06 12:06:08 | Train | Epoch[384/600] Iteration[022/030] Train loss: 0.0177
2023-02-06 12:06:08 | Train | Epoch[384/600] Iteration[023/030] Train loss: 0.0177
2023-02-06 12:06:08 | Train | Epoch[384/600] Iteration[024/030] Train loss: 0.0178
2023-02-06 12:06:08 | Train | Epoch[384/600] Iteration[025/030] Train loss: 0.0179
2023-02-06 12:06:08 | Train | Epoch[384/600] Iteration[026/030] Train loss: 0.0181
2023-02-06 12:06:08 | Train | Epoch[384/600] Iteration[027/030] Train loss: 0.0181
2023-02-06 12:06:08 | Train | Epoch[384/600] Iteration[028/030] Train loss: 0.0180
2023-02-06 12:06:08 | Train | Epoch[384/600] Iteration[029/030] Train loss: 0.0179
2023-02-06 12:06:08 | Train | Epoch[384/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 12:06:08 | Valid | Epoch[384/600] Iteration[001/008] Valid loss: 0.1497
2023-02-06 12:06:08 | Valid | Epoch[384/600] Iteration[002/008] Valid loss: 0.1114
2023-02-06 12:06:09 | Valid | Epoch[384/600] Iteration[003/008] Valid loss: 0.1074
2023-02-06 12:06:09 | Valid | Epoch[384/600] Iteration[004/008] Valid loss: 0.0970
2023-02-06 12:06:09 | Valid | Epoch[384/600] Iteration[005/008] Valid loss: 0.0938
2023-02-06 12:06:09 | Valid | Epoch[384/600] Iteration[006/008] Valid loss: 0.0870
2023-02-06 12:06:09 | Valid | Epoch[384/600] Iteration[007/008] Valid loss: 0.0888
2023-02-06 12:06:09 | Valid | Epoch[384/600] Iteration[008/008] Valid loss: 0.0844
2023-02-06 12:06:09 | Valid | Epoch[384/600] MIou: 0.9409751454717843
2023-02-06 12:06:09 | Valid | Epoch[384/600] Pixel Accuracy: 0.9899304707845052
2023-02-06 12:06:09 | Valid | Epoch[384/600] Mean Pixel Accuracy: 0.9629024901009966
2023-02-06 12:06:09 | Stage | Epoch[384/600] Train loss:0.0180
2023-02-06 12:06:09 | Stage | Epoch[384/600] Valid loss:0.0844
2023-02-06 12:06:09 | Stage | Epoch[384/600] LR:0.01

2023-02-06 12:06:09 | Train | Epoch[385/600] Iteration[001/030] Train loss: 0.0190
2023-02-06 12:06:09 | Train | Epoch[385/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:06:09 | Train | Epoch[385/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 12:06:09 | Train | Epoch[385/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 12:06:09 | Train | Epoch[385/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:06:09 | Train | Epoch[385/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[014/030] Train loss: 0.0170
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[015/030] Train loss: 0.0171
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[016/030] Train loss: 0.0171
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[017/030] Train loss: 0.0171
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[018/030] Train loss: 0.0172
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[019/030] Train loss: 0.0173
2023-02-06 12:06:10 | Train | Epoch[385/600] Iteration[020/030] Train loss: 0.0173
2023-02-06 12:06:11 | Train | Epoch[385/600] Iteration[021/030] Train loss: 0.0174
2023-02-06 12:06:11 | Train | Epoch[385/600] Iteration[022/030] Train loss: 0.0174
2023-02-06 12:06:11 | Train | Epoch[385/600] Iteration[023/030] Train loss: 0.0176
2023-02-06 12:06:11 | Train | Epoch[385/600] Iteration[024/030] Train loss: 0.0176
2023-02-06 12:06:11 | Train | Epoch[385/600] Iteration[025/030] Train loss: 0.0176
2023-02-06 12:06:11 | Train | Epoch[385/600] Iteration[026/030] Train loss: 0.0177
2023-02-06 12:06:11 | Train | Epoch[385/600] Iteration[027/030] Train loss: 0.0178
2023-02-06 12:06:11 | Train | Epoch[385/600] Iteration[028/030] Train loss: 0.0178
2023-02-06 12:06:11 | Train | Epoch[385/600] Iteration[029/030] Train loss: 0.0179
2023-02-06 12:06:11 | Train | Epoch[385/600] Iteration[030/030] Train loss: 0.0178
2023-02-06 12:06:12 | Valid | Epoch[385/600] Iteration[001/008] Valid loss: 0.5054
2023-02-06 12:06:12 | Valid | Epoch[385/600] Iteration[002/008] Valid loss: 0.4411
2023-02-06 12:06:12 | Valid | Epoch[385/600] Iteration[003/008] Valid loss: 0.4343
2023-02-06 12:06:12 | Valid | Epoch[385/600] Iteration[004/008] Valid loss: 0.4485
2023-02-06 12:06:12 | Valid | Epoch[385/600] Iteration[005/008] Valid loss: 0.4631
2023-02-06 12:06:12 | Valid | Epoch[385/600] Iteration[006/008] Valid loss: 0.4524
2023-02-06 12:06:12 | Valid | Epoch[385/600] Iteration[007/008] Valid loss: 0.4747
2023-02-06 12:06:12 | Valid | Epoch[385/600] Iteration[008/008] Valid loss: 0.4672
2023-02-06 12:06:12 | Valid | Epoch[385/600] MIou: 0.8969809121335001
2023-02-06 12:06:12 | Valid | Epoch[385/600] Pixel Accuracy: 0.9798240661621094
2023-02-06 12:06:12 | Valid | Epoch[385/600] Mean Pixel Accuracy: 0.9850744610151208
2023-02-06 12:06:12 | Stage | Epoch[385/600] Train loss:0.0178
2023-02-06 12:06:12 | Stage | Epoch[385/600] Valid loss:0.4672
2023-02-06 12:06:12 | Stage | Epoch[385/600] LR:0.01

2023-02-06 12:06:12 | Train | Epoch[386/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 12:06:12 | Train | Epoch[386/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 12:06:12 | Train | Epoch[386/600] Iteration[003/030] Train loss: 0.0172
2023-02-06 12:06:12 | Train | Epoch[386/600] Iteration[004/030] Train loss: 0.0171
2023-02-06 12:06:12 | Train | Epoch[386/600] Iteration[005/030] Train loss: 0.0175
2023-02-06 12:06:12 | Train | Epoch[386/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[009/030] Train loss: 0.0173
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[011/030] Train loss: 0.0173
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[012/030] Train loss: 0.0174
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[013/030] Train loss: 0.0174
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[014/030] Train loss: 0.0174
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[015/030] Train loss: 0.0174
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[016/030] Train loss: 0.0174
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[017/030] Train loss: 0.0173
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[018/030] Train loss: 0.0173
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[019/030] Train loss: 0.0173
2023-02-06 12:06:13 | Train | Epoch[386/600] Iteration[020/030] Train loss: 0.0173
2023-02-06 12:06:14 | Train | Epoch[386/600] Iteration[021/030] Train loss: 0.0173
2023-02-06 12:06:14 | Train | Epoch[386/600] Iteration[022/030] Train loss: 0.0174
2023-02-06 12:06:14 | Train | Epoch[386/600] Iteration[023/030] Train loss: 0.0173
2023-02-06 12:06:14 | Train | Epoch[386/600] Iteration[024/030] Train loss: 0.0175
2023-02-06 12:06:14 | Train | Epoch[386/600] Iteration[025/030] Train loss: 0.0175
2023-02-06 12:06:14 | Train | Epoch[386/600] Iteration[026/030] Train loss: 0.0176
2023-02-06 12:06:14 | Train | Epoch[386/600] Iteration[027/030] Train loss: 0.0176
2023-02-06 12:06:14 | Train | Epoch[386/600] Iteration[028/030] Train loss: 0.0178
2023-02-06 12:06:14 | Train | Epoch[386/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 12:06:14 | Train | Epoch[386/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 12:06:15 | Valid | Epoch[386/600] Iteration[001/008] Valid loss: 0.1374
2023-02-06 12:06:15 | Valid | Epoch[386/600] Iteration[002/008] Valid loss: 0.0986
2023-02-06 12:06:15 | Valid | Epoch[386/600] Iteration[003/008] Valid loss: 0.0970
2023-02-06 12:06:15 | Valid | Epoch[386/600] Iteration[004/008] Valid loss: 0.0889
2023-02-06 12:06:15 | Valid | Epoch[386/600] Iteration[005/008] Valid loss: 0.0875
2023-02-06 12:06:15 | Valid | Epoch[386/600] Iteration[006/008] Valid loss: 0.0831
2023-02-06 12:06:15 | Valid | Epoch[386/600] Iteration[007/008] Valid loss: 0.0897
2023-02-06 12:06:15 | Valid | Epoch[386/600] Iteration[008/008] Valid loss: 0.0859
2023-02-06 12:06:15 | Valid | Epoch[386/600] MIou: 0.9402503431782836
2023-02-06 12:06:15 | Valid | Epoch[386/600] Pixel Accuracy: 0.9896647135416666
2023-02-06 12:06:15 | Valid | Epoch[386/600] Mean Pixel Accuracy: 0.9687164618074153
2023-02-06 12:06:15 | Stage | Epoch[386/600] Train loss:0.0180
2023-02-06 12:06:15 | Stage | Epoch[386/600] Valid loss:0.0859
2023-02-06 12:06:15 | Stage | Epoch[386/600] LR:0.01

2023-02-06 12:06:15 | Train | Epoch[387/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 12:06:15 | Train | Epoch[387/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 12:06:15 | Train | Epoch[387/600] Iteration[003/030] Train loss: 0.0179
2023-02-06 12:06:15 | Train | Epoch[387/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:06:15 | Train | Epoch[387/600] Iteration[005/030] Train loss: 0.0168
2023-02-06 12:06:15 | Train | Epoch[387/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[013/030] Train loss: 0.0175
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[014/030] Train loss: 0.0176
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[015/030] Train loss: 0.0178
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[016/030] Train loss: 0.0178
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[017/030] Train loss: 0.0179
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[018/030] Train loss: 0.0179
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[019/030] Train loss: 0.0180
2023-02-06 12:06:16 | Train | Epoch[387/600] Iteration[020/030] Train loss: 0.0180
2023-02-06 12:06:17 | Train | Epoch[387/600] Iteration[021/030] Train loss: 0.0181
2023-02-06 12:06:17 | Train | Epoch[387/600] Iteration[022/030] Train loss: 0.0181
2023-02-06 12:06:17 | Train | Epoch[387/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:06:17 | Train | Epoch[387/600] Iteration[024/030] Train loss: 0.0181
2023-02-06 12:06:17 | Train | Epoch[387/600] Iteration[025/030] Train loss: 0.0182
2023-02-06 12:06:17 | Train | Epoch[387/600] Iteration[026/030] Train loss: 0.0181
2023-02-06 12:06:17 | Train | Epoch[387/600] Iteration[027/030] Train loss: 0.0182
2023-02-06 12:06:17 | Train | Epoch[387/600] Iteration[028/030] Train loss: 0.0182
2023-02-06 12:06:17 | Train | Epoch[387/600] Iteration[029/030] Train loss: 0.0184
2023-02-06 12:06:17 | Train | Epoch[387/600] Iteration[030/030] Train loss: 0.0183
2023-02-06 12:06:18 | Valid | Epoch[387/600] Iteration[001/008] Valid loss: 0.1076
2023-02-06 12:06:18 | Valid | Epoch[387/600] Iteration[002/008] Valid loss: 0.0749
2023-02-06 12:06:18 | Valid | Epoch[387/600] Iteration[003/008] Valid loss: 0.0704
2023-02-06 12:06:18 | Valid | Epoch[387/600] Iteration[004/008] Valid loss: 0.0639
2023-02-06 12:06:18 | Valid | Epoch[387/600] Iteration[005/008] Valid loss: 0.0605
2023-02-06 12:06:18 | Valid | Epoch[387/600] Iteration[006/008] Valid loss: 0.0575
2023-02-06 12:06:18 | Valid | Epoch[387/600] Iteration[007/008] Valid loss: 0.0602
2023-02-06 12:06:18 | Valid | Epoch[387/600] Iteration[008/008] Valid loss: 0.0583
2023-02-06 12:06:18 | Valid | Epoch[387/600] MIou: 0.9328388462455899
2023-02-06 12:06:18 | Valid | Epoch[387/600] Pixel Accuracy: 0.9885915120442709
2023-02-06 12:06:18 | Valid | Epoch[387/600] Mean Pixel Accuracy: 0.9531820931395376
2023-02-06 12:06:18 | Stage | Epoch[387/600] Train loss:0.0183
2023-02-06 12:06:18 | Stage | Epoch[387/600] Valid loss:0.0583
2023-02-06 12:06:18 | Stage | Epoch[387/600] LR:0.01

2023-02-06 12:06:18 | Train | Epoch[388/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 12:06:18 | Train | Epoch[388/600] Iteration[002/030] Train loss: 0.0178
2023-02-06 12:06:18 | Train | Epoch[388/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 12:06:18 | Train | Epoch[388/600] Iteration[004/030] Train loss: 0.0185
2023-02-06 12:06:18 | Train | Epoch[388/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[006/030] Train loss: 0.0184
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[007/030] Train loss: 0.0180
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[008/030] Train loss: 0.0182
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[009/030] Train loss: 0.0181
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[011/030] Train loss: 0.0181
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[012/030] Train loss: 0.0182
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[013/030] Train loss: 0.0183
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[015/030] Train loss: 0.0181
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[016/030] Train loss: 0.0181
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:06:19 | Train | Epoch[388/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[020/030] Train loss: 0.0183
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[021/030] Train loss: 0.0182
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[022/030] Train loss: 0.0183
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[023/030] Train loss: 0.0184
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[025/030] Train loss: 0.0182
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[026/030] Train loss: 0.0182
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[027/030] Train loss: 0.0182
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[028/030] Train loss: 0.0182
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[029/030] Train loss: 0.0181
2023-02-06 12:06:20 | Train | Epoch[388/600] Iteration[030/030] Train loss: 0.0182
2023-02-06 12:06:21 | Valid | Epoch[388/600] Iteration[001/008] Valid loss: 0.5668
2023-02-06 12:06:21 | Valid | Epoch[388/600] Iteration[002/008] Valid loss: 0.5515
2023-02-06 12:06:21 | Valid | Epoch[388/600] Iteration[003/008] Valid loss: 0.5572
2023-02-06 12:06:21 | Valid | Epoch[388/600] Iteration[004/008] Valid loss: 0.5686
2023-02-06 12:06:21 | Valid | Epoch[388/600] Iteration[005/008] Valid loss: 0.5896
2023-02-06 12:06:21 | Valid | Epoch[388/600] Iteration[006/008] Valid loss: 0.5729
2023-02-06 12:06:21 | Valid | Epoch[388/600] Iteration[007/008] Valid loss: 0.6037
2023-02-06 12:06:21 | Valid | Epoch[388/600] Iteration[008/008] Valid loss: 0.6107
2023-02-06 12:06:21 | Valid | Epoch[388/600] MIou: 0.8895601696352934
2023-02-06 12:06:21 | Valid | Epoch[388/600] Pixel Accuracy: 0.9780731201171875
2023-02-06 12:06:21 | Valid | Epoch[388/600] Mean Pixel Accuracy: 0.9838267451747453
2023-02-06 12:06:21 | Stage | Epoch[388/600] Train loss:0.0182
2023-02-06 12:06:21 | Stage | Epoch[388/600] Valid loss:0.6107
2023-02-06 12:06:21 | Stage | Epoch[388/600] LR:0.01

2023-02-06 12:06:21 | Train | Epoch[389/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 12:06:21 | Train | Epoch[389/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 12:06:21 | Train | Epoch[389/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 12:06:21 | Train | Epoch[389/600] Iteration[004/030] Train loss: 0.0191
2023-02-06 12:06:21 | Train | Epoch[389/600] Iteration[005/030] Train loss: 0.0185
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[006/030] Train loss: 0.0185
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[007/030] Train loss: 0.0180
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[008/030] Train loss: 0.0179
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[009/030] Train loss: 0.0178
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[011/030] Train loss: 0.0179
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[012/030] Train loss: 0.0179
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[013/030] Train loss: 0.0180
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[015/030] Train loss: 0.0181
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[016/030] Train loss: 0.0180
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:06:22 | Train | Epoch[389/600] Iteration[019/030] Train loss: 0.0181
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[020/030] Train loss: 0.0182
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[021/030] Train loss: 0.0182
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[022/030] Train loss: 0.0183
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[023/030] Train loss: 0.0183
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[025/030] Train loss: 0.0183
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[028/030] Train loss: 0.0182
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[029/030] Train loss: 0.0182
2023-02-06 12:06:23 | Train | Epoch[389/600] Iteration[030/030] Train loss: 0.0182
2023-02-06 12:06:24 | Valid | Epoch[389/600] Iteration[001/008] Valid loss: 0.0728
2023-02-06 12:06:24 | Valid | Epoch[389/600] Iteration[002/008] Valid loss: 0.0618
2023-02-06 12:06:24 | Valid | Epoch[389/600] Iteration[003/008] Valid loss: 0.0617
2023-02-06 12:06:24 | Valid | Epoch[389/600] Iteration[004/008] Valid loss: 0.0571
2023-02-06 12:06:24 | Valid | Epoch[389/600] Iteration[005/008] Valid loss: 0.0560
2023-02-06 12:06:24 | Valid | Epoch[389/600] Iteration[006/008] Valid loss: 0.0532
2023-02-06 12:06:24 | Valid | Epoch[389/600] Iteration[007/008] Valid loss: 0.0529
2023-02-06 12:06:24 | Valid | Epoch[389/600] Iteration[008/008] Valid loss: 0.0523
2023-02-06 12:06:24 | Valid | Epoch[389/600] MIou: 0.8761836870970756
2023-02-06 12:06:24 | Valid | Epoch[389/600] Pixel Accuracy: 0.9794603983561198
2023-02-06 12:06:24 | Valid | Epoch[389/600] Mean Pixel Accuracy: 0.8900464817442264
2023-02-06 12:06:24 | Stage | Epoch[389/600] Train loss:0.0182
2023-02-06 12:06:24 | Stage | Epoch[389/600] Valid loss:0.0523
2023-02-06 12:06:24 | Stage | Epoch[389/600] LR:0.01

2023-02-06 12:06:24 | Train | Epoch[390/600] Iteration[001/030] Train loss: 0.0173
2023-02-06 12:06:24 | Train | Epoch[390/600] Iteration[002/030] Train loss: 0.0179
2023-02-06 12:06:24 | Train | Epoch[390/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 12:06:24 | Train | Epoch[390/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:06:24 | Train | Epoch[390/600] Iteration[005/030] Train loss: 0.0181
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[006/030] Train loss: 0.0175
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[007/030] Train loss: 0.0175
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[008/030] Train loss: 0.0174
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[009/030] Train loss: 0.0173
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[011/030] Train loss: 0.0173
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[012/030] Train loss: 0.0172
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[013/030] Train loss: 0.0172
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[014/030] Train loss: 0.0173
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[015/030] Train loss: 0.0171
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[016/030] Train loss: 0.0172
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[017/030] Train loss: 0.0174
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[018/030] Train loss: 0.0174
2023-02-06 12:06:25 | Train | Epoch[390/600] Iteration[019/030] Train loss: 0.0173
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[020/030] Train loss: 0.0175
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[021/030] Train loss: 0.0177
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[022/030] Train loss: 0.0177
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[023/030] Train loss: 0.0176
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[024/030] Train loss: 0.0176
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[025/030] Train loss: 0.0177
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[026/030] Train loss: 0.0177
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[027/030] Train loss: 0.0178
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[028/030] Train loss: 0.0178
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[029/030] Train loss: 0.0178
2023-02-06 12:06:26 | Train | Epoch[390/600] Iteration[030/030] Train loss: 0.0178
2023-02-06 12:06:27 | Valid | Epoch[390/600] Iteration[001/008] Valid loss: 0.5395
2023-02-06 12:06:27 | Valid | Epoch[390/600] Iteration[002/008] Valid loss: 0.4708
2023-02-06 12:06:27 | Valid | Epoch[390/600] Iteration[003/008] Valid loss: 0.4766
2023-02-06 12:06:27 | Valid | Epoch[390/600] Iteration[004/008] Valid loss: 0.4984
2023-02-06 12:06:27 | Valid | Epoch[390/600] Iteration[005/008] Valid loss: 0.5191
2023-02-06 12:06:27 | Valid | Epoch[390/600] Iteration[006/008] Valid loss: 0.5079
2023-02-06 12:06:27 | Valid | Epoch[390/600] Iteration[007/008] Valid loss: 0.5426
2023-02-06 12:06:27 | Valid | Epoch[390/600] Iteration[008/008] Valid loss: 0.5402
2023-02-06 12:06:27 | Valid | Epoch[390/600] MIou: 0.8907551397682787
2023-02-06 12:06:27 | Valid | Epoch[390/600] Pixel Accuracy: 0.9784151713053385
2023-02-06 12:06:27 | Valid | Epoch[390/600] Mean Pixel Accuracy: 0.9826895925498588
2023-02-06 12:06:27 | Stage | Epoch[390/600] Train loss:0.0178
2023-02-06 12:06:27 | Stage | Epoch[390/600] Valid loss:0.5402
2023-02-06 12:06:27 | Stage | Epoch[390/600] LR:0.01

2023-02-06 12:06:27 | Train | Epoch[391/600] Iteration[001/030] Train loss: 0.0159
2023-02-06 12:06:27 | Train | Epoch[391/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:06:27 | Train | Epoch[391/600] Iteration[003/030] Train loss: 0.0176
2023-02-06 12:06:27 | Train | Epoch[391/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 12:06:27 | Train | Epoch[391/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:06:27 | Train | Epoch[391/600] Iteration[006/030] Train loss: 0.0177
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[007/030] Train loss: 0.0176
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[008/030] Train loss: 0.0177
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[009/030] Train loss: 0.0173
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[010/030] Train loss: 0.0177
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[011/030] Train loss: 0.0179
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[013/030] Train loss: 0.0181
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[014/030] Train loss: 0.0186
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[015/030] Train loss: 0.0186
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 12:06:28 | Train | Epoch[391/600] Iteration[020/030] Train loss: 0.0185
2023-02-06 12:06:29 | Train | Epoch[391/600] Iteration[021/030] Train loss: 0.0184
2023-02-06 12:06:29 | Train | Epoch[391/600] Iteration[022/030] Train loss: 0.0184
2023-02-06 12:06:29 | Train | Epoch[391/600] Iteration[023/030] Train loss: 0.0183
2023-02-06 12:06:29 | Train | Epoch[391/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:06:29 | Train | Epoch[391/600] Iteration[025/030] Train loss: 0.0184
2023-02-06 12:06:29 | Train | Epoch[391/600] Iteration[026/030] Train loss: 0.0184
2023-02-06 12:06:29 | Train | Epoch[391/600] Iteration[027/030] Train loss: 0.0185
2023-02-06 12:06:29 | Train | Epoch[391/600] Iteration[028/030] Train loss: 0.0184
2023-02-06 12:06:29 | Train | Epoch[391/600] Iteration[029/030] Train loss: 0.0185
2023-02-06 12:06:29 | Train | Epoch[391/600] Iteration[030/030] Train loss: 0.0183
2023-02-06 12:06:30 | Valid | Epoch[391/600] Iteration[001/008] Valid loss: 0.2075
2023-02-06 12:06:30 | Valid | Epoch[391/600] Iteration[002/008] Valid loss: 0.1499
2023-02-06 12:06:30 | Valid | Epoch[391/600] Iteration[003/008] Valid loss: 0.1473
2023-02-06 12:06:30 | Valid | Epoch[391/600] Iteration[004/008] Valid loss: 0.1414
2023-02-06 12:06:30 | Valid | Epoch[391/600] Iteration[005/008] Valid loss: 0.1484
2023-02-06 12:06:30 | Valid | Epoch[391/600] Iteration[006/008] Valid loss: 0.1415
2023-02-06 12:06:30 | Valid | Epoch[391/600] Iteration[007/008] Valid loss: 0.1540
2023-02-06 12:06:30 | Valid | Epoch[391/600] Iteration[008/008] Valid loss: 0.1483
2023-02-06 12:06:30 | Valid | Epoch[391/600] MIou: 0.9373010873392787
2023-02-06 12:06:30 | Valid | Epoch[391/600] Pixel Accuracy: 0.9888801574707031
2023-02-06 12:06:30 | Valid | Epoch[391/600] Mean Pixel Accuracy: 0.9778276459559867
2023-02-06 12:06:30 | Stage | Epoch[391/600] Train loss:0.0183
2023-02-06 12:06:30 | Stage | Epoch[391/600] Valid loss:0.1483
2023-02-06 12:06:30 | Stage | Epoch[391/600] LR:0.01

2023-02-06 12:06:30 | Train | Epoch[392/600] Iteration[001/030] Train loss: 0.0212
2023-02-06 12:06:30 | Train | Epoch[392/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:06:30 | Train | Epoch[392/600] Iteration[003/030] Train loss: 0.0177
2023-02-06 12:06:30 | Train | Epoch[392/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 12:06:30 | Train | Epoch[392/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:06:30 | Train | Epoch[392/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 12:06:30 | Train | Epoch[392/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[011/030] Train loss: 0.0172
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[012/030] Train loss: 0.0175
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[013/030] Train loss: 0.0176
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[014/030] Train loss: 0.0178
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[015/030] Train loss: 0.0176
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[016/030] Train loss: 0.0176
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[017/030] Train loss: 0.0176
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[018/030] Train loss: 0.0176
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[019/030] Train loss: 0.0176
2023-02-06 12:06:31 | Train | Epoch[392/600] Iteration[020/030] Train loss: 0.0176
2023-02-06 12:06:32 | Train | Epoch[392/600] Iteration[021/030] Train loss: 0.0176
2023-02-06 12:06:32 | Train | Epoch[392/600] Iteration[022/030] Train loss: 0.0175
2023-02-06 12:06:32 | Train | Epoch[392/600] Iteration[023/030] Train loss: 0.0176
2023-02-06 12:06:32 | Train | Epoch[392/600] Iteration[024/030] Train loss: 0.0175
2023-02-06 12:06:32 | Train | Epoch[392/600] Iteration[025/030] Train loss: 0.0176
2023-02-06 12:06:32 | Train | Epoch[392/600] Iteration[026/030] Train loss: 0.0176
2023-02-06 12:06:32 | Train | Epoch[392/600] Iteration[027/030] Train loss: 0.0176
2023-02-06 12:06:32 | Train | Epoch[392/600] Iteration[028/030] Train loss: 0.0177
2023-02-06 12:06:32 | Train | Epoch[392/600] Iteration[029/030] Train loss: 0.0176
2023-02-06 12:06:32 | Train | Epoch[392/600] Iteration[030/030] Train loss: 0.0176
2023-02-06 12:06:32 | Valid | Epoch[392/600] Iteration[001/008] Valid loss: 0.0837
2023-02-06 12:06:32 | Valid | Epoch[392/600] Iteration[002/008] Valid loss: 0.0845
2023-02-06 12:06:33 | Valid | Epoch[392/600] Iteration[003/008] Valid loss: 0.0910
2023-02-06 12:06:33 | Valid | Epoch[392/600] Iteration[004/008] Valid loss: 0.0883
2023-02-06 12:06:33 | Valid | Epoch[392/600] Iteration[005/008] Valid loss: 0.0903
2023-02-06 12:06:33 | Valid | Epoch[392/600] Iteration[006/008] Valid loss: 0.0889
2023-02-06 12:06:33 | Valid | Epoch[392/600] Iteration[007/008] Valid loss: 0.0865
2023-02-06 12:06:33 | Valid | Epoch[392/600] Iteration[008/008] Valid loss: 0.0901
2023-02-06 12:06:33 | Valid | Epoch[392/600] MIou: 0.7278774274342757
2023-02-06 12:06:33 | Valid | Epoch[392/600] Pixel Accuracy: 0.955078125
2023-02-06 12:06:33 | Valid | Epoch[392/600] Mean Pixel Accuracy: 0.7514840367804396
2023-02-06 12:06:33 | Stage | Epoch[392/600] Train loss:0.0176
2023-02-06 12:06:33 | Stage | Epoch[392/600] Valid loss:0.0901
2023-02-06 12:06:33 | Stage | Epoch[392/600] LR:0.01

2023-02-06 12:06:33 | Train | Epoch[393/600] Iteration[001/030] Train loss: 0.0201
2023-02-06 12:06:33 | Train | Epoch[393/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 12:06:33 | Train | Epoch[393/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 12:06:33 | Train | Epoch[393/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:06:33 | Train | Epoch[393/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:06:33 | Train | Epoch[393/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 12:06:33 | Train | Epoch[393/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[009/030] Train loss: 0.0175
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[010/030] Train loss: 0.0176
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[011/030] Train loss: 0.0173
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[012/030] Train loss: 0.0173
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[013/030] Train loss: 0.0171
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[014/030] Train loss: 0.0173
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[015/030] Train loss: 0.0174
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[016/030] Train loss: 0.0175
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[017/030] Train loss: 0.0176
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[018/030] Train loss: 0.0176
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[019/030] Train loss: 0.0176
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[020/030] Train loss: 0.0176
2023-02-06 12:06:34 | Train | Epoch[393/600] Iteration[021/030] Train loss: 0.0180
2023-02-06 12:06:35 | Train | Epoch[393/600] Iteration[022/030] Train loss: 0.0180
2023-02-06 12:06:35 | Train | Epoch[393/600] Iteration[023/030] Train loss: 0.0179
2023-02-06 12:06:35 | Train | Epoch[393/600] Iteration[024/030] Train loss: 0.0182
2023-02-06 12:06:35 | Train | Epoch[393/600] Iteration[025/030] Train loss: 0.0180
2023-02-06 12:06:35 | Train | Epoch[393/600] Iteration[026/030] Train loss: 0.0180
2023-02-06 12:06:35 | Train | Epoch[393/600] Iteration[027/030] Train loss: 0.0181
2023-02-06 12:06:35 | Train | Epoch[393/600] Iteration[028/030] Train loss: 0.0181
2023-02-06 12:06:35 | Train | Epoch[393/600] Iteration[029/030] Train loss: 0.0182
2023-02-06 12:06:35 | Train | Epoch[393/600] Iteration[030/030] Train loss: 0.0183
2023-02-06 12:06:35 | Valid | Epoch[393/600] Iteration[001/008] Valid loss: 0.1073
2023-02-06 12:06:35 | Valid | Epoch[393/600] Iteration[002/008] Valid loss: 0.0722
2023-02-06 12:06:35 | Valid | Epoch[393/600] Iteration[003/008] Valid loss: 0.0726
2023-02-06 12:06:36 | Valid | Epoch[393/600] Iteration[004/008] Valid loss: 0.0666
2023-02-06 12:06:36 | Valid | Epoch[393/600] Iteration[005/008] Valid loss: 0.0634
2023-02-06 12:06:36 | Valid | Epoch[393/600] Iteration[006/008] Valid loss: 0.0584
2023-02-06 12:06:36 | Valid | Epoch[393/600] Iteration[007/008] Valid loss: 0.0623
2023-02-06 12:06:36 | Valid | Epoch[393/600] Iteration[008/008] Valid loss: 0.0595
2023-02-06 12:06:36 | Valid | Epoch[393/600] MIou: 0.9331319146741013
2023-02-06 12:06:36 | Valid | Epoch[393/600] Pixel Accuracy: 0.9887034098307291
2023-02-06 12:06:36 | Valid | Epoch[393/600] Mean Pixel Accuracy: 0.9509673676624637
2023-02-06 12:06:36 | Stage | Epoch[393/600] Train loss:0.0183
2023-02-06 12:06:36 | Stage | Epoch[393/600] Valid loss:0.0595
2023-02-06 12:06:36 | Stage | Epoch[393/600] LR:0.01

2023-02-06 12:06:36 | Train | Epoch[394/600] Iteration[001/030] Train loss: 0.0149
2023-02-06 12:06:36 | Train | Epoch[394/600] Iteration[002/030] Train loss: 0.0162
2023-02-06 12:06:36 | Train | Epoch[394/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:06:36 | Train | Epoch[394/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:06:36 | Train | Epoch[394/600] Iteration[005/030] Train loss: 0.0167
2023-02-06 12:06:36 | Train | Epoch[394/600] Iteration[006/030] Train loss: 0.0171
2023-02-06 12:06:36 | Train | Epoch[394/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[011/030] Train loss: 0.0174
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[013/030] Train loss: 0.0178
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[014/030] Train loss: 0.0177
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[016/030] Train loss: 0.0182
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[018/030] Train loss: 0.0181
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[019/030] Train loss: 0.0182
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[020/030] Train loss: 0.0183
2023-02-06 12:06:37 | Train | Epoch[394/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 12:06:38 | Train | Epoch[394/600] Iteration[022/030] Train loss: 0.0182
2023-02-06 12:06:38 | Train | Epoch[394/600] Iteration[023/030] Train loss: 0.0183
2023-02-06 12:06:38 | Train | Epoch[394/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 12:06:38 | Train | Epoch[394/600] Iteration[025/030] Train loss: 0.0182
2023-02-06 12:06:38 | Train | Epoch[394/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:06:38 | Train | Epoch[394/600] Iteration[027/030] Train loss: 0.0184
2023-02-06 12:06:38 | Train | Epoch[394/600] Iteration[028/030] Train loss: 0.0183
2023-02-06 12:06:38 | Train | Epoch[394/600] Iteration[029/030] Train loss: 0.0183
2023-02-06 12:06:38 | Train | Epoch[394/600] Iteration[030/030] Train loss: 0.0184
2023-02-06 12:06:38 | Valid | Epoch[394/600] Iteration[001/008] Valid loss: 0.1231
2023-02-06 12:06:38 | Valid | Epoch[394/600] Iteration[002/008] Valid loss: 0.0864
2023-02-06 12:06:38 | Valid | Epoch[394/600] Iteration[003/008] Valid loss: 0.0897
2023-02-06 12:06:38 | Valid | Epoch[394/600] Iteration[004/008] Valid loss: 0.0861
2023-02-06 12:06:39 | Valid | Epoch[394/600] Iteration[005/008] Valid loss: 0.0857
2023-02-06 12:06:39 | Valid | Epoch[394/600] Iteration[006/008] Valid loss: 0.0798
2023-02-06 12:06:39 | Valid | Epoch[394/600] Iteration[007/008] Valid loss: 0.0844
2023-02-06 12:06:39 | Valid | Epoch[394/600] Iteration[008/008] Valid loss: 0.0795
2023-02-06 12:06:39 | Valid | Epoch[394/600] MIou: 0.9364857880499944
2023-02-06 12:06:39 | Valid | Epoch[394/600] Pixel Accuracy: 0.9891777038574219
2023-02-06 12:06:39 | Valid | Epoch[394/600] Mean Pixel Accuracy: 0.958063088177707
2023-02-06 12:06:39 | Stage | Epoch[394/600] Train loss:0.0184
2023-02-06 12:06:39 | Stage | Epoch[394/600] Valid loss:0.0795
2023-02-06 12:06:39 | Stage | Epoch[394/600] LR:0.01

2023-02-06 12:06:39 | Train | Epoch[395/600] Iteration[001/030] Train loss: 0.0173
2023-02-06 12:06:39 | Train | Epoch[395/600] Iteration[002/030] Train loss: 0.0171
2023-02-06 12:06:39 | Train | Epoch[395/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 12:06:39 | Train | Epoch[395/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 12:06:39 | Train | Epoch[395/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 12:06:39 | Train | Epoch[395/600] Iteration[006/030] Train loss: 0.0189
2023-02-06 12:06:39 | Train | Epoch[395/600] Iteration[007/030] Train loss: 0.0188
2023-02-06 12:06:39 | Train | Epoch[395/600] Iteration[008/030] Train loss: 0.0182
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[009/030] Train loss: 0.0180
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[010/030] Train loss: 0.0181
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[011/030] Train loss: 0.0180
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[013/030] Train loss: 0.0178
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[014/030] Train loss: 0.0179
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[015/030] Train loss: 0.0179
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[016/030] Train loss: 0.0177
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[017/030] Train loss: 0.0177
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[018/030] Train loss: 0.0178
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[019/030] Train loss: 0.0177
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[020/030] Train loss: 0.0178
2023-02-06 12:06:40 | Train | Epoch[395/600] Iteration[021/030] Train loss: 0.0179
2023-02-06 12:06:41 | Train | Epoch[395/600] Iteration[022/030] Train loss: 0.0179
2023-02-06 12:06:41 | Train | Epoch[395/600] Iteration[023/030] Train loss: 0.0178
2023-02-06 12:06:41 | Train | Epoch[395/600] Iteration[024/030] Train loss: 0.0179
2023-02-06 12:06:41 | Train | Epoch[395/600] Iteration[025/030] Train loss: 0.0179
2023-02-06 12:06:41 | Train | Epoch[395/600] Iteration[026/030] Train loss: 0.0179
2023-02-06 12:06:41 | Train | Epoch[395/600] Iteration[027/030] Train loss: 0.0179
2023-02-06 12:06:41 | Train | Epoch[395/600] Iteration[028/030] Train loss: 0.0178
2023-02-06 12:06:41 | Train | Epoch[395/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 12:06:41 | Train | Epoch[395/600] Iteration[030/030] Train loss: 0.0179
2023-02-06 12:06:41 | Valid | Epoch[395/600] Iteration[001/008] Valid loss: 0.0775
2023-02-06 12:06:41 | Valid | Epoch[395/600] Iteration[002/008] Valid loss: 0.0577
2023-02-06 12:06:41 | Valid | Epoch[395/600] Iteration[003/008] Valid loss: 0.0593
2023-02-06 12:06:41 | Valid | Epoch[395/600] Iteration[004/008] Valid loss: 0.0529
2023-02-06 12:06:41 | Valid | Epoch[395/600] Iteration[005/008] Valid loss: 0.0503
2023-02-06 12:06:42 | Valid | Epoch[395/600] Iteration[006/008] Valid loss: 0.0478
2023-02-06 12:06:42 | Valid | Epoch[395/600] Iteration[007/008] Valid loss: 0.0489
2023-02-06 12:06:42 | Valid | Epoch[395/600] Iteration[008/008] Valid loss: 0.0470
2023-02-06 12:06:42 | Valid | Epoch[395/600] MIou: 0.9270434229038689
2023-02-06 12:06:42 | Valid | Epoch[395/600] Pixel Accuracy: 0.9877599080403646
2023-02-06 12:06:42 | Valid | Epoch[395/600] Mean Pixel Accuracy: 0.9421364206867645
2023-02-06 12:06:42 | Stage | Epoch[395/600] Train loss:0.0179
2023-02-06 12:06:42 | Stage | Epoch[395/600] Valid loss:0.0470
2023-02-06 12:06:42 | Stage | Epoch[395/600] LR:0.01

2023-02-06 12:06:42 | Train | Epoch[396/600] Iteration[001/030] Train loss: 0.0146
2023-02-06 12:06:42 | Train | Epoch[396/600] Iteration[002/030] Train loss: 0.0146
2023-02-06 12:06:42 | Train | Epoch[396/600] Iteration[003/030] Train loss: 0.0156
2023-02-06 12:06:42 | Train | Epoch[396/600] Iteration[004/030] Train loss: 0.0163
2023-02-06 12:06:42 | Train | Epoch[396/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:06:42 | Train | Epoch[396/600] Iteration[006/030] Train loss: 0.0162
2023-02-06 12:06:42 | Train | Epoch[396/600] Iteration[007/030] Train loss: 0.0159
2023-02-06 12:06:42 | Train | Epoch[396/600] Iteration[008/030] Train loss: 0.0159
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[015/030] Train loss: 0.0171
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[016/030] Train loss: 0.0171
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[017/030] Train loss: 0.0171
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[019/030] Train loss: 0.0170
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[020/030] Train loss: 0.0172
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[021/030] Train loss: 0.0171
2023-02-06 12:06:43 | Train | Epoch[396/600] Iteration[022/030] Train loss: 0.0170
2023-02-06 12:06:44 | Train | Epoch[396/600] Iteration[023/030] Train loss: 0.0171
2023-02-06 12:06:44 | Train | Epoch[396/600] Iteration[024/030] Train loss: 0.0170
2023-02-06 12:06:44 | Train | Epoch[396/600] Iteration[025/030] Train loss: 0.0172
2023-02-06 12:06:44 | Train | Epoch[396/600] Iteration[026/030] Train loss: 0.0173
2023-02-06 12:06:44 | Train | Epoch[396/600] Iteration[027/030] Train loss: 0.0172
2023-02-06 12:06:44 | Train | Epoch[396/600] Iteration[028/030] Train loss: 0.0172
2023-02-06 12:06:44 | Train | Epoch[396/600] Iteration[029/030] Train loss: 0.0172
2023-02-06 12:06:44 | Train | Epoch[396/600] Iteration[030/030] Train loss: 0.0175
2023-02-06 12:06:44 | Valid | Epoch[396/600] Iteration[001/008] Valid loss: 0.4618
2023-02-06 12:06:44 | Valid | Epoch[396/600] Iteration[002/008] Valid loss: 0.3974
2023-02-06 12:06:44 | Valid | Epoch[396/600] Iteration[003/008] Valid loss: 0.4096
2023-02-06 12:06:44 | Valid | Epoch[396/600] Iteration[004/008] Valid loss: 0.4095
2023-02-06 12:06:44 | Valid | Epoch[396/600] Iteration[005/008] Valid loss: 0.4316
2023-02-06 12:06:44 | Valid | Epoch[396/600] Iteration[006/008] Valid loss: 0.4111
2023-02-06 12:06:44 | Valid | Epoch[396/600] Iteration[007/008] Valid loss: 0.4392
2023-02-06 12:06:45 | Valid | Epoch[396/600] Iteration[008/008] Valid loss: 0.4475
2023-02-06 12:06:45 | Valid | Epoch[396/600] MIou: 0.9028698101327639
2023-02-06 12:06:45 | Valid | Epoch[396/600] Pixel Accuracy: 0.9813626607259115
2023-02-06 12:06:45 | Valid | Epoch[396/600] Mean Pixel Accuracy: 0.9811394226867491
2023-02-06 12:06:45 | Stage | Epoch[396/600] Train loss:0.0175
2023-02-06 12:06:45 | Stage | Epoch[396/600] Valid loss:0.4475
2023-02-06 12:06:45 | Stage | Epoch[396/600] LR:0.01

2023-02-06 12:06:45 | Train | Epoch[397/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 12:06:45 | Train | Epoch[397/600] Iteration[002/030] Train loss: 0.0159
2023-02-06 12:06:45 | Train | Epoch[397/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 12:06:45 | Train | Epoch[397/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 12:06:45 | Train | Epoch[397/600] Iteration[005/030] Train loss: 0.0180
2023-02-06 12:06:45 | Train | Epoch[397/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 12:06:45 | Train | Epoch[397/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 12:06:45 | Train | Epoch[397/600] Iteration[008/030] Train loss: 0.0186
2023-02-06 12:06:45 | Train | Epoch[397/600] Iteration[009/030] Train loss: 0.0187
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[011/030] Train loss: 0.0186
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[012/030] Train loss: 0.0184
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[013/030] Train loss: 0.0184
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[014/030] Train loss: 0.0183
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[016/030] Train loss: 0.0182
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[017/030] Train loss: 0.0182
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[019/030] Train loss: 0.0180
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[020/030] Train loss: 0.0179
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[021/030] Train loss: 0.0180
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[022/030] Train loss: 0.0179
2023-02-06 12:06:46 | Train | Epoch[397/600] Iteration[023/030] Train loss: 0.0179
2023-02-06 12:06:47 | Train | Epoch[397/600] Iteration[024/030] Train loss: 0.0177
2023-02-06 12:06:47 | Train | Epoch[397/600] Iteration[025/030] Train loss: 0.0177
2023-02-06 12:06:47 | Train | Epoch[397/600] Iteration[026/030] Train loss: 0.0178
2023-02-06 12:06:47 | Train | Epoch[397/600] Iteration[027/030] Train loss: 0.0178
2023-02-06 12:06:47 | Train | Epoch[397/600] Iteration[028/030] Train loss: 0.0178
2023-02-06 12:06:47 | Train | Epoch[397/600] Iteration[029/030] Train loss: 0.0178
2023-02-06 12:06:47 | Train | Epoch[397/600] Iteration[030/030] Train loss: 0.0178
2023-02-06 12:06:47 | Valid | Epoch[397/600] Iteration[001/008] Valid loss: 0.0917
2023-02-06 12:06:47 | Valid | Epoch[397/600] Iteration[002/008] Valid loss: 0.0937
2023-02-06 12:06:47 | Valid | Epoch[397/600] Iteration[003/008] Valid loss: 0.0987
2023-02-06 12:06:47 | Valid | Epoch[397/600] Iteration[004/008] Valid loss: 0.0968
2023-02-06 12:06:47 | Valid | Epoch[397/600] Iteration[005/008] Valid loss: 0.0983
2023-02-06 12:06:47 | Valid | Epoch[397/600] Iteration[006/008] Valid loss: 0.0972
2023-02-06 12:06:47 | Valid | Epoch[397/600] Iteration[007/008] Valid loss: 0.0949
2023-02-06 12:06:47 | Valid | Epoch[397/600] Iteration[008/008] Valid loss: 0.0983
2023-02-06 12:06:48 | Valid | Epoch[397/600] MIou: 0.7280501461871071
2023-02-06 12:06:48 | Valid | Epoch[397/600] Pixel Accuracy: 0.9551188151041666
2023-02-06 12:06:48 | Valid | Epoch[397/600] Mean Pixel Accuracy: 0.7515761469837136
2023-02-06 12:06:48 | Stage | Epoch[397/600] Train loss:0.0178
2023-02-06 12:06:48 | Stage | Epoch[397/600] Valid loss:0.0983
2023-02-06 12:06:48 | Stage | Epoch[397/600] LR:0.01

2023-02-06 12:06:48 | Train | Epoch[398/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 12:06:48 | Train | Epoch[398/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:06:48 | Train | Epoch[398/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:06:48 | Train | Epoch[398/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 12:06:48 | Train | Epoch[398/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:06:48 | Train | Epoch[398/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:06:48 | Train | Epoch[398/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:06:48 | Train | Epoch[398/600] Iteration[008/030] Train loss: 0.0173
2023-02-06 12:06:48 | Train | Epoch[398/600] Iteration[009/030] Train loss: 0.0174
2023-02-06 12:06:48 | Train | Epoch[398/600] Iteration[010/030] Train loss: 0.0175
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[012/030] Train loss: 0.0172
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[013/030] Train loss: 0.0172
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[014/030] Train loss: 0.0172
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[015/030] Train loss: 0.0173
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[016/030] Train loss: 0.0171
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[017/030] Train loss: 0.0175
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[018/030] Train loss: 0.0176
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[019/030] Train loss: 0.0177
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[020/030] Train loss: 0.0182
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[021/030] Train loss: 0.0182
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[022/030] Train loss: 0.0181
2023-02-06 12:06:49 | Train | Epoch[398/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:06:50 | Train | Epoch[398/600] Iteration[024/030] Train loss: 0.0181
2023-02-06 12:06:50 | Train | Epoch[398/600] Iteration[025/030] Train loss: 0.0180
2023-02-06 12:06:50 | Train | Epoch[398/600] Iteration[026/030] Train loss: 0.0180
2023-02-06 12:06:50 | Train | Epoch[398/600] Iteration[027/030] Train loss: 0.0180
2023-02-06 12:06:50 | Train | Epoch[398/600] Iteration[028/030] Train loss: 0.0179
2023-02-06 12:06:50 | Train | Epoch[398/600] Iteration[029/030] Train loss: 0.0181
2023-02-06 12:06:50 | Train | Epoch[398/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 12:06:50 | Valid | Epoch[398/600] Iteration[001/008] Valid loss: 0.0780
2023-02-06 12:06:50 | Valid | Epoch[398/600] Iteration[002/008] Valid loss: 0.0635
2023-02-06 12:06:50 | Valid | Epoch[398/600] Iteration[003/008] Valid loss: 0.0685
2023-02-06 12:06:50 | Valid | Epoch[398/600] Iteration[004/008] Valid loss: 0.0622
2023-02-06 12:06:50 | Valid | Epoch[398/600] Iteration[005/008] Valid loss: 0.0607
2023-02-06 12:06:50 | Valid | Epoch[398/600] Iteration[006/008] Valid loss: 0.0570
2023-02-06 12:06:50 | Valid | Epoch[398/600] Iteration[007/008] Valid loss: 0.0546
2023-02-06 12:06:50 | Valid | Epoch[398/600] Iteration[008/008] Valid loss: 0.0538
2023-02-06 12:06:50 | Valid | Epoch[398/600] MIou: 0.8725523408640361
2023-02-06 12:06:51 | Valid | Epoch[398/600] Pixel Accuracy: 0.9788920084635416
2023-02-06 12:06:51 | Valid | Epoch[398/600] Mean Pixel Accuracy: 0.8860629374125286
2023-02-06 12:06:51 | Stage | Epoch[398/600] Train loss:0.0180
2023-02-06 12:06:51 | Stage | Epoch[398/600] Valid loss:0.0538
2023-02-06 12:06:51 | Stage | Epoch[398/600] LR:0.01

2023-02-06 12:06:51 | Train | Epoch[399/600] Iteration[001/030] Train loss: 0.0195
2023-02-06 12:06:51 | Train | Epoch[399/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 12:06:51 | Train | Epoch[399/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 12:06:51 | Train | Epoch[399/600] Iteration[004/030] Train loss: 0.0177
2023-02-06 12:06:51 | Train | Epoch[399/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:06:51 | Train | Epoch[399/600] Iteration[006/030] Train loss: 0.0179
2023-02-06 12:06:51 | Train | Epoch[399/600] Iteration[007/030] Train loss: 0.0178
2023-02-06 12:06:51 | Train | Epoch[399/600] Iteration[008/030] Train loss: 0.0177
2023-02-06 12:06:51 | Train | Epoch[399/600] Iteration[009/030] Train loss: 0.0176
2023-02-06 12:06:51 | Train | Epoch[399/600] Iteration[010/030] Train loss: 0.0174
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[011/030] Train loss: 0.0173
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[012/030] Train loss: 0.0175
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[013/030] Train loss: 0.0173
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[014/030] Train loss: 0.0174
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[015/030] Train loss: 0.0176
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[016/030] Train loss: 0.0176
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[017/030] Train loss: 0.0177
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[018/030] Train loss: 0.0176
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[019/030] Train loss: 0.0175
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[020/030] Train loss: 0.0176
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[021/030] Train loss: 0.0176
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[022/030] Train loss: 0.0178
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[023/030] Train loss: 0.0177
2023-02-06 12:06:52 | Train | Epoch[399/600] Iteration[024/030] Train loss: 0.0177
2023-02-06 12:06:53 | Train | Epoch[399/600] Iteration[025/030] Train loss: 0.0179
2023-02-06 12:06:53 | Train | Epoch[399/600] Iteration[026/030] Train loss: 0.0178
2023-02-06 12:06:53 | Train | Epoch[399/600] Iteration[027/030] Train loss: 0.0179
2023-02-06 12:06:53 | Train | Epoch[399/600] Iteration[028/030] Train loss: 0.0179
2023-02-06 12:06:53 | Train | Epoch[399/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 12:06:53 | Train | Epoch[399/600] Iteration[030/030] Train loss: 0.0179
2023-02-06 12:06:53 | Valid | Epoch[399/600] Iteration[001/008] Valid loss: 0.1443
2023-02-06 12:06:53 | Valid | Epoch[399/600] Iteration[002/008] Valid loss: 0.1109
2023-02-06 12:06:53 | Valid | Epoch[399/600] Iteration[003/008] Valid loss: 0.1035
2023-02-06 12:06:53 | Valid | Epoch[399/600] Iteration[004/008] Valid loss: 0.0961
2023-02-06 12:06:53 | Valid | Epoch[399/600] Iteration[005/008] Valid loss: 0.0963
2023-02-06 12:06:53 | Valid | Epoch[399/600] Iteration[006/008] Valid loss: 0.0917
2023-02-06 12:06:53 | Valid | Epoch[399/600] Iteration[007/008] Valid loss: 0.0972
2023-02-06 12:06:53 | Valid | Epoch[399/600] Iteration[008/008] Valid loss: 0.0949
2023-02-06 12:06:53 | Valid | Epoch[399/600] MIou: 0.9355156503321518
2023-02-06 12:06:53 | Valid | Epoch[399/600] Pixel Accuracy: 0.9887708028157552
2023-02-06 12:06:53 | Valid | Epoch[399/600] Mean Pixel Accuracy: 0.9672930810358082
2023-02-06 12:06:53 | Stage | Epoch[399/600] Train loss:0.0179
2023-02-06 12:06:53 | Stage | Epoch[399/600] Valid loss:0.0949
2023-02-06 12:06:53 | Stage | Epoch[399/600] LR:0.01

2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[001/030] Train loss: 0.0143
2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[002/030] Train loss: 0.0167
2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[003/030] Train loss: 0.0175
2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[005/030] Train loss: 0.0175
2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[009/030] Train loss: 0.0170
2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[010/030] Train loss: 0.0174
2023-02-06 12:06:54 | Train | Epoch[400/600] Iteration[011/030] Train loss: 0.0177
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[013/030] Train loss: 0.0177
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[014/030] Train loss: 0.0175
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[015/030] Train loss: 0.0174
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[016/030] Train loss: 0.0174
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[017/030] Train loss: 0.0177
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[018/030] Train loss: 0.0176
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[019/030] Train loss: 0.0176
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[020/030] Train loss: 0.0179
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[021/030] Train loss: 0.0181
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[022/030] Train loss: 0.0181
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[023/030] Train loss: 0.0182
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[024/030] Train loss: 0.0182
2023-02-06 12:06:55 | Train | Epoch[400/600] Iteration[025/030] Train loss: 0.0182
2023-02-06 12:06:56 | Train | Epoch[400/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 12:06:56 | Train | Epoch[400/600] Iteration[027/030] Train loss: 0.0185
2023-02-06 12:06:56 | Train | Epoch[400/600] Iteration[028/030] Train loss: 0.0184
2023-02-06 12:06:56 | Train | Epoch[400/600] Iteration[029/030] Train loss: 0.0184
2023-02-06 12:06:56 | Train | Epoch[400/600] Iteration[030/030] Train loss: 0.0184
2023-02-06 12:06:56 | Valid | Epoch[400/600] Iteration[001/008] Valid loss: 0.1226
2023-02-06 12:06:56 | Valid | Epoch[400/600] Iteration[002/008] Valid loss: 0.0892
2023-02-06 12:06:56 | Valid | Epoch[400/600] Iteration[003/008] Valid loss: 0.0807
2023-02-06 12:06:56 | Valid | Epoch[400/600] Iteration[004/008] Valid loss: 0.0736
2023-02-06 12:06:56 | Valid | Epoch[400/600] Iteration[005/008] Valid loss: 0.0722
2023-02-06 12:06:56 | Valid | Epoch[400/600] Iteration[006/008] Valid loss: 0.0694
2023-02-06 12:06:56 | Valid | Epoch[400/600] Iteration[007/008] Valid loss: 0.0731
2023-02-06 12:06:56 | Valid | Epoch[400/600] Iteration[008/008] Valid loss: 0.0720
2023-02-06 12:06:56 | Valid | Epoch[400/600] MIou: 0.9346854230309294
2023-02-06 12:06:56 | Valid | Epoch[400/600] Pixel Accuracy: 0.9888013203938802
2023-02-06 12:06:56 | Valid | Epoch[400/600] Mean Pixel Accuracy: 0.9592257536203872
2023-02-06 12:06:56 | Stage | Epoch[400/600] Train loss:0.0184
2023-02-06 12:06:56 | Stage | Epoch[400/600] Valid loss:0.0720
2023-02-06 12:06:56 | Stage | Epoch[400/600] LR:0.01

2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[002/030] Train loss: 0.0184
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[004/030] Train loss: 0.0182
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[007/030] Train loss: 0.0176
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[008/030] Train loss: 0.0177
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[009/030] Train loss: 0.0175
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[010/030] Train loss: 0.0175
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[011/030] Train loss: 0.0174
2023-02-06 12:06:57 | Train | Epoch[401/600] Iteration[012/030] Train loss: 0.0173
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[013/030] Train loss: 0.0173
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[014/030] Train loss: 0.0172
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[015/030] Train loss: 0.0172
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[019/030] Train loss: 0.0171
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[020/030] Train loss: 0.0172
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[021/030] Train loss: 0.0172
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[022/030] Train loss: 0.0172
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[023/030] Train loss: 0.0172
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[024/030] Train loss: 0.0172
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[025/030] Train loss: 0.0172
2023-02-06 12:06:58 | Train | Epoch[401/600] Iteration[026/030] Train loss: 0.0173
2023-02-06 12:06:59 | Train | Epoch[401/600] Iteration[027/030] Train loss: 0.0173
2023-02-06 12:06:59 | Train | Epoch[401/600] Iteration[028/030] Train loss: 0.0173
2023-02-06 12:06:59 | Train | Epoch[401/600] Iteration[029/030] Train loss: 0.0173
2023-02-06 12:06:59 | Train | Epoch[401/600] Iteration[030/030] Train loss: 0.0172
2023-02-06 12:06:59 | Valid | Epoch[401/600] Iteration[001/008] Valid loss: 0.0559
2023-02-06 12:06:59 | Valid | Epoch[401/600] Iteration[002/008] Valid loss: 0.0452
2023-02-06 12:06:59 | Valid | Epoch[401/600] Iteration[003/008] Valid loss: 0.0459
2023-02-06 12:06:59 | Valid | Epoch[401/600] Iteration[004/008] Valid loss: 0.0417
2023-02-06 12:06:59 | Valid | Epoch[401/600] Iteration[005/008] Valid loss: 0.0408
2023-02-06 12:06:59 | Valid | Epoch[401/600] Iteration[006/008] Valid loss: 0.0392
2023-02-06 12:06:59 | Valid | Epoch[401/600] Iteration[007/008] Valid loss: 0.0394
2023-02-06 12:06:59 | Valid | Epoch[401/600] Iteration[008/008] Valid loss: 0.0389
2023-02-06 12:06:59 | Valid | Epoch[401/600] MIou: 0.8995987692840832
2023-02-06 12:06:59 | Valid | Epoch[401/600] Pixel Accuracy: 0.9833030700683594
2023-02-06 12:06:59 | Valid | Epoch[401/600] Mean Pixel Accuracy: 0.9127651104175174
2023-02-06 12:06:59 | Stage | Epoch[401/600] Train loss:0.0172
2023-02-06 12:06:59 | Stage | Epoch[401/600] Valid loss:0.0389
2023-02-06 12:06:59 | Stage | Epoch[401/600] LR:0.001

2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[001/030] Train loss: 0.0155
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[002/030] Train loss: 0.0156
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[005/030] Train loss: 0.0167
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[006/030] Train loss: 0.0165
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[011/030] Train loss: 0.0174
2023-02-06 12:07:00 | Train | Epoch[402/600] Iteration[012/030] Train loss: 0.0173
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[013/030] Train loss: 0.0173
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[014/030] Train loss: 0.0173
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[015/030] Train loss: 0.0172
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[016/030] Train loss: 0.0171
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[017/030] Train loss: 0.0171
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[018/030] Train loss: 0.0171
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:07:01 | Train | Epoch[402/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:07:02 | Train | Epoch[402/600] Iteration[026/030] Train loss: 0.0169
2023-02-06 12:07:02 | Train | Epoch[402/600] Iteration[027/030] Train loss: 0.0169
2023-02-06 12:07:02 | Train | Epoch[402/600] Iteration[028/030] Train loss: 0.0170
2023-02-06 12:07:02 | Train | Epoch[402/600] Iteration[029/030] Train loss: 0.0170
2023-02-06 12:07:02 | Train | Epoch[402/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:07:02 | Valid | Epoch[402/600] Iteration[001/008] Valid loss: 0.0783
2023-02-06 12:07:02 | Valid | Epoch[402/600] Iteration[002/008] Valid loss: 0.0561
2023-02-06 12:07:02 | Valid | Epoch[402/600] Iteration[003/008] Valid loss: 0.0559
2023-02-06 12:07:02 | Valid | Epoch[402/600] Iteration[004/008] Valid loss: 0.0496
2023-02-06 12:07:02 | Valid | Epoch[402/600] Iteration[005/008] Valid loss: 0.0472
2023-02-06 12:07:02 | Valid | Epoch[402/600] Iteration[006/008] Valid loss: 0.0443
2023-02-06 12:07:02 | Valid | Epoch[402/600] Iteration[007/008] Valid loss: 0.0456
2023-02-06 12:07:02 | Valid | Epoch[402/600] Iteration[008/008] Valid loss: 0.0441
2023-02-06 12:07:02 | Valid | Epoch[402/600] MIou: 0.9273956424718566
2023-02-06 12:07:02 | Valid | Epoch[402/600] Pixel Accuracy: 0.9878044128417969
2023-02-06 12:07:02 | Valid | Epoch[402/600] Mean Pixel Accuracy: 0.9429978246633102
2023-02-06 12:07:02 | Stage | Epoch[402/600] Train loss:0.0169
2023-02-06 12:07:02 | Stage | Epoch[402/600] Valid loss:0.0441
2023-02-06 12:07:02 | Stage | Epoch[402/600] LR:0.001

2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[003/030] Train loss: 0.0170
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[008/030] Train loss: 0.0173
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[011/030] Train loss: 0.0172
2023-02-06 12:07:03 | Train | Epoch[403/600] Iteration[012/030] Train loss: 0.0173
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[013/030] Train loss: 0.0173
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[014/030] Train loss: 0.0170
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[024/030] Train loss: 0.0170
2023-02-06 12:07:04 | Train | Epoch[403/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:07:05 | Train | Epoch[403/600] Iteration[026/030] Train loss: 0.0169
2023-02-06 12:07:05 | Train | Epoch[403/600] Iteration[027/030] Train loss: 0.0170
2023-02-06 12:07:05 | Train | Epoch[403/600] Iteration[028/030] Train loss: 0.0170
2023-02-06 12:07:05 | Train | Epoch[403/600] Iteration[029/030] Train loss: 0.0170
2023-02-06 12:07:05 | Train | Epoch[403/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:07:05 | Valid | Epoch[403/600] Iteration[001/008] Valid loss: 0.0736
2023-02-06 12:07:05 | Valid | Epoch[403/600] Iteration[002/008] Valid loss: 0.0537
2023-02-06 12:07:05 | Valid | Epoch[403/600] Iteration[003/008] Valid loss: 0.0544
2023-02-06 12:07:05 | Valid | Epoch[403/600] Iteration[004/008] Valid loss: 0.0484
2023-02-06 12:07:05 | Valid | Epoch[403/600] Iteration[005/008] Valid loss: 0.0461
2023-02-06 12:07:05 | Valid | Epoch[403/600] Iteration[006/008] Valid loss: 0.0436
2023-02-06 12:07:05 | Valid | Epoch[403/600] Iteration[007/008] Valid loss: 0.0446
2023-02-06 12:07:05 | Valid | Epoch[403/600] Iteration[008/008] Valid loss: 0.0431
2023-02-06 12:07:05 | Valid | Epoch[403/600] MIou: 0.9244325921279513
2023-02-06 12:07:05 | Valid | Epoch[403/600] Pixel Accuracy: 0.9873326619466146
2023-02-06 12:07:05 | Valid | Epoch[403/600] Mean Pixel Accuracy: 0.9393146756351058
2023-02-06 12:07:05 | Stage | Epoch[403/600] Train loss:0.0169
2023-02-06 12:07:05 | Stage | Epoch[403/600] Valid loss:0.0431
2023-02-06 12:07:05 | Stage | Epoch[403/600] LR:0.001

2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[001/030] Train loss: 0.0151
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[002/030] Train loss: 0.0148
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[003/030] Train loss: 0.0158
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[005/030] Train loss: 0.0160
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:07:06 | Train | Epoch[404/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:07:07 | Train | Epoch[404/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:07:08 | Train | Epoch[404/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:07:08 | Train | Epoch[404/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:07:08 | Train | Epoch[404/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:07:08 | Train | Epoch[404/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:07:08 | Valid | Epoch[404/600] Iteration[001/008] Valid loss: 0.0785
2023-02-06 12:07:08 | Valid | Epoch[404/600] Iteration[002/008] Valid loss: 0.0561
2023-02-06 12:07:08 | Valid | Epoch[404/600] Iteration[003/008] Valid loss: 0.0571
2023-02-06 12:07:08 | Valid | Epoch[404/600] Iteration[004/008] Valid loss: 0.0507
2023-02-06 12:07:08 | Valid | Epoch[404/600] Iteration[005/008] Valid loss: 0.0482
2023-02-06 12:07:08 | Valid | Epoch[404/600] Iteration[006/008] Valid loss: 0.0453
2023-02-06 12:07:08 | Valid | Epoch[404/600] Iteration[007/008] Valid loss: 0.0467
2023-02-06 12:07:08 | Valid | Epoch[404/600] Iteration[008/008] Valid loss: 0.0450
2023-02-06 12:07:08 | Valid | Epoch[404/600] MIou: 0.9286014602095025
2023-02-06 12:07:08 | Valid | Epoch[404/600] Pixel Accuracy: 0.9879976908365885
2023-02-06 12:07:08 | Valid | Epoch[404/600] Mean Pixel Accuracy: 0.944473600338964
2023-02-06 12:07:08 | Stage | Epoch[404/600] Train loss:0.0167
2023-02-06 12:07:08 | Stage | Epoch[404/600] Valid loss:0.0450
2023-02-06 12:07:08 | Stage | Epoch[404/600] LR:0.001

2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[001/030] Train loss: 0.0163
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[005/030] Train loss: 0.0174
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[010/030] Train loss: 0.0171
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:07:09 | Train | Epoch[405/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:07:10 | Train | Epoch[405/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:07:11 | Train | Epoch[405/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:07:11 | Train | Epoch[405/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:07:11 | Train | Epoch[405/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:07:11 | Train | Epoch[405/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:07:11 | Valid | Epoch[405/600] Iteration[001/008] Valid loss: 0.0809
2023-02-06 12:07:11 | Valid | Epoch[405/600] Iteration[002/008] Valid loss: 0.0578
2023-02-06 12:07:11 | Valid | Epoch[405/600] Iteration[003/008] Valid loss: 0.0593
2023-02-06 12:07:11 | Valid | Epoch[405/600] Iteration[004/008] Valid loss: 0.0524
2023-02-06 12:07:11 | Valid | Epoch[405/600] Iteration[005/008] Valid loss: 0.0498
2023-02-06 12:07:11 | Valid | Epoch[405/600] Iteration[006/008] Valid loss: 0.0466
2023-02-06 12:07:11 | Valid | Epoch[405/600] Iteration[007/008] Valid loss: 0.0480
2023-02-06 12:07:11 | Valid | Epoch[405/600] Iteration[008/008] Valid loss: 0.0463
2023-02-06 12:07:11 | Valid | Epoch[405/600] MIou: 0.9289745948363215
2023-02-06 12:07:11 | Valid | Epoch[405/600] Pixel Accuracy: 0.9880460103352865
2023-02-06 12:07:11 | Valid | Epoch[405/600] Mean Pixel Accuracy: 0.945362462921868
2023-02-06 12:07:11 | Stage | Epoch[405/600] Train loss:0.0169
2023-02-06 12:07:11 | Stage | Epoch[405/600] Valid loss:0.0463
2023-02-06 12:07:11 | Stage | Epoch[405/600] LR:0.001

2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[005/030] Train loss: 0.0181
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[006/030] Train loss: 0.0175
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[007/030] Train loss: 0.0175
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[008/030] Train loss: 0.0175
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[009/030] Train loss: 0.0176
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[011/030] Train loss: 0.0173
2023-02-06 12:07:12 | Train | Epoch[406/600] Iteration[012/030] Train loss: 0.0174
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[013/030] Train loss: 0.0174
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[014/030] Train loss: 0.0175
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[015/030] Train loss: 0.0174
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[016/030] Train loss: 0.0174
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[017/030] Train loss: 0.0172
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[018/030] Train loss: 0.0171
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[019/030] Train loss: 0.0170
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[020/030] Train loss: 0.0171
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[021/030] Train loss: 0.0171
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[022/030] Train loss: 0.0170
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[025/030] Train loss: 0.0171
2023-02-06 12:07:13 | Train | Epoch[406/600] Iteration[026/030] Train loss: 0.0170
2023-02-06 12:07:14 | Train | Epoch[406/600] Iteration[027/030] Train loss: 0.0170
2023-02-06 12:07:14 | Train | Epoch[406/600] Iteration[028/030] Train loss: 0.0171
2023-02-06 12:07:14 | Train | Epoch[406/600] Iteration[029/030] Train loss: 0.0170
2023-02-06 12:07:14 | Train | Epoch[406/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:07:14 | Valid | Epoch[406/600] Iteration[001/008] Valid loss: 0.1024
2023-02-06 12:07:14 | Valid | Epoch[406/600] Iteration[002/008] Valid loss: 0.0718
2023-02-06 12:07:14 | Valid | Epoch[406/600] Iteration[003/008] Valid loss: 0.0712
2023-02-06 12:07:14 | Valid | Epoch[406/600] Iteration[004/008] Valid loss: 0.0640
2023-02-06 12:07:14 | Valid | Epoch[406/600] Iteration[005/008] Valid loss: 0.0608
2023-02-06 12:07:14 | Valid | Epoch[406/600] Iteration[006/008] Valid loss: 0.0570
2023-02-06 12:07:14 | Valid | Epoch[406/600] Iteration[007/008] Valid loss: 0.0600
2023-02-06 12:07:14 | Valid | Epoch[406/600] Iteration[008/008] Valid loss: 0.0576
2023-02-06 12:07:14 | Valid | Epoch[406/600] MIou: 0.9368355228847309
2023-02-06 12:07:14 | Valid | Epoch[406/600] Pixel Accuracy: 0.9892628987630209
2023-02-06 12:07:14 | Valid | Epoch[406/600] Mean Pixel Accuracy: 0.9572983345777528
2023-02-06 12:07:14 | Stage | Epoch[406/600] Train loss:0.0169
2023-02-06 12:07:14 | Stage | Epoch[406/600] Valid loss:0.0576
2023-02-06 12:07:14 | Stage | Epoch[406/600] LR:0.001

2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[003/030] Train loss: 0.0160
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[004/030] Train loss: 0.0163
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:07:15 | Train | Epoch[407/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:07:16 | Train | Epoch[407/600] Iteration[027/030] Train loss: 0.0169
2023-02-06 12:07:17 | Train | Epoch[407/600] Iteration[028/030] Train loss: 0.0169
2023-02-06 12:07:17 | Train | Epoch[407/600] Iteration[029/030] Train loss: 0.0169
2023-02-06 12:07:17 | Train | Epoch[407/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:07:17 | Valid | Epoch[407/600] Iteration[001/008] Valid loss: 0.0712
2023-02-06 12:07:17 | Valid | Epoch[407/600] Iteration[002/008] Valid loss: 0.0526
2023-02-06 12:07:17 | Valid | Epoch[407/600] Iteration[003/008] Valid loss: 0.0533
2023-02-06 12:07:17 | Valid | Epoch[407/600] Iteration[004/008] Valid loss: 0.0474
2023-02-06 12:07:17 | Valid | Epoch[407/600] Iteration[005/008] Valid loss: 0.0452
2023-02-06 12:07:17 | Valid | Epoch[407/600] Iteration[006/008] Valid loss: 0.0426
2023-02-06 12:07:17 | Valid | Epoch[407/600] Iteration[007/008] Valid loss: 0.0438
2023-02-06 12:07:17 | Valid | Epoch[407/600] Iteration[008/008] Valid loss: 0.0424
2023-02-06 12:07:17 | Valid | Epoch[407/600] MIou: 0.9232437711249535
2023-02-06 12:07:17 | Valid | Epoch[407/600] Pixel Accuracy: 0.9871431986490885
2023-02-06 12:07:17 | Valid | Epoch[407/600] Mean Pixel Accuracy: 0.9378663585658104
2023-02-06 12:07:17 | Stage | Epoch[407/600] Train loss:0.0168
2023-02-06 12:07:17 | Stage | Epoch[407/600] Valid loss:0.0424
2023-02-06 12:07:17 | Stage | Epoch[407/600] LR:0.001

2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[001/030] Train loss: 0.0207
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[003/030] Train loss: 0.0185
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[004/030] Train loss: 0.0186
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[005/030] Train loss: 0.0185
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[006/030] Train loss: 0.0179
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[007/030] Train loss: 0.0178
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[008/030] Train loss: 0.0177
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[009/030] Train loss: 0.0175
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[011/030] Train loss: 0.0173
2023-02-06 12:07:18 | Train | Epoch[408/600] Iteration[012/030] Train loss: 0.0174
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[013/030] Train loss: 0.0174
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[014/030] Train loss: 0.0172
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[019/030] Train loss: 0.0170
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[020/030] Train loss: 0.0169
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[021/030] Train loss: 0.0170
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[023/030] Train loss: 0.0170
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:07:19 | Train | Epoch[408/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:07:20 | Train | Epoch[408/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:07:20 | Train | Epoch[408/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:07:20 | Train | Epoch[408/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:07:20 | Train | Epoch[408/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:07:20 | Valid | Epoch[408/600] Iteration[001/008] Valid loss: 0.0926
2023-02-06 12:07:20 | Valid | Epoch[408/600] Iteration[002/008] Valid loss: 0.0652
2023-02-06 12:07:20 | Valid | Epoch[408/600] Iteration[003/008] Valid loss: 0.0663
2023-02-06 12:07:20 | Valid | Epoch[408/600] Iteration[004/008] Valid loss: 0.0593
2023-02-06 12:07:20 | Valid | Epoch[408/600] Iteration[005/008] Valid loss: 0.0563
2023-02-06 12:07:20 | Valid | Epoch[408/600] Iteration[006/008] Valid loss: 0.0528
2023-02-06 12:07:20 | Valid | Epoch[408/600] Iteration[007/008] Valid loss: 0.0549
2023-02-06 12:07:20 | Valid | Epoch[408/600] Iteration[008/008] Valid loss: 0.0526
2023-02-06 12:07:20 | Valid | Epoch[408/600] MIou: 0.9341315288592758
2023-02-06 12:07:20 | Valid | Epoch[408/600] Pixel Accuracy: 0.9888534545898438
2023-02-06 12:07:20 | Valid | Epoch[408/600] Mean Pixel Accuracy: 0.9526793398399318
2023-02-06 12:07:20 | Stage | Epoch[408/600] Train loss:0.0166
2023-02-06 12:07:20 | Stage | Epoch[408/600] Valid loss:0.0526
2023-02-06 12:07:20 | Stage | Epoch[408/600] LR:0.001

2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[001/030] Train loss: 0.0162
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[002/030] Train loss: 0.0165
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[006/030] Train loss: 0.0160
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[007/030] Train loss: 0.0160
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:07:21 | Train | Epoch[409/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:07:22 | Train | Epoch[409/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:07:23 | Train | Epoch[409/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:07:23 | Train | Epoch[409/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:07:23 | Train | Epoch[409/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:07:23 | Train | Epoch[409/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:07:23 | Valid | Epoch[409/600] Iteration[001/008] Valid loss: 0.0810
2023-02-06 12:07:23 | Valid | Epoch[409/600] Iteration[002/008] Valid loss: 0.0580
2023-02-06 12:07:23 | Valid | Epoch[409/600] Iteration[003/008] Valid loss: 0.0596
2023-02-06 12:07:23 | Valid | Epoch[409/600] Iteration[004/008] Valid loss: 0.0529
2023-02-06 12:07:23 | Valid | Epoch[409/600] Iteration[005/008] Valid loss: 0.0502
2023-02-06 12:07:23 | Valid | Epoch[409/600] Iteration[006/008] Valid loss: 0.0472
2023-02-06 12:07:23 | Valid | Epoch[409/600] Iteration[007/008] Valid loss: 0.0487
2023-02-06 12:07:23 | Valid | Epoch[409/600] Iteration[008/008] Valid loss: 0.0469
2023-02-06 12:07:23 | Valid | Epoch[409/600] MIou: 0.9289853040232192
2023-02-06 12:07:23 | Valid | Epoch[409/600] Pixel Accuracy: 0.9880485534667969
2023-02-06 12:07:23 | Valid | Epoch[409/600] Mean Pixel Accuracy: 0.9453448393208719
2023-02-06 12:07:23 | Stage | Epoch[409/600] Train loss:0.0166
2023-02-06 12:07:23 | Stage | Epoch[409/600] Valid loss:0.0469
2023-02-06 12:07:23 | Stage | Epoch[409/600] LR:0.001

2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[001/030] Train loss: 0.0193
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[003/030] Train loss: 0.0179
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[009/030] Train loss: 0.0166
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:07:24 | Train | Epoch[410/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:07:25 | Train | Epoch[410/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:07:26 | Train | Epoch[410/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:07:26 | Train | Epoch[410/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:07:26 | Train | Epoch[410/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:07:26 | Train | Epoch[410/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:07:26 | Valid | Epoch[410/600] Iteration[001/008] Valid loss: 0.0758
2023-02-06 12:07:26 | Valid | Epoch[410/600] Iteration[002/008] Valid loss: 0.0545
2023-02-06 12:07:26 | Valid | Epoch[410/600] Iteration[003/008] Valid loss: 0.0545
2023-02-06 12:07:26 | Valid | Epoch[410/600] Iteration[004/008] Valid loss: 0.0485
2023-02-06 12:07:26 | Valid | Epoch[410/600] Iteration[005/008] Valid loss: 0.0462
2023-02-06 12:07:26 | Valid | Epoch[410/600] Iteration[006/008] Valid loss: 0.0435
2023-02-06 12:07:26 | Valid | Epoch[410/600] Iteration[007/008] Valid loss: 0.0449
2023-02-06 12:07:26 | Valid | Epoch[410/600] Iteration[008/008] Valid loss: 0.0435
2023-02-06 12:07:26 | Valid | Epoch[410/600] MIou: 0.9256442710185742
2023-02-06 12:07:26 | Valid | Epoch[410/600] Pixel Accuracy: 0.9875208536783854
2023-02-06 12:07:26 | Valid | Epoch[410/600] Mean Pixel Accuracy: 0.9409778698290419
2023-02-06 12:07:26 | Stage | Epoch[410/600] Train loss:0.0165
2023-02-06 12:07:26 | Stage | Epoch[410/600] Valid loss:0.0435
2023-02-06 12:07:26 | Stage | Epoch[410/600] LR:0.001

2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[002/030] Train loss: 0.0197
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[003/030] Train loss: 0.0189
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[007/030] Train loss: 0.0178
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[008/030] Train loss: 0.0176
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[009/030] Train loss: 0.0174
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:07:27 | Train | Epoch[411/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:07:28 | Train | Epoch[411/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:07:29 | Train | Epoch[411/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:07:29 | Train | Epoch[411/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:07:29 | Train | Epoch[411/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:07:29 | Train | Epoch[411/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:07:29 | Valid | Epoch[411/600] Iteration[001/008] Valid loss: 0.0971
2023-02-06 12:07:29 | Valid | Epoch[411/600] Iteration[002/008] Valid loss: 0.0690
2023-02-06 12:07:29 | Valid | Epoch[411/600] Iteration[003/008] Valid loss: 0.0685
2023-02-06 12:07:29 | Valid | Epoch[411/600] Iteration[004/008] Valid loss: 0.0617
2023-02-06 12:07:29 | Valid | Epoch[411/600] Iteration[005/008] Valid loss: 0.0588
2023-02-06 12:07:29 | Valid | Epoch[411/600] Iteration[006/008] Valid loss: 0.0552
2023-02-06 12:07:29 | Valid | Epoch[411/600] Iteration[007/008] Valid loss: 0.0575
2023-02-06 12:07:29 | Valid | Epoch[411/600] Iteration[008/008] Valid loss: 0.0550
2023-02-06 12:07:29 | Valid | Epoch[411/600] MIou: 0.9350191814370127
2023-02-06 12:07:29 | Valid | Epoch[411/600] Pixel Accuracy: 0.9889780680338541
2023-02-06 12:07:29 | Valid | Epoch[411/600] Mean Pixel Accuracy: 0.9545802289703857
2023-02-06 12:07:29 | Stage | Epoch[411/600] Train loss:0.0167
2023-02-06 12:07:29 | Stage | Epoch[411/600] Valid loss:0.0550
2023-02-06 12:07:29 | Stage | Epoch[411/600] LR:0.001

2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[002/030] Train loss: 0.0150
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[004/030] Train loss: 0.0161
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[005/030] Train loss: 0.0167
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:07:30 | Train | Epoch[412/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:07:31 | Train | Epoch[412/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:07:32 | Train | Epoch[412/600] Iteration[026/030] Train loss: 0.0169
2023-02-06 12:07:32 | Train | Epoch[412/600] Iteration[027/030] Train loss: 0.0169
2023-02-06 12:07:32 | Train | Epoch[412/600] Iteration[028/030] Train loss: 0.0169
2023-02-06 12:07:32 | Train | Epoch[412/600] Iteration[029/030] Train loss: 0.0169
2023-02-06 12:07:32 | Train | Epoch[412/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:07:32 | Valid | Epoch[412/600] Iteration[001/008] Valid loss: 0.0628
2023-02-06 12:07:32 | Valid | Epoch[412/600] Iteration[002/008] Valid loss: 0.0486
2023-02-06 12:07:32 | Valid | Epoch[412/600] Iteration[003/008] Valid loss: 0.0510
2023-02-06 12:07:32 | Valid | Epoch[412/600] Iteration[004/008] Valid loss: 0.0459
2023-02-06 12:07:32 | Valid | Epoch[412/600] Iteration[005/008] Valid loss: 0.0440
2023-02-06 12:07:32 | Valid | Epoch[412/600] Iteration[006/008] Valid loss: 0.0418
2023-02-06 12:07:32 | Valid | Epoch[412/600] Iteration[007/008] Valid loss: 0.0426
2023-02-06 12:07:32 | Valid | Epoch[412/600] Iteration[008/008] Valid loss: 0.0413
2023-02-06 12:07:32 | Valid | Epoch[412/600] MIou: 0.9174695185543423
2023-02-06 12:07:32 | Valid | Epoch[412/600] Pixel Accuracy: 0.9862047831217448
2023-02-06 12:07:32 | Valid | Epoch[412/600] Mean Pixel Accuracy: 0.9315617148789991
2023-02-06 12:07:32 | Stage | Epoch[412/600] Train loss:0.0169
2023-02-06 12:07:32 | Stage | Epoch[412/600] Valid loss:0.0413
2023-02-06 12:07:32 | Stage | Epoch[412/600] LR:0.001

2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[001/030] Train loss: 0.0154
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[002/030] Train loss: 0.0156
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[003/030] Train loss: 0.0159
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[004/030] Train loss: 0.0161
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[007/030] Train loss: 0.0159
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[008/030] Train loss: 0.0160
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:07:33 | Train | Epoch[413/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:07:34 | Train | Epoch[413/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:07:35 | Train | Epoch[413/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:07:35 | Train | Epoch[413/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:07:35 | Train | Epoch[413/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:07:35 | Train | Epoch[413/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:07:35 | Valid | Epoch[413/600] Iteration[001/008] Valid loss: 0.1061
2023-02-06 12:07:35 | Valid | Epoch[413/600] Iteration[002/008] Valid loss: 0.0732
2023-02-06 12:07:35 | Valid | Epoch[413/600] Iteration[003/008] Valid loss: 0.0722
2023-02-06 12:07:35 | Valid | Epoch[413/600] Iteration[004/008] Valid loss: 0.0647
2023-02-06 12:07:35 | Valid | Epoch[413/600] Iteration[005/008] Valid loss: 0.0614
2023-02-06 12:07:35 | Valid | Epoch[413/600] Iteration[006/008] Valid loss: 0.0573
2023-02-06 12:07:35 | Valid | Epoch[413/600] Iteration[007/008] Valid loss: 0.0607
2023-02-06 12:07:35 | Valid | Epoch[413/600] Iteration[008/008] Valid loss: 0.0585
2023-02-06 12:07:35 | Valid | Epoch[413/600] MIou: 0.9366133323077187
2023-02-06 12:07:35 | Valid | Epoch[413/600] Pixel Accuracy: 0.9892069498697916
2023-02-06 12:07:35 | Valid | Epoch[413/600] Mean Pixel Accuracy: 0.9578635870020069
2023-02-06 12:07:35 | Stage | Epoch[413/600] Train loss:0.0167
2023-02-06 12:07:35 | Stage | Epoch[413/600] Valid loss:0.0585
2023-02-06 12:07:35 | Stage | Epoch[413/600] LR:0.001

2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[003/030] Train loss: 0.0181
2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[006/030] Train loss: 0.0177
2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[008/030] Train loss: 0.0176
2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[009/030] Train loss: 0.0174
2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[010/030] Train loss: 0.0174
2023-02-06 12:07:36 | Train | Epoch[414/600] Iteration[011/030] Train loss: 0.0172
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[012/030] Train loss: 0.0170
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[017/030] Train loss: 0.0172
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[018/030] Train loss: 0.0172
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[019/030] Train loss: 0.0172
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[020/030] Train loss: 0.0173
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[021/030] Train loss: 0.0173
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[022/030] Train loss: 0.0171
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[023/030] Train loss: 0.0170
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:07:37 | Train | Epoch[414/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:07:38 | Train | Epoch[414/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:07:38 | Train | Epoch[414/600] Iteration[027/030] Train loss: 0.0169
2023-02-06 12:07:38 | Train | Epoch[414/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:07:38 | Train | Epoch[414/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:07:38 | Train | Epoch[414/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:07:38 | Valid | Epoch[414/600] Iteration[001/008] Valid loss: 0.0595
2023-02-06 12:07:38 | Valid | Epoch[414/600] Iteration[002/008] Valid loss: 0.0468
2023-02-06 12:07:38 | Valid | Epoch[414/600] Iteration[003/008] Valid loss: 0.0480
2023-02-06 12:07:38 | Valid | Epoch[414/600] Iteration[004/008] Valid loss: 0.0433
2023-02-06 12:07:38 | Valid | Epoch[414/600] Iteration[005/008] Valid loss: 0.0417
2023-02-06 12:07:38 | Valid | Epoch[414/600] Iteration[006/008] Valid loss: 0.0398
2023-02-06 12:07:38 | Valid | Epoch[414/600] Iteration[007/008] Valid loss: 0.0404
2023-02-06 12:07:38 | Valid | Epoch[414/600] Iteration[008/008] Valid loss: 0.0394
2023-02-06 12:07:38 | Valid | Epoch[414/600] MIou: 0.9122020268393332
2023-02-06 12:07:38 | Valid | Epoch[414/600] Pixel Accuracy: 0.9853680928548177
2023-02-06 12:07:38 | Valid | Epoch[414/600] Mean Pixel Accuracy: 0.925370047977399
2023-02-06 12:07:38 | Stage | Epoch[414/600] Train loss:0.0167
2023-02-06 12:07:38 | Stage | Epoch[414/600] Valid loss:0.0394
2023-02-06 12:07:38 | Stage | Epoch[414/600] LR:0.001

2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[003/030] Train loss: 0.0176
2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[004/030] Train loss: 0.0171
2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:07:39 | Train | Epoch[415/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[018/030] Train loss: 0.0171
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[019/030] Train loss: 0.0171
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[020/030] Train loss: 0.0170
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[021/030] Train loss: 0.0170
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:07:40 | Train | Epoch[415/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:07:41 | Train | Epoch[415/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:07:41 | Train | Epoch[415/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:07:41 | Train | Epoch[415/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:07:41 | Train | Epoch[415/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:07:41 | Train | Epoch[415/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:07:41 | Valid | Epoch[415/600] Iteration[001/008] Valid loss: 0.0688
2023-02-06 12:07:41 | Valid | Epoch[415/600] Iteration[002/008] Valid loss: 0.0511
2023-02-06 12:07:41 | Valid | Epoch[415/600] Iteration[003/008] Valid loss: 0.0514
2023-02-06 12:07:41 | Valid | Epoch[415/600] Iteration[004/008] Valid loss: 0.0458
2023-02-06 12:07:41 | Valid | Epoch[415/600] Iteration[005/008] Valid loss: 0.0438
2023-02-06 12:07:41 | Valid | Epoch[415/600] Iteration[006/008] Valid loss: 0.0414
2023-02-06 12:07:41 | Valid | Epoch[415/600] Iteration[007/008] Valid loss: 0.0424
2023-02-06 12:07:41 | Valid | Epoch[415/600] Iteration[008/008] Valid loss: 0.0413
2023-02-06 12:07:41 | Valid | Epoch[415/600] MIou: 0.9214790447937762
2023-02-06 12:07:41 | Valid | Epoch[415/600] Pixel Accuracy: 0.9868647257486979
2023-02-06 12:07:41 | Valid | Epoch[415/600] Mean Pixel Accuracy: 0.9356463042702357
2023-02-06 12:07:41 | Stage | Epoch[415/600] Train loss:0.0167
2023-02-06 12:07:41 | Stage | Epoch[415/600] Valid loss:0.0413
2023-02-06 12:07:41 | Stage | Epoch[415/600] LR:0.001

2023-02-06 12:07:42 | Train | Epoch[416/600] Iteration[001/030] Train loss: 0.0155
2023-02-06 12:07:42 | Train | Epoch[416/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:07:42 | Train | Epoch[416/600] Iteration[003/030] Train loss: 0.0162
2023-02-06 12:07:42 | Train | Epoch[416/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:07:42 | Train | Epoch[416/600] Iteration[005/030] Train loss: 0.0160
2023-02-06 12:07:42 | Train | Epoch[416/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:07:42 | Train | Epoch[416/600] Iteration[007/030] Train loss: 0.0158
2023-02-06 12:07:42 | Train | Epoch[416/600] Iteration[008/030] Train loss: 0.0160
2023-02-06 12:07:42 | Train | Epoch[416/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:07:42 | Train | Epoch[416/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[014/030] Train loss: 0.0170
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[015/030] Train loss: 0.0170
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[016/030] Train loss: 0.0169
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[019/030] Train loss: 0.0170
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[020/030] Train loss: 0.0169
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:07:43 | Train | Epoch[416/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:07:44 | Train | Epoch[416/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:07:44 | Train | Epoch[416/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:07:44 | Train | Epoch[416/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:07:44 | Train | Epoch[416/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:07:44 | Train | Epoch[416/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:07:44 | Train | Epoch[416/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:07:44 | Valid | Epoch[416/600] Iteration[001/008] Valid loss: 0.0764
2023-02-06 12:07:44 | Valid | Epoch[416/600] Iteration[002/008] Valid loss: 0.0553
2023-02-06 12:07:44 | Valid | Epoch[416/600] Iteration[003/008] Valid loss: 0.0560
2023-02-06 12:07:44 | Valid | Epoch[416/600] Iteration[004/008] Valid loss: 0.0499
2023-02-06 12:07:44 | Valid | Epoch[416/600] Iteration[005/008] Valid loss: 0.0473
2023-02-06 12:07:44 | Valid | Epoch[416/600] Iteration[006/008] Valid loss: 0.0446
2023-02-06 12:07:44 | Valid | Epoch[416/600] Iteration[007/008] Valid loss: 0.0460
2023-02-06 12:07:44 | Valid | Epoch[416/600] Iteration[008/008] Valid loss: 0.0444
2023-02-06 12:07:45 | Valid | Epoch[416/600] MIou: 0.9266577154975404
2023-02-06 12:07:45 | Valid | Epoch[416/600] Pixel Accuracy: 0.987677256266276
2023-02-06 12:07:45 | Valid | Epoch[416/600] Mean Pixel Accuracy: 0.9424206962653408
2023-02-06 12:07:45 | Stage | Epoch[416/600] Train loss:0.0166
2023-02-06 12:07:45 | Stage | Epoch[416/600] Valid loss:0.0444
2023-02-06 12:07:45 | Stage | Epoch[416/600] LR:0.001

2023-02-06 12:07:45 | Train | Epoch[417/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 12:07:45 | Train | Epoch[417/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:07:45 | Train | Epoch[417/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:07:45 | Train | Epoch[417/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:07:45 | Train | Epoch[417/600] Iteration[005/030] Train loss: 0.0168
2023-02-06 12:07:45 | Train | Epoch[417/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:07:45 | Train | Epoch[417/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:07:45 | Train | Epoch[417/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:07:45 | Train | Epoch[417/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:07:45 | Train | Epoch[417/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:07:46 | Train | Epoch[417/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:07:47 | Train | Epoch[417/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:07:47 | Train | Epoch[417/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:07:47 | Train | Epoch[417/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:07:47 | Train | Epoch[417/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:07:47 | Train | Epoch[417/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:07:47 | Train | Epoch[417/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:07:47 | Valid | Epoch[417/600] Iteration[001/008] Valid loss: 0.1141
2023-02-06 12:07:47 | Valid | Epoch[417/600] Iteration[002/008] Valid loss: 0.0791
2023-02-06 12:07:47 | Valid | Epoch[417/600] Iteration[003/008] Valid loss: 0.0778
2023-02-06 12:07:47 | Valid | Epoch[417/600] Iteration[004/008] Valid loss: 0.0706
2023-02-06 12:07:47 | Valid | Epoch[417/600] Iteration[005/008] Valid loss: 0.0672
2023-02-06 12:07:47 | Valid | Epoch[417/600] Iteration[006/008] Valid loss: 0.0629
2023-02-06 12:07:47 | Valid | Epoch[417/600] Iteration[007/008] Valid loss: 0.0670
2023-02-06 12:07:47 | Valid | Epoch[417/600] Iteration[008/008] Valid loss: 0.0642
2023-02-06 12:07:48 | Valid | Epoch[417/600] MIou: 0.9384758595322515
2023-02-06 12:07:48 | Valid | Epoch[417/600] Pixel Accuracy: 0.9894879659016927
2023-02-06 12:07:48 | Valid | Epoch[417/600] Mean Pixel Accuracy: 0.9612326644548082
2023-02-06 12:07:48 | Stage | Epoch[417/600] Train loss:0.0166
2023-02-06 12:07:48 | Stage | Epoch[417/600] Valid loss:0.0642
2023-02-06 12:07:48 | Stage | Epoch[417/600] LR:0.001

2023-02-06 12:07:48 | Train | Epoch[418/600] Iteration[001/030] Train loss: 0.0169
2023-02-06 12:07:48 | Train | Epoch[418/600] Iteration[002/030] Train loss: 0.0154
2023-02-06 12:07:48 | Train | Epoch[418/600] Iteration[003/030] Train loss: 0.0168
2023-02-06 12:07:48 | Train | Epoch[418/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:07:48 | Train | Epoch[418/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:07:48 | Train | Epoch[418/600] Iteration[006/030] Train loss: 0.0165
2023-02-06 12:07:48 | Train | Epoch[418/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:07:48 | Train | Epoch[418/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:07:48 | Train | Epoch[418/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:07:49 | Train | Epoch[418/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:07:50 | Train | Epoch[418/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:07:50 | Train | Epoch[418/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:07:50 | Train | Epoch[418/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:07:50 | Train | Epoch[418/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:07:50 | Train | Epoch[418/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:07:50 | Train | Epoch[418/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:07:50 | Train | Epoch[418/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:07:50 | Valid | Epoch[418/600] Iteration[001/008] Valid loss: 0.0928
2023-02-06 12:07:50 | Valid | Epoch[418/600] Iteration[002/008] Valid loss: 0.0660
2023-02-06 12:07:50 | Valid | Epoch[418/600] Iteration[003/008] Valid loss: 0.0673
2023-02-06 12:07:50 | Valid | Epoch[418/600] Iteration[004/008] Valid loss: 0.0604
2023-02-06 12:07:50 | Valid | Epoch[418/600] Iteration[005/008] Valid loss: 0.0576
2023-02-06 12:07:50 | Valid | Epoch[418/600] Iteration[006/008] Valid loss: 0.0540
2023-02-06 12:07:50 | Valid | Epoch[418/600] Iteration[007/008] Valid loss: 0.0561
2023-02-06 12:07:50 | Valid | Epoch[418/600] Iteration[008/008] Valid loss: 0.0537
2023-02-06 12:07:51 | Valid | Epoch[418/600] MIou: 0.9344807072331179
2023-02-06 12:07:51 | Valid | Epoch[418/600] Pixel Accuracy: 0.9889005025227865
2023-02-06 12:07:51 | Valid | Epoch[418/600] Mean Pixel Accuracy: 0.9535040988009449
2023-02-06 12:07:51 | Stage | Epoch[418/600] Train loss:0.0168
2023-02-06 12:07:51 | Stage | Epoch[418/600] Valid loss:0.0537
2023-02-06 12:07:51 | Stage | Epoch[418/600] LR:0.001

2023-02-06 12:07:51 | Train | Epoch[419/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 12:07:51 | Train | Epoch[419/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:07:51 | Train | Epoch[419/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:07:51 | Train | Epoch[419/600] Iteration[004/030] Train loss: 0.0157
2023-02-06 12:07:51 | Train | Epoch[419/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:07:51 | Train | Epoch[419/600] Iteration[006/030] Train loss: 0.0171
2023-02-06 12:07:51 | Train | Epoch[419/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:07:51 | Train | Epoch[419/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:07:51 | Train | Epoch[419/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[012/030] Train loss: 0.0170
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[018/030] Train loss: 0.0169
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[020/030] Train loss: 0.0170
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[021/030] Train loss: 0.0170
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 12:07:52 | Train | Epoch[419/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:07:53 | Train | Epoch[419/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:07:53 | Train | Epoch[419/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:07:53 | Train | Epoch[419/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:07:53 | Train | Epoch[419/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:07:53 | Train | Epoch[419/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:07:53 | Train | Epoch[419/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:07:53 | Train | Epoch[419/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:07:53 | Valid | Epoch[419/600] Iteration[001/008] Valid loss: 0.0583
2023-02-06 12:07:53 | Valid | Epoch[419/600] Iteration[002/008] Valid loss: 0.0454
2023-02-06 12:07:53 | Valid | Epoch[419/600] Iteration[003/008] Valid loss: 0.0458
2023-02-06 12:07:53 | Valid | Epoch[419/600] Iteration[004/008] Valid loss: 0.0414
2023-02-06 12:07:53 | Valid | Epoch[419/600] Iteration[005/008] Valid loss: 0.0401
2023-02-06 12:07:53 | Valid | Epoch[419/600] Iteration[006/008] Valid loss: 0.0384
2023-02-06 12:07:53 | Valid | Epoch[419/600] Iteration[007/008] Valid loss: 0.0389
2023-02-06 12:07:53 | Valid | Epoch[419/600] Iteration[008/008] Valid loss: 0.0382
2023-02-06 12:07:54 | Valid | Epoch[419/600] MIou: 0.9091131986883774
2023-02-06 12:07:54 | Valid | Epoch[419/600] Pixel Accuracy: 0.984869639078776
2023-02-06 12:07:54 | Valid | Epoch[419/600] Mean Pixel Accuracy: 0.9220399692547248
2023-02-06 12:07:54 | Stage | Epoch[419/600] Train loss:0.0168
2023-02-06 12:07:54 | Stage | Epoch[419/600] Valid loss:0.0382
2023-02-06 12:07:54 | Stage | Epoch[419/600] LR:0.001

2023-02-06 12:07:54 | Train | Epoch[420/600] Iteration[001/030] Train loss: 0.0144
2023-02-06 12:07:54 | Train | Epoch[420/600] Iteration[002/030] Train loss: 0.0140
2023-02-06 12:07:54 | Train | Epoch[420/600] Iteration[003/030] Train loss: 0.0140
2023-02-06 12:07:54 | Train | Epoch[420/600] Iteration[004/030] Train loss: 0.0142
2023-02-06 12:07:54 | Train | Epoch[420/600] Iteration[005/030] Train loss: 0.0152
2023-02-06 12:07:54 | Train | Epoch[420/600] Iteration[006/030] Train loss: 0.0151
2023-02-06 12:07:54 | Train | Epoch[420/600] Iteration[007/030] Train loss: 0.0155
2023-02-06 12:07:54 | Train | Epoch[420/600] Iteration[008/030] Train loss: 0.0156
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[009/030] Train loss: 0.0157
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[010/030] Train loss: 0.0157
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[011/030] Train loss: 0.0158
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[014/030] Train loss: 0.0160
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:07:55 | Train | Epoch[420/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:07:56 | Train | Epoch[420/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:07:56 | Train | Epoch[420/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:07:56 | Train | Epoch[420/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:07:56 | Train | Epoch[420/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:07:56 | Train | Epoch[420/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:07:56 | Train | Epoch[420/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:07:56 | Train | Epoch[420/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:07:56 | Train | Epoch[420/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:07:56 | Valid | Epoch[420/600] Iteration[001/008] Valid loss: 0.1297
2023-02-06 12:07:56 | Valid | Epoch[420/600] Iteration[002/008] Valid loss: 0.0907
2023-02-06 12:07:56 | Valid | Epoch[420/600] Iteration[003/008] Valid loss: 0.0882
2023-02-06 12:07:56 | Valid | Epoch[420/600] Iteration[004/008] Valid loss: 0.0804
2023-02-06 12:07:57 | Valid | Epoch[420/600] Iteration[005/008] Valid loss: 0.0772
2023-02-06 12:07:57 | Valid | Epoch[420/600] Iteration[006/008] Valid loss: 0.0724
2023-02-06 12:07:57 | Valid | Epoch[420/600] Iteration[007/008] Valid loss: 0.0776
2023-02-06 12:07:57 | Valid | Epoch[420/600] Iteration[008/008] Valid loss: 0.0745
2023-02-06 12:07:57 | Valid | Epoch[420/600] MIou: 0.9407049501222109
2023-02-06 12:07:57 | Valid | Epoch[420/600] Pixel Accuracy: 0.9898211161295573
2023-02-06 12:07:57 | Valid | Epoch[420/600] Mean Pixel Accuracy: 0.9655624463974564
2023-02-06 12:07:57 | Stage | Epoch[420/600] Train loss:0.0166
2023-02-06 12:07:57 | Stage | Epoch[420/600] Valid loss:0.0745
2023-02-06 12:07:57 | Stage | Epoch[420/600] LR:0.001

2023-02-06 12:07:57 | Train | Epoch[421/600] Iteration[001/030] Train loss: 0.0173
2023-02-06 12:07:57 | Train | Epoch[421/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 12:07:57 | Train | Epoch[421/600] Iteration[003/030] Train loss: 0.0173
2023-02-06 12:07:57 | Train | Epoch[421/600] Iteration[004/030] Train loss: 0.0172
2023-02-06 12:07:57 | Train | Epoch[421/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:07:57 | Train | Epoch[421/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:07:57 | Train | Epoch[421/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[009/030] Train loss: 0.0170
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[011/030] Train loss: 0.0172
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[014/030] Train loss: 0.0172
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[015/030] Train loss: 0.0172
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[016/030] Train loss: 0.0171
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[017/030] Train loss: 0.0172
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[018/030] Train loss: 0.0171
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[019/030] Train loss: 0.0170
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[020/030] Train loss: 0.0169
2023-02-06 12:07:58 | Train | Epoch[421/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:07:59 | Train | Epoch[421/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 12:07:59 | Train | Epoch[421/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:07:59 | Train | Epoch[421/600] Iteration[024/030] Train loss: 0.0171
2023-02-06 12:07:59 | Train | Epoch[421/600] Iteration[025/030] Train loss: 0.0171
2023-02-06 12:07:59 | Train | Epoch[421/600] Iteration[026/030] Train loss: 0.0171
2023-02-06 12:07:59 | Train | Epoch[421/600] Iteration[027/030] Train loss: 0.0170
2023-02-06 12:07:59 | Train | Epoch[421/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:07:59 | Train | Epoch[421/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:07:59 | Train | Epoch[421/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:07:59 | Valid | Epoch[421/600] Iteration[001/008] Valid loss: 0.0684
2023-02-06 12:07:59 | Valid | Epoch[421/600] Iteration[002/008] Valid loss: 0.0512
2023-02-06 12:08:00 | Valid | Epoch[421/600] Iteration[003/008] Valid loss: 0.0523
2023-02-06 12:08:00 | Valid | Epoch[421/600] Iteration[004/008] Valid loss: 0.0467
2023-02-06 12:08:00 | Valid | Epoch[421/600] Iteration[005/008] Valid loss: 0.0445
2023-02-06 12:08:00 | Valid | Epoch[421/600] Iteration[006/008] Valid loss: 0.0421
2023-02-06 12:08:00 | Valid | Epoch[421/600] Iteration[007/008] Valid loss: 0.0431
2023-02-06 12:08:00 | Valid | Epoch[421/600] Iteration[008/008] Valid loss: 0.0417
2023-02-06 12:08:00 | Valid | Epoch[421/600] MIou: 0.9209797080196527
2023-02-06 12:08:00 | Valid | Epoch[421/600] Pixel Accuracy: 0.9867820739746094
2023-02-06 12:08:00 | Valid | Epoch[421/600] Mean Pixel Accuracy: 0.935150701852826
2023-02-06 12:08:00 | Stage | Epoch[421/600] Train loss:0.0168
2023-02-06 12:08:00 | Stage | Epoch[421/600] Valid loss:0.0417
2023-02-06 12:08:00 | Stage | Epoch[421/600] LR:0.001

2023-02-06 12:08:00 | Train | Epoch[422/600] Iteration[001/030] Train loss: 0.0160
2023-02-06 12:08:00 | Train | Epoch[422/600] Iteration[002/030] Train loss: 0.0174
2023-02-06 12:08:00 | Train | Epoch[422/600] Iteration[003/030] Train loss: 0.0170
2023-02-06 12:08:00 | Train | Epoch[422/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:08:00 | Train | Epoch[422/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:08:00 | Train | Epoch[422/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[010/030] Train loss: 0.0174
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[011/030] Train loss: 0.0172
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[012/030] Train loss: 0.0172
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[013/030] Train loss: 0.0172
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[014/030] Train loss: 0.0171
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[015/030] Train loss: 0.0171
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[016/030] Train loss: 0.0171
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[017/030] Train loss: 0.0170
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[018/030] Train loss: 0.0169
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:08:01 | Train | Epoch[422/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:08:02 | Train | Epoch[422/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:08:02 | Train | Epoch[422/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:08:02 | Train | Epoch[422/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:08:02 | Train | Epoch[422/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:08:02 | Train | Epoch[422/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:08:02 | Train | Epoch[422/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:08:02 | Train | Epoch[422/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:08:02 | Train | Epoch[422/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:08:02 | Train | Epoch[422/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:08:02 | Train | Epoch[422/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:08:03 | Valid | Epoch[422/600] Iteration[001/008] Valid loss: 0.0874
2023-02-06 12:08:03 | Valid | Epoch[422/600] Iteration[002/008] Valid loss: 0.0615
2023-02-06 12:08:03 | Valid | Epoch[422/600] Iteration[003/008] Valid loss: 0.0607
2023-02-06 12:08:03 | Valid | Epoch[422/600] Iteration[004/008] Valid loss: 0.0543
2023-02-06 12:08:03 | Valid | Epoch[422/600] Iteration[005/008] Valid loss: 0.0515
2023-02-06 12:08:03 | Valid | Epoch[422/600] Iteration[006/008] Valid loss: 0.0481
2023-02-06 12:08:03 | Valid | Epoch[422/600] Iteration[007/008] Valid loss: 0.0500
2023-02-06 12:08:03 | Valid | Epoch[422/600] Iteration[008/008] Valid loss: 0.0482
2023-02-06 12:08:03 | Valid | Epoch[422/600] MIou: 0.9314638577127907
2023-02-06 12:08:03 | Valid | Epoch[422/600] Pixel Accuracy: 0.9884363810221354
2023-02-06 12:08:03 | Valid | Epoch[422/600] Mean Pixel Accuracy: 0.9488170082429401
2023-02-06 12:08:03 | Stage | Epoch[422/600] Train loss:0.0167
2023-02-06 12:08:03 | Stage | Epoch[422/600] Valid loss:0.0482
2023-02-06 12:08:03 | Stage | Epoch[422/600] LR:0.001

2023-02-06 12:08:03 | Train | Epoch[423/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:08:03 | Train | Epoch[423/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:08:03 | Train | Epoch[423/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:08:03 | Train | Epoch[423/600] Iteration[004/030] Train loss: 0.0177
2023-02-06 12:08:03 | Train | Epoch[423/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:08:03 | Train | Epoch[423/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:08:04 | Train | Epoch[423/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:08:05 | Train | Epoch[423/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:08:05 | Train | Epoch[423/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:08:05 | Train | Epoch[423/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:08:05 | Train | Epoch[423/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:08:05 | Train | Epoch[423/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:08:05 | Train | Epoch[423/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:08:05 | Train | Epoch[423/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:08:05 | Train | Epoch[423/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:08:05 | Train | Epoch[423/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:08:05 | Train | Epoch[423/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:08:06 | Valid | Epoch[423/600] Iteration[001/008] Valid loss: 0.0529
2023-02-06 12:08:06 | Valid | Epoch[423/600] Iteration[002/008] Valid loss: 0.0436
2023-02-06 12:08:06 | Valid | Epoch[423/600] Iteration[003/008] Valid loss: 0.0446
2023-02-06 12:08:06 | Valid | Epoch[423/600] Iteration[004/008] Valid loss: 0.0407
2023-02-06 12:08:06 | Valid | Epoch[423/600] Iteration[005/008] Valid loss: 0.0400
2023-02-06 12:08:06 | Valid | Epoch[423/600] Iteration[006/008] Valid loss: 0.0386
2023-02-06 12:08:06 | Valid | Epoch[423/600] Iteration[007/008] Valid loss: 0.0386
2023-02-06 12:08:06 | Valid | Epoch[423/600] Iteration[008/008] Valid loss: 0.0384
2023-02-06 12:08:06 | Valid | Epoch[423/600] MIou: 0.8946143408440778
2023-02-06 12:08:06 | Valid | Epoch[423/600] Pixel Accuracy: 0.9825172424316406
2023-02-06 12:08:06 | Valid | Epoch[423/600] Mean Pixel Accuracy: 0.9071339993937333
2023-02-06 12:08:06 | Stage | Epoch[423/600] Train loss:0.0168
2023-02-06 12:08:06 | Stage | Epoch[423/600] Valid loss:0.0384
2023-02-06 12:08:06 | Stage | Epoch[423/600] LR:0.001

2023-02-06 12:08:06 | Train | Epoch[424/600] Iteration[001/030] Train loss: 0.0170
2023-02-06 12:08:06 | Train | Epoch[424/600] Iteration[002/030] Train loss: 0.0161
2023-02-06 12:08:06 | Train | Epoch[424/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:08:06 | Train | Epoch[424/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:08:06 | Train | Epoch[424/600] Iteration[005/030] Train loss: 0.0157
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[006/030] Train loss: 0.0165
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:08:07 | Train | Epoch[424/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:08:08 | Train | Epoch[424/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:08:09 | Valid | Epoch[424/600] Iteration[001/008] Valid loss: 0.1227
2023-02-06 12:08:09 | Valid | Epoch[424/600] Iteration[002/008] Valid loss: 0.0857
2023-02-06 12:08:09 | Valid | Epoch[424/600] Iteration[003/008] Valid loss: 0.0835
2023-02-06 12:08:09 | Valid | Epoch[424/600] Iteration[004/008] Valid loss: 0.0765
2023-02-06 12:08:09 | Valid | Epoch[424/600] Iteration[005/008] Valid loss: 0.0734
2023-02-06 12:08:09 | Valid | Epoch[424/600] Iteration[006/008] Valid loss: 0.0688
2023-02-06 12:08:09 | Valid | Epoch[424/600] Iteration[007/008] Valid loss: 0.0741
2023-02-06 12:08:09 | Valid | Epoch[424/600] Iteration[008/008] Valid loss: 0.0716
2023-02-06 12:08:09 | Valid | Epoch[424/600] MIou: 0.9393856778918908
2023-02-06 12:08:09 | Valid | Epoch[424/600] Pixel Accuracy: 0.9895858764648438
2023-02-06 12:08:09 | Valid | Epoch[424/600] Mean Pixel Accuracy: 0.9646913134780872
2023-02-06 12:08:09 | Stage | Epoch[424/600] Train loss:0.0164
2023-02-06 12:08:09 | Stage | Epoch[424/600] Valid loss:0.0716
2023-02-06 12:08:09 | Stage | Epoch[424/600] LR:0.001

2023-02-06 12:08:09 | Train | Epoch[425/600] Iteration[001/030] Train loss: 0.0174
2023-02-06 12:08:09 | Train | Epoch[425/600] Iteration[002/030] Train loss: 0.0168
2023-02-06 12:08:09 | Train | Epoch[425/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:08:09 | Train | Epoch[425/600] Iteration[004/030] Train loss: 0.0171
2023-02-06 12:08:09 | Train | Epoch[425/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 12:08:09 | Train | Epoch[425/600] Iteration[006/030] Train loss: 0.0160
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:08:10 | Train | Epoch[425/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:08:11 | Train | Epoch[425/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:08:12 | Valid | Epoch[425/600] Iteration[001/008] Valid loss: 0.0735
2023-02-06 12:08:12 | Valid | Epoch[425/600] Iteration[002/008] Valid loss: 0.0536
2023-02-06 12:08:12 | Valid | Epoch[425/600] Iteration[003/008] Valid loss: 0.0550
2023-02-06 12:08:12 | Valid | Epoch[425/600] Iteration[004/008] Valid loss: 0.0492
2023-02-06 12:08:12 | Valid | Epoch[425/600] Iteration[005/008] Valid loss: 0.0467
2023-02-06 12:08:12 | Valid | Epoch[425/600] Iteration[006/008] Valid loss: 0.0440
2023-02-06 12:08:12 | Valid | Epoch[425/600] Iteration[007/008] Valid loss: 0.0452
2023-02-06 12:08:12 | Valid | Epoch[425/600] Iteration[008/008] Valid loss: 0.0436
2023-02-06 12:08:12 | Valid | Epoch[425/600] MIou: 0.9238189097965752
2023-02-06 12:08:12 | Valid | Epoch[425/600] Pixel Accuracy: 0.9872271219889323
2023-02-06 12:08:12 | Valid | Epoch[425/600] Mean Pixel Accuracy: 0.9388318547818839
2023-02-06 12:08:12 | Stage | Epoch[425/600] Train loss:0.0166
2023-02-06 12:08:12 | Stage | Epoch[425/600] Valid loss:0.0436
2023-02-06 12:08:12 | Stage | Epoch[425/600] LR:0.001

2023-02-06 12:08:12 | Train | Epoch[426/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 12:08:12 | Train | Epoch[426/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:08:12 | Train | Epoch[426/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:08:12 | Train | Epoch[426/600] Iteration[004/030] Train loss: 0.0159
2023-02-06 12:08:12 | Train | Epoch[426/600] Iteration[005/030] Train loss: 0.0162
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:08:13 | Train | Epoch[426/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:08:14 | Train | Epoch[426/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:08:15 | Valid | Epoch[426/600] Iteration[001/008] Valid loss: 0.0727
2023-02-06 12:08:15 | Valid | Epoch[426/600] Iteration[002/008] Valid loss: 0.0533
2023-02-06 12:08:15 | Valid | Epoch[426/600] Iteration[003/008] Valid loss: 0.0542
2023-02-06 12:08:15 | Valid | Epoch[426/600] Iteration[004/008] Valid loss: 0.0481
2023-02-06 12:08:15 | Valid | Epoch[426/600] Iteration[005/008] Valid loss: 0.0458
2023-02-06 12:08:15 | Valid | Epoch[426/600] Iteration[006/008] Valid loss: 0.0431
2023-02-06 12:08:15 | Valid | Epoch[426/600] Iteration[007/008] Valid loss: 0.0442
2023-02-06 12:08:15 | Valid | Epoch[426/600] Iteration[008/008] Valid loss: 0.0428
2023-02-06 12:08:15 | Valid | Epoch[426/600] MIou: 0.9232554258482408
2023-02-06 12:08:15 | Valid | Epoch[426/600] Pixel Accuracy: 0.9871368408203125
2023-02-06 12:08:15 | Valid | Epoch[426/600] Mean Pixel Accuracy: 0.9381608661930279
2023-02-06 12:08:15 | Stage | Epoch[426/600] Train loss:0.0164
2023-02-06 12:08:15 | Stage | Epoch[426/600] Valid loss:0.0428
2023-02-06 12:08:15 | Stage | Epoch[426/600] LR:0.001

2023-02-06 12:08:15 | Train | Epoch[427/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 12:08:15 | Train | Epoch[427/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 12:08:15 | Train | Epoch[427/600] Iteration[003/030] Train loss: 0.0180
2023-02-06 12:08:15 | Train | Epoch[427/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[005/030] Train loss: 0.0179
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[006/030] Train loss: 0.0175
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[008/030] Train loss: 0.0174
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[009/030] Train loss: 0.0173
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:08:16 | Train | Epoch[427/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:08:17 | Train | Epoch[427/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:08:18 | Valid | Epoch[427/600] Iteration[001/008] Valid loss: 0.0724
2023-02-06 12:08:18 | Valid | Epoch[427/600] Iteration[002/008] Valid loss: 0.0524
2023-02-06 12:08:18 | Valid | Epoch[427/600] Iteration[003/008] Valid loss: 0.0525
2023-02-06 12:08:18 | Valid | Epoch[427/600] Iteration[004/008] Valid loss: 0.0468
2023-02-06 12:08:18 | Valid | Epoch[427/600] Iteration[005/008] Valid loss: 0.0447
2023-02-06 12:08:18 | Valid | Epoch[427/600] Iteration[006/008] Valid loss: 0.0422
2023-02-06 12:08:18 | Valid | Epoch[427/600] Iteration[007/008] Valid loss: 0.0434
2023-02-06 12:08:18 | Valid | Epoch[427/600] Iteration[008/008] Valid loss: 0.0421
2023-02-06 12:08:18 | Valid | Epoch[427/600] MIou: 0.9224223199691864
2023-02-06 12:08:18 | Valid | Epoch[427/600] Pixel Accuracy: 0.9870033264160156
2023-02-06 12:08:18 | Valid | Epoch[427/600] Mean Pixel Accuracy: 0.9371744530844353
2023-02-06 12:08:18 | Stage | Epoch[427/600] Train loss:0.0165
2023-02-06 12:08:18 | Stage | Epoch[427/600] Valid loss:0.0421
2023-02-06 12:08:18 | Stage | Epoch[427/600] LR:0.001

2023-02-06 12:08:18 | Train | Epoch[428/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 12:08:18 | Train | Epoch[428/600] Iteration[002/030] Train loss: 0.0212
2023-02-06 12:08:18 | Train | Epoch[428/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[005/030] Train loss: 0.0180
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:08:19 | Train | Epoch[428/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:08:20 | Train | Epoch[428/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:08:21 | Valid | Epoch[428/600] Iteration[001/008] Valid loss: 0.0793
2023-02-06 12:08:21 | Valid | Epoch[428/600] Iteration[002/008] Valid loss: 0.0567
2023-02-06 12:08:21 | Valid | Epoch[428/600] Iteration[003/008] Valid loss: 0.0582
2023-02-06 12:08:21 | Valid | Epoch[428/600] Iteration[004/008] Valid loss: 0.0518
2023-02-06 12:08:21 | Valid | Epoch[428/600] Iteration[005/008] Valid loss: 0.0491
2023-02-06 12:08:21 | Valid | Epoch[428/600] Iteration[006/008] Valid loss: 0.0460
2023-02-06 12:08:21 | Valid | Epoch[428/600] Iteration[007/008] Valid loss: 0.0474
2023-02-06 12:08:21 | Valid | Epoch[428/600] Iteration[008/008] Valid loss: 0.0457
2023-02-06 12:08:21 | Valid | Epoch[428/600] MIou: 0.9279161941687651
2023-02-06 12:08:21 | Valid | Epoch[428/600] Pixel Accuracy: 0.9878807067871094
2023-02-06 12:08:21 | Valid | Epoch[428/600] Mean Pixel Accuracy: 0.9438957227236426
2023-02-06 12:08:21 | Stage | Epoch[428/600] Train loss:0.0165
2023-02-06 12:08:21 | Stage | Epoch[428/600] Valid loss:0.0457
2023-02-06 12:08:21 | Stage | Epoch[428/600] LR:0.001

2023-02-06 12:08:21 | Train | Epoch[429/600] Iteration[001/030] Train loss: 0.0161
2023-02-06 12:08:21 | Train | Epoch[429/600] Iteration[002/030] Train loss: 0.0169
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[005/030] Train loss: 0.0168
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:08:22 | Train | Epoch[429/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[018/030] Train loss: 0.0169
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:08:23 | Train | Epoch[429/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:08:24 | Valid | Epoch[429/600] Iteration[001/008] Valid loss: 0.0578
2023-02-06 12:08:24 | Valid | Epoch[429/600] Iteration[002/008] Valid loss: 0.0454
2023-02-06 12:08:24 | Valid | Epoch[429/600] Iteration[003/008] Valid loss: 0.0465
2023-02-06 12:08:24 | Valid | Epoch[429/600] Iteration[004/008] Valid loss: 0.0421
2023-02-06 12:08:24 | Valid | Epoch[429/600] Iteration[005/008] Valid loss: 0.0408
2023-02-06 12:08:24 | Valid | Epoch[429/600] Iteration[006/008] Valid loss: 0.0391
2023-02-06 12:08:24 | Valid | Epoch[429/600] Iteration[007/008] Valid loss: 0.0397
2023-02-06 12:08:24 | Valid | Epoch[429/600] Iteration[008/008] Valid loss: 0.0389
2023-02-06 12:08:24 | Valid | Epoch[429/600] MIou: 0.9091796295344022
2023-02-06 12:08:24 | Valid | Epoch[429/600] Pixel Accuracy: 0.9848721822102865
2023-02-06 12:08:24 | Valid | Epoch[429/600] Mean Pixel Accuracy: 0.9223393692293325
2023-02-06 12:08:24 | Stage | Epoch[429/600] Train loss:0.0168
2023-02-06 12:08:24 | Stage | Epoch[429/600] Valid loss:0.0389
2023-02-06 12:08:24 | Stage | Epoch[429/600] LR:0.001

2023-02-06 12:08:24 | Train | Epoch[430/600] Iteration[001/030] Train loss: 0.0155
2023-02-06 12:08:24 | Train | Epoch[430/600] Iteration[002/030] Train loss: 0.0169
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[006/030] Train loss: 0.0162
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:08:25 | Train | Epoch[430/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[026/030] Train loss: 0.0170
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[027/030] Train loss: 0.0169
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[028/030] Train loss: 0.0169
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[029/030] Train loss: 0.0169
2023-02-06 12:08:26 | Train | Epoch[430/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:08:27 | Valid | Epoch[430/600] Iteration[001/008] Valid loss: 0.0873
2023-02-06 12:08:27 | Valid | Epoch[430/600] Iteration[002/008] Valid loss: 0.0612
2023-02-06 12:08:27 | Valid | Epoch[430/600] Iteration[003/008] Valid loss: 0.0614
2023-02-06 12:08:27 | Valid | Epoch[430/600] Iteration[004/008] Valid loss: 0.0548
2023-02-06 12:08:27 | Valid | Epoch[430/600] Iteration[005/008] Valid loss: 0.0518
2023-02-06 12:08:27 | Valid | Epoch[430/600] Iteration[006/008] Valid loss: 0.0484
2023-02-06 12:08:27 | Valid | Epoch[430/600] Iteration[007/008] Valid loss: 0.0503
2023-02-06 12:08:27 | Valid | Epoch[430/600] Iteration[008/008] Valid loss: 0.0485
2023-02-06 12:08:27 | Valid | Epoch[430/600] MIou: 0.9305171084585326
2023-02-06 12:08:27 | Valid | Epoch[430/600] Pixel Accuracy: 0.9882825215657552
2023-02-06 12:08:27 | Valid | Epoch[430/600] Mean Pixel Accuracy: 0.9476989436672973
2023-02-06 12:08:27 | Stage | Epoch[430/600] Train loss:0.0168
2023-02-06 12:08:27 | Stage | Epoch[430/600] Valid loss:0.0485
2023-02-06 12:08:27 | Stage | Epoch[430/600] LR:0.001

2023-02-06 12:08:27 | Train | Epoch[431/600] Iteration[001/030] Train loss: 0.0144
2023-02-06 12:08:27 | Train | Epoch[431/600] Iteration[002/030] Train loss: 0.0153
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[003/030] Train loss: 0.0148
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[004/030] Train loss: 0.0149
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[005/030] Train loss: 0.0153
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[006/030] Train loss: 0.0158
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[007/030] Train loss: 0.0160
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[008/030] Train loss: 0.0158
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[009/030] Train loss: 0.0159
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[011/030] Train loss: 0.0158
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[013/030] Train loss: 0.0160
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[014/030] Train loss: 0.0160
2023-02-06 12:08:28 | Train | Epoch[431/600] Iteration[015/030] Train loss: 0.0159
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[016/030] Train loss: 0.0159
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[018/030] Train loss: 0.0160
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:08:29 | Train | Epoch[431/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:08:30 | Valid | Epoch[431/600] Iteration[001/008] Valid loss: 0.1049
2023-02-06 12:08:30 | Valid | Epoch[431/600] Iteration[002/008] Valid loss: 0.0749
2023-02-06 12:08:30 | Valid | Epoch[431/600] Iteration[003/008] Valid loss: 0.0741
2023-02-06 12:08:30 | Valid | Epoch[431/600] Iteration[004/008] Valid loss: 0.0667
2023-02-06 12:08:30 | Valid | Epoch[431/600] Iteration[005/008] Valid loss: 0.0635
2023-02-06 12:08:30 | Valid | Epoch[431/600] Iteration[006/008] Valid loss: 0.0597
2023-02-06 12:08:30 | Valid | Epoch[431/600] Iteration[007/008] Valid loss: 0.0627
2023-02-06 12:08:30 | Valid | Epoch[431/600] Iteration[008/008] Valid loss: 0.0603
2023-02-06 12:08:30 | Valid | Epoch[431/600] MIou: 0.9365407930088516
2023-02-06 12:08:30 | Valid | Epoch[431/600] Pixel Accuracy: 0.9891955057779948
2023-02-06 12:08:30 | Valid | Epoch[431/600] Mean Pixel Accuracy: 0.9577558492968834
2023-02-06 12:08:30 | Stage | Epoch[431/600] Train loss:0.0167
2023-02-06 12:08:30 | Stage | Epoch[431/600] Valid loss:0.0603
2023-02-06 12:08:30 | Stage | Epoch[431/600] LR:0.001

2023-02-06 12:08:30 | Train | Epoch[432/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:08:30 | Train | Epoch[432/600] Iteration[002/030] Train loss: 0.0159
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[004/030] Train loss: 0.0161
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[005/030] Train loss: 0.0157
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[006/030] Train loss: 0.0158
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[007/030] Train loss: 0.0159
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:08:31 | Train | Epoch[432/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:08:32 | Train | Epoch[432/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:08:33 | Valid | Epoch[432/600] Iteration[001/008] Valid loss: 0.1032
2023-02-06 12:08:33 | Valid | Epoch[432/600] Iteration[002/008] Valid loss: 0.0724
2023-02-06 12:08:33 | Valid | Epoch[432/600] Iteration[003/008] Valid loss: 0.0733
2023-02-06 12:08:33 | Valid | Epoch[432/600] Iteration[004/008] Valid loss: 0.0665
2023-02-06 12:08:33 | Valid | Epoch[432/600] Iteration[005/008] Valid loss: 0.0634
2023-02-06 12:08:33 | Valid | Epoch[432/600] Iteration[006/008] Valid loss: 0.0592
2023-02-06 12:08:33 | Valid | Epoch[432/600] Iteration[007/008] Valid loss: 0.0621
2023-02-06 12:08:33 | Valid | Epoch[432/600] Iteration[008/008] Valid loss: 0.0593
2023-02-06 12:08:33 | Valid | Epoch[432/600] MIou: 0.9367920734767533
2023-02-06 12:08:33 | Valid | Epoch[432/600] Pixel Accuracy: 0.9892603556315104
2023-02-06 12:08:33 | Valid | Epoch[432/600] Mean Pixel Accuracy: 0.9570496583752416
2023-02-06 12:08:33 | Stage | Epoch[432/600] Train loss:0.0165
2023-02-06 12:08:33 | Stage | Epoch[432/600] Valid loss:0.0593
2023-02-06 12:08:33 | Stage | Epoch[432/600] LR:0.001

2023-02-06 12:08:33 | Train | Epoch[433/600] Iteration[001/030] Train loss: 0.0152
2023-02-06 12:08:33 | Train | Epoch[433/600] Iteration[002/030] Train loss: 0.0154
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[003/030] Train loss: 0.0151
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[004/030] Train loss: 0.0156
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[005/030] Train loss: 0.0156
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[006/030] Train loss: 0.0162
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:08:34 | Train | Epoch[433/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[022/030] Train loss: 0.0170
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[023/030] Train loss: 0.0170
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[024/030] Train loss: 0.0171
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[025/030] Train loss: 0.0170
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[026/030] Train loss: 0.0171
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[027/030] Train loss: 0.0171
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[028/030] Train loss: 0.0170
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[029/030] Train loss: 0.0170
2023-02-06 12:08:35 | Train | Epoch[433/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:08:36 | Valid | Epoch[433/600] Iteration[001/008] Valid loss: 0.0529
2023-02-06 12:08:36 | Valid | Epoch[433/600] Iteration[002/008] Valid loss: 0.0436
2023-02-06 12:08:36 | Valid | Epoch[433/600] Iteration[003/008] Valid loss: 0.0448
2023-02-06 12:08:36 | Valid | Epoch[433/600] Iteration[004/008] Valid loss: 0.0409
2023-02-06 12:08:36 | Valid | Epoch[433/600] Iteration[005/008] Valid loss: 0.0400
2023-02-06 12:08:36 | Valid | Epoch[433/600] Iteration[006/008] Valid loss: 0.0385
2023-02-06 12:08:36 | Valid | Epoch[433/600] Iteration[007/008] Valid loss: 0.0387
2023-02-06 12:08:36 | Valid | Epoch[433/600] Iteration[008/008] Valid loss: 0.0384
2023-02-06 12:08:36 | Valid | Epoch[433/600] MIou: 0.8975708825362596
2023-02-06 12:08:36 | Valid | Epoch[433/600] Pixel Accuracy: 0.9829851786295573
2023-02-06 12:08:36 | Valid | Epoch[433/600] Mean Pixel Accuracy: 0.9104156019963665
2023-02-06 12:08:36 | Stage | Epoch[433/600] Train loss:0.0169
2023-02-06 12:08:36 | Stage | Epoch[433/600] Valid loss:0.0384
2023-02-06 12:08:36 | Stage | Epoch[433/600] LR:0.001

2023-02-06 12:08:36 | Train | Epoch[434/600] Iteration[001/030] Train loss: 0.0192
2023-02-06 12:08:36 | Train | Epoch[434/600] Iteration[002/030] Train loss: 0.0185
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[004/030] Train loss: 0.0179
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[005/030] Train loss: 0.0174
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[006/030] Train loss: 0.0175
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:08:37 | Train | Epoch[434/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:08:38 | Train | Epoch[434/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:08:39 | Valid | Epoch[434/600] Iteration[001/008] Valid loss: 0.0681
2023-02-06 12:08:39 | Valid | Epoch[434/600] Iteration[002/008] Valid loss: 0.0507
2023-02-06 12:08:39 | Valid | Epoch[434/600] Iteration[003/008] Valid loss: 0.0519
2023-02-06 12:08:39 | Valid | Epoch[434/600] Iteration[004/008] Valid loss: 0.0465
2023-02-06 12:08:39 | Valid | Epoch[434/600] Iteration[005/008] Valid loss: 0.0446
2023-02-06 12:08:39 | Valid | Epoch[434/600] Iteration[006/008] Valid loss: 0.0422
2023-02-06 12:08:39 | Valid | Epoch[434/600] Iteration[007/008] Valid loss: 0.0434
2023-02-06 12:08:39 | Valid | Epoch[434/600] Iteration[008/008] Valid loss: 0.0421
2023-02-06 12:08:39 | Valid | Epoch[434/600] MIou: 0.9216273738062044
2023-02-06 12:08:39 | Valid | Epoch[434/600] Pixel Accuracy: 0.9868698120117188
2023-02-06 12:08:39 | Valid | Epoch[434/600] Mean Pixel Accuracy: 0.9364416588363258
2023-02-06 12:08:39 | Stage | Epoch[434/600] Train loss:0.0167
2023-02-06 12:08:39 | Stage | Epoch[434/600] Valid loss:0.0421
2023-02-06 12:08:39 | Stage | Epoch[434/600] LR:0.001

2023-02-06 12:08:39 | Train | Epoch[435/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 12:08:39 | Train | Epoch[435/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[005/030] Train loss: 0.0166
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:08:40 | Train | Epoch[435/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[018/030] Train loss: 0.0169
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[023/030] Train loss: 0.0170
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:08:41 | Train | Epoch[435/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:08:42 | Valid | Epoch[435/600] Iteration[001/008] Valid loss: 0.1048
2023-02-06 12:08:42 | Valid | Epoch[435/600] Iteration[002/008] Valid loss: 0.0727
2023-02-06 12:08:42 | Valid | Epoch[435/600] Iteration[003/008] Valid loss: 0.0726
2023-02-06 12:08:42 | Valid | Epoch[435/600] Iteration[004/008] Valid loss: 0.0657
2023-02-06 12:08:42 | Valid | Epoch[435/600] Iteration[005/008] Valid loss: 0.0625
2023-02-06 12:08:42 | Valid | Epoch[435/600] Iteration[006/008] Valid loss: 0.0583
2023-02-06 12:08:42 | Valid | Epoch[435/600] Iteration[007/008] Valid loss: 0.0616
2023-02-06 12:08:42 | Valid | Epoch[435/600] Iteration[008/008] Valid loss: 0.0592
2023-02-06 12:08:42 | Valid | Epoch[435/600] MIou: 0.9361185156474603
2023-02-06 12:08:42 | Valid | Epoch[435/600] Pixel Accuracy: 0.9891268412272135
2023-02-06 12:08:42 | Valid | Epoch[435/600] Mean Pixel Accuracy: 0.9572172110818474
2023-02-06 12:08:42 | Stage | Epoch[435/600] Train loss:0.0167
2023-02-06 12:08:42 | Stage | Epoch[435/600] Valid loss:0.0592
2023-02-06 12:08:42 | Stage | Epoch[435/600] LR:0.001

2023-02-06 12:08:42 | Train | Epoch[436/600] Iteration[001/030] Train loss: 0.0154
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[002/030] Train loss: 0.0158
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[004/030] Train loss: 0.0171
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[005/030] Train loss: 0.0167
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:08:43 | Train | Epoch[436/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[017/030] Train loss: 0.0170
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[019/030] Train loss: 0.0170
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[020/030] Train loss: 0.0169
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[021/030] Train loss: 0.0170
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[026/030] Train loss: 0.0169
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[027/030] Train loss: 0.0170
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[028/030] Train loss: 0.0169
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[029/030] Train loss: 0.0169
2023-02-06 12:08:44 | Train | Epoch[436/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:08:45 | Valid | Epoch[436/600] Iteration[001/008] Valid loss: 0.0721
2023-02-06 12:08:45 | Valid | Epoch[436/600] Iteration[002/008] Valid loss: 0.0529
2023-02-06 12:08:45 | Valid | Epoch[436/600] Iteration[003/008] Valid loss: 0.0543
2023-02-06 12:08:45 | Valid | Epoch[436/600] Iteration[004/008] Valid loss: 0.0487
2023-02-06 12:08:45 | Valid | Epoch[436/600] Iteration[005/008] Valid loss: 0.0465
2023-02-06 12:08:45 | Valid | Epoch[436/600] Iteration[006/008] Valid loss: 0.0439
2023-02-06 12:08:45 | Valid | Epoch[436/600] Iteration[007/008] Valid loss: 0.0454
2023-02-06 12:08:45 | Valid | Epoch[436/600] Iteration[008/008] Valid loss: 0.0439
2023-02-06 12:08:45 | Valid | Epoch[436/600] MIou: 0.9243881542536836
2023-02-06 12:08:45 | Valid | Epoch[436/600] Pixel Accuracy: 0.9873097737630209
2023-02-06 12:08:45 | Valid | Epoch[436/600] Mean Pixel Accuracy: 0.9398093330342117
2023-02-06 12:08:45 | Stage | Epoch[436/600] Train loss:0.0169
2023-02-06 12:08:45 | Stage | Epoch[436/600] Valid loss:0.0439
2023-02-06 12:08:45 | Stage | Epoch[436/600] LR:0.001

2023-02-06 12:08:45 | Train | Epoch[437/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:08:45 | Train | Epoch[437/600] Iteration[002/030] Train loss: 0.0149
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[003/030] Train loss: 0.0158
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[004/030] Train loss: 0.0154
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[005/030] Train loss: 0.0162
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[007/030] Train loss: 0.0169
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:08:46 | Train | Epoch[437/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[018/030] Train loss: 0.0169
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[019/030] Train loss: 0.0170
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[020/030] Train loss: 0.0170
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:08:47 | Train | Epoch[437/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:08:48 | Valid | Epoch[437/600] Iteration[001/008] Valid loss: 0.1052
2023-02-06 12:08:48 | Valid | Epoch[437/600] Iteration[002/008] Valid loss: 0.0726
2023-02-06 12:08:48 | Valid | Epoch[437/600] Iteration[003/008] Valid loss: 0.0727
2023-02-06 12:08:48 | Valid | Epoch[437/600] Iteration[004/008] Valid loss: 0.0656
2023-02-06 12:08:48 | Valid | Epoch[437/600] Iteration[005/008] Valid loss: 0.0623
2023-02-06 12:08:48 | Valid | Epoch[437/600] Iteration[006/008] Valid loss: 0.0581
2023-02-06 12:08:48 | Valid | Epoch[437/600] Iteration[007/008] Valid loss: 0.0612
2023-02-06 12:08:48 | Valid | Epoch[437/600] Iteration[008/008] Valid loss: 0.0587
2023-02-06 12:08:48 | Valid | Epoch[437/600] MIou: 0.9364005199646792
2023-02-06 12:08:48 | Valid | Epoch[437/600] Pixel Accuracy: 0.9891929626464844
2023-02-06 12:08:48 | Valid | Epoch[437/600] Mean Pixel Accuracy: 0.9567146141553623
2023-02-06 12:08:48 | Stage | Epoch[437/600] Train loss:0.0167
2023-02-06 12:08:48 | Stage | Epoch[437/600] Valid loss:0.0587
2023-02-06 12:08:48 | Stage | Epoch[437/600] LR:0.001

2023-02-06 12:08:48 | Train | Epoch[438/600] Iteration[001/030] Train loss: 0.0155
2023-02-06 12:08:48 | Train | Epoch[438/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:08:48 | Train | Epoch[438/600] Iteration[003/030] Train loss: 0.0156
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[005/030] Train loss: 0.0162
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[006/030] Train loss: 0.0158
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[007/030] Train loss: 0.0156
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[008/030] Train loss: 0.0155
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:08:49 | Train | Epoch[438/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[029/030] Train loss: 0.0169
2023-02-06 12:08:50 | Train | Epoch[438/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:08:51 | Valid | Epoch[438/600] Iteration[001/008] Valid loss: 0.0639
2023-02-06 12:08:51 | Valid | Epoch[438/600] Iteration[002/008] Valid loss: 0.0485
2023-02-06 12:08:51 | Valid | Epoch[438/600] Iteration[003/008] Valid loss: 0.0494
2023-02-06 12:08:51 | Valid | Epoch[438/600] Iteration[004/008] Valid loss: 0.0447
2023-02-06 12:08:51 | Valid | Epoch[438/600] Iteration[005/008] Valid loss: 0.0430
2023-02-06 12:08:51 | Valid | Epoch[438/600] Iteration[006/008] Valid loss: 0.0409
2023-02-06 12:08:51 | Valid | Epoch[438/600] Iteration[007/008] Valid loss: 0.0418
2023-02-06 12:08:51 | Valid | Epoch[438/600] Iteration[008/008] Valid loss: 0.0407
2023-02-06 12:08:51 | Valid | Epoch[438/600] MIou: 0.9162023144106188
2023-02-06 12:08:51 | Valid | Epoch[438/600] Pixel Accuracy: 0.985998789469401
2023-02-06 12:08:51 | Valid | Epoch[438/600] Mean Pixel Accuracy: 0.9301994190943745
2023-02-06 12:08:51 | Stage | Epoch[438/600] Train loss:0.0169
2023-02-06 12:08:51 | Stage | Epoch[438/600] Valid loss:0.0407
2023-02-06 12:08:51 | Stage | Epoch[438/600] LR:0.001

2023-02-06 12:08:51 | Train | Epoch[439/600] Iteration[001/030] Train loss: 0.0162
2023-02-06 12:08:51 | Train | Epoch[439/600] Iteration[002/030] Train loss: 0.0158
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[003/030] Train loss: 0.0162
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:08:52 | Train | Epoch[439/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:08:53 | Train | Epoch[439/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:08:54 | Valid | Epoch[439/600] Iteration[001/008] Valid loss: 0.1064
2023-02-06 12:08:54 | Valid | Epoch[439/600] Iteration[002/008] Valid loss: 0.0737
2023-02-06 12:08:54 | Valid | Epoch[439/600] Iteration[003/008] Valid loss: 0.0726
2023-02-06 12:08:54 | Valid | Epoch[439/600] Iteration[004/008] Valid loss: 0.0656
2023-02-06 12:08:54 | Valid | Epoch[439/600] Iteration[005/008] Valid loss: 0.0622
2023-02-06 12:08:54 | Valid | Epoch[439/600] Iteration[006/008] Valid loss: 0.0583
2023-02-06 12:08:54 | Valid | Epoch[439/600] Iteration[007/008] Valid loss: 0.0622
2023-02-06 12:08:54 | Valid | Epoch[439/600] Iteration[008/008] Valid loss: 0.0598
2023-02-06 12:08:54 | Valid | Epoch[439/600] MIou: 0.936912060017246
2023-02-06 12:08:54 | Valid | Epoch[439/600] Pixel Accuracy: 0.9892603556315104
2023-02-06 12:08:54 | Valid | Epoch[439/600] Mean Pixel Accuracy: 0.9580387719311261
2023-02-06 12:08:54 | Stage | Epoch[439/600] Train loss:0.0167
2023-02-06 12:08:54 | Stage | Epoch[439/600] Valid loss:0.0598
2023-02-06 12:08:54 | Stage | Epoch[439/600] LR:0.001

2023-02-06 12:08:54 | Train | Epoch[440/600] Iteration[001/030] Train loss: 0.0159
2023-02-06 12:08:54 | Train | Epoch[440/600] Iteration[002/030] Train loss: 0.0158
2023-02-06 12:08:54 | Train | Epoch[440/600] Iteration[003/030] Train loss: 0.0168
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[006/030] Train loss: 0.0158
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[007/030] Train loss: 0.0162
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:08:55 | Train | Epoch[440/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:08:56 | Train | Epoch[440/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:08:57 | Valid | Epoch[440/600] Iteration[001/008] Valid loss: 0.1016
2023-02-06 12:08:57 | Valid | Epoch[440/600] Iteration[002/008] Valid loss: 0.0713
2023-02-06 12:08:57 | Valid | Epoch[440/600] Iteration[003/008] Valid loss: 0.0719
2023-02-06 12:08:57 | Valid | Epoch[440/600] Iteration[004/008] Valid loss: 0.0648
2023-02-06 12:08:57 | Valid | Epoch[440/600] Iteration[005/008] Valid loss: 0.0620
2023-02-06 12:08:57 | Valid | Epoch[440/600] Iteration[006/008] Valid loss: 0.0579
2023-02-06 12:08:57 | Valid | Epoch[440/600] Iteration[007/008] Valid loss: 0.0609
2023-02-06 12:08:57 | Valid | Epoch[440/600] Iteration[008/008] Valid loss: 0.0584
2023-02-06 12:08:57 | Valid | Epoch[440/600] MIou: 0.9364079949697961
2023-02-06 12:08:57 | Valid | Epoch[440/600] Pixel Accuracy: 0.9891942342122396
2023-02-06 12:08:57 | Valid | Epoch[440/600] Mean Pixel Accuracy: 0.9567216535336445
2023-02-06 12:08:57 | Stage | Epoch[440/600] Train loss:0.0166
2023-02-06 12:08:57 | Stage | Epoch[440/600] Valid loss:0.0584
2023-02-06 12:08:57 | Stage | Epoch[440/600] LR:0.001

2023-02-06 12:08:57 | Train | Epoch[441/600] Iteration[001/030] Train loss: 0.0193
2023-02-06 12:08:57 | Train | Epoch[441/600] Iteration[002/030] Train loss: 0.0162
2023-02-06 12:08:57 | Train | Epoch[441/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[009/030] Train loss: 0.0170
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[013/030] Train loss: 0.0172
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:08:58 | Train | Epoch[441/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[026/030] Train loss: 0.0169
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[027/030] Train loss: 0.0170
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[028/030] Train loss: 0.0169
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:08:59 | Train | Epoch[441/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:09:00 | Valid | Epoch[441/600] Iteration[001/008] Valid loss: 0.0605
2023-02-06 12:09:00 | Valid | Epoch[441/600] Iteration[002/008] Valid loss: 0.0464
2023-02-06 12:09:00 | Valid | Epoch[441/600] Iteration[003/008] Valid loss: 0.0473
2023-02-06 12:09:00 | Valid | Epoch[441/600] Iteration[004/008] Valid loss: 0.0426
2023-02-06 12:09:00 | Valid | Epoch[441/600] Iteration[005/008] Valid loss: 0.0412
2023-02-06 12:09:00 | Valid | Epoch[441/600] Iteration[006/008] Valid loss: 0.0393
2023-02-06 12:09:00 | Valid | Epoch[441/600] Iteration[007/008] Valid loss: 0.0400
2023-02-06 12:09:00 | Valid | Epoch[441/600] Iteration[008/008] Valid loss: 0.0391
2023-02-06 12:09:00 | Valid | Epoch[441/600] MIou: 0.9140797680976995
2023-02-06 12:09:00 | Valid | Epoch[441/600] Pixel Accuracy: 0.9856694539388021
2023-02-06 12:09:00 | Valid | Epoch[441/600] Mean Pixel Accuracy: 0.9274631922215684
2023-02-06 12:09:00 | Stage | Epoch[441/600] Train loss:0.0167
2023-02-06 12:09:00 | Stage | Epoch[441/600] Valid loss:0.0391
2023-02-06 12:09:00 | Stage | Epoch[441/600] LR:0.001

2023-02-06 12:09:00 | Train | Epoch[442/600] Iteration[001/030] Train loss: 0.0152
2023-02-06 12:09:00 | Train | Epoch[442/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[003/030] Train loss: 0.0160
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:09:01 | Train | Epoch[442/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:09:02 | Train | Epoch[442/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:09:03 | Valid | Epoch[442/600] Iteration[001/008] Valid loss: 0.0729
2023-02-06 12:09:03 | Valid | Epoch[442/600] Iteration[002/008] Valid loss: 0.0536
2023-02-06 12:09:03 | Valid | Epoch[442/600] Iteration[003/008] Valid loss: 0.0549
2023-02-06 12:09:03 | Valid | Epoch[442/600] Iteration[004/008] Valid loss: 0.0490
2023-02-06 12:09:03 | Valid | Epoch[442/600] Iteration[005/008] Valid loss: 0.0466
2023-02-06 12:09:03 | Valid | Epoch[442/600] Iteration[006/008] Valid loss: 0.0439
2023-02-06 12:09:03 | Valid | Epoch[442/600] Iteration[007/008] Valid loss: 0.0452
2023-02-06 12:09:03 | Valid | Epoch[442/600] Iteration[008/008] Valid loss: 0.0437
2023-02-06 12:09:03 | Valid | Epoch[442/600] MIou: 0.9245777797046268
2023-02-06 12:09:03 | Valid | Epoch[442/600] Pixel Accuracy: 0.9873479207356771
2023-02-06 12:09:03 | Valid | Epoch[442/600] Mean Pixel Accuracy: 0.9397668955221917
2023-02-06 12:09:03 | Stage | Epoch[442/600] Train loss:0.0167
2023-02-06 12:09:03 | Stage | Epoch[442/600] Valid loss:0.0437
2023-02-06 12:09:03 | Stage | Epoch[442/600] LR:0.001

2023-02-06 12:09:03 | Train | Epoch[443/600] Iteration[001/030] Train loss: 0.0160
2023-02-06 12:09:03 | Train | Epoch[443/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:09:03 | Train | Epoch[443/600] Iteration[003/030] Train loss: 0.0183
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[006/030] Train loss: 0.0176
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:09:04 | Train | Epoch[443/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:09:05 | Train | Epoch[443/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:09:06 | Valid | Epoch[443/600] Iteration[001/008] Valid loss: 0.0818
2023-02-06 12:09:06 | Valid | Epoch[443/600] Iteration[002/008] Valid loss: 0.0580
2023-02-06 12:09:06 | Valid | Epoch[443/600] Iteration[003/008] Valid loss: 0.0589
2023-02-06 12:09:06 | Valid | Epoch[443/600] Iteration[004/008] Valid loss: 0.0527
2023-02-06 12:09:06 | Valid | Epoch[443/600] Iteration[005/008] Valid loss: 0.0499
2023-02-06 12:09:06 | Valid | Epoch[443/600] Iteration[006/008] Valid loss: 0.0467
2023-02-06 12:09:06 | Valid | Epoch[443/600] Iteration[007/008] Valid loss: 0.0483
2023-02-06 12:09:06 | Valid | Epoch[443/600] Iteration[008/008] Valid loss: 0.0465
2023-02-06 12:09:06 | Valid | Epoch[443/600] MIou: 0.928816333930256
2023-02-06 12:09:06 | Valid | Epoch[443/600] Pixel Accuracy: 0.9880154927571615
2023-02-06 12:09:06 | Valid | Epoch[443/600] Mean Pixel Accuracy: 0.9453583701024113
2023-02-06 12:09:06 | Stage | Epoch[443/600] Train loss:0.0167
2023-02-06 12:09:06 | Stage | Epoch[443/600] Valid loss:0.0465
2023-02-06 12:09:06 | Stage | Epoch[443/600] LR:0.001

2023-02-06 12:09:06 | Train | Epoch[444/600] Iteration[001/030] Train loss: 0.0174
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[002/030] Train loss: 0.0169
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[003/030] Train loss: 0.0181
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[004/030] Train loss: 0.0177
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[005/030] Train loss: 0.0172
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[006/030] Train loss: 0.0171
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[010/030] Train loss: 0.0171
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:09:07 | Train | Epoch[444/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[016/030] Train loss: 0.0171
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[017/030] Train loss: 0.0170
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[018/030] Train loss: 0.0171
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[019/030] Train loss: 0.0170
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[020/030] Train loss: 0.0170
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[021/030] Train loss: 0.0170
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:09:08 | Train | Epoch[444/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:09:09 | Valid | Epoch[444/600] Iteration[001/008] Valid loss: 0.1042
2023-02-06 12:09:09 | Valid | Epoch[444/600] Iteration[002/008] Valid loss: 0.0728
2023-02-06 12:09:09 | Valid | Epoch[444/600] Iteration[003/008] Valid loss: 0.0725
2023-02-06 12:09:09 | Valid | Epoch[444/600] Iteration[004/008] Valid loss: 0.0657
2023-02-06 12:09:09 | Valid | Epoch[444/600] Iteration[005/008] Valid loss: 0.0624
2023-02-06 12:09:09 | Valid | Epoch[444/600] Iteration[006/008] Valid loss: 0.0584
2023-02-06 12:09:09 | Valid | Epoch[444/600] Iteration[007/008] Valid loss: 0.0622
2023-02-06 12:09:09 | Valid | Epoch[444/600] Iteration[008/008] Valid loss: 0.0597
2023-02-06 12:09:09 | Valid | Epoch[444/600] MIou: 0.9366545532087046
2023-02-06 12:09:09 | Valid | Epoch[444/600] Pixel Accuracy: 0.989220937093099
2023-02-06 12:09:09 | Valid | Epoch[444/600] Mean Pixel Accuracy: 0.9576049751729699
2023-02-06 12:09:09 | Stage | Epoch[444/600] Train loss:0.0169
2023-02-06 12:09:09 | Stage | Epoch[444/600] Valid loss:0.0597
2023-02-06 12:09:09 | Stage | Epoch[444/600] LR:0.001

2023-02-06 12:09:09 | Train | Epoch[445/600] Iteration[001/030] Train loss: 0.0162
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[002/030] Train loss: 0.0156
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[003/030] Train loss: 0.0156
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[004/030] Train loss: 0.0154
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[005/030] Train loss: 0.0160
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[006/030] Train loss: 0.0162
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[007/030] Train loss: 0.0162
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[009/030] Train loss: 0.0166
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:09:10 | Train | Epoch[445/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[018/030] Train loss: 0.0169
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:09:11 | Train | Epoch[445/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:09:12 | Train | Epoch[445/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:09:12 | Train | Epoch[445/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:09:12 | Valid | Epoch[445/600] Iteration[001/008] Valid loss: 0.0564
2023-02-06 12:09:12 | Valid | Epoch[445/600] Iteration[002/008] Valid loss: 0.0447
2023-02-06 12:09:12 | Valid | Epoch[445/600] Iteration[003/008] Valid loss: 0.0461
2023-02-06 12:09:12 | Valid | Epoch[445/600] Iteration[004/008] Valid loss: 0.0419
2023-02-06 12:09:12 | Valid | Epoch[445/600] Iteration[005/008] Valid loss: 0.0407
2023-02-06 12:09:12 | Valid | Epoch[445/600] Iteration[006/008] Valid loss: 0.0390
2023-02-06 12:09:12 | Valid | Epoch[445/600] Iteration[007/008] Valid loss: 0.0398
2023-02-06 12:09:12 | Valid | Epoch[445/600] Iteration[008/008] Valid loss: 0.0390
2023-02-06 12:09:12 | Valid | Epoch[445/600] MIou: 0.9073815879109004
2023-02-06 12:09:12 | Valid | Epoch[445/600] Pixel Accuracy: 0.9845759073893229
2023-02-06 12:09:12 | Valid | Epoch[445/600] Mean Pixel Accuracy: 0.9205787251308712
2023-02-06 12:09:12 | Stage | Epoch[445/600] Train loss:0.0166
2023-02-06 12:09:12 | Stage | Epoch[445/600] Valid loss:0.0390
2023-02-06 12:09:12 | Stage | Epoch[445/600] LR:0.001

2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[001/030] Train loss: 0.0140
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[002/030] Train loss: 0.0154
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[007/030] Train loss: 0.0169
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:09:13 | Train | Epoch[446/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:09:14 | Train | Epoch[446/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:09:15 | Train | Epoch[446/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:09:15 | Train | Epoch[446/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:09:15 | Train | Epoch[446/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:09:15 | Valid | Epoch[446/600] Iteration[001/008] Valid loss: 0.0562
2023-02-06 12:09:15 | Valid | Epoch[446/600] Iteration[002/008] Valid loss: 0.0446
2023-02-06 12:09:15 | Valid | Epoch[446/600] Iteration[003/008] Valid loss: 0.0465
2023-02-06 12:09:15 | Valid | Epoch[446/600] Iteration[004/008] Valid loss: 0.0420
2023-02-06 12:09:15 | Valid | Epoch[446/600] Iteration[005/008] Valid loss: 0.0407
2023-02-06 12:09:15 | Valid | Epoch[446/600] Iteration[006/008] Valid loss: 0.0390
2023-02-06 12:09:15 | Valid | Epoch[446/600] Iteration[007/008] Valid loss: 0.0395
2023-02-06 12:09:15 | Valid | Epoch[446/600] Iteration[008/008] Valid loss: 0.0388
2023-02-06 12:09:15 | Valid | Epoch[446/600] MIou: 0.9078159854197244
2023-02-06 12:09:15 | Valid | Epoch[446/600] Pixel Accuracy: 0.9846585591634115
2023-02-06 12:09:15 | Valid | Epoch[446/600] Mean Pixel Accuracy: 0.9207002397290682
2023-02-06 12:09:15 | Stage | Epoch[446/600] Train loss:0.0166
2023-02-06 12:09:15 | Stage | Epoch[446/600] Valid loss:0.0388
2023-02-06 12:09:15 | Stage | Epoch[446/600] LR:0.001

2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[001/030] Train loss: 0.0166
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[010/030] Train loss: 0.0171
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:09:16 | Train | Epoch[447/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:09:17 | Train | Epoch[447/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:09:18 | Train | Epoch[447/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:09:18 | Train | Epoch[447/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:09:18 | Valid | Epoch[447/600] Iteration[001/008] Valid loss: 0.1146
2023-02-06 12:09:18 | Valid | Epoch[447/600] Iteration[002/008] Valid loss: 0.0799
2023-02-06 12:09:18 | Valid | Epoch[447/600] Iteration[003/008] Valid loss: 0.0784
2023-02-06 12:09:18 | Valid | Epoch[447/600] Iteration[004/008] Valid loss: 0.0712
2023-02-06 12:09:18 | Valid | Epoch[447/600] Iteration[005/008] Valid loss: 0.0677
2023-02-06 12:09:18 | Valid | Epoch[447/600] Iteration[006/008] Valid loss: 0.0631
2023-02-06 12:09:18 | Valid | Epoch[447/600] Iteration[007/008] Valid loss: 0.0675
2023-02-06 12:09:18 | Valid | Epoch[447/600] Iteration[008/008] Valid loss: 0.0648
2023-02-06 12:09:18 | Valid | Epoch[447/600] MIou: 0.9378447208503633
2023-02-06 12:09:18 | Valid | Epoch[447/600] Pixel Accuracy: 0.9893900553385416
2023-02-06 12:09:18 | Valid | Epoch[447/600] Mean Pixel Accuracy: 0.9601960755491434
2023-02-06 12:09:18 | Stage | Epoch[447/600] Train loss:0.0167
2023-02-06 12:09:18 | Stage | Epoch[447/600] Valid loss:0.0648
2023-02-06 12:09:18 | Stage | Epoch[447/600] LR:0.001

2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[001/030] Train loss: 0.0150
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[005/030] Train loss: 0.0172
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[006/030] Train loss: 0.0176
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[008/030] Train loss: 0.0176
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[009/030] Train loss: 0.0176
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[012/030] Train loss: 0.0170
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:09:19 | Train | Epoch[448/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[018/030] Train loss: 0.0169
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[020/030] Train loss: 0.0169
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[022/030] Train loss: 0.0170
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[023/030] Train loss: 0.0171
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[024/030] Train loss: 0.0170
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[026/030] Train loss: 0.0171
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[027/030] Train loss: 0.0170
2023-02-06 12:09:20 | Train | Epoch[448/600] Iteration[028/030] Train loss: 0.0169
2023-02-06 12:09:21 | Train | Epoch[448/600] Iteration[029/030] Train loss: 0.0169
2023-02-06 12:09:21 | Train | Epoch[448/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:09:21 | Valid | Epoch[448/600] Iteration[001/008] Valid loss: 0.0744
2023-02-06 12:09:21 | Valid | Epoch[448/600] Iteration[002/008] Valid loss: 0.0547
2023-02-06 12:09:21 | Valid | Epoch[448/600] Iteration[003/008] Valid loss: 0.0545
2023-02-06 12:09:21 | Valid | Epoch[448/600] Iteration[004/008] Valid loss: 0.0488
2023-02-06 12:09:21 | Valid | Epoch[448/600] Iteration[005/008] Valid loss: 0.0466
2023-02-06 12:09:21 | Valid | Epoch[448/600] Iteration[006/008] Valid loss: 0.0438
2023-02-06 12:09:21 | Valid | Epoch[448/600] Iteration[007/008] Valid loss: 0.0451
2023-02-06 12:09:21 | Valid | Epoch[448/600] Iteration[008/008] Valid loss: 0.0437
2023-02-06 12:09:21 | Valid | Epoch[448/600] MIou: 0.9249077256323237
2023-02-06 12:09:21 | Valid | Epoch[448/600] Pixel Accuracy: 0.9874000549316406
2023-02-06 12:09:21 | Valid | Epoch[448/600] Mean Pixel Accuracy: 0.9401886599335119
2023-02-06 12:09:21 | Stage | Epoch[448/600] Train loss:0.0169
2023-02-06 12:09:21 | Stage | Epoch[448/600] Valid loss:0.0437
2023-02-06 12:09:21 | Stage | Epoch[448/600] LR:0.001

2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[005/030] Train loss: 0.0175
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[006/030] Train loss: 0.0178
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[007/030] Train loss: 0.0174
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[008/030] Train loss: 0.0173
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:09:22 | Train | Epoch[449/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[017/030] Train loss: 0.0170
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[018/030] Train loss: 0.0171
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[019/030] Train loss: 0.0172
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[020/030] Train loss: 0.0171
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[021/030] Train loss: 0.0170
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:09:23 | Train | Epoch[449/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:09:24 | Train | Epoch[449/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:09:24 | Train | Epoch[449/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:09:24 | Valid | Epoch[449/600] Iteration[001/008] Valid loss: 0.0783
2023-02-06 12:09:24 | Valid | Epoch[449/600] Iteration[002/008] Valid loss: 0.0563
2023-02-06 12:09:24 | Valid | Epoch[449/600] Iteration[003/008] Valid loss: 0.0576
2023-02-06 12:09:24 | Valid | Epoch[449/600] Iteration[004/008] Valid loss: 0.0515
2023-02-06 12:09:24 | Valid | Epoch[449/600] Iteration[005/008] Valid loss: 0.0488
2023-02-06 12:09:24 | Valid | Epoch[449/600] Iteration[006/008] Valid loss: 0.0459
2023-02-06 12:09:24 | Valid | Epoch[449/600] Iteration[007/008] Valid loss: 0.0474
2023-02-06 12:09:24 | Valid | Epoch[449/600] Iteration[008/008] Valid loss: 0.0457
2023-02-06 12:09:24 | Valid | Epoch[449/600] MIou: 0.9261914053777411
2023-02-06 12:09:24 | Valid | Epoch[449/600] Pixel Accuracy: 0.9876009623209635
2023-02-06 12:09:24 | Valid | Epoch[449/600] Mean Pixel Accuracy: 0.941909566967245
2023-02-06 12:09:24 | Stage | Epoch[449/600] Train loss:0.0166
2023-02-06 12:09:24 | Stage | Epoch[449/600] Valid loss:0.0457
2023-02-06 12:09:24 | Stage | Epoch[449/600] LR:0.001

2023-02-06 12:09:24 | Train | Epoch[450/600] Iteration[001/030] Train loss: 0.0150
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[009/030] Train loss: 0.0173
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[010/030] Train loss: 0.0177
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[011/030] Train loss: 0.0176
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[012/030] Train loss: 0.0176
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[013/030] Train loss: 0.0177
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[014/030] Train loss: 0.0176
2023-02-06 12:09:25 | Train | Epoch[450/600] Iteration[015/030] Train loss: 0.0176
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[016/030] Train loss: 0.0175
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[017/030] Train loss: 0.0173
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[018/030] Train loss: 0.0172
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[019/030] Train loss: 0.0171
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[020/030] Train loss: 0.0171
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[021/030] Train loss: 0.0170
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:09:26 | Train | Epoch[450/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:09:27 | Valid | Epoch[450/600] Iteration[001/008] Valid loss: 0.0558
2023-02-06 12:09:27 | Valid | Epoch[450/600] Iteration[002/008] Valid loss: 0.0444
2023-02-06 12:09:27 | Valid | Epoch[450/600] Iteration[003/008] Valid loss: 0.0455
2023-02-06 12:09:27 | Valid | Epoch[450/600] Iteration[004/008] Valid loss: 0.0412
2023-02-06 12:09:27 | Valid | Epoch[450/600] Iteration[005/008] Valid loss: 0.0402
2023-02-06 12:09:27 | Valid | Epoch[450/600] Iteration[006/008] Valid loss: 0.0385
2023-02-06 12:09:27 | Valid | Epoch[450/600] Iteration[007/008] Valid loss: 0.0389
2023-02-06 12:09:27 | Valid | Epoch[450/600] Iteration[008/008] Valid loss: 0.0384
2023-02-06 12:09:27 | Valid | Epoch[450/600] MIou: 0.9048445530126372
2023-02-06 12:09:27 | Valid | Epoch[450/600] Pixel Accuracy: 0.9841664632161459
2023-02-06 12:09:27 | Valid | Epoch[450/600] Mean Pixel Accuracy: 0.9178745527896983
2023-02-06 12:09:27 | Stage | Epoch[450/600] Train loss:0.0169
2023-02-06 12:09:27 | Stage | Epoch[450/600] Valid loss:0.0384
2023-02-06 12:09:27 | Stage | Epoch[450/600] LR:0.001

2023-02-06 12:09:27 | Train | Epoch[451/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 12:09:27 | Train | Epoch[451/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:09:28 | Train | Epoch[451/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:09:29 | Train | Epoch[451/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:09:30 | Valid | Epoch[451/600] Iteration[001/008] Valid loss: 0.0910
2023-02-06 12:09:30 | Valid | Epoch[451/600] Iteration[002/008] Valid loss: 0.0631
2023-02-06 12:09:30 | Valid | Epoch[451/600] Iteration[003/008] Valid loss: 0.0635
2023-02-06 12:09:30 | Valid | Epoch[451/600] Iteration[004/008] Valid loss: 0.0568
2023-02-06 12:09:30 | Valid | Epoch[451/600] Iteration[005/008] Valid loss: 0.0539
2023-02-06 12:09:30 | Valid | Epoch[451/600] Iteration[006/008] Valid loss: 0.0504
2023-02-06 12:09:30 | Valid | Epoch[451/600] Iteration[007/008] Valid loss: 0.0524
2023-02-06 12:09:30 | Valid | Epoch[451/600] Iteration[008/008] Valid loss: 0.0505
2023-02-06 12:09:30 | Valid | Epoch[451/600] MIou: 0.9321896866504936
2023-02-06 12:09:30 | Valid | Epoch[451/600] Pixel Accuracy: 0.9885470072428385
2023-02-06 12:09:30 | Valid | Epoch[451/600] Mean Pixel Accuracy: 0.9499683742320104
2023-02-06 12:09:30 | Stage | Epoch[451/600] Train loss:0.0166
2023-02-06 12:09:30 | Stage | Epoch[451/600] Valid loss:0.0505
2023-02-06 12:09:30 | Stage | Epoch[451/600] LR:0.001

2023-02-06 12:09:30 | Train | Epoch[452/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 12:09:30 | Train | Epoch[452/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:09:30 | Train | Epoch[452/600] Iteration[003/030] Train loss: 0.0159
2023-02-06 12:09:30 | Train | Epoch[452/600] Iteration[004/030] Train loss: 0.0158
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[006/030] Train loss: 0.0158
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[007/030] Train loss: 0.0161
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:09:31 | Train | Epoch[452/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:09:32 | Train | Epoch[452/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:09:33 | Valid | Epoch[452/600] Iteration[001/008] Valid loss: 0.0765
2023-02-06 12:09:33 | Valid | Epoch[452/600] Iteration[002/008] Valid loss: 0.0550
2023-02-06 12:09:33 | Valid | Epoch[452/600] Iteration[003/008] Valid loss: 0.0566
2023-02-06 12:09:33 | Valid | Epoch[452/600] Iteration[004/008] Valid loss: 0.0504
2023-02-06 12:09:33 | Valid | Epoch[452/600] Iteration[005/008] Valid loss: 0.0479
2023-02-06 12:09:33 | Valid | Epoch[452/600] Iteration[006/008] Valid loss: 0.0450
2023-02-06 12:09:33 | Valid | Epoch[452/600] Iteration[007/008] Valid loss: 0.0463
2023-02-06 12:09:33 | Valid | Epoch[452/600] Iteration[008/008] Valid loss: 0.0448
2023-02-06 12:09:33 | Valid | Epoch[452/600] MIou: 0.9259815573674657
2023-02-06 12:09:33 | Valid | Epoch[452/600] Pixel Accuracy: 0.9875653584798177
2023-02-06 12:09:33 | Valid | Epoch[452/600] Mean Pixel Accuracy: 0.94172514531837
2023-02-06 12:09:33 | Stage | Epoch[452/600] Train loss:0.0166
2023-02-06 12:09:33 | Stage | Epoch[452/600] Valid loss:0.0448
2023-02-06 12:09:33 | Stage | Epoch[452/600] LR:0.001

2023-02-06 12:09:33 | Train | Epoch[453/600] Iteration[001/030] Train loss: 0.0181
2023-02-06 12:09:33 | Train | Epoch[453/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:09:33 | Train | Epoch[453/600] Iteration[003/030] Train loss: 0.0157
2023-02-06 12:09:33 | Train | Epoch[453/600] Iteration[004/030] Train loss: 0.0157
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[005/030] Train loss: 0.0154
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[006/030] Train loss: 0.0153
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[007/030] Train loss: 0.0157
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[008/030] Train loss: 0.0154
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[009/030] Train loss: 0.0157
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[013/030] Train loss: 0.0160
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[016/030] Train loss: 0.0160
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:09:34 | Train | Epoch[453/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:09:35 | Train | Epoch[453/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:09:36 | Valid | Epoch[453/600] Iteration[001/008] Valid loss: 0.0678
2023-02-06 12:09:36 | Valid | Epoch[453/600] Iteration[002/008] Valid loss: 0.0508
2023-02-06 12:09:36 | Valid | Epoch[453/600] Iteration[003/008] Valid loss: 0.0515
2023-02-06 12:09:36 | Valid | Epoch[453/600] Iteration[004/008] Valid loss: 0.0460
2023-02-06 12:09:36 | Valid | Epoch[453/600] Iteration[005/008] Valid loss: 0.0439
2023-02-06 12:09:36 | Valid | Epoch[453/600] Iteration[006/008] Valid loss: 0.0415
2023-02-06 12:09:36 | Valid | Epoch[453/600] Iteration[007/008] Valid loss: 0.0424
2023-02-06 12:09:36 | Valid | Epoch[453/600] Iteration[008/008] Valid loss: 0.0412
2023-02-06 12:09:36 | Valid | Epoch[453/600] MIou: 0.9188775926647884
2023-02-06 12:09:36 | Valid | Epoch[453/600] Pixel Accuracy: 0.9864463806152344
2023-02-06 12:09:36 | Valid | Epoch[453/600] Mean Pixel Accuracy: 0.9326772802496772
2023-02-06 12:09:36 | Stage | Epoch[453/600] Train loss:0.0164
2023-02-06 12:09:36 | Stage | Epoch[453/600] Valid loss:0.0412
2023-02-06 12:09:36 | Stage | Epoch[453/600] LR:0.001

2023-02-06 12:09:36 | Train | Epoch[454/600] Iteration[001/030] Train loss: 0.0205
2023-02-06 12:09:36 | Train | Epoch[454/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:09:36 | Train | Epoch[454/600] Iteration[003/030] Train loss: 0.0159
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:09:37 | Train | Epoch[454/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:09:38 | Train | Epoch[454/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:09:39 | Valid | Epoch[454/600] Iteration[001/008] Valid loss: 0.0666
2023-02-06 12:09:39 | Valid | Epoch[454/600] Iteration[002/008] Valid loss: 0.0503
2023-02-06 12:09:39 | Valid | Epoch[454/600] Iteration[003/008] Valid loss: 0.0516
2023-02-06 12:09:39 | Valid | Epoch[454/600] Iteration[004/008] Valid loss: 0.0464
2023-02-06 12:09:39 | Valid | Epoch[454/600] Iteration[005/008] Valid loss: 0.0443
2023-02-06 12:09:39 | Valid | Epoch[454/600] Iteration[006/008] Valid loss: 0.0419
2023-02-06 12:09:39 | Valid | Epoch[454/600] Iteration[007/008] Valid loss: 0.0427
2023-02-06 12:09:39 | Valid | Epoch[454/600] Iteration[008/008] Valid loss: 0.0414
2023-02-06 12:09:39 | Valid | Epoch[454/600] MIou: 0.9177124966049108
2023-02-06 12:09:39 | Valid | Epoch[454/600] Pixel Accuracy: 0.9862543741861979
2023-02-06 12:09:39 | Valid | Epoch[454/600] Mean Pixel Accuracy: 0.9315065461133732
2023-02-06 12:09:39 | Stage | Epoch[454/600] Train loss:0.0164
2023-02-06 12:09:39 | Stage | Epoch[454/600] Valid loss:0.0414
2023-02-06 12:09:39 | Stage | Epoch[454/600] LR:0.001

2023-02-06 12:09:39 | Train | Epoch[455/600] Iteration[001/030] Train loss: 0.0169
2023-02-06 12:09:39 | Train | Epoch[455/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 12:09:39 | Train | Epoch[455/600] Iteration[003/030] Train loss: 0.0168
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[004/030] Train loss: 0.0161
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[005/030] Train loss: 0.0162
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[007/030] Train loss: 0.0157
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[008/030] Train loss: 0.0160
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[009/030] Train loss: 0.0159
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[010/030] Train loss: 0.0159
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:09:40 | Train | Epoch[455/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:09:41 | Train | Epoch[455/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:09:42 | Valid | Epoch[455/600] Iteration[001/008] Valid loss: 0.0819
2023-02-06 12:09:42 | Valid | Epoch[455/600] Iteration[002/008] Valid loss: 0.0588
2023-02-06 12:09:42 | Valid | Epoch[455/600] Iteration[003/008] Valid loss: 0.0610
2023-02-06 12:09:42 | Valid | Epoch[455/600] Iteration[004/008] Valid loss: 0.0544
2023-02-06 12:09:42 | Valid | Epoch[455/600] Iteration[005/008] Valid loss: 0.0517
2023-02-06 12:09:42 | Valid | Epoch[455/600] Iteration[006/008] Valid loss: 0.0484
2023-02-06 12:09:42 | Valid | Epoch[455/600] Iteration[007/008] Valid loss: 0.0501
2023-02-06 12:09:42 | Valid | Epoch[455/600] Iteration[008/008] Valid loss: 0.0482
2023-02-06 12:09:42 | Valid | Epoch[455/600] MIou: 0.929364137908872
2023-02-06 12:09:42 | Valid | Epoch[455/600] Pixel Accuracy: 0.9881057739257812
2023-02-06 12:09:42 | Valid | Epoch[455/600] Mean Pixel Accuracy: 0.9459469325616103
2023-02-06 12:09:42 | Stage | Epoch[455/600] Train loss:0.0168
2023-02-06 12:09:42 | Stage | Epoch[455/600] Valid loss:0.0482
2023-02-06 12:09:42 | Stage | Epoch[455/600] LR:0.001

2023-02-06 12:09:42 | Train | Epoch[456/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:09:42 | Train | Epoch[456/600] Iteration[002/030] Train loss: 0.0161
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[003/030] Train loss: 0.0157
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:09:43 | Train | Epoch[456/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:09:44 | Train | Epoch[456/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:09:45 | Valid | Epoch[456/600] Iteration[001/008] Valid loss: 0.0907
2023-02-06 12:09:45 | Valid | Epoch[456/600] Iteration[002/008] Valid loss: 0.0650
2023-02-06 12:09:45 | Valid | Epoch[456/600] Iteration[003/008] Valid loss: 0.0641
2023-02-06 12:09:45 | Valid | Epoch[456/600] Iteration[004/008] Valid loss: 0.0579
2023-02-06 12:09:45 | Valid | Epoch[456/600] Iteration[005/008] Valid loss: 0.0551
2023-02-06 12:09:45 | Valid | Epoch[456/600] Iteration[006/008] Valid loss: 0.0520
2023-02-06 12:09:45 | Valid | Epoch[456/600] Iteration[007/008] Valid loss: 0.0542
2023-02-06 12:09:45 | Valid | Epoch[456/600] Iteration[008/008] Valid loss: 0.0522
2023-02-06 12:09:45 | Valid | Epoch[456/600] MIou: 0.93280470146315
2023-02-06 12:09:45 | Valid | Epoch[456/600] Pixel Accuracy: 0.9886283874511719
2023-02-06 12:09:45 | Valid | Epoch[456/600] Mean Pixel Accuracy: 0.9514460508270224
2023-02-06 12:09:45 | Stage | Epoch[456/600] Train loss:0.0165
2023-02-06 12:09:45 | Stage | Epoch[456/600] Valid loss:0.0522
2023-02-06 12:09:45 | Stage | Epoch[456/600] LR:0.001

2023-02-06 12:09:45 | Train | Epoch[457/600] Iteration[001/030] Train loss: 0.0172
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[002/030] Train loss: 0.0159
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[003/030] Train loss: 0.0172
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[007/030] Train loss: 0.0159
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[008/030] Train loss: 0.0159
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[009/030] Train loss: 0.0159
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[010/030] Train loss: 0.0159
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:09:46 | Train | Epoch[457/600] Iteration[015/030] Train loss: 0.0160
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[017/030] Train loss: 0.0161
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:09:47 | Train | Epoch[457/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:09:48 | Valid | Epoch[457/600] Iteration[001/008] Valid loss: 0.0906
2023-02-06 12:09:48 | Valid | Epoch[457/600] Iteration[002/008] Valid loss: 0.0639
2023-02-06 12:09:48 | Valid | Epoch[457/600] Iteration[003/008] Valid loss: 0.0661
2023-02-06 12:09:48 | Valid | Epoch[457/600] Iteration[004/008] Valid loss: 0.0594
2023-02-06 12:09:48 | Valid | Epoch[457/600] Iteration[005/008] Valid loss: 0.0567
2023-02-06 12:09:48 | Valid | Epoch[457/600] Iteration[006/008] Valid loss: 0.0531
2023-02-06 12:09:48 | Valid | Epoch[457/600] Iteration[007/008] Valid loss: 0.0553
2023-02-06 12:09:48 | Valid | Epoch[457/600] Iteration[008/008] Valid loss: 0.0530
2023-02-06 12:09:48 | Valid | Epoch[457/600] MIou: 0.9334886826568201
2023-02-06 12:09:48 | Valid | Epoch[457/600] Pixel Accuracy: 0.9887517293294271
2023-02-06 12:09:48 | Valid | Epoch[457/600] Mean Pixel Accuracy: 0.9517864850587348
2023-02-06 12:09:48 | Stage | Epoch[457/600] Train loss:0.0165
2023-02-06 12:09:48 | Stage | Epoch[457/600] Valid loss:0.0530
2023-02-06 12:09:48 | Stage | Epoch[457/600] LR:0.001

2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[001/030] Train loss: 0.0150
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[002/030] Train loss: 0.0179
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[005/030] Train loss: 0.0175
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[009/030] Train loss: 0.0166
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:09:49 | Train | Epoch[458/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[019/030] Train loss: 0.0171
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[020/030] Train loss: 0.0170
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[021/030] Train loss: 0.0171
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[022/030] Train loss: 0.0171
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[023/030] Train loss: 0.0170
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[026/030] Train loss: 0.0169
2023-02-06 12:09:50 | Train | Epoch[458/600] Iteration[027/030] Train loss: 0.0169
2023-02-06 12:09:51 | Train | Epoch[458/600] Iteration[028/030] Train loss: 0.0169
2023-02-06 12:09:51 | Train | Epoch[458/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:09:51 | Train | Epoch[458/600] Iteration[030/030] Train loss: 0.0170
2023-02-06 12:09:51 | Valid | Epoch[458/600] Iteration[001/008] Valid loss: 0.0786
2023-02-06 12:09:51 | Valid | Epoch[458/600] Iteration[002/008] Valid loss: 0.0569
2023-02-06 12:09:51 | Valid | Epoch[458/600] Iteration[003/008] Valid loss: 0.0593
2023-02-06 12:09:51 | Valid | Epoch[458/600] Iteration[004/008] Valid loss: 0.0532
2023-02-06 12:09:51 | Valid | Epoch[458/600] Iteration[005/008] Valid loss: 0.0508
2023-02-06 12:09:51 | Valid | Epoch[458/600] Iteration[006/008] Valid loss: 0.0478
2023-02-06 12:09:51 | Valid | Epoch[458/600] Iteration[007/008] Valid loss: 0.0492
2023-02-06 12:09:51 | Valid | Epoch[458/600] Iteration[008/008] Valid loss: 0.0473
2023-02-06 12:09:51 | Valid | Epoch[458/600] MIou: 0.9279288029997834
2023-02-06 12:09:51 | Valid | Epoch[458/600] Pixel Accuracy: 0.9878705342610677
2023-02-06 12:09:51 | Valid | Epoch[458/600] Mean Pixel Accuracy: 0.9443593263613763
2023-02-06 12:09:51 | Stage | Epoch[458/600] Train loss:0.0170
2023-02-06 12:09:51 | Stage | Epoch[458/600] Valid loss:0.0473
2023-02-06 12:09:51 | Stage | Epoch[458/600] LR:0.001

2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[001/030] Train loss: 0.0155
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[004/030] Train loss: 0.0171
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:09:52 | Train | Epoch[459/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:09:53 | Train | Epoch[459/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:09:54 | Train | Epoch[459/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:09:54 | Train | Epoch[459/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:09:54 | Train | Epoch[459/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:09:54 | Valid | Epoch[459/600] Iteration[001/008] Valid loss: 0.0901
2023-02-06 12:09:54 | Valid | Epoch[459/600] Iteration[002/008] Valid loss: 0.0632
2023-02-06 12:09:54 | Valid | Epoch[459/600] Iteration[003/008] Valid loss: 0.0645
2023-02-06 12:09:54 | Valid | Epoch[459/600] Iteration[004/008] Valid loss: 0.0578
2023-02-06 12:09:54 | Valid | Epoch[459/600] Iteration[005/008] Valid loss: 0.0550
2023-02-06 12:09:54 | Valid | Epoch[459/600] Iteration[006/008] Valid loss: 0.0514
2023-02-06 12:09:54 | Valid | Epoch[459/600] Iteration[007/008] Valid loss: 0.0533
2023-02-06 12:09:54 | Valid | Epoch[459/600] Iteration[008/008] Valid loss: 0.0512
2023-02-06 12:09:54 | Valid | Epoch[459/600] MIou: 0.93272155727367
2023-02-06 12:09:54 | Valid | Epoch[459/600] Pixel Accuracy: 0.9886309305826823
2023-02-06 12:09:54 | Valid | Epoch[459/600] Mean Pixel Accuracy: 0.9507056134736491
2023-02-06 12:09:54 | Stage | Epoch[459/600] Train loss:0.0166
2023-02-06 12:09:54 | Stage | Epoch[459/600] Valid loss:0.0512
2023-02-06 12:09:54 | Stage | Epoch[459/600] LR:0.001

2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[003/030] Train loss: 0.0176
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[010/030] Train loss: 0.0171
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[011/030] Train loss: 0.0174
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 12:09:55 | Train | Epoch[460/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[014/030] Train loss: 0.0170
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[018/030] Train loss: 0.0169
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:09:56 | Train | Epoch[460/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:09:57 | Train | Epoch[460/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:09:57 | Train | Epoch[460/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:09:57 | Train | Epoch[460/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:09:57 | Valid | Epoch[460/600] Iteration[001/008] Valid loss: 0.0592
2023-02-06 12:09:57 | Valid | Epoch[460/600] Iteration[002/008] Valid loss: 0.0458
2023-02-06 12:09:57 | Valid | Epoch[460/600] Iteration[003/008] Valid loss: 0.0478
2023-02-06 12:09:57 | Valid | Epoch[460/600] Iteration[004/008] Valid loss: 0.0431
2023-02-06 12:09:57 | Valid | Epoch[460/600] Iteration[005/008] Valid loss: 0.0416
2023-02-06 12:09:57 | Valid | Epoch[460/600] Iteration[006/008] Valid loss: 0.0397
2023-02-06 12:09:57 | Valid | Epoch[460/600] Iteration[007/008] Valid loss: 0.0405
2023-02-06 12:09:57 | Valid | Epoch[460/600] Iteration[008/008] Valid loss: 0.0396
2023-02-06 12:09:57 | Valid | Epoch[460/600] MIou: 0.9104530556516959
2023-02-06 12:09:57 | Valid | Epoch[460/600] Pixel Accuracy: 0.9850756327311198
2023-02-06 12:09:57 | Valid | Epoch[460/600] Mean Pixel Accuracy: 0.9237700123870499
2023-02-06 12:09:57 | Stage | Epoch[460/600] Train loss:0.0166
2023-02-06 12:09:57 | Stage | Epoch[460/600] Valid loss:0.0396
2023-02-06 12:09:57 | Stage | Epoch[460/600] LR:0.001

2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[002/030] Train loss: 0.0164
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[005/030] Train loss: 0.0166
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[009/030] Train loss: 0.0166
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:09:58 | Train | Epoch[461/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:09:59 | Train | Epoch[461/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:10:00 | Train | Epoch[461/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:10:00 | Train | Epoch[461/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:10:00 | Train | Epoch[461/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:10:00 | Train | Epoch[461/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:10:00 | Valid | Epoch[461/600] Iteration[001/008] Valid loss: 0.0724
2023-02-06 12:10:00 | Valid | Epoch[461/600] Iteration[002/008] Valid loss: 0.0534
2023-02-06 12:10:00 | Valid | Epoch[461/600] Iteration[003/008] Valid loss: 0.0538
2023-02-06 12:10:00 | Valid | Epoch[461/600] Iteration[004/008] Valid loss: 0.0481
2023-02-06 12:10:00 | Valid | Epoch[461/600] Iteration[005/008] Valid loss: 0.0459
2023-02-06 12:10:00 | Valid | Epoch[461/600] Iteration[006/008] Valid loss: 0.0432
2023-02-06 12:10:00 | Valid | Epoch[461/600] Iteration[007/008] Valid loss: 0.0444
2023-02-06 12:10:00 | Valid | Epoch[461/600] Iteration[008/008] Valid loss: 0.0430
2023-02-06 12:10:00 | Valid | Epoch[461/600] MIou: 0.9227948044104786
2023-02-06 12:10:00 | Valid | Epoch[461/600] Pixel Accuracy: 0.9870643615722656
2023-02-06 12:10:00 | Valid | Epoch[461/600] Mean Pixel Accuracy: 0.9375694074855853
2023-02-06 12:10:00 | Stage | Epoch[461/600] Train loss:0.0165
2023-02-06 12:10:00 | Stage | Epoch[461/600] Valid loss:0.0430
2023-02-06 12:10:00 | Stage | Epoch[461/600] LR:0.001

2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[003/030] Train loss: 0.0176
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[008/030] Train loss: 0.0180
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[009/030] Train loss: 0.0179
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[010/030] Train loss: 0.0178
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[011/030] Train loss: 0.0175
2023-02-06 12:10:01 | Train | Epoch[462/600] Iteration[012/030] Train loss: 0.0173
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[020/030] Train loss: 0.0169
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[023/030] Train loss: 0.0170
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:10:02 | Train | Epoch[462/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:10:03 | Train | Epoch[462/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:10:03 | Train | Epoch[462/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:10:03 | Train | Epoch[462/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:10:03 | Train | Epoch[462/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:10:03 | Train | Epoch[462/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:10:03 | Valid | Epoch[462/600] Iteration[001/008] Valid loss: 0.0739
2023-02-06 12:10:03 | Valid | Epoch[462/600] Iteration[002/008] Valid loss: 0.0539
2023-02-06 12:10:03 | Valid | Epoch[462/600] Iteration[003/008] Valid loss: 0.0564
2023-02-06 12:10:03 | Valid | Epoch[462/600] Iteration[004/008] Valid loss: 0.0502
2023-02-06 12:10:03 | Valid | Epoch[462/600] Iteration[005/008] Valid loss: 0.0477
2023-02-06 12:10:03 | Valid | Epoch[462/600] Iteration[006/008] Valid loss: 0.0448
2023-02-06 12:10:03 | Valid | Epoch[462/600] Iteration[007/008] Valid loss: 0.0460
2023-02-06 12:10:03 | Valid | Epoch[462/600] Iteration[008/008] Valid loss: 0.0444
2023-02-06 12:10:03 | Valid | Epoch[462/600] MIou: 0.9246074070754717
2023-02-06 12:10:03 | Valid | Epoch[462/600] Pixel Accuracy: 0.9873568216959635
2023-02-06 12:10:03 | Valid | Epoch[462/600] Mean Pixel Accuracy: 0.9396576593823645
2023-02-06 12:10:03 | Stage | Epoch[462/600] Train loss:0.0168
2023-02-06 12:10:03 | Stage | Epoch[462/600] Valid loss:0.0444
2023-02-06 12:10:03 | Stage | Epoch[462/600] LR:0.001

2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[002/030] Train loss: 0.0171
2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[003/030] Train loss: 0.0159
2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[005/030] Train loss: 0.0158
2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[006/030] Train loss: 0.0157
2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[007/030] Train loss: 0.0160
2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[008/030] Train loss: 0.0159
2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[010/030] Train loss: 0.0159
2023-02-06 12:10:04 | Train | Epoch[463/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[013/030] Train loss: 0.0160
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[014/030] Train loss: 0.0159
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[015/030] Train loss: 0.0157
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[016/030] Train loss: 0.0156
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[017/030] Train loss: 0.0157
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[018/030] Train loss: 0.0159
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:10:05 | Train | Epoch[463/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:10:06 | Train | Epoch[463/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:10:06 | Train | Epoch[463/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:10:06 | Train | Epoch[463/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:10:06 | Train | Epoch[463/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:10:06 | Train | Epoch[463/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:10:06 | Valid | Epoch[463/600] Iteration[001/008] Valid loss: 0.1264
2023-02-06 12:10:06 | Valid | Epoch[463/600] Iteration[002/008] Valid loss: 0.0884
2023-02-06 12:10:06 | Valid | Epoch[463/600] Iteration[003/008] Valid loss: 0.0865
2023-02-06 12:10:06 | Valid | Epoch[463/600] Iteration[004/008] Valid loss: 0.0799
2023-02-06 12:10:06 | Valid | Epoch[463/600] Iteration[005/008] Valid loss: 0.0774
2023-02-06 12:10:06 | Valid | Epoch[463/600] Iteration[006/008] Valid loss: 0.0727
2023-02-06 12:10:06 | Valid | Epoch[463/600] Iteration[007/008] Valid loss: 0.0786
2023-02-06 12:10:06 | Valid | Epoch[463/600] Iteration[008/008] Valid loss: 0.0758
2023-02-06 12:10:07 | Valid | Epoch[463/600] MIou: 0.9400948101350911
2023-02-06 12:10:07 | Valid | Epoch[463/600] Pixel Accuracy: 0.9896990458170573
2023-02-06 12:10:07 | Valid | Epoch[463/600] Mean Pixel Accuracy: 0.9657679916225528
2023-02-06 12:10:07 | Stage | Epoch[463/600] Train loss:0.0168
2023-02-06 12:10:07 | Stage | Epoch[463/600] Valid loss:0.0758
2023-02-06 12:10:07 | Stage | Epoch[463/600] LR:0.001

2023-02-06 12:10:07 | Train | Epoch[464/600] Iteration[001/030] Train loss: 0.0175
2023-02-06 12:10:07 | Train | Epoch[464/600] Iteration[002/030] Train loss: 0.0160
2023-02-06 12:10:07 | Train | Epoch[464/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 12:10:07 | Train | Epoch[464/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:10:07 | Train | Epoch[464/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:10:07 | Train | Epoch[464/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:10:07 | Train | Epoch[464/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:10:07 | Train | Epoch[464/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 12:10:07 | Train | Epoch[464/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:10:07 | Train | Epoch[464/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:10:08 | Train | Epoch[464/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:10:09 | Train | Epoch[464/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:10:09 | Train | Epoch[464/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:10:09 | Train | Epoch[464/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:10:09 | Train | Epoch[464/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:10:09 | Train | Epoch[464/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:10:09 | Train | Epoch[464/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:10:09 | Valid | Epoch[464/600] Iteration[001/008] Valid loss: 0.0583
2023-02-06 12:10:09 | Valid | Epoch[464/600] Iteration[002/008] Valid loss: 0.0453
2023-02-06 12:10:09 | Valid | Epoch[464/600] Iteration[003/008] Valid loss: 0.0473
2023-02-06 12:10:09 | Valid | Epoch[464/600] Iteration[004/008] Valid loss: 0.0428
2023-02-06 12:10:09 | Valid | Epoch[464/600] Iteration[005/008] Valid loss: 0.0415
2023-02-06 12:10:09 | Valid | Epoch[464/600] Iteration[006/008] Valid loss: 0.0396
2023-02-06 12:10:09 | Valid | Epoch[464/600] Iteration[007/008] Valid loss: 0.0401
2023-02-06 12:10:09 | Valid | Epoch[464/600] Iteration[008/008] Valid loss: 0.0393
2023-02-06 12:10:10 | Valid | Epoch[464/600] MIou: 0.9081720757824301
2023-02-06 12:10:10 | Valid | Epoch[464/600] Pixel Accuracy: 0.9847119649251302
2023-02-06 12:10:10 | Valid | Epoch[464/600] Mean Pixel Accuracy: 0.9211924482337913
2023-02-06 12:10:10 | Stage | Epoch[464/600] Train loss:0.0164
2023-02-06 12:10:10 | Stage | Epoch[464/600] Valid loss:0.0393
2023-02-06 12:10:10 | Stage | Epoch[464/600] LR:0.001

2023-02-06 12:10:10 | Train | Epoch[465/600] Iteration[001/030] Train loss: 0.0173
2023-02-06 12:10:10 | Train | Epoch[465/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:10:10 | Train | Epoch[465/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:10:10 | Train | Epoch[465/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:10:10 | Train | Epoch[465/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:10:10 | Train | Epoch[465/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:10:10 | Train | Epoch[465/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:10:10 | Train | Epoch[465/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:10:10 | Train | Epoch[465/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:10:11 | Train | Epoch[465/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 12:10:12 | Train | Epoch[465/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:10:12 | Train | Epoch[465/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:10:12 | Train | Epoch[465/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:10:12 | Train | Epoch[465/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:10:12 | Train | Epoch[465/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:10:12 | Train | Epoch[465/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:10:12 | Train | Epoch[465/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:10:12 | Train | Epoch[465/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:10:12 | Valid | Epoch[465/600] Iteration[001/008] Valid loss: 0.0936
2023-02-06 12:10:12 | Valid | Epoch[465/600] Iteration[002/008] Valid loss: 0.0655
2023-02-06 12:10:12 | Valid | Epoch[465/600] Iteration[003/008] Valid loss: 0.0660
2023-02-06 12:10:12 | Valid | Epoch[465/600] Iteration[004/008] Valid loss: 0.0596
2023-02-06 12:10:12 | Valid | Epoch[465/600] Iteration[005/008] Valid loss: 0.0564
2023-02-06 12:10:12 | Valid | Epoch[465/600] Iteration[006/008] Valid loss: 0.0526
2023-02-06 12:10:13 | Valid | Epoch[465/600] Iteration[007/008] Valid loss: 0.0547
2023-02-06 12:10:13 | Valid | Epoch[465/600] Iteration[008/008] Valid loss: 0.0525
2023-02-06 12:10:13 | Valid | Epoch[465/600] MIou: 0.9334591313308545
2023-02-06 12:10:13 | Valid | Epoch[465/600] Pixel Accuracy: 0.9887504577636719
2023-02-06 12:10:13 | Valid | Epoch[465/600] Mean Pixel Accuracy: 0.9516082529496266
2023-02-06 12:10:13 | Stage | Epoch[465/600] Train loss:0.0167
2023-02-06 12:10:13 | Stage | Epoch[465/600] Valid loss:0.0525
2023-02-06 12:10:13 | Stage | Epoch[465/600] LR:0.001

2023-02-06 12:10:13 | Train | Epoch[466/600] Iteration[001/030] Train loss: 0.0152
2023-02-06 12:10:13 | Train | Epoch[466/600] Iteration[002/030] Train loss: 0.0168
2023-02-06 12:10:13 | Train | Epoch[466/600] Iteration[003/030] Train loss: 0.0173
2023-02-06 12:10:13 | Train | Epoch[466/600] Iteration[004/030] Train loss: 0.0172
2023-02-06 12:10:13 | Train | Epoch[466/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:10:13 | Train | Epoch[466/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:10:13 | Train | Epoch[466/600] Iteration[007/030] Train loss: 0.0161
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:10:14 | Train | Epoch[466/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 12:10:15 | Train | Epoch[466/600] Iteration[022/030] Train loss: 0.0161
2023-02-06 12:10:15 | Train | Epoch[466/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:10:15 | Train | Epoch[466/600] Iteration[024/030] Train loss: 0.0161
2023-02-06 12:10:15 | Train | Epoch[466/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:10:15 | Train | Epoch[466/600] Iteration[026/030] Train loss: 0.0161
2023-02-06 12:10:15 | Train | Epoch[466/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:10:15 | Train | Epoch[466/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:10:15 | Train | Epoch[466/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:10:15 | Train | Epoch[466/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:10:15 | Valid | Epoch[466/600] Iteration[001/008] Valid loss: 0.0628
2023-02-06 12:10:16 | Valid | Epoch[466/600] Iteration[002/008] Valid loss: 0.0477
2023-02-06 12:10:16 | Valid | Epoch[466/600] Iteration[003/008] Valid loss: 0.0481
2023-02-06 12:10:16 | Valid | Epoch[466/600] Iteration[004/008] Valid loss: 0.0434
2023-02-06 12:10:16 | Valid | Epoch[466/600] Iteration[005/008] Valid loss: 0.0419
2023-02-06 12:10:16 | Valid | Epoch[466/600] Iteration[006/008] Valid loss: 0.0398
2023-02-06 12:10:16 | Valid | Epoch[466/600] Iteration[007/008] Valid loss: 0.0408
2023-02-06 12:10:16 | Valid | Epoch[466/600] Iteration[008/008] Valid loss: 0.0398
2023-02-06 12:10:16 | Valid | Epoch[466/600] MIou: 0.915828283294924
2023-02-06 12:10:16 | Valid | Epoch[466/600] Pixel Accuracy: 0.9859491984049479
2023-02-06 12:10:16 | Valid | Epoch[466/600] Mean Pixel Accuracy: 0.9294556884494782
2023-02-06 12:10:16 | Stage | Epoch[466/600] Train loss:0.0165
2023-02-06 12:10:16 | Stage | Epoch[466/600] Valid loss:0.0398
2023-02-06 12:10:16 | Stage | Epoch[466/600] LR:0.001

2023-02-06 12:10:16 | Train | Epoch[467/600] Iteration[001/030] Train loss: 0.0161
2023-02-06 12:10:16 | Train | Epoch[467/600] Iteration[002/030] Train loss: 0.0155
2023-02-06 12:10:16 | Train | Epoch[467/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 12:10:16 | Train | Epoch[467/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:10:16 | Train | Epoch[467/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:10:16 | Train | Epoch[467/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:10:17 | Train | Epoch[467/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:10:18 | Train | Epoch[467/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:10:18 | Train | Epoch[467/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:10:18 | Train | Epoch[467/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:10:18 | Train | Epoch[467/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:10:18 | Train | Epoch[467/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:10:18 | Train | Epoch[467/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:10:18 | Train | Epoch[467/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:10:18 | Train | Epoch[467/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:10:18 | Train | Epoch[467/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:10:18 | Train | Epoch[467/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:10:19 | Valid | Epoch[467/600] Iteration[001/008] Valid loss: 0.0719
2023-02-06 12:10:19 | Valid | Epoch[467/600] Iteration[002/008] Valid loss: 0.0526
2023-02-06 12:10:19 | Valid | Epoch[467/600] Iteration[003/008] Valid loss: 0.0529
2023-02-06 12:10:19 | Valid | Epoch[467/600] Iteration[004/008] Valid loss: 0.0474
2023-02-06 12:10:19 | Valid | Epoch[467/600] Iteration[005/008] Valid loss: 0.0452
2023-02-06 12:10:19 | Valid | Epoch[467/600] Iteration[006/008] Valid loss: 0.0427
2023-02-06 12:10:19 | Valid | Epoch[467/600] Iteration[007/008] Valid loss: 0.0441
2023-02-06 12:10:19 | Valid | Epoch[467/600] Iteration[008/008] Valid loss: 0.0427
2023-02-06 12:10:19 | Valid | Epoch[467/600] MIou: 0.9226639874190196
2023-02-06 12:10:19 | Valid | Epoch[467/600] Pixel Accuracy: 0.9870313008626302
2023-02-06 12:10:19 | Valid | Epoch[467/600] Mean Pixel Accuracy: 0.9378238761845838
2023-02-06 12:10:19 | Stage | Epoch[467/600] Train loss:0.0168
2023-02-06 12:10:19 | Stage | Epoch[467/600] Valid loss:0.0427
2023-02-06 12:10:19 | Stage | Epoch[467/600] LR:0.001

2023-02-06 12:10:19 | Train | Epoch[468/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 12:10:19 | Train | Epoch[468/600] Iteration[002/030] Train loss: 0.0168
2023-02-06 12:10:19 | Train | Epoch[468/600] Iteration[003/030] Train loss: 0.0175
2023-02-06 12:10:19 | Train | Epoch[468/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:10:19 | Train | Epoch[468/600] Iteration[005/030] Train loss: 0.0175
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[006/030] Train loss: 0.0176
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[018/030] Train loss: 0.0169
2023-02-06 12:10:20 | Train | Epoch[468/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:10:21 | Train | Epoch[468/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:10:22 | Valid | Epoch[468/600] Iteration[001/008] Valid loss: 0.0750
2023-02-06 12:10:22 | Valid | Epoch[468/600] Iteration[002/008] Valid loss: 0.0549
2023-02-06 12:10:22 | Valid | Epoch[468/600] Iteration[003/008] Valid loss: 0.0549
2023-02-06 12:10:22 | Valid | Epoch[468/600] Iteration[004/008] Valid loss: 0.0493
2023-02-06 12:10:22 | Valid | Epoch[468/600] Iteration[005/008] Valid loss: 0.0471
2023-02-06 12:10:22 | Valid | Epoch[468/600] Iteration[006/008] Valid loss: 0.0443
2023-02-06 12:10:22 | Valid | Epoch[468/600] Iteration[007/008] Valid loss: 0.0457
2023-02-06 12:10:22 | Valid | Epoch[468/600] Iteration[008/008] Valid loss: 0.0442
2023-02-06 12:10:22 | Valid | Epoch[468/600] MIou: 0.925729030809186
2023-02-06 12:10:22 | Valid | Epoch[468/600] Pixel Accuracy: 0.9875272115071615
2023-02-06 12:10:22 | Valid | Epoch[468/600] Mean Pixel Accuracy: 0.9413364307675685
2023-02-06 12:10:22 | Stage | Epoch[468/600] Train loss:0.0167
2023-02-06 12:10:22 | Stage | Epoch[468/600] Valid loss:0.0442
2023-02-06 12:10:22 | Stage | Epoch[468/600] LR:0.001

2023-02-06 12:10:22 | Train | Epoch[469/600] Iteration[001/030] Train loss: 0.0162
2023-02-06 12:10:22 | Train | Epoch[469/600] Iteration[002/030] Train loss: 0.0169
2023-02-06 12:10:22 | Train | Epoch[469/600] Iteration[003/030] Train loss: 0.0163
2023-02-06 12:10:22 | Train | Epoch[469/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[009/030] Train loss: 0.0166
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:10:23 | Train | Epoch[469/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:10:24 | Train | Epoch[469/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:10:25 | Valid | Epoch[469/600] Iteration[001/008] Valid loss: 0.1171
2023-02-06 12:10:25 | Valid | Epoch[469/600] Iteration[002/008] Valid loss: 0.0822
2023-02-06 12:10:25 | Valid | Epoch[469/600] Iteration[003/008] Valid loss: 0.0815
2023-02-06 12:10:25 | Valid | Epoch[469/600] Iteration[004/008] Valid loss: 0.0749
2023-02-06 12:10:25 | Valid | Epoch[469/600] Iteration[005/008] Valid loss: 0.0718
2023-02-06 12:10:25 | Valid | Epoch[469/600] Iteration[006/008] Valid loss: 0.0670
2023-02-06 12:10:25 | Valid | Epoch[469/600] Iteration[007/008] Valid loss: 0.0715
2023-02-06 12:10:25 | Valid | Epoch[469/600] Iteration[008/008] Valid loss: 0.0685
2023-02-06 12:10:25 | Valid | Epoch[469/600] MIou: 0.9386044669099372
2023-02-06 12:10:25 | Valid | Epoch[469/600] Pixel Accuracy: 0.989501953125
2023-02-06 12:10:25 | Valid | Epoch[469/600] Mean Pixel Accuracy: 0.9617095473211723
2023-02-06 12:10:25 | Stage | Epoch[469/600] Train loss:0.0166
2023-02-06 12:10:25 | Stage | Epoch[469/600] Valid loss:0.0685
2023-02-06 12:10:25 | Stage | Epoch[469/600] LR:0.001

2023-02-06 12:10:25 | Train | Epoch[470/600] Iteration[001/030] Train loss: 0.0152
2023-02-06 12:10:25 | Train | Epoch[470/600] Iteration[002/030] Train loss: 0.0152
2023-02-06 12:10:25 | Train | Epoch[470/600] Iteration[003/030] Train loss: 0.0147
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[004/030] Train loss: 0.0148
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[005/030] Train loss: 0.0151
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[006/030] Train loss: 0.0155
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[007/030] Train loss: 0.0156
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[008/030] Train loss: 0.0155
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[009/030] Train loss: 0.0155
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:10:26 | Train | Epoch[470/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:10:27 | Train | Epoch[470/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:10:28 | Valid | Epoch[470/600] Iteration[001/008] Valid loss: 0.1186
2023-02-06 12:10:28 | Valid | Epoch[470/600] Iteration[002/008] Valid loss: 0.0834
2023-02-06 12:10:28 | Valid | Epoch[470/600] Iteration[003/008] Valid loss: 0.0823
2023-02-06 12:10:28 | Valid | Epoch[470/600] Iteration[004/008] Valid loss: 0.0752
2023-02-06 12:10:28 | Valid | Epoch[470/600] Iteration[005/008] Valid loss: 0.0729
2023-02-06 12:10:28 | Valid | Epoch[470/600] Iteration[006/008] Valid loss: 0.0681
2023-02-06 12:10:28 | Valid | Epoch[470/600] Iteration[007/008] Valid loss: 0.0722
2023-02-06 12:10:28 | Valid | Epoch[470/600] Iteration[008/008] Valid loss: 0.0693
2023-02-06 12:10:28 | Valid | Epoch[470/600] MIou: 0.9390089394506564
2023-02-06 12:10:28 | Valid | Epoch[470/600] Pixel Accuracy: 0.9895617167154948
2023-02-06 12:10:28 | Valid | Epoch[470/600] Mean Pixel Accuracy: 0.9625159334638376
2023-02-06 12:10:28 | Stage | Epoch[470/600] Train loss:0.0166
2023-02-06 12:10:28 | Stage | Epoch[470/600] Valid loss:0.0693
2023-02-06 12:10:28 | Stage | Epoch[470/600] LR:0.001

2023-02-06 12:10:28 | Train | Epoch[471/600] Iteration[001/030] Train loss: 0.0143
2023-02-06 12:10:28 | Train | Epoch[471/600] Iteration[002/030] Train loss: 0.0155
2023-02-06 12:10:28 | Train | Epoch[471/600] Iteration[003/030] Train loss: 0.0156
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:10:29 | Train | Epoch[471/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:10:30 | Train | Epoch[471/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:10:31 | Valid | Epoch[471/600] Iteration[001/008] Valid loss: 0.0690
2023-02-06 12:10:31 | Valid | Epoch[471/600] Iteration[002/008] Valid loss: 0.0507
2023-02-06 12:10:31 | Valid | Epoch[471/600] Iteration[003/008] Valid loss: 0.0524
2023-02-06 12:10:31 | Valid | Epoch[471/600] Iteration[004/008] Valid loss: 0.0471
2023-02-06 12:10:31 | Valid | Epoch[471/600] Iteration[005/008] Valid loss: 0.0451
2023-02-06 12:10:31 | Valid | Epoch[471/600] Iteration[006/008] Valid loss: 0.0425
2023-02-06 12:10:31 | Valid | Epoch[471/600] Iteration[007/008] Valid loss: 0.0436
2023-02-06 12:10:31 | Valid | Epoch[471/600] Iteration[008/008] Valid loss: 0.0423
2023-02-06 12:10:31 | Valid | Epoch[471/600] MIou: 0.9211813061750304
2023-02-06 12:10:31 | Valid | Epoch[471/600] Pixel Accuracy: 0.9868087768554688
2023-02-06 12:10:31 | Valid | Epoch[471/600] Mean Pixel Accuracy: 0.9355711690717698
2023-02-06 12:10:31 | Stage | Epoch[471/600] Train loss:0.0165
2023-02-06 12:10:31 | Stage | Epoch[471/600] Valid loss:0.0423
2023-02-06 12:10:31 | Stage | Epoch[471/600] LR:0.001

2023-02-06 12:10:31 | Train | Epoch[472/600] Iteration[001/030] Train loss: 0.0163
2023-02-06 12:10:31 | Train | Epoch[472/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[003/030] Train loss: 0.0162
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[009/030] Train loss: 0.0170
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:10:32 | Train | Epoch[472/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:10:33 | Train | Epoch[472/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:10:34 | Valid | Epoch[472/600] Iteration[001/008] Valid loss: 0.0586
2023-02-06 12:10:34 | Valid | Epoch[472/600] Iteration[002/008] Valid loss: 0.0456
2023-02-06 12:10:34 | Valid | Epoch[472/600] Iteration[003/008] Valid loss: 0.0463
2023-02-06 12:10:34 | Valid | Epoch[472/600] Iteration[004/008] Valid loss: 0.0418
2023-02-06 12:10:34 | Valid | Epoch[472/600] Iteration[005/008] Valid loss: 0.0405
2023-02-06 12:10:34 | Valid | Epoch[472/600] Iteration[006/008] Valid loss: 0.0387
2023-02-06 12:10:34 | Valid | Epoch[472/600] Iteration[007/008] Valid loss: 0.0393
2023-02-06 12:10:34 | Valid | Epoch[472/600] Iteration[008/008] Valid loss: 0.0386
2023-02-06 12:10:34 | Valid | Epoch[472/600] MIou: 0.908485860548027
2023-02-06 12:10:34 | Valid | Epoch[472/600] Pixel Accuracy: 0.9847679138183594
2023-02-06 12:10:34 | Valid | Epoch[472/600] Mean Pixel Accuracy: 0.9213817119194747
2023-02-06 12:10:34 | Stage | Epoch[472/600] Train loss:0.0167
2023-02-06 12:10:34 | Stage | Epoch[472/600] Valid loss:0.0386
2023-02-06 12:10:34 | Stage | Epoch[472/600] LR:0.001

2023-02-06 12:10:34 | Train | Epoch[473/600] Iteration[001/030] Train loss: 0.0146
2023-02-06 12:10:34 | Train | Epoch[473/600] Iteration[002/030] Train loss: 0.0147
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[003/030] Train loss: 0.0152
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[004/030] Train loss: 0.0156
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[005/030] Train loss: 0.0167
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[009/030] Train loss: 0.0170
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:10:35 | Train | Epoch[473/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[020/030] Train loss: 0.0169
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:10:36 | Train | Epoch[473/600] Iteration[029/030] Train loss: 0.0169
2023-02-06 12:10:37 | Train | Epoch[473/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 12:10:37 | Valid | Epoch[473/600] Iteration[001/008] Valid loss: 0.0662
2023-02-06 12:10:37 | Valid | Epoch[473/600] Iteration[002/008] Valid loss: 0.0491
2023-02-06 12:10:37 | Valid | Epoch[473/600] Iteration[003/008] Valid loss: 0.0507
2023-02-06 12:10:37 | Valid | Epoch[473/600] Iteration[004/008] Valid loss: 0.0455
2023-02-06 12:10:37 | Valid | Epoch[473/600] Iteration[005/008] Valid loss: 0.0436
2023-02-06 12:10:37 | Valid | Epoch[473/600] Iteration[006/008] Valid loss: 0.0413
2023-02-06 12:10:37 | Valid | Epoch[473/600] Iteration[007/008] Valid loss: 0.0424
2023-02-06 12:10:37 | Valid | Epoch[473/600] Iteration[008/008] Valid loss: 0.0412
2023-02-06 12:10:37 | Valid | Epoch[473/600] MIou: 0.918815232587311
2023-02-06 12:10:37 | Valid | Epoch[473/600] Pixel Accuracy: 0.9864323933919271
2023-02-06 12:10:37 | Valid | Epoch[473/600] Mean Pixel Accuracy: 0.9327329969903277
2023-02-06 12:10:37 | Stage | Epoch[473/600] Train loss:0.0169
2023-02-06 12:10:37 | Stage | Epoch[473/600] Valid loss:0.0412
2023-02-06 12:10:37 | Stage | Epoch[473/600] LR:0.001

2023-02-06 12:10:37 | Train | Epoch[474/600] Iteration[001/030] Train loss: 0.0144
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[002/030] Train loss: 0.0137
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[003/030] Train loss: 0.0149
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[004/030] Train loss: 0.0155
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[005/030] Train loss: 0.0154
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[006/030] Train loss: 0.0156
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[013/030] Train loss: 0.0171
2023-02-06 12:10:38 | Train | Epoch[474/600] Iteration[014/030] Train loss: 0.0172
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[015/030] Train loss: 0.0170
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:10:39 | Train | Epoch[474/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:10:40 | Train | Epoch[474/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:10:40 | Train | Epoch[474/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:10:40 | Valid | Epoch[474/600] Iteration[001/008] Valid loss: 0.0699
2023-02-06 12:10:40 | Valid | Epoch[474/600] Iteration[002/008] Valid loss: 0.0518
2023-02-06 12:10:40 | Valid | Epoch[474/600] Iteration[003/008] Valid loss: 0.0534
2023-02-06 12:10:40 | Valid | Epoch[474/600] Iteration[004/008] Valid loss: 0.0477
2023-02-06 12:10:40 | Valid | Epoch[474/600] Iteration[005/008] Valid loss: 0.0455
2023-02-06 12:10:40 | Valid | Epoch[474/600] Iteration[006/008] Valid loss: 0.0429
2023-02-06 12:10:40 | Valid | Epoch[474/600] Iteration[007/008] Valid loss: 0.0439
2023-02-06 12:10:40 | Valid | Epoch[474/600] Iteration[008/008] Valid loss: 0.0426
2023-02-06 12:10:40 | Valid | Epoch[474/600] MIou: 0.9224544108231423
2023-02-06 12:10:40 | Valid | Epoch[474/600] Pixel Accuracy: 0.9870198567708334
2023-02-06 12:10:40 | Valid | Epoch[474/600] Mean Pixel Accuracy: 0.9368284724677692
2023-02-06 12:10:40 | Stage | Epoch[474/600] Train loss:0.0166
2023-02-06 12:10:40 | Stage | Epoch[474/600] Valid loss:0.0426
2023-02-06 12:10:40 | Stage | Epoch[474/600] LR:0.001

2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[001/030] Train loss: 0.0161
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[003/030] Train loss: 0.0163
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:10:41 | Train | Epoch[475/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:10:42 | Train | Epoch[475/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:10:43 | Train | Epoch[475/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:10:43 | Train | Epoch[475/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:10:43 | Valid | Epoch[475/600] Iteration[001/008] Valid loss: 0.0926
2023-02-06 12:10:43 | Valid | Epoch[475/600] Iteration[002/008] Valid loss: 0.0659
2023-02-06 12:10:43 | Valid | Epoch[475/600] Iteration[003/008] Valid loss: 0.0659
2023-02-06 12:10:43 | Valid | Epoch[475/600] Iteration[004/008] Valid loss: 0.0597
2023-02-06 12:10:43 | Valid | Epoch[475/600] Iteration[005/008] Valid loss: 0.0568
2023-02-06 12:10:43 | Valid | Epoch[475/600] Iteration[006/008] Valid loss: 0.0535
2023-02-06 12:10:43 | Valid | Epoch[475/600] Iteration[007/008] Valid loss: 0.0562
2023-02-06 12:10:43 | Valid | Epoch[475/600] Iteration[008/008] Valid loss: 0.0539
2023-02-06 12:10:43 | Valid | Epoch[475/600] MIou: 0.9345149886312374
2023-02-06 12:10:43 | Valid | Epoch[475/600] Pixel Accuracy: 0.9889068603515625
2023-02-06 12:10:43 | Valid | Epoch[475/600] Mean Pixel Accuracy: 0.9535139338063071
2023-02-06 12:10:43 | Stage | Epoch[475/600] Train loss:0.0165
2023-02-06 12:10:43 | Stage | Epoch[475/600] Valid loss:0.0539
2023-02-06 12:10:43 | Stage | Epoch[475/600] LR:0.001

2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[002/030] Train loss: 0.0171
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[006/030] Train loss: 0.0176
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[007/030] Train loss: 0.0176
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[008/030] Train loss: 0.0174
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[009/030] Train loss: 0.0173
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[010/030] Train loss: 0.0171
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:10:44 | Train | Epoch[476/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:10:45 | Train | Epoch[476/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:10:46 | Train | Epoch[476/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:10:46 | Train | Epoch[476/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:10:46 | Train | Epoch[476/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:10:46 | Train | Epoch[476/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:10:46 | Valid | Epoch[476/600] Iteration[001/008] Valid loss: 0.1005
2023-02-06 12:10:46 | Valid | Epoch[476/600] Iteration[002/008] Valid loss: 0.0692
2023-02-06 12:10:46 | Valid | Epoch[476/600] Iteration[003/008] Valid loss: 0.0691
2023-02-06 12:10:46 | Valid | Epoch[476/600] Iteration[004/008] Valid loss: 0.0625
2023-02-06 12:10:46 | Valid | Epoch[476/600] Iteration[005/008] Valid loss: 0.0590
2023-02-06 12:10:46 | Valid | Epoch[476/600] Iteration[006/008] Valid loss: 0.0550
2023-02-06 12:10:46 | Valid | Epoch[476/600] Iteration[007/008] Valid loss: 0.0582
2023-02-06 12:10:46 | Valid | Epoch[476/600] Iteration[008/008] Valid loss: 0.0559
2023-02-06 12:10:46 | Valid | Epoch[476/600] MIou: 0.9351358256398862
2023-02-06 12:10:46 | Valid | Epoch[476/600] Pixel Accuracy: 0.9890098571777344
2023-02-06 12:10:46 | Valid | Epoch[476/600] Mean Pixel Accuracy: 0.9541919114628634
2023-02-06 12:10:46 | Stage | Epoch[476/600] Train loss:0.0164
2023-02-06 12:10:46 | Stage | Epoch[476/600] Valid loss:0.0559
2023-02-06 12:10:46 | Stage | Epoch[476/600] LR:0.001

2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[001/030] Train loss: 0.0141
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[002/030] Train loss: 0.0169
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[005/030] Train loss: 0.0175
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[006/030] Train loss: 0.0176
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[007/030] Train loss: 0.0178
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[008/030] Train loss: 0.0175
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[009/030] Train loss: 0.0173
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:10:47 | Train | Epoch[477/600] Iteration[012/030] Train loss: 0.0170
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:10:48 | Train | Epoch[477/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:10:49 | Train | Epoch[477/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:10:49 | Train | Epoch[477/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:10:49 | Train | Epoch[477/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:10:49 | Train | Epoch[477/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:10:49 | Valid | Epoch[477/600] Iteration[001/008] Valid loss: 0.0811
2023-02-06 12:10:49 | Valid | Epoch[477/600] Iteration[002/008] Valid loss: 0.0577
2023-02-06 12:10:49 | Valid | Epoch[477/600] Iteration[003/008] Valid loss: 0.0586
2023-02-06 12:10:49 | Valid | Epoch[477/600] Iteration[004/008] Valid loss: 0.0523
2023-02-06 12:10:49 | Valid | Epoch[477/600] Iteration[005/008] Valid loss: 0.0497
2023-02-06 12:10:49 | Valid | Epoch[477/600] Iteration[006/008] Valid loss: 0.0466
2023-02-06 12:10:49 | Valid | Epoch[477/600] Iteration[007/008] Valid loss: 0.0484
2023-02-06 12:10:49 | Valid | Epoch[477/600] Iteration[008/008] Valid loss: 0.0468
2023-02-06 12:10:49 | Valid | Epoch[477/600] MIou: 0.9279492323966992
2023-02-06 12:10:49 | Valid | Epoch[477/600] Pixel Accuracy: 0.9878730773925781
2023-02-06 12:10:49 | Valid | Epoch[477/600] Mean Pixel Accuracy: 0.9444114479470131
2023-02-06 12:10:49 | Stage | Epoch[477/600] Train loss:0.0168
2023-02-06 12:10:49 | Stage | Epoch[477/600] Valid loss:0.0468
2023-02-06 12:10:49 | Stage | Epoch[477/600] LR:0.001

2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[001/030] Train loss: 0.0149
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[002/030] Train loss: 0.0154
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:10:50 | Train | Epoch[478/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:10:51 | Train | Epoch[478/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:10:52 | Train | Epoch[478/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:10:52 | Train | Epoch[478/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:10:52 | Train | Epoch[478/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:10:52 | Train | Epoch[478/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:10:52 | Train | Epoch[478/600] Iteration[030/030] Train loss: 0.0168
2023-02-06 12:10:52 | Valid | Epoch[478/600] Iteration[001/008] Valid loss: 0.0872
2023-02-06 12:10:52 | Valid | Epoch[478/600] Iteration[002/008] Valid loss: 0.0618
2023-02-06 12:10:52 | Valid | Epoch[478/600] Iteration[003/008] Valid loss: 0.0632
2023-02-06 12:10:52 | Valid | Epoch[478/600] Iteration[004/008] Valid loss: 0.0567
2023-02-06 12:10:52 | Valid | Epoch[478/600] Iteration[005/008] Valid loss: 0.0540
2023-02-06 12:10:52 | Valid | Epoch[478/600] Iteration[006/008] Valid loss: 0.0506
2023-02-06 12:10:52 | Valid | Epoch[478/600] Iteration[007/008] Valid loss: 0.0526
2023-02-06 12:10:52 | Valid | Epoch[478/600] Iteration[008/008] Valid loss: 0.0505
2023-02-06 12:10:52 | Valid | Epoch[478/600] MIou: 0.9319849683023127
2023-02-06 12:10:52 | Valid | Epoch[478/600] Pixel Accuracy: 0.9885164896647135
2023-02-06 12:10:52 | Valid | Epoch[478/600] Mean Pixel Accuracy: 0.9496155554793895
2023-02-06 12:10:52 | Stage | Epoch[478/600] Train loss:0.0168
2023-02-06 12:10:52 | Stage | Epoch[478/600] Valid loss:0.0505
2023-02-06 12:10:52 | Stage | Epoch[478/600] LR:0.001

2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[007/030] Train loss: 0.0162
2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:10:53 | Train | Epoch[479/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[014/030] Train loss: 0.0170
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:10:54 | Train | Epoch[479/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:10:55 | Train | Epoch[479/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:10:55 | Train | Epoch[479/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:10:55 | Train | Epoch[479/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:10:55 | Train | Epoch[479/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:10:55 | Train | Epoch[479/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:10:55 | Valid | Epoch[479/600] Iteration[001/008] Valid loss: 0.0741
2023-02-06 12:10:55 | Valid | Epoch[479/600] Iteration[002/008] Valid loss: 0.0539
2023-02-06 12:10:55 | Valid | Epoch[479/600] Iteration[003/008] Valid loss: 0.0543
2023-02-06 12:10:55 | Valid | Epoch[479/600] Iteration[004/008] Valid loss: 0.0488
2023-02-06 12:10:55 | Valid | Epoch[479/600] Iteration[005/008] Valid loss: 0.0465
2023-02-06 12:10:55 | Valid | Epoch[479/600] Iteration[006/008] Valid loss: 0.0438
2023-02-06 12:10:55 | Valid | Epoch[479/600] Iteration[007/008] Valid loss: 0.0450
2023-02-06 12:10:55 | Valid | Epoch[479/600] Iteration[008/008] Valid loss: 0.0435
2023-02-06 12:10:55 | Valid | Epoch[479/600] MIou: 0.92450887515906
2023-02-06 12:10:55 | Valid | Epoch[479/600] Pixel Accuracy: 0.9873390197753906
2023-02-06 12:10:56 | Valid | Epoch[479/600] Mean Pixel Accuracy: 0.9396098318585115
2023-02-06 12:10:56 | Stage | Epoch[479/600] Train loss:0.0165
2023-02-06 12:10:56 | Stage | Epoch[479/600] Valid loss:0.0435
2023-02-06 12:10:56 | Stage | Epoch[479/600] LR:0.001

2023-02-06 12:10:56 | Train | Epoch[480/600] Iteration[001/030] Train loss: 0.0160
2023-02-06 12:10:56 | Train | Epoch[480/600] Iteration[002/030] Train loss: 0.0180
2023-02-06 12:10:56 | Train | Epoch[480/600] Iteration[003/030] Train loss: 0.0183
2023-02-06 12:10:56 | Train | Epoch[480/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:10:56 | Train | Epoch[480/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:10:56 | Train | Epoch[480/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:10:56 | Train | Epoch[480/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:10:56 | Train | Epoch[480/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:10:56 | Train | Epoch[480/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:10:56 | Train | Epoch[480/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:10:57 | Train | Epoch[480/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:10:58 | Train | Epoch[480/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:10:58 | Train | Epoch[480/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:10:58 | Train | Epoch[480/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:10:58 | Train | Epoch[480/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:10:58 | Train | Epoch[480/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:10:58 | Train | Epoch[480/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:10:58 | Train | Epoch[480/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:10:58 | Valid | Epoch[480/600] Iteration[001/008] Valid loss: 0.0709
2023-02-06 12:10:58 | Valid | Epoch[480/600] Iteration[002/008] Valid loss: 0.0519
2023-02-06 12:10:58 | Valid | Epoch[480/600] Iteration[003/008] Valid loss: 0.0528
2023-02-06 12:10:58 | Valid | Epoch[480/600] Iteration[004/008] Valid loss: 0.0473
2023-02-06 12:10:58 | Valid | Epoch[480/600] Iteration[005/008] Valid loss: 0.0452
2023-02-06 12:10:58 | Valid | Epoch[480/600] Iteration[006/008] Valid loss: 0.0428
2023-02-06 12:10:58 | Valid | Epoch[480/600] Iteration[007/008] Valid loss: 0.0441
2023-02-06 12:10:58 | Valid | Epoch[480/600] Iteration[008/008] Valid loss: 0.0427
2023-02-06 12:10:59 | Valid | Epoch[480/600] MIou: 0.9219773662349409
2023-02-06 12:10:59 | Valid | Epoch[480/600] Pixel Accuracy: 0.9869257609049479
2023-02-06 12:10:59 | Valid | Epoch[480/600] Mean Pixel Accuracy: 0.936859179496444
2023-02-06 12:10:59 | Stage | Epoch[480/600] Train loss:0.0166
2023-02-06 12:10:59 | Stage | Epoch[480/600] Valid loss:0.0427
2023-02-06 12:10:59 | Stage | Epoch[480/600] LR:0.001

2023-02-06 12:10:59 | Train | Epoch[481/600] Iteration[001/030] Train loss: 0.0195
2023-02-06 12:10:59 | Train | Epoch[481/600] Iteration[002/030] Train loss: 0.0185
2023-02-06 12:10:59 | Train | Epoch[481/600] Iteration[003/030] Train loss: 0.0173
2023-02-06 12:10:59 | Train | Epoch[481/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:10:59 | Train | Epoch[481/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:10:59 | Train | Epoch[481/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:10:59 | Train | Epoch[481/600] Iteration[007/030] Train loss: 0.0161
2023-02-06 12:10:59 | Train | Epoch[481/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:10:59 | Train | Epoch[481/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:11:00 | Train | Epoch[481/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:11:01 | Train | Epoch[481/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:11:01 | Train | Epoch[481/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:11:01 | Train | Epoch[481/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:11:01 | Train | Epoch[481/600] Iteration[027/030] Train loss: 0.0169
2023-02-06 12:11:01 | Train | Epoch[481/600] Iteration[028/030] Train loss: 0.0169
2023-02-06 12:11:01 | Train | Epoch[481/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:11:01 | Train | Epoch[481/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:11:01 | Valid | Epoch[481/600] Iteration[001/008] Valid loss: 0.0921
2023-02-06 12:11:01 | Valid | Epoch[481/600] Iteration[002/008] Valid loss: 0.0636
2023-02-06 12:11:01 | Valid | Epoch[481/600] Iteration[003/008] Valid loss: 0.0645
2023-02-06 12:11:01 | Valid | Epoch[481/600] Iteration[004/008] Valid loss: 0.0580
2023-02-06 12:11:01 | Valid | Epoch[481/600] Iteration[005/008] Valid loss: 0.0551
2023-02-06 12:11:01 | Valid | Epoch[481/600] Iteration[006/008] Valid loss: 0.0515
2023-02-06 12:11:02 | Valid | Epoch[481/600] Iteration[007/008] Valid loss: 0.0541
2023-02-06 12:11:02 | Valid | Epoch[481/600] Iteration[008/008] Valid loss: 0.0521
2023-02-06 12:11:02 | Valid | Epoch[481/600] MIou: 0.9326726998422317
2023-02-06 12:11:02 | Valid | Epoch[481/600] Pixel Accuracy: 0.9886156717936198
2023-02-06 12:11:02 | Valid | Epoch[481/600] Mean Pixel Accuracy: 0.9509381645098678
2023-02-06 12:11:02 | Stage | Epoch[481/600] Train loss:0.0166
2023-02-06 12:11:02 | Stage | Epoch[481/600] Valid loss:0.0521
2023-02-06 12:11:02 | Stage | Epoch[481/600] LR:0.001

2023-02-06 12:11:02 | Train | Epoch[482/600] Iteration[001/030] Train loss: 0.0162
2023-02-06 12:11:02 | Train | Epoch[482/600] Iteration[002/030] Train loss: 0.0161
2023-02-06 12:11:02 | Train | Epoch[482/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:11:02 | Train | Epoch[482/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 12:11:02 | Train | Epoch[482/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:11:02 | Train | Epoch[482/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:11:02 | Train | Epoch[482/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:11:02 | Train | Epoch[482/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:11:03 | Train | Epoch[482/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:11:04 | Train | Epoch[482/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:11:04 | Train | Epoch[482/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:11:04 | Train | Epoch[482/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:11:04 | Train | Epoch[482/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:11:04 | Train | Epoch[482/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:11:04 | Train | Epoch[482/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:11:04 | Train | Epoch[482/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:11:04 | Train | Epoch[482/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:11:04 | Valid | Epoch[482/600] Iteration[001/008] Valid loss: 0.1085
2023-02-06 12:11:04 | Valid | Epoch[482/600] Iteration[002/008] Valid loss: 0.0765
2023-02-06 12:11:04 | Valid | Epoch[482/600] Iteration[003/008] Valid loss: 0.0773
2023-02-06 12:11:05 | Valid | Epoch[482/600] Iteration[004/008] Valid loss: 0.0701
2023-02-06 12:11:05 | Valid | Epoch[482/600] Iteration[005/008] Valid loss: 0.0672
2023-02-06 12:11:05 | Valid | Epoch[482/600] Iteration[006/008] Valid loss: 0.0626
2023-02-06 12:11:05 | Valid | Epoch[482/600] Iteration[007/008] Valid loss: 0.0653
2023-02-06 12:11:05 | Valid | Epoch[482/600] Iteration[008/008] Valid loss: 0.0623
2023-02-06 12:11:05 | Valid | Epoch[482/600] MIou: 0.9372045042365283
2023-02-06 12:11:05 | Valid | Epoch[482/600] Pixel Accuracy: 0.9893213907877604
2023-02-06 12:11:05 | Valid | Epoch[482/600] Mean Pixel Accuracy: 0.9578313815386285
2023-02-06 12:11:05 | Stage | Epoch[482/600] Train loss:0.0166
2023-02-06 12:11:05 | Stage | Epoch[482/600] Valid loss:0.0623
2023-02-06 12:11:05 | Stage | Epoch[482/600] LR:0.001

2023-02-06 12:11:05 | Train | Epoch[483/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 12:11:05 | Train | Epoch[483/600] Iteration[002/030] Train loss: 0.0174
2023-02-06 12:11:05 | Train | Epoch[483/600] Iteration[003/030] Train loss: 0.0172
2023-02-06 12:11:05 | Train | Epoch[483/600] Iteration[004/030] Train loss: 0.0178
2023-02-06 12:11:05 | Train | Epoch[483/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:11:05 | Train | Epoch[483/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[007/030] Train loss: 0.0177
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[008/030] Train loss: 0.0175
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[011/030] Train loss: 0.0172
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[016/030] Train loss: 0.0169
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:11:06 | Train | Epoch[483/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:11:07 | Train | Epoch[483/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:11:07 | Train | Epoch[483/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:11:07 | Train | Epoch[483/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:11:07 | Train | Epoch[483/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:11:07 | Train | Epoch[483/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:11:07 | Train | Epoch[483/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:11:07 | Train | Epoch[483/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:11:07 | Train | Epoch[483/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:11:07 | Train | Epoch[483/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:11:07 | Train | Epoch[483/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:11:08 | Valid | Epoch[483/600] Iteration[001/008] Valid loss: 0.0666
2023-02-06 12:11:08 | Valid | Epoch[483/600] Iteration[002/008] Valid loss: 0.0499
2023-02-06 12:11:08 | Valid | Epoch[483/600] Iteration[003/008] Valid loss: 0.0521
2023-02-06 12:11:08 | Valid | Epoch[483/600] Iteration[004/008] Valid loss: 0.0468
2023-02-06 12:11:08 | Valid | Epoch[483/600] Iteration[005/008] Valid loss: 0.0446
2023-02-06 12:11:08 | Valid | Epoch[483/600] Iteration[006/008] Valid loss: 0.0422
2023-02-06 12:11:08 | Valid | Epoch[483/600] Iteration[007/008] Valid loss: 0.0432
2023-02-06 12:11:08 | Valid | Epoch[483/600] Iteration[008/008] Valid loss: 0.0419
2023-02-06 12:11:08 | Valid | Epoch[483/600] MIou: 0.9188162175071473
2023-02-06 12:11:08 | Valid | Epoch[483/600] Pixel Accuracy: 0.9864298502604166
2023-02-06 12:11:08 | Valid | Epoch[483/600] Mean Pixel Accuracy: 0.9328203657779568
2023-02-06 12:11:08 | Stage | Epoch[483/600] Train loss:0.0167
2023-02-06 12:11:08 | Stage | Epoch[483/600] Valid loss:0.0419
2023-02-06 12:11:08 | Stage | Epoch[483/600] LR:0.001

2023-02-06 12:11:08 | Train | Epoch[484/600] Iteration[001/030] Train loss: 0.0152
2023-02-06 12:11:08 | Train | Epoch[484/600] Iteration[002/030] Train loss: 0.0161
2023-02-06 12:11:08 | Train | Epoch[484/600] Iteration[003/030] Train loss: 0.0159
2023-02-06 12:11:08 | Train | Epoch[484/600] Iteration[004/030] Train loss: 0.0159
2023-02-06 12:11:08 | Train | Epoch[484/600] Iteration[005/030] Train loss: 0.0162
2023-02-06 12:11:08 | Train | Epoch[484/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[010/030] Train loss: 0.0159
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:11:09 | Train | Epoch[484/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:11:10 | Train | Epoch[484/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:11:10 | Valid | Epoch[484/600] Iteration[001/008] Valid loss: 0.1235
2023-02-06 12:11:11 | Valid | Epoch[484/600] Iteration[002/008] Valid loss: 0.0856
2023-02-06 12:11:11 | Valid | Epoch[484/600] Iteration[003/008] Valid loss: 0.0843
2023-02-06 12:11:11 | Valid | Epoch[484/600] Iteration[004/008] Valid loss: 0.0777
2023-02-06 12:11:11 | Valid | Epoch[484/600] Iteration[005/008] Valid loss: 0.0750
2023-02-06 12:11:11 | Valid | Epoch[484/600] Iteration[006/008] Valid loss: 0.0701
2023-02-06 12:11:11 | Valid | Epoch[484/600] Iteration[007/008] Valid loss: 0.0754
2023-02-06 12:11:11 | Valid | Epoch[484/600] Iteration[008/008] Valid loss: 0.0723
2023-02-06 12:11:11 | Valid | Epoch[484/600] MIou: 0.9394658193501777
2023-02-06 12:11:11 | Valid | Epoch[484/600] Pixel Accuracy: 0.9896278381347656
2023-02-06 12:11:11 | Valid | Epoch[484/600] Mean Pixel Accuracy: 0.963497006871179
2023-02-06 12:11:11 | Stage | Epoch[484/600] Train loss:0.0165
2023-02-06 12:11:11 | Stage | Epoch[484/600] Valid loss:0.0723
2023-02-06 12:11:11 | Stage | Epoch[484/600] LR:0.001

2023-02-06 12:11:11 | Train | Epoch[485/600] Iteration[001/030] Train loss: 0.0166
2023-02-06 12:11:11 | Train | Epoch[485/600] Iteration[002/030] Train loss: 0.0173
2023-02-06 12:11:11 | Train | Epoch[485/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:11:11 | Train | Epoch[485/600] Iteration[004/030] Train loss: 0.0158
2023-02-06 12:11:11 | Train | Epoch[485/600] Iteration[005/030] Train loss: 0.0160
2023-02-06 12:11:11 | Train | Epoch[485/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[009/030] Train loss: 0.0166
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:11:12 | Train | Epoch[485/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:11:13 | Train | Epoch[485/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:11:13 | Train | Epoch[485/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:11:13 | Train | Epoch[485/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:11:13 | Train | Epoch[485/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:11:13 | Train | Epoch[485/600] Iteration[025/030] Train loss: 0.0169
2023-02-06 12:11:13 | Train | Epoch[485/600] Iteration[026/030] Train loss: 0.0169
2023-02-06 12:11:13 | Train | Epoch[485/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:11:13 | Train | Epoch[485/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:11:13 | Train | Epoch[485/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:11:13 | Train | Epoch[485/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:11:14 | Valid | Epoch[485/600] Iteration[001/008] Valid loss: 0.0639
2023-02-06 12:11:14 | Valid | Epoch[485/600] Iteration[002/008] Valid loss: 0.0484
2023-02-06 12:11:14 | Valid | Epoch[485/600] Iteration[003/008] Valid loss: 0.0496
2023-02-06 12:11:14 | Valid | Epoch[485/600] Iteration[004/008] Valid loss: 0.0445
2023-02-06 12:11:14 | Valid | Epoch[485/600] Iteration[005/008] Valid loss: 0.0428
2023-02-06 12:11:14 | Valid | Epoch[485/600] Iteration[006/008] Valid loss: 0.0406
2023-02-06 12:11:14 | Valid | Epoch[485/600] Iteration[007/008] Valid loss: 0.0414
2023-02-06 12:11:14 | Valid | Epoch[485/600] Iteration[008/008] Valid loss: 0.0404
2023-02-06 12:11:14 | Valid | Epoch[485/600] MIou: 0.9150109964287585
2023-02-06 12:11:14 | Valid | Epoch[485/600] Pixel Accuracy: 0.9858118693033854
2023-02-06 12:11:14 | Valid | Epoch[485/600] Mean Pixel Accuracy: 0.9287207974810587
2023-02-06 12:11:14 | Stage | Epoch[485/600] Train loss:0.0166
2023-02-06 12:11:14 | Stage | Epoch[485/600] Valid loss:0.0404
2023-02-06 12:11:14 | Stage | Epoch[485/600] LR:0.001

2023-02-06 12:11:14 | Train | Epoch[486/600] Iteration[001/030] Train loss: 0.0157
2023-02-06 12:11:14 | Train | Epoch[486/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:11:14 | Train | Epoch[486/600] Iteration[003/030] Train loss: 0.0163
2023-02-06 12:11:14 | Train | Epoch[486/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:11:14 | Train | Epoch[486/600] Iteration[005/030] Train loss: 0.0174
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[006/030] Train loss: 0.0175
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:11:15 | Train | Epoch[486/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:11:16 | Train | Epoch[486/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:11:17 | Valid | Epoch[486/600] Iteration[001/008] Valid loss: 0.0580
2023-02-06 12:11:17 | Valid | Epoch[486/600] Iteration[002/008] Valid loss: 0.0453
2023-02-06 12:11:17 | Valid | Epoch[486/600] Iteration[003/008] Valid loss: 0.0458
2023-02-06 12:11:17 | Valid | Epoch[486/600] Iteration[004/008] Valid loss: 0.0415
2023-02-06 12:11:17 | Valid | Epoch[486/600] Iteration[005/008] Valid loss: 0.0404
2023-02-06 12:11:17 | Valid | Epoch[486/600] Iteration[006/008] Valid loss: 0.0387
2023-02-06 12:11:17 | Valid | Epoch[486/600] Iteration[007/008] Valid loss: 0.0393
2023-02-06 12:11:17 | Valid | Epoch[486/600] Iteration[008/008] Valid loss: 0.0386
2023-02-06 12:11:17 | Valid | Epoch[486/600] MIou: 0.9079835560938524
2023-02-06 12:11:17 | Valid | Epoch[486/600] Pixel Accuracy: 0.9846839904785156
2023-02-06 12:11:17 | Valid | Epoch[486/600] Mean Pixel Accuracy: 0.9209234534243675
2023-02-06 12:11:17 | Stage | Epoch[486/600] Train loss:0.0167
2023-02-06 12:11:17 | Stage | Epoch[486/600] Valid loss:0.0386
2023-02-06 12:11:17 | Stage | Epoch[486/600] LR:0.001

2023-02-06 12:11:17 | Train | Epoch[487/600] Iteration[001/030] Train loss: 0.0141
2023-02-06 12:11:17 | Train | Epoch[487/600] Iteration[002/030] Train loss: 0.0160
2023-02-06 12:11:17 | Train | Epoch[487/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:11:17 | Train | Epoch[487/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:11:17 | Train | Epoch[487/600] Iteration[005/030] Train loss: 0.0157
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[006/030] Train loss: 0.0162
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[012/030] Train loss: 0.0158
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[014/030] Train loss: 0.0159
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[017/030] Train loss: 0.0161
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:11:18 | Train | Epoch[487/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:11:19 | Train | Epoch[487/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:11:20 | Valid | Epoch[487/600] Iteration[001/008] Valid loss: 0.0842
2023-02-06 12:11:20 | Valid | Epoch[487/600] Iteration[002/008] Valid loss: 0.0598
2023-02-06 12:11:20 | Valid | Epoch[487/600] Iteration[003/008] Valid loss: 0.0628
2023-02-06 12:11:20 | Valid | Epoch[487/600] Iteration[004/008] Valid loss: 0.0561
2023-02-06 12:11:20 | Valid | Epoch[487/600] Iteration[005/008] Valid loss: 0.0534
2023-02-06 12:11:20 | Valid | Epoch[487/600] Iteration[006/008] Valid loss: 0.0501
2023-02-06 12:11:20 | Valid | Epoch[487/600] Iteration[007/008] Valid loss: 0.0516
2023-02-06 12:11:20 | Valid | Epoch[487/600] Iteration[008/008] Valid loss: 0.0495
2023-02-06 12:11:20 | Valid | Epoch[487/600] MIou: 0.9298610789658142
2023-02-06 12:11:20 | Valid | Epoch[487/600] Pixel Accuracy: 0.988189697265625
2023-02-06 12:11:20 | Valid | Epoch[487/600] Mean Pixel Accuracy: 0.9464051910567175
2023-02-06 12:11:20 | Stage | Epoch[487/600] Train loss:0.0164
2023-02-06 12:11:20 | Stage | Epoch[487/600] Valid loss:0.0495
2023-02-06 12:11:20 | Stage | Epoch[487/600] LR:0.001

2023-02-06 12:11:20 | Train | Epoch[488/600] Iteration[001/030] Train loss: 0.0169
2023-02-06 12:11:20 | Train | Epoch[488/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:11:20 | Train | Epoch[488/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:11:20 | Train | Epoch[488/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 12:11:20 | Train | Epoch[488/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:11:20 | Train | Epoch[488/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:11:21 | Train | Epoch[488/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:11:22 | Train | Epoch[488/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:11:22 | Train | Epoch[488/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:11:22 | Train | Epoch[488/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:11:22 | Train | Epoch[488/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:11:22 | Train | Epoch[488/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:11:22 | Train | Epoch[488/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:11:22 | Train | Epoch[488/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:11:22 | Train | Epoch[488/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:11:22 | Train | Epoch[488/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:11:22 | Train | Epoch[488/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:11:22 | Valid | Epoch[488/600] Iteration[001/008] Valid loss: 0.0768
2023-02-06 12:11:23 | Valid | Epoch[488/600] Iteration[002/008] Valid loss: 0.0554
2023-02-06 12:11:23 | Valid | Epoch[488/600] Iteration[003/008] Valid loss: 0.0548
2023-02-06 12:11:23 | Valid | Epoch[488/600] Iteration[004/008] Valid loss: 0.0492
2023-02-06 12:11:23 | Valid | Epoch[488/600] Iteration[005/008] Valid loss: 0.0469
2023-02-06 12:11:23 | Valid | Epoch[488/600] Iteration[006/008] Valid loss: 0.0441
2023-02-06 12:11:23 | Valid | Epoch[488/600] Iteration[007/008] Valid loss: 0.0457
2023-02-06 12:11:23 | Valid | Epoch[488/600] Iteration[008/008] Valid loss: 0.0443
2023-02-06 12:11:23 | Valid | Epoch[488/600] MIou: 0.9258245324180656
2023-02-06 12:11:23 | Valid | Epoch[488/600] Pixel Accuracy: 0.987548828125
2023-02-06 12:11:23 | Valid | Epoch[488/600] Mean Pixel Accuracy: 0.9412278432239296
2023-02-06 12:11:23 | Stage | Epoch[488/600] Train loss:0.0167
2023-02-06 12:11:23 | Stage | Epoch[488/600] Valid loss:0.0443
2023-02-06 12:11:23 | Stage | Epoch[488/600] LR:0.001

2023-02-06 12:11:23 | Train | Epoch[489/600] Iteration[001/030] Train loss: 0.0145
2023-02-06 12:11:23 | Train | Epoch[489/600] Iteration[002/030] Train loss: 0.0147
2023-02-06 12:11:23 | Train | Epoch[489/600] Iteration[003/030] Train loss: 0.0144
2023-02-06 12:11:23 | Train | Epoch[489/600] Iteration[004/030] Train loss: 0.0147
2023-02-06 12:11:23 | Train | Epoch[489/600] Iteration[005/030] Train loss: 0.0158
2023-02-06 12:11:23 | Train | Epoch[489/600] Iteration[006/030] Train loss: 0.0162
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:11:24 | Train | Epoch[489/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 12:11:25 | Train | Epoch[489/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 12:11:25 | Train | Epoch[489/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:11:25 | Train | Epoch[489/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:11:25 | Train | Epoch[489/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:11:25 | Train | Epoch[489/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:11:25 | Train | Epoch[489/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:11:25 | Train | Epoch[489/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:11:25 | Train | Epoch[489/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:11:25 | Train | Epoch[489/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:11:25 | Train | Epoch[489/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:11:25 | Valid | Epoch[489/600] Iteration[001/008] Valid loss: 0.0487
2023-02-06 12:11:26 | Valid | Epoch[489/600] Iteration[002/008] Valid loss: 0.0427
2023-02-06 12:11:26 | Valid | Epoch[489/600] Iteration[003/008] Valid loss: 0.0448
2023-02-06 12:11:26 | Valid | Epoch[489/600] Iteration[004/008] Valid loss: 0.0417
2023-02-06 12:11:26 | Valid | Epoch[489/600] Iteration[005/008] Valid loss: 0.0413
2023-02-06 12:11:26 | Valid | Epoch[489/600] Iteration[006/008] Valid loss: 0.0402
2023-02-06 12:11:26 | Valid | Epoch[489/600] Iteration[007/008] Valid loss: 0.0399
2023-02-06 12:11:26 | Valid | Epoch[489/600] Iteration[008/008] Valid loss: 0.0401
2023-02-06 12:11:26 | Valid | Epoch[489/600] MIou: 0.8796881021126683
2023-02-06 12:11:26 | Valid | Epoch[489/600] Pixel Accuracy: 0.9800771077473959
2023-02-06 12:11:26 | Valid | Epoch[489/600] Mean Pixel Accuracy: 0.892598276085407
2023-02-06 12:11:26 | Stage | Epoch[489/600] Train loss:0.0165
2023-02-06 12:11:26 | Stage | Epoch[489/600] Valid loss:0.0401
2023-02-06 12:11:26 | Stage | Epoch[489/600] LR:0.001

2023-02-06 12:11:26 | Train | Epoch[490/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:11:26 | Train | Epoch[490/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:11:26 | Train | Epoch[490/600] Iteration[003/030] Train loss: 0.0172
2023-02-06 12:11:26 | Train | Epoch[490/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:11:26 | Train | Epoch[490/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:11:26 | Train | Epoch[490/600] Iteration[006/030] Train loss: 0.0175
2023-02-06 12:11:26 | Train | Epoch[490/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[013/030] Train loss: 0.0173
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[014/030] Train loss: 0.0173
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[015/030] Train loss: 0.0174
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[016/030] Train loss: 0.0173
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[017/030] Train loss: 0.0173
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[018/030] Train loss: 0.0172
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[019/030] Train loss: 0.0174
2023-02-06 12:11:27 | Train | Epoch[490/600] Iteration[020/030] Train loss: 0.0173
2023-02-06 12:11:28 | Train | Epoch[490/600] Iteration[021/030] Train loss: 0.0173
2023-02-06 12:11:28 | Train | Epoch[490/600] Iteration[022/030] Train loss: 0.0172
2023-02-06 12:11:28 | Train | Epoch[490/600] Iteration[023/030] Train loss: 0.0170
2023-02-06 12:11:28 | Train | Epoch[490/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:11:28 | Train | Epoch[490/600] Iteration[025/030] Train loss: 0.0171
2023-02-06 12:11:28 | Train | Epoch[490/600] Iteration[026/030] Train loss: 0.0171
2023-02-06 12:11:28 | Train | Epoch[490/600] Iteration[027/030] Train loss: 0.0169
2023-02-06 12:11:28 | Train | Epoch[490/600] Iteration[028/030] Train loss: 0.0169
2023-02-06 12:11:28 | Train | Epoch[490/600] Iteration[029/030] Train loss: 0.0168
2023-02-06 12:11:28 | Train | Epoch[490/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:11:28 | Valid | Epoch[490/600] Iteration[001/008] Valid loss: 0.0850
2023-02-06 12:11:29 | Valid | Epoch[490/600] Iteration[002/008] Valid loss: 0.0606
2023-02-06 12:11:29 | Valid | Epoch[490/600] Iteration[003/008] Valid loss: 0.0591
2023-02-06 12:11:29 | Valid | Epoch[490/600] Iteration[004/008] Valid loss: 0.0530
2023-02-06 12:11:29 | Valid | Epoch[490/600] Iteration[005/008] Valid loss: 0.0506
2023-02-06 12:11:29 | Valid | Epoch[490/600] Iteration[006/008] Valid loss: 0.0475
2023-02-06 12:11:29 | Valid | Epoch[490/600] Iteration[007/008] Valid loss: 0.0493
2023-02-06 12:11:29 | Valid | Epoch[490/600] Iteration[008/008] Valid loss: 0.0477
2023-02-06 12:11:29 | Valid | Epoch[490/600] MIou: 0.9303243452114458
2023-02-06 12:11:29 | Valid | Epoch[490/600] Pixel Accuracy: 0.9882520039876302
2023-02-06 12:11:29 | Valid | Epoch[490/600] Mean Pixel Accuracy: 0.9474412319873576
2023-02-06 12:11:29 | Stage | Epoch[490/600] Train loss:0.0167
2023-02-06 12:11:29 | Stage | Epoch[490/600] Valid loss:0.0477
2023-02-06 12:11:29 | Stage | Epoch[490/600] LR:0.001

2023-02-06 12:11:29 | Train | Epoch[491/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 12:11:29 | Train | Epoch[491/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:11:29 | Train | Epoch[491/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:11:29 | Train | Epoch[491/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 12:11:29 | Train | Epoch[491/600] Iteration[005/030] Train loss: 0.0167
2023-02-06 12:11:29 | Train | Epoch[491/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[008/030] Train loss: 0.0173
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:11:30 | Train | Epoch[491/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:11:31 | Train | Epoch[491/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:11:31 | Train | Epoch[491/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:11:31 | Train | Epoch[491/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:11:31 | Train | Epoch[491/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:11:31 | Train | Epoch[491/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:11:31 | Train | Epoch[491/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:11:31 | Train | Epoch[491/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:11:31 | Train | Epoch[491/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:11:31 | Train | Epoch[491/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:11:31 | Train | Epoch[491/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:11:32 | Valid | Epoch[491/600] Iteration[001/008] Valid loss: 0.0963
2023-02-06 12:11:32 | Valid | Epoch[491/600] Iteration[002/008] Valid loss: 0.0664
2023-02-06 12:11:32 | Valid | Epoch[491/600] Iteration[003/008] Valid loss: 0.0664
2023-02-06 12:11:32 | Valid | Epoch[491/600] Iteration[004/008] Valid loss: 0.0595
2023-02-06 12:11:32 | Valid | Epoch[491/600] Iteration[005/008] Valid loss: 0.0563
2023-02-06 12:11:32 | Valid | Epoch[491/600] Iteration[006/008] Valid loss: 0.0528
2023-02-06 12:11:32 | Valid | Epoch[491/600] Iteration[007/008] Valid loss: 0.0554
2023-02-06 12:11:32 | Valid | Epoch[491/600] Iteration[008/008] Valid loss: 0.0532
2023-02-06 12:11:32 | Valid | Epoch[491/600] MIou: 0.9337051840826412
2023-02-06 12:11:32 | Valid | Epoch[491/600] Pixel Accuracy: 0.9887962341308594
2023-02-06 12:11:32 | Valid | Epoch[491/600] Mean Pixel Accuracy: 0.95167145642242
2023-02-06 12:11:32 | Stage | Epoch[491/600] Train loss:0.0166
2023-02-06 12:11:32 | Stage | Epoch[491/600] Valid loss:0.0532
2023-02-06 12:11:32 | Stage | Epoch[491/600] LR:0.001

2023-02-06 12:11:32 | Train | Epoch[492/600] Iteration[001/030] Train loss: 0.0135
2023-02-06 12:11:32 | Train | Epoch[492/600] Iteration[002/030] Train loss: 0.0154
2023-02-06 12:11:32 | Train | Epoch[492/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:11:32 | Train | Epoch[492/600] Iteration[004/030] Train loss: 0.0161
2023-02-06 12:11:32 | Train | Epoch[492/600] Iteration[005/030] Train loss: 0.0158
2023-02-06 12:11:32 | Train | Epoch[492/600] Iteration[006/030] Train loss: 0.0158
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:11:33 | Train | Epoch[492/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:11:34 | Train | Epoch[492/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:11:34 | Train | Epoch[492/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:11:34 | Train | Epoch[492/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:11:34 | Train | Epoch[492/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:11:34 | Train | Epoch[492/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:11:34 | Train | Epoch[492/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:11:34 | Train | Epoch[492/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:11:34 | Train | Epoch[492/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:11:34 | Train | Epoch[492/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:11:34 | Train | Epoch[492/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:11:34 | Valid | Epoch[492/600] Iteration[001/008] Valid loss: 0.0732
2023-02-06 12:11:34 | Valid | Epoch[492/600] Iteration[002/008] Valid loss: 0.0533
2023-02-06 12:11:34 | Valid | Epoch[492/600] Iteration[003/008] Valid loss: 0.0546
2023-02-06 12:11:35 | Valid | Epoch[492/600] Iteration[004/008] Valid loss: 0.0489
2023-02-06 12:11:35 | Valid | Epoch[492/600] Iteration[005/008] Valid loss: 0.0467
2023-02-06 12:11:35 | Valid | Epoch[492/600] Iteration[006/008] Valid loss: 0.0440
2023-02-06 12:11:35 | Valid | Epoch[492/600] Iteration[007/008] Valid loss: 0.0453
2023-02-06 12:11:35 | Valid | Epoch[492/600] Iteration[008/008] Valid loss: 0.0437
2023-02-06 12:11:35 | Valid | Epoch[492/600] MIou: 0.9237773440873923
2023-02-06 12:11:35 | Valid | Epoch[492/600] Pixel Accuracy: 0.9872334798177084
2023-02-06 12:11:35 | Valid | Epoch[492/600] Mean Pixel Accuracy: 0.9383344520662797
2023-02-06 12:11:35 | Stage | Epoch[492/600] Train loss:0.0166
2023-02-06 12:11:35 | Stage | Epoch[492/600] Valid loss:0.0437
2023-02-06 12:11:35 | Stage | Epoch[492/600] LR:0.001

2023-02-06 12:11:35 | Train | Epoch[493/600] Iteration[001/030] Train loss: 0.0148
2023-02-06 12:11:35 | Train | Epoch[493/600] Iteration[002/030] Train loss: 0.0152
2023-02-06 12:11:35 | Train | Epoch[493/600] Iteration[003/030] Train loss: 0.0156
2023-02-06 12:11:35 | Train | Epoch[493/600] Iteration[004/030] Train loss: 0.0161
2023-02-06 12:11:35 | Train | Epoch[493/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 12:11:35 | Train | Epoch[493/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:11:35 | Train | Epoch[493/600] Iteration[007/030] Train loss: 0.0160
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:11:36 | Train | Epoch[493/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:11:37 | Train | Epoch[493/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:11:37 | Train | Epoch[493/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:11:37 | Train | Epoch[493/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:11:37 | Train | Epoch[493/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:11:37 | Train | Epoch[493/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:11:37 | Train | Epoch[493/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:11:37 | Train | Epoch[493/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:11:37 | Train | Epoch[493/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:11:37 | Train | Epoch[493/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:11:37 | Valid | Epoch[493/600] Iteration[001/008] Valid loss: 0.0742
2023-02-06 12:11:38 | Valid | Epoch[493/600] Iteration[002/008] Valid loss: 0.0543
2023-02-06 12:11:38 | Valid | Epoch[493/600] Iteration[003/008] Valid loss: 0.0576
2023-02-06 12:11:38 | Valid | Epoch[493/600] Iteration[004/008] Valid loss: 0.0513
2023-02-06 12:11:38 | Valid | Epoch[493/600] Iteration[005/008] Valid loss: 0.0489
2023-02-06 12:11:38 | Valid | Epoch[493/600] Iteration[006/008] Valid loss: 0.0460
2023-02-06 12:11:38 | Valid | Epoch[493/600] Iteration[007/008] Valid loss: 0.0472
2023-02-06 12:11:38 | Valid | Epoch[493/600] Iteration[008/008] Valid loss: 0.0454
2023-02-06 12:11:38 | Valid | Epoch[493/600] MIou: 0.9251809539053852
2023-02-06 12:11:38 | Valid | Epoch[493/600] Pixel Accuracy: 0.9874521891276041
2023-02-06 12:11:38 | Valid | Epoch[493/600] Mean Pixel Accuracy: 0.9402236555825952
2023-02-06 12:11:38 | Stage | Epoch[493/600] Train loss:0.0165
2023-02-06 12:11:38 | Stage | Epoch[493/600] Valid loss:0.0454
2023-02-06 12:11:38 | Stage | Epoch[493/600] LR:0.001

2023-02-06 12:11:38 | Train | Epoch[494/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 12:11:38 | Train | Epoch[494/600] Iteration[002/030] Train loss: 0.0173
2023-02-06 12:11:38 | Train | Epoch[494/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:11:38 | Train | Epoch[494/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 12:11:38 | Train | Epoch[494/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:11:38 | Train | Epoch[494/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[007/030] Train loss: 0.0174
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[008/030] Train loss: 0.0175
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[011/030] Train loss: 0.0173
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:11:39 | Train | Epoch[494/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:11:40 | Train | Epoch[494/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:11:40 | Train | Epoch[494/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:11:40 | Train | Epoch[494/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:11:40 | Train | Epoch[494/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:11:40 | Train | Epoch[494/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:11:40 | Train | Epoch[494/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:11:40 | Train | Epoch[494/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:11:40 | Train | Epoch[494/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:11:40 | Train | Epoch[494/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:11:40 | Train | Epoch[494/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:11:41 | Valid | Epoch[494/600] Iteration[001/008] Valid loss: 0.0640
2023-02-06 12:11:41 | Valid | Epoch[494/600] Iteration[002/008] Valid loss: 0.0484
2023-02-06 12:11:41 | Valid | Epoch[494/600] Iteration[003/008] Valid loss: 0.0496
2023-02-06 12:11:41 | Valid | Epoch[494/600] Iteration[004/008] Valid loss: 0.0446
2023-02-06 12:11:41 | Valid | Epoch[494/600] Iteration[005/008] Valid loss: 0.0429
2023-02-06 12:11:41 | Valid | Epoch[494/600] Iteration[006/008] Valid loss: 0.0408
2023-02-06 12:11:41 | Valid | Epoch[494/600] Iteration[007/008] Valid loss: 0.0418
2023-02-06 12:11:41 | Valid | Epoch[494/600] Iteration[008/008] Valid loss: 0.0407
2023-02-06 12:11:41 | Valid | Epoch[494/600] MIou: 0.9168870214421556
2023-02-06 12:11:41 | Valid | Epoch[494/600] Pixel Accuracy: 0.9861195882161459
2023-02-06 12:11:41 | Valid | Epoch[494/600] Mean Pixel Accuracy: 0.93063990305674
2023-02-06 12:11:41 | Stage | Epoch[494/600] Train loss:0.0165
2023-02-06 12:11:41 | Stage | Epoch[494/600] Valid loss:0.0407
2023-02-06 12:11:41 | Stage | Epoch[494/600] LR:0.001

2023-02-06 12:11:41 | Train | Epoch[495/600] Iteration[001/030] Train loss: 0.0157
2023-02-06 12:11:41 | Train | Epoch[495/600] Iteration[002/030] Train loss: 0.0171
2023-02-06 12:11:41 | Train | Epoch[495/600] Iteration[003/030] Train loss: 0.0160
2023-02-06 12:11:41 | Train | Epoch[495/600] Iteration[004/030] Train loss: 0.0155
2023-02-06 12:11:41 | Train | Epoch[495/600] Iteration[005/030] Train loss: 0.0160
2023-02-06 12:11:41 | Train | Epoch[495/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[007/030] Train loss: 0.0157
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[008/030] Train loss: 0.0158
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[009/030] Train loss: 0.0160
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[014/030] Train loss: 0.0160
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:11:42 | Train | Epoch[495/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:11:43 | Train | Epoch[495/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:11:43 | Train | Epoch[495/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:11:43 | Train | Epoch[495/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:11:43 | Train | Epoch[495/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:11:43 | Train | Epoch[495/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:11:43 | Train | Epoch[495/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:11:43 | Train | Epoch[495/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:11:43 | Train | Epoch[495/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:11:43 | Train | Epoch[495/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:11:43 | Train | Epoch[495/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:11:44 | Valid | Epoch[495/600] Iteration[001/008] Valid loss: 0.0985
2023-02-06 12:11:44 | Valid | Epoch[495/600] Iteration[002/008] Valid loss: 0.0684
2023-02-06 12:11:44 | Valid | Epoch[495/600] Iteration[003/008] Valid loss: 0.0690
2023-02-06 12:11:44 | Valid | Epoch[495/600] Iteration[004/008] Valid loss: 0.0619
2023-02-06 12:11:44 | Valid | Epoch[495/600] Iteration[005/008] Valid loss: 0.0587
2023-02-06 12:11:44 | Valid | Epoch[495/600] Iteration[006/008] Valid loss: 0.0548
2023-02-06 12:11:44 | Valid | Epoch[495/600] Iteration[007/008] Valid loss: 0.0572
2023-02-06 12:11:44 | Valid | Epoch[495/600] Iteration[008/008] Valid loss: 0.0550
2023-02-06 12:11:44 | Valid | Epoch[495/600] MIou: 0.9343928880045674
2023-02-06 12:11:44 | Valid | Epoch[495/600] Pixel Accuracy: 0.9888954162597656
2023-02-06 12:11:44 | Valid | Epoch[495/600] Mean Pixel Accuracy: 0.9530194273389467
2023-02-06 12:11:44 | Stage | Epoch[495/600] Train loss:0.0166
2023-02-06 12:11:44 | Stage | Epoch[495/600] Valid loss:0.0550
2023-02-06 12:11:44 | Stage | Epoch[495/600] LR:0.001

2023-02-06 12:11:44 | Train | Epoch[496/600] Iteration[001/030] Train loss: 0.0145
2023-02-06 12:11:44 | Train | Epoch[496/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:11:44 | Train | Epoch[496/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:11:44 | Train | Epoch[496/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:11:44 | Train | Epoch[496/600] Iteration[005/030] Train loss: 0.0168
2023-02-06 12:11:44 | Train | Epoch[496/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:11:45 | Train | Epoch[496/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:11:46 | Train | Epoch[496/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:11:46 | Train | Epoch[496/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:11:46 | Train | Epoch[496/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:11:46 | Train | Epoch[496/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:11:46 | Train | Epoch[496/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:11:46 | Train | Epoch[496/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:11:46 | Train | Epoch[496/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:11:46 | Train | Epoch[496/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:11:46 | Train | Epoch[496/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:11:46 | Train | Epoch[496/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:11:46 | Valid | Epoch[496/600] Iteration[001/008] Valid loss: 0.0627
2023-02-06 12:11:46 | Valid | Epoch[496/600] Iteration[002/008] Valid loss: 0.0479
2023-02-06 12:11:47 | Valid | Epoch[496/600] Iteration[003/008] Valid loss: 0.0487
2023-02-06 12:11:47 | Valid | Epoch[496/600] Iteration[004/008] Valid loss: 0.0439
2023-02-06 12:11:47 | Valid | Epoch[496/600] Iteration[005/008] Valid loss: 0.0424
2023-02-06 12:11:47 | Valid | Epoch[496/600] Iteration[006/008] Valid loss: 0.0404
2023-02-06 12:11:47 | Valid | Epoch[496/600] Iteration[007/008] Valid loss: 0.0413
2023-02-06 12:11:47 | Valid | Epoch[496/600] Iteration[008/008] Valid loss: 0.0403
2023-02-06 12:11:47 | Valid | Epoch[496/600] MIou: 0.9144901942475476
2023-02-06 12:11:47 | Valid | Epoch[496/600] Pixel Accuracy: 0.9857317606608073
2023-02-06 12:11:47 | Valid | Epoch[496/600] Mean Pixel Accuracy: 0.9280300382603146
2023-02-06 12:11:47 | Stage | Epoch[496/600] Train loss:0.0165
2023-02-06 12:11:47 | Stage | Epoch[496/600] Valid loss:0.0403
2023-02-06 12:11:47 | Stage | Epoch[496/600] LR:0.001

2023-02-06 12:11:47 | Train | Epoch[497/600] Iteration[001/030] Train loss: 0.0170
2023-02-06 12:11:47 | Train | Epoch[497/600] Iteration[002/030] Train loss: 0.0164
2023-02-06 12:11:47 | Train | Epoch[497/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:11:47 | Train | Epoch[497/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:11:47 | Train | Epoch[497/600] Iteration[005/030] Train loss: 0.0174
2023-02-06 12:11:47 | Train | Epoch[497/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:11:47 | Train | Epoch[497/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:11:48 | Train | Epoch[497/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:11:49 | Train | Epoch[497/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:11:49 | Train | Epoch[497/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:11:49 | Train | Epoch[497/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:11:49 | Train | Epoch[497/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:11:49 | Train | Epoch[497/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:11:49 | Train | Epoch[497/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:11:49 | Train | Epoch[497/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:11:49 | Train | Epoch[497/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:11:49 | Train | Epoch[497/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:11:49 | Train | Epoch[497/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:11:49 | Valid | Epoch[497/600] Iteration[001/008] Valid loss: 0.1174
2023-02-06 12:11:49 | Valid | Epoch[497/600] Iteration[002/008] Valid loss: 0.0820
2023-02-06 12:11:49 | Valid | Epoch[497/600] Iteration[003/008] Valid loss: 0.0809
2023-02-06 12:11:50 | Valid | Epoch[497/600] Iteration[004/008] Valid loss: 0.0735
2023-02-06 12:11:50 | Valid | Epoch[497/600] Iteration[005/008] Valid loss: 0.0703
2023-02-06 12:11:50 | Valid | Epoch[497/600] Iteration[006/008] Valid loss: 0.0657
2023-02-06 12:11:50 | Valid | Epoch[497/600] Iteration[007/008] Valid loss: 0.0698
2023-02-06 12:11:50 | Valid | Epoch[497/600] Iteration[008/008] Valid loss: 0.0670
2023-02-06 12:11:50 | Valid | Epoch[497/600] MIou: 0.9386892139432435
2023-02-06 12:11:50 | Valid | Epoch[497/600] Pixel Accuracy: 0.9895235697428385
2023-02-06 12:11:50 | Valid | Epoch[497/600] Mean Pixel Accuracy: 0.9614741503472918
2023-02-06 12:11:50 | Stage | Epoch[497/600] Train loss:0.0166
2023-02-06 12:11:50 | Stage | Epoch[497/600] Valid loss:0.0670
2023-02-06 12:11:50 | Stage | Epoch[497/600] LR:0.001

2023-02-06 12:11:50 | Train | Epoch[498/600] Iteration[001/030] Train loss: 0.0137
2023-02-06 12:11:50 | Train | Epoch[498/600] Iteration[002/030] Train loss: 0.0145
2023-02-06 12:11:50 | Train | Epoch[498/600] Iteration[003/030] Train loss: 0.0153
2023-02-06 12:11:50 | Train | Epoch[498/600] Iteration[004/030] Train loss: 0.0155
2023-02-06 12:11:50 | Train | Epoch[498/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:11:50 | Train | Epoch[498/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:11:50 | Train | Epoch[498/600] Iteration[007/030] Train loss: 0.0158
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[008/030] Train loss: 0.0159
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:11:51 | Train | Epoch[498/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:11:52 | Train | Epoch[498/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:11:52 | Train | Epoch[498/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:11:52 | Train | Epoch[498/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:11:52 | Train | Epoch[498/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:11:52 | Train | Epoch[498/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:11:52 | Train | Epoch[498/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:11:52 | Train | Epoch[498/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:11:52 | Train | Epoch[498/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:11:52 | Train | Epoch[498/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:11:52 | Valid | Epoch[498/600] Iteration[001/008] Valid loss: 0.1204
2023-02-06 12:11:52 | Valid | Epoch[498/600] Iteration[002/008] Valid loss: 0.0854
2023-02-06 12:11:52 | Valid | Epoch[498/600] Iteration[003/008] Valid loss: 0.0847
2023-02-06 12:11:52 | Valid | Epoch[498/600] Iteration[004/008] Valid loss: 0.0772
2023-02-06 12:11:52 | Valid | Epoch[498/600] Iteration[005/008] Valid loss: 0.0743
2023-02-06 12:11:53 | Valid | Epoch[498/600] Iteration[006/008] Valid loss: 0.0695
2023-02-06 12:11:53 | Valid | Epoch[498/600] Iteration[007/008] Valid loss: 0.0741
2023-02-06 12:11:53 | Valid | Epoch[498/600] Iteration[008/008] Valid loss: 0.0708
2023-02-06 12:11:53 | Valid | Epoch[498/600] MIou: 0.9392955464612118
2023-02-06 12:11:53 | Valid | Epoch[498/600] Pixel Accuracy: 0.9896125793457031
2023-02-06 12:11:53 | Valid | Epoch[498/600] Mean Pixel Accuracy: 0.9627087419939528
2023-02-06 12:11:53 | Stage | Epoch[498/600] Train loss:0.0164
2023-02-06 12:11:53 | Stage | Epoch[498/600] Valid loss:0.0708
2023-02-06 12:11:53 | Stage | Epoch[498/600] LR:0.001

2023-02-06 12:11:53 | Train | Epoch[499/600] Iteration[001/030] Train loss: 0.0150
2023-02-06 12:11:53 | Train | Epoch[499/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:11:53 | Train | Epoch[499/600] Iteration[003/030] Train loss: 0.0177
2023-02-06 12:11:53 | Train | Epoch[499/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:11:53 | Train | Epoch[499/600] Iteration[005/030] Train loss: 0.0172
2023-02-06 12:11:53 | Train | Epoch[499/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:11:53 | Train | Epoch[499/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:11:53 | Train | Epoch[499/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:11:54 | Train | Epoch[499/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:11:55 | Train | Epoch[499/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:11:55 | Train | Epoch[499/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:11:55 | Train | Epoch[499/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:11:55 | Train | Epoch[499/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:11:55 | Train | Epoch[499/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:11:55 | Train | Epoch[499/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:11:55 | Train | Epoch[499/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:11:55 | Train | Epoch[499/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:11:55 | Train | Epoch[499/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:11:55 | Valid | Epoch[499/600] Iteration[001/008] Valid loss: 0.0767
2023-02-06 12:11:55 | Valid | Epoch[499/600] Iteration[002/008] Valid loss: 0.0556
2023-02-06 12:11:55 | Valid | Epoch[499/600] Iteration[003/008] Valid loss: 0.0558
2023-02-06 12:11:55 | Valid | Epoch[499/600] Iteration[004/008] Valid loss: 0.0500
2023-02-06 12:11:55 | Valid | Epoch[499/600] Iteration[005/008] Valid loss: 0.0477
2023-02-06 12:11:56 | Valid | Epoch[499/600] Iteration[006/008] Valid loss: 0.0449
2023-02-06 12:11:56 | Valid | Epoch[499/600] Iteration[007/008] Valid loss: 0.0465
2023-02-06 12:11:56 | Valid | Epoch[499/600] Iteration[008/008] Valid loss: 0.0450
2023-02-06 12:11:56 | Valid | Epoch[499/600] MIou: 0.9270413002989912
2023-02-06 12:11:56 | Valid | Epoch[499/600] Pixel Accuracy: 0.987738291422526
2023-02-06 12:11:56 | Valid | Epoch[499/600] Mean Pixel Accuracy: 0.9429044172676598
2023-02-06 12:11:56 | Stage | Epoch[499/600] Train loss:0.0166
2023-02-06 12:11:56 | Stage | Epoch[499/600] Valid loss:0.0450
2023-02-06 12:11:56 | Stage | Epoch[499/600] LR:0.001

2023-02-06 12:11:56 | Train | Epoch[500/600] Iteration[001/030] Train loss: 0.0163
2023-02-06 12:11:56 | Train | Epoch[500/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:11:56 | Train | Epoch[500/600] Iteration[003/030] Train loss: 0.0163
2023-02-06 12:11:56 | Train | Epoch[500/600] Iteration[004/030] Train loss: 0.0156
2023-02-06 12:11:56 | Train | Epoch[500/600] Iteration[005/030] Train loss: 0.0158
2023-02-06 12:11:56 | Train | Epoch[500/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:11:56 | Train | Epoch[500/600] Iteration[007/030] Train loss: 0.0157
2023-02-06 12:11:56 | Train | Epoch[500/600] Iteration[008/030] Train loss: 0.0158
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[014/030] Train loss: 0.0158
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[015/030] Train loss: 0.0157
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[016/030] Train loss: 0.0158
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[019/030] Train loss: 0.0161
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:11:57 | Train | Epoch[500/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:11:58 | Train | Epoch[500/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:11:58 | Train | Epoch[500/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:11:58 | Train | Epoch[500/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:11:58 | Train | Epoch[500/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:11:58 | Train | Epoch[500/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:11:58 | Train | Epoch[500/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:11:58 | Train | Epoch[500/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:11:58 | Train | Epoch[500/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:11:58 | Valid | Epoch[500/600] Iteration[001/008] Valid loss: 0.0643
2023-02-06 12:11:58 | Valid | Epoch[500/600] Iteration[002/008] Valid loss: 0.0483
2023-02-06 12:11:58 | Valid | Epoch[500/600] Iteration[003/008] Valid loss: 0.0499
2023-02-06 12:11:58 | Valid | Epoch[500/600] Iteration[004/008] Valid loss: 0.0447
2023-02-06 12:11:58 | Valid | Epoch[500/600] Iteration[005/008] Valid loss: 0.0429
2023-02-06 12:11:58 | Valid | Epoch[500/600] Iteration[006/008] Valid loss: 0.0407
2023-02-06 12:11:58 | Valid | Epoch[500/600] Iteration[007/008] Valid loss: 0.0416
2023-02-06 12:11:58 | Valid | Epoch[500/600] Iteration[008/008] Valid loss: 0.0405
2023-02-06 12:11:59 | Valid | Epoch[500/600] MIou: 0.9159689066435528
2023-02-06 12:11:59 | Valid | Epoch[500/600] Pixel Accuracy: 0.9859797159830729
2023-02-06 12:11:59 | Valid | Epoch[500/600] Mean Pixel Accuracy: 0.9293710146677657
2023-02-06 12:11:59 | Stage | Epoch[500/600] Train loss:0.0165
2023-02-06 12:11:59 | Stage | Epoch[500/600] Valid loss:0.0405
2023-02-06 12:11:59 | Stage | Epoch[500/600] LR:0.001

2023-02-06 12:11:59 | Train | Epoch[501/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 12:11:59 | Train | Epoch[501/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 12:11:59 | Train | Epoch[501/600] Iteration[003/030] Train loss: 0.0173
2023-02-06 12:11:59 | Train | Epoch[501/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 12:11:59 | Train | Epoch[501/600] Iteration[005/030] Train loss: 0.0172
2023-02-06 12:11:59 | Train | Epoch[501/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 12:11:59 | Train | Epoch[501/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:11:59 | Train | Epoch[501/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:11:59 | Train | Epoch[501/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:11:59 | Train | Epoch[501/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:12:00 | Train | Epoch[501/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:12:01 | Train | Epoch[501/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:12:01 | Train | Epoch[501/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:12:01 | Train | Epoch[501/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:12:01 | Train | Epoch[501/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:12:01 | Train | Epoch[501/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:12:01 | Train | Epoch[501/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:12:01 | Train | Epoch[501/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:12:01 | Valid | Epoch[501/600] Iteration[001/008] Valid loss: 0.0832
2023-02-06 12:12:01 | Valid | Epoch[501/600] Iteration[002/008] Valid loss: 0.0594
2023-02-06 12:12:01 | Valid | Epoch[501/600] Iteration[003/008] Valid loss: 0.0609
2023-02-06 12:12:01 | Valid | Epoch[501/600] Iteration[004/008] Valid loss: 0.0544
2023-02-06 12:12:01 | Valid | Epoch[501/600] Iteration[005/008] Valid loss: 0.0516
2023-02-06 12:12:01 | Valid | Epoch[501/600] Iteration[006/008] Valid loss: 0.0484
2023-02-06 12:12:01 | Valid | Epoch[501/600] Iteration[007/008] Valid loss: 0.0501
2023-02-06 12:12:01 | Valid | Epoch[501/600] Iteration[008/008] Valid loss: 0.0483
2023-02-06 12:12:02 | Valid | Epoch[501/600] MIou: 0.9296185743527159
2023-02-06 12:12:02 | Valid | Epoch[501/600] Pixel Accuracy: 0.9881502787272135
2023-02-06 12:12:02 | Valid | Epoch[501/600] Mean Pixel Accuracy: 0.9461235656148512
2023-02-06 12:12:02 | Stage | Epoch[501/600] Train loss:0.0167
2023-02-06 12:12:02 | Stage | Epoch[501/600] Valid loss:0.0483
2023-02-06 12:12:02 | Stage | Epoch[501/600] LR:0.0001

2023-02-06 12:12:02 | Train | Epoch[502/600] Iteration[001/030] Train loss: 0.0136
2023-02-06 12:12:02 | Train | Epoch[502/600] Iteration[002/030] Train loss: 0.0143
2023-02-06 12:12:02 | Train | Epoch[502/600] Iteration[003/030] Train loss: 0.0147
2023-02-06 12:12:02 | Train | Epoch[502/600] Iteration[004/030] Train loss: 0.0152
2023-02-06 12:12:02 | Train | Epoch[502/600] Iteration[005/030] Train loss: 0.0154
2023-02-06 12:12:02 | Train | Epoch[502/600] Iteration[006/030] Train loss: 0.0154
2023-02-06 12:12:02 | Train | Epoch[502/600] Iteration[007/030] Train loss: 0.0158
2023-02-06 12:12:02 | Train | Epoch[502/600] Iteration[008/030] Train loss: 0.0159
2023-02-06 12:12:02 | Train | Epoch[502/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:12:02 | Train | Epoch[502/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:12:03 | Train | Epoch[502/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:12:04 | Train | Epoch[502/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:12:04 | Train | Epoch[502/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:12:04 | Train | Epoch[502/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:12:04 | Train | Epoch[502/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:12:04 | Train | Epoch[502/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:12:04 | Train | Epoch[502/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:12:04 | Train | Epoch[502/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:12:04 | Valid | Epoch[502/600] Iteration[001/008] Valid loss: 0.0759
2023-02-06 12:12:04 | Valid | Epoch[502/600] Iteration[002/008] Valid loss: 0.0549
2023-02-06 12:12:04 | Valid | Epoch[502/600] Iteration[003/008] Valid loss: 0.0559
2023-02-06 12:12:04 | Valid | Epoch[502/600] Iteration[004/008] Valid loss: 0.0496
2023-02-06 12:12:04 | Valid | Epoch[502/600] Iteration[005/008] Valid loss: 0.0471
2023-02-06 12:12:04 | Valid | Epoch[502/600] Iteration[006/008] Valid loss: 0.0443
2023-02-06 12:12:04 | Valid | Epoch[502/600] Iteration[007/008] Valid loss: 0.0456
2023-02-06 12:12:04 | Valid | Epoch[502/600] Iteration[008/008] Valid loss: 0.0441
2023-02-06 12:12:05 | Valid | Epoch[502/600] MIou: 0.9247978885518358
2023-02-06 12:12:05 | Valid | Epoch[502/600] Pixel Accuracy: 0.9873911539713541
2023-02-06 12:12:05 | Valid | Epoch[502/600] Mean Pixel Accuracy: 0.9397526155233002
2023-02-06 12:12:05 | Stage | Epoch[502/600] Train loss:0.0165
2023-02-06 12:12:05 | Stage | Epoch[502/600] Valid loss:0.0441
2023-02-06 12:12:05 | Stage | Epoch[502/600] LR:0.0001

2023-02-06 12:12:05 | Train | Epoch[503/600] Iteration[001/030] Train loss: 0.0161
2023-02-06 12:12:05 | Train | Epoch[503/600] Iteration[002/030] Train loss: 0.0162
2023-02-06 12:12:05 | Train | Epoch[503/600] Iteration[003/030] Train loss: 0.0157
2023-02-06 12:12:05 | Train | Epoch[503/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:12:05 | Train | Epoch[503/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:12:05 | Train | Epoch[503/600] Iteration[006/030] Train loss: 0.0157
2023-02-06 12:12:05 | Train | Epoch[503/600] Iteration[007/030] Train loss: 0.0157
2023-02-06 12:12:05 | Train | Epoch[503/600] Iteration[008/030] Train loss: 0.0154
2023-02-06 12:12:05 | Train | Epoch[503/600] Iteration[009/030] Train loss: 0.0157
2023-02-06 12:12:05 | Train | Epoch[503/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[014/030] Train loss: 0.0159
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[015/030] Train loss: 0.0159
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[016/030] Train loss: 0.0157
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[017/030] Train loss: 0.0157
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[018/030] Train loss: 0.0159
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[019/030] Train loss: 0.0159
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[020/030] Train loss: 0.0159
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[021/030] Train loss: 0.0160
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[022/030] Train loss: 0.0161
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[023/030] Train loss: 0.0161
2023-02-06 12:12:06 | Train | Epoch[503/600] Iteration[024/030] Train loss: 0.0161
2023-02-06 12:12:07 | Train | Epoch[503/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:12:07 | Train | Epoch[503/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:12:07 | Train | Epoch[503/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:12:07 | Train | Epoch[503/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:12:07 | Train | Epoch[503/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:12:07 | Train | Epoch[503/600] Iteration[030/030] Train loss: 0.0162
2023-02-06 12:12:07 | Valid | Epoch[503/600] Iteration[001/008] Valid loss: 0.0811
2023-02-06 12:12:07 | Valid | Epoch[503/600] Iteration[002/008] Valid loss: 0.0581
2023-02-06 12:12:07 | Valid | Epoch[503/600] Iteration[003/008] Valid loss: 0.0595
2023-02-06 12:12:07 | Valid | Epoch[503/600] Iteration[004/008] Valid loss: 0.0530
2023-02-06 12:12:07 | Valid | Epoch[503/600] Iteration[005/008] Valid loss: 0.0503
2023-02-06 12:12:07 | Valid | Epoch[503/600] Iteration[006/008] Valid loss: 0.0472
2023-02-06 12:12:07 | Valid | Epoch[503/600] Iteration[007/008] Valid loss: 0.0487
2023-02-06 12:12:07 | Valid | Epoch[503/600] Iteration[008/008] Valid loss: 0.0469
2023-02-06 12:12:07 | Valid | Epoch[503/600] MIou: 0.9283876121867535
2023-02-06 12:12:07 | Valid | Epoch[503/600] Pixel Accuracy: 0.9879582722981771
2023-02-06 12:12:07 | Valid | Epoch[503/600] Mean Pixel Accuracy: 0.9444012104569963
2023-02-06 12:12:07 | Stage | Epoch[503/600] Train loss:0.0162
2023-02-06 12:12:07 | Stage | Epoch[503/600] Valid loss:0.0469
2023-02-06 12:12:07 | Stage | Epoch[503/600] LR:0.0001

2023-02-06 12:12:08 | Train | Epoch[504/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 12:12:08 | Train | Epoch[504/600] Iteration[002/030] Train loss: 0.0169
2023-02-06 12:12:08 | Train | Epoch[504/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:12:08 | Train | Epoch[504/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 12:12:08 | Train | Epoch[504/600] Iteration[005/030] Train loss: 0.0168
2023-02-06 12:12:08 | Train | Epoch[504/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:12:08 | Train | Epoch[504/600] Iteration[007/030] Train loss: 0.0169
2023-02-06 12:12:08 | Train | Epoch[504/600] Iteration[008/030] Train loss: 0.0174
2023-02-06 12:12:08 | Train | Epoch[504/600] Iteration[009/030] Train loss: 0.0175
2023-02-06 12:12:08 | Train | Epoch[504/600] Iteration[010/030] Train loss: 0.0175
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[011/030] Train loss: 0.0174
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:12:09 | Train | Epoch[504/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:12:10 | Train | Epoch[504/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:12:10 | Train | Epoch[504/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:12:10 | Train | Epoch[504/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:12:10 | Train | Epoch[504/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:12:10 | Train | Epoch[504/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:12:10 | Train | Epoch[504/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:12:10 | Valid | Epoch[504/600] Iteration[001/008] Valid loss: 0.0828
2023-02-06 12:12:10 | Valid | Epoch[504/600] Iteration[002/008] Valid loss: 0.0591
2023-02-06 12:12:10 | Valid | Epoch[504/600] Iteration[003/008] Valid loss: 0.0606
2023-02-06 12:12:10 | Valid | Epoch[504/600] Iteration[004/008] Valid loss: 0.0539
2023-02-06 12:12:10 | Valid | Epoch[504/600] Iteration[005/008] Valid loss: 0.0512
2023-02-06 12:12:10 | Valid | Epoch[504/600] Iteration[006/008] Valid loss: 0.0480
2023-02-06 12:12:10 | Valid | Epoch[504/600] Iteration[007/008] Valid loss: 0.0496
2023-02-06 12:12:10 | Valid | Epoch[504/600] Iteration[008/008] Valid loss: 0.0478
2023-02-06 12:12:11 | Valid | Epoch[504/600] MIou: 0.9293414739600815
2023-02-06 12:12:11 | Valid | Epoch[504/600] Pixel Accuracy: 0.9881057739257812
2023-02-06 12:12:11 | Valid | Epoch[504/600] Mean Pixel Accuracy: 0.9457820803022963
2023-02-06 12:12:11 | Stage | Epoch[504/600] Train loss:0.0165
2023-02-06 12:12:11 | Stage | Epoch[504/600] Valid loss:0.0478
2023-02-06 12:12:11 | Stage | Epoch[504/600] LR:0.0001

2023-02-06 12:12:11 | Train | Epoch[505/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 12:12:11 | Train | Epoch[505/600] Iteration[002/030] Train loss: 0.0164
2023-02-06 12:12:11 | Train | Epoch[505/600] Iteration[003/030] Train loss: 0.0156
2023-02-06 12:12:11 | Train | Epoch[505/600] Iteration[004/030] Train loss: 0.0158
2023-02-06 12:12:11 | Train | Epoch[505/600] Iteration[005/030] Train loss: 0.0160
2023-02-06 12:12:11 | Train | Epoch[505/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:12:11 | Train | Epoch[505/600] Iteration[007/030] Train loss: 0.0161
2023-02-06 12:12:11 | Train | Epoch[505/600] Iteration[008/030] Train loss: 0.0160
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[009/030] Train loss: 0.0160
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[012/030] Train loss: 0.0158
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[015/030] Train loss: 0.0160
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[017/030] Train loss: 0.0161
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[018/030] Train loss: 0.0159
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[019/030] Train loss: 0.0159
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[020/030] Train loss: 0.0159
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[021/030] Train loss: 0.0159
2023-02-06 12:12:12 | Train | Epoch[505/600] Iteration[022/030] Train loss: 0.0161
2023-02-06 12:12:13 | Train | Epoch[505/600] Iteration[023/030] Train loss: 0.0160
2023-02-06 12:12:13 | Train | Epoch[505/600] Iteration[024/030] Train loss: 0.0161
2023-02-06 12:12:13 | Train | Epoch[505/600] Iteration[025/030] Train loss: 0.0161
2023-02-06 12:12:13 | Train | Epoch[505/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:12:13 | Train | Epoch[505/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:12:13 | Train | Epoch[505/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:12:13 | Train | Epoch[505/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 12:12:13 | Train | Epoch[505/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:12:13 | Valid | Epoch[505/600] Iteration[001/008] Valid loss: 0.0796
2023-02-06 12:12:13 | Valid | Epoch[505/600] Iteration[002/008] Valid loss: 0.0571
2023-02-06 12:12:13 | Valid | Epoch[505/600] Iteration[003/008] Valid loss: 0.0588
2023-02-06 12:12:13 | Valid | Epoch[505/600] Iteration[004/008] Valid loss: 0.0525
2023-02-06 12:12:13 | Valid | Epoch[505/600] Iteration[005/008] Valid loss: 0.0498
2023-02-06 12:12:14 | Valid | Epoch[505/600] Iteration[006/008] Valid loss: 0.0468
2023-02-06 12:12:14 | Valid | Epoch[505/600] Iteration[007/008] Valid loss: 0.0484
2023-02-06 12:12:14 | Valid | Epoch[505/600] Iteration[008/008] Valid loss: 0.0466
2023-02-06 12:12:14 | Valid | Epoch[505/600] MIou: 0.9271787711504229
2023-02-06 12:12:14 | Valid | Epoch[505/600] Pixel Accuracy: 0.9877599080403646
2023-02-06 12:12:14 | Valid | Epoch[505/600] Mean Pixel Accuracy: 0.9430874914135765
2023-02-06 12:12:14 | Stage | Epoch[505/600] Train loss:0.0164
2023-02-06 12:12:14 | Stage | Epoch[505/600] Valid loss:0.0466
2023-02-06 12:12:14 | Stage | Epoch[505/600] LR:0.0001

2023-02-06 12:12:14 | Train | Epoch[506/600] Iteration[001/030] Train loss: 0.0127
2023-02-06 12:12:14 | Train | Epoch[506/600] Iteration[002/030] Train loss: 0.0136
2023-02-06 12:12:14 | Train | Epoch[506/600] Iteration[003/030] Train loss: 0.0150
2023-02-06 12:12:14 | Train | Epoch[506/600] Iteration[004/030] Train loss: 0.0154
2023-02-06 12:12:14 | Train | Epoch[506/600] Iteration[005/030] Train loss: 0.0152
2023-02-06 12:12:14 | Train | Epoch[506/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:12:14 | Train | Epoch[506/600] Iteration[007/030] Train loss: 0.0159
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[008/030] Train loss: 0.0157
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:12:15 | Train | Epoch[506/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:12:16 | Train | Epoch[506/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:12:16 | Train | Epoch[506/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:12:16 | Train | Epoch[506/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:12:16 | Train | Epoch[506/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:12:16 | Train | Epoch[506/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:12:16 | Train | Epoch[506/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:12:16 | Train | Epoch[506/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:12:16 | Train | Epoch[506/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:12:16 | Train | Epoch[506/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:12:16 | Train | Epoch[506/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:12:16 | Valid | Epoch[506/600] Iteration[001/008] Valid loss: 0.0783
2023-02-06 12:12:17 | Valid | Epoch[506/600] Iteration[002/008] Valid loss: 0.0564
2023-02-06 12:12:17 | Valid | Epoch[506/600] Iteration[003/008] Valid loss: 0.0580
2023-02-06 12:12:17 | Valid | Epoch[506/600] Iteration[004/008] Valid loss: 0.0516
2023-02-06 12:12:17 | Valid | Epoch[506/600] Iteration[005/008] Valid loss: 0.0491
2023-02-06 12:12:17 | Valid | Epoch[506/600] Iteration[006/008] Valid loss: 0.0461
2023-02-06 12:12:17 | Valid | Epoch[506/600] Iteration[007/008] Valid loss: 0.0475
2023-02-06 12:12:17 | Valid | Epoch[506/600] Iteration[008/008] Valid loss: 0.0458
2023-02-06 12:12:17 | Valid | Epoch[506/600] MIou: 0.9259712578654324
2023-02-06 12:12:17 | Valid | Epoch[506/600] Pixel Accuracy: 0.9875691731770834
2023-02-06 12:12:17 | Valid | Epoch[506/600] Mean Pixel Accuracy: 0.9415180064787815
2023-02-06 12:12:17 | Stage | Epoch[506/600] Train loss:0.0164
2023-02-06 12:12:17 | Stage | Epoch[506/600] Valid loss:0.0458
2023-02-06 12:12:17 | Stage | Epoch[506/600] LR:0.0001

2023-02-06 12:12:17 | Train | Epoch[507/600] Iteration[001/030] Train loss: 0.0145
2023-02-06 12:12:17 | Train | Epoch[507/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 12:12:17 | Train | Epoch[507/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:12:17 | Train | Epoch[507/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:12:17 | Train | Epoch[507/600] Iteration[005/030] Train loss: 0.0168
2023-02-06 12:12:17 | Train | Epoch[507/600] Iteration[006/030] Train loss: 0.0171
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:12:18 | Train | Epoch[507/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:12:19 | Train | Epoch[507/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:12:19 | Train | Epoch[507/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:12:19 | Train | Epoch[507/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:12:19 | Train | Epoch[507/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:12:19 | Train | Epoch[507/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:12:19 | Train | Epoch[507/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:12:19 | Train | Epoch[507/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:12:19 | Train | Epoch[507/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:12:19 | Train | Epoch[507/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:12:19 | Train | Epoch[507/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:12:20 | Valid | Epoch[507/600] Iteration[001/008] Valid loss: 0.0796
2023-02-06 12:12:20 | Valid | Epoch[507/600] Iteration[002/008] Valid loss: 0.0569
2023-02-06 12:12:20 | Valid | Epoch[507/600] Iteration[003/008] Valid loss: 0.0577
2023-02-06 12:12:20 | Valid | Epoch[507/600] Iteration[004/008] Valid loss: 0.0516
2023-02-06 12:12:20 | Valid | Epoch[507/600] Iteration[005/008] Valid loss: 0.0490
2023-02-06 12:12:20 | Valid | Epoch[507/600] Iteration[006/008] Valid loss: 0.0461
2023-02-06 12:12:20 | Valid | Epoch[507/600] Iteration[007/008] Valid loss: 0.0477
2023-02-06 12:12:20 | Valid | Epoch[507/600] Iteration[008/008] Valid loss: 0.0460
2023-02-06 12:12:20 | Valid | Epoch[507/600] MIou: 0.9273827799667376
2023-02-06 12:12:20 | Valid | Epoch[507/600] Pixel Accuracy: 0.9877942403157552
2023-02-06 12:12:20 | Valid | Epoch[507/600] Mean Pixel Accuracy: 0.9432775546271934
2023-02-06 12:12:20 | Stage | Epoch[507/600] Train loss:0.0166
2023-02-06 12:12:20 | Stage | Epoch[507/600] Valid loss:0.0460
2023-02-06 12:12:20 | Stage | Epoch[507/600] LR:0.0001

2023-02-06 12:12:20 | Train | Epoch[508/600] Iteration[001/030] Train loss: 0.0144
2023-02-06 12:12:20 | Train | Epoch[508/600] Iteration[002/030] Train loss: 0.0149
2023-02-06 12:12:20 | Train | Epoch[508/600] Iteration[003/030] Train loss: 0.0153
2023-02-06 12:12:20 | Train | Epoch[508/600] Iteration[004/030] Train loss: 0.0158
2023-02-06 12:12:20 | Train | Epoch[508/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[008/030] Train loss: 0.0160
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:12:21 | Train | Epoch[508/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:12:22 | Train | Epoch[508/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:12:23 | Valid | Epoch[508/600] Iteration[001/008] Valid loss: 0.0864
2023-02-06 12:12:23 | Valid | Epoch[508/600] Iteration[002/008] Valid loss: 0.0615
2023-02-06 12:12:23 | Valid | Epoch[508/600] Iteration[003/008] Valid loss: 0.0628
2023-02-06 12:12:23 | Valid | Epoch[508/600] Iteration[004/008] Valid loss: 0.0564
2023-02-06 12:12:23 | Valid | Epoch[508/600] Iteration[005/008] Valid loss: 0.0536
2023-02-06 12:12:23 | Valid | Epoch[508/600] Iteration[006/008] Valid loss: 0.0504
2023-02-06 12:12:23 | Valid | Epoch[508/600] Iteration[007/008] Valid loss: 0.0525
2023-02-06 12:12:23 | Valid | Epoch[508/600] Iteration[008/008] Valid loss: 0.0505
2023-02-06 12:12:23 | Valid | Epoch[508/600] MIou: 0.9308406355406713
2023-02-06 12:12:23 | Valid | Epoch[508/600] Pixel Accuracy: 0.9883321126302084
2023-02-06 12:12:23 | Valid | Epoch[508/600] Mean Pixel Accuracy: 0.9481953959232226
2023-02-06 12:12:23 | Stage | Epoch[508/600] Train loss:0.0166
2023-02-06 12:12:23 | Stage | Epoch[508/600] Valid loss:0.0505
2023-02-06 12:12:23 | Stage | Epoch[508/600] LR:0.0001

2023-02-06 12:12:23 | Train | Epoch[509/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 12:12:23 | Train | Epoch[509/600] Iteration[002/030] Train loss: 0.0180
2023-02-06 12:12:23 | Train | Epoch[509/600] Iteration[003/030] Train loss: 0.0181
2023-02-06 12:12:23 | Train | Epoch[509/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 12:12:23 | Train | Epoch[509/600] Iteration[005/030] Train loss: 0.0178
2023-02-06 12:12:23 | Train | Epoch[509/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[007/030] Train loss: 0.0174
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[008/030] Train loss: 0.0173
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[009/030] Train loss: 0.0174
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[010/030] Train loss: 0.0175
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:12:24 | Train | Epoch[509/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:12:25 | Train | Epoch[509/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:12:25 | Train | Epoch[509/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:12:25 | Train | Epoch[509/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:12:25 | Train | Epoch[509/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:12:25 | Train | Epoch[509/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:12:25 | Train | Epoch[509/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:12:25 | Train | Epoch[509/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:12:25 | Train | Epoch[509/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:12:25 | Train | Epoch[509/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:12:25 | Train | Epoch[509/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:12:26 | Valid | Epoch[509/600] Iteration[001/008] Valid loss: 0.0827
2023-02-06 12:12:26 | Valid | Epoch[509/600] Iteration[002/008] Valid loss: 0.0589
2023-02-06 12:12:26 | Valid | Epoch[509/600] Iteration[003/008] Valid loss: 0.0602
2023-02-06 12:12:26 | Valid | Epoch[509/600] Iteration[004/008] Valid loss: 0.0537
2023-02-06 12:12:26 | Valid | Epoch[509/600] Iteration[005/008] Valid loss: 0.0510
2023-02-06 12:12:26 | Valid | Epoch[509/600] Iteration[006/008] Valid loss: 0.0478
2023-02-06 12:12:26 | Valid | Epoch[509/600] Iteration[007/008] Valid loss: 0.0495
2023-02-06 12:12:26 | Valid | Epoch[509/600] Iteration[008/008] Valid loss: 0.0477
2023-02-06 12:12:26 | Valid | Epoch[509/600] MIou: 0.9292309210616612
2023-02-06 12:12:26 | Valid | Epoch[509/600] Pixel Accuracy: 0.9880867004394531
2023-02-06 12:12:26 | Valid | Epoch[509/600] Mean Pixel Accuracy: 0.9456955110426009
2023-02-06 12:12:26 | Stage | Epoch[509/600] Train loss:0.0164
2023-02-06 12:12:26 | Stage | Epoch[509/600] Valid loss:0.0477
2023-02-06 12:12:26 | Stage | Epoch[509/600] LR:0.0001

2023-02-06 12:12:26 | Train | Epoch[510/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 12:12:26 | Train | Epoch[510/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 12:12:26 | Train | Epoch[510/600] Iteration[003/030] Train loss: 0.0177
2023-02-06 12:12:26 | Train | Epoch[510/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:12:26 | Train | Epoch[510/600] Iteration[005/030] Train loss: 0.0174
2023-02-06 12:12:26 | Train | Epoch[510/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[008/030] Train loss: 0.0174
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[011/030] Train loss: 0.0174
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[012/030] Train loss: 0.0175
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[013/030] Train loss: 0.0173
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[014/030] Train loss: 0.0170
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[015/030] Train loss: 0.0170
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[017/030] Train loss: 0.0170
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[019/030] Train loss: 0.0170
2023-02-06 12:12:27 | Train | Epoch[510/600] Iteration[020/030] Train loss: 0.0169
2023-02-06 12:12:28 | Train | Epoch[510/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:12:28 | Train | Epoch[510/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:12:28 | Train | Epoch[510/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:12:28 | Train | Epoch[510/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:12:28 | Train | Epoch[510/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:12:28 | Train | Epoch[510/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:12:28 | Train | Epoch[510/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:12:28 | Train | Epoch[510/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:12:28 | Train | Epoch[510/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:12:28 | Train | Epoch[510/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:12:29 | Valid | Epoch[510/600] Iteration[001/008] Valid loss: 0.0771
2023-02-06 12:12:29 | Valid | Epoch[510/600] Iteration[002/008] Valid loss: 0.0559
2023-02-06 12:12:29 | Valid | Epoch[510/600] Iteration[003/008] Valid loss: 0.0578
2023-02-06 12:12:29 | Valid | Epoch[510/600] Iteration[004/008] Valid loss: 0.0515
2023-02-06 12:12:29 | Valid | Epoch[510/600] Iteration[005/008] Valid loss: 0.0489
2023-02-06 12:12:29 | Valid | Epoch[510/600] Iteration[006/008] Valid loss: 0.0460
2023-02-06 12:12:29 | Valid | Epoch[510/600] Iteration[007/008] Valid loss: 0.0473
2023-02-06 12:12:29 | Valid | Epoch[510/600] Iteration[008/008] Valid loss: 0.0456
2023-02-06 12:12:29 | Valid | Epoch[510/600] MIou: 0.9257654252604723
2023-02-06 12:12:29 | Valid | Epoch[510/600] Pixel Accuracy: 0.9875361124674479
2023-02-06 12:12:29 | Valid | Epoch[510/600] Mean Pixel Accuracy: 0.9412715779283258
2023-02-06 12:12:29 | Stage | Epoch[510/600] Train loss:0.0166
2023-02-06 12:12:29 | Stage | Epoch[510/600] Valid loss:0.0456
2023-02-06 12:12:29 | Stage | Epoch[510/600] LR:0.0001

2023-02-06 12:12:29 | Train | Epoch[511/600] Iteration[001/030] Train loss: 0.0160
2023-02-06 12:12:29 | Train | Epoch[511/600] Iteration[002/030] Train loss: 0.0154
2023-02-06 12:12:29 | Train | Epoch[511/600] Iteration[003/030] Train loss: 0.0154
2023-02-06 12:12:29 | Train | Epoch[511/600] Iteration[004/030] Train loss: 0.0161
2023-02-06 12:12:29 | Train | Epoch[511/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:12:30 | Train | Epoch[511/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:12:31 | Train | Epoch[511/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:12:32 | Valid | Epoch[511/600] Iteration[001/008] Valid loss: 0.0768
2023-02-06 12:12:32 | Valid | Epoch[511/600] Iteration[002/008] Valid loss: 0.0552
2023-02-06 12:12:32 | Valid | Epoch[511/600] Iteration[003/008] Valid loss: 0.0562
2023-02-06 12:12:32 | Valid | Epoch[511/600] Iteration[004/008] Valid loss: 0.0501
2023-02-06 12:12:32 | Valid | Epoch[511/600] Iteration[005/008] Valid loss: 0.0476
2023-02-06 12:12:32 | Valid | Epoch[511/600] Iteration[006/008] Valid loss: 0.0448
2023-02-06 12:12:32 | Valid | Epoch[511/600] Iteration[007/008] Valid loss: 0.0462
2023-02-06 12:12:32 | Valid | Epoch[511/600] Iteration[008/008] Valid loss: 0.0446
2023-02-06 12:12:32 | Valid | Epoch[511/600] MIou: 0.9251970400550897
2023-02-06 12:12:32 | Valid | Epoch[511/600] Pixel Accuracy: 0.9874471028645834
2023-02-06 12:12:32 | Valid | Epoch[511/600] Mean Pixel Accuracy: 0.9405125216450707
2023-02-06 12:12:32 | Stage | Epoch[511/600] Train loss:0.0164
2023-02-06 12:12:32 | Stage | Epoch[511/600] Valid loss:0.0446
2023-02-06 12:12:32 | Stage | Epoch[511/600] LR:0.0001

2023-02-06 12:12:32 | Train | Epoch[512/600] Iteration[001/030] Train loss: 0.0142
2023-02-06 12:12:32 | Train | Epoch[512/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:12:32 | Train | Epoch[512/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:12:32 | Train | Epoch[512/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[006/030] Train loss: 0.0177
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[009/030] Train loss: 0.0170
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[010/030] Train loss: 0.0171
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:12:33 | Train | Epoch[512/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:12:34 | Train | Epoch[512/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:12:35 | Valid | Epoch[512/600] Iteration[001/008] Valid loss: 0.0789
2023-02-06 12:12:35 | Valid | Epoch[512/600] Iteration[002/008] Valid loss: 0.0567
2023-02-06 12:12:35 | Valid | Epoch[512/600] Iteration[003/008] Valid loss: 0.0582
2023-02-06 12:12:35 | Valid | Epoch[512/600] Iteration[004/008] Valid loss: 0.0517
2023-02-06 12:12:35 | Valid | Epoch[512/600] Iteration[005/008] Valid loss: 0.0491
2023-02-06 12:12:35 | Valid | Epoch[512/600] Iteration[006/008] Valid loss: 0.0461
2023-02-06 12:12:35 | Valid | Epoch[512/600] Iteration[007/008] Valid loss: 0.0474
2023-02-06 12:12:35 | Valid | Epoch[512/600] Iteration[008/008] Valid loss: 0.0458
2023-02-06 12:12:35 | Valid | Epoch[512/600] MIou: 0.9267245447476633
2023-02-06 12:12:35 | Valid | Epoch[512/600] Pixel Accuracy: 0.9876912434895834
2023-02-06 12:12:35 | Valid | Epoch[512/600] Mean Pixel Accuracy: 0.9423840009392265
2023-02-06 12:12:35 | Stage | Epoch[512/600] Train loss:0.0164
2023-02-06 12:12:35 | Stage | Epoch[512/600] Valid loss:0.0458
2023-02-06 12:12:35 | Stage | Epoch[512/600] LR:0.0001

2023-02-06 12:12:35 | Train | Epoch[513/600] Iteration[001/030] Train loss: 0.0151
2023-02-06 12:12:35 | Train | Epoch[513/600] Iteration[002/030] Train loss: 0.0168
2023-02-06 12:12:35 | Train | Epoch[513/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:12:35 | Train | Epoch[513/600] Iteration[004/030] Train loss: 0.0171
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[007/030] Train loss: 0.0169
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[009/030] Train loss: 0.0166
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[014/030] Train loss: 0.0160
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[017/030] Train loss: 0.0161
2023-02-06 12:12:36 | Train | Epoch[513/600] Iteration[018/030] Train loss: 0.0159
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[019/030] Train loss: 0.0161
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:12:37 | Train | Epoch[513/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:12:38 | Valid | Epoch[513/600] Iteration[001/008] Valid loss: 0.0754
2023-02-06 12:12:38 | Valid | Epoch[513/600] Iteration[002/008] Valid loss: 0.0545
2023-02-06 12:12:38 | Valid | Epoch[513/600] Iteration[003/008] Valid loss: 0.0555
2023-02-06 12:12:38 | Valid | Epoch[513/600] Iteration[004/008] Valid loss: 0.0496
2023-02-06 12:12:38 | Valid | Epoch[513/600] Iteration[005/008] Valid loss: 0.0471
2023-02-06 12:12:38 | Valid | Epoch[513/600] Iteration[006/008] Valid loss: 0.0444
2023-02-06 12:12:38 | Valid | Epoch[513/600] Iteration[007/008] Valid loss: 0.0458
2023-02-06 12:12:38 | Valid | Epoch[513/600] Iteration[008/008] Valid loss: 0.0443
2023-02-06 12:12:38 | Valid | Epoch[513/600] MIou: 0.9243715681586413
2023-02-06 12:12:38 | Valid | Epoch[513/600] Pixel Accuracy: 0.9873148600260416
2023-02-06 12:12:38 | Valid | Epoch[513/600] Mean Pixel Accuracy: 0.9395204669717361
2023-02-06 12:12:38 | Stage | Epoch[513/600] Train loss:0.0165
2023-02-06 12:12:38 | Stage | Epoch[513/600] Valid loss:0.0443
2023-02-06 12:12:38 | Stage | Epoch[513/600] LR:0.0001

2023-02-06 12:12:38 | Train | Epoch[514/600] Iteration[001/030] Train loss: 0.0155
2023-02-06 12:12:38 | Train | Epoch[514/600] Iteration[002/030] Train loss: 0.0146
2023-02-06 12:12:38 | Train | Epoch[514/600] Iteration[003/030] Train loss: 0.0151
2023-02-06 12:12:38 | Train | Epoch[514/600] Iteration[004/030] Train loss: 0.0155
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[005/030] Train loss: 0.0157
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:12:39 | Train | Epoch[514/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:12:40 | Train | Epoch[514/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:12:41 | Valid | Epoch[514/600] Iteration[001/008] Valid loss: 0.0798
2023-02-06 12:12:41 | Valid | Epoch[514/600] Iteration[002/008] Valid loss: 0.0574
2023-02-06 12:12:41 | Valid | Epoch[514/600] Iteration[003/008] Valid loss: 0.0595
2023-02-06 12:12:41 | Valid | Epoch[514/600] Iteration[004/008] Valid loss: 0.0531
2023-02-06 12:12:41 | Valid | Epoch[514/600] Iteration[005/008] Valid loss: 0.0505
2023-02-06 12:12:41 | Valid | Epoch[514/600] Iteration[006/008] Valid loss: 0.0474
2023-02-06 12:12:41 | Valid | Epoch[514/600] Iteration[007/008] Valid loss: 0.0490
2023-02-06 12:12:41 | Valid | Epoch[514/600] Iteration[008/008] Valid loss: 0.0471
2023-02-06 12:12:41 | Valid | Epoch[514/600] MIou: 0.9278864465611523
2023-02-06 12:12:41 | Valid | Epoch[514/600] Pixel Accuracy: 0.9878743489583334
2023-02-06 12:12:41 | Valid | Epoch[514/600] Mean Pixel Accuracy: 0.943917590075841
2023-02-06 12:12:41 | Stage | Epoch[514/600] Train loss:0.0163
2023-02-06 12:12:41 | Stage | Epoch[514/600] Valid loss:0.0471
2023-02-06 12:12:41 | Stage | Epoch[514/600] LR:0.0001

2023-02-06 12:12:41 | Train | Epoch[515/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 12:12:41 | Train | Epoch[515/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:12:41 | Train | Epoch[515/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:12:41 | Train | Epoch[515/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[005/030] Train loss: 0.0166
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[015/030] Train loss: 0.0172
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[016/030] Train loss: 0.0173
2023-02-06 12:12:42 | Train | Epoch[515/600] Iteration[017/030] Train loss: 0.0171
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[020/030] Train loss: 0.0170
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:12:43 | Train | Epoch[515/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:12:44 | Valid | Epoch[515/600] Iteration[001/008] Valid loss: 0.0829
2023-02-06 12:12:44 | Valid | Epoch[515/600] Iteration[002/008] Valid loss: 0.0590
2023-02-06 12:12:44 | Valid | Epoch[515/600] Iteration[003/008] Valid loss: 0.0604
2023-02-06 12:12:44 | Valid | Epoch[515/600] Iteration[004/008] Valid loss: 0.0539
2023-02-06 12:12:44 | Valid | Epoch[515/600] Iteration[005/008] Valid loss: 0.0512
2023-02-06 12:12:44 | Valid | Epoch[515/600] Iteration[006/008] Valid loss: 0.0480
2023-02-06 12:12:44 | Valid | Epoch[515/600] Iteration[007/008] Valid loss: 0.0496
2023-02-06 12:12:44 | Valid | Epoch[515/600] Iteration[008/008] Valid loss: 0.0478
2023-02-06 12:12:44 | Valid | Epoch[515/600] MIou: 0.9290719431972869
2023-02-06 12:12:44 | Valid | Epoch[515/600] Pixel Accuracy: 0.9880587259928385
2023-02-06 12:12:44 | Valid | Epoch[515/600] Mean Pixel Accuracy: 0.945591368492491
2023-02-06 12:12:44 | Stage | Epoch[515/600] Train loss:0.0165
2023-02-06 12:12:44 | Stage | Epoch[515/600] Valid loss:0.0478
2023-02-06 12:12:44 | Stage | Epoch[515/600] LR:0.0001

2023-02-06 12:12:44 | Train | Epoch[516/600] Iteration[001/030] Train loss: 0.0151
2023-02-06 12:12:44 | Train | Epoch[516/600] Iteration[002/030] Train loss: 0.0146
2023-02-06 12:12:44 | Train | Epoch[516/600] Iteration[003/030] Train loss: 0.0143
2023-02-06 12:12:44 | Train | Epoch[516/600] Iteration[004/030] Train loss: 0.0147
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[005/030] Train loss: 0.0149
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[006/030] Train loss: 0.0150
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[007/030] Train loss: 0.0153
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[008/030] Train loss: 0.0151
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[009/030] Train loss: 0.0154
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[010/030] Train loss: 0.0157
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[011/030] Train loss: 0.0158
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:12:45 | Train | Epoch[516/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:12:46 | Train | Epoch[516/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:12:47 | Valid | Epoch[516/600] Iteration[001/008] Valid loss: 0.0744
2023-02-06 12:12:47 | Valid | Epoch[516/600] Iteration[002/008] Valid loss: 0.0539
2023-02-06 12:12:47 | Valid | Epoch[516/600] Iteration[003/008] Valid loss: 0.0548
2023-02-06 12:12:47 | Valid | Epoch[516/600] Iteration[004/008] Valid loss: 0.0490
2023-02-06 12:12:47 | Valid | Epoch[516/600] Iteration[005/008] Valid loss: 0.0466
2023-02-06 12:12:47 | Valid | Epoch[516/600] Iteration[006/008] Valid loss: 0.0440
2023-02-06 12:12:47 | Valid | Epoch[516/600] Iteration[007/008] Valid loss: 0.0454
2023-02-06 12:12:47 | Valid | Epoch[516/600] Iteration[008/008] Valid loss: 0.0439
2023-02-06 12:12:47 | Valid | Epoch[516/600] MIou: 0.9235784260981044
2023-02-06 12:12:47 | Valid | Epoch[516/600] Pixel Accuracy: 0.9871864318847656
2023-02-06 12:12:47 | Valid | Epoch[516/600] Mean Pixel Accuracy: 0.9386192756198806
2023-02-06 12:12:47 | Stage | Epoch[516/600] Train loss:0.0165
2023-02-06 12:12:47 | Stage | Epoch[516/600] Valid loss:0.0439
2023-02-06 12:12:47 | Stage | Epoch[516/600] LR:0.0001

2023-02-06 12:12:47 | Train | Epoch[517/600] Iteration[001/030] Train loss: 0.0150
2023-02-06 12:12:47 | Train | Epoch[517/600] Iteration[002/030] Train loss: 0.0147
2023-02-06 12:12:47 | Train | Epoch[517/600] Iteration[003/030] Train loss: 0.0153
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[006/030] Train loss: 0.0160
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[008/030] Train loss: 0.0163
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:12:48 | Train | Epoch[517/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:12:49 | Train | Epoch[517/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:12:50 | Valid | Epoch[517/600] Iteration[001/008] Valid loss: 0.0809
2023-02-06 12:12:50 | Valid | Epoch[517/600] Iteration[002/008] Valid loss: 0.0578
2023-02-06 12:12:50 | Valid | Epoch[517/600] Iteration[003/008] Valid loss: 0.0596
2023-02-06 12:12:50 | Valid | Epoch[517/600] Iteration[004/008] Valid loss: 0.0532
2023-02-06 12:12:50 | Valid | Epoch[517/600] Iteration[005/008] Valid loss: 0.0505
2023-02-06 12:12:50 | Valid | Epoch[517/600] Iteration[006/008] Valid loss: 0.0474
2023-02-06 12:12:50 | Valid | Epoch[517/600] Iteration[007/008] Valid loss: 0.0491
2023-02-06 12:12:50 | Valid | Epoch[517/600] Iteration[008/008] Valid loss: 0.0472
2023-02-06 12:12:50 | Valid | Epoch[517/600] MIou: 0.9285193673215951
2023-02-06 12:12:50 | Valid | Epoch[517/600] Pixel Accuracy: 0.9879748026529948
2023-02-06 12:12:50 | Valid | Epoch[517/600] Mean Pixel Accuracy: 0.9447336602921228
2023-02-06 12:12:50 | Stage | Epoch[517/600] Train loss:0.0163
2023-02-06 12:12:50 | Stage | Epoch[517/600] Valid loss:0.0472
2023-02-06 12:12:50 | Stage | Epoch[517/600] LR:0.0001

2023-02-06 12:12:50 | Train | Epoch[518/600] Iteration[001/030] Train loss: 0.0168
2023-02-06 12:12:50 | Train | Epoch[518/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[004/030] Train loss: 0.0185
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[005/030] Train loss: 0.0182
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[006/030] Train loss: 0.0178
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[007/030] Train loss: 0.0176
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[008/030] Train loss: 0.0173
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:12:51 | Train | Epoch[518/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:12:52 | Train | Epoch[518/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:12:53 | Valid | Epoch[518/600] Iteration[001/008] Valid loss: 0.0846
2023-02-06 12:12:53 | Valid | Epoch[518/600] Iteration[002/008] Valid loss: 0.0601
2023-02-06 12:12:53 | Valid | Epoch[518/600] Iteration[003/008] Valid loss: 0.0615
2023-02-06 12:12:53 | Valid | Epoch[518/600] Iteration[004/008] Valid loss: 0.0549
2023-02-06 12:12:53 | Valid | Epoch[518/600] Iteration[005/008] Valid loss: 0.0521
2023-02-06 12:12:53 | Valid | Epoch[518/600] Iteration[006/008] Valid loss: 0.0488
2023-02-06 12:12:53 | Valid | Epoch[518/600] Iteration[007/008] Valid loss: 0.0506
2023-02-06 12:12:53 | Valid | Epoch[518/600] Iteration[008/008] Valid loss: 0.0487
2023-02-06 12:12:53 | Valid | Epoch[518/600] MIou: 0.9297848205461466
2023-02-06 12:12:53 | Valid | Epoch[518/600] Pixel Accuracy: 0.9881680806477865
2023-02-06 12:12:53 | Valid | Epoch[518/600] Mean Pixel Accuracy: 0.9466659499166464
2023-02-06 12:12:53 | Stage | Epoch[518/600] Train loss:0.0166
2023-02-06 12:12:53 | Stage | Epoch[518/600] Valid loss:0.0487
2023-02-06 12:12:53 | Stage | Epoch[518/600] LR:0.0001

2023-02-06 12:12:53 | Train | Epoch[519/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 12:12:53 | Train | Epoch[519/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:12:54 | Train | Epoch[519/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:12:55 | Train | Epoch[519/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:12:56 | Valid | Epoch[519/600] Iteration[001/008] Valid loss: 0.0798
2023-02-06 12:12:56 | Valid | Epoch[519/600] Iteration[002/008] Valid loss: 0.0572
2023-02-06 12:12:56 | Valid | Epoch[519/600] Iteration[003/008] Valid loss: 0.0586
2023-02-06 12:12:56 | Valid | Epoch[519/600] Iteration[004/008] Valid loss: 0.0523
2023-02-06 12:12:56 | Valid | Epoch[519/600] Iteration[005/008] Valid loss: 0.0497
2023-02-06 12:12:56 | Valid | Epoch[519/600] Iteration[006/008] Valid loss: 0.0467
2023-02-06 12:12:56 | Valid | Epoch[519/600] Iteration[007/008] Valid loss: 0.0482
2023-02-06 12:12:56 | Valid | Epoch[519/600] Iteration[008/008] Valid loss: 0.0464
2023-02-06 12:12:56 | Valid | Epoch[519/600] MIou: 0.9270567537795761
2023-02-06 12:12:56 | Valid | Epoch[519/600] Pixel Accuracy: 0.9877421061197916
2023-02-06 12:12:56 | Valid | Epoch[519/600] Mean Pixel Accuracy: 0.9428748116304095
2023-02-06 12:12:56 | Stage | Epoch[519/600] Train loss:0.0165
2023-02-06 12:12:56 | Stage | Epoch[519/600] Valid loss:0.0464
2023-02-06 12:12:56 | Stage | Epoch[519/600] LR:0.0001

2023-02-06 12:12:56 | Train | Epoch[520/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 12:12:56 | Train | Epoch[520/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:12:56 | Train | Epoch[520/600] Iteration[003/030] Train loss: 0.0168
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[009/030] Train loss: 0.0166
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:12:57 | Train | Epoch[520/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:12:58 | Train | Epoch[520/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:12:59 | Valid | Epoch[520/600] Iteration[001/008] Valid loss: 0.0765
2023-02-06 12:12:59 | Valid | Epoch[520/600] Iteration[002/008] Valid loss: 0.0552
2023-02-06 12:12:59 | Valid | Epoch[520/600] Iteration[003/008] Valid loss: 0.0566
2023-02-06 12:12:59 | Valid | Epoch[520/600] Iteration[004/008] Valid loss: 0.0505
2023-02-06 12:12:59 | Valid | Epoch[520/600] Iteration[005/008] Valid loss: 0.0479
2023-02-06 12:12:59 | Valid | Epoch[520/600] Iteration[006/008] Valid loss: 0.0451
2023-02-06 12:12:59 | Valid | Epoch[520/600] Iteration[007/008] Valid loss: 0.0464
2023-02-06 12:12:59 | Valid | Epoch[520/600] Iteration[008/008] Valid loss: 0.0448
2023-02-06 12:12:59 | Valid | Epoch[520/600] MIou: 0.9247962840276005
2023-02-06 12:12:59 | Valid | Epoch[520/600] Pixel Accuracy: 0.9873835245768229
2023-02-06 12:12:59 | Valid | Epoch[520/600] Mean Pixel Accuracy: 0.9400083814146754
2023-02-06 12:12:59 | Stage | Epoch[520/600] Train loss:0.0165
2023-02-06 12:12:59 | Stage | Epoch[520/600] Valid loss:0.0448
2023-02-06 12:12:59 | Stage | Epoch[520/600] LR:0.0001

2023-02-06 12:12:59 | Train | Epoch[521/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 12:12:59 | Train | Epoch[521/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:12:59 | Train | Epoch[521/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[007/030] Train loss: 0.0158
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:13:00 | Train | Epoch[521/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:13:01 | Train | Epoch[521/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:13:02 | Valid | Epoch[521/600] Iteration[001/008] Valid loss: 0.0787
2023-02-06 12:13:02 | Valid | Epoch[521/600] Iteration[002/008] Valid loss: 0.0565
2023-02-06 12:13:02 | Valid | Epoch[521/600] Iteration[003/008] Valid loss: 0.0576
2023-02-06 12:13:02 | Valid | Epoch[521/600] Iteration[004/008] Valid loss: 0.0514
2023-02-06 12:13:02 | Valid | Epoch[521/600] Iteration[005/008] Valid loss: 0.0488
2023-02-06 12:13:02 | Valid | Epoch[521/600] Iteration[006/008] Valid loss: 0.0459
2023-02-06 12:13:02 | Valid | Epoch[521/600] Iteration[007/008] Valid loss: 0.0473
2023-02-06 12:13:02 | Valid | Epoch[521/600] Iteration[008/008] Valid loss: 0.0456
2023-02-06 12:13:02 | Valid | Epoch[521/600] MIou: 0.9265385471160048
2023-02-06 12:13:02 | Valid | Epoch[521/600] Pixel Accuracy: 0.9876607259114584
2023-02-06 12:13:02 | Valid | Epoch[521/600] Mean Pixel Accuracy: 0.9421833535028954
2023-02-06 12:13:02 | Stage | Epoch[521/600] Train loss:0.0164
2023-02-06 12:13:02 | Stage | Epoch[521/600] Valid loss:0.0456
2023-02-06 12:13:02 | Stage | Epoch[521/600] LR:0.0001

2023-02-06 12:13:02 | Train | Epoch[522/600] Iteration[001/030] Train loss: 0.0163
2023-02-06 12:13:02 | Train | Epoch[522/600] Iteration[002/030] Train loss: 0.0164
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[006/030] Train loss: 0.0162
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[007/030] Train loss: 0.0159
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:13:03 | Train | Epoch[522/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:13:04 | Train | Epoch[522/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:13:05 | Valid | Epoch[522/600] Iteration[001/008] Valid loss: 0.0800
2023-02-06 12:13:05 | Valid | Epoch[522/600] Iteration[002/008] Valid loss: 0.0573
2023-02-06 12:13:05 | Valid | Epoch[522/600] Iteration[003/008] Valid loss: 0.0587
2023-02-06 12:13:05 | Valid | Epoch[522/600] Iteration[004/008] Valid loss: 0.0523
2023-02-06 12:13:05 | Valid | Epoch[522/600] Iteration[005/008] Valid loss: 0.0496
2023-02-06 12:13:05 | Valid | Epoch[522/600] Iteration[006/008] Valid loss: 0.0465
2023-02-06 12:13:05 | Valid | Epoch[522/600] Iteration[007/008] Valid loss: 0.0480
2023-02-06 12:13:05 | Valid | Epoch[522/600] Iteration[008/008] Valid loss: 0.0463
2023-02-06 12:13:05 | Valid | Epoch[522/600] MIou: 0.9271597062717383
2023-02-06 12:13:05 | Valid | Epoch[522/600] Pixel Accuracy: 0.987756093343099
2023-02-06 12:13:05 | Valid | Epoch[522/600] Mean Pixel Accuracy: 0.9430917351647785
2023-02-06 12:13:05 | Stage | Epoch[522/600] Train loss:0.0164
2023-02-06 12:13:05 | Stage | Epoch[522/600] Valid loss:0.0463
2023-02-06 12:13:05 | Stage | Epoch[522/600] LR:0.0001

2023-02-06 12:13:05 | Train | Epoch[523/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 12:13:05 | Train | Epoch[523/600] Iteration[002/030] Train loss: 0.0162
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[003/030] Train loss: 0.0170
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[005/030] Train loss: 0.0168
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:13:06 | Train | Epoch[523/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:13:07 | Train | Epoch[523/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:13:08 | Valid | Epoch[523/600] Iteration[001/008] Valid loss: 0.0799
2023-02-06 12:13:08 | Valid | Epoch[523/600] Iteration[002/008] Valid loss: 0.0574
2023-02-06 12:13:08 | Valid | Epoch[523/600] Iteration[003/008] Valid loss: 0.0593
2023-02-06 12:13:08 | Valid | Epoch[523/600] Iteration[004/008] Valid loss: 0.0528
2023-02-06 12:13:08 | Valid | Epoch[523/600] Iteration[005/008] Valid loss: 0.0501
2023-02-06 12:13:08 | Valid | Epoch[523/600] Iteration[006/008] Valid loss: 0.0470
2023-02-06 12:13:08 | Valid | Epoch[523/600] Iteration[007/008] Valid loss: 0.0485
2023-02-06 12:13:08 | Valid | Epoch[523/600] Iteration[008/008] Valid loss: 0.0467
2023-02-06 12:13:08 | Valid | Epoch[523/600] MIou: 0.92752416353668
2023-02-06 12:13:08 | Valid | Epoch[523/600] Pixel Accuracy: 0.987817128499349
2023-02-06 12:13:08 | Valid | Epoch[523/600] Mean Pixel Accuracy: 0.9434423062653439
2023-02-06 12:13:08 | Stage | Epoch[523/600] Train loss:0.0163
2023-02-06 12:13:08 | Stage | Epoch[523/600] Valid loss:0.0467
2023-02-06 12:13:08 | Stage | Epoch[523/600] LR:0.0001

2023-02-06 12:13:08 | Train | Epoch[524/600] Iteration[001/030] Train loss: 0.0168
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[002/030] Train loss: 0.0169
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[003/030] Train loss: 0.0173
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[005/030] Train loss: 0.0162
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[006/030] Train loss: 0.0160
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[007/030] Train loss: 0.0159
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:13:09 | Train | Epoch[524/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:13:10 | Train | Epoch[524/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:13:11 | Train | Epoch[524/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:13:11 | Valid | Epoch[524/600] Iteration[001/008] Valid loss: 0.0832
2023-02-06 12:13:11 | Valid | Epoch[524/600] Iteration[002/008] Valid loss: 0.0588
2023-02-06 12:13:11 | Valid | Epoch[524/600] Iteration[003/008] Valid loss: 0.0597
2023-02-06 12:13:11 | Valid | Epoch[524/600] Iteration[004/008] Valid loss: 0.0533
2023-02-06 12:13:11 | Valid | Epoch[524/600] Iteration[005/008] Valid loss: 0.0506
2023-02-06 12:13:11 | Valid | Epoch[524/600] Iteration[006/008] Valid loss: 0.0475
2023-02-06 12:13:11 | Valid | Epoch[524/600] Iteration[007/008] Valid loss: 0.0492
2023-02-06 12:13:11 | Valid | Epoch[524/600] Iteration[008/008] Valid loss: 0.0474
2023-02-06 12:13:11 | Valid | Epoch[524/600] MIou: 0.9287410371040368
2023-02-06 12:13:11 | Valid | Epoch[524/600] Pixel Accuracy: 0.9880053202311198
2023-02-06 12:13:11 | Valid | Epoch[524/600] Mean Pixel Accuracy: 0.9451942670604492
2023-02-06 12:13:11 | Stage | Epoch[524/600] Train loss:0.0163
2023-02-06 12:13:11 | Stage | Epoch[524/600] Valid loss:0.0474
2023-02-06 12:13:11 | Stage | Epoch[524/600] LR:0.0001

2023-02-06 12:13:11 | Train | Epoch[525/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[002/030] Train loss: 0.0164
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[003/030] Train loss: 0.0160
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[005/030] Train loss: 0.0168
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:13:12 | Train | Epoch[525/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:13:13 | Train | Epoch[525/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:13:14 | Train | Epoch[525/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:13:14 | Valid | Epoch[525/600] Iteration[001/008] Valid loss: 0.0805
2023-02-06 12:13:14 | Valid | Epoch[525/600] Iteration[002/008] Valid loss: 0.0573
2023-02-06 12:13:14 | Valid | Epoch[525/600] Iteration[003/008] Valid loss: 0.0588
2023-02-06 12:13:14 | Valid | Epoch[525/600] Iteration[004/008] Valid loss: 0.0525
2023-02-06 12:13:14 | Valid | Epoch[525/600] Iteration[005/008] Valid loss: 0.0498
2023-02-06 12:13:14 | Valid | Epoch[525/600] Iteration[006/008] Valid loss: 0.0468
2023-02-06 12:13:14 | Valid | Epoch[525/600] Iteration[007/008] Valid loss: 0.0485
2023-02-06 12:13:14 | Valid | Epoch[525/600] Iteration[008/008] Valid loss: 0.0467
2023-02-06 12:13:14 | Valid | Epoch[525/600] MIou: 0.9277131309697081
2023-02-06 12:13:14 | Valid | Epoch[525/600] Pixel Accuracy: 0.9878463745117188
2023-02-06 12:13:14 | Valid | Epoch[525/600] Mean Pixel Accuracy: 0.9437119999815378
2023-02-06 12:13:14 | Stage | Epoch[525/600] Train loss:0.0165
2023-02-06 12:13:14 | Stage | Epoch[525/600] Valid loss:0.0467
2023-02-06 12:13:14 | Stage | Epoch[525/600] LR:0.0001

2023-02-06 12:13:14 | Train | Epoch[526/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[002/030] Train loss: 0.0154
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[003/030] Train loss: 0.0162
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:13:15 | Train | Epoch[526/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:13:16 | Train | Epoch[526/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:13:17 | Train | Epoch[526/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:13:17 | Train | Epoch[526/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:13:17 | Valid | Epoch[526/600] Iteration[001/008] Valid loss: 0.0816
2023-02-06 12:13:17 | Valid | Epoch[526/600] Iteration[002/008] Valid loss: 0.0582
2023-02-06 12:13:17 | Valid | Epoch[526/600] Iteration[003/008] Valid loss: 0.0598
2023-02-06 12:13:17 | Valid | Epoch[526/600] Iteration[004/008] Valid loss: 0.0534
2023-02-06 12:13:17 | Valid | Epoch[526/600] Iteration[005/008] Valid loss: 0.0507
2023-02-06 12:13:17 | Valid | Epoch[526/600] Iteration[006/008] Valid loss: 0.0477
2023-02-06 12:13:17 | Valid | Epoch[526/600] Iteration[007/008] Valid loss: 0.0493
2023-02-06 12:13:17 | Valid | Epoch[526/600] Iteration[008/008] Valid loss: 0.0474
2023-02-06 12:13:17 | Valid | Epoch[526/600] MIou: 0.9282769389396379
2023-02-06 12:13:17 | Valid | Epoch[526/600] Pixel Accuracy: 0.9879366556803385
2023-02-06 12:13:17 | Valid | Epoch[526/600] Mean Pixel Accuracy: 0.9444083504564421
2023-02-06 12:13:17 | Stage | Epoch[526/600] Train loss:0.0164
2023-02-06 12:13:17 | Stage | Epoch[526/600] Valid loss:0.0474
2023-02-06 12:13:17 | Stage | Epoch[526/600] LR:0.0001

2023-02-06 12:13:17 | Train | Epoch[527/600] Iteration[001/030] Train loss: 0.0181
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[002/030] Train loss: 0.0183
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[005/030] Train loss: 0.0168
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:13:18 | Train | Epoch[527/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:13:19 | Train | Epoch[527/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:13:20 | Train | Epoch[527/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:13:20 | Train | Epoch[527/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:13:20 | Valid | Epoch[527/600] Iteration[001/008] Valid loss: 0.0863
2023-02-06 12:13:20 | Valid | Epoch[527/600] Iteration[002/008] Valid loss: 0.0613
2023-02-06 12:13:20 | Valid | Epoch[527/600] Iteration[003/008] Valid loss: 0.0628
2023-02-06 12:13:20 | Valid | Epoch[527/600] Iteration[004/008] Valid loss: 0.0560
2023-02-06 12:13:20 | Valid | Epoch[527/600] Iteration[005/008] Valid loss: 0.0531
2023-02-06 12:13:20 | Valid | Epoch[527/600] Iteration[006/008] Valid loss: 0.0496
2023-02-06 12:13:20 | Valid | Epoch[527/600] Iteration[007/008] Valid loss: 0.0514
2023-02-06 12:13:20 | Valid | Epoch[527/600] Iteration[008/008] Valid loss: 0.0495
2023-02-06 12:13:20 | Valid | Epoch[527/600] MIou: 0.9303565637300749
2023-02-06 12:13:20 | Valid | Epoch[527/600] Pixel Accuracy: 0.9882545471191406
2023-02-06 12:13:20 | Valid | Epoch[527/600] Mean Pixel Accuracy: 0.9475821201741634
2023-02-06 12:13:20 | Stage | Epoch[527/600] Train loss:0.0164
2023-02-06 12:13:20 | Stage | Epoch[527/600] Valid loss:0.0495
2023-02-06 12:13:20 | Stage | Epoch[527/600] LR:0.0001

2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[001/030] Train loss: 0.0160
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[002/030] Train loss: 0.0152
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[003/030] Train loss: 0.0156
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[004/030] Train loss: 0.0155
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[007/030] Train loss: 0.0158
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[009/030] Train loss: 0.0159
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:13:21 | Train | Epoch[528/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[017/030] Train loss: 0.0161
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[018/030] Train loss: 0.0160
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[019/030] Train loss: 0.0161
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[021/030] Train loss: 0.0160
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:13:22 | Train | Epoch[528/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:13:23 | Train | Epoch[528/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:13:23 | Train | Epoch[528/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:13:23 | Valid | Epoch[528/600] Iteration[001/008] Valid loss: 0.0786
2023-02-06 12:13:23 | Valid | Epoch[528/600] Iteration[002/008] Valid loss: 0.0566
2023-02-06 12:13:23 | Valid | Epoch[528/600] Iteration[003/008] Valid loss: 0.0579
2023-02-06 12:13:23 | Valid | Epoch[528/600] Iteration[004/008] Valid loss: 0.0517
2023-02-06 12:13:23 | Valid | Epoch[528/600] Iteration[005/008] Valid loss: 0.0491
2023-02-06 12:13:23 | Valid | Epoch[528/600] Iteration[006/008] Valid loss: 0.0460
2023-02-06 12:13:23 | Valid | Epoch[528/600] Iteration[007/008] Valid loss: 0.0474
2023-02-06 12:13:23 | Valid | Epoch[528/600] Iteration[008/008] Valid loss: 0.0458
2023-02-06 12:13:23 | Valid | Epoch[528/600] MIou: 0.9265080185381196
2023-02-06 12:13:23 | Valid | Epoch[528/600] Pixel Accuracy: 0.9876543680826823
2023-02-06 12:13:23 | Valid | Epoch[528/600] Mean Pixel Accuracy: 0.9421988803835815
2023-02-06 12:13:23 | Stage | Epoch[528/600] Train loss:0.0163
2023-02-06 12:13:23 | Stage | Epoch[528/600] Valid loss:0.0458
2023-02-06 12:13:23 | Stage | Epoch[528/600] LR:0.0001

2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[002/030] Train loss: 0.0160
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[007/030] Train loss: 0.0162
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:13:24 | Train | Epoch[529/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:13:25 | Train | Epoch[529/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:13:26 | Train | Epoch[529/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:13:26 | Train | Epoch[529/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:13:26 | Valid | Epoch[529/600] Iteration[001/008] Valid loss: 0.0773
2023-02-06 12:13:26 | Valid | Epoch[529/600] Iteration[002/008] Valid loss: 0.0556
2023-02-06 12:13:26 | Valid | Epoch[529/600] Iteration[003/008] Valid loss: 0.0566
2023-02-06 12:13:26 | Valid | Epoch[529/600] Iteration[004/008] Valid loss: 0.0505
2023-02-06 12:13:26 | Valid | Epoch[529/600] Iteration[005/008] Valid loss: 0.0480
2023-02-06 12:13:26 | Valid | Epoch[529/600] Iteration[006/008] Valid loss: 0.0452
2023-02-06 12:13:26 | Valid | Epoch[529/600] Iteration[007/008] Valid loss: 0.0467
2023-02-06 12:13:26 | Valid | Epoch[529/600] Iteration[008/008] Valid loss: 0.0450
2023-02-06 12:13:26 | Valid | Epoch[529/600] MIou: 0.9254536336215788
2023-02-06 12:13:26 | Valid | Epoch[529/600] Pixel Accuracy: 0.9874852498372396
2023-02-06 12:13:26 | Valid | Epoch[529/600] Mean Pixel Accuracy: 0.9409265980819206
2023-02-06 12:13:26 | Stage | Epoch[529/600] Train loss:0.0165
2023-02-06 12:13:26 | Stage | Epoch[529/600] Valid loss:0.0450
2023-02-06 12:13:26 | Stage | Epoch[529/600] LR:0.0001

2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[002/030] Train loss: 0.0162
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:13:27 | Train | Epoch[530/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:13:28 | Train | Epoch[530/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:13:29 | Train | Epoch[530/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:13:29 | Train | Epoch[530/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:13:29 | Valid | Epoch[530/600] Iteration[001/008] Valid loss: 0.0775
2023-02-06 12:13:29 | Valid | Epoch[530/600] Iteration[002/008] Valid loss: 0.0557
2023-02-06 12:13:29 | Valid | Epoch[530/600] Iteration[003/008] Valid loss: 0.0574
2023-02-06 12:13:29 | Valid | Epoch[530/600] Iteration[004/008] Valid loss: 0.0512
2023-02-06 12:13:29 | Valid | Epoch[530/600] Iteration[005/008] Valid loss: 0.0486
2023-02-06 12:13:29 | Valid | Epoch[530/600] Iteration[006/008] Valid loss: 0.0457
2023-02-06 12:13:29 | Valid | Epoch[530/600] Iteration[007/008] Valid loss: 0.0472
2023-02-06 12:13:29 | Valid | Epoch[530/600] Iteration[008/008] Valid loss: 0.0455
2023-02-06 12:13:29 | Valid | Epoch[530/600] MIou: 0.9256047381621809
2023-02-06 12:13:29 | Valid | Epoch[530/600] Pixel Accuracy: 0.9875094095865885
2023-02-06 12:13:29 | Valid | Epoch[530/600] Mean Pixel Accuracy: 0.9411110700413774
2023-02-06 12:13:29 | Stage | Epoch[530/600] Train loss:0.0164
2023-02-06 12:13:29 | Stage | Epoch[530/600] Valid loss:0.0455
2023-02-06 12:13:29 | Stage | Epoch[530/600] LR:0.0001

2023-02-06 12:13:29 | Train | Epoch[531/600] Iteration[001/030] Train loss: 0.0154
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[002/030] Train loss: 0.0164
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[007/030] Train loss: 0.0169
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:13:30 | Train | Epoch[531/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:13:31 | Train | Epoch[531/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:13:32 | Train | Epoch[531/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:13:32 | Train | Epoch[531/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:13:32 | Valid | Epoch[531/600] Iteration[001/008] Valid loss: 0.0756
2023-02-06 12:13:32 | Valid | Epoch[531/600] Iteration[002/008] Valid loss: 0.0547
2023-02-06 12:13:32 | Valid | Epoch[531/600] Iteration[003/008] Valid loss: 0.0559
2023-02-06 12:13:32 | Valid | Epoch[531/600] Iteration[004/008] Valid loss: 0.0498
2023-02-06 12:13:32 | Valid | Epoch[531/600] Iteration[005/008] Valid loss: 0.0473
2023-02-06 12:13:32 | Valid | Epoch[531/600] Iteration[006/008] Valid loss: 0.0445
2023-02-06 12:13:32 | Valid | Epoch[531/600] Iteration[007/008] Valid loss: 0.0458
2023-02-06 12:13:32 | Valid | Epoch[531/600] Iteration[008/008] Valid loss: 0.0443
2023-02-06 12:13:32 | Valid | Epoch[531/600] MIou: 0.9243016100474155
2023-02-06 12:13:32 | Valid | Epoch[531/600] Pixel Accuracy: 0.9873046875
2023-02-06 12:13:32 | Valid | Epoch[531/600] Mean Pixel Accuracy: 0.9394007472303584
2023-02-06 12:13:32 | Stage | Epoch[531/600] Train loss:0.0164
2023-02-06 12:13:32 | Stage | Epoch[531/600] Valid loss:0.0443
2023-02-06 12:13:32 | Stage | Epoch[531/600] LR:0.0001

2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[003/030] Train loss: 0.0179
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[007/030] Train loss: 0.0175
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[009/030] Train loss: 0.0170
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:13:33 | Train | Epoch[532/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:13:34 | Train | Epoch[532/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:13:35 | Train | Epoch[532/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:13:35 | Train | Epoch[532/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:13:35 | Train | Epoch[532/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:13:35 | Valid | Epoch[532/600] Iteration[001/008] Valid loss: 0.0821
2023-02-06 12:13:35 | Valid | Epoch[532/600] Iteration[002/008] Valid loss: 0.0585
2023-02-06 12:13:35 | Valid | Epoch[532/600] Iteration[003/008] Valid loss: 0.0599
2023-02-06 12:13:35 | Valid | Epoch[532/600] Iteration[004/008] Valid loss: 0.0534
2023-02-06 12:13:35 | Valid | Epoch[532/600] Iteration[005/008] Valid loss: 0.0507
2023-02-06 12:13:35 | Valid | Epoch[532/600] Iteration[006/008] Valid loss: 0.0476
2023-02-06 12:13:35 | Valid | Epoch[532/600] Iteration[007/008] Valid loss: 0.0491
2023-02-06 12:13:35 | Valid | Epoch[532/600] Iteration[008/008] Valid loss: 0.0473
2023-02-06 12:13:35 | Valid | Epoch[532/600] MIou: 0.9285293783520991
2023-02-06 12:13:35 | Valid | Epoch[532/600] Pixel Accuracy: 0.9879709879557291
2023-02-06 12:13:35 | Valid | Epoch[532/600] Mean Pixel Accuracy: 0.9449471396032234
2023-02-06 12:13:35 | Stage | Epoch[532/600] Train loss:0.0164
2023-02-06 12:13:35 | Stage | Epoch[532/600] Valid loss:0.0473
2023-02-06 12:13:35 | Stage | Epoch[532/600] LR:0.0001

2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[003/030] Train loss: 0.0172
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[005/030] Train loss: 0.0166
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[006/030] Train loss: 0.0165
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[007/030] Train loss: 0.0169
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:13:36 | Train | Epoch[533/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:13:37 | Train | Epoch[533/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:13:38 | Train | Epoch[533/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:13:38 | Train | Epoch[533/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:13:38 | Train | Epoch[533/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:13:38 | Valid | Epoch[533/600] Iteration[001/008] Valid loss: 0.0796
2023-02-06 12:13:38 | Valid | Epoch[533/600] Iteration[002/008] Valid loss: 0.0570
2023-02-06 12:13:38 | Valid | Epoch[533/600] Iteration[003/008] Valid loss: 0.0585
2023-02-06 12:13:38 | Valid | Epoch[533/600] Iteration[004/008] Valid loss: 0.0521
2023-02-06 12:13:38 | Valid | Epoch[533/600] Iteration[005/008] Valid loss: 0.0495
2023-02-06 12:13:38 | Valid | Epoch[533/600] Iteration[006/008] Valid loss: 0.0465
2023-02-06 12:13:38 | Valid | Epoch[533/600] Iteration[007/008] Valid loss: 0.0479
2023-02-06 12:13:38 | Valid | Epoch[533/600] Iteration[008/008] Valid loss: 0.0462
2023-02-06 12:13:38 | Valid | Epoch[533/600] MIou: 0.9267447761645007
2023-02-06 12:13:38 | Valid | Epoch[533/600] Pixel Accuracy: 0.9876887003580729
2023-02-06 12:13:38 | Valid | Epoch[533/600] Mean Pixel Accuracy: 0.9426172005716333
2023-02-06 12:13:38 | Stage | Epoch[533/600] Train loss:0.0165
2023-02-06 12:13:38 | Stage | Epoch[533/600] Valid loss:0.0462
2023-02-06 12:13:38 | Stage | Epoch[533/600] LR:0.0001

2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[001/030] Train loss: 0.0151
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[003/030] Train loss: 0.0157
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:13:39 | Train | Epoch[534/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:13:40 | Train | Epoch[534/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:13:41 | Train | Epoch[534/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:13:41 | Train | Epoch[534/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:13:41 | Train | Epoch[534/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:13:41 | Train | Epoch[534/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:13:41 | Valid | Epoch[534/600] Iteration[001/008] Valid loss: 0.0784
2023-02-06 12:13:41 | Valid | Epoch[534/600] Iteration[002/008] Valid loss: 0.0564
2023-02-06 12:13:41 | Valid | Epoch[534/600] Iteration[003/008] Valid loss: 0.0582
2023-02-06 12:13:41 | Valid | Epoch[534/600] Iteration[004/008] Valid loss: 0.0518
2023-02-06 12:13:41 | Valid | Epoch[534/600] Iteration[005/008] Valid loss: 0.0493
2023-02-06 12:13:41 | Valid | Epoch[534/600] Iteration[006/008] Valid loss: 0.0464
2023-02-06 12:13:41 | Valid | Epoch[534/600] Iteration[007/008] Valid loss: 0.0480
2023-02-06 12:13:41 | Valid | Epoch[534/600] Iteration[008/008] Valid loss: 0.0462
2023-02-06 12:13:41 | Valid | Epoch[534/600] MIou: 0.9262095198925513
2023-02-06 12:13:41 | Valid | Epoch[534/600] Pixel Accuracy: 0.9876047770182291
2023-02-06 12:13:41 | Valid | Epoch[534/600] Mean Pixel Accuracy: 0.941898982744531
2023-02-06 12:13:41 | Stage | Epoch[534/600] Train loss:0.0167
2023-02-06 12:13:41 | Stage | Epoch[534/600] Valid loss:0.0462
2023-02-06 12:13:41 | Stage | Epoch[534/600] LR:0.0001

2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[002/030] Train loss: 0.0149
2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[005/030] Train loss: 0.0166
2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:13:42 | Train | Epoch[535/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:13:43 | Train | Epoch[535/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:13:44 | Train | Epoch[535/600] Iteration[026/030] Train loss: 0.0161
2023-02-06 12:13:44 | Train | Epoch[535/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:13:44 | Train | Epoch[535/600] Iteration[028/030] Train loss: 0.0161
2023-02-06 12:13:44 | Train | Epoch[535/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 12:13:44 | Train | Epoch[535/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:13:44 | Valid | Epoch[535/600] Iteration[001/008] Valid loss: 0.0792
2023-02-06 12:13:44 | Valid | Epoch[535/600] Iteration[002/008] Valid loss: 0.0568
2023-02-06 12:13:44 | Valid | Epoch[535/600] Iteration[003/008] Valid loss: 0.0581
2023-02-06 12:13:44 | Valid | Epoch[535/600] Iteration[004/008] Valid loss: 0.0520
2023-02-06 12:13:44 | Valid | Epoch[535/600] Iteration[005/008] Valid loss: 0.0494
2023-02-06 12:13:44 | Valid | Epoch[535/600] Iteration[006/008] Valid loss: 0.0465
2023-02-06 12:13:44 | Valid | Epoch[535/600] Iteration[007/008] Valid loss: 0.0481
2023-02-06 12:13:44 | Valid | Epoch[535/600] Iteration[008/008] Valid loss: 0.0464
2023-02-06 12:13:44 | Valid | Epoch[535/600] MIou: 0.9269297564261973
2023-02-06 12:13:44 | Valid | Epoch[535/600] Pixel Accuracy: 0.9877192179361979
2023-02-06 12:13:44 | Valid | Epoch[535/600] Mean Pixel Accuracy: 0.9428115075364523
2023-02-06 12:13:44 | Stage | Epoch[535/600] Train loss:0.0163
2023-02-06 12:13:44 | Stage | Epoch[535/600] Valid loss:0.0464
2023-02-06 12:13:44 | Stage | Epoch[535/600] LR:0.0001

2023-02-06 12:13:45 | Train | Epoch[536/600] Iteration[001/030] Train loss: 0.0154
2023-02-06 12:13:45 | Train | Epoch[536/600] Iteration[002/030] Train loss: 0.0158
2023-02-06 12:13:45 | Train | Epoch[536/600] Iteration[003/030] Train loss: 0.0154
2023-02-06 12:13:45 | Train | Epoch[536/600] Iteration[004/030] Train loss: 0.0154
2023-02-06 12:13:45 | Train | Epoch[536/600] Iteration[005/030] Train loss: 0.0156
2023-02-06 12:13:45 | Train | Epoch[536/600] Iteration[006/030] Train loss: 0.0154
2023-02-06 12:13:45 | Train | Epoch[536/600] Iteration[007/030] Train loss: 0.0154
2023-02-06 12:13:45 | Train | Epoch[536/600] Iteration[008/030] Train loss: 0.0152
2023-02-06 12:13:45 | Train | Epoch[536/600] Iteration[009/030] Train loss: 0.0153
2023-02-06 12:13:45 | Train | Epoch[536/600] Iteration[010/030] Train loss: 0.0159
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:13:46 | Train | Epoch[536/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:13:47 | Train | Epoch[536/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:13:47 | Train | Epoch[536/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:13:47 | Train | Epoch[536/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:13:47 | Train | Epoch[536/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:13:47 | Train | Epoch[536/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:13:47 | Train | Epoch[536/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:13:47 | Valid | Epoch[536/600] Iteration[001/008] Valid loss: 0.0817
2023-02-06 12:13:47 | Valid | Epoch[536/600] Iteration[002/008] Valid loss: 0.0584
2023-02-06 12:13:47 | Valid | Epoch[536/600] Iteration[003/008] Valid loss: 0.0600
2023-02-06 12:13:47 | Valid | Epoch[536/600] Iteration[004/008] Valid loss: 0.0535
2023-02-06 12:13:47 | Valid | Epoch[536/600] Iteration[005/008] Valid loss: 0.0509
2023-02-06 12:13:47 | Valid | Epoch[536/600] Iteration[006/008] Valid loss: 0.0477
2023-02-06 12:13:47 | Valid | Epoch[536/600] Iteration[007/008] Valid loss: 0.0493
2023-02-06 12:13:47 | Valid | Epoch[536/600] Iteration[008/008] Valid loss: 0.0474
2023-02-06 12:13:47 | Valid | Epoch[536/600] MIou: 0.9286382802598547
2023-02-06 12:13:47 | Valid | Epoch[536/600] Pixel Accuracy: 0.9879926045735677
2023-02-06 12:13:47 | Valid | Epoch[536/600] Mean Pixel Accuracy: 0.9449273186607536
2023-02-06 12:13:47 | Stage | Epoch[536/600] Train loss:0.0164
2023-02-06 12:13:47 | Stage | Epoch[536/600] Valid loss:0.0474
2023-02-06 12:13:47 | Stage | Epoch[536/600] LR:0.0001

2023-02-06 12:13:48 | Train | Epoch[537/600] Iteration[001/030] Train loss: 0.0160
2023-02-06 12:13:48 | Train | Epoch[537/600] Iteration[002/030] Train loss: 0.0151
2023-02-06 12:13:48 | Train | Epoch[537/600] Iteration[003/030] Train loss: 0.0153
2023-02-06 12:13:48 | Train | Epoch[537/600] Iteration[004/030] Train loss: 0.0159
2023-02-06 12:13:48 | Train | Epoch[537/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:13:48 | Train | Epoch[537/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:13:48 | Train | Epoch[537/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:13:48 | Train | Epoch[537/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:13:48 | Train | Epoch[537/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:13:48 | Train | Epoch[537/600] Iteration[010/030] Train loss: 0.0159
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[013/030] Train loss: 0.0160
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:13:49 | Train | Epoch[537/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:13:50 | Train | Epoch[537/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:13:50 | Train | Epoch[537/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:13:50 | Train | Epoch[537/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:13:50 | Train | Epoch[537/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:13:50 | Train | Epoch[537/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:13:50 | Train | Epoch[537/600] Iteration[030/030] Train loss: 0.0162
2023-02-06 12:13:50 | Valid | Epoch[537/600] Iteration[001/008] Valid loss: 0.0763
2023-02-06 12:13:50 | Valid | Epoch[537/600] Iteration[002/008] Valid loss: 0.0552
2023-02-06 12:13:50 | Valid | Epoch[537/600] Iteration[003/008] Valid loss: 0.0568
2023-02-06 12:13:50 | Valid | Epoch[537/600] Iteration[004/008] Valid loss: 0.0505
2023-02-06 12:13:50 | Valid | Epoch[537/600] Iteration[005/008] Valid loss: 0.0479
2023-02-06 12:13:50 | Valid | Epoch[537/600] Iteration[006/008] Valid loss: 0.0450
2023-02-06 12:13:50 | Valid | Epoch[537/600] Iteration[007/008] Valid loss: 0.0463
2023-02-06 12:13:50 | Valid | Epoch[537/600] Iteration[008/008] Valid loss: 0.0447
2023-02-06 12:13:50 | Valid | Epoch[537/600] MIou: 0.9249066030076296
2023-02-06 12:13:50 | Valid | Epoch[537/600] Pixel Accuracy: 0.9874076843261719
2023-02-06 12:13:50 | Valid | Epoch[537/600] Mean Pixel Accuracy: 0.9399138726276006
2023-02-06 12:13:50 | Stage | Epoch[537/600] Train loss:0.0162
2023-02-06 12:13:50 | Stage | Epoch[537/600] Valid loss:0.0447
2023-02-06 12:13:50 | Stage | Epoch[537/600] LR:0.0001

2023-02-06 12:13:51 | Train | Epoch[538/600] Iteration[001/030] Train loss: 0.0139
2023-02-06 12:13:51 | Train | Epoch[538/600] Iteration[002/030] Train loss: 0.0139
2023-02-06 12:13:51 | Train | Epoch[538/600] Iteration[003/030] Train loss: 0.0145
2023-02-06 12:13:51 | Train | Epoch[538/600] Iteration[004/030] Train loss: 0.0147
2023-02-06 12:13:51 | Train | Epoch[538/600] Iteration[005/030] Train loss: 0.0157
2023-02-06 12:13:51 | Train | Epoch[538/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:13:51 | Train | Epoch[538/600] Iteration[007/030] Train loss: 0.0161
2023-02-06 12:13:51 | Train | Epoch[538/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:13:51 | Train | Epoch[538/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:13:51 | Train | Epoch[538/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:13:52 | Train | Epoch[538/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:13:53 | Train | Epoch[538/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:13:53 | Train | Epoch[538/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:13:53 | Train | Epoch[538/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:13:53 | Train | Epoch[538/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:13:53 | Train | Epoch[538/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:13:53 | Train | Epoch[538/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:13:53 | Valid | Epoch[538/600] Iteration[001/008] Valid loss: 0.0762
2023-02-06 12:13:53 | Valid | Epoch[538/600] Iteration[002/008] Valid loss: 0.0551
2023-02-06 12:13:53 | Valid | Epoch[538/600] Iteration[003/008] Valid loss: 0.0559
2023-02-06 12:13:53 | Valid | Epoch[538/600] Iteration[004/008] Valid loss: 0.0498
2023-02-06 12:13:53 | Valid | Epoch[538/600] Iteration[005/008] Valid loss: 0.0474
2023-02-06 12:13:53 | Valid | Epoch[538/600] Iteration[006/008] Valid loss: 0.0446
2023-02-06 12:13:53 | Valid | Epoch[538/600] Iteration[007/008] Valid loss: 0.0458
2023-02-06 12:13:53 | Valid | Epoch[538/600] Iteration[008/008] Valid loss: 0.0443
2023-02-06 12:13:53 | Valid | Epoch[538/600] MIou: 0.9245172147531285
2023-02-06 12:13:53 | Valid | Epoch[538/600] Pixel Accuracy: 0.9873377482096354
2023-02-06 12:13:53 | Valid | Epoch[538/600] Mean Pixel Accuracy: 0.9397105804959348
2023-02-06 12:13:53 | Stage | Epoch[538/600] Train loss:0.0166
2023-02-06 12:13:53 | Stage | Epoch[538/600] Valid loss:0.0443
2023-02-06 12:13:53 | Stage | Epoch[538/600] LR:0.0001

2023-02-06 12:13:54 | Train | Epoch[539/600] Iteration[001/030] Train loss: 0.0160
2023-02-06 12:13:54 | Train | Epoch[539/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:13:54 | Train | Epoch[539/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:13:54 | Train | Epoch[539/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:13:54 | Train | Epoch[539/600] Iteration[005/030] Train loss: 0.0167
2023-02-06 12:13:54 | Train | Epoch[539/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:13:54 | Train | Epoch[539/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:13:54 | Train | Epoch[539/600] Iteration[008/030] Train loss: 0.0163
2023-02-06 12:13:54 | Train | Epoch[539/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:13:54 | Train | Epoch[539/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[013/030] Train loss: 0.0160
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[014/030] Train loss: 0.0160
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[015/030] Train loss: 0.0158
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[016/030] Train loss: 0.0159
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:13:55 | Train | Epoch[539/600] Iteration[023/030] Train loss: 0.0161
2023-02-06 12:13:56 | Train | Epoch[539/600] Iteration[024/030] Train loss: 0.0161
2023-02-06 12:13:56 | Train | Epoch[539/600] Iteration[025/030] Train loss: 0.0161
2023-02-06 12:13:56 | Train | Epoch[539/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:13:56 | Train | Epoch[539/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:13:56 | Train | Epoch[539/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:13:56 | Train | Epoch[539/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:13:56 | Train | Epoch[539/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:13:56 | Valid | Epoch[539/600] Iteration[001/008] Valid loss: 0.0790
2023-02-06 12:13:56 | Valid | Epoch[539/600] Iteration[002/008] Valid loss: 0.0566
2023-02-06 12:13:56 | Valid | Epoch[539/600] Iteration[003/008] Valid loss: 0.0578
2023-02-06 12:13:56 | Valid | Epoch[539/600] Iteration[004/008] Valid loss: 0.0516
2023-02-06 12:13:56 | Valid | Epoch[539/600] Iteration[005/008] Valid loss: 0.0492
2023-02-06 12:13:56 | Valid | Epoch[539/600] Iteration[006/008] Valid loss: 0.0463
2023-02-06 12:13:56 | Valid | Epoch[539/600] Iteration[007/008] Valid loss: 0.0480
2023-02-06 12:13:56 | Valid | Epoch[539/600] Iteration[008/008] Valid loss: 0.0462
2023-02-06 12:13:57 | Valid | Epoch[539/600] MIou: 0.9269896392535908
2023-02-06 12:13:57 | Valid | Epoch[539/600] Pixel Accuracy: 0.9877306620279948
2023-02-06 12:13:57 | Valid | Epoch[539/600] Mean Pixel Accuracy: 0.9428177976973826
2023-02-06 12:13:57 | Stage | Epoch[539/600] Train loss:0.0163
2023-02-06 12:13:57 | Stage | Epoch[539/600] Valid loss:0.0462
2023-02-06 12:13:57 | Stage | Epoch[539/600] LR:0.0001

2023-02-06 12:13:57 | Train | Epoch[540/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 12:13:57 | Train | Epoch[540/600] Iteration[002/030] Train loss: 0.0158
2023-02-06 12:13:57 | Train | Epoch[540/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:13:57 | Train | Epoch[540/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 12:13:57 | Train | Epoch[540/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:13:57 | Train | Epoch[540/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:13:57 | Train | Epoch[540/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:13:57 | Train | Epoch[540/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:13:57 | Train | Epoch[540/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:13:58 | Train | Epoch[540/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:13:59 | Train | Epoch[540/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:13:59 | Train | Epoch[540/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:13:59 | Train | Epoch[540/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:13:59 | Train | Epoch[540/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:13:59 | Train | Epoch[540/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:13:59 | Train | Epoch[540/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:13:59 | Train | Epoch[540/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:13:59 | Valid | Epoch[540/600] Iteration[001/008] Valid loss: 0.0781
2023-02-06 12:13:59 | Valid | Epoch[540/600] Iteration[002/008] Valid loss: 0.0564
2023-02-06 12:13:59 | Valid | Epoch[540/600] Iteration[003/008] Valid loss: 0.0580
2023-02-06 12:13:59 | Valid | Epoch[540/600] Iteration[004/008] Valid loss: 0.0516
2023-02-06 12:13:59 | Valid | Epoch[540/600] Iteration[005/008] Valid loss: 0.0490
2023-02-06 12:13:59 | Valid | Epoch[540/600] Iteration[006/008] Valid loss: 0.0459
2023-02-06 12:13:59 | Valid | Epoch[540/600] Iteration[007/008] Valid loss: 0.0471
2023-02-06 12:13:59 | Valid | Epoch[540/600] Iteration[008/008] Valid loss: 0.0455
2023-02-06 12:14:00 | Valid | Epoch[540/600] MIou: 0.9257470354932787
2023-02-06 12:14:00 | Valid | Epoch[540/600] Pixel Accuracy: 0.9875361124674479
2023-02-06 12:14:00 | Valid | Epoch[540/600] Mean Pixel Accuracy: 0.9411447684980843
2023-02-06 12:14:00 | Stage | Epoch[540/600] Train loss:0.0166
2023-02-06 12:14:00 | Stage | Epoch[540/600] Valid loss:0.0455
2023-02-06 12:14:00 | Stage | Epoch[540/600] LR:0.0001

2023-02-06 12:14:00 | Train | Epoch[541/600] Iteration[001/030] Train loss: 0.0137
2023-02-06 12:14:00 | Train | Epoch[541/600] Iteration[002/030] Train loss: 0.0154
2023-02-06 12:14:00 | Train | Epoch[541/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 12:14:00 | Train | Epoch[541/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 12:14:00 | Train | Epoch[541/600] Iteration[005/030] Train loss: 0.0168
2023-02-06 12:14:00 | Train | Epoch[541/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:14:00 | Train | Epoch[541/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:14:00 | Train | Epoch[541/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:14:00 | Train | Epoch[541/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[014/030] Train loss: 0.0159
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[015/030] Train loss: 0.0158
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[016/030] Train loss: 0.0158
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[017/030] Train loss: 0.0158
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[018/030] Train loss: 0.0159
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[022/030] Train loss: 0.0161
2023-02-06 12:14:01 | Train | Epoch[541/600] Iteration[023/030] Train loss: 0.0161
2023-02-06 12:14:02 | Train | Epoch[541/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:14:02 | Train | Epoch[541/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:14:02 | Train | Epoch[541/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:14:02 | Train | Epoch[541/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:14:02 | Train | Epoch[541/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:14:02 | Train | Epoch[541/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 12:14:02 | Train | Epoch[541/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:14:02 | Valid | Epoch[541/600] Iteration[001/008] Valid loss: 0.0793
2023-02-06 12:14:02 | Valid | Epoch[541/600] Iteration[002/008] Valid loss: 0.0572
2023-02-06 12:14:02 | Valid | Epoch[541/600] Iteration[003/008] Valid loss: 0.0590
2023-02-06 12:14:02 | Valid | Epoch[541/600] Iteration[004/008] Valid loss: 0.0527
2023-02-06 12:14:02 | Valid | Epoch[541/600] Iteration[005/008] Valid loss: 0.0501
2023-02-06 12:14:02 | Valid | Epoch[541/600] Iteration[006/008] Valid loss: 0.0470
2023-02-06 12:14:02 | Valid | Epoch[541/600] Iteration[007/008] Valid loss: 0.0485
2023-02-06 12:14:02 | Valid | Epoch[541/600] Iteration[008/008] Valid loss: 0.0467
2023-02-06 12:14:03 | Valid | Epoch[541/600] MIou: 0.9274410544692621
2023-02-06 12:14:03 | Valid | Epoch[541/600] Pixel Accuracy: 0.9878031412760416
2023-02-06 12:14:03 | Valid | Epoch[541/600] Mean Pixel Accuracy: 0.9433648731042408
2023-02-06 12:14:03 | Stage | Epoch[541/600] Train loss:0.0163
2023-02-06 12:14:03 | Stage | Epoch[541/600] Valid loss:0.0467
2023-02-06 12:14:03 | Stage | Epoch[541/600] LR:0.0001

2023-02-06 12:14:03 | Train | Epoch[542/600] Iteration[001/030] Train loss: 0.0153
2023-02-06 12:14:03 | Train | Epoch[542/600] Iteration[002/030] Train loss: 0.0157
2023-02-06 12:14:03 | Train | Epoch[542/600] Iteration[003/030] Train loss: 0.0160
2023-02-06 12:14:03 | Train | Epoch[542/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:14:03 | Train | Epoch[542/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:14:03 | Train | Epoch[542/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:14:03 | Train | Epoch[542/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:14:03 | Train | Epoch[542/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:14:03 | Train | Epoch[542/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:14:04 | Train | Epoch[542/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:14:05 | Train | Epoch[542/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:14:05 | Train | Epoch[542/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:14:05 | Train | Epoch[542/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:14:05 | Train | Epoch[542/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:14:05 | Train | Epoch[542/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:14:05 | Train | Epoch[542/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:14:05 | Train | Epoch[542/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:14:05 | Valid | Epoch[542/600] Iteration[001/008] Valid loss: 0.0804
2023-02-06 12:14:05 | Valid | Epoch[542/600] Iteration[002/008] Valid loss: 0.0576
2023-02-06 12:14:05 | Valid | Epoch[542/600] Iteration[003/008] Valid loss: 0.0593
2023-02-06 12:14:05 | Valid | Epoch[542/600] Iteration[004/008] Valid loss: 0.0530
2023-02-06 12:14:05 | Valid | Epoch[542/600] Iteration[005/008] Valid loss: 0.0504
2023-02-06 12:14:05 | Valid | Epoch[542/600] Iteration[006/008] Valid loss: 0.0473
2023-02-06 12:14:05 | Valid | Epoch[542/600] Iteration[007/008] Valid loss: 0.0489
2023-02-06 12:14:06 | Valid | Epoch[542/600] Iteration[008/008] Valid loss: 0.0471
2023-02-06 12:14:06 | Valid | Epoch[542/600] MIou: 0.9282903099309439
2023-02-06 12:14:06 | Valid | Epoch[542/600] Pixel Accuracy: 0.9879417419433594
2023-02-06 12:14:06 | Valid | Epoch[542/600] Mean Pixel Accuracy: 0.9443160390108409
2023-02-06 12:14:06 | Stage | Epoch[542/600] Train loss:0.0163
2023-02-06 12:14:06 | Stage | Epoch[542/600] Valid loss:0.0471
2023-02-06 12:14:06 | Stage | Epoch[542/600] LR:0.0001

2023-02-06 12:14:06 | Train | Epoch[543/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 12:14:06 | Train | Epoch[543/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 12:14:06 | Train | Epoch[543/600] Iteration[003/030] Train loss: 0.0175
2023-02-06 12:14:06 | Train | Epoch[543/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 12:14:06 | Train | Epoch[543/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:14:06 | Train | Epoch[543/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 12:14:06 | Train | Epoch[543/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:14:06 | Train | Epoch[543/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:14:06 | Train | Epoch[543/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[019/030] Train loss: 0.0161
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:14:07 | Train | Epoch[543/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:14:08 | Train | Epoch[543/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:14:08 | Train | Epoch[543/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:14:08 | Train | Epoch[543/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:14:08 | Train | Epoch[543/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:14:08 | Train | Epoch[543/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:14:08 | Train | Epoch[543/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:14:08 | Train | Epoch[543/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:14:08 | Train | Epoch[543/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:14:08 | Valid | Epoch[543/600] Iteration[001/008] Valid loss: 0.0792
2023-02-06 12:14:08 | Valid | Epoch[543/600] Iteration[002/008] Valid loss: 0.0570
2023-02-06 12:14:08 | Valid | Epoch[543/600] Iteration[003/008] Valid loss: 0.0589
2023-02-06 12:14:08 | Valid | Epoch[543/600] Iteration[004/008] Valid loss: 0.0524
2023-02-06 12:14:08 | Valid | Epoch[543/600] Iteration[005/008] Valid loss: 0.0497
2023-02-06 12:14:09 | Valid | Epoch[543/600] Iteration[006/008] Valid loss: 0.0465
2023-02-06 12:14:09 | Valid | Epoch[543/600] Iteration[007/008] Valid loss: 0.0478
2023-02-06 12:14:09 | Valid | Epoch[543/600] Iteration[008/008] Valid loss: 0.0461
2023-02-06 12:14:09 | Valid | Epoch[543/600] MIou: 0.9268999892257548
2023-02-06 12:14:09 | Valid | Epoch[543/600] Pixel Accuracy: 0.9877230326334635
2023-02-06 12:14:09 | Valid | Epoch[543/600] Mean Pixel Accuracy: 0.942464878323598
2023-02-06 12:14:09 | Stage | Epoch[543/600] Train loss:0.0165
2023-02-06 12:14:09 | Stage | Epoch[543/600] Valid loss:0.0461
2023-02-06 12:14:09 | Stage | Epoch[543/600] LR:0.0001

2023-02-06 12:14:09 | Train | Epoch[544/600] Iteration[001/030] Train loss: 0.0166
2023-02-06 12:14:09 | Train | Epoch[544/600] Iteration[002/030] Train loss: 0.0159
2023-02-06 12:14:09 | Train | Epoch[544/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 12:14:09 | Train | Epoch[544/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:14:09 | Train | Epoch[544/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:14:09 | Train | Epoch[544/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:14:09 | Train | Epoch[544/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[009/030] Train loss: 0.0166
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:14:10 | Train | Epoch[544/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:14:11 | Train | Epoch[544/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:14:11 | Train | Epoch[544/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:14:11 | Train | Epoch[544/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:14:11 | Train | Epoch[544/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:14:11 | Train | Epoch[544/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:14:11 | Train | Epoch[544/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:14:11 | Train | Epoch[544/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:14:11 | Train | Epoch[544/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:14:11 | Train | Epoch[544/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:14:11 | Valid | Epoch[544/600] Iteration[001/008] Valid loss: 0.0794
2023-02-06 12:14:11 | Valid | Epoch[544/600] Iteration[002/008] Valid loss: 0.0569
2023-02-06 12:14:12 | Valid | Epoch[544/600] Iteration[003/008] Valid loss: 0.0588
2023-02-06 12:14:12 | Valid | Epoch[544/600] Iteration[004/008] Valid loss: 0.0522
2023-02-06 12:14:12 | Valid | Epoch[544/600] Iteration[005/008] Valid loss: 0.0496
2023-02-06 12:14:12 | Valid | Epoch[544/600] Iteration[006/008] Valid loss: 0.0465
2023-02-06 12:14:12 | Valid | Epoch[544/600] Iteration[007/008] Valid loss: 0.0478
2023-02-06 12:14:12 | Valid | Epoch[544/600] Iteration[008/008] Valid loss: 0.0461
2023-02-06 12:14:12 | Valid | Epoch[544/600] MIou: 0.927019974194393
2023-02-06 12:14:12 | Valid | Epoch[544/600] Pixel Accuracy: 0.9877395629882812
2023-02-06 12:14:12 | Valid | Epoch[544/600] Mean Pixel Accuracy: 0.9427085615575554
2023-02-06 12:14:12 | Stage | Epoch[544/600] Train loss:0.0166
2023-02-06 12:14:12 | Stage | Epoch[544/600] Valid loss:0.0461
2023-02-06 12:14:12 | Stage | Epoch[544/600] LR:0.0001

2023-02-06 12:14:12 | Train | Epoch[545/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 12:14:12 | Train | Epoch[545/600] Iteration[002/030] Train loss: 0.0184
2023-02-06 12:14:12 | Train | Epoch[545/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:14:12 | Train | Epoch[545/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:14:12 | Train | Epoch[545/600] Iteration[005/030] Train loss: 0.0160
2023-02-06 12:14:12 | Train | Epoch[545/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:14:13 | Train | Epoch[545/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:14:14 | Train | Epoch[545/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:14:14 | Train | Epoch[545/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:14:14 | Train | Epoch[545/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:14:14 | Train | Epoch[545/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:14:14 | Train | Epoch[545/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:14:14 | Train | Epoch[545/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:14:14 | Train | Epoch[545/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:14:14 | Train | Epoch[545/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:14:14 | Train | Epoch[545/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:14:14 | Train | Epoch[545/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:14:15 | Valid | Epoch[545/600] Iteration[001/008] Valid loss: 0.0831
2023-02-06 12:14:15 | Valid | Epoch[545/600] Iteration[002/008] Valid loss: 0.0595
2023-02-06 12:14:15 | Valid | Epoch[545/600] Iteration[003/008] Valid loss: 0.0612
2023-02-06 12:14:15 | Valid | Epoch[545/600] Iteration[004/008] Valid loss: 0.0546
2023-02-06 12:14:15 | Valid | Epoch[545/600] Iteration[005/008] Valid loss: 0.0519
2023-02-06 12:14:15 | Valid | Epoch[545/600] Iteration[006/008] Valid loss: 0.0486
2023-02-06 12:14:15 | Valid | Epoch[545/600] Iteration[007/008] Valid loss: 0.0501
2023-02-06 12:14:15 | Valid | Epoch[545/600] Iteration[008/008] Valid loss: 0.0482
2023-02-06 12:14:15 | Valid | Epoch[545/600] MIou: 0.9295581918084097
2023-02-06 12:14:15 | Valid | Epoch[545/600] Pixel Accuracy: 0.9881362915039062
2023-02-06 12:14:15 | Valid | Epoch[545/600] Mean Pixel Accuracy: 0.9462109847130622
2023-02-06 12:14:15 | Stage | Epoch[545/600] Train loss:0.0166
2023-02-06 12:14:15 | Stage | Epoch[545/600] Valid loss:0.0482
2023-02-06 12:14:15 | Stage | Epoch[545/600] LR:0.0001

2023-02-06 12:14:15 | Train | Epoch[546/600] Iteration[001/030] Train loss: 0.0153
2023-02-06 12:14:15 | Train | Epoch[546/600] Iteration[002/030] Train loss: 0.0174
2023-02-06 12:14:15 | Train | Epoch[546/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:14:15 | Train | Epoch[546/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:14:15 | Train | Epoch[546/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[006/030] Train loss: 0.0165
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:14:16 | Train | Epoch[546/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:14:17 | Train | Epoch[546/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:14:18 | Valid | Epoch[546/600] Iteration[001/008] Valid loss: 0.0773
2023-02-06 12:14:18 | Valid | Epoch[546/600] Iteration[002/008] Valid loss: 0.0556
2023-02-06 12:14:18 | Valid | Epoch[546/600] Iteration[003/008] Valid loss: 0.0568
2023-02-06 12:14:18 | Valid | Epoch[546/600] Iteration[004/008] Valid loss: 0.0505
2023-02-06 12:14:18 | Valid | Epoch[546/600] Iteration[005/008] Valid loss: 0.0481
2023-02-06 12:14:18 | Valid | Epoch[546/600] Iteration[006/008] Valid loss: 0.0451
2023-02-06 12:14:18 | Valid | Epoch[546/600] Iteration[007/008] Valid loss: 0.0464
2023-02-06 12:14:18 | Valid | Epoch[546/600] Iteration[008/008] Valid loss: 0.0449
2023-02-06 12:14:18 | Valid | Epoch[546/600] MIou: 0.9257855725003958
2023-02-06 12:14:18 | Valid | Epoch[546/600] Pixel Accuracy: 0.9875411987304688
2023-02-06 12:14:18 | Valid | Epoch[546/600] Mean Pixel Accuracy: 0.9412299902548215
2023-02-06 12:14:18 | Stage | Epoch[546/600] Train loss:0.0164
2023-02-06 12:14:18 | Stage | Epoch[546/600] Valid loss:0.0449
2023-02-06 12:14:18 | Stage | Epoch[546/600] LR:0.0001

2023-02-06 12:14:18 | Train | Epoch[547/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:14:18 | Train | Epoch[547/600] Iteration[002/030] Train loss: 0.0165
2023-02-06 12:14:18 | Train | Epoch[547/600] Iteration[003/030] Train loss: 0.0162
2023-02-06 12:14:18 | Train | Epoch[547/600] Iteration[004/030] Train loss: 0.0163
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[005/030] Train loss: 0.0160
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[007/030] Train loss: 0.0162
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[008/030] Train loss: 0.0163
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:14:19 | Train | Epoch[547/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:14:20 | Train | Epoch[547/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:14:21 | Valid | Epoch[547/600] Iteration[001/008] Valid loss: 0.0825
2023-02-06 12:14:21 | Valid | Epoch[547/600] Iteration[002/008] Valid loss: 0.0592
2023-02-06 12:14:21 | Valid | Epoch[547/600] Iteration[003/008] Valid loss: 0.0610
2023-02-06 12:14:21 | Valid | Epoch[547/600] Iteration[004/008] Valid loss: 0.0546
2023-02-06 12:14:21 | Valid | Epoch[547/600] Iteration[005/008] Valid loss: 0.0518
2023-02-06 12:14:21 | Valid | Epoch[547/600] Iteration[006/008] Valid loss: 0.0487
2023-02-06 12:14:21 | Valid | Epoch[547/600] Iteration[007/008] Valid loss: 0.0504
2023-02-06 12:14:21 | Valid | Epoch[547/600] Iteration[008/008] Valid loss: 0.0484
2023-02-06 12:14:21 | Valid | Epoch[547/600] MIou: 0.9295715751695264
2023-02-06 12:14:21 | Valid | Epoch[547/600] Pixel Accuracy: 0.9881426493326823
2023-02-06 12:14:21 | Valid | Epoch[547/600] Mean Pixel Accuracy: 0.9460686484021346
2023-02-06 12:14:21 | Stage | Epoch[547/600] Train loss:0.0167
2023-02-06 12:14:21 | Stage | Epoch[547/600] Valid loss:0.0484
2023-02-06 12:14:21 | Stage | Epoch[547/600] LR:0.0001

2023-02-06 12:14:21 | Train | Epoch[548/600] Iteration[001/030] Train loss: 0.0136
2023-02-06 12:14:21 | Train | Epoch[548/600] Iteration[002/030] Train loss: 0.0146
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[003/030] Train loss: 0.0156
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[004/030] Train loss: 0.0156
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[005/030] Train loss: 0.0154
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[006/030] Train loss: 0.0153
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[007/030] Train loss: 0.0151
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[008/030] Train loss: 0.0150
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[009/030] Train loss: 0.0154
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[010/030] Train loss: 0.0153
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[011/030] Train loss: 0.0156
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[012/030] Train loss: 0.0157
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[013/030] Train loss: 0.0156
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[014/030] Train loss: 0.0157
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[015/030] Train loss: 0.0158
2023-02-06 12:14:22 | Train | Epoch[548/600] Iteration[016/030] Train loss: 0.0160
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[020/030] Train loss: 0.0160
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[021/030] Train loss: 0.0160
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[022/030] Train loss: 0.0160
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[023/030] Train loss: 0.0161
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[024/030] Train loss: 0.0160
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[025/030] Train loss: 0.0161
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 12:14:23 | Train | Epoch[548/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:14:24 | Valid | Epoch[548/600] Iteration[001/008] Valid loss: 0.0805
2023-02-06 12:14:24 | Valid | Epoch[548/600] Iteration[002/008] Valid loss: 0.0576
2023-02-06 12:14:24 | Valid | Epoch[548/600] Iteration[003/008] Valid loss: 0.0585
2023-02-06 12:14:24 | Valid | Epoch[548/600] Iteration[004/008] Valid loss: 0.0524
2023-02-06 12:14:24 | Valid | Epoch[548/600] Iteration[005/008] Valid loss: 0.0498
2023-02-06 12:14:24 | Valid | Epoch[548/600] Iteration[006/008] Valid loss: 0.0468
2023-02-06 12:14:24 | Valid | Epoch[548/600] Iteration[007/008] Valid loss: 0.0485
2023-02-06 12:14:24 | Valid | Epoch[548/600] Iteration[008/008] Valid loss: 0.0468
2023-02-06 12:14:24 | Valid | Epoch[548/600] MIou: 0.92789896297571
2023-02-06 12:14:24 | Valid | Epoch[548/600] Pixel Accuracy: 0.9878718058268229
2023-02-06 12:14:24 | Valid | Epoch[548/600] Mean Pixel Accuracy: 0.9441000659361511
2023-02-06 12:14:24 | Stage | Epoch[548/600] Train loss:0.0163
2023-02-06 12:14:24 | Stage | Epoch[548/600] Valid loss:0.0468
2023-02-06 12:14:24 | Stage | Epoch[548/600] LR:0.0001

2023-02-06 12:14:24 | Train | Epoch[549/600] Iteration[001/030] Train loss: 0.0154
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[002/030] Train loss: 0.0147
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[003/030] Train loss: 0.0155
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[004/030] Train loss: 0.0163
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:14:25 | Train | Epoch[549/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:14:26 | Train | Epoch[549/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:14:27 | Train | Epoch[549/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:14:27 | Train | Epoch[549/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:14:27 | Valid | Epoch[549/600] Iteration[001/008] Valid loss: 0.0785
2023-02-06 12:14:27 | Valid | Epoch[549/600] Iteration[002/008] Valid loss: 0.0562
2023-02-06 12:14:27 | Valid | Epoch[549/600] Iteration[003/008] Valid loss: 0.0574
2023-02-06 12:14:27 | Valid | Epoch[549/600] Iteration[004/008] Valid loss: 0.0512
2023-02-06 12:14:27 | Valid | Epoch[549/600] Iteration[005/008] Valid loss: 0.0487
2023-02-06 12:14:27 | Valid | Epoch[549/600] Iteration[006/008] Valid loss: 0.0458
2023-02-06 12:14:27 | Valid | Epoch[549/600] Iteration[007/008] Valid loss: 0.0472
2023-02-06 12:14:27 | Valid | Epoch[549/600] Iteration[008/008] Valid loss: 0.0456
2023-02-06 12:14:27 | Valid | Epoch[549/600] MIou: 0.926424222454472
2023-02-06 12:14:27 | Valid | Epoch[549/600] Pixel Accuracy: 0.9876416524251302
2023-02-06 12:14:27 | Valid | Epoch[549/600] Mean Pixel Accuracy: 0.9420714223571517
2023-02-06 12:14:27 | Stage | Epoch[549/600] Train loss:0.0165
2023-02-06 12:14:27 | Stage | Epoch[549/600] Valid loss:0.0456
2023-02-06 12:14:27 | Stage | Epoch[549/600] LR:0.0001

2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[001/030] Train loss: 0.0228
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[002/030] Train loss: 0.0209
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[003/030] Train loss: 0.0189
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[005/030] Train loss: 0.0174
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:14:28 | Train | Epoch[550/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[020/030] Train loss: 0.0170
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[021/030] Train loss: 0.0171
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[022/030] Train loss: 0.0170
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:14:29 | Train | Epoch[550/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:14:30 | Train | Epoch[550/600] Iteration[028/030] Train loss: 0.0167
2023-02-06 12:14:30 | Train | Epoch[550/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:14:30 | Train | Epoch[550/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:14:30 | Valid | Epoch[550/600] Iteration[001/008] Valid loss: 0.0805
2023-02-06 12:14:30 | Valid | Epoch[550/600] Iteration[002/008] Valid loss: 0.0577
2023-02-06 12:14:30 | Valid | Epoch[550/600] Iteration[003/008] Valid loss: 0.0597
2023-02-06 12:14:30 | Valid | Epoch[550/600] Iteration[004/008] Valid loss: 0.0533
2023-02-06 12:14:30 | Valid | Epoch[550/600] Iteration[005/008] Valid loss: 0.0507
2023-02-06 12:14:30 | Valid | Epoch[550/600] Iteration[006/008] Valid loss: 0.0477
2023-02-06 12:14:30 | Valid | Epoch[550/600] Iteration[007/008] Valid loss: 0.0493
2023-02-06 12:14:30 | Valid | Epoch[550/600] Iteration[008/008] Valid loss: 0.0474
2023-02-06 12:14:30 | Valid | Epoch[550/600] MIou: 0.9284195252699674
2023-02-06 12:14:30 | Valid | Epoch[550/600] Pixel Accuracy: 0.9879608154296875
2023-02-06 12:14:30 | Valid | Epoch[550/600] Mean Pixel Accuracy: 0.9445357581722902
2023-02-06 12:14:30 | Stage | Epoch[550/600] Train loss:0.0167
2023-02-06 12:14:30 | Stage | Epoch[550/600] Valid loss:0.0474
2023-02-06 12:14:30 | Stage | Epoch[550/600] LR:0.0001

2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[001/030] Train loss: 0.0166
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[011/030] Train loss: 0.0172
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[012/030] Train loss: 0.0170
2023-02-06 12:14:31 | Train | Epoch[551/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[014/030] Train loss: 0.0171
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:14:32 | Train | Epoch[551/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:14:33 | Train | Epoch[551/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:14:33 | Train | Epoch[551/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:14:33 | Train | Epoch[551/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:14:33 | Valid | Epoch[551/600] Iteration[001/008] Valid loss: 0.0800
2023-02-06 12:14:33 | Valid | Epoch[551/600] Iteration[002/008] Valid loss: 0.0572
2023-02-06 12:14:33 | Valid | Epoch[551/600] Iteration[003/008] Valid loss: 0.0591
2023-02-06 12:14:33 | Valid | Epoch[551/600] Iteration[004/008] Valid loss: 0.0527
2023-02-06 12:14:33 | Valid | Epoch[551/600] Iteration[005/008] Valid loss: 0.0500
2023-02-06 12:14:33 | Valid | Epoch[551/600] Iteration[006/008] Valid loss: 0.0470
2023-02-06 12:14:33 | Valid | Epoch[551/600] Iteration[007/008] Valid loss: 0.0485
2023-02-06 12:14:33 | Valid | Epoch[551/600] Iteration[008/008] Valid loss: 0.0467
2023-02-06 12:14:33 | Valid | Epoch[551/600] MIou: 0.9274894594485592
2023-02-06 12:14:33 | Valid | Epoch[551/600] Pixel Accuracy: 0.9878120422363281
2023-02-06 12:14:33 | Valid | Epoch[551/600] Mean Pixel Accuracy: 0.9433824463946552
2023-02-06 12:14:33 | Stage | Epoch[551/600] Train loss:0.0165
2023-02-06 12:14:33 | Stage | Epoch[551/600] Valid loss:0.0467
2023-02-06 12:14:33 | Stage | Epoch[551/600] LR:0.0001

2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[001/030] Train loss: 0.0181
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[003/030] Train loss: 0.0175
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[006/030] Train loss: 0.0165
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:14:34 | Train | Epoch[552/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:14:35 | Train | Epoch[552/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:14:36 | Train | Epoch[552/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:14:36 | Train | Epoch[552/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:14:36 | Train | Epoch[552/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:14:36 | Train | Epoch[552/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:14:36 | Valid | Epoch[552/600] Iteration[001/008] Valid loss: 0.0766
2023-02-06 12:14:36 | Valid | Epoch[552/600] Iteration[002/008] Valid loss: 0.0552
2023-02-06 12:14:36 | Valid | Epoch[552/600] Iteration[003/008] Valid loss: 0.0566
2023-02-06 12:14:36 | Valid | Epoch[552/600] Iteration[004/008] Valid loss: 0.0504
2023-02-06 12:14:36 | Valid | Epoch[552/600] Iteration[005/008] Valid loss: 0.0479
2023-02-06 12:14:36 | Valid | Epoch[552/600] Iteration[006/008] Valid loss: 0.0450
2023-02-06 12:14:36 | Valid | Epoch[552/600] Iteration[007/008] Valid loss: 0.0463
2023-02-06 12:14:36 | Valid | Epoch[552/600] Iteration[008/008] Valid loss: 0.0447
2023-02-06 12:14:36 | Valid | Epoch[552/600] MIou: 0.9251772686645323
2023-02-06 12:14:36 | Valid | Epoch[552/600] Pixel Accuracy: 0.9874445597330729
2023-02-06 12:14:36 | Valid | Epoch[552/600] Mean Pixel Accuracy: 0.9404667405309461
2023-02-06 12:14:36 | Stage | Epoch[552/600] Train loss:0.0163
2023-02-06 12:14:36 | Stage | Epoch[552/600] Valid loss:0.0447
2023-02-06 12:14:36 | Stage | Epoch[552/600] LR:0.0001

2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[002/030] Train loss: 0.0162
2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[007/030] Train loss: 0.0162
2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[008/030] Train loss: 0.0163
2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:14:37 | Train | Epoch[553/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[017/030] Train loss: 0.0166
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:14:38 | Train | Epoch[553/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:14:39 | Train | Epoch[553/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:14:39 | Train | Epoch[553/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:14:39 | Train | Epoch[553/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:14:39 | Train | Epoch[553/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:14:39 | Train | Epoch[553/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:14:39 | Train | Epoch[553/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:14:39 | Valid | Epoch[553/600] Iteration[001/008] Valid loss: 0.0818
2023-02-06 12:14:39 | Valid | Epoch[553/600] Iteration[002/008] Valid loss: 0.0584
2023-02-06 12:14:39 | Valid | Epoch[553/600] Iteration[003/008] Valid loss: 0.0601
2023-02-06 12:14:39 | Valid | Epoch[553/600] Iteration[004/008] Valid loss: 0.0536
2023-02-06 12:14:39 | Valid | Epoch[553/600] Iteration[005/008] Valid loss: 0.0510
2023-02-06 12:14:39 | Valid | Epoch[553/600] Iteration[006/008] Valid loss: 0.0479
2023-02-06 12:14:39 | Valid | Epoch[553/600] Iteration[007/008] Valid loss: 0.0495
2023-02-06 12:14:39 | Valid | Epoch[553/600] Iteration[008/008] Valid loss: 0.0476
2023-02-06 12:14:40 | Valid | Epoch[553/600] MIou: 0.9287600706568491
2023-02-06 12:14:40 | Valid | Epoch[553/600] Pixel Accuracy: 0.9880154927571615
2023-02-06 12:14:40 | Valid | Epoch[553/600] Mean Pixel Accuracy: 0.9449525799256383
2023-02-06 12:14:40 | Stage | Epoch[553/600] Train loss:0.0164
2023-02-06 12:14:40 | Stage | Epoch[553/600] Valid loss:0.0476
2023-02-06 12:14:40 | Stage | Epoch[553/600] LR:0.0001

2023-02-06 12:14:40 | Train | Epoch[554/600] Iteration[001/030] Train loss: 0.0169
2023-02-06 12:14:40 | Train | Epoch[554/600] Iteration[002/030] Train loss: 0.0173
2023-02-06 12:14:40 | Train | Epoch[554/600] Iteration[003/030] Train loss: 0.0172
2023-02-06 12:14:40 | Train | Epoch[554/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:14:40 | Train | Epoch[554/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 12:14:40 | Train | Epoch[554/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:14:40 | Train | Epoch[554/600] Iteration[007/030] Train loss: 0.0162
2023-02-06 12:14:40 | Train | Epoch[554/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:14:40 | Train | Epoch[554/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[014/030] Train loss: 0.0159
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[022/030] Train loss: 0.0161
2023-02-06 12:14:41 | Train | Epoch[554/600] Iteration[023/030] Train loss: 0.0161
2023-02-06 12:14:42 | Train | Epoch[554/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:14:42 | Train | Epoch[554/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:14:42 | Train | Epoch[554/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:14:42 | Train | Epoch[554/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:14:42 | Train | Epoch[554/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:14:42 | Train | Epoch[554/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:14:42 | Train | Epoch[554/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:14:42 | Valid | Epoch[554/600] Iteration[001/008] Valid loss: 0.0798
2023-02-06 12:14:42 | Valid | Epoch[554/600] Iteration[002/008] Valid loss: 0.0574
2023-02-06 12:14:42 | Valid | Epoch[554/600] Iteration[003/008] Valid loss: 0.0595
2023-02-06 12:14:42 | Valid | Epoch[554/600] Iteration[004/008] Valid loss: 0.0530
2023-02-06 12:14:42 | Valid | Epoch[554/600] Iteration[005/008] Valid loss: 0.0504
2023-02-06 12:14:42 | Valid | Epoch[554/600] Iteration[006/008] Valid loss: 0.0473
2023-02-06 12:14:42 | Valid | Epoch[554/600] Iteration[007/008] Valid loss: 0.0487
2023-02-06 12:14:42 | Valid | Epoch[554/600] Iteration[008/008] Valid loss: 0.0469
2023-02-06 12:14:43 | Valid | Epoch[554/600] MIou: 0.9277308400385625
2023-02-06 12:14:43 | Valid | Epoch[554/600] Pixel Accuracy: 0.9878514607747396
2023-02-06 12:14:43 | Valid | Epoch[554/600] Mean Pixel Accuracy: 0.9436513908934971
2023-02-06 12:14:43 | Stage | Epoch[554/600] Train loss:0.0163
2023-02-06 12:14:43 | Stage | Epoch[554/600] Valid loss:0.0469
2023-02-06 12:14:43 | Stage | Epoch[554/600] LR:0.0001

2023-02-06 12:14:43 | Train | Epoch[555/600] Iteration[001/030] Train loss: 0.0170
2023-02-06 12:14:43 | Train | Epoch[555/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 12:14:43 | Train | Epoch[555/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 12:14:43 | Train | Epoch[555/600] Iteration[004/030] Train loss: 0.0172
2023-02-06 12:14:43 | Train | Epoch[555/600] Iteration[005/030] Train loss: 0.0174
2023-02-06 12:14:43 | Train | Epoch[555/600] Iteration[006/030] Train loss: 0.0171
2023-02-06 12:14:43 | Train | Epoch[555/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:14:43 | Train | Epoch[555/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:14:44 | Train | Epoch[555/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:14:45 | Train | Epoch[555/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:14:45 | Train | Epoch[555/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:14:45 | Train | Epoch[555/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:14:45 | Train | Epoch[555/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:14:45 | Train | Epoch[555/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:14:45 | Train | Epoch[555/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:14:45 | Train | Epoch[555/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:14:45 | Train | Epoch[555/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:14:45 | Valid | Epoch[555/600] Iteration[001/008] Valid loss: 0.0766
2023-02-06 12:14:45 | Valid | Epoch[555/600] Iteration[002/008] Valid loss: 0.0554
2023-02-06 12:14:45 | Valid | Epoch[555/600] Iteration[003/008] Valid loss: 0.0574
2023-02-06 12:14:45 | Valid | Epoch[555/600] Iteration[004/008] Valid loss: 0.0511
2023-02-06 12:14:46 | Valid | Epoch[555/600] Iteration[005/008] Valid loss: 0.0486
2023-02-06 12:14:46 | Valid | Epoch[555/600] Iteration[006/008] Valid loss: 0.0457
2023-02-06 12:14:46 | Valid | Epoch[555/600] Iteration[007/008] Valid loss: 0.0470
2023-02-06 12:14:46 | Valid | Epoch[555/600] Iteration[008/008] Valid loss: 0.0453
2023-02-06 12:14:46 | Valid | Epoch[555/600] MIou: 0.9254074946402799
2023-02-06 12:14:46 | Valid | Epoch[555/600] Pixel Accuracy: 0.9874788920084635
2023-02-06 12:14:46 | Valid | Epoch[555/600] Mean Pixel Accuracy: 0.9408343369469014
2023-02-06 12:14:46 | Stage | Epoch[555/600] Train loss:0.0164
2023-02-06 12:14:46 | Stage | Epoch[555/600] Valid loss:0.0453
2023-02-06 12:14:46 | Stage | Epoch[555/600] LR:0.0001

2023-02-06 12:14:46 | Train | Epoch[556/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 12:14:46 | Train | Epoch[556/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 12:14:46 | Train | Epoch[556/600] Iteration[003/030] Train loss: 0.0183
2023-02-06 12:14:46 | Train | Epoch[556/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:14:46 | Train | Epoch[556/600] Iteration[005/030] Train loss: 0.0173
2023-02-06 12:14:46 | Train | Epoch[556/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:14:46 | Train | Epoch[556/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:14:47 | Train | Epoch[556/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:14:48 | Train | Epoch[556/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:14:48 | Train | Epoch[556/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:14:48 | Train | Epoch[556/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:14:48 | Train | Epoch[556/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:14:48 | Train | Epoch[556/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:14:48 | Train | Epoch[556/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:14:48 | Train | Epoch[556/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:14:48 | Train | Epoch[556/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:14:48 | Train | Epoch[556/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:14:48 | Train | Epoch[556/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:14:48 | Valid | Epoch[556/600] Iteration[001/008] Valid loss: 0.0777
2023-02-06 12:14:49 | Valid | Epoch[556/600] Iteration[002/008] Valid loss: 0.0557
2023-02-06 12:14:49 | Valid | Epoch[556/600] Iteration[003/008] Valid loss: 0.0572
2023-02-06 12:14:49 | Valid | Epoch[556/600] Iteration[004/008] Valid loss: 0.0509
2023-02-06 12:14:49 | Valid | Epoch[556/600] Iteration[005/008] Valid loss: 0.0483
2023-02-06 12:14:49 | Valid | Epoch[556/600] Iteration[006/008] Valid loss: 0.0453
2023-02-06 12:14:49 | Valid | Epoch[556/600] Iteration[007/008] Valid loss: 0.0466
2023-02-06 12:14:49 | Valid | Epoch[556/600] Iteration[008/008] Valid loss: 0.0450
2023-02-06 12:14:49 | Valid | Epoch[556/600] MIou: 0.925209087342566
2023-02-06 12:14:49 | Valid | Epoch[556/600] Pixel Accuracy: 0.9874471028645834
2023-02-06 12:14:49 | Valid | Epoch[556/600] Mean Pixel Accuracy: 0.9405949477747277
2023-02-06 12:14:49 | Stage | Epoch[556/600] Train loss:0.0166
2023-02-06 12:14:49 | Stage | Epoch[556/600] Valid loss:0.0450
2023-02-06 12:14:49 | Stage | Epoch[556/600] LR:0.0001

2023-02-06 12:14:49 | Train | Epoch[557/600] Iteration[001/030] Train loss: 0.0144
2023-02-06 12:14:49 | Train | Epoch[557/600] Iteration[002/030] Train loss: 0.0149
2023-02-06 12:14:49 | Train | Epoch[557/600] Iteration[003/030] Train loss: 0.0157
2023-02-06 12:14:49 | Train | Epoch[557/600] Iteration[004/030] Train loss: 0.0157
2023-02-06 12:14:49 | Train | Epoch[557/600] Iteration[005/030] Train loss: 0.0155
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[006/030] Train loss: 0.0152
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[007/030] Train loss: 0.0156
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[008/030] Train loss: 0.0156
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[016/030] Train loss: 0.0160
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[018/030] Train loss: 0.0160
2023-02-06 12:14:50 | Train | Epoch[557/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:14:51 | Train | Epoch[557/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:14:52 | Valid | Epoch[557/600] Iteration[001/008] Valid loss: 0.0794
2023-02-06 12:14:52 | Valid | Epoch[557/600] Iteration[002/008] Valid loss: 0.0567
2023-02-06 12:14:52 | Valid | Epoch[557/600] Iteration[003/008] Valid loss: 0.0583
2023-02-06 12:14:52 | Valid | Epoch[557/600] Iteration[004/008] Valid loss: 0.0519
2023-02-06 12:14:52 | Valid | Epoch[557/600] Iteration[005/008] Valid loss: 0.0493
2023-02-06 12:14:52 | Valid | Epoch[557/600] Iteration[006/008] Valid loss: 0.0462
2023-02-06 12:14:52 | Valid | Epoch[557/600] Iteration[007/008] Valid loss: 0.0476
2023-02-06 12:14:52 | Valid | Epoch[557/600] Iteration[008/008] Valid loss: 0.0460
2023-02-06 12:14:52 | Valid | Epoch[557/600] MIou: 0.9266117499787963
2023-02-06 12:14:52 | Valid | Epoch[557/600] Pixel Accuracy: 0.9876708984375
2023-02-06 12:14:52 | Valid | Epoch[557/600] Mean Pixel Accuracy: 0.9423284351303214
2023-02-06 12:14:52 | Stage | Epoch[557/600] Train loss:0.0165
2023-02-06 12:14:52 | Stage | Epoch[557/600] Valid loss:0.0460
2023-02-06 12:14:52 | Stage | Epoch[557/600] LR:0.0001

2023-02-06 12:14:52 | Train | Epoch[558/600] Iteration[001/030] Train loss: 0.0168
2023-02-06 12:14:52 | Train | Epoch[558/600] Iteration[002/030] Train loss: 0.0171
2023-02-06 12:14:52 | Train | Epoch[558/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:14:52 | Train | Epoch[558/600] Iteration[004/030] Train loss: 0.0161
2023-02-06 12:14:52 | Train | Epoch[558/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[012/030] Train loss: 0.0168
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:14:53 | Train | Epoch[558/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:14:54 | Train | Epoch[558/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:14:55 | Valid | Epoch[558/600] Iteration[001/008] Valid loss: 0.0820
2023-02-06 12:14:55 | Valid | Epoch[558/600] Iteration[002/008] Valid loss: 0.0587
2023-02-06 12:14:55 | Valid | Epoch[558/600] Iteration[003/008] Valid loss: 0.0604
2023-02-06 12:14:55 | Valid | Epoch[558/600] Iteration[004/008] Valid loss: 0.0539
2023-02-06 12:14:55 | Valid | Epoch[558/600] Iteration[005/008] Valid loss: 0.0512
2023-02-06 12:14:55 | Valid | Epoch[558/600] Iteration[006/008] Valid loss: 0.0481
2023-02-06 12:14:55 | Valid | Epoch[558/600] Iteration[007/008] Valid loss: 0.0496
2023-02-06 12:14:55 | Valid | Epoch[558/600] Iteration[008/008] Valid loss: 0.0478
2023-02-06 12:14:55 | Valid | Epoch[558/600] MIou: 0.9286090790513635
2023-02-06 12:14:55 | Valid | Epoch[558/600] Pixel Accuracy: 0.9879900614420573
2023-02-06 12:14:55 | Valid | Epoch[558/600] Mean Pixel Accuracy: 0.9448117923599961
2023-02-06 12:14:55 | Stage | Epoch[558/600] Train loss:0.0164
2023-02-06 12:14:55 | Stage | Epoch[558/600] Valid loss:0.0478
2023-02-06 12:14:55 | Stage | Epoch[558/600] LR:0.0001

2023-02-06 12:14:55 | Train | Epoch[559/600] Iteration[001/030] Train loss: 0.0147
2023-02-06 12:14:55 | Train | Epoch[559/600] Iteration[002/030] Train loss: 0.0147
2023-02-06 12:14:55 | Train | Epoch[559/600] Iteration[003/030] Train loss: 0.0153
2023-02-06 12:14:55 | Train | Epoch[559/600] Iteration[004/030] Train loss: 0.0155
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[006/030] Train loss: 0.0160
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[011/030] Train loss: 0.0158
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[012/030] Train loss: 0.0158
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[014/030] Train loss: 0.0158
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[015/030] Train loss: 0.0158
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[016/030] Train loss: 0.0159
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[017/030] Train loss: 0.0159
2023-02-06 12:14:56 | Train | Epoch[559/600] Iteration[018/030] Train loss: 0.0160
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[019/030] Train loss: 0.0161
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[020/030] Train loss: 0.0160
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:14:57 | Train | Epoch[559/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:14:58 | Valid | Epoch[559/600] Iteration[001/008] Valid loss: 0.0829
2023-02-06 12:14:58 | Valid | Epoch[559/600] Iteration[002/008] Valid loss: 0.0591
2023-02-06 12:14:58 | Valid | Epoch[559/600] Iteration[003/008] Valid loss: 0.0605
2023-02-06 12:14:58 | Valid | Epoch[559/600] Iteration[004/008] Valid loss: 0.0541
2023-02-06 12:14:58 | Valid | Epoch[559/600] Iteration[005/008] Valid loss: 0.0514
2023-02-06 12:14:58 | Valid | Epoch[559/600] Iteration[006/008] Valid loss: 0.0484
2023-02-06 12:14:58 | Valid | Epoch[559/600] Iteration[007/008] Valid loss: 0.0500
2023-02-06 12:14:58 | Valid | Epoch[559/600] Iteration[008/008] Valid loss: 0.0481
2023-02-06 12:14:58 | Valid | Epoch[559/600] MIou: 0.929432883540027
2023-02-06 12:14:58 | Valid | Epoch[559/600] Pixel Accuracy: 0.9881210327148438
2023-02-06 12:14:58 | Valid | Epoch[559/600] Mean Pixel Accuracy: 0.9458728933131937
2023-02-06 12:14:58 | Stage | Epoch[559/600] Train loss:0.0164
2023-02-06 12:14:58 | Stage | Epoch[559/600] Valid loss:0.0481
2023-02-06 12:14:58 | Stage | Epoch[559/600] LR:0.0001

2023-02-06 12:14:58 | Train | Epoch[560/600] Iteration[001/030] Train loss: 0.0192
2023-02-06 12:14:58 | Train | Epoch[560/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 12:14:58 | Train | Epoch[560/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 12:14:58 | Train | Epoch[560/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[005/030] Train loss: 0.0182
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[006/030] Train loss: 0.0180
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[007/030] Train loss: 0.0183
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[008/030] Train loss: 0.0182
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[009/030] Train loss: 0.0179
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[010/030] Train loss: 0.0178
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[011/030] Train loss: 0.0174
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[012/030] Train loss: 0.0175
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[013/030] Train loss: 0.0174
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[014/030] Train loss: 0.0173
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[015/030] Train loss: 0.0173
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[016/030] Train loss: 0.0172
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[017/030] Train loss: 0.0173
2023-02-06 12:14:59 | Train | Epoch[560/600] Iteration[018/030] Train loss: 0.0173
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[019/030] Train loss: 0.0172
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[020/030] Train loss: 0.0172
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[021/030] Train loss: 0.0171
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[022/030] Train loss: 0.0172
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[023/030] Train loss: 0.0170
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:15:00 | Train | Epoch[560/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:15:01 | Valid | Epoch[560/600] Iteration[001/008] Valid loss: 0.0802
2023-02-06 12:15:01 | Valid | Epoch[560/600] Iteration[002/008] Valid loss: 0.0577
2023-02-06 12:15:01 | Valid | Epoch[560/600] Iteration[003/008] Valid loss: 0.0599
2023-02-06 12:15:01 | Valid | Epoch[560/600] Iteration[004/008] Valid loss: 0.0534
2023-02-06 12:15:01 | Valid | Epoch[560/600] Iteration[005/008] Valid loss: 0.0507
2023-02-06 12:15:01 | Valid | Epoch[560/600] Iteration[006/008] Valid loss: 0.0476
2023-02-06 12:15:01 | Valid | Epoch[560/600] Iteration[007/008] Valid loss: 0.0490
2023-02-06 12:15:01 | Valid | Epoch[560/600] Iteration[008/008] Valid loss: 0.0472
2023-02-06 12:15:01 | Valid | Epoch[560/600] MIou: 0.9277629184191001
2023-02-06 12:15:01 | Valid | Epoch[560/600] Pixel Accuracy: 0.98785400390625
2023-02-06 12:15:01 | Valid | Epoch[560/600] Mean Pixel Accuracy: 0.9437859386087908
2023-02-06 12:15:01 | Stage | Epoch[560/600] Train loss:0.0166
2023-02-06 12:15:01 | Stage | Epoch[560/600] Valid loss:0.0472
2023-02-06 12:15:01 | Stage | Epoch[560/600] LR:0.0001

2023-02-06 12:15:01 | Train | Epoch[561/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 12:15:01 | Train | Epoch[561/600] Iteration[002/030] Train loss: 0.0168
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[004/030] Train loss: 0.0159
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[005/030] Train loss: 0.0155
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[006/030] Train loss: 0.0157
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[007/030] Train loss: 0.0159
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[008/030] Train loss: 0.0156
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[009/030] Train loss: 0.0154
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[010/030] Train loss: 0.0155
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[011/030] Train loss: 0.0155
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[012/030] Train loss: 0.0155
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[013/030] Train loss: 0.0156
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[014/030] Train loss: 0.0155
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[015/030] Train loss: 0.0157
2023-02-06 12:15:02 | Train | Epoch[561/600] Iteration[016/030] Train loss: 0.0158
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[017/030] Train loss: 0.0159
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[018/030] Train loss: 0.0159
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[019/030] Train loss: 0.0159
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[020/030] Train loss: 0.0160
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[022/030] Train loss: 0.0161
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[023/030] Train loss: 0.0161
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:15:03 | Train | Epoch[561/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:15:04 | Valid | Epoch[561/600] Iteration[001/008] Valid loss: 0.0788
2023-02-06 12:15:04 | Valid | Epoch[561/600] Iteration[002/008] Valid loss: 0.0567
2023-02-06 12:15:04 | Valid | Epoch[561/600] Iteration[003/008] Valid loss: 0.0583
2023-02-06 12:15:04 | Valid | Epoch[561/600] Iteration[004/008] Valid loss: 0.0520
2023-02-06 12:15:04 | Valid | Epoch[561/600] Iteration[005/008] Valid loss: 0.0496
2023-02-06 12:15:04 | Valid | Epoch[561/600] Iteration[006/008] Valid loss: 0.0467
2023-02-06 12:15:04 | Valid | Epoch[561/600] Iteration[007/008] Valid loss: 0.0483
2023-02-06 12:15:04 | Valid | Epoch[561/600] Iteration[008/008] Valid loss: 0.0465
2023-02-06 12:15:04 | Valid | Epoch[561/600] MIou: 0.9270358861579135
2023-02-06 12:15:04 | Valid | Epoch[561/600] Pixel Accuracy: 0.987738291422526
2023-02-06 12:15:04 | Valid | Epoch[561/600] Mean Pixel Accuracy: 0.9428663744385873
2023-02-06 12:15:04 | Stage | Epoch[561/600] Train loss:0.0164
2023-02-06 12:15:04 | Stage | Epoch[561/600] Valid loss:0.0465
2023-02-06 12:15:04 | Stage | Epoch[561/600] LR:0.0001

2023-02-06 12:15:04 | Train | Epoch[562/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:15:04 | Train | Epoch[562/600] Iteration[002/030] Train loss: 0.0161
2023-02-06 12:15:04 | Train | Epoch[562/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[004/030] Train loss: 0.0157
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[006/030] Train loss: 0.0160
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[007/030] Train loss: 0.0160
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[009/030] Train loss: 0.0159
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:15:05 | Train | Epoch[562/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[024/030] Train loss: 0.0168
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[027/030] Train loss: 0.0168
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[028/030] Train loss: 0.0168
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[029/030] Train loss: 0.0167
2023-02-06 12:15:06 | Train | Epoch[562/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 12:15:07 | Valid | Epoch[562/600] Iteration[001/008] Valid loss: 0.0840
2023-02-06 12:15:07 | Valid | Epoch[562/600] Iteration[002/008] Valid loss: 0.0598
2023-02-06 12:15:07 | Valid | Epoch[562/600] Iteration[003/008] Valid loss: 0.0609
2023-02-06 12:15:07 | Valid | Epoch[562/600] Iteration[004/008] Valid loss: 0.0546
2023-02-06 12:15:07 | Valid | Epoch[562/600] Iteration[005/008] Valid loss: 0.0519
2023-02-06 12:15:07 | Valid | Epoch[562/600] Iteration[006/008] Valid loss: 0.0487
2023-02-06 12:15:07 | Valid | Epoch[562/600] Iteration[007/008] Valid loss: 0.0504
2023-02-06 12:15:07 | Valid | Epoch[562/600] Iteration[008/008] Valid loss: 0.0485
2023-02-06 12:15:07 | Valid | Epoch[562/600] MIou: 0.9298489511714332
2023-02-06 12:15:07 | Valid | Epoch[562/600] Pixel Accuracy: 0.9881807963053385
2023-02-06 12:15:07 | Valid | Epoch[562/600] Mean Pixel Accuracy: 0.9466539175698105
2023-02-06 12:15:07 | Stage | Epoch[562/600] Train loss:0.0167
2023-02-06 12:15:07 | Stage | Epoch[562/600] Valid loss:0.0485
2023-02-06 12:15:07 | Stage | Epoch[562/600] LR:0.0001

2023-02-06 12:15:07 | Train | Epoch[563/600] Iteration[001/030] Train loss: 0.0140
2023-02-06 12:15:07 | Train | Epoch[563/600] Iteration[002/030] Train loss: 0.0149
2023-02-06 12:15:07 | Train | Epoch[563/600] Iteration[003/030] Train loss: 0.0148
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[004/030] Train loss: 0.0151
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[005/030] Train loss: 0.0154
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[006/030] Train loss: 0.0157
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:15:08 | Train | Epoch[563/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 12:15:09 | Train | Epoch[563/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:15:10 | Valid | Epoch[563/600] Iteration[001/008] Valid loss: 0.0811
2023-02-06 12:15:10 | Valid | Epoch[563/600] Iteration[002/008] Valid loss: 0.0580
2023-02-06 12:15:10 | Valid | Epoch[563/600] Iteration[003/008] Valid loss: 0.0595
2023-02-06 12:15:10 | Valid | Epoch[563/600] Iteration[004/008] Valid loss: 0.0531
2023-02-06 12:15:10 | Valid | Epoch[563/600] Iteration[005/008] Valid loss: 0.0504
2023-02-06 12:15:10 | Valid | Epoch[563/600] Iteration[006/008] Valid loss: 0.0473
2023-02-06 12:15:10 | Valid | Epoch[563/600] Iteration[007/008] Valid loss: 0.0489
2023-02-06 12:15:10 | Valid | Epoch[563/600] Iteration[008/008] Valid loss: 0.0471
2023-02-06 12:15:10 | Valid | Epoch[563/600] MIou: 0.9283244348216395
2023-02-06 12:15:10 | Valid | Epoch[563/600] Pixel Accuracy: 0.9879430135091146
2023-02-06 12:15:10 | Valid | Epoch[563/600] Mean Pixel Accuracy: 0.9445132925344855
2023-02-06 12:15:10 | Stage | Epoch[563/600] Train loss:0.0163
2023-02-06 12:15:10 | Stage | Epoch[563/600] Valid loss:0.0471
2023-02-06 12:15:10 | Stage | Epoch[563/600] LR:0.0001

2023-02-06 12:15:10 | Train | Epoch[564/600] Iteration[001/030] Train loss: 0.0131
2023-02-06 12:15:10 | Train | Epoch[564/600] Iteration[002/030] Train loss: 0.0161
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[003/030] Train loss: 0.0159
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[004/030] Train loss: 0.0156
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[005/030] Train loss: 0.0153
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[006/030] Train loss: 0.0158
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:15:11 | Train | Epoch[564/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:15:12 | Train | Epoch[564/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:15:13 | Valid | Epoch[564/600] Iteration[001/008] Valid loss: 0.0773
2023-02-06 12:15:13 | Valid | Epoch[564/600] Iteration[002/008] Valid loss: 0.0560
2023-02-06 12:15:13 | Valid | Epoch[564/600] Iteration[003/008] Valid loss: 0.0576
2023-02-06 12:15:13 | Valid | Epoch[564/600] Iteration[004/008] Valid loss: 0.0514
2023-02-06 12:15:13 | Valid | Epoch[564/600] Iteration[005/008] Valid loss: 0.0488
2023-02-06 12:15:13 | Valid | Epoch[564/600] Iteration[006/008] Valid loss: 0.0459
2023-02-06 12:15:13 | Valid | Epoch[564/600] Iteration[007/008] Valid loss: 0.0472
2023-02-06 12:15:13 | Valid | Epoch[564/600] Iteration[008/008] Valid loss: 0.0455
2023-02-06 12:15:13 | Valid | Epoch[564/600] MIou: 0.9258449569219332
2023-02-06 12:15:13 | Valid | Epoch[564/600] Pixel Accuracy: 0.9875500996907552
2023-02-06 12:15:13 | Valid | Epoch[564/600] Mean Pixel Accuracy: 0.9413236492033807
2023-02-06 12:15:13 | Stage | Epoch[564/600] Train loss:0.0165
2023-02-06 12:15:13 | Stage | Epoch[564/600] Valid loss:0.0455
2023-02-06 12:15:13 | Stage | Epoch[564/600] LR:0.0001

2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[001/030] Train loss: 0.0157
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[002/030] Train loss: 0.0164
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[005/030] Train loss: 0.0155
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[006/030] Train loss: 0.0156
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[007/030] Train loss: 0.0156
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[008/030] Train loss: 0.0156
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[009/030] Train loss: 0.0155
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[010/030] Train loss: 0.0153
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[011/030] Train loss: 0.0153
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[012/030] Train loss: 0.0155
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 12:15:14 | Train | Epoch[565/600] Iteration[014/030] Train loss: 0.0159
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[015/030] Train loss: 0.0160
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[019/030] Train loss: 0.0161
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[022/030] Train loss: 0.0161
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:15:15 | Train | Epoch[565/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:15:16 | Train | Epoch[565/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:15:16 | Train | Epoch[565/600] Iteration[030/030] Train loss: 0.0162
2023-02-06 12:15:16 | Valid | Epoch[565/600] Iteration[001/008] Valid loss: 0.0768
2023-02-06 12:15:16 | Valid | Epoch[565/600] Iteration[002/008] Valid loss: 0.0557
2023-02-06 12:15:16 | Valid | Epoch[565/600] Iteration[003/008] Valid loss: 0.0574
2023-02-06 12:15:16 | Valid | Epoch[565/600] Iteration[004/008] Valid loss: 0.0513
2023-02-06 12:15:16 | Valid | Epoch[565/600] Iteration[005/008] Valid loss: 0.0488
2023-02-06 12:15:16 | Valid | Epoch[565/600] Iteration[006/008] Valid loss: 0.0459
2023-02-06 12:15:16 | Valid | Epoch[565/600] Iteration[007/008] Valid loss: 0.0473
2023-02-06 12:15:16 | Valid | Epoch[565/600] Iteration[008/008] Valid loss: 0.0456
2023-02-06 12:15:16 | Valid | Epoch[565/600] MIou: 0.9255453348184914
2023-02-06 12:15:16 | Valid | Epoch[565/600] Pixel Accuracy: 0.9875005086263021
2023-02-06 12:15:16 | Valid | Epoch[565/600] Mean Pixel Accuracy: 0.941017411092818
2023-02-06 12:15:16 | Stage | Epoch[565/600] Train loss:0.0162
2023-02-06 12:15:16 | Stage | Epoch[565/600] Valid loss:0.0456
2023-02-06 12:15:16 | Stage | Epoch[565/600] LR:0.0001

2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[001/030] Train loss: 0.0150
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[002/030] Train loss: 0.0152
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[007/030] Train loss: 0.0159
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[008/030] Train loss: 0.0157
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[009/030] Train loss: 0.0157
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[013/030] Train loss: 0.0160
2023-02-06 12:15:17 | Train | Epoch[566/600] Iteration[014/030] Train loss: 0.0159
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:15:18 | Train | Epoch[566/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:15:19 | Train | Epoch[566/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:15:19 | Train | Epoch[566/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:15:19 | Valid | Epoch[566/600] Iteration[001/008] Valid loss: 0.0815
2023-02-06 12:15:19 | Valid | Epoch[566/600] Iteration[002/008] Valid loss: 0.0584
2023-02-06 12:15:19 | Valid | Epoch[566/600] Iteration[003/008] Valid loss: 0.0599
2023-02-06 12:15:19 | Valid | Epoch[566/600] Iteration[004/008] Valid loss: 0.0536
2023-02-06 12:15:19 | Valid | Epoch[566/600] Iteration[005/008] Valid loss: 0.0510
2023-02-06 12:15:19 | Valid | Epoch[566/600] Iteration[006/008] Valid loss: 0.0479
2023-02-06 12:15:19 | Valid | Epoch[566/600] Iteration[007/008] Valid loss: 0.0495
2023-02-06 12:15:19 | Valid | Epoch[566/600] Iteration[008/008] Valid loss: 0.0477
2023-02-06 12:15:19 | Valid | Epoch[566/600] MIou: 0.928892281636216
2023-02-06 12:15:19 | Valid | Epoch[566/600] Pixel Accuracy: 0.9880358378092448
2023-02-06 12:15:19 | Valid | Epoch[566/600] Mean Pixel Accuracy: 0.945147636107809
2023-02-06 12:15:19 | Stage | Epoch[566/600] Train loss:0.0166
2023-02-06 12:15:19 | Stage | Epoch[566/600] Valid loss:0.0477
2023-02-06 12:15:19 | Stage | Epoch[566/600] LR:0.0001

2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[001/030] Train loss: 0.0133
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[002/030] Train loss: 0.0155
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[009/030] Train loss: 0.0163
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[011/030] Train loss: 0.0161
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[013/030] Train loss: 0.0160
2023-02-06 12:15:20 | Train | Epoch[567/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[016/030] Train loss: 0.0160
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[018/030] Train loss: 0.0159
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:15:21 | Train | Epoch[567/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:15:22 | Train | Epoch[567/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:15:22 | Train | Epoch[567/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:15:22 | Train | Epoch[567/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:15:22 | Valid | Epoch[567/600] Iteration[001/008] Valid loss: 0.0850
2023-02-06 12:15:22 | Valid | Epoch[567/600] Iteration[002/008] Valid loss: 0.0605
2023-02-06 12:15:22 | Valid | Epoch[567/600] Iteration[003/008] Valid loss: 0.0623
2023-02-06 12:15:22 | Valid | Epoch[567/600] Iteration[004/008] Valid loss: 0.0556
2023-02-06 12:15:22 | Valid | Epoch[567/600] Iteration[005/008] Valid loss: 0.0527
2023-02-06 12:15:22 | Valid | Epoch[567/600] Iteration[006/008] Valid loss: 0.0493
2023-02-06 12:15:22 | Valid | Epoch[567/600] Iteration[007/008] Valid loss: 0.0510
2023-02-06 12:15:22 | Valid | Epoch[567/600] Iteration[008/008] Valid loss: 0.0491
2023-02-06 12:15:22 | Valid | Epoch[567/600] MIou: 0.9299654789829255
2023-02-06 12:15:22 | Valid | Epoch[567/600] Pixel Accuracy: 0.9881998697916666
2023-02-06 12:15:22 | Valid | Epoch[567/600] Mean Pixel Accuracy: 0.9467848701300905
2023-02-06 12:15:22 | Stage | Epoch[567/600] Train loss:0.0164
2023-02-06 12:15:22 | Stage | Epoch[567/600] Valid loss:0.0491
2023-02-06 12:15:22 | Stage | Epoch[567/600] LR:0.0001

2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[001/030] Train loss: 0.0160
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[002/030] Train loss: 0.0160
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[003/030] Train loss: 0.0155
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[004/030] Train loss: 0.0154
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[005/030] Train loss: 0.0154
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[006/030] Train loss: 0.0153
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[007/030] Train loss: 0.0152
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[008/030] Train loss: 0.0155
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[009/030] Train loss: 0.0157
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:15:23 | Train | Epoch[568/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:15:24 | Train | Epoch[568/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:15:25 | Train | Epoch[568/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:15:25 | Train | Epoch[568/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:15:25 | Train | Epoch[568/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:15:25 | Train | Epoch[568/600] Iteration[030/030] Train loss: 0.0162
2023-02-06 12:15:25 | Valid | Epoch[568/600] Iteration[001/008] Valid loss: 0.0792
2023-02-06 12:15:25 | Valid | Epoch[568/600] Iteration[002/008] Valid loss: 0.0569
2023-02-06 12:15:25 | Valid | Epoch[568/600] Iteration[003/008] Valid loss: 0.0586
2023-02-06 12:15:25 | Valid | Epoch[568/600] Iteration[004/008] Valid loss: 0.0523
2023-02-06 12:15:25 | Valid | Epoch[568/600] Iteration[005/008] Valid loss: 0.0497
2023-02-06 12:15:25 | Valid | Epoch[568/600] Iteration[006/008] Valid loss: 0.0467
2023-02-06 12:15:25 | Valid | Epoch[568/600] Iteration[007/008] Valid loss: 0.0482
2023-02-06 12:15:25 | Valid | Epoch[568/600] Iteration[008/008] Valid loss: 0.0464
2023-02-06 12:15:25 | Valid | Epoch[568/600] MIou: 0.9268644609177881
2023-02-06 12:15:25 | Valid | Epoch[568/600] Pixel Accuracy: 0.987707773844401
2023-02-06 12:15:25 | Valid | Epoch[568/600] Mean Pixel Accuracy: 0.9427671745464495
2023-02-06 12:15:25 | Stage | Epoch[568/600] Train loss:0.0162
2023-02-06 12:15:25 | Stage | Epoch[568/600] Valid loss:0.0464
2023-02-06 12:15:25 | Stage | Epoch[568/600] LR:0.0001

2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[002/030] Train loss: 0.0150
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[003/030] Train loss: 0.0158
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[007/030] Train loss: 0.0161
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[009/030] Train loss: 0.0160
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 12:15:26 | Train | Epoch[569/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[014/030] Train loss: 0.0159
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[015/030] Train loss: 0.0159
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[017/030] Train loss: 0.0161
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[019/030] Train loss: 0.0161
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[020/030] Train loss: 0.0159
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[021/030] Train loss: 0.0159
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[022/030] Train loss: 0.0159
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[023/030] Train loss: 0.0159
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[024/030] Train loss: 0.0161
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[025/030] Train loss: 0.0160
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[026/030] Train loss: 0.0161
2023-02-06 12:15:27 | Train | Epoch[569/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:15:28 | Train | Epoch[569/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:15:28 | Train | Epoch[569/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:15:28 | Train | Epoch[569/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:15:28 | Valid | Epoch[569/600] Iteration[001/008] Valid loss: 0.0789
2023-02-06 12:15:28 | Valid | Epoch[569/600] Iteration[002/008] Valid loss: 0.0567
2023-02-06 12:15:28 | Valid | Epoch[569/600] Iteration[003/008] Valid loss: 0.0582
2023-02-06 12:15:28 | Valid | Epoch[569/600] Iteration[004/008] Valid loss: 0.0519
2023-02-06 12:15:28 | Valid | Epoch[569/600] Iteration[005/008] Valid loss: 0.0493
2023-02-06 12:15:28 | Valid | Epoch[569/600] Iteration[006/008] Valid loss: 0.0463
2023-02-06 12:15:28 | Valid | Epoch[569/600] Iteration[007/008] Valid loss: 0.0477
2023-02-06 12:15:28 | Valid | Epoch[569/600] Iteration[008/008] Valid loss: 0.0460
2023-02-06 12:15:28 | Valid | Epoch[569/600] MIou: 0.9263762186388191
2023-02-06 12:15:28 | Valid | Epoch[569/600] Pixel Accuracy: 0.9876302083333334
2023-02-06 12:15:28 | Valid | Epoch[569/600] Mean Pixel Accuracy: 0.9421475583258785
2023-02-06 12:15:28 | Stage | Epoch[569/600] Train loss:0.0163
2023-02-06 12:15:28 | Stage | Epoch[569/600] Valid loss:0.0460
2023-02-06 12:15:28 | Stage | Epoch[569/600] LR:0.0001

2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[001/030] Train loss: 0.0153
2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[002/030] Train loss: 0.0156
2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[003/030] Train loss: 0.0152
2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[004/030] Train loss: 0.0158
2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[007/030] Train loss: 0.0159
2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[008/030] Train loss: 0.0158
2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[009/030] Train loss: 0.0157
2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 12:15:29 | Train | Epoch[570/600] Iteration[011/030] Train loss: 0.0158
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:15:30 | Train | Epoch[570/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:15:31 | Train | Epoch[570/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:15:31 | Train | Epoch[570/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:15:31 | Train | Epoch[570/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:15:31 | Train | Epoch[570/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:15:31 | Train | Epoch[570/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:15:31 | Valid | Epoch[570/600] Iteration[001/008] Valid loss: 0.0821
2023-02-06 12:15:31 | Valid | Epoch[570/600] Iteration[002/008] Valid loss: 0.0585
2023-02-06 12:15:31 | Valid | Epoch[570/600] Iteration[003/008] Valid loss: 0.0602
2023-02-06 12:15:31 | Valid | Epoch[570/600] Iteration[004/008] Valid loss: 0.0538
2023-02-06 12:15:31 | Valid | Epoch[570/600] Iteration[005/008] Valid loss: 0.0511
2023-02-06 12:15:31 | Valid | Epoch[570/600] Iteration[006/008] Valid loss: 0.0480
2023-02-06 12:15:31 | Valid | Epoch[570/600] Iteration[007/008] Valid loss: 0.0497
2023-02-06 12:15:31 | Valid | Epoch[570/600] Iteration[008/008] Valid loss: 0.0478
2023-02-06 12:15:31 | Valid | Epoch[570/600] MIou: 0.9289691472344068
2023-02-06 12:15:31 | Valid | Epoch[570/600] Pixel Accuracy: 0.988043467203776
2023-02-06 12:15:31 | Valid | Epoch[570/600] Mean Pixel Accuracy: 0.9454181293519366
2023-02-06 12:15:31 | Stage | Epoch[570/600] Train loss:0.0164
2023-02-06 12:15:31 | Stage | Epoch[570/600] Valid loss:0.0478
2023-02-06 12:15:31 | Stage | Epoch[570/600] LR:0.0001

2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[002/030] Train loss: 0.0165
2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[005/030] Train loss: 0.0162
2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[006/030] Train loss: 0.0162
2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[007/030] Train loss: 0.0161
2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[009/030] Train loss: 0.0160
2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:15:32 | Train | Epoch[571/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[016/030] Train loss: 0.0160
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[018/030] Train loss: 0.0159
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:15:33 | Train | Epoch[571/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:15:34 | Train | Epoch[571/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:15:34 | Train | Epoch[571/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:15:34 | Train | Epoch[571/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:15:34 | Train | Epoch[571/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:15:34 | Train | Epoch[571/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:15:34 | Valid | Epoch[571/600] Iteration[001/008] Valid loss: 0.0789
2023-02-06 12:15:34 | Valid | Epoch[571/600] Iteration[002/008] Valid loss: 0.0567
2023-02-06 12:15:34 | Valid | Epoch[571/600] Iteration[003/008] Valid loss: 0.0581
2023-02-06 12:15:34 | Valid | Epoch[571/600] Iteration[004/008] Valid loss: 0.0518
2023-02-06 12:15:34 | Valid | Epoch[571/600] Iteration[005/008] Valid loss: 0.0491
2023-02-06 12:15:34 | Valid | Epoch[571/600] Iteration[006/008] Valid loss: 0.0461
2023-02-06 12:15:34 | Valid | Epoch[571/600] Iteration[007/008] Valid loss: 0.0474
2023-02-06 12:15:34 | Valid | Epoch[571/600] Iteration[008/008] Valid loss: 0.0458
2023-02-06 12:15:34 | Valid | Epoch[571/600] MIou: 0.9263504353522415
2023-02-06 12:15:34 | Valid | Epoch[571/600] Pixel Accuracy: 0.9876289367675781
2023-02-06 12:15:34 | Valid | Epoch[571/600] Mean Pixel Accuracy: 0.9420137095173547
2023-02-06 12:15:34 | Stage | Epoch[571/600] Train loss:0.0164
2023-02-06 12:15:34 | Stage | Epoch[571/600] Valid loss:0.0458
2023-02-06 12:15:34 | Stage | Epoch[571/600] LR:0.0001

2023-02-06 12:15:35 | Train | Epoch[572/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 12:15:35 | Train | Epoch[572/600] Iteration[002/030] Train loss: 0.0165
2023-02-06 12:15:35 | Train | Epoch[572/600] Iteration[003/030] Train loss: 0.0154
2023-02-06 12:15:35 | Train | Epoch[572/600] Iteration[004/030] Train loss: 0.0152
2023-02-06 12:15:35 | Train | Epoch[572/600] Iteration[005/030] Train loss: 0.0154
2023-02-06 12:15:35 | Train | Epoch[572/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:15:35 | Train | Epoch[572/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 12:15:35 | Train | Epoch[572/600] Iteration[008/030] Train loss: 0.0174
2023-02-06 12:15:35 | Train | Epoch[572/600] Iteration[009/030] Train loss: 0.0174
2023-02-06 12:15:35 | Train | Epoch[572/600] Iteration[010/030] Train loss: 0.0173
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[012/030] Train loss: 0.0170
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[015/030] Train loss: 0.0170
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[022/030] Train loss: 0.0167
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:15:36 | Train | Epoch[572/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:15:37 | Train | Epoch[572/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:15:37 | Train | Epoch[572/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:15:37 | Train | Epoch[572/600] Iteration[027/030] Train loss: 0.0167
2023-02-06 12:15:37 | Train | Epoch[572/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:15:37 | Train | Epoch[572/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:15:37 | Train | Epoch[572/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:15:37 | Valid | Epoch[572/600] Iteration[001/008] Valid loss: 0.0801
2023-02-06 12:15:37 | Valid | Epoch[572/600] Iteration[002/008] Valid loss: 0.0576
2023-02-06 12:15:37 | Valid | Epoch[572/600] Iteration[003/008] Valid loss: 0.0598
2023-02-06 12:15:37 | Valid | Epoch[572/600] Iteration[004/008] Valid loss: 0.0532
2023-02-06 12:15:37 | Valid | Epoch[572/600] Iteration[005/008] Valid loss: 0.0506
2023-02-06 12:15:37 | Valid | Epoch[572/600] Iteration[006/008] Valid loss: 0.0474
2023-02-06 12:15:37 | Valid | Epoch[572/600] Iteration[007/008] Valid loss: 0.0489
2023-02-06 12:15:37 | Valid | Epoch[572/600] Iteration[008/008] Valid loss: 0.0471
2023-02-06 12:15:38 | Valid | Epoch[572/600] MIou: 0.9278460589592197
2023-02-06 12:15:38 | Valid | Epoch[572/600] Pixel Accuracy: 0.9878654479980469
2023-02-06 12:15:38 | Valid | Epoch[572/600] Mean Pixel Accuracy: 0.9439570810290352
2023-02-06 12:15:38 | Stage | Epoch[572/600] Train loss:0.0165
2023-02-06 12:15:38 | Stage | Epoch[572/600] Valid loss:0.0471
2023-02-06 12:15:38 | Stage | Epoch[572/600] LR:0.0001

2023-02-06 12:15:38 | Train | Epoch[573/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 12:15:38 | Train | Epoch[573/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:15:38 | Train | Epoch[573/600] Iteration[003/030] Train loss: 0.0158
2023-02-06 12:15:38 | Train | Epoch[573/600] Iteration[004/030] Train loss: 0.0159
2023-02-06 12:15:38 | Train | Epoch[573/600] Iteration[005/030] Train loss: 0.0172
2023-02-06 12:15:38 | Train | Epoch[573/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:15:38 | Train | Epoch[573/600] Iteration[007/030] Train loss: 0.0162
2023-02-06 12:15:38 | Train | Epoch[573/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:15:38 | Train | Epoch[573/600] Iteration[009/030] Train loss: 0.0166
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:15:39 | Train | Epoch[573/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:15:40 | Train | Epoch[573/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:15:40 | Train | Epoch[573/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:15:40 | Train | Epoch[573/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:15:40 | Train | Epoch[573/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:15:40 | Train | Epoch[573/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:15:40 | Train | Epoch[573/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:15:40 | Train | Epoch[573/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:15:40 | Valid | Epoch[573/600] Iteration[001/008] Valid loss: 0.0797
2023-02-06 12:15:40 | Valid | Epoch[573/600] Iteration[002/008] Valid loss: 0.0571
2023-02-06 12:15:40 | Valid | Epoch[573/600] Iteration[003/008] Valid loss: 0.0587
2023-02-06 12:15:40 | Valid | Epoch[573/600] Iteration[004/008] Valid loss: 0.0524
2023-02-06 12:15:40 | Valid | Epoch[573/600] Iteration[005/008] Valid loss: 0.0498
2023-02-06 12:15:40 | Valid | Epoch[573/600] Iteration[006/008] Valid loss: 0.0467
2023-02-06 12:15:41 | Valid | Epoch[573/600] Iteration[007/008] Valid loss: 0.0482
2023-02-06 12:15:41 | Valid | Epoch[573/600] Iteration[008/008] Valid loss: 0.0465
2023-02-06 12:15:41 | Valid | Epoch[573/600] MIou: 0.9271895746288036
2023-02-06 12:15:41 | Valid | Epoch[573/600] Pixel Accuracy: 0.9877599080403646
2023-02-06 12:15:41 | Valid | Epoch[573/600] Mean Pixel Accuracy: 0.9431635770717215
2023-02-06 12:15:41 | Stage | Epoch[573/600] Train loss:0.0166
2023-02-06 12:15:41 | Stage | Epoch[573/600] Valid loss:0.0465
2023-02-06 12:15:41 | Stage | Epoch[573/600] LR:0.0001

2023-02-06 12:15:41 | Train | Epoch[574/600] Iteration[001/030] Train loss: 0.0169
2023-02-06 12:15:41 | Train | Epoch[574/600] Iteration[002/030] Train loss: 0.0174
2023-02-06 12:15:41 | Train | Epoch[574/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 12:15:41 | Train | Epoch[574/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:15:41 | Train | Epoch[574/600] Iteration[005/030] Train loss: 0.0156
2023-02-06 12:15:41 | Train | Epoch[574/600] Iteration[006/030] Train loss: 0.0157
2023-02-06 12:15:41 | Train | Epoch[574/600] Iteration[007/030] Train loss: 0.0156
2023-02-06 12:15:41 | Train | Epoch[574/600] Iteration[008/030] Train loss: 0.0156
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[011/030] Train loss: 0.0158
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[012/030] Train loss: 0.0156
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[013/030] Train loss: 0.0158
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[014/030] Train loss: 0.0159
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[015/030] Train loss: 0.0159
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[016/030] Train loss: 0.0160
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[017/030] Train loss: 0.0159
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[018/030] Train loss: 0.0159
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[019/030] Train loss: 0.0159
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 12:15:42 | Train | Epoch[574/600] Iteration[021/030] Train loss: 0.0160
2023-02-06 12:15:43 | Train | Epoch[574/600] Iteration[022/030] Train loss: 0.0161
2023-02-06 12:15:43 | Train | Epoch[574/600] Iteration[023/030] Train loss: 0.0161
2023-02-06 12:15:43 | Train | Epoch[574/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:15:43 | Train | Epoch[574/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:15:43 | Train | Epoch[574/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:15:43 | Train | Epoch[574/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:15:43 | Train | Epoch[574/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:15:43 | Train | Epoch[574/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:15:43 | Train | Epoch[574/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:15:43 | Valid | Epoch[574/600] Iteration[001/008] Valid loss: 0.0787
2023-02-06 12:15:43 | Valid | Epoch[574/600] Iteration[002/008] Valid loss: 0.0566
2023-02-06 12:15:43 | Valid | Epoch[574/600] Iteration[003/008] Valid loss: 0.0585
2023-02-06 12:15:44 | Valid | Epoch[574/600] Iteration[004/008] Valid loss: 0.0522
2023-02-06 12:15:44 | Valid | Epoch[574/600] Iteration[005/008] Valid loss: 0.0496
2023-02-06 12:15:44 | Valid | Epoch[574/600] Iteration[006/008] Valid loss: 0.0466
2023-02-06 12:15:44 | Valid | Epoch[574/600] Iteration[007/008] Valid loss: 0.0480
2023-02-06 12:15:44 | Valid | Epoch[574/600] Iteration[008/008] Valid loss: 0.0463
2023-02-06 12:15:44 | Valid | Epoch[574/600] MIou: 0.9265930250310705
2023-02-06 12:15:44 | Valid | Epoch[574/600] Pixel Accuracy: 0.987664540608724
2023-02-06 12:15:44 | Valid | Epoch[574/600] Mean Pixel Accuracy: 0.9424263881406645
2023-02-06 12:15:44 | Stage | Epoch[574/600] Train loss:0.0163
2023-02-06 12:15:44 | Stage | Epoch[574/600] Valid loss:0.0463
2023-02-06 12:15:44 | Stage | Epoch[574/600] LR:0.0001

2023-02-06 12:15:44 | Train | Epoch[575/600] Iteration[001/030] Train loss: 0.0157
2023-02-06 12:15:44 | Train | Epoch[575/600] Iteration[002/030] Train loss: 0.0167
2023-02-06 12:15:44 | Train | Epoch[575/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 12:15:44 | Train | Epoch[575/600] Iteration[004/030] Train loss: 0.0163
2023-02-06 12:15:44 | Train | Epoch[575/600] Iteration[005/030] Train loss: 0.0158
2023-02-06 12:15:44 | Train | Epoch[575/600] Iteration[006/030] Train loss: 0.0165
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:15:45 | Train | Epoch[575/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:15:46 | Train | Epoch[575/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:15:46 | Train | Epoch[575/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:15:46 | Train | Epoch[575/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:15:46 | Train | Epoch[575/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:15:46 | Train | Epoch[575/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:15:46 | Train | Epoch[575/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:15:46 | Train | Epoch[575/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:15:46 | Train | Epoch[575/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:15:46 | Train | Epoch[575/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:15:46 | Train | Epoch[575/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:15:46 | Valid | Epoch[575/600] Iteration[001/008] Valid loss: 0.0812
2023-02-06 12:15:47 | Valid | Epoch[575/600] Iteration[002/008] Valid loss: 0.0580
2023-02-06 12:15:47 | Valid | Epoch[575/600] Iteration[003/008] Valid loss: 0.0594
2023-02-06 12:15:47 | Valid | Epoch[575/600] Iteration[004/008] Valid loss: 0.0532
2023-02-06 12:15:47 | Valid | Epoch[575/600] Iteration[005/008] Valid loss: 0.0506
2023-02-06 12:15:47 | Valid | Epoch[575/600] Iteration[006/008] Valid loss: 0.0475
2023-02-06 12:15:47 | Valid | Epoch[575/600] Iteration[007/008] Valid loss: 0.0491
2023-02-06 12:15:47 | Valid | Epoch[575/600] Iteration[008/008] Valid loss: 0.0473
2023-02-06 12:15:47 | Valid | Epoch[575/600] MIou: 0.9283274580569626
2023-02-06 12:15:47 | Valid | Epoch[575/600] Pixel Accuracy: 0.987939198811849
2023-02-06 12:15:47 | Valid | Epoch[575/600] Mean Pixel Accuracy: 0.9446760480734895
2023-02-06 12:15:47 | Stage | Epoch[575/600] Train loss:0.0163
2023-02-06 12:15:47 | Stage | Epoch[575/600] Valid loss:0.0473
2023-02-06 12:15:47 | Stage | Epoch[575/600] LR:0.0001

2023-02-06 12:15:47 | Train | Epoch[576/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 12:15:47 | Train | Epoch[576/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 12:15:47 | Train | Epoch[576/600] Iteration[003/030] Train loss: 0.0187
2023-02-06 12:15:47 | Train | Epoch[576/600] Iteration[004/030] Train loss: 0.0179
2023-02-06 12:15:47 | Train | Epoch[576/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:15:47 | Train | Epoch[576/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[008/030] Train loss: 0.0174
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[009/030] Train loss: 0.0170
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:15:48 | Train | Epoch[576/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:15:49 | Train | Epoch[576/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:15:49 | Train | Epoch[576/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:15:49 | Train | Epoch[576/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:15:49 | Train | Epoch[576/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:15:49 | Train | Epoch[576/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:15:49 | Train | Epoch[576/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:15:49 | Train | Epoch[576/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:15:49 | Train | Epoch[576/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:15:49 | Train | Epoch[576/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:15:49 | Train | Epoch[576/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:15:50 | Valid | Epoch[576/600] Iteration[001/008] Valid loss: 0.0801
2023-02-06 12:15:50 | Valid | Epoch[576/600] Iteration[002/008] Valid loss: 0.0571
2023-02-06 12:15:50 | Valid | Epoch[576/600] Iteration[003/008] Valid loss: 0.0586
2023-02-06 12:15:50 | Valid | Epoch[576/600] Iteration[004/008] Valid loss: 0.0524
2023-02-06 12:15:50 | Valid | Epoch[576/600] Iteration[005/008] Valid loss: 0.0498
2023-02-06 12:15:50 | Valid | Epoch[576/600] Iteration[006/008] Valid loss: 0.0468
2023-02-06 12:15:50 | Valid | Epoch[576/600] Iteration[007/008] Valid loss: 0.0484
2023-02-06 12:15:50 | Valid | Epoch[576/600] Iteration[008/008] Valid loss: 0.0466
2023-02-06 12:15:50 | Valid | Epoch[576/600] MIou: 0.9278735925312117
2023-02-06 12:15:50 | Valid | Epoch[576/600] Pixel Accuracy: 0.9878705342610677
2023-02-06 12:15:50 | Valid | Epoch[576/600] Mean Pixel Accuracy: 0.9439662171276274
2023-02-06 12:15:50 | Stage | Epoch[576/600] Train loss:0.0164
2023-02-06 12:15:50 | Stage | Epoch[576/600] Valid loss:0.0466
2023-02-06 12:15:50 | Stage | Epoch[576/600] LR:0.0001

2023-02-06 12:15:50 | Train | Epoch[577/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 12:15:50 | Train | Epoch[577/600] Iteration[002/030] Train loss: 0.0162
2023-02-06 12:15:50 | Train | Epoch[577/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 12:15:50 | Train | Epoch[577/600] Iteration[004/030] Train loss: 0.0159
2023-02-06 12:15:50 | Train | Epoch[577/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[006/030] Train loss: 0.0160
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[007/030] Train loss: 0.0161
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:15:51 | Train | Epoch[577/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:15:52 | Train | Epoch[577/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:15:53 | Valid | Epoch[577/600] Iteration[001/008] Valid loss: 0.0777
2023-02-06 12:15:53 | Valid | Epoch[577/600] Iteration[002/008] Valid loss: 0.0558
2023-02-06 12:15:53 | Valid | Epoch[577/600] Iteration[003/008] Valid loss: 0.0577
2023-02-06 12:15:53 | Valid | Epoch[577/600] Iteration[004/008] Valid loss: 0.0514
2023-02-06 12:15:53 | Valid | Epoch[577/600] Iteration[005/008] Valid loss: 0.0488
2023-02-06 12:15:53 | Valid | Epoch[577/600] Iteration[006/008] Valid loss: 0.0458
2023-02-06 12:15:53 | Valid | Epoch[577/600] Iteration[007/008] Valid loss: 0.0472
2023-02-06 12:15:53 | Valid | Epoch[577/600] Iteration[008/008] Valid loss: 0.0456
2023-02-06 12:15:53 | Valid | Epoch[577/600] MIou: 0.9257124769540352
2023-02-06 12:15:53 | Valid | Epoch[577/600] Pixel Accuracy: 0.9875272115071615
2023-02-06 12:15:53 | Valid | Epoch[577/600] Mean Pixel Accuracy: 0.9412223022803511
2023-02-06 12:15:53 | Stage | Epoch[577/600] Train loss:0.0164
2023-02-06 12:15:53 | Stage | Epoch[577/600] Valid loss:0.0456
2023-02-06 12:15:53 | Stage | Epoch[577/600] LR:0.0001

2023-02-06 12:15:53 | Train | Epoch[578/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 12:15:53 | Train | Epoch[578/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:15:53 | Train | Epoch[578/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 12:15:53 | Train | Epoch[578/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:15:53 | Train | Epoch[578/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[006/030] Train loss: 0.0160
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[007/030] Train loss: 0.0158
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:15:54 | Train | Epoch[578/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[019/030] Train loss: 0.0161
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[022/030] Train loss: 0.0161
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[023/030] Train loss: 0.0160
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[024/030] Train loss: 0.0161
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[025/030] Train loss: 0.0161
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[026/030] Train loss: 0.0161
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:15:55 | Train | Epoch[578/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:15:56 | Valid | Epoch[578/600] Iteration[001/008] Valid loss: 0.0813
2023-02-06 12:15:56 | Valid | Epoch[578/600] Iteration[002/008] Valid loss: 0.0581
2023-02-06 12:15:56 | Valid | Epoch[578/600] Iteration[003/008] Valid loss: 0.0599
2023-02-06 12:15:56 | Valid | Epoch[578/600] Iteration[004/008] Valid loss: 0.0535
2023-02-06 12:15:56 | Valid | Epoch[578/600] Iteration[005/008] Valid loss: 0.0508
2023-02-06 12:15:56 | Valid | Epoch[578/600] Iteration[006/008] Valid loss: 0.0478
2023-02-06 12:15:56 | Valid | Epoch[578/600] Iteration[007/008] Valid loss: 0.0494
2023-02-06 12:15:56 | Valid | Epoch[578/600] Iteration[008/008] Valid loss: 0.0476
2023-02-06 12:15:56 | Valid | Epoch[578/600] MIou: 0.9283834776108386
2023-02-06 12:15:56 | Valid | Epoch[578/600] Pixel Accuracy: 0.987951914469401
2023-02-06 12:15:56 | Valid | Epoch[578/600] Mean Pixel Accuracy: 0.9446069514830449
2023-02-06 12:15:56 | Stage | Epoch[578/600] Train loss:0.0163
2023-02-06 12:15:56 | Stage | Epoch[578/600] Valid loss:0.0476
2023-02-06 12:15:56 | Stage | Epoch[578/600] LR:0.0001

2023-02-06 12:15:56 | Train | Epoch[579/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 12:15:56 | Train | Epoch[579/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 12:15:56 | Train | Epoch[579/600] Iteration[003/030] Train loss: 0.0177
2023-02-06 12:15:56 | Train | Epoch[579/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:15:57 | Train | Epoch[579/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:15:58 | Train | Epoch[579/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:15:59 | Valid | Epoch[579/600] Iteration[001/008] Valid loss: 0.0797
2023-02-06 12:15:59 | Valid | Epoch[579/600] Iteration[002/008] Valid loss: 0.0570
2023-02-06 12:15:59 | Valid | Epoch[579/600] Iteration[003/008] Valid loss: 0.0587
2023-02-06 12:15:59 | Valid | Epoch[579/600] Iteration[004/008] Valid loss: 0.0523
2023-02-06 12:15:59 | Valid | Epoch[579/600] Iteration[005/008] Valid loss: 0.0497
2023-02-06 12:15:59 | Valid | Epoch[579/600] Iteration[006/008] Valid loss: 0.0465
2023-02-06 12:15:59 | Valid | Epoch[579/600] Iteration[007/008] Valid loss: 0.0480
2023-02-06 12:15:59 | Valid | Epoch[579/600] Iteration[008/008] Valid loss: 0.0463
2023-02-06 12:15:59 | Valid | Epoch[579/600] MIou: 0.9271107685171778
2023-02-06 12:15:59 | Valid | Epoch[579/600] Pixel Accuracy: 0.9877484639485677
2023-02-06 12:15:59 | Valid | Epoch[579/600] Mean Pixel Accuracy: 0.9430241370090375
2023-02-06 12:15:59 | Stage | Epoch[579/600] Train loss:0.0165
2023-02-06 12:15:59 | Stage | Epoch[579/600] Valid loss:0.0463
2023-02-06 12:15:59 | Stage | Epoch[579/600] LR:0.0001

2023-02-06 12:15:59 | Train | Epoch[580/600] Iteration[001/030] Train loss: 0.0136
2023-02-06 12:15:59 | Train | Epoch[580/600] Iteration[002/030] Train loss: 0.0156
2023-02-06 12:15:59 | Train | Epoch[580/600] Iteration[003/030] Train loss: 0.0159
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[004/030] Train loss: 0.0163
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[005/030] Train loss: 0.0167
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[007/030] Train loss: 0.0162
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[015/030] Train loss: 0.0166
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 12:16:00 | Train | Epoch[580/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[018/030] Train loss: 0.0169
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[021/030] Train loss: 0.0167
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[023/030] Train loss: 0.0167
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:16:01 | Train | Epoch[580/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:16:02 | Valid | Epoch[580/600] Iteration[001/008] Valid loss: 0.0820
2023-02-06 12:16:02 | Valid | Epoch[580/600] Iteration[002/008] Valid loss: 0.0586
2023-02-06 12:16:02 | Valid | Epoch[580/600] Iteration[003/008] Valid loss: 0.0605
2023-02-06 12:16:02 | Valid | Epoch[580/600] Iteration[004/008] Valid loss: 0.0539
2023-02-06 12:16:02 | Valid | Epoch[580/600] Iteration[005/008] Valid loss: 0.0512
2023-02-06 12:16:02 | Valid | Epoch[580/600] Iteration[006/008] Valid loss: 0.0480
2023-02-06 12:16:02 | Valid | Epoch[580/600] Iteration[007/008] Valid loss: 0.0495
2023-02-06 12:16:02 | Valid | Epoch[580/600] Iteration[008/008] Valid loss: 0.0477
2023-02-06 12:16:02 | Valid | Epoch[580/600] MIou: 0.9286838197275509
2023-02-06 12:16:02 | Valid | Epoch[580/600] Pixel Accuracy: 0.9879964192708334
2023-02-06 12:16:02 | Valid | Epoch[580/600] Mean Pixel Accuracy: 0.945113289054914
2023-02-06 12:16:02 | Stage | Epoch[580/600] Train loss:0.0164
2023-02-06 12:16:02 | Stage | Epoch[580/600] Valid loss:0.0477
2023-02-06 12:16:02 | Stage | Epoch[580/600] LR:0.0001

2023-02-06 12:16:02 | Train | Epoch[581/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 12:16:02 | Train | Epoch[581/600] Iteration[002/030] Train loss: 0.0154
2023-02-06 12:16:02 | Train | Epoch[581/600] Iteration[003/030] Train loss: 0.0162
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[004/030] Train loss: 0.0174
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:16:03 | Train | Epoch[581/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:16:04 | Train | Epoch[581/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:16:05 | Valid | Epoch[581/600] Iteration[001/008] Valid loss: 0.0799
2023-02-06 12:16:05 | Valid | Epoch[581/600] Iteration[002/008] Valid loss: 0.0570
2023-02-06 12:16:05 | Valid | Epoch[581/600] Iteration[003/008] Valid loss: 0.0583
2023-02-06 12:16:05 | Valid | Epoch[581/600] Iteration[004/008] Valid loss: 0.0520
2023-02-06 12:16:05 | Valid | Epoch[581/600] Iteration[005/008] Valid loss: 0.0495
2023-02-06 12:16:05 | Valid | Epoch[581/600] Iteration[006/008] Valid loss: 0.0465
2023-02-06 12:16:05 | Valid | Epoch[581/600] Iteration[007/008] Valid loss: 0.0481
2023-02-06 12:16:05 | Valid | Epoch[581/600] Iteration[008/008] Valid loss: 0.0464
2023-02-06 12:16:05 | Valid | Epoch[581/600] MIou: 0.927439400391126
2023-02-06 12:16:05 | Valid | Epoch[581/600] Pixel Accuracy: 0.9878005981445312
2023-02-06 12:16:05 | Valid | Epoch[581/600] Mean Pixel Accuracy: 0.9434459014203578
2023-02-06 12:16:05 | Stage | Epoch[581/600] Train loss:0.0165
2023-02-06 12:16:05 | Stage | Epoch[581/600] Valid loss:0.0464
2023-02-06 12:16:05 | Stage | Epoch[581/600] LR:0.0001

2023-02-06 12:16:05 | Train | Epoch[582/600] Iteration[001/030] Train loss: 0.0144
2023-02-06 12:16:05 | Train | Epoch[582/600] Iteration[002/030] Train loss: 0.0152
2023-02-06 12:16:05 | Train | Epoch[582/600] Iteration[003/030] Train loss: 0.0158
2023-02-06 12:16:05 | Train | Epoch[582/600] Iteration[004/030] Train loss: 0.0159
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:16:06 | Train | Epoch[582/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:16:07 | Train | Epoch[582/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:16:08 | Valid | Epoch[582/600] Iteration[001/008] Valid loss: 0.0826
2023-02-06 12:16:08 | Valid | Epoch[582/600] Iteration[002/008] Valid loss: 0.0591
2023-02-06 12:16:08 | Valid | Epoch[582/600] Iteration[003/008] Valid loss: 0.0616
2023-02-06 12:16:08 | Valid | Epoch[582/600] Iteration[004/008] Valid loss: 0.0548
2023-02-06 12:16:08 | Valid | Epoch[582/600] Iteration[005/008] Valid loss: 0.0520
2023-02-06 12:16:08 | Valid | Epoch[582/600] Iteration[006/008] Valid loss: 0.0488
2023-02-06 12:16:08 | Valid | Epoch[582/600] Iteration[007/008] Valid loss: 0.0503
2023-02-06 12:16:08 | Valid | Epoch[582/600] Iteration[008/008] Valid loss: 0.0484
2023-02-06 12:16:08 | Valid | Epoch[582/600] MIou: 0.9290233759366056
2023-02-06 12:16:08 | Valid | Epoch[582/600] Pixel Accuracy: 0.9880536397298177
2023-02-06 12:16:08 | Valid | Epoch[582/600] Mean Pixel Accuracy: 0.945430061077609
2023-02-06 12:16:08 | Stage | Epoch[582/600] Train loss:0.0164
2023-02-06 12:16:08 | Stage | Epoch[582/600] Valid loss:0.0484
2023-02-06 12:16:08 | Stage | Epoch[582/600] LR:0.0001

2023-02-06 12:16:08 | Train | Epoch[583/600] Iteration[001/030] Train loss: 0.0174
2023-02-06 12:16:08 | Train | Epoch[583/600] Iteration[002/030] Train loss: 0.0165
2023-02-06 12:16:08 | Train | Epoch[583/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:16:08 | Train | Epoch[583/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[005/030] Train loss: 0.0174
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[010/030] Train loss: 0.0169
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[015/030] Train loss: 0.0169
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:16:09 | Train | Epoch[583/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:16:10 | Train | Epoch[583/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:16:11 | Valid | Epoch[583/600] Iteration[001/008] Valid loss: 0.0769
2023-02-06 12:16:11 | Valid | Epoch[583/600] Iteration[002/008] Valid loss: 0.0558
2023-02-06 12:16:11 | Valid | Epoch[583/600] Iteration[003/008] Valid loss: 0.0578
2023-02-06 12:16:11 | Valid | Epoch[583/600] Iteration[004/008] Valid loss: 0.0515
2023-02-06 12:16:11 | Valid | Epoch[583/600] Iteration[005/008] Valid loss: 0.0491
2023-02-06 12:16:11 | Valid | Epoch[583/600] Iteration[006/008] Valid loss: 0.0462
2023-02-06 12:16:11 | Valid | Epoch[583/600] Iteration[007/008] Valid loss: 0.0476
2023-02-06 12:16:11 | Valid | Epoch[583/600] Iteration[008/008] Valid loss: 0.0458
2023-02-06 12:16:11 | Valid | Epoch[583/600] MIou: 0.9259879841974863
2023-02-06 12:16:11 | Valid | Epoch[583/600] Pixel Accuracy: 0.9875704447428385
2023-02-06 12:16:11 | Valid | Epoch[583/600] Mean Pixel Accuracy: 0.9415884505721843
2023-02-06 12:16:11 | Stage | Epoch[583/600] Train loss:0.0163
2023-02-06 12:16:11 | Stage | Epoch[583/600] Valid loss:0.0458
2023-02-06 12:16:11 | Stage | Epoch[583/600] LR:0.0001

2023-02-06 12:16:11 | Train | Epoch[584/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 12:16:11 | Train | Epoch[584/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:16:11 | Train | Epoch[584/600] Iteration[003/030] Train loss: 0.0160
2023-02-06 12:16:11 | Train | Epoch[584/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[013/030] Train loss: 0.0164
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:16:12 | Train | Epoch[584/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:16:13 | Train | Epoch[584/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:16:14 | Valid | Epoch[584/600] Iteration[001/008] Valid loss: 0.0797
2023-02-06 12:16:14 | Valid | Epoch[584/600] Iteration[002/008] Valid loss: 0.0568
2023-02-06 12:16:14 | Valid | Epoch[584/600] Iteration[003/008] Valid loss: 0.0581
2023-02-06 12:16:14 | Valid | Epoch[584/600] Iteration[004/008] Valid loss: 0.0519
2023-02-06 12:16:14 | Valid | Epoch[584/600] Iteration[005/008] Valid loss: 0.0493
2023-02-06 12:16:14 | Valid | Epoch[584/600] Iteration[006/008] Valid loss: 0.0463
2023-02-06 12:16:14 | Valid | Epoch[584/600] Iteration[007/008] Valid loss: 0.0480
2023-02-06 12:16:14 | Valid | Epoch[584/600] Iteration[008/008] Valid loss: 0.0463
2023-02-06 12:16:14 | Valid | Epoch[584/600] MIou: 0.92769900146643
2023-02-06 12:16:14 | Valid | Epoch[584/600] Pixel Accuracy: 0.9878412882486979
2023-02-06 12:16:14 | Valid | Epoch[584/600] Mean Pixel Accuracy: 0.9437979709556268
2023-02-06 12:16:14 | Stage | Epoch[584/600] Train loss:0.0165
2023-02-06 12:16:14 | Stage | Epoch[584/600] Valid loss:0.0463
2023-02-06 12:16:14 | Stage | Epoch[584/600] LR:0.0001

2023-02-06 12:16:14 | Train | Epoch[585/600] Iteration[001/030] Train loss: 0.0154
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[002/030] Train loss: 0.0148
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[003/030] Train loss: 0.0148
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[004/030] Train loss: 0.0152
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[005/030] Train loss: 0.0157
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[006/030] Train loss: 0.0158
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[007/030] Train loss: 0.0157
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[008/030] Train loss: 0.0158
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[009/030] Train loss: 0.0157
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[010/030] Train loss: 0.0159
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:16:15 | Train | Epoch[585/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:16:16 | Train | Epoch[585/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:16:17 | Train | Epoch[585/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:16:17 | Train | Epoch[585/600] Iteration[030/030] Train loss: 0.0166
2023-02-06 12:16:17 | Valid | Epoch[585/600] Iteration[001/008] Valid loss: 0.0856
2023-02-06 12:16:17 | Valid | Epoch[585/600] Iteration[002/008] Valid loss: 0.0610
2023-02-06 12:16:17 | Valid | Epoch[585/600] Iteration[003/008] Valid loss: 0.0625
2023-02-06 12:16:17 | Valid | Epoch[585/600] Iteration[004/008] Valid loss: 0.0560
2023-02-06 12:16:17 | Valid | Epoch[585/600] Iteration[005/008] Valid loss: 0.0532
2023-02-06 12:16:17 | Valid | Epoch[585/600] Iteration[006/008] Valid loss: 0.0499
2023-02-06 12:16:17 | Valid | Epoch[585/600] Iteration[007/008] Valid loss: 0.0518
2023-02-06 12:16:17 | Valid | Epoch[585/600] Iteration[008/008] Valid loss: 0.0498
2023-02-06 12:16:17 | Valid | Epoch[585/600] MIou: 0.9307851070057367
2023-02-06 12:16:17 | Valid | Epoch[585/600] Pixel Accuracy: 0.9883257548014323
2023-02-06 12:16:17 | Valid | Epoch[585/600] Mean Pixel Accuracy: 0.9480270491300582
2023-02-06 12:16:17 | Stage | Epoch[585/600] Train loss:0.0166
2023-02-06 12:16:17 | Stage | Epoch[585/600] Valid loss:0.0498
2023-02-06 12:16:17 | Stage | Epoch[585/600] LR:0.0001

2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[002/030] Train loss: 0.0180
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[004/030] Train loss: 0.0172
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[007/030] Train loss: 0.0169
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[010/030] Train loss: 0.0171
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[011/030] Train loss: 0.0172
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[012/030] Train loss: 0.0172
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[013/030] Train loss: 0.0173
2023-02-06 12:16:18 | Train | Epoch[586/600] Iteration[014/030] Train loss: 0.0172
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[015/030] Train loss: 0.0172
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[019/030] Train loss: 0.0168
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:16:19 | Train | Epoch[586/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:16:20 | Train | Epoch[586/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:16:20 | Train | Epoch[586/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:16:20 | Valid | Epoch[586/600] Iteration[001/008] Valid loss: 0.0790
2023-02-06 12:16:20 | Valid | Epoch[586/600] Iteration[002/008] Valid loss: 0.0568
2023-02-06 12:16:20 | Valid | Epoch[586/600] Iteration[003/008] Valid loss: 0.0587
2023-02-06 12:16:20 | Valid | Epoch[586/600] Iteration[004/008] Valid loss: 0.0525
2023-02-06 12:16:20 | Valid | Epoch[586/600] Iteration[005/008] Valid loss: 0.0499
2023-02-06 12:16:20 | Valid | Epoch[586/600] Iteration[006/008] Valid loss: 0.0469
2023-02-06 12:16:20 | Valid | Epoch[586/600] Iteration[007/008] Valid loss: 0.0485
2023-02-06 12:16:20 | Valid | Epoch[586/600] Iteration[008/008] Valid loss: 0.0467
2023-02-06 12:16:20 | Valid | Epoch[586/600] MIou: 0.9272107946735306
2023-02-06 12:16:20 | Valid | Epoch[586/600] Pixel Accuracy: 0.9877649943033854
2023-02-06 12:16:20 | Valid | Epoch[586/600] Mean Pixel Accuracy: 0.943128329869729
2023-02-06 12:16:20 | Stage | Epoch[586/600] Train loss:0.0165
2023-02-06 12:16:20 | Stage | Epoch[586/600] Valid loss:0.0467
2023-02-06 12:16:20 | Stage | Epoch[586/600] LR:0.0001

2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[001/030] Train loss: 0.0158
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[002/030] Train loss: 0.0159
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[003/030] Train loss: 0.0160
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[006/030] Train loss: 0.0168
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[013/030] Train loss: 0.0169
2023-02-06 12:16:21 | Train | Epoch[587/600] Iteration[014/030] Train loss: 0.0170
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[015/030] Train loss: 0.0170
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:16:22 | Train | Epoch[587/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:16:23 | Train | Epoch[587/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:16:23 | Train | Epoch[587/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:16:23 | Valid | Epoch[587/600] Iteration[001/008] Valid loss: 0.0798
2023-02-06 12:16:23 | Valid | Epoch[587/600] Iteration[002/008] Valid loss: 0.0573
2023-02-06 12:16:23 | Valid | Epoch[587/600] Iteration[003/008] Valid loss: 0.0592
2023-02-06 12:16:23 | Valid | Epoch[587/600] Iteration[004/008] Valid loss: 0.0528
2023-02-06 12:16:23 | Valid | Epoch[587/600] Iteration[005/008] Valid loss: 0.0502
2023-02-06 12:16:23 | Valid | Epoch[587/600] Iteration[006/008] Valid loss: 0.0471
2023-02-06 12:16:23 | Valid | Epoch[587/600] Iteration[007/008] Valid loss: 0.0486
2023-02-06 12:16:23 | Valid | Epoch[587/600] Iteration[008/008] Valid loss: 0.0469
2023-02-06 12:16:23 | Valid | Epoch[587/600] MIou: 0.9277758277147528
2023-02-06 12:16:23 | Valid | Epoch[587/600] Pixel Accuracy: 0.9878552754720052
2023-02-06 12:16:23 | Valid | Epoch[587/600] Mean Pixel Accuracy: 0.9438310208161456
2023-02-06 12:16:23 | Stage | Epoch[587/600] Train loss:0.0163
2023-02-06 12:16:23 | Stage | Epoch[587/600] Valid loss:0.0469
2023-02-06 12:16:23 | Stage | Epoch[587/600] LR:0.0001

2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[001/030] Train loss: 0.0175
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[002/030] Train loss: 0.0156
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[005/030] Train loss: 0.0160
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 12:16:24 | Train | Epoch[588/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:16:25 | Train | Epoch[588/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:16:26 | Train | Epoch[588/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:16:26 | Train | Epoch[588/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:16:26 | Valid | Epoch[588/600] Iteration[001/008] Valid loss: 0.0781
2023-02-06 12:16:26 | Valid | Epoch[588/600] Iteration[002/008] Valid loss: 0.0563
2023-02-06 12:16:26 | Valid | Epoch[588/600] Iteration[003/008] Valid loss: 0.0582
2023-02-06 12:16:26 | Valid | Epoch[588/600] Iteration[004/008] Valid loss: 0.0519
2023-02-06 12:16:26 | Valid | Epoch[588/600] Iteration[005/008] Valid loss: 0.0492
2023-02-06 12:16:26 | Valid | Epoch[588/600] Iteration[006/008] Valid loss: 0.0462
2023-02-06 12:16:26 | Valid | Epoch[588/600] Iteration[007/008] Valid loss: 0.0477
2023-02-06 12:16:26 | Valid | Epoch[588/600] Iteration[008/008] Valid loss: 0.0460
2023-02-06 12:16:26 | Valid | Epoch[588/600] MIou: 0.9262681790164786
2023-02-06 12:16:26 | Valid | Epoch[588/600] Pixel Accuracy: 0.9876149495442709
2023-02-06 12:16:26 | Valid | Epoch[588/600] Mean Pixel Accuracy: 0.9419426168277636
2023-02-06 12:16:26 | Stage | Epoch[588/600] Train loss:0.0164
2023-02-06 12:16:26 | Stage | Epoch[588/600] Valid loss:0.0460
2023-02-06 12:16:26 | Stage | Epoch[588/600] LR:0.0001

2023-02-06 12:16:26 | Train | Epoch[589/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[002/030] Train loss: 0.0180
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[004/030] Train loss: 0.0177
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 12:16:27 | Train | Epoch[589/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[017/030] Train loss: 0.0161
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[018/030] Train loss: 0.0160
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[020/030] Train loss: 0.0159
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[021/030] Train loss: 0.0159
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:16:28 | Train | Epoch[589/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:16:29 | Train | Epoch[589/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:16:29 | Valid | Epoch[589/600] Iteration[001/008] Valid loss: 0.0801
2023-02-06 12:16:29 | Valid | Epoch[589/600] Iteration[002/008] Valid loss: 0.0572
2023-02-06 12:16:29 | Valid | Epoch[589/600] Iteration[003/008] Valid loss: 0.0586
2023-02-06 12:16:29 | Valid | Epoch[589/600] Iteration[004/008] Valid loss: 0.0523
2023-02-06 12:16:29 | Valid | Epoch[589/600] Iteration[005/008] Valid loss: 0.0497
2023-02-06 12:16:29 | Valid | Epoch[589/600] Iteration[006/008] Valid loss: 0.0466
2023-02-06 12:16:29 | Valid | Epoch[589/600] Iteration[007/008] Valid loss: 0.0481
2023-02-06 12:16:29 | Valid | Epoch[589/600] Iteration[008/008] Valid loss: 0.0464
2023-02-06 12:16:29 | Valid | Epoch[589/600] MIou: 0.9272476735218672
2023-02-06 12:16:29 | Valid | Epoch[589/600] Pixel Accuracy: 0.9877713521321615
2023-02-06 12:16:29 | Valid | Epoch[589/600] Mean Pixel Accuracy: 0.9431571862896275
2023-02-06 12:16:29 | Stage | Epoch[589/600] Train loss:0.0164
2023-02-06 12:16:29 | Stage | Epoch[589/600] Valid loss:0.0464
2023-02-06 12:16:29 | Stage | Epoch[589/600] LR:0.0001

2023-02-06 12:16:29 | Train | Epoch[590/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[003/030] Train loss: 0.0177
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[008/030] Train loss: 0.0163
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:16:30 | Train | Epoch[590/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[024/030] Train loss: 0.0161
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[025/030] Train loss: 0.0161
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:16:31 | Train | Epoch[590/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:16:32 | Train | Epoch[590/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:16:32 | Valid | Epoch[590/600] Iteration[001/008] Valid loss: 0.0771
2023-02-06 12:16:32 | Valid | Epoch[590/600] Iteration[002/008] Valid loss: 0.0555
2023-02-06 12:16:32 | Valid | Epoch[590/600] Iteration[003/008] Valid loss: 0.0574
2023-02-06 12:16:32 | Valid | Epoch[590/600] Iteration[004/008] Valid loss: 0.0513
2023-02-06 12:16:32 | Valid | Epoch[590/600] Iteration[005/008] Valid loss: 0.0487
2023-02-06 12:16:32 | Valid | Epoch[590/600] Iteration[006/008] Valid loss: 0.0457
2023-02-06 12:16:32 | Valid | Epoch[590/600] Iteration[007/008] Valid loss: 0.0471
2023-02-06 12:16:32 | Valid | Epoch[590/600] Iteration[008/008] Valid loss: 0.0455
2023-02-06 12:16:32 | Valid | Epoch[590/600] MIou: 0.9256115759303074
2023-02-06 12:16:32 | Valid | Epoch[590/600] Pixel Accuracy: 0.987511952718099
2023-02-06 12:16:32 | Valid | Epoch[590/600] Mean Pixel Accuracy: 0.9410680845543329
2023-02-06 12:16:32 | Stage | Epoch[590/600] Train loss:0.0163
2023-02-06 12:16:32 | Stage | Epoch[590/600] Valid loss:0.0455
2023-02-06 12:16:32 | Stage | Epoch[590/600] LR:0.0001

2023-02-06 12:16:32 | Train | Epoch[591/600] Iteration[001/030] Train loss: 0.0161
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[002/030] Train loss: 0.0168
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[007/030] Train loss: 0.0161
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:16:33 | Train | Epoch[591/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[015/030] Train loss: 0.0161
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[024/030] Train loss: 0.0164
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:16:34 | Train | Epoch[591/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:16:35 | Train | Epoch[591/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:16:35 | Train | Epoch[591/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:16:35 | Valid | Epoch[591/600] Iteration[001/008] Valid loss: 0.0812
2023-02-06 12:16:35 | Valid | Epoch[591/600] Iteration[002/008] Valid loss: 0.0582
2023-02-06 12:16:35 | Valid | Epoch[591/600] Iteration[003/008] Valid loss: 0.0602
2023-02-06 12:16:35 | Valid | Epoch[591/600] Iteration[004/008] Valid loss: 0.0536
2023-02-06 12:16:35 | Valid | Epoch[591/600] Iteration[005/008] Valid loss: 0.0509
2023-02-06 12:16:35 | Valid | Epoch[591/600] Iteration[006/008] Valid loss: 0.0477
2023-02-06 12:16:35 | Valid | Epoch[591/600] Iteration[007/008] Valid loss: 0.0492
2023-02-06 12:16:35 | Valid | Epoch[591/600] Iteration[008/008] Valid loss: 0.0474
2023-02-06 12:16:35 | Valid | Epoch[591/600] MIou: 0.9281654480618324
2023-02-06 12:16:35 | Valid | Epoch[591/600] Pixel Accuracy: 0.9879175821940104
2023-02-06 12:16:35 | Valid | Epoch[591/600] Mean Pixel Accuracy: 0.9443154407252345
2023-02-06 12:16:35 | Stage | Epoch[591/600] Train loss:0.0164
2023-02-06 12:16:35 | Stage | Epoch[591/600] Valid loss:0.0474
2023-02-06 12:16:35 | Stage | Epoch[591/600] LR:0.0001

2023-02-06 12:16:35 | Train | Epoch[592/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[006/030] Train loss: 0.0176
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[007/030] Train loss: 0.0172
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[010/030] Train loss: 0.0170
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 12:16:36 | Train | Epoch[592/600] Iteration[014/030] Train loss: 0.0168
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[016/030] Train loss: 0.0169
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[020/030] Train loss: 0.0166
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[022/030] Train loss: 0.0165
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:16:37 | Train | Epoch[592/600] Iteration[028/030] Train loss: 0.0165
2023-02-06 12:16:38 | Train | Epoch[592/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 12:16:38 | Train | Epoch[592/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 12:16:38 | Valid | Epoch[592/600] Iteration[001/008] Valid loss: 0.0848
2023-02-06 12:16:38 | Valid | Epoch[592/600] Iteration[002/008] Valid loss: 0.0603
2023-02-06 12:16:38 | Valid | Epoch[592/600] Iteration[003/008] Valid loss: 0.0621
2023-02-06 12:16:38 | Valid | Epoch[592/600] Iteration[004/008] Valid loss: 0.0555
2023-02-06 12:16:38 | Valid | Epoch[592/600] Iteration[005/008] Valid loss: 0.0526
2023-02-06 12:16:38 | Valid | Epoch[592/600] Iteration[006/008] Valid loss: 0.0493
2023-02-06 12:16:38 | Valid | Epoch[592/600] Iteration[007/008] Valid loss: 0.0511
2023-02-06 12:16:38 | Valid | Epoch[592/600] Iteration[008/008] Valid loss: 0.0492
2023-02-06 12:16:38 | Valid | Epoch[592/600] MIou: 0.9302023516530431
2023-02-06 12:16:38 | Valid | Epoch[592/600] Pixel Accuracy: 0.9882354736328125
2023-02-06 12:16:38 | Valid | Epoch[592/600] Mean Pixel Accuracy: 0.9471721868673519
2023-02-06 12:16:38 | Stage | Epoch[592/600] Train loss:0.0164
2023-02-06 12:16:38 | Stage | Epoch[592/600] Valid loss:0.0492
2023-02-06 12:16:38 | Stage | Epoch[592/600] LR:0.0001

2023-02-06 12:16:38 | Train | Epoch[593/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[003/030] Train loss: 0.0170
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[006/030] Train loss: 0.0166
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[007/030] Train loss: 0.0166
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[010/030] Train loss: 0.0166
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:16:39 | Train | Epoch[593/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:16:40 | Train | Epoch[593/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:16:41 | Train | Epoch[593/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:16:41 | Train | Epoch[593/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:16:41 | Valid | Epoch[593/600] Iteration[001/008] Valid loss: 0.0878
2023-02-06 12:16:41 | Valid | Epoch[593/600] Iteration[002/008] Valid loss: 0.0621
2023-02-06 12:16:41 | Valid | Epoch[593/600] Iteration[003/008] Valid loss: 0.0636
2023-02-06 12:16:41 | Valid | Epoch[593/600] Iteration[004/008] Valid loss: 0.0569
2023-02-06 12:16:41 | Valid | Epoch[593/600] Iteration[005/008] Valid loss: 0.0540
2023-02-06 12:16:41 | Valid | Epoch[593/600] Iteration[006/008] Valid loss: 0.0506
2023-02-06 12:16:41 | Valid | Epoch[593/600] Iteration[007/008] Valid loss: 0.0526
2023-02-06 12:16:41 | Valid | Epoch[593/600] Iteration[008/008] Valid loss: 0.0506
2023-02-06 12:16:41 | Valid | Epoch[593/600] MIou: 0.931014120279452
2023-02-06 12:16:41 | Valid | Epoch[593/600] Pixel Accuracy: 0.9883575439453125
2023-02-06 12:16:41 | Valid | Epoch[593/600] Mean Pixel Accuracy: 0.9485073762196908
2023-02-06 12:16:41 | Stage | Epoch[593/600] Train loss:0.0165
2023-02-06 12:16:41 | Stage | Epoch[593/600] Valid loss:0.0506
2023-02-06 12:16:41 | Stage | Epoch[593/600] LR:0.0001

2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[003/030] Train loss: 0.0170
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[006/030] Train loss: 0.0163
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[007/030] Train loss: 0.0161
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[008/030] Train loss: 0.0161
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:16:42 | Train | Epoch[594/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[015/030] Train loss: 0.0160
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[023/030] Train loss: 0.0161
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[025/030] Train loss: 0.0161
2023-02-06 12:16:43 | Train | Epoch[594/600] Iteration[026/030] Train loss: 0.0161
2023-02-06 12:16:44 | Train | Epoch[594/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:16:44 | Train | Epoch[594/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:16:44 | Train | Epoch[594/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:16:44 | Train | Epoch[594/600] Iteration[030/030] Train loss: 0.0162
2023-02-06 12:16:44 | Valid | Epoch[594/600] Iteration[001/008] Valid loss: 0.0815
2023-02-06 12:16:44 | Valid | Epoch[594/600] Iteration[002/008] Valid loss: 0.0578
2023-02-06 12:16:44 | Valid | Epoch[594/600] Iteration[003/008] Valid loss: 0.0591
2023-02-06 12:16:44 | Valid | Epoch[594/600] Iteration[004/008] Valid loss: 0.0528
2023-02-06 12:16:44 | Valid | Epoch[594/600] Iteration[005/008] Valid loss: 0.0501
2023-02-06 12:16:44 | Valid | Epoch[594/600] Iteration[006/008] Valid loss: 0.0472
2023-02-06 12:16:44 | Valid | Epoch[594/600] Iteration[007/008] Valid loss: 0.0489
2023-02-06 12:16:44 | Valid | Epoch[594/600] Iteration[008/008] Valid loss: 0.0471
2023-02-06 12:16:44 | Valid | Epoch[594/600] MIou: 0.9280468617862042
2023-02-06 12:16:44 | Valid | Epoch[594/600] Pixel Accuracy: 0.9878959655761719
2023-02-06 12:16:44 | Valid | Epoch[594/600] Mean Pixel Accuracy: 0.9442655164810716
2023-02-06 12:16:44 | Stage | Epoch[594/600] Train loss:0.0162
2023-02-06 12:16:44 | Stage | Epoch[594/600] Valid loss:0.0471
2023-02-06 12:16:44 | Stage | Epoch[594/600] LR:0.0001

2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[001/030] Train loss: 0.0155
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[003/030] Train loss: 0.0163
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[005/030] Train loss: 0.0176
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[006/030] Train loss: 0.0174
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[007/030] Train loss: 0.0170
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[008/030] Train loss: 0.0169
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[011/030] Train loss: 0.0166
2023-02-06 12:16:45 | Train | Epoch[595/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[016/030] Train loss: 0.0165
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[017/030] Train loss: 0.0164
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[018/030] Train loss: 0.0164
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 12:16:46 | Train | Epoch[595/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:16:47 | Train | Epoch[595/600] Iteration[026/030] Train loss: 0.0165
2023-02-06 12:16:47 | Train | Epoch[595/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 12:16:47 | Train | Epoch[595/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 12:16:47 | Train | Epoch[595/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 12:16:47 | Train | Epoch[595/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:16:47 | Valid | Epoch[595/600] Iteration[001/008] Valid loss: 0.0743
2023-02-06 12:16:47 | Valid | Epoch[595/600] Iteration[002/008] Valid loss: 0.0542
2023-02-06 12:16:47 | Valid | Epoch[595/600] Iteration[003/008] Valid loss: 0.0563
2023-02-06 12:16:47 | Valid | Epoch[595/600] Iteration[004/008] Valid loss: 0.0501
2023-02-06 12:16:47 | Valid | Epoch[595/600] Iteration[005/008] Valid loss: 0.0477
2023-02-06 12:16:47 | Valid | Epoch[595/600] Iteration[006/008] Valid loss: 0.0448
2023-02-06 12:16:47 | Valid | Epoch[595/600] Iteration[007/008] Valid loss: 0.0460
2023-02-06 12:16:47 | Valid | Epoch[595/600] Iteration[008/008] Valid loss: 0.0445
2023-02-06 12:16:47 | Valid | Epoch[595/600] MIou: 0.9240584273719032
2023-02-06 12:16:47 | Valid | Epoch[595/600] Pixel Accuracy: 0.9872665405273438
2023-02-06 12:16:47 | Valid | Epoch[595/600] Mean Pixel Accuracy: 0.9390817778661897
2023-02-06 12:16:47 | Stage | Epoch[595/600] Train loss:0.0163
2023-02-06 12:16:47 | Stage | Epoch[595/600] Valid loss:0.0445
2023-02-06 12:16:47 | Stage | Epoch[595/600] LR:0.0001

2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[001/030] Train loss: 0.0172
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[003/030] Train loss: 0.0167
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[007/030] Train loss: 0.0157
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[008/030] Train loss: 0.0159
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[010/030] Train loss: 0.0161
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 12:16:48 | Train | Epoch[596/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[019/030] Train loss: 0.0164
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[025/030] Train loss: 0.0161
2023-02-06 12:16:49 | Train | Epoch[596/600] Iteration[026/030] Train loss: 0.0160
2023-02-06 12:16:50 | Train | Epoch[596/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 12:16:50 | Train | Epoch[596/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:16:50 | Train | Epoch[596/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 12:16:50 | Train | Epoch[596/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:16:50 | Valid | Epoch[596/600] Iteration[001/008] Valid loss: 0.0790
2023-02-06 12:16:50 | Valid | Epoch[596/600] Iteration[002/008] Valid loss: 0.0570
2023-02-06 12:16:50 | Valid | Epoch[596/600] Iteration[003/008] Valid loss: 0.0593
2023-02-06 12:16:50 | Valid | Epoch[596/600] Iteration[004/008] Valid loss: 0.0527
2023-02-06 12:16:50 | Valid | Epoch[596/600] Iteration[005/008] Valid loss: 0.0501
2023-02-06 12:16:50 | Valid | Epoch[596/600] Iteration[006/008] Valid loss: 0.0469
2023-02-06 12:16:50 | Valid | Epoch[596/600] Iteration[007/008] Valid loss: 0.0482
2023-02-06 12:16:50 | Valid | Epoch[596/600] Iteration[008/008] Valid loss: 0.0465
2023-02-06 12:16:50 | Valid | Epoch[596/600] MIou: 0.9268726605078907
2023-02-06 12:16:50 | Valid | Epoch[596/600] Pixel Accuracy: 0.9877115885416666
2023-02-06 12:16:50 | Valid | Epoch[596/600] Mean Pixel Accuracy: 0.9426868451371027
2023-02-06 12:16:50 | Stage | Epoch[596/600] Train loss:0.0163
2023-02-06 12:16:50 | Stage | Epoch[596/600] Valid loss:0.0465
2023-02-06 12:16:50 | Stage | Epoch[596/600] LR:0.0001

2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[001/030] Train loss: 0.0166
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[008/030] Train loss: 0.0160
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 12:16:51 | Train | Epoch[597/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[013/030] Train loss: 0.0161
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[015/030] Train loss: 0.0160
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[016/030] Train loss: 0.0160
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[018/030] Train loss: 0.0160
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[020/030] Train loss: 0.0160
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[021/030] Train loss: 0.0160
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[022/030] Train loss: 0.0160
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[023/030] Train loss: 0.0159
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[024/030] Train loss: 0.0160
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[025/030] Train loss: 0.0160
2023-02-06 12:16:52 | Train | Epoch[597/600] Iteration[026/030] Train loss: 0.0161
2023-02-06 12:16:53 | Train | Epoch[597/600] Iteration[027/030] Train loss: 0.0161
2023-02-06 12:16:53 | Train | Epoch[597/600] Iteration[028/030] Train loss: 0.0160
2023-02-06 12:16:53 | Train | Epoch[597/600] Iteration[029/030] Train loss: 0.0161
2023-02-06 12:16:53 | Train | Epoch[597/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 12:16:53 | Valid | Epoch[597/600] Iteration[001/008] Valid loss: 0.0774
2023-02-06 12:16:53 | Valid | Epoch[597/600] Iteration[002/008] Valid loss: 0.0557
2023-02-06 12:16:53 | Valid | Epoch[597/600] Iteration[003/008] Valid loss: 0.0571
2023-02-06 12:16:53 | Valid | Epoch[597/600] Iteration[004/008] Valid loss: 0.0510
2023-02-06 12:16:53 | Valid | Epoch[597/600] Iteration[005/008] Valid loss: 0.0485
2023-02-06 12:16:53 | Valid | Epoch[597/600] Iteration[006/008] Valid loss: 0.0455
2023-02-06 12:16:53 | Valid | Epoch[597/600] Iteration[007/008] Valid loss: 0.0469
2023-02-06 12:16:53 | Valid | Epoch[597/600] Iteration[008/008] Valid loss: 0.0453
2023-02-06 12:16:53 | Valid | Epoch[597/600] MIou: 0.9256907050086098
2023-02-06 12:16:53 | Valid | Epoch[597/600] Pixel Accuracy: 0.9875233968098959
2023-02-06 12:16:53 | Valid | Epoch[597/600] Mean Pixel Accuracy: 0.9412075246170168
2023-02-06 12:16:53 | Stage | Epoch[597/600] Train loss:0.0163
2023-02-06 12:16:53 | Stage | Epoch[597/600] Valid loss:0.0453
2023-02-06 12:16:53 | Stage | Epoch[597/600] LR:0.0001

2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[001/030] Train loss: 0.0153
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[002/030] Train loss: 0.0157
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[003/030] Train loss: 0.0157
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[007/030] Train loss: 0.0163
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[008/030] Train loss: 0.0162
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:16:54 | Train | Epoch[598/600] Iteration[012/030] Train loss: 0.0161
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[020/030] Train loss: 0.0164
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[025/030] Train loss: 0.0164
2023-02-06 12:16:55 | Train | Epoch[598/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 12:16:56 | Train | Epoch[598/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 12:16:56 | Train | Epoch[598/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 12:16:56 | Train | Epoch[598/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 12:16:56 | Train | Epoch[598/600] Iteration[030/030] Train loss: 0.0162
2023-02-06 12:16:56 | Valid | Epoch[598/600] Iteration[001/008] Valid loss: 0.0787
2023-02-06 12:16:56 | Valid | Epoch[598/600] Iteration[002/008] Valid loss: 0.0568
2023-02-06 12:16:56 | Valid | Epoch[598/600] Iteration[003/008] Valid loss: 0.0585
2023-02-06 12:16:56 | Valid | Epoch[598/600] Iteration[004/008] Valid loss: 0.0523
2023-02-06 12:16:56 | Valid | Epoch[598/600] Iteration[005/008] Valid loss: 0.0498
2023-02-06 12:16:56 | Valid | Epoch[598/600] Iteration[006/008] Valid loss: 0.0468
2023-02-06 12:16:56 | Valid | Epoch[598/600] Iteration[007/008] Valid loss: 0.0483
2023-02-06 12:16:56 | Valid | Epoch[598/600] Iteration[008/008] Valid loss: 0.0466
2023-02-06 12:16:56 | Valid | Epoch[598/600] MIou: 0.9269548059285881
2023-02-06 12:16:56 | Valid | Epoch[598/600] Pixel Accuracy: 0.9877217610677084
2023-02-06 12:16:56 | Valid | Epoch[598/600] Mean Pixel Accuracy: 0.9428953314796494
2023-02-06 12:16:56 | Stage | Epoch[598/600] Train loss:0.0162
2023-02-06 12:16:56 | Stage | Epoch[598/600] Valid loss:0.0466
2023-02-06 12:16:56 | Stage | Epoch[598/600] LR:0.0001

2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[003/030] Train loss: 0.0180
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[004/030] Train loss: 0.0175
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[005/030] Train loss: 0.0172
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[008/030] Train loss: 0.0170
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[009/030] Train loss: 0.0167
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[011/030] Train loss: 0.0167
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[012/030] Train loss: 0.0166
2023-02-06 12:16:57 | Train | Epoch[599/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[016/030] Train loss: 0.0168
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[017/030] Train loss: 0.0169
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[018/030] Train loss: 0.0167
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[019/030] Train loss: 0.0167
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[020/030] Train loss: 0.0168
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[023/030] Train loss: 0.0168
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[024/030] Train loss: 0.0167
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[025/030] Train loss: 0.0167
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[026/030] Train loss: 0.0167
2023-02-06 12:16:58 | Train | Epoch[599/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 12:16:59 | Train | Epoch[599/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:16:59 | Train | Epoch[599/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 12:16:59 | Train | Epoch[599/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:16:59 | Valid | Epoch[599/600] Iteration[001/008] Valid loss: 0.0802
2023-02-06 12:16:59 | Valid | Epoch[599/600] Iteration[002/008] Valid loss: 0.0574
2023-02-06 12:16:59 | Valid | Epoch[599/600] Iteration[003/008] Valid loss: 0.0590
2023-02-06 12:16:59 | Valid | Epoch[599/600] Iteration[004/008] Valid loss: 0.0527
2023-02-06 12:16:59 | Valid | Epoch[599/600] Iteration[005/008] Valid loss: 0.0500
2023-02-06 12:16:59 | Valid | Epoch[599/600] Iteration[006/008] Valid loss: 0.0470
2023-02-06 12:16:59 | Valid | Epoch[599/600] Iteration[007/008] Valid loss: 0.0485
2023-02-06 12:16:59 | Valid | Epoch[599/600] Iteration[008/008] Valid loss: 0.0467
2023-02-06 12:16:59 | Valid | Epoch[599/600] MIou: 0.9271944291126607
2023-02-06 12:16:59 | Valid | Epoch[599/600] Pixel Accuracy: 0.9877611796061198
2023-02-06 12:16:59 | Valid | Epoch[599/600] Mean Pixel Accuracy: 0.9431515950354673
2023-02-06 12:16:59 | Stage | Epoch[599/600] Train loss:0.0165
2023-02-06 12:16:59 | Stage | Epoch[599/600] Valid loss:0.0467
2023-02-06 12:16:59 | Stage | Epoch[599/600] LR:0.0001

2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[001/030] Train loss: 0.0151
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[003/030] Train loss: 0.0162
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[006/030] Train loss: 0.0158
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[007/030] Train loss: 0.0156
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[008/030] Train loss: 0.0160
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[009/030] Train loss: 0.0161
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[010/030] Train loss: 0.0162
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 12:17:00 | Train | Epoch[600/600] Iteration[013/030] Train loss: 0.0166
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[017/030] Train loss: 0.0167
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[019/030] Train loss: 0.0166
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[020/030] Train loss: 0.0167
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[021/030] Train loss: 0.0166
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[022/030] Train loss: 0.0166
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[023/030] Train loss: 0.0166
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[024/030] Train loss: 0.0166
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[025/030] Train loss: 0.0166
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 12:17:01 | Train | Epoch[600/600] Iteration[027/030] Train loss: 0.0165
2023-02-06 12:17:02 | Train | Epoch[600/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 12:17:02 | Train | Epoch[600/600] Iteration[029/030] Train loss: 0.0165
2023-02-06 12:17:02 | Train | Epoch[600/600] Iteration[030/030] Train loss: 0.0165
2023-02-06 12:17:02 | Valid | Epoch[600/600] Iteration[001/008] Valid loss: 0.0815
2023-02-06 12:17:02 | Valid | Epoch[600/600] Iteration[002/008] Valid loss: 0.0584
2023-02-06 12:17:02 | Valid | Epoch[600/600] Iteration[003/008] Valid loss: 0.0604
2023-02-06 12:17:02 | Valid | Epoch[600/600] Iteration[004/008] Valid loss: 0.0539
2023-02-06 12:17:02 | Valid | Epoch[600/600] Iteration[005/008] Valid loss: 0.0513
2023-02-06 12:17:02 | Valid | Epoch[600/600] Iteration[006/008] Valid loss: 0.0481
2023-02-06 12:17:02 | Valid | Epoch[600/600] Iteration[007/008] Valid loss: 0.0498
2023-02-06 12:17:02 | Valid | Epoch[600/600] Iteration[008/008] Valid loss: 0.0479
2023-02-06 12:17:02 | Valid | Epoch[600/600] MIou: 0.9291727718401442
2023-02-06 12:17:02 | Valid | Epoch[600/600] Pixel Accuracy: 0.9880816141764323
2023-02-06 12:17:02 | Valid | Epoch[600/600] Mean Pixel Accuracy: 0.9454644584410858
2023-02-06 12:17:02 | Stage | Epoch[600/600] Train loss:0.0165
2023-02-06 12:17:02 | Stage | Epoch[600/600] Valid loss:0.0479
2023-02-06 12:17:02 | Stage | Epoch[600/600] LR:0.0001

2023-02-06 12:17:02 | Final | Model training completed!!!
2023-02-06 12:17:02 | Final | Start time: 2023-02-06 11:46:57
2023-02-06 12:17:02 | Final | End time: 2023-02-06 12:17:02
2023-02-06 12:17:02 | Final | Spend time: 1805s
2023-02-06 12:17:02 | Final | Final epoch is 600
2023-02-06 12:17:02 | Final | Each epoch spend 3.0083333333333333s
