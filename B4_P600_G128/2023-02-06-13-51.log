2023-02-06 13:51:04 | Start | Model starts training!!!

2023-02-06 13:51:09 | Train | Epoch[001/600] Iteration[001/030] Train loss: 0.8538
2023-02-06 13:51:09 | Train | Epoch[001/600] Iteration[002/030] Train loss: 0.8384
2023-02-06 13:51:09 | Train | Epoch[001/600] Iteration[003/030] Train loss: 0.8328
2023-02-06 13:51:10 | Train | Epoch[001/600] Iteration[004/030] Train loss: 0.8266
2023-02-06 13:51:10 | Train | Epoch[001/600] Iteration[005/030] Train loss: 0.8207
2023-02-06 13:51:10 | Train | Epoch[001/600] Iteration[006/030] Train loss: 0.8167
2023-02-06 13:51:10 | Train | Epoch[001/600] Iteration[007/030] Train loss: 0.8120
2023-02-06 13:51:10 | Train | Epoch[001/600] Iteration[008/030] Train loss: 0.8057
2023-02-06 13:51:11 | Train | Epoch[001/600] Iteration[009/030] Train loss: 0.7995
2023-02-06 13:51:11 | Train | Epoch[001/600] Iteration[010/030] Train loss: 0.7929
2023-02-06 13:51:11 | Train | Epoch[001/600] Iteration[011/030] Train loss: 0.7868
2023-02-06 13:51:11 | Train | Epoch[001/600] Iteration[012/030] Train loss: 0.7809
2023-02-06 13:51:12 | Train | Epoch[001/600] Iteration[013/030] Train loss: 0.7749
2023-02-06 13:51:12 | Train | Epoch[001/600] Iteration[014/030] Train loss: 0.7691
2023-02-06 13:51:12 | Train | Epoch[001/600] Iteration[015/030] Train loss: 0.7635
2023-02-06 13:51:12 | Train | Epoch[001/600] Iteration[016/030] Train loss: 0.7583
2023-02-06 13:51:12 | Train | Epoch[001/600] Iteration[017/030] Train loss: 0.7529
2023-02-06 13:51:13 | Train | Epoch[001/600] Iteration[018/030] Train loss: 0.7480
2023-02-06 13:51:13 | Train | Epoch[001/600] Iteration[019/030] Train loss: 0.7437
2023-02-06 13:51:13 | Train | Epoch[001/600] Iteration[020/030] Train loss: 0.7396
2023-02-06 13:51:13 | Train | Epoch[001/600] Iteration[021/030] Train loss: 0.7355
2023-02-06 13:51:14 | Train | Epoch[001/600] Iteration[022/030] Train loss: 0.7317
2023-02-06 13:51:14 | Train | Epoch[001/600] Iteration[023/030] Train loss: 0.7280
2023-02-06 13:51:14 | Train | Epoch[001/600] Iteration[024/030] Train loss: 0.7245
2023-02-06 13:51:14 | Train | Epoch[001/600] Iteration[025/030] Train loss: 0.7210
2023-02-06 13:51:14 | Train | Epoch[001/600] Iteration[026/030] Train loss: 0.7177
2023-02-06 13:51:15 | Train | Epoch[001/600] Iteration[027/030] Train loss: 0.7146
2023-02-06 13:51:15 | Train | Epoch[001/600] Iteration[028/030] Train loss: 0.7118
2023-02-06 13:51:15 | Train | Epoch[001/600] Iteration[029/030] Train loss: 0.7090
2023-02-06 13:51:15 | Train | Epoch[001/600] Iteration[030/030] Train loss: 0.7064
2023-02-06 13:51:15 | Valid | Epoch[001/600] Iteration[001/008] Valid loss: 0.6483
2023-02-06 13:51:16 | Valid | Epoch[001/600] Iteration[002/008] Valid loss: 0.6475
2023-02-06 13:51:16 | Valid | Epoch[001/600] Iteration[003/008] Valid loss: 0.6476
2023-02-06 13:51:16 | Valid | Epoch[001/600] Iteration[004/008] Valid loss: 0.6478
2023-02-06 13:51:16 | Valid | Epoch[001/600] Iteration[005/008] Valid loss: 0.6477
2023-02-06 13:51:16 | Valid | Epoch[001/600] Iteration[006/008] Valid loss: 0.6478
2023-02-06 13:51:16 | Valid | Epoch[001/600] Iteration[007/008] Valid loss: 0.6477
2023-02-06 13:51:16 | Valid | Epoch[001/600] Iteration[008/008] Valid loss: 0.6476
2023-02-06 13:51:16 | Valid | Epoch[001/600] MIou: 0.5931335990551188
2023-02-06 13:51:16 | Valid | Epoch[001/600] Pixel Accuracy: 0.9312477111816406
2023-02-06 13:51:16 | Valid | Epoch[001/600] Mean Pixel Accuracy: 0.6302427428932683
2023-02-06 13:51:16 | Stage | Epoch[001/600] Train loss:0.7064
2023-02-06 13:51:16 | Stage | Epoch[001/600] Valid loss:0.6476
2023-02-06 13:51:16 | Stage | Epoch[001/600] LR:0.01

2023-02-06 13:51:16 | Train | Epoch[002/600] Iteration[001/030] Train loss: 0.6246
2023-02-06 13:51:17 | Train | Epoch[002/600] Iteration[002/030] Train loss: 0.6237
2023-02-06 13:51:17 | Train | Epoch[002/600] Iteration[003/030] Train loss: 0.6226
2023-02-06 13:51:17 | Train | Epoch[002/600] Iteration[004/030] Train loss: 0.6226
2023-02-06 13:51:17 | Train | Epoch[002/600] Iteration[005/030] Train loss: 0.6229
2023-02-06 13:51:17 | Train | Epoch[002/600] Iteration[006/030] Train loss: 0.6222
2023-02-06 13:51:18 | Train | Epoch[002/600] Iteration[007/030] Train loss: 0.6222
2023-02-06 13:51:18 | Train | Epoch[002/600] Iteration[008/030] Train loss: 0.6213
2023-02-06 13:51:18 | Train | Epoch[002/600] Iteration[009/030] Train loss: 0.6208
2023-02-06 13:51:18 | Train | Epoch[002/600] Iteration[010/030] Train loss: 0.6199
2023-02-06 13:51:19 | Train | Epoch[002/600] Iteration[011/030] Train loss: 0.6192
2023-02-06 13:51:19 | Train | Epoch[002/600] Iteration[012/030] Train loss: 0.6187
2023-02-06 13:51:19 | Train | Epoch[002/600] Iteration[013/030] Train loss: 0.6185
2023-02-06 13:51:19 | Train | Epoch[002/600] Iteration[014/030] Train loss: 0.6184
2023-02-06 13:51:19 | Train | Epoch[002/600] Iteration[015/030] Train loss: 0.6178
2023-02-06 13:51:20 | Train | Epoch[002/600] Iteration[016/030] Train loss: 0.6172
2023-02-06 13:51:20 | Train | Epoch[002/600] Iteration[017/030] Train loss: 0.6168
2023-02-06 13:51:20 | Train | Epoch[002/600] Iteration[018/030] Train loss: 0.6163
2023-02-06 13:51:20 | Train | Epoch[002/600] Iteration[019/030] Train loss: 0.6160
2023-02-06 13:51:21 | Train | Epoch[002/600] Iteration[020/030] Train loss: 0.6154
2023-02-06 13:51:21 | Train | Epoch[002/600] Iteration[021/030] Train loss: 0.6151
2023-02-06 13:51:21 | Train | Epoch[002/600] Iteration[022/030] Train loss: 0.6145
2023-02-06 13:51:21 | Train | Epoch[002/600] Iteration[023/030] Train loss: 0.6143
2023-02-06 13:51:21 | Train | Epoch[002/600] Iteration[024/030] Train loss: 0.6137
2023-02-06 13:51:22 | Train | Epoch[002/600] Iteration[025/030] Train loss: 0.6134
2023-02-06 13:51:22 | Train | Epoch[002/600] Iteration[026/030] Train loss: 0.6130
2023-02-06 13:51:22 | Train | Epoch[002/600] Iteration[027/030] Train loss: 0.6126
2023-02-06 13:51:22 | Train | Epoch[002/600] Iteration[028/030] Train loss: 0.6122
2023-02-06 13:51:23 | Train | Epoch[002/600] Iteration[029/030] Train loss: 0.6118
2023-02-06 13:51:23 | Train | Epoch[002/600] Iteration[030/030] Train loss: 0.6112
2023-02-06 13:51:23 | Valid | Epoch[002/600] Iteration[001/008] Valid loss: 0.6135
2023-02-06 13:51:23 | Valid | Epoch[002/600] Iteration[002/008] Valid loss: 0.6118
2023-02-06 13:51:23 | Valid | Epoch[002/600] Iteration[003/008] Valid loss: 0.6109
2023-02-06 13:51:23 | Valid | Epoch[002/600] Iteration[004/008] Valid loss: 0.6105
2023-02-06 13:51:23 | Valid | Epoch[002/600] Iteration[005/008] Valid loss: 0.6099
2023-02-06 13:51:23 | Valid | Epoch[002/600] Iteration[006/008] Valid loss: 0.6100
2023-02-06 13:51:23 | Valid | Epoch[002/600] Iteration[007/008] Valid loss: 0.6099
2023-02-06 13:51:23 | Valid | Epoch[002/600] Iteration[008/008] Valid loss: 0.6091
2023-02-06 13:51:23 | Valid | Epoch[002/600] MIou: 0.8483071362724852
2023-02-06 13:51:23 | Valid | Epoch[002/600] Pixel Accuracy: 0.9736671447753906
2023-02-06 13:51:23 | Valid | Epoch[002/600] Mean Pixel Accuracy: 0.8811812000251448
2023-02-06 13:51:23 | Stage | Epoch[002/600] Train loss:0.6112
2023-02-06 13:51:23 | Stage | Epoch[002/600] Valid loss:0.6091
2023-02-06 13:51:23 | Stage | Epoch[002/600] LR:0.01

2023-02-06 13:51:24 | Train | Epoch[003/600] Iteration[001/030] Train loss: 0.5988
2023-02-06 13:51:24 | Train | Epoch[003/600] Iteration[002/030] Train loss: 0.5983
2023-02-06 13:51:24 | Train | Epoch[003/600] Iteration[003/030] Train loss: 0.5982
2023-02-06 13:51:25 | Train | Epoch[003/600] Iteration[004/030] Train loss: 0.5983
2023-02-06 13:51:25 | Train | Epoch[003/600] Iteration[005/030] Train loss: 0.5976
2023-02-06 13:51:25 | Train | Epoch[003/600] Iteration[006/030] Train loss: 0.5971
2023-02-06 13:51:25 | Train | Epoch[003/600] Iteration[007/030] Train loss: 0.5965
2023-02-06 13:51:26 | Train | Epoch[003/600] Iteration[008/030] Train loss: 0.5963
2023-02-06 13:51:26 | Train | Epoch[003/600] Iteration[009/030] Train loss: 0.5961
2023-02-06 13:51:26 | Train | Epoch[003/600] Iteration[010/030] Train loss: 0.5959
2023-02-06 13:51:26 | Train | Epoch[003/600] Iteration[011/030] Train loss: 0.5956
2023-02-06 13:51:26 | Train | Epoch[003/600] Iteration[012/030] Train loss: 0.5951
2023-02-06 13:51:27 | Train | Epoch[003/600] Iteration[013/030] Train loss: 0.5949
2023-02-06 13:51:27 | Train | Epoch[003/600] Iteration[014/030] Train loss: 0.5944
2023-02-06 13:51:27 | Train | Epoch[003/600] Iteration[015/030] Train loss: 0.5941
2023-02-06 13:51:27 | Train | Epoch[003/600] Iteration[016/030] Train loss: 0.5938
2023-02-06 13:51:27 | Train | Epoch[003/600] Iteration[017/030] Train loss: 0.5937
2023-02-06 13:51:28 | Train | Epoch[003/600] Iteration[018/030] Train loss: 0.5935
2023-02-06 13:51:28 | Train | Epoch[003/600] Iteration[019/030] Train loss: 0.5933
2023-02-06 13:51:28 | Train | Epoch[003/600] Iteration[020/030] Train loss: 0.5929
2023-02-06 13:51:28 | Train | Epoch[003/600] Iteration[021/030] Train loss: 0.5927
2023-02-06 13:51:29 | Train | Epoch[003/600] Iteration[022/030] Train loss: 0.5923
2023-02-06 13:51:29 | Train | Epoch[003/600] Iteration[023/030] Train loss: 0.5920
2023-02-06 13:51:29 | Train | Epoch[003/600] Iteration[024/030] Train loss: 0.5918
2023-02-06 13:51:29 | Train | Epoch[003/600] Iteration[025/030] Train loss: 0.5916
2023-02-06 13:51:29 | Train | Epoch[003/600] Iteration[026/030] Train loss: 0.5912
2023-02-06 13:51:30 | Train | Epoch[003/600] Iteration[027/030] Train loss: 0.5908
2023-02-06 13:51:30 | Train | Epoch[003/600] Iteration[028/030] Train loss: 0.5905
2023-02-06 13:51:30 | Train | Epoch[003/600] Iteration[029/030] Train loss: 0.5901
2023-02-06 13:51:30 | Train | Epoch[003/600] Iteration[030/030] Train loss: 0.5898
2023-02-06 13:51:31 | Valid | Epoch[003/600] Iteration[001/008] Valid loss: 0.5910
2023-02-06 13:51:31 | Valid | Epoch[003/600] Iteration[002/008] Valid loss: 0.5899
2023-02-06 13:51:31 | Valid | Epoch[003/600] Iteration[003/008] Valid loss: 0.5895
2023-02-06 13:51:31 | Valid | Epoch[003/600] Iteration[004/008] Valid loss: 0.5889
2023-02-06 13:51:31 | Valid | Epoch[003/600] Iteration[005/008] Valid loss: 0.5884
2023-02-06 13:51:31 | Valid | Epoch[003/600] Iteration[006/008] Valid loss: 0.5879
2023-02-06 13:51:31 | Valid | Epoch[003/600] Iteration[007/008] Valid loss: 0.5882
2023-02-06 13:51:31 | Valid | Epoch[003/600] Iteration[008/008] Valid loss: 0.5884
2023-02-06 13:51:31 | Valid | Epoch[003/600] MIou: 0.8028019980178592
2023-02-06 13:51:31 | Valid | Epoch[003/600] Pixel Accuracy: 0.9541371663411459
2023-02-06 13:51:31 | Valid | Epoch[003/600] Mean Pixel Accuracy: 0.9602658103843716
2023-02-06 13:51:31 | Stage | Epoch[003/600] Train loss:0.5898
2023-02-06 13:51:31 | Stage | Epoch[003/600] Valid loss:0.5884
2023-02-06 13:51:31 | Stage | Epoch[003/600] LR:0.01

2023-02-06 13:51:31 | Train | Epoch[004/600] Iteration[001/030] Train loss: 0.5827
2023-02-06 13:51:32 | Train | Epoch[004/600] Iteration[002/030] Train loss: 0.5825
2023-02-06 13:51:32 | Train | Epoch[004/600] Iteration[003/030] Train loss: 0.5809
2023-02-06 13:51:32 | Train | Epoch[004/600] Iteration[004/030] Train loss: 0.5797
2023-02-06 13:51:32 | Train | Epoch[004/600] Iteration[005/030] Train loss: 0.5784
2023-02-06 13:51:33 | Train | Epoch[004/600] Iteration[006/030] Train loss: 0.5782
2023-02-06 13:51:33 | Train | Epoch[004/600] Iteration[007/030] Train loss: 0.5774
2023-02-06 13:51:33 | Train | Epoch[004/600] Iteration[008/030] Train loss: 0.5770
2023-02-06 13:51:33 | Train | Epoch[004/600] Iteration[009/030] Train loss: 0.5764
2023-02-06 13:51:33 | Train | Epoch[004/600] Iteration[010/030] Train loss: 0.5761
2023-02-06 13:51:34 | Train | Epoch[004/600] Iteration[011/030] Train loss: 0.5759
2023-02-06 13:51:34 | Train | Epoch[004/600] Iteration[012/030] Train loss: 0.5754
2023-02-06 13:51:34 | Train | Epoch[004/600] Iteration[013/030] Train loss: 0.5749
2023-02-06 13:51:34 | Train | Epoch[004/600] Iteration[014/030] Train loss: 0.5746
2023-02-06 13:51:35 | Train | Epoch[004/600] Iteration[015/030] Train loss: 0.5741
2023-02-06 13:51:35 | Train | Epoch[004/600] Iteration[016/030] Train loss: 0.5740
2023-02-06 13:51:35 | Train | Epoch[004/600] Iteration[017/030] Train loss: 0.5736
2023-02-06 13:51:35 | Train | Epoch[004/600] Iteration[018/030] Train loss: 0.5734
2023-02-06 13:51:35 | Train | Epoch[004/600] Iteration[019/030] Train loss: 0.5730
2023-02-06 13:51:36 | Train | Epoch[004/600] Iteration[020/030] Train loss: 0.5727
2023-02-06 13:51:36 | Train | Epoch[004/600] Iteration[021/030] Train loss: 0.5726
2023-02-06 13:51:36 | Train | Epoch[004/600] Iteration[022/030] Train loss: 0.5723
2023-02-06 13:51:36 | Train | Epoch[004/600] Iteration[023/030] Train loss: 0.5721
2023-02-06 13:51:36 | Train | Epoch[004/600] Iteration[024/030] Train loss: 0.5720
2023-02-06 13:51:37 | Train | Epoch[004/600] Iteration[025/030] Train loss: 0.5716
2023-02-06 13:51:37 | Train | Epoch[004/600] Iteration[026/030] Train loss: 0.5712
2023-02-06 13:51:37 | Train | Epoch[004/600] Iteration[027/030] Train loss: 0.5709
2023-02-06 13:51:37 | Train | Epoch[004/600] Iteration[028/030] Train loss: 0.5707
2023-02-06 13:51:38 | Train | Epoch[004/600] Iteration[029/030] Train loss: 0.5704
2023-02-06 13:51:38 | Train | Epoch[004/600] Iteration[030/030] Train loss: 0.5699
2023-02-06 13:51:38 | Valid | Epoch[004/600] Iteration[001/008] Valid loss: 0.5758
2023-02-06 13:51:38 | Valid | Epoch[004/600] Iteration[002/008] Valid loss: 0.5750
2023-02-06 13:51:38 | Valid | Epoch[004/600] Iteration[003/008] Valid loss: 0.5740
2023-02-06 13:51:38 | Valid | Epoch[004/600] Iteration[004/008] Valid loss: 0.5734
2023-02-06 13:51:38 | Valid | Epoch[004/600] Iteration[005/008] Valid loss: 0.5730
2023-02-06 13:51:38 | Valid | Epoch[004/600] Iteration[006/008] Valid loss: 0.5729
2023-02-06 13:51:38 | Valid | Epoch[004/600] Iteration[007/008] Valid loss: 0.5727
2023-02-06 13:51:38 | Valid | Epoch[004/600] Iteration[008/008] Valid loss: 0.5724
2023-02-06 13:51:38 | Valid | Epoch[004/600] MIou: 0.8748773672387258
2023-02-06 13:51:38 | Valid | Epoch[004/600] Pixel Accuracy: 0.9780311584472656
2023-02-06 13:51:38 | Valid | Epoch[004/600] Mean Pixel Accuracy: 0.9116744773299144
2023-02-06 13:51:38 | Stage | Epoch[004/600] Train loss:0.5699
2023-02-06 13:51:38 | Stage | Epoch[004/600] Valid loss:0.5724
2023-02-06 13:51:38 | Stage | Epoch[004/600] LR:0.01

2023-02-06 13:51:39 | Train | Epoch[005/600] Iteration[001/030] Train loss: 0.5602
2023-02-06 13:51:39 | Train | Epoch[005/600] Iteration[002/030] Train loss: 0.5608
2023-02-06 13:51:39 | Train | Epoch[005/600] Iteration[003/030] Train loss: 0.5582
2023-02-06 13:51:40 | Train | Epoch[005/600] Iteration[004/030] Train loss: 0.5593
2023-02-06 13:51:40 | Train | Epoch[005/600] Iteration[005/030] Train loss: 0.5588
2023-02-06 13:51:40 | Train | Epoch[005/600] Iteration[006/030] Train loss: 0.5587
2023-02-06 13:51:40 | Train | Epoch[005/600] Iteration[007/030] Train loss: 0.5582
2023-02-06 13:51:40 | Train | Epoch[005/600] Iteration[008/030] Train loss: 0.5583
2023-02-06 13:51:41 | Train | Epoch[005/600] Iteration[009/030] Train loss: 0.5576
2023-02-06 13:51:41 | Train | Epoch[005/600] Iteration[010/030] Train loss: 0.5577
2023-02-06 13:51:41 | Train | Epoch[005/600] Iteration[011/030] Train loss: 0.5574
2023-02-06 13:51:41 | Train | Epoch[005/600] Iteration[012/030] Train loss: 0.5570
2023-02-06 13:51:42 | Train | Epoch[005/600] Iteration[013/030] Train loss: 0.5565
2023-02-06 13:51:42 | Train | Epoch[005/600] Iteration[014/030] Train loss: 0.5560
2023-02-06 13:51:42 | Train | Epoch[005/600] Iteration[015/030] Train loss: 0.5553
2023-02-06 13:51:42 | Train | Epoch[005/600] Iteration[016/030] Train loss: 0.5551
2023-02-06 13:51:42 | Train | Epoch[005/600] Iteration[017/030] Train loss: 0.5547
2023-02-06 13:51:43 | Train | Epoch[005/600] Iteration[018/030] Train loss: 0.5542
2023-02-06 13:51:43 | Train | Epoch[005/600] Iteration[019/030] Train loss: 0.5538
2023-02-06 13:51:43 | Train | Epoch[005/600] Iteration[020/030] Train loss: 0.5533
2023-02-06 13:51:43 | Train | Epoch[005/600] Iteration[021/030] Train loss: 0.5530
2023-02-06 13:51:44 | Train | Epoch[005/600] Iteration[022/030] Train loss: 0.5526
2023-02-06 13:51:44 | Train | Epoch[005/600] Iteration[023/030] Train loss: 0.5522
2023-02-06 13:51:44 | Train | Epoch[005/600] Iteration[024/030] Train loss: 0.5521
2023-02-06 13:51:44 | Train | Epoch[005/600] Iteration[025/030] Train loss: 0.5517
2023-02-06 13:51:44 | Train | Epoch[005/600] Iteration[026/030] Train loss: 0.5512
2023-02-06 13:51:45 | Train | Epoch[005/600] Iteration[027/030] Train loss: 0.5508
2023-02-06 13:51:45 | Train | Epoch[005/600] Iteration[028/030] Train loss: 0.5505
2023-02-06 13:51:45 | Train | Epoch[005/600] Iteration[029/030] Train loss: 0.5500
2023-02-06 13:51:45 | Train | Epoch[005/600] Iteration[030/030] Train loss: 0.5496
2023-02-06 13:51:45 | Valid | Epoch[005/600] Iteration[001/008] Valid loss: 0.5445
2023-02-06 13:51:46 | Valid | Epoch[005/600] Iteration[002/008] Valid loss: 0.5441
2023-02-06 13:51:46 | Valid | Epoch[005/600] Iteration[003/008] Valid loss: 0.5427
2023-02-06 13:51:46 | Valid | Epoch[005/600] Iteration[004/008] Valid loss: 0.5418
2023-02-06 13:51:46 | Valid | Epoch[005/600] Iteration[005/008] Valid loss: 0.5418
2023-02-06 13:51:46 | Valid | Epoch[005/600] Iteration[006/008] Valid loss: 0.5414
2023-02-06 13:51:46 | Valid | Epoch[005/600] Iteration[007/008] Valid loss: 0.5415
2023-02-06 13:51:46 | Valid | Epoch[005/600] Iteration[008/008] Valid loss: 0.5412
2023-02-06 13:51:46 | Valid | Epoch[005/600] MIou: 0.8917969202241682
2023-02-06 13:51:46 | Valid | Epoch[005/600] Pixel Accuracy: 0.9794845581054688
2023-02-06 13:51:46 | Valid | Epoch[005/600] Mean Pixel Accuracy: 0.9634316973106445
2023-02-06 13:51:46 | Stage | Epoch[005/600] Train loss:0.5496
2023-02-06 13:51:46 | Stage | Epoch[005/600] Valid loss:0.5412
2023-02-06 13:51:46 | Stage | Epoch[005/600] LR:0.01

2023-02-06 13:51:46 | Train | Epoch[006/600] Iteration[001/030] Train loss: 0.5387
2023-02-06 13:51:47 | Train | Epoch[006/600] Iteration[002/030] Train loss: 0.5393
2023-02-06 13:51:47 | Train | Epoch[006/600] Iteration[003/030] Train loss: 0.5374
2023-02-06 13:51:47 | Train | Epoch[006/600] Iteration[004/030] Train loss: 0.5371
2023-02-06 13:51:47 | Train | Epoch[006/600] Iteration[005/030] Train loss: 0.5370
2023-02-06 13:51:47 | Train | Epoch[006/600] Iteration[006/030] Train loss: 0.5372
2023-02-06 13:51:48 | Train | Epoch[006/600] Iteration[007/030] Train loss: 0.5369
2023-02-06 13:51:48 | Train | Epoch[006/600] Iteration[008/030] Train loss: 0.5364
2023-02-06 13:51:48 | Train | Epoch[006/600] Iteration[009/030] Train loss: 0.5359
2023-02-06 13:51:48 | Train | Epoch[006/600] Iteration[010/030] Train loss: 0.5351
2023-02-06 13:51:49 | Train | Epoch[006/600] Iteration[011/030] Train loss: 0.5348
2023-02-06 13:51:49 | Train | Epoch[006/600] Iteration[012/030] Train loss: 0.5349
2023-02-06 13:51:49 | Train | Epoch[006/600] Iteration[013/030] Train loss: 0.5345
2023-02-06 13:51:49 | Train | Epoch[006/600] Iteration[014/030] Train loss: 0.5342
2023-02-06 13:51:49 | Train | Epoch[006/600] Iteration[015/030] Train loss: 0.5341
2023-02-06 13:51:50 | Train | Epoch[006/600] Iteration[016/030] Train loss: 0.5342
2023-02-06 13:51:50 | Train | Epoch[006/600] Iteration[017/030] Train loss: 0.5337
2023-02-06 13:51:50 | Train | Epoch[006/600] Iteration[018/030] Train loss: 0.5335
2023-02-06 13:51:50 | Train | Epoch[006/600] Iteration[019/030] Train loss: 0.5329
2023-02-06 13:51:51 | Train | Epoch[006/600] Iteration[020/030] Train loss: 0.5328
2023-02-06 13:51:51 | Train | Epoch[006/600] Iteration[021/030] Train loss: 0.5323
2023-02-06 13:51:51 | Train | Epoch[006/600] Iteration[022/030] Train loss: 0.5319
2023-02-06 13:51:51 | Train | Epoch[006/600] Iteration[023/030] Train loss: 0.5316
2023-02-06 13:51:51 | Train | Epoch[006/600] Iteration[024/030] Train loss: 0.5312
2023-02-06 13:51:52 | Train | Epoch[006/600] Iteration[025/030] Train loss: 0.5309
2023-02-06 13:51:52 | Train | Epoch[006/600] Iteration[026/030] Train loss: 0.5307
2023-02-06 13:51:52 | Train | Epoch[006/600] Iteration[027/030] Train loss: 0.5304
2023-02-06 13:51:52 | Train | Epoch[006/600] Iteration[028/030] Train loss: 0.5301
2023-02-06 13:51:52 | Train | Epoch[006/600] Iteration[029/030] Train loss: 0.5297
2023-02-06 13:51:53 | Train | Epoch[006/600] Iteration[030/030] Train loss: 0.5294
2023-02-06 13:51:53 | Valid | Epoch[006/600] Iteration[001/008] Valid loss: 0.5285
2023-02-06 13:51:53 | Valid | Epoch[006/600] Iteration[002/008] Valid loss: 0.5267
2023-02-06 13:51:53 | Valid | Epoch[006/600] Iteration[003/008] Valid loss: 0.5261
2023-02-06 13:51:53 | Valid | Epoch[006/600] Iteration[004/008] Valid loss: 0.5259
2023-02-06 13:51:53 | Valid | Epoch[006/600] Iteration[005/008] Valid loss: 0.5256
2023-02-06 13:51:53 | Valid | Epoch[006/600] Iteration[006/008] Valid loss: 0.5258
2023-02-06 13:51:53 | Valid | Epoch[006/600] Iteration[007/008] Valid loss: 0.5255
2023-02-06 13:51:53 | Valid | Epoch[006/600] Iteration[008/008] Valid loss: 0.5247
2023-02-06 13:51:53 | Valid | Epoch[006/600] MIou: 0.8022638162162608
2023-02-06 13:51:53 | Valid | Epoch[006/600] Pixel Accuracy: 0.9674021402994791
2023-02-06 13:51:53 | Valid | Epoch[006/600] Mean Pixel Accuracy: 0.8195955626034336
2023-02-06 13:51:53 | Stage | Epoch[006/600] Train loss:0.5294
2023-02-06 13:51:53 | Stage | Epoch[006/600] Valid loss:0.5247
2023-02-06 13:51:53 | Stage | Epoch[006/600] LR:0.01

2023-02-06 13:51:54 | Train | Epoch[007/600] Iteration[001/030] Train loss: 0.5165
2023-02-06 13:51:54 | Train | Epoch[007/600] Iteration[002/030] Train loss: 0.5173
2023-02-06 13:51:54 | Train | Epoch[007/600] Iteration[003/030] Train loss: 0.5165
2023-02-06 13:51:55 | Train | Epoch[007/600] Iteration[004/030] Train loss: 0.5151
2023-02-06 13:51:55 | Train | Epoch[007/600] Iteration[005/030] Train loss: 0.5148
2023-02-06 13:51:55 | Train | Epoch[007/600] Iteration[006/030] Train loss: 0.5159
2023-02-06 13:51:55 | Train | Epoch[007/600] Iteration[007/030] Train loss: 0.5167
2023-02-06 13:51:55 | Train | Epoch[007/600] Iteration[008/030] Train loss: 0.5161
2023-02-06 13:51:56 | Train | Epoch[007/600] Iteration[009/030] Train loss: 0.5155
2023-02-06 13:51:56 | Train | Epoch[007/600] Iteration[010/030] Train loss: 0.5151
2023-02-06 13:51:56 | Train | Epoch[007/600] Iteration[011/030] Train loss: 0.5150
2023-02-06 13:51:56 | Train | Epoch[007/600] Iteration[012/030] Train loss: 0.5152
2023-02-06 13:51:57 | Train | Epoch[007/600] Iteration[013/030] Train loss: 0.5147
2023-02-06 13:51:57 | Train | Epoch[007/600] Iteration[014/030] Train loss: 0.5143
2023-02-06 13:51:57 | Train | Epoch[007/600] Iteration[015/030] Train loss: 0.5139
2023-02-06 13:51:57 | Train | Epoch[007/600] Iteration[016/030] Train loss: 0.5137
2023-02-06 13:51:57 | Train | Epoch[007/600] Iteration[017/030] Train loss: 0.5133
2023-02-06 13:51:58 | Train | Epoch[007/600] Iteration[018/030] Train loss: 0.5129
2023-02-06 13:51:58 | Train | Epoch[007/600] Iteration[019/030] Train loss: 0.5129
2023-02-06 13:51:58 | Train | Epoch[007/600] Iteration[020/030] Train loss: 0.5125
2023-02-06 13:51:58 | Train | Epoch[007/600] Iteration[021/030] Train loss: 0.5124
2023-02-06 13:51:59 | Train | Epoch[007/600] Iteration[022/030] Train loss: 0.5125
2023-02-06 13:51:59 | Train | Epoch[007/600] Iteration[023/030] Train loss: 0.5122
2023-02-06 13:51:59 | Train | Epoch[007/600] Iteration[024/030] Train loss: 0.5118
2023-02-06 13:51:59 | Train | Epoch[007/600] Iteration[025/030] Train loss: 0.5113
2023-02-06 13:51:59 | Train | Epoch[007/600] Iteration[026/030] Train loss: 0.5111
2023-02-06 13:52:00 | Train | Epoch[007/600] Iteration[027/030] Train loss: 0.5107
2023-02-06 13:52:00 | Train | Epoch[007/600] Iteration[028/030] Train loss: 0.5104
2023-02-06 13:52:00 | Train | Epoch[007/600] Iteration[029/030] Train loss: 0.5099
2023-02-06 13:52:00 | Train | Epoch[007/600] Iteration[030/030] Train loss: 0.5096
2023-02-06 13:52:01 | Valid | Epoch[007/600] Iteration[001/008] Valid loss: 0.5073
2023-02-06 13:52:01 | Valid | Epoch[007/600] Iteration[002/008] Valid loss: 0.5076
2023-02-06 13:52:01 | Valid | Epoch[007/600] Iteration[003/008] Valid loss: 0.5068
2023-02-06 13:52:01 | Valid | Epoch[007/600] Iteration[004/008] Valid loss: 0.5061
2023-02-06 13:52:01 | Valid | Epoch[007/600] Iteration[005/008] Valid loss: 0.5059
2023-02-06 13:52:01 | Valid | Epoch[007/600] Iteration[006/008] Valid loss: 0.5057
2023-02-06 13:52:01 | Valid | Epoch[007/600] Iteration[007/008] Valid loss: 0.5052
2023-02-06 13:52:01 | Valid | Epoch[007/600] Iteration[008/008] Valid loss: 0.5050
2023-02-06 13:52:01 | Valid | Epoch[007/600] MIou: 0.8300191131424002
2023-02-06 13:52:01 | Valid | Epoch[007/600] Pixel Accuracy: 0.9719454447428385
2023-02-06 13:52:01 | Valid | Epoch[007/600] Mean Pixel Accuracy: 0.8455334796729109
2023-02-06 13:52:01 | Stage | Epoch[007/600] Train loss:0.5096
2023-02-06 13:52:01 | Stage | Epoch[007/600] Valid loss:0.5050
2023-02-06 13:52:01 | Stage | Epoch[007/600] LR:0.01

2023-02-06 13:52:01 | Train | Epoch[008/600] Iteration[001/030] Train loss: 0.4955
2023-02-06 13:52:02 | Train | Epoch[008/600] Iteration[002/030] Train loss: 0.4955
2023-02-06 13:52:02 | Train | Epoch[008/600] Iteration[003/030] Train loss: 0.4951
2023-02-06 13:52:02 | Train | Epoch[008/600] Iteration[004/030] Train loss: 0.4955
2023-02-06 13:52:02 | Train | Epoch[008/600] Iteration[005/030] Train loss: 0.4962
2023-02-06 13:52:03 | Train | Epoch[008/600] Iteration[006/030] Train loss: 0.4974
2023-02-06 13:52:03 | Train | Epoch[008/600] Iteration[007/030] Train loss: 0.4967
2023-02-06 13:52:03 | Train | Epoch[008/600] Iteration[008/030] Train loss: 0.4964
2023-02-06 13:52:03 | Train | Epoch[008/600] Iteration[009/030] Train loss: 0.4959
2023-02-06 13:52:03 | Train | Epoch[008/600] Iteration[010/030] Train loss: 0.4964
2023-02-06 13:52:04 | Train | Epoch[008/600] Iteration[011/030] Train loss: 0.4961
2023-02-06 13:52:04 | Train | Epoch[008/600] Iteration[012/030] Train loss: 0.4963
2023-02-06 13:52:04 | Train | Epoch[008/600] Iteration[013/030] Train loss: 0.4959
2023-02-06 13:52:04 | Train | Epoch[008/600] Iteration[014/030] Train loss: 0.4959
2023-02-06 13:52:05 | Train | Epoch[008/600] Iteration[015/030] Train loss: 0.4956
2023-02-06 13:52:05 | Train | Epoch[008/600] Iteration[016/030] Train loss: 0.4951
2023-02-06 13:52:05 | Train | Epoch[008/600] Iteration[017/030] Train loss: 0.4950
2023-02-06 13:52:05 | Train | Epoch[008/600] Iteration[018/030] Train loss: 0.4945
2023-02-06 13:52:05 | Train | Epoch[008/600] Iteration[019/030] Train loss: 0.4940
2023-02-06 13:52:06 | Train | Epoch[008/600] Iteration[020/030] Train loss: 0.4935
2023-02-06 13:52:06 | Train | Epoch[008/600] Iteration[021/030] Train loss: 0.4931
2023-02-06 13:52:06 | Train | Epoch[008/600] Iteration[022/030] Train loss: 0.4929
2023-02-06 13:52:06 | Train | Epoch[008/600] Iteration[023/030] Train loss: 0.4925
2023-02-06 13:52:06 | Train | Epoch[008/600] Iteration[024/030] Train loss: 0.4920
2023-02-06 13:52:07 | Train | Epoch[008/600] Iteration[025/030] Train loss: 0.4915
2023-02-06 13:52:07 | Train | Epoch[008/600] Iteration[026/030] Train loss: 0.4913
2023-02-06 13:52:07 | Train | Epoch[008/600] Iteration[027/030] Train loss: 0.4909
2023-02-06 13:52:07 | Train | Epoch[008/600] Iteration[028/030] Train loss: 0.4910
2023-02-06 13:52:08 | Train | Epoch[008/600] Iteration[029/030] Train loss: 0.4908
2023-02-06 13:52:08 | Train | Epoch[008/600] Iteration[030/030] Train loss: 0.4904
2023-02-06 13:52:08 | Valid | Epoch[008/600] Iteration[001/008] Valid loss: 0.4782
2023-02-06 13:52:08 | Valid | Epoch[008/600] Iteration[002/008] Valid loss: 0.4779
2023-02-06 13:52:08 | Valid | Epoch[008/600] Iteration[003/008] Valid loss: 0.4765
2023-02-06 13:52:08 | Valid | Epoch[008/600] Iteration[004/008] Valid loss: 0.4758
2023-02-06 13:52:08 | Valid | Epoch[008/600] Iteration[005/008] Valid loss: 0.4761
2023-02-06 13:52:08 | Valid | Epoch[008/600] Iteration[006/008] Valid loss: 0.4761
2023-02-06 13:52:08 | Valid | Epoch[008/600] Iteration[007/008] Valid loss: 0.4767
2023-02-06 13:52:08 | Valid | Epoch[008/600] Iteration[008/008] Valid loss: 0.4760
2023-02-06 13:52:09 | Valid | Epoch[008/600] MIou: 0.917822839221905
2023-02-06 13:52:09 | Valid | Epoch[008/600] Pixel Accuracy: 0.9848543802897135
2023-02-06 13:52:09 | Valid | Epoch[008/600] Mean Pixel Accuracy: 0.976908363310535
2023-02-06 13:52:09 | Stage | Epoch[008/600] Train loss:0.4904
2023-02-06 13:52:09 | Stage | Epoch[008/600] Valid loss:0.4760
2023-02-06 13:52:09 | Stage | Epoch[008/600] LR:0.01

2023-02-06 13:52:09 | Train | Epoch[009/600] Iteration[001/030] Train loss: 0.4775
2023-02-06 13:52:09 | Train | Epoch[009/600] Iteration[002/030] Train loss: 0.4782
2023-02-06 13:52:09 | Train | Epoch[009/600] Iteration[003/030] Train loss: 0.4802
2023-02-06 13:52:10 | Train | Epoch[009/600] Iteration[004/030] Train loss: 0.4814
2023-02-06 13:52:10 | Train | Epoch[009/600] Iteration[005/030] Train loss: 0.4812
2023-02-06 13:52:10 | Train | Epoch[009/600] Iteration[006/030] Train loss: 0.4801
2023-02-06 13:52:10 | Train | Epoch[009/600] Iteration[007/030] Train loss: 0.4797
2023-02-06 13:52:11 | Train | Epoch[009/600] Iteration[008/030] Train loss: 0.4788
2023-02-06 13:52:11 | Train | Epoch[009/600] Iteration[009/030] Train loss: 0.4786
2023-02-06 13:52:11 | Train | Epoch[009/600] Iteration[010/030] Train loss: 0.4787
2023-02-06 13:52:11 | Train | Epoch[009/600] Iteration[011/030] Train loss: 0.4780
2023-02-06 13:52:11 | Train | Epoch[009/600] Iteration[012/030] Train loss: 0.4776
2023-02-06 13:52:12 | Train | Epoch[009/600] Iteration[013/030] Train loss: 0.4771
2023-02-06 13:52:12 | Train | Epoch[009/600] Iteration[014/030] Train loss: 0.4768
2023-02-06 13:52:12 | Train | Epoch[009/600] Iteration[015/030] Train loss: 0.4764
2023-02-06 13:52:12 | Train | Epoch[009/600] Iteration[016/030] Train loss: 0.4760
2023-02-06 13:52:13 | Train | Epoch[009/600] Iteration[017/030] Train loss: 0.4754
2023-02-06 13:52:13 | Train | Epoch[009/600] Iteration[018/030] Train loss: 0.4752
2023-02-06 13:52:13 | Train | Epoch[009/600] Iteration[019/030] Train loss: 0.4748
2023-02-06 13:52:13 | Train | Epoch[009/600] Iteration[020/030] Train loss: 0.4751
2023-02-06 13:52:13 | Train | Epoch[009/600] Iteration[021/030] Train loss: 0.4747
2023-02-06 13:52:14 | Train | Epoch[009/600] Iteration[022/030] Train loss: 0.4743
2023-02-06 13:52:14 | Train | Epoch[009/600] Iteration[023/030] Train loss: 0.4741
2023-02-06 13:52:14 | Train | Epoch[009/600] Iteration[024/030] Train loss: 0.4739
2023-02-06 13:52:14 | Train | Epoch[009/600] Iteration[025/030] Train loss: 0.4736
2023-02-06 13:52:15 | Train | Epoch[009/600] Iteration[026/030] Train loss: 0.4733
2023-02-06 13:52:15 | Train | Epoch[009/600] Iteration[027/030] Train loss: 0.4729
2023-02-06 13:52:15 | Train | Epoch[009/600] Iteration[028/030] Train loss: 0.4725
2023-02-06 13:52:15 | Train | Epoch[009/600] Iteration[029/030] Train loss: 0.4720
2023-02-06 13:52:15 | Train | Epoch[009/600] Iteration[030/030] Train loss: 0.4719
2023-02-06 13:52:16 | Valid | Epoch[009/600] Iteration[001/008] Valid loss: 0.4975
2023-02-06 13:52:16 | Valid | Epoch[009/600] Iteration[002/008] Valid loss: 0.4957
2023-02-06 13:52:16 | Valid | Epoch[009/600] Iteration[003/008] Valid loss: 0.4960
2023-02-06 13:52:16 | Valid | Epoch[009/600] Iteration[004/008] Valid loss: 0.4960
2023-02-06 13:52:16 | Valid | Epoch[009/600] Iteration[005/008] Valid loss: 0.4972
2023-02-06 13:52:16 | Valid | Epoch[009/600] Iteration[006/008] Valid loss: 0.4965
2023-02-06 13:52:16 | Valid | Epoch[009/600] Iteration[007/008] Valid loss: 0.4982
2023-02-06 13:52:16 | Valid | Epoch[009/600] Iteration[008/008] Valid loss: 0.4984
2023-02-06 13:52:16 | Valid | Epoch[009/600] MIou: 0.8395800002929019
2023-02-06 13:52:16 | Valid | Epoch[009/600] Pixel Accuracy: 0.9648145039876302
2023-02-06 13:52:16 | Valid | Epoch[009/600] Mean Pixel Accuracy: 0.9765772871127116
2023-02-06 13:52:16 | Stage | Epoch[009/600] Train loss:0.4719
2023-02-06 13:52:16 | Stage | Epoch[009/600] Valid loss:0.4984
2023-02-06 13:52:16 | Stage | Epoch[009/600] LR:0.01

2023-02-06 13:52:17 | Train | Epoch[010/600] Iteration[001/030] Train loss: 0.4626
2023-02-06 13:52:17 | Train | Epoch[010/600] Iteration[002/030] Train loss: 0.4611
2023-02-06 13:52:17 | Train | Epoch[010/600] Iteration[003/030] Train loss: 0.4613
2023-02-06 13:52:17 | Train | Epoch[010/600] Iteration[004/030] Train loss: 0.4609
2023-02-06 13:52:17 | Train | Epoch[010/600] Iteration[005/030] Train loss: 0.4605
2023-02-06 13:52:18 | Train | Epoch[010/600] Iteration[006/030] Train loss: 0.4614
2023-02-06 13:52:18 | Train | Epoch[010/600] Iteration[007/030] Train loss: 0.4606
2023-02-06 13:52:18 | Train | Epoch[010/600] Iteration[008/030] Train loss: 0.4605
2023-02-06 13:52:18 | Train | Epoch[010/600] Iteration[009/030] Train loss: 0.4602
2023-02-06 13:52:19 | Train | Epoch[010/600] Iteration[010/030] Train loss: 0.4607
2023-02-06 13:52:19 | Train | Epoch[010/600] Iteration[011/030] Train loss: 0.4601
2023-02-06 13:52:19 | Train | Epoch[010/600] Iteration[012/030] Train loss: 0.4595
2023-02-06 13:52:19 | Train | Epoch[010/600] Iteration[013/030] Train loss: 0.4594
2023-02-06 13:52:19 | Train | Epoch[010/600] Iteration[014/030] Train loss: 0.4593
2023-02-06 13:52:20 | Train | Epoch[010/600] Iteration[015/030] Train loss: 0.4589
2023-02-06 13:52:20 | Train | Epoch[010/600] Iteration[016/030] Train loss: 0.4588
2023-02-06 13:52:20 | Train | Epoch[010/600] Iteration[017/030] Train loss: 0.4585
2023-02-06 13:52:20 | Train | Epoch[010/600] Iteration[018/030] Train loss: 0.4582
2023-02-06 13:52:20 | Train | Epoch[010/600] Iteration[019/030] Train loss: 0.4577
2023-02-06 13:52:21 | Train | Epoch[010/600] Iteration[020/030] Train loss: 0.4572
2023-02-06 13:52:21 | Train | Epoch[010/600] Iteration[021/030] Train loss: 0.4567
2023-02-06 13:52:21 | Train | Epoch[010/600] Iteration[022/030] Train loss: 0.4563
2023-02-06 13:52:21 | Train | Epoch[010/600] Iteration[023/030] Train loss: 0.4559
2023-02-06 13:52:22 | Train | Epoch[010/600] Iteration[024/030] Train loss: 0.4557
2023-02-06 13:52:22 | Train | Epoch[010/600] Iteration[025/030] Train loss: 0.4554
2023-02-06 13:52:22 | Train | Epoch[010/600] Iteration[026/030] Train loss: 0.4550
2023-02-06 13:52:22 | Train | Epoch[010/600] Iteration[027/030] Train loss: 0.4546
2023-02-06 13:52:22 | Train | Epoch[010/600] Iteration[028/030] Train loss: 0.4545
2023-02-06 13:52:23 | Train | Epoch[010/600] Iteration[029/030] Train loss: 0.4541
2023-02-06 13:52:23 | Train | Epoch[010/600] Iteration[030/030] Train loss: 0.4539
2023-02-06 13:52:23 | Valid | Epoch[010/600] Iteration[001/008] Valid loss: 0.5214
2023-02-06 13:52:23 | Valid | Epoch[010/600] Iteration[002/008] Valid loss: 0.5198
2023-02-06 13:52:23 | Valid | Epoch[010/600] Iteration[003/008] Valid loss: 0.5196
2023-02-06 13:52:23 | Valid | Epoch[010/600] Iteration[004/008] Valid loss: 0.5200
2023-02-06 13:52:23 | Valid | Epoch[010/600] Iteration[005/008] Valid loss: 0.5200
2023-02-06 13:52:23 | Valid | Epoch[010/600] Iteration[006/008] Valid loss: 0.5197
2023-02-06 13:52:23 | Valid | Epoch[010/600] Iteration[007/008] Valid loss: 0.5198
2023-02-06 13:52:23 | Valid | Epoch[010/600] Iteration[008/008] Valid loss: 0.5198
2023-02-06 13:52:24 | Valid | Epoch[010/600] MIou: 0.8419285836321097
2023-02-06 13:52:24 | Valid | Epoch[010/600] Pixel Accuracy: 0.9660975138346354
2023-02-06 13:52:24 | Valid | Epoch[010/600] Mean Pixel Accuracy: 0.9679049266773062
2023-02-06 13:52:24 | Stage | Epoch[010/600] Train loss:0.4539
2023-02-06 13:52:24 | Stage | Epoch[010/600] Valid loss:0.5198
2023-02-06 13:52:24 | Stage | Epoch[010/600] LR:0.01

2023-02-06 13:52:24 | Train | Epoch[011/600] Iteration[001/030] Train loss: 0.4442
2023-02-06 13:52:24 | Train | Epoch[011/600] Iteration[002/030] Train loss: 0.4429
2023-02-06 13:52:24 | Train | Epoch[011/600] Iteration[003/030] Train loss: 0.4425
2023-02-06 13:52:25 | Train | Epoch[011/600] Iteration[004/030] Train loss: 0.4434
2023-02-06 13:52:25 | Train | Epoch[011/600] Iteration[005/030] Train loss: 0.4437
2023-02-06 13:52:25 | Train | Epoch[011/600] Iteration[006/030] Train loss: 0.4439
2023-02-06 13:52:25 | Train | Epoch[011/600] Iteration[007/030] Train loss: 0.4436
2023-02-06 13:52:26 | Train | Epoch[011/600] Iteration[008/030] Train loss: 0.4432
2023-02-06 13:52:26 | Train | Epoch[011/600] Iteration[009/030] Train loss: 0.4433
2023-02-06 13:52:26 | Train | Epoch[011/600] Iteration[010/030] Train loss: 0.4438
2023-02-06 13:52:26 | Train | Epoch[011/600] Iteration[011/030] Train loss: 0.4431
2023-02-06 13:52:26 | Train | Epoch[011/600] Iteration[012/030] Train loss: 0.4426
2023-02-06 13:52:27 | Train | Epoch[011/600] Iteration[013/030] Train loss: 0.4423
2023-02-06 13:52:27 | Train | Epoch[011/600] Iteration[014/030] Train loss: 0.4419
2023-02-06 13:52:27 | Train | Epoch[011/600] Iteration[015/030] Train loss: 0.4420
2023-02-06 13:52:27 | Train | Epoch[011/600] Iteration[016/030] Train loss: 0.4417
2023-02-06 13:52:28 | Train | Epoch[011/600] Iteration[017/030] Train loss: 0.4414
2023-02-06 13:52:28 | Train | Epoch[011/600] Iteration[018/030] Train loss: 0.4414
2023-02-06 13:52:28 | Train | Epoch[011/600] Iteration[019/030] Train loss: 0.4411
2023-02-06 13:52:28 | Train | Epoch[011/600] Iteration[020/030] Train loss: 0.4406
2023-02-06 13:52:28 | Train | Epoch[011/600] Iteration[021/030] Train loss: 0.4401
2023-02-06 13:52:29 | Train | Epoch[011/600] Iteration[022/030] Train loss: 0.4398
2023-02-06 13:52:29 | Train | Epoch[011/600] Iteration[023/030] Train loss: 0.4393
2023-02-06 13:52:29 | Train | Epoch[011/600] Iteration[024/030] Train loss: 0.4389
2023-02-06 13:52:29 | Train | Epoch[011/600] Iteration[025/030] Train loss: 0.4386
2023-02-06 13:52:29 | Train | Epoch[011/600] Iteration[026/030] Train loss: 0.4382
2023-02-06 13:52:30 | Train | Epoch[011/600] Iteration[027/030] Train loss: 0.4379
2023-02-06 13:52:30 | Train | Epoch[011/600] Iteration[028/030] Train loss: 0.4375
2023-02-06 13:52:30 | Train | Epoch[011/600] Iteration[029/030] Train loss: 0.4373
2023-02-06 13:52:30 | Train | Epoch[011/600] Iteration[030/030] Train loss: 0.4370
2023-02-06 13:52:31 | Valid | Epoch[011/600] Iteration[001/008] Valid loss: 0.4424
2023-02-06 13:52:31 | Valid | Epoch[011/600] Iteration[002/008] Valid loss: 0.4419
2023-02-06 13:52:31 | Valid | Epoch[011/600] Iteration[003/008] Valid loss: 0.4407
2023-02-06 13:52:31 | Valid | Epoch[011/600] Iteration[004/008] Valid loss: 0.4405
2023-02-06 13:52:31 | Valid | Epoch[011/600] Iteration[005/008] Valid loss: 0.4405
2023-02-06 13:52:31 | Valid | Epoch[011/600] Iteration[006/008] Valid loss: 0.4399
2023-02-06 13:52:31 | Valid | Epoch[011/600] Iteration[007/008] Valid loss: 0.4409
2023-02-06 13:52:31 | Valid | Epoch[011/600] Iteration[008/008] Valid loss: 0.4409
2023-02-06 13:52:31 | Valid | Epoch[011/600] MIou: 0.9037022641937436
2023-02-06 13:52:31 | Valid | Epoch[011/600] Pixel Accuracy: 0.9819170633951823
2023-02-06 13:52:31 | Valid | Epoch[011/600] Mean Pixel Accuracy: 0.9713437749197393
2023-02-06 13:52:31 | Stage | Epoch[011/600] Train loss:0.4370
2023-02-06 13:52:31 | Stage | Epoch[011/600] Valid loss:0.4409
2023-02-06 13:52:31 | Stage | Epoch[011/600] LR:0.01

2023-02-06 13:52:32 | Train | Epoch[012/600] Iteration[001/030] Train loss: 0.4242
2023-02-06 13:52:32 | Train | Epoch[012/600] Iteration[002/030] Train loss: 0.4272
2023-02-06 13:52:32 | Train | Epoch[012/600] Iteration[003/030] Train loss: 0.4267
2023-02-06 13:52:32 | Train | Epoch[012/600] Iteration[004/030] Train loss: 0.4262
2023-02-06 13:52:32 | Train | Epoch[012/600] Iteration[005/030] Train loss: 0.4255
2023-02-06 13:52:33 | Train | Epoch[012/600] Iteration[006/030] Train loss: 0.4261
2023-02-06 13:52:33 | Train | Epoch[012/600] Iteration[007/030] Train loss: 0.4256
2023-02-06 13:52:33 | Train | Epoch[012/600] Iteration[008/030] Train loss: 0.4253
2023-02-06 13:52:33 | Train | Epoch[012/600] Iteration[009/030] Train loss: 0.4251
2023-02-06 13:52:34 | Train | Epoch[012/600] Iteration[010/030] Train loss: 0.4253
2023-02-06 13:52:34 | Train | Epoch[012/600] Iteration[011/030] Train loss: 0.4253
2023-02-06 13:52:34 | Train | Epoch[012/600] Iteration[012/030] Train loss: 0.4252
2023-02-06 13:52:34 | Train | Epoch[012/600] Iteration[013/030] Train loss: 0.4244
2023-02-06 13:52:34 | Train | Epoch[012/600] Iteration[014/030] Train loss: 0.4240
2023-02-06 13:52:35 | Train | Epoch[012/600] Iteration[015/030] Train loss: 0.4236
2023-02-06 13:52:35 | Train | Epoch[012/600] Iteration[016/030] Train loss: 0.4240
2023-02-06 13:52:35 | Train | Epoch[012/600] Iteration[017/030] Train loss: 0.4236
2023-02-06 13:52:35 | Train | Epoch[012/600] Iteration[018/030] Train loss: 0.4234
2023-02-06 13:52:35 | Train | Epoch[012/600] Iteration[019/030] Train loss: 0.4232
2023-02-06 13:52:36 | Train | Epoch[012/600] Iteration[020/030] Train loss: 0.4229
2023-02-06 13:52:36 | Train | Epoch[012/600] Iteration[021/030] Train loss: 0.4227
2023-02-06 13:52:36 | Train | Epoch[012/600] Iteration[022/030] Train loss: 0.4223
2023-02-06 13:52:36 | Train | Epoch[012/600] Iteration[023/030] Train loss: 0.4221
2023-02-06 13:52:37 | Train | Epoch[012/600] Iteration[024/030] Train loss: 0.4217
2023-02-06 13:52:37 | Train | Epoch[012/600] Iteration[025/030] Train loss: 0.4213
2023-02-06 13:52:37 | Train | Epoch[012/600] Iteration[026/030] Train loss: 0.4212
2023-02-06 13:52:37 | Train | Epoch[012/600] Iteration[027/030] Train loss: 0.4209
2023-02-06 13:52:37 | Train | Epoch[012/600] Iteration[028/030] Train loss: 0.4206
2023-02-06 13:52:38 | Train | Epoch[012/600] Iteration[029/030] Train loss: 0.4202
2023-02-06 13:52:38 | Train | Epoch[012/600] Iteration[030/030] Train loss: 0.4199
2023-02-06 13:52:38 | Valid | Epoch[012/600] Iteration[001/008] Valid loss: 0.6596
2023-02-06 13:52:38 | Valid | Epoch[012/600] Iteration[002/008] Valid loss: 0.6480
2023-02-06 13:52:38 | Valid | Epoch[012/600] Iteration[003/008] Valid loss: 0.6541
2023-02-06 13:52:38 | Valid | Epoch[012/600] Iteration[004/008] Valid loss: 0.6562
2023-02-06 13:52:38 | Valid | Epoch[012/600] Iteration[005/008] Valid loss: 0.6628
2023-02-06 13:52:38 | Valid | Epoch[012/600] Iteration[006/008] Valid loss: 0.6603
2023-02-06 13:52:38 | Valid | Epoch[012/600] Iteration[007/008] Valid loss: 0.6665
2023-02-06 13:52:39 | Valid | Epoch[012/600] Iteration[008/008] Valid loss: 0.6723
2023-02-06 13:52:39 | Valid | Epoch[012/600] MIou: 0.6834162428694732
2023-02-06 13:52:39 | Valid | Epoch[012/600] Pixel Accuracy: 0.9006856282552084
2023-02-06 13:52:39 | Valid | Epoch[012/600] Mean Pixel Accuracy: 0.9448990074410735
2023-02-06 13:52:39 | Stage | Epoch[012/600] Train loss:0.4199
2023-02-06 13:52:39 | Stage | Epoch[012/600] Valid loss:0.6723
2023-02-06 13:52:39 | Stage | Epoch[012/600] LR:0.01

2023-02-06 13:52:39 | Train | Epoch[013/600] Iteration[001/030] Train loss: 0.4109
2023-02-06 13:52:39 | Train | Epoch[013/600] Iteration[002/030] Train loss: 0.4116
2023-02-06 13:52:40 | Train | Epoch[013/600] Iteration[003/030] Train loss: 0.4116
2023-02-06 13:52:40 | Train | Epoch[013/600] Iteration[004/030] Train loss: 0.4114
2023-02-06 13:52:40 | Train | Epoch[013/600] Iteration[005/030] Train loss: 0.4108
2023-02-06 13:52:40 | Train | Epoch[013/600] Iteration[006/030] Train loss: 0.4101
2023-02-06 13:52:40 | Train | Epoch[013/600] Iteration[007/030] Train loss: 0.4091
2023-02-06 13:52:41 | Train | Epoch[013/600] Iteration[008/030] Train loss: 0.4088
2023-02-06 13:52:41 | Train | Epoch[013/600] Iteration[009/030] Train loss: 0.4086
2023-02-06 13:52:41 | Train | Epoch[013/600] Iteration[010/030] Train loss: 0.4088
2023-02-06 13:52:41 | Train | Epoch[013/600] Iteration[011/030] Train loss: 0.4083
2023-02-06 13:52:41 | Train | Epoch[013/600] Iteration[012/030] Train loss: 0.4080
2023-02-06 13:52:42 | Train | Epoch[013/600] Iteration[013/030] Train loss: 0.4078
2023-02-06 13:52:42 | Train | Epoch[013/600] Iteration[014/030] Train loss: 0.4076
2023-02-06 13:52:42 | Train | Epoch[013/600] Iteration[015/030] Train loss: 0.4076
2023-02-06 13:52:42 | Train | Epoch[013/600] Iteration[016/030] Train loss: 0.4072
2023-02-06 13:52:43 | Train | Epoch[013/600] Iteration[017/030] Train loss: 0.4073
2023-02-06 13:52:43 | Train | Epoch[013/600] Iteration[018/030] Train loss: 0.4070
2023-02-06 13:52:43 | Train | Epoch[013/600] Iteration[019/030] Train loss: 0.4067
2023-02-06 13:52:43 | Train | Epoch[013/600] Iteration[020/030] Train loss: 0.4064
2023-02-06 13:52:43 | Train | Epoch[013/600] Iteration[021/030] Train loss: 0.4062
2023-02-06 13:52:44 | Train | Epoch[013/600] Iteration[022/030] Train loss: 0.4058
2023-02-06 13:52:44 | Train | Epoch[013/600] Iteration[023/030] Train loss: 0.4056
2023-02-06 13:52:44 | Train | Epoch[013/600] Iteration[024/030] Train loss: 0.4051
2023-02-06 13:52:44 | Train | Epoch[013/600] Iteration[025/030] Train loss: 0.4047
2023-02-06 13:52:45 | Train | Epoch[013/600] Iteration[026/030] Train loss: 0.4044
2023-02-06 13:52:45 | Train | Epoch[013/600] Iteration[027/030] Train loss: 0.4040
2023-02-06 13:52:45 | Train | Epoch[013/600] Iteration[028/030] Train loss: 0.4036
2023-02-06 13:52:45 | Train | Epoch[013/600] Iteration[029/030] Train loss: 0.4034
2023-02-06 13:52:45 | Train | Epoch[013/600] Iteration[030/030] Train loss: 0.4032
2023-02-06 13:52:46 | Valid | Epoch[013/600] Iteration[001/008] Valid loss: 0.5222
2023-02-06 13:52:46 | Valid | Epoch[013/600] Iteration[002/008] Valid loss: 0.5176
2023-02-06 13:52:46 | Valid | Epoch[013/600] Iteration[003/008] Valid loss: 0.5222
2023-02-06 13:52:46 | Valid | Epoch[013/600] Iteration[004/008] Valid loss: 0.5250
2023-02-06 13:52:46 | Valid | Epoch[013/600] Iteration[005/008] Valid loss: 0.5299
2023-02-06 13:52:46 | Valid | Epoch[013/600] Iteration[006/008] Valid loss: 0.5291
2023-02-06 13:52:46 | Valid | Epoch[013/600] Iteration[007/008] Valid loss: 0.5345
2023-02-06 13:52:46 | Valid | Epoch[013/600] Iteration[008/008] Valid loss: 0.5368
2023-02-06 13:52:46 | Valid | Epoch[013/600] MIou: 0.7887490922801352
2023-02-06 13:52:46 | Valid | Epoch[013/600] Pixel Accuracy: 0.9481023152669271
2023-02-06 13:52:46 | Valid | Epoch[013/600] Mean Pixel Accuracy: 0.9704223008169773
2023-02-06 13:52:46 | Stage | Epoch[013/600] Train loss:0.4032
2023-02-06 13:52:46 | Stage | Epoch[013/600] Valid loss:0.5368
2023-02-06 13:52:46 | Stage | Epoch[013/600] LR:0.01

2023-02-06 13:52:47 | Train | Epoch[014/600] Iteration[001/030] Train loss: 0.3933
2023-02-06 13:52:47 | Train | Epoch[014/600] Iteration[002/030] Train loss: 0.3940
2023-02-06 13:52:47 | Train | Epoch[014/600] Iteration[003/030] Train loss: 0.3939
2023-02-06 13:52:47 | Train | Epoch[014/600] Iteration[004/030] Train loss: 0.3927
2023-02-06 13:52:47 | Train | Epoch[014/600] Iteration[005/030] Train loss: 0.3934
2023-02-06 13:52:48 | Train | Epoch[014/600] Iteration[006/030] Train loss: 0.3924
2023-02-06 13:52:48 | Train | Epoch[014/600] Iteration[007/030] Train loss: 0.3919
2023-02-06 13:52:48 | Train | Epoch[014/600] Iteration[008/030] Train loss: 0.3918
2023-02-06 13:52:48 | Train | Epoch[014/600] Iteration[009/030] Train loss: 0.3912
2023-02-06 13:52:49 | Train | Epoch[014/600] Iteration[010/030] Train loss: 0.3917
2023-02-06 13:52:49 | Train | Epoch[014/600] Iteration[011/030] Train loss: 0.3911
2023-02-06 13:52:49 | Train | Epoch[014/600] Iteration[012/030] Train loss: 0.3916
2023-02-06 13:52:49 | Train | Epoch[014/600] Iteration[013/030] Train loss: 0.3912
2023-02-06 13:52:49 | Train | Epoch[014/600] Iteration[014/030] Train loss: 0.3912
2023-02-06 13:52:50 | Train | Epoch[014/600] Iteration[015/030] Train loss: 0.3906
2023-02-06 13:52:50 | Train | Epoch[014/600] Iteration[016/030] Train loss: 0.3907
2023-02-06 13:52:50 | Train | Epoch[014/600] Iteration[017/030] Train loss: 0.3906
2023-02-06 13:52:50 | Train | Epoch[014/600] Iteration[018/030] Train loss: 0.3905
2023-02-06 13:52:51 | Train | Epoch[014/600] Iteration[019/030] Train loss: 0.3903
2023-02-06 13:52:51 | Train | Epoch[014/600] Iteration[020/030] Train loss: 0.3900
2023-02-06 13:52:51 | Train | Epoch[014/600] Iteration[021/030] Train loss: 0.3896
2023-02-06 13:52:51 | Train | Epoch[014/600] Iteration[022/030] Train loss: 0.3892
2023-02-06 13:52:51 | Train | Epoch[014/600] Iteration[023/030] Train loss: 0.3889
2023-02-06 13:52:52 | Train | Epoch[014/600] Iteration[024/030] Train loss: 0.3888
2023-02-06 13:52:52 | Train | Epoch[014/600] Iteration[025/030] Train loss: 0.3887
2023-02-06 13:52:52 | Train | Epoch[014/600] Iteration[026/030] Train loss: 0.3884
2023-02-06 13:52:52 | Train | Epoch[014/600] Iteration[027/030] Train loss: 0.3882
2023-02-06 13:52:52 | Train | Epoch[014/600] Iteration[028/030] Train loss: 0.3881
2023-02-06 13:52:53 | Train | Epoch[014/600] Iteration[029/030] Train loss: 0.3877
2023-02-06 13:52:53 | Train | Epoch[014/600] Iteration[030/030] Train loss: 0.3876
2023-02-06 13:52:53 | Valid | Epoch[014/600] Iteration[001/008] Valid loss: 0.4183
2023-02-06 13:52:53 | Valid | Epoch[014/600] Iteration[002/008] Valid loss: 0.4164
2023-02-06 13:52:53 | Valid | Epoch[014/600] Iteration[003/008] Valid loss: 0.4171
2023-02-06 13:52:53 | Valid | Epoch[014/600] Iteration[004/008] Valid loss: 0.4169
2023-02-06 13:52:53 | Valid | Epoch[014/600] Iteration[005/008] Valid loss: 0.4173
2023-02-06 13:52:53 | Valid | Epoch[014/600] Iteration[006/008] Valid loss: 0.4167
2023-02-06 13:52:54 | Valid | Epoch[014/600] Iteration[007/008] Valid loss: 0.4174
2023-02-06 13:52:54 | Valid | Epoch[014/600] Iteration[008/008] Valid loss: 0.4171
2023-02-06 13:52:54 | Valid | Epoch[014/600] MIou: 0.9131046621124199
2023-02-06 13:52:54 | Valid | Epoch[014/600] Pixel Accuracy: 0.9841079711914062
2023-02-06 13:52:54 | Valid | Epoch[014/600] Mean Pixel Accuracy: 0.9683062158429201
2023-02-06 13:52:54 | Stage | Epoch[014/600] Train loss:0.3876
2023-02-06 13:52:54 | Stage | Epoch[014/600] Valid loss:0.4171
2023-02-06 13:52:54 | Stage | Epoch[014/600] LR:0.01

2023-02-06 13:52:54 | Train | Epoch[015/600] Iteration[001/030] Train loss: 0.3767
2023-02-06 13:52:54 | Train | Epoch[015/600] Iteration[002/030] Train loss: 0.3785
2023-02-06 13:52:55 | Train | Epoch[015/600] Iteration[003/030] Train loss: 0.3785
2023-02-06 13:52:55 | Train | Epoch[015/600] Iteration[004/030] Train loss: 0.3784
2023-02-06 13:52:55 | Train | Epoch[015/600] Iteration[005/030] Train loss: 0.3793
2023-02-06 13:52:55 | Train | Epoch[015/600] Iteration[006/030] Train loss: 0.3789
2023-02-06 13:52:55 | Train | Epoch[015/600] Iteration[007/030] Train loss: 0.3783
2023-02-06 13:52:56 | Train | Epoch[015/600] Iteration[008/030] Train loss: 0.3780
2023-02-06 13:52:56 | Train | Epoch[015/600] Iteration[009/030] Train loss: 0.3780
2023-02-06 13:52:56 | Train | Epoch[015/600] Iteration[010/030] Train loss: 0.3783
2023-02-06 13:52:56 | Train | Epoch[015/600] Iteration[011/030] Train loss: 0.3777
2023-02-06 13:52:57 | Train | Epoch[015/600] Iteration[012/030] Train loss: 0.3771
2023-02-06 13:52:57 | Train | Epoch[015/600] Iteration[013/030] Train loss: 0.3771
2023-02-06 13:52:57 | Train | Epoch[015/600] Iteration[014/030] Train loss: 0.3767
2023-02-06 13:52:57 | Train | Epoch[015/600] Iteration[015/030] Train loss: 0.3762
2023-02-06 13:52:57 | Train | Epoch[015/600] Iteration[016/030] Train loss: 0.3760
2023-02-06 13:52:58 | Train | Epoch[015/600] Iteration[017/030] Train loss: 0.3757
2023-02-06 13:52:58 | Train | Epoch[015/600] Iteration[018/030] Train loss: 0.3759
2023-02-06 13:52:58 | Train | Epoch[015/600] Iteration[019/030] Train loss: 0.3756
2023-02-06 13:52:58 | Train | Epoch[015/600] Iteration[020/030] Train loss: 0.3752
2023-02-06 13:52:58 | Train | Epoch[015/600] Iteration[021/030] Train loss: 0.3749
2023-02-06 13:52:59 | Train | Epoch[015/600] Iteration[022/030] Train loss: 0.3746
2023-02-06 13:52:59 | Train | Epoch[015/600] Iteration[023/030] Train loss: 0.3747
2023-02-06 13:52:59 | Train | Epoch[015/600] Iteration[024/030] Train loss: 0.3746
2023-02-06 13:52:59 | Train | Epoch[015/600] Iteration[025/030] Train loss: 0.3741
2023-02-06 13:53:00 | Train | Epoch[015/600] Iteration[026/030] Train loss: 0.3739
2023-02-06 13:53:00 | Train | Epoch[015/600] Iteration[027/030] Train loss: 0.3736
2023-02-06 13:53:00 | Train | Epoch[015/600] Iteration[028/030] Train loss: 0.3734
2023-02-06 13:53:00 | Train | Epoch[015/600] Iteration[029/030] Train loss: 0.3731
2023-02-06 13:53:00 | Train | Epoch[015/600] Iteration[030/030] Train loss: 0.3729
2023-02-06 13:53:01 | Valid | Epoch[015/600] Iteration[001/008] Valid loss: 0.3810
2023-02-06 13:53:01 | Valid | Epoch[015/600] Iteration[002/008] Valid loss: 0.3841
2023-02-06 13:53:01 | Valid | Epoch[015/600] Iteration[003/008] Valid loss: 0.3856
2023-02-06 13:53:01 | Valid | Epoch[015/600] Iteration[004/008] Valid loss: 0.3850
2023-02-06 13:53:01 | Valid | Epoch[015/600] Iteration[005/008] Valid loss: 0.3866
2023-02-06 13:53:01 | Valid | Epoch[015/600] Iteration[006/008] Valid loss: 0.3864
2023-02-06 13:53:01 | Valid | Epoch[015/600] Iteration[007/008] Valid loss: 0.3860
2023-02-06 13:53:01 | Valid | Epoch[015/600] Iteration[008/008] Valid loss: 0.3881
2023-02-06 13:53:01 | Valid | Epoch[015/600] MIou: 0.6432259795214967
2023-02-06 13:53:01 | Valid | Epoch[015/600] Pixel Accuracy: 0.9407857259114584
2023-02-06 13:53:01 | Valid | Epoch[015/600] Mean Pixel Accuracy: 0.6744093971879237
2023-02-06 13:53:01 | Stage | Epoch[015/600] Train loss:0.3729
2023-02-06 13:53:01 | Stage | Epoch[015/600] Valid loss:0.3881
2023-02-06 13:53:01 | Stage | Epoch[015/600] LR:0.01

2023-02-06 13:53:02 | Train | Epoch[016/600] Iteration[001/030] Train loss: 0.3649
2023-02-06 13:53:02 | Train | Epoch[016/600] Iteration[002/030] Train loss: 0.3632
2023-02-06 13:53:02 | Train | Epoch[016/600] Iteration[003/030] Train loss: 0.3627
2023-02-06 13:53:02 | Train | Epoch[016/600] Iteration[004/030] Train loss: 0.3632
2023-02-06 13:53:02 | Train | Epoch[016/600] Iteration[005/030] Train loss: 0.3632
2023-02-06 13:53:03 | Train | Epoch[016/600] Iteration[006/030] Train loss: 0.3625
2023-02-06 13:53:03 | Train | Epoch[016/600] Iteration[007/030] Train loss: 0.3627
2023-02-06 13:53:03 | Train | Epoch[016/600] Iteration[008/030] Train loss: 0.3632
2023-02-06 13:53:03 | Train | Epoch[016/600] Iteration[009/030] Train loss: 0.3625
2023-02-06 13:53:04 | Train | Epoch[016/600] Iteration[010/030] Train loss: 0.3623
2023-02-06 13:53:04 | Train | Epoch[016/600] Iteration[011/030] Train loss: 0.3623
2023-02-06 13:53:04 | Train | Epoch[016/600] Iteration[012/030] Train loss: 0.3626
2023-02-06 13:53:04 | Train | Epoch[016/600] Iteration[013/030] Train loss: 0.3629
2023-02-06 13:53:04 | Train | Epoch[016/600] Iteration[014/030] Train loss: 0.3625
2023-02-06 13:53:05 | Train | Epoch[016/600] Iteration[015/030] Train loss: 0.3622
2023-02-06 13:53:05 | Train | Epoch[016/600] Iteration[016/030] Train loss: 0.3617
2023-02-06 13:53:05 | Train | Epoch[016/600] Iteration[017/030] Train loss: 0.3611
2023-02-06 13:53:05 | Train | Epoch[016/600] Iteration[018/030] Train loss: 0.3613
2023-02-06 13:53:06 | Train | Epoch[016/600] Iteration[019/030] Train loss: 0.3610
2023-02-06 13:53:06 | Train | Epoch[016/600] Iteration[020/030] Train loss: 0.3607
2023-02-06 13:53:06 | Train | Epoch[016/600] Iteration[021/030] Train loss: 0.3605
2023-02-06 13:53:06 | Train | Epoch[016/600] Iteration[022/030] Train loss: 0.3603
2023-02-06 13:53:06 | Train | Epoch[016/600] Iteration[023/030] Train loss: 0.3600
2023-02-06 13:53:07 | Train | Epoch[016/600] Iteration[024/030] Train loss: 0.3598
2023-02-06 13:53:07 | Train | Epoch[016/600] Iteration[025/030] Train loss: 0.3596
2023-02-06 13:53:07 | Train | Epoch[016/600] Iteration[026/030] Train loss: 0.3593
2023-02-06 13:53:07 | Train | Epoch[016/600] Iteration[027/030] Train loss: 0.3592
2023-02-06 13:53:08 | Train | Epoch[016/600] Iteration[028/030] Train loss: 0.3590
2023-02-06 13:53:08 | Train | Epoch[016/600] Iteration[029/030] Train loss: 0.3587
2023-02-06 13:53:08 | Train | Epoch[016/600] Iteration[030/030] Train loss: 0.3584
2023-02-06 13:53:08 | Valid | Epoch[016/600] Iteration[001/008] Valid loss: 0.3886
2023-02-06 13:53:08 | Valid | Epoch[016/600] Iteration[002/008] Valid loss: 0.3918
2023-02-06 13:53:08 | Valid | Epoch[016/600] Iteration[003/008] Valid loss: 0.3948
2023-02-06 13:53:08 | Valid | Epoch[016/600] Iteration[004/008] Valid loss: 0.3934
2023-02-06 13:53:09 | Valid | Epoch[016/600] Iteration[005/008] Valid loss: 0.3971
2023-02-06 13:53:09 | Valid | Epoch[016/600] Iteration[006/008] Valid loss: 0.3966
2023-02-06 13:53:09 | Valid | Epoch[016/600] Iteration[007/008] Valid loss: 0.3969
2023-02-06 13:53:09 | Valid | Epoch[016/600] Iteration[008/008] Valid loss: 0.3996
2023-02-06 13:53:09 | Valid | Epoch[016/600] MIou: 0.6509903798484354
2023-02-06 13:53:09 | Valid | Epoch[016/600] Pixel Accuracy: 0.9404678344726562
2023-02-06 13:53:09 | Valid | Epoch[016/600] Mean Pixel Accuracy: 0.6865288447573389
2023-02-06 13:53:09 | Stage | Epoch[016/600] Train loss:0.3584
2023-02-06 13:53:09 | Stage | Epoch[016/600] Valid loss:0.3996
2023-02-06 13:53:09 | Stage | Epoch[016/600] LR:0.01

2023-02-06 13:53:09 | Train | Epoch[017/600] Iteration[001/030] Train loss: 0.3479
2023-02-06 13:53:09 | Train | Epoch[017/600] Iteration[002/030] Train loss: 0.3488
2023-02-06 13:53:10 | Train | Epoch[017/600] Iteration[003/030] Train loss: 0.3492
2023-02-06 13:53:10 | Train | Epoch[017/600] Iteration[004/030] Train loss: 0.3490
2023-02-06 13:53:10 | Train | Epoch[017/600] Iteration[005/030] Train loss: 0.3495
2023-02-06 13:53:10 | Train | Epoch[017/600] Iteration[006/030] Train loss: 0.3494
2023-02-06 13:53:11 | Train | Epoch[017/600] Iteration[007/030] Train loss: 0.3489
2023-02-06 13:53:11 | Train | Epoch[017/600] Iteration[008/030] Train loss: 0.3485
2023-02-06 13:53:11 | Train | Epoch[017/600] Iteration[009/030] Train loss: 0.3483
2023-02-06 13:53:11 | Train | Epoch[017/600] Iteration[010/030] Train loss: 0.3485
2023-02-06 13:53:11 | Train | Epoch[017/600] Iteration[011/030] Train loss: 0.3487
2023-02-06 13:53:12 | Train | Epoch[017/600] Iteration[012/030] Train loss: 0.3488
2023-02-06 13:53:12 | Train | Epoch[017/600] Iteration[013/030] Train loss: 0.3485
2023-02-06 13:53:12 | Train | Epoch[017/600] Iteration[014/030] Train loss: 0.3481
2023-02-06 13:53:12 | Train | Epoch[017/600] Iteration[015/030] Train loss: 0.3484
2023-02-06 13:53:13 | Train | Epoch[017/600] Iteration[016/030] Train loss: 0.3483
2023-02-06 13:53:13 | Train | Epoch[017/600] Iteration[017/030] Train loss: 0.3481
2023-02-06 13:53:13 | Train | Epoch[017/600] Iteration[018/030] Train loss: 0.3478
2023-02-06 13:53:13 | Train | Epoch[017/600] Iteration[019/030] Train loss: 0.3475
2023-02-06 13:53:13 | Train | Epoch[017/600] Iteration[020/030] Train loss: 0.3474
2023-02-06 13:53:14 | Train | Epoch[017/600] Iteration[021/030] Train loss: 0.3470
2023-02-06 13:53:14 | Train | Epoch[017/600] Iteration[022/030] Train loss: 0.3470
2023-02-06 13:53:14 | Train | Epoch[017/600] Iteration[023/030] Train loss: 0.3466
2023-02-06 13:53:14 | Train | Epoch[017/600] Iteration[024/030] Train loss: 0.3464
2023-02-06 13:53:14 | Train | Epoch[017/600] Iteration[025/030] Train loss: 0.3460
2023-02-06 13:53:15 | Train | Epoch[017/600] Iteration[026/030] Train loss: 0.3458
2023-02-06 13:53:15 | Train | Epoch[017/600] Iteration[027/030] Train loss: 0.3455
2023-02-06 13:53:15 | Train | Epoch[017/600] Iteration[028/030] Train loss: 0.3454
2023-02-06 13:53:15 | Train | Epoch[017/600] Iteration[029/030] Train loss: 0.3453
2023-02-06 13:53:15 | Train | Epoch[017/600] Iteration[030/030] Train loss: 0.3450
2023-02-06 13:53:16 | Valid | Epoch[017/600] Iteration[001/008] Valid loss: 0.3779
2023-02-06 13:53:16 | Valid | Epoch[017/600] Iteration[002/008] Valid loss: 0.3735
2023-02-06 13:53:16 | Valid | Epoch[017/600] Iteration[003/008] Valid loss: 0.3741
2023-02-06 13:53:16 | Valid | Epoch[017/600] Iteration[004/008] Valid loss: 0.3747
2023-02-06 13:53:16 | Valid | Epoch[017/600] Iteration[005/008] Valid loss: 0.3755
2023-02-06 13:53:16 | Valid | Epoch[017/600] Iteration[006/008] Valid loss: 0.3742
2023-02-06 13:53:16 | Valid | Epoch[017/600] Iteration[007/008] Valid loss: 0.3763
2023-02-06 13:53:16 | Valid | Epoch[017/600] Iteration[008/008] Valid loss: 0.3776
2023-02-06 13:53:16 | Valid | Epoch[017/600] MIou: 0.8514437060186264
2023-02-06 13:53:16 | Valid | Epoch[017/600] Pixel Accuracy: 0.9683787027994791
2023-02-06 13:53:16 | Valid | Epoch[017/600] Mean Pixel Accuracy: 0.97546753457726
2023-02-06 13:53:16 | Stage | Epoch[017/600] Train loss:0.3450
2023-02-06 13:53:16 | Stage | Epoch[017/600] Valid loss:0.3776
2023-02-06 13:53:16 | Stage | Epoch[017/600] LR:0.01

2023-02-06 13:53:17 | Train | Epoch[018/600] Iteration[001/030] Train loss: 0.3378
2023-02-06 13:53:17 | Train | Epoch[018/600] Iteration[002/030] Train loss: 0.3379
2023-02-06 13:53:17 | Train | Epoch[018/600] Iteration[003/030] Train loss: 0.3389
2023-02-06 13:53:17 | Train | Epoch[018/600] Iteration[004/030] Train loss: 0.3375
2023-02-06 13:53:18 | Train | Epoch[018/600] Iteration[005/030] Train loss: 0.3370
2023-02-06 13:53:18 | Train | Epoch[018/600] Iteration[006/030] Train loss: 0.3365
2023-02-06 13:53:18 | Train | Epoch[018/600] Iteration[007/030] Train loss: 0.3357
2023-02-06 13:53:18 | Train | Epoch[018/600] Iteration[008/030] Train loss: 0.3356
2023-02-06 13:53:19 | Train | Epoch[018/600] Iteration[009/030] Train loss: 0.3369
2023-02-06 13:53:19 | Train | Epoch[018/600] Iteration[010/030] Train loss: 0.3369
2023-02-06 13:53:19 | Train | Epoch[018/600] Iteration[011/030] Train loss: 0.3364
2023-02-06 13:53:19 | Train | Epoch[018/600] Iteration[012/030] Train loss: 0.3361
2023-02-06 13:53:19 | Train | Epoch[018/600] Iteration[013/030] Train loss: 0.3357
2023-02-06 13:53:20 | Train | Epoch[018/600] Iteration[014/030] Train loss: 0.3352
2023-02-06 13:53:20 | Train | Epoch[018/600] Iteration[015/030] Train loss: 0.3356
2023-02-06 13:53:20 | Train | Epoch[018/600] Iteration[016/030] Train loss: 0.3353
2023-02-06 13:53:20 | Train | Epoch[018/600] Iteration[017/030] Train loss: 0.3351
2023-02-06 13:53:21 | Train | Epoch[018/600] Iteration[018/030] Train loss: 0.3350
2023-02-06 13:53:21 | Train | Epoch[018/600] Iteration[019/030] Train loss: 0.3347
2023-02-06 13:53:21 | Train | Epoch[018/600] Iteration[020/030] Train loss: 0.3344
2023-02-06 13:53:21 | Train | Epoch[018/600] Iteration[021/030] Train loss: 0.3343
2023-02-06 13:53:21 | Train | Epoch[018/600] Iteration[022/030] Train loss: 0.3342
2023-02-06 13:53:22 | Train | Epoch[018/600] Iteration[023/030] Train loss: 0.3339
2023-02-06 13:53:22 | Train | Epoch[018/600] Iteration[024/030] Train loss: 0.3337
2023-02-06 13:53:22 | Train | Epoch[018/600] Iteration[025/030] Train loss: 0.3335
2023-02-06 13:53:22 | Train | Epoch[018/600] Iteration[026/030] Train loss: 0.3334
2023-02-06 13:53:22 | Train | Epoch[018/600] Iteration[027/030] Train loss: 0.3331
2023-02-06 13:53:23 | Train | Epoch[018/600] Iteration[028/030] Train loss: 0.3331
2023-02-06 13:53:23 | Train | Epoch[018/600] Iteration[029/030] Train loss: 0.3327
2023-02-06 13:53:23 | Train | Epoch[018/600] Iteration[030/030] Train loss: 0.3325
2023-02-06 13:53:23 | Valid | Epoch[018/600] Iteration[001/008] Valid loss: 0.3558
2023-02-06 13:53:23 | Valid | Epoch[018/600] Iteration[002/008] Valid loss: 0.3580
2023-02-06 13:53:23 | Valid | Epoch[018/600] Iteration[003/008] Valid loss: 0.3583
2023-02-06 13:53:24 | Valid | Epoch[018/600] Iteration[004/008] Valid loss: 0.3578
2023-02-06 13:53:24 | Valid | Epoch[018/600] Iteration[005/008] Valid loss: 0.3583
2023-02-06 13:53:24 | Valid | Epoch[018/600] Iteration[006/008] Valid loss: 0.3578
2023-02-06 13:53:24 | Valid | Epoch[018/600] Iteration[007/008] Valid loss: 0.3570
2023-02-06 13:53:24 | Valid | Epoch[018/600] Iteration[008/008] Valid loss: 0.3577
2023-02-06 13:53:24 | Valid | Epoch[018/600] MIou: 0.7658257703935647
2023-02-06 13:53:24 | Valid | Epoch[018/600] Pixel Accuracy: 0.9610239664713541
2023-02-06 13:53:24 | Valid | Epoch[018/600] Mean Pixel Accuracy: 0.7887814354424338
2023-02-06 13:53:24 | Stage | Epoch[018/600] Train loss:0.3325
2023-02-06 13:53:24 | Stage | Epoch[018/600] Valid loss:0.3577
2023-02-06 13:53:24 | Stage | Epoch[018/600] LR:0.01

2023-02-06 13:53:24 | Train | Epoch[019/600] Iteration[001/030] Train loss: 0.3257
2023-02-06 13:53:25 | Train | Epoch[019/600] Iteration[002/030] Train loss: 0.3248
2023-02-06 13:53:25 | Train | Epoch[019/600] Iteration[003/030] Train loss: 0.3232
2023-02-06 13:53:25 | Train | Epoch[019/600] Iteration[004/030] Train loss: 0.3232
2023-02-06 13:53:25 | Train | Epoch[019/600] Iteration[005/030] Train loss: 0.3227
2023-02-06 13:53:25 | Train | Epoch[019/600] Iteration[006/030] Train loss: 0.3227
2023-02-06 13:53:26 | Train | Epoch[019/600] Iteration[007/030] Train loss: 0.3225
2023-02-06 13:53:26 | Train | Epoch[019/600] Iteration[008/030] Train loss: 0.3220
2023-02-06 13:53:26 | Train | Epoch[019/600] Iteration[009/030] Train loss: 0.3220
2023-02-06 13:53:26 | Train | Epoch[019/600] Iteration[010/030] Train loss: 0.3220
2023-02-06 13:53:27 | Train | Epoch[019/600] Iteration[011/030] Train loss: 0.3218
2023-02-06 13:53:27 | Train | Epoch[019/600] Iteration[012/030] Train loss: 0.3222
2023-02-06 13:53:27 | Train | Epoch[019/600] Iteration[013/030] Train loss: 0.3222
2023-02-06 13:53:27 | Train | Epoch[019/600] Iteration[014/030] Train loss: 0.3221
2023-02-06 13:53:27 | Train | Epoch[019/600] Iteration[015/030] Train loss: 0.3220
2023-02-06 13:53:28 | Train | Epoch[019/600] Iteration[016/030] Train loss: 0.3224
2023-02-06 13:53:28 | Train | Epoch[019/600] Iteration[017/030] Train loss: 0.3223
2023-02-06 13:53:28 | Train | Epoch[019/600] Iteration[018/030] Train loss: 0.3221
2023-02-06 13:53:28 | Train | Epoch[019/600] Iteration[019/030] Train loss: 0.3218
2023-02-06 13:53:28 | Train | Epoch[019/600] Iteration[020/030] Train loss: 0.3216
2023-02-06 13:53:29 | Train | Epoch[019/600] Iteration[021/030] Train loss: 0.3216
2023-02-06 13:53:29 | Train | Epoch[019/600] Iteration[022/030] Train loss: 0.3215
2023-02-06 13:53:29 | Train | Epoch[019/600] Iteration[023/030] Train loss: 0.3213
2023-02-06 13:53:29 | Train | Epoch[019/600] Iteration[024/030] Train loss: 0.3209
2023-02-06 13:53:30 | Train | Epoch[019/600] Iteration[025/030] Train loss: 0.3205
2023-02-06 13:53:30 | Train | Epoch[019/600] Iteration[026/030] Train loss: 0.3203
2023-02-06 13:53:30 | Train | Epoch[019/600] Iteration[027/030] Train loss: 0.3202
2023-02-06 13:53:30 | Train | Epoch[019/600] Iteration[028/030] Train loss: 0.3200
2023-02-06 13:53:30 | Train | Epoch[019/600] Iteration[029/030] Train loss: 0.3198
2023-02-06 13:53:31 | Train | Epoch[019/600] Iteration[030/030] Train loss: 0.3195
2023-02-06 13:53:31 | Valid | Epoch[019/600] Iteration[001/008] Valid loss: 0.4352
2023-02-06 13:53:31 | Valid | Epoch[019/600] Iteration[002/008] Valid loss: 0.4284
2023-02-06 13:53:31 | Valid | Epoch[019/600] Iteration[003/008] Valid loss: 0.4297
2023-02-06 13:53:31 | Valid | Epoch[019/600] Iteration[004/008] Valid loss: 0.4314
2023-02-06 13:53:31 | Valid | Epoch[019/600] Iteration[005/008] Valid loss: 0.4352
2023-02-06 13:53:31 | Valid | Epoch[019/600] Iteration[006/008] Valid loss: 0.4336
2023-02-06 13:53:31 | Valid | Epoch[019/600] Iteration[007/008] Valid loss: 0.4390
2023-02-06 13:53:31 | Valid | Epoch[019/600] Iteration[008/008] Valid loss: 0.4412
2023-02-06 13:53:31 | Valid | Epoch[019/600] MIou: 0.8374356845215951
2023-02-06 13:53:31 | Valid | Epoch[019/600] Pixel Accuracy: 0.9641151428222656
2023-02-06 13:53:31 | Valid | Epoch[019/600] Mean Pixel Accuracy: 0.9772707685462485
2023-02-06 13:53:31 | Stage | Epoch[019/600] Train loss:0.3195
2023-02-06 13:53:31 | Stage | Epoch[019/600] Valid loss:0.4412
2023-02-06 13:53:31 | Stage | Epoch[019/600] LR:0.01

2023-02-06 13:53:32 | Train | Epoch[020/600] Iteration[001/030] Train loss: 0.3187
2023-02-06 13:53:32 | Train | Epoch[020/600] Iteration[002/030] Train loss: 0.3157
2023-02-06 13:53:32 | Train | Epoch[020/600] Iteration[003/030] Train loss: 0.3140
2023-02-06 13:53:32 | Train | Epoch[020/600] Iteration[004/030] Train loss: 0.3134
2023-02-06 13:53:33 | Train | Epoch[020/600] Iteration[005/030] Train loss: 0.3125
2023-02-06 13:53:33 | Train | Epoch[020/600] Iteration[006/030] Train loss: 0.3119
2023-02-06 13:53:33 | Train | Epoch[020/600] Iteration[007/030] Train loss: 0.3119
2023-02-06 13:53:33 | Train | Epoch[020/600] Iteration[008/030] Train loss: 0.3117
2023-02-06 13:53:34 | Train | Epoch[020/600] Iteration[009/030] Train loss: 0.3118
2023-02-06 13:53:34 | Train | Epoch[020/600] Iteration[010/030] Train loss: 0.3114
2023-02-06 13:53:34 | Train | Epoch[020/600] Iteration[011/030] Train loss: 0.3111
2023-02-06 13:53:34 | Train | Epoch[020/600] Iteration[012/030] Train loss: 0.3112
2023-02-06 13:53:34 | Train | Epoch[020/600] Iteration[013/030] Train loss: 0.3107
2023-02-06 13:53:35 | Train | Epoch[020/600] Iteration[014/030] Train loss: 0.3107
2023-02-06 13:53:35 | Train | Epoch[020/600] Iteration[015/030] Train loss: 0.3109
2023-02-06 13:53:35 | Train | Epoch[020/600] Iteration[016/030] Train loss: 0.3107
2023-02-06 13:53:35 | Train | Epoch[020/600] Iteration[017/030] Train loss: 0.3105
2023-02-06 13:53:36 | Train | Epoch[020/600] Iteration[018/030] Train loss: 0.3102
2023-02-06 13:53:36 | Train | Epoch[020/600] Iteration[019/030] Train loss: 0.3099
2023-02-06 13:53:36 | Train | Epoch[020/600] Iteration[020/030] Train loss: 0.3097
2023-02-06 13:53:36 | Train | Epoch[020/600] Iteration[021/030] Train loss: 0.3094
2023-02-06 13:53:36 | Train | Epoch[020/600] Iteration[022/030] Train loss: 0.3090
2023-02-06 13:53:37 | Train | Epoch[020/600] Iteration[023/030] Train loss: 0.3092
2023-02-06 13:53:37 | Train | Epoch[020/600] Iteration[024/030] Train loss: 0.3090
2023-02-06 13:53:37 | Train | Epoch[020/600] Iteration[025/030] Train loss: 0.3088
2023-02-06 13:53:37 | Train | Epoch[020/600] Iteration[026/030] Train loss: 0.3086
2023-02-06 13:53:37 | Train | Epoch[020/600] Iteration[027/030] Train loss: 0.3083
2023-02-06 13:53:38 | Train | Epoch[020/600] Iteration[028/030] Train loss: 0.3081
2023-02-06 13:53:38 | Train | Epoch[020/600] Iteration[029/030] Train loss: 0.3078
2023-02-06 13:53:38 | Train | Epoch[020/600] Iteration[030/030] Train loss: 0.3079
2023-02-06 13:53:38 | Valid | Epoch[020/600] Iteration[001/008] Valid loss: 2.3214
2023-02-06 13:53:38 | Valid | Epoch[020/600] Iteration[002/008] Valid loss: 2.2610
2023-02-06 13:53:38 | Valid | Epoch[020/600] Iteration[003/008] Valid loss: 2.3603
2023-02-06 13:53:38 | Valid | Epoch[020/600] Iteration[004/008] Valid loss: 2.4007
2023-02-06 13:53:39 | Valid | Epoch[020/600] Iteration[005/008] Valid loss: 2.4579
2023-02-06 13:53:39 | Valid | Epoch[020/600] Iteration[006/008] Valid loss: 2.4114
2023-02-06 13:53:39 | Valid | Epoch[020/600] Iteration[007/008] Valid loss: 2.4703
2023-02-06 13:53:39 | Valid | Epoch[020/600] Iteration[008/008] Valid loss: 2.5746
2023-02-06 13:53:39 | Valid | Epoch[020/600] MIou: 0.5139144925316399
2023-02-06 13:53:39 | Valid | Epoch[020/600] Pixel Accuracy: 0.7693570454915365
2023-02-06 13:53:39 | Valid | Epoch[020/600] Mean Pixel Accuracy: 0.8731590503314177
2023-02-06 13:53:39 | Stage | Epoch[020/600] Train loss:0.3079
2023-02-06 13:53:39 | Stage | Epoch[020/600] Valid loss:2.5746
2023-02-06 13:53:39 | Stage | Epoch[020/600] LR:0.01

2023-02-06 13:53:39 | Train | Epoch[021/600] Iteration[001/030] Train loss: 0.3006
2023-02-06 13:53:39 | Train | Epoch[021/600] Iteration[002/030] Train loss: 0.3015
2023-02-06 13:53:40 | Train | Epoch[021/600] Iteration[003/030] Train loss: 0.3009
2023-02-06 13:53:40 | Train | Epoch[021/600] Iteration[004/030] Train loss: 0.3009
2023-02-06 13:53:40 | Train | Epoch[021/600] Iteration[005/030] Train loss: 0.3005
2023-02-06 13:53:40 | Train | Epoch[021/600] Iteration[006/030] Train loss: 0.3012
2023-02-06 13:53:41 | Train | Epoch[021/600] Iteration[007/030] Train loss: 0.3017
2023-02-06 13:53:41 | Train | Epoch[021/600] Iteration[008/030] Train loss: 0.3022
2023-02-06 13:53:41 | Train | Epoch[021/600] Iteration[009/030] Train loss: 0.3031
2023-02-06 13:53:41 | Train | Epoch[021/600] Iteration[010/030] Train loss: 0.3027
2023-02-06 13:53:41 | Train | Epoch[021/600] Iteration[011/030] Train loss: 0.3022
2023-02-06 13:53:42 | Train | Epoch[021/600] Iteration[012/030] Train loss: 0.3021
2023-02-06 13:53:42 | Train | Epoch[021/600] Iteration[013/030] Train loss: 0.3019
2023-02-06 13:53:42 | Train | Epoch[021/600] Iteration[014/030] Train loss: 0.3017
2023-02-06 13:53:42 | Train | Epoch[021/600] Iteration[015/030] Train loss: 0.3015
2023-02-06 13:53:42 | Train | Epoch[021/600] Iteration[016/030] Train loss: 0.3016
2023-02-06 13:53:43 | Train | Epoch[021/600] Iteration[017/030] Train loss: 0.3015
2023-02-06 13:53:43 | Train | Epoch[021/600] Iteration[018/030] Train loss: 0.3016
2023-02-06 13:53:43 | Train | Epoch[021/600] Iteration[019/030] Train loss: 0.3013
2023-02-06 13:53:43 | Train | Epoch[021/600] Iteration[020/030] Train loss: 0.3010
2023-02-06 13:53:44 | Train | Epoch[021/600] Iteration[021/030] Train loss: 0.3006
2023-02-06 13:53:44 | Train | Epoch[021/600] Iteration[022/030] Train loss: 0.3008
2023-02-06 13:53:44 | Train | Epoch[021/600] Iteration[023/030] Train loss: 0.3005
2023-02-06 13:53:44 | Train | Epoch[021/600] Iteration[024/030] Train loss: 0.3002
2023-02-06 13:53:44 | Train | Epoch[021/600] Iteration[025/030] Train loss: 0.2999
2023-02-06 13:53:45 | Train | Epoch[021/600] Iteration[026/030] Train loss: 0.2996
2023-02-06 13:53:45 | Train | Epoch[021/600] Iteration[027/030] Train loss: 0.2993
2023-02-06 13:53:45 | Train | Epoch[021/600] Iteration[028/030] Train loss: 0.2992
2023-02-06 13:53:45 | Train | Epoch[021/600] Iteration[029/030] Train loss: 0.2990
2023-02-06 13:53:45 | Train | Epoch[021/600] Iteration[030/030] Train loss: 0.2988
2023-02-06 13:53:46 | Valid | Epoch[021/600] Iteration[001/008] Valid loss: 0.3266
2023-02-06 13:53:46 | Valid | Epoch[021/600] Iteration[002/008] Valid loss: 0.3238
2023-02-06 13:53:46 | Valid | Epoch[021/600] Iteration[003/008] Valid loss: 0.3241
2023-02-06 13:53:46 | Valid | Epoch[021/600] Iteration[004/008] Valid loss: 0.3244
2023-02-06 13:53:46 | Valid | Epoch[021/600] Iteration[005/008] Valid loss: 0.3247
2023-02-06 13:53:46 | Valid | Epoch[021/600] Iteration[006/008] Valid loss: 0.3234
2023-02-06 13:53:46 | Valid | Epoch[021/600] Iteration[007/008] Valid loss: 0.3248
2023-02-06 13:53:46 | Valid | Epoch[021/600] Iteration[008/008] Valid loss: 0.3266
2023-02-06 13:53:46 | Valid | Epoch[021/600] MIou: 0.867101481041731
2023-02-06 13:53:46 | Valid | Epoch[021/600] Pixel Accuracy: 0.9728736877441406
2023-02-06 13:53:46 | Valid | Epoch[021/600] Mean Pixel Accuracy: 0.9724663430943923
2023-02-06 13:53:46 | Stage | Epoch[021/600] Train loss:0.2988
2023-02-06 13:53:46 | Stage | Epoch[021/600] Valid loss:0.3266
2023-02-06 13:53:46 | Stage | Epoch[021/600] LR:0.01

2023-02-06 13:53:47 | Train | Epoch[022/600] Iteration[001/030] Train loss: 0.2890
2023-02-06 13:53:47 | Train | Epoch[022/600] Iteration[002/030] Train loss: 0.2905
2023-02-06 13:53:47 | Train | Epoch[022/600] Iteration[003/030] Train loss: 0.2894
2023-02-06 13:53:47 | Train | Epoch[022/600] Iteration[004/030] Train loss: 0.2892
2023-02-06 13:53:48 | Train | Epoch[022/600] Iteration[005/030] Train loss: 0.2893
2023-02-06 13:53:48 | Train | Epoch[022/600] Iteration[006/030] Train loss: 0.2910
2023-02-06 13:53:48 | Train | Epoch[022/600] Iteration[007/030] Train loss: 0.2904
2023-02-06 13:53:48 | Train | Epoch[022/600] Iteration[008/030] Train loss: 0.2900
2023-02-06 13:53:48 | Train | Epoch[022/600] Iteration[009/030] Train loss: 0.2896
2023-02-06 13:53:49 | Train | Epoch[022/600] Iteration[010/030] Train loss: 0.2894
2023-02-06 13:53:49 | Train | Epoch[022/600] Iteration[011/030] Train loss: 0.2895
2023-02-06 13:53:49 | Train | Epoch[022/600] Iteration[012/030] Train loss: 0.2891
2023-02-06 13:53:49 | Train | Epoch[022/600] Iteration[013/030] Train loss: 0.2890
2023-02-06 13:53:50 | Train | Epoch[022/600] Iteration[014/030] Train loss: 0.2892
2023-02-06 13:53:50 | Train | Epoch[022/600] Iteration[015/030] Train loss: 0.2889
2023-02-06 13:53:50 | Train | Epoch[022/600] Iteration[016/030] Train loss: 0.2888
2023-02-06 13:53:50 | Train | Epoch[022/600] Iteration[017/030] Train loss: 0.2885
2023-02-06 13:53:50 | Train | Epoch[022/600] Iteration[018/030] Train loss: 0.2885
2023-02-06 13:53:51 | Train | Epoch[022/600] Iteration[019/030] Train loss: 0.2883
2023-02-06 13:53:51 | Train | Epoch[022/600] Iteration[020/030] Train loss: 0.2882
2023-02-06 13:53:51 | Train | Epoch[022/600] Iteration[021/030] Train loss: 0.2882
2023-02-06 13:53:51 | Train | Epoch[022/600] Iteration[022/030] Train loss: 0.2882
2023-02-06 13:53:52 | Train | Epoch[022/600] Iteration[023/030] Train loss: 0.2882
2023-02-06 13:53:52 | Train | Epoch[022/600] Iteration[024/030] Train loss: 0.2882
2023-02-06 13:53:52 | Train | Epoch[022/600] Iteration[025/030] Train loss: 0.2880
2023-02-06 13:53:52 | Train | Epoch[022/600] Iteration[026/030] Train loss: 0.2878
2023-02-06 13:53:52 | Train | Epoch[022/600] Iteration[027/030] Train loss: 0.2875
2023-02-06 13:53:53 | Train | Epoch[022/600] Iteration[028/030] Train loss: 0.2874
2023-02-06 13:53:53 | Train | Epoch[022/600] Iteration[029/030] Train loss: 0.2871
2023-02-06 13:53:53 | Train | Epoch[022/600] Iteration[030/030] Train loss: 0.2870
2023-02-06 13:53:53 | Valid | Epoch[022/600] Iteration[001/008] Valid loss: 0.3102
2023-02-06 13:53:53 | Valid | Epoch[022/600] Iteration[002/008] Valid loss: 0.3079
2023-02-06 13:53:53 | Valid | Epoch[022/600] Iteration[003/008] Valid loss: 0.3085
2023-02-06 13:53:53 | Valid | Epoch[022/600] Iteration[004/008] Valid loss: 0.3082
2023-02-06 13:53:53 | Valid | Epoch[022/600] Iteration[005/008] Valid loss: 0.3091
2023-02-06 13:53:54 | Valid | Epoch[022/600] Iteration[006/008] Valid loss: 0.3090
2023-02-06 13:53:54 | Valid | Epoch[022/600] Iteration[007/008] Valid loss: 0.3098
2023-02-06 13:53:54 | Valid | Epoch[022/600] Iteration[008/008] Valid loss: 0.3098
2023-02-06 13:53:54 | Valid | Epoch[022/600] MIou: 0.9004380611596362
2023-02-06 13:53:54 | Valid | Epoch[022/600] Pixel Accuracy: 0.9814580281575521
2023-02-06 13:53:54 | Valid | Epoch[022/600] Mean Pixel Accuracy: 0.963926736767108
2023-02-06 13:53:54 | Stage | Epoch[022/600] Train loss:0.2870
2023-02-06 13:53:54 | Stage | Epoch[022/600] Valid loss:0.3098
2023-02-06 13:53:54 | Stage | Epoch[022/600] LR:0.01

2023-02-06 13:53:54 | Train | Epoch[023/600] Iteration[001/030] Train loss: 0.2775
2023-02-06 13:53:54 | Train | Epoch[023/600] Iteration[002/030] Train loss: 0.2800
2023-02-06 13:53:55 | Train | Epoch[023/600] Iteration[003/030] Train loss: 0.2795
2023-02-06 13:53:55 | Train | Epoch[023/600] Iteration[004/030] Train loss: 0.2785
2023-02-06 13:53:55 | Train | Epoch[023/600] Iteration[005/030] Train loss: 0.2786
2023-02-06 13:53:55 | Train | Epoch[023/600] Iteration[006/030] Train loss: 0.2785
2023-02-06 13:53:55 | Train | Epoch[023/600] Iteration[007/030] Train loss: 0.2784
2023-02-06 13:53:56 | Train | Epoch[023/600] Iteration[008/030] Train loss: 0.2787
2023-02-06 13:53:56 | Train | Epoch[023/600] Iteration[009/030] Train loss: 0.2794
2023-02-06 13:53:56 | Train | Epoch[023/600] Iteration[010/030] Train loss: 0.2791
2023-02-06 13:53:56 | Train | Epoch[023/600] Iteration[011/030] Train loss: 0.2789
2023-02-06 13:53:57 | Train | Epoch[023/600] Iteration[012/030] Train loss: 0.2789
2023-02-06 13:53:57 | Train | Epoch[023/600] Iteration[013/030] Train loss: 0.2788
2023-02-06 13:53:57 | Train | Epoch[023/600] Iteration[014/030] Train loss: 0.2787
2023-02-06 13:53:57 | Train | Epoch[023/600] Iteration[015/030] Train loss: 0.2783
2023-02-06 13:53:57 | Train | Epoch[023/600] Iteration[016/030] Train loss: 0.2781
2023-02-06 13:53:58 | Train | Epoch[023/600] Iteration[017/030] Train loss: 0.2780
2023-02-06 13:53:58 | Train | Epoch[023/600] Iteration[018/030] Train loss: 0.2777
2023-02-06 13:53:58 | Train | Epoch[023/600] Iteration[019/030] Train loss: 0.2775
2023-02-06 13:53:58 | Train | Epoch[023/600] Iteration[020/030] Train loss: 0.2772
2023-02-06 13:53:59 | Train | Epoch[023/600] Iteration[021/030] Train loss: 0.2770
2023-02-06 13:53:59 | Train | Epoch[023/600] Iteration[022/030] Train loss: 0.2770
2023-02-06 13:53:59 | Train | Epoch[023/600] Iteration[023/030] Train loss: 0.2767
2023-02-06 13:53:59 | Train | Epoch[023/600] Iteration[024/030] Train loss: 0.2767
2023-02-06 13:53:59 | Train | Epoch[023/600] Iteration[025/030] Train loss: 0.2766
2023-02-06 13:54:00 | Train | Epoch[023/600] Iteration[026/030] Train loss: 0.2764
2023-02-06 13:54:00 | Train | Epoch[023/600] Iteration[027/030] Train loss: 0.2762
2023-02-06 13:54:00 | Train | Epoch[023/600] Iteration[028/030] Train loss: 0.2761
2023-02-06 13:54:00 | Train | Epoch[023/600] Iteration[029/030] Train loss: 0.2759
2023-02-06 13:54:00 | Train | Epoch[023/600] Iteration[030/030] Train loss: 0.2758
2023-02-06 13:54:01 | Valid | Epoch[023/600] Iteration[001/008] Valid loss: 0.2926
2023-02-06 13:54:01 | Valid | Epoch[023/600] Iteration[002/008] Valid loss: 0.2908
2023-02-06 13:54:01 | Valid | Epoch[023/600] Iteration[003/008] Valid loss: 0.2905
2023-02-06 13:54:01 | Valid | Epoch[023/600] Iteration[004/008] Valid loss: 0.2897
2023-02-06 13:54:01 | Valid | Epoch[023/600] Iteration[005/008] Valid loss: 0.2899
2023-02-06 13:54:01 | Valid | Epoch[023/600] Iteration[006/008] Valid loss: 0.2897
2023-02-06 13:54:01 | Valid | Epoch[023/600] Iteration[007/008] Valid loss: 0.2901
2023-02-06 13:54:01 | Valid | Epoch[023/600] Iteration[008/008] Valid loss: 0.2900
2023-02-06 13:54:01 | Valid | Epoch[023/600] MIou: 0.8991701648319486
2023-02-06 13:54:01 | Valid | Epoch[023/600] Pixel Accuracy: 0.9830322265625
2023-02-06 13:54:01 | Valid | Epoch[023/600] Mean Pixel Accuracy: 0.9172764898368796
2023-02-06 13:54:01 | Stage | Epoch[023/600] Train loss:0.2758
2023-02-06 13:54:01 | Stage | Epoch[023/600] Valid loss:0.2900
2023-02-06 13:54:01 | Stage | Epoch[023/600] LR:0.01

2023-02-06 13:54:02 | Train | Epoch[024/600] Iteration[001/030] Train loss: 0.2744
2023-02-06 13:54:02 | Train | Epoch[024/600] Iteration[002/030] Train loss: 0.2727
2023-02-06 13:54:02 | Train | Epoch[024/600] Iteration[003/030] Train loss: 0.2719
2023-02-06 13:54:02 | Train | Epoch[024/600] Iteration[004/030] Train loss: 0.2712
2023-02-06 13:54:03 | Train | Epoch[024/600] Iteration[005/030] Train loss: 0.2707
2023-02-06 13:54:03 | Train | Epoch[024/600] Iteration[006/030] Train loss: 0.2705
2023-02-06 13:54:03 | Train | Epoch[024/600] Iteration[007/030] Train loss: 0.2702
2023-02-06 13:54:03 | Train | Epoch[024/600] Iteration[008/030] Train loss: 0.2706
2023-02-06 13:54:03 | Train | Epoch[024/600] Iteration[009/030] Train loss: 0.2704
2023-02-06 13:54:04 | Train | Epoch[024/600] Iteration[010/030] Train loss: 0.2702
2023-02-06 13:54:04 | Train | Epoch[024/600] Iteration[011/030] Train loss: 0.2697
2023-02-06 13:54:04 | Train | Epoch[024/600] Iteration[012/030] Train loss: 0.2692
2023-02-06 13:54:04 | Train | Epoch[024/600] Iteration[013/030] Train loss: 0.2691
2023-02-06 13:54:05 | Train | Epoch[024/600] Iteration[014/030] Train loss: 0.2688
2023-02-06 13:54:05 | Train | Epoch[024/600] Iteration[015/030] Train loss: 0.2685
2023-02-06 13:54:05 | Train | Epoch[024/600] Iteration[016/030] Train loss: 0.2682
2023-02-06 13:54:05 | Train | Epoch[024/600] Iteration[017/030] Train loss: 0.2684
2023-02-06 13:54:05 | Train | Epoch[024/600] Iteration[018/030] Train loss: 0.2682
2023-02-06 13:54:06 | Train | Epoch[024/600] Iteration[019/030] Train loss: 0.2680
2023-02-06 13:54:06 | Train | Epoch[024/600] Iteration[020/030] Train loss: 0.2678
2023-02-06 13:54:06 | Train | Epoch[024/600] Iteration[021/030] Train loss: 0.2676
2023-02-06 13:54:06 | Train | Epoch[024/600] Iteration[022/030] Train loss: 0.2673
2023-02-06 13:54:07 | Train | Epoch[024/600] Iteration[023/030] Train loss: 0.2676
2023-02-06 13:54:07 | Train | Epoch[024/600] Iteration[024/030] Train loss: 0.2672
2023-02-06 13:54:07 | Train | Epoch[024/600] Iteration[025/030] Train loss: 0.2670
2023-02-06 13:54:07 | Train | Epoch[024/600] Iteration[026/030] Train loss: 0.2669
2023-02-06 13:54:07 | Train | Epoch[024/600] Iteration[027/030] Train loss: 0.2666
2023-02-06 13:54:08 | Train | Epoch[024/600] Iteration[028/030] Train loss: 0.2663
2023-02-06 13:54:08 | Train | Epoch[024/600] Iteration[029/030] Train loss: 0.2662
2023-02-06 13:54:08 | Train | Epoch[024/600] Iteration[030/030] Train loss: 0.2661
2023-02-06 13:54:08 | Valid | Epoch[024/600] Iteration[001/008] Valid loss: 0.3590
2023-02-06 13:54:08 | Valid | Epoch[024/600] Iteration[002/008] Valid loss: 0.3601
2023-02-06 13:54:08 | Valid | Epoch[024/600] Iteration[003/008] Valid loss: 0.3629
2023-02-06 13:54:08 | Valid | Epoch[024/600] Iteration[004/008] Valid loss: 0.3650
2023-02-06 13:54:08 | Valid | Epoch[024/600] Iteration[005/008] Valid loss: 0.3663
2023-02-06 13:54:09 | Valid | Epoch[024/600] Iteration[006/008] Valid loss: 0.3653
2023-02-06 13:54:09 | Valid | Epoch[024/600] Iteration[007/008] Valid loss: 0.3686
2023-02-06 13:54:09 | Valid | Epoch[024/600] Iteration[008/008] Valid loss: 0.3712
2023-02-06 13:54:09 | Valid | Epoch[024/600] MIou: 0.8299319665848035
2023-02-06 13:54:09 | Valid | Epoch[024/600] Pixel Accuracy: 0.9618479410807291
2023-02-06 13:54:09 | Valid | Epoch[024/600] Mean Pixel Accuracy: 0.9763479818224006
2023-02-06 13:54:09 | Stage | Epoch[024/600] Train loss:0.2661
2023-02-06 13:54:09 | Stage | Epoch[024/600] Valid loss:0.3712
2023-02-06 13:54:09 | Stage | Epoch[024/600] LR:0.01

2023-02-06 13:54:09 | Train | Epoch[025/600] Iteration[001/030] Train loss: 0.2592
2023-02-06 13:54:09 | Train | Epoch[025/600] Iteration[002/030] Train loss: 0.2596
2023-02-06 13:54:10 | Train | Epoch[025/600] Iteration[003/030] Train loss: 0.2592
2023-02-06 13:54:10 | Train | Epoch[025/600] Iteration[004/030] Train loss: 0.2591
2023-02-06 13:54:10 | Train | Epoch[025/600] Iteration[005/030] Train loss: 0.2606
2023-02-06 13:54:10 | Train | Epoch[025/600] Iteration[006/030] Train loss: 0.2601
2023-02-06 13:54:11 | Train | Epoch[025/600] Iteration[007/030] Train loss: 0.2598
2023-02-06 13:54:11 | Train | Epoch[025/600] Iteration[008/030] Train loss: 0.2601
2023-02-06 13:54:11 | Train | Epoch[025/600] Iteration[009/030] Train loss: 0.2599
2023-02-06 13:54:11 | Train | Epoch[025/600] Iteration[010/030] Train loss: 0.2599
2023-02-06 13:54:11 | Train | Epoch[025/600] Iteration[011/030] Train loss: 0.2597
2023-02-06 13:54:12 | Train | Epoch[025/600] Iteration[012/030] Train loss: 0.2595
2023-02-06 13:54:12 | Train | Epoch[025/600] Iteration[013/030] Train loss: 0.2594
2023-02-06 13:54:12 | Train | Epoch[025/600] Iteration[014/030] Train loss: 0.2591
2023-02-06 13:54:12 | Train | Epoch[025/600] Iteration[015/030] Train loss: 0.2586
2023-02-06 13:54:12 | Train | Epoch[025/600] Iteration[016/030] Train loss: 0.2586
2023-02-06 13:54:13 | Train | Epoch[025/600] Iteration[017/030] Train loss: 0.2585
2023-02-06 13:54:13 | Train | Epoch[025/600] Iteration[018/030] Train loss: 0.2588
2023-02-06 13:54:13 | Train | Epoch[025/600] Iteration[019/030] Train loss: 0.2588
2023-02-06 13:54:13 | Train | Epoch[025/600] Iteration[020/030] Train loss: 0.2587
2023-02-06 13:54:14 | Train | Epoch[025/600] Iteration[021/030] Train loss: 0.2584
2023-02-06 13:54:14 | Train | Epoch[025/600] Iteration[022/030] Train loss: 0.2583
2023-02-06 13:54:14 | Train | Epoch[025/600] Iteration[023/030] Train loss: 0.2582
2023-02-06 13:54:14 | Train | Epoch[025/600] Iteration[024/030] Train loss: 0.2583
2023-02-06 13:54:14 | Train | Epoch[025/600] Iteration[025/030] Train loss: 0.2580
2023-02-06 13:54:15 | Train | Epoch[025/600] Iteration[026/030] Train loss: 0.2577
2023-02-06 13:54:15 | Train | Epoch[025/600] Iteration[027/030] Train loss: 0.2575
2023-02-06 13:54:15 | Train | Epoch[025/600] Iteration[028/030] Train loss: 0.2574
2023-02-06 13:54:15 | Train | Epoch[025/600] Iteration[029/030] Train loss: 0.2573
2023-02-06 13:54:15 | Train | Epoch[025/600] Iteration[030/030] Train loss: 0.2571
2023-02-06 13:54:16 | Valid | Epoch[025/600] Iteration[001/008] Valid loss: 0.3365
2023-02-06 13:54:16 | Valid | Epoch[025/600] Iteration[002/008] Valid loss: 0.3339
2023-02-06 13:54:16 | Valid | Epoch[025/600] Iteration[003/008] Valid loss: 0.3374
2023-02-06 13:54:16 | Valid | Epoch[025/600] Iteration[004/008] Valid loss: 0.3383
2023-02-06 13:54:16 | Valid | Epoch[025/600] Iteration[005/008] Valid loss: 0.3410
2023-02-06 13:54:16 | Valid | Epoch[025/600] Iteration[006/008] Valid loss: 0.3405
2023-02-06 13:54:16 | Valid | Epoch[025/600] Iteration[007/008] Valid loss: 0.3403
2023-02-06 13:54:16 | Valid | Epoch[025/600] Iteration[008/008] Valid loss: 0.3424
2023-02-06 13:54:16 | Valid | Epoch[025/600] MIou: 0.46949857986441484
2023-02-06 13:54:16 | Valid | Epoch[025/600] Pixel Accuracy: 0.9121259053548177
2023-02-06 13:54:16 | Valid | Epoch[025/600] Mean Pixel Accuracy: 0.5135423660012398
2023-02-06 13:54:16 | Stage | Epoch[025/600] Train loss:0.2571
2023-02-06 13:54:16 | Stage | Epoch[025/600] Valid loss:0.3424
2023-02-06 13:54:16 | Stage | Epoch[025/600] LR:0.01

2023-02-06 13:54:17 | Train | Epoch[026/600] Iteration[001/030] Train loss: 0.2503
2023-02-06 13:54:17 | Train | Epoch[026/600] Iteration[002/030] Train loss: 0.2512
2023-02-06 13:54:17 | Train | Epoch[026/600] Iteration[003/030] Train loss: 0.2503
2023-02-06 13:54:17 | Train | Epoch[026/600] Iteration[004/030] Train loss: 0.2497
2023-02-06 13:54:18 | Train | Epoch[026/600] Iteration[005/030] Train loss: 0.2505
2023-02-06 13:54:18 | Train | Epoch[026/600] Iteration[006/030] Train loss: 0.2505
2023-02-06 13:54:18 | Train | Epoch[026/600] Iteration[007/030] Train loss: 0.2505
2023-02-06 13:54:18 | Train | Epoch[026/600] Iteration[008/030] Train loss: 0.2511
2023-02-06 13:54:18 | Train | Epoch[026/600] Iteration[009/030] Train loss: 0.2511
2023-02-06 13:54:19 | Train | Epoch[026/600] Iteration[010/030] Train loss: 0.2509
2023-02-06 13:54:19 | Train | Epoch[026/600] Iteration[011/030] Train loss: 0.2506
2023-02-06 13:54:19 | Train | Epoch[026/600] Iteration[012/030] Train loss: 0.2503
2023-02-06 13:54:19 | Train | Epoch[026/600] Iteration[013/030] Train loss: 0.2500
2023-02-06 13:54:20 | Train | Epoch[026/600] Iteration[014/030] Train loss: 0.2502
2023-02-06 13:54:20 | Train | Epoch[026/600] Iteration[015/030] Train loss: 0.2501
2023-02-06 13:54:20 | Train | Epoch[026/600] Iteration[016/030] Train loss: 0.2500
2023-02-06 13:54:20 | Train | Epoch[026/600] Iteration[017/030] Train loss: 0.2498
2023-02-06 13:54:20 | Train | Epoch[026/600] Iteration[018/030] Train loss: 0.2495
2023-02-06 13:54:21 | Train | Epoch[026/600] Iteration[019/030] Train loss: 0.2493
2023-02-06 13:54:21 | Train | Epoch[026/600] Iteration[020/030] Train loss: 0.2492
2023-02-06 13:54:21 | Train | Epoch[026/600] Iteration[021/030] Train loss: 0.2489
2023-02-06 13:54:21 | Train | Epoch[026/600] Iteration[022/030] Train loss: 0.2487
2023-02-06 13:54:22 | Train | Epoch[026/600] Iteration[023/030] Train loss: 0.2487
2023-02-06 13:54:22 | Train | Epoch[026/600] Iteration[024/030] Train loss: 0.2488
2023-02-06 13:54:22 | Train | Epoch[026/600] Iteration[025/030] Train loss: 0.2487
2023-02-06 13:54:22 | Train | Epoch[026/600] Iteration[026/030] Train loss: 0.2484
2023-02-06 13:54:22 | Train | Epoch[026/600] Iteration[027/030] Train loss: 0.2483
2023-02-06 13:54:23 | Train | Epoch[026/600] Iteration[028/030] Train loss: 0.2481
2023-02-06 13:54:23 | Train | Epoch[026/600] Iteration[029/030] Train loss: 0.2479
2023-02-06 13:54:23 | Train | Epoch[026/600] Iteration[030/030] Train loss: 0.2477
2023-02-06 13:54:23 | Valid | Epoch[026/600] Iteration[001/008] Valid loss: 0.3103
2023-02-06 13:54:23 | Valid | Epoch[026/600] Iteration[002/008] Valid loss: 0.3035
2023-02-06 13:54:23 | Valid | Epoch[026/600] Iteration[003/008] Valid loss: 0.3085
2023-02-06 13:54:23 | Valid | Epoch[026/600] Iteration[004/008] Valid loss: 0.3063
2023-02-06 13:54:24 | Valid | Epoch[026/600] Iteration[005/008] Valid loss: 0.3097
2023-02-06 13:54:24 | Valid | Epoch[026/600] Iteration[006/008] Valid loss: 0.3077
2023-02-06 13:54:24 | Valid | Epoch[026/600] Iteration[007/008] Valid loss: 0.3110
2023-02-06 13:54:24 | Valid | Epoch[026/600] Iteration[008/008] Valid loss: 0.3116
2023-02-06 13:54:24 | Valid | Epoch[026/600] MIou: 0.8833537858281179
2023-02-06 13:54:24 | Valid | Epoch[026/600] Pixel Accuracy: 0.9772389729817709
2023-02-06 13:54:24 | Valid | Epoch[026/600] Mean Pixel Accuracy: 0.9682969615493917
2023-02-06 13:54:24 | Stage | Epoch[026/600] Train loss:0.2477
2023-02-06 13:54:24 | Stage | Epoch[026/600] Valid loss:0.3116
2023-02-06 13:54:24 | Stage | Epoch[026/600] LR:0.01

2023-02-06 13:54:24 | Train | Epoch[027/600] Iteration[001/030] Train loss: 0.2423
2023-02-06 13:54:24 | Train | Epoch[027/600] Iteration[002/030] Train loss: 0.2405
2023-02-06 13:54:25 | Train | Epoch[027/600] Iteration[003/030] Train loss: 0.2410
2023-02-06 13:54:25 | Train | Epoch[027/600] Iteration[004/030] Train loss: 0.2418
2023-02-06 13:54:25 | Train | Epoch[027/600] Iteration[005/030] Train loss: 0.2425
2023-02-06 13:54:25 | Train | Epoch[027/600] Iteration[006/030] Train loss: 0.2423
2023-02-06 13:54:26 | Train | Epoch[027/600] Iteration[007/030] Train loss: 0.2422
2023-02-06 13:54:26 | Train | Epoch[027/600] Iteration[008/030] Train loss: 0.2420
2023-02-06 13:54:26 | Train | Epoch[027/600] Iteration[009/030] Train loss: 0.2419
2023-02-06 13:54:26 | Train | Epoch[027/600] Iteration[010/030] Train loss: 0.2419
2023-02-06 13:54:26 | Train | Epoch[027/600] Iteration[011/030] Train loss: 0.2418
2023-02-06 13:54:27 | Train | Epoch[027/600] Iteration[012/030] Train loss: 0.2421
2023-02-06 13:54:27 | Train | Epoch[027/600] Iteration[013/030] Train loss: 0.2417
2023-02-06 13:54:27 | Train | Epoch[027/600] Iteration[014/030] Train loss: 0.2414
2023-02-06 13:54:27 | Train | Epoch[027/600] Iteration[015/030] Train loss: 0.2412
2023-02-06 13:54:28 | Train | Epoch[027/600] Iteration[016/030] Train loss: 0.2419
2023-02-06 13:54:28 | Train | Epoch[027/600] Iteration[017/030] Train loss: 0.2420
2023-02-06 13:54:28 | Train | Epoch[027/600] Iteration[018/030] Train loss: 0.2420
2023-02-06 13:54:28 | Train | Epoch[027/600] Iteration[019/030] Train loss: 0.2418
2023-02-06 13:54:28 | Train | Epoch[027/600] Iteration[020/030] Train loss: 0.2416
2023-02-06 13:54:29 | Train | Epoch[027/600] Iteration[021/030] Train loss: 0.2413
2023-02-06 13:54:29 | Train | Epoch[027/600] Iteration[022/030] Train loss: 0.2412
2023-02-06 13:54:29 | Train | Epoch[027/600] Iteration[023/030] Train loss: 0.2409
2023-02-06 13:54:29 | Train | Epoch[027/600] Iteration[024/030] Train loss: 0.2407
2023-02-06 13:54:30 | Train | Epoch[027/600] Iteration[025/030] Train loss: 0.2404
2023-02-06 13:54:30 | Train | Epoch[027/600] Iteration[026/030] Train loss: 0.2402
2023-02-06 13:54:30 | Train | Epoch[027/600] Iteration[027/030] Train loss: 0.2400
2023-02-06 13:54:30 | Train | Epoch[027/600] Iteration[028/030] Train loss: 0.2398
2023-02-06 13:54:30 | Train | Epoch[027/600] Iteration[029/030] Train loss: 0.2396
2023-02-06 13:54:30 | Train | Epoch[027/600] Iteration[030/030] Train loss: 0.2394
2023-02-06 13:54:31 | Valid | Epoch[027/600] Iteration[001/008] Valid loss: 0.3804
2023-02-06 13:54:31 | Valid | Epoch[027/600] Iteration[002/008] Valid loss: 0.3562
2023-02-06 13:54:31 | Valid | Epoch[027/600] Iteration[003/008] Valid loss: 0.3538
2023-02-06 13:54:31 | Valid | Epoch[027/600] Iteration[004/008] Valid loss: 0.3540
2023-02-06 13:54:31 | Valid | Epoch[027/600] Iteration[005/008] Valid loss: 0.3577
2023-02-06 13:54:31 | Valid | Epoch[027/600] Iteration[006/008] Valid loss: 0.3547
2023-02-06 13:54:31 | Valid | Epoch[027/600] Iteration[007/008] Valid loss: 0.3645
2023-02-06 13:54:31 | Valid | Epoch[027/600] Iteration[008/008] Valid loss: 0.3671
2023-02-06 13:54:31 | Valid | Epoch[027/600] MIou: 0.8536442557043855
2023-02-06 13:54:31 | Valid | Epoch[027/600] Pixel Accuracy: 0.9688847859700521
2023-02-06 13:54:31 | Valid | Epoch[027/600] Mean Pixel Accuracy: 0.9774766481945298
2023-02-06 13:54:31 | Stage | Epoch[027/600] Train loss:0.2394
2023-02-06 13:54:31 | Stage | Epoch[027/600] Valid loss:0.3671
2023-02-06 13:54:31 | Stage | Epoch[027/600] LR:0.01

2023-02-06 13:54:32 | Train | Epoch[028/600] Iteration[001/030] Train loss: 0.2311
2023-02-06 13:54:32 | Train | Epoch[028/600] Iteration[002/030] Train loss: 0.2335
2023-02-06 13:54:32 | Train | Epoch[028/600] Iteration[003/030] Train loss: 0.2326
2023-02-06 13:54:32 | Train | Epoch[028/600] Iteration[004/030] Train loss: 0.2326
2023-02-06 13:54:33 | Train | Epoch[028/600] Iteration[005/030] Train loss: 0.2331
2023-02-06 13:54:33 | Train | Epoch[028/600] Iteration[006/030] Train loss: 0.2329
2023-02-06 13:54:33 | Train | Epoch[028/600] Iteration[007/030] Train loss: 0.2329
2023-02-06 13:54:33 | Train | Epoch[028/600] Iteration[008/030] Train loss: 0.2328
2023-02-06 13:54:34 | Train | Epoch[028/600] Iteration[009/030] Train loss: 0.2328
2023-02-06 13:54:34 | Train | Epoch[028/600] Iteration[010/030] Train loss: 0.2325
2023-02-06 13:54:34 | Train | Epoch[028/600] Iteration[011/030] Train loss: 0.2321
2023-02-06 13:54:34 | Train | Epoch[028/600] Iteration[012/030] Train loss: 0.2324
2023-02-06 13:54:34 | Train | Epoch[028/600] Iteration[013/030] Train loss: 0.2325
2023-02-06 13:54:35 | Train | Epoch[028/600] Iteration[014/030] Train loss: 0.2325
2023-02-06 13:54:35 | Train | Epoch[028/600] Iteration[015/030] Train loss: 0.2326
2023-02-06 13:54:35 | Train | Epoch[028/600] Iteration[016/030] Train loss: 0.2324
2023-02-06 13:54:35 | Train | Epoch[028/600] Iteration[017/030] Train loss: 0.2322
2023-02-06 13:54:36 | Train | Epoch[028/600] Iteration[018/030] Train loss: 0.2321
2023-02-06 13:54:36 | Train | Epoch[028/600] Iteration[019/030] Train loss: 0.2319
2023-02-06 13:54:36 | Train | Epoch[028/600] Iteration[020/030] Train loss: 0.2318
2023-02-06 13:54:36 | Train | Epoch[028/600] Iteration[021/030] Train loss: 0.2319
2023-02-06 13:54:36 | Train | Epoch[028/600] Iteration[022/030] Train loss: 0.2317
2023-02-06 13:54:37 | Train | Epoch[028/600] Iteration[023/030] Train loss: 0.2317
2023-02-06 13:54:37 | Train | Epoch[028/600] Iteration[024/030] Train loss: 0.2317
2023-02-06 13:54:37 | Train | Epoch[028/600] Iteration[025/030] Train loss: 0.2315
2023-02-06 13:54:37 | Train | Epoch[028/600] Iteration[026/030] Train loss: 0.2314
2023-02-06 13:54:38 | Train | Epoch[028/600] Iteration[027/030] Train loss: 0.2314
2023-02-06 13:54:38 | Train | Epoch[028/600] Iteration[028/030] Train loss: 0.2313
2023-02-06 13:54:38 | Train | Epoch[028/600] Iteration[029/030] Train loss: 0.2313
2023-02-06 13:54:38 | Train | Epoch[028/600] Iteration[030/030] Train loss: 0.2311
2023-02-06 13:54:38 | Valid | Epoch[028/600] Iteration[001/008] Valid loss: 0.2641
2023-02-06 13:54:38 | Valid | Epoch[028/600] Iteration[002/008] Valid loss: 0.2645
2023-02-06 13:54:39 | Valid | Epoch[028/600] Iteration[003/008] Valid loss: 0.2657
2023-02-06 13:54:39 | Valid | Epoch[028/600] Iteration[004/008] Valid loss: 0.2667
2023-02-06 13:54:39 | Valid | Epoch[028/600] Iteration[005/008] Valid loss: 0.2667
2023-02-06 13:54:39 | Valid | Epoch[028/600] Iteration[006/008] Valid loss: 0.2678
2023-02-06 13:54:39 | Valid | Epoch[028/600] Iteration[007/008] Valid loss: 0.2678
2023-02-06 13:54:39 | Valid | Epoch[028/600] Iteration[008/008] Valid loss: 0.2681
2023-02-06 13:54:39 | Valid | Epoch[028/600] MIou: 0.8634661735133822
2023-02-06 13:54:39 | Valid | Epoch[028/600] Pixel Accuracy: 0.9760348002115885
2023-02-06 13:54:39 | Valid | Epoch[028/600] Mean Pixel Accuracy: 0.9003500131519822
2023-02-06 13:54:39 | Stage | Epoch[028/600] Train loss:0.2311
2023-02-06 13:54:39 | Stage | Epoch[028/600] Valid loss:0.2681
2023-02-06 13:54:39 | Stage | Epoch[028/600] LR:0.01

2023-02-06 13:54:39 | Train | Epoch[029/600] Iteration[001/030] Train loss: 0.2284
2023-02-06 13:54:40 | Train | Epoch[029/600] Iteration[002/030] Train loss: 0.2260
2023-02-06 13:54:40 | Train | Epoch[029/600] Iteration[003/030] Train loss: 0.2269
2023-02-06 13:54:40 | Train | Epoch[029/600] Iteration[004/030] Train loss: 0.2284
2023-02-06 13:54:40 | Train | Epoch[029/600] Iteration[005/030] Train loss: 0.2274
2023-02-06 13:54:40 | Train | Epoch[029/600] Iteration[006/030] Train loss: 0.2271
2023-02-06 13:54:41 | Train | Epoch[029/600] Iteration[007/030] Train loss: 0.2271
2023-02-06 13:54:41 | Train | Epoch[029/600] Iteration[008/030] Train loss: 0.2266
2023-02-06 13:54:41 | Train | Epoch[029/600] Iteration[009/030] Train loss: 0.2264
2023-02-06 13:54:41 | Train | Epoch[029/600] Iteration[010/030] Train loss: 0.2264
2023-02-06 13:54:42 | Train | Epoch[029/600] Iteration[011/030] Train loss: 0.2259
2023-02-06 13:54:42 | Train | Epoch[029/600] Iteration[012/030] Train loss: 0.2261
2023-02-06 13:54:42 | Train | Epoch[029/600] Iteration[013/030] Train loss: 0.2259
2023-02-06 13:54:42 | Train | Epoch[029/600] Iteration[014/030] Train loss: 0.2258
2023-02-06 13:54:42 | Train | Epoch[029/600] Iteration[015/030] Train loss: 0.2258
2023-02-06 13:54:43 | Train | Epoch[029/600] Iteration[016/030] Train loss: 0.2257
2023-02-06 13:54:43 | Train | Epoch[029/600] Iteration[017/030] Train loss: 0.2254
2023-02-06 13:54:43 | Train | Epoch[029/600] Iteration[018/030] Train loss: 0.2254
2023-02-06 13:54:43 | Train | Epoch[029/600] Iteration[019/030] Train loss: 0.2252
2023-02-06 13:54:44 | Train | Epoch[029/600] Iteration[020/030] Train loss: 0.2248
2023-02-06 13:54:44 | Train | Epoch[029/600] Iteration[021/030] Train loss: 0.2252
2023-02-06 13:54:44 | Train | Epoch[029/600] Iteration[022/030] Train loss: 0.2249
2023-02-06 13:54:44 | Train | Epoch[029/600] Iteration[023/030] Train loss: 0.2247
2023-02-06 13:54:44 | Train | Epoch[029/600] Iteration[024/030] Train loss: 0.2246
2023-02-06 13:54:45 | Train | Epoch[029/600] Iteration[025/030] Train loss: 0.2245
2023-02-06 13:54:45 | Train | Epoch[029/600] Iteration[026/030] Train loss: 0.2244
2023-02-06 13:54:45 | Train | Epoch[029/600] Iteration[027/030] Train loss: 0.2242
2023-02-06 13:54:45 | Train | Epoch[029/600] Iteration[028/030] Train loss: 0.2238
2023-02-06 13:54:46 | Train | Epoch[029/600] Iteration[029/030] Train loss: 0.2237
2023-02-06 13:54:46 | Train | Epoch[029/600] Iteration[030/030] Train loss: 0.2237
2023-02-06 13:54:46 | Valid | Epoch[029/600] Iteration[001/008] Valid loss: 0.3600
2023-02-06 13:54:46 | Valid | Epoch[029/600] Iteration[002/008] Valid loss: 0.3485
2023-02-06 13:54:46 | Valid | Epoch[029/600] Iteration[003/008] Valid loss: 0.3580
2023-02-06 13:54:46 | Valid | Epoch[029/600] Iteration[004/008] Valid loss: 0.3596
2023-02-06 13:54:46 | Valid | Epoch[029/600] Iteration[005/008] Valid loss: 0.3633
2023-02-06 13:54:46 | Valid | Epoch[029/600] Iteration[006/008] Valid loss: 0.3625
2023-02-06 13:54:46 | Valid | Epoch[029/600] Iteration[007/008] Valid loss: 0.3709
2023-02-06 13:54:46 | Valid | Epoch[029/600] Iteration[008/008] Valid loss: 0.3722
2023-02-06 13:54:46 | Valid | Epoch[029/600] MIou: 0.8424001741443716
2023-02-06 13:54:46 | Valid | Epoch[029/600] Pixel Accuracy: 0.9656283060709635
2023-02-06 13:54:46 | Valid | Epoch[029/600] Mean Pixel Accuracy: 0.9770943326321639
2023-02-06 13:54:46 | Stage | Epoch[029/600] Train loss:0.2237
2023-02-06 13:54:46 | Stage | Epoch[029/600] Valid loss:0.3722
2023-02-06 13:54:46 | Stage | Epoch[029/600] LR:0.01

2023-02-06 13:54:47 | Train | Epoch[030/600] Iteration[001/030] Train loss: 0.2169
2023-02-06 13:54:47 | Train | Epoch[030/600] Iteration[002/030] Train loss: 0.2186
2023-02-06 13:54:47 | Train | Epoch[030/600] Iteration[003/030] Train loss: 0.2182
2023-02-06 13:54:48 | Train | Epoch[030/600] Iteration[004/030] Train loss: 0.2178
2023-02-06 13:54:48 | Train | Epoch[030/600] Iteration[005/030] Train loss: 0.2181
2023-02-06 13:54:48 | Train | Epoch[030/600] Iteration[006/030] Train loss: 0.2179
2023-02-06 13:54:48 | Train | Epoch[030/600] Iteration[007/030] Train loss: 0.2174
2023-02-06 13:54:48 | Train | Epoch[030/600] Iteration[008/030] Train loss: 0.2175
2023-02-06 13:54:49 | Train | Epoch[030/600] Iteration[009/030] Train loss: 0.2177
2023-02-06 13:54:49 | Train | Epoch[030/600] Iteration[010/030] Train loss: 0.2173
2023-02-06 13:54:49 | Train | Epoch[030/600] Iteration[011/030] Train loss: 0.2171
2023-02-06 13:54:49 | Train | Epoch[030/600] Iteration[012/030] Train loss: 0.2171
2023-02-06 13:54:50 | Train | Epoch[030/600] Iteration[013/030] Train loss: 0.2167
2023-02-06 13:54:50 | Train | Epoch[030/600] Iteration[014/030] Train loss: 0.2167
2023-02-06 13:54:50 | Train | Epoch[030/600] Iteration[015/030] Train loss: 0.2166
2023-02-06 13:54:50 | Train | Epoch[030/600] Iteration[016/030] Train loss: 0.2163
2023-02-06 13:54:50 | Train | Epoch[030/600] Iteration[017/030] Train loss: 0.2163
2023-02-06 13:54:51 | Train | Epoch[030/600] Iteration[018/030] Train loss: 0.2160
2023-02-06 13:54:51 | Train | Epoch[030/600] Iteration[019/030] Train loss: 0.2163
2023-02-06 13:54:51 | Train | Epoch[030/600] Iteration[020/030] Train loss: 0.2162
2023-02-06 13:54:51 | Train | Epoch[030/600] Iteration[021/030] Train loss: 0.2162
2023-02-06 13:54:51 | Train | Epoch[030/600] Iteration[022/030] Train loss: 0.2161
2023-02-06 13:54:52 | Train | Epoch[030/600] Iteration[023/030] Train loss: 0.2161
2023-02-06 13:54:52 | Train | Epoch[030/600] Iteration[024/030] Train loss: 0.2161
2023-02-06 13:54:52 | Train | Epoch[030/600] Iteration[025/030] Train loss: 0.2159
2023-02-06 13:54:52 | Train | Epoch[030/600] Iteration[026/030] Train loss: 0.2158
2023-02-06 13:54:53 | Train | Epoch[030/600] Iteration[027/030] Train loss: 0.2156
2023-02-06 13:54:53 | Train | Epoch[030/600] Iteration[028/030] Train loss: 0.2154
2023-02-06 13:54:53 | Train | Epoch[030/600] Iteration[029/030] Train loss: 0.2154
2023-02-06 13:54:53 | Train | Epoch[030/600] Iteration[030/030] Train loss: 0.2151
2023-02-06 13:54:53 | Valid | Epoch[030/600] Iteration[001/008] Valid loss: 0.2285
2023-02-06 13:54:53 | Valid | Epoch[030/600] Iteration[002/008] Valid loss: 0.2264
2023-02-06 13:54:54 | Valid | Epoch[030/600] Iteration[003/008] Valid loss: 0.2263
2023-02-06 13:54:54 | Valid | Epoch[030/600] Iteration[004/008] Valid loss: 0.2257
2023-02-06 13:54:54 | Valid | Epoch[030/600] Iteration[005/008] Valid loss: 0.2263
2023-02-06 13:54:54 | Valid | Epoch[030/600] Iteration[006/008] Valid loss: 0.2261
2023-02-06 13:54:54 | Valid | Epoch[030/600] Iteration[007/008] Valid loss: 0.2274
2023-02-06 13:54:54 | Valid | Epoch[030/600] Iteration[008/008] Valid loss: 0.2270
2023-02-06 13:54:54 | Valid | Epoch[030/600] MIou: 0.9263457455630564
2023-02-06 13:54:54 | Valid | Epoch[030/600] Pixel Accuracy: 0.9873517354329427
2023-02-06 13:54:54 | Valid | Epoch[030/600] Mean Pixel Accuracy: 0.951942697545695
2023-02-06 13:54:54 | Stage | Epoch[030/600] Train loss:0.2151
2023-02-06 13:54:54 | Stage | Epoch[030/600] Valid loss:0.2270
2023-02-06 13:54:54 | Stage | Epoch[030/600] LR:0.01

2023-02-06 13:54:54 | Train | Epoch[031/600] Iteration[001/030] Train loss: 0.2120
2023-02-06 13:54:55 | Train | Epoch[031/600] Iteration[002/030] Train loss: 0.2112
2023-02-06 13:54:55 | Train | Epoch[031/600] Iteration[003/030] Train loss: 0.2127
2023-02-06 13:54:55 | Train | Epoch[031/600] Iteration[004/030] Train loss: 0.2120
2023-02-06 13:54:55 | Train | Epoch[031/600] Iteration[005/030] Train loss: 0.2110
2023-02-06 13:54:55 | Train | Epoch[031/600] Iteration[006/030] Train loss: 0.2106
2023-02-06 13:54:56 | Train | Epoch[031/600] Iteration[007/030] Train loss: 0.2102
2023-02-06 13:54:56 | Train | Epoch[031/600] Iteration[008/030] Train loss: 0.2104
2023-02-06 13:54:56 | Train | Epoch[031/600] Iteration[009/030] Train loss: 0.2103
2023-02-06 13:54:56 | Train | Epoch[031/600] Iteration[010/030] Train loss: 0.2103
2023-02-06 13:54:57 | Train | Epoch[031/600] Iteration[011/030] Train loss: 0.2102
2023-02-06 13:54:57 | Train | Epoch[031/600] Iteration[012/030] Train loss: 0.2098
2023-02-06 13:54:57 | Train | Epoch[031/600] Iteration[013/030] Train loss: 0.2097
2023-02-06 13:54:57 | Train | Epoch[031/600] Iteration[014/030] Train loss: 0.2097
2023-02-06 13:54:57 | Train | Epoch[031/600] Iteration[015/030] Train loss: 0.2095
2023-02-06 13:54:58 | Train | Epoch[031/600] Iteration[016/030] Train loss: 0.2096
2023-02-06 13:54:58 | Train | Epoch[031/600] Iteration[017/030] Train loss: 0.2095
2023-02-06 13:54:58 | Train | Epoch[031/600] Iteration[018/030] Train loss: 0.2092
2023-02-06 13:54:58 | Train | Epoch[031/600] Iteration[019/030] Train loss: 0.2089
2023-02-06 13:54:59 | Train | Epoch[031/600] Iteration[020/030] Train loss: 0.2090
2023-02-06 13:54:59 | Train | Epoch[031/600] Iteration[021/030] Train loss: 0.2090
2023-02-06 13:54:59 | Train | Epoch[031/600] Iteration[022/030] Train loss: 0.2091
2023-02-06 13:54:59 | Train | Epoch[031/600] Iteration[023/030] Train loss: 0.2089
2023-02-06 13:54:59 | Train | Epoch[031/600] Iteration[024/030] Train loss: 0.2089
2023-02-06 13:55:00 | Train | Epoch[031/600] Iteration[025/030] Train loss: 0.2088
2023-02-06 13:55:00 | Train | Epoch[031/600] Iteration[026/030] Train loss: 0.2087
2023-02-06 13:55:00 | Train | Epoch[031/600] Iteration[027/030] Train loss: 0.2086
2023-02-06 13:55:00 | Train | Epoch[031/600] Iteration[028/030] Train loss: 0.2085
2023-02-06 13:55:01 | Train | Epoch[031/600] Iteration[029/030] Train loss: 0.2084
2023-02-06 13:55:01 | Train | Epoch[031/600] Iteration[030/030] Train loss: 0.2082
2023-02-06 13:55:01 | Valid | Epoch[031/600] Iteration[001/008] Valid loss: 0.3271
2023-02-06 13:55:01 | Valid | Epoch[031/600] Iteration[002/008] Valid loss: 0.3097
2023-02-06 13:55:01 | Valid | Epoch[031/600] Iteration[003/008] Valid loss: 0.3120
2023-02-06 13:55:01 | Valid | Epoch[031/600] Iteration[004/008] Valid loss: 0.3138
2023-02-06 13:55:01 | Valid | Epoch[031/600] Iteration[005/008] Valid loss: 0.3203
2023-02-06 13:55:01 | Valid | Epoch[031/600] Iteration[006/008] Valid loss: 0.3214
2023-02-06 13:55:01 | Valid | Epoch[031/600] Iteration[007/008] Valid loss: 0.3291
2023-02-06 13:55:01 | Valid | Epoch[031/600] Iteration[008/008] Valid loss: 0.3269
2023-02-06 13:55:01 | Valid | Epoch[031/600] MIou: 0.8583445732749613
2023-02-06 13:55:01 | Valid | Epoch[031/600] Pixel Accuracy: 0.9702898661295573
2023-02-06 13:55:01 | Valid | Epoch[031/600] Mean Pixel Accuracy: 0.9760804989182821
2023-02-06 13:55:01 | Stage | Epoch[031/600] Train loss:0.2082
2023-02-06 13:55:01 | Stage | Epoch[031/600] Valid loss:0.3269
2023-02-06 13:55:01 | Stage | Epoch[031/600] LR:0.01

2023-02-06 13:55:02 | Train | Epoch[032/600] Iteration[001/030] Train loss: 0.2092
2023-02-06 13:55:02 | Train | Epoch[032/600] Iteration[002/030] Train loss: 0.2061
2023-02-06 13:55:02 | Train | Epoch[032/600] Iteration[003/030] Train loss: 0.2051
2023-02-06 13:55:03 | Train | Epoch[032/600] Iteration[004/030] Train loss: 0.2041
2023-02-06 13:55:03 | Train | Epoch[032/600] Iteration[005/030] Train loss: 0.2039
2023-02-06 13:55:03 | Train | Epoch[032/600] Iteration[006/030] Train loss: 0.2035
2023-02-06 13:55:03 | Train | Epoch[032/600] Iteration[007/030] Train loss: 0.2033
2023-02-06 13:55:03 | Train | Epoch[032/600] Iteration[008/030] Train loss: 0.2029
2023-02-06 13:55:04 | Train | Epoch[032/600] Iteration[009/030] Train loss: 0.2028
2023-02-06 13:55:04 | Train | Epoch[032/600] Iteration[010/030] Train loss: 0.2027
2023-02-06 13:55:04 | Train | Epoch[032/600] Iteration[011/030] Train loss: 0.2038
2023-02-06 13:55:04 | Train | Epoch[032/600] Iteration[012/030] Train loss: 0.2038
2023-02-06 13:55:05 | Train | Epoch[032/600] Iteration[013/030] Train loss: 0.2036
2023-02-06 13:55:05 | Train | Epoch[032/600] Iteration[014/030] Train loss: 0.2040
2023-02-06 13:55:05 | Train | Epoch[032/600] Iteration[015/030] Train loss: 0.2038
2023-02-06 13:55:05 | Train | Epoch[032/600] Iteration[016/030] Train loss: 0.2037
2023-02-06 13:55:05 | Train | Epoch[032/600] Iteration[017/030] Train loss: 0.2036
2023-02-06 13:55:06 | Train | Epoch[032/600] Iteration[018/030] Train loss: 0.2034
2023-02-06 13:55:06 | Train | Epoch[032/600] Iteration[019/030] Train loss: 0.2034
2023-02-06 13:55:06 | Train | Epoch[032/600] Iteration[020/030] Train loss: 0.2033
2023-02-06 13:55:06 | Train | Epoch[032/600] Iteration[021/030] Train loss: 0.2031
2023-02-06 13:55:07 | Train | Epoch[032/600] Iteration[022/030] Train loss: 0.2029
2023-02-06 13:55:07 | Train | Epoch[032/600] Iteration[023/030] Train loss: 0.2030
2023-02-06 13:55:07 | Train | Epoch[032/600] Iteration[024/030] Train loss: 0.2028
2023-02-06 13:55:07 | Train | Epoch[032/600] Iteration[025/030] Train loss: 0.2025
2023-02-06 13:55:07 | Train | Epoch[032/600] Iteration[026/030] Train loss: 0.2023
2023-02-06 13:55:08 | Train | Epoch[032/600] Iteration[027/030] Train loss: 0.2021
2023-02-06 13:55:08 | Train | Epoch[032/600] Iteration[028/030] Train loss: 0.2022
2023-02-06 13:55:08 | Train | Epoch[032/600] Iteration[029/030] Train loss: 0.2021
2023-02-06 13:55:08 | Train | Epoch[032/600] Iteration[030/030] Train loss: 0.2020
2023-02-06 13:55:08 | Valid | Epoch[032/600] Iteration[001/008] Valid loss: 0.2913
2023-02-06 13:55:09 | Valid | Epoch[032/600] Iteration[002/008] Valid loss: 0.2838
2023-02-06 13:55:09 | Valid | Epoch[032/600] Iteration[003/008] Valid loss: 0.2852
2023-02-06 13:55:09 | Valid | Epoch[032/600] Iteration[004/008] Valid loss: 0.2857
2023-02-06 13:55:09 | Valid | Epoch[032/600] Iteration[005/008] Valid loss: 0.2866
2023-02-06 13:55:09 | Valid | Epoch[032/600] Iteration[006/008] Valid loss: 0.2868
2023-02-06 13:55:09 | Valid | Epoch[032/600] Iteration[007/008] Valid loss: 0.2915
2023-02-06 13:55:09 | Valid | Epoch[032/600] Iteration[008/008] Valid loss: 0.2910
2023-02-06 13:55:09 | Valid | Epoch[032/600] MIou: 0.8814553290656804
2023-02-06 13:55:09 | Valid | Epoch[032/600] Pixel Accuracy: 0.9760958353678385
2023-02-06 13:55:09 | Valid | Epoch[032/600] Mean Pixel Accuracy: 0.9826511785461791
2023-02-06 13:55:09 | Stage | Epoch[032/600] Train loss:0.2020
2023-02-06 13:55:09 | Stage | Epoch[032/600] Valid loss:0.2910
2023-02-06 13:55:09 | Stage | Epoch[032/600] LR:0.01

2023-02-06 13:55:09 | Train | Epoch[033/600] Iteration[001/030] Train loss: 0.1965
2023-02-06 13:55:10 | Train | Epoch[033/600] Iteration[002/030] Train loss: 0.1956
2023-02-06 13:55:10 | Train | Epoch[033/600] Iteration[003/030] Train loss: 0.1971
2023-02-06 13:55:10 | Train | Epoch[033/600] Iteration[004/030] Train loss: 0.1967
2023-02-06 13:55:10 | Train | Epoch[033/600] Iteration[005/030] Train loss: 0.1964
2023-02-06 13:55:10 | Train | Epoch[033/600] Iteration[006/030] Train loss: 0.1962
2023-02-06 13:55:11 | Train | Epoch[033/600] Iteration[007/030] Train loss: 0.1961
2023-02-06 13:55:11 | Train | Epoch[033/600] Iteration[008/030] Train loss: 0.1963
2023-02-06 13:55:11 | Train | Epoch[033/600] Iteration[009/030] Train loss: 0.1965
2023-02-06 13:55:11 | Train | Epoch[033/600] Iteration[010/030] Train loss: 0.1961
2023-02-06 13:55:12 | Train | Epoch[033/600] Iteration[011/030] Train loss: 0.1959
2023-02-06 13:55:12 | Train | Epoch[033/600] Iteration[012/030] Train loss: 0.1956
2023-02-06 13:55:12 | Train | Epoch[033/600] Iteration[013/030] Train loss: 0.1962
2023-02-06 13:55:12 | Train | Epoch[033/600] Iteration[014/030] Train loss: 0.1964
2023-02-06 13:55:12 | Train | Epoch[033/600] Iteration[015/030] Train loss: 0.1963
2023-02-06 13:55:13 | Train | Epoch[033/600] Iteration[016/030] Train loss: 0.1963
2023-02-06 13:55:13 | Train | Epoch[033/600] Iteration[017/030] Train loss: 0.1965
2023-02-06 13:55:13 | Train | Epoch[033/600] Iteration[018/030] Train loss: 0.1965
2023-02-06 13:55:13 | Train | Epoch[033/600] Iteration[019/030] Train loss: 0.1963
2023-02-06 13:55:14 | Train | Epoch[033/600] Iteration[020/030] Train loss: 0.1962
2023-02-06 13:55:14 | Train | Epoch[033/600] Iteration[021/030] Train loss: 0.1961
2023-02-06 13:55:14 | Train | Epoch[033/600] Iteration[022/030] Train loss: 0.1960
2023-02-06 13:55:14 | Train | Epoch[033/600] Iteration[023/030] Train loss: 0.1960
2023-02-06 13:55:14 | Train | Epoch[033/600] Iteration[024/030] Train loss: 0.1960
2023-02-06 13:55:15 | Train | Epoch[033/600] Iteration[025/030] Train loss: 0.1959
2023-02-06 13:55:15 | Train | Epoch[033/600] Iteration[026/030] Train loss: 0.1958
2023-02-06 13:55:15 | Train | Epoch[033/600] Iteration[027/030] Train loss: 0.1956
2023-02-06 13:55:15 | Train | Epoch[033/600] Iteration[028/030] Train loss: 0.1954
2023-02-06 13:55:16 | Train | Epoch[033/600] Iteration[029/030] Train loss: 0.1953
2023-02-06 13:55:16 | Train | Epoch[033/600] Iteration[030/030] Train loss: 0.1953
2023-02-06 13:55:16 | Valid | Epoch[033/600] Iteration[001/008] Valid loss: 0.5075
2023-02-06 13:55:16 | Valid | Epoch[033/600] Iteration[002/008] Valid loss: 0.4808
2023-02-06 13:55:16 | Valid | Epoch[033/600] Iteration[003/008] Valid loss: 0.4780
2023-02-06 13:55:16 | Valid | Epoch[033/600] Iteration[004/008] Valid loss: 0.4810
2023-02-06 13:55:16 | Valid | Epoch[033/600] Iteration[005/008] Valid loss: 0.4848
2023-02-06 13:55:16 | Valid | Epoch[033/600] Iteration[006/008] Valid loss: 0.4837
2023-02-06 13:55:16 | Valid | Epoch[033/600] Iteration[007/008] Valid loss: 0.4944
2023-02-06 13:55:16 | Valid | Epoch[033/600] Iteration[008/008] Valid loss: 0.4928
2023-02-06 13:55:17 | Valid | Epoch[033/600] MIou: 0.808271954704765
2023-02-06 13:55:17 | Valid | Epoch[033/600] Pixel Accuracy: 0.9548238118489584
2023-02-06 13:55:17 | Valid | Epoch[033/600] Mean Pixel Accuracy: 0.974389362278377
2023-02-06 13:55:17 | Stage | Epoch[033/600] Train loss:0.1953
2023-02-06 13:55:17 | Stage | Epoch[033/600] Valid loss:0.4928
2023-02-06 13:55:17 | Stage | Epoch[033/600] LR:0.01

2023-02-06 13:55:17 | Train | Epoch[034/600] Iteration[001/030] Train loss: 0.1937
2023-02-06 13:55:17 | Train | Epoch[034/600] Iteration[002/030] Train loss: 0.1930
2023-02-06 13:55:17 | Train | Epoch[034/600] Iteration[003/030] Train loss: 0.1914
2023-02-06 13:55:18 | Train | Epoch[034/600] Iteration[004/030] Train loss: 0.1910
2023-02-06 13:55:18 | Train | Epoch[034/600] Iteration[005/030] Train loss: 0.1907
2023-02-06 13:55:18 | Train | Epoch[034/600] Iteration[006/030] Train loss: 0.1902
2023-02-06 13:55:18 | Train | Epoch[034/600] Iteration[007/030] Train loss: 0.1903
2023-02-06 13:55:19 | Train | Epoch[034/600] Iteration[008/030] Train loss: 0.1903
2023-02-06 13:55:19 | Train | Epoch[034/600] Iteration[009/030] Train loss: 0.1902
2023-02-06 13:55:19 | Train | Epoch[034/600] Iteration[010/030] Train loss: 0.1903
2023-02-06 13:55:19 | Train | Epoch[034/600] Iteration[011/030] Train loss: 0.1901
2023-02-06 13:55:19 | Train | Epoch[034/600] Iteration[012/030] Train loss: 0.1901
2023-02-06 13:55:20 | Train | Epoch[034/600] Iteration[013/030] Train loss: 0.1901
2023-02-06 13:55:20 | Train | Epoch[034/600] Iteration[014/030] Train loss: 0.1905
2023-02-06 13:55:20 | Train | Epoch[034/600] Iteration[015/030] Train loss: 0.1907
2023-02-06 13:55:20 | Train | Epoch[034/600] Iteration[016/030] Train loss: 0.1906
2023-02-06 13:55:21 | Train | Epoch[034/600] Iteration[017/030] Train loss: 0.1908
2023-02-06 13:55:21 | Train | Epoch[034/600] Iteration[018/030] Train loss: 0.1905
2023-02-06 13:55:21 | Train | Epoch[034/600] Iteration[019/030] Train loss: 0.1904
2023-02-06 13:55:21 | Train | Epoch[034/600] Iteration[020/030] Train loss: 0.1903
2023-02-06 13:55:21 | Train | Epoch[034/600] Iteration[021/030] Train loss: 0.1902
2023-02-06 13:55:22 | Train | Epoch[034/600] Iteration[022/030] Train loss: 0.1900
2023-02-06 13:55:22 | Train | Epoch[034/600] Iteration[023/030] Train loss: 0.1898
2023-02-06 13:55:22 | Train | Epoch[034/600] Iteration[024/030] Train loss: 0.1899
2023-02-06 13:55:22 | Train | Epoch[034/600] Iteration[025/030] Train loss: 0.1897
2023-02-06 13:55:22 | Train | Epoch[034/600] Iteration[026/030] Train loss: 0.1896
2023-02-06 13:55:23 | Train | Epoch[034/600] Iteration[027/030] Train loss: 0.1894
2023-02-06 13:55:23 | Train | Epoch[034/600] Iteration[028/030] Train loss: 0.1891
2023-02-06 13:55:23 | Train | Epoch[034/600] Iteration[029/030] Train loss: 0.1890
2023-02-06 13:55:23 | Train | Epoch[034/600] Iteration[030/030] Train loss: 0.1889
2023-02-06 13:55:24 | Valid | Epoch[034/600] Iteration[001/008] Valid loss: 0.4909
2023-02-06 13:55:24 | Valid | Epoch[034/600] Iteration[002/008] Valid loss: 0.4896
2023-02-06 13:55:24 | Valid | Epoch[034/600] Iteration[003/008] Valid loss: 0.4774
2023-02-06 13:55:24 | Valid | Epoch[034/600] Iteration[004/008] Valid loss: 0.4869
2023-02-06 13:55:24 | Valid | Epoch[034/600] Iteration[005/008] Valid loss: 0.4848
2023-02-06 13:55:24 | Valid | Epoch[034/600] Iteration[006/008] Valid loss: 0.4750
2023-02-06 13:55:24 | Valid | Epoch[034/600] Iteration[007/008] Valid loss: 0.4914
2023-02-06 13:55:24 | Valid | Epoch[034/600] Iteration[008/008] Valid loss: 0.4931
2023-02-06 13:55:24 | Valid | Epoch[034/600] MIou: 0.8180046477225817
2023-02-06 13:55:24 | Valid | Epoch[034/600] Pixel Accuracy: 0.9584477742513021
2023-02-06 13:55:24 | Valid | Epoch[034/600] Mean Pixel Accuracy: 0.9703831605225359
2023-02-06 13:55:24 | Stage | Epoch[034/600] Train loss:0.1889
2023-02-06 13:55:24 | Stage | Epoch[034/600] Valid loss:0.4931
2023-02-06 13:55:24 | Stage | Epoch[034/600] LR:0.01

2023-02-06 13:55:25 | Train | Epoch[035/600] Iteration[001/030] Train loss: 0.1919
2023-02-06 13:55:25 | Train | Epoch[035/600] Iteration[002/030] Train loss: 0.1869
2023-02-06 13:55:25 | Train | Epoch[035/600] Iteration[003/030] Train loss: 0.1855
2023-02-06 13:55:25 | Train | Epoch[035/600] Iteration[004/030] Train loss: 0.1863
2023-02-06 13:55:25 | Train | Epoch[035/600] Iteration[005/030] Train loss: 0.1858
2023-02-06 13:55:26 | Train | Epoch[035/600] Iteration[006/030] Train loss: 0.1855
2023-02-06 13:55:26 | Train | Epoch[035/600] Iteration[007/030] Train loss: 0.1852
2023-02-06 13:55:26 | Train | Epoch[035/600] Iteration[008/030] Train loss: 0.1849
2023-02-06 13:55:26 | Train | Epoch[035/600] Iteration[009/030] Train loss: 0.1845
2023-02-06 13:55:26 | Train | Epoch[035/600] Iteration[010/030] Train loss: 0.1847
2023-02-06 13:55:27 | Train | Epoch[035/600] Iteration[011/030] Train loss: 0.1848
2023-02-06 13:55:27 | Train | Epoch[035/600] Iteration[012/030] Train loss: 0.1853
2023-02-06 13:55:27 | Train | Epoch[035/600] Iteration[013/030] Train loss: 0.1851
2023-02-06 13:55:27 | Train | Epoch[035/600] Iteration[014/030] Train loss: 0.1851
2023-02-06 13:55:28 | Train | Epoch[035/600] Iteration[015/030] Train loss: 0.1848
2023-02-06 13:55:28 | Train | Epoch[035/600] Iteration[016/030] Train loss: 0.1846
2023-02-06 13:55:28 | Train | Epoch[035/600] Iteration[017/030] Train loss: 0.1847
2023-02-06 13:55:28 | Train | Epoch[035/600] Iteration[018/030] Train loss: 0.1846
2023-02-06 13:55:28 | Train | Epoch[035/600] Iteration[019/030] Train loss: 0.1844
2023-02-06 13:55:29 | Train | Epoch[035/600] Iteration[020/030] Train loss: 0.1843
2023-02-06 13:55:29 | Train | Epoch[035/600] Iteration[021/030] Train loss: 0.1842
2023-02-06 13:55:29 | Train | Epoch[035/600] Iteration[022/030] Train loss: 0.1840
2023-02-06 13:55:29 | Train | Epoch[035/600] Iteration[023/030] Train loss: 0.1839
2023-02-06 13:55:30 | Train | Epoch[035/600] Iteration[024/030] Train loss: 0.1838
2023-02-06 13:55:30 | Train | Epoch[035/600] Iteration[025/030] Train loss: 0.1835
2023-02-06 13:55:30 | Train | Epoch[035/600] Iteration[026/030] Train loss: 0.1834
2023-02-06 13:55:30 | Train | Epoch[035/600] Iteration[027/030] Train loss: 0.1835
2023-02-06 13:55:30 | Train | Epoch[035/600] Iteration[028/030] Train loss: 0.1835
2023-02-06 13:55:31 | Train | Epoch[035/600] Iteration[029/030] Train loss: 0.1834
2023-02-06 13:55:31 | Train | Epoch[035/600] Iteration[030/030] Train loss: 0.1833
2023-02-06 13:55:31 | Valid | Epoch[035/600] Iteration[001/008] Valid loss: 0.2026
2023-02-06 13:55:31 | Valid | Epoch[035/600] Iteration[002/008] Valid loss: 0.2030
2023-02-06 13:55:31 | Valid | Epoch[035/600] Iteration[003/008] Valid loss: 0.2030
2023-02-06 13:55:31 | Valid | Epoch[035/600] Iteration[004/008] Valid loss: 0.2023
2023-02-06 13:55:31 | Valid | Epoch[035/600] Iteration[005/008] Valid loss: 0.2028
2023-02-06 13:55:31 | Valid | Epoch[035/600] Iteration[006/008] Valid loss: 0.2024
2023-02-06 13:55:31 | Valid | Epoch[035/600] Iteration[007/008] Valid loss: 0.2022
2023-02-06 13:55:31 | Valid | Epoch[035/600] Iteration[008/008] Valid loss: 0.2027
2023-02-06 13:55:32 | Valid | Epoch[035/600] MIou: 0.8288008600770828
2023-02-06 13:55:32 | Valid | Epoch[035/600] Pixel Accuracy: 0.971747080485026
2023-02-06 13:55:32 | Valid | Epoch[035/600] Mean Pixel Accuracy: 0.844378272417293
2023-02-06 13:55:32 | Stage | Epoch[035/600] Train loss:0.1833
2023-02-06 13:55:32 | Stage | Epoch[035/600] Valid loss:0.2027
2023-02-06 13:55:32 | Stage | Epoch[035/600] LR:0.01

2023-02-06 13:55:32 | Train | Epoch[036/600] Iteration[001/030] Train loss: 0.1770
2023-02-06 13:55:32 | Train | Epoch[036/600] Iteration[002/030] Train loss: 0.1774
2023-02-06 13:55:32 | Train | Epoch[036/600] Iteration[003/030] Train loss: 0.1778
2023-02-06 13:55:33 | Train | Epoch[036/600] Iteration[004/030] Train loss: 0.1795
2023-02-06 13:55:33 | Train | Epoch[036/600] Iteration[005/030] Train loss: 0.1788
2023-02-06 13:55:33 | Train | Epoch[036/600] Iteration[006/030] Train loss: 0.1783
2023-02-06 13:55:33 | Train | Epoch[036/600] Iteration[007/030] Train loss: 0.1784
2023-02-06 13:55:34 | Train | Epoch[036/600] Iteration[008/030] Train loss: 0.1789
2023-02-06 13:55:34 | Train | Epoch[036/600] Iteration[009/030] Train loss: 0.1789
2023-02-06 13:55:34 | Train | Epoch[036/600] Iteration[010/030] Train loss: 0.1787
2023-02-06 13:55:34 | Train | Epoch[036/600] Iteration[011/030] Train loss: 0.1786
2023-02-06 13:55:34 | Train | Epoch[036/600] Iteration[012/030] Train loss: 0.1790
2023-02-06 13:55:35 | Train | Epoch[036/600] Iteration[013/030] Train loss: 0.1789
2023-02-06 13:55:35 | Train | Epoch[036/600] Iteration[014/030] Train loss: 0.1788
2023-02-06 13:55:35 | Train | Epoch[036/600] Iteration[015/030] Train loss: 0.1785
2023-02-06 13:55:35 | Train | Epoch[036/600] Iteration[016/030] Train loss: 0.1785
2023-02-06 13:55:36 | Train | Epoch[036/600] Iteration[017/030] Train loss: 0.1782
2023-02-06 13:55:36 | Train | Epoch[036/600] Iteration[018/030] Train loss: 0.1782
2023-02-06 13:55:36 | Train | Epoch[036/600] Iteration[019/030] Train loss: 0.1780
2023-02-06 13:55:36 | Train | Epoch[036/600] Iteration[020/030] Train loss: 0.1777
2023-02-06 13:55:36 | Train | Epoch[036/600] Iteration[021/030] Train loss: 0.1776
2023-02-06 13:55:37 | Train | Epoch[036/600] Iteration[022/030] Train loss: 0.1776
2023-02-06 13:55:37 | Train | Epoch[036/600] Iteration[023/030] Train loss: 0.1775
2023-02-06 13:55:37 | Train | Epoch[036/600] Iteration[024/030] Train loss: 0.1773
2023-02-06 13:55:37 | Train | Epoch[036/600] Iteration[025/030] Train loss: 0.1772
2023-02-06 13:55:38 | Train | Epoch[036/600] Iteration[026/030] Train loss: 0.1771
2023-02-06 13:55:38 | Train | Epoch[036/600] Iteration[027/030] Train loss: 0.1771
2023-02-06 13:55:38 | Train | Epoch[036/600] Iteration[028/030] Train loss: 0.1771
2023-02-06 13:55:38 | Train | Epoch[036/600] Iteration[029/030] Train loss: 0.1770
2023-02-06 13:55:38 | Train | Epoch[036/600] Iteration[030/030] Train loss: 0.1769
2023-02-06 13:55:39 | Valid | Epoch[036/600] Iteration[001/008] Valid loss: 0.2157
2023-02-06 13:55:39 | Valid | Epoch[036/600] Iteration[002/008] Valid loss: 0.2131
2023-02-06 13:55:39 | Valid | Epoch[036/600] Iteration[003/008] Valid loss: 0.2127
2023-02-06 13:55:39 | Valid | Epoch[036/600] Iteration[004/008] Valid loss: 0.2121
2023-02-06 13:55:39 | Valid | Epoch[036/600] Iteration[005/008] Valid loss: 0.2118
2023-02-06 13:55:39 | Valid | Epoch[036/600] Iteration[006/008] Valid loss: 0.2120
2023-02-06 13:55:39 | Valid | Epoch[036/600] Iteration[007/008] Valid loss: 0.2130
2023-02-06 13:55:39 | Valid | Epoch[036/600] Iteration[008/008] Valid loss: 0.2127
2023-02-06 13:55:39 | Valid | Epoch[036/600] MIou: 0.9163203950325205
2023-02-06 13:55:39 | Valid | Epoch[036/600] Pixel Accuracy: 0.9856605529785156
2023-02-06 13:55:39 | Valid | Epoch[036/600] Mean Pixel Accuracy: 0.9413756348431934
2023-02-06 13:55:39 | Stage | Epoch[036/600] Train loss:0.1769
2023-02-06 13:55:39 | Stage | Epoch[036/600] Valid loss:0.2127
2023-02-06 13:55:39 | Stage | Epoch[036/600] LR:0.01

2023-02-06 13:55:39 | Train | Epoch[037/600] Iteration[001/030] Train loss: 0.1715
2023-02-06 13:55:40 | Train | Epoch[037/600] Iteration[002/030] Train loss: 0.1715
2023-02-06 13:55:40 | Train | Epoch[037/600] Iteration[003/030] Train loss: 0.1743
2023-02-06 13:55:40 | Train | Epoch[037/600] Iteration[004/030] Train loss: 0.1737
2023-02-06 13:55:40 | Train | Epoch[037/600] Iteration[005/030] Train loss: 0.1747
2023-02-06 13:55:41 | Train | Epoch[037/600] Iteration[006/030] Train loss: 0.1744
2023-02-06 13:55:41 | Train | Epoch[037/600] Iteration[007/030] Train loss: 0.1744
2023-02-06 13:55:41 | Train | Epoch[037/600] Iteration[008/030] Train loss: 0.1745
2023-02-06 13:55:41 | Train | Epoch[037/600] Iteration[009/030] Train loss: 0.1739
2023-02-06 13:55:41 | Train | Epoch[037/600] Iteration[010/030] Train loss: 0.1737
2023-02-06 13:55:42 | Train | Epoch[037/600] Iteration[011/030] Train loss: 0.1734
2023-02-06 13:55:42 | Train | Epoch[037/600] Iteration[012/030] Train loss: 0.1735
2023-02-06 13:55:42 | Train | Epoch[037/600] Iteration[013/030] Train loss: 0.1733
2023-02-06 13:55:42 | Train | Epoch[037/600] Iteration[014/030] Train loss: 0.1731
2023-02-06 13:55:43 | Train | Epoch[037/600] Iteration[015/030] Train loss: 0.1735
2023-02-06 13:55:43 | Train | Epoch[037/600] Iteration[016/030] Train loss: 0.1735
2023-02-06 13:55:43 | Train | Epoch[037/600] Iteration[017/030] Train loss: 0.1732
2023-02-06 13:55:43 | Train | Epoch[037/600] Iteration[018/030] Train loss: 0.1731
2023-02-06 13:55:43 | Train | Epoch[037/600] Iteration[019/030] Train loss: 0.1733
2023-02-06 13:55:44 | Train | Epoch[037/600] Iteration[020/030] Train loss: 0.1734
2023-02-06 13:55:44 | Train | Epoch[037/600] Iteration[021/030] Train loss: 0.1734
2023-02-06 13:55:44 | Train | Epoch[037/600] Iteration[022/030] Train loss: 0.1733
2023-02-06 13:55:44 | Train | Epoch[037/600] Iteration[023/030] Train loss: 0.1732
2023-02-06 13:55:45 | Train | Epoch[037/600] Iteration[024/030] Train loss: 0.1731
2023-02-06 13:55:45 | Train | Epoch[037/600] Iteration[025/030] Train loss: 0.1730
2023-02-06 13:55:45 | Train | Epoch[037/600] Iteration[026/030] Train loss: 0.1728
2023-02-06 13:55:45 | Train | Epoch[037/600] Iteration[027/030] Train loss: 0.1727
2023-02-06 13:55:45 | Train | Epoch[037/600] Iteration[028/030] Train loss: 0.1725
2023-02-06 13:55:46 | Train | Epoch[037/600] Iteration[029/030] Train loss: 0.1723
2023-02-06 13:55:46 | Train | Epoch[037/600] Iteration[030/030] Train loss: 0.1724
2023-02-06 13:55:46 | Valid | Epoch[037/600] Iteration[001/008] Valid loss: 0.2761
2023-02-06 13:55:46 | Valid | Epoch[037/600] Iteration[002/008] Valid loss: 0.2723
2023-02-06 13:55:46 | Valid | Epoch[037/600] Iteration[003/008] Valid loss: 0.2707
2023-02-06 13:55:46 | Valid | Epoch[037/600] Iteration[004/008] Valid loss: 0.2719
2023-02-06 13:55:46 | Valid | Epoch[037/600] Iteration[005/008] Valid loss: 0.2729
2023-02-06 13:55:46 | Valid | Epoch[037/600] Iteration[006/008] Valid loss: 0.2738
2023-02-06 13:55:46 | Valid | Epoch[037/600] Iteration[007/008] Valid loss: 0.2794
2023-02-06 13:55:46 | Valid | Epoch[037/600] Iteration[008/008] Valid loss: 0.2809
2023-02-06 13:55:46 | Valid | Epoch[037/600] MIou: 0.8869303202439016
2023-02-06 13:55:46 | Valid | Epoch[037/600] Pixel Accuracy: 0.9778048197428385
2023-02-06 13:55:46 | Valid | Epoch[037/600] Mean Pixel Accuracy: 0.9751767035485699
2023-02-06 13:55:46 | Stage | Epoch[037/600] Train loss:0.1724
2023-02-06 13:55:46 | Stage | Epoch[037/600] Valid loss:0.2809
2023-02-06 13:55:46 | Stage | Epoch[037/600] LR:0.01

2023-02-06 13:55:47 | Train | Epoch[038/600] Iteration[001/030] Train loss: 0.1665
2023-02-06 13:55:47 | Train | Epoch[038/600] Iteration[002/030] Train loss: 0.1668
2023-02-06 13:55:47 | Train | Epoch[038/600] Iteration[003/030] Train loss: 0.1681
2023-02-06 13:55:48 | Train | Epoch[038/600] Iteration[004/030] Train loss: 0.1694
2023-02-06 13:55:48 | Train | Epoch[038/600] Iteration[005/030] Train loss: 0.1687
2023-02-06 13:55:48 | Train | Epoch[038/600] Iteration[006/030] Train loss: 0.1691
2023-02-06 13:55:48 | Train | Epoch[038/600] Iteration[007/030] Train loss: 0.1688
2023-02-06 13:55:49 | Train | Epoch[038/600] Iteration[008/030] Train loss: 0.1687
2023-02-06 13:55:49 | Train | Epoch[038/600] Iteration[009/030] Train loss: 0.1683
2023-02-06 13:55:49 | Train | Epoch[038/600] Iteration[010/030] Train loss: 0.1682
2023-02-06 13:55:49 | Train | Epoch[038/600] Iteration[011/030] Train loss: 0.1680
2023-02-06 13:55:49 | Train | Epoch[038/600] Iteration[012/030] Train loss: 0.1679
2023-02-06 13:55:50 | Train | Epoch[038/600] Iteration[013/030] Train loss: 0.1678
2023-02-06 13:55:50 | Train | Epoch[038/600] Iteration[014/030] Train loss: 0.1677
2023-02-06 13:55:50 | Train | Epoch[038/600] Iteration[015/030] Train loss: 0.1675
2023-02-06 13:55:50 | Train | Epoch[038/600] Iteration[016/030] Train loss: 0.1675
2023-02-06 13:55:50 | Train | Epoch[038/600] Iteration[017/030] Train loss: 0.1675
2023-02-06 13:55:51 | Train | Epoch[038/600] Iteration[018/030] Train loss: 0.1673
2023-02-06 13:55:51 | Train | Epoch[038/600] Iteration[019/030] Train loss: 0.1672
2023-02-06 13:55:51 | Train | Epoch[038/600] Iteration[020/030] Train loss: 0.1672
2023-02-06 13:55:51 | Train | Epoch[038/600] Iteration[021/030] Train loss: 0.1671
2023-02-06 13:55:52 | Train | Epoch[038/600] Iteration[022/030] Train loss: 0.1670
2023-02-06 13:55:52 | Train | Epoch[038/600] Iteration[023/030] Train loss: 0.1669
2023-02-06 13:55:52 | Train | Epoch[038/600] Iteration[024/030] Train loss: 0.1668
2023-02-06 13:55:52 | Train | Epoch[038/600] Iteration[025/030] Train loss: 0.1669
2023-02-06 13:55:52 | Train | Epoch[038/600] Iteration[026/030] Train loss: 0.1669
2023-02-06 13:55:53 | Train | Epoch[038/600] Iteration[027/030] Train loss: 0.1668
2023-02-06 13:55:53 | Train | Epoch[038/600] Iteration[028/030] Train loss: 0.1666
2023-02-06 13:55:53 | Train | Epoch[038/600] Iteration[029/030] Train loss: 0.1665
2023-02-06 13:55:53 | Train | Epoch[038/600] Iteration[030/030] Train loss: 0.1664
2023-02-06 13:55:54 | Valid | Epoch[038/600] Iteration[001/008] Valid loss: 0.1808
2023-02-06 13:55:54 | Valid | Epoch[038/600] Iteration[002/008] Valid loss: 0.1791
2023-02-06 13:55:54 | Valid | Epoch[038/600] Iteration[003/008] Valid loss: 0.1807
2023-02-06 13:55:54 | Valid | Epoch[038/600] Iteration[004/008] Valid loss: 0.1810
2023-02-06 13:55:54 | Valid | Epoch[038/600] Iteration[005/008] Valid loss: 0.1815
2023-02-06 13:55:54 | Valid | Epoch[038/600] Iteration[006/008] Valid loss: 0.1815
2023-02-06 13:55:54 | Valid | Epoch[038/600] Iteration[007/008] Valid loss: 0.1810
2023-02-06 13:55:54 | Valid | Epoch[038/600] Iteration[008/008] Valid loss: 0.1809
2023-02-06 13:55:54 | Valid | Epoch[038/600] MIou: 0.7945948250482997
2023-02-06 13:55:54 | Valid | Epoch[038/600] Pixel Accuracy: 0.9661165873209635
2023-02-06 13:55:54 | Valid | Epoch[038/600] Mean Pixel Accuracy: 0.8127323700207034
2023-02-06 13:55:54 | Stage | Epoch[038/600] Train loss:0.1664
2023-02-06 13:55:54 | Stage | Epoch[038/600] Valid loss:0.1809
2023-02-06 13:55:54 | Stage | Epoch[038/600] LR:0.01

2023-02-06 13:55:54 | Train | Epoch[039/600] Iteration[001/030] Train loss: 0.1621
2023-02-06 13:55:55 | Train | Epoch[039/600] Iteration[002/030] Train loss: 0.1624
2023-02-06 13:55:55 | Train | Epoch[039/600] Iteration[003/030] Train loss: 0.1623
2023-02-06 13:55:55 | Train | Epoch[039/600] Iteration[004/030] Train loss: 0.1623
2023-02-06 13:55:55 | Train | Epoch[039/600] Iteration[005/030] Train loss: 0.1628
2023-02-06 13:55:56 | Train | Epoch[039/600] Iteration[006/030] Train loss: 0.1628
2023-02-06 13:55:56 | Train | Epoch[039/600] Iteration[007/030] Train loss: 0.1626
2023-02-06 13:55:56 | Train | Epoch[039/600] Iteration[008/030] Train loss: 0.1629
2023-02-06 13:55:56 | Train | Epoch[039/600] Iteration[009/030] Train loss: 0.1627
2023-02-06 13:55:56 | Train | Epoch[039/600] Iteration[010/030] Train loss: 0.1625
2023-02-06 13:55:57 | Train | Epoch[039/600] Iteration[011/030] Train loss: 0.1625
2023-02-06 13:55:57 | Train | Epoch[039/600] Iteration[012/030] Train loss: 0.1623
2023-02-06 13:55:57 | Train | Epoch[039/600] Iteration[013/030] Train loss: 0.1625
2023-02-06 13:55:57 | Train | Epoch[039/600] Iteration[014/030] Train loss: 0.1624
2023-02-06 13:55:58 | Train | Epoch[039/600] Iteration[015/030] Train loss: 0.1622
2023-02-06 13:55:58 | Train | Epoch[039/600] Iteration[016/030] Train loss: 0.1620
2023-02-06 13:55:58 | Train | Epoch[039/600] Iteration[017/030] Train loss: 0.1621
2023-02-06 13:55:58 | Train | Epoch[039/600] Iteration[018/030] Train loss: 0.1619
2023-02-06 13:55:58 | Train | Epoch[039/600] Iteration[019/030] Train loss: 0.1618
2023-02-06 13:55:59 | Train | Epoch[039/600] Iteration[020/030] Train loss: 0.1618
2023-02-06 13:55:59 | Train | Epoch[039/600] Iteration[021/030] Train loss: 0.1619
2023-02-06 13:55:59 | Train | Epoch[039/600] Iteration[022/030] Train loss: 0.1620
2023-02-06 13:55:59 | Train | Epoch[039/600] Iteration[023/030] Train loss: 0.1621
2023-02-06 13:56:00 | Train | Epoch[039/600] Iteration[024/030] Train loss: 0.1619
2023-02-06 13:56:00 | Train | Epoch[039/600] Iteration[025/030] Train loss: 0.1619
2023-02-06 13:56:00 | Train | Epoch[039/600] Iteration[026/030] Train loss: 0.1618
2023-02-06 13:56:00 | Train | Epoch[039/600] Iteration[027/030] Train loss: 0.1617
2023-02-06 13:56:00 | Train | Epoch[039/600] Iteration[028/030] Train loss: 0.1616
2023-02-06 13:56:01 | Train | Epoch[039/600] Iteration[029/030] Train loss: 0.1615
2023-02-06 13:56:01 | Train | Epoch[039/600] Iteration[030/030] Train loss: 0.1613
2023-02-06 13:56:01 | Valid | Epoch[039/600] Iteration[001/008] Valid loss: 0.2058
2023-02-06 13:56:01 | Valid | Epoch[039/600] Iteration[002/008] Valid loss: 0.2094
2023-02-06 13:56:01 | Valid | Epoch[039/600] Iteration[003/008] Valid loss: 0.2121
2023-02-06 13:56:01 | Valid | Epoch[039/600] Iteration[004/008] Valid loss: 0.2120
2023-02-06 13:56:01 | Valid | Epoch[039/600] Iteration[005/008] Valid loss: 0.2148
2023-02-06 13:56:01 | Valid | Epoch[039/600] Iteration[006/008] Valid loss: 0.2156
2023-02-06 13:56:01 | Valid | Epoch[039/600] Iteration[007/008] Valid loss: 0.2154
2023-02-06 13:56:01 | Valid | Epoch[039/600] Iteration[008/008] Valid loss: 0.2186
2023-02-06 13:56:02 | Valid | Epoch[039/600] MIou: 0.6209274354652625
2023-02-06 13:56:02 | Valid | Epoch[039/600] Pixel Accuracy: 0.9366480509440104
2023-02-06 13:56:02 | Valid | Epoch[039/600] Mean Pixel Accuracy: 0.6547876245011947
2023-02-06 13:56:02 | Stage | Epoch[039/600] Train loss:0.1613
2023-02-06 13:56:02 | Stage | Epoch[039/600] Valid loss:0.2186
2023-02-06 13:56:02 | Stage | Epoch[039/600] LR:0.01

2023-02-06 13:56:02 | Train | Epoch[040/600] Iteration[001/030] Train loss: 0.1551
2023-02-06 13:56:02 | Train | Epoch[040/600] Iteration[002/030] Train loss: 0.1580
2023-02-06 13:56:02 | Train | Epoch[040/600] Iteration[003/030] Train loss: 0.1574
2023-02-06 13:56:03 | Train | Epoch[040/600] Iteration[004/030] Train loss: 0.1584
2023-02-06 13:56:03 | Train | Epoch[040/600] Iteration[005/030] Train loss: 0.1582
2023-02-06 13:56:03 | Train | Epoch[040/600] Iteration[006/030] Train loss: 0.1596
2023-02-06 13:56:03 | Train | Epoch[040/600] Iteration[007/030] Train loss: 0.1589
2023-02-06 13:56:04 | Train | Epoch[040/600] Iteration[008/030] Train loss: 0.1588
2023-02-06 13:56:04 | Train | Epoch[040/600] Iteration[009/030] Train loss: 0.1586
2023-02-06 13:56:04 | Train | Epoch[040/600] Iteration[010/030] Train loss: 0.1585
2023-02-06 13:56:04 | Train | Epoch[040/600] Iteration[011/030] Train loss: 0.1582
2023-02-06 13:56:04 | Train | Epoch[040/600] Iteration[012/030] Train loss: 0.1580
2023-02-06 13:56:05 | Train | Epoch[040/600] Iteration[013/030] Train loss: 0.1580
2023-02-06 13:56:05 | Train | Epoch[040/600] Iteration[014/030] Train loss: 0.1577
2023-02-06 13:56:05 | Train | Epoch[040/600] Iteration[015/030] Train loss: 0.1577
2023-02-06 13:56:05 | Train | Epoch[040/600] Iteration[016/030] Train loss: 0.1576
2023-02-06 13:56:05 | Train | Epoch[040/600] Iteration[017/030] Train loss: 0.1575
2023-02-06 13:56:06 | Train | Epoch[040/600] Iteration[018/030] Train loss: 0.1574
2023-02-06 13:56:06 | Train | Epoch[040/600] Iteration[019/030] Train loss: 0.1573
2023-02-06 13:56:06 | Train | Epoch[040/600] Iteration[020/030] Train loss: 0.1575
2023-02-06 13:56:06 | Train | Epoch[040/600] Iteration[021/030] Train loss: 0.1574
2023-02-06 13:56:07 | Train | Epoch[040/600] Iteration[022/030] Train loss: 0.1573
2023-02-06 13:56:07 | Train | Epoch[040/600] Iteration[023/030] Train loss: 0.1573
2023-02-06 13:56:07 | Train | Epoch[040/600] Iteration[024/030] Train loss: 0.1573
2023-02-06 13:56:07 | Train | Epoch[040/600] Iteration[025/030] Train loss: 0.1572
2023-02-06 13:56:07 | Train | Epoch[040/600] Iteration[026/030] Train loss: 0.1573
2023-02-06 13:56:08 | Train | Epoch[040/600] Iteration[027/030] Train loss: 0.1573
2023-02-06 13:56:08 | Train | Epoch[040/600] Iteration[028/030] Train loss: 0.1574
2023-02-06 13:56:08 | Train | Epoch[040/600] Iteration[029/030] Train loss: 0.1573
2023-02-06 13:56:08 | Train | Epoch[040/600] Iteration[030/030] Train loss: 0.1571
2023-02-06 13:56:09 | Valid | Epoch[040/600] Iteration[001/008] Valid loss: 0.3655
2023-02-06 13:56:09 | Valid | Epoch[040/600] Iteration[002/008] Valid loss: 0.3498
2023-02-06 13:56:09 | Valid | Epoch[040/600] Iteration[003/008] Valid loss: 0.3509
2023-02-06 13:56:09 | Valid | Epoch[040/600] Iteration[004/008] Valid loss: 0.3547
2023-02-06 13:56:09 | Valid | Epoch[040/600] Iteration[005/008] Valid loss: 0.3539
2023-02-06 13:56:09 | Valid | Epoch[040/600] Iteration[006/008] Valid loss: 0.3529
2023-02-06 13:56:09 | Valid | Epoch[040/600] Iteration[007/008] Valid loss: 0.3610
2023-02-06 13:56:09 | Valid | Epoch[040/600] Iteration[008/008] Valid loss: 0.3621
2023-02-06 13:56:09 | Valid | Epoch[040/600] MIou: 0.8291040911248048
2023-02-06 13:56:09 | Valid | Epoch[040/600] Pixel Accuracy: 0.9616266886393229
2023-02-06 13:56:09 | Valid | Epoch[040/600] Mean Pixel Accuracy: 0.9757888795100818
2023-02-06 13:56:09 | Stage | Epoch[040/600] Train loss:0.1571
2023-02-06 13:56:09 | Stage | Epoch[040/600] Valid loss:0.3621
2023-02-06 13:56:09 | Stage | Epoch[040/600] LR:0.01

2023-02-06 13:56:09 | Train | Epoch[041/600] Iteration[001/030] Train loss: 0.1519
2023-02-06 13:56:10 | Train | Epoch[041/600] Iteration[002/030] Train loss: 0.1527
2023-02-06 13:56:10 | Train | Epoch[041/600] Iteration[003/030] Train loss: 0.1531
2023-02-06 13:56:10 | Train | Epoch[041/600] Iteration[004/030] Train loss: 0.1536
2023-02-06 13:56:10 | Train | Epoch[041/600] Iteration[005/030] Train loss: 0.1531
2023-02-06 13:56:11 | Train | Epoch[041/600] Iteration[006/030] Train loss: 0.1540
2023-02-06 13:56:11 | Train | Epoch[041/600] Iteration[007/030] Train loss: 0.1537
2023-02-06 13:56:11 | Train | Epoch[041/600] Iteration[008/030] Train loss: 0.1535
2023-02-06 13:56:11 | Train | Epoch[041/600] Iteration[009/030] Train loss: 0.1537
2023-02-06 13:56:11 | Train | Epoch[041/600] Iteration[010/030] Train loss: 0.1536
2023-02-06 13:56:12 | Train | Epoch[041/600] Iteration[011/030] Train loss: 0.1533
2023-02-06 13:56:12 | Train | Epoch[041/600] Iteration[012/030] Train loss: 0.1531
2023-02-06 13:56:12 | Train | Epoch[041/600] Iteration[013/030] Train loss: 0.1529
2023-02-06 13:56:12 | Train | Epoch[041/600] Iteration[014/030] Train loss: 0.1531
2023-02-06 13:56:12 | Train | Epoch[041/600] Iteration[015/030] Train loss: 0.1530
2023-02-06 13:56:13 | Train | Epoch[041/600] Iteration[016/030] Train loss: 0.1530
2023-02-06 13:56:13 | Train | Epoch[041/600] Iteration[017/030] Train loss: 0.1529
2023-02-06 13:56:13 | Train | Epoch[041/600] Iteration[018/030] Train loss: 0.1528
2023-02-06 13:56:13 | Train | Epoch[041/600] Iteration[019/030] Train loss: 0.1527
2023-02-06 13:56:14 | Train | Epoch[041/600] Iteration[020/030] Train loss: 0.1528
2023-02-06 13:56:14 | Train | Epoch[041/600] Iteration[021/030] Train loss: 0.1527
2023-02-06 13:56:14 | Train | Epoch[041/600] Iteration[022/030] Train loss: 0.1527
2023-02-06 13:56:14 | Train | Epoch[041/600] Iteration[023/030] Train loss: 0.1527
2023-02-06 13:56:14 | Train | Epoch[041/600] Iteration[024/030] Train loss: 0.1526
2023-02-06 13:56:15 | Train | Epoch[041/600] Iteration[025/030] Train loss: 0.1526
2023-02-06 13:56:15 | Train | Epoch[041/600] Iteration[026/030] Train loss: 0.1525
2023-02-06 13:56:15 | Train | Epoch[041/600] Iteration[027/030] Train loss: 0.1525
2023-02-06 13:56:15 | Train | Epoch[041/600] Iteration[028/030] Train loss: 0.1524
2023-02-06 13:56:16 | Train | Epoch[041/600] Iteration[029/030] Train loss: 0.1523
2023-02-06 13:56:16 | Train | Epoch[041/600] Iteration[030/030] Train loss: 0.1523
2023-02-06 13:56:16 | Valid | Epoch[041/600] Iteration[001/008] Valid loss: 0.1776
2023-02-06 13:56:16 | Valid | Epoch[041/600] Iteration[002/008] Valid loss: 0.1777
2023-02-06 13:56:16 | Valid | Epoch[041/600] Iteration[003/008] Valid loss: 0.1788
2023-02-06 13:56:16 | Valid | Epoch[041/600] Iteration[004/008] Valid loss: 0.1790
2023-02-06 13:56:16 | Valid | Epoch[041/600] Iteration[005/008] Valid loss: 0.1794
2023-02-06 13:56:16 | Valid | Epoch[041/600] Iteration[006/008] Valid loss: 0.1787
2023-02-06 13:56:16 | Valid | Epoch[041/600] Iteration[007/008] Valid loss: 0.1782
2023-02-06 13:56:16 | Valid | Epoch[041/600] Iteration[008/008] Valid loss: 0.1783
2023-02-06 13:56:16 | Valid | Epoch[041/600] MIou: 0.8461606733151834
2023-02-06 13:56:16 | Valid | Epoch[041/600] Pixel Accuracy: 0.9743868509928385
2023-02-06 13:56:16 | Valid | Epoch[041/600] Mean Pixel Accuracy: 0.863550820748139
2023-02-06 13:56:16 | Stage | Epoch[041/600] Train loss:0.1523
2023-02-06 13:56:16 | Stage | Epoch[041/600] Valid loss:0.1783
2023-02-06 13:56:16 | Stage | Epoch[041/600] LR:0.01

2023-02-06 13:56:17 | Train | Epoch[042/600] Iteration[001/030] Train loss: 0.1478
2023-02-06 13:56:17 | Train | Epoch[042/600] Iteration[002/030] Train loss: 0.1493
2023-02-06 13:56:17 | Train | Epoch[042/600] Iteration[003/030] Train loss: 0.1504
2023-02-06 13:56:18 | Train | Epoch[042/600] Iteration[004/030] Train loss: 0.1495
2023-02-06 13:56:18 | Train | Epoch[042/600] Iteration[005/030] Train loss: 0.1489
2023-02-06 13:56:18 | Train | Epoch[042/600] Iteration[006/030] Train loss: 0.1493
2023-02-06 13:56:18 | Train | Epoch[042/600] Iteration[007/030] Train loss: 0.1491
2023-02-06 13:56:18 | Train | Epoch[042/600] Iteration[008/030] Train loss: 0.1488
2023-02-06 13:56:19 | Train | Epoch[042/600] Iteration[009/030] Train loss: 0.1490
2023-02-06 13:56:19 | Train | Epoch[042/600] Iteration[010/030] Train loss: 0.1490
2023-02-06 13:56:19 | Train | Epoch[042/600] Iteration[011/030] Train loss: 0.1490
2023-02-06 13:56:19 | Train | Epoch[042/600] Iteration[012/030] Train loss: 0.1494
2023-02-06 13:56:20 | Train | Epoch[042/600] Iteration[013/030] Train loss: 0.1494
2023-02-06 13:56:20 | Train | Epoch[042/600] Iteration[014/030] Train loss: 0.1491
2023-02-06 13:56:20 | Train | Epoch[042/600] Iteration[015/030] Train loss: 0.1489
2023-02-06 13:56:20 | Train | Epoch[042/600] Iteration[016/030] Train loss: 0.1490
2023-02-06 13:56:20 | Train | Epoch[042/600] Iteration[017/030] Train loss: 0.1492
2023-02-06 13:56:21 | Train | Epoch[042/600] Iteration[018/030] Train loss: 0.1490
2023-02-06 13:56:21 | Train | Epoch[042/600] Iteration[019/030] Train loss: 0.1489
2023-02-06 13:56:21 | Train | Epoch[042/600] Iteration[020/030] Train loss: 0.1488
2023-02-06 13:56:21 | Train | Epoch[042/600] Iteration[021/030] Train loss: 0.1490
2023-02-06 13:56:22 | Train | Epoch[042/600] Iteration[022/030] Train loss: 0.1489
2023-02-06 13:56:22 | Train | Epoch[042/600] Iteration[023/030] Train loss: 0.1489
2023-02-06 13:56:22 | Train | Epoch[042/600] Iteration[024/030] Train loss: 0.1488
2023-02-06 13:56:22 | Train | Epoch[042/600] Iteration[025/030] Train loss: 0.1486
2023-02-06 13:56:22 | Train | Epoch[042/600] Iteration[026/030] Train loss: 0.1486
2023-02-06 13:56:23 | Train | Epoch[042/600] Iteration[027/030] Train loss: 0.1486
2023-02-06 13:56:23 | Train | Epoch[042/600] Iteration[028/030] Train loss: 0.1485
2023-02-06 13:56:23 | Train | Epoch[042/600] Iteration[029/030] Train loss: 0.1485
2023-02-06 13:56:23 | Train | Epoch[042/600] Iteration[030/030] Train loss: 0.1484
2023-02-06 13:56:23 | Valid | Epoch[042/600] Iteration[001/008] Valid loss: 0.1682
2023-02-06 13:56:24 | Valid | Epoch[042/600] Iteration[002/008] Valid loss: 0.1668
2023-02-06 13:56:24 | Valid | Epoch[042/600] Iteration[003/008] Valid loss: 0.1674
2023-02-06 13:56:24 | Valid | Epoch[042/600] Iteration[004/008] Valid loss: 0.1666
2023-02-06 13:56:24 | Valid | Epoch[042/600] Iteration[005/008] Valid loss: 0.1678
2023-02-06 13:56:24 | Valid | Epoch[042/600] Iteration[006/008] Valid loss: 0.1674
2023-02-06 13:56:24 | Valid | Epoch[042/600] Iteration[007/008] Valid loss: 0.1700
2023-02-06 13:56:24 | Valid | Epoch[042/600] Iteration[008/008] Valid loss: 0.1697
2023-02-06 13:56:24 | Valid | Epoch[042/600] MIou: 0.9203459774173013
2023-02-06 13:56:24 | Valid | Epoch[042/600] Pixel Accuracy: 0.9861234029134115
2023-02-06 13:56:24 | Valid | Epoch[042/600] Mean Pixel Accuracy: 0.9527131811106
2023-02-06 13:56:24 | Stage | Epoch[042/600] Train loss:0.1484
2023-02-06 13:56:24 | Stage | Epoch[042/600] Valid loss:0.1697
2023-02-06 13:56:24 | Stage | Epoch[042/600] LR:0.01

2023-02-06 13:56:24 | Train | Epoch[043/600] Iteration[001/030] Train loss: 0.1443
2023-02-06 13:56:25 | Train | Epoch[043/600] Iteration[002/030] Train loss: 0.1443
2023-02-06 13:56:25 | Train | Epoch[043/600] Iteration[003/030] Train loss: 0.1443
2023-02-06 13:56:25 | Train | Epoch[043/600] Iteration[004/030] Train loss: 0.1440
2023-02-06 13:56:25 | Train | Epoch[043/600] Iteration[005/030] Train loss: 0.1439
2023-02-06 13:56:25 | Train | Epoch[043/600] Iteration[006/030] Train loss: 0.1439
2023-02-06 13:56:26 | Train | Epoch[043/600] Iteration[007/030] Train loss: 0.1441
2023-02-06 13:56:26 | Train | Epoch[043/600] Iteration[008/030] Train loss: 0.1442
2023-02-06 13:56:26 | Train | Epoch[043/600] Iteration[009/030] Train loss: 0.1442
2023-02-06 13:56:26 | Train | Epoch[043/600] Iteration[010/030] Train loss: 0.1443
2023-02-06 13:56:27 | Train | Epoch[043/600] Iteration[011/030] Train loss: 0.1443
2023-02-06 13:56:27 | Train | Epoch[043/600] Iteration[012/030] Train loss: 0.1446
2023-02-06 13:56:27 | Train | Epoch[043/600] Iteration[013/030] Train loss: 0.1445
2023-02-06 13:56:27 | Train | Epoch[043/600] Iteration[014/030] Train loss: 0.1449
2023-02-06 13:56:27 | Train | Epoch[043/600] Iteration[015/030] Train loss: 0.1455
2023-02-06 13:56:28 | Train | Epoch[043/600] Iteration[016/030] Train loss: 0.1454
2023-02-06 13:56:28 | Train | Epoch[043/600] Iteration[017/030] Train loss: 0.1453
2023-02-06 13:56:28 | Train | Epoch[043/600] Iteration[018/030] Train loss: 0.1453
2023-02-06 13:56:28 | Train | Epoch[043/600] Iteration[019/030] Train loss: 0.1452
2023-02-06 13:56:29 | Train | Epoch[043/600] Iteration[020/030] Train loss: 0.1452
2023-02-06 13:56:29 | Train | Epoch[043/600] Iteration[021/030] Train loss: 0.1452
2023-02-06 13:56:29 | Train | Epoch[043/600] Iteration[022/030] Train loss: 0.1452
2023-02-06 13:56:29 | Train | Epoch[043/600] Iteration[023/030] Train loss: 0.1450
2023-02-06 13:56:29 | Train | Epoch[043/600] Iteration[024/030] Train loss: 0.1448
2023-02-06 13:56:30 | Train | Epoch[043/600] Iteration[025/030] Train loss: 0.1448
2023-02-06 13:56:30 | Train | Epoch[043/600] Iteration[026/030] Train loss: 0.1447
2023-02-06 13:56:30 | Train | Epoch[043/600] Iteration[027/030] Train loss: 0.1445
2023-02-06 13:56:30 | Train | Epoch[043/600] Iteration[028/030] Train loss: 0.1444
2023-02-06 13:56:30 | Train | Epoch[043/600] Iteration[029/030] Train loss: 0.1443
2023-02-06 13:56:31 | Train | Epoch[043/600] Iteration[030/030] Train loss: 0.1442
2023-02-06 13:56:31 | Valid | Epoch[043/600] Iteration[001/008] Valid loss: 0.2041
2023-02-06 13:56:31 | Valid | Epoch[043/600] Iteration[002/008] Valid loss: 0.1970
2023-02-06 13:56:31 | Valid | Epoch[043/600] Iteration[003/008] Valid loss: 0.1960
2023-02-06 13:56:31 | Valid | Epoch[043/600] Iteration[004/008] Valid loss: 0.1939
2023-02-06 13:56:31 | Valid | Epoch[043/600] Iteration[005/008] Valid loss: 0.1945
2023-02-06 13:56:31 | Valid | Epoch[043/600] Iteration[006/008] Valid loss: 0.1923
2023-02-06 13:56:31 | Valid | Epoch[043/600] Iteration[007/008] Valid loss: 0.1941
2023-02-06 13:56:31 | Valid | Epoch[043/600] Iteration[008/008] Valid loss: 0.1946
2023-02-06 13:56:31 | Valid | Epoch[043/600] MIou: 0.9188992101741369
2023-02-06 13:56:31 | Valid | Epoch[043/600] Pixel Accuracy: 0.9853261311848959
2023-02-06 13:56:31 | Valid | Epoch[043/600] Mean Pixel Accuracy: 0.9690455137152421
2023-02-06 13:56:31 | Stage | Epoch[043/600] Train loss:0.1442
2023-02-06 13:56:31 | Stage | Epoch[043/600] Valid loss:0.1946
2023-02-06 13:56:31 | Stage | Epoch[043/600] LR:0.01

2023-02-06 13:56:32 | Train | Epoch[044/600] Iteration[001/030] Train loss: 0.1433
2023-02-06 13:56:32 | Train | Epoch[044/600] Iteration[002/030] Train loss: 0.1433
2023-02-06 13:56:32 | Train | Epoch[044/600] Iteration[003/030] Train loss: 0.1422
2023-02-06 13:56:33 | Train | Epoch[044/600] Iteration[004/030] Train loss: 0.1416
2023-02-06 13:56:33 | Train | Epoch[044/600] Iteration[005/030] Train loss: 0.1419
2023-02-06 13:56:33 | Train | Epoch[044/600] Iteration[006/030] Train loss: 0.1414
2023-02-06 13:56:33 | Train | Epoch[044/600] Iteration[007/030] Train loss: 0.1412
2023-02-06 13:56:33 | Train | Epoch[044/600] Iteration[008/030] Train loss: 0.1408
2023-02-06 13:56:34 | Train | Epoch[044/600] Iteration[009/030] Train loss: 0.1407
2023-02-06 13:56:34 | Train | Epoch[044/600] Iteration[010/030] Train loss: 0.1407
2023-02-06 13:56:34 | Train | Epoch[044/600] Iteration[011/030] Train loss: 0.1405
2023-02-06 13:56:34 | Train | Epoch[044/600] Iteration[012/030] Train loss: 0.1403
2023-02-06 13:56:34 | Train | Epoch[044/600] Iteration[013/030] Train loss: 0.1404
2023-02-06 13:56:35 | Train | Epoch[044/600] Iteration[014/030] Train loss: 0.1403
2023-02-06 13:56:35 | Train | Epoch[044/600] Iteration[015/030] Train loss: 0.1403
2023-02-06 13:56:35 | Train | Epoch[044/600] Iteration[016/030] Train loss: 0.1402
2023-02-06 13:56:35 | Train | Epoch[044/600] Iteration[017/030] Train loss: 0.1401
2023-02-06 13:56:36 | Train | Epoch[044/600] Iteration[018/030] Train loss: 0.1402
2023-02-06 13:56:36 | Train | Epoch[044/600] Iteration[019/030] Train loss: 0.1404
2023-02-06 13:56:36 | Train | Epoch[044/600] Iteration[020/030] Train loss: 0.1402
2023-02-06 13:56:36 | Train | Epoch[044/600] Iteration[021/030] Train loss: 0.1402
2023-02-06 13:56:36 | Train | Epoch[044/600] Iteration[022/030] Train loss: 0.1401
2023-02-06 13:56:37 | Train | Epoch[044/600] Iteration[023/030] Train loss: 0.1401
2023-02-06 13:56:37 | Train | Epoch[044/600] Iteration[024/030] Train loss: 0.1400
2023-02-06 13:56:37 | Train | Epoch[044/600] Iteration[025/030] Train loss: 0.1400
2023-02-06 13:56:37 | Train | Epoch[044/600] Iteration[026/030] Train loss: 0.1400
2023-02-06 13:56:38 | Train | Epoch[044/600] Iteration[027/030] Train loss: 0.1399
2023-02-06 13:56:38 | Train | Epoch[044/600] Iteration[028/030] Train loss: 0.1399
2023-02-06 13:56:38 | Train | Epoch[044/600] Iteration[029/030] Train loss: 0.1398
2023-02-06 13:56:38 | Train | Epoch[044/600] Iteration[030/030] Train loss: 0.1398
2023-02-06 13:56:38 | Valid | Epoch[044/600] Iteration[001/008] Valid loss: 0.5655
2023-02-06 13:56:39 | Valid | Epoch[044/600] Iteration[002/008] Valid loss: 0.4937
2023-02-06 13:56:39 | Valid | Epoch[044/600] Iteration[003/008] Valid loss: 0.4908
2023-02-06 13:56:39 | Valid | Epoch[044/600] Iteration[004/008] Valid loss: 0.4886
2023-02-06 13:56:39 | Valid | Epoch[044/600] Iteration[005/008] Valid loss: 0.5056
2023-02-06 13:56:39 | Valid | Epoch[044/600] Iteration[006/008] Valid loss: 0.4930
2023-02-06 13:56:39 | Valid | Epoch[044/600] Iteration[007/008] Valid loss: 0.5235
2023-02-06 13:56:39 | Valid | Epoch[044/600] Iteration[008/008] Valid loss: 0.5256
2023-02-06 13:56:39 | Valid | Epoch[044/600] MIou: 0.8413356701641448
2023-02-06 13:56:39 | Valid | Epoch[044/600] Pixel Accuracy: 0.9652201334635416
2023-02-06 13:56:39 | Valid | Epoch[044/600] Mean Pixel Accuracy: 0.9784360800224678
2023-02-06 13:56:39 | Stage | Epoch[044/600] Train loss:0.1398
2023-02-06 13:56:39 | Stage | Epoch[044/600] Valid loss:0.5256
2023-02-06 13:56:39 | Stage | Epoch[044/600] LR:0.01

2023-02-06 13:56:39 | Train | Epoch[045/600] Iteration[001/030] Train loss: 0.1358
2023-02-06 13:56:40 | Train | Epoch[045/600] Iteration[002/030] Train loss: 0.1360
2023-02-06 13:56:40 | Train | Epoch[045/600] Iteration[003/030] Train loss: 0.1371
2023-02-06 13:56:40 | Train | Epoch[045/600] Iteration[004/030] Train loss: 0.1379
2023-02-06 13:56:40 | Train | Epoch[045/600] Iteration[005/030] Train loss: 0.1384
2023-02-06 13:56:40 | Train | Epoch[045/600] Iteration[006/030] Train loss: 0.1382
2023-02-06 13:56:41 | Train | Epoch[045/600] Iteration[007/030] Train loss: 0.1381
2023-02-06 13:56:41 | Train | Epoch[045/600] Iteration[008/030] Train loss: 0.1380
2023-02-06 13:56:41 | Train | Epoch[045/600] Iteration[009/030] Train loss: 0.1377
2023-02-06 13:56:41 | Train | Epoch[045/600] Iteration[010/030] Train loss: 0.1374
2023-02-06 13:56:42 | Train | Epoch[045/600] Iteration[011/030] Train loss: 0.1369
2023-02-06 13:56:42 | Train | Epoch[045/600] Iteration[012/030] Train loss: 0.1373
2023-02-06 13:56:42 | Train | Epoch[045/600] Iteration[013/030] Train loss: 0.1371
2023-02-06 13:56:42 | Train | Epoch[045/600] Iteration[014/030] Train loss: 0.1371
2023-02-06 13:56:42 | Train | Epoch[045/600] Iteration[015/030] Train loss: 0.1371
2023-02-06 13:56:43 | Train | Epoch[045/600] Iteration[016/030] Train loss: 0.1369
2023-02-06 13:56:43 | Train | Epoch[045/600] Iteration[017/030] Train loss: 0.1369
2023-02-06 13:56:43 | Train | Epoch[045/600] Iteration[018/030] Train loss: 0.1368
2023-02-06 13:56:43 | Train | Epoch[045/600] Iteration[019/030] Train loss: 0.1367
2023-02-06 13:56:44 | Train | Epoch[045/600] Iteration[020/030] Train loss: 0.1366
2023-02-06 13:56:44 | Train | Epoch[045/600] Iteration[021/030] Train loss: 0.1366
2023-02-06 13:56:44 | Train | Epoch[045/600] Iteration[022/030] Train loss: 0.1364
2023-02-06 13:56:44 | Train | Epoch[045/600] Iteration[023/030] Train loss: 0.1364
2023-02-06 13:56:44 | Train | Epoch[045/600] Iteration[024/030] Train loss: 0.1364
2023-02-06 13:56:45 | Train | Epoch[045/600] Iteration[025/030] Train loss: 0.1364
2023-02-06 13:56:45 | Train | Epoch[045/600] Iteration[026/030] Train loss: 0.1363
2023-02-06 13:56:45 | Train | Epoch[045/600] Iteration[027/030] Train loss: 0.1362
2023-02-06 13:56:45 | Train | Epoch[045/600] Iteration[028/030] Train loss: 0.1361
2023-02-06 13:56:45 | Train | Epoch[045/600] Iteration[029/030] Train loss: 0.1360
2023-02-06 13:56:46 | Train | Epoch[045/600] Iteration[030/030] Train loss: 0.1359
2023-02-06 13:56:46 | Valid | Epoch[045/600] Iteration[001/008] Valid loss: 0.1873
2023-02-06 13:56:46 | Valid | Epoch[045/600] Iteration[002/008] Valid loss: 0.1815
2023-02-06 13:56:46 | Valid | Epoch[045/600] Iteration[003/008] Valid loss: 0.1786
2023-02-06 13:56:46 | Valid | Epoch[045/600] Iteration[004/008] Valid loss: 0.1772
2023-02-06 13:56:46 | Valid | Epoch[045/600] Iteration[005/008] Valid loss: 0.1759
2023-02-06 13:56:46 | Valid | Epoch[045/600] Iteration[006/008] Valid loss: 0.1760
2023-02-06 13:56:46 | Valid | Epoch[045/600] Iteration[007/008] Valid loss: 0.1783
2023-02-06 13:56:46 | Valid | Epoch[045/600] Iteration[008/008] Valid loss: 0.1777
2023-02-06 13:56:46 | Valid | Epoch[045/600] MIou: 0.9197160136058755
2023-02-06 13:56:46 | Valid | Epoch[045/600] Pixel Accuracy: 0.9853108723958334
2023-02-06 13:56:46 | Valid | Epoch[045/600] Mean Pixel Accuracy: 0.9752824912734003
2023-02-06 13:56:46 | Stage | Epoch[045/600] Train loss:0.1359
2023-02-06 13:56:46 | Stage | Epoch[045/600] Valid loss:0.1777
2023-02-06 13:56:46 | Stage | Epoch[045/600] LR:0.01

2023-02-06 13:56:47 | Train | Epoch[046/600] Iteration[001/030] Train loss: 0.1316
2023-02-06 13:56:47 | Train | Epoch[046/600] Iteration[002/030] Train loss: 0.1336
2023-02-06 13:56:47 | Train | Epoch[046/600] Iteration[003/030] Train loss: 0.1333
2023-02-06 13:56:48 | Train | Epoch[046/600] Iteration[004/030] Train loss: 0.1336
2023-02-06 13:56:48 | Train | Epoch[046/600] Iteration[005/030] Train loss: 0.1333
2023-02-06 13:56:48 | Train | Epoch[046/600] Iteration[006/030] Train loss: 0.1329
2023-02-06 13:56:48 | Train | Epoch[046/600] Iteration[007/030] Train loss: 0.1328
2023-02-06 13:56:48 | Train | Epoch[046/600] Iteration[008/030] Train loss: 0.1330
2023-02-06 13:56:49 | Train | Epoch[046/600] Iteration[009/030] Train loss: 0.1327
2023-02-06 13:56:49 | Train | Epoch[046/600] Iteration[010/030] Train loss: 0.1325
2023-02-06 13:56:49 | Train | Epoch[046/600] Iteration[011/030] Train loss: 0.1322
2023-02-06 13:56:49 | Train | Epoch[046/600] Iteration[012/030] Train loss: 0.1320
2023-02-06 13:56:49 | Train | Epoch[046/600] Iteration[013/030] Train loss: 0.1320
2023-02-06 13:56:50 | Train | Epoch[046/600] Iteration[014/030] Train loss: 0.1319
2023-02-06 13:56:50 | Train | Epoch[046/600] Iteration[015/030] Train loss: 0.1318
2023-02-06 13:56:50 | Train | Epoch[046/600] Iteration[016/030] Train loss: 0.1322
2023-02-06 13:56:50 | Train | Epoch[046/600] Iteration[017/030] Train loss: 0.1321
2023-02-06 13:56:51 | Train | Epoch[046/600] Iteration[018/030] Train loss: 0.1320
2023-02-06 13:56:51 | Train | Epoch[046/600] Iteration[019/030] Train loss: 0.1319
2023-02-06 13:56:51 | Train | Epoch[046/600] Iteration[020/030] Train loss: 0.1321
2023-02-06 13:56:51 | Train | Epoch[046/600] Iteration[021/030] Train loss: 0.1322
2023-02-06 13:56:51 | Train | Epoch[046/600] Iteration[022/030] Train loss: 0.1322
2023-02-06 13:56:52 | Train | Epoch[046/600] Iteration[023/030] Train loss: 0.1323
2023-02-06 13:56:52 | Train | Epoch[046/600] Iteration[024/030] Train loss: 0.1323
2023-02-06 13:56:52 | Train | Epoch[046/600] Iteration[025/030] Train loss: 0.1323
2023-02-06 13:56:52 | Train | Epoch[046/600] Iteration[026/030] Train loss: 0.1323
2023-02-06 13:56:53 | Train | Epoch[046/600] Iteration[027/030] Train loss: 0.1322
2023-02-06 13:56:53 | Train | Epoch[046/600] Iteration[028/030] Train loss: 0.1321
2023-02-06 13:56:53 | Train | Epoch[046/600] Iteration[029/030] Train loss: 0.1321
2023-02-06 13:56:53 | Train | Epoch[046/600] Iteration[030/030] Train loss: 0.1320
2023-02-06 13:56:53 | Valid | Epoch[046/600] Iteration[001/008] Valid loss: 0.2072
2023-02-06 13:56:53 | Valid | Epoch[046/600] Iteration[002/008] Valid loss: 0.2025
2023-02-06 13:56:54 | Valid | Epoch[046/600] Iteration[003/008] Valid loss: 0.2013
2023-02-06 13:56:54 | Valid | Epoch[046/600] Iteration[004/008] Valid loss: 0.1995
2023-02-06 13:56:54 | Valid | Epoch[046/600] Iteration[005/008] Valid loss: 0.2023
2023-02-06 13:56:54 | Valid | Epoch[046/600] Iteration[006/008] Valid loss: 0.2006
2023-02-06 13:56:54 | Valid | Epoch[046/600] Iteration[007/008] Valid loss: 0.2060
2023-02-06 13:56:54 | Valid | Epoch[046/600] Iteration[008/008] Valid loss: 0.2087
2023-02-06 13:56:54 | Valid | Epoch[046/600] MIou: 0.898840946025201
2023-02-06 13:56:54 | Valid | Epoch[046/600] Pixel Accuracy: 0.9807929992675781
2023-02-06 13:56:54 | Valid | Epoch[046/600] Mean Pixel Accuracy: 0.9716072668752116
2023-02-06 13:56:54 | Stage | Epoch[046/600] Train loss:0.1320
2023-02-06 13:56:54 | Stage | Epoch[046/600] Valid loss:0.2087
2023-02-06 13:56:54 | Stage | Epoch[046/600] LR:0.01

2023-02-06 13:56:54 | Train | Epoch[047/600] Iteration[001/030] Train loss: 0.1280
2023-02-06 13:56:55 | Train | Epoch[047/600] Iteration[002/030] Train loss: 0.1282
2023-02-06 13:56:55 | Train | Epoch[047/600] Iteration[003/030] Train loss: 0.1286
2023-02-06 13:56:55 | Train | Epoch[047/600] Iteration[004/030] Train loss: 0.1290
2023-02-06 13:56:55 | Train | Epoch[047/600] Iteration[005/030] Train loss: 0.1289
2023-02-06 13:56:55 | Train | Epoch[047/600] Iteration[006/030] Train loss: 0.1289
2023-02-06 13:56:56 | Train | Epoch[047/600] Iteration[007/030] Train loss: 0.1292
2023-02-06 13:56:56 | Train | Epoch[047/600] Iteration[008/030] Train loss: 0.1289
2023-02-06 13:56:56 | Train | Epoch[047/600] Iteration[009/030] Train loss: 0.1293
2023-02-06 13:56:56 | Train | Epoch[047/600] Iteration[010/030] Train loss: 0.1292
2023-02-06 13:56:57 | Train | Epoch[047/600] Iteration[011/030] Train loss: 0.1293
2023-02-06 13:56:57 | Train | Epoch[047/600] Iteration[012/030] Train loss: 0.1292
2023-02-06 13:56:57 | Train | Epoch[047/600] Iteration[013/030] Train loss: 0.1293
2023-02-06 13:56:57 | Train | Epoch[047/600] Iteration[014/030] Train loss: 0.1295
2023-02-06 13:56:57 | Train | Epoch[047/600] Iteration[015/030] Train loss: 0.1294
2023-02-06 13:56:58 | Train | Epoch[047/600] Iteration[016/030] Train loss: 0.1292
2023-02-06 13:56:58 | Train | Epoch[047/600] Iteration[017/030] Train loss: 0.1292
2023-02-06 13:56:58 | Train | Epoch[047/600] Iteration[018/030] Train loss: 0.1289
2023-02-06 13:56:58 | Train | Epoch[047/600] Iteration[019/030] Train loss: 0.1289
2023-02-06 13:56:59 | Train | Epoch[047/600] Iteration[020/030] Train loss: 0.1289
2023-02-06 13:56:59 | Train | Epoch[047/600] Iteration[021/030] Train loss: 0.1289
2023-02-06 13:56:59 | Train | Epoch[047/600] Iteration[022/030] Train loss: 0.1286
2023-02-06 13:56:59 | Train | Epoch[047/600] Iteration[023/030] Train loss: 0.1286
2023-02-06 13:56:59 | Train | Epoch[047/600] Iteration[024/030] Train loss: 0.1284
2023-02-06 13:57:00 | Train | Epoch[047/600] Iteration[025/030] Train loss: 0.1283
2023-02-06 13:57:00 | Train | Epoch[047/600] Iteration[026/030] Train loss: 0.1287
2023-02-06 13:57:00 | Train | Epoch[047/600] Iteration[027/030] Train loss: 0.1286
2023-02-06 13:57:00 | Train | Epoch[047/600] Iteration[028/030] Train loss: 0.1286
2023-02-06 13:57:01 | Train | Epoch[047/600] Iteration[029/030] Train loss: 0.1286
2023-02-06 13:57:01 | Train | Epoch[047/600] Iteration[030/030] Train loss: 0.1286
2023-02-06 13:57:01 | Valid | Epoch[047/600] Iteration[001/008] Valid loss: 0.8618
2023-02-06 13:57:01 | Valid | Epoch[047/600] Iteration[002/008] Valid loss: 0.8191
2023-02-06 13:57:01 | Valid | Epoch[047/600] Iteration[003/008] Valid loss: 0.8482
2023-02-06 13:57:01 | Valid | Epoch[047/600] Iteration[004/008] Valid loss: 0.8486
2023-02-06 13:57:01 | Valid | Epoch[047/600] Iteration[005/008] Valid loss: 0.8784
2023-02-06 13:57:01 | Valid | Epoch[047/600] Iteration[006/008] Valid loss: 0.8622
2023-02-06 13:57:01 | Valid | Epoch[047/600] Iteration[007/008] Valid loss: 0.9075
2023-02-06 13:57:01 | Valid | Epoch[047/600] Iteration[008/008] Valid loss: 0.9152
2023-02-06 13:57:01 | Valid | Epoch[047/600] MIou: 0.8145628856457208
2023-02-06 13:57:01 | Valid | Epoch[047/600] Pixel Accuracy: 0.9569218953450521
2023-02-06 13:57:01 | Valid | Epoch[047/600] Mean Pixel Accuracy: 0.9750923849715694
2023-02-06 13:57:01 | Stage | Epoch[047/600] Train loss:0.1286
2023-02-06 13:57:01 | Stage | Epoch[047/600] Valid loss:0.9152
2023-02-06 13:57:01 | Stage | Epoch[047/600] LR:0.01

2023-02-06 13:57:02 | Train | Epoch[048/600] Iteration[001/030] Train loss: 0.1261
2023-02-06 13:57:02 | Train | Epoch[048/600] Iteration[002/030] Train loss: 0.1280
2023-02-06 13:57:02 | Train | Epoch[048/600] Iteration[003/030] Train loss: 0.1274
2023-02-06 13:57:03 | Train | Epoch[048/600] Iteration[004/030] Train loss: 0.1272
2023-02-06 13:57:03 | Train | Epoch[048/600] Iteration[005/030] Train loss: 0.1270
2023-02-06 13:57:03 | Train | Epoch[048/600] Iteration[006/030] Train loss: 0.1267
2023-02-06 13:57:03 | Train | Epoch[048/600] Iteration[007/030] Train loss: 0.1268
2023-02-06 13:57:03 | Train | Epoch[048/600] Iteration[008/030] Train loss: 0.1264
2023-02-06 13:57:04 | Train | Epoch[048/600] Iteration[009/030] Train loss: 0.1262
2023-02-06 13:57:04 | Train | Epoch[048/600] Iteration[010/030] Train loss: 0.1264
2023-02-06 13:57:04 | Train | Epoch[048/600] Iteration[011/030] Train loss: 0.1262
2023-02-06 13:57:04 | Train | Epoch[048/600] Iteration[012/030] Train loss: 0.1260
2023-02-06 13:57:05 | Train | Epoch[048/600] Iteration[013/030] Train loss: 0.1262
2023-02-06 13:57:05 | Train | Epoch[048/600] Iteration[014/030] Train loss: 0.1259
2023-02-06 13:57:05 | Train | Epoch[048/600] Iteration[015/030] Train loss: 0.1259
2023-02-06 13:57:05 | Train | Epoch[048/600] Iteration[016/030] Train loss: 0.1262
2023-02-06 13:57:05 | Train | Epoch[048/600] Iteration[017/030] Train loss: 0.1262
2023-02-06 13:57:06 | Train | Epoch[048/600] Iteration[018/030] Train loss: 0.1261
2023-02-06 13:57:06 | Train | Epoch[048/600] Iteration[019/030] Train loss: 0.1260
2023-02-06 13:57:06 | Train | Epoch[048/600] Iteration[020/030] Train loss: 0.1259
2023-02-06 13:57:06 | Train | Epoch[048/600] Iteration[021/030] Train loss: 0.1257
2023-02-06 13:57:07 | Train | Epoch[048/600] Iteration[022/030] Train loss: 0.1258
2023-02-06 13:57:07 | Train | Epoch[048/600] Iteration[023/030] Train loss: 0.1256
2023-02-06 13:57:07 | Train | Epoch[048/600] Iteration[024/030] Train loss: 0.1255
2023-02-06 13:57:07 | Train | Epoch[048/600] Iteration[025/030] Train loss: 0.1255
2023-02-06 13:57:07 | Train | Epoch[048/600] Iteration[026/030] Train loss: 0.1255
2023-02-06 13:57:08 | Train | Epoch[048/600] Iteration[027/030] Train loss: 0.1254
2023-02-06 13:57:08 | Train | Epoch[048/600] Iteration[028/030] Train loss: 0.1253
2023-02-06 13:57:08 | Train | Epoch[048/600] Iteration[029/030] Train loss: 0.1252
2023-02-06 13:57:08 | Train | Epoch[048/600] Iteration[030/030] Train loss: 0.1252
2023-02-06 13:57:08 | Valid | Epoch[048/600] Iteration[001/008] Valid loss: 0.2556
2023-02-06 13:57:09 | Valid | Epoch[048/600] Iteration[002/008] Valid loss: 0.2446
2023-02-06 13:57:09 | Valid | Epoch[048/600] Iteration[003/008] Valid loss: 0.2480
2023-02-06 13:57:09 | Valid | Epoch[048/600] Iteration[004/008] Valid loss: 0.2490
2023-02-06 13:57:09 | Valid | Epoch[048/600] Iteration[005/008] Valid loss: 0.2507
2023-02-06 13:57:09 | Valid | Epoch[048/600] Iteration[006/008] Valid loss: 0.2512
2023-02-06 13:57:09 | Valid | Epoch[048/600] Iteration[007/008] Valid loss: 0.2542
2023-02-06 13:57:09 | Valid | Epoch[048/600] Iteration[008/008] Valid loss: 0.2524
2023-02-06 13:57:09 | Valid | Epoch[048/600] MIou: 0.8878425260094872
2023-02-06 13:57:09 | Valid | Epoch[048/600] Pixel Accuracy: 0.9784876505533854
2023-02-06 13:57:09 | Valid | Epoch[048/600] Mean Pixel Accuracy: 0.9647858958565647
2023-02-06 13:57:09 | Stage | Epoch[048/600] Train loss:0.1252
2023-02-06 13:57:09 | Stage | Epoch[048/600] Valid loss:0.2524
2023-02-06 13:57:09 | Stage | Epoch[048/600] LR:0.01

2023-02-06 13:57:09 | Train | Epoch[049/600] Iteration[001/030] Train loss: 0.1211
2023-02-06 13:57:10 | Train | Epoch[049/600] Iteration[002/030] Train loss: 0.1218
2023-02-06 13:57:10 | Train | Epoch[049/600] Iteration[003/030] Train loss: 0.1208
2023-02-06 13:57:10 | Train | Epoch[049/600] Iteration[004/030] Train loss: 0.1210
2023-02-06 13:57:10 | Train | Epoch[049/600] Iteration[005/030] Train loss: 0.1214
2023-02-06 13:57:10 | Train | Epoch[049/600] Iteration[006/030] Train loss: 0.1217
2023-02-06 13:57:11 | Train | Epoch[049/600] Iteration[007/030] Train loss: 0.1215
2023-02-06 13:57:11 | Train | Epoch[049/600] Iteration[008/030] Train loss: 0.1217
2023-02-06 13:57:11 | Train | Epoch[049/600] Iteration[009/030] Train loss: 0.1216
2023-02-06 13:57:11 | Train | Epoch[049/600] Iteration[010/030] Train loss: 0.1216
2023-02-06 13:57:12 | Train | Epoch[049/600] Iteration[011/030] Train loss: 0.1216
2023-02-06 13:57:12 | Train | Epoch[049/600] Iteration[012/030] Train loss: 0.1215
2023-02-06 13:57:12 | Train | Epoch[049/600] Iteration[013/030] Train loss: 0.1215
2023-02-06 13:57:12 | Train | Epoch[049/600] Iteration[014/030] Train loss: 0.1218
2023-02-06 13:57:12 | Train | Epoch[049/600] Iteration[015/030] Train loss: 0.1218
2023-02-06 13:57:13 | Train | Epoch[049/600] Iteration[016/030] Train loss: 0.1220
2023-02-06 13:57:13 | Train | Epoch[049/600] Iteration[017/030] Train loss: 0.1221
2023-02-06 13:57:13 | Train | Epoch[049/600] Iteration[018/030] Train loss: 0.1223
2023-02-06 13:57:13 | Train | Epoch[049/600] Iteration[019/030] Train loss: 0.1224
2023-02-06 13:57:13 | Train | Epoch[049/600] Iteration[020/030] Train loss: 0.1223
2023-02-06 13:57:14 | Train | Epoch[049/600] Iteration[021/030] Train loss: 0.1224
2023-02-06 13:57:14 | Train | Epoch[049/600] Iteration[022/030] Train loss: 0.1224
2023-02-06 13:57:14 | Train | Epoch[049/600] Iteration[023/030] Train loss: 0.1227
2023-02-06 13:57:14 | Train | Epoch[049/600] Iteration[024/030] Train loss: 0.1226
2023-02-06 13:57:15 | Train | Epoch[049/600] Iteration[025/030] Train loss: 0.1226
2023-02-06 13:57:15 | Train | Epoch[049/600] Iteration[026/030] Train loss: 0.1225
2023-02-06 13:57:15 | Train | Epoch[049/600] Iteration[027/030] Train loss: 0.1224
2023-02-06 13:57:15 | Train | Epoch[049/600] Iteration[028/030] Train loss: 0.1225
2023-02-06 13:57:15 | Train | Epoch[049/600] Iteration[029/030] Train loss: 0.1224
2023-02-06 13:57:16 | Train | Epoch[049/600] Iteration[030/030] Train loss: 0.1222
2023-02-06 13:57:16 | Valid | Epoch[049/600] Iteration[001/008] Valid loss: 0.1760
2023-02-06 13:57:16 | Valid | Epoch[049/600] Iteration[002/008] Valid loss: 0.1781
2023-02-06 13:57:16 | Valid | Epoch[049/600] Iteration[003/008] Valid loss: 0.1807
2023-02-06 13:57:16 | Valid | Epoch[049/600] Iteration[004/008] Valid loss: 0.1808
2023-02-06 13:57:16 | Valid | Epoch[049/600] Iteration[005/008] Valid loss: 0.1827
2023-02-06 13:57:16 | Valid | Epoch[049/600] Iteration[006/008] Valid loss: 0.1827
2023-02-06 13:57:16 | Valid | Epoch[049/600] Iteration[007/008] Valid loss: 0.1815
2023-02-06 13:57:16 | Valid | Epoch[049/600] Iteration[008/008] Valid loss: 0.1837
2023-02-06 13:57:16 | Valid | Epoch[049/600] MIou: 0.5908259574104986
2023-02-06 13:57:16 | Valid | Epoch[049/600] Pixel Accuracy: 0.9323209126790365
2023-02-06 13:57:16 | Valid | Epoch[049/600] Mean Pixel Accuracy: 0.6254749217794665
2023-02-06 13:57:16 | Stage | Epoch[049/600] Train loss:0.1222
2023-02-06 13:57:16 | Stage | Epoch[049/600] Valid loss:0.1837
2023-02-06 13:57:16 | Stage | Epoch[049/600] LR:0.01

2023-02-06 13:57:17 | Train | Epoch[050/600] Iteration[001/030] Train loss: 0.1236
2023-02-06 13:57:17 | Train | Epoch[050/600] Iteration[002/030] Train loss: 0.1227
2023-02-06 13:57:17 | Train | Epoch[050/600] Iteration[003/030] Train loss: 0.1208
2023-02-06 13:57:17 | Train | Epoch[050/600] Iteration[004/030] Train loss: 0.1206
2023-02-06 13:57:18 | Train | Epoch[050/600] Iteration[005/030] Train loss: 0.1202
2023-02-06 13:57:18 | Train | Epoch[050/600] Iteration[006/030] Train loss: 0.1200
2023-02-06 13:57:18 | Train | Epoch[050/600] Iteration[007/030] Train loss: 0.1200
2023-02-06 13:57:18 | Train | Epoch[050/600] Iteration[008/030] Train loss: 0.1206
2023-02-06 13:57:19 | Train | Epoch[050/600] Iteration[009/030] Train loss: 0.1207
2023-02-06 13:57:19 | Train | Epoch[050/600] Iteration[010/030] Train loss: 0.1205
2023-02-06 13:57:19 | Train | Epoch[050/600] Iteration[011/030] Train loss: 0.1205
2023-02-06 13:57:19 | Train | Epoch[050/600] Iteration[012/030] Train loss: 0.1203
2023-02-06 13:57:19 | Train | Epoch[050/600] Iteration[013/030] Train loss: 0.1203
2023-02-06 13:57:20 | Train | Epoch[050/600] Iteration[014/030] Train loss: 0.1201
2023-02-06 13:57:20 | Train | Epoch[050/600] Iteration[015/030] Train loss: 0.1202
2023-02-06 13:57:20 | Train | Epoch[050/600] Iteration[016/030] Train loss: 0.1200
2023-02-06 13:57:20 | Train | Epoch[050/600] Iteration[017/030] Train loss: 0.1199
2023-02-06 13:57:21 | Train | Epoch[050/600] Iteration[018/030] Train loss: 0.1197
2023-02-06 13:57:21 | Train | Epoch[050/600] Iteration[019/030] Train loss: 0.1196
2023-02-06 13:57:21 | Train | Epoch[050/600] Iteration[020/030] Train loss: 0.1194
2023-02-06 13:57:21 | Train | Epoch[050/600] Iteration[021/030] Train loss: 0.1192
2023-02-06 13:57:21 | Train | Epoch[050/600] Iteration[022/030] Train loss: 0.1192
2023-02-06 13:57:22 | Train | Epoch[050/600] Iteration[023/030] Train loss: 0.1191
2023-02-06 13:57:22 | Train | Epoch[050/600] Iteration[024/030] Train loss: 0.1193
2023-02-06 13:57:22 | Train | Epoch[050/600] Iteration[025/030] Train loss: 0.1191
2023-02-06 13:57:22 | Train | Epoch[050/600] Iteration[026/030] Train loss: 0.1191
2023-02-06 13:57:23 | Train | Epoch[050/600] Iteration[027/030] Train loss: 0.1190
2023-02-06 13:57:23 | Train | Epoch[050/600] Iteration[028/030] Train loss: 0.1190
2023-02-06 13:57:23 | Train | Epoch[050/600] Iteration[029/030] Train loss: 0.1189
2023-02-06 13:57:23 | Train | Epoch[050/600] Iteration[030/030] Train loss: 0.1189
2023-02-06 13:57:23 | Valid | Epoch[050/600] Iteration[001/008] Valid loss: 0.1542
2023-02-06 13:57:23 | Valid | Epoch[050/600] Iteration[002/008] Valid loss: 0.1530
2023-02-06 13:57:24 | Valid | Epoch[050/600] Iteration[003/008] Valid loss: 0.1559
2023-02-06 13:57:24 | Valid | Epoch[050/600] Iteration[004/008] Valid loss: 0.1560
2023-02-06 13:57:24 | Valid | Epoch[050/600] Iteration[005/008] Valid loss: 0.1568
2023-02-06 13:57:24 | Valid | Epoch[050/600] Iteration[006/008] Valid loss: 0.1558
2023-02-06 13:57:24 | Valid | Epoch[050/600] Iteration[007/008] Valid loss: 0.1542
2023-02-06 13:57:24 | Valid | Epoch[050/600] Iteration[008/008] Valid loss: 0.1550
2023-02-06 13:57:24 | Valid | Epoch[050/600] MIou: 0.7598101071997267
2023-02-06 13:57:24 | Valid | Epoch[050/600] Pixel Accuracy: 0.960381825764974
2023-02-06 13:57:24 | Valid | Epoch[050/600] Mean Pixel Accuracy: 0.7806804313358069
2023-02-06 13:57:24 | Stage | Epoch[050/600] Train loss:0.1189
2023-02-06 13:57:24 | Stage | Epoch[050/600] Valid loss:0.1550
2023-02-06 13:57:24 | Stage | Epoch[050/600] LR:0.01

2023-02-06 13:57:24 | Train | Epoch[051/600] Iteration[001/030] Train loss: 0.1167
2023-02-06 13:57:25 | Train | Epoch[051/600] Iteration[002/030] Train loss: 0.1156
2023-02-06 13:57:25 | Train | Epoch[051/600] Iteration[003/030] Train loss: 0.1160
2023-02-06 13:57:25 | Train | Epoch[051/600] Iteration[004/030] Train loss: 0.1161
2023-02-06 13:57:25 | Train | Epoch[051/600] Iteration[005/030] Train loss: 0.1166
2023-02-06 13:57:25 | Train | Epoch[051/600] Iteration[006/030] Train loss: 0.1165
2023-02-06 13:57:26 | Train | Epoch[051/600] Iteration[007/030] Train loss: 0.1164
2023-02-06 13:57:26 | Train | Epoch[051/600] Iteration[008/030] Train loss: 0.1162
2023-02-06 13:57:26 | Train | Epoch[051/600] Iteration[009/030] Train loss: 0.1160
2023-02-06 13:57:26 | Train | Epoch[051/600] Iteration[010/030] Train loss: 0.1160
2023-02-06 13:57:27 | Train | Epoch[051/600] Iteration[011/030] Train loss: 0.1159
2023-02-06 13:57:27 | Train | Epoch[051/600] Iteration[012/030] Train loss: 0.1160
2023-02-06 13:57:27 | Train | Epoch[051/600] Iteration[013/030] Train loss: 0.1158
2023-02-06 13:57:27 | Train | Epoch[051/600] Iteration[014/030] Train loss: 0.1158
2023-02-06 13:57:27 | Train | Epoch[051/600] Iteration[015/030] Train loss: 0.1158
2023-02-06 13:57:28 | Train | Epoch[051/600] Iteration[016/030] Train loss: 0.1157
2023-02-06 13:57:28 | Train | Epoch[051/600] Iteration[017/030] Train loss: 0.1158
2023-02-06 13:57:28 | Train | Epoch[051/600] Iteration[018/030] Train loss: 0.1157
2023-02-06 13:57:28 | Train | Epoch[051/600] Iteration[019/030] Train loss: 0.1156
2023-02-06 13:57:28 | Train | Epoch[051/600] Iteration[020/030] Train loss: 0.1156
2023-02-06 13:57:29 | Train | Epoch[051/600] Iteration[021/030] Train loss: 0.1155
2023-02-06 13:57:29 | Train | Epoch[051/600] Iteration[022/030] Train loss: 0.1156
2023-02-06 13:57:29 | Train | Epoch[051/600] Iteration[023/030] Train loss: 0.1155
2023-02-06 13:57:29 | Train | Epoch[051/600] Iteration[024/030] Train loss: 0.1155
2023-02-06 13:57:30 | Train | Epoch[051/600] Iteration[025/030] Train loss: 0.1154
2023-02-06 13:57:30 | Train | Epoch[051/600] Iteration[026/030] Train loss: 0.1154
2023-02-06 13:57:30 | Train | Epoch[051/600] Iteration[027/030] Train loss: 0.1156
2023-02-06 13:57:30 | Train | Epoch[051/600] Iteration[028/030] Train loss: 0.1156
2023-02-06 13:57:30 | Train | Epoch[051/600] Iteration[029/030] Train loss: 0.1155
2023-02-06 13:57:31 | Train | Epoch[051/600] Iteration[030/030] Train loss: 0.1154
2023-02-06 13:57:31 | Valid | Epoch[051/600] Iteration[001/008] Valid loss: 0.9540
2023-02-06 13:57:31 | Valid | Epoch[051/600] Iteration[002/008] Valid loss: 0.8666
2023-02-06 13:57:31 | Valid | Epoch[051/600] Iteration[003/008] Valid loss: 0.9025
2023-02-06 13:57:31 | Valid | Epoch[051/600] Iteration[004/008] Valid loss: 0.9065
2023-02-06 13:57:31 | Valid | Epoch[051/600] Iteration[005/008] Valid loss: 0.9350
2023-02-06 13:57:31 | Valid | Epoch[051/600] Iteration[006/008] Valid loss: 0.9267
2023-02-06 13:57:31 | Valid | Epoch[051/600] Iteration[007/008] Valid loss: 0.9706
2023-02-06 13:57:31 | Valid | Epoch[051/600] Iteration[008/008] Valid loss: 0.9855
2023-02-06 13:57:31 | Valid | Epoch[051/600] MIou: 0.8224846611767703
2023-02-06 13:57:31 | Valid | Epoch[051/600] Pixel Accuracy: 0.9594535827636719
2023-02-06 13:57:31 | Valid | Epoch[051/600] Mean Pixel Accuracy: 0.9763761203349943
2023-02-06 13:57:31 | Stage | Epoch[051/600] Train loss:0.1154
2023-02-06 13:57:31 | Stage | Epoch[051/600] Valid loss:0.9855
2023-02-06 13:57:31 | Stage | Epoch[051/600] LR:0.01

2023-02-06 13:57:32 | Train | Epoch[052/600] Iteration[001/030] Train loss: 0.1158
2023-02-06 13:57:32 | Train | Epoch[052/600] Iteration[002/030] Train loss: 0.1141
2023-02-06 13:57:32 | Train | Epoch[052/600] Iteration[003/030] Train loss: 0.1133
2023-02-06 13:57:33 | Train | Epoch[052/600] Iteration[004/030] Train loss: 0.1128
2023-02-06 13:57:33 | Train | Epoch[052/600] Iteration[005/030] Train loss: 0.1130
2023-02-06 13:57:33 | Train | Epoch[052/600] Iteration[006/030] Train loss: 0.1129
2023-02-06 13:57:33 | Train | Epoch[052/600] Iteration[007/030] Train loss: 0.1129
2023-02-06 13:57:33 | Train | Epoch[052/600] Iteration[008/030] Train loss: 0.1129
2023-02-06 13:57:34 | Train | Epoch[052/600] Iteration[009/030] Train loss: 0.1127
2023-02-06 13:57:34 | Train | Epoch[052/600] Iteration[010/030] Train loss: 0.1131
2023-02-06 13:57:34 | Train | Epoch[052/600] Iteration[011/030] Train loss: 0.1129
2023-02-06 13:57:34 | Train | Epoch[052/600] Iteration[012/030] Train loss: 0.1129
2023-02-06 13:57:34 | Train | Epoch[052/600] Iteration[013/030] Train loss: 0.1132
2023-02-06 13:57:35 | Train | Epoch[052/600] Iteration[014/030] Train loss: 0.1132
2023-02-06 13:57:35 | Train | Epoch[052/600] Iteration[015/030] Train loss: 0.1131
2023-02-06 13:57:35 | Train | Epoch[052/600] Iteration[016/030] Train loss: 0.1130
2023-02-06 13:57:35 | Train | Epoch[052/600] Iteration[017/030] Train loss: 0.1130
2023-02-06 13:57:36 | Train | Epoch[052/600] Iteration[018/030] Train loss: 0.1130
2023-02-06 13:57:36 | Train | Epoch[052/600] Iteration[019/030] Train loss: 0.1131
2023-02-06 13:57:36 | Train | Epoch[052/600] Iteration[020/030] Train loss: 0.1131
2023-02-06 13:57:36 | Train | Epoch[052/600] Iteration[021/030] Train loss: 0.1130
2023-02-06 13:57:36 | Train | Epoch[052/600] Iteration[022/030] Train loss: 0.1129
2023-02-06 13:57:37 | Train | Epoch[052/600] Iteration[023/030] Train loss: 0.1132
2023-02-06 13:57:37 | Train | Epoch[052/600] Iteration[024/030] Train loss: 0.1131
2023-02-06 13:57:37 | Train | Epoch[052/600] Iteration[025/030] Train loss: 0.1130
2023-02-06 13:57:37 | Train | Epoch[052/600] Iteration[026/030] Train loss: 0.1128
2023-02-06 13:57:38 | Train | Epoch[052/600] Iteration[027/030] Train loss: 0.1129
2023-02-06 13:57:38 | Train | Epoch[052/600] Iteration[028/030] Train loss: 0.1128
2023-02-06 13:57:38 | Train | Epoch[052/600] Iteration[029/030] Train loss: 0.1128
2023-02-06 13:57:38 | Train | Epoch[052/600] Iteration[030/030] Train loss: 0.1127
2023-02-06 13:57:38 | Valid | Epoch[052/600] Iteration[001/008] Valid loss: 0.5941
2023-02-06 13:57:39 | Valid | Epoch[052/600] Iteration[002/008] Valid loss: 0.5214
2023-02-06 13:57:39 | Valid | Epoch[052/600] Iteration[003/008] Valid loss: 0.5192
2023-02-06 13:57:39 | Valid | Epoch[052/600] Iteration[004/008] Valid loss: 0.5176
2023-02-06 13:57:39 | Valid | Epoch[052/600] Iteration[005/008] Valid loss: 0.5423
2023-02-06 13:57:39 | Valid | Epoch[052/600] Iteration[006/008] Valid loss: 0.5307
2023-02-06 13:57:39 | Valid | Epoch[052/600] Iteration[007/008] Valid loss: 0.5656
2023-02-06 13:57:39 | Valid | Epoch[052/600] Iteration[008/008] Valid loss: 0.5702
2023-02-06 13:57:39 | Valid | Epoch[052/600] MIou: 0.8569940092623944
2023-02-06 13:57:39 | Valid | Epoch[052/600] Pixel Accuracy: 0.9696795145670573
2023-02-06 13:57:39 | Valid | Epoch[052/600] Mean Pixel Accuracy: 0.9800692252399059
2023-02-06 13:57:39 | Stage | Epoch[052/600] Train loss:0.1127
2023-02-06 13:57:39 | Stage | Epoch[052/600] Valid loss:0.5702
2023-02-06 13:57:39 | Stage | Epoch[052/600] LR:0.01

2023-02-06 13:57:39 | Train | Epoch[053/600] Iteration[001/030] Train loss: 0.1098
2023-02-06 13:57:40 | Train | Epoch[053/600] Iteration[002/030] Train loss: 0.1092
2023-02-06 13:57:40 | Train | Epoch[053/600] Iteration[003/030] Train loss: 0.1089
2023-02-06 13:57:40 | Train | Epoch[053/600] Iteration[004/030] Train loss: 0.1090
2023-02-06 13:57:40 | Train | Epoch[053/600] Iteration[005/030] Train loss: 0.1097
2023-02-06 13:57:40 | Train | Epoch[053/600] Iteration[006/030] Train loss: 0.1101
2023-02-06 13:57:41 | Train | Epoch[053/600] Iteration[007/030] Train loss: 0.1109
2023-02-06 13:57:41 | Train | Epoch[053/600] Iteration[008/030] Train loss: 0.1107
2023-02-06 13:57:41 | Train | Epoch[053/600] Iteration[009/030] Train loss: 0.1108
2023-02-06 13:57:41 | Train | Epoch[053/600] Iteration[010/030] Train loss: 0.1108
2023-02-06 13:57:42 | Train | Epoch[053/600] Iteration[011/030] Train loss: 0.1108
2023-02-06 13:57:42 | Train | Epoch[053/600] Iteration[012/030] Train loss: 0.1108
2023-02-06 13:57:42 | Train | Epoch[053/600] Iteration[013/030] Train loss: 0.1111
2023-02-06 13:57:42 | Train | Epoch[053/600] Iteration[014/030] Train loss: 0.1110
2023-02-06 13:57:42 | Train | Epoch[053/600] Iteration[015/030] Train loss: 0.1112
2023-02-06 13:57:43 | Train | Epoch[053/600] Iteration[016/030] Train loss: 0.1111
2023-02-06 13:57:43 | Train | Epoch[053/600] Iteration[017/030] Train loss: 0.1110
2023-02-06 13:57:43 | Train | Epoch[053/600] Iteration[018/030] Train loss: 0.1109
2023-02-06 13:57:43 | Train | Epoch[053/600] Iteration[019/030] Train loss: 0.1108
2023-02-06 13:57:44 | Train | Epoch[053/600] Iteration[020/030] Train loss: 0.1107
2023-02-06 13:57:44 | Train | Epoch[053/600] Iteration[021/030] Train loss: 0.1106
2023-02-06 13:57:44 | Train | Epoch[053/600] Iteration[022/030] Train loss: 0.1105
2023-02-06 13:57:44 | Train | Epoch[053/600] Iteration[023/030] Train loss: 0.1104
2023-02-06 13:57:44 | Train | Epoch[053/600] Iteration[024/030] Train loss: 0.1103
2023-02-06 13:57:45 | Train | Epoch[053/600] Iteration[025/030] Train loss: 0.1103
2023-02-06 13:57:45 | Train | Epoch[053/600] Iteration[026/030] Train loss: 0.1102
2023-02-06 13:57:45 | Train | Epoch[053/600] Iteration[027/030] Train loss: 0.1101
2023-02-06 13:57:45 | Train | Epoch[053/600] Iteration[028/030] Train loss: 0.1100
2023-02-06 13:57:46 | Train | Epoch[053/600] Iteration[029/030] Train loss: 0.1099
2023-02-06 13:57:46 | Train | Epoch[053/600] Iteration[030/030] Train loss: 0.1099
2023-02-06 13:57:46 | Valid | Epoch[053/600] Iteration[001/008] Valid loss: 0.5061
2023-02-06 13:57:46 | Valid | Epoch[053/600] Iteration[002/008] Valid loss: 0.4777
2023-02-06 13:57:46 | Valid | Epoch[053/600] Iteration[003/008] Valid loss: 0.4690
2023-02-06 13:57:46 | Valid | Epoch[053/600] Iteration[004/008] Valid loss: 0.4657
2023-02-06 13:57:46 | Valid | Epoch[053/600] Iteration[005/008] Valid loss: 0.4700
2023-02-06 13:57:46 | Valid | Epoch[053/600] Iteration[006/008] Valid loss: 0.4644
2023-02-06 13:57:46 | Valid | Epoch[053/600] Iteration[007/008] Valid loss: 0.4893
2023-02-06 13:57:46 | Valid | Epoch[053/600] Iteration[008/008] Valid loss: 0.4889
2023-02-06 13:57:46 | Valid | Epoch[053/600] MIou: 0.8527147792649037
2023-02-06 13:57:46 | Valid | Epoch[053/600] Pixel Accuracy: 0.9684295654296875
2023-02-06 13:57:46 | Valid | Epoch[053/600] Mean Pixel Accuracy: 0.9806122513583095
2023-02-06 13:57:46 | Stage | Epoch[053/600] Train loss:0.1099
2023-02-06 13:57:46 | Stage | Epoch[053/600] Valid loss:0.4889
2023-02-06 13:57:46 | Stage | Epoch[053/600] LR:0.01

2023-02-06 13:57:47 | Train | Epoch[054/600] Iteration[001/030] Train loss: 0.1115
2023-02-06 13:57:47 | Train | Epoch[054/600] Iteration[002/030] Train loss: 0.1093
2023-02-06 13:57:47 | Train | Epoch[054/600] Iteration[003/030] Train loss: 0.1084
2023-02-06 13:57:48 | Train | Epoch[054/600] Iteration[004/030] Train loss: 0.1081
2023-02-06 13:57:48 | Train | Epoch[054/600] Iteration[005/030] Train loss: 0.1081
2023-02-06 13:57:48 | Train | Epoch[054/600] Iteration[006/030] Train loss: 0.1077
2023-02-06 13:57:48 | Train | Epoch[054/600] Iteration[007/030] Train loss: 0.1073
2023-02-06 13:57:48 | Train | Epoch[054/600] Iteration[008/030] Train loss: 0.1072
2023-02-06 13:57:49 | Train | Epoch[054/600] Iteration[009/030] Train loss: 0.1075
2023-02-06 13:57:49 | Train | Epoch[054/600] Iteration[010/030] Train loss: 0.1077
2023-02-06 13:57:49 | Train | Epoch[054/600] Iteration[011/030] Train loss: 0.1076
2023-02-06 13:57:49 | Train | Epoch[054/600] Iteration[012/030] Train loss: 0.1076
2023-02-06 13:57:50 | Train | Epoch[054/600] Iteration[013/030] Train loss: 0.1075
2023-02-06 13:57:50 | Train | Epoch[054/600] Iteration[014/030] Train loss: 0.1074
2023-02-06 13:57:50 | Train | Epoch[054/600] Iteration[015/030] Train loss: 0.1074
2023-02-06 13:57:50 | Train | Epoch[054/600] Iteration[016/030] Train loss: 0.1073
2023-02-06 13:57:50 | Train | Epoch[054/600] Iteration[017/030] Train loss: 0.1071
2023-02-06 13:57:51 | Train | Epoch[054/600] Iteration[018/030] Train loss: 0.1072
2023-02-06 13:57:51 | Train | Epoch[054/600] Iteration[019/030] Train loss: 0.1073
2023-02-06 13:57:51 | Train | Epoch[054/600] Iteration[020/030] Train loss: 0.1072
2023-02-06 13:57:51 | Train | Epoch[054/600] Iteration[021/030] Train loss: 0.1071
2023-02-06 13:57:52 | Train | Epoch[054/600] Iteration[022/030] Train loss: 0.1072
2023-02-06 13:57:52 | Train | Epoch[054/600] Iteration[023/030] Train loss: 0.1071
2023-02-06 13:57:52 | Train | Epoch[054/600] Iteration[024/030] Train loss: 0.1070
2023-02-06 13:57:52 | Train | Epoch[054/600] Iteration[025/030] Train loss: 0.1070
2023-02-06 13:57:52 | Train | Epoch[054/600] Iteration[026/030] Train loss: 0.1070
2023-02-06 13:57:53 | Train | Epoch[054/600] Iteration[027/030] Train loss: 0.1070
2023-02-06 13:57:53 | Train | Epoch[054/600] Iteration[028/030] Train loss: 0.1069
2023-02-06 13:57:53 | Train | Epoch[054/600] Iteration[029/030] Train loss: 0.1069
2023-02-06 13:57:53 | Train | Epoch[054/600] Iteration[030/030] Train loss: 0.1070
2023-02-06 13:57:53 | Valid | Epoch[054/600] Iteration[001/008] Valid loss: 0.1560
2023-02-06 13:57:54 | Valid | Epoch[054/600] Iteration[002/008] Valid loss: 0.1483
2023-02-06 13:57:54 | Valid | Epoch[054/600] Iteration[003/008] Valid loss: 0.1502
2023-02-06 13:57:54 | Valid | Epoch[054/600] Iteration[004/008] Valid loss: 0.1502
2023-02-06 13:57:54 | Valid | Epoch[054/600] Iteration[005/008] Valid loss: 0.1513
2023-02-06 13:57:54 | Valid | Epoch[054/600] Iteration[006/008] Valid loss: 0.1526
2023-02-06 13:57:54 | Valid | Epoch[054/600] Iteration[007/008] Valid loss: 0.1581
2023-02-06 13:57:54 | Valid | Epoch[054/600] Iteration[008/008] Valid loss: 0.1569
2023-02-06 13:57:54 | Valid | Epoch[054/600] MIou: 0.9169863725225469
2023-02-06 13:57:54 | Valid | Epoch[054/600] Pixel Accuracy: 0.9853477478027344
2023-02-06 13:57:54 | Valid | Epoch[054/600] Mean Pixel Accuracy: 0.9554444027938972
2023-02-06 13:57:54 | Stage | Epoch[054/600] Train loss:0.1070
2023-02-06 13:57:54 | Stage | Epoch[054/600] Valid loss:0.1569
2023-02-06 13:57:54 | Stage | Epoch[054/600] LR:0.01

2023-02-06 13:57:54 | Train | Epoch[055/600] Iteration[001/030] Train loss: 0.1052
2023-02-06 13:57:55 | Train | Epoch[055/600] Iteration[002/030] Train loss: 0.1051
2023-02-06 13:57:55 | Train | Epoch[055/600] Iteration[003/030] Train loss: 0.1053
2023-02-06 13:57:55 | Train | Epoch[055/600] Iteration[004/030] Train loss: 0.1052
2023-02-06 13:57:55 | Train | Epoch[055/600] Iteration[005/030] Train loss: 0.1049
2023-02-06 13:57:56 | Train | Epoch[055/600] Iteration[006/030] Train loss: 0.1047
2023-02-06 13:57:56 | Train | Epoch[055/600] Iteration[007/030] Train loss: 0.1045
2023-02-06 13:57:56 | Train | Epoch[055/600] Iteration[008/030] Train loss: 0.1043
2023-02-06 13:57:56 | Train | Epoch[055/600] Iteration[009/030] Train loss: 0.1040
2023-02-06 13:57:56 | Train | Epoch[055/600] Iteration[010/030] Train loss: 0.1043
2023-02-06 13:57:57 | Train | Epoch[055/600] Iteration[011/030] Train loss: 0.1046
2023-02-06 13:57:57 | Train | Epoch[055/600] Iteration[012/030] Train loss: 0.1047
2023-02-06 13:57:57 | Train | Epoch[055/600] Iteration[013/030] Train loss: 0.1046
2023-02-06 13:57:57 | Train | Epoch[055/600] Iteration[014/030] Train loss: 0.1047
2023-02-06 13:57:58 | Train | Epoch[055/600] Iteration[015/030] Train loss: 0.1045
2023-02-06 13:57:58 | Train | Epoch[055/600] Iteration[016/030] Train loss: 0.1046
2023-02-06 13:57:58 | Train | Epoch[055/600] Iteration[017/030] Train loss: 0.1046
2023-02-06 13:57:58 | Train | Epoch[055/600] Iteration[018/030] Train loss: 0.1046
2023-02-06 13:57:58 | Train | Epoch[055/600] Iteration[019/030] Train loss: 0.1048
2023-02-06 13:57:59 | Train | Epoch[055/600] Iteration[020/030] Train loss: 0.1048
2023-02-06 13:57:59 | Train | Epoch[055/600] Iteration[021/030] Train loss: 0.1048
2023-02-06 13:57:59 | Train | Epoch[055/600] Iteration[022/030] Train loss: 0.1048
2023-02-06 13:57:59 | Train | Epoch[055/600] Iteration[023/030] Train loss: 0.1047
2023-02-06 13:57:59 | Train | Epoch[055/600] Iteration[024/030] Train loss: 0.1047
2023-02-06 13:58:00 | Train | Epoch[055/600] Iteration[025/030] Train loss: 0.1046
2023-02-06 13:58:00 | Train | Epoch[055/600] Iteration[026/030] Train loss: 0.1046
2023-02-06 13:58:00 | Train | Epoch[055/600] Iteration[027/030] Train loss: 0.1045
2023-02-06 13:58:00 | Train | Epoch[055/600] Iteration[028/030] Train loss: 0.1048
2023-02-06 13:58:01 | Train | Epoch[055/600] Iteration[029/030] Train loss: 0.1048
2023-02-06 13:58:01 | Train | Epoch[055/600] Iteration[030/030] Train loss: 0.1048
2023-02-06 13:58:01 | Valid | Epoch[055/600] Iteration[001/008] Valid loss: 1.7403
2023-02-06 13:58:01 | Valid | Epoch[055/600] Iteration[002/008] Valid loss: 1.7955
2023-02-06 13:58:01 | Valid | Epoch[055/600] Iteration[003/008] Valid loss: 1.8486
2023-02-06 13:58:01 | Valid | Epoch[055/600] Iteration[004/008] Valid loss: 1.8856
2023-02-06 13:58:01 | Valid | Epoch[055/600] Iteration[005/008] Valid loss: 1.8940
2023-02-06 13:58:01 | Valid | Epoch[055/600] Iteration[006/008] Valid loss: 1.8424
2023-02-06 13:58:01 | Valid | Epoch[055/600] Iteration[007/008] Valid loss: 1.8874
2023-02-06 13:58:01 | Valid | Epoch[055/600] Iteration[008/008] Valid loss: 1.9433
2023-02-06 13:58:02 | Valid | Epoch[055/600] MIou: 0.6815370059012094
2023-02-06 13:58:02 | Valid | Epoch[055/600] Pixel Accuracy: 0.8995844523111979
2023-02-06 13:58:02 | Valid | Epoch[055/600] Mean Pixel Accuracy: 0.9446741824689521
2023-02-06 13:58:02 | Stage | Epoch[055/600] Train loss:0.1048
2023-02-06 13:58:02 | Stage | Epoch[055/600] Valid loss:1.9433
2023-02-06 13:58:02 | Stage | Epoch[055/600] LR:0.01

2023-02-06 13:58:02 | Train | Epoch[056/600] Iteration[001/030] Train loss: 0.1035
2023-02-06 13:58:02 | Train | Epoch[056/600] Iteration[002/030] Train loss: 0.1035
2023-02-06 13:58:02 | Train | Epoch[056/600] Iteration[003/030] Train loss: 0.1040
2023-02-06 13:58:03 | Train | Epoch[056/600] Iteration[004/030] Train loss: 0.1039
2023-02-06 13:58:03 | Train | Epoch[056/600] Iteration[005/030] Train loss: 0.1037
2023-02-06 13:58:03 | Train | Epoch[056/600] Iteration[006/030] Train loss: 0.1035
2023-02-06 13:58:03 | Train | Epoch[056/600] Iteration[007/030] Train loss: 0.1033
2023-02-06 13:58:04 | Train | Epoch[056/600] Iteration[008/030] Train loss: 0.1032
2023-02-06 13:58:04 | Train | Epoch[056/600] Iteration[009/030] Train loss: 0.1038
2023-02-06 13:58:04 | Train | Epoch[056/600] Iteration[010/030] Train loss: 0.1035
2023-02-06 13:58:04 | Train | Epoch[056/600] Iteration[011/030] Train loss: 0.1033
2023-02-06 13:58:04 | Train | Epoch[056/600] Iteration[012/030] Train loss: 0.1030
2023-02-06 13:58:05 | Train | Epoch[056/600] Iteration[013/030] Train loss: 0.1030
2023-02-06 13:58:05 | Train | Epoch[056/600] Iteration[014/030] Train loss: 0.1032
2023-02-06 13:58:05 | Train | Epoch[056/600] Iteration[015/030] Train loss: 0.1031
2023-02-06 13:58:05 | Train | Epoch[056/600] Iteration[016/030] Train loss: 0.1030
2023-02-06 13:58:05 | Train | Epoch[056/600] Iteration[017/030] Train loss: 0.1032
2023-02-06 13:58:06 | Train | Epoch[056/600] Iteration[018/030] Train loss: 0.1030
2023-02-06 13:58:06 | Train | Epoch[056/600] Iteration[019/030] Train loss: 0.1030
2023-02-06 13:58:06 | Train | Epoch[056/600] Iteration[020/030] Train loss: 0.1028
2023-02-06 13:58:06 | Train | Epoch[056/600] Iteration[021/030] Train loss: 0.1029
2023-02-06 13:58:07 | Train | Epoch[056/600] Iteration[022/030] Train loss: 0.1030
2023-02-06 13:58:07 | Train | Epoch[056/600] Iteration[023/030] Train loss: 0.1029
2023-02-06 13:58:07 | Train | Epoch[056/600] Iteration[024/030] Train loss: 0.1029
2023-02-06 13:58:07 | Train | Epoch[056/600] Iteration[025/030] Train loss: 0.1028
2023-02-06 13:58:07 | Train | Epoch[056/600] Iteration[026/030] Train loss: 0.1028
2023-02-06 13:58:08 | Train | Epoch[056/600] Iteration[027/030] Train loss: 0.1027
2023-02-06 13:58:08 | Train | Epoch[056/600] Iteration[028/030] Train loss: 0.1029
2023-02-06 13:58:08 | Train | Epoch[056/600] Iteration[029/030] Train loss: 0.1028
2023-02-06 13:58:08 | Train | Epoch[056/600] Iteration[030/030] Train loss: 0.1028
2023-02-06 13:58:09 | Valid | Epoch[056/600] Iteration[001/008] Valid loss: 0.1410
2023-02-06 13:58:09 | Valid | Epoch[056/600] Iteration[002/008] Valid loss: 0.1358
2023-02-06 13:58:09 | Valid | Epoch[056/600] Iteration[003/008] Valid loss: 0.1357
2023-02-06 13:58:09 | Valid | Epoch[056/600] Iteration[004/008] Valid loss: 0.1346
2023-02-06 13:58:09 | Valid | Epoch[056/600] Iteration[005/008] Valid loss: 0.1370
2023-02-06 13:58:09 | Valid | Epoch[056/600] Iteration[006/008] Valid loss: 0.1358
2023-02-06 13:58:09 | Valid | Epoch[056/600] Iteration[007/008] Valid loss: 0.1391
2023-02-06 13:58:09 | Valid | Epoch[056/600] Iteration[008/008] Valid loss: 0.1396
2023-02-06 13:58:09 | Valid | Epoch[056/600] MIou: 0.9178621142954064
2023-02-06 13:58:09 | Valid | Epoch[056/600] Pixel Accuracy: 0.9852371215820312
2023-02-06 13:58:09 | Valid | Epoch[056/600] Mean Pixel Accuracy: 0.9648182195148793
2023-02-06 13:58:09 | Stage | Epoch[056/600] Train loss:0.1028
2023-02-06 13:58:09 | Stage | Epoch[056/600] Valid loss:0.1396
2023-02-06 13:58:09 | Stage | Epoch[056/600] LR:0.01

2023-02-06 13:58:10 | Train | Epoch[057/600] Iteration[001/030] Train loss: 0.1022
2023-02-06 13:58:10 | Train | Epoch[057/600] Iteration[002/030] Train loss: 0.1028
2023-02-06 13:58:10 | Train | Epoch[057/600] Iteration[003/030] Train loss: 0.1033
2023-02-06 13:58:10 | Train | Epoch[057/600] Iteration[004/030] Train loss: 0.1029
2023-02-06 13:58:10 | Train | Epoch[057/600] Iteration[005/030] Train loss: 0.1029
2023-02-06 13:58:11 | Train | Epoch[057/600] Iteration[006/030] Train loss: 0.1024
2023-02-06 13:58:11 | Train | Epoch[057/600] Iteration[007/030] Train loss: 0.1019
2023-02-06 13:58:11 | Train | Epoch[057/600] Iteration[008/030] Train loss: 0.1014
2023-02-06 13:58:11 | Train | Epoch[057/600] Iteration[009/030] Train loss: 0.1014
2023-02-06 13:58:11 | Train | Epoch[057/600] Iteration[010/030] Train loss: 0.1012
2023-02-06 13:58:12 | Train | Epoch[057/600] Iteration[011/030] Train loss: 0.1011
2023-02-06 13:58:12 | Train | Epoch[057/600] Iteration[012/030] Train loss: 0.1011
2023-02-06 13:58:12 | Train | Epoch[057/600] Iteration[013/030] Train loss: 0.1009
2023-02-06 13:58:12 | Train | Epoch[057/600] Iteration[014/030] Train loss: 0.1006
2023-02-06 13:58:13 | Train | Epoch[057/600] Iteration[015/030] Train loss: 0.1006
2023-02-06 13:58:13 | Train | Epoch[057/600] Iteration[016/030] Train loss: 0.1004
2023-02-06 13:58:13 | Train | Epoch[057/600] Iteration[017/030] Train loss: 0.1005
2023-02-06 13:58:13 | Train | Epoch[057/600] Iteration[018/030] Train loss: 0.1003
2023-02-06 13:58:13 | Train | Epoch[057/600] Iteration[019/030] Train loss: 0.1003
2023-02-06 13:58:14 | Train | Epoch[057/600] Iteration[020/030] Train loss: 0.1002
2023-02-06 13:58:14 | Train | Epoch[057/600] Iteration[021/030] Train loss: 0.1001
2023-02-06 13:58:14 | Train | Epoch[057/600] Iteration[022/030] Train loss: 0.1000
2023-02-06 13:58:14 | Train | Epoch[057/600] Iteration[023/030] Train loss: 0.1000
2023-02-06 13:58:15 | Train | Epoch[057/600] Iteration[024/030] Train loss: 0.0999
2023-02-06 13:58:15 | Train | Epoch[057/600] Iteration[025/030] Train loss: 0.0998
2023-02-06 13:58:15 | Train | Epoch[057/600] Iteration[026/030] Train loss: 0.0998
2023-02-06 13:58:15 | Train | Epoch[057/600] Iteration[027/030] Train loss: 0.0997
2023-02-06 13:58:15 | Train | Epoch[057/600] Iteration[028/030] Train loss: 0.0996
2023-02-06 13:58:16 | Train | Epoch[057/600] Iteration[029/030] Train loss: 0.0996
2023-02-06 13:58:16 | Train | Epoch[057/600] Iteration[030/030] Train loss: 0.0997
2023-02-06 13:58:16 | Valid | Epoch[057/600] Iteration[001/008] Valid loss: 0.7626
2023-02-06 13:58:16 | Valid | Epoch[057/600] Iteration[002/008] Valid loss: 0.6856
2023-02-06 13:58:16 | Valid | Epoch[057/600] Iteration[003/008] Valid loss: 0.6963
2023-02-06 13:58:16 | Valid | Epoch[057/600] Iteration[004/008] Valid loss: 0.6841
2023-02-06 13:58:16 | Valid | Epoch[057/600] Iteration[005/008] Valid loss: 0.7064
2023-02-06 13:58:16 | Valid | Epoch[057/600] Iteration[006/008] Valid loss: 0.6867
2023-02-06 13:58:16 | Valid | Epoch[057/600] Iteration[007/008] Valid loss: 0.7241
2023-02-06 13:58:16 | Valid | Epoch[057/600] Iteration[008/008] Valid loss: 0.7482
2023-02-06 13:58:17 | Valid | Epoch[057/600] MIou: 0.8389586611549117
2023-02-06 13:58:17 | Valid | Epoch[057/600] Pixel Accuracy: 0.9647191365559896
2023-02-06 13:58:17 | Valid | Epoch[057/600] Mean Pixel Accuracy: 0.9752060510304468
2023-02-06 13:58:17 | Stage | Epoch[057/600] Train loss:0.0997
2023-02-06 13:58:17 | Stage | Epoch[057/600] Valid loss:0.7482
2023-02-06 13:58:17 | Stage | Epoch[057/600] LR:0.01

2023-02-06 13:58:17 | Train | Epoch[058/600] Iteration[001/030] Train loss: 0.0980
2023-02-06 13:58:17 | Train | Epoch[058/600] Iteration[002/030] Train loss: 0.0979
2023-02-06 13:58:17 | Train | Epoch[058/600] Iteration[003/030] Train loss: 0.0975
2023-02-06 13:58:18 | Train | Epoch[058/600] Iteration[004/030] Train loss: 0.0981
2023-02-06 13:58:18 | Train | Epoch[058/600] Iteration[005/030] Train loss: 0.0981
2023-02-06 13:58:18 | Train | Epoch[058/600] Iteration[006/030] Train loss: 0.0986
2023-02-06 13:58:18 | Train | Epoch[058/600] Iteration[007/030] Train loss: 0.0984
2023-02-06 13:58:19 | Train | Epoch[058/600] Iteration[008/030] Train loss: 0.0981
2023-02-06 13:58:19 | Train | Epoch[058/600] Iteration[009/030] Train loss: 0.0979
2023-02-06 13:58:19 | Train | Epoch[058/600] Iteration[010/030] Train loss: 0.0978
2023-02-06 13:58:19 | Train | Epoch[058/600] Iteration[011/030] Train loss: 0.0976
2023-02-06 13:58:19 | Train | Epoch[058/600] Iteration[012/030] Train loss: 0.0974
2023-02-06 13:58:20 | Train | Epoch[058/600] Iteration[013/030] Train loss: 0.0974
2023-02-06 13:58:20 | Train | Epoch[058/600] Iteration[014/030] Train loss: 0.0973
2023-02-06 13:58:20 | Train | Epoch[058/600] Iteration[015/030] Train loss: 0.0973
2023-02-06 13:58:20 | Train | Epoch[058/600] Iteration[016/030] Train loss: 0.0973
2023-02-06 13:58:21 | Train | Epoch[058/600] Iteration[017/030] Train loss: 0.0972
2023-02-06 13:58:21 | Train | Epoch[058/600] Iteration[018/030] Train loss: 0.0973
2023-02-06 13:58:21 | Train | Epoch[058/600] Iteration[019/030] Train loss: 0.0973
2023-02-06 13:58:21 | Train | Epoch[058/600] Iteration[020/030] Train loss: 0.0972
2023-02-06 13:58:21 | Train | Epoch[058/600] Iteration[021/030] Train loss: 0.0973
2023-02-06 13:58:22 | Train | Epoch[058/600] Iteration[022/030] Train loss: 0.0973
2023-02-06 13:58:22 | Train | Epoch[058/600] Iteration[023/030] Train loss: 0.0973
2023-02-06 13:58:22 | Train | Epoch[058/600] Iteration[024/030] Train loss: 0.0972
2023-02-06 13:58:22 | Train | Epoch[058/600] Iteration[025/030] Train loss: 0.0973
2023-02-06 13:58:23 | Train | Epoch[058/600] Iteration[026/030] Train loss: 0.0973
2023-02-06 13:58:23 | Train | Epoch[058/600] Iteration[027/030] Train loss: 0.0973
2023-02-06 13:58:23 | Train | Epoch[058/600] Iteration[028/030] Train loss: 0.0972
2023-02-06 13:58:23 | Train | Epoch[058/600] Iteration[029/030] Train loss: 0.0971
2023-02-06 13:58:23 | Train | Epoch[058/600] Iteration[030/030] Train loss: 0.0971
2023-02-06 13:58:24 | Valid | Epoch[058/600] Iteration[001/008] Valid loss: 0.1300
2023-02-06 13:58:24 | Valid | Epoch[058/600] Iteration[002/008] Valid loss: 0.1322
2023-02-06 13:58:24 | Valid | Epoch[058/600] Iteration[003/008] Valid loss: 0.1337
2023-02-06 13:58:24 | Valid | Epoch[058/600] Iteration[004/008] Valid loss: 0.1336
2023-02-06 13:58:24 | Valid | Epoch[058/600] Iteration[005/008] Valid loss: 0.1341
2023-02-06 13:58:24 | Valid | Epoch[058/600] Iteration[006/008] Valid loss: 0.1340
2023-02-06 13:58:24 | Valid | Epoch[058/600] Iteration[007/008] Valid loss: 0.1345
2023-02-06 13:58:24 | Valid | Epoch[058/600] Iteration[008/008] Valid loss: 0.1350
2023-02-06 13:58:24 | Valid | Epoch[058/600] MIou: 0.8842867626183103
2023-02-06 13:58:24 | Valid | Epoch[058/600] Pixel Accuracy: 0.9801902770996094
2023-02-06 13:58:24 | Valid | Epoch[058/600] Mean Pixel Accuracy: 0.9102996705345456
2023-02-06 13:58:24 | Stage | Epoch[058/600] Train loss:0.0971
2023-02-06 13:58:24 | Stage | Epoch[058/600] Valid loss:0.1350
2023-02-06 13:58:24 | Stage | Epoch[058/600] LR:0.01

2023-02-06 13:58:25 | Train | Epoch[059/600] Iteration[001/030] Train loss: 0.0956
2023-02-06 13:58:25 | Train | Epoch[059/600] Iteration[002/030] Train loss: 0.0960
2023-02-06 13:58:25 | Train | Epoch[059/600] Iteration[003/030] Train loss: 0.0954
2023-02-06 13:58:25 | Train | Epoch[059/600] Iteration[004/030] Train loss: 0.0955
2023-02-06 13:58:25 | Train | Epoch[059/600] Iteration[005/030] Train loss: 0.0957
2023-02-06 13:58:26 | Train | Epoch[059/600] Iteration[006/030] Train loss: 0.0955
2023-02-06 13:58:26 | Train | Epoch[059/600] Iteration[007/030] Train loss: 0.0952
2023-02-06 13:58:26 | Train | Epoch[059/600] Iteration[008/030] Train loss: 0.0951
2023-02-06 13:58:26 | Train | Epoch[059/600] Iteration[009/030] Train loss: 0.0952
2023-02-06 13:58:27 | Train | Epoch[059/600] Iteration[010/030] Train loss: 0.0954
2023-02-06 13:58:27 | Train | Epoch[059/600] Iteration[011/030] Train loss: 0.0952
2023-02-06 13:58:27 | Train | Epoch[059/600] Iteration[012/030] Train loss: 0.0958
2023-02-06 13:58:27 | Train | Epoch[059/600] Iteration[013/030] Train loss: 0.0959
2023-02-06 13:58:27 | Train | Epoch[059/600] Iteration[014/030] Train loss: 0.0958
2023-02-06 13:58:28 | Train | Epoch[059/600] Iteration[015/030] Train loss: 0.0958
2023-02-06 13:58:28 | Train | Epoch[059/600] Iteration[016/030] Train loss: 0.0958
2023-02-06 13:58:28 | Train | Epoch[059/600] Iteration[017/030] Train loss: 0.0958
2023-02-06 13:58:28 | Train | Epoch[059/600] Iteration[018/030] Train loss: 0.0957
2023-02-06 13:58:29 | Train | Epoch[059/600] Iteration[019/030] Train loss: 0.0956
2023-02-06 13:58:29 | Train | Epoch[059/600] Iteration[020/030] Train loss: 0.0956
2023-02-06 13:58:29 | Train | Epoch[059/600] Iteration[021/030] Train loss: 0.0955
2023-02-06 13:58:29 | Train | Epoch[059/600] Iteration[022/030] Train loss: 0.0956
2023-02-06 13:58:29 | Train | Epoch[059/600] Iteration[023/030] Train loss: 0.0955
2023-02-06 13:58:30 | Train | Epoch[059/600] Iteration[024/030] Train loss: 0.0954
2023-02-06 13:58:30 | Train | Epoch[059/600] Iteration[025/030] Train loss: 0.0953
2023-02-06 13:58:30 | Train | Epoch[059/600] Iteration[026/030] Train loss: 0.0953
2023-02-06 13:58:30 | Train | Epoch[059/600] Iteration[027/030] Train loss: 0.0953
2023-02-06 13:58:31 | Train | Epoch[059/600] Iteration[028/030] Train loss: 0.0953
2023-02-06 13:58:31 | Train | Epoch[059/600] Iteration[029/030] Train loss: 0.0953
2023-02-06 13:58:31 | Train | Epoch[059/600] Iteration[030/030] Train loss: 0.0952
2023-02-06 13:58:31 | Valid | Epoch[059/600] Iteration[001/008] Valid loss: 0.9576
2023-02-06 13:58:31 | Valid | Epoch[059/600] Iteration[002/008] Valid loss: 0.9012
2023-02-06 13:58:31 | Valid | Epoch[059/600] Iteration[003/008] Valid loss: 0.9582
2023-02-06 13:58:31 | Valid | Epoch[059/600] Iteration[004/008] Valid loss: 0.9593
2023-02-06 13:58:31 | Valid | Epoch[059/600] Iteration[005/008] Valid loss: 0.9911
2023-02-06 13:58:31 | Valid | Epoch[059/600] Iteration[006/008] Valid loss: 0.9690
2023-02-06 13:58:31 | Valid | Epoch[059/600] Iteration[007/008] Valid loss: 1.0194
2023-02-06 13:58:31 | Valid | Epoch[059/600] Iteration[008/008] Valid loss: 1.0500
2023-02-06 13:58:32 | Valid | Epoch[059/600] MIou: 0.7891273396010555
2023-02-06 13:58:32 | Valid | Epoch[059/600] Pixel Accuracy: 0.9484850565592448
2023-02-06 13:58:32 | Valid | Epoch[059/600] Mean Pixel Accuracy: 0.9678999285330501
2023-02-06 13:58:32 | Stage | Epoch[059/600] Train loss:0.0952
2023-02-06 13:58:32 | Stage | Epoch[059/600] Valid loss:1.0500
2023-02-06 13:58:32 | Stage | Epoch[059/600] LR:0.01

2023-02-06 13:58:32 | Train | Epoch[060/600] Iteration[001/030] Train loss: 0.0927
2023-02-06 13:58:32 | Train | Epoch[060/600] Iteration[002/030] Train loss: 0.0921
2023-02-06 13:58:33 | Train | Epoch[060/600] Iteration[003/030] Train loss: 0.0937
2023-02-06 13:58:33 | Train | Epoch[060/600] Iteration[004/030] Train loss: 0.0939
2023-02-06 13:58:33 | Train | Epoch[060/600] Iteration[005/030] Train loss: 0.0938
2023-02-06 13:58:33 | Train | Epoch[060/600] Iteration[006/030] Train loss: 0.0936
2023-02-06 13:58:33 | Train | Epoch[060/600] Iteration[007/030] Train loss: 0.0933
2023-02-06 13:58:34 | Train | Epoch[060/600] Iteration[008/030] Train loss: 0.0930
2023-02-06 13:58:34 | Train | Epoch[060/600] Iteration[009/030] Train loss: 0.0928
2023-02-06 13:58:34 | Train | Epoch[060/600] Iteration[010/030] Train loss: 0.0934
2023-02-06 13:58:34 | Train | Epoch[060/600] Iteration[011/030] Train loss: 0.0934
2023-02-06 13:58:35 | Train | Epoch[060/600] Iteration[012/030] Train loss: 0.0933
2023-02-06 13:58:35 | Train | Epoch[060/600] Iteration[013/030] Train loss: 0.0933
2023-02-06 13:58:35 | Train | Epoch[060/600] Iteration[014/030] Train loss: 0.0936
2023-02-06 13:58:35 | Train | Epoch[060/600] Iteration[015/030] Train loss: 0.0935
2023-02-06 13:58:35 | Train | Epoch[060/600] Iteration[016/030] Train loss: 0.0934
2023-02-06 13:58:36 | Train | Epoch[060/600] Iteration[017/030] Train loss: 0.0933
2023-02-06 13:58:36 | Train | Epoch[060/600] Iteration[018/030] Train loss: 0.0933
2023-02-06 13:58:36 | Train | Epoch[060/600] Iteration[019/030] Train loss: 0.0932
2023-02-06 13:58:36 | Train | Epoch[060/600] Iteration[020/030] Train loss: 0.0931
2023-02-06 13:58:36 | Train | Epoch[060/600] Iteration[021/030] Train loss: 0.0930
2023-02-06 13:58:37 | Train | Epoch[060/600] Iteration[022/030] Train loss: 0.0930
2023-02-06 13:58:37 | Train | Epoch[060/600] Iteration[023/030] Train loss: 0.0930
2023-02-06 13:58:37 | Train | Epoch[060/600] Iteration[024/030] Train loss: 0.0930
2023-02-06 13:58:37 | Train | Epoch[060/600] Iteration[025/030] Train loss: 0.0931
2023-02-06 13:58:38 | Train | Epoch[060/600] Iteration[026/030] Train loss: 0.0930
2023-02-06 13:58:38 | Train | Epoch[060/600] Iteration[027/030] Train loss: 0.0930
2023-02-06 13:58:38 | Train | Epoch[060/600] Iteration[028/030] Train loss: 0.0930
2023-02-06 13:58:38 | Train | Epoch[060/600] Iteration[029/030] Train loss: 0.0930
2023-02-06 13:58:38 | Train | Epoch[060/600] Iteration[030/030] Train loss: 0.0931
2023-02-06 13:58:39 | Valid | Epoch[060/600] Iteration[001/008] Valid loss: 0.1290
2023-02-06 13:58:39 | Valid | Epoch[060/600] Iteration[002/008] Valid loss: 0.1284
2023-02-06 13:58:39 | Valid | Epoch[060/600] Iteration[003/008] Valid loss: 0.1317
2023-02-06 13:58:39 | Valid | Epoch[060/600] Iteration[004/008] Valid loss: 0.1313
2023-02-06 13:58:39 | Valid | Epoch[060/600] Iteration[005/008] Valid loss: 0.1321
2023-02-06 13:58:39 | Valid | Epoch[060/600] Iteration[006/008] Valid loss: 0.1311
2023-02-06 13:58:39 | Valid | Epoch[060/600] Iteration[007/008] Valid loss: 0.1298
2023-02-06 13:58:39 | Valid | Epoch[060/600] Iteration[008/008] Valid loss: 0.1308
2023-02-06 13:58:39 | Valid | Epoch[060/600] MIou: 0.7601001733377581
2023-02-06 13:58:39 | Valid | Epoch[060/600] Pixel Accuracy: 0.9604212443033854
2023-02-06 13:58:39 | Valid | Epoch[060/600] Mean Pixel Accuracy: 0.7810064400782577
2023-02-06 13:58:39 | Stage | Epoch[060/600] Train loss:0.0931
2023-02-06 13:58:39 | Stage | Epoch[060/600] Valid loss:0.1308
2023-02-06 13:58:39 | Stage | Epoch[060/600] LR:0.01

2023-02-06 13:58:40 | Train | Epoch[061/600] Iteration[001/030] Train loss: 0.0902
2023-02-06 13:58:40 | Train | Epoch[061/600] Iteration[002/030] Train loss: 0.0918
2023-02-06 13:58:40 | Train | Epoch[061/600] Iteration[003/030] Train loss: 0.0927
2023-02-06 13:58:40 | Train | Epoch[061/600] Iteration[004/030] Train loss: 0.0919
2023-02-06 13:58:41 | Train | Epoch[061/600] Iteration[005/030] Train loss: 0.0916
2023-02-06 13:58:41 | Train | Epoch[061/600] Iteration[006/030] Train loss: 0.0916
2023-02-06 13:58:41 | Train | Epoch[061/600] Iteration[007/030] Train loss: 0.0914
2023-02-06 13:58:41 | Train | Epoch[061/600] Iteration[008/030] Train loss: 0.0916
2023-02-06 13:58:41 | Train | Epoch[061/600] Iteration[009/030] Train loss: 0.0914
2023-02-06 13:58:42 | Train | Epoch[061/600] Iteration[010/030] Train loss: 0.0913
2023-02-06 13:58:42 | Train | Epoch[061/600] Iteration[011/030] Train loss: 0.0912
2023-02-06 13:58:42 | Train | Epoch[061/600] Iteration[012/030] Train loss: 0.0912
2023-02-06 13:58:42 | Train | Epoch[061/600] Iteration[013/030] Train loss: 0.0914
2023-02-06 13:58:43 | Train | Epoch[061/600] Iteration[014/030] Train loss: 0.0914
2023-02-06 13:58:43 | Train | Epoch[061/600] Iteration[015/030] Train loss: 0.0912
2023-02-06 13:58:43 | Train | Epoch[061/600] Iteration[016/030] Train loss: 0.0912
2023-02-06 13:58:43 | Train | Epoch[061/600] Iteration[017/030] Train loss: 0.0911
2023-02-06 13:58:43 | Train | Epoch[061/600] Iteration[018/030] Train loss: 0.0911
2023-02-06 13:58:44 | Train | Epoch[061/600] Iteration[019/030] Train loss: 0.0911
2023-02-06 13:58:44 | Train | Epoch[061/600] Iteration[020/030] Train loss: 0.0910
2023-02-06 13:58:44 | Train | Epoch[061/600] Iteration[021/030] Train loss: 0.0909
2023-02-06 13:58:44 | Train | Epoch[061/600] Iteration[022/030] Train loss: 0.0909
2023-02-06 13:58:45 | Train | Epoch[061/600] Iteration[023/030] Train loss: 0.0911
2023-02-06 13:58:45 | Train | Epoch[061/600] Iteration[024/030] Train loss: 0.0910
2023-02-06 13:58:45 | Train | Epoch[061/600] Iteration[025/030] Train loss: 0.0910
2023-02-06 13:58:45 | Train | Epoch[061/600] Iteration[026/030] Train loss: 0.0911
2023-02-06 13:58:45 | Train | Epoch[061/600] Iteration[027/030] Train loss: 0.0910
2023-02-06 13:58:46 | Train | Epoch[061/600] Iteration[028/030] Train loss: 0.0910
2023-02-06 13:58:46 | Train | Epoch[061/600] Iteration[029/030] Train loss: 0.0910
2023-02-06 13:58:46 | Train | Epoch[061/600] Iteration[030/030] Train loss: 0.0909
2023-02-06 13:58:46 | Valid | Epoch[061/600] Iteration[001/008] Valid loss: 0.1390
2023-02-06 13:58:46 | Valid | Epoch[061/600] Iteration[002/008] Valid loss: 0.1408
2023-02-06 13:58:46 | Valid | Epoch[061/600] Iteration[003/008] Valid loss: 0.1440
2023-02-06 13:58:47 | Valid | Epoch[061/600] Iteration[004/008] Valid loss: 0.1430
2023-02-06 13:58:47 | Valid | Epoch[061/600] Iteration[005/008] Valid loss: 0.1469
2023-02-06 13:58:47 | Valid | Epoch[061/600] Iteration[006/008] Valid loss: 0.1462
2023-02-06 13:58:47 | Valid | Epoch[061/600] Iteration[007/008] Valid loss: 0.1470
2023-02-06 13:58:47 | Valid | Epoch[061/600] Iteration[008/008] Valid loss: 0.1487
2023-02-06 13:58:47 | Valid | Epoch[061/600] MIou: 0.6873206053220158
2023-02-06 13:58:47 | Valid | Epoch[061/600] Pixel Accuracy: 0.9470380147298177
2023-02-06 13:58:47 | Valid | Epoch[061/600] Mean Pixel Accuracy: 0.7195979266832083
2023-02-06 13:58:47 | Stage | Epoch[061/600] Train loss:0.0909
2023-02-06 13:58:47 | Stage | Epoch[061/600] Valid loss:0.1487
2023-02-06 13:58:47 | Stage | Epoch[061/600] LR:0.01

2023-02-06 13:58:47 | Train | Epoch[062/600] Iteration[001/030] Train loss: 0.0894
2023-02-06 13:58:48 | Train | Epoch[062/600] Iteration[002/030] Train loss: 0.0894
2023-02-06 13:58:48 | Train | Epoch[062/600] Iteration[003/030] Train loss: 0.0900
2023-02-06 13:58:48 | Train | Epoch[062/600] Iteration[004/030] Train loss: 0.0898
2023-02-06 13:58:48 | Train | Epoch[062/600] Iteration[005/030] Train loss: 0.0897
2023-02-06 13:58:48 | Train | Epoch[062/600] Iteration[006/030] Train loss: 0.0896
2023-02-06 13:58:49 | Train | Epoch[062/600] Iteration[007/030] Train loss: 0.0896
2023-02-06 13:58:49 | Train | Epoch[062/600] Iteration[008/030] Train loss: 0.0897
2023-02-06 13:58:49 | Train | Epoch[062/600] Iteration[009/030] Train loss: 0.0894
2023-02-06 13:58:49 | Train | Epoch[062/600] Iteration[010/030] Train loss: 0.0894
2023-02-06 13:58:49 | Train | Epoch[062/600] Iteration[011/030] Train loss: 0.0894
2023-02-06 13:58:50 | Train | Epoch[062/600] Iteration[012/030] Train loss: 0.0893
2023-02-06 13:58:50 | Train | Epoch[062/600] Iteration[013/030] Train loss: 0.0894
2023-02-06 13:58:50 | Train | Epoch[062/600] Iteration[014/030] Train loss: 0.0891
2023-02-06 13:58:50 | Train | Epoch[062/600] Iteration[015/030] Train loss: 0.0890
2023-02-06 13:58:51 | Train | Epoch[062/600] Iteration[016/030] Train loss: 0.0890
2023-02-06 13:58:51 | Train | Epoch[062/600] Iteration[017/030] Train loss: 0.0889
2023-02-06 13:58:51 | Train | Epoch[062/600] Iteration[018/030] Train loss: 0.0888
2023-02-06 13:58:51 | Train | Epoch[062/600] Iteration[019/030] Train loss: 0.0893
2023-02-06 13:58:51 | Train | Epoch[062/600] Iteration[020/030] Train loss: 0.0893
2023-02-06 13:58:52 | Train | Epoch[062/600] Iteration[021/030] Train loss: 0.0892
2023-02-06 13:58:52 | Train | Epoch[062/600] Iteration[022/030] Train loss: 0.0892
2023-02-06 13:58:52 | Train | Epoch[062/600] Iteration[023/030] Train loss: 0.0894
2023-02-06 13:58:52 | Train | Epoch[062/600] Iteration[024/030] Train loss: 0.0893
2023-02-06 13:58:53 | Train | Epoch[062/600] Iteration[025/030] Train loss: 0.0893
2023-02-06 13:58:53 | Train | Epoch[062/600] Iteration[026/030] Train loss: 0.0893
2023-02-06 13:58:53 | Train | Epoch[062/600] Iteration[027/030] Train loss: 0.0893
2023-02-06 13:58:53 | Train | Epoch[062/600] Iteration[028/030] Train loss: 0.0893
2023-02-06 13:58:53 | Train | Epoch[062/600] Iteration[029/030] Train loss: 0.0894
2023-02-06 13:58:54 | Train | Epoch[062/600] Iteration[030/030] Train loss: 0.0893
2023-02-06 13:58:54 | Valid | Epoch[062/600] Iteration[001/008] Valid loss: 0.1143
2023-02-06 13:58:54 | Valid | Epoch[062/600] Iteration[002/008] Valid loss: 0.1141
2023-02-06 13:58:54 | Valid | Epoch[062/600] Iteration[003/008] Valid loss: 0.1153
2023-02-06 13:58:54 | Valid | Epoch[062/600] Iteration[004/008] Valid loss: 0.1154
2023-02-06 13:58:54 | Valid | Epoch[062/600] Iteration[005/008] Valid loss: 0.1165
2023-02-06 13:58:54 | Valid | Epoch[062/600] Iteration[006/008] Valid loss: 0.1157
2023-02-06 13:58:54 | Valid | Epoch[062/600] Iteration[007/008] Valid loss: 0.1148
2023-02-06 13:58:54 | Valid | Epoch[062/600] Iteration[008/008] Valid loss: 0.1152
2023-02-06 13:58:54 | Valid | Epoch[062/600] MIou: 0.829329732239303
2023-02-06 13:58:54 | Valid | Epoch[062/600] Pixel Accuracy: 0.9718449910481771
2023-02-06 13:58:54 | Valid | Epoch[062/600] Mean Pixel Accuracy: 0.8447364308711651
2023-02-06 13:58:54 | Stage | Epoch[062/600] Train loss:0.0893
2023-02-06 13:58:54 | Stage | Epoch[062/600] Valid loss:0.1152
2023-02-06 13:58:54 | Stage | Epoch[062/600] LR:0.01

2023-02-06 13:58:55 | Train | Epoch[063/600] Iteration[001/030] Train loss: 0.0881
2023-02-06 13:58:55 | Train | Epoch[063/600] Iteration[002/030] Train loss: 0.0871
2023-02-06 13:58:55 | Train | Epoch[063/600] Iteration[003/030] Train loss: 0.0876
2023-02-06 13:58:55 | Train | Epoch[063/600] Iteration[004/030] Train loss: 0.0876
2023-02-06 13:58:56 | Train | Epoch[063/600] Iteration[005/030] Train loss: 0.0881
2023-02-06 13:58:56 | Train | Epoch[063/600] Iteration[006/030] Train loss: 0.0877
2023-02-06 13:58:56 | Train | Epoch[063/600] Iteration[007/030] Train loss: 0.0874
2023-02-06 13:58:56 | Train | Epoch[063/600] Iteration[008/030] Train loss: 0.0875
2023-02-06 13:58:57 | Train | Epoch[063/600] Iteration[009/030] Train loss: 0.0876
2023-02-06 13:58:57 | Train | Epoch[063/600] Iteration[010/030] Train loss: 0.0876
2023-02-06 13:58:57 | Train | Epoch[063/600] Iteration[011/030] Train loss: 0.0877
2023-02-06 13:58:57 | Train | Epoch[063/600] Iteration[012/030] Train loss: 0.0875
2023-02-06 13:58:57 | Train | Epoch[063/600] Iteration[013/030] Train loss: 0.0876
2023-02-06 13:58:58 | Train | Epoch[063/600] Iteration[014/030] Train loss: 0.0875
2023-02-06 13:58:58 | Train | Epoch[063/600] Iteration[015/030] Train loss: 0.0874
2023-02-06 13:58:58 | Train | Epoch[063/600] Iteration[016/030] Train loss: 0.0874
2023-02-06 13:58:58 | Train | Epoch[063/600] Iteration[017/030] Train loss: 0.0872
2023-02-06 13:58:58 | Train | Epoch[063/600] Iteration[018/030] Train loss: 0.0872
2023-02-06 13:58:59 | Train | Epoch[063/600] Iteration[019/030] Train loss: 0.0872
2023-02-06 13:58:59 | Train | Epoch[063/600] Iteration[020/030] Train loss: 0.0872
2023-02-06 13:58:59 | Train | Epoch[063/600] Iteration[021/030] Train loss: 0.0871
2023-02-06 13:58:59 | Train | Epoch[063/600] Iteration[022/030] Train loss: 0.0871
2023-02-06 13:59:00 | Train | Epoch[063/600] Iteration[023/030] Train loss: 0.0873
2023-02-06 13:59:00 | Train | Epoch[063/600] Iteration[024/030] Train loss: 0.0873
2023-02-06 13:59:00 | Train | Epoch[063/600] Iteration[025/030] Train loss: 0.0872
2023-02-06 13:59:00 | Train | Epoch[063/600] Iteration[026/030] Train loss: 0.0871
2023-02-06 13:59:00 | Train | Epoch[063/600] Iteration[027/030] Train loss: 0.0870
2023-02-06 13:59:01 | Train | Epoch[063/600] Iteration[028/030] Train loss: 0.0869
2023-02-06 13:59:01 | Train | Epoch[063/600] Iteration[029/030] Train loss: 0.0869
2023-02-06 13:59:01 | Train | Epoch[063/600] Iteration[030/030] Train loss: 0.0867
2023-02-06 13:59:01 | Valid | Epoch[063/600] Iteration[001/008] Valid loss: 0.1127
2023-02-06 13:59:01 | Valid | Epoch[063/600] Iteration[002/008] Valid loss: 0.1088
2023-02-06 13:59:01 | Valid | Epoch[063/600] Iteration[003/008] Valid loss: 0.1078
2023-02-06 13:59:02 | Valid | Epoch[063/600] Iteration[004/008] Valid loss: 0.1063
2023-02-06 13:59:02 | Valid | Epoch[063/600] Iteration[005/008] Valid loss: 0.1065
2023-02-06 13:59:02 | Valid | Epoch[063/600] Iteration[006/008] Valid loss: 0.1059
2023-02-06 13:59:02 | Valid | Epoch[063/600] Iteration[007/008] Valid loss: 0.1065
2023-02-06 13:59:02 | Valid | Epoch[063/600] Iteration[008/008] Valid loss: 0.1064
2023-02-06 13:59:02 | Valid | Epoch[063/600] MIou: 0.913930941181723
2023-02-06 13:59:02 | Valid | Epoch[063/600] Pixel Accuracy: 0.9853947957356771
2023-02-06 13:59:02 | Valid | Epoch[063/600] Mean Pixel Accuracy: 0.934781303800472
2023-02-06 13:59:02 | Stage | Epoch[063/600] Train loss:0.0867
2023-02-06 13:59:02 | Stage | Epoch[063/600] Valid loss:0.1064
2023-02-06 13:59:02 | Stage | Epoch[063/600] LR:0.01

2023-02-06 13:59:02 | Train | Epoch[064/600] Iteration[001/030] Train loss: 0.0864
2023-02-06 13:59:03 | Train | Epoch[064/600] Iteration[002/030] Train loss: 0.0858
2023-02-06 13:59:03 | Train | Epoch[064/600] Iteration[003/030] Train loss: 0.0859
2023-02-06 13:59:03 | Train | Epoch[064/600] Iteration[004/030] Train loss: 0.0860
2023-02-06 13:59:03 | Train | Epoch[064/600] Iteration[005/030] Train loss: 0.0856
2023-02-06 13:59:03 | Train | Epoch[064/600] Iteration[006/030] Train loss: 0.0854
2023-02-06 13:59:04 | Train | Epoch[064/600] Iteration[007/030] Train loss: 0.0853
2023-02-06 13:59:04 | Train | Epoch[064/600] Iteration[008/030] Train loss: 0.0856
2023-02-06 13:59:04 | Train | Epoch[064/600] Iteration[009/030] Train loss: 0.0858
2023-02-06 13:59:04 | Train | Epoch[064/600] Iteration[010/030] Train loss: 0.0860
2023-02-06 13:59:05 | Train | Epoch[064/600] Iteration[011/030] Train loss: 0.0861
2023-02-06 13:59:05 | Train | Epoch[064/600] Iteration[012/030] Train loss: 0.0860
2023-02-06 13:59:05 | Train | Epoch[064/600] Iteration[013/030] Train loss: 0.0863
2023-02-06 13:59:05 | Train | Epoch[064/600] Iteration[014/030] Train loss: 0.0862
2023-02-06 13:59:05 | Train | Epoch[064/600] Iteration[015/030] Train loss: 0.0862
2023-02-06 13:59:06 | Train | Epoch[064/600] Iteration[016/030] Train loss: 0.0862
2023-02-06 13:59:06 | Train | Epoch[064/600] Iteration[017/030] Train loss: 0.0862
2023-02-06 13:59:06 | Train | Epoch[064/600] Iteration[018/030] Train loss: 0.0862
2023-02-06 13:59:06 | Train | Epoch[064/600] Iteration[019/030] Train loss: 0.0862
2023-02-06 13:59:06 | Train | Epoch[064/600] Iteration[020/030] Train loss: 0.0862
2023-02-06 13:59:07 | Train | Epoch[064/600] Iteration[021/030] Train loss: 0.0861
2023-02-06 13:59:07 | Train | Epoch[064/600] Iteration[022/030] Train loss: 0.0860
2023-02-06 13:59:07 | Train | Epoch[064/600] Iteration[023/030] Train loss: 0.0859
2023-02-06 13:59:07 | Train | Epoch[064/600] Iteration[024/030] Train loss: 0.0859
2023-02-06 13:59:08 | Train | Epoch[064/600] Iteration[025/030] Train loss: 0.0857
2023-02-06 13:59:08 | Train | Epoch[064/600] Iteration[026/030] Train loss: 0.0856
2023-02-06 13:59:08 | Train | Epoch[064/600] Iteration[027/030] Train loss: 0.0856
2023-02-06 13:59:08 | Train | Epoch[064/600] Iteration[028/030] Train loss: 0.0856
2023-02-06 13:59:08 | Train | Epoch[064/600] Iteration[029/030] Train loss: 0.0855
2023-02-06 13:59:09 | Train | Epoch[064/600] Iteration[030/030] Train loss: 0.0857
2023-02-06 13:59:09 | Valid | Epoch[064/600] Iteration[001/008] Valid loss: 0.1956
2023-02-06 13:59:09 | Valid | Epoch[064/600] Iteration[002/008] Valid loss: 0.1728
2023-02-06 13:59:09 | Valid | Epoch[064/600] Iteration[003/008] Valid loss: 0.1717
2023-02-06 13:59:09 | Valid | Epoch[064/600] Iteration[004/008] Valid loss: 0.1645
2023-02-06 13:59:09 | Valid | Epoch[064/600] Iteration[005/008] Valid loss: 0.1657
2023-02-06 13:59:09 | Valid | Epoch[064/600] Iteration[006/008] Valid loss: 0.1625
2023-02-06 13:59:09 | Valid | Epoch[064/600] Iteration[007/008] Valid loss: 0.1669
2023-02-06 13:59:09 | Valid | Epoch[064/600] Iteration[008/008] Valid loss: 0.1670
2023-02-06 13:59:09 | Valid | Epoch[064/600] MIou: 0.9016317195107424
2023-02-06 13:59:09 | Valid | Epoch[064/600] Pixel Accuracy: 0.9813575744628906
2023-02-06 13:59:09 | Valid | Epoch[064/600] Mean Pixel Accuracy: 0.9736612111469269
2023-02-06 13:59:09 | Stage | Epoch[064/600] Train loss:0.0857
2023-02-06 13:59:09 | Stage | Epoch[064/600] Valid loss:0.1670
2023-02-06 13:59:09 | Stage | Epoch[064/600] LR:0.01

2023-02-06 13:59:10 | Train | Epoch[065/600] Iteration[001/030] Train loss: 0.0847
2023-02-06 13:59:10 | Train | Epoch[065/600] Iteration[002/030] Train loss: 0.0831
2023-02-06 13:59:10 | Train | Epoch[065/600] Iteration[003/030] Train loss: 0.0832
2023-02-06 13:59:10 | Train | Epoch[065/600] Iteration[004/030] Train loss: 0.0832
2023-02-06 13:59:11 | Train | Epoch[065/600] Iteration[005/030] Train loss: 0.0837
2023-02-06 13:59:11 | Train | Epoch[065/600] Iteration[006/030] Train loss: 0.0839
2023-02-06 13:59:11 | Train | Epoch[065/600] Iteration[007/030] Train loss: 0.0843
2023-02-06 13:59:11 | Train | Epoch[065/600] Iteration[008/030] Train loss: 0.0841
2023-02-06 13:59:11 | Train | Epoch[065/600] Iteration[009/030] Train loss: 0.0838
2023-02-06 13:59:12 | Train | Epoch[065/600] Iteration[010/030] Train loss: 0.0838
2023-02-06 13:59:12 | Train | Epoch[065/600] Iteration[011/030] Train loss: 0.0836
2023-02-06 13:59:12 | Train | Epoch[065/600] Iteration[012/030] Train loss: 0.0835
2023-02-06 13:59:12 | Train | Epoch[065/600] Iteration[013/030] Train loss: 0.0834
2023-02-06 13:59:13 | Train | Epoch[065/600] Iteration[014/030] Train loss: 0.0834
2023-02-06 13:59:13 | Train | Epoch[065/600] Iteration[015/030] Train loss: 0.0835
2023-02-06 13:59:13 | Train | Epoch[065/600] Iteration[016/030] Train loss: 0.0834
2023-02-06 13:59:13 | Train | Epoch[065/600] Iteration[017/030] Train loss: 0.0833
2023-02-06 13:59:13 | Train | Epoch[065/600] Iteration[018/030] Train loss: 0.0834
2023-02-06 13:59:14 | Train | Epoch[065/600] Iteration[019/030] Train loss: 0.0834
2023-02-06 13:59:14 | Train | Epoch[065/600] Iteration[020/030] Train loss: 0.0834
2023-02-06 13:59:14 | Train | Epoch[065/600] Iteration[021/030] Train loss: 0.0837
2023-02-06 13:59:14 | Train | Epoch[065/600] Iteration[022/030] Train loss: 0.0836
2023-02-06 13:59:15 | Train | Epoch[065/600] Iteration[023/030] Train loss: 0.0836
2023-02-06 13:59:15 | Train | Epoch[065/600] Iteration[024/030] Train loss: 0.0837
2023-02-06 13:59:15 | Train | Epoch[065/600] Iteration[025/030] Train loss: 0.0836
2023-02-06 13:59:15 | Train | Epoch[065/600] Iteration[026/030] Train loss: 0.0837
2023-02-06 13:59:15 | Train | Epoch[065/600] Iteration[027/030] Train loss: 0.0838
2023-02-06 13:59:16 | Train | Epoch[065/600] Iteration[028/030] Train loss: 0.0838
2023-02-06 13:59:16 | Train | Epoch[065/600] Iteration[029/030] Train loss: 0.0838
2023-02-06 13:59:16 | Train | Epoch[065/600] Iteration[030/030] Train loss: 0.0838
2023-02-06 13:59:16 | Valid | Epoch[065/600] Iteration[001/008] Valid loss: 0.1570
2023-02-06 13:59:16 | Valid | Epoch[065/600] Iteration[002/008] Valid loss: 0.1362
2023-02-06 13:59:16 | Valid | Epoch[065/600] Iteration[003/008] Valid loss: 0.1321
2023-02-06 13:59:16 | Valid | Epoch[065/600] Iteration[004/008] Valid loss: 0.1315
2023-02-06 13:59:17 | Valid | Epoch[065/600] Iteration[005/008] Valid loss: 0.1345
2023-02-06 13:59:17 | Valid | Epoch[065/600] Iteration[006/008] Valid loss: 0.1322
2023-02-06 13:59:17 | Valid | Epoch[065/600] Iteration[007/008] Valid loss: 0.1377
2023-02-06 13:59:17 | Valid | Epoch[065/600] Iteration[008/008] Valid loss: 0.1363
2023-02-06 13:59:17 | Valid | Epoch[065/600] MIou: 0.9256804939588984
2023-02-06 13:59:17 | Valid | Epoch[065/600] Pixel Accuracy: 0.9867286682128906
2023-02-06 13:59:17 | Valid | Epoch[065/600] Mean Pixel Accuracy: 0.9695627890221024
2023-02-06 13:59:17 | Stage | Epoch[065/600] Train loss:0.0838
2023-02-06 13:59:17 | Stage | Epoch[065/600] Valid loss:0.1363
2023-02-06 13:59:17 | Stage | Epoch[065/600] LR:0.01

2023-02-06 13:59:17 | Train | Epoch[066/600] Iteration[001/030] Train loss: 0.0825
2023-02-06 13:59:17 | Train | Epoch[066/600] Iteration[002/030] Train loss: 0.0825
2023-02-06 13:59:18 | Train | Epoch[066/600] Iteration[003/030] Train loss: 0.0822
2023-02-06 13:59:18 | Train | Epoch[066/600] Iteration[004/030] Train loss: 0.0822
2023-02-06 13:59:18 | Train | Epoch[066/600] Iteration[005/030] Train loss: 0.0819
2023-02-06 13:59:18 | Train | Epoch[066/600] Iteration[006/030] Train loss: 0.0817
2023-02-06 13:59:19 | Train | Epoch[066/600] Iteration[007/030] Train loss: 0.0818
2023-02-06 13:59:19 | Train | Epoch[066/600] Iteration[008/030] Train loss: 0.0818
2023-02-06 13:59:19 | Train | Epoch[066/600] Iteration[009/030] Train loss: 0.0816
2023-02-06 13:59:19 | Train | Epoch[066/600] Iteration[010/030] Train loss: 0.0815
2023-02-06 13:59:19 | Train | Epoch[066/600] Iteration[011/030] Train loss: 0.0814
2023-02-06 13:59:20 | Train | Epoch[066/600] Iteration[012/030] Train loss: 0.0815
2023-02-06 13:59:20 | Train | Epoch[066/600] Iteration[013/030] Train loss: 0.0815
2023-02-06 13:59:20 | Train | Epoch[066/600] Iteration[014/030] Train loss: 0.0814
2023-02-06 13:59:20 | Train | Epoch[066/600] Iteration[015/030] Train loss: 0.0813
2023-02-06 13:59:21 | Train | Epoch[066/600] Iteration[016/030] Train loss: 0.0812
2023-02-06 13:59:21 | Train | Epoch[066/600] Iteration[017/030] Train loss: 0.0817
2023-02-06 13:59:21 | Train | Epoch[066/600] Iteration[018/030] Train loss: 0.0816
2023-02-06 13:59:21 | Train | Epoch[066/600] Iteration[019/030] Train loss: 0.0815
2023-02-06 13:59:21 | Train | Epoch[066/600] Iteration[020/030] Train loss: 0.0816
2023-02-06 13:59:22 | Train | Epoch[066/600] Iteration[021/030] Train loss: 0.0815
2023-02-06 13:59:22 | Train | Epoch[066/600] Iteration[022/030] Train loss: 0.0815
2023-02-06 13:59:22 | Train | Epoch[066/600] Iteration[023/030] Train loss: 0.0815
2023-02-06 13:59:22 | Train | Epoch[066/600] Iteration[024/030] Train loss: 0.0814
2023-02-06 13:59:23 | Train | Epoch[066/600] Iteration[025/030] Train loss: 0.0814
2023-02-06 13:59:23 | Train | Epoch[066/600] Iteration[026/030] Train loss: 0.0815
2023-02-06 13:59:23 | Train | Epoch[066/600] Iteration[027/030] Train loss: 0.0815
2023-02-06 13:59:23 | Train | Epoch[066/600] Iteration[028/030] Train loss: 0.0816
2023-02-06 13:59:23 | Train | Epoch[066/600] Iteration[029/030] Train loss: 0.0816
2023-02-06 13:59:23 | Train | Epoch[066/600] Iteration[030/030] Train loss: 0.0816
2023-02-06 13:59:24 | Valid | Epoch[066/600] Iteration[001/008] Valid loss: 0.3806
2023-02-06 13:59:24 | Valid | Epoch[066/600] Iteration[002/008] Valid loss: 0.3426
2023-02-06 13:59:24 | Valid | Epoch[066/600] Iteration[003/008] Valid loss: 0.3556
2023-02-06 13:59:24 | Valid | Epoch[066/600] Iteration[004/008] Valid loss: 0.3352
2023-02-06 13:59:24 | Valid | Epoch[066/600] Iteration[005/008] Valid loss: 0.3410
2023-02-06 13:59:24 | Valid | Epoch[066/600] Iteration[006/008] Valid loss: 0.3318
2023-02-06 13:59:24 | Valid | Epoch[066/600] Iteration[007/008] Valid loss: 0.3519
2023-02-06 13:59:24 | Valid | Epoch[066/600] Iteration[008/008] Valid loss: 0.3611
2023-02-06 13:59:24 | Valid | Epoch[066/600] MIou: 0.8735506859021831
2023-02-06 13:59:24 | Valid | Epoch[066/600] Pixel Accuracy: 0.9743766784667969
2023-02-06 13:59:24 | Valid | Epoch[066/600] Mean Pixel Accuracy: 0.9761710249630524
2023-02-06 13:59:24 | Stage | Epoch[066/600] Train loss:0.0816
2023-02-06 13:59:24 | Stage | Epoch[066/600] Valid loss:0.3611
2023-02-06 13:59:24 | Stage | Epoch[066/600] LR:0.01

2023-02-06 13:59:25 | Train | Epoch[067/600] Iteration[001/030] Train loss: 0.0798
2023-02-06 13:59:25 | Train | Epoch[067/600] Iteration[002/030] Train loss: 0.0798
2023-02-06 13:59:25 | Train | Epoch[067/600] Iteration[003/030] Train loss: 0.0804
2023-02-06 13:59:25 | Train | Epoch[067/600] Iteration[004/030] Train loss: 0.0805
2023-02-06 13:59:26 | Train | Epoch[067/600] Iteration[005/030] Train loss: 0.0803
2023-02-06 13:59:26 | Train | Epoch[067/600] Iteration[006/030] Train loss: 0.0800
2023-02-06 13:59:26 | Train | Epoch[067/600] Iteration[007/030] Train loss: 0.0799
2023-02-06 13:59:26 | Train | Epoch[067/600] Iteration[008/030] Train loss: 0.0797
2023-02-06 13:59:27 | Train | Epoch[067/600] Iteration[009/030] Train loss: 0.0798
2023-02-06 13:59:27 | Train | Epoch[067/600] Iteration[010/030] Train loss: 0.0799
2023-02-06 13:59:27 | Train | Epoch[067/600] Iteration[011/030] Train loss: 0.0799
2023-02-06 13:59:27 | Train | Epoch[067/600] Iteration[012/030] Train loss: 0.0797
2023-02-06 13:59:27 | Train | Epoch[067/600] Iteration[013/030] Train loss: 0.0798
2023-02-06 13:59:28 | Train | Epoch[067/600] Iteration[014/030] Train loss: 0.0798
2023-02-06 13:59:28 | Train | Epoch[067/600] Iteration[015/030] Train loss: 0.0797
2023-02-06 13:59:28 | Train | Epoch[067/600] Iteration[016/030] Train loss: 0.0796
2023-02-06 13:59:28 | Train | Epoch[067/600] Iteration[017/030] Train loss: 0.0797
2023-02-06 13:59:29 | Train | Epoch[067/600] Iteration[018/030] Train loss: 0.0796
2023-02-06 13:59:29 | Train | Epoch[067/600] Iteration[019/030] Train loss: 0.0798
2023-02-06 13:59:29 | Train | Epoch[067/600] Iteration[020/030] Train loss: 0.0796
2023-02-06 13:59:29 | Train | Epoch[067/600] Iteration[021/030] Train loss: 0.0799
2023-02-06 13:59:29 | Train | Epoch[067/600] Iteration[022/030] Train loss: 0.0797
2023-02-06 13:59:30 | Train | Epoch[067/600] Iteration[023/030] Train loss: 0.0797
2023-02-06 13:59:30 | Train | Epoch[067/600] Iteration[024/030] Train loss: 0.0797
2023-02-06 13:59:30 | Train | Epoch[067/600] Iteration[025/030] Train loss: 0.0796
2023-02-06 13:59:30 | Train | Epoch[067/600] Iteration[026/030] Train loss: 0.0797
2023-02-06 13:59:31 | Train | Epoch[067/600] Iteration[027/030] Train loss: 0.0797
2023-02-06 13:59:31 | Train | Epoch[067/600] Iteration[028/030] Train loss: 0.0798
2023-02-06 13:59:31 | Train | Epoch[067/600] Iteration[029/030] Train loss: 0.0799
2023-02-06 13:59:31 | Train | Epoch[067/600] Iteration[030/030] Train loss: 0.0798
2023-02-06 13:59:31 | Valid | Epoch[067/600] Iteration[001/008] Valid loss: 0.1513
2023-02-06 13:59:31 | Valid | Epoch[067/600] Iteration[002/008] Valid loss: 0.1327
2023-02-06 13:59:32 | Valid | Epoch[067/600] Iteration[003/008] Valid loss: 0.1294
2023-02-06 13:59:32 | Valid | Epoch[067/600] Iteration[004/008] Valid loss: 0.1265
2023-02-06 13:59:32 | Valid | Epoch[067/600] Iteration[005/008] Valid loss: 0.1255
2023-02-06 13:59:32 | Valid | Epoch[067/600] Iteration[006/008] Valid loss: 0.1253
2023-02-06 13:59:32 | Valid | Epoch[067/600] Iteration[007/008] Valid loss: 0.1315
2023-02-06 13:59:32 | Valid | Epoch[067/600] Iteration[008/008] Valid loss: 0.1298
2023-02-06 13:59:32 | Valid | Epoch[067/600] MIou: 0.9277095703286715
2023-02-06 13:59:32 | Valid | Epoch[067/600] Pixel Accuracy: 0.987054189046224
2023-02-06 13:59:32 | Valid | Epoch[067/600] Mean Pixel Accuracy: 0.9729626686833666
2023-02-06 13:59:32 | Stage | Epoch[067/600] Train loss:0.0798
2023-02-06 13:59:32 | Stage | Epoch[067/600] Valid loss:0.1298
2023-02-06 13:59:32 | Stage | Epoch[067/600] LR:0.01

2023-02-06 13:59:32 | Train | Epoch[068/600] Iteration[001/030] Train loss: 0.0775
2023-02-06 13:59:33 | Train | Epoch[068/600] Iteration[002/030] Train loss: 0.0776
2023-02-06 13:59:33 | Train | Epoch[068/600] Iteration[003/030] Train loss: 0.0776
2023-02-06 13:59:33 | Train | Epoch[068/600] Iteration[004/030] Train loss: 0.0781
2023-02-06 13:59:33 | Train | Epoch[068/600] Iteration[005/030] Train loss: 0.0783
2023-02-06 13:59:33 | Train | Epoch[068/600] Iteration[006/030] Train loss: 0.0787
2023-02-06 13:59:34 | Train | Epoch[068/600] Iteration[007/030] Train loss: 0.0786
2023-02-06 13:59:34 | Train | Epoch[068/600] Iteration[008/030] Train loss: 0.0783
2023-02-06 13:59:34 | Train | Epoch[068/600] Iteration[009/030] Train loss: 0.0783
2023-02-06 13:59:34 | Train | Epoch[068/600] Iteration[010/030] Train loss: 0.0783
2023-02-06 13:59:35 | Train | Epoch[068/600] Iteration[011/030] Train loss: 0.0781
2023-02-06 13:59:35 | Train | Epoch[068/600] Iteration[012/030] Train loss: 0.0782
2023-02-06 13:59:35 | Train | Epoch[068/600] Iteration[013/030] Train loss: 0.0781
2023-02-06 13:59:35 | Train | Epoch[068/600] Iteration[014/030] Train loss: 0.0780
2023-02-06 13:59:35 | Train | Epoch[068/600] Iteration[015/030] Train loss: 0.0779
2023-02-06 13:59:36 | Train | Epoch[068/600] Iteration[016/030] Train loss: 0.0779
2023-02-06 13:59:36 | Train | Epoch[068/600] Iteration[017/030] Train loss: 0.0779
2023-02-06 13:59:36 | Train | Epoch[068/600] Iteration[018/030] Train loss: 0.0779
2023-02-06 13:59:36 | Train | Epoch[068/600] Iteration[019/030] Train loss: 0.0778
2023-02-06 13:59:36 | Train | Epoch[068/600] Iteration[020/030] Train loss: 0.0777
2023-02-06 13:59:37 | Train | Epoch[068/600] Iteration[021/030] Train loss: 0.0777
2023-02-06 13:59:37 | Train | Epoch[068/600] Iteration[022/030] Train loss: 0.0776
2023-02-06 13:59:37 | Train | Epoch[068/600] Iteration[023/030] Train loss: 0.0776
2023-02-06 13:59:37 | Train | Epoch[068/600] Iteration[024/030] Train loss: 0.0777
2023-02-06 13:59:38 | Train | Epoch[068/600] Iteration[025/030] Train loss: 0.0776
2023-02-06 13:59:38 | Train | Epoch[068/600] Iteration[026/030] Train loss: 0.0778
2023-02-06 13:59:38 | Train | Epoch[068/600] Iteration[027/030] Train loss: 0.0778
2023-02-06 13:59:38 | Train | Epoch[068/600] Iteration[028/030] Train loss: 0.0778
2023-02-06 13:59:38 | Train | Epoch[068/600] Iteration[029/030] Train loss: 0.0778
2023-02-06 13:59:39 | Train | Epoch[068/600] Iteration[030/030] Train loss: 0.0778
2023-02-06 13:59:39 | Valid | Epoch[068/600] Iteration[001/008] Valid loss: 0.1007
2023-02-06 13:59:39 | Valid | Epoch[068/600] Iteration[002/008] Valid loss: 0.1004
2023-02-06 13:59:39 | Valid | Epoch[068/600] Iteration[003/008] Valid loss: 0.1021
2023-02-06 13:59:39 | Valid | Epoch[068/600] Iteration[004/008] Valid loss: 0.1016
2023-02-06 13:59:39 | Valid | Epoch[068/600] Iteration[005/008] Valid loss: 0.1026
2023-02-06 13:59:39 | Valid | Epoch[068/600] Iteration[006/008] Valid loss: 0.1024
2023-02-06 13:59:39 | Valid | Epoch[068/600] Iteration[007/008] Valid loss: 0.1022
2023-02-06 13:59:39 | Valid | Epoch[068/600] Iteration[008/008] Valid loss: 0.1022
2023-02-06 13:59:39 | Valid | Epoch[068/600] MIou: 0.8612828946653842
2023-02-06 13:59:39 | Valid | Epoch[068/600] Pixel Accuracy: 0.9768155415852865
2023-02-06 13:59:39 | Valid | Epoch[068/600] Mean Pixel Accuracy: 0.8790630269799073
2023-02-06 13:59:39 | Stage | Epoch[068/600] Train loss:0.0778
2023-02-06 13:59:39 | Stage | Epoch[068/600] Valid loss:0.1022
2023-02-06 13:59:39 | Stage | Epoch[068/600] LR:0.01

2023-02-06 13:59:40 | Train | Epoch[069/600] Iteration[001/030] Train loss: 0.0786
2023-02-06 13:59:40 | Train | Epoch[069/600] Iteration[002/030] Train loss: 0.0773
2023-02-06 13:59:40 | Train | Epoch[069/600] Iteration[003/030] Train loss: 0.0768
2023-02-06 13:59:40 | Train | Epoch[069/600] Iteration[004/030] Train loss: 0.0768
2023-02-06 13:59:41 | Train | Epoch[069/600] Iteration[005/030] Train loss: 0.0769
2023-02-06 13:59:41 | Train | Epoch[069/600] Iteration[006/030] Train loss: 0.0769
2023-02-06 13:59:41 | Train | Epoch[069/600] Iteration[007/030] Train loss: 0.0770
2023-02-06 13:59:41 | Train | Epoch[069/600] Iteration[008/030] Train loss: 0.0770
2023-02-06 13:59:41 | Train | Epoch[069/600] Iteration[009/030] Train loss: 0.0769
2023-02-06 13:59:42 | Train | Epoch[069/600] Iteration[010/030] Train loss: 0.0767
2023-02-06 13:59:42 | Train | Epoch[069/600] Iteration[011/030] Train loss: 0.0766
2023-02-06 13:59:42 | Train | Epoch[069/600] Iteration[012/030] Train loss: 0.0766
2023-02-06 13:59:42 | Train | Epoch[069/600] Iteration[013/030] Train loss: 0.0766
2023-02-06 13:59:43 | Train | Epoch[069/600] Iteration[014/030] Train loss: 0.0766
2023-02-06 13:59:43 | Train | Epoch[069/600] Iteration[015/030] Train loss: 0.0765
2023-02-06 13:59:43 | Train | Epoch[069/600] Iteration[016/030] Train loss: 0.0764
2023-02-06 13:59:43 | Train | Epoch[069/600] Iteration[017/030] Train loss: 0.0764
2023-02-06 13:59:43 | Train | Epoch[069/600] Iteration[018/030] Train loss: 0.0763
2023-02-06 13:59:44 | Train | Epoch[069/600] Iteration[019/030] Train loss: 0.0762
2023-02-06 13:59:44 | Train | Epoch[069/600] Iteration[020/030] Train loss: 0.0762
2023-02-06 13:59:44 | Train | Epoch[069/600] Iteration[021/030] Train loss: 0.0762
2023-02-06 13:59:44 | Train | Epoch[069/600] Iteration[022/030] Train loss: 0.0763
2023-02-06 13:59:45 | Train | Epoch[069/600] Iteration[023/030] Train loss: 0.0763
2023-02-06 13:59:45 | Train | Epoch[069/600] Iteration[024/030] Train loss: 0.0762
2023-02-06 13:59:45 | Train | Epoch[069/600] Iteration[025/030] Train loss: 0.0762
2023-02-06 13:59:45 | Train | Epoch[069/600] Iteration[026/030] Train loss: 0.0761
2023-02-06 13:59:45 | Train | Epoch[069/600] Iteration[027/030] Train loss: 0.0761
2023-02-06 13:59:46 | Train | Epoch[069/600] Iteration[028/030] Train loss: 0.0761
2023-02-06 13:59:46 | Train | Epoch[069/600] Iteration[029/030] Train loss: 0.0763
2023-02-06 13:59:46 | Train | Epoch[069/600] Iteration[030/030] Train loss: 0.0762
2023-02-06 13:59:46 | Valid | Epoch[069/600] Iteration[001/008] Valid loss: 0.1046
2023-02-06 13:59:46 | Valid | Epoch[069/600] Iteration[002/008] Valid loss: 0.1026
2023-02-06 13:59:46 | Valid | Epoch[069/600] Iteration[003/008] Valid loss: 0.1023
2023-02-06 13:59:47 | Valid | Epoch[069/600] Iteration[004/008] Valid loss: 0.1015
2023-02-06 13:59:47 | Valid | Epoch[069/600] Iteration[005/008] Valid loss: 0.1012
2023-02-06 13:59:47 | Valid | Epoch[069/600] Iteration[006/008] Valid loss: 0.1016
2023-02-06 13:59:47 | Valid | Epoch[069/600] Iteration[007/008] Valid loss: 0.1026
2023-02-06 13:59:47 | Valid | Epoch[069/600] Iteration[008/008] Valid loss: 0.1021
2023-02-06 13:59:47 | Valid | Epoch[069/600] MIou: 0.8718521443097149
2023-02-06 13:59:47 | Valid | Epoch[069/600] Pixel Accuracy: 0.9785931905110677
2023-02-06 13:59:47 | Valid | Epoch[069/600] Mean Pixel Accuracy: 0.8887265446159591
2023-02-06 13:59:47 | Stage | Epoch[069/600] Train loss:0.0762
2023-02-06 13:59:47 | Stage | Epoch[069/600] Valid loss:0.1021
2023-02-06 13:59:47 | Stage | Epoch[069/600] LR:0.01

2023-02-06 13:59:47 | Train | Epoch[070/600] Iteration[001/030] Train loss: 0.0751
2023-02-06 13:59:48 | Train | Epoch[070/600] Iteration[002/030] Train loss: 0.0743
2023-02-06 13:59:48 | Train | Epoch[070/600] Iteration[003/030] Train loss: 0.0745
2023-02-06 13:59:48 | Train | Epoch[070/600] Iteration[004/030] Train loss: 0.0746
2023-02-06 13:59:48 | Train | Epoch[070/600] Iteration[005/030] Train loss: 0.0746
2023-02-06 13:59:48 | Train | Epoch[070/600] Iteration[006/030] Train loss: 0.0749
2023-02-06 13:59:49 | Train | Epoch[070/600] Iteration[007/030] Train loss: 0.0748
2023-02-06 13:59:49 | Train | Epoch[070/600] Iteration[008/030] Train loss: 0.0753
2023-02-06 13:59:49 | Train | Epoch[070/600] Iteration[009/030] Train loss: 0.0752
2023-02-06 13:59:49 | Train | Epoch[070/600] Iteration[010/030] Train loss: 0.0751
2023-02-06 13:59:50 | Train | Epoch[070/600] Iteration[011/030] Train loss: 0.0750
2023-02-06 13:59:50 | Train | Epoch[070/600] Iteration[012/030] Train loss: 0.0751
2023-02-06 13:59:50 | Train | Epoch[070/600] Iteration[013/030] Train loss: 0.0751
2023-02-06 13:59:50 | Train | Epoch[070/600] Iteration[014/030] Train loss: 0.0751
2023-02-06 13:59:50 | Train | Epoch[070/600] Iteration[015/030] Train loss: 0.0750
2023-02-06 13:59:51 | Train | Epoch[070/600] Iteration[016/030] Train loss: 0.0751
2023-02-06 13:59:51 | Train | Epoch[070/600] Iteration[017/030] Train loss: 0.0751
2023-02-06 13:59:51 | Train | Epoch[070/600] Iteration[018/030] Train loss: 0.0751
2023-02-06 13:59:51 | Train | Epoch[070/600] Iteration[019/030] Train loss: 0.0752
2023-02-06 13:59:51 | Train | Epoch[070/600] Iteration[020/030] Train loss: 0.0751
2023-02-06 13:59:52 | Train | Epoch[070/600] Iteration[021/030] Train loss: 0.0750
2023-02-06 13:59:52 | Train | Epoch[070/600] Iteration[022/030] Train loss: 0.0750
2023-02-06 13:59:52 | Train | Epoch[070/600] Iteration[023/030] Train loss: 0.0749
2023-02-06 13:59:52 | Train | Epoch[070/600] Iteration[024/030] Train loss: 0.0749
2023-02-06 13:59:53 | Train | Epoch[070/600] Iteration[025/030] Train loss: 0.0749
2023-02-06 13:59:53 | Train | Epoch[070/600] Iteration[026/030] Train loss: 0.0749
2023-02-06 13:59:53 | Train | Epoch[070/600] Iteration[027/030] Train loss: 0.0748
2023-02-06 13:59:53 | Train | Epoch[070/600] Iteration[028/030] Train loss: 0.0748
2023-02-06 13:59:53 | Train | Epoch[070/600] Iteration[029/030] Train loss: 0.0746
2023-02-06 13:59:54 | Train | Epoch[070/600] Iteration[030/030] Train loss: 0.0749
2023-02-06 13:59:54 | Valid | Epoch[070/600] Iteration[001/008] Valid loss: 0.4376
2023-02-06 13:59:54 | Valid | Epoch[070/600] Iteration[002/008] Valid loss: 0.3673
2023-02-06 13:59:54 | Valid | Epoch[070/600] Iteration[003/008] Valid loss: 0.3756
2023-02-06 13:59:54 | Valid | Epoch[070/600] Iteration[004/008] Valid loss: 0.3684
2023-02-06 13:59:54 | Valid | Epoch[070/600] Iteration[005/008] Valid loss: 0.3731
2023-02-06 13:59:54 | Valid | Epoch[070/600] Iteration[006/008] Valid loss: 0.3637
2023-02-06 13:59:54 | Valid | Epoch[070/600] Iteration[007/008] Valid loss: 0.3908
2023-02-06 13:59:54 | Valid | Epoch[070/600] Iteration[008/008] Valid loss: 0.3959
2023-02-06 13:59:54 | Valid | Epoch[070/600] MIou: 0.8871140169640246
2023-02-06 13:59:54 | Valid | Epoch[070/600] Pixel Accuracy: 0.9776178995768229
2023-02-06 13:59:54 | Valid | Epoch[070/600] Mean Pixel Accuracy: 0.9804126412665466
2023-02-06 13:59:54 | Stage | Epoch[070/600] Train loss:0.0749
2023-02-06 13:59:54 | Stage | Epoch[070/600] Valid loss:0.3959
2023-02-06 13:59:54 | Stage | Epoch[070/600] LR:0.01

2023-02-06 13:59:55 | Train | Epoch[071/600] Iteration[001/030] Train loss: 0.0741
2023-02-06 13:59:55 | Train | Epoch[071/600] Iteration[002/030] Train loss: 0.0735
2023-02-06 13:59:55 | Train | Epoch[071/600] Iteration[003/030] Train loss: 0.0727
2023-02-06 13:59:56 | Train | Epoch[071/600] Iteration[004/030] Train loss: 0.0731
2023-02-06 13:59:56 | Train | Epoch[071/600] Iteration[005/030] Train loss: 0.0733
2023-02-06 13:59:56 | Train | Epoch[071/600] Iteration[006/030] Train loss: 0.0737
2023-02-06 13:59:56 | Train | Epoch[071/600] Iteration[007/030] Train loss: 0.0735
2023-02-06 13:59:56 | Train | Epoch[071/600] Iteration[008/030] Train loss: 0.0737
2023-02-06 13:59:57 | Train | Epoch[071/600] Iteration[009/030] Train loss: 0.0735
2023-02-06 13:59:57 | Train | Epoch[071/600] Iteration[010/030] Train loss: 0.0734
2023-02-06 13:59:57 | Train | Epoch[071/600] Iteration[011/030] Train loss: 0.0733
2023-02-06 13:59:57 | Train | Epoch[071/600] Iteration[012/030] Train loss: 0.0733
2023-02-06 13:59:58 | Train | Epoch[071/600] Iteration[013/030] Train loss: 0.0734
2023-02-06 13:59:58 | Train | Epoch[071/600] Iteration[014/030] Train loss: 0.0736
2023-02-06 13:59:58 | Train | Epoch[071/600] Iteration[015/030] Train loss: 0.0737
2023-02-06 13:59:58 | Train | Epoch[071/600] Iteration[016/030] Train loss: 0.0736
2023-02-06 13:59:58 | Train | Epoch[071/600] Iteration[017/030] Train loss: 0.0736
2023-02-06 13:59:59 | Train | Epoch[071/600] Iteration[018/030] Train loss: 0.0735
2023-02-06 13:59:59 | Train | Epoch[071/600] Iteration[019/030] Train loss: 0.0735
2023-02-06 13:59:59 | Train | Epoch[071/600] Iteration[020/030] Train loss: 0.0735
2023-02-06 13:59:59 | Train | Epoch[071/600] Iteration[021/030] Train loss: 0.0734
2023-02-06 13:59:59 | Train | Epoch[071/600] Iteration[022/030] Train loss: 0.0736
2023-02-06 14:00:00 | Train | Epoch[071/600] Iteration[023/030] Train loss: 0.0736
2023-02-06 14:00:00 | Train | Epoch[071/600] Iteration[024/030] Train loss: 0.0736
2023-02-06 14:00:00 | Train | Epoch[071/600] Iteration[025/030] Train loss: 0.0736
2023-02-06 14:00:00 | Train | Epoch[071/600] Iteration[026/030] Train loss: 0.0737
2023-02-06 14:00:01 | Train | Epoch[071/600] Iteration[027/030] Train loss: 0.0736
2023-02-06 14:00:01 | Train | Epoch[071/600] Iteration[028/030] Train loss: 0.0736
2023-02-06 14:00:01 | Train | Epoch[071/600] Iteration[029/030] Train loss: 0.0737
2023-02-06 14:00:01 | Train | Epoch[071/600] Iteration[030/030] Train loss: 0.0737
2023-02-06 14:00:01 | Valid | Epoch[071/600] Iteration[001/008] Valid loss: 0.1180
2023-02-06 14:00:02 | Valid | Epoch[071/600] Iteration[002/008] Valid loss: 0.1051
2023-02-06 14:00:02 | Valid | Epoch[071/600] Iteration[003/008] Valid loss: 0.1043
2023-02-06 14:00:02 | Valid | Epoch[071/600] Iteration[004/008] Valid loss: 0.1036
2023-02-06 14:00:02 | Valid | Epoch[071/600] Iteration[005/008] Valid loss: 0.1051
2023-02-06 14:00:02 | Valid | Epoch[071/600] Iteration[006/008] Valid loss: 0.1046
2023-02-06 14:00:02 | Valid | Epoch[071/600] Iteration[007/008] Valid loss: 0.1068
2023-02-06 14:00:02 | Valid | Epoch[071/600] Iteration[008/008] Valid loss: 0.1062
2023-02-06 14:00:02 | Valid | Epoch[071/600] MIou: 0.9256857091762515
2023-02-06 14:00:02 | Valid | Epoch[071/600] Pixel Accuracy: 0.9870783487955729
2023-02-06 14:00:02 | Valid | Epoch[071/600] Mean Pixel Accuracy: 0.9570296620591164
2023-02-06 14:00:02 | Stage | Epoch[071/600] Train loss:0.0737
2023-02-06 14:00:02 | Stage | Epoch[071/600] Valid loss:0.1062
2023-02-06 14:00:02 | Stage | Epoch[071/600] LR:0.01

2023-02-06 14:00:02 | Train | Epoch[072/600] Iteration[001/030] Train loss: 0.0746
2023-02-06 14:00:03 | Train | Epoch[072/600] Iteration[002/030] Train loss: 0.0736
2023-02-06 14:00:03 | Train | Epoch[072/600] Iteration[003/030] Train loss: 0.0725
2023-02-06 14:00:03 | Train | Epoch[072/600] Iteration[004/030] Train loss: 0.0733
2023-02-06 14:00:03 | Train | Epoch[072/600] Iteration[005/030] Train loss: 0.0732
2023-02-06 14:00:03 | Train | Epoch[072/600] Iteration[006/030] Train loss: 0.0731
2023-02-06 14:00:04 | Train | Epoch[072/600] Iteration[007/030] Train loss: 0.0730
2023-02-06 14:00:04 | Train | Epoch[072/600] Iteration[008/030] Train loss: 0.0729
2023-02-06 14:00:04 | Train | Epoch[072/600] Iteration[009/030] Train loss: 0.0728
2023-02-06 14:00:04 | Train | Epoch[072/600] Iteration[010/030] Train loss: 0.0727
2023-02-06 14:00:05 | Train | Epoch[072/600] Iteration[011/030] Train loss: 0.0729
2023-02-06 14:00:05 | Train | Epoch[072/600] Iteration[012/030] Train loss: 0.0729
2023-02-06 14:00:05 | Train | Epoch[072/600] Iteration[013/030] Train loss: 0.0730
2023-02-06 14:00:05 | Train | Epoch[072/600] Iteration[014/030] Train loss: 0.0730
2023-02-06 14:00:05 | Train | Epoch[072/600] Iteration[015/030] Train loss: 0.0731
2023-02-06 14:00:06 | Train | Epoch[072/600] Iteration[016/030] Train loss: 0.0730
2023-02-06 14:00:06 | Train | Epoch[072/600] Iteration[017/030] Train loss: 0.0729
2023-02-06 14:00:06 | Train | Epoch[072/600] Iteration[018/030] Train loss: 0.0728
2023-02-06 14:00:06 | Train | Epoch[072/600] Iteration[019/030] Train loss: 0.0727
2023-02-06 14:00:07 | Train | Epoch[072/600] Iteration[020/030] Train loss: 0.0726
2023-02-06 14:00:07 | Train | Epoch[072/600] Iteration[021/030] Train loss: 0.0725
2023-02-06 14:00:07 | Train | Epoch[072/600] Iteration[022/030] Train loss: 0.0724
2023-02-06 14:00:07 | Train | Epoch[072/600] Iteration[023/030] Train loss: 0.0724
2023-02-06 14:00:07 | Train | Epoch[072/600] Iteration[024/030] Train loss: 0.0723
2023-02-06 14:00:08 | Train | Epoch[072/600] Iteration[025/030] Train loss: 0.0722
2023-02-06 14:00:08 | Train | Epoch[072/600] Iteration[026/030] Train loss: 0.0722
2023-02-06 14:00:08 | Train | Epoch[072/600] Iteration[027/030] Train loss: 0.0722
2023-02-06 14:00:08 | Train | Epoch[072/600] Iteration[028/030] Train loss: 0.0721
2023-02-06 14:00:09 | Train | Epoch[072/600] Iteration[029/030] Train loss: 0.0720
2023-02-06 14:00:09 | Train | Epoch[072/600] Iteration[030/030] Train loss: 0.0719
2023-02-06 14:00:09 | Valid | Epoch[072/600] Iteration[001/008] Valid loss: 0.7367
2023-02-06 14:00:09 | Valid | Epoch[072/600] Iteration[002/008] Valid loss: 0.6712
2023-02-06 14:00:09 | Valid | Epoch[072/600] Iteration[003/008] Valid loss: 0.6734
2023-02-06 14:00:09 | Valid | Epoch[072/600] Iteration[004/008] Valid loss: 0.6626
2023-02-06 14:00:09 | Valid | Epoch[072/600] Iteration[005/008] Valid loss: 0.6720
2023-02-06 14:00:09 | Valid | Epoch[072/600] Iteration[006/008] Valid loss: 0.6510
2023-02-06 14:00:09 | Valid | Epoch[072/600] Iteration[007/008] Valid loss: 0.6867
2023-02-06 14:00:09 | Valid | Epoch[072/600] Iteration[008/008] Valid loss: 0.7136
2023-02-06 14:00:09 | Valid | Epoch[072/600] MIou: 0.8603942483183538
2023-02-06 14:00:09 | Valid | Epoch[072/600] Pixel Accuracy: 0.9707120259602865
2023-02-06 14:00:09 | Valid | Epoch[072/600] Mean Pixel Accuracy: 0.9786331485393533
2023-02-06 14:00:09 | Stage | Epoch[072/600] Train loss:0.0719
2023-02-06 14:00:09 | Stage | Epoch[072/600] Valid loss:0.7136
2023-02-06 14:00:09 | Stage | Epoch[072/600] LR:0.01

2023-02-06 14:00:10 | Train | Epoch[073/600] Iteration[001/030] Train loss: 0.0697
2023-02-06 14:00:10 | Train | Epoch[073/600] Iteration[002/030] Train loss: 0.0692
2023-02-06 14:00:10 | Train | Epoch[073/600] Iteration[003/030] Train loss: 0.0699
2023-02-06 14:00:11 | Train | Epoch[073/600] Iteration[004/030] Train loss: 0.0698
2023-02-06 14:00:11 | Train | Epoch[073/600] Iteration[005/030] Train loss: 0.0709
2023-02-06 14:00:11 | Train | Epoch[073/600] Iteration[006/030] Train loss: 0.0706
2023-02-06 14:00:11 | Train | Epoch[073/600] Iteration[007/030] Train loss: 0.0705
2023-02-06 14:00:11 | Train | Epoch[073/600] Iteration[008/030] Train loss: 0.0704
2023-02-06 14:00:12 | Train | Epoch[073/600] Iteration[009/030] Train loss: 0.0704
2023-02-06 14:00:12 | Train | Epoch[073/600] Iteration[010/030] Train loss: 0.0705
2023-02-06 14:00:12 | Train | Epoch[073/600] Iteration[011/030] Train loss: 0.0704
2023-02-06 14:00:12 | Train | Epoch[073/600] Iteration[012/030] Train loss: 0.0703
2023-02-06 14:00:12 | Train | Epoch[073/600] Iteration[013/030] Train loss: 0.0706
2023-02-06 14:00:13 | Train | Epoch[073/600] Iteration[014/030] Train loss: 0.0706
2023-02-06 14:00:13 | Train | Epoch[073/600] Iteration[015/030] Train loss: 0.0705
2023-02-06 14:00:13 | Train | Epoch[073/600] Iteration[016/030] Train loss: 0.0704
2023-02-06 14:00:13 | Train | Epoch[073/600] Iteration[017/030] Train loss: 0.0704
2023-02-06 14:00:14 | Train | Epoch[073/600] Iteration[018/030] Train loss: 0.0703
2023-02-06 14:00:14 | Train | Epoch[073/600] Iteration[019/030] Train loss: 0.0703
2023-02-06 14:00:14 | Train | Epoch[073/600] Iteration[020/030] Train loss: 0.0703
2023-02-06 14:00:14 | Train | Epoch[073/600] Iteration[021/030] Train loss: 0.0703
2023-02-06 14:00:14 | Train | Epoch[073/600] Iteration[022/030] Train loss: 0.0702
2023-02-06 14:00:15 | Train | Epoch[073/600] Iteration[023/030] Train loss: 0.0703
2023-02-06 14:00:15 | Train | Epoch[073/600] Iteration[024/030] Train loss: 0.0703
2023-02-06 14:00:15 | Train | Epoch[073/600] Iteration[025/030] Train loss: 0.0704
2023-02-06 14:00:15 | Train | Epoch[073/600] Iteration[026/030] Train loss: 0.0703
2023-02-06 14:00:16 | Train | Epoch[073/600] Iteration[027/030] Train loss: 0.0703
2023-02-06 14:00:16 | Train | Epoch[073/600] Iteration[028/030] Train loss: 0.0702
2023-02-06 14:00:16 | Train | Epoch[073/600] Iteration[029/030] Train loss: 0.0702
2023-02-06 14:00:16 | Train | Epoch[073/600] Iteration[030/030] Train loss: 0.0702
2023-02-06 14:00:16 | Valid | Epoch[073/600] Iteration[001/008] Valid loss: 0.7231
2023-02-06 14:00:16 | Valid | Epoch[073/600] Iteration[002/008] Valid loss: 0.6882
2023-02-06 14:00:17 | Valid | Epoch[073/600] Iteration[003/008] Valid loss: 0.6947
2023-02-06 14:00:17 | Valid | Epoch[073/600] Iteration[004/008] Valid loss: 0.6946
2023-02-06 14:00:17 | Valid | Epoch[073/600] Iteration[005/008] Valid loss: 0.7003
2023-02-06 14:00:17 | Valid | Epoch[073/600] Iteration[006/008] Valid loss: 0.6933
2023-02-06 14:00:17 | Valid | Epoch[073/600] Iteration[007/008] Valid loss: 0.7322
2023-02-06 14:00:17 | Valid | Epoch[073/600] Iteration[008/008] Valid loss: 0.7476
2023-02-06 14:00:17 | Valid | Epoch[073/600] MIou: 0.85517413851337
2023-02-06 14:00:17 | Valid | Epoch[073/600] Pixel Accuracy: 0.969146728515625
2023-02-06 14:00:17 | Valid | Epoch[073/600] Mean Pixel Accuracy: 0.9803723876253987
2023-02-06 14:00:17 | Stage | Epoch[073/600] Train loss:0.0702
2023-02-06 14:00:17 | Stage | Epoch[073/600] Valid loss:0.7476
2023-02-06 14:00:17 | Stage | Epoch[073/600] LR:0.01

2023-02-06 14:00:17 | Train | Epoch[074/600] Iteration[001/030] Train loss: 0.0728
2023-02-06 14:00:18 | Train | Epoch[074/600] Iteration[002/030] Train loss: 0.0702
2023-02-06 14:00:18 | Train | Epoch[074/600] Iteration[003/030] Train loss: 0.0701
2023-02-06 14:00:18 | Train | Epoch[074/600] Iteration[004/030] Train loss: 0.0698
2023-02-06 14:00:18 | Train | Epoch[074/600] Iteration[005/030] Train loss: 0.0699
2023-02-06 14:00:18 | Train | Epoch[074/600] Iteration[006/030] Train loss: 0.0702
2023-02-06 14:00:19 | Train | Epoch[074/600] Iteration[007/030] Train loss: 0.0700
2023-02-06 14:00:19 | Train | Epoch[074/600] Iteration[008/030] Train loss: 0.0699
2023-02-06 14:00:19 | Train | Epoch[074/600] Iteration[009/030] Train loss: 0.0698
2023-02-06 14:00:19 | Train | Epoch[074/600] Iteration[010/030] Train loss: 0.0697
2023-02-06 14:00:20 | Train | Epoch[074/600] Iteration[011/030] Train loss: 0.0696
2023-02-06 14:00:20 | Train | Epoch[074/600] Iteration[012/030] Train loss: 0.0696
2023-02-06 14:00:20 | Train | Epoch[074/600] Iteration[013/030] Train loss: 0.0695
2023-02-06 14:00:20 | Train | Epoch[074/600] Iteration[014/030] Train loss: 0.0697
2023-02-06 14:00:20 | Train | Epoch[074/600] Iteration[015/030] Train loss: 0.0695
2023-02-06 14:00:21 | Train | Epoch[074/600] Iteration[016/030] Train loss: 0.0695
2023-02-06 14:00:21 | Train | Epoch[074/600] Iteration[017/030] Train loss: 0.0694
2023-02-06 14:00:21 | Train | Epoch[074/600] Iteration[018/030] Train loss: 0.0694
2023-02-06 14:00:21 | Train | Epoch[074/600] Iteration[019/030] Train loss: 0.0692
2023-02-06 14:00:21 | Train | Epoch[074/600] Iteration[020/030] Train loss: 0.0695
2023-02-06 14:00:22 | Train | Epoch[074/600] Iteration[021/030] Train loss: 0.0694
2023-02-06 14:00:22 | Train | Epoch[074/600] Iteration[022/030] Train loss: 0.0693
2023-02-06 14:00:22 | Train | Epoch[074/600] Iteration[023/030] Train loss: 0.0692
2023-02-06 14:00:22 | Train | Epoch[074/600] Iteration[024/030] Train loss: 0.0692
2023-02-06 14:00:23 | Train | Epoch[074/600] Iteration[025/030] Train loss: 0.0692
2023-02-06 14:00:23 | Train | Epoch[074/600] Iteration[026/030] Train loss: 0.0692
2023-02-06 14:00:23 | Train | Epoch[074/600] Iteration[027/030] Train loss: 0.0692
2023-02-06 14:00:23 | Train | Epoch[074/600] Iteration[028/030] Train loss: 0.0692
2023-02-06 14:00:23 | Train | Epoch[074/600] Iteration[029/030] Train loss: 0.0694
2023-02-06 14:00:24 | Train | Epoch[074/600] Iteration[030/030] Train loss: 0.0694
2023-02-06 14:00:24 | Valid | Epoch[074/600] Iteration[001/008] Valid loss: 1.0102
2023-02-06 14:00:24 | Valid | Epoch[074/600] Iteration[002/008] Valid loss: 0.9776
2023-02-06 14:00:24 | Valid | Epoch[074/600] Iteration[003/008] Valid loss: 1.0243
2023-02-06 14:00:24 | Valid | Epoch[074/600] Iteration[004/008] Valid loss: 1.0351
2023-02-06 14:00:24 | Valid | Epoch[074/600] Iteration[005/008] Valid loss: 1.0654
2023-02-06 14:00:24 | Valid | Epoch[074/600] Iteration[006/008] Valid loss: 1.0518
2023-02-06 14:00:24 | Valid | Epoch[074/600] Iteration[007/008] Valid loss: 1.1197
2023-02-06 14:00:24 | Valid | Epoch[074/600] Iteration[008/008] Valid loss: 1.1448
2023-02-06 14:00:24 | Valid | Epoch[074/600] MIou: 0.7863515047069631
2023-02-06 14:00:24 | Valid | Epoch[074/600] Pixel Accuracy: 0.9472007751464844
2023-02-06 14:00:24 | Valid | Epoch[074/600] Mean Pixel Accuracy: 0.9703198851507748
2023-02-06 14:00:24 | Stage | Epoch[074/600] Train loss:0.0694
2023-02-06 14:00:24 | Stage | Epoch[074/600] Valid loss:1.1448
2023-02-06 14:00:24 | Stage | Epoch[074/600] LR:0.01

2023-02-06 14:00:25 | Train | Epoch[075/600] Iteration[001/030] Train loss: 0.0681
2023-02-06 14:00:25 | Train | Epoch[075/600] Iteration[002/030] Train loss: 0.0679
2023-02-06 14:00:25 | Train | Epoch[075/600] Iteration[003/030] Train loss: 0.0684
2023-02-06 14:00:25 | Train | Epoch[075/600] Iteration[004/030] Train loss: 0.0693
2023-02-06 14:00:26 | Train | Epoch[075/600] Iteration[005/030] Train loss: 0.0695
2023-02-06 14:00:26 | Train | Epoch[075/600] Iteration[006/030] Train loss: 0.0693
2023-02-06 14:00:26 | Train | Epoch[075/600] Iteration[007/030] Train loss: 0.0692
2023-02-06 14:00:26 | Train | Epoch[075/600] Iteration[008/030] Train loss: 0.0691
2023-02-06 14:00:27 | Train | Epoch[075/600] Iteration[009/030] Train loss: 0.0692
2023-02-06 14:00:27 | Train | Epoch[075/600] Iteration[010/030] Train loss: 0.0695
2023-02-06 14:00:27 | Train | Epoch[075/600] Iteration[011/030] Train loss: 0.0695
2023-02-06 14:00:27 | Train | Epoch[075/600] Iteration[012/030] Train loss: 0.0693
2023-02-06 14:00:27 | Train | Epoch[075/600] Iteration[013/030] Train loss: 0.0691
2023-02-06 14:00:28 | Train | Epoch[075/600] Iteration[014/030] Train loss: 0.0690
2023-02-06 14:00:28 | Train | Epoch[075/600] Iteration[015/030] Train loss: 0.0689
2023-02-06 14:00:28 | Train | Epoch[075/600] Iteration[016/030] Train loss: 0.0687
2023-02-06 14:00:28 | Train | Epoch[075/600] Iteration[017/030] Train loss: 0.0687
2023-02-06 14:00:29 | Train | Epoch[075/600] Iteration[018/030] Train loss: 0.0689
2023-02-06 14:00:29 | Train | Epoch[075/600] Iteration[019/030] Train loss: 0.0688
2023-02-06 14:00:29 | Train | Epoch[075/600] Iteration[020/030] Train loss: 0.0689
2023-02-06 14:00:29 | Train | Epoch[075/600] Iteration[021/030] Train loss: 0.0688
2023-02-06 14:00:29 | Train | Epoch[075/600] Iteration[022/030] Train loss: 0.0687
2023-02-06 14:00:30 | Train | Epoch[075/600] Iteration[023/030] Train loss: 0.0686
2023-02-06 14:00:30 | Train | Epoch[075/600] Iteration[024/030] Train loss: 0.0686
2023-02-06 14:00:30 | Train | Epoch[075/600] Iteration[025/030] Train loss: 0.0686
2023-02-06 14:00:30 | Train | Epoch[075/600] Iteration[026/030] Train loss: 0.0686
2023-02-06 14:00:31 | Train | Epoch[075/600] Iteration[027/030] Train loss: 0.0686
2023-02-06 14:00:31 | Train | Epoch[075/600] Iteration[028/030] Train loss: 0.0688
2023-02-06 14:00:31 | Train | Epoch[075/600] Iteration[029/030] Train loss: 0.0688
2023-02-06 14:00:31 | Train | Epoch[075/600] Iteration[030/030] Train loss: 0.0688
2023-02-06 14:00:31 | Valid | Epoch[075/600] Iteration[001/008] Valid loss: 0.5654
2023-02-06 14:00:31 | Valid | Epoch[075/600] Iteration[002/008] Valid loss: 0.4850
2023-02-06 14:00:32 | Valid | Epoch[075/600] Iteration[003/008] Valid loss: 0.5086
2023-02-06 14:00:32 | Valid | Epoch[075/600] Iteration[004/008] Valid loss: 0.5070
2023-02-06 14:00:32 | Valid | Epoch[075/600] Iteration[005/008] Valid loss: 0.5275
2023-02-06 14:00:32 | Valid | Epoch[075/600] Iteration[006/008] Valid loss: 0.5170
2023-02-06 14:00:32 | Valid | Epoch[075/600] Iteration[007/008] Valid loss: 0.5616
2023-02-06 14:00:32 | Valid | Epoch[075/600] Iteration[008/008] Valid loss: 0.5667
2023-02-06 14:00:32 | Valid | Epoch[075/600] MIou: 0.8702489257780837
2023-02-06 14:00:32 | Valid | Epoch[075/600] Pixel Accuracy: 0.9732742309570312
2023-02-06 14:00:32 | Valid | Epoch[075/600] Mean Pixel Accuracy: 0.9807135356612449
2023-02-06 14:00:32 | Stage | Epoch[075/600] Train loss:0.0688
2023-02-06 14:00:32 | Stage | Epoch[075/600] Valid loss:0.5667
2023-02-06 14:00:32 | Stage | Epoch[075/600] LR:0.01

2023-02-06 14:00:32 | Train | Epoch[076/600] Iteration[001/030] Train loss: 0.0679
2023-02-06 14:00:33 | Train | Epoch[076/600] Iteration[002/030] Train loss: 0.0682
2023-02-06 14:00:33 | Train | Epoch[076/600] Iteration[003/030] Train loss: 0.0680
2023-02-06 14:00:33 | Train | Epoch[076/600] Iteration[004/030] Train loss: 0.0685
2023-02-06 14:00:33 | Train | Epoch[076/600] Iteration[005/030] Train loss: 0.0688
2023-02-06 14:00:33 | Train | Epoch[076/600] Iteration[006/030] Train loss: 0.0687
2023-02-06 14:00:34 | Train | Epoch[076/600] Iteration[007/030] Train loss: 0.0683
2023-02-06 14:00:34 | Train | Epoch[076/600] Iteration[008/030] Train loss: 0.0681
2023-02-06 14:00:34 | Train | Epoch[076/600] Iteration[009/030] Train loss: 0.0683
2023-02-06 14:00:34 | Train | Epoch[076/600] Iteration[010/030] Train loss: 0.0681
2023-02-06 14:00:35 | Train | Epoch[076/600] Iteration[011/030] Train loss: 0.0680
2023-02-06 14:00:35 | Train | Epoch[076/600] Iteration[012/030] Train loss: 0.0678
2023-02-06 14:00:35 | Train | Epoch[076/600] Iteration[013/030] Train loss: 0.0678
2023-02-06 14:00:35 | Train | Epoch[076/600] Iteration[014/030] Train loss: 0.0677
2023-02-06 14:00:35 | Train | Epoch[076/600] Iteration[015/030] Train loss: 0.0677
2023-02-06 14:00:36 | Train | Epoch[076/600] Iteration[016/030] Train loss: 0.0676
2023-02-06 14:00:36 | Train | Epoch[076/600] Iteration[017/030] Train loss: 0.0676
2023-02-06 14:00:36 | Train | Epoch[076/600] Iteration[018/030] Train loss: 0.0675
2023-02-06 14:00:36 | Train | Epoch[076/600] Iteration[019/030] Train loss: 0.0675
2023-02-06 14:00:37 | Train | Epoch[076/600] Iteration[020/030] Train loss: 0.0674
2023-02-06 14:00:37 | Train | Epoch[076/600] Iteration[021/030] Train loss: 0.0675
2023-02-06 14:00:37 | Train | Epoch[076/600] Iteration[022/030] Train loss: 0.0674
2023-02-06 14:00:37 | Train | Epoch[076/600] Iteration[023/030] Train loss: 0.0674
2023-02-06 14:00:37 | Train | Epoch[076/600] Iteration[024/030] Train loss: 0.0673
2023-02-06 14:00:38 | Train | Epoch[076/600] Iteration[025/030] Train loss: 0.0671
2023-02-06 14:00:38 | Train | Epoch[076/600] Iteration[026/030] Train loss: 0.0671
2023-02-06 14:00:38 | Train | Epoch[076/600] Iteration[027/030] Train loss: 0.0670
2023-02-06 14:00:38 | Train | Epoch[076/600] Iteration[028/030] Train loss: 0.0669
2023-02-06 14:00:39 | Train | Epoch[076/600] Iteration[029/030] Train loss: 0.0669
2023-02-06 14:00:39 | Train | Epoch[076/600] Iteration[030/030] Train loss: 0.0669
2023-02-06 14:00:39 | Valid | Epoch[076/600] Iteration[001/008] Valid loss: 0.0995
2023-02-06 14:00:39 | Valid | Epoch[076/600] Iteration[002/008] Valid loss: 0.0991
2023-02-06 14:00:39 | Valid | Epoch[076/600] Iteration[003/008] Valid loss: 0.1015
2023-02-06 14:00:39 | Valid | Epoch[076/600] Iteration[004/008] Valid loss: 0.1012
2023-02-06 14:00:39 | Valid | Epoch[076/600] Iteration[005/008] Valid loss: 0.1020
2023-02-06 14:00:39 | Valid | Epoch[076/600] Iteration[006/008] Valid loss: 0.1014
2023-02-06 14:00:39 | Valid | Epoch[076/600] Iteration[007/008] Valid loss: 0.0999
2023-02-06 14:00:39 | Valid | Epoch[076/600] Iteration[008/008] Valid loss: 0.1011
2023-02-06 14:00:39 | Valid | Epoch[076/600] MIou: 0.7759168538766956
2023-02-06 14:00:39 | Valid | Epoch[076/600] Pixel Accuracy: 0.9630088806152344
2023-02-06 14:00:39 | Valid | Epoch[076/600] Mean Pixel Accuracy: 0.795743705530637
2023-02-06 14:00:39 | Stage | Epoch[076/600] Train loss:0.0669
2023-02-06 14:00:39 | Stage | Epoch[076/600] Valid loss:0.1011
2023-02-06 14:00:39 | Stage | Epoch[076/600] LR:0.01

2023-02-06 14:00:40 | Train | Epoch[077/600] Iteration[001/030] Train loss: 0.0647
2023-02-06 14:00:40 | Train | Epoch[077/600] Iteration[002/030] Train loss: 0.0650
2023-02-06 14:00:40 | Train | Epoch[077/600] Iteration[003/030] Train loss: 0.0665
2023-02-06 14:00:41 | Train | Epoch[077/600] Iteration[004/030] Train loss: 0.0658
2023-02-06 14:00:41 | Train | Epoch[077/600] Iteration[005/030] Train loss: 0.0655
2023-02-06 14:00:41 | Train | Epoch[077/600] Iteration[006/030] Train loss: 0.0654
2023-02-06 14:00:41 | Train | Epoch[077/600] Iteration[007/030] Train loss: 0.0653
2023-02-06 14:00:41 | Train | Epoch[077/600] Iteration[008/030] Train loss: 0.0652
2023-02-06 14:00:42 | Train | Epoch[077/600] Iteration[009/030] Train loss: 0.0652
2023-02-06 14:00:42 | Train | Epoch[077/600] Iteration[010/030] Train loss: 0.0652
2023-02-06 14:00:42 | Train | Epoch[077/600] Iteration[011/030] Train loss: 0.0651
2023-02-06 14:00:42 | Train | Epoch[077/600] Iteration[012/030] Train loss: 0.0652
2023-02-06 14:00:43 | Train | Epoch[077/600] Iteration[013/030] Train loss: 0.0651
2023-02-06 14:00:43 | Train | Epoch[077/600] Iteration[014/030] Train loss: 0.0651
2023-02-06 14:00:43 | Train | Epoch[077/600] Iteration[015/030] Train loss: 0.0651
2023-02-06 14:00:43 | Train | Epoch[077/600] Iteration[016/030] Train loss: 0.0650
2023-02-06 14:00:43 | Train | Epoch[077/600] Iteration[017/030] Train loss: 0.0650
2023-02-06 14:00:44 | Train | Epoch[077/600] Iteration[018/030] Train loss: 0.0649
2023-02-06 14:00:44 | Train | Epoch[077/600] Iteration[019/030] Train loss: 0.0649
2023-02-06 14:00:44 | Train | Epoch[077/600] Iteration[020/030] Train loss: 0.0649
2023-02-06 14:00:44 | Train | Epoch[077/600] Iteration[021/030] Train loss: 0.0648
2023-02-06 14:00:45 | Train | Epoch[077/600] Iteration[022/030] Train loss: 0.0648
2023-02-06 14:00:45 | Train | Epoch[077/600] Iteration[023/030] Train loss: 0.0649
2023-02-06 14:00:45 | Train | Epoch[077/600] Iteration[024/030] Train loss: 0.0650
2023-02-06 14:00:45 | Train | Epoch[077/600] Iteration[025/030] Train loss: 0.0650
2023-02-06 14:00:45 | Train | Epoch[077/600] Iteration[026/030] Train loss: 0.0650
2023-02-06 14:00:46 | Train | Epoch[077/600] Iteration[027/030] Train loss: 0.0650
2023-02-06 14:00:46 | Train | Epoch[077/600] Iteration[028/030] Train loss: 0.0651
2023-02-06 14:00:46 | Train | Epoch[077/600] Iteration[029/030] Train loss: 0.0651
2023-02-06 14:00:46 | Train | Epoch[077/600] Iteration[030/030] Train loss: 0.0650
2023-02-06 14:00:47 | Valid | Epoch[077/600] Iteration[001/008] Valid loss: 0.0878
2023-02-06 14:00:47 | Valid | Epoch[077/600] Iteration[002/008] Valid loss: 0.0873
2023-02-06 14:00:47 | Valid | Epoch[077/600] Iteration[003/008] Valid loss: 0.0880
2023-02-06 14:00:47 | Valid | Epoch[077/600] Iteration[004/008] Valid loss: 0.0872
2023-02-06 14:00:47 | Valid | Epoch[077/600] Iteration[005/008] Valid loss: 0.0876
2023-02-06 14:00:47 | Valid | Epoch[077/600] Iteration[006/008] Valid loss: 0.0867
2023-02-06 14:00:47 | Valid | Epoch[077/600] Iteration[007/008] Valid loss: 0.0854
2023-02-06 14:00:47 | Valid | Epoch[077/600] Iteration[008/008] Valid loss: 0.0860
2023-02-06 14:00:47 | Valid | Epoch[077/600] MIou: 0.8530231781793632
2023-02-06 14:00:47 | Valid | Epoch[077/600] Pixel Accuracy: 0.9757486979166666
2023-02-06 14:00:47 | Valid | Epoch[077/600] Mean Pixel Accuracy: 0.8666326434152869
2023-02-06 14:00:47 | Stage | Epoch[077/600] Train loss:0.0650
2023-02-06 14:00:47 | Stage | Epoch[077/600] Valid loss:0.0860
2023-02-06 14:00:47 | Stage | Epoch[077/600] LR:0.01

2023-02-06 14:00:47 | Train | Epoch[078/600] Iteration[001/030] Train loss: 0.0651
2023-02-06 14:00:48 | Train | Epoch[078/600] Iteration[002/030] Train loss: 0.0636
2023-02-06 14:00:48 | Train | Epoch[078/600] Iteration[003/030] Train loss: 0.0642
2023-02-06 14:00:48 | Train | Epoch[078/600] Iteration[004/030] Train loss: 0.0642
2023-02-06 14:00:48 | Train | Epoch[078/600] Iteration[005/030] Train loss: 0.0641
2023-02-06 14:00:49 | Train | Epoch[078/600] Iteration[006/030] Train loss: 0.0640
2023-02-06 14:00:49 | Train | Epoch[078/600] Iteration[007/030] Train loss: 0.0640
2023-02-06 14:00:49 | Train | Epoch[078/600] Iteration[008/030] Train loss: 0.0640
2023-02-06 14:00:49 | Train | Epoch[078/600] Iteration[009/030] Train loss: 0.0639
2023-02-06 14:00:49 | Train | Epoch[078/600] Iteration[010/030] Train loss: 0.0639
2023-02-06 14:00:50 | Train | Epoch[078/600] Iteration[011/030] Train loss: 0.0637
2023-02-06 14:00:50 | Train | Epoch[078/600] Iteration[012/030] Train loss: 0.0636
2023-02-06 14:00:50 | Train | Epoch[078/600] Iteration[013/030] Train loss: 0.0634
2023-02-06 14:00:50 | Train | Epoch[078/600] Iteration[014/030] Train loss: 0.0636
2023-02-06 14:00:50 | Train | Epoch[078/600] Iteration[015/030] Train loss: 0.0637
2023-02-06 14:00:51 | Train | Epoch[078/600] Iteration[016/030] Train loss: 0.0638
2023-02-06 14:00:51 | Train | Epoch[078/600] Iteration[017/030] Train loss: 0.0638
2023-02-06 14:00:51 | Train | Epoch[078/600] Iteration[018/030] Train loss: 0.0638
2023-02-06 14:00:51 | Train | Epoch[078/600] Iteration[019/030] Train loss: 0.0639
2023-02-06 14:00:52 | Train | Epoch[078/600] Iteration[020/030] Train loss: 0.0638
2023-02-06 14:00:52 | Train | Epoch[078/600] Iteration[021/030] Train loss: 0.0638
2023-02-06 14:00:52 | Train | Epoch[078/600] Iteration[022/030] Train loss: 0.0637
2023-02-06 14:00:52 | Train | Epoch[078/600] Iteration[023/030] Train loss: 0.0637
2023-02-06 14:00:52 | Train | Epoch[078/600] Iteration[024/030] Train loss: 0.0636
2023-02-06 14:00:53 | Train | Epoch[078/600] Iteration[025/030] Train loss: 0.0637
2023-02-06 14:00:53 | Train | Epoch[078/600] Iteration[026/030] Train loss: 0.0638
2023-02-06 14:00:53 | Train | Epoch[078/600] Iteration[027/030] Train loss: 0.0639
2023-02-06 14:00:53 | Train | Epoch[078/600] Iteration[028/030] Train loss: 0.0639
2023-02-06 14:00:54 | Train | Epoch[078/600] Iteration[029/030] Train loss: 0.0638
2023-02-06 14:00:54 | Train | Epoch[078/600] Iteration[030/030] Train loss: 0.0638
2023-02-06 14:00:54 | Valid | Epoch[078/600] Iteration[001/008] Valid loss: 0.1628
2023-02-06 14:00:54 | Valid | Epoch[078/600] Iteration[002/008] Valid loss: 0.1362
2023-02-06 14:00:54 | Valid | Epoch[078/600] Iteration[003/008] Valid loss: 0.1272
2023-02-06 14:00:54 | Valid | Epoch[078/600] Iteration[004/008] Valid loss: 0.1215
2023-02-06 14:00:54 | Valid | Epoch[078/600] Iteration[005/008] Valid loss: 0.1207
2023-02-06 14:00:54 | Valid | Epoch[078/600] Iteration[006/008] Valid loss: 0.1180
2023-02-06 14:00:54 | Valid | Epoch[078/600] Iteration[007/008] Valid loss: 0.1241
2023-02-06 14:00:54 | Valid | Epoch[078/600] Iteration[008/008] Valid loss: 0.1244
2023-02-06 14:00:55 | Valid | Epoch[078/600] MIou: 0.9213891015121687
2023-02-06 14:00:55 | Valid | Epoch[078/600] Pixel Accuracy: 0.9856796264648438
2023-02-06 14:00:55 | Valid | Epoch[078/600] Mean Pixel Accuracy: 0.9748638080285252
2023-02-06 14:00:55 | Stage | Epoch[078/600] Train loss:0.0638
2023-02-06 14:00:55 | Stage | Epoch[078/600] Valid loss:0.1244
2023-02-06 14:00:55 | Stage | Epoch[078/600] LR:0.01

2023-02-06 14:00:55 | Train | Epoch[079/600] Iteration[001/030] Train loss: 0.0630
2023-02-06 14:00:55 | Train | Epoch[079/600] Iteration[002/030] Train loss: 0.0635
2023-02-06 14:00:55 | Train | Epoch[079/600] Iteration[003/030] Train loss: 0.0631
2023-02-06 14:00:56 | Train | Epoch[079/600] Iteration[004/030] Train loss: 0.0630
2023-02-06 14:00:56 | Train | Epoch[079/600] Iteration[005/030] Train loss: 0.0628
2023-02-06 14:00:56 | Train | Epoch[079/600] Iteration[006/030] Train loss: 0.0627
2023-02-06 14:00:56 | Train | Epoch[079/600] Iteration[007/030] Train loss: 0.0633
2023-02-06 14:00:57 | Train | Epoch[079/600] Iteration[008/030] Train loss: 0.0631
2023-02-06 14:00:57 | Train | Epoch[079/600] Iteration[009/030] Train loss: 0.0630
2023-02-06 14:00:57 | Train | Epoch[079/600] Iteration[010/030] Train loss: 0.0628
2023-02-06 14:00:57 | Train | Epoch[079/600] Iteration[011/030] Train loss: 0.0627
2023-02-06 14:00:57 | Train | Epoch[079/600] Iteration[012/030] Train loss: 0.0625
2023-02-06 14:00:58 | Train | Epoch[079/600] Iteration[013/030] Train loss: 0.0625
2023-02-06 14:00:58 | Train | Epoch[079/600] Iteration[014/030] Train loss: 0.0623
2023-02-06 14:00:58 | Train | Epoch[079/600] Iteration[015/030] Train loss: 0.0625
2023-02-06 14:00:58 | Train | Epoch[079/600] Iteration[016/030] Train loss: 0.0625
2023-02-06 14:00:59 | Train | Epoch[079/600] Iteration[017/030] Train loss: 0.0624
2023-02-06 14:00:59 | Train | Epoch[079/600] Iteration[018/030] Train loss: 0.0624
2023-02-06 14:00:59 | Train | Epoch[079/600] Iteration[019/030] Train loss: 0.0625
2023-02-06 14:00:59 | Train | Epoch[079/600] Iteration[020/030] Train loss: 0.0624
2023-02-06 14:00:59 | Train | Epoch[079/600] Iteration[021/030] Train loss: 0.0624
2023-02-06 14:01:00 | Train | Epoch[079/600] Iteration[022/030] Train loss: 0.0625
2023-02-06 14:01:00 | Train | Epoch[079/600] Iteration[023/030] Train loss: 0.0626
2023-02-06 14:01:00 | Train | Epoch[079/600] Iteration[024/030] Train loss: 0.0626
2023-02-06 14:01:00 | Train | Epoch[079/600] Iteration[025/030] Train loss: 0.0628
2023-02-06 14:01:00 | Train | Epoch[079/600] Iteration[026/030] Train loss: 0.0629
2023-02-06 14:01:01 | Train | Epoch[079/600] Iteration[027/030] Train loss: 0.0629
2023-02-06 14:01:01 | Train | Epoch[079/600] Iteration[028/030] Train loss: 0.0629
2023-02-06 14:01:01 | Train | Epoch[079/600] Iteration[029/030] Train loss: 0.0628
2023-02-06 14:01:01 | Train | Epoch[079/600] Iteration[030/030] Train loss: 0.0628
2023-02-06 14:01:02 | Valid | Epoch[079/600] Iteration[001/008] Valid loss: 0.1020
2023-02-06 14:01:02 | Valid | Epoch[079/600] Iteration[002/008] Valid loss: 0.1016
2023-02-06 14:01:02 | Valid | Epoch[079/600] Iteration[003/008] Valid loss: 0.1077
2023-02-06 14:01:02 | Valid | Epoch[079/600] Iteration[004/008] Valid loss: 0.1075
2023-02-06 14:01:02 | Valid | Epoch[079/600] Iteration[005/008] Valid loss: 0.1086
2023-02-06 14:01:02 | Valid | Epoch[079/600] Iteration[006/008] Valid loss: 0.1077
2023-02-06 14:01:02 | Valid | Epoch[079/600] Iteration[007/008] Valid loss: 0.1059
2023-02-06 14:01:02 | Valid | Epoch[079/600] Iteration[008/008] Valid loss: 0.1070
2023-02-06 14:01:02 | Valid | Epoch[079/600] MIou: 0.7465814055570746
2023-02-06 14:01:02 | Valid | Epoch[079/600] Pixel Accuracy: 0.9580968221028646
2023-02-06 14:01:02 | Valid | Epoch[079/600] Mean Pixel Accuracy: 0.7691529320204932
2023-02-06 14:01:02 | Stage | Epoch[079/600] Train loss:0.0628
2023-02-06 14:01:02 | Stage | Epoch[079/600] Valid loss:0.1070
2023-02-06 14:01:02 | Stage | Epoch[079/600] LR:0.01

2023-02-06 14:01:03 | Train | Epoch[080/600] Iteration[001/030] Train loss: 0.0603
2023-02-06 14:01:03 | Train | Epoch[080/600] Iteration[002/030] Train loss: 0.0609
2023-02-06 14:01:03 | Train | Epoch[080/600] Iteration[003/030] Train loss: 0.0618
2023-02-06 14:01:03 | Train | Epoch[080/600] Iteration[004/030] Train loss: 0.0615
2023-02-06 14:01:03 | Train | Epoch[080/600] Iteration[005/030] Train loss: 0.0618
2023-02-06 14:01:04 | Train | Epoch[080/600] Iteration[006/030] Train loss: 0.0616
2023-02-06 14:01:04 | Train | Epoch[080/600] Iteration[007/030] Train loss: 0.0612
2023-02-06 14:01:04 | Train | Epoch[080/600] Iteration[008/030] Train loss: 0.0612
2023-02-06 14:01:04 | Train | Epoch[080/600] Iteration[009/030] Train loss: 0.0611
2023-02-06 14:01:05 | Train | Epoch[080/600] Iteration[010/030] Train loss: 0.0611
2023-02-06 14:01:05 | Train | Epoch[080/600] Iteration[011/030] Train loss: 0.0610
2023-02-06 14:01:05 | Train | Epoch[080/600] Iteration[012/030] Train loss: 0.0612
2023-02-06 14:01:05 | Train | Epoch[080/600] Iteration[013/030] Train loss: 0.0614
2023-02-06 14:01:05 | Train | Epoch[080/600] Iteration[014/030] Train loss: 0.0613
2023-02-06 14:01:06 | Train | Epoch[080/600] Iteration[015/030] Train loss: 0.0613
2023-02-06 14:01:06 | Train | Epoch[080/600] Iteration[016/030] Train loss: 0.0612
2023-02-06 14:01:06 | Train | Epoch[080/600] Iteration[017/030] Train loss: 0.0612
2023-02-06 14:01:06 | Train | Epoch[080/600] Iteration[018/030] Train loss: 0.0613
2023-02-06 14:01:06 | Train | Epoch[080/600] Iteration[019/030] Train loss: 0.0614
2023-02-06 14:01:07 | Train | Epoch[080/600] Iteration[020/030] Train loss: 0.0615
2023-02-06 14:01:07 | Train | Epoch[080/600] Iteration[021/030] Train loss: 0.0614
2023-02-06 14:01:07 | Train | Epoch[080/600] Iteration[022/030] Train loss: 0.0615
2023-02-06 14:01:07 | Train | Epoch[080/600] Iteration[023/030] Train loss: 0.0615
2023-02-06 14:01:08 | Train | Epoch[080/600] Iteration[024/030] Train loss: 0.0615
2023-02-06 14:01:08 | Train | Epoch[080/600] Iteration[025/030] Train loss: 0.0614
2023-02-06 14:01:08 | Train | Epoch[080/600] Iteration[026/030] Train loss: 0.0614
2023-02-06 14:01:08 | Train | Epoch[080/600] Iteration[027/030] Train loss: 0.0614
2023-02-06 14:01:08 | Train | Epoch[080/600] Iteration[028/030] Train loss: 0.0614
2023-02-06 14:01:09 | Train | Epoch[080/600] Iteration[029/030] Train loss: 0.0614
2023-02-06 14:01:09 | Train | Epoch[080/600] Iteration[030/030] Train loss: 0.0613
2023-02-06 14:01:09 | Valid | Epoch[080/600] Iteration[001/008] Valid loss: 0.0815
2023-02-06 14:01:09 | Valid | Epoch[080/600] Iteration[002/008] Valid loss: 0.0788
2023-02-06 14:01:09 | Valid | Epoch[080/600] Iteration[003/008] Valid loss: 0.0786
2023-02-06 14:01:09 | Valid | Epoch[080/600] Iteration[004/008] Valid loss: 0.0775
2023-02-06 14:01:09 | Valid | Epoch[080/600] Iteration[005/008] Valid loss: 0.0777
2023-02-06 14:01:09 | Valid | Epoch[080/600] Iteration[006/008] Valid loss: 0.0770
2023-02-06 14:01:09 | Valid | Epoch[080/600] Iteration[007/008] Valid loss: 0.0775
2023-02-06 14:01:09 | Valid | Epoch[080/600] Iteration[008/008] Valid loss: 0.0774
2023-02-06 14:01:10 | Valid | Epoch[080/600] MIou: 0.9098564496971399
2023-02-06 14:01:10 | Valid | Epoch[080/600] Pixel Accuracy: 0.9848581949869791
2023-02-06 14:01:10 | Valid | Epoch[080/600] Mean Pixel Accuracy: 0.9265417543388832
2023-02-06 14:01:10 | Stage | Epoch[080/600] Train loss:0.0613
2023-02-06 14:01:10 | Stage | Epoch[080/600] Valid loss:0.0774
2023-02-06 14:01:10 | Stage | Epoch[080/600] LR:0.01

2023-02-06 14:01:10 | Train | Epoch[081/600] Iteration[001/030] Train loss: 0.0587
2023-02-06 14:01:10 | Train | Epoch[081/600] Iteration[002/030] Train loss: 0.0588
2023-02-06 14:01:10 | Train | Epoch[081/600] Iteration[003/030] Train loss: 0.0588
2023-02-06 14:01:11 | Train | Epoch[081/600] Iteration[004/030] Train loss: 0.0595
2023-02-06 14:01:11 | Train | Epoch[081/600] Iteration[005/030] Train loss: 0.0594
2023-02-06 14:01:11 | Train | Epoch[081/600] Iteration[006/030] Train loss: 0.0593
2023-02-06 14:01:11 | Train | Epoch[081/600] Iteration[007/030] Train loss: 0.0593
2023-02-06 14:01:12 | Train | Epoch[081/600] Iteration[008/030] Train loss: 0.0598
2023-02-06 14:01:12 | Train | Epoch[081/600] Iteration[009/030] Train loss: 0.0598
2023-02-06 14:01:12 | Train | Epoch[081/600] Iteration[010/030] Train loss: 0.0597
2023-02-06 14:01:12 | Train | Epoch[081/600] Iteration[011/030] Train loss: 0.0599
2023-02-06 14:01:12 | Train | Epoch[081/600] Iteration[012/030] Train loss: 0.0599
2023-02-06 14:01:13 | Train | Epoch[081/600] Iteration[013/030] Train loss: 0.0599
2023-02-06 14:01:13 | Train | Epoch[081/600] Iteration[014/030] Train loss: 0.0600
2023-02-06 14:01:13 | Train | Epoch[081/600] Iteration[015/030] Train loss: 0.0599
2023-02-06 14:01:13 | Train | Epoch[081/600] Iteration[016/030] Train loss: 0.0600
2023-02-06 14:01:14 | Train | Epoch[081/600] Iteration[017/030] Train loss: 0.0601
2023-02-06 14:01:14 | Train | Epoch[081/600] Iteration[018/030] Train loss: 0.0600
2023-02-06 14:01:14 | Train | Epoch[081/600] Iteration[019/030] Train loss: 0.0602
2023-02-06 14:01:14 | Train | Epoch[081/600] Iteration[020/030] Train loss: 0.0602
2023-02-06 14:01:14 | Train | Epoch[081/600] Iteration[021/030] Train loss: 0.0603
2023-02-06 14:01:15 | Train | Epoch[081/600] Iteration[022/030] Train loss: 0.0603
2023-02-06 14:01:15 | Train | Epoch[081/600] Iteration[023/030] Train loss: 0.0603
2023-02-06 14:01:15 | Train | Epoch[081/600] Iteration[024/030] Train loss: 0.0602
2023-02-06 14:01:15 | Train | Epoch[081/600] Iteration[025/030] Train loss: 0.0602
2023-02-06 14:01:15 | Train | Epoch[081/600] Iteration[026/030] Train loss: 0.0602
2023-02-06 14:01:16 | Train | Epoch[081/600] Iteration[027/030] Train loss: 0.0602
2023-02-06 14:01:16 | Train | Epoch[081/600] Iteration[028/030] Train loss: 0.0602
2023-02-06 14:01:16 | Train | Epoch[081/600] Iteration[029/030] Train loss: 0.0601
2023-02-06 14:01:16 | Train | Epoch[081/600] Iteration[030/030] Train loss: 0.0602
2023-02-06 14:01:17 | Valid | Epoch[081/600] Iteration[001/008] Valid loss: 0.3406
2023-02-06 14:01:17 | Valid | Epoch[081/600] Iteration[002/008] Valid loss: 0.2799
2023-02-06 14:01:17 | Valid | Epoch[081/600] Iteration[003/008] Valid loss: 0.2737
2023-02-06 14:01:17 | Valid | Epoch[081/600] Iteration[004/008] Valid loss: 0.2649
2023-02-06 14:01:17 | Valid | Epoch[081/600] Iteration[005/008] Valid loss: 0.2719
2023-02-06 14:01:17 | Valid | Epoch[081/600] Iteration[006/008] Valid loss: 0.2631
2023-02-06 14:01:17 | Valid | Epoch[081/600] Iteration[007/008] Valid loss: 0.2817
2023-02-06 14:01:17 | Valid | Epoch[081/600] Iteration[008/008] Valid loss: 0.2821
2023-02-06 14:01:17 | Valid | Epoch[081/600] MIou: 0.9082922261194134
2023-02-06 14:01:17 | Valid | Epoch[081/600] Pixel Accuracy: 0.9826825459798177
2023-02-06 14:01:17 | Valid | Epoch[081/600] Mean Pixel Accuracy: 0.9789355900754597
2023-02-06 14:01:17 | Stage | Epoch[081/600] Train loss:0.0602
2023-02-06 14:01:17 | Stage | Epoch[081/600] Valid loss:0.2821
2023-02-06 14:01:17 | Stage | Epoch[081/600] LR:0.01

2023-02-06 14:01:17 | Train | Epoch[082/600] Iteration[001/030] Train loss: 0.0600
2023-02-06 14:01:18 | Train | Epoch[082/600] Iteration[002/030] Train loss: 0.0606
2023-02-06 14:01:18 | Train | Epoch[082/600] Iteration[003/030] Train loss: 0.0613
2023-02-06 14:01:18 | Train | Epoch[082/600] Iteration[004/030] Train loss: 0.0621
2023-02-06 14:01:18 | Train | Epoch[082/600] Iteration[005/030] Train loss: 0.0617
2023-02-06 14:01:19 | Train | Epoch[082/600] Iteration[006/030] Train loss: 0.0614
2023-02-06 14:01:19 | Train | Epoch[082/600] Iteration[007/030] Train loss: 0.0610
2023-02-06 14:01:19 | Train | Epoch[082/600] Iteration[008/030] Train loss: 0.0608
2023-02-06 14:01:19 | Train | Epoch[082/600] Iteration[009/030] Train loss: 0.0607
2023-02-06 14:01:19 | Train | Epoch[082/600] Iteration[010/030] Train loss: 0.0605
2023-02-06 14:01:20 | Train | Epoch[082/600] Iteration[011/030] Train loss: 0.0605
2023-02-06 14:01:20 | Train | Epoch[082/600] Iteration[012/030] Train loss: 0.0604
2023-02-06 14:01:20 | Train | Epoch[082/600] Iteration[013/030] Train loss: 0.0602
2023-02-06 14:01:20 | Train | Epoch[082/600] Iteration[014/030] Train loss: 0.0602
2023-02-06 14:01:21 | Train | Epoch[082/600] Iteration[015/030] Train loss: 0.0601
2023-02-06 14:01:21 | Train | Epoch[082/600] Iteration[016/030] Train loss: 0.0601
2023-02-06 14:01:21 | Train | Epoch[082/600] Iteration[017/030] Train loss: 0.0601
2023-02-06 14:01:21 | Train | Epoch[082/600] Iteration[018/030] Train loss: 0.0601
2023-02-06 14:01:21 | Train | Epoch[082/600] Iteration[019/030] Train loss: 0.0600
2023-02-06 14:01:22 | Train | Epoch[082/600] Iteration[020/030] Train loss: 0.0599
2023-02-06 14:01:22 | Train | Epoch[082/600] Iteration[021/030] Train loss: 0.0599
2023-02-06 14:01:22 | Train | Epoch[082/600] Iteration[022/030] Train loss: 0.0601
2023-02-06 14:01:22 | Train | Epoch[082/600] Iteration[023/030] Train loss: 0.0600
2023-02-06 14:01:23 | Train | Epoch[082/600] Iteration[024/030] Train loss: 0.0600
2023-02-06 14:01:23 | Train | Epoch[082/600] Iteration[025/030] Train loss: 0.0600
2023-02-06 14:01:23 | Train | Epoch[082/600] Iteration[026/030] Train loss: 0.0601
2023-02-06 14:01:23 | Train | Epoch[082/600] Iteration[027/030] Train loss: 0.0600
2023-02-06 14:01:23 | Train | Epoch[082/600] Iteration[028/030] Train loss: 0.0600
2023-02-06 14:01:24 | Train | Epoch[082/600] Iteration[029/030] Train loss: 0.0600
2023-02-06 14:01:24 | Train | Epoch[082/600] Iteration[030/030] Train loss: 0.0599
2023-02-06 14:01:24 | Valid | Epoch[082/600] Iteration[001/008] Valid loss: 0.0983
2023-02-06 14:01:24 | Valid | Epoch[082/600] Iteration[002/008] Valid loss: 0.0954
2023-02-06 14:01:24 | Valid | Epoch[082/600] Iteration[003/008] Valid loss: 0.0972
2023-02-06 14:01:24 | Valid | Epoch[082/600] Iteration[004/008] Valid loss: 0.0956
2023-02-06 14:01:24 | Valid | Epoch[082/600] Iteration[005/008] Valid loss: 0.0975
2023-02-06 14:01:24 | Valid | Epoch[082/600] Iteration[006/008] Valid loss: 0.0977
2023-02-06 14:01:24 | Valid | Epoch[082/600] Iteration[007/008] Valid loss: 0.1014
2023-02-06 14:01:24 | Valid | Epoch[082/600] Iteration[008/008] Valid loss: 0.1005
2023-02-06 14:01:25 | Valid | Epoch[082/600] MIou: 0.9086801458664886
2023-02-06 14:01:25 | Valid | Epoch[082/600] Pixel Accuracy: 0.9841092427571615
2023-02-06 14:01:25 | Valid | Epoch[082/600] Mean Pixel Accuracy: 0.9408399921593604
2023-02-06 14:01:25 | Stage | Epoch[082/600] Train loss:0.0599
2023-02-06 14:01:25 | Stage | Epoch[082/600] Valid loss:0.1005
2023-02-06 14:01:25 | Stage | Epoch[082/600] LR:0.01

2023-02-06 14:01:25 | Train | Epoch[083/600] Iteration[001/030] Train loss: 0.0570
2023-02-06 14:01:25 | Train | Epoch[083/600] Iteration[002/030] Train loss: 0.0566
2023-02-06 14:01:25 | Train | Epoch[083/600] Iteration[003/030] Train loss: 0.0568
2023-02-06 14:01:26 | Train | Epoch[083/600] Iteration[004/030] Train loss: 0.0573
2023-02-06 14:01:26 | Train | Epoch[083/600] Iteration[005/030] Train loss: 0.0578
2023-02-06 14:01:26 | Train | Epoch[083/600] Iteration[006/030] Train loss: 0.0577
2023-02-06 14:01:26 | Train | Epoch[083/600] Iteration[007/030] Train loss: 0.0578
2023-02-06 14:01:27 | Train | Epoch[083/600] Iteration[008/030] Train loss: 0.0582
2023-02-06 14:01:27 | Train | Epoch[083/600] Iteration[009/030] Train loss: 0.0583
2023-02-06 14:01:27 | Train | Epoch[083/600] Iteration[010/030] Train loss: 0.0583
2023-02-06 14:01:27 | Train | Epoch[083/600] Iteration[011/030] Train loss: 0.0585
2023-02-06 14:01:27 | Train | Epoch[083/600] Iteration[012/030] Train loss: 0.0585
2023-02-06 14:01:28 | Train | Epoch[083/600] Iteration[013/030] Train loss: 0.0585
2023-02-06 14:01:28 | Train | Epoch[083/600] Iteration[014/030] Train loss: 0.0583
2023-02-06 14:01:28 | Train | Epoch[083/600] Iteration[015/030] Train loss: 0.0587
2023-02-06 14:01:28 | Train | Epoch[083/600] Iteration[016/030] Train loss: 0.0586
2023-02-06 14:01:29 | Train | Epoch[083/600] Iteration[017/030] Train loss: 0.0586
2023-02-06 14:01:29 | Train | Epoch[083/600] Iteration[018/030] Train loss: 0.0585
2023-02-06 14:01:29 | Train | Epoch[083/600] Iteration[019/030] Train loss: 0.0585
2023-02-06 14:01:29 | Train | Epoch[083/600] Iteration[020/030] Train loss: 0.0585
2023-02-06 14:01:29 | Train | Epoch[083/600] Iteration[021/030] Train loss: 0.0583
2023-02-06 14:01:30 | Train | Epoch[083/600] Iteration[022/030] Train loss: 0.0585
2023-02-06 14:01:30 | Train | Epoch[083/600] Iteration[023/030] Train loss: 0.0586
2023-02-06 14:01:30 | Train | Epoch[083/600] Iteration[024/030] Train loss: 0.0586
2023-02-06 14:01:30 | Train | Epoch[083/600] Iteration[025/030] Train loss: 0.0586
2023-02-06 14:01:30 | Train | Epoch[083/600] Iteration[026/030] Train loss: 0.0585
2023-02-06 14:01:31 | Train | Epoch[083/600] Iteration[027/030] Train loss: 0.0585
2023-02-06 14:01:31 | Train | Epoch[083/600] Iteration[028/030] Train loss: 0.0585
2023-02-06 14:01:31 | Train | Epoch[083/600] Iteration[029/030] Train loss: 0.0585
2023-02-06 14:01:31 | Train | Epoch[083/600] Iteration[030/030] Train loss: 0.0586
2023-02-06 14:01:32 | Valid | Epoch[083/600] Iteration[001/008] Valid loss: 0.0779
2023-02-06 14:01:32 | Valid | Epoch[083/600] Iteration[002/008] Valid loss: 0.0771
2023-02-06 14:01:32 | Valid | Epoch[083/600] Iteration[003/008] Valid loss: 0.0764
2023-02-06 14:01:32 | Valid | Epoch[083/600] Iteration[004/008] Valid loss: 0.0751
2023-02-06 14:01:32 | Valid | Epoch[083/600] Iteration[005/008] Valid loss: 0.0755
2023-02-06 14:01:32 | Valid | Epoch[083/600] Iteration[006/008] Valid loss: 0.0745
2023-02-06 14:01:32 | Valid | Epoch[083/600] Iteration[007/008] Valid loss: 0.0742
2023-02-06 14:01:32 | Valid | Epoch[083/600] Iteration[008/008] Valid loss: 0.0741
2023-02-06 14:01:32 | Valid | Epoch[083/600] MIou: 0.8947062165009702
2023-02-06 14:01:32 | Valid | Epoch[083/600] Pixel Accuracy: 0.9825096130371094
2023-02-06 14:01:32 | Valid | Epoch[083/600] Mean Pixel Accuracy: 0.9077511721612969
2023-02-06 14:01:32 | Stage | Epoch[083/600] Train loss:0.0586
2023-02-06 14:01:32 | Stage | Epoch[083/600] Valid loss:0.0741
2023-02-06 14:01:32 | Stage | Epoch[083/600] LR:0.01

2023-02-06 14:01:32 | Train | Epoch[084/600] Iteration[001/030] Train loss: 0.0569
2023-02-06 14:01:33 | Train | Epoch[084/600] Iteration[002/030] Train loss: 0.0574
2023-02-06 14:01:33 | Train | Epoch[084/600] Iteration[003/030] Train loss: 0.0571
2023-02-06 14:01:33 | Train | Epoch[084/600] Iteration[004/030] Train loss: 0.0567
2023-02-06 14:01:33 | Train | Epoch[084/600] Iteration[005/030] Train loss: 0.0573
2023-02-06 14:01:34 | Train | Epoch[084/600] Iteration[006/030] Train loss: 0.0573
2023-02-06 14:01:34 | Train | Epoch[084/600] Iteration[007/030] Train loss: 0.0572
2023-02-06 14:01:34 | Train | Epoch[084/600] Iteration[008/030] Train loss: 0.0572
2023-02-06 14:01:34 | Train | Epoch[084/600] Iteration[009/030] Train loss: 0.0571
2023-02-06 14:01:34 | Train | Epoch[084/600] Iteration[010/030] Train loss: 0.0574
2023-02-06 14:01:35 | Train | Epoch[084/600] Iteration[011/030] Train loss: 0.0574
2023-02-06 14:01:35 | Train | Epoch[084/600] Iteration[012/030] Train loss: 0.0575
2023-02-06 14:01:35 | Train | Epoch[084/600] Iteration[013/030] Train loss: 0.0575
2023-02-06 14:01:35 | Train | Epoch[084/600] Iteration[014/030] Train loss: 0.0576
2023-02-06 14:01:36 | Train | Epoch[084/600] Iteration[015/030] Train loss: 0.0577
2023-02-06 14:01:36 | Train | Epoch[084/600] Iteration[016/030] Train loss: 0.0576
2023-02-06 14:01:36 | Train | Epoch[084/600] Iteration[017/030] Train loss: 0.0577
2023-02-06 14:01:36 | Train | Epoch[084/600] Iteration[018/030] Train loss: 0.0576
2023-02-06 14:01:36 | Train | Epoch[084/600] Iteration[019/030] Train loss: 0.0577
2023-02-06 14:01:37 | Train | Epoch[084/600] Iteration[020/030] Train loss: 0.0577
2023-02-06 14:01:37 | Train | Epoch[084/600] Iteration[021/030] Train loss: 0.0578
2023-02-06 14:01:37 | Train | Epoch[084/600] Iteration[022/030] Train loss: 0.0578
2023-02-06 14:01:37 | Train | Epoch[084/600] Iteration[023/030] Train loss: 0.0577
2023-02-06 14:01:37 | Train | Epoch[084/600] Iteration[024/030] Train loss: 0.0576
2023-02-06 14:01:38 | Train | Epoch[084/600] Iteration[025/030] Train loss: 0.0576
2023-02-06 14:01:38 | Train | Epoch[084/600] Iteration[026/030] Train loss: 0.0576
2023-02-06 14:01:38 | Train | Epoch[084/600] Iteration[027/030] Train loss: 0.0576
2023-02-06 14:01:38 | Train | Epoch[084/600] Iteration[028/030] Train loss: 0.0577
2023-02-06 14:01:39 | Train | Epoch[084/600] Iteration[029/030] Train loss: 0.0577
2023-02-06 14:01:39 | Train | Epoch[084/600] Iteration[030/030] Train loss: 0.0579
2023-02-06 14:01:39 | Valid | Epoch[084/600] Iteration[001/008] Valid loss: 0.0857
2023-02-06 14:01:39 | Valid | Epoch[084/600] Iteration[002/008] Valid loss: 0.0801
2023-02-06 14:01:39 | Valid | Epoch[084/600] Iteration[003/008] Valid loss: 0.0781
2023-02-06 14:01:39 | Valid | Epoch[084/600] Iteration[004/008] Valid loss: 0.0767
2023-02-06 14:01:39 | Valid | Epoch[084/600] Iteration[005/008] Valid loss: 0.0766
2023-02-06 14:01:39 | Valid | Epoch[084/600] Iteration[006/008] Valid loss: 0.0758
2023-02-06 14:01:39 | Valid | Epoch[084/600] Iteration[007/008] Valid loss: 0.0773
2023-02-06 14:01:39 | Valid | Epoch[084/600] Iteration[008/008] Valid loss: 0.0774
2023-02-06 14:01:39 | Valid | Epoch[084/600] MIou: 0.9137695427555264
2023-02-06 14:01:39 | Valid | Epoch[084/600] Pixel Accuracy: 0.9854214986165365
2023-02-06 14:01:39 | Valid | Epoch[084/600] Mean Pixel Accuracy: 0.9330143083477482
2023-02-06 14:01:39 | Stage | Epoch[084/600] Train loss:0.0579
2023-02-06 14:01:39 | Stage | Epoch[084/600] Valid loss:0.0774
2023-02-06 14:01:39 | Stage | Epoch[084/600] LR:0.01

2023-02-06 14:01:40 | Train | Epoch[085/600] Iteration[001/030] Train loss: 0.0577
2023-02-06 14:01:40 | Train | Epoch[085/600] Iteration[002/030] Train loss: 0.0570
2023-02-06 14:01:40 | Train | Epoch[085/600] Iteration[003/030] Train loss: 0.0577
2023-02-06 14:01:41 | Train | Epoch[085/600] Iteration[004/030] Train loss: 0.0574
2023-02-06 14:01:41 | Train | Epoch[085/600] Iteration[005/030] Train loss: 0.0571
2023-02-06 14:01:41 | Train | Epoch[085/600] Iteration[006/030] Train loss: 0.0570
2023-02-06 14:01:41 | Train | Epoch[085/600] Iteration[007/030] Train loss: 0.0569
2023-02-06 14:01:41 | Train | Epoch[085/600] Iteration[008/030] Train loss: 0.0568
2023-02-06 14:01:42 | Train | Epoch[085/600] Iteration[009/030] Train loss: 0.0567
2023-02-06 14:01:42 | Train | Epoch[085/600] Iteration[010/030] Train loss: 0.0568
2023-02-06 14:01:42 | Train | Epoch[085/600] Iteration[011/030] Train loss: 0.0566
2023-02-06 14:01:42 | Train | Epoch[085/600] Iteration[012/030] Train loss: 0.0565
2023-02-06 14:01:43 | Train | Epoch[085/600] Iteration[013/030] Train loss: 0.0565
2023-02-06 14:01:43 | Train | Epoch[085/600] Iteration[014/030] Train loss: 0.0567
2023-02-06 14:01:43 | Train | Epoch[085/600] Iteration[015/030] Train loss: 0.0566
2023-02-06 14:01:43 | Train | Epoch[085/600] Iteration[016/030] Train loss: 0.0566
2023-02-06 14:01:43 | Train | Epoch[085/600] Iteration[017/030] Train loss: 0.0565
2023-02-06 14:01:44 | Train | Epoch[085/600] Iteration[018/030] Train loss: 0.0566
2023-02-06 14:01:44 | Train | Epoch[085/600] Iteration[019/030] Train loss: 0.0565
2023-02-06 14:01:44 | Train | Epoch[085/600] Iteration[020/030] Train loss: 0.0566
2023-02-06 14:01:44 | Train | Epoch[085/600] Iteration[021/030] Train loss: 0.0565
2023-02-06 14:01:45 | Train | Epoch[085/600] Iteration[022/030] Train loss: 0.0565
2023-02-06 14:01:45 | Train | Epoch[085/600] Iteration[023/030] Train loss: 0.0564
2023-02-06 14:01:45 | Train | Epoch[085/600] Iteration[024/030] Train loss: 0.0566
2023-02-06 14:01:45 | Train | Epoch[085/600] Iteration[025/030] Train loss: 0.0568
2023-02-06 14:01:45 | Train | Epoch[085/600] Iteration[026/030] Train loss: 0.0567
2023-02-06 14:01:46 | Train | Epoch[085/600] Iteration[027/030] Train loss: 0.0568
2023-02-06 14:01:46 | Train | Epoch[085/600] Iteration[028/030] Train loss: 0.0568
2023-02-06 14:01:46 | Train | Epoch[085/600] Iteration[029/030] Train loss: 0.0568
2023-02-06 14:01:46 | Train | Epoch[085/600] Iteration[030/030] Train loss: 0.0568
2023-02-06 14:01:47 | Valid | Epoch[085/600] Iteration[001/008] Valid loss: 0.1401
2023-02-06 14:01:47 | Valid | Epoch[085/600] Iteration[002/008] Valid loss: 0.1087
2023-02-06 14:01:47 | Valid | Epoch[085/600] Iteration[003/008] Valid loss: 0.1079
2023-02-06 14:01:47 | Valid | Epoch[085/600] Iteration[004/008] Valid loss: 0.1054
2023-02-06 14:01:47 | Valid | Epoch[085/600] Iteration[005/008] Valid loss: 0.1060
2023-02-06 14:01:47 | Valid | Epoch[085/600] Iteration[006/008] Valid loss: 0.1031
2023-02-06 14:01:47 | Valid | Epoch[085/600] Iteration[007/008] Valid loss: 0.1064
2023-02-06 14:01:47 | Valid | Epoch[085/600] Iteration[008/008] Valid loss: 0.1049
2023-02-06 14:01:47 | Valid | Epoch[085/600] MIou: 0.9178009410854229
2023-02-06 14:01:47 | Valid | Epoch[085/600] Pixel Accuracy: 0.9856249491373698
2023-02-06 14:01:47 | Valid | Epoch[085/600] Mean Pixel Accuracy: 0.9519890361793903
2023-02-06 14:01:47 | Stage | Epoch[085/600] Train loss:0.0568
2023-02-06 14:01:47 | Stage | Epoch[085/600] Valid loss:0.1049
2023-02-06 14:01:47 | Stage | Epoch[085/600] LR:0.01

2023-02-06 14:01:48 | Train | Epoch[086/600] Iteration[001/030] Train loss: 0.0553
2023-02-06 14:01:48 | Train | Epoch[086/600] Iteration[002/030] Train loss: 0.0549
2023-02-06 14:01:48 | Train | Epoch[086/600] Iteration[003/030] Train loss: 0.0565
2023-02-06 14:01:48 | Train | Epoch[086/600] Iteration[004/030] Train loss: 0.0562
2023-02-06 14:01:48 | Train | Epoch[086/600] Iteration[005/030] Train loss: 0.0569
2023-02-06 14:01:49 | Train | Epoch[086/600] Iteration[006/030] Train loss: 0.0566
2023-02-06 14:01:49 | Train | Epoch[086/600] Iteration[007/030] Train loss: 0.0565
2023-02-06 14:01:49 | Train | Epoch[086/600] Iteration[008/030] Train loss: 0.0564
2023-02-06 14:01:49 | Train | Epoch[086/600] Iteration[009/030] Train loss: 0.0566
2023-02-06 14:01:50 | Train | Epoch[086/600] Iteration[010/030] Train loss: 0.0569
2023-02-06 14:01:50 | Train | Epoch[086/600] Iteration[011/030] Train loss: 0.0567
2023-02-06 14:01:50 | Train | Epoch[086/600] Iteration[012/030] Train loss: 0.0565
2023-02-06 14:01:50 | Train | Epoch[086/600] Iteration[013/030] Train loss: 0.0564
2023-02-06 14:01:50 | Train | Epoch[086/600] Iteration[014/030] Train loss: 0.0563
2023-02-06 14:01:51 | Train | Epoch[086/600] Iteration[015/030] Train loss: 0.0562
2023-02-06 14:01:51 | Train | Epoch[086/600] Iteration[016/030] Train loss: 0.0562
2023-02-06 14:01:51 | Train | Epoch[086/600] Iteration[017/030] Train loss: 0.0562
2023-02-06 14:01:51 | Train | Epoch[086/600] Iteration[018/030] Train loss: 0.0562
2023-02-06 14:01:51 | Train | Epoch[086/600] Iteration[019/030] Train loss: 0.0566
2023-02-06 14:01:52 | Train | Epoch[086/600] Iteration[020/030] Train loss: 0.0566
2023-02-06 14:01:52 | Train | Epoch[086/600] Iteration[021/030] Train loss: 0.0564
2023-02-06 14:01:52 | Train | Epoch[086/600] Iteration[022/030] Train loss: 0.0564
2023-02-06 14:01:52 | Train | Epoch[086/600] Iteration[023/030] Train loss: 0.0564
2023-02-06 14:01:53 | Train | Epoch[086/600] Iteration[024/030] Train loss: 0.0563
2023-02-06 14:01:53 | Train | Epoch[086/600] Iteration[025/030] Train loss: 0.0563
2023-02-06 14:01:53 | Train | Epoch[086/600] Iteration[026/030] Train loss: 0.0562
2023-02-06 14:01:53 | Train | Epoch[086/600] Iteration[027/030] Train loss: 0.0561
2023-02-06 14:01:53 | Train | Epoch[086/600] Iteration[028/030] Train loss: 0.0560
2023-02-06 14:01:54 | Train | Epoch[086/600] Iteration[029/030] Train loss: 0.0560
2023-02-06 14:01:54 | Train | Epoch[086/600] Iteration[030/030] Train loss: 0.0560
2023-02-06 14:01:54 | Valid | Epoch[086/600] Iteration[001/008] Valid loss: 0.3480
2023-02-06 14:01:54 | Valid | Epoch[086/600] Iteration[002/008] Valid loss: 0.2720
2023-02-06 14:01:54 | Valid | Epoch[086/600] Iteration[003/008] Valid loss: 0.2610
2023-02-06 14:01:54 | Valid | Epoch[086/600] Iteration[004/008] Valid loss: 0.2594
2023-02-06 14:01:54 | Valid | Epoch[086/600] Iteration[005/008] Valid loss: 0.2603
2023-02-06 14:01:54 | Valid | Epoch[086/600] Iteration[006/008] Valid loss: 0.2566
2023-02-06 14:01:54 | Valid | Epoch[086/600] Iteration[007/008] Valid loss: 0.2643
2023-02-06 14:01:54 | Valid | Epoch[086/600] Iteration[008/008] Valid loss: 0.2649
2023-02-06 14:01:55 | Valid | Epoch[086/600] MIou: 0.8769873490576754
2023-02-06 14:01:55 | Valid | Epoch[086/600] Pixel Accuracy: 0.9750315348307291
2023-02-06 14:01:55 | Valid | Epoch[086/600] Mean Pixel Accuracy: 0.9809312491790014
2023-02-06 14:01:55 | Stage | Epoch[086/600] Train loss:0.0560
2023-02-06 14:01:55 | Stage | Epoch[086/600] Valid loss:0.2649
2023-02-06 14:01:55 | Stage | Epoch[086/600] LR:0.01

2023-02-06 14:01:55 | Train | Epoch[087/600] Iteration[001/030] Train loss: 0.0559
2023-02-06 14:01:55 | Train | Epoch[087/600] Iteration[002/030] Train loss: 0.0551
2023-02-06 14:01:55 | Train | Epoch[087/600] Iteration[003/030] Train loss: 0.0558
2023-02-06 14:01:56 | Train | Epoch[087/600] Iteration[004/030] Train loss: 0.0554
2023-02-06 14:01:56 | Train | Epoch[087/600] Iteration[005/030] Train loss: 0.0549
2023-02-06 14:01:56 | Train | Epoch[087/600] Iteration[006/030] Train loss: 0.0551
2023-02-06 14:01:56 | Train | Epoch[087/600] Iteration[007/030] Train loss: 0.0550
2023-02-06 14:01:57 | Train | Epoch[087/600] Iteration[008/030] Train loss: 0.0550
2023-02-06 14:01:57 | Train | Epoch[087/600] Iteration[009/030] Train loss: 0.0548
2023-02-06 14:01:57 | Train | Epoch[087/600] Iteration[010/030] Train loss: 0.0548
2023-02-06 14:01:57 | Train | Epoch[087/600] Iteration[011/030] Train loss: 0.0548
2023-02-06 14:01:57 | Train | Epoch[087/600] Iteration[012/030] Train loss: 0.0547
2023-02-06 14:01:58 | Train | Epoch[087/600] Iteration[013/030] Train loss: 0.0546
2023-02-06 14:01:58 | Train | Epoch[087/600] Iteration[014/030] Train loss: 0.0547
2023-02-06 14:01:58 | Train | Epoch[087/600] Iteration[015/030] Train loss: 0.0546
2023-02-06 14:01:58 | Train | Epoch[087/600] Iteration[016/030] Train loss: 0.0548
2023-02-06 14:01:59 | Train | Epoch[087/600] Iteration[017/030] Train loss: 0.0548
2023-02-06 14:01:59 | Train | Epoch[087/600] Iteration[018/030] Train loss: 0.0547
2023-02-06 14:01:59 | Train | Epoch[087/600] Iteration[019/030] Train loss: 0.0547
2023-02-06 14:01:59 | Train | Epoch[087/600] Iteration[020/030] Train loss: 0.0551
2023-02-06 14:01:59 | Train | Epoch[087/600] Iteration[021/030] Train loss: 0.0550
2023-02-06 14:02:00 | Train | Epoch[087/600] Iteration[022/030] Train loss: 0.0551
2023-02-06 14:02:00 | Train | Epoch[087/600] Iteration[023/030] Train loss: 0.0551
2023-02-06 14:02:00 | Train | Epoch[087/600] Iteration[024/030] Train loss: 0.0551
2023-02-06 14:02:00 | Train | Epoch[087/600] Iteration[025/030] Train loss: 0.0551
2023-02-06 14:02:01 | Train | Epoch[087/600] Iteration[026/030] Train loss: 0.0550
2023-02-06 14:02:01 | Train | Epoch[087/600] Iteration[027/030] Train loss: 0.0550
2023-02-06 14:02:01 | Train | Epoch[087/600] Iteration[028/030] Train loss: 0.0550
2023-02-06 14:02:01 | Train | Epoch[087/600] Iteration[029/030] Train loss: 0.0550
2023-02-06 14:02:01 | Train | Epoch[087/600] Iteration[030/030] Train loss: 0.0551
2023-02-06 14:02:02 | Valid | Epoch[087/600] Iteration[001/008] Valid loss: 0.2379
2023-02-06 14:02:02 | Valid | Epoch[087/600] Iteration[002/008] Valid loss: 0.2063
2023-02-06 14:02:02 | Valid | Epoch[087/600] Iteration[003/008] Valid loss: 0.1977
2023-02-06 14:02:02 | Valid | Epoch[087/600] Iteration[004/008] Valid loss: 0.2001
2023-02-06 14:02:02 | Valid | Epoch[087/600] Iteration[005/008] Valid loss: 0.2023
2023-02-06 14:02:02 | Valid | Epoch[087/600] Iteration[006/008] Valid loss: 0.2047
2023-02-06 14:02:02 | Valid | Epoch[087/600] Iteration[007/008] Valid loss: 0.2186
2023-02-06 14:02:02 | Valid | Epoch[087/600] Iteration[008/008] Valid loss: 0.2217
2023-02-06 14:02:02 | Valid | Epoch[087/600] MIou: 0.899982230938319
2023-02-06 14:02:02 | Valid | Epoch[087/600] Pixel Accuracy: 0.9810562133789062
2023-02-06 14:02:02 | Valid | Epoch[087/600] Mean Pixel Accuracy: 0.9716187906748541
2023-02-06 14:02:02 | Stage | Epoch[087/600] Train loss:0.0551
2023-02-06 14:02:02 | Stage | Epoch[087/600] Valid loss:0.2217
2023-02-06 14:02:02 | Stage | Epoch[087/600] LR:0.01

2023-02-06 14:02:02 | Train | Epoch[088/600] Iteration[001/030] Train loss: 0.0556
2023-02-06 14:02:03 | Train | Epoch[088/600] Iteration[002/030] Train loss: 0.0553
2023-02-06 14:02:03 | Train | Epoch[088/600] Iteration[003/030] Train loss: 0.0550
2023-02-06 14:02:03 | Train | Epoch[088/600] Iteration[004/030] Train loss: 0.0546
2023-02-06 14:02:03 | Train | Epoch[088/600] Iteration[005/030] Train loss: 0.0544
2023-02-06 14:02:04 | Train | Epoch[088/600] Iteration[006/030] Train loss: 0.0543
2023-02-06 14:02:04 | Train | Epoch[088/600] Iteration[007/030] Train loss: 0.0542
2023-02-06 14:02:04 | Train | Epoch[088/600] Iteration[008/030] Train loss: 0.0543
2023-02-06 14:02:04 | Train | Epoch[088/600] Iteration[009/030] Train loss: 0.0543
2023-02-06 14:02:04 | Train | Epoch[088/600] Iteration[010/030] Train loss: 0.0543
2023-02-06 14:02:05 | Train | Epoch[088/600] Iteration[011/030] Train loss: 0.0542
2023-02-06 14:02:05 | Train | Epoch[088/600] Iteration[012/030] Train loss: 0.0541
2023-02-06 14:02:05 | Train | Epoch[088/600] Iteration[013/030] Train loss: 0.0540
2023-02-06 14:02:05 | Train | Epoch[088/600] Iteration[014/030] Train loss: 0.0540
2023-02-06 14:02:06 | Train | Epoch[088/600] Iteration[015/030] Train loss: 0.0541
2023-02-06 14:02:06 | Train | Epoch[088/600] Iteration[016/030] Train loss: 0.0544
2023-02-06 14:02:06 | Train | Epoch[088/600] Iteration[017/030] Train loss: 0.0546
2023-02-06 14:02:06 | Train | Epoch[088/600] Iteration[018/030] Train loss: 0.0545
2023-02-06 14:02:06 | Train | Epoch[088/600] Iteration[019/030] Train loss: 0.0546
2023-02-06 14:02:07 | Train | Epoch[088/600] Iteration[020/030] Train loss: 0.0546
2023-02-06 14:02:07 | Train | Epoch[088/600] Iteration[021/030] Train loss: 0.0547
2023-02-06 14:02:07 | Train | Epoch[088/600] Iteration[022/030] Train loss: 0.0547
2023-02-06 14:02:07 | Train | Epoch[088/600] Iteration[023/030] Train loss: 0.0547
2023-02-06 14:02:08 | Train | Epoch[088/600] Iteration[024/030] Train loss: 0.0546
2023-02-06 14:02:08 | Train | Epoch[088/600] Iteration[025/030] Train loss: 0.0545
2023-02-06 14:02:08 | Train | Epoch[088/600] Iteration[026/030] Train loss: 0.0545
2023-02-06 14:02:08 | Train | Epoch[088/600] Iteration[027/030] Train loss: 0.0544
2023-02-06 14:02:08 | Train | Epoch[088/600] Iteration[028/030] Train loss: 0.0543
2023-02-06 14:02:09 | Train | Epoch[088/600] Iteration[029/030] Train loss: 0.0543
2023-02-06 14:02:09 | Train | Epoch[088/600] Iteration[030/030] Train loss: 0.0542
2023-02-06 14:02:09 | Valid | Epoch[088/600] Iteration[001/008] Valid loss: 0.6154
2023-02-06 14:02:09 | Valid | Epoch[088/600] Iteration[002/008] Valid loss: 0.6059
2023-02-06 14:02:09 | Valid | Epoch[088/600] Iteration[003/008] Valid loss: 0.6236
2023-02-06 14:02:09 | Valid | Epoch[088/600] Iteration[004/008] Valid loss: 0.6306
2023-02-06 14:02:09 | Valid | Epoch[088/600] Iteration[005/008] Valid loss: 0.6407
2023-02-06 14:02:09 | Valid | Epoch[088/600] Iteration[006/008] Valid loss: 0.6321
2023-02-06 14:02:09 | Valid | Epoch[088/600] Iteration[007/008] Valid loss: 0.6735
2023-02-06 14:02:09 | Valid | Epoch[088/600] Iteration[008/008] Valid loss: 0.6865
2023-02-06 14:02:10 | Valid | Epoch[088/600] MIou: 0.8488987446118785
2023-02-06 14:02:10 | Valid | Epoch[088/600] Pixel Accuracy: 0.9674059549967448
2023-02-06 14:02:10 | Valid | Epoch[088/600] Mean Pixel Accuracy: 0.9792951152984977
2023-02-06 14:02:10 | Stage | Epoch[088/600] Train loss:0.0542
2023-02-06 14:02:10 | Stage | Epoch[088/600] Valid loss:0.6865
2023-02-06 14:02:10 | Stage | Epoch[088/600] LR:0.01

2023-02-06 14:02:10 | Train | Epoch[089/600] Iteration[001/030] Train loss: 0.0522
2023-02-06 14:02:10 | Train | Epoch[089/600] Iteration[002/030] Train loss: 0.0521
2023-02-06 14:02:10 | Train | Epoch[089/600] Iteration[003/030] Train loss: 0.0523
2023-02-06 14:02:11 | Train | Epoch[089/600] Iteration[004/030] Train loss: 0.0527
2023-02-06 14:02:11 | Train | Epoch[089/600] Iteration[005/030] Train loss: 0.0525
2023-02-06 14:02:11 | Train | Epoch[089/600] Iteration[006/030] Train loss: 0.0523
2023-02-06 14:02:11 | Train | Epoch[089/600] Iteration[007/030] Train loss: 0.0525
2023-02-06 14:02:12 | Train | Epoch[089/600] Iteration[008/030] Train loss: 0.0526
2023-02-06 14:02:12 | Train | Epoch[089/600] Iteration[009/030] Train loss: 0.0525
2023-02-06 14:02:12 | Train | Epoch[089/600] Iteration[010/030] Train loss: 0.0525
2023-02-06 14:02:12 | Train | Epoch[089/600] Iteration[011/030] Train loss: 0.0525
2023-02-06 14:02:12 | Train | Epoch[089/600] Iteration[012/030] Train loss: 0.0525
2023-02-06 14:02:13 | Train | Epoch[089/600] Iteration[013/030] Train loss: 0.0526
2023-02-06 14:02:13 | Train | Epoch[089/600] Iteration[014/030] Train loss: 0.0526
2023-02-06 14:02:13 | Train | Epoch[089/600] Iteration[015/030] Train loss: 0.0528
2023-02-06 14:02:13 | Train | Epoch[089/600] Iteration[016/030] Train loss: 0.0528
2023-02-06 14:02:13 | Train | Epoch[089/600] Iteration[017/030] Train loss: 0.0527
2023-02-06 14:02:14 | Train | Epoch[089/600] Iteration[018/030] Train loss: 0.0527
2023-02-06 14:02:14 | Train | Epoch[089/600] Iteration[019/030] Train loss: 0.0527
2023-02-06 14:02:14 | Train | Epoch[089/600] Iteration[020/030] Train loss: 0.0529
2023-02-06 14:02:14 | Train | Epoch[089/600] Iteration[021/030] Train loss: 0.0529
2023-02-06 14:02:15 | Train | Epoch[089/600] Iteration[022/030] Train loss: 0.0530
2023-02-06 14:02:15 | Train | Epoch[089/600] Iteration[023/030] Train loss: 0.0531
2023-02-06 14:02:15 | Train | Epoch[089/600] Iteration[024/030] Train loss: 0.0530
2023-02-06 14:02:15 | Train | Epoch[089/600] Iteration[025/030] Train loss: 0.0529
2023-02-06 14:02:15 | Train | Epoch[089/600] Iteration[026/030] Train loss: 0.0529
2023-02-06 14:02:16 | Train | Epoch[089/600] Iteration[027/030] Train loss: 0.0529
2023-02-06 14:02:16 | Train | Epoch[089/600] Iteration[028/030] Train loss: 0.0529
2023-02-06 14:02:16 | Train | Epoch[089/600] Iteration[029/030] Train loss: 0.0529
2023-02-06 14:02:16 | Train | Epoch[089/600] Iteration[030/030] Train loss: 0.0529
2023-02-06 14:02:17 | Valid | Epoch[089/600] Iteration[001/008] Valid loss: 0.1851
2023-02-06 14:02:17 | Valid | Epoch[089/600] Iteration[002/008] Valid loss: 0.1553
2023-02-06 14:02:17 | Valid | Epoch[089/600] Iteration[003/008] Valid loss: 0.1452
2023-02-06 14:02:17 | Valid | Epoch[089/600] Iteration[004/008] Valid loss: 0.1430
2023-02-06 14:02:17 | Valid | Epoch[089/600] Iteration[005/008] Valid loss: 0.1427
2023-02-06 14:02:17 | Valid | Epoch[089/600] Iteration[006/008] Valid loss: 0.1405
2023-02-06 14:02:17 | Valid | Epoch[089/600] Iteration[007/008] Valid loss: 0.1516
2023-02-06 14:02:17 | Valid | Epoch[089/600] Iteration[008/008] Valid loss: 0.1525
2023-02-06 14:02:17 | Valid | Epoch[089/600] MIou: 0.9173411771338593
2023-02-06 14:02:17 | Valid | Epoch[089/600] Pixel Accuracy: 0.9849713643391927
2023-02-06 14:02:17 | Valid | Epoch[089/600] Mean Pixel Accuracy: 0.9698015894532155
2023-02-06 14:02:17 | Stage | Epoch[089/600] Train loss:0.0529
2023-02-06 14:02:17 | Stage | Epoch[089/600] Valid loss:0.1525
2023-02-06 14:02:17 | Stage | Epoch[089/600] LR:0.01

2023-02-06 14:02:17 | Train | Epoch[090/600] Iteration[001/030] Train loss: 0.0524
2023-02-06 14:02:18 | Train | Epoch[090/600] Iteration[002/030] Train loss: 0.0508
2023-02-06 14:02:18 | Train | Epoch[090/600] Iteration[003/030] Train loss: 0.0519
2023-02-06 14:02:18 | Train | Epoch[090/600] Iteration[004/030] Train loss: 0.0515
2023-02-06 14:02:18 | Train | Epoch[090/600] Iteration[005/030] Train loss: 0.0513
2023-02-06 14:02:19 | Train | Epoch[090/600] Iteration[006/030] Train loss: 0.0512
2023-02-06 14:02:19 | Train | Epoch[090/600] Iteration[007/030] Train loss: 0.0511
2023-02-06 14:02:19 | Train | Epoch[090/600] Iteration[008/030] Train loss: 0.0514
2023-02-06 14:02:19 | Train | Epoch[090/600] Iteration[009/030] Train loss: 0.0513
2023-02-06 14:02:19 | Train | Epoch[090/600] Iteration[010/030] Train loss: 0.0513
2023-02-06 14:02:20 | Train | Epoch[090/600] Iteration[011/030] Train loss: 0.0516
2023-02-06 14:02:20 | Train | Epoch[090/600] Iteration[012/030] Train loss: 0.0520
2023-02-06 14:02:20 | Train | Epoch[090/600] Iteration[013/030] Train loss: 0.0519
2023-02-06 14:02:20 | Train | Epoch[090/600] Iteration[014/030] Train loss: 0.0519
2023-02-06 14:02:20 | Train | Epoch[090/600] Iteration[015/030] Train loss: 0.0520
2023-02-06 14:02:21 | Train | Epoch[090/600] Iteration[016/030] Train loss: 0.0520
2023-02-06 14:02:21 | Train | Epoch[090/600] Iteration[017/030] Train loss: 0.0520
2023-02-06 14:02:21 | Train | Epoch[090/600] Iteration[018/030] Train loss: 0.0520
2023-02-06 14:02:21 | Train | Epoch[090/600] Iteration[019/030] Train loss: 0.0520
2023-02-06 14:02:22 | Train | Epoch[090/600] Iteration[020/030] Train loss: 0.0524
2023-02-06 14:02:22 | Train | Epoch[090/600] Iteration[021/030] Train loss: 0.0523
2023-02-06 14:02:22 | Train | Epoch[090/600] Iteration[022/030] Train loss: 0.0523
2023-02-06 14:02:22 | Train | Epoch[090/600] Iteration[023/030] Train loss: 0.0524
2023-02-06 14:02:22 | Train | Epoch[090/600] Iteration[024/030] Train loss: 0.0524
2023-02-06 14:02:23 | Train | Epoch[090/600] Iteration[025/030] Train loss: 0.0526
2023-02-06 14:02:23 | Train | Epoch[090/600] Iteration[026/030] Train loss: 0.0525
2023-02-06 14:02:23 | Train | Epoch[090/600] Iteration[027/030] Train loss: 0.0525
2023-02-06 14:02:23 | Train | Epoch[090/600] Iteration[028/030] Train loss: 0.0525
2023-02-06 14:02:24 | Train | Epoch[090/600] Iteration[029/030] Train loss: 0.0525
2023-02-06 14:02:24 | Train | Epoch[090/600] Iteration[030/030] Train loss: 0.0525
2023-02-06 14:02:24 | Valid | Epoch[090/600] Iteration[001/008] Valid loss: 2.7164
2023-02-06 14:02:24 | Valid | Epoch[090/600] Iteration[002/008] Valid loss: 2.6865
2023-02-06 14:02:24 | Valid | Epoch[090/600] Iteration[003/008] Valid loss: 2.8546
2023-02-06 14:02:24 | Valid | Epoch[090/600] Iteration[004/008] Valid loss: 2.9347
2023-02-06 14:02:24 | Valid | Epoch[090/600] Iteration[005/008] Valid loss: 2.9762
2023-02-06 14:02:24 | Valid | Epoch[090/600] Iteration[006/008] Valid loss: 2.9366
2023-02-06 14:02:24 | Valid | Epoch[090/600] Iteration[007/008] Valid loss: 3.0210
2023-02-06 14:02:24 | Valid | Epoch[090/600] Iteration[008/008] Valid loss: 3.1414
2023-02-06 14:02:24 | Valid | Epoch[090/600] MIou: 0.5813264738678898
2023-02-06 14:02:24 | Valid | Epoch[090/600] Pixel Accuracy: 0.8311144510904948
2023-02-06 14:02:24 | Valid | Epoch[090/600] Mean Pixel Accuracy: 0.9068752973638154
2023-02-06 14:02:24 | Stage | Epoch[090/600] Train loss:0.0525
2023-02-06 14:02:24 | Stage | Epoch[090/600] Valid loss:3.1414
2023-02-06 14:02:24 | Stage | Epoch[090/600] LR:0.01

2023-02-06 14:02:25 | Train | Epoch[091/600] Iteration[001/030] Train loss: 0.0518
2023-02-06 14:02:25 | Train | Epoch[091/600] Iteration[002/030] Train loss: 0.0515
2023-02-06 14:02:25 | Train | Epoch[091/600] Iteration[003/030] Train loss: 0.0510
2023-02-06 14:02:26 | Train | Epoch[091/600] Iteration[004/030] Train loss: 0.0506
2023-02-06 14:02:26 | Train | Epoch[091/600] Iteration[005/030] Train loss: 0.0509
2023-02-06 14:02:26 | Train | Epoch[091/600] Iteration[006/030] Train loss: 0.0511
2023-02-06 14:02:26 | Train | Epoch[091/600] Iteration[007/030] Train loss: 0.0512
2023-02-06 14:02:26 | Train | Epoch[091/600] Iteration[008/030] Train loss: 0.0511
2023-02-06 14:02:27 | Train | Epoch[091/600] Iteration[009/030] Train loss: 0.0513
2023-02-06 14:02:27 | Train | Epoch[091/600] Iteration[010/030] Train loss: 0.0516
2023-02-06 14:02:27 | Train | Epoch[091/600] Iteration[011/030] Train loss: 0.0516
2023-02-06 14:02:27 | Train | Epoch[091/600] Iteration[012/030] Train loss: 0.0517
2023-02-06 14:02:28 | Train | Epoch[091/600] Iteration[013/030] Train loss: 0.0516
2023-02-06 14:02:28 | Train | Epoch[091/600] Iteration[014/030] Train loss: 0.0516
2023-02-06 14:02:28 | Train | Epoch[091/600] Iteration[015/030] Train loss: 0.0516
2023-02-06 14:02:28 | Train | Epoch[091/600] Iteration[016/030] Train loss: 0.0515
2023-02-06 14:02:28 | Train | Epoch[091/600] Iteration[017/030] Train loss: 0.0514
2023-02-06 14:02:29 | Train | Epoch[091/600] Iteration[018/030] Train loss: 0.0514
2023-02-06 14:02:29 | Train | Epoch[091/600] Iteration[019/030] Train loss: 0.0514
2023-02-06 14:02:29 | Train | Epoch[091/600] Iteration[020/030] Train loss: 0.0514
2023-02-06 14:02:29 | Train | Epoch[091/600] Iteration[021/030] Train loss: 0.0514
2023-02-06 14:02:30 | Train | Epoch[091/600] Iteration[022/030] Train loss: 0.0514
2023-02-06 14:02:30 | Train | Epoch[091/600] Iteration[023/030] Train loss: 0.0516
2023-02-06 14:02:30 | Train | Epoch[091/600] Iteration[024/030] Train loss: 0.0515
2023-02-06 14:02:30 | Train | Epoch[091/600] Iteration[025/030] Train loss: 0.0515
2023-02-06 14:02:30 | Train | Epoch[091/600] Iteration[026/030] Train loss: 0.0515
2023-02-06 14:02:31 | Train | Epoch[091/600] Iteration[027/030] Train loss: 0.0514
2023-02-06 14:02:31 | Train | Epoch[091/600] Iteration[028/030] Train loss: 0.0514
2023-02-06 14:02:31 | Train | Epoch[091/600] Iteration[029/030] Train loss: 0.0513
2023-02-06 14:02:31 | Train | Epoch[091/600] Iteration[030/030] Train loss: 0.0512
2023-02-06 14:02:32 | Valid | Epoch[091/600] Iteration[001/008] Valid loss: 0.0736
2023-02-06 14:02:32 | Valid | Epoch[091/600] Iteration[002/008] Valid loss: 0.0719
2023-02-06 14:02:32 | Valid | Epoch[091/600] Iteration[003/008] Valid loss: 0.0733
2023-02-06 14:02:32 | Valid | Epoch[091/600] Iteration[004/008] Valid loss: 0.0728
2023-02-06 14:02:32 | Valid | Epoch[091/600] Iteration[005/008] Valid loss: 0.0737
2023-02-06 14:02:32 | Valid | Epoch[091/600] Iteration[006/008] Valid loss: 0.0729
2023-02-06 14:02:32 | Valid | Epoch[091/600] Iteration[007/008] Valid loss: 0.0718
2023-02-06 14:02:32 | Valid | Epoch[091/600] Iteration[008/008] Valid loss: 0.0718
2023-02-06 14:02:32 | Valid | Epoch[091/600] MIou: 0.8724976242822198
2023-02-06 14:02:32 | Valid | Epoch[091/600] Pixel Accuracy: 0.9789237976074219
2023-02-06 14:02:32 | Valid | Epoch[091/600] Mean Pixel Accuracy: 0.8852688297282332
2023-02-06 14:02:32 | Stage | Epoch[091/600] Train loss:0.0512
2023-02-06 14:02:32 | Stage | Epoch[091/600] Valid loss:0.0718
2023-02-06 14:02:32 | Stage | Epoch[091/600] LR:0.01

2023-02-06 14:02:32 | Train | Epoch[092/600] Iteration[001/030] Train loss: 0.0498
2023-02-06 14:02:33 | Train | Epoch[092/600] Iteration[002/030] Train loss: 0.0503
2023-02-06 14:02:33 | Train | Epoch[092/600] Iteration[003/030] Train loss: 0.0504
2023-02-06 14:02:33 | Train | Epoch[092/600] Iteration[004/030] Train loss: 0.0502
2023-02-06 14:02:33 | Train | Epoch[092/600] Iteration[005/030] Train loss: 0.0507
2023-02-06 14:02:34 | Train | Epoch[092/600] Iteration[006/030] Train loss: 0.0507
2023-02-06 14:02:34 | Train | Epoch[092/600] Iteration[007/030] Train loss: 0.0506
2023-02-06 14:02:34 | Train | Epoch[092/600] Iteration[008/030] Train loss: 0.0506
2023-02-06 14:02:34 | Train | Epoch[092/600] Iteration[009/030] Train loss: 0.0508
2023-02-06 14:02:34 | Train | Epoch[092/600] Iteration[010/030] Train loss: 0.0505
2023-02-06 14:02:35 | Train | Epoch[092/600] Iteration[011/030] Train loss: 0.0507
2023-02-06 14:02:35 | Train | Epoch[092/600] Iteration[012/030] Train loss: 0.0506
2023-02-06 14:02:35 | Train | Epoch[092/600] Iteration[013/030] Train loss: 0.0507
2023-02-06 14:02:35 | Train | Epoch[092/600] Iteration[014/030] Train loss: 0.0506
2023-02-06 14:02:35 | Train | Epoch[092/600] Iteration[015/030] Train loss: 0.0506
2023-02-06 14:02:36 | Train | Epoch[092/600] Iteration[016/030] Train loss: 0.0506
2023-02-06 14:02:36 | Train | Epoch[092/600] Iteration[017/030] Train loss: 0.0505
2023-02-06 14:02:36 | Train | Epoch[092/600] Iteration[018/030] Train loss: 0.0506
2023-02-06 14:02:36 | Train | Epoch[092/600] Iteration[019/030] Train loss: 0.0506
2023-02-06 14:02:37 | Train | Epoch[092/600] Iteration[020/030] Train loss: 0.0506
2023-02-06 14:02:37 | Train | Epoch[092/600] Iteration[021/030] Train loss: 0.0505
2023-02-06 14:02:37 | Train | Epoch[092/600] Iteration[022/030] Train loss: 0.0505
2023-02-06 14:02:37 | Train | Epoch[092/600] Iteration[023/030] Train loss: 0.0504
2023-02-06 14:02:37 | Train | Epoch[092/600] Iteration[024/030] Train loss: 0.0504
2023-02-06 14:02:38 | Train | Epoch[092/600] Iteration[025/030] Train loss: 0.0504
2023-02-06 14:02:38 | Train | Epoch[092/600] Iteration[026/030] Train loss: 0.0504
2023-02-06 14:02:38 | Train | Epoch[092/600] Iteration[027/030] Train loss: 0.0503
2023-02-06 14:02:38 | Train | Epoch[092/600] Iteration[028/030] Train loss: 0.0503
2023-02-06 14:02:39 | Train | Epoch[092/600] Iteration[029/030] Train loss: 0.0503
2023-02-06 14:02:39 | Train | Epoch[092/600] Iteration[030/030] Train loss: 0.0503
2023-02-06 14:02:39 | Valid | Epoch[092/600] Iteration[001/008] Valid loss: 0.2689
2023-02-06 14:02:39 | Valid | Epoch[092/600] Iteration[002/008] Valid loss: 0.2162
2023-02-06 14:02:39 | Valid | Epoch[092/600] Iteration[003/008] Valid loss: 0.2125
2023-02-06 14:02:39 | Valid | Epoch[092/600] Iteration[004/008] Valid loss: 0.2068
2023-02-06 14:02:39 | Valid | Epoch[092/600] Iteration[005/008] Valid loss: 0.2088
2023-02-06 14:02:39 | Valid | Epoch[092/600] Iteration[006/008] Valid loss: 0.2024
2023-02-06 14:02:39 | Valid | Epoch[092/600] Iteration[007/008] Valid loss: 0.2127
2023-02-06 14:02:39 | Valid | Epoch[092/600] Iteration[008/008] Valid loss: 0.2109
2023-02-06 14:02:39 | Valid | Epoch[092/600] MIou: 0.8994915760532112
2023-02-06 14:02:39 | Valid | Epoch[092/600] Pixel Accuracy: 0.9806493123372396
2023-02-06 14:02:39 | Valid | Epoch[092/600] Mean Pixel Accuracy: 0.9791875799967905
2023-02-06 14:02:39 | Stage | Epoch[092/600] Train loss:0.0503
2023-02-06 14:02:39 | Stage | Epoch[092/600] Valid loss:0.2109
2023-02-06 14:02:39 | Stage | Epoch[092/600] LR:0.01

2023-02-06 14:02:40 | Train | Epoch[093/600] Iteration[001/030] Train loss: 0.0490
2023-02-06 14:02:40 | Train | Epoch[093/600] Iteration[002/030] Train loss: 0.0487
2023-02-06 14:02:40 | Train | Epoch[093/600] Iteration[003/030] Train loss: 0.0491
2023-02-06 14:02:41 | Train | Epoch[093/600] Iteration[004/030] Train loss: 0.0490
2023-02-06 14:02:41 | Train | Epoch[093/600] Iteration[005/030] Train loss: 0.0491
2023-02-06 14:02:41 | Train | Epoch[093/600] Iteration[006/030] Train loss: 0.0490
2023-02-06 14:02:41 | Train | Epoch[093/600] Iteration[007/030] Train loss: 0.0490
2023-02-06 14:02:41 | Train | Epoch[093/600] Iteration[008/030] Train loss: 0.0495
2023-02-06 14:02:42 | Train | Epoch[093/600] Iteration[009/030] Train loss: 0.0493
2023-02-06 14:02:42 | Train | Epoch[093/600] Iteration[010/030] Train loss: 0.0493
2023-02-06 14:02:42 | Train | Epoch[093/600] Iteration[011/030] Train loss: 0.0494
2023-02-06 14:02:42 | Train | Epoch[093/600] Iteration[012/030] Train loss: 0.0493
2023-02-06 14:02:43 | Train | Epoch[093/600] Iteration[013/030] Train loss: 0.0494
2023-02-06 14:02:43 | Train | Epoch[093/600] Iteration[014/030] Train loss: 0.0495
2023-02-06 14:02:43 | Train | Epoch[093/600] Iteration[015/030] Train loss: 0.0494
2023-02-06 14:02:43 | Train | Epoch[093/600] Iteration[016/030] Train loss: 0.0495
2023-02-06 14:02:43 | Train | Epoch[093/600] Iteration[017/030] Train loss: 0.0496
2023-02-06 14:02:44 | Train | Epoch[093/600] Iteration[018/030] Train loss: 0.0495
2023-02-06 14:02:44 | Train | Epoch[093/600] Iteration[019/030] Train loss: 0.0495
2023-02-06 14:02:44 | Train | Epoch[093/600] Iteration[020/030] Train loss: 0.0493
2023-02-06 14:02:44 | Train | Epoch[093/600] Iteration[021/030] Train loss: 0.0494
2023-02-06 14:02:45 | Train | Epoch[093/600] Iteration[022/030] Train loss: 0.0493
2023-02-06 14:02:45 | Train | Epoch[093/600] Iteration[023/030] Train loss: 0.0493
2023-02-06 14:02:45 | Train | Epoch[093/600] Iteration[024/030] Train loss: 0.0493
2023-02-06 14:02:45 | Train | Epoch[093/600] Iteration[025/030] Train loss: 0.0493
2023-02-06 14:02:45 | Train | Epoch[093/600] Iteration[026/030] Train loss: 0.0493
2023-02-06 14:02:46 | Train | Epoch[093/600] Iteration[027/030] Train loss: 0.0494
2023-02-06 14:02:46 | Train | Epoch[093/600] Iteration[028/030] Train loss: 0.0494
2023-02-06 14:02:46 | Train | Epoch[093/600] Iteration[029/030] Train loss: 0.0494
2023-02-06 14:02:46 | Train | Epoch[093/600] Iteration[030/030] Train loss: 0.0494
2023-02-06 14:02:47 | Valid | Epoch[093/600] Iteration[001/008] Valid loss: 3.1447
2023-02-06 14:02:47 | Valid | Epoch[093/600] Iteration[002/008] Valid loss: 3.0448
2023-02-06 14:02:47 | Valid | Epoch[093/600] Iteration[003/008] Valid loss: 3.2319
2023-02-06 14:02:47 | Valid | Epoch[093/600] Iteration[004/008] Valid loss: 3.3337
2023-02-06 14:02:47 | Valid | Epoch[093/600] Iteration[005/008] Valid loss: 3.4168
2023-02-06 14:02:47 | Valid | Epoch[093/600] Iteration[006/008] Valid loss: 3.3700
2023-02-06 14:02:47 | Valid | Epoch[093/600] Iteration[007/008] Valid loss: 3.4623
2023-02-06 14:02:47 | Valid | Epoch[093/600] Iteration[008/008] Valid loss: 3.5768
2023-02-06 14:02:47 | Valid | Epoch[093/600] MIou: 0.6848267561563992
2023-02-06 14:02:47 | Valid | Epoch[093/600] Pixel Accuracy: 0.9014294942220052
2023-02-06 14:02:47 | Valid | Epoch[093/600] Mean Pixel Accuracy: 0.9455488058190002
2023-02-06 14:02:47 | Stage | Epoch[093/600] Train loss:0.0494
2023-02-06 14:02:47 | Stage | Epoch[093/600] Valid loss:3.5768
2023-02-06 14:02:47 | Stage | Epoch[093/600] LR:0.01

2023-02-06 14:02:47 | Train | Epoch[094/600] Iteration[001/030] Train loss: 0.0497
2023-02-06 14:02:48 | Train | Epoch[094/600] Iteration[002/030] Train loss: 0.0496
2023-02-06 14:02:48 | Train | Epoch[094/600] Iteration[003/030] Train loss: 0.0499
2023-02-06 14:02:48 | Train | Epoch[094/600] Iteration[004/030] Train loss: 0.0498
2023-02-06 14:02:48 | Train | Epoch[094/600] Iteration[005/030] Train loss: 0.0500
2023-02-06 14:02:49 | Train | Epoch[094/600] Iteration[006/030] Train loss: 0.0502
2023-02-06 14:02:49 | Train | Epoch[094/600] Iteration[007/030] Train loss: 0.0502
2023-02-06 14:02:49 | Train | Epoch[094/600] Iteration[008/030] Train loss: 0.0502
2023-02-06 14:02:49 | Train | Epoch[094/600] Iteration[009/030] Train loss: 0.0502
2023-02-06 14:02:49 | Train | Epoch[094/600] Iteration[010/030] Train loss: 0.0500
2023-02-06 14:02:50 | Train | Epoch[094/600] Iteration[011/030] Train loss: 0.0497
2023-02-06 14:02:50 | Train | Epoch[094/600] Iteration[012/030] Train loss: 0.0496
2023-02-06 14:02:50 | Train | Epoch[094/600] Iteration[013/030] Train loss: 0.0498
2023-02-06 14:02:50 | Train | Epoch[094/600] Iteration[014/030] Train loss: 0.0498
2023-02-06 14:02:50 | Train | Epoch[094/600] Iteration[015/030] Train loss: 0.0496
2023-02-06 14:02:51 | Train | Epoch[094/600] Iteration[016/030] Train loss: 0.0495
2023-02-06 14:02:51 | Train | Epoch[094/600] Iteration[017/030] Train loss: 0.0496
2023-02-06 14:02:51 | Train | Epoch[094/600] Iteration[018/030] Train loss: 0.0494
2023-02-06 14:02:51 | Train | Epoch[094/600] Iteration[019/030] Train loss: 0.0494
2023-02-06 14:02:52 | Train | Epoch[094/600] Iteration[020/030] Train loss: 0.0495
2023-02-06 14:02:52 | Train | Epoch[094/600] Iteration[021/030] Train loss: 0.0494
2023-02-06 14:02:52 | Train | Epoch[094/600] Iteration[022/030] Train loss: 0.0493
2023-02-06 14:02:52 | Train | Epoch[094/600] Iteration[023/030] Train loss: 0.0493
2023-02-06 14:02:52 | Train | Epoch[094/600] Iteration[024/030] Train loss: 0.0494
2023-02-06 14:02:53 | Train | Epoch[094/600] Iteration[025/030] Train loss: 0.0494
2023-02-06 14:02:53 | Train | Epoch[094/600] Iteration[026/030] Train loss: 0.0493
2023-02-06 14:02:53 | Train | Epoch[094/600] Iteration[027/030] Train loss: 0.0494
2023-02-06 14:02:53 | Train | Epoch[094/600] Iteration[028/030] Train loss: 0.0494
2023-02-06 14:02:54 | Train | Epoch[094/600] Iteration[029/030] Train loss: 0.0493
2023-02-06 14:02:54 | Train | Epoch[094/600] Iteration[030/030] Train loss: 0.0492
2023-02-06 14:02:54 | Valid | Epoch[094/600] Iteration[001/008] Valid loss: 0.1178
2023-02-06 14:02:54 | Valid | Epoch[094/600] Iteration[002/008] Valid loss: 0.1152
2023-02-06 14:02:54 | Valid | Epoch[094/600] Iteration[003/008] Valid loss: 0.1175
2023-02-06 14:02:54 | Valid | Epoch[094/600] Iteration[004/008] Valid loss: 0.1166
2023-02-06 14:02:54 | Valid | Epoch[094/600] Iteration[005/008] Valid loss: 0.1171
2023-02-06 14:02:54 | Valid | Epoch[094/600] Iteration[006/008] Valid loss: 0.1161
2023-02-06 14:02:54 | Valid | Epoch[094/600] Iteration[007/008] Valid loss: 0.1150
2023-02-06 14:02:54 | Valid | Epoch[094/600] Iteration[008/008] Valid loss: 0.1156
2023-02-06 14:02:54 | Valid | Epoch[094/600] MIou: 0.8445921034070633
2023-02-06 14:02:54 | Valid | Epoch[094/600] Pixel Accuracy: 0.9731127421061198
2023-02-06 14:02:54 | Valid | Epoch[094/600] Mean Pixel Accuracy: 0.8762986562416899
2023-02-06 14:02:54 | Stage | Epoch[094/600] Train loss:0.0492
2023-02-06 14:02:54 | Stage | Epoch[094/600] Valid loss:0.1156
2023-02-06 14:02:54 | Stage | Epoch[094/600] LR:0.01

2023-02-06 14:02:55 | Train | Epoch[095/600] Iteration[001/030] Train loss: 0.0468
2023-02-06 14:02:55 | Train | Epoch[095/600] Iteration[002/030] Train loss: 0.0472
2023-02-06 14:02:55 | Train | Epoch[095/600] Iteration[003/030] Train loss: 0.0474
2023-02-06 14:02:56 | Train | Epoch[095/600] Iteration[004/030] Train loss: 0.0491
2023-02-06 14:02:56 | Train | Epoch[095/600] Iteration[005/030] Train loss: 0.0487
2023-02-06 14:02:56 | Train | Epoch[095/600] Iteration[006/030] Train loss: 0.0485
2023-02-06 14:02:56 | Train | Epoch[095/600] Iteration[007/030] Train loss: 0.0486
2023-02-06 14:02:56 | Train | Epoch[095/600] Iteration[008/030] Train loss: 0.0491
2023-02-06 14:02:57 | Train | Epoch[095/600] Iteration[009/030] Train loss: 0.0493
2023-02-06 14:02:57 | Train | Epoch[095/600] Iteration[010/030] Train loss: 0.0494
2023-02-06 14:02:57 | Train | Epoch[095/600] Iteration[011/030] Train loss: 0.0494
2023-02-06 14:02:57 | Train | Epoch[095/600] Iteration[012/030] Train loss: 0.0495
2023-02-06 14:02:58 | Train | Epoch[095/600] Iteration[013/030] Train loss: 0.0495
2023-02-06 14:02:58 | Train | Epoch[095/600] Iteration[014/030] Train loss: 0.0496
2023-02-06 14:02:58 | Train | Epoch[095/600] Iteration[015/030] Train loss: 0.0495
2023-02-06 14:02:58 | Train | Epoch[095/600] Iteration[016/030] Train loss: 0.0493
2023-02-06 14:02:58 | Train | Epoch[095/600] Iteration[017/030] Train loss: 0.0493
2023-02-06 14:02:59 | Train | Epoch[095/600] Iteration[018/030] Train loss: 0.0493
2023-02-06 14:02:59 | Train | Epoch[095/600] Iteration[019/030] Train loss: 0.0493
2023-02-06 14:02:59 | Train | Epoch[095/600] Iteration[020/030] Train loss: 0.0493
2023-02-06 14:02:59 | Train | Epoch[095/600] Iteration[021/030] Train loss: 0.0492
2023-02-06 14:03:00 | Train | Epoch[095/600] Iteration[022/030] Train loss: 0.0493
2023-02-06 14:03:00 | Train | Epoch[095/600] Iteration[023/030] Train loss: 0.0491
2023-02-06 14:03:00 | Train | Epoch[095/600] Iteration[024/030] Train loss: 0.0491
2023-02-06 14:03:00 | Train | Epoch[095/600] Iteration[025/030] Train loss: 0.0491
2023-02-06 14:03:00 | Train | Epoch[095/600] Iteration[026/030] Train loss: 0.0491
2023-02-06 14:03:01 | Train | Epoch[095/600] Iteration[027/030] Train loss: 0.0491
2023-02-06 14:03:01 | Train | Epoch[095/600] Iteration[028/030] Train loss: 0.0490
2023-02-06 14:03:01 | Train | Epoch[095/600] Iteration[029/030] Train loss: 0.0489
2023-02-06 14:03:01 | Train | Epoch[095/600] Iteration[030/030] Train loss: 0.0489
2023-02-06 14:03:02 | Valid | Epoch[095/600] Iteration[001/008] Valid loss: 0.2792
2023-02-06 14:03:02 | Valid | Epoch[095/600] Iteration[002/008] Valid loss: 0.2177
2023-02-06 14:03:02 | Valid | Epoch[095/600] Iteration[003/008] Valid loss: 0.2227
2023-02-06 14:03:02 | Valid | Epoch[095/600] Iteration[004/008] Valid loss: 0.2191
2023-02-06 14:03:02 | Valid | Epoch[095/600] Iteration[005/008] Valid loss: 0.2225
2023-02-06 14:03:02 | Valid | Epoch[095/600] Iteration[006/008] Valid loss: 0.2185
2023-02-06 14:03:02 | Valid | Epoch[095/600] Iteration[007/008] Valid loss: 0.2410
2023-02-06 14:03:02 | Valid | Epoch[095/600] Iteration[008/008] Valid loss: 0.2358
2023-02-06 14:03:02 | Valid | Epoch[095/600] MIou: 0.9079336353139764
2023-02-06 14:03:02 | Valid | Epoch[095/600] Pixel Accuracy: 0.9825795491536459
2023-02-06 14:03:02 | Valid | Epoch[095/600] Mean Pixel Accuracy: 0.9795637495503919
2023-02-06 14:03:02 | Stage | Epoch[095/600] Train loss:0.0489
2023-02-06 14:03:02 | Stage | Epoch[095/600] Valid loss:0.2358
2023-02-06 14:03:02 | Stage | Epoch[095/600] LR:0.01

2023-02-06 14:03:02 | Train | Epoch[096/600] Iteration[001/030] Train loss: 0.0494
2023-02-06 14:03:03 | Train | Epoch[096/600] Iteration[002/030] Train loss: 0.0480
2023-02-06 14:03:03 | Train | Epoch[096/600] Iteration[003/030] Train loss: 0.0478
2023-02-06 14:03:03 | Train | Epoch[096/600] Iteration[004/030] Train loss: 0.0477
2023-02-06 14:03:03 | Train | Epoch[096/600] Iteration[005/030] Train loss: 0.0477
2023-02-06 14:03:04 | Train | Epoch[096/600] Iteration[006/030] Train loss: 0.0473
2023-02-06 14:03:04 | Train | Epoch[096/600] Iteration[007/030] Train loss: 0.0475
2023-02-06 14:03:04 | Train | Epoch[096/600] Iteration[008/030] Train loss: 0.0480
2023-02-06 14:03:04 | Train | Epoch[096/600] Iteration[009/030] Train loss: 0.0478
2023-02-06 14:03:04 | Train | Epoch[096/600] Iteration[010/030] Train loss: 0.0479
2023-02-06 14:03:05 | Train | Epoch[096/600] Iteration[011/030] Train loss: 0.0480
2023-02-06 14:03:05 | Train | Epoch[096/600] Iteration[012/030] Train loss: 0.0482
2023-02-06 14:03:05 | Train | Epoch[096/600] Iteration[013/030] Train loss: 0.0481
2023-02-06 14:03:05 | Train | Epoch[096/600] Iteration[014/030] Train loss: 0.0482
2023-02-06 14:03:05 | Train | Epoch[096/600] Iteration[015/030] Train loss: 0.0481
2023-02-06 14:03:06 | Train | Epoch[096/600] Iteration[016/030] Train loss: 0.0480
2023-02-06 14:03:06 | Train | Epoch[096/600] Iteration[017/030] Train loss: 0.0479
2023-02-06 14:03:06 | Train | Epoch[096/600] Iteration[018/030] Train loss: 0.0478
2023-02-06 14:03:06 | Train | Epoch[096/600] Iteration[019/030] Train loss: 0.0478
2023-02-06 14:03:07 | Train | Epoch[096/600] Iteration[020/030] Train loss: 0.0477
2023-02-06 14:03:07 | Train | Epoch[096/600] Iteration[021/030] Train loss: 0.0478
2023-02-06 14:03:07 | Train | Epoch[096/600] Iteration[022/030] Train loss: 0.0477
2023-02-06 14:03:07 | Train | Epoch[096/600] Iteration[023/030] Train loss: 0.0477
2023-02-06 14:03:07 | Train | Epoch[096/600] Iteration[024/030] Train loss: 0.0477
2023-02-06 14:03:08 | Train | Epoch[096/600] Iteration[025/030] Train loss: 0.0477
2023-02-06 14:03:08 | Train | Epoch[096/600] Iteration[026/030] Train loss: 0.0477
2023-02-06 14:03:08 | Train | Epoch[096/600] Iteration[027/030] Train loss: 0.0476
2023-02-06 14:03:08 | Train | Epoch[096/600] Iteration[028/030] Train loss: 0.0477
2023-02-06 14:03:09 | Train | Epoch[096/600] Iteration[029/030] Train loss: 0.0477
2023-02-06 14:03:09 | Train | Epoch[096/600] Iteration[030/030] Train loss: 0.0478
2023-02-06 14:03:09 | Valid | Epoch[096/600] Iteration[001/008] Valid loss: 0.2394
2023-02-06 14:03:09 | Valid | Epoch[096/600] Iteration[002/008] Valid loss: 0.2241
2023-02-06 14:03:09 | Valid | Epoch[096/600] Iteration[003/008] Valid loss: 0.2352
2023-02-06 14:03:09 | Valid | Epoch[096/600] Iteration[004/008] Valid loss: 0.2359
2023-02-06 14:03:09 | Valid | Epoch[096/600] Iteration[005/008] Valid loss: 0.2403
2023-02-06 14:03:09 | Valid | Epoch[096/600] Iteration[006/008] Valid loss: 0.2348
2023-02-06 14:03:09 | Valid | Epoch[096/600] Iteration[007/008] Valid loss: 0.2540
2023-02-06 14:03:09 | Valid | Epoch[096/600] Iteration[008/008] Valid loss: 0.2510
2023-02-06 14:03:09 | Valid | Epoch[096/600] MIou: 0.899239290459886
2023-02-06 14:03:09 | Valid | Epoch[096/600] Pixel Accuracy: 0.9805653889973959
2023-02-06 14:03:09 | Valid | Epoch[096/600] Mean Pixel Accuracy: 0.9798262230732732
2023-02-06 14:03:09 | Stage | Epoch[096/600] Train loss:0.0478
2023-02-06 14:03:09 | Stage | Epoch[096/600] Valid loss:0.2510
2023-02-06 14:03:09 | Stage | Epoch[096/600] LR:0.01

2023-02-06 14:03:10 | Train | Epoch[097/600] Iteration[001/030] Train loss: 0.0445
2023-02-06 14:03:10 | Train | Epoch[097/600] Iteration[002/030] Train loss: 0.0448
2023-02-06 14:03:10 | Train | Epoch[097/600] Iteration[003/030] Train loss: 0.0456
2023-02-06 14:03:11 | Train | Epoch[097/600] Iteration[004/030] Train loss: 0.0460
2023-02-06 14:03:11 | Train | Epoch[097/600] Iteration[005/030] Train loss: 0.0461
2023-02-06 14:03:11 | Train | Epoch[097/600] Iteration[006/030] Train loss: 0.0459
2023-02-06 14:03:11 | Train | Epoch[097/600] Iteration[007/030] Train loss: 0.0459
2023-02-06 14:03:11 | Train | Epoch[097/600] Iteration[008/030] Train loss: 0.0459
2023-02-06 14:03:12 | Train | Epoch[097/600] Iteration[009/030] Train loss: 0.0458
2023-02-06 14:03:12 | Train | Epoch[097/600] Iteration[010/030] Train loss: 0.0457
2023-02-06 14:03:12 | Train | Epoch[097/600] Iteration[011/030] Train loss: 0.0461
2023-02-06 14:03:12 | Train | Epoch[097/600] Iteration[012/030] Train loss: 0.0460
2023-02-06 14:03:13 | Train | Epoch[097/600] Iteration[013/030] Train loss: 0.0461
2023-02-06 14:03:13 | Train | Epoch[097/600] Iteration[014/030] Train loss: 0.0461
2023-02-06 14:03:13 | Train | Epoch[097/600] Iteration[015/030] Train loss: 0.0461
2023-02-06 14:03:13 | Train | Epoch[097/600] Iteration[016/030] Train loss: 0.0460
2023-02-06 14:03:13 | Train | Epoch[097/600] Iteration[017/030] Train loss: 0.0460
2023-02-06 14:03:14 | Train | Epoch[097/600] Iteration[018/030] Train loss: 0.0460
2023-02-06 14:03:14 | Train | Epoch[097/600] Iteration[019/030] Train loss: 0.0459
2023-02-06 14:03:14 | Train | Epoch[097/600] Iteration[020/030] Train loss: 0.0460
2023-02-06 14:03:14 | Train | Epoch[097/600] Iteration[021/030] Train loss: 0.0461
2023-02-06 14:03:15 | Train | Epoch[097/600] Iteration[022/030] Train loss: 0.0461
2023-02-06 14:03:15 | Train | Epoch[097/600] Iteration[023/030] Train loss: 0.0462
2023-02-06 14:03:15 | Train | Epoch[097/600] Iteration[024/030] Train loss: 0.0461
2023-02-06 14:03:15 | Train | Epoch[097/600] Iteration[025/030] Train loss: 0.0461
2023-02-06 14:03:15 | Train | Epoch[097/600] Iteration[026/030] Train loss: 0.0461
2023-02-06 14:03:16 | Train | Epoch[097/600] Iteration[027/030] Train loss: 0.0461
2023-02-06 14:03:16 | Train | Epoch[097/600] Iteration[028/030] Train loss: 0.0461
2023-02-06 14:03:16 | Train | Epoch[097/600] Iteration[029/030] Train loss: 0.0461
2023-02-06 14:03:16 | Train | Epoch[097/600] Iteration[030/030] Train loss: 0.0461
2023-02-06 14:03:17 | Valid | Epoch[097/600] Iteration[001/008] Valid loss: 0.0814
2023-02-06 14:03:17 | Valid | Epoch[097/600] Iteration[002/008] Valid loss: 0.0820
2023-02-06 14:03:17 | Valid | Epoch[097/600] Iteration[003/008] Valid loss: 0.0833
2023-02-06 14:03:17 | Valid | Epoch[097/600] Iteration[004/008] Valid loss: 0.0828
2023-02-06 14:03:17 | Valid | Epoch[097/600] Iteration[005/008] Valid loss: 0.0837
2023-02-06 14:03:17 | Valid | Epoch[097/600] Iteration[006/008] Valid loss: 0.0829
2023-02-06 14:03:17 | Valid | Epoch[097/600] Iteration[007/008] Valid loss: 0.0818
2023-02-06 14:03:17 | Valid | Epoch[097/600] Iteration[008/008] Valid loss: 0.0822
2023-02-06 14:03:17 | Valid | Epoch[097/600] MIou: 0.8079471817545695
2023-02-06 14:03:17 | Valid | Epoch[097/600] Pixel Accuracy: 0.9682133992513021
2023-02-06 14:03:17 | Valid | Epoch[097/600] Mean Pixel Accuracy: 0.8261029558882612
2023-02-06 14:03:17 | Stage | Epoch[097/600] Train loss:0.0461
2023-02-06 14:03:17 | Stage | Epoch[097/600] Valid loss:0.0822
2023-02-06 14:03:17 | Stage | Epoch[097/600] LR:0.01

2023-02-06 14:03:17 | Train | Epoch[098/600] Iteration[001/030] Train loss: 0.0503
2023-02-06 14:03:18 | Train | Epoch[098/600] Iteration[002/030] Train loss: 0.0477
2023-02-06 14:03:18 | Train | Epoch[098/600] Iteration[003/030] Train loss: 0.0467
2023-02-06 14:03:18 | Train | Epoch[098/600] Iteration[004/030] Train loss: 0.0461
2023-02-06 14:03:18 | Train | Epoch[098/600] Iteration[005/030] Train loss: 0.0461
2023-02-06 14:03:18 | Train | Epoch[098/600] Iteration[006/030] Train loss: 0.0458
2023-02-06 14:03:19 | Train | Epoch[098/600] Iteration[007/030] Train loss: 0.0455
2023-02-06 14:03:19 | Train | Epoch[098/600] Iteration[008/030] Train loss: 0.0454
2023-02-06 14:03:19 | Train | Epoch[098/600] Iteration[009/030] Train loss: 0.0452
2023-02-06 14:03:19 | Train | Epoch[098/600] Iteration[010/030] Train loss: 0.0453
2023-02-06 14:03:20 | Train | Epoch[098/600] Iteration[011/030] Train loss: 0.0453
2023-02-06 14:03:20 | Train | Epoch[098/600] Iteration[012/030] Train loss: 0.0452
2023-02-06 14:03:20 | Train | Epoch[098/600] Iteration[013/030] Train loss: 0.0452
2023-02-06 14:03:20 | Train | Epoch[098/600] Iteration[014/030] Train loss: 0.0452
2023-02-06 14:03:20 | Train | Epoch[098/600] Iteration[015/030] Train loss: 0.0453
2023-02-06 14:03:21 | Train | Epoch[098/600] Iteration[016/030] Train loss: 0.0455
2023-02-06 14:03:21 | Train | Epoch[098/600] Iteration[017/030] Train loss: 0.0456
2023-02-06 14:03:21 | Train | Epoch[098/600] Iteration[018/030] Train loss: 0.0456
2023-02-06 14:03:21 | Train | Epoch[098/600] Iteration[019/030] Train loss: 0.0455
2023-02-06 14:03:22 | Train | Epoch[098/600] Iteration[020/030] Train loss: 0.0455
2023-02-06 14:03:22 | Train | Epoch[098/600] Iteration[021/030] Train loss: 0.0455
2023-02-06 14:03:22 | Train | Epoch[098/600] Iteration[022/030] Train loss: 0.0455
2023-02-06 14:03:22 | Train | Epoch[098/600] Iteration[023/030] Train loss: 0.0454
2023-02-06 14:03:22 | Train | Epoch[098/600] Iteration[024/030] Train loss: 0.0455
2023-02-06 14:03:23 | Train | Epoch[098/600] Iteration[025/030] Train loss: 0.0454
2023-02-06 14:03:23 | Train | Epoch[098/600] Iteration[026/030] Train loss: 0.0454
2023-02-06 14:03:23 | Train | Epoch[098/600] Iteration[027/030] Train loss: 0.0454
2023-02-06 14:03:23 | Train | Epoch[098/600] Iteration[028/030] Train loss: 0.0454
2023-02-06 14:03:24 | Train | Epoch[098/600] Iteration[029/030] Train loss: 0.0453
2023-02-06 14:03:24 | Train | Epoch[098/600] Iteration[030/030] Train loss: 0.0454
2023-02-06 14:03:24 | Valid | Epoch[098/600] Iteration[001/008] Valid loss: 0.0769
2023-02-06 14:03:24 | Valid | Epoch[098/600] Iteration[002/008] Valid loss: 0.0726
2023-02-06 14:03:24 | Valid | Epoch[098/600] Iteration[003/008] Valid loss: 0.0756
2023-02-06 14:03:24 | Valid | Epoch[098/600] Iteration[004/008] Valid loss: 0.0741
2023-02-06 14:03:24 | Valid | Epoch[098/600] Iteration[005/008] Valid loss: 0.0757
2023-02-06 14:03:24 | Valid | Epoch[098/600] Iteration[006/008] Valid loss: 0.0750
2023-02-06 14:03:24 | Valid | Epoch[098/600] Iteration[007/008] Valid loss: 0.0760
2023-02-06 14:03:24 | Valid | Epoch[098/600] Iteration[008/008] Valid loss: 0.0752
2023-02-06 14:03:24 | Valid | Epoch[098/600] MIou: 0.8935447184013252
2023-02-06 14:03:24 | Valid | Epoch[098/600] Pixel Accuracy: 0.981957753499349
2023-02-06 14:03:24 | Valid | Epoch[098/600] Mean Pixel Accuracy: 0.91493594347887
2023-02-06 14:03:24 | Stage | Epoch[098/600] Train loss:0.0454
2023-02-06 14:03:24 | Stage | Epoch[098/600] Valid loss:0.0752
2023-02-06 14:03:24 | Stage | Epoch[098/600] LR:0.01

2023-02-06 14:03:25 | Train | Epoch[099/600] Iteration[001/030] Train loss: 0.0426
2023-02-06 14:03:25 | Train | Epoch[099/600] Iteration[002/030] Train loss: 0.0437
2023-02-06 14:03:25 | Train | Epoch[099/600] Iteration[003/030] Train loss: 0.0440
2023-02-06 14:03:25 | Train | Epoch[099/600] Iteration[004/030] Train loss: 0.0451
2023-02-06 14:03:26 | Train | Epoch[099/600] Iteration[005/030] Train loss: 0.0448
2023-02-06 14:03:26 | Train | Epoch[099/600] Iteration[006/030] Train loss: 0.0448
2023-02-06 14:03:26 | Train | Epoch[099/600] Iteration[007/030] Train loss: 0.0449
2023-02-06 14:03:26 | Train | Epoch[099/600] Iteration[008/030] Train loss: 0.0451
2023-02-06 14:03:27 | Train | Epoch[099/600] Iteration[009/030] Train loss: 0.0452
2023-02-06 14:03:27 | Train | Epoch[099/600] Iteration[010/030] Train loss: 0.0451
2023-02-06 14:03:27 | Train | Epoch[099/600] Iteration[011/030] Train loss: 0.0452
2023-02-06 14:03:27 | Train | Epoch[099/600] Iteration[012/030] Train loss: 0.0453
2023-02-06 14:03:27 | Train | Epoch[099/600] Iteration[013/030] Train loss: 0.0452
2023-02-06 14:03:28 | Train | Epoch[099/600] Iteration[014/030] Train loss: 0.0452
2023-02-06 14:03:28 | Train | Epoch[099/600] Iteration[015/030] Train loss: 0.0451
2023-02-06 14:03:28 | Train | Epoch[099/600] Iteration[016/030] Train loss: 0.0451
2023-02-06 14:03:28 | Train | Epoch[099/600] Iteration[017/030] Train loss: 0.0451
2023-02-06 14:03:29 | Train | Epoch[099/600] Iteration[018/030] Train loss: 0.0450
2023-02-06 14:03:29 | Train | Epoch[099/600] Iteration[019/030] Train loss: 0.0450
2023-02-06 14:03:29 | Train | Epoch[099/600] Iteration[020/030] Train loss: 0.0449
2023-02-06 14:03:29 | Train | Epoch[099/600] Iteration[021/030] Train loss: 0.0449
2023-02-06 14:03:29 | Train | Epoch[099/600] Iteration[022/030] Train loss: 0.0449
2023-02-06 14:03:30 | Train | Epoch[099/600] Iteration[023/030] Train loss: 0.0448
2023-02-06 14:03:30 | Train | Epoch[099/600] Iteration[024/030] Train loss: 0.0448
2023-02-06 14:03:30 | Train | Epoch[099/600] Iteration[025/030] Train loss: 0.0448
2023-02-06 14:03:30 | Train | Epoch[099/600] Iteration[026/030] Train loss: 0.0447
2023-02-06 14:03:31 | Train | Epoch[099/600] Iteration[027/030] Train loss: 0.0447
2023-02-06 14:03:31 | Train | Epoch[099/600] Iteration[028/030] Train loss: 0.0447
2023-02-06 14:03:31 | Train | Epoch[099/600] Iteration[029/030] Train loss: 0.0446
2023-02-06 14:03:31 | Train | Epoch[099/600] Iteration[030/030] Train loss: 0.0446
2023-02-06 14:03:31 | Valid | Epoch[099/600] Iteration[001/008] Valid loss: 0.0976
2023-02-06 14:03:31 | Valid | Epoch[099/600] Iteration[002/008] Valid loss: 0.0935
2023-02-06 14:03:32 | Valid | Epoch[099/600] Iteration[003/008] Valid loss: 0.0936
2023-02-06 14:03:32 | Valid | Epoch[099/600] Iteration[004/008] Valid loss: 0.0922
2023-02-06 14:03:32 | Valid | Epoch[099/600] Iteration[005/008] Valid loss: 0.0917
2023-02-06 14:03:32 | Valid | Epoch[099/600] Iteration[006/008] Valid loss: 0.0929
2023-02-06 14:03:32 | Valid | Epoch[099/600] Iteration[007/008] Valid loss: 0.0941
2023-02-06 14:03:32 | Valid | Epoch[099/600] Iteration[008/008] Valid loss: 0.0938
2023-02-06 14:03:32 | Valid | Epoch[099/600] MIou: 0.8720527313839721
2023-02-06 14:03:32 | Valid | Epoch[099/600] Pixel Accuracy: 0.9779586791992188
2023-02-06 14:03:32 | Valid | Epoch[099/600] Mean Pixel Accuracy: 0.9011094569339703
2023-02-06 14:03:32 | Stage | Epoch[099/600] Train loss:0.0446
2023-02-06 14:03:32 | Stage | Epoch[099/600] Valid loss:0.0938
2023-02-06 14:03:32 | Stage | Epoch[099/600] LR:0.01

2023-02-06 14:03:32 | Train | Epoch[100/600] Iteration[001/030] Train loss: 0.0429
2023-02-06 14:03:33 | Train | Epoch[100/600] Iteration[002/030] Train loss: 0.0433
2023-02-06 14:03:33 | Train | Epoch[100/600] Iteration[003/030] Train loss: 0.0433
2023-02-06 14:03:33 | Train | Epoch[100/600] Iteration[004/030] Train loss: 0.0435
2023-02-06 14:03:33 | Train | Epoch[100/600] Iteration[005/030] Train loss: 0.0436
2023-02-06 14:03:33 | Train | Epoch[100/600] Iteration[006/030] Train loss: 0.0435
2023-02-06 14:03:34 | Train | Epoch[100/600] Iteration[007/030] Train loss: 0.0441
2023-02-06 14:03:34 | Train | Epoch[100/600] Iteration[008/030] Train loss: 0.0440
2023-02-06 14:03:34 | Train | Epoch[100/600] Iteration[009/030] Train loss: 0.0440
2023-02-06 14:03:34 | Train | Epoch[100/600] Iteration[010/030] Train loss: 0.0440
2023-02-06 14:03:35 | Train | Epoch[100/600] Iteration[011/030] Train loss: 0.0440
2023-02-06 14:03:35 | Train | Epoch[100/600] Iteration[012/030] Train loss: 0.0443
2023-02-06 14:03:35 | Train | Epoch[100/600] Iteration[013/030] Train loss: 0.0441
2023-02-06 14:03:35 | Train | Epoch[100/600] Iteration[014/030] Train loss: 0.0441
2023-02-06 14:03:35 | Train | Epoch[100/600] Iteration[015/030] Train loss: 0.0441
2023-02-06 14:03:36 | Train | Epoch[100/600] Iteration[016/030] Train loss: 0.0441
2023-02-06 14:03:36 | Train | Epoch[100/600] Iteration[017/030] Train loss: 0.0441
2023-02-06 14:03:36 | Train | Epoch[100/600] Iteration[018/030] Train loss: 0.0442
2023-02-06 14:03:36 | Train | Epoch[100/600] Iteration[019/030] Train loss: 0.0445
2023-02-06 14:03:37 | Train | Epoch[100/600] Iteration[020/030] Train loss: 0.0444
2023-02-06 14:03:37 | Train | Epoch[100/600] Iteration[021/030] Train loss: 0.0445
2023-02-06 14:03:37 | Train | Epoch[100/600] Iteration[022/030] Train loss: 0.0445
2023-02-06 14:03:37 | Train | Epoch[100/600] Iteration[023/030] Train loss: 0.0445
2023-02-06 14:03:37 | Train | Epoch[100/600] Iteration[024/030] Train loss: 0.0444
2023-02-06 14:03:38 | Train | Epoch[100/600] Iteration[025/030] Train loss: 0.0444
2023-02-06 14:03:38 | Train | Epoch[100/600] Iteration[026/030] Train loss: 0.0444
2023-02-06 14:03:38 | Train | Epoch[100/600] Iteration[027/030] Train loss: 0.0444
2023-02-06 14:03:38 | Train | Epoch[100/600] Iteration[028/030] Train loss: 0.0444
2023-02-06 14:03:38 | Train | Epoch[100/600] Iteration[029/030] Train loss: 0.0444
2023-02-06 14:03:39 | Train | Epoch[100/600] Iteration[030/030] Train loss: 0.0444
2023-02-06 14:03:39 | Valid | Epoch[100/600] Iteration[001/008] Valid loss: 0.1454
2023-02-06 14:03:39 | Valid | Epoch[100/600] Iteration[002/008] Valid loss: 0.1266
2023-02-06 14:03:39 | Valid | Epoch[100/600] Iteration[003/008] Valid loss: 0.1217
2023-02-06 14:03:39 | Valid | Epoch[100/600] Iteration[004/008] Valid loss: 0.1213
2023-02-06 14:03:39 | Valid | Epoch[100/600] Iteration[005/008] Valid loss: 0.1181
2023-02-06 14:03:39 | Valid | Epoch[100/600] Iteration[006/008] Valid loss: 0.1140
2023-02-06 14:03:39 | Valid | Epoch[100/600] Iteration[007/008] Valid loss: 0.1167
2023-02-06 14:03:39 | Valid | Epoch[100/600] Iteration[008/008] Valid loss: 0.1173
2023-02-06 14:03:39 | Valid | Epoch[100/600] MIou: 0.9179885144907307
2023-02-06 14:03:39 | Valid | Epoch[100/600] Pixel Accuracy: 0.9849904378255209
2023-02-06 14:03:39 | Valid | Epoch[100/600] Mean Pixel Accuracy: 0.9736543987910864
2023-02-06 14:03:39 | Stage | Epoch[100/600] Train loss:0.0444
2023-02-06 14:03:39 | Stage | Epoch[100/600] Valid loss:0.1173
2023-02-06 14:03:39 | Stage | Epoch[100/600] LR:0.01

2023-02-06 14:03:40 | Train | Epoch[101/600] Iteration[001/030] Train loss: 0.0432
2023-02-06 14:03:40 | Train | Epoch[101/600] Iteration[002/030] Train loss: 0.0433
2023-02-06 14:03:40 | Train | Epoch[101/600] Iteration[003/030] Train loss: 0.0430
2023-02-06 14:03:41 | Train | Epoch[101/600] Iteration[004/030] Train loss: 0.0431
2023-02-06 14:03:41 | Train | Epoch[101/600] Iteration[005/030] Train loss: 0.0433
2023-02-06 14:03:41 | Train | Epoch[101/600] Iteration[006/030] Train loss: 0.0434
2023-02-06 14:03:41 | Train | Epoch[101/600] Iteration[007/030] Train loss: 0.0431
2023-02-06 14:03:41 | Train | Epoch[101/600] Iteration[008/030] Train loss: 0.0433
2023-02-06 14:03:42 | Train | Epoch[101/600] Iteration[009/030] Train loss: 0.0432
2023-02-06 14:03:42 | Train | Epoch[101/600] Iteration[010/030] Train loss: 0.0433
2023-02-06 14:03:42 | Train | Epoch[101/600] Iteration[011/030] Train loss: 0.0431
2023-02-06 14:03:42 | Train | Epoch[101/600] Iteration[012/030] Train loss: 0.0434
2023-02-06 14:03:43 | Train | Epoch[101/600] Iteration[013/030] Train loss: 0.0434
2023-02-06 14:03:43 | Train | Epoch[101/600] Iteration[014/030] Train loss: 0.0433
2023-02-06 14:03:43 | Train | Epoch[101/600] Iteration[015/030] Train loss: 0.0432
2023-02-06 14:03:43 | Train | Epoch[101/600] Iteration[016/030] Train loss: 0.0439
2023-02-06 14:03:43 | Train | Epoch[101/600] Iteration[017/030] Train loss: 0.0437
2023-02-06 14:03:44 | Train | Epoch[101/600] Iteration[018/030] Train loss: 0.0438
2023-02-06 14:03:44 | Train | Epoch[101/600] Iteration[019/030] Train loss: 0.0438
2023-02-06 14:03:44 | Train | Epoch[101/600] Iteration[020/030] Train loss: 0.0439
2023-02-06 14:03:44 | Train | Epoch[101/600] Iteration[021/030] Train loss: 0.0440
2023-02-06 14:03:44 | Train | Epoch[101/600] Iteration[022/030] Train loss: 0.0440
2023-02-06 14:03:45 | Train | Epoch[101/600] Iteration[023/030] Train loss: 0.0440
2023-02-06 14:03:45 | Train | Epoch[101/600] Iteration[024/030] Train loss: 0.0440
2023-02-06 14:03:45 | Train | Epoch[101/600] Iteration[025/030] Train loss: 0.0439
2023-02-06 14:03:45 | Train | Epoch[101/600] Iteration[026/030] Train loss: 0.0440
2023-02-06 14:03:46 | Train | Epoch[101/600] Iteration[027/030] Train loss: 0.0441
2023-02-06 14:03:46 | Train | Epoch[101/600] Iteration[028/030] Train loss: 0.0441
2023-02-06 14:03:46 | Train | Epoch[101/600] Iteration[029/030] Train loss: 0.0441
2023-02-06 14:03:46 | Train | Epoch[101/600] Iteration[030/030] Train loss: 0.0441
2023-02-06 14:03:47 | Valid | Epoch[101/600] Iteration[001/008] Valid loss: 0.0813
2023-02-06 14:03:47 | Valid | Epoch[101/600] Iteration[002/008] Valid loss: 0.0722
2023-02-06 14:03:47 | Valid | Epoch[101/600] Iteration[003/008] Valid loss: 0.0700
2023-02-06 14:03:47 | Valid | Epoch[101/600] Iteration[004/008] Valid loss: 0.0720
2023-02-06 14:03:47 | Valid | Epoch[101/600] Iteration[005/008] Valid loss: 0.0719
2023-02-06 14:03:47 | Valid | Epoch[101/600] Iteration[006/008] Valid loss: 0.0712
2023-02-06 14:03:47 | Valid | Epoch[101/600] Iteration[007/008] Valid loss: 0.0728
2023-02-06 14:03:47 | Valid | Epoch[101/600] Iteration[008/008] Valid loss: 0.0724
2023-02-06 14:03:47 | Valid | Epoch[101/600] MIou: 0.9208697474086557
2023-02-06 14:03:47 | Valid | Epoch[101/600] Pixel Accuracy: 0.9864018758138021
2023-02-06 14:03:47 | Valid | Epoch[101/600] Mean Pixel Accuracy: 0.9470013055445627
2023-02-06 14:03:47 | Stage | Epoch[101/600] Train loss:0.0441
2023-02-06 14:03:47 | Stage | Epoch[101/600] Valid loss:0.0724
2023-02-06 14:03:47 | Stage | Epoch[101/600] LR:0.01

2023-02-06 14:03:47 | Train | Epoch[102/600] Iteration[001/030] Train loss: 0.0418
2023-02-06 14:03:48 | Train | Epoch[102/600] Iteration[002/030] Train loss: 0.0419
2023-02-06 14:03:48 | Train | Epoch[102/600] Iteration[003/030] Train loss: 0.0422
2023-02-06 14:03:48 | Train | Epoch[102/600] Iteration[004/030] Train loss: 0.0426
2023-02-06 14:03:48 | Train | Epoch[102/600] Iteration[005/030] Train loss: 0.0424
2023-02-06 14:03:48 | Train | Epoch[102/600] Iteration[006/030] Train loss: 0.0425
2023-02-06 14:03:49 | Train | Epoch[102/600] Iteration[007/030] Train loss: 0.0425
2023-02-06 14:03:49 | Train | Epoch[102/600] Iteration[008/030] Train loss: 0.0431
2023-02-06 14:03:49 | Train | Epoch[102/600] Iteration[009/030] Train loss: 0.0428
2023-02-06 14:03:49 | Train | Epoch[102/600] Iteration[010/030] Train loss: 0.0429
2023-02-06 14:03:50 | Train | Epoch[102/600] Iteration[011/030] Train loss: 0.0431
2023-02-06 14:03:50 | Train | Epoch[102/600] Iteration[012/030] Train loss: 0.0433
2023-02-06 14:03:50 | Train | Epoch[102/600] Iteration[013/030] Train loss: 0.0434
2023-02-06 14:03:50 | Train | Epoch[102/600] Iteration[014/030] Train loss: 0.0433
2023-02-06 14:03:50 | Train | Epoch[102/600] Iteration[015/030] Train loss: 0.0433
2023-02-06 14:03:51 | Train | Epoch[102/600] Iteration[016/030] Train loss: 0.0433
2023-02-06 14:03:51 | Train | Epoch[102/600] Iteration[017/030] Train loss: 0.0434
2023-02-06 14:03:51 | Train | Epoch[102/600] Iteration[018/030] Train loss: 0.0434
2023-02-06 14:03:51 | Train | Epoch[102/600] Iteration[019/030] Train loss: 0.0434
2023-02-06 14:03:52 | Train | Epoch[102/600] Iteration[020/030] Train loss: 0.0434
2023-02-06 14:03:52 | Train | Epoch[102/600] Iteration[021/030] Train loss: 0.0436
2023-02-06 14:03:52 | Train | Epoch[102/600] Iteration[022/030] Train loss: 0.0436
2023-02-06 14:03:52 | Train | Epoch[102/600] Iteration[023/030] Train loss: 0.0436
2023-02-06 14:03:52 | Train | Epoch[102/600] Iteration[024/030] Train loss: 0.0438
2023-02-06 14:03:53 | Train | Epoch[102/600] Iteration[025/030] Train loss: 0.0437
2023-02-06 14:03:53 | Train | Epoch[102/600] Iteration[026/030] Train loss: 0.0438
2023-02-06 14:03:53 | Train | Epoch[102/600] Iteration[027/030] Train loss: 0.0439
2023-02-06 14:03:53 | Train | Epoch[102/600] Iteration[028/030] Train loss: 0.0438
2023-02-06 14:03:54 | Train | Epoch[102/600] Iteration[029/030] Train loss: 0.0438
2023-02-06 14:03:54 | Train | Epoch[102/600] Iteration[030/030] Train loss: 0.0438
2023-02-06 14:03:54 | Valid | Epoch[102/600] Iteration[001/008] Valid loss: 0.1940
2023-02-06 14:03:54 | Valid | Epoch[102/600] Iteration[002/008] Valid loss: 0.1894
2023-02-06 14:03:54 | Valid | Epoch[102/600] Iteration[003/008] Valid loss: 0.1887
2023-02-06 14:03:54 | Valid | Epoch[102/600] Iteration[004/008] Valid loss: 0.1819
2023-02-06 14:03:54 | Valid | Epoch[102/600] Iteration[005/008] Valid loss: 0.1845
2023-02-06 14:03:54 | Valid | Epoch[102/600] Iteration[006/008] Valid loss: 0.1835
2023-02-06 14:03:54 | Valid | Epoch[102/600] Iteration[007/008] Valid loss: 0.2038
2023-02-06 14:03:54 | Valid | Epoch[102/600] Iteration[008/008] Valid loss: 0.2011
2023-02-06 14:03:54 | Valid | Epoch[102/600] MIou: 0.9041772217147503
2023-02-06 14:03:54 | Valid | Epoch[102/600] Pixel Accuracy: 0.981744130452474
2023-02-06 14:03:54 | Valid | Epoch[102/600] Mean Pixel Accuracy: 0.9789777583722404
2023-02-06 14:03:54 | Stage | Epoch[102/600] Train loss:0.0438
2023-02-06 14:03:54 | Stage | Epoch[102/600] Valid loss:0.2011
2023-02-06 14:03:54 | Stage | Epoch[102/600] LR:0.01

2023-02-06 14:03:55 | Train | Epoch[103/600] Iteration[001/030] Train loss: 0.0414
2023-02-06 14:03:55 | Train | Epoch[103/600] Iteration[002/030] Train loss: 0.0426
2023-02-06 14:03:55 | Train | Epoch[103/600] Iteration[003/030] Train loss: 0.0425
2023-02-06 14:03:56 | Train | Epoch[103/600] Iteration[004/030] Train loss: 0.0421
2023-02-06 14:03:56 | Train | Epoch[103/600] Iteration[005/030] Train loss: 0.0424
2023-02-06 14:03:56 | Train | Epoch[103/600] Iteration[006/030] Train loss: 0.0426
2023-02-06 14:03:56 | Train | Epoch[103/600] Iteration[007/030] Train loss: 0.0429
2023-02-06 14:03:56 | Train | Epoch[103/600] Iteration[008/030] Train loss: 0.0432
2023-02-06 14:03:57 | Train | Epoch[103/600] Iteration[009/030] Train loss: 0.0431
2023-02-06 14:03:57 | Train | Epoch[103/600] Iteration[010/030] Train loss: 0.0431
2023-02-06 14:03:57 | Train | Epoch[103/600] Iteration[011/030] Train loss: 0.0430
2023-02-06 14:03:57 | Train | Epoch[103/600] Iteration[012/030] Train loss: 0.0429
2023-02-06 14:03:58 | Train | Epoch[103/600] Iteration[013/030] Train loss: 0.0429
2023-02-06 14:03:58 | Train | Epoch[103/600] Iteration[014/030] Train loss: 0.0430
2023-02-06 14:03:58 | Train | Epoch[103/600] Iteration[015/030] Train loss: 0.0430
2023-02-06 14:03:58 | Train | Epoch[103/600] Iteration[016/030] Train loss: 0.0429
2023-02-06 14:03:58 | Train | Epoch[103/600] Iteration[017/030] Train loss: 0.0429
2023-02-06 14:03:59 | Train | Epoch[103/600] Iteration[018/030] Train loss: 0.0429
2023-02-06 14:03:59 | Train | Epoch[103/600] Iteration[019/030] Train loss: 0.0429
2023-02-06 14:03:59 | Train | Epoch[103/600] Iteration[020/030] Train loss: 0.0428
2023-02-06 14:03:59 | Train | Epoch[103/600] Iteration[021/030] Train loss: 0.0429
2023-02-06 14:03:59 | Train | Epoch[103/600] Iteration[022/030] Train loss: 0.0429
2023-02-06 14:04:00 | Train | Epoch[103/600] Iteration[023/030] Train loss: 0.0430
2023-02-06 14:04:00 | Train | Epoch[103/600] Iteration[024/030] Train loss: 0.0430
2023-02-06 14:04:00 | Train | Epoch[103/600] Iteration[025/030] Train loss: 0.0430
2023-02-06 14:04:00 | Train | Epoch[103/600] Iteration[026/030] Train loss: 0.0429
2023-02-06 14:04:01 | Train | Epoch[103/600] Iteration[027/030] Train loss: 0.0429
2023-02-06 14:04:01 | Train | Epoch[103/600] Iteration[028/030] Train loss: 0.0429
2023-02-06 14:04:01 | Train | Epoch[103/600] Iteration[029/030] Train loss: 0.0428
2023-02-06 14:04:01 | Train | Epoch[103/600] Iteration[030/030] Train loss: 0.0430
2023-02-06 14:04:01 | Valid | Epoch[103/600] Iteration[001/008] Valid loss: 0.1076
2023-02-06 14:04:02 | Valid | Epoch[103/600] Iteration[002/008] Valid loss: 0.0940
2023-02-06 14:04:02 | Valid | Epoch[103/600] Iteration[003/008] Valid loss: 0.0943
2023-02-06 14:04:02 | Valid | Epoch[103/600] Iteration[004/008] Valid loss: 0.0917
2023-02-06 14:04:02 | Valid | Epoch[103/600] Iteration[005/008] Valid loss: 0.0946
2023-02-06 14:04:02 | Valid | Epoch[103/600] Iteration[006/008] Valid loss: 0.0922
2023-02-06 14:04:02 | Valid | Epoch[103/600] Iteration[007/008] Valid loss: 0.0950
2023-02-06 14:04:02 | Valid | Epoch[103/600] Iteration[008/008] Valid loss: 0.0951
2023-02-06 14:04:02 | Valid | Epoch[103/600] MIou: 0.8946630827856775
2023-02-06 14:04:02 | Valid | Epoch[103/600] Pixel Accuracy: 0.980743408203125
2023-02-06 14:04:02 | Valid | Epoch[103/600] Mean Pixel Accuracy: 0.9492298474310991
2023-02-06 14:04:02 | Stage | Epoch[103/600] Train loss:0.0430
2023-02-06 14:04:02 | Stage | Epoch[103/600] Valid loss:0.0951
2023-02-06 14:04:02 | Stage | Epoch[103/600] LR:0.01

2023-02-06 14:04:02 | Train | Epoch[104/600] Iteration[001/030] Train loss: 0.0407
2023-02-06 14:04:03 | Train | Epoch[104/600] Iteration[002/030] Train loss: 0.0412
2023-02-06 14:04:03 | Train | Epoch[104/600] Iteration[003/030] Train loss: 0.0414
2023-02-06 14:04:03 | Train | Epoch[104/600] Iteration[004/030] Train loss: 0.0413
2023-02-06 14:04:03 | Train | Epoch[104/600] Iteration[005/030] Train loss: 0.0416
2023-02-06 14:04:03 | Train | Epoch[104/600] Iteration[006/030] Train loss: 0.0415
2023-02-06 14:04:04 | Train | Epoch[104/600] Iteration[007/030] Train loss: 0.0415
2023-02-06 14:04:04 | Train | Epoch[104/600] Iteration[008/030] Train loss: 0.0414
2023-02-06 14:04:04 | Train | Epoch[104/600] Iteration[009/030] Train loss: 0.0413
2023-02-06 14:04:04 | Train | Epoch[104/600] Iteration[010/030] Train loss: 0.0414
2023-02-06 14:04:05 | Train | Epoch[104/600] Iteration[011/030] Train loss: 0.0415
2023-02-06 14:04:05 | Train | Epoch[104/600] Iteration[012/030] Train loss: 0.0414
2023-02-06 14:04:05 | Train | Epoch[104/600] Iteration[013/030] Train loss: 0.0413
2023-02-06 14:04:05 | Train | Epoch[104/600] Iteration[014/030] Train loss: 0.0414
2023-02-06 14:04:05 | Train | Epoch[104/600] Iteration[015/030] Train loss: 0.0415
2023-02-06 14:04:06 | Train | Epoch[104/600] Iteration[016/030] Train loss: 0.0417
2023-02-06 14:04:06 | Train | Epoch[104/600] Iteration[017/030] Train loss: 0.0416
2023-02-06 14:04:06 | Train | Epoch[104/600] Iteration[018/030] Train loss: 0.0417
2023-02-06 14:04:06 | Train | Epoch[104/600] Iteration[019/030] Train loss: 0.0417
2023-02-06 14:04:07 | Train | Epoch[104/600] Iteration[020/030] Train loss: 0.0417
2023-02-06 14:04:07 | Train | Epoch[104/600] Iteration[021/030] Train loss: 0.0417
2023-02-06 14:04:07 | Train | Epoch[104/600] Iteration[022/030] Train loss: 0.0417
2023-02-06 14:04:07 | Train | Epoch[104/600] Iteration[023/030] Train loss: 0.0418
2023-02-06 14:04:07 | Train | Epoch[104/600] Iteration[024/030] Train loss: 0.0418
2023-02-06 14:04:08 | Train | Epoch[104/600] Iteration[025/030] Train loss: 0.0418
2023-02-06 14:04:08 | Train | Epoch[104/600] Iteration[026/030] Train loss: 0.0419
2023-02-06 14:04:08 | Train | Epoch[104/600] Iteration[027/030] Train loss: 0.0419
2023-02-06 14:04:08 | Train | Epoch[104/600] Iteration[028/030] Train loss: 0.0419
2023-02-06 14:04:09 | Train | Epoch[104/600] Iteration[029/030] Train loss: 0.0419
2023-02-06 14:04:09 | Train | Epoch[104/600] Iteration[030/030] Train loss: 0.0418
2023-02-06 14:04:09 | Valid | Epoch[104/600] Iteration[001/008] Valid loss: 0.0724
2023-02-06 14:04:09 | Valid | Epoch[104/600] Iteration[002/008] Valid loss: 0.0683
2023-02-06 14:04:09 | Valid | Epoch[104/600] Iteration[003/008] Valid loss: 0.0685
2023-02-06 14:04:09 | Valid | Epoch[104/600] Iteration[004/008] Valid loss: 0.0666
2023-02-06 14:04:09 | Valid | Epoch[104/600] Iteration[005/008] Valid loss: 0.0666
2023-02-06 14:04:09 | Valid | Epoch[104/600] Iteration[006/008] Valid loss: 0.0658
2023-02-06 14:04:09 | Valid | Epoch[104/600] Iteration[007/008] Valid loss: 0.0656
2023-02-06 14:04:09 | Valid | Epoch[104/600] Iteration[008/008] Valid loss: 0.0653
2023-02-06 14:04:09 | Valid | Epoch[104/600] MIou: 0.8856007302903603
2023-02-06 14:04:09 | Valid | Epoch[104/600] Pixel Accuracy: 0.9810333251953125
2023-02-06 14:04:09 | Valid | Epoch[104/600] Mean Pixel Accuracy: 0.898544957119298
2023-02-06 14:04:09 | Stage | Epoch[104/600] Train loss:0.0418
2023-02-06 14:04:09 | Stage | Epoch[104/600] Valid loss:0.0653
2023-02-06 14:04:09 | Stage | Epoch[104/600] LR:0.01

2023-02-06 14:04:10 | Train | Epoch[105/600] Iteration[001/030] Train loss: 0.0404
2023-02-06 14:04:10 | Train | Epoch[105/600] Iteration[002/030] Train loss: 0.0405
2023-02-06 14:04:10 | Train | Epoch[105/600] Iteration[003/030] Train loss: 0.0405
2023-02-06 14:04:11 | Train | Epoch[105/600] Iteration[004/030] Train loss: 0.0404
2023-02-06 14:04:11 | Train | Epoch[105/600] Iteration[005/030] Train loss: 0.0402
2023-02-06 14:04:11 | Train | Epoch[105/600] Iteration[006/030] Train loss: 0.0417
2023-02-06 14:04:11 | Train | Epoch[105/600] Iteration[007/030] Train loss: 0.0415
2023-02-06 14:04:11 | Train | Epoch[105/600] Iteration[008/030] Train loss: 0.0413
2023-02-06 14:04:12 | Train | Epoch[105/600] Iteration[009/030] Train loss: 0.0411
2023-02-06 14:04:12 | Train | Epoch[105/600] Iteration[010/030] Train loss: 0.0412
2023-02-06 14:04:12 | Train | Epoch[105/600] Iteration[011/030] Train loss: 0.0412
2023-02-06 14:04:12 | Train | Epoch[105/600] Iteration[012/030] Train loss: 0.0411
2023-02-06 14:04:13 | Train | Epoch[105/600] Iteration[013/030] Train loss: 0.0410
2023-02-06 14:04:13 | Train | Epoch[105/600] Iteration[014/030] Train loss: 0.0410
2023-02-06 14:04:13 | Train | Epoch[105/600] Iteration[015/030] Train loss: 0.0409
2023-02-06 14:04:13 | Train | Epoch[105/600] Iteration[016/030] Train loss: 0.0408
2023-02-06 14:04:13 | Train | Epoch[105/600] Iteration[017/030] Train loss: 0.0410
2023-02-06 14:04:14 | Train | Epoch[105/600] Iteration[018/030] Train loss: 0.0410
2023-02-06 14:04:14 | Train | Epoch[105/600] Iteration[019/030] Train loss: 0.0411
2023-02-06 14:04:14 | Train | Epoch[105/600] Iteration[020/030] Train loss: 0.0410
2023-02-06 14:04:14 | Train | Epoch[105/600] Iteration[021/030] Train loss: 0.0411
2023-02-06 14:04:15 | Train | Epoch[105/600] Iteration[022/030] Train loss: 0.0412
2023-02-06 14:04:15 | Train | Epoch[105/600] Iteration[023/030] Train loss: 0.0413
2023-02-06 14:04:15 | Train | Epoch[105/600] Iteration[024/030] Train loss: 0.0413
2023-02-06 14:04:15 | Train | Epoch[105/600] Iteration[025/030] Train loss: 0.0413
2023-02-06 14:04:15 | Train | Epoch[105/600] Iteration[026/030] Train loss: 0.0414
2023-02-06 14:04:16 | Train | Epoch[105/600] Iteration[027/030] Train loss: 0.0413
2023-02-06 14:04:16 | Train | Epoch[105/600] Iteration[028/030] Train loss: 0.0414
2023-02-06 14:04:16 | Train | Epoch[105/600] Iteration[029/030] Train loss: 0.0414
2023-02-06 14:04:16 | Train | Epoch[105/600] Iteration[030/030] Train loss: 0.0413
2023-02-06 14:04:17 | Valid | Epoch[105/600] Iteration[001/008] Valid loss: 0.9976
2023-02-06 14:04:17 | Valid | Epoch[105/600] Iteration[002/008] Valid loss: 0.9398
2023-02-06 14:04:17 | Valid | Epoch[105/600] Iteration[003/008] Valid loss: 0.9764
2023-02-06 14:04:17 | Valid | Epoch[105/600] Iteration[004/008] Valid loss: 0.9903
2023-02-06 14:04:17 | Valid | Epoch[105/600] Iteration[005/008] Valid loss: 1.0169
2023-02-06 14:04:17 | Valid | Epoch[105/600] Iteration[006/008] Valid loss: 0.9971
2023-02-06 14:04:17 | Valid | Epoch[105/600] Iteration[007/008] Valid loss: 1.0540
2023-02-06 14:04:17 | Valid | Epoch[105/600] Iteration[008/008] Valid loss: 1.0915
2023-02-06 14:04:17 | Valid | Epoch[105/600] MIou: 0.8294455531760321
2023-02-06 14:04:17 | Valid | Epoch[105/600] Pixel Accuracy: 0.961639404296875
2023-02-06 14:04:17 | Valid | Epoch[105/600] Mean Pixel Accuracy: 0.9771020057092705
2023-02-06 14:04:17 | Stage | Epoch[105/600] Train loss:0.0413
2023-02-06 14:04:17 | Stage | Epoch[105/600] Valid loss:1.0915
2023-02-06 14:04:17 | Stage | Epoch[105/600] LR:0.01

2023-02-06 14:04:18 | Train | Epoch[106/600] Iteration[001/030] Train loss: 0.0398
2023-02-06 14:04:18 | Train | Epoch[106/600] Iteration[002/030] Train loss: 0.0411
2023-02-06 14:04:18 | Train | Epoch[106/600] Iteration[003/030] Train loss: 0.0407
2023-02-06 14:04:18 | Train | Epoch[106/600] Iteration[004/030] Train loss: 0.0407
2023-02-06 14:04:18 | Train | Epoch[106/600] Iteration[005/030] Train loss: 0.0413
2023-02-06 14:04:19 | Train | Epoch[106/600] Iteration[006/030] Train loss: 0.0414
2023-02-06 14:04:19 | Train | Epoch[106/600] Iteration[007/030] Train loss: 0.0411
2023-02-06 14:04:19 | Train | Epoch[106/600] Iteration[008/030] Train loss: 0.0410
2023-02-06 14:04:19 | Train | Epoch[106/600] Iteration[009/030] Train loss: 0.0409
2023-02-06 14:04:20 | Train | Epoch[106/600] Iteration[010/030] Train loss: 0.0409
2023-02-06 14:04:20 | Train | Epoch[106/600] Iteration[011/030] Train loss: 0.0408
2023-02-06 14:04:20 | Train | Epoch[106/600] Iteration[012/030] Train loss: 0.0407
2023-02-06 14:04:20 | Train | Epoch[106/600] Iteration[013/030] Train loss: 0.0407
2023-02-06 14:04:20 | Train | Epoch[106/600] Iteration[014/030] Train loss: 0.0406
2023-02-06 14:04:21 | Train | Epoch[106/600] Iteration[015/030] Train loss: 0.0406
2023-02-06 14:04:21 | Train | Epoch[106/600] Iteration[016/030] Train loss: 0.0407
2023-02-06 14:04:21 | Train | Epoch[106/600] Iteration[017/030] Train loss: 0.0407
2023-02-06 14:04:21 | Train | Epoch[106/600] Iteration[018/030] Train loss: 0.0413
2023-02-06 14:04:22 | Train | Epoch[106/600] Iteration[019/030] Train loss: 0.0414
2023-02-06 14:04:22 | Train | Epoch[106/600] Iteration[020/030] Train loss: 0.0413
2023-02-06 14:04:22 | Train | Epoch[106/600] Iteration[021/030] Train loss: 0.0414
2023-02-06 14:04:22 | Train | Epoch[106/600] Iteration[022/030] Train loss: 0.0415
2023-02-06 14:04:22 | Train | Epoch[106/600] Iteration[023/030] Train loss: 0.0415
2023-02-06 14:04:23 | Train | Epoch[106/600] Iteration[024/030] Train loss: 0.0415
2023-02-06 14:04:23 | Train | Epoch[106/600] Iteration[025/030] Train loss: 0.0416
2023-02-06 14:04:23 | Train | Epoch[106/600] Iteration[026/030] Train loss: 0.0416
2023-02-06 14:04:23 | Train | Epoch[106/600] Iteration[027/030] Train loss: 0.0416
2023-02-06 14:04:24 | Train | Epoch[106/600] Iteration[028/030] Train loss: 0.0416
2023-02-06 14:04:24 | Train | Epoch[106/600] Iteration[029/030] Train loss: 0.0417
2023-02-06 14:04:24 | Train | Epoch[106/600] Iteration[030/030] Train loss: 0.0417
2023-02-06 14:04:24 | Valid | Epoch[106/600] Iteration[001/008] Valid loss: 1.4826
2023-02-06 14:04:24 | Valid | Epoch[106/600] Iteration[002/008] Valid loss: 1.3731
2023-02-06 14:04:24 | Valid | Epoch[106/600] Iteration[003/008] Valid loss: 1.4475
2023-02-06 14:04:24 | Valid | Epoch[106/600] Iteration[004/008] Valid loss: 1.4813
2023-02-06 14:04:24 | Valid | Epoch[106/600] Iteration[005/008] Valid loss: 1.5084
2023-02-06 14:04:24 | Valid | Epoch[106/600] Iteration[006/008] Valid loss: 1.4510
2023-02-06 14:04:24 | Valid | Epoch[106/600] Iteration[007/008] Valid loss: 1.5176
2023-02-06 14:04:25 | Valid | Epoch[106/600] Iteration[008/008] Valid loss: 1.5772
2023-02-06 14:04:25 | Valid | Epoch[106/600] MIou: 0.6758173813248742
2023-02-06 14:04:25 | Valid | Epoch[106/600] Pixel Accuracy: 0.8965314229329427
2023-02-06 14:04:25 | Valid | Epoch[106/600] Mean Pixel Accuracy: 0.9418167796128625
2023-02-06 14:04:25 | Stage | Epoch[106/600] Train loss:0.0417
2023-02-06 14:04:25 | Stage | Epoch[106/600] Valid loss:1.5772
2023-02-06 14:04:25 | Stage | Epoch[106/600] LR:0.01

2023-02-06 14:04:25 | Train | Epoch[107/600] Iteration[001/030] Train loss: 0.0421
2023-02-06 14:04:25 | Train | Epoch[107/600] Iteration[002/030] Train loss: 0.0416
2023-02-06 14:04:26 | Train | Epoch[107/600] Iteration[003/030] Train loss: 0.0415
2023-02-06 14:04:26 | Train | Epoch[107/600] Iteration[004/030] Train loss: 0.0411
2023-02-06 14:04:26 | Train | Epoch[107/600] Iteration[005/030] Train loss: 0.0410
2023-02-06 14:04:26 | Train | Epoch[107/600] Iteration[006/030] Train loss: 0.0418
2023-02-06 14:04:26 | Train | Epoch[107/600] Iteration[007/030] Train loss: 0.0416
2023-02-06 14:04:27 | Train | Epoch[107/600] Iteration[008/030] Train loss: 0.0415
2023-02-06 14:04:27 | Train | Epoch[107/600] Iteration[009/030] Train loss: 0.0414
2023-02-06 14:04:27 | Train | Epoch[107/600] Iteration[010/030] Train loss: 0.0416
2023-02-06 14:04:27 | Train | Epoch[107/600] Iteration[011/030] Train loss: 0.0414
2023-02-06 14:04:28 | Train | Epoch[107/600] Iteration[012/030] Train loss: 0.0414
2023-02-06 14:04:28 | Train | Epoch[107/600] Iteration[013/030] Train loss: 0.0414
2023-02-06 14:04:28 | Train | Epoch[107/600] Iteration[014/030] Train loss: 0.0413
2023-02-06 14:04:28 | Train | Epoch[107/600] Iteration[015/030] Train loss: 0.0415
2023-02-06 14:04:28 | Train | Epoch[107/600] Iteration[016/030] Train loss: 0.0413
2023-02-06 14:04:29 | Train | Epoch[107/600] Iteration[017/030] Train loss: 0.0412
2023-02-06 14:04:29 | Train | Epoch[107/600] Iteration[018/030] Train loss: 0.0412
2023-02-06 14:04:29 | Train | Epoch[107/600] Iteration[019/030] Train loss: 0.0412
2023-02-06 14:04:29 | Train | Epoch[107/600] Iteration[020/030] Train loss: 0.0412
2023-02-06 14:04:30 | Train | Epoch[107/600] Iteration[021/030] Train loss: 0.0412
2023-02-06 14:04:30 | Train | Epoch[107/600] Iteration[022/030] Train loss: 0.0413
2023-02-06 14:04:30 | Train | Epoch[107/600] Iteration[023/030] Train loss: 0.0412
2023-02-06 14:04:30 | Train | Epoch[107/600] Iteration[024/030] Train loss: 0.0411
2023-02-06 14:04:30 | Train | Epoch[107/600] Iteration[025/030] Train loss: 0.0411
2023-02-06 14:04:31 | Train | Epoch[107/600] Iteration[026/030] Train loss: 0.0412
2023-02-06 14:04:31 | Train | Epoch[107/600] Iteration[027/030] Train loss: 0.0412
2023-02-06 14:04:31 | Train | Epoch[107/600] Iteration[028/030] Train loss: 0.0412
2023-02-06 14:04:31 | Train | Epoch[107/600] Iteration[029/030] Train loss: 0.0412
2023-02-06 14:04:31 | Train | Epoch[107/600] Iteration[030/030] Train loss: 0.0412
2023-02-06 14:04:32 | Valid | Epoch[107/600] Iteration[001/008] Valid loss: 0.0881
2023-02-06 14:04:32 | Valid | Epoch[107/600] Iteration[002/008] Valid loss: 0.0810
2023-02-06 14:04:32 | Valid | Epoch[107/600] Iteration[003/008] Valid loss: 0.0846
2023-02-06 14:04:32 | Valid | Epoch[107/600] Iteration[004/008] Valid loss: 0.0824
2023-02-06 14:04:32 | Valid | Epoch[107/600] Iteration[005/008] Valid loss: 0.0863
2023-02-06 14:04:32 | Valid | Epoch[107/600] Iteration[006/008] Valid loss: 0.0846
2023-02-06 14:04:32 | Valid | Epoch[107/600] Iteration[007/008] Valid loss: 0.0843
2023-02-06 14:04:32 | Valid | Epoch[107/600] Iteration[008/008] Valid loss: 0.0839
2023-02-06 14:04:32 | Valid | Epoch[107/600] MIou: 0.8553070564296178
2023-02-06 14:04:32 | Valid | Epoch[107/600] Pixel Accuracy: 0.9756266276041666
2023-02-06 14:04:32 | Valid | Epoch[107/600] Mean Pixel Accuracy: 0.876418641095136
2023-02-06 14:04:32 | Stage | Epoch[107/600] Train loss:0.0412
2023-02-06 14:04:32 | Stage | Epoch[107/600] Valid loss:0.0839
2023-02-06 14:04:32 | Stage | Epoch[107/600] LR:0.01

2023-02-06 14:04:33 | Train | Epoch[108/600] Iteration[001/030] Train loss: 0.0410
2023-02-06 14:04:33 | Train | Epoch[108/600] Iteration[002/030] Train loss: 0.0411
2023-02-06 14:04:33 | Train | Epoch[108/600] Iteration[003/030] Train loss: 0.0405
2023-02-06 14:04:33 | Train | Epoch[108/600] Iteration[004/030] Train loss: 0.0400
2023-02-06 14:04:33 | Train | Epoch[108/600] Iteration[005/030] Train loss: 0.0398
2023-02-06 14:04:34 | Train | Epoch[108/600] Iteration[006/030] Train loss: 0.0400
2023-02-06 14:04:34 | Train | Epoch[108/600] Iteration[007/030] Train loss: 0.0399
2023-02-06 14:04:34 | Train | Epoch[108/600] Iteration[008/030] Train loss: 0.0397
2023-02-06 14:04:34 | Train | Epoch[108/600] Iteration[009/030] Train loss: 0.0396
2023-02-06 14:04:35 | Train | Epoch[108/600] Iteration[010/030] Train loss: 0.0399
2023-02-06 14:04:35 | Train | Epoch[108/600] Iteration[011/030] Train loss: 0.0399
2023-02-06 14:04:35 | Train | Epoch[108/600] Iteration[012/030] Train loss: 0.0399
2023-02-06 14:04:35 | Train | Epoch[108/600] Iteration[013/030] Train loss: 0.0400
2023-02-06 14:04:35 | Train | Epoch[108/600] Iteration[014/030] Train loss: 0.0400
2023-02-06 14:04:36 | Train | Epoch[108/600] Iteration[015/030] Train loss: 0.0400
2023-02-06 14:04:36 | Train | Epoch[108/600] Iteration[016/030] Train loss: 0.0401
2023-02-06 14:04:36 | Train | Epoch[108/600] Iteration[017/030] Train loss: 0.0400
2023-02-06 14:04:36 | Train | Epoch[108/600] Iteration[018/030] Train loss: 0.0400
2023-02-06 14:04:37 | Train | Epoch[108/600] Iteration[019/030] Train loss: 0.0400
2023-02-06 14:04:37 | Train | Epoch[108/600] Iteration[020/030] Train loss: 0.0400
2023-02-06 14:04:37 | Train | Epoch[108/600] Iteration[021/030] Train loss: 0.0400
2023-02-06 14:04:37 | Train | Epoch[108/600] Iteration[022/030] Train loss: 0.0400
2023-02-06 14:04:37 | Train | Epoch[108/600] Iteration[023/030] Train loss: 0.0399
2023-02-06 14:04:38 | Train | Epoch[108/600] Iteration[024/030] Train loss: 0.0400
2023-02-06 14:04:38 | Train | Epoch[108/600] Iteration[025/030] Train loss: 0.0400
2023-02-06 14:04:38 | Train | Epoch[108/600] Iteration[026/030] Train loss: 0.0401
2023-02-06 14:04:38 | Train | Epoch[108/600] Iteration[027/030] Train loss: 0.0401
2023-02-06 14:04:39 | Train | Epoch[108/600] Iteration[028/030] Train loss: 0.0401
2023-02-06 14:04:39 | Train | Epoch[108/600] Iteration[029/030] Train loss: 0.0402
2023-02-06 14:04:39 | Train | Epoch[108/600] Iteration[030/030] Train loss: 0.0401
2023-02-06 14:04:39 | Valid | Epoch[108/600] Iteration[001/008] Valid loss: 0.2350
2023-02-06 14:04:39 | Valid | Epoch[108/600] Iteration[002/008] Valid loss: 0.2400
2023-02-06 14:04:39 | Valid | Epoch[108/600] Iteration[003/008] Valid loss: 0.2520
2023-02-06 14:04:39 | Valid | Epoch[108/600] Iteration[004/008] Valid loss: 0.2535
2023-02-06 14:04:39 | Valid | Epoch[108/600] Iteration[005/008] Valid loss: 0.2592
2023-02-06 14:04:39 | Valid | Epoch[108/600] Iteration[006/008] Valid loss: 0.2569
2023-02-06 14:04:40 | Valid | Epoch[108/600] Iteration[007/008] Valid loss: 0.2534
2023-02-06 14:04:40 | Valid | Epoch[108/600] Iteration[008/008] Valid loss: 0.2612
2023-02-06 14:04:40 | Valid | Epoch[108/600] MIou: 0.46142325363944187
2023-02-06 14:04:40 | Valid | Epoch[108/600] Pixel Accuracy: 0.9107805887858073
2023-02-06 14:04:40 | Valid | Epoch[108/600] Mean Pixel Accuracy: 0.5060820228357431
2023-02-06 14:04:40 | Stage | Epoch[108/600] Train loss:0.0401
2023-02-06 14:04:40 | Stage | Epoch[108/600] Valid loss:0.2612
2023-02-06 14:04:40 | Stage | Epoch[108/600] LR:0.01

2023-02-06 14:04:40 | Train | Epoch[109/600] Iteration[001/030] Train loss: 0.0404
2023-02-06 14:04:40 | Train | Epoch[109/600] Iteration[002/030] Train loss: 0.0408
2023-02-06 14:04:41 | Train | Epoch[109/600] Iteration[003/030] Train loss: 0.0402
2023-02-06 14:04:41 | Train | Epoch[109/600] Iteration[004/030] Train loss: 0.0397
2023-02-06 14:04:41 | Train | Epoch[109/600] Iteration[005/030] Train loss: 0.0394
2023-02-06 14:04:41 | Train | Epoch[109/600] Iteration[006/030] Train loss: 0.0395
2023-02-06 14:04:41 | Train | Epoch[109/600] Iteration[007/030] Train loss: 0.0394
2023-02-06 14:04:42 | Train | Epoch[109/600] Iteration[008/030] Train loss: 0.0395
2023-02-06 14:04:42 | Train | Epoch[109/600] Iteration[009/030] Train loss: 0.0395
2023-02-06 14:04:42 | Train | Epoch[109/600] Iteration[010/030] Train loss: 0.0395
2023-02-06 14:04:42 | Train | Epoch[109/600] Iteration[011/030] Train loss: 0.0394
2023-02-06 14:04:43 | Train | Epoch[109/600] Iteration[012/030] Train loss: 0.0393
2023-02-06 14:04:43 | Train | Epoch[109/600] Iteration[013/030] Train loss: 0.0392
2023-02-06 14:04:43 | Train | Epoch[109/600] Iteration[014/030] Train loss: 0.0391
2023-02-06 14:04:43 | Train | Epoch[109/600] Iteration[015/030] Train loss: 0.0390
2023-02-06 14:04:43 | Train | Epoch[109/600] Iteration[016/030] Train loss: 0.0390
2023-02-06 14:04:44 | Train | Epoch[109/600] Iteration[017/030] Train loss: 0.0391
2023-02-06 14:04:44 | Train | Epoch[109/600] Iteration[018/030] Train loss: 0.0390
2023-02-06 14:04:44 | Train | Epoch[109/600] Iteration[019/030] Train loss: 0.0390
2023-02-06 14:04:44 | Train | Epoch[109/600] Iteration[020/030] Train loss: 0.0390
2023-02-06 14:04:44 | Train | Epoch[109/600] Iteration[021/030] Train loss: 0.0389
2023-02-06 14:04:45 | Train | Epoch[109/600] Iteration[022/030] Train loss: 0.0390
2023-02-06 14:04:45 | Train | Epoch[109/600] Iteration[023/030] Train loss: 0.0389
2023-02-06 14:04:45 | Train | Epoch[109/600] Iteration[024/030] Train loss: 0.0389
2023-02-06 14:04:45 | Train | Epoch[109/600] Iteration[025/030] Train loss: 0.0389
2023-02-06 14:04:46 | Train | Epoch[109/600] Iteration[026/030] Train loss: 0.0389
2023-02-06 14:04:46 | Train | Epoch[109/600] Iteration[027/030] Train loss: 0.0390
2023-02-06 14:04:46 | Train | Epoch[109/600] Iteration[028/030] Train loss: 0.0391
2023-02-06 14:04:46 | Train | Epoch[109/600] Iteration[029/030] Train loss: 0.0391
2023-02-06 14:04:46 | Train | Epoch[109/600] Iteration[030/030] Train loss: 0.0390
2023-02-06 14:04:47 | Valid | Epoch[109/600] Iteration[001/008] Valid loss: 0.0877
2023-02-06 14:04:47 | Valid | Epoch[109/600] Iteration[002/008] Valid loss: 0.0873
2023-02-06 14:04:47 | Valid | Epoch[109/600] Iteration[003/008] Valid loss: 0.0898
2023-02-06 14:04:47 | Valid | Epoch[109/600] Iteration[004/008] Valid loss: 0.0891
2023-02-06 14:04:47 | Valid | Epoch[109/600] Iteration[005/008] Valid loss: 0.0900
2023-02-06 14:04:47 | Valid | Epoch[109/600] Iteration[006/008] Valid loss: 0.0888
2023-02-06 14:04:47 | Valid | Epoch[109/600] Iteration[007/008] Valid loss: 0.0877
2023-02-06 14:04:47 | Valid | Epoch[109/600] Iteration[008/008] Valid loss: 0.0883
2023-02-06 14:04:47 | Valid | Epoch[109/600] MIou: 0.8010890438567402
2023-02-06 14:04:47 | Valid | Epoch[109/600] Pixel Accuracy: 0.9670664469401041
2023-02-06 14:04:47 | Valid | Epoch[109/600] Mean Pixel Accuracy: 0.8198802461080394
2023-02-06 14:04:47 | Stage | Epoch[109/600] Train loss:0.0390
2023-02-06 14:04:47 | Stage | Epoch[109/600] Valid loss:0.0883
2023-02-06 14:04:47 | Stage | Epoch[109/600] LR:0.01

2023-02-06 14:04:48 | Train | Epoch[110/600] Iteration[001/030] Train loss: 0.0373
2023-02-06 14:04:48 | Train | Epoch[110/600] Iteration[002/030] Train loss: 0.0380
2023-02-06 14:04:48 | Train | Epoch[110/600] Iteration[003/030] Train loss: 0.0386
2023-02-06 14:04:48 | Train | Epoch[110/600] Iteration[004/030] Train loss: 0.0384
2023-02-06 14:04:49 | Train | Epoch[110/600] Iteration[005/030] Train loss: 0.0383
2023-02-06 14:04:49 | Train | Epoch[110/600] Iteration[006/030] Train loss: 0.0381
2023-02-06 14:04:49 | Train | Epoch[110/600] Iteration[007/030] Train loss: 0.0379
2023-02-06 14:04:49 | Train | Epoch[110/600] Iteration[008/030] Train loss: 0.0380
2023-02-06 14:04:49 | Train | Epoch[110/600] Iteration[009/030] Train loss: 0.0379
2023-02-06 14:04:50 | Train | Epoch[110/600] Iteration[010/030] Train loss: 0.0378
2023-02-06 14:04:50 | Train | Epoch[110/600] Iteration[011/030] Train loss: 0.0378
2023-02-06 14:04:50 | Train | Epoch[110/600] Iteration[012/030] Train loss: 0.0377
2023-02-06 14:04:50 | Train | Epoch[110/600] Iteration[013/030] Train loss: 0.0379
2023-02-06 14:04:50 | Train | Epoch[110/600] Iteration[014/030] Train loss: 0.0378
2023-02-06 14:04:51 | Train | Epoch[110/600] Iteration[015/030] Train loss: 0.0378
2023-02-06 14:04:51 | Train | Epoch[110/600] Iteration[016/030] Train loss: 0.0379
2023-02-06 14:04:51 | Train | Epoch[110/600] Iteration[017/030] Train loss: 0.0380
2023-02-06 14:04:51 | Train | Epoch[110/600] Iteration[018/030] Train loss: 0.0380
2023-02-06 14:04:52 | Train | Epoch[110/600] Iteration[019/030] Train loss: 0.0380
2023-02-06 14:04:52 | Train | Epoch[110/600] Iteration[020/030] Train loss: 0.0380
2023-02-06 14:04:52 | Train | Epoch[110/600] Iteration[021/030] Train loss: 0.0380
2023-02-06 14:04:52 | Train | Epoch[110/600] Iteration[022/030] Train loss: 0.0381
2023-02-06 14:04:52 | Train | Epoch[110/600] Iteration[023/030] Train loss: 0.0380
2023-02-06 14:04:53 | Train | Epoch[110/600] Iteration[024/030] Train loss: 0.0381
2023-02-06 14:04:53 | Train | Epoch[110/600] Iteration[025/030] Train loss: 0.0381
2023-02-06 14:04:53 | Train | Epoch[110/600] Iteration[026/030] Train loss: 0.0380
2023-02-06 14:04:53 | Train | Epoch[110/600] Iteration[027/030] Train loss: 0.0381
2023-02-06 14:04:54 | Train | Epoch[110/600] Iteration[028/030] Train loss: 0.0380
2023-02-06 14:04:54 | Train | Epoch[110/600] Iteration[029/030] Train loss: 0.0380
2023-02-06 14:04:54 | Train | Epoch[110/600] Iteration[030/030] Train loss: 0.0380
2023-02-06 14:04:54 | Valid | Epoch[110/600] Iteration[001/008] Valid loss: 0.3779
2023-02-06 14:04:54 | Valid | Epoch[110/600] Iteration[002/008] Valid loss: 0.3462
2023-02-06 14:04:54 | Valid | Epoch[110/600] Iteration[003/008] Valid loss: 0.3495
2023-02-06 14:04:54 | Valid | Epoch[110/600] Iteration[004/008] Valid loss: 0.3522
2023-02-06 14:04:54 | Valid | Epoch[110/600] Iteration[005/008] Valid loss: 0.3512
2023-02-06 14:04:54 | Valid | Epoch[110/600] Iteration[006/008] Valid loss: 0.3507
2023-02-06 14:04:55 | Valid | Epoch[110/600] Iteration[007/008] Valid loss: 0.3770
2023-02-06 14:04:55 | Valid | Epoch[110/600] Iteration[008/008] Valid loss: 0.3764
2023-02-06 14:04:55 | Valid | Epoch[110/600] MIou: 0.8964681076420644
2023-02-06 14:04:55 | Valid | Epoch[110/600] Pixel Accuracy: 0.9797986348470052
2023-02-06 14:04:55 | Valid | Epoch[110/600] Mean Pixel Accuracy: 0.9826320822905935
2023-02-06 14:04:55 | Stage | Epoch[110/600] Train loss:0.0380
2023-02-06 14:04:55 | Stage | Epoch[110/600] Valid loss:0.3764
2023-02-06 14:04:55 | Stage | Epoch[110/600] LR:0.01

2023-02-06 14:04:55 | Train | Epoch[111/600] Iteration[001/030] Train loss: 0.0365
2023-02-06 14:04:55 | Train | Epoch[111/600] Iteration[002/030] Train loss: 0.0360
2023-02-06 14:04:56 | Train | Epoch[111/600] Iteration[003/030] Train loss: 0.0365
2023-02-06 14:04:56 | Train | Epoch[111/600] Iteration[004/030] Train loss: 0.0369
2023-02-06 14:04:56 | Train | Epoch[111/600] Iteration[005/030] Train loss: 0.0376
2023-02-06 14:04:56 | Train | Epoch[111/600] Iteration[006/030] Train loss: 0.0378
2023-02-06 14:04:56 | Train | Epoch[111/600] Iteration[007/030] Train loss: 0.0376
2023-02-06 14:04:57 | Train | Epoch[111/600] Iteration[008/030] Train loss: 0.0378
2023-02-06 14:04:57 | Train | Epoch[111/600] Iteration[009/030] Train loss: 0.0378
2023-02-06 14:04:57 | Train | Epoch[111/600] Iteration[010/030] Train loss: 0.0378
2023-02-06 14:04:57 | Train | Epoch[111/600] Iteration[011/030] Train loss: 0.0379
2023-02-06 14:04:57 | Train | Epoch[111/600] Iteration[012/030] Train loss: 0.0378
2023-02-06 14:04:58 | Train | Epoch[111/600] Iteration[013/030] Train loss: 0.0377
2023-02-06 14:04:58 | Train | Epoch[111/600] Iteration[014/030] Train loss: 0.0377
2023-02-06 14:04:58 | Train | Epoch[111/600] Iteration[015/030] Train loss: 0.0378
2023-02-06 14:04:58 | Train | Epoch[111/600] Iteration[016/030] Train loss: 0.0378
2023-02-06 14:04:59 | Train | Epoch[111/600] Iteration[017/030] Train loss: 0.0378
2023-02-06 14:04:59 | Train | Epoch[111/600] Iteration[018/030] Train loss: 0.0379
2023-02-06 14:04:59 | Train | Epoch[111/600] Iteration[019/030] Train loss: 0.0380
2023-02-06 14:04:59 | Train | Epoch[111/600] Iteration[020/030] Train loss: 0.0380
2023-02-06 14:04:59 | Train | Epoch[111/600] Iteration[021/030] Train loss: 0.0380
2023-02-06 14:05:00 | Train | Epoch[111/600] Iteration[022/030] Train loss: 0.0379
2023-02-06 14:05:00 | Train | Epoch[111/600] Iteration[023/030] Train loss: 0.0379
2023-02-06 14:05:00 | Train | Epoch[111/600] Iteration[024/030] Train loss: 0.0379
2023-02-06 14:05:00 | Train | Epoch[111/600] Iteration[025/030] Train loss: 0.0379
2023-02-06 14:05:01 | Train | Epoch[111/600] Iteration[026/030] Train loss: 0.0379
2023-02-06 14:05:01 | Train | Epoch[111/600] Iteration[027/030] Train loss: 0.0379
2023-02-06 14:05:01 | Train | Epoch[111/600] Iteration[028/030] Train loss: 0.0379
2023-02-06 14:05:01 | Train | Epoch[111/600] Iteration[029/030] Train loss: 0.0378
2023-02-06 14:05:01 | Train | Epoch[111/600] Iteration[030/030] Train loss: 0.0378
2023-02-06 14:05:02 | Valid | Epoch[111/600] Iteration[001/008] Valid loss: 0.2307
2023-02-06 14:05:02 | Valid | Epoch[111/600] Iteration[002/008] Valid loss: 0.1870
2023-02-06 14:05:02 | Valid | Epoch[111/600] Iteration[003/008] Valid loss: 0.1772
2023-02-06 14:05:02 | Valid | Epoch[111/600] Iteration[004/008] Valid loss: 0.1714
2023-02-06 14:05:02 | Valid | Epoch[111/600] Iteration[005/008] Valid loss: 0.1745
2023-02-06 14:05:02 | Valid | Epoch[111/600] Iteration[006/008] Valid loss: 0.1666
2023-02-06 14:05:02 | Valid | Epoch[111/600] Iteration[007/008] Valid loss: 0.1845
2023-02-06 14:05:02 | Valid | Epoch[111/600] Iteration[008/008] Valid loss: 0.1850
2023-02-06 14:05:02 | Valid | Epoch[111/600] MIou: 0.9153512772490922
2023-02-06 14:05:02 | Valid | Epoch[111/600] Pixel Accuracy: 0.9843622843424479
2023-02-06 14:05:02 | Valid | Epoch[111/600] Mean Pixel Accuracy: 0.975502941989871
2023-02-06 14:05:02 | Stage | Epoch[111/600] Train loss:0.0378
2023-02-06 14:05:02 | Stage | Epoch[111/600] Valid loss:0.1850
2023-02-06 14:05:02 | Stage | Epoch[111/600] LR:0.01

2023-02-06 14:05:03 | Train | Epoch[112/600] Iteration[001/030] Train loss: 0.0389
2023-02-06 14:05:03 | Train | Epoch[112/600] Iteration[002/030] Train loss: 0.0380
2023-02-06 14:05:03 | Train | Epoch[112/600] Iteration[003/030] Train loss: 0.0376
2023-02-06 14:05:03 | Train | Epoch[112/600] Iteration[004/030] Train loss: 0.0371
2023-02-06 14:05:03 | Train | Epoch[112/600] Iteration[005/030] Train loss: 0.0370
2023-02-06 14:05:04 | Train | Epoch[112/600] Iteration[006/030] Train loss: 0.0371
2023-02-06 14:05:04 | Train | Epoch[112/600] Iteration[007/030] Train loss: 0.0373
2023-02-06 14:05:04 | Train | Epoch[112/600] Iteration[008/030] Train loss: 0.0372
2023-02-06 14:05:04 | Train | Epoch[112/600] Iteration[009/030] Train loss: 0.0372
2023-02-06 14:05:05 | Train | Epoch[112/600] Iteration[010/030] Train loss: 0.0372
2023-02-06 14:05:05 | Train | Epoch[112/600] Iteration[011/030] Train loss: 0.0372
2023-02-06 14:05:05 | Train | Epoch[112/600] Iteration[012/030] Train loss: 0.0372
2023-02-06 14:05:05 | Train | Epoch[112/600] Iteration[013/030] Train loss: 0.0371
2023-02-06 14:05:05 | Train | Epoch[112/600] Iteration[014/030] Train loss: 0.0375
2023-02-06 14:05:06 | Train | Epoch[112/600] Iteration[015/030] Train loss: 0.0374
2023-02-06 14:05:06 | Train | Epoch[112/600] Iteration[016/030] Train loss: 0.0373
2023-02-06 14:05:06 | Train | Epoch[112/600] Iteration[017/030] Train loss: 0.0373
2023-02-06 14:05:06 | Train | Epoch[112/600] Iteration[018/030] Train loss: 0.0375
2023-02-06 14:05:07 | Train | Epoch[112/600] Iteration[019/030] Train loss: 0.0375
2023-02-06 14:05:07 | Train | Epoch[112/600] Iteration[020/030] Train loss: 0.0374
2023-02-06 14:05:07 | Train | Epoch[112/600] Iteration[021/030] Train loss: 0.0374
2023-02-06 14:05:07 | Train | Epoch[112/600] Iteration[022/030] Train loss: 0.0375
2023-02-06 14:05:07 | Train | Epoch[112/600] Iteration[023/030] Train loss: 0.0374
2023-02-06 14:05:08 | Train | Epoch[112/600] Iteration[024/030] Train loss: 0.0374
2023-02-06 14:05:08 | Train | Epoch[112/600] Iteration[025/030] Train loss: 0.0374
2023-02-06 14:05:08 | Train | Epoch[112/600] Iteration[026/030] Train loss: 0.0373
2023-02-06 14:05:08 | Train | Epoch[112/600] Iteration[027/030] Train loss: 0.0373
2023-02-06 14:05:09 | Train | Epoch[112/600] Iteration[028/030] Train loss: 0.0373
2023-02-06 14:05:09 | Train | Epoch[112/600] Iteration[029/030] Train loss: 0.0373
2023-02-06 14:05:09 | Train | Epoch[112/600] Iteration[030/030] Train loss: 0.0374
2023-02-06 14:05:09 | Valid | Epoch[112/600] Iteration[001/008] Valid loss: 0.0958
2023-02-06 14:05:09 | Valid | Epoch[112/600] Iteration[002/008] Valid loss: 0.0998
2023-02-06 14:05:09 | Valid | Epoch[112/600] Iteration[003/008] Valid loss: 0.1047
2023-02-06 14:05:09 | Valid | Epoch[112/600] Iteration[004/008] Valid loss: 0.1041
2023-02-06 14:05:09 | Valid | Epoch[112/600] Iteration[005/008] Valid loss: 0.1061
2023-02-06 14:05:09 | Valid | Epoch[112/600] Iteration[006/008] Valid loss: 0.1042
2023-02-06 14:05:09 | Valid | Epoch[112/600] Iteration[007/008] Valid loss: 0.1010
2023-02-06 14:05:10 | Valid | Epoch[112/600] Iteration[008/008] Valid loss: 0.1035
2023-02-06 14:05:10 | Valid | Epoch[112/600] MIou: 0.7041544396712363
2023-02-06 14:05:10 | Valid | Epoch[112/600] Pixel Accuracy: 0.9511489868164062
2023-02-06 14:05:10 | Valid | Epoch[112/600] Mean Pixel Accuracy: 0.7296879745881348
2023-02-06 14:05:10 | Stage | Epoch[112/600] Train loss:0.0374
2023-02-06 14:05:10 | Stage | Epoch[112/600] Valid loss:0.1035
2023-02-06 14:05:10 | Stage | Epoch[112/600] LR:0.01

2023-02-06 14:05:10 | Train | Epoch[113/600] Iteration[001/030] Train loss: 0.0365
2023-02-06 14:05:10 | Train | Epoch[113/600] Iteration[002/030] Train loss: 0.0364
2023-02-06 14:05:11 | Train | Epoch[113/600] Iteration[003/030] Train loss: 0.0365
2023-02-06 14:05:11 | Train | Epoch[113/600] Iteration[004/030] Train loss: 0.0364
2023-02-06 14:05:11 | Train | Epoch[113/600] Iteration[005/030] Train loss: 0.0365
2023-02-06 14:05:11 | Train | Epoch[113/600] Iteration[006/030] Train loss: 0.0365
2023-02-06 14:05:11 | Train | Epoch[113/600] Iteration[007/030] Train loss: 0.0366
2023-02-06 14:05:12 | Train | Epoch[113/600] Iteration[008/030] Train loss: 0.0367
2023-02-06 14:05:12 | Train | Epoch[113/600] Iteration[009/030] Train loss: 0.0367
2023-02-06 14:05:12 | Train | Epoch[113/600] Iteration[010/030] Train loss: 0.0366
2023-02-06 14:05:12 | Train | Epoch[113/600] Iteration[011/030] Train loss: 0.0365
2023-02-06 14:05:13 | Train | Epoch[113/600] Iteration[012/030] Train loss: 0.0367
2023-02-06 14:05:13 | Train | Epoch[113/600] Iteration[013/030] Train loss: 0.0368
2023-02-06 14:05:13 | Train | Epoch[113/600] Iteration[014/030] Train loss: 0.0366
2023-02-06 14:05:13 | Train | Epoch[113/600] Iteration[015/030] Train loss: 0.0367
2023-02-06 14:05:13 | Train | Epoch[113/600] Iteration[016/030] Train loss: 0.0366
2023-02-06 14:05:14 | Train | Epoch[113/600] Iteration[017/030] Train loss: 0.0366
2023-02-06 14:05:14 | Train | Epoch[113/600] Iteration[018/030] Train loss: 0.0368
2023-02-06 14:05:14 | Train | Epoch[113/600] Iteration[019/030] Train loss: 0.0368
2023-02-06 14:05:14 | Train | Epoch[113/600] Iteration[020/030] Train loss: 0.0368
2023-02-06 14:05:14 | Train | Epoch[113/600] Iteration[021/030] Train loss: 0.0367
2023-02-06 14:05:15 | Train | Epoch[113/600] Iteration[022/030] Train loss: 0.0367
2023-02-06 14:05:15 | Train | Epoch[113/600] Iteration[023/030] Train loss: 0.0367
2023-02-06 14:05:15 | Train | Epoch[113/600] Iteration[024/030] Train loss: 0.0367
2023-02-06 14:05:15 | Train | Epoch[113/600] Iteration[025/030] Train loss: 0.0366
2023-02-06 14:05:16 | Train | Epoch[113/600] Iteration[026/030] Train loss: 0.0367
2023-02-06 14:05:16 | Train | Epoch[113/600] Iteration[027/030] Train loss: 0.0367
2023-02-06 14:05:16 | Train | Epoch[113/600] Iteration[028/030] Train loss: 0.0367
2023-02-06 14:05:16 | Train | Epoch[113/600] Iteration[029/030] Train loss: 0.0367
2023-02-06 14:05:16 | Train | Epoch[113/600] Iteration[030/030] Train loss: 0.0367
2023-02-06 14:05:17 | Valid | Epoch[113/600] Iteration[001/008] Valid loss: 0.2519
2023-02-06 14:05:17 | Valid | Epoch[113/600] Iteration[002/008] Valid loss: 0.1916
2023-02-06 14:05:17 | Valid | Epoch[113/600] Iteration[003/008] Valid loss: 0.1815
2023-02-06 14:05:17 | Valid | Epoch[113/600] Iteration[004/008] Valid loss: 0.1820
2023-02-06 14:05:17 | Valid | Epoch[113/600] Iteration[005/008] Valid loss: 0.1848
2023-02-06 14:05:17 | Valid | Epoch[113/600] Iteration[006/008] Valid loss: 0.1801
2023-02-06 14:05:17 | Valid | Epoch[113/600] Iteration[007/008] Valid loss: 0.1897
2023-02-06 14:05:17 | Valid | Epoch[113/600] Iteration[008/008] Valid loss: 0.1935
2023-02-06 14:05:17 | Valid | Epoch[113/600] MIou: 0.9086176091081622
2023-02-06 14:05:17 | Valid | Epoch[113/600] Pixel Accuracy: 0.9828516642252604
2023-02-06 14:05:17 | Valid | Epoch[113/600] Mean Pixel Accuracy: 0.9761816729669499
2023-02-06 14:05:17 | Stage | Epoch[113/600] Train loss:0.0367
2023-02-06 14:05:17 | Stage | Epoch[113/600] Valid loss:0.1935
2023-02-06 14:05:17 | Stage | Epoch[113/600] LR:0.01

2023-02-06 14:05:18 | Train | Epoch[114/600] Iteration[001/030] Train loss: 0.0355
2023-02-06 14:05:18 | Train | Epoch[114/600] Iteration[002/030] Train loss: 0.0353
2023-02-06 14:05:18 | Train | Epoch[114/600] Iteration[003/030] Train loss: 0.0355
2023-02-06 14:05:18 | Train | Epoch[114/600] Iteration[004/030] Train loss: 0.0359
2023-02-06 14:05:18 | Train | Epoch[114/600] Iteration[005/030] Train loss: 0.0359
2023-02-06 14:05:19 | Train | Epoch[114/600] Iteration[006/030] Train loss: 0.0359
2023-02-06 14:05:19 | Train | Epoch[114/600] Iteration[007/030] Train loss: 0.0359
2023-02-06 14:05:19 | Train | Epoch[114/600] Iteration[008/030] Train loss: 0.0360
2023-02-06 14:05:19 | Train | Epoch[114/600] Iteration[009/030] Train loss: 0.0362
2023-02-06 14:05:20 | Train | Epoch[114/600] Iteration[010/030] Train loss: 0.0363
2023-02-06 14:05:20 | Train | Epoch[114/600] Iteration[011/030] Train loss: 0.0363
2023-02-06 14:05:20 | Train | Epoch[114/600] Iteration[012/030] Train loss: 0.0362
2023-02-06 14:05:20 | Train | Epoch[114/600] Iteration[013/030] Train loss: 0.0363
2023-02-06 14:05:20 | Train | Epoch[114/600] Iteration[014/030] Train loss: 0.0362
2023-02-06 14:05:21 | Train | Epoch[114/600] Iteration[015/030] Train loss: 0.0362
2023-02-06 14:05:21 | Train | Epoch[114/600] Iteration[016/030] Train loss: 0.0362
2023-02-06 14:05:21 | Train | Epoch[114/600] Iteration[017/030] Train loss: 0.0362
2023-02-06 14:05:21 | Train | Epoch[114/600] Iteration[018/030] Train loss: 0.0362
2023-02-06 14:05:22 | Train | Epoch[114/600] Iteration[019/030] Train loss: 0.0362
2023-02-06 14:05:22 | Train | Epoch[114/600] Iteration[020/030] Train loss: 0.0361
2023-02-06 14:05:22 | Train | Epoch[114/600] Iteration[021/030] Train loss: 0.0360
2023-02-06 14:05:22 | Train | Epoch[114/600] Iteration[022/030] Train loss: 0.0361
2023-02-06 14:05:22 | Train | Epoch[114/600] Iteration[023/030] Train loss: 0.0360
2023-02-06 14:05:23 | Train | Epoch[114/600] Iteration[024/030] Train loss: 0.0361
2023-02-06 14:05:23 | Train | Epoch[114/600] Iteration[025/030] Train loss: 0.0360
2023-02-06 14:05:23 | Train | Epoch[114/600] Iteration[026/030] Train loss: 0.0360
2023-02-06 14:05:23 | Train | Epoch[114/600] Iteration[027/030] Train loss: 0.0360
2023-02-06 14:05:23 | Train | Epoch[114/600] Iteration[028/030] Train loss: 0.0360
2023-02-06 14:05:24 | Train | Epoch[114/600] Iteration[029/030] Train loss: 0.0361
2023-02-06 14:05:24 | Train | Epoch[114/600] Iteration[030/030] Train loss: 0.0361
2023-02-06 14:05:24 | Valid | Epoch[114/600] Iteration[001/008] Valid loss: 0.0728
2023-02-06 14:05:24 | Valid | Epoch[114/600] Iteration[002/008] Valid loss: 0.0639
2023-02-06 14:05:24 | Valid | Epoch[114/600] Iteration[003/008] Valid loss: 0.0613
2023-02-06 14:05:24 | Valid | Epoch[114/600] Iteration[004/008] Valid loss: 0.0590
2023-02-06 14:05:24 | Valid | Epoch[114/600] Iteration[005/008] Valid loss: 0.0586
2023-02-06 14:05:24 | Valid | Epoch[114/600] Iteration[006/008] Valid loss: 0.0575
2023-02-06 14:05:24 | Valid | Epoch[114/600] Iteration[007/008] Valid loss: 0.0569
2023-02-06 14:05:25 | Valid | Epoch[114/600] Iteration[008/008] Valid loss: 0.0565
2023-02-06 14:05:25 | Valid | Epoch[114/600] MIou: 0.903661461078322
2023-02-06 14:05:25 | Valid | Epoch[114/600] Pixel Accuracy: 0.9840240478515625
2023-02-06 14:05:25 | Valid | Epoch[114/600] Mean Pixel Accuracy: 0.9153615341708163
2023-02-06 14:05:25 | Stage | Epoch[114/600] Train loss:0.0361
2023-02-06 14:05:25 | Stage | Epoch[114/600] Valid loss:0.0565
2023-02-06 14:05:25 | Stage | Epoch[114/600] LR:0.01

2023-02-06 14:05:25 | Train | Epoch[115/600] Iteration[001/030] Train loss: 0.0349
2023-02-06 14:05:25 | Train | Epoch[115/600] Iteration[002/030] Train loss: 0.0349
2023-02-06 14:05:26 | Train | Epoch[115/600] Iteration[003/030] Train loss: 0.0349
2023-02-06 14:05:26 | Train | Epoch[115/600] Iteration[004/030] Train loss: 0.0351
2023-02-06 14:05:26 | Train | Epoch[115/600] Iteration[005/030] Train loss: 0.0350
2023-02-06 14:05:26 | Train | Epoch[115/600] Iteration[006/030] Train loss: 0.0351
2023-02-06 14:05:26 | Train | Epoch[115/600] Iteration[007/030] Train loss: 0.0354
2023-02-06 14:05:27 | Train | Epoch[115/600] Iteration[008/030] Train loss: 0.0352
2023-02-06 14:05:27 | Train | Epoch[115/600] Iteration[009/030] Train loss: 0.0352
2023-02-06 14:05:27 | Train | Epoch[115/600] Iteration[010/030] Train loss: 0.0352
2023-02-06 14:05:27 | Train | Epoch[115/600] Iteration[011/030] Train loss: 0.0351
2023-02-06 14:05:28 | Train | Epoch[115/600] Iteration[012/030] Train loss: 0.0350
2023-02-06 14:05:28 | Train | Epoch[115/600] Iteration[013/030] Train loss: 0.0349
2023-02-06 14:05:28 | Train | Epoch[115/600] Iteration[014/030] Train loss: 0.0350
2023-02-06 14:05:28 | Train | Epoch[115/600] Iteration[015/030] Train loss: 0.0350
2023-02-06 14:05:28 | Train | Epoch[115/600] Iteration[016/030] Train loss: 0.0351
2023-02-06 14:05:29 | Train | Epoch[115/600] Iteration[017/030] Train loss: 0.0353
2023-02-06 14:05:29 | Train | Epoch[115/600] Iteration[018/030] Train loss: 0.0352
2023-02-06 14:05:29 | Train | Epoch[115/600] Iteration[019/030] Train loss: 0.0352
2023-02-06 14:05:29 | Train | Epoch[115/600] Iteration[020/030] Train loss: 0.0351
2023-02-06 14:05:30 | Train | Epoch[115/600] Iteration[021/030] Train loss: 0.0352
2023-02-06 14:05:30 | Train | Epoch[115/600] Iteration[022/030] Train loss: 0.0352
2023-02-06 14:05:30 | Train | Epoch[115/600] Iteration[023/030] Train loss: 0.0352
2023-02-06 14:05:30 | Train | Epoch[115/600] Iteration[024/030] Train loss: 0.0354
2023-02-06 14:05:30 | Train | Epoch[115/600] Iteration[025/030] Train loss: 0.0355
2023-02-06 14:05:31 | Train | Epoch[115/600] Iteration[026/030] Train loss: 0.0355
2023-02-06 14:05:31 | Train | Epoch[115/600] Iteration[027/030] Train loss: 0.0355
2023-02-06 14:05:31 | Train | Epoch[115/600] Iteration[028/030] Train loss: 0.0356
2023-02-06 14:05:31 | Train | Epoch[115/600] Iteration[029/030] Train loss: 0.0356
2023-02-06 14:05:31 | Train | Epoch[115/600] Iteration[030/030] Train loss: 0.0357
2023-02-06 14:05:32 | Valid | Epoch[115/600] Iteration[001/008] Valid loss: 0.0837
2023-02-06 14:05:32 | Valid | Epoch[115/600] Iteration[002/008] Valid loss: 0.0820
2023-02-06 14:05:32 | Valid | Epoch[115/600] Iteration[003/008] Valid loss: 0.0845
2023-02-06 14:05:32 | Valid | Epoch[115/600] Iteration[004/008] Valid loss: 0.0836
2023-02-06 14:05:32 | Valid | Epoch[115/600] Iteration[005/008] Valid loss: 0.0843
2023-02-06 14:05:32 | Valid | Epoch[115/600] Iteration[006/008] Valid loss: 0.0831
2023-02-06 14:05:32 | Valid | Epoch[115/600] Iteration[007/008] Valid loss: 0.0811
2023-02-06 14:05:32 | Valid | Epoch[115/600] Iteration[008/008] Valid loss: 0.0816
2023-02-06 14:05:32 | Valid | Epoch[115/600] MIou: 0.8156460406751028
2023-02-06 14:05:32 | Valid | Epoch[115/600] Pixel Accuracy: 0.9695994059244791
2023-02-06 14:05:32 | Valid | Epoch[115/600] Mean Pixel Accuracy: 0.832006886663891
2023-02-06 14:05:32 | Stage | Epoch[115/600] Train loss:0.0357
2023-02-06 14:05:32 | Stage | Epoch[115/600] Valid loss:0.0816
2023-02-06 14:05:32 | Stage | Epoch[115/600] LR:0.01

2023-02-06 14:05:33 | Train | Epoch[116/600] Iteration[001/030] Train loss: 0.0353
2023-02-06 14:05:33 | Train | Epoch[116/600] Iteration[002/030] Train loss: 0.0343
2023-02-06 14:05:33 | Train | Epoch[116/600] Iteration[003/030] Train loss: 0.0343
2023-02-06 14:05:33 | Train | Epoch[116/600] Iteration[004/030] Train loss: 0.0346
2023-02-06 14:05:34 | Train | Epoch[116/600] Iteration[005/030] Train loss: 0.0349
2023-02-06 14:05:34 | Train | Epoch[116/600] Iteration[006/030] Train loss: 0.0347
2023-02-06 14:05:34 | Train | Epoch[116/600] Iteration[007/030] Train loss: 0.0348
2023-02-06 14:05:34 | Train | Epoch[116/600] Iteration[008/030] Train loss: 0.0348
2023-02-06 14:05:34 | Train | Epoch[116/600] Iteration[009/030] Train loss: 0.0348
2023-02-06 14:05:35 | Train | Epoch[116/600] Iteration[010/030] Train loss: 0.0349
2023-02-06 14:05:35 | Train | Epoch[116/600] Iteration[011/030] Train loss: 0.0350
2023-02-06 14:05:35 | Train | Epoch[116/600] Iteration[012/030] Train loss: 0.0356
2023-02-06 14:05:35 | Train | Epoch[116/600] Iteration[013/030] Train loss: 0.0356
2023-02-06 14:05:36 | Train | Epoch[116/600] Iteration[014/030] Train loss: 0.0356
2023-02-06 14:05:36 | Train | Epoch[116/600] Iteration[015/030] Train loss: 0.0356
2023-02-06 14:05:36 | Train | Epoch[116/600] Iteration[016/030] Train loss: 0.0356
2023-02-06 14:05:36 | Train | Epoch[116/600] Iteration[017/030] Train loss: 0.0355
2023-02-06 14:05:36 | Train | Epoch[116/600] Iteration[018/030] Train loss: 0.0357
2023-02-06 14:05:37 | Train | Epoch[116/600] Iteration[019/030] Train loss: 0.0357
2023-02-06 14:05:37 | Train | Epoch[116/600] Iteration[020/030] Train loss: 0.0357
2023-02-06 14:05:37 | Train | Epoch[116/600] Iteration[021/030] Train loss: 0.0357
2023-02-06 14:05:37 | Train | Epoch[116/600] Iteration[022/030] Train loss: 0.0359
2023-02-06 14:05:37 | Train | Epoch[116/600] Iteration[023/030] Train loss: 0.0358
2023-02-06 14:05:38 | Train | Epoch[116/600] Iteration[024/030] Train loss: 0.0358
2023-02-06 14:05:38 | Train | Epoch[116/600] Iteration[025/030] Train loss: 0.0358
2023-02-06 14:05:38 | Train | Epoch[116/600] Iteration[026/030] Train loss: 0.0358
2023-02-06 14:05:38 | Train | Epoch[116/600] Iteration[027/030] Train loss: 0.0358
2023-02-06 14:05:39 | Train | Epoch[116/600] Iteration[028/030] Train loss: 0.0359
2023-02-06 14:05:39 | Train | Epoch[116/600] Iteration[029/030] Train loss: 0.0358
2023-02-06 14:05:39 | Train | Epoch[116/600] Iteration[030/030] Train loss: 0.0358
2023-02-06 14:05:39 | Valid | Epoch[116/600] Iteration[001/008] Valid loss: 0.2495
2023-02-06 14:05:39 | Valid | Epoch[116/600] Iteration[002/008] Valid loss: 0.2246
2023-02-06 14:05:39 | Valid | Epoch[116/600] Iteration[003/008] Valid loss: 0.2258
2023-02-06 14:05:39 | Valid | Epoch[116/600] Iteration[004/008] Valid loss: 0.2189
2023-02-06 14:05:39 | Valid | Epoch[116/600] Iteration[005/008] Valid loss: 0.2209
2023-02-06 14:05:39 | Valid | Epoch[116/600] Iteration[006/008] Valid loss: 0.2248
2023-02-06 14:05:40 | Valid | Epoch[116/600] Iteration[007/008] Valid loss: 0.2474
2023-02-06 14:05:40 | Valid | Epoch[116/600] Iteration[008/008] Valid loss: 0.2447
2023-02-06 14:05:40 | Valid | Epoch[116/600] MIou: 0.8980767012025311
2023-02-06 14:05:40 | Valid | Epoch[116/600] Pixel Accuracy: 0.9805628458658854
2023-02-06 14:05:40 | Valid | Epoch[116/600] Mean Pixel Accuracy: 0.9729454136691265
2023-02-06 14:05:40 | Stage | Epoch[116/600] Train loss:0.0358
2023-02-06 14:05:40 | Stage | Epoch[116/600] Valid loss:0.2447
2023-02-06 14:05:40 | Stage | Epoch[116/600] LR:0.01

2023-02-06 14:05:40 | Train | Epoch[117/600] Iteration[001/030] Train loss: 0.0366
2023-02-06 14:05:40 | Train | Epoch[117/600] Iteration[002/030] Train loss: 0.0353
2023-02-06 14:05:41 | Train | Epoch[117/600] Iteration[003/030] Train loss: 0.0350
2023-02-06 14:05:41 | Train | Epoch[117/600] Iteration[004/030] Train loss: 0.0346
2023-02-06 14:05:41 | Train | Epoch[117/600] Iteration[005/030] Train loss: 0.0345
2023-02-06 14:05:41 | Train | Epoch[117/600] Iteration[006/030] Train loss: 0.0350
2023-02-06 14:05:41 | Train | Epoch[117/600] Iteration[007/030] Train loss: 0.0348
2023-02-06 14:05:42 | Train | Epoch[117/600] Iteration[008/030] Train loss: 0.0349
2023-02-06 14:05:42 | Train | Epoch[117/600] Iteration[009/030] Train loss: 0.0349
2023-02-06 14:05:42 | Train | Epoch[117/600] Iteration[010/030] Train loss: 0.0348
2023-02-06 14:05:42 | Train | Epoch[117/600] Iteration[011/030] Train loss: 0.0348
2023-02-06 14:05:43 | Train | Epoch[117/600] Iteration[012/030] Train loss: 0.0348
2023-02-06 14:05:43 | Train | Epoch[117/600] Iteration[013/030] Train loss: 0.0350
2023-02-06 14:05:43 | Train | Epoch[117/600] Iteration[014/030] Train loss: 0.0351
2023-02-06 14:05:43 | Train | Epoch[117/600] Iteration[015/030] Train loss: 0.0350
2023-02-06 14:05:43 | Train | Epoch[117/600] Iteration[016/030] Train loss: 0.0350
2023-02-06 14:05:44 | Train | Epoch[117/600] Iteration[017/030] Train loss: 0.0350
2023-02-06 14:05:44 | Train | Epoch[117/600] Iteration[018/030] Train loss: 0.0350
2023-02-06 14:05:44 | Train | Epoch[117/600] Iteration[019/030] Train loss: 0.0349
2023-02-06 14:05:44 | Train | Epoch[117/600] Iteration[020/030] Train loss: 0.0350
2023-02-06 14:05:45 | Train | Epoch[117/600] Iteration[021/030] Train loss: 0.0351
2023-02-06 14:05:45 | Train | Epoch[117/600] Iteration[022/030] Train loss: 0.0351
2023-02-06 14:05:45 | Train | Epoch[117/600] Iteration[023/030] Train loss: 0.0351
2023-02-06 14:05:45 | Train | Epoch[117/600] Iteration[024/030] Train loss: 0.0352
2023-02-06 14:05:45 | Train | Epoch[117/600] Iteration[025/030] Train loss: 0.0352
2023-02-06 14:05:46 | Train | Epoch[117/600] Iteration[026/030] Train loss: 0.0352
2023-02-06 14:05:46 | Train | Epoch[117/600] Iteration[027/030] Train loss: 0.0352
2023-02-06 14:05:46 | Train | Epoch[117/600] Iteration[028/030] Train loss: 0.0352
2023-02-06 14:05:46 | Train | Epoch[117/600] Iteration[029/030] Train loss: 0.0352
2023-02-06 14:05:46 | Train | Epoch[117/600] Iteration[030/030] Train loss: 0.0352
2023-02-06 14:05:47 | Valid | Epoch[117/600] Iteration[001/008] Valid loss: 0.0872
2023-02-06 14:05:47 | Valid | Epoch[117/600] Iteration[002/008] Valid loss: 0.0858
2023-02-06 14:05:47 | Valid | Epoch[117/600] Iteration[003/008] Valid loss: 0.0892
2023-02-06 14:05:47 | Valid | Epoch[117/600] Iteration[004/008] Valid loss: 0.0882
2023-02-06 14:05:47 | Valid | Epoch[117/600] Iteration[005/008] Valid loss: 0.0883
2023-02-06 14:05:47 | Valid | Epoch[117/600] Iteration[006/008] Valid loss: 0.0869
2023-02-06 14:05:47 | Valid | Epoch[117/600] Iteration[007/008] Valid loss: 0.0851
2023-02-06 14:05:47 | Valid | Epoch[117/600] Iteration[008/008] Valid loss: 0.0866
2023-02-06 14:05:47 | Valid | Epoch[117/600] MIou: 0.7635851985559188
2023-02-06 14:05:47 | Valid | Epoch[117/600] Pixel Accuracy: 0.9609235127766927
2023-02-06 14:05:47 | Valid | Epoch[117/600] Mean Pixel Accuracy: 0.7847380652265032
2023-02-06 14:05:47 | Stage | Epoch[117/600] Train loss:0.0352
2023-02-06 14:05:47 | Stage | Epoch[117/600] Valid loss:0.0866
2023-02-06 14:05:47 | Stage | Epoch[117/600] LR:0.01

2023-02-06 14:05:48 | Train | Epoch[118/600] Iteration[001/030] Train loss: 0.0350
2023-02-06 14:05:48 | Train | Epoch[118/600] Iteration[002/030] Train loss: 0.0339
2023-02-06 14:05:48 | Train | Epoch[118/600] Iteration[003/030] Train loss: 0.0336
2023-02-06 14:05:48 | Train | Epoch[118/600] Iteration[004/030] Train loss: 0.0340
2023-02-06 14:05:49 | Train | Epoch[118/600] Iteration[005/030] Train loss: 0.0339
2023-02-06 14:05:49 | Train | Epoch[118/600] Iteration[006/030] Train loss: 0.0339
2023-02-06 14:05:49 | Train | Epoch[118/600] Iteration[007/030] Train loss: 0.0340
2023-02-06 14:05:49 | Train | Epoch[118/600] Iteration[008/030] Train loss: 0.0342
2023-02-06 14:05:49 | Train | Epoch[118/600] Iteration[009/030] Train loss: 0.0343
2023-02-06 14:05:50 | Train | Epoch[118/600] Iteration[010/030] Train loss: 0.0344
2023-02-06 14:05:50 | Train | Epoch[118/600] Iteration[011/030] Train loss: 0.0346
2023-02-06 14:05:50 | Train | Epoch[118/600] Iteration[012/030] Train loss: 0.0345
2023-02-06 14:05:50 | Train | Epoch[118/600] Iteration[013/030] Train loss: 0.0345
2023-02-06 14:05:51 | Train | Epoch[118/600] Iteration[014/030] Train loss: 0.0345
2023-02-06 14:05:51 | Train | Epoch[118/600] Iteration[015/030] Train loss: 0.0344
2023-02-06 14:05:51 | Train | Epoch[118/600] Iteration[016/030] Train loss: 0.0346
2023-02-06 14:05:51 | Train | Epoch[118/600] Iteration[017/030] Train loss: 0.0345
2023-02-06 14:05:51 | Train | Epoch[118/600] Iteration[018/030] Train loss: 0.0345
2023-02-06 14:05:52 | Train | Epoch[118/600] Iteration[019/030] Train loss: 0.0344
2023-02-06 14:05:52 | Train | Epoch[118/600] Iteration[020/030] Train loss: 0.0344
2023-02-06 14:05:52 | Train | Epoch[118/600] Iteration[021/030] Train loss: 0.0344
2023-02-06 14:05:52 | Train | Epoch[118/600] Iteration[022/030] Train loss: 0.0343
2023-02-06 14:05:52 | Train | Epoch[118/600] Iteration[023/030] Train loss: 0.0343
2023-02-06 14:05:53 | Train | Epoch[118/600] Iteration[024/030] Train loss: 0.0344
2023-02-06 14:05:53 | Train | Epoch[118/600] Iteration[025/030] Train loss: 0.0344
2023-02-06 14:05:53 | Train | Epoch[118/600] Iteration[026/030] Train loss: 0.0343
2023-02-06 14:05:53 | Train | Epoch[118/600] Iteration[027/030] Train loss: 0.0344
2023-02-06 14:05:54 | Train | Epoch[118/600] Iteration[028/030] Train loss: 0.0343
2023-02-06 14:05:54 | Train | Epoch[118/600] Iteration[029/030] Train loss: 0.0344
2023-02-06 14:05:54 | Train | Epoch[118/600] Iteration[030/030] Train loss: 0.0344
2023-02-06 14:05:54 | Valid | Epoch[118/600] Iteration[001/008] Valid loss: 0.2403
2023-02-06 14:05:54 | Valid | Epoch[118/600] Iteration[002/008] Valid loss: 0.1893
2023-02-06 14:05:54 | Valid | Epoch[118/600] Iteration[003/008] Valid loss: 0.1922
2023-02-06 14:05:54 | Valid | Epoch[118/600] Iteration[004/008] Valid loss: 0.1771
2023-02-06 14:05:54 | Valid | Epoch[118/600] Iteration[005/008] Valid loss: 0.1730
2023-02-06 14:05:55 | Valid | Epoch[118/600] Iteration[006/008] Valid loss: 0.1657
2023-02-06 14:05:55 | Valid | Epoch[118/600] Iteration[007/008] Valid loss: 0.1764
2023-02-06 14:05:55 | Valid | Epoch[118/600] Iteration[008/008] Valid loss: 0.1740
2023-02-06 14:05:55 | Valid | Epoch[118/600] MIou: 0.913262086716463
2023-02-06 14:05:55 | Valid | Epoch[118/600] Pixel Accuracy: 0.9838523864746094
2023-02-06 14:05:55 | Valid | Epoch[118/600] Mean Pixel Accuracy: 0.9771184813572007
2023-02-06 14:05:55 | Stage | Epoch[118/600] Train loss:0.0344
2023-02-06 14:05:55 | Stage | Epoch[118/600] Valid loss:0.1740
2023-02-06 14:05:55 | Stage | Epoch[118/600] LR:0.01

2023-02-06 14:05:55 | Train | Epoch[119/600] Iteration[001/030] Train loss: 0.0330
2023-02-06 14:05:55 | Train | Epoch[119/600] Iteration[002/030] Train loss: 0.0333
2023-02-06 14:05:56 | Train | Epoch[119/600] Iteration[003/030] Train loss: 0.0331
2023-02-06 14:05:56 | Train | Epoch[119/600] Iteration[004/030] Train loss: 0.0341
2023-02-06 14:05:56 | Train | Epoch[119/600] Iteration[005/030] Train loss: 0.0341
2023-02-06 14:05:56 | Train | Epoch[119/600] Iteration[006/030] Train loss: 0.0342
2023-02-06 14:05:57 | Train | Epoch[119/600] Iteration[007/030] Train loss: 0.0343
2023-02-06 14:05:57 | Train | Epoch[119/600] Iteration[008/030] Train loss: 0.0343
2023-02-06 14:05:57 | Train | Epoch[119/600] Iteration[009/030] Train loss: 0.0344
2023-02-06 14:05:57 | Train | Epoch[119/600] Iteration[010/030] Train loss: 0.0344
2023-02-06 14:05:57 | Train | Epoch[119/600] Iteration[011/030] Train loss: 0.0346
2023-02-06 14:05:58 | Train | Epoch[119/600] Iteration[012/030] Train loss: 0.0345
2023-02-06 14:05:58 | Train | Epoch[119/600] Iteration[013/030] Train loss: 0.0347
2023-02-06 14:05:58 | Train | Epoch[119/600] Iteration[014/030] Train loss: 0.0347
2023-02-06 14:05:58 | Train | Epoch[119/600] Iteration[015/030] Train loss: 0.0347
2023-02-06 14:05:58 | Train | Epoch[119/600] Iteration[016/030] Train loss: 0.0346
2023-02-06 14:05:59 | Train | Epoch[119/600] Iteration[017/030] Train loss: 0.0344
2023-02-06 14:05:59 | Train | Epoch[119/600] Iteration[018/030] Train loss: 0.0345
2023-02-06 14:05:59 | Train | Epoch[119/600] Iteration[019/030] Train loss: 0.0346
2023-02-06 14:05:59 | Train | Epoch[119/600] Iteration[020/030] Train loss: 0.0345
2023-02-06 14:06:00 | Train | Epoch[119/600] Iteration[021/030] Train loss: 0.0345
2023-02-06 14:06:00 | Train | Epoch[119/600] Iteration[022/030] Train loss: 0.0345
2023-02-06 14:06:00 | Train | Epoch[119/600] Iteration[023/030] Train loss: 0.0345
2023-02-06 14:06:00 | Train | Epoch[119/600] Iteration[024/030] Train loss: 0.0346
2023-02-06 14:06:00 | Train | Epoch[119/600] Iteration[025/030] Train loss: 0.0346
2023-02-06 14:06:01 | Train | Epoch[119/600] Iteration[026/030] Train loss: 0.0347
2023-02-06 14:06:01 | Train | Epoch[119/600] Iteration[027/030] Train loss: 0.0347
2023-02-06 14:06:01 | Train | Epoch[119/600] Iteration[028/030] Train loss: 0.0347
2023-02-06 14:06:01 | Train | Epoch[119/600] Iteration[029/030] Train loss: 0.0348
2023-02-06 14:06:01 | Train | Epoch[119/600] Iteration[030/030] Train loss: 0.0348
2023-02-06 14:06:02 | Valid | Epoch[119/600] Iteration[001/008] Valid loss: 0.0843
2023-02-06 14:06:02 | Valid | Epoch[119/600] Iteration[002/008] Valid loss: 0.0814
2023-02-06 14:06:02 | Valid | Epoch[119/600] Iteration[003/008] Valid loss: 0.0831
2023-02-06 14:06:02 | Valid | Epoch[119/600] Iteration[004/008] Valid loss: 0.0840
2023-02-06 14:06:02 | Valid | Epoch[119/600] Iteration[005/008] Valid loss: 0.0875
2023-02-06 14:06:02 | Valid | Epoch[119/600] Iteration[006/008] Valid loss: 0.0861
2023-02-06 14:06:02 | Valid | Epoch[119/600] Iteration[007/008] Valid loss: 0.0882
2023-02-06 14:06:02 | Valid | Epoch[119/600] Iteration[008/008] Valid loss: 0.0862
2023-02-06 14:06:02 | Valid | Epoch[119/600] MIou: 0.8899564100807779
2023-02-06 14:06:02 | Valid | Epoch[119/600] Pixel Accuracy: 0.9811871846516927
2023-02-06 14:06:02 | Valid | Epoch[119/600] Mean Pixel Accuracy: 0.9151401126559275
2023-02-06 14:06:02 | Stage | Epoch[119/600] Train loss:0.0348
2023-02-06 14:06:02 | Stage | Epoch[119/600] Valid loss:0.0862
2023-02-06 14:06:02 | Stage | Epoch[119/600] LR:0.01

2023-02-06 14:06:03 | Train | Epoch[120/600] Iteration[001/030] Train loss: 0.0330
2023-02-06 14:06:03 | Train | Epoch[120/600] Iteration[002/030] Train loss: 0.0335
2023-02-06 14:06:03 | Train | Epoch[120/600] Iteration[003/030] Train loss: 0.0332
2023-02-06 14:06:03 | Train | Epoch[120/600] Iteration[004/030] Train loss: 0.0335
2023-02-06 14:06:04 | Train | Epoch[120/600] Iteration[005/030] Train loss: 0.0335
2023-02-06 14:06:04 | Train | Epoch[120/600] Iteration[006/030] Train loss: 0.0339
2023-02-06 14:06:04 | Train | Epoch[120/600] Iteration[007/030] Train loss: 0.0338
2023-02-06 14:06:04 | Train | Epoch[120/600] Iteration[008/030] Train loss: 0.0337
2023-02-06 14:06:05 | Train | Epoch[120/600] Iteration[009/030] Train loss: 0.0337
2023-02-06 14:06:05 | Train | Epoch[120/600] Iteration[010/030] Train loss: 0.0336
2023-02-06 14:06:05 | Train | Epoch[120/600] Iteration[011/030] Train loss: 0.0335
2023-02-06 14:06:05 | Train | Epoch[120/600] Iteration[012/030] Train loss: 0.0336
2023-02-06 14:06:05 | Train | Epoch[120/600] Iteration[013/030] Train loss: 0.0334
2023-02-06 14:06:06 | Train | Epoch[120/600] Iteration[014/030] Train loss: 0.0334
2023-02-06 14:06:06 | Train | Epoch[120/600] Iteration[015/030] Train loss: 0.0334
2023-02-06 14:06:06 | Train | Epoch[120/600] Iteration[016/030] Train loss: 0.0334
2023-02-06 14:06:06 | Train | Epoch[120/600] Iteration[017/030] Train loss: 0.0334
2023-02-06 14:06:06 | Train | Epoch[120/600] Iteration[018/030] Train loss: 0.0333
2023-02-06 14:06:07 | Train | Epoch[120/600] Iteration[019/030] Train loss: 0.0333
2023-02-06 14:06:07 | Train | Epoch[120/600] Iteration[020/030] Train loss: 0.0333
2023-02-06 14:06:07 | Train | Epoch[120/600] Iteration[021/030] Train loss: 0.0333
2023-02-06 14:06:07 | Train | Epoch[120/600] Iteration[022/030] Train loss: 0.0333
2023-02-06 14:06:08 | Train | Epoch[120/600] Iteration[023/030] Train loss: 0.0333
2023-02-06 14:06:08 | Train | Epoch[120/600] Iteration[024/030] Train loss: 0.0333
2023-02-06 14:06:08 | Train | Epoch[120/600] Iteration[025/030] Train loss: 0.0333
2023-02-06 14:06:08 | Train | Epoch[120/600] Iteration[026/030] Train loss: 0.0334
2023-02-06 14:06:08 | Train | Epoch[120/600] Iteration[027/030] Train loss: 0.0334
2023-02-06 14:06:09 | Train | Epoch[120/600] Iteration[028/030] Train loss: 0.0334
2023-02-06 14:06:09 | Train | Epoch[120/600] Iteration[029/030] Train loss: 0.0333
2023-02-06 14:06:09 | Train | Epoch[120/600] Iteration[030/030] Train loss: 0.0334
2023-02-06 14:06:09 | Valid | Epoch[120/600] Iteration[001/008] Valid loss: 0.0680
2023-02-06 14:06:09 | Valid | Epoch[120/600] Iteration[002/008] Valid loss: 0.0669
2023-02-06 14:06:09 | Valid | Epoch[120/600] Iteration[003/008] Valid loss: 0.0689
2023-02-06 14:06:10 | Valid | Epoch[120/600] Iteration[004/008] Valid loss: 0.0675
2023-02-06 14:06:10 | Valid | Epoch[120/600] Iteration[005/008] Valid loss: 0.0684
2023-02-06 14:06:10 | Valid | Epoch[120/600] Iteration[006/008] Valid loss: 0.0673
2023-02-06 14:06:10 | Valid | Epoch[120/600] Iteration[007/008] Valid loss: 0.0659
2023-02-06 14:06:10 | Valid | Epoch[120/600] Iteration[008/008] Valid loss: 0.0661
2023-02-06 14:06:10 | Valid | Epoch[120/600] MIou: 0.8547152871314286
2023-02-06 14:06:10 | Valid | Epoch[120/600] Pixel Accuracy: 0.9759788513183594
2023-02-06 14:06:10 | Valid | Epoch[120/600] Mean Pixel Accuracy: 0.8689402677408178
2023-02-06 14:06:10 | Stage | Epoch[120/600] Train loss:0.0334
2023-02-06 14:06:10 | Stage | Epoch[120/600] Valid loss:0.0661
2023-02-06 14:06:10 | Stage | Epoch[120/600] LR:0.01

2023-02-06 14:06:10 | Train | Epoch[121/600] Iteration[001/030] Train loss: 0.0344
2023-02-06 14:06:10 | Train | Epoch[121/600] Iteration[002/030] Train loss: 0.0329
2023-02-06 14:06:11 | Train | Epoch[121/600] Iteration[003/030] Train loss: 0.0329
2023-02-06 14:06:11 | Train | Epoch[121/600] Iteration[004/030] Train loss: 0.0332
2023-02-06 14:06:11 | Train | Epoch[121/600] Iteration[005/030] Train loss: 0.0333
2023-02-06 14:06:11 | Train | Epoch[121/600] Iteration[006/030] Train loss: 0.0336
2023-02-06 14:06:12 | Train | Epoch[121/600] Iteration[007/030] Train loss: 0.0335
2023-02-06 14:06:12 | Train | Epoch[121/600] Iteration[008/030] Train loss: 0.0333
2023-02-06 14:06:12 | Train | Epoch[121/600] Iteration[009/030] Train loss: 0.0332
2023-02-06 14:06:12 | Train | Epoch[121/600] Iteration[010/030] Train loss: 0.0332
2023-02-06 14:06:12 | Train | Epoch[121/600] Iteration[011/030] Train loss: 0.0334
2023-02-06 14:06:13 | Train | Epoch[121/600] Iteration[012/030] Train loss: 0.0332
2023-02-06 14:06:13 | Train | Epoch[121/600] Iteration[013/030] Train loss: 0.0332
2023-02-06 14:06:13 | Train | Epoch[121/600] Iteration[014/030] Train loss: 0.0331
2023-02-06 14:06:13 | Train | Epoch[121/600] Iteration[015/030] Train loss: 0.0332
2023-02-06 14:06:14 | Train | Epoch[121/600] Iteration[016/030] Train loss: 0.0331
2023-02-06 14:06:14 | Train | Epoch[121/600] Iteration[017/030] Train loss: 0.0331
2023-02-06 14:06:14 | Train | Epoch[121/600] Iteration[018/030] Train loss: 0.0331
2023-02-06 14:06:14 | Train | Epoch[121/600] Iteration[019/030] Train loss: 0.0331
2023-02-06 14:06:14 | Train | Epoch[121/600] Iteration[020/030] Train loss: 0.0331
2023-02-06 14:06:15 | Train | Epoch[121/600] Iteration[021/030] Train loss: 0.0332
2023-02-06 14:06:15 | Train | Epoch[121/600] Iteration[022/030] Train loss: 0.0331
2023-02-06 14:06:15 | Train | Epoch[121/600] Iteration[023/030] Train loss: 0.0331
2023-02-06 14:06:15 | Train | Epoch[121/600] Iteration[024/030] Train loss: 0.0331
2023-02-06 14:06:16 | Train | Epoch[121/600] Iteration[025/030] Train loss: 0.0332
2023-02-06 14:06:16 | Train | Epoch[121/600] Iteration[026/030] Train loss: 0.0332
2023-02-06 14:06:16 | Train | Epoch[121/600] Iteration[027/030] Train loss: 0.0332
2023-02-06 14:06:16 | Train | Epoch[121/600] Iteration[028/030] Train loss: 0.0332
2023-02-06 14:06:16 | Train | Epoch[121/600] Iteration[029/030] Train loss: 0.0332
2023-02-06 14:06:17 | Train | Epoch[121/600] Iteration[030/030] Train loss: 0.0332
2023-02-06 14:06:17 | Valid | Epoch[121/600] Iteration[001/008] Valid loss: 0.1054
2023-02-06 14:06:17 | Valid | Epoch[121/600] Iteration[002/008] Valid loss: 0.1079
2023-02-06 14:06:17 | Valid | Epoch[121/600] Iteration[003/008] Valid loss: 0.1139
2023-02-06 14:06:17 | Valid | Epoch[121/600] Iteration[004/008] Valid loss: 0.1117
2023-02-06 14:06:17 | Valid | Epoch[121/600] Iteration[005/008] Valid loss: 0.1138
2023-02-06 14:06:17 | Valid | Epoch[121/600] Iteration[006/008] Valid loss: 0.1108
2023-02-06 14:06:17 | Valid | Epoch[121/600] Iteration[007/008] Valid loss: 0.1067
2023-02-06 14:06:17 | Valid | Epoch[121/600] Iteration[008/008] Valid loss: 0.1113
2023-02-06 14:06:17 | Valid | Epoch[121/600] MIou: 0.660163342830174
2023-02-06 14:06:17 | Valid | Epoch[121/600] Pixel Accuracy: 0.9438578287760416
2023-02-06 14:06:17 | Valid | Epoch[121/600] Mean Pixel Accuracy: 0.6892417533888584
2023-02-06 14:06:17 | Stage | Epoch[121/600] Train loss:0.0332
2023-02-06 14:06:17 | Stage | Epoch[121/600] Valid loss:0.1113
2023-02-06 14:06:17 | Stage | Epoch[121/600] LR:0.01

2023-02-06 14:06:18 | Train | Epoch[122/600] Iteration[001/030] Train loss: 0.0331
2023-02-06 14:06:18 | Train | Epoch[122/600] Iteration[002/030] Train loss: 0.0328
2023-02-06 14:06:18 | Train | Epoch[122/600] Iteration[003/030] Train loss: 0.0328
2023-02-06 14:06:18 | Train | Epoch[122/600] Iteration[004/030] Train loss: 0.0329
2023-02-06 14:06:19 | Train | Epoch[122/600] Iteration[005/030] Train loss: 0.0330
2023-02-06 14:06:19 | Train | Epoch[122/600] Iteration[006/030] Train loss: 0.0336
2023-02-06 14:06:19 | Train | Epoch[122/600] Iteration[007/030] Train loss: 0.0333
2023-02-06 14:06:19 | Train | Epoch[122/600] Iteration[008/030] Train loss: 0.0335
2023-02-06 14:06:20 | Train | Epoch[122/600] Iteration[009/030] Train loss: 0.0332
2023-02-06 14:06:20 | Train | Epoch[122/600] Iteration[010/030] Train loss: 0.0332
2023-02-06 14:06:20 | Train | Epoch[122/600] Iteration[011/030] Train loss: 0.0332
2023-02-06 14:06:20 | Train | Epoch[122/600] Iteration[012/030] Train loss: 0.0332
2023-02-06 14:06:20 | Train | Epoch[122/600] Iteration[013/030] Train loss: 0.0332
2023-02-06 14:06:21 | Train | Epoch[122/600] Iteration[014/030] Train loss: 0.0330
2023-02-06 14:06:21 | Train | Epoch[122/600] Iteration[015/030] Train loss: 0.0330
2023-02-06 14:06:21 | Train | Epoch[122/600] Iteration[016/030] Train loss: 0.0330
2023-02-06 14:06:21 | Train | Epoch[122/600] Iteration[017/030] Train loss: 0.0329
2023-02-06 14:06:22 | Train | Epoch[122/600] Iteration[018/030] Train loss: 0.0329
2023-02-06 14:06:22 | Train | Epoch[122/600] Iteration[019/030] Train loss: 0.0330
2023-02-06 14:06:22 | Train | Epoch[122/600] Iteration[020/030] Train loss: 0.0329
2023-02-06 14:06:22 | Train | Epoch[122/600] Iteration[021/030] Train loss: 0.0330
2023-02-06 14:06:22 | Train | Epoch[122/600] Iteration[022/030] Train loss: 0.0330
2023-02-06 14:06:23 | Train | Epoch[122/600] Iteration[023/030] Train loss: 0.0331
2023-02-06 14:06:23 | Train | Epoch[122/600] Iteration[024/030] Train loss: 0.0332
2023-02-06 14:06:23 | Train | Epoch[122/600] Iteration[025/030] Train loss: 0.0332
2023-02-06 14:06:23 | Train | Epoch[122/600] Iteration[026/030] Train loss: 0.0331
2023-02-06 14:06:24 | Train | Epoch[122/600] Iteration[027/030] Train loss: 0.0331
2023-02-06 14:06:24 | Train | Epoch[122/600] Iteration[028/030] Train loss: 0.0330
2023-02-06 14:06:24 | Train | Epoch[122/600] Iteration[029/030] Train loss: 0.0331
2023-02-06 14:06:24 | Train | Epoch[122/600] Iteration[030/030] Train loss: 0.0331
2023-02-06 14:06:24 | Valid | Epoch[122/600] Iteration[001/008] Valid loss: 0.5082
2023-02-06 14:06:24 | Valid | Epoch[122/600] Iteration[002/008] Valid loss: 0.4382
2023-02-06 14:06:25 | Valid | Epoch[122/600] Iteration[003/008] Valid loss: 0.4391
2023-02-06 14:06:25 | Valid | Epoch[122/600] Iteration[004/008] Valid loss: 0.4359
2023-02-06 14:06:25 | Valid | Epoch[122/600] Iteration[005/008] Valid loss: 0.4506
2023-02-06 14:06:25 | Valid | Epoch[122/600] Iteration[006/008] Valid loss: 0.4361
2023-02-06 14:06:25 | Valid | Epoch[122/600] Iteration[007/008] Valid loss: 0.4743
2023-02-06 14:06:25 | Valid | Epoch[122/600] Iteration[008/008] Valid loss: 0.4834
2023-02-06 14:06:25 | Valid | Epoch[122/600] MIou: 0.8836566718118659
2023-02-06 14:06:25 | Valid | Epoch[122/600] Pixel Accuracy: 0.9768091837565104
2023-02-06 14:06:25 | Valid | Epoch[122/600] Mean Pixel Accuracy: 0.9792516632799424
2023-02-06 14:06:25 | Stage | Epoch[122/600] Train loss:0.0331
2023-02-06 14:06:25 | Stage | Epoch[122/600] Valid loss:0.4834
2023-02-06 14:06:25 | Stage | Epoch[122/600] LR:0.01

2023-02-06 14:06:25 | Train | Epoch[123/600] Iteration[001/030] Train loss: 0.0338
2023-02-06 14:06:26 | Train | Epoch[123/600] Iteration[002/030] Train loss: 0.0325
2023-02-06 14:06:26 | Train | Epoch[123/600] Iteration[003/030] Train loss: 0.0322
2023-02-06 14:06:26 | Train | Epoch[123/600] Iteration[004/030] Train loss: 0.0322
2023-02-06 14:06:26 | Train | Epoch[123/600] Iteration[005/030] Train loss: 0.0326
2023-02-06 14:06:26 | Train | Epoch[123/600] Iteration[006/030] Train loss: 0.0324
2023-02-06 14:06:27 | Train | Epoch[123/600] Iteration[007/030] Train loss: 0.0326
2023-02-06 14:06:27 | Train | Epoch[123/600] Iteration[008/030] Train loss: 0.0326
2023-02-06 14:06:27 | Train | Epoch[123/600] Iteration[009/030] Train loss: 0.0325
2023-02-06 14:06:27 | Train | Epoch[123/600] Iteration[010/030] Train loss: 0.0326
2023-02-06 14:06:28 | Train | Epoch[123/600] Iteration[011/030] Train loss: 0.0326
2023-02-06 14:06:28 | Train | Epoch[123/600] Iteration[012/030] Train loss: 0.0324
2023-02-06 14:06:28 | Train | Epoch[123/600] Iteration[013/030] Train loss: 0.0326
2023-02-06 14:06:28 | Train | Epoch[123/600] Iteration[014/030] Train loss: 0.0331
2023-02-06 14:06:28 | Train | Epoch[123/600] Iteration[015/030] Train loss: 0.0330
2023-02-06 14:06:29 | Train | Epoch[123/600] Iteration[016/030] Train loss: 0.0330
2023-02-06 14:06:29 | Train | Epoch[123/600] Iteration[017/030] Train loss: 0.0330
2023-02-06 14:06:29 | Train | Epoch[123/600] Iteration[018/030] Train loss: 0.0329
2023-02-06 14:06:29 | Train | Epoch[123/600] Iteration[019/030] Train loss: 0.0329
2023-02-06 14:06:29 | Train | Epoch[123/600] Iteration[020/030] Train loss: 0.0329
2023-02-06 14:06:30 | Train | Epoch[123/600] Iteration[021/030] Train loss: 0.0331
2023-02-06 14:06:30 | Train | Epoch[123/600] Iteration[022/030] Train loss: 0.0331
2023-02-06 14:06:30 | Train | Epoch[123/600] Iteration[023/030] Train loss: 0.0332
2023-02-06 14:06:30 | Train | Epoch[123/600] Iteration[024/030] Train loss: 0.0332
2023-02-06 14:06:31 | Train | Epoch[123/600] Iteration[025/030] Train loss: 0.0332
2023-02-06 14:06:31 | Train | Epoch[123/600] Iteration[026/030] Train loss: 0.0332
2023-02-06 14:06:31 | Train | Epoch[123/600] Iteration[027/030] Train loss: 0.0332
2023-02-06 14:06:31 | Train | Epoch[123/600] Iteration[028/030] Train loss: 0.0332
2023-02-06 14:06:31 | Train | Epoch[123/600] Iteration[029/030] Train loss: 0.0332
2023-02-06 14:06:32 | Train | Epoch[123/600] Iteration[030/030] Train loss: 0.0332
2023-02-06 14:06:32 | Valid | Epoch[123/600] Iteration[001/008] Valid loss: 0.8994
2023-02-06 14:06:32 | Valid | Epoch[123/600] Iteration[002/008] Valid loss: 0.8938
2023-02-06 14:06:32 | Valid | Epoch[123/600] Iteration[003/008] Valid loss: 0.9239
2023-02-06 14:06:32 | Valid | Epoch[123/600] Iteration[004/008] Valid loss: 0.9286
2023-02-06 14:06:32 | Valid | Epoch[123/600] Iteration[005/008] Valid loss: 0.9530
2023-02-06 14:06:32 | Valid | Epoch[123/600] Iteration[006/008] Valid loss: 0.9281
2023-02-06 14:06:32 | Valid | Epoch[123/600] Iteration[007/008] Valid loss: 0.9826
2023-02-06 14:06:32 | Valid | Epoch[123/600] Iteration[008/008] Valid loss: 1.0173
2023-02-06 14:06:32 | Valid | Epoch[123/600] MIou: 0.8485444102642268
2023-02-06 14:06:32 | Valid | Epoch[123/600] Pixel Accuracy: 0.9672902425130209
2023-02-06 14:06:32 | Valid | Epoch[123/600] Mean Pixel Accuracy: 0.9794914741144203
2023-02-06 14:06:32 | Stage | Epoch[123/600] Train loss:0.0332
2023-02-06 14:06:32 | Stage | Epoch[123/600] Valid loss:1.0173
2023-02-06 14:06:32 | Stage | Epoch[123/600] LR:0.01

2023-02-06 14:06:33 | Train | Epoch[124/600] Iteration[001/030] Train loss: 0.0332
2023-02-06 14:06:33 | Train | Epoch[124/600] Iteration[002/030] Train loss: 0.0330
2023-02-06 14:06:33 | Train | Epoch[124/600] Iteration[003/030] Train loss: 0.0330
2023-02-06 14:06:34 | Train | Epoch[124/600] Iteration[004/030] Train loss: 0.0333
2023-02-06 14:06:34 | Train | Epoch[124/600] Iteration[005/030] Train loss: 0.0330
2023-02-06 14:06:34 | Train | Epoch[124/600] Iteration[006/030] Train loss: 0.0332
2023-02-06 14:06:34 | Train | Epoch[124/600] Iteration[007/030] Train loss: 0.0331
2023-02-06 14:06:34 | Train | Epoch[124/600] Iteration[008/030] Train loss: 0.0329
2023-02-06 14:06:35 | Train | Epoch[124/600] Iteration[009/030] Train loss: 0.0329
2023-02-06 14:06:35 | Train | Epoch[124/600] Iteration[010/030] Train loss: 0.0328
2023-02-06 14:06:35 | Train | Epoch[124/600] Iteration[011/030] Train loss: 0.0328
2023-02-06 14:06:35 | Train | Epoch[124/600] Iteration[012/030] Train loss: 0.0327
2023-02-06 14:06:35 | Train | Epoch[124/600] Iteration[013/030] Train loss: 0.0327
2023-02-06 14:06:36 | Train | Epoch[124/600] Iteration[014/030] Train loss: 0.0327
2023-02-06 14:06:36 | Train | Epoch[124/600] Iteration[015/030] Train loss: 0.0326
2023-02-06 14:06:36 | Train | Epoch[124/600] Iteration[016/030] Train loss: 0.0325
2023-02-06 14:06:36 | Train | Epoch[124/600] Iteration[017/030] Train loss: 0.0324
2023-02-06 14:06:37 | Train | Epoch[124/600] Iteration[018/030] Train loss: 0.0324
2023-02-06 14:06:37 | Train | Epoch[124/600] Iteration[019/030] Train loss: 0.0323
2023-02-06 14:06:37 | Train | Epoch[124/600] Iteration[020/030] Train loss: 0.0323
2023-02-06 14:06:37 | Train | Epoch[124/600] Iteration[021/030] Train loss: 0.0322
2023-02-06 14:06:37 | Train | Epoch[124/600] Iteration[022/030] Train loss: 0.0322
2023-02-06 14:06:38 | Train | Epoch[124/600] Iteration[023/030] Train loss: 0.0322
2023-02-06 14:06:38 | Train | Epoch[124/600] Iteration[024/030] Train loss: 0.0322
2023-02-06 14:06:38 | Train | Epoch[124/600] Iteration[025/030] Train loss: 0.0322
2023-02-06 14:06:38 | Train | Epoch[124/600] Iteration[026/030] Train loss: 0.0322
2023-02-06 14:06:39 | Train | Epoch[124/600] Iteration[027/030] Train loss: 0.0322
2023-02-06 14:06:39 | Train | Epoch[124/600] Iteration[028/030] Train loss: 0.0322
2023-02-06 14:06:39 | Train | Epoch[124/600] Iteration[029/030] Train loss: 0.0323
2023-02-06 14:06:39 | Train | Epoch[124/600] Iteration[030/030] Train loss: 0.0323
2023-02-06 14:06:39 | Valid | Epoch[124/600] Iteration[001/008] Valid loss: 0.8428
2023-02-06 14:06:40 | Valid | Epoch[124/600] Iteration[002/008] Valid loss: 0.7922
2023-02-06 14:06:40 | Valid | Epoch[124/600] Iteration[003/008] Valid loss: 0.8196
2023-02-06 14:06:40 | Valid | Epoch[124/600] Iteration[004/008] Valid loss: 0.8116
2023-02-06 14:06:40 | Valid | Epoch[124/600] Iteration[005/008] Valid loss: 0.8351
2023-02-06 14:06:40 | Valid | Epoch[124/600] Iteration[006/008] Valid loss: 0.8233
2023-02-06 14:06:40 | Valid | Epoch[124/600] Iteration[007/008] Valid loss: 0.8729
2023-02-06 14:06:40 | Valid | Epoch[124/600] Iteration[008/008] Valid loss: 0.9025
2023-02-06 14:06:40 | Valid | Epoch[124/600] MIou: 0.8455105162026217
2023-02-06 14:06:40 | Valid | Epoch[124/600] Pixel Accuracy: 0.9664471944173177
2023-02-06 14:06:40 | Valid | Epoch[124/600] Mean Pixel Accuracy: 0.9787237562933103
2023-02-06 14:06:40 | Stage | Epoch[124/600] Train loss:0.0323
2023-02-06 14:06:40 | Stage | Epoch[124/600] Valid loss:0.9025
2023-02-06 14:06:40 | Stage | Epoch[124/600] LR:0.01

2023-02-06 14:06:40 | Train | Epoch[125/600] Iteration[001/030] Train loss: 0.0308
2023-02-06 14:06:41 | Train | Epoch[125/600] Iteration[002/030] Train loss: 0.0314
2023-02-06 14:06:41 | Train | Epoch[125/600] Iteration[003/030] Train loss: 0.0315
2023-02-06 14:06:41 | Train | Epoch[125/600] Iteration[004/030] Train loss: 0.0313
2023-02-06 14:06:41 | Train | Epoch[125/600] Iteration[005/030] Train loss: 0.0316
2023-02-06 14:06:41 | Train | Epoch[125/600] Iteration[006/030] Train loss: 0.0317
2023-02-06 14:06:42 | Train | Epoch[125/600] Iteration[007/030] Train loss: 0.0314
2023-02-06 14:06:42 | Train | Epoch[125/600] Iteration[008/030] Train loss: 0.0313
2023-02-06 14:06:42 | Train | Epoch[125/600] Iteration[009/030] Train loss: 0.0314
2023-02-06 14:06:42 | Train | Epoch[125/600] Iteration[010/030] Train loss: 0.0312
2023-02-06 14:06:43 | Train | Epoch[125/600] Iteration[011/030] Train loss: 0.0311
2023-02-06 14:06:43 | Train | Epoch[125/600] Iteration[012/030] Train loss: 0.0312
2023-02-06 14:06:43 | Train | Epoch[125/600] Iteration[013/030] Train loss: 0.0313
2023-02-06 14:06:43 | Train | Epoch[125/600] Iteration[014/030] Train loss: 0.0313
2023-02-06 14:06:43 | Train | Epoch[125/600] Iteration[015/030] Train loss: 0.0313
2023-02-06 14:06:44 | Train | Epoch[125/600] Iteration[016/030] Train loss: 0.0314
2023-02-06 14:06:44 | Train | Epoch[125/600] Iteration[017/030] Train loss: 0.0316
2023-02-06 14:06:44 | Train | Epoch[125/600] Iteration[018/030] Train loss: 0.0316
2023-02-06 14:06:44 | Train | Epoch[125/600] Iteration[019/030] Train loss: 0.0316
2023-02-06 14:06:45 | Train | Epoch[125/600] Iteration[020/030] Train loss: 0.0317
2023-02-06 14:06:45 | Train | Epoch[125/600] Iteration[021/030] Train loss: 0.0316
2023-02-06 14:06:45 | Train | Epoch[125/600] Iteration[022/030] Train loss: 0.0316
2023-02-06 14:06:45 | Train | Epoch[125/600] Iteration[023/030] Train loss: 0.0316
2023-02-06 14:06:45 | Train | Epoch[125/600] Iteration[024/030] Train loss: 0.0316
2023-02-06 14:06:46 | Train | Epoch[125/600] Iteration[025/030] Train loss: 0.0316
2023-02-06 14:06:46 | Train | Epoch[125/600] Iteration[026/030] Train loss: 0.0315
2023-02-06 14:06:46 | Train | Epoch[125/600] Iteration[027/030] Train loss: 0.0315
2023-02-06 14:06:46 | Train | Epoch[125/600] Iteration[028/030] Train loss: 0.0315
2023-02-06 14:06:47 | Train | Epoch[125/600] Iteration[029/030] Train loss: 0.0315
2023-02-06 14:06:47 | Train | Epoch[125/600] Iteration[030/030] Train loss: 0.0316
2023-02-06 14:06:47 | Valid | Epoch[125/600] Iteration[001/008] Valid loss: 0.1199
2023-02-06 14:06:47 | Valid | Epoch[125/600] Iteration[002/008] Valid loss: 0.0980
2023-02-06 14:06:47 | Valid | Epoch[125/600] Iteration[003/008] Valid loss: 0.1081
2023-02-06 14:06:47 | Valid | Epoch[125/600] Iteration[004/008] Valid loss: 0.1050
2023-02-06 14:06:47 | Valid | Epoch[125/600] Iteration[005/008] Valid loss: 0.1095
2023-02-06 14:06:47 | Valid | Epoch[125/600] Iteration[006/008] Valid loss: 0.1069
2023-02-06 14:06:47 | Valid | Epoch[125/600] Iteration[007/008] Valid loss: 0.1104
2023-02-06 14:06:47 | Valid | Epoch[125/600] Iteration[008/008] Valid loss: 0.1085
2023-02-06 14:06:47 | Valid | Epoch[125/600] MIou: 0.8972677507304336
2023-02-06 14:06:47 | Valid | Epoch[125/600] Pixel Accuracy: 0.9821955362955729
2023-02-06 14:06:47 | Valid | Epoch[125/600] Mean Pixel Accuracy: 0.9279821795149722
2023-02-06 14:06:47 | Stage | Epoch[125/600] Train loss:0.0316
2023-02-06 14:06:47 | Stage | Epoch[125/600] Valid loss:0.1085
2023-02-06 14:06:47 | Stage | Epoch[125/600] LR:0.01

2023-02-06 14:06:48 | Train | Epoch[126/600] Iteration[001/030] Train loss: 0.0333
2023-02-06 14:06:48 | Train | Epoch[126/600] Iteration[002/030] Train loss: 0.0329
2023-02-06 14:06:48 | Train | Epoch[126/600] Iteration[003/030] Train loss: 0.0320
2023-02-06 14:06:49 | Train | Epoch[126/600] Iteration[004/030] Train loss: 0.0318
2023-02-06 14:06:49 | Train | Epoch[126/600] Iteration[005/030] Train loss: 0.0315
2023-02-06 14:06:49 | Train | Epoch[126/600] Iteration[006/030] Train loss: 0.0316
2023-02-06 14:06:49 | Train | Epoch[126/600] Iteration[007/030] Train loss: 0.0315
2023-02-06 14:06:49 | Train | Epoch[126/600] Iteration[008/030] Train loss: 0.0314
2023-02-06 14:06:50 | Train | Epoch[126/600] Iteration[009/030] Train loss: 0.0315
2023-02-06 14:06:50 | Train | Epoch[126/600] Iteration[010/030] Train loss: 0.0320
2023-02-06 14:06:50 | Train | Epoch[126/600] Iteration[011/030] Train loss: 0.0319
2023-02-06 14:06:50 | Train | Epoch[126/600] Iteration[012/030] Train loss: 0.0318
2023-02-06 14:06:51 | Train | Epoch[126/600] Iteration[013/030] Train loss: 0.0317
2023-02-06 14:06:51 | Train | Epoch[126/600] Iteration[014/030] Train loss: 0.0316
2023-02-06 14:06:51 | Train | Epoch[126/600] Iteration[015/030] Train loss: 0.0316
2023-02-06 14:06:51 | Train | Epoch[126/600] Iteration[016/030] Train loss: 0.0315
2023-02-06 14:06:51 | Train | Epoch[126/600] Iteration[017/030] Train loss: 0.0315
2023-02-06 14:06:52 | Train | Epoch[126/600] Iteration[018/030] Train loss: 0.0317
2023-02-06 14:06:52 | Train | Epoch[126/600] Iteration[019/030] Train loss: 0.0317
2023-02-06 14:06:52 | Train | Epoch[126/600] Iteration[020/030] Train loss: 0.0317
2023-02-06 14:06:52 | Train | Epoch[126/600] Iteration[021/030] Train loss: 0.0316
2023-02-06 14:06:53 | Train | Epoch[126/600] Iteration[022/030] Train loss: 0.0316
2023-02-06 14:06:53 | Train | Epoch[126/600] Iteration[023/030] Train loss: 0.0316
2023-02-06 14:06:53 | Train | Epoch[126/600] Iteration[024/030] Train loss: 0.0317
2023-02-06 14:06:53 | Train | Epoch[126/600] Iteration[025/030] Train loss: 0.0317
2023-02-06 14:06:53 | Train | Epoch[126/600] Iteration[026/030] Train loss: 0.0317
2023-02-06 14:06:54 | Train | Epoch[126/600] Iteration[027/030] Train loss: 0.0318
2023-02-06 14:06:54 | Train | Epoch[126/600] Iteration[028/030] Train loss: 0.0317
2023-02-06 14:06:54 | Train | Epoch[126/600] Iteration[029/030] Train loss: 0.0317
2023-02-06 14:06:54 | Train | Epoch[126/600] Iteration[030/030] Train loss: 0.0317
2023-02-06 14:06:55 | Valid | Epoch[126/600] Iteration[001/008] Valid loss: 0.0820
2023-02-06 14:06:55 | Valid | Epoch[126/600] Iteration[002/008] Valid loss: 0.0754
2023-02-06 14:06:55 | Valid | Epoch[126/600] Iteration[003/008] Valid loss: 0.0731
2023-02-06 14:06:55 | Valid | Epoch[126/600] Iteration[004/008] Valid loss: 0.0691
2023-02-06 14:06:55 | Valid | Epoch[126/600] Iteration[005/008] Valid loss: 0.0677
2023-02-06 14:06:55 | Valid | Epoch[126/600] Iteration[006/008] Valid loss: 0.0653
2023-02-06 14:06:55 | Valid | Epoch[126/600] Iteration[007/008] Valid loss: 0.0658
2023-02-06 14:06:55 | Valid | Epoch[126/600] Iteration[008/008] Valid loss: 0.0663
2023-02-06 14:06:55 | Valid | Epoch[126/600] MIou: 0.9134918424019041
2023-02-06 14:06:55 | Valid | Epoch[126/600] Pixel Accuracy: 0.9849637349446615
2023-02-06 14:06:55 | Valid | Epoch[126/600] Mean Pixel Accuracy: 0.9450061524003633
2023-02-06 14:06:55 | Stage | Epoch[126/600] Train loss:0.0317
2023-02-06 14:06:55 | Stage | Epoch[126/600] Valid loss:0.0663
2023-02-06 14:06:55 | Stage | Epoch[126/600] LR:0.01

2023-02-06 14:06:55 | Train | Epoch[127/600] Iteration[001/030] Train loss: 0.0297
2023-02-06 14:06:56 | Train | Epoch[127/600] Iteration[002/030] Train loss: 0.0310
2023-02-06 14:06:56 | Train | Epoch[127/600] Iteration[003/030] Train loss: 0.0312
2023-02-06 14:06:56 | Train | Epoch[127/600] Iteration[004/030] Train loss: 0.0314
2023-02-06 14:06:56 | Train | Epoch[127/600] Iteration[005/030] Train loss: 0.0310
2023-02-06 14:06:56 | Train | Epoch[127/600] Iteration[006/030] Train loss: 0.0310
2023-02-06 14:06:57 | Train | Epoch[127/600] Iteration[007/030] Train loss: 0.0310
2023-02-06 14:06:57 | Train | Epoch[127/600] Iteration[008/030] Train loss: 0.0313
2023-02-06 14:06:57 | Train | Epoch[127/600] Iteration[009/030] Train loss: 0.0312
2023-02-06 14:06:57 | Train | Epoch[127/600] Iteration[010/030] Train loss: 0.0310
2023-02-06 14:06:58 | Train | Epoch[127/600] Iteration[011/030] Train loss: 0.0310
2023-02-06 14:06:58 | Train | Epoch[127/600] Iteration[012/030] Train loss: 0.0308
2023-02-06 14:06:58 | Train | Epoch[127/600] Iteration[013/030] Train loss: 0.0308
2023-02-06 14:06:58 | Train | Epoch[127/600] Iteration[014/030] Train loss: 0.0308
2023-02-06 14:06:58 | Train | Epoch[127/600] Iteration[015/030] Train loss: 0.0307
2023-02-06 14:06:59 | Train | Epoch[127/600] Iteration[016/030] Train loss: 0.0308
2023-02-06 14:06:59 | Train | Epoch[127/600] Iteration[017/030] Train loss: 0.0308
2023-02-06 14:06:59 | Train | Epoch[127/600] Iteration[018/030] Train loss: 0.0308
2023-02-06 14:06:59 | Train | Epoch[127/600] Iteration[019/030] Train loss: 0.0308
2023-02-06 14:07:00 | Train | Epoch[127/600] Iteration[020/030] Train loss: 0.0307
2023-02-06 14:07:00 | Train | Epoch[127/600] Iteration[021/030] Train loss: 0.0308
2023-02-06 14:07:00 | Train | Epoch[127/600] Iteration[022/030] Train loss: 0.0307
2023-02-06 14:07:00 | Train | Epoch[127/600] Iteration[023/030] Train loss: 0.0308
2023-02-06 14:07:00 | Train | Epoch[127/600] Iteration[024/030] Train loss: 0.0307
2023-02-06 14:07:01 | Train | Epoch[127/600] Iteration[025/030] Train loss: 0.0307
2023-02-06 14:07:01 | Train | Epoch[127/600] Iteration[026/030] Train loss: 0.0306
2023-02-06 14:07:01 | Train | Epoch[127/600] Iteration[027/030] Train loss: 0.0307
2023-02-06 14:07:01 | Train | Epoch[127/600] Iteration[028/030] Train loss: 0.0307
2023-02-06 14:07:02 | Train | Epoch[127/600] Iteration[029/030] Train loss: 0.0308
2023-02-06 14:07:02 | Train | Epoch[127/600] Iteration[030/030] Train loss: 0.0308
2023-02-06 14:07:02 | Valid | Epoch[127/600] Iteration[001/008] Valid loss: 0.6798
2023-02-06 14:07:02 | Valid | Epoch[127/600] Iteration[002/008] Valid loss: 0.6679
2023-02-06 14:07:02 | Valid | Epoch[127/600] Iteration[003/008] Valid loss: 0.6794
2023-02-06 14:07:02 | Valid | Epoch[127/600] Iteration[004/008] Valid loss: 0.6811
2023-02-06 14:07:02 | Valid | Epoch[127/600] Iteration[005/008] Valid loss: 0.7017
2023-02-06 14:07:02 | Valid | Epoch[127/600] Iteration[006/008] Valid loss: 0.6760
2023-02-06 14:07:02 | Valid | Epoch[127/600] Iteration[007/008] Valid loss: 0.7160
2023-02-06 14:07:02 | Valid | Epoch[127/600] Iteration[008/008] Valid loss: 0.7440
2023-02-06 14:07:02 | Valid | Epoch[127/600] MIou: 0.8690312784645244
2023-02-06 14:07:02 | Valid | Epoch[127/600] Pixel Accuracy: 0.9729843139648438
2023-02-06 14:07:02 | Valid | Epoch[127/600] Mean Pixel Accuracy: 0.9800469471967116
2023-02-06 14:07:02 | Stage | Epoch[127/600] Train loss:0.0308
2023-02-06 14:07:02 | Stage | Epoch[127/600] Valid loss:0.7440
2023-02-06 14:07:02 | Stage | Epoch[127/600] LR:0.01

2023-02-06 14:07:03 | Train | Epoch[128/600] Iteration[001/030] Train loss: 0.0335
2023-02-06 14:07:03 | Train | Epoch[128/600] Iteration[002/030] Train loss: 0.0319
2023-02-06 14:07:03 | Train | Epoch[128/600] Iteration[003/030] Train loss: 0.0325
2023-02-06 14:07:04 | Train | Epoch[128/600] Iteration[004/030] Train loss: 0.0318
2023-02-06 14:07:04 | Train | Epoch[128/600] Iteration[005/030] Train loss: 0.0313
2023-02-06 14:07:04 | Train | Epoch[128/600] Iteration[006/030] Train loss: 0.0314
2023-02-06 14:07:04 | Train | Epoch[128/600] Iteration[007/030] Train loss: 0.0310
2023-02-06 14:07:05 | Train | Epoch[128/600] Iteration[008/030] Train loss: 0.0311
2023-02-06 14:07:05 | Train | Epoch[128/600] Iteration[009/030] Train loss: 0.0310
2023-02-06 14:07:05 | Train | Epoch[128/600] Iteration[010/030] Train loss: 0.0310
2023-02-06 14:07:05 | Train | Epoch[128/600] Iteration[011/030] Train loss: 0.0311
2023-02-06 14:07:05 | Train | Epoch[128/600] Iteration[012/030] Train loss: 0.0310
2023-02-06 14:07:06 | Train | Epoch[128/600] Iteration[013/030] Train loss: 0.0311
2023-02-06 14:07:06 | Train | Epoch[128/600] Iteration[014/030] Train loss: 0.0310
2023-02-06 14:07:06 | Train | Epoch[128/600] Iteration[015/030] Train loss: 0.0309
2023-02-06 14:07:06 | Train | Epoch[128/600] Iteration[016/030] Train loss: 0.0308
2023-02-06 14:07:06 | Train | Epoch[128/600] Iteration[017/030] Train loss: 0.0307
2023-02-06 14:07:07 | Train | Epoch[128/600] Iteration[018/030] Train loss: 0.0307
2023-02-06 14:07:07 | Train | Epoch[128/600] Iteration[019/030] Train loss: 0.0306
2023-02-06 14:07:07 | Train | Epoch[128/600] Iteration[020/030] Train loss: 0.0306
2023-02-06 14:07:07 | Train | Epoch[128/600] Iteration[021/030] Train loss: 0.0306
2023-02-06 14:07:08 | Train | Epoch[128/600] Iteration[022/030] Train loss: 0.0305
2023-02-06 14:07:08 | Train | Epoch[128/600] Iteration[023/030] Train loss: 0.0305
2023-02-06 14:07:08 | Train | Epoch[128/600] Iteration[024/030] Train loss: 0.0307
2023-02-06 14:07:08 | Train | Epoch[128/600] Iteration[025/030] Train loss: 0.0307
2023-02-06 14:07:08 | Train | Epoch[128/600] Iteration[026/030] Train loss: 0.0307
2023-02-06 14:07:09 | Train | Epoch[128/600] Iteration[027/030] Train loss: 0.0306
2023-02-06 14:07:09 | Train | Epoch[128/600] Iteration[028/030] Train loss: 0.0306
2023-02-06 14:07:09 | Train | Epoch[128/600] Iteration[029/030] Train loss: 0.0306
2023-02-06 14:07:09 | Train | Epoch[128/600] Iteration[030/030] Train loss: 0.0307
2023-02-06 14:07:10 | Valid | Epoch[128/600] Iteration[001/008] Valid loss: 0.2395
2023-02-06 14:07:10 | Valid | Epoch[128/600] Iteration[002/008] Valid loss: 0.1753
2023-02-06 14:07:10 | Valid | Epoch[128/600] Iteration[003/008] Valid loss: 0.1649
2023-02-06 14:07:10 | Valid | Epoch[128/600] Iteration[004/008] Valid loss: 0.1662
2023-02-06 14:07:10 | Valid | Epoch[128/600] Iteration[005/008] Valid loss: 0.1709
2023-02-06 14:07:10 | Valid | Epoch[128/600] Iteration[006/008] Valid loss: 0.1622
2023-02-06 14:07:10 | Valid | Epoch[128/600] Iteration[007/008] Valid loss: 0.1746
2023-02-06 14:07:10 | Valid | Epoch[128/600] Iteration[008/008] Valid loss: 0.1789
2023-02-06 14:07:10 | Valid | Epoch[128/600] MIou: 0.917504504630827
2023-02-06 14:07:10 | Valid | Epoch[128/600] Pixel Accuracy: 0.984954833984375
2023-02-06 14:07:10 | Valid | Epoch[128/600] Mean Pixel Accuracy: 0.97145370720137
2023-02-06 14:07:10 | Stage | Epoch[128/600] Train loss:0.0307
2023-02-06 14:07:10 | Stage | Epoch[128/600] Valid loss:0.1789
2023-02-06 14:07:10 | Stage | Epoch[128/600] LR:0.01

2023-02-06 14:07:10 | Train | Epoch[129/600] Iteration[001/030] Train loss: 0.0315
2023-02-06 14:07:11 | Train | Epoch[129/600] Iteration[002/030] Train loss: 0.0300
2023-02-06 14:07:11 | Train | Epoch[129/600] Iteration[003/030] Train loss: 0.0296
2023-02-06 14:07:11 | Train | Epoch[129/600] Iteration[004/030] Train loss: 0.0301
2023-02-06 14:07:11 | Train | Epoch[129/600] Iteration[005/030] Train loss: 0.0303
2023-02-06 14:07:12 | Train | Epoch[129/600] Iteration[006/030] Train loss: 0.0306
2023-02-06 14:07:12 | Train | Epoch[129/600] Iteration[007/030] Train loss: 0.0305
2023-02-06 14:07:12 | Train | Epoch[129/600] Iteration[008/030] Train loss: 0.0303
2023-02-06 14:07:12 | Train | Epoch[129/600] Iteration[009/030] Train loss: 0.0303
2023-02-06 14:07:12 | Train | Epoch[129/600] Iteration[010/030] Train loss: 0.0301
2023-02-06 14:07:13 | Train | Epoch[129/600] Iteration[011/030] Train loss: 0.0301
2023-02-06 14:07:13 | Train | Epoch[129/600] Iteration[012/030] Train loss: 0.0300
2023-02-06 14:07:13 | Train | Epoch[129/600] Iteration[013/030] Train loss: 0.0301
2023-02-06 14:07:13 | Train | Epoch[129/600] Iteration[014/030] Train loss: 0.0301
2023-02-06 14:07:14 | Train | Epoch[129/600] Iteration[015/030] Train loss: 0.0302
2023-02-06 14:07:14 | Train | Epoch[129/600] Iteration[016/030] Train loss: 0.0301
2023-02-06 14:07:14 | Train | Epoch[129/600] Iteration[017/030] Train loss: 0.0302
2023-02-06 14:07:14 | Train | Epoch[129/600] Iteration[018/030] Train loss: 0.0302
2023-02-06 14:07:14 | Train | Epoch[129/600] Iteration[019/030] Train loss: 0.0301
2023-02-06 14:07:15 | Train | Epoch[129/600] Iteration[020/030] Train loss: 0.0302
2023-02-06 14:07:15 | Train | Epoch[129/600] Iteration[021/030] Train loss: 0.0303
2023-02-06 14:07:15 | Train | Epoch[129/600] Iteration[022/030] Train loss: 0.0302
2023-02-06 14:07:15 | Train | Epoch[129/600] Iteration[023/030] Train loss: 0.0302
2023-02-06 14:07:16 | Train | Epoch[129/600] Iteration[024/030] Train loss: 0.0302
2023-02-06 14:07:16 | Train | Epoch[129/600] Iteration[025/030] Train loss: 0.0302
2023-02-06 14:07:16 | Train | Epoch[129/600] Iteration[026/030] Train loss: 0.0302
2023-02-06 14:07:16 | Train | Epoch[129/600] Iteration[027/030] Train loss: 0.0302
2023-02-06 14:07:16 | Train | Epoch[129/600] Iteration[028/030] Train loss: 0.0302
2023-02-06 14:07:17 | Train | Epoch[129/600] Iteration[029/030] Train loss: 0.0301
2023-02-06 14:07:17 | Train | Epoch[129/600] Iteration[030/030] Train loss: 0.0301
2023-02-06 14:07:17 | Valid | Epoch[129/600] Iteration[001/008] Valid loss: 0.1002
2023-02-06 14:07:17 | Valid | Epoch[129/600] Iteration[002/008] Valid loss: 0.0897
2023-02-06 14:07:17 | Valid | Epoch[129/600] Iteration[003/008] Valid loss: 0.0888
2023-02-06 14:07:17 | Valid | Epoch[129/600] Iteration[004/008] Valid loss: 0.0839
2023-02-06 14:07:17 | Valid | Epoch[129/600] Iteration[005/008] Valid loss: 0.0826
2023-02-06 14:07:17 | Valid | Epoch[129/600] Iteration[006/008] Valid loss: 0.0810
2023-02-06 14:07:17 | Valid | Epoch[129/600] Iteration[007/008] Valid loss: 0.0849
2023-02-06 14:07:17 | Valid | Epoch[129/600] Iteration[008/008] Valid loss: 0.0830
2023-02-06 14:07:18 | Valid | Epoch[129/600] MIou: 0.9157483922497434
2023-02-06 14:07:18 | Valid | Epoch[129/600] Pixel Accuracy: 0.9854380289713541
2023-02-06 14:07:18 | Valid | Epoch[129/600] Mean Pixel Accuracy: 0.9446644998319371
2023-02-06 14:07:18 | Stage | Epoch[129/600] Train loss:0.0301
2023-02-06 14:07:18 | Stage | Epoch[129/600] Valid loss:0.0830
2023-02-06 14:07:18 | Stage | Epoch[129/600] LR:0.01

2023-02-06 14:07:18 | Train | Epoch[130/600] Iteration[001/030] Train loss: 0.0298
2023-02-06 14:07:18 | Train | Epoch[130/600] Iteration[002/030] Train loss: 0.0293
2023-02-06 14:07:18 | Train | Epoch[130/600] Iteration[003/030] Train loss: 0.0292
2023-02-06 14:07:19 | Train | Epoch[130/600] Iteration[004/030] Train loss: 0.0292
2023-02-06 14:07:19 | Train | Epoch[130/600] Iteration[005/030] Train loss: 0.0298
2023-02-06 14:07:19 | Train | Epoch[130/600] Iteration[006/030] Train loss: 0.0297
2023-02-06 14:07:19 | Train | Epoch[130/600] Iteration[007/030] Train loss: 0.0296
2023-02-06 14:07:20 | Train | Epoch[130/600] Iteration[008/030] Train loss: 0.0297
2023-02-06 14:07:20 | Train | Epoch[130/600] Iteration[009/030] Train loss: 0.0297
2023-02-06 14:07:20 | Train | Epoch[130/600] Iteration[010/030] Train loss: 0.0297
2023-02-06 14:07:20 | Train | Epoch[130/600] Iteration[011/030] Train loss: 0.0296
2023-02-06 14:07:20 | Train | Epoch[130/600] Iteration[012/030] Train loss: 0.0297
2023-02-06 14:07:21 | Train | Epoch[130/600] Iteration[013/030] Train loss: 0.0296
2023-02-06 14:07:21 | Train | Epoch[130/600] Iteration[014/030] Train loss: 0.0296
2023-02-06 14:07:21 | Train | Epoch[130/600] Iteration[015/030] Train loss: 0.0297
2023-02-06 14:07:21 | Train | Epoch[130/600] Iteration[016/030] Train loss: 0.0298
2023-02-06 14:07:22 | Train | Epoch[130/600] Iteration[017/030] Train loss: 0.0299
2023-02-06 14:07:22 | Train | Epoch[130/600] Iteration[018/030] Train loss: 0.0299
2023-02-06 14:07:22 | Train | Epoch[130/600] Iteration[019/030] Train loss: 0.0298
2023-02-06 14:07:22 | Train | Epoch[130/600] Iteration[020/030] Train loss: 0.0299
2023-02-06 14:07:22 | Train | Epoch[130/600] Iteration[021/030] Train loss: 0.0300
2023-02-06 14:07:23 | Train | Epoch[130/600] Iteration[022/030] Train loss: 0.0301
2023-02-06 14:07:23 | Train | Epoch[130/600] Iteration[023/030] Train loss: 0.0302
2023-02-06 14:07:23 | Train | Epoch[130/600] Iteration[024/030] Train loss: 0.0301
2023-02-06 14:07:23 | Train | Epoch[130/600] Iteration[025/030] Train loss: 0.0300
2023-02-06 14:07:24 | Train | Epoch[130/600] Iteration[026/030] Train loss: 0.0300
2023-02-06 14:07:24 | Train | Epoch[130/600] Iteration[027/030] Train loss: 0.0300
2023-02-06 14:07:24 | Train | Epoch[130/600] Iteration[028/030] Train loss: 0.0299
2023-02-06 14:07:24 | Train | Epoch[130/600] Iteration[029/030] Train loss: 0.0299
2023-02-06 14:07:24 | Train | Epoch[130/600] Iteration[030/030] Train loss: 0.0299
2023-02-06 14:07:25 | Valid | Epoch[130/600] Iteration[001/008] Valid loss: 0.8402
2023-02-06 14:07:25 | Valid | Epoch[130/600] Iteration[002/008] Valid loss: 0.7843
2023-02-06 14:07:25 | Valid | Epoch[130/600] Iteration[003/008] Valid loss: 0.8095
2023-02-06 14:07:25 | Valid | Epoch[130/600] Iteration[004/008] Valid loss: 0.8178
2023-02-06 14:07:25 | Valid | Epoch[130/600] Iteration[005/008] Valid loss: 0.8414
2023-02-06 14:07:25 | Valid | Epoch[130/600] Iteration[006/008] Valid loss: 0.8333
2023-02-06 14:07:25 | Valid | Epoch[130/600] Iteration[007/008] Valid loss: 0.8888
2023-02-06 14:07:25 | Valid | Epoch[130/600] Iteration[008/008] Valid loss: 0.8979
2023-02-06 14:07:25 | Valid | Epoch[130/600] MIou: 0.8450975340020841
2023-02-06 14:07:25 | Valid | Epoch[130/600] Pixel Accuracy: 0.9662577311197916
2023-02-06 14:07:25 | Valid | Epoch[130/600] Mean Pixel Accuracy: 0.9797672445282622
2023-02-06 14:07:25 | Stage | Epoch[130/600] Train loss:0.0299
2023-02-06 14:07:25 | Stage | Epoch[130/600] Valid loss:0.8979
2023-02-06 14:07:25 | Stage | Epoch[130/600] LR:0.01

2023-02-06 14:07:26 | Train | Epoch[131/600] Iteration[001/030] Train loss: 0.0278
2023-02-06 14:07:26 | Train | Epoch[131/600] Iteration[002/030] Train loss: 0.0283
2023-02-06 14:07:26 | Train | Epoch[131/600] Iteration[003/030] Train loss: 0.0282
2023-02-06 14:07:26 | Train | Epoch[131/600] Iteration[004/030] Train loss: 0.0291
2023-02-06 14:07:26 | Train | Epoch[131/600] Iteration[005/030] Train loss: 0.0293
2023-02-06 14:07:27 | Train | Epoch[131/600] Iteration[006/030] Train loss: 0.0294
2023-02-06 14:07:27 | Train | Epoch[131/600] Iteration[007/030] Train loss: 0.0294
2023-02-06 14:07:27 | Train | Epoch[131/600] Iteration[008/030] Train loss: 0.0293
2023-02-06 14:07:27 | Train | Epoch[131/600] Iteration[009/030] Train loss: 0.0296
2023-02-06 14:07:28 | Train | Epoch[131/600] Iteration[010/030] Train loss: 0.0294
2023-02-06 14:07:28 | Train | Epoch[131/600] Iteration[011/030] Train loss: 0.0294
2023-02-06 14:07:28 | Train | Epoch[131/600] Iteration[012/030] Train loss: 0.0293
2023-02-06 14:07:28 | Train | Epoch[131/600] Iteration[013/030] Train loss: 0.0293
2023-02-06 14:07:28 | Train | Epoch[131/600] Iteration[014/030] Train loss: 0.0294
2023-02-06 14:07:29 | Train | Epoch[131/600] Iteration[015/030] Train loss: 0.0293
2023-02-06 14:07:29 | Train | Epoch[131/600] Iteration[016/030] Train loss: 0.0295
2023-02-06 14:07:29 | Train | Epoch[131/600] Iteration[017/030] Train loss: 0.0295
2023-02-06 14:07:29 | Train | Epoch[131/600] Iteration[018/030] Train loss: 0.0295
2023-02-06 14:07:29 | Train | Epoch[131/600] Iteration[019/030] Train loss: 0.0295
2023-02-06 14:07:30 | Train | Epoch[131/600] Iteration[020/030] Train loss: 0.0296
2023-02-06 14:07:30 | Train | Epoch[131/600] Iteration[021/030] Train loss: 0.0296
2023-02-06 14:07:30 | Train | Epoch[131/600] Iteration[022/030] Train loss: 0.0297
2023-02-06 14:07:30 | Train | Epoch[131/600] Iteration[023/030] Train loss: 0.0297
2023-02-06 14:07:31 | Train | Epoch[131/600] Iteration[024/030] Train loss: 0.0296
2023-02-06 14:07:31 | Train | Epoch[131/600] Iteration[025/030] Train loss: 0.0296
2023-02-06 14:07:31 | Train | Epoch[131/600] Iteration[026/030] Train loss: 0.0295
2023-02-06 14:07:31 | Train | Epoch[131/600] Iteration[027/030] Train loss: 0.0295
2023-02-06 14:07:31 | Train | Epoch[131/600] Iteration[028/030] Train loss: 0.0296
2023-02-06 14:07:32 | Train | Epoch[131/600] Iteration[029/030] Train loss: 0.0296
2023-02-06 14:07:32 | Train | Epoch[131/600] Iteration[030/030] Train loss: 0.0297
2023-02-06 14:07:32 | Valid | Epoch[131/600] Iteration[001/008] Valid loss: 0.0813
2023-02-06 14:07:32 | Valid | Epoch[131/600] Iteration[002/008] Valid loss: 0.0788
2023-02-06 14:07:32 | Valid | Epoch[131/600] Iteration[003/008] Valid loss: 0.0803
2023-02-06 14:07:32 | Valid | Epoch[131/600] Iteration[004/008] Valid loss: 0.0792
2023-02-06 14:07:32 | Valid | Epoch[131/600] Iteration[005/008] Valid loss: 0.0793
2023-02-06 14:07:32 | Valid | Epoch[131/600] Iteration[006/008] Valid loss: 0.0778
2023-02-06 14:07:32 | Valid | Epoch[131/600] Iteration[007/008] Valid loss: 0.0763
2023-02-06 14:07:32 | Valid | Epoch[131/600] Iteration[008/008] Valid loss: 0.0757
2023-02-06 14:07:33 | Valid | Epoch[131/600] MIou: 0.8384292372108157
2023-02-06 14:07:33 | Valid | Epoch[131/600] Pixel Accuracy: 0.9732233683268229
2023-02-06 14:07:33 | Valid | Epoch[131/600] Mean Pixel Accuracy: 0.8547321128029783
2023-02-06 14:07:33 | Stage | Epoch[131/600] Train loss:0.0297
2023-02-06 14:07:33 | Stage | Epoch[131/600] Valid loss:0.0757
2023-02-06 14:07:33 | Stage | Epoch[131/600] LR:0.01

2023-02-06 14:07:33 | Train | Epoch[132/600] Iteration[001/030] Train loss: 0.0316
2023-02-06 14:07:33 | Train | Epoch[132/600] Iteration[002/030] Train loss: 0.0302
2023-02-06 14:07:33 | Train | Epoch[132/600] Iteration[003/030] Train loss: 0.0298
2023-02-06 14:07:34 | Train | Epoch[132/600] Iteration[004/030] Train loss: 0.0296
2023-02-06 14:07:34 | Train | Epoch[132/600] Iteration[005/030] Train loss: 0.0295
2023-02-06 14:07:34 | Train | Epoch[132/600] Iteration[006/030] Train loss: 0.0292
2023-02-06 14:07:34 | Train | Epoch[132/600] Iteration[007/030] Train loss: 0.0291
2023-02-06 14:07:35 | Train | Epoch[132/600] Iteration[008/030] Train loss: 0.0293
2023-02-06 14:07:35 | Train | Epoch[132/600] Iteration[009/030] Train loss: 0.0291
2023-02-06 14:07:35 | Train | Epoch[132/600] Iteration[010/030] Train loss: 0.0290
2023-02-06 14:07:35 | Train | Epoch[132/600] Iteration[011/030] Train loss: 0.0290
2023-02-06 14:07:35 | Train | Epoch[132/600] Iteration[012/030] Train loss: 0.0290
2023-02-06 14:07:36 | Train | Epoch[132/600] Iteration[013/030] Train loss: 0.0290
2023-02-06 14:07:36 | Train | Epoch[132/600] Iteration[014/030] Train loss: 0.0290
2023-02-06 14:07:36 | Train | Epoch[132/600] Iteration[015/030] Train loss: 0.0291
2023-02-06 14:07:36 | Train | Epoch[132/600] Iteration[016/030] Train loss: 0.0291
2023-02-06 14:07:37 | Train | Epoch[132/600] Iteration[017/030] Train loss: 0.0291
2023-02-06 14:07:37 | Train | Epoch[132/600] Iteration[018/030] Train loss: 0.0291
2023-02-06 14:07:37 | Train | Epoch[132/600] Iteration[019/030] Train loss: 0.0291
2023-02-06 14:07:37 | Train | Epoch[132/600] Iteration[020/030] Train loss: 0.0290
2023-02-06 14:07:37 | Train | Epoch[132/600] Iteration[021/030] Train loss: 0.0290
2023-02-06 14:07:38 | Train | Epoch[132/600] Iteration[022/030] Train loss: 0.0291
2023-02-06 14:07:38 | Train | Epoch[132/600] Iteration[023/030] Train loss: 0.0291
2023-02-06 14:07:38 | Train | Epoch[132/600] Iteration[024/030] Train loss: 0.0291
2023-02-06 14:07:38 | Train | Epoch[132/600] Iteration[025/030] Train loss: 0.0291
2023-02-06 14:07:39 | Train | Epoch[132/600] Iteration[026/030] Train loss: 0.0291
2023-02-06 14:07:39 | Train | Epoch[132/600] Iteration[027/030] Train loss: 0.0291
2023-02-06 14:07:39 | Train | Epoch[132/600] Iteration[028/030] Train loss: 0.0291
2023-02-06 14:07:39 | Train | Epoch[132/600] Iteration[029/030] Train loss: 0.0291
2023-02-06 14:07:39 | Train | Epoch[132/600] Iteration[030/030] Train loss: 0.0291
2023-02-06 14:07:40 | Valid | Epoch[132/600] Iteration[001/008] Valid loss: 0.0862
2023-02-06 14:07:40 | Valid | Epoch[132/600] Iteration[002/008] Valid loss: 0.0779
2023-02-06 14:07:40 | Valid | Epoch[132/600] Iteration[003/008] Valid loss: 0.0755
2023-02-06 14:07:40 | Valid | Epoch[132/600] Iteration[004/008] Valid loss: 0.0715
2023-02-06 14:07:40 | Valid | Epoch[132/600] Iteration[005/008] Valid loss: 0.0734
2023-02-06 14:07:40 | Valid | Epoch[132/600] Iteration[006/008] Valid loss: 0.0713
2023-02-06 14:07:40 | Valid | Epoch[132/600] Iteration[007/008] Valid loss: 0.0739
2023-02-06 14:07:40 | Valid | Epoch[132/600] Iteration[008/008] Valid loss: 0.0742
2023-02-06 14:07:40 | Valid | Epoch[132/600] MIou: 0.899964277128104
2023-02-06 14:07:40 | Valid | Epoch[132/600] Pixel Accuracy: 0.9824498494466146
2023-02-06 14:07:40 | Valid | Epoch[132/600] Mean Pixel Accuracy: 0.9359524431863968
2023-02-06 14:07:40 | Stage | Epoch[132/600] Train loss:0.0291
2023-02-06 14:07:40 | Stage | Epoch[132/600] Valid loss:0.0742
2023-02-06 14:07:40 | Stage | Epoch[132/600] LR:0.01

2023-02-06 14:07:41 | Train | Epoch[133/600] Iteration[001/030] Train loss: 0.0285
2023-02-06 14:07:41 | Train | Epoch[133/600] Iteration[002/030] Train loss: 0.0295
2023-02-06 14:07:41 | Train | Epoch[133/600] Iteration[003/030] Train loss: 0.0292
2023-02-06 14:07:41 | Train | Epoch[133/600] Iteration[004/030] Train loss: 0.0290
2023-02-06 14:07:41 | Train | Epoch[133/600] Iteration[005/030] Train loss: 0.0289
2023-02-06 14:07:42 | Train | Epoch[133/600] Iteration[006/030] Train loss: 0.0287
2023-02-06 14:07:42 | Train | Epoch[133/600] Iteration[007/030] Train loss: 0.0288
2023-02-06 14:07:42 | Train | Epoch[133/600] Iteration[008/030] Train loss: 0.0288
2023-02-06 14:07:42 | Train | Epoch[133/600] Iteration[009/030] Train loss: 0.0287
2023-02-06 14:07:43 | Train | Epoch[133/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 14:07:43 | Train | Epoch[133/600] Iteration[011/030] Train loss: 0.0286
2023-02-06 14:07:43 | Train | Epoch[133/600] Iteration[012/030] Train loss: 0.0284
2023-02-06 14:07:43 | Train | Epoch[133/600] Iteration[013/030] Train loss: 0.0285
2023-02-06 14:07:43 | Train | Epoch[133/600] Iteration[014/030] Train loss: 0.0285
2023-02-06 14:07:44 | Train | Epoch[133/600] Iteration[015/030] Train loss: 0.0284
2023-02-06 14:07:44 | Train | Epoch[133/600] Iteration[016/030] Train loss: 0.0286
2023-02-06 14:07:44 | Train | Epoch[133/600] Iteration[017/030] Train loss: 0.0286
2023-02-06 14:07:44 | Train | Epoch[133/600] Iteration[018/030] Train loss: 0.0285
2023-02-06 14:07:45 | Train | Epoch[133/600] Iteration[019/030] Train loss: 0.0285
2023-02-06 14:07:45 | Train | Epoch[133/600] Iteration[020/030] Train loss: 0.0284
2023-02-06 14:07:45 | Train | Epoch[133/600] Iteration[021/030] Train loss: 0.0285
2023-02-06 14:07:45 | Train | Epoch[133/600] Iteration[022/030] Train loss: 0.0285
2023-02-06 14:07:45 | Train | Epoch[133/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 14:07:46 | Train | Epoch[133/600] Iteration[024/030] Train loss: 0.0286
2023-02-06 14:07:46 | Train | Epoch[133/600] Iteration[025/030] Train loss: 0.0286
2023-02-06 14:07:46 | Train | Epoch[133/600] Iteration[026/030] Train loss: 0.0287
2023-02-06 14:07:46 | Train | Epoch[133/600] Iteration[027/030] Train loss: 0.0287
2023-02-06 14:07:47 | Train | Epoch[133/600] Iteration[028/030] Train loss: 0.0287
2023-02-06 14:07:47 | Train | Epoch[133/600] Iteration[029/030] Train loss: 0.0286
2023-02-06 14:07:47 | Train | Epoch[133/600] Iteration[030/030] Train loss: 0.0286
2023-02-06 14:07:47 | Valid | Epoch[133/600] Iteration[001/008] Valid loss: 0.5855
2023-02-06 14:07:47 | Valid | Epoch[133/600] Iteration[002/008] Valid loss: 0.5654
2023-02-06 14:07:47 | Valid | Epoch[133/600] Iteration[003/008] Valid loss: 0.5928
2023-02-06 14:07:47 | Valid | Epoch[133/600] Iteration[004/008] Valid loss: 0.5857
2023-02-06 14:07:47 | Valid | Epoch[133/600] Iteration[005/008] Valid loss: 0.6088
2023-02-06 14:07:48 | Valid | Epoch[133/600] Iteration[006/008] Valid loss: 0.5902
2023-02-06 14:07:48 | Valid | Epoch[133/600] Iteration[007/008] Valid loss: 0.6366
2023-02-06 14:07:48 | Valid | Epoch[133/600] Iteration[008/008] Valid loss: 0.6624
2023-02-06 14:07:48 | Valid | Epoch[133/600] MIou: 0.8738961818997815
2023-02-06 14:07:48 | Valid | Epoch[133/600] Pixel Accuracy: 0.9743309020996094
2023-02-06 14:07:48 | Valid | Epoch[133/600] Mean Pixel Accuracy: 0.9788595861265015
2023-02-06 14:07:48 | Stage | Epoch[133/600] Train loss:0.0286
2023-02-06 14:07:48 | Stage | Epoch[133/600] Valid loss:0.6624
2023-02-06 14:07:48 | Stage | Epoch[133/600] LR:0.01

2023-02-06 14:07:48 | Train | Epoch[134/600] Iteration[001/030] Train loss: 0.0288
2023-02-06 14:07:48 | Train | Epoch[134/600] Iteration[002/030] Train loss: 0.0283
2023-02-06 14:07:49 | Train | Epoch[134/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 14:07:49 | Train | Epoch[134/600] Iteration[004/030] Train loss: 0.0278
2023-02-06 14:07:49 | Train | Epoch[134/600] Iteration[005/030] Train loss: 0.0284
2023-02-06 14:07:49 | Train | Epoch[134/600] Iteration[006/030] Train loss: 0.0284
2023-02-06 14:07:49 | Train | Epoch[134/600] Iteration[007/030] Train loss: 0.0282
2023-02-06 14:07:50 | Train | Epoch[134/600] Iteration[008/030] Train loss: 0.0281
2023-02-06 14:07:50 | Train | Epoch[134/600] Iteration[009/030] Train loss: 0.0284
2023-02-06 14:07:50 | Train | Epoch[134/600] Iteration[010/030] Train loss: 0.0286
2023-02-06 14:07:50 | Train | Epoch[134/600] Iteration[011/030] Train loss: 0.0287
2023-02-06 14:07:51 | Train | Epoch[134/600] Iteration[012/030] Train loss: 0.0287
2023-02-06 14:07:51 | Train | Epoch[134/600] Iteration[013/030] Train loss: 0.0288
2023-02-06 14:07:51 | Train | Epoch[134/600] Iteration[014/030] Train loss: 0.0287
2023-02-06 14:07:51 | Train | Epoch[134/600] Iteration[015/030] Train loss: 0.0286
2023-02-06 14:07:51 | Train | Epoch[134/600] Iteration[016/030] Train loss: 0.0285
2023-02-06 14:07:52 | Train | Epoch[134/600] Iteration[017/030] Train loss: 0.0286
2023-02-06 14:07:52 | Train | Epoch[134/600] Iteration[018/030] Train loss: 0.0285
2023-02-06 14:07:52 | Train | Epoch[134/600] Iteration[019/030] Train loss: 0.0285
2023-02-06 14:07:52 | Train | Epoch[134/600] Iteration[020/030] Train loss: 0.0285
2023-02-06 14:07:53 | Train | Epoch[134/600] Iteration[021/030] Train loss: 0.0284
2023-02-06 14:07:53 | Train | Epoch[134/600] Iteration[022/030] Train loss: 0.0285
2023-02-06 14:07:53 | Train | Epoch[134/600] Iteration[023/030] Train loss: 0.0286
2023-02-06 14:07:53 | Train | Epoch[134/600] Iteration[024/030] Train loss: 0.0286
2023-02-06 14:07:53 | Train | Epoch[134/600] Iteration[025/030] Train loss: 0.0286
2023-02-06 14:07:54 | Train | Epoch[134/600] Iteration[026/030] Train loss: 0.0286
2023-02-06 14:07:54 | Train | Epoch[134/600] Iteration[027/030] Train loss: 0.0286
2023-02-06 14:07:54 | Train | Epoch[134/600] Iteration[028/030] Train loss: 0.0287
2023-02-06 14:07:54 | Train | Epoch[134/600] Iteration[029/030] Train loss: 0.0287
2023-02-06 14:07:54 | Train | Epoch[134/600] Iteration[030/030] Train loss: 0.0286
2023-02-06 14:07:55 | Valid | Epoch[134/600] Iteration[001/008] Valid loss: 0.4687
2023-02-06 14:07:55 | Valid | Epoch[134/600] Iteration[002/008] Valid loss: 0.3658
2023-02-06 14:07:55 | Valid | Epoch[134/600] Iteration[003/008] Valid loss: 0.3823
2023-02-06 14:07:55 | Valid | Epoch[134/600] Iteration[004/008] Valid loss: 0.3859
2023-02-06 14:07:55 | Valid | Epoch[134/600] Iteration[005/008] Valid loss: 0.3994
2023-02-06 14:07:55 | Valid | Epoch[134/600] Iteration[006/008] Valid loss: 0.3904
2023-02-06 14:07:55 | Valid | Epoch[134/600] Iteration[007/008] Valid loss: 0.4212
2023-02-06 14:07:55 | Valid | Epoch[134/600] Iteration[008/008] Valid loss: 0.4323
2023-02-06 14:07:55 | Valid | Epoch[134/600] MIou: 0.8858256651396738
2023-02-06 14:07:55 | Valid | Epoch[134/600] Pixel Accuracy: 0.9774360656738281
2023-02-06 14:07:55 | Valid | Epoch[134/600] Mean Pixel Accuracy: 0.9773390164592668
2023-02-06 14:07:55 | Stage | Epoch[134/600] Train loss:0.0286
2023-02-06 14:07:55 | Stage | Epoch[134/600] Valid loss:0.4323
2023-02-06 14:07:55 | Stage | Epoch[134/600] LR:0.01

2023-02-06 14:07:56 | Train | Epoch[135/600] Iteration[001/030] Train loss: 0.0271
2023-02-06 14:07:56 | Train | Epoch[135/600] Iteration[002/030] Train loss: 0.0301
2023-02-06 14:07:56 | Train | Epoch[135/600] Iteration[003/030] Train loss: 0.0290
2023-02-06 14:07:56 | Train | Epoch[135/600] Iteration[004/030] Train loss: 0.0287
2023-02-06 14:07:56 | Train | Epoch[135/600] Iteration[005/030] Train loss: 0.0285
2023-02-06 14:07:57 | Train | Epoch[135/600] Iteration[006/030] Train loss: 0.0283
2023-02-06 14:07:57 | Train | Epoch[135/600] Iteration[007/030] Train loss: 0.0282
2023-02-06 14:07:57 | Train | Epoch[135/600] Iteration[008/030] Train loss: 0.0281
2023-02-06 14:07:57 | Train | Epoch[135/600] Iteration[009/030] Train loss: 0.0281
2023-02-06 14:07:58 | Train | Epoch[135/600] Iteration[010/030] Train loss: 0.0281
2023-02-06 14:07:58 | Train | Epoch[135/600] Iteration[011/030] Train loss: 0.0282
2023-02-06 14:07:58 | Train | Epoch[135/600] Iteration[012/030] Train loss: 0.0282
2023-02-06 14:07:58 | Train | Epoch[135/600] Iteration[013/030] Train loss: 0.0281
2023-02-06 14:07:58 | Train | Epoch[135/600] Iteration[014/030] Train loss: 0.0281
2023-02-06 14:07:59 | Train | Epoch[135/600] Iteration[015/030] Train loss: 0.0281
2023-02-06 14:07:59 | Train | Epoch[135/600] Iteration[016/030] Train loss: 0.0281
2023-02-06 14:07:59 | Train | Epoch[135/600] Iteration[017/030] Train loss: 0.0283
2023-02-06 14:07:59 | Train | Epoch[135/600] Iteration[018/030] Train loss: 0.0283
2023-02-06 14:08:00 | Train | Epoch[135/600] Iteration[019/030] Train loss: 0.0283
2023-02-06 14:08:00 | Train | Epoch[135/600] Iteration[020/030] Train loss: 0.0283
2023-02-06 14:08:00 | Train | Epoch[135/600] Iteration[021/030] Train loss: 0.0283
2023-02-06 14:08:00 | Train | Epoch[135/600] Iteration[022/030] Train loss: 0.0284
2023-02-06 14:08:00 | Train | Epoch[135/600] Iteration[023/030] Train loss: 0.0284
2023-02-06 14:08:01 | Train | Epoch[135/600] Iteration[024/030] Train loss: 0.0286
2023-02-06 14:08:01 | Train | Epoch[135/600] Iteration[025/030] Train loss: 0.0287
2023-02-06 14:08:01 | Train | Epoch[135/600] Iteration[026/030] Train loss: 0.0287
2023-02-06 14:08:01 | Train | Epoch[135/600] Iteration[027/030] Train loss: 0.0287
2023-02-06 14:08:02 | Train | Epoch[135/600] Iteration[028/030] Train loss: 0.0287
2023-02-06 14:08:02 | Train | Epoch[135/600] Iteration[029/030] Train loss: 0.0287
2023-02-06 14:08:02 | Train | Epoch[135/600] Iteration[030/030] Train loss: 0.0287
2023-02-06 14:08:02 | Valid | Epoch[135/600] Iteration[001/008] Valid loss: 0.5455
2023-02-06 14:08:02 | Valid | Epoch[135/600] Iteration[002/008] Valid loss: 0.4898
2023-02-06 14:08:02 | Valid | Epoch[135/600] Iteration[003/008] Valid loss: 0.4916
2023-02-06 14:08:02 | Valid | Epoch[135/600] Iteration[004/008] Valid loss: 0.4944
2023-02-06 14:08:02 | Valid | Epoch[135/600] Iteration[005/008] Valid loss: 0.4996
2023-02-06 14:08:02 | Valid | Epoch[135/600] Iteration[006/008] Valid loss: 0.4823
2023-02-06 14:08:03 | Valid | Epoch[135/600] Iteration[007/008] Valid loss: 0.5034
2023-02-06 14:08:03 | Valid | Epoch[135/600] Iteration[008/008] Valid loss: 0.5318
2023-02-06 14:08:03 | Valid | Epoch[135/600] MIou: 0.8554230943913257
2023-02-06 14:08:03 | Valid | Epoch[135/600] Pixel Accuracy: 0.9695154825846354
2023-02-06 14:08:03 | Valid | Epoch[135/600] Mean Pixel Accuracy: 0.9753505220627539
2023-02-06 14:08:03 | Stage | Epoch[135/600] Train loss:0.0287
2023-02-06 14:08:03 | Stage | Epoch[135/600] Valid loss:0.5318
2023-02-06 14:08:03 | Stage | Epoch[135/600] LR:0.01

2023-02-06 14:08:03 | Train | Epoch[136/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 14:08:03 | Train | Epoch[136/600] Iteration[002/030] Train loss: 0.0308
2023-02-06 14:08:04 | Train | Epoch[136/600] Iteration[003/030] Train loss: 0.0303
2023-02-06 14:08:04 | Train | Epoch[136/600] Iteration[004/030] Train loss: 0.0297
2023-02-06 14:08:04 | Train | Epoch[136/600] Iteration[005/030] Train loss: 0.0297
2023-02-06 14:08:04 | Train | Epoch[136/600] Iteration[006/030] Train loss: 0.0291
2023-02-06 14:08:04 | Train | Epoch[136/600] Iteration[007/030] Train loss: 0.0289
2023-02-06 14:08:05 | Train | Epoch[136/600] Iteration[008/030] Train loss: 0.0290
2023-02-06 14:08:05 | Train | Epoch[136/600] Iteration[009/030] Train loss: 0.0289
2023-02-06 14:08:05 | Train | Epoch[136/600] Iteration[010/030] Train loss: 0.0288
2023-02-06 14:08:05 | Train | Epoch[136/600] Iteration[011/030] Train loss: 0.0287
2023-02-06 14:08:06 | Train | Epoch[136/600] Iteration[012/030] Train loss: 0.0289
2023-02-06 14:08:06 | Train | Epoch[136/600] Iteration[013/030] Train loss: 0.0288
2023-02-06 14:08:06 | Train | Epoch[136/600] Iteration[014/030] Train loss: 0.0288
2023-02-06 14:08:06 | Train | Epoch[136/600] Iteration[015/030] Train loss: 0.0288
2023-02-06 14:08:06 | Train | Epoch[136/600] Iteration[016/030] Train loss: 0.0288
2023-02-06 14:08:07 | Train | Epoch[136/600] Iteration[017/030] Train loss: 0.0288
2023-02-06 14:08:07 | Train | Epoch[136/600] Iteration[018/030] Train loss: 0.0288
2023-02-06 14:08:07 | Train | Epoch[136/600] Iteration[019/030] Train loss: 0.0287
2023-02-06 14:08:07 | Train | Epoch[136/600] Iteration[020/030] Train loss: 0.0287
2023-02-06 14:08:07 | Train | Epoch[136/600] Iteration[021/030] Train loss: 0.0287
2023-02-06 14:08:08 | Train | Epoch[136/600] Iteration[022/030] Train loss: 0.0286
2023-02-06 14:08:08 | Train | Epoch[136/600] Iteration[023/030] Train loss: 0.0286
2023-02-06 14:08:08 | Train | Epoch[136/600] Iteration[024/030] Train loss: 0.0286
2023-02-06 14:08:08 | Train | Epoch[136/600] Iteration[025/030] Train loss: 0.0285
2023-02-06 14:08:09 | Train | Epoch[136/600] Iteration[026/030] Train loss: 0.0286
2023-02-06 14:08:09 | Train | Epoch[136/600] Iteration[027/030] Train loss: 0.0286
2023-02-06 14:08:09 | Train | Epoch[136/600] Iteration[028/030] Train loss: 0.0286
2023-02-06 14:08:09 | Train | Epoch[136/600] Iteration[029/030] Train loss: 0.0285
2023-02-06 14:08:09 | Train | Epoch[136/600] Iteration[030/030] Train loss: 0.0284
2023-02-06 14:08:10 | Valid | Epoch[136/600] Iteration[001/008] Valid loss: 0.1051
2023-02-06 14:08:10 | Valid | Epoch[136/600] Iteration[002/008] Valid loss: 0.0891
2023-02-06 14:08:10 | Valid | Epoch[136/600] Iteration[003/008] Valid loss: 0.0846
2023-02-06 14:08:10 | Valid | Epoch[136/600] Iteration[004/008] Valid loss: 0.0802
2023-02-06 14:08:10 | Valid | Epoch[136/600] Iteration[005/008] Valid loss: 0.0812
2023-02-06 14:08:10 | Valid | Epoch[136/600] Iteration[006/008] Valid loss: 0.0768
2023-02-06 14:08:10 | Valid | Epoch[136/600] Iteration[007/008] Valid loss: 0.0789
2023-02-06 14:08:10 | Valid | Epoch[136/600] Iteration[008/008] Valid loss: 0.0813
2023-02-06 14:08:10 | Valid | Epoch[136/600] MIou: 0.8883916783299408
2023-02-06 14:08:10 | Valid | Epoch[136/600] Pixel Accuracy: 0.9803581237792969
2023-02-06 14:08:10 | Valid | Epoch[136/600] Mean Pixel Accuracy: 0.9259514433188336
2023-02-06 14:08:10 | Stage | Epoch[136/600] Train loss:0.0284
2023-02-06 14:08:10 | Stage | Epoch[136/600] Valid loss:0.0813
2023-02-06 14:08:10 | Stage | Epoch[136/600] LR:0.01

2023-02-06 14:08:11 | Train | Epoch[137/600] Iteration[001/030] Train loss: 0.0265
2023-02-06 14:08:11 | Train | Epoch[137/600] Iteration[002/030] Train loss: 0.0272
2023-02-06 14:08:11 | Train | Epoch[137/600] Iteration[003/030] Train loss: 0.0276
2023-02-06 14:08:11 | Train | Epoch[137/600] Iteration[004/030] Train loss: 0.0272
2023-02-06 14:08:12 | Train | Epoch[137/600] Iteration[005/030] Train loss: 0.0275
2023-02-06 14:08:12 | Train | Epoch[137/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 14:08:12 | Train | Epoch[137/600] Iteration[007/030] Train loss: 0.0273
2023-02-06 14:08:12 | Train | Epoch[137/600] Iteration[008/030] Train loss: 0.0276
2023-02-06 14:08:12 | Train | Epoch[137/600] Iteration[009/030] Train loss: 0.0275
2023-02-06 14:08:13 | Train | Epoch[137/600] Iteration[010/030] Train loss: 0.0275
2023-02-06 14:08:13 | Train | Epoch[137/600] Iteration[011/030] Train loss: 0.0275
2023-02-06 14:08:13 | Train | Epoch[137/600] Iteration[012/030] Train loss: 0.0275
2023-02-06 14:08:13 | Train | Epoch[137/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 14:08:13 | Train | Epoch[137/600] Iteration[014/030] Train loss: 0.0275
2023-02-06 14:08:14 | Train | Epoch[137/600] Iteration[015/030] Train loss: 0.0276
2023-02-06 14:08:14 | Train | Epoch[137/600] Iteration[016/030] Train loss: 0.0276
2023-02-06 14:08:14 | Train | Epoch[137/600] Iteration[017/030] Train loss: 0.0279
2023-02-06 14:08:14 | Train | Epoch[137/600] Iteration[018/030] Train loss: 0.0278
2023-02-06 14:08:15 | Train | Epoch[137/600] Iteration[019/030] Train loss: 0.0281
2023-02-06 14:08:15 | Train | Epoch[137/600] Iteration[020/030] Train loss: 0.0282
2023-02-06 14:08:15 | Train | Epoch[137/600] Iteration[021/030] Train loss: 0.0281
2023-02-06 14:08:15 | Train | Epoch[137/600] Iteration[022/030] Train loss: 0.0283
2023-02-06 14:08:15 | Train | Epoch[137/600] Iteration[023/030] Train loss: 0.0283
2023-02-06 14:08:16 | Train | Epoch[137/600] Iteration[024/030] Train loss: 0.0284
2023-02-06 14:08:16 | Train | Epoch[137/600] Iteration[025/030] Train loss: 0.0284
2023-02-06 14:08:16 | Train | Epoch[137/600] Iteration[026/030] Train loss: 0.0284
2023-02-06 14:08:16 | Train | Epoch[137/600] Iteration[027/030] Train loss: 0.0284
2023-02-06 14:08:17 | Train | Epoch[137/600] Iteration[028/030] Train loss: 0.0284
2023-02-06 14:08:17 | Train | Epoch[137/600] Iteration[029/030] Train loss: 0.0285
2023-02-06 14:08:17 | Train | Epoch[137/600] Iteration[030/030] Train loss: 0.0284
2023-02-06 14:08:17 | Valid | Epoch[137/600] Iteration[001/008] Valid loss: 0.2625
2023-02-06 14:08:17 | Valid | Epoch[137/600] Iteration[002/008] Valid loss: 0.2261
2023-02-06 14:08:17 | Valid | Epoch[137/600] Iteration[003/008] Valid loss: 0.2126
2023-02-06 14:08:17 | Valid | Epoch[137/600] Iteration[004/008] Valid loss: 0.2020
2023-02-06 14:08:17 | Valid | Epoch[137/600] Iteration[005/008] Valid loss: 0.1906
2023-02-06 14:08:17 | Valid | Epoch[137/600] Iteration[006/008] Valid loss: 0.1844
2023-02-06 14:08:18 | Valid | Epoch[137/600] Iteration[007/008] Valid loss: 0.1964
2023-02-06 14:08:18 | Valid | Epoch[137/600] Iteration[008/008] Valid loss: 0.2080
2023-02-06 14:08:18 | Valid | Epoch[137/600] MIou: 0.9067095141171795
2023-02-06 14:08:18 | Valid | Epoch[137/600] Pixel Accuracy: 0.9824930826822916
2023-02-06 14:08:18 | Valid | Epoch[137/600] Mean Pixel Accuracy: 0.9741902278198828
2023-02-06 14:08:18 | Stage | Epoch[137/600] Train loss:0.0284
2023-02-06 14:08:18 | Stage | Epoch[137/600] Valid loss:0.2080
2023-02-06 14:08:18 | Stage | Epoch[137/600] LR:0.01

2023-02-06 14:08:18 | Train | Epoch[138/600] Iteration[001/030] Train loss: 0.0278
2023-02-06 14:08:18 | Train | Epoch[138/600] Iteration[002/030] Train loss: 0.0283
2023-02-06 14:08:19 | Train | Epoch[138/600] Iteration[003/030] Train loss: 0.0283
2023-02-06 14:08:19 | Train | Epoch[138/600] Iteration[004/030] Train loss: 0.0283
2023-02-06 14:08:19 | Train | Epoch[138/600] Iteration[005/030] Train loss: 0.0280
2023-02-06 14:08:19 | Train | Epoch[138/600] Iteration[006/030] Train loss: 0.0279
2023-02-06 14:08:19 | Train | Epoch[138/600] Iteration[007/030] Train loss: 0.0285
2023-02-06 14:08:20 | Train | Epoch[138/600] Iteration[008/030] Train loss: 0.0287
2023-02-06 14:08:20 | Train | Epoch[138/600] Iteration[009/030] Train loss: 0.0289
2023-02-06 14:08:20 | Train | Epoch[138/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 14:08:20 | Train | Epoch[138/600] Iteration[011/030] Train loss: 0.0287
2023-02-06 14:08:21 | Train | Epoch[138/600] Iteration[012/030] Train loss: 0.0286
2023-02-06 14:08:21 | Train | Epoch[138/600] Iteration[013/030] Train loss: 0.0286
2023-02-06 14:08:21 | Train | Epoch[138/600] Iteration[014/030] Train loss: 0.0286
2023-02-06 14:08:21 | Train | Epoch[138/600] Iteration[015/030] Train loss: 0.0287
2023-02-06 14:08:21 | Train | Epoch[138/600] Iteration[016/030] Train loss: 0.0287
2023-02-06 14:08:22 | Train | Epoch[138/600] Iteration[017/030] Train loss: 0.0287
2023-02-06 14:08:22 | Train | Epoch[138/600] Iteration[018/030] Train loss: 0.0285
2023-02-06 14:08:22 | Train | Epoch[138/600] Iteration[019/030] Train loss: 0.0285
2023-02-06 14:08:22 | Train | Epoch[138/600] Iteration[020/030] Train loss: 0.0285
2023-02-06 14:08:23 | Train | Epoch[138/600] Iteration[021/030] Train loss: 0.0284
2023-02-06 14:08:23 | Train | Epoch[138/600] Iteration[022/030] Train loss: 0.0283
2023-02-06 14:08:23 | Train | Epoch[138/600] Iteration[023/030] Train loss: 0.0283
2023-02-06 14:08:23 | Train | Epoch[138/600] Iteration[024/030] Train loss: 0.0283
2023-02-06 14:08:23 | Train | Epoch[138/600] Iteration[025/030] Train loss: 0.0283
2023-02-06 14:08:24 | Train | Epoch[138/600] Iteration[026/030] Train loss: 0.0283
2023-02-06 14:08:24 | Train | Epoch[138/600] Iteration[027/030] Train loss: 0.0283
2023-02-06 14:08:24 | Train | Epoch[138/600] Iteration[028/030] Train loss: 0.0284
2023-02-06 14:08:24 | Train | Epoch[138/600] Iteration[029/030] Train loss: 0.0284
2023-02-06 14:08:24 | Train | Epoch[138/600] Iteration[030/030] Train loss: 0.0284
2023-02-06 14:08:25 | Valid | Epoch[138/600] Iteration[001/008] Valid loss: 0.0875
2023-02-06 14:08:25 | Valid | Epoch[138/600] Iteration[002/008] Valid loss: 0.0714
2023-02-06 14:08:25 | Valid | Epoch[138/600] Iteration[003/008] Valid loss: 0.0669
2023-02-06 14:08:25 | Valid | Epoch[138/600] Iteration[004/008] Valid loss: 0.0639
2023-02-06 14:08:25 | Valid | Epoch[138/600] Iteration[005/008] Valid loss: 0.0633
2023-02-06 14:08:25 | Valid | Epoch[138/600] Iteration[006/008] Valid loss: 0.0623
2023-02-06 14:08:25 | Valid | Epoch[138/600] Iteration[007/008] Valid loss: 0.0649
2023-02-06 14:08:25 | Valid | Epoch[138/600] Iteration[008/008] Valid loss: 0.0639
2023-02-06 14:08:25 | Valid | Epoch[138/600] MIou: 0.888263070258124
2023-02-06 14:08:25 | Valid | Epoch[138/600] Pixel Accuracy: 0.9812723795572916
2023-02-06 14:08:25 | Valid | Epoch[138/600] Mean Pixel Accuracy: 0.9053845704518442
2023-02-06 14:08:25 | Stage | Epoch[138/600] Train loss:0.0284
2023-02-06 14:08:25 | Stage | Epoch[138/600] Valid loss:0.0639
2023-02-06 14:08:25 | Stage | Epoch[138/600] LR:0.01

2023-02-06 14:08:26 | Train | Epoch[139/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 14:08:26 | Train | Epoch[139/600] Iteration[002/030] Train loss: 0.0272
2023-02-06 14:08:26 | Train | Epoch[139/600] Iteration[003/030] Train loss: 0.0269
2023-02-06 14:08:26 | Train | Epoch[139/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 14:08:27 | Train | Epoch[139/600] Iteration[005/030] Train loss: 0.0270
2023-02-06 14:08:27 | Train | Epoch[139/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 14:08:27 | Train | Epoch[139/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 14:08:27 | Train | Epoch[139/600] Iteration[008/030] Train loss: 0.0270
2023-02-06 14:08:27 | Train | Epoch[139/600] Iteration[009/030] Train loss: 0.0270
2023-02-06 14:08:28 | Train | Epoch[139/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 14:08:28 | Train | Epoch[139/600] Iteration[011/030] Train loss: 0.0269
2023-02-06 14:08:28 | Train | Epoch[139/600] Iteration[012/030] Train loss: 0.0268
2023-02-06 14:08:28 | Train | Epoch[139/600] Iteration[013/030] Train loss: 0.0268
2023-02-06 14:08:29 | Train | Epoch[139/600] Iteration[014/030] Train loss: 0.0269
2023-02-06 14:08:29 | Train | Epoch[139/600] Iteration[015/030] Train loss: 0.0268
2023-02-06 14:08:29 | Train | Epoch[139/600] Iteration[016/030] Train loss: 0.0268
2023-02-06 14:08:29 | Train | Epoch[139/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 14:08:29 | Train | Epoch[139/600] Iteration[018/030] Train loss: 0.0269
2023-02-06 14:08:30 | Train | Epoch[139/600] Iteration[019/030] Train loss: 0.0269
2023-02-06 14:08:30 | Train | Epoch[139/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 14:08:30 | Train | Epoch[139/600] Iteration[021/030] Train loss: 0.0270
2023-02-06 14:08:30 | Train | Epoch[139/600] Iteration[022/030] Train loss: 0.0270
2023-02-06 14:08:31 | Train | Epoch[139/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 14:08:31 | Train | Epoch[139/600] Iteration[024/030] Train loss: 0.0270
2023-02-06 14:08:31 | Train | Epoch[139/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 14:08:31 | Train | Epoch[139/600] Iteration[026/030] Train loss: 0.0271
2023-02-06 14:08:31 | Train | Epoch[139/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 14:08:32 | Train | Epoch[139/600] Iteration[028/030] Train loss: 0.0271
2023-02-06 14:08:32 | Train | Epoch[139/600] Iteration[029/030] Train loss: 0.0271
2023-02-06 14:08:32 | Train | Epoch[139/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 14:08:32 | Valid | Epoch[139/600] Iteration[001/008] Valid loss: 0.0844
2023-02-06 14:08:32 | Valid | Epoch[139/600] Iteration[002/008] Valid loss: 0.0732
2023-02-06 14:08:32 | Valid | Epoch[139/600] Iteration[003/008] Valid loss: 0.0720
2023-02-06 14:08:32 | Valid | Epoch[139/600] Iteration[004/008] Valid loss: 0.0687
2023-02-06 14:08:32 | Valid | Epoch[139/600] Iteration[005/008] Valid loss: 0.0692
2023-02-06 14:08:33 | Valid | Epoch[139/600] Iteration[006/008] Valid loss: 0.0677
2023-02-06 14:08:33 | Valid | Epoch[139/600] Iteration[007/008] Valid loss: 0.0660
2023-02-06 14:08:33 | Valid | Epoch[139/600] Iteration[008/008] Valid loss: 0.0657
2023-02-06 14:08:33 | Valid | Epoch[139/600] MIou: 0.8620941628747594
2023-02-06 14:08:33 | Valid | Epoch[139/600] Pixel Accuracy: 0.9772148132324219
2023-02-06 14:08:33 | Valid | Epoch[139/600] Mean Pixel Accuracy: 0.8754908817414733
2023-02-06 14:08:33 | Stage | Epoch[139/600] Train loss:0.0272
2023-02-06 14:08:33 | Stage | Epoch[139/600] Valid loss:0.0657
2023-02-06 14:08:33 | Stage | Epoch[139/600] LR:0.01

2023-02-06 14:08:33 | Train | Epoch[140/600] Iteration[001/030] Train loss: 0.0292
2023-02-06 14:08:33 | Train | Epoch[140/600] Iteration[002/030] Train loss: 0.0279
2023-02-06 14:08:34 | Train | Epoch[140/600] Iteration[003/030] Train loss: 0.0272
2023-02-06 14:08:34 | Train | Epoch[140/600] Iteration[004/030] Train loss: 0.0269
2023-02-06 14:08:34 | Train | Epoch[140/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 14:08:34 | Train | Epoch[140/600] Iteration[006/030] Train loss: 0.0270
2023-02-06 14:08:34 | Train | Epoch[140/600] Iteration[007/030] Train loss: 0.0270
2023-02-06 14:08:35 | Train | Epoch[140/600] Iteration[008/030] Train loss: 0.0268
2023-02-06 14:08:35 | Train | Epoch[140/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 14:08:35 | Train | Epoch[140/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 14:08:35 | Train | Epoch[140/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 14:08:36 | Train | Epoch[140/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 14:08:36 | Train | Epoch[140/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 14:08:36 | Train | Epoch[140/600] Iteration[014/030] Train loss: 0.0271
2023-02-06 14:08:36 | Train | Epoch[140/600] Iteration[015/030] Train loss: 0.0272
2023-02-06 14:08:36 | Train | Epoch[140/600] Iteration[016/030] Train loss: 0.0272
2023-02-06 14:08:37 | Train | Epoch[140/600] Iteration[017/030] Train loss: 0.0273
2023-02-06 14:08:37 | Train | Epoch[140/600] Iteration[018/030] Train loss: 0.0273
2023-02-06 14:08:37 | Train | Epoch[140/600] Iteration[019/030] Train loss: 0.0272
2023-02-06 14:08:37 | Train | Epoch[140/600] Iteration[020/030] Train loss: 0.0271
2023-02-06 14:08:38 | Train | Epoch[140/600] Iteration[021/030] Train loss: 0.0271
2023-02-06 14:08:38 | Train | Epoch[140/600] Iteration[022/030] Train loss: 0.0270
2023-02-06 14:08:38 | Train | Epoch[140/600] Iteration[023/030] Train loss: 0.0271
2023-02-06 14:08:38 | Train | Epoch[140/600] Iteration[024/030] Train loss: 0.0270
2023-02-06 14:08:38 | Train | Epoch[140/600] Iteration[025/030] Train loss: 0.0270
2023-02-06 14:08:39 | Train | Epoch[140/600] Iteration[026/030] Train loss: 0.0270
2023-02-06 14:08:39 | Train | Epoch[140/600] Iteration[027/030] Train loss: 0.0270
2023-02-06 14:08:39 | Train | Epoch[140/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 14:08:39 | Train | Epoch[140/600] Iteration[029/030] Train loss: 0.0271
2023-02-06 14:08:39 | Train | Epoch[140/600] Iteration[030/030] Train loss: 0.0271
2023-02-06 14:08:40 | Valid | Epoch[140/600] Iteration[001/008] Valid loss: 0.5022
2023-02-06 14:08:40 | Valid | Epoch[140/600] Iteration[002/008] Valid loss: 0.4476
2023-02-06 14:08:40 | Valid | Epoch[140/600] Iteration[003/008] Valid loss: 0.4515
2023-02-06 14:08:40 | Valid | Epoch[140/600] Iteration[004/008] Valid loss: 0.4550
2023-02-06 14:08:40 | Valid | Epoch[140/600] Iteration[005/008] Valid loss: 0.4760
2023-02-06 14:08:40 | Valid | Epoch[140/600] Iteration[006/008] Valid loss: 0.4688
2023-02-06 14:08:40 | Valid | Epoch[140/600] Iteration[007/008] Valid loss: 0.5049
2023-02-06 14:08:40 | Valid | Epoch[140/600] Iteration[008/008] Valid loss: 0.5202
2023-02-06 14:08:40 | Valid | Epoch[140/600] MIou: 0.8917803643221481
2023-02-06 14:08:40 | Valid | Epoch[140/600] Pixel Accuracy: 0.9786911010742188
2023-02-06 14:08:40 | Valid | Epoch[140/600] Mean Pixel Accuracy: 0.9820803987375057
2023-02-06 14:08:40 | Stage | Epoch[140/600] Train loss:0.0271
2023-02-06 14:08:40 | Stage | Epoch[140/600] Valid loss:0.5202
2023-02-06 14:08:40 | Stage | Epoch[140/600] LR:0.01

2023-02-06 14:08:41 | Train | Epoch[141/600] Iteration[001/030] Train loss: 0.0274
2023-02-06 14:08:41 | Train | Epoch[141/600] Iteration[002/030] Train loss: 0.0277
2023-02-06 14:08:41 | Train | Epoch[141/600] Iteration[003/030] Train loss: 0.0272
2023-02-06 14:08:41 | Train | Epoch[141/600] Iteration[004/030] Train loss: 0.0265
2023-02-06 14:08:42 | Train | Epoch[141/600] Iteration[005/030] Train loss: 0.0265
2023-02-06 14:08:42 | Train | Epoch[141/600] Iteration[006/030] Train loss: 0.0265
2023-02-06 14:08:42 | Train | Epoch[141/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 14:08:42 | Train | Epoch[141/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 14:08:42 | Train | Epoch[141/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 14:08:43 | Train | Epoch[141/600] Iteration[010/030] Train loss: 0.0264
2023-02-06 14:08:43 | Train | Epoch[141/600] Iteration[011/030] Train loss: 0.0263
2023-02-06 14:08:43 | Train | Epoch[141/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 14:08:43 | Train | Epoch[141/600] Iteration[013/030] Train loss: 0.0265
2023-02-06 14:08:44 | Train | Epoch[141/600] Iteration[014/030] Train loss: 0.0265
2023-02-06 14:08:44 | Train | Epoch[141/600] Iteration[015/030] Train loss: 0.0264
2023-02-06 14:08:44 | Train | Epoch[141/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 14:08:44 | Train | Epoch[141/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 14:08:44 | Train | Epoch[141/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 14:08:45 | Train | Epoch[141/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 14:08:45 | Train | Epoch[141/600] Iteration[020/030] Train loss: 0.0267
2023-02-06 14:08:45 | Train | Epoch[141/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 14:08:45 | Train | Epoch[141/600] Iteration[022/030] Train loss: 0.0266
2023-02-06 14:08:46 | Train | Epoch[141/600] Iteration[023/030] Train loss: 0.0266
2023-02-06 14:08:46 | Train | Epoch[141/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 14:08:46 | Train | Epoch[141/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 14:08:46 | Train | Epoch[141/600] Iteration[026/030] Train loss: 0.0266
2023-02-06 14:08:46 | Train | Epoch[141/600] Iteration[027/030] Train loss: 0.0267
2023-02-06 14:08:47 | Train | Epoch[141/600] Iteration[028/030] Train loss: 0.0267
2023-02-06 14:08:47 | Train | Epoch[141/600] Iteration[029/030] Train loss: 0.0267
2023-02-06 14:08:47 | Train | Epoch[141/600] Iteration[030/030] Train loss: 0.0268
2023-02-06 14:08:47 | Valid | Epoch[141/600] Iteration[001/008] Valid loss: 0.2832
2023-02-06 14:08:47 | Valid | Epoch[141/600] Iteration[002/008] Valid loss: 0.2299
2023-02-06 14:08:47 | Valid | Epoch[141/600] Iteration[003/008] Valid loss: 0.2164
2023-02-06 14:08:47 | Valid | Epoch[141/600] Iteration[004/008] Valid loss: 0.2081
2023-02-06 14:08:48 | Valid | Epoch[141/600] Iteration[005/008] Valid loss: 0.2105
2023-02-06 14:08:48 | Valid | Epoch[141/600] Iteration[006/008] Valid loss: 0.2055
2023-02-06 14:08:48 | Valid | Epoch[141/600] Iteration[007/008] Valid loss: 0.2281
2023-02-06 14:08:48 | Valid | Epoch[141/600] Iteration[008/008] Valid loss: 0.2320
2023-02-06 14:08:48 | Valid | Epoch[141/600] MIou: 0.9115666391038573
2023-02-06 14:08:48 | Valid | Epoch[141/600] Pixel Accuracy: 0.9834454854329427
2023-02-06 14:08:48 | Valid | Epoch[141/600] Mean Pixel Accuracy: 0.9780741588920379
2023-02-06 14:08:48 | Stage | Epoch[141/600] Train loss:0.0268
2023-02-06 14:08:48 | Stage | Epoch[141/600] Valid loss:0.2320
2023-02-06 14:08:48 | Stage | Epoch[141/600] LR:0.01

2023-02-06 14:08:48 | Train | Epoch[142/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 14:08:48 | Train | Epoch[142/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 14:08:49 | Train | Epoch[142/600] Iteration[003/030] Train loss: 0.0274
2023-02-06 14:08:49 | Train | Epoch[142/600] Iteration[004/030] Train loss: 0.0272
2023-02-06 14:08:49 | Train | Epoch[142/600] Iteration[005/030] Train loss: 0.0270
2023-02-06 14:08:49 | Train | Epoch[142/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 14:08:50 | Train | Epoch[142/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 14:08:50 | Train | Epoch[142/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 14:08:50 | Train | Epoch[142/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 14:08:50 | Train | Epoch[142/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 14:08:50 | Train | Epoch[142/600] Iteration[011/030] Train loss: 0.0268
2023-02-06 14:08:51 | Train | Epoch[142/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 14:08:51 | Train | Epoch[142/600] Iteration[013/030] Train loss: 0.0267
2023-02-06 14:08:51 | Train | Epoch[142/600] Iteration[014/030] Train loss: 0.0266
2023-02-06 14:08:51 | Train | Epoch[142/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 14:08:52 | Train | Epoch[142/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 14:08:52 | Train | Epoch[142/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 14:08:52 | Train | Epoch[142/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 14:08:52 | Train | Epoch[142/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 14:08:52 | Train | Epoch[142/600] Iteration[020/030] Train loss: 0.0265
2023-02-06 14:08:53 | Train | Epoch[142/600] Iteration[021/030] Train loss: 0.0265
2023-02-06 14:08:53 | Train | Epoch[142/600] Iteration[022/030] Train loss: 0.0264
2023-02-06 14:08:53 | Train | Epoch[142/600] Iteration[023/030] Train loss: 0.0264
2023-02-06 14:08:53 | Train | Epoch[142/600] Iteration[024/030] Train loss: 0.0263
2023-02-06 14:08:53 | Train | Epoch[142/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 14:08:54 | Train | Epoch[142/600] Iteration[026/030] Train loss: 0.0264
2023-02-06 14:08:54 | Train | Epoch[142/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 14:08:54 | Train | Epoch[142/600] Iteration[028/030] Train loss: 0.0264
2023-02-06 14:08:54 | Train | Epoch[142/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 14:08:54 | Train | Epoch[142/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 14:08:55 | Valid | Epoch[142/600] Iteration[001/008] Valid loss: 0.2234
2023-02-06 14:08:55 | Valid | Epoch[142/600] Iteration[002/008] Valid loss: 0.1655
2023-02-06 14:08:55 | Valid | Epoch[142/600] Iteration[003/008] Valid loss: 0.1529
2023-02-06 14:08:55 | Valid | Epoch[142/600] Iteration[004/008] Valid loss: 0.1464
2023-02-06 14:08:55 | Valid | Epoch[142/600] Iteration[005/008] Valid loss: 0.1495
2023-02-06 14:08:55 | Valid | Epoch[142/600] Iteration[006/008] Valid loss: 0.1458
2023-02-06 14:08:55 | Valid | Epoch[142/600] Iteration[007/008] Valid loss: 0.1638
2023-02-06 14:08:55 | Valid | Epoch[142/600] Iteration[008/008] Valid loss: 0.1610
2023-02-06 14:08:55 | Valid | Epoch[142/600] MIou: 0.9186797055087337
2023-02-06 14:08:55 | Valid | Epoch[142/600] Pixel Accuracy: 0.985205332438151
2023-02-06 14:08:55 | Valid | Epoch[142/600] Mean Pixel Accuracy: 0.9714709228763365
2023-02-06 14:08:55 | Stage | Epoch[142/600] Train loss:0.0263
2023-02-06 14:08:55 | Stage | Epoch[142/600] Valid loss:0.1610
2023-02-06 14:08:55 | Stage | Epoch[142/600] LR:0.01

2023-02-06 14:08:56 | Train | Epoch[143/600] Iteration[001/030] Train loss: 0.0255
2023-02-06 14:08:56 | Train | Epoch[143/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 14:08:56 | Train | Epoch[143/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 14:08:56 | Train | Epoch[143/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 14:08:57 | Train | Epoch[143/600] Iteration[005/030] Train loss: 0.0257
2023-02-06 14:08:57 | Train | Epoch[143/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 14:08:57 | Train | Epoch[143/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 14:08:57 | Train | Epoch[143/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 14:08:58 | Train | Epoch[143/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 14:08:58 | Train | Epoch[143/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 14:08:58 | Train | Epoch[143/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 14:08:58 | Train | Epoch[143/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 14:08:58 | Train | Epoch[143/600] Iteration[013/030] Train loss: 0.0258
2023-02-06 14:08:59 | Train | Epoch[143/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 14:08:59 | Train | Epoch[143/600] Iteration[015/030] Train loss: 0.0260
2023-02-06 14:08:59 | Train | Epoch[143/600] Iteration[016/030] Train loss: 0.0261
2023-02-06 14:08:59 | Train | Epoch[143/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 14:08:59 | Train | Epoch[143/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 14:09:00 | Train | Epoch[143/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 14:09:00 | Train | Epoch[143/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 14:09:00 | Train | Epoch[143/600] Iteration[021/030] Train loss: 0.0263
2023-02-06 14:09:00 | Train | Epoch[143/600] Iteration[022/030] Train loss: 0.0264
2023-02-06 14:09:01 | Train | Epoch[143/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 14:09:01 | Train | Epoch[143/600] Iteration[024/030] Train loss: 0.0265
2023-02-06 14:09:01 | Train | Epoch[143/600] Iteration[025/030] Train loss: 0.0265
2023-02-06 14:09:01 | Train | Epoch[143/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 14:09:01 | Train | Epoch[143/600] Iteration[027/030] Train loss: 0.0266
2023-02-06 14:09:02 | Train | Epoch[143/600] Iteration[028/030] Train loss: 0.0267
2023-02-06 14:09:02 | Train | Epoch[143/600] Iteration[029/030] Train loss: 0.0267
2023-02-06 14:09:02 | Train | Epoch[143/600] Iteration[030/030] Train loss: 0.0268
2023-02-06 14:09:02 | Valid | Epoch[143/600] Iteration[001/008] Valid loss: 0.1313
2023-02-06 14:09:02 | Valid | Epoch[143/600] Iteration[002/008] Valid loss: 0.1452
2023-02-06 14:09:02 | Valid | Epoch[143/600] Iteration[003/008] Valid loss: 0.1529
2023-02-06 14:09:02 | Valid | Epoch[143/600] Iteration[004/008] Valid loss: 0.1510
2023-02-06 14:09:03 | Valid | Epoch[143/600] Iteration[005/008] Valid loss: 0.1562
2023-02-06 14:09:03 | Valid | Epoch[143/600] Iteration[006/008] Valid loss: 0.1533
2023-02-06 14:09:03 | Valid | Epoch[143/600] Iteration[007/008] Valid loss: 0.1498
2023-02-06 14:09:03 | Valid | Epoch[143/600] Iteration[008/008] Valid loss: 0.1563
2023-02-06 14:09:03 | Valid | Epoch[143/600] MIou: 0.5610848729109671
2023-02-06 14:09:03 | Valid | Epoch[143/600] Pixel Accuracy: 0.9269561767578125
2023-02-06 14:09:03 | Valid | Epoch[143/600] Mean Pixel Accuracy: 0.5985909541586073
2023-02-06 14:09:03 | Stage | Epoch[143/600] Train loss:0.0268
2023-02-06 14:09:03 | Stage | Epoch[143/600] Valid loss:0.1563
2023-02-06 14:09:03 | Stage | Epoch[143/600] LR:0.01

2023-02-06 14:09:03 | Train | Epoch[144/600] Iteration[001/030] Train loss: 0.0266
2023-02-06 14:09:03 | Train | Epoch[144/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 14:09:04 | Train | Epoch[144/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 14:09:04 | Train | Epoch[144/600] Iteration[004/030] Train loss: 0.0269
2023-02-06 14:09:04 | Train | Epoch[144/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 14:09:04 | Train | Epoch[144/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 14:09:05 | Train | Epoch[144/600] Iteration[007/030] Train loss: 0.0263
2023-02-06 14:09:05 | Train | Epoch[144/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 14:09:05 | Train | Epoch[144/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 14:09:05 | Train | Epoch[144/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 14:09:05 | Train | Epoch[144/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 14:09:06 | Train | Epoch[144/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 14:09:06 | Train | Epoch[144/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 14:09:06 | Train | Epoch[144/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 14:09:06 | Train | Epoch[144/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 14:09:06 | Train | Epoch[144/600] Iteration[016/030] Train loss: 0.0266
2023-02-06 14:09:07 | Train | Epoch[144/600] Iteration[017/030] Train loss: 0.0266
2023-02-06 14:09:07 | Train | Epoch[144/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 14:09:07 | Train | Epoch[144/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 14:09:07 | Train | Epoch[144/600] Iteration[020/030] Train loss: 0.0265
2023-02-06 14:09:08 | Train | Epoch[144/600] Iteration[021/030] Train loss: 0.0265
2023-02-06 14:09:08 | Train | Epoch[144/600] Iteration[022/030] Train loss: 0.0264
2023-02-06 14:09:08 | Train | Epoch[144/600] Iteration[023/030] Train loss: 0.0264
2023-02-06 14:09:08 | Train | Epoch[144/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 14:09:08 | Train | Epoch[144/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 14:09:09 | Train | Epoch[144/600] Iteration[026/030] Train loss: 0.0264
2023-02-06 14:09:09 | Train | Epoch[144/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 14:09:09 | Train | Epoch[144/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 14:09:09 | Train | Epoch[144/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 14:09:09 | Train | Epoch[144/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 14:09:10 | Valid | Epoch[144/600] Iteration[001/008] Valid loss: 0.7215
2023-02-06 14:09:10 | Valid | Epoch[144/600] Iteration[002/008] Valid loss: 0.6502
2023-02-06 14:09:10 | Valid | Epoch[144/600] Iteration[003/008] Valid loss: 0.6389
2023-02-06 14:09:10 | Valid | Epoch[144/600] Iteration[004/008] Valid loss: 0.6295
2023-02-06 14:09:10 | Valid | Epoch[144/600] Iteration[005/008] Valid loss: 0.6527
2023-02-06 14:09:10 | Valid | Epoch[144/600] Iteration[006/008] Valid loss: 0.6446
2023-02-06 14:09:10 | Valid | Epoch[144/600] Iteration[007/008] Valid loss: 0.6958
2023-02-06 14:09:10 | Valid | Epoch[144/600] Iteration[008/008] Valid loss: 0.7046
2023-02-06 14:09:10 | Valid | Epoch[144/600] MIou: 0.8702282404092508
2023-02-06 14:09:10 | Valid | Epoch[144/600] Pixel Accuracy: 0.9731903076171875
2023-02-06 14:09:10 | Valid | Epoch[144/600] Mean Pixel Accuracy: 0.9822208233348824
2023-02-06 14:09:10 | Stage | Epoch[144/600] Train loss:0.0263
2023-02-06 14:09:10 | Stage | Epoch[144/600] Valid loss:0.7046
2023-02-06 14:09:10 | Stage | Epoch[144/600] LR:0.01

2023-02-06 14:09:11 | Train | Epoch[145/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 14:09:11 | Train | Epoch[145/600] Iteration[002/030] Train loss: 0.0244
2023-02-06 14:09:11 | Train | Epoch[145/600] Iteration[003/030] Train loss: 0.0245
2023-02-06 14:09:11 | Train | Epoch[145/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 14:09:12 | Train | Epoch[145/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 14:09:12 | Train | Epoch[145/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 14:09:12 | Train | Epoch[145/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 14:09:12 | Train | Epoch[145/600] Iteration[008/030] Train loss: 0.0251
2023-02-06 14:09:12 | Train | Epoch[145/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 14:09:13 | Train | Epoch[145/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 14:09:13 | Train | Epoch[145/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 14:09:13 | Train | Epoch[145/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 14:09:13 | Train | Epoch[145/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 14:09:14 | Train | Epoch[145/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 14:09:14 | Train | Epoch[145/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 14:09:14 | Train | Epoch[145/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 14:09:14 | Train | Epoch[145/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 14:09:14 | Train | Epoch[145/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 14:09:15 | Train | Epoch[145/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 14:09:15 | Train | Epoch[145/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 14:09:15 | Train | Epoch[145/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 14:09:15 | Train | Epoch[145/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 14:09:16 | Train | Epoch[145/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 14:09:16 | Train | Epoch[145/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 14:09:16 | Train | Epoch[145/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 14:09:16 | Train | Epoch[145/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 14:09:16 | Train | Epoch[145/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 14:09:17 | Train | Epoch[145/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 14:09:17 | Train | Epoch[145/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 14:09:17 | Train | Epoch[145/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 14:09:17 | Valid | Epoch[145/600] Iteration[001/008] Valid loss: 0.0739
2023-02-06 14:09:17 | Valid | Epoch[145/600] Iteration[002/008] Valid loss: 0.0728
2023-02-06 14:09:17 | Valid | Epoch[145/600] Iteration[003/008] Valid loss: 0.0728
2023-02-06 14:09:17 | Valid | Epoch[145/600] Iteration[004/008] Valid loss: 0.0704
2023-02-06 14:09:17 | Valid | Epoch[145/600] Iteration[005/008] Valid loss: 0.0692
2023-02-06 14:09:18 | Valid | Epoch[145/600] Iteration[006/008] Valid loss: 0.0682
2023-02-06 14:09:18 | Valid | Epoch[145/600] Iteration[007/008] Valid loss: 0.0688
2023-02-06 14:09:18 | Valid | Epoch[145/600] Iteration[008/008] Valid loss: 0.0688
2023-02-06 14:09:18 | Valid | Epoch[145/600] MIou: 0.8294235293666405
2023-02-06 14:09:18 | Valid | Epoch[145/600] Pixel Accuracy: 0.9717000325520834
2023-02-06 14:09:18 | Valid | Epoch[145/600] Mean Pixel Accuracy: 0.8467744729844164
2023-02-06 14:09:18 | Stage | Epoch[145/600] Train loss:0.0254
2023-02-06 14:09:18 | Stage | Epoch[145/600] Valid loss:0.0688
2023-02-06 14:09:18 | Stage | Epoch[145/600] LR:0.01

2023-02-06 14:09:18 | Train | Epoch[146/600] Iteration[001/030] Train loss: 0.0275
2023-02-06 14:09:18 | Train | Epoch[146/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 14:09:19 | Train | Epoch[146/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 14:09:19 | Train | Epoch[146/600] Iteration[004/030] Train loss: 0.0250
2023-02-06 14:09:19 | Train | Epoch[146/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 14:09:19 | Train | Epoch[146/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 14:09:20 | Train | Epoch[146/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 14:09:20 | Train | Epoch[146/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 14:09:20 | Train | Epoch[146/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 14:09:20 | Train | Epoch[146/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 14:09:20 | Train | Epoch[146/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 14:09:21 | Train | Epoch[146/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 14:09:21 | Train | Epoch[146/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 14:09:21 | Train | Epoch[146/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 14:09:21 | Train | Epoch[146/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 14:09:21 | Train | Epoch[146/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 14:09:22 | Train | Epoch[146/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 14:09:22 | Train | Epoch[146/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 14:09:22 | Train | Epoch[146/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 14:09:22 | Train | Epoch[146/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 14:09:23 | Train | Epoch[146/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 14:09:23 | Train | Epoch[146/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 14:09:23 | Train | Epoch[146/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 14:09:23 | Train | Epoch[146/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 14:09:23 | Train | Epoch[146/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 14:09:24 | Train | Epoch[146/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 14:09:24 | Train | Epoch[146/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 14:09:24 | Train | Epoch[146/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 14:09:24 | Train | Epoch[146/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 14:09:24 | Train | Epoch[146/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 14:09:25 | Valid | Epoch[146/600] Iteration[001/008] Valid loss: 0.2228
2023-02-06 14:09:25 | Valid | Epoch[146/600] Iteration[002/008] Valid loss: 0.1692
2023-02-06 14:09:25 | Valid | Epoch[146/600] Iteration[003/008] Valid loss: 0.1727
2023-02-06 14:09:25 | Valid | Epoch[146/600] Iteration[004/008] Valid loss: 0.1701
2023-02-06 14:09:25 | Valid | Epoch[146/600] Iteration[005/008] Valid loss: 0.1761
2023-02-06 14:09:25 | Valid | Epoch[146/600] Iteration[006/008] Valid loss: 0.1711
2023-02-06 14:09:25 | Valid | Epoch[146/600] Iteration[007/008] Valid loss: 0.1852
2023-02-06 14:09:25 | Valid | Epoch[146/600] Iteration[008/008] Valid loss: 0.1831
2023-02-06 14:09:25 | Valid | Epoch[146/600] MIou: 0.9139159851927527
2023-02-06 14:09:25 | Valid | Epoch[146/600] Pixel Accuracy: 0.984167734781901
2023-02-06 14:09:25 | Valid | Epoch[146/600] Mean Pixel Accuracy: 0.9718516856788038
2023-02-06 14:09:25 | Stage | Epoch[146/600] Train loss:0.0251
2023-02-06 14:09:25 | Stage | Epoch[146/600] Valid loss:0.1831
2023-02-06 14:09:25 | Stage | Epoch[146/600] LR:0.01

2023-02-06 14:09:26 | Train | Epoch[147/600] Iteration[001/030] Train loss: 0.0247
2023-02-06 14:09:26 | Train | Epoch[147/600] Iteration[002/030] Train loss: 0.0246
2023-02-06 14:09:26 | Train | Epoch[147/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 14:09:26 | Train | Epoch[147/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 14:09:26 | Train | Epoch[147/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 14:09:27 | Train | Epoch[147/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 14:09:27 | Train | Epoch[147/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 14:09:27 | Train | Epoch[147/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 14:09:27 | Train | Epoch[147/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 14:09:28 | Train | Epoch[147/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 14:09:28 | Train | Epoch[147/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 14:09:28 | Train | Epoch[147/600] Iteration[012/030] Train loss: 0.0247
2023-02-06 14:09:28 | Train | Epoch[147/600] Iteration[013/030] Train loss: 0.0247
2023-02-06 14:09:28 | Train | Epoch[147/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 14:09:29 | Train | Epoch[147/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 14:09:29 | Train | Epoch[147/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 14:09:29 | Train | Epoch[147/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 14:09:29 | Train | Epoch[147/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 14:09:30 | Train | Epoch[147/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 14:09:30 | Train | Epoch[147/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 14:09:30 | Train | Epoch[147/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 14:09:30 | Train | Epoch[147/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 14:09:30 | Train | Epoch[147/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 14:09:31 | Train | Epoch[147/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 14:09:31 | Train | Epoch[147/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 14:09:31 | Train | Epoch[147/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 14:09:31 | Train | Epoch[147/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 14:09:32 | Train | Epoch[147/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 14:09:32 | Train | Epoch[147/600] Iteration[029/030] Train loss: 0.0248
2023-02-06 14:09:32 | Train | Epoch[147/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 14:09:32 | Valid | Epoch[147/600] Iteration[001/008] Valid loss: 0.0786
2023-02-06 14:09:32 | Valid | Epoch[147/600] Iteration[002/008] Valid loss: 0.0768
2023-02-06 14:09:32 | Valid | Epoch[147/600] Iteration[003/008] Valid loss: 0.0776
2023-02-06 14:09:32 | Valid | Epoch[147/600] Iteration[004/008] Valid loss: 0.0747
2023-02-06 14:09:32 | Valid | Epoch[147/600] Iteration[005/008] Valid loss: 0.0735
2023-02-06 14:09:32 | Valid | Epoch[147/600] Iteration[006/008] Valid loss: 0.0722
2023-02-06 14:09:33 | Valid | Epoch[147/600] Iteration[007/008] Valid loss: 0.0726
2023-02-06 14:09:33 | Valid | Epoch[147/600] Iteration[008/008] Valid loss: 0.0730
2023-02-06 14:09:33 | Valid | Epoch[147/600] MIou: 0.8311659835591259
2023-02-06 14:09:33 | Valid | Epoch[147/600] Pixel Accuracy: 0.97174072265625
2023-02-06 14:09:33 | Valid | Epoch[147/600] Mean Pixel Accuracy: 0.8514634250339481
2023-02-06 14:09:33 | Stage | Epoch[147/600] Train loss:0.0249
2023-02-06 14:09:33 | Stage | Epoch[147/600] Valid loss:0.0730
2023-02-06 14:09:33 | Stage | Epoch[147/600] LR:0.01

2023-02-06 14:09:33 | Train | Epoch[148/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 14:09:33 | Train | Epoch[148/600] Iteration[002/030] Train loss: 0.0247
2023-02-06 14:09:34 | Train | Epoch[148/600] Iteration[003/030] Train loss: 0.0245
2023-02-06 14:09:34 | Train | Epoch[148/600] Iteration[004/030] Train loss: 0.0246
2023-02-06 14:09:34 | Train | Epoch[148/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 14:09:34 | Train | Epoch[148/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 14:09:34 | Train | Epoch[148/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 14:09:35 | Train | Epoch[148/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 14:09:35 | Train | Epoch[148/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 14:09:35 | Train | Epoch[148/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 14:09:35 | Train | Epoch[148/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 14:09:36 | Train | Epoch[148/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 14:09:36 | Train | Epoch[148/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 14:09:36 | Train | Epoch[148/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 14:09:36 | Train | Epoch[148/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 14:09:36 | Train | Epoch[148/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 14:09:37 | Train | Epoch[148/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 14:09:37 | Train | Epoch[148/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 14:09:37 | Train | Epoch[148/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 14:09:37 | Train | Epoch[148/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 14:09:38 | Train | Epoch[148/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 14:09:38 | Train | Epoch[148/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 14:09:38 | Train | Epoch[148/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 14:09:38 | Train | Epoch[148/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 14:09:38 | Train | Epoch[148/600] Iteration[025/030] Train loss: 0.0247
2023-02-06 14:09:39 | Train | Epoch[148/600] Iteration[026/030] Train loss: 0.0247
2023-02-06 14:09:39 | Train | Epoch[148/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 14:09:39 | Train | Epoch[148/600] Iteration[028/030] Train loss: 0.0248
2023-02-06 14:09:39 | Train | Epoch[148/600] Iteration[029/030] Train loss: 0.0248
2023-02-06 14:09:39 | Train | Epoch[148/600] Iteration[030/030] Train loss: 0.0248
2023-02-06 14:09:40 | Valid | Epoch[148/600] Iteration[001/008] Valid loss: 0.0825
2023-02-06 14:09:40 | Valid | Epoch[148/600] Iteration[002/008] Valid loss: 0.0653
2023-02-06 14:09:40 | Valid | Epoch[148/600] Iteration[003/008] Valid loss: 0.0617
2023-02-06 14:09:40 | Valid | Epoch[148/600] Iteration[004/008] Valid loss: 0.0575
2023-02-06 14:09:40 | Valid | Epoch[148/600] Iteration[005/008] Valid loss: 0.0573
2023-02-06 14:09:40 | Valid | Epoch[148/600] Iteration[006/008] Valid loss: 0.0557
2023-02-06 14:09:40 | Valid | Epoch[148/600] Iteration[007/008] Valid loss: 0.0553
2023-02-06 14:09:40 | Valid | Epoch[148/600] Iteration[008/008] Valid loss: 0.0544
2023-02-06 14:09:40 | Valid | Epoch[148/600] MIou: 0.902917595324014
2023-02-06 14:09:40 | Valid | Epoch[148/600] Pixel Accuracy: 0.9837786356608073
2023-02-06 14:09:40 | Valid | Epoch[148/600] Mean Pixel Accuracy: 0.917813557541129
2023-02-06 14:09:40 | Stage | Epoch[148/600] Train loss:0.0248
2023-02-06 14:09:40 | Stage | Epoch[148/600] Valid loss:0.0544
2023-02-06 14:09:40 | Stage | Epoch[148/600] LR:0.01

2023-02-06 14:09:41 | Train | Epoch[149/600] Iteration[001/030] Train loss: 0.0257
2023-02-06 14:09:41 | Train | Epoch[149/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 14:09:41 | Train | Epoch[149/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 14:09:41 | Train | Epoch[149/600] Iteration[004/030] Train loss: 0.0243
2023-02-06 14:09:42 | Train | Epoch[149/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 14:09:42 | Train | Epoch[149/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 14:09:42 | Train | Epoch[149/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 14:09:42 | Train | Epoch[149/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 14:09:42 | Train | Epoch[149/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 14:09:43 | Train | Epoch[149/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 14:09:43 | Train | Epoch[149/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 14:09:43 | Train | Epoch[149/600] Iteration[012/030] Train loss: 0.0242
2023-02-06 14:09:43 | Train | Epoch[149/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 14:09:44 | Train | Epoch[149/600] Iteration[014/030] Train loss: 0.0243
2023-02-06 14:09:44 | Train | Epoch[149/600] Iteration[015/030] Train loss: 0.0244
2023-02-06 14:09:44 | Train | Epoch[149/600] Iteration[016/030] Train loss: 0.0244
2023-02-06 14:09:44 | Train | Epoch[149/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 14:09:44 | Train | Epoch[149/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 14:09:45 | Train | Epoch[149/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 14:09:45 | Train | Epoch[149/600] Iteration[020/030] Train loss: 0.0246
2023-02-06 14:09:45 | Train | Epoch[149/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 14:09:45 | Train | Epoch[149/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 14:09:46 | Train | Epoch[149/600] Iteration[023/030] Train loss: 0.0246
2023-02-06 14:09:46 | Train | Epoch[149/600] Iteration[024/030] Train loss: 0.0245
2023-02-06 14:09:46 | Train | Epoch[149/600] Iteration[025/030] Train loss: 0.0245
2023-02-06 14:09:46 | Train | Epoch[149/600] Iteration[026/030] Train loss: 0.0245
2023-02-06 14:09:46 | Train | Epoch[149/600] Iteration[027/030] Train loss: 0.0246
2023-02-06 14:09:47 | Train | Epoch[149/600] Iteration[028/030] Train loss: 0.0246
2023-02-06 14:09:47 | Train | Epoch[149/600] Iteration[029/030] Train loss: 0.0245
2023-02-06 14:09:47 | Train | Epoch[149/600] Iteration[030/030] Train loss: 0.0246
2023-02-06 14:09:47 | Valid | Epoch[149/600] Iteration[001/008] Valid loss: 0.2994
2023-02-06 14:09:47 | Valid | Epoch[149/600] Iteration[002/008] Valid loss: 0.2439
2023-02-06 14:09:47 | Valid | Epoch[149/600] Iteration[003/008] Valid loss: 0.2521
2023-02-06 14:09:47 | Valid | Epoch[149/600] Iteration[004/008] Valid loss: 0.2424
2023-02-06 14:09:47 | Valid | Epoch[149/600] Iteration[005/008] Valid loss: 0.2493
2023-02-06 14:09:47 | Valid | Epoch[149/600] Iteration[006/008] Valid loss: 0.2374
2023-02-06 14:09:48 | Valid | Epoch[149/600] Iteration[007/008] Valid loss: 0.2580
2023-02-06 14:09:48 | Valid | Epoch[149/600] Iteration[008/008] Valid loss: 0.2588
2023-02-06 14:09:48 | Valid | Epoch[149/600] MIou: 0.9155541719016523
2023-02-06 14:09:48 | Valid | Epoch[149/600] Pixel Accuracy: 0.9844144185384115
2023-02-06 14:09:48 | Valid | Epoch[149/600] Mean Pixel Accuracy: 0.9752526164209108
2023-02-06 14:09:48 | Stage | Epoch[149/600] Train loss:0.0246
2023-02-06 14:09:48 | Stage | Epoch[149/600] Valid loss:0.2588
2023-02-06 14:09:48 | Stage | Epoch[149/600] LR:0.01

2023-02-06 14:09:48 | Train | Epoch[150/600] Iteration[001/030] Train loss: 0.0230
2023-02-06 14:09:48 | Train | Epoch[150/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 14:09:49 | Train | Epoch[150/600] Iteration[003/030] Train loss: 0.0238
2023-02-06 14:09:49 | Train | Epoch[150/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 14:09:49 | Train | Epoch[150/600] Iteration[005/030] Train loss: 0.0236
2023-02-06 14:09:49 | Train | Epoch[150/600] Iteration[006/030] Train loss: 0.0241
2023-02-06 14:09:49 | Train | Epoch[150/600] Iteration[007/030] Train loss: 0.0241
2023-02-06 14:09:50 | Train | Epoch[150/600] Iteration[008/030] Train loss: 0.0240
2023-02-06 14:09:50 | Train | Epoch[150/600] Iteration[009/030] Train loss: 0.0240
2023-02-06 14:09:50 | Train | Epoch[150/600] Iteration[010/030] Train loss: 0.0239
2023-02-06 14:09:50 | Train | Epoch[150/600] Iteration[011/030] Train loss: 0.0239
2023-02-06 14:09:51 | Train | Epoch[150/600] Iteration[012/030] Train loss: 0.0239
2023-02-06 14:09:51 | Train | Epoch[150/600] Iteration[013/030] Train loss: 0.0240
2023-02-06 14:09:51 | Train | Epoch[150/600] Iteration[014/030] Train loss: 0.0239
2023-02-06 14:09:51 | Train | Epoch[150/600] Iteration[015/030] Train loss: 0.0239
2023-02-06 14:09:51 | Train | Epoch[150/600] Iteration[016/030] Train loss: 0.0238
2023-02-06 14:09:52 | Train | Epoch[150/600] Iteration[017/030] Train loss: 0.0238
2023-02-06 14:09:52 | Train | Epoch[150/600] Iteration[018/030] Train loss: 0.0239
2023-02-06 14:09:52 | Train | Epoch[150/600] Iteration[019/030] Train loss: 0.0240
2023-02-06 14:09:52 | Train | Epoch[150/600] Iteration[020/030] Train loss: 0.0240
2023-02-06 14:09:53 | Train | Epoch[150/600] Iteration[021/030] Train loss: 0.0241
2023-02-06 14:09:53 | Train | Epoch[150/600] Iteration[022/030] Train loss: 0.0240
2023-02-06 14:09:53 | Train | Epoch[150/600] Iteration[023/030] Train loss: 0.0240
2023-02-06 14:09:53 | Train | Epoch[150/600] Iteration[024/030] Train loss: 0.0240
2023-02-06 14:09:53 | Train | Epoch[150/600] Iteration[025/030] Train loss: 0.0241
2023-02-06 14:09:54 | Train | Epoch[150/600] Iteration[026/030] Train loss: 0.0242
2023-02-06 14:09:54 | Train | Epoch[150/600] Iteration[027/030] Train loss: 0.0242
2023-02-06 14:09:54 | Train | Epoch[150/600] Iteration[028/030] Train loss: 0.0243
2023-02-06 14:09:54 | Train | Epoch[150/600] Iteration[029/030] Train loss: 0.0244
2023-02-06 14:09:54 | Train | Epoch[150/600] Iteration[030/030] Train loss: 0.0244
2023-02-06 14:09:55 | Valid | Epoch[150/600] Iteration[001/008] Valid loss: 2.6361
2023-02-06 14:09:55 | Valid | Epoch[150/600] Iteration[002/008] Valid loss: 2.5090
2023-02-06 14:09:55 | Valid | Epoch[150/600] Iteration[003/008] Valid loss: 2.6634
2023-02-06 14:09:55 | Valid | Epoch[150/600] Iteration[004/008] Valid loss: 2.7615
2023-02-06 14:09:55 | Valid | Epoch[150/600] Iteration[005/008] Valid loss: 2.9075
2023-02-06 14:09:55 | Valid | Epoch[150/600] Iteration[006/008] Valid loss: 2.8765
2023-02-06 14:09:55 | Valid | Epoch[150/600] Iteration[007/008] Valid loss: 2.9588
2023-02-06 14:09:55 | Valid | Epoch[150/600] Iteration[008/008] Valid loss: 3.0354
2023-02-06 14:09:55 | Valid | Epoch[150/600] MIou: 0.7435182853853944
2023-02-06 14:09:55 | Valid | Epoch[150/600] Pixel Accuracy: 0.9301986694335938
2023-02-06 14:09:55 | Valid | Epoch[150/600] Mean Pixel Accuracy: 0.9610699098013806
2023-02-06 14:09:55 | Stage | Epoch[150/600] Train loss:0.0244
2023-02-06 14:09:55 | Stage | Epoch[150/600] Valid loss:3.0354
2023-02-06 14:09:55 | Stage | Epoch[150/600] LR:0.01

2023-02-06 14:09:56 | Train | Epoch[151/600] Iteration[001/030] Train loss: 0.0257
2023-02-06 14:09:56 | Train | Epoch[151/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 14:09:56 | Train | Epoch[151/600] Iteration[003/030] Train loss: 0.0244
2023-02-06 14:09:56 | Train | Epoch[151/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 14:09:56 | Train | Epoch[151/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 14:09:57 | Train | Epoch[151/600] Iteration[006/030] Train loss: 0.0246
2023-02-06 14:09:57 | Train | Epoch[151/600] Iteration[007/030] Train loss: 0.0244
2023-02-06 14:09:57 | Train | Epoch[151/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 14:09:57 | Train | Epoch[151/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 14:09:58 | Train | Epoch[151/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 14:09:58 | Train | Epoch[151/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 14:09:58 | Train | Epoch[151/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 14:09:58 | Train | Epoch[151/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 14:09:58 | Train | Epoch[151/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 14:09:59 | Train | Epoch[151/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 14:09:59 | Train | Epoch[151/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 14:09:59 | Train | Epoch[151/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 14:09:59 | Train | Epoch[151/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 14:10:00 | Train | Epoch[151/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 14:10:00 | Train | Epoch[151/600] Iteration[020/030] Train loss: 0.0246
2023-02-06 14:10:00 | Train | Epoch[151/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 14:10:00 | Train | Epoch[151/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 14:10:00 | Train | Epoch[151/600] Iteration[023/030] Train loss: 0.0246
2023-02-06 14:10:01 | Train | Epoch[151/600] Iteration[024/030] Train loss: 0.0246
2023-02-06 14:10:01 | Train | Epoch[151/600] Iteration[025/030] Train loss: 0.0245
2023-02-06 14:10:01 | Train | Epoch[151/600] Iteration[026/030] Train loss: 0.0245
2023-02-06 14:10:01 | Train | Epoch[151/600] Iteration[027/030] Train loss: 0.0246
2023-02-06 14:10:02 | Train | Epoch[151/600] Iteration[028/030] Train loss: 0.0246
2023-02-06 14:10:02 | Train | Epoch[151/600] Iteration[029/030] Train loss: 0.0247
2023-02-06 14:10:02 | Train | Epoch[151/600] Iteration[030/030] Train loss: 0.0247
2023-02-06 14:10:02 | Valid | Epoch[151/600] Iteration[001/008] Valid loss: 0.2015
2023-02-06 14:10:02 | Valid | Epoch[151/600] Iteration[002/008] Valid loss: 0.1799
2023-02-06 14:10:02 | Valid | Epoch[151/600] Iteration[003/008] Valid loss: 0.1745
2023-02-06 14:10:02 | Valid | Epoch[151/600] Iteration[004/008] Valid loss: 0.1719
2023-02-06 14:10:02 | Valid | Epoch[151/600] Iteration[005/008] Valid loss: 0.1675
2023-02-06 14:10:02 | Valid | Epoch[151/600] Iteration[006/008] Valid loss: 0.1677
2023-02-06 14:10:03 | Valid | Epoch[151/600] Iteration[007/008] Valid loss: 0.1844
2023-02-06 14:10:03 | Valid | Epoch[151/600] Iteration[008/008] Valid loss: 0.1844
2023-02-06 14:10:03 | Valid | Epoch[151/600] MIou: 0.9065066360256266
2023-02-06 14:10:03 | Valid | Epoch[151/600] Pixel Accuracy: 0.9827740987141927
2023-02-06 14:10:03 | Valid | Epoch[151/600] Mean Pixel Accuracy: 0.965081257336911
2023-02-06 14:10:03 | Stage | Epoch[151/600] Train loss:0.0247
2023-02-06 14:10:03 | Stage | Epoch[151/600] Valid loss:0.1844
2023-02-06 14:10:03 | Stage | Epoch[151/600] LR:0.01

2023-02-06 14:10:03 | Train | Epoch[152/600] Iteration[001/030] Train loss: 0.0252
2023-02-06 14:10:03 | Train | Epoch[152/600] Iteration[002/030] Train loss: 0.0259
2023-02-06 14:10:04 | Train | Epoch[152/600] Iteration[003/030] Train loss: 0.0249
2023-02-06 14:10:04 | Train | Epoch[152/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 14:10:04 | Train | Epoch[152/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 14:10:04 | Train | Epoch[152/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 14:10:04 | Train | Epoch[152/600] Iteration[007/030] Train loss: 0.0241
2023-02-06 14:10:05 | Train | Epoch[152/600] Iteration[008/030] Train loss: 0.0242
2023-02-06 14:10:05 | Train | Epoch[152/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 14:10:05 | Train | Epoch[152/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 14:10:05 | Train | Epoch[152/600] Iteration[011/030] Train loss: 0.0240
2023-02-06 14:10:06 | Train | Epoch[152/600] Iteration[012/030] Train loss: 0.0240
2023-02-06 14:10:06 | Train | Epoch[152/600] Iteration[013/030] Train loss: 0.0239
2023-02-06 14:10:06 | Train | Epoch[152/600] Iteration[014/030] Train loss: 0.0241
2023-02-06 14:10:06 | Train | Epoch[152/600] Iteration[015/030] Train loss: 0.0241
2023-02-06 14:10:06 | Train | Epoch[152/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 14:10:07 | Train | Epoch[152/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 14:10:07 | Train | Epoch[152/600] Iteration[018/030] Train loss: 0.0243
2023-02-06 14:10:07 | Train | Epoch[152/600] Iteration[019/030] Train loss: 0.0241
2023-02-06 14:10:07 | Train | Epoch[152/600] Iteration[020/030] Train loss: 0.0241
2023-02-06 14:10:08 | Train | Epoch[152/600] Iteration[021/030] Train loss: 0.0240
2023-02-06 14:10:08 | Train | Epoch[152/600] Iteration[022/030] Train loss: 0.0240
2023-02-06 14:10:08 | Train | Epoch[152/600] Iteration[023/030] Train loss: 0.0240
2023-02-06 14:10:08 | Train | Epoch[152/600] Iteration[024/030] Train loss: 0.0244
2023-02-06 14:10:08 | Train | Epoch[152/600] Iteration[025/030] Train loss: 0.0243
2023-02-06 14:10:09 | Train | Epoch[152/600] Iteration[026/030] Train loss: 0.0243
2023-02-06 14:10:09 | Train | Epoch[152/600] Iteration[027/030] Train loss: 0.0243
2023-02-06 14:10:09 | Train | Epoch[152/600] Iteration[028/030] Train loss: 0.0243
2023-02-06 14:10:09 | Train | Epoch[152/600] Iteration[029/030] Train loss: 0.0243
2023-02-06 14:10:09 | Train | Epoch[152/600] Iteration[030/030] Train loss: 0.0243
2023-02-06 14:10:10 | Valid | Epoch[152/600] Iteration[001/008] Valid loss: 0.9193
2023-02-06 14:10:10 | Valid | Epoch[152/600] Iteration[002/008] Valid loss: 0.8363
2023-02-06 14:10:10 | Valid | Epoch[152/600] Iteration[003/008] Valid loss: 0.8872
2023-02-06 14:10:10 | Valid | Epoch[152/600] Iteration[004/008] Valid loss: 0.8836
2023-02-06 14:10:10 | Valid | Epoch[152/600] Iteration[005/008] Valid loss: 0.9239
2023-02-06 14:10:10 | Valid | Epoch[152/600] Iteration[006/008] Valid loss: 0.9080
2023-02-06 14:10:10 | Valid | Epoch[152/600] Iteration[007/008] Valid loss: 0.9644
2023-02-06 14:10:10 | Valid | Epoch[152/600] Iteration[008/008] Valid loss: 1.0041
2023-02-06 14:10:10 | Valid | Epoch[152/600] MIou: 0.8472568005188763
2023-02-06 14:10:10 | Valid | Epoch[152/600] Pixel Accuracy: 0.9670270284016927
2023-02-06 14:10:10 | Valid | Epoch[152/600] Mean Pixel Accuracy: 0.9776919373483711
2023-02-06 14:10:10 | Stage | Epoch[152/600] Train loss:0.0243
2023-02-06 14:10:10 | Stage | Epoch[152/600] Valid loss:1.0041
2023-02-06 14:10:10 | Stage | Epoch[152/600] LR:0.01

2023-02-06 14:10:11 | Train | Epoch[153/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 14:10:11 | Train | Epoch[153/600] Iteration[002/030] Train loss: 0.0232
2023-02-06 14:10:11 | Train | Epoch[153/600] Iteration[003/030] Train loss: 0.0237
2023-02-06 14:10:11 | Train | Epoch[153/600] Iteration[004/030] Train loss: 0.0239
2023-02-06 14:10:12 | Train | Epoch[153/600] Iteration[005/030] Train loss: 0.0241
2023-02-06 14:10:12 | Train | Epoch[153/600] Iteration[006/030] Train loss: 0.0242
2023-02-06 14:10:12 | Train | Epoch[153/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 14:10:12 | Train | Epoch[153/600] Iteration[008/030] Train loss: 0.0243
2023-02-06 14:10:12 | Train | Epoch[153/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 14:10:13 | Train | Epoch[153/600] Iteration[010/030] Train loss: 0.0244
2023-02-06 14:10:13 | Train | Epoch[153/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 14:10:13 | Train | Epoch[153/600] Iteration[012/030] Train loss: 0.0241
2023-02-06 14:10:13 | Train | Epoch[153/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 14:10:13 | Train | Epoch[153/600] Iteration[014/030] Train loss: 0.0241
2023-02-06 14:10:14 | Train | Epoch[153/600] Iteration[015/030] Train loss: 0.0241
2023-02-06 14:10:14 | Train | Epoch[153/600] Iteration[016/030] Train loss: 0.0241
2023-02-06 14:10:14 | Train | Epoch[153/600] Iteration[017/030] Train loss: 0.0241
2023-02-06 14:10:14 | Train | Epoch[153/600] Iteration[018/030] Train loss: 0.0242
2023-02-06 14:10:15 | Train | Epoch[153/600] Iteration[019/030] Train loss: 0.0242
2023-02-06 14:10:15 | Train | Epoch[153/600] Iteration[020/030] Train loss: 0.0243
2023-02-06 14:10:15 | Train | Epoch[153/600] Iteration[021/030] Train loss: 0.0242
2023-02-06 14:10:15 | Train | Epoch[153/600] Iteration[022/030] Train loss: 0.0243
2023-02-06 14:10:15 | Train | Epoch[153/600] Iteration[023/030] Train loss: 0.0243
2023-02-06 14:10:16 | Train | Epoch[153/600] Iteration[024/030] Train loss: 0.0243
2023-02-06 14:10:16 | Train | Epoch[153/600] Iteration[025/030] Train loss: 0.0244
2023-02-06 14:10:16 | Train | Epoch[153/600] Iteration[026/030] Train loss: 0.0243
2023-02-06 14:10:16 | Train | Epoch[153/600] Iteration[027/030] Train loss: 0.0243
2023-02-06 14:10:17 | Train | Epoch[153/600] Iteration[028/030] Train loss: 0.0243
2023-02-06 14:10:17 | Train | Epoch[153/600] Iteration[029/030] Train loss: 0.0243
2023-02-06 14:10:17 | Train | Epoch[153/600] Iteration[030/030] Train loss: 0.0243
2023-02-06 14:10:17 | Valid | Epoch[153/600] Iteration[001/008] Valid loss: 0.1206
2023-02-06 14:10:17 | Valid | Epoch[153/600] Iteration[002/008] Valid loss: 0.1252
2023-02-06 14:10:17 | Valid | Epoch[153/600] Iteration[003/008] Valid loss: 0.1318
2023-02-06 14:10:17 | Valid | Epoch[153/600] Iteration[004/008] Valid loss: 0.1327
2023-02-06 14:10:17 | Valid | Epoch[153/600] Iteration[005/008] Valid loss: 0.1341
2023-02-06 14:10:17 | Valid | Epoch[153/600] Iteration[006/008] Valid loss: 0.1318
2023-02-06 14:10:18 | Valid | Epoch[153/600] Iteration[007/008] Valid loss: 0.1278
2023-02-06 14:10:18 | Valid | Epoch[153/600] Iteration[008/008] Valid loss: 0.1332
2023-02-06 14:10:18 | Valid | Epoch[153/600] MIou: 0.6106748738846327
2023-02-06 14:10:18 | Valid | Epoch[153/600] Pixel Accuracy: 0.9356117248535156
2023-02-06 14:10:18 | Valid | Epoch[153/600] Mean Pixel Accuracy: 0.6437752589032245
2023-02-06 14:10:18 | Stage | Epoch[153/600] Train loss:0.0243
2023-02-06 14:10:18 | Stage | Epoch[153/600] Valid loss:0.1332
2023-02-06 14:10:18 | Stage | Epoch[153/600] LR:0.01

2023-02-06 14:10:18 | Train | Epoch[154/600] Iteration[001/030] Train loss: 0.0240
2023-02-06 14:10:18 | Train | Epoch[154/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 14:10:19 | Train | Epoch[154/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 14:10:19 | Train | Epoch[154/600] Iteration[004/030] Train loss: 0.0240
2023-02-06 14:10:19 | Train | Epoch[154/600] Iteration[005/030] Train loss: 0.0239
2023-02-06 14:10:19 | Train | Epoch[154/600] Iteration[006/030] Train loss: 0.0242
2023-02-06 14:10:19 | Train | Epoch[154/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 14:10:20 | Train | Epoch[154/600] Iteration[008/030] Train loss: 0.0239
2023-02-06 14:10:20 | Train | Epoch[154/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 14:10:20 | Train | Epoch[154/600] Iteration[010/030] Train loss: 0.0240
2023-02-06 14:10:20 | Train | Epoch[154/600] Iteration[011/030] Train loss: 0.0239
2023-02-06 14:10:21 | Train | Epoch[154/600] Iteration[012/030] Train loss: 0.0239
2023-02-06 14:10:21 | Train | Epoch[154/600] Iteration[013/030] Train loss: 0.0238
2023-02-06 14:10:21 | Train | Epoch[154/600] Iteration[014/030] Train loss: 0.0240
2023-02-06 14:10:21 | Train | Epoch[154/600] Iteration[015/030] Train loss: 0.0239
2023-02-06 14:10:21 | Train | Epoch[154/600] Iteration[016/030] Train loss: 0.0240
2023-02-06 14:10:22 | Train | Epoch[154/600] Iteration[017/030] Train loss: 0.0241
2023-02-06 14:10:22 | Train | Epoch[154/600] Iteration[018/030] Train loss: 0.0240
2023-02-06 14:10:22 | Train | Epoch[154/600] Iteration[019/030] Train loss: 0.0241
2023-02-06 14:10:22 | Train | Epoch[154/600] Iteration[020/030] Train loss: 0.0241
2023-02-06 14:10:22 | Train | Epoch[154/600] Iteration[021/030] Train loss: 0.0240
2023-02-06 14:10:23 | Train | Epoch[154/600] Iteration[022/030] Train loss: 0.0241
2023-02-06 14:10:23 | Train | Epoch[154/600] Iteration[023/030] Train loss: 0.0241
2023-02-06 14:10:23 | Train | Epoch[154/600] Iteration[024/030] Train loss: 0.0241
2023-02-06 14:10:23 | Train | Epoch[154/600] Iteration[025/030] Train loss: 0.0241
2023-02-06 14:10:24 | Train | Epoch[154/600] Iteration[026/030] Train loss: 0.0241
2023-02-06 14:10:24 | Train | Epoch[154/600] Iteration[027/030] Train loss: 0.0240
2023-02-06 14:10:24 | Train | Epoch[154/600] Iteration[028/030] Train loss: 0.0240
2023-02-06 14:10:24 | Train | Epoch[154/600] Iteration[029/030] Train loss: 0.0240
2023-02-06 14:10:24 | Train | Epoch[154/600] Iteration[030/030] Train loss: 0.0240
2023-02-06 14:10:25 | Valid | Epoch[154/600] Iteration[001/008] Valid loss: 0.0922
2023-02-06 14:10:25 | Valid | Epoch[154/600] Iteration[002/008] Valid loss: 0.0898
2023-02-06 14:10:25 | Valid | Epoch[154/600] Iteration[003/008] Valid loss: 0.0933
2023-02-06 14:10:25 | Valid | Epoch[154/600] Iteration[004/008] Valid loss: 0.0923
2023-02-06 14:10:25 | Valid | Epoch[154/600] Iteration[005/008] Valid loss: 0.0942
2023-02-06 14:10:25 | Valid | Epoch[154/600] Iteration[006/008] Valid loss: 0.0927
2023-02-06 14:10:25 | Valid | Epoch[154/600] Iteration[007/008] Valid loss: 0.0901
2023-02-06 14:10:25 | Valid | Epoch[154/600] Iteration[008/008] Valid loss: 0.0910
2023-02-06 14:10:25 | Valid | Epoch[154/600] MIou: 0.7752765935126162
2023-02-06 14:10:25 | Valid | Epoch[154/600] Pixel Accuracy: 0.9629198710123698
2023-02-06 14:10:25 | Valid | Epoch[154/600] Mean Pixel Accuracy: 0.7950226920764545
2023-02-06 14:10:25 | Stage | Epoch[154/600] Train loss:0.0240
2023-02-06 14:10:25 | Stage | Epoch[154/600] Valid loss:0.0910
2023-02-06 14:10:25 | Stage | Epoch[154/600] LR:0.01

2023-02-06 14:10:26 | Train | Epoch[155/600] Iteration[001/030] Train loss: 0.0240
2023-02-06 14:10:26 | Train | Epoch[155/600] Iteration[002/030] Train loss: 0.0240
2023-02-06 14:10:26 | Train | Epoch[155/600] Iteration[003/030] Train loss: 0.0238
2023-02-06 14:10:26 | Train | Epoch[155/600] Iteration[004/030] Train loss: 0.0237
2023-02-06 14:10:27 | Train | Epoch[155/600] Iteration[005/030] Train loss: 0.0235
2023-02-06 14:10:27 | Train | Epoch[155/600] Iteration[006/030] Train loss: 0.0238
2023-02-06 14:10:27 | Train | Epoch[155/600] Iteration[007/030] Train loss: 0.0237
2023-02-06 14:10:27 | Train | Epoch[155/600] Iteration[008/030] Train loss: 0.0236
2023-02-06 14:10:27 | Train | Epoch[155/600] Iteration[009/030] Train loss: 0.0236
2023-02-06 14:10:28 | Train | Epoch[155/600] Iteration[010/030] Train loss: 0.0236
2023-02-06 14:10:28 | Train | Epoch[155/600] Iteration[011/030] Train loss: 0.0235
2023-02-06 14:10:28 | Train | Epoch[155/600] Iteration[012/030] Train loss: 0.0235
2023-02-06 14:10:28 | Train | Epoch[155/600] Iteration[013/030] Train loss: 0.0233
2023-02-06 14:10:28 | Train | Epoch[155/600] Iteration[014/030] Train loss: 0.0236
2023-02-06 14:10:29 | Train | Epoch[155/600] Iteration[015/030] Train loss: 0.0236
2023-02-06 14:10:29 | Train | Epoch[155/600] Iteration[016/030] Train loss: 0.0235
2023-02-06 14:10:29 | Train | Epoch[155/600] Iteration[017/030] Train loss: 0.0235
2023-02-06 14:10:29 | Train | Epoch[155/600] Iteration[018/030] Train loss: 0.0234
2023-02-06 14:10:30 | Train | Epoch[155/600] Iteration[019/030] Train loss: 0.0233
2023-02-06 14:10:30 | Train | Epoch[155/600] Iteration[020/030] Train loss: 0.0232
2023-02-06 14:10:30 | Train | Epoch[155/600] Iteration[021/030] Train loss: 0.0232
2023-02-06 14:10:30 | Train | Epoch[155/600] Iteration[022/030] Train loss: 0.0233
2023-02-06 14:10:30 | Train | Epoch[155/600] Iteration[023/030] Train loss: 0.0232
2023-02-06 14:10:31 | Train | Epoch[155/600] Iteration[024/030] Train loss: 0.0232
2023-02-06 14:10:31 | Train | Epoch[155/600] Iteration[025/030] Train loss: 0.0232
2023-02-06 14:10:31 | Train | Epoch[155/600] Iteration[026/030] Train loss: 0.0232
2023-02-06 14:10:31 | Train | Epoch[155/600] Iteration[027/030] Train loss: 0.0232
2023-02-06 14:10:32 | Train | Epoch[155/600] Iteration[028/030] Train loss: 0.0232
2023-02-06 14:10:32 | Train | Epoch[155/600] Iteration[029/030] Train loss: 0.0232
2023-02-06 14:10:32 | Train | Epoch[155/600] Iteration[030/030] Train loss: 0.0232
2023-02-06 14:10:32 | Valid | Epoch[155/600] Iteration[001/008] Valid loss: 0.0764
2023-02-06 14:10:32 | Valid | Epoch[155/600] Iteration[002/008] Valid loss: 0.0675
2023-02-06 14:10:32 | Valid | Epoch[155/600] Iteration[003/008] Valid loss: 0.0648
2023-02-06 14:10:32 | Valid | Epoch[155/600] Iteration[004/008] Valid loss: 0.0618
2023-02-06 14:10:32 | Valid | Epoch[155/600] Iteration[005/008] Valid loss: 0.0617
2023-02-06 14:10:32 | Valid | Epoch[155/600] Iteration[006/008] Valid loss: 0.0608
2023-02-06 14:10:33 | Valid | Epoch[155/600] Iteration[007/008] Valid loss: 0.0609
2023-02-06 14:10:33 | Valid | Epoch[155/600] Iteration[008/008] Valid loss: 0.0601
2023-02-06 14:10:33 | Valid | Epoch[155/600] MIou: 0.8973372039273801
2023-02-06 14:10:33 | Valid | Epoch[155/600] Pixel Accuracy: 0.9827219645182291
2023-02-06 14:10:33 | Valid | Epoch[155/600] Mean Pixel Accuracy: 0.9155969243651172
2023-02-06 14:10:33 | Stage | Epoch[155/600] Train loss:0.0232
2023-02-06 14:10:33 | Stage | Epoch[155/600] Valid loss:0.0601
2023-02-06 14:10:33 | Stage | Epoch[155/600] LR:0.01

2023-02-06 14:10:33 | Train | Epoch[156/600] Iteration[001/030] Train loss: 0.0213
2023-02-06 14:10:33 | Train | Epoch[156/600] Iteration[002/030] Train loss: 0.0232
2023-02-06 14:10:34 | Train | Epoch[156/600] Iteration[003/030] Train loss: 0.0234
2023-02-06 14:10:34 | Train | Epoch[156/600] Iteration[004/030] Train loss: 0.0231
2023-02-06 14:10:34 | Train | Epoch[156/600] Iteration[005/030] Train loss: 0.0235
2023-02-06 14:10:34 | Train | Epoch[156/600] Iteration[006/030] Train loss: 0.0236
2023-02-06 14:10:34 | Train | Epoch[156/600] Iteration[007/030] Train loss: 0.0236
2023-02-06 14:10:35 | Train | Epoch[156/600] Iteration[008/030] Train loss: 0.0237
2023-02-06 14:10:35 | Train | Epoch[156/600] Iteration[009/030] Train loss: 0.0236
2023-02-06 14:10:35 | Train | Epoch[156/600] Iteration[010/030] Train loss: 0.0237
2023-02-06 14:10:35 | Train | Epoch[156/600] Iteration[011/030] Train loss: 0.0239
2023-02-06 14:10:36 | Train | Epoch[156/600] Iteration[012/030] Train loss: 0.0240
2023-02-06 14:10:36 | Train | Epoch[156/600] Iteration[013/030] Train loss: 0.0240
2023-02-06 14:10:36 | Train | Epoch[156/600] Iteration[014/030] Train loss: 0.0240
2023-02-06 14:10:36 | Train | Epoch[156/600] Iteration[015/030] Train loss: 0.0242
2023-02-06 14:10:36 | Train | Epoch[156/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 14:10:37 | Train | Epoch[156/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 14:10:37 | Train | Epoch[156/600] Iteration[018/030] Train loss: 0.0242
2023-02-06 14:10:37 | Train | Epoch[156/600] Iteration[019/030] Train loss: 0.0242
2023-02-06 14:10:37 | Train | Epoch[156/600] Iteration[020/030] Train loss: 0.0241
2023-02-06 14:10:38 | Train | Epoch[156/600] Iteration[021/030] Train loss: 0.0240
2023-02-06 14:10:38 | Train | Epoch[156/600] Iteration[022/030] Train loss: 0.0242
2023-02-06 14:10:38 | Train | Epoch[156/600] Iteration[023/030] Train loss: 0.0241
2023-02-06 14:10:38 | Train | Epoch[156/600] Iteration[024/030] Train loss: 0.0241
2023-02-06 14:10:38 | Train | Epoch[156/600] Iteration[025/030] Train loss: 0.0240
2023-02-06 14:10:39 | Train | Epoch[156/600] Iteration[026/030] Train loss: 0.0240
2023-02-06 14:10:39 | Train | Epoch[156/600] Iteration[027/030] Train loss: 0.0240
2023-02-06 14:10:39 | Train | Epoch[156/600] Iteration[028/030] Train loss: 0.0240
2023-02-06 14:10:39 | Train | Epoch[156/600] Iteration[029/030] Train loss: 0.0240
2023-02-06 14:10:39 | Train | Epoch[156/600] Iteration[030/030] Train loss: 0.0239
2023-02-06 14:10:40 | Valid | Epoch[156/600] Iteration[001/008] Valid loss: 0.0804
2023-02-06 14:10:40 | Valid | Epoch[156/600] Iteration[002/008] Valid loss: 0.0778
2023-02-06 14:10:40 | Valid | Epoch[156/600] Iteration[003/008] Valid loss: 0.0773
2023-02-06 14:10:40 | Valid | Epoch[156/600] Iteration[004/008] Valid loss: 0.0759
2023-02-06 14:10:40 | Valid | Epoch[156/600] Iteration[005/008] Valid loss: 0.0751
2023-02-06 14:10:40 | Valid | Epoch[156/600] Iteration[006/008] Valid loss: 0.0735
2023-02-06 14:10:40 | Valid | Epoch[156/600] Iteration[007/008] Valid loss: 0.0729
2023-02-06 14:10:40 | Valid | Epoch[156/600] Iteration[008/008] Valid loss: 0.0735
2023-02-06 14:10:40 | Valid | Epoch[156/600] MIou: 0.8147134694620202
2023-02-06 14:10:40 | Valid | Epoch[156/600] Pixel Accuracy: 0.9692827860514323
2023-02-06 14:10:40 | Valid | Epoch[156/600] Mean Pixel Accuracy: 0.8328980580921829
2023-02-06 14:10:40 | Stage | Epoch[156/600] Train loss:0.0239
2023-02-06 14:10:40 | Stage | Epoch[156/600] Valid loss:0.0735
2023-02-06 14:10:40 | Stage | Epoch[156/600] LR:0.01

2023-02-06 14:10:41 | Train | Epoch[157/600] Iteration[001/030] Train loss: 0.0232
2023-02-06 14:10:41 | Train | Epoch[157/600] Iteration[002/030] Train loss: 0.0240
2023-02-06 14:10:41 | Train | Epoch[157/600] Iteration[003/030] Train loss: 0.0235
2023-02-06 14:10:41 | Train | Epoch[157/600] Iteration[004/030] Train loss: 0.0231
2023-02-06 14:10:42 | Train | Epoch[157/600] Iteration[005/030] Train loss: 0.0232
2023-02-06 14:10:42 | Train | Epoch[157/600] Iteration[006/030] Train loss: 0.0230
2023-02-06 14:10:42 | Train | Epoch[157/600] Iteration[007/030] Train loss: 0.0234
2023-02-06 14:10:42 | Train | Epoch[157/600] Iteration[008/030] Train loss: 0.0235
2023-02-06 14:10:42 | Train | Epoch[157/600] Iteration[009/030] Train loss: 0.0233
2023-02-06 14:10:43 | Train | Epoch[157/600] Iteration[010/030] Train loss: 0.0233
2023-02-06 14:10:43 | Train | Epoch[157/600] Iteration[011/030] Train loss: 0.0232
2023-02-06 14:10:43 | Train | Epoch[157/600] Iteration[012/030] Train loss: 0.0231
2023-02-06 14:10:43 | Train | Epoch[157/600] Iteration[013/030] Train loss: 0.0233
2023-02-06 14:10:43 | Train | Epoch[157/600] Iteration[014/030] Train loss: 0.0234
2023-02-06 14:10:44 | Train | Epoch[157/600] Iteration[015/030] Train loss: 0.0232
2023-02-06 14:10:44 | Train | Epoch[157/600] Iteration[016/030] Train loss: 0.0231
2023-02-06 14:10:44 | Train | Epoch[157/600] Iteration[017/030] Train loss: 0.0231
2023-02-06 14:10:44 | Train | Epoch[157/600] Iteration[018/030] Train loss: 0.0230
2023-02-06 14:10:45 | Train | Epoch[157/600] Iteration[019/030] Train loss: 0.0232
2023-02-06 14:10:45 | Train | Epoch[157/600] Iteration[020/030] Train loss: 0.0232
2023-02-06 14:10:45 | Train | Epoch[157/600] Iteration[021/030] Train loss: 0.0232
2023-02-06 14:10:45 | Train | Epoch[157/600] Iteration[022/030] Train loss: 0.0233
2023-02-06 14:10:45 | Train | Epoch[157/600] Iteration[023/030] Train loss: 0.0234
2023-02-06 14:10:46 | Train | Epoch[157/600] Iteration[024/030] Train loss: 0.0234
2023-02-06 14:10:46 | Train | Epoch[157/600] Iteration[025/030] Train loss: 0.0234
2023-02-06 14:10:46 | Train | Epoch[157/600] Iteration[026/030] Train loss: 0.0234
2023-02-06 14:10:46 | Train | Epoch[157/600] Iteration[027/030] Train loss: 0.0235
2023-02-06 14:10:47 | Train | Epoch[157/600] Iteration[028/030] Train loss: 0.0235
2023-02-06 14:10:47 | Train | Epoch[157/600] Iteration[029/030] Train loss: 0.0235
2023-02-06 14:10:47 | Train | Epoch[157/600] Iteration[030/030] Train loss: 0.0235
2023-02-06 14:10:47 | Valid | Epoch[157/600] Iteration[001/008] Valid loss: 0.3803
2023-02-06 14:10:47 | Valid | Epoch[157/600] Iteration[002/008] Valid loss: 0.2961
2023-02-06 14:10:47 | Valid | Epoch[157/600] Iteration[003/008] Valid loss: 0.2992
2023-02-06 14:10:47 | Valid | Epoch[157/600] Iteration[004/008] Valid loss: 0.3028
2023-02-06 14:10:47 | Valid | Epoch[157/600] Iteration[005/008] Valid loss: 0.3115
2023-02-06 14:10:47 | Valid | Epoch[157/600] Iteration[006/008] Valid loss: 0.3053
2023-02-06 14:10:48 | Valid | Epoch[157/600] Iteration[007/008] Valid loss: 0.3300
2023-02-06 14:10:48 | Valid | Epoch[157/600] Iteration[008/008] Valid loss: 0.3427
2023-02-06 14:10:48 | Valid | Epoch[157/600] MIou: 0.9009827958344867
2023-02-06 14:10:48 | Valid | Epoch[157/600] Pixel Accuracy: 0.981225331624349
2023-02-06 14:10:48 | Valid | Epoch[157/600] Mean Pixel Accuracy: 0.9732144370236311
2023-02-06 14:10:48 | Stage | Epoch[157/600] Train loss:0.0235
2023-02-06 14:10:48 | Stage | Epoch[157/600] Valid loss:0.3427
2023-02-06 14:10:48 | Stage | Epoch[157/600] LR:0.01

2023-02-06 14:10:48 | Train | Epoch[158/600] Iteration[001/030] Train loss: 0.0219
2023-02-06 14:10:48 | Train | Epoch[158/600] Iteration[002/030] Train loss: 0.0224
2023-02-06 14:10:49 | Train | Epoch[158/600] Iteration[003/030] Train loss: 0.0219
2023-02-06 14:10:49 | Train | Epoch[158/600] Iteration[004/030] Train loss: 0.0229
2023-02-06 14:10:49 | Train | Epoch[158/600] Iteration[005/030] Train loss: 0.0228
2023-02-06 14:10:49 | Train | Epoch[158/600] Iteration[006/030] Train loss: 0.0230
2023-02-06 14:10:49 | Train | Epoch[158/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 14:10:50 | Train | Epoch[158/600] Iteration[008/030] Train loss: 0.0230
2023-02-06 14:10:50 | Train | Epoch[158/600] Iteration[009/030] Train loss: 0.0231
2023-02-06 14:10:50 | Train | Epoch[158/600] Iteration[010/030] Train loss: 0.0229
2023-02-06 14:10:50 | Train | Epoch[158/600] Iteration[011/030] Train loss: 0.0229
2023-02-06 14:10:50 | Train | Epoch[158/600] Iteration[012/030] Train loss: 0.0230
2023-02-06 14:10:51 | Train | Epoch[158/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 14:10:51 | Train | Epoch[158/600] Iteration[014/030] Train loss: 0.0229
2023-02-06 14:10:51 | Train | Epoch[158/600] Iteration[015/030] Train loss: 0.0228
2023-02-06 14:10:51 | Train | Epoch[158/600] Iteration[016/030] Train loss: 0.0229
2023-02-06 14:10:52 | Train | Epoch[158/600] Iteration[017/030] Train loss: 0.0229
2023-02-06 14:10:52 | Train | Epoch[158/600] Iteration[018/030] Train loss: 0.0229
2023-02-06 14:10:52 | Train | Epoch[158/600] Iteration[019/030] Train loss: 0.0229
2023-02-06 14:10:52 | Train | Epoch[158/600] Iteration[020/030] Train loss: 0.0229
2023-02-06 14:10:52 | Train | Epoch[158/600] Iteration[021/030] Train loss: 0.0229
2023-02-06 14:10:53 | Train | Epoch[158/600] Iteration[022/030] Train loss: 0.0229
2023-02-06 14:10:53 | Train | Epoch[158/600] Iteration[023/030] Train loss: 0.0229
2023-02-06 14:10:53 | Train | Epoch[158/600] Iteration[024/030] Train loss: 0.0230
2023-02-06 14:10:53 | Train | Epoch[158/600] Iteration[025/030] Train loss: 0.0230
2023-02-06 14:10:54 | Train | Epoch[158/600] Iteration[026/030] Train loss: 0.0230
2023-02-06 14:10:54 | Train | Epoch[158/600] Iteration[027/030] Train loss: 0.0230
2023-02-06 14:10:54 | Train | Epoch[158/600] Iteration[028/030] Train loss: 0.0231
2023-02-06 14:10:54 | Train | Epoch[158/600] Iteration[029/030] Train loss: 0.0231
2023-02-06 14:10:54 | Train | Epoch[158/600] Iteration[030/030] Train loss: 0.0230
2023-02-06 14:10:55 | Valid | Epoch[158/600] Iteration[001/008] Valid loss: 0.0890
2023-02-06 14:10:55 | Valid | Epoch[158/600] Iteration[002/008] Valid loss: 0.0884
2023-02-06 14:10:55 | Valid | Epoch[158/600] Iteration[003/008] Valid loss: 0.0930
2023-02-06 14:10:55 | Valid | Epoch[158/600] Iteration[004/008] Valid loss: 0.0908
2023-02-06 14:10:55 | Valid | Epoch[158/600] Iteration[005/008] Valid loss: 0.0915
2023-02-06 14:10:55 | Valid | Epoch[158/600] Iteration[006/008] Valid loss: 0.0892
2023-02-06 14:10:55 | Valid | Epoch[158/600] Iteration[007/008] Valid loss: 0.0868
2023-02-06 14:10:55 | Valid | Epoch[158/600] Iteration[008/008] Valid loss: 0.0888
2023-02-06 14:10:55 | Valid | Epoch[158/600] MIou: 0.7603067457104375
2023-02-06 14:10:55 | Valid | Epoch[158/600] Pixel Accuracy: 0.9604352315266927
2023-02-06 14:10:55 | Valid | Epoch[158/600] Mean Pixel Accuracy: 0.7813374920998442
2023-02-06 14:10:55 | Stage | Epoch[158/600] Train loss:0.0230
2023-02-06 14:10:55 | Stage | Epoch[158/600] Valid loss:0.0888
2023-02-06 14:10:55 | Stage | Epoch[158/600] LR:0.01

2023-02-06 14:10:56 | Train | Epoch[159/600] Iteration[001/030] Train loss: 0.0210
2023-02-06 14:10:56 | Train | Epoch[159/600] Iteration[002/030] Train loss: 0.0226
2023-02-06 14:10:56 | Train | Epoch[159/600] Iteration[003/030] Train loss: 0.0224
2023-02-06 14:10:56 | Train | Epoch[159/600] Iteration[004/030] Train loss: 0.0226
2023-02-06 14:10:56 | Train | Epoch[159/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 14:10:57 | Train | Epoch[159/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 14:10:57 | Train | Epoch[159/600] Iteration[007/030] Train loss: 0.0224
2023-02-06 14:10:57 | Train | Epoch[159/600] Iteration[008/030] Train loss: 0.0222
2023-02-06 14:10:57 | Train | Epoch[159/600] Iteration[009/030] Train loss: 0.0223
2023-02-06 14:10:58 | Train | Epoch[159/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 14:10:58 | Train | Epoch[159/600] Iteration[011/030] Train loss: 0.0224
2023-02-06 14:10:58 | Train | Epoch[159/600] Iteration[012/030] Train loss: 0.0225
2023-02-06 14:10:58 | Train | Epoch[159/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 14:10:58 | Train | Epoch[159/600] Iteration[014/030] Train loss: 0.0225
2023-02-06 14:10:59 | Train | Epoch[159/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 14:10:59 | Train | Epoch[159/600] Iteration[016/030] Train loss: 0.0226
2023-02-06 14:10:59 | Train | Epoch[159/600] Iteration[017/030] Train loss: 0.0227
2023-02-06 14:10:59 | Train | Epoch[159/600] Iteration[018/030] Train loss: 0.0229
2023-02-06 14:11:00 | Train | Epoch[159/600] Iteration[019/030] Train loss: 0.0230
2023-02-06 14:11:00 | Train | Epoch[159/600] Iteration[020/030] Train loss: 0.0230
2023-02-06 14:11:00 | Train | Epoch[159/600] Iteration[021/030] Train loss: 0.0231
2023-02-06 14:11:00 | Train | Epoch[159/600] Iteration[022/030] Train loss: 0.0231
2023-02-06 14:11:00 | Train | Epoch[159/600] Iteration[023/030] Train loss: 0.0231
2023-02-06 14:11:01 | Train | Epoch[159/600] Iteration[024/030] Train loss: 0.0231
2023-02-06 14:11:01 | Train | Epoch[159/600] Iteration[025/030] Train loss: 0.0231
2023-02-06 14:11:01 | Train | Epoch[159/600] Iteration[026/030] Train loss: 0.0230
2023-02-06 14:11:01 | Train | Epoch[159/600] Iteration[027/030] Train loss: 0.0229
2023-02-06 14:11:02 | Train | Epoch[159/600] Iteration[028/030] Train loss: 0.0229
2023-02-06 14:11:02 | Train | Epoch[159/600] Iteration[029/030] Train loss: 0.0229
2023-02-06 14:11:02 | Train | Epoch[159/600] Iteration[030/030] Train loss: 0.0229
2023-02-06 14:11:02 | Valid | Epoch[159/600] Iteration[001/008] Valid loss: 0.6375
2023-02-06 14:11:02 | Valid | Epoch[159/600] Iteration[002/008] Valid loss: 0.5929
2023-02-06 14:11:02 | Valid | Epoch[159/600] Iteration[003/008] Valid loss: 0.6201
2023-02-06 14:11:02 | Valid | Epoch[159/600] Iteration[004/008] Valid loss: 0.6248
2023-02-06 14:11:02 | Valid | Epoch[159/600] Iteration[005/008] Valid loss: 0.6371
2023-02-06 14:11:02 | Valid | Epoch[159/600] Iteration[006/008] Valid loss: 0.6255
2023-02-06 14:11:02 | Valid | Epoch[159/600] Iteration[007/008] Valid loss: 0.6653
2023-02-06 14:11:03 | Valid | Epoch[159/600] Iteration[008/008] Valid loss: 0.7016
2023-02-06 14:11:03 | Valid | Epoch[159/600] MIou: 0.8715238956609889
2023-02-06 14:11:03 | Valid | Epoch[159/600] Pixel Accuracy: 0.97369384765625
2023-02-06 14:11:03 | Valid | Epoch[159/600] Mean Pixel Accuracy: 0.9791371405144121
2023-02-06 14:11:03 | Stage | Epoch[159/600] Train loss:0.0229
2023-02-06 14:11:03 | Stage | Epoch[159/600] Valid loss:0.7016
2023-02-06 14:11:03 | Stage | Epoch[159/600] LR:0.01

2023-02-06 14:11:03 | Train | Epoch[160/600] Iteration[001/030] Train loss: 0.0219
2023-02-06 14:11:03 | Train | Epoch[160/600] Iteration[002/030] Train loss: 0.0225
2023-02-06 14:11:04 | Train | Epoch[160/600] Iteration[003/030] Train loss: 0.0232
2023-02-06 14:11:04 | Train | Epoch[160/600] Iteration[004/030] Train loss: 0.0227
2023-02-06 14:11:04 | Train | Epoch[160/600] Iteration[005/030] Train loss: 0.0224
2023-02-06 14:11:04 | Train | Epoch[160/600] Iteration[006/030] Train loss: 0.0222
2023-02-06 14:11:04 | Train | Epoch[160/600] Iteration[007/030] Train loss: 0.0224
2023-02-06 14:11:05 | Train | Epoch[160/600] Iteration[008/030] Train loss: 0.0224
2023-02-06 14:11:05 | Train | Epoch[160/600] Iteration[009/030] Train loss: 0.0223
2023-02-06 14:11:05 | Train | Epoch[160/600] Iteration[010/030] Train loss: 0.0222
2023-02-06 14:11:05 | Train | Epoch[160/600] Iteration[011/030] Train loss: 0.0221
2023-02-06 14:11:06 | Train | Epoch[160/600] Iteration[012/030] Train loss: 0.0221
2023-02-06 14:11:06 | Train | Epoch[160/600] Iteration[013/030] Train loss: 0.0220
2023-02-06 14:11:06 | Train | Epoch[160/600] Iteration[014/030] Train loss: 0.0221
2023-02-06 14:11:06 | Train | Epoch[160/600] Iteration[015/030] Train loss: 0.0221
2023-02-06 14:11:06 | Train | Epoch[160/600] Iteration[016/030] Train loss: 0.0220
2023-02-06 14:11:07 | Train | Epoch[160/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 14:11:07 | Train | Epoch[160/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 14:11:07 | Train | Epoch[160/600] Iteration[019/030] Train loss: 0.0219
2023-02-06 14:11:07 | Train | Epoch[160/600] Iteration[020/030] Train loss: 0.0219
2023-02-06 14:11:07 | Train | Epoch[160/600] Iteration[021/030] Train loss: 0.0219
2023-02-06 14:11:08 | Train | Epoch[160/600] Iteration[022/030] Train loss: 0.0219
2023-02-06 14:11:08 | Train | Epoch[160/600] Iteration[023/030] Train loss: 0.0222
2023-02-06 14:11:08 | Train | Epoch[160/600] Iteration[024/030] Train loss: 0.0223
2023-02-06 14:11:08 | Train | Epoch[160/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 14:11:09 | Train | Epoch[160/600] Iteration[026/030] Train loss: 0.0223
2023-02-06 14:11:09 | Train | Epoch[160/600] Iteration[027/030] Train loss: 0.0223
2023-02-06 14:11:09 | Train | Epoch[160/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 14:11:09 | Train | Epoch[160/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 14:11:09 | Train | Epoch[160/600] Iteration[030/030] Train loss: 0.0225
2023-02-06 14:11:10 | Valid | Epoch[160/600] Iteration[001/008] Valid loss: 0.1151
2023-02-06 14:11:10 | Valid | Epoch[160/600] Iteration[002/008] Valid loss: 0.1000
2023-02-06 14:11:10 | Valid | Epoch[160/600] Iteration[003/008] Valid loss: 0.0936
2023-02-06 14:11:10 | Valid | Epoch[160/600] Iteration[004/008] Valid loss: 0.0856
2023-02-06 14:11:10 | Valid | Epoch[160/600] Iteration[005/008] Valid loss: 0.0876
2023-02-06 14:11:10 | Valid | Epoch[160/600] Iteration[006/008] Valid loss: 0.0849
2023-02-06 14:11:10 | Valid | Epoch[160/600] Iteration[007/008] Valid loss: 0.0895
2023-02-06 14:11:10 | Valid | Epoch[160/600] Iteration[008/008] Valid loss: 0.0910
2023-02-06 14:11:10 | Valid | Epoch[160/600] MIou: 0.9011275777709419
2023-02-06 14:11:10 | Valid | Epoch[160/600] Pixel Accuracy: 0.9828656514485677
2023-02-06 14:11:10 | Valid | Epoch[160/600] Mean Pixel Accuracy: 0.9316919318696443
2023-02-06 14:11:10 | Stage | Epoch[160/600] Train loss:0.0225
2023-02-06 14:11:10 | Stage | Epoch[160/600] Valid loss:0.0910
2023-02-06 14:11:10 | Stage | Epoch[160/600] LR:0.01

2023-02-06 14:11:11 | Train | Epoch[161/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 14:11:11 | Train | Epoch[161/600] Iteration[002/030] Train loss: 0.0241
2023-02-06 14:11:11 | Train | Epoch[161/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 14:11:11 | Train | Epoch[161/600] Iteration[004/030] Train loss: 0.0231
2023-02-06 14:11:11 | Train | Epoch[161/600] Iteration[005/030] Train loss: 0.0228
2023-02-06 14:11:12 | Train | Epoch[161/600] Iteration[006/030] Train loss: 0.0229
2023-02-06 14:11:12 | Train | Epoch[161/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 14:11:12 | Train | Epoch[161/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 14:11:12 | Train | Epoch[161/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 14:11:13 | Train | Epoch[161/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 14:11:13 | Train | Epoch[161/600] Iteration[011/030] Train loss: 0.0227
2023-02-06 14:11:13 | Train | Epoch[161/600] Iteration[012/030] Train loss: 0.0228
2023-02-06 14:11:13 | Train | Epoch[161/600] Iteration[013/030] Train loss: 0.0229
2023-02-06 14:11:13 | Train | Epoch[161/600] Iteration[014/030] Train loss: 0.0228
2023-02-06 14:11:14 | Train | Epoch[161/600] Iteration[015/030] Train loss: 0.0229
2023-02-06 14:11:14 | Train | Epoch[161/600] Iteration[016/030] Train loss: 0.0228
2023-02-06 14:11:14 | Train | Epoch[161/600] Iteration[017/030] Train loss: 0.0229
2023-02-06 14:11:14 | Train | Epoch[161/600] Iteration[018/030] Train loss: 0.0228
2023-02-06 14:11:14 | Train | Epoch[161/600] Iteration[019/030] Train loss: 0.0227
2023-02-06 14:11:15 | Train | Epoch[161/600] Iteration[020/030] Train loss: 0.0227
2023-02-06 14:11:15 | Train | Epoch[161/600] Iteration[021/030] Train loss: 0.0227
2023-02-06 14:11:15 | Train | Epoch[161/600] Iteration[022/030] Train loss: 0.0228
2023-02-06 14:11:15 | Train | Epoch[161/600] Iteration[023/030] Train loss: 0.0228
2023-02-06 14:11:16 | Train | Epoch[161/600] Iteration[024/030] Train loss: 0.0228
2023-02-06 14:11:16 | Train | Epoch[161/600] Iteration[025/030] Train loss: 0.0227
2023-02-06 14:11:16 | Train | Epoch[161/600] Iteration[026/030] Train loss: 0.0227
2023-02-06 14:11:16 | Train | Epoch[161/600] Iteration[027/030] Train loss: 0.0227
2023-02-06 14:11:16 | Train | Epoch[161/600] Iteration[028/030] Train loss: 0.0228
2023-02-06 14:11:17 | Train | Epoch[161/600] Iteration[029/030] Train loss: 0.0227
2023-02-06 14:11:17 | Train | Epoch[161/600] Iteration[030/030] Train loss: 0.0227
2023-02-06 14:11:17 | Valid | Epoch[161/600] Iteration[001/008] Valid loss: 0.0892
2023-02-06 14:11:17 | Valid | Epoch[161/600] Iteration[002/008] Valid loss: 0.0754
2023-02-06 14:11:17 | Valid | Epoch[161/600] Iteration[003/008] Valid loss: 0.0677
2023-02-06 14:11:17 | Valid | Epoch[161/600] Iteration[004/008] Valid loss: 0.0624
2023-02-06 14:11:17 | Valid | Epoch[161/600] Iteration[005/008] Valid loss: 0.0619
2023-02-06 14:11:17 | Valid | Epoch[161/600] Iteration[006/008] Valid loss: 0.0603
2023-02-06 14:11:17 | Valid | Epoch[161/600] Iteration[007/008] Valid loss: 0.0603
2023-02-06 14:11:17 | Valid | Epoch[161/600] Iteration[008/008] Valid loss: 0.0592
2023-02-06 14:11:18 | Valid | Epoch[161/600] MIou: 0.9138025747556793
2023-02-06 14:11:18 | Valid | Epoch[161/600] Pixel Accuracy: 0.9853846232096354
2023-02-06 14:11:18 | Valid | Epoch[161/600] Mean Pixel Accuracy: 0.9343128581259299
2023-02-06 14:11:18 | Stage | Epoch[161/600] Train loss:0.0227
2023-02-06 14:11:18 | Stage | Epoch[161/600] Valid loss:0.0592
2023-02-06 14:11:18 | Stage | Epoch[161/600] LR:0.01

2023-02-06 14:11:18 | Train | Epoch[162/600] Iteration[001/030] Train loss: 0.0217
2023-02-06 14:11:18 | Train | Epoch[162/600] Iteration[002/030] Train loss: 0.0220
2023-02-06 14:11:18 | Train | Epoch[162/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 14:11:19 | Train | Epoch[162/600] Iteration[004/030] Train loss: 0.0220
2023-02-06 14:11:19 | Train | Epoch[162/600] Iteration[005/030] Train loss: 0.0223
2023-02-06 14:11:19 | Train | Epoch[162/600] Iteration[006/030] Train loss: 0.0221
2023-02-06 14:11:19 | Train | Epoch[162/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 14:11:20 | Train | Epoch[162/600] Iteration[008/030] Train loss: 0.0218
2023-02-06 14:11:20 | Train | Epoch[162/600] Iteration[009/030] Train loss: 0.0218
2023-02-06 14:11:20 | Train | Epoch[162/600] Iteration[010/030] Train loss: 0.0218
2023-02-06 14:11:20 | Train | Epoch[162/600] Iteration[011/030] Train loss: 0.0217
2023-02-06 14:11:20 | Train | Epoch[162/600] Iteration[012/030] Train loss: 0.0216
2023-02-06 14:11:21 | Train | Epoch[162/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 14:11:21 | Train | Epoch[162/600] Iteration[014/030] Train loss: 0.0216
2023-02-06 14:11:21 | Train | Epoch[162/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 14:11:21 | Train | Epoch[162/600] Iteration[016/030] Train loss: 0.0218
2023-02-06 14:11:22 | Train | Epoch[162/600] Iteration[017/030] Train loss: 0.0218
2023-02-06 14:11:22 | Train | Epoch[162/600] Iteration[018/030] Train loss: 0.0217
2023-02-06 14:11:22 | Train | Epoch[162/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 14:11:22 | Train | Epoch[162/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 14:11:22 | Train | Epoch[162/600] Iteration[021/030] Train loss: 0.0216
2023-02-06 14:11:23 | Train | Epoch[162/600] Iteration[022/030] Train loss: 0.0216
2023-02-06 14:11:23 | Train | Epoch[162/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 14:11:23 | Train | Epoch[162/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 14:11:23 | Train | Epoch[162/600] Iteration[025/030] Train loss: 0.0216
2023-02-06 14:11:23 | Train | Epoch[162/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 14:11:24 | Train | Epoch[162/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 14:11:24 | Train | Epoch[162/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 14:11:24 | Train | Epoch[162/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 14:11:24 | Train | Epoch[162/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 14:11:25 | Valid | Epoch[162/600] Iteration[001/008] Valid loss: 0.0623
2023-02-06 14:11:25 | Valid | Epoch[162/600] Iteration[002/008] Valid loss: 0.0583
2023-02-06 14:11:25 | Valid | Epoch[162/600] Iteration[003/008] Valid loss: 0.0587
2023-02-06 14:11:25 | Valid | Epoch[162/600] Iteration[004/008] Valid loss: 0.0562
2023-02-06 14:11:25 | Valid | Epoch[162/600] Iteration[005/008] Valid loss: 0.0559
2023-02-06 14:11:25 | Valid | Epoch[162/600] Iteration[006/008] Valid loss: 0.0545
2023-02-06 14:11:25 | Valid | Epoch[162/600] Iteration[007/008] Valid loss: 0.0531
2023-02-06 14:11:25 | Valid | Epoch[162/600] Iteration[008/008] Valid loss: 0.0532
2023-02-06 14:11:25 | Valid | Epoch[162/600] MIou: 0.8720150787348604
2023-02-06 14:11:25 | Valid | Epoch[162/600] Pixel Accuracy: 0.9788157145182291
2023-02-06 14:11:25 | Valid | Epoch[162/600] Mean Pixel Accuracy: 0.8853362320830223
2023-02-06 14:11:25 | Stage | Epoch[162/600] Train loss:0.0216
2023-02-06 14:11:25 | Stage | Epoch[162/600] Valid loss:0.0532
2023-02-06 14:11:25 | Stage | Epoch[162/600] LR:0.01

2023-02-06 14:11:26 | Train | Epoch[163/600] Iteration[001/030] Train loss: 0.0207
2023-02-06 14:11:26 | Train | Epoch[163/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 14:11:26 | Train | Epoch[163/600] Iteration[003/030] Train loss: 0.0213
2023-02-06 14:11:26 | Train | Epoch[163/600] Iteration[004/030] Train loss: 0.0213
2023-02-06 14:11:26 | Train | Epoch[163/600] Iteration[005/030] Train loss: 0.0214
2023-02-06 14:11:27 | Train | Epoch[163/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 14:11:27 | Train | Epoch[163/600] Iteration[007/030] Train loss: 0.0212
2023-02-06 14:11:27 | Train | Epoch[163/600] Iteration[008/030] Train loss: 0.0213
2023-02-06 14:11:27 | Train | Epoch[163/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 14:11:27 | Train | Epoch[163/600] Iteration[010/030] Train loss: 0.0215
2023-02-06 14:11:28 | Train | Epoch[163/600] Iteration[011/030] Train loss: 0.0215
2023-02-06 14:11:28 | Train | Epoch[163/600] Iteration[012/030] Train loss: 0.0214
2023-02-06 14:11:28 | Train | Epoch[163/600] Iteration[013/030] Train loss: 0.0212
2023-02-06 14:11:28 | Train | Epoch[163/600] Iteration[014/030] Train loss: 0.0215
2023-02-06 14:11:29 | Train | Epoch[163/600] Iteration[015/030] Train loss: 0.0214
2023-02-06 14:11:29 | Train | Epoch[163/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 14:11:29 | Train | Epoch[163/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 14:11:29 | Train | Epoch[163/600] Iteration[018/030] Train loss: 0.0216
2023-02-06 14:11:29 | Train | Epoch[163/600] Iteration[019/030] Train loss: 0.0216
2023-02-06 14:11:30 | Train | Epoch[163/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 14:11:30 | Train | Epoch[163/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 14:11:30 | Train | Epoch[163/600] Iteration[022/030] Train loss: 0.0218
2023-02-06 14:11:30 | Train | Epoch[163/600] Iteration[023/030] Train loss: 0.0218
2023-02-06 14:11:31 | Train | Epoch[163/600] Iteration[024/030] Train loss: 0.0217
2023-02-06 14:11:31 | Train | Epoch[163/600] Iteration[025/030] Train loss: 0.0217
2023-02-06 14:11:31 | Train | Epoch[163/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 14:11:31 | Train | Epoch[163/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 14:11:31 | Train | Epoch[163/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 14:11:32 | Train | Epoch[163/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 14:11:32 | Train | Epoch[163/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 14:11:32 | Valid | Epoch[163/600] Iteration[001/008] Valid loss: 0.7795
2023-02-06 14:11:32 | Valid | Epoch[163/600] Iteration[002/008] Valid loss: 0.7382
2023-02-06 14:11:32 | Valid | Epoch[163/600] Iteration[003/008] Valid loss: 0.7501
2023-02-06 14:11:32 | Valid | Epoch[163/600] Iteration[004/008] Valid loss: 0.7482
2023-02-06 14:11:32 | Valid | Epoch[163/600] Iteration[005/008] Valid loss: 0.7670
2023-02-06 14:11:32 | Valid | Epoch[163/600] Iteration[006/008] Valid loss: 0.7542
2023-02-06 14:11:33 | Valid | Epoch[163/600] Iteration[007/008] Valid loss: 0.7985
2023-02-06 14:11:33 | Valid | Epoch[163/600] Iteration[008/008] Valid loss: 0.8286
2023-02-06 14:11:33 | Valid | Epoch[163/600] MIou: 0.8636881821180403
2023-02-06 14:11:33 | Valid | Epoch[163/600] Pixel Accuracy: 0.9715003967285156
2023-02-06 14:11:33 | Valid | Epoch[163/600] Mean Pixel Accuracy: 0.9807530361589853
2023-02-06 14:11:33 | Stage | Epoch[163/600] Train loss:0.0216
2023-02-06 14:11:33 | Stage | Epoch[163/600] Valid loss:0.8286
2023-02-06 14:11:33 | Stage | Epoch[163/600] LR:0.01

2023-02-06 14:11:33 | Train | Epoch[164/600] Iteration[001/030] Train loss: 0.0215
2023-02-06 14:11:33 | Train | Epoch[164/600] Iteration[002/030] Train loss: 0.0209
2023-02-06 14:11:34 | Train | Epoch[164/600] Iteration[003/030] Train loss: 0.0212
2023-02-06 14:11:34 | Train | Epoch[164/600] Iteration[004/030] Train loss: 0.0213
2023-02-06 14:11:34 | Train | Epoch[164/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 14:11:34 | Train | Epoch[164/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 14:11:34 | Train | Epoch[164/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 14:11:35 | Train | Epoch[164/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 14:11:35 | Train | Epoch[164/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 14:11:35 | Train | Epoch[164/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 14:11:35 | Train | Epoch[164/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 14:11:36 | Train | Epoch[164/600] Iteration[012/030] Train loss: 0.0211
2023-02-06 14:11:36 | Train | Epoch[164/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 14:11:36 | Train | Epoch[164/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 14:11:36 | Train | Epoch[164/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 14:11:36 | Train | Epoch[164/600] Iteration[016/030] Train loss: 0.0210
2023-02-06 14:11:37 | Train | Epoch[164/600] Iteration[017/030] Train loss: 0.0210
2023-02-06 14:11:37 | Train | Epoch[164/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 14:11:37 | Train | Epoch[164/600] Iteration[019/030] Train loss: 0.0212
2023-02-06 14:11:37 | Train | Epoch[164/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 14:11:38 | Train | Epoch[164/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 14:11:38 | Train | Epoch[164/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 14:11:38 | Train | Epoch[164/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 14:11:38 | Train | Epoch[164/600] Iteration[024/030] Train loss: 0.0214
2023-02-06 14:11:38 | Train | Epoch[164/600] Iteration[025/030] Train loss: 0.0214
2023-02-06 14:11:39 | Train | Epoch[164/600] Iteration[026/030] Train loss: 0.0214
2023-02-06 14:11:39 | Train | Epoch[164/600] Iteration[027/030] Train loss: 0.0214
2023-02-06 14:11:39 | Train | Epoch[164/600] Iteration[028/030] Train loss: 0.0215
2023-02-06 14:11:39 | Train | Epoch[164/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 14:11:39 | Train | Epoch[164/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 14:11:40 | Valid | Epoch[164/600] Iteration[001/008] Valid loss: 0.4570
2023-02-06 14:11:40 | Valid | Epoch[164/600] Iteration[002/008] Valid loss: 0.3867
2023-02-06 14:11:40 | Valid | Epoch[164/600] Iteration[003/008] Valid loss: 0.3792
2023-02-06 14:11:40 | Valid | Epoch[164/600] Iteration[004/008] Valid loss: 0.3837
2023-02-06 14:11:40 | Valid | Epoch[164/600] Iteration[005/008] Valid loss: 0.3981
2023-02-06 14:11:40 | Valid | Epoch[164/600] Iteration[006/008] Valid loss: 0.3840
2023-02-06 14:11:40 | Valid | Epoch[164/600] Iteration[007/008] Valid loss: 0.4102
2023-02-06 14:11:40 | Valid | Epoch[164/600] Iteration[008/008] Valid loss: 0.4231
2023-02-06 14:11:40 | Valid | Epoch[164/600] MIou: 0.886983158535203
2023-02-06 14:11:40 | Valid | Epoch[164/600] Pixel Accuracy: 0.9776331583658854
2023-02-06 14:11:40 | Valid | Epoch[164/600] Mean Pixel Accuracy: 0.9793368075192214
2023-02-06 14:11:40 | Stage | Epoch[164/600] Train loss:0.0214
2023-02-06 14:11:40 | Stage | Epoch[164/600] Valid loss:0.4231
2023-02-06 14:11:40 | Stage | Epoch[164/600] LR:0.01

2023-02-06 14:11:41 | Train | Epoch[165/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 14:11:41 | Train | Epoch[165/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 14:11:41 | Train | Epoch[165/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 14:11:41 | Train | Epoch[165/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 14:11:41 | Train | Epoch[165/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 14:11:42 | Train | Epoch[165/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 14:11:42 | Train | Epoch[165/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 14:11:42 | Train | Epoch[165/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 14:11:42 | Train | Epoch[165/600] Iteration[009/030] Train loss: 0.0213
2023-02-06 14:11:43 | Train | Epoch[165/600] Iteration[010/030] Train loss: 0.0214
2023-02-06 14:11:43 | Train | Epoch[165/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 14:11:43 | Train | Epoch[165/600] Iteration[012/030] Train loss: 0.0213
2023-02-06 14:11:43 | Train | Epoch[165/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 14:11:43 | Train | Epoch[165/600] Iteration[014/030] Train loss: 0.0214
2023-02-06 14:11:44 | Train | Epoch[165/600] Iteration[015/030] Train loss: 0.0217
2023-02-06 14:11:44 | Train | Epoch[165/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 14:11:44 | Train | Epoch[165/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 14:11:44 | Train | Epoch[165/600] Iteration[018/030] Train loss: 0.0214
2023-02-06 14:11:45 | Train | Epoch[165/600] Iteration[019/030] Train loss: 0.0215
2023-02-06 14:11:45 | Train | Epoch[165/600] Iteration[020/030] Train loss: 0.0215
2023-02-06 14:11:45 | Train | Epoch[165/600] Iteration[021/030] Train loss: 0.0215
2023-02-06 14:11:45 | Train | Epoch[165/600] Iteration[022/030] Train loss: 0.0215
2023-02-06 14:11:45 | Train | Epoch[165/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 14:11:46 | Train | Epoch[165/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 14:11:46 | Train | Epoch[165/600] Iteration[025/030] Train loss: 0.0217
2023-02-06 14:11:46 | Train | Epoch[165/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 14:11:46 | Train | Epoch[165/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 14:11:47 | Train | Epoch[165/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 14:11:47 | Train | Epoch[165/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 14:11:47 | Train | Epoch[165/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 14:11:47 | Valid | Epoch[165/600] Iteration[001/008] Valid loss: 0.1180
2023-02-06 14:11:47 | Valid | Epoch[165/600] Iteration[002/008] Valid loss: 0.0995
2023-02-06 14:11:47 | Valid | Epoch[165/600] Iteration[003/008] Valid loss: 0.0946
2023-02-06 14:11:47 | Valid | Epoch[165/600] Iteration[004/008] Valid loss: 0.0878
2023-02-06 14:11:47 | Valid | Epoch[165/600] Iteration[005/008] Valid loss: 0.0857
2023-02-06 14:11:47 | Valid | Epoch[165/600] Iteration[006/008] Valid loss: 0.0849
2023-02-06 14:11:48 | Valid | Epoch[165/600] Iteration[007/008] Valid loss: 0.0886
2023-02-06 14:11:48 | Valid | Epoch[165/600] Iteration[008/008] Valid loss: 0.0848
2023-02-06 14:11:48 | Valid | Epoch[165/600] MIou: 0.9232464358197146
2023-02-06 14:11:48 | Valid | Epoch[165/600] Pixel Accuracy: 0.9868354797363281
2023-02-06 14:11:48 | Valid | Epoch[165/600] Mean Pixel Accuracy: 0.94841896045439
2023-02-06 14:11:48 | Stage | Epoch[165/600] Train loss:0.0216
2023-02-06 14:11:48 | Stage | Epoch[165/600] Valid loss:0.0848
2023-02-06 14:11:48 | Stage | Epoch[165/600] LR:0.01

2023-02-06 14:11:48 | Train | Epoch[166/600] Iteration[001/030] Train loss: 0.0210
2023-02-06 14:11:48 | Train | Epoch[166/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 14:11:49 | Train | Epoch[166/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 14:11:49 | Train | Epoch[166/600] Iteration[004/030] Train loss: 0.0216
2023-02-06 14:11:49 | Train | Epoch[166/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 14:11:49 | Train | Epoch[166/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 14:11:49 | Train | Epoch[166/600] Iteration[007/030] Train loss: 0.0212
2023-02-06 14:11:50 | Train | Epoch[166/600] Iteration[008/030] Train loss: 0.0214
2023-02-06 14:11:50 | Train | Epoch[166/600] Iteration[009/030] Train loss: 0.0213
2023-02-06 14:11:50 | Train | Epoch[166/600] Iteration[010/030] Train loss: 0.0214
2023-02-06 14:11:50 | Train | Epoch[166/600] Iteration[011/030] Train loss: 0.0214
2023-02-06 14:11:51 | Train | Epoch[166/600] Iteration[012/030] Train loss: 0.0214
2023-02-06 14:11:51 | Train | Epoch[166/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 14:11:51 | Train | Epoch[166/600] Iteration[014/030] Train loss: 0.0214
2023-02-06 14:11:51 | Train | Epoch[166/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 14:11:51 | Train | Epoch[166/600] Iteration[016/030] Train loss: 0.0217
2023-02-06 14:11:52 | Train | Epoch[166/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 14:11:52 | Train | Epoch[166/600] Iteration[018/030] Train loss: 0.0215
2023-02-06 14:11:52 | Train | Epoch[166/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 14:11:52 | Train | Epoch[166/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 14:11:52 | Train | Epoch[166/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 14:11:53 | Train | Epoch[166/600] Iteration[022/030] Train loss: 0.0217
2023-02-06 14:11:53 | Train | Epoch[166/600] Iteration[023/030] Train loss: 0.0217
2023-02-06 14:11:53 | Train | Epoch[166/600] Iteration[024/030] Train loss: 0.0217
2023-02-06 14:11:53 | Train | Epoch[166/600] Iteration[025/030] Train loss: 0.0216
2023-02-06 14:11:54 | Train | Epoch[166/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 14:11:54 | Train | Epoch[166/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 14:11:54 | Train | Epoch[166/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 14:11:54 | Train | Epoch[166/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 14:11:54 | Train | Epoch[166/600] Iteration[030/030] Train loss: 0.0218
2023-02-06 14:11:55 | Valid | Epoch[166/600] Iteration[001/008] Valid loss: 0.2298
2023-02-06 14:11:55 | Valid | Epoch[166/600] Iteration[002/008] Valid loss: 0.1947
2023-02-06 14:11:55 | Valid | Epoch[166/600] Iteration[003/008] Valid loss: 0.1909
2023-02-06 14:11:55 | Valid | Epoch[166/600] Iteration[004/008] Valid loss: 0.1834
2023-02-06 14:11:55 | Valid | Epoch[166/600] Iteration[005/008] Valid loss: 0.1919
2023-02-06 14:11:55 | Valid | Epoch[166/600] Iteration[006/008] Valid loss: 0.1904
2023-02-06 14:11:55 | Valid | Epoch[166/600] Iteration[007/008] Valid loss: 0.2121
2023-02-06 14:11:55 | Valid | Epoch[166/600] Iteration[008/008] Valid loss: 0.2118
2023-02-06 14:11:55 | Valid | Epoch[166/600] MIou: 0.9138409803268568
2023-02-06 14:11:55 | Valid | Epoch[166/600] Pixel Accuracy: 0.9840990702311198
2023-02-06 14:11:55 | Valid | Epoch[166/600] Mean Pixel Accuracy: 0.9734561268348507
2023-02-06 14:11:55 | Stage | Epoch[166/600] Train loss:0.0218
2023-02-06 14:11:55 | Stage | Epoch[166/600] Valid loss:0.2118
2023-02-06 14:11:55 | Stage | Epoch[166/600] LR:0.01

2023-02-06 14:11:56 | Train | Epoch[167/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 14:11:56 | Train | Epoch[167/600] Iteration[002/030] Train loss: 0.0210
2023-02-06 14:11:56 | Train | Epoch[167/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 14:11:56 | Train | Epoch[167/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 14:11:56 | Train | Epoch[167/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 14:11:57 | Train | Epoch[167/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 14:11:57 | Train | Epoch[167/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 14:11:57 | Train | Epoch[167/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 14:11:57 | Train | Epoch[167/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 14:11:58 | Train | Epoch[167/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 14:11:58 | Train | Epoch[167/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 14:11:58 | Train | Epoch[167/600] Iteration[012/030] Train loss: 0.0208
2023-02-06 14:11:58 | Train | Epoch[167/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 14:11:58 | Train | Epoch[167/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 14:11:59 | Train | Epoch[167/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 14:11:59 | Train | Epoch[167/600] Iteration[016/030] Train loss: 0.0208
2023-02-06 14:11:59 | Train | Epoch[167/600] Iteration[017/030] Train loss: 0.0208
2023-02-06 14:11:59 | Train | Epoch[167/600] Iteration[018/030] Train loss: 0.0208
2023-02-06 14:11:59 | Train | Epoch[167/600] Iteration[019/030] Train loss: 0.0207
2023-02-06 14:12:00 | Train | Epoch[167/600] Iteration[020/030] Train loss: 0.0207
2023-02-06 14:12:00 | Train | Epoch[167/600] Iteration[021/030] Train loss: 0.0207
2023-02-06 14:12:00 | Train | Epoch[167/600] Iteration[022/030] Train loss: 0.0207
2023-02-06 14:12:00 | Train | Epoch[167/600] Iteration[023/030] Train loss: 0.0208
2023-02-06 14:12:01 | Train | Epoch[167/600] Iteration[024/030] Train loss: 0.0209
2023-02-06 14:12:01 | Train | Epoch[167/600] Iteration[025/030] Train loss: 0.0209
2023-02-06 14:12:01 | Train | Epoch[167/600] Iteration[026/030] Train loss: 0.0209
2023-02-06 14:12:01 | Train | Epoch[167/600] Iteration[027/030] Train loss: 0.0209
2023-02-06 14:12:01 | Train | Epoch[167/600] Iteration[028/030] Train loss: 0.0209
2023-02-06 14:12:02 | Train | Epoch[167/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 14:12:02 | Train | Epoch[167/600] Iteration[030/030] Train loss: 0.0210
2023-02-06 14:12:02 | Valid | Epoch[167/600] Iteration[001/008] Valid loss: 0.1176
2023-02-06 14:12:02 | Valid | Epoch[167/600] Iteration[002/008] Valid loss: 0.0878
2023-02-06 14:12:02 | Valid | Epoch[167/600] Iteration[003/008] Valid loss: 0.0802
2023-02-06 14:12:02 | Valid | Epoch[167/600] Iteration[004/008] Valid loss: 0.0726
2023-02-06 14:12:02 | Valid | Epoch[167/600] Iteration[005/008] Valid loss: 0.0705
2023-02-06 14:12:02 | Valid | Epoch[167/600] Iteration[006/008] Valid loss: 0.0670
2023-02-06 14:12:02 | Valid | Epoch[167/600] Iteration[007/008] Valid loss: 0.0689
2023-02-06 14:12:02 | Valid | Epoch[167/600] Iteration[008/008] Valid loss: 0.0677
2023-02-06 14:12:03 | Valid | Epoch[167/600] MIou: 0.9319380080626681
2023-02-06 14:12:03 | Valid | Epoch[167/600] Pixel Accuracy: 0.9883880615234375
2023-02-06 14:12:03 | Valid | Epoch[167/600] Mean Pixel Accuracy: 0.9543130004727004
2023-02-06 14:12:03 | Stage | Epoch[167/600] Train loss:0.0210
2023-02-06 14:12:03 | Stage | Epoch[167/600] Valid loss:0.0677
2023-02-06 14:12:03 | Stage | Epoch[167/600] LR:0.01

2023-02-06 14:12:03 | Train | Epoch[168/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 14:12:03 | Train | Epoch[168/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 14:12:04 | Train | Epoch[168/600] Iteration[003/030] Train loss: 0.0224
2023-02-06 14:12:04 | Train | Epoch[168/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 14:12:04 | Train | Epoch[168/600] Iteration[005/030] Train loss: 0.0221
2023-02-06 14:12:04 | Train | Epoch[168/600] Iteration[006/030] Train loss: 0.0221
2023-02-06 14:12:04 | Train | Epoch[168/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 14:12:05 | Train | Epoch[168/600] Iteration[008/030] Train loss: 0.0216
2023-02-06 14:12:05 | Train | Epoch[168/600] Iteration[009/030] Train loss: 0.0216
2023-02-06 14:12:05 | Train | Epoch[168/600] Iteration[010/030] Train loss: 0.0214
2023-02-06 14:12:05 | Train | Epoch[168/600] Iteration[011/030] Train loss: 0.0218
2023-02-06 14:12:05 | Train | Epoch[168/600] Iteration[012/030] Train loss: 0.0216
2023-02-06 14:12:06 | Train | Epoch[168/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 14:12:06 | Train | Epoch[168/600] Iteration[014/030] Train loss: 0.0216
2023-02-06 14:12:06 | Train | Epoch[168/600] Iteration[015/030] Train loss: 0.0217
2023-02-06 14:12:06 | Train | Epoch[168/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 14:12:07 | Train | Epoch[168/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 14:12:07 | Train | Epoch[168/600] Iteration[018/030] Train loss: 0.0216
2023-02-06 14:12:07 | Train | Epoch[168/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 14:12:07 | Train | Epoch[168/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 14:12:07 | Train | Epoch[168/600] Iteration[021/030] Train loss: 0.0217
2023-02-06 14:12:08 | Train | Epoch[168/600] Iteration[022/030] Train loss: 0.0217
2023-02-06 14:12:08 | Train | Epoch[168/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 14:12:08 | Train | Epoch[168/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 14:12:08 | Train | Epoch[168/600] Iteration[025/030] Train loss: 0.0216
2023-02-06 14:12:09 | Train | Epoch[168/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 14:12:09 | Train | Epoch[168/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 14:12:09 | Train | Epoch[168/600] Iteration[028/030] Train loss: 0.0215
2023-02-06 14:12:09 | Train | Epoch[168/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 14:12:09 | Train | Epoch[168/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 14:12:10 | Valid | Epoch[168/600] Iteration[001/008] Valid loss: 0.2990
2023-02-06 14:12:10 | Valid | Epoch[168/600] Iteration[002/008] Valid loss: 0.2496
2023-02-06 14:12:10 | Valid | Epoch[168/600] Iteration[003/008] Valid loss: 0.2643
2023-02-06 14:12:10 | Valid | Epoch[168/600] Iteration[004/008] Valid loss: 0.2661
2023-02-06 14:12:10 | Valid | Epoch[168/600] Iteration[005/008] Valid loss: 0.2721
2023-02-06 14:12:10 | Valid | Epoch[168/600] Iteration[006/008] Valid loss: 0.2717
2023-02-06 14:12:10 | Valid | Epoch[168/600] Iteration[007/008] Valid loss: 0.2981
2023-02-06 14:12:10 | Valid | Epoch[168/600] Iteration[008/008] Valid loss: 0.2997
2023-02-06 14:12:10 | Valid | Epoch[168/600] MIou: 0.9053174531419598
2023-02-06 14:12:10 | Valid | Epoch[168/600] Pixel Accuracy: 0.9820823669433594
2023-02-06 14:12:10 | Valid | Epoch[168/600] Mean Pixel Accuracy: 0.9768493954711593
2023-02-06 14:12:10 | Stage | Epoch[168/600] Train loss:0.0214
2023-02-06 14:12:10 | Stage | Epoch[168/600] Valid loss:0.2997
2023-02-06 14:12:10 | Stage | Epoch[168/600] LR:0.01

2023-02-06 14:12:11 | Train | Epoch[169/600] Iteration[001/030] Train loss: 0.0207
2023-02-06 14:12:11 | Train | Epoch[169/600] Iteration[002/030] Train loss: 0.0203
2023-02-06 14:12:11 | Train | Epoch[169/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 14:12:11 | Train | Epoch[169/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 14:12:12 | Train | Epoch[169/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 14:12:12 | Train | Epoch[169/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 14:12:12 | Train | Epoch[169/600] Iteration[007/030] Train loss: 0.0204
2023-02-06 14:12:12 | Train | Epoch[169/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 14:12:12 | Train | Epoch[169/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 14:12:13 | Train | Epoch[169/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 14:12:13 | Train | Epoch[169/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 14:12:13 | Train | Epoch[169/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 14:12:13 | Train | Epoch[169/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 14:12:13 | Train | Epoch[169/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 14:12:14 | Train | Epoch[169/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 14:12:14 | Train | Epoch[169/600] Iteration[016/030] Train loss: 0.0204
2023-02-06 14:12:14 | Train | Epoch[169/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 14:12:14 | Train | Epoch[169/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 14:12:15 | Train | Epoch[169/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 14:12:15 | Train | Epoch[169/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 14:12:15 | Train | Epoch[169/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 14:12:15 | Train | Epoch[169/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 14:12:15 | Train | Epoch[169/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 14:12:16 | Train | Epoch[169/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 14:12:16 | Train | Epoch[169/600] Iteration[025/030] Train loss: 0.0205
2023-02-06 14:12:16 | Train | Epoch[169/600] Iteration[026/030] Train loss: 0.0205
2023-02-06 14:12:16 | Train | Epoch[169/600] Iteration[027/030] Train loss: 0.0205
2023-02-06 14:12:17 | Train | Epoch[169/600] Iteration[028/030] Train loss: 0.0206
2023-02-06 14:12:17 | Train | Epoch[169/600] Iteration[029/030] Train loss: 0.0206
2023-02-06 14:12:17 | Train | Epoch[169/600] Iteration[030/030] Train loss: 0.0206
2023-02-06 14:12:17 | Valid | Epoch[169/600] Iteration[001/008] Valid loss: 0.0724
2023-02-06 14:12:17 | Valid | Epoch[169/600] Iteration[002/008] Valid loss: 0.0691
2023-02-06 14:12:17 | Valid | Epoch[169/600] Iteration[003/008] Valid loss: 0.0689
2023-02-06 14:12:17 | Valid | Epoch[169/600] Iteration[004/008] Valid loss: 0.0666
2023-02-06 14:12:17 | Valid | Epoch[169/600] Iteration[005/008] Valid loss: 0.0663
2023-02-06 14:12:18 | Valid | Epoch[169/600] Iteration[006/008] Valid loss: 0.0648
2023-02-06 14:12:18 | Valid | Epoch[169/600] Iteration[007/008] Valid loss: 0.0633
2023-02-06 14:12:18 | Valid | Epoch[169/600] Iteration[008/008] Valid loss: 0.0641
2023-02-06 14:12:18 | Valid | Epoch[169/600] MIou: 0.8221586370174967
2023-02-06 14:12:18 | Valid | Epoch[169/600] Pixel Accuracy: 0.9705365498860677
2023-02-06 14:12:18 | Valid | Epoch[169/600] Mean Pixel Accuracy: 0.839566244803324
2023-02-06 14:12:18 | Stage | Epoch[169/600] Train loss:0.0206
2023-02-06 14:12:18 | Stage | Epoch[169/600] Valid loss:0.0641
2023-02-06 14:12:18 | Stage | Epoch[169/600] LR:0.01

2023-02-06 14:12:18 | Train | Epoch[170/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 14:12:18 | Train | Epoch[170/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 14:12:19 | Train | Epoch[170/600] Iteration[003/030] Train loss: 0.0197
2023-02-06 14:12:19 | Train | Epoch[170/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 14:12:19 | Train | Epoch[170/600] Iteration[005/030] Train loss: 0.0214
2023-02-06 14:12:19 | Train | Epoch[170/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 14:12:20 | Train | Epoch[170/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 14:12:20 | Train | Epoch[170/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 14:12:20 | Train | Epoch[170/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 14:12:20 | Train | Epoch[170/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 14:12:20 | Train | Epoch[170/600] Iteration[011/030] Train loss: 0.0212
2023-02-06 14:12:21 | Train | Epoch[170/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 14:12:21 | Train | Epoch[170/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 14:12:21 | Train | Epoch[170/600] Iteration[014/030] Train loss: 0.0208
2023-02-06 14:12:21 | Train | Epoch[170/600] Iteration[015/030] Train loss: 0.0207
2023-02-06 14:12:21 | Train | Epoch[170/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 14:12:22 | Train | Epoch[170/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 14:12:22 | Train | Epoch[170/600] Iteration[018/030] Train loss: 0.0206
2023-02-06 14:12:22 | Train | Epoch[170/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 14:12:22 | Train | Epoch[170/600] Iteration[020/030] Train loss: 0.0206
2023-02-06 14:12:23 | Train | Epoch[170/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 14:12:23 | Train | Epoch[170/600] Iteration[022/030] Train loss: 0.0207
2023-02-06 14:12:23 | Train | Epoch[170/600] Iteration[023/030] Train loss: 0.0208
2023-02-06 14:12:23 | Train | Epoch[170/600] Iteration[024/030] Train loss: 0.0208
2023-02-06 14:12:23 | Train | Epoch[170/600] Iteration[025/030] Train loss: 0.0207
2023-02-06 14:12:24 | Train | Epoch[170/600] Iteration[026/030] Train loss: 0.0208
2023-02-06 14:12:24 | Train | Epoch[170/600] Iteration[027/030] Train loss: 0.0208
2023-02-06 14:12:24 | Train | Epoch[170/600] Iteration[028/030] Train loss: 0.0208
2023-02-06 14:12:24 | Train | Epoch[170/600] Iteration[029/030] Train loss: 0.0208
2023-02-06 14:12:24 | Train | Epoch[170/600] Iteration[030/030] Train loss: 0.0208
2023-02-06 14:12:25 | Valid | Epoch[170/600] Iteration[001/008] Valid loss: 0.0835
2023-02-06 14:12:25 | Valid | Epoch[170/600] Iteration[002/008] Valid loss: 0.0661
2023-02-06 14:12:25 | Valid | Epoch[170/600] Iteration[003/008] Valid loss: 0.0650
2023-02-06 14:12:25 | Valid | Epoch[170/600] Iteration[004/008] Valid loss: 0.0608
2023-02-06 14:12:25 | Valid | Epoch[170/600] Iteration[005/008] Valid loss: 0.0600
2023-02-06 14:12:25 | Valid | Epoch[170/600] Iteration[006/008] Valid loss: 0.0590
2023-02-06 14:12:25 | Valid | Epoch[170/600] Iteration[007/008] Valid loss: 0.0584
2023-02-06 14:12:25 | Valid | Epoch[170/600] Iteration[008/008] Valid loss: 0.0568
2023-02-06 14:12:25 | Valid | Epoch[170/600] MIou: 0.91807690876062
2023-02-06 14:12:25 | Valid | Epoch[170/600] Pixel Accuracy: 0.9861628214518229
2023-02-06 14:12:25 | Valid | Epoch[170/600] Mean Pixel Accuracy: 0.9366680924088606
2023-02-06 14:12:25 | Stage | Epoch[170/600] Train loss:0.0208
2023-02-06 14:12:25 | Stage | Epoch[170/600] Valid loss:0.0568
2023-02-06 14:12:25 | Stage | Epoch[170/600] LR:0.01

2023-02-06 14:12:26 | Train | Epoch[171/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 14:12:26 | Train | Epoch[171/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 14:12:26 | Train | Epoch[171/600] Iteration[003/030] Train loss: 0.0197
2023-02-06 14:12:26 | Train | Epoch[171/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 14:12:27 | Train | Epoch[171/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 14:12:27 | Train | Epoch[171/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 14:12:27 | Train | Epoch[171/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 14:12:27 | Train | Epoch[171/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 14:12:27 | Train | Epoch[171/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 14:12:28 | Train | Epoch[171/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 14:12:28 | Train | Epoch[171/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 14:12:28 | Train | Epoch[171/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 14:12:28 | Train | Epoch[171/600] Iteration[013/030] Train loss: 0.0207
2023-02-06 14:12:29 | Train | Epoch[171/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 14:12:29 | Train | Epoch[171/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 14:12:29 | Train | Epoch[171/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 14:12:29 | Train | Epoch[171/600] Iteration[017/030] Train loss: 0.0206
2023-02-06 14:12:29 | Train | Epoch[171/600] Iteration[018/030] Train loss: 0.0206
2023-02-06 14:12:30 | Train | Epoch[171/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 14:12:30 | Train | Epoch[171/600] Iteration[020/030] Train loss: 0.0206
2023-02-06 14:12:30 | Train | Epoch[171/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 14:12:30 | Train | Epoch[171/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 14:12:30 | Train | Epoch[171/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 14:12:31 | Train | Epoch[171/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 14:12:31 | Train | Epoch[171/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 14:12:31 | Train | Epoch[171/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 14:12:31 | Train | Epoch[171/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 14:12:32 | Train | Epoch[171/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 14:12:32 | Train | Epoch[171/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 14:12:32 | Train | Epoch[171/600] Iteration[030/030] Train loss: 0.0204
2023-02-06 14:12:32 | Valid | Epoch[171/600] Iteration[001/008] Valid loss: 0.0870
2023-02-06 14:12:32 | Valid | Epoch[171/600] Iteration[002/008] Valid loss: 0.0662
2023-02-06 14:12:32 | Valid | Epoch[171/600] Iteration[003/008] Valid loss: 0.0640
2023-02-06 14:12:32 | Valid | Epoch[171/600] Iteration[004/008] Valid loss: 0.0591
2023-02-06 14:12:32 | Valid | Epoch[171/600] Iteration[005/008] Valid loss: 0.0570
2023-02-06 14:12:32 | Valid | Epoch[171/600] Iteration[006/008] Valid loss: 0.0566
2023-02-06 14:12:33 | Valid | Epoch[171/600] Iteration[007/008] Valid loss: 0.0572
2023-02-06 14:12:33 | Valid | Epoch[171/600] Iteration[008/008] Valid loss: 0.0559
2023-02-06 14:12:33 | Valid | Epoch[171/600] MIou: 0.9186710981936363
2023-02-06 14:12:33 | Valid | Epoch[171/600] Pixel Accuracy: 0.9862200419108073
2023-02-06 14:12:33 | Valid | Epoch[171/600] Mean Pixel Accuracy: 0.938608025138648
2023-02-06 14:12:33 | Stage | Epoch[171/600] Train loss:0.0204
2023-02-06 14:12:33 | Stage | Epoch[171/600] Valid loss:0.0559
2023-02-06 14:12:33 | Stage | Epoch[171/600] LR:0.01

2023-02-06 14:12:33 | Train | Epoch[172/600] Iteration[001/030] Train loss: 0.0208
2023-02-06 14:12:33 | Train | Epoch[172/600] Iteration[002/030] Train loss: 0.0203
2023-02-06 14:12:34 | Train | Epoch[172/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 14:12:34 | Train | Epoch[172/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 14:12:34 | Train | Epoch[172/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 14:12:34 | Train | Epoch[172/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 14:12:34 | Train | Epoch[172/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 14:12:35 | Train | Epoch[172/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 14:12:35 | Train | Epoch[172/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 14:12:35 | Train | Epoch[172/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 14:12:35 | Train | Epoch[172/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 14:12:36 | Train | Epoch[172/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 14:12:36 | Train | Epoch[172/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 14:12:36 | Train | Epoch[172/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 14:12:36 | Train | Epoch[172/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 14:12:36 | Train | Epoch[172/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 14:12:37 | Train | Epoch[172/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 14:12:37 | Train | Epoch[172/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 14:12:37 | Train | Epoch[172/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 14:12:37 | Train | Epoch[172/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 14:12:38 | Train | Epoch[172/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 14:12:38 | Train | Epoch[172/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 14:12:38 | Train | Epoch[172/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 14:12:38 | Train | Epoch[172/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 14:12:38 | Train | Epoch[172/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 14:12:39 | Train | Epoch[172/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 14:12:39 | Train | Epoch[172/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 14:12:39 | Train | Epoch[172/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 14:12:39 | Train | Epoch[172/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 14:12:39 | Train | Epoch[172/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 14:12:40 | Valid | Epoch[172/600] Iteration[001/008] Valid loss: 0.2409
2023-02-06 14:12:40 | Valid | Epoch[172/600] Iteration[002/008] Valid loss: 0.2142
2023-02-06 14:12:40 | Valid | Epoch[172/600] Iteration[003/008] Valid loss: 0.2288
2023-02-06 14:12:40 | Valid | Epoch[172/600] Iteration[004/008] Valid loss: 0.2193
2023-02-06 14:12:40 | Valid | Epoch[172/600] Iteration[005/008] Valid loss: 0.2248
2023-02-06 14:12:40 | Valid | Epoch[172/600] Iteration[006/008] Valid loss: 0.2244
2023-02-06 14:12:40 | Valid | Epoch[172/600] Iteration[007/008] Valid loss: 0.2426
2023-02-06 14:12:40 | Valid | Epoch[172/600] Iteration[008/008] Valid loss: 0.2403
2023-02-06 14:12:40 | Valid | Epoch[172/600] MIou: 0.9061340177231798
2023-02-06 14:12:40 | Valid | Epoch[172/600] Pixel Accuracy: 0.9822743733723959
2023-02-06 14:12:40 | Valid | Epoch[172/600] Mean Pixel Accuracy: 0.9766696091753904
2023-02-06 14:12:40 | Stage | Epoch[172/600] Train loss:0.0201
2023-02-06 14:12:40 | Stage | Epoch[172/600] Valid loss:0.2403
2023-02-06 14:12:40 | Stage | Epoch[172/600] LR:0.01

2023-02-06 14:12:41 | Train | Epoch[173/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 14:12:41 | Train | Epoch[173/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 14:12:41 | Train | Epoch[173/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 14:12:41 | Train | Epoch[173/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 14:12:41 | Train | Epoch[173/600] Iteration[005/030] Train loss: 0.0193
2023-02-06 14:12:42 | Train | Epoch[173/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 14:12:42 | Train | Epoch[173/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 14:12:42 | Train | Epoch[173/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 14:12:42 | Train | Epoch[173/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 14:12:43 | Train | Epoch[173/600] Iteration[010/030] Train loss: 0.0192
2023-02-06 14:12:43 | Train | Epoch[173/600] Iteration[011/030] Train loss: 0.0191
2023-02-06 14:12:43 | Train | Epoch[173/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 14:12:43 | Train | Epoch[173/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 14:12:43 | Train | Epoch[173/600] Iteration[014/030] Train loss: 0.0192
2023-02-06 14:12:44 | Train | Epoch[173/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 14:12:44 | Train | Epoch[173/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 14:12:44 | Train | Epoch[173/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 14:12:44 | Train | Epoch[173/600] Iteration[018/030] Train loss: 0.0195
2023-02-06 14:12:45 | Train | Epoch[173/600] Iteration[019/030] Train loss: 0.0194
2023-02-06 14:12:45 | Train | Epoch[173/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 14:12:45 | Train | Epoch[173/600] Iteration[021/030] Train loss: 0.0195
2023-02-06 14:12:45 | Train | Epoch[173/600] Iteration[022/030] Train loss: 0.0195
2023-02-06 14:12:45 | Train | Epoch[173/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 14:12:46 | Train | Epoch[173/600] Iteration[024/030] Train loss: 0.0196
2023-02-06 14:12:46 | Train | Epoch[173/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 14:12:46 | Train | Epoch[173/600] Iteration[026/030] Train loss: 0.0196
2023-02-06 14:12:46 | Train | Epoch[173/600] Iteration[027/030] Train loss: 0.0196
2023-02-06 14:12:47 | Train | Epoch[173/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 14:12:47 | Train | Epoch[173/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 14:12:47 | Train | Epoch[173/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 14:12:47 | Valid | Epoch[173/600] Iteration[001/008] Valid loss: 1.8164
2023-02-06 14:12:47 | Valid | Epoch[173/600] Iteration[002/008] Valid loss: 1.7521
2023-02-06 14:12:47 | Valid | Epoch[173/600] Iteration[003/008] Valid loss: 1.8590
2023-02-06 14:12:47 | Valid | Epoch[173/600] Iteration[004/008] Valid loss: 1.8785
2023-02-06 14:12:47 | Valid | Epoch[173/600] Iteration[005/008] Valid loss: 1.9262
2023-02-06 14:12:47 | Valid | Epoch[173/600] Iteration[006/008] Valid loss: 1.8936
2023-02-06 14:12:48 | Valid | Epoch[173/600] Iteration[007/008] Valid loss: 1.9626
2023-02-06 14:12:48 | Valid | Epoch[173/600] Iteration[008/008] Valid loss: 2.0598
2023-02-06 14:12:48 | Valid | Epoch[173/600] MIou: 0.7957220259596594
2023-02-06 14:12:48 | Valid | Epoch[173/600] Pixel Accuracy: 0.9506365458170573
2023-02-06 14:12:48 | Valid | Epoch[173/600] Mean Pixel Accuracy: 0.9710733868427344
2023-02-06 14:12:48 | Stage | Epoch[173/600] Train loss:0.0198
2023-02-06 14:12:48 | Stage | Epoch[173/600] Valid loss:2.0598
2023-02-06 14:12:48 | Stage | Epoch[173/600] LR:0.01

2023-02-06 14:12:48 | Train | Epoch[174/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 14:12:48 | Train | Epoch[174/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 14:12:49 | Train | Epoch[174/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 14:12:49 | Train | Epoch[174/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 14:12:49 | Train | Epoch[174/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 14:12:49 | Train | Epoch[174/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 14:12:49 | Train | Epoch[174/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 14:12:50 | Train | Epoch[174/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 14:12:50 | Train | Epoch[174/600] Iteration[009/030] Train loss: 0.0196
2023-02-06 14:12:50 | Train | Epoch[174/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 14:12:50 | Train | Epoch[174/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 14:12:51 | Train | Epoch[174/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 14:12:51 | Train | Epoch[174/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 14:12:51 | Train | Epoch[174/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 14:12:51 | Train | Epoch[174/600] Iteration[015/030] Train loss: 0.0207
2023-02-06 14:12:51 | Train | Epoch[174/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 14:12:52 | Train | Epoch[174/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 14:12:52 | Train | Epoch[174/600] Iteration[018/030] Train loss: 0.0206
2023-02-06 14:12:52 | Train | Epoch[174/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 14:12:52 | Train | Epoch[174/600] Iteration[020/030] Train loss: 0.0207
2023-02-06 14:12:53 | Train | Epoch[174/600] Iteration[021/030] Train loss: 0.0207
2023-02-06 14:12:53 | Train | Epoch[174/600] Iteration[022/030] Train loss: 0.0207
2023-02-06 14:12:53 | Train | Epoch[174/600] Iteration[023/030] Train loss: 0.0207
2023-02-06 14:12:53 | Train | Epoch[174/600] Iteration[024/030] Train loss: 0.0207
2023-02-06 14:12:53 | Train | Epoch[174/600] Iteration[025/030] Train loss: 0.0207
2023-02-06 14:12:54 | Train | Epoch[174/600] Iteration[026/030] Train loss: 0.0207
2023-02-06 14:12:54 | Train | Epoch[174/600] Iteration[027/030] Train loss: 0.0207
2023-02-06 14:12:54 | Train | Epoch[174/600] Iteration[028/030] Train loss: 0.0207
2023-02-06 14:12:54 | Train | Epoch[174/600] Iteration[029/030] Train loss: 0.0206
2023-02-06 14:12:54 | Train | Epoch[174/600] Iteration[030/030] Train loss: 0.0207
2023-02-06 14:12:55 | Valid | Epoch[174/600] Iteration[001/008] Valid loss: 0.1924
2023-02-06 14:12:55 | Valid | Epoch[174/600] Iteration[002/008] Valid loss: 0.2099
2023-02-06 14:12:55 | Valid | Epoch[174/600] Iteration[003/008] Valid loss: 0.2218
2023-02-06 14:12:55 | Valid | Epoch[174/600] Iteration[004/008] Valid loss: 0.2241
2023-02-06 14:12:55 | Valid | Epoch[174/600] Iteration[005/008] Valid loss: 0.2299
2023-02-06 14:12:55 | Valid | Epoch[174/600] Iteration[006/008] Valid loss: 0.2258
2023-02-06 14:12:55 | Valid | Epoch[174/600] Iteration[007/008] Valid loss: 0.2193
2023-02-06 14:12:55 | Valid | Epoch[174/600] Iteration[008/008] Valid loss: 0.2277
2023-02-06 14:12:55 | Valid | Epoch[174/600] MIou: 0.5056256920015718
2023-02-06 14:12:55 | Valid | Epoch[174/600] Pixel Accuracy: 0.9181493123372396
2023-02-06 14:12:55 | Valid | Epoch[174/600] Mean Pixel Accuracy: 0.5469005818666196
2023-02-06 14:12:55 | Stage | Epoch[174/600] Train loss:0.0207
2023-02-06 14:12:55 | Stage | Epoch[174/600] Valid loss:0.2277
2023-02-06 14:12:55 | Stage | Epoch[174/600] LR:0.01

2023-02-06 14:12:56 | Train | Epoch[175/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 14:12:56 | Train | Epoch[175/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 14:12:56 | Train | Epoch[175/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 14:12:56 | Train | Epoch[175/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 14:12:57 | Train | Epoch[175/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 14:12:57 | Train | Epoch[175/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 14:12:57 | Train | Epoch[175/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 14:12:57 | Train | Epoch[175/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 14:12:57 | Train | Epoch[175/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 14:12:58 | Train | Epoch[175/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 14:12:58 | Train | Epoch[175/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 14:12:58 | Train | Epoch[175/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 14:12:58 | Train | Epoch[175/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 14:12:58 | Train | Epoch[175/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 14:12:59 | Train | Epoch[175/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 14:12:59 | Train | Epoch[175/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 14:12:59 | Train | Epoch[175/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 14:12:59 | Train | Epoch[175/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 14:13:00 | Train | Epoch[175/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 14:13:00 | Train | Epoch[175/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 14:13:00 | Train | Epoch[175/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 14:13:00 | Train | Epoch[175/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 14:13:00 | Train | Epoch[175/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 14:13:01 | Train | Epoch[175/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 14:13:01 | Train | Epoch[175/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 14:13:01 | Train | Epoch[175/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 14:13:01 | Train | Epoch[175/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 14:13:02 | Train | Epoch[175/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 14:13:02 | Train | Epoch[175/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 14:13:02 | Train | Epoch[175/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 14:13:02 | Valid | Epoch[175/600] Iteration[001/008] Valid loss: 0.6858
2023-02-06 14:13:02 | Valid | Epoch[175/600] Iteration[002/008] Valid loss: 0.6230
2023-02-06 14:13:02 | Valid | Epoch[175/600] Iteration[003/008] Valid loss: 0.6254
2023-02-06 14:13:02 | Valid | Epoch[175/600] Iteration[004/008] Valid loss: 0.6199
2023-02-06 14:13:02 | Valid | Epoch[175/600] Iteration[005/008] Valid loss: 0.6386
2023-02-06 14:13:02 | Valid | Epoch[175/600] Iteration[006/008] Valid loss: 0.6200
2023-02-06 14:13:03 | Valid | Epoch[175/600] Iteration[007/008] Valid loss: 0.6612
2023-02-06 14:13:03 | Valid | Epoch[175/600] Iteration[008/008] Valid loss: 0.6842
2023-02-06 14:13:03 | Valid | Epoch[175/600] MIou: 0.8842994654309204
2023-02-06 14:13:03 | Valid | Epoch[175/600] Pixel Accuracy: 0.9768549601236979
2023-02-06 14:13:03 | Valid | Epoch[175/600] Mean Pixel Accuracy: 0.981781310170935
2023-02-06 14:13:03 | Stage | Epoch[175/600] Train loss:0.0203
2023-02-06 14:13:03 | Stage | Epoch[175/600] Valid loss:0.6842
2023-02-06 14:13:03 | Stage | Epoch[175/600] LR:0.01

2023-02-06 14:13:03 | Train | Epoch[176/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 14:13:03 | Train | Epoch[176/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 14:13:04 | Train | Epoch[176/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 14:13:04 | Train | Epoch[176/600] Iteration[004/030] Train loss: 0.0195
2023-02-06 14:13:04 | Train | Epoch[176/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 14:13:04 | Train | Epoch[176/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 14:13:04 | Train | Epoch[176/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 14:13:05 | Train | Epoch[176/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 14:13:05 | Train | Epoch[176/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 14:13:05 | Train | Epoch[176/600] Iteration[010/030] Train loss: 0.0193
2023-02-06 14:13:05 | Train | Epoch[176/600] Iteration[011/030] Train loss: 0.0193
2023-02-06 14:13:06 | Train | Epoch[176/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 14:13:06 | Train | Epoch[176/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 14:13:06 | Train | Epoch[176/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 14:13:06 | Train | Epoch[176/600] Iteration[015/030] Train loss: 0.0192
2023-02-06 14:13:06 | Train | Epoch[176/600] Iteration[016/030] Train loss: 0.0192
2023-02-06 14:13:07 | Train | Epoch[176/600] Iteration[017/030] Train loss: 0.0191
2023-02-06 14:13:07 | Train | Epoch[176/600] Iteration[018/030] Train loss: 0.0192
2023-02-06 14:13:07 | Train | Epoch[176/600] Iteration[019/030] Train loss: 0.0192
2023-02-06 14:13:07 | Train | Epoch[176/600] Iteration[020/030] Train loss: 0.0192
2023-02-06 14:13:08 | Train | Epoch[176/600] Iteration[021/030] Train loss: 0.0192
2023-02-06 14:13:08 | Train | Epoch[176/600] Iteration[022/030] Train loss: 0.0192
2023-02-06 14:13:08 | Train | Epoch[176/600] Iteration[023/030] Train loss: 0.0193
2023-02-06 14:13:08 | Train | Epoch[176/600] Iteration[024/030] Train loss: 0.0194
2023-02-06 14:13:08 | Train | Epoch[176/600] Iteration[025/030] Train loss: 0.0194
2023-02-06 14:13:09 | Train | Epoch[176/600] Iteration[026/030] Train loss: 0.0194
2023-02-06 14:13:09 | Train | Epoch[176/600] Iteration[027/030] Train loss: 0.0194
2023-02-06 14:13:09 | Train | Epoch[176/600] Iteration[028/030] Train loss: 0.0194
2023-02-06 14:13:09 | Train | Epoch[176/600] Iteration[029/030] Train loss: 0.0194
2023-02-06 14:13:09 | Train | Epoch[176/600] Iteration[030/030] Train loss: 0.0194
2023-02-06 14:13:10 | Valid | Epoch[176/600] Iteration[001/008] Valid loss: 1.9529
2023-02-06 14:13:10 | Valid | Epoch[176/600] Iteration[002/008] Valid loss: 1.9357
2023-02-06 14:13:10 | Valid | Epoch[176/600] Iteration[003/008] Valid loss: 2.0501
2023-02-06 14:13:10 | Valid | Epoch[176/600] Iteration[004/008] Valid loss: 2.0949
2023-02-06 14:13:10 | Valid | Epoch[176/600] Iteration[005/008] Valid loss: 2.1417
2023-02-06 14:13:10 | Valid | Epoch[176/600] Iteration[006/008] Valid loss: 2.0955
2023-02-06 14:13:10 | Valid | Epoch[176/600] Iteration[007/008] Valid loss: 2.1671
2023-02-06 14:13:10 | Valid | Epoch[176/600] Iteration[008/008] Valid loss: 2.2733
2023-02-06 14:13:10 | Valid | Epoch[176/600] MIou: 0.7659984037406365
2023-02-06 14:13:10 | Valid | Epoch[176/600] Pixel Accuracy: 0.939581553141276
2023-02-06 14:13:10 | Valid | Epoch[176/600] Mean Pixel Accuracy: 0.9653204554312069
2023-02-06 14:13:10 | Stage | Epoch[176/600] Train loss:0.0194
2023-02-06 14:13:10 | Stage | Epoch[176/600] Valid loss:2.2733
2023-02-06 14:13:10 | Stage | Epoch[176/600] LR:0.01

2023-02-06 14:13:11 | Train | Epoch[177/600] Iteration[001/030] Train loss: 0.0183
2023-02-06 14:13:11 | Train | Epoch[177/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 14:13:11 | Train | Epoch[177/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 14:13:11 | Train | Epoch[177/600] Iteration[004/030] Train loss: 0.0186
2023-02-06 14:13:12 | Train | Epoch[177/600] Iteration[005/030] Train loss: 0.0187
2023-02-06 14:13:12 | Train | Epoch[177/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 14:13:12 | Train | Epoch[177/600] Iteration[007/030] Train loss: 0.0188
2023-02-06 14:13:12 | Train | Epoch[177/600] Iteration[008/030] Train loss: 0.0187
2023-02-06 14:13:12 | Train | Epoch[177/600] Iteration[009/030] Train loss: 0.0187
2023-02-06 14:13:13 | Train | Epoch[177/600] Iteration[010/030] Train loss: 0.0187
2023-02-06 14:13:13 | Train | Epoch[177/600] Iteration[011/030] Train loss: 0.0189
2023-02-06 14:13:13 | Train | Epoch[177/600] Iteration[012/030] Train loss: 0.0191
2023-02-06 14:13:13 | Train | Epoch[177/600] Iteration[013/030] Train loss: 0.0191
2023-02-06 14:13:13 | Train | Epoch[177/600] Iteration[014/030] Train loss: 0.0191
2023-02-06 14:13:14 | Train | Epoch[177/600] Iteration[015/030] Train loss: 0.0190
2023-02-06 14:13:14 | Train | Epoch[177/600] Iteration[016/030] Train loss: 0.0190
2023-02-06 14:13:14 | Train | Epoch[177/600] Iteration[017/030] Train loss: 0.0191
2023-02-06 14:13:14 | Train | Epoch[177/600] Iteration[018/030] Train loss: 0.0192
2023-02-06 14:13:15 | Train | Epoch[177/600] Iteration[019/030] Train loss: 0.0193
2023-02-06 14:13:15 | Train | Epoch[177/600] Iteration[020/030] Train loss: 0.0192
2023-02-06 14:13:15 | Train | Epoch[177/600] Iteration[021/030] Train loss: 0.0192
2023-02-06 14:13:15 | Train | Epoch[177/600] Iteration[022/030] Train loss: 0.0192
2023-02-06 14:13:15 | Train | Epoch[177/600] Iteration[023/030] Train loss: 0.0191
2023-02-06 14:13:16 | Train | Epoch[177/600] Iteration[024/030] Train loss: 0.0191
2023-02-06 14:13:16 | Train | Epoch[177/600] Iteration[025/030] Train loss: 0.0191
2023-02-06 14:13:16 | Train | Epoch[177/600] Iteration[026/030] Train loss: 0.0192
2023-02-06 14:13:16 | Train | Epoch[177/600] Iteration[027/030] Train loss: 0.0192
2023-02-06 14:13:17 | Train | Epoch[177/600] Iteration[028/030] Train loss: 0.0192
2023-02-06 14:13:17 | Train | Epoch[177/600] Iteration[029/030] Train loss: 0.0193
2023-02-06 14:13:17 | Train | Epoch[177/600] Iteration[030/030] Train loss: 0.0193
2023-02-06 14:13:17 | Valid | Epoch[177/600] Iteration[001/008] Valid loss: 0.0681
2023-02-06 14:13:17 | Valid | Epoch[177/600] Iteration[002/008] Valid loss: 0.0588
2023-02-06 14:13:17 | Valid | Epoch[177/600] Iteration[003/008] Valid loss: 0.0580
2023-02-06 14:13:17 | Valid | Epoch[177/600] Iteration[004/008] Valid loss: 0.0555
2023-02-06 14:13:17 | Valid | Epoch[177/600] Iteration[005/008] Valid loss: 0.0560
2023-02-06 14:13:17 | Valid | Epoch[177/600] Iteration[006/008] Valid loss: 0.0540
2023-02-06 14:13:18 | Valid | Epoch[177/600] Iteration[007/008] Valid loss: 0.0522
2023-02-06 14:13:18 | Valid | Epoch[177/600] Iteration[008/008] Valid loss: 0.0521
2023-02-06 14:13:18 | Valid | Epoch[177/600] MIou: 0.8914665649832352
2023-02-06 14:13:18 | Valid | Epoch[177/600] Pixel Accuracy: 0.9818496704101562
2023-02-06 14:13:18 | Valid | Epoch[177/600] Mean Pixel Accuracy: 0.9074772061488202
2023-02-06 14:13:18 | Stage | Epoch[177/600] Train loss:0.0193
2023-02-06 14:13:18 | Stage | Epoch[177/600] Valid loss:0.0521
2023-02-06 14:13:18 | Stage | Epoch[177/600] LR:0.01

2023-02-06 14:13:18 | Train | Epoch[178/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 14:13:18 | Train | Epoch[178/600] Iteration[002/030] Train loss: 0.0191
2023-02-06 14:13:19 | Train | Epoch[178/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 14:13:19 | Train | Epoch[178/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 14:13:19 | Train | Epoch[178/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 14:13:19 | Train | Epoch[178/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 14:13:19 | Train | Epoch[178/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 14:13:20 | Train | Epoch[178/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 14:13:20 | Train | Epoch[178/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 14:13:20 | Train | Epoch[178/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 14:13:20 | Train | Epoch[178/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 14:13:21 | Train | Epoch[178/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 14:13:21 | Train | Epoch[178/600] Iteration[013/030] Train loss: 0.0193
2023-02-06 14:13:21 | Train | Epoch[178/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 14:13:21 | Train | Epoch[178/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 14:13:21 | Train | Epoch[178/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 14:13:22 | Train | Epoch[178/600] Iteration[017/030] Train loss: 0.0194
2023-02-06 14:13:22 | Train | Epoch[178/600] Iteration[018/030] Train loss: 0.0194
2023-02-06 14:13:22 | Train | Epoch[178/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 14:13:22 | Train | Epoch[178/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 14:13:22 | Train | Epoch[178/600] Iteration[021/030] Train loss: 0.0195
2023-02-06 14:13:23 | Train | Epoch[178/600] Iteration[022/030] Train loss: 0.0195
2023-02-06 14:13:23 | Train | Epoch[178/600] Iteration[023/030] Train loss: 0.0194
2023-02-06 14:13:23 | Train | Epoch[178/600] Iteration[024/030] Train loss: 0.0194
2023-02-06 14:13:23 | Train | Epoch[178/600] Iteration[025/030] Train loss: 0.0194
2023-02-06 14:13:24 | Train | Epoch[178/600] Iteration[026/030] Train loss: 0.0194
2023-02-06 14:13:24 | Train | Epoch[178/600] Iteration[027/030] Train loss: 0.0195
2023-02-06 14:13:24 | Train | Epoch[178/600] Iteration[028/030] Train loss: 0.0196
2023-02-06 14:13:24 | Train | Epoch[178/600] Iteration[029/030] Train loss: 0.0196
2023-02-06 14:13:24 | Train | Epoch[178/600] Iteration[030/030] Train loss: 0.0197
2023-02-06 14:13:25 | Valid | Epoch[178/600] Iteration[001/008] Valid loss: 0.9519
2023-02-06 14:13:25 | Valid | Epoch[178/600] Iteration[002/008] Valid loss: 0.9284
2023-02-06 14:13:25 | Valid | Epoch[178/600] Iteration[003/008] Valid loss: 0.9516
2023-02-06 14:13:25 | Valid | Epoch[178/600] Iteration[004/008] Valid loss: 0.9548
2023-02-06 14:13:25 | Valid | Epoch[178/600] Iteration[005/008] Valid loss: 0.9789
2023-02-06 14:13:25 | Valid | Epoch[178/600] Iteration[006/008] Valid loss: 0.9587
2023-02-06 14:13:25 | Valid | Epoch[178/600] Iteration[007/008] Valid loss: 1.0166
2023-02-06 14:13:25 | Valid | Epoch[178/600] Iteration[008/008] Valid loss: 1.0628
2023-02-06 14:13:25 | Valid | Epoch[178/600] MIou: 0.851768022607482
2023-02-06 14:13:25 | Valid | Epoch[178/600] Pixel Accuracy: 0.9682807922363281
2023-02-06 14:13:25 | Valid | Epoch[178/600] Mean Pixel Accuracy: 0.9785839545120076
2023-02-06 14:13:25 | Stage | Epoch[178/600] Train loss:0.0197
2023-02-06 14:13:25 | Stage | Epoch[178/600] Valid loss:1.0628
2023-02-06 14:13:25 | Stage | Epoch[178/600] LR:0.01

2023-02-06 14:13:26 | Train | Epoch[179/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 14:13:26 | Train | Epoch[179/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 14:13:26 | Train | Epoch[179/600] Iteration[003/030] Train loss: 0.0197
2023-02-06 14:13:26 | Train | Epoch[179/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 14:13:27 | Train | Epoch[179/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 14:13:27 | Train | Epoch[179/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 14:13:27 | Train | Epoch[179/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 14:13:27 | Train | Epoch[179/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 14:13:27 | Train | Epoch[179/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 14:13:28 | Train | Epoch[179/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 14:13:28 | Train | Epoch[179/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 14:13:28 | Train | Epoch[179/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 14:13:28 | Train | Epoch[179/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 14:13:28 | Train | Epoch[179/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 14:13:29 | Train | Epoch[179/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 14:13:29 | Train | Epoch[179/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 14:13:29 | Train | Epoch[179/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 14:13:29 | Train | Epoch[179/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 14:13:30 | Train | Epoch[179/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 14:13:30 | Train | Epoch[179/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 14:13:30 | Train | Epoch[179/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 14:13:30 | Train | Epoch[179/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 14:13:30 | Train | Epoch[179/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 14:13:31 | Train | Epoch[179/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 14:13:31 | Train | Epoch[179/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 14:13:31 | Train | Epoch[179/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 14:13:31 | Train | Epoch[179/600] Iteration[027/030] Train loss: 0.0197
2023-02-06 14:13:32 | Train | Epoch[179/600] Iteration[028/030] Train loss: 0.0196
2023-02-06 14:13:32 | Train | Epoch[179/600] Iteration[029/030] Train loss: 0.0196
2023-02-06 14:13:32 | Train | Epoch[179/600] Iteration[030/030] Train loss: 0.0196
2023-02-06 14:13:32 | Valid | Epoch[179/600] Iteration[001/008] Valid loss: 0.2764
2023-02-06 14:13:32 | Valid | Epoch[179/600] Iteration[002/008] Valid loss: 0.2086
2023-02-06 14:13:32 | Valid | Epoch[179/600] Iteration[003/008] Valid loss: 0.1996
2023-02-06 14:13:32 | Valid | Epoch[179/600] Iteration[004/008] Valid loss: 0.1941
2023-02-06 14:13:32 | Valid | Epoch[179/600] Iteration[005/008] Valid loss: 0.1938
2023-02-06 14:13:32 | Valid | Epoch[179/600] Iteration[006/008] Valid loss: 0.1845
2023-02-06 14:13:33 | Valid | Epoch[179/600] Iteration[007/008] Valid loss: 0.1958
2023-02-06 14:13:33 | Valid | Epoch[179/600] Iteration[008/008] Valid loss: 0.2018
2023-02-06 14:13:33 | Valid | Epoch[179/600] MIou: 0.9163813914211808
2023-02-06 14:13:33 | Valid | Epoch[179/600] Pixel Accuracy: 0.9847539265950521
2023-02-06 14:13:33 | Valid | Epoch[179/600] Mean Pixel Accuracy: 0.9701829736449946
2023-02-06 14:13:33 | Stage | Epoch[179/600] Train loss:0.0196
2023-02-06 14:13:33 | Stage | Epoch[179/600] Valid loss:0.2018
2023-02-06 14:13:33 | Stage | Epoch[179/600] LR:0.01

2023-02-06 14:13:33 | Train | Epoch[180/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 14:13:33 | Train | Epoch[180/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 14:13:34 | Train | Epoch[180/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 14:13:34 | Train | Epoch[180/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 14:13:34 | Train | Epoch[180/600] Iteration[005/030] Train loss: 0.0181
2023-02-06 14:13:34 | Train | Epoch[180/600] Iteration[006/030] Train loss: 0.0182
2023-02-06 14:13:34 | Train | Epoch[180/600] Iteration[007/030] Train loss: 0.0182
2023-02-06 14:13:35 | Train | Epoch[180/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 14:13:35 | Train | Epoch[180/600] Iteration[009/030] Train loss: 0.0182
2023-02-06 14:13:35 | Train | Epoch[180/600] Iteration[010/030] Train loss: 0.0184
2023-02-06 14:13:35 | Train | Epoch[180/600] Iteration[011/030] Train loss: 0.0183
2023-02-06 14:13:36 | Train | Epoch[180/600] Iteration[012/030] Train loss: 0.0183
2023-02-06 14:13:36 | Train | Epoch[180/600] Iteration[013/030] Train loss: 0.0183
2023-02-06 14:13:36 | Train | Epoch[180/600] Iteration[014/030] Train loss: 0.0183
2023-02-06 14:13:36 | Train | Epoch[180/600] Iteration[015/030] Train loss: 0.0184
2023-02-06 14:13:36 | Train | Epoch[180/600] Iteration[016/030] Train loss: 0.0184
2023-02-06 14:13:37 | Train | Epoch[180/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 14:13:37 | Train | Epoch[180/600] Iteration[018/030] Train loss: 0.0186
2023-02-06 14:13:37 | Train | Epoch[180/600] Iteration[019/030] Train loss: 0.0186
2023-02-06 14:13:37 | Train | Epoch[180/600] Iteration[020/030] Train loss: 0.0186
2023-02-06 14:13:37 | Train | Epoch[180/600] Iteration[021/030] Train loss: 0.0186
2023-02-06 14:13:38 | Train | Epoch[180/600] Iteration[022/030] Train loss: 0.0187
2023-02-06 14:13:38 | Train | Epoch[180/600] Iteration[023/030] Train loss: 0.0186
2023-02-06 14:13:38 | Train | Epoch[180/600] Iteration[024/030] Train loss: 0.0186
2023-02-06 14:13:38 | Train | Epoch[180/600] Iteration[025/030] Train loss: 0.0187
2023-02-06 14:13:39 | Train | Epoch[180/600] Iteration[026/030] Train loss: 0.0188
2023-02-06 14:13:39 | Train | Epoch[180/600] Iteration[027/030] Train loss: 0.0188
2023-02-06 14:13:39 | Train | Epoch[180/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 14:13:39 | Train | Epoch[180/600] Iteration[029/030] Train loss: 0.0188
2023-02-06 14:13:39 | Train | Epoch[180/600] Iteration[030/030] Train loss: 0.0189
2023-02-06 14:13:40 | Valid | Epoch[180/600] Iteration[001/008] Valid loss: 1.6397
2023-02-06 14:13:40 | Valid | Epoch[180/600] Iteration[002/008] Valid loss: 1.5793
2023-02-06 14:13:40 | Valid | Epoch[180/600] Iteration[003/008] Valid loss: 1.6795
2023-02-06 14:13:40 | Valid | Epoch[180/600] Iteration[004/008] Valid loss: 1.6961
2023-02-06 14:13:40 | Valid | Epoch[180/600] Iteration[005/008] Valid loss: 1.7217
2023-02-06 14:13:40 | Valid | Epoch[180/600] Iteration[006/008] Valid loss: 1.6832
2023-02-06 14:13:40 | Valid | Epoch[180/600] Iteration[007/008] Valid loss: 1.7304
2023-02-06 14:13:40 | Valid | Epoch[180/600] Iteration[008/008] Valid loss: 1.8222
2023-02-06 14:13:40 | Valid | Epoch[180/600] MIou: 0.8150504762066662
2023-02-06 14:13:40 | Valid | Epoch[180/600] Pixel Accuracy: 0.9571571350097656
2023-02-06 14:13:40 | Valid | Epoch[180/600] Mean Pixel Accuracy: 0.9742135477536042
2023-02-06 14:13:40 | Stage | Epoch[180/600] Train loss:0.0189
2023-02-06 14:13:40 | Stage | Epoch[180/600] Valid loss:1.8222
2023-02-06 14:13:40 | Stage | Epoch[180/600] LR:0.01

2023-02-06 14:13:41 | Train | Epoch[181/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 14:13:41 | Train | Epoch[181/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 14:13:41 | Train | Epoch[181/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 14:13:41 | Train | Epoch[181/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 14:13:42 | Train | Epoch[181/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 14:13:42 | Train | Epoch[181/600] Iteration[006/030] Train loss: 0.0190
2023-02-06 14:13:42 | Train | Epoch[181/600] Iteration[007/030] Train loss: 0.0189
2023-02-06 14:13:42 | Train | Epoch[181/600] Iteration[008/030] Train loss: 0.0186
2023-02-06 14:13:42 | Train | Epoch[181/600] Iteration[009/030] Train loss: 0.0186
2023-02-06 14:13:43 | Train | Epoch[181/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 14:13:43 | Train | Epoch[181/600] Iteration[011/030] Train loss: 0.0185
2023-02-06 14:13:43 | Train | Epoch[181/600] Iteration[012/030] Train loss: 0.0185
2023-02-06 14:13:43 | Train | Epoch[181/600] Iteration[013/030] Train loss: 0.0184
2023-02-06 14:13:43 | Train | Epoch[181/600] Iteration[014/030] Train loss: 0.0183
2023-02-06 14:13:44 | Train | Epoch[181/600] Iteration[015/030] Train loss: 0.0183
2023-02-06 14:13:44 | Train | Epoch[181/600] Iteration[016/030] Train loss: 0.0183
2023-02-06 14:13:44 | Train | Epoch[181/600] Iteration[017/030] Train loss: 0.0183
2023-02-06 14:13:44 | Train | Epoch[181/600] Iteration[018/030] Train loss: 0.0182
2023-02-06 14:13:45 | Train | Epoch[181/600] Iteration[019/030] Train loss: 0.0183
2023-02-06 14:13:45 | Train | Epoch[181/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 14:13:45 | Train | Epoch[181/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 14:13:45 | Train | Epoch[181/600] Iteration[022/030] Train loss: 0.0184
2023-02-06 14:13:45 | Train | Epoch[181/600] Iteration[023/030] Train loss: 0.0185
2023-02-06 14:13:46 | Train | Epoch[181/600] Iteration[024/030] Train loss: 0.0186
2023-02-06 14:13:46 | Train | Epoch[181/600] Iteration[025/030] Train loss: 0.0187
2023-02-06 14:13:46 | Train | Epoch[181/600] Iteration[026/030] Train loss: 0.0186
2023-02-06 14:13:46 | Train | Epoch[181/600] Iteration[027/030] Train loss: 0.0187
2023-02-06 14:13:47 | Train | Epoch[181/600] Iteration[028/030] Train loss: 0.0187
2023-02-06 14:13:47 | Train | Epoch[181/600] Iteration[029/030] Train loss: 0.0187
2023-02-06 14:13:47 | Train | Epoch[181/600] Iteration[030/030] Train loss: 0.0187
2023-02-06 14:13:47 | Valid | Epoch[181/600] Iteration[001/008] Valid loss: 0.1984
2023-02-06 14:13:47 | Valid | Epoch[181/600] Iteration[002/008] Valid loss: 0.1770
2023-02-06 14:13:47 | Valid | Epoch[181/600] Iteration[003/008] Valid loss: 0.1785
2023-02-06 14:13:47 | Valid | Epoch[181/600] Iteration[004/008] Valid loss: 0.1722
2023-02-06 14:13:47 | Valid | Epoch[181/600] Iteration[005/008] Valid loss: 0.1668
2023-02-06 14:13:47 | Valid | Epoch[181/600] Iteration[006/008] Valid loss: 0.1669
2023-02-06 14:13:47 | Valid | Epoch[181/600] Iteration[007/008] Valid loss: 0.1761
2023-02-06 14:13:48 | Valid | Epoch[181/600] Iteration[008/008] Valid loss: 0.1763
2023-02-06 14:13:48 | Valid | Epoch[181/600] MIou: 0.9166017161095976
2023-02-06 14:13:48 | Valid | Epoch[181/600] Pixel Accuracy: 0.9848276774088541
2023-02-06 14:13:48 | Valid | Epoch[181/600] Mean Pixel Accuracy: 0.9693421846974773
2023-02-06 14:13:48 | Stage | Epoch[181/600] Train loss:0.0187
2023-02-06 14:13:48 | Stage | Epoch[181/600] Valid loss:0.1763
2023-02-06 14:13:48 | Stage | Epoch[181/600] LR:0.01

2023-02-06 14:13:48 | Train | Epoch[182/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 14:13:48 | Train | Epoch[182/600] Iteration[002/030] Train loss: 0.0183
2023-02-06 14:13:48 | Train | Epoch[182/600] Iteration[003/030] Train loss: 0.0181
2023-02-06 14:13:49 | Train | Epoch[182/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 14:13:49 | Train | Epoch[182/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 14:13:49 | Train | Epoch[182/600] Iteration[006/030] Train loss: 0.0183
2023-02-06 14:13:49 | Train | Epoch[182/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 14:13:50 | Train | Epoch[182/600] Iteration[008/030] Train loss: 0.0184
2023-02-06 14:13:50 | Train | Epoch[182/600] Iteration[009/030] Train loss: 0.0185
2023-02-06 14:13:50 | Train | Epoch[182/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 14:13:50 | Train | Epoch[182/600] Iteration[011/030] Train loss: 0.0185
2023-02-06 14:13:50 | Train | Epoch[182/600] Iteration[012/030] Train loss: 0.0185
2023-02-06 14:13:51 | Train | Epoch[182/600] Iteration[013/030] Train loss: 0.0184
2023-02-06 14:13:51 | Train | Epoch[182/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 14:13:51 | Train | Epoch[182/600] Iteration[015/030] Train loss: 0.0185
2023-02-06 14:13:51 | Train | Epoch[182/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 14:13:52 | Train | Epoch[182/600] Iteration[017/030] Train loss: 0.0186
2023-02-06 14:13:52 | Train | Epoch[182/600] Iteration[018/030] Train loss: 0.0187
2023-02-06 14:13:52 | Train | Epoch[182/600] Iteration[019/030] Train loss: 0.0187
2023-02-06 14:13:52 | Train | Epoch[182/600] Iteration[020/030] Train loss: 0.0187
2023-02-06 14:13:52 | Train | Epoch[182/600] Iteration[021/030] Train loss: 0.0187
2023-02-06 14:13:53 | Train | Epoch[182/600] Iteration[022/030] Train loss: 0.0187
2023-02-06 14:13:53 | Train | Epoch[182/600] Iteration[023/030] Train loss: 0.0186
2023-02-06 14:13:53 | Train | Epoch[182/600] Iteration[024/030] Train loss: 0.0191
2023-02-06 14:13:53 | Train | Epoch[182/600] Iteration[025/030] Train loss: 0.0191
2023-02-06 14:13:54 | Train | Epoch[182/600] Iteration[026/030] Train loss: 0.0191
2023-02-06 14:13:54 | Train | Epoch[182/600] Iteration[027/030] Train loss: 0.0192
2023-02-06 14:13:54 | Train | Epoch[182/600] Iteration[028/030] Train loss: 0.0191
2023-02-06 14:13:54 | Train | Epoch[182/600] Iteration[029/030] Train loss: 0.0191
2023-02-06 14:13:54 | Train | Epoch[182/600] Iteration[030/030] Train loss: 0.0191
2023-02-06 14:13:55 | Valid | Epoch[182/600] Iteration[001/008] Valid loss: 0.0928
2023-02-06 14:13:55 | Valid | Epoch[182/600] Iteration[002/008] Valid loss: 0.0745
2023-02-06 14:13:55 | Valid | Epoch[182/600] Iteration[003/008] Valid loss: 0.0746
2023-02-06 14:13:55 | Valid | Epoch[182/600] Iteration[004/008] Valid loss: 0.0765
2023-02-06 14:13:55 | Valid | Epoch[182/600] Iteration[005/008] Valid loss: 0.0732
2023-02-06 14:13:55 | Valid | Epoch[182/600] Iteration[006/008] Valid loss: 0.0740
2023-02-06 14:13:55 | Valid | Epoch[182/600] Iteration[007/008] Valid loss: 0.0741
2023-02-06 14:13:55 | Valid | Epoch[182/600] Iteration[008/008] Valid loss: 0.0731
2023-02-06 14:13:55 | Valid | Epoch[182/600] MIou: 0.8998162379892505
2023-02-06 14:13:55 | Valid | Epoch[182/600] Pixel Accuracy: 0.9829025268554688
2023-02-06 14:13:55 | Valid | Epoch[182/600] Mean Pixel Accuracy: 0.9238183131334358
2023-02-06 14:13:55 | Stage | Epoch[182/600] Train loss:0.0191
2023-02-06 14:13:55 | Stage | Epoch[182/600] Valid loss:0.0731
2023-02-06 14:13:55 | Stage | Epoch[182/600] LR:0.01

2023-02-06 14:13:56 | Train | Epoch[183/600] Iteration[001/030] Train loss: 0.0205
2023-02-06 14:13:56 | Train | Epoch[183/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 14:13:56 | Train | Epoch[183/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 14:13:56 | Train | Epoch[183/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 14:13:56 | Train | Epoch[183/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 14:13:57 | Train | Epoch[183/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 14:13:57 | Train | Epoch[183/600] Iteration[007/030] Train loss: 0.0192
2023-02-06 14:13:57 | Train | Epoch[183/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 14:13:57 | Train | Epoch[183/600] Iteration[009/030] Train loss: 0.0192
2023-02-06 14:13:58 | Train | Epoch[183/600] Iteration[010/030] Train loss: 0.0190
2023-02-06 14:13:58 | Train | Epoch[183/600] Iteration[011/030] Train loss: 0.0190
2023-02-06 14:13:58 | Train | Epoch[183/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 14:13:58 | Train | Epoch[183/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 14:13:58 | Train | Epoch[183/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 14:13:59 | Train | Epoch[183/600] Iteration[015/030] Train loss: 0.0192
2023-02-06 14:13:59 | Train | Epoch[183/600] Iteration[016/030] Train loss: 0.0191
2023-02-06 14:13:59 | Train | Epoch[183/600] Iteration[017/030] Train loss: 0.0192
2023-02-06 14:13:59 | Train | Epoch[183/600] Iteration[018/030] Train loss: 0.0192
2023-02-06 14:14:00 | Train | Epoch[183/600] Iteration[019/030] Train loss: 0.0191
2023-02-06 14:14:00 | Train | Epoch[183/600] Iteration[020/030] Train loss: 0.0191
2023-02-06 14:14:00 | Train | Epoch[183/600] Iteration[021/030] Train loss: 0.0191
2023-02-06 14:14:00 | Train | Epoch[183/600] Iteration[022/030] Train loss: 0.0191
2023-02-06 14:14:00 | Train | Epoch[183/600] Iteration[023/030] Train loss: 0.0191
2023-02-06 14:14:01 | Train | Epoch[183/600] Iteration[024/030] Train loss: 0.0191
2023-02-06 14:14:01 | Train | Epoch[183/600] Iteration[025/030] Train loss: 0.0191
2023-02-06 14:14:01 | Train | Epoch[183/600] Iteration[026/030] Train loss: 0.0190
2023-02-06 14:14:01 | Train | Epoch[183/600] Iteration[027/030] Train loss: 0.0191
2023-02-06 14:14:01 | Train | Epoch[183/600] Iteration[028/030] Train loss: 0.0191
2023-02-06 14:14:02 | Train | Epoch[183/600] Iteration[029/030] Train loss: 0.0190
2023-02-06 14:14:02 | Train | Epoch[183/600] Iteration[030/030] Train loss: 0.0191
2023-02-06 14:14:02 | Valid | Epoch[183/600] Iteration[001/008] Valid loss: 0.1566
2023-02-06 14:14:02 | Valid | Epoch[183/600] Iteration[002/008] Valid loss: 0.1180
2023-02-06 14:14:02 | Valid | Epoch[183/600] Iteration[003/008] Valid loss: 0.0999
2023-02-06 14:14:02 | Valid | Epoch[183/600] Iteration[004/008] Valid loss: 0.0917
2023-02-06 14:14:02 | Valid | Epoch[183/600] Iteration[005/008] Valid loss: 0.0881
2023-02-06 14:14:02 | Valid | Epoch[183/600] Iteration[006/008] Valid loss: 0.0863
2023-02-06 14:14:02 | Valid | Epoch[183/600] Iteration[007/008] Valid loss: 0.0930
2023-02-06 14:14:03 | Valid | Epoch[183/600] Iteration[008/008] Valid loss: 0.0905
2023-02-06 14:14:03 | Valid | Epoch[183/600] MIou: 0.9310379972648886
2023-02-06 14:14:03 | Valid | Epoch[183/600] Pixel Accuracy: 0.9880968729654948
2023-02-06 14:14:03 | Valid | Epoch[183/600] Mean Pixel Accuracy: 0.9588068569122301
2023-02-06 14:14:03 | Stage | Epoch[183/600] Train loss:0.0191
2023-02-06 14:14:03 | Stage | Epoch[183/600] Valid loss:0.0905
2023-02-06 14:14:03 | Stage | Epoch[183/600] LR:0.01

2023-02-06 14:14:03 | Train | Epoch[184/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 14:14:03 | Train | Epoch[184/600] Iteration[002/030] Train loss: 0.0191
2023-02-06 14:14:04 | Train | Epoch[184/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 14:14:04 | Train | Epoch[184/600] Iteration[004/030] Train loss: 0.0191
2023-02-06 14:14:04 | Train | Epoch[184/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 14:14:04 | Train | Epoch[184/600] Iteration[006/030] Train loss: 0.0190
2023-02-06 14:14:04 | Train | Epoch[184/600] Iteration[007/030] Train loss: 0.0189
2023-02-06 14:14:05 | Train | Epoch[184/600] Iteration[008/030] Train loss: 0.0188
2023-02-06 14:14:05 | Train | Epoch[184/600] Iteration[009/030] Train loss: 0.0188
2023-02-06 14:14:05 | Train | Epoch[184/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 14:14:05 | Train | Epoch[184/600] Iteration[011/030] Train loss: 0.0186
2023-02-06 14:14:05 | Train | Epoch[184/600] Iteration[012/030] Train loss: 0.0189
2023-02-06 14:14:06 | Train | Epoch[184/600] Iteration[013/030] Train loss: 0.0188
2023-02-06 14:14:06 | Train | Epoch[184/600] Iteration[014/030] Train loss: 0.0187
2023-02-06 14:14:06 | Train | Epoch[184/600] Iteration[015/030] Train loss: 0.0186
2023-02-06 14:14:06 | Train | Epoch[184/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 14:14:07 | Train | Epoch[184/600] Iteration[017/030] Train loss: 0.0185
2023-02-06 14:14:07 | Train | Epoch[184/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 14:14:07 | Train | Epoch[184/600] Iteration[019/030] Train loss: 0.0187
2023-02-06 14:14:07 | Train | Epoch[184/600] Iteration[020/030] Train loss: 0.0186
2023-02-06 14:14:07 | Train | Epoch[184/600] Iteration[021/030] Train loss: 0.0186
2023-02-06 14:14:08 | Train | Epoch[184/600] Iteration[022/030] Train loss: 0.0188
2023-02-06 14:14:08 | Train | Epoch[184/600] Iteration[023/030] Train loss: 0.0188
2023-02-06 14:14:08 | Train | Epoch[184/600] Iteration[024/030] Train loss: 0.0188
2023-02-06 14:14:08 | Train | Epoch[184/600] Iteration[025/030] Train loss: 0.0189
2023-02-06 14:14:09 | Train | Epoch[184/600] Iteration[026/030] Train loss: 0.0190
2023-02-06 14:14:09 | Train | Epoch[184/600] Iteration[027/030] Train loss: 0.0190
2023-02-06 14:14:09 | Train | Epoch[184/600] Iteration[028/030] Train loss: 0.0191
2023-02-06 14:14:09 | Train | Epoch[184/600] Iteration[029/030] Train loss: 0.0191
2023-02-06 14:14:09 | Train | Epoch[184/600] Iteration[030/030] Train loss: 0.0191
2023-02-06 14:14:10 | Valid | Epoch[184/600] Iteration[001/008] Valid loss: 0.0747
2023-02-06 14:14:10 | Valid | Epoch[184/600] Iteration[002/008] Valid loss: 0.0765
2023-02-06 14:14:10 | Valid | Epoch[184/600] Iteration[003/008] Valid loss: 0.0766
2023-02-06 14:14:10 | Valid | Epoch[184/600] Iteration[004/008] Valid loss: 0.0742
2023-02-06 14:14:10 | Valid | Epoch[184/600] Iteration[005/008] Valid loss: 0.0726
2023-02-06 14:14:10 | Valid | Epoch[184/600] Iteration[006/008] Valid loss: 0.0716
2023-02-06 14:14:10 | Valid | Epoch[184/600] Iteration[007/008] Valid loss: 0.0691
2023-02-06 14:14:10 | Valid | Epoch[184/600] Iteration[008/008] Valid loss: 0.0696
2023-02-06 14:14:10 | Valid | Epoch[184/600] MIou: 0.8168196135669079
2023-02-06 14:14:10 | Valid | Epoch[184/600] Pixel Accuracy: 0.9695752461751302
2023-02-06 14:14:10 | Valid | Epoch[184/600] Mean Pixel Accuracy: 0.8354681858238802
2023-02-06 14:14:10 | Stage | Epoch[184/600] Train loss:0.0191
2023-02-06 14:14:10 | Stage | Epoch[184/600] Valid loss:0.0696
2023-02-06 14:14:10 | Stage | Epoch[184/600] LR:0.01

2023-02-06 14:14:11 | Train | Epoch[185/600] Iteration[001/030] Train loss: 0.0201
2023-02-06 14:14:11 | Train | Epoch[185/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 14:14:11 | Train | Epoch[185/600] Iteration[003/030] Train loss: 0.0185
2023-02-06 14:14:11 | Train | Epoch[185/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 14:14:12 | Train | Epoch[185/600] Iteration[005/030] Train loss: 0.0182
2023-02-06 14:14:12 | Train | Epoch[185/600] Iteration[006/030] Train loss: 0.0184
2023-02-06 14:14:12 | Train | Epoch[185/600] Iteration[007/030] Train loss: 0.0185
2023-02-06 14:14:12 | Train | Epoch[185/600] Iteration[008/030] Train loss: 0.0184
2023-02-06 14:14:12 | Train | Epoch[185/600] Iteration[009/030] Train loss: 0.0186
2023-02-06 14:14:13 | Train | Epoch[185/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 14:14:13 | Train | Epoch[185/600] Iteration[011/030] Train loss: 0.0187
2023-02-06 14:14:13 | Train | Epoch[185/600] Iteration[012/030] Train loss: 0.0187
2023-02-06 14:14:13 | Train | Epoch[185/600] Iteration[013/030] Train loss: 0.0186
2023-02-06 14:14:14 | Train | Epoch[185/600] Iteration[014/030] Train loss: 0.0186
2023-02-06 14:14:14 | Train | Epoch[185/600] Iteration[015/030] Train loss: 0.0186
2023-02-06 14:14:14 | Train | Epoch[185/600] Iteration[016/030] Train loss: 0.0185
2023-02-06 14:14:14 | Train | Epoch[185/600] Iteration[017/030] Train loss: 0.0188
2023-02-06 14:14:14 | Train | Epoch[185/600] Iteration[018/030] Train loss: 0.0187
2023-02-06 14:14:15 | Train | Epoch[185/600] Iteration[019/030] Train loss: 0.0187
2023-02-06 14:14:15 | Train | Epoch[185/600] Iteration[020/030] Train loss: 0.0187
2023-02-06 14:14:15 | Train | Epoch[185/600] Iteration[021/030] Train loss: 0.0188
2023-02-06 14:14:15 | Train | Epoch[185/600] Iteration[022/030] Train loss: 0.0187
2023-02-06 14:14:16 | Train | Epoch[185/600] Iteration[023/030] Train loss: 0.0187
2023-02-06 14:14:16 | Train | Epoch[185/600] Iteration[024/030] Train loss: 0.0187
2023-02-06 14:14:16 | Train | Epoch[185/600] Iteration[025/030] Train loss: 0.0187
2023-02-06 14:14:16 | Train | Epoch[185/600] Iteration[026/030] Train loss: 0.0188
2023-02-06 14:14:16 | Train | Epoch[185/600] Iteration[027/030] Train loss: 0.0188
2023-02-06 14:14:17 | Train | Epoch[185/600] Iteration[028/030] Train loss: 0.0188
2023-02-06 14:14:17 | Train | Epoch[185/600] Iteration[029/030] Train loss: 0.0189
2023-02-06 14:14:17 | Train | Epoch[185/600] Iteration[030/030] Train loss: 0.0188
2023-02-06 14:14:17 | Valid | Epoch[185/600] Iteration[001/008] Valid loss: 0.2218
2023-02-06 14:14:17 | Valid | Epoch[185/600] Iteration[002/008] Valid loss: 0.1858
2023-02-06 14:14:17 | Valid | Epoch[185/600] Iteration[003/008] Valid loss: 0.1948
2023-02-06 14:14:17 | Valid | Epoch[185/600] Iteration[004/008] Valid loss: 0.1896
2023-02-06 14:14:17 | Valid | Epoch[185/600] Iteration[005/008] Valid loss: 0.1919
2023-02-06 14:14:18 | Valid | Epoch[185/600] Iteration[006/008] Valid loss: 0.1892
2023-02-06 14:14:18 | Valid | Epoch[185/600] Iteration[007/008] Valid loss: 0.2019
2023-02-06 14:14:18 | Valid | Epoch[185/600] Iteration[008/008] Valid loss: 0.2038
2023-02-06 14:14:18 | Valid | Epoch[185/600] MIou: 0.8983834665968082
2023-02-06 14:14:18 | Valid | Epoch[185/600] Pixel Accuracy: 0.9807726542154948
2023-02-06 14:14:18 | Valid | Epoch[185/600] Mean Pixel Accuracy: 0.9694339835812718
2023-02-06 14:14:18 | Stage | Epoch[185/600] Train loss:0.0188
2023-02-06 14:14:18 | Stage | Epoch[185/600] Valid loss:0.2038
2023-02-06 14:14:18 | Stage | Epoch[185/600] LR:0.01

2023-02-06 14:14:18 | Train | Epoch[186/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 14:14:18 | Train | Epoch[186/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 14:14:19 | Train | Epoch[186/600] Iteration[003/030] Train loss: 0.0183
2023-02-06 14:14:19 | Train | Epoch[186/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 14:14:19 | Train | Epoch[186/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 14:14:19 | Train | Epoch[186/600] Iteration[006/030] Train loss: 0.0183
2023-02-06 14:14:19 | Train | Epoch[186/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 14:14:20 | Train | Epoch[186/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 14:14:20 | Train | Epoch[186/600] Iteration[009/030] Train loss: 0.0186
2023-02-06 14:14:20 | Train | Epoch[186/600] Iteration[010/030] Train loss: 0.0188
2023-02-06 14:14:20 | Train | Epoch[186/600] Iteration[011/030] Train loss: 0.0186
2023-02-06 14:14:21 | Train | Epoch[186/600] Iteration[012/030] Train loss: 0.0185
2023-02-06 14:14:21 | Train | Epoch[186/600] Iteration[013/030] Train loss: 0.0184
2023-02-06 14:14:21 | Train | Epoch[186/600] Iteration[014/030] Train loss: 0.0185
2023-02-06 14:14:21 | Train | Epoch[186/600] Iteration[015/030] Train loss: 0.0184
2023-02-06 14:14:21 | Train | Epoch[186/600] Iteration[016/030] Train loss: 0.0184
2023-02-06 14:14:22 | Train | Epoch[186/600] Iteration[017/030] Train loss: 0.0184
2023-02-06 14:14:22 | Train | Epoch[186/600] Iteration[018/030] Train loss: 0.0185
2023-02-06 14:14:22 | Train | Epoch[186/600] Iteration[019/030] Train loss: 0.0184
2023-02-06 14:14:22 | Train | Epoch[186/600] Iteration[020/030] Train loss: 0.0184
2023-02-06 14:14:23 | Train | Epoch[186/600] Iteration[021/030] Train loss: 0.0183
2023-02-06 14:14:23 | Train | Epoch[186/600] Iteration[022/030] Train loss: 0.0183
2023-02-06 14:14:23 | Train | Epoch[186/600] Iteration[023/030] Train loss: 0.0183
2023-02-06 14:14:23 | Train | Epoch[186/600] Iteration[024/030] Train loss: 0.0183
2023-02-06 14:14:23 | Train | Epoch[186/600] Iteration[025/030] Train loss: 0.0183
2023-02-06 14:14:24 | Train | Epoch[186/600] Iteration[026/030] Train loss: 0.0183
2023-02-06 14:14:24 | Train | Epoch[186/600] Iteration[027/030] Train loss: 0.0183
2023-02-06 14:14:24 | Train | Epoch[186/600] Iteration[028/030] Train loss: 0.0183
2023-02-06 14:14:24 | Train | Epoch[186/600] Iteration[029/030] Train loss: 0.0183
2023-02-06 14:14:24 | Train | Epoch[186/600] Iteration[030/030] Train loss: 0.0185
2023-02-06 14:14:25 | Valid | Epoch[186/600] Iteration[001/008] Valid loss: 0.0685
2023-02-06 14:14:25 | Valid | Epoch[186/600] Iteration[002/008] Valid loss: 0.0613
2023-02-06 14:14:25 | Valid | Epoch[186/600] Iteration[003/008] Valid loss: 0.0584
2023-02-06 14:14:25 | Valid | Epoch[186/600] Iteration[004/008] Valid loss: 0.0548
2023-02-06 14:14:25 | Valid | Epoch[186/600] Iteration[005/008] Valid loss: 0.0559
2023-02-06 14:14:25 | Valid | Epoch[186/600] Iteration[006/008] Valid loss: 0.0539
2023-02-06 14:14:25 | Valid | Epoch[186/600] Iteration[007/008] Valid loss: 0.0545
2023-02-06 14:14:25 | Valid | Epoch[186/600] Iteration[008/008] Valid loss: 0.0546
2023-02-06 14:14:25 | Valid | Epoch[186/600] MIou: 0.8938709318675866
2023-02-06 14:14:25 | Valid | Epoch[186/600] Pixel Accuracy: 0.9819259643554688
2023-02-06 14:14:25 | Valid | Epoch[186/600] Mean Pixel Accuracy: 0.9172644452690888
2023-02-06 14:14:25 | Stage | Epoch[186/600] Train loss:0.0185
2023-02-06 14:14:25 | Stage | Epoch[186/600] Valid loss:0.0546
2023-02-06 14:14:25 | Stage | Epoch[186/600] LR:0.01

2023-02-06 14:14:26 | Train | Epoch[187/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 14:14:26 | Train | Epoch[187/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 14:14:26 | Train | Epoch[187/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 14:14:26 | Train | Epoch[187/600] Iteration[004/030] Train loss: 0.0181
2023-02-06 14:14:27 | Train | Epoch[187/600] Iteration[005/030] Train loss: 0.0178
2023-02-06 14:14:27 | Train | Epoch[187/600] Iteration[006/030] Train loss: 0.0175
2023-02-06 14:14:27 | Train | Epoch[187/600] Iteration[007/030] Train loss: 0.0177
2023-02-06 14:14:27 | Train | Epoch[187/600] Iteration[008/030] Train loss: 0.0177
2023-02-06 14:14:27 | Train | Epoch[187/600] Iteration[009/030] Train loss: 0.0176
2023-02-06 14:14:28 | Train | Epoch[187/600] Iteration[010/030] Train loss: 0.0175
2023-02-06 14:14:28 | Train | Epoch[187/600] Iteration[011/030] Train loss: 0.0176
2023-02-06 14:14:28 | Train | Epoch[187/600] Iteration[012/030] Train loss: 0.0176
2023-02-06 14:14:28 | Train | Epoch[187/600] Iteration[013/030] Train loss: 0.0177
2023-02-06 14:14:28 | Train | Epoch[187/600] Iteration[014/030] Train loss: 0.0177
2023-02-06 14:14:29 | Train | Epoch[187/600] Iteration[015/030] Train loss: 0.0177
2023-02-06 14:14:29 | Train | Epoch[187/600] Iteration[016/030] Train loss: 0.0176
2023-02-06 14:14:29 | Train | Epoch[187/600] Iteration[017/030] Train loss: 0.0177
2023-02-06 14:14:29 | Train | Epoch[187/600] Iteration[018/030] Train loss: 0.0178
2023-02-06 14:14:30 | Train | Epoch[187/600] Iteration[019/030] Train loss: 0.0178
2023-02-06 14:14:30 | Train | Epoch[187/600] Iteration[020/030] Train loss: 0.0178
2023-02-06 14:14:30 | Train | Epoch[187/600] Iteration[021/030] Train loss: 0.0179
2023-02-06 14:14:30 | Train | Epoch[187/600] Iteration[022/030] Train loss: 0.0178
2023-02-06 14:14:30 | Train | Epoch[187/600] Iteration[023/030] Train loss: 0.0179
2023-02-06 14:14:31 | Train | Epoch[187/600] Iteration[024/030] Train loss: 0.0179
2023-02-06 14:14:31 | Train | Epoch[187/600] Iteration[025/030] Train loss: 0.0179
2023-02-06 14:14:31 | Train | Epoch[187/600] Iteration[026/030] Train loss: 0.0179
2023-02-06 14:14:31 | Train | Epoch[187/600] Iteration[027/030] Train loss: 0.0179
2023-02-06 14:14:32 | Train | Epoch[187/600] Iteration[028/030] Train loss: 0.0179
2023-02-06 14:14:32 | Train | Epoch[187/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 14:14:32 | Train | Epoch[187/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 14:14:32 | Valid | Epoch[187/600] Iteration[001/008] Valid loss: 0.3473
2023-02-06 14:14:32 | Valid | Epoch[187/600] Iteration[002/008] Valid loss: 0.2792
2023-02-06 14:14:32 | Valid | Epoch[187/600] Iteration[003/008] Valid loss: 0.2728
2023-02-06 14:14:32 | Valid | Epoch[187/600] Iteration[004/008] Valid loss: 0.2658
2023-02-06 14:14:32 | Valid | Epoch[187/600] Iteration[005/008] Valid loss: 0.2667
2023-02-06 14:14:32 | Valid | Epoch[187/600] Iteration[006/008] Valid loss: 0.2598
2023-02-06 14:14:33 | Valid | Epoch[187/600] Iteration[007/008] Valid loss: 0.2793
2023-02-06 14:14:33 | Valid | Epoch[187/600] Iteration[008/008] Valid loss: 0.2822
2023-02-06 14:14:33 | Valid | Epoch[187/600] MIou: 0.9087526664324239
2023-02-06 14:14:33 | Valid | Epoch[187/600] Pixel Accuracy: 0.9828109741210938
2023-02-06 14:14:33 | Valid | Epoch[187/600] Mean Pixel Accuracy: 0.9782263016632471
2023-02-06 14:14:33 | Stage | Epoch[187/600] Train loss:0.0180
2023-02-06 14:14:33 | Stage | Epoch[187/600] Valid loss:0.2822
2023-02-06 14:14:33 | Stage | Epoch[187/600] LR:0.01

2023-02-06 14:14:33 | Train | Epoch[188/600] Iteration[001/030] Train loss: 0.0172
2023-02-06 14:14:33 | Train | Epoch[188/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 14:14:34 | Train | Epoch[188/600] Iteration[003/030] Train loss: 0.0170
2023-02-06 14:14:34 | Train | Epoch[188/600] Iteration[004/030] Train loss: 0.0176
2023-02-06 14:14:34 | Train | Epoch[188/600] Iteration[005/030] Train loss: 0.0181
2023-02-06 14:14:34 | Train | Epoch[188/600] Iteration[006/030] Train loss: 0.0179
2023-02-06 14:14:35 | Train | Epoch[188/600] Iteration[007/030] Train loss: 0.0179
2023-02-06 14:14:35 | Train | Epoch[188/600] Iteration[008/030] Train loss: 0.0179
2023-02-06 14:14:35 | Train | Epoch[188/600] Iteration[009/030] Train loss: 0.0178
2023-02-06 14:14:35 | Train | Epoch[188/600] Iteration[010/030] Train loss: 0.0177
2023-02-06 14:14:35 | Train | Epoch[188/600] Iteration[011/030] Train loss: 0.0179
2023-02-06 14:14:36 | Train | Epoch[188/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 14:14:36 | Train | Epoch[188/600] Iteration[013/030] Train loss: 0.0181
2023-02-06 14:14:36 | Train | Epoch[188/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 14:14:36 | Train | Epoch[188/600] Iteration[015/030] Train loss: 0.0179
2023-02-06 14:14:36 | Train | Epoch[188/600] Iteration[016/030] Train loss: 0.0179
2023-02-06 14:14:37 | Train | Epoch[188/600] Iteration[017/030] Train loss: 0.0178
2023-02-06 14:14:37 | Train | Epoch[188/600] Iteration[018/030] Train loss: 0.0178
2023-02-06 14:14:37 | Train | Epoch[188/600] Iteration[019/030] Train loss: 0.0177
2023-02-06 14:14:37 | Train | Epoch[188/600] Iteration[020/030] Train loss: 0.0178
2023-02-06 14:14:38 | Train | Epoch[188/600] Iteration[021/030] Train loss: 0.0179
2023-02-06 14:14:38 | Train | Epoch[188/600] Iteration[022/030] Train loss: 0.0179
2023-02-06 14:14:38 | Train | Epoch[188/600] Iteration[023/030] Train loss: 0.0178
2023-02-06 14:14:38 | Train | Epoch[188/600] Iteration[024/030] Train loss: 0.0178
2023-02-06 14:14:38 | Train | Epoch[188/600] Iteration[025/030] Train loss: 0.0178
2023-02-06 14:14:39 | Train | Epoch[188/600] Iteration[026/030] Train loss: 0.0178
2023-02-06 14:14:39 | Train | Epoch[188/600] Iteration[027/030] Train loss: 0.0178
2023-02-06 14:14:39 | Train | Epoch[188/600] Iteration[028/030] Train loss: 0.0178
2023-02-06 14:14:39 | Train | Epoch[188/600] Iteration[029/030] Train loss: 0.0179
2023-02-06 14:14:39 | Train | Epoch[188/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 14:14:40 | Valid | Epoch[188/600] Iteration[001/008] Valid loss: 1.7431
2023-02-06 14:14:40 | Valid | Epoch[188/600] Iteration[002/008] Valid loss: 1.7178
2023-02-06 14:14:40 | Valid | Epoch[188/600] Iteration[003/008] Valid loss: 1.7992
2023-02-06 14:14:40 | Valid | Epoch[188/600] Iteration[004/008] Valid loss: 1.8144
2023-02-06 14:14:40 | Valid | Epoch[188/600] Iteration[005/008] Valid loss: 1.8745
2023-02-06 14:14:40 | Valid | Epoch[188/600] Iteration[006/008] Valid loss: 1.8605
2023-02-06 14:14:40 | Valid | Epoch[188/600] Iteration[007/008] Valid loss: 1.9303
2023-02-06 14:14:40 | Valid | Epoch[188/600] Iteration[008/008] Valid loss: 2.0085
2023-02-06 14:14:40 | Valid | Epoch[188/600] MIou: 0.7946264298261054
2023-02-06 14:14:40 | Valid | Epoch[188/600] Pixel Accuracy: 0.9502385457356771
2023-02-06 14:14:40 | Valid | Epoch[188/600] Mean Pixel Accuracy: 0.9710258217545411
2023-02-06 14:14:40 | Stage | Epoch[188/600] Train loss:0.0180
2023-02-06 14:14:40 | Stage | Epoch[188/600] Valid loss:2.0085
2023-02-06 14:14:40 | Stage | Epoch[188/600] LR:0.01

2023-02-06 14:14:41 | Train | Epoch[189/600] Iteration[001/030] Train loss: 0.0173
2023-02-06 14:14:41 | Train | Epoch[189/600] Iteration[002/030] Train loss: 0.0166
2023-02-06 14:14:41 | Train | Epoch[189/600] Iteration[003/030] Train loss: 0.0169
2023-02-06 14:14:41 | Train | Epoch[189/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 14:14:42 | Train | Epoch[189/600] Iteration[005/030] Train loss: 0.0170
2023-02-06 14:14:42 | Train | Epoch[189/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 14:14:42 | Train | Epoch[189/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 14:14:42 | Train | Epoch[189/600] Iteration[008/030] Train loss: 0.0173
2023-02-06 14:14:42 | Train | Epoch[189/600] Iteration[009/030] Train loss: 0.0174
2023-02-06 14:14:43 | Train | Epoch[189/600] Iteration[010/030] Train loss: 0.0174
2023-02-06 14:14:43 | Train | Epoch[189/600] Iteration[011/030] Train loss: 0.0177
2023-02-06 14:14:43 | Train | Epoch[189/600] Iteration[012/030] Train loss: 0.0178
2023-02-06 14:14:43 | Train | Epoch[189/600] Iteration[013/030] Train loss: 0.0178
2023-02-06 14:14:44 | Train | Epoch[189/600] Iteration[014/030] Train loss: 0.0180
2023-02-06 14:14:44 | Train | Epoch[189/600] Iteration[015/030] Train loss: 0.0179
2023-02-06 14:14:44 | Train | Epoch[189/600] Iteration[016/030] Train loss: 0.0178
2023-02-06 14:14:44 | Train | Epoch[189/600] Iteration[017/030] Train loss: 0.0178
2023-02-06 14:14:44 | Train | Epoch[189/600] Iteration[018/030] Train loss: 0.0178
2023-02-06 14:14:45 | Train | Epoch[189/600] Iteration[019/030] Train loss: 0.0178
2023-02-06 14:14:45 | Train | Epoch[189/600] Iteration[020/030] Train loss: 0.0178
2023-02-06 14:14:45 | Train | Epoch[189/600] Iteration[021/030] Train loss: 0.0178
2023-02-06 14:14:45 | Train | Epoch[189/600] Iteration[022/030] Train loss: 0.0178
2023-02-06 14:14:45 | Train | Epoch[189/600] Iteration[023/030] Train loss: 0.0178
2023-02-06 14:14:46 | Train | Epoch[189/600] Iteration[024/030] Train loss: 0.0178
2023-02-06 14:14:46 | Train | Epoch[189/600] Iteration[025/030] Train loss: 0.0179
2023-02-06 14:14:46 | Train | Epoch[189/600] Iteration[026/030] Train loss: 0.0179
2023-02-06 14:14:46 | Train | Epoch[189/600] Iteration[027/030] Train loss: 0.0180
2023-02-06 14:14:47 | Train | Epoch[189/600] Iteration[028/030] Train loss: 0.0179
2023-02-06 14:14:47 | Train | Epoch[189/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 14:14:47 | Train | Epoch[189/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 14:14:47 | Valid | Epoch[189/600] Iteration[001/008] Valid loss: 0.3302
2023-02-06 14:14:47 | Valid | Epoch[189/600] Iteration[002/008] Valid loss: 0.2916
2023-02-06 14:14:47 | Valid | Epoch[189/600] Iteration[003/008] Valid loss: 0.2867
2023-02-06 14:14:47 | Valid | Epoch[189/600] Iteration[004/008] Valid loss: 0.2794
2023-02-06 14:14:47 | Valid | Epoch[189/600] Iteration[005/008] Valid loss: 0.2837
2023-02-06 14:14:47 | Valid | Epoch[189/600] Iteration[006/008] Valid loss: 0.2777
2023-02-06 14:14:48 | Valid | Epoch[189/600] Iteration[007/008] Valid loss: 0.2951
2023-02-06 14:14:48 | Valid | Epoch[189/600] Iteration[008/008] Valid loss: 0.2944
2023-02-06 14:14:48 | Valid | Epoch[189/600] MIou: 0.9045273491425165
2023-02-06 14:14:48 | Valid | Epoch[189/600] Pixel Accuracy: 0.9818878173828125
2023-02-06 14:14:48 | Valid | Epoch[189/600] Mean Pixel Accuracy: 0.977243359984799
2023-02-06 14:14:48 | Stage | Epoch[189/600] Train loss:0.0180
2023-02-06 14:14:48 | Stage | Epoch[189/600] Valid loss:0.2944
2023-02-06 14:14:48 | Stage | Epoch[189/600] LR:0.01

2023-02-06 14:14:48 | Train | Epoch[190/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 14:14:48 | Train | Epoch[190/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 14:14:49 | Train | Epoch[190/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 14:14:49 | Train | Epoch[190/600] Iteration[004/030] Train loss: 0.0172
2023-02-06 14:14:49 | Train | Epoch[190/600] Iteration[005/030] Train loss: 0.0172
2023-02-06 14:14:49 | Train | Epoch[190/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 14:14:49 | Train | Epoch[190/600] Iteration[007/030] Train loss: 0.0174
2023-02-06 14:14:50 | Train | Epoch[190/600] Iteration[008/030] Train loss: 0.0176
2023-02-06 14:14:50 | Train | Epoch[190/600] Iteration[009/030] Train loss: 0.0176
2023-02-06 14:14:50 | Train | Epoch[190/600] Iteration[010/030] Train loss: 0.0177
2023-02-06 14:14:50 | Train | Epoch[190/600] Iteration[011/030] Train loss: 0.0176
2023-02-06 14:14:51 | Train | Epoch[190/600] Iteration[012/030] Train loss: 0.0175
2023-02-06 14:14:51 | Train | Epoch[190/600] Iteration[013/030] Train loss: 0.0176
2023-02-06 14:14:51 | Train | Epoch[190/600] Iteration[014/030] Train loss: 0.0176
2023-02-06 14:14:51 | Train | Epoch[190/600] Iteration[015/030] Train loss: 0.0176
2023-02-06 14:14:51 | Train | Epoch[190/600] Iteration[016/030] Train loss: 0.0175
2023-02-06 14:14:52 | Train | Epoch[190/600] Iteration[017/030] Train loss: 0.0175
2023-02-06 14:14:52 | Train | Epoch[190/600] Iteration[018/030] Train loss: 0.0175
2023-02-06 14:14:52 | Train | Epoch[190/600] Iteration[019/030] Train loss: 0.0175
2023-02-06 14:14:52 | Train | Epoch[190/600] Iteration[020/030] Train loss: 0.0175
2023-02-06 14:14:53 | Train | Epoch[190/600] Iteration[021/030] Train loss: 0.0175
2023-02-06 14:14:53 | Train | Epoch[190/600] Iteration[022/030] Train loss: 0.0176
2023-02-06 14:14:53 | Train | Epoch[190/600] Iteration[023/030] Train loss: 0.0176
2023-02-06 14:14:53 | Train | Epoch[190/600] Iteration[024/030] Train loss: 0.0175
2023-02-06 14:14:53 | Train | Epoch[190/600] Iteration[025/030] Train loss: 0.0175
2023-02-06 14:14:54 | Train | Epoch[190/600] Iteration[026/030] Train loss: 0.0176
2023-02-06 14:14:54 | Train | Epoch[190/600] Iteration[027/030] Train loss: 0.0176
2023-02-06 14:14:54 | Train | Epoch[190/600] Iteration[028/030] Train loss: 0.0177
2023-02-06 14:14:54 | Train | Epoch[190/600] Iteration[029/030] Train loss: 0.0177
2023-02-06 14:14:54 | Train | Epoch[190/600] Iteration[030/030] Train loss: 0.0177
2023-02-06 14:14:55 | Valid | Epoch[190/600] Iteration[001/008] Valid loss: 0.2889
2023-02-06 14:14:55 | Valid | Epoch[190/600] Iteration[002/008] Valid loss: 0.2128
2023-02-06 14:14:55 | Valid | Epoch[190/600] Iteration[003/008] Valid loss: 0.1954
2023-02-06 14:14:55 | Valid | Epoch[190/600] Iteration[004/008] Valid loss: 0.1875
2023-02-06 14:14:55 | Valid | Epoch[190/600] Iteration[005/008] Valid loss: 0.1887
2023-02-06 14:14:55 | Valid | Epoch[190/600] Iteration[006/008] Valid loss: 0.1799
2023-02-06 14:14:55 | Valid | Epoch[190/600] Iteration[007/008] Valid loss: 0.1880
2023-02-06 14:14:55 | Valid | Epoch[190/600] Iteration[008/008] Valid loss: 0.1850
2023-02-06 14:14:55 | Valid | Epoch[190/600] MIou: 0.9193471426514233
2023-02-06 14:14:55 | Valid | Epoch[190/600] Pixel Accuracy: 0.9853401184082031
2023-02-06 14:14:55 | Valid | Epoch[190/600] Mean Pixel Accuracy: 0.9717098592532738
2023-02-06 14:14:55 | Stage | Epoch[190/600] Train loss:0.0177
2023-02-06 14:14:55 | Stage | Epoch[190/600] Valid loss:0.1850
2023-02-06 14:14:55 | Stage | Epoch[190/600] LR:0.01

2023-02-06 14:14:56 | Train | Epoch[191/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 14:14:56 | Train | Epoch[191/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 14:14:56 | Train | Epoch[191/600] Iteration[003/030] Train loss: 0.0185
2023-02-06 14:14:56 | Train | Epoch[191/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 14:14:57 | Train | Epoch[191/600] Iteration[005/030] Train loss: 0.0177
2023-02-06 14:14:57 | Train | Epoch[191/600] Iteration[006/030] Train loss: 0.0175
2023-02-06 14:14:57 | Train | Epoch[191/600] Iteration[007/030] Train loss: 0.0175
2023-02-06 14:14:57 | Train | Epoch[191/600] Iteration[008/030] Train loss: 0.0173
2023-02-06 14:14:57 | Train | Epoch[191/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 14:14:58 | Train | Epoch[191/600] Iteration[010/030] Train loss: 0.0171
2023-02-06 14:14:58 | Train | Epoch[191/600] Iteration[011/030] Train loss: 0.0170
2023-02-06 14:14:58 | Train | Epoch[191/600] Iteration[012/030] Train loss: 0.0170
2023-02-06 14:14:58 | Train | Epoch[191/600] Iteration[013/030] Train loss: 0.0171
2023-02-06 14:14:59 | Train | Epoch[191/600] Iteration[014/030] Train loss: 0.0171
2023-02-06 14:14:59 | Train | Epoch[191/600] Iteration[015/030] Train loss: 0.0171
2023-02-06 14:14:59 | Train | Epoch[191/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 14:14:59 | Train | Epoch[191/600] Iteration[017/030] Train loss: 0.0170
2023-02-06 14:14:59 | Train | Epoch[191/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 14:15:00 | Train | Epoch[191/600] Iteration[019/030] Train loss: 0.0171
2023-02-06 14:15:00 | Train | Epoch[191/600] Iteration[020/030] Train loss: 0.0171
2023-02-06 14:15:00 | Train | Epoch[191/600] Iteration[021/030] Train loss: 0.0171
2023-02-06 14:15:00 | Train | Epoch[191/600] Iteration[022/030] Train loss: 0.0170
2023-02-06 14:15:01 | Train | Epoch[191/600] Iteration[023/030] Train loss: 0.0170
2023-02-06 14:15:01 | Train | Epoch[191/600] Iteration[024/030] Train loss: 0.0172
2023-02-06 14:15:01 | Train | Epoch[191/600] Iteration[025/030] Train loss: 0.0174
2023-02-06 14:15:01 | Train | Epoch[191/600] Iteration[026/030] Train loss: 0.0173
2023-02-06 14:15:01 | Train | Epoch[191/600] Iteration[027/030] Train loss: 0.0173
2023-02-06 14:15:02 | Train | Epoch[191/600] Iteration[028/030] Train loss: 0.0174
2023-02-06 14:15:02 | Train | Epoch[191/600] Iteration[029/030] Train loss: 0.0173
2023-02-06 14:15:02 | Train | Epoch[191/600] Iteration[030/030] Train loss: 0.0173
2023-02-06 14:15:02 | Valid | Epoch[191/600] Iteration[001/008] Valid loss: 0.1041
2023-02-06 14:15:02 | Valid | Epoch[191/600] Iteration[002/008] Valid loss: 0.0744
2023-02-06 14:15:02 | Valid | Epoch[191/600] Iteration[003/008] Valid loss: 0.0674
2023-02-06 14:15:02 | Valid | Epoch[191/600] Iteration[004/008] Valid loss: 0.0602
2023-02-06 14:15:03 | Valid | Epoch[191/600] Iteration[005/008] Valid loss: 0.0594
2023-02-06 14:15:03 | Valid | Epoch[191/600] Iteration[006/008] Valid loss: 0.0564
2023-02-06 14:15:03 | Valid | Epoch[191/600] Iteration[007/008] Valid loss: 0.0561
2023-02-06 14:15:03 | Valid | Epoch[191/600] Iteration[008/008] Valid loss: 0.0545
2023-02-06 14:15:03 | Valid | Epoch[191/600] MIou: 0.925500242555099
2023-02-06 14:15:03 | Valid | Epoch[191/600] Pixel Accuracy: 0.987450917561849
2023-02-06 14:15:03 | Valid | Epoch[191/600] Mean Pixel Accuracy: 0.9424611431195893
2023-02-06 14:15:03 | Stage | Epoch[191/600] Train loss:0.0173
2023-02-06 14:15:03 | Stage | Epoch[191/600] Valid loss:0.0545
2023-02-06 14:15:03 | Stage | Epoch[191/600] LR:0.01

2023-02-06 14:15:03 | Train | Epoch[192/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 14:15:03 | Train | Epoch[192/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 14:15:04 | Train | Epoch[192/600] Iteration[003/030] Train loss: 0.0172
2023-02-06 14:15:04 | Train | Epoch[192/600] Iteration[004/030] Train loss: 0.0170
2023-02-06 14:15:04 | Train | Epoch[192/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 14:15:04 | Train | Epoch[192/600] Iteration[006/030] Train loss: 0.0172
2023-02-06 14:15:05 | Train | Epoch[192/600] Iteration[007/030] Train loss: 0.0173
2023-02-06 14:15:05 | Train | Epoch[192/600] Iteration[008/030] Train loss: 0.0172
2023-02-06 14:15:05 | Train | Epoch[192/600] Iteration[009/030] Train loss: 0.0172
2023-02-06 14:15:05 | Train | Epoch[192/600] Iteration[010/030] Train loss: 0.0172
2023-02-06 14:15:05 | Train | Epoch[192/600] Iteration[011/030] Train loss: 0.0173
2023-02-06 14:15:06 | Train | Epoch[192/600] Iteration[012/030] Train loss: 0.0176
2023-02-06 14:15:06 | Train | Epoch[192/600] Iteration[013/030] Train loss: 0.0177
2023-02-06 14:15:06 | Train | Epoch[192/600] Iteration[014/030] Train loss: 0.0176
2023-02-06 14:15:06 | Train | Epoch[192/600] Iteration[015/030] Train loss: 0.0177
2023-02-06 14:15:06 | Train | Epoch[192/600] Iteration[016/030] Train loss: 0.0178
2023-02-06 14:15:07 | Train | Epoch[192/600] Iteration[017/030] Train loss: 0.0178
2023-02-06 14:15:07 | Train | Epoch[192/600] Iteration[018/030] Train loss: 0.0179
2023-02-06 14:15:07 | Train | Epoch[192/600] Iteration[019/030] Train loss: 0.0179
2023-02-06 14:15:07 | Train | Epoch[192/600] Iteration[020/030] Train loss: 0.0179
2023-02-06 14:15:08 | Train | Epoch[192/600] Iteration[021/030] Train loss: 0.0179
2023-02-06 14:15:08 | Train | Epoch[192/600] Iteration[022/030] Train loss: 0.0179
2023-02-06 14:15:08 | Train | Epoch[192/600] Iteration[023/030] Train loss: 0.0179
2023-02-06 14:15:08 | Train | Epoch[192/600] Iteration[024/030] Train loss: 0.0178
2023-02-06 14:15:08 | Train | Epoch[192/600] Iteration[025/030] Train loss: 0.0180
2023-02-06 14:15:09 | Train | Epoch[192/600] Iteration[026/030] Train loss: 0.0180
2023-02-06 14:15:09 | Train | Epoch[192/600] Iteration[027/030] Train loss: 0.0179
2023-02-06 14:15:09 | Train | Epoch[192/600] Iteration[028/030] Train loss: 0.0179
2023-02-06 14:15:09 | Train | Epoch[192/600] Iteration[029/030] Train loss: 0.0179
2023-02-06 14:15:09 | Train | Epoch[192/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 14:15:10 | Valid | Epoch[192/600] Iteration[001/008] Valid loss: 0.2042
2023-02-06 14:15:10 | Valid | Epoch[192/600] Iteration[002/008] Valid loss: 0.1823
2023-02-06 14:15:10 | Valid | Epoch[192/600] Iteration[003/008] Valid loss: 0.1892
2023-02-06 14:15:10 | Valid | Epoch[192/600] Iteration[004/008] Valid loss: 0.1848
2023-02-06 14:15:10 | Valid | Epoch[192/600] Iteration[005/008] Valid loss: 0.1861
2023-02-06 14:15:10 | Valid | Epoch[192/600] Iteration[006/008] Valid loss: 0.1878
2023-02-06 14:15:10 | Valid | Epoch[192/600] Iteration[007/008] Valid loss: 0.2084
2023-02-06 14:15:10 | Valid | Epoch[192/600] Iteration[008/008] Valid loss: 0.2007
2023-02-06 14:15:10 | Valid | Epoch[192/600] MIou: 0.9226756709150745
2023-02-06 14:15:10 | Valid | Epoch[192/600] Pixel Accuracy: 0.986077626546224
2023-02-06 14:15:10 | Valid | Epoch[192/600] Mean Pixel Accuracy: 0.9705110858873351
2023-02-06 14:15:10 | Stage | Epoch[192/600] Train loss:0.0180
2023-02-06 14:15:10 | Stage | Epoch[192/600] Valid loss:0.2007
2023-02-06 14:15:10 | Stage | Epoch[192/600] LR:0.01

2023-02-06 14:15:11 | Train | Epoch[193/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 14:15:11 | Train | Epoch[193/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 14:15:11 | Train | Epoch[193/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 14:15:11 | Train | Epoch[193/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 14:15:12 | Train | Epoch[193/600] Iteration[005/030] Train loss: 0.0185
2023-02-06 14:15:12 | Train | Epoch[193/600] Iteration[006/030] Train loss: 0.0187
2023-02-06 14:15:12 | Train | Epoch[193/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 14:15:12 | Train | Epoch[193/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 14:15:12 | Train | Epoch[193/600] Iteration[009/030] Train loss: 0.0182
2023-02-06 14:15:13 | Train | Epoch[193/600] Iteration[010/030] Train loss: 0.0180
2023-02-06 14:15:13 | Train | Epoch[193/600] Iteration[011/030] Train loss: 0.0182
2023-02-06 14:15:13 | Train | Epoch[193/600] Iteration[012/030] Train loss: 0.0180
2023-02-06 14:15:13 | Train | Epoch[193/600] Iteration[013/030] Train loss: 0.0180
2023-02-06 14:15:14 | Train | Epoch[193/600] Iteration[014/030] Train loss: 0.0179
2023-02-06 14:15:14 | Train | Epoch[193/600] Iteration[015/030] Train loss: 0.0179
2023-02-06 14:15:14 | Train | Epoch[193/600] Iteration[016/030] Train loss: 0.0179
2023-02-06 14:15:14 | Train | Epoch[193/600] Iteration[017/030] Train loss: 0.0179
2023-02-06 14:15:14 | Train | Epoch[193/600] Iteration[018/030] Train loss: 0.0177
2023-02-06 14:15:15 | Train | Epoch[193/600] Iteration[019/030] Train loss: 0.0177
2023-02-06 14:15:15 | Train | Epoch[193/600] Iteration[020/030] Train loss: 0.0176
2023-02-06 14:15:15 | Train | Epoch[193/600] Iteration[021/030] Train loss: 0.0176
2023-02-06 14:15:15 | Train | Epoch[193/600] Iteration[022/030] Train loss: 0.0176
2023-02-06 14:15:16 | Train | Epoch[193/600] Iteration[023/030] Train loss: 0.0175
2023-02-06 14:15:16 | Train | Epoch[193/600] Iteration[024/030] Train loss: 0.0176
2023-02-06 14:15:16 | Train | Epoch[193/600] Iteration[025/030] Train loss: 0.0175
2023-02-06 14:15:16 | Train | Epoch[193/600] Iteration[026/030] Train loss: 0.0175
2023-02-06 14:15:16 | Train | Epoch[193/600] Iteration[027/030] Train loss: 0.0175
2023-02-06 14:15:17 | Train | Epoch[193/600] Iteration[028/030] Train loss: 0.0175
2023-02-06 14:15:17 | Train | Epoch[193/600] Iteration[029/030] Train loss: 0.0175
2023-02-06 14:15:17 | Train | Epoch[193/600] Iteration[030/030] Train loss: 0.0175
2023-02-06 14:15:17 | Valid | Epoch[193/600] Iteration[001/008] Valid loss: 0.0696
2023-02-06 14:15:17 | Valid | Epoch[193/600] Iteration[002/008] Valid loss: 0.0633
2023-02-06 14:15:17 | Valid | Epoch[193/600] Iteration[003/008] Valid loss: 0.0608
2023-02-06 14:15:18 | Valid | Epoch[193/600] Iteration[004/008] Valid loss: 0.0576
2023-02-06 14:15:18 | Valid | Epoch[193/600] Iteration[005/008] Valid loss: 0.0583
2023-02-06 14:15:18 | Valid | Epoch[193/600] Iteration[006/008] Valid loss: 0.0567
2023-02-06 14:15:18 | Valid | Epoch[193/600] Iteration[007/008] Valid loss: 0.0564
2023-02-06 14:15:18 | Valid | Epoch[193/600] Iteration[008/008] Valid loss: 0.0560
2023-02-06 14:15:18 | Valid | Epoch[193/600] MIou: 0.8900012191345967
2023-02-06 14:15:18 | Valid | Epoch[193/600] Pixel Accuracy: 0.9813931783040365
2023-02-06 14:15:18 | Valid | Epoch[193/600] Mean Pixel Accuracy: 0.9107833031366561
2023-02-06 14:15:18 | Stage | Epoch[193/600] Train loss:0.0175
2023-02-06 14:15:18 | Stage | Epoch[193/600] Valid loss:0.0560
2023-02-06 14:15:18 | Stage | Epoch[193/600] LR:0.01

2023-02-06 14:15:18 | Train | Epoch[194/600] Iteration[001/030] Train loss: 0.0160
2023-02-06 14:15:18 | Train | Epoch[194/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 14:15:19 | Train | Epoch[194/600] Iteration[003/030] Train loss: 0.0163
2023-02-06 14:15:19 | Train | Epoch[194/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 14:15:19 | Train | Epoch[194/600] Iteration[005/030] Train loss: 0.0187
2023-02-06 14:15:19 | Train | Epoch[194/600] Iteration[006/030] Train loss: 0.0182
2023-02-06 14:15:20 | Train | Epoch[194/600] Iteration[007/030] Train loss: 0.0181
2023-02-06 14:15:20 | Train | Epoch[194/600] Iteration[008/030] Train loss: 0.0187
2023-02-06 14:15:20 | Train | Epoch[194/600] Iteration[009/030] Train loss: 0.0183
2023-02-06 14:15:20 | Train | Epoch[194/600] Iteration[010/030] Train loss: 0.0184
2023-02-06 14:15:20 | Train | Epoch[194/600] Iteration[011/030] Train loss: 0.0183
2023-02-06 14:15:21 | Train | Epoch[194/600] Iteration[012/030] Train loss: 0.0183
2023-02-06 14:15:21 | Train | Epoch[194/600] Iteration[013/030] Train loss: 0.0181
2023-02-06 14:15:21 | Train | Epoch[194/600] Iteration[014/030] Train loss: 0.0182
2023-02-06 14:15:21 | Train | Epoch[194/600] Iteration[015/030] Train loss: 0.0182
2023-02-06 14:15:22 | Train | Epoch[194/600] Iteration[016/030] Train loss: 0.0181
2023-02-06 14:15:22 | Train | Epoch[194/600] Iteration[017/030] Train loss: 0.0181
2023-02-06 14:15:22 | Train | Epoch[194/600] Iteration[018/030] Train loss: 0.0180
2023-02-06 14:15:22 | Train | Epoch[194/600] Iteration[019/030] Train loss: 0.0181
2023-02-06 14:15:22 | Train | Epoch[194/600] Iteration[020/030] Train loss: 0.0180
2023-02-06 14:15:23 | Train | Epoch[194/600] Iteration[021/030] Train loss: 0.0180
2023-02-06 14:15:23 | Train | Epoch[194/600] Iteration[022/030] Train loss: 0.0180
2023-02-06 14:15:23 | Train | Epoch[194/600] Iteration[023/030] Train loss: 0.0180
2023-02-06 14:15:23 | Train | Epoch[194/600] Iteration[024/030] Train loss: 0.0180
2023-02-06 14:15:24 | Train | Epoch[194/600] Iteration[025/030] Train loss: 0.0180
2023-02-06 14:15:24 | Train | Epoch[194/600] Iteration[026/030] Train loss: 0.0180
2023-02-06 14:15:24 | Train | Epoch[194/600] Iteration[027/030] Train loss: 0.0180
2023-02-06 14:15:24 | Train | Epoch[194/600] Iteration[028/030] Train loss: 0.0181
2023-02-06 14:15:24 | Train | Epoch[194/600] Iteration[029/030] Train loss: 0.0180
2023-02-06 14:15:25 | Train | Epoch[194/600] Iteration[030/030] Train loss: 0.0180
2023-02-06 14:15:25 | Valid | Epoch[194/600] Iteration[001/008] Valid loss: 0.6079
2023-02-06 14:15:25 | Valid | Epoch[194/600] Iteration[002/008] Valid loss: 0.5473
2023-02-06 14:15:25 | Valid | Epoch[194/600] Iteration[003/008] Valid loss: 0.5890
2023-02-06 14:15:25 | Valid | Epoch[194/600] Iteration[004/008] Valid loss: 0.5901
2023-02-06 14:15:25 | Valid | Epoch[194/600] Iteration[005/008] Valid loss: 0.6051
2023-02-06 14:15:25 | Valid | Epoch[194/600] Iteration[006/008] Valid loss: 0.5990
2023-02-06 14:15:25 | Valid | Epoch[194/600] Iteration[007/008] Valid loss: 0.6284
2023-02-06 14:15:25 | Valid | Epoch[194/600] Iteration[008/008] Valid loss: 0.6498
2023-02-06 14:15:25 | Valid | Epoch[194/600] MIou: 0.8835234415652167
2023-02-06 14:15:25 | Valid | Epoch[194/600] Pixel Accuracy: 0.9767939249674479
2023-02-06 14:15:25 | Valid | Epoch[194/600] Mean Pixel Accuracy: 0.978856507636465
2023-02-06 14:15:25 | Stage | Epoch[194/600] Train loss:0.0180
2023-02-06 14:15:25 | Stage | Epoch[194/600] Valid loss:0.6498
2023-02-06 14:15:25 | Stage | Epoch[194/600] LR:0.01

2023-02-06 14:15:26 | Train | Epoch[195/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 14:15:26 | Train | Epoch[195/600] Iteration[002/030] Train loss: 0.0175
2023-02-06 14:15:26 | Train | Epoch[195/600] Iteration[003/030] Train loss: 0.0171
2023-02-06 14:15:26 | Train | Epoch[195/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 14:15:27 | Train | Epoch[195/600] Iteration[005/030] Train loss: 0.0172
2023-02-06 14:15:27 | Train | Epoch[195/600] Iteration[006/030] Train loss: 0.0173
2023-02-06 14:15:27 | Train | Epoch[195/600] Iteration[007/030] Train loss: 0.0171
2023-02-06 14:15:27 | Train | Epoch[195/600] Iteration[008/030] Train loss: 0.0171
2023-02-06 14:15:28 | Train | Epoch[195/600] Iteration[009/030] Train loss: 0.0171
2023-02-06 14:15:28 | Train | Epoch[195/600] Iteration[010/030] Train loss: 0.0171
2023-02-06 14:15:28 | Train | Epoch[195/600] Iteration[011/030] Train loss: 0.0171
2023-02-06 14:15:28 | Train | Epoch[195/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 14:15:28 | Train | Epoch[195/600] Iteration[013/030] Train loss: 0.0172
2023-02-06 14:15:29 | Train | Epoch[195/600] Iteration[014/030] Train loss: 0.0173
2023-02-06 14:15:29 | Train | Epoch[195/600] Iteration[015/030] Train loss: 0.0173
2023-02-06 14:15:29 | Train | Epoch[195/600] Iteration[016/030] Train loss: 0.0175
2023-02-06 14:15:29 | Train | Epoch[195/600] Iteration[017/030] Train loss: 0.0175
2023-02-06 14:15:30 | Train | Epoch[195/600] Iteration[018/030] Train loss: 0.0175
2023-02-06 14:15:30 | Train | Epoch[195/600] Iteration[019/030] Train loss: 0.0175
2023-02-06 14:15:30 | Train | Epoch[195/600] Iteration[020/030] Train loss: 0.0174
2023-02-06 14:15:30 | Train | Epoch[195/600] Iteration[021/030] Train loss: 0.0174
2023-02-06 14:15:30 | Train | Epoch[195/600] Iteration[022/030] Train loss: 0.0174
2023-02-06 14:15:31 | Train | Epoch[195/600] Iteration[023/030] Train loss: 0.0174
2023-02-06 14:15:31 | Train | Epoch[195/600] Iteration[024/030] Train loss: 0.0175
2023-02-06 14:15:31 | Train | Epoch[195/600] Iteration[025/030] Train loss: 0.0175
2023-02-06 14:15:31 | Train | Epoch[195/600] Iteration[026/030] Train loss: 0.0175
2023-02-06 14:15:31 | Train | Epoch[195/600] Iteration[027/030] Train loss: 0.0175
2023-02-06 14:15:32 | Train | Epoch[195/600] Iteration[028/030] Train loss: 0.0174
2023-02-06 14:15:32 | Train | Epoch[195/600] Iteration[029/030] Train loss: 0.0174
2023-02-06 14:15:32 | Train | Epoch[195/600] Iteration[030/030] Train loss: 0.0173
2023-02-06 14:15:32 | Valid | Epoch[195/600] Iteration[001/008] Valid loss: 0.2529
2023-02-06 14:15:32 | Valid | Epoch[195/600] Iteration[002/008] Valid loss: 0.1938
2023-02-06 14:15:32 | Valid | Epoch[195/600] Iteration[003/008] Valid loss: 0.1831
2023-02-06 14:15:33 | Valid | Epoch[195/600] Iteration[004/008] Valid loss: 0.1771
2023-02-06 14:15:33 | Valid | Epoch[195/600] Iteration[005/008] Valid loss: 0.1756
2023-02-06 14:15:33 | Valid | Epoch[195/600] Iteration[006/008] Valid loss: 0.1674
2023-02-06 14:15:33 | Valid | Epoch[195/600] Iteration[007/008] Valid loss: 0.1801
2023-02-06 14:15:33 | Valid | Epoch[195/600] Iteration[008/008] Valid loss: 0.1869
2023-02-06 14:15:33 | Valid | Epoch[195/600] MIou: 0.9203703670943794
2023-02-06 14:15:33 | Valid | Epoch[195/600] Pixel Accuracy: 0.9855626424153646
2023-02-06 14:15:33 | Valid | Epoch[195/600] Mean Pixel Accuracy: 0.9715278253054493
2023-02-06 14:15:33 | Stage | Epoch[195/600] Train loss:0.0173
2023-02-06 14:15:33 | Stage | Epoch[195/600] Valid loss:0.1869
2023-02-06 14:15:33 | Stage | Epoch[195/600] LR:0.01

2023-02-06 14:15:33 | Train | Epoch[196/600] Iteration[001/030] Train loss: 0.0159
2023-02-06 14:15:33 | Train | Epoch[196/600] Iteration[002/030] Train loss: 0.0171
2023-02-06 14:15:34 | Train | Epoch[196/600] Iteration[003/030] Train loss: 0.0170
2023-02-06 14:15:34 | Train | Epoch[196/600] Iteration[004/030] Train loss: 0.0168
2023-02-06 14:15:34 | Train | Epoch[196/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 14:15:34 | Train | Epoch[196/600] Iteration[006/030] Train loss: 0.0169
2023-02-06 14:15:35 | Train | Epoch[196/600] Iteration[007/030] Train loss: 0.0168
2023-02-06 14:15:35 | Train | Epoch[196/600] Iteration[008/030] Train loss: 0.0168
2023-02-06 14:15:35 | Train | Epoch[196/600] Iteration[009/030] Train loss: 0.0169
2023-02-06 14:15:35 | Train | Epoch[196/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 14:15:35 | Train | Epoch[196/600] Iteration[011/030] Train loss: 0.0169
2023-02-06 14:15:36 | Train | Epoch[196/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 14:15:36 | Train | Epoch[196/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 14:15:36 | Train | Epoch[196/600] Iteration[014/030] Train loss: 0.0167
2023-02-06 14:15:36 | Train | Epoch[196/600] Iteration[015/030] Train loss: 0.0167
2023-02-06 14:15:37 | Train | Epoch[196/600] Iteration[016/030] Train loss: 0.0167
2023-02-06 14:15:37 | Train | Epoch[196/600] Iteration[017/030] Train loss: 0.0168
2023-02-06 14:15:37 | Train | Epoch[196/600] Iteration[018/030] Train loss: 0.0168
2023-02-06 14:15:37 | Train | Epoch[196/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 14:15:37 | Train | Epoch[196/600] Iteration[020/030] Train loss: 0.0169
2023-02-06 14:15:38 | Train | Epoch[196/600] Iteration[021/030] Train loss: 0.0168
2023-02-06 14:15:38 | Train | Epoch[196/600] Iteration[022/030] Train loss: 0.0168
2023-02-06 14:15:38 | Train | Epoch[196/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 14:15:38 | Train | Epoch[196/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 14:15:39 | Train | Epoch[196/600] Iteration[025/030] Train loss: 0.0174
2023-02-06 14:15:39 | Train | Epoch[196/600] Iteration[026/030] Train loss: 0.0174
2023-02-06 14:15:39 | Train | Epoch[196/600] Iteration[027/030] Train loss: 0.0174
2023-02-06 14:15:39 | Train | Epoch[196/600] Iteration[028/030] Train loss: 0.0173
2023-02-06 14:15:39 | Train | Epoch[196/600] Iteration[029/030] Train loss: 0.0174
2023-02-06 14:15:40 | Train | Epoch[196/600] Iteration[030/030] Train loss: 0.0174
2023-02-06 14:15:40 | Valid | Epoch[196/600] Iteration[001/008] Valid loss: 0.1175
2023-02-06 14:15:40 | Valid | Epoch[196/600] Iteration[002/008] Valid loss: 0.0852
2023-02-06 14:15:40 | Valid | Epoch[196/600] Iteration[003/008] Valid loss: 0.0764
2023-02-06 14:15:40 | Valid | Epoch[196/600] Iteration[004/008] Valid loss: 0.0682
2023-02-06 14:15:40 | Valid | Epoch[196/600] Iteration[005/008] Valid loss: 0.0664
2023-02-06 14:15:40 | Valid | Epoch[196/600] Iteration[006/008] Valid loss: 0.0651
2023-02-06 14:15:40 | Valid | Epoch[196/600] Iteration[007/008] Valid loss: 0.0660
2023-02-06 14:15:40 | Valid | Epoch[196/600] Iteration[008/008] Valid loss: 0.0635
2023-02-06 14:15:40 | Valid | Epoch[196/600] MIou: 0.9227136343311322
2023-02-06 14:15:40 | Valid | Epoch[196/600] Pixel Accuracy: 0.9869372049967448
2023-02-06 14:15:40 | Valid | Epoch[196/600] Mean Pixel Accuracy: 0.9413418425449026
2023-02-06 14:15:40 | Stage | Epoch[196/600] Train loss:0.0174
2023-02-06 14:15:40 | Stage | Epoch[196/600] Valid loss:0.0635
2023-02-06 14:15:40 | Stage | Epoch[196/600] LR:0.01

2023-02-06 14:15:41 | Train | Epoch[197/600] Iteration[001/030] Train loss: 0.0154
2023-02-06 14:15:41 | Train | Epoch[197/600] Iteration[002/030] Train loss: 0.0160
2023-02-06 14:15:41 | Train | Epoch[197/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 14:15:41 | Train | Epoch[197/600] Iteration[004/030] Train loss: 0.0169
2023-02-06 14:15:42 | Train | Epoch[197/600] Iteration[005/030] Train loss: 0.0169
2023-02-06 14:15:42 | Train | Epoch[197/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 14:15:42 | Train | Epoch[197/600] Iteration[007/030] Train loss: 0.0167
2023-02-06 14:15:42 | Train | Epoch[197/600] Iteration[008/030] Train loss: 0.0167
2023-02-06 14:15:43 | Train | Epoch[197/600] Iteration[009/030] Train loss: 0.0168
2023-02-06 14:15:43 | Train | Epoch[197/600] Iteration[010/030] Train loss: 0.0168
2023-02-06 14:15:43 | Train | Epoch[197/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 14:15:43 | Train | Epoch[197/600] Iteration[012/030] Train loss: 0.0169
2023-02-06 14:15:43 | Train | Epoch[197/600] Iteration[013/030] Train loss: 0.0168
2023-02-06 14:15:44 | Train | Epoch[197/600] Iteration[014/030] Train loss: 0.0169
2023-02-06 14:15:44 | Train | Epoch[197/600] Iteration[015/030] Train loss: 0.0168
2023-02-06 14:15:44 | Train | Epoch[197/600] Iteration[016/030] Train loss: 0.0170
2023-02-06 14:15:44 | Train | Epoch[197/600] Iteration[017/030] Train loss: 0.0170
2023-02-06 14:15:45 | Train | Epoch[197/600] Iteration[018/030] Train loss: 0.0170
2023-02-06 14:15:45 | Train | Epoch[197/600] Iteration[019/030] Train loss: 0.0169
2023-02-06 14:15:45 | Train | Epoch[197/600] Iteration[020/030] Train loss: 0.0169
2023-02-06 14:15:45 | Train | Epoch[197/600] Iteration[021/030] Train loss: 0.0169
2023-02-06 14:15:45 | Train | Epoch[197/600] Iteration[022/030] Train loss: 0.0169
2023-02-06 14:15:46 | Train | Epoch[197/600] Iteration[023/030] Train loss: 0.0169
2023-02-06 14:15:46 | Train | Epoch[197/600] Iteration[024/030] Train loss: 0.0169
2023-02-06 14:15:46 | Train | Epoch[197/600] Iteration[025/030] Train loss: 0.0168
2023-02-06 14:15:46 | Train | Epoch[197/600] Iteration[026/030] Train loss: 0.0168
2023-02-06 14:15:46 | Train | Epoch[197/600] Iteration[027/030] Train loss: 0.0169
2023-02-06 14:15:47 | Train | Epoch[197/600] Iteration[028/030] Train loss: 0.0169
2023-02-06 14:15:47 | Train | Epoch[197/600] Iteration[029/030] Train loss: 0.0169
2023-02-06 14:15:47 | Train | Epoch[197/600] Iteration[030/030] Train loss: 0.0169
2023-02-06 14:15:47 | Valid | Epoch[197/600] Iteration[001/008] Valid loss: 1.0107
2023-02-06 14:15:47 | Valid | Epoch[197/600] Iteration[002/008] Valid loss: 0.9045
2023-02-06 14:15:47 | Valid | Epoch[197/600] Iteration[003/008] Valid loss: 0.9582
2023-02-06 14:15:48 | Valid | Epoch[197/600] Iteration[004/008] Valid loss: 0.9748
2023-02-06 14:15:48 | Valid | Epoch[197/600] Iteration[005/008] Valid loss: 1.0246
2023-02-06 14:15:48 | Valid | Epoch[197/600] Iteration[006/008] Valid loss: 1.0118
2023-02-06 14:15:48 | Valid | Epoch[197/600] Iteration[007/008] Valid loss: 1.0611
2023-02-06 14:15:48 | Valid | Epoch[197/600] Iteration[008/008] Valid loss: 1.1096
2023-02-06 14:15:48 | Valid | Epoch[197/600] MIou: 0.8484824941976694
2023-02-06 14:15:48 | Valid | Epoch[197/600] Pixel Accuracy: 0.9673296610514323
2023-02-06 14:15:48 | Valid | Epoch[197/600] Mean Pixel Accuracy: 0.9785747504405033
2023-02-06 14:15:48 | Stage | Epoch[197/600] Train loss:0.0169
2023-02-06 14:15:48 | Stage | Epoch[197/600] Valid loss:1.1096
2023-02-06 14:15:48 | Stage | Epoch[197/600] LR:0.01

2023-02-06 14:15:48 | Train | Epoch[198/600] Iteration[001/030] Train loss: 0.0159
2023-02-06 14:15:49 | Train | Epoch[198/600] Iteration[002/030] Train loss: 0.0162
2023-02-06 14:15:49 | Train | Epoch[198/600] Iteration[003/030] Train loss: 0.0162
2023-02-06 14:15:49 | Train | Epoch[198/600] Iteration[004/030] Train loss: 0.0166
2023-02-06 14:15:49 | Train | Epoch[198/600] Iteration[005/030] Train loss: 0.0164
2023-02-06 14:15:49 | Train | Epoch[198/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 14:15:50 | Train | Epoch[198/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 14:15:50 | Train | Epoch[198/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 14:15:50 | Train | Epoch[198/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 14:15:50 | Train | Epoch[198/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 14:15:50 | Train | Epoch[198/600] Iteration[011/030] Train loss: 0.0164
2023-02-06 14:15:51 | Train | Epoch[198/600] Iteration[012/030] Train loss: 0.0164
2023-02-06 14:15:51 | Train | Epoch[198/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 14:15:51 | Train | Epoch[198/600] Iteration[014/030] Train loss: 0.0164
2023-02-06 14:15:51 | Train | Epoch[198/600] Iteration[015/030] Train loss: 0.0164
2023-02-06 14:15:52 | Train | Epoch[198/600] Iteration[016/030] Train loss: 0.0163
2023-02-06 14:15:52 | Train | Epoch[198/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 14:15:52 | Train | Epoch[198/600] Iteration[018/030] Train loss: 0.0163
2023-02-06 14:15:52 | Train | Epoch[198/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 14:15:52 | Train | Epoch[198/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 14:15:53 | Train | Epoch[198/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 14:15:53 | Train | Epoch[198/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 14:15:53 | Train | Epoch[198/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 14:15:53 | Train | Epoch[198/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 14:15:54 | Train | Epoch[198/600] Iteration[025/030] Train loss: 0.0161
2023-02-06 14:15:54 | Train | Epoch[198/600] Iteration[026/030] Train loss: 0.0161
2023-02-06 14:15:54 | Train | Epoch[198/600] Iteration[027/030] Train loss: 0.0161
2023-02-06 14:15:54 | Train | Epoch[198/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 14:15:54 | Train | Epoch[198/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 14:15:55 | Train | Epoch[198/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 14:15:55 | Valid | Epoch[198/600] Iteration[001/008] Valid loss: 0.2758
2023-02-06 14:15:55 | Valid | Epoch[198/600] Iteration[002/008] Valid loss: 0.2264
2023-02-06 14:15:55 | Valid | Epoch[198/600] Iteration[003/008] Valid loss: 0.2213
2023-02-06 14:15:55 | Valid | Epoch[198/600] Iteration[004/008] Valid loss: 0.2124
2023-02-06 14:15:55 | Valid | Epoch[198/600] Iteration[005/008] Valid loss: 0.2187
2023-02-06 14:15:55 | Valid | Epoch[198/600] Iteration[006/008] Valid loss: 0.2149
2023-02-06 14:15:55 | Valid | Epoch[198/600] Iteration[007/008] Valid loss: 0.2340
2023-02-06 14:15:55 | Valid | Epoch[198/600] Iteration[008/008] Valid loss: 0.2365
2023-02-06 14:15:55 | Valid | Epoch[198/600] MIou: 0.9207297809002148
2023-02-06 14:15:55 | Valid | Epoch[198/600] Pixel Accuracy: 0.9855384826660156
2023-02-06 14:15:55 | Valid | Epoch[198/600] Mean Pixel Accuracy: 0.9749003578642693
2023-02-06 14:15:55 | Stage | Epoch[198/600] Train loss:0.0164
2023-02-06 14:15:55 | Stage | Epoch[198/600] Valid loss:0.2365
2023-02-06 14:15:55 | Stage | Epoch[198/600] LR:0.01

2023-02-06 14:15:56 | Train | Epoch[199/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 14:15:56 | Train | Epoch[199/600] Iteration[002/030] Train loss: 0.0174
2023-02-06 14:15:56 | Train | Epoch[199/600] Iteration[003/030] Train loss: 0.0174
2023-02-06 14:15:56 | Train | Epoch[199/600] Iteration[004/030] Train loss: 0.0172
2023-02-06 14:15:57 | Train | Epoch[199/600] Iteration[005/030] Train loss: 0.0171
2023-02-06 14:15:57 | Train | Epoch[199/600] Iteration[006/030] Train loss: 0.0170
2023-02-06 14:15:57 | Train | Epoch[199/600] Iteration[007/030] Train loss: 0.0175
2023-02-06 14:15:57 | Train | Epoch[199/600] Iteration[008/030] Train loss: 0.0177
2023-02-06 14:15:58 | Train | Epoch[199/600] Iteration[009/030] Train loss: 0.0176
2023-02-06 14:15:58 | Train | Epoch[199/600] Iteration[010/030] Train loss: 0.0174
2023-02-06 14:15:58 | Train | Epoch[199/600] Iteration[011/030] Train loss: 0.0172
2023-02-06 14:15:58 | Train | Epoch[199/600] Iteration[012/030] Train loss: 0.0171
2023-02-06 14:15:58 | Train | Epoch[199/600] Iteration[013/030] Train loss: 0.0170
2023-02-06 14:15:59 | Train | Epoch[199/600] Iteration[014/030] Train loss: 0.0172
2023-02-06 14:15:59 | Train | Epoch[199/600] Iteration[015/030] Train loss: 0.0173
2023-02-06 14:15:59 | Train | Epoch[199/600] Iteration[016/030] Train loss: 0.0173
2023-02-06 14:15:59 | Train | Epoch[199/600] Iteration[017/030] Train loss: 0.0172
2023-02-06 14:16:00 | Train | Epoch[199/600] Iteration[018/030] Train loss: 0.0172
2023-02-06 14:16:00 | Train | Epoch[199/600] Iteration[019/030] Train loss: 0.0172
2023-02-06 14:16:00 | Train | Epoch[199/600] Iteration[020/030] Train loss: 0.0172
2023-02-06 14:16:00 | Train | Epoch[199/600] Iteration[021/030] Train loss: 0.0171
2023-02-06 14:16:00 | Train | Epoch[199/600] Iteration[022/030] Train loss: 0.0170
2023-02-06 14:16:01 | Train | Epoch[199/600] Iteration[023/030] Train loss: 0.0170
2023-02-06 14:16:01 | Train | Epoch[199/600] Iteration[024/030] Train loss: 0.0171
2023-02-06 14:16:01 | Train | Epoch[199/600] Iteration[025/030] Train loss: 0.0171
2023-02-06 14:16:01 | Train | Epoch[199/600] Iteration[026/030] Train loss: 0.0171
2023-02-06 14:16:02 | Train | Epoch[199/600] Iteration[027/030] Train loss: 0.0171
2023-02-06 14:16:02 | Train | Epoch[199/600] Iteration[028/030] Train loss: 0.0171
2023-02-06 14:16:02 | Train | Epoch[199/600] Iteration[029/030] Train loss: 0.0171
2023-02-06 14:16:02 | Train | Epoch[199/600] Iteration[030/030] Train loss: 0.0170
2023-02-06 14:16:02 | Valid | Epoch[199/600] Iteration[001/008] Valid loss: 0.1414
2023-02-06 14:16:02 | Valid | Epoch[199/600] Iteration[002/008] Valid loss: 0.1471
2023-02-06 14:16:03 | Valid | Epoch[199/600] Iteration[003/008] Valid loss: 0.1543
2023-02-06 14:16:03 | Valid | Epoch[199/600] Iteration[004/008] Valid loss: 0.1541
2023-02-06 14:16:03 | Valid | Epoch[199/600] Iteration[005/008] Valid loss: 0.1562
2023-02-06 14:16:03 | Valid | Epoch[199/600] Iteration[006/008] Valid loss: 0.1519
2023-02-06 14:16:03 | Valid | Epoch[199/600] Iteration[007/008] Valid loss: 0.1461
2023-02-06 14:16:03 | Valid | Epoch[199/600] Iteration[008/008] Valid loss: 0.1505
2023-02-06 14:16:03 | Valid | Epoch[199/600] MIou: 0.6337019981235272
2023-02-06 14:16:03 | Valid | Epoch[199/600] Pixel Accuracy: 0.9394442240397135
2023-02-06 14:16:03 | Valid | Epoch[199/600] Mean Pixel Accuracy: 0.6649602426879441
2023-02-06 14:16:03 | Stage | Epoch[199/600] Train loss:0.0170
2023-02-06 14:16:03 | Stage | Epoch[199/600] Valid loss:0.1505
2023-02-06 14:16:03 | Stage | Epoch[199/600] LR:0.01

2023-02-06 14:16:03 | Train | Epoch[200/600] Iteration[001/030] Train loss: 0.0162
2023-02-06 14:16:04 | Train | Epoch[200/600] Iteration[002/030] Train loss: 0.0167
2023-02-06 14:16:04 | Train | Epoch[200/600] Iteration[003/030] Train loss: 0.0166
2023-02-06 14:16:04 | Train | Epoch[200/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 14:16:04 | Train | Epoch[200/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 14:16:04 | Train | Epoch[200/600] Iteration[006/030] Train loss: 0.0165
2023-02-06 14:16:05 | Train | Epoch[200/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 14:16:05 | Train | Epoch[200/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 14:16:05 | Train | Epoch[200/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 14:16:05 | Train | Epoch[200/600] Iteration[010/030] Train loss: 0.0165
2023-02-06 14:16:05 | Train | Epoch[200/600] Iteration[011/030] Train loss: 0.0165
2023-02-06 14:16:06 | Train | Epoch[200/600] Iteration[012/030] Train loss: 0.0165
2023-02-06 14:16:06 | Train | Epoch[200/600] Iteration[013/030] Train loss: 0.0165
2023-02-06 14:16:06 | Train | Epoch[200/600] Iteration[014/030] Train loss: 0.0165
2023-02-06 14:16:06 | Train | Epoch[200/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 14:16:07 | Train | Epoch[200/600] Iteration[016/030] Train loss: 0.0164
2023-02-06 14:16:07 | Train | Epoch[200/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 14:16:07 | Train | Epoch[200/600] Iteration[018/030] Train loss: 0.0165
2023-02-06 14:16:07 | Train | Epoch[200/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 14:16:07 | Train | Epoch[200/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 14:16:08 | Train | Epoch[200/600] Iteration[021/030] Train loss: 0.0165
2023-02-06 14:16:08 | Train | Epoch[200/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 14:16:08 | Train | Epoch[200/600] Iteration[023/030] Train loss: 0.0165
2023-02-06 14:16:08 | Train | Epoch[200/600] Iteration[024/030] Train loss: 0.0165
2023-02-06 14:16:09 | Train | Epoch[200/600] Iteration[025/030] Train loss: 0.0165
2023-02-06 14:16:09 | Train | Epoch[200/600] Iteration[026/030] Train loss: 0.0166
2023-02-06 14:16:09 | Train | Epoch[200/600] Iteration[027/030] Train loss: 0.0166
2023-02-06 14:16:09 | Train | Epoch[200/600] Iteration[028/030] Train loss: 0.0166
2023-02-06 14:16:09 | Train | Epoch[200/600] Iteration[029/030] Train loss: 0.0166
2023-02-06 14:16:10 | Train | Epoch[200/600] Iteration[030/030] Train loss: 0.0167
2023-02-06 14:16:10 | Valid | Epoch[200/600] Iteration[001/008] Valid loss: 0.2177
2023-02-06 14:16:10 | Valid | Epoch[200/600] Iteration[002/008] Valid loss: 0.1656
2023-02-06 14:16:10 | Valid | Epoch[200/600] Iteration[003/008] Valid loss: 0.1579
2023-02-06 14:16:10 | Valid | Epoch[200/600] Iteration[004/008] Valid loss: 0.1486
2023-02-06 14:16:10 | Valid | Epoch[200/600] Iteration[005/008] Valid loss: 0.1442
2023-02-06 14:16:10 | Valid | Epoch[200/600] Iteration[006/008] Valid loss: 0.1436
2023-02-06 14:16:10 | Valid | Epoch[200/600] Iteration[007/008] Valid loss: 0.1538
2023-02-06 14:16:10 | Valid | Epoch[200/600] Iteration[008/008] Valid loss: 0.1555
2023-02-06 14:16:10 | Valid | Epoch[200/600] MIou: 0.9248309156813135
2023-02-06 14:16:10 | Valid | Epoch[200/600] Pixel Accuracy: 0.9864756266276041
2023-02-06 14:16:10 | Valid | Epoch[200/600] Mean Pixel Accuracy: 0.9723276425273988
2023-02-06 14:16:10 | Stage | Epoch[200/600] Train loss:0.0167
2023-02-06 14:16:10 | Stage | Epoch[200/600] Valid loss:0.1555
2023-02-06 14:16:10 | Stage | Epoch[200/600] LR:0.01

2023-02-06 14:16:11 | Train | Epoch[201/600] Iteration[001/030] Train loss: 0.0151
2023-02-06 14:16:11 | Train | Epoch[201/600] Iteration[002/030] Train loss: 0.0159
2023-02-06 14:16:11 | Train | Epoch[201/600] Iteration[003/030] Train loss: 0.0163
2023-02-06 14:16:11 | Train | Epoch[201/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 14:16:12 | Train | Epoch[201/600] Iteration[005/030] Train loss: 0.0163
2023-02-06 14:16:12 | Train | Epoch[201/600] Iteration[006/030] Train loss: 0.0165
2023-02-06 14:16:12 | Train | Epoch[201/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 14:16:12 | Train | Epoch[201/600] Iteration[008/030] Train loss: 0.0164
2023-02-06 14:16:13 | Train | Epoch[201/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 14:16:13 | Train | Epoch[201/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 14:16:13 | Train | Epoch[201/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 14:16:13 | Train | Epoch[201/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 14:16:13 | Train | Epoch[201/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 14:16:14 | Train | Epoch[201/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 14:16:14 | Train | Epoch[201/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 14:16:14 | Train | Epoch[201/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 14:16:14 | Train | Epoch[201/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 14:16:15 | Train | Epoch[201/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 14:16:15 | Train | Epoch[201/600] Iteration[019/030] Train loss: 0.0163
2023-02-06 14:16:15 | Train | Epoch[201/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 14:16:15 | Train | Epoch[201/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 14:16:15 | Train | Epoch[201/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 14:16:16 | Train | Epoch[201/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 14:16:16 | Train | Epoch[201/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 14:16:16 | Train | Epoch[201/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 14:16:16 | Train | Epoch[201/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 14:16:17 | Train | Epoch[201/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 14:16:17 | Train | Epoch[201/600] Iteration[028/030] Train loss: 0.0163
2023-02-06 14:16:17 | Train | Epoch[201/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 14:16:17 | Train | Epoch[201/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 14:16:17 | Valid | Epoch[201/600] Iteration[001/008] Valid loss: 0.1066
2023-02-06 14:16:18 | Valid | Epoch[201/600] Iteration[002/008] Valid loss: 0.1025
2023-02-06 14:16:18 | Valid | Epoch[201/600] Iteration[003/008] Valid loss: 0.1080
2023-02-06 14:16:18 | Valid | Epoch[201/600] Iteration[004/008] Valid loss: 0.1064
2023-02-06 14:16:18 | Valid | Epoch[201/600] Iteration[005/008] Valid loss: 0.1054
2023-02-06 14:16:18 | Valid | Epoch[201/600] Iteration[006/008] Valid loss: 0.1042
2023-02-06 14:16:18 | Valid | Epoch[201/600] Iteration[007/008] Valid loss: 0.1009
2023-02-06 14:16:18 | Valid | Epoch[201/600] Iteration[008/008] Valid loss: 0.1019
2023-02-06 14:16:18 | Valid | Epoch[201/600] MIou: 0.7570392892109046
2023-02-06 14:16:18 | Valid | Epoch[201/600] Pixel Accuracy: 0.9596900939941406
2023-02-06 14:16:18 | Valid | Epoch[201/600] Mean Pixel Accuracy: 0.7797359240883354
2023-02-06 14:16:18 | Stage | Epoch[201/600] Train loss:0.0163
2023-02-06 14:16:18 | Stage | Epoch[201/600] Valid loss:0.1019
2023-02-06 14:16:18 | Stage | Epoch[201/600] LR:0.01

2023-02-06 14:16:18 | Train | Epoch[202/600] Iteration[001/030] Train loss: 0.0156
2023-02-06 14:16:19 | Train | Epoch[202/600] Iteration[002/030] Train loss: 0.0157
2023-02-06 14:16:19 | Train | Epoch[202/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 14:16:19 | Train | Epoch[202/600] Iteration[004/030] Train loss: 0.0161
2023-02-06 14:16:19 | Train | Epoch[202/600] Iteration[005/030] Train loss: 0.0158
2023-02-06 14:16:20 | Train | Epoch[202/600] Iteration[006/030] Train loss: 0.0157
2023-02-06 14:16:20 | Train | Epoch[202/600] Iteration[007/030] Train loss: 0.0158
2023-02-06 14:16:20 | Train | Epoch[202/600] Iteration[008/030] Train loss: 0.0159
2023-02-06 14:16:20 | Train | Epoch[202/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 14:16:20 | Train | Epoch[202/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 14:16:21 | Train | Epoch[202/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 14:16:21 | Train | Epoch[202/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 14:16:21 | Train | Epoch[202/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 14:16:21 | Train | Epoch[202/600] Iteration[014/030] Train loss: 0.0160
2023-02-06 14:16:21 | Train | Epoch[202/600] Iteration[015/030] Train loss: 0.0159
2023-02-06 14:16:22 | Train | Epoch[202/600] Iteration[016/030] Train loss: 0.0160
2023-02-06 14:16:22 | Train | Epoch[202/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 14:16:22 | Train | Epoch[202/600] Iteration[018/030] Train loss: 0.0159
2023-02-06 14:16:22 | Train | Epoch[202/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 14:16:23 | Train | Epoch[202/600] Iteration[020/030] Train loss: 0.0159
2023-02-06 14:16:23 | Train | Epoch[202/600] Iteration[021/030] Train loss: 0.0159
2023-02-06 14:16:23 | Train | Epoch[202/600] Iteration[022/030] Train loss: 0.0159
2023-02-06 14:16:23 | Train | Epoch[202/600] Iteration[023/030] Train loss: 0.0159
2023-02-06 14:16:23 | Train | Epoch[202/600] Iteration[024/030] Train loss: 0.0160
2023-02-06 14:16:24 | Train | Epoch[202/600] Iteration[025/030] Train loss: 0.0161
2023-02-06 14:16:24 | Train | Epoch[202/600] Iteration[026/030] Train loss: 0.0161
2023-02-06 14:16:24 | Train | Epoch[202/600] Iteration[027/030] Train loss: 0.0161
2023-02-06 14:16:24 | Train | Epoch[202/600] Iteration[028/030] Train loss: 0.0161
2023-02-06 14:16:25 | Train | Epoch[202/600] Iteration[029/030] Train loss: 0.0161
2023-02-06 14:16:25 | Train | Epoch[202/600] Iteration[030/030] Train loss: 0.0161
2023-02-06 14:16:25 | Valid | Epoch[202/600] Iteration[001/008] Valid loss: 0.0880
2023-02-06 14:16:25 | Valid | Epoch[202/600] Iteration[002/008] Valid loss: 0.0691
2023-02-06 14:16:25 | Valid | Epoch[202/600] Iteration[003/008] Valid loss: 0.0628
2023-02-06 14:16:25 | Valid | Epoch[202/600] Iteration[004/008] Valid loss: 0.0578
2023-02-06 14:16:25 | Valid | Epoch[202/600] Iteration[005/008] Valid loss: 0.0576
2023-02-06 14:16:25 | Valid | Epoch[202/600] Iteration[006/008] Valid loss: 0.0551
2023-02-06 14:16:25 | Valid | Epoch[202/600] Iteration[007/008] Valid loss: 0.0552
2023-02-06 14:16:25 | Valid | Epoch[202/600] Iteration[008/008] Valid loss: 0.0540
2023-02-06 14:16:25 | Valid | Epoch[202/600] MIou: 0.9115758661126725
2023-02-06 14:16:25 | Valid | Epoch[202/600] Pixel Accuracy: 0.9851697285970052
2023-02-06 14:16:25 | Valid | Epoch[202/600] Mean Pixel Accuracy: 0.9274992049650385
2023-02-06 14:16:25 | Stage | Epoch[202/600] Train loss:0.0161
2023-02-06 14:16:25 | Stage | Epoch[202/600] Valid loss:0.0540
2023-02-06 14:16:25 | Stage | Epoch[202/600] LR:0.01

2023-02-06 14:16:26 | Train | Epoch[203/600] Iteration[001/030] Train loss: 0.0158
2023-02-06 14:16:26 | Train | Epoch[203/600] Iteration[002/030] Train loss: 0.0157
2023-02-06 14:16:26 | Train | Epoch[203/600] Iteration[003/030] Train loss: 0.0157
2023-02-06 14:16:26 | Train | Epoch[203/600] Iteration[004/030] Train loss: 0.0158
2023-02-06 14:16:27 | Train | Epoch[203/600] Iteration[005/030] Train loss: 0.0158
2023-02-06 14:16:27 | Train | Epoch[203/600] Iteration[006/030] Train loss: 0.0156
2023-02-06 14:16:27 | Train | Epoch[203/600] Iteration[007/030] Train loss: 0.0155
2023-02-06 14:16:27 | Train | Epoch[203/600] Iteration[008/030] Train loss: 0.0157
2023-02-06 14:16:28 | Train | Epoch[203/600] Iteration[009/030] Train loss: 0.0159
2023-02-06 14:16:28 | Train | Epoch[203/600] Iteration[010/030] Train loss: 0.0159
2023-02-06 14:16:28 | Train | Epoch[203/600] Iteration[011/030] Train loss: 0.0158
2023-02-06 14:16:28 | Train | Epoch[203/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 14:16:28 | Train | Epoch[203/600] Iteration[013/030] Train loss: 0.0160
2023-02-06 14:16:29 | Train | Epoch[203/600] Iteration[014/030] Train loss: 0.0159
2023-02-06 14:16:29 | Train | Epoch[203/600] Iteration[015/030] Train loss: 0.0159
2023-02-06 14:16:29 | Train | Epoch[203/600] Iteration[016/030] Train loss: 0.0161
2023-02-06 14:16:29 | Train | Epoch[203/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 14:16:30 | Train | Epoch[203/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 14:16:30 | Train | Epoch[203/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 14:16:30 | Train | Epoch[203/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 14:16:30 | Train | Epoch[203/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 14:16:30 | Train | Epoch[203/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 14:16:31 | Train | Epoch[203/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 14:16:31 | Train | Epoch[203/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 14:16:31 | Train | Epoch[203/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 14:16:31 | Train | Epoch[203/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 14:16:32 | Train | Epoch[203/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 14:16:32 | Train | Epoch[203/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 14:16:32 | Train | Epoch[203/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 14:16:32 | Train | Epoch[203/600] Iteration[030/030] Train loss: 0.0162
2023-02-06 14:16:32 | Valid | Epoch[203/600] Iteration[001/008] Valid loss: 1.4859
2023-02-06 14:16:32 | Valid | Epoch[203/600] Iteration[002/008] Valid loss: 1.4460
2023-02-06 14:16:33 | Valid | Epoch[203/600] Iteration[003/008] Valid loss: 1.4734
2023-02-06 14:16:33 | Valid | Epoch[203/600] Iteration[004/008] Valid loss: 1.4907
2023-02-06 14:16:33 | Valid | Epoch[203/600] Iteration[005/008] Valid loss: 1.5338
2023-02-06 14:16:33 | Valid | Epoch[203/600] Iteration[006/008] Valid loss: 1.5152
2023-02-06 14:16:33 | Valid | Epoch[203/600] Iteration[007/008] Valid loss: 1.5817
2023-02-06 14:16:33 | Valid | Epoch[203/600] Iteration[008/008] Valid loss: 1.6393
2023-02-06 14:16:33 | Valid | Epoch[203/600] MIou: 0.8318525595735454
2023-02-06 14:16:33 | Valid | Epoch[203/600] Pixel Accuracy: 0.9623438517252604
2023-02-06 14:16:33 | Valid | Epoch[203/600] Mean Pixel Accuracy: 0.9778632878790801
2023-02-06 14:16:33 | Stage | Epoch[203/600] Train loss:0.0162
2023-02-06 14:16:33 | Stage | Epoch[203/600] Valid loss:1.6393
2023-02-06 14:16:33 | Stage | Epoch[203/600] LR:0.01

2023-02-06 14:16:33 | Train | Epoch[204/600] Iteration[001/030] Train loss: 0.0163
2023-02-06 14:16:34 | Train | Epoch[204/600] Iteration[002/030] Train loss: 0.0165
2023-02-06 14:16:34 | Train | Epoch[204/600] Iteration[003/030] Train loss: 0.0161
2023-02-06 14:16:34 | Train | Epoch[204/600] Iteration[004/030] Train loss: 0.0164
2023-02-06 14:16:34 | Train | Epoch[204/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 14:16:34 | Train | Epoch[204/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 14:16:35 | Train | Epoch[204/600] Iteration[007/030] Train loss: 0.0164
2023-02-06 14:16:35 | Train | Epoch[204/600] Iteration[008/030] Train loss: 0.0163
2023-02-06 14:16:35 | Train | Epoch[204/600] Iteration[009/030] Train loss: 0.0162
2023-02-06 14:16:35 | Train | Epoch[204/600] Iteration[010/030] Train loss: 0.0163
2023-02-06 14:16:36 | Train | Epoch[204/600] Iteration[011/030] Train loss: 0.0162
2023-02-06 14:16:36 | Train | Epoch[204/600] Iteration[012/030] Train loss: 0.0162
2023-02-06 14:16:36 | Train | Epoch[204/600] Iteration[013/030] Train loss: 0.0160
2023-02-06 14:16:36 | Train | Epoch[204/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 14:16:36 | Train | Epoch[204/600] Iteration[015/030] Train loss: 0.0160
2023-02-06 14:16:37 | Train | Epoch[204/600] Iteration[016/030] Train loss: 0.0160
2023-02-06 14:16:37 | Train | Epoch[204/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 14:16:37 | Train | Epoch[204/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 14:16:37 | Train | Epoch[204/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 14:16:38 | Train | Epoch[204/600] Iteration[020/030] Train loss: 0.0160
2023-02-06 14:16:38 | Train | Epoch[204/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 14:16:38 | Train | Epoch[204/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 14:16:38 | Train | Epoch[204/600] Iteration[023/030] Train loss: 0.0164
2023-02-06 14:16:38 | Train | Epoch[204/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 14:16:39 | Train | Epoch[204/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 14:16:39 | Train | Epoch[204/600] Iteration[026/030] Train loss: 0.0164
2023-02-06 14:16:39 | Train | Epoch[204/600] Iteration[027/030] Train loss: 0.0164
2023-02-06 14:16:39 | Train | Epoch[204/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 14:16:39 | Train | Epoch[204/600] Iteration[029/030] Train loss: 0.0163
2023-02-06 14:16:40 | Train | Epoch[204/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 14:16:40 | Valid | Epoch[204/600] Iteration[001/008] Valid loss: 0.9711
2023-02-06 14:16:40 | Valid | Epoch[204/600] Iteration[002/008] Valid loss: 0.9451
2023-02-06 14:16:40 | Valid | Epoch[204/600] Iteration[003/008] Valid loss: 0.9814
2023-02-06 14:16:40 | Valid | Epoch[204/600] Iteration[004/008] Valid loss: 0.9923
2023-02-06 14:16:40 | Valid | Epoch[204/600] Iteration[005/008] Valid loss: 1.0211
2023-02-06 14:16:40 | Valid | Epoch[204/600] Iteration[006/008] Valid loss: 1.0048
2023-02-06 14:16:40 | Valid | Epoch[204/600] Iteration[007/008] Valid loss: 1.0575
2023-02-06 14:16:40 | Valid | Epoch[204/600] Iteration[008/008] Valid loss: 1.1150
2023-02-06 14:16:40 | Valid | Epoch[204/600] MIou: 0.8348626230117733
2023-02-06 14:16:40 | Valid | Epoch[204/600] Pixel Accuracy: 0.9635124206542969
2023-02-06 14:16:40 | Valid | Epoch[204/600] Mean Pixel Accuracy: 0.9745681503917363
2023-02-06 14:16:40 | Stage | Epoch[204/600] Train loss:0.0163
2023-02-06 14:16:40 | Stage | Epoch[204/600] Valid loss:1.1150
2023-02-06 14:16:40 | Stage | Epoch[204/600] LR:0.01

2023-02-06 14:16:41 | Train | Epoch[205/600] Iteration[001/030] Train loss: 0.0158
2023-02-06 14:16:41 | Train | Epoch[205/600] Iteration[002/030] Train loss: 0.0155
2023-02-06 14:16:41 | Train | Epoch[205/600] Iteration[003/030] Train loss: 0.0157
2023-02-06 14:16:41 | Train | Epoch[205/600] Iteration[004/030] Train loss: 0.0155
2023-02-06 14:16:42 | Train | Epoch[205/600] Iteration[005/030] Train loss: 0.0153
2023-02-06 14:16:42 | Train | Epoch[205/600] Iteration[006/030] Train loss: 0.0160
2023-02-06 14:16:42 | Train | Epoch[205/600] Iteration[007/030] Train loss: 0.0160
2023-02-06 14:16:42 | Train | Epoch[205/600] Iteration[008/030] Train loss: 0.0159
2023-02-06 14:16:43 | Train | Epoch[205/600] Iteration[009/030] Train loss: 0.0159
2023-02-06 14:16:43 | Train | Epoch[205/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 14:16:43 | Train | Epoch[205/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 14:16:43 | Train | Epoch[205/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 14:16:43 | Train | Epoch[205/600] Iteration[013/030] Train loss: 0.0160
2023-02-06 14:16:44 | Train | Epoch[205/600] Iteration[014/030] Train loss: 0.0161
2023-02-06 14:16:44 | Train | Epoch[205/600] Iteration[015/030] Train loss: 0.0162
2023-02-06 14:16:44 | Train | Epoch[205/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 14:16:44 | Train | Epoch[205/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 14:16:45 | Train | Epoch[205/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 14:16:45 | Train | Epoch[205/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 14:16:45 | Train | Epoch[205/600] Iteration[020/030] Train loss: 0.0162
2023-02-06 14:16:45 | Train | Epoch[205/600] Iteration[021/030] Train loss: 0.0162
2023-02-06 14:16:45 | Train | Epoch[205/600] Iteration[022/030] Train loss: 0.0163
2023-02-06 14:16:46 | Train | Epoch[205/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 14:16:46 | Train | Epoch[205/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 14:16:46 | Train | Epoch[205/600] Iteration[025/030] Train loss: 0.0163
2023-02-06 14:16:46 | Train | Epoch[205/600] Iteration[026/030] Train loss: 0.0163
2023-02-06 14:16:47 | Train | Epoch[205/600] Iteration[027/030] Train loss: 0.0163
2023-02-06 14:16:47 | Train | Epoch[205/600] Iteration[028/030] Train loss: 0.0164
2023-02-06 14:16:47 | Train | Epoch[205/600] Iteration[029/030] Train loss: 0.0164
2023-02-06 14:16:47 | Train | Epoch[205/600] Iteration[030/030] Train loss: 0.0164
2023-02-06 14:16:47 | Valid | Epoch[205/600] Iteration[001/008] Valid loss: 0.5592
2023-02-06 14:16:47 | Valid | Epoch[205/600] Iteration[002/008] Valid loss: 0.4485
2023-02-06 14:16:48 | Valid | Epoch[205/600] Iteration[003/008] Valid loss: 0.4535
2023-02-06 14:16:48 | Valid | Epoch[205/600] Iteration[004/008] Valid loss: 0.4452
2023-02-06 14:16:48 | Valid | Epoch[205/600] Iteration[005/008] Valid loss: 0.4547
2023-02-06 14:16:48 | Valid | Epoch[205/600] Iteration[006/008] Valid loss: 0.4461
2023-02-06 14:16:48 | Valid | Epoch[205/600] Iteration[007/008] Valid loss: 0.4653
2023-02-06 14:16:48 | Valid | Epoch[205/600] Iteration[008/008] Valid loss: 0.4855
2023-02-06 14:16:48 | Valid | Epoch[205/600] MIou: 0.886808779673663
2023-02-06 14:16:48 | Valid | Epoch[205/600] Pixel Accuracy: 0.9775721232096354
2023-02-06 14:16:48 | Valid | Epoch[205/600] Mean Pixel Accuracy: 0.9797407525285934
2023-02-06 14:16:48 | Stage | Epoch[205/600] Train loss:0.0164
2023-02-06 14:16:48 | Stage | Epoch[205/600] Valid loss:0.4855
2023-02-06 14:16:48 | Stage | Epoch[205/600] LR:0.01

2023-02-06 14:16:48 | Train | Epoch[206/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 14:16:48 | Train | Epoch[206/600] Iteration[002/030] Train loss: 0.0158
2023-02-06 14:16:49 | Train | Epoch[206/600] Iteration[003/030] Train loss: 0.0164
2023-02-06 14:16:49 | Train | Epoch[206/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 14:16:49 | Train | Epoch[206/600] Iteration[005/030] Train loss: 0.0160
2023-02-06 14:16:49 | Train | Epoch[206/600] Iteration[006/030] Train loss: 0.0159
2023-02-06 14:16:50 | Train | Epoch[206/600] Iteration[007/030] Train loss: 0.0160
2023-02-06 14:16:50 | Train | Epoch[206/600] Iteration[008/030] Train loss: 0.0160
2023-02-06 14:16:50 | Train | Epoch[206/600] Iteration[009/030] Train loss: 0.0159
2023-02-06 14:16:50 | Train | Epoch[206/600] Iteration[010/030] Train loss: 0.0160
2023-02-06 14:16:50 | Train | Epoch[206/600] Iteration[011/030] Train loss: 0.0160
2023-02-06 14:16:51 | Train | Epoch[206/600] Iteration[012/030] Train loss: 0.0160
2023-02-06 14:16:51 | Train | Epoch[206/600] Iteration[013/030] Train loss: 0.0162
2023-02-06 14:16:51 | Train | Epoch[206/600] Iteration[014/030] Train loss: 0.0162
2023-02-06 14:16:51 | Train | Epoch[206/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 14:16:52 | Train | Epoch[206/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 14:16:52 | Train | Epoch[206/600] Iteration[017/030] Train loss: 0.0162
2023-02-06 14:16:52 | Train | Epoch[206/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 14:16:52 | Train | Epoch[206/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 14:16:52 | Train | Epoch[206/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 14:16:53 | Train | Epoch[206/600] Iteration[021/030] Train loss: 0.0160
2023-02-06 14:16:53 | Train | Epoch[206/600] Iteration[022/030] Train loss: 0.0160
2023-02-06 14:16:53 | Train | Epoch[206/600] Iteration[023/030] Train loss: 0.0159
2023-02-06 14:16:53 | Train | Epoch[206/600] Iteration[024/030] Train loss: 0.0159
2023-02-06 14:16:54 | Train | Epoch[206/600] Iteration[025/030] Train loss: 0.0159
2023-02-06 14:16:54 | Train | Epoch[206/600] Iteration[026/030] Train loss: 0.0159
2023-02-06 14:16:54 | Train | Epoch[206/600] Iteration[027/030] Train loss: 0.0158
2023-02-06 14:16:54 | Train | Epoch[206/600] Iteration[028/030] Train loss: 0.0158
2023-02-06 14:16:54 | Train | Epoch[206/600] Iteration[029/030] Train loss: 0.0158
2023-02-06 14:16:55 | Train | Epoch[206/600] Iteration[030/030] Train loss: 0.0160
2023-02-06 14:16:55 | Valid | Epoch[206/600] Iteration[001/008] Valid loss: 0.1304
2023-02-06 14:16:55 | Valid | Epoch[206/600] Iteration[002/008] Valid loss: 0.1018
2023-02-06 14:16:55 | Valid | Epoch[206/600] Iteration[003/008] Valid loss: 0.0968
2023-02-06 14:16:55 | Valid | Epoch[206/600] Iteration[004/008] Valid loss: 0.0904
2023-02-06 14:16:55 | Valid | Epoch[206/600] Iteration[005/008] Valid loss: 0.0883
2023-02-06 14:16:55 | Valid | Epoch[206/600] Iteration[006/008] Valid loss: 0.0861
2023-02-06 14:16:55 | Valid | Epoch[206/600] Iteration[007/008] Valid loss: 0.0920
2023-02-06 14:16:55 | Valid | Epoch[206/600] Iteration[008/008] Valid loss: 0.0893
2023-02-06 14:16:55 | Valid | Epoch[206/600] MIou: 0.9313547640592482
2023-02-06 14:16:55 | Valid | Epoch[206/600] Pixel Accuracy: 0.9881693522135416
2023-02-06 14:16:55 | Valid | Epoch[206/600] Mean Pixel Accuracy: 0.9584155425353004
2023-02-06 14:16:55 | Stage | Epoch[206/600] Train loss:0.0160
2023-02-06 14:16:55 | Stage | Epoch[206/600] Valid loss:0.0893
2023-02-06 14:16:55 | Stage | Epoch[206/600] LR:0.01

2023-02-06 14:16:56 | Train | Epoch[207/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 14:16:56 | Train | Epoch[207/600] Iteration[002/030] Train loss: 0.0171
2023-02-06 14:16:56 | Train | Epoch[207/600] Iteration[003/030] Train loss: 0.0163
2023-02-06 14:16:56 | Train | Epoch[207/600] Iteration[004/030] Train loss: 0.0165
2023-02-06 14:16:57 | Train | Epoch[207/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 14:16:57 | Train | Epoch[207/600] Iteration[006/030] Train loss: 0.0161
2023-02-06 14:16:57 | Train | Epoch[207/600] Iteration[007/030] Train loss: 0.0160
2023-02-06 14:16:57 | Train | Epoch[207/600] Iteration[008/030] Train loss: 0.0158
2023-02-06 14:16:58 | Train | Epoch[207/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 14:16:58 | Train | Epoch[207/600] Iteration[010/030] Train loss: 0.0158
2023-02-06 14:16:58 | Train | Epoch[207/600] Iteration[011/030] Train loss: 0.0159
2023-02-06 14:16:58 | Train | Epoch[207/600] Iteration[012/030] Train loss: 0.0159
2023-02-06 14:16:58 | Train | Epoch[207/600] Iteration[013/030] Train loss: 0.0159
2023-02-06 14:16:59 | Train | Epoch[207/600] Iteration[014/030] Train loss: 0.0160
2023-02-06 14:16:59 | Train | Epoch[207/600] Iteration[015/030] Train loss: 0.0160
2023-02-06 14:16:59 | Train | Epoch[207/600] Iteration[016/030] Train loss: 0.0160
2023-02-06 14:16:59 | Train | Epoch[207/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 14:17:00 | Train | Epoch[207/600] Iteration[018/030] Train loss: 0.0161
2023-02-06 14:17:00 | Train | Epoch[207/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 14:17:00 | Train | Epoch[207/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 14:17:00 | Train | Epoch[207/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 14:17:00 | Train | Epoch[207/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 14:17:01 | Train | Epoch[207/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 14:17:01 | Train | Epoch[207/600] Iteration[024/030] Train loss: 0.0162
2023-02-06 14:17:01 | Train | Epoch[207/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 14:17:01 | Train | Epoch[207/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 14:17:02 | Train | Epoch[207/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 14:17:02 | Train | Epoch[207/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 14:17:02 | Train | Epoch[207/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 14:17:02 | Train | Epoch[207/600] Iteration[030/030] Train loss: 0.0162
2023-02-06 14:17:02 | Valid | Epoch[207/600] Iteration[001/008] Valid loss: 0.0753
2023-02-06 14:17:03 | Valid | Epoch[207/600] Iteration[002/008] Valid loss: 0.0620
2023-02-06 14:17:03 | Valid | Epoch[207/600] Iteration[003/008] Valid loss: 0.0613
2023-02-06 14:17:03 | Valid | Epoch[207/600] Iteration[004/008] Valid loss: 0.0591
2023-02-06 14:17:03 | Valid | Epoch[207/600] Iteration[005/008] Valid loss: 0.0578
2023-02-06 14:17:03 | Valid | Epoch[207/600] Iteration[006/008] Valid loss: 0.0569
2023-02-06 14:17:03 | Valid | Epoch[207/600] Iteration[007/008] Valid loss: 0.0559
2023-02-06 14:17:03 | Valid | Epoch[207/600] Iteration[008/008] Valid loss: 0.0553
2023-02-06 14:17:03 | Valid | Epoch[207/600] MIou: 0.892729365543946
2023-02-06 14:17:03 | Valid | Epoch[207/600] Pixel Accuracy: 0.9819602966308594
2023-02-06 14:17:03 | Valid | Epoch[207/600] Mean Pixel Accuracy: 0.9109491847113118
2023-02-06 14:17:03 | Stage | Epoch[207/600] Train loss:0.0162
2023-02-06 14:17:03 | Stage | Epoch[207/600] Valid loss:0.0553
2023-02-06 14:17:03 | Stage | Epoch[207/600] LR:0.01

2023-02-06 14:17:03 | Train | Epoch[208/600] Iteration[001/030] Train loss: 0.0146
2023-02-06 14:17:04 | Train | Epoch[208/600] Iteration[002/030] Train loss: 0.0145
2023-02-06 14:17:04 | Train | Epoch[208/600] Iteration[003/030] Train loss: 0.0159
2023-02-06 14:17:04 | Train | Epoch[208/600] Iteration[004/030] Train loss: 0.0153
2023-02-06 14:17:04 | Train | Epoch[208/600] Iteration[005/030] Train loss: 0.0153
2023-02-06 14:17:04 | Train | Epoch[208/600] Iteration[006/030] Train loss: 0.0152
2023-02-06 14:17:05 | Train | Epoch[208/600] Iteration[007/030] Train loss: 0.0152
2023-02-06 14:17:05 | Train | Epoch[208/600] Iteration[008/030] Train loss: 0.0152
2023-02-06 14:17:05 | Train | Epoch[208/600] Iteration[009/030] Train loss: 0.0153
2023-02-06 14:17:05 | Train | Epoch[208/600] Iteration[010/030] Train loss: 0.0152
2023-02-06 14:17:06 | Train | Epoch[208/600] Iteration[011/030] Train loss: 0.0152
2023-02-06 14:17:06 | Train | Epoch[208/600] Iteration[012/030] Train loss: 0.0153
2023-02-06 14:17:06 | Train | Epoch[208/600] Iteration[013/030] Train loss: 0.0155
2023-02-06 14:17:06 | Train | Epoch[208/600] Iteration[014/030] Train loss: 0.0157
2023-02-06 14:17:06 | Train | Epoch[208/600] Iteration[015/030] Train loss: 0.0158
2023-02-06 14:17:07 | Train | Epoch[208/600] Iteration[016/030] Train loss: 0.0158
2023-02-06 14:17:07 | Train | Epoch[208/600] Iteration[017/030] Train loss: 0.0160
2023-02-06 14:17:07 | Train | Epoch[208/600] Iteration[018/030] Train loss: 0.0160
2023-02-06 14:17:07 | Train | Epoch[208/600] Iteration[019/030] Train loss: 0.0160
2023-02-06 14:17:08 | Train | Epoch[208/600] Iteration[020/030] Train loss: 0.0161
2023-02-06 14:17:08 | Train | Epoch[208/600] Iteration[021/030] Train loss: 0.0161
2023-02-06 14:17:08 | Train | Epoch[208/600] Iteration[022/030] Train loss: 0.0161
2023-02-06 14:17:08 | Train | Epoch[208/600] Iteration[023/030] Train loss: 0.0161
2023-02-06 14:17:08 | Train | Epoch[208/600] Iteration[024/030] Train loss: 0.0161
2023-02-06 14:17:09 | Train | Epoch[208/600] Iteration[025/030] Train loss: 0.0161
2023-02-06 14:17:09 | Train | Epoch[208/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 14:17:09 | Train | Epoch[208/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 14:17:09 | Train | Epoch[208/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 14:17:10 | Train | Epoch[208/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 14:17:10 | Train | Epoch[208/600] Iteration[030/030] Train loss: 0.0163
2023-02-06 14:17:10 | Valid | Epoch[208/600] Iteration[001/008] Valid loss: 0.1119
2023-02-06 14:17:10 | Valid | Epoch[208/600] Iteration[002/008] Valid loss: 0.0886
2023-02-06 14:17:10 | Valid | Epoch[208/600] Iteration[003/008] Valid loss: 0.0808
2023-02-06 14:17:10 | Valid | Epoch[208/600] Iteration[004/008] Valid loss: 0.0752
2023-02-06 14:17:10 | Valid | Epoch[208/600] Iteration[005/008] Valid loss: 0.0732
2023-02-06 14:17:10 | Valid | Epoch[208/600] Iteration[006/008] Valid loss: 0.0693
2023-02-06 14:17:10 | Valid | Epoch[208/600] Iteration[007/008] Valid loss: 0.0691
2023-02-06 14:17:10 | Valid | Epoch[208/600] Iteration[008/008] Valid loss: 0.0703
2023-02-06 14:17:10 | Valid | Epoch[208/600] MIou: 0.9158987143371338
2023-02-06 14:17:10 | Valid | Epoch[208/600] Pixel Accuracy: 0.9855995178222656
2023-02-06 14:17:10 | Valid | Epoch[208/600] Mean Pixel Accuracy: 0.940625614037367
2023-02-06 14:17:10 | Stage | Epoch[208/600] Train loss:0.0163
2023-02-06 14:17:10 | Stage | Epoch[208/600] Valid loss:0.0703
2023-02-06 14:17:10 | Stage | Epoch[208/600] LR:0.01

2023-02-06 14:17:11 | Train | Epoch[209/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 14:17:11 | Train | Epoch[209/600] Iteration[002/030] Train loss: 0.0173
2023-02-06 14:17:11 | Train | Epoch[209/600] Iteration[003/030] Train loss: 0.0165
2023-02-06 14:17:12 | Train | Epoch[209/600] Iteration[004/030] Train loss: 0.0167
2023-02-06 14:17:12 | Train | Epoch[209/600] Iteration[005/030] Train loss: 0.0161
2023-02-06 14:17:12 | Train | Epoch[209/600] Iteration[006/030] Train loss: 0.0164
2023-02-06 14:17:12 | Train | Epoch[209/600] Iteration[007/030] Train loss: 0.0162
2023-02-06 14:17:12 | Train | Epoch[209/600] Iteration[008/030] Train loss: 0.0166
2023-02-06 14:17:13 | Train | Epoch[209/600] Iteration[009/030] Train loss: 0.0165
2023-02-06 14:17:13 | Train | Epoch[209/600] Iteration[010/030] Train loss: 0.0164
2023-02-06 14:17:13 | Train | Epoch[209/600] Iteration[011/030] Train loss: 0.0163
2023-02-06 14:17:13 | Train | Epoch[209/600] Iteration[012/030] Train loss: 0.0163
2023-02-06 14:17:14 | Train | Epoch[209/600] Iteration[013/030] Train loss: 0.0163
2023-02-06 14:17:14 | Train | Epoch[209/600] Iteration[014/030] Train loss: 0.0163
2023-02-06 14:17:14 | Train | Epoch[209/600] Iteration[015/030] Train loss: 0.0163
2023-02-06 14:17:14 | Train | Epoch[209/600] Iteration[016/030] Train loss: 0.0162
2023-02-06 14:17:14 | Train | Epoch[209/600] Iteration[017/030] Train loss: 0.0163
2023-02-06 14:17:15 | Train | Epoch[209/600] Iteration[018/030] Train loss: 0.0162
2023-02-06 14:17:15 | Train | Epoch[209/600] Iteration[019/030] Train loss: 0.0162
2023-02-06 14:17:15 | Train | Epoch[209/600] Iteration[020/030] Train loss: 0.0163
2023-02-06 14:17:15 | Train | Epoch[209/600] Iteration[021/030] Train loss: 0.0163
2023-02-06 14:17:16 | Train | Epoch[209/600] Iteration[022/030] Train loss: 0.0162
2023-02-06 14:17:16 | Train | Epoch[209/600] Iteration[023/030] Train loss: 0.0162
2023-02-06 14:17:16 | Train | Epoch[209/600] Iteration[024/030] Train loss: 0.0161
2023-02-06 14:17:16 | Train | Epoch[209/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 14:17:16 | Train | Epoch[209/600] Iteration[026/030] Train loss: 0.0162
2023-02-06 14:17:17 | Train | Epoch[209/600] Iteration[027/030] Train loss: 0.0161
2023-02-06 14:17:17 | Train | Epoch[209/600] Iteration[028/030] Train loss: 0.0161
2023-02-06 14:17:17 | Train | Epoch[209/600] Iteration[029/030] Train loss: 0.0161
2023-02-06 14:17:17 | Train | Epoch[209/600] Iteration[030/030] Train loss: 0.0161
2023-02-06 14:17:18 | Valid | Epoch[209/600] Iteration[001/008] Valid loss: 0.1767
2023-02-06 14:17:18 | Valid | Epoch[209/600] Iteration[002/008] Valid loss: 0.1302
2023-02-06 14:17:18 | Valid | Epoch[209/600] Iteration[003/008] Valid loss: 0.1304
2023-02-06 14:17:18 | Valid | Epoch[209/600] Iteration[004/008] Valid loss: 0.1202
2023-02-06 14:17:18 | Valid | Epoch[209/600] Iteration[005/008] Valid loss: 0.1216
2023-02-06 14:17:18 | Valid | Epoch[209/600] Iteration[006/008] Valid loss: 0.1175
2023-02-06 14:17:18 | Valid | Epoch[209/600] Iteration[007/008] Valid loss: 0.1268
2023-02-06 14:17:18 | Valid | Epoch[209/600] Iteration[008/008] Valid loss: 0.1226
2023-02-06 14:17:18 | Valid | Epoch[209/600] MIou: 0.929649857103936
2023-02-06 14:17:18 | Valid | Epoch[209/600] Pixel Accuracy: 0.987646738688151
2023-02-06 14:17:18 | Valid | Epoch[209/600] Mean Pixel Accuracy: 0.9655022602213668
2023-02-06 14:17:18 | Stage | Epoch[209/600] Train loss:0.0161
2023-02-06 14:17:18 | Stage | Epoch[209/600] Valid loss:0.1226
2023-02-06 14:17:18 | Stage | Epoch[209/600] LR:0.01

2023-02-06 14:17:18 | Train | Epoch[210/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 14:17:19 | Train | Epoch[210/600] Iteration[002/030] Train loss: 0.0161
2023-02-06 14:17:19 | Train | Epoch[210/600] Iteration[003/030] Train loss: 0.0160
2023-02-06 14:17:19 | Train | Epoch[210/600] Iteration[004/030] Train loss: 0.0162
2023-02-06 14:17:19 | Train | Epoch[210/600] Iteration[005/030] Train loss: 0.0158
2023-02-06 14:17:20 | Train | Epoch[210/600] Iteration[006/030] Train loss: 0.0157
2023-02-06 14:17:20 | Train | Epoch[210/600] Iteration[007/030] Train loss: 0.0157
2023-02-06 14:17:20 | Train | Epoch[210/600] Iteration[008/030] Train loss: 0.0157
2023-02-06 14:17:20 | Train | Epoch[210/600] Iteration[009/030] Train loss: 0.0158
2023-02-06 14:17:20 | Train | Epoch[210/600] Iteration[010/030] Train loss: 0.0157
2023-02-06 14:17:21 | Train | Epoch[210/600] Iteration[011/030] Train loss: 0.0157
2023-02-06 14:17:21 | Train | Epoch[210/600] Iteration[012/030] Train loss: 0.0157
2023-02-06 14:17:21 | Train | Epoch[210/600] Iteration[013/030] Train loss: 0.0157
2023-02-06 14:17:21 | Train | Epoch[210/600] Iteration[014/030] Train loss: 0.0156
2023-02-06 14:17:21 | Train | Epoch[210/600] Iteration[015/030] Train loss: 0.0155
2023-02-06 14:17:22 | Train | Epoch[210/600] Iteration[016/030] Train loss: 0.0155
2023-02-06 14:17:22 | Train | Epoch[210/600] Iteration[017/030] Train loss: 0.0156
2023-02-06 14:17:22 | Train | Epoch[210/600] Iteration[018/030] Train loss: 0.0156
2023-02-06 14:17:22 | Train | Epoch[210/600] Iteration[019/030] Train loss: 0.0156
2023-02-06 14:17:23 | Train | Epoch[210/600] Iteration[020/030] Train loss: 0.0157
2023-02-06 14:17:23 | Train | Epoch[210/600] Iteration[021/030] Train loss: 0.0158
2023-02-06 14:17:23 | Train | Epoch[210/600] Iteration[022/030] Train loss: 0.0160
2023-02-06 14:17:23 | Train | Epoch[210/600] Iteration[023/030] Train loss: 0.0160
2023-02-06 14:17:23 | Train | Epoch[210/600] Iteration[024/030] Train loss: 0.0161
2023-02-06 14:17:24 | Train | Epoch[210/600] Iteration[025/030] Train loss: 0.0160
2023-02-06 14:17:24 | Train | Epoch[210/600] Iteration[026/030] Train loss: 0.0160
2023-02-06 14:17:24 | Train | Epoch[210/600] Iteration[027/030] Train loss: 0.0160
2023-02-06 14:17:24 | Train | Epoch[210/600] Iteration[028/030] Train loss: 0.0160
2023-02-06 14:17:25 | Train | Epoch[210/600] Iteration[029/030] Train loss: 0.0160
2023-02-06 14:17:25 | Train | Epoch[210/600] Iteration[030/030] Train loss: 0.0160
2023-02-06 14:17:25 | Valid | Epoch[210/600] Iteration[001/008] Valid loss: 1.6538
2023-02-06 14:17:25 | Valid | Epoch[210/600] Iteration[002/008] Valid loss: 1.6702
2023-02-06 14:17:25 | Valid | Epoch[210/600] Iteration[003/008] Valid loss: 1.7493
2023-02-06 14:17:25 | Valid | Epoch[210/600] Iteration[004/008] Valid loss: 1.7690
2023-02-06 14:17:25 | Valid | Epoch[210/600] Iteration[005/008] Valid loss: 1.8203
2023-02-06 14:17:25 | Valid | Epoch[210/600] Iteration[006/008] Valid loss: 1.8075
2023-02-06 14:17:25 | Valid | Epoch[210/600] Iteration[007/008] Valid loss: 1.8800
2023-02-06 14:17:25 | Valid | Epoch[210/600] Iteration[008/008] Valid loss: 1.9598
2023-02-06 14:17:25 | Valid | Epoch[210/600] MIou: 0.8029477531275594
2023-02-06 14:17:25 | Valid | Epoch[210/600] Pixel Accuracy: 0.9531059265136719
2023-02-06 14:17:25 | Valid | Epoch[210/600] Mean Pixel Accuracy: 0.9726081969924716
2023-02-06 14:17:25 | Stage | Epoch[210/600] Train loss:0.0160
2023-02-06 14:17:25 | Stage | Epoch[210/600] Valid loss:1.9598
2023-02-06 14:17:25 | Stage | Epoch[210/600] LR:0.01

2023-02-06 14:17:26 | Train | Epoch[211/600] Iteration[001/030] Train loss: 0.0153
2023-02-06 14:17:26 | Train | Epoch[211/600] Iteration[002/030] Train loss: 0.0154
2023-02-06 14:17:26 | Train | Epoch[211/600] Iteration[003/030] Train loss: 0.0154
2023-02-06 14:17:27 | Train | Epoch[211/600] Iteration[004/030] Train loss: 0.0160
2023-02-06 14:17:27 | Train | Epoch[211/600] Iteration[005/030] Train loss: 0.0165
2023-02-06 14:17:27 | Train | Epoch[211/600] Iteration[006/030] Train loss: 0.0167
2023-02-06 14:17:27 | Train | Epoch[211/600] Iteration[007/030] Train loss: 0.0165
2023-02-06 14:17:27 | Train | Epoch[211/600] Iteration[008/030] Train loss: 0.0165
2023-02-06 14:17:28 | Train | Epoch[211/600] Iteration[009/030] Train loss: 0.0164
2023-02-06 14:17:28 | Train | Epoch[211/600] Iteration[010/030] Train loss: 0.0167
2023-02-06 14:17:28 | Train | Epoch[211/600] Iteration[011/030] Train loss: 0.0168
2023-02-06 14:17:28 | Train | Epoch[211/600] Iteration[012/030] Train loss: 0.0167
2023-02-06 14:17:28 | Train | Epoch[211/600] Iteration[013/030] Train loss: 0.0167
2023-02-06 14:17:29 | Train | Epoch[211/600] Iteration[014/030] Train loss: 0.0166
2023-02-06 14:17:29 | Train | Epoch[211/600] Iteration[015/030] Train loss: 0.0165
2023-02-06 14:17:29 | Train | Epoch[211/600] Iteration[016/030] Train loss: 0.0166
2023-02-06 14:17:29 | Train | Epoch[211/600] Iteration[017/030] Train loss: 0.0165
2023-02-06 14:17:30 | Train | Epoch[211/600] Iteration[018/030] Train loss: 0.0166
2023-02-06 14:17:30 | Train | Epoch[211/600] Iteration[019/030] Train loss: 0.0165
2023-02-06 14:17:30 | Train | Epoch[211/600] Iteration[020/030] Train loss: 0.0165
2023-02-06 14:17:30 | Train | Epoch[211/600] Iteration[021/030] Train loss: 0.0164
2023-02-06 14:17:30 | Train | Epoch[211/600] Iteration[022/030] Train loss: 0.0164
2023-02-06 14:17:31 | Train | Epoch[211/600] Iteration[023/030] Train loss: 0.0163
2023-02-06 14:17:31 | Train | Epoch[211/600] Iteration[024/030] Train loss: 0.0163
2023-02-06 14:17:31 | Train | Epoch[211/600] Iteration[025/030] Train loss: 0.0162
2023-02-06 14:17:31 | Train | Epoch[211/600] Iteration[026/030] Train loss: 0.0161
2023-02-06 14:17:32 | Train | Epoch[211/600] Iteration[027/030] Train loss: 0.0162
2023-02-06 14:17:32 | Train | Epoch[211/600] Iteration[028/030] Train loss: 0.0162
2023-02-06 14:17:32 | Train | Epoch[211/600] Iteration[029/030] Train loss: 0.0162
2023-02-06 14:17:32 | Train | Epoch[211/600] Iteration[030/030] Train loss: 0.0162
2023-02-06 14:17:32 | Valid | Epoch[211/600] Iteration[001/008] Valid loss: 0.1376
2023-02-06 14:17:32 | Valid | Epoch[211/600] Iteration[002/008] Valid loss: 0.1237
2023-02-06 14:17:33 | Valid | Epoch[211/600] Iteration[003/008] Valid loss: 0.1179
2023-02-06 14:17:33 | Valid | Epoch[211/600] Iteration[004/008] Valid loss: 0.1181
2023-02-06 14:17:33 | Valid | Epoch[211/600] Iteration[005/008] Valid loss: 0.1156
2023-02-06 14:17:33 | Valid | Epoch[211/600] Iteration[006/008] Valid loss: 0.1172
2023-02-06 14:17:33 | Valid | Epoch[211/600] Iteration[007/008] Valid loss: 0.1237
2023-02-06 14:17:33 | Valid | Epoch[211/600] Iteration[008/008] Valid loss: 0.1215
2023-02-06 14:17:33 | Valid | Epoch[211/600] MIou: 0.9201066897331933
2023-02-06 14:17:33 | Valid | Epoch[211/600] Pixel Accuracy: 0.9859657287597656
2023-02-06 14:17:33 | Valid | Epoch[211/600] Mean Pixel Accuracy: 0.9563039901481225
2023-02-06 14:17:33 | Stage | Epoch[211/600] Train loss:0.0162
2023-02-06 14:17:33 | Stage | Epoch[211/600] Valid loss:0.1215
2023-02-06 14:17:33 | Stage | Epoch[211/600] LR:0.01

2023-02-06 14:17:33 | Train | Epoch[212/600] Iteration[001/030] Train loss: 0.0151
2023-02-06 14:17:34 | Train | Epoch[212/600] Iteration[002/030] Train loss: 0.0143
2023-02-06 14:17:34 | Train | Epoch[212/600] Iteration[003/030] Train loss: 0.0146
2023-02-06 14:17:34 | Train | Epoch[212/600] Iteration[004/030] Train loss: 0.0148
2023-02-06 14:17:34 | Train | Epoch[212/600] Iteration[005/030] Train loss: 0.0147
2023-02-06 14:17:34 | Train | Epoch[212/600] Iteration[006/030] Train loss: 0.0148
2023-02-06 14:17:35 | Train | Epoch[212/600] Iteration[007/030] Train loss: 0.0150
2023-02-06 14:17:35 | Train | Epoch[212/600] Iteration[008/030] Train loss: 0.0152
2023-02-06 14:17:35 | Train | Epoch[212/600] Iteration[009/030] Train loss: 0.0153
2023-02-06 14:17:35 | Train | Epoch[212/600] Iteration[010/030] Train loss: 0.0152
2023-02-06 14:17:35 | Train | Epoch[212/600] Iteration[011/030] Train loss: 0.0154
2023-02-06 14:17:36 | Train | Epoch[212/600] Iteration[012/030] Train loss: 0.0156
2023-02-06 14:17:36 | Train | Epoch[212/600] Iteration[013/030] Train loss: 0.0156
2023-02-06 14:17:36 | Train | Epoch[212/600] Iteration[014/030] Train loss: 0.0155
2023-02-06 14:17:36 | Train | Epoch[212/600] Iteration[015/030] Train loss: 0.0154
2023-02-06 14:17:37 | Train | Epoch[212/600] Iteration[016/030] Train loss: 0.0154
2023-02-06 14:17:37 | Train | Epoch[212/600] Iteration[017/030] Train loss: 0.0154
2023-02-06 14:17:37 | Train | Epoch[212/600] Iteration[018/030] Train loss: 0.0153
2023-02-06 14:17:37 | Train | Epoch[212/600] Iteration[019/030] Train loss: 0.0152
2023-02-06 14:17:37 | Train | Epoch[212/600] Iteration[020/030] Train loss: 0.0152
2023-02-06 14:17:38 | Train | Epoch[212/600] Iteration[021/030] Train loss: 0.0152
2023-02-06 14:17:38 | Train | Epoch[212/600] Iteration[022/030] Train loss: 0.0152
2023-02-06 14:17:38 | Train | Epoch[212/600] Iteration[023/030] Train loss: 0.0152
2023-02-06 14:17:38 | Train | Epoch[212/600] Iteration[024/030] Train loss: 0.0152
2023-02-06 14:17:39 | Train | Epoch[212/600] Iteration[025/030] Train loss: 0.0152
2023-02-06 14:17:39 | Train | Epoch[212/600] Iteration[026/030] Train loss: 0.0153
2023-02-06 14:17:39 | Train | Epoch[212/600] Iteration[027/030] Train loss: 0.0153
2023-02-06 14:17:39 | Train | Epoch[212/600] Iteration[028/030] Train loss: 0.0153
2023-02-06 14:17:39 | Train | Epoch[212/600] Iteration[029/030] Train loss: 0.0153
2023-02-06 14:17:40 | Train | Epoch[212/600] Iteration[030/030] Train loss: 0.0154
2023-02-06 14:17:40 | Valid | Epoch[212/600] Iteration[001/008] Valid loss: 0.2664
2023-02-06 14:17:40 | Valid | Epoch[212/600] Iteration[002/008] Valid loss: 0.1996
2023-02-06 14:17:40 | Valid | Epoch[212/600] Iteration[003/008] Valid loss: 0.2065
2023-02-06 14:17:40 | Valid | Epoch[212/600] Iteration[004/008] Valid loss: 0.1965
2023-02-06 14:17:40 | Valid | Epoch[212/600] Iteration[005/008] Valid loss: 0.2086
2023-02-06 14:17:40 | Valid | Epoch[212/600] Iteration[006/008] Valid loss: 0.2047
2023-02-06 14:17:40 | Valid | Epoch[212/600] Iteration[007/008] Valid loss: 0.2225
2023-02-06 14:17:40 | Valid | Epoch[212/600] Iteration[008/008] Valid loss: 0.2220
2023-02-06 14:17:40 | Valid | Epoch[212/600] MIou: 0.9175491395213475
2023-02-06 14:17:40 | Valid | Epoch[212/600] Pixel Accuracy: 0.9848823547363281
2023-02-06 14:17:40 | Valid | Epoch[212/600] Mean Pixel Accuracy: 0.9740958889650881
2023-02-06 14:17:40 | Stage | Epoch[212/600] Train loss:0.0154
2023-02-06 14:17:40 | Stage | Epoch[212/600] Valid loss:0.2220
2023-02-06 14:17:40 | Stage | Epoch[212/600] LR:0.01

2023-02-06 14:17:41 | Train | Epoch[213/600] Iteration[001/030] Train loss: 0.0135
2023-02-06 14:17:41 | Train | Epoch[213/600] Iteration[002/030] Train loss: 0.0138
2023-02-06 14:17:41 | Train | Epoch[213/600] Iteration[003/030] Train loss: 0.0138
2023-02-06 14:17:41 | Train | Epoch[213/600] Iteration[004/030] Train loss: 0.0141
2023-02-06 14:17:42 | Train | Epoch[213/600] Iteration[005/030] Train loss: 0.0143
2023-02-06 14:17:42 | Train | Epoch[213/600] Iteration[006/030] Train loss: 0.0145
2023-02-06 14:17:42 | Train | Epoch[213/600] Iteration[007/030] Train loss: 0.0145
2023-02-06 14:17:42 | Train | Epoch[213/600] Iteration[008/030] Train loss: 0.0145
2023-02-06 14:17:43 | Train | Epoch[213/600] Iteration[009/030] Train loss: 0.0144
2023-02-06 14:17:43 | Train | Epoch[213/600] Iteration[010/030] Train loss: 0.0144
2023-02-06 14:17:43 | Train | Epoch[213/600] Iteration[011/030] Train loss: 0.0145
2023-02-06 14:17:43 | Train | Epoch[213/600] Iteration[012/030] Train loss: 0.0145
2023-02-06 14:17:43 | Train | Epoch[213/600] Iteration[013/030] Train loss: 0.0144
2023-02-06 14:17:44 | Train | Epoch[213/600] Iteration[014/030] Train loss: 0.0144
2023-02-06 14:17:44 | Train | Epoch[213/600] Iteration[015/030] Train loss: 0.0144
2023-02-06 14:17:44 | Train | Epoch[213/600] Iteration[016/030] Train loss: 0.0145
2023-02-06 14:17:44 | Train | Epoch[213/600] Iteration[017/030] Train loss: 0.0146
2023-02-06 14:17:45 | Train | Epoch[213/600] Iteration[018/030] Train loss: 0.0147
2023-02-06 14:17:45 | Train | Epoch[213/600] Iteration[019/030] Train loss: 0.0147
2023-02-06 14:17:45 | Train | Epoch[213/600] Iteration[020/030] Train loss: 0.0150
2023-02-06 14:17:45 | Train | Epoch[213/600] Iteration[021/030] Train loss: 0.0151
2023-02-06 14:17:45 | Train | Epoch[213/600] Iteration[022/030] Train loss: 0.0152
2023-02-06 14:17:46 | Train | Epoch[213/600] Iteration[023/030] Train loss: 0.0151
2023-02-06 14:17:46 | Train | Epoch[213/600] Iteration[024/030] Train loss: 0.0154
2023-02-06 14:17:46 | Train | Epoch[213/600] Iteration[025/030] Train loss: 0.0154
2023-02-06 14:17:46 | Train | Epoch[213/600] Iteration[026/030] Train loss: 0.0154
2023-02-06 14:17:47 | Train | Epoch[213/600] Iteration[027/030] Train loss: 0.0154
2023-02-06 14:17:47 | Train | Epoch[213/600] Iteration[028/030] Train loss: 0.0154
2023-02-06 14:17:47 | Train | Epoch[213/600] Iteration[029/030] Train loss: 0.0154
2023-02-06 14:17:47 | Train | Epoch[213/600] Iteration[030/030] Train loss: 0.0154
2023-02-06 14:17:48 | Valid | Epoch[213/600] Iteration[001/008] Valid loss: 0.0690
2023-02-06 14:17:48 | Valid | Epoch[213/600] Iteration[002/008] Valid loss: 0.0629
2023-02-06 14:17:48 | Valid | Epoch[213/600] Iteration[003/008] Valid loss: 0.0637
2023-02-06 14:17:48 | Valid | Epoch[213/600] Iteration[004/008] Valid loss: 0.0621
2023-02-06 14:17:48 | Valid | Epoch[213/600] Iteration[005/008] Valid loss: 0.0615
2023-02-06 14:17:48 | Valid | Epoch[213/600] Iteration[006/008] Valid loss: 0.0600
2023-02-06 14:17:48 | Valid | Epoch[213/600] Iteration[007/008] Valid loss: 0.0588
2023-02-06 14:17:48 | Valid | Epoch[213/600] Iteration[008/008] Valid loss: 0.0583
2023-02-06 14:17:48 | Valid | Epoch[213/600] MIou: 0.8849548093717654
2023-02-06 14:17:48 | Valid | Epoch[213/600] Pixel Accuracy: 0.980810801188151
2023-02-06 14:17:48 | Valid | Epoch[213/600] Mean Pixel Accuracy: 0.900350151774215
2023-02-06 14:17:48 | Stage | Epoch[213/600] Train loss:0.0154
2023-02-06 14:17:48 | Stage | Epoch[213/600] Valid loss:0.0583
2023-02-06 14:17:48 | Stage | Epoch[213/600] LR:0.01

2023-02-06 14:17:48 | Train | Epoch[214/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 14:17:49 | Train | Epoch[214/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 14:17:49 | Train | Epoch[214/600] Iteration[003/030] Train loss: 0.0158
2023-02-06 14:17:49 | Train | Epoch[214/600] Iteration[004/030] Train loss: 0.0154
2023-02-06 14:17:49 | Train | Epoch[214/600] Iteration[005/030] Train loss: 0.0151
2023-02-06 14:17:50 | Train | Epoch[214/600] Iteration[006/030] Train loss: 0.0153
2023-02-06 14:17:50 | Train | Epoch[214/600] Iteration[007/030] Train loss: 0.0152
2023-02-06 14:17:50 | Train | Epoch[214/600] Iteration[008/030] Train loss: 0.0152
2023-02-06 14:17:50 | Train | Epoch[214/600] Iteration[009/030] Train loss: 0.0151
2023-02-06 14:17:50 | Train | Epoch[214/600] Iteration[010/030] Train loss: 0.0150
2023-02-06 14:17:51 | Train | Epoch[214/600] Iteration[011/030] Train loss: 0.0150
2023-02-06 14:17:51 | Train | Epoch[214/600] Iteration[012/030] Train loss: 0.0149
2023-02-06 14:17:51 | Train | Epoch[214/600] Iteration[013/030] Train loss: 0.0151
2023-02-06 14:17:51 | Train | Epoch[214/600] Iteration[014/030] Train loss: 0.0151
2023-02-06 14:17:51 | Train | Epoch[214/600] Iteration[015/030] Train loss: 0.0151
2023-02-06 14:17:52 | Train | Epoch[214/600] Iteration[016/030] Train loss: 0.0150
2023-02-06 14:17:52 | Train | Epoch[214/600] Iteration[017/030] Train loss: 0.0150
2023-02-06 14:17:52 | Train | Epoch[214/600] Iteration[018/030] Train loss: 0.0150
2023-02-06 14:17:52 | Train | Epoch[214/600] Iteration[019/030] Train loss: 0.0151
2023-02-06 14:17:53 | Train | Epoch[214/600] Iteration[020/030] Train loss: 0.0150
2023-02-06 14:17:53 | Train | Epoch[214/600] Iteration[021/030] Train loss: 0.0151
2023-02-06 14:17:53 | Train | Epoch[214/600] Iteration[022/030] Train loss: 0.0150
2023-02-06 14:17:53 | Train | Epoch[214/600] Iteration[023/030] Train loss: 0.0151
2023-02-06 14:17:53 | Train | Epoch[214/600] Iteration[024/030] Train loss: 0.0152
2023-02-06 14:17:54 | Train | Epoch[214/600] Iteration[025/030] Train loss: 0.0152
2023-02-06 14:17:54 | Train | Epoch[214/600] Iteration[026/030] Train loss: 0.0152
2023-02-06 14:17:54 | Train | Epoch[214/600] Iteration[027/030] Train loss: 0.0152
2023-02-06 14:17:54 | Train | Epoch[214/600] Iteration[028/030] Train loss: 0.0151
2023-02-06 14:17:55 | Train | Epoch[214/600] Iteration[029/030] Train loss: 0.0152
2023-02-06 14:17:55 | Train | Epoch[214/600] Iteration[030/030] Train loss: 0.0152
2023-02-06 14:17:55 | Valid | Epoch[214/600] Iteration[001/008] Valid loss: 0.2212
2023-02-06 14:17:55 | Valid | Epoch[214/600] Iteration[002/008] Valid loss: 0.1789
2023-02-06 14:17:55 | Valid | Epoch[214/600] Iteration[003/008] Valid loss: 0.1731
2023-02-06 14:17:55 | Valid | Epoch[214/600] Iteration[004/008] Valid loss: 0.1711
2023-02-06 14:17:55 | Valid | Epoch[214/600] Iteration[005/008] Valid loss: 0.1709
2023-02-06 14:17:55 | Valid | Epoch[214/600] Iteration[006/008] Valid loss: 0.1656
2023-02-06 14:17:55 | Valid | Epoch[214/600] Iteration[007/008] Valid loss: 0.1791
2023-02-06 14:17:55 | Valid | Epoch[214/600] Iteration[008/008] Valid loss: 0.1787
2023-02-06 14:17:55 | Valid | Epoch[214/600] MIou: 0.9205344794377093
2023-02-06 14:17:55 | Valid | Epoch[214/600] Pixel Accuracy: 0.9857355753580729
2023-02-06 14:17:55 | Valid | Epoch[214/600] Mean Pixel Accuracy: 0.966899225349674
2023-02-06 14:17:55 | Stage | Epoch[214/600] Train loss:0.0152
2023-02-06 14:17:55 | Stage | Epoch[214/600] Valid loss:0.1787
2023-02-06 14:17:55 | Stage | Epoch[214/600] LR:0.01

2023-02-06 14:17:56 | Train | Epoch[215/600] Iteration[001/030] Train loss: 0.0153
2023-02-06 14:17:56 | Train | Epoch[215/600] Iteration[002/030] Train loss: 0.0149
2023-02-06 14:17:56 | Train | Epoch[215/600] Iteration[003/030] Train loss: 0.0149
2023-02-06 14:17:57 | Train | Epoch[215/600] Iteration[004/030] Train loss: 0.0148
2023-02-06 14:17:57 | Train | Epoch[215/600] Iteration[005/030] Train loss: 0.0149
2023-02-06 14:17:57 | Train | Epoch[215/600] Iteration[006/030] Train loss: 0.0145
2023-02-06 14:17:57 | Train | Epoch[215/600] Iteration[007/030] Train loss: 0.0144
2023-02-06 14:17:57 | Train | Epoch[215/600] Iteration[008/030] Train loss: 0.0145
2023-02-06 14:17:58 | Train | Epoch[215/600] Iteration[009/030] Train loss: 0.0145
2023-02-06 14:17:58 | Train | Epoch[215/600] Iteration[010/030] Train loss: 0.0145
2023-02-06 14:17:58 | Train | Epoch[215/600] Iteration[011/030] Train loss: 0.0144
2023-02-06 14:17:58 | Train | Epoch[215/600] Iteration[012/030] Train loss: 0.0144
2023-02-06 14:17:59 | Train | Epoch[215/600] Iteration[013/030] Train loss: 0.0146
2023-02-06 14:17:59 | Train | Epoch[215/600] Iteration[014/030] Train loss: 0.0146
2023-02-06 14:17:59 | Train | Epoch[215/600] Iteration[015/030] Train loss: 0.0146
2023-02-06 14:17:59 | Train | Epoch[215/600] Iteration[016/030] Train loss: 0.0147
2023-02-06 14:17:59 | Train | Epoch[215/600] Iteration[017/030] Train loss: 0.0148
2023-02-06 14:18:00 | Train | Epoch[215/600] Iteration[018/030] Train loss: 0.0148
2023-02-06 14:18:00 | Train | Epoch[215/600] Iteration[019/030] Train loss: 0.0148
2023-02-06 14:18:00 | Train | Epoch[215/600] Iteration[020/030] Train loss: 0.0148
2023-02-06 14:18:00 | Train | Epoch[215/600] Iteration[021/030] Train loss: 0.0147
2023-02-06 14:18:01 | Train | Epoch[215/600] Iteration[022/030] Train loss: 0.0148
2023-02-06 14:18:01 | Train | Epoch[215/600] Iteration[023/030] Train loss: 0.0148
2023-02-06 14:18:01 | Train | Epoch[215/600] Iteration[024/030] Train loss: 0.0148
2023-02-06 14:18:01 | Train | Epoch[215/600] Iteration[025/030] Train loss: 0.0148
2023-02-06 14:18:01 | Train | Epoch[215/600] Iteration[026/030] Train loss: 0.0148
2023-02-06 14:18:02 | Train | Epoch[215/600] Iteration[027/030] Train loss: 0.0149
2023-02-06 14:18:02 | Train | Epoch[215/600] Iteration[028/030] Train loss: 0.0149
2023-02-06 14:18:02 | Train | Epoch[215/600] Iteration[029/030] Train loss: 0.0151
2023-02-06 14:18:02 | Train | Epoch[215/600] Iteration[030/030] Train loss: 0.0150
2023-02-06 14:18:02 | Valid | Epoch[215/600] Iteration[001/008] Valid loss: 0.5020
2023-02-06 14:18:03 | Valid | Epoch[215/600] Iteration[002/008] Valid loss: 0.4276
2023-02-06 14:18:03 | Valid | Epoch[215/600] Iteration[003/008] Valid loss: 0.4553
2023-02-06 14:18:03 | Valid | Epoch[215/600] Iteration[004/008] Valid loss: 0.4621
2023-02-06 14:18:03 | Valid | Epoch[215/600] Iteration[005/008] Valid loss: 0.4806
2023-02-06 14:18:03 | Valid | Epoch[215/600] Iteration[006/008] Valid loss: 0.4792
2023-02-06 14:18:03 | Valid | Epoch[215/600] Iteration[007/008] Valid loss: 0.5039
2023-02-06 14:18:03 | Valid | Epoch[215/600] Iteration[008/008] Valid loss: 0.5332
2023-02-06 14:18:03 | Valid | Epoch[215/600] MIou: 0.8924495722717121
2023-02-06 14:18:03 | Valid | Epoch[215/600] Pixel Accuracy: 0.9790128072102865
2023-02-06 14:18:03 | Valid | Epoch[215/600] Mean Pixel Accuracy: 0.9782754060407373
2023-02-06 14:18:03 | Stage | Epoch[215/600] Train loss:0.0150
2023-02-06 14:18:03 | Stage | Epoch[215/600] Valid loss:0.5332
2023-02-06 14:18:03 | Stage | Epoch[215/600] LR:0.01

2023-02-06 14:18:03 | Train | Epoch[216/600] Iteration[001/030] Train loss: 0.0144
2023-02-06 14:18:04 | Train | Epoch[216/600] Iteration[002/030] Train loss: 0.0149
2023-02-06 14:18:04 | Train | Epoch[216/600] Iteration[003/030] Train loss: 0.0148
2023-02-06 14:18:04 | Train | Epoch[216/600] Iteration[004/030] Train loss: 0.0151
2023-02-06 14:18:04 | Train | Epoch[216/600] Iteration[005/030] Train loss: 0.0150
2023-02-06 14:18:05 | Train | Epoch[216/600] Iteration[006/030] Train loss: 0.0149
2023-02-06 14:18:05 | Train | Epoch[216/600] Iteration[007/030] Train loss: 0.0152
2023-02-06 14:18:05 | Train | Epoch[216/600] Iteration[008/030] Train loss: 0.0152
2023-02-06 14:18:05 | Train | Epoch[216/600] Iteration[009/030] Train loss: 0.0151
2023-02-06 14:18:05 | Train | Epoch[216/600] Iteration[010/030] Train loss: 0.0148
2023-02-06 14:18:06 | Train | Epoch[216/600] Iteration[011/030] Train loss: 0.0147
2023-02-06 14:18:06 | Train | Epoch[216/600] Iteration[012/030] Train loss: 0.0147
2023-02-06 14:18:06 | Train | Epoch[216/600] Iteration[013/030] Train loss: 0.0149
2023-02-06 14:18:06 | Train | Epoch[216/600] Iteration[014/030] Train loss: 0.0151
2023-02-06 14:18:06 | Train | Epoch[216/600] Iteration[015/030] Train loss: 0.0152
2023-02-06 14:18:07 | Train | Epoch[216/600] Iteration[016/030] Train loss: 0.0152
2023-02-06 14:18:07 | Train | Epoch[216/600] Iteration[017/030] Train loss: 0.0152
2023-02-06 14:18:07 | Train | Epoch[216/600] Iteration[018/030] Train loss: 0.0152
2023-02-06 14:18:07 | Train | Epoch[216/600] Iteration[019/030] Train loss: 0.0151
2023-02-06 14:18:08 | Train | Epoch[216/600] Iteration[020/030] Train loss: 0.0151
2023-02-06 14:18:08 | Train | Epoch[216/600] Iteration[021/030] Train loss: 0.0151
2023-02-06 14:18:08 | Train | Epoch[216/600] Iteration[022/030] Train loss: 0.0152
2023-02-06 14:18:08 | Train | Epoch[216/600] Iteration[023/030] Train loss: 0.0151
2023-02-06 14:18:08 | Train | Epoch[216/600] Iteration[024/030] Train loss: 0.0152
2023-02-06 14:18:09 | Train | Epoch[216/600] Iteration[025/030] Train loss: 0.0152
2023-02-06 14:18:09 | Train | Epoch[216/600] Iteration[026/030] Train loss: 0.0152
2023-02-06 14:18:09 | Train | Epoch[216/600] Iteration[027/030] Train loss: 0.0153
2023-02-06 14:18:09 | Train | Epoch[216/600] Iteration[028/030] Train loss: 0.0153
2023-02-06 14:18:10 | Train | Epoch[216/600] Iteration[029/030] Train loss: 0.0153
2023-02-06 14:18:10 | Train | Epoch[216/600] Iteration[030/030] Train loss: 0.0154
2023-02-06 14:18:10 | Valid | Epoch[216/600] Iteration[001/008] Valid loss: 0.3385
2023-02-06 14:18:10 | Valid | Epoch[216/600] Iteration[002/008] Valid loss: 0.3165
2023-02-06 14:18:10 | Valid | Epoch[216/600] Iteration[003/008] Valid loss: 0.3195
2023-02-06 14:18:10 | Valid | Epoch[216/600] Iteration[004/008] Valid loss: 0.3113
2023-02-06 14:18:10 | Valid | Epoch[216/600] Iteration[005/008] Valid loss: 0.3199
2023-02-06 14:18:10 | Valid | Epoch[216/600] Iteration[006/008] Valid loss: 0.3213
2023-02-06 14:18:10 | Valid | Epoch[216/600] Iteration[007/008] Valid loss: 0.3434
2023-02-06 14:18:10 | Valid | Epoch[216/600] Iteration[008/008] Valid loss: 0.3513
2023-02-06 14:18:10 | Valid | Epoch[216/600] MIou: 0.899956710345478
2023-02-06 14:18:10 | Valid | Epoch[216/600] Pixel Accuracy: 0.9807688395182291
2023-02-06 14:18:10 | Valid | Epoch[216/600] Mean Pixel Accuracy: 0.978910891771521
2023-02-06 14:18:10 | Stage | Epoch[216/600] Train loss:0.0154
2023-02-06 14:18:10 | Stage | Epoch[216/600] Valid loss:0.3513
2023-02-06 14:18:10 | Stage | Epoch[216/600] LR:0.01

2023-02-06 14:18:11 | Train | Epoch[217/600] Iteration[001/030] Train loss: 0.0146
2023-02-06 14:18:11 | Train | Epoch[217/600] Iteration[002/030] Train loss: 0.0147
2023-02-06 14:18:11 | Train | Epoch[217/600] Iteration[003/030] Train loss: 0.0152
2023-02-06 14:18:12 | Train | Epoch[217/600] Iteration[004/030] Train loss: 0.0158
2023-02-06 14:18:12 | Train | Epoch[217/600] Iteration[005/030] Train loss: 0.0159
2023-02-06 14:18:12 | Train | Epoch[217/600] Iteration[006/030] Train loss: 0.0158
2023-02-06 14:18:12 | Train | Epoch[217/600] Iteration[007/030] Train loss: 0.0160
2023-02-06 14:18:12 | Train | Epoch[217/600] Iteration[008/030] Train loss: 0.0158
2023-02-06 14:18:13 | Train | Epoch[217/600] Iteration[009/030] Train loss: 0.0157
2023-02-06 14:18:13 | Train | Epoch[217/600] Iteration[010/030] Train loss: 0.0156
2023-02-06 14:18:13 | Train | Epoch[217/600] Iteration[011/030] Train loss: 0.0155
2023-02-06 14:18:13 | Train | Epoch[217/600] Iteration[012/030] Train loss: 0.0155
2023-02-06 14:18:14 | Train | Epoch[217/600] Iteration[013/030] Train loss: 0.0156
2023-02-06 14:18:14 | Train | Epoch[217/600] Iteration[014/030] Train loss: 0.0156
2023-02-06 14:18:14 | Train | Epoch[217/600] Iteration[015/030] Train loss: 0.0156
2023-02-06 14:18:14 | Train | Epoch[217/600] Iteration[016/030] Train loss: 0.0155
2023-02-06 14:18:14 | Train | Epoch[217/600] Iteration[017/030] Train loss: 0.0155
2023-02-06 14:18:15 | Train | Epoch[217/600] Iteration[018/030] Train loss: 0.0156
2023-02-06 14:18:15 | Train | Epoch[217/600] Iteration[019/030] Train loss: 0.0156
2023-02-06 14:18:15 | Train | Epoch[217/600] Iteration[020/030] Train loss: 0.0156
2023-02-06 14:18:15 | Train | Epoch[217/600] Iteration[021/030] Train loss: 0.0156
2023-02-06 14:18:16 | Train | Epoch[217/600] Iteration[022/030] Train loss: 0.0155
2023-02-06 14:18:16 | Train | Epoch[217/600] Iteration[023/030] Train loss: 0.0154
2023-02-06 14:18:16 | Train | Epoch[217/600] Iteration[024/030] Train loss: 0.0155
2023-02-06 14:18:16 | Train | Epoch[217/600] Iteration[025/030] Train loss: 0.0155
2023-02-06 14:18:16 | Train | Epoch[217/600] Iteration[026/030] Train loss: 0.0155
2023-02-06 14:18:17 | Train | Epoch[217/600] Iteration[027/030] Train loss: 0.0155
2023-02-06 14:18:17 | Train | Epoch[217/600] Iteration[028/030] Train loss: 0.0155
2023-02-06 14:18:17 | Train | Epoch[217/600] Iteration[029/030] Train loss: 0.0155
2023-02-06 14:18:17 | Train | Epoch[217/600] Iteration[030/030] Train loss: 0.0155
2023-02-06 14:18:18 | Valid | Epoch[217/600] Iteration[001/008] Valid loss: 0.3588
2023-02-06 14:18:18 | Valid | Epoch[217/600] Iteration[002/008] Valid loss: 0.2863
2023-02-06 14:18:18 | Valid | Epoch[217/600] Iteration[003/008] Valid loss: 0.2808
2023-02-06 14:18:18 | Valid | Epoch[217/600] Iteration[004/008] Valid loss: 0.2779
2023-02-06 14:18:18 | Valid | Epoch[217/600] Iteration[005/008] Valid loss: 0.2860
2023-02-06 14:18:18 | Valid | Epoch[217/600] Iteration[006/008] Valid loss: 0.2785
2023-02-06 14:18:18 | Valid | Epoch[217/600] Iteration[007/008] Valid loss: 0.3028
2023-02-06 14:18:18 | Valid | Epoch[217/600] Iteration[008/008] Valid loss: 0.3030
2023-02-06 14:18:18 | Valid | Epoch[217/600] MIou: 0.9193498259166355
2023-02-06 14:18:18 | Valid | Epoch[217/600] Pixel Accuracy: 0.9851125081380209
2023-02-06 14:18:18 | Valid | Epoch[217/600] Mean Pixel Accuracy: 0.9792567254710549
2023-02-06 14:18:18 | Stage | Epoch[217/600] Train loss:0.0155
2023-02-06 14:18:18 | Stage | Epoch[217/600] Valid loss:0.3030
2023-02-06 14:18:18 | Stage | Epoch[217/600] LR:0.01

2023-02-06 14:18:18 | Train | Epoch[218/600] Iteration[001/030] Train loss: 0.0150
2023-02-06 14:18:19 | Train | Epoch[218/600] Iteration[002/030] Train loss: 0.0159
2023-02-06 14:18:19 | Train | Epoch[218/600] Iteration[003/030] Train loss: 0.0156
2023-02-06 14:18:19 | Train | Epoch[218/600] Iteration[004/030] Train loss: 0.0153
2023-02-06 14:18:19 | Train | Epoch[218/600] Iteration[005/030] Train loss: 0.0152
2023-02-06 14:18:20 | Train | Epoch[218/600] Iteration[006/030] Train loss: 0.0152
2023-02-06 14:18:20 | Train | Epoch[218/600] Iteration[007/030] Train loss: 0.0150
2023-02-06 14:18:20 | Train | Epoch[218/600] Iteration[008/030] Train loss: 0.0151
2023-02-06 14:18:20 | Train | Epoch[218/600] Iteration[009/030] Train loss: 0.0156
2023-02-06 14:18:20 | Train | Epoch[218/600] Iteration[010/030] Train loss: 0.0156
2023-02-06 14:18:21 | Train | Epoch[218/600] Iteration[011/030] Train loss: 0.0155
2023-02-06 14:18:21 | Train | Epoch[218/600] Iteration[012/030] Train loss: 0.0155
2023-02-06 14:18:21 | Train | Epoch[218/600] Iteration[013/030] Train loss: 0.0155
2023-02-06 14:18:21 | Train | Epoch[218/600] Iteration[014/030] Train loss: 0.0155
2023-02-06 14:18:22 | Train | Epoch[218/600] Iteration[015/030] Train loss: 0.0155
2023-02-06 14:18:22 | Train | Epoch[218/600] Iteration[016/030] Train loss: 0.0155
2023-02-06 14:18:22 | Train | Epoch[218/600] Iteration[017/030] Train loss: 0.0155
2023-02-06 14:18:22 | Train | Epoch[218/600] Iteration[018/030] Train loss: 0.0156
2023-02-06 14:18:22 | Train | Epoch[218/600] Iteration[019/030] Train loss: 0.0156
2023-02-06 14:18:23 | Train | Epoch[218/600] Iteration[020/030] Train loss: 0.0156
2023-02-06 14:18:23 | Train | Epoch[218/600] Iteration[021/030] Train loss: 0.0156
2023-02-06 14:18:23 | Train | Epoch[218/600] Iteration[022/030] Train loss: 0.0156
2023-02-06 14:18:23 | Train | Epoch[218/600] Iteration[023/030] Train loss: 0.0155
2023-02-06 14:18:24 | Train | Epoch[218/600] Iteration[024/030] Train loss: 0.0155
2023-02-06 14:18:24 | Train | Epoch[218/600] Iteration[025/030] Train loss: 0.0156
2023-02-06 14:18:24 | Train | Epoch[218/600] Iteration[026/030] Train loss: 0.0156
2023-02-06 14:18:24 | Train | Epoch[218/600] Iteration[027/030] Train loss: 0.0156
2023-02-06 14:18:24 | Train | Epoch[218/600] Iteration[028/030] Train loss: 0.0156
2023-02-06 14:18:25 | Train | Epoch[218/600] Iteration[029/030] Train loss: 0.0156
2023-02-06 14:18:25 | Train | Epoch[218/600] Iteration[030/030] Train loss: 0.0157
2023-02-06 14:18:25 | Valid | Epoch[218/600] Iteration[001/008] Valid loss: 0.0835
2023-02-06 14:18:25 | Valid | Epoch[218/600] Iteration[002/008] Valid loss: 0.0769
2023-02-06 14:18:25 | Valid | Epoch[218/600] Iteration[003/008] Valid loss: 0.0797
2023-02-06 14:18:25 | Valid | Epoch[218/600] Iteration[004/008] Valid loss: 0.0773
2023-02-06 14:18:25 | Valid | Epoch[218/600] Iteration[005/008] Valid loss: 0.0769
2023-02-06 14:18:25 | Valid | Epoch[218/600] Iteration[006/008] Valid loss: 0.0759
2023-02-06 14:18:25 | Valid | Epoch[218/600] Iteration[007/008] Valid loss: 0.0734
2023-02-06 14:18:25 | Valid | Epoch[218/600] Iteration[008/008] Valid loss: 0.0738
2023-02-06 14:18:26 | Valid | Epoch[218/600] MIou: 0.832185256854933
2023-02-06 14:18:26 | Valid | Epoch[218/600] Pixel Accuracy: 0.9721196492513021
2023-02-06 14:18:26 | Valid | Epoch[218/600] Mean Pixel Accuracy: 0.8498139410983778
2023-02-06 14:18:26 | Stage | Epoch[218/600] Train loss:0.0157
2023-02-06 14:18:26 | Stage | Epoch[218/600] Valid loss:0.0738
2023-02-06 14:18:26 | Stage | Epoch[218/600] LR:0.01

2023-02-06 14:18:26 | Train | Epoch[219/600] Iteration[001/030] Train loss: 0.0142
2023-02-06 14:18:26 | Train | Epoch[219/600] Iteration[002/030] Train loss: 0.0143
2023-02-06 14:18:26 | Train | Epoch[219/600] Iteration[003/030] Train loss: 0.0137
2023-02-06 14:18:27 | Train | Epoch[219/600] Iteration[004/030] Train loss: 0.0143
2023-02-06 14:18:27 | Train | Epoch[219/600] Iteration[005/030] Train loss: 0.0145
2023-02-06 14:18:27 | Train | Epoch[219/600] Iteration[006/030] Train loss: 0.0149
2023-02-06 14:18:27 | Train | Epoch[219/600] Iteration[007/030] Train loss: 0.0152
2023-02-06 14:18:28 | Train | Epoch[219/600] Iteration[008/030] Train loss: 0.0150
2023-02-06 14:18:28 | Train | Epoch[219/600] Iteration[009/030] Train loss: 0.0150
2023-02-06 14:18:28 | Train | Epoch[219/600] Iteration[010/030] Train loss: 0.0151
2023-02-06 14:18:28 | Train | Epoch[219/600] Iteration[011/030] Train loss: 0.0151
2023-02-06 14:18:28 | Train | Epoch[219/600] Iteration[012/030] Train loss: 0.0150
2023-02-06 14:18:29 | Train | Epoch[219/600] Iteration[013/030] Train loss: 0.0150
2023-02-06 14:18:29 | Train | Epoch[219/600] Iteration[014/030] Train loss: 0.0149
2023-02-06 14:18:29 | Train | Epoch[219/600] Iteration[015/030] Train loss: 0.0149
2023-02-06 14:18:29 | Train | Epoch[219/600] Iteration[016/030] Train loss: 0.0149
2023-02-06 14:18:29 | Train | Epoch[219/600] Iteration[017/030] Train loss: 0.0150
2023-02-06 14:18:30 | Train | Epoch[219/600] Iteration[018/030] Train loss: 0.0150
2023-02-06 14:18:30 | Train | Epoch[219/600] Iteration[019/030] Train loss: 0.0151
2023-02-06 14:18:30 | Train | Epoch[219/600] Iteration[020/030] Train loss: 0.0151
2023-02-06 14:18:30 | Train | Epoch[219/600] Iteration[021/030] Train loss: 0.0152
2023-02-06 14:18:31 | Train | Epoch[219/600] Iteration[022/030] Train loss: 0.0153
2023-02-06 14:18:31 | Train | Epoch[219/600] Iteration[023/030] Train loss: 0.0153
2023-02-06 14:18:31 | Train | Epoch[219/600] Iteration[024/030] Train loss: 0.0153
2023-02-06 14:18:31 | Train | Epoch[219/600] Iteration[025/030] Train loss: 0.0154
2023-02-06 14:18:31 | Train | Epoch[219/600] Iteration[026/030] Train loss: 0.0154
2023-02-06 14:18:32 | Train | Epoch[219/600] Iteration[027/030] Train loss: 0.0154
2023-02-06 14:18:32 | Train | Epoch[219/600] Iteration[028/030] Train loss: 0.0154
2023-02-06 14:18:32 | Train | Epoch[219/600] Iteration[029/030] Train loss: 0.0154
2023-02-06 14:18:32 | Train | Epoch[219/600] Iteration[030/030] Train loss: 0.0155
2023-02-06 14:18:33 | Valid | Epoch[219/600] Iteration[001/008] Valid loss: 0.0796
2023-02-06 14:18:33 | Valid | Epoch[219/600] Iteration[002/008] Valid loss: 0.0778
2023-02-06 14:18:33 | Valid | Epoch[219/600] Iteration[003/008] Valid loss: 0.0795
2023-02-06 14:18:33 | Valid | Epoch[219/600] Iteration[004/008] Valid loss: 0.0783
2023-02-06 14:18:33 | Valid | Epoch[219/600] Iteration[005/008] Valid loss: 0.0788
2023-02-06 14:18:33 | Valid | Epoch[219/600] Iteration[006/008] Valid loss: 0.0762
2023-02-06 14:18:33 | Valid | Epoch[219/600] Iteration[007/008] Valid loss: 0.0749
2023-02-06 14:18:33 | Valid | Epoch[219/600] Iteration[008/008] Valid loss: 0.0751
2023-02-06 14:18:33 | Valid | Epoch[219/600] MIou: 0.8329992504520547
2023-02-06 14:18:33 | Valid | Epoch[219/600] Pixel Accuracy: 0.9722671508789062
2023-02-06 14:18:33 | Valid | Epoch[219/600] Mean Pixel Accuracy: 0.8504149329476918
2023-02-06 14:18:33 | Stage | Epoch[219/600] Train loss:0.0155
2023-02-06 14:18:33 | Stage | Epoch[219/600] Valid loss:0.0751
2023-02-06 14:18:33 | Stage | Epoch[219/600] LR:0.01

2023-02-06 14:18:33 | Train | Epoch[220/600] Iteration[001/030] Train loss: 0.0145
2023-02-06 14:18:34 | Train | Epoch[220/600] Iteration[002/030] Train loss: 0.0136
2023-02-06 14:18:34 | Train | Epoch[220/600] Iteration[003/030] Train loss: 0.0140
2023-02-06 14:18:34 | Train | Epoch[220/600] Iteration[004/030] Train loss: 0.0143
2023-02-06 14:18:34 | Train | Epoch[220/600] Iteration[005/030] Train loss: 0.0142
2023-02-06 14:18:35 | Train | Epoch[220/600] Iteration[006/030] Train loss: 0.0145
2023-02-06 14:18:35 | Train | Epoch[220/600] Iteration[007/030] Train loss: 0.0143
2023-02-06 14:18:35 | Train | Epoch[220/600] Iteration[008/030] Train loss: 0.0144
2023-02-06 14:18:35 | Train | Epoch[220/600] Iteration[009/030] Train loss: 0.0145
2023-02-06 14:18:35 | Train | Epoch[220/600] Iteration[010/030] Train loss: 0.0146
2023-02-06 14:18:36 | Train | Epoch[220/600] Iteration[011/030] Train loss: 0.0147
2023-02-06 14:18:36 | Train | Epoch[220/600] Iteration[012/030] Train loss: 0.0149
2023-02-06 14:18:36 | Train | Epoch[220/600] Iteration[013/030] Train loss: 0.0147
2023-02-06 14:18:36 | Train | Epoch[220/600] Iteration[014/030] Train loss: 0.0148
2023-02-06 14:18:37 | Train | Epoch[220/600] Iteration[015/030] Train loss: 0.0149
2023-02-06 14:18:37 | Train | Epoch[220/600] Iteration[016/030] Train loss: 0.0148
2023-02-06 14:18:37 | Train | Epoch[220/600] Iteration[017/030] Train loss: 0.0148
2023-02-06 14:18:37 | Train | Epoch[220/600] Iteration[018/030] Train loss: 0.0149
2023-02-06 14:18:37 | Train | Epoch[220/600] Iteration[019/030] Train loss: 0.0151
2023-02-06 14:18:38 | Train | Epoch[220/600] Iteration[020/030] Train loss: 0.0150
2023-02-06 14:18:38 | Train | Epoch[220/600] Iteration[021/030] Train loss: 0.0149
2023-02-06 14:18:38 | Train | Epoch[220/600] Iteration[022/030] Train loss: 0.0149
2023-02-06 14:18:38 | Train | Epoch[220/600] Iteration[023/030] Train loss: 0.0149
2023-02-06 14:18:39 | Train | Epoch[220/600] Iteration[024/030] Train loss: 0.0149
2023-02-06 14:18:39 | Train | Epoch[220/600] Iteration[025/030] Train loss: 0.0149
2023-02-06 14:18:39 | Train | Epoch[220/600] Iteration[026/030] Train loss: 0.0149
2023-02-06 14:18:39 | Train | Epoch[220/600] Iteration[027/030] Train loss: 0.0151
2023-02-06 14:18:39 | Train | Epoch[220/600] Iteration[028/030] Train loss: 0.0151
2023-02-06 14:18:40 | Train | Epoch[220/600] Iteration[029/030] Train loss: 0.0151
2023-02-06 14:18:40 | Train | Epoch[220/600] Iteration[030/030] Train loss: 0.0152
2023-02-06 14:18:40 | Valid | Epoch[220/600] Iteration[001/008] Valid loss: 0.5348
2023-02-06 14:18:40 | Valid | Epoch[220/600] Iteration[002/008] Valid loss: 0.4815
2023-02-06 14:18:40 | Valid | Epoch[220/600] Iteration[003/008] Valid loss: 0.4977
2023-02-06 14:18:40 | Valid | Epoch[220/600] Iteration[004/008] Valid loss: 0.4929
2023-02-06 14:18:40 | Valid | Epoch[220/600] Iteration[005/008] Valid loss: 0.5160
2023-02-06 14:18:40 | Valid | Epoch[220/600] Iteration[006/008] Valid loss: 0.5095
2023-02-06 14:18:40 | Valid | Epoch[220/600] Iteration[007/008] Valid loss: 0.5486
2023-02-06 14:18:40 | Valid | Epoch[220/600] Iteration[008/008] Valid loss: 0.5607
2023-02-06 14:18:41 | Valid | Epoch[220/600] MIou: 0.8920029017456238
2023-02-06 14:18:41 | Valid | Epoch[220/600] Pixel Accuracy: 0.9788004557291666
2023-02-06 14:18:41 | Valid | Epoch[220/600] Mean Pixel Accuracy: 0.9807646224016071
2023-02-06 14:18:41 | Stage | Epoch[220/600] Train loss:0.0152
2023-02-06 14:18:41 | Stage | Epoch[220/600] Valid loss:0.5607
2023-02-06 14:18:41 | Stage | Epoch[220/600] LR:0.01

2023-02-06 14:18:41 | Train | Epoch[221/600] Iteration[001/030] Train loss: 0.0133
2023-02-06 14:18:41 | Train | Epoch[221/600] Iteration[002/030] Train loss: 0.0163
2023-02-06 14:18:41 | Train | Epoch[221/600] Iteration[003/030] Train loss: 0.0154
2023-02-06 14:18:42 | Train | Epoch[221/600] Iteration[004/030] Train loss: 0.0153
2023-02-06 14:18:42 | Train | Epoch[221/600] Iteration[005/030] Train loss: 0.0154
2023-02-06 14:18:42 | Train | Epoch[221/600] Iteration[006/030] Train loss: 0.0152
2023-02-06 14:18:42 | Train | Epoch[221/600] Iteration[007/030] Train loss: 0.0154
2023-02-06 14:18:43 | Train | Epoch[221/600] Iteration[008/030] Train loss: 0.0156
2023-02-06 14:18:43 | Train | Epoch[221/600] Iteration[009/030] Train loss: 0.0154
2023-02-06 14:18:43 | Train | Epoch[221/600] Iteration[010/030] Train loss: 0.0152
2023-02-06 14:18:43 | Train | Epoch[221/600] Iteration[011/030] Train loss: 0.0152
2023-02-06 14:18:43 | Train | Epoch[221/600] Iteration[012/030] Train loss: 0.0151
2023-02-06 14:18:44 | Train | Epoch[221/600] Iteration[013/030] Train loss: 0.0150
2023-02-06 14:18:44 | Train | Epoch[221/600] Iteration[014/030] Train loss: 0.0149
2023-02-06 14:18:44 | Train | Epoch[221/600] Iteration[015/030] Train loss: 0.0149
2023-02-06 14:18:44 | Train | Epoch[221/600] Iteration[016/030] Train loss: 0.0150
2023-02-06 14:18:44 | Train | Epoch[221/600] Iteration[017/030] Train loss: 0.0150
2023-02-06 14:18:45 | Train | Epoch[221/600] Iteration[018/030] Train loss: 0.0150
2023-02-06 14:18:45 | Train | Epoch[221/600] Iteration[019/030] Train loss: 0.0148
2023-02-06 14:18:45 | Train | Epoch[221/600] Iteration[020/030] Train loss: 0.0148
2023-02-06 14:18:45 | Train | Epoch[221/600] Iteration[021/030] Train loss: 0.0147
2023-02-06 14:18:46 | Train | Epoch[221/600] Iteration[022/030] Train loss: 0.0147
2023-02-06 14:18:46 | Train | Epoch[221/600] Iteration[023/030] Train loss: 0.0147
2023-02-06 14:18:46 | Train | Epoch[221/600] Iteration[024/030] Train loss: 0.0147
2023-02-06 14:18:46 | Train | Epoch[221/600] Iteration[025/030] Train loss: 0.0147
2023-02-06 14:18:46 | Train | Epoch[221/600] Iteration[026/030] Train loss: 0.0148
2023-02-06 14:18:47 | Train | Epoch[221/600] Iteration[027/030] Train loss: 0.0147
2023-02-06 14:18:47 | Train | Epoch[221/600] Iteration[028/030] Train loss: 0.0147
2023-02-06 14:18:47 | Train | Epoch[221/600] Iteration[029/030] Train loss: 0.0147
2023-02-06 14:18:47 | Train | Epoch[221/600] Iteration[030/030] Train loss: 0.0147
2023-02-06 14:18:48 | Valid | Epoch[221/600] Iteration[001/008] Valid loss: 0.0866
2023-02-06 14:18:48 | Valid | Epoch[221/600] Iteration[002/008] Valid loss: 0.0802
2023-02-06 14:18:48 | Valid | Epoch[221/600] Iteration[003/008] Valid loss: 0.0816
2023-02-06 14:18:48 | Valid | Epoch[221/600] Iteration[004/008] Valid loss: 0.0799
2023-02-06 14:18:48 | Valid | Epoch[221/600] Iteration[005/008] Valid loss: 0.0796
2023-02-06 14:18:48 | Valid | Epoch[221/600] Iteration[006/008] Valid loss: 0.0776
2023-02-06 14:18:48 | Valid | Epoch[221/600] Iteration[007/008] Valid loss: 0.0743
2023-02-06 14:18:48 | Valid | Epoch[221/600] Iteration[008/008] Valid loss: 0.0751
2023-02-06 14:18:48 | Valid | Epoch[221/600] MIou: 0.798588263082174
2023-02-06 14:18:48 | Valid | Epoch[221/600] Pixel Accuracy: 0.9667269388834635
2023-02-06 14:18:48 | Valid | Epoch[221/600] Mean Pixel Accuracy: 0.8168657877060538
2023-02-06 14:18:48 | Stage | Epoch[221/600] Train loss:0.0147
2023-02-06 14:18:48 | Stage | Epoch[221/600] Valid loss:0.0751
2023-02-06 14:18:48 | Stage | Epoch[221/600] LR:0.01

2023-02-06 14:18:48 | Train | Epoch[222/600] Iteration[001/030] Train loss: 0.0149
2023-02-06 14:18:49 | Train | Epoch[222/600] Iteration[002/030] Train loss: 0.0139
2023-02-06 14:18:49 | Train | Epoch[222/600] Iteration[003/030] Train loss: 0.0139
2023-02-06 14:18:49 | Train | Epoch[222/600] Iteration[004/030] Train loss: 0.0136
2023-02-06 14:18:49 | Train | Epoch[222/600] Iteration[005/030] Train loss: 0.0136
2023-02-06 14:18:50 | Train | Epoch[222/600] Iteration[006/030] Train loss: 0.0137
2023-02-06 14:18:50 | Train | Epoch[222/600] Iteration[007/030] Train loss: 0.0138
2023-02-06 14:18:50 | Train | Epoch[222/600] Iteration[008/030] Train loss: 0.0142
2023-02-06 14:18:50 | Train | Epoch[222/600] Iteration[009/030] Train loss: 0.0145
2023-02-06 14:18:50 | Train | Epoch[222/600] Iteration[010/030] Train loss: 0.0144
2023-02-06 14:18:51 | Train | Epoch[222/600] Iteration[011/030] Train loss: 0.0144
2023-02-06 14:18:51 | Train | Epoch[222/600] Iteration[012/030] Train loss: 0.0144
2023-02-06 14:18:51 | Train | Epoch[222/600] Iteration[013/030] Train loss: 0.0144
2023-02-06 14:18:51 | Train | Epoch[222/600] Iteration[014/030] Train loss: 0.0144
2023-02-06 14:18:52 | Train | Epoch[222/600] Iteration[015/030] Train loss: 0.0144
2023-02-06 14:18:52 | Train | Epoch[222/600] Iteration[016/030] Train loss: 0.0144
2023-02-06 14:18:52 | Train | Epoch[222/600] Iteration[017/030] Train loss: 0.0144
2023-02-06 14:18:52 | Train | Epoch[222/600] Iteration[018/030] Train loss: 0.0144
2023-02-06 14:18:52 | Train | Epoch[222/600] Iteration[019/030] Train loss: 0.0144
2023-02-06 14:18:53 | Train | Epoch[222/600] Iteration[020/030] Train loss: 0.0144
2023-02-06 14:18:53 | Train | Epoch[222/600] Iteration[021/030] Train loss: 0.0144
2023-02-06 14:18:53 | Train | Epoch[222/600] Iteration[022/030] Train loss: 0.0143
2023-02-06 14:18:53 | Train | Epoch[222/600] Iteration[023/030] Train loss: 0.0143
2023-02-06 14:18:54 | Train | Epoch[222/600] Iteration[024/030] Train loss: 0.0142
2023-02-06 14:18:54 | Train | Epoch[222/600] Iteration[025/030] Train loss: 0.0142
2023-02-06 14:18:54 | Train | Epoch[222/600] Iteration[026/030] Train loss: 0.0144
2023-02-06 14:18:54 | Train | Epoch[222/600] Iteration[027/030] Train loss: 0.0144
2023-02-06 14:18:54 | Train | Epoch[222/600] Iteration[028/030] Train loss: 0.0145
2023-02-06 14:18:55 | Train | Epoch[222/600] Iteration[029/030] Train loss: 0.0144
2023-02-06 14:18:55 | Train | Epoch[222/600] Iteration[030/030] Train loss: 0.0145
2023-02-06 14:18:55 | Valid | Epoch[222/600] Iteration[001/008] Valid loss: 0.0838
2023-02-06 14:18:55 | Valid | Epoch[222/600] Iteration[002/008] Valid loss: 0.0847
2023-02-06 14:18:55 | Valid | Epoch[222/600] Iteration[003/008] Valid loss: 0.0900
2023-02-06 14:18:55 | Valid | Epoch[222/600] Iteration[004/008] Valid loss: 0.0882
2023-02-06 14:18:55 | Valid | Epoch[222/600] Iteration[005/008] Valid loss: 0.0889
2023-02-06 14:18:55 | Valid | Epoch[222/600] Iteration[006/008] Valid loss: 0.0868
2023-02-06 14:18:55 | Valid | Epoch[222/600] Iteration[007/008] Valid loss: 0.0828
2023-02-06 14:18:55 | Valid | Epoch[222/600] Iteration[008/008] Valid loss: 0.0856
2023-02-06 14:18:56 | Valid | Epoch[222/600] MIou: 0.7544197238029642
2023-02-06 14:18:56 | Valid | Epoch[222/600] Pixel Accuracy: 0.9594065348307291
2023-02-06 14:18:56 | Valid | Epoch[222/600] Mean Pixel Accuracy: 0.7762957036353613
2023-02-06 14:18:56 | Stage | Epoch[222/600] Train loss:0.0145
2023-02-06 14:18:56 | Stage | Epoch[222/600] Valid loss:0.0856
2023-02-06 14:18:56 | Stage | Epoch[222/600] LR:0.01

2023-02-06 14:18:56 | Train | Epoch[223/600] Iteration[001/030] Train loss: 0.0153
2023-02-06 14:18:56 | Train | Epoch[223/600] Iteration[002/030] Train loss: 0.0149
2023-02-06 14:18:56 | Train | Epoch[223/600] Iteration[003/030] Train loss: 0.0142
2023-02-06 14:18:57 | Train | Epoch[223/600] Iteration[004/030] Train loss: 0.0141
2023-02-06 14:18:57 | Train | Epoch[223/600] Iteration[005/030] Train loss: 0.0143
2023-02-06 14:18:57 | Train | Epoch[223/600] Iteration[006/030] Train loss: 0.0143
2023-02-06 14:18:57 | Train | Epoch[223/600] Iteration[007/030] Train loss: 0.0150
2023-02-06 14:18:58 | Train | Epoch[223/600] Iteration[008/030] Train loss: 0.0150
2023-02-06 14:18:58 | Train | Epoch[223/600] Iteration[009/030] Train loss: 0.0150
2023-02-06 14:18:58 | Train | Epoch[223/600] Iteration[010/030] Train loss: 0.0149
2023-02-06 14:18:58 | Train | Epoch[223/600] Iteration[011/030] Train loss: 0.0148
2023-02-06 14:18:58 | Train | Epoch[223/600] Iteration[012/030] Train loss: 0.0147
2023-02-06 14:18:59 | Train | Epoch[223/600] Iteration[013/030] Train loss: 0.0147
2023-02-06 14:18:59 | Train | Epoch[223/600] Iteration[014/030] Train loss: 0.0146
2023-02-06 14:18:59 | Train | Epoch[223/600] Iteration[015/030] Train loss: 0.0146
2023-02-06 14:18:59 | Train | Epoch[223/600] Iteration[016/030] Train loss: 0.0145
2023-02-06 14:18:59 | Train | Epoch[223/600] Iteration[017/030] Train loss: 0.0146
2023-02-06 14:19:00 | Train | Epoch[223/600] Iteration[018/030] Train loss: 0.0146
2023-02-06 14:19:00 | Train | Epoch[223/600] Iteration[019/030] Train loss: 0.0145
2023-02-06 14:19:00 | Train | Epoch[223/600] Iteration[020/030] Train loss: 0.0145
2023-02-06 14:19:00 | Train | Epoch[223/600] Iteration[021/030] Train loss: 0.0145
2023-02-06 14:19:01 | Train | Epoch[223/600] Iteration[022/030] Train loss: 0.0146
2023-02-06 14:19:01 | Train | Epoch[223/600] Iteration[023/030] Train loss: 0.0147
2023-02-06 14:19:01 | Train | Epoch[223/600] Iteration[024/030] Train loss: 0.0146
2023-02-06 14:19:01 | Train | Epoch[223/600] Iteration[025/030] Train loss: 0.0148
2023-02-06 14:19:01 | Train | Epoch[223/600] Iteration[026/030] Train loss: 0.0147
2023-02-06 14:19:02 | Train | Epoch[223/600] Iteration[027/030] Train loss: 0.0147
2023-02-06 14:19:02 | Train | Epoch[223/600] Iteration[028/030] Train loss: 0.0148
2023-02-06 14:19:02 | Train | Epoch[223/600] Iteration[029/030] Train loss: 0.0148
2023-02-06 14:19:02 | Train | Epoch[223/600] Iteration[030/030] Train loss: 0.0147
2023-02-06 14:19:03 | Valid | Epoch[223/600] Iteration[001/008] Valid loss: 0.7077
2023-02-06 14:19:03 | Valid | Epoch[223/600] Iteration[002/008] Valid loss: 0.5910
2023-02-06 14:19:03 | Valid | Epoch[223/600] Iteration[003/008] Valid loss: 0.6094
2023-02-06 14:19:03 | Valid | Epoch[223/600] Iteration[004/008] Valid loss: 0.6055
2023-02-06 14:19:03 | Valid | Epoch[223/600] Iteration[005/008] Valid loss: 0.6322
2023-02-06 14:19:03 | Valid | Epoch[223/600] Iteration[006/008] Valid loss: 0.6556
2023-02-06 14:19:03 | Valid | Epoch[223/600] Iteration[007/008] Valid loss: 0.7059
2023-02-06 14:19:03 | Valid | Epoch[223/600] Iteration[008/008] Valid loss: 0.7114
2023-02-06 14:19:03 | Valid | Epoch[223/600] MIou: 0.8718462158239422
2023-02-06 14:19:03 | Valid | Epoch[223/600] Pixel Accuracy: 0.9737141927083334
2023-02-06 14:19:03 | Valid | Epoch[223/600] Mean Pixel Accuracy: 0.9803973959106124
2023-02-06 14:19:03 | Stage | Epoch[223/600] Train loss:0.0147
2023-02-06 14:19:03 | Stage | Epoch[223/600] Valid loss:0.7114
2023-02-06 14:19:03 | Stage | Epoch[223/600] LR:0.01

2023-02-06 14:19:03 | Train | Epoch[224/600] Iteration[001/030] Train loss: 0.0137
2023-02-06 14:19:04 | Train | Epoch[224/600] Iteration[002/030] Train loss: 0.0138
2023-02-06 14:19:04 | Train | Epoch[224/600] Iteration[003/030] Train loss: 0.0142
2023-02-06 14:19:04 | Train | Epoch[224/600] Iteration[004/030] Train loss: 0.0140
2023-02-06 14:19:04 | Train | Epoch[224/600] Iteration[005/030] Train loss: 0.0141
2023-02-06 14:19:05 | Train | Epoch[224/600] Iteration[006/030] Train loss: 0.0141
2023-02-06 14:19:05 | Train | Epoch[224/600] Iteration[007/030] Train loss: 0.0143
2023-02-06 14:19:05 | Train | Epoch[224/600] Iteration[008/030] Train loss: 0.0141
2023-02-06 14:19:05 | Train | Epoch[224/600] Iteration[009/030] Train loss: 0.0140
2023-02-06 14:19:05 | Train | Epoch[224/600] Iteration[010/030] Train loss: 0.0141
2023-02-06 14:19:06 | Train | Epoch[224/600] Iteration[011/030] Train loss: 0.0140
2023-02-06 14:19:06 | Train | Epoch[224/600] Iteration[012/030] Train loss: 0.0141
2023-02-06 14:19:06 | Train | Epoch[224/600] Iteration[013/030] Train loss: 0.0140
2023-02-06 14:19:06 | Train | Epoch[224/600] Iteration[014/030] Train loss: 0.0141
2023-02-06 14:19:07 | Train | Epoch[224/600] Iteration[015/030] Train loss: 0.0142
2023-02-06 14:19:07 | Train | Epoch[224/600] Iteration[016/030] Train loss: 0.0144
2023-02-06 14:19:07 | Train | Epoch[224/600] Iteration[017/030] Train loss: 0.0145
2023-02-06 14:19:07 | Train | Epoch[224/600] Iteration[018/030] Train loss: 0.0145
2023-02-06 14:19:07 | Train | Epoch[224/600] Iteration[019/030] Train loss: 0.0145
2023-02-06 14:19:08 | Train | Epoch[224/600] Iteration[020/030] Train loss: 0.0145
2023-02-06 14:19:08 | Train | Epoch[224/600] Iteration[021/030] Train loss: 0.0145
2023-02-06 14:19:08 | Train | Epoch[224/600] Iteration[022/030] Train loss: 0.0145
2023-02-06 14:19:08 | Train | Epoch[224/600] Iteration[023/030] Train loss: 0.0145
2023-02-06 14:19:09 | Train | Epoch[224/600] Iteration[024/030] Train loss: 0.0145
2023-02-06 14:19:09 | Train | Epoch[224/600] Iteration[025/030] Train loss: 0.0145
2023-02-06 14:19:09 | Train | Epoch[224/600] Iteration[026/030] Train loss: 0.0146
2023-02-06 14:19:09 | Train | Epoch[224/600] Iteration[027/030] Train loss: 0.0145
2023-02-06 14:19:09 | Train | Epoch[224/600] Iteration[028/030] Train loss: 0.0145
2023-02-06 14:19:10 | Train | Epoch[224/600] Iteration[029/030] Train loss: 0.0145
2023-02-06 14:19:10 | Train | Epoch[224/600] Iteration[030/030] Train loss: 0.0146
2023-02-06 14:19:10 | Valid | Epoch[224/600] Iteration[001/008] Valid loss: 0.4752
2023-02-06 14:19:10 | Valid | Epoch[224/600] Iteration[002/008] Valid loss: 0.4403
2023-02-06 14:19:10 | Valid | Epoch[224/600] Iteration[003/008] Valid loss: 0.4715
2023-02-06 14:19:10 | Valid | Epoch[224/600] Iteration[004/008] Valid loss: 0.4752
2023-02-06 14:19:10 | Valid | Epoch[224/600] Iteration[005/008] Valid loss: 0.4997
2023-02-06 14:19:10 | Valid | Epoch[224/600] Iteration[006/008] Valid loss: 0.4893
2023-02-06 14:19:10 | Valid | Epoch[224/600] Iteration[007/008] Valid loss: 0.5238
2023-02-06 14:19:10 | Valid | Epoch[224/600] Iteration[008/008] Valid loss: 0.5479
2023-02-06 14:19:11 | Valid | Epoch[224/600] MIou: 0.8917140751110382
2023-02-06 14:19:11 | Valid | Epoch[224/600] Pixel Accuracy: 0.9788220723470052
2023-02-06 14:19:11 | Valid | Epoch[224/600] Mean Pixel Accuracy: 0.97858904114503
2023-02-06 14:19:11 | Stage | Epoch[224/600] Train loss:0.0146
2023-02-06 14:19:11 | Stage | Epoch[224/600] Valid loss:0.5479
2023-02-06 14:19:11 | Stage | Epoch[224/600] LR:0.01

2023-02-06 14:19:11 | Train | Epoch[225/600] Iteration[001/030] Train loss: 0.0131
2023-02-06 14:19:11 | Train | Epoch[225/600] Iteration[002/030] Train loss: 0.0139
2023-02-06 14:19:11 | Train | Epoch[225/600] Iteration[003/030] Train loss: 0.0137
2023-02-06 14:19:12 | Train | Epoch[225/600] Iteration[004/030] Train loss: 0.0135
2023-02-06 14:19:12 | Train | Epoch[225/600] Iteration[005/030] Train loss: 0.0136
2023-02-06 14:19:12 | Train | Epoch[225/600] Iteration[006/030] Train loss: 0.0136
2023-02-06 14:19:12 | Train | Epoch[225/600] Iteration[007/030] Train loss: 0.0134
2023-02-06 14:19:13 | Train | Epoch[225/600] Iteration[008/030] Train loss: 0.0134
2023-02-06 14:19:13 | Train | Epoch[225/600] Iteration[009/030] Train loss: 0.0135
2023-02-06 14:19:13 | Train | Epoch[225/600] Iteration[010/030] Train loss: 0.0135
2023-02-06 14:19:13 | Train | Epoch[225/600] Iteration[011/030] Train loss: 0.0143
2023-02-06 14:19:13 | Train | Epoch[225/600] Iteration[012/030] Train loss: 0.0143
2023-02-06 14:19:14 | Train | Epoch[225/600] Iteration[013/030] Train loss: 0.0142
2023-02-06 14:19:14 | Train | Epoch[225/600] Iteration[014/030] Train loss: 0.0143
2023-02-06 14:19:14 | Train | Epoch[225/600] Iteration[015/030] Train loss: 0.0144
2023-02-06 14:19:14 | Train | Epoch[225/600] Iteration[016/030] Train loss: 0.0145
2023-02-06 14:19:14 | Train | Epoch[225/600] Iteration[017/030] Train loss: 0.0146
2023-02-06 14:19:15 | Train | Epoch[225/600] Iteration[018/030] Train loss: 0.0147
2023-02-06 14:19:15 | Train | Epoch[225/600] Iteration[019/030] Train loss: 0.0146
2023-02-06 14:19:15 | Train | Epoch[225/600] Iteration[020/030] Train loss: 0.0146
2023-02-06 14:19:15 | Train | Epoch[225/600] Iteration[021/030] Train loss: 0.0146
2023-02-06 14:19:16 | Train | Epoch[225/600] Iteration[022/030] Train loss: 0.0147
2023-02-06 14:19:16 | Train | Epoch[225/600] Iteration[023/030] Train loss: 0.0146
2023-02-06 14:19:16 | Train | Epoch[225/600] Iteration[024/030] Train loss: 0.0146
2023-02-06 14:19:16 | Train | Epoch[225/600] Iteration[025/030] Train loss: 0.0146
2023-02-06 14:19:16 | Train | Epoch[225/600] Iteration[026/030] Train loss: 0.0146
2023-02-06 14:19:17 | Train | Epoch[225/600] Iteration[027/030] Train loss: 0.0145
2023-02-06 14:19:17 | Train | Epoch[225/600] Iteration[028/030] Train loss: 0.0145
2023-02-06 14:19:17 | Train | Epoch[225/600] Iteration[029/030] Train loss: 0.0145
2023-02-06 14:19:17 | Train | Epoch[225/600] Iteration[030/030] Train loss: 0.0145
2023-02-06 14:19:18 | Valid | Epoch[225/600] Iteration[001/008] Valid loss: 0.1036
2023-02-06 14:19:18 | Valid | Epoch[225/600] Iteration[002/008] Valid loss: 0.0793
2023-02-06 14:19:18 | Valid | Epoch[225/600] Iteration[003/008] Valid loss: 0.0794
2023-02-06 14:19:18 | Valid | Epoch[225/600] Iteration[004/008] Valid loss: 0.0762
2023-02-06 14:19:18 | Valid | Epoch[225/600] Iteration[005/008] Valid loss: 0.0730
2023-02-06 14:19:18 | Valid | Epoch[225/600] Iteration[006/008] Valid loss: 0.0724
2023-02-06 14:19:18 | Valid | Epoch[225/600] Iteration[007/008] Valid loss: 0.0755
2023-02-06 14:19:18 | Valid | Epoch[225/600] Iteration[008/008] Valid loss: 0.0723
2023-02-06 14:19:18 | Valid | Epoch[225/600] MIou: 0.9210777769304714
2023-02-06 14:19:18 | Valid | Epoch[225/600] Pixel Accuracy: 0.9865544637044271
2023-02-06 14:19:18 | Valid | Epoch[225/600] Mean Pixel Accuracy: 0.943318934278791
2023-02-06 14:19:18 | Stage | Epoch[225/600] Train loss:0.0145
2023-02-06 14:19:18 | Stage | Epoch[225/600] Valid loss:0.0723
2023-02-06 14:19:18 | Stage | Epoch[225/600] LR:0.01

2023-02-06 14:19:19 | Train | Epoch[226/600] Iteration[001/030] Train loss: 0.0131
2023-02-06 14:19:19 | Train | Epoch[226/600] Iteration[002/030] Train loss: 0.0132
2023-02-06 14:19:19 | Train | Epoch[226/600] Iteration[003/030] Train loss: 0.0130
2023-02-06 14:19:19 | Train | Epoch[226/600] Iteration[004/030] Train loss: 0.0131
2023-02-06 14:19:19 | Train | Epoch[226/600] Iteration[005/030] Train loss: 0.0133
2023-02-06 14:19:20 | Train | Epoch[226/600] Iteration[006/030] Train loss: 0.0134
2023-02-06 14:19:20 | Train | Epoch[226/600] Iteration[007/030] Train loss: 0.0134
2023-02-06 14:19:20 | Train | Epoch[226/600] Iteration[008/030] Train loss: 0.0136
2023-02-06 14:19:20 | Train | Epoch[226/600] Iteration[009/030] Train loss: 0.0138
2023-02-06 14:19:20 | Train | Epoch[226/600] Iteration[010/030] Train loss: 0.0139
2023-02-06 14:19:21 | Train | Epoch[226/600] Iteration[011/030] Train loss: 0.0138
2023-02-06 14:19:21 | Train | Epoch[226/600] Iteration[012/030] Train loss: 0.0139
2023-02-06 14:19:21 | Train | Epoch[226/600] Iteration[013/030] Train loss: 0.0140
2023-02-06 14:19:21 | Train | Epoch[226/600] Iteration[014/030] Train loss: 0.0140
2023-02-06 14:19:22 | Train | Epoch[226/600] Iteration[015/030] Train loss: 0.0140
2023-02-06 14:19:22 | Train | Epoch[226/600] Iteration[016/030] Train loss: 0.0139
2023-02-06 14:19:22 | Train | Epoch[226/600] Iteration[017/030] Train loss: 0.0139
2023-02-06 14:19:22 | Train | Epoch[226/600] Iteration[018/030] Train loss: 0.0139
2023-02-06 14:19:22 | Train | Epoch[226/600] Iteration[019/030] Train loss: 0.0139
2023-02-06 14:19:23 | Train | Epoch[226/600] Iteration[020/030] Train loss: 0.0140
2023-02-06 14:19:23 | Train | Epoch[226/600] Iteration[021/030] Train loss: 0.0139
2023-02-06 14:19:23 | Train | Epoch[226/600] Iteration[022/030] Train loss: 0.0139
2023-02-06 14:19:23 | Train | Epoch[226/600] Iteration[023/030] Train loss: 0.0139
2023-02-06 14:19:24 | Train | Epoch[226/600] Iteration[024/030] Train loss: 0.0139
2023-02-06 14:19:24 | Train | Epoch[226/600] Iteration[025/030] Train loss: 0.0140
2023-02-06 14:19:24 | Train | Epoch[226/600] Iteration[026/030] Train loss: 0.0145
2023-02-06 14:19:24 | Train | Epoch[226/600] Iteration[027/030] Train loss: 0.0145
2023-02-06 14:19:24 | Train | Epoch[226/600] Iteration[028/030] Train loss: 0.0145
2023-02-06 14:19:25 | Train | Epoch[226/600] Iteration[029/030] Train loss: 0.0146
2023-02-06 14:19:25 | Train | Epoch[226/600] Iteration[030/030] Train loss: 0.0148
2023-02-06 14:19:25 | Valid | Epoch[226/600] Iteration[001/008] Valid loss: 1.1499
2023-02-06 14:19:25 | Valid | Epoch[226/600] Iteration[002/008] Valid loss: 1.1147
2023-02-06 14:19:25 | Valid | Epoch[226/600] Iteration[003/008] Valid loss: 1.1460
2023-02-06 14:19:25 | Valid | Epoch[226/600] Iteration[004/008] Valid loss: 1.1486
2023-02-06 14:19:25 | Valid | Epoch[226/600] Iteration[005/008] Valid loss: 1.1787
2023-02-06 14:19:25 | Valid | Epoch[226/600] Iteration[006/008] Valid loss: 1.1386
2023-02-06 14:19:25 | Valid | Epoch[226/600] Iteration[007/008] Valid loss: 1.1854
2023-02-06 14:19:25 | Valid | Epoch[226/600] Iteration[008/008] Valid loss: 1.2559
2023-02-06 14:19:26 | Valid | Epoch[226/600] MIou: 0.8472867484478894
2023-02-06 14:19:26 | Valid | Epoch[226/600] Pixel Accuracy: 0.9670308430989584
2023-02-06 14:19:26 | Valid | Epoch[226/600] Mean Pixel Accuracy: 0.9777701197268263
2023-02-06 14:19:26 | Stage | Epoch[226/600] Train loss:0.0148
2023-02-06 14:19:26 | Stage | Epoch[226/600] Valid loss:1.2559
2023-02-06 14:19:26 | Stage | Epoch[226/600] LR:0.01

2023-02-06 14:19:26 | Train | Epoch[227/600] Iteration[001/030] Train loss: 0.0155
2023-02-06 14:19:26 | Train | Epoch[227/600] Iteration[002/030] Train loss: 0.0146
2023-02-06 14:19:26 | Train | Epoch[227/600] Iteration[003/030] Train loss: 0.0143
2023-02-06 14:19:27 | Train | Epoch[227/600] Iteration[004/030] Train loss: 0.0144
2023-02-06 14:19:27 | Train | Epoch[227/600] Iteration[005/030] Train loss: 0.0145
2023-02-06 14:19:27 | Train | Epoch[227/600] Iteration[006/030] Train loss: 0.0143
2023-02-06 14:19:27 | Train | Epoch[227/600] Iteration[007/030] Train loss: 0.0141
2023-02-06 14:19:27 | Train | Epoch[227/600] Iteration[008/030] Train loss: 0.0143
2023-02-06 14:19:28 | Train | Epoch[227/600] Iteration[009/030] Train loss: 0.0142
2023-02-06 14:19:28 | Train | Epoch[227/600] Iteration[010/030] Train loss: 0.0142
2023-02-06 14:19:28 | Train | Epoch[227/600] Iteration[011/030] Train loss: 0.0141
2023-02-06 14:19:28 | Train | Epoch[227/600] Iteration[012/030] Train loss: 0.0141
2023-02-06 14:19:29 | Train | Epoch[227/600] Iteration[013/030] Train loss: 0.0142
2023-02-06 14:19:29 | Train | Epoch[227/600] Iteration[014/030] Train loss: 0.0141
2023-02-06 14:19:29 | Train | Epoch[227/600] Iteration[015/030] Train loss: 0.0141
2023-02-06 14:19:29 | Train | Epoch[227/600] Iteration[016/030] Train loss: 0.0142
2023-02-06 14:19:29 | Train | Epoch[227/600] Iteration[017/030] Train loss: 0.0144
2023-02-06 14:19:30 | Train | Epoch[227/600] Iteration[018/030] Train loss: 0.0144
2023-02-06 14:19:30 | Train | Epoch[227/600] Iteration[019/030] Train loss: 0.0144
2023-02-06 14:19:30 | Train | Epoch[227/600] Iteration[020/030] Train loss: 0.0144
2023-02-06 14:19:30 | Train | Epoch[227/600] Iteration[021/030] Train loss: 0.0144
2023-02-06 14:19:31 | Train | Epoch[227/600] Iteration[022/030] Train loss: 0.0145
2023-02-06 14:19:31 | Train | Epoch[227/600] Iteration[023/030] Train loss: 0.0144
2023-02-06 14:19:31 | Train | Epoch[227/600] Iteration[024/030] Train loss: 0.0144
2023-02-06 14:19:31 | Train | Epoch[227/600] Iteration[025/030] Train loss: 0.0144
2023-02-06 14:19:31 | Train | Epoch[227/600] Iteration[026/030] Train loss: 0.0144
2023-02-06 14:19:32 | Train | Epoch[227/600] Iteration[027/030] Train loss: 0.0144
2023-02-06 14:19:32 | Train | Epoch[227/600] Iteration[028/030] Train loss: 0.0144
2023-02-06 14:19:32 | Train | Epoch[227/600] Iteration[029/030] Train loss: 0.0145
2023-02-06 14:19:32 | Train | Epoch[227/600] Iteration[030/030] Train loss: 0.0145
2023-02-06 14:19:33 | Valid | Epoch[227/600] Iteration[001/008] Valid loss: 0.1523
2023-02-06 14:19:33 | Valid | Epoch[227/600] Iteration[002/008] Valid loss: 0.1185
2023-02-06 14:19:33 | Valid | Epoch[227/600] Iteration[003/008] Valid loss: 0.1049
2023-02-06 14:19:33 | Valid | Epoch[227/600] Iteration[004/008] Valid loss: 0.1014
2023-02-06 14:19:33 | Valid | Epoch[227/600] Iteration[005/008] Valid loss: 0.0978
2023-02-06 14:19:33 | Valid | Epoch[227/600] Iteration[006/008] Valid loss: 0.0959
2023-02-06 14:19:33 | Valid | Epoch[227/600] Iteration[007/008] Valid loss: 0.1005
2023-02-06 14:19:33 | Valid | Epoch[227/600] Iteration[008/008] Valid loss: 0.1018
2023-02-06 14:19:33 | Valid | Epoch[227/600] MIou: 0.920961972741132
2023-02-06 14:19:33 | Valid | Epoch[227/600] Pixel Accuracy: 0.9862111409505209
2023-02-06 14:19:33 | Valid | Epoch[227/600] Mean Pixel Accuracy: 0.9539660952650272
2023-02-06 14:19:33 | Stage | Epoch[227/600] Train loss:0.0145
2023-02-06 14:19:33 | Stage | Epoch[227/600] Valid loss:0.1018
2023-02-06 14:19:33 | Stage | Epoch[227/600] LR:0.01

2023-02-06 14:19:33 | Train | Epoch[228/600] Iteration[001/030] Train loss: 0.0136
2023-02-06 14:19:34 | Train | Epoch[228/600] Iteration[002/030] Train loss: 0.0135
2023-02-06 14:19:34 | Train | Epoch[228/600] Iteration[003/030] Train loss: 0.0138
2023-02-06 14:19:34 | Train | Epoch[228/600] Iteration[004/030] Train loss: 0.0136
2023-02-06 14:19:34 | Train | Epoch[228/600] Iteration[005/030] Train loss: 0.0140
2023-02-06 14:19:35 | Train | Epoch[228/600] Iteration[006/030] Train loss: 0.0141
2023-02-06 14:19:35 | Train | Epoch[228/600] Iteration[007/030] Train loss: 0.0140
2023-02-06 14:19:35 | Train | Epoch[228/600] Iteration[008/030] Train loss: 0.0139
2023-02-06 14:19:35 | Train | Epoch[228/600] Iteration[009/030] Train loss: 0.0140
2023-02-06 14:19:35 | Train | Epoch[228/600] Iteration[010/030] Train loss: 0.0139
2023-02-06 14:19:36 | Train | Epoch[228/600] Iteration[011/030] Train loss: 0.0139
2023-02-06 14:19:36 | Train | Epoch[228/600] Iteration[012/030] Train loss: 0.0139
2023-02-06 14:19:36 | Train | Epoch[228/600] Iteration[013/030] Train loss: 0.0139
2023-02-06 14:19:36 | Train | Epoch[228/600] Iteration[014/030] Train loss: 0.0139
2023-02-06 14:19:37 | Train | Epoch[228/600] Iteration[015/030] Train loss: 0.0140
2023-02-06 14:19:37 | Train | Epoch[228/600] Iteration[016/030] Train loss: 0.0140
2023-02-06 14:19:37 | Train | Epoch[228/600] Iteration[017/030] Train loss: 0.0140
2023-02-06 14:19:37 | Train | Epoch[228/600] Iteration[018/030] Train loss: 0.0141
2023-02-06 14:19:37 | Train | Epoch[228/600] Iteration[019/030] Train loss: 0.0141
2023-02-06 14:19:38 | Train | Epoch[228/600] Iteration[020/030] Train loss: 0.0140
2023-02-06 14:19:38 | Train | Epoch[228/600] Iteration[021/030] Train loss: 0.0140
2023-02-06 14:19:38 | Train | Epoch[228/600] Iteration[022/030] Train loss: 0.0140
2023-02-06 14:19:38 | Train | Epoch[228/600] Iteration[023/030] Train loss: 0.0140
2023-02-06 14:19:38 | Train | Epoch[228/600] Iteration[024/030] Train loss: 0.0141
2023-02-06 14:19:39 | Train | Epoch[228/600] Iteration[025/030] Train loss: 0.0141
2023-02-06 14:19:39 | Train | Epoch[228/600] Iteration[026/030] Train loss: 0.0141
2023-02-06 14:19:39 | Train | Epoch[228/600] Iteration[027/030] Train loss: 0.0142
2023-02-06 14:19:39 | Train | Epoch[228/600] Iteration[028/030] Train loss: 0.0142
2023-02-06 14:19:40 | Train | Epoch[228/600] Iteration[029/030] Train loss: 0.0141
2023-02-06 14:19:40 | Train | Epoch[228/600] Iteration[030/030] Train loss: 0.0145
2023-02-06 14:19:40 | Valid | Epoch[228/600] Iteration[001/008] Valid loss: 0.2468
2023-02-06 14:19:40 | Valid | Epoch[228/600] Iteration[002/008] Valid loss: 0.2017
2023-02-06 14:19:40 | Valid | Epoch[228/600] Iteration[003/008] Valid loss: 0.2064
2023-02-06 14:19:40 | Valid | Epoch[228/600] Iteration[004/008] Valid loss: 0.1927
2023-02-06 14:19:40 | Valid | Epoch[228/600] Iteration[005/008] Valid loss: 0.1996
2023-02-06 14:19:40 | Valid | Epoch[228/600] Iteration[006/008] Valid loss: 0.2011
2023-02-06 14:19:40 | Valid | Epoch[228/600] Iteration[007/008] Valid loss: 0.2163
2023-02-06 14:19:40 | Valid | Epoch[228/600] Iteration[008/008] Valid loss: 0.2154
2023-02-06 14:19:40 | Valid | Epoch[228/600] MIou: 0.9125414661877211
2023-02-06 14:19:40 | Valid | Epoch[228/600] Pixel Accuracy: 0.9838205973307291
2023-02-06 14:19:40 | Valid | Epoch[228/600] Mean Pixel Accuracy: 0.9732777043661658
2023-02-06 14:19:40 | Stage | Epoch[228/600] Train loss:0.0145
2023-02-06 14:19:40 | Stage | Epoch[228/600] Valid loss:0.2154
2023-02-06 14:19:40 | Stage | Epoch[228/600] LR:0.01

2023-02-06 14:19:41 | Train | Epoch[229/600] Iteration[001/030] Train loss: 0.0128
2023-02-06 14:19:41 | Train | Epoch[229/600] Iteration[002/030] Train loss: 0.0131
2023-02-06 14:19:41 | Train | Epoch[229/600] Iteration[003/030] Train loss: 0.0135
2023-02-06 14:19:42 | Train | Epoch[229/600] Iteration[004/030] Train loss: 0.0133
2023-02-06 14:19:42 | Train | Epoch[229/600] Iteration[005/030] Train loss: 0.0133
2023-02-06 14:19:42 | Train | Epoch[229/600] Iteration[006/030] Train loss: 0.0133
2023-02-06 14:19:42 | Train | Epoch[229/600] Iteration[007/030] Train loss: 0.0134
2023-02-06 14:19:42 | Train | Epoch[229/600] Iteration[008/030] Train loss: 0.0136
2023-02-06 14:19:43 | Train | Epoch[229/600] Iteration[009/030] Train loss: 0.0135
2023-02-06 14:19:43 | Train | Epoch[229/600] Iteration[010/030] Train loss: 0.0139
2023-02-06 14:19:43 | Train | Epoch[229/600] Iteration[011/030] Train loss: 0.0140
2023-02-06 14:19:43 | Train | Epoch[229/600] Iteration[012/030] Train loss: 0.0141
2023-02-06 14:19:44 | Train | Epoch[229/600] Iteration[013/030] Train loss: 0.0143
2023-02-06 14:19:44 | Train | Epoch[229/600] Iteration[014/030] Train loss: 0.0143
2023-02-06 14:19:44 | Train | Epoch[229/600] Iteration[015/030] Train loss: 0.0143
2023-02-06 14:19:44 | Train | Epoch[229/600] Iteration[016/030] Train loss: 0.0142
2023-02-06 14:19:44 | Train | Epoch[229/600] Iteration[017/030] Train loss: 0.0142
2023-02-06 14:19:45 | Train | Epoch[229/600] Iteration[018/030] Train loss: 0.0142
2023-02-06 14:19:45 | Train | Epoch[229/600] Iteration[019/030] Train loss: 0.0142
2023-02-06 14:19:45 | Train | Epoch[229/600] Iteration[020/030] Train loss: 0.0143
2023-02-06 14:19:45 | Train | Epoch[229/600] Iteration[021/030] Train loss: 0.0143
2023-02-06 14:19:46 | Train | Epoch[229/600] Iteration[022/030] Train loss: 0.0143
2023-02-06 14:19:46 | Train | Epoch[229/600] Iteration[023/030] Train loss: 0.0143
2023-02-06 14:19:46 | Train | Epoch[229/600] Iteration[024/030] Train loss: 0.0143
2023-02-06 14:19:46 | Train | Epoch[229/600] Iteration[025/030] Train loss: 0.0143
2023-02-06 14:19:46 | Train | Epoch[229/600] Iteration[026/030] Train loss: 0.0143
2023-02-06 14:19:47 | Train | Epoch[229/600] Iteration[027/030] Train loss: 0.0142
2023-02-06 14:19:47 | Train | Epoch[229/600] Iteration[028/030] Train loss: 0.0143
2023-02-06 14:19:47 | Train | Epoch[229/600] Iteration[029/030] Train loss: 0.0143
2023-02-06 14:19:47 | Train | Epoch[229/600] Iteration[030/030] Train loss: 0.0143
2023-02-06 14:19:48 | Valid | Epoch[229/600] Iteration[001/008] Valid loss: 0.0806
2023-02-06 14:19:48 | Valid | Epoch[229/600] Iteration[002/008] Valid loss: 0.0655
2023-02-06 14:19:48 | Valid | Epoch[229/600] Iteration[003/008] Valid loss: 0.0656
2023-02-06 14:19:48 | Valid | Epoch[229/600] Iteration[004/008] Valid loss: 0.0631
2023-02-06 14:19:48 | Valid | Epoch[229/600] Iteration[005/008] Valid loss: 0.0627
2023-02-06 14:19:48 | Valid | Epoch[229/600] Iteration[006/008] Valid loss: 0.0624
2023-02-06 14:19:48 | Valid | Epoch[229/600] Iteration[007/008] Valid loss: 0.0633
2023-02-06 14:19:48 | Valid | Epoch[229/600] Iteration[008/008] Valid loss: 0.0623
2023-02-06 14:19:48 | Valid | Epoch[229/600] MIou: 0.8944910378587579
2023-02-06 14:19:48 | Valid | Epoch[229/600] Pixel Accuracy: 0.9822896321614584
2023-02-06 14:19:48 | Valid | Epoch[229/600] Mean Pixel Accuracy: 0.9118339939025906
2023-02-06 14:19:48 | Stage | Epoch[229/600] Train loss:0.0143
2023-02-06 14:19:48 | Stage | Epoch[229/600] Valid loss:0.0623
2023-02-06 14:19:48 | Stage | Epoch[229/600] LR:0.01

2023-02-06 14:19:48 | Train | Epoch[230/600] Iteration[001/030] Train loss: 0.0133
2023-02-06 14:19:49 | Train | Epoch[230/600] Iteration[002/030] Train loss: 0.0131
2023-02-06 14:19:49 | Train | Epoch[230/600] Iteration[003/030] Train loss: 0.0135
2023-02-06 14:19:49 | Train | Epoch[230/600] Iteration[004/030] Train loss: 0.0134
2023-02-06 14:19:49 | Train | Epoch[230/600] Iteration[005/030] Train loss: 0.0135
2023-02-06 14:19:50 | Train | Epoch[230/600] Iteration[006/030] Train loss: 0.0133
2023-02-06 14:19:50 | Train | Epoch[230/600] Iteration[007/030] Train loss: 0.0135
2023-02-06 14:19:50 | Train | Epoch[230/600] Iteration[008/030] Train loss: 0.0136
2023-02-06 14:19:50 | Train | Epoch[230/600] Iteration[009/030] Train loss: 0.0138
2023-02-06 14:19:50 | Train | Epoch[230/600] Iteration[010/030] Train loss: 0.0138
2023-02-06 14:19:51 | Train | Epoch[230/600] Iteration[011/030] Train loss: 0.0137
2023-02-06 14:19:51 | Train | Epoch[230/600] Iteration[012/030] Train loss: 0.0136
2023-02-06 14:19:51 | Train | Epoch[230/600] Iteration[013/030] Train loss: 0.0136
2023-02-06 14:19:51 | Train | Epoch[230/600] Iteration[014/030] Train loss: 0.0136
2023-02-06 14:19:52 | Train | Epoch[230/600] Iteration[015/030] Train loss: 0.0136
2023-02-06 14:19:52 | Train | Epoch[230/600] Iteration[016/030] Train loss: 0.0136
2023-02-06 14:19:52 | Train | Epoch[230/600] Iteration[017/030] Train loss: 0.0136
2023-02-06 14:19:52 | Train | Epoch[230/600] Iteration[018/030] Train loss: 0.0137
2023-02-06 14:19:52 | Train | Epoch[230/600] Iteration[019/030] Train loss: 0.0138
2023-02-06 14:19:53 | Train | Epoch[230/600] Iteration[020/030] Train loss: 0.0138
2023-02-06 14:19:53 | Train | Epoch[230/600] Iteration[021/030] Train loss: 0.0138
2023-02-06 14:19:53 | Train | Epoch[230/600] Iteration[022/030] Train loss: 0.0138
2023-02-06 14:19:53 | Train | Epoch[230/600] Iteration[023/030] Train loss: 0.0139
2023-02-06 14:19:53 | Train | Epoch[230/600] Iteration[024/030] Train loss: 0.0139
2023-02-06 14:19:54 | Train | Epoch[230/600] Iteration[025/030] Train loss: 0.0139
2023-02-06 14:19:54 | Train | Epoch[230/600] Iteration[026/030] Train loss: 0.0139
2023-02-06 14:19:54 | Train | Epoch[230/600] Iteration[027/030] Train loss: 0.0139
2023-02-06 14:19:54 | Train | Epoch[230/600] Iteration[028/030] Train loss: 0.0140
2023-02-06 14:19:55 | Train | Epoch[230/600] Iteration[029/030] Train loss: 0.0139
2023-02-06 14:19:55 | Train | Epoch[230/600] Iteration[030/030] Train loss: 0.0140
2023-02-06 14:19:55 | Valid | Epoch[230/600] Iteration[001/008] Valid loss: 0.0706
2023-02-06 14:19:55 | Valid | Epoch[230/600] Iteration[002/008] Valid loss: 0.0683
2023-02-06 14:19:55 | Valid | Epoch[230/600] Iteration[003/008] Valid loss: 0.0706
2023-02-06 14:19:55 | Valid | Epoch[230/600] Iteration[004/008] Valid loss: 0.0691
2023-02-06 14:19:55 | Valid | Epoch[230/600] Iteration[005/008] Valid loss: 0.0695
2023-02-06 14:19:55 | Valid | Epoch[230/600] Iteration[006/008] Valid loss: 0.0677
2023-02-06 14:19:55 | Valid | Epoch[230/600] Iteration[007/008] Valid loss: 0.0654
2023-02-06 14:19:55 | Valid | Epoch[230/600] Iteration[008/008] Valid loss: 0.0652
2023-02-06 14:19:55 | Valid | Epoch[230/600] MIou: 0.8486495740563587
2023-02-06 14:19:55 | Valid | Epoch[230/600] Pixel Accuracy: 0.9748992919921875
2023-02-06 14:19:55 | Valid | Epoch[230/600] Mean Pixel Accuracy: 0.8644475059131329
2023-02-06 14:19:55 | Stage | Epoch[230/600] Train loss:0.0140
2023-02-06 14:19:55 | Stage | Epoch[230/600] Valid loss:0.0652
2023-02-06 14:19:55 | Stage | Epoch[230/600] LR:0.01

2023-02-06 14:19:56 | Train | Epoch[231/600] Iteration[001/030] Train loss: 0.0141
2023-02-06 14:19:56 | Train | Epoch[231/600] Iteration[002/030] Train loss: 0.0129
2023-02-06 14:19:56 | Train | Epoch[231/600] Iteration[003/030] Train loss: 0.0139
2023-02-06 14:19:57 | Train | Epoch[231/600] Iteration[004/030] Train loss: 0.0140
2023-02-06 14:19:57 | Train | Epoch[231/600] Iteration[005/030] Train loss: 0.0138
2023-02-06 14:19:57 | Train | Epoch[231/600] Iteration[006/030] Train loss: 0.0136
2023-02-06 14:19:57 | Train | Epoch[231/600] Iteration[007/030] Train loss: 0.0140
2023-02-06 14:19:57 | Train | Epoch[231/600] Iteration[008/030] Train loss: 0.0143
2023-02-06 14:19:58 | Train | Epoch[231/600] Iteration[009/030] Train loss: 0.0144
2023-02-06 14:19:58 | Train | Epoch[231/600] Iteration[010/030] Train loss: 0.0145
2023-02-06 14:19:58 | Train | Epoch[231/600] Iteration[011/030] Train loss: 0.0144
2023-02-06 14:19:58 | Train | Epoch[231/600] Iteration[012/030] Train loss: 0.0144
2023-02-06 14:19:59 | Train | Epoch[231/600] Iteration[013/030] Train loss: 0.0144
2023-02-06 14:19:59 | Train | Epoch[231/600] Iteration[014/030] Train loss: 0.0143
2023-02-06 14:19:59 | Train | Epoch[231/600] Iteration[015/030] Train loss: 0.0143
2023-02-06 14:19:59 | Train | Epoch[231/600] Iteration[016/030] Train loss: 0.0143
2023-02-06 14:19:59 | Train | Epoch[231/600] Iteration[017/030] Train loss: 0.0143
2023-02-06 14:20:00 | Train | Epoch[231/600] Iteration[018/030] Train loss: 0.0143
2023-02-06 14:20:00 | Train | Epoch[231/600] Iteration[019/030] Train loss: 0.0144
2023-02-06 14:20:00 | Train | Epoch[231/600] Iteration[020/030] Train loss: 0.0144
2023-02-06 14:20:00 | Train | Epoch[231/600] Iteration[021/030] Train loss: 0.0143
2023-02-06 14:20:01 | Train | Epoch[231/600] Iteration[022/030] Train loss: 0.0143
2023-02-06 14:20:01 | Train | Epoch[231/600] Iteration[023/030] Train loss: 0.0143
2023-02-06 14:20:01 | Train | Epoch[231/600] Iteration[024/030] Train loss: 0.0142
2023-02-06 14:20:01 | Train | Epoch[231/600] Iteration[025/030] Train loss: 0.0142
2023-02-06 14:20:01 | Train | Epoch[231/600] Iteration[026/030] Train loss: 0.0142
2023-02-06 14:20:02 | Train | Epoch[231/600] Iteration[027/030] Train loss: 0.0142
2023-02-06 14:20:02 | Train | Epoch[231/600] Iteration[028/030] Train loss: 0.0141
2023-02-06 14:20:02 | Train | Epoch[231/600] Iteration[029/030] Train loss: 0.0141
2023-02-06 14:20:02 | Train | Epoch[231/600] Iteration[030/030] Train loss: 0.0141
2023-02-06 14:20:03 | Valid | Epoch[231/600] Iteration[001/008] Valid loss: 0.0765
2023-02-06 14:20:03 | Valid | Epoch[231/600] Iteration[002/008] Valid loss: 0.0715
2023-02-06 14:20:03 | Valid | Epoch[231/600] Iteration[003/008] Valid loss: 0.0677
2023-02-06 14:20:03 | Valid | Epoch[231/600] Iteration[004/008] Valid loss: 0.0648
2023-02-06 14:20:03 | Valid | Epoch[231/600] Iteration[005/008] Valid loss: 0.0637
2023-02-06 14:20:03 | Valid | Epoch[231/600] Iteration[006/008] Valid loss: 0.0624
2023-02-06 14:20:03 | Valid | Epoch[231/600] Iteration[007/008] Valid loss: 0.0620
2023-02-06 14:20:03 | Valid | Epoch[231/600] Iteration[008/008] Valid loss: 0.0632
2023-02-06 14:20:03 | Valid | Epoch[231/600] MIou: 0.880899597867747
2023-02-06 14:20:03 | Valid | Epoch[231/600] Pixel Accuracy: 0.9800885518391927
2023-02-06 14:20:03 | Valid | Epoch[231/600] Mean Pixel Accuracy: 0.8974867293106388
2023-02-06 14:20:03 | Stage | Epoch[231/600] Train loss:0.0141
2023-02-06 14:20:03 | Stage | Epoch[231/600] Valid loss:0.0632
2023-02-06 14:20:03 | Stage | Epoch[231/600] LR:0.01

2023-02-06 14:20:03 | Train | Epoch[232/600] Iteration[001/030] Train loss: 0.0141
2023-02-06 14:20:04 | Train | Epoch[232/600] Iteration[002/030] Train loss: 0.0143
2023-02-06 14:20:04 | Train | Epoch[232/600] Iteration[003/030] Train loss: 0.0138
2023-02-06 14:20:04 | Train | Epoch[232/600] Iteration[004/030] Train loss: 0.0136
2023-02-06 14:20:04 | Train | Epoch[232/600] Iteration[005/030] Train loss: 0.0134
2023-02-06 14:20:05 | Train | Epoch[232/600] Iteration[006/030] Train loss: 0.0132
2023-02-06 14:20:05 | Train | Epoch[232/600] Iteration[007/030] Train loss: 0.0132
2023-02-06 14:20:05 | Train | Epoch[232/600] Iteration[008/030] Train loss: 0.0133
2023-02-06 14:20:05 | Train | Epoch[232/600] Iteration[009/030] Train loss: 0.0133
2023-02-06 14:20:05 | Train | Epoch[232/600] Iteration[010/030] Train loss: 0.0131
2023-02-06 14:20:06 | Train | Epoch[232/600] Iteration[011/030] Train loss: 0.0132
2023-02-06 14:20:06 | Train | Epoch[232/600] Iteration[012/030] Train loss: 0.0131
2023-02-06 14:20:06 | Train | Epoch[232/600] Iteration[013/030] Train loss: 0.0132
2023-02-06 14:20:06 | Train | Epoch[232/600] Iteration[014/030] Train loss: 0.0132
2023-02-06 14:20:07 | Train | Epoch[232/600] Iteration[015/030] Train loss: 0.0133
2023-02-06 14:20:07 | Train | Epoch[232/600] Iteration[016/030] Train loss: 0.0134
2023-02-06 14:20:07 | Train | Epoch[232/600] Iteration[017/030] Train loss: 0.0134
2023-02-06 14:20:07 | Train | Epoch[232/600] Iteration[018/030] Train loss: 0.0134
2023-02-06 14:20:07 | Train | Epoch[232/600] Iteration[019/030] Train loss: 0.0134
2023-02-06 14:20:08 | Train | Epoch[232/600] Iteration[020/030] Train loss: 0.0134
2023-02-06 14:20:08 | Train | Epoch[232/600] Iteration[021/030] Train loss: 0.0134
2023-02-06 14:20:08 | Train | Epoch[232/600] Iteration[022/030] Train loss: 0.0134
2023-02-06 14:20:08 | Train | Epoch[232/600] Iteration[023/030] Train loss: 0.0134
2023-02-06 14:20:09 | Train | Epoch[232/600] Iteration[024/030] Train loss: 0.0133
2023-02-06 14:20:09 | Train | Epoch[232/600] Iteration[025/030] Train loss: 0.0134
2023-02-06 14:20:09 | Train | Epoch[232/600] Iteration[026/030] Train loss: 0.0134
2023-02-06 14:20:09 | Train | Epoch[232/600] Iteration[027/030] Train loss: 0.0133
2023-02-06 14:20:09 | Train | Epoch[232/600] Iteration[028/030] Train loss: 0.0134
2023-02-06 14:20:10 | Train | Epoch[232/600] Iteration[029/030] Train loss: 0.0135
2023-02-06 14:20:10 | Train | Epoch[232/600] Iteration[030/030] Train loss: 0.0135
2023-02-06 14:20:10 | Valid | Epoch[232/600] Iteration[001/008] Valid loss: 0.0855
2023-02-06 14:20:10 | Valid | Epoch[232/600] Iteration[002/008] Valid loss: 0.0773
2023-02-06 14:20:10 | Valid | Epoch[232/600] Iteration[003/008] Valid loss: 0.0771
2023-02-06 14:20:10 | Valid | Epoch[232/600] Iteration[004/008] Valid loss: 0.0752
2023-02-06 14:20:10 | Valid | Epoch[232/600] Iteration[005/008] Valid loss: 0.0750
2023-02-06 14:20:10 | Valid | Epoch[232/600] Iteration[006/008] Valid loss: 0.0727
2023-02-06 14:20:10 | Valid | Epoch[232/600] Iteration[007/008] Valid loss: 0.0696
2023-02-06 14:20:10 | Valid | Epoch[232/600] Iteration[008/008] Valid loss: 0.0700
2023-02-06 14:20:11 | Valid | Epoch[232/600] MIou: 0.8271146703721002
2023-02-06 14:20:11 | Valid | Epoch[232/600] Pixel Accuracy: 0.9714673360188802
2023-02-06 14:20:11 | Valid | Epoch[232/600] Mean Pixel Accuracy: 0.842842290138253
2023-02-06 14:20:11 | Stage | Epoch[232/600] Train loss:0.0135
2023-02-06 14:20:11 | Stage | Epoch[232/600] Valid loss:0.0700
2023-02-06 14:20:11 | Stage | Epoch[232/600] LR:0.01

2023-02-06 14:20:11 | Train | Epoch[233/600] Iteration[001/030] Train loss: 0.0129
2023-02-06 14:20:11 | Train | Epoch[233/600] Iteration[002/030] Train loss: 0.0131
2023-02-06 14:20:11 | Train | Epoch[233/600] Iteration[003/030] Train loss: 0.0129
2023-02-06 14:20:12 | Train | Epoch[233/600] Iteration[004/030] Train loss: 0.0130
2023-02-06 14:20:12 | Train | Epoch[233/600] Iteration[005/030] Train loss: 0.0127
2023-02-06 14:20:12 | Train | Epoch[233/600] Iteration[006/030] Train loss: 0.0127
2023-02-06 14:20:12 | Train | Epoch[233/600] Iteration[007/030] Train loss: 0.0129
2023-02-06 14:20:13 | Train | Epoch[233/600] Iteration[008/030] Train loss: 0.0132
2023-02-06 14:20:13 | Train | Epoch[233/600] Iteration[009/030] Train loss: 0.0133
2023-02-06 14:20:13 | Train | Epoch[233/600] Iteration[010/030] Train loss: 0.0133
2023-02-06 14:20:13 | Train | Epoch[233/600] Iteration[011/030] Train loss: 0.0135
2023-02-06 14:20:13 | Train | Epoch[233/600] Iteration[012/030] Train loss: 0.0135
2023-02-06 14:20:14 | Train | Epoch[233/600] Iteration[013/030] Train loss: 0.0134
2023-02-06 14:20:14 | Train | Epoch[233/600] Iteration[014/030] Train loss: 0.0134
2023-02-06 14:20:14 | Train | Epoch[233/600] Iteration[015/030] Train loss: 0.0134
2023-02-06 14:20:14 | Train | Epoch[233/600] Iteration[016/030] Train loss: 0.0134
2023-02-06 14:20:15 | Train | Epoch[233/600] Iteration[017/030] Train loss: 0.0134
2023-02-06 14:20:15 | Train | Epoch[233/600] Iteration[018/030] Train loss: 0.0134
2023-02-06 14:20:15 | Train | Epoch[233/600] Iteration[019/030] Train loss: 0.0134
2023-02-06 14:20:15 | Train | Epoch[233/600] Iteration[020/030] Train loss: 0.0135
2023-02-06 14:20:15 | Train | Epoch[233/600] Iteration[021/030] Train loss: 0.0135
2023-02-06 14:20:16 | Train | Epoch[233/600] Iteration[022/030] Train loss: 0.0135
2023-02-06 14:20:16 | Train | Epoch[233/600] Iteration[023/030] Train loss: 0.0135
2023-02-06 14:20:16 | Train | Epoch[233/600] Iteration[024/030] Train loss: 0.0135
2023-02-06 14:20:16 | Train | Epoch[233/600] Iteration[025/030] Train loss: 0.0135
2023-02-06 14:20:17 | Train | Epoch[233/600] Iteration[026/030] Train loss: 0.0135
2023-02-06 14:20:17 | Train | Epoch[233/600] Iteration[027/030] Train loss: 0.0134
2023-02-06 14:20:17 | Train | Epoch[233/600] Iteration[028/030] Train loss: 0.0134
2023-02-06 14:20:17 | Train | Epoch[233/600] Iteration[029/030] Train loss: 0.0134
2023-02-06 14:20:17 | Train | Epoch[233/600] Iteration[030/030] Train loss: 0.0134
2023-02-06 14:20:18 | Valid | Epoch[233/600] Iteration[001/008] Valid loss: 0.1298
2023-02-06 14:20:18 | Valid | Epoch[233/600] Iteration[002/008] Valid loss: 0.1302
2023-02-06 14:20:18 | Valid | Epoch[233/600] Iteration[003/008] Valid loss: 0.1363
2023-02-06 14:20:18 | Valid | Epoch[233/600] Iteration[004/008] Valid loss: 0.1363
2023-02-06 14:20:18 | Valid | Epoch[233/600] Iteration[005/008] Valid loss: 0.1374
2023-02-06 14:20:18 | Valid | Epoch[233/600] Iteration[006/008] Valid loss: 0.1342
2023-02-06 14:20:18 | Valid | Epoch[233/600] Iteration[007/008] Valid loss: 0.1286
2023-02-06 14:20:18 | Valid | Epoch[233/600] Iteration[008/008] Valid loss: 0.1324
2023-02-06 14:20:18 | Valid | Epoch[233/600] MIou: 0.683061193858777
2023-02-06 14:20:18 | Valid | Epoch[233/600] Pixel Accuracy: 0.947638193766276
2023-02-06 14:20:18 | Valid | Epoch[233/600] Mean Pixel Accuracy: 0.7103600391669341
2023-02-06 14:20:18 | Stage | Epoch[233/600] Train loss:0.0134
2023-02-06 14:20:18 | Stage | Epoch[233/600] Valid loss:0.1324
2023-02-06 14:20:18 | Stage | Epoch[233/600] LR:0.01

2023-02-06 14:20:18 | Train | Epoch[234/600] Iteration[001/030] Train loss: 0.0126
2023-02-06 14:20:19 | Train | Epoch[234/600] Iteration[002/030] Train loss: 0.0129
2023-02-06 14:20:19 | Train | Epoch[234/600] Iteration[003/030] Train loss: 0.0130
2023-02-06 14:20:19 | Train | Epoch[234/600] Iteration[004/030] Train loss: 0.0141
2023-02-06 14:20:19 | Train | Epoch[234/600] Iteration[005/030] Train loss: 0.0137
2023-02-06 14:20:20 | Train | Epoch[234/600] Iteration[006/030] Train loss: 0.0135
2023-02-06 14:20:20 | Train | Epoch[234/600] Iteration[007/030] Train loss: 0.0133
2023-02-06 14:20:20 | Train | Epoch[234/600] Iteration[008/030] Train loss: 0.0134
2023-02-06 14:20:20 | Train | Epoch[234/600] Iteration[009/030] Train loss: 0.0135
2023-02-06 14:20:20 | Train | Epoch[234/600] Iteration[010/030] Train loss: 0.0136
2023-02-06 14:20:21 | Train | Epoch[234/600] Iteration[011/030] Train loss: 0.0135
2023-02-06 14:20:21 | Train | Epoch[234/600] Iteration[012/030] Train loss: 0.0137
2023-02-06 14:20:21 | Train | Epoch[234/600] Iteration[013/030] Train loss: 0.0137
2023-02-06 14:20:21 | Train | Epoch[234/600] Iteration[014/030] Train loss: 0.0136
2023-02-06 14:20:22 | Train | Epoch[234/600] Iteration[015/030] Train loss: 0.0138
2023-02-06 14:20:22 | Train | Epoch[234/600] Iteration[016/030] Train loss: 0.0138
2023-02-06 14:20:22 | Train | Epoch[234/600] Iteration[017/030] Train loss: 0.0138
2023-02-06 14:20:22 | Train | Epoch[234/600] Iteration[018/030] Train loss: 0.0139
2023-02-06 14:20:22 | Train | Epoch[234/600] Iteration[019/030] Train loss: 0.0139
2023-02-06 14:20:23 | Train | Epoch[234/600] Iteration[020/030] Train loss: 0.0140
2023-02-06 14:20:23 | Train | Epoch[234/600] Iteration[021/030] Train loss: 0.0140
2023-02-06 14:20:23 | Train | Epoch[234/600] Iteration[022/030] Train loss: 0.0140
2023-02-06 14:20:23 | Train | Epoch[234/600] Iteration[023/030] Train loss: 0.0140
2023-02-06 14:20:24 | Train | Epoch[234/600] Iteration[024/030] Train loss: 0.0140
2023-02-06 14:20:24 | Train | Epoch[234/600] Iteration[025/030] Train loss: 0.0141
2023-02-06 14:20:24 | Train | Epoch[234/600] Iteration[026/030] Train loss: 0.0141
2023-02-06 14:20:24 | Train | Epoch[234/600] Iteration[027/030] Train loss: 0.0141
2023-02-06 14:20:24 | Train | Epoch[234/600] Iteration[028/030] Train loss: 0.0141
2023-02-06 14:20:25 | Train | Epoch[234/600] Iteration[029/030] Train loss: 0.0141
2023-02-06 14:20:25 | Train | Epoch[234/600] Iteration[030/030] Train loss: 0.0142
2023-02-06 14:20:25 | Valid | Epoch[234/600] Iteration[001/008] Valid loss: 0.1758
2023-02-06 14:20:25 | Valid | Epoch[234/600] Iteration[002/008] Valid loss: 0.1405
2023-02-06 14:20:25 | Valid | Epoch[234/600] Iteration[003/008] Valid loss: 0.1289
2023-02-06 14:20:25 | Valid | Epoch[234/600] Iteration[004/008] Valid loss: 0.1208
2023-02-06 14:20:25 | Valid | Epoch[234/600] Iteration[005/008] Valid loss: 0.1183
2023-02-06 14:20:25 | Valid | Epoch[234/600] Iteration[006/008] Valid loss: 0.1156
2023-02-06 14:20:25 | Valid | Epoch[234/600] Iteration[007/008] Valid loss: 0.1204
2023-02-06 14:20:25 | Valid | Epoch[234/600] Iteration[008/008] Valid loss: 0.1206
2023-02-06 14:20:26 | Valid | Epoch[234/600] MIou: 0.9298571814922637
2023-02-06 14:20:26 | Valid | Epoch[234/600] Pixel Accuracy: 0.9878323872884115
2023-02-06 14:20:26 | Valid | Epoch[234/600] Mean Pixel Accuracy: 0.9599866428500885
2023-02-06 14:20:26 | Stage | Epoch[234/600] Train loss:0.0142
2023-02-06 14:20:26 | Stage | Epoch[234/600] Valid loss:0.1206
2023-02-06 14:20:26 | Stage | Epoch[234/600] LR:0.01

2023-02-06 14:20:26 | Train | Epoch[235/600] Iteration[001/030] Train loss: 0.0146
2023-02-06 14:20:26 | Train | Epoch[235/600] Iteration[002/030] Train loss: 0.0138
2023-02-06 14:20:26 | Train | Epoch[235/600] Iteration[003/030] Train loss: 0.0143
2023-02-06 14:20:27 | Train | Epoch[235/600] Iteration[004/030] Train loss: 0.0142
2023-02-06 14:20:27 | Train | Epoch[235/600] Iteration[005/030] Train loss: 0.0140
2023-02-06 14:20:27 | Train | Epoch[235/600] Iteration[006/030] Train loss: 0.0139
2023-02-06 14:20:27 | Train | Epoch[235/600] Iteration[007/030] Train loss: 0.0138
2023-02-06 14:20:28 | Train | Epoch[235/600] Iteration[008/030] Train loss: 0.0137
2023-02-06 14:20:28 | Train | Epoch[235/600] Iteration[009/030] Train loss: 0.0137
2023-02-06 14:20:28 | Train | Epoch[235/600] Iteration[010/030] Train loss: 0.0137
2023-02-06 14:20:28 | Train | Epoch[235/600] Iteration[011/030] Train loss: 0.0139
2023-02-06 14:20:28 | Train | Epoch[235/600] Iteration[012/030] Train loss: 0.0139
2023-02-06 14:20:29 | Train | Epoch[235/600] Iteration[013/030] Train loss: 0.0139
2023-02-06 14:20:29 | Train | Epoch[235/600] Iteration[014/030] Train loss: 0.0138
2023-02-06 14:20:29 | Train | Epoch[235/600] Iteration[015/030] Train loss: 0.0139
2023-02-06 14:20:29 | Train | Epoch[235/600] Iteration[016/030] Train loss: 0.0138
2023-02-06 14:20:30 | Train | Epoch[235/600] Iteration[017/030] Train loss: 0.0138
2023-02-06 14:20:30 | Train | Epoch[235/600] Iteration[018/030] Train loss: 0.0139
2023-02-06 14:20:30 | Train | Epoch[235/600] Iteration[019/030] Train loss: 0.0138
2023-02-06 14:20:30 | Train | Epoch[235/600] Iteration[020/030] Train loss: 0.0138
2023-02-06 14:20:30 | Train | Epoch[235/600] Iteration[021/030] Train loss: 0.0137
2023-02-06 14:20:31 | Train | Epoch[235/600] Iteration[022/030] Train loss: 0.0138
2023-02-06 14:20:31 | Train | Epoch[235/600] Iteration[023/030] Train loss: 0.0137
2023-02-06 14:20:31 | Train | Epoch[235/600] Iteration[024/030] Train loss: 0.0137
2023-02-06 14:20:31 | Train | Epoch[235/600] Iteration[025/030] Train loss: 0.0137
2023-02-06 14:20:31 | Train | Epoch[235/600] Iteration[026/030] Train loss: 0.0137
2023-02-06 14:20:32 | Train | Epoch[235/600] Iteration[027/030] Train loss: 0.0138
2023-02-06 14:20:32 | Train | Epoch[235/600] Iteration[028/030] Train loss: 0.0137
2023-02-06 14:20:32 | Train | Epoch[235/600] Iteration[029/030] Train loss: 0.0138
2023-02-06 14:20:32 | Train | Epoch[235/600] Iteration[030/030] Train loss: 0.0138
2023-02-06 14:20:33 | Valid | Epoch[235/600] Iteration[001/008] Valid loss: 0.6615
2023-02-06 14:20:33 | Valid | Epoch[235/600] Iteration[002/008] Valid loss: 0.6052
2023-02-06 14:20:33 | Valid | Epoch[235/600] Iteration[003/008] Valid loss: 0.6177
2023-02-06 14:20:33 | Valid | Epoch[235/600] Iteration[004/008] Valid loss: 0.6146
2023-02-06 14:20:33 | Valid | Epoch[235/600] Iteration[005/008] Valid loss: 0.6333
2023-02-06 14:20:33 | Valid | Epoch[235/600] Iteration[006/008] Valid loss: 0.6190
2023-02-06 14:20:33 | Valid | Epoch[235/600] Iteration[007/008] Valid loss: 0.6603
2023-02-06 14:20:33 | Valid | Epoch[235/600] Iteration[008/008] Valid loss: 0.6953
2023-02-06 14:20:33 | Valid | Epoch[235/600] MIou: 0.8868179453551106
2023-02-06 14:20:33 | Valid | Epoch[235/600] Pixel Accuracy: 0.9775581359863281
2023-02-06 14:20:33 | Valid | Epoch[235/600] Mean Pixel Accuracy: 0.9801071523733358
2023-02-06 14:20:33 | Stage | Epoch[235/600] Train loss:0.0138
2023-02-06 14:20:33 | Stage | Epoch[235/600] Valid loss:0.6953
2023-02-06 14:20:33 | Stage | Epoch[235/600] LR:0.01

2023-02-06 14:20:33 | Train | Epoch[236/600] Iteration[001/030] Train loss: 0.0135
2023-02-06 14:20:34 | Train | Epoch[236/600] Iteration[002/030] Train loss: 0.0133
2023-02-06 14:20:34 | Train | Epoch[236/600] Iteration[003/030] Train loss: 0.0146
2023-02-06 14:20:34 | Train | Epoch[236/600] Iteration[004/030] Train loss: 0.0142
2023-02-06 14:20:34 | Train | Epoch[236/600] Iteration[005/030] Train loss: 0.0139
2023-02-06 14:20:35 | Train | Epoch[236/600] Iteration[006/030] Train loss: 0.0136
2023-02-06 14:20:35 | Train | Epoch[236/600] Iteration[007/030] Train loss: 0.0135
2023-02-06 14:20:35 | Train | Epoch[236/600] Iteration[008/030] Train loss: 0.0135
2023-02-06 14:20:35 | Train | Epoch[236/600] Iteration[009/030] Train loss: 0.0134
2023-02-06 14:20:35 | Train | Epoch[236/600] Iteration[010/030] Train loss: 0.0134
2023-02-06 14:20:36 | Train | Epoch[236/600] Iteration[011/030] Train loss: 0.0135
2023-02-06 14:20:36 | Train | Epoch[236/600] Iteration[012/030] Train loss: 0.0135
2023-02-06 14:20:36 | Train | Epoch[236/600] Iteration[013/030] Train loss: 0.0136
2023-02-06 14:20:36 | Train | Epoch[236/600] Iteration[014/030] Train loss: 0.0136
2023-02-06 14:20:37 | Train | Epoch[236/600] Iteration[015/030] Train loss: 0.0136
2023-02-06 14:20:37 | Train | Epoch[236/600] Iteration[016/030] Train loss: 0.0135
2023-02-06 14:20:37 | Train | Epoch[236/600] Iteration[017/030] Train loss: 0.0134
2023-02-06 14:20:37 | Train | Epoch[236/600] Iteration[018/030] Train loss: 0.0134
2023-02-06 14:20:37 | Train | Epoch[236/600] Iteration[019/030] Train loss: 0.0134
2023-02-06 14:20:38 | Train | Epoch[236/600] Iteration[020/030] Train loss: 0.0134
2023-02-06 14:20:38 | Train | Epoch[236/600] Iteration[021/030] Train loss: 0.0135
2023-02-06 14:20:38 | Train | Epoch[236/600] Iteration[022/030] Train loss: 0.0135
2023-02-06 14:20:38 | Train | Epoch[236/600] Iteration[023/030] Train loss: 0.0136
2023-02-06 14:20:38 | Train | Epoch[236/600] Iteration[024/030] Train loss: 0.0135
2023-02-06 14:20:39 | Train | Epoch[236/600] Iteration[025/030] Train loss: 0.0136
2023-02-06 14:20:39 | Train | Epoch[236/600] Iteration[026/030] Train loss: 0.0136
2023-02-06 14:20:39 | Train | Epoch[236/600] Iteration[027/030] Train loss: 0.0136
2023-02-06 14:20:39 | Train | Epoch[236/600] Iteration[028/030] Train loss: 0.0136
2023-02-06 14:20:40 | Train | Epoch[236/600] Iteration[029/030] Train loss: 0.0136
2023-02-06 14:20:40 | Train | Epoch[236/600] Iteration[030/030] Train loss: 0.0136
2023-02-06 14:20:40 | Valid | Epoch[236/600] Iteration[001/008] Valid loss: 0.1118
2023-02-06 14:20:40 | Valid | Epoch[236/600] Iteration[002/008] Valid loss: 0.0834
2023-02-06 14:20:40 | Valid | Epoch[236/600] Iteration[003/008] Valid loss: 0.0797
2023-02-06 14:20:40 | Valid | Epoch[236/600] Iteration[004/008] Valid loss: 0.0757
2023-02-06 14:20:40 | Valid | Epoch[236/600] Iteration[005/008] Valid loss: 0.0729
2023-02-06 14:20:40 | Valid | Epoch[236/600] Iteration[006/008] Valid loss: 0.0720
2023-02-06 14:20:40 | Valid | Epoch[236/600] Iteration[007/008] Valid loss: 0.0742
2023-02-06 14:20:40 | Valid | Epoch[236/600] Iteration[008/008] Valid loss: 0.0734
2023-02-06 14:20:40 | Valid | Epoch[236/600] MIou: 0.9233820544750395
2023-02-06 14:20:40 | Valid | Epoch[236/600] Pixel Accuracy: 0.986822764078776
2023-02-06 14:20:40 | Valid | Epoch[236/600] Mean Pixel Accuracy: 0.949787853704811
2023-02-06 14:20:40 | Stage | Epoch[236/600] Train loss:0.0136
2023-02-06 14:20:40 | Stage | Epoch[236/600] Valid loss:0.0734
2023-02-06 14:20:40 | Stage | Epoch[236/600] LR:0.01

2023-02-06 14:20:41 | Train | Epoch[237/600] Iteration[001/030] Train loss: 0.0138
2023-02-06 14:20:41 | Train | Epoch[237/600] Iteration[002/030] Train loss: 0.0137
2023-02-06 14:20:41 | Train | Epoch[237/600] Iteration[003/030] Train loss: 0.0135
2023-02-06 14:20:42 | Train | Epoch[237/600] Iteration[004/030] Train loss: 0.0150
2023-02-06 14:20:42 | Train | Epoch[237/600] Iteration[005/030] Train loss: 0.0150
2023-02-06 14:20:42 | Train | Epoch[237/600] Iteration[006/030] Train loss: 0.0146
2023-02-06 14:20:42 | Train | Epoch[237/600] Iteration[007/030] Train loss: 0.0144
2023-02-06 14:20:42 | Train | Epoch[237/600] Iteration[008/030] Train loss: 0.0143
2023-02-06 14:20:43 | Train | Epoch[237/600] Iteration[009/030] Train loss: 0.0142
2023-02-06 14:20:43 | Train | Epoch[237/600] Iteration[010/030] Train loss: 0.0141
2023-02-06 14:20:43 | Train | Epoch[237/600] Iteration[011/030] Train loss: 0.0140
2023-02-06 14:20:43 | Train | Epoch[237/600] Iteration[012/030] Train loss: 0.0139
2023-02-06 14:20:44 | Train | Epoch[237/600] Iteration[013/030] Train loss: 0.0138
2023-02-06 14:20:44 | Train | Epoch[237/600] Iteration[014/030] Train loss: 0.0137
2023-02-06 14:20:44 | Train | Epoch[237/600] Iteration[015/030] Train loss: 0.0137
2023-02-06 14:20:44 | Train | Epoch[237/600] Iteration[016/030] Train loss: 0.0136
2023-02-06 14:20:44 | Train | Epoch[237/600] Iteration[017/030] Train loss: 0.0137
2023-02-06 14:20:45 | Train | Epoch[237/600] Iteration[018/030] Train loss: 0.0136
2023-02-06 14:20:45 | Train | Epoch[237/600] Iteration[019/030] Train loss: 0.0137
2023-02-06 14:20:45 | Train | Epoch[237/600] Iteration[020/030] Train loss: 0.0136
2023-02-06 14:20:45 | Train | Epoch[237/600] Iteration[021/030] Train loss: 0.0135
2023-02-06 14:20:46 | Train | Epoch[237/600] Iteration[022/030] Train loss: 0.0136
2023-02-06 14:20:46 | Train | Epoch[237/600] Iteration[023/030] Train loss: 0.0135
2023-02-06 14:20:46 | Train | Epoch[237/600] Iteration[024/030] Train loss: 0.0135
2023-02-06 14:20:46 | Train | Epoch[237/600] Iteration[025/030] Train loss: 0.0135
2023-02-06 14:20:46 | Train | Epoch[237/600] Iteration[026/030] Train loss: 0.0135
2023-02-06 14:20:47 | Train | Epoch[237/600] Iteration[027/030] Train loss: 0.0136
2023-02-06 14:20:47 | Train | Epoch[237/600] Iteration[028/030] Train loss: 0.0136
2023-02-06 14:20:47 | Train | Epoch[237/600] Iteration[029/030] Train loss: 0.0136
2023-02-06 14:20:47 | Train | Epoch[237/600] Iteration[030/030] Train loss: 0.0136
2023-02-06 14:20:48 | Valid | Epoch[237/600] Iteration[001/008] Valid loss: 0.1635
2023-02-06 14:20:48 | Valid | Epoch[237/600] Iteration[002/008] Valid loss: 0.1342
2023-02-06 14:20:48 | Valid | Epoch[237/600] Iteration[003/008] Valid loss: 0.1325
2023-02-06 14:20:48 | Valid | Epoch[237/600] Iteration[004/008] Valid loss: 0.1249
2023-02-06 14:20:48 | Valid | Epoch[237/600] Iteration[005/008] Valid loss: 0.1214
2023-02-06 14:20:48 | Valid | Epoch[237/600] Iteration[006/008] Valid loss: 0.1218
2023-02-06 14:20:48 | Valid | Epoch[237/600] Iteration[007/008] Valid loss: 0.1274
2023-02-06 14:20:48 | Valid | Epoch[237/600] Iteration[008/008] Valid loss: 0.1232
2023-02-06 14:20:48 | Valid | Epoch[237/600] MIou: 0.9214089479868875
2023-02-06 14:20:48 | Valid | Epoch[237/600] Pixel Accuracy: 0.9862785339355469
2023-02-06 14:20:48 | Valid | Epoch[237/600] Mean Pixel Accuracy: 0.9547576534337763
2023-02-06 14:20:48 | Stage | Epoch[237/600] Train loss:0.0136
2023-02-06 14:20:48 | Stage | Epoch[237/600] Valid loss:0.1232
2023-02-06 14:20:48 | Stage | Epoch[237/600] LR:0.01

2023-02-06 14:20:48 | Train | Epoch[238/600] Iteration[001/030] Train loss: 0.0110
2023-02-06 14:20:49 | Train | Epoch[238/600] Iteration[002/030] Train loss: 0.0126
2023-02-06 14:20:49 | Train | Epoch[238/600] Iteration[003/030] Train loss: 0.0128
2023-02-06 14:20:49 | Train | Epoch[238/600] Iteration[004/030] Train loss: 0.0127
2023-02-06 14:20:49 | Train | Epoch[238/600] Iteration[005/030] Train loss: 0.0127
2023-02-06 14:20:50 | Train | Epoch[238/600] Iteration[006/030] Train loss: 0.0129
2023-02-06 14:20:50 | Train | Epoch[238/600] Iteration[007/030] Train loss: 0.0133
2023-02-06 14:20:50 | Train | Epoch[238/600] Iteration[008/030] Train loss: 0.0134
2023-02-06 14:20:50 | Train | Epoch[238/600] Iteration[009/030] Train loss: 0.0133
2023-02-06 14:20:50 | Train | Epoch[238/600] Iteration[010/030] Train loss: 0.0132
2023-02-06 14:20:51 | Train | Epoch[238/600] Iteration[011/030] Train loss: 0.0132
2023-02-06 14:20:51 | Train | Epoch[238/600] Iteration[012/030] Train loss: 0.0131
2023-02-06 14:20:51 | Train | Epoch[238/600] Iteration[013/030] Train loss: 0.0133
2023-02-06 14:20:51 | Train | Epoch[238/600] Iteration[014/030] Train loss: 0.0132
2023-02-06 14:20:52 | Train | Epoch[238/600] Iteration[015/030] Train loss: 0.0133
2023-02-06 14:20:52 | Train | Epoch[238/600] Iteration[016/030] Train loss: 0.0132
2023-02-06 14:20:52 | Train | Epoch[238/600] Iteration[017/030] Train loss: 0.0132
2023-02-06 14:20:52 | Train | Epoch[238/600] Iteration[018/030] Train loss: 0.0133
2023-02-06 14:20:52 | Train | Epoch[238/600] Iteration[019/030] Train loss: 0.0132
2023-02-06 14:20:53 | Train | Epoch[238/600] Iteration[020/030] Train loss: 0.0132
2023-02-06 14:20:53 | Train | Epoch[238/600] Iteration[021/030] Train loss: 0.0133
2023-02-06 14:20:53 | Train | Epoch[238/600] Iteration[022/030] Train loss: 0.0133
2023-02-06 14:20:53 | Train | Epoch[238/600] Iteration[023/030] Train loss: 0.0133
2023-02-06 14:20:54 | Train | Epoch[238/600] Iteration[024/030] Train loss: 0.0134
2023-02-06 14:20:54 | Train | Epoch[238/600] Iteration[025/030] Train loss: 0.0135
2023-02-06 14:20:54 | Train | Epoch[238/600] Iteration[026/030] Train loss: 0.0135
2023-02-06 14:20:54 | Train | Epoch[238/600] Iteration[027/030] Train loss: 0.0135
2023-02-06 14:20:54 | Train | Epoch[238/600] Iteration[028/030] Train loss: 0.0135
2023-02-06 14:20:55 | Train | Epoch[238/600] Iteration[029/030] Train loss: 0.0135
2023-02-06 14:20:55 | Train | Epoch[238/600] Iteration[030/030] Train loss: 0.0134
2023-02-06 14:20:55 | Valid | Epoch[238/600] Iteration[001/008] Valid loss: 0.1880
2023-02-06 14:20:55 | Valid | Epoch[238/600] Iteration[002/008] Valid loss: 0.1477
2023-02-06 14:20:55 | Valid | Epoch[238/600] Iteration[003/008] Valid loss: 0.1443
2023-02-06 14:20:55 | Valid | Epoch[238/600] Iteration[004/008] Valid loss: 0.1411
2023-02-06 14:20:55 | Valid | Epoch[238/600] Iteration[005/008] Valid loss: 0.1413
2023-02-06 14:20:55 | Valid | Epoch[238/600] Iteration[006/008] Valid loss: 0.1428
2023-02-06 14:20:55 | Valid | Epoch[238/600] Iteration[007/008] Valid loss: 0.1547
2023-02-06 14:20:55 | Valid | Epoch[238/600] Iteration[008/008] Valid loss: 0.1518
2023-02-06 14:20:55 | Valid | Epoch[238/600] MIou: 0.9251977122967516
2023-02-06 14:20:55 | Valid | Epoch[238/600] Pixel Accuracy: 0.9867210388183594
2023-02-06 14:20:55 | Valid | Epoch[238/600] Mean Pixel Accuracy: 0.9662678908667126
2023-02-06 14:20:55 | Stage | Epoch[238/600] Train loss:0.0134
2023-02-06 14:20:55 | Stage | Epoch[238/600] Valid loss:0.1518
2023-02-06 14:20:55 | Stage | Epoch[238/600] LR:0.01

2023-02-06 14:20:56 | Train | Epoch[239/600] Iteration[001/030] Train loss: 0.0137
2023-02-06 14:20:56 | Train | Epoch[239/600] Iteration[002/030] Train loss: 0.0134
2023-02-06 14:20:56 | Train | Epoch[239/600] Iteration[003/030] Train loss: 0.0128
2023-02-06 14:20:57 | Train | Epoch[239/600] Iteration[004/030] Train loss: 0.0128
2023-02-06 14:20:57 | Train | Epoch[239/600] Iteration[005/030] Train loss: 0.0130
2023-02-06 14:20:57 | Train | Epoch[239/600] Iteration[006/030] Train loss: 0.0129
2023-02-06 14:20:57 | Train | Epoch[239/600] Iteration[007/030] Train loss: 0.0128
2023-02-06 14:20:57 | Train | Epoch[239/600] Iteration[008/030] Train loss: 0.0127
2023-02-06 14:20:58 | Train | Epoch[239/600] Iteration[009/030] Train loss: 0.0128
2023-02-06 14:20:58 | Train | Epoch[239/600] Iteration[010/030] Train loss: 0.0128
2023-02-06 14:20:58 | Train | Epoch[239/600] Iteration[011/030] Train loss: 0.0127
2023-02-06 14:20:58 | Train | Epoch[239/600] Iteration[012/030] Train loss: 0.0128
2023-02-06 14:20:59 | Train | Epoch[239/600] Iteration[013/030] Train loss: 0.0127
2023-02-06 14:20:59 | Train | Epoch[239/600] Iteration[014/030] Train loss: 0.0128
2023-02-06 14:20:59 | Train | Epoch[239/600] Iteration[015/030] Train loss: 0.0129
2023-02-06 14:20:59 | Train | Epoch[239/600] Iteration[016/030] Train loss: 0.0130
2023-02-06 14:20:59 | Train | Epoch[239/600] Iteration[017/030] Train loss: 0.0129
2023-02-06 14:21:00 | Train | Epoch[239/600] Iteration[018/030] Train loss: 0.0130
2023-02-06 14:21:00 | Train | Epoch[239/600] Iteration[019/030] Train loss: 0.0132
2023-02-06 14:21:00 | Train | Epoch[239/600] Iteration[020/030] Train loss: 0.0133
2023-02-06 14:21:00 | Train | Epoch[239/600] Iteration[021/030] Train loss: 0.0133
2023-02-06 14:21:01 | Train | Epoch[239/600] Iteration[022/030] Train loss: 0.0133
2023-02-06 14:21:01 | Train | Epoch[239/600] Iteration[023/030] Train loss: 0.0134
2023-02-06 14:21:01 | Train | Epoch[239/600] Iteration[024/030] Train loss: 0.0134
2023-02-06 14:21:01 | Train | Epoch[239/600] Iteration[025/030] Train loss: 0.0134
2023-02-06 14:21:01 | Train | Epoch[239/600] Iteration[026/030] Train loss: 0.0135
2023-02-06 14:21:02 | Train | Epoch[239/600] Iteration[027/030] Train loss: 0.0136
2023-02-06 14:21:02 | Train | Epoch[239/600] Iteration[028/030] Train loss: 0.0135
2023-02-06 14:21:02 | Train | Epoch[239/600] Iteration[029/030] Train loss: 0.0135
2023-02-06 14:21:02 | Train | Epoch[239/600] Iteration[030/030] Train loss: 0.0136
2023-02-06 14:21:03 | Valid | Epoch[239/600] Iteration[001/008] Valid loss: 0.6592
2023-02-06 14:21:03 | Valid | Epoch[239/600] Iteration[002/008] Valid loss: 0.6078
2023-02-06 14:21:03 | Valid | Epoch[239/600] Iteration[003/008] Valid loss: 0.6374
2023-02-06 14:21:03 | Valid | Epoch[239/600] Iteration[004/008] Valid loss: 0.6275
2023-02-06 14:21:03 | Valid | Epoch[239/600] Iteration[005/008] Valid loss: 0.6551
2023-02-06 14:21:03 | Valid | Epoch[239/600] Iteration[006/008] Valid loss: 0.6468
2023-02-06 14:21:03 | Valid | Epoch[239/600] Iteration[007/008] Valid loss: 0.6809
2023-02-06 14:21:03 | Valid | Epoch[239/600] Iteration[008/008] Valid loss: 0.7045
2023-02-06 14:21:03 | Valid | Epoch[239/600] MIou: 0.8827436706767069
2023-02-06 14:21:03 | Valid | Epoch[239/600] Pixel Accuracy: 0.9764912923177084
2023-02-06 14:21:03 | Valid | Epoch[239/600] Mean Pixel Accuracy: 0.981169292186421
2023-02-06 14:21:03 | Stage | Epoch[239/600] Train loss:0.0136
2023-02-06 14:21:03 | Stage | Epoch[239/600] Valid loss:0.7045
2023-02-06 14:21:03 | Stage | Epoch[239/600] LR:0.01

2023-02-06 14:21:04 | Train | Epoch[240/600] Iteration[001/030] Train loss: 0.0128
2023-02-06 14:21:04 | Train | Epoch[240/600] Iteration[002/030] Train loss: 0.0132
2023-02-06 14:21:04 | Train | Epoch[240/600] Iteration[003/030] Train loss: 0.0136
2023-02-06 14:21:04 | Train | Epoch[240/600] Iteration[004/030] Train loss: 0.0138
2023-02-06 14:21:04 | Train | Epoch[240/600] Iteration[005/030] Train loss: 0.0133
2023-02-06 14:21:05 | Train | Epoch[240/600] Iteration[006/030] Train loss: 0.0131
2023-02-06 14:21:05 | Train | Epoch[240/600] Iteration[007/030] Train loss: 0.0135
2023-02-06 14:21:05 | Train | Epoch[240/600] Iteration[008/030] Train loss: 0.0137
2023-02-06 14:21:05 | Train | Epoch[240/600] Iteration[009/030] Train loss: 0.0138
2023-02-06 14:21:06 | Train | Epoch[240/600] Iteration[010/030] Train loss: 0.0139
2023-02-06 14:21:06 | Train | Epoch[240/600] Iteration[011/030] Train loss: 0.0139
2023-02-06 14:21:06 | Train | Epoch[240/600] Iteration[012/030] Train loss: 0.0139
2023-02-06 14:21:06 | Train | Epoch[240/600] Iteration[013/030] Train loss: 0.0140
2023-02-06 14:21:06 | Train | Epoch[240/600] Iteration[014/030] Train loss: 0.0139
2023-02-06 14:21:07 | Train | Epoch[240/600] Iteration[015/030] Train loss: 0.0139
2023-02-06 14:21:07 | Train | Epoch[240/600] Iteration[016/030] Train loss: 0.0139
2023-02-06 14:21:07 | Train | Epoch[240/600] Iteration[017/030] Train loss: 0.0138
2023-02-06 14:21:07 | Train | Epoch[240/600] Iteration[018/030] Train loss: 0.0138
2023-02-06 14:21:07 | Train | Epoch[240/600] Iteration[019/030] Train loss: 0.0138
2023-02-06 14:21:08 | Train | Epoch[240/600] Iteration[020/030] Train loss: 0.0138
2023-02-06 14:21:08 | Train | Epoch[240/600] Iteration[021/030] Train loss: 0.0137
2023-02-06 14:21:08 | Train | Epoch[240/600] Iteration[022/030] Train loss: 0.0137
2023-02-06 14:21:08 | Train | Epoch[240/600] Iteration[023/030] Train loss: 0.0137
2023-02-06 14:21:09 | Train | Epoch[240/600] Iteration[024/030] Train loss: 0.0137
2023-02-06 14:21:09 | Train | Epoch[240/600] Iteration[025/030] Train loss: 0.0137
2023-02-06 14:21:09 | Train | Epoch[240/600] Iteration[026/030] Train loss: 0.0138
2023-02-06 14:21:09 | Train | Epoch[240/600] Iteration[027/030] Train loss: 0.0137
2023-02-06 14:21:09 | Train | Epoch[240/600] Iteration[028/030] Train loss: 0.0137
2023-02-06 14:21:10 | Train | Epoch[240/600] Iteration[029/030] Train loss: 0.0137
2023-02-06 14:21:10 | Train | Epoch[240/600] Iteration[030/030] Train loss: 0.0138
2023-02-06 14:21:10 | Valid | Epoch[240/600] Iteration[001/008] Valid loss: 0.2512
2023-02-06 14:21:10 | Valid | Epoch[240/600] Iteration[002/008] Valid loss: 0.1802
2023-02-06 14:21:10 | Valid | Epoch[240/600] Iteration[003/008] Valid loss: 0.1757
2023-02-06 14:21:10 | Valid | Epoch[240/600] Iteration[004/008] Valid loss: 0.1702
2023-02-06 14:21:10 | Valid | Epoch[240/600] Iteration[005/008] Valid loss: 0.1694
2023-02-06 14:21:10 | Valid | Epoch[240/600] Iteration[006/008] Valid loss: 0.1649
2023-02-06 14:21:10 | Valid | Epoch[240/600] Iteration[007/008] Valid loss: 0.1737
2023-02-06 14:21:10 | Valid | Epoch[240/600] Iteration[008/008] Valid loss: 0.1726
2023-02-06 14:21:11 | Valid | Epoch[240/600] MIou: 0.9271980037039548
2023-02-06 14:21:11 | Valid | Epoch[240/600] Pixel Accuracy: 0.9870274861653646
2023-02-06 14:21:11 | Valid | Epoch[240/600] Mean Pixel Accuracy: 0.9700503961601754
2023-02-06 14:21:11 | Stage | Epoch[240/600] Train loss:0.0138
2023-02-06 14:21:11 | Stage | Epoch[240/600] Valid loss:0.1726
2023-02-06 14:21:11 | Stage | Epoch[240/600] LR:0.01

2023-02-06 14:21:11 | Train | Epoch[241/600] Iteration[001/030] Train loss: 0.0135
2023-02-06 14:21:11 | Train | Epoch[241/600] Iteration[002/030] Train loss: 0.0140
2023-02-06 14:21:11 | Train | Epoch[241/600] Iteration[003/030] Train loss: 0.0138
2023-02-06 14:21:12 | Train | Epoch[241/600] Iteration[004/030] Train loss: 0.0136
2023-02-06 14:21:12 | Train | Epoch[241/600] Iteration[005/030] Train loss: 0.0134
2023-02-06 14:21:12 | Train | Epoch[241/600] Iteration[006/030] Train loss: 0.0134
2023-02-06 14:21:12 | Train | Epoch[241/600] Iteration[007/030] Train loss: 0.0134
2023-02-06 14:21:13 | Train | Epoch[241/600] Iteration[008/030] Train loss: 0.0134
2023-02-06 14:21:13 | Train | Epoch[241/600] Iteration[009/030] Train loss: 0.0133
2023-02-06 14:21:13 | Train | Epoch[241/600] Iteration[010/030] Train loss: 0.0132
2023-02-06 14:21:13 | Train | Epoch[241/600] Iteration[011/030] Train loss: 0.0132
2023-02-06 14:21:13 | Train | Epoch[241/600] Iteration[012/030] Train loss: 0.0131
2023-02-06 14:21:14 | Train | Epoch[241/600] Iteration[013/030] Train loss: 0.0131
2023-02-06 14:21:14 | Train | Epoch[241/600] Iteration[014/030] Train loss: 0.0130
2023-02-06 14:21:14 | Train | Epoch[241/600] Iteration[015/030] Train loss: 0.0130
2023-02-06 14:21:14 | Train | Epoch[241/600] Iteration[016/030] Train loss: 0.0130
2023-02-06 14:21:15 | Train | Epoch[241/600] Iteration[017/030] Train loss: 0.0130
2023-02-06 14:21:15 | Train | Epoch[241/600] Iteration[018/030] Train loss: 0.0130
2023-02-06 14:21:15 | Train | Epoch[241/600] Iteration[019/030] Train loss: 0.0131
2023-02-06 14:21:15 | Train | Epoch[241/600] Iteration[020/030] Train loss: 0.0132
2023-02-06 14:21:15 | Train | Epoch[241/600] Iteration[021/030] Train loss: 0.0132
2023-02-06 14:21:16 | Train | Epoch[241/600] Iteration[022/030] Train loss: 0.0132
2023-02-06 14:21:16 | Train | Epoch[241/600] Iteration[023/030] Train loss: 0.0132
2023-02-06 14:21:16 | Train | Epoch[241/600] Iteration[024/030] Train loss: 0.0133
2023-02-06 14:21:16 | Train | Epoch[241/600] Iteration[025/030] Train loss: 0.0134
2023-02-06 14:21:17 | Train | Epoch[241/600] Iteration[026/030] Train loss: 0.0133
2023-02-06 14:21:17 | Train | Epoch[241/600] Iteration[027/030] Train loss: 0.0134
2023-02-06 14:21:17 | Train | Epoch[241/600] Iteration[028/030] Train loss: 0.0134
2023-02-06 14:21:17 | Train | Epoch[241/600] Iteration[029/030] Train loss: 0.0134
2023-02-06 14:21:17 | Train | Epoch[241/600] Iteration[030/030] Train loss: 0.0135
2023-02-06 14:21:18 | Valid | Epoch[241/600] Iteration[001/008] Valid loss: 0.4202
2023-02-06 14:21:18 | Valid | Epoch[241/600] Iteration[002/008] Valid loss: 0.3751
2023-02-06 14:21:18 | Valid | Epoch[241/600] Iteration[003/008] Valid loss: 0.3847
2023-02-06 14:21:18 | Valid | Epoch[241/600] Iteration[004/008] Valid loss: 0.3811
2023-02-06 14:21:18 | Valid | Epoch[241/600] Iteration[005/008] Valid loss: 0.3925
2023-02-06 14:21:18 | Valid | Epoch[241/600] Iteration[006/008] Valid loss: 0.3850
2023-02-06 14:21:18 | Valid | Epoch[241/600] Iteration[007/008] Valid loss: 0.4132
2023-02-06 14:21:18 | Valid | Epoch[241/600] Iteration[008/008] Valid loss: 0.4339
2023-02-06 14:21:18 | Valid | Epoch[241/600] MIou: 0.9052953056256319
2023-02-06 14:21:18 | Valid | Epoch[241/600] Pixel Accuracy: 0.9820276896158854
2023-02-06 14:21:18 | Valid | Epoch[241/600] Mean Pixel Accuracy: 0.9782205866842177
2023-02-06 14:21:18 | Stage | Epoch[241/600] Train loss:0.0135
2023-02-06 14:21:18 | Stage | Epoch[241/600] Valid loss:0.4339
2023-02-06 14:21:18 | Stage | Epoch[241/600] LR:0.01

2023-02-06 14:21:19 | Train | Epoch[242/600] Iteration[001/030] Train loss: 0.0136
2023-02-06 14:21:19 | Train | Epoch[242/600] Iteration[002/030] Train loss: 0.0142
2023-02-06 14:21:19 | Train | Epoch[242/600] Iteration[003/030] Train loss: 0.0142
2023-02-06 14:21:19 | Train | Epoch[242/600] Iteration[004/030] Train loss: 0.0139
2023-02-06 14:21:19 | Train | Epoch[242/600] Iteration[005/030] Train loss: 0.0137
2023-02-06 14:21:20 | Train | Epoch[242/600] Iteration[006/030] Train loss: 0.0136
2023-02-06 14:21:20 | Train | Epoch[242/600] Iteration[007/030] Train loss: 0.0137
2023-02-06 14:21:20 | Train | Epoch[242/600] Iteration[008/030] Train loss: 0.0136
2023-02-06 14:21:20 | Train | Epoch[242/600] Iteration[009/030] Train loss: 0.0138
2023-02-06 14:21:21 | Train | Epoch[242/600] Iteration[010/030] Train loss: 0.0136
2023-02-06 14:21:21 | Train | Epoch[242/600] Iteration[011/030] Train loss: 0.0135
2023-02-06 14:21:21 | Train | Epoch[242/600] Iteration[012/030] Train loss: 0.0136
2023-02-06 14:21:21 | Train | Epoch[242/600] Iteration[013/030] Train loss: 0.0136
2023-02-06 14:21:21 | Train | Epoch[242/600] Iteration[014/030] Train loss: 0.0138
2023-02-06 14:21:22 | Train | Epoch[242/600] Iteration[015/030] Train loss: 0.0137
2023-02-06 14:21:22 | Train | Epoch[242/600] Iteration[016/030] Train loss: 0.0137
2023-02-06 14:21:22 | Train | Epoch[242/600] Iteration[017/030] Train loss: 0.0137
2023-02-06 14:21:22 | Train | Epoch[242/600] Iteration[018/030] Train loss: 0.0137
2023-02-06 14:21:22 | Train | Epoch[242/600] Iteration[019/030] Train loss: 0.0136
2023-02-06 14:21:23 | Train | Epoch[242/600] Iteration[020/030] Train loss: 0.0137
2023-02-06 14:21:23 | Train | Epoch[242/600] Iteration[021/030] Train loss: 0.0137
2023-02-06 14:21:23 | Train | Epoch[242/600] Iteration[022/030] Train loss: 0.0137
2023-02-06 14:21:23 | Train | Epoch[242/600] Iteration[023/030] Train loss: 0.0137
2023-02-06 14:21:24 | Train | Epoch[242/600] Iteration[024/030] Train loss: 0.0137
2023-02-06 14:21:24 | Train | Epoch[242/600] Iteration[025/030] Train loss: 0.0136
2023-02-06 14:21:24 | Train | Epoch[242/600] Iteration[026/030] Train loss: 0.0136
2023-02-06 14:21:24 | Train | Epoch[242/600] Iteration[027/030] Train loss: 0.0136
2023-02-06 14:21:24 | Train | Epoch[242/600] Iteration[028/030] Train loss: 0.0135
2023-02-06 14:21:25 | Train | Epoch[242/600] Iteration[029/030] Train loss: 0.0135
2023-02-06 14:21:25 | Train | Epoch[242/600] Iteration[030/030] Train loss: 0.0135
2023-02-06 14:21:25 | Valid | Epoch[242/600] Iteration[001/008] Valid loss: 0.1348
2023-02-06 14:21:25 | Valid | Epoch[242/600] Iteration[002/008] Valid loss: 0.1124
2023-02-06 14:21:25 | Valid | Epoch[242/600] Iteration[003/008] Valid loss: 0.1042
2023-02-06 14:21:25 | Valid | Epoch[242/600] Iteration[004/008] Valid loss: 0.1022
2023-02-06 14:21:25 | Valid | Epoch[242/600] Iteration[005/008] Valid loss: 0.1005
2023-02-06 14:21:25 | Valid | Epoch[242/600] Iteration[006/008] Valid loss: 0.1003
2023-02-06 14:21:25 | Valid | Epoch[242/600] Iteration[007/008] Valid loss: 0.1060
2023-02-06 14:21:26 | Valid | Epoch[242/600] Iteration[008/008] Valid loss: 0.1078
2023-02-06 14:21:26 | Valid | Epoch[242/600] MIou: 0.9153020498955002
2023-02-06 14:21:26 | Valid | Epoch[242/600] Pixel Accuracy: 0.9850196838378906
2023-02-06 14:21:26 | Valid | Epoch[242/600] Mean Pixel Accuracy: 0.9547314852402147
2023-02-06 14:21:26 | Stage | Epoch[242/600] Train loss:0.0135
2023-02-06 14:21:26 | Stage | Epoch[242/600] Valid loss:0.1078
2023-02-06 14:21:26 | Stage | Epoch[242/600] LR:0.01

2023-02-06 14:21:26 | Train | Epoch[243/600] Iteration[001/030] Train loss: 0.0114
2023-02-06 14:21:26 | Train | Epoch[243/600] Iteration[002/030] Train loss: 0.0129
2023-02-06 14:21:26 | Train | Epoch[243/600] Iteration[003/030] Train loss: 0.0132
2023-02-06 14:21:27 | Train | Epoch[243/600] Iteration[004/030] Train loss: 0.0128
2023-02-06 14:21:27 | Train | Epoch[243/600] Iteration[005/030] Train loss: 0.0129
2023-02-06 14:21:27 | Train | Epoch[243/600] Iteration[006/030] Train loss: 0.0129
2023-02-06 14:21:27 | Train | Epoch[243/600] Iteration[007/030] Train loss: 0.0128
2023-02-06 14:21:28 | Train | Epoch[243/600] Iteration[008/030] Train loss: 0.0129
2023-02-06 14:21:28 | Train | Epoch[243/600] Iteration[009/030] Train loss: 0.0129
2023-02-06 14:21:28 | Train | Epoch[243/600] Iteration[010/030] Train loss: 0.0129
2023-02-06 14:21:28 | Train | Epoch[243/600] Iteration[011/030] Train loss: 0.0130
2023-02-06 14:21:28 | Train | Epoch[243/600] Iteration[012/030] Train loss: 0.0129
2023-02-06 14:21:29 | Train | Epoch[243/600] Iteration[013/030] Train loss: 0.0129
2023-02-06 14:21:29 | Train | Epoch[243/600] Iteration[014/030] Train loss: 0.0128
2023-02-06 14:21:29 | Train | Epoch[243/600] Iteration[015/030] Train loss: 0.0127
2023-02-06 14:21:29 | Train | Epoch[243/600] Iteration[016/030] Train loss: 0.0127
2023-02-06 14:21:30 | Train | Epoch[243/600] Iteration[017/030] Train loss: 0.0129
2023-02-06 14:21:30 | Train | Epoch[243/600] Iteration[018/030] Train loss: 0.0128
2023-02-06 14:21:30 | Train | Epoch[243/600] Iteration[019/030] Train loss: 0.0128
2023-02-06 14:21:30 | Train | Epoch[243/600] Iteration[020/030] Train loss: 0.0129
2023-02-06 14:21:30 | Train | Epoch[243/600] Iteration[021/030] Train loss: 0.0130
2023-02-06 14:21:31 | Train | Epoch[243/600] Iteration[022/030] Train loss: 0.0130
2023-02-06 14:21:31 | Train | Epoch[243/600] Iteration[023/030] Train loss: 0.0132
2023-02-06 14:21:31 | Train | Epoch[243/600] Iteration[024/030] Train loss: 0.0131
2023-02-06 14:21:31 | Train | Epoch[243/600] Iteration[025/030] Train loss: 0.0131
2023-02-06 14:21:32 | Train | Epoch[243/600] Iteration[026/030] Train loss: 0.0132
2023-02-06 14:21:32 | Train | Epoch[243/600] Iteration[027/030] Train loss: 0.0131
2023-02-06 14:21:32 | Train | Epoch[243/600] Iteration[028/030] Train loss: 0.0131
2023-02-06 14:21:32 | Train | Epoch[243/600] Iteration[029/030] Train loss: 0.0131
2023-02-06 14:21:32 | Train | Epoch[243/600] Iteration[030/030] Train loss: 0.0131
2023-02-06 14:21:33 | Valid | Epoch[243/600] Iteration[001/008] Valid loss: 0.5104
2023-02-06 14:21:33 | Valid | Epoch[243/600] Iteration[002/008] Valid loss: 0.4432
2023-02-06 14:21:33 | Valid | Epoch[243/600] Iteration[003/008] Valid loss: 0.4531
2023-02-06 14:21:33 | Valid | Epoch[243/600] Iteration[004/008] Valid loss: 0.4412
2023-02-06 14:21:33 | Valid | Epoch[243/600] Iteration[005/008] Valid loss: 0.4573
2023-02-06 14:21:33 | Valid | Epoch[243/600] Iteration[006/008] Valid loss: 0.4509
2023-02-06 14:21:33 | Valid | Epoch[243/600] Iteration[007/008] Valid loss: 0.4848
2023-02-06 14:21:33 | Valid | Epoch[243/600] Iteration[008/008] Valid loss: 0.4960
2023-02-06 14:21:33 | Valid | Epoch[243/600] MIou: 0.8992804400850332
2023-02-06 14:21:33 | Valid | Epoch[243/600] Pixel Accuracy: 0.9805221557617188
2023-02-06 14:21:33 | Valid | Epoch[243/600] Mean Pixel Accuracy: 0.9811910235042376
2023-02-06 14:21:33 | Stage | Epoch[243/600] Train loss:0.0131
2023-02-06 14:21:33 | Stage | Epoch[243/600] Valid loss:0.4960
2023-02-06 14:21:33 | Stage | Epoch[243/600] LR:0.01

2023-02-06 14:21:34 | Train | Epoch[244/600] Iteration[001/030] Train loss: 0.0132
2023-02-06 14:21:34 | Train | Epoch[244/600] Iteration[002/030] Train loss: 0.0134
2023-02-06 14:21:34 | Train | Epoch[244/600] Iteration[003/030] Train loss: 0.0125
2023-02-06 14:21:34 | Train | Epoch[244/600] Iteration[004/030] Train loss: 0.0125
2023-02-06 14:21:34 | Train | Epoch[244/600] Iteration[005/030] Train loss: 0.0127
2023-02-06 14:21:35 | Train | Epoch[244/600] Iteration[006/030] Train loss: 0.0125
2023-02-06 14:21:35 | Train | Epoch[244/600] Iteration[007/030] Train loss: 0.0124
2023-02-06 14:21:35 | Train | Epoch[244/600] Iteration[008/030] Train loss: 0.0124
2023-02-06 14:21:35 | Train | Epoch[244/600] Iteration[009/030] Train loss: 0.0126
2023-02-06 14:21:36 | Train | Epoch[244/600] Iteration[010/030] Train loss: 0.0126
2023-02-06 14:21:36 | Train | Epoch[244/600] Iteration[011/030] Train loss: 0.0126
2023-02-06 14:21:36 | Train | Epoch[244/600] Iteration[012/030] Train loss: 0.0127
2023-02-06 14:21:36 | Train | Epoch[244/600] Iteration[013/030] Train loss: 0.0129
2023-02-06 14:21:36 | Train | Epoch[244/600] Iteration[014/030] Train loss: 0.0129
2023-02-06 14:21:37 | Train | Epoch[244/600] Iteration[015/030] Train loss: 0.0128
2023-02-06 14:21:37 | Train | Epoch[244/600] Iteration[016/030] Train loss: 0.0129
2023-02-06 14:21:37 | Train | Epoch[244/600] Iteration[017/030] Train loss: 0.0129
2023-02-06 14:21:37 | Train | Epoch[244/600] Iteration[018/030] Train loss: 0.0129
2023-02-06 14:21:37 | Train | Epoch[244/600] Iteration[019/030] Train loss: 0.0129
2023-02-06 14:21:38 | Train | Epoch[244/600] Iteration[020/030] Train loss: 0.0129
2023-02-06 14:21:38 | Train | Epoch[244/600] Iteration[021/030] Train loss: 0.0129
2023-02-06 14:21:38 | Train | Epoch[244/600] Iteration[022/030] Train loss: 0.0130
2023-02-06 14:21:38 | Train | Epoch[244/600] Iteration[023/030] Train loss: 0.0130
2023-02-06 14:21:39 | Train | Epoch[244/600] Iteration[024/030] Train loss: 0.0131
2023-02-06 14:21:39 | Train | Epoch[244/600] Iteration[025/030] Train loss: 0.0130
2023-02-06 14:21:39 | Train | Epoch[244/600] Iteration[026/030] Train loss: 0.0130
2023-02-06 14:21:39 | Train | Epoch[244/600] Iteration[027/030] Train loss: 0.0130
2023-02-06 14:21:39 | Train | Epoch[244/600] Iteration[028/030] Train loss: 0.0129
2023-02-06 14:21:40 | Train | Epoch[244/600] Iteration[029/030] Train loss: 0.0130
2023-02-06 14:21:40 | Train | Epoch[244/600] Iteration[030/030] Train loss: 0.0132
2023-02-06 14:21:40 | Valid | Epoch[244/600] Iteration[001/008] Valid loss: 0.1621
2023-02-06 14:21:40 | Valid | Epoch[244/600] Iteration[002/008] Valid loss: 0.1655
2023-02-06 14:21:40 | Valid | Epoch[244/600] Iteration[003/008] Valid loss: 0.1733
2023-02-06 14:21:40 | Valid | Epoch[244/600] Iteration[004/008] Valid loss: 0.1749
2023-02-06 14:21:40 | Valid | Epoch[244/600] Iteration[005/008] Valid loss: 0.1758
2023-02-06 14:21:40 | Valid | Epoch[244/600] Iteration[006/008] Valid loss: 0.1702
2023-02-06 14:21:40 | Valid | Epoch[244/600] Iteration[007/008] Valid loss: 0.1633
2023-02-06 14:21:40 | Valid | Epoch[244/600] Iteration[008/008] Valid loss: 0.1679
2023-02-06 14:21:41 | Valid | Epoch[244/600] MIou: 0.6620180291429283
2023-02-06 14:21:41 | Valid | Epoch[244/600] Pixel Accuracy: 0.9441184997558594
2023-02-06 14:21:41 | Valid | Epoch[244/600] Mean Pixel Accuracy: 0.6911032970564882
2023-02-06 14:21:41 | Stage | Epoch[244/600] Train loss:0.0132
2023-02-06 14:21:41 | Stage | Epoch[244/600] Valid loss:0.1679
2023-02-06 14:21:41 | Stage | Epoch[244/600] LR:0.01

2023-02-06 14:21:41 | Train | Epoch[245/600] Iteration[001/030] Train loss: 0.0124
2023-02-06 14:21:41 | Train | Epoch[245/600] Iteration[002/030] Train loss: 0.0126
2023-02-06 14:21:41 | Train | Epoch[245/600] Iteration[003/030] Train loss: 0.0126
2023-02-06 14:21:42 | Train | Epoch[245/600] Iteration[004/030] Train loss: 0.0127
2023-02-06 14:21:42 | Train | Epoch[245/600] Iteration[005/030] Train loss: 0.0133
2023-02-06 14:21:42 | Train | Epoch[245/600] Iteration[006/030] Train loss: 0.0131
2023-02-06 14:21:42 | Train | Epoch[245/600] Iteration[007/030] Train loss: 0.0130
2023-02-06 14:21:43 | Train | Epoch[245/600] Iteration[008/030] Train loss: 0.0130
2023-02-06 14:21:43 | Train | Epoch[245/600] Iteration[009/030] Train loss: 0.0130
2023-02-06 14:21:43 | Train | Epoch[245/600] Iteration[010/030] Train loss: 0.0130
2023-02-06 14:21:43 | Train | Epoch[245/600] Iteration[011/030] Train loss: 0.0130
2023-02-06 14:21:43 | Train | Epoch[245/600] Iteration[012/030] Train loss: 0.0131
2023-02-06 14:21:44 | Train | Epoch[245/600] Iteration[013/030] Train loss: 0.0134
2023-02-06 14:21:44 | Train | Epoch[245/600] Iteration[014/030] Train loss: 0.0134
2023-02-06 14:21:44 | Train | Epoch[245/600] Iteration[015/030] Train loss: 0.0135
2023-02-06 14:21:44 | Train | Epoch[245/600] Iteration[016/030] Train loss: 0.0135
2023-02-06 14:21:45 | Train | Epoch[245/600] Iteration[017/030] Train loss: 0.0135
2023-02-06 14:21:45 | Train | Epoch[245/600] Iteration[018/030] Train loss: 0.0135
2023-02-06 14:21:45 | Train | Epoch[245/600] Iteration[019/030] Train loss: 0.0137
2023-02-06 14:21:45 | Train | Epoch[245/600] Iteration[020/030] Train loss: 0.0138
2023-02-06 14:21:45 | Train | Epoch[245/600] Iteration[021/030] Train loss: 0.0139
2023-02-06 14:21:46 | Train | Epoch[245/600] Iteration[022/030] Train loss: 0.0139
2023-02-06 14:21:46 | Train | Epoch[245/600] Iteration[023/030] Train loss: 0.0139
2023-02-06 14:21:46 | Train | Epoch[245/600] Iteration[024/030] Train loss: 0.0139
2023-02-06 14:21:46 | Train | Epoch[245/600] Iteration[025/030] Train loss: 0.0139
2023-02-06 14:21:47 | Train | Epoch[245/600] Iteration[026/030] Train loss: 0.0139
2023-02-06 14:21:47 | Train | Epoch[245/600] Iteration[027/030] Train loss: 0.0140
2023-02-06 14:21:47 | Train | Epoch[245/600] Iteration[028/030] Train loss: 0.0140
2023-02-06 14:21:47 | Train | Epoch[245/600] Iteration[029/030] Train loss: 0.0140
2023-02-06 14:21:47 | Train | Epoch[245/600] Iteration[030/030] Train loss: 0.0140
2023-02-06 14:21:48 | Valid | Epoch[245/600] Iteration[001/008] Valid loss: 0.1133
2023-02-06 14:21:48 | Valid | Epoch[245/600] Iteration[002/008] Valid loss: 0.0926
2023-02-06 14:21:48 | Valid | Epoch[245/600] Iteration[003/008] Valid loss: 0.0937
2023-02-06 14:21:48 | Valid | Epoch[245/600] Iteration[004/008] Valid loss: 0.0881
2023-02-06 14:21:48 | Valid | Epoch[245/600] Iteration[005/008] Valid loss: 0.0961
2023-02-06 14:21:48 | Valid | Epoch[245/600] Iteration[006/008] Valid loss: 0.0927
2023-02-06 14:21:48 | Valid | Epoch[245/600] Iteration[007/008] Valid loss: 0.0955
2023-02-06 14:21:48 | Valid | Epoch[245/600] Iteration[008/008] Valid loss: 0.0989
2023-02-06 14:21:48 | Valid | Epoch[245/600] MIou: 0.8837320052884277
2023-02-06 14:21:48 | Valid | Epoch[245/600] Pixel Accuracy: 0.9799346923828125
2023-02-06 14:21:48 | Valid | Epoch[245/600] Mean Pixel Accuracy: 0.9131011690553746
2023-02-06 14:21:48 | Stage | Epoch[245/600] Train loss:0.0140
2023-02-06 14:21:48 | Stage | Epoch[245/600] Valid loss:0.0989
2023-02-06 14:21:48 | Stage | Epoch[245/600] LR:0.01

2023-02-06 14:21:49 | Train | Epoch[246/600] Iteration[001/030] Train loss: 0.0149
2023-02-06 14:21:49 | Train | Epoch[246/600] Iteration[002/030] Train loss: 0.0140
2023-02-06 14:21:49 | Train | Epoch[246/600] Iteration[003/030] Train loss: 0.0138
2023-02-06 14:21:49 | Train | Epoch[246/600] Iteration[004/030] Train loss: 0.0136
2023-02-06 14:21:49 | Train | Epoch[246/600] Iteration[005/030] Train loss: 0.0136
2023-02-06 14:21:50 | Train | Epoch[246/600] Iteration[006/030] Train loss: 0.0140
2023-02-06 14:21:50 | Train | Epoch[246/600] Iteration[007/030] Train loss: 0.0140
2023-02-06 14:21:50 | Train | Epoch[246/600] Iteration[008/030] Train loss: 0.0142
2023-02-06 14:21:50 | Train | Epoch[246/600] Iteration[009/030] Train loss: 0.0141
2023-02-06 14:21:51 | Train | Epoch[246/600] Iteration[010/030] Train loss: 0.0140
2023-02-06 14:21:51 | Train | Epoch[246/600] Iteration[011/030] Train loss: 0.0138
2023-02-06 14:21:51 | Train | Epoch[246/600] Iteration[012/030] Train loss: 0.0138
2023-02-06 14:21:51 | Train | Epoch[246/600] Iteration[013/030] Train loss: 0.0138
2023-02-06 14:21:51 | Train | Epoch[246/600] Iteration[014/030] Train loss: 0.0138
2023-02-06 14:21:52 | Train | Epoch[246/600] Iteration[015/030] Train loss: 0.0137
2023-02-06 14:21:52 | Train | Epoch[246/600] Iteration[016/030] Train loss: 0.0137
2023-02-06 14:21:52 | Train | Epoch[246/600] Iteration[017/030] Train loss: 0.0136
2023-02-06 14:21:52 | Train | Epoch[246/600] Iteration[018/030] Train loss: 0.0137
2023-02-06 14:21:53 | Train | Epoch[246/600] Iteration[019/030] Train loss: 0.0136
2023-02-06 14:21:53 | Train | Epoch[246/600] Iteration[020/030] Train loss: 0.0136
2023-02-06 14:21:53 | Train | Epoch[246/600] Iteration[021/030] Train loss: 0.0135
2023-02-06 14:21:53 | Train | Epoch[246/600] Iteration[022/030] Train loss: 0.0135
2023-02-06 14:21:53 | Train | Epoch[246/600] Iteration[023/030] Train loss: 0.0134
2023-02-06 14:21:54 | Train | Epoch[246/600] Iteration[024/030] Train loss: 0.0134
2023-02-06 14:21:54 | Train | Epoch[246/600] Iteration[025/030] Train loss: 0.0134
2023-02-06 14:21:54 | Train | Epoch[246/600] Iteration[026/030] Train loss: 0.0134
2023-02-06 14:21:54 | Train | Epoch[246/600] Iteration[027/030] Train loss: 0.0134
2023-02-06 14:21:55 | Train | Epoch[246/600] Iteration[028/030] Train loss: 0.0134
2023-02-06 14:21:55 | Train | Epoch[246/600] Iteration[029/030] Train loss: 0.0137
2023-02-06 14:21:55 | Train | Epoch[246/600] Iteration[030/030] Train loss: 0.0137
2023-02-06 14:21:55 | Valid | Epoch[246/600] Iteration[001/008] Valid loss: 0.1801
2023-02-06 14:21:55 | Valid | Epoch[246/600] Iteration[002/008] Valid loss: 0.1748
2023-02-06 14:21:55 | Valid | Epoch[246/600] Iteration[003/008] Valid loss: 0.1866
2023-02-06 14:21:55 | Valid | Epoch[246/600] Iteration[004/008] Valid loss: 0.1841
2023-02-06 14:21:55 | Valid | Epoch[246/600] Iteration[005/008] Valid loss: 0.1866
2023-02-06 14:21:55 | Valid | Epoch[246/600] Iteration[006/008] Valid loss: 0.1817
2023-02-06 14:21:55 | Valid | Epoch[246/600] Iteration[007/008] Valid loss: 0.1753
2023-02-06 14:21:56 | Valid | Epoch[246/600] Iteration[008/008] Valid loss: 0.1825
2023-02-06 14:21:56 | Valid | Epoch[246/600] MIou: 0.5786552325146825
2023-02-06 14:21:56 | Valid | Epoch[246/600] Pixel Accuracy: 0.9302660624186198
2023-02-06 14:21:56 | Valid | Epoch[246/600] Mean Pixel Accuracy: 0.6143085220354751
2023-02-06 14:21:56 | Stage | Epoch[246/600] Train loss:0.0137
2023-02-06 14:21:56 | Stage | Epoch[246/600] Valid loss:0.1825
2023-02-06 14:21:56 | Stage | Epoch[246/600] LR:0.01

2023-02-06 14:21:56 | Train | Epoch[247/600] Iteration[001/030] Train loss: 0.0135
2023-02-06 14:21:56 | Train | Epoch[247/600] Iteration[002/030] Train loss: 0.0131
2023-02-06 14:21:57 | Train | Epoch[247/600] Iteration[003/030] Train loss: 0.0135
2023-02-06 14:21:57 | Train | Epoch[247/600] Iteration[004/030] Train loss: 0.0136
2023-02-06 14:21:57 | Train | Epoch[247/600] Iteration[005/030] Train loss: 0.0134
2023-02-06 14:21:57 | Train | Epoch[247/600] Iteration[006/030] Train loss: 0.0133
2023-02-06 14:21:57 | Train | Epoch[247/600] Iteration[007/030] Train loss: 0.0137
2023-02-06 14:21:58 | Train | Epoch[247/600] Iteration[008/030] Train loss: 0.0135
2023-02-06 14:21:58 | Train | Epoch[247/600] Iteration[009/030] Train loss: 0.0135
2023-02-06 14:21:58 | Train | Epoch[247/600] Iteration[010/030] Train loss: 0.0134
2023-02-06 14:21:58 | Train | Epoch[247/600] Iteration[011/030] Train loss: 0.0134
2023-02-06 14:21:59 | Train | Epoch[247/600] Iteration[012/030] Train loss: 0.0134
2023-02-06 14:21:59 | Train | Epoch[247/600] Iteration[013/030] Train loss: 0.0134
2023-02-06 14:21:59 | Train | Epoch[247/600] Iteration[014/030] Train loss: 0.0136
2023-02-06 14:21:59 | Train | Epoch[247/600] Iteration[015/030] Train loss: 0.0136
2023-02-06 14:21:59 | Train | Epoch[247/600] Iteration[016/030] Train loss: 0.0136
2023-02-06 14:22:00 | Train | Epoch[247/600] Iteration[017/030] Train loss: 0.0135
2023-02-06 14:22:00 | Train | Epoch[247/600] Iteration[018/030] Train loss: 0.0135
2023-02-06 14:22:00 | Train | Epoch[247/600] Iteration[019/030] Train loss: 0.0135
2023-02-06 14:22:00 | Train | Epoch[247/600] Iteration[020/030] Train loss: 0.0135
2023-02-06 14:22:00 | Train | Epoch[247/600] Iteration[021/030] Train loss: 0.0135
2023-02-06 14:22:01 | Train | Epoch[247/600] Iteration[022/030] Train loss: 0.0136
2023-02-06 14:22:01 | Train | Epoch[247/600] Iteration[023/030] Train loss: 0.0136
2023-02-06 14:22:01 | Train | Epoch[247/600] Iteration[024/030] Train loss: 0.0136
2023-02-06 14:22:01 | Train | Epoch[247/600] Iteration[025/030] Train loss: 0.0136
2023-02-06 14:22:02 | Train | Epoch[247/600] Iteration[026/030] Train loss: 0.0136
2023-02-06 14:22:02 | Train | Epoch[247/600] Iteration[027/030] Train loss: 0.0136
2023-02-06 14:22:02 | Train | Epoch[247/600] Iteration[028/030] Train loss: 0.0137
2023-02-06 14:22:02 | Train | Epoch[247/600] Iteration[029/030] Train loss: 0.0137
2023-02-06 14:22:02 | Train | Epoch[247/600] Iteration[030/030] Train loss: 0.0137
2023-02-06 14:22:03 | Valid | Epoch[247/600] Iteration[001/008] Valid loss: 0.2976
2023-02-06 14:22:03 | Valid | Epoch[247/600] Iteration[002/008] Valid loss: 0.2513
2023-02-06 14:22:03 | Valid | Epoch[247/600] Iteration[003/008] Valid loss: 0.2475
2023-02-06 14:22:03 | Valid | Epoch[247/600] Iteration[004/008] Valid loss: 0.2460
2023-02-06 14:22:03 | Valid | Epoch[247/600] Iteration[005/008] Valid loss: 0.2523
2023-02-06 14:22:03 | Valid | Epoch[247/600] Iteration[006/008] Valid loss: 0.2481
2023-02-06 14:22:03 | Valid | Epoch[247/600] Iteration[007/008] Valid loss: 0.2782
2023-02-06 14:22:03 | Valid | Epoch[247/600] Iteration[008/008] Valid loss: 0.2845
2023-02-06 14:22:03 | Valid | Epoch[247/600] MIou: 0.9040153377038642
2023-02-06 14:22:03 | Valid | Epoch[247/600] Pixel Accuracy: 0.98199462890625
2023-02-06 14:22:03 | Valid | Epoch[247/600] Mean Pixel Accuracy: 0.9711644917297884
2023-02-06 14:22:03 | Stage | Epoch[247/600] Train loss:0.0137
2023-02-06 14:22:03 | Stage | Epoch[247/600] Valid loss:0.2845
2023-02-06 14:22:03 | Stage | Epoch[247/600] LR:0.01

2023-02-06 14:22:04 | Train | Epoch[248/600] Iteration[001/030] Train loss: 0.0130
2023-02-06 14:22:04 | Train | Epoch[248/600] Iteration[002/030] Train loss: 0.0131
2023-02-06 14:22:04 | Train | Epoch[248/600] Iteration[003/030] Train loss: 0.0131
2023-02-06 14:22:04 | Train | Epoch[248/600] Iteration[004/030] Train loss: 0.0130
2023-02-06 14:22:04 | Train | Epoch[248/600] Iteration[005/030] Train loss: 0.0130
2023-02-06 14:22:05 | Train | Epoch[248/600] Iteration[006/030] Train loss: 0.0131
2023-02-06 14:22:05 | Train | Epoch[248/600] Iteration[007/030] Train loss: 0.0133
2023-02-06 14:22:05 | Train | Epoch[248/600] Iteration[008/030] Train loss: 0.0133
2023-02-06 14:22:05 | Train | Epoch[248/600] Iteration[009/030] Train loss: 0.0132
2023-02-06 14:22:06 | Train | Epoch[248/600] Iteration[010/030] Train loss: 0.0133
2023-02-06 14:22:06 | Train | Epoch[248/600] Iteration[011/030] Train loss: 0.0133
2023-02-06 14:22:06 | Train | Epoch[248/600] Iteration[012/030] Train loss: 0.0134
2023-02-06 14:22:06 | Train | Epoch[248/600] Iteration[013/030] Train loss: 0.0133
2023-02-06 14:22:06 | Train | Epoch[248/600] Iteration[014/030] Train loss: 0.0133
2023-02-06 14:22:07 | Train | Epoch[248/600] Iteration[015/030] Train loss: 0.0134
2023-02-06 14:22:07 | Train | Epoch[248/600] Iteration[016/030] Train loss: 0.0133
2023-02-06 14:22:07 | Train | Epoch[248/600] Iteration[017/030] Train loss: 0.0135
2023-02-06 14:22:07 | Train | Epoch[248/600] Iteration[018/030] Train loss: 0.0135
2023-02-06 14:22:08 | Train | Epoch[248/600] Iteration[019/030] Train loss: 0.0135
2023-02-06 14:22:08 | Train | Epoch[248/600] Iteration[020/030] Train loss: 0.0134
2023-02-06 14:22:08 | Train | Epoch[248/600] Iteration[021/030] Train loss: 0.0135
2023-02-06 14:22:08 | Train | Epoch[248/600] Iteration[022/030] Train loss: 0.0135
2023-02-06 14:22:08 | Train | Epoch[248/600] Iteration[023/030] Train loss: 0.0135
2023-02-06 14:22:09 | Train | Epoch[248/600] Iteration[024/030] Train loss: 0.0135
2023-02-06 14:22:09 | Train | Epoch[248/600] Iteration[025/030] Train loss: 0.0135
2023-02-06 14:22:09 | Train | Epoch[248/600] Iteration[026/030] Train loss: 0.0138
2023-02-06 14:22:09 | Train | Epoch[248/600] Iteration[027/030] Train loss: 0.0138
2023-02-06 14:22:10 | Train | Epoch[248/600] Iteration[028/030] Train loss: 0.0138
2023-02-06 14:22:10 | Train | Epoch[248/600] Iteration[029/030] Train loss: 0.0138
2023-02-06 14:22:10 | Train | Epoch[248/600] Iteration[030/030] Train loss: 0.0138
2023-02-06 14:22:10 | Valid | Epoch[248/600] Iteration[001/008] Valid loss: 0.0921
2023-02-06 14:22:10 | Valid | Epoch[248/600] Iteration[002/008] Valid loss: 0.0911
2023-02-06 14:22:10 | Valid | Epoch[248/600] Iteration[003/008] Valid loss: 0.0840
2023-02-06 14:22:10 | Valid | Epoch[248/600] Iteration[004/008] Valid loss: 0.0785
2023-02-06 14:22:10 | Valid | Epoch[248/600] Iteration[005/008] Valid loss: 0.0802
2023-02-06 14:22:10 | Valid | Epoch[248/600] Iteration[006/008] Valid loss: 0.0810
2023-02-06 14:22:11 | Valid | Epoch[248/600] Iteration[007/008] Valid loss: 0.0839
2023-02-06 14:22:11 | Valid | Epoch[248/600] Iteration[008/008] Valid loss: 0.0851
2023-02-06 14:22:11 | Valid | Epoch[248/600] MIou: 0.9006460081467051
2023-02-06 14:22:11 | Valid | Epoch[248/600] Pixel Accuracy: 0.9828618367513021
2023-02-06 14:22:11 | Valid | Epoch[248/600] Mean Pixel Accuracy: 0.9292107107881109
2023-02-06 14:22:11 | Stage | Epoch[248/600] Train loss:0.0138
2023-02-06 14:22:11 | Stage | Epoch[248/600] Valid loss:0.0851
2023-02-06 14:22:11 | Stage | Epoch[248/600] LR:0.01

2023-02-06 14:22:11 | Train | Epoch[249/600] Iteration[001/030] Train loss: 0.0136
2023-02-06 14:22:11 | Train | Epoch[249/600] Iteration[002/030] Train loss: 0.0143
2023-02-06 14:22:12 | Train | Epoch[249/600] Iteration[003/030] Train loss: 0.0143
2023-02-06 14:22:12 | Train | Epoch[249/600] Iteration[004/030] Train loss: 0.0145
2023-02-06 14:22:12 | Train | Epoch[249/600] Iteration[005/030] Train loss: 0.0140
2023-02-06 14:22:12 | Train | Epoch[249/600] Iteration[006/030] Train loss: 0.0138
2023-02-06 14:22:12 | Train | Epoch[249/600] Iteration[007/030] Train loss: 0.0137
2023-02-06 14:22:13 | Train | Epoch[249/600] Iteration[008/030] Train loss: 0.0136
2023-02-06 14:22:13 | Train | Epoch[249/600] Iteration[009/030] Train loss: 0.0133
2023-02-06 14:22:13 | Train | Epoch[249/600] Iteration[010/030] Train loss: 0.0133
2023-02-06 14:22:13 | Train | Epoch[249/600] Iteration[011/030] Train loss: 0.0131
2023-02-06 14:22:14 | Train | Epoch[249/600] Iteration[012/030] Train loss: 0.0132
2023-02-06 14:22:14 | Train | Epoch[249/600] Iteration[013/030] Train loss: 0.0133
2023-02-06 14:22:14 | Train | Epoch[249/600] Iteration[014/030] Train loss: 0.0133
2023-02-06 14:22:14 | Train | Epoch[249/600] Iteration[015/030] Train loss: 0.0132
2023-02-06 14:22:14 | Train | Epoch[249/600] Iteration[016/030] Train loss: 0.0132
2023-02-06 14:22:15 | Train | Epoch[249/600] Iteration[017/030] Train loss: 0.0132
2023-02-06 14:22:15 | Train | Epoch[249/600] Iteration[018/030] Train loss: 0.0132
2023-02-06 14:22:15 | Train | Epoch[249/600] Iteration[019/030] Train loss: 0.0132
2023-02-06 14:22:15 | Train | Epoch[249/600] Iteration[020/030] Train loss: 0.0132
2023-02-06 14:22:16 | Train | Epoch[249/600] Iteration[021/030] Train loss: 0.0131
2023-02-06 14:22:16 | Train | Epoch[249/600] Iteration[022/030] Train loss: 0.0131
2023-02-06 14:22:16 | Train | Epoch[249/600] Iteration[023/030] Train loss: 0.0131
2023-02-06 14:22:16 | Train | Epoch[249/600] Iteration[024/030] Train loss: 0.0131
2023-02-06 14:22:16 | Train | Epoch[249/600] Iteration[025/030] Train loss: 0.0130
2023-02-06 14:22:17 | Train | Epoch[249/600] Iteration[026/030] Train loss: 0.0130
2023-02-06 14:22:17 | Train | Epoch[249/600] Iteration[027/030] Train loss: 0.0131
2023-02-06 14:22:17 | Train | Epoch[249/600] Iteration[028/030] Train loss: 0.0131
2023-02-06 14:22:17 | Train | Epoch[249/600] Iteration[029/030] Train loss: 0.0132
2023-02-06 14:22:17 | Train | Epoch[249/600] Iteration[030/030] Train loss: 0.0132
2023-02-06 14:22:18 | Valid | Epoch[249/600] Iteration[001/008] Valid loss: 0.1577
2023-02-06 14:22:18 | Valid | Epoch[249/600] Iteration[002/008] Valid loss: 0.1137
2023-02-06 14:22:18 | Valid | Epoch[249/600] Iteration[003/008] Valid loss: 0.1079
2023-02-06 14:22:18 | Valid | Epoch[249/600] Iteration[004/008] Valid loss: 0.1014
2023-02-06 14:22:18 | Valid | Epoch[249/600] Iteration[005/008] Valid loss: 0.1025
2023-02-06 14:22:18 | Valid | Epoch[249/600] Iteration[006/008] Valid loss: 0.0991
2023-02-06 14:22:18 | Valid | Epoch[249/600] Iteration[007/008] Valid loss: 0.1028
2023-02-06 14:22:18 | Valid | Epoch[249/600] Iteration[008/008] Valid loss: 0.1012
2023-02-06 14:22:18 | Valid | Epoch[249/600] MIou: 0.929416694599247
2023-02-06 14:22:18 | Valid | Epoch[249/600] Pixel Accuracy: 0.9877395629882812
2023-02-06 14:22:18 | Valid | Epoch[249/600] Mean Pixel Accuracy: 0.9601829010448473
2023-02-06 14:22:18 | Stage | Epoch[249/600] Train loss:0.0132
2023-02-06 14:22:18 | Stage | Epoch[249/600] Valid loss:0.1012
2023-02-06 14:22:18 | Stage | Epoch[249/600] LR:0.01

2023-02-06 14:22:19 | Train | Epoch[250/600] Iteration[001/030] Train loss: 0.0112
2023-02-06 14:22:19 | Train | Epoch[250/600] Iteration[002/030] Train loss: 0.0121
2023-02-06 14:22:19 | Train | Epoch[250/600] Iteration[003/030] Train loss: 0.0131
2023-02-06 14:22:19 | Train | Epoch[250/600] Iteration[004/030] Train loss: 0.0126
2023-02-06 14:22:19 | Train | Epoch[250/600] Iteration[005/030] Train loss: 0.0126
2023-02-06 14:22:20 | Train | Epoch[250/600] Iteration[006/030] Train loss: 0.0129
2023-02-06 14:22:20 | Train | Epoch[250/600] Iteration[007/030] Train loss: 0.0128
2023-02-06 14:22:20 | Train | Epoch[250/600] Iteration[008/030] Train loss: 0.0127
2023-02-06 14:22:20 | Train | Epoch[250/600] Iteration[009/030] Train loss: 0.0125
2023-02-06 14:22:21 | Train | Epoch[250/600] Iteration[010/030] Train loss: 0.0124
2023-02-06 14:22:21 | Train | Epoch[250/600] Iteration[011/030] Train loss: 0.0125
2023-02-06 14:22:21 | Train | Epoch[250/600] Iteration[012/030] Train loss: 0.0124
2023-02-06 14:22:21 | Train | Epoch[250/600] Iteration[013/030] Train loss: 0.0124
2023-02-06 14:22:21 | Train | Epoch[250/600] Iteration[014/030] Train loss: 0.0125
2023-02-06 14:22:22 | Train | Epoch[250/600] Iteration[015/030] Train loss: 0.0125
2023-02-06 14:22:22 | Train | Epoch[250/600] Iteration[016/030] Train loss: 0.0126
2023-02-06 14:22:22 | Train | Epoch[250/600] Iteration[017/030] Train loss: 0.0127
2023-02-06 14:22:22 | Train | Epoch[250/600] Iteration[018/030] Train loss: 0.0127
2023-02-06 14:22:23 | Train | Epoch[250/600] Iteration[019/030] Train loss: 0.0128
2023-02-06 14:22:23 | Train | Epoch[250/600] Iteration[020/030] Train loss: 0.0128
2023-02-06 14:22:23 | Train | Epoch[250/600] Iteration[021/030] Train loss: 0.0129
2023-02-06 14:22:23 | Train | Epoch[250/600] Iteration[022/030] Train loss: 0.0129
2023-02-06 14:22:23 | Train | Epoch[250/600] Iteration[023/030] Train loss: 0.0128
2023-02-06 14:22:24 | Train | Epoch[250/600] Iteration[024/030] Train loss: 0.0128
2023-02-06 14:22:24 | Train | Epoch[250/600] Iteration[025/030] Train loss: 0.0129
2023-02-06 14:22:24 | Train | Epoch[250/600] Iteration[026/030] Train loss: 0.0129
2023-02-06 14:22:24 | Train | Epoch[250/600] Iteration[027/030] Train loss: 0.0129
2023-02-06 14:22:25 | Train | Epoch[250/600] Iteration[028/030] Train loss: 0.0129
2023-02-06 14:22:25 | Train | Epoch[250/600] Iteration[029/030] Train loss: 0.0129
2023-02-06 14:22:25 | Train | Epoch[250/600] Iteration[030/030] Train loss: 0.0129
2023-02-06 14:22:25 | Valid | Epoch[250/600] Iteration[001/008] Valid loss: 0.1824
2023-02-06 14:22:25 | Valid | Epoch[250/600] Iteration[002/008] Valid loss: 0.1358
2023-02-06 14:22:25 | Valid | Epoch[250/600] Iteration[003/008] Valid loss: 0.1245
2023-02-06 14:22:25 | Valid | Epoch[250/600] Iteration[004/008] Valid loss: 0.1140
2023-02-06 14:22:25 | Valid | Epoch[250/600] Iteration[005/008] Valid loss: 0.1152
2023-02-06 14:22:25 | Valid | Epoch[250/600] Iteration[006/008] Valid loss: 0.1113
2023-02-06 14:22:26 | Valid | Epoch[250/600] Iteration[007/008] Valid loss: 0.1186
2023-02-06 14:22:26 | Valid | Epoch[250/600] Iteration[008/008] Valid loss: 0.1167
2023-02-06 14:22:26 | Valid | Epoch[250/600] MIou: 0.9284850881334497
2023-02-06 14:22:26 | Valid | Epoch[250/600] Pixel Accuracy: 0.9874649047851562
2023-02-06 14:22:26 | Valid | Epoch[250/600] Mean Pixel Accuracy: 0.9635065155711405
2023-02-06 14:22:26 | Stage | Epoch[250/600] Train loss:0.0129
2023-02-06 14:22:26 | Stage | Epoch[250/600] Valid loss:0.1167
2023-02-06 14:22:26 | Stage | Epoch[250/600] LR:0.01

2023-02-06 14:22:26 | Train | Epoch[251/600] Iteration[001/030] Train loss: 0.0109
2023-02-06 14:22:26 | Train | Epoch[251/600] Iteration[002/030] Train loss: 0.0120
2023-02-06 14:22:27 | Train | Epoch[251/600] Iteration[003/030] Train loss: 0.0121
2023-02-06 14:22:27 | Train | Epoch[251/600] Iteration[004/030] Train loss: 0.0122
2023-02-06 14:22:27 | Train | Epoch[251/600] Iteration[005/030] Train loss: 0.0124
2023-02-06 14:22:27 | Train | Epoch[251/600] Iteration[006/030] Train loss: 0.0124
2023-02-06 14:22:27 | Train | Epoch[251/600] Iteration[007/030] Train loss: 0.0125
2023-02-06 14:22:28 | Train | Epoch[251/600] Iteration[008/030] Train loss: 0.0124
2023-02-06 14:22:28 | Train | Epoch[251/600] Iteration[009/030] Train loss: 0.0123
2023-02-06 14:22:28 | Train | Epoch[251/600] Iteration[010/030] Train loss: 0.0124
2023-02-06 14:22:28 | Train | Epoch[251/600] Iteration[011/030] Train loss: 0.0127
2023-02-06 14:22:29 | Train | Epoch[251/600] Iteration[012/030] Train loss: 0.0126
2023-02-06 14:22:29 | Train | Epoch[251/600] Iteration[013/030] Train loss: 0.0127
2023-02-06 14:22:29 | Train | Epoch[251/600] Iteration[014/030] Train loss: 0.0127
2023-02-06 14:22:29 | Train | Epoch[251/600] Iteration[015/030] Train loss: 0.0127
2023-02-06 14:22:29 | Train | Epoch[251/600] Iteration[016/030] Train loss: 0.0127
2023-02-06 14:22:30 | Train | Epoch[251/600] Iteration[017/030] Train loss: 0.0126
2023-02-06 14:22:30 | Train | Epoch[251/600] Iteration[018/030] Train loss: 0.0126
2023-02-06 14:22:30 | Train | Epoch[251/600] Iteration[019/030] Train loss: 0.0126
2023-02-06 14:22:30 | Train | Epoch[251/600] Iteration[020/030] Train loss: 0.0127
2023-02-06 14:22:31 | Train | Epoch[251/600] Iteration[021/030] Train loss: 0.0127
2023-02-06 14:22:31 | Train | Epoch[251/600] Iteration[022/030] Train loss: 0.0127
2023-02-06 14:22:31 | Train | Epoch[251/600] Iteration[023/030] Train loss: 0.0128
2023-02-06 14:22:31 | Train | Epoch[251/600] Iteration[024/030] Train loss: 0.0128
2023-02-06 14:22:31 | Train | Epoch[251/600] Iteration[025/030] Train loss: 0.0127
2023-02-06 14:22:32 | Train | Epoch[251/600] Iteration[026/030] Train loss: 0.0127
2023-02-06 14:22:32 | Train | Epoch[251/600] Iteration[027/030] Train loss: 0.0127
2023-02-06 14:22:32 | Train | Epoch[251/600] Iteration[028/030] Train loss: 0.0126
2023-02-06 14:22:32 | Train | Epoch[251/600] Iteration[029/030] Train loss: 0.0127
2023-02-06 14:22:32 | Train | Epoch[251/600] Iteration[030/030] Train loss: 0.0127
2023-02-06 14:22:33 | Valid | Epoch[251/600] Iteration[001/008] Valid loss: 0.0785
2023-02-06 14:22:33 | Valid | Epoch[251/600] Iteration[002/008] Valid loss: 0.0644
2023-02-06 14:22:33 | Valid | Epoch[251/600] Iteration[003/008] Valid loss: 0.0618
2023-02-06 14:22:33 | Valid | Epoch[251/600] Iteration[004/008] Valid loss: 0.0576
2023-02-06 14:22:33 | Valid | Epoch[251/600] Iteration[005/008] Valid loss: 0.0563
2023-02-06 14:22:33 | Valid | Epoch[251/600] Iteration[006/008] Valid loss: 0.0541
2023-02-06 14:22:33 | Valid | Epoch[251/600] Iteration[007/008] Valid loss: 0.0531
2023-02-06 14:22:33 | Valid | Epoch[251/600] Iteration[008/008] Valid loss: 0.0522
2023-02-06 14:22:33 | Valid | Epoch[251/600] MIou: 0.9028142958996984
2023-02-06 14:22:33 | Valid | Epoch[251/600] Pixel Accuracy: 0.9836705525716146
2023-02-06 14:22:33 | Valid | Epoch[251/600] Mean Pixel Accuracy: 0.9200557416245614
2023-02-06 14:22:33 | Stage | Epoch[251/600] Train loss:0.0127
2023-02-06 14:22:33 | Stage | Epoch[251/600] Valid loss:0.0522
2023-02-06 14:22:33 | Stage | Epoch[251/600] LR:0.01

2023-02-06 14:22:34 | Train | Epoch[252/600] Iteration[001/030] Train loss: 0.0117
2023-02-06 14:22:34 | Train | Epoch[252/600] Iteration[002/030] Train loss: 0.0115
2023-02-06 14:22:34 | Train | Epoch[252/600] Iteration[003/030] Train loss: 0.0118
2023-02-06 14:22:34 | Train | Epoch[252/600] Iteration[004/030] Train loss: 0.0118
2023-02-06 14:22:35 | Train | Epoch[252/600] Iteration[005/030] Train loss: 0.0116
2023-02-06 14:22:35 | Train | Epoch[252/600] Iteration[006/030] Train loss: 0.0118
2023-02-06 14:22:35 | Train | Epoch[252/600] Iteration[007/030] Train loss: 0.0117
2023-02-06 14:22:35 | Train | Epoch[252/600] Iteration[008/030] Train loss: 0.0119
2023-02-06 14:22:35 | Train | Epoch[252/600] Iteration[009/030] Train loss: 0.0120
2023-02-06 14:22:36 | Train | Epoch[252/600] Iteration[010/030] Train loss: 0.0121
2023-02-06 14:22:36 | Train | Epoch[252/600] Iteration[011/030] Train loss: 0.0124
2023-02-06 14:22:36 | Train | Epoch[252/600] Iteration[012/030] Train loss: 0.0123
2023-02-06 14:22:36 | Train | Epoch[252/600] Iteration[013/030] Train loss: 0.0124
2023-02-06 14:22:37 | Train | Epoch[252/600] Iteration[014/030] Train loss: 0.0124
2023-02-06 14:22:37 | Train | Epoch[252/600] Iteration[015/030] Train loss: 0.0124
2023-02-06 14:22:37 | Train | Epoch[252/600] Iteration[016/030] Train loss: 0.0123
2023-02-06 14:22:37 | Train | Epoch[252/600] Iteration[017/030] Train loss: 0.0124
2023-02-06 14:22:37 | Train | Epoch[252/600] Iteration[018/030] Train loss: 0.0125
2023-02-06 14:22:38 | Train | Epoch[252/600] Iteration[019/030] Train loss: 0.0125
2023-02-06 14:22:38 | Train | Epoch[252/600] Iteration[020/030] Train loss: 0.0124
2023-02-06 14:22:38 | Train | Epoch[252/600] Iteration[021/030] Train loss: 0.0124
2023-02-06 14:22:38 | Train | Epoch[252/600] Iteration[022/030] Train loss: 0.0123
2023-02-06 14:22:39 | Train | Epoch[252/600] Iteration[023/030] Train loss: 0.0123
2023-02-06 14:22:39 | Train | Epoch[252/600] Iteration[024/030] Train loss: 0.0125
2023-02-06 14:22:39 | Train | Epoch[252/600] Iteration[025/030] Train loss: 0.0125
2023-02-06 14:22:39 | Train | Epoch[252/600] Iteration[026/030] Train loss: 0.0125
2023-02-06 14:22:39 | Train | Epoch[252/600] Iteration[027/030] Train loss: 0.0126
2023-02-06 14:22:40 | Train | Epoch[252/600] Iteration[028/030] Train loss: 0.0126
2023-02-06 14:22:40 | Train | Epoch[252/600] Iteration[029/030] Train loss: 0.0126
2023-02-06 14:22:40 | Train | Epoch[252/600] Iteration[030/030] Train loss: 0.0126
2023-02-06 14:22:40 | Valid | Epoch[252/600] Iteration[001/008] Valid loss: 0.8174
2023-02-06 14:22:40 | Valid | Epoch[252/600] Iteration[002/008] Valid loss: 0.7624
2023-02-06 14:22:40 | Valid | Epoch[252/600] Iteration[003/008] Valid loss: 0.7807
2023-02-06 14:22:40 | Valid | Epoch[252/600] Iteration[004/008] Valid loss: 0.7679
2023-02-06 14:22:41 | Valid | Epoch[252/600] Iteration[005/008] Valid loss: 0.7870
2023-02-06 14:22:41 | Valid | Epoch[252/600] Iteration[006/008] Valid loss: 0.7761
2023-02-06 14:22:41 | Valid | Epoch[252/600] Iteration[007/008] Valid loss: 0.8228
2023-02-06 14:22:41 | Valid | Epoch[252/600] Iteration[008/008] Valid loss: 0.8624
2023-02-06 14:22:41 | Valid | Epoch[252/600] MIou: 0.8756993191561948
2023-02-06 14:22:41 | Valid | Epoch[252/600] Pixel Accuracy: 0.9746971130371094
2023-02-06 14:22:41 | Valid | Epoch[252/600] Mean Pixel Accuracy: 0.9809376508438458
2023-02-06 14:22:41 | Stage | Epoch[252/600] Train loss:0.0126
2023-02-06 14:22:41 | Stage | Epoch[252/600] Valid loss:0.8624
2023-02-06 14:22:41 | Stage | Epoch[252/600] LR:0.01

2023-02-06 14:22:41 | Train | Epoch[253/600] Iteration[001/030] Train loss: 0.0112
2023-02-06 14:22:41 | Train | Epoch[253/600] Iteration[002/030] Train loss: 0.0108
2023-02-06 14:22:42 | Train | Epoch[253/600] Iteration[003/030] Train loss: 0.0112
2023-02-06 14:22:42 | Train | Epoch[253/600] Iteration[004/030] Train loss: 0.0120
2023-02-06 14:22:42 | Train | Epoch[253/600] Iteration[005/030] Train loss: 0.0118
2023-02-06 14:22:42 | Train | Epoch[253/600] Iteration[006/030] Train loss: 0.0118
2023-02-06 14:22:43 | Train | Epoch[253/600] Iteration[007/030] Train loss: 0.0122
2023-02-06 14:22:43 | Train | Epoch[253/600] Iteration[008/030] Train loss: 0.0122
2023-02-06 14:22:43 | Train | Epoch[253/600] Iteration[009/030] Train loss: 0.0124
2023-02-06 14:22:43 | Train | Epoch[253/600] Iteration[010/030] Train loss: 0.0123
2023-02-06 14:22:43 | Train | Epoch[253/600] Iteration[011/030] Train loss: 0.0123
2023-02-06 14:22:44 | Train | Epoch[253/600] Iteration[012/030] Train loss: 0.0124
2023-02-06 14:22:44 | Train | Epoch[253/600] Iteration[013/030] Train loss: 0.0125
2023-02-06 14:22:44 | Train | Epoch[253/600] Iteration[014/030] Train loss: 0.0125
2023-02-06 14:22:44 | Train | Epoch[253/600] Iteration[015/030] Train loss: 0.0125
2023-02-06 14:22:44 | Train | Epoch[253/600] Iteration[016/030] Train loss: 0.0125
2023-02-06 14:22:45 | Train | Epoch[253/600] Iteration[017/030] Train loss: 0.0125
2023-02-06 14:22:45 | Train | Epoch[253/600] Iteration[018/030] Train loss: 0.0126
2023-02-06 14:22:45 | Train | Epoch[253/600] Iteration[019/030] Train loss: 0.0127
2023-02-06 14:22:45 | Train | Epoch[253/600] Iteration[020/030] Train loss: 0.0126
2023-02-06 14:22:46 | Train | Epoch[253/600] Iteration[021/030] Train loss: 0.0127
2023-02-06 14:22:46 | Train | Epoch[253/600] Iteration[022/030] Train loss: 0.0127
2023-02-06 14:22:46 | Train | Epoch[253/600] Iteration[023/030] Train loss: 0.0127
2023-02-06 14:22:46 | Train | Epoch[253/600] Iteration[024/030] Train loss: 0.0127
2023-02-06 14:22:46 | Train | Epoch[253/600] Iteration[025/030] Train loss: 0.0127
2023-02-06 14:22:47 | Train | Epoch[253/600] Iteration[026/030] Train loss: 0.0127
2023-02-06 14:22:47 | Train | Epoch[253/600] Iteration[027/030] Train loss: 0.0129
2023-02-06 14:22:47 | Train | Epoch[253/600] Iteration[028/030] Train loss: 0.0129
2023-02-06 14:22:47 | Train | Epoch[253/600] Iteration[029/030] Train loss: 0.0129
2023-02-06 14:22:47 | Train | Epoch[253/600] Iteration[030/030] Train loss: 0.0128
2023-02-06 14:22:48 | Valid | Epoch[253/600] Iteration[001/008] Valid loss: 0.4846
2023-02-06 14:22:48 | Valid | Epoch[253/600] Iteration[002/008] Valid loss: 0.4447
2023-02-06 14:22:48 | Valid | Epoch[253/600] Iteration[003/008] Valid loss: 0.4645
2023-02-06 14:22:48 | Valid | Epoch[253/600] Iteration[004/008] Valid loss: 0.4603
2023-02-06 14:22:48 | Valid | Epoch[253/600] Iteration[005/008] Valid loss: 0.4808
2023-02-06 14:22:48 | Valid | Epoch[253/600] Iteration[006/008] Valid loss: 0.4763
2023-02-06 14:22:48 | Valid | Epoch[253/600] Iteration[007/008] Valid loss: 0.5154
2023-02-06 14:22:48 | Valid | Epoch[253/600] Iteration[008/008] Valid loss: 0.5351
2023-02-06 14:22:48 | Valid | Epoch[253/600] MIou: 0.8963560628198868
2023-02-06 14:22:48 | Valid | Epoch[253/600] Pixel Accuracy: 0.9799346923828125
2023-02-06 14:22:48 | Valid | Epoch[253/600] Mean Pixel Accuracy: 0.9785665374175987
2023-02-06 14:22:48 | Stage | Epoch[253/600] Train loss:0.0128
2023-02-06 14:22:48 | Stage | Epoch[253/600] Valid loss:0.5351
2023-02-06 14:22:48 | Stage | Epoch[253/600] LR:0.01

2023-02-06 14:22:49 | Train | Epoch[254/600] Iteration[001/030] Train loss: 0.0123
2023-02-06 14:22:49 | Train | Epoch[254/600] Iteration[002/030] Train loss: 0.0122
2023-02-06 14:22:49 | Train | Epoch[254/600] Iteration[003/030] Train loss: 0.0125
2023-02-06 14:22:49 | Train | Epoch[254/600] Iteration[004/030] Train loss: 0.0130
2023-02-06 14:22:50 | Train | Epoch[254/600] Iteration[005/030] Train loss: 0.0126
2023-02-06 14:22:50 | Train | Epoch[254/600] Iteration[006/030] Train loss: 0.0126
2023-02-06 14:22:50 | Train | Epoch[254/600] Iteration[007/030] Train loss: 0.0129
2023-02-06 14:22:50 | Train | Epoch[254/600] Iteration[008/030] Train loss: 0.0128
2023-02-06 14:22:50 | Train | Epoch[254/600] Iteration[009/030] Train loss: 0.0128
2023-02-06 14:22:51 | Train | Epoch[254/600] Iteration[010/030] Train loss: 0.0129
2023-02-06 14:22:51 | Train | Epoch[254/600] Iteration[011/030] Train loss: 0.0129
2023-02-06 14:22:51 | Train | Epoch[254/600] Iteration[012/030] Train loss: 0.0130
2023-02-06 14:22:51 | Train | Epoch[254/600] Iteration[013/030] Train loss: 0.0130
2023-02-06 14:22:52 | Train | Epoch[254/600] Iteration[014/030] Train loss: 0.0129
2023-02-06 14:22:52 | Train | Epoch[254/600] Iteration[015/030] Train loss: 0.0130
2023-02-06 14:22:52 | Train | Epoch[254/600] Iteration[016/030] Train loss: 0.0132
2023-02-06 14:22:52 | Train | Epoch[254/600] Iteration[017/030] Train loss: 0.0132
2023-02-06 14:22:52 | Train | Epoch[254/600] Iteration[018/030] Train loss: 0.0131
2023-02-06 14:22:53 | Train | Epoch[254/600] Iteration[019/030] Train loss: 0.0131
2023-02-06 14:22:53 | Train | Epoch[254/600] Iteration[020/030] Train loss: 0.0131
2023-02-06 14:22:53 | Train | Epoch[254/600] Iteration[021/030] Train loss: 0.0131
2023-02-06 14:22:53 | Train | Epoch[254/600] Iteration[022/030] Train loss: 0.0130
2023-02-06 14:22:54 | Train | Epoch[254/600] Iteration[023/030] Train loss: 0.0130
2023-02-06 14:22:54 | Train | Epoch[254/600] Iteration[024/030] Train loss: 0.0130
2023-02-06 14:22:54 | Train | Epoch[254/600] Iteration[025/030] Train loss: 0.0131
2023-02-06 14:22:54 | Train | Epoch[254/600] Iteration[026/030] Train loss: 0.0130
2023-02-06 14:22:54 | Train | Epoch[254/600] Iteration[027/030] Train loss: 0.0130
2023-02-06 14:22:55 | Train | Epoch[254/600] Iteration[028/030] Train loss: 0.0130
2023-02-06 14:22:55 | Train | Epoch[254/600] Iteration[029/030] Train loss: 0.0131
2023-02-06 14:22:55 | Train | Epoch[254/600] Iteration[030/030] Train loss: 0.0130
2023-02-06 14:22:55 | Valid | Epoch[254/600] Iteration[001/008] Valid loss: 0.1192
2023-02-06 14:22:55 | Valid | Epoch[254/600] Iteration[002/008] Valid loss: 0.1016
2023-02-06 14:22:55 | Valid | Epoch[254/600] Iteration[003/008] Valid loss: 0.0966
2023-02-06 14:22:55 | Valid | Epoch[254/600] Iteration[004/008] Valid loss: 0.0914
2023-02-06 14:22:56 | Valid | Epoch[254/600] Iteration[005/008] Valid loss: 0.0863
2023-02-06 14:22:56 | Valid | Epoch[254/600] Iteration[006/008] Valid loss: 0.0849
2023-02-06 14:22:56 | Valid | Epoch[254/600] Iteration[007/008] Valid loss: 0.0898
2023-02-06 14:22:56 | Valid | Epoch[254/600] Iteration[008/008] Valid loss: 0.0876
2023-02-06 14:22:56 | Valid | Epoch[254/600] MIou: 0.9065237392662
2023-02-06 14:22:56 | Valid | Epoch[254/600] Pixel Accuracy: 0.9840838114420573
2023-02-06 14:22:56 | Valid | Epoch[254/600] Mean Pixel Accuracy: 0.9292229511568537
2023-02-06 14:22:56 | Stage | Epoch[254/600] Train loss:0.0130
2023-02-06 14:22:56 | Stage | Epoch[254/600] Valid loss:0.0876
2023-02-06 14:22:56 | Stage | Epoch[254/600] LR:0.01

2023-02-06 14:22:56 | Train | Epoch[255/600] Iteration[001/030] Train loss: 0.0135
2023-02-06 14:22:56 | Train | Epoch[255/600] Iteration[002/030] Train loss: 0.0124
2023-02-06 14:22:57 | Train | Epoch[255/600] Iteration[003/030] Train loss: 0.0125
2023-02-06 14:22:57 | Train | Epoch[255/600] Iteration[004/030] Train loss: 0.0121
2023-02-06 14:22:57 | Train | Epoch[255/600] Iteration[005/030] Train loss: 0.0120
2023-02-06 14:22:57 | Train | Epoch[255/600] Iteration[006/030] Train loss: 0.0118
2023-02-06 14:22:58 | Train | Epoch[255/600] Iteration[007/030] Train loss: 0.0119
2023-02-06 14:22:58 | Train | Epoch[255/600] Iteration[008/030] Train loss: 0.0121
2023-02-06 14:22:58 | Train | Epoch[255/600] Iteration[009/030] Train loss: 0.0120
2023-02-06 14:22:58 | Train | Epoch[255/600] Iteration[010/030] Train loss: 0.0121
2023-02-06 14:22:58 | Train | Epoch[255/600] Iteration[011/030] Train loss: 0.0121
2023-02-06 14:22:59 | Train | Epoch[255/600] Iteration[012/030] Train loss: 0.0121
2023-02-06 14:22:59 | Train | Epoch[255/600] Iteration[013/030] Train loss: 0.0121
2023-02-06 14:22:59 | Train | Epoch[255/600] Iteration[014/030] Train loss: 0.0121
2023-02-06 14:22:59 | Train | Epoch[255/600] Iteration[015/030] Train loss: 0.0121
2023-02-06 14:23:00 | Train | Epoch[255/600] Iteration[016/030] Train loss: 0.0122
2023-02-06 14:23:00 | Train | Epoch[255/600] Iteration[017/030] Train loss: 0.0122
2023-02-06 14:23:00 | Train | Epoch[255/600] Iteration[018/030] Train loss: 0.0123
2023-02-06 14:23:00 | Train | Epoch[255/600] Iteration[019/030] Train loss: 0.0123
2023-02-06 14:23:00 | Train | Epoch[255/600] Iteration[020/030] Train loss: 0.0123
2023-02-06 14:23:01 | Train | Epoch[255/600] Iteration[021/030] Train loss: 0.0123
2023-02-06 14:23:01 | Train | Epoch[255/600] Iteration[022/030] Train loss: 0.0123
2023-02-06 14:23:01 | Train | Epoch[255/600] Iteration[023/030] Train loss: 0.0123
2023-02-06 14:23:01 | Train | Epoch[255/600] Iteration[024/030] Train loss: 0.0123
2023-02-06 14:23:01 | Train | Epoch[255/600] Iteration[025/030] Train loss: 0.0123
2023-02-06 14:23:02 | Train | Epoch[255/600] Iteration[026/030] Train loss: 0.0123
2023-02-06 14:23:02 | Train | Epoch[255/600] Iteration[027/030] Train loss: 0.0123
2023-02-06 14:23:02 | Train | Epoch[255/600] Iteration[028/030] Train loss: 0.0123
2023-02-06 14:23:02 | Train | Epoch[255/600] Iteration[029/030] Train loss: 0.0123
2023-02-06 14:23:02 | Train | Epoch[255/600] Iteration[030/030] Train loss: 0.0123
2023-02-06 14:23:03 | Valid | Epoch[255/600] Iteration[001/008] Valid loss: 0.0700
2023-02-06 14:23:03 | Valid | Epoch[255/600] Iteration[002/008] Valid loss: 0.0636
2023-02-06 14:23:03 | Valid | Epoch[255/600] Iteration[003/008] Valid loss: 0.0648
2023-02-06 14:23:03 | Valid | Epoch[255/600] Iteration[004/008] Valid loss: 0.0626
2023-02-06 14:23:03 | Valid | Epoch[255/600] Iteration[005/008] Valid loss: 0.0628
2023-02-06 14:23:03 | Valid | Epoch[255/600] Iteration[006/008] Valid loss: 0.0609
2023-02-06 14:23:03 | Valid | Epoch[255/600] Iteration[007/008] Valid loss: 0.0582
2023-02-06 14:23:03 | Valid | Epoch[255/600] Iteration[008/008] Valid loss: 0.0583
2023-02-06 14:23:03 | Valid | Epoch[255/600] MIou: 0.8584858418903749
2023-02-06 14:23:03 | Valid | Epoch[255/600] Pixel Accuracy: 0.9765701293945312
2023-02-06 14:23:03 | Valid | Epoch[255/600] Mean Pixel Accuracy: 0.872930051922864
2023-02-06 14:23:03 | Stage | Epoch[255/600] Train loss:0.0123
2023-02-06 14:23:03 | Stage | Epoch[255/600] Valid loss:0.0583
2023-02-06 14:23:03 | Stage | Epoch[255/600] LR:0.01

2023-02-06 14:23:04 | Train | Epoch[256/600] Iteration[001/030] Train loss: 0.0128
2023-02-06 14:23:04 | Train | Epoch[256/600] Iteration[002/030] Train loss: 0.0126
2023-02-06 14:23:04 | Train | Epoch[256/600] Iteration[003/030] Train loss: 0.0121
2023-02-06 14:23:04 | Train | Epoch[256/600] Iteration[004/030] Train loss: 0.0121
2023-02-06 14:23:05 | Train | Epoch[256/600] Iteration[005/030] Train loss: 0.0123
2023-02-06 14:23:05 | Train | Epoch[256/600] Iteration[006/030] Train loss: 0.0123
2023-02-06 14:23:05 | Train | Epoch[256/600] Iteration[007/030] Train loss: 0.0121
2023-02-06 14:23:05 | Train | Epoch[256/600] Iteration[008/030] Train loss: 0.0121
2023-02-06 14:23:06 | Train | Epoch[256/600] Iteration[009/030] Train loss: 0.0120
2023-02-06 14:23:06 | Train | Epoch[256/600] Iteration[010/030] Train loss: 0.0118
2023-02-06 14:23:06 | Train | Epoch[256/600] Iteration[011/030] Train loss: 0.0118
2023-02-06 14:23:06 | Train | Epoch[256/600] Iteration[012/030] Train loss: 0.0118
2023-02-06 14:23:06 | Train | Epoch[256/600] Iteration[013/030] Train loss: 0.0120
2023-02-06 14:23:07 | Train | Epoch[256/600] Iteration[014/030] Train loss: 0.0120
2023-02-06 14:23:07 | Train | Epoch[256/600] Iteration[015/030] Train loss: 0.0119
2023-02-06 14:23:07 | Train | Epoch[256/600] Iteration[016/030] Train loss: 0.0121
2023-02-06 14:23:07 | Train | Epoch[256/600] Iteration[017/030] Train loss: 0.0120
2023-02-06 14:23:08 | Train | Epoch[256/600] Iteration[018/030] Train loss: 0.0120
2023-02-06 14:23:08 | Train | Epoch[256/600] Iteration[019/030] Train loss: 0.0120
2023-02-06 14:23:08 | Train | Epoch[256/600] Iteration[020/030] Train loss: 0.0121
2023-02-06 14:23:08 | Train | Epoch[256/600] Iteration[021/030] Train loss: 0.0121
2023-02-06 14:23:08 | Train | Epoch[256/600] Iteration[022/030] Train loss: 0.0121
2023-02-06 14:23:09 | Train | Epoch[256/600] Iteration[023/030] Train loss: 0.0121
2023-02-06 14:23:09 | Train | Epoch[256/600] Iteration[024/030] Train loss: 0.0122
2023-02-06 14:23:09 | Train | Epoch[256/600] Iteration[025/030] Train loss: 0.0122
2023-02-06 14:23:09 | Train | Epoch[256/600] Iteration[026/030] Train loss: 0.0122
2023-02-06 14:23:10 | Train | Epoch[256/600] Iteration[027/030] Train loss: 0.0123
2023-02-06 14:23:10 | Train | Epoch[256/600] Iteration[028/030] Train loss: 0.0124
2023-02-06 14:23:10 | Train | Epoch[256/600] Iteration[029/030] Train loss: 0.0125
2023-02-06 14:23:10 | Train | Epoch[256/600] Iteration[030/030] Train loss: 0.0127
2023-02-06 14:23:10 | Valid | Epoch[256/600] Iteration[001/008] Valid loss: 0.7188
2023-02-06 14:23:10 | Valid | Epoch[256/600] Iteration[002/008] Valid loss: 0.6360
2023-02-06 14:23:11 | Valid | Epoch[256/600] Iteration[003/008] Valid loss: 0.6627
2023-02-06 14:23:11 | Valid | Epoch[256/600] Iteration[004/008] Valid loss: 0.6565
2023-02-06 14:23:11 | Valid | Epoch[256/600] Iteration[005/008] Valid loss: 0.6870
2023-02-06 14:23:11 | Valid | Epoch[256/600] Iteration[006/008] Valid loss: 0.6889
2023-02-06 14:23:11 | Valid | Epoch[256/600] Iteration[007/008] Valid loss: 0.7289
2023-02-06 14:23:11 | Valid | Epoch[256/600] Iteration[008/008] Valid loss: 0.7499
2023-02-06 14:23:11 | Valid | Epoch[256/600] MIou: 0.884208634070168
2023-02-06 14:23:11 | Valid | Epoch[256/600] Pixel Accuracy: 0.9768155415852865
2023-02-06 14:23:11 | Valid | Epoch[256/600] Mean Pixel Accuracy: 0.9821464128233008
2023-02-06 14:23:11 | Stage | Epoch[256/600] Train loss:0.0127
2023-02-06 14:23:11 | Stage | Epoch[256/600] Valid loss:0.7499
2023-02-06 14:23:11 | Stage | Epoch[256/600] LR:0.01

2023-02-06 14:23:11 | Train | Epoch[257/600] Iteration[001/030] Train loss: 0.0134
2023-02-06 14:23:12 | Train | Epoch[257/600] Iteration[002/030] Train loss: 0.0126
2023-02-06 14:23:12 | Train | Epoch[257/600] Iteration[003/030] Train loss: 0.0126
2023-02-06 14:23:12 | Train | Epoch[257/600] Iteration[004/030] Train loss: 0.0131
2023-02-06 14:23:12 | Train | Epoch[257/600] Iteration[005/030] Train loss: 0.0132
2023-02-06 14:23:12 | Train | Epoch[257/600] Iteration[006/030] Train loss: 0.0131
2023-02-06 14:23:13 | Train | Epoch[257/600] Iteration[007/030] Train loss: 0.0129
2023-02-06 14:23:13 | Train | Epoch[257/600] Iteration[008/030] Train loss: 0.0128
2023-02-06 14:23:13 | Train | Epoch[257/600] Iteration[009/030] Train loss: 0.0126
2023-02-06 14:23:13 | Train | Epoch[257/600] Iteration[010/030] Train loss: 0.0129
2023-02-06 14:23:14 | Train | Epoch[257/600] Iteration[011/030] Train loss: 0.0131
2023-02-06 14:23:14 | Train | Epoch[257/600] Iteration[012/030] Train loss: 0.0134
2023-02-06 14:23:14 | Train | Epoch[257/600] Iteration[013/030] Train loss: 0.0133
2023-02-06 14:23:14 | Train | Epoch[257/600] Iteration[014/030] Train loss: 0.0134
2023-02-06 14:23:14 | Train | Epoch[257/600] Iteration[015/030] Train loss: 0.0137
2023-02-06 14:23:15 | Train | Epoch[257/600] Iteration[016/030] Train loss: 0.0137
2023-02-06 14:23:15 | Train | Epoch[257/600] Iteration[017/030] Train loss: 0.0137
2023-02-06 14:23:15 | Train | Epoch[257/600] Iteration[018/030] Train loss: 0.0137
2023-02-06 14:23:15 | Train | Epoch[257/600] Iteration[019/030] Train loss: 0.0136
2023-02-06 14:23:16 | Train | Epoch[257/600] Iteration[020/030] Train loss: 0.0136
2023-02-06 14:23:16 | Train | Epoch[257/600] Iteration[021/030] Train loss: 0.0136
2023-02-06 14:23:16 | Train | Epoch[257/600] Iteration[022/030] Train loss: 0.0136
2023-02-06 14:23:16 | Train | Epoch[257/600] Iteration[023/030] Train loss: 0.0136
2023-02-06 14:23:16 | Train | Epoch[257/600] Iteration[024/030] Train loss: 0.0137
2023-02-06 14:23:17 | Train | Epoch[257/600] Iteration[025/030] Train loss: 0.0137
2023-02-06 14:23:17 | Train | Epoch[257/600] Iteration[026/030] Train loss: 0.0137
2023-02-06 14:23:17 | Train | Epoch[257/600] Iteration[027/030] Train loss: 0.0137
2023-02-06 14:23:17 | Train | Epoch[257/600] Iteration[028/030] Train loss: 0.0137
2023-02-06 14:23:18 | Train | Epoch[257/600] Iteration[029/030] Train loss: 0.0136
2023-02-06 14:23:18 | Train | Epoch[257/600] Iteration[030/030] Train loss: 0.0135
2023-02-06 14:23:18 | Valid | Epoch[257/600] Iteration[001/008] Valid loss: 1.3809
2023-02-06 14:23:18 | Valid | Epoch[257/600] Iteration[002/008] Valid loss: 1.3811
2023-02-06 14:23:18 | Valid | Epoch[257/600] Iteration[003/008] Valid loss: 1.4626
2023-02-06 14:23:18 | Valid | Epoch[257/600] Iteration[004/008] Valid loss: 1.4881
2023-02-06 14:23:18 | Valid | Epoch[257/600] Iteration[005/008] Valid loss: 1.5295
2023-02-06 14:23:18 | Valid | Epoch[257/600] Iteration[006/008] Valid loss: 1.5311
2023-02-06 14:23:18 | Valid | Epoch[257/600] Iteration[007/008] Valid loss: 1.5941
2023-02-06 14:23:18 | Valid | Epoch[257/600] Iteration[008/008] Valid loss: 1.6736
2023-02-06 14:23:18 | Valid | Epoch[257/600] MIou: 0.8133846714951624
2023-02-06 14:23:18 | Valid | Epoch[257/600] Pixel Accuracy: 0.9566383361816406
2023-02-06 14:23:18 | Valid | Epoch[257/600] Mean Pixel Accuracy: 0.9736684344594366
2023-02-06 14:23:18 | Stage | Epoch[257/600] Train loss:0.0135
2023-02-06 14:23:18 | Stage | Epoch[257/600] Valid loss:1.6736
2023-02-06 14:23:18 | Stage | Epoch[257/600] LR:0.01

2023-02-06 14:23:19 | Train | Epoch[258/600] Iteration[001/030] Train loss: 0.0138
2023-02-06 14:23:19 | Train | Epoch[258/600] Iteration[002/030] Train loss: 0.0132
2023-02-06 14:23:19 | Train | Epoch[258/600] Iteration[003/030] Train loss: 0.0128
2023-02-06 14:23:19 | Train | Epoch[258/600] Iteration[004/030] Train loss: 0.0126
2023-02-06 14:23:20 | Train | Epoch[258/600] Iteration[005/030] Train loss: 0.0126
2023-02-06 14:23:20 | Train | Epoch[258/600] Iteration[006/030] Train loss: 0.0127
2023-02-06 14:23:20 | Train | Epoch[258/600] Iteration[007/030] Train loss: 0.0127
2023-02-06 14:23:20 | Train | Epoch[258/600] Iteration[008/030] Train loss: 0.0126
2023-02-06 14:23:21 | Train | Epoch[258/600] Iteration[009/030] Train loss: 0.0126
2023-02-06 14:23:21 | Train | Epoch[258/600] Iteration[010/030] Train loss: 0.0124
2023-02-06 14:23:21 | Train | Epoch[258/600] Iteration[011/030] Train loss: 0.0123
2023-02-06 14:23:21 | Train | Epoch[258/600] Iteration[012/030] Train loss: 0.0124
2023-02-06 14:23:21 | Train | Epoch[258/600] Iteration[013/030] Train loss: 0.0125
2023-02-06 14:23:22 | Train | Epoch[258/600] Iteration[014/030] Train loss: 0.0124
2023-02-06 14:23:22 | Train | Epoch[258/600] Iteration[015/030] Train loss: 0.0124
2023-02-06 14:23:22 | Train | Epoch[258/600] Iteration[016/030] Train loss: 0.0124
2023-02-06 14:23:22 | Train | Epoch[258/600] Iteration[017/030] Train loss: 0.0124
2023-02-06 14:23:23 | Train | Epoch[258/600] Iteration[018/030] Train loss: 0.0125
2023-02-06 14:23:23 | Train | Epoch[258/600] Iteration[019/030] Train loss: 0.0124
2023-02-06 14:23:23 | Train | Epoch[258/600] Iteration[020/030] Train loss: 0.0125
2023-02-06 14:23:23 | Train | Epoch[258/600] Iteration[021/030] Train loss: 0.0125
2023-02-06 14:23:23 | Train | Epoch[258/600] Iteration[022/030] Train loss: 0.0125
2023-02-06 14:23:24 | Train | Epoch[258/600] Iteration[023/030] Train loss: 0.0125
2023-02-06 14:23:24 | Train | Epoch[258/600] Iteration[024/030] Train loss: 0.0125
2023-02-06 14:23:24 | Train | Epoch[258/600] Iteration[025/030] Train loss: 0.0125
2023-02-06 14:23:24 | Train | Epoch[258/600] Iteration[026/030] Train loss: 0.0124
2023-02-06 14:23:24 | Train | Epoch[258/600] Iteration[027/030] Train loss: 0.0124
2023-02-06 14:23:25 | Train | Epoch[258/600] Iteration[028/030] Train loss: 0.0125
2023-02-06 14:23:25 | Train | Epoch[258/600] Iteration[029/030] Train loss: 0.0125
2023-02-06 14:23:25 | Train | Epoch[258/600] Iteration[030/030] Train loss: 0.0124
2023-02-06 14:23:25 | Valid | Epoch[258/600] Iteration[001/008] Valid loss: 0.5619
2023-02-06 14:23:25 | Valid | Epoch[258/600] Iteration[002/008] Valid loss: 0.5042
2023-02-06 14:23:26 | Valid | Epoch[258/600] Iteration[003/008] Valid loss: 0.5132
2023-02-06 14:23:26 | Valid | Epoch[258/600] Iteration[004/008] Valid loss: 0.4987
2023-02-06 14:23:26 | Valid | Epoch[258/600] Iteration[005/008] Valid loss: 0.5112
2023-02-06 14:23:26 | Valid | Epoch[258/600] Iteration[006/008] Valid loss: 0.5112
2023-02-06 14:23:26 | Valid | Epoch[258/600] Iteration[007/008] Valid loss: 0.5464
2023-02-06 14:23:26 | Valid | Epoch[258/600] Iteration[008/008] Valid loss: 0.5712
2023-02-06 14:23:26 | Valid | Epoch[258/600] MIou: 0.8882095888559478
2023-02-06 14:23:26 | Valid | Epoch[258/600] Pixel Accuracy: 0.9778709411621094
2023-02-06 14:23:26 | Valid | Epoch[258/600] Mean Pixel Accuracy: 0.980811683045778
2023-02-06 14:23:26 | Stage | Epoch[258/600] Train loss:0.0124
2023-02-06 14:23:26 | Stage | Epoch[258/600] Valid loss:0.5712
2023-02-06 14:23:26 | Stage | Epoch[258/600] LR:0.01

2023-02-06 14:23:26 | Train | Epoch[259/600] Iteration[001/030] Train loss: 0.0110
2023-02-06 14:23:27 | Train | Epoch[259/600] Iteration[002/030] Train loss: 0.0111
2023-02-06 14:23:27 | Train | Epoch[259/600] Iteration[003/030] Train loss: 0.0112
2023-02-06 14:23:27 | Train | Epoch[259/600] Iteration[004/030] Train loss: 0.0113
2023-02-06 14:23:27 | Train | Epoch[259/600] Iteration[005/030] Train loss: 0.0113
2023-02-06 14:23:27 | Train | Epoch[259/600] Iteration[006/030] Train loss: 0.0116
2023-02-06 14:23:28 | Train | Epoch[259/600] Iteration[007/030] Train loss: 0.0118
2023-02-06 14:23:28 | Train | Epoch[259/600] Iteration[008/030] Train loss: 0.0117
2023-02-06 14:23:28 | Train | Epoch[259/600] Iteration[009/030] Train loss: 0.0117
2023-02-06 14:23:28 | Train | Epoch[259/600] Iteration[010/030] Train loss: 0.0120
2023-02-06 14:23:29 | Train | Epoch[259/600] Iteration[011/030] Train loss: 0.0121
2023-02-06 14:23:29 | Train | Epoch[259/600] Iteration[012/030] Train loss: 0.0123
2023-02-06 14:23:29 | Train | Epoch[259/600] Iteration[013/030] Train loss: 0.0122
2023-02-06 14:23:29 | Train | Epoch[259/600] Iteration[014/030] Train loss: 0.0122
2023-02-06 14:23:29 | Train | Epoch[259/600] Iteration[015/030] Train loss: 0.0121
2023-02-06 14:23:30 | Train | Epoch[259/600] Iteration[016/030] Train loss: 0.0121
2023-02-06 14:23:30 | Train | Epoch[259/600] Iteration[017/030] Train loss: 0.0121
2023-02-06 14:23:30 | Train | Epoch[259/600] Iteration[018/030] Train loss: 0.0122
2023-02-06 14:23:30 | Train | Epoch[259/600] Iteration[019/030] Train loss: 0.0122
2023-02-06 14:23:31 | Train | Epoch[259/600] Iteration[020/030] Train loss: 0.0122
2023-02-06 14:23:31 | Train | Epoch[259/600] Iteration[021/030] Train loss: 0.0122
2023-02-06 14:23:31 | Train | Epoch[259/600] Iteration[022/030] Train loss: 0.0122
2023-02-06 14:23:31 | Train | Epoch[259/600] Iteration[023/030] Train loss: 0.0123
2023-02-06 14:23:31 | Train | Epoch[259/600] Iteration[024/030] Train loss: 0.0123
2023-02-06 14:23:32 | Train | Epoch[259/600] Iteration[025/030] Train loss: 0.0123
2023-02-06 14:23:32 | Train | Epoch[259/600] Iteration[026/030] Train loss: 0.0124
2023-02-06 14:23:32 | Train | Epoch[259/600] Iteration[027/030] Train loss: 0.0123
2023-02-06 14:23:32 | Train | Epoch[259/600] Iteration[028/030] Train loss: 0.0123
2023-02-06 14:23:32 | Train | Epoch[259/600] Iteration[029/030] Train loss: 0.0123
2023-02-06 14:23:33 | Train | Epoch[259/600] Iteration[030/030] Train loss: 0.0123
2023-02-06 14:23:33 | Valid | Epoch[259/600] Iteration[001/008] Valid loss: 0.5009
2023-02-06 14:23:33 | Valid | Epoch[259/600] Iteration[002/008] Valid loss: 0.4401
2023-02-06 14:23:33 | Valid | Epoch[259/600] Iteration[003/008] Valid loss: 0.4546
2023-02-06 14:23:33 | Valid | Epoch[259/600] Iteration[004/008] Valid loss: 0.4488
2023-02-06 14:23:33 | Valid | Epoch[259/600] Iteration[005/008] Valid loss: 0.4591
2023-02-06 14:23:33 | Valid | Epoch[259/600] Iteration[006/008] Valid loss: 0.4560
2023-02-06 14:23:33 | Valid | Epoch[259/600] Iteration[007/008] Valid loss: 0.4938
2023-02-06 14:23:33 | Valid | Epoch[259/600] Iteration[008/008] Valid loss: 0.4989
2023-02-06 14:23:33 | Valid | Epoch[259/600] MIou: 0.9085588071335668
2023-02-06 14:23:33 | Valid | Epoch[259/600] Pixel Accuracy: 0.9826698303222656
2023-02-06 14:23:33 | Valid | Epoch[259/600] Mean Pixel Accuracy: 0.9810336375497699
2023-02-06 14:23:33 | Stage | Epoch[259/600] Train loss:0.0123
2023-02-06 14:23:33 | Stage | Epoch[259/600] Valid loss:0.4989
2023-02-06 14:23:33 | Stage | Epoch[259/600] LR:0.01

2023-02-06 14:23:34 | Train | Epoch[260/600] Iteration[001/030] Train loss: 0.0131
2023-02-06 14:23:34 | Train | Epoch[260/600] Iteration[002/030] Train loss: 0.0124
2023-02-06 14:23:34 | Train | Epoch[260/600] Iteration[003/030] Train loss: 0.0118
2023-02-06 14:23:35 | Train | Epoch[260/600] Iteration[004/030] Train loss: 0.0118
2023-02-06 14:23:35 | Train | Epoch[260/600] Iteration[005/030] Train loss: 0.0120
2023-02-06 14:23:35 | Train | Epoch[260/600] Iteration[006/030] Train loss: 0.0120
2023-02-06 14:23:35 | Train | Epoch[260/600] Iteration[007/030] Train loss: 0.0119
2023-02-06 14:23:35 | Train | Epoch[260/600] Iteration[008/030] Train loss: 0.0120
2023-02-06 14:23:36 | Train | Epoch[260/600] Iteration[009/030] Train loss: 0.0119
2023-02-06 14:23:36 | Train | Epoch[260/600] Iteration[010/030] Train loss: 0.0119
2023-02-06 14:23:36 | Train | Epoch[260/600] Iteration[011/030] Train loss: 0.0118
2023-02-06 14:23:36 | Train | Epoch[260/600] Iteration[012/030] Train loss: 0.0118
2023-02-06 14:23:36 | Train | Epoch[260/600] Iteration[013/030] Train loss: 0.0118
2023-02-06 14:23:37 | Train | Epoch[260/600] Iteration[014/030] Train loss: 0.0118
2023-02-06 14:23:37 | Train | Epoch[260/600] Iteration[015/030] Train loss: 0.0118
2023-02-06 14:23:37 | Train | Epoch[260/600] Iteration[016/030] Train loss: 0.0119
2023-02-06 14:23:37 | Train | Epoch[260/600] Iteration[017/030] Train loss: 0.0119
2023-02-06 14:23:38 | Train | Epoch[260/600] Iteration[018/030] Train loss: 0.0119
2023-02-06 14:23:38 | Train | Epoch[260/600] Iteration[019/030] Train loss: 0.0119
2023-02-06 14:23:38 | Train | Epoch[260/600] Iteration[020/030] Train loss: 0.0119
2023-02-06 14:23:38 | Train | Epoch[260/600] Iteration[021/030] Train loss: 0.0118
2023-02-06 14:23:38 | Train | Epoch[260/600] Iteration[022/030] Train loss: 0.0118
2023-02-06 14:23:39 | Train | Epoch[260/600] Iteration[023/030] Train loss: 0.0118
2023-02-06 14:23:39 | Train | Epoch[260/600] Iteration[024/030] Train loss: 0.0118
2023-02-06 14:23:39 | Train | Epoch[260/600] Iteration[025/030] Train loss: 0.0119
2023-02-06 14:23:39 | Train | Epoch[260/600] Iteration[026/030] Train loss: 0.0119
2023-02-06 14:23:40 | Train | Epoch[260/600] Iteration[027/030] Train loss: 0.0119
2023-02-06 14:23:40 | Train | Epoch[260/600] Iteration[028/030] Train loss: 0.0119
2023-02-06 14:23:40 | Train | Epoch[260/600] Iteration[029/030] Train loss: 0.0119
2023-02-06 14:23:40 | Train | Epoch[260/600] Iteration[030/030] Train loss: 0.0120
2023-02-06 14:23:40 | Valid | Epoch[260/600] Iteration[001/008] Valid loss: 0.0813
2023-02-06 14:23:41 | Valid | Epoch[260/600] Iteration[002/008] Valid loss: 0.0665
2023-02-06 14:23:41 | Valid | Epoch[260/600] Iteration[003/008] Valid loss: 0.0624
2023-02-06 14:23:41 | Valid | Epoch[260/600] Iteration[004/008] Valid loss: 0.0580
2023-02-06 14:23:41 | Valid | Epoch[260/600] Iteration[005/008] Valid loss: 0.0567
2023-02-06 14:23:41 | Valid | Epoch[260/600] Iteration[006/008] Valid loss: 0.0547
2023-02-06 14:23:41 | Valid | Epoch[260/600] Iteration[007/008] Valid loss: 0.0539
2023-02-06 14:23:41 | Valid | Epoch[260/600] Iteration[008/008] Valid loss: 0.0531
2023-02-06 14:23:41 | Valid | Epoch[260/600] MIou: 0.9028337880925745
2023-02-06 14:23:41 | Valid | Epoch[260/600] Pixel Accuracy: 0.9837265014648438
2023-02-06 14:23:41 | Valid | Epoch[260/600] Mean Pixel Accuracy: 0.9187169516758336
2023-02-06 14:23:41 | Stage | Epoch[260/600] Train loss:0.0120
2023-02-06 14:23:41 | Stage | Epoch[260/600] Valid loss:0.0531
2023-02-06 14:23:41 | Stage | Epoch[260/600] LR:0.01

2023-02-06 14:23:41 | Train | Epoch[261/600] Iteration[001/030] Train loss: 0.0101
2023-02-06 14:23:42 | Train | Epoch[261/600] Iteration[002/030] Train loss: 0.0122
2023-02-06 14:23:42 | Train | Epoch[261/600] Iteration[003/030] Train loss: 0.0123
2023-02-06 14:23:42 | Train | Epoch[261/600] Iteration[004/030] Train loss: 0.0119
2023-02-06 14:23:42 | Train | Epoch[261/600] Iteration[005/030] Train loss: 0.0119
2023-02-06 14:23:42 | Train | Epoch[261/600] Iteration[006/030] Train loss: 0.0119
2023-02-06 14:23:43 | Train | Epoch[261/600] Iteration[007/030] Train loss: 0.0120
2023-02-06 14:23:43 | Train | Epoch[261/600] Iteration[008/030] Train loss: 0.0121
2023-02-06 14:23:43 | Train | Epoch[261/600] Iteration[009/030] Train loss: 0.0120
2023-02-06 14:23:43 | Train | Epoch[261/600] Iteration[010/030] Train loss: 0.0120
2023-02-06 14:23:44 | Train | Epoch[261/600] Iteration[011/030] Train loss: 0.0120
2023-02-06 14:23:44 | Train | Epoch[261/600] Iteration[012/030] Train loss: 0.0121
2023-02-06 14:23:44 | Train | Epoch[261/600] Iteration[013/030] Train loss: 0.0121
2023-02-06 14:23:44 | Train | Epoch[261/600] Iteration[014/030] Train loss: 0.0121
2023-02-06 14:23:44 | Train | Epoch[261/600] Iteration[015/030] Train loss: 0.0122
2023-02-06 14:23:45 | Train | Epoch[261/600] Iteration[016/030] Train loss: 0.0122
2023-02-06 14:23:45 | Train | Epoch[261/600] Iteration[017/030] Train loss: 0.0122
2023-02-06 14:23:45 | Train | Epoch[261/600] Iteration[018/030] Train loss: 0.0122
2023-02-06 14:23:45 | Train | Epoch[261/600] Iteration[019/030] Train loss: 0.0123
2023-02-06 14:23:46 | Train | Epoch[261/600] Iteration[020/030] Train loss: 0.0123
2023-02-06 14:23:46 | Train | Epoch[261/600] Iteration[021/030] Train loss: 0.0122
2023-02-06 14:23:46 | Train | Epoch[261/600] Iteration[022/030] Train loss: 0.0122
2023-02-06 14:23:46 | Train | Epoch[261/600] Iteration[023/030] Train loss: 0.0122
2023-02-06 14:23:46 | Train | Epoch[261/600] Iteration[024/030] Train loss: 0.0121
2023-02-06 14:23:47 | Train | Epoch[261/600] Iteration[025/030] Train loss: 0.0121
2023-02-06 14:23:47 | Train | Epoch[261/600] Iteration[026/030] Train loss: 0.0121
2023-02-06 14:23:47 | Train | Epoch[261/600] Iteration[027/030] Train loss: 0.0120
2023-02-06 14:23:47 | Train | Epoch[261/600] Iteration[028/030] Train loss: 0.0121
2023-02-06 14:23:48 | Train | Epoch[261/600] Iteration[029/030] Train loss: 0.0122
2023-02-06 14:23:48 | Train | Epoch[261/600] Iteration[030/030] Train loss: 0.0123
2023-02-06 14:23:48 | Valid | Epoch[261/600] Iteration[001/008] Valid loss: 0.2614
2023-02-06 14:23:48 | Valid | Epoch[261/600] Iteration[002/008] Valid loss: 0.2053
2023-02-06 14:23:48 | Valid | Epoch[261/600] Iteration[003/008] Valid loss: 0.1976
2023-02-06 14:23:48 | Valid | Epoch[261/600] Iteration[004/008] Valid loss: 0.1836
2023-02-06 14:23:48 | Valid | Epoch[261/600] Iteration[005/008] Valid loss: 0.1809
2023-02-06 14:23:48 | Valid | Epoch[261/600] Iteration[006/008] Valid loss: 0.1777
2023-02-06 14:23:48 | Valid | Epoch[261/600] Iteration[007/008] Valid loss: 0.1878
2023-02-06 14:23:48 | Valid | Epoch[261/600] Iteration[008/008] Valid loss: 0.1916
2023-02-06 14:23:48 | Valid | Epoch[261/600] MIou: 0.9191206502853192
2023-02-06 14:23:48 | Valid | Epoch[261/600] Pixel Accuracy: 0.9852790832519531
2023-02-06 14:23:48 | Valid | Epoch[261/600] Mean Pixel Accuracy: 0.9721328256771822
2023-02-06 14:23:48 | Stage | Epoch[261/600] Train loss:0.0123
2023-02-06 14:23:48 | Stage | Epoch[261/600] Valid loss:0.1916
2023-02-06 14:23:48 | Stage | Epoch[261/600] LR:0.01

2023-02-06 14:23:49 | Train | Epoch[262/600] Iteration[001/030] Train loss: 0.0130
2023-02-06 14:23:49 | Train | Epoch[262/600] Iteration[002/030] Train loss: 0.0125
2023-02-06 14:23:49 | Train | Epoch[262/600] Iteration[003/030] Train loss: 0.0119
2023-02-06 14:23:50 | Train | Epoch[262/600] Iteration[004/030] Train loss: 0.0129
2023-02-06 14:23:50 | Train | Epoch[262/600] Iteration[005/030] Train loss: 0.0132
2023-02-06 14:23:50 | Train | Epoch[262/600] Iteration[006/030] Train loss: 0.0128
2023-02-06 14:23:50 | Train | Epoch[262/600] Iteration[007/030] Train loss: 0.0128
2023-02-06 14:23:50 | Train | Epoch[262/600] Iteration[008/030] Train loss: 0.0127
2023-02-06 14:23:51 | Train | Epoch[262/600] Iteration[009/030] Train loss: 0.0128
2023-02-06 14:23:51 | Train | Epoch[262/600] Iteration[010/030] Train loss: 0.0126
2023-02-06 14:23:51 | Train | Epoch[262/600] Iteration[011/030] Train loss: 0.0125
2023-02-06 14:23:51 | Train | Epoch[262/600] Iteration[012/030] Train loss: 0.0126
2023-02-06 14:23:52 | Train | Epoch[262/600] Iteration[013/030] Train loss: 0.0124
2023-02-06 14:23:52 | Train | Epoch[262/600] Iteration[014/030] Train loss: 0.0124
2023-02-06 14:23:52 | Train | Epoch[262/600] Iteration[015/030] Train loss: 0.0125
2023-02-06 14:23:52 | Train | Epoch[262/600] Iteration[016/030] Train loss: 0.0124
2023-02-06 14:23:52 | Train | Epoch[262/600] Iteration[017/030] Train loss: 0.0124
2023-02-06 14:23:53 | Train | Epoch[262/600] Iteration[018/030] Train loss: 0.0125
2023-02-06 14:23:53 | Train | Epoch[262/600] Iteration[019/030] Train loss: 0.0124
2023-02-06 14:23:53 | Train | Epoch[262/600] Iteration[020/030] Train loss: 0.0124
2023-02-06 14:23:53 | Train | Epoch[262/600] Iteration[021/030] Train loss: 0.0124
2023-02-06 14:23:53 | Train | Epoch[262/600] Iteration[022/030] Train loss: 0.0124
2023-02-06 14:23:54 | Train | Epoch[262/600] Iteration[023/030] Train loss: 0.0124
2023-02-06 14:23:54 | Train | Epoch[262/600] Iteration[024/030] Train loss: 0.0124
2023-02-06 14:23:54 | Train | Epoch[262/600] Iteration[025/030] Train loss: 0.0123
2023-02-06 14:23:54 | Train | Epoch[262/600] Iteration[026/030] Train loss: 0.0123
2023-02-06 14:23:55 | Train | Epoch[262/600] Iteration[027/030] Train loss: 0.0123
2023-02-06 14:23:55 | Train | Epoch[262/600] Iteration[028/030] Train loss: 0.0123
2023-02-06 14:23:55 | Train | Epoch[262/600] Iteration[029/030] Train loss: 0.0123
2023-02-06 14:23:55 | Train | Epoch[262/600] Iteration[030/030] Train loss: 0.0124
2023-02-06 14:23:55 | Valid | Epoch[262/600] Iteration[001/008] Valid loss: 0.3464
2023-02-06 14:23:56 | Valid | Epoch[262/600] Iteration[002/008] Valid loss: 0.2802
2023-02-06 14:23:56 | Valid | Epoch[262/600] Iteration[003/008] Valid loss: 0.2854
2023-02-06 14:23:56 | Valid | Epoch[262/600] Iteration[004/008] Valid loss: 0.2827
2023-02-06 14:23:56 | Valid | Epoch[262/600] Iteration[005/008] Valid loss: 0.2845
2023-02-06 14:23:56 | Valid | Epoch[262/600] Iteration[006/008] Valid loss: 0.2818
2023-02-06 14:23:56 | Valid | Epoch[262/600] Iteration[007/008] Valid loss: 0.3001
2023-02-06 14:23:56 | Valid | Epoch[262/600] Iteration[008/008] Valid loss: 0.3121
2023-02-06 14:23:56 | Valid | Epoch[262/600] MIou: 0.9132055359868814
2023-02-06 14:23:56 | Valid | Epoch[262/600] Pixel Accuracy: 0.9839286804199219
2023-02-06 14:23:56 | Valid | Epoch[262/600] Mean Pixel Accuracy: 0.974414991598672
2023-02-06 14:23:56 | Stage | Epoch[262/600] Train loss:0.0124
2023-02-06 14:23:56 | Stage | Epoch[262/600] Valid loss:0.3121
2023-02-06 14:23:56 | Stage | Epoch[262/600] LR:0.01

2023-02-06 14:23:56 | Train | Epoch[263/600] Iteration[001/030] Train loss: 0.0114
2023-02-06 14:23:57 | Train | Epoch[263/600] Iteration[002/030] Train loss: 0.0117
2023-02-06 14:23:57 | Train | Epoch[263/600] Iteration[003/030] Train loss: 0.0120
2023-02-06 14:23:57 | Train | Epoch[263/600] Iteration[004/030] Train loss: 0.0121
2023-02-06 14:23:57 | Train | Epoch[263/600] Iteration[005/030] Train loss: 0.0122
2023-02-06 14:23:57 | Train | Epoch[263/600] Iteration[006/030] Train loss: 0.0123
2023-02-06 14:23:58 | Train | Epoch[263/600] Iteration[007/030] Train loss: 0.0123
2023-02-06 14:23:58 | Train | Epoch[263/600] Iteration[008/030] Train loss: 0.0122
2023-02-06 14:23:58 | Train | Epoch[263/600] Iteration[009/030] Train loss: 0.0123
2023-02-06 14:23:58 | Train | Epoch[263/600] Iteration[010/030] Train loss: 0.0122
2023-02-06 14:23:59 | Train | Epoch[263/600] Iteration[011/030] Train loss: 0.0122
2023-02-06 14:23:59 | Train | Epoch[263/600] Iteration[012/030] Train loss: 0.0123
2023-02-06 14:23:59 | Train | Epoch[263/600] Iteration[013/030] Train loss: 0.0123
2023-02-06 14:23:59 | Train | Epoch[263/600] Iteration[014/030] Train loss: 0.0123
2023-02-06 14:23:59 | Train | Epoch[263/600] Iteration[015/030] Train loss: 0.0125
2023-02-06 14:24:00 | Train | Epoch[263/600] Iteration[016/030] Train loss: 0.0125
2023-02-06 14:24:00 | Train | Epoch[263/600] Iteration[017/030] Train loss: 0.0125
2023-02-06 14:24:00 | Train | Epoch[263/600] Iteration[018/030] Train loss: 0.0126
2023-02-06 14:24:00 | Train | Epoch[263/600] Iteration[019/030] Train loss: 0.0126
2023-02-06 14:24:01 | Train | Epoch[263/600] Iteration[020/030] Train loss: 0.0126
2023-02-06 14:24:01 | Train | Epoch[263/600] Iteration[021/030] Train loss: 0.0126
2023-02-06 14:24:01 | Train | Epoch[263/600] Iteration[022/030] Train loss: 0.0126
2023-02-06 14:24:01 | Train | Epoch[263/600] Iteration[023/030] Train loss: 0.0126
2023-02-06 14:24:01 | Train | Epoch[263/600] Iteration[024/030] Train loss: 0.0125
2023-02-06 14:24:02 | Train | Epoch[263/600] Iteration[025/030] Train loss: 0.0126
2023-02-06 14:24:02 | Train | Epoch[263/600] Iteration[026/030] Train loss: 0.0125
2023-02-06 14:24:02 | Train | Epoch[263/600] Iteration[027/030] Train loss: 0.0124
2023-02-06 14:24:02 | Train | Epoch[263/600] Iteration[028/030] Train loss: 0.0124
2023-02-06 14:24:02 | Train | Epoch[263/600] Iteration[029/030] Train loss: 0.0125
2023-02-06 14:24:03 | Train | Epoch[263/600] Iteration[030/030] Train loss: 0.0126
2023-02-06 14:24:03 | Valid | Epoch[263/600] Iteration[001/008] Valid loss: 0.1274
2023-02-06 14:24:03 | Valid | Epoch[263/600] Iteration[002/008] Valid loss: 0.1245
2023-02-06 14:24:03 | Valid | Epoch[263/600] Iteration[003/008] Valid loss: 0.1294
2023-02-06 14:24:03 | Valid | Epoch[263/600] Iteration[004/008] Valid loss: 0.1292
2023-02-06 14:24:03 | Valid | Epoch[263/600] Iteration[005/008] Valid loss: 0.1297
2023-02-06 14:24:03 | Valid | Epoch[263/600] Iteration[006/008] Valid loss: 0.1265
2023-02-06 14:24:03 | Valid | Epoch[263/600] Iteration[007/008] Valid loss: 0.1218
2023-02-06 14:24:03 | Valid | Epoch[263/600] Iteration[008/008] Valid loss: 0.1241
2023-02-06 14:24:03 | Valid | Epoch[263/600] MIou: 0.7563155611934652
2023-02-06 14:24:03 | Valid | Epoch[263/600] Pixel Accuracy: 0.9598007202148438
2023-02-06 14:24:03 | Valid | Epoch[263/600] Mean Pixel Accuracy: 0.7774951378184429
2023-02-06 14:24:03 | Stage | Epoch[263/600] Train loss:0.0126
2023-02-06 14:24:03 | Stage | Epoch[263/600] Valid loss:0.1241
2023-02-06 14:24:03 | Stage | Epoch[263/600] LR:0.01

2023-02-06 14:24:04 | Train | Epoch[264/600] Iteration[001/030] Train loss: 0.0135
2023-02-06 14:24:04 | Train | Epoch[264/600] Iteration[002/030] Train loss: 0.0125
2023-02-06 14:24:04 | Train | Epoch[264/600] Iteration[003/030] Train loss: 0.0128
2023-02-06 14:24:05 | Train | Epoch[264/600] Iteration[004/030] Train loss: 0.0127
2023-02-06 14:24:05 | Train | Epoch[264/600] Iteration[005/030] Train loss: 0.0122
2023-02-06 14:24:05 | Train | Epoch[264/600] Iteration[006/030] Train loss: 0.0120
2023-02-06 14:24:05 | Train | Epoch[264/600] Iteration[007/030] Train loss: 0.0120
2023-02-06 14:24:05 | Train | Epoch[264/600] Iteration[008/030] Train loss: 0.0119
2023-02-06 14:24:06 | Train | Epoch[264/600] Iteration[009/030] Train loss: 0.0120
2023-02-06 14:24:06 | Train | Epoch[264/600] Iteration[010/030] Train loss: 0.0123
2023-02-06 14:24:06 | Train | Epoch[264/600] Iteration[011/030] Train loss: 0.0122
2023-02-06 14:24:06 | Train | Epoch[264/600] Iteration[012/030] Train loss: 0.0123
2023-02-06 14:24:07 | Train | Epoch[264/600] Iteration[013/030] Train loss: 0.0121
2023-02-06 14:24:07 | Train | Epoch[264/600] Iteration[014/030] Train loss: 0.0123
2023-02-06 14:24:07 | Train | Epoch[264/600] Iteration[015/030] Train loss: 0.0124
2023-02-06 14:24:07 | Train | Epoch[264/600] Iteration[016/030] Train loss: 0.0125
2023-02-06 14:24:07 | Train | Epoch[264/600] Iteration[017/030] Train loss: 0.0125
2023-02-06 14:24:08 | Train | Epoch[264/600] Iteration[018/030] Train loss: 0.0125
2023-02-06 14:24:08 | Train | Epoch[264/600] Iteration[019/030] Train loss: 0.0125
2023-02-06 14:24:08 | Train | Epoch[264/600] Iteration[020/030] Train loss: 0.0125
2023-02-06 14:24:08 | Train | Epoch[264/600] Iteration[021/030] Train loss: 0.0125
2023-02-06 14:24:09 | Train | Epoch[264/600] Iteration[022/030] Train loss: 0.0125
2023-02-06 14:24:09 | Train | Epoch[264/600] Iteration[023/030] Train loss: 0.0125
2023-02-06 14:24:09 | Train | Epoch[264/600] Iteration[024/030] Train loss: 0.0128
2023-02-06 14:24:09 | Train | Epoch[264/600] Iteration[025/030] Train loss: 0.0128
2023-02-06 14:24:09 | Train | Epoch[264/600] Iteration[026/030] Train loss: 0.0128
2023-02-06 14:24:10 | Train | Epoch[264/600] Iteration[027/030] Train loss: 0.0128
2023-02-06 14:24:10 | Train | Epoch[264/600] Iteration[028/030] Train loss: 0.0128
2023-02-06 14:24:10 | Train | Epoch[264/600] Iteration[029/030] Train loss: 0.0129
2023-02-06 14:24:10 | Train | Epoch[264/600] Iteration[030/030] Train loss: 0.0129
2023-02-06 14:24:11 | Valid | Epoch[264/600] Iteration[001/008] Valid loss: 0.2328
2023-02-06 14:24:11 | Valid | Epoch[264/600] Iteration[002/008] Valid loss: 0.1659
2023-02-06 14:24:11 | Valid | Epoch[264/600] Iteration[003/008] Valid loss: 0.1526
2023-02-06 14:24:11 | Valid | Epoch[264/600] Iteration[004/008] Valid loss: 0.1425
2023-02-06 14:24:11 | Valid | Epoch[264/600] Iteration[005/008] Valid loss: 0.1454
2023-02-06 14:24:11 | Valid | Epoch[264/600] Iteration[006/008] Valid loss: 0.1410
2023-02-06 14:24:11 | Valid | Epoch[264/600] Iteration[007/008] Valid loss: 0.1534
2023-02-06 14:24:11 | Valid | Epoch[264/600] Iteration[008/008] Valid loss: 0.1539
2023-02-06 14:24:11 | Valid | Epoch[264/600] MIou: 0.9229640507630468
2023-02-06 14:24:11 | Valid | Epoch[264/600] Pixel Accuracy: 0.9863141377766927
2023-02-06 14:24:11 | Valid | Epoch[264/600] Mean Pixel Accuracy: 0.9644083990501864
2023-02-06 14:24:11 | Stage | Epoch[264/600] Train loss:0.0129
2023-02-06 14:24:11 | Stage | Epoch[264/600] Valid loss:0.1539
2023-02-06 14:24:11 | Stage | Epoch[264/600] LR:0.01

2023-02-06 14:24:12 | Train | Epoch[265/600] Iteration[001/030] Train loss: 0.0115
2023-02-06 14:24:12 | Train | Epoch[265/600] Iteration[002/030] Train loss: 0.0110
2023-02-06 14:24:12 | Train | Epoch[265/600] Iteration[003/030] Train loss: 0.0118
2023-02-06 14:24:12 | Train | Epoch[265/600] Iteration[004/030] Train loss: 0.0120
2023-02-06 14:24:12 | Train | Epoch[265/600] Iteration[005/030] Train loss: 0.0123
2023-02-06 14:24:13 | Train | Epoch[265/600] Iteration[006/030] Train loss: 0.0123
2023-02-06 14:24:13 | Train | Epoch[265/600] Iteration[007/030] Train loss: 0.0122
2023-02-06 14:24:13 | Train | Epoch[265/600] Iteration[008/030] Train loss: 0.0120
2023-02-06 14:24:13 | Train | Epoch[265/600] Iteration[009/030] Train loss: 0.0122
2023-02-06 14:24:14 | Train | Epoch[265/600] Iteration[010/030] Train loss: 0.0124
2023-02-06 14:24:14 | Train | Epoch[265/600] Iteration[011/030] Train loss: 0.0126
2023-02-06 14:24:14 | Train | Epoch[265/600] Iteration[012/030] Train loss: 0.0126
2023-02-06 14:24:14 | Train | Epoch[265/600] Iteration[013/030] Train loss: 0.0126
2023-02-06 14:24:14 | Train | Epoch[265/600] Iteration[014/030] Train loss: 0.0125
2023-02-06 14:24:15 | Train | Epoch[265/600] Iteration[015/030] Train loss: 0.0124
2023-02-06 14:24:15 | Train | Epoch[265/600] Iteration[016/030] Train loss: 0.0124
2023-02-06 14:24:15 | Train | Epoch[265/600] Iteration[017/030] Train loss: 0.0123
2023-02-06 14:24:15 | Train | Epoch[265/600] Iteration[018/030] Train loss: 0.0123
2023-02-06 14:24:15 | Train | Epoch[265/600] Iteration[019/030] Train loss: 0.0123
2023-02-06 14:24:16 | Train | Epoch[265/600] Iteration[020/030] Train loss: 0.0125
2023-02-06 14:24:16 | Train | Epoch[265/600] Iteration[021/030] Train loss: 0.0125
2023-02-06 14:24:16 | Train | Epoch[265/600] Iteration[022/030] Train loss: 0.0125
2023-02-06 14:24:16 | Train | Epoch[265/600] Iteration[023/030] Train loss: 0.0124
2023-02-06 14:24:17 | Train | Epoch[265/600] Iteration[024/030] Train loss: 0.0125
2023-02-06 14:24:17 | Train | Epoch[265/600] Iteration[025/030] Train loss: 0.0125
2023-02-06 14:24:17 | Train | Epoch[265/600] Iteration[026/030] Train loss: 0.0125
2023-02-06 14:24:17 | Train | Epoch[265/600] Iteration[027/030] Train loss: 0.0126
2023-02-06 14:24:17 | Train | Epoch[265/600] Iteration[028/030] Train loss: 0.0126
2023-02-06 14:24:18 | Train | Epoch[265/600] Iteration[029/030] Train loss: 0.0125
2023-02-06 14:24:18 | Train | Epoch[265/600] Iteration[030/030] Train loss: 0.0127
2023-02-06 14:24:18 | Valid | Epoch[265/600] Iteration[001/008] Valid loss: 0.6922
2023-02-06 14:24:18 | Valid | Epoch[265/600] Iteration[002/008] Valid loss: 0.6224
2023-02-06 14:24:18 | Valid | Epoch[265/600] Iteration[003/008] Valid loss: 0.6257
2023-02-06 14:24:18 | Valid | Epoch[265/600] Iteration[004/008] Valid loss: 0.6261
2023-02-06 14:24:18 | Valid | Epoch[265/600] Iteration[005/008] Valid loss: 0.6370
2023-02-06 14:24:18 | Valid | Epoch[265/600] Iteration[006/008] Valid loss: 0.6295
2023-02-06 14:24:18 | Valid | Epoch[265/600] Iteration[007/008] Valid loss: 0.6561
2023-02-06 14:24:18 | Valid | Epoch[265/600] Iteration[008/008] Valid loss: 0.6967
2023-02-06 14:24:19 | Valid | Epoch[265/600] MIou: 0.8515314851122497
2023-02-06 14:24:19 | Valid | Epoch[265/600] Pixel Accuracy: 0.9683202107747396
2023-02-06 14:24:19 | Valid | Epoch[265/600] Mean Pixel Accuracy: 0.9768302885984962
2023-02-06 14:24:19 | Stage | Epoch[265/600] Train loss:0.0127
2023-02-06 14:24:19 | Stage | Epoch[265/600] Valid loss:0.6967
2023-02-06 14:24:19 | Stage | Epoch[265/600] LR:0.01

2023-02-06 14:24:19 | Train | Epoch[266/600] Iteration[001/030] Train loss: 0.0117
2023-02-06 14:24:19 | Train | Epoch[266/600] Iteration[002/030] Train loss: 0.0121
2023-02-06 14:24:19 | Train | Epoch[266/600] Iteration[003/030] Train loss: 0.0120
2023-02-06 14:24:20 | Train | Epoch[266/600] Iteration[004/030] Train loss: 0.0122
2023-02-06 14:24:20 | Train | Epoch[266/600] Iteration[005/030] Train loss: 0.0120
2023-02-06 14:24:20 | Train | Epoch[266/600] Iteration[006/030] Train loss: 0.0121
2023-02-06 14:24:20 | Train | Epoch[266/600] Iteration[007/030] Train loss: 0.0119
2023-02-06 14:24:21 | Train | Epoch[266/600] Iteration[008/030] Train loss: 0.0119
2023-02-06 14:24:21 | Train | Epoch[266/600] Iteration[009/030] Train loss: 0.0118
2023-02-06 14:24:21 | Train | Epoch[266/600] Iteration[010/030] Train loss: 0.0119
2023-02-06 14:24:21 | Train | Epoch[266/600] Iteration[011/030] Train loss: 0.0119
2023-02-06 14:24:21 | Train | Epoch[266/600] Iteration[012/030] Train loss: 0.0121
2023-02-06 14:24:22 | Train | Epoch[266/600] Iteration[013/030] Train loss: 0.0120
2023-02-06 14:24:22 | Train | Epoch[266/600] Iteration[014/030] Train loss: 0.0121
2023-02-06 14:24:22 | Train | Epoch[266/600] Iteration[015/030] Train loss: 0.0121
2023-02-06 14:24:22 | Train | Epoch[266/600] Iteration[016/030] Train loss: 0.0120
2023-02-06 14:24:23 | Train | Epoch[266/600] Iteration[017/030] Train loss: 0.0120
2023-02-06 14:24:23 | Train | Epoch[266/600] Iteration[018/030] Train loss: 0.0121
2023-02-06 14:24:23 | Train | Epoch[266/600] Iteration[019/030] Train loss: 0.0121
2023-02-06 14:24:23 | Train | Epoch[266/600] Iteration[020/030] Train loss: 0.0120
2023-02-06 14:24:23 | Train | Epoch[266/600] Iteration[021/030] Train loss: 0.0123
2023-02-06 14:24:24 | Train | Epoch[266/600] Iteration[022/030] Train loss: 0.0123
2023-02-06 14:24:24 | Train | Epoch[266/600] Iteration[023/030] Train loss: 0.0123
2023-02-06 14:24:24 | Train | Epoch[266/600] Iteration[024/030] Train loss: 0.0123
2023-02-06 14:24:24 | Train | Epoch[266/600] Iteration[025/030] Train loss: 0.0123
2023-02-06 14:24:24 | Train | Epoch[266/600] Iteration[026/030] Train loss: 0.0125
2023-02-06 14:24:25 | Train | Epoch[266/600] Iteration[027/030] Train loss: 0.0125
2023-02-06 14:24:25 | Train | Epoch[266/600] Iteration[028/030] Train loss: 0.0125
2023-02-06 14:24:25 | Train | Epoch[266/600] Iteration[029/030] Train loss: 0.0125
2023-02-06 14:24:25 | Train | Epoch[266/600] Iteration[030/030] Train loss: 0.0125
2023-02-06 14:24:26 | Valid | Epoch[266/600] Iteration[001/008] Valid loss: 0.0985
2023-02-06 14:24:26 | Valid | Epoch[266/600] Iteration[002/008] Valid loss: 0.0795
2023-02-06 14:24:26 | Valid | Epoch[266/600] Iteration[003/008] Valid loss: 0.0735
2023-02-06 14:24:26 | Valid | Epoch[266/600] Iteration[004/008] Valid loss: 0.0690
2023-02-06 14:24:26 | Valid | Epoch[266/600] Iteration[005/008] Valid loss: 0.0671
2023-02-06 14:24:26 | Valid | Epoch[266/600] Iteration[006/008] Valid loss: 0.0643
2023-02-06 14:24:26 | Valid | Epoch[266/600] Iteration[007/008] Valid loss: 0.0648
2023-02-06 14:24:26 | Valid | Epoch[266/600] Iteration[008/008] Valid loss: 0.0639
2023-02-06 14:24:26 | Valid | Epoch[266/600] MIou: 0.9120714948512079
2023-02-06 14:24:26 | Valid | Epoch[266/600] Pixel Accuracy: 0.9851531982421875
2023-02-06 14:24:26 | Valid | Epoch[266/600] Mean Pixel Accuracy: 0.9308632500214544
2023-02-06 14:24:26 | Stage | Epoch[266/600] Train loss:0.0125
2023-02-06 14:24:26 | Stage | Epoch[266/600] Valid loss:0.0639
2023-02-06 14:24:26 | Stage | Epoch[266/600] LR:0.01

2023-02-06 14:24:26 | Train | Epoch[267/600] Iteration[001/030] Train loss: 0.0115
2023-02-06 14:24:27 | Train | Epoch[267/600] Iteration[002/030] Train loss: 0.0120
2023-02-06 14:24:27 | Train | Epoch[267/600] Iteration[003/030] Train loss: 0.0119
2023-02-06 14:24:27 | Train | Epoch[267/600] Iteration[004/030] Train loss: 0.0118
2023-02-06 14:24:27 | Train | Epoch[267/600] Iteration[005/030] Train loss: 0.0120
2023-02-06 14:24:28 | Train | Epoch[267/600] Iteration[006/030] Train loss: 0.0119
2023-02-06 14:24:28 | Train | Epoch[267/600] Iteration[007/030] Train loss: 0.0119
2023-02-06 14:24:28 | Train | Epoch[267/600] Iteration[008/030] Train loss: 0.0119
2023-02-06 14:24:28 | Train | Epoch[267/600] Iteration[009/030] Train loss: 0.0119
2023-02-06 14:24:28 | Train | Epoch[267/600] Iteration[010/030] Train loss: 0.0120
2023-02-06 14:24:29 | Train | Epoch[267/600] Iteration[011/030] Train loss: 0.0119
2023-02-06 14:24:29 | Train | Epoch[267/600] Iteration[012/030] Train loss: 0.0120
2023-02-06 14:24:29 | Train | Epoch[267/600] Iteration[013/030] Train loss: 0.0120
2023-02-06 14:24:29 | Train | Epoch[267/600] Iteration[014/030] Train loss: 0.0120
2023-02-06 14:24:30 | Train | Epoch[267/600] Iteration[015/030] Train loss: 0.0120
2023-02-06 14:24:30 | Train | Epoch[267/600] Iteration[016/030] Train loss: 0.0119
2023-02-06 14:24:30 | Train | Epoch[267/600] Iteration[017/030] Train loss: 0.0119
2023-02-06 14:24:30 | Train | Epoch[267/600] Iteration[018/030] Train loss: 0.0119
2023-02-06 14:24:30 | Train | Epoch[267/600] Iteration[019/030] Train loss: 0.0119
2023-02-06 14:24:31 | Train | Epoch[267/600] Iteration[020/030] Train loss: 0.0120
2023-02-06 14:24:31 | Train | Epoch[267/600] Iteration[021/030] Train loss: 0.0120
2023-02-06 14:24:31 | Train | Epoch[267/600] Iteration[022/030] Train loss: 0.0121
2023-02-06 14:24:31 | Train | Epoch[267/600] Iteration[023/030] Train loss: 0.0121
2023-02-06 14:24:32 | Train | Epoch[267/600] Iteration[024/030] Train loss: 0.0121
2023-02-06 14:24:32 | Train | Epoch[267/600] Iteration[025/030] Train loss: 0.0122
2023-02-06 14:24:32 | Train | Epoch[267/600] Iteration[026/030] Train loss: 0.0123
2023-02-06 14:24:32 | Train | Epoch[267/600] Iteration[027/030] Train loss: 0.0123
2023-02-06 14:24:32 | Train | Epoch[267/600] Iteration[028/030] Train loss: 0.0123
2023-02-06 14:24:33 | Train | Epoch[267/600] Iteration[029/030] Train loss: 0.0123
2023-02-06 14:24:33 | Train | Epoch[267/600] Iteration[030/030] Train loss: 0.0124
2023-02-06 14:24:33 | Valid | Epoch[267/600] Iteration[001/008] Valid loss: 0.3906
2023-02-06 14:24:33 | Valid | Epoch[267/600] Iteration[002/008] Valid loss: 0.3128
2023-02-06 14:24:33 | Valid | Epoch[267/600] Iteration[003/008] Valid loss: 0.3041
2023-02-06 14:24:33 | Valid | Epoch[267/600] Iteration[004/008] Valid loss: 0.2989
2023-02-06 14:24:33 | Valid | Epoch[267/600] Iteration[005/008] Valid loss: 0.3122
2023-02-06 14:24:33 | Valid | Epoch[267/600] Iteration[006/008] Valid loss: 0.3098
2023-02-06 14:24:33 | Valid | Epoch[267/600] Iteration[007/008] Valid loss: 0.3363
2023-02-06 14:24:33 | Valid | Epoch[267/600] Iteration[008/008] Valid loss: 0.3449
2023-02-06 14:24:34 | Valid | Epoch[267/600] MIou: 0.9125517910342531
2023-02-06 14:24:34 | Valid | Epoch[267/600] Pixel Accuracy: 0.9837481180826823
2023-02-06 14:24:34 | Valid | Epoch[267/600] Mean Pixel Accuracy: 0.9755331173676469
2023-02-06 14:24:34 | Stage | Epoch[267/600] Train loss:0.0124
2023-02-06 14:24:34 | Stage | Epoch[267/600] Valid loss:0.3449
2023-02-06 14:24:34 | Stage | Epoch[267/600] LR:0.01

2023-02-06 14:24:34 | Train | Epoch[268/600] Iteration[001/030] Train loss: 0.0125
2023-02-06 14:24:34 | Train | Epoch[268/600] Iteration[002/030] Train loss: 0.0136
2023-02-06 14:24:34 | Train | Epoch[268/600] Iteration[003/030] Train loss: 0.0136
2023-02-06 14:24:35 | Train | Epoch[268/600] Iteration[004/030] Train loss: 0.0133
2023-02-06 14:24:35 | Train | Epoch[268/600] Iteration[005/030] Train loss: 0.0128
2023-02-06 14:24:35 | Train | Epoch[268/600] Iteration[006/030] Train loss: 0.0125
2023-02-06 14:24:35 | Train | Epoch[268/600] Iteration[007/030] Train loss: 0.0123
2023-02-06 14:24:36 | Train | Epoch[268/600] Iteration[008/030] Train loss: 0.0124
2023-02-06 14:24:36 | Train | Epoch[268/600] Iteration[009/030] Train loss: 0.0124
2023-02-06 14:24:36 | Train | Epoch[268/600] Iteration[010/030] Train loss: 0.0124
2023-02-06 14:24:36 | Train | Epoch[268/600] Iteration[011/030] Train loss: 0.0126
2023-02-06 14:24:36 | Train | Epoch[268/600] Iteration[012/030] Train loss: 0.0124
2023-02-06 14:24:37 | Train | Epoch[268/600] Iteration[013/030] Train loss: 0.0124
2023-02-06 14:24:37 | Train | Epoch[268/600] Iteration[014/030] Train loss: 0.0124
2023-02-06 14:24:37 | Train | Epoch[268/600] Iteration[015/030] Train loss: 0.0124
2023-02-06 14:24:37 | Train | Epoch[268/600] Iteration[016/030] Train loss: 0.0125
2023-02-06 14:24:38 | Train | Epoch[268/600] Iteration[017/030] Train loss: 0.0125
2023-02-06 14:24:38 | Train | Epoch[268/600] Iteration[018/030] Train loss: 0.0125
2023-02-06 14:24:38 | Train | Epoch[268/600] Iteration[019/030] Train loss: 0.0125
2023-02-06 14:24:38 | Train | Epoch[268/600] Iteration[020/030] Train loss: 0.0128
2023-02-06 14:24:38 | Train | Epoch[268/600] Iteration[021/030] Train loss: 0.0129
2023-02-06 14:24:39 | Train | Epoch[268/600] Iteration[022/030] Train loss: 0.0129
2023-02-06 14:24:39 | Train | Epoch[268/600] Iteration[023/030] Train loss: 0.0129
2023-02-06 14:24:39 | Train | Epoch[268/600] Iteration[024/030] Train loss: 0.0128
2023-02-06 14:24:39 | Train | Epoch[268/600] Iteration[025/030] Train loss: 0.0128
2023-02-06 14:24:40 | Train | Epoch[268/600] Iteration[026/030] Train loss: 0.0129
2023-02-06 14:24:40 | Train | Epoch[268/600] Iteration[027/030] Train loss: 0.0129
2023-02-06 14:24:40 | Train | Epoch[268/600] Iteration[028/030] Train loss: 0.0129
2023-02-06 14:24:40 | Train | Epoch[268/600] Iteration[029/030] Train loss: 0.0128
2023-02-06 14:24:40 | Train | Epoch[268/600] Iteration[030/030] Train loss: 0.0130
2023-02-06 14:24:41 | Valid | Epoch[268/600] Iteration[001/008] Valid loss: 0.4190
2023-02-06 14:24:41 | Valid | Epoch[268/600] Iteration[002/008] Valid loss: 0.3555
2023-02-06 14:24:41 | Valid | Epoch[268/600] Iteration[003/008] Valid loss: 0.3577
2023-02-06 14:24:41 | Valid | Epoch[268/600] Iteration[004/008] Valid loss: 0.3520
2023-02-06 14:24:41 | Valid | Epoch[268/600] Iteration[005/008] Valid loss: 0.3660
2023-02-06 14:24:41 | Valid | Epoch[268/600] Iteration[006/008] Valid loss: 0.3569
2023-02-06 14:24:41 | Valid | Epoch[268/600] Iteration[007/008] Valid loss: 0.3857
2023-02-06 14:24:41 | Valid | Epoch[268/600] Iteration[008/008] Valid loss: 0.4072
2023-02-06 14:24:41 | Valid | Epoch[268/600] MIou: 0.9038045574678919
2023-02-06 14:24:41 | Valid | Epoch[268/600] Pixel Accuracy: 0.9818242390950521
2023-02-06 14:24:41 | Valid | Epoch[268/600] Mean Pixel Accuracy: 0.9744820118961032
2023-02-06 14:24:41 | Stage | Epoch[268/600] Train loss:0.0130
2023-02-06 14:24:41 | Stage | Epoch[268/600] Valid loss:0.4072
2023-02-06 14:24:41 | Stage | Epoch[268/600] LR:0.01

2023-02-06 14:24:42 | Train | Epoch[269/600] Iteration[001/030] Train loss: 0.0121
2023-02-06 14:24:42 | Train | Epoch[269/600] Iteration[002/030] Train loss: 0.0124
2023-02-06 14:24:42 | Train | Epoch[269/600] Iteration[003/030] Train loss: 0.0127
2023-02-06 14:24:42 | Train | Epoch[269/600] Iteration[004/030] Train loss: 0.0125
2023-02-06 14:24:42 | Train | Epoch[269/600] Iteration[005/030] Train loss: 0.0126
2023-02-06 14:24:43 | Train | Epoch[269/600] Iteration[006/030] Train loss: 0.0128
2023-02-06 14:24:43 | Train | Epoch[269/600] Iteration[007/030] Train loss: 0.0126
2023-02-06 14:24:43 | Train | Epoch[269/600] Iteration[008/030] Train loss: 0.0126
2023-02-06 14:24:43 | Train | Epoch[269/600] Iteration[009/030] Train loss: 0.0127
2023-02-06 14:24:44 | Train | Epoch[269/600] Iteration[010/030] Train loss: 0.0125
2023-02-06 14:24:44 | Train | Epoch[269/600] Iteration[011/030] Train loss: 0.0125
2023-02-06 14:24:44 | Train | Epoch[269/600] Iteration[012/030] Train loss: 0.0126
2023-02-06 14:24:44 | Train | Epoch[269/600] Iteration[013/030] Train loss: 0.0126
2023-02-06 14:24:44 | Train | Epoch[269/600] Iteration[014/030] Train loss: 0.0126
2023-02-06 14:24:45 | Train | Epoch[269/600] Iteration[015/030] Train loss: 0.0125
2023-02-06 14:24:45 | Train | Epoch[269/600] Iteration[016/030] Train loss: 0.0125
2023-02-06 14:24:45 | Train | Epoch[269/600] Iteration[017/030] Train loss: 0.0124
2023-02-06 14:24:45 | Train | Epoch[269/600] Iteration[018/030] Train loss: 0.0124
2023-02-06 14:24:45 | Train | Epoch[269/600] Iteration[019/030] Train loss: 0.0124
2023-02-06 14:24:46 | Train | Epoch[269/600] Iteration[020/030] Train loss: 0.0124
2023-02-06 14:24:46 | Train | Epoch[269/600] Iteration[021/030] Train loss: 0.0123
2023-02-06 14:24:46 | Train | Epoch[269/600] Iteration[022/030] Train loss: 0.0123
2023-02-06 14:24:46 | Train | Epoch[269/600] Iteration[023/030] Train loss: 0.0123
2023-02-06 14:24:47 | Train | Epoch[269/600] Iteration[024/030] Train loss: 0.0123
2023-02-06 14:24:47 | Train | Epoch[269/600] Iteration[025/030] Train loss: 0.0122
2023-02-06 14:24:47 | Train | Epoch[269/600] Iteration[026/030] Train loss: 0.0123
2023-02-06 14:24:47 | Train | Epoch[269/600] Iteration[027/030] Train loss: 0.0124
2023-02-06 14:24:47 | Train | Epoch[269/600] Iteration[028/030] Train loss: 0.0123
2023-02-06 14:24:48 | Train | Epoch[269/600] Iteration[029/030] Train loss: 0.0124
2023-02-06 14:24:48 | Train | Epoch[269/600] Iteration[030/030] Train loss: 0.0124
2023-02-06 14:24:48 | Valid | Epoch[269/600] Iteration[001/008] Valid loss: 0.1223
2023-02-06 14:24:48 | Valid | Epoch[269/600] Iteration[002/008] Valid loss: 0.0961
2023-02-06 14:24:48 | Valid | Epoch[269/600] Iteration[003/008] Valid loss: 0.0888
2023-02-06 14:24:48 | Valid | Epoch[269/600] Iteration[004/008] Valid loss: 0.0921
2023-02-06 14:24:48 | Valid | Epoch[269/600] Iteration[005/008] Valid loss: 0.0927
2023-02-06 14:24:48 | Valid | Epoch[269/600] Iteration[006/008] Valid loss: 0.0893
2023-02-06 14:24:48 | Valid | Epoch[269/600] Iteration[007/008] Valid loss: 0.0897
2023-02-06 14:24:48 | Valid | Epoch[269/600] Iteration[008/008] Valid loss: 0.0884
2023-02-06 14:24:49 | Valid | Epoch[269/600] MIou: 0.9157050747970448
2023-02-06 14:24:49 | Valid | Epoch[269/600] Pixel Accuracy: 0.9855308532714844
2023-02-06 14:24:49 | Valid | Epoch[269/600] Mean Pixel Accuracy: 0.9415326033270852
2023-02-06 14:24:49 | Stage | Epoch[269/600] Train loss:0.0124
2023-02-06 14:24:49 | Stage | Epoch[269/600] Valid loss:0.0884
2023-02-06 14:24:49 | Stage | Epoch[269/600] LR:0.01

2023-02-06 14:24:49 | Train | Epoch[270/600] Iteration[001/030] Train loss: 0.0115
2023-02-06 14:24:49 | Train | Epoch[270/600] Iteration[002/030] Train loss: 0.0118
2023-02-06 14:24:49 | Train | Epoch[270/600] Iteration[003/030] Train loss: 0.0122
2023-02-06 14:24:50 | Train | Epoch[270/600] Iteration[004/030] Train loss: 0.0122
2023-02-06 14:24:50 | Train | Epoch[270/600] Iteration[005/030] Train loss: 0.0119
2023-02-06 14:24:50 | Train | Epoch[270/600] Iteration[006/030] Train loss: 0.0117
2023-02-06 14:24:50 | Train | Epoch[270/600] Iteration[007/030] Train loss: 0.0119
2023-02-06 14:24:51 | Train | Epoch[270/600] Iteration[008/030] Train loss: 0.0121
2023-02-06 14:24:51 | Train | Epoch[270/600] Iteration[009/030] Train loss: 0.0121
2023-02-06 14:24:51 | Train | Epoch[270/600] Iteration[010/030] Train loss: 0.0121
2023-02-06 14:24:51 | Train | Epoch[270/600] Iteration[011/030] Train loss: 0.0121
2023-02-06 14:24:51 | Train | Epoch[270/600] Iteration[012/030] Train loss: 0.0121
2023-02-06 14:24:52 | Train | Epoch[270/600] Iteration[013/030] Train loss: 0.0121
2023-02-06 14:24:52 | Train | Epoch[270/600] Iteration[014/030] Train loss: 0.0120
2023-02-06 14:24:52 | Train | Epoch[270/600] Iteration[015/030] Train loss: 0.0120
2023-02-06 14:24:52 | Train | Epoch[270/600] Iteration[016/030] Train loss: 0.0121
2023-02-06 14:24:53 | Train | Epoch[270/600] Iteration[017/030] Train loss: 0.0121
2023-02-06 14:24:53 | Train | Epoch[270/600] Iteration[018/030] Train loss: 0.0121
2023-02-06 14:24:53 | Train | Epoch[270/600] Iteration[019/030] Train loss: 0.0121
2023-02-06 14:24:53 | Train | Epoch[270/600] Iteration[020/030] Train loss: 0.0120
2023-02-06 14:24:53 | Train | Epoch[270/600] Iteration[021/030] Train loss: 0.0120
2023-02-06 14:24:54 | Train | Epoch[270/600] Iteration[022/030] Train loss: 0.0120
2023-02-06 14:24:54 | Train | Epoch[270/600] Iteration[023/030] Train loss: 0.0120
2023-02-06 14:24:54 | Train | Epoch[270/600] Iteration[024/030] Train loss: 0.0120
2023-02-06 14:24:54 | Train | Epoch[270/600] Iteration[025/030] Train loss: 0.0120
2023-02-06 14:24:54 | Train | Epoch[270/600] Iteration[026/030] Train loss: 0.0120
2023-02-06 14:24:55 | Train | Epoch[270/600] Iteration[027/030] Train loss: 0.0120
2023-02-06 14:24:55 | Train | Epoch[270/600] Iteration[028/030] Train loss: 0.0119
2023-02-06 14:24:55 | Train | Epoch[270/600] Iteration[029/030] Train loss: 0.0119
2023-02-06 14:24:55 | Train | Epoch[270/600] Iteration[030/030] Train loss: 0.0119
2023-02-06 14:24:56 | Valid | Epoch[270/600] Iteration[001/008] Valid loss: 0.1262
2023-02-06 14:24:56 | Valid | Epoch[270/600] Iteration[002/008] Valid loss: 0.0999
2023-02-06 14:24:56 | Valid | Epoch[270/600] Iteration[003/008] Valid loss: 0.0934
2023-02-06 14:24:56 | Valid | Epoch[270/600] Iteration[004/008] Valid loss: 0.0908
2023-02-06 14:24:56 | Valid | Epoch[270/600] Iteration[005/008] Valid loss: 0.0863
2023-02-06 14:24:56 | Valid | Epoch[270/600] Iteration[006/008] Valid loss: 0.0852
2023-02-06 14:24:56 | Valid | Epoch[270/600] Iteration[007/008] Valid loss: 0.0906
2023-02-06 14:24:56 | Valid | Epoch[270/600] Iteration[008/008] Valid loss: 0.0874
2023-02-06 14:24:56 | Valid | Epoch[270/600] MIou: 0.9305415780355057
2023-02-06 14:24:56 | Valid | Epoch[270/600] Pixel Accuracy: 0.988012949625651
2023-02-06 14:24:56 | Valid | Epoch[270/600] Mean Pixel Accuracy: 0.9582598318159538
2023-02-06 14:24:56 | Stage | Epoch[270/600] Train loss:0.0119
2023-02-06 14:24:56 | Stage | Epoch[270/600] Valid loss:0.0874
2023-02-06 14:24:56 | Stage | Epoch[270/600] LR:0.01

2023-02-06 14:24:56 | Train | Epoch[271/600] Iteration[001/030] Train loss: 0.0141
2023-02-06 14:24:57 | Train | Epoch[271/600] Iteration[002/030] Train loss: 0.0130
2023-02-06 14:24:57 | Train | Epoch[271/600] Iteration[003/030] Train loss: 0.0121
2023-02-06 14:24:57 | Train | Epoch[271/600] Iteration[004/030] Train loss: 0.0120
2023-02-06 14:24:57 | Train | Epoch[271/600] Iteration[005/030] Train loss: 0.0119
2023-02-06 14:24:58 | Train | Epoch[271/600] Iteration[006/030] Train loss: 0.0121
2023-02-06 14:24:58 | Train | Epoch[271/600] Iteration[007/030] Train loss: 0.0120
2023-02-06 14:24:58 | Train | Epoch[271/600] Iteration[008/030] Train loss: 0.0120
2023-02-06 14:24:58 | Train | Epoch[271/600] Iteration[009/030] Train loss: 0.0119
2023-02-06 14:24:58 | Train | Epoch[271/600] Iteration[010/030] Train loss: 0.0121
2023-02-06 14:24:59 | Train | Epoch[271/600] Iteration[011/030] Train loss: 0.0122
2023-02-06 14:24:59 | Train | Epoch[271/600] Iteration[012/030] Train loss: 0.0122
2023-02-06 14:24:59 | Train | Epoch[271/600] Iteration[013/030] Train loss: 0.0123
2023-02-06 14:24:59 | Train | Epoch[271/600] Iteration[014/030] Train loss: 0.0122
2023-02-06 14:25:00 | Train | Epoch[271/600] Iteration[015/030] Train loss: 0.0124
2023-02-06 14:25:00 | Train | Epoch[271/600] Iteration[016/030] Train loss: 0.0123
2023-02-06 14:25:00 | Train | Epoch[271/600] Iteration[017/030] Train loss: 0.0123
2023-02-06 14:25:00 | Train | Epoch[271/600] Iteration[018/030] Train loss: 0.0123
2023-02-06 14:25:00 | Train | Epoch[271/600] Iteration[019/030] Train loss: 0.0123
2023-02-06 14:25:01 | Train | Epoch[271/600] Iteration[020/030] Train loss: 0.0128
2023-02-06 14:25:01 | Train | Epoch[271/600] Iteration[021/030] Train loss: 0.0127
2023-02-06 14:25:01 | Train | Epoch[271/600] Iteration[022/030] Train loss: 0.0126
2023-02-06 14:25:01 | Train | Epoch[271/600] Iteration[023/030] Train loss: 0.0127
2023-02-06 14:25:02 | Train | Epoch[271/600] Iteration[024/030] Train loss: 0.0126
2023-02-06 14:25:02 | Train | Epoch[271/600] Iteration[025/030] Train loss: 0.0126
2023-02-06 14:25:02 | Train | Epoch[271/600] Iteration[026/030] Train loss: 0.0127
2023-02-06 14:25:02 | Train | Epoch[271/600] Iteration[027/030] Train loss: 0.0127
2023-02-06 14:25:02 | Train | Epoch[271/600] Iteration[028/030] Train loss: 0.0127
2023-02-06 14:25:03 | Train | Epoch[271/600] Iteration[029/030] Train loss: 0.0126
2023-02-06 14:25:03 | Train | Epoch[271/600] Iteration[030/030] Train loss: 0.0126
2023-02-06 14:25:03 | Valid | Epoch[271/600] Iteration[001/008] Valid loss: 0.1996
2023-02-06 14:25:03 | Valid | Epoch[271/600] Iteration[002/008] Valid loss: 0.1912
2023-02-06 14:25:03 | Valid | Epoch[271/600] Iteration[003/008] Valid loss: 0.1996
2023-02-06 14:25:03 | Valid | Epoch[271/600] Iteration[004/008] Valid loss: 0.1967
2023-02-06 14:25:03 | Valid | Epoch[271/600] Iteration[005/008] Valid loss: 0.1980
2023-02-06 14:25:03 | Valid | Epoch[271/600] Iteration[006/008] Valid loss: 0.1950
2023-02-06 14:25:03 | Valid | Epoch[271/600] Iteration[007/008] Valid loss: 0.1897
2023-02-06 14:25:03 | Valid | Epoch[271/600] Iteration[008/008] Valid loss: 0.1959
2023-02-06 14:25:04 | Valid | Epoch[271/600] MIou: 0.5967641664259945
2023-02-06 14:25:04 | Valid | Epoch[271/600] Pixel Accuracy: 0.9332771301269531
2023-02-06 14:25:04 | Valid | Epoch[271/600] Mean Pixel Accuracy: 0.6310031316935603
2023-02-06 14:25:04 | Stage | Epoch[271/600] Train loss:0.0126
2023-02-06 14:25:04 | Stage | Epoch[271/600] Valid loss:0.1959
2023-02-06 14:25:04 | Stage | Epoch[271/600] LR:0.01

2023-02-06 14:25:04 | Train | Epoch[272/600] Iteration[001/030] Train loss: 0.0109
2023-02-06 14:25:04 | Train | Epoch[272/600] Iteration[002/030] Train loss: 0.0120
2023-02-06 14:25:04 | Train | Epoch[272/600] Iteration[003/030] Train loss: 0.0125
2023-02-06 14:25:05 | Train | Epoch[272/600] Iteration[004/030] Train loss: 0.0124
2023-02-06 14:25:05 | Train | Epoch[272/600] Iteration[005/030] Train loss: 0.0134
2023-02-06 14:25:05 | Train | Epoch[272/600] Iteration[006/030] Train loss: 0.0132
2023-02-06 14:25:05 | Train | Epoch[272/600] Iteration[007/030] Train loss: 0.0129
2023-02-06 14:25:06 | Train | Epoch[272/600] Iteration[008/030] Train loss: 0.0130
2023-02-06 14:25:06 | Train | Epoch[272/600] Iteration[009/030] Train loss: 0.0129
2023-02-06 14:25:06 | Train | Epoch[272/600] Iteration[010/030] Train loss: 0.0128
2023-02-06 14:25:06 | Train | Epoch[272/600] Iteration[011/030] Train loss: 0.0128
2023-02-06 14:25:06 | Train | Epoch[272/600] Iteration[012/030] Train loss: 0.0128
2023-02-06 14:25:07 | Train | Epoch[272/600] Iteration[013/030] Train loss: 0.0128
2023-02-06 14:25:07 | Train | Epoch[272/600] Iteration[014/030] Train loss: 0.0129
2023-02-06 14:25:07 | Train | Epoch[272/600] Iteration[015/030] Train loss: 0.0129
2023-02-06 14:25:07 | Train | Epoch[272/600] Iteration[016/030] Train loss: 0.0129
2023-02-06 14:25:08 | Train | Epoch[272/600] Iteration[017/030] Train loss: 0.0130
2023-02-06 14:25:08 | Train | Epoch[272/600] Iteration[018/030] Train loss: 0.0130
2023-02-06 14:25:08 | Train | Epoch[272/600] Iteration[019/030] Train loss: 0.0130
2023-02-06 14:25:08 | Train | Epoch[272/600] Iteration[020/030] Train loss: 0.0130
2023-02-06 14:25:08 | Train | Epoch[272/600] Iteration[021/030] Train loss: 0.0130
2023-02-06 14:25:09 | Train | Epoch[272/600] Iteration[022/030] Train loss: 0.0130
2023-02-06 14:25:09 | Train | Epoch[272/600] Iteration[023/030] Train loss: 0.0130
2023-02-06 14:25:09 | Train | Epoch[272/600] Iteration[024/030] Train loss: 0.0129
2023-02-06 14:25:09 | Train | Epoch[272/600] Iteration[025/030] Train loss: 0.0129
2023-02-06 14:25:09 | Train | Epoch[272/600] Iteration[026/030] Train loss: 0.0129
2023-02-06 14:25:10 | Train | Epoch[272/600] Iteration[027/030] Train loss: 0.0128
2023-02-06 14:25:10 | Train | Epoch[272/600] Iteration[028/030] Train loss: 0.0128
2023-02-06 14:25:10 | Train | Epoch[272/600] Iteration[029/030] Train loss: 0.0128
2023-02-06 14:25:10 | Train | Epoch[272/600] Iteration[030/030] Train loss: 0.0129
2023-02-06 14:25:11 | Valid | Epoch[272/600] Iteration[001/008] Valid loss: 0.2527
2023-02-06 14:25:11 | Valid | Epoch[272/600] Iteration[002/008] Valid loss: 0.2024
2023-02-06 14:25:11 | Valid | Epoch[272/600] Iteration[003/008] Valid loss: 0.2013
2023-02-06 14:25:11 | Valid | Epoch[272/600] Iteration[004/008] Valid loss: 0.2031
2023-02-06 14:25:11 | Valid | Epoch[272/600] Iteration[005/008] Valid loss: 0.2058
2023-02-06 14:25:11 | Valid | Epoch[272/600] Iteration[006/008] Valid loss: 0.2064
2023-02-06 14:25:11 | Valid | Epoch[272/600] Iteration[007/008] Valid loss: 0.2329
2023-02-06 14:25:11 | Valid | Epoch[272/600] Iteration[008/008] Valid loss: 0.2315
2023-02-06 14:25:11 | Valid | Epoch[272/600] MIou: 0.9256278713733266
2023-02-06 14:25:11 | Valid | Epoch[272/600] Pixel Accuracy: 0.9866065979003906
2023-02-06 14:25:11 | Valid | Epoch[272/600] Mean Pixel Accuracy: 0.9735789576259588
2023-02-06 14:25:11 | Stage | Epoch[272/600] Train loss:0.0129
2023-02-06 14:25:11 | Stage | Epoch[272/600] Valid loss:0.2315
2023-02-06 14:25:11 | Stage | Epoch[272/600] LR:0.01

2023-02-06 14:25:12 | Train | Epoch[273/600] Iteration[001/030] Train loss: 0.0142
2023-02-06 14:25:12 | Train | Epoch[273/600] Iteration[002/030] Train loss: 0.0136
2023-02-06 14:25:12 | Train | Epoch[273/600] Iteration[003/030] Train loss: 0.0134
2023-02-06 14:25:12 | Train | Epoch[273/600] Iteration[004/030] Train loss: 0.0127
2023-02-06 14:25:12 | Train | Epoch[273/600] Iteration[005/030] Train loss: 0.0130
2023-02-06 14:25:13 | Train | Epoch[273/600] Iteration[006/030] Train loss: 0.0135
2023-02-06 14:25:13 | Train | Epoch[273/600] Iteration[007/030] Train loss: 0.0131
2023-02-06 14:25:13 | Train | Epoch[273/600] Iteration[008/030] Train loss: 0.0131
2023-02-06 14:25:13 | Train | Epoch[273/600] Iteration[009/030] Train loss: 0.0131
2023-02-06 14:25:14 | Train | Epoch[273/600] Iteration[010/030] Train loss: 0.0131
2023-02-06 14:25:14 | Train | Epoch[273/600] Iteration[011/030] Train loss: 0.0129
2023-02-06 14:25:14 | Train | Epoch[273/600] Iteration[012/030] Train loss: 0.0128
2023-02-06 14:25:14 | Train | Epoch[273/600] Iteration[013/030] Train loss: 0.0127
2023-02-06 14:25:14 | Train | Epoch[273/600] Iteration[014/030] Train loss: 0.0126
2023-02-06 14:25:15 | Train | Epoch[273/600] Iteration[015/030] Train loss: 0.0126
2023-02-06 14:25:15 | Train | Epoch[273/600] Iteration[016/030] Train loss: 0.0125
2023-02-06 14:25:15 | Train | Epoch[273/600] Iteration[017/030] Train loss: 0.0124
2023-02-06 14:25:15 | Train | Epoch[273/600] Iteration[018/030] Train loss: 0.0124
2023-02-06 14:25:16 | Train | Epoch[273/600] Iteration[019/030] Train loss: 0.0124
2023-02-06 14:25:16 | Train | Epoch[273/600] Iteration[020/030] Train loss: 0.0124
2023-02-06 14:25:16 | Train | Epoch[273/600] Iteration[021/030] Train loss: 0.0125
2023-02-06 14:25:16 | Train | Epoch[273/600] Iteration[022/030] Train loss: 0.0124
2023-02-06 14:25:16 | Train | Epoch[273/600] Iteration[023/030] Train loss: 0.0124
2023-02-06 14:25:17 | Train | Epoch[273/600] Iteration[024/030] Train loss: 0.0124
2023-02-06 14:25:17 | Train | Epoch[273/600] Iteration[025/030] Train loss: 0.0124
2023-02-06 14:25:17 | Train | Epoch[273/600] Iteration[026/030] Train loss: 0.0124
2023-02-06 14:25:17 | Train | Epoch[273/600] Iteration[027/030] Train loss: 0.0124
2023-02-06 14:25:18 | Train | Epoch[273/600] Iteration[028/030] Train loss: 0.0124
2023-02-06 14:25:18 | Train | Epoch[273/600] Iteration[029/030] Train loss: 0.0124
2023-02-06 14:25:18 | Train | Epoch[273/600] Iteration[030/030] Train loss: 0.0124
2023-02-06 14:25:18 | Valid | Epoch[273/600] Iteration[001/008] Valid loss: 0.1085
2023-02-06 14:25:18 | Valid | Epoch[273/600] Iteration[002/008] Valid loss: 0.0798
2023-02-06 14:25:18 | Valid | Epoch[273/600] Iteration[003/008] Valid loss: 0.0747
2023-02-06 14:25:18 | Valid | Epoch[273/600] Iteration[004/008] Valid loss: 0.0688
2023-02-06 14:25:18 | Valid | Epoch[273/600] Iteration[005/008] Valid loss: 0.0678
2023-02-06 14:25:18 | Valid | Epoch[273/600] Iteration[006/008] Valid loss: 0.0654
2023-02-06 14:25:18 | Valid | Epoch[273/600] Iteration[007/008] Valid loss: 0.0640
2023-02-06 14:25:18 | Valid | Epoch[273/600] Iteration[008/008] Valid loss: 0.0620
2023-02-06 14:25:19 | Valid | Epoch[273/600] MIou: 0.8970455995651019
2023-02-06 14:25:19 | Valid | Epoch[273/600] Pixel Accuracy: 0.9828020731608073
2023-02-06 14:25:19 | Valid | Epoch[273/600] Mean Pixel Accuracy: 0.9122234413466181
2023-02-06 14:25:19 | Stage | Epoch[273/600] Train loss:0.0124
2023-02-06 14:25:19 | Stage | Epoch[273/600] Valid loss:0.0620
2023-02-06 14:25:19 | Stage | Epoch[273/600] LR:0.01

2023-02-06 14:25:19 | Train | Epoch[274/600] Iteration[001/030] Train loss: 0.0122
2023-02-06 14:25:19 | Train | Epoch[274/600] Iteration[002/030] Train loss: 0.0122
2023-02-06 14:25:19 | Train | Epoch[274/600] Iteration[003/030] Train loss: 0.0121
2023-02-06 14:25:20 | Train | Epoch[274/600] Iteration[004/030] Train loss: 0.0124
2023-02-06 14:25:20 | Train | Epoch[274/600] Iteration[005/030] Train loss: 0.0125
2023-02-06 14:25:20 | Train | Epoch[274/600] Iteration[006/030] Train loss: 0.0123
2023-02-06 14:25:20 | Train | Epoch[274/600] Iteration[007/030] Train loss: 0.0128
2023-02-06 14:25:21 | Train | Epoch[274/600] Iteration[008/030] Train loss: 0.0126
2023-02-06 14:25:21 | Train | Epoch[274/600] Iteration[009/030] Train loss: 0.0124
2023-02-06 14:25:21 | Train | Epoch[274/600] Iteration[010/030] Train loss: 0.0124
2023-02-06 14:25:21 | Train | Epoch[274/600] Iteration[011/030] Train loss: 0.0123
2023-02-06 14:25:21 | Train | Epoch[274/600] Iteration[012/030] Train loss: 0.0123
2023-02-06 14:25:22 | Train | Epoch[274/600] Iteration[013/030] Train loss: 0.0121
2023-02-06 14:25:22 | Train | Epoch[274/600] Iteration[014/030] Train loss: 0.0123
2023-02-06 14:25:22 | Train | Epoch[274/600] Iteration[015/030] Train loss: 0.0123
2023-02-06 14:25:22 | Train | Epoch[274/600] Iteration[016/030] Train loss: 0.0123
2023-02-06 14:25:23 | Train | Epoch[274/600] Iteration[017/030] Train loss: 0.0123
2023-02-06 14:25:23 | Train | Epoch[274/600] Iteration[018/030] Train loss: 0.0122
2023-02-06 14:25:23 | Train | Epoch[274/600] Iteration[019/030] Train loss: 0.0123
2023-02-06 14:25:23 | Train | Epoch[274/600] Iteration[020/030] Train loss: 0.0123
2023-02-06 14:25:23 | Train | Epoch[274/600] Iteration[021/030] Train loss: 0.0123
2023-02-06 14:25:24 | Train | Epoch[274/600] Iteration[022/030] Train loss: 0.0123
2023-02-06 14:25:24 | Train | Epoch[274/600] Iteration[023/030] Train loss: 0.0123
2023-02-06 14:25:24 | Train | Epoch[274/600] Iteration[024/030] Train loss: 0.0123
2023-02-06 14:25:24 | Train | Epoch[274/600] Iteration[025/030] Train loss: 0.0124
2023-02-06 14:25:25 | Train | Epoch[274/600] Iteration[026/030] Train loss: 0.0123
2023-02-06 14:25:25 | Train | Epoch[274/600] Iteration[027/030] Train loss: 0.0123
2023-02-06 14:25:25 | Train | Epoch[274/600] Iteration[028/030] Train loss: 0.0124
2023-02-06 14:25:25 | Train | Epoch[274/600] Iteration[029/030] Train loss: 0.0123
2023-02-06 14:25:25 | Train | Epoch[274/600] Iteration[030/030] Train loss: 0.0124
2023-02-06 14:25:26 | Valid | Epoch[274/600] Iteration[001/008] Valid loss: 0.3775
2023-02-06 14:25:26 | Valid | Epoch[274/600] Iteration[002/008] Valid loss: 0.3535
2023-02-06 14:25:26 | Valid | Epoch[274/600] Iteration[003/008] Valid loss: 0.3656
2023-02-06 14:25:26 | Valid | Epoch[274/600] Iteration[004/008] Valid loss: 0.3578
2023-02-06 14:25:26 | Valid | Epoch[274/600] Iteration[005/008] Valid loss: 0.3752
2023-02-06 14:25:26 | Valid | Epoch[274/600] Iteration[006/008] Valid loss: 0.3802
2023-02-06 14:25:26 | Valid | Epoch[274/600] Iteration[007/008] Valid loss: 0.4132
2023-02-06 14:25:26 | Valid | Epoch[274/600] Iteration[008/008] Valid loss: 0.4353
2023-02-06 14:25:26 | Valid | Epoch[274/600] MIou: 0.8966029238971958
2023-02-06 14:25:26 | Valid | Epoch[274/600] Pixel Accuracy: 0.9799931844075521
2023-02-06 14:25:26 | Valid | Epoch[274/600] Mean Pixel Accuracy: 0.9785669847714595
2023-02-06 14:25:26 | Stage | Epoch[274/600] Train loss:0.0124
2023-02-06 14:25:26 | Stage | Epoch[274/600] Valid loss:0.4353
2023-02-06 14:25:26 | Stage | Epoch[274/600] LR:0.01

2023-02-06 14:25:26 | Train | Epoch[275/600] Iteration[001/030] Train loss: 0.0130
2023-02-06 14:25:27 | Train | Epoch[275/600] Iteration[002/030] Train loss: 0.0121
2023-02-06 14:25:27 | Train | Epoch[275/600] Iteration[003/030] Train loss: 0.0127
2023-02-06 14:25:27 | Train | Epoch[275/600] Iteration[004/030] Train loss: 0.0129
2023-02-06 14:25:27 | Train | Epoch[275/600] Iteration[005/030] Train loss: 0.0129
2023-02-06 14:25:28 | Train | Epoch[275/600] Iteration[006/030] Train loss: 0.0130
2023-02-06 14:25:28 | Train | Epoch[275/600] Iteration[007/030] Train loss: 0.0131
2023-02-06 14:25:28 | Train | Epoch[275/600] Iteration[008/030] Train loss: 0.0135
2023-02-06 14:25:28 | Train | Epoch[275/600] Iteration[009/030] Train loss: 0.0133
2023-02-06 14:25:28 | Train | Epoch[275/600] Iteration[010/030] Train loss: 0.0132
2023-02-06 14:25:29 | Train | Epoch[275/600] Iteration[011/030] Train loss: 0.0132
2023-02-06 14:25:29 | Train | Epoch[275/600] Iteration[012/030] Train loss: 0.0130
2023-02-06 14:25:29 | Train | Epoch[275/600] Iteration[013/030] Train loss: 0.0130
2023-02-06 14:25:29 | Train | Epoch[275/600] Iteration[014/030] Train loss: 0.0130
2023-02-06 14:25:30 | Train | Epoch[275/600] Iteration[015/030] Train loss: 0.0129
2023-02-06 14:25:30 | Train | Epoch[275/600] Iteration[016/030] Train loss: 0.0130
2023-02-06 14:25:30 | Train | Epoch[275/600] Iteration[017/030] Train loss: 0.0129
2023-02-06 14:25:30 | Train | Epoch[275/600] Iteration[018/030] Train loss: 0.0129
2023-02-06 14:25:30 | Train | Epoch[275/600] Iteration[019/030] Train loss: 0.0128
2023-02-06 14:25:31 | Train | Epoch[275/600] Iteration[020/030] Train loss: 0.0127
2023-02-06 14:25:31 | Train | Epoch[275/600] Iteration[021/030] Train loss: 0.0126
2023-02-06 14:25:31 | Train | Epoch[275/600] Iteration[022/030] Train loss: 0.0126
2023-02-06 14:25:31 | Train | Epoch[275/600] Iteration[023/030] Train loss: 0.0126
2023-02-06 14:25:32 | Train | Epoch[275/600] Iteration[024/030] Train loss: 0.0126
2023-02-06 14:25:32 | Train | Epoch[275/600] Iteration[025/030] Train loss: 0.0126
2023-02-06 14:25:32 | Train | Epoch[275/600] Iteration[026/030] Train loss: 0.0126
2023-02-06 14:25:32 | Train | Epoch[275/600] Iteration[027/030] Train loss: 0.0126
2023-02-06 14:25:32 | Train | Epoch[275/600] Iteration[028/030] Train loss: 0.0126
2023-02-06 14:25:33 | Train | Epoch[275/600] Iteration[029/030] Train loss: 0.0126
2023-02-06 14:25:33 | Train | Epoch[275/600] Iteration[030/030] Train loss: 0.0126
2023-02-06 14:25:33 | Valid | Epoch[275/600] Iteration[001/008] Valid loss: 0.1034
2023-02-06 14:25:33 | Valid | Epoch[275/600] Iteration[002/008] Valid loss: 0.1051
2023-02-06 14:25:33 | Valid | Epoch[275/600] Iteration[003/008] Valid loss: 0.1085
2023-02-06 14:25:33 | Valid | Epoch[275/600] Iteration[004/008] Valid loss: 0.1066
2023-02-06 14:25:33 | Valid | Epoch[275/600] Iteration[005/008] Valid loss: 0.1075
2023-02-06 14:25:33 | Valid | Epoch[275/600] Iteration[006/008] Valid loss: 0.1043
2023-02-06 14:25:33 | Valid | Epoch[275/600] Iteration[007/008] Valid loss: 0.0997
2023-02-06 14:25:33 | Valid | Epoch[275/600] Iteration[008/008] Valid loss: 0.1035
2023-02-06 14:25:34 | Valid | Epoch[275/600] MIou: 0.7124509409138338
2023-02-06 14:25:34 | Valid | Epoch[275/600] Pixel Accuracy: 0.9525108337402344
2023-02-06 14:25:34 | Valid | Epoch[275/600] Mean Pixel Accuracy: 0.7373729795730526
2023-02-06 14:25:34 | Stage | Epoch[275/600] Train loss:0.0126
2023-02-06 14:25:34 | Stage | Epoch[275/600] Valid loss:0.1035
2023-02-06 14:25:34 | Stage | Epoch[275/600] LR:0.01

2023-02-06 14:25:34 | Train | Epoch[276/600] Iteration[001/030] Train loss: 0.0112
2023-02-06 14:25:34 | Train | Epoch[276/600] Iteration[002/030] Train loss: 0.0111
2023-02-06 14:25:34 | Train | Epoch[276/600] Iteration[003/030] Train loss: 0.0110
2023-02-06 14:25:35 | Train | Epoch[276/600] Iteration[004/030] Train loss: 0.0112
2023-02-06 14:25:35 | Train | Epoch[276/600] Iteration[005/030] Train loss: 0.0113
2023-02-06 14:25:35 | Train | Epoch[276/600] Iteration[006/030] Train loss: 0.0114
2023-02-06 14:25:35 | Train | Epoch[276/600] Iteration[007/030] Train loss: 0.0115
2023-02-06 14:25:36 | Train | Epoch[276/600] Iteration[008/030] Train loss: 0.0113
2023-02-06 14:25:36 | Train | Epoch[276/600] Iteration[009/030] Train loss: 0.0113
2023-02-06 14:25:36 | Train | Epoch[276/600] Iteration[010/030] Train loss: 0.0111
2023-02-06 14:25:36 | Train | Epoch[276/600] Iteration[011/030] Train loss: 0.0111
2023-02-06 14:25:36 | Train | Epoch[276/600] Iteration[012/030] Train loss: 0.0112
2023-02-06 14:25:37 | Train | Epoch[276/600] Iteration[013/030] Train loss: 0.0112
2023-02-06 14:25:37 | Train | Epoch[276/600] Iteration[014/030] Train loss: 0.0113
2023-02-06 14:25:37 | Train | Epoch[276/600] Iteration[015/030] Train loss: 0.0113
2023-02-06 14:25:37 | Train | Epoch[276/600] Iteration[016/030] Train loss: 0.0113
2023-02-06 14:25:37 | Train | Epoch[276/600] Iteration[017/030] Train loss: 0.0114
2023-02-06 14:25:38 | Train | Epoch[276/600] Iteration[018/030] Train loss: 0.0113
2023-02-06 14:25:38 | Train | Epoch[276/600] Iteration[019/030] Train loss: 0.0113
2023-02-06 14:25:38 | Train | Epoch[276/600] Iteration[020/030] Train loss: 0.0114
2023-02-06 14:25:38 | Train | Epoch[276/600] Iteration[021/030] Train loss: 0.0114
2023-02-06 14:25:39 | Train | Epoch[276/600] Iteration[022/030] Train loss: 0.0114
2023-02-06 14:25:39 | Train | Epoch[276/600] Iteration[023/030] Train loss: 0.0114
2023-02-06 14:25:39 | Train | Epoch[276/600] Iteration[024/030] Train loss: 0.0115
2023-02-06 14:25:39 | Train | Epoch[276/600] Iteration[025/030] Train loss: 0.0117
2023-02-06 14:25:39 | Train | Epoch[276/600] Iteration[026/030] Train loss: 0.0116
2023-02-06 14:25:40 | Train | Epoch[276/600] Iteration[027/030] Train loss: 0.0117
2023-02-06 14:25:40 | Train | Epoch[276/600] Iteration[028/030] Train loss: 0.0117
2023-02-06 14:25:40 | Train | Epoch[276/600] Iteration[029/030] Train loss: 0.0117
2023-02-06 14:25:40 | Train | Epoch[276/600] Iteration[030/030] Train loss: 0.0117
2023-02-06 14:25:41 | Valid | Epoch[276/600] Iteration[001/008] Valid loss: 0.1360
2023-02-06 14:25:41 | Valid | Epoch[276/600] Iteration[002/008] Valid loss: 0.1405
2023-02-06 14:25:41 | Valid | Epoch[276/600] Iteration[003/008] Valid loss: 0.1471
2023-02-06 14:25:41 | Valid | Epoch[276/600] Iteration[004/008] Valid loss: 0.1472
2023-02-06 14:25:41 | Valid | Epoch[276/600] Iteration[005/008] Valid loss: 0.1478
2023-02-06 14:25:41 | Valid | Epoch[276/600] Iteration[006/008] Valid loss: 0.1439
2023-02-06 14:25:41 | Valid | Epoch[276/600] Iteration[007/008] Valid loss: 0.1377
2023-02-06 14:25:41 | Valid | Epoch[276/600] Iteration[008/008] Valid loss: 0.1405
2023-02-06 14:25:41 | Valid | Epoch[276/600] MIou: 0.6818395504238943
2023-02-06 14:25:41 | Valid | Epoch[276/600] Pixel Accuracy: 0.9474461873372396
2023-02-06 14:25:41 | Valid | Epoch[276/600] Mean Pixel Accuracy: 0.7091956455021422
2023-02-06 14:25:41 | Stage | Epoch[276/600] Train loss:0.0117
2023-02-06 14:25:41 | Stage | Epoch[276/600] Valid loss:0.1405
2023-02-06 14:25:41 | Stage | Epoch[276/600] LR:0.01

2023-02-06 14:25:41 | Train | Epoch[277/600] Iteration[001/030] Train loss: 0.0106
2023-02-06 14:25:42 | Train | Epoch[277/600] Iteration[002/030] Train loss: 0.0107
2023-02-06 14:25:42 | Train | Epoch[277/600] Iteration[003/030] Train loss: 0.0105
2023-02-06 14:25:42 | Train | Epoch[277/600] Iteration[004/030] Train loss: 0.0117
2023-02-06 14:25:42 | Train | Epoch[277/600] Iteration[005/030] Train loss: 0.0118
2023-02-06 14:25:43 | Train | Epoch[277/600] Iteration[006/030] Train loss: 0.0115
2023-02-06 14:25:43 | Train | Epoch[277/600] Iteration[007/030] Train loss: 0.0114
2023-02-06 14:25:43 | Train | Epoch[277/600] Iteration[008/030] Train loss: 0.0115
2023-02-06 14:25:43 | Train | Epoch[277/600] Iteration[009/030] Train loss: 0.0114
2023-02-06 14:25:43 | Train | Epoch[277/600] Iteration[010/030] Train loss: 0.0115
2023-02-06 14:25:44 | Train | Epoch[277/600] Iteration[011/030] Train loss: 0.0114
2023-02-06 14:25:44 | Train | Epoch[277/600] Iteration[012/030] Train loss: 0.0117
2023-02-06 14:25:44 | Train | Epoch[277/600] Iteration[013/030] Train loss: 0.0116
2023-02-06 14:25:44 | Train | Epoch[277/600] Iteration[014/030] Train loss: 0.0116
2023-02-06 14:25:45 | Train | Epoch[277/600] Iteration[015/030] Train loss: 0.0117
2023-02-06 14:25:45 | Train | Epoch[277/600] Iteration[016/030] Train loss: 0.0116
2023-02-06 14:25:45 | Train | Epoch[277/600] Iteration[017/030] Train loss: 0.0116
2023-02-06 14:25:45 | Train | Epoch[277/600] Iteration[018/030] Train loss: 0.0118
2023-02-06 14:25:45 | Train | Epoch[277/600] Iteration[019/030] Train loss: 0.0118
2023-02-06 14:25:46 | Train | Epoch[277/600] Iteration[020/030] Train loss: 0.0118
2023-02-06 14:25:46 | Train | Epoch[277/600] Iteration[021/030] Train loss: 0.0117
2023-02-06 14:25:46 | Train | Epoch[277/600] Iteration[022/030] Train loss: 0.0117
2023-02-06 14:25:46 | Train | Epoch[277/600] Iteration[023/030] Train loss: 0.0117
2023-02-06 14:25:47 | Train | Epoch[277/600] Iteration[024/030] Train loss: 0.0118
2023-02-06 14:25:47 | Train | Epoch[277/600] Iteration[025/030] Train loss: 0.0118
2023-02-06 14:25:47 | Train | Epoch[277/600] Iteration[026/030] Train loss: 0.0118
2023-02-06 14:25:47 | Train | Epoch[277/600] Iteration[027/030] Train loss: 0.0118
2023-02-06 14:25:47 | Train | Epoch[277/600] Iteration[028/030] Train loss: 0.0118
2023-02-06 14:25:48 | Train | Epoch[277/600] Iteration[029/030] Train loss: 0.0118
2023-02-06 14:25:48 | Train | Epoch[277/600] Iteration[030/030] Train loss: 0.0118
2023-02-06 14:25:48 | Valid | Epoch[277/600] Iteration[001/008] Valid loss: 0.0862
2023-02-06 14:25:48 | Valid | Epoch[277/600] Iteration[002/008] Valid loss: 0.0780
2023-02-06 14:25:48 | Valid | Epoch[277/600] Iteration[003/008] Valid loss: 0.0786
2023-02-06 14:25:48 | Valid | Epoch[277/600] Iteration[004/008] Valid loss: 0.0760
2023-02-06 14:25:48 | Valid | Epoch[277/600] Iteration[005/008] Valid loss: 0.0751
2023-02-06 14:25:48 | Valid | Epoch[277/600] Iteration[006/008] Valid loss: 0.0732
2023-02-06 14:25:48 | Valid | Epoch[277/600] Iteration[007/008] Valid loss: 0.0701
2023-02-06 14:25:48 | Valid | Epoch[277/600] Iteration[008/008] Valid loss: 0.0707
2023-02-06 14:25:49 | Valid | Epoch[277/600] MIou: 0.8229626067379627
2023-02-06 14:25:49 | Valid | Epoch[277/600] Pixel Accuracy: 0.9707310994466146
2023-02-06 14:25:49 | Valid | Epoch[277/600] Mean Pixel Accuracy: 0.8396034323525057
2023-02-06 14:25:49 | Stage | Epoch[277/600] Train loss:0.0118
2023-02-06 14:25:49 | Stage | Epoch[277/600] Valid loss:0.0707
2023-02-06 14:25:49 | Stage | Epoch[277/600] LR:0.01

2023-02-06 14:25:49 | Train | Epoch[278/600] Iteration[001/030] Train loss: 0.0116
2023-02-06 14:25:49 | Train | Epoch[278/600] Iteration[002/030] Train loss: 0.0111
2023-02-06 14:25:49 | Train | Epoch[278/600] Iteration[003/030] Train loss: 0.0109
2023-02-06 14:25:50 | Train | Epoch[278/600] Iteration[004/030] Train loss: 0.0113
2023-02-06 14:25:50 | Train | Epoch[278/600] Iteration[005/030] Train loss: 0.0109
2023-02-06 14:25:50 | Train | Epoch[278/600] Iteration[006/030] Train loss: 0.0109
2023-02-06 14:25:50 | Train | Epoch[278/600] Iteration[007/030] Train loss: 0.0108
2023-02-06 14:25:51 | Train | Epoch[278/600] Iteration[008/030] Train loss: 0.0111
2023-02-06 14:25:51 | Train | Epoch[278/600] Iteration[009/030] Train loss: 0.0111
2023-02-06 14:25:51 | Train | Epoch[278/600] Iteration[010/030] Train loss: 0.0111
2023-02-06 14:25:51 | Train | Epoch[278/600] Iteration[011/030] Train loss: 0.0113
2023-02-06 14:25:51 | Train | Epoch[278/600] Iteration[012/030] Train loss: 0.0114
2023-02-06 14:25:52 | Train | Epoch[278/600] Iteration[013/030] Train loss: 0.0114
2023-02-06 14:25:52 | Train | Epoch[278/600] Iteration[014/030] Train loss: 0.0115
2023-02-06 14:25:52 | Train | Epoch[278/600] Iteration[015/030] Train loss: 0.0115
2023-02-06 14:25:52 | Train | Epoch[278/600] Iteration[016/030] Train loss: 0.0116
2023-02-06 14:25:53 | Train | Epoch[278/600] Iteration[017/030] Train loss: 0.0117
2023-02-06 14:25:53 | Train | Epoch[278/600] Iteration[018/030] Train loss: 0.0117
2023-02-06 14:25:53 | Train | Epoch[278/600] Iteration[019/030] Train loss: 0.0117
2023-02-06 14:25:53 | Train | Epoch[278/600] Iteration[020/030] Train loss: 0.0116
2023-02-06 14:25:53 | Train | Epoch[278/600] Iteration[021/030] Train loss: 0.0117
2023-02-06 14:25:54 | Train | Epoch[278/600] Iteration[022/030] Train loss: 0.0117
2023-02-06 14:25:54 | Train | Epoch[278/600] Iteration[023/030] Train loss: 0.0117
2023-02-06 14:25:54 | Train | Epoch[278/600] Iteration[024/030] Train loss: 0.0116
2023-02-06 14:25:54 | Train | Epoch[278/600] Iteration[025/030] Train loss: 0.0116
2023-02-06 14:25:54 | Train | Epoch[278/600] Iteration[026/030] Train loss: 0.0117
2023-02-06 14:25:55 | Train | Epoch[278/600] Iteration[027/030] Train loss: 0.0116
2023-02-06 14:25:55 | Train | Epoch[278/600] Iteration[028/030] Train loss: 0.0116
2023-02-06 14:25:55 | Train | Epoch[278/600] Iteration[029/030] Train loss: 0.0116
2023-02-06 14:25:55 | Train | Epoch[278/600] Iteration[030/030] Train loss: 0.0117
2023-02-06 14:25:56 | Valid | Epoch[278/600] Iteration[001/008] Valid loss: 1.7804
2023-02-06 14:25:56 | Valid | Epoch[278/600] Iteration[002/008] Valid loss: 1.7294
2023-02-06 14:25:56 | Valid | Epoch[278/600] Iteration[003/008] Valid loss: 1.8363
2023-02-06 14:25:56 | Valid | Epoch[278/600] Iteration[004/008] Valid loss: 1.8529
2023-02-06 14:25:56 | Valid | Epoch[278/600] Iteration[005/008] Valid loss: 1.9037
2023-02-06 14:25:56 | Valid | Epoch[278/600] Iteration[006/008] Valid loss: 1.8785
2023-02-06 14:25:56 | Valid | Epoch[278/600] Iteration[007/008] Valid loss: 1.9409
2023-02-06 14:25:56 | Valid | Epoch[278/600] Iteration[008/008] Valid loss: 2.0367
2023-02-06 14:25:56 | Valid | Epoch[278/600] MIou: 0.8127675735757094
2023-02-06 14:25:56 | Valid | Epoch[278/600] Pixel Accuracy: 0.956329345703125
2023-02-06 14:25:56 | Valid | Epoch[278/600] Mean Pixel Accuracy: 0.9748871633754648
2023-02-06 14:25:56 | Stage | Epoch[278/600] Train loss:0.0117
2023-02-06 14:25:56 | Stage | Epoch[278/600] Valid loss:2.0367
2023-02-06 14:25:56 | Stage | Epoch[278/600] LR:0.01

2023-02-06 14:25:56 | Train | Epoch[279/600] Iteration[001/030] Train loss: 0.0104
2023-02-06 14:25:57 | Train | Epoch[279/600] Iteration[002/030] Train loss: 0.0114
2023-02-06 14:25:57 | Train | Epoch[279/600] Iteration[003/030] Train loss: 0.0113
2023-02-06 14:25:57 | Train | Epoch[279/600] Iteration[004/030] Train loss: 0.0121
2023-02-06 14:25:57 | Train | Epoch[279/600] Iteration[005/030] Train loss: 0.0118
2023-02-06 14:25:58 | Train | Epoch[279/600] Iteration[006/030] Train loss: 0.0118
2023-02-06 14:25:58 | Train | Epoch[279/600] Iteration[007/030] Train loss: 0.0117
2023-02-06 14:25:58 | Train | Epoch[279/600] Iteration[008/030] Train loss: 0.0120
2023-02-06 14:25:58 | Train | Epoch[279/600] Iteration[009/030] Train loss: 0.0121
2023-02-06 14:25:58 | Train | Epoch[279/600] Iteration[010/030] Train loss: 0.0121
2023-02-06 14:25:59 | Train | Epoch[279/600] Iteration[011/030] Train loss: 0.0121
2023-02-06 14:25:59 | Train | Epoch[279/600] Iteration[012/030] Train loss: 0.0120
2023-02-06 14:25:59 | Train | Epoch[279/600] Iteration[013/030] Train loss: 0.0120
2023-02-06 14:25:59 | Train | Epoch[279/600] Iteration[014/030] Train loss: 0.0120
2023-02-06 14:26:00 | Train | Epoch[279/600] Iteration[015/030] Train loss: 0.0121
2023-02-06 14:26:00 | Train | Epoch[279/600] Iteration[016/030] Train loss: 0.0120
2023-02-06 14:26:00 | Train | Epoch[279/600] Iteration[017/030] Train loss: 0.0120
2023-02-06 14:26:00 | Train | Epoch[279/600] Iteration[018/030] Train loss: 0.0121
2023-02-06 14:26:00 | Train | Epoch[279/600] Iteration[019/030] Train loss: 0.0121
2023-02-06 14:26:01 | Train | Epoch[279/600] Iteration[020/030] Train loss: 0.0120
2023-02-06 14:26:01 | Train | Epoch[279/600] Iteration[021/030] Train loss: 0.0120
2023-02-06 14:26:01 | Train | Epoch[279/600] Iteration[022/030] Train loss: 0.0120
2023-02-06 14:26:01 | Train | Epoch[279/600] Iteration[023/030] Train loss: 0.0121
2023-02-06 14:26:02 | Train | Epoch[279/600] Iteration[024/030] Train loss: 0.0120
2023-02-06 14:26:02 | Train | Epoch[279/600] Iteration[025/030] Train loss: 0.0120
2023-02-06 14:26:02 | Train | Epoch[279/600] Iteration[026/030] Train loss: 0.0120
2023-02-06 14:26:02 | Train | Epoch[279/600] Iteration[027/030] Train loss: 0.0122
2023-02-06 14:26:02 | Train | Epoch[279/600] Iteration[028/030] Train loss: 0.0122
2023-02-06 14:26:03 | Train | Epoch[279/600] Iteration[029/030] Train loss: 0.0122
2023-02-06 14:26:03 | Train | Epoch[279/600] Iteration[030/030] Train loss: 0.0122
2023-02-06 14:26:03 | Valid | Epoch[279/600] Iteration[001/008] Valid loss: 0.8884
2023-02-06 14:26:03 | Valid | Epoch[279/600] Iteration[002/008] Valid loss: 0.8392
2023-02-06 14:26:03 | Valid | Epoch[279/600] Iteration[003/008] Valid loss: 0.8694
2023-02-06 14:26:03 | Valid | Epoch[279/600] Iteration[004/008] Valid loss: 0.8620
2023-02-06 14:26:03 | Valid | Epoch[279/600] Iteration[005/008] Valid loss: 0.8890
2023-02-06 14:26:03 | Valid | Epoch[279/600] Iteration[006/008] Valid loss: 0.8756
2023-02-06 14:26:03 | Valid | Epoch[279/600] Iteration[007/008] Valid loss: 0.9223
2023-02-06 14:26:03 | Valid | Epoch[279/600] Iteration[008/008] Valid loss: 0.9672
2023-02-06 14:26:03 | Valid | Epoch[279/600] MIou: 0.8716264295400229
2023-02-06 14:26:03 | Valid | Epoch[279/600] Pixel Accuracy: 0.9736887613932291
2023-02-06 14:26:03 | Valid | Epoch[279/600] Mean Pixel Accuracy: 0.979762051567028
2023-02-06 14:26:03 | Stage | Epoch[279/600] Train loss:0.0122
2023-02-06 14:26:03 | Stage | Epoch[279/600] Valid loss:0.9672
2023-02-06 14:26:03 | Stage | Epoch[279/600] LR:0.01

2023-02-06 14:26:04 | Train | Epoch[280/600] Iteration[001/030] Train loss: 0.0116
2023-02-06 14:26:04 | Train | Epoch[280/600] Iteration[002/030] Train loss: 0.0121
2023-02-06 14:26:04 | Train | Epoch[280/600] Iteration[003/030] Train loss: 0.0118
2023-02-06 14:26:05 | Train | Epoch[280/600] Iteration[004/030] Train loss: 0.0115
2023-02-06 14:26:05 | Train | Epoch[280/600] Iteration[005/030] Train loss: 0.0115
2023-02-06 14:26:05 | Train | Epoch[280/600] Iteration[006/030] Train loss: 0.0113
2023-02-06 14:26:05 | Train | Epoch[280/600] Iteration[007/030] Train loss: 0.0114
2023-02-06 14:26:05 | Train | Epoch[280/600] Iteration[008/030] Train loss: 0.0112
2023-02-06 14:26:06 | Train | Epoch[280/600] Iteration[009/030] Train loss: 0.0113
2023-02-06 14:26:06 | Train | Epoch[280/600] Iteration[010/030] Train loss: 0.0115
2023-02-06 14:26:06 | Train | Epoch[280/600] Iteration[011/030] Train loss: 0.0117
2023-02-06 14:26:06 | Train | Epoch[280/600] Iteration[012/030] Train loss: 0.0116
2023-02-06 14:26:07 | Train | Epoch[280/600] Iteration[013/030] Train loss: 0.0115
2023-02-06 14:26:07 | Train | Epoch[280/600] Iteration[014/030] Train loss: 0.0115
2023-02-06 14:26:07 | Train | Epoch[280/600] Iteration[015/030] Train loss: 0.0117
2023-02-06 14:26:07 | Train | Epoch[280/600] Iteration[016/030] Train loss: 0.0116
2023-02-06 14:26:07 | Train | Epoch[280/600] Iteration[017/030] Train loss: 0.0118
2023-02-06 14:26:08 | Train | Epoch[280/600] Iteration[018/030] Train loss: 0.0118
2023-02-06 14:26:08 | Train | Epoch[280/600] Iteration[019/030] Train loss: 0.0119
2023-02-06 14:26:08 | Train | Epoch[280/600] Iteration[020/030] Train loss: 0.0118
2023-02-06 14:26:08 | Train | Epoch[280/600] Iteration[021/030] Train loss: 0.0118
2023-02-06 14:26:09 | Train | Epoch[280/600] Iteration[022/030] Train loss: 0.0119
2023-02-06 14:26:09 | Train | Epoch[280/600] Iteration[023/030] Train loss: 0.0118
2023-02-06 14:26:09 | Train | Epoch[280/600] Iteration[024/030] Train loss: 0.0118
2023-02-06 14:26:09 | Train | Epoch[280/600] Iteration[025/030] Train loss: 0.0118
2023-02-06 14:26:09 | Train | Epoch[280/600] Iteration[026/030] Train loss: 0.0118
2023-02-06 14:26:10 | Train | Epoch[280/600] Iteration[027/030] Train loss: 0.0118
2023-02-06 14:26:10 | Train | Epoch[280/600] Iteration[028/030] Train loss: 0.0117
2023-02-06 14:26:10 | Train | Epoch[280/600] Iteration[029/030] Train loss: 0.0117
2023-02-06 14:26:10 | Train | Epoch[280/600] Iteration[030/030] Train loss: 0.0117
2023-02-06 14:26:11 | Valid | Epoch[280/600] Iteration[001/008] Valid loss: 0.1174
2023-02-06 14:26:11 | Valid | Epoch[280/600] Iteration[002/008] Valid loss: 0.1146
2023-02-06 14:26:11 | Valid | Epoch[280/600] Iteration[003/008] Valid loss: 0.1185
2023-02-06 14:26:11 | Valid | Epoch[280/600] Iteration[004/008] Valid loss: 0.1182
2023-02-06 14:26:11 | Valid | Epoch[280/600] Iteration[005/008] Valid loss: 0.1172
2023-02-06 14:26:11 | Valid | Epoch[280/600] Iteration[006/008] Valid loss: 0.1142
2023-02-06 14:26:11 | Valid | Epoch[280/600] Iteration[007/008] Valid loss: 0.1099
2023-02-06 14:26:11 | Valid | Epoch[280/600] Iteration[008/008] Valid loss: 0.1119
2023-02-06 14:26:11 | Valid | Epoch[280/600] MIou: 0.7494477979654145
2023-02-06 14:26:11 | Valid | Epoch[280/600] Pixel Accuracy: 0.9586079915364584
2023-02-06 14:26:11 | Valid | Epoch[280/600] Mean Pixel Accuracy: 0.7715579504985921
2023-02-06 14:26:11 | Stage | Epoch[280/600] Train loss:0.0117
2023-02-06 14:26:11 | Stage | Epoch[280/600] Valid loss:0.1119
2023-02-06 14:26:11 | Stage | Epoch[280/600] LR:0.01

2023-02-06 14:26:12 | Train | Epoch[281/600] Iteration[001/030] Train loss: 0.0103
2023-02-06 14:26:12 | Train | Epoch[281/600] Iteration[002/030] Train loss: 0.0106
2023-02-06 14:26:12 | Train | Epoch[281/600] Iteration[003/030] Train loss: 0.0111
2023-02-06 14:26:12 | Train | Epoch[281/600] Iteration[004/030] Train loss: 0.0110
2023-02-06 14:26:12 | Train | Epoch[281/600] Iteration[005/030] Train loss: 0.0112
2023-02-06 14:26:13 | Train | Epoch[281/600] Iteration[006/030] Train loss: 0.0117
2023-02-06 14:26:13 | Train | Epoch[281/600] Iteration[007/030] Train loss: 0.0116
2023-02-06 14:26:13 | Train | Epoch[281/600] Iteration[008/030] Train loss: 0.0118
2023-02-06 14:26:13 | Train | Epoch[281/600] Iteration[009/030] Train loss: 0.0118
2023-02-06 14:26:14 | Train | Epoch[281/600] Iteration[010/030] Train loss: 0.0117
2023-02-06 14:26:14 | Train | Epoch[281/600] Iteration[011/030] Train loss: 0.0116
2023-02-06 14:26:14 | Train | Epoch[281/600] Iteration[012/030] Train loss: 0.0114
2023-02-06 14:26:14 | Train | Epoch[281/600] Iteration[013/030] Train loss: 0.0115
2023-02-06 14:26:14 | Train | Epoch[281/600] Iteration[014/030] Train loss: 0.0115
2023-02-06 14:26:15 | Train | Epoch[281/600] Iteration[015/030] Train loss: 0.0114
2023-02-06 14:26:15 | Train | Epoch[281/600] Iteration[016/030] Train loss: 0.0114
2023-02-06 14:26:15 | Train | Epoch[281/600] Iteration[017/030] Train loss: 0.0114
2023-02-06 14:26:15 | Train | Epoch[281/600] Iteration[018/030] Train loss: 0.0113
2023-02-06 14:26:16 | Train | Epoch[281/600] Iteration[019/030] Train loss: 0.0113
2023-02-06 14:26:16 | Train | Epoch[281/600] Iteration[020/030] Train loss: 0.0113
2023-02-06 14:26:16 | Train | Epoch[281/600] Iteration[021/030] Train loss: 0.0113
2023-02-06 14:26:16 | Train | Epoch[281/600] Iteration[022/030] Train loss: 0.0113
2023-02-06 14:26:16 | Train | Epoch[281/600] Iteration[023/030] Train loss: 0.0112
2023-02-06 14:26:17 | Train | Epoch[281/600] Iteration[024/030] Train loss: 0.0112
2023-02-06 14:26:17 | Train | Epoch[281/600] Iteration[025/030] Train loss: 0.0112
2023-02-06 14:26:17 | Train | Epoch[281/600] Iteration[026/030] Train loss: 0.0113
2023-02-06 14:26:17 | Train | Epoch[281/600] Iteration[027/030] Train loss: 0.0112
2023-02-06 14:26:17 | Train | Epoch[281/600] Iteration[028/030] Train loss: 0.0112
2023-02-06 14:26:18 | Train | Epoch[281/600] Iteration[029/030] Train loss: 0.0113
2023-02-06 14:26:18 | Train | Epoch[281/600] Iteration[030/030] Train loss: 0.0114
2023-02-06 14:26:18 | Valid | Epoch[281/600] Iteration[001/008] Valid loss: 0.1196
2023-02-06 14:26:18 | Valid | Epoch[281/600] Iteration[002/008] Valid loss: 0.0958
2023-02-06 14:26:18 | Valid | Epoch[281/600] Iteration[003/008] Valid loss: 0.0866
2023-02-06 14:26:18 | Valid | Epoch[281/600] Iteration[004/008] Valid loss: 0.0816
2023-02-06 14:26:18 | Valid | Epoch[281/600] Iteration[005/008] Valid loss: 0.0794
2023-02-06 14:26:18 | Valid | Epoch[281/600] Iteration[006/008] Valid loss: 0.0792
2023-02-06 14:26:18 | Valid | Epoch[281/600] Iteration[007/008] Valid loss: 0.0857
2023-02-06 14:26:19 | Valid | Epoch[281/600] Iteration[008/008] Valid loss: 0.0834
2023-02-06 14:26:19 | Valid | Epoch[281/600] MIou: 0.9174031719787554
2023-02-06 14:26:19 | Valid | Epoch[281/600] Pixel Accuracy: 0.9859301249186198
2023-02-06 14:26:19 | Valid | Epoch[281/600] Mean Pixel Accuracy: 0.9397674924695938
2023-02-06 14:26:19 | Stage | Epoch[281/600] Train loss:0.0114
2023-02-06 14:26:19 | Stage | Epoch[281/600] Valid loss:0.0834
2023-02-06 14:26:19 | Stage | Epoch[281/600] LR:0.01

2023-02-06 14:26:19 | Train | Epoch[282/600] Iteration[001/030] Train loss: 0.0120
2023-02-06 14:26:19 | Train | Epoch[282/600] Iteration[002/030] Train loss: 0.0115
2023-02-06 14:26:20 | Train | Epoch[282/600] Iteration[003/030] Train loss: 0.0117
2023-02-06 14:26:20 | Train | Epoch[282/600] Iteration[004/030] Train loss: 0.0115
2023-02-06 14:26:20 | Train | Epoch[282/600] Iteration[005/030] Train loss: 0.0118
2023-02-06 14:26:20 | Train | Epoch[282/600] Iteration[006/030] Train loss: 0.0115
2023-02-06 14:26:20 | Train | Epoch[282/600] Iteration[007/030] Train loss: 0.0114
2023-02-06 14:26:21 | Train | Epoch[282/600] Iteration[008/030] Train loss: 0.0114
2023-02-06 14:26:21 | Train | Epoch[282/600] Iteration[009/030] Train loss: 0.0113
2023-02-06 14:26:21 | Train | Epoch[282/600] Iteration[010/030] Train loss: 0.0112
2023-02-06 14:26:21 | Train | Epoch[282/600] Iteration[011/030] Train loss: 0.0111
2023-02-06 14:26:21 | Train | Epoch[282/600] Iteration[012/030] Train loss: 0.0110
2023-02-06 14:26:22 | Train | Epoch[282/600] Iteration[013/030] Train loss: 0.0109
2023-02-06 14:26:22 | Train | Epoch[282/600] Iteration[014/030] Train loss: 0.0111
2023-02-06 14:26:22 | Train | Epoch[282/600] Iteration[015/030] Train loss: 0.0110
2023-02-06 14:26:22 | Train | Epoch[282/600] Iteration[016/030] Train loss: 0.0110
2023-02-06 14:26:23 | Train | Epoch[282/600] Iteration[017/030] Train loss: 0.0111
2023-02-06 14:26:23 | Train | Epoch[282/600] Iteration[018/030] Train loss: 0.0110
2023-02-06 14:26:23 | Train | Epoch[282/600] Iteration[019/030] Train loss: 0.0110
2023-02-06 14:26:23 | Train | Epoch[282/600] Iteration[020/030] Train loss: 0.0110
2023-02-06 14:26:23 | Train | Epoch[282/600] Iteration[021/030] Train loss: 0.0110
2023-02-06 14:26:24 | Train | Epoch[282/600] Iteration[022/030] Train loss: 0.0110
2023-02-06 14:26:24 | Train | Epoch[282/600] Iteration[023/030] Train loss: 0.0111
2023-02-06 14:26:24 | Train | Epoch[282/600] Iteration[024/030] Train loss: 0.0111
2023-02-06 14:26:24 | Train | Epoch[282/600] Iteration[025/030] Train loss: 0.0112
2023-02-06 14:26:25 | Train | Epoch[282/600] Iteration[026/030] Train loss: 0.0112
2023-02-06 14:26:25 | Train | Epoch[282/600] Iteration[027/030] Train loss: 0.0112
2023-02-06 14:26:25 | Train | Epoch[282/600] Iteration[028/030] Train loss: 0.0112
2023-02-06 14:26:25 | Train | Epoch[282/600] Iteration[029/030] Train loss: 0.0112
2023-02-06 14:26:25 | Train | Epoch[282/600] Iteration[030/030] Train loss: 0.0112
2023-02-06 14:26:26 | Valid | Epoch[282/600] Iteration[001/008] Valid loss: 1.3082
2023-02-06 14:26:26 | Valid | Epoch[282/600] Iteration[002/008] Valid loss: 1.2371
2023-02-06 14:26:26 | Valid | Epoch[282/600] Iteration[003/008] Valid loss: 1.2933
2023-02-06 14:26:26 | Valid | Epoch[282/600] Iteration[004/008] Valid loss: 1.3004
2023-02-06 14:26:26 | Valid | Epoch[282/600] Iteration[005/008] Valid loss: 1.3510
2023-02-06 14:26:26 | Valid | Epoch[282/600] Iteration[006/008] Valid loss: 1.3260
2023-02-06 14:26:26 | Valid | Epoch[282/600] Iteration[007/008] Valid loss: 1.3791
2023-02-06 14:26:26 | Valid | Epoch[282/600] Iteration[008/008] Valid loss: 1.4325
2023-02-06 14:26:26 | Valid | Epoch[282/600] MIou: 0.8492681462530407
2023-02-06 14:26:26 | Valid | Epoch[282/600] Pixel Accuracy: 0.9674733479817709
2023-02-06 14:26:26 | Valid | Epoch[282/600] Mean Pixel Accuracy: 0.9799408426224689
2023-02-06 14:26:26 | Stage | Epoch[282/600] Train loss:0.0112
2023-02-06 14:26:26 | Stage | Epoch[282/600] Valid loss:1.4325
2023-02-06 14:26:26 | Stage | Epoch[282/600] LR:0.01

2023-02-06 14:26:27 | Train | Epoch[283/600] Iteration[001/030] Train loss: 0.0118
2023-02-06 14:26:27 | Train | Epoch[283/600] Iteration[002/030] Train loss: 0.0111
2023-02-06 14:26:27 | Train | Epoch[283/600] Iteration[003/030] Train loss: 0.0108
2023-02-06 14:26:27 | Train | Epoch[283/600] Iteration[004/030] Train loss: 0.0125
2023-02-06 14:26:27 | Train | Epoch[283/600] Iteration[005/030] Train loss: 0.0124
2023-02-06 14:26:28 | Train | Epoch[283/600] Iteration[006/030] Train loss: 0.0122
2023-02-06 14:26:28 | Train | Epoch[283/600] Iteration[007/030] Train loss: 0.0123
2023-02-06 14:26:28 | Train | Epoch[283/600] Iteration[008/030] Train loss: 0.0124
2023-02-06 14:26:28 | Train | Epoch[283/600] Iteration[009/030] Train loss: 0.0123
2023-02-06 14:26:28 | Train | Epoch[283/600] Iteration[010/030] Train loss: 0.0123
2023-02-06 14:26:29 | Train | Epoch[283/600] Iteration[011/030] Train loss: 0.0123
2023-02-06 14:26:29 | Train | Epoch[283/600] Iteration[012/030] Train loss: 0.0121
2023-02-06 14:26:29 | Train | Epoch[283/600] Iteration[013/030] Train loss: 0.0122
2023-02-06 14:26:29 | Train | Epoch[283/600] Iteration[014/030] Train loss: 0.0121
2023-02-06 14:26:30 | Train | Epoch[283/600] Iteration[015/030] Train loss: 0.0124
2023-02-06 14:26:30 | Train | Epoch[283/600] Iteration[016/030] Train loss: 0.0123
2023-02-06 14:26:30 | Train | Epoch[283/600] Iteration[017/030] Train loss: 0.0123
2023-02-06 14:26:30 | Train | Epoch[283/600] Iteration[018/030] Train loss: 0.0122
2023-02-06 14:26:30 | Train | Epoch[283/600] Iteration[019/030] Train loss: 0.0122
2023-02-06 14:26:31 | Train | Epoch[283/600] Iteration[020/030] Train loss: 0.0121
2023-02-06 14:26:31 | Train | Epoch[283/600] Iteration[021/030] Train loss: 0.0121
2023-02-06 14:26:31 | Train | Epoch[283/600] Iteration[022/030] Train loss: 0.0122
2023-02-06 14:26:31 | Train | Epoch[283/600] Iteration[023/030] Train loss: 0.0122
2023-02-06 14:26:32 | Train | Epoch[283/600] Iteration[024/030] Train loss: 0.0122
2023-02-06 14:26:32 | Train | Epoch[283/600] Iteration[025/030] Train loss: 0.0121
2023-02-06 14:26:32 | Train | Epoch[283/600] Iteration[026/030] Train loss: 0.0121
2023-02-06 14:26:32 | Train | Epoch[283/600] Iteration[027/030] Train loss: 0.0121
2023-02-06 14:26:32 | Train | Epoch[283/600] Iteration[028/030] Train loss: 0.0121
2023-02-06 14:26:33 | Train | Epoch[283/600] Iteration[029/030] Train loss: 0.0121
2023-02-06 14:26:33 | Train | Epoch[283/600] Iteration[030/030] Train loss: 0.0122
2023-02-06 14:26:33 | Valid | Epoch[283/600] Iteration[001/008] Valid loss: 0.2760
2023-02-06 14:26:33 | Valid | Epoch[283/600] Iteration[002/008] Valid loss: 0.2287
2023-02-06 14:26:33 | Valid | Epoch[283/600] Iteration[003/008] Valid loss: 0.2277
2023-02-06 14:26:33 | Valid | Epoch[283/600] Iteration[004/008] Valid loss: 0.2246
2023-02-06 14:26:33 | Valid | Epoch[283/600] Iteration[005/008] Valid loss: 0.2230
2023-02-06 14:26:33 | Valid | Epoch[283/600] Iteration[006/008] Valid loss: 0.2236
2023-02-06 14:26:33 | Valid | Epoch[283/600] Iteration[007/008] Valid loss: 0.2440
2023-02-06 14:26:33 | Valid | Epoch[283/600] Iteration[008/008] Valid loss: 0.2453
2023-02-06 14:26:34 | Valid | Epoch[283/600] MIou: 0.9201014620147969
2023-02-06 14:26:34 | Valid | Epoch[283/600] Pixel Accuracy: 0.9854583740234375
2023-02-06 14:26:34 | Valid | Epoch[283/600] Mean Pixel Accuracy: 0.9731063566004234
2023-02-06 14:26:34 | Stage | Epoch[283/600] Train loss:0.0122
2023-02-06 14:26:34 | Stage | Epoch[283/600] Valid loss:0.2453
2023-02-06 14:26:34 | Stage | Epoch[283/600] LR:0.01

2023-02-06 14:26:34 | Train | Epoch[284/600] Iteration[001/030] Train loss: 0.0113
2023-02-06 14:26:34 | Train | Epoch[284/600] Iteration[002/030] Train loss: 0.0110
2023-02-06 14:26:34 | Train | Epoch[284/600] Iteration[003/030] Train loss: 0.0116
2023-02-06 14:26:35 | Train | Epoch[284/600] Iteration[004/030] Train loss: 0.0118
2023-02-06 14:26:35 | Train | Epoch[284/600] Iteration[005/030] Train loss: 0.0122
2023-02-06 14:26:35 | Train | Epoch[284/600] Iteration[006/030] Train loss: 0.0127
2023-02-06 14:26:35 | Train | Epoch[284/600] Iteration[007/030] Train loss: 0.0128
2023-02-06 14:26:35 | Train | Epoch[284/600] Iteration[008/030] Train loss: 0.0129
2023-02-06 14:26:36 | Train | Epoch[284/600] Iteration[009/030] Train loss: 0.0128
2023-02-06 14:26:36 | Train | Epoch[284/600] Iteration[010/030] Train loss: 0.0127
2023-02-06 14:26:36 | Train | Epoch[284/600] Iteration[011/030] Train loss: 0.0127
2023-02-06 14:26:36 | Train | Epoch[284/600] Iteration[012/030] Train loss: 0.0126
2023-02-06 14:26:37 | Train | Epoch[284/600] Iteration[013/030] Train loss: 0.0126
2023-02-06 14:26:37 | Train | Epoch[284/600] Iteration[014/030] Train loss: 0.0126
2023-02-06 14:26:37 | Train | Epoch[284/600] Iteration[015/030] Train loss: 0.0124
2023-02-06 14:26:37 | Train | Epoch[284/600] Iteration[016/030] Train loss: 0.0126
2023-02-06 14:26:37 | Train | Epoch[284/600] Iteration[017/030] Train loss: 0.0126
2023-02-06 14:26:38 | Train | Epoch[284/600] Iteration[018/030] Train loss: 0.0126
2023-02-06 14:26:38 | Train | Epoch[284/600] Iteration[019/030] Train loss: 0.0125
2023-02-06 14:26:38 | Train | Epoch[284/600] Iteration[020/030] Train loss: 0.0125
2023-02-06 14:26:38 | Train | Epoch[284/600] Iteration[021/030] Train loss: 0.0125
2023-02-06 14:26:39 | Train | Epoch[284/600] Iteration[022/030] Train loss: 0.0125
2023-02-06 14:26:39 | Train | Epoch[284/600] Iteration[023/030] Train loss: 0.0124
2023-02-06 14:26:39 | Train | Epoch[284/600] Iteration[024/030] Train loss: 0.0125
2023-02-06 14:26:39 | Train | Epoch[284/600] Iteration[025/030] Train loss: 0.0125
2023-02-06 14:26:39 | Train | Epoch[284/600] Iteration[026/030] Train loss: 0.0125
2023-02-06 14:26:40 | Train | Epoch[284/600] Iteration[027/030] Train loss: 0.0124
2023-02-06 14:26:40 | Train | Epoch[284/600] Iteration[028/030] Train loss: 0.0124
2023-02-06 14:26:40 | Train | Epoch[284/600] Iteration[029/030] Train loss: 0.0125
2023-02-06 14:26:40 | Train | Epoch[284/600] Iteration[030/030] Train loss: 0.0125
2023-02-06 14:26:40 | Valid | Epoch[284/600] Iteration[001/008] Valid loss: 0.0920
2023-02-06 14:26:41 | Valid | Epoch[284/600] Iteration[002/008] Valid loss: 0.0759
2023-02-06 14:26:41 | Valid | Epoch[284/600] Iteration[003/008] Valid loss: 0.0729
2023-02-06 14:26:41 | Valid | Epoch[284/600] Iteration[004/008] Valid loss: 0.0694
2023-02-06 14:26:41 | Valid | Epoch[284/600] Iteration[005/008] Valid loss: 0.0669
2023-02-06 14:26:41 | Valid | Epoch[284/600] Iteration[006/008] Valid loss: 0.0646
2023-02-06 14:26:41 | Valid | Epoch[284/600] Iteration[007/008] Valid loss: 0.0635
2023-02-06 14:26:41 | Valid | Epoch[284/600] Iteration[008/008] Valid loss: 0.0635
2023-02-06 14:26:41 | Valid | Epoch[284/600] MIou: 0.8769386549253673
2023-02-06 14:26:41 | Valid | Epoch[284/600] Pixel Accuracy: 0.9795570373535156
2023-02-06 14:26:41 | Valid | Epoch[284/600] Mean Pixel Accuracy: 0.8912916073030197
2023-02-06 14:26:41 | Stage | Epoch[284/600] Train loss:0.0125
2023-02-06 14:26:41 | Stage | Epoch[284/600] Valid loss:0.0635
2023-02-06 14:26:41 | Stage | Epoch[284/600] LR:0.01

2023-02-06 14:26:41 | Train | Epoch[285/600] Iteration[001/030] Train loss: 0.0114
2023-02-06 14:26:42 | Train | Epoch[285/600] Iteration[002/030] Train loss: 0.0113
2023-02-06 14:26:42 | Train | Epoch[285/600] Iteration[003/030] Train loss: 0.0116
2023-02-06 14:26:42 | Train | Epoch[285/600] Iteration[004/030] Train loss: 0.0113
2023-02-06 14:26:42 | Train | Epoch[285/600] Iteration[005/030] Train loss: 0.0112
2023-02-06 14:26:42 | Train | Epoch[285/600] Iteration[006/030] Train loss: 0.0115
2023-02-06 14:26:43 | Train | Epoch[285/600] Iteration[007/030] Train loss: 0.0118
2023-02-06 14:26:43 | Train | Epoch[285/600] Iteration[008/030] Train loss: 0.0118
2023-02-06 14:26:43 | Train | Epoch[285/600] Iteration[009/030] Train loss: 0.0117
2023-02-06 14:26:43 | Train | Epoch[285/600] Iteration[010/030] Train loss: 0.0120
2023-02-06 14:26:44 | Train | Epoch[285/600] Iteration[011/030] Train loss: 0.0120
2023-02-06 14:26:44 | Train | Epoch[285/600] Iteration[012/030] Train loss: 0.0121
2023-02-06 14:26:44 | Train | Epoch[285/600] Iteration[013/030] Train loss: 0.0121
2023-02-06 14:26:44 | Train | Epoch[285/600] Iteration[014/030] Train loss: 0.0120
2023-02-06 14:26:44 | Train | Epoch[285/600] Iteration[015/030] Train loss: 0.0120
2023-02-06 14:26:45 | Train | Epoch[285/600] Iteration[016/030] Train loss: 0.0120
2023-02-06 14:26:45 | Train | Epoch[285/600] Iteration[017/030] Train loss: 0.0120
2023-02-06 14:26:45 | Train | Epoch[285/600] Iteration[018/030] Train loss: 0.0119
2023-02-06 14:26:45 | Train | Epoch[285/600] Iteration[019/030] Train loss: 0.0120
2023-02-06 14:26:45 | Train | Epoch[285/600] Iteration[020/030] Train loss: 0.0120
2023-02-06 14:26:46 | Train | Epoch[285/600] Iteration[021/030] Train loss: 0.0120
2023-02-06 14:26:46 | Train | Epoch[285/600] Iteration[022/030] Train loss: 0.0119
2023-02-06 14:26:46 | Train | Epoch[285/600] Iteration[023/030] Train loss: 0.0120
2023-02-06 14:26:46 | Train | Epoch[285/600] Iteration[024/030] Train loss: 0.0120
2023-02-06 14:26:47 | Train | Epoch[285/600] Iteration[025/030] Train loss: 0.0120
2023-02-06 14:26:47 | Train | Epoch[285/600] Iteration[026/030] Train loss: 0.0120
2023-02-06 14:26:47 | Train | Epoch[285/600] Iteration[027/030] Train loss: 0.0119
2023-02-06 14:26:47 | Train | Epoch[285/600] Iteration[028/030] Train loss: 0.0119
2023-02-06 14:26:47 | Train | Epoch[285/600] Iteration[029/030] Train loss: 0.0119
2023-02-06 14:26:48 | Train | Epoch[285/600] Iteration[030/030] Train loss: 0.0119
2023-02-06 14:26:48 | Valid | Epoch[285/600] Iteration[001/008] Valid loss: 0.4282
2023-02-06 14:26:48 | Valid | Epoch[285/600] Iteration[002/008] Valid loss: 0.3628
2023-02-06 14:26:48 | Valid | Epoch[285/600] Iteration[003/008] Valid loss: 0.3711
2023-02-06 14:26:48 | Valid | Epoch[285/600] Iteration[004/008] Valid loss: 0.3578
2023-02-06 14:26:48 | Valid | Epoch[285/600] Iteration[005/008] Valid loss: 0.3702
2023-02-06 14:26:48 | Valid | Epoch[285/600] Iteration[006/008] Valid loss: 0.3654
2023-02-06 14:26:48 | Valid | Epoch[285/600] Iteration[007/008] Valid loss: 0.3973
2023-02-06 14:26:48 | Valid | Epoch[285/600] Iteration[008/008] Valid loss: 0.4143
2023-02-06 14:26:48 | Valid | Epoch[285/600] MIou: 0.907527947725621
2023-02-06 14:26:48 | Valid | Epoch[285/600] Pixel Accuracy: 0.9825642903645834
2023-02-06 14:26:48 | Valid | Epoch[285/600] Mean Pixel Accuracy: 0.9773869214120203
2023-02-06 14:26:48 | Stage | Epoch[285/600] Train loss:0.0119
2023-02-06 14:26:48 | Stage | Epoch[285/600] Valid loss:0.4143
2023-02-06 14:26:48 | Stage | Epoch[285/600] LR:0.01

2023-02-06 14:26:49 | Train | Epoch[286/600] Iteration[001/030] Train loss: 0.0111
2023-02-06 14:26:49 | Train | Epoch[286/600] Iteration[002/030] Train loss: 0.0112
2023-02-06 14:26:49 | Train | Epoch[286/600] Iteration[003/030] Train loss: 0.0117
2023-02-06 14:26:49 | Train | Epoch[286/600] Iteration[004/030] Train loss: 0.0114
2023-02-06 14:26:50 | Train | Epoch[286/600] Iteration[005/030] Train loss: 0.0110
2023-02-06 14:26:50 | Train | Epoch[286/600] Iteration[006/030] Train loss: 0.0113
2023-02-06 14:26:50 | Train | Epoch[286/600] Iteration[007/030] Train loss: 0.0113
2023-02-06 14:26:50 | Train | Epoch[286/600] Iteration[008/030] Train loss: 0.0112
2023-02-06 14:26:50 | Train | Epoch[286/600] Iteration[009/030] Train loss: 0.0112
2023-02-06 14:26:51 | Train | Epoch[286/600] Iteration[010/030] Train loss: 0.0113
2023-02-06 14:26:51 | Train | Epoch[286/600] Iteration[011/030] Train loss: 0.0112
2023-02-06 14:26:51 | Train | Epoch[286/600] Iteration[012/030] Train loss: 0.0114
2023-02-06 14:26:51 | Train | Epoch[286/600] Iteration[013/030] Train loss: 0.0113
2023-02-06 14:26:52 | Train | Epoch[286/600] Iteration[014/030] Train loss: 0.0113
2023-02-06 14:26:52 | Train | Epoch[286/600] Iteration[015/030] Train loss: 0.0113
2023-02-06 14:26:52 | Train | Epoch[286/600] Iteration[016/030] Train loss: 0.0112
2023-02-06 14:26:52 | Train | Epoch[286/600] Iteration[017/030] Train loss: 0.0112
2023-02-06 14:26:52 | Train | Epoch[286/600] Iteration[018/030] Train loss: 0.0112
2023-02-06 14:26:53 | Train | Epoch[286/600] Iteration[019/030] Train loss: 0.0113
2023-02-06 14:26:53 | Train | Epoch[286/600] Iteration[020/030] Train loss: 0.0113
2023-02-06 14:26:53 | Train | Epoch[286/600] Iteration[021/030] Train loss: 0.0113
2023-02-06 14:26:53 | Train | Epoch[286/600] Iteration[022/030] Train loss: 0.0113
2023-02-06 14:26:54 | Train | Epoch[286/600] Iteration[023/030] Train loss: 0.0113
2023-02-06 14:26:54 | Train | Epoch[286/600] Iteration[024/030] Train loss: 0.0113
2023-02-06 14:26:54 | Train | Epoch[286/600] Iteration[025/030] Train loss: 0.0113
2023-02-06 14:26:54 | Train | Epoch[286/600] Iteration[026/030] Train loss: 0.0113
2023-02-06 14:26:54 | Train | Epoch[286/600] Iteration[027/030] Train loss: 0.0113
2023-02-06 14:26:55 | Train | Epoch[286/600] Iteration[028/030] Train loss: 0.0115
2023-02-06 14:26:55 | Train | Epoch[286/600] Iteration[029/030] Train loss: 0.0116
2023-02-06 14:26:55 | Train | Epoch[286/600] Iteration[030/030] Train loss: 0.0116
2023-02-06 14:26:55 | Valid | Epoch[286/600] Iteration[001/008] Valid loss: 0.0979
2023-02-06 14:26:55 | Valid | Epoch[286/600] Iteration[002/008] Valid loss: 0.0755
2023-02-06 14:26:55 | Valid | Epoch[286/600] Iteration[003/008] Valid loss: 0.0732
2023-02-06 14:26:55 | Valid | Epoch[286/600] Iteration[004/008] Valid loss: 0.0713
2023-02-06 14:26:55 | Valid | Epoch[286/600] Iteration[005/008] Valid loss: 0.0713
2023-02-06 14:26:56 | Valid | Epoch[286/600] Iteration[006/008] Valid loss: 0.0699
2023-02-06 14:26:56 | Valid | Epoch[286/600] Iteration[007/008] Valid loss: 0.0698
2023-02-06 14:26:56 | Valid | Epoch[286/600] Iteration[008/008] Valid loss: 0.0685
2023-02-06 14:26:56 | Valid | Epoch[286/600] MIou: 0.8897867285355446
2023-02-06 14:26:56 | Valid | Epoch[286/600] Pixel Accuracy: 0.9813499450683594
2023-02-06 14:26:56 | Valid | Epoch[286/600] Mean Pixel Accuracy: 0.9107341784204268
2023-02-06 14:26:56 | Stage | Epoch[286/600] Train loss:0.0116
2023-02-06 14:26:56 | Stage | Epoch[286/600] Valid loss:0.0685
2023-02-06 14:26:56 | Stage | Epoch[286/600] LR:0.01

2023-02-06 14:26:56 | Train | Epoch[287/600] Iteration[001/030] Train loss: 0.0123
2023-02-06 14:26:56 | Train | Epoch[287/600] Iteration[002/030] Train loss: 0.0114
2023-02-06 14:26:57 | Train | Epoch[287/600] Iteration[003/030] Train loss: 0.0113
2023-02-06 14:26:57 | Train | Epoch[287/600] Iteration[004/030] Train loss: 0.0108
2023-02-06 14:26:57 | Train | Epoch[287/600] Iteration[005/030] Train loss: 0.0108
2023-02-06 14:26:57 | Train | Epoch[287/600] Iteration[006/030] Train loss: 0.0108
2023-02-06 14:26:57 | Train | Epoch[287/600] Iteration[007/030] Train loss: 0.0108
2023-02-06 14:26:58 | Train | Epoch[287/600] Iteration[008/030] Train loss: 0.0107
2023-02-06 14:26:58 | Train | Epoch[287/600] Iteration[009/030] Train loss: 0.0106
2023-02-06 14:26:58 | Train | Epoch[287/600] Iteration[010/030] Train loss: 0.0105
2023-02-06 14:26:58 | Train | Epoch[287/600] Iteration[011/030] Train loss: 0.0106
2023-02-06 14:26:59 | Train | Epoch[287/600] Iteration[012/030] Train loss: 0.0106
2023-02-06 14:26:59 | Train | Epoch[287/600] Iteration[013/030] Train loss: 0.0106
2023-02-06 14:26:59 | Train | Epoch[287/600] Iteration[014/030] Train loss: 0.0107
2023-02-06 14:26:59 | Train | Epoch[287/600] Iteration[015/030] Train loss: 0.0109
2023-02-06 14:26:59 | Train | Epoch[287/600] Iteration[016/030] Train loss: 0.0108
2023-02-06 14:27:00 | Train | Epoch[287/600] Iteration[017/030] Train loss: 0.0109
2023-02-06 14:27:00 | Train | Epoch[287/600] Iteration[018/030] Train loss: 0.0109
2023-02-06 14:27:00 | Train | Epoch[287/600] Iteration[019/030] Train loss: 0.0109
2023-02-06 14:27:00 | Train | Epoch[287/600] Iteration[020/030] Train loss: 0.0110
2023-02-06 14:27:01 | Train | Epoch[287/600] Iteration[021/030] Train loss: 0.0109
2023-02-06 14:27:01 | Train | Epoch[287/600] Iteration[022/030] Train loss: 0.0110
2023-02-06 14:27:01 | Train | Epoch[287/600] Iteration[023/030] Train loss: 0.0110
2023-02-06 14:27:01 | Train | Epoch[287/600] Iteration[024/030] Train loss: 0.0111
2023-02-06 14:27:01 | Train | Epoch[287/600] Iteration[025/030] Train loss: 0.0110
2023-02-06 14:27:02 | Train | Epoch[287/600] Iteration[026/030] Train loss: 0.0111
2023-02-06 14:27:02 | Train | Epoch[287/600] Iteration[027/030] Train loss: 0.0111
2023-02-06 14:27:02 | Train | Epoch[287/600] Iteration[028/030] Train loss: 0.0111
2023-02-06 14:27:02 | Train | Epoch[287/600] Iteration[029/030] Train loss: 0.0112
2023-02-06 14:27:02 | Train | Epoch[287/600] Iteration[030/030] Train loss: 0.0112
2023-02-06 14:27:03 | Valid | Epoch[287/600] Iteration[001/008] Valid loss: 0.1154
2023-02-06 14:27:03 | Valid | Epoch[287/600] Iteration[002/008] Valid loss: 0.0952
2023-02-06 14:27:03 | Valid | Epoch[287/600] Iteration[003/008] Valid loss: 0.0935
2023-02-06 14:27:03 | Valid | Epoch[287/600] Iteration[004/008] Valid loss: 0.0849
2023-02-06 14:27:03 | Valid | Epoch[287/600] Iteration[005/008] Valid loss: 0.0821
2023-02-06 14:27:03 | Valid | Epoch[287/600] Iteration[006/008] Valid loss: 0.0816
2023-02-06 14:27:03 | Valid | Epoch[287/600] Iteration[007/008] Valid loss: 0.0852
2023-02-06 14:27:03 | Valid | Epoch[287/600] Iteration[008/008] Valid loss: 0.0828
2023-02-06 14:27:03 | Valid | Epoch[287/600] MIou: 0.9177294249763353
2023-02-06 14:27:03 | Valid | Epoch[287/600] Pixel Accuracy: 0.9858258565266927
2023-02-06 14:27:03 | Valid | Epoch[287/600] Mean Pixel Accuracy: 0.9451376257287916
2023-02-06 14:27:03 | Stage | Epoch[287/600] Train loss:0.0112
2023-02-06 14:27:03 | Stage | Epoch[287/600] Valid loss:0.0828
2023-02-06 14:27:03 | Stage | Epoch[287/600] LR:0.01

2023-02-06 14:27:04 | Train | Epoch[288/600] Iteration[001/030] Train loss: 0.0106
2023-02-06 14:27:04 | Train | Epoch[288/600] Iteration[002/030] Train loss: 0.0102
2023-02-06 14:27:04 | Train | Epoch[288/600] Iteration[003/030] Train loss: 0.0099
2023-02-06 14:27:04 | Train | Epoch[288/600] Iteration[004/030] Train loss: 0.0100
2023-02-06 14:27:05 | Train | Epoch[288/600] Iteration[005/030] Train loss: 0.0102
2023-02-06 14:27:05 | Train | Epoch[288/600] Iteration[006/030] Train loss: 0.0106
2023-02-06 14:27:05 | Train | Epoch[288/600] Iteration[007/030] Train loss: 0.0105
2023-02-06 14:27:05 | Train | Epoch[288/600] Iteration[008/030] Train loss: 0.0104
2023-02-06 14:27:05 | Train | Epoch[288/600] Iteration[009/030] Train loss: 0.0104
2023-02-06 14:27:06 | Train | Epoch[288/600] Iteration[010/030] Train loss: 0.0104
2023-02-06 14:27:06 | Train | Epoch[288/600] Iteration[011/030] Train loss: 0.0105
2023-02-06 14:27:06 | Train | Epoch[288/600] Iteration[012/030] Train loss: 0.0105
2023-02-06 14:27:06 | Train | Epoch[288/600] Iteration[013/030] Train loss: 0.0105
2023-02-06 14:27:07 | Train | Epoch[288/600] Iteration[014/030] Train loss: 0.0105
2023-02-06 14:27:07 | Train | Epoch[288/600] Iteration[015/030] Train loss: 0.0105
2023-02-06 14:27:07 | Train | Epoch[288/600] Iteration[016/030] Train loss: 0.0107
2023-02-06 14:27:07 | Train | Epoch[288/600] Iteration[017/030] Train loss: 0.0108
2023-02-06 14:27:07 | Train | Epoch[288/600] Iteration[018/030] Train loss: 0.0107
2023-02-06 14:27:08 | Train | Epoch[288/600] Iteration[019/030] Train loss: 0.0107
2023-02-06 14:27:08 | Train | Epoch[288/600] Iteration[020/030] Train loss: 0.0107
2023-02-06 14:27:08 | Train | Epoch[288/600] Iteration[021/030] Train loss: 0.0107
2023-02-06 14:27:08 | Train | Epoch[288/600] Iteration[022/030] Train loss: 0.0107
2023-02-06 14:27:09 | Train | Epoch[288/600] Iteration[023/030] Train loss: 0.0107
2023-02-06 14:27:09 | Train | Epoch[288/600] Iteration[024/030] Train loss: 0.0107
2023-02-06 14:27:09 | Train | Epoch[288/600] Iteration[025/030] Train loss: 0.0107
2023-02-06 14:27:09 | Train | Epoch[288/600] Iteration[026/030] Train loss: 0.0107
2023-02-06 14:27:09 | Train | Epoch[288/600] Iteration[027/030] Train loss: 0.0108
2023-02-06 14:27:10 | Train | Epoch[288/600] Iteration[028/030] Train loss: 0.0108
2023-02-06 14:27:10 | Train | Epoch[288/600] Iteration[029/030] Train loss: 0.0109
2023-02-06 14:27:10 | Train | Epoch[288/600] Iteration[030/030] Train loss: 0.0109
2023-02-06 14:27:10 | Valid | Epoch[288/600] Iteration[001/008] Valid loss: 0.1334
2023-02-06 14:27:10 | Valid | Epoch[288/600] Iteration[002/008] Valid loss: 0.1040
2023-02-06 14:27:10 | Valid | Epoch[288/600] Iteration[003/008] Valid loss: 0.0997
2023-02-06 14:27:10 | Valid | Epoch[288/600] Iteration[004/008] Valid loss: 0.0924
2023-02-06 14:27:10 | Valid | Epoch[288/600] Iteration[005/008] Valid loss: 0.0935
2023-02-06 14:27:11 | Valid | Epoch[288/600] Iteration[006/008] Valid loss: 0.0948
2023-02-06 14:27:11 | Valid | Epoch[288/600] Iteration[007/008] Valid loss: 0.1033
2023-02-06 14:27:11 | Valid | Epoch[288/600] Iteration[008/008] Valid loss: 0.0994
2023-02-06 14:27:11 | Valid | Epoch[288/600] MIou: 0.9266370959893298
2023-02-06 14:27:11 | Valid | Epoch[288/600] Pixel Accuracy: 0.9872894287109375
2023-02-06 14:27:11 | Valid | Epoch[288/600] Mean Pixel Accuracy: 0.9562960574003228
2023-02-06 14:27:11 | Stage | Epoch[288/600] Train loss:0.0109
2023-02-06 14:27:11 | Stage | Epoch[288/600] Valid loss:0.0994
2023-02-06 14:27:11 | Stage | Epoch[288/600] LR:0.01

2023-02-06 14:27:11 | Train | Epoch[289/600] Iteration[001/030] Train loss: 0.0110
2023-02-06 14:27:11 | Train | Epoch[289/600] Iteration[002/030] Train loss: 0.0103
2023-02-06 14:27:12 | Train | Epoch[289/600] Iteration[003/030] Train loss: 0.0101
2023-02-06 14:27:12 | Train | Epoch[289/600] Iteration[004/030] Train loss: 0.0105
2023-02-06 14:27:12 | Train | Epoch[289/600] Iteration[005/030] Train loss: 0.0104
2023-02-06 14:27:12 | Train | Epoch[289/600] Iteration[006/030] Train loss: 0.0108
2023-02-06 14:27:13 | Train | Epoch[289/600] Iteration[007/030] Train loss: 0.0108
2023-02-06 14:27:13 | Train | Epoch[289/600] Iteration[008/030] Train loss: 0.0107
2023-02-06 14:27:13 | Train | Epoch[289/600] Iteration[009/030] Train loss: 0.0107
2023-02-06 14:27:13 | Train | Epoch[289/600] Iteration[010/030] Train loss: 0.0106
2023-02-06 14:27:13 | Train | Epoch[289/600] Iteration[011/030] Train loss: 0.0106
2023-02-06 14:27:14 | Train | Epoch[289/600] Iteration[012/030] Train loss: 0.0107
2023-02-06 14:27:14 | Train | Epoch[289/600] Iteration[013/030] Train loss: 0.0107
2023-02-06 14:27:14 | Train | Epoch[289/600] Iteration[014/030] Train loss: 0.0108
2023-02-06 14:27:14 | Train | Epoch[289/600] Iteration[015/030] Train loss: 0.0108
2023-02-06 14:27:14 | Train | Epoch[289/600] Iteration[016/030] Train loss: 0.0110
2023-02-06 14:27:15 | Train | Epoch[289/600] Iteration[017/030] Train loss: 0.0110
2023-02-06 14:27:15 | Train | Epoch[289/600] Iteration[018/030] Train loss: 0.0112
2023-02-06 14:27:15 | Train | Epoch[289/600] Iteration[019/030] Train loss: 0.0112
2023-02-06 14:27:15 | Train | Epoch[289/600] Iteration[020/030] Train loss: 0.0111
2023-02-06 14:27:16 | Train | Epoch[289/600] Iteration[021/030] Train loss: 0.0110
2023-02-06 14:27:16 | Train | Epoch[289/600] Iteration[022/030] Train loss: 0.0110
2023-02-06 14:27:16 | Train | Epoch[289/600] Iteration[023/030] Train loss: 0.0111
2023-02-06 14:27:16 | Train | Epoch[289/600] Iteration[024/030] Train loss: 0.0110
2023-02-06 14:27:16 | Train | Epoch[289/600] Iteration[025/030] Train loss: 0.0111
2023-02-06 14:27:17 | Train | Epoch[289/600] Iteration[026/030] Train loss: 0.0111
2023-02-06 14:27:17 | Train | Epoch[289/600] Iteration[027/030] Train loss: 0.0110
2023-02-06 14:27:17 | Train | Epoch[289/600] Iteration[028/030] Train loss: 0.0110
2023-02-06 14:27:17 | Train | Epoch[289/600] Iteration[029/030] Train loss: 0.0111
2023-02-06 14:27:17 | Train | Epoch[289/600] Iteration[030/030] Train loss: 0.0110
2023-02-06 14:27:18 | Valid | Epoch[289/600] Iteration[001/008] Valid loss: 0.1093
2023-02-06 14:27:18 | Valid | Epoch[289/600] Iteration[002/008] Valid loss: 0.0819
2023-02-06 14:27:18 | Valid | Epoch[289/600] Iteration[003/008] Valid loss: 0.0753
2023-02-06 14:27:18 | Valid | Epoch[289/600] Iteration[004/008] Valid loss: 0.0713
2023-02-06 14:27:18 | Valid | Epoch[289/600] Iteration[005/008] Valid loss: 0.0686
2023-02-06 14:27:18 | Valid | Epoch[289/600] Iteration[006/008] Valid loss: 0.0671
2023-02-06 14:27:18 | Valid | Epoch[289/600] Iteration[007/008] Valid loss: 0.0686
2023-02-06 14:27:18 | Valid | Epoch[289/600] Iteration[008/008] Valid loss: 0.0666
2023-02-06 14:27:18 | Valid | Epoch[289/600] MIou: 0.9177950165935402
2023-02-06 14:27:18 | Valid | Epoch[289/600] Pixel Accuracy: 0.9860420227050781
2023-02-06 14:27:18 | Valid | Epoch[289/600] Mean Pixel Accuracy: 0.9387130732792304
2023-02-06 14:27:18 | Stage | Epoch[289/600] Train loss:0.0110
2023-02-06 14:27:18 | Stage | Epoch[289/600] Valid loss:0.0666
2023-02-06 14:27:18 | Stage | Epoch[289/600] LR:0.01

2023-02-06 14:27:19 | Train | Epoch[290/600] Iteration[001/030] Train loss: 0.0097
2023-02-06 14:27:19 | Train | Epoch[290/600] Iteration[002/030] Train loss: 0.0099
2023-02-06 14:27:19 | Train | Epoch[290/600] Iteration[003/030] Train loss: 0.0098
2023-02-06 14:27:19 | Train | Epoch[290/600] Iteration[004/030] Train loss: 0.0099
2023-02-06 14:27:20 | Train | Epoch[290/600] Iteration[005/030] Train loss: 0.0102
2023-02-06 14:27:20 | Train | Epoch[290/600] Iteration[006/030] Train loss: 0.0101
2023-02-06 14:27:20 | Train | Epoch[290/600] Iteration[007/030] Train loss: 0.0103
2023-02-06 14:27:20 | Train | Epoch[290/600] Iteration[008/030] Train loss: 0.0106
2023-02-06 14:27:20 | Train | Epoch[290/600] Iteration[009/030] Train loss: 0.0105
2023-02-06 14:27:21 | Train | Epoch[290/600] Iteration[010/030] Train loss: 0.0104
2023-02-06 14:27:21 | Train | Epoch[290/600] Iteration[011/030] Train loss: 0.0106
2023-02-06 14:27:21 | Train | Epoch[290/600] Iteration[012/030] Train loss: 0.0106
2023-02-06 14:27:21 | Train | Epoch[290/600] Iteration[013/030] Train loss: 0.0106
2023-02-06 14:27:22 | Train | Epoch[290/600] Iteration[014/030] Train loss: 0.0107
2023-02-06 14:27:22 | Train | Epoch[290/600] Iteration[015/030] Train loss: 0.0108
2023-02-06 14:27:22 | Train | Epoch[290/600] Iteration[016/030] Train loss: 0.0108
2023-02-06 14:27:22 | Train | Epoch[290/600] Iteration[017/030] Train loss: 0.0108
2023-02-06 14:27:22 | Train | Epoch[290/600] Iteration[018/030] Train loss: 0.0109
2023-02-06 14:27:23 | Train | Epoch[290/600] Iteration[019/030] Train loss: 0.0109
2023-02-06 14:27:23 | Train | Epoch[290/600] Iteration[020/030] Train loss: 0.0110
2023-02-06 14:27:23 | Train | Epoch[290/600] Iteration[021/030] Train loss: 0.0110
2023-02-06 14:27:23 | Train | Epoch[290/600] Iteration[022/030] Train loss: 0.0109
2023-02-06 14:27:24 | Train | Epoch[290/600] Iteration[023/030] Train loss: 0.0109
2023-02-06 14:27:24 | Train | Epoch[290/600] Iteration[024/030] Train loss: 0.0109
2023-02-06 14:27:24 | Train | Epoch[290/600] Iteration[025/030] Train loss: 0.0109
2023-02-06 14:27:24 | Train | Epoch[290/600] Iteration[026/030] Train loss: 0.0110
2023-02-06 14:27:24 | Train | Epoch[290/600] Iteration[027/030] Train loss: 0.0110
2023-02-06 14:27:25 | Train | Epoch[290/600] Iteration[028/030] Train loss: 0.0110
2023-02-06 14:27:25 | Train | Epoch[290/600] Iteration[029/030] Train loss: 0.0110
2023-02-06 14:27:25 | Train | Epoch[290/600] Iteration[030/030] Train loss: 0.0113
2023-02-06 14:27:25 | Valid | Epoch[290/600] Iteration[001/008] Valid loss: 0.1450
2023-02-06 14:27:25 | Valid | Epoch[290/600] Iteration[002/008] Valid loss: 0.1062
2023-02-06 14:27:25 | Valid | Epoch[290/600] Iteration[003/008] Valid loss: 0.1003
2023-02-06 14:27:25 | Valid | Epoch[290/600] Iteration[004/008] Valid loss: 0.0980
2023-02-06 14:27:25 | Valid | Epoch[290/600] Iteration[005/008] Valid loss: 0.0986
2023-02-06 14:27:26 | Valid | Epoch[290/600] Iteration[006/008] Valid loss: 0.0949
2023-02-06 14:27:26 | Valid | Epoch[290/600] Iteration[007/008] Valid loss: 0.0968
2023-02-06 14:27:26 | Valid | Epoch[290/600] Iteration[008/008] Valid loss: 0.0954
2023-02-06 14:27:26 | Valid | Epoch[290/600] MIou: 0.9220619447493117
2023-02-06 14:27:26 | Valid | Epoch[290/600] Pixel Accuracy: 0.9864832560221354
2023-02-06 14:27:26 | Valid | Epoch[290/600] Mean Pixel Accuracy: 0.9523213078758951
2023-02-06 14:27:26 | Stage | Epoch[290/600] Train loss:0.0113
2023-02-06 14:27:26 | Stage | Epoch[290/600] Valid loss:0.0954
2023-02-06 14:27:26 | Stage | Epoch[290/600] LR:0.01

2023-02-06 14:27:26 | Train | Epoch[291/600] Iteration[001/030] Train loss: 0.0097
2023-02-06 14:27:26 | Train | Epoch[291/600] Iteration[002/030] Train loss: 0.0105
2023-02-06 14:27:27 | Train | Epoch[291/600] Iteration[003/030] Train loss: 0.0118
2023-02-06 14:27:27 | Train | Epoch[291/600] Iteration[004/030] Train loss: 0.0123
2023-02-06 14:27:27 | Train | Epoch[291/600] Iteration[005/030] Train loss: 0.0123
2023-02-06 14:27:27 | Train | Epoch[291/600] Iteration[006/030] Train loss: 0.0121
2023-02-06 14:27:27 | Train | Epoch[291/600] Iteration[007/030] Train loss: 0.0121
2023-02-06 14:27:28 | Train | Epoch[291/600] Iteration[008/030] Train loss: 0.0121
2023-02-06 14:27:28 | Train | Epoch[291/600] Iteration[009/030] Train loss: 0.0119
2023-02-06 14:27:28 | Train | Epoch[291/600] Iteration[010/030] Train loss: 0.0118
2023-02-06 14:27:28 | Train | Epoch[291/600] Iteration[011/030] Train loss: 0.0118
2023-02-06 14:27:29 | Train | Epoch[291/600] Iteration[012/030] Train loss: 0.0117
2023-02-06 14:27:29 | Train | Epoch[291/600] Iteration[013/030] Train loss: 0.0117
2023-02-06 14:27:29 | Train | Epoch[291/600] Iteration[014/030] Train loss: 0.0117
2023-02-06 14:27:29 | Train | Epoch[291/600] Iteration[015/030] Train loss: 0.0116
2023-02-06 14:27:29 | Train | Epoch[291/600] Iteration[016/030] Train loss: 0.0116
2023-02-06 14:27:30 | Train | Epoch[291/600] Iteration[017/030] Train loss: 0.0118
2023-02-06 14:27:30 | Train | Epoch[291/600] Iteration[018/030] Train loss: 0.0118
2023-02-06 14:27:30 | Train | Epoch[291/600] Iteration[019/030] Train loss: 0.0118
2023-02-06 14:27:30 | Train | Epoch[291/600] Iteration[020/030] Train loss: 0.0119
2023-02-06 14:27:31 | Train | Epoch[291/600] Iteration[021/030] Train loss: 0.0120
2023-02-06 14:27:31 | Train | Epoch[291/600] Iteration[022/030] Train loss: 0.0118
2023-02-06 14:27:31 | Train | Epoch[291/600] Iteration[023/030] Train loss: 0.0119
2023-02-06 14:27:31 | Train | Epoch[291/600] Iteration[024/030] Train loss: 0.0118
2023-02-06 14:27:31 | Train | Epoch[291/600] Iteration[025/030] Train loss: 0.0118
2023-02-06 14:27:32 | Train | Epoch[291/600] Iteration[026/030] Train loss: 0.0118
2023-02-06 14:27:32 | Train | Epoch[291/600] Iteration[027/030] Train loss: 0.0117
2023-02-06 14:27:32 | Train | Epoch[291/600] Iteration[028/030] Train loss: 0.0117
2023-02-06 14:27:32 | Train | Epoch[291/600] Iteration[029/030] Train loss: 0.0117
2023-02-06 14:27:32 | Train | Epoch[291/600] Iteration[030/030] Train loss: 0.0117
2023-02-06 14:27:33 | Valid | Epoch[291/600] Iteration[001/008] Valid loss: 0.1939
2023-02-06 14:27:33 | Valid | Epoch[291/600] Iteration[002/008] Valid loss: 0.1541
2023-02-06 14:27:33 | Valid | Epoch[291/600] Iteration[003/008] Valid loss: 0.1605
2023-02-06 14:27:33 | Valid | Epoch[291/600] Iteration[004/008] Valid loss: 0.1533
2023-02-06 14:27:33 | Valid | Epoch[291/600] Iteration[005/008] Valid loss: 0.1591
2023-02-06 14:27:33 | Valid | Epoch[291/600] Iteration[006/008] Valid loss: 0.1638
2023-02-06 14:27:33 | Valid | Epoch[291/600] Iteration[007/008] Valid loss: 0.1763
2023-02-06 14:27:33 | Valid | Epoch[291/600] Iteration[008/008] Valid loss: 0.1704
2023-02-06 14:27:33 | Valid | Epoch[291/600] MIou: 0.9198144897293086
2023-02-06 14:27:33 | Valid | Epoch[291/600] Pixel Accuracy: 0.985833485921224
2023-02-06 14:27:33 | Valid | Epoch[291/600] Mean Pixel Accuracy: 0.9586787258477021
2023-02-06 14:27:33 | Stage | Epoch[291/600] Train loss:0.0117
2023-02-06 14:27:33 | Stage | Epoch[291/600] Valid loss:0.1704
2023-02-06 14:27:33 | Stage | Epoch[291/600] LR:0.01

2023-02-06 14:27:34 | Train | Epoch[292/600] Iteration[001/030] Train loss: 0.0100
2023-02-06 14:27:34 | Train | Epoch[292/600] Iteration[002/030] Train loss: 0.0110
2023-02-06 14:27:34 | Train | Epoch[292/600] Iteration[003/030] Train loss: 0.0109
2023-02-06 14:27:34 | Train | Epoch[292/600] Iteration[004/030] Train loss: 0.0106
2023-02-06 14:27:35 | Train | Epoch[292/600] Iteration[005/030] Train loss: 0.0110
2023-02-06 14:27:35 | Train | Epoch[292/600] Iteration[006/030] Train loss: 0.0109
2023-02-06 14:27:35 | Train | Epoch[292/600] Iteration[007/030] Train loss: 0.0110
2023-02-06 14:27:35 | Train | Epoch[292/600] Iteration[008/030] Train loss: 0.0110
2023-02-06 14:27:35 | Train | Epoch[292/600] Iteration[009/030] Train loss: 0.0108
2023-02-06 14:27:36 | Train | Epoch[292/600] Iteration[010/030] Train loss: 0.0109
2023-02-06 14:27:36 | Train | Epoch[292/600] Iteration[011/030] Train loss: 0.0111
2023-02-06 14:27:36 | Train | Epoch[292/600] Iteration[012/030] Train loss: 0.0111
2023-02-06 14:27:36 | Train | Epoch[292/600] Iteration[013/030] Train loss: 0.0111
2023-02-06 14:27:37 | Train | Epoch[292/600] Iteration[014/030] Train loss: 0.0111
2023-02-06 14:27:37 | Train | Epoch[292/600] Iteration[015/030] Train loss: 0.0112
2023-02-06 14:27:37 | Train | Epoch[292/600] Iteration[016/030] Train loss: 0.0112
2023-02-06 14:27:37 | Train | Epoch[292/600] Iteration[017/030] Train loss: 0.0112
2023-02-06 14:27:37 | Train | Epoch[292/600] Iteration[018/030] Train loss: 0.0112
2023-02-06 14:27:38 | Train | Epoch[292/600] Iteration[019/030] Train loss: 0.0112
2023-02-06 14:27:38 | Train | Epoch[292/600] Iteration[020/030] Train loss: 0.0112
2023-02-06 14:27:38 | Train | Epoch[292/600] Iteration[021/030] Train loss: 0.0112
2023-02-06 14:27:38 | Train | Epoch[292/600] Iteration[022/030] Train loss: 0.0112
2023-02-06 14:27:39 | Train | Epoch[292/600] Iteration[023/030] Train loss: 0.0112
2023-02-06 14:27:39 | Train | Epoch[292/600] Iteration[024/030] Train loss: 0.0113
2023-02-06 14:27:39 | Train | Epoch[292/600] Iteration[025/030] Train loss: 0.0113
2023-02-06 14:27:39 | Train | Epoch[292/600] Iteration[026/030] Train loss: 0.0112
2023-02-06 14:27:39 | Train | Epoch[292/600] Iteration[027/030] Train loss: 0.0112
2023-02-06 14:27:40 | Train | Epoch[292/600] Iteration[028/030] Train loss: 0.0112
2023-02-06 14:27:40 | Train | Epoch[292/600] Iteration[029/030] Train loss: 0.0113
2023-02-06 14:27:40 | Train | Epoch[292/600] Iteration[030/030] Train loss: 0.0112
2023-02-06 14:27:40 | Valid | Epoch[292/600] Iteration[001/008] Valid loss: 0.0962
2023-02-06 14:27:40 | Valid | Epoch[292/600] Iteration[002/008] Valid loss: 0.0918
2023-02-06 14:27:40 | Valid | Epoch[292/600] Iteration[003/008] Valid loss: 0.0947
2023-02-06 14:27:40 | Valid | Epoch[292/600] Iteration[004/008] Valid loss: 0.0920
2023-02-06 14:27:40 | Valid | Epoch[292/600] Iteration[005/008] Valid loss: 0.0919
2023-02-06 14:27:41 | Valid | Epoch[292/600] Iteration[006/008] Valid loss: 0.0897
2023-02-06 14:27:41 | Valid | Epoch[292/600] Iteration[007/008] Valid loss: 0.0873
2023-02-06 14:27:41 | Valid | Epoch[292/600] Iteration[008/008] Valid loss: 0.0891
2023-02-06 14:27:41 | Valid | Epoch[292/600] MIou: 0.7589112093533685
2023-02-06 14:27:41 | Valid | Epoch[292/600] Pixel Accuracy: 0.9599622090657552
2023-02-06 14:27:41 | Valid | Epoch[292/600] Mean Pixel Accuracy: 0.7817369078186491
2023-02-06 14:27:41 | Stage | Epoch[292/600] Train loss:0.0112
2023-02-06 14:27:41 | Stage | Epoch[292/600] Valid loss:0.0891
2023-02-06 14:27:41 | Stage | Epoch[292/600] LR:0.01

2023-02-06 14:27:41 | Train | Epoch[293/600] Iteration[001/030] Train loss: 0.0106
2023-02-06 14:27:41 | Train | Epoch[293/600] Iteration[002/030] Train loss: 0.0106
2023-02-06 14:27:42 | Train | Epoch[293/600] Iteration[003/030] Train loss: 0.0103
2023-02-06 14:27:42 | Train | Epoch[293/600] Iteration[004/030] Train loss: 0.0105
2023-02-06 14:27:42 | Train | Epoch[293/600] Iteration[005/030] Train loss: 0.0104
2023-02-06 14:27:42 | Train | Epoch[293/600] Iteration[006/030] Train loss: 0.0105
2023-02-06 14:27:42 | Train | Epoch[293/600] Iteration[007/030] Train loss: 0.0107
2023-02-06 14:27:43 | Train | Epoch[293/600] Iteration[008/030] Train loss: 0.0108
2023-02-06 14:27:43 | Train | Epoch[293/600] Iteration[009/030] Train loss: 0.0114
2023-02-06 14:27:43 | Train | Epoch[293/600] Iteration[010/030] Train loss: 0.0114
2023-02-06 14:27:43 | Train | Epoch[293/600] Iteration[011/030] Train loss: 0.0112
2023-02-06 14:27:44 | Train | Epoch[293/600] Iteration[012/030] Train loss: 0.0111
2023-02-06 14:27:44 | Train | Epoch[293/600] Iteration[013/030] Train loss: 0.0112
2023-02-06 14:27:44 | Train | Epoch[293/600] Iteration[014/030] Train loss: 0.0113
2023-02-06 14:27:44 | Train | Epoch[293/600] Iteration[015/030] Train loss: 0.0114
2023-02-06 14:27:44 | Train | Epoch[293/600] Iteration[016/030] Train loss: 0.0115
2023-02-06 14:27:45 | Train | Epoch[293/600] Iteration[017/030] Train loss: 0.0115
2023-02-06 14:27:45 | Train | Epoch[293/600] Iteration[018/030] Train loss: 0.0114
2023-02-06 14:27:45 | Train | Epoch[293/600] Iteration[019/030] Train loss: 0.0114
2023-02-06 14:27:45 | Train | Epoch[293/600] Iteration[020/030] Train loss: 0.0115
2023-02-06 14:27:46 | Train | Epoch[293/600] Iteration[021/030] Train loss: 0.0114
2023-02-06 14:27:46 | Train | Epoch[293/600] Iteration[022/030] Train loss: 0.0115
2023-02-06 14:27:46 | Train | Epoch[293/600] Iteration[023/030] Train loss: 0.0115
2023-02-06 14:27:46 | Train | Epoch[293/600] Iteration[024/030] Train loss: 0.0114
2023-02-06 14:27:46 | Train | Epoch[293/600] Iteration[025/030] Train loss: 0.0114
2023-02-06 14:27:47 | Train | Epoch[293/600] Iteration[026/030] Train loss: 0.0114
2023-02-06 14:27:47 | Train | Epoch[293/600] Iteration[027/030] Train loss: 0.0114
2023-02-06 14:27:47 | Train | Epoch[293/600] Iteration[028/030] Train loss: 0.0114
2023-02-06 14:27:47 | Train | Epoch[293/600] Iteration[029/030] Train loss: 0.0114
2023-02-06 14:27:47 | Train | Epoch[293/600] Iteration[030/030] Train loss: 0.0113
2023-02-06 14:27:48 | Valid | Epoch[293/600] Iteration[001/008] Valid loss: 0.5336
2023-02-06 14:27:48 | Valid | Epoch[293/600] Iteration[002/008] Valid loss: 0.4868
2023-02-06 14:27:48 | Valid | Epoch[293/600] Iteration[003/008] Valid loss: 0.4972
2023-02-06 14:27:48 | Valid | Epoch[293/600] Iteration[004/008] Valid loss: 0.4956
2023-02-06 14:27:48 | Valid | Epoch[293/600] Iteration[005/008] Valid loss: 0.5100
2023-02-06 14:27:48 | Valid | Epoch[293/600] Iteration[006/008] Valid loss: 0.4994
2023-02-06 14:27:48 | Valid | Epoch[293/600] Iteration[007/008] Valid loss: 0.5321
2023-02-06 14:27:48 | Valid | Epoch[293/600] Iteration[008/008] Valid loss: 0.5552
2023-02-06 14:27:48 | Valid | Epoch[293/600] MIou: 0.9009530230309906
2023-02-06 14:27:48 | Valid | Epoch[293/600] Pixel Accuracy: 0.9809697469075521
2023-02-06 14:27:48 | Valid | Epoch[293/600] Mean Pixel Accuracy: 0.9797377923220509
2023-02-06 14:27:48 | Stage | Epoch[293/600] Train loss:0.0113
2023-02-06 14:27:48 | Stage | Epoch[293/600] Valid loss:0.5552
2023-02-06 14:27:48 | Stage | Epoch[293/600] LR:0.01

2023-02-06 14:27:49 | Train | Epoch[294/600] Iteration[001/030] Train loss: 0.0125
2023-02-06 14:27:49 | Train | Epoch[294/600] Iteration[002/030] Train loss: 0.0120
2023-02-06 14:27:49 | Train | Epoch[294/600] Iteration[003/030] Train loss: 0.0114
2023-02-06 14:27:49 | Train | Epoch[294/600] Iteration[004/030] Train loss: 0.0113
2023-02-06 14:27:50 | Train | Epoch[294/600] Iteration[005/030] Train loss: 0.0112
2023-02-06 14:27:50 | Train | Epoch[294/600] Iteration[006/030] Train loss: 0.0111
2023-02-06 14:27:50 | Train | Epoch[294/600] Iteration[007/030] Train loss: 0.0111
2023-02-06 14:27:50 | Train | Epoch[294/600] Iteration[008/030] Train loss: 0.0109
2023-02-06 14:27:50 | Train | Epoch[294/600] Iteration[009/030] Train loss: 0.0111
2023-02-06 14:27:51 | Train | Epoch[294/600] Iteration[010/030] Train loss: 0.0110
2023-02-06 14:27:51 | Train | Epoch[294/600] Iteration[011/030] Train loss: 0.0110
2023-02-06 14:27:51 | Train | Epoch[294/600] Iteration[012/030] Train loss: 0.0109
2023-02-06 14:27:51 | Train | Epoch[294/600] Iteration[013/030] Train loss: 0.0108
2023-02-06 14:27:52 | Train | Epoch[294/600] Iteration[014/030] Train loss: 0.0109
2023-02-06 14:27:52 | Train | Epoch[294/600] Iteration[015/030] Train loss: 0.0109
2023-02-06 14:27:52 | Train | Epoch[294/600] Iteration[016/030] Train loss: 0.0109
2023-02-06 14:27:52 | Train | Epoch[294/600] Iteration[017/030] Train loss: 0.0109
2023-02-06 14:27:52 | Train | Epoch[294/600] Iteration[018/030] Train loss: 0.0109
2023-02-06 14:27:53 | Train | Epoch[294/600] Iteration[019/030] Train loss: 0.0109
2023-02-06 14:27:53 | Train | Epoch[294/600] Iteration[020/030] Train loss: 0.0109
2023-02-06 14:27:53 | Train | Epoch[294/600] Iteration[021/030] Train loss: 0.0109
2023-02-06 14:27:53 | Train | Epoch[294/600] Iteration[022/030] Train loss: 0.0109
2023-02-06 14:27:54 | Train | Epoch[294/600] Iteration[023/030] Train loss: 0.0109
2023-02-06 14:27:54 | Train | Epoch[294/600] Iteration[024/030] Train loss: 0.0108
2023-02-06 14:27:54 | Train | Epoch[294/600] Iteration[025/030] Train loss: 0.0109
2023-02-06 14:27:54 | Train | Epoch[294/600] Iteration[026/030] Train loss: 0.0109
2023-02-06 14:27:54 | Train | Epoch[294/600] Iteration[027/030] Train loss: 0.0109
2023-02-06 14:27:55 | Train | Epoch[294/600] Iteration[028/030] Train loss: 0.0109
2023-02-06 14:27:55 | Train | Epoch[294/600] Iteration[029/030] Train loss: 0.0110
2023-02-06 14:27:55 | Train | Epoch[294/600] Iteration[030/030] Train loss: 0.0110
2023-02-06 14:27:55 | Valid | Epoch[294/600] Iteration[001/008] Valid loss: 0.0971
2023-02-06 14:27:55 | Valid | Epoch[294/600] Iteration[002/008] Valid loss: 0.0751
2023-02-06 14:27:55 | Valid | Epoch[294/600] Iteration[003/008] Valid loss: 0.0746
2023-02-06 14:27:55 | Valid | Epoch[294/600] Iteration[004/008] Valid loss: 0.0690
2023-02-06 14:27:56 | Valid | Epoch[294/600] Iteration[005/008] Valid loss: 0.0665
2023-02-06 14:27:56 | Valid | Epoch[294/600] Iteration[006/008] Valid loss: 0.0649
2023-02-06 14:27:56 | Valid | Epoch[294/600] Iteration[007/008] Valid loss: 0.0666
2023-02-06 14:27:56 | Valid | Epoch[294/600] Iteration[008/008] Valid loss: 0.0651
2023-02-06 14:27:56 | Valid | Epoch[294/600] MIou: 0.9025725164056579
2023-02-06 14:27:56 | Valid | Epoch[294/600] Pixel Accuracy: 0.9836298624674479
2023-02-06 14:27:56 | Valid | Epoch[294/600] Mean Pixel Accuracy: 0.919830481519534
2023-02-06 14:27:56 | Stage | Epoch[294/600] Train loss:0.0110
2023-02-06 14:27:56 | Stage | Epoch[294/600] Valid loss:0.0651
2023-02-06 14:27:56 | Stage | Epoch[294/600] LR:0.01

2023-02-06 14:27:56 | Train | Epoch[295/600] Iteration[001/030] Train loss: 0.0139
2023-02-06 14:27:56 | Train | Epoch[295/600] Iteration[002/030] Train loss: 0.0114
2023-02-06 14:27:57 | Train | Epoch[295/600] Iteration[003/030] Train loss: 0.0120
2023-02-06 14:27:57 | Train | Epoch[295/600] Iteration[004/030] Train loss: 0.0116
2023-02-06 14:27:57 | Train | Epoch[295/600] Iteration[005/030] Train loss: 0.0113
2023-02-06 14:27:57 | Train | Epoch[295/600] Iteration[006/030] Train loss: 0.0110
2023-02-06 14:27:58 | Train | Epoch[295/600] Iteration[007/030] Train loss: 0.0109
2023-02-06 14:27:58 | Train | Epoch[295/600] Iteration[008/030] Train loss: 0.0107
2023-02-06 14:27:58 | Train | Epoch[295/600] Iteration[009/030] Train loss: 0.0106
2023-02-06 14:27:58 | Train | Epoch[295/600] Iteration[010/030] Train loss: 0.0106
2023-02-06 14:27:58 | Train | Epoch[295/600] Iteration[011/030] Train loss: 0.0106
2023-02-06 14:27:59 | Train | Epoch[295/600] Iteration[012/030] Train loss: 0.0106
2023-02-06 14:27:59 | Train | Epoch[295/600] Iteration[013/030] Train loss: 0.0107
2023-02-06 14:27:59 | Train | Epoch[295/600] Iteration[014/030] Train loss: 0.0106
2023-02-06 14:27:59 | Train | Epoch[295/600] Iteration[015/030] Train loss: 0.0106
2023-02-06 14:27:59 | Train | Epoch[295/600] Iteration[016/030] Train loss: 0.0106
2023-02-06 14:28:00 | Train | Epoch[295/600] Iteration[017/030] Train loss: 0.0106
2023-02-06 14:28:00 | Train | Epoch[295/600] Iteration[018/030] Train loss: 0.0106
2023-02-06 14:28:00 | Train | Epoch[295/600] Iteration[019/030] Train loss: 0.0107
2023-02-06 14:28:00 | Train | Epoch[295/600] Iteration[020/030] Train loss: 0.0106
2023-02-06 14:28:01 | Train | Epoch[295/600] Iteration[021/030] Train loss: 0.0107
2023-02-06 14:28:01 | Train | Epoch[295/600] Iteration[022/030] Train loss: 0.0107
2023-02-06 14:28:01 | Train | Epoch[295/600] Iteration[023/030] Train loss: 0.0107
2023-02-06 14:28:01 | Train | Epoch[295/600] Iteration[024/030] Train loss: 0.0108
2023-02-06 14:28:01 | Train | Epoch[295/600] Iteration[025/030] Train loss: 0.0108
2023-02-06 14:28:02 | Train | Epoch[295/600] Iteration[026/030] Train loss: 0.0109
2023-02-06 14:28:02 | Train | Epoch[295/600] Iteration[027/030] Train loss: 0.0109
2023-02-06 14:28:02 | Train | Epoch[295/600] Iteration[028/030] Train loss: 0.0110
2023-02-06 14:28:02 | Train | Epoch[295/600] Iteration[029/030] Train loss: 0.0110
2023-02-06 14:28:02 | Train | Epoch[295/600] Iteration[030/030] Train loss: 0.0111
2023-02-06 14:28:03 | Valid | Epoch[295/600] Iteration[001/008] Valid loss: 0.2976
2023-02-06 14:28:03 | Valid | Epoch[295/600] Iteration[002/008] Valid loss: 0.2328
2023-02-06 14:28:03 | Valid | Epoch[295/600] Iteration[003/008] Valid loss: 0.2331
2023-02-06 14:28:03 | Valid | Epoch[295/600] Iteration[004/008] Valid loss: 0.2278
2023-02-06 14:28:03 | Valid | Epoch[295/600] Iteration[005/008] Valid loss: 0.2313
2023-02-06 14:28:03 | Valid | Epoch[295/600] Iteration[006/008] Valid loss: 0.2289
2023-02-06 14:28:03 | Valid | Epoch[295/600] Iteration[007/008] Valid loss: 0.2515
2023-02-06 14:28:03 | Valid | Epoch[295/600] Iteration[008/008] Valid loss: 0.2551
2023-02-06 14:28:03 | Valid | Epoch[295/600] MIou: 0.9218903895135162
2023-02-06 14:28:03 | Valid | Epoch[295/600] Pixel Accuracy: 0.9858601888020834
2023-02-06 14:28:03 | Valid | Epoch[295/600] Mean Pixel Accuracy: 0.9723190761693323
2023-02-06 14:28:03 | Stage | Epoch[295/600] Train loss:0.0111
2023-02-06 14:28:03 | Stage | Epoch[295/600] Valid loss:0.2551
2023-02-06 14:28:03 | Stage | Epoch[295/600] LR:0.01

2023-02-06 14:28:04 | Train | Epoch[296/600] Iteration[001/030] Train loss: 0.0101
2023-02-06 14:28:04 | Train | Epoch[296/600] Iteration[002/030] Train loss: 0.0113
2023-02-06 14:28:04 | Train | Epoch[296/600] Iteration[003/030] Train loss: 0.0109
2023-02-06 14:28:04 | Train | Epoch[296/600] Iteration[004/030] Train loss: 0.0108
2023-02-06 14:28:05 | Train | Epoch[296/600] Iteration[005/030] Train loss: 0.0107
2023-02-06 14:28:05 | Train | Epoch[296/600] Iteration[006/030] Train loss: 0.0109
2023-02-06 14:28:05 | Train | Epoch[296/600] Iteration[007/030] Train loss: 0.0108
2023-02-06 14:28:05 | Train | Epoch[296/600] Iteration[008/030] Train loss: 0.0109
2023-02-06 14:28:05 | Train | Epoch[296/600] Iteration[009/030] Train loss: 0.0111
2023-02-06 14:28:06 | Train | Epoch[296/600] Iteration[010/030] Train loss: 0.0111
2023-02-06 14:28:06 | Train | Epoch[296/600] Iteration[011/030] Train loss: 0.0111
2023-02-06 14:28:06 | Train | Epoch[296/600] Iteration[012/030] Train loss: 0.0111
2023-02-06 14:28:06 | Train | Epoch[296/600] Iteration[013/030] Train loss: 0.0110
2023-02-06 14:28:07 | Train | Epoch[296/600] Iteration[014/030] Train loss: 0.0110
2023-02-06 14:28:07 | Train | Epoch[296/600] Iteration[015/030] Train loss: 0.0110
2023-02-06 14:28:07 | Train | Epoch[296/600] Iteration[016/030] Train loss: 0.0109
2023-02-06 14:28:07 | Train | Epoch[296/600] Iteration[017/030] Train loss: 0.0109
2023-02-06 14:28:07 | Train | Epoch[296/600] Iteration[018/030] Train loss: 0.0108
2023-02-06 14:28:08 | Train | Epoch[296/600] Iteration[019/030] Train loss: 0.0109
2023-02-06 14:28:08 | Train | Epoch[296/600] Iteration[020/030] Train loss: 0.0109
2023-02-06 14:28:08 | Train | Epoch[296/600] Iteration[021/030] Train loss: 0.0108
2023-02-06 14:28:08 | Train | Epoch[296/600] Iteration[022/030] Train loss: 0.0109
2023-02-06 14:28:09 | Train | Epoch[296/600] Iteration[023/030] Train loss: 0.0109
2023-02-06 14:28:09 | Train | Epoch[296/600] Iteration[024/030] Train loss: 0.0109
2023-02-06 14:28:09 | Train | Epoch[296/600] Iteration[025/030] Train loss: 0.0109
2023-02-06 14:28:09 | Train | Epoch[296/600] Iteration[026/030] Train loss: 0.0109
2023-02-06 14:28:09 | Train | Epoch[296/600] Iteration[027/030] Train loss: 0.0109
2023-02-06 14:28:10 | Train | Epoch[296/600] Iteration[028/030] Train loss: 0.0109
2023-02-06 14:28:10 | Train | Epoch[296/600] Iteration[029/030] Train loss: 0.0109
2023-02-06 14:28:10 | Train | Epoch[296/600] Iteration[030/030] Train loss: 0.0109
2023-02-06 14:28:10 | Valid | Epoch[296/600] Iteration[001/008] Valid loss: 0.2143
2023-02-06 14:28:10 | Valid | Epoch[296/600] Iteration[002/008] Valid loss: 0.1586
2023-02-06 14:28:10 | Valid | Epoch[296/600] Iteration[003/008] Valid loss: 0.1463
2023-02-06 14:28:10 | Valid | Epoch[296/600] Iteration[004/008] Valid loss: 0.1356
2023-02-06 14:28:11 | Valid | Epoch[296/600] Iteration[005/008] Valid loss: 0.1380
2023-02-06 14:28:11 | Valid | Epoch[296/600] Iteration[006/008] Valid loss: 0.1353
2023-02-06 14:28:11 | Valid | Epoch[296/600] Iteration[007/008] Valid loss: 0.1507
2023-02-06 14:28:11 | Valid | Epoch[296/600] Iteration[008/008] Valid loss: 0.1494
2023-02-06 14:28:11 | Valid | Epoch[296/600] MIou: 0.9296023940688671
2023-02-06 14:28:11 | Valid | Epoch[296/600] Pixel Accuracy: 0.9875742594401041
2023-02-06 14:28:11 | Valid | Epoch[296/600] Mean Pixel Accuracy: 0.9679098445391379
2023-02-06 14:28:11 | Stage | Epoch[296/600] Train loss:0.0109
2023-02-06 14:28:11 | Stage | Epoch[296/600] Valid loss:0.1494
2023-02-06 14:28:11 | Stage | Epoch[296/600] LR:0.01

2023-02-06 14:28:11 | Train | Epoch[297/600] Iteration[001/030] Train loss: 0.0109
2023-02-06 14:28:11 | Train | Epoch[297/600] Iteration[002/030] Train loss: 0.0117
2023-02-06 14:28:12 | Train | Epoch[297/600] Iteration[003/030] Train loss: 0.0113
2023-02-06 14:28:12 | Train | Epoch[297/600] Iteration[004/030] Train loss: 0.0114
2023-02-06 14:28:12 | Train | Epoch[297/600] Iteration[005/030] Train loss: 0.0111
2023-02-06 14:28:12 | Train | Epoch[297/600] Iteration[006/030] Train loss: 0.0110
2023-02-06 14:28:13 | Train | Epoch[297/600] Iteration[007/030] Train loss: 0.0114
2023-02-06 14:28:13 | Train | Epoch[297/600] Iteration[008/030] Train loss: 0.0111
2023-02-06 14:28:13 | Train | Epoch[297/600] Iteration[009/030] Train loss: 0.0110
2023-02-06 14:28:13 | Train | Epoch[297/600] Iteration[010/030] Train loss: 0.0110
2023-02-06 14:28:13 | Train | Epoch[297/600] Iteration[011/030] Train loss: 0.0109
2023-02-06 14:28:14 | Train | Epoch[297/600] Iteration[012/030] Train loss: 0.0108
2023-02-06 14:28:14 | Train | Epoch[297/600] Iteration[013/030] Train loss: 0.0110
2023-02-06 14:28:14 | Train | Epoch[297/600] Iteration[014/030] Train loss: 0.0112
2023-02-06 14:28:14 | Train | Epoch[297/600] Iteration[015/030] Train loss: 0.0112
2023-02-06 14:28:15 | Train | Epoch[297/600] Iteration[016/030] Train loss: 0.0111
2023-02-06 14:28:15 | Train | Epoch[297/600] Iteration[017/030] Train loss: 0.0111
2023-02-06 14:28:15 | Train | Epoch[297/600] Iteration[018/030] Train loss: 0.0111
2023-02-06 14:28:15 | Train | Epoch[297/600] Iteration[019/030] Train loss: 0.0111
2023-02-06 14:28:15 | Train | Epoch[297/600] Iteration[020/030] Train loss: 0.0110
2023-02-06 14:28:16 | Train | Epoch[297/600] Iteration[021/030] Train loss: 0.0113
2023-02-06 14:28:16 | Train | Epoch[297/600] Iteration[022/030] Train loss: 0.0112
2023-02-06 14:28:16 | Train | Epoch[297/600] Iteration[023/030] Train loss: 0.0113
2023-02-06 14:28:16 | Train | Epoch[297/600] Iteration[024/030] Train loss: 0.0114
2023-02-06 14:28:17 | Train | Epoch[297/600] Iteration[025/030] Train loss: 0.0114
2023-02-06 14:28:17 | Train | Epoch[297/600] Iteration[026/030] Train loss: 0.0113
2023-02-06 14:28:17 | Train | Epoch[297/600] Iteration[027/030] Train loss: 0.0113
2023-02-06 14:28:17 | Train | Epoch[297/600] Iteration[028/030] Train loss: 0.0113
2023-02-06 14:28:17 | Train | Epoch[297/600] Iteration[029/030] Train loss: 0.0113
2023-02-06 14:28:17 | Train | Epoch[297/600] Iteration[030/030] Train loss: 0.0113
2023-02-06 14:28:18 | Valid | Epoch[297/600] Iteration[001/008] Valid loss: 2.8010
2023-02-06 14:28:18 | Valid | Epoch[297/600] Iteration[002/008] Valid loss: 2.7150
2023-02-06 14:28:18 | Valid | Epoch[297/600] Iteration[003/008] Valid loss: 2.8953
2023-02-06 14:28:18 | Valid | Epoch[297/600] Iteration[004/008] Valid loss: 2.9719
2023-02-06 14:28:18 | Valid | Epoch[297/600] Iteration[005/008] Valid loss: 3.0492
2023-02-06 14:28:18 | Valid | Epoch[297/600] Iteration[006/008] Valid loss: 3.0123
2023-02-06 14:28:18 | Valid | Epoch[297/600] Iteration[007/008] Valid loss: 3.1056
2023-02-06 14:28:18 | Valid | Epoch[297/600] Iteration[008/008] Valid loss: 3.2261
2023-02-06 14:28:18 | Valid | Epoch[297/600] MIou: 0.7640511846015707
2023-02-06 14:28:18 | Valid | Epoch[297/600] Pixel Accuracy: 0.938720703125
2023-02-06 14:28:18 | Valid | Epoch[297/600] Mean Pixel Accuracy: 0.9657222806165634
2023-02-06 14:28:18 | Stage | Epoch[297/600] Train loss:0.0113
2023-02-06 14:28:18 | Stage | Epoch[297/600] Valid loss:3.2261
2023-02-06 14:28:18 | Stage | Epoch[297/600] LR:0.01

2023-02-06 14:28:19 | Train | Epoch[298/600] Iteration[001/030] Train loss: 0.0126
2023-02-06 14:28:19 | Train | Epoch[298/600] Iteration[002/030] Train loss: 0.0116
2023-02-06 14:28:19 | Train | Epoch[298/600] Iteration[003/030] Train loss: 0.0114
2023-02-06 14:28:19 | Train | Epoch[298/600] Iteration[004/030] Train loss: 0.0117
2023-02-06 14:28:20 | Train | Epoch[298/600] Iteration[005/030] Train loss: 0.0115
2023-02-06 14:28:20 | Train | Epoch[298/600] Iteration[006/030] Train loss: 0.0115
2023-02-06 14:28:20 | Train | Epoch[298/600] Iteration[007/030] Train loss: 0.0115
2023-02-06 14:28:20 | Train | Epoch[298/600] Iteration[008/030] Train loss: 0.0112
2023-02-06 14:28:21 | Train | Epoch[298/600] Iteration[009/030] Train loss: 0.0112
2023-02-06 14:28:21 | Train | Epoch[298/600] Iteration[010/030] Train loss: 0.0112
2023-02-06 14:28:21 | Train | Epoch[298/600] Iteration[011/030] Train loss: 0.0113
2023-02-06 14:28:21 | Train | Epoch[298/600] Iteration[012/030] Train loss: 0.0112
2023-02-06 14:28:21 | Train | Epoch[298/600] Iteration[013/030] Train loss: 0.0111
2023-02-06 14:28:22 | Train | Epoch[298/600] Iteration[014/030] Train loss: 0.0112
2023-02-06 14:28:22 | Train | Epoch[298/600] Iteration[015/030] Train loss: 0.0112
2023-02-06 14:28:22 | Train | Epoch[298/600] Iteration[016/030] Train loss: 0.0113
2023-02-06 14:28:22 | Train | Epoch[298/600] Iteration[017/030] Train loss: 0.0113
2023-02-06 14:28:23 | Train | Epoch[298/600] Iteration[018/030] Train loss: 0.0112
2023-02-06 14:28:23 | Train | Epoch[298/600] Iteration[019/030] Train loss: 0.0112
2023-02-06 14:28:23 | Train | Epoch[298/600] Iteration[020/030] Train loss: 0.0111
2023-02-06 14:28:23 | Train | Epoch[298/600] Iteration[021/030] Train loss: 0.0112
2023-02-06 14:28:23 | Train | Epoch[298/600] Iteration[022/030] Train loss: 0.0114
2023-02-06 14:28:24 | Train | Epoch[298/600] Iteration[023/030] Train loss: 0.0114
2023-02-06 14:28:24 | Train | Epoch[298/600] Iteration[024/030] Train loss: 0.0114
2023-02-06 14:28:24 | Train | Epoch[298/600] Iteration[025/030] Train loss: 0.0115
2023-02-06 14:28:24 | Train | Epoch[298/600] Iteration[026/030] Train loss: 0.0114
2023-02-06 14:28:24 | Train | Epoch[298/600] Iteration[027/030] Train loss: 0.0115
2023-02-06 14:28:25 | Train | Epoch[298/600] Iteration[028/030] Train loss: 0.0115
2023-02-06 14:28:25 | Train | Epoch[298/600] Iteration[029/030] Train loss: 0.0115
2023-02-06 14:28:25 | Train | Epoch[298/600] Iteration[030/030] Train loss: 0.0114
2023-02-06 14:28:25 | Valid | Epoch[298/600] Iteration[001/008] Valid loss: 0.0793
2023-02-06 14:28:25 | Valid | Epoch[298/600] Iteration[002/008] Valid loss: 0.0749
2023-02-06 14:28:26 | Valid | Epoch[298/600] Iteration[003/008] Valid loss: 0.0725
2023-02-06 14:28:26 | Valid | Epoch[298/600] Iteration[004/008] Valid loss: 0.0724
2023-02-06 14:28:26 | Valid | Epoch[298/600] Iteration[005/008] Valid loss: 0.0708
2023-02-06 14:28:26 | Valid | Epoch[298/600] Iteration[006/008] Valid loss: 0.0698
2023-02-06 14:28:26 | Valid | Epoch[298/600] Iteration[007/008] Valid loss: 0.0709
2023-02-06 14:28:26 | Valid | Epoch[298/600] Iteration[008/008] Valid loss: 0.0697
2023-02-06 14:28:26 | Valid | Epoch[298/600] MIou: 0.8909021630818164
2023-02-06 14:28:26 | Valid | Epoch[298/600] Pixel Accuracy: 0.9817708333333334
2023-02-06 14:28:26 | Valid | Epoch[298/600] Mean Pixel Accuracy: 0.9066032721609959
2023-02-06 14:28:26 | Stage | Epoch[298/600] Train loss:0.0114
2023-02-06 14:28:26 | Stage | Epoch[298/600] Valid loss:0.0697
2023-02-06 14:28:26 | Stage | Epoch[298/600] LR:0.01

2023-02-06 14:28:26 | Train | Epoch[299/600] Iteration[001/030] Train loss: 0.0095
2023-02-06 14:28:27 | Train | Epoch[299/600] Iteration[002/030] Train loss: 0.0102
2023-02-06 14:28:27 | Train | Epoch[299/600] Iteration[003/030] Train loss: 0.0103
2023-02-06 14:28:27 | Train | Epoch[299/600] Iteration[004/030] Train loss: 0.0107
2023-02-06 14:28:27 | Train | Epoch[299/600] Iteration[005/030] Train loss: 0.0107
2023-02-06 14:28:27 | Train | Epoch[299/600] Iteration[006/030] Train loss: 0.0107
2023-02-06 14:28:28 | Train | Epoch[299/600] Iteration[007/030] Train loss: 0.0107
2023-02-06 14:28:28 | Train | Epoch[299/600] Iteration[008/030] Train loss: 0.0111
2023-02-06 14:28:28 | Train | Epoch[299/600] Iteration[009/030] Train loss: 0.0110
2023-02-06 14:28:28 | Train | Epoch[299/600] Iteration[010/030] Train loss: 0.0111
2023-02-06 14:28:29 | Train | Epoch[299/600] Iteration[011/030] Train loss: 0.0109
2023-02-06 14:28:29 | Train | Epoch[299/600] Iteration[012/030] Train loss: 0.0109
2023-02-06 14:28:29 | Train | Epoch[299/600] Iteration[013/030] Train loss: 0.0110
2023-02-06 14:28:29 | Train | Epoch[299/600] Iteration[014/030] Train loss: 0.0110
2023-02-06 14:28:29 | Train | Epoch[299/600] Iteration[015/030] Train loss: 0.0110
2023-02-06 14:28:30 | Train | Epoch[299/600] Iteration[016/030] Train loss: 0.0110
2023-02-06 14:28:30 | Train | Epoch[299/600] Iteration[017/030] Train loss: 0.0111
2023-02-06 14:28:30 | Train | Epoch[299/600] Iteration[018/030] Train loss: 0.0112
2023-02-06 14:28:30 | Train | Epoch[299/600] Iteration[019/030] Train loss: 0.0111
2023-02-06 14:28:30 | Train | Epoch[299/600] Iteration[020/030] Train loss: 0.0111
2023-02-06 14:28:31 | Train | Epoch[299/600] Iteration[021/030] Train loss: 0.0112
2023-02-06 14:28:31 | Train | Epoch[299/600] Iteration[022/030] Train loss: 0.0112
2023-02-06 14:28:31 | Train | Epoch[299/600] Iteration[023/030] Train loss: 0.0112
2023-02-06 14:28:31 | Train | Epoch[299/600] Iteration[024/030] Train loss: 0.0112
2023-02-06 14:28:32 | Train | Epoch[299/600] Iteration[025/030] Train loss: 0.0112
2023-02-06 14:28:32 | Train | Epoch[299/600] Iteration[026/030] Train loss: 0.0112
2023-02-06 14:28:32 | Train | Epoch[299/600] Iteration[027/030] Train loss: 0.0112
2023-02-06 14:28:32 | Train | Epoch[299/600] Iteration[028/030] Train loss: 0.0112
2023-02-06 14:28:32 | Train | Epoch[299/600] Iteration[029/030] Train loss: 0.0112
2023-02-06 14:28:33 | Train | Epoch[299/600] Iteration[030/030] Train loss: 0.0112
2023-02-06 14:28:33 | Valid | Epoch[299/600] Iteration[001/008] Valid loss: 0.3863
2023-02-06 14:28:33 | Valid | Epoch[299/600] Iteration[002/008] Valid loss: 0.3508
2023-02-06 14:28:33 | Valid | Epoch[299/600] Iteration[003/008] Valid loss: 0.3502
2023-02-06 14:28:33 | Valid | Epoch[299/600] Iteration[004/008] Valid loss: 0.3461
2023-02-06 14:28:33 | Valid | Epoch[299/600] Iteration[005/008] Valid loss: 0.3552
2023-02-06 14:28:33 | Valid | Epoch[299/600] Iteration[006/008] Valid loss: 0.3495
2023-02-06 14:28:33 | Valid | Epoch[299/600] Iteration[007/008] Valid loss: 0.3722
2023-02-06 14:28:33 | Valid | Epoch[299/600] Iteration[008/008] Valid loss: 0.3828
2023-02-06 14:28:33 | Valid | Epoch[299/600] MIou: 0.9093340109651764
2023-02-06 14:28:33 | Valid | Epoch[299/600] Pixel Accuracy: 0.982995351155599
2023-02-06 14:28:33 | Valid | Epoch[299/600] Mean Pixel Accuracy: 0.9766664396087366
2023-02-06 14:28:33 | Stage | Epoch[299/600] Train loss:0.0112
2023-02-06 14:28:33 | Stage | Epoch[299/600] Valid loss:0.3828
2023-02-06 14:28:33 | Stage | Epoch[299/600] LR:0.01

2023-02-06 14:28:34 | Train | Epoch[300/600] Iteration[001/030] Train loss: 0.0118
2023-02-06 14:28:34 | Train | Epoch[300/600] Iteration[002/030] Train loss: 0.0118
2023-02-06 14:28:34 | Train | Epoch[300/600] Iteration[003/030] Train loss: 0.0115
2023-02-06 14:28:35 | Train | Epoch[300/600] Iteration[004/030] Train loss: 0.0112
2023-02-06 14:28:35 | Train | Epoch[300/600] Iteration[005/030] Train loss: 0.0112
2023-02-06 14:28:35 | Train | Epoch[300/600] Iteration[006/030] Train loss: 0.0111
2023-02-06 14:28:35 | Train | Epoch[300/600] Iteration[007/030] Train loss: 0.0111
2023-02-06 14:28:35 | Train | Epoch[300/600] Iteration[008/030] Train loss: 0.0110
2023-02-06 14:28:36 | Train | Epoch[300/600] Iteration[009/030] Train loss: 0.0108
2023-02-06 14:28:36 | Train | Epoch[300/600] Iteration[010/030] Train loss: 0.0108
2023-02-06 14:28:36 | Train | Epoch[300/600] Iteration[011/030] Train loss: 0.0107
2023-02-06 14:28:36 | Train | Epoch[300/600] Iteration[012/030] Train loss: 0.0107
2023-02-06 14:28:36 | Train | Epoch[300/600] Iteration[013/030] Train loss: 0.0106
2023-02-06 14:28:37 | Train | Epoch[300/600] Iteration[014/030] Train loss: 0.0107
2023-02-06 14:28:37 | Train | Epoch[300/600] Iteration[015/030] Train loss: 0.0107
2023-02-06 14:28:37 | Train | Epoch[300/600] Iteration[016/030] Train loss: 0.0106
2023-02-06 14:28:37 | Train | Epoch[300/600] Iteration[017/030] Train loss: 0.0106
2023-02-06 14:28:38 | Train | Epoch[300/600] Iteration[018/030] Train loss: 0.0107
2023-02-06 14:28:38 | Train | Epoch[300/600] Iteration[019/030] Train loss: 0.0109
2023-02-06 14:28:38 | Train | Epoch[300/600] Iteration[020/030] Train loss: 0.0110
2023-02-06 14:28:38 | Train | Epoch[300/600] Iteration[021/030] Train loss: 0.0110
2023-02-06 14:28:38 | Train | Epoch[300/600] Iteration[022/030] Train loss: 0.0110
2023-02-06 14:28:39 | Train | Epoch[300/600] Iteration[023/030] Train loss: 0.0111
2023-02-06 14:28:39 | Train | Epoch[300/600] Iteration[024/030] Train loss: 0.0111
2023-02-06 14:28:39 | Train | Epoch[300/600] Iteration[025/030] Train loss: 0.0112
2023-02-06 14:28:39 | Train | Epoch[300/600] Iteration[026/030] Train loss: 0.0113
2023-02-06 14:28:40 | Train | Epoch[300/600] Iteration[027/030] Train loss: 0.0112
2023-02-06 14:28:40 | Train | Epoch[300/600] Iteration[028/030] Train loss: 0.0112
2023-02-06 14:28:40 | Train | Epoch[300/600] Iteration[029/030] Train loss: 0.0115
2023-02-06 14:28:40 | Train | Epoch[300/600] Iteration[030/030] Train loss: 0.0115
2023-02-06 14:28:40 | Valid | Epoch[300/600] Iteration[001/008] Valid loss: 1.8087
2023-02-06 14:28:40 | Valid | Epoch[300/600] Iteration[002/008] Valid loss: 1.7910
2023-02-06 14:28:41 | Valid | Epoch[300/600] Iteration[003/008] Valid loss: 1.8836
2023-02-06 14:28:41 | Valid | Epoch[300/600] Iteration[004/008] Valid loss: 1.9155
2023-02-06 14:28:41 | Valid | Epoch[300/600] Iteration[005/008] Valid loss: 1.9716
2023-02-06 14:28:41 | Valid | Epoch[300/600] Iteration[006/008] Valid loss: 1.9526
2023-02-06 14:28:41 | Valid | Epoch[300/600] Iteration[007/008] Valid loss: 2.0280
2023-02-06 14:28:41 | Valid | Epoch[300/600] Iteration[008/008] Valid loss: 2.1162
2023-02-06 14:28:41 | Valid | Epoch[300/600] MIou: 0.8078960945776948
2023-02-06 14:28:41 | Valid | Epoch[300/600] Pixel Accuracy: 0.9547157287597656
2023-02-06 14:28:41 | Valid | Epoch[300/600] Mean Pixel Accuracy: 0.9741207196430258
2023-02-06 14:28:41 | Stage | Epoch[300/600] Train loss:0.0115
2023-02-06 14:28:41 | Stage | Epoch[300/600] Valid loss:2.1162
2023-02-06 14:28:41 | Stage | Epoch[300/600] LR:0.01

2023-02-06 14:28:41 | Train | Epoch[301/600] Iteration[001/030] Train loss: 0.0106
2023-02-06 14:28:42 | Train | Epoch[301/600] Iteration[002/030] Train loss: 0.0116
2023-02-06 14:28:42 | Train | Epoch[301/600] Iteration[003/030] Train loss: 0.0118
2023-02-06 14:28:42 | Train | Epoch[301/600] Iteration[004/030] Train loss: 0.0118
2023-02-06 14:28:42 | Train | Epoch[301/600] Iteration[005/030] Train loss: 0.0119
2023-02-06 14:28:42 | Train | Epoch[301/600] Iteration[006/030] Train loss: 0.0120
2023-02-06 14:28:43 | Train | Epoch[301/600] Iteration[007/030] Train loss: 0.0124
2023-02-06 14:28:43 | Train | Epoch[301/600] Iteration[008/030] Train loss: 0.0124
2023-02-06 14:28:43 | Train | Epoch[301/600] Iteration[009/030] Train loss: 0.0122
2023-02-06 14:28:43 | Train | Epoch[301/600] Iteration[010/030] Train loss: 0.0121
2023-02-06 14:28:44 | Train | Epoch[301/600] Iteration[011/030] Train loss: 0.0123
2023-02-06 14:28:44 | Train | Epoch[301/600] Iteration[012/030] Train loss: 0.0122
2023-02-06 14:28:44 | Train | Epoch[301/600] Iteration[013/030] Train loss: 0.0121
2023-02-06 14:28:44 | Train | Epoch[301/600] Iteration[014/030] Train loss: 0.0120
2023-02-06 14:28:44 | Train | Epoch[301/600] Iteration[015/030] Train loss: 0.0120
2023-02-06 14:28:45 | Train | Epoch[301/600] Iteration[016/030] Train loss: 0.0119
2023-02-06 14:28:45 | Train | Epoch[301/600] Iteration[017/030] Train loss: 0.0120
2023-02-06 14:28:45 | Train | Epoch[301/600] Iteration[018/030] Train loss: 0.0120
2023-02-06 14:28:45 | Train | Epoch[301/600] Iteration[019/030] Train loss: 0.0120
2023-02-06 14:28:46 | Train | Epoch[301/600] Iteration[020/030] Train loss: 0.0121
2023-02-06 14:28:46 | Train | Epoch[301/600] Iteration[021/030] Train loss: 0.0120
2023-02-06 14:28:46 | Train | Epoch[301/600] Iteration[022/030] Train loss: 0.0120
2023-02-06 14:28:46 | Train | Epoch[301/600] Iteration[023/030] Train loss: 0.0121
2023-02-06 14:28:46 | Train | Epoch[301/600] Iteration[024/030] Train loss: 0.0120
2023-02-06 14:28:47 | Train | Epoch[301/600] Iteration[025/030] Train loss: 0.0121
2023-02-06 14:28:47 | Train | Epoch[301/600] Iteration[026/030] Train loss: 0.0121
2023-02-06 14:28:47 | Train | Epoch[301/600] Iteration[027/030] Train loss: 0.0120
2023-02-06 14:28:47 | Train | Epoch[301/600] Iteration[028/030] Train loss: 0.0120
2023-02-06 14:28:47 | Train | Epoch[301/600] Iteration[029/030] Train loss: 0.0120
2023-02-06 14:28:48 | Train | Epoch[301/600] Iteration[030/030] Train loss: 0.0122
2023-02-06 14:28:48 | Valid | Epoch[301/600] Iteration[001/008] Valid loss: 0.6629
2023-02-06 14:28:48 | Valid | Epoch[301/600] Iteration[002/008] Valid loss: 0.5816
2023-02-06 14:28:48 | Valid | Epoch[301/600] Iteration[003/008] Valid loss: 0.6125
2023-02-06 14:28:48 | Valid | Epoch[301/600] Iteration[004/008] Valid loss: 0.6002
2023-02-06 14:28:48 | Valid | Epoch[301/600] Iteration[005/008] Valid loss: 0.6152
2023-02-06 14:28:48 | Valid | Epoch[301/600] Iteration[006/008] Valid loss: 0.6018
2023-02-06 14:28:48 | Valid | Epoch[301/600] Iteration[007/008] Valid loss: 0.6417
2023-02-06 14:28:48 | Valid | Epoch[301/600] Iteration[008/008] Valid loss: 0.6754
2023-02-06 14:28:48 | Valid | Epoch[301/600] MIou: 0.8880619412794697
2023-02-06 14:28:48 | Valid | Epoch[301/600] Pixel Accuracy: 0.9779243469238281
2023-02-06 14:28:48 | Valid | Epoch[301/600] Mean Pixel Accuracy: 0.978761362474157
2023-02-06 14:28:48 | Stage | Epoch[301/600] Train loss:0.0122
2023-02-06 14:28:48 | Stage | Epoch[301/600] Valid loss:0.6754
2023-02-06 14:28:48 | Stage | Epoch[301/600] LR:0.01

2023-02-06 14:28:49 | Train | Epoch[302/600] Iteration[001/030] Train loss: 0.0111
2023-02-06 14:28:49 | Train | Epoch[302/600] Iteration[002/030] Train loss: 0.0112
2023-02-06 14:28:49 | Train | Epoch[302/600] Iteration[003/030] Train loss: 0.0108
2023-02-06 14:28:50 | Train | Epoch[302/600] Iteration[004/030] Train loss: 0.0117
2023-02-06 14:28:50 | Train | Epoch[302/600] Iteration[005/030] Train loss: 0.0119
2023-02-06 14:28:50 | Train | Epoch[302/600] Iteration[006/030] Train loss: 0.0115
2023-02-06 14:28:50 | Train | Epoch[302/600] Iteration[007/030] Train loss: 0.0116
2023-02-06 14:28:50 | Train | Epoch[302/600] Iteration[008/030] Train loss: 0.0115
2023-02-06 14:28:51 | Train | Epoch[302/600] Iteration[009/030] Train loss: 0.0115
2023-02-06 14:28:51 | Train | Epoch[302/600] Iteration[010/030] Train loss: 0.0114
2023-02-06 14:28:51 | Train | Epoch[302/600] Iteration[011/030] Train loss: 0.0115
2023-02-06 14:28:51 | Train | Epoch[302/600] Iteration[012/030] Train loss: 0.0114
2023-02-06 14:28:52 | Train | Epoch[302/600] Iteration[013/030] Train loss: 0.0116
2023-02-06 14:28:52 | Train | Epoch[302/600] Iteration[014/030] Train loss: 0.0117
2023-02-06 14:28:52 | Train | Epoch[302/600] Iteration[015/030] Train loss: 0.0116
2023-02-06 14:28:52 | Train | Epoch[302/600] Iteration[016/030] Train loss: 0.0116
2023-02-06 14:28:52 | Train | Epoch[302/600] Iteration[017/030] Train loss: 0.0116
2023-02-06 14:28:53 | Train | Epoch[302/600] Iteration[018/030] Train loss: 0.0115
2023-02-06 14:28:53 | Train | Epoch[302/600] Iteration[019/030] Train loss: 0.0116
2023-02-06 14:28:53 | Train | Epoch[302/600] Iteration[020/030] Train loss: 0.0117
2023-02-06 14:28:53 | Train | Epoch[302/600] Iteration[021/030] Train loss: 0.0117
2023-02-06 14:28:53 | Train | Epoch[302/600] Iteration[022/030] Train loss: 0.0119
2023-02-06 14:28:54 | Train | Epoch[302/600] Iteration[023/030] Train loss: 0.0119
2023-02-06 14:28:54 | Train | Epoch[302/600] Iteration[024/030] Train loss: 0.0119
2023-02-06 14:28:54 | Train | Epoch[302/600] Iteration[025/030] Train loss: 0.0121
2023-02-06 14:28:54 | Train | Epoch[302/600] Iteration[026/030] Train loss: 0.0121
2023-02-06 14:28:55 | Train | Epoch[302/600] Iteration[027/030] Train loss: 0.0121
2023-02-06 14:28:55 | Train | Epoch[302/600] Iteration[028/030] Train loss: 0.0121
2023-02-06 14:28:55 | Train | Epoch[302/600] Iteration[029/030] Train loss: 0.0121
2023-02-06 14:28:55 | Train | Epoch[302/600] Iteration[030/030] Train loss: 0.0121
2023-02-06 14:28:55 | Valid | Epoch[302/600] Iteration[001/008] Valid loss: 0.0850
2023-02-06 14:28:56 | Valid | Epoch[302/600] Iteration[002/008] Valid loss: 0.0773
2023-02-06 14:28:56 | Valid | Epoch[302/600] Iteration[003/008] Valid loss: 0.0766
2023-02-06 14:28:56 | Valid | Epoch[302/600] Iteration[004/008] Valid loss: 0.0745
2023-02-06 14:28:56 | Valid | Epoch[302/600] Iteration[005/008] Valid loss: 0.0741
2023-02-06 14:28:56 | Valid | Epoch[302/600] Iteration[006/008] Valid loss: 0.0710
2023-02-06 14:28:56 | Valid | Epoch[302/600] Iteration[007/008] Valid loss: 0.0688
2023-02-06 14:28:56 | Valid | Epoch[302/600] Iteration[008/008] Valid loss: 0.0689
2023-02-06 14:28:56 | Valid | Epoch[302/600] MIou: 0.8485351425062955
2023-02-06 14:28:56 | Valid | Epoch[302/600] Pixel Accuracy: 0.974951426188151
2023-02-06 14:28:56 | Valid | Epoch[302/600] Mean Pixel Accuracy: 0.8633158548039936
2023-02-06 14:28:56 | Stage | Epoch[302/600] Train loss:0.0121
2023-02-06 14:28:56 | Stage | Epoch[302/600] Valid loss:0.0689
2023-02-06 14:28:56 | Stage | Epoch[302/600] LR:0.01

2023-02-06 14:28:56 | Train | Epoch[303/600] Iteration[001/030] Train loss: 0.0104
2023-02-06 14:28:57 | Train | Epoch[303/600] Iteration[002/030] Train loss: 0.0114
2023-02-06 14:28:57 | Train | Epoch[303/600] Iteration[003/030] Train loss: 0.0117
2023-02-06 14:28:57 | Train | Epoch[303/600] Iteration[004/030] Train loss: 0.0119
2023-02-06 14:28:57 | Train | Epoch[303/600] Iteration[005/030] Train loss: 0.0120
2023-02-06 14:28:57 | Train | Epoch[303/600] Iteration[006/030] Train loss: 0.0119
2023-02-06 14:28:58 | Train | Epoch[303/600] Iteration[007/030] Train loss: 0.0116
2023-02-06 14:28:58 | Train | Epoch[303/600] Iteration[008/030] Train loss: 0.0115
2023-02-06 14:28:58 | Train | Epoch[303/600] Iteration[009/030] Train loss: 0.0115
2023-02-06 14:28:58 | Train | Epoch[303/600] Iteration[010/030] Train loss: 0.0116
2023-02-06 14:28:59 | Train | Epoch[303/600] Iteration[011/030] Train loss: 0.0116
2023-02-06 14:28:59 | Train | Epoch[303/600] Iteration[012/030] Train loss: 0.0115
2023-02-06 14:28:59 | Train | Epoch[303/600] Iteration[013/030] Train loss: 0.0114
2023-02-06 14:28:59 | Train | Epoch[303/600] Iteration[014/030] Train loss: 0.0115
2023-02-06 14:28:59 | Train | Epoch[303/600] Iteration[015/030] Train loss: 0.0116
2023-02-06 14:29:00 | Train | Epoch[303/600] Iteration[016/030] Train loss: 0.0119
2023-02-06 14:29:00 | Train | Epoch[303/600] Iteration[017/030] Train loss: 0.0118
2023-02-06 14:29:00 | Train | Epoch[303/600] Iteration[018/030] Train loss: 0.0116
2023-02-06 14:29:00 | Train | Epoch[303/600] Iteration[019/030] Train loss: 0.0117
2023-02-06 14:29:01 | Train | Epoch[303/600] Iteration[020/030] Train loss: 0.0117
2023-02-06 14:29:01 | Train | Epoch[303/600] Iteration[021/030] Train loss: 0.0117
2023-02-06 14:29:01 | Train | Epoch[303/600] Iteration[022/030] Train loss: 0.0116
2023-02-06 14:29:01 | Train | Epoch[303/600] Iteration[023/030] Train loss: 0.0116
2023-02-06 14:29:01 | Train | Epoch[303/600] Iteration[024/030] Train loss: 0.0116
2023-02-06 14:29:02 | Train | Epoch[303/600] Iteration[025/030] Train loss: 0.0116
2023-02-06 14:29:02 | Train | Epoch[303/600] Iteration[026/030] Train loss: 0.0116
2023-02-06 14:29:02 | Train | Epoch[303/600] Iteration[027/030] Train loss: 0.0116
2023-02-06 14:29:02 | Train | Epoch[303/600] Iteration[028/030] Train loss: 0.0117
2023-02-06 14:29:03 | Train | Epoch[303/600] Iteration[029/030] Train loss: 0.0118
2023-02-06 14:29:03 | Train | Epoch[303/600] Iteration[030/030] Train loss: 0.0117
2023-02-06 14:29:03 | Valid | Epoch[303/600] Iteration[001/008] Valid loss: 0.5448
2023-02-06 14:29:03 | Valid | Epoch[303/600] Iteration[002/008] Valid loss: 0.5078
2023-02-06 14:29:03 | Valid | Epoch[303/600] Iteration[003/008] Valid loss: 0.5325
2023-02-06 14:29:03 | Valid | Epoch[303/600] Iteration[004/008] Valid loss: 0.5252
2023-02-06 14:29:03 | Valid | Epoch[303/600] Iteration[005/008] Valid loss: 0.5604
2023-02-06 14:29:03 | Valid | Epoch[303/600] Iteration[006/008] Valid loss: 0.5618
2023-02-06 14:29:03 | Valid | Epoch[303/600] Iteration[007/008] Valid loss: 0.6039
2023-02-06 14:29:03 | Valid | Epoch[303/600] Iteration[008/008] Valid loss: 0.6245
2023-02-06 14:29:03 | Valid | Epoch[303/600] MIou: 0.8865082288665476
2023-02-06 14:29:03 | Valid | Epoch[303/600] Pixel Accuracy: 0.977514902750651
2023-02-06 14:29:03 | Valid | Epoch[303/600] Mean Pixel Accuracy: 0.9793542353192656
2023-02-06 14:29:03 | Stage | Epoch[303/600] Train loss:0.0117
2023-02-06 14:29:03 | Stage | Epoch[303/600] Valid loss:0.6245
2023-02-06 14:29:03 | Stage | Epoch[303/600] LR:0.01

2023-02-06 14:29:04 | Train | Epoch[304/600] Iteration[001/030] Train loss: 0.0107
2023-02-06 14:29:04 | Train | Epoch[304/600] Iteration[002/030] Train loss: 0.0106
2023-02-06 14:29:04 | Train | Epoch[304/600] Iteration[003/030] Train loss: 0.0110
2023-02-06 14:29:05 | Train | Epoch[304/600] Iteration[004/030] Train loss: 0.0112
2023-02-06 14:29:05 | Train | Epoch[304/600] Iteration[005/030] Train loss: 0.0108
2023-02-06 14:29:05 | Train | Epoch[304/600] Iteration[006/030] Train loss: 0.0106
2023-02-06 14:29:05 | Train | Epoch[304/600] Iteration[007/030] Train loss: 0.0106
2023-02-06 14:29:05 | Train | Epoch[304/600] Iteration[008/030] Train loss: 0.0108
2023-02-06 14:29:06 | Train | Epoch[304/600] Iteration[009/030] Train loss: 0.0107
2023-02-06 14:29:06 | Train | Epoch[304/600] Iteration[010/030] Train loss: 0.0107
2023-02-06 14:29:06 | Train | Epoch[304/600] Iteration[011/030] Train loss: 0.0107
2023-02-06 14:29:06 | Train | Epoch[304/600] Iteration[012/030] Train loss: 0.0107
2023-02-06 14:29:07 | Train | Epoch[304/600] Iteration[013/030] Train loss: 0.0108
2023-02-06 14:29:07 | Train | Epoch[304/600] Iteration[014/030] Train loss: 0.0107
2023-02-06 14:29:07 | Train | Epoch[304/600] Iteration[015/030] Train loss: 0.0108
2023-02-06 14:29:07 | Train | Epoch[304/600] Iteration[016/030] Train loss: 0.0107
2023-02-06 14:29:07 | Train | Epoch[304/600] Iteration[017/030] Train loss: 0.0108
2023-02-06 14:29:08 | Train | Epoch[304/600] Iteration[018/030] Train loss: 0.0108
2023-02-06 14:29:08 | Train | Epoch[304/600] Iteration[019/030] Train loss: 0.0109
2023-02-06 14:29:08 | Train | Epoch[304/600] Iteration[020/030] Train loss: 0.0109
2023-02-06 14:29:08 | Train | Epoch[304/600] Iteration[021/030] Train loss: 0.0110
2023-02-06 14:29:09 | Train | Epoch[304/600] Iteration[022/030] Train loss: 0.0111
2023-02-06 14:29:09 | Train | Epoch[304/600] Iteration[023/030] Train loss: 0.0111
2023-02-06 14:29:09 | Train | Epoch[304/600] Iteration[024/030] Train loss: 0.0111
2023-02-06 14:29:09 | Train | Epoch[304/600] Iteration[025/030] Train loss: 0.0112
2023-02-06 14:29:09 | Train | Epoch[304/600] Iteration[026/030] Train loss: 0.0112
2023-02-06 14:29:10 | Train | Epoch[304/600] Iteration[027/030] Train loss: 0.0112
2023-02-06 14:29:10 | Train | Epoch[304/600] Iteration[028/030] Train loss: 0.0112
2023-02-06 14:29:10 | Train | Epoch[304/600] Iteration[029/030] Train loss: 0.0112
2023-02-06 14:29:10 | Train | Epoch[304/600] Iteration[030/030] Train loss: 0.0113
2023-02-06 14:29:11 | Valid | Epoch[304/600] Iteration[001/008] Valid loss: 0.4946
2023-02-06 14:29:11 | Valid | Epoch[304/600] Iteration[002/008] Valid loss: 0.4363
2023-02-06 14:29:11 | Valid | Epoch[304/600] Iteration[003/008] Valid loss: 0.4443
2023-02-06 14:29:11 | Valid | Epoch[304/600] Iteration[004/008] Valid loss: 0.4421
2023-02-06 14:29:11 | Valid | Epoch[304/600] Iteration[005/008] Valid loss: 0.4517
2023-02-06 14:29:11 | Valid | Epoch[304/600] Iteration[006/008] Valid loss: 0.4478
2023-02-06 14:29:11 | Valid | Epoch[304/600] Iteration[007/008] Valid loss: 0.4808
2023-02-06 14:29:11 | Valid | Epoch[304/600] Iteration[008/008] Valid loss: 0.5051
2023-02-06 14:29:11 | Valid | Epoch[304/600] MIou: 0.8970631997699121
2023-02-06 14:29:11 | Valid | Epoch[304/600] Pixel Accuracy: 0.9800593058268229
2023-02-06 14:29:11 | Valid | Epoch[304/600] Mean Pixel Accuracy: 0.9796431652514823
2023-02-06 14:29:11 | Stage | Epoch[304/600] Train loss:0.0113
2023-02-06 14:29:11 | Stage | Epoch[304/600] Valid loss:0.5051
2023-02-06 14:29:11 | Stage | Epoch[304/600] LR:0.01

2023-02-06 14:29:11 | Train | Epoch[305/600] Iteration[001/030] Train loss: 0.0115
2023-02-06 14:29:12 | Train | Epoch[305/600] Iteration[002/030] Train loss: 0.0117
2023-02-06 14:29:12 | Train | Epoch[305/600] Iteration[003/030] Train loss: 0.0114
2023-02-06 14:29:12 | Train | Epoch[305/600] Iteration[004/030] Train loss: 0.0112
2023-02-06 14:29:12 | Train | Epoch[305/600] Iteration[005/030] Train loss: 0.0112
2023-02-06 14:29:13 | Train | Epoch[305/600] Iteration[006/030] Train loss: 0.0110
2023-02-06 14:29:13 | Train | Epoch[305/600] Iteration[007/030] Train loss: 0.0111
2023-02-06 14:29:13 | Train | Epoch[305/600] Iteration[008/030] Train loss: 0.0113
2023-02-06 14:29:13 | Train | Epoch[305/600] Iteration[009/030] Train loss: 0.0113
2023-02-06 14:29:13 | Train | Epoch[305/600] Iteration[010/030] Train loss: 0.0111
2023-02-06 14:29:14 | Train | Epoch[305/600] Iteration[011/030] Train loss: 0.0110
2023-02-06 14:29:14 | Train | Epoch[305/600] Iteration[012/030] Train loss: 0.0109
2023-02-06 14:29:14 | Train | Epoch[305/600] Iteration[013/030] Train loss: 0.0111
2023-02-06 14:29:14 | Train | Epoch[305/600] Iteration[014/030] Train loss: 0.0111
2023-02-06 14:29:15 | Train | Epoch[305/600] Iteration[015/030] Train loss: 0.0111
2023-02-06 14:29:15 | Train | Epoch[305/600] Iteration[016/030] Train loss: 0.0111
2023-02-06 14:29:15 | Train | Epoch[305/600] Iteration[017/030] Train loss: 0.0111
2023-02-06 14:29:15 | Train | Epoch[305/600] Iteration[018/030] Train loss: 0.0110
2023-02-06 14:29:15 | Train | Epoch[305/600] Iteration[019/030] Train loss: 0.0110
2023-02-06 14:29:16 | Train | Epoch[305/600] Iteration[020/030] Train loss: 0.0112
2023-02-06 14:29:16 | Train | Epoch[305/600] Iteration[021/030] Train loss: 0.0114
2023-02-06 14:29:16 | Train | Epoch[305/600] Iteration[022/030] Train loss: 0.0116
2023-02-06 14:29:16 | Train | Epoch[305/600] Iteration[023/030] Train loss: 0.0115
2023-02-06 14:29:17 | Train | Epoch[305/600] Iteration[024/030] Train loss: 0.0115
2023-02-06 14:29:17 | Train | Epoch[305/600] Iteration[025/030] Train loss: 0.0115
2023-02-06 14:29:17 | Train | Epoch[305/600] Iteration[026/030] Train loss: 0.0115
2023-02-06 14:29:17 | Train | Epoch[305/600] Iteration[027/030] Train loss: 0.0115
2023-02-06 14:29:17 | Train | Epoch[305/600] Iteration[028/030] Train loss: 0.0115
2023-02-06 14:29:18 | Train | Epoch[305/600] Iteration[029/030] Train loss: 0.0115
2023-02-06 14:29:18 | Train | Epoch[305/600] Iteration[030/030] Train loss: 0.0114
2023-02-06 14:29:18 | Valid | Epoch[305/600] Iteration[001/008] Valid loss: 2.0275
2023-02-06 14:29:18 | Valid | Epoch[305/600] Iteration[002/008] Valid loss: 2.0074
2023-02-06 14:29:18 | Valid | Epoch[305/600] Iteration[003/008] Valid loss: 2.1547
2023-02-06 14:29:18 | Valid | Epoch[305/600] Iteration[004/008] Valid loss: 2.2033
2023-02-06 14:29:18 | Valid | Epoch[305/600] Iteration[005/008] Valid loss: 2.2804
2023-02-06 14:29:18 | Valid | Epoch[305/600] Iteration[006/008] Valid loss: 2.2606
2023-02-06 14:29:18 | Valid | Epoch[305/600] Iteration[007/008] Valid loss: 2.3509
2023-02-06 14:29:18 | Valid | Epoch[305/600] Iteration[008/008] Valid loss: 2.4573
2023-02-06 14:29:19 | Valid | Epoch[305/600] MIou: 0.7912135998371465
2023-02-06 14:29:19 | Valid | Epoch[305/600] Pixel Accuracy: 0.9489707946777344
2023-02-06 14:29:19 | Valid | Epoch[305/600] Mean Pixel Accuracy: 0.9710391445141737
2023-02-06 14:29:19 | Stage | Epoch[305/600] Train loss:0.0114
2023-02-06 14:29:19 | Stage | Epoch[305/600] Valid loss:2.4573
2023-02-06 14:29:19 | Stage | Epoch[305/600] LR:0.01

2023-02-06 14:29:19 | Train | Epoch[306/600] Iteration[001/030] Train loss: 0.0113
2023-02-06 14:29:19 | Train | Epoch[306/600] Iteration[002/030] Train loss: 0.0109
2023-02-06 14:29:19 | Train | Epoch[306/600] Iteration[003/030] Train loss: 0.0109
2023-02-06 14:29:20 | Train | Epoch[306/600] Iteration[004/030] Train loss: 0.0113
2023-02-06 14:29:20 | Train | Epoch[306/600] Iteration[005/030] Train loss: 0.0112
2023-02-06 14:29:20 | Train | Epoch[306/600] Iteration[006/030] Train loss: 0.0112
2023-02-06 14:29:20 | Train | Epoch[306/600] Iteration[007/030] Train loss: 0.0112
2023-02-06 14:29:21 | Train | Epoch[306/600] Iteration[008/030] Train loss: 0.0111
2023-02-06 14:29:21 | Train | Epoch[306/600] Iteration[009/030] Train loss: 0.0109
2023-02-06 14:29:21 | Train | Epoch[306/600] Iteration[010/030] Train loss: 0.0109
2023-02-06 14:29:21 | Train | Epoch[306/600] Iteration[011/030] Train loss: 0.0109
2023-02-06 14:29:21 | Train | Epoch[306/600] Iteration[012/030] Train loss: 0.0108
2023-02-06 14:29:22 | Train | Epoch[306/600] Iteration[013/030] Train loss: 0.0108
2023-02-06 14:29:22 | Train | Epoch[306/600] Iteration[014/030] Train loss: 0.0107
2023-02-06 14:29:22 | Train | Epoch[306/600] Iteration[015/030] Train loss: 0.0108
2023-02-06 14:29:22 | Train | Epoch[306/600] Iteration[016/030] Train loss: 0.0108
2023-02-06 14:29:23 | Train | Epoch[306/600] Iteration[017/030] Train loss: 0.0109
2023-02-06 14:29:23 | Train | Epoch[306/600] Iteration[018/030] Train loss: 0.0109
2023-02-06 14:29:23 | Train | Epoch[306/600] Iteration[019/030] Train loss: 0.0109
2023-02-06 14:29:23 | Train | Epoch[306/600] Iteration[020/030] Train loss: 0.0109
2023-02-06 14:29:23 | Train | Epoch[306/600] Iteration[021/030] Train loss: 0.0110
2023-02-06 14:29:24 | Train | Epoch[306/600] Iteration[022/030] Train loss: 0.0110
2023-02-06 14:29:24 | Train | Epoch[306/600] Iteration[023/030] Train loss: 0.0111
2023-02-06 14:29:24 | Train | Epoch[306/600] Iteration[024/030] Train loss: 0.0111
2023-02-06 14:29:24 | Train | Epoch[306/600] Iteration[025/030] Train loss: 0.0110
2023-02-06 14:29:25 | Train | Epoch[306/600] Iteration[026/030] Train loss: 0.0110
2023-02-06 14:29:25 | Train | Epoch[306/600] Iteration[027/030] Train loss: 0.0111
2023-02-06 14:29:25 | Train | Epoch[306/600] Iteration[028/030] Train loss: 0.0111
2023-02-06 14:29:25 | Train | Epoch[306/600] Iteration[029/030] Train loss: 0.0111
2023-02-06 14:29:25 | Train | Epoch[306/600] Iteration[030/030] Train loss: 0.0112
2023-02-06 14:29:26 | Valid | Epoch[306/600] Iteration[001/008] Valid loss: 0.1999
2023-02-06 14:29:26 | Valid | Epoch[306/600] Iteration[002/008] Valid loss: 0.1690
2023-02-06 14:29:26 | Valid | Epoch[306/600] Iteration[003/008] Valid loss: 0.1559
2023-02-06 14:29:26 | Valid | Epoch[306/600] Iteration[004/008] Valid loss: 0.1473
2023-02-06 14:29:26 | Valid | Epoch[306/600] Iteration[005/008] Valid loss: 0.1462
2023-02-06 14:29:26 | Valid | Epoch[306/600] Iteration[006/008] Valid loss: 0.1413
2023-02-06 14:29:26 | Valid | Epoch[306/600] Iteration[007/008] Valid loss: 0.1499
2023-02-06 14:29:26 | Valid | Epoch[306/600] Iteration[008/008] Valid loss: 0.1550
2023-02-06 14:29:26 | Valid | Epoch[306/600] MIou: 0.9205538888176557
2023-02-06 14:29:26 | Valid | Epoch[306/600] Pixel Accuracy: 0.9857393900553385
2023-02-06 14:29:26 | Valid | Epoch[306/600] Mean Pixel Accuracy: 0.9669076625414961
2023-02-06 14:29:26 | Stage | Epoch[306/600] Train loss:0.0112
2023-02-06 14:29:26 | Stage | Epoch[306/600] Valid loss:0.1550
2023-02-06 14:29:26 | Stage | Epoch[306/600] LR:0.01

2023-02-06 14:29:27 | Train | Epoch[307/600] Iteration[001/030] Train loss: 0.0090
2023-02-06 14:29:27 | Train | Epoch[307/600] Iteration[002/030] Train loss: 0.0101
2023-02-06 14:29:27 | Train | Epoch[307/600] Iteration[003/030] Train loss: 0.0101
2023-02-06 14:29:27 | Train | Epoch[307/600] Iteration[004/030] Train loss: 0.0102
2023-02-06 14:29:27 | Train | Epoch[307/600] Iteration[005/030] Train loss: 0.0103
2023-02-06 14:29:28 | Train | Epoch[307/600] Iteration[006/030] Train loss: 0.0104
2023-02-06 14:29:28 | Train | Epoch[307/600] Iteration[007/030] Train loss: 0.0106
2023-02-06 14:29:28 | Train | Epoch[307/600] Iteration[008/030] Train loss: 0.0106
2023-02-06 14:29:28 | Train | Epoch[307/600] Iteration[009/030] Train loss: 0.0105
2023-02-06 14:29:29 | Train | Epoch[307/600] Iteration[010/030] Train loss: 0.0105
2023-02-06 14:29:29 | Train | Epoch[307/600] Iteration[011/030] Train loss: 0.0107
2023-02-06 14:29:29 | Train | Epoch[307/600] Iteration[012/030] Train loss: 0.0106
2023-02-06 14:29:29 | Train | Epoch[307/600] Iteration[013/030] Train loss: 0.0106
2023-02-06 14:29:29 | Train | Epoch[307/600] Iteration[014/030] Train loss: 0.0106
2023-02-06 14:29:30 | Train | Epoch[307/600] Iteration[015/030] Train loss: 0.0106
2023-02-06 14:29:30 | Train | Epoch[307/600] Iteration[016/030] Train loss: 0.0105
2023-02-06 14:29:30 | Train | Epoch[307/600] Iteration[017/030] Train loss: 0.0106
2023-02-06 14:29:30 | Train | Epoch[307/600] Iteration[018/030] Train loss: 0.0105
2023-02-06 14:29:30 | Train | Epoch[307/600] Iteration[019/030] Train loss: 0.0105
2023-02-06 14:29:31 | Train | Epoch[307/600] Iteration[020/030] Train loss: 0.0105
2023-02-06 14:29:31 | Train | Epoch[307/600] Iteration[021/030] Train loss: 0.0105
2023-02-06 14:29:31 | Train | Epoch[307/600] Iteration[022/030] Train loss: 0.0105
2023-02-06 14:29:31 | Train | Epoch[307/600] Iteration[023/030] Train loss: 0.0104
2023-02-06 14:29:32 | Train | Epoch[307/600] Iteration[024/030] Train loss: 0.0105
2023-02-06 14:29:32 | Train | Epoch[307/600] Iteration[025/030] Train loss: 0.0105
2023-02-06 14:29:32 | Train | Epoch[307/600] Iteration[026/030] Train loss: 0.0106
2023-02-06 14:29:32 | Train | Epoch[307/600] Iteration[027/030] Train loss: 0.0106
2023-02-06 14:29:32 | Train | Epoch[307/600] Iteration[028/030] Train loss: 0.0106
2023-02-06 14:29:33 | Train | Epoch[307/600] Iteration[029/030] Train loss: 0.0106
2023-02-06 14:29:33 | Train | Epoch[307/600] Iteration[030/030] Train loss: 0.0107
2023-02-06 14:29:33 | Valid | Epoch[307/600] Iteration[001/008] Valid loss: 0.0876
2023-02-06 14:29:33 | Valid | Epoch[307/600] Iteration[002/008] Valid loss: 0.0666
2023-02-06 14:29:33 | Valid | Epoch[307/600] Iteration[003/008] Valid loss: 0.0622
2023-02-06 14:29:33 | Valid | Epoch[307/600] Iteration[004/008] Valid loss: 0.0601
2023-02-06 14:29:33 | Valid | Epoch[307/600] Iteration[005/008] Valid loss: 0.0588
2023-02-06 14:29:33 | Valid | Epoch[307/600] Iteration[006/008] Valid loss: 0.0564
2023-02-06 14:29:33 | Valid | Epoch[307/600] Iteration[007/008] Valid loss: 0.0557
2023-02-06 14:29:33 | Valid | Epoch[307/600] Iteration[008/008] Valid loss: 0.0541
2023-02-06 14:29:34 | Valid | Epoch[307/600] MIou: 0.9092493900737912
2023-02-06 14:29:34 | Valid | Epoch[307/600] Pixel Accuracy: 0.9848658243815104
2023-02-06 14:29:34 | Valid | Epoch[307/600] Mean Pixel Accuracy: 0.9229065171315695
2023-02-06 14:29:34 | Stage | Epoch[307/600] Train loss:0.0107
2023-02-06 14:29:34 | Stage | Epoch[307/600] Valid loss:0.0541
2023-02-06 14:29:34 | Stage | Epoch[307/600] LR:0.01

2023-02-06 14:29:34 | Train | Epoch[308/600] Iteration[001/030] Train loss: 0.0140
2023-02-06 14:29:34 | Train | Epoch[308/600] Iteration[002/030] Train loss: 0.0124
2023-02-06 14:29:34 | Train | Epoch[308/600] Iteration[003/030] Train loss: 0.0123
2023-02-06 14:29:35 | Train | Epoch[308/600] Iteration[004/030] Train loss: 0.0118
2023-02-06 14:29:35 | Train | Epoch[308/600] Iteration[005/030] Train loss: 0.0111
2023-02-06 14:29:35 | Train | Epoch[308/600] Iteration[006/030] Train loss: 0.0112
2023-02-06 14:29:35 | Train | Epoch[308/600] Iteration[007/030] Train loss: 0.0114
2023-02-06 14:29:36 | Train | Epoch[308/600] Iteration[008/030] Train loss: 0.0111
2023-02-06 14:29:36 | Train | Epoch[308/600] Iteration[009/030] Train loss: 0.0116
2023-02-06 14:29:36 | Train | Epoch[308/600] Iteration[010/030] Train loss: 0.0115
2023-02-06 14:29:36 | Train | Epoch[308/600] Iteration[011/030] Train loss: 0.0114
2023-02-06 14:29:36 | Train | Epoch[308/600] Iteration[012/030] Train loss: 0.0113
2023-02-06 14:29:37 | Train | Epoch[308/600] Iteration[013/030] Train loss: 0.0112
2023-02-06 14:29:37 | Train | Epoch[308/600] Iteration[014/030] Train loss: 0.0112
2023-02-06 14:29:37 | Train | Epoch[308/600] Iteration[015/030] Train loss: 0.0111
2023-02-06 14:29:37 | Train | Epoch[308/600] Iteration[016/030] Train loss: 0.0111
2023-02-06 14:29:38 | Train | Epoch[308/600] Iteration[017/030] Train loss: 0.0112
2023-02-06 14:29:38 | Train | Epoch[308/600] Iteration[018/030] Train loss: 0.0113
2023-02-06 14:29:38 | Train | Epoch[308/600] Iteration[019/030] Train loss: 0.0113
2023-02-06 14:29:38 | Train | Epoch[308/600] Iteration[020/030] Train loss: 0.0112
2023-02-06 14:29:38 | Train | Epoch[308/600] Iteration[021/030] Train loss: 0.0113
2023-02-06 14:29:39 | Train | Epoch[308/600] Iteration[022/030] Train loss: 0.0114
2023-02-06 14:29:39 | Train | Epoch[308/600] Iteration[023/030] Train loss: 0.0114
2023-02-06 14:29:39 | Train | Epoch[308/600] Iteration[024/030] Train loss: 0.0114
2023-02-06 14:29:39 | Train | Epoch[308/600] Iteration[025/030] Train loss: 0.0114
2023-02-06 14:29:40 | Train | Epoch[308/600] Iteration[026/030] Train loss: 0.0114
2023-02-06 14:29:40 | Train | Epoch[308/600] Iteration[027/030] Train loss: 0.0113
2023-02-06 14:29:40 | Train | Epoch[308/600] Iteration[028/030] Train loss: 0.0113
2023-02-06 14:29:40 | Train | Epoch[308/600] Iteration[029/030] Train loss: 0.0113
2023-02-06 14:29:40 | Train | Epoch[308/600] Iteration[030/030] Train loss: 0.0113
2023-02-06 14:29:41 | Valid | Epoch[308/600] Iteration[001/008] Valid loss: 0.5401
2023-02-06 14:29:41 | Valid | Epoch[308/600] Iteration[002/008] Valid loss: 0.4488
2023-02-06 14:29:41 | Valid | Epoch[308/600] Iteration[003/008] Valid loss: 0.4388
2023-02-06 14:29:41 | Valid | Epoch[308/600] Iteration[004/008] Valid loss: 0.4325
2023-02-06 14:29:41 | Valid | Epoch[308/600] Iteration[005/008] Valid loss: 0.4527
2023-02-06 14:29:41 | Valid | Epoch[308/600] Iteration[006/008] Valid loss: 0.4579
2023-02-06 14:29:41 | Valid | Epoch[308/600] Iteration[007/008] Valid loss: 0.4973
2023-02-06 14:29:41 | Valid | Epoch[308/600] Iteration[008/008] Valid loss: 0.5090
2023-02-06 14:29:41 | Valid | Epoch[308/600] MIou: 0.9002254205982462
2023-02-06 14:29:41 | Valid | Epoch[308/600] Pixel Accuracy: 0.9807319641113281
2023-02-06 14:29:41 | Valid | Epoch[308/600] Mean Pixel Accuracy: 0.9815092382096791
2023-02-06 14:29:41 | Stage | Epoch[308/600] Train loss:0.0113
2023-02-06 14:29:41 | Stage | Epoch[308/600] Valid loss:0.5090
2023-02-06 14:29:41 | Stage | Epoch[308/600] LR:0.01

2023-02-06 14:29:42 | Train | Epoch[309/600] Iteration[001/030] Train loss: 0.0098
2023-02-06 14:29:42 | Train | Epoch[309/600] Iteration[002/030] Train loss: 0.0100
2023-02-06 14:29:42 | Train | Epoch[309/600] Iteration[003/030] Train loss: 0.0097
2023-02-06 14:29:42 | Train | Epoch[309/600] Iteration[004/030] Train loss: 0.0099
2023-02-06 14:29:42 | Train | Epoch[309/600] Iteration[005/030] Train loss: 0.0100
2023-02-06 14:29:43 | Train | Epoch[309/600] Iteration[006/030] Train loss: 0.0103
2023-02-06 14:29:43 | Train | Epoch[309/600] Iteration[007/030] Train loss: 0.0105
2023-02-06 14:29:43 | Train | Epoch[309/600] Iteration[008/030] Train loss: 0.0105
2023-02-06 14:29:43 | Train | Epoch[309/600] Iteration[009/030] Train loss: 0.0105
2023-02-06 14:29:43 | Train | Epoch[309/600] Iteration[010/030] Train loss: 0.0104
2023-02-06 14:29:44 | Train | Epoch[309/600] Iteration[011/030] Train loss: 0.0107
2023-02-06 14:29:44 | Train | Epoch[309/600] Iteration[012/030] Train loss: 0.0106
2023-02-06 14:29:44 | Train | Epoch[309/600] Iteration[013/030] Train loss: 0.0106
2023-02-06 14:29:44 | Train | Epoch[309/600] Iteration[014/030] Train loss: 0.0107
2023-02-06 14:29:45 | Train | Epoch[309/600] Iteration[015/030] Train loss: 0.0107
2023-02-06 14:29:45 | Train | Epoch[309/600] Iteration[016/030] Train loss: 0.0108
2023-02-06 14:29:45 | Train | Epoch[309/600] Iteration[017/030] Train loss: 0.0108
2023-02-06 14:29:45 | Train | Epoch[309/600] Iteration[018/030] Train loss: 0.0109
2023-02-06 14:29:45 | Train | Epoch[309/600] Iteration[019/030] Train loss: 0.0108
2023-02-06 14:29:46 | Train | Epoch[309/600] Iteration[020/030] Train loss: 0.0109
2023-02-06 14:29:46 | Train | Epoch[309/600] Iteration[021/030] Train loss: 0.0110
2023-02-06 14:29:46 | Train | Epoch[309/600] Iteration[022/030] Train loss: 0.0110
2023-02-06 14:29:46 | Train | Epoch[309/600] Iteration[023/030] Train loss: 0.0110
2023-02-06 14:29:47 | Train | Epoch[309/600] Iteration[024/030] Train loss: 0.0110
2023-02-06 14:29:47 | Train | Epoch[309/600] Iteration[025/030] Train loss: 0.0110
2023-02-06 14:29:47 | Train | Epoch[309/600] Iteration[026/030] Train loss: 0.0109
2023-02-06 14:29:47 | Train | Epoch[309/600] Iteration[027/030] Train loss: 0.0111
2023-02-06 14:29:47 | Train | Epoch[309/600] Iteration[028/030] Train loss: 0.0111
2023-02-06 14:29:48 | Train | Epoch[309/600] Iteration[029/030] Train loss: 0.0110
2023-02-06 14:29:48 | Train | Epoch[309/600] Iteration[030/030] Train loss: 0.0110
2023-02-06 14:29:48 | Valid | Epoch[309/600] Iteration[001/008] Valid loss: 0.0900
2023-02-06 14:29:48 | Valid | Epoch[309/600] Iteration[002/008] Valid loss: 0.0737
2023-02-06 14:29:48 | Valid | Epoch[309/600] Iteration[003/008] Valid loss: 0.0721
2023-02-06 14:29:48 | Valid | Epoch[309/600] Iteration[004/008] Valid loss: 0.0688
2023-02-06 14:29:48 | Valid | Epoch[309/600] Iteration[005/008] Valid loss: 0.0687
2023-02-06 14:29:48 | Valid | Epoch[309/600] Iteration[006/008] Valid loss: 0.0659
2023-02-06 14:29:48 | Valid | Epoch[309/600] Iteration[007/008] Valid loss: 0.0658
2023-02-06 14:29:48 | Valid | Epoch[309/600] Iteration[008/008] Valid loss: 0.0646
2023-02-06 14:29:49 | Valid | Epoch[309/600] MIou: 0.8867360471558353
2023-02-06 14:29:49 | Valid | Epoch[309/600] Pixel Accuracy: 0.981133778889974
2023-02-06 14:29:49 | Valid | Epoch[309/600] Mean Pixel Accuracy: 0.9014597234060784
2023-02-06 14:29:49 | Stage | Epoch[309/600] Train loss:0.0110
2023-02-06 14:29:49 | Stage | Epoch[309/600] Valid loss:0.0646
2023-02-06 14:29:49 | Stage | Epoch[309/600] LR:0.01

2023-02-06 14:29:49 | Train | Epoch[310/600] Iteration[001/030] Train loss: 0.0109
2023-02-06 14:29:49 | Train | Epoch[310/600] Iteration[002/030] Train loss: 0.0113
2023-02-06 14:29:49 | Train | Epoch[310/600] Iteration[003/030] Train loss: 0.0109
2023-02-06 14:29:50 | Train | Epoch[310/600] Iteration[004/030] Train loss: 0.0115
2023-02-06 14:29:50 | Train | Epoch[310/600] Iteration[005/030] Train loss: 0.0110
2023-02-06 14:29:50 | Train | Epoch[310/600] Iteration[006/030] Train loss: 0.0108
2023-02-06 14:29:50 | Train | Epoch[310/600] Iteration[007/030] Train loss: 0.0109
2023-02-06 14:29:51 | Train | Epoch[310/600] Iteration[008/030] Train loss: 0.0110
2023-02-06 14:29:51 | Train | Epoch[310/600] Iteration[009/030] Train loss: 0.0109
2023-02-06 14:29:51 | Train | Epoch[310/600] Iteration[010/030] Train loss: 0.0108
2023-02-06 14:29:51 | Train | Epoch[310/600] Iteration[011/030] Train loss: 0.0109
2023-02-06 14:29:51 | Train | Epoch[310/600] Iteration[012/030] Train loss: 0.0107
2023-02-06 14:29:52 | Train | Epoch[310/600] Iteration[013/030] Train loss: 0.0107
2023-02-06 14:29:52 | Train | Epoch[310/600] Iteration[014/030] Train loss: 0.0107
2023-02-06 14:29:52 | Train | Epoch[310/600] Iteration[015/030] Train loss: 0.0107
2023-02-06 14:29:52 | Train | Epoch[310/600] Iteration[016/030] Train loss: 0.0107
2023-02-06 14:29:53 | Train | Epoch[310/600] Iteration[017/030] Train loss: 0.0108
2023-02-06 14:29:53 | Train | Epoch[310/600] Iteration[018/030] Train loss: 0.0107
2023-02-06 14:29:53 | Train | Epoch[310/600] Iteration[019/030] Train loss: 0.0107
2023-02-06 14:29:53 | Train | Epoch[310/600] Iteration[020/030] Train loss: 0.0106
2023-02-06 14:29:53 | Train | Epoch[310/600] Iteration[021/030] Train loss: 0.0106
2023-02-06 14:29:54 | Train | Epoch[310/600] Iteration[022/030] Train loss: 0.0106
2023-02-06 14:29:54 | Train | Epoch[310/600] Iteration[023/030] Train loss: 0.0106
2023-02-06 14:29:54 | Train | Epoch[310/600] Iteration[024/030] Train loss: 0.0106
2023-02-06 14:29:54 | Train | Epoch[310/600] Iteration[025/030] Train loss: 0.0106
2023-02-06 14:29:55 | Train | Epoch[310/600] Iteration[026/030] Train loss: 0.0106
2023-02-06 14:29:55 | Train | Epoch[310/600] Iteration[027/030] Train loss: 0.0106
2023-02-06 14:29:55 | Train | Epoch[310/600] Iteration[028/030] Train loss: 0.0106
2023-02-06 14:29:55 | Train | Epoch[310/600] Iteration[029/030] Train loss: 0.0106
2023-02-06 14:29:55 | Train | Epoch[310/600] Iteration[030/030] Train loss: 0.0107
2023-02-06 14:29:56 | Valid | Epoch[310/600] Iteration[001/008] Valid loss: 0.3147
2023-02-06 14:29:56 | Valid | Epoch[310/600] Iteration[002/008] Valid loss: 0.2518
2023-02-06 14:29:56 | Valid | Epoch[310/600] Iteration[003/008] Valid loss: 0.2510
2023-02-06 14:29:56 | Valid | Epoch[310/600] Iteration[004/008] Valid loss: 0.2441
2023-02-06 14:29:56 | Valid | Epoch[310/600] Iteration[005/008] Valid loss: 0.2519
2023-02-06 14:29:56 | Valid | Epoch[310/600] Iteration[006/008] Valid loss: 0.2449
2023-02-06 14:29:56 | Valid | Epoch[310/600] Iteration[007/008] Valid loss: 0.2600
2023-02-06 14:29:56 | Valid | Epoch[310/600] Iteration[008/008] Valid loss: 0.2643
2023-02-06 14:29:56 | Valid | Epoch[310/600] MIou: 0.9188486876885389
2023-02-06 14:29:56 | Valid | Epoch[310/600] Pixel Accuracy: 0.9851353963216146
2023-02-06 14:29:56 | Valid | Epoch[310/600] Mean Pixel Accuracy: 0.974945104221677
2023-02-06 14:29:56 | Stage | Epoch[310/600] Train loss:0.0107
2023-02-06 14:29:56 | Stage | Epoch[310/600] Valid loss:0.2643
2023-02-06 14:29:56 | Stage | Epoch[310/600] LR:0.01

2023-02-06 14:29:56 | Train | Epoch[311/600] Iteration[001/030] Train loss: 0.0102
2023-02-06 14:29:57 | Train | Epoch[311/600] Iteration[002/030] Train loss: 0.0103
2023-02-06 14:29:57 | Train | Epoch[311/600] Iteration[003/030] Train loss: 0.0109
2023-02-06 14:29:57 | Train | Epoch[311/600] Iteration[004/030] Train loss: 0.0107
2023-02-06 14:29:57 | Train | Epoch[311/600] Iteration[005/030] Train loss: 0.0104
2023-02-06 14:29:58 | Train | Epoch[311/600] Iteration[006/030] Train loss: 0.0102
2023-02-06 14:29:58 | Train | Epoch[311/600] Iteration[007/030] Train loss: 0.0100
2023-02-06 14:29:58 | Train | Epoch[311/600] Iteration[008/030] Train loss: 0.0101
2023-02-06 14:29:58 | Train | Epoch[311/600] Iteration[009/030] Train loss: 0.0100
2023-02-06 14:29:58 | Train | Epoch[311/600] Iteration[010/030] Train loss: 0.0101
2023-02-06 14:29:59 | Train | Epoch[311/600] Iteration[011/030] Train loss: 0.0103
2023-02-06 14:29:59 | Train | Epoch[311/600] Iteration[012/030] Train loss: 0.0102
2023-02-06 14:29:59 | Train | Epoch[311/600] Iteration[013/030] Train loss: 0.0104
2023-02-06 14:29:59 | Train | Epoch[311/600] Iteration[014/030] Train loss: 0.0103
2023-02-06 14:30:00 | Train | Epoch[311/600] Iteration[015/030] Train loss: 0.0102
2023-02-06 14:30:00 | Train | Epoch[311/600] Iteration[016/030] Train loss: 0.0103
2023-02-06 14:30:00 | Train | Epoch[311/600] Iteration[017/030] Train loss: 0.0103
2023-02-06 14:30:00 | Train | Epoch[311/600] Iteration[018/030] Train loss: 0.0104
2023-02-06 14:30:00 | Train | Epoch[311/600] Iteration[019/030] Train loss: 0.0104
2023-02-06 14:30:01 | Train | Epoch[311/600] Iteration[020/030] Train loss: 0.0104
2023-02-06 14:30:01 | Train | Epoch[311/600] Iteration[021/030] Train loss: 0.0103
2023-02-06 14:30:01 | Train | Epoch[311/600] Iteration[022/030] Train loss: 0.0103
2023-02-06 14:30:01 | Train | Epoch[311/600] Iteration[023/030] Train loss: 0.0103
2023-02-06 14:30:01 | Train | Epoch[311/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:30:02 | Train | Epoch[311/600] Iteration[025/030] Train loss: 0.0103
2023-02-06 14:30:02 | Train | Epoch[311/600] Iteration[026/030] Train loss: 0.0103
2023-02-06 14:30:02 | Train | Epoch[311/600] Iteration[027/030] Train loss: 0.0103
2023-02-06 14:30:02 | Train | Epoch[311/600] Iteration[028/030] Train loss: 0.0103
2023-02-06 14:30:03 | Train | Epoch[311/600] Iteration[029/030] Train loss: 0.0103
2023-02-06 14:30:03 | Train | Epoch[311/600] Iteration[030/030] Train loss: 0.0103
2023-02-06 14:30:03 | Valid | Epoch[311/600] Iteration[001/008] Valid loss: 0.0848
2023-02-06 14:30:03 | Valid | Epoch[311/600] Iteration[002/008] Valid loss: 0.0691
2023-02-06 14:30:03 | Valid | Epoch[311/600] Iteration[003/008] Valid loss: 0.0666
2023-02-06 14:30:03 | Valid | Epoch[311/600] Iteration[004/008] Valid loss: 0.0626
2023-02-06 14:30:03 | Valid | Epoch[311/600] Iteration[005/008] Valid loss: 0.0610
2023-02-06 14:30:03 | Valid | Epoch[311/600] Iteration[006/008] Valid loss: 0.0597
2023-02-06 14:30:03 | Valid | Epoch[311/600] Iteration[007/008] Valid loss: 0.0601
2023-02-06 14:30:03 | Valid | Epoch[311/600] Iteration[008/008] Valid loss: 0.0590
2023-02-06 14:30:03 | Valid | Epoch[311/600] MIou: 0.894475119283673
2023-02-06 14:30:03 | Valid | Epoch[311/600] Pixel Accuracy: 0.9824028015136719
2023-02-06 14:30:03 | Valid | Epoch[311/600] Mean Pixel Accuracy: 0.9091254105543443
2023-02-06 14:30:03 | Stage | Epoch[311/600] Train loss:0.0103
2023-02-06 14:30:03 | Stage | Epoch[311/600] Valid loss:0.0590
2023-02-06 14:30:03 | Stage | Epoch[311/600] LR:0.01

2023-02-06 14:30:04 | Train | Epoch[312/600] Iteration[001/030] Train loss: 0.0099
2023-02-06 14:30:04 | Train | Epoch[312/600] Iteration[002/030] Train loss: 0.0122
2023-02-06 14:30:04 | Train | Epoch[312/600] Iteration[003/030] Train loss: 0.0112
2023-02-06 14:30:05 | Train | Epoch[312/600] Iteration[004/030] Train loss: 0.0108
2023-02-06 14:30:05 | Train | Epoch[312/600] Iteration[005/030] Train loss: 0.0108
2023-02-06 14:30:05 | Train | Epoch[312/600] Iteration[006/030] Train loss: 0.0105
2023-02-06 14:30:05 | Train | Epoch[312/600] Iteration[007/030] Train loss: 0.0104
2023-02-06 14:30:05 | Train | Epoch[312/600] Iteration[008/030] Train loss: 0.0103
2023-02-06 14:30:06 | Train | Epoch[312/600] Iteration[009/030] Train loss: 0.0104
2023-02-06 14:30:06 | Train | Epoch[312/600] Iteration[010/030] Train loss: 0.0102
2023-02-06 14:30:06 | Train | Epoch[312/600] Iteration[011/030] Train loss: 0.0104
2023-02-06 14:30:06 | Train | Epoch[312/600] Iteration[012/030] Train loss: 0.0106
2023-02-06 14:30:07 | Train | Epoch[312/600] Iteration[013/030] Train loss: 0.0106
2023-02-06 14:30:07 | Train | Epoch[312/600] Iteration[014/030] Train loss: 0.0105
2023-02-06 14:30:07 | Train | Epoch[312/600] Iteration[015/030] Train loss: 0.0104
2023-02-06 14:30:07 | Train | Epoch[312/600] Iteration[016/030] Train loss: 0.0104
2023-02-06 14:30:07 | Train | Epoch[312/600] Iteration[017/030] Train loss: 0.0103
2023-02-06 14:30:08 | Train | Epoch[312/600] Iteration[018/030] Train loss: 0.0104
2023-02-06 14:30:08 | Train | Epoch[312/600] Iteration[019/030] Train loss: 0.0104
2023-02-06 14:30:08 | Train | Epoch[312/600] Iteration[020/030] Train loss: 0.0104
2023-02-06 14:30:08 | Train | Epoch[312/600] Iteration[021/030] Train loss: 0.0104
2023-02-06 14:30:09 | Train | Epoch[312/600] Iteration[022/030] Train loss: 0.0104
2023-02-06 14:30:09 | Train | Epoch[312/600] Iteration[023/030] Train loss: 0.0104
2023-02-06 14:30:09 | Train | Epoch[312/600] Iteration[024/030] Train loss: 0.0104
2023-02-06 14:30:09 | Train | Epoch[312/600] Iteration[025/030] Train loss: 0.0104
2023-02-06 14:30:09 | Train | Epoch[312/600] Iteration[026/030] Train loss: 0.0104
2023-02-06 14:30:10 | Train | Epoch[312/600] Iteration[027/030] Train loss: 0.0104
2023-02-06 14:30:10 | Train | Epoch[312/600] Iteration[028/030] Train loss: 0.0104
2023-02-06 14:30:10 | Train | Epoch[312/600] Iteration[029/030] Train loss: 0.0103
2023-02-06 14:30:10 | Train | Epoch[312/600] Iteration[030/030] Train loss: 0.0103
2023-02-06 14:30:11 | Valid | Epoch[312/600] Iteration[001/008] Valid loss: 0.5320
2023-02-06 14:30:11 | Valid | Epoch[312/600] Iteration[002/008] Valid loss: 0.4567
2023-02-06 14:30:11 | Valid | Epoch[312/600] Iteration[003/008] Valid loss: 0.4602
2023-02-06 14:30:11 | Valid | Epoch[312/600] Iteration[004/008] Valid loss: 0.4589
2023-02-06 14:30:11 | Valid | Epoch[312/600] Iteration[005/008] Valid loss: 0.4695
2023-02-06 14:30:11 | Valid | Epoch[312/600] Iteration[006/008] Valid loss: 0.4747
2023-02-06 14:30:11 | Valid | Epoch[312/600] Iteration[007/008] Valid loss: 0.5081
2023-02-06 14:30:11 | Valid | Epoch[312/600] Iteration[008/008] Valid loss: 0.5210
2023-02-06 14:30:11 | Valid | Epoch[312/600] MIou: 0.9021582830645135
2023-02-06 14:30:11 | Valid | Epoch[312/600] Pixel Accuracy: 0.981207529703776
2023-02-06 14:30:11 | Valid | Epoch[312/600] Mean Pixel Accuracy: 0.9808702823869552
2023-02-06 14:30:11 | Stage | Epoch[312/600] Train loss:0.0103
2023-02-06 14:30:11 | Stage | Epoch[312/600] Valid loss:0.5210
2023-02-06 14:30:11 | Stage | Epoch[312/600] LR:0.01

2023-02-06 14:30:12 | Train | Epoch[313/600] Iteration[001/030] Train loss: 0.0093
2023-02-06 14:30:12 | Train | Epoch[313/600] Iteration[002/030] Train loss: 0.0098
2023-02-06 14:30:12 | Train | Epoch[313/600] Iteration[003/030] Train loss: 0.0103
2023-02-06 14:30:12 | Train | Epoch[313/600] Iteration[004/030] Train loss: 0.0101
2023-02-06 14:30:12 | Train | Epoch[313/600] Iteration[005/030] Train loss: 0.0100
2023-02-06 14:30:13 | Train | Epoch[313/600] Iteration[006/030] Train loss: 0.0099
2023-02-06 14:30:13 | Train | Epoch[313/600] Iteration[007/030] Train loss: 0.0098
2023-02-06 14:30:13 | Train | Epoch[313/600] Iteration[008/030] Train loss: 0.0104
2023-02-06 14:30:13 | Train | Epoch[313/600] Iteration[009/030] Train loss: 0.0105
2023-02-06 14:30:13 | Train | Epoch[313/600] Iteration[010/030] Train loss: 0.0104
2023-02-06 14:30:14 | Train | Epoch[313/600] Iteration[011/030] Train loss: 0.0105
2023-02-06 14:30:14 | Train | Epoch[313/600] Iteration[012/030] Train loss: 0.0104
2023-02-06 14:30:14 | Train | Epoch[313/600] Iteration[013/030] Train loss: 0.0104
2023-02-06 14:30:14 | Train | Epoch[313/600] Iteration[014/030] Train loss: 0.0103
2023-02-06 14:30:15 | Train | Epoch[313/600] Iteration[015/030] Train loss: 0.0103
2023-02-06 14:30:15 | Train | Epoch[313/600] Iteration[016/030] Train loss: 0.0103
2023-02-06 14:30:15 | Train | Epoch[313/600] Iteration[017/030] Train loss: 0.0104
2023-02-06 14:30:15 | Train | Epoch[313/600] Iteration[018/030] Train loss: 0.0104
2023-02-06 14:30:15 | Train | Epoch[313/600] Iteration[019/030] Train loss: 0.0105
2023-02-06 14:30:16 | Train | Epoch[313/600] Iteration[020/030] Train loss: 0.0105
2023-02-06 14:30:16 | Train | Epoch[313/600] Iteration[021/030] Train loss: 0.0104
2023-02-06 14:30:16 | Train | Epoch[313/600] Iteration[022/030] Train loss: 0.0106
2023-02-06 14:30:16 | Train | Epoch[313/600] Iteration[023/030] Train loss: 0.0106
2023-02-06 14:30:17 | Train | Epoch[313/600] Iteration[024/030] Train loss: 0.0107
2023-02-06 14:30:17 | Train | Epoch[313/600] Iteration[025/030] Train loss: 0.0107
2023-02-06 14:30:17 | Train | Epoch[313/600] Iteration[026/030] Train loss: 0.0108
2023-02-06 14:30:17 | Train | Epoch[313/600] Iteration[027/030] Train loss: 0.0108
2023-02-06 14:30:17 | Train | Epoch[313/600] Iteration[028/030] Train loss: 0.0108
2023-02-06 14:30:18 | Train | Epoch[313/600] Iteration[029/030] Train loss: 0.0108
2023-02-06 14:30:18 | Train | Epoch[313/600] Iteration[030/030] Train loss: 0.0109
2023-02-06 14:30:18 | Valid | Epoch[313/600] Iteration[001/008] Valid loss: 1.0946
2023-02-06 14:30:18 | Valid | Epoch[313/600] Iteration[002/008] Valid loss: 1.0731
2023-02-06 14:30:18 | Valid | Epoch[313/600] Iteration[003/008] Valid loss: 1.0814
2023-02-06 14:30:18 | Valid | Epoch[313/600] Iteration[004/008] Valid loss: 1.0802
2023-02-06 14:30:18 | Valid | Epoch[313/600] Iteration[005/008] Valid loss: 1.1329
2023-02-06 14:30:18 | Valid | Epoch[313/600] Iteration[006/008] Valid loss: 1.1130
2023-02-06 14:30:18 | Valid | Epoch[313/600] Iteration[007/008] Valid loss: 1.1779
2023-02-06 14:30:18 | Valid | Epoch[313/600] Iteration[008/008] Valid loss: 1.2117
2023-02-06 14:30:19 | Valid | Epoch[313/600] MIou: 0.8561342046909373
2023-02-06 14:30:19 | Valid | Epoch[313/600] Pixel Accuracy: 0.9693984985351562
2023-02-06 14:30:19 | Valid | Epoch[313/600] Mean Pixel Accuracy: 0.9807200067257633
2023-02-06 14:30:19 | Stage | Epoch[313/600] Train loss:0.0109
2023-02-06 14:30:19 | Stage | Epoch[313/600] Valid loss:1.2117
2023-02-06 14:30:19 | Stage | Epoch[313/600] LR:0.01

2023-02-06 14:30:19 | Train | Epoch[314/600] Iteration[001/030] Train loss: 0.0102
2023-02-06 14:30:19 | Train | Epoch[314/600] Iteration[002/030] Train loss: 0.0104
2023-02-06 14:30:19 | Train | Epoch[314/600] Iteration[003/030] Train loss: 0.0103
2023-02-06 14:30:20 | Train | Epoch[314/600] Iteration[004/030] Train loss: 0.0107
2023-02-06 14:30:20 | Train | Epoch[314/600] Iteration[005/030] Train loss: 0.0107
2023-02-06 14:30:20 | Train | Epoch[314/600] Iteration[006/030] Train loss: 0.0107
2023-02-06 14:30:20 | Train | Epoch[314/600] Iteration[007/030] Train loss: 0.0108
2023-02-06 14:30:21 | Train | Epoch[314/600] Iteration[008/030] Train loss: 0.0109
2023-02-06 14:30:21 | Train | Epoch[314/600] Iteration[009/030] Train loss: 0.0110
2023-02-06 14:30:21 | Train | Epoch[314/600] Iteration[010/030] Train loss: 0.0109
2023-02-06 14:30:21 | Train | Epoch[314/600] Iteration[011/030] Train loss: 0.0110
2023-02-06 14:30:21 | Train | Epoch[314/600] Iteration[012/030] Train loss: 0.0111
2023-02-06 14:30:22 | Train | Epoch[314/600] Iteration[013/030] Train loss: 0.0110
2023-02-06 14:30:22 | Train | Epoch[314/600] Iteration[014/030] Train loss: 0.0111
2023-02-06 14:30:22 | Train | Epoch[314/600] Iteration[015/030] Train loss: 0.0112
2023-02-06 14:30:22 | Train | Epoch[314/600] Iteration[016/030] Train loss: 0.0112
2023-02-06 14:30:23 | Train | Epoch[314/600] Iteration[017/030] Train loss: 0.0112
2023-02-06 14:30:23 | Train | Epoch[314/600] Iteration[018/030] Train loss: 0.0112
2023-02-06 14:30:23 | Train | Epoch[314/600] Iteration[019/030] Train loss: 0.0112
2023-02-06 14:30:23 | Train | Epoch[314/600] Iteration[020/030] Train loss: 0.0113
2023-02-06 14:30:23 | Train | Epoch[314/600] Iteration[021/030] Train loss: 0.0112
2023-02-06 14:30:24 | Train | Epoch[314/600] Iteration[022/030] Train loss: 0.0114
2023-02-06 14:30:24 | Train | Epoch[314/600] Iteration[023/030] Train loss: 0.0113
2023-02-06 14:30:24 | Train | Epoch[314/600] Iteration[024/030] Train loss: 0.0113
2023-02-06 14:30:24 | Train | Epoch[314/600] Iteration[025/030] Train loss: 0.0113
2023-02-06 14:30:25 | Train | Epoch[314/600] Iteration[026/030] Train loss: 0.0113
2023-02-06 14:30:25 | Train | Epoch[314/600] Iteration[027/030] Train loss: 0.0113
2023-02-06 14:30:25 | Train | Epoch[314/600] Iteration[028/030] Train loss: 0.0113
2023-02-06 14:30:25 | Train | Epoch[314/600] Iteration[029/030] Train loss: 0.0113
2023-02-06 14:30:25 | Train | Epoch[314/600] Iteration[030/030] Train loss: 0.0112
2023-02-06 14:30:26 | Valid | Epoch[314/600] Iteration[001/008] Valid loss: 0.1150
2023-02-06 14:30:26 | Valid | Epoch[314/600] Iteration[002/008] Valid loss: 0.0991
2023-02-06 14:30:26 | Valid | Epoch[314/600] Iteration[003/008] Valid loss: 0.0948
2023-02-06 14:30:26 | Valid | Epoch[314/600] Iteration[004/008] Valid loss: 0.0939
2023-02-06 14:30:26 | Valid | Epoch[314/600] Iteration[005/008] Valid loss: 0.0917
2023-02-06 14:30:26 | Valid | Epoch[314/600] Iteration[006/008] Valid loss: 0.0891
2023-02-06 14:30:26 | Valid | Epoch[314/600] Iteration[007/008] Valid loss: 0.0901
2023-02-06 14:30:26 | Valid | Epoch[314/600] Iteration[008/008] Valid loss: 0.0882
2023-02-06 14:30:26 | Valid | Epoch[314/600] MIou: 0.87261337983843
2023-02-06 14:30:26 | Valid | Epoch[314/600] Pixel Accuracy: 0.9784456888834635
2023-02-06 14:30:26 | Valid | Epoch[314/600] Mean Pixel Accuracy: 0.8944660242787248
2023-02-06 14:30:26 | Stage | Epoch[314/600] Train loss:0.0112
2023-02-06 14:30:26 | Stage | Epoch[314/600] Valid loss:0.0882
2023-02-06 14:30:26 | Stage | Epoch[314/600] LR:0.01

2023-02-06 14:30:27 | Train | Epoch[315/600] Iteration[001/030] Train loss: 0.0114
2023-02-06 14:30:27 | Train | Epoch[315/600] Iteration[002/030] Train loss: 0.0123
2023-02-06 14:30:27 | Train | Epoch[315/600] Iteration[003/030] Train loss: 0.0113
2023-02-06 14:30:27 | Train | Epoch[315/600] Iteration[004/030] Train loss: 0.0112
2023-02-06 14:30:27 | Train | Epoch[315/600] Iteration[005/030] Train loss: 0.0112
2023-02-06 14:30:28 | Train | Epoch[315/600] Iteration[006/030] Train loss: 0.0111
2023-02-06 14:30:28 | Train | Epoch[315/600] Iteration[007/030] Train loss: 0.0108
2023-02-06 14:30:28 | Train | Epoch[315/600] Iteration[008/030] Train loss: 0.0109
2023-02-06 14:30:28 | Train | Epoch[315/600] Iteration[009/030] Train loss: 0.0108
2023-02-06 14:30:29 | Train | Epoch[315/600] Iteration[010/030] Train loss: 0.0107
2023-02-06 14:30:29 | Train | Epoch[315/600] Iteration[011/030] Train loss: 0.0107
2023-02-06 14:30:29 | Train | Epoch[315/600] Iteration[012/030] Train loss: 0.0108
2023-02-06 14:30:29 | Train | Epoch[315/600] Iteration[013/030] Train loss: 0.0107
2023-02-06 14:30:29 | Train | Epoch[315/600] Iteration[014/030] Train loss: 0.0107
2023-02-06 14:30:30 | Train | Epoch[315/600] Iteration[015/030] Train loss: 0.0106
2023-02-06 14:30:30 | Train | Epoch[315/600] Iteration[016/030] Train loss: 0.0106
2023-02-06 14:30:30 | Train | Epoch[315/600] Iteration[017/030] Train loss: 0.0110
2023-02-06 14:30:30 | Train | Epoch[315/600] Iteration[018/030] Train loss: 0.0110
2023-02-06 14:30:30 | Train | Epoch[315/600] Iteration[019/030] Train loss: 0.0110
2023-02-06 14:30:31 | Train | Epoch[315/600] Iteration[020/030] Train loss: 0.0111
2023-02-06 14:30:31 | Train | Epoch[315/600] Iteration[021/030] Train loss: 0.0111
2023-02-06 14:30:31 | Train | Epoch[315/600] Iteration[022/030] Train loss: 0.0112
2023-02-06 14:30:31 | Train | Epoch[315/600] Iteration[023/030] Train loss: 0.0113
2023-02-06 14:30:32 | Train | Epoch[315/600] Iteration[024/030] Train loss: 0.0112
2023-02-06 14:30:32 | Train | Epoch[315/600] Iteration[025/030] Train loss: 0.0112
2023-02-06 14:30:32 | Train | Epoch[315/600] Iteration[026/030] Train loss: 0.0113
2023-02-06 14:30:32 | Train | Epoch[315/600] Iteration[027/030] Train loss: 0.0112
2023-02-06 14:30:32 | Train | Epoch[315/600] Iteration[028/030] Train loss: 0.0112
2023-02-06 14:30:33 | Train | Epoch[315/600] Iteration[029/030] Train loss: 0.0112
2023-02-06 14:30:33 | Train | Epoch[315/600] Iteration[030/030] Train loss: 0.0112
2023-02-06 14:30:33 | Valid | Epoch[315/600] Iteration[001/008] Valid loss: 0.7977
2023-02-06 14:30:33 | Valid | Epoch[315/600] Iteration[002/008] Valid loss: 0.7428
2023-02-06 14:30:33 | Valid | Epoch[315/600] Iteration[003/008] Valid loss: 0.7843
2023-02-06 14:30:33 | Valid | Epoch[315/600] Iteration[004/008] Valid loss: 0.7768
2023-02-06 14:30:33 | Valid | Epoch[315/600] Iteration[005/008] Valid loss: 0.8085
2023-02-06 14:30:33 | Valid | Epoch[315/600] Iteration[006/008] Valid loss: 0.8013
2023-02-06 14:30:33 | Valid | Epoch[315/600] Iteration[007/008] Valid loss: 0.8492
2023-02-06 14:30:33 | Valid | Epoch[315/600] Iteration[008/008] Valid loss: 0.8894
2023-02-06 14:30:34 | Valid | Epoch[315/600] MIou: 0.8749540114861615
2023-02-06 14:30:34 | Valid | Epoch[315/600] Pixel Accuracy: 0.9745407104492188
2023-02-06 14:30:34 | Valid | Epoch[315/600] Mean Pixel Accuracy: 0.9801795953308516
2023-02-06 14:30:34 | Stage | Epoch[315/600] Train loss:0.0112
2023-02-06 14:30:34 | Stage | Epoch[315/600] Valid loss:0.8894
2023-02-06 14:30:34 | Stage | Epoch[315/600] LR:0.01

2023-02-06 14:30:34 | Train | Epoch[316/600] Iteration[001/030] Train loss: 0.0115
2023-02-06 14:30:34 | Train | Epoch[316/600] Iteration[002/030] Train loss: 0.0110
2023-02-06 14:30:34 | Train | Epoch[316/600] Iteration[003/030] Train loss: 0.0109
2023-02-06 14:30:35 | Train | Epoch[316/600] Iteration[004/030] Train loss: 0.0106
2023-02-06 14:30:35 | Train | Epoch[316/600] Iteration[005/030] Train loss: 0.0103
2023-02-06 14:30:35 | Train | Epoch[316/600] Iteration[006/030] Train loss: 0.0103
2023-02-06 14:30:35 | Train | Epoch[316/600] Iteration[007/030] Train loss: 0.0103
2023-02-06 14:30:36 | Train | Epoch[316/600] Iteration[008/030] Train loss: 0.0103
2023-02-06 14:30:36 | Train | Epoch[316/600] Iteration[009/030] Train loss: 0.0104
2023-02-06 14:30:36 | Train | Epoch[316/600] Iteration[010/030] Train loss: 0.0106
2023-02-06 14:30:36 | Train | Epoch[316/600] Iteration[011/030] Train loss: 0.0106
2023-02-06 14:30:36 | Train | Epoch[316/600] Iteration[012/030] Train loss: 0.0106
2023-02-06 14:30:37 | Train | Epoch[316/600] Iteration[013/030] Train loss: 0.0108
2023-02-06 14:30:37 | Train | Epoch[316/600] Iteration[014/030] Train loss: 0.0110
2023-02-06 14:30:37 | Train | Epoch[316/600] Iteration[015/030] Train loss: 0.0108
2023-02-06 14:30:37 | Train | Epoch[316/600] Iteration[016/030] Train loss: 0.0108
2023-02-06 14:30:37 | Train | Epoch[316/600] Iteration[017/030] Train loss: 0.0109
2023-02-06 14:30:38 | Train | Epoch[316/600] Iteration[018/030] Train loss: 0.0108
2023-02-06 14:30:38 | Train | Epoch[316/600] Iteration[019/030] Train loss: 0.0108
2023-02-06 14:30:38 | Train | Epoch[316/600] Iteration[020/030] Train loss: 0.0109
2023-02-06 14:30:38 | Train | Epoch[316/600] Iteration[021/030] Train loss: 0.0109
2023-02-06 14:30:39 | Train | Epoch[316/600] Iteration[022/030] Train loss: 0.0109
2023-02-06 14:30:39 | Train | Epoch[316/600] Iteration[023/030] Train loss: 0.0109
2023-02-06 14:30:39 | Train | Epoch[316/600] Iteration[024/030] Train loss: 0.0109
2023-02-06 14:30:39 | Train | Epoch[316/600] Iteration[025/030] Train loss: 0.0109
2023-02-06 14:30:39 | Train | Epoch[316/600] Iteration[026/030] Train loss: 0.0109
2023-02-06 14:30:40 | Train | Epoch[316/600] Iteration[027/030] Train loss: 0.0109
2023-02-06 14:30:40 | Train | Epoch[316/600] Iteration[028/030] Train loss: 0.0109
2023-02-06 14:30:40 | Train | Epoch[316/600] Iteration[029/030] Train loss: 0.0109
2023-02-06 14:30:40 | Train | Epoch[316/600] Iteration[030/030] Train loss: 0.0109
2023-02-06 14:30:41 | Valid | Epoch[316/600] Iteration[001/008] Valid loss: 0.1965
2023-02-06 14:30:41 | Valid | Epoch[316/600] Iteration[002/008] Valid loss: 0.1643
2023-02-06 14:30:41 | Valid | Epoch[316/600] Iteration[003/008] Valid loss: 0.1539
2023-02-06 14:30:41 | Valid | Epoch[316/600] Iteration[004/008] Valid loss: 0.1492
2023-02-06 14:30:41 | Valid | Epoch[316/600] Iteration[005/008] Valid loss: 0.1486
2023-02-06 14:30:41 | Valid | Epoch[316/600] Iteration[006/008] Valid loss: 0.1479
2023-02-06 14:30:41 | Valid | Epoch[316/600] Iteration[007/008] Valid loss: 0.1630
2023-02-06 14:30:41 | Valid | Epoch[316/600] Iteration[008/008] Valid loss: 0.1594
2023-02-06 14:30:41 | Valid | Epoch[316/600] MIou: 0.9275320129255099
2023-02-06 14:30:41 | Valid | Epoch[316/600] Pixel Accuracy: 0.9872868855794271
2023-02-06 14:30:41 | Valid | Epoch[316/600] Mean Pixel Accuracy: 0.9629775165605148
2023-02-06 14:30:41 | Stage | Epoch[316/600] Train loss:0.0109
2023-02-06 14:30:41 | Stage | Epoch[316/600] Valid loss:0.1594
2023-02-06 14:30:41 | Stage | Epoch[316/600] LR:0.01

2023-02-06 14:30:41 | Train | Epoch[317/600] Iteration[001/030] Train loss: 0.0118
2023-02-06 14:30:42 | Train | Epoch[317/600] Iteration[002/030] Train loss: 0.0113
2023-02-06 14:30:42 | Train | Epoch[317/600] Iteration[003/030] Train loss: 0.0114
2023-02-06 14:30:42 | Train | Epoch[317/600] Iteration[004/030] Train loss: 0.0114
2023-02-06 14:30:42 | Train | Epoch[317/600] Iteration[005/030] Train loss: 0.0112
2023-02-06 14:30:43 | Train | Epoch[317/600] Iteration[006/030] Train loss: 0.0114
2023-02-06 14:30:43 | Train | Epoch[317/600] Iteration[007/030] Train loss: 0.0113
2023-02-06 14:30:43 | Train | Epoch[317/600] Iteration[008/030] Train loss: 0.0114
2023-02-06 14:30:43 | Train | Epoch[317/600] Iteration[009/030] Train loss: 0.0114
2023-02-06 14:30:43 | Train | Epoch[317/600] Iteration[010/030] Train loss: 0.0114
2023-02-06 14:30:44 | Train | Epoch[317/600] Iteration[011/030] Train loss: 0.0112
2023-02-06 14:30:44 | Train | Epoch[317/600] Iteration[012/030] Train loss: 0.0112
2023-02-06 14:30:44 | Train | Epoch[317/600] Iteration[013/030] Train loss: 0.0111
2023-02-06 14:30:44 | Train | Epoch[317/600] Iteration[014/030] Train loss: 0.0111
2023-02-06 14:30:45 | Train | Epoch[317/600] Iteration[015/030] Train loss: 0.0112
2023-02-06 14:30:45 | Train | Epoch[317/600] Iteration[016/030] Train loss: 0.0112
2023-02-06 14:30:45 | Train | Epoch[317/600] Iteration[017/030] Train loss: 0.0112
2023-02-06 14:30:45 | Train | Epoch[317/600] Iteration[018/030] Train loss: 0.0113
2023-02-06 14:30:45 | Train | Epoch[317/600] Iteration[019/030] Train loss: 0.0113
2023-02-06 14:30:46 | Train | Epoch[317/600] Iteration[020/030] Train loss: 0.0112
2023-02-06 14:30:46 | Train | Epoch[317/600] Iteration[021/030] Train loss: 0.0112
2023-02-06 14:30:46 | Train | Epoch[317/600] Iteration[022/030] Train loss: 0.0112
2023-02-06 14:30:46 | Train | Epoch[317/600] Iteration[023/030] Train loss: 0.0112
2023-02-06 14:30:47 | Train | Epoch[317/600] Iteration[024/030] Train loss: 0.0112
2023-02-06 14:30:47 | Train | Epoch[317/600] Iteration[025/030] Train loss: 0.0112
2023-02-06 14:30:47 | Train | Epoch[317/600] Iteration[026/030] Train loss: 0.0112
2023-02-06 14:30:47 | Train | Epoch[317/600] Iteration[027/030] Train loss: 0.0112
2023-02-06 14:30:47 | Train | Epoch[317/600] Iteration[028/030] Train loss: 0.0112
2023-02-06 14:30:48 | Train | Epoch[317/600] Iteration[029/030] Train loss: 0.0112
2023-02-06 14:30:48 | Train | Epoch[317/600] Iteration[030/030] Train loss: 0.0112
2023-02-06 14:30:48 | Valid | Epoch[317/600] Iteration[001/008] Valid loss: 0.1056
2023-02-06 14:30:48 | Valid | Epoch[317/600] Iteration[002/008] Valid loss: 0.0845
2023-02-06 14:30:48 | Valid | Epoch[317/600] Iteration[003/008] Valid loss: 0.0829
2023-02-06 14:30:48 | Valid | Epoch[317/600] Iteration[004/008] Valid loss: 0.0805
2023-02-06 14:30:48 | Valid | Epoch[317/600] Iteration[005/008] Valid loss: 0.0795
2023-02-06 14:30:48 | Valid | Epoch[317/600] Iteration[006/008] Valid loss: 0.0769
2023-02-06 14:30:48 | Valid | Epoch[317/600] Iteration[007/008] Valid loss: 0.0788
2023-02-06 14:30:48 | Valid | Epoch[317/600] Iteration[008/008] Valid loss: 0.0773
2023-02-06 14:30:48 | Valid | Epoch[317/600] MIou: 0.9034599140757472
2023-02-06 14:30:48 | Valid | Epoch[317/600] Pixel Accuracy: 0.9835700988769531
2023-02-06 14:30:48 | Valid | Epoch[317/600] Mean Pixel Accuracy: 0.9261000615843498
2023-02-06 14:30:48 | Stage | Epoch[317/600] Train loss:0.0112
2023-02-06 14:30:48 | Stage | Epoch[317/600] Valid loss:0.0773
2023-02-06 14:30:48 | Stage | Epoch[317/600] LR:0.01

2023-02-06 14:30:49 | Train | Epoch[318/600] Iteration[001/030] Train loss: 0.0113
2023-02-06 14:30:49 | Train | Epoch[318/600] Iteration[002/030] Train loss: 0.0110
2023-02-06 14:30:49 | Train | Epoch[318/600] Iteration[003/030] Train loss: 0.0110
2023-02-06 14:30:50 | Train | Epoch[318/600] Iteration[004/030] Train loss: 0.0108
2023-02-06 14:30:50 | Train | Epoch[318/600] Iteration[005/030] Train loss: 0.0109
2023-02-06 14:30:50 | Train | Epoch[318/600] Iteration[006/030] Train loss: 0.0109
2023-02-06 14:30:50 | Train | Epoch[318/600] Iteration[007/030] Train loss: 0.0108
2023-02-06 14:30:50 | Train | Epoch[318/600] Iteration[008/030] Train loss: 0.0108
2023-02-06 14:30:51 | Train | Epoch[318/600] Iteration[009/030] Train loss: 0.0107
2023-02-06 14:30:51 | Train | Epoch[318/600] Iteration[010/030] Train loss: 0.0109
2023-02-06 14:30:51 | Train | Epoch[318/600] Iteration[011/030] Train loss: 0.0108
2023-02-06 14:30:51 | Train | Epoch[318/600] Iteration[012/030] Train loss: 0.0109
2023-02-06 14:30:52 | Train | Epoch[318/600] Iteration[013/030] Train loss: 0.0109
2023-02-06 14:30:52 | Train | Epoch[318/600] Iteration[014/030] Train loss: 0.0108
2023-02-06 14:30:52 | Train | Epoch[318/600] Iteration[015/030] Train loss: 0.0108
2023-02-06 14:30:52 | Train | Epoch[318/600] Iteration[016/030] Train loss: 0.0108
2023-02-06 14:30:52 | Train | Epoch[318/600] Iteration[017/030] Train loss: 0.0108
2023-02-06 14:30:53 | Train | Epoch[318/600] Iteration[018/030] Train loss: 0.0108
2023-02-06 14:30:53 | Train | Epoch[318/600] Iteration[019/030] Train loss: 0.0108
2023-02-06 14:30:53 | Train | Epoch[318/600] Iteration[020/030] Train loss: 0.0108
2023-02-06 14:30:53 | Train | Epoch[318/600] Iteration[021/030] Train loss: 0.0108
2023-02-06 14:30:53 | Train | Epoch[318/600] Iteration[022/030] Train loss: 0.0109
2023-02-06 14:30:54 | Train | Epoch[318/600] Iteration[023/030] Train loss: 0.0108
2023-02-06 14:30:54 | Train | Epoch[318/600] Iteration[024/030] Train loss: 0.0109
2023-02-06 14:30:54 | Train | Epoch[318/600] Iteration[025/030] Train loss: 0.0108
2023-02-06 14:30:54 | Train | Epoch[318/600] Iteration[026/030] Train loss: 0.0109
2023-02-06 14:30:55 | Train | Epoch[318/600] Iteration[027/030] Train loss: 0.0109
2023-02-06 14:30:55 | Train | Epoch[318/600] Iteration[028/030] Train loss: 0.0110
2023-02-06 14:30:55 | Train | Epoch[318/600] Iteration[029/030] Train loss: 0.0110
2023-02-06 14:30:55 | Train | Epoch[318/600] Iteration[030/030] Train loss: 0.0110
2023-02-06 14:30:55 | Valid | Epoch[318/600] Iteration[001/008] Valid loss: 0.2982
2023-02-06 14:30:56 | Valid | Epoch[318/600] Iteration[002/008] Valid loss: 0.2276
2023-02-06 14:30:56 | Valid | Epoch[318/600] Iteration[003/008] Valid loss: 0.2180
2023-02-06 14:30:56 | Valid | Epoch[318/600] Iteration[004/008] Valid loss: 0.2092
2023-02-06 14:30:56 | Valid | Epoch[318/600] Iteration[005/008] Valid loss: 0.2166
2023-02-06 14:30:56 | Valid | Epoch[318/600] Iteration[006/008] Valid loss: 0.2142
2023-02-06 14:30:56 | Valid | Epoch[318/600] Iteration[007/008] Valid loss: 0.2327
2023-02-06 14:30:56 | Valid | Epoch[318/600] Iteration[008/008] Valid loss: 0.2379
2023-02-06 14:30:56 | Valid | Epoch[318/600] MIou: 0.9181944523884603
2023-02-06 14:30:56 | Valid | Epoch[318/600] Pixel Accuracy: 0.985137939453125
2023-02-06 14:30:56 | Valid | Epoch[318/600] Mean Pixel Accuracy: 0.9702989364168626
2023-02-06 14:30:56 | Stage | Epoch[318/600] Train loss:0.0110
2023-02-06 14:30:56 | Stage | Epoch[318/600] Valid loss:0.2379
2023-02-06 14:30:56 | Stage | Epoch[318/600] LR:0.01

2023-02-06 14:30:56 | Train | Epoch[319/600] Iteration[001/030] Train loss: 0.0093
2023-02-06 14:30:57 | Train | Epoch[319/600] Iteration[002/030] Train loss: 0.0093
2023-02-06 14:30:57 | Train | Epoch[319/600] Iteration[003/030] Train loss: 0.0109
2023-02-06 14:30:57 | Train | Epoch[319/600] Iteration[004/030] Train loss: 0.0115
2023-02-06 14:30:57 | Train | Epoch[319/600] Iteration[005/030] Train loss: 0.0114
2023-02-06 14:30:58 | Train | Epoch[319/600] Iteration[006/030] Train loss: 0.0112
2023-02-06 14:30:58 | Train | Epoch[319/600] Iteration[007/030] Train loss: 0.0110
2023-02-06 14:30:58 | Train | Epoch[319/600] Iteration[008/030] Train loss: 0.0113
2023-02-06 14:30:58 | Train | Epoch[319/600] Iteration[009/030] Train loss: 0.0115
2023-02-06 14:30:58 | Train | Epoch[319/600] Iteration[010/030] Train loss: 0.0119
2023-02-06 14:30:59 | Train | Epoch[319/600] Iteration[011/030] Train loss: 0.0118
2023-02-06 14:30:59 | Train | Epoch[319/600] Iteration[012/030] Train loss: 0.0116
2023-02-06 14:30:59 | Train | Epoch[319/600] Iteration[013/030] Train loss: 0.0115
2023-02-06 14:30:59 | Train | Epoch[319/600] Iteration[014/030] Train loss: 0.0114
2023-02-06 14:30:59 | Train | Epoch[319/600] Iteration[015/030] Train loss: 0.0113
2023-02-06 14:31:00 | Train | Epoch[319/600] Iteration[016/030] Train loss: 0.0113
2023-02-06 14:31:00 | Train | Epoch[319/600] Iteration[017/030] Train loss: 0.0113
2023-02-06 14:31:00 | Train | Epoch[319/600] Iteration[018/030] Train loss: 0.0113
2023-02-06 14:31:00 | Train | Epoch[319/600] Iteration[019/030] Train loss: 0.0113
2023-02-06 14:31:01 | Train | Epoch[319/600] Iteration[020/030] Train loss: 0.0113
2023-02-06 14:31:01 | Train | Epoch[319/600] Iteration[021/030] Train loss: 0.0113
2023-02-06 14:31:01 | Train | Epoch[319/600] Iteration[022/030] Train loss: 0.0113
2023-02-06 14:31:01 | Train | Epoch[319/600] Iteration[023/030] Train loss: 0.0112
2023-02-06 14:31:01 | Train | Epoch[319/600] Iteration[024/030] Train loss: 0.0113
2023-02-06 14:31:02 | Train | Epoch[319/600] Iteration[025/030] Train loss: 0.0113
2023-02-06 14:31:02 | Train | Epoch[319/600] Iteration[026/030] Train loss: 0.0113
2023-02-06 14:31:02 | Train | Epoch[319/600] Iteration[027/030] Train loss: 0.0113
2023-02-06 14:31:02 | Train | Epoch[319/600] Iteration[028/030] Train loss: 0.0113
2023-02-06 14:31:03 | Train | Epoch[319/600] Iteration[029/030] Train loss: 0.0114
2023-02-06 14:31:03 | Train | Epoch[319/600] Iteration[030/030] Train loss: 0.0114
2023-02-06 14:31:03 | Valid | Epoch[319/600] Iteration[001/008] Valid loss: 0.4643
2023-02-06 14:31:03 | Valid | Epoch[319/600] Iteration[002/008] Valid loss: 0.3788
2023-02-06 14:31:03 | Valid | Epoch[319/600] Iteration[003/008] Valid loss: 0.3636
2023-02-06 14:31:03 | Valid | Epoch[319/600] Iteration[004/008] Valid loss: 0.3572
2023-02-06 14:31:03 | Valid | Epoch[319/600] Iteration[005/008] Valid loss: 0.3683
2023-02-06 14:31:03 | Valid | Epoch[319/600] Iteration[006/008] Valid loss: 0.3640
2023-02-06 14:31:03 | Valid | Epoch[319/600] Iteration[007/008] Valid loss: 0.3930
2023-02-06 14:31:03 | Valid | Epoch[319/600] Iteration[008/008] Valid loss: 0.4056
2023-02-06 14:31:04 | Valid | Epoch[319/600] MIou: 0.9058411901703263
2023-02-06 14:31:04 | Valid | Epoch[319/600] Pixel Accuracy: 0.9821828206380209
2023-02-06 14:31:04 | Valid | Epoch[319/600] Mean Pixel Accuracy: 0.9773674635263736
2023-02-06 14:31:04 | Stage | Epoch[319/600] Train loss:0.0114
2023-02-06 14:31:04 | Stage | Epoch[319/600] Valid loss:0.4056
2023-02-06 14:31:04 | Stage | Epoch[319/600] LR:0.01

2023-02-06 14:31:04 | Train | Epoch[320/600] Iteration[001/030] Train loss: 0.0102
2023-02-06 14:31:04 | Train | Epoch[320/600] Iteration[002/030] Train loss: 0.0105
2023-02-06 14:31:04 | Train | Epoch[320/600] Iteration[003/030] Train loss: 0.0107
2023-02-06 14:31:05 | Train | Epoch[320/600] Iteration[004/030] Train loss: 0.0108
2023-02-06 14:31:05 | Train | Epoch[320/600] Iteration[005/030] Train loss: 0.0105
2023-02-06 14:31:05 | Train | Epoch[320/600] Iteration[006/030] Train loss: 0.0105
2023-02-06 14:31:05 | Train | Epoch[320/600] Iteration[007/030] Train loss: 0.0104
2023-02-06 14:31:06 | Train | Epoch[320/600] Iteration[008/030] Train loss: 0.0105
2023-02-06 14:31:06 | Train | Epoch[320/600] Iteration[009/030] Train loss: 0.0105
2023-02-06 14:31:06 | Train | Epoch[320/600] Iteration[010/030] Train loss: 0.0105
2023-02-06 14:31:06 | Train | Epoch[320/600] Iteration[011/030] Train loss: 0.0106
2023-02-06 14:31:06 | Train | Epoch[320/600] Iteration[012/030] Train loss: 0.0107
2023-02-06 14:31:07 | Train | Epoch[320/600] Iteration[013/030] Train loss: 0.0107
2023-02-06 14:31:07 | Train | Epoch[320/600] Iteration[014/030] Train loss: 0.0108
2023-02-06 14:31:07 | Train | Epoch[320/600] Iteration[015/030] Train loss: 0.0108
2023-02-06 14:31:07 | Train | Epoch[320/600] Iteration[016/030] Train loss: 0.0108
2023-02-06 14:31:08 | Train | Epoch[320/600] Iteration[017/030] Train loss: 0.0107
2023-02-06 14:31:08 | Train | Epoch[320/600] Iteration[018/030] Train loss: 0.0108
2023-02-06 14:31:08 | Train | Epoch[320/600] Iteration[019/030] Train loss: 0.0107
2023-02-06 14:31:08 | Train | Epoch[320/600] Iteration[020/030] Train loss: 0.0107
2023-02-06 14:31:08 | Train | Epoch[320/600] Iteration[021/030] Train loss: 0.0106
2023-02-06 14:31:09 | Train | Epoch[320/600] Iteration[022/030] Train loss: 0.0106
2023-02-06 14:31:09 | Train | Epoch[320/600] Iteration[023/030] Train loss: 0.0107
2023-02-06 14:31:09 | Train | Epoch[320/600] Iteration[024/030] Train loss: 0.0107
2023-02-06 14:31:09 | Train | Epoch[320/600] Iteration[025/030] Train loss: 0.0107
2023-02-06 14:31:09 | Train | Epoch[320/600] Iteration[026/030] Train loss: 0.0108
2023-02-06 14:31:10 | Train | Epoch[320/600] Iteration[027/030] Train loss: 0.0108
2023-02-06 14:31:10 | Train | Epoch[320/600] Iteration[028/030] Train loss: 0.0108
2023-02-06 14:31:10 | Train | Epoch[320/600] Iteration[029/030] Train loss: 0.0108
2023-02-06 14:31:10 | Train | Epoch[320/600] Iteration[030/030] Train loss: 0.0108
2023-02-06 14:31:11 | Valid | Epoch[320/600] Iteration[001/008] Valid loss: 0.1730
2023-02-06 14:31:11 | Valid | Epoch[320/600] Iteration[002/008] Valid loss: 0.1387
2023-02-06 14:31:11 | Valid | Epoch[320/600] Iteration[003/008] Valid loss: 0.1337
2023-02-06 14:31:11 | Valid | Epoch[320/600] Iteration[004/008] Valid loss: 0.1239
2023-02-06 14:31:11 | Valid | Epoch[320/600] Iteration[005/008] Valid loss: 0.1199
2023-02-06 14:31:11 | Valid | Epoch[320/600] Iteration[006/008] Valid loss: 0.1150
2023-02-06 14:31:11 | Valid | Epoch[320/600] Iteration[007/008] Valid loss: 0.1205
2023-02-06 14:31:11 | Valid | Epoch[320/600] Iteration[008/008] Valid loss: 0.1207
2023-02-06 14:31:11 | Valid | Epoch[320/600] MIou: 0.9261846899287651
2023-02-06 14:31:11 | Valid | Epoch[320/600] Pixel Accuracy: 0.9870223999023438
2023-02-06 14:31:11 | Valid | Epoch[320/600] Mean Pixel Accuracy: 0.9626736321645466
2023-02-06 14:31:11 | Stage | Epoch[320/600] Train loss:0.0108
2023-02-06 14:31:11 | Stage | Epoch[320/600] Valid loss:0.1207
2023-02-06 14:31:11 | Stage | Epoch[320/600] LR:0.01

2023-02-06 14:31:12 | Train | Epoch[321/600] Iteration[001/030] Train loss: 0.0100
2023-02-06 14:31:12 | Train | Epoch[321/600] Iteration[002/030] Train loss: 0.0095
2023-02-06 14:31:12 | Train | Epoch[321/600] Iteration[003/030] Train loss: 0.0096
2023-02-06 14:31:12 | Train | Epoch[321/600] Iteration[004/030] Train loss: 0.0101
2023-02-06 14:31:12 | Train | Epoch[321/600] Iteration[005/030] Train loss: 0.0100
2023-02-06 14:31:13 | Train | Epoch[321/600] Iteration[006/030] Train loss: 0.0102
2023-02-06 14:31:13 | Train | Epoch[321/600] Iteration[007/030] Train loss: 0.0105
2023-02-06 14:31:13 | Train | Epoch[321/600] Iteration[008/030] Train loss: 0.0104
2023-02-06 14:31:13 | Train | Epoch[321/600] Iteration[009/030] Train loss: 0.0104
2023-02-06 14:31:14 | Train | Epoch[321/600] Iteration[010/030] Train loss: 0.0103
2023-02-06 14:31:14 | Train | Epoch[321/600] Iteration[011/030] Train loss: 0.0104
2023-02-06 14:31:14 | Train | Epoch[321/600] Iteration[012/030] Train loss: 0.0105
2023-02-06 14:31:14 | Train | Epoch[321/600] Iteration[013/030] Train loss: 0.0106
2023-02-06 14:31:14 | Train | Epoch[321/600] Iteration[014/030] Train loss: 0.0104
2023-02-06 14:31:15 | Train | Epoch[321/600] Iteration[015/030] Train loss: 0.0104
2023-02-06 14:31:15 | Train | Epoch[321/600] Iteration[016/030] Train loss: 0.0104
2023-02-06 14:31:15 | Train | Epoch[321/600] Iteration[017/030] Train loss: 0.0105
2023-02-06 14:31:15 | Train | Epoch[321/600] Iteration[018/030] Train loss: 0.0106
2023-02-06 14:31:16 | Train | Epoch[321/600] Iteration[019/030] Train loss: 0.0106
2023-02-06 14:31:16 | Train | Epoch[321/600] Iteration[020/030] Train loss: 0.0106
2023-02-06 14:31:16 | Train | Epoch[321/600] Iteration[021/030] Train loss: 0.0106
2023-02-06 14:31:16 | Train | Epoch[321/600] Iteration[022/030] Train loss: 0.0105
2023-02-06 14:31:16 | Train | Epoch[321/600] Iteration[023/030] Train loss: 0.0108
2023-02-06 14:31:17 | Train | Epoch[321/600] Iteration[024/030] Train loss: 0.0108
2023-02-06 14:31:17 | Train | Epoch[321/600] Iteration[025/030] Train loss: 0.0107
2023-02-06 14:31:17 | Train | Epoch[321/600] Iteration[026/030] Train loss: 0.0107
2023-02-06 14:31:17 | Train | Epoch[321/600] Iteration[027/030] Train loss: 0.0107
2023-02-06 14:31:17 | Train | Epoch[321/600] Iteration[028/030] Train loss: 0.0107
2023-02-06 14:31:18 | Train | Epoch[321/600] Iteration[029/030] Train loss: 0.0108
2023-02-06 14:31:18 | Train | Epoch[321/600] Iteration[030/030] Train loss: 0.0108
2023-02-06 14:31:18 | Valid | Epoch[321/600] Iteration[001/008] Valid loss: 0.0896
2023-02-06 14:31:18 | Valid | Epoch[321/600] Iteration[002/008] Valid loss: 0.0855
2023-02-06 14:31:18 | Valid | Epoch[321/600] Iteration[003/008] Valid loss: 0.0849
2023-02-06 14:31:18 | Valid | Epoch[321/600] Iteration[004/008] Valid loss: 0.0835
2023-02-06 14:31:18 | Valid | Epoch[321/600] Iteration[005/008] Valid loss: 0.0820
2023-02-06 14:31:18 | Valid | Epoch[321/600] Iteration[006/008] Valid loss: 0.0796
2023-02-06 14:31:18 | Valid | Epoch[321/600] Iteration[007/008] Valid loss: 0.0768
2023-02-06 14:31:19 | Valid | Epoch[321/600] Iteration[008/008] Valid loss: 0.0773
2023-02-06 14:31:19 | Valid | Epoch[321/600] MIou: 0.8294959175130197
2023-02-06 14:31:19 | Valid | Epoch[321/600] Pixel Accuracy: 0.9718004862467448
2023-02-06 14:31:19 | Valid | Epoch[321/600] Mean Pixel Accuracy: 0.8457644874052195
2023-02-06 14:31:19 | Stage | Epoch[321/600] Train loss:0.0108
2023-02-06 14:31:19 | Stage | Epoch[321/600] Valid loss:0.0773
2023-02-06 14:31:19 | Stage | Epoch[321/600] LR:0.01

2023-02-06 14:31:19 | Train | Epoch[322/600] Iteration[001/030] Train loss: 0.0110
2023-02-06 14:31:19 | Train | Epoch[322/600] Iteration[002/030] Train loss: 0.0125
2023-02-06 14:31:20 | Train | Epoch[322/600] Iteration[003/030] Train loss: 0.0116
2023-02-06 14:31:20 | Train | Epoch[322/600] Iteration[004/030] Train loss: 0.0109
2023-02-06 14:31:20 | Train | Epoch[322/600] Iteration[005/030] Train loss: 0.0105
2023-02-06 14:31:20 | Train | Epoch[322/600] Iteration[006/030] Train loss: 0.0104
2023-02-06 14:31:20 | Train | Epoch[322/600] Iteration[007/030] Train loss: 0.0105
2023-02-06 14:31:21 | Train | Epoch[322/600] Iteration[008/030] Train loss: 0.0104
2023-02-06 14:31:21 | Train | Epoch[322/600] Iteration[009/030] Train loss: 0.0104
2023-02-06 14:31:21 | Train | Epoch[322/600] Iteration[010/030] Train loss: 0.0104
2023-02-06 14:31:21 | Train | Epoch[322/600] Iteration[011/030] Train loss: 0.0105
2023-02-06 14:31:22 | Train | Epoch[322/600] Iteration[012/030] Train loss: 0.0107
2023-02-06 14:31:22 | Train | Epoch[322/600] Iteration[013/030] Train loss: 0.0108
2023-02-06 14:31:22 | Train | Epoch[322/600] Iteration[014/030] Train loss: 0.0109
2023-02-06 14:31:22 | Train | Epoch[322/600] Iteration[015/030] Train loss: 0.0111
2023-02-06 14:31:22 | Train | Epoch[322/600] Iteration[016/030] Train loss: 0.0111
2023-02-06 14:31:23 | Train | Epoch[322/600] Iteration[017/030] Train loss: 0.0110
2023-02-06 14:31:23 | Train | Epoch[322/600] Iteration[018/030] Train loss: 0.0109
2023-02-06 14:31:23 | Train | Epoch[322/600] Iteration[019/030] Train loss: 0.0109
2023-02-06 14:31:23 | Train | Epoch[322/600] Iteration[020/030] Train loss: 0.0109
2023-02-06 14:31:24 | Train | Epoch[322/600] Iteration[021/030] Train loss: 0.0109
2023-02-06 14:31:24 | Train | Epoch[322/600] Iteration[022/030] Train loss: 0.0110
2023-02-06 14:31:24 | Train | Epoch[322/600] Iteration[023/030] Train loss: 0.0110
2023-02-06 14:31:24 | Train | Epoch[322/600] Iteration[024/030] Train loss: 0.0109
2023-02-06 14:31:24 | Train | Epoch[322/600] Iteration[025/030] Train loss: 0.0110
2023-02-06 14:31:25 | Train | Epoch[322/600] Iteration[026/030] Train loss: 0.0110
2023-02-06 14:31:25 | Train | Epoch[322/600] Iteration[027/030] Train loss: 0.0110
2023-02-06 14:31:25 | Train | Epoch[322/600] Iteration[028/030] Train loss: 0.0110
2023-02-06 14:31:25 | Train | Epoch[322/600] Iteration[029/030] Train loss: 0.0110
2023-02-06 14:31:25 | Train | Epoch[322/600] Iteration[030/030] Train loss: 0.0110
2023-02-06 14:31:26 | Valid | Epoch[322/600] Iteration[001/008] Valid loss: 0.6963
2023-02-06 14:31:26 | Valid | Epoch[322/600] Iteration[002/008] Valid loss: 0.5999
2023-02-06 14:31:26 | Valid | Epoch[322/600] Iteration[003/008] Valid loss: 0.5998
2023-02-06 14:31:26 | Valid | Epoch[322/600] Iteration[004/008] Valid loss: 0.6000
2023-02-06 14:31:26 | Valid | Epoch[322/600] Iteration[005/008] Valid loss: 0.6258
2023-02-06 14:31:26 | Valid | Epoch[322/600] Iteration[006/008] Valid loss: 0.6336
2023-02-06 14:31:26 | Valid | Epoch[322/600] Iteration[007/008] Valid loss: 0.6763
2023-02-06 14:31:26 | Valid | Epoch[322/600] Iteration[008/008] Valid loss: 0.6953
2023-02-06 14:31:26 | Valid | Epoch[322/600] MIou: 0.8818846806574925
2023-02-06 14:31:26 | Valid | Epoch[322/600] Pixel Accuracy: 0.9762751261393229
2023-02-06 14:31:26 | Valid | Epoch[322/600] Mean Pixel Accuracy: 0.9811455851081972
2023-02-06 14:31:26 | Stage | Epoch[322/600] Train loss:0.0110
2023-02-06 14:31:26 | Stage | Epoch[322/600] Valid loss:0.6953
2023-02-06 14:31:26 | Stage | Epoch[322/600] LR:0.01

2023-02-06 14:31:27 | Train | Epoch[323/600] Iteration[001/030] Train loss: 0.0097
2023-02-06 14:31:27 | Train | Epoch[323/600] Iteration[002/030] Train loss: 0.0100
2023-02-06 14:31:27 | Train | Epoch[323/600] Iteration[003/030] Train loss: 0.0101
2023-02-06 14:31:27 | Train | Epoch[323/600] Iteration[004/030] Train loss: 0.0105
2023-02-06 14:31:28 | Train | Epoch[323/600] Iteration[005/030] Train loss: 0.0102
2023-02-06 14:31:28 | Train | Epoch[323/600] Iteration[006/030] Train loss: 0.0101
2023-02-06 14:31:28 | Train | Epoch[323/600] Iteration[007/030] Train loss: 0.0099
2023-02-06 14:31:28 | Train | Epoch[323/600] Iteration[008/030] Train loss: 0.0102
2023-02-06 14:31:28 | Train | Epoch[323/600] Iteration[009/030] Train loss: 0.0103
2023-02-06 14:31:29 | Train | Epoch[323/600] Iteration[010/030] Train loss: 0.0104
2023-02-06 14:31:29 | Train | Epoch[323/600] Iteration[011/030] Train loss: 0.0103
2023-02-06 14:31:29 | Train | Epoch[323/600] Iteration[012/030] Train loss: 0.0104
2023-02-06 14:31:29 | Train | Epoch[323/600] Iteration[013/030] Train loss: 0.0105
2023-02-06 14:31:30 | Train | Epoch[323/600] Iteration[014/030] Train loss: 0.0107
2023-02-06 14:31:30 | Train | Epoch[323/600] Iteration[015/030] Train loss: 0.0107
2023-02-06 14:31:30 | Train | Epoch[323/600] Iteration[016/030] Train loss: 0.0108
2023-02-06 14:31:30 | Train | Epoch[323/600] Iteration[017/030] Train loss: 0.0109
2023-02-06 14:31:30 | Train | Epoch[323/600] Iteration[018/030] Train loss: 0.0109
2023-02-06 14:31:31 | Train | Epoch[323/600] Iteration[019/030] Train loss: 0.0109
2023-02-06 14:31:31 | Train | Epoch[323/600] Iteration[020/030] Train loss: 0.0109
2023-02-06 14:31:31 | Train | Epoch[323/600] Iteration[021/030] Train loss: 0.0109
2023-02-06 14:31:31 | Train | Epoch[323/600] Iteration[022/030] Train loss: 0.0110
2023-02-06 14:31:32 | Train | Epoch[323/600] Iteration[023/030] Train loss: 0.0110
2023-02-06 14:31:32 | Train | Epoch[323/600] Iteration[024/030] Train loss: 0.0110
2023-02-06 14:31:32 | Train | Epoch[323/600] Iteration[025/030] Train loss: 0.0110
2023-02-06 14:31:32 | Train | Epoch[323/600] Iteration[026/030] Train loss: 0.0110
2023-02-06 14:31:32 | Train | Epoch[323/600] Iteration[027/030] Train loss: 0.0110
2023-02-06 14:31:33 | Train | Epoch[323/600] Iteration[028/030] Train loss: 0.0110
2023-02-06 14:31:33 | Train | Epoch[323/600] Iteration[029/030] Train loss: 0.0110
2023-02-06 14:31:33 | Train | Epoch[323/600] Iteration[030/030] Train loss: 0.0110
2023-02-06 14:31:33 | Valid | Epoch[323/600] Iteration[001/008] Valid loss: 0.7160
2023-02-06 14:31:33 | Valid | Epoch[323/600] Iteration[002/008] Valid loss: 0.6669
2023-02-06 14:31:33 | Valid | Epoch[323/600] Iteration[003/008] Valid loss: 0.7014
2023-02-06 14:31:33 | Valid | Epoch[323/600] Iteration[004/008] Valid loss: 0.7049
2023-02-06 14:31:34 | Valid | Epoch[323/600] Iteration[005/008] Valid loss: 0.7211
2023-02-06 14:31:34 | Valid | Epoch[323/600] Iteration[006/008] Valid loss: 0.7195
2023-02-06 14:31:34 | Valid | Epoch[323/600] Iteration[007/008] Valid loss: 0.7577
2023-02-06 14:31:34 | Valid | Epoch[323/600] Iteration[008/008] Valid loss: 0.7849
2023-02-06 14:31:34 | Valid | Epoch[323/600] MIou: 0.8606773204874585
2023-02-06 14:31:34 | Valid | Epoch[323/600] Pixel Accuracy: 0.9707450866699219
2023-02-06 14:31:34 | Valid | Epoch[323/600] Mean Pixel Accuracy: 0.9794311981113599
2023-02-06 14:31:34 | Stage | Epoch[323/600] Train loss:0.0110
2023-02-06 14:31:34 | Stage | Epoch[323/600] Valid loss:0.7849
2023-02-06 14:31:34 | Stage | Epoch[323/600] LR:0.01

2023-02-06 14:31:34 | Train | Epoch[324/600] Iteration[001/030] Train loss: 0.0094
2023-02-06 14:31:34 | Train | Epoch[324/600] Iteration[002/030] Train loss: 0.0091
2023-02-06 14:31:35 | Train | Epoch[324/600] Iteration[003/030] Train loss: 0.0096
2023-02-06 14:31:35 | Train | Epoch[324/600] Iteration[004/030] Train loss: 0.0104
2023-02-06 14:31:35 | Train | Epoch[324/600] Iteration[005/030] Train loss: 0.0109
2023-02-06 14:31:35 | Train | Epoch[324/600] Iteration[006/030] Train loss: 0.0108
2023-02-06 14:31:36 | Train | Epoch[324/600] Iteration[007/030] Train loss: 0.0107
2023-02-06 14:31:36 | Train | Epoch[324/600] Iteration[008/030] Train loss: 0.0106
2023-02-06 14:31:36 | Train | Epoch[324/600] Iteration[009/030] Train loss: 0.0107
2023-02-06 14:31:36 | Train | Epoch[324/600] Iteration[010/030] Train loss: 0.0106
2023-02-06 14:31:36 | Train | Epoch[324/600] Iteration[011/030] Train loss: 0.0105
2023-02-06 14:31:37 | Train | Epoch[324/600] Iteration[012/030] Train loss: 0.0104
2023-02-06 14:31:37 | Train | Epoch[324/600] Iteration[013/030] Train loss: 0.0104
2023-02-06 14:31:37 | Train | Epoch[324/600] Iteration[014/030] Train loss: 0.0103
2023-02-06 14:31:37 | Train | Epoch[324/600] Iteration[015/030] Train loss: 0.0103
2023-02-06 14:31:38 | Train | Epoch[324/600] Iteration[016/030] Train loss: 0.0103
2023-02-06 14:31:38 | Train | Epoch[324/600] Iteration[017/030] Train loss: 0.0104
2023-02-06 14:31:38 | Train | Epoch[324/600] Iteration[018/030] Train loss: 0.0104
2023-02-06 14:31:38 | Train | Epoch[324/600] Iteration[019/030] Train loss: 0.0103
2023-02-06 14:31:38 | Train | Epoch[324/600] Iteration[020/030] Train loss: 0.0105
2023-02-06 14:31:39 | Train | Epoch[324/600] Iteration[021/030] Train loss: 0.0106
2023-02-06 14:31:39 | Train | Epoch[324/600] Iteration[022/030] Train loss: 0.0105
2023-02-06 14:31:39 | Train | Epoch[324/600] Iteration[023/030] Train loss: 0.0106
2023-02-06 14:31:39 | Train | Epoch[324/600] Iteration[024/030] Train loss: 0.0106
2023-02-06 14:31:40 | Train | Epoch[324/600] Iteration[025/030] Train loss: 0.0106
2023-02-06 14:31:40 | Train | Epoch[324/600] Iteration[026/030] Train loss: 0.0106
2023-02-06 14:31:40 | Train | Epoch[324/600] Iteration[027/030] Train loss: 0.0106
2023-02-06 14:31:40 | Train | Epoch[324/600] Iteration[028/030] Train loss: 0.0106
2023-02-06 14:31:40 | Train | Epoch[324/600] Iteration[029/030] Train loss: 0.0105
2023-02-06 14:31:40 | Train | Epoch[324/600] Iteration[030/030] Train loss: 0.0105
2023-02-06 14:31:41 | Valid | Epoch[324/600] Iteration[001/008] Valid loss: 0.2158
2023-02-06 14:31:41 | Valid | Epoch[324/600] Iteration[002/008] Valid loss: 0.1759
2023-02-06 14:31:41 | Valid | Epoch[324/600] Iteration[003/008] Valid loss: 0.1588
2023-02-06 14:31:41 | Valid | Epoch[324/600] Iteration[004/008] Valid loss: 0.1532
2023-02-06 14:31:41 | Valid | Epoch[324/600] Iteration[005/008] Valid loss: 0.1521
2023-02-06 14:31:41 | Valid | Epoch[324/600] Iteration[006/008] Valid loss: 0.1497
2023-02-06 14:31:41 | Valid | Epoch[324/600] Iteration[007/008] Valid loss: 0.1615
2023-02-06 14:31:41 | Valid | Epoch[324/600] Iteration[008/008] Valid loss: 0.1633
2023-02-06 14:31:41 | Valid | Epoch[324/600] MIou: 0.9257208161353785
2023-02-06 14:31:41 | Valid | Epoch[324/600] Pixel Accuracy: 0.986840565999349
2023-02-06 14:31:41 | Valid | Epoch[324/600] Mean Pixel Accuracy: 0.9658263503821292
2023-02-06 14:31:41 | Stage | Epoch[324/600] Train loss:0.0105
2023-02-06 14:31:41 | Stage | Epoch[324/600] Valid loss:0.1633
2023-02-06 14:31:41 | Stage | Epoch[324/600] LR:0.01

2023-02-06 14:31:42 | Train | Epoch[325/600] Iteration[001/030] Train loss: 0.0121
2023-02-06 14:31:42 | Train | Epoch[325/600] Iteration[002/030] Train loss: 0.0105
2023-02-06 14:31:42 | Train | Epoch[325/600] Iteration[003/030] Train loss: 0.0109
2023-02-06 14:31:42 | Train | Epoch[325/600] Iteration[004/030] Train loss: 0.0108
2023-02-06 14:31:43 | Train | Epoch[325/600] Iteration[005/030] Train loss: 0.0105
2023-02-06 14:31:43 | Train | Epoch[325/600] Iteration[006/030] Train loss: 0.0105
2023-02-06 14:31:43 | Train | Epoch[325/600] Iteration[007/030] Train loss: 0.0105
2023-02-06 14:31:43 | Train | Epoch[325/600] Iteration[008/030] Train loss: 0.0103
2023-02-06 14:31:43 | Train | Epoch[325/600] Iteration[009/030] Train loss: 0.0101
2023-02-06 14:31:44 | Train | Epoch[325/600] Iteration[010/030] Train loss: 0.0100
2023-02-06 14:31:44 | Train | Epoch[325/600] Iteration[011/030] Train loss: 0.0100
2023-02-06 14:31:44 | Train | Epoch[325/600] Iteration[012/030] Train loss: 0.0099
2023-02-06 14:31:44 | Train | Epoch[325/600] Iteration[013/030] Train loss: 0.0100
2023-02-06 14:31:45 | Train | Epoch[325/600] Iteration[014/030] Train loss: 0.0099
2023-02-06 14:31:45 | Train | Epoch[325/600] Iteration[015/030] Train loss: 0.0099
2023-02-06 14:31:45 | Train | Epoch[325/600] Iteration[016/030] Train loss: 0.0099
2023-02-06 14:31:45 | Train | Epoch[325/600] Iteration[017/030] Train loss: 0.0100
2023-02-06 14:31:45 | Train | Epoch[325/600] Iteration[018/030] Train loss: 0.0100
2023-02-06 14:31:46 | Train | Epoch[325/600] Iteration[019/030] Train loss: 0.0101
2023-02-06 14:31:46 | Train | Epoch[325/600] Iteration[020/030] Train loss: 0.0102
2023-02-06 14:31:46 | Train | Epoch[325/600] Iteration[021/030] Train loss: 0.0102
2023-02-06 14:31:46 | Train | Epoch[325/600] Iteration[022/030] Train loss: 0.0101
2023-02-06 14:31:47 | Train | Epoch[325/600] Iteration[023/030] Train loss: 0.0101
2023-02-06 14:31:47 | Train | Epoch[325/600] Iteration[024/030] Train loss: 0.0101
2023-02-06 14:31:47 | Train | Epoch[325/600] Iteration[025/030] Train loss: 0.0102
2023-02-06 14:31:47 | Train | Epoch[325/600] Iteration[026/030] Train loss: 0.0102
2023-02-06 14:31:47 | Train | Epoch[325/600] Iteration[027/030] Train loss: 0.0103
2023-02-06 14:31:48 | Train | Epoch[325/600] Iteration[028/030] Train loss: 0.0103
2023-02-06 14:31:48 | Train | Epoch[325/600] Iteration[029/030] Train loss: 0.0103
2023-02-06 14:31:48 | Train | Epoch[325/600] Iteration[030/030] Train loss: 0.0103
2023-02-06 14:31:48 | Valid | Epoch[325/600] Iteration[001/008] Valid loss: 0.2828
2023-02-06 14:31:48 | Valid | Epoch[325/600] Iteration[002/008] Valid loss: 0.2176
2023-02-06 14:31:48 | Valid | Epoch[325/600] Iteration[003/008] Valid loss: 0.2163
2023-02-06 14:31:48 | Valid | Epoch[325/600] Iteration[004/008] Valid loss: 0.2095
2023-02-06 14:31:48 | Valid | Epoch[325/600] Iteration[005/008] Valid loss: 0.2136
2023-02-06 14:31:49 | Valid | Epoch[325/600] Iteration[006/008] Valid loss: 0.2114
2023-02-06 14:31:49 | Valid | Epoch[325/600] Iteration[007/008] Valid loss: 0.2236
2023-02-06 14:31:49 | Valid | Epoch[325/600] Iteration[008/008] Valid loss: 0.2206
2023-02-06 14:31:49 | Valid | Epoch[325/600] MIou: 0.9167502480950107
2023-02-06 14:31:49 | Valid | Epoch[325/600] Pixel Accuracy: 0.985040028889974
2023-02-06 14:31:49 | Valid | Epoch[325/600] Mean Pixel Accuracy: 0.9636129873939348
2023-02-06 14:31:49 | Stage | Epoch[325/600] Train loss:0.0103
2023-02-06 14:31:49 | Stage | Epoch[325/600] Valid loss:0.2206
2023-02-06 14:31:49 | Stage | Epoch[325/600] LR:0.01

2023-02-06 14:31:49 | Train | Epoch[326/600] Iteration[001/030] Train loss: 0.0095
2023-02-06 14:31:49 | Train | Epoch[326/600] Iteration[002/030] Train loss: 0.0090
2023-02-06 14:31:50 | Train | Epoch[326/600] Iteration[003/030] Train loss: 0.0087
2023-02-06 14:31:50 | Train | Epoch[326/600] Iteration[004/030] Train loss: 0.0093
2023-02-06 14:31:50 | Train | Epoch[326/600] Iteration[005/030] Train loss: 0.0095
2023-02-06 14:31:50 | Train | Epoch[326/600] Iteration[006/030] Train loss: 0.0094
2023-02-06 14:31:50 | Train | Epoch[326/600] Iteration[007/030] Train loss: 0.0094
2023-02-06 14:31:51 | Train | Epoch[326/600] Iteration[008/030] Train loss: 0.0095
2023-02-06 14:31:51 | Train | Epoch[326/600] Iteration[009/030] Train loss: 0.0095
2023-02-06 14:31:51 | Train | Epoch[326/600] Iteration[010/030] Train loss: 0.0096
2023-02-06 14:31:51 | Train | Epoch[326/600] Iteration[011/030] Train loss: 0.0095
2023-02-06 14:31:52 | Train | Epoch[326/600] Iteration[012/030] Train loss: 0.0097
2023-02-06 14:31:52 | Train | Epoch[326/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:31:52 | Train | Epoch[326/600] Iteration[014/030] Train loss: 0.0097
2023-02-06 14:31:52 | Train | Epoch[326/600] Iteration[015/030] Train loss: 0.0097
2023-02-06 14:31:52 | Train | Epoch[326/600] Iteration[016/030] Train loss: 0.0098
2023-02-06 14:31:53 | Train | Epoch[326/600] Iteration[017/030] Train loss: 0.0098
2023-02-06 14:31:53 | Train | Epoch[326/600] Iteration[018/030] Train loss: 0.0098
2023-02-06 14:31:53 | Train | Epoch[326/600] Iteration[019/030] Train loss: 0.0100
2023-02-06 14:31:53 | Train | Epoch[326/600] Iteration[020/030] Train loss: 0.0101
2023-02-06 14:31:54 | Train | Epoch[326/600] Iteration[021/030] Train loss: 0.0102
2023-02-06 14:31:54 | Train | Epoch[326/600] Iteration[022/030] Train loss: 0.0102
2023-02-06 14:31:54 | Train | Epoch[326/600] Iteration[023/030] Train loss: 0.0102
2023-02-06 14:31:54 | Train | Epoch[326/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:31:54 | Train | Epoch[326/600] Iteration[025/030] Train loss: 0.0103
2023-02-06 14:31:55 | Train | Epoch[326/600] Iteration[026/030] Train loss: 0.0103
2023-02-06 14:31:55 | Train | Epoch[326/600] Iteration[027/030] Train loss: 0.0103
2023-02-06 14:31:55 | Train | Epoch[326/600] Iteration[028/030] Train loss: 0.0105
2023-02-06 14:31:55 | Train | Epoch[326/600] Iteration[029/030] Train loss: 0.0104
2023-02-06 14:31:55 | Train | Epoch[326/600] Iteration[030/030] Train loss: 0.0104
2023-02-06 14:31:56 | Valid | Epoch[326/600] Iteration[001/008] Valid loss: 0.0896
2023-02-06 14:31:56 | Valid | Epoch[326/600] Iteration[002/008] Valid loss: 0.0747
2023-02-06 14:31:56 | Valid | Epoch[326/600] Iteration[003/008] Valid loss: 0.0744
2023-02-06 14:31:56 | Valid | Epoch[326/600] Iteration[004/008] Valid loss: 0.0706
2023-02-06 14:31:56 | Valid | Epoch[326/600] Iteration[005/008] Valid loss: 0.0676
2023-02-06 14:31:56 | Valid | Epoch[326/600] Iteration[006/008] Valid loss: 0.0659
2023-02-06 14:31:56 | Valid | Epoch[326/600] Iteration[007/008] Valid loss: 0.0678
2023-02-06 14:31:56 | Valid | Epoch[326/600] Iteration[008/008] Valid loss: 0.0674
2023-02-06 14:31:56 | Valid | Epoch[326/600] MIou: 0.8954283598622776
2023-02-06 14:31:56 | Valid | Epoch[326/600] Pixel Accuracy: 0.9824269612630209
2023-02-06 14:31:56 | Valid | Epoch[326/600] Mean Pixel Accuracy: 0.9131839106076818
2023-02-06 14:31:56 | Stage | Epoch[326/600] Train loss:0.0104
2023-02-06 14:31:56 | Stage | Epoch[326/600] Valid loss:0.0674
2023-02-06 14:31:56 | Stage | Epoch[326/600] LR:0.01

2023-02-06 14:31:57 | Train | Epoch[327/600] Iteration[001/030] Train loss: 0.0097
2023-02-06 14:31:57 | Train | Epoch[327/600] Iteration[002/030] Train loss: 0.0101
2023-02-06 14:31:57 | Train | Epoch[327/600] Iteration[003/030] Train loss: 0.0101
2023-02-06 14:31:57 | Train | Epoch[327/600] Iteration[004/030] Train loss: 0.0100
2023-02-06 14:31:58 | Train | Epoch[327/600] Iteration[005/030] Train loss: 0.0098
2023-02-06 14:31:58 | Train | Epoch[327/600] Iteration[006/030] Train loss: 0.0098
2023-02-06 14:31:58 | Train | Epoch[327/600] Iteration[007/030] Train loss: 0.0097
2023-02-06 14:31:58 | Train | Epoch[327/600] Iteration[008/030] Train loss: 0.0103
2023-02-06 14:31:59 | Train | Epoch[327/600] Iteration[009/030] Train loss: 0.0102
2023-02-06 14:31:59 | Train | Epoch[327/600] Iteration[010/030] Train loss: 0.0101
2023-02-06 14:31:59 | Train | Epoch[327/600] Iteration[011/030] Train loss: 0.0103
2023-02-06 14:31:59 | Train | Epoch[327/600] Iteration[012/030] Train loss: 0.0102
2023-02-06 14:31:59 | Train | Epoch[327/600] Iteration[013/030] Train loss: 0.0102
2023-02-06 14:32:00 | Train | Epoch[327/600] Iteration[014/030] Train loss: 0.0103
2023-02-06 14:32:00 | Train | Epoch[327/600] Iteration[015/030] Train loss: 0.0103
2023-02-06 14:32:00 | Train | Epoch[327/600] Iteration[016/030] Train loss: 0.0103
2023-02-06 14:32:00 | Train | Epoch[327/600] Iteration[017/030] Train loss: 0.0106
2023-02-06 14:32:00 | Train | Epoch[327/600] Iteration[018/030] Train loss: 0.0105
2023-02-06 14:32:01 | Train | Epoch[327/600] Iteration[019/030] Train loss: 0.0105
2023-02-06 14:32:01 | Train | Epoch[327/600] Iteration[020/030] Train loss: 0.0106
2023-02-06 14:32:01 | Train | Epoch[327/600] Iteration[021/030] Train loss: 0.0106
2023-02-06 14:32:01 | Train | Epoch[327/600] Iteration[022/030] Train loss: 0.0106
2023-02-06 14:32:02 | Train | Epoch[327/600] Iteration[023/030] Train loss: 0.0105
2023-02-06 14:32:02 | Train | Epoch[327/600] Iteration[024/030] Train loss: 0.0106
2023-02-06 14:32:02 | Train | Epoch[327/600] Iteration[025/030] Train loss: 0.0106
2023-02-06 14:32:02 | Train | Epoch[327/600] Iteration[026/030] Train loss: 0.0106
2023-02-06 14:32:02 | Train | Epoch[327/600] Iteration[027/030] Train loss: 0.0106
2023-02-06 14:32:03 | Train | Epoch[327/600] Iteration[028/030] Train loss: 0.0106
2023-02-06 14:32:03 | Train | Epoch[327/600] Iteration[029/030] Train loss: 0.0106
2023-02-06 14:32:03 | Train | Epoch[327/600] Iteration[030/030] Train loss: 0.0107
2023-02-06 14:32:03 | Valid | Epoch[327/600] Iteration[001/008] Valid loss: 0.2986
2023-02-06 14:32:03 | Valid | Epoch[327/600] Iteration[002/008] Valid loss: 0.2517
2023-02-06 14:32:03 | Valid | Epoch[327/600] Iteration[003/008] Valid loss: 0.2404
2023-02-06 14:32:03 | Valid | Epoch[327/600] Iteration[004/008] Valid loss: 0.2331
2023-02-06 14:32:04 | Valid | Epoch[327/600] Iteration[005/008] Valid loss: 0.2368
2023-02-06 14:32:04 | Valid | Epoch[327/600] Iteration[006/008] Valid loss: 0.2350
2023-02-06 14:32:04 | Valid | Epoch[327/600] Iteration[007/008] Valid loss: 0.2569
2023-02-06 14:32:04 | Valid | Epoch[327/600] Iteration[008/008] Valid loss: 0.2574
2023-02-06 14:32:04 | Valid | Epoch[327/600] MIou: 0.9238984497408587
2023-02-06 14:32:04 | Valid | Epoch[327/600] Pixel Accuracy: 0.9861526489257812
2023-02-06 14:32:04 | Valid | Epoch[327/600] Mean Pixel Accuracy: 0.9768610905412864
2023-02-06 14:32:04 | Stage | Epoch[327/600] Train loss:0.0107
2023-02-06 14:32:04 | Stage | Epoch[327/600] Valid loss:0.2574
2023-02-06 14:32:04 | Stage | Epoch[327/600] LR:0.01

2023-02-06 14:32:04 | Train | Epoch[328/600] Iteration[001/030] Train loss: 0.0103
2023-02-06 14:32:04 | Train | Epoch[328/600] Iteration[002/030] Train loss: 0.0098
2023-02-06 14:32:05 | Train | Epoch[328/600] Iteration[003/030] Train loss: 0.0099
2023-02-06 14:32:05 | Train | Epoch[328/600] Iteration[004/030] Train loss: 0.0097
2023-02-06 14:32:05 | Train | Epoch[328/600] Iteration[005/030] Train loss: 0.0098
2023-02-06 14:32:05 | Train | Epoch[328/600] Iteration[006/030] Train loss: 0.0100
2023-02-06 14:32:06 | Train | Epoch[328/600] Iteration[007/030] Train loss: 0.0101
2023-02-06 14:32:06 | Train | Epoch[328/600] Iteration[008/030] Train loss: 0.0100
2023-02-06 14:32:06 | Train | Epoch[328/600] Iteration[009/030] Train loss: 0.0100
2023-02-06 14:32:06 | Train | Epoch[328/600] Iteration[010/030] Train loss: 0.0101
2023-02-06 14:32:06 | Train | Epoch[328/600] Iteration[011/030] Train loss: 0.0100
2023-02-06 14:32:07 | Train | Epoch[328/600] Iteration[012/030] Train loss: 0.0101
2023-02-06 14:32:07 | Train | Epoch[328/600] Iteration[013/030] Train loss: 0.0101
2023-02-06 14:32:07 | Train | Epoch[328/600] Iteration[014/030] Train loss: 0.0100
2023-02-06 14:32:07 | Train | Epoch[328/600] Iteration[015/030] Train loss: 0.0100
2023-02-06 14:32:08 | Train | Epoch[328/600] Iteration[016/030] Train loss: 0.0100
2023-02-06 14:32:08 | Train | Epoch[328/600] Iteration[017/030] Train loss: 0.0100
2023-02-06 14:32:08 | Train | Epoch[328/600] Iteration[018/030] Train loss: 0.0101
2023-02-06 14:32:08 | Train | Epoch[328/600] Iteration[019/030] Train loss: 0.0101
2023-02-06 14:32:08 | Train | Epoch[328/600] Iteration[020/030] Train loss: 0.0101
2023-02-06 14:32:09 | Train | Epoch[328/600] Iteration[021/030] Train loss: 0.0103
2023-02-06 14:32:09 | Train | Epoch[328/600] Iteration[022/030] Train loss: 0.0102
2023-02-06 14:32:09 | Train | Epoch[328/600] Iteration[023/030] Train loss: 0.0103
2023-02-06 14:32:09 | Train | Epoch[328/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:32:09 | Train | Epoch[328/600] Iteration[025/030] Train loss: 0.0103
2023-02-06 14:32:10 | Train | Epoch[328/600] Iteration[026/030] Train loss: 0.0103
2023-02-06 14:32:10 | Train | Epoch[328/600] Iteration[027/030] Train loss: 0.0102
2023-02-06 14:32:10 | Train | Epoch[328/600] Iteration[028/030] Train loss: 0.0102
2023-02-06 14:32:10 | Train | Epoch[328/600] Iteration[029/030] Train loss: 0.0103
2023-02-06 14:32:10 | Train | Epoch[328/600] Iteration[030/030] Train loss: 0.0104
2023-02-06 14:32:11 | Valid | Epoch[328/600] Iteration[001/008] Valid loss: 0.2119
2023-02-06 14:32:11 | Valid | Epoch[328/600] Iteration[002/008] Valid loss: 0.2127
2023-02-06 14:32:11 | Valid | Epoch[328/600] Iteration[003/008] Valid loss: 0.2223
2023-02-06 14:32:11 | Valid | Epoch[328/600] Iteration[004/008] Valid loss: 0.2243
2023-02-06 14:32:11 | Valid | Epoch[328/600] Iteration[005/008] Valid loss: 0.2257
2023-02-06 14:32:11 | Valid | Epoch[328/600] Iteration[006/008] Valid loss: 0.2221
2023-02-06 14:32:11 | Valid | Epoch[328/600] Iteration[007/008] Valid loss: 0.2158
2023-02-06 14:32:11 | Valid | Epoch[328/600] Iteration[008/008] Valid loss: 0.2179
2023-02-06 14:32:11 | Valid | Epoch[328/600] MIou: 0.6274889150717435
2023-02-06 14:32:11 | Valid | Epoch[328/600] Pixel Accuracy: 0.9384320576985677
2023-02-06 14:32:11 | Valid | Epoch[328/600] Mean Pixel Accuracy: 0.6591920453160702
2023-02-06 14:32:11 | Stage | Epoch[328/600] Train loss:0.0104
2023-02-06 14:32:11 | Stage | Epoch[328/600] Valid loss:0.2179
2023-02-06 14:32:11 | Stage | Epoch[328/600] LR:0.01

2023-02-06 14:32:12 | Train | Epoch[329/600] Iteration[001/030] Train loss: 0.0094
2023-02-06 14:32:12 | Train | Epoch[329/600] Iteration[002/030] Train loss: 0.0099
2023-02-06 14:32:12 | Train | Epoch[329/600] Iteration[003/030] Train loss: 0.0101
2023-02-06 14:32:12 | Train | Epoch[329/600] Iteration[004/030] Train loss: 0.0102
2023-02-06 14:32:13 | Train | Epoch[329/600] Iteration[005/030] Train loss: 0.0103
2023-02-06 14:32:13 | Train | Epoch[329/600] Iteration[006/030] Train loss: 0.0103
2023-02-06 14:32:13 | Train | Epoch[329/600] Iteration[007/030] Train loss: 0.0102
2023-02-06 14:32:13 | Train | Epoch[329/600] Iteration[008/030] Train loss: 0.0103
2023-02-06 14:32:13 | Train | Epoch[329/600] Iteration[009/030] Train loss: 0.0102
2023-02-06 14:32:14 | Train | Epoch[329/600] Iteration[010/030] Train loss: 0.0102
2023-02-06 14:32:14 | Train | Epoch[329/600] Iteration[011/030] Train loss: 0.0103
2023-02-06 14:32:14 | Train | Epoch[329/600] Iteration[012/030] Train loss: 0.0102
2023-02-06 14:32:14 | Train | Epoch[329/600] Iteration[013/030] Train loss: 0.0101
2023-02-06 14:32:15 | Train | Epoch[329/600] Iteration[014/030] Train loss: 0.0101
2023-02-06 14:32:15 | Train | Epoch[329/600] Iteration[015/030] Train loss: 0.0101
2023-02-06 14:32:15 | Train | Epoch[329/600] Iteration[016/030] Train loss: 0.0102
2023-02-06 14:32:15 | Train | Epoch[329/600] Iteration[017/030] Train loss: 0.0102
2023-02-06 14:32:15 | Train | Epoch[329/600] Iteration[018/030] Train loss: 0.0102
2023-02-06 14:32:16 | Train | Epoch[329/600] Iteration[019/030] Train loss: 0.0102
2023-02-06 14:32:16 | Train | Epoch[329/600] Iteration[020/030] Train loss: 0.0102
2023-02-06 14:32:16 | Train | Epoch[329/600] Iteration[021/030] Train loss: 0.0101
2023-02-06 14:32:16 | Train | Epoch[329/600] Iteration[022/030] Train loss: 0.0102
2023-02-06 14:32:17 | Train | Epoch[329/600] Iteration[023/030] Train loss: 0.0103
2023-02-06 14:32:17 | Train | Epoch[329/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:32:17 | Train | Epoch[329/600] Iteration[025/030] Train loss: 0.0103
2023-02-06 14:32:17 | Train | Epoch[329/600] Iteration[026/030] Train loss: 0.0104
2023-02-06 14:32:17 | Train | Epoch[329/600] Iteration[027/030] Train loss: 0.0104
2023-02-06 14:32:18 | Train | Epoch[329/600] Iteration[028/030] Train loss: 0.0103
2023-02-06 14:32:18 | Train | Epoch[329/600] Iteration[029/030] Train loss: 0.0104
2023-02-06 14:32:18 | Train | Epoch[329/600] Iteration[030/030] Train loss: 0.0104
2023-02-06 14:32:18 | Valid | Epoch[329/600] Iteration[001/008] Valid loss: 0.3222
2023-02-06 14:32:18 | Valid | Epoch[329/600] Iteration[002/008] Valid loss: 0.2563
2023-02-06 14:32:18 | Valid | Epoch[329/600] Iteration[003/008] Valid loss: 0.2541
2023-02-06 14:32:18 | Valid | Epoch[329/600] Iteration[004/008] Valid loss: 0.2460
2023-02-06 14:32:19 | Valid | Epoch[329/600] Iteration[005/008] Valid loss: 0.2495
2023-02-06 14:32:19 | Valid | Epoch[329/600] Iteration[006/008] Valid loss: 0.2435
2023-02-06 14:32:19 | Valid | Epoch[329/600] Iteration[007/008] Valid loss: 0.2576
2023-02-06 14:32:19 | Valid | Epoch[329/600] Iteration[008/008] Valid loss: 0.2602
2023-02-06 14:32:19 | Valid | Epoch[329/600] MIou: 0.9034794525445426
2023-02-06 14:32:19 | Valid | Epoch[329/600] Pixel Accuracy: 0.9818331400553385
2023-02-06 14:32:19 | Valid | Epoch[329/600] Mean Pixel Accuracy: 0.9722423773282172
2023-02-06 14:32:19 | Stage | Epoch[329/600] Train loss:0.0104
2023-02-06 14:32:19 | Stage | Epoch[329/600] Valid loss:0.2602
2023-02-06 14:32:19 | Stage | Epoch[329/600] LR:0.01

2023-02-06 14:32:19 | Train | Epoch[330/600] Iteration[001/030] Train loss: 0.0103
2023-02-06 14:32:19 | Train | Epoch[330/600] Iteration[002/030] Train loss: 0.0092
2023-02-06 14:32:20 | Train | Epoch[330/600] Iteration[003/030] Train loss: 0.0095
2023-02-06 14:32:20 | Train | Epoch[330/600] Iteration[004/030] Train loss: 0.0097
2023-02-06 14:32:20 | Train | Epoch[330/600] Iteration[005/030] Train loss: 0.0097
2023-02-06 14:32:20 | Train | Epoch[330/600] Iteration[006/030] Train loss: 0.0104
2023-02-06 14:32:21 | Train | Epoch[330/600] Iteration[007/030] Train loss: 0.0104
2023-02-06 14:32:21 | Train | Epoch[330/600] Iteration[008/030] Train loss: 0.0103
2023-02-06 14:32:21 | Train | Epoch[330/600] Iteration[009/030] Train loss: 0.0102
2023-02-06 14:32:21 | Train | Epoch[330/600] Iteration[010/030] Train loss: 0.0101
2023-02-06 14:32:21 | Train | Epoch[330/600] Iteration[011/030] Train loss: 0.0104
2023-02-06 14:32:22 | Train | Epoch[330/600] Iteration[012/030] Train loss: 0.0103
2023-02-06 14:32:22 | Train | Epoch[330/600] Iteration[013/030] Train loss: 0.0103
2023-02-06 14:32:22 | Train | Epoch[330/600] Iteration[014/030] Train loss: 0.0102
2023-02-06 14:32:22 | Train | Epoch[330/600] Iteration[015/030] Train loss: 0.0103
2023-02-06 14:32:22 | Train | Epoch[330/600] Iteration[016/030] Train loss: 0.0104
2023-02-06 14:32:23 | Train | Epoch[330/600] Iteration[017/030] Train loss: 0.0104
2023-02-06 14:32:23 | Train | Epoch[330/600] Iteration[018/030] Train loss: 0.0104
2023-02-06 14:32:23 | Train | Epoch[330/600] Iteration[019/030] Train loss: 0.0104
2023-02-06 14:32:23 | Train | Epoch[330/600] Iteration[020/030] Train loss: 0.0104
2023-02-06 14:32:24 | Train | Epoch[330/600] Iteration[021/030] Train loss: 0.0104
2023-02-06 14:32:24 | Train | Epoch[330/600] Iteration[022/030] Train loss: 0.0104
2023-02-06 14:32:24 | Train | Epoch[330/600] Iteration[023/030] Train loss: 0.0104
2023-02-06 14:32:24 | Train | Epoch[330/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:32:24 | Train | Epoch[330/600] Iteration[025/030] Train loss: 0.0103
2023-02-06 14:32:25 | Train | Epoch[330/600] Iteration[026/030] Train loss: 0.0103
2023-02-06 14:32:25 | Train | Epoch[330/600] Iteration[027/030] Train loss: 0.0103
2023-02-06 14:32:25 | Train | Epoch[330/600] Iteration[028/030] Train loss: 0.0102
2023-02-06 14:32:25 | Train | Epoch[330/600] Iteration[029/030] Train loss: 0.0102
2023-02-06 14:32:25 | Train | Epoch[330/600] Iteration[030/030] Train loss: 0.0103
2023-02-06 14:32:26 | Valid | Epoch[330/600] Iteration[001/008] Valid loss: 0.1202
2023-02-06 14:32:26 | Valid | Epoch[330/600] Iteration[002/008] Valid loss: 0.0842
2023-02-06 14:32:26 | Valid | Epoch[330/600] Iteration[003/008] Valid loss: 0.0805
2023-02-06 14:32:26 | Valid | Epoch[330/600] Iteration[004/008] Valid loss: 0.0781
2023-02-06 14:32:26 | Valid | Epoch[330/600] Iteration[005/008] Valid loss: 0.0758
2023-02-06 14:32:26 | Valid | Epoch[330/600] Iteration[006/008] Valid loss: 0.0724
2023-02-06 14:32:26 | Valid | Epoch[330/600] Iteration[007/008] Valid loss: 0.0741
2023-02-06 14:32:26 | Valid | Epoch[330/600] Iteration[008/008] Valid loss: 0.0719
2023-02-06 14:32:26 | Valid | Epoch[330/600] MIou: 0.9156480306384492
2023-02-06 14:32:26 | Valid | Epoch[330/600] Pixel Accuracy: 0.9857953389485677
2023-02-06 14:32:26 | Valid | Epoch[330/600] Mean Pixel Accuracy: 0.9330676156218471
2023-02-06 14:32:26 | Stage | Epoch[330/600] Train loss:0.0103
2023-02-06 14:32:26 | Stage | Epoch[330/600] Valid loss:0.0719
2023-02-06 14:32:26 | Stage | Epoch[330/600] LR:0.01

2023-02-06 14:32:27 | Train | Epoch[331/600] Iteration[001/030] Train loss: 0.0102
2023-02-06 14:32:27 | Train | Epoch[331/600] Iteration[002/030] Train loss: 0.0101
2023-02-06 14:32:27 | Train | Epoch[331/600] Iteration[003/030] Train loss: 0.0098
2023-02-06 14:32:27 | Train | Epoch[331/600] Iteration[004/030] Train loss: 0.0097
2023-02-06 14:32:28 | Train | Epoch[331/600] Iteration[005/030] Train loss: 0.0098
2023-02-06 14:32:28 | Train | Epoch[331/600] Iteration[006/030] Train loss: 0.0098
2023-02-06 14:32:28 | Train | Epoch[331/600] Iteration[007/030] Train loss: 0.0096
2023-02-06 14:32:28 | Train | Epoch[331/600] Iteration[008/030] Train loss: 0.0096
2023-02-06 14:32:29 | Train | Epoch[331/600] Iteration[009/030] Train loss: 0.0097
2023-02-06 14:32:29 | Train | Epoch[331/600] Iteration[010/030] Train loss: 0.0098
2023-02-06 14:32:29 | Train | Epoch[331/600] Iteration[011/030] Train loss: 0.0098
2023-02-06 14:32:29 | Train | Epoch[331/600] Iteration[012/030] Train loss: 0.0098
2023-02-06 14:32:29 | Train | Epoch[331/600] Iteration[013/030] Train loss: 0.0102
2023-02-06 14:32:30 | Train | Epoch[331/600] Iteration[014/030] Train loss: 0.0103
2023-02-06 14:32:30 | Train | Epoch[331/600] Iteration[015/030] Train loss: 0.0103
2023-02-06 14:32:30 | Train | Epoch[331/600] Iteration[016/030] Train loss: 0.0103
2023-02-06 14:32:30 | Train | Epoch[331/600] Iteration[017/030] Train loss: 0.0104
2023-02-06 14:32:31 | Train | Epoch[331/600] Iteration[018/030] Train loss: 0.0103
2023-02-06 14:32:31 | Train | Epoch[331/600] Iteration[019/030] Train loss: 0.0103
2023-02-06 14:32:31 | Train | Epoch[331/600] Iteration[020/030] Train loss: 0.0103
2023-02-06 14:32:31 | Train | Epoch[331/600] Iteration[021/030] Train loss: 0.0102
2023-02-06 14:32:31 | Train | Epoch[331/600] Iteration[022/030] Train loss: 0.0102
2023-02-06 14:32:32 | Train | Epoch[331/600] Iteration[023/030] Train loss: 0.0102
2023-02-06 14:32:32 | Train | Epoch[331/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:32:32 | Train | Epoch[331/600] Iteration[025/030] Train loss: 0.0104
2023-02-06 14:32:32 | Train | Epoch[331/600] Iteration[026/030] Train loss: 0.0104
2023-02-06 14:32:33 | Train | Epoch[331/600] Iteration[027/030] Train loss: 0.0104
2023-02-06 14:32:33 | Train | Epoch[331/600] Iteration[028/030] Train loss: 0.0103
2023-02-06 14:32:33 | Train | Epoch[331/600] Iteration[029/030] Train loss: 0.0103
2023-02-06 14:32:33 | Train | Epoch[331/600] Iteration[030/030] Train loss: 0.0103
2023-02-06 14:32:33 | Valid | Epoch[331/600] Iteration[001/008] Valid loss: 0.1507
2023-02-06 14:32:33 | Valid | Epoch[331/600] Iteration[002/008] Valid loss: 0.1182
2023-02-06 14:32:34 | Valid | Epoch[331/600] Iteration[003/008] Valid loss: 0.1170
2023-02-06 14:32:34 | Valid | Epoch[331/600] Iteration[004/008] Valid loss: 0.1180
2023-02-06 14:32:34 | Valid | Epoch[331/600] Iteration[005/008] Valid loss: 0.1153
2023-02-06 14:32:34 | Valid | Epoch[331/600] Iteration[006/008] Valid loss: 0.1167
2023-02-06 14:32:34 | Valid | Epoch[331/600] Iteration[007/008] Valid loss: 0.1237
2023-02-06 14:32:34 | Valid | Epoch[331/600] Iteration[008/008] Valid loss: 0.1185
2023-02-06 14:32:34 | Valid | Epoch[331/600] MIou: 0.9255193387375333
2023-02-06 14:32:34 | Valid | Epoch[331/600] Pixel Accuracy: 0.9871050516764323
2023-02-06 14:32:34 | Valid | Epoch[331/600] Mean Pixel Accuracy: 0.9548822383156679
2023-02-06 14:32:34 | Stage | Epoch[331/600] Train loss:0.0103
2023-02-06 14:32:34 | Stage | Epoch[331/600] Valid loss:0.1185
2023-02-06 14:32:34 | Stage | Epoch[331/600] LR:0.01

2023-02-06 14:32:34 | Train | Epoch[332/600] Iteration[001/030] Train loss: 0.0094
2023-02-06 14:32:35 | Train | Epoch[332/600] Iteration[002/030] Train loss: 0.0101
2023-02-06 14:32:35 | Train | Epoch[332/600] Iteration[003/030] Train loss: 0.0094
2023-02-06 14:32:35 | Train | Epoch[332/600] Iteration[004/030] Train loss: 0.0096
2023-02-06 14:32:35 | Train | Epoch[332/600] Iteration[005/030] Train loss: 0.0098
2023-02-06 14:32:35 | Train | Epoch[332/600] Iteration[006/030] Train loss: 0.0097
2023-02-06 14:32:36 | Train | Epoch[332/600] Iteration[007/030] Train loss: 0.0096
2023-02-06 14:32:36 | Train | Epoch[332/600] Iteration[008/030] Train loss: 0.0095
2023-02-06 14:32:36 | Train | Epoch[332/600] Iteration[009/030] Train loss: 0.0096
2023-02-06 14:32:36 | Train | Epoch[332/600] Iteration[010/030] Train loss: 0.0098
2023-02-06 14:32:37 | Train | Epoch[332/600] Iteration[011/030] Train loss: 0.0098
2023-02-06 14:32:37 | Train | Epoch[332/600] Iteration[012/030] Train loss: 0.0098
2023-02-06 14:32:37 | Train | Epoch[332/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:32:37 | Train | Epoch[332/600] Iteration[014/030] Train loss: 0.0098
2023-02-06 14:32:37 | Train | Epoch[332/600] Iteration[015/030] Train loss: 0.0098
2023-02-06 14:32:38 | Train | Epoch[332/600] Iteration[016/030] Train loss: 0.0099
2023-02-06 14:32:38 | Train | Epoch[332/600] Iteration[017/030] Train loss: 0.0099
2023-02-06 14:32:38 | Train | Epoch[332/600] Iteration[018/030] Train loss: 0.0099
2023-02-06 14:32:38 | Train | Epoch[332/600] Iteration[019/030] Train loss: 0.0099
2023-02-06 14:32:39 | Train | Epoch[332/600] Iteration[020/030] Train loss: 0.0103
2023-02-06 14:32:39 | Train | Epoch[332/600] Iteration[021/030] Train loss: 0.0103
2023-02-06 14:32:39 | Train | Epoch[332/600] Iteration[022/030] Train loss: 0.0103
2023-02-06 14:32:39 | Train | Epoch[332/600] Iteration[023/030] Train loss: 0.0103
2023-02-06 14:32:39 | Train | Epoch[332/600] Iteration[024/030] Train loss: 0.0104
2023-02-06 14:32:40 | Train | Epoch[332/600] Iteration[025/030] Train loss: 0.0104
2023-02-06 14:32:40 | Train | Epoch[332/600] Iteration[026/030] Train loss: 0.0104
2023-02-06 14:32:40 | Train | Epoch[332/600] Iteration[027/030] Train loss: 0.0104
2023-02-06 14:32:40 | Train | Epoch[332/600] Iteration[028/030] Train loss: 0.0104
2023-02-06 14:32:41 | Train | Epoch[332/600] Iteration[029/030] Train loss: 0.0104
2023-02-06 14:32:41 | Train | Epoch[332/600] Iteration[030/030] Train loss: 0.0105
2023-02-06 14:32:41 | Valid | Epoch[332/600] Iteration[001/008] Valid loss: 0.1286
2023-02-06 14:32:41 | Valid | Epoch[332/600] Iteration[002/008] Valid loss: 0.0917
2023-02-06 14:32:41 | Valid | Epoch[332/600] Iteration[003/008] Valid loss: 0.0869
2023-02-06 14:32:41 | Valid | Epoch[332/600] Iteration[004/008] Valid loss: 0.0807
2023-02-06 14:32:41 | Valid | Epoch[332/600] Iteration[005/008] Valid loss: 0.0797
2023-02-06 14:32:41 | Valid | Epoch[332/600] Iteration[006/008] Valid loss: 0.0772
2023-02-06 14:32:41 | Valid | Epoch[332/600] Iteration[007/008] Valid loss: 0.0787
2023-02-06 14:32:41 | Valid | Epoch[332/600] Iteration[008/008] Valid loss: 0.0765
2023-02-06 14:32:41 | Valid | Epoch[332/600] MIou: 0.9145925145549623
2023-02-06 14:32:41 | Valid | Epoch[332/600] Pixel Accuracy: 0.9854393005371094
2023-02-06 14:32:41 | Valid | Epoch[332/600] Mean Pixel Accuracy: 0.9374560826294723
2023-02-06 14:32:41 | Stage | Epoch[332/600] Train loss:0.0105
2023-02-06 14:32:41 | Stage | Epoch[332/600] Valid loss:0.0765
2023-02-06 14:32:41 | Stage | Epoch[332/600] LR:0.01

2023-02-06 14:32:42 | Train | Epoch[333/600] Iteration[001/030] Train loss: 0.0086
2023-02-06 14:32:42 | Train | Epoch[333/600] Iteration[002/030] Train loss: 0.0092
2023-02-06 14:32:42 | Train | Epoch[333/600] Iteration[003/030] Train loss: 0.0095
2023-02-06 14:32:42 | Train | Epoch[333/600] Iteration[004/030] Train loss: 0.0095
2023-02-06 14:32:43 | Train | Epoch[333/600] Iteration[005/030] Train loss: 0.0097
2023-02-06 14:32:43 | Train | Epoch[333/600] Iteration[006/030] Train loss: 0.0094
2023-02-06 14:32:43 | Train | Epoch[333/600] Iteration[007/030] Train loss: 0.0096
2023-02-06 14:32:43 | Train | Epoch[333/600] Iteration[008/030] Train loss: 0.0097
2023-02-06 14:32:44 | Train | Epoch[333/600] Iteration[009/030] Train loss: 0.0097
2023-02-06 14:32:44 | Train | Epoch[333/600] Iteration[010/030] Train loss: 0.0096
2023-02-06 14:32:44 | Train | Epoch[333/600] Iteration[011/030] Train loss: 0.0096
2023-02-06 14:32:44 | Train | Epoch[333/600] Iteration[012/030] Train loss: 0.0095
2023-02-06 14:32:44 | Train | Epoch[333/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:32:45 | Train | Epoch[333/600] Iteration[014/030] Train loss: 0.0098
2023-02-06 14:32:45 | Train | Epoch[333/600] Iteration[015/030] Train loss: 0.0097
2023-02-06 14:32:45 | Train | Epoch[333/600] Iteration[016/030] Train loss: 0.0097
2023-02-06 14:32:45 | Train | Epoch[333/600] Iteration[017/030] Train loss: 0.0098
2023-02-06 14:32:46 | Train | Epoch[333/600] Iteration[018/030] Train loss: 0.0098
2023-02-06 14:32:46 | Train | Epoch[333/600] Iteration[019/030] Train loss: 0.0098
2023-02-06 14:32:46 | Train | Epoch[333/600] Iteration[020/030] Train loss: 0.0100
2023-02-06 14:32:46 | Train | Epoch[333/600] Iteration[021/030] Train loss: 0.0099
2023-02-06 14:32:46 | Train | Epoch[333/600] Iteration[022/030] Train loss: 0.0100
2023-02-06 14:32:47 | Train | Epoch[333/600] Iteration[023/030] Train loss: 0.0100
2023-02-06 14:32:47 | Train | Epoch[333/600] Iteration[024/030] Train loss: 0.0100
2023-02-06 14:32:47 | Train | Epoch[333/600] Iteration[025/030] Train loss: 0.0100
2023-02-06 14:32:47 | Train | Epoch[333/600] Iteration[026/030] Train loss: 0.0100
2023-02-06 14:32:48 | Train | Epoch[333/600] Iteration[027/030] Train loss: 0.0100
2023-02-06 14:32:48 | Train | Epoch[333/600] Iteration[028/030] Train loss: 0.0101
2023-02-06 14:32:48 | Train | Epoch[333/600] Iteration[029/030] Train loss: 0.0102
2023-02-06 14:32:48 | Train | Epoch[333/600] Iteration[030/030] Train loss: 0.0102
2023-02-06 14:32:48 | Valid | Epoch[333/600] Iteration[001/008] Valid loss: 0.8446
2023-02-06 14:32:49 | Valid | Epoch[333/600] Iteration[002/008] Valid loss: 0.8066
2023-02-06 14:32:49 | Valid | Epoch[333/600] Iteration[003/008] Valid loss: 0.8318
2023-02-06 14:32:49 | Valid | Epoch[333/600] Iteration[004/008] Valid loss: 0.8347
2023-02-06 14:32:49 | Valid | Epoch[333/600] Iteration[005/008] Valid loss: 0.8689
2023-02-06 14:32:49 | Valid | Epoch[333/600] Iteration[006/008] Valid loss: 0.8578
2023-02-06 14:32:49 | Valid | Epoch[333/600] Iteration[007/008] Valid loss: 0.9074
2023-02-06 14:32:49 | Valid | Epoch[333/600] Iteration[008/008] Valid loss: 0.9493
2023-02-06 14:32:49 | Valid | Epoch[333/600] MIou: 0.8727966388313222
2023-02-06 14:32:49 | Valid | Epoch[333/600] Pixel Accuracy: 0.9738883972167969
2023-02-06 14:32:49 | Valid | Epoch[333/600] Mean Pixel Accuracy: 0.9819007308137883
2023-02-06 14:32:49 | Stage | Epoch[333/600] Train loss:0.0102
2023-02-06 14:32:49 | Stage | Epoch[333/600] Valid loss:0.9493
2023-02-06 14:32:49 | Stage | Epoch[333/600] LR:0.01

2023-02-06 14:32:49 | Train | Epoch[334/600] Iteration[001/030] Train loss: 0.0096
2023-02-06 14:32:50 | Train | Epoch[334/600] Iteration[002/030] Train loss: 0.0097
2023-02-06 14:32:50 | Train | Epoch[334/600] Iteration[003/030] Train loss: 0.0097
2023-02-06 14:32:50 | Train | Epoch[334/600] Iteration[004/030] Train loss: 0.0099
2023-02-06 14:32:50 | Train | Epoch[334/600] Iteration[005/030] Train loss: 0.0095
2023-02-06 14:32:50 | Train | Epoch[334/600] Iteration[006/030] Train loss: 0.0096
2023-02-06 14:32:51 | Train | Epoch[334/600] Iteration[007/030] Train loss: 0.0099
2023-02-06 14:32:51 | Train | Epoch[334/600] Iteration[008/030] Train loss: 0.0098
2023-02-06 14:32:51 | Train | Epoch[334/600] Iteration[009/030] Train loss: 0.0098
2023-02-06 14:32:51 | Train | Epoch[334/600] Iteration[010/030] Train loss: 0.0101
2023-02-06 14:32:52 | Train | Epoch[334/600] Iteration[011/030] Train loss: 0.0102
2023-02-06 14:32:52 | Train | Epoch[334/600] Iteration[012/030] Train loss: 0.0102
2023-02-06 14:32:52 | Train | Epoch[334/600] Iteration[013/030] Train loss: 0.0102
2023-02-06 14:32:52 | Train | Epoch[334/600] Iteration[014/030] Train loss: 0.0102
2023-02-06 14:32:52 | Train | Epoch[334/600] Iteration[015/030] Train loss: 0.0102
2023-02-06 14:32:53 | Train | Epoch[334/600] Iteration[016/030] Train loss: 0.0102
2023-02-06 14:32:53 | Train | Epoch[334/600] Iteration[017/030] Train loss: 0.0101
2023-02-06 14:32:53 | Train | Epoch[334/600] Iteration[018/030] Train loss: 0.0101
2023-02-06 14:32:53 | Train | Epoch[334/600] Iteration[019/030] Train loss: 0.0100
2023-02-06 14:32:54 | Train | Epoch[334/600] Iteration[020/030] Train loss: 0.0100
2023-02-06 14:32:54 | Train | Epoch[334/600] Iteration[021/030] Train loss: 0.0101
2023-02-06 14:32:54 | Train | Epoch[334/600] Iteration[022/030] Train loss: 0.0101
2023-02-06 14:32:54 | Train | Epoch[334/600] Iteration[023/030] Train loss: 0.0101
2023-02-06 14:32:54 | Train | Epoch[334/600] Iteration[024/030] Train loss: 0.0102
2023-02-06 14:32:55 | Train | Epoch[334/600] Iteration[025/030] Train loss: 0.0103
2023-02-06 14:32:55 | Train | Epoch[334/600] Iteration[026/030] Train loss: 0.0103
2023-02-06 14:32:55 | Train | Epoch[334/600] Iteration[027/030] Train loss: 0.0103
2023-02-06 14:32:55 | Train | Epoch[334/600] Iteration[028/030] Train loss: 0.0103
2023-02-06 14:32:56 | Train | Epoch[334/600] Iteration[029/030] Train loss: 0.0104
2023-02-06 14:32:56 | Train | Epoch[334/600] Iteration[030/030] Train loss: 0.0104
2023-02-06 14:32:56 | Valid | Epoch[334/600] Iteration[001/008] Valid loss: 0.4718
2023-02-06 14:32:56 | Valid | Epoch[334/600] Iteration[002/008] Valid loss: 0.4084
2023-02-06 14:32:56 | Valid | Epoch[334/600] Iteration[003/008] Valid loss: 0.4080
2023-02-06 14:32:56 | Valid | Epoch[334/600] Iteration[004/008] Valid loss: 0.3967
2023-02-06 14:32:56 | Valid | Epoch[334/600] Iteration[005/008] Valid loss: 0.4098
2023-02-06 14:32:56 | Valid | Epoch[334/600] Iteration[006/008] Valid loss: 0.4074
2023-02-06 14:32:56 | Valid | Epoch[334/600] Iteration[007/008] Valid loss: 0.4364
2023-02-06 14:32:56 | Valid | Epoch[334/600] Iteration[008/008] Valid loss: 0.4459
2023-02-06 14:32:56 | Valid | Epoch[334/600] MIou: 0.9126714699950159
2023-02-06 14:32:56 | Valid | Epoch[334/600] Pixel Accuracy: 0.9835980733235677
2023-02-06 14:32:56 | Valid | Epoch[334/600] Mean Pixel Accuracy: 0.9808780899831238
2023-02-06 14:32:56 | Stage | Epoch[334/600] Train loss:0.0104
2023-02-06 14:32:56 | Stage | Epoch[334/600] Valid loss:0.4459
2023-02-06 14:32:56 | Stage | Epoch[334/600] LR:0.01

2023-02-06 14:32:57 | Train | Epoch[335/600] Iteration[001/030] Train loss: 0.0098
2023-02-06 14:32:57 | Train | Epoch[335/600] Iteration[002/030] Train loss: 0.0095
2023-02-06 14:32:57 | Train | Epoch[335/600] Iteration[003/030] Train loss: 0.0096
2023-02-06 14:32:58 | Train | Epoch[335/600] Iteration[004/030] Train loss: 0.0096
2023-02-06 14:32:58 | Train | Epoch[335/600] Iteration[005/030] Train loss: 0.0096
2023-02-06 14:32:58 | Train | Epoch[335/600] Iteration[006/030] Train loss: 0.0097
2023-02-06 14:32:58 | Train | Epoch[335/600] Iteration[007/030] Train loss: 0.0099
2023-02-06 14:32:58 | Train | Epoch[335/600] Iteration[008/030] Train loss: 0.0099
2023-02-06 14:32:59 | Train | Epoch[335/600] Iteration[009/030] Train loss: 0.0099
2023-02-06 14:32:59 | Train | Epoch[335/600] Iteration[010/030] Train loss: 0.0099
2023-02-06 14:32:59 | Train | Epoch[335/600] Iteration[011/030] Train loss: 0.0098
2023-02-06 14:32:59 | Train | Epoch[335/600] Iteration[012/030] Train loss: 0.0098
2023-02-06 14:33:00 | Train | Epoch[335/600] Iteration[013/030] Train loss: 0.0098
2023-02-06 14:33:00 | Train | Epoch[335/600] Iteration[014/030] Train loss: 0.0099
2023-02-06 14:33:00 | Train | Epoch[335/600] Iteration[015/030] Train loss: 0.0099
2023-02-06 14:33:00 | Train | Epoch[335/600] Iteration[016/030] Train loss: 0.0098
2023-02-06 14:33:00 | Train | Epoch[335/600] Iteration[017/030] Train loss: 0.0098
2023-02-06 14:33:01 | Train | Epoch[335/600] Iteration[018/030] Train loss: 0.0099
2023-02-06 14:33:01 | Train | Epoch[335/600] Iteration[019/030] Train loss: 0.0099
2023-02-06 14:33:01 | Train | Epoch[335/600] Iteration[020/030] Train loss: 0.0099
2023-02-06 14:33:01 | Train | Epoch[335/600] Iteration[021/030] Train loss: 0.0099
2023-02-06 14:33:02 | Train | Epoch[335/600] Iteration[022/030] Train loss: 0.0099
2023-02-06 14:33:02 | Train | Epoch[335/600] Iteration[023/030] Train loss: 0.0099
2023-02-06 14:33:02 | Train | Epoch[335/600] Iteration[024/030] Train loss: 0.0099
2023-02-06 14:33:02 | Train | Epoch[335/600] Iteration[025/030] Train loss: 0.0100
2023-02-06 14:33:02 | Train | Epoch[335/600] Iteration[026/030] Train loss: 0.0100
2023-02-06 14:33:03 | Train | Epoch[335/600] Iteration[027/030] Train loss: 0.0100
2023-02-06 14:33:03 | Train | Epoch[335/600] Iteration[028/030] Train loss: 0.0100
2023-02-06 14:33:03 | Train | Epoch[335/600] Iteration[029/030] Train loss: 0.0101
2023-02-06 14:33:03 | Train | Epoch[335/600] Iteration[030/030] Train loss: 0.0100
2023-02-06 14:33:04 | Valid | Epoch[335/600] Iteration[001/008] Valid loss: 1.1426
2023-02-06 14:33:04 | Valid | Epoch[335/600] Iteration[002/008] Valid loss: 1.1232
2023-02-06 14:33:04 | Valid | Epoch[335/600] Iteration[003/008] Valid loss: 1.1620
2023-02-06 14:33:04 | Valid | Epoch[335/600] Iteration[004/008] Valid loss: 1.1696
2023-02-06 14:33:04 | Valid | Epoch[335/600] Iteration[005/008] Valid loss: 1.2257
2023-02-06 14:33:04 | Valid | Epoch[335/600] Iteration[006/008] Valid loss: 1.2121
2023-02-06 14:33:04 | Valid | Epoch[335/600] Iteration[007/008] Valid loss: 1.2789
2023-02-06 14:33:04 | Valid | Epoch[335/600] Iteration[008/008] Valid loss: 1.3325
2023-02-06 14:33:04 | Valid | Epoch[335/600] MIou: 0.8493008626359523
2023-02-06 14:33:04 | Valid | Epoch[335/600] Pixel Accuracy: 0.967535654703776
2023-02-06 14:33:04 | Valid | Epoch[335/600] Mean Pixel Accuracy: 0.9790937635140213
2023-02-06 14:33:04 | Stage | Epoch[335/600] Train loss:0.0100
2023-02-06 14:33:04 | Stage | Epoch[335/600] Valid loss:1.3325
2023-02-06 14:33:04 | Stage | Epoch[335/600] LR:0.01

2023-02-06 14:33:04 | Train | Epoch[336/600] Iteration[001/030] Train loss: 0.0079
2023-02-06 14:33:05 | Train | Epoch[336/600] Iteration[002/030] Train loss: 0.0096
2023-02-06 14:33:05 | Train | Epoch[336/600] Iteration[003/030] Train loss: 0.0093
2023-02-06 14:33:05 | Train | Epoch[336/600] Iteration[004/030] Train loss: 0.0092
2023-02-06 14:33:05 | Train | Epoch[336/600] Iteration[005/030] Train loss: 0.0094
2023-02-06 14:33:06 | Train | Epoch[336/600] Iteration[006/030] Train loss: 0.0097
2023-02-06 14:33:06 | Train | Epoch[336/600] Iteration[007/030] Train loss: 0.0100
2023-02-06 14:33:06 | Train | Epoch[336/600] Iteration[008/030] Train loss: 0.0100
2023-02-06 14:33:06 | Train | Epoch[336/600] Iteration[009/030] Train loss: 0.0100
2023-02-06 14:33:06 | Train | Epoch[336/600] Iteration[010/030] Train loss: 0.0099
2023-02-06 14:33:07 | Train | Epoch[336/600] Iteration[011/030] Train loss: 0.0099
2023-02-06 14:33:07 | Train | Epoch[336/600] Iteration[012/030] Train loss: 0.0099
2023-02-06 14:33:07 | Train | Epoch[336/600] Iteration[013/030] Train loss: 0.0098
2023-02-06 14:33:07 | Train | Epoch[336/600] Iteration[014/030] Train loss: 0.0098
2023-02-06 14:33:08 | Train | Epoch[336/600] Iteration[015/030] Train loss: 0.0099
2023-02-06 14:33:08 | Train | Epoch[336/600] Iteration[016/030] Train loss: 0.0099
2023-02-06 14:33:08 | Train | Epoch[336/600] Iteration[017/030] Train loss: 0.0099
2023-02-06 14:33:08 | Train | Epoch[336/600] Iteration[018/030] Train loss: 0.0098
2023-02-06 14:33:08 | Train | Epoch[336/600] Iteration[019/030] Train loss: 0.0099
2023-02-06 14:33:09 | Train | Epoch[336/600] Iteration[020/030] Train loss: 0.0099
2023-02-06 14:33:09 | Train | Epoch[336/600] Iteration[021/030] Train loss: 0.0101
2023-02-06 14:33:09 | Train | Epoch[336/600] Iteration[022/030] Train loss: 0.0101
2023-02-06 14:33:09 | Train | Epoch[336/600] Iteration[023/030] Train loss: 0.0100
2023-02-06 14:33:10 | Train | Epoch[336/600] Iteration[024/030] Train loss: 0.0101
2023-02-06 14:33:10 | Train | Epoch[336/600] Iteration[025/030] Train loss: 0.0101
2023-02-06 14:33:10 | Train | Epoch[336/600] Iteration[026/030] Train loss: 0.0101
2023-02-06 14:33:10 | Train | Epoch[336/600] Iteration[027/030] Train loss: 0.0101
2023-02-06 14:33:10 | Train | Epoch[336/600] Iteration[028/030] Train loss: 0.0101
2023-02-06 14:33:11 | Train | Epoch[336/600] Iteration[029/030] Train loss: 0.0101
2023-02-06 14:33:11 | Train | Epoch[336/600] Iteration[030/030] Train loss: 0.0102
2023-02-06 14:33:11 | Valid | Epoch[336/600] Iteration[001/008] Valid loss: 0.0890
2023-02-06 14:33:11 | Valid | Epoch[336/600] Iteration[002/008] Valid loss: 0.0757
2023-02-06 14:33:11 | Valid | Epoch[336/600] Iteration[003/008] Valid loss: 0.0753
2023-02-06 14:33:11 | Valid | Epoch[336/600] Iteration[004/008] Valid loss: 0.0729
2023-02-06 14:33:11 | Valid | Epoch[336/600] Iteration[005/008] Valid loss: 0.0727
2023-02-06 14:33:11 | Valid | Epoch[336/600] Iteration[006/008] Valid loss: 0.0699
2023-02-06 14:33:11 | Valid | Epoch[336/600] Iteration[007/008] Valid loss: 0.0672
2023-02-06 14:33:11 | Valid | Epoch[336/600] Iteration[008/008] Valid loss: 0.0664
2023-02-06 14:33:12 | Valid | Epoch[336/600] MIou: 0.8760166020797524
2023-02-06 14:33:12 | Valid | Epoch[336/600] Pixel Accuracy: 0.9793841044108073
2023-02-06 14:33:12 | Valid | Epoch[336/600] Mean Pixel Accuracy: 0.8908097872200587
2023-02-06 14:33:12 | Stage | Epoch[336/600] Train loss:0.0102
2023-02-06 14:33:12 | Stage | Epoch[336/600] Valid loss:0.0664
2023-02-06 14:33:12 | Stage | Epoch[336/600] LR:0.01

2023-02-06 14:33:12 | Train | Epoch[337/600] Iteration[001/030] Train loss: 0.0098
2023-02-06 14:33:12 | Train | Epoch[337/600] Iteration[002/030] Train loss: 0.0105
2023-02-06 14:33:12 | Train | Epoch[337/600] Iteration[003/030] Train loss: 0.0101
2023-02-06 14:33:13 | Train | Epoch[337/600] Iteration[004/030] Train loss: 0.0102
2023-02-06 14:33:13 | Train | Epoch[337/600] Iteration[005/030] Train loss: 0.0101
2023-02-06 14:33:13 | Train | Epoch[337/600] Iteration[006/030] Train loss: 0.0100
2023-02-06 14:33:13 | Train | Epoch[337/600] Iteration[007/030] Train loss: 0.0101
2023-02-06 14:33:14 | Train | Epoch[337/600] Iteration[008/030] Train loss: 0.0108
2023-02-06 14:33:14 | Train | Epoch[337/600] Iteration[009/030] Train loss: 0.0110
2023-02-06 14:33:14 | Train | Epoch[337/600] Iteration[010/030] Train loss: 0.0108
2023-02-06 14:33:14 | Train | Epoch[337/600] Iteration[011/030] Train loss: 0.0107
2023-02-06 14:33:14 | Train | Epoch[337/600] Iteration[012/030] Train loss: 0.0107
2023-02-06 14:33:15 | Train | Epoch[337/600] Iteration[013/030] Train loss: 0.0106
2023-02-06 14:33:15 | Train | Epoch[337/600] Iteration[014/030] Train loss: 0.0105
2023-02-06 14:33:15 | Train | Epoch[337/600] Iteration[015/030] Train loss: 0.0104
2023-02-06 14:33:15 | Train | Epoch[337/600] Iteration[016/030] Train loss: 0.0104
2023-02-06 14:33:16 | Train | Epoch[337/600] Iteration[017/030] Train loss: 0.0104
2023-02-06 14:33:16 | Train | Epoch[337/600] Iteration[018/030] Train loss: 0.0105
2023-02-06 14:33:16 | Train | Epoch[337/600] Iteration[019/030] Train loss: 0.0106
2023-02-06 14:33:16 | Train | Epoch[337/600] Iteration[020/030] Train loss: 0.0105
2023-02-06 14:33:16 | Train | Epoch[337/600] Iteration[021/030] Train loss: 0.0104
2023-02-06 14:33:17 | Train | Epoch[337/600] Iteration[022/030] Train loss: 0.0104
2023-02-06 14:33:17 | Train | Epoch[337/600] Iteration[023/030] Train loss: 0.0104
2023-02-06 14:33:17 | Train | Epoch[337/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:33:17 | Train | Epoch[337/600] Iteration[025/030] Train loss: 0.0103
2023-02-06 14:33:17 | Train | Epoch[337/600] Iteration[026/030] Train loss: 0.0103
2023-02-06 14:33:18 | Train | Epoch[337/600] Iteration[027/030] Train loss: 0.0103
2023-02-06 14:33:18 | Train | Epoch[337/600] Iteration[028/030] Train loss: 0.0103
2023-02-06 14:33:18 | Train | Epoch[337/600] Iteration[029/030] Train loss: 0.0102
2023-02-06 14:33:18 | Train | Epoch[337/600] Iteration[030/030] Train loss: 0.0102
2023-02-06 14:33:19 | Valid | Epoch[337/600] Iteration[001/008] Valid loss: 0.0827
2023-02-06 14:33:19 | Valid | Epoch[337/600] Iteration[002/008] Valid loss: 0.0760
2023-02-06 14:33:19 | Valid | Epoch[337/600] Iteration[003/008] Valid loss: 0.0778
2023-02-06 14:33:19 | Valid | Epoch[337/600] Iteration[004/008] Valid loss: 0.0757
2023-02-06 14:33:19 | Valid | Epoch[337/600] Iteration[005/008] Valid loss: 0.0755
2023-02-06 14:33:19 | Valid | Epoch[337/600] Iteration[006/008] Valid loss: 0.0727
2023-02-06 14:33:19 | Valid | Epoch[337/600] Iteration[007/008] Valid loss: 0.0699
2023-02-06 14:33:19 | Valid | Epoch[337/600] Iteration[008/008] Valid loss: 0.0693
2023-02-06 14:33:19 | Valid | Epoch[337/600] MIou: 0.8634117622467898
2023-02-06 14:33:19 | Valid | Epoch[337/600] Pixel Accuracy: 0.9773991902669271
2023-02-06 14:33:19 | Valid | Epoch[337/600] Mean Pixel Accuracy: 0.8772597672308046
2023-02-06 14:33:19 | Stage | Epoch[337/600] Train loss:0.0102
2023-02-06 14:33:19 | Stage | Epoch[337/600] Valid loss:0.0693
2023-02-06 14:33:19 | Stage | Epoch[337/600] LR:0.01

2023-02-06 14:33:19 | Train | Epoch[338/600] Iteration[001/030] Train loss: 0.0088
2023-02-06 14:33:20 | Train | Epoch[338/600] Iteration[002/030] Train loss: 0.0099
2023-02-06 14:33:20 | Train | Epoch[338/600] Iteration[003/030] Train loss: 0.0105
2023-02-06 14:33:20 | Train | Epoch[338/600] Iteration[004/030] Train loss: 0.0101
2023-02-06 14:33:20 | Train | Epoch[338/600] Iteration[005/030] Train loss: 0.0103
2023-02-06 14:33:21 | Train | Epoch[338/600] Iteration[006/030] Train loss: 0.0102
2023-02-06 14:33:21 | Train | Epoch[338/600] Iteration[007/030] Train loss: 0.0102
2023-02-06 14:33:21 | Train | Epoch[338/600] Iteration[008/030] Train loss: 0.0103
2023-02-06 14:33:21 | Train | Epoch[338/600] Iteration[009/030] Train loss: 0.0105
2023-02-06 14:33:21 | Train | Epoch[338/600] Iteration[010/030] Train loss: 0.0104
2023-02-06 14:33:22 | Train | Epoch[338/600] Iteration[011/030] Train loss: 0.0102
2023-02-06 14:33:22 | Train | Epoch[338/600] Iteration[012/030] Train loss: 0.0103
2023-02-06 14:33:22 | Train | Epoch[338/600] Iteration[013/030] Train loss: 0.0104
2023-02-06 14:33:22 | Train | Epoch[338/600] Iteration[014/030] Train loss: 0.0104
2023-02-06 14:33:23 | Train | Epoch[338/600] Iteration[015/030] Train loss: 0.0104
2023-02-06 14:33:23 | Train | Epoch[338/600] Iteration[016/030] Train loss: 0.0104
2023-02-06 14:33:23 | Train | Epoch[338/600] Iteration[017/030] Train loss: 0.0104
2023-02-06 14:33:23 | Train | Epoch[338/600] Iteration[018/030] Train loss: 0.0103
2023-02-06 14:33:23 | Train | Epoch[338/600] Iteration[019/030] Train loss: 0.0103
2023-02-06 14:33:24 | Train | Epoch[338/600] Iteration[020/030] Train loss: 0.0104
2023-02-06 14:33:24 | Train | Epoch[338/600] Iteration[021/030] Train loss: 0.0104
2023-02-06 14:33:24 | Train | Epoch[338/600] Iteration[022/030] Train loss: 0.0104
2023-02-06 14:33:24 | Train | Epoch[338/600] Iteration[023/030] Train loss: 0.0104
2023-02-06 14:33:24 | Train | Epoch[338/600] Iteration[024/030] Train loss: 0.0105
2023-02-06 14:33:25 | Train | Epoch[338/600] Iteration[025/030] Train loss: 0.0105
2023-02-06 14:33:25 | Train | Epoch[338/600] Iteration[026/030] Train loss: 0.0106
2023-02-06 14:33:25 | Train | Epoch[338/600] Iteration[027/030] Train loss: 0.0107
2023-02-06 14:33:25 | Train | Epoch[338/600] Iteration[028/030] Train loss: 0.0106
2023-02-06 14:33:26 | Train | Epoch[338/600] Iteration[029/030] Train loss: 0.0107
2023-02-06 14:33:26 | Train | Epoch[338/600] Iteration[030/030] Train loss: 0.0106
2023-02-06 14:33:26 | Valid | Epoch[338/600] Iteration[001/008] Valid loss: 0.0952
2023-02-06 14:33:26 | Valid | Epoch[338/600] Iteration[002/008] Valid loss: 0.0878
2023-02-06 14:33:26 | Valid | Epoch[338/600] Iteration[003/008] Valid loss: 0.0928
2023-02-06 14:33:26 | Valid | Epoch[338/600] Iteration[004/008] Valid loss: 0.0898
2023-02-06 14:33:26 | Valid | Epoch[338/600] Iteration[005/008] Valid loss: 0.0894
2023-02-06 14:33:26 | Valid | Epoch[338/600] Iteration[006/008] Valid loss: 0.0897
2023-02-06 14:33:26 | Valid | Epoch[338/600] Iteration[007/008] Valid loss: 0.0909
2023-02-06 14:33:26 | Valid | Epoch[338/600] Iteration[008/008] Valid loss: 0.0910
2023-02-06 14:33:26 | Valid | Epoch[338/600] MIou: 0.8206236279436929
2023-02-06 14:33:26 | Valid | Epoch[338/600] Pixel Accuracy: 0.9697926839192709
2023-02-06 14:33:26 | Valid | Epoch[338/600] Mean Pixel Accuracy: 0.8436908214739933
2023-02-06 14:33:26 | Stage | Epoch[338/600] Train loss:0.0106
2023-02-06 14:33:26 | Stage | Epoch[338/600] Valid loss:0.0910
2023-02-06 14:33:26 | Stage | Epoch[338/600] LR:0.01

2023-02-06 14:33:27 | Train | Epoch[339/600] Iteration[001/030] Train loss: 0.0119
2023-02-06 14:33:27 | Train | Epoch[339/600] Iteration[002/030] Train loss: 0.0115
2023-02-06 14:33:27 | Train | Epoch[339/600] Iteration[003/030] Train loss: 0.0110
2023-02-06 14:33:28 | Train | Epoch[339/600] Iteration[004/030] Train loss: 0.0107
2023-02-06 14:33:28 | Train | Epoch[339/600] Iteration[005/030] Train loss: 0.0104
2023-02-06 14:33:28 | Train | Epoch[339/600] Iteration[006/030] Train loss: 0.0104
2023-02-06 14:33:28 | Train | Epoch[339/600] Iteration[007/030] Train loss: 0.0103
2023-02-06 14:33:28 | Train | Epoch[339/600] Iteration[008/030] Train loss: 0.0103
2023-02-06 14:33:29 | Train | Epoch[339/600] Iteration[009/030] Train loss: 0.0102
2023-02-06 14:33:29 | Train | Epoch[339/600] Iteration[010/030] Train loss: 0.0102
2023-02-06 14:33:29 | Train | Epoch[339/600] Iteration[011/030] Train loss: 0.0102
2023-02-06 14:33:29 | Train | Epoch[339/600] Iteration[012/030] Train loss: 0.0104
2023-02-06 14:33:30 | Train | Epoch[339/600] Iteration[013/030] Train loss: 0.0103
2023-02-06 14:33:30 | Train | Epoch[339/600] Iteration[014/030] Train loss: 0.0104
2023-02-06 14:33:30 | Train | Epoch[339/600] Iteration[015/030] Train loss: 0.0104
2023-02-06 14:33:30 | Train | Epoch[339/600] Iteration[016/030] Train loss: 0.0104
2023-02-06 14:33:30 | Train | Epoch[339/600] Iteration[017/030] Train loss: 0.0103
2023-02-06 14:33:31 | Train | Epoch[339/600] Iteration[018/030] Train loss: 0.0104
2023-02-06 14:33:31 | Train | Epoch[339/600] Iteration[019/030] Train loss: 0.0103
2023-02-06 14:33:31 | Train | Epoch[339/600] Iteration[020/030] Train loss: 0.0103
2023-02-06 14:33:31 | Train | Epoch[339/600] Iteration[021/030] Train loss: 0.0103
2023-02-06 14:33:32 | Train | Epoch[339/600] Iteration[022/030] Train loss: 0.0104
2023-02-06 14:33:32 | Train | Epoch[339/600] Iteration[023/030] Train loss: 0.0104
2023-02-06 14:33:32 | Train | Epoch[339/600] Iteration[024/030] Train loss: 0.0104
2023-02-06 14:33:32 | Train | Epoch[339/600] Iteration[025/030] Train loss: 0.0105
2023-02-06 14:33:32 | Train | Epoch[339/600] Iteration[026/030] Train loss: 0.0105
2023-02-06 14:33:33 | Train | Epoch[339/600] Iteration[027/030] Train loss: 0.0105
2023-02-06 14:33:33 | Train | Epoch[339/600] Iteration[028/030] Train loss: 0.0105
2023-02-06 14:33:33 | Train | Epoch[339/600] Iteration[029/030] Train loss: 0.0106
2023-02-06 14:33:33 | Train | Epoch[339/600] Iteration[030/030] Train loss: 0.0106
2023-02-06 14:33:34 | Valid | Epoch[339/600] Iteration[001/008] Valid loss: 0.4370
2023-02-06 14:33:34 | Valid | Epoch[339/600] Iteration[002/008] Valid loss: 0.4046
2023-02-06 14:33:34 | Valid | Epoch[339/600] Iteration[003/008] Valid loss: 0.4118
2023-02-06 14:33:34 | Valid | Epoch[339/600] Iteration[004/008] Valid loss: 0.4023
2023-02-06 14:33:34 | Valid | Epoch[339/600] Iteration[005/008] Valid loss: 0.4181
2023-02-06 14:33:34 | Valid | Epoch[339/600] Iteration[006/008] Valid loss: 0.4218
2023-02-06 14:33:34 | Valid | Epoch[339/600] Iteration[007/008] Valid loss: 0.4543
2023-02-06 14:33:34 | Valid | Epoch[339/600] Iteration[008/008] Valid loss: 0.4694
2023-02-06 14:33:34 | Valid | Epoch[339/600] MIou: 0.9021890072007306
2023-02-06 14:33:34 | Valid | Epoch[339/600] Pixel Accuracy: 0.9813982645670573
2023-02-06 14:33:34 | Valid | Epoch[339/600] Mean Pixel Accuracy: 0.9759788268509408
2023-02-06 14:33:34 | Stage | Epoch[339/600] Train loss:0.0106
2023-02-06 14:33:34 | Stage | Epoch[339/600] Valid loss:0.4694
2023-02-06 14:33:34 | Stage | Epoch[339/600] LR:0.01

2023-02-06 14:33:34 | Train | Epoch[340/600] Iteration[001/030] Train loss: 0.0112
2023-02-06 14:33:35 | Train | Epoch[340/600] Iteration[002/030] Train loss: 0.0106
2023-02-06 14:33:35 | Train | Epoch[340/600] Iteration[003/030] Train loss: 0.0101
2023-02-06 14:33:35 | Train | Epoch[340/600] Iteration[004/030] Train loss: 0.0102
2023-02-06 14:33:35 | Train | Epoch[340/600] Iteration[005/030] Train loss: 0.0102
2023-02-06 14:33:36 | Train | Epoch[340/600] Iteration[006/030] Train loss: 0.0105
2023-02-06 14:33:36 | Train | Epoch[340/600] Iteration[007/030] Train loss: 0.0103
2023-02-06 14:33:36 | Train | Epoch[340/600] Iteration[008/030] Train loss: 0.0102
2023-02-06 14:33:36 | Train | Epoch[340/600] Iteration[009/030] Train loss: 0.0104
2023-02-06 14:33:36 | Train | Epoch[340/600] Iteration[010/030] Train loss: 0.0103
2023-02-06 14:33:37 | Train | Epoch[340/600] Iteration[011/030] Train loss: 0.0102
2023-02-06 14:33:37 | Train | Epoch[340/600] Iteration[012/030] Train loss: 0.0102
2023-02-06 14:33:37 | Train | Epoch[340/600] Iteration[013/030] Train loss: 0.0102
2023-02-06 14:33:37 | Train | Epoch[340/600] Iteration[014/030] Train loss: 0.0102
2023-02-06 14:33:37 | Train | Epoch[340/600] Iteration[015/030] Train loss: 0.0102
2023-02-06 14:33:38 | Train | Epoch[340/600] Iteration[016/030] Train loss: 0.0102
2023-02-06 14:33:38 | Train | Epoch[340/600] Iteration[017/030] Train loss: 0.0103
2023-02-06 14:33:38 | Train | Epoch[340/600] Iteration[018/030] Train loss: 0.0103
2023-02-06 14:33:38 | Train | Epoch[340/600] Iteration[019/030] Train loss: 0.0104
2023-02-06 14:33:39 | Train | Epoch[340/600] Iteration[020/030] Train loss: 0.0105
2023-02-06 14:33:39 | Train | Epoch[340/600] Iteration[021/030] Train loss: 0.0105
2023-02-06 14:33:39 | Train | Epoch[340/600] Iteration[022/030] Train loss: 0.0105
2023-02-06 14:33:39 | Train | Epoch[340/600] Iteration[023/030] Train loss: 0.0105
2023-02-06 14:33:39 | Train | Epoch[340/600] Iteration[024/030] Train loss: 0.0105
2023-02-06 14:33:40 | Train | Epoch[340/600] Iteration[025/030] Train loss: 0.0105
2023-02-06 14:33:40 | Train | Epoch[340/600] Iteration[026/030] Train loss: 0.0105
2023-02-06 14:33:40 | Train | Epoch[340/600] Iteration[027/030] Train loss: 0.0105
2023-02-06 14:33:40 | Train | Epoch[340/600] Iteration[028/030] Train loss: 0.0108
2023-02-06 14:33:41 | Train | Epoch[340/600] Iteration[029/030] Train loss: 0.0108
2023-02-06 14:33:41 | Train | Epoch[340/600] Iteration[030/030] Train loss: 0.0108
2023-02-06 14:33:41 | Valid | Epoch[340/600] Iteration[001/008] Valid loss: 0.4602
2023-02-06 14:33:41 | Valid | Epoch[340/600] Iteration[002/008] Valid loss: 0.4140
2023-02-06 14:33:41 | Valid | Epoch[340/600] Iteration[003/008] Valid loss: 0.4181
2023-02-06 14:33:41 | Valid | Epoch[340/600] Iteration[004/008] Valid loss: 0.4109
2023-02-06 14:33:41 | Valid | Epoch[340/600] Iteration[005/008] Valid loss: 0.4210
2023-02-06 14:33:41 | Valid | Epoch[340/600] Iteration[006/008] Valid loss: 0.4194
2023-02-06 14:33:41 | Valid | Epoch[340/600] Iteration[007/008] Valid loss: 0.4496
2023-02-06 14:33:41 | Valid | Epoch[340/600] Iteration[008/008] Valid loss: 0.4702
2023-02-06 14:33:41 | Valid | Epoch[340/600] MIou: 0.9028255926246154
2023-02-06 14:33:41 | Valid | Epoch[340/600] Pixel Accuracy: 0.9813715616861979
2023-02-06 14:33:41 | Valid | Epoch[340/600] Mean Pixel Accuracy: 0.9806243963701489
2023-02-06 14:33:41 | Stage | Epoch[340/600] Train loss:0.0108
2023-02-06 14:33:41 | Stage | Epoch[340/600] Valid loss:0.4702
2023-02-06 14:33:41 | Stage | Epoch[340/600] LR:0.01

2023-02-06 14:33:42 | Train | Epoch[341/600] Iteration[001/030] Train loss: 0.0116
2023-02-06 14:33:42 | Train | Epoch[341/600] Iteration[002/030] Train loss: 0.0120
2023-02-06 14:33:42 | Train | Epoch[341/600] Iteration[003/030] Train loss: 0.0112
2023-02-06 14:33:43 | Train | Epoch[341/600] Iteration[004/030] Train loss: 0.0109
2023-02-06 14:33:43 | Train | Epoch[341/600] Iteration[005/030] Train loss: 0.0111
2023-02-06 14:33:43 | Train | Epoch[341/600] Iteration[006/030] Train loss: 0.0110
2023-02-06 14:33:43 | Train | Epoch[341/600] Iteration[007/030] Train loss: 0.0112
2023-02-06 14:33:43 | Train | Epoch[341/600] Iteration[008/030] Train loss: 0.0110
2023-02-06 14:33:44 | Train | Epoch[341/600] Iteration[009/030] Train loss: 0.0111
2023-02-06 14:33:44 | Train | Epoch[341/600] Iteration[010/030] Train loss: 0.0109
2023-02-06 14:33:44 | Train | Epoch[341/600] Iteration[011/030] Train loss: 0.0110
2023-02-06 14:33:44 | Train | Epoch[341/600] Iteration[012/030] Train loss: 0.0109
2023-02-06 14:33:45 | Train | Epoch[341/600] Iteration[013/030] Train loss: 0.0109
2023-02-06 14:33:45 | Train | Epoch[341/600] Iteration[014/030] Train loss: 0.0108
2023-02-06 14:33:45 | Train | Epoch[341/600] Iteration[015/030] Train loss: 0.0108
2023-02-06 14:33:45 | Train | Epoch[341/600] Iteration[016/030] Train loss: 0.0107
2023-02-06 14:33:45 | Train | Epoch[341/600] Iteration[017/030] Train loss: 0.0106
2023-02-06 14:33:46 | Train | Epoch[341/600] Iteration[018/030] Train loss: 0.0106
2023-02-06 14:33:46 | Train | Epoch[341/600] Iteration[019/030] Train loss: 0.0105
2023-02-06 14:33:46 | Train | Epoch[341/600] Iteration[020/030] Train loss: 0.0105
2023-02-06 14:33:46 | Train | Epoch[341/600] Iteration[021/030] Train loss: 0.0105
2023-02-06 14:33:47 | Train | Epoch[341/600] Iteration[022/030] Train loss: 0.0105
2023-02-06 14:33:47 | Train | Epoch[341/600] Iteration[023/030] Train loss: 0.0105
2023-02-06 14:33:47 | Train | Epoch[341/600] Iteration[024/030] Train loss: 0.0105
2023-02-06 14:33:47 | Train | Epoch[341/600] Iteration[025/030] Train loss: 0.0105
2023-02-06 14:33:47 | Train | Epoch[341/600] Iteration[026/030] Train loss: 0.0105
2023-02-06 14:33:48 | Train | Epoch[341/600] Iteration[027/030] Train loss: 0.0105
2023-02-06 14:33:48 | Train | Epoch[341/600] Iteration[028/030] Train loss: 0.0107
2023-02-06 14:33:48 | Train | Epoch[341/600] Iteration[029/030] Train loss: 0.0106
2023-02-06 14:33:48 | Train | Epoch[341/600] Iteration[030/030] Train loss: 0.0107
2023-02-06 14:33:49 | Valid | Epoch[341/600] Iteration[001/008] Valid loss: 0.1174
2023-02-06 14:33:49 | Valid | Epoch[341/600] Iteration[002/008] Valid loss: 0.1142
2023-02-06 14:33:49 | Valid | Epoch[341/600] Iteration[003/008] Valid loss: 0.1153
2023-02-06 14:33:49 | Valid | Epoch[341/600] Iteration[004/008] Valid loss: 0.1136
2023-02-06 14:33:49 | Valid | Epoch[341/600] Iteration[005/008] Valid loss: 0.1149
2023-02-06 14:33:49 | Valid | Epoch[341/600] Iteration[006/008] Valid loss: 0.1114
2023-02-06 14:33:49 | Valid | Epoch[341/600] Iteration[007/008] Valid loss: 0.1064
2023-02-06 14:33:49 | Valid | Epoch[341/600] Iteration[008/008] Valid loss: 0.1092
2023-02-06 14:33:49 | Valid | Epoch[341/600] MIou: 0.7633773953248552
2023-02-06 14:33:49 | Valid | Epoch[341/600] Pixel Accuracy: 0.9609464009602865
2023-02-06 14:33:49 | Valid | Epoch[341/600] Mean Pixel Accuracy: 0.784135619811692
2023-02-06 14:33:49 | Stage | Epoch[341/600] Train loss:0.0107
2023-02-06 14:33:49 | Stage | Epoch[341/600] Valid loss:0.1092
2023-02-06 14:33:49 | Stage | Epoch[341/600] LR:0.01

2023-02-06 14:33:49 | Train | Epoch[342/600] Iteration[001/030] Train loss: 0.0098
2023-02-06 14:33:50 | Train | Epoch[342/600] Iteration[002/030] Train loss: 0.0094
2023-02-06 14:33:50 | Train | Epoch[342/600] Iteration[003/030] Train loss: 0.0096
2023-02-06 14:33:50 | Train | Epoch[342/600] Iteration[004/030] Train loss: 0.0094
2023-02-06 14:33:50 | Train | Epoch[342/600] Iteration[005/030] Train loss: 0.0097
2023-02-06 14:33:51 | Train | Epoch[342/600] Iteration[006/030] Train loss: 0.0101
2023-02-06 14:33:51 | Train | Epoch[342/600] Iteration[007/030] Train loss: 0.0102
2023-02-06 14:33:51 | Train | Epoch[342/600] Iteration[008/030] Train loss: 0.0100
2023-02-06 14:33:51 | Train | Epoch[342/600] Iteration[009/030] Train loss: 0.0101
2023-02-06 14:33:51 | Train | Epoch[342/600] Iteration[010/030] Train loss: 0.0101
2023-02-06 14:33:52 | Train | Epoch[342/600] Iteration[011/030] Train loss: 0.0100
2023-02-06 14:33:52 | Train | Epoch[342/600] Iteration[012/030] Train loss: 0.0101
2023-02-06 14:33:52 | Train | Epoch[342/600] Iteration[013/030] Train loss: 0.0101
2023-02-06 14:33:52 | Train | Epoch[342/600] Iteration[014/030] Train loss: 0.0101
2023-02-06 14:33:53 | Train | Epoch[342/600] Iteration[015/030] Train loss: 0.0101
2023-02-06 14:33:53 | Train | Epoch[342/600] Iteration[016/030] Train loss: 0.0101
2023-02-06 14:33:53 | Train | Epoch[342/600] Iteration[017/030] Train loss: 0.0102
2023-02-06 14:33:53 | Train | Epoch[342/600] Iteration[018/030] Train loss: 0.0102
2023-02-06 14:33:53 | Train | Epoch[342/600] Iteration[019/030] Train loss: 0.0101
2023-02-06 14:33:54 | Train | Epoch[342/600] Iteration[020/030] Train loss: 0.0101
2023-02-06 14:33:54 | Train | Epoch[342/600] Iteration[021/030] Train loss: 0.0101
2023-02-06 14:33:54 | Train | Epoch[342/600] Iteration[022/030] Train loss: 0.0101
2023-02-06 14:33:54 | Train | Epoch[342/600] Iteration[023/030] Train loss: 0.0102
2023-02-06 14:33:54 | Train | Epoch[342/600] Iteration[024/030] Train loss: 0.0102
2023-02-06 14:33:55 | Train | Epoch[342/600] Iteration[025/030] Train loss: 0.0102
2023-02-06 14:33:55 | Train | Epoch[342/600] Iteration[026/030] Train loss: 0.0102
2023-02-06 14:33:55 | Train | Epoch[342/600] Iteration[027/030] Train loss: 0.0102
2023-02-06 14:33:55 | Train | Epoch[342/600] Iteration[028/030] Train loss: 0.0103
2023-02-06 14:33:56 | Train | Epoch[342/600] Iteration[029/030] Train loss: 0.0103
2023-02-06 14:33:56 | Train | Epoch[342/600] Iteration[030/030] Train loss: 0.0103
2023-02-06 14:33:56 | Valid | Epoch[342/600] Iteration[001/008] Valid loss: 0.1144
2023-02-06 14:33:56 | Valid | Epoch[342/600] Iteration[002/008] Valid loss: 0.1172
2023-02-06 14:33:56 | Valid | Epoch[342/600] Iteration[003/008] Valid loss: 0.1224
2023-02-06 14:33:56 | Valid | Epoch[342/600] Iteration[004/008] Valid loss: 0.1231
2023-02-06 14:33:56 | Valid | Epoch[342/600] Iteration[005/008] Valid loss: 0.1244
2023-02-06 14:33:56 | Valid | Epoch[342/600] Iteration[006/008] Valid loss: 0.1207
2023-02-06 14:33:56 | Valid | Epoch[342/600] Iteration[007/008] Valid loss: 0.1153
2023-02-06 14:33:56 | Valid | Epoch[342/600] Iteration[008/008] Valid loss: 0.1171
2023-02-06 14:33:56 | Valid | Epoch[342/600] MIou: 0.7504461654732973
2023-02-06 14:33:56 | Valid | Epoch[342/600] Pixel Accuracy: 0.9587961832682291
2023-02-06 14:33:56 | Valid | Epoch[342/600] Mean Pixel Accuracy: 0.772327138209325
2023-02-06 14:33:56 | Stage | Epoch[342/600] Train loss:0.0103
2023-02-06 14:33:56 | Stage | Epoch[342/600] Valid loss:0.1171
2023-02-06 14:33:56 | Stage | Epoch[342/600] LR:0.01

2023-02-06 14:33:57 | Train | Epoch[343/600] Iteration[001/030] Train loss: 0.0090
2023-02-06 14:33:57 | Train | Epoch[343/600] Iteration[002/030] Train loss: 0.0086
2023-02-06 14:33:57 | Train | Epoch[343/600] Iteration[003/030] Train loss: 0.0093
2023-02-06 14:33:58 | Train | Epoch[343/600] Iteration[004/030] Train loss: 0.0095
2023-02-06 14:33:58 | Train | Epoch[343/600] Iteration[005/030] Train loss: 0.0093
2023-02-06 14:33:58 | Train | Epoch[343/600] Iteration[006/030] Train loss: 0.0094
2023-02-06 14:33:58 | Train | Epoch[343/600] Iteration[007/030] Train loss: 0.0094
2023-02-06 14:33:58 | Train | Epoch[343/600] Iteration[008/030] Train loss: 0.0097
2023-02-06 14:33:59 | Train | Epoch[343/600] Iteration[009/030] Train loss: 0.0096
2023-02-06 14:33:59 | Train | Epoch[343/600] Iteration[010/030] Train loss: 0.0096
2023-02-06 14:33:59 | Train | Epoch[343/600] Iteration[011/030] Train loss: 0.0096
2023-02-06 14:33:59 | Train | Epoch[343/600] Iteration[012/030] Train loss: 0.0097
2023-02-06 14:34:00 | Train | Epoch[343/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:34:00 | Train | Epoch[343/600] Iteration[014/030] Train loss: 0.0097
2023-02-06 14:34:00 | Train | Epoch[343/600] Iteration[015/030] Train loss: 0.0097
2023-02-06 14:34:00 | Train | Epoch[343/600] Iteration[016/030] Train loss: 0.0097
2023-02-06 14:34:00 | Train | Epoch[343/600] Iteration[017/030] Train loss: 0.0098
2023-02-06 14:34:01 | Train | Epoch[343/600] Iteration[018/030] Train loss: 0.0098
2023-02-06 14:34:01 | Train | Epoch[343/600] Iteration[019/030] Train loss: 0.0098
2023-02-06 14:34:01 | Train | Epoch[343/600] Iteration[020/030] Train loss: 0.0098
2023-02-06 14:34:01 | Train | Epoch[343/600] Iteration[021/030] Train loss: 0.0098
2023-02-06 14:34:02 | Train | Epoch[343/600] Iteration[022/030] Train loss: 0.0099
2023-02-06 14:34:02 | Train | Epoch[343/600] Iteration[023/030] Train loss: 0.0099
2023-02-06 14:34:02 | Train | Epoch[343/600] Iteration[024/030] Train loss: 0.0099
2023-02-06 14:34:02 | Train | Epoch[343/600] Iteration[025/030] Train loss: 0.0098
2023-02-06 14:34:02 | Train | Epoch[343/600] Iteration[026/030] Train loss: 0.0099
2023-02-06 14:34:03 | Train | Epoch[343/600] Iteration[027/030] Train loss: 0.0099
2023-02-06 14:34:03 | Train | Epoch[343/600] Iteration[028/030] Train loss: 0.0099
2023-02-06 14:34:03 | Train | Epoch[343/600] Iteration[029/030] Train loss: 0.0099
2023-02-06 14:34:03 | Train | Epoch[343/600] Iteration[030/030] Train loss: 0.0099
2023-02-06 14:34:04 | Valid | Epoch[343/600] Iteration[001/008] Valid loss: 0.3987
2023-02-06 14:34:04 | Valid | Epoch[343/600] Iteration[002/008] Valid loss: 0.3559
2023-02-06 14:34:04 | Valid | Epoch[343/600] Iteration[003/008] Valid loss: 0.3459
2023-02-06 14:34:04 | Valid | Epoch[343/600] Iteration[004/008] Valid loss: 0.3361
2023-02-06 14:34:04 | Valid | Epoch[343/600] Iteration[005/008] Valid loss: 0.3464
2023-02-06 14:34:04 | Valid | Epoch[343/600] Iteration[006/008] Valid loss: 0.3379
2023-02-06 14:34:04 | Valid | Epoch[343/600] Iteration[007/008] Valid loss: 0.3655
2023-02-06 14:34:04 | Valid | Epoch[343/600] Iteration[008/008] Valid loss: 0.3850
2023-02-06 14:34:04 | Valid | Epoch[343/600] MIou: 0.9117751617938885
2023-02-06 14:34:04 | Valid | Epoch[343/600] Pixel Accuracy: 0.9835789998372396
2023-02-06 14:34:04 | Valid | Epoch[343/600] Mean Pixel Accuracy: 0.9754655246532813
2023-02-06 14:34:04 | Stage | Epoch[343/600] Train loss:0.0099
2023-02-06 14:34:04 | Stage | Epoch[343/600] Valid loss:0.3850
2023-02-06 14:34:04 | Stage | Epoch[343/600] LR:0.01

2023-02-06 14:34:04 | Train | Epoch[344/600] Iteration[001/030] Train loss: 0.0120
2023-02-06 14:34:05 | Train | Epoch[344/600] Iteration[002/030] Train loss: 0.0124
2023-02-06 14:34:05 | Train | Epoch[344/600] Iteration[003/030] Train loss: 0.0125
2023-02-06 14:34:05 | Train | Epoch[344/600] Iteration[004/030] Train loss: 0.0116
2023-02-06 14:34:05 | Train | Epoch[344/600] Iteration[005/030] Train loss: 0.0113
2023-02-06 14:34:06 | Train | Epoch[344/600] Iteration[006/030] Train loss: 0.0113
2023-02-06 14:34:06 | Train | Epoch[344/600] Iteration[007/030] Train loss: 0.0111
2023-02-06 14:34:06 | Train | Epoch[344/600] Iteration[008/030] Train loss: 0.0109
2023-02-06 14:34:06 | Train | Epoch[344/600] Iteration[009/030] Train loss: 0.0110
2023-02-06 14:34:06 | Train | Epoch[344/600] Iteration[010/030] Train loss: 0.0110
2023-02-06 14:34:07 | Train | Epoch[344/600] Iteration[011/030] Train loss: 0.0111
2023-02-06 14:34:07 | Train | Epoch[344/600] Iteration[012/030] Train loss: 0.0112
2023-02-06 14:34:07 | Train | Epoch[344/600] Iteration[013/030] Train loss: 0.0112
2023-02-06 14:34:07 | Train | Epoch[344/600] Iteration[014/030] Train loss: 0.0111
2023-02-06 14:34:08 | Train | Epoch[344/600] Iteration[015/030] Train loss: 0.0111
2023-02-06 14:34:08 | Train | Epoch[344/600] Iteration[016/030] Train loss: 0.0110
2023-02-06 14:34:08 | Train | Epoch[344/600] Iteration[017/030] Train loss: 0.0109
2023-02-06 14:34:08 | Train | Epoch[344/600] Iteration[018/030] Train loss: 0.0111
2023-02-06 14:34:08 | Train | Epoch[344/600] Iteration[019/030] Train loss: 0.0110
2023-02-06 14:34:09 | Train | Epoch[344/600] Iteration[020/030] Train loss: 0.0110
2023-02-06 14:34:09 | Train | Epoch[344/600] Iteration[021/030] Train loss: 0.0110
2023-02-06 14:34:09 | Train | Epoch[344/600] Iteration[022/030] Train loss: 0.0110
2023-02-06 14:34:09 | Train | Epoch[344/600] Iteration[023/030] Train loss: 0.0110
2023-02-06 14:34:09 | Train | Epoch[344/600] Iteration[024/030] Train loss: 0.0109
2023-02-06 14:34:10 | Train | Epoch[344/600] Iteration[025/030] Train loss: 0.0109
2023-02-06 14:34:10 | Train | Epoch[344/600] Iteration[026/030] Train loss: 0.0109
2023-02-06 14:34:10 | Train | Epoch[344/600] Iteration[027/030] Train loss: 0.0109
2023-02-06 14:34:10 | Train | Epoch[344/600] Iteration[028/030] Train loss: 0.0110
2023-02-06 14:34:11 | Train | Epoch[344/600] Iteration[029/030] Train loss: 0.0110
2023-02-06 14:34:11 | Train | Epoch[344/600] Iteration[030/030] Train loss: 0.0110
2023-02-06 14:34:11 | Valid | Epoch[344/600] Iteration[001/008] Valid loss: 0.4980
2023-02-06 14:34:11 | Valid | Epoch[344/600] Iteration[002/008] Valid loss: 0.4411
2023-02-06 14:34:11 | Valid | Epoch[344/600] Iteration[003/008] Valid loss: 0.4513
2023-02-06 14:34:11 | Valid | Epoch[344/600] Iteration[004/008] Valid loss: 0.4483
2023-02-06 14:34:11 | Valid | Epoch[344/600] Iteration[005/008] Valid loss: 0.4740
2023-02-06 14:34:11 | Valid | Epoch[344/600] Iteration[006/008] Valid loss: 0.4717
2023-02-06 14:34:11 | Valid | Epoch[344/600] Iteration[007/008] Valid loss: 0.5103
2023-02-06 14:34:11 | Valid | Epoch[344/600] Iteration[008/008] Valid loss: 0.5216
2023-02-06 14:34:12 | Valid | Epoch[344/600] MIou: 0.8922090012563216
2023-02-06 14:34:12 | Valid | Epoch[344/600] Pixel Accuracy: 0.9788970947265625
2023-02-06 14:34:12 | Valid | Epoch[344/600] Mean Pixel Accuracy: 0.9796510925579067
2023-02-06 14:34:12 | Stage | Epoch[344/600] Train loss:0.0110
2023-02-06 14:34:12 | Stage | Epoch[344/600] Valid loss:0.5216
2023-02-06 14:34:12 | Stage | Epoch[344/600] LR:0.01

2023-02-06 14:34:12 | Train | Epoch[345/600] Iteration[001/030] Train loss: 0.0091
2023-02-06 14:34:12 | Train | Epoch[345/600] Iteration[002/030] Train loss: 0.0093
2023-02-06 14:34:12 | Train | Epoch[345/600] Iteration[003/030] Train loss: 0.0099
2023-02-06 14:34:13 | Train | Epoch[345/600] Iteration[004/030] Train loss: 0.0106
2023-02-06 14:34:13 | Train | Epoch[345/600] Iteration[005/030] Train loss: 0.0104
2023-02-06 14:34:13 | Train | Epoch[345/600] Iteration[006/030] Train loss: 0.0108
2023-02-06 14:34:13 | Train | Epoch[345/600] Iteration[007/030] Train loss: 0.0106
2023-02-06 14:34:14 | Train | Epoch[345/600] Iteration[008/030] Train loss: 0.0107
2023-02-06 14:34:14 | Train | Epoch[345/600] Iteration[009/030] Train loss: 0.0107
2023-02-06 14:34:14 | Train | Epoch[345/600] Iteration[010/030] Train loss: 0.0106
2023-02-06 14:34:14 | Train | Epoch[345/600] Iteration[011/030] Train loss: 0.0106
2023-02-06 14:34:14 | Train | Epoch[345/600] Iteration[012/030] Train loss: 0.0106
2023-02-06 14:34:15 | Train | Epoch[345/600] Iteration[013/030] Train loss: 0.0105
2023-02-06 14:34:15 | Train | Epoch[345/600] Iteration[014/030] Train loss: 0.0106
2023-02-06 14:34:15 | Train | Epoch[345/600] Iteration[015/030] Train loss: 0.0106
2023-02-06 14:34:15 | Train | Epoch[345/600] Iteration[016/030] Train loss: 0.0106
2023-02-06 14:34:16 | Train | Epoch[345/600] Iteration[017/030] Train loss: 0.0105
2023-02-06 14:34:16 | Train | Epoch[345/600] Iteration[018/030] Train loss: 0.0105
2023-02-06 14:34:16 | Train | Epoch[345/600] Iteration[019/030] Train loss: 0.0104
2023-02-06 14:34:16 | Train | Epoch[345/600] Iteration[020/030] Train loss: 0.0103
2023-02-06 14:34:16 | Train | Epoch[345/600] Iteration[021/030] Train loss: 0.0103
2023-02-06 14:34:17 | Train | Epoch[345/600] Iteration[022/030] Train loss: 0.0102
2023-02-06 14:34:17 | Train | Epoch[345/600] Iteration[023/030] Train loss: 0.0102
2023-02-06 14:34:17 | Train | Epoch[345/600] Iteration[024/030] Train loss: 0.0102
2023-02-06 14:34:17 | Train | Epoch[345/600] Iteration[025/030] Train loss: 0.0102
2023-02-06 14:34:18 | Train | Epoch[345/600] Iteration[026/030] Train loss: 0.0102
2023-02-06 14:34:18 | Train | Epoch[345/600] Iteration[027/030] Train loss: 0.0102
2023-02-06 14:34:18 | Train | Epoch[345/600] Iteration[028/030] Train loss: 0.0103
2023-02-06 14:34:18 | Train | Epoch[345/600] Iteration[029/030] Train loss: 0.0104
2023-02-06 14:34:18 | Train | Epoch[345/600] Iteration[030/030] Train loss: 0.0105
2023-02-06 14:34:19 | Valid | Epoch[345/600] Iteration[001/008] Valid loss: 0.0946
2023-02-06 14:34:19 | Valid | Epoch[345/600] Iteration[002/008] Valid loss: 0.0805
2023-02-06 14:34:19 | Valid | Epoch[345/600] Iteration[003/008] Valid loss: 0.0747
2023-02-06 14:34:19 | Valid | Epoch[345/600] Iteration[004/008] Valid loss: 0.0707
2023-02-06 14:34:19 | Valid | Epoch[345/600] Iteration[005/008] Valid loss: 0.0686
2023-02-06 14:34:19 | Valid | Epoch[345/600] Iteration[006/008] Valid loss: 0.0664
2023-02-06 14:34:19 | Valid | Epoch[345/600] Iteration[007/008] Valid loss: 0.0675
2023-02-06 14:34:19 | Valid | Epoch[345/600] Iteration[008/008] Valid loss: 0.0656
2023-02-06 14:34:19 | Valid | Epoch[345/600] MIou: 0.898433435541007
2023-02-06 14:34:19 | Valid | Epoch[345/600] Pixel Accuracy: 0.98291015625
2023-02-06 14:34:19 | Valid | Epoch[345/600] Mean Pixel Accuracy: 0.9165373048066763
2023-02-06 14:34:19 | Stage | Epoch[345/600] Train loss:0.0105
2023-02-06 14:34:19 | Stage | Epoch[345/600] Valid loss:0.0656
2023-02-06 14:34:19 | Stage | Epoch[345/600] LR:0.01

2023-02-06 14:34:20 | Train | Epoch[346/600] Iteration[001/030] Train loss: 0.0106
2023-02-06 14:34:20 | Train | Epoch[346/600] Iteration[002/030] Train loss: 0.0103
2023-02-06 14:34:20 | Train | Epoch[346/600] Iteration[003/030] Train loss: 0.0100
2023-02-06 14:34:20 | Train | Epoch[346/600] Iteration[004/030] Train loss: 0.0119
2023-02-06 14:34:20 | Train | Epoch[346/600] Iteration[005/030] Train loss: 0.0114
2023-02-06 14:34:21 | Train | Epoch[346/600] Iteration[006/030] Train loss: 0.0111
2023-02-06 14:34:21 | Train | Epoch[346/600] Iteration[007/030] Train loss: 0.0108
2023-02-06 14:34:21 | Train | Epoch[346/600] Iteration[008/030] Train loss: 0.0108
2023-02-06 14:34:21 | Train | Epoch[346/600] Iteration[009/030] Train loss: 0.0108
2023-02-06 14:34:21 | Train | Epoch[346/600] Iteration[010/030] Train loss: 0.0110
2023-02-06 14:34:22 | Train | Epoch[346/600] Iteration[011/030] Train loss: 0.0109
2023-02-06 14:34:22 | Train | Epoch[346/600] Iteration[012/030] Train loss: 0.0110
2023-02-06 14:34:22 | Train | Epoch[346/600] Iteration[013/030] Train loss: 0.0110
2023-02-06 14:34:22 | Train | Epoch[346/600] Iteration[014/030] Train loss: 0.0109
2023-02-06 14:34:23 | Train | Epoch[346/600] Iteration[015/030] Train loss: 0.0110
2023-02-06 14:34:23 | Train | Epoch[346/600] Iteration[016/030] Train loss: 0.0109
2023-02-06 14:34:23 | Train | Epoch[346/600] Iteration[017/030] Train loss: 0.0109
2023-02-06 14:34:23 | Train | Epoch[346/600] Iteration[018/030] Train loss: 0.0109
2023-02-06 14:34:23 | Train | Epoch[346/600] Iteration[019/030] Train loss: 0.0108
2023-02-06 14:34:24 | Train | Epoch[346/600] Iteration[020/030] Train loss: 0.0110
2023-02-06 14:34:24 | Train | Epoch[346/600] Iteration[021/030] Train loss: 0.0109
2023-02-06 14:34:24 | Train | Epoch[346/600] Iteration[022/030] Train loss: 0.0110
2023-02-06 14:34:24 | Train | Epoch[346/600] Iteration[023/030] Train loss: 0.0109
2023-02-06 14:34:25 | Train | Epoch[346/600] Iteration[024/030] Train loss: 0.0109
2023-02-06 14:34:25 | Train | Epoch[346/600] Iteration[025/030] Train loss: 0.0108
2023-02-06 14:34:25 | Train | Epoch[346/600] Iteration[026/030] Train loss: 0.0109
2023-02-06 14:34:25 | Train | Epoch[346/600] Iteration[027/030] Train loss: 0.0109
2023-02-06 14:34:25 | Train | Epoch[346/600] Iteration[028/030] Train loss: 0.0111
2023-02-06 14:34:26 | Train | Epoch[346/600] Iteration[029/030] Train loss: 0.0111
2023-02-06 14:34:26 | Train | Epoch[346/600] Iteration[030/030] Train loss: 0.0111
2023-02-06 14:34:26 | Valid | Epoch[346/600] Iteration[001/008] Valid loss: 0.1191
2023-02-06 14:34:26 | Valid | Epoch[346/600] Iteration[002/008] Valid loss: 0.0940
2023-02-06 14:34:26 | Valid | Epoch[346/600] Iteration[003/008] Valid loss: 0.0860
2023-02-06 14:34:26 | Valid | Epoch[346/600] Iteration[004/008] Valid loss: 0.0836
2023-02-06 14:34:26 | Valid | Epoch[346/600] Iteration[005/008] Valid loss: 0.0824
2023-02-06 14:34:26 | Valid | Epoch[346/600] Iteration[006/008] Valid loss: 0.0769
2023-02-06 14:34:26 | Valid | Epoch[346/600] Iteration[007/008] Valid loss: 0.0768
2023-02-06 14:34:26 | Valid | Epoch[346/600] Iteration[008/008] Valid loss: 0.0751
2023-02-06 14:34:27 | Valid | Epoch[346/600] MIou: 0.9126238604817214
2023-02-06 14:34:27 | Valid | Epoch[346/600] Pixel Accuracy: 0.9850667317708334
2023-02-06 14:34:27 | Valid | Epoch[346/600] Mean Pixel Accuracy: 0.9366679795667421
2023-02-06 14:34:27 | Stage | Epoch[346/600] Train loss:0.0111
2023-02-06 14:34:27 | Stage | Epoch[346/600] Valid loss:0.0751
2023-02-06 14:34:27 | Stage | Epoch[346/600] LR:0.01

2023-02-06 14:34:27 | Train | Epoch[347/600] Iteration[001/030] Train loss: 0.0103
2023-02-06 14:34:27 | Train | Epoch[347/600] Iteration[002/030] Train loss: 0.0106
2023-02-06 14:34:27 | Train | Epoch[347/600] Iteration[003/030] Train loss: 0.0105
2023-02-06 14:34:28 | Train | Epoch[347/600] Iteration[004/030] Train loss: 0.0103
2023-02-06 14:34:28 | Train | Epoch[347/600] Iteration[005/030] Train loss: 0.0101
2023-02-06 14:34:28 | Train | Epoch[347/600] Iteration[006/030] Train loss: 0.0099
2023-02-06 14:34:28 | Train | Epoch[347/600] Iteration[007/030] Train loss: 0.0100
2023-02-06 14:34:28 | Train | Epoch[347/600] Iteration[008/030] Train loss: 0.0099
2023-02-06 14:34:29 | Train | Epoch[347/600] Iteration[009/030] Train loss: 0.0102
2023-02-06 14:34:29 | Train | Epoch[347/600] Iteration[010/030] Train loss: 0.0106
2023-02-06 14:34:29 | Train | Epoch[347/600] Iteration[011/030] Train loss: 0.0106
2023-02-06 14:34:29 | Train | Epoch[347/600] Iteration[012/030] Train loss: 0.0107
2023-02-06 14:34:30 | Train | Epoch[347/600] Iteration[013/030] Train loss: 0.0107
2023-02-06 14:34:30 | Train | Epoch[347/600] Iteration[014/030] Train loss: 0.0106
2023-02-06 14:34:30 | Train | Epoch[347/600] Iteration[015/030] Train loss: 0.0107
2023-02-06 14:34:30 | Train | Epoch[347/600] Iteration[016/030] Train loss: 0.0106
2023-02-06 14:34:30 | Train | Epoch[347/600] Iteration[017/030] Train loss: 0.0106
2023-02-06 14:34:31 | Train | Epoch[347/600] Iteration[018/030] Train loss: 0.0106
2023-02-06 14:34:31 | Train | Epoch[347/600] Iteration[019/030] Train loss: 0.0107
2023-02-06 14:34:31 | Train | Epoch[347/600] Iteration[020/030] Train loss: 0.0106
2023-02-06 14:34:31 | Train | Epoch[347/600] Iteration[021/030] Train loss: 0.0106
2023-02-06 14:34:32 | Train | Epoch[347/600] Iteration[022/030] Train loss: 0.0106
2023-02-06 14:34:32 | Train | Epoch[347/600] Iteration[023/030] Train loss: 0.0106
2023-02-06 14:34:32 | Train | Epoch[347/600] Iteration[024/030] Train loss: 0.0106
2023-02-06 14:34:32 | Train | Epoch[347/600] Iteration[025/030] Train loss: 0.0106
2023-02-06 14:34:32 | Train | Epoch[347/600] Iteration[026/030] Train loss: 0.0106
2023-02-06 14:34:33 | Train | Epoch[347/600] Iteration[027/030] Train loss: 0.0106
2023-02-06 14:34:33 | Train | Epoch[347/600] Iteration[028/030] Train loss: 0.0105
2023-02-06 14:34:33 | Train | Epoch[347/600] Iteration[029/030] Train loss: 0.0105
2023-02-06 14:34:33 | Train | Epoch[347/600] Iteration[030/030] Train loss: 0.0105
2023-02-06 14:34:34 | Valid | Epoch[347/600] Iteration[001/008] Valid loss: 0.0973
2023-02-06 14:34:34 | Valid | Epoch[347/600] Iteration[002/008] Valid loss: 0.0776
2023-02-06 14:34:34 | Valid | Epoch[347/600] Iteration[003/008] Valid loss: 0.0775
2023-02-06 14:34:34 | Valid | Epoch[347/600] Iteration[004/008] Valid loss: 0.0767
2023-02-06 14:34:34 | Valid | Epoch[347/600] Iteration[005/008] Valid loss: 0.0735
2023-02-06 14:34:34 | Valid | Epoch[347/600] Iteration[006/008] Valid loss: 0.0720
2023-02-06 14:34:34 | Valid | Epoch[347/600] Iteration[007/008] Valid loss: 0.0732
2023-02-06 14:34:34 | Valid | Epoch[347/600] Iteration[008/008] Valid loss: 0.0704
2023-02-06 14:34:34 | Valid | Epoch[347/600] MIou: 0.9086357221894796
2023-02-06 14:34:34 | Valid | Epoch[347/600] Pixel Accuracy: 0.9846509297688802
2023-02-06 14:34:34 | Valid | Epoch[347/600] Mean Pixel Accuracy: 0.9254577403940201
2023-02-06 14:34:34 | Stage | Epoch[347/600] Train loss:0.0105
2023-02-06 14:34:34 | Stage | Epoch[347/600] Valid loss:0.0704
2023-02-06 14:34:34 | Stage | Epoch[347/600] LR:0.01

2023-02-06 14:34:35 | Train | Epoch[348/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:34:35 | Train | Epoch[348/600] Iteration[002/030] Train loss: 0.0091
2023-02-06 14:34:35 | Train | Epoch[348/600] Iteration[003/030] Train loss: 0.0097
2023-02-06 14:34:35 | Train | Epoch[348/600] Iteration[004/030] Train loss: 0.0097
2023-02-06 14:34:35 | Train | Epoch[348/600] Iteration[005/030] Train loss: 0.0097
2023-02-06 14:34:36 | Train | Epoch[348/600] Iteration[006/030] Train loss: 0.0098
2023-02-06 14:34:36 | Train | Epoch[348/600] Iteration[007/030] Train loss: 0.0097
2023-02-06 14:34:36 | Train | Epoch[348/600] Iteration[008/030] Train loss: 0.0096
2023-02-06 14:34:36 | Train | Epoch[348/600] Iteration[009/030] Train loss: 0.0098
2023-02-06 14:34:37 | Train | Epoch[348/600] Iteration[010/030] Train loss: 0.0097
2023-02-06 14:34:37 | Train | Epoch[348/600] Iteration[011/030] Train loss: 0.0098
2023-02-06 14:34:37 | Train | Epoch[348/600] Iteration[012/030] Train loss: 0.0098
2023-02-06 14:34:37 | Train | Epoch[348/600] Iteration[013/030] Train loss: 0.0099
2023-02-06 14:34:37 | Train | Epoch[348/600] Iteration[014/030] Train loss: 0.0099
2023-02-06 14:34:38 | Train | Epoch[348/600] Iteration[015/030] Train loss: 0.0099
2023-02-06 14:34:38 | Train | Epoch[348/600] Iteration[016/030] Train loss: 0.0099
2023-02-06 14:34:38 | Train | Epoch[348/600] Iteration[017/030] Train loss: 0.0099
2023-02-06 14:34:38 | Train | Epoch[348/600] Iteration[018/030] Train loss: 0.0100
2023-02-06 14:34:38 | Train | Epoch[348/600] Iteration[019/030] Train loss: 0.0099
2023-02-06 14:34:39 | Train | Epoch[348/600] Iteration[020/030] Train loss: 0.0099
2023-02-06 14:34:39 | Train | Epoch[348/600] Iteration[021/030] Train loss: 0.0099
2023-02-06 14:34:39 | Train | Epoch[348/600] Iteration[022/030] Train loss: 0.0102
2023-02-06 14:34:39 | Train | Epoch[348/600] Iteration[023/030] Train loss: 0.0102
2023-02-06 14:34:40 | Train | Epoch[348/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:34:40 | Train | Epoch[348/600] Iteration[025/030] Train loss: 0.0102
2023-02-06 14:34:40 | Train | Epoch[348/600] Iteration[026/030] Train loss: 0.0102
2023-02-06 14:34:40 | Train | Epoch[348/600] Iteration[027/030] Train loss: 0.0102
2023-02-06 14:34:40 | Train | Epoch[348/600] Iteration[028/030] Train loss: 0.0103
2023-02-06 14:34:41 | Train | Epoch[348/600] Iteration[029/030] Train loss: 0.0102
2023-02-06 14:34:41 | Train | Epoch[348/600] Iteration[030/030] Train loss: 0.0103
2023-02-06 14:34:41 | Valid | Epoch[348/600] Iteration[001/008] Valid loss: 0.0929
2023-02-06 14:34:41 | Valid | Epoch[348/600] Iteration[002/008] Valid loss: 0.0830
2023-02-06 14:34:41 | Valid | Epoch[348/600] Iteration[003/008] Valid loss: 0.0789
2023-02-06 14:34:41 | Valid | Epoch[348/600] Iteration[004/008] Valid loss: 0.0761
2023-02-06 14:34:41 | Valid | Epoch[348/600] Iteration[005/008] Valid loss: 0.0744
2023-02-06 14:34:41 | Valid | Epoch[348/600] Iteration[006/008] Valid loss: 0.0714
2023-02-06 14:34:41 | Valid | Epoch[348/600] Iteration[007/008] Valid loss: 0.0697
2023-02-06 14:34:41 | Valid | Epoch[348/600] Iteration[008/008] Valid loss: 0.0699
2023-02-06 14:34:42 | Valid | Epoch[348/600] MIou: 0.8623471574653732
2023-02-06 14:34:42 | Valid | Epoch[348/600] Pixel Accuracy: 0.9772466023763021
2023-02-06 14:34:42 | Valid | Epoch[348/600] Mean Pixel Accuracy: 0.8758887827014488
2023-02-06 14:34:42 | Stage | Epoch[348/600] Train loss:0.0103
2023-02-06 14:34:42 | Stage | Epoch[348/600] Valid loss:0.0699
2023-02-06 14:34:42 | Stage | Epoch[348/600] LR:0.01

2023-02-06 14:34:42 | Train | Epoch[349/600] Iteration[001/030] Train loss: 0.0096
2023-02-06 14:34:42 | Train | Epoch[349/600] Iteration[002/030] Train loss: 0.0097
2023-02-06 14:34:42 | Train | Epoch[349/600] Iteration[003/030] Train loss: 0.0095
2023-02-06 14:34:43 | Train | Epoch[349/600] Iteration[004/030] Train loss: 0.0095
2023-02-06 14:34:43 | Train | Epoch[349/600] Iteration[005/030] Train loss: 0.0094
2023-02-06 14:34:43 | Train | Epoch[349/600] Iteration[006/030] Train loss: 0.0093
2023-02-06 14:34:43 | Train | Epoch[349/600] Iteration[007/030] Train loss: 0.0095
2023-02-06 14:34:44 | Train | Epoch[349/600] Iteration[008/030] Train loss: 0.0096
2023-02-06 14:34:44 | Train | Epoch[349/600] Iteration[009/030] Train loss: 0.0096
2023-02-06 14:34:44 | Train | Epoch[349/600] Iteration[010/030] Train loss: 0.0097
2023-02-06 14:34:44 | Train | Epoch[349/600] Iteration[011/030] Train loss: 0.0098
2023-02-06 14:34:44 | Train | Epoch[349/600] Iteration[012/030] Train loss: 0.0097
2023-02-06 14:34:45 | Train | Epoch[349/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:34:45 | Train | Epoch[349/600] Iteration[014/030] Train loss: 0.0097
2023-02-06 14:34:45 | Train | Epoch[349/600] Iteration[015/030] Train loss: 0.0099
2023-02-06 14:34:45 | Train | Epoch[349/600] Iteration[016/030] Train loss: 0.0099
2023-02-06 14:34:45 | Train | Epoch[349/600] Iteration[017/030] Train loss: 0.0100
2023-02-06 14:34:46 | Train | Epoch[349/600] Iteration[018/030] Train loss: 0.0099
2023-02-06 14:34:46 | Train | Epoch[349/600] Iteration[019/030] Train loss: 0.0099
2023-02-06 14:34:46 | Train | Epoch[349/600] Iteration[020/030] Train loss: 0.0099
2023-02-06 14:34:46 | Train | Epoch[349/600] Iteration[021/030] Train loss: 0.0099
2023-02-06 14:34:47 | Train | Epoch[349/600] Iteration[022/030] Train loss: 0.0100
2023-02-06 14:34:47 | Train | Epoch[349/600] Iteration[023/030] Train loss: 0.0101
2023-02-06 14:34:47 | Train | Epoch[349/600] Iteration[024/030] Train loss: 0.0101
2023-02-06 14:34:47 | Train | Epoch[349/600] Iteration[025/030] Train loss: 0.0101
2023-02-06 14:34:47 | Train | Epoch[349/600] Iteration[026/030] Train loss: 0.0101
2023-02-06 14:34:48 | Train | Epoch[349/600] Iteration[027/030] Train loss: 0.0101
2023-02-06 14:34:48 | Train | Epoch[349/600] Iteration[028/030] Train loss: 0.0101
2023-02-06 14:34:48 | Train | Epoch[349/600] Iteration[029/030] Train loss: 0.0101
2023-02-06 14:34:48 | Train | Epoch[349/600] Iteration[030/030] Train loss: 0.0101
2023-02-06 14:34:49 | Valid | Epoch[349/600] Iteration[001/008] Valid loss: 0.2203
2023-02-06 14:34:49 | Valid | Epoch[349/600] Iteration[002/008] Valid loss: 0.1678
2023-02-06 14:34:49 | Valid | Epoch[349/600] Iteration[003/008] Valid loss: 0.1548
2023-02-06 14:34:49 | Valid | Epoch[349/600] Iteration[004/008] Valid loss: 0.1460
2023-02-06 14:34:49 | Valid | Epoch[349/600] Iteration[005/008] Valid loss: 0.1457
2023-02-06 14:34:49 | Valid | Epoch[349/600] Iteration[006/008] Valid loss: 0.1388
2023-02-06 14:34:49 | Valid | Epoch[349/600] Iteration[007/008] Valid loss: 0.1475
2023-02-06 14:34:49 | Valid | Epoch[349/600] Iteration[008/008] Valid loss: 0.1494
2023-02-06 14:34:49 | Valid | Epoch[349/600] MIou: 0.9233396200151365
2023-02-06 14:34:49 | Valid | Epoch[349/600] Pixel Accuracy: 0.9865811665852865
2023-02-06 14:34:49 | Valid | Epoch[349/600] Mean Pixel Accuracy: 0.9578342696690881
2023-02-06 14:34:49 | Stage | Epoch[349/600] Train loss:0.0101
2023-02-06 14:34:49 | Stage | Epoch[349/600] Valid loss:0.1494
2023-02-06 14:34:49 | Stage | Epoch[349/600] LR:0.01

2023-02-06 14:34:50 | Train | Epoch[350/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:34:50 | Train | Epoch[350/600] Iteration[002/030] Train loss: 0.0093
2023-02-06 14:34:50 | Train | Epoch[350/600] Iteration[003/030] Train loss: 0.0089
2023-02-06 14:34:50 | Train | Epoch[350/600] Iteration[004/030] Train loss: 0.0092
2023-02-06 14:34:50 | Train | Epoch[350/600] Iteration[005/030] Train loss: 0.0093
2023-02-06 14:34:51 | Train | Epoch[350/600] Iteration[006/030] Train loss: 0.0092
2023-02-06 14:34:51 | Train | Epoch[350/600] Iteration[007/030] Train loss: 0.0095
2023-02-06 14:34:51 | Train | Epoch[350/600] Iteration[008/030] Train loss: 0.0096
2023-02-06 14:34:51 | Train | Epoch[350/600] Iteration[009/030] Train loss: 0.0096
2023-02-06 14:34:51 | Train | Epoch[350/600] Iteration[010/030] Train loss: 0.0096
2023-02-06 14:34:52 | Train | Epoch[350/600] Iteration[011/030] Train loss: 0.0097
2023-02-06 14:34:52 | Train | Epoch[350/600] Iteration[012/030] Train loss: 0.0097
2023-02-06 14:34:52 | Train | Epoch[350/600] Iteration[013/030] Train loss: 0.0099
2023-02-06 14:34:52 | Train | Epoch[350/600] Iteration[014/030] Train loss: 0.0099
2023-02-06 14:34:53 | Train | Epoch[350/600] Iteration[015/030] Train loss: 0.0100
2023-02-06 14:34:53 | Train | Epoch[350/600] Iteration[016/030] Train loss: 0.0100
2023-02-06 14:34:53 | Train | Epoch[350/600] Iteration[017/030] Train loss: 0.0101
2023-02-06 14:34:53 | Train | Epoch[350/600] Iteration[018/030] Train loss: 0.0103
2023-02-06 14:34:53 | Train | Epoch[350/600] Iteration[019/030] Train loss: 0.0103
2023-02-06 14:34:54 | Train | Epoch[350/600] Iteration[020/030] Train loss: 0.0102
2023-02-06 14:34:54 | Train | Epoch[350/600] Iteration[021/030] Train loss: 0.0103
2023-02-06 14:34:54 | Train | Epoch[350/600] Iteration[022/030] Train loss: 0.0102
2023-02-06 14:34:54 | Train | Epoch[350/600] Iteration[023/030] Train loss: 0.0102
2023-02-06 14:34:55 | Train | Epoch[350/600] Iteration[024/030] Train loss: 0.0102
2023-02-06 14:34:55 | Train | Epoch[350/600] Iteration[025/030] Train loss: 0.0102
2023-02-06 14:34:55 | Train | Epoch[350/600] Iteration[026/030] Train loss: 0.0102
2023-02-06 14:34:55 | Train | Epoch[350/600] Iteration[027/030] Train loss: 0.0102
2023-02-06 14:34:55 | Train | Epoch[350/600] Iteration[028/030] Train loss: 0.0102
2023-02-06 14:34:56 | Train | Epoch[350/600] Iteration[029/030] Train loss: 0.0103
2023-02-06 14:34:56 | Train | Epoch[350/600] Iteration[030/030] Train loss: 0.0103
2023-02-06 14:34:56 | Valid | Epoch[350/600] Iteration[001/008] Valid loss: 0.1212
2023-02-06 14:34:56 | Valid | Epoch[350/600] Iteration[002/008] Valid loss: 0.0947
2023-02-06 14:34:56 | Valid | Epoch[350/600] Iteration[003/008] Valid loss: 0.0870
2023-02-06 14:34:56 | Valid | Epoch[350/600] Iteration[004/008] Valid loss: 0.0840
2023-02-06 14:34:56 | Valid | Epoch[350/600] Iteration[005/008] Valid loss: 0.0843
2023-02-06 14:34:56 | Valid | Epoch[350/600] Iteration[006/008] Valid loss: 0.0818
2023-02-06 14:34:56 | Valid | Epoch[350/600] Iteration[007/008] Valid loss: 0.0864
2023-02-06 14:34:56 | Valid | Epoch[350/600] Iteration[008/008] Valid loss: 0.0842
2023-02-06 14:34:57 | Valid | Epoch[350/600] MIou: 0.9241923035818198
2023-02-06 14:34:57 | Valid | Epoch[350/600] Pixel Accuracy: 0.9870516459147135
2023-02-06 14:34:57 | Valid | Epoch[350/600] Mean Pixel Accuracy: 0.9474472135052174
2023-02-06 14:34:57 | Stage | Epoch[350/600] Train loss:0.0103
2023-02-06 14:34:57 | Stage | Epoch[350/600] Valid loss:0.0842
2023-02-06 14:34:57 | Stage | Epoch[350/600] LR:0.01

2023-02-06 14:34:57 | Train | Epoch[351/600] Iteration[001/030] Train loss: 0.0097
2023-02-06 14:34:57 | Train | Epoch[351/600] Iteration[002/030] Train loss: 0.0093
2023-02-06 14:34:57 | Train | Epoch[351/600] Iteration[003/030] Train loss: 0.0093
2023-02-06 14:34:58 | Train | Epoch[351/600] Iteration[004/030] Train loss: 0.0096
2023-02-06 14:34:58 | Train | Epoch[351/600] Iteration[005/030] Train loss: 0.0099
2023-02-06 14:34:58 | Train | Epoch[351/600] Iteration[006/030] Train loss: 0.0099
2023-02-06 14:34:58 | Train | Epoch[351/600] Iteration[007/030] Train loss: 0.0098
2023-02-06 14:34:59 | Train | Epoch[351/600] Iteration[008/030] Train loss: 0.0099
2023-02-06 14:34:59 | Train | Epoch[351/600] Iteration[009/030] Train loss: 0.0100
2023-02-06 14:34:59 | Train | Epoch[351/600] Iteration[010/030] Train loss: 0.0099
2023-02-06 14:34:59 | Train | Epoch[351/600] Iteration[011/030] Train loss: 0.0101
2023-02-06 14:34:59 | Train | Epoch[351/600] Iteration[012/030] Train loss: 0.0101
2023-02-06 14:35:00 | Train | Epoch[351/600] Iteration[013/030] Train loss: 0.0100
2023-02-06 14:35:00 | Train | Epoch[351/600] Iteration[014/030] Train loss: 0.0100
2023-02-06 14:35:00 | Train | Epoch[351/600] Iteration[015/030] Train loss: 0.0100
2023-02-06 14:35:00 | Train | Epoch[351/600] Iteration[016/030] Train loss: 0.0099
2023-02-06 14:35:01 | Train | Epoch[351/600] Iteration[017/030] Train loss: 0.0099
2023-02-06 14:35:01 | Train | Epoch[351/600] Iteration[018/030] Train loss: 0.0098
2023-02-06 14:35:01 | Train | Epoch[351/600] Iteration[019/030] Train loss: 0.0100
2023-02-06 14:35:01 | Train | Epoch[351/600] Iteration[020/030] Train loss: 0.0099
2023-02-06 14:35:01 | Train | Epoch[351/600] Iteration[021/030] Train loss: 0.0100
2023-02-06 14:35:02 | Train | Epoch[351/600] Iteration[022/030] Train loss: 0.0101
2023-02-06 14:35:02 | Train | Epoch[351/600] Iteration[023/030] Train loss: 0.0103
2023-02-06 14:35:02 | Train | Epoch[351/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:35:02 | Train | Epoch[351/600] Iteration[025/030] Train loss: 0.0103
2023-02-06 14:35:03 | Train | Epoch[351/600] Iteration[026/030] Train loss: 0.0103
2023-02-06 14:35:03 | Train | Epoch[351/600] Iteration[027/030] Train loss: 0.0102
2023-02-06 14:35:03 | Train | Epoch[351/600] Iteration[028/030] Train loss: 0.0103
2023-02-06 14:35:03 | Train | Epoch[351/600] Iteration[029/030] Train loss: 0.0103
2023-02-06 14:35:03 | Train | Epoch[351/600] Iteration[030/030] Train loss: 0.0103
2023-02-06 14:35:04 | Valid | Epoch[351/600] Iteration[001/008] Valid loss: 0.3436
2023-02-06 14:35:04 | Valid | Epoch[351/600] Iteration[002/008] Valid loss: 0.2667
2023-02-06 14:35:04 | Valid | Epoch[351/600] Iteration[003/008] Valid loss: 0.2633
2023-02-06 14:35:04 | Valid | Epoch[351/600] Iteration[004/008] Valid loss: 0.2532
2023-02-06 14:35:04 | Valid | Epoch[351/600] Iteration[005/008] Valid loss: 0.2505
2023-02-06 14:35:04 | Valid | Epoch[351/600] Iteration[006/008] Valid loss: 0.2490
2023-02-06 14:35:04 | Valid | Epoch[351/600] Iteration[007/008] Valid loss: 0.2708
2023-02-06 14:35:04 | Valid | Epoch[351/600] Iteration[008/008] Valid loss: 0.2799
2023-02-06 14:35:04 | Valid | Epoch[351/600] MIou: 0.9045964005255476
2023-02-06 14:35:04 | Valid | Epoch[351/600] Pixel Accuracy: 0.9821243286132812
2023-02-06 14:35:04 | Valid | Epoch[351/600] Mean Pixel Accuracy: 0.9712104183342831
2023-02-06 14:35:04 | Stage | Epoch[351/600] Train loss:0.0103
2023-02-06 14:35:04 | Stage | Epoch[351/600] Valid loss:0.2799
2023-02-06 14:35:04 | Stage | Epoch[351/600] LR:0.01

2023-02-06 14:35:05 | Train | Epoch[352/600] Iteration[001/030] Train loss: 0.0102
2023-02-06 14:35:05 | Train | Epoch[352/600] Iteration[002/030] Train loss: 0.0118
2023-02-06 14:35:05 | Train | Epoch[352/600] Iteration[003/030] Train loss: 0.0114
2023-02-06 14:35:05 | Train | Epoch[352/600] Iteration[004/030] Train loss: 0.0111
2023-02-06 14:35:06 | Train | Epoch[352/600] Iteration[005/030] Train loss: 0.0107
2023-02-06 14:35:06 | Train | Epoch[352/600] Iteration[006/030] Train loss: 0.0106
2023-02-06 14:35:06 | Train | Epoch[352/600] Iteration[007/030] Train loss: 0.0107
2023-02-06 14:35:06 | Train | Epoch[352/600] Iteration[008/030] Train loss: 0.0106
2023-02-06 14:35:06 | Train | Epoch[352/600] Iteration[009/030] Train loss: 0.0107
2023-02-06 14:35:07 | Train | Epoch[352/600] Iteration[010/030] Train loss: 0.0106
2023-02-06 14:35:07 | Train | Epoch[352/600] Iteration[011/030] Train loss: 0.0105
2023-02-06 14:35:07 | Train | Epoch[352/600] Iteration[012/030] Train loss: 0.0104
2023-02-06 14:35:07 | Train | Epoch[352/600] Iteration[013/030] Train loss: 0.0104
2023-02-06 14:35:08 | Train | Epoch[352/600] Iteration[014/030] Train loss: 0.0104
2023-02-06 14:35:08 | Train | Epoch[352/600] Iteration[015/030] Train loss: 0.0104
2023-02-06 14:35:08 | Train | Epoch[352/600] Iteration[016/030] Train loss: 0.0104
2023-02-06 14:35:08 | Train | Epoch[352/600] Iteration[017/030] Train loss: 0.0103
2023-02-06 14:35:08 | Train | Epoch[352/600] Iteration[018/030] Train loss: 0.0102
2023-02-06 14:35:09 | Train | Epoch[352/600] Iteration[019/030] Train loss: 0.0101
2023-02-06 14:35:09 | Train | Epoch[352/600] Iteration[020/030] Train loss: 0.0102
2023-02-06 14:35:09 | Train | Epoch[352/600] Iteration[021/030] Train loss: 0.0103
2023-02-06 14:35:09 | Train | Epoch[352/600] Iteration[022/030] Train loss: 0.0103
2023-02-06 14:35:09 | Train | Epoch[352/600] Iteration[023/030] Train loss: 0.0104
2023-02-06 14:35:10 | Train | Epoch[352/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:35:10 | Train | Epoch[352/600] Iteration[025/030] Train loss: 0.0104
2023-02-06 14:35:10 | Train | Epoch[352/600] Iteration[026/030] Train loss: 0.0103
2023-02-06 14:35:10 | Train | Epoch[352/600] Iteration[027/030] Train loss: 0.0103
2023-02-06 14:35:11 | Train | Epoch[352/600] Iteration[028/030] Train loss: 0.0102
2023-02-06 14:35:11 | Train | Epoch[352/600] Iteration[029/030] Train loss: 0.0102
2023-02-06 14:35:11 | Train | Epoch[352/600] Iteration[030/030] Train loss: 0.0102
2023-02-06 14:35:11 | Valid | Epoch[352/600] Iteration[001/008] Valid loss: 0.4138
2023-02-06 14:35:11 | Valid | Epoch[352/600] Iteration[002/008] Valid loss: 0.3618
2023-02-06 14:35:11 | Valid | Epoch[352/600] Iteration[003/008] Valid loss: 0.3719
2023-02-06 14:35:11 | Valid | Epoch[352/600] Iteration[004/008] Valid loss: 0.3613
2023-02-06 14:35:11 | Valid | Epoch[352/600] Iteration[005/008] Valid loss: 0.3866
2023-02-06 14:35:12 | Valid | Epoch[352/600] Iteration[006/008] Valid loss: 0.3806
2023-02-06 14:35:12 | Valid | Epoch[352/600] Iteration[007/008] Valid loss: 0.4109
2023-02-06 14:35:12 | Valid | Epoch[352/600] Iteration[008/008] Valid loss: 0.4190
2023-02-06 14:35:12 | Valid | Epoch[352/600] MIou: 0.910122956385431
2023-02-06 14:35:12 | Valid | Epoch[352/600] Pixel Accuracy: 0.9831275939941406
2023-02-06 14:35:12 | Valid | Epoch[352/600] Mean Pixel Accuracy: 0.977956496443139
2023-02-06 14:35:12 | Stage | Epoch[352/600] Train loss:0.0102
2023-02-06 14:35:12 | Stage | Epoch[352/600] Valid loss:0.4190
2023-02-06 14:35:12 | Stage | Epoch[352/600] LR:0.01

2023-02-06 14:35:12 | Train | Epoch[353/600] Iteration[001/030] Train loss: 0.0100
2023-02-06 14:35:12 | Train | Epoch[353/600] Iteration[002/030] Train loss: 0.0101
2023-02-06 14:35:13 | Train | Epoch[353/600] Iteration[003/030] Train loss: 0.0104
2023-02-06 14:35:13 | Train | Epoch[353/600] Iteration[004/030] Train loss: 0.0102
2023-02-06 14:35:13 | Train | Epoch[353/600] Iteration[005/030] Train loss: 0.0106
2023-02-06 14:35:13 | Train | Epoch[353/600] Iteration[006/030] Train loss: 0.0103
2023-02-06 14:35:14 | Train | Epoch[353/600] Iteration[007/030] Train loss: 0.0103
2023-02-06 14:35:14 | Train | Epoch[353/600] Iteration[008/030] Train loss: 0.0102
2023-02-06 14:35:14 | Train | Epoch[353/600] Iteration[009/030] Train loss: 0.0100
2023-02-06 14:35:14 | Train | Epoch[353/600] Iteration[010/030] Train loss: 0.0098
2023-02-06 14:35:14 | Train | Epoch[353/600] Iteration[011/030] Train loss: 0.0097
2023-02-06 14:35:15 | Train | Epoch[353/600] Iteration[012/030] Train loss: 0.0098
2023-02-06 14:35:15 | Train | Epoch[353/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:35:15 | Train | Epoch[353/600] Iteration[014/030] Train loss: 0.0097
2023-02-06 14:35:15 | Train | Epoch[353/600] Iteration[015/030] Train loss: 0.0097
2023-02-06 14:35:16 | Train | Epoch[353/600] Iteration[016/030] Train loss: 0.0098
2023-02-06 14:35:16 | Train | Epoch[353/600] Iteration[017/030] Train loss: 0.0097
2023-02-06 14:35:16 | Train | Epoch[353/600] Iteration[018/030] Train loss: 0.0097
2023-02-06 14:35:16 | Train | Epoch[353/600] Iteration[019/030] Train loss: 0.0097
2023-02-06 14:35:16 | Train | Epoch[353/600] Iteration[020/030] Train loss: 0.0097
2023-02-06 14:35:17 | Train | Epoch[353/600] Iteration[021/030] Train loss: 0.0096
2023-02-06 14:35:17 | Train | Epoch[353/600] Iteration[022/030] Train loss: 0.0097
2023-02-06 14:35:17 | Train | Epoch[353/600] Iteration[023/030] Train loss: 0.0097
2023-02-06 14:35:17 | Train | Epoch[353/600] Iteration[024/030] Train loss: 0.0097
2023-02-06 14:35:17 | Train | Epoch[353/600] Iteration[025/030] Train loss: 0.0097
2023-02-06 14:35:18 | Train | Epoch[353/600] Iteration[026/030] Train loss: 0.0097
2023-02-06 14:35:18 | Train | Epoch[353/600] Iteration[027/030] Train loss: 0.0097
2023-02-06 14:35:18 | Train | Epoch[353/600] Iteration[028/030] Train loss: 0.0097
2023-02-06 14:35:18 | Train | Epoch[353/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:35:18 | Train | Epoch[353/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:35:19 | Valid | Epoch[353/600] Iteration[001/008] Valid loss: 0.3858
2023-02-06 14:35:19 | Valid | Epoch[353/600] Iteration[002/008] Valid loss: 0.3159
2023-02-06 14:35:19 | Valid | Epoch[353/600] Iteration[003/008] Valid loss: 0.3089
2023-02-06 14:35:19 | Valid | Epoch[353/600] Iteration[004/008] Valid loss: 0.3025
2023-02-06 14:35:19 | Valid | Epoch[353/600] Iteration[005/008] Valid loss: 0.3136
2023-02-06 14:35:19 | Valid | Epoch[353/600] Iteration[006/008] Valid loss: 0.3078
2023-02-06 14:35:19 | Valid | Epoch[353/600] Iteration[007/008] Valid loss: 0.3316
2023-02-06 14:35:19 | Valid | Epoch[353/600] Iteration[008/008] Valid loss: 0.3368
2023-02-06 14:35:19 | Valid | Epoch[353/600] MIou: 0.9174195509460197
2023-02-06 14:35:19 | Valid | Epoch[353/600] Pixel Accuracy: 0.9846903483072916
2023-02-06 14:35:19 | Valid | Epoch[353/600] Mean Pixel Accuracy: 0.9793860952995934
2023-02-06 14:35:19 | Stage | Epoch[353/600] Train loss:0.0098
2023-02-06 14:35:19 | Stage | Epoch[353/600] Valid loss:0.3368
2023-02-06 14:35:19 | Stage | Epoch[353/600] LR:0.01

2023-02-06 14:35:20 | Train | Epoch[354/600] Iteration[001/030] Train loss: 0.0095
2023-02-06 14:35:20 | Train | Epoch[354/600] Iteration[002/030] Train loss: 0.0094
2023-02-06 14:35:20 | Train | Epoch[354/600] Iteration[003/030] Train loss: 0.0094
2023-02-06 14:35:20 | Train | Epoch[354/600] Iteration[004/030] Train loss: 0.0093
2023-02-06 14:35:21 | Train | Epoch[354/600] Iteration[005/030] Train loss: 0.0092
2023-02-06 14:35:21 | Train | Epoch[354/600] Iteration[006/030] Train loss: 0.0093
2023-02-06 14:35:21 | Train | Epoch[354/600] Iteration[007/030] Train loss: 0.0093
2023-02-06 14:35:21 | Train | Epoch[354/600] Iteration[008/030] Train loss: 0.0095
2023-02-06 14:35:22 | Train | Epoch[354/600] Iteration[009/030] Train loss: 0.0093
2023-02-06 14:35:22 | Train | Epoch[354/600] Iteration[010/030] Train loss: 0.0095
2023-02-06 14:35:22 | Train | Epoch[354/600] Iteration[011/030] Train loss: 0.0096
2023-02-06 14:35:22 | Train | Epoch[354/600] Iteration[012/030] Train loss: 0.0096
2023-02-06 14:35:22 | Train | Epoch[354/600] Iteration[013/030] Train loss: 0.0095
2023-02-06 14:35:23 | Train | Epoch[354/600] Iteration[014/030] Train loss: 0.0094
2023-02-06 14:35:23 | Train | Epoch[354/600] Iteration[015/030] Train loss: 0.0095
2023-02-06 14:35:23 | Train | Epoch[354/600] Iteration[016/030] Train loss: 0.0095
2023-02-06 14:35:23 | Train | Epoch[354/600] Iteration[017/030] Train loss: 0.0095
2023-02-06 14:35:23 | Train | Epoch[354/600] Iteration[018/030] Train loss: 0.0095
2023-02-06 14:35:24 | Train | Epoch[354/600] Iteration[019/030] Train loss: 0.0096
2023-02-06 14:35:24 | Train | Epoch[354/600] Iteration[020/030] Train loss: 0.0096
2023-02-06 14:35:24 | Train | Epoch[354/600] Iteration[021/030] Train loss: 0.0096
2023-02-06 14:35:24 | Train | Epoch[354/600] Iteration[022/030] Train loss: 0.0096
2023-02-06 14:35:25 | Train | Epoch[354/600] Iteration[023/030] Train loss: 0.0098
2023-02-06 14:35:25 | Train | Epoch[354/600] Iteration[024/030] Train loss: 0.0098
2023-02-06 14:35:25 | Train | Epoch[354/600] Iteration[025/030] Train loss: 0.0099
2023-02-06 14:35:25 | Train | Epoch[354/600] Iteration[026/030] Train loss: 0.0099
2023-02-06 14:35:25 | Train | Epoch[354/600] Iteration[027/030] Train loss: 0.0099
2023-02-06 14:35:26 | Train | Epoch[354/600] Iteration[028/030] Train loss: 0.0098
2023-02-06 14:35:26 | Train | Epoch[354/600] Iteration[029/030] Train loss: 0.0099
2023-02-06 14:35:26 | Train | Epoch[354/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:35:26 | Valid | Epoch[354/600] Iteration[001/008] Valid loss: 0.5124
2023-02-06 14:35:26 | Valid | Epoch[354/600] Iteration[002/008] Valid loss: 0.4427
2023-02-06 14:35:26 | Valid | Epoch[354/600] Iteration[003/008] Valid loss: 0.4637
2023-02-06 14:35:26 | Valid | Epoch[354/600] Iteration[004/008] Valid loss: 0.4570
2023-02-06 14:35:27 | Valid | Epoch[354/600] Iteration[005/008] Valid loss: 0.4804
2023-02-06 14:35:27 | Valid | Epoch[354/600] Iteration[006/008] Valid loss: 0.4686
2023-02-06 14:35:27 | Valid | Epoch[354/600] Iteration[007/008] Valid loss: 0.5036
2023-02-06 14:35:27 | Valid | Epoch[354/600] Iteration[008/008] Valid loss: 0.5191
2023-02-06 14:35:27 | Valid | Epoch[354/600] MIou: 0.9075019331212543
2023-02-06 14:35:27 | Valid | Epoch[354/600] Pixel Accuracy: 0.9824816385904948
2023-02-06 14:35:27 | Valid | Epoch[354/600] Mean Pixel Accuracy: 0.9795669979727084
2023-02-06 14:35:27 | Stage | Epoch[354/600] Train loss:0.0098
2023-02-06 14:35:27 | Stage | Epoch[354/600] Valid loss:0.5191
2023-02-06 14:35:27 | Stage | Epoch[354/600] LR:0.01

2023-02-06 14:35:27 | Train | Epoch[355/600] Iteration[001/030] Train loss: 0.0107
2023-02-06 14:35:27 | Train | Epoch[355/600] Iteration[002/030] Train loss: 0.0099
2023-02-06 14:35:28 | Train | Epoch[355/600] Iteration[003/030] Train loss: 0.0108
2023-02-06 14:35:28 | Train | Epoch[355/600] Iteration[004/030] Train loss: 0.0119
2023-02-06 14:35:28 | Train | Epoch[355/600] Iteration[005/030] Train loss: 0.0119
2023-02-06 14:35:28 | Train | Epoch[355/600] Iteration[006/030] Train loss: 0.0120
2023-02-06 14:35:29 | Train | Epoch[355/600] Iteration[007/030] Train loss: 0.0115
2023-02-06 14:35:29 | Train | Epoch[355/600] Iteration[008/030] Train loss: 0.0112
2023-02-06 14:35:29 | Train | Epoch[355/600] Iteration[009/030] Train loss: 0.0109
2023-02-06 14:35:29 | Train | Epoch[355/600] Iteration[010/030] Train loss: 0.0110
2023-02-06 14:35:29 | Train | Epoch[355/600] Iteration[011/030] Train loss: 0.0109
2023-02-06 14:35:30 | Train | Epoch[355/600] Iteration[012/030] Train loss: 0.0107
2023-02-06 14:35:30 | Train | Epoch[355/600] Iteration[013/030] Train loss: 0.0107
2023-02-06 14:35:30 | Train | Epoch[355/600] Iteration[014/030] Train loss: 0.0107
2023-02-06 14:35:30 | Train | Epoch[355/600] Iteration[015/030] Train loss: 0.0107
2023-02-06 14:35:31 | Train | Epoch[355/600] Iteration[016/030] Train loss: 0.0107
2023-02-06 14:35:31 | Train | Epoch[355/600] Iteration[017/030] Train loss: 0.0106
2023-02-06 14:35:31 | Train | Epoch[355/600] Iteration[018/030] Train loss: 0.0106
2023-02-06 14:35:31 | Train | Epoch[355/600] Iteration[019/030] Train loss: 0.0106
2023-02-06 14:35:31 | Train | Epoch[355/600] Iteration[020/030] Train loss: 0.0106
2023-02-06 14:35:32 | Train | Epoch[355/600] Iteration[021/030] Train loss: 0.0105
2023-02-06 14:35:32 | Train | Epoch[355/600] Iteration[022/030] Train loss: 0.0105
2023-02-06 14:35:32 | Train | Epoch[355/600] Iteration[023/030] Train loss: 0.0105
2023-02-06 14:35:32 | Train | Epoch[355/600] Iteration[024/030] Train loss: 0.0105
2023-02-06 14:35:32 | Train | Epoch[355/600] Iteration[025/030] Train loss: 0.0105
2023-02-06 14:35:33 | Train | Epoch[355/600] Iteration[026/030] Train loss: 0.0104
2023-02-06 14:35:33 | Train | Epoch[355/600] Iteration[027/030] Train loss: 0.0104
2023-02-06 14:35:33 | Train | Epoch[355/600] Iteration[028/030] Train loss: 0.0104
2023-02-06 14:35:33 | Train | Epoch[355/600] Iteration[029/030] Train loss: 0.0104
2023-02-06 14:35:33 | Train | Epoch[355/600] Iteration[030/030] Train loss: 0.0104
2023-02-06 14:35:34 | Valid | Epoch[355/600] Iteration[001/008] Valid loss: 0.1096
2023-02-06 14:35:34 | Valid | Epoch[355/600] Iteration[002/008] Valid loss: 0.0874
2023-02-06 14:35:34 | Valid | Epoch[355/600] Iteration[003/008] Valid loss: 0.0835
2023-02-06 14:35:34 | Valid | Epoch[355/600] Iteration[004/008] Valid loss: 0.0807
2023-02-06 14:35:34 | Valid | Epoch[355/600] Iteration[005/008] Valid loss: 0.0773
2023-02-06 14:35:34 | Valid | Epoch[355/600] Iteration[006/008] Valid loss: 0.0734
2023-02-06 14:35:34 | Valid | Epoch[355/600] Iteration[007/008] Valid loss: 0.0763
2023-02-06 14:35:34 | Valid | Epoch[355/600] Iteration[008/008] Valid loss: 0.0748
2023-02-06 14:35:34 | Valid | Epoch[355/600] MIou: 0.913378579325808
2023-02-06 14:35:34 | Valid | Epoch[355/600] Pixel Accuracy: 0.9853057861328125
2023-02-06 14:35:34 | Valid | Epoch[355/600] Mean Pixel Accuracy: 0.9341173545898981
2023-02-06 14:35:34 | Stage | Epoch[355/600] Train loss:0.0104
2023-02-06 14:35:34 | Stage | Epoch[355/600] Valid loss:0.0748
2023-02-06 14:35:34 | Stage | Epoch[355/600] LR:0.01

2023-02-06 14:35:35 | Train | Epoch[356/600] Iteration[001/030] Train loss: 0.0082
2023-02-06 14:35:35 | Train | Epoch[356/600] Iteration[002/030] Train loss: 0.0090
2023-02-06 14:35:35 | Train | Epoch[356/600] Iteration[003/030] Train loss: 0.0092
2023-02-06 14:35:36 | Train | Epoch[356/600] Iteration[004/030] Train loss: 0.0091
2023-02-06 14:35:36 | Train | Epoch[356/600] Iteration[005/030] Train loss: 0.0090
2023-02-06 14:35:36 | Train | Epoch[356/600] Iteration[006/030] Train loss: 0.0099
2023-02-06 14:35:36 | Train | Epoch[356/600] Iteration[007/030] Train loss: 0.0112
2023-02-06 14:35:36 | Train | Epoch[356/600] Iteration[008/030] Train loss: 0.0110
2023-02-06 14:35:37 | Train | Epoch[356/600] Iteration[009/030] Train loss: 0.0109
2023-02-06 14:35:37 | Train | Epoch[356/600] Iteration[010/030] Train loss: 0.0108
2023-02-06 14:35:37 | Train | Epoch[356/600] Iteration[011/030] Train loss: 0.0111
2023-02-06 14:35:37 | Train | Epoch[356/600] Iteration[012/030] Train loss: 0.0111
2023-02-06 14:35:37 | Train | Epoch[356/600] Iteration[013/030] Train loss: 0.0112
2023-02-06 14:35:38 | Train | Epoch[356/600] Iteration[014/030] Train loss: 0.0112
2023-02-06 14:35:38 | Train | Epoch[356/600] Iteration[015/030] Train loss: 0.0112
2023-02-06 14:35:38 | Train | Epoch[356/600] Iteration[016/030] Train loss: 0.0111
2023-02-06 14:35:38 | Train | Epoch[356/600] Iteration[017/030] Train loss: 0.0111
2023-02-06 14:35:39 | Train | Epoch[356/600] Iteration[018/030] Train loss: 0.0111
2023-02-06 14:35:39 | Train | Epoch[356/600] Iteration[019/030] Train loss: 0.0111
2023-02-06 14:35:39 | Train | Epoch[356/600] Iteration[020/030] Train loss: 0.0112
2023-02-06 14:35:39 | Train | Epoch[356/600] Iteration[021/030] Train loss: 0.0111
2023-02-06 14:35:39 | Train | Epoch[356/600] Iteration[022/030] Train loss: 0.0111
2023-02-06 14:35:40 | Train | Epoch[356/600] Iteration[023/030] Train loss: 0.0112
2023-02-06 14:35:40 | Train | Epoch[356/600] Iteration[024/030] Train loss: 0.0113
2023-02-06 14:35:40 | Train | Epoch[356/600] Iteration[025/030] Train loss: 0.0113
2023-02-06 14:35:40 | Train | Epoch[356/600] Iteration[026/030] Train loss: 0.0114
2023-02-06 14:35:41 | Train | Epoch[356/600] Iteration[027/030] Train loss: 0.0114
2023-02-06 14:35:41 | Train | Epoch[356/600] Iteration[028/030] Train loss: 0.0114
2023-02-06 14:35:41 | Train | Epoch[356/600] Iteration[029/030] Train loss: 0.0113
2023-02-06 14:35:41 | Train | Epoch[356/600] Iteration[030/030] Train loss: 0.0113
2023-02-06 14:35:41 | Valid | Epoch[356/600] Iteration[001/008] Valid loss: 0.1076
2023-02-06 14:35:42 | Valid | Epoch[356/600] Iteration[002/008] Valid loss: 0.1087
2023-02-06 14:35:42 | Valid | Epoch[356/600] Iteration[003/008] Valid loss: 0.1113
2023-02-06 14:35:42 | Valid | Epoch[356/600] Iteration[004/008] Valid loss: 0.1123
2023-02-06 14:35:42 | Valid | Epoch[356/600] Iteration[005/008] Valid loss: 0.1120
2023-02-06 14:35:42 | Valid | Epoch[356/600] Iteration[006/008] Valid loss: 0.1090
2023-02-06 14:35:42 | Valid | Epoch[356/600] Iteration[007/008] Valid loss: 0.1060
2023-02-06 14:35:42 | Valid | Epoch[356/600] Iteration[008/008] Valid loss: 0.1079
2023-02-06 14:35:42 | Valid | Epoch[356/600] MIou: 0.7527635179725739
2023-02-06 14:35:42 | Valid | Epoch[356/600] Pixel Accuracy: 0.959021250406901
2023-02-06 14:35:42 | Valid | Epoch[356/600] Mean Pixel Accuracy: 0.7755069519764428
2023-02-06 14:35:42 | Stage | Epoch[356/600] Train loss:0.0113
2023-02-06 14:35:42 | Stage | Epoch[356/600] Valid loss:0.1079
2023-02-06 14:35:42 | Stage | Epoch[356/600] LR:0.01

2023-02-06 14:35:42 | Train | Epoch[357/600] Iteration[001/030] Train loss: 0.0137
2023-02-06 14:35:43 | Train | Epoch[357/600] Iteration[002/030] Train loss: 0.0117
2023-02-06 14:35:43 | Train | Epoch[357/600] Iteration[003/030] Train loss: 0.0110
2023-02-06 14:35:43 | Train | Epoch[357/600] Iteration[004/030] Train loss: 0.0110
2023-02-06 14:35:43 | Train | Epoch[357/600] Iteration[005/030] Train loss: 0.0105
2023-02-06 14:35:43 | Train | Epoch[357/600] Iteration[006/030] Train loss: 0.0105
2023-02-06 14:35:44 | Train | Epoch[357/600] Iteration[007/030] Train loss: 0.0105
2023-02-06 14:35:44 | Train | Epoch[357/600] Iteration[008/030] Train loss: 0.0107
2023-02-06 14:35:44 | Train | Epoch[357/600] Iteration[009/030] Train loss: 0.0110
2023-02-06 14:35:44 | Train | Epoch[357/600] Iteration[010/030] Train loss: 0.0108
2023-02-06 14:35:45 | Train | Epoch[357/600] Iteration[011/030] Train loss: 0.0107
2023-02-06 14:35:45 | Train | Epoch[357/600] Iteration[012/030] Train loss: 0.0106
2023-02-06 14:35:45 | Train | Epoch[357/600] Iteration[013/030] Train loss: 0.0107
2023-02-06 14:35:45 | Train | Epoch[357/600] Iteration[014/030] Train loss: 0.0105
2023-02-06 14:35:45 | Train | Epoch[357/600] Iteration[015/030] Train loss: 0.0105
2023-02-06 14:35:46 | Train | Epoch[357/600] Iteration[016/030] Train loss: 0.0105
2023-02-06 14:35:46 | Train | Epoch[357/600] Iteration[017/030] Train loss: 0.0106
2023-02-06 14:35:46 | Train | Epoch[357/600] Iteration[018/030] Train loss: 0.0106
2023-02-06 14:35:46 | Train | Epoch[357/600] Iteration[019/030] Train loss: 0.0105
2023-02-06 14:35:47 | Train | Epoch[357/600] Iteration[020/030] Train loss: 0.0105
2023-02-06 14:35:47 | Train | Epoch[357/600] Iteration[021/030] Train loss: 0.0106
2023-02-06 14:35:47 | Train | Epoch[357/600] Iteration[022/030] Train loss: 0.0106
2023-02-06 14:35:47 | Train | Epoch[357/600] Iteration[023/030] Train loss: 0.0106
2023-02-06 14:35:47 | Train | Epoch[357/600] Iteration[024/030] Train loss: 0.0106
2023-02-06 14:35:48 | Train | Epoch[357/600] Iteration[025/030] Train loss: 0.0106
2023-02-06 14:35:48 | Train | Epoch[357/600] Iteration[026/030] Train loss: 0.0106
2023-02-06 14:35:48 | Train | Epoch[357/600] Iteration[027/030] Train loss: 0.0107
2023-02-06 14:35:48 | Train | Epoch[357/600] Iteration[028/030] Train loss: 0.0107
2023-02-06 14:35:48 | Train | Epoch[357/600] Iteration[029/030] Train loss: 0.0107
2023-02-06 14:35:49 | Train | Epoch[357/600] Iteration[030/030] Train loss: 0.0107
2023-02-06 14:35:49 | Valid | Epoch[357/600] Iteration[001/008] Valid loss: 0.1034
2023-02-06 14:35:49 | Valid | Epoch[357/600] Iteration[002/008] Valid loss: 0.1014
2023-02-06 14:35:49 | Valid | Epoch[357/600] Iteration[003/008] Valid loss: 0.1051
2023-02-06 14:35:49 | Valid | Epoch[357/600] Iteration[004/008] Valid loss: 0.1044
2023-02-06 14:35:49 | Valid | Epoch[357/600] Iteration[005/008] Valid loss: 0.1063
2023-02-06 14:35:49 | Valid | Epoch[357/600] Iteration[006/008] Valid loss: 0.1039
2023-02-06 14:35:49 | Valid | Epoch[357/600] Iteration[007/008] Valid loss: 0.1017
2023-02-06 14:35:49 | Valid | Epoch[357/600] Iteration[008/008] Valid loss: 0.1032
2023-02-06 14:35:49 | Valid | Epoch[357/600] MIou: 0.7386661102172355
2023-02-06 14:35:49 | Valid | Epoch[357/600] Pixel Accuracy: 0.956597646077474
2023-02-06 14:35:49 | Valid | Epoch[357/600] Mean Pixel Accuracy: 0.7629839034539441
2023-02-06 14:35:49 | Stage | Epoch[357/600] Train loss:0.0107
2023-02-06 14:35:49 | Stage | Epoch[357/600] Valid loss:0.1032
2023-02-06 14:35:49 | Stage | Epoch[357/600] LR:0.01

2023-02-06 14:35:50 | Train | Epoch[358/600] Iteration[001/030] Train loss: 0.0092
2023-02-06 14:35:50 | Train | Epoch[358/600] Iteration[002/030] Train loss: 0.0091
2023-02-06 14:35:50 | Train | Epoch[358/600] Iteration[003/030] Train loss: 0.0094
2023-02-06 14:35:51 | Train | Epoch[358/600] Iteration[004/030] Train loss: 0.0095
2023-02-06 14:35:51 | Train | Epoch[358/600] Iteration[005/030] Train loss: 0.0099
2023-02-06 14:35:51 | Train | Epoch[358/600] Iteration[006/030] Train loss: 0.0099
2023-02-06 14:35:51 | Train | Epoch[358/600] Iteration[007/030] Train loss: 0.0098
2023-02-06 14:35:51 | Train | Epoch[358/600] Iteration[008/030] Train loss: 0.0099
2023-02-06 14:35:52 | Train | Epoch[358/600] Iteration[009/030] Train loss: 0.0101
2023-02-06 14:35:52 | Train | Epoch[358/600] Iteration[010/030] Train loss: 0.0101
2023-02-06 14:35:52 | Train | Epoch[358/600] Iteration[011/030] Train loss: 0.0101
2023-02-06 14:35:52 | Train | Epoch[358/600] Iteration[012/030] Train loss: 0.0101
2023-02-06 14:35:53 | Train | Epoch[358/600] Iteration[013/030] Train loss: 0.0101
2023-02-06 14:35:53 | Train | Epoch[358/600] Iteration[014/030] Train loss: 0.0101
2023-02-06 14:35:53 | Train | Epoch[358/600] Iteration[015/030] Train loss: 0.0103
2023-02-06 14:35:53 | Train | Epoch[358/600] Iteration[016/030] Train loss: 0.0103
2023-02-06 14:35:53 | Train | Epoch[358/600] Iteration[017/030] Train loss: 0.0103
2023-02-06 14:35:54 | Train | Epoch[358/600] Iteration[018/030] Train loss: 0.0103
2023-02-06 14:35:54 | Train | Epoch[358/600] Iteration[019/030] Train loss: 0.0102
2023-02-06 14:35:54 | Train | Epoch[358/600] Iteration[020/030] Train loss: 0.0102
2023-02-06 14:35:54 | Train | Epoch[358/600] Iteration[021/030] Train loss: 0.0102
2023-02-06 14:35:55 | Train | Epoch[358/600] Iteration[022/030] Train loss: 0.0102
2023-02-06 14:35:55 | Train | Epoch[358/600] Iteration[023/030] Train loss: 0.0102
2023-02-06 14:35:55 | Train | Epoch[358/600] Iteration[024/030] Train loss: 0.0103
2023-02-06 14:35:55 | Train | Epoch[358/600] Iteration[025/030] Train loss: 0.0103
2023-02-06 14:35:55 | Train | Epoch[358/600] Iteration[026/030] Train loss: 0.0102
2023-02-06 14:35:56 | Train | Epoch[358/600] Iteration[027/030] Train loss: 0.0102
2023-02-06 14:35:56 | Train | Epoch[358/600] Iteration[028/030] Train loss: 0.0102
2023-02-06 14:35:56 | Train | Epoch[358/600] Iteration[029/030] Train loss: 0.0102
2023-02-06 14:35:56 | Train | Epoch[358/600] Iteration[030/030] Train loss: 0.0101
2023-02-06 14:35:57 | Valid | Epoch[358/600] Iteration[001/008] Valid loss: 0.0910
2023-02-06 14:35:57 | Valid | Epoch[358/600] Iteration[002/008] Valid loss: 0.0789
2023-02-06 14:35:57 | Valid | Epoch[358/600] Iteration[003/008] Valid loss: 0.0765
2023-02-06 14:35:57 | Valid | Epoch[358/600] Iteration[004/008] Valid loss: 0.0734
2023-02-06 14:35:57 | Valid | Epoch[358/600] Iteration[005/008] Valid loss: 0.0715
2023-02-06 14:35:57 | Valid | Epoch[358/600] Iteration[006/008] Valid loss: 0.0685
2023-02-06 14:35:57 | Valid | Epoch[358/600] Iteration[007/008] Valid loss: 0.0664
2023-02-06 14:35:57 | Valid | Epoch[358/600] Iteration[008/008] Valid loss: 0.0659
2023-02-06 14:35:57 | Valid | Epoch[358/600] MIou: 0.8723575282985011
2023-02-06 14:35:57 | Valid | Epoch[358/600] Pixel Accuracy: 0.9788551330566406
2023-02-06 14:35:57 | Valid | Epoch[358/600] Mean Pixel Accuracy: 0.8859665834580528
2023-02-06 14:35:57 | Stage | Epoch[358/600] Train loss:0.0101
2023-02-06 14:35:57 | Stage | Epoch[358/600] Valid loss:0.0659
2023-02-06 14:35:57 | Stage | Epoch[358/600] LR:0.01

2023-02-06 14:35:57 | Train | Epoch[359/600] Iteration[001/030] Train loss: 0.0100
2023-02-06 14:35:58 | Train | Epoch[359/600] Iteration[002/030] Train loss: 0.0102
2023-02-06 14:35:58 | Train | Epoch[359/600] Iteration[003/030] Train loss: 0.0102
2023-02-06 14:35:58 | Train | Epoch[359/600] Iteration[004/030] Train loss: 0.0102
2023-02-06 14:35:58 | Train | Epoch[359/600] Iteration[005/030] Train loss: 0.0099
2023-02-06 14:35:59 | Train | Epoch[359/600] Iteration[006/030] Train loss: 0.0099
2023-02-06 14:35:59 | Train | Epoch[359/600] Iteration[007/030] Train loss: 0.0096
2023-02-06 14:35:59 | Train | Epoch[359/600] Iteration[008/030] Train loss: 0.0097
2023-02-06 14:35:59 | Train | Epoch[359/600] Iteration[009/030] Train loss: 0.0096
2023-02-06 14:35:59 | Train | Epoch[359/600] Iteration[010/030] Train loss: 0.0097
2023-02-06 14:36:00 | Train | Epoch[359/600] Iteration[011/030] Train loss: 0.0097
2023-02-06 14:36:00 | Train | Epoch[359/600] Iteration[012/030] Train loss: 0.0098
2023-02-06 14:36:00 | Train | Epoch[359/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:36:00 | Train | Epoch[359/600] Iteration[014/030] Train loss: 0.0098
2023-02-06 14:36:00 | Train | Epoch[359/600] Iteration[015/030] Train loss: 0.0097
2023-02-06 14:36:01 | Train | Epoch[359/600] Iteration[016/030] Train loss: 0.0098
2023-02-06 14:36:01 | Train | Epoch[359/600] Iteration[017/030] Train loss: 0.0098
2023-02-06 14:36:01 | Train | Epoch[359/600] Iteration[018/030] Train loss: 0.0099
2023-02-06 14:36:01 | Train | Epoch[359/600] Iteration[019/030] Train loss: 0.0099
2023-02-06 14:36:02 | Train | Epoch[359/600] Iteration[020/030] Train loss: 0.0098
2023-02-06 14:36:02 | Train | Epoch[359/600] Iteration[021/030] Train loss: 0.0098
2023-02-06 14:36:02 | Train | Epoch[359/600] Iteration[022/030] Train loss: 0.0099
2023-02-06 14:36:02 | Train | Epoch[359/600] Iteration[023/030] Train loss: 0.0099
2023-02-06 14:36:02 | Train | Epoch[359/600] Iteration[024/030] Train loss: 0.0099
2023-02-06 14:36:03 | Train | Epoch[359/600] Iteration[025/030] Train loss: 0.0099
2023-02-06 14:36:03 | Train | Epoch[359/600] Iteration[026/030] Train loss: 0.0098
2023-02-06 14:36:03 | Train | Epoch[359/600] Iteration[027/030] Train loss: 0.0098
2023-02-06 14:36:03 | Train | Epoch[359/600] Iteration[028/030] Train loss: 0.0098
2023-02-06 14:36:04 | Train | Epoch[359/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:36:04 | Train | Epoch[359/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:36:04 | Valid | Epoch[359/600] Iteration[001/008] Valid loss: 0.1032
2023-02-06 14:36:04 | Valid | Epoch[359/600] Iteration[002/008] Valid loss: 0.0789
2023-02-06 14:36:04 | Valid | Epoch[359/600] Iteration[003/008] Valid loss: 0.0787
2023-02-06 14:36:04 | Valid | Epoch[359/600] Iteration[004/008] Valid loss: 0.0785
2023-02-06 14:36:04 | Valid | Epoch[359/600] Iteration[005/008] Valid loss: 0.0760
2023-02-06 14:36:04 | Valid | Epoch[359/600] Iteration[006/008] Valid loss: 0.0739
2023-02-06 14:36:04 | Valid | Epoch[359/600] Iteration[007/008] Valid loss: 0.0751
2023-02-06 14:36:04 | Valid | Epoch[359/600] Iteration[008/008] Valid loss: 0.0725
2023-02-06 14:36:04 | Valid | Epoch[359/600] MIou: 0.9102059383381214
2023-02-06 14:36:04 | Valid | Epoch[359/600] Pixel Accuracy: 0.9849128723144531
2023-02-06 14:36:04 | Valid | Epoch[359/600] Mean Pixel Accuracy: 0.9269839379782796
2023-02-06 14:36:04 | Stage | Epoch[359/600] Train loss:0.0098
2023-02-06 14:36:04 | Stage | Epoch[359/600] Valid loss:0.0725
2023-02-06 14:36:04 | Stage | Epoch[359/600] LR:0.01

2023-02-06 14:36:05 | Train | Epoch[360/600] Iteration[001/030] Train loss: 0.0101
2023-02-06 14:36:05 | Train | Epoch[360/600] Iteration[002/030] Train loss: 0.0096
2023-02-06 14:36:05 | Train | Epoch[360/600] Iteration[003/030] Train loss: 0.0095
2023-02-06 14:36:06 | Train | Epoch[360/600] Iteration[004/030] Train loss: 0.0091
2023-02-06 14:36:06 | Train | Epoch[360/600] Iteration[005/030] Train loss: 0.0092
2023-02-06 14:36:06 | Train | Epoch[360/600] Iteration[006/030] Train loss: 0.0093
2023-02-06 14:36:06 | Train | Epoch[360/600] Iteration[007/030] Train loss: 0.0097
2023-02-06 14:36:06 | Train | Epoch[360/600] Iteration[008/030] Train loss: 0.0096
2023-02-06 14:36:07 | Train | Epoch[360/600] Iteration[009/030] Train loss: 0.0095
2023-02-06 14:36:07 | Train | Epoch[360/600] Iteration[010/030] Train loss: 0.0095
2023-02-06 14:36:07 | Train | Epoch[360/600] Iteration[011/030] Train loss: 0.0094
2023-02-06 14:36:07 | Train | Epoch[360/600] Iteration[012/030] Train loss: 0.0097
2023-02-06 14:36:08 | Train | Epoch[360/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:36:08 | Train | Epoch[360/600] Iteration[014/030] Train loss: 0.0096
2023-02-06 14:36:08 | Train | Epoch[360/600] Iteration[015/030] Train loss: 0.0097
2023-02-06 14:36:08 | Train | Epoch[360/600] Iteration[016/030] Train loss: 0.0097
2023-02-06 14:36:08 | Train | Epoch[360/600] Iteration[017/030] Train loss: 0.0097
2023-02-06 14:36:09 | Train | Epoch[360/600] Iteration[018/030] Train loss: 0.0097
2023-02-06 14:36:09 | Train | Epoch[360/600] Iteration[019/030] Train loss: 0.0096
2023-02-06 14:36:09 | Train | Epoch[360/600] Iteration[020/030] Train loss: 0.0097
2023-02-06 14:36:09 | Train | Epoch[360/600] Iteration[021/030] Train loss: 0.0097
2023-02-06 14:36:10 | Train | Epoch[360/600] Iteration[022/030] Train loss: 0.0097
2023-02-06 14:36:10 | Train | Epoch[360/600] Iteration[023/030] Train loss: 0.0096
2023-02-06 14:36:10 | Train | Epoch[360/600] Iteration[024/030] Train loss: 0.0096
2023-02-06 14:36:10 | Train | Epoch[360/600] Iteration[025/030] Train loss: 0.0097
2023-02-06 14:36:10 | Train | Epoch[360/600] Iteration[026/030] Train loss: 0.0097
2023-02-06 14:36:11 | Train | Epoch[360/600] Iteration[027/030] Train loss: 0.0097
2023-02-06 14:36:11 | Train | Epoch[360/600] Iteration[028/030] Train loss: 0.0097
2023-02-06 14:36:11 | Train | Epoch[360/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:36:11 | Train | Epoch[360/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:36:12 | Valid | Epoch[360/600] Iteration[001/008] Valid loss: 0.3272
2023-02-06 14:36:12 | Valid | Epoch[360/600] Iteration[002/008] Valid loss: 0.2637
2023-02-06 14:36:12 | Valid | Epoch[360/600] Iteration[003/008] Valid loss: 0.2565
2023-02-06 14:36:12 | Valid | Epoch[360/600] Iteration[004/008] Valid loss: 0.2491
2023-02-06 14:36:12 | Valid | Epoch[360/600] Iteration[005/008] Valid loss: 0.2548
2023-02-06 14:36:12 | Valid | Epoch[360/600] Iteration[006/008] Valid loss: 0.2564
2023-02-06 14:36:12 | Valid | Epoch[360/600] Iteration[007/008] Valid loss: 0.2743
2023-02-06 14:36:12 | Valid | Epoch[360/600] Iteration[008/008] Valid loss: 0.2775
2023-02-06 14:36:12 | Valid | Epoch[360/600] MIou: 0.908662763871988
2023-02-06 14:36:12 | Valid | Epoch[360/600] Pixel Accuracy: 0.9830271402994791
2023-02-06 14:36:12 | Valid | Epoch[360/600] Mean Pixel Accuracy: 0.9714340018659852
2023-02-06 14:36:12 | Stage | Epoch[360/600] Train loss:0.0098
2023-02-06 14:36:12 | Stage | Epoch[360/600] Valid loss:0.2775
2023-02-06 14:36:12 | Stage | Epoch[360/600] LR:0.01

2023-02-06 14:36:13 | Train | Epoch[361/600] Iteration[001/030] Train loss: 0.0100
2023-02-06 14:36:13 | Train | Epoch[361/600] Iteration[002/030] Train loss: 0.0097
2023-02-06 14:36:13 | Train | Epoch[361/600] Iteration[003/030] Train loss: 0.0093
2023-02-06 14:36:13 | Train | Epoch[361/600] Iteration[004/030] Train loss: 0.0092
2023-02-06 14:36:13 | Train | Epoch[361/600] Iteration[005/030] Train loss: 0.0094
2023-02-06 14:36:14 | Train | Epoch[361/600] Iteration[006/030] Train loss: 0.0094
2023-02-06 14:36:14 | Train | Epoch[361/600] Iteration[007/030] Train loss: 0.0093
2023-02-06 14:36:14 | Train | Epoch[361/600] Iteration[008/030] Train loss: 0.0095
2023-02-06 14:36:14 | Train | Epoch[361/600] Iteration[009/030] Train loss: 0.0094
2023-02-06 14:36:14 | Train | Epoch[361/600] Iteration[010/030] Train loss: 0.0093
2023-02-06 14:36:15 | Train | Epoch[361/600] Iteration[011/030] Train loss: 0.0095
2023-02-06 14:36:15 | Train | Epoch[361/600] Iteration[012/030] Train loss: 0.0096
2023-02-06 14:36:15 | Train | Epoch[361/600] Iteration[013/030] Train loss: 0.0095
2023-02-06 14:36:15 | Train | Epoch[361/600] Iteration[014/030] Train loss: 0.0095
2023-02-06 14:36:16 | Train | Epoch[361/600] Iteration[015/030] Train loss: 0.0094
2023-02-06 14:36:16 | Train | Epoch[361/600] Iteration[016/030] Train loss: 0.0095
2023-02-06 14:36:16 | Train | Epoch[361/600] Iteration[017/030] Train loss: 0.0094
2023-02-06 14:36:16 | Train | Epoch[361/600] Iteration[018/030] Train loss: 0.0095
2023-02-06 14:36:16 | Train | Epoch[361/600] Iteration[019/030] Train loss: 0.0095
2023-02-06 14:36:17 | Train | Epoch[361/600] Iteration[020/030] Train loss: 0.0095
2023-02-06 14:36:17 | Train | Epoch[361/600] Iteration[021/030] Train loss: 0.0095
2023-02-06 14:36:17 | Train | Epoch[361/600] Iteration[022/030] Train loss: 0.0095
2023-02-06 14:36:17 | Train | Epoch[361/600] Iteration[023/030] Train loss: 0.0096
2023-02-06 14:36:18 | Train | Epoch[361/600] Iteration[024/030] Train loss: 0.0097
2023-02-06 14:36:18 | Train | Epoch[361/600] Iteration[025/030] Train loss: 0.0097
2023-02-06 14:36:18 | Train | Epoch[361/600] Iteration[026/030] Train loss: 0.0097
2023-02-06 14:36:18 | Train | Epoch[361/600] Iteration[027/030] Train loss: 0.0097
2023-02-06 14:36:18 | Train | Epoch[361/600] Iteration[028/030] Train loss: 0.0097
2023-02-06 14:36:19 | Train | Epoch[361/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:36:19 | Train | Epoch[361/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:36:19 | Valid | Epoch[361/600] Iteration[001/008] Valid loss: 0.1496
2023-02-06 14:36:19 | Valid | Epoch[361/600] Iteration[002/008] Valid loss: 0.1092
2023-02-06 14:36:19 | Valid | Epoch[361/600] Iteration[003/008] Valid loss: 0.1038
2023-02-06 14:36:19 | Valid | Epoch[361/600] Iteration[004/008] Valid loss: 0.0980
2023-02-06 14:36:19 | Valid | Epoch[361/600] Iteration[005/008] Valid loss: 0.1004
2023-02-06 14:36:19 | Valid | Epoch[361/600] Iteration[006/008] Valid loss: 0.0941
2023-02-06 14:36:19 | Valid | Epoch[361/600] Iteration[007/008] Valid loss: 0.0989
2023-02-06 14:36:19 | Valid | Epoch[361/600] Iteration[008/008] Valid loss: 0.0985
2023-02-06 14:36:20 | Valid | Epoch[361/600] MIou: 0.9205324340425576
2023-02-06 14:36:20 | Valid | Epoch[361/600] Pixel Accuracy: 0.9863726298014323
2023-02-06 14:36:20 | Valid | Epoch[361/600] Mean Pixel Accuracy: 0.9457298173294603
2023-02-06 14:36:20 | Stage | Epoch[361/600] Train loss:0.0098
2023-02-06 14:36:20 | Stage | Epoch[361/600] Valid loss:0.0985
2023-02-06 14:36:20 | Stage | Epoch[361/600] LR:0.01

2023-02-06 14:36:20 | Train | Epoch[362/600] Iteration[001/030] Train loss: 0.0103
2023-02-06 14:36:20 | Train | Epoch[362/600] Iteration[002/030] Train loss: 0.0092
2023-02-06 14:36:20 | Train | Epoch[362/600] Iteration[003/030] Train loss: 0.0106
2023-02-06 14:36:21 | Train | Epoch[362/600] Iteration[004/030] Train loss: 0.0107
2023-02-06 14:36:21 | Train | Epoch[362/600] Iteration[005/030] Train loss: 0.0103
2023-02-06 14:36:21 | Train | Epoch[362/600] Iteration[006/030] Train loss: 0.0105
2023-02-06 14:36:21 | Train | Epoch[362/600] Iteration[007/030] Train loss: 0.0104
2023-02-06 14:36:22 | Train | Epoch[362/600] Iteration[008/030] Train loss: 0.0102
2023-02-06 14:36:22 | Train | Epoch[362/600] Iteration[009/030] Train loss: 0.0100
2023-02-06 14:36:22 | Train | Epoch[362/600] Iteration[010/030] Train loss: 0.0098
2023-02-06 14:36:22 | Train | Epoch[362/600] Iteration[011/030] Train loss: 0.0101
2023-02-06 14:36:22 | Train | Epoch[362/600] Iteration[012/030] Train loss: 0.0099
2023-02-06 14:36:23 | Train | Epoch[362/600] Iteration[013/030] Train loss: 0.0099
2023-02-06 14:36:23 | Train | Epoch[362/600] Iteration[014/030] Train loss: 0.0100
2023-02-06 14:36:23 | Train | Epoch[362/600] Iteration[015/030] Train loss: 0.0099
2023-02-06 14:36:23 | Train | Epoch[362/600] Iteration[016/030] Train loss: 0.0099
2023-02-06 14:36:24 | Train | Epoch[362/600] Iteration[017/030] Train loss: 0.0098
2023-02-06 14:36:24 | Train | Epoch[362/600] Iteration[018/030] Train loss: 0.0099
2023-02-06 14:36:24 | Train | Epoch[362/600] Iteration[019/030] Train loss: 0.0100
2023-02-06 14:36:24 | Train | Epoch[362/600] Iteration[020/030] Train loss: 0.0100
2023-02-06 14:36:24 | Train | Epoch[362/600] Iteration[021/030] Train loss: 0.0100
2023-02-06 14:36:25 | Train | Epoch[362/600] Iteration[022/030] Train loss: 0.0100
2023-02-06 14:36:25 | Train | Epoch[362/600] Iteration[023/030] Train loss: 0.0100
2023-02-06 14:36:25 | Train | Epoch[362/600] Iteration[024/030] Train loss: 0.0100
2023-02-06 14:36:25 | Train | Epoch[362/600] Iteration[025/030] Train loss: 0.0099
2023-02-06 14:36:25 | Train | Epoch[362/600] Iteration[026/030] Train loss: 0.0099
2023-02-06 14:36:26 | Train | Epoch[362/600] Iteration[027/030] Train loss: 0.0099
2023-02-06 14:36:26 | Train | Epoch[362/600] Iteration[028/030] Train loss: 0.0099
2023-02-06 14:36:26 | Train | Epoch[362/600] Iteration[029/030] Train loss: 0.0099
2023-02-06 14:36:26 | Train | Epoch[362/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:36:27 | Valid | Epoch[362/600] Iteration[001/008] Valid loss: 0.1562
2023-02-06 14:36:27 | Valid | Epoch[362/600] Iteration[002/008] Valid loss: 0.1192
2023-02-06 14:36:27 | Valid | Epoch[362/600] Iteration[003/008] Valid loss: 0.1098
2023-02-06 14:36:27 | Valid | Epoch[362/600] Iteration[004/008] Valid loss: 0.1026
2023-02-06 14:36:27 | Valid | Epoch[362/600] Iteration[005/008] Valid loss: 0.1002
2023-02-06 14:36:27 | Valid | Epoch[362/600] Iteration[006/008] Valid loss: 0.0956
2023-02-06 14:36:27 | Valid | Epoch[362/600] Iteration[007/008] Valid loss: 0.1021
2023-02-06 14:36:27 | Valid | Epoch[362/600] Iteration[008/008] Valid loss: 0.1009
2023-02-06 14:36:27 | Valid | Epoch[362/600] MIou: 0.9292541184660119
2023-02-06 14:36:27 | Valid | Epoch[362/600] Pixel Accuracy: 0.9878743489583334
2023-02-06 14:36:27 | Valid | Epoch[362/600] Mean Pixel Accuracy: 0.953859449406782
2023-02-06 14:36:27 | Stage | Epoch[362/600] Train loss:0.0098
2023-02-06 14:36:27 | Stage | Epoch[362/600] Valid loss:0.1009
2023-02-06 14:36:27 | Stage | Epoch[362/600] LR:0.01

2023-02-06 14:36:27 | Train | Epoch[363/600] Iteration[001/030] Train loss: 0.0093
2023-02-06 14:36:28 | Train | Epoch[363/600] Iteration[002/030] Train loss: 0.0090
2023-02-06 14:36:28 | Train | Epoch[363/600] Iteration[003/030] Train loss: 0.0088
2023-02-06 14:36:28 | Train | Epoch[363/600] Iteration[004/030] Train loss: 0.0088
2023-02-06 14:36:28 | Train | Epoch[363/600] Iteration[005/030] Train loss: 0.0085
2023-02-06 14:36:29 | Train | Epoch[363/600] Iteration[006/030] Train loss: 0.0088
2023-02-06 14:36:29 | Train | Epoch[363/600] Iteration[007/030] Train loss: 0.0088
2023-02-06 14:36:29 | Train | Epoch[363/600] Iteration[008/030] Train loss: 0.0090
2023-02-06 14:36:29 | Train | Epoch[363/600] Iteration[009/030] Train loss: 0.0090
2023-02-06 14:36:29 | Train | Epoch[363/600] Iteration[010/030] Train loss: 0.0090
2023-02-06 14:36:30 | Train | Epoch[363/600] Iteration[011/030] Train loss: 0.0089
2023-02-06 14:36:30 | Train | Epoch[363/600] Iteration[012/030] Train loss: 0.0090
2023-02-06 14:36:30 | Train | Epoch[363/600] Iteration[013/030] Train loss: 0.0090
2023-02-06 14:36:30 | Train | Epoch[363/600] Iteration[014/030] Train loss: 0.0091
2023-02-06 14:36:30 | Train | Epoch[363/600] Iteration[015/030] Train loss: 0.0091
2023-02-06 14:36:31 | Train | Epoch[363/600] Iteration[016/030] Train loss: 0.0091
2023-02-06 14:36:31 | Train | Epoch[363/600] Iteration[017/030] Train loss: 0.0091
2023-02-06 14:36:31 | Train | Epoch[363/600] Iteration[018/030] Train loss: 0.0091
2023-02-06 14:36:31 | Train | Epoch[363/600] Iteration[019/030] Train loss: 0.0091
2023-02-06 14:36:32 | Train | Epoch[363/600] Iteration[020/030] Train loss: 0.0091
2023-02-06 14:36:32 | Train | Epoch[363/600] Iteration[021/030] Train loss: 0.0090
2023-02-06 14:36:32 | Train | Epoch[363/600] Iteration[022/030] Train loss: 0.0091
2023-02-06 14:36:32 | Train | Epoch[363/600] Iteration[023/030] Train loss: 0.0092
2023-02-06 14:36:32 | Train | Epoch[363/600] Iteration[024/030] Train loss: 0.0092
2023-02-06 14:36:33 | Train | Epoch[363/600] Iteration[025/030] Train loss: 0.0092
2023-02-06 14:36:33 | Train | Epoch[363/600] Iteration[026/030] Train loss: 0.0093
2023-02-06 14:36:33 | Train | Epoch[363/600] Iteration[027/030] Train loss: 0.0093
2023-02-06 14:36:33 | Train | Epoch[363/600] Iteration[028/030] Train loss: 0.0094
2023-02-06 14:36:34 | Train | Epoch[363/600] Iteration[029/030] Train loss: 0.0094
2023-02-06 14:36:34 | Train | Epoch[363/600] Iteration[030/030] Train loss: 0.0094
2023-02-06 14:36:34 | Valid | Epoch[363/600] Iteration[001/008] Valid loss: 0.1512
2023-02-06 14:36:34 | Valid | Epoch[363/600] Iteration[002/008] Valid loss: 0.1118
2023-02-06 14:36:34 | Valid | Epoch[363/600] Iteration[003/008] Valid loss: 0.1069
2023-02-06 14:36:34 | Valid | Epoch[363/600] Iteration[004/008] Valid loss: 0.1014
2023-02-06 14:36:34 | Valid | Epoch[363/600] Iteration[005/008] Valid loss: 0.0974
2023-02-06 14:36:34 | Valid | Epoch[363/600] Iteration[006/008] Valid loss: 0.0949
2023-02-06 14:36:34 | Valid | Epoch[363/600] Iteration[007/008] Valid loss: 0.0985
2023-02-06 14:36:34 | Valid | Epoch[363/600] Iteration[008/008] Valid loss: 0.0961
2023-02-06 14:36:34 | Valid | Epoch[363/600] MIou: 0.9247391342800095
2023-02-06 14:36:34 | Valid | Epoch[363/600] Pixel Accuracy: 0.9870592753092448
2023-02-06 14:36:34 | Valid | Epoch[363/600] Mean Pixel Accuracy: 0.950983049578066
2023-02-06 14:36:34 | Stage | Epoch[363/600] Train loss:0.0094
2023-02-06 14:36:34 | Stage | Epoch[363/600] Valid loss:0.0961
2023-02-06 14:36:34 | Stage | Epoch[363/600] LR:0.01

2023-02-06 14:36:35 | Train | Epoch[364/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 14:36:35 | Train | Epoch[364/600] Iteration[002/030] Train loss: 0.0089
2023-02-06 14:36:35 | Train | Epoch[364/600] Iteration[003/030] Train loss: 0.0086
2023-02-06 14:36:36 | Train | Epoch[364/600] Iteration[004/030] Train loss: 0.0089
2023-02-06 14:36:36 | Train | Epoch[364/600] Iteration[005/030] Train loss: 0.0090
2023-02-06 14:36:36 | Train | Epoch[364/600] Iteration[006/030] Train loss: 0.0089
2023-02-06 14:36:36 | Train | Epoch[364/600] Iteration[007/030] Train loss: 0.0092
2023-02-06 14:36:36 | Train | Epoch[364/600] Iteration[008/030] Train loss: 0.0092
2023-02-06 14:36:37 | Train | Epoch[364/600] Iteration[009/030] Train loss: 0.0092
2023-02-06 14:36:37 | Train | Epoch[364/600] Iteration[010/030] Train loss: 0.0094
2023-02-06 14:36:37 | Train | Epoch[364/600] Iteration[011/030] Train loss: 0.0095
2023-02-06 14:36:37 | Train | Epoch[364/600] Iteration[012/030] Train loss: 0.0095
2023-02-06 14:36:38 | Train | Epoch[364/600] Iteration[013/030] Train loss: 0.0095
2023-02-06 14:36:38 | Train | Epoch[364/600] Iteration[014/030] Train loss: 0.0094
2023-02-06 14:36:38 | Train | Epoch[364/600] Iteration[015/030] Train loss: 0.0094
2023-02-06 14:36:38 | Train | Epoch[364/600] Iteration[016/030] Train loss: 0.0094
2023-02-06 14:36:38 | Train | Epoch[364/600] Iteration[017/030] Train loss: 0.0094
2023-02-06 14:36:39 | Train | Epoch[364/600] Iteration[018/030] Train loss: 0.0095
2023-02-06 14:36:39 | Train | Epoch[364/600] Iteration[019/030] Train loss: 0.0095
2023-02-06 14:36:39 | Train | Epoch[364/600] Iteration[020/030] Train loss: 0.0095
2023-02-06 14:36:39 | Train | Epoch[364/600] Iteration[021/030] Train loss: 0.0095
2023-02-06 14:36:39 | Train | Epoch[364/600] Iteration[022/030] Train loss: 0.0095
2023-02-06 14:36:40 | Train | Epoch[364/600] Iteration[023/030] Train loss: 0.0095
2023-02-06 14:36:40 | Train | Epoch[364/600] Iteration[024/030] Train loss: 0.0096
2023-02-06 14:36:40 | Train | Epoch[364/600] Iteration[025/030] Train loss: 0.0095
2023-02-06 14:36:40 | Train | Epoch[364/600] Iteration[026/030] Train loss: 0.0095
2023-02-06 14:36:41 | Train | Epoch[364/600] Iteration[027/030] Train loss: 0.0095
2023-02-06 14:36:41 | Train | Epoch[364/600] Iteration[028/030] Train loss: 0.0095
2023-02-06 14:36:41 | Train | Epoch[364/600] Iteration[029/030] Train loss: 0.0095
2023-02-06 14:36:41 | Train | Epoch[364/600] Iteration[030/030] Train loss: 0.0095
2023-02-06 14:36:41 | Valid | Epoch[364/600] Iteration[001/008] Valid loss: 0.0894
2023-02-06 14:36:42 | Valid | Epoch[364/600] Iteration[002/008] Valid loss: 0.0752
2023-02-06 14:36:42 | Valid | Epoch[364/600] Iteration[003/008] Valid loss: 0.0720
2023-02-06 14:36:42 | Valid | Epoch[364/600] Iteration[004/008] Valid loss: 0.0681
2023-02-06 14:36:42 | Valid | Epoch[364/600] Iteration[005/008] Valid loss: 0.0677
2023-02-06 14:36:42 | Valid | Epoch[364/600] Iteration[006/008] Valid loss: 0.0642
2023-02-06 14:36:42 | Valid | Epoch[364/600] Iteration[007/008] Valid loss: 0.0621
2023-02-06 14:36:42 | Valid | Epoch[364/600] Iteration[008/008] Valid loss: 0.0618
2023-02-06 14:36:42 | Valid | Epoch[364/600] MIou: 0.8873787399021957
2023-02-06 14:36:42 | Valid | Epoch[364/600] Pixel Accuracy: 0.9811897277832031
2023-02-06 14:36:42 | Valid | Epoch[364/600] Mean Pixel Accuracy: 0.9031516788401246
2023-02-06 14:36:42 | Stage | Epoch[364/600] Train loss:0.0095
2023-02-06 14:36:42 | Stage | Epoch[364/600] Valid loss:0.0618
2023-02-06 14:36:42 | Stage | Epoch[364/600] LR:0.01

2023-02-06 14:36:42 | Train | Epoch[365/600] Iteration[001/030] Train loss: 0.0095
2023-02-06 14:36:43 | Train | Epoch[365/600] Iteration[002/030] Train loss: 0.0094
2023-02-06 14:36:43 | Train | Epoch[365/600] Iteration[003/030] Train loss: 0.0089
2023-02-06 14:36:43 | Train | Epoch[365/600] Iteration[004/030] Train loss: 0.0090
2023-02-06 14:36:43 | Train | Epoch[365/600] Iteration[005/030] Train loss: 0.0090
2023-02-06 14:36:43 | Train | Epoch[365/600] Iteration[006/030] Train loss: 0.0098
2023-02-06 14:36:44 | Train | Epoch[365/600] Iteration[007/030] Train loss: 0.0096
2023-02-06 14:36:44 | Train | Epoch[365/600] Iteration[008/030] Train loss: 0.0096
2023-02-06 14:36:44 | Train | Epoch[365/600] Iteration[009/030] Train loss: 0.0094
2023-02-06 14:36:44 | Train | Epoch[365/600] Iteration[010/030] Train loss: 0.0095
2023-02-06 14:36:45 | Train | Epoch[365/600] Iteration[011/030] Train loss: 0.0094
2023-02-06 14:36:45 | Train | Epoch[365/600] Iteration[012/030] Train loss: 0.0095
2023-02-06 14:36:45 | Train | Epoch[365/600] Iteration[013/030] Train loss: 0.0095
2023-02-06 14:36:45 | Train | Epoch[365/600] Iteration[014/030] Train loss: 0.0095
2023-02-06 14:36:45 | Train | Epoch[365/600] Iteration[015/030] Train loss: 0.0095
2023-02-06 14:36:46 | Train | Epoch[365/600] Iteration[016/030] Train loss: 0.0094
2023-02-06 14:36:46 | Train | Epoch[365/600] Iteration[017/030] Train loss: 0.0094
2023-02-06 14:36:46 | Train | Epoch[365/600] Iteration[018/030] Train loss: 0.0093
2023-02-06 14:36:46 | Train | Epoch[365/600] Iteration[019/030] Train loss: 0.0093
2023-02-06 14:36:47 | Train | Epoch[365/600] Iteration[020/030] Train loss: 0.0094
2023-02-06 14:36:47 | Train | Epoch[365/600] Iteration[021/030] Train loss: 0.0094
2023-02-06 14:36:47 | Train | Epoch[365/600] Iteration[022/030] Train loss: 0.0094
2023-02-06 14:36:47 | Train | Epoch[365/600] Iteration[023/030] Train loss: 0.0094
2023-02-06 14:36:47 | Train | Epoch[365/600] Iteration[024/030] Train loss: 0.0094
2023-02-06 14:36:48 | Train | Epoch[365/600] Iteration[025/030] Train loss: 0.0094
2023-02-06 14:36:48 | Train | Epoch[365/600] Iteration[026/030] Train loss: 0.0095
2023-02-06 14:36:48 | Train | Epoch[365/600] Iteration[027/030] Train loss: 0.0096
2023-02-06 14:36:48 | Train | Epoch[365/600] Iteration[028/030] Train loss: 0.0095
2023-02-06 14:36:49 | Train | Epoch[365/600] Iteration[029/030] Train loss: 0.0096
2023-02-06 14:36:49 | Train | Epoch[365/600] Iteration[030/030] Train loss: 0.0097
2023-02-06 14:36:49 | Valid | Epoch[365/600] Iteration[001/008] Valid loss: 0.0853
2023-02-06 14:36:49 | Valid | Epoch[365/600] Iteration[002/008] Valid loss: 0.0777
2023-02-06 14:36:49 | Valid | Epoch[365/600] Iteration[003/008] Valid loss: 0.0781
2023-02-06 14:36:49 | Valid | Epoch[365/600] Iteration[004/008] Valid loss: 0.0764
2023-02-06 14:36:49 | Valid | Epoch[365/600] Iteration[005/008] Valid loss: 0.0760
2023-02-06 14:36:49 | Valid | Epoch[365/600] Iteration[006/008] Valid loss: 0.0740
2023-02-06 14:36:49 | Valid | Epoch[365/600] Iteration[007/008] Valid loss: 0.0706
2023-02-06 14:36:49 | Valid | Epoch[365/600] Iteration[008/008] Valid loss: 0.0707
2023-02-06 14:36:49 | Valid | Epoch[365/600] MIou: 0.8581504633898538
2023-02-06 14:36:49 | Valid | Epoch[365/600] Pixel Accuracy: 0.9765141805013021
2023-02-06 14:36:49 | Valid | Epoch[365/600] Mean Pixel Accuracy: 0.8726266597499632
2023-02-06 14:36:49 | Stage | Epoch[365/600] Train loss:0.0097
2023-02-06 14:36:49 | Stage | Epoch[365/600] Valid loss:0.0707
2023-02-06 14:36:49 | Stage | Epoch[365/600] LR:0.01

2023-02-06 14:36:50 | Train | Epoch[366/600] Iteration[001/030] Train loss: 0.0084
2023-02-06 14:36:50 | Train | Epoch[366/600] Iteration[002/030] Train loss: 0.0089
2023-02-06 14:36:50 | Train | Epoch[366/600] Iteration[003/030] Train loss: 0.0089
2023-02-06 14:36:51 | Train | Epoch[366/600] Iteration[004/030] Train loss: 0.0088
2023-02-06 14:36:51 | Train | Epoch[366/600] Iteration[005/030] Train loss: 0.0087
2023-02-06 14:36:51 | Train | Epoch[366/600] Iteration[006/030] Train loss: 0.0087
2023-02-06 14:36:51 | Train | Epoch[366/600] Iteration[007/030] Train loss: 0.0090
2023-02-06 14:36:51 | Train | Epoch[366/600] Iteration[008/030] Train loss: 0.0091
2023-02-06 14:36:52 | Train | Epoch[366/600] Iteration[009/030] Train loss: 0.0090
2023-02-06 14:36:52 | Train | Epoch[366/600] Iteration[010/030] Train loss: 0.0090
2023-02-06 14:36:52 | Train | Epoch[366/600] Iteration[011/030] Train loss: 0.0090
2023-02-06 14:36:52 | Train | Epoch[366/600] Iteration[012/030] Train loss: 0.0091
2023-02-06 14:36:53 | Train | Epoch[366/600] Iteration[013/030] Train loss: 0.0090
2023-02-06 14:36:53 | Train | Epoch[366/600] Iteration[014/030] Train loss: 0.0092
2023-02-06 14:36:53 | Train | Epoch[366/600] Iteration[015/030] Train loss: 0.0092
2023-02-06 14:36:53 | Train | Epoch[366/600] Iteration[016/030] Train loss: 0.0093
2023-02-06 14:36:53 | Train | Epoch[366/600] Iteration[017/030] Train loss: 0.0093
2023-02-06 14:36:54 | Train | Epoch[366/600] Iteration[018/030] Train loss: 0.0093
2023-02-06 14:36:54 | Train | Epoch[366/600] Iteration[019/030] Train loss: 0.0093
2023-02-06 14:36:54 | Train | Epoch[366/600] Iteration[020/030] Train loss: 0.0093
2023-02-06 14:36:54 | Train | Epoch[366/600] Iteration[021/030] Train loss: 0.0094
2023-02-06 14:36:55 | Train | Epoch[366/600] Iteration[022/030] Train loss: 0.0094
2023-02-06 14:36:55 | Train | Epoch[366/600] Iteration[023/030] Train loss: 0.0094
2023-02-06 14:36:55 | Train | Epoch[366/600] Iteration[024/030] Train loss: 0.0094
2023-02-06 14:36:55 | Train | Epoch[366/600] Iteration[025/030] Train loss: 0.0095
2023-02-06 14:36:55 | Train | Epoch[366/600] Iteration[026/030] Train loss: 0.0096
2023-02-06 14:36:56 | Train | Epoch[366/600] Iteration[027/030] Train loss: 0.0096
2023-02-06 14:36:56 | Train | Epoch[366/600] Iteration[028/030] Train loss: 0.0096
2023-02-06 14:36:56 | Train | Epoch[366/600] Iteration[029/030] Train loss: 0.0096
2023-02-06 14:36:56 | Train | Epoch[366/600] Iteration[030/030] Train loss: 0.0097
2023-02-06 14:36:57 | Valid | Epoch[366/600] Iteration[001/008] Valid loss: 3.2894
2023-02-06 14:36:57 | Valid | Epoch[366/600] Iteration[002/008] Valid loss: 3.2130
2023-02-06 14:36:57 | Valid | Epoch[366/600] Iteration[003/008] Valid loss: 3.4424
2023-02-06 14:36:57 | Valid | Epoch[366/600] Iteration[004/008] Valid loss: 3.5391
2023-02-06 14:36:57 | Valid | Epoch[366/600] Iteration[005/008] Valid loss: 3.6467
2023-02-06 14:36:57 | Valid | Epoch[366/600] Iteration[006/008] Valid loss: 3.6086
2023-02-06 14:36:57 | Valid | Epoch[366/600] Iteration[007/008] Valid loss: 3.7128
2023-02-06 14:36:57 | Valid | Epoch[366/600] Iteration[008/008] Valid loss: 3.8675
2023-02-06 14:36:57 | Valid | Epoch[366/600] MIou: 0.7395314396730981
2023-02-06 14:36:57 | Valid | Epoch[366/600] Pixel Accuracy: 0.9284350077311198
2023-02-06 14:36:57 | Valid | Epoch[366/600] Mean Pixel Accuracy: 0.9603097616712472
2023-02-06 14:36:57 | Stage | Epoch[366/600] Train loss:0.0097
2023-02-06 14:36:57 | Stage | Epoch[366/600] Valid loss:3.8675
2023-02-06 14:36:57 | Stage | Epoch[366/600] LR:0.01

2023-02-06 14:36:57 | Train | Epoch[367/600] Iteration[001/030] Train loss: 0.0111
2023-02-06 14:36:58 | Train | Epoch[367/600] Iteration[002/030] Train loss: 0.0105
2023-02-06 14:36:58 | Train | Epoch[367/600] Iteration[003/030] Train loss: 0.0101
2023-02-06 14:36:58 | Train | Epoch[367/600] Iteration[004/030] Train loss: 0.0106
2023-02-06 14:36:58 | Train | Epoch[367/600] Iteration[005/030] Train loss: 0.0105
2023-02-06 14:36:59 | Train | Epoch[367/600] Iteration[006/030] Train loss: 0.0105
2023-02-06 14:36:59 | Train | Epoch[367/600] Iteration[007/030] Train loss: 0.0104
2023-02-06 14:36:59 | Train | Epoch[367/600] Iteration[008/030] Train loss: 0.0106
2023-02-06 14:36:59 | Train | Epoch[367/600] Iteration[009/030] Train loss: 0.0104
2023-02-06 14:36:59 | Train | Epoch[367/600] Iteration[010/030] Train loss: 0.0105
2023-02-06 14:37:00 | Train | Epoch[367/600] Iteration[011/030] Train loss: 0.0104
2023-02-06 14:37:00 | Train | Epoch[367/600] Iteration[012/030] Train loss: 0.0103
2023-02-06 14:37:00 | Train | Epoch[367/600] Iteration[013/030] Train loss: 0.0102
2023-02-06 14:37:00 | Train | Epoch[367/600] Iteration[014/030] Train loss: 0.0102
2023-02-06 14:37:01 | Train | Epoch[367/600] Iteration[015/030] Train loss: 0.0103
2023-02-06 14:37:01 | Train | Epoch[367/600] Iteration[016/030] Train loss: 0.0101
2023-02-06 14:37:01 | Train | Epoch[367/600] Iteration[017/030] Train loss: 0.0102
2023-02-06 14:37:01 | Train | Epoch[367/600] Iteration[018/030] Train loss: 0.0100
2023-02-06 14:37:01 | Train | Epoch[367/600] Iteration[019/030] Train loss: 0.0100
2023-02-06 14:37:02 | Train | Epoch[367/600] Iteration[020/030] Train loss: 0.0100
2023-02-06 14:37:02 | Train | Epoch[367/600] Iteration[021/030] Train loss: 0.0100
2023-02-06 14:37:02 | Train | Epoch[367/600] Iteration[022/030] Train loss: 0.0100
2023-02-06 14:37:02 | Train | Epoch[367/600] Iteration[023/030] Train loss: 0.0101
2023-02-06 14:37:03 | Train | Epoch[367/600] Iteration[024/030] Train loss: 0.0101
2023-02-06 14:37:03 | Train | Epoch[367/600] Iteration[025/030] Train loss: 0.0103
2023-02-06 14:37:03 | Train | Epoch[367/600] Iteration[026/030] Train loss: 0.0102
2023-02-06 14:37:03 | Train | Epoch[367/600] Iteration[027/030] Train loss: 0.0105
2023-02-06 14:37:03 | Train | Epoch[367/600] Iteration[028/030] Train loss: 0.0105
2023-02-06 14:37:04 | Train | Epoch[367/600] Iteration[029/030] Train loss: 0.0105
2023-02-06 14:37:04 | Train | Epoch[367/600] Iteration[030/030] Train loss: 0.0105
2023-02-06 14:37:04 | Valid | Epoch[367/600] Iteration[001/008] Valid loss: 0.0984
2023-02-06 14:37:04 | Valid | Epoch[367/600] Iteration[002/008] Valid loss: 0.0815
2023-02-06 14:37:04 | Valid | Epoch[367/600] Iteration[003/008] Valid loss: 0.0777
2023-02-06 14:37:04 | Valid | Epoch[367/600] Iteration[004/008] Valid loss: 0.0740
2023-02-06 14:37:04 | Valid | Epoch[367/600] Iteration[005/008] Valid loss: 0.0729
2023-02-06 14:37:04 | Valid | Epoch[367/600] Iteration[006/008] Valid loss: 0.0695
2023-02-06 14:37:04 | Valid | Epoch[367/600] Iteration[007/008] Valid loss: 0.0668
2023-02-06 14:37:04 | Valid | Epoch[367/600] Iteration[008/008] Valid loss: 0.0661
2023-02-06 14:37:04 | Valid | Epoch[367/600] MIou: 0.8844778510639548
2023-02-06 14:37:04 | Valid | Epoch[367/600] Pixel Accuracy: 0.9808743794759115
2023-02-06 14:37:04 | Valid | Epoch[367/600] Mean Pixel Accuracy: 0.8969422210816571
2023-02-06 14:37:04 | Stage | Epoch[367/600] Train loss:0.0105
2023-02-06 14:37:04 | Stage | Epoch[367/600] Valid loss:0.0661
2023-02-06 14:37:04 | Stage | Epoch[367/600] LR:0.01

2023-02-06 14:37:05 | Train | Epoch[368/600] Iteration[001/030] Train loss: 0.0103
2023-02-06 14:37:05 | Train | Epoch[368/600] Iteration[002/030] Train loss: 0.0102
2023-02-06 14:37:05 | Train | Epoch[368/600] Iteration[003/030] Train loss: 0.0108
2023-02-06 14:37:06 | Train | Epoch[368/600] Iteration[004/030] Train loss: 0.0104
2023-02-06 14:37:06 | Train | Epoch[368/600] Iteration[005/030] Train loss: 0.0101
2023-02-06 14:37:06 | Train | Epoch[368/600] Iteration[006/030] Train loss: 0.0101
2023-02-06 14:37:06 | Train | Epoch[368/600] Iteration[007/030] Train loss: 0.0102
2023-02-06 14:37:06 | Train | Epoch[368/600] Iteration[008/030] Train loss: 0.0102
2023-02-06 14:37:07 | Train | Epoch[368/600] Iteration[009/030] Train loss: 0.0104
2023-02-06 14:37:07 | Train | Epoch[368/600] Iteration[010/030] Train loss: 0.0105
2023-02-06 14:37:07 | Train | Epoch[368/600] Iteration[011/030] Train loss: 0.0105
2023-02-06 14:37:07 | Train | Epoch[368/600] Iteration[012/030] Train loss: 0.0105
2023-02-06 14:37:08 | Train | Epoch[368/600] Iteration[013/030] Train loss: 0.0104
2023-02-06 14:37:08 | Train | Epoch[368/600] Iteration[014/030] Train loss: 0.0104
2023-02-06 14:37:08 | Train | Epoch[368/600] Iteration[015/030] Train loss: 0.0106
2023-02-06 14:37:08 | Train | Epoch[368/600] Iteration[016/030] Train loss: 0.0106
2023-02-06 14:37:08 | Train | Epoch[368/600] Iteration[017/030] Train loss: 0.0106
2023-02-06 14:37:09 | Train | Epoch[368/600] Iteration[018/030] Train loss: 0.0106
2023-02-06 14:37:09 | Train | Epoch[368/600] Iteration[019/030] Train loss: 0.0105
2023-02-06 14:37:09 | Train | Epoch[368/600] Iteration[020/030] Train loss: 0.0106
2023-02-06 14:37:09 | Train | Epoch[368/600] Iteration[021/030] Train loss: 0.0106
2023-02-06 14:37:09 | Train | Epoch[368/600] Iteration[022/030] Train loss: 0.0105
2023-02-06 14:37:10 | Train | Epoch[368/600] Iteration[023/030] Train loss: 0.0105
2023-02-06 14:37:10 | Train | Epoch[368/600] Iteration[024/030] Train loss: 0.0105
2023-02-06 14:37:10 | Train | Epoch[368/600] Iteration[025/030] Train loss: 0.0105
2023-02-06 14:37:10 | Train | Epoch[368/600] Iteration[026/030] Train loss: 0.0105
2023-02-06 14:37:11 | Train | Epoch[368/600] Iteration[027/030] Train loss: 0.0105
2023-02-06 14:37:11 | Train | Epoch[368/600] Iteration[028/030] Train loss: 0.0105
2023-02-06 14:37:11 | Train | Epoch[368/600] Iteration[029/030] Train loss: 0.0105
2023-02-06 14:37:11 | Train | Epoch[368/600] Iteration[030/030] Train loss: 0.0105
2023-02-06 14:37:11 | Valid | Epoch[368/600] Iteration[001/008] Valid loss: 0.1404
2023-02-06 14:37:12 | Valid | Epoch[368/600] Iteration[002/008] Valid loss: 0.1102
2023-02-06 14:37:12 | Valid | Epoch[368/600] Iteration[003/008] Valid loss: 0.1024
2023-02-06 14:37:12 | Valid | Epoch[368/600] Iteration[004/008] Valid loss: 0.1017
2023-02-06 14:37:12 | Valid | Epoch[368/600] Iteration[005/008] Valid loss: 0.0987
2023-02-06 14:37:12 | Valid | Epoch[368/600] Iteration[006/008] Valid loss: 0.0954
2023-02-06 14:37:12 | Valid | Epoch[368/600] Iteration[007/008] Valid loss: 0.1003
2023-02-06 14:37:12 | Valid | Epoch[368/600] Iteration[008/008] Valid loss: 0.0979
2023-02-06 14:37:12 | Valid | Epoch[368/600] MIou: 0.9233645860667096
2023-02-06 14:37:12 | Valid | Epoch[368/600] Pixel Accuracy: 0.9868253072102865
2023-02-06 14:37:12 | Valid | Epoch[368/600] Mean Pixel Accuracy: 0.9495800159584524
2023-02-06 14:37:12 | Stage | Epoch[368/600] Train loss:0.0105
2023-02-06 14:37:12 | Stage | Epoch[368/600] Valid loss:0.0979
2023-02-06 14:37:12 | Stage | Epoch[368/600] LR:0.01

2023-02-06 14:37:12 | Train | Epoch[369/600] Iteration[001/030] Train loss: 0.0129
2023-02-06 14:37:13 | Train | Epoch[369/600] Iteration[002/030] Train loss: 0.0112
2023-02-06 14:37:13 | Train | Epoch[369/600] Iteration[003/030] Train loss: 0.0104
2023-02-06 14:37:13 | Train | Epoch[369/600] Iteration[004/030] Train loss: 0.0100
2023-02-06 14:37:13 | Train | Epoch[369/600] Iteration[005/030] Train loss: 0.0101
2023-02-06 14:37:14 | Train | Epoch[369/600] Iteration[006/030] Train loss: 0.0103
2023-02-06 14:37:14 | Train | Epoch[369/600] Iteration[007/030] Train loss: 0.0105
2023-02-06 14:37:14 | Train | Epoch[369/600] Iteration[008/030] Train loss: 0.0104
2023-02-06 14:37:14 | Train | Epoch[369/600] Iteration[009/030] Train loss: 0.0105
2023-02-06 14:37:14 | Train | Epoch[369/600] Iteration[010/030] Train loss: 0.0104
2023-02-06 14:37:15 | Train | Epoch[369/600] Iteration[011/030] Train loss: 0.0104
2023-02-06 14:37:15 | Train | Epoch[369/600] Iteration[012/030] Train loss: 0.0105
2023-02-06 14:37:15 | Train | Epoch[369/600] Iteration[013/030] Train loss: 0.0107
2023-02-06 14:37:15 | Train | Epoch[369/600] Iteration[014/030] Train loss: 0.0105
2023-02-06 14:37:15 | Train | Epoch[369/600] Iteration[015/030] Train loss: 0.0105
2023-02-06 14:37:16 | Train | Epoch[369/600] Iteration[016/030] Train loss: 0.0105
2023-02-06 14:37:16 | Train | Epoch[369/600] Iteration[017/030] Train loss: 0.0104
2023-02-06 14:37:16 | Train | Epoch[369/600] Iteration[018/030] Train loss: 0.0104
2023-02-06 14:37:16 | Train | Epoch[369/600] Iteration[019/030] Train loss: 0.0105
2023-02-06 14:37:17 | Train | Epoch[369/600] Iteration[020/030] Train loss: 0.0106
2023-02-06 14:37:17 | Train | Epoch[369/600] Iteration[021/030] Train loss: 0.0106
2023-02-06 14:37:17 | Train | Epoch[369/600] Iteration[022/030] Train loss: 0.0106
2023-02-06 14:37:17 | Train | Epoch[369/600] Iteration[023/030] Train loss: 0.0105
2023-02-06 14:37:17 | Train | Epoch[369/600] Iteration[024/030] Train loss: 0.0105
2023-02-06 14:37:18 | Train | Epoch[369/600] Iteration[025/030] Train loss: 0.0104
2023-02-06 14:37:18 | Train | Epoch[369/600] Iteration[026/030] Train loss: 0.0104
2023-02-06 14:37:18 | Train | Epoch[369/600] Iteration[027/030] Train loss: 0.0104
2023-02-06 14:37:18 | Train | Epoch[369/600] Iteration[028/030] Train loss: 0.0104
2023-02-06 14:37:19 | Train | Epoch[369/600] Iteration[029/030] Train loss: 0.0104
2023-02-06 14:37:19 | Train | Epoch[369/600] Iteration[030/030] Train loss: 0.0104
2023-02-06 14:37:19 | Valid | Epoch[369/600] Iteration[001/008] Valid loss: 0.1523
2023-02-06 14:37:19 | Valid | Epoch[369/600] Iteration[002/008] Valid loss: 0.1272
2023-02-06 14:37:19 | Valid | Epoch[369/600] Iteration[003/008] Valid loss: 0.1235
2023-02-06 14:37:19 | Valid | Epoch[369/600] Iteration[004/008] Valid loss: 0.1190
2023-02-06 14:37:19 | Valid | Epoch[369/600] Iteration[005/008] Valid loss: 0.1172
2023-02-06 14:37:19 | Valid | Epoch[369/600] Iteration[006/008] Valid loss: 0.1162
2023-02-06 14:37:19 | Valid | Epoch[369/600] Iteration[007/008] Valid loss: 0.1236
2023-02-06 14:37:19 | Valid | Epoch[369/600] Iteration[008/008] Valid loss: 0.1217
2023-02-06 14:37:19 | Valid | Epoch[369/600] MIou: 0.9161241518466552
2023-02-06 14:37:19 | Valid | Epoch[369/600] Pixel Accuracy: 0.9852892557779948
2023-02-06 14:37:19 | Valid | Epoch[369/600] Mean Pixel Accuracy: 0.9516713748903487
2023-02-06 14:37:19 | Stage | Epoch[369/600] Train loss:0.0104
2023-02-06 14:37:19 | Stage | Epoch[369/600] Valid loss:0.1217
2023-02-06 14:37:19 | Stage | Epoch[369/600] LR:0.01

2023-02-06 14:37:20 | Train | Epoch[370/600] Iteration[001/030] Train loss: 0.0100
2023-02-06 14:37:20 | Train | Epoch[370/600] Iteration[002/030] Train loss: 0.0098
2023-02-06 14:37:20 | Train | Epoch[370/600] Iteration[003/030] Train loss: 0.0109
2023-02-06 14:37:21 | Train | Epoch[370/600] Iteration[004/030] Train loss: 0.0104
2023-02-06 14:37:21 | Train | Epoch[370/600] Iteration[005/030] Train loss: 0.0103
2023-02-06 14:37:21 | Train | Epoch[370/600] Iteration[006/030] Train loss: 0.0101
2023-02-06 14:37:21 | Train | Epoch[370/600] Iteration[007/030] Train loss: 0.0100
2023-02-06 14:37:21 | Train | Epoch[370/600] Iteration[008/030] Train loss: 0.0098
2023-02-06 14:37:22 | Train | Epoch[370/600] Iteration[009/030] Train loss: 0.0098
2023-02-06 14:37:22 | Train | Epoch[370/600] Iteration[010/030] Train loss: 0.0100
2023-02-06 14:37:22 | Train | Epoch[370/600] Iteration[011/030] Train loss: 0.0099
2023-02-06 14:37:22 | Train | Epoch[370/600] Iteration[012/030] Train loss: 0.0097
2023-02-06 14:37:23 | Train | Epoch[370/600] Iteration[013/030] Train loss: 0.0098
2023-02-06 14:37:23 | Train | Epoch[370/600] Iteration[014/030] Train loss: 0.0097
2023-02-06 14:37:23 | Train | Epoch[370/600] Iteration[015/030] Train loss: 0.0097
2023-02-06 14:37:23 | Train | Epoch[370/600] Iteration[016/030] Train loss: 0.0097
2023-02-06 14:37:23 | Train | Epoch[370/600] Iteration[017/030] Train loss: 0.0097
2023-02-06 14:37:24 | Train | Epoch[370/600] Iteration[018/030] Train loss: 0.0097
2023-02-06 14:37:24 | Train | Epoch[370/600] Iteration[019/030] Train loss: 0.0097
2023-02-06 14:37:24 | Train | Epoch[370/600] Iteration[020/030] Train loss: 0.0097
2023-02-06 14:37:24 | Train | Epoch[370/600] Iteration[021/030] Train loss: 0.0097
2023-02-06 14:37:25 | Train | Epoch[370/600] Iteration[022/030] Train loss: 0.0097
2023-02-06 14:37:25 | Train | Epoch[370/600] Iteration[023/030] Train loss: 0.0099
2023-02-06 14:37:25 | Train | Epoch[370/600] Iteration[024/030] Train loss: 0.0098
2023-02-06 14:37:25 | Train | Epoch[370/600] Iteration[025/030] Train loss: 0.0098
2023-02-06 14:37:25 | Train | Epoch[370/600] Iteration[026/030] Train loss: 0.0098
2023-02-06 14:37:26 | Train | Epoch[370/600] Iteration[027/030] Train loss: 0.0098
2023-02-06 14:37:26 | Train | Epoch[370/600] Iteration[028/030] Train loss: 0.0099
2023-02-06 14:37:26 | Train | Epoch[370/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:37:26 | Train | Epoch[370/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:37:27 | Valid | Epoch[370/600] Iteration[001/008] Valid loss: 0.1629
2023-02-06 14:37:27 | Valid | Epoch[370/600] Iteration[002/008] Valid loss: 0.1313
2023-02-06 14:37:27 | Valid | Epoch[370/600] Iteration[003/008] Valid loss: 0.1220
2023-02-06 14:37:27 | Valid | Epoch[370/600] Iteration[004/008] Valid loss: 0.1173
2023-02-06 14:37:27 | Valid | Epoch[370/600] Iteration[005/008] Valid loss: 0.1135
2023-02-06 14:37:27 | Valid | Epoch[370/600] Iteration[006/008] Valid loss: 0.1133
2023-02-06 14:37:27 | Valid | Epoch[370/600] Iteration[007/008] Valid loss: 0.1214
2023-02-06 14:37:27 | Valid | Epoch[370/600] Iteration[008/008] Valid loss: 0.1183
2023-02-06 14:37:27 | Valid | Epoch[370/600] MIou: 0.9241657853527353
2023-02-06 14:37:27 | Valid | Epoch[370/600] Pixel Accuracy: 0.9869473775227865
2023-02-06 14:37:27 | Valid | Epoch[370/600] Mean Pixel Accuracy: 0.9508961838962551
2023-02-06 14:37:27 | Stage | Epoch[370/600] Train loss:0.0098
2023-02-06 14:37:27 | Stage | Epoch[370/600] Valid loss:0.1183
2023-02-06 14:37:27 | Stage | Epoch[370/600] LR:0.01

2023-02-06 14:37:27 | Train | Epoch[371/600] Iteration[001/030] Train loss: 0.0090
2023-02-06 14:37:28 | Train | Epoch[371/600] Iteration[002/030] Train loss: 0.0087
2023-02-06 14:37:28 | Train | Epoch[371/600] Iteration[003/030] Train loss: 0.0089
2023-02-06 14:37:28 | Train | Epoch[371/600] Iteration[004/030] Train loss: 0.0086
2023-02-06 14:37:28 | Train | Epoch[371/600] Iteration[005/030] Train loss: 0.0088
2023-02-06 14:37:28 | Train | Epoch[371/600] Iteration[006/030] Train loss: 0.0089
2023-02-06 14:37:29 | Train | Epoch[371/600] Iteration[007/030] Train loss: 0.0089
2023-02-06 14:37:29 | Train | Epoch[371/600] Iteration[008/030] Train loss: 0.0091
2023-02-06 14:37:29 | Train | Epoch[371/600] Iteration[009/030] Train loss: 0.0092
2023-02-06 14:37:29 | Train | Epoch[371/600] Iteration[010/030] Train loss: 0.0091
2023-02-06 14:37:30 | Train | Epoch[371/600] Iteration[011/030] Train loss: 0.0092
2023-02-06 14:37:30 | Train | Epoch[371/600] Iteration[012/030] Train loss: 0.0093
2023-02-06 14:37:30 | Train | Epoch[371/600] Iteration[013/030] Train loss: 0.0095
2023-02-06 14:37:30 | Train | Epoch[371/600] Iteration[014/030] Train loss: 0.0094
2023-02-06 14:37:30 | Train | Epoch[371/600] Iteration[015/030] Train loss: 0.0097
2023-02-06 14:37:31 | Train | Epoch[371/600] Iteration[016/030] Train loss: 0.0097
2023-02-06 14:37:31 | Train | Epoch[371/600] Iteration[017/030] Train loss: 0.0097
2023-02-06 14:37:31 | Train | Epoch[371/600] Iteration[018/030] Train loss: 0.0098
2023-02-06 14:37:31 | Train | Epoch[371/600] Iteration[019/030] Train loss: 0.0097
2023-02-06 14:37:32 | Train | Epoch[371/600] Iteration[020/030] Train loss: 0.0097
2023-02-06 14:37:32 | Train | Epoch[371/600] Iteration[021/030] Train loss: 0.0097
2023-02-06 14:37:32 | Train | Epoch[371/600] Iteration[022/030] Train loss: 0.0097
2023-02-06 14:37:32 | Train | Epoch[371/600] Iteration[023/030] Train loss: 0.0096
2023-02-06 14:37:32 | Train | Epoch[371/600] Iteration[024/030] Train loss: 0.0096
2023-02-06 14:37:33 | Train | Epoch[371/600] Iteration[025/030] Train loss: 0.0097
2023-02-06 14:37:33 | Train | Epoch[371/600] Iteration[026/030] Train loss: 0.0098
2023-02-06 14:37:33 | Train | Epoch[371/600] Iteration[027/030] Train loss: 0.0098
2023-02-06 14:37:33 | Train | Epoch[371/600] Iteration[028/030] Train loss: 0.0098
2023-02-06 14:37:34 | Train | Epoch[371/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:37:34 | Train | Epoch[371/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:37:34 | Valid | Epoch[371/600] Iteration[001/008] Valid loss: 0.1023
2023-02-06 14:37:34 | Valid | Epoch[371/600] Iteration[002/008] Valid loss: 0.0834
2023-02-06 14:37:34 | Valid | Epoch[371/600] Iteration[003/008] Valid loss: 0.0799
2023-02-06 14:37:34 | Valid | Epoch[371/600] Iteration[004/008] Valid loss: 0.0772
2023-02-06 14:37:34 | Valid | Epoch[371/600] Iteration[005/008] Valid loss: 0.0759
2023-02-06 14:37:34 | Valid | Epoch[371/600] Iteration[006/008] Valid loss: 0.0791
2023-02-06 14:37:34 | Valid | Epoch[371/600] Iteration[007/008] Valid loss: 0.0801
2023-02-06 14:37:34 | Valid | Epoch[371/600] Iteration[008/008] Valid loss: 0.0772
2023-02-06 14:37:34 | Valid | Epoch[371/600] MIou: 0.8979141547429343
2023-02-06 14:37:34 | Valid | Epoch[371/600] Pixel Accuracy: 0.982873280843099
2023-02-06 14:37:34 | Valid | Epoch[371/600] Mean Pixel Accuracy: 0.91482413061662
2023-02-06 14:37:34 | Stage | Epoch[371/600] Train loss:0.0098
2023-02-06 14:37:34 | Stage | Epoch[371/600] Valid loss:0.0772
2023-02-06 14:37:34 | Stage | Epoch[371/600] LR:0.01

2023-02-06 14:37:35 | Train | Epoch[372/600] Iteration[001/030] Train loss: 0.0089
2023-02-06 14:37:35 | Train | Epoch[372/600] Iteration[002/030] Train loss: 0.0103
2023-02-06 14:37:35 | Train | Epoch[372/600] Iteration[003/030] Train loss: 0.0104
2023-02-06 14:37:35 | Train | Epoch[372/600] Iteration[004/030] Train loss: 0.0105
2023-02-06 14:37:36 | Train | Epoch[372/600] Iteration[005/030] Train loss: 0.0103
2023-02-06 14:37:36 | Train | Epoch[372/600] Iteration[006/030] Train loss: 0.0102
2023-02-06 14:37:36 | Train | Epoch[372/600] Iteration[007/030] Train loss: 0.0099
2023-02-06 14:37:36 | Train | Epoch[372/600] Iteration[008/030] Train loss: 0.0098
2023-02-06 14:37:37 | Train | Epoch[372/600] Iteration[009/030] Train loss: 0.0098
2023-02-06 14:37:37 | Train | Epoch[372/600] Iteration[010/030] Train loss: 0.0097
2023-02-06 14:37:37 | Train | Epoch[372/600] Iteration[011/030] Train loss: 0.0096
2023-02-06 14:37:37 | Train | Epoch[372/600] Iteration[012/030] Train loss: 0.0097
2023-02-06 14:37:37 | Train | Epoch[372/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:37:38 | Train | Epoch[372/600] Iteration[014/030] Train loss: 0.0096
2023-02-06 14:37:38 | Train | Epoch[372/600] Iteration[015/030] Train loss: 0.0096
2023-02-06 14:37:38 | Train | Epoch[372/600] Iteration[016/030] Train loss: 0.0097
2023-02-06 14:37:38 | Train | Epoch[372/600] Iteration[017/030] Train loss: 0.0098
2023-02-06 14:37:39 | Train | Epoch[372/600] Iteration[018/030] Train loss: 0.0097
2023-02-06 14:37:39 | Train | Epoch[372/600] Iteration[019/030] Train loss: 0.0097
2023-02-06 14:37:39 | Train | Epoch[372/600] Iteration[020/030] Train loss: 0.0097
2023-02-06 14:37:39 | Train | Epoch[372/600] Iteration[021/030] Train loss: 0.0097
2023-02-06 14:37:39 | Train | Epoch[372/600] Iteration[022/030] Train loss: 0.0097
2023-02-06 14:37:40 | Train | Epoch[372/600] Iteration[023/030] Train loss: 0.0097
2023-02-06 14:37:40 | Train | Epoch[372/600] Iteration[024/030] Train loss: 0.0098
2023-02-06 14:37:40 | Train | Epoch[372/600] Iteration[025/030] Train loss: 0.0098
2023-02-06 14:37:40 | Train | Epoch[372/600] Iteration[026/030] Train loss: 0.0098
2023-02-06 14:37:40 | Train | Epoch[372/600] Iteration[027/030] Train loss: 0.0098
2023-02-06 14:37:41 | Train | Epoch[372/600] Iteration[028/030] Train loss: 0.0097
2023-02-06 14:37:41 | Train | Epoch[372/600] Iteration[029/030] Train loss: 0.0097
2023-02-06 14:37:41 | Train | Epoch[372/600] Iteration[030/030] Train loss: 0.0097
2023-02-06 14:37:41 | Valid | Epoch[372/600] Iteration[001/008] Valid loss: 0.1163
2023-02-06 14:37:41 | Valid | Epoch[372/600] Iteration[002/008] Valid loss: 0.0898
2023-02-06 14:37:42 | Valid | Epoch[372/600] Iteration[003/008] Valid loss: 0.0833
2023-02-06 14:37:42 | Valid | Epoch[372/600] Iteration[004/008] Valid loss: 0.0780
2023-02-06 14:37:42 | Valid | Epoch[372/600] Iteration[005/008] Valid loss: 0.0750
2023-02-06 14:37:42 | Valid | Epoch[372/600] Iteration[006/008] Valid loss: 0.0717
2023-02-06 14:37:42 | Valid | Epoch[372/600] Iteration[007/008] Valid loss: 0.0733
2023-02-06 14:37:42 | Valid | Epoch[372/600] Iteration[008/008] Valid loss: 0.0721
2023-02-06 14:37:42 | Valid | Epoch[372/600] MIou: 0.9087402393243896
2023-02-06 14:37:42 | Valid | Epoch[372/600] Pixel Accuracy: 0.9844004313151041
2023-02-06 14:37:42 | Valid | Epoch[372/600] Mean Pixel Accuracy: 0.933030069119013
2023-02-06 14:37:42 | Stage | Epoch[372/600] Train loss:0.0097
2023-02-06 14:37:42 | Stage | Epoch[372/600] Valid loss:0.0721
2023-02-06 14:37:42 | Stage | Epoch[372/600] LR:0.01

2023-02-06 14:37:42 | Train | Epoch[373/600] Iteration[001/030] Train loss: 0.0117
2023-02-06 14:37:43 | Train | Epoch[373/600] Iteration[002/030] Train loss: 0.0106
2023-02-06 14:37:43 | Train | Epoch[373/600] Iteration[003/030] Train loss: 0.0108
2023-02-06 14:37:43 | Train | Epoch[373/600] Iteration[004/030] Train loss: 0.0102
2023-02-06 14:37:43 | Train | Epoch[373/600] Iteration[005/030] Train loss: 0.0101
2023-02-06 14:37:43 | Train | Epoch[373/600] Iteration[006/030] Train loss: 0.0104
2023-02-06 14:37:44 | Train | Epoch[373/600] Iteration[007/030] Train loss: 0.0103
2023-02-06 14:37:44 | Train | Epoch[373/600] Iteration[008/030] Train loss: 0.0102
2023-02-06 14:37:44 | Train | Epoch[373/600] Iteration[009/030] Train loss: 0.0104
2023-02-06 14:37:44 | Train | Epoch[373/600] Iteration[010/030] Train loss: 0.0103
2023-02-06 14:37:45 | Train | Epoch[373/600] Iteration[011/030] Train loss: 0.0102
2023-02-06 14:37:45 | Train | Epoch[373/600] Iteration[012/030] Train loss: 0.0102
2023-02-06 14:37:45 | Train | Epoch[373/600] Iteration[013/030] Train loss: 0.0101
2023-02-06 14:37:45 | Train | Epoch[373/600] Iteration[014/030] Train loss: 0.0101
2023-02-06 14:37:45 | Train | Epoch[373/600] Iteration[015/030] Train loss: 0.0101
2023-02-06 14:37:46 | Train | Epoch[373/600] Iteration[016/030] Train loss: 0.0101
2023-02-06 14:37:46 | Train | Epoch[373/600] Iteration[017/030] Train loss: 0.0100
2023-02-06 14:37:46 | Train | Epoch[373/600] Iteration[018/030] Train loss: 0.0101
2023-02-06 14:37:46 | Train | Epoch[373/600] Iteration[019/030] Train loss: 0.0100
2023-02-06 14:37:47 | Train | Epoch[373/600] Iteration[020/030] Train loss: 0.0100
2023-02-06 14:37:47 | Train | Epoch[373/600] Iteration[021/030] Train loss: 0.0099
2023-02-06 14:37:47 | Train | Epoch[373/600] Iteration[022/030] Train loss: 0.0100
2023-02-06 14:37:47 | Train | Epoch[373/600] Iteration[023/030] Train loss: 0.0100
2023-02-06 14:37:47 | Train | Epoch[373/600] Iteration[024/030] Train loss: 0.0100
2023-02-06 14:37:48 | Train | Epoch[373/600] Iteration[025/030] Train loss: 0.0100
2023-02-06 14:37:48 | Train | Epoch[373/600] Iteration[026/030] Train loss: 0.0100
2023-02-06 14:37:48 | Train | Epoch[373/600] Iteration[027/030] Train loss: 0.0099
2023-02-06 14:37:48 | Train | Epoch[373/600] Iteration[028/030] Train loss: 0.0099
2023-02-06 14:37:48 | Train | Epoch[373/600] Iteration[029/030] Train loss: 0.0099
2023-02-06 14:37:49 | Train | Epoch[373/600] Iteration[030/030] Train loss: 0.0099
2023-02-06 14:37:49 | Valid | Epoch[373/600] Iteration[001/008] Valid loss: 0.1846
2023-02-06 14:37:49 | Valid | Epoch[373/600] Iteration[002/008] Valid loss: 0.1433
2023-02-06 14:37:49 | Valid | Epoch[373/600] Iteration[003/008] Valid loss: 0.1401
2023-02-06 14:37:49 | Valid | Epoch[373/600] Iteration[004/008] Valid loss: 0.1380
2023-02-06 14:37:49 | Valid | Epoch[373/600] Iteration[005/008] Valid loss: 0.1399
2023-02-06 14:37:49 | Valid | Epoch[373/600] Iteration[006/008] Valid loss: 0.1356
2023-02-06 14:37:49 | Valid | Epoch[373/600] Iteration[007/008] Valid loss: 0.1415
2023-02-06 14:37:49 | Valid | Epoch[373/600] Iteration[008/008] Valid loss: 0.1435
2023-02-06 14:37:49 | Valid | Epoch[373/600] MIou: 0.9219009444403347
2023-02-06 14:37:49 | Valid | Epoch[373/600] Pixel Accuracy: 0.9862556457519531
2023-02-06 14:37:49 | Valid | Epoch[373/600] Mean Pixel Accuracy: 0.9589234438383764
2023-02-06 14:37:49 | Stage | Epoch[373/600] Train loss:0.0099
2023-02-06 14:37:49 | Stage | Epoch[373/600] Valid loss:0.1435
2023-02-06 14:37:49 | Stage | Epoch[373/600] LR:0.01

2023-02-06 14:37:50 | Train | Epoch[374/600] Iteration[001/030] Train loss: 0.0093
2023-02-06 14:37:50 | Train | Epoch[374/600] Iteration[002/030] Train loss: 0.0100
2023-02-06 14:37:50 | Train | Epoch[374/600] Iteration[003/030] Train loss: 0.0099
2023-02-06 14:37:50 | Train | Epoch[374/600] Iteration[004/030] Train loss: 0.0098
2023-02-06 14:37:51 | Train | Epoch[374/600] Iteration[005/030] Train loss: 0.0094
2023-02-06 14:37:51 | Train | Epoch[374/600] Iteration[006/030] Train loss: 0.0095
2023-02-06 14:37:51 | Train | Epoch[374/600] Iteration[007/030] Train loss: 0.0096
2023-02-06 14:37:51 | Train | Epoch[374/600] Iteration[008/030] Train loss: 0.0094
2023-02-06 14:37:52 | Train | Epoch[374/600] Iteration[009/030] Train loss: 0.0094
2023-02-06 14:37:52 | Train | Epoch[374/600] Iteration[010/030] Train loss: 0.0093
2023-02-06 14:37:52 | Train | Epoch[374/600] Iteration[011/030] Train loss: 0.0093
2023-02-06 14:37:52 | Train | Epoch[374/600] Iteration[012/030] Train loss: 0.0094
2023-02-06 14:37:52 | Train | Epoch[374/600] Iteration[013/030] Train loss: 0.0094
2023-02-06 14:37:53 | Train | Epoch[374/600] Iteration[014/030] Train loss: 0.0096
2023-02-06 14:37:53 | Train | Epoch[374/600] Iteration[015/030] Train loss: 0.0095
2023-02-06 14:37:53 | Train | Epoch[374/600] Iteration[016/030] Train loss: 0.0095
2023-02-06 14:37:53 | Train | Epoch[374/600] Iteration[017/030] Train loss: 0.0095
2023-02-06 14:37:54 | Train | Epoch[374/600] Iteration[018/030] Train loss: 0.0096
2023-02-06 14:37:54 | Train | Epoch[374/600] Iteration[019/030] Train loss: 0.0096
2023-02-06 14:37:54 | Train | Epoch[374/600] Iteration[020/030] Train loss: 0.0096
2023-02-06 14:37:54 | Train | Epoch[374/600] Iteration[021/030] Train loss: 0.0097
2023-02-06 14:37:54 | Train | Epoch[374/600] Iteration[022/030] Train loss: 0.0097
2023-02-06 14:37:55 | Train | Epoch[374/600] Iteration[023/030] Train loss: 0.0097
2023-02-06 14:37:55 | Train | Epoch[374/600] Iteration[024/030] Train loss: 0.0097
2023-02-06 14:37:55 | Train | Epoch[374/600] Iteration[025/030] Train loss: 0.0097
2023-02-06 14:37:55 | Train | Epoch[374/600] Iteration[026/030] Train loss: 0.0097
2023-02-06 14:37:56 | Train | Epoch[374/600] Iteration[027/030] Train loss: 0.0097
2023-02-06 14:37:56 | Train | Epoch[374/600] Iteration[028/030] Train loss: 0.0097
2023-02-06 14:37:56 | Train | Epoch[374/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:37:56 | Train | Epoch[374/600] Iteration[030/030] Train loss: 0.0097
2023-02-06 14:37:56 | Valid | Epoch[374/600] Iteration[001/008] Valid loss: 0.0761
2023-02-06 14:37:56 | Valid | Epoch[374/600] Iteration[002/008] Valid loss: 0.0650
2023-02-06 14:37:57 | Valid | Epoch[374/600] Iteration[003/008] Valid loss: 0.0668
2023-02-06 14:37:57 | Valid | Epoch[374/600] Iteration[004/008] Valid loss: 0.0669
2023-02-06 14:37:57 | Valid | Epoch[374/600] Iteration[005/008] Valid loss: 0.0661
2023-02-06 14:37:57 | Valid | Epoch[374/600] Iteration[006/008] Valid loss: 0.0645
2023-02-06 14:37:57 | Valid | Epoch[374/600] Iteration[007/008] Valid loss: 0.0644
2023-02-06 14:37:57 | Valid | Epoch[374/600] Iteration[008/008] Valid loss: 0.0634
2023-02-06 14:37:57 | Valid | Epoch[374/600] MIou: 0.8784968549042658
2023-02-06 14:37:57 | Valid | Epoch[374/600] Pixel Accuracy: 0.9797477722167969
2023-02-06 14:37:57 | Valid | Epoch[374/600] Mean Pixel Accuracy: 0.8940594413535978
2023-02-06 14:37:57 | Stage | Epoch[374/600] Train loss:0.0097
2023-02-06 14:37:57 | Stage | Epoch[374/600] Valid loss:0.0634
2023-02-06 14:37:57 | Stage | Epoch[374/600] LR:0.01

2023-02-06 14:37:57 | Train | Epoch[375/600] Iteration[001/030] Train loss: 0.0096
2023-02-06 14:37:58 | Train | Epoch[375/600] Iteration[002/030] Train loss: 0.0089
2023-02-06 14:37:58 | Train | Epoch[375/600] Iteration[003/030] Train loss: 0.0088
2023-02-06 14:37:58 | Train | Epoch[375/600] Iteration[004/030] Train loss: 0.0089
2023-02-06 14:37:58 | Train | Epoch[375/600] Iteration[005/030] Train loss: 0.0092
2023-02-06 14:37:58 | Train | Epoch[375/600] Iteration[006/030] Train loss: 0.0094
2023-02-06 14:37:59 | Train | Epoch[375/600] Iteration[007/030] Train loss: 0.0098
2023-02-06 14:37:59 | Train | Epoch[375/600] Iteration[008/030] Train loss: 0.0096
2023-02-06 14:37:59 | Train | Epoch[375/600] Iteration[009/030] Train loss: 0.0097
2023-02-06 14:37:59 | Train | Epoch[375/600] Iteration[010/030] Train loss: 0.0095
2023-02-06 14:38:00 | Train | Epoch[375/600] Iteration[011/030] Train loss: 0.0097
2023-02-06 14:38:00 | Train | Epoch[375/600] Iteration[012/030] Train loss: 0.0097
2023-02-06 14:38:00 | Train | Epoch[375/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:38:00 | Train | Epoch[375/600] Iteration[014/030] Train loss: 0.0098
2023-02-06 14:38:00 | Train | Epoch[375/600] Iteration[015/030] Train loss: 0.0097
2023-02-06 14:38:01 | Train | Epoch[375/600] Iteration[016/030] Train loss: 0.0098
2023-02-06 14:38:01 | Train | Epoch[375/600] Iteration[017/030] Train loss: 0.0098
2023-02-06 14:38:01 | Train | Epoch[375/600] Iteration[018/030] Train loss: 0.0100
2023-02-06 14:38:01 | Train | Epoch[375/600] Iteration[019/030] Train loss: 0.0100
2023-02-06 14:38:02 | Train | Epoch[375/600] Iteration[020/030] Train loss: 0.0099
2023-02-06 14:38:02 | Train | Epoch[375/600] Iteration[021/030] Train loss: 0.0099
2023-02-06 14:38:02 | Train | Epoch[375/600] Iteration[022/030] Train loss: 0.0099
2023-02-06 14:38:02 | Train | Epoch[375/600] Iteration[023/030] Train loss: 0.0099
2023-02-06 14:38:02 | Train | Epoch[375/600] Iteration[024/030] Train loss: 0.0099
2023-02-06 14:38:03 | Train | Epoch[375/600] Iteration[025/030] Train loss: 0.0099
2023-02-06 14:38:03 | Train | Epoch[375/600] Iteration[026/030] Train loss: 0.0099
2023-02-06 14:38:03 | Train | Epoch[375/600] Iteration[027/030] Train loss: 0.0099
2023-02-06 14:38:03 | Train | Epoch[375/600] Iteration[028/030] Train loss: 0.0099
2023-02-06 14:38:03 | Train | Epoch[375/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:38:04 | Train | Epoch[375/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:38:04 | Valid | Epoch[375/600] Iteration[001/008] Valid loss: 0.5507
2023-02-06 14:38:04 | Valid | Epoch[375/600] Iteration[002/008] Valid loss: 0.5066
2023-02-06 14:38:04 | Valid | Epoch[375/600] Iteration[003/008] Valid loss: 0.4895
2023-02-06 14:38:04 | Valid | Epoch[375/600] Iteration[004/008] Valid loss: 0.4867
2023-02-06 14:38:04 | Valid | Epoch[375/600] Iteration[005/008] Valid loss: 0.4971
2023-02-06 14:38:04 | Valid | Epoch[375/600] Iteration[006/008] Valid loss: 0.4917
2023-02-06 14:38:04 | Valid | Epoch[375/600] Iteration[007/008] Valid loss: 0.5317
2023-02-06 14:38:04 | Valid | Epoch[375/600] Iteration[008/008] Valid loss: 0.5492
2023-02-06 14:38:04 | Valid | Epoch[375/600] MIou: 0.894705703338198
2023-02-06 14:38:04 | Valid | Epoch[375/600] Pixel Accuracy: 0.9794286092122396
2023-02-06 14:38:04 | Valid | Epoch[375/600] Mean Pixel Accuracy: 0.981344479791949
2023-02-06 14:38:04 | Stage | Epoch[375/600] Train loss:0.0098
2023-02-06 14:38:04 | Stage | Epoch[375/600] Valid loss:0.5492
2023-02-06 14:38:04 | Stage | Epoch[375/600] LR:0.01

2023-02-06 14:38:05 | Train | Epoch[376/600] Iteration[001/030] Train loss: 0.0087
2023-02-06 14:38:05 | Train | Epoch[376/600] Iteration[002/030] Train loss: 0.0091
2023-02-06 14:38:05 | Train | Epoch[376/600] Iteration[003/030] Train loss: 0.0088
2023-02-06 14:38:06 | Train | Epoch[376/600] Iteration[004/030] Train loss: 0.0088
2023-02-06 14:38:06 | Train | Epoch[376/600] Iteration[005/030] Train loss: 0.0087
2023-02-06 14:38:06 | Train | Epoch[376/600] Iteration[006/030] Train loss: 0.0088
2023-02-06 14:38:06 | Train | Epoch[376/600] Iteration[007/030] Train loss: 0.0088
2023-02-06 14:38:06 | Train | Epoch[376/600] Iteration[008/030] Train loss: 0.0087
2023-02-06 14:38:07 | Train | Epoch[376/600] Iteration[009/030] Train loss: 0.0088
2023-02-06 14:38:07 | Train | Epoch[376/600] Iteration[010/030] Train loss: 0.0088
2023-02-06 14:38:07 | Train | Epoch[376/600] Iteration[011/030] Train loss: 0.0089
2023-02-06 14:38:07 | Train | Epoch[376/600] Iteration[012/030] Train loss: 0.0089
2023-02-06 14:38:08 | Train | Epoch[376/600] Iteration[013/030] Train loss: 0.0090
2023-02-06 14:38:08 | Train | Epoch[376/600] Iteration[014/030] Train loss: 0.0090
2023-02-06 14:38:08 | Train | Epoch[376/600] Iteration[015/030] Train loss: 0.0092
2023-02-06 14:38:08 | Train | Epoch[376/600] Iteration[016/030] Train loss: 0.0092
2023-02-06 14:38:08 | Train | Epoch[376/600] Iteration[017/030] Train loss: 0.0091
2023-02-06 14:38:09 | Train | Epoch[376/600] Iteration[018/030] Train loss: 0.0092
2023-02-06 14:38:09 | Train | Epoch[376/600] Iteration[019/030] Train loss: 0.0092
2023-02-06 14:38:09 | Train | Epoch[376/600] Iteration[020/030] Train loss: 0.0093
2023-02-06 14:38:09 | Train | Epoch[376/600] Iteration[021/030] Train loss: 0.0092
2023-02-06 14:38:09 | Train | Epoch[376/600] Iteration[022/030] Train loss: 0.0092
2023-02-06 14:38:10 | Train | Epoch[376/600] Iteration[023/030] Train loss: 0.0092
2023-02-06 14:38:10 | Train | Epoch[376/600] Iteration[024/030] Train loss: 0.0094
2023-02-06 14:38:10 | Train | Epoch[376/600] Iteration[025/030] Train loss: 0.0093
2023-02-06 14:38:10 | Train | Epoch[376/600] Iteration[026/030] Train loss: 0.0093
2023-02-06 14:38:11 | Train | Epoch[376/600] Iteration[027/030] Train loss: 0.0094
2023-02-06 14:38:11 | Train | Epoch[376/600] Iteration[028/030] Train loss: 0.0094
2023-02-06 14:38:11 | Train | Epoch[376/600] Iteration[029/030] Train loss: 0.0094
2023-02-06 14:38:11 | Train | Epoch[376/600] Iteration[030/030] Train loss: 0.0093
2023-02-06 14:38:12 | Valid | Epoch[376/600] Iteration[001/008] Valid loss: 0.0896
2023-02-06 14:38:12 | Valid | Epoch[376/600] Iteration[002/008] Valid loss: 0.0710
2023-02-06 14:38:12 | Valid | Epoch[376/600] Iteration[003/008] Valid loss: 0.0706
2023-02-06 14:38:12 | Valid | Epoch[376/600] Iteration[004/008] Valid loss: 0.0668
2023-02-06 14:38:12 | Valid | Epoch[376/600] Iteration[005/008] Valid loss: 0.0662
2023-02-06 14:38:12 | Valid | Epoch[376/600] Iteration[006/008] Valid loss: 0.0632
2023-02-06 14:38:12 | Valid | Epoch[376/600] Iteration[007/008] Valid loss: 0.0616
2023-02-06 14:38:12 | Valid | Epoch[376/600] Iteration[008/008] Valid loss: 0.0607
2023-02-06 14:38:12 | Valid | Epoch[376/600] MIou: 0.8858313704239265
2023-02-06 14:38:12 | Valid | Epoch[376/600] Pixel Accuracy: 0.9809379577636719
2023-02-06 14:38:12 | Valid | Epoch[376/600] Mean Pixel Accuracy: 0.9015676677949045
2023-02-06 14:38:12 | Stage | Epoch[376/600] Train loss:0.0093
2023-02-06 14:38:12 | Stage | Epoch[376/600] Valid loss:0.0607
2023-02-06 14:38:12 | Stage | Epoch[376/600] LR:0.01

2023-02-06 14:38:12 | Train | Epoch[377/600] Iteration[001/030] Train loss: 0.0076
2023-02-06 14:38:13 | Train | Epoch[377/600] Iteration[002/030] Train loss: 0.0080
2023-02-06 14:38:13 | Train | Epoch[377/600] Iteration[003/030] Train loss: 0.0083
2023-02-06 14:38:13 | Train | Epoch[377/600] Iteration[004/030] Train loss: 0.0090
2023-02-06 14:38:13 | Train | Epoch[377/600] Iteration[005/030] Train loss: 0.0090
2023-02-06 14:38:14 | Train | Epoch[377/600] Iteration[006/030] Train loss: 0.0090
2023-02-06 14:38:14 | Train | Epoch[377/600] Iteration[007/030] Train loss: 0.0096
2023-02-06 14:38:14 | Train | Epoch[377/600] Iteration[008/030] Train loss: 0.0095
2023-02-06 14:38:14 | Train | Epoch[377/600] Iteration[009/030] Train loss: 0.0095
2023-02-06 14:38:14 | Train | Epoch[377/600] Iteration[010/030] Train loss: 0.0097
2023-02-06 14:38:15 | Train | Epoch[377/600] Iteration[011/030] Train loss: 0.0097
2023-02-06 14:38:15 | Train | Epoch[377/600] Iteration[012/030] Train loss: 0.0098
2023-02-06 14:38:15 | Train | Epoch[377/600] Iteration[013/030] Train loss: 0.0098
2023-02-06 14:38:15 | Train | Epoch[377/600] Iteration[014/030] Train loss: 0.0099
2023-02-06 14:38:16 | Train | Epoch[377/600] Iteration[015/030] Train loss: 0.0098
2023-02-06 14:38:16 | Train | Epoch[377/600] Iteration[016/030] Train loss: 0.0099
2023-02-06 14:38:16 | Train | Epoch[377/600] Iteration[017/030] Train loss: 0.0099
2023-02-06 14:38:16 | Train | Epoch[377/600] Iteration[018/030] Train loss: 0.0098
2023-02-06 14:38:16 | Train | Epoch[377/600] Iteration[019/030] Train loss: 0.0098
2023-02-06 14:38:17 | Train | Epoch[377/600] Iteration[020/030] Train loss: 0.0097
2023-02-06 14:38:17 | Train | Epoch[377/600] Iteration[021/030] Train loss: 0.0098
2023-02-06 14:38:17 | Train | Epoch[377/600] Iteration[022/030] Train loss: 0.0098
2023-02-06 14:38:17 | Train | Epoch[377/600] Iteration[023/030] Train loss: 0.0098
2023-02-06 14:38:18 | Train | Epoch[377/600] Iteration[024/030] Train loss: 0.0097
2023-02-06 14:38:18 | Train | Epoch[377/600] Iteration[025/030] Train loss: 0.0097
2023-02-06 14:38:18 | Train | Epoch[377/600] Iteration[026/030] Train loss: 0.0097
2023-02-06 14:38:18 | Train | Epoch[377/600] Iteration[027/030] Train loss: 0.0097
2023-02-06 14:38:18 | Train | Epoch[377/600] Iteration[028/030] Train loss: 0.0097
2023-02-06 14:38:19 | Train | Epoch[377/600] Iteration[029/030] Train loss: 0.0097
2023-02-06 14:38:19 | Train | Epoch[377/600] Iteration[030/030] Train loss: 0.0097
2023-02-06 14:38:19 | Valid | Epoch[377/600] Iteration[001/008] Valid loss: 0.2925
2023-02-06 14:38:19 | Valid | Epoch[377/600] Iteration[002/008] Valid loss: 0.2397
2023-02-06 14:38:19 | Valid | Epoch[377/600] Iteration[003/008] Valid loss: 0.2339
2023-02-06 14:38:19 | Valid | Epoch[377/600] Iteration[004/008] Valid loss: 0.2248
2023-02-06 14:38:19 | Valid | Epoch[377/600] Iteration[005/008] Valid loss: 0.2291
2023-02-06 14:38:19 | Valid | Epoch[377/600] Iteration[006/008] Valid loss: 0.2273
2023-02-06 14:38:19 | Valid | Epoch[377/600] Iteration[007/008] Valid loss: 0.2456
2023-02-06 14:38:19 | Valid | Epoch[377/600] Iteration[008/008] Valid loss: 0.2423
2023-02-06 14:38:20 | Valid | Epoch[377/600] MIou: 0.9129857483702337
2023-02-06 14:38:20 | Valid | Epoch[377/600] Pixel Accuracy: 0.9839998881022135
2023-02-06 14:38:20 | Valid | Epoch[377/600] Mean Pixel Accuracy: 0.9707956783153235
2023-02-06 14:38:20 | Stage | Epoch[377/600] Train loss:0.0097
2023-02-06 14:38:20 | Stage | Epoch[377/600] Valid loss:0.2423
2023-02-06 14:38:20 | Stage | Epoch[377/600] LR:0.01

2023-02-06 14:38:20 | Train | Epoch[378/600] Iteration[001/030] Train loss: 0.0082
2023-02-06 14:38:20 | Train | Epoch[378/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:38:20 | Train | Epoch[378/600] Iteration[003/030] Train loss: 0.0083
2023-02-06 14:38:21 | Train | Epoch[378/600] Iteration[004/030] Train loss: 0.0083
2023-02-06 14:38:21 | Train | Epoch[378/600] Iteration[005/030] Train loss: 0.0085
2023-02-06 14:38:21 | Train | Epoch[378/600] Iteration[006/030] Train loss: 0.0086
2023-02-06 14:38:21 | Train | Epoch[378/600] Iteration[007/030] Train loss: 0.0087
2023-02-06 14:38:22 | Train | Epoch[378/600] Iteration[008/030] Train loss: 0.0088
2023-02-06 14:38:22 | Train | Epoch[378/600] Iteration[009/030] Train loss: 0.0089
2023-02-06 14:38:22 | Train | Epoch[378/600] Iteration[010/030] Train loss: 0.0090
2023-02-06 14:38:22 | Train | Epoch[378/600] Iteration[011/030] Train loss: 0.0089
2023-02-06 14:38:22 | Train | Epoch[378/600] Iteration[012/030] Train loss: 0.0090
2023-02-06 14:38:23 | Train | Epoch[378/600] Iteration[013/030] Train loss: 0.0090
2023-02-06 14:38:23 | Train | Epoch[378/600] Iteration[014/030] Train loss: 0.0090
2023-02-06 14:38:23 | Train | Epoch[378/600] Iteration[015/030] Train loss: 0.0090
2023-02-06 14:38:23 | Train | Epoch[378/600] Iteration[016/030] Train loss: 0.0091
2023-02-06 14:38:24 | Train | Epoch[378/600] Iteration[017/030] Train loss: 0.0092
2023-02-06 14:38:24 | Train | Epoch[378/600] Iteration[018/030] Train loss: 0.0093
2023-02-06 14:38:24 | Train | Epoch[378/600] Iteration[019/030] Train loss: 0.0092
2023-02-06 14:38:24 | Train | Epoch[378/600] Iteration[020/030] Train loss: 0.0093
2023-02-06 14:38:24 | Train | Epoch[378/600] Iteration[021/030] Train loss: 0.0093
2023-02-06 14:38:25 | Train | Epoch[378/600] Iteration[022/030] Train loss: 0.0094
2023-02-06 14:38:25 | Train | Epoch[378/600] Iteration[023/030] Train loss: 0.0094
2023-02-06 14:38:25 | Train | Epoch[378/600] Iteration[024/030] Train loss: 0.0094
2023-02-06 14:38:25 | Train | Epoch[378/600] Iteration[025/030] Train loss: 0.0094
2023-02-06 14:38:26 | Train | Epoch[378/600] Iteration[026/030] Train loss: 0.0094
2023-02-06 14:38:26 | Train | Epoch[378/600] Iteration[027/030] Train loss: 0.0094
2023-02-06 14:38:26 | Train | Epoch[378/600] Iteration[028/030] Train loss: 0.0095
2023-02-06 14:38:26 | Train | Epoch[378/600] Iteration[029/030] Train loss: 0.0095
2023-02-06 14:38:26 | Train | Epoch[378/600] Iteration[030/030] Train loss: 0.0095
2023-02-06 14:38:27 | Valid | Epoch[378/600] Iteration[001/008] Valid loss: 0.1207
2023-02-06 14:38:27 | Valid | Epoch[378/600] Iteration[002/008] Valid loss: 0.0927
2023-02-06 14:38:27 | Valid | Epoch[378/600] Iteration[003/008] Valid loss: 0.0848
2023-02-06 14:38:27 | Valid | Epoch[378/600] Iteration[004/008] Valid loss: 0.0810
2023-02-06 14:38:27 | Valid | Epoch[378/600] Iteration[005/008] Valid loss: 0.0804
2023-02-06 14:38:27 | Valid | Epoch[378/600] Iteration[006/008] Valid loss: 0.0766
2023-02-06 14:38:27 | Valid | Epoch[378/600] Iteration[007/008] Valid loss: 0.0770
2023-02-06 14:38:27 | Valid | Epoch[378/600] Iteration[008/008] Valid loss: 0.0759
2023-02-06 14:38:27 | Valid | Epoch[378/600] MIou: 0.9149755534877866
2023-02-06 14:38:27 | Valid | Epoch[378/600] Pixel Accuracy: 0.9855295817057291
2023-02-06 14:38:27 | Valid | Epoch[378/600] Mean Pixel Accuracy: 0.9370618720042989
2023-02-06 14:38:27 | Stage | Epoch[378/600] Train loss:0.0095
2023-02-06 14:38:27 | Stage | Epoch[378/600] Valid loss:0.0759
2023-02-06 14:38:27 | Stage | Epoch[378/600] LR:0.01

2023-02-06 14:38:28 | Train | Epoch[379/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:38:28 | Train | Epoch[379/600] Iteration[002/030] Train loss: 0.0093
2023-02-06 14:38:28 | Train | Epoch[379/600] Iteration[003/030] Train loss: 0.0094
2023-02-06 14:38:28 | Train | Epoch[379/600] Iteration[004/030] Train loss: 0.0089
2023-02-06 14:38:28 | Train | Epoch[379/600] Iteration[005/030] Train loss: 0.0092
2023-02-06 14:38:29 | Train | Epoch[379/600] Iteration[006/030] Train loss: 0.0092
2023-02-06 14:38:29 | Train | Epoch[379/600] Iteration[007/030] Train loss: 0.0091
2023-02-06 14:38:29 | Train | Epoch[379/600] Iteration[008/030] Train loss: 0.0093
2023-02-06 14:38:29 | Train | Epoch[379/600] Iteration[009/030] Train loss: 0.0093
2023-02-06 14:38:30 | Train | Epoch[379/600] Iteration[010/030] Train loss: 0.0091
2023-02-06 14:38:30 | Train | Epoch[379/600] Iteration[011/030] Train loss: 0.0092
2023-02-06 14:38:30 | Train | Epoch[379/600] Iteration[012/030] Train loss: 0.0091
2023-02-06 14:38:30 | Train | Epoch[379/600] Iteration[013/030] Train loss: 0.0091
2023-02-06 14:38:30 | Train | Epoch[379/600] Iteration[014/030] Train loss: 0.0092
2023-02-06 14:38:31 | Train | Epoch[379/600] Iteration[015/030] Train loss: 0.0092
2023-02-06 14:38:31 | Train | Epoch[379/600] Iteration[016/030] Train loss: 0.0092
2023-02-06 14:38:31 | Train | Epoch[379/600] Iteration[017/030] Train loss: 0.0092
2023-02-06 14:38:31 | Train | Epoch[379/600] Iteration[018/030] Train loss: 0.0091
2023-02-06 14:38:31 | Train | Epoch[379/600] Iteration[019/030] Train loss: 0.0092
2023-02-06 14:38:32 | Train | Epoch[379/600] Iteration[020/030] Train loss: 0.0092
2023-02-06 14:38:32 | Train | Epoch[379/600] Iteration[021/030] Train loss: 0.0091
2023-02-06 14:38:32 | Train | Epoch[379/600] Iteration[022/030] Train loss: 0.0092
2023-02-06 14:38:32 | Train | Epoch[379/600] Iteration[023/030] Train loss: 0.0091
2023-02-06 14:38:33 | Train | Epoch[379/600] Iteration[024/030] Train loss: 0.0092
2023-02-06 14:38:33 | Train | Epoch[379/600] Iteration[025/030] Train loss: 0.0093
2023-02-06 14:38:33 | Train | Epoch[379/600] Iteration[026/030] Train loss: 0.0094
2023-02-06 14:38:33 | Train | Epoch[379/600] Iteration[027/030] Train loss: 0.0095
2023-02-06 14:38:33 | Train | Epoch[379/600] Iteration[028/030] Train loss: 0.0095
2023-02-06 14:38:34 | Train | Epoch[379/600] Iteration[029/030] Train loss: 0.0095
2023-02-06 14:38:34 | Train | Epoch[379/600] Iteration[030/030] Train loss: 0.0095
2023-02-06 14:38:34 | Valid | Epoch[379/600] Iteration[001/008] Valid loss: 0.2169
2023-02-06 14:38:34 | Valid | Epoch[379/600] Iteration[002/008] Valid loss: 0.1679
2023-02-06 14:38:34 | Valid | Epoch[379/600] Iteration[003/008] Valid loss: 0.1563
2023-02-06 14:38:34 | Valid | Epoch[379/600] Iteration[004/008] Valid loss: 0.1481
2023-02-06 14:38:34 | Valid | Epoch[379/600] Iteration[005/008] Valid loss: 0.1485
2023-02-06 14:38:34 | Valid | Epoch[379/600] Iteration[006/008] Valid loss: 0.1475
2023-02-06 14:38:34 | Valid | Epoch[379/600] Iteration[007/008] Valid loss: 0.1661
2023-02-06 14:38:34 | Valid | Epoch[379/600] Iteration[008/008] Valid loss: 0.1653
2023-02-06 14:38:35 | Valid | Epoch[379/600] MIou: 0.927821096607589
2023-02-06 14:38:35 | Valid | Epoch[379/600] Pixel Accuracy: 0.9873479207356771
2023-02-06 14:38:35 | Valid | Epoch[379/600] Mean Pixel Accuracy: 0.9628779141837226
2023-02-06 14:38:35 | Stage | Epoch[379/600] Train loss:0.0095
2023-02-06 14:38:35 | Stage | Epoch[379/600] Valid loss:0.1653
2023-02-06 14:38:35 | Stage | Epoch[379/600] LR:0.01

2023-02-06 14:38:35 | Train | Epoch[380/600] Iteration[001/030] Train loss: 0.0098
2023-02-06 14:38:35 | Train | Epoch[380/600] Iteration[002/030] Train loss: 0.0096
2023-02-06 14:38:35 | Train | Epoch[380/600] Iteration[003/030] Train loss: 0.0101
2023-02-06 14:38:36 | Train | Epoch[380/600] Iteration[004/030] Train loss: 0.0098
2023-02-06 14:38:36 | Train | Epoch[380/600] Iteration[005/030] Train loss: 0.0096
2023-02-06 14:38:36 | Train | Epoch[380/600] Iteration[006/030] Train loss: 0.0097
2023-02-06 14:38:36 | Train | Epoch[380/600] Iteration[007/030] Train loss: 0.0096
2023-02-06 14:38:37 | Train | Epoch[380/600] Iteration[008/030] Train loss: 0.0097
2023-02-06 14:38:37 | Train | Epoch[380/600] Iteration[009/030] Train loss: 0.0098
2023-02-06 14:38:37 | Train | Epoch[380/600] Iteration[010/030] Train loss: 0.0097
2023-02-06 14:38:37 | Train | Epoch[380/600] Iteration[011/030] Train loss: 0.0097
2023-02-06 14:38:37 | Train | Epoch[380/600] Iteration[012/030] Train loss: 0.0096
2023-02-06 14:38:38 | Train | Epoch[380/600] Iteration[013/030] Train loss: 0.0095
2023-02-06 14:38:38 | Train | Epoch[380/600] Iteration[014/030] Train loss: 0.0095
2023-02-06 14:38:38 | Train | Epoch[380/600] Iteration[015/030] Train loss: 0.0094
2023-02-06 14:38:38 | Train | Epoch[380/600] Iteration[016/030] Train loss: 0.0094
2023-02-06 14:38:39 | Train | Epoch[380/600] Iteration[017/030] Train loss: 0.0093
2023-02-06 14:38:39 | Train | Epoch[380/600] Iteration[018/030] Train loss: 0.0093
2023-02-06 14:38:39 | Train | Epoch[380/600] Iteration[019/030] Train loss: 0.0092
2023-02-06 14:38:39 | Train | Epoch[380/600] Iteration[020/030] Train loss: 0.0092
2023-02-06 14:38:39 | Train | Epoch[380/600] Iteration[021/030] Train loss: 0.0092
2023-02-06 14:38:40 | Train | Epoch[380/600] Iteration[022/030] Train loss: 0.0093
2023-02-06 14:38:40 | Train | Epoch[380/600] Iteration[023/030] Train loss: 0.0094
2023-02-06 14:38:40 | Train | Epoch[380/600] Iteration[024/030] Train loss: 0.0095
2023-02-06 14:38:40 | Train | Epoch[380/600] Iteration[025/030] Train loss: 0.0094
2023-02-06 14:38:40 | Train | Epoch[380/600] Iteration[026/030] Train loss: 0.0094
2023-02-06 14:38:41 | Train | Epoch[380/600] Iteration[027/030] Train loss: 0.0094
2023-02-06 14:38:41 | Train | Epoch[380/600] Iteration[028/030] Train loss: 0.0095
2023-02-06 14:38:41 | Train | Epoch[380/600] Iteration[029/030] Train loss: 0.0095
2023-02-06 14:38:41 | Train | Epoch[380/600] Iteration[030/030] Train loss: 0.0095
2023-02-06 14:38:42 | Valid | Epoch[380/600] Iteration[001/008] Valid loss: 0.6358
2023-02-06 14:38:42 | Valid | Epoch[380/600] Iteration[002/008] Valid loss: 0.5980
2023-02-06 14:38:42 | Valid | Epoch[380/600] Iteration[003/008] Valid loss: 0.5960
2023-02-06 14:38:42 | Valid | Epoch[380/600] Iteration[004/008] Valid loss: 0.5933
2023-02-06 14:38:42 | Valid | Epoch[380/600] Iteration[005/008] Valid loss: 0.6099
2023-02-06 14:38:42 | Valid | Epoch[380/600] Iteration[006/008] Valid loss: 0.6094
2023-02-06 14:38:42 | Valid | Epoch[380/600] Iteration[007/008] Valid loss: 0.6443
2023-02-06 14:38:42 | Valid | Epoch[380/600] Iteration[008/008] Valid loss: 0.6573
2023-02-06 14:38:42 | Valid | Epoch[380/600] MIou: 0.8944149802819361
2023-02-06 14:38:42 | Valid | Epoch[380/600] Pixel Accuracy: 0.9793179829915365
2023-02-06 14:38:42 | Valid | Epoch[380/600] Mean Pixel Accuracy: 0.9823425336454736
2023-02-06 14:38:42 | Stage | Epoch[380/600] Train loss:0.0095
2023-02-06 14:38:42 | Stage | Epoch[380/600] Valid loss:0.6573
2023-02-06 14:38:42 | Stage | Epoch[380/600] LR:0.01

2023-02-06 14:38:42 | Train | Epoch[381/600] Iteration[001/030] Train loss: 0.0093
2023-02-06 14:38:43 | Train | Epoch[381/600] Iteration[002/030] Train loss: 0.0090
2023-02-06 14:38:43 | Train | Epoch[381/600] Iteration[003/030] Train loss: 0.0102
2023-02-06 14:38:43 | Train | Epoch[381/600] Iteration[004/030] Train loss: 0.0095
2023-02-06 14:38:43 | Train | Epoch[381/600] Iteration[005/030] Train loss: 0.0092
2023-02-06 14:38:44 | Train | Epoch[381/600] Iteration[006/030] Train loss: 0.0095
2023-02-06 14:38:44 | Train | Epoch[381/600] Iteration[007/030] Train loss: 0.0099
2023-02-06 14:38:44 | Train | Epoch[381/600] Iteration[008/030] Train loss: 0.0100
2023-02-06 14:38:44 | Train | Epoch[381/600] Iteration[009/030] Train loss: 0.0101
2023-02-06 14:38:44 | Train | Epoch[381/600] Iteration[010/030] Train loss: 0.0103
2023-02-06 14:38:45 | Train | Epoch[381/600] Iteration[011/030] Train loss: 0.0101
2023-02-06 14:38:45 | Train | Epoch[381/600] Iteration[012/030] Train loss: 0.0102
2023-02-06 14:38:45 | Train | Epoch[381/600] Iteration[013/030] Train loss: 0.0101
2023-02-06 14:38:45 | Train | Epoch[381/600] Iteration[014/030] Train loss: 0.0101
2023-02-06 14:38:45 | Train | Epoch[381/600] Iteration[015/030] Train loss: 0.0100
2023-02-06 14:38:46 | Train | Epoch[381/600] Iteration[016/030] Train loss: 0.0099
2023-02-06 14:38:46 | Train | Epoch[381/600] Iteration[017/030] Train loss: 0.0099
2023-02-06 14:38:46 | Train | Epoch[381/600] Iteration[018/030] Train loss: 0.0098
2023-02-06 14:38:46 | Train | Epoch[381/600] Iteration[019/030] Train loss: 0.0098
2023-02-06 14:38:47 | Train | Epoch[381/600] Iteration[020/030] Train loss: 0.0098
2023-02-06 14:38:47 | Train | Epoch[381/600] Iteration[021/030] Train loss: 0.0098
2023-02-06 14:38:47 | Train | Epoch[381/600] Iteration[022/030] Train loss: 0.0098
2023-02-06 14:38:47 | Train | Epoch[381/600] Iteration[023/030] Train loss: 0.0098
2023-02-06 14:38:47 | Train | Epoch[381/600] Iteration[024/030] Train loss: 0.0098
2023-02-06 14:38:48 | Train | Epoch[381/600] Iteration[025/030] Train loss: 0.0098
2023-02-06 14:38:48 | Train | Epoch[381/600] Iteration[026/030] Train loss: 0.0098
2023-02-06 14:38:48 | Train | Epoch[381/600] Iteration[027/030] Train loss: 0.0098
2023-02-06 14:38:48 | Train | Epoch[381/600] Iteration[028/030] Train loss: 0.0098
2023-02-06 14:38:49 | Train | Epoch[381/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:38:49 | Train | Epoch[381/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:38:49 | Valid | Epoch[381/600] Iteration[001/008] Valid loss: 0.0921
2023-02-06 14:38:49 | Valid | Epoch[381/600] Iteration[002/008] Valid loss: 0.0829
2023-02-06 14:38:49 | Valid | Epoch[381/600] Iteration[003/008] Valid loss: 0.0838
2023-02-06 14:38:49 | Valid | Epoch[381/600] Iteration[004/008] Valid loss: 0.0827
2023-02-06 14:38:49 | Valid | Epoch[381/600] Iteration[005/008] Valid loss: 0.0818
2023-02-06 14:38:49 | Valid | Epoch[381/600] Iteration[006/008] Valid loss: 0.0791
2023-02-06 14:38:49 | Valid | Epoch[381/600] Iteration[007/008] Valid loss: 0.0755
2023-02-06 14:38:49 | Valid | Epoch[381/600] Iteration[008/008] Valid loss: 0.0761
2023-02-06 14:38:50 | Valid | Epoch[381/600] MIou: 0.8379594680977742
2023-02-06 14:38:50 | Valid | Epoch[381/600] Pixel Accuracy: 0.9731966654459635
2023-02-06 14:38:50 | Valid | Epoch[381/600] Mean Pixel Accuracy: 0.8536268746607301
2023-02-06 14:38:50 | Stage | Epoch[381/600] Train loss:0.0098
2023-02-06 14:38:50 | Stage | Epoch[381/600] Valid loss:0.0761
2023-02-06 14:38:50 | Stage | Epoch[381/600] LR:0.01

2023-02-06 14:38:50 | Train | Epoch[382/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 14:38:50 | Train | Epoch[382/600] Iteration[002/030] Train loss: 0.0086
2023-02-06 14:38:50 | Train | Epoch[382/600] Iteration[003/030] Train loss: 0.0084
2023-02-06 14:38:51 | Train | Epoch[382/600] Iteration[004/030] Train loss: 0.0086
2023-02-06 14:38:51 | Train | Epoch[382/600] Iteration[005/030] Train loss: 0.0085
2023-02-06 14:38:51 | Train | Epoch[382/600] Iteration[006/030] Train loss: 0.0086
2023-02-06 14:38:51 | Train | Epoch[382/600] Iteration[007/030] Train loss: 0.0087
2023-02-06 14:38:52 | Train | Epoch[382/600] Iteration[008/030] Train loss: 0.0087
2023-02-06 14:38:52 | Train | Epoch[382/600] Iteration[009/030] Train loss: 0.0089
2023-02-06 14:38:52 | Train | Epoch[382/600] Iteration[010/030] Train loss: 0.0090
2023-02-06 14:38:52 | Train | Epoch[382/600] Iteration[011/030] Train loss: 0.0090
2023-02-06 14:38:52 | Train | Epoch[382/600] Iteration[012/030] Train loss: 0.0089
2023-02-06 14:38:53 | Train | Epoch[382/600] Iteration[013/030] Train loss: 0.0089
2023-02-06 14:38:53 | Train | Epoch[382/600] Iteration[014/030] Train loss: 0.0089
2023-02-06 14:38:53 | Train | Epoch[382/600] Iteration[015/030] Train loss: 0.0089
2023-02-06 14:38:53 | Train | Epoch[382/600] Iteration[016/030] Train loss: 0.0089
2023-02-06 14:38:54 | Train | Epoch[382/600] Iteration[017/030] Train loss: 0.0089
2023-02-06 14:38:54 | Train | Epoch[382/600] Iteration[018/030] Train loss: 0.0090
2023-02-06 14:38:54 | Train | Epoch[382/600] Iteration[019/030] Train loss: 0.0090
2023-02-06 14:38:54 | Train | Epoch[382/600] Iteration[020/030] Train loss: 0.0090
2023-02-06 14:38:54 | Train | Epoch[382/600] Iteration[021/030] Train loss: 0.0090
2023-02-06 14:38:55 | Train | Epoch[382/600] Iteration[022/030] Train loss: 0.0091
2023-02-06 14:38:55 | Train | Epoch[382/600] Iteration[023/030] Train loss: 0.0091
2023-02-06 14:38:55 | Train | Epoch[382/600] Iteration[024/030] Train loss: 0.0091
2023-02-06 14:38:55 | Train | Epoch[382/600] Iteration[025/030] Train loss: 0.0091
2023-02-06 14:38:56 | Train | Epoch[382/600] Iteration[026/030] Train loss: 0.0091
2023-02-06 14:38:56 | Train | Epoch[382/600] Iteration[027/030] Train loss: 0.0092
2023-02-06 14:38:56 | Train | Epoch[382/600] Iteration[028/030] Train loss: 0.0092
2023-02-06 14:38:56 | Train | Epoch[382/600] Iteration[029/030] Train loss: 0.0092
2023-02-06 14:38:56 | Train | Epoch[382/600] Iteration[030/030] Train loss: 0.0093
2023-02-06 14:38:57 | Valid | Epoch[382/600] Iteration[001/008] Valid loss: 0.3754
2023-02-06 14:38:57 | Valid | Epoch[382/600] Iteration[002/008] Valid loss: 0.3116
2023-02-06 14:38:57 | Valid | Epoch[382/600] Iteration[003/008] Valid loss: 0.3071
2023-02-06 14:38:57 | Valid | Epoch[382/600] Iteration[004/008] Valid loss: 0.2984
2023-02-06 14:38:57 | Valid | Epoch[382/600] Iteration[005/008] Valid loss: 0.3084
2023-02-06 14:38:57 | Valid | Epoch[382/600] Iteration[006/008] Valid loss: 0.2981
2023-02-06 14:38:57 | Valid | Epoch[382/600] Iteration[007/008] Valid loss: 0.3198
2023-02-06 14:38:57 | Valid | Epoch[382/600] Iteration[008/008] Valid loss: 0.3310
2023-02-06 14:38:57 | Valid | Epoch[382/600] MIou: 0.9105146749137207
2023-02-06 14:38:57 | Valid | Epoch[382/600] Pixel Accuracy: 0.9834149678548177
2023-02-06 14:38:57 | Valid | Epoch[382/600] Mean Pixel Accuracy: 0.9720783204936658
2023-02-06 14:38:57 | Stage | Epoch[382/600] Train loss:0.0093
2023-02-06 14:38:57 | Stage | Epoch[382/600] Valid loss:0.3310
2023-02-06 14:38:57 | Stage | Epoch[382/600] LR:0.01

2023-02-06 14:38:58 | Train | Epoch[383/600] Iteration[001/030] Train loss: 0.0093
2023-02-06 14:38:58 | Train | Epoch[383/600] Iteration[002/030] Train loss: 0.0091
2023-02-06 14:38:58 | Train | Epoch[383/600] Iteration[003/030] Train loss: 0.0090
2023-02-06 14:38:58 | Train | Epoch[383/600] Iteration[004/030] Train loss: 0.0091
2023-02-06 14:38:58 | Train | Epoch[383/600] Iteration[005/030] Train loss: 0.0089
2023-02-06 14:38:59 | Train | Epoch[383/600] Iteration[006/030] Train loss: 0.0092
2023-02-06 14:38:59 | Train | Epoch[383/600] Iteration[007/030] Train loss: 0.0093
2023-02-06 14:38:59 | Train | Epoch[383/600] Iteration[008/030] Train loss: 0.0093
2023-02-06 14:38:59 | Train | Epoch[383/600] Iteration[009/030] Train loss: 0.0094
2023-02-06 14:39:00 | Train | Epoch[383/600] Iteration[010/030] Train loss: 0.0096
2023-02-06 14:39:00 | Train | Epoch[383/600] Iteration[011/030] Train loss: 0.0098
2023-02-06 14:39:00 | Train | Epoch[383/600] Iteration[012/030] Train loss: 0.0096
2023-02-06 14:39:00 | Train | Epoch[383/600] Iteration[013/030] Train loss: 0.0096
2023-02-06 14:39:00 | Train | Epoch[383/600] Iteration[014/030] Train loss: 0.0095
2023-02-06 14:39:01 | Train | Epoch[383/600] Iteration[015/030] Train loss: 0.0094
2023-02-06 14:39:01 | Train | Epoch[383/600] Iteration[016/030] Train loss: 0.0095
2023-02-06 14:39:01 | Train | Epoch[383/600] Iteration[017/030] Train loss: 0.0096
2023-02-06 14:39:01 | Train | Epoch[383/600] Iteration[018/030] Train loss: 0.0096
2023-02-06 14:39:02 | Train | Epoch[383/600] Iteration[019/030] Train loss: 0.0096
2023-02-06 14:39:02 | Train | Epoch[383/600] Iteration[020/030] Train loss: 0.0096
2023-02-06 14:39:02 | Train | Epoch[383/600] Iteration[021/030] Train loss: 0.0096
2023-02-06 14:39:02 | Train | Epoch[383/600] Iteration[022/030] Train loss: 0.0096
2023-02-06 14:39:02 | Train | Epoch[383/600] Iteration[023/030] Train loss: 0.0096
2023-02-06 14:39:03 | Train | Epoch[383/600] Iteration[024/030] Train loss: 0.0096
2023-02-06 14:39:03 | Train | Epoch[383/600] Iteration[025/030] Train loss: 0.0096
2023-02-06 14:39:03 | Train | Epoch[383/600] Iteration[026/030] Train loss: 0.0096
2023-02-06 14:39:03 | Train | Epoch[383/600] Iteration[027/030] Train loss: 0.0096
2023-02-06 14:39:04 | Train | Epoch[383/600] Iteration[028/030] Train loss: 0.0096
2023-02-06 14:39:04 | Train | Epoch[383/600] Iteration[029/030] Train loss: 0.0096
2023-02-06 14:39:04 | Train | Epoch[383/600] Iteration[030/030] Train loss: 0.0096
2023-02-06 14:39:04 | Valid | Epoch[383/600] Iteration[001/008] Valid loss: 0.1303
2023-02-06 14:39:04 | Valid | Epoch[383/600] Iteration[002/008] Valid loss: 0.1050
2023-02-06 14:39:04 | Valid | Epoch[383/600] Iteration[003/008] Valid loss: 0.1011
2023-02-06 14:39:04 | Valid | Epoch[383/600] Iteration[004/008] Valid loss: 0.0970
2023-02-06 14:39:04 | Valid | Epoch[383/600] Iteration[005/008] Valid loss: 0.0917
2023-02-06 14:39:04 | Valid | Epoch[383/600] Iteration[006/008] Valid loss: 0.0908
2023-02-06 14:39:05 | Valid | Epoch[383/600] Iteration[007/008] Valid loss: 0.0965
2023-02-06 14:39:05 | Valid | Epoch[383/600] Iteration[008/008] Valid loss: 0.0940
2023-02-06 14:39:05 | Valid | Epoch[383/600] MIou: 0.9171519802797862
2023-02-06 14:39:05 | Valid | Epoch[383/600] Pixel Accuracy: 0.9859199523925781
2023-02-06 14:39:05 | Valid | Epoch[383/600] Mean Pixel Accuracy: 0.9385064878560416
2023-02-06 14:39:05 | Stage | Epoch[383/600] Train loss:0.0096
2023-02-06 14:39:05 | Stage | Epoch[383/600] Valid loss:0.0940
2023-02-06 14:39:05 | Stage | Epoch[383/600] LR:0.01

2023-02-06 14:39:05 | Train | Epoch[384/600] Iteration[001/030] Train loss: 0.0086
2023-02-06 14:39:05 | Train | Epoch[384/600] Iteration[002/030] Train loss: 0.0098
2023-02-06 14:39:06 | Train | Epoch[384/600] Iteration[003/030] Train loss: 0.0090
2023-02-06 14:39:06 | Train | Epoch[384/600] Iteration[004/030] Train loss: 0.0090
2023-02-06 14:39:06 | Train | Epoch[384/600] Iteration[005/030] Train loss: 0.0091
2023-02-06 14:39:06 | Train | Epoch[384/600] Iteration[006/030] Train loss: 0.0093
2023-02-06 14:39:07 | Train | Epoch[384/600] Iteration[007/030] Train loss: 0.0092
2023-02-06 14:39:07 | Train | Epoch[384/600] Iteration[008/030] Train loss: 0.0092
2023-02-06 14:39:07 | Train | Epoch[384/600] Iteration[009/030] Train loss: 0.0091
2023-02-06 14:39:07 | Train | Epoch[384/600] Iteration[010/030] Train loss: 0.0092
2023-02-06 14:39:07 | Train | Epoch[384/600] Iteration[011/030] Train loss: 0.0096
2023-02-06 14:39:08 | Train | Epoch[384/600] Iteration[012/030] Train loss: 0.0096
2023-02-06 14:39:08 | Train | Epoch[384/600] Iteration[013/030] Train loss: 0.0096
2023-02-06 14:39:08 | Train | Epoch[384/600] Iteration[014/030] Train loss: 0.0096
2023-02-06 14:39:08 | Train | Epoch[384/600] Iteration[015/030] Train loss: 0.0096
2023-02-06 14:39:09 | Train | Epoch[384/600] Iteration[016/030] Train loss: 0.0096
2023-02-06 14:39:09 | Train | Epoch[384/600] Iteration[017/030] Train loss: 0.0096
2023-02-06 14:39:09 | Train | Epoch[384/600] Iteration[018/030] Train loss: 0.0097
2023-02-06 14:39:09 | Train | Epoch[384/600] Iteration[019/030] Train loss: 0.0097
2023-02-06 14:39:09 | Train | Epoch[384/600] Iteration[020/030] Train loss: 0.0097
2023-02-06 14:39:10 | Train | Epoch[384/600] Iteration[021/030] Train loss: 0.0097
2023-02-06 14:39:10 | Train | Epoch[384/600] Iteration[022/030] Train loss: 0.0097
2023-02-06 14:39:10 | Train | Epoch[384/600] Iteration[023/030] Train loss: 0.0097
2023-02-06 14:39:10 | Train | Epoch[384/600] Iteration[024/030] Train loss: 0.0097
2023-02-06 14:39:10 | Train | Epoch[384/600] Iteration[025/030] Train loss: 0.0097
2023-02-06 14:39:11 | Train | Epoch[384/600] Iteration[026/030] Train loss: 0.0097
2023-02-06 14:39:11 | Train | Epoch[384/600] Iteration[027/030] Train loss: 0.0097
2023-02-06 14:39:11 | Train | Epoch[384/600] Iteration[028/030] Train loss: 0.0098
2023-02-06 14:39:11 | Train | Epoch[384/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:39:11 | Train | Epoch[384/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:39:12 | Valid | Epoch[384/600] Iteration[001/008] Valid loss: 0.1130
2023-02-06 14:39:12 | Valid | Epoch[384/600] Iteration[002/008] Valid loss: 0.0880
2023-02-06 14:39:12 | Valid | Epoch[384/600] Iteration[003/008] Valid loss: 0.0803
2023-02-06 14:39:12 | Valid | Epoch[384/600] Iteration[004/008] Valid loss: 0.0762
2023-02-06 14:39:12 | Valid | Epoch[384/600] Iteration[005/008] Valid loss: 0.0756
2023-02-06 14:39:12 | Valid | Epoch[384/600] Iteration[006/008] Valid loss: 0.0730
2023-02-06 14:39:12 | Valid | Epoch[384/600] Iteration[007/008] Valid loss: 0.0744
2023-02-06 14:39:12 | Valid | Epoch[384/600] Iteration[008/008] Valid loss: 0.0724
2023-02-06 14:39:12 | Valid | Epoch[384/600] MIou: 0.9102916565695025
2023-02-06 14:39:12 | Valid | Epoch[384/600] Pixel Accuracy: 0.9849116007486979
2023-02-06 14:39:12 | Valid | Epoch[384/600] Mean Pixel Accuracy: 0.9275094982070122
2023-02-06 14:39:12 | Stage | Epoch[384/600] Train loss:0.0098
2023-02-06 14:39:12 | Stage | Epoch[384/600] Valid loss:0.0724
2023-02-06 14:39:12 | Stage | Epoch[384/600] LR:0.01

2023-02-06 14:39:13 | Train | Epoch[385/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:39:13 | Train | Epoch[385/600] Iteration[002/030] Train loss: 0.0090
2023-02-06 14:39:13 | Train | Epoch[385/600] Iteration[003/030] Train loss: 0.0094
2023-02-06 14:39:13 | Train | Epoch[385/600] Iteration[004/030] Train loss: 0.0094
2023-02-06 14:39:14 | Train | Epoch[385/600] Iteration[005/030] Train loss: 0.0095
2023-02-06 14:39:14 | Train | Epoch[385/600] Iteration[006/030] Train loss: 0.0098
2023-02-06 14:39:14 | Train | Epoch[385/600] Iteration[007/030] Train loss: 0.0097
2023-02-06 14:39:14 | Train | Epoch[385/600] Iteration[008/030] Train loss: 0.0096
2023-02-06 14:39:14 | Train | Epoch[385/600] Iteration[009/030] Train loss: 0.0096
2023-02-06 14:39:15 | Train | Epoch[385/600] Iteration[010/030] Train loss: 0.0095
2023-02-06 14:39:15 | Train | Epoch[385/600] Iteration[011/030] Train loss: 0.0093
2023-02-06 14:39:15 | Train | Epoch[385/600] Iteration[012/030] Train loss: 0.0093
2023-02-06 14:39:15 | Train | Epoch[385/600] Iteration[013/030] Train loss: 0.0093
2023-02-06 14:39:16 | Train | Epoch[385/600] Iteration[014/030] Train loss: 0.0092
2023-02-06 14:39:16 | Train | Epoch[385/600] Iteration[015/030] Train loss: 0.0092
2023-02-06 14:39:16 | Train | Epoch[385/600] Iteration[016/030] Train loss: 0.0092
2023-02-06 14:39:16 | Train | Epoch[385/600] Iteration[017/030] Train loss: 0.0094
2023-02-06 14:39:16 | Train | Epoch[385/600] Iteration[018/030] Train loss: 0.0094
2023-02-06 14:39:17 | Train | Epoch[385/600] Iteration[019/030] Train loss: 0.0094
2023-02-06 14:39:17 | Train | Epoch[385/600] Iteration[020/030] Train loss: 0.0094
2023-02-06 14:39:17 | Train | Epoch[385/600] Iteration[021/030] Train loss: 0.0094
2023-02-06 14:39:17 | Train | Epoch[385/600] Iteration[022/030] Train loss: 0.0094
2023-02-06 14:39:18 | Train | Epoch[385/600] Iteration[023/030] Train loss: 0.0094
2023-02-06 14:39:18 | Train | Epoch[385/600] Iteration[024/030] Train loss: 0.0094
2023-02-06 14:39:18 | Train | Epoch[385/600] Iteration[025/030] Train loss: 0.0095
2023-02-06 14:39:18 | Train | Epoch[385/600] Iteration[026/030] Train loss: 0.0095
2023-02-06 14:39:18 | Train | Epoch[385/600] Iteration[027/030] Train loss: 0.0096
2023-02-06 14:39:19 | Train | Epoch[385/600] Iteration[028/030] Train loss: 0.0096
2023-02-06 14:39:19 | Train | Epoch[385/600] Iteration[029/030] Train loss: 0.0096
2023-02-06 14:39:19 | Train | Epoch[385/600] Iteration[030/030] Train loss: 0.0096
2023-02-06 14:39:19 | Valid | Epoch[385/600] Iteration[001/008] Valid loss: 0.0733
2023-02-06 14:39:19 | Valid | Epoch[385/600] Iteration[002/008] Valid loss: 0.0694
2023-02-06 14:39:20 | Valid | Epoch[385/600] Iteration[003/008] Valid loss: 0.0703
2023-02-06 14:39:20 | Valid | Epoch[385/600] Iteration[004/008] Valid loss: 0.0689
2023-02-06 14:39:20 | Valid | Epoch[385/600] Iteration[005/008] Valid loss: 0.0684
2023-02-06 14:39:20 | Valid | Epoch[385/600] Iteration[006/008] Valid loss: 0.0666
2023-02-06 14:39:20 | Valid | Epoch[385/600] Iteration[007/008] Valid loss: 0.0658
2023-02-06 14:39:20 | Valid | Epoch[385/600] Iteration[008/008] Valid loss: 0.0659
2023-02-06 14:39:20 | Valid | Epoch[385/600] MIou: 0.8632028581003778
2023-02-06 14:39:20 | Valid | Epoch[385/600] Pixel Accuracy: 0.9771906534830729
2023-02-06 14:39:20 | Valid | Epoch[385/600] Mean Pixel Accuracy: 0.8799539754003709
2023-02-06 14:39:20 | Stage | Epoch[385/600] Train loss:0.0096
2023-02-06 14:39:20 | Stage | Epoch[385/600] Valid loss:0.0659
2023-02-06 14:39:20 | Stage | Epoch[385/600] LR:0.01

2023-02-06 14:39:20 | Train | Epoch[386/600] Iteration[001/030] Train loss: 0.0096
2023-02-06 14:39:21 | Train | Epoch[386/600] Iteration[002/030] Train loss: 0.0091
2023-02-06 14:39:21 | Train | Epoch[386/600] Iteration[003/030] Train loss: 0.0088
2023-02-06 14:39:21 | Train | Epoch[386/600] Iteration[004/030] Train loss: 0.0089
2023-02-06 14:39:21 | Train | Epoch[386/600] Iteration[005/030] Train loss: 0.0090
2023-02-06 14:39:21 | Train | Epoch[386/600] Iteration[006/030] Train loss: 0.0091
2023-02-06 14:39:22 | Train | Epoch[386/600] Iteration[007/030] Train loss: 0.0099
2023-02-06 14:39:22 | Train | Epoch[386/600] Iteration[008/030] Train loss: 0.0100
2023-02-06 14:39:22 | Train | Epoch[386/600] Iteration[009/030] Train loss: 0.0100
2023-02-06 14:39:22 | Train | Epoch[386/600] Iteration[010/030] Train loss: 0.0103
2023-02-06 14:39:23 | Train | Epoch[386/600] Iteration[011/030] Train loss: 0.0103
2023-02-06 14:39:23 | Train | Epoch[386/600] Iteration[012/030] Train loss: 0.0105
2023-02-06 14:39:23 | Train | Epoch[386/600] Iteration[013/030] Train loss: 0.0104
2023-02-06 14:39:23 | Train | Epoch[386/600] Iteration[014/030] Train loss: 0.0104
2023-02-06 14:39:23 | Train | Epoch[386/600] Iteration[015/030] Train loss: 0.0103
2023-02-06 14:39:24 | Train | Epoch[386/600] Iteration[016/030] Train loss: 0.0103
2023-02-06 14:39:24 | Train | Epoch[386/600] Iteration[017/030] Train loss: 0.0104
2023-02-06 14:39:24 | Train | Epoch[386/600] Iteration[018/030] Train loss: 0.0103
2023-02-06 14:39:24 | Train | Epoch[386/600] Iteration[019/030] Train loss: 0.0103
2023-02-06 14:39:25 | Train | Epoch[386/600] Iteration[020/030] Train loss: 0.0107
2023-02-06 14:39:25 | Train | Epoch[386/600] Iteration[021/030] Train loss: 0.0106
2023-02-06 14:39:25 | Train | Epoch[386/600] Iteration[022/030] Train loss: 0.0106
2023-02-06 14:39:25 | Train | Epoch[386/600] Iteration[023/030] Train loss: 0.0108
2023-02-06 14:39:25 | Train | Epoch[386/600] Iteration[024/030] Train loss: 0.0109
2023-02-06 14:39:26 | Train | Epoch[386/600] Iteration[025/030] Train loss: 0.0110
2023-02-06 14:39:26 | Train | Epoch[386/600] Iteration[026/030] Train loss: 0.0109
2023-02-06 14:39:26 | Train | Epoch[386/600] Iteration[027/030] Train loss: 0.0109
2023-02-06 14:39:26 | Train | Epoch[386/600] Iteration[028/030] Train loss: 0.0108
2023-02-06 14:39:27 | Train | Epoch[386/600] Iteration[029/030] Train loss: 0.0109
2023-02-06 14:39:27 | Train | Epoch[386/600] Iteration[030/030] Train loss: 0.0109
2023-02-06 14:39:27 | Valid | Epoch[386/600] Iteration[001/008] Valid loss: 0.5729
2023-02-06 14:39:27 | Valid | Epoch[386/600] Iteration[002/008] Valid loss: 0.5431
2023-02-06 14:39:27 | Valid | Epoch[386/600] Iteration[003/008] Valid loss: 0.5621
2023-02-06 14:39:27 | Valid | Epoch[386/600] Iteration[004/008] Valid loss: 0.5647
2023-02-06 14:39:27 | Valid | Epoch[386/600] Iteration[005/008] Valid loss: 0.5787
2023-02-06 14:39:27 | Valid | Epoch[386/600] Iteration[006/008] Valid loss: 0.5775
2023-02-06 14:39:27 | Valid | Epoch[386/600] Iteration[007/008] Valid loss: 0.6124
2023-02-06 14:39:27 | Valid | Epoch[386/600] Iteration[008/008] Valid loss: 0.6329
2023-02-06 14:39:27 | Valid | Epoch[386/600] MIou: 0.88267147303813
2023-02-06 14:39:27 | Valid | Epoch[386/600] Pixel Accuracy: 0.9766082763671875
2023-02-06 14:39:27 | Valid | Epoch[386/600] Mean Pixel Accuracy: 0.9782472295270743
2023-02-06 14:39:27 | Stage | Epoch[386/600] Train loss:0.0109
2023-02-06 14:39:27 | Stage | Epoch[386/600] Valid loss:0.6329
2023-02-06 14:39:27 | Stage | Epoch[386/600] LR:0.01

2023-02-06 14:39:28 | Train | Epoch[387/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:39:28 | Train | Epoch[387/600] Iteration[002/030] Train loss: 0.0090
2023-02-06 14:39:28 | Train | Epoch[387/600] Iteration[003/030] Train loss: 0.0090
2023-02-06 14:39:29 | Train | Epoch[387/600] Iteration[004/030] Train loss: 0.0091
2023-02-06 14:39:29 | Train | Epoch[387/600] Iteration[005/030] Train loss: 0.0093
2023-02-06 14:39:29 | Train | Epoch[387/600] Iteration[006/030] Train loss: 0.0094
2023-02-06 14:39:29 | Train | Epoch[387/600] Iteration[007/030] Train loss: 0.0098
2023-02-06 14:39:29 | Train | Epoch[387/600] Iteration[008/030] Train loss: 0.0098
2023-02-06 14:39:30 | Train | Epoch[387/600] Iteration[009/030] Train loss: 0.0098
2023-02-06 14:39:30 | Train | Epoch[387/600] Iteration[010/030] Train loss: 0.0097
2023-02-06 14:39:30 | Train | Epoch[387/600] Iteration[011/030] Train loss: 0.0098
2023-02-06 14:39:30 | Train | Epoch[387/600] Iteration[012/030] Train loss: 0.0099
2023-02-06 14:39:31 | Train | Epoch[387/600] Iteration[013/030] Train loss: 0.0099
2023-02-06 14:39:31 | Train | Epoch[387/600] Iteration[014/030] Train loss: 0.0099
2023-02-06 14:39:31 | Train | Epoch[387/600] Iteration[015/030] Train loss: 0.0099
2023-02-06 14:39:31 | Train | Epoch[387/600] Iteration[016/030] Train loss: 0.0099
2023-02-06 14:39:31 | Train | Epoch[387/600] Iteration[017/030] Train loss: 0.0099
2023-02-06 14:39:32 | Train | Epoch[387/600] Iteration[018/030] Train loss: 0.0099
2023-02-06 14:39:32 | Train | Epoch[387/600] Iteration[019/030] Train loss: 0.0100
2023-02-06 14:39:32 | Train | Epoch[387/600] Iteration[020/030] Train loss: 0.0100
2023-02-06 14:39:32 | Train | Epoch[387/600] Iteration[021/030] Train loss: 0.0100
2023-02-06 14:39:33 | Train | Epoch[387/600] Iteration[022/030] Train loss: 0.0099
2023-02-06 14:39:33 | Train | Epoch[387/600] Iteration[023/030] Train loss: 0.0100
2023-02-06 14:39:33 | Train | Epoch[387/600] Iteration[024/030] Train loss: 0.0101
2023-02-06 14:39:33 | Train | Epoch[387/600] Iteration[025/030] Train loss: 0.0101
2023-02-06 14:39:33 | Train | Epoch[387/600] Iteration[026/030] Train loss: 0.0102
2023-02-06 14:39:34 | Train | Epoch[387/600] Iteration[027/030] Train loss: 0.0102
2023-02-06 14:39:34 | Train | Epoch[387/600] Iteration[028/030] Train loss: 0.0102
2023-02-06 14:39:34 | Train | Epoch[387/600] Iteration[029/030] Train loss: 0.0102
2023-02-06 14:39:34 | Train | Epoch[387/600] Iteration[030/030] Train loss: 0.0102
2023-02-06 14:39:35 | Valid | Epoch[387/600] Iteration[001/008] Valid loss: 0.1189
2023-02-06 14:39:35 | Valid | Epoch[387/600] Iteration[002/008] Valid loss: 0.0946
2023-02-06 14:39:35 | Valid | Epoch[387/600] Iteration[003/008] Valid loss: 0.0938
2023-02-06 14:39:35 | Valid | Epoch[387/600] Iteration[004/008] Valid loss: 0.0939
2023-02-06 14:39:35 | Valid | Epoch[387/600] Iteration[005/008] Valid loss: 0.0895
2023-02-06 14:39:35 | Valid | Epoch[387/600] Iteration[006/008] Valid loss: 0.0889
2023-02-06 14:39:35 | Valid | Epoch[387/600] Iteration[007/008] Valid loss: 0.0939
2023-02-06 14:39:35 | Valid | Epoch[387/600] Iteration[008/008] Valid loss: 0.0922
2023-02-06 14:39:35 | Valid | Epoch[387/600] MIou: 0.9137457144406473
2023-02-06 14:39:35 | Valid | Epoch[387/600] Pixel Accuracy: 0.9852714538574219
2023-02-06 14:39:35 | Valid | Epoch[387/600] Mean Pixel Accuracy: 0.9373511459928041
2023-02-06 14:39:35 | Stage | Epoch[387/600] Train loss:0.0102
2023-02-06 14:39:35 | Stage | Epoch[387/600] Valid loss:0.0922
2023-02-06 14:39:35 | Stage | Epoch[387/600] LR:0.01

2023-02-06 14:39:36 | Train | Epoch[388/600] Iteration[001/030] Train loss: 0.0103
2023-02-06 14:39:36 | Train | Epoch[388/600] Iteration[002/030] Train loss: 0.0090
2023-02-06 14:39:36 | Train | Epoch[388/600] Iteration[003/030] Train loss: 0.0092
2023-02-06 14:39:36 | Train | Epoch[388/600] Iteration[004/030] Train loss: 0.0091
2023-02-06 14:39:36 | Train | Epoch[388/600] Iteration[005/030] Train loss: 0.0094
2023-02-06 14:39:37 | Train | Epoch[388/600] Iteration[006/030] Train loss: 0.0094
2023-02-06 14:39:37 | Train | Epoch[388/600] Iteration[007/030] Train loss: 0.0096
2023-02-06 14:39:37 | Train | Epoch[388/600] Iteration[008/030] Train loss: 0.0096
2023-02-06 14:39:37 | Train | Epoch[388/600] Iteration[009/030] Train loss: 0.0097
2023-02-06 14:39:38 | Train | Epoch[388/600] Iteration[010/030] Train loss: 0.0096
2023-02-06 14:39:38 | Train | Epoch[388/600] Iteration[011/030] Train loss: 0.0097
2023-02-06 14:39:38 | Train | Epoch[388/600] Iteration[012/030] Train loss: 0.0097
2023-02-06 14:39:38 | Train | Epoch[388/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:39:38 | Train | Epoch[388/600] Iteration[014/030] Train loss: 0.0097
2023-02-06 14:39:39 | Train | Epoch[388/600] Iteration[015/030] Train loss: 0.0096
2023-02-06 14:39:39 | Train | Epoch[388/600] Iteration[016/030] Train loss: 0.0096
2023-02-06 14:39:39 | Train | Epoch[388/600] Iteration[017/030] Train loss: 0.0097
2023-02-06 14:39:39 | Train | Epoch[388/600] Iteration[018/030] Train loss: 0.0097
2023-02-06 14:39:39 | Train | Epoch[388/600] Iteration[019/030] Train loss: 0.0096
2023-02-06 14:39:40 | Train | Epoch[388/600] Iteration[020/030] Train loss: 0.0096
2023-02-06 14:39:40 | Train | Epoch[388/600] Iteration[021/030] Train loss: 0.0096
2023-02-06 14:39:40 | Train | Epoch[388/600] Iteration[022/030] Train loss: 0.0096
2023-02-06 14:39:40 | Train | Epoch[388/600] Iteration[023/030] Train loss: 0.0096
2023-02-06 14:39:41 | Train | Epoch[388/600] Iteration[024/030] Train loss: 0.0096
2023-02-06 14:39:41 | Train | Epoch[388/600] Iteration[025/030] Train loss: 0.0096
2023-02-06 14:39:41 | Train | Epoch[388/600] Iteration[026/030] Train loss: 0.0097
2023-02-06 14:39:41 | Train | Epoch[388/600] Iteration[027/030] Train loss: 0.0097
2023-02-06 14:39:41 | Train | Epoch[388/600] Iteration[028/030] Train loss: 0.0098
2023-02-06 14:39:42 | Train | Epoch[388/600] Iteration[029/030] Train loss: 0.0098
2023-02-06 14:39:42 | Train | Epoch[388/600] Iteration[030/030] Train loss: 0.0098
2023-02-06 14:39:42 | Valid | Epoch[388/600] Iteration[001/008] Valid loss: 0.1990
2023-02-06 14:39:42 | Valid | Epoch[388/600] Iteration[002/008] Valid loss: 0.1700
2023-02-06 14:39:42 | Valid | Epoch[388/600] Iteration[003/008] Valid loss: 0.1587
2023-02-06 14:39:42 | Valid | Epoch[388/600] Iteration[004/008] Valid loss: 0.1491
2023-02-06 14:39:42 | Valid | Epoch[388/600] Iteration[005/008] Valid loss: 0.1437
2023-02-06 14:39:42 | Valid | Epoch[388/600] Iteration[006/008] Valid loss: 0.1405
2023-02-06 14:39:42 | Valid | Epoch[388/600] Iteration[007/008] Valid loss: 0.1519
2023-02-06 14:39:42 | Valid | Epoch[388/600] Iteration[008/008] Valid loss: 0.1508
2023-02-06 14:39:43 | Valid | Epoch[388/600] MIou: 0.927532140433674
2023-02-06 14:39:43 | Valid | Epoch[388/600] Pixel Accuracy: 0.987328847249349
2023-02-06 14:39:43 | Valid | Epoch[388/600] Mean Pixel Accuracy: 0.96142814354893
2023-02-06 14:39:43 | Stage | Epoch[388/600] Train loss:0.0098
2023-02-06 14:39:43 | Stage | Epoch[388/600] Valid loss:0.1508
2023-02-06 14:39:43 | Stage | Epoch[388/600] LR:0.01

2023-02-06 14:39:43 | Train | Epoch[389/600] Iteration[001/030] Train loss: 0.0092
2023-02-06 14:39:43 | Train | Epoch[389/600] Iteration[002/030] Train loss: 0.0119
2023-02-06 14:39:44 | Train | Epoch[389/600] Iteration[003/030] Train loss: 0.0124
2023-02-06 14:39:44 | Train | Epoch[389/600] Iteration[004/030] Train loss: 0.0120
2023-02-06 14:39:44 | Train | Epoch[389/600] Iteration[005/030] Train loss: 0.0112
2023-02-06 14:39:44 | Train | Epoch[389/600] Iteration[006/030] Train loss: 0.0106
2023-02-06 14:39:44 | Train | Epoch[389/600] Iteration[007/030] Train loss: 0.0104
2023-02-06 14:39:45 | Train | Epoch[389/600] Iteration[008/030] Train loss: 0.0102
2023-02-06 14:39:45 | Train | Epoch[389/600] Iteration[009/030] Train loss: 0.0102
2023-02-06 14:39:45 | Train | Epoch[389/600] Iteration[010/030] Train loss: 0.0102
2023-02-06 14:39:45 | Train | Epoch[389/600] Iteration[011/030] Train loss: 0.0101
2023-02-06 14:39:45 | Train | Epoch[389/600] Iteration[012/030] Train loss: 0.0102
2023-02-06 14:39:46 | Train | Epoch[389/600] Iteration[013/030] Train loss: 0.0100
2023-02-06 14:39:46 | Train | Epoch[389/600] Iteration[014/030] Train loss: 0.0102
2023-02-06 14:39:46 | Train | Epoch[389/600] Iteration[015/030] Train loss: 0.0101
2023-02-06 14:39:46 | Train | Epoch[389/600] Iteration[016/030] Train loss: 0.0101
2023-02-06 14:39:47 | Train | Epoch[389/600] Iteration[017/030] Train loss: 0.0100
2023-02-06 14:39:47 | Train | Epoch[389/600] Iteration[018/030] Train loss: 0.0100
2023-02-06 14:39:47 | Train | Epoch[389/600] Iteration[019/030] Train loss: 0.0099
2023-02-06 14:39:47 | Train | Epoch[389/600] Iteration[020/030] Train loss: 0.0099
2023-02-06 14:39:47 | Train | Epoch[389/600] Iteration[021/030] Train loss: 0.0100
2023-02-06 14:39:48 | Train | Epoch[389/600] Iteration[022/030] Train loss: 0.0100
2023-02-06 14:39:48 | Train | Epoch[389/600] Iteration[023/030] Train loss: 0.0101
2023-02-06 14:39:48 | Train | Epoch[389/600] Iteration[024/030] Train loss: 0.0101
2023-02-06 14:39:48 | Train | Epoch[389/600] Iteration[025/030] Train loss: 0.0100
2023-02-06 14:39:49 | Train | Epoch[389/600] Iteration[026/030] Train loss: 0.0100
2023-02-06 14:39:49 | Train | Epoch[389/600] Iteration[027/030] Train loss: 0.0100
2023-02-06 14:39:49 | Train | Epoch[389/600] Iteration[028/030] Train loss: 0.0101
2023-02-06 14:39:49 | Train | Epoch[389/600] Iteration[029/030] Train loss: 0.0101
2023-02-06 14:39:49 | Train | Epoch[389/600] Iteration[030/030] Train loss: 0.0102
2023-02-06 14:39:50 | Valid | Epoch[389/600] Iteration[001/008] Valid loss: 0.1043
2023-02-06 14:39:50 | Valid | Epoch[389/600] Iteration[002/008] Valid loss: 0.0789
2023-02-06 14:39:50 | Valid | Epoch[389/600] Iteration[003/008] Valid loss: 0.0736
2023-02-06 14:39:50 | Valid | Epoch[389/600] Iteration[004/008] Valid loss: 0.0708
2023-02-06 14:39:50 | Valid | Epoch[389/600] Iteration[005/008] Valid loss: 0.0695
2023-02-06 14:39:50 | Valid | Epoch[389/600] Iteration[006/008] Valid loss: 0.0660
2023-02-06 14:39:50 | Valid | Epoch[389/600] Iteration[007/008] Valid loss: 0.0653
2023-02-06 14:39:50 | Valid | Epoch[389/600] Iteration[008/008] Valid loss: 0.0650
2023-02-06 14:39:50 | Valid | Epoch[389/600] MIou: 0.8928231527792942
2023-02-06 14:39:50 | Valid | Epoch[389/600] Pixel Accuracy: 0.9819984436035156
2023-02-06 14:39:50 | Valid | Epoch[389/600] Mean Pixel Accuracy: 0.9105263189085672
2023-02-06 14:39:50 | Stage | Epoch[389/600] Train loss:0.0102
2023-02-06 14:39:50 | Stage | Epoch[389/600] Valid loss:0.0650
2023-02-06 14:39:50 | Stage | Epoch[389/600] LR:0.01

2023-02-06 14:39:51 | Train | Epoch[390/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:39:51 | Train | Epoch[390/600] Iteration[002/030] Train loss: 0.0088
2023-02-06 14:39:51 | Train | Epoch[390/600] Iteration[003/030] Train loss: 0.0090
2023-02-06 14:39:51 | Train | Epoch[390/600] Iteration[004/030] Train loss: 0.0090
2023-02-06 14:39:51 | Train | Epoch[390/600] Iteration[005/030] Train loss: 0.0093
2023-02-06 14:39:52 | Train | Epoch[390/600] Iteration[006/030] Train loss: 0.0091
2023-02-06 14:39:52 | Train | Epoch[390/600] Iteration[007/030] Train loss: 0.0092
2023-02-06 14:39:52 | Train | Epoch[390/600] Iteration[008/030] Train loss: 0.0094
2023-02-06 14:39:52 | Train | Epoch[390/600] Iteration[009/030] Train loss: 0.0093
2023-02-06 14:39:53 | Train | Epoch[390/600] Iteration[010/030] Train loss: 0.0093
2023-02-06 14:39:53 | Train | Epoch[390/600] Iteration[011/030] Train loss: 0.0093
2023-02-06 14:39:53 | Train | Epoch[390/600] Iteration[012/030] Train loss: 0.0093
2023-02-06 14:39:53 | Train | Epoch[390/600] Iteration[013/030] Train loss: 0.0092
2023-02-06 14:39:53 | Train | Epoch[390/600] Iteration[014/030] Train loss: 0.0091
2023-02-06 14:39:54 | Train | Epoch[390/600] Iteration[015/030] Train loss: 0.0093
2023-02-06 14:39:54 | Train | Epoch[390/600] Iteration[016/030] Train loss: 0.0092
2023-02-06 14:39:54 | Train | Epoch[390/600] Iteration[017/030] Train loss: 0.0092
2023-02-06 14:39:54 | Train | Epoch[390/600] Iteration[018/030] Train loss: 0.0092
2023-02-06 14:39:55 | Train | Epoch[390/600] Iteration[019/030] Train loss: 0.0092
2023-02-06 14:39:55 | Train | Epoch[390/600] Iteration[020/030] Train loss: 0.0092
2023-02-06 14:39:55 | Train | Epoch[390/600] Iteration[021/030] Train loss: 0.0093
2023-02-06 14:39:55 | Train | Epoch[390/600] Iteration[022/030] Train loss: 0.0092
2023-02-06 14:39:55 | Train | Epoch[390/600] Iteration[023/030] Train loss: 0.0092
2023-02-06 14:39:56 | Train | Epoch[390/600] Iteration[024/030] Train loss: 0.0092
2023-02-06 14:39:56 | Train | Epoch[390/600] Iteration[025/030] Train loss: 0.0093
2023-02-06 14:39:56 | Train | Epoch[390/600] Iteration[026/030] Train loss: 0.0093
2023-02-06 14:39:56 | Train | Epoch[390/600] Iteration[027/030] Train loss: 0.0093
2023-02-06 14:39:57 | Train | Epoch[390/600] Iteration[028/030] Train loss: 0.0093
2023-02-06 14:39:57 | Train | Epoch[390/600] Iteration[029/030] Train loss: 0.0094
2023-02-06 14:39:57 | Train | Epoch[390/600] Iteration[030/030] Train loss: 0.0094
2023-02-06 14:39:57 | Valid | Epoch[390/600] Iteration[001/008] Valid loss: 0.1166
2023-02-06 14:39:57 | Valid | Epoch[390/600] Iteration[002/008] Valid loss: 0.0942
2023-02-06 14:39:57 | Valid | Epoch[390/600] Iteration[003/008] Valid loss: 0.0869
2023-02-06 14:39:57 | Valid | Epoch[390/600] Iteration[004/008] Valid loss: 0.0822
2023-02-06 14:39:57 | Valid | Epoch[390/600] Iteration[005/008] Valid loss: 0.0781
2023-02-06 14:39:57 | Valid | Epoch[390/600] Iteration[006/008] Valid loss: 0.0743
2023-02-06 14:39:58 | Valid | Epoch[390/600] Iteration[007/008] Valid loss: 0.0752
2023-02-06 14:39:58 | Valid | Epoch[390/600] Iteration[008/008] Valid loss: 0.0733
2023-02-06 14:39:58 | Valid | Epoch[390/600] MIou: 0.9137352753429552
2023-02-06 14:39:58 | Valid | Epoch[390/600] Pixel Accuracy: 0.9854927062988281
2023-02-06 14:39:58 | Valid | Epoch[390/600] Mean Pixel Accuracy: 0.9306884512528641
2023-02-06 14:39:58 | Stage | Epoch[390/600] Train loss:0.0094
2023-02-06 14:39:58 | Stage | Epoch[390/600] Valid loss:0.0733
2023-02-06 14:39:58 | Stage | Epoch[390/600] LR:0.01

2023-02-06 14:39:58 | Train | Epoch[391/600] Iteration[001/030] Train loss: 0.0084
2023-02-06 14:39:58 | Train | Epoch[391/600] Iteration[002/030] Train loss: 0.0096
2023-02-06 14:39:59 | Train | Epoch[391/600] Iteration[003/030] Train loss: 0.0097
2023-02-06 14:39:59 | Train | Epoch[391/600] Iteration[004/030] Train loss: 0.0094
2023-02-06 14:39:59 | Train | Epoch[391/600] Iteration[005/030] Train loss: 0.0093
2023-02-06 14:39:59 | Train | Epoch[391/600] Iteration[006/030] Train loss: 0.0099
2023-02-06 14:40:00 | Train | Epoch[391/600] Iteration[007/030] Train loss: 0.0097
2023-02-06 14:40:00 | Train | Epoch[391/600] Iteration[008/030] Train loss: 0.0097
2023-02-06 14:40:00 | Train | Epoch[391/600] Iteration[009/030] Train loss: 0.0097
2023-02-06 14:40:00 | Train | Epoch[391/600] Iteration[010/030] Train loss: 0.0097
2023-02-06 14:40:00 | Train | Epoch[391/600] Iteration[011/030] Train loss: 0.0097
2023-02-06 14:40:01 | Train | Epoch[391/600] Iteration[012/030] Train loss: 0.0097
2023-02-06 14:40:01 | Train | Epoch[391/600] Iteration[013/030] Train loss: 0.0097
2023-02-06 14:40:01 | Train | Epoch[391/600] Iteration[014/030] Train loss: 0.0097
2023-02-06 14:40:01 | Train | Epoch[391/600] Iteration[015/030] Train loss: 0.0096
2023-02-06 14:40:01 | Train | Epoch[391/600] Iteration[016/030] Train loss: 0.0097
2023-02-06 14:40:02 | Train | Epoch[391/600] Iteration[017/030] Train loss: 0.0097
2023-02-06 14:40:02 | Train | Epoch[391/600] Iteration[018/030] Train loss: 0.0097
2023-02-06 14:40:02 | Train | Epoch[391/600] Iteration[019/030] Train loss: 0.0096
2023-02-06 14:40:02 | Train | Epoch[391/600] Iteration[020/030] Train loss: 0.0095
2023-02-06 14:40:03 | Train | Epoch[391/600] Iteration[021/030] Train loss: 0.0095
2023-02-06 14:40:03 | Train | Epoch[391/600] Iteration[022/030] Train loss: 0.0095
2023-02-06 14:40:03 | Train | Epoch[391/600] Iteration[023/030] Train loss: 0.0096
2023-02-06 14:40:03 | Train | Epoch[391/600] Iteration[024/030] Train loss: 0.0096
2023-02-06 14:40:03 | Train | Epoch[391/600] Iteration[025/030] Train loss: 0.0096
2023-02-06 14:40:04 | Train | Epoch[391/600] Iteration[026/030] Train loss: 0.0096
2023-02-06 14:40:04 | Train | Epoch[391/600] Iteration[027/030] Train loss: 0.0095
2023-02-06 14:40:04 | Train | Epoch[391/600] Iteration[028/030] Train loss: 0.0096
2023-02-06 14:40:04 | Train | Epoch[391/600] Iteration[029/030] Train loss: 0.0096
2023-02-06 14:40:04 | Train | Epoch[391/600] Iteration[030/030] Train loss: 0.0096
2023-02-06 14:40:05 | Valid | Epoch[391/600] Iteration[001/008] Valid loss: 0.1154
2023-02-06 14:40:05 | Valid | Epoch[391/600] Iteration[002/008] Valid loss: 0.0981
2023-02-06 14:40:05 | Valid | Epoch[391/600] Iteration[003/008] Valid loss: 0.0986
2023-02-06 14:40:05 | Valid | Epoch[391/600] Iteration[004/008] Valid loss: 0.0966
2023-02-06 14:40:05 | Valid | Epoch[391/600] Iteration[005/008] Valid loss: 0.0987
2023-02-06 14:40:05 | Valid | Epoch[391/600] Iteration[006/008] Valid loss: 0.0953
2023-02-06 14:40:05 | Valid | Epoch[391/600] Iteration[007/008] Valid loss: 0.1027
2023-02-06 14:40:05 | Valid | Epoch[391/600] Iteration[008/008] Valid loss: 0.1014
2023-02-06 14:40:05 | Valid | Epoch[391/600] MIou: 0.9211638773847604
2023-02-06 14:40:05 | Valid | Epoch[391/600] Pixel Accuracy: 0.9865036010742188
2023-02-06 14:40:05 | Valid | Epoch[391/600] Mean Pixel Accuracy: 0.9455798882238506
2023-02-06 14:40:05 | Stage | Epoch[391/600] Train loss:0.0096
2023-02-06 14:40:05 | Stage | Epoch[391/600] Valid loss:0.1014
2023-02-06 14:40:05 | Stage | Epoch[391/600] LR:0.01

2023-02-06 14:40:06 | Train | Epoch[392/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:40:06 | Train | Epoch[392/600] Iteration[002/030] Train loss: 0.0087
2023-02-06 14:40:06 | Train | Epoch[392/600] Iteration[003/030] Train loss: 0.0090
2023-02-06 14:40:06 | Train | Epoch[392/600] Iteration[004/030] Train loss: 0.0094
2023-02-06 14:40:07 | Train | Epoch[392/600] Iteration[005/030] Train loss: 0.0094
2023-02-06 14:40:07 | Train | Epoch[392/600] Iteration[006/030] Train loss: 0.0096
2023-02-06 14:40:07 | Train | Epoch[392/600] Iteration[007/030] Train loss: 0.0094
2023-02-06 14:40:07 | Train | Epoch[392/600] Iteration[008/030] Train loss: 0.0093
2023-02-06 14:40:07 | Train | Epoch[392/600] Iteration[009/030] Train loss: 0.0093
2023-02-06 14:40:08 | Train | Epoch[392/600] Iteration[010/030] Train loss: 0.0093
2023-02-06 14:40:08 | Train | Epoch[392/600] Iteration[011/030] Train loss: 0.0094
2023-02-06 14:40:08 | Train | Epoch[392/600] Iteration[012/030] Train loss: 0.0095
2023-02-06 14:40:08 | Train | Epoch[392/600] Iteration[013/030] Train loss: 0.0095
2023-02-06 14:40:09 | Train | Epoch[392/600] Iteration[014/030] Train loss: 0.0094
2023-02-06 14:40:09 | Train | Epoch[392/600] Iteration[015/030] Train loss: 0.0092
2023-02-06 14:40:09 | Train | Epoch[392/600] Iteration[016/030] Train loss: 0.0092
2023-02-06 14:40:09 | Train | Epoch[392/600] Iteration[017/030] Train loss: 0.0092
2023-02-06 14:40:09 | Train | Epoch[392/600] Iteration[018/030] Train loss: 0.0091
2023-02-06 14:40:10 | Train | Epoch[392/600] Iteration[019/030] Train loss: 0.0090
2023-02-06 14:40:10 | Train | Epoch[392/600] Iteration[020/030] Train loss: 0.0090
2023-02-06 14:40:10 | Train | Epoch[392/600] Iteration[021/030] Train loss: 0.0090
2023-02-06 14:40:10 | Train | Epoch[392/600] Iteration[022/030] Train loss: 0.0090
2023-02-06 14:40:11 | Train | Epoch[392/600] Iteration[023/030] Train loss: 0.0093
2023-02-06 14:40:11 | Train | Epoch[392/600] Iteration[024/030] Train loss: 0.0093
2023-02-06 14:40:11 | Train | Epoch[392/600] Iteration[025/030] Train loss: 0.0093
2023-02-06 14:40:11 | Train | Epoch[392/600] Iteration[026/030] Train loss: 0.0093
2023-02-06 14:40:11 | Train | Epoch[392/600] Iteration[027/030] Train loss: 0.0093
2023-02-06 14:40:12 | Train | Epoch[392/600] Iteration[028/030] Train loss: 0.0093
2023-02-06 14:40:12 | Train | Epoch[392/600] Iteration[029/030] Train loss: 0.0093
2023-02-06 14:40:12 | Train | Epoch[392/600] Iteration[030/030] Train loss: 0.0092
2023-02-06 14:40:12 | Valid | Epoch[392/600] Iteration[001/008] Valid loss: 0.1571
2023-02-06 14:40:12 | Valid | Epoch[392/600] Iteration[002/008] Valid loss: 0.1279
2023-02-06 14:40:12 | Valid | Epoch[392/600] Iteration[003/008] Valid loss: 0.1209
2023-02-06 14:40:13 | Valid | Epoch[392/600] Iteration[004/008] Valid loss: 0.1145
2023-02-06 14:40:13 | Valid | Epoch[392/600] Iteration[005/008] Valid loss: 0.1135
2023-02-06 14:40:13 | Valid | Epoch[392/600] Iteration[006/008] Valid loss: 0.1098
2023-02-06 14:40:13 | Valid | Epoch[392/600] Iteration[007/008] Valid loss: 0.1192
2023-02-06 14:40:13 | Valid | Epoch[392/600] Iteration[008/008] Valid loss: 0.1201
2023-02-06 14:40:13 | Valid | Epoch[392/600] MIou: 0.9205577207292767
2023-02-06 14:40:13 | Valid | Epoch[392/600] Pixel Accuracy: 0.986230214436849
2023-02-06 14:40:13 | Valid | Epoch[392/600] Mean Pixel Accuracy: 0.9506034480221512
2023-02-06 14:40:13 | Stage | Epoch[392/600] Train loss:0.0092
2023-02-06 14:40:13 | Stage | Epoch[392/600] Valid loss:0.1201
2023-02-06 14:40:13 | Stage | Epoch[392/600] LR:0.01

2023-02-06 14:40:13 | Train | Epoch[393/600] Iteration[001/030] Train loss: 0.0087
2023-02-06 14:40:14 | Train | Epoch[393/600] Iteration[002/030] Train loss: 0.0087
2023-02-06 14:40:14 | Train | Epoch[393/600] Iteration[003/030] Train loss: 0.0092
2023-02-06 14:40:14 | Train | Epoch[393/600] Iteration[004/030] Train loss: 0.0093
2023-02-06 14:40:14 | Train | Epoch[393/600] Iteration[005/030] Train loss: 0.0096
2023-02-06 14:40:14 | Train | Epoch[393/600] Iteration[006/030] Train loss: 0.0096
2023-02-06 14:40:15 | Train | Epoch[393/600] Iteration[007/030] Train loss: 0.0096
2023-02-06 14:40:15 | Train | Epoch[393/600] Iteration[008/030] Train loss: 0.0095
2023-02-06 14:40:15 | Train | Epoch[393/600] Iteration[009/030] Train loss: 0.0094
2023-02-06 14:40:15 | Train | Epoch[393/600] Iteration[010/030] Train loss: 0.0094
2023-02-06 14:40:15 | Train | Epoch[393/600] Iteration[011/030] Train loss: 0.0093
2023-02-06 14:40:16 | Train | Epoch[393/600] Iteration[012/030] Train loss: 0.0093
2023-02-06 14:40:16 | Train | Epoch[393/600] Iteration[013/030] Train loss: 0.0093
2023-02-06 14:40:16 | Train | Epoch[393/600] Iteration[014/030] Train loss: 0.0093
2023-02-06 14:40:16 | Train | Epoch[393/600] Iteration[015/030] Train loss: 0.0094
2023-02-06 14:40:17 | Train | Epoch[393/600] Iteration[016/030] Train loss: 0.0094
2023-02-06 14:40:17 | Train | Epoch[393/600] Iteration[017/030] Train loss: 0.0094
2023-02-06 14:40:17 | Train | Epoch[393/600] Iteration[018/030] Train loss: 0.0094
2023-02-06 14:40:17 | Train | Epoch[393/600] Iteration[019/030] Train loss: 0.0095
2023-02-06 14:40:17 | Train | Epoch[393/600] Iteration[020/030] Train loss: 0.0094
2023-02-06 14:40:18 | Train | Epoch[393/600] Iteration[021/030] Train loss: 0.0094
2023-02-06 14:40:18 | Train | Epoch[393/600] Iteration[022/030] Train loss: 0.0094
2023-02-06 14:40:18 | Train | Epoch[393/600] Iteration[023/030] Train loss: 0.0094
2023-02-06 14:40:18 | Train | Epoch[393/600] Iteration[024/030] Train loss: 0.0094
2023-02-06 14:40:19 | Train | Epoch[393/600] Iteration[025/030] Train loss: 0.0095
2023-02-06 14:40:19 | Train | Epoch[393/600] Iteration[026/030] Train loss: 0.0095
2023-02-06 14:40:19 | Train | Epoch[393/600] Iteration[027/030] Train loss: 0.0094
2023-02-06 14:40:19 | Train | Epoch[393/600] Iteration[028/030] Train loss: 0.0094
2023-02-06 14:40:19 | Train | Epoch[393/600] Iteration[029/030] Train loss: 0.0093
2023-02-06 14:40:20 | Train | Epoch[393/600] Iteration[030/030] Train loss: 0.0093
2023-02-06 14:40:20 | Valid | Epoch[393/600] Iteration[001/008] Valid loss: 0.7410
2023-02-06 14:40:20 | Valid | Epoch[393/600] Iteration[002/008] Valid loss: 0.6772
2023-02-06 14:40:20 | Valid | Epoch[393/600] Iteration[003/008] Valid loss: 0.6876
2023-02-06 14:40:20 | Valid | Epoch[393/600] Iteration[004/008] Valid loss: 0.6789
2023-02-06 14:40:20 | Valid | Epoch[393/600] Iteration[005/008] Valid loss: 0.7101
2023-02-06 14:40:20 | Valid | Epoch[393/600] Iteration[006/008] Valid loss: 0.6859
2023-02-06 14:40:20 | Valid | Epoch[393/600] Iteration[007/008] Valid loss: 0.7355
2023-02-06 14:40:20 | Valid | Epoch[393/600] Iteration[008/008] Valid loss: 0.7746
2023-02-06 14:40:20 | Valid | Epoch[393/600] MIou: 0.8871823884678232
2023-02-06 14:40:20 | Valid | Epoch[393/600] Pixel Accuracy: 0.9776382446289062
2023-02-06 14:40:20 | Valid | Epoch[393/600] Mean Pixel Accuracy: 0.980335057173698
2023-02-06 14:40:20 | Stage | Epoch[393/600] Train loss:0.0093
2023-02-06 14:40:20 | Stage | Epoch[393/600] Valid loss:0.7746
2023-02-06 14:40:20 | Stage | Epoch[393/600] LR:0.01

2023-02-06 14:40:21 | Train | Epoch[394/600] Iteration[001/030] Train loss: 0.0093
2023-02-06 14:40:21 | Train | Epoch[394/600] Iteration[002/030] Train loss: 0.0100
2023-02-06 14:40:21 | Train | Epoch[394/600] Iteration[003/030] Train loss: 0.0096
2023-02-06 14:40:21 | Train | Epoch[394/600] Iteration[004/030] Train loss: 0.0094
2023-02-06 14:40:22 | Train | Epoch[394/600] Iteration[005/030] Train loss: 0.0094
2023-02-06 14:40:22 | Train | Epoch[394/600] Iteration[006/030] Train loss: 0.0093
2023-02-06 14:40:22 | Train | Epoch[394/600] Iteration[007/030] Train loss: 0.0093
2023-02-06 14:40:22 | Train | Epoch[394/600] Iteration[008/030] Train loss: 0.0092
2023-02-06 14:40:23 | Train | Epoch[394/600] Iteration[009/030] Train loss: 0.0093
2023-02-06 14:40:23 | Train | Epoch[394/600] Iteration[010/030] Train loss: 0.0092
2023-02-06 14:40:23 | Train | Epoch[394/600] Iteration[011/030] Train loss: 0.0093
2023-02-06 14:40:23 | Train | Epoch[394/600] Iteration[012/030] Train loss: 0.0093
2023-02-06 14:40:23 | Train | Epoch[394/600] Iteration[013/030] Train loss: 0.0094
2023-02-06 14:40:24 | Train | Epoch[394/600] Iteration[014/030] Train loss: 0.0094
2023-02-06 14:40:24 | Train | Epoch[394/600] Iteration[015/030] Train loss: 0.0094
2023-02-06 14:40:24 | Train | Epoch[394/600] Iteration[016/030] Train loss: 0.0093
2023-02-06 14:40:24 | Train | Epoch[394/600] Iteration[017/030] Train loss: 0.0093
2023-02-06 14:40:25 | Train | Epoch[394/600] Iteration[018/030] Train loss: 0.0092
2023-02-06 14:40:25 | Train | Epoch[394/600] Iteration[019/030] Train loss: 0.0093
2023-02-06 14:40:25 | Train | Epoch[394/600] Iteration[020/030] Train loss: 0.0092
2023-02-06 14:40:25 | Train | Epoch[394/600] Iteration[021/030] Train loss: 0.0092
2023-02-06 14:40:25 | Train | Epoch[394/600] Iteration[022/030] Train loss: 0.0092
2023-02-06 14:40:26 | Train | Epoch[394/600] Iteration[023/030] Train loss: 0.0094
2023-02-06 14:40:26 | Train | Epoch[394/600] Iteration[024/030] Train loss: 0.0095
2023-02-06 14:40:26 | Train | Epoch[394/600] Iteration[025/030] Train loss: 0.0095
2023-02-06 14:40:26 | Train | Epoch[394/600] Iteration[026/030] Train loss: 0.0095
2023-02-06 14:40:27 | Train | Epoch[394/600] Iteration[027/030] Train loss: 0.0096
2023-02-06 14:40:27 | Train | Epoch[394/600] Iteration[028/030] Train loss: 0.0095
2023-02-06 14:40:27 | Train | Epoch[394/600] Iteration[029/030] Train loss: 0.0096
2023-02-06 14:40:27 | Train | Epoch[394/600] Iteration[030/030] Train loss: 0.0096
2023-02-06 14:40:27 | Valid | Epoch[394/600] Iteration[001/008] Valid loss: 0.1515
2023-02-06 14:40:27 | Valid | Epoch[394/600] Iteration[002/008] Valid loss: 0.1119
2023-02-06 14:40:27 | Valid | Epoch[394/600] Iteration[003/008] Valid loss: 0.1099
2023-02-06 14:40:28 | Valid | Epoch[394/600] Iteration[004/008] Valid loss: 0.1049
2023-02-06 14:40:28 | Valid | Epoch[394/600] Iteration[005/008] Valid loss: 0.1075
2023-02-06 14:40:28 | Valid | Epoch[394/600] Iteration[006/008] Valid loss: 0.1039
2023-02-06 14:40:28 | Valid | Epoch[394/600] Iteration[007/008] Valid loss: 0.1113
2023-02-06 14:40:28 | Valid | Epoch[394/600] Iteration[008/008] Valid loss: 0.1099
2023-02-06 14:40:28 | Valid | Epoch[394/600] MIou: 0.925242356266833
2023-02-06 14:40:28 | Valid | Epoch[394/600] Pixel Accuracy: 0.9870402018229166
2023-02-06 14:40:28 | Valid | Epoch[394/600] Mean Pixel Accuracy: 0.9552143414180969
2023-02-06 14:40:28 | Stage | Epoch[394/600] Train loss:0.0096
2023-02-06 14:40:28 | Stage | Epoch[394/600] Valid loss:0.1099
2023-02-06 14:40:28 | Stage | Epoch[394/600] LR:0.01

2023-02-06 14:40:28 | Train | Epoch[395/600] Iteration[001/030] Train loss: 0.0088
2023-02-06 14:40:28 | Train | Epoch[395/600] Iteration[002/030] Train loss: 0.0086
2023-02-06 14:40:29 | Train | Epoch[395/600] Iteration[003/030] Train loss: 0.0089
2023-02-06 14:40:29 | Train | Epoch[395/600] Iteration[004/030] Train loss: 0.0089
2023-02-06 14:40:29 | Train | Epoch[395/600] Iteration[005/030] Train loss: 0.0089
2023-02-06 14:40:29 | Train | Epoch[395/600] Iteration[006/030] Train loss: 0.0089
2023-02-06 14:40:30 | Train | Epoch[395/600] Iteration[007/030] Train loss: 0.0089
2023-02-06 14:40:30 | Train | Epoch[395/600] Iteration[008/030] Train loss: 0.0090
2023-02-06 14:40:30 | Train | Epoch[395/600] Iteration[009/030] Train loss: 0.0090
2023-02-06 14:40:30 | Train | Epoch[395/600] Iteration[010/030] Train loss: 0.0091
2023-02-06 14:40:30 | Train | Epoch[395/600] Iteration[011/030] Train loss: 0.0090
2023-02-06 14:40:31 | Train | Epoch[395/600] Iteration[012/030] Train loss: 0.0090
2023-02-06 14:40:31 | Train | Epoch[395/600] Iteration[013/030] Train loss: 0.0090
2023-02-06 14:40:31 | Train | Epoch[395/600] Iteration[014/030] Train loss: 0.0089
2023-02-06 14:40:31 | Train | Epoch[395/600] Iteration[015/030] Train loss: 0.0089
2023-02-06 14:40:32 | Train | Epoch[395/600] Iteration[016/030] Train loss: 0.0090
2023-02-06 14:40:32 | Train | Epoch[395/600] Iteration[017/030] Train loss: 0.0090
2023-02-06 14:40:32 | Train | Epoch[395/600] Iteration[018/030] Train loss: 0.0091
2023-02-06 14:40:32 | Train | Epoch[395/600] Iteration[019/030] Train loss: 0.0091
2023-02-06 14:40:32 | Train | Epoch[395/600] Iteration[020/030] Train loss: 0.0092
2023-02-06 14:40:33 | Train | Epoch[395/600] Iteration[021/030] Train loss: 0.0093
2023-02-06 14:40:33 | Train | Epoch[395/600] Iteration[022/030] Train loss: 0.0094
2023-02-06 14:40:33 | Train | Epoch[395/600] Iteration[023/030] Train loss: 0.0094
2023-02-06 14:40:33 | Train | Epoch[395/600] Iteration[024/030] Train loss: 0.0093
2023-02-06 14:40:34 | Train | Epoch[395/600] Iteration[025/030] Train loss: 0.0094
2023-02-06 14:40:34 | Train | Epoch[395/600] Iteration[026/030] Train loss: 0.0094
2023-02-06 14:40:34 | Train | Epoch[395/600] Iteration[027/030] Train loss: 0.0094
2023-02-06 14:40:34 | Train | Epoch[395/600] Iteration[028/030] Train loss: 0.0094
2023-02-06 14:40:34 | Train | Epoch[395/600] Iteration[029/030] Train loss: 0.0094
2023-02-06 14:40:34 | Train | Epoch[395/600] Iteration[030/030] Train loss: 0.0094
2023-02-06 14:40:35 | Valid | Epoch[395/600] Iteration[001/008] Valid loss: 0.1347
2023-02-06 14:40:35 | Valid | Epoch[395/600] Iteration[002/008] Valid loss: 0.1131
2023-02-06 14:40:35 | Valid | Epoch[395/600] Iteration[003/008] Valid loss: 0.1104
2023-02-06 14:40:35 | Valid | Epoch[395/600] Iteration[004/008] Valid loss: 0.1009
2023-02-06 14:40:35 | Valid | Epoch[395/600] Iteration[005/008] Valid loss: 0.0962
2023-02-06 14:40:35 | Valid | Epoch[395/600] Iteration[006/008] Valid loss: 0.0944
2023-02-06 14:40:35 | Valid | Epoch[395/600] Iteration[007/008] Valid loss: 0.1005
2023-02-06 14:40:35 | Valid | Epoch[395/600] Iteration[008/008] Valid loss: 0.0993
2023-02-06 14:40:35 | Valid | Epoch[395/600] MIou: 0.9203370455835731
2023-02-06 14:40:35 | Valid | Epoch[395/600] Pixel Accuracy: 0.9863090515136719
2023-02-06 14:40:35 | Valid | Epoch[395/600] Mean Pixel Accuracy: 0.9465318142305532
2023-02-06 14:40:35 | Stage | Epoch[395/600] Train loss:0.0094
2023-02-06 14:40:35 | Stage | Epoch[395/600] Valid loss:0.0993
2023-02-06 14:40:35 | Stage | Epoch[395/600] LR:0.01

2023-02-06 14:40:36 | Train | Epoch[396/600] Iteration[001/030] Train loss: 0.0094
2023-02-06 14:40:36 | Train | Epoch[396/600] Iteration[002/030] Train loss: 0.0093
2023-02-06 14:40:36 | Train | Epoch[396/600] Iteration[003/030] Train loss: 0.0105
2023-02-06 14:40:37 | Train | Epoch[396/600] Iteration[004/030] Train loss: 0.0104
2023-02-06 14:40:37 | Train | Epoch[396/600] Iteration[005/030] Train loss: 0.0102
2023-02-06 14:40:37 | Train | Epoch[396/600] Iteration[006/030] Train loss: 0.0101
2023-02-06 14:40:37 | Train | Epoch[396/600] Iteration[007/030] Train loss: 0.0100
2023-02-06 14:40:37 | Train | Epoch[396/600] Iteration[008/030] Train loss: 0.0098
2023-02-06 14:40:38 | Train | Epoch[396/600] Iteration[009/030] Train loss: 0.0101
2023-02-06 14:40:38 | Train | Epoch[396/600] Iteration[010/030] Train loss: 0.0102
2023-02-06 14:40:38 | Train | Epoch[396/600] Iteration[011/030] Train loss: 0.0102
2023-02-06 14:40:38 | Train | Epoch[396/600] Iteration[012/030] Train loss: 0.0101
2023-02-06 14:40:38 | Train | Epoch[396/600] Iteration[013/030] Train loss: 0.0100
2023-02-06 14:40:39 | Train | Epoch[396/600] Iteration[014/030] Train loss: 0.0100
2023-02-06 14:40:39 | Train | Epoch[396/600] Iteration[015/030] Train loss: 0.0100
2023-02-06 14:40:39 | Train | Epoch[396/600] Iteration[016/030] Train loss: 0.0100
2023-02-06 14:40:39 | Train | Epoch[396/600] Iteration[017/030] Train loss: 0.0107
2023-02-06 14:40:40 | Train | Epoch[396/600] Iteration[018/030] Train loss: 0.0106
2023-02-06 14:40:40 | Train | Epoch[396/600] Iteration[019/030] Train loss: 0.0105
2023-02-06 14:40:40 | Train | Epoch[396/600] Iteration[020/030] Train loss: 0.0105
2023-02-06 14:40:40 | Train | Epoch[396/600] Iteration[021/030] Train loss: 0.0105
2023-02-06 14:40:40 | Train | Epoch[396/600] Iteration[022/030] Train loss: 0.0104
2023-02-06 14:40:41 | Train | Epoch[396/600] Iteration[023/030] Train loss: 0.0105
2023-02-06 14:40:41 | Train | Epoch[396/600] Iteration[024/030] Train loss: 0.0105
2023-02-06 14:40:41 | Train | Epoch[396/600] Iteration[025/030] Train loss: 0.0105
2023-02-06 14:40:41 | Train | Epoch[396/600] Iteration[026/030] Train loss: 0.0105
2023-02-06 14:40:42 | Train | Epoch[396/600] Iteration[027/030] Train loss: 0.0105
2023-02-06 14:40:42 | Train | Epoch[396/600] Iteration[028/030] Train loss: 0.0104
2023-02-06 14:40:42 | Train | Epoch[396/600] Iteration[029/030] Train loss: 0.0104
2023-02-06 14:40:42 | Train | Epoch[396/600] Iteration[030/030] Train loss: 0.0104
2023-02-06 14:40:42 | Valid | Epoch[396/600] Iteration[001/008] Valid loss: 0.6155
2023-02-06 14:40:43 | Valid | Epoch[396/600] Iteration[002/008] Valid loss: 0.5789
2023-02-06 14:40:43 | Valid | Epoch[396/600] Iteration[003/008] Valid loss: 0.5942
2023-02-06 14:40:43 | Valid | Epoch[396/600] Iteration[004/008] Valid loss: 0.5797
2023-02-06 14:40:43 | Valid | Epoch[396/600] Iteration[005/008] Valid loss: 0.6055
2023-02-06 14:40:43 | Valid | Epoch[396/600] Iteration[006/008] Valid loss: 0.6179
2023-02-06 14:40:43 | Valid | Epoch[396/600] Iteration[007/008] Valid loss: 0.6624
2023-02-06 14:40:43 | Valid | Epoch[396/600] Iteration[008/008] Valid loss: 0.6700
2023-02-06 14:40:43 | Valid | Epoch[396/600] MIou: 0.8799668084259507
2023-02-06 14:40:43 | Valid | Epoch[396/600] Pixel Accuracy: 0.9759190877278646
2023-02-06 14:40:43 | Valid | Epoch[396/600] Mean Pixel Accuracy: 0.9783693193071722
2023-02-06 14:40:43 | Stage | Epoch[396/600] Train loss:0.0104
2023-02-06 14:40:43 | Stage | Epoch[396/600] Valid loss:0.6700
2023-02-06 14:40:43 | Stage | Epoch[396/600] LR:0.01

2023-02-06 14:40:43 | Train | Epoch[397/600] Iteration[001/030] Train loss: 0.0099
2023-02-06 14:40:44 | Train | Epoch[397/600] Iteration[002/030] Train loss: 0.0123
2023-02-06 14:40:44 | Train | Epoch[397/600] Iteration[003/030] Train loss: 0.0112
2023-02-06 14:40:44 | Train | Epoch[397/600] Iteration[004/030] Train loss: 0.0105
2023-02-06 14:40:44 | Train | Epoch[397/600] Iteration[005/030] Train loss: 0.0107
2023-02-06 14:40:44 | Train | Epoch[397/600] Iteration[006/030] Train loss: 0.0106
2023-02-06 14:40:45 | Train | Epoch[397/600] Iteration[007/030] Train loss: 0.0104
2023-02-06 14:40:45 | Train | Epoch[397/600] Iteration[008/030] Train loss: 0.0102
2023-02-06 14:40:45 | Train | Epoch[397/600] Iteration[009/030] Train loss: 0.0101
2023-02-06 14:40:45 | Train | Epoch[397/600] Iteration[010/030] Train loss: 0.0101
2023-02-06 14:40:46 | Train | Epoch[397/600] Iteration[011/030] Train loss: 0.0100
2023-02-06 14:40:46 | Train | Epoch[397/600] Iteration[012/030] Train loss: 0.0099
2023-02-06 14:40:46 | Train | Epoch[397/600] Iteration[013/030] Train loss: 0.0099
2023-02-06 14:40:46 | Train | Epoch[397/600] Iteration[014/030] Train loss: 0.0100
2023-02-06 14:40:46 | Train | Epoch[397/600] Iteration[015/030] Train loss: 0.0101
2023-02-06 14:40:47 | Train | Epoch[397/600] Iteration[016/030] Train loss: 0.0101
2023-02-06 14:40:47 | Train | Epoch[397/600] Iteration[017/030] Train loss: 0.0100
2023-02-06 14:40:47 | Train | Epoch[397/600] Iteration[018/030] Train loss: 0.0100
2023-02-06 14:40:47 | Train | Epoch[397/600] Iteration[019/030] Train loss: 0.0099
2023-02-06 14:40:48 | Train | Epoch[397/600] Iteration[020/030] Train loss: 0.0099
2023-02-06 14:40:48 | Train | Epoch[397/600] Iteration[021/030] Train loss: 0.0099
2023-02-06 14:40:48 | Train | Epoch[397/600] Iteration[022/030] Train loss: 0.0099
2023-02-06 14:40:48 | Train | Epoch[397/600] Iteration[023/030] Train loss: 0.0099
2023-02-06 14:40:48 | Train | Epoch[397/600] Iteration[024/030] Train loss: 0.0100
2023-02-06 14:40:49 | Train | Epoch[397/600] Iteration[025/030] Train loss: 0.0100
2023-02-06 14:40:49 | Train | Epoch[397/600] Iteration[026/030] Train loss: 0.0100
2023-02-06 14:40:49 | Train | Epoch[397/600] Iteration[027/030] Train loss: 0.0099
2023-02-06 14:40:49 | Train | Epoch[397/600] Iteration[028/030] Train loss: 0.0100
2023-02-06 14:40:49 | Train | Epoch[397/600] Iteration[029/030] Train loss: 0.0100
2023-02-06 14:40:50 | Train | Epoch[397/600] Iteration[030/030] Train loss: 0.0100
2023-02-06 14:40:50 | Valid | Epoch[397/600] Iteration[001/008] Valid loss: 0.0991
2023-02-06 14:40:50 | Valid | Epoch[397/600] Iteration[002/008] Valid loss: 0.0788
2023-02-06 14:40:50 | Valid | Epoch[397/600] Iteration[003/008] Valid loss: 0.0738
2023-02-06 14:40:50 | Valid | Epoch[397/600] Iteration[004/008] Valid loss: 0.0710
2023-02-06 14:40:50 | Valid | Epoch[397/600] Iteration[005/008] Valid loss: 0.0688
2023-02-06 14:40:50 | Valid | Epoch[397/600] Iteration[006/008] Valid loss: 0.0683
2023-02-06 14:40:50 | Valid | Epoch[397/600] Iteration[007/008] Valid loss: 0.0688
2023-02-06 14:40:50 | Valid | Epoch[397/600] Iteration[008/008] Valid loss: 0.0670
2023-02-06 14:40:50 | Valid | Epoch[397/600] MIou: 0.8973606028929257
2023-02-06 14:40:50 | Valid | Epoch[397/600] Pixel Accuracy: 0.982934315999349
2023-02-06 14:40:50 | Valid | Epoch[397/600] Mean Pixel Accuracy: 0.910603221756976
2023-02-06 14:40:50 | Stage | Epoch[397/600] Train loss:0.0100
2023-02-06 14:40:50 | Stage | Epoch[397/600] Valid loss:0.0670
2023-02-06 14:40:50 | Stage | Epoch[397/600] LR:0.01

2023-02-06 14:40:51 | Train | Epoch[398/600] Iteration[001/030] Train loss: 0.0115
2023-02-06 14:40:51 | Train | Epoch[398/600] Iteration[002/030] Train loss: 0.0122
2023-02-06 14:40:51 | Train | Epoch[398/600] Iteration[003/030] Train loss: 0.0114
2023-02-06 14:40:52 | Train | Epoch[398/600] Iteration[004/030] Train loss: 0.0112
2023-02-06 14:40:52 | Train | Epoch[398/600] Iteration[005/030] Train loss: 0.0110
2023-02-06 14:40:52 | Train | Epoch[398/600] Iteration[006/030] Train loss: 0.0107
2023-02-06 14:40:52 | Train | Epoch[398/600] Iteration[007/030] Train loss: 0.0105
2023-02-06 14:40:52 | Train | Epoch[398/600] Iteration[008/030] Train loss: 0.0104
2023-02-06 14:40:53 | Train | Epoch[398/600] Iteration[009/030] Train loss: 0.0102
2023-02-06 14:40:53 | Train | Epoch[398/600] Iteration[010/030] Train loss: 0.0102
2023-02-06 14:40:53 | Train | Epoch[398/600] Iteration[011/030] Train loss: 0.0100
2023-02-06 14:40:53 | Train | Epoch[398/600] Iteration[012/030] Train loss: 0.0099
2023-02-06 14:40:54 | Train | Epoch[398/600] Iteration[013/030] Train loss: 0.0100
2023-02-06 14:40:54 | Train | Epoch[398/600] Iteration[014/030] Train loss: 0.0098
2023-02-06 14:40:54 | Train | Epoch[398/600] Iteration[015/030] Train loss: 0.0098
2023-02-06 14:40:54 | Train | Epoch[398/600] Iteration[016/030] Train loss: 0.0098
2023-02-06 14:40:54 | Train | Epoch[398/600] Iteration[017/030] Train loss: 0.0097
2023-02-06 14:40:55 | Train | Epoch[398/600] Iteration[018/030] Train loss: 0.0097
2023-02-06 14:40:55 | Train | Epoch[398/600] Iteration[019/030] Train loss: 0.0097
2023-02-06 14:40:55 | Train | Epoch[398/600] Iteration[020/030] Train loss: 0.0098
2023-02-06 14:40:55 | Train | Epoch[398/600] Iteration[021/030] Train loss: 0.0097
2023-02-06 14:40:56 | Train | Epoch[398/600] Iteration[022/030] Train loss: 0.0099
2023-02-06 14:40:56 | Train | Epoch[398/600] Iteration[023/030] Train loss: 0.0099
2023-02-06 14:40:56 | Train | Epoch[398/600] Iteration[024/030] Train loss: 0.0099
2023-02-06 14:40:56 | Train | Epoch[398/600] Iteration[025/030] Train loss: 0.0100
2023-02-06 14:40:56 | Train | Epoch[398/600] Iteration[026/030] Train loss: 0.0100
2023-02-06 14:40:57 | Train | Epoch[398/600] Iteration[027/030] Train loss: 0.0100
2023-02-06 14:40:57 | Train | Epoch[398/600] Iteration[028/030] Train loss: 0.0099
2023-02-06 14:40:57 | Train | Epoch[398/600] Iteration[029/030] Train loss: 0.0099
2023-02-06 14:40:57 | Train | Epoch[398/600] Iteration[030/030] Train loss: 0.0099
2023-02-06 14:40:57 | Valid | Epoch[398/600] Iteration[001/008] Valid loss: 0.8514
2023-02-06 14:40:58 | Valid | Epoch[398/600] Iteration[002/008] Valid loss: 0.8024
2023-02-06 14:40:58 | Valid | Epoch[398/600] Iteration[003/008] Valid loss: 0.8285
2023-02-06 14:40:58 | Valid | Epoch[398/600] Iteration[004/008] Valid loss: 0.8191
2023-02-06 14:40:58 | Valid | Epoch[398/600] Iteration[005/008] Valid loss: 0.8501
2023-02-06 14:40:58 | Valid | Epoch[398/600] Iteration[006/008] Valid loss: 0.8365
2023-02-06 14:40:58 | Valid | Epoch[398/600] Iteration[007/008] Valid loss: 0.8849
2023-02-06 14:40:58 | Valid | Epoch[398/600] Iteration[008/008] Valid loss: 0.9287
2023-02-06 14:40:58 | Valid | Epoch[398/600] MIou: 0.8727095190936376
2023-02-06 14:40:58 | Valid | Epoch[398/600] Pixel Accuracy: 0.9739799499511719
2023-02-06 14:40:58 | Valid | Epoch[398/600] Mean Pixel Accuracy: 0.9796494609423454
2023-02-06 14:40:58 | Stage | Epoch[398/600] Train loss:0.0099
2023-02-06 14:40:58 | Stage | Epoch[398/600] Valid loss:0.9287
2023-02-06 14:40:58 | Stage | Epoch[398/600] LR:0.01

2023-02-06 14:40:58 | Train | Epoch[399/600] Iteration[001/030] Train loss: 0.0100
2023-02-06 14:40:59 | Train | Epoch[399/600] Iteration[002/030] Train loss: 0.0101
2023-02-06 14:40:59 | Train | Epoch[399/600] Iteration[003/030] Train loss: 0.0095
2023-02-06 14:40:59 | Train | Epoch[399/600] Iteration[004/030] Train loss: 0.0093
2023-02-06 14:40:59 | Train | Epoch[399/600] Iteration[005/030] Train loss: 0.0092
2023-02-06 14:41:00 | Train | Epoch[399/600] Iteration[006/030] Train loss: 0.0091
2023-02-06 14:41:00 | Train | Epoch[399/600] Iteration[007/030] Train loss: 0.0091
2023-02-06 14:41:00 | Train | Epoch[399/600] Iteration[008/030] Train loss: 0.0091
2023-02-06 14:41:00 | Train | Epoch[399/600] Iteration[009/030] Train loss: 0.0091
2023-02-06 14:41:00 | Train | Epoch[399/600] Iteration[010/030] Train loss: 0.0091
2023-02-06 14:41:01 | Train | Epoch[399/600] Iteration[011/030] Train loss: 0.0092
2023-02-06 14:41:01 | Train | Epoch[399/600] Iteration[012/030] Train loss: 0.0090
2023-02-06 14:41:01 | Train | Epoch[399/600] Iteration[013/030] Train loss: 0.0090
2023-02-06 14:41:01 | Train | Epoch[399/600] Iteration[014/030] Train loss: 0.0090
2023-02-06 14:41:01 | Train | Epoch[399/600] Iteration[015/030] Train loss: 0.0089
2023-02-06 14:41:02 | Train | Epoch[399/600] Iteration[016/030] Train loss: 0.0090
2023-02-06 14:41:02 | Train | Epoch[399/600] Iteration[017/030] Train loss: 0.0091
2023-02-06 14:41:02 | Train | Epoch[399/600] Iteration[018/030] Train loss: 0.0091
2023-02-06 14:41:02 | Train | Epoch[399/600] Iteration[019/030] Train loss: 0.0091
2023-02-06 14:41:03 | Train | Epoch[399/600] Iteration[020/030] Train loss: 0.0091
2023-02-06 14:41:03 | Train | Epoch[399/600] Iteration[021/030] Train loss: 0.0092
2023-02-06 14:41:03 | Train | Epoch[399/600] Iteration[022/030] Train loss: 0.0092
2023-02-06 14:41:03 | Train | Epoch[399/600] Iteration[023/030] Train loss: 0.0092
2023-02-06 14:41:03 | Train | Epoch[399/600] Iteration[024/030] Train loss: 0.0093
2023-02-06 14:41:04 | Train | Epoch[399/600] Iteration[025/030] Train loss: 0.0093
2023-02-06 14:41:04 | Train | Epoch[399/600] Iteration[026/030] Train loss: 0.0093
2023-02-06 14:41:04 | Train | Epoch[399/600] Iteration[027/030] Train loss: 0.0093
2023-02-06 14:41:04 | Train | Epoch[399/600] Iteration[028/030] Train loss: 0.0092
2023-02-06 14:41:05 | Train | Epoch[399/600] Iteration[029/030] Train loss: 0.0092
2023-02-06 14:41:05 | Train | Epoch[399/600] Iteration[030/030] Train loss: 0.0092
2023-02-06 14:41:05 | Valid | Epoch[399/600] Iteration[001/008] Valid loss: 0.1254
2023-02-06 14:41:05 | Valid | Epoch[399/600] Iteration[002/008] Valid loss: 0.1284
2023-02-06 14:41:05 | Valid | Epoch[399/600] Iteration[003/008] Valid loss: 0.1329
2023-02-06 14:41:05 | Valid | Epoch[399/600] Iteration[004/008] Valid loss: 0.1340
2023-02-06 14:41:05 | Valid | Epoch[399/600] Iteration[005/008] Valid loss: 0.1350
2023-02-06 14:41:05 | Valid | Epoch[399/600] Iteration[006/008] Valid loss: 0.1304
2023-02-06 14:41:05 | Valid | Epoch[399/600] Iteration[007/008] Valid loss: 0.1243
2023-02-06 14:41:05 | Valid | Epoch[399/600] Iteration[008/008] Valid loss: 0.1263
2023-02-06 14:41:05 | Valid | Epoch[399/600] MIou: 0.7526938452835865
2023-02-06 14:41:05 | Valid | Epoch[399/600] Pixel Accuracy: 0.9591712951660156
2023-02-06 14:41:05 | Valid | Epoch[399/600] Mean Pixel Accuracy: 0.7743720524449871
2023-02-06 14:41:05 | Stage | Epoch[399/600] Train loss:0.0092
2023-02-06 14:41:05 | Stage | Epoch[399/600] Valid loss:0.1263
2023-02-06 14:41:05 | Stage | Epoch[399/600] LR:0.01

2023-02-06 14:41:06 | Train | Epoch[400/600] Iteration[001/030] Train loss: 0.0083
2023-02-06 14:41:06 | Train | Epoch[400/600] Iteration[002/030] Train loss: 0.0086
2023-02-06 14:41:06 | Train | Epoch[400/600] Iteration[003/030] Train loss: 0.0087
2023-02-06 14:41:07 | Train | Epoch[400/600] Iteration[004/030] Train loss: 0.0089
2023-02-06 14:41:07 | Train | Epoch[400/600] Iteration[005/030] Train loss: 0.0088
2023-02-06 14:41:07 | Train | Epoch[400/600] Iteration[006/030] Train loss: 0.0086
2023-02-06 14:41:07 | Train | Epoch[400/600] Iteration[007/030] Train loss: 0.0088
2023-02-06 14:41:07 | Train | Epoch[400/600] Iteration[008/030] Train loss: 0.0087
2023-02-06 14:41:08 | Train | Epoch[400/600] Iteration[009/030] Train loss: 0.0088
2023-02-06 14:41:08 | Train | Epoch[400/600] Iteration[010/030] Train loss: 0.0089
2023-02-06 14:41:08 | Train | Epoch[400/600] Iteration[011/030] Train loss: 0.0089
2023-02-06 14:41:08 | Train | Epoch[400/600] Iteration[012/030] Train loss: 0.0091
2023-02-06 14:41:09 | Train | Epoch[400/600] Iteration[013/030] Train loss: 0.0090
2023-02-06 14:41:09 | Train | Epoch[400/600] Iteration[014/030] Train loss: 0.0089
2023-02-06 14:41:09 | Train | Epoch[400/600] Iteration[015/030] Train loss: 0.0090
2023-02-06 14:41:09 | Train | Epoch[400/600] Iteration[016/030] Train loss: 0.0090
2023-02-06 14:41:09 | Train | Epoch[400/600] Iteration[017/030] Train loss: 0.0090
2023-02-06 14:41:10 | Train | Epoch[400/600] Iteration[018/030] Train loss: 0.0090
2023-02-06 14:41:10 | Train | Epoch[400/600] Iteration[019/030] Train loss: 0.0090
2023-02-06 14:41:10 | Train | Epoch[400/600] Iteration[020/030] Train loss: 0.0090
2023-02-06 14:41:10 | Train | Epoch[400/600] Iteration[021/030] Train loss: 0.0090
2023-02-06 14:41:11 | Train | Epoch[400/600] Iteration[022/030] Train loss: 0.0089
2023-02-06 14:41:11 | Train | Epoch[400/600] Iteration[023/030] Train loss: 0.0090
2023-02-06 14:41:11 | Train | Epoch[400/600] Iteration[024/030] Train loss: 0.0090
2023-02-06 14:41:11 | Train | Epoch[400/600] Iteration[025/030] Train loss: 0.0090
2023-02-06 14:41:11 | Train | Epoch[400/600] Iteration[026/030] Train loss: 0.0090
2023-02-06 14:41:12 | Train | Epoch[400/600] Iteration[027/030] Train loss: 0.0090
2023-02-06 14:41:12 | Train | Epoch[400/600] Iteration[028/030] Train loss: 0.0090
2023-02-06 14:41:12 | Train | Epoch[400/600] Iteration[029/030] Train loss: 0.0090
2023-02-06 14:41:12 | Train | Epoch[400/600] Iteration[030/030] Train loss: 0.0090
2023-02-06 14:41:13 | Valid | Epoch[400/600] Iteration[001/008] Valid loss: 0.3747
2023-02-06 14:41:13 | Valid | Epoch[400/600] Iteration[002/008] Valid loss: 0.3187
2023-02-06 14:41:13 | Valid | Epoch[400/600] Iteration[003/008] Valid loss: 0.3013
2023-02-06 14:41:13 | Valid | Epoch[400/600] Iteration[004/008] Valid loss: 0.2949
2023-02-06 14:41:13 | Valid | Epoch[400/600] Iteration[005/008] Valid loss: 0.2991
2023-02-06 14:41:13 | Valid | Epoch[400/600] Iteration[006/008] Valid loss: 0.2916
2023-02-06 14:41:13 | Valid | Epoch[400/600] Iteration[007/008] Valid loss: 0.3140
2023-02-06 14:41:13 | Valid | Epoch[400/600] Iteration[008/008] Valid loss: 0.3230
2023-02-06 14:41:13 | Valid | Epoch[400/600] MIou: 0.9153562308275998
2023-02-06 14:41:13 | Valid | Epoch[400/600] Pixel Accuracy: 0.984399159749349
2023-02-06 14:41:13 | Valid | Epoch[400/600] Mean Pixel Accuracy: 0.9743819254140276
2023-02-06 14:41:13 | Stage | Epoch[400/600] Train loss:0.0090
2023-02-06 14:41:13 | Stage | Epoch[400/600] Valid loss:0.3230
2023-02-06 14:41:13 | Stage | Epoch[400/600] LR:0.01

2023-02-06 14:41:13 | Train | Epoch[401/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:41:14 | Train | Epoch[401/600] Iteration[002/030] Train loss: 0.0088
2023-02-06 14:41:14 | Train | Epoch[401/600] Iteration[003/030] Train loss: 0.0086
2023-02-06 14:41:14 | Train | Epoch[401/600] Iteration[004/030] Train loss: 0.0091
2023-02-06 14:41:14 | Train | Epoch[401/600] Iteration[005/030] Train loss: 0.0090
2023-02-06 14:41:15 | Train | Epoch[401/600] Iteration[006/030] Train loss: 0.0090
2023-02-06 14:41:15 | Train | Epoch[401/600] Iteration[007/030] Train loss: 0.0090
2023-02-06 14:41:15 | Train | Epoch[401/600] Iteration[008/030] Train loss: 0.0089
2023-02-06 14:41:15 | Train | Epoch[401/600] Iteration[009/030] Train loss: 0.0088
2023-02-06 14:41:15 | Train | Epoch[401/600] Iteration[010/030] Train loss: 0.0088
2023-02-06 14:41:16 | Train | Epoch[401/600] Iteration[011/030] Train loss: 0.0086
2023-02-06 14:41:16 | Train | Epoch[401/600] Iteration[012/030] Train loss: 0.0087
2023-02-06 14:41:16 | Train | Epoch[401/600] Iteration[013/030] Train loss: 0.0088
2023-02-06 14:41:16 | Train | Epoch[401/600] Iteration[014/030] Train loss: 0.0088
2023-02-06 14:41:17 | Train | Epoch[401/600] Iteration[015/030] Train loss: 0.0090
2023-02-06 14:41:17 | Train | Epoch[401/600] Iteration[016/030] Train loss: 0.0089
2023-02-06 14:41:17 | Train | Epoch[401/600] Iteration[017/030] Train loss: 0.0091
2023-02-06 14:41:17 | Train | Epoch[401/600] Iteration[018/030] Train loss: 0.0090
2023-02-06 14:41:17 | Train | Epoch[401/600] Iteration[019/030] Train loss: 0.0090
2023-02-06 14:41:18 | Train | Epoch[401/600] Iteration[020/030] Train loss: 0.0090
2023-02-06 14:41:18 | Train | Epoch[401/600] Iteration[021/030] Train loss: 0.0089
2023-02-06 14:41:18 | Train | Epoch[401/600] Iteration[022/030] Train loss: 0.0089
2023-02-06 14:41:18 | Train | Epoch[401/600] Iteration[023/030] Train loss: 0.0089
2023-02-06 14:41:19 | Train | Epoch[401/600] Iteration[024/030] Train loss: 0.0089
2023-02-06 14:41:19 | Train | Epoch[401/600] Iteration[025/030] Train loss: 0.0088
2023-02-06 14:41:19 | Train | Epoch[401/600] Iteration[026/030] Train loss: 0.0088
2023-02-06 14:41:19 | Train | Epoch[401/600] Iteration[027/030] Train loss: 0.0088
2023-02-06 14:41:19 | Train | Epoch[401/600] Iteration[028/030] Train loss: 0.0088
2023-02-06 14:41:20 | Train | Epoch[401/600] Iteration[029/030] Train loss: 0.0087
2023-02-06 14:41:20 | Train | Epoch[401/600] Iteration[030/030] Train loss: 0.0087
2023-02-06 14:41:20 | Valid | Epoch[401/600] Iteration[001/008] Valid loss: 0.1464
2023-02-06 14:41:20 | Valid | Epoch[401/600] Iteration[002/008] Valid loss: 0.1102
2023-02-06 14:41:20 | Valid | Epoch[401/600] Iteration[003/008] Valid loss: 0.1030
2023-02-06 14:41:20 | Valid | Epoch[401/600] Iteration[004/008] Valid loss: 0.0956
2023-02-06 14:41:20 | Valid | Epoch[401/600] Iteration[005/008] Valid loss: 0.0942
2023-02-06 14:41:20 | Valid | Epoch[401/600] Iteration[006/008] Valid loss: 0.0903
2023-02-06 14:41:20 | Valid | Epoch[401/600] Iteration[007/008] Valid loss: 0.0944
2023-02-06 14:41:20 | Valid | Epoch[401/600] Iteration[008/008] Valid loss: 0.0916
2023-02-06 14:41:21 | Valid | Epoch[401/600] MIou: 0.9285261571080188
2023-02-06 14:41:21 | Valid | Epoch[401/600] Pixel Accuracy: 0.9877840677897135
2023-02-06 14:41:21 | Valid | Epoch[401/600] Mean Pixel Accuracy: 0.9518759832149255
2023-02-06 14:41:21 | Stage | Epoch[401/600] Train loss:0.0087
2023-02-06 14:41:21 | Stage | Epoch[401/600] Valid loss:0.0916
2023-02-06 14:41:21 | Stage | Epoch[401/600] LR:0.001

2023-02-06 14:41:21 | Train | Epoch[402/600] Iteration[001/030] Train loss: 0.0079
2023-02-06 14:41:21 | Train | Epoch[402/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:41:21 | Train | Epoch[402/600] Iteration[003/030] Train loss: 0.0086
2023-02-06 14:41:22 | Train | Epoch[402/600] Iteration[004/030] Train loss: 0.0084
2023-02-06 14:41:22 | Train | Epoch[402/600] Iteration[005/030] Train loss: 0.0088
2023-02-06 14:41:22 | Train | Epoch[402/600] Iteration[006/030] Train loss: 0.0091
2023-02-06 14:41:22 | Train | Epoch[402/600] Iteration[007/030] Train loss: 0.0088
2023-02-06 14:41:23 | Train | Epoch[402/600] Iteration[008/030] Train loss: 0.0087
2023-02-06 14:41:23 | Train | Epoch[402/600] Iteration[009/030] Train loss: 0.0086
2023-02-06 14:41:23 | Train | Epoch[402/600] Iteration[010/030] Train loss: 0.0085
2023-02-06 14:41:23 | Train | Epoch[402/600] Iteration[011/030] Train loss: 0.0085
2023-02-06 14:41:23 | Train | Epoch[402/600] Iteration[012/030] Train loss: 0.0086
2023-02-06 14:41:24 | Train | Epoch[402/600] Iteration[013/030] Train loss: 0.0086
2023-02-06 14:41:24 | Train | Epoch[402/600] Iteration[014/030] Train loss: 0.0086
2023-02-06 14:41:24 | Train | Epoch[402/600] Iteration[015/030] Train loss: 0.0087
2023-02-06 14:41:24 | Train | Epoch[402/600] Iteration[016/030] Train loss: 0.0087
2023-02-06 14:41:24 | Train | Epoch[402/600] Iteration[017/030] Train loss: 0.0086
2023-02-06 14:41:25 | Train | Epoch[402/600] Iteration[018/030] Train loss: 0.0086
2023-02-06 14:41:25 | Train | Epoch[402/600] Iteration[019/030] Train loss: 0.0086
2023-02-06 14:41:25 | Train | Epoch[402/600] Iteration[020/030] Train loss: 0.0085
2023-02-06 14:41:25 | Train | Epoch[402/600] Iteration[021/030] Train loss: 0.0085
2023-02-06 14:41:26 | Train | Epoch[402/600] Iteration[022/030] Train loss: 0.0085
2023-02-06 14:41:26 | Train | Epoch[402/600] Iteration[023/030] Train loss: 0.0085
2023-02-06 14:41:26 | Train | Epoch[402/600] Iteration[024/030] Train loss: 0.0086
2023-02-06 14:41:26 | Train | Epoch[402/600] Iteration[025/030] Train loss: 0.0085
2023-02-06 14:41:26 | Train | Epoch[402/600] Iteration[026/030] Train loss: 0.0085
2023-02-06 14:41:27 | Train | Epoch[402/600] Iteration[027/030] Train loss: 0.0084
2023-02-06 14:41:27 | Train | Epoch[402/600] Iteration[028/030] Train loss: 0.0084
2023-02-06 14:41:27 | Train | Epoch[402/600] Iteration[029/030] Train loss: 0.0085
2023-02-06 14:41:27 | Train | Epoch[402/600] Iteration[030/030] Train loss: 0.0084
2023-02-06 14:41:28 | Valid | Epoch[402/600] Iteration[001/008] Valid loss: 0.1726
2023-02-06 14:41:28 | Valid | Epoch[402/600] Iteration[002/008] Valid loss: 0.1298
2023-02-06 14:41:28 | Valid | Epoch[402/600] Iteration[003/008] Valid loss: 0.1237
2023-02-06 14:41:28 | Valid | Epoch[402/600] Iteration[004/008] Valid loss: 0.1153
2023-02-06 14:41:28 | Valid | Epoch[402/600] Iteration[005/008] Valid loss: 0.1137
2023-02-06 14:41:28 | Valid | Epoch[402/600] Iteration[006/008] Valid loss: 0.1095
2023-02-06 14:41:28 | Valid | Epoch[402/600] Iteration[007/008] Valid loss: 0.1165
2023-02-06 14:41:28 | Valid | Epoch[402/600] Iteration[008/008] Valid loss: 0.1140
2023-02-06 14:41:28 | Valid | Epoch[402/600] MIou: 0.9297772975149496
2023-02-06 14:41:28 | Valid | Epoch[402/600] Pixel Accuracy: 0.9878794352213541
2023-02-06 14:41:28 | Valid | Epoch[402/600] Mean Pixel Accuracy: 0.957584101811453
2023-02-06 14:41:28 | Stage | Epoch[402/600] Train loss:0.0084
2023-02-06 14:41:28 | Stage | Epoch[402/600] Valid loss:0.1140
2023-02-06 14:41:28 | Stage | Epoch[402/600] LR:0.001

2023-02-06 14:41:28 | Train | Epoch[403/600] Iteration[001/030] Train loss: 0.0081
2023-02-06 14:41:29 | Train | Epoch[403/600] Iteration[002/030] Train loss: 0.0080
2023-02-06 14:41:29 | Train | Epoch[403/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:41:29 | Train | Epoch[403/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:41:29 | Train | Epoch[403/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:41:30 | Train | Epoch[403/600] Iteration[006/030] Train loss: 0.0088
2023-02-06 14:41:30 | Train | Epoch[403/600] Iteration[007/030] Train loss: 0.0086
2023-02-06 14:41:30 | Train | Epoch[403/600] Iteration[008/030] Train loss: 0.0087
2023-02-06 14:41:30 | Train | Epoch[403/600] Iteration[009/030] Train loss: 0.0088
2023-02-06 14:41:30 | Train | Epoch[403/600] Iteration[010/030] Train loss: 0.0086
2023-02-06 14:41:31 | Train | Epoch[403/600] Iteration[011/030] Train loss: 0.0086
2023-02-06 14:41:31 | Train | Epoch[403/600] Iteration[012/030] Train loss: 0.0085
2023-02-06 14:41:31 | Train | Epoch[403/600] Iteration[013/030] Train loss: 0.0086
2023-02-06 14:41:31 | Train | Epoch[403/600] Iteration[014/030] Train loss: 0.0086
2023-02-06 14:41:32 | Train | Epoch[403/600] Iteration[015/030] Train loss: 0.0086
2023-02-06 14:41:32 | Train | Epoch[403/600] Iteration[016/030] Train loss: 0.0087
2023-02-06 14:41:32 | Train | Epoch[403/600] Iteration[017/030] Train loss: 0.0086
2023-02-06 14:41:32 | Train | Epoch[403/600] Iteration[018/030] Train loss: 0.0086
2023-02-06 14:41:32 | Train | Epoch[403/600] Iteration[019/030] Train loss: 0.0086
2023-02-06 14:41:33 | Train | Epoch[403/600] Iteration[020/030] Train loss: 0.0086
2023-02-06 14:41:33 | Train | Epoch[403/600] Iteration[021/030] Train loss: 0.0085
2023-02-06 14:41:33 | Train | Epoch[403/600] Iteration[022/030] Train loss: 0.0085
2023-02-06 14:41:33 | Train | Epoch[403/600] Iteration[023/030] Train loss: 0.0085
2023-02-06 14:41:34 | Train | Epoch[403/600] Iteration[024/030] Train loss: 0.0084
2023-02-06 14:41:34 | Train | Epoch[403/600] Iteration[025/030] Train loss: 0.0084
2023-02-06 14:41:34 | Train | Epoch[403/600] Iteration[026/030] Train loss: 0.0084
2023-02-06 14:41:34 | Train | Epoch[403/600] Iteration[027/030] Train loss: 0.0084
2023-02-06 14:41:34 | Train | Epoch[403/600] Iteration[028/030] Train loss: 0.0084
2023-02-06 14:41:35 | Train | Epoch[403/600] Iteration[029/030] Train loss: 0.0084
2023-02-06 14:41:35 | Train | Epoch[403/600] Iteration[030/030] Train loss: 0.0084
2023-02-06 14:41:35 | Valid | Epoch[403/600] Iteration[001/008] Valid loss: 0.1646
2023-02-06 14:41:35 | Valid | Epoch[403/600] Iteration[002/008] Valid loss: 0.1259
2023-02-06 14:41:35 | Valid | Epoch[403/600] Iteration[003/008] Valid loss: 0.1193
2023-02-06 14:41:35 | Valid | Epoch[403/600] Iteration[004/008] Valid loss: 0.1115
2023-02-06 14:41:35 | Valid | Epoch[403/600] Iteration[005/008] Valid loss: 0.1095
2023-02-06 14:41:35 | Valid | Epoch[403/600] Iteration[006/008] Valid loss: 0.1057
2023-02-06 14:41:35 | Valid | Epoch[403/600] Iteration[007/008] Valid loss: 0.1119
2023-02-06 14:41:35 | Valid | Epoch[403/600] Iteration[008/008] Valid loss: 0.1096
2023-02-06 14:41:36 | Valid | Epoch[403/600] MIou: 0.9296337859146682
2023-02-06 14:41:36 | Valid | Epoch[403/600] Pixel Accuracy: 0.9878768920898438
2023-02-06 14:41:36 | Valid | Epoch[403/600] Mean Pixel Accuracy: 0.9565999309135406
2023-02-06 14:41:36 | Stage | Epoch[403/600] Train loss:0.0084
2023-02-06 14:41:36 | Stage | Epoch[403/600] Valid loss:0.1096
2023-02-06 14:41:36 | Stage | Epoch[403/600] LR:0.001

2023-02-06 14:41:36 | Train | Epoch[404/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 14:41:36 | Train | Epoch[404/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:41:36 | Train | Epoch[404/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:41:37 | Train | Epoch[404/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:41:37 | Train | Epoch[404/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:41:37 | Train | Epoch[404/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:41:37 | Train | Epoch[404/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:41:38 | Train | Epoch[404/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:41:38 | Train | Epoch[404/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:41:38 | Train | Epoch[404/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:41:38 | Train | Epoch[404/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:41:38 | Train | Epoch[404/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:41:39 | Train | Epoch[404/600] Iteration[013/030] Train loss: 0.0082
2023-02-06 14:41:39 | Train | Epoch[404/600] Iteration[014/030] Train loss: 0.0081
2023-02-06 14:41:39 | Train | Epoch[404/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 14:41:39 | Train | Epoch[404/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:41:40 | Train | Epoch[404/600] Iteration[017/030] Train loss: 0.0081
2023-02-06 14:41:40 | Train | Epoch[404/600] Iteration[018/030] Train loss: 0.0081
2023-02-06 14:41:40 | Train | Epoch[404/600] Iteration[019/030] Train loss: 0.0081
2023-02-06 14:41:40 | Train | Epoch[404/600] Iteration[020/030] Train loss: 0.0081
2023-02-06 14:41:40 | Train | Epoch[404/600] Iteration[021/030] Train loss: 0.0081
2023-02-06 14:41:41 | Train | Epoch[404/600] Iteration[022/030] Train loss: 0.0081
2023-02-06 14:41:41 | Train | Epoch[404/600] Iteration[023/030] Train loss: 0.0081
2023-02-06 14:41:41 | Train | Epoch[404/600] Iteration[024/030] Train loss: 0.0081
2023-02-06 14:41:41 | Train | Epoch[404/600] Iteration[025/030] Train loss: 0.0081
2023-02-06 14:41:41 | Train | Epoch[404/600] Iteration[026/030] Train loss: 0.0081
2023-02-06 14:41:42 | Train | Epoch[404/600] Iteration[027/030] Train loss: 0.0081
2023-02-06 14:41:42 | Train | Epoch[404/600] Iteration[028/030] Train loss: 0.0081
2023-02-06 14:41:42 | Train | Epoch[404/600] Iteration[029/030] Train loss: 0.0081
2023-02-06 14:41:42 | Train | Epoch[404/600] Iteration[030/030] Train loss: 0.0081
2023-02-06 14:41:43 | Valid | Epoch[404/600] Iteration[001/008] Valid loss: 0.1594
2023-02-06 14:41:43 | Valid | Epoch[404/600] Iteration[002/008] Valid loss: 0.1209
2023-02-06 14:41:43 | Valid | Epoch[404/600] Iteration[003/008] Valid loss: 0.1147
2023-02-06 14:41:43 | Valid | Epoch[404/600] Iteration[004/008] Valid loss: 0.1071
2023-02-06 14:41:43 | Valid | Epoch[404/600] Iteration[005/008] Valid loss: 0.1055
2023-02-06 14:41:43 | Valid | Epoch[404/600] Iteration[006/008] Valid loss: 0.1014
2023-02-06 14:41:43 | Valid | Epoch[404/600] Iteration[007/008] Valid loss: 0.1074
2023-02-06 14:41:43 | Valid | Epoch[404/600] Iteration[008/008] Valid loss: 0.1052
2023-02-06 14:41:43 | Valid | Epoch[404/600] MIou: 0.9294105983587315
2023-02-06 14:41:43 | Valid | Epoch[404/600] Pixel Accuracy: 0.9878667195638021
2023-02-06 14:41:43 | Valid | Epoch[404/600] Mean Pixel Accuracy: 0.9553135644139402
2023-02-06 14:41:43 | Stage | Epoch[404/600] Train loss:0.0081
2023-02-06 14:41:43 | Stage | Epoch[404/600] Valid loss:0.1052
2023-02-06 14:41:43 | Stage | Epoch[404/600] LR:0.001

2023-02-06 14:41:44 | Train | Epoch[405/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 14:41:44 | Train | Epoch[405/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:41:44 | Train | Epoch[405/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:41:44 | Train | Epoch[405/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:41:44 | Train | Epoch[405/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:41:45 | Train | Epoch[405/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:41:45 | Train | Epoch[405/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:41:45 | Train | Epoch[405/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:41:45 | Train | Epoch[405/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:41:46 | Train | Epoch[405/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:41:46 | Train | Epoch[405/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:41:46 | Train | Epoch[405/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:41:46 | Train | Epoch[405/600] Iteration[013/030] Train loss: 0.0081
2023-02-06 14:41:46 | Train | Epoch[405/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:41:47 | Train | Epoch[405/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 14:41:47 | Train | Epoch[405/600] Iteration[016/030] Train loss: 0.0082
2023-02-06 14:41:47 | Train | Epoch[405/600] Iteration[017/030] Train loss: 0.0081
2023-02-06 14:41:47 | Train | Epoch[405/600] Iteration[018/030] Train loss: 0.0081
2023-02-06 14:41:48 | Train | Epoch[405/600] Iteration[019/030] Train loss: 0.0081
2023-02-06 14:41:48 | Train | Epoch[405/600] Iteration[020/030] Train loss: 0.0081
2023-02-06 14:41:48 | Train | Epoch[405/600] Iteration[021/030] Train loss: 0.0081
2023-02-06 14:41:48 | Train | Epoch[405/600] Iteration[022/030] Train loss: 0.0081
2023-02-06 14:41:48 | Train | Epoch[405/600] Iteration[023/030] Train loss: 0.0081
2023-02-06 14:41:49 | Train | Epoch[405/600] Iteration[024/030] Train loss: 0.0081
2023-02-06 14:41:49 | Train | Epoch[405/600] Iteration[025/030] Train loss: 0.0082
2023-02-06 14:41:49 | Train | Epoch[405/600] Iteration[026/030] Train loss: 0.0082
2023-02-06 14:41:49 | Train | Epoch[405/600] Iteration[027/030] Train loss: 0.0082
2023-02-06 14:41:49 | Train | Epoch[405/600] Iteration[028/030] Train loss: 0.0082
2023-02-06 14:41:50 | Train | Epoch[405/600] Iteration[029/030] Train loss: 0.0082
2023-02-06 14:41:50 | Train | Epoch[405/600] Iteration[030/030] Train loss: 0.0082
2023-02-06 14:41:50 | Valid | Epoch[405/600] Iteration[001/008] Valid loss: 0.1529
2023-02-06 14:41:50 | Valid | Epoch[405/600] Iteration[002/008] Valid loss: 0.1180
2023-02-06 14:41:50 | Valid | Epoch[405/600] Iteration[003/008] Valid loss: 0.1109
2023-02-06 14:41:50 | Valid | Epoch[405/600] Iteration[004/008] Valid loss: 0.1037
2023-02-06 14:41:50 | Valid | Epoch[405/600] Iteration[005/008] Valid loss: 0.1018
2023-02-06 14:41:50 | Valid | Epoch[405/600] Iteration[006/008] Valid loss: 0.0980
2023-02-06 14:41:50 | Valid | Epoch[405/600] Iteration[007/008] Valid loss: 0.1036
2023-02-06 14:41:50 | Valid | Epoch[405/600] Iteration[008/008] Valid loss: 0.1013
2023-02-06 14:41:51 | Valid | Epoch[405/600] MIou: 0.9287997568119144
2023-02-06 14:41:51 | Valid | Epoch[405/600] Pixel Accuracy: 0.9877789815266927
2023-02-06 14:41:51 | Valid | Epoch[405/600] Mean Pixel Accuracy: 0.9540796716740492
2023-02-06 14:41:51 | Stage | Epoch[405/600] Train loss:0.0082
2023-02-06 14:41:51 | Stage | Epoch[405/600] Valid loss:0.1013
2023-02-06 14:41:51 | Stage | Epoch[405/600] LR:0.001

2023-02-06 14:41:51 | Train | Epoch[406/600] Iteration[001/030] Train loss: 0.0066
2023-02-06 14:41:51 | Train | Epoch[406/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:41:52 | Train | Epoch[406/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:41:52 | Train | Epoch[406/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:41:52 | Train | Epoch[406/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:41:52 | Train | Epoch[406/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 14:41:52 | Train | Epoch[406/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:41:53 | Train | Epoch[406/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:41:53 | Train | Epoch[406/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:41:53 | Train | Epoch[406/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:41:53 | Train | Epoch[406/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:41:53 | Train | Epoch[406/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:41:54 | Train | Epoch[406/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:41:54 | Train | Epoch[406/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:41:54 | Train | Epoch[406/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:41:54 | Train | Epoch[406/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:41:55 | Train | Epoch[406/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:41:55 | Train | Epoch[406/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:41:55 | Train | Epoch[406/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:41:55 | Train | Epoch[406/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:41:55 | Train | Epoch[406/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:41:56 | Train | Epoch[406/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:41:56 | Train | Epoch[406/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:41:56 | Train | Epoch[406/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:41:56 | Train | Epoch[406/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:41:57 | Train | Epoch[406/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:41:57 | Train | Epoch[406/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:41:57 | Train | Epoch[406/600] Iteration[028/030] Train loss: 0.0081
2023-02-06 14:41:57 | Train | Epoch[406/600] Iteration[029/030] Train loss: 0.0081
2023-02-06 14:41:57 | Train | Epoch[406/600] Iteration[030/030] Train loss: 0.0081
2023-02-06 14:41:58 | Valid | Epoch[406/600] Iteration[001/008] Valid loss: 0.1651
2023-02-06 14:41:58 | Valid | Epoch[406/600] Iteration[002/008] Valid loss: 0.1266
2023-02-06 14:41:58 | Valid | Epoch[406/600] Iteration[003/008] Valid loss: 0.1192
2023-02-06 14:41:58 | Valid | Epoch[406/600] Iteration[004/008] Valid loss: 0.1116
2023-02-06 14:41:58 | Valid | Epoch[406/600] Iteration[005/008] Valid loss: 0.1104
2023-02-06 14:41:58 | Valid | Epoch[406/600] Iteration[006/008] Valid loss: 0.1061
2023-02-06 14:41:58 | Valid | Epoch[406/600] Iteration[007/008] Valid loss: 0.1124
2023-02-06 14:41:58 | Valid | Epoch[406/600] Iteration[008/008] Valid loss: 0.1105
2023-02-06 14:41:58 | Valid | Epoch[406/600] MIou: 0.9302358926010464
2023-02-06 14:41:58 | Valid | Epoch[406/600] Pixel Accuracy: 0.9879798889160156
2023-02-06 14:41:58 | Valid | Epoch[406/600] Mean Pixel Accuracy: 0.9572081633834639
2023-02-06 14:41:58 | Stage | Epoch[406/600] Train loss:0.0081
2023-02-06 14:41:58 | Stage | Epoch[406/600] Valid loss:0.1105
2023-02-06 14:41:58 | Stage | Epoch[406/600] LR:0.001

2023-02-06 14:41:59 | Train | Epoch[407/600] Iteration[001/030] Train loss: 0.0082
2023-02-06 14:41:59 | Train | Epoch[407/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:41:59 | Train | Epoch[407/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 14:41:59 | Train | Epoch[407/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:41:59 | Train | Epoch[407/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:42:00 | Train | Epoch[407/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:42:00 | Train | Epoch[407/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:42:00 | Train | Epoch[407/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:42:00 | Train | Epoch[407/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:42:01 | Train | Epoch[407/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:42:01 | Train | Epoch[407/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:42:01 | Train | Epoch[407/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:42:01 | Train | Epoch[407/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:42:01 | Train | Epoch[407/600] Iteration[014/030] Train loss: 0.0082
2023-02-06 14:42:02 | Train | Epoch[407/600] Iteration[015/030] Train loss: 0.0082
2023-02-06 14:42:02 | Train | Epoch[407/600] Iteration[016/030] Train loss: 0.0082
2023-02-06 14:42:02 | Train | Epoch[407/600] Iteration[017/030] Train loss: 0.0083
2023-02-06 14:42:02 | Train | Epoch[407/600] Iteration[018/030] Train loss: 0.0082
2023-02-06 14:42:03 | Train | Epoch[407/600] Iteration[019/030] Train loss: 0.0082
2023-02-06 14:42:03 | Train | Epoch[407/600] Iteration[020/030] Train loss: 0.0082
2023-02-06 14:42:03 | Train | Epoch[407/600] Iteration[021/030] Train loss: 0.0082
2023-02-06 14:42:03 | Train | Epoch[407/600] Iteration[022/030] Train loss: 0.0082
2023-02-06 14:42:03 | Train | Epoch[407/600] Iteration[023/030] Train loss: 0.0082
2023-02-06 14:42:04 | Train | Epoch[407/600] Iteration[024/030] Train loss: 0.0082
2023-02-06 14:42:04 | Train | Epoch[407/600] Iteration[025/030] Train loss: 0.0082
2023-02-06 14:42:04 | Train | Epoch[407/600] Iteration[026/030] Train loss: 0.0082
2023-02-06 14:42:04 | Train | Epoch[407/600] Iteration[027/030] Train loss: 0.0081
2023-02-06 14:42:04 | Train | Epoch[407/600] Iteration[028/030] Train loss: 0.0082
2023-02-06 14:42:05 | Train | Epoch[407/600] Iteration[029/030] Train loss: 0.0081
2023-02-06 14:42:05 | Train | Epoch[407/600] Iteration[030/030] Train loss: 0.0082
2023-02-06 14:42:05 | Valid | Epoch[407/600] Iteration[001/008] Valid loss: 0.1579
2023-02-06 14:42:05 | Valid | Epoch[407/600] Iteration[002/008] Valid loss: 0.1198
2023-02-06 14:42:05 | Valid | Epoch[407/600] Iteration[003/008] Valid loss: 0.1134
2023-02-06 14:42:05 | Valid | Epoch[407/600] Iteration[004/008] Valid loss: 0.1057
2023-02-06 14:42:05 | Valid | Epoch[407/600] Iteration[005/008] Valid loss: 0.1038
2023-02-06 14:42:05 | Valid | Epoch[407/600] Iteration[006/008] Valid loss: 0.0998
2023-02-06 14:42:05 | Valid | Epoch[407/600] Iteration[007/008] Valid loss: 0.1050
2023-02-06 14:42:06 | Valid | Epoch[407/600] Iteration[008/008] Valid loss: 0.1024
2023-02-06 14:42:06 | Valid | Epoch[407/600] MIou: 0.9294667683162705
2023-02-06 14:42:06 | Valid | Epoch[407/600] Pixel Accuracy: 0.9878921508789062
2023-02-06 14:42:06 | Valid | Epoch[407/600] Mean Pixel Accuracy: 0.9547695810562777
2023-02-06 14:42:06 | Stage | Epoch[407/600] Train loss:0.0082
2023-02-06 14:42:06 | Stage | Epoch[407/600] Valid loss:0.1024
2023-02-06 14:42:06 | Stage | Epoch[407/600] LR:0.001

2023-02-06 14:42:06 | Train | Epoch[408/600] Iteration[001/030] Train loss: 0.0074
2023-02-06 14:42:06 | Train | Epoch[408/600] Iteration[002/030] Train loss: 0.0080
2023-02-06 14:42:07 | Train | Epoch[408/600] Iteration[003/030] Train loss: 0.0081
2023-02-06 14:42:07 | Train | Epoch[408/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:42:07 | Train | Epoch[408/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:42:07 | Train | Epoch[408/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:42:07 | Train | Epoch[408/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:42:08 | Train | Epoch[408/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:42:08 | Train | Epoch[408/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:42:08 | Train | Epoch[408/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:42:08 | Train | Epoch[408/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:42:08 | Train | Epoch[408/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:42:09 | Train | Epoch[408/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:42:09 | Train | Epoch[408/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:42:09 | Train | Epoch[408/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:42:09 | Train | Epoch[408/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:42:10 | Train | Epoch[408/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:42:10 | Train | Epoch[408/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:42:10 | Train | Epoch[408/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:42:10 | Train | Epoch[408/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:42:10 | Train | Epoch[408/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:42:11 | Train | Epoch[408/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:42:11 | Train | Epoch[408/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:42:11 | Train | Epoch[408/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:42:11 | Train | Epoch[408/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:42:12 | Train | Epoch[408/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:42:12 | Train | Epoch[408/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:42:12 | Train | Epoch[408/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:42:12 | Train | Epoch[408/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:42:12 | Train | Epoch[408/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:42:13 | Valid | Epoch[408/600] Iteration[001/008] Valid loss: 0.1780
2023-02-06 14:42:13 | Valid | Epoch[408/600] Iteration[002/008] Valid loss: 0.1374
2023-02-06 14:42:13 | Valid | Epoch[408/600] Iteration[003/008] Valid loss: 0.1303
2023-02-06 14:42:13 | Valid | Epoch[408/600] Iteration[004/008] Valid loss: 0.1223
2023-02-06 14:42:13 | Valid | Epoch[408/600] Iteration[005/008] Valid loss: 0.1216
2023-02-06 14:42:13 | Valid | Epoch[408/600] Iteration[006/008] Valid loss: 0.1172
2023-02-06 14:42:13 | Valid | Epoch[408/600] Iteration[007/008] Valid loss: 0.1247
2023-02-06 14:42:13 | Valid | Epoch[408/600] Iteration[008/008] Valid loss: 0.1226
2023-02-06 14:42:13 | Valid | Epoch[408/600] MIou: 0.9312164850583395
2023-02-06 14:42:13 | Valid | Epoch[408/600] Pixel Accuracy: 0.9880956013997396
2023-02-06 14:42:13 | Valid | Epoch[408/600] Mean Pixel Accuracy: 0.960232764095678
2023-02-06 14:42:13 | Stage | Epoch[408/600] Train loss:0.0079
2023-02-06 14:42:13 | Stage | Epoch[408/600] Valid loss:0.1226
2023-02-06 14:42:13 | Stage | Epoch[408/600] LR:0.001

2023-02-06 14:42:14 | Train | Epoch[409/600] Iteration[001/030] Train loss: 0.0086
2023-02-06 14:42:14 | Train | Epoch[409/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:42:14 | Train | Epoch[409/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:42:14 | Train | Epoch[409/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:42:14 | Train | Epoch[409/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 14:42:15 | Train | Epoch[409/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:42:15 | Train | Epoch[409/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:42:15 | Train | Epoch[409/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:42:15 | Train | Epoch[409/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:42:16 | Train | Epoch[409/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:42:16 | Train | Epoch[409/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:42:16 | Train | Epoch[409/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:42:16 | Train | Epoch[409/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:42:16 | Train | Epoch[409/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:42:17 | Train | Epoch[409/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:42:17 | Train | Epoch[409/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:42:17 | Train | Epoch[409/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:42:17 | Train | Epoch[409/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:42:18 | Train | Epoch[409/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:42:18 | Train | Epoch[409/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:42:18 | Train | Epoch[409/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:42:18 | Train | Epoch[409/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:42:18 | Train | Epoch[409/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:42:19 | Train | Epoch[409/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:42:19 | Train | Epoch[409/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:42:19 | Train | Epoch[409/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:42:19 | Train | Epoch[409/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:42:20 | Train | Epoch[409/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:42:20 | Train | Epoch[409/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:42:20 | Train | Epoch[409/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:42:20 | Valid | Epoch[409/600] Iteration[001/008] Valid loss: 0.1312
2023-02-06 14:42:20 | Valid | Epoch[409/600] Iteration[002/008] Valid loss: 0.0993
2023-02-06 14:42:20 | Valid | Epoch[409/600] Iteration[003/008] Valid loss: 0.0952
2023-02-06 14:42:20 | Valid | Epoch[409/600] Iteration[004/008] Valid loss: 0.0887
2023-02-06 14:42:20 | Valid | Epoch[409/600] Iteration[005/008] Valid loss: 0.0865
2023-02-06 14:42:20 | Valid | Epoch[409/600] Iteration[006/008] Valid loss: 0.0829
2023-02-06 14:42:21 | Valid | Epoch[409/600] Iteration[007/008] Valid loss: 0.0858
2023-02-06 14:42:21 | Valid | Epoch[409/600] Iteration[008/008] Valid loss: 0.0834
2023-02-06 14:42:21 | Valid | Epoch[409/600] MIou: 0.9251736579468296
2023-02-06 14:42:21 | Valid | Epoch[409/600] Pixel Accuracy: 0.9872919718424479
2023-02-06 14:42:21 | Valid | Epoch[409/600] Mean Pixel Accuracy: 0.9458166558043949
2023-02-06 14:42:21 | Stage | Epoch[409/600] Train loss:0.0078
2023-02-06 14:42:21 | Stage | Epoch[409/600] Valid loss:0.0834
2023-02-06 14:42:21 | Stage | Epoch[409/600] LR:0.001

2023-02-06 14:42:21 | Train | Epoch[410/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 14:42:21 | Train | Epoch[410/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 14:42:22 | Train | Epoch[410/600] Iteration[003/030] Train loss: 0.0082
2023-02-06 14:42:22 | Train | Epoch[410/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:42:22 | Train | Epoch[410/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:42:22 | Train | Epoch[410/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:42:22 | Train | Epoch[410/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:42:23 | Train | Epoch[410/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:42:23 | Train | Epoch[410/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:42:23 | Train | Epoch[410/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:42:23 | Train | Epoch[410/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:42:24 | Train | Epoch[410/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:42:24 | Train | Epoch[410/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:42:24 | Train | Epoch[410/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:42:24 | Train | Epoch[410/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:42:24 | Train | Epoch[410/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:42:25 | Train | Epoch[410/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:42:25 | Train | Epoch[410/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:42:25 | Train | Epoch[410/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:42:25 | Train | Epoch[410/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:42:26 | Train | Epoch[410/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:42:26 | Train | Epoch[410/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:42:26 | Train | Epoch[410/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:42:26 | Train | Epoch[410/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:42:26 | Train | Epoch[410/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:42:27 | Train | Epoch[410/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:42:27 | Train | Epoch[410/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:42:27 | Train | Epoch[410/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:42:27 | Train | Epoch[410/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:42:27 | Train | Epoch[410/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:42:28 | Valid | Epoch[410/600] Iteration[001/008] Valid loss: 0.1647
2023-02-06 14:42:28 | Valid | Epoch[410/600] Iteration[002/008] Valid loss: 0.1270
2023-02-06 14:42:28 | Valid | Epoch[410/600] Iteration[003/008] Valid loss: 0.1210
2023-02-06 14:42:28 | Valid | Epoch[410/600] Iteration[004/008] Valid loss: 0.1137
2023-02-06 14:42:28 | Valid | Epoch[410/600] Iteration[005/008] Valid loss: 0.1117
2023-02-06 14:42:28 | Valid | Epoch[410/600] Iteration[006/008] Valid loss: 0.1075
2023-02-06 14:42:28 | Valid | Epoch[410/600] Iteration[007/008] Valid loss: 0.1137
2023-02-06 14:42:28 | Valid | Epoch[410/600] Iteration[008/008] Valid loss: 0.1113
2023-02-06 14:42:28 | Valid | Epoch[410/600] MIou: 0.9301040241149389
2023-02-06 14:42:28 | Valid | Epoch[410/600] Pixel Accuracy: 0.987969716389974
2023-02-06 14:42:28 | Valid | Epoch[410/600] Mean Pixel Accuracy: 0.9566002273356561
2023-02-06 14:42:28 | Stage | Epoch[410/600] Train loss:0.0080
2023-02-06 14:42:28 | Stage | Epoch[410/600] Valid loss:0.1113
2023-02-06 14:42:28 | Stage | Epoch[410/600] LR:0.001

2023-02-06 14:42:29 | Train | Epoch[411/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 14:42:29 | Train | Epoch[411/600] Iteration[002/030] Train loss: 0.0084
2023-02-06 14:42:29 | Train | Epoch[411/600] Iteration[003/030] Train loss: 0.0082
2023-02-06 14:42:29 | Train | Epoch[411/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:42:30 | Train | Epoch[411/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:42:30 | Train | Epoch[411/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 14:42:30 | Train | Epoch[411/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:42:30 | Train | Epoch[411/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:42:30 | Train | Epoch[411/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:42:31 | Train | Epoch[411/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:42:31 | Train | Epoch[411/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:42:31 | Train | Epoch[411/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:42:31 | Train | Epoch[411/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:42:32 | Train | Epoch[411/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:42:32 | Train | Epoch[411/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:42:32 | Train | Epoch[411/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:42:32 | Train | Epoch[411/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:42:32 | Train | Epoch[411/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:42:33 | Train | Epoch[411/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:42:33 | Train | Epoch[411/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:42:33 | Train | Epoch[411/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:42:33 | Train | Epoch[411/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:42:34 | Train | Epoch[411/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:42:34 | Train | Epoch[411/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:42:34 | Train | Epoch[411/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:42:34 | Train | Epoch[411/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:42:34 | Train | Epoch[411/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:42:35 | Train | Epoch[411/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:42:35 | Train | Epoch[411/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:42:35 | Train | Epoch[411/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:42:35 | Valid | Epoch[411/600] Iteration[001/008] Valid loss: 0.1809
2023-02-06 14:42:35 | Valid | Epoch[411/600] Iteration[002/008] Valid loss: 0.1403
2023-02-06 14:42:35 | Valid | Epoch[411/600] Iteration[003/008] Valid loss: 0.1324
2023-02-06 14:42:35 | Valid | Epoch[411/600] Iteration[004/008] Valid loss: 0.1244
2023-02-06 14:42:35 | Valid | Epoch[411/600] Iteration[005/008] Valid loss: 0.1233
2023-02-06 14:42:36 | Valid | Epoch[411/600] Iteration[006/008] Valid loss: 0.1188
2023-02-06 14:42:36 | Valid | Epoch[411/600] Iteration[007/008] Valid loss: 0.1266
2023-02-06 14:42:36 | Valid | Epoch[411/600] Iteration[008/008] Valid loss: 0.1250
2023-02-06 14:42:36 | Valid | Epoch[411/600] MIou: 0.9313551412357957
2023-02-06 14:42:36 | Valid | Epoch[411/600] Pixel Accuracy: 0.9881172180175781
2023-02-06 14:42:36 | Valid | Epoch[411/600] Mean Pixel Accuracy: 0.9604602215421791
2023-02-06 14:42:36 | Stage | Epoch[411/600] Train loss:0.0079
2023-02-06 14:42:36 | Stage | Epoch[411/600] Valid loss:0.1250
2023-02-06 14:42:36 | Stage | Epoch[411/600] LR:0.001

2023-02-06 14:42:36 | Train | Epoch[412/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 14:42:36 | Train | Epoch[412/600] Iteration[002/030] Train loss: 0.0084
2023-02-06 14:42:37 | Train | Epoch[412/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:42:37 | Train | Epoch[412/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:42:37 | Train | Epoch[412/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:42:37 | Train | Epoch[412/600] Iteration[006/030] Train loss: 0.0083
2023-02-06 14:42:38 | Train | Epoch[412/600] Iteration[007/030] Train loss: 0.0083
2023-02-06 14:42:38 | Train | Epoch[412/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:42:38 | Train | Epoch[412/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:42:38 | Train | Epoch[412/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:42:38 | Train | Epoch[412/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:42:39 | Train | Epoch[412/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:42:39 | Train | Epoch[412/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:42:39 | Train | Epoch[412/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:42:39 | Train | Epoch[412/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:42:39 | Train | Epoch[412/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:42:40 | Train | Epoch[412/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:42:40 | Train | Epoch[412/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:42:40 | Train | Epoch[412/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:42:40 | Train | Epoch[412/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:42:41 | Train | Epoch[412/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:42:41 | Train | Epoch[412/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:42:41 | Train | Epoch[412/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:42:41 | Train | Epoch[412/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:42:41 | Train | Epoch[412/600] Iteration[025/030] Train loss: 0.0081
2023-02-06 14:42:42 | Train | Epoch[412/600] Iteration[026/030] Train loss: 0.0081
2023-02-06 14:42:42 | Train | Epoch[412/600] Iteration[027/030] Train loss: 0.0081
2023-02-06 14:42:42 | Train | Epoch[412/600] Iteration[028/030] Train loss: 0.0081
2023-02-06 14:42:42 | Train | Epoch[412/600] Iteration[029/030] Train loss: 0.0081
2023-02-06 14:42:42 | Train | Epoch[412/600] Iteration[030/030] Train loss: 0.0081
2023-02-06 14:42:43 | Valid | Epoch[412/600] Iteration[001/008] Valid loss: 0.2159
2023-02-06 14:42:43 | Valid | Epoch[412/600] Iteration[002/008] Valid loss: 0.1692
2023-02-06 14:42:43 | Valid | Epoch[412/600] Iteration[003/008] Valid loss: 0.1640
2023-02-06 14:42:43 | Valid | Epoch[412/600] Iteration[004/008] Valid loss: 0.1546
2023-02-06 14:42:43 | Valid | Epoch[412/600] Iteration[005/008] Valid loss: 0.1538
2023-02-06 14:42:43 | Valid | Epoch[412/600] Iteration[006/008] Valid loss: 0.1504
2023-02-06 14:42:43 | Valid | Epoch[412/600] Iteration[007/008] Valid loss: 0.1613
2023-02-06 14:42:43 | Valid | Epoch[412/600] Iteration[008/008] Valid loss: 0.1598
2023-02-06 14:42:43 | Valid | Epoch[412/600] MIou: 0.9296045377436076
2023-02-06 14:42:43 | Valid | Epoch[412/600] Pixel Accuracy: 0.987646738688151
2023-02-06 14:42:43 | Valid | Epoch[412/600] Mean Pixel Accuracy: 0.9651535342882023
2023-02-06 14:42:43 | Stage | Epoch[412/600] Train loss:0.0081
2023-02-06 14:42:43 | Stage | Epoch[412/600] Valid loss:0.1598
2023-02-06 14:42:43 | Stage | Epoch[412/600] LR:0.001

2023-02-06 14:42:44 | Train | Epoch[413/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 14:42:44 | Train | Epoch[413/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 14:42:44 | Train | Epoch[413/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 14:42:44 | Train | Epoch[413/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 14:42:45 | Train | Epoch[413/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:42:45 | Train | Epoch[413/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:42:45 | Train | Epoch[413/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:42:45 | Train | Epoch[413/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:42:45 | Train | Epoch[413/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:42:46 | Train | Epoch[413/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:42:46 | Train | Epoch[413/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:42:46 | Train | Epoch[413/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:42:46 | Train | Epoch[413/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:42:47 | Train | Epoch[413/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:42:47 | Train | Epoch[413/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:42:47 | Train | Epoch[413/600] Iteration[016/030] Train loss: 0.0081
2023-02-06 14:42:47 | Train | Epoch[413/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:42:47 | Train | Epoch[413/600] Iteration[018/030] Train loss: 0.0081
2023-02-06 14:42:48 | Train | Epoch[413/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:42:48 | Train | Epoch[413/600] Iteration[020/030] Train loss: 0.0081
2023-02-06 14:42:48 | Train | Epoch[413/600] Iteration[021/030] Train loss: 0.0081
2023-02-06 14:42:48 | Train | Epoch[413/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:42:49 | Train | Epoch[413/600] Iteration[023/030] Train loss: 0.0081
2023-02-06 14:42:49 | Train | Epoch[413/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:42:49 | Train | Epoch[413/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:42:49 | Train | Epoch[413/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:42:49 | Train | Epoch[413/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:42:50 | Train | Epoch[413/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:42:50 | Train | Epoch[413/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:42:50 | Train | Epoch[413/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:42:50 | Valid | Epoch[413/600] Iteration[001/008] Valid loss: 0.1251
2023-02-06 14:42:50 | Valid | Epoch[413/600] Iteration[002/008] Valid loss: 0.0969
2023-02-06 14:42:50 | Valid | Epoch[413/600] Iteration[003/008] Valid loss: 0.0926
2023-02-06 14:42:51 | Valid | Epoch[413/600] Iteration[004/008] Valid loss: 0.0870
2023-02-06 14:42:51 | Valid | Epoch[413/600] Iteration[005/008] Valid loss: 0.0845
2023-02-06 14:42:51 | Valid | Epoch[413/600] Iteration[006/008] Valid loss: 0.0813
2023-02-06 14:42:51 | Valid | Epoch[413/600] Iteration[007/008] Valid loss: 0.0842
2023-02-06 14:42:51 | Valid | Epoch[413/600] Iteration[008/008] Valid loss: 0.0818
2023-02-06 14:42:51 | Valid | Epoch[413/600] MIou: 0.9236943333635649
2023-02-06 14:42:51 | Valid | Epoch[413/600] Pixel Accuracy: 0.987054189046224
2023-02-06 14:42:51 | Valid | Epoch[413/600] Mean Pixel Accuracy: 0.9439486710440894
2023-02-06 14:42:51 | Stage | Epoch[413/600] Train loss:0.0079
2023-02-06 14:42:51 | Stage | Epoch[413/600] Valid loss:0.0818
2023-02-06 14:42:51 | Stage | Epoch[413/600] LR:0.001

2023-02-06 14:42:51 | Train | Epoch[414/600] Iteration[001/030] Train loss: 0.0067
2023-02-06 14:42:52 | Train | Epoch[414/600] Iteration[002/030] Train loss: 0.0071
2023-02-06 14:42:52 | Train | Epoch[414/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 14:42:52 | Train | Epoch[414/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 14:42:52 | Train | Epoch[414/600] Iteration[005/030] Train loss: 0.0072
2023-02-06 14:42:52 | Train | Epoch[414/600] Iteration[006/030] Train loss: 0.0072
2023-02-06 14:42:53 | Train | Epoch[414/600] Iteration[007/030] Train loss: 0.0072
2023-02-06 14:42:53 | Train | Epoch[414/600] Iteration[008/030] Train loss: 0.0073
2023-02-06 14:42:53 | Train | Epoch[414/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 14:42:53 | Train | Epoch[414/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:42:53 | Train | Epoch[414/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:42:54 | Train | Epoch[414/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:42:54 | Train | Epoch[414/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:42:54 | Train | Epoch[414/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:42:54 | Train | Epoch[414/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:42:55 | Train | Epoch[414/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:42:55 | Train | Epoch[414/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:42:55 | Train | Epoch[414/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:42:55 | Train | Epoch[414/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:42:55 | Train | Epoch[414/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:42:56 | Train | Epoch[414/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:42:56 | Train | Epoch[414/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:42:56 | Train | Epoch[414/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:42:56 | Train | Epoch[414/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:42:57 | Train | Epoch[414/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:42:57 | Train | Epoch[414/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:42:57 | Train | Epoch[414/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:42:57 | Train | Epoch[414/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:42:57 | Train | Epoch[414/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:42:58 | Train | Epoch[414/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:42:58 | Valid | Epoch[414/600] Iteration[001/008] Valid loss: 0.1346
2023-02-06 14:42:58 | Valid | Epoch[414/600] Iteration[002/008] Valid loss: 0.1026
2023-02-06 14:42:58 | Valid | Epoch[414/600] Iteration[003/008] Valid loss: 0.0981
2023-02-06 14:42:58 | Valid | Epoch[414/600] Iteration[004/008] Valid loss: 0.0918
2023-02-06 14:42:58 | Valid | Epoch[414/600] Iteration[005/008] Valid loss: 0.0892
2023-02-06 14:42:58 | Valid | Epoch[414/600] Iteration[006/008] Valid loss: 0.0855
2023-02-06 14:42:58 | Valid | Epoch[414/600] Iteration[007/008] Valid loss: 0.0893
2023-02-06 14:42:58 | Valid | Epoch[414/600] Iteration[008/008] Valid loss: 0.0867
2023-02-06 14:42:58 | Valid | Epoch[414/600] MIou: 0.9257077843562286
2023-02-06 14:42:58 | Valid | Epoch[414/600] Pixel Accuracy: 0.9873644510904948
2023-02-06 14:42:58 | Valid | Epoch[414/600] Mean Pixel Accuracy: 0.9469724164764127
2023-02-06 14:42:58 | Stage | Epoch[414/600] Train loss:0.0079
2023-02-06 14:42:58 | Stage | Epoch[414/600] Valid loss:0.0867
2023-02-06 14:42:58 | Stage | Epoch[414/600] LR:0.001

2023-02-06 14:42:59 | Train | Epoch[415/600] Iteration[001/030] Train loss: 0.0081
2023-02-06 14:42:59 | Train | Epoch[415/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:42:59 | Train | Epoch[415/600] Iteration[003/030] Train loss: 0.0078
2023-02-06 14:42:59 | Train | Epoch[415/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:43:00 | Train | Epoch[415/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:43:00 | Train | Epoch[415/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:43:00 | Train | Epoch[415/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:43:00 | Train | Epoch[415/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:43:00 | Train | Epoch[415/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:43:01 | Train | Epoch[415/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:43:01 | Train | Epoch[415/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:43:01 | Train | Epoch[415/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:43:01 | Train | Epoch[415/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:43:02 | Train | Epoch[415/600] Iteration[014/030] Train loss: 0.0081
2023-02-06 14:43:02 | Train | Epoch[415/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:43:02 | Train | Epoch[415/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:43:02 | Train | Epoch[415/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:43:02 | Train | Epoch[415/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:43:03 | Train | Epoch[415/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:43:03 | Train | Epoch[415/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:43:03 | Train | Epoch[415/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:43:03 | Train | Epoch[415/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:43:04 | Train | Epoch[415/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:43:04 | Train | Epoch[415/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:43:04 | Train | Epoch[415/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:43:04 | Train | Epoch[415/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:43:04 | Train | Epoch[415/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:43:05 | Train | Epoch[415/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:43:05 | Train | Epoch[415/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:43:05 | Train | Epoch[415/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:43:05 | Valid | Epoch[415/600] Iteration[001/008] Valid loss: 0.1310
2023-02-06 14:43:05 | Valid | Epoch[415/600] Iteration[002/008] Valid loss: 0.1001
2023-02-06 14:43:05 | Valid | Epoch[415/600] Iteration[003/008] Valid loss: 0.0959
2023-02-06 14:43:05 | Valid | Epoch[415/600] Iteration[004/008] Valid loss: 0.0903
2023-02-06 14:43:06 | Valid | Epoch[415/600] Iteration[005/008] Valid loss: 0.0881
2023-02-06 14:43:06 | Valid | Epoch[415/600] Iteration[006/008] Valid loss: 0.0843
2023-02-06 14:43:06 | Valid | Epoch[415/600] Iteration[007/008] Valid loss: 0.0876
2023-02-06 14:43:06 | Valid | Epoch[415/600] Iteration[008/008] Valid loss: 0.0851
2023-02-06 14:43:06 | Valid | Epoch[415/600] MIou: 0.925517219962645
2023-02-06 14:43:06 | Valid | Epoch[415/600] Pixel Accuracy: 0.9873479207356771
2023-02-06 14:43:06 | Valid | Epoch[415/600] Mean Pixel Accuracy: 0.9462278359930011
2023-02-06 14:43:06 | Stage | Epoch[415/600] Train loss:0.0080
2023-02-06 14:43:06 | Stage | Epoch[415/600] Valid loss:0.0851
2023-02-06 14:43:06 | Stage | Epoch[415/600] LR:0.001

2023-02-06 14:43:06 | Train | Epoch[416/600] Iteration[001/030] Train loss: 0.0088
2023-02-06 14:43:06 | Train | Epoch[416/600] Iteration[002/030] Train loss: 0.0089
2023-02-06 14:43:07 | Train | Epoch[416/600] Iteration[003/030] Train loss: 0.0086
2023-02-06 14:43:07 | Train | Epoch[416/600] Iteration[004/030] Train loss: 0.0086
2023-02-06 14:43:07 | Train | Epoch[416/600] Iteration[005/030] Train loss: 0.0092
2023-02-06 14:43:07 | Train | Epoch[416/600] Iteration[006/030] Train loss: 0.0088
2023-02-06 14:43:08 | Train | Epoch[416/600] Iteration[007/030] Train loss: 0.0087
2023-02-06 14:43:08 | Train | Epoch[416/600] Iteration[008/030] Train loss: 0.0086
2023-02-06 14:43:08 | Train | Epoch[416/600] Iteration[009/030] Train loss: 0.0084
2023-02-06 14:43:08 | Train | Epoch[416/600] Iteration[010/030] Train loss: 0.0083
2023-02-06 14:43:08 | Train | Epoch[416/600] Iteration[011/030] Train loss: 0.0083
2023-02-06 14:43:09 | Train | Epoch[416/600] Iteration[012/030] Train loss: 0.0082
2023-02-06 14:43:09 | Train | Epoch[416/600] Iteration[013/030] Train loss: 0.0082
2023-02-06 14:43:09 | Train | Epoch[416/600] Iteration[014/030] Train loss: 0.0082
2023-02-06 14:43:09 | Train | Epoch[416/600] Iteration[015/030] Train loss: 0.0082
2023-02-06 14:43:10 | Train | Epoch[416/600] Iteration[016/030] Train loss: 0.0082
2023-02-06 14:43:10 | Train | Epoch[416/600] Iteration[017/030] Train loss: 0.0082
2023-02-06 14:43:10 | Train | Epoch[416/600] Iteration[018/030] Train loss: 0.0082
2023-02-06 14:43:10 | Train | Epoch[416/600] Iteration[019/030] Train loss: 0.0081
2023-02-06 14:43:10 | Train | Epoch[416/600] Iteration[020/030] Train loss: 0.0081
2023-02-06 14:43:11 | Train | Epoch[416/600] Iteration[021/030] Train loss: 0.0081
2023-02-06 14:43:11 | Train | Epoch[416/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:43:11 | Train | Epoch[416/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:43:11 | Train | Epoch[416/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:43:12 | Train | Epoch[416/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:43:12 | Train | Epoch[416/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:43:12 | Train | Epoch[416/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:43:12 | Train | Epoch[416/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:43:12 | Train | Epoch[416/600] Iteration[029/030] Train loss: 0.0081
2023-02-06 14:43:12 | Train | Epoch[416/600] Iteration[030/030] Train loss: 0.0081
2023-02-06 14:43:13 | Valid | Epoch[416/600] Iteration[001/008] Valid loss: 0.2115
2023-02-06 14:43:13 | Valid | Epoch[416/600] Iteration[002/008] Valid loss: 0.1650
2023-02-06 14:43:13 | Valid | Epoch[416/600] Iteration[003/008] Valid loss: 0.1575
2023-02-06 14:43:13 | Valid | Epoch[416/600] Iteration[004/008] Valid loss: 0.1488
2023-02-06 14:43:13 | Valid | Epoch[416/600] Iteration[005/008] Valid loss: 0.1478
2023-02-06 14:43:13 | Valid | Epoch[416/600] Iteration[006/008] Valid loss: 0.1441
2023-02-06 14:43:13 | Valid | Epoch[416/600] Iteration[007/008] Valid loss: 0.1547
2023-02-06 14:43:13 | Valid | Epoch[416/600] Iteration[008/008] Valid loss: 0.1531
2023-02-06 14:43:13 | Valid | Epoch[416/600] MIou: 0.9306297931070768
2023-02-06 14:43:13 | Valid | Epoch[416/600] Pixel Accuracy: 0.9878654479980469
2023-02-06 14:43:13 | Valid | Epoch[416/600] Mean Pixel Accuracy: 0.9646523800444637
2023-02-06 14:43:13 | Stage | Epoch[416/600] Train loss:0.0081
2023-02-06 14:43:13 | Stage | Epoch[416/600] Valid loss:0.1531
2023-02-06 14:43:13 | Stage | Epoch[416/600] LR:0.001

2023-02-06 14:43:14 | Train | Epoch[417/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 14:43:14 | Train | Epoch[417/600] Iteration[002/030] Train loss: 0.0080
2023-02-06 14:43:14 | Train | Epoch[417/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:43:14 | Train | Epoch[417/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:43:15 | Train | Epoch[417/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:43:15 | Train | Epoch[417/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:43:15 | Train | Epoch[417/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:43:15 | Train | Epoch[417/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:43:16 | Train | Epoch[417/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:43:16 | Train | Epoch[417/600] Iteration[010/030] Train loss: 0.0081
2023-02-06 14:43:16 | Train | Epoch[417/600] Iteration[011/030] Train loss: 0.0081
2023-02-06 14:43:16 | Train | Epoch[417/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:43:16 | Train | Epoch[417/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:43:17 | Train | Epoch[417/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:43:17 | Train | Epoch[417/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:43:17 | Train | Epoch[417/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:43:17 | Train | Epoch[417/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:43:18 | Train | Epoch[417/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:43:18 | Train | Epoch[417/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:43:18 | Train | Epoch[417/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:43:18 | Train | Epoch[417/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:43:18 | Train | Epoch[417/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:43:19 | Train | Epoch[417/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:43:19 | Train | Epoch[417/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:43:19 | Train | Epoch[417/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:43:19 | Train | Epoch[417/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:43:20 | Train | Epoch[417/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:43:20 | Train | Epoch[417/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:43:20 | Train | Epoch[417/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:43:20 | Train | Epoch[417/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:43:20 | Valid | Epoch[417/600] Iteration[001/008] Valid loss: 0.1587
2023-02-06 14:43:20 | Valid | Epoch[417/600] Iteration[002/008] Valid loss: 0.1217
2023-02-06 14:43:21 | Valid | Epoch[417/600] Iteration[003/008] Valid loss: 0.1149
2023-02-06 14:43:21 | Valid | Epoch[417/600] Iteration[004/008] Valid loss: 0.1077
2023-02-06 14:43:21 | Valid | Epoch[417/600] Iteration[005/008] Valid loss: 0.1055
2023-02-06 14:43:21 | Valid | Epoch[417/600] Iteration[006/008] Valid loss: 0.1017
2023-02-06 14:43:21 | Valid | Epoch[417/600] Iteration[007/008] Valid loss: 0.1073
2023-02-06 14:43:21 | Valid | Epoch[417/600] Iteration[008/008] Valid loss: 0.1049
2023-02-06 14:43:21 | Valid | Epoch[417/600] MIou: 0.9287286242109176
2023-02-06 14:43:21 | Valid | Epoch[417/600] Pixel Accuracy: 0.9877751668294271
2023-02-06 14:43:21 | Valid | Epoch[417/600] Mean Pixel Accuracy: 0.9536971466630143
2023-02-06 14:43:21 | Stage | Epoch[417/600] Train loss:0.0078
2023-02-06 14:43:21 | Stage | Epoch[417/600] Valid loss:0.1049
2023-02-06 14:43:21 | Stage | Epoch[417/600] LR:0.001

2023-02-06 14:43:21 | Train | Epoch[418/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 14:43:22 | Train | Epoch[418/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:43:22 | Train | Epoch[418/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:43:22 | Train | Epoch[418/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 14:43:22 | Train | Epoch[418/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:43:22 | Train | Epoch[418/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:43:23 | Train | Epoch[418/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:43:23 | Train | Epoch[418/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:43:23 | Train | Epoch[418/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:43:23 | Train | Epoch[418/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:43:24 | Train | Epoch[418/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:43:24 | Train | Epoch[418/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:43:24 | Train | Epoch[418/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:43:24 | Train | Epoch[418/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:43:24 | Train | Epoch[418/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:43:25 | Train | Epoch[418/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:43:25 | Train | Epoch[418/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:43:25 | Train | Epoch[418/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:43:25 | Train | Epoch[418/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:43:26 | Train | Epoch[418/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:43:26 | Train | Epoch[418/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:43:26 | Train | Epoch[418/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:43:26 | Train | Epoch[418/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:43:26 | Train | Epoch[418/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:43:27 | Train | Epoch[418/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:43:27 | Train | Epoch[418/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:43:27 | Train | Epoch[418/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:43:27 | Train | Epoch[418/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:43:27 | Train | Epoch[418/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:43:28 | Train | Epoch[418/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:43:28 | Valid | Epoch[418/600] Iteration[001/008] Valid loss: 0.1569
2023-02-06 14:43:28 | Valid | Epoch[418/600] Iteration[002/008] Valid loss: 0.1215
2023-02-06 14:43:28 | Valid | Epoch[418/600] Iteration[003/008] Valid loss: 0.1136
2023-02-06 14:43:28 | Valid | Epoch[418/600] Iteration[004/008] Valid loss: 0.1071
2023-02-06 14:43:28 | Valid | Epoch[418/600] Iteration[005/008] Valid loss: 0.1057
2023-02-06 14:43:28 | Valid | Epoch[418/600] Iteration[006/008] Valid loss: 0.1013
2023-02-06 14:43:28 | Valid | Epoch[418/600] Iteration[007/008] Valid loss: 0.1067
2023-02-06 14:43:28 | Valid | Epoch[418/600] Iteration[008/008] Valid loss: 0.1042
2023-02-06 14:43:28 | Valid | Epoch[418/600] MIou: 0.9294686850952254
2023-02-06 14:43:28 | Valid | Epoch[418/600] Pixel Accuracy: 0.9878997802734375
2023-02-06 14:43:28 | Valid | Epoch[418/600] Mean Pixel Accuracy: 0.9544947937503665
2023-02-06 14:43:28 | Stage | Epoch[418/600] Train loss:0.0079
2023-02-06 14:43:28 | Stage | Epoch[418/600] Valid loss:0.1042
2023-02-06 14:43:28 | Stage | Epoch[418/600] LR:0.001

2023-02-06 14:43:29 | Train | Epoch[419/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 14:43:29 | Train | Epoch[419/600] Iteration[002/030] Train loss: 0.0080
2023-02-06 14:43:29 | Train | Epoch[419/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:43:30 | Train | Epoch[419/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:43:30 | Train | Epoch[419/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:43:30 | Train | Epoch[419/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:43:30 | Train | Epoch[419/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:43:30 | Train | Epoch[419/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:43:31 | Train | Epoch[419/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:43:31 | Train | Epoch[419/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:43:31 | Train | Epoch[419/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:43:31 | Train | Epoch[419/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:43:31 | Train | Epoch[419/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:43:32 | Train | Epoch[419/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:43:32 | Train | Epoch[419/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:43:32 | Train | Epoch[419/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:43:32 | Train | Epoch[419/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:43:33 | Train | Epoch[419/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:43:33 | Train | Epoch[419/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:43:33 | Train | Epoch[419/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:43:33 | Train | Epoch[419/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:43:33 | Train | Epoch[419/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:43:34 | Train | Epoch[419/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:43:34 | Train | Epoch[419/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:43:34 | Train | Epoch[419/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:43:34 | Train | Epoch[419/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:43:35 | Train | Epoch[419/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:43:35 | Train | Epoch[419/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:43:35 | Train | Epoch[419/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:43:35 | Train | Epoch[419/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:43:35 | Valid | Epoch[419/600] Iteration[001/008] Valid loss: 0.2778
2023-02-06 14:43:35 | Valid | Epoch[419/600] Iteration[002/008] Valid loss: 0.2223
2023-02-06 14:43:36 | Valid | Epoch[419/600] Iteration[003/008] Valid loss: 0.2145
2023-02-06 14:43:36 | Valid | Epoch[419/600] Iteration[004/008] Valid loss: 0.2064
2023-02-06 14:43:36 | Valid | Epoch[419/600] Iteration[005/008] Valid loss: 0.2099
2023-02-06 14:43:36 | Valid | Epoch[419/600] Iteration[006/008] Valid loss: 0.2056
2023-02-06 14:43:36 | Valid | Epoch[419/600] Iteration[007/008] Valid loss: 0.2228
2023-02-06 14:43:36 | Valid | Epoch[419/600] Iteration[008/008] Valid loss: 0.2235
2023-02-06 14:43:36 | Valid | Epoch[419/600] MIou: 0.927573205247207
2023-02-06 14:43:36 | Valid | Epoch[419/600] Pixel Accuracy: 0.9870567321777344
2023-02-06 14:43:36 | Valid | Epoch[419/600] Mean Pixel Accuracy: 0.9718227816247322
2023-02-06 14:43:36 | Stage | Epoch[419/600] Train loss:0.0080
2023-02-06 14:43:36 | Stage | Epoch[419/600] Valid loss:0.2235
2023-02-06 14:43:36 | Stage | Epoch[419/600] LR:0.001

2023-02-06 14:43:36 | Train | Epoch[420/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:43:37 | Train | Epoch[420/600] Iteration[002/030] Train loss: 0.0073
2023-02-06 14:43:37 | Train | Epoch[420/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:43:37 | Train | Epoch[420/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:43:37 | Train | Epoch[420/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:43:37 | Train | Epoch[420/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:43:38 | Train | Epoch[420/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:43:38 | Train | Epoch[420/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:43:38 | Train | Epoch[420/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:43:38 | Train | Epoch[420/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:43:38 | Train | Epoch[420/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:43:39 | Train | Epoch[420/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:43:39 | Train | Epoch[420/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:43:39 | Train | Epoch[420/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:43:39 | Train | Epoch[420/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:43:40 | Train | Epoch[420/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:43:40 | Train | Epoch[420/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:43:40 | Train | Epoch[420/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:43:40 | Train | Epoch[420/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:43:40 | Train | Epoch[420/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:43:41 | Train | Epoch[420/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:43:41 | Train | Epoch[420/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:43:41 | Train | Epoch[420/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:43:41 | Train | Epoch[420/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:43:42 | Train | Epoch[420/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:43:42 | Train | Epoch[420/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:43:42 | Train | Epoch[420/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:43:42 | Train | Epoch[420/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:43:42 | Train | Epoch[420/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:43:43 | Train | Epoch[420/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:43:43 | Valid | Epoch[420/600] Iteration[001/008] Valid loss: 0.1747
2023-02-06 14:43:43 | Valid | Epoch[420/600] Iteration[002/008] Valid loss: 0.1360
2023-02-06 14:43:43 | Valid | Epoch[420/600] Iteration[003/008] Valid loss: 0.1274
2023-02-06 14:43:43 | Valid | Epoch[420/600] Iteration[004/008] Valid loss: 0.1204
2023-02-06 14:43:43 | Valid | Epoch[420/600] Iteration[005/008] Valid loss: 0.1193
2023-02-06 14:43:43 | Valid | Epoch[420/600] Iteration[006/008] Valid loss: 0.1148
2023-02-06 14:43:43 | Valid | Epoch[420/600] Iteration[007/008] Valid loss: 0.1227
2023-02-06 14:43:43 | Valid | Epoch[420/600] Iteration[008/008] Valid loss: 0.1209
2023-02-06 14:43:43 | Valid | Epoch[420/600] MIou: 0.9308055621108916
2023-02-06 14:43:43 | Valid | Epoch[420/600] Pixel Accuracy: 0.9880485534667969
2023-02-06 14:43:43 | Valid | Epoch[420/600] Mean Pixel Accuracy: 0.9589007674136985
2023-02-06 14:43:43 | Stage | Epoch[420/600] Train loss:0.0078
2023-02-06 14:43:43 | Stage | Epoch[420/600] Valid loss:0.1209
2023-02-06 14:43:43 | Stage | Epoch[420/600] LR:0.001

2023-02-06 14:43:44 | Train | Epoch[421/600] Iteration[001/030] Train loss: 0.0059
2023-02-06 14:43:44 | Train | Epoch[421/600] Iteration[002/030] Train loss: 0.0071
2023-02-06 14:43:44 | Train | Epoch[421/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:43:44 | Train | Epoch[421/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 14:43:45 | Train | Epoch[421/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:43:45 | Train | Epoch[421/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:43:45 | Train | Epoch[421/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:43:45 | Train | Epoch[421/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:43:46 | Train | Epoch[421/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:43:46 | Train | Epoch[421/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:43:46 | Train | Epoch[421/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:43:46 | Train | Epoch[421/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:43:46 | Train | Epoch[421/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:43:47 | Train | Epoch[421/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:43:47 | Train | Epoch[421/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:43:47 | Train | Epoch[421/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:43:47 | Train | Epoch[421/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:43:47 | Train | Epoch[421/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:43:48 | Train | Epoch[421/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:43:48 | Train | Epoch[421/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:43:48 | Train | Epoch[421/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:43:48 | Train | Epoch[421/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:43:49 | Train | Epoch[421/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:43:49 | Train | Epoch[421/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:43:49 | Train | Epoch[421/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:43:49 | Train | Epoch[421/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:43:49 | Train | Epoch[421/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:43:50 | Train | Epoch[421/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:43:50 | Train | Epoch[421/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:43:50 | Train | Epoch[421/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:43:50 | Valid | Epoch[421/600] Iteration[001/008] Valid loss: 0.1985
2023-02-06 14:43:50 | Valid | Epoch[421/600] Iteration[002/008] Valid loss: 0.1552
2023-02-06 14:43:50 | Valid | Epoch[421/600] Iteration[003/008] Valid loss: 0.1492
2023-02-06 14:43:50 | Valid | Epoch[421/600] Iteration[004/008] Valid loss: 0.1407
2023-02-06 14:43:51 | Valid | Epoch[421/600] Iteration[005/008] Valid loss: 0.1397
2023-02-06 14:43:51 | Valid | Epoch[421/600] Iteration[006/008] Valid loss: 0.1358
2023-02-06 14:43:51 | Valid | Epoch[421/600] Iteration[007/008] Valid loss: 0.1458
2023-02-06 14:43:51 | Valid | Epoch[421/600] Iteration[008/008] Valid loss: 0.1437
2023-02-06 14:43:51 | Valid | Epoch[421/600] MIou: 0.9301819826605615
2023-02-06 14:43:51 | Valid | Epoch[421/600] Pixel Accuracy: 0.9878425598144531
2023-02-06 14:43:51 | Valid | Epoch[421/600] Mean Pixel Accuracy: 0.9620782492317229
2023-02-06 14:43:51 | Stage | Epoch[421/600] Train loss:0.0079
2023-02-06 14:43:51 | Stage | Epoch[421/600] Valid loss:0.1437
2023-02-06 14:43:51 | Stage | Epoch[421/600] LR:0.001

2023-02-06 14:43:51 | Train | Epoch[422/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:43:51 | Train | Epoch[422/600] Iteration[002/030] Train loss: 0.0068
2023-02-06 14:43:52 | Train | Epoch[422/600] Iteration[003/030] Train loss: 0.0070
2023-02-06 14:43:52 | Train | Epoch[422/600] Iteration[004/030] Train loss: 0.0070
2023-02-06 14:43:52 | Train | Epoch[422/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 14:43:52 | Train | Epoch[422/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:43:53 | Train | Epoch[422/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:43:53 | Train | Epoch[422/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:43:53 | Train | Epoch[422/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:43:53 | Train | Epoch[422/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:43:53 | Train | Epoch[422/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:43:54 | Train | Epoch[422/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:43:54 | Train | Epoch[422/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:43:54 | Train | Epoch[422/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:43:54 | Train | Epoch[422/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:43:55 | Train | Epoch[422/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:43:55 | Train | Epoch[422/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:43:55 | Train | Epoch[422/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:43:55 | Train | Epoch[422/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:43:55 | Train | Epoch[422/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:43:56 | Train | Epoch[422/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:43:56 | Train | Epoch[422/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:43:56 | Train | Epoch[422/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:43:56 | Train | Epoch[422/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:43:56 | Train | Epoch[422/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:43:57 | Train | Epoch[422/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:43:57 | Train | Epoch[422/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:43:57 | Train | Epoch[422/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:43:57 | Train | Epoch[422/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:43:57 | Train | Epoch[422/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:43:58 | Valid | Epoch[422/600] Iteration[001/008] Valid loss: 0.1874
2023-02-06 14:43:58 | Valid | Epoch[422/600] Iteration[002/008] Valid loss: 0.1476
2023-02-06 14:43:58 | Valid | Epoch[422/600] Iteration[003/008] Valid loss: 0.1417
2023-02-06 14:43:58 | Valid | Epoch[422/600] Iteration[004/008] Valid loss: 0.1343
2023-02-06 14:43:58 | Valid | Epoch[422/600] Iteration[005/008] Valid loss: 0.1340
2023-02-06 14:43:58 | Valid | Epoch[422/600] Iteration[006/008] Valid loss: 0.1299
2023-02-06 14:43:58 | Valid | Epoch[422/600] Iteration[007/008] Valid loss: 0.1387
2023-02-06 14:43:58 | Valid | Epoch[422/600] Iteration[008/008] Valid loss: 0.1367
2023-02-06 14:43:58 | Valid | Epoch[422/600] MIou: 0.9311413125519632
2023-02-06 14:43:58 | Valid | Epoch[422/600] Pixel Accuracy: 0.9880409240722656
2023-02-06 14:43:58 | Valid | Epoch[422/600] Mean Pixel Accuracy: 0.9617878289825866
2023-02-06 14:43:58 | Stage | Epoch[422/600] Train loss:0.0079
2023-02-06 14:43:58 | Stage | Epoch[422/600] Valid loss:0.1367
2023-02-06 14:43:58 | Stage | Epoch[422/600] LR:0.001

2023-02-06 14:43:59 | Train | Epoch[423/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 14:43:59 | Train | Epoch[423/600] Iteration[002/030] Train loss: 0.0087
2023-02-06 14:43:59 | Train | Epoch[423/600] Iteration[003/030] Train loss: 0.0084
2023-02-06 14:43:59 | Train | Epoch[423/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:44:00 | Train | Epoch[423/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 14:44:00 | Train | Epoch[423/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:44:00 | Train | Epoch[423/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:44:00 | Train | Epoch[423/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:44:00 | Train | Epoch[423/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:44:01 | Train | Epoch[423/600] Iteration[010/030] Train loss: 0.0082
2023-02-06 14:44:01 | Train | Epoch[423/600] Iteration[011/030] Train loss: 0.0081
2023-02-06 14:44:01 | Train | Epoch[423/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:44:01 | Train | Epoch[423/600] Iteration[013/030] Train loss: 0.0082
2023-02-06 14:44:02 | Train | Epoch[423/600] Iteration[014/030] Train loss: 0.0082
2023-02-06 14:44:02 | Train | Epoch[423/600] Iteration[015/030] Train loss: 0.0082
2023-02-06 14:44:02 | Train | Epoch[423/600] Iteration[016/030] Train loss: 0.0083
2023-02-06 14:44:02 | Train | Epoch[423/600] Iteration[017/030] Train loss: 0.0083
2023-02-06 14:44:02 | Train | Epoch[423/600] Iteration[018/030] Train loss: 0.0083
2023-02-06 14:44:03 | Train | Epoch[423/600] Iteration[019/030] Train loss: 0.0083
2023-02-06 14:44:03 | Train | Epoch[423/600] Iteration[020/030] Train loss: 0.0083
2023-02-06 14:44:03 | Train | Epoch[423/600] Iteration[021/030] Train loss: 0.0083
2023-02-06 14:44:03 | Train | Epoch[423/600] Iteration[022/030] Train loss: 0.0082
2023-02-06 14:44:04 | Train | Epoch[423/600] Iteration[023/030] Train loss: 0.0083
2023-02-06 14:44:04 | Train | Epoch[423/600] Iteration[024/030] Train loss: 0.0082
2023-02-06 14:44:04 | Train | Epoch[423/600] Iteration[025/030] Train loss: 0.0082
2023-02-06 14:44:04 | Train | Epoch[423/600] Iteration[026/030] Train loss: 0.0082
2023-02-06 14:44:04 | Train | Epoch[423/600] Iteration[027/030] Train loss: 0.0082
2023-02-06 14:44:05 | Train | Epoch[423/600] Iteration[028/030] Train loss: 0.0082
2023-02-06 14:44:05 | Train | Epoch[423/600] Iteration[029/030] Train loss: 0.0082
2023-02-06 14:44:05 | Train | Epoch[423/600] Iteration[030/030] Train loss: 0.0082
2023-02-06 14:44:05 | Valid | Epoch[423/600] Iteration[001/008] Valid loss: 0.1838
2023-02-06 14:44:05 | Valid | Epoch[423/600] Iteration[002/008] Valid loss: 0.1460
2023-02-06 14:44:05 | Valid | Epoch[423/600] Iteration[003/008] Valid loss: 0.1393
2023-02-06 14:44:05 | Valid | Epoch[423/600] Iteration[004/008] Valid loss: 0.1319
2023-02-06 14:44:05 | Valid | Epoch[423/600] Iteration[005/008] Valid loss: 0.1304
2023-02-06 14:44:06 | Valid | Epoch[423/600] Iteration[006/008] Valid loss: 0.1260
2023-02-06 14:44:06 | Valid | Epoch[423/600] Iteration[007/008] Valid loss: 0.1349
2023-02-06 14:44:06 | Valid | Epoch[423/600] Iteration[008/008] Valid loss: 0.1328
2023-02-06 14:44:06 | Valid | Epoch[423/600] MIou: 0.9304917160132767
2023-02-06 14:44:06 | Valid | Epoch[423/600] Pixel Accuracy: 0.9879328409830729
2023-02-06 14:44:06 | Valid | Epoch[423/600] Mean Pixel Accuracy: 0.9609739057971965
2023-02-06 14:44:06 | Stage | Epoch[423/600] Train loss:0.0082
2023-02-06 14:44:06 | Stage | Epoch[423/600] Valid loss:0.1328
2023-02-06 14:44:06 | Stage | Epoch[423/600] LR:0.001

2023-02-06 14:44:06 | Train | Epoch[424/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 14:44:06 | Train | Epoch[424/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:44:07 | Train | Epoch[424/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:44:07 | Train | Epoch[424/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:44:07 | Train | Epoch[424/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:44:07 | Train | Epoch[424/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:44:07 | Train | Epoch[424/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:44:08 | Train | Epoch[424/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:44:08 | Train | Epoch[424/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:44:08 | Train | Epoch[424/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:44:08 | Train | Epoch[424/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:44:09 | Train | Epoch[424/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:44:09 | Train | Epoch[424/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:44:09 | Train | Epoch[424/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:44:09 | Train | Epoch[424/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:44:09 | Train | Epoch[424/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:44:10 | Train | Epoch[424/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:44:10 | Train | Epoch[424/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:44:10 | Train | Epoch[424/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:44:10 | Train | Epoch[424/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:44:11 | Train | Epoch[424/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:44:11 | Train | Epoch[424/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:44:11 | Train | Epoch[424/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:44:11 | Train | Epoch[424/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:44:11 | Train | Epoch[424/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:44:12 | Train | Epoch[424/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:44:12 | Train | Epoch[424/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:44:12 | Train | Epoch[424/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:44:12 | Train | Epoch[424/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:44:12 | Train | Epoch[424/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:44:13 | Valid | Epoch[424/600] Iteration[001/008] Valid loss: 0.1435
2023-02-06 14:44:13 | Valid | Epoch[424/600] Iteration[002/008] Valid loss: 0.1118
2023-02-06 14:44:13 | Valid | Epoch[424/600] Iteration[003/008] Valid loss: 0.1072
2023-02-06 14:44:13 | Valid | Epoch[424/600] Iteration[004/008] Valid loss: 0.1010
2023-02-06 14:44:13 | Valid | Epoch[424/600] Iteration[005/008] Valid loss: 0.0984
2023-02-06 14:44:13 | Valid | Epoch[424/600] Iteration[006/008] Valid loss: 0.0948
2023-02-06 14:44:13 | Valid | Epoch[424/600] Iteration[007/008] Valid loss: 0.0994
2023-02-06 14:44:13 | Valid | Epoch[424/600] Iteration[008/008] Valid loss: 0.0969
2023-02-06 14:44:13 | Valid | Epoch[424/600] MIou: 0.9269226034625437
2023-02-06 14:44:13 | Valid | Epoch[424/600] Pixel Accuracy: 0.9875144958496094
2023-02-06 14:44:13 | Valid | Epoch[424/600] Mean Pixel Accuracy: 0.9501807399307316
2023-02-06 14:44:13 | Stage | Epoch[424/600] Train loss:0.0078
2023-02-06 14:44:13 | Stage | Epoch[424/600] Valid loss:0.0969
2023-02-06 14:44:13 | Stage | Epoch[424/600] LR:0.001

2023-02-06 14:44:14 | Train | Epoch[425/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 14:44:14 | Train | Epoch[425/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 14:44:14 | Train | Epoch[425/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:44:14 | Train | Epoch[425/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:44:15 | Train | Epoch[425/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:44:15 | Train | Epoch[425/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:44:15 | Train | Epoch[425/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:44:15 | Train | Epoch[425/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:44:16 | Train | Epoch[425/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:44:16 | Train | Epoch[425/600] Iteration[010/030] Train loss: 0.0083
2023-02-06 14:44:16 | Train | Epoch[425/600] Iteration[011/030] Train loss: 0.0081
2023-02-06 14:44:16 | Train | Epoch[425/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:44:16 | Train | Epoch[425/600] Iteration[013/030] Train loss: 0.0087
2023-02-06 14:44:17 | Train | Epoch[425/600] Iteration[014/030] Train loss: 0.0086
2023-02-06 14:44:17 | Train | Epoch[425/600] Iteration[015/030] Train loss: 0.0086
2023-02-06 14:44:17 | Train | Epoch[425/600] Iteration[016/030] Train loss: 0.0085
2023-02-06 14:44:17 | Train | Epoch[425/600] Iteration[017/030] Train loss: 0.0084
2023-02-06 14:44:18 | Train | Epoch[425/600] Iteration[018/030] Train loss: 0.0084
2023-02-06 14:44:18 | Train | Epoch[425/600] Iteration[019/030] Train loss: 0.0085
2023-02-06 14:44:18 | Train | Epoch[425/600] Iteration[020/030] Train loss: 0.0085
2023-02-06 14:44:18 | Train | Epoch[425/600] Iteration[021/030] Train loss: 0.0085
2023-02-06 14:44:18 | Train | Epoch[425/600] Iteration[022/030] Train loss: 0.0084
2023-02-06 14:44:19 | Train | Epoch[425/600] Iteration[023/030] Train loss: 0.0084
2023-02-06 14:44:19 | Train | Epoch[425/600] Iteration[024/030] Train loss: 0.0083
2023-02-06 14:44:19 | Train | Epoch[425/600] Iteration[025/030] Train loss: 0.0083
2023-02-06 14:44:19 | Train | Epoch[425/600] Iteration[026/030] Train loss: 0.0083
2023-02-06 14:44:20 | Train | Epoch[425/600] Iteration[027/030] Train loss: 0.0083
2023-02-06 14:44:20 | Train | Epoch[425/600] Iteration[028/030] Train loss: 0.0082
2023-02-06 14:44:20 | Train | Epoch[425/600] Iteration[029/030] Train loss: 0.0082
2023-02-06 14:44:20 | Train | Epoch[425/600] Iteration[030/030] Train loss: 0.0082
2023-02-06 14:44:21 | Valid | Epoch[425/600] Iteration[001/008] Valid loss: 0.1590
2023-02-06 14:44:21 | Valid | Epoch[425/600] Iteration[002/008] Valid loss: 0.1231
2023-02-06 14:44:21 | Valid | Epoch[425/600] Iteration[003/008] Valid loss: 0.1168
2023-02-06 14:44:21 | Valid | Epoch[425/600] Iteration[004/008] Valid loss: 0.1100
2023-02-06 14:44:21 | Valid | Epoch[425/600] Iteration[005/008] Valid loss: 0.1089
2023-02-06 14:44:21 | Valid | Epoch[425/600] Iteration[006/008] Valid loss: 0.1049
2023-02-06 14:44:21 | Valid | Epoch[425/600] Iteration[007/008] Valid loss: 0.1116
2023-02-06 14:44:21 | Valid | Epoch[425/600] Iteration[008/008] Valid loss: 0.1095
2023-02-06 14:44:21 | Valid | Epoch[425/600] MIou: 0.9292927057915292
2023-02-06 14:44:21 | Valid | Epoch[425/600] Pixel Accuracy: 0.9878489176432291
2023-02-06 14:44:21 | Valid | Epoch[425/600] Mean Pixel Accuracy: 0.9551072251022853
2023-02-06 14:44:21 | Stage | Epoch[425/600] Train loss:0.0082
2023-02-06 14:44:21 | Stage | Epoch[425/600] Valid loss:0.1095
2023-02-06 14:44:21 | Stage | Epoch[425/600] LR:0.001

2023-02-06 14:44:22 | Train | Epoch[426/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 14:44:22 | Train | Epoch[426/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:44:22 | Train | Epoch[426/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:44:22 | Train | Epoch[426/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:44:22 | Train | Epoch[426/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:44:23 | Train | Epoch[426/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 14:44:23 | Train | Epoch[426/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:44:23 | Train | Epoch[426/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:44:23 | Train | Epoch[426/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:44:24 | Train | Epoch[426/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:44:24 | Train | Epoch[426/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:44:24 | Train | Epoch[426/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:44:24 | Train | Epoch[426/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:44:24 | Train | Epoch[426/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:44:25 | Train | Epoch[426/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:44:25 | Train | Epoch[426/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:44:25 | Train | Epoch[426/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:44:25 | Train | Epoch[426/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:44:26 | Train | Epoch[426/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:44:26 | Train | Epoch[426/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:44:26 | Train | Epoch[426/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:44:26 | Train | Epoch[426/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:44:26 | Train | Epoch[426/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:44:27 | Train | Epoch[426/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:44:27 | Train | Epoch[426/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:44:27 | Train | Epoch[426/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:44:27 | Train | Epoch[426/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:44:28 | Train | Epoch[426/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:44:28 | Train | Epoch[426/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:44:28 | Train | Epoch[426/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:44:28 | Valid | Epoch[426/600] Iteration[001/008] Valid loss: 0.1816
2023-02-06 14:44:28 | Valid | Epoch[426/600] Iteration[002/008] Valid loss: 0.1423
2023-02-06 14:44:28 | Valid | Epoch[426/600] Iteration[003/008] Valid loss: 0.1360
2023-02-06 14:44:28 | Valid | Epoch[426/600] Iteration[004/008] Valid loss: 0.1294
2023-02-06 14:44:28 | Valid | Epoch[426/600] Iteration[005/008] Valid loss: 0.1287
2023-02-06 14:44:28 | Valid | Epoch[426/600] Iteration[006/008] Valid loss: 0.1247
2023-02-06 14:44:28 | Valid | Epoch[426/600] Iteration[007/008] Valid loss: 0.1337
2023-02-06 14:44:28 | Valid | Epoch[426/600] Iteration[008/008] Valid loss: 0.1318
2023-02-06 14:44:29 | Valid | Epoch[426/600] MIou: 0.9306871232323863
2023-02-06 14:44:29 | Valid | Epoch[426/600] Pixel Accuracy: 0.9879735310872396
2023-02-06 14:44:29 | Valid | Epoch[426/600] Mean Pixel Accuracy: 0.9609011637411563
2023-02-06 14:44:29 | Stage | Epoch[426/600] Train loss:0.0079
2023-02-06 14:44:29 | Stage | Epoch[426/600] Valid loss:0.1318
2023-02-06 14:44:29 | Stage | Epoch[426/600] LR:0.001

2023-02-06 14:44:29 | Train | Epoch[427/600] Iteration[001/030] Train loss: 0.0086
2023-02-06 14:44:29 | Train | Epoch[427/600] Iteration[002/030] Train loss: 0.0084
2023-02-06 14:44:30 | Train | Epoch[427/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:44:30 | Train | Epoch[427/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:44:30 | Train | Epoch[427/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:44:30 | Train | Epoch[427/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:44:30 | Train | Epoch[427/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:44:31 | Train | Epoch[427/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:44:31 | Train | Epoch[427/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:44:31 | Train | Epoch[427/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:44:31 | Train | Epoch[427/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:44:31 | Train | Epoch[427/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:44:32 | Train | Epoch[427/600] Iteration[013/030] Train loss: 0.0081
2023-02-06 14:44:32 | Train | Epoch[427/600] Iteration[014/030] Train loss: 0.0081
2023-02-06 14:44:32 | Train | Epoch[427/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 14:44:32 | Train | Epoch[427/600] Iteration[016/030] Train loss: 0.0081
2023-02-06 14:44:33 | Train | Epoch[427/600] Iteration[017/030] Train loss: 0.0081
2023-02-06 14:44:33 | Train | Epoch[427/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:44:33 | Train | Epoch[427/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:44:33 | Train | Epoch[427/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:44:33 | Train | Epoch[427/600] Iteration[021/030] Train loss: 0.0081
2023-02-06 14:44:34 | Train | Epoch[427/600] Iteration[022/030] Train loss: 0.0081
2023-02-06 14:44:34 | Train | Epoch[427/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:44:34 | Train | Epoch[427/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:44:34 | Train | Epoch[427/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:44:35 | Train | Epoch[427/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:44:35 | Train | Epoch[427/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:44:35 | Train | Epoch[427/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:44:35 | Train | Epoch[427/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:44:35 | Train | Epoch[427/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:44:36 | Valid | Epoch[427/600] Iteration[001/008] Valid loss: 0.1231
2023-02-06 14:44:36 | Valid | Epoch[427/600] Iteration[002/008] Valid loss: 0.0951
2023-02-06 14:44:36 | Valid | Epoch[427/600] Iteration[003/008] Valid loss: 0.0923
2023-02-06 14:44:36 | Valid | Epoch[427/600] Iteration[004/008] Valid loss: 0.0877
2023-02-06 14:44:36 | Valid | Epoch[427/600] Iteration[005/008] Valid loss: 0.0850
2023-02-06 14:44:36 | Valid | Epoch[427/600] Iteration[006/008] Valid loss: 0.0818
2023-02-06 14:44:36 | Valid | Epoch[427/600] Iteration[007/008] Valid loss: 0.0845
2023-02-06 14:44:36 | Valid | Epoch[427/600] Iteration[008/008] Valid loss: 0.0821
2023-02-06 14:44:36 | Valid | Epoch[427/600] MIou: 0.922222455110331
2023-02-06 14:44:36 | Valid | Epoch[427/600] Pixel Accuracy: 0.9868253072102865
2023-02-06 14:44:36 | Valid | Epoch[427/600] Mean Pixel Accuracy: 0.9418509811852271
2023-02-06 14:44:36 | Stage | Epoch[427/600] Train loss:0.0080
2023-02-06 14:44:36 | Stage | Epoch[427/600] Valid loss:0.0821
2023-02-06 14:44:36 | Stage | Epoch[427/600] LR:0.001

2023-02-06 14:44:37 | Train | Epoch[428/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 14:44:37 | Train | Epoch[428/600] Iteration[002/030] Train loss: 0.0069
2023-02-06 14:44:37 | Train | Epoch[428/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:44:37 | Train | Epoch[428/600] Iteration[004/030] Train loss: 0.0076
2023-02-06 14:44:37 | Train | Epoch[428/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:44:38 | Train | Epoch[428/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 14:44:38 | Train | Epoch[428/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:44:38 | Train | Epoch[428/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:44:38 | Train | Epoch[428/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:44:39 | Train | Epoch[428/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:44:39 | Train | Epoch[428/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:44:39 | Train | Epoch[428/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:44:39 | Train | Epoch[428/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:44:39 | Train | Epoch[428/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:44:40 | Train | Epoch[428/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:44:40 | Train | Epoch[428/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:44:40 | Train | Epoch[428/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:44:40 | Train | Epoch[428/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:44:41 | Train | Epoch[428/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:44:41 | Train | Epoch[428/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:44:41 | Train | Epoch[428/600] Iteration[021/030] Train loss: 0.0081
2023-02-06 14:44:41 | Train | Epoch[428/600] Iteration[022/030] Train loss: 0.0082
2023-02-06 14:44:41 | Train | Epoch[428/600] Iteration[023/030] Train loss: 0.0082
2023-02-06 14:44:42 | Train | Epoch[428/600] Iteration[024/030] Train loss: 0.0081
2023-02-06 14:44:42 | Train | Epoch[428/600] Iteration[025/030] Train loss: 0.0081
2023-02-06 14:44:42 | Train | Epoch[428/600] Iteration[026/030] Train loss: 0.0081
2023-02-06 14:44:42 | Train | Epoch[428/600] Iteration[027/030] Train loss: 0.0081
2023-02-06 14:44:42 | Train | Epoch[428/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:44:43 | Train | Epoch[428/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:44:43 | Train | Epoch[428/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:44:43 | Valid | Epoch[428/600] Iteration[001/008] Valid loss: 0.1703
2023-02-06 14:44:43 | Valid | Epoch[428/600] Iteration[002/008] Valid loss: 0.1314
2023-02-06 14:44:43 | Valid | Epoch[428/600] Iteration[003/008] Valid loss: 0.1241
2023-02-06 14:44:43 | Valid | Epoch[428/600] Iteration[004/008] Valid loss: 0.1169
2023-02-06 14:44:43 | Valid | Epoch[428/600] Iteration[005/008] Valid loss: 0.1157
2023-02-06 14:44:43 | Valid | Epoch[428/600] Iteration[006/008] Valid loss: 0.1116
2023-02-06 14:44:44 | Valid | Epoch[428/600] Iteration[007/008] Valid loss: 0.1183
2023-02-06 14:44:44 | Valid | Epoch[428/600] Iteration[008/008] Valid loss: 0.1164
2023-02-06 14:44:44 | Valid | Epoch[428/600] MIou: 0.9297687910726353
2023-02-06 14:44:44 | Valid | Epoch[428/600] Pixel Accuracy: 0.9879010518391927
2023-02-06 14:44:44 | Valid | Epoch[428/600] Mean Pixel Accuracy: 0.9566956362718282
2023-02-06 14:44:44 | Stage | Epoch[428/600] Train loss:0.0080
2023-02-06 14:44:44 | Stage | Epoch[428/600] Valid loss:0.1164
2023-02-06 14:44:44 | Stage | Epoch[428/600] LR:0.001

2023-02-06 14:44:44 | Train | Epoch[429/600] Iteration[001/030] Train loss: 0.0089
2023-02-06 14:44:44 | Train | Epoch[429/600] Iteration[002/030] Train loss: 0.0083
2023-02-06 14:44:45 | Train | Epoch[429/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:44:45 | Train | Epoch[429/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:44:45 | Train | Epoch[429/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:44:45 | Train | Epoch[429/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 14:44:45 | Train | Epoch[429/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:44:46 | Train | Epoch[429/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:44:46 | Train | Epoch[429/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:44:46 | Train | Epoch[429/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:44:46 | Train | Epoch[429/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:44:46 | Train | Epoch[429/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:44:47 | Train | Epoch[429/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:44:47 | Train | Epoch[429/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:44:47 | Train | Epoch[429/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:44:47 | Train | Epoch[429/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:44:48 | Train | Epoch[429/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:44:48 | Train | Epoch[429/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:44:48 | Train | Epoch[429/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:44:48 | Train | Epoch[429/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:44:48 | Train | Epoch[429/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:44:49 | Train | Epoch[429/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:44:49 | Train | Epoch[429/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:44:49 | Train | Epoch[429/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:44:49 | Train | Epoch[429/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:44:50 | Train | Epoch[429/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:44:50 | Train | Epoch[429/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:44:50 | Train | Epoch[429/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:44:50 | Train | Epoch[429/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:44:50 | Train | Epoch[429/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:44:51 | Valid | Epoch[429/600] Iteration[001/008] Valid loss: 0.1707
2023-02-06 14:44:51 | Valid | Epoch[429/600] Iteration[002/008] Valid loss: 0.1342
2023-02-06 14:44:51 | Valid | Epoch[429/600] Iteration[003/008] Valid loss: 0.1285
2023-02-06 14:44:51 | Valid | Epoch[429/600] Iteration[004/008] Valid loss: 0.1216
2023-02-06 14:44:51 | Valid | Epoch[429/600] Iteration[005/008] Valid loss: 0.1199
2023-02-06 14:44:51 | Valid | Epoch[429/600] Iteration[006/008] Valid loss: 0.1161
2023-02-06 14:44:51 | Valid | Epoch[429/600] Iteration[007/008] Valid loss: 0.1240
2023-02-06 14:44:51 | Valid | Epoch[429/600] Iteration[008/008] Valid loss: 0.1221
2023-02-06 14:44:51 | Valid | Epoch[429/600] MIou: 0.9288448144063519
2023-02-06 14:44:51 | Valid | Epoch[429/600] Pixel Accuracy: 0.9876988728841146
2023-02-06 14:44:51 | Valid | Epoch[429/600] Mean Pixel Accuracy: 0.9574214523349879
2023-02-06 14:44:51 | Stage | Epoch[429/600] Train loss:0.0078
2023-02-06 14:44:51 | Stage | Epoch[429/600] Valid loss:0.1221
2023-02-06 14:44:51 | Stage | Epoch[429/600] LR:0.001

2023-02-06 14:44:52 | Train | Epoch[430/600] Iteration[001/030] Train loss: 0.0086
2023-02-06 14:44:52 | Train | Epoch[430/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 14:44:52 | Train | Epoch[430/600] Iteration[003/030] Train loss: 0.0081
2023-02-06 14:44:52 | Train | Epoch[430/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:44:52 | Train | Epoch[430/600] Iteration[005/030] Train loss: 0.0083
2023-02-06 14:44:53 | Train | Epoch[430/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:44:53 | Train | Epoch[430/600] Iteration[007/030] Train loss: 0.0083
2023-02-06 14:44:53 | Train | Epoch[430/600] Iteration[008/030] Train loss: 0.0082
2023-02-06 14:44:53 | Train | Epoch[430/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:44:54 | Train | Epoch[430/600] Iteration[010/030] Train loss: 0.0081
2023-02-06 14:44:54 | Train | Epoch[430/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:44:54 | Train | Epoch[430/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:44:54 | Train | Epoch[430/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:44:54 | Train | Epoch[430/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:44:55 | Train | Epoch[430/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:44:55 | Train | Epoch[430/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:44:55 | Train | Epoch[430/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:44:55 | Train | Epoch[430/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:44:56 | Train | Epoch[430/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:44:56 | Train | Epoch[430/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:44:56 | Train | Epoch[430/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:44:56 | Train | Epoch[430/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:44:56 | Train | Epoch[430/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:44:57 | Train | Epoch[430/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:44:57 | Train | Epoch[430/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:44:57 | Train | Epoch[430/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:44:57 | Train | Epoch[430/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:44:57 | Train | Epoch[430/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:44:58 | Train | Epoch[430/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:44:58 | Train | Epoch[430/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:44:58 | Valid | Epoch[430/600] Iteration[001/008] Valid loss: 0.1357
2023-02-06 14:44:58 | Valid | Epoch[430/600] Iteration[002/008] Valid loss: 0.1045
2023-02-06 14:44:58 | Valid | Epoch[430/600] Iteration[003/008] Valid loss: 0.1001
2023-02-06 14:44:58 | Valid | Epoch[430/600] Iteration[004/008] Valid loss: 0.0951
2023-02-06 14:44:58 | Valid | Epoch[430/600] Iteration[005/008] Valid loss: 0.0927
2023-02-06 14:44:58 | Valid | Epoch[430/600] Iteration[006/008] Valid loss: 0.0892
2023-02-06 14:44:58 | Valid | Epoch[430/600] Iteration[007/008] Valid loss: 0.0930
2023-02-06 14:44:58 | Valid | Epoch[430/600] Iteration[008/008] Valid loss: 0.0904
2023-02-06 14:44:59 | Valid | Epoch[430/600] MIou: 0.9241695131547534
2023-02-06 14:44:59 | Valid | Epoch[430/600] Pixel Accuracy: 0.9870999654134115
2023-02-06 14:44:59 | Valid | Epoch[430/600] Mean Pixel Accuracy: 0.9456096733379271
2023-02-06 14:44:59 | Stage | Epoch[430/600] Train loss:0.0079
2023-02-06 14:44:59 | Stage | Epoch[430/600] Valid loss:0.0904
2023-02-06 14:44:59 | Stage | Epoch[430/600] LR:0.001

2023-02-06 14:44:59 | Train | Epoch[431/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:44:59 | Train | Epoch[431/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:44:59 | Train | Epoch[431/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:45:00 | Train | Epoch[431/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 14:45:00 | Train | Epoch[431/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 14:45:00 | Train | Epoch[431/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:45:00 | Train | Epoch[431/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:45:01 | Train | Epoch[431/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 14:45:01 | Train | Epoch[431/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:45:01 | Train | Epoch[431/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:45:01 | Train | Epoch[431/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:45:01 | Train | Epoch[431/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:45:02 | Train | Epoch[431/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:45:02 | Train | Epoch[431/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:45:02 | Train | Epoch[431/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:45:02 | Train | Epoch[431/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:45:03 | Train | Epoch[431/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:45:03 | Train | Epoch[431/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:45:03 | Train | Epoch[431/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:45:03 | Train | Epoch[431/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:45:03 | Train | Epoch[431/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:45:04 | Train | Epoch[431/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:45:04 | Train | Epoch[431/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:45:04 | Train | Epoch[431/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:45:04 | Train | Epoch[431/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:45:05 | Train | Epoch[431/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:45:05 | Train | Epoch[431/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:45:05 | Train | Epoch[431/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:45:05 | Train | Epoch[431/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:45:05 | Train | Epoch[431/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:45:06 | Valid | Epoch[431/600] Iteration[001/008] Valid loss: 0.1634
2023-02-06 14:45:06 | Valid | Epoch[431/600] Iteration[002/008] Valid loss: 0.1267
2023-02-06 14:45:06 | Valid | Epoch[431/600] Iteration[003/008] Valid loss: 0.1207
2023-02-06 14:45:06 | Valid | Epoch[431/600] Iteration[004/008] Valid loss: 0.1141
2023-02-06 14:45:06 | Valid | Epoch[431/600] Iteration[005/008] Valid loss: 0.1129
2023-02-06 14:45:06 | Valid | Epoch[431/600] Iteration[006/008] Valid loss: 0.1089
2023-02-06 14:45:06 | Valid | Epoch[431/600] Iteration[007/008] Valid loss: 0.1157
2023-02-06 14:45:06 | Valid | Epoch[431/600] Iteration[008/008] Valid loss: 0.1131
2023-02-06 14:45:06 | Valid | Epoch[431/600] MIou: 0.9294444146165448
2023-02-06 14:45:06 | Valid | Epoch[431/600] Pixel Accuracy: 0.9878629048665365
2023-02-06 14:45:06 | Valid | Epoch[431/600] Mean Pixel Accuracy: 0.9557109173988911
2023-02-06 14:45:06 | Stage | Epoch[431/600] Train loss:0.0079
2023-02-06 14:45:06 | Stage | Epoch[431/600] Valid loss:0.1131
2023-02-06 14:45:06 | Stage | Epoch[431/600] LR:0.001

2023-02-06 14:45:07 | Train | Epoch[432/600] Iteration[001/030] Train loss: 0.0090
2023-02-06 14:45:07 | Train | Epoch[432/600] Iteration[002/030] Train loss: 0.0090
2023-02-06 14:45:07 | Train | Epoch[432/600] Iteration[003/030] Train loss: 0.0089
2023-02-06 14:45:07 | Train | Epoch[432/600] Iteration[004/030] Train loss: 0.0086
2023-02-06 14:45:07 | Train | Epoch[432/600] Iteration[005/030] Train loss: 0.0087
2023-02-06 14:45:08 | Train | Epoch[432/600] Iteration[006/030] Train loss: 0.0084
2023-02-06 14:45:08 | Train | Epoch[432/600] Iteration[007/030] Train loss: 0.0084
2023-02-06 14:45:08 | Train | Epoch[432/600] Iteration[008/030] Train loss: 0.0082
2023-02-06 14:45:08 | Train | Epoch[432/600] Iteration[009/030] Train loss: 0.0082
2023-02-06 14:45:08 | Train | Epoch[432/600] Iteration[010/030] Train loss: 0.0082
2023-02-06 14:45:09 | Train | Epoch[432/600] Iteration[011/030] Train loss: 0.0082
2023-02-06 14:45:09 | Train | Epoch[432/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:45:09 | Train | Epoch[432/600] Iteration[013/030] Train loss: 0.0081
2023-02-06 14:45:09 | Train | Epoch[432/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:45:10 | Train | Epoch[432/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 14:45:10 | Train | Epoch[432/600] Iteration[016/030] Train loss: 0.0081
2023-02-06 14:45:10 | Train | Epoch[432/600] Iteration[017/030] Train loss: 0.0081
2023-02-06 14:45:10 | Train | Epoch[432/600] Iteration[018/030] Train loss: 0.0081
2023-02-06 14:45:10 | Train | Epoch[432/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:45:11 | Train | Epoch[432/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:45:11 | Train | Epoch[432/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:45:11 | Train | Epoch[432/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:45:11 | Train | Epoch[432/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:45:12 | Train | Epoch[432/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:45:12 | Train | Epoch[432/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:45:12 | Train | Epoch[432/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:45:12 | Train | Epoch[432/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:45:12 | Train | Epoch[432/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:45:13 | Train | Epoch[432/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:45:13 | Train | Epoch[432/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:45:13 | Valid | Epoch[432/600] Iteration[001/008] Valid loss: 0.1460
2023-02-06 14:45:13 | Valid | Epoch[432/600] Iteration[002/008] Valid loss: 0.1154
2023-02-06 14:45:13 | Valid | Epoch[432/600] Iteration[003/008] Valid loss: 0.1095
2023-02-06 14:45:13 | Valid | Epoch[432/600] Iteration[004/008] Valid loss: 0.1035
2023-02-06 14:45:13 | Valid | Epoch[432/600] Iteration[005/008] Valid loss: 0.1024
2023-02-06 14:45:13 | Valid | Epoch[432/600] Iteration[006/008] Valid loss: 0.0987
2023-02-06 14:45:13 | Valid | Epoch[432/600] Iteration[007/008] Valid loss: 0.1043
2023-02-06 14:45:13 | Valid | Epoch[432/600] Iteration[008/008] Valid loss: 0.1017
2023-02-06 14:45:14 | Valid | Epoch[432/600] MIou: 0.9286612682524873
2023-02-06 14:45:14 | Valid | Epoch[432/600] Pixel Accuracy: 0.9877955118815104
2023-02-06 14:45:14 | Valid | Epoch[432/600] Mean Pixel Accuracy: 0.9524402348689188
2023-02-06 14:45:14 | Stage | Epoch[432/600] Train loss:0.0079
2023-02-06 14:45:14 | Stage | Epoch[432/600] Valid loss:0.1017
2023-02-06 14:45:14 | Stage | Epoch[432/600] LR:0.001

2023-02-06 14:45:14 | Train | Epoch[433/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 14:45:14 | Train | Epoch[433/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:45:15 | Train | Epoch[433/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:45:15 | Train | Epoch[433/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:45:15 | Train | Epoch[433/600] Iteration[005/030] Train loss: 0.0072
2023-02-06 14:45:15 | Train | Epoch[433/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:45:15 | Train | Epoch[433/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:45:16 | Train | Epoch[433/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:45:16 | Train | Epoch[433/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:45:16 | Train | Epoch[433/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:45:16 | Train | Epoch[433/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:45:16 | Train | Epoch[433/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:45:17 | Train | Epoch[433/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:45:17 | Train | Epoch[433/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:45:17 | Train | Epoch[433/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:45:17 | Train | Epoch[433/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:45:18 | Train | Epoch[433/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:45:18 | Train | Epoch[433/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:45:18 | Train | Epoch[433/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:45:18 | Train | Epoch[433/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:45:18 | Train | Epoch[433/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:45:19 | Train | Epoch[433/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:45:19 | Train | Epoch[433/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:45:19 | Train | Epoch[433/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:45:19 | Train | Epoch[433/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:45:20 | Train | Epoch[433/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:45:20 | Train | Epoch[433/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:45:20 | Train | Epoch[433/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:45:20 | Train | Epoch[433/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:45:20 | Train | Epoch[433/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:45:21 | Valid | Epoch[433/600] Iteration[001/008] Valid loss: 0.1734
2023-02-06 14:45:21 | Valid | Epoch[433/600] Iteration[002/008] Valid loss: 0.1367
2023-02-06 14:45:21 | Valid | Epoch[433/600] Iteration[003/008] Valid loss: 0.1303
2023-02-06 14:45:21 | Valid | Epoch[433/600] Iteration[004/008] Valid loss: 0.1233
2023-02-06 14:45:21 | Valid | Epoch[433/600] Iteration[005/008] Valid loss: 0.1219
2023-02-06 14:45:21 | Valid | Epoch[433/600] Iteration[006/008] Valid loss: 0.1187
2023-02-06 14:45:21 | Valid | Epoch[433/600] Iteration[007/008] Valid loss: 0.1269
2023-02-06 14:45:21 | Valid | Epoch[433/600] Iteration[008/008] Valid loss: 0.1250
2023-02-06 14:45:21 | Valid | Epoch[433/600] MIou: 0.9287786484635643
2023-02-06 14:45:21 | Valid | Epoch[433/600] Pixel Accuracy: 0.9876734415690104
2023-02-06 14:45:21 | Valid | Epoch[433/600] Mean Pixel Accuracy: 0.9578830095629933
2023-02-06 14:45:21 | Stage | Epoch[433/600] Train loss:0.0079
2023-02-06 14:45:21 | Stage | Epoch[433/600] Valid loss:0.1250
2023-02-06 14:45:21 | Stage | Epoch[433/600] LR:0.001

2023-02-06 14:45:21 | Train | Epoch[434/600] Iteration[001/030] Train loss: 0.0091
2023-02-06 14:45:22 | Train | Epoch[434/600] Iteration[002/030] Train loss: 0.0084
2023-02-06 14:45:22 | Train | Epoch[434/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:45:22 | Train | Epoch[434/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:45:22 | Train | Epoch[434/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:45:23 | Train | Epoch[434/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:45:23 | Train | Epoch[434/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:45:23 | Train | Epoch[434/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:45:23 | Train | Epoch[434/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:45:23 | Train | Epoch[434/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:45:24 | Train | Epoch[434/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:45:24 | Train | Epoch[434/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:45:24 | Train | Epoch[434/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:45:24 | Train | Epoch[434/600] Iteration[014/030] Train loss: 0.0081
2023-02-06 14:45:25 | Train | Epoch[434/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:45:25 | Train | Epoch[434/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:45:25 | Train | Epoch[434/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:45:25 | Train | Epoch[434/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:45:25 | Train | Epoch[434/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:45:26 | Train | Epoch[434/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:45:26 | Train | Epoch[434/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:45:26 | Train | Epoch[434/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:45:26 | Train | Epoch[434/600] Iteration[023/030] Train loss: 0.0081
2023-02-06 14:45:27 | Train | Epoch[434/600] Iteration[024/030] Train loss: 0.0081
2023-02-06 14:45:27 | Train | Epoch[434/600] Iteration[025/030] Train loss: 0.0081
2023-02-06 14:45:27 | Train | Epoch[434/600] Iteration[026/030] Train loss: 0.0081
2023-02-06 14:45:27 | Train | Epoch[434/600] Iteration[027/030] Train loss: 0.0081
2023-02-06 14:45:27 | Train | Epoch[434/600] Iteration[028/030] Train loss: 0.0081
2023-02-06 14:45:28 | Train | Epoch[434/600] Iteration[029/030] Train loss: 0.0081
2023-02-06 14:45:28 | Train | Epoch[434/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:45:28 | Valid | Epoch[434/600] Iteration[001/008] Valid loss: 0.1559
2023-02-06 14:45:28 | Valid | Epoch[434/600] Iteration[002/008] Valid loss: 0.1231
2023-02-06 14:45:28 | Valid | Epoch[434/600] Iteration[003/008] Valid loss: 0.1173
2023-02-06 14:45:28 | Valid | Epoch[434/600] Iteration[004/008] Valid loss: 0.1107
2023-02-06 14:45:28 | Valid | Epoch[434/600] Iteration[005/008] Valid loss: 0.1090
2023-02-06 14:45:28 | Valid | Epoch[434/600] Iteration[006/008] Valid loss: 0.1049
2023-02-06 14:45:28 | Valid | Epoch[434/600] Iteration[007/008] Valid loss: 0.1114
2023-02-06 14:45:28 | Valid | Epoch[434/600] Iteration[008/008] Valid loss: 0.1089
2023-02-06 14:45:28 | Valid | Epoch[434/600] MIou: 0.9293677030326957
2023-02-06 14:45:28 | Valid | Epoch[434/600] Pixel Accuracy: 0.9878730773925781
2023-02-06 14:45:28 | Valid | Epoch[434/600] Mean Pixel Accuracy: 0.9547527569832153
2023-02-06 14:45:28 | Stage | Epoch[434/600] Train loss:0.0080
2023-02-06 14:45:28 | Stage | Epoch[434/600] Valid loss:0.1089
2023-02-06 14:45:28 | Stage | Epoch[434/600] LR:0.001

2023-02-06 14:45:29 | Train | Epoch[435/600] Iteration[001/030] Train loss: 0.0084
2023-02-06 14:45:29 | Train | Epoch[435/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 14:45:29 | Train | Epoch[435/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:45:30 | Train | Epoch[435/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:45:30 | Train | Epoch[435/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 14:45:30 | Train | Epoch[435/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:45:30 | Train | Epoch[435/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:45:31 | Train | Epoch[435/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:45:31 | Train | Epoch[435/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:45:31 | Train | Epoch[435/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:45:31 | Train | Epoch[435/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:45:31 | Train | Epoch[435/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:45:32 | Train | Epoch[435/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:45:32 | Train | Epoch[435/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:45:32 | Train | Epoch[435/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:45:32 | Train | Epoch[435/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:45:32 | Train | Epoch[435/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:45:33 | Train | Epoch[435/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:45:33 | Train | Epoch[435/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:45:33 | Train | Epoch[435/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:45:33 | Train | Epoch[435/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:45:34 | Train | Epoch[435/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:45:34 | Train | Epoch[435/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:45:34 | Train | Epoch[435/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:45:34 | Train | Epoch[435/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:45:34 | Train | Epoch[435/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:45:35 | Train | Epoch[435/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:45:35 | Train | Epoch[435/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:45:35 | Train | Epoch[435/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:45:35 | Train | Epoch[435/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:45:36 | Valid | Epoch[435/600] Iteration[001/008] Valid loss: 0.1742
2023-02-06 14:45:36 | Valid | Epoch[435/600] Iteration[002/008] Valid loss: 0.1366
2023-02-06 14:45:36 | Valid | Epoch[435/600] Iteration[003/008] Valid loss: 0.1292
2023-02-06 14:45:36 | Valid | Epoch[435/600] Iteration[004/008] Valid loss: 0.1225
2023-02-06 14:45:36 | Valid | Epoch[435/600] Iteration[005/008] Valid loss: 0.1219
2023-02-06 14:45:36 | Valid | Epoch[435/600] Iteration[006/008] Valid loss: 0.1173
2023-02-06 14:45:36 | Valid | Epoch[435/600] Iteration[007/008] Valid loss: 0.1250
2023-02-06 14:45:36 | Valid | Epoch[435/600] Iteration[008/008] Valid loss: 0.1228
2023-02-06 14:45:36 | Valid | Epoch[435/600] MIou: 0.9303943991791355
2023-02-06 14:45:36 | Valid | Epoch[435/600] Pixel Accuracy: 0.9879875183105469
2023-02-06 14:45:36 | Valid | Epoch[435/600] Mean Pixel Accuracy: 0.9581190442503116
2023-02-06 14:45:36 | Stage | Epoch[435/600] Train loss:0.0079
2023-02-06 14:45:36 | Stage | Epoch[435/600] Valid loss:0.1228
2023-02-06 14:45:36 | Stage | Epoch[435/600] LR:0.001

2023-02-06 14:45:37 | Train | Epoch[436/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:45:37 | Train | Epoch[436/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:45:37 | Train | Epoch[436/600] Iteration[003/030] Train loss: 0.0081
2023-02-06 14:45:37 | Train | Epoch[436/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:45:37 | Train | Epoch[436/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:45:38 | Train | Epoch[436/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:45:38 | Train | Epoch[436/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:45:38 | Train | Epoch[436/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:45:38 | Train | Epoch[436/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:45:38 | Train | Epoch[436/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:45:39 | Train | Epoch[436/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:45:39 | Train | Epoch[436/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:45:39 | Train | Epoch[436/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:45:39 | Train | Epoch[436/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:45:40 | Train | Epoch[436/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:45:40 | Train | Epoch[436/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:45:40 | Train | Epoch[436/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:45:40 | Train | Epoch[436/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:45:40 | Train | Epoch[436/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:45:41 | Train | Epoch[436/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:45:41 | Train | Epoch[436/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:45:41 | Train | Epoch[436/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:45:41 | Train | Epoch[436/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:45:42 | Train | Epoch[436/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:45:42 | Train | Epoch[436/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:45:42 | Train | Epoch[436/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:45:42 | Train | Epoch[436/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:45:42 | Train | Epoch[436/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:45:43 | Train | Epoch[436/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:45:43 | Train | Epoch[436/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:45:43 | Valid | Epoch[436/600] Iteration[001/008] Valid loss: 0.1016
2023-02-06 14:45:43 | Valid | Epoch[436/600] Iteration[002/008] Valid loss: 0.0809
2023-02-06 14:45:43 | Valid | Epoch[436/600] Iteration[003/008] Valid loss: 0.0782
2023-02-06 14:45:43 | Valid | Epoch[436/600] Iteration[004/008] Valid loss: 0.0742
2023-02-06 14:45:43 | Valid | Epoch[436/600] Iteration[005/008] Valid loss: 0.0719
2023-02-06 14:45:43 | Valid | Epoch[436/600] Iteration[006/008] Valid loss: 0.0691
2023-02-06 14:45:43 | Valid | Epoch[436/600] Iteration[007/008] Valid loss: 0.0698
2023-02-06 14:45:43 | Valid | Epoch[436/600] Iteration[008/008] Valid loss: 0.0684
2023-02-06 14:45:44 | Valid | Epoch[436/600] MIou: 0.9080579522137707
2023-02-06 14:45:44 | Valid | Epoch[436/600] Pixel Accuracy: 0.984582265218099
2023-02-06 14:45:44 | Valid | Epoch[436/600] Mean Pixel Accuracy: 0.9241328837114862
2023-02-06 14:45:44 | Stage | Epoch[436/600] Train loss:0.0080
2023-02-06 14:45:44 | Stage | Epoch[436/600] Valid loss:0.0684
2023-02-06 14:45:44 | Stage | Epoch[436/600] LR:0.001

2023-02-06 14:45:44 | Train | Epoch[437/600] Iteration[001/030] Train loss: 0.0082
2023-02-06 14:45:44 | Train | Epoch[437/600] Iteration[002/030] Train loss: 0.0085
2023-02-06 14:45:44 | Train | Epoch[437/600] Iteration[003/030] Train loss: 0.0085
2023-02-06 14:45:45 | Train | Epoch[437/600] Iteration[004/030] Train loss: 0.0083
2023-02-06 14:45:45 | Train | Epoch[437/600] Iteration[005/030] Train loss: 0.0082
2023-02-06 14:45:45 | Train | Epoch[437/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:45:45 | Train | Epoch[437/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:45:46 | Train | Epoch[437/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:45:46 | Train | Epoch[437/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:45:46 | Train | Epoch[437/600] Iteration[010/030] Train loss: 0.0084
2023-02-06 14:45:46 | Train | Epoch[437/600] Iteration[011/030] Train loss: 0.0082
2023-02-06 14:45:46 | Train | Epoch[437/600] Iteration[012/030] Train loss: 0.0083
2023-02-06 14:45:47 | Train | Epoch[437/600] Iteration[013/030] Train loss: 0.0082
2023-02-06 14:45:47 | Train | Epoch[437/600] Iteration[014/030] Train loss: 0.0081
2023-02-06 14:45:47 | Train | Epoch[437/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 14:45:47 | Train | Epoch[437/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:45:47 | Train | Epoch[437/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:45:48 | Train | Epoch[437/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:45:48 | Train | Epoch[437/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:45:48 | Train | Epoch[437/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:45:48 | Train | Epoch[437/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:45:49 | Train | Epoch[437/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:45:49 | Train | Epoch[437/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:45:49 | Train | Epoch[437/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:45:49 | Train | Epoch[437/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:45:49 | Train | Epoch[437/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:45:50 | Train | Epoch[437/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:45:50 | Train | Epoch[437/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:45:50 | Train | Epoch[437/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:45:50 | Train | Epoch[437/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:45:51 | Valid | Epoch[437/600] Iteration[001/008] Valid loss: 0.1889
2023-02-06 14:45:51 | Valid | Epoch[437/600] Iteration[002/008] Valid loss: 0.1483
2023-02-06 14:45:51 | Valid | Epoch[437/600] Iteration[003/008] Valid loss: 0.1399
2023-02-06 14:45:51 | Valid | Epoch[437/600] Iteration[004/008] Valid loss: 0.1330
2023-02-06 14:45:51 | Valid | Epoch[437/600] Iteration[005/008] Valid loss: 0.1318
2023-02-06 14:45:51 | Valid | Epoch[437/600] Iteration[006/008] Valid loss: 0.1281
2023-02-06 14:45:51 | Valid | Epoch[437/600] Iteration[007/008] Valid loss: 0.1368
2023-02-06 14:45:51 | Valid | Epoch[437/600] Iteration[008/008] Valid loss: 0.1355
2023-02-06 14:45:51 | Valid | Epoch[437/600] MIou: 0.9298712260638868
2023-02-06 14:45:51 | Valid | Epoch[437/600] Pixel Accuracy: 0.9878094991048177
2023-02-06 14:45:51 | Valid | Epoch[437/600] Mean Pixel Accuracy: 0.9609695165556245
2023-02-06 14:45:51 | Stage | Epoch[437/600] Train loss:0.0080
2023-02-06 14:45:51 | Stage | Epoch[437/600] Valid loss:0.1355
2023-02-06 14:45:51 | Stage | Epoch[437/600] LR:0.001

2023-02-06 14:45:51 | Train | Epoch[438/600] Iteration[001/030] Train loss: 0.0076
2023-02-06 14:45:52 | Train | Epoch[438/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:45:52 | Train | Epoch[438/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:45:52 | Train | Epoch[438/600] Iteration[004/030] Train loss: 0.0104
2023-02-06 14:45:52 | Train | Epoch[438/600] Iteration[005/030] Train loss: 0.0100
2023-02-06 14:45:53 | Train | Epoch[438/600] Iteration[006/030] Train loss: 0.0095
2023-02-06 14:45:53 | Train | Epoch[438/600] Iteration[007/030] Train loss: 0.0092
2023-02-06 14:45:53 | Train | Epoch[438/600] Iteration[008/030] Train loss: 0.0090
2023-02-06 14:45:53 | Train | Epoch[438/600] Iteration[009/030] Train loss: 0.0089
2023-02-06 14:45:53 | Train | Epoch[438/600] Iteration[010/030] Train loss: 0.0089
2023-02-06 14:45:54 | Train | Epoch[438/600] Iteration[011/030] Train loss: 0.0087
2023-02-06 14:45:54 | Train | Epoch[438/600] Iteration[012/030] Train loss: 0.0086
2023-02-06 14:45:54 | Train | Epoch[438/600] Iteration[013/030] Train loss: 0.0085
2023-02-06 14:45:54 | Train | Epoch[438/600] Iteration[014/030] Train loss: 0.0085
2023-02-06 14:45:55 | Train | Epoch[438/600] Iteration[015/030] Train loss: 0.0084
2023-02-06 14:45:55 | Train | Epoch[438/600] Iteration[016/030] Train loss: 0.0084
2023-02-06 14:45:55 | Train | Epoch[438/600] Iteration[017/030] Train loss: 0.0083
2023-02-06 14:45:55 | Train | Epoch[438/600] Iteration[018/030] Train loss: 0.0083
2023-02-06 14:45:55 | Train | Epoch[438/600] Iteration[019/030] Train loss: 0.0083
2023-02-06 14:45:56 | Train | Epoch[438/600] Iteration[020/030] Train loss: 0.0082
2023-02-06 14:45:56 | Train | Epoch[438/600] Iteration[021/030] Train loss: 0.0082
2023-02-06 14:45:56 | Train | Epoch[438/600] Iteration[022/030] Train loss: 0.0082
2023-02-06 14:45:56 | Train | Epoch[438/600] Iteration[023/030] Train loss: 0.0083
2023-02-06 14:45:57 | Train | Epoch[438/600] Iteration[024/030] Train loss: 0.0083
2023-02-06 14:45:57 | Train | Epoch[438/600] Iteration[025/030] Train loss: 0.0083
2023-02-06 14:45:57 | Train | Epoch[438/600] Iteration[026/030] Train loss: 0.0082
2023-02-06 14:45:57 | Train | Epoch[438/600] Iteration[027/030] Train loss: 0.0082
2023-02-06 14:45:57 | Train | Epoch[438/600] Iteration[028/030] Train loss: 0.0082
2023-02-06 14:45:58 | Train | Epoch[438/600] Iteration[029/030] Train loss: 0.0082
2023-02-06 14:45:58 | Train | Epoch[438/600] Iteration[030/030] Train loss: 0.0082
2023-02-06 14:45:58 | Valid | Epoch[438/600] Iteration[001/008] Valid loss: 0.1496
2023-02-06 14:45:58 | Valid | Epoch[438/600] Iteration[002/008] Valid loss: 0.1168
2023-02-06 14:45:58 | Valid | Epoch[438/600] Iteration[003/008] Valid loss: 0.1101
2023-02-06 14:45:58 | Valid | Epoch[438/600] Iteration[004/008] Valid loss: 0.1043
2023-02-06 14:45:58 | Valid | Epoch[438/600] Iteration[005/008] Valid loss: 0.1020
2023-02-06 14:45:58 | Valid | Epoch[438/600] Iteration[006/008] Valid loss: 0.0983
2023-02-06 14:45:58 | Valid | Epoch[438/600] Iteration[007/008] Valid loss: 0.1037
2023-02-06 14:45:58 | Valid | Epoch[438/600] Iteration[008/008] Valid loss: 0.1015
2023-02-06 14:45:58 | Valid | Epoch[438/600] MIou: 0.927607156542996
2023-02-06 14:45:58 | Valid | Epoch[438/600] Pixel Accuracy: 0.9876149495442709
2023-02-06 14:45:58 | Valid | Epoch[438/600] Mean Pixel Accuracy: 0.9514406431528591
2023-02-06 14:45:59 | Stage | Epoch[438/600] Train loss:0.0082
2023-02-06 14:45:59 | Stage | Epoch[438/600] Valid loss:0.1015
2023-02-06 14:45:59 | Stage | Epoch[438/600] LR:0.001

2023-02-06 14:45:59 | Train | Epoch[439/600] Iteration[001/030] Train loss: 0.0081
2023-02-06 14:45:59 | Train | Epoch[439/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:45:59 | Train | Epoch[439/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:46:00 | Train | Epoch[439/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:46:00 | Train | Epoch[439/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:46:00 | Train | Epoch[439/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:46:00 | Train | Epoch[439/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:46:00 | Train | Epoch[439/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:46:01 | Train | Epoch[439/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:46:01 | Train | Epoch[439/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:46:01 | Train | Epoch[439/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:46:01 | Train | Epoch[439/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:46:02 | Train | Epoch[439/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:46:02 | Train | Epoch[439/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:46:02 | Train | Epoch[439/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:46:02 | Train | Epoch[439/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:46:02 | Train | Epoch[439/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:46:03 | Train | Epoch[439/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:46:03 | Train | Epoch[439/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:46:03 | Train | Epoch[439/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:46:03 | Train | Epoch[439/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:46:04 | Train | Epoch[439/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:46:04 | Train | Epoch[439/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:46:04 | Train | Epoch[439/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:46:04 | Train | Epoch[439/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:46:04 | Train | Epoch[439/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:46:05 | Train | Epoch[439/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:46:05 | Train | Epoch[439/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:46:05 | Train | Epoch[439/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:46:05 | Train | Epoch[439/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:46:06 | Valid | Epoch[439/600] Iteration[001/008] Valid loss: 0.1870
2023-02-06 14:46:06 | Valid | Epoch[439/600] Iteration[002/008] Valid loss: 0.1455
2023-02-06 14:46:06 | Valid | Epoch[439/600] Iteration[003/008] Valid loss: 0.1381
2023-02-06 14:46:06 | Valid | Epoch[439/600] Iteration[004/008] Valid loss: 0.1308
2023-02-06 14:46:06 | Valid | Epoch[439/600] Iteration[005/008] Valid loss: 0.1298
2023-02-06 14:46:06 | Valid | Epoch[439/600] Iteration[006/008] Valid loss: 0.1254
2023-02-06 14:46:06 | Valid | Epoch[439/600] Iteration[007/008] Valid loss: 0.1342
2023-02-06 14:46:06 | Valid | Epoch[439/600] Iteration[008/008] Valid loss: 0.1325
2023-02-06 14:46:06 | Valid | Epoch[439/600] MIou: 0.9307161391747705
2023-02-06 14:46:06 | Valid | Epoch[439/600] Pixel Accuracy: 0.9879938761393229
2023-02-06 14:46:06 | Valid | Epoch[439/600] Mean Pixel Accuracy: 0.9603353633418776
2023-02-06 14:46:06 | Stage | Epoch[439/600] Train loss:0.0080
2023-02-06 14:46:06 | Stage | Epoch[439/600] Valid loss:0.1325
2023-02-06 14:46:06 | Stage | Epoch[439/600] LR:0.001

2023-02-06 14:46:06 | Train | Epoch[440/600] Iteration[001/030] Train loss: 0.0079
2023-02-06 14:46:07 | Train | Epoch[440/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:46:07 | Train | Epoch[440/600] Iteration[003/030] Train loss: 0.0085
2023-02-06 14:46:07 | Train | Epoch[440/600] Iteration[004/030] Train loss: 0.0084
2023-02-06 14:46:07 | Train | Epoch[440/600] Iteration[005/030] Train loss: 0.0084
2023-02-06 14:46:08 | Train | Epoch[440/600] Iteration[006/030] Train loss: 0.0083
2023-02-06 14:46:08 | Train | Epoch[440/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:46:08 | Train | Epoch[440/600] Iteration[008/030] Train loss: 0.0082
2023-02-06 14:46:08 | Train | Epoch[440/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:46:08 | Train | Epoch[440/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:46:09 | Train | Epoch[440/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:46:09 | Train | Epoch[440/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:46:09 | Train | Epoch[440/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:46:09 | Train | Epoch[440/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:46:10 | Train | Epoch[440/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:46:10 | Train | Epoch[440/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:46:10 | Train | Epoch[440/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:46:10 | Train | Epoch[440/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:46:10 | Train | Epoch[440/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:46:11 | Train | Epoch[440/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:46:11 | Train | Epoch[440/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:46:11 | Train | Epoch[440/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:46:11 | Train | Epoch[440/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:46:12 | Train | Epoch[440/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:46:12 | Train | Epoch[440/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:46:12 | Train | Epoch[440/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:46:12 | Train | Epoch[440/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:46:12 | Train | Epoch[440/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:46:13 | Train | Epoch[440/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:46:13 | Train | Epoch[440/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:46:13 | Valid | Epoch[440/600] Iteration[001/008] Valid loss: 0.1625
2023-02-06 14:46:13 | Valid | Epoch[440/600] Iteration[002/008] Valid loss: 0.1293
2023-02-06 14:46:13 | Valid | Epoch[440/600] Iteration[003/008] Valid loss: 0.1225
2023-02-06 14:46:13 | Valid | Epoch[440/600] Iteration[004/008] Valid loss: 0.1159
2023-02-06 14:46:13 | Valid | Epoch[440/600] Iteration[005/008] Valid loss: 0.1148
2023-02-06 14:46:13 | Valid | Epoch[440/600] Iteration[006/008] Valid loss: 0.1109
2023-02-06 14:46:13 | Valid | Epoch[440/600] Iteration[007/008] Valid loss: 0.1190
2023-02-06 14:46:13 | Valid | Epoch[440/600] Iteration[008/008] Valid loss: 0.1172
2023-02-06 14:46:13 | Valid | Epoch[440/600] MIou: 0.9299809296397783
2023-02-06 14:46:13 | Valid | Epoch[440/600] Pixel Accuracy: 0.9879608154296875
2023-02-06 14:46:13 | Valid | Epoch[440/600] Mean Pixel Accuracy: 0.9560120116091546
2023-02-06 14:46:13 | Stage | Epoch[440/600] Train loss:0.0078
2023-02-06 14:46:13 | Stage | Epoch[440/600] Valid loss:0.1172
2023-02-06 14:46:13 | Stage | Epoch[440/600] LR:0.001

2023-02-06 14:46:14 | Train | Epoch[441/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 14:46:14 | Train | Epoch[441/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:46:14 | Train | Epoch[441/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:46:15 | Train | Epoch[441/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:46:15 | Train | Epoch[441/600] Iteration[005/030] Train loss: 0.0082
2023-02-06 14:46:15 | Train | Epoch[441/600] Iteration[006/030] Train loss: 0.0085
2023-02-06 14:46:15 | Train | Epoch[441/600] Iteration[007/030] Train loss: 0.0085
2023-02-06 14:46:15 | Train | Epoch[441/600] Iteration[008/030] Train loss: 0.0086
2023-02-06 14:46:16 | Train | Epoch[441/600] Iteration[009/030] Train loss: 0.0084
2023-02-06 14:46:16 | Train | Epoch[441/600] Iteration[010/030] Train loss: 0.0083
2023-02-06 14:46:16 | Train | Epoch[441/600] Iteration[011/030] Train loss: 0.0084
2023-02-06 14:46:16 | Train | Epoch[441/600] Iteration[012/030] Train loss: 0.0083
2023-02-06 14:46:17 | Train | Epoch[441/600] Iteration[013/030] Train loss: 0.0081
2023-02-06 14:46:17 | Train | Epoch[441/600] Iteration[014/030] Train loss: 0.0082
2023-02-06 14:46:17 | Train | Epoch[441/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 14:46:17 | Train | Epoch[441/600] Iteration[016/030] Train loss: 0.0081
2023-02-06 14:46:17 | Train | Epoch[441/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:46:18 | Train | Epoch[441/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:46:18 | Train | Epoch[441/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:46:18 | Train | Epoch[441/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:46:18 | Train | Epoch[441/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:46:19 | Train | Epoch[441/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:46:19 | Train | Epoch[441/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:46:19 | Train | Epoch[441/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:46:19 | Train | Epoch[441/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:46:19 | Train | Epoch[441/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:46:20 | Train | Epoch[441/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:46:20 | Train | Epoch[441/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:46:20 | Train | Epoch[441/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:46:20 | Train | Epoch[441/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:46:20 | Valid | Epoch[441/600] Iteration[001/008] Valid loss: 0.1819
2023-02-06 14:46:21 | Valid | Epoch[441/600] Iteration[002/008] Valid loss: 0.1430
2023-02-06 14:46:21 | Valid | Epoch[441/600] Iteration[003/008] Valid loss: 0.1379
2023-02-06 14:46:21 | Valid | Epoch[441/600] Iteration[004/008] Valid loss: 0.1302
2023-02-06 14:46:21 | Valid | Epoch[441/600] Iteration[005/008] Valid loss: 0.1285
2023-02-06 14:46:21 | Valid | Epoch[441/600] Iteration[006/008] Valid loss: 0.1249
2023-02-06 14:46:21 | Valid | Epoch[441/600] Iteration[007/008] Valid loss: 0.1340
2023-02-06 14:46:21 | Valid | Epoch[441/600] Iteration[008/008] Valid loss: 0.1321
2023-02-06 14:46:21 | Valid | Epoch[441/600] MIou: 0.9290606616921803
2023-02-06 14:46:21 | Valid | Epoch[441/600] Pixel Accuracy: 0.9876988728841146
2023-02-06 14:46:21 | Valid | Epoch[441/600] Mean Pixel Accuracy: 0.9590382725705682
2023-02-06 14:46:21 | Stage | Epoch[441/600] Train loss:0.0079
2023-02-06 14:46:21 | Stage | Epoch[441/600] Valid loss:0.1321
2023-02-06 14:46:21 | Stage | Epoch[441/600] LR:0.001

2023-02-06 14:46:21 | Train | Epoch[442/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:46:22 | Train | Epoch[442/600] Iteration[002/030] Train loss: 0.0070
2023-02-06 14:46:22 | Train | Epoch[442/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 14:46:22 | Train | Epoch[442/600] Iteration[004/030] Train loss: 0.0086
2023-02-06 14:46:22 | Train | Epoch[442/600] Iteration[005/030] Train loss: 0.0083
2023-02-06 14:46:23 | Train | Epoch[442/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:46:23 | Train | Epoch[442/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:46:23 | Train | Epoch[442/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:46:23 | Train | Epoch[442/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:46:23 | Train | Epoch[442/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:46:24 | Train | Epoch[442/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:46:24 | Train | Epoch[442/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:46:24 | Train | Epoch[442/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:46:24 | Train | Epoch[442/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:46:24 | Train | Epoch[442/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:46:25 | Train | Epoch[442/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:46:25 | Train | Epoch[442/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:46:25 | Train | Epoch[442/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:46:25 | Train | Epoch[442/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:46:26 | Train | Epoch[442/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:46:26 | Train | Epoch[442/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:46:26 | Train | Epoch[442/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:46:26 | Train | Epoch[442/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:46:26 | Train | Epoch[442/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:46:27 | Train | Epoch[442/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:46:27 | Train | Epoch[442/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:46:27 | Train | Epoch[442/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:46:27 | Train | Epoch[442/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:46:28 | Train | Epoch[442/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:46:28 | Train | Epoch[442/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:46:28 | Valid | Epoch[442/600] Iteration[001/008] Valid loss: 0.1498
2023-02-06 14:46:28 | Valid | Epoch[442/600] Iteration[002/008] Valid loss: 0.1167
2023-02-06 14:46:28 | Valid | Epoch[442/600] Iteration[003/008] Valid loss: 0.1110
2023-02-06 14:46:28 | Valid | Epoch[442/600] Iteration[004/008] Valid loss: 0.1048
2023-02-06 14:46:28 | Valid | Epoch[442/600] Iteration[005/008] Valid loss: 0.1026
2023-02-06 14:46:28 | Valid | Epoch[442/600] Iteration[006/008] Valid loss: 0.0988
2023-02-06 14:46:28 | Valid | Epoch[442/600] Iteration[007/008] Valid loss: 0.1048
2023-02-06 14:46:28 | Valid | Epoch[442/600] Iteration[008/008] Valid loss: 0.1026
2023-02-06 14:46:28 | Valid | Epoch[442/600] MIou: 0.9278913665322015
2023-02-06 14:46:28 | Valid | Epoch[442/600] Pixel Accuracy: 0.9876569112141927
2023-02-06 14:46:28 | Valid | Epoch[442/600] Mean Pixel Accuracy: 0.9519582638542123
2023-02-06 14:46:28 | Stage | Epoch[442/600] Train loss:0.0080
2023-02-06 14:46:28 | Stage | Epoch[442/600] Valid loss:0.1026
2023-02-06 14:46:28 | Stage | Epoch[442/600] LR:0.001

2023-02-06 14:46:29 | Train | Epoch[443/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:46:29 | Train | Epoch[443/600] Iteration[002/030] Train loss: 0.0071
2023-02-06 14:46:29 | Train | Epoch[443/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:46:30 | Train | Epoch[443/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 14:46:30 | Train | Epoch[443/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:46:30 | Train | Epoch[443/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:46:30 | Train | Epoch[443/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:46:30 | Train | Epoch[443/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:46:31 | Train | Epoch[443/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:46:31 | Train | Epoch[443/600] Iteration[010/030] Train loss: 0.0081
2023-02-06 14:46:31 | Train | Epoch[443/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:46:31 | Train | Epoch[443/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:46:32 | Train | Epoch[443/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:46:32 | Train | Epoch[443/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:46:32 | Train | Epoch[443/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:46:32 | Train | Epoch[443/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:46:32 | Train | Epoch[443/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:46:33 | Train | Epoch[443/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:46:33 | Train | Epoch[443/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:46:33 | Train | Epoch[443/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:46:33 | Train | Epoch[443/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:46:34 | Train | Epoch[443/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:46:34 | Train | Epoch[443/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:46:34 | Train | Epoch[443/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:46:34 | Train | Epoch[443/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:46:34 | Train | Epoch[443/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:46:35 | Train | Epoch[443/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:46:35 | Train | Epoch[443/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:46:35 | Train | Epoch[443/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:46:35 | Train | Epoch[443/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:46:36 | Valid | Epoch[443/600] Iteration[001/008] Valid loss: 0.2004
2023-02-06 14:46:36 | Valid | Epoch[443/600] Iteration[002/008] Valid loss: 0.1587
2023-02-06 14:46:36 | Valid | Epoch[443/600] Iteration[003/008] Valid loss: 0.1538
2023-02-06 14:46:36 | Valid | Epoch[443/600] Iteration[004/008] Valid loss: 0.1455
2023-02-06 14:46:36 | Valid | Epoch[443/600] Iteration[005/008] Valid loss: 0.1444
2023-02-06 14:46:36 | Valid | Epoch[443/600] Iteration[006/008] Valid loss: 0.1406
2023-02-06 14:46:36 | Valid | Epoch[443/600] Iteration[007/008] Valid loss: 0.1508
2023-02-06 14:46:36 | Valid | Epoch[443/600] Iteration[008/008] Valid loss: 0.1491
2023-02-06 14:46:36 | Valid | Epoch[443/600] MIou: 0.9297819706776398
2023-02-06 14:46:36 | Valid | Epoch[443/600] Pixel Accuracy: 0.9877471923828125
2023-02-06 14:46:36 | Valid | Epoch[443/600] Mean Pixel Accuracy: 0.9626725593182028
2023-02-06 14:46:36 | Stage | Epoch[443/600] Train loss:0.0078
2023-02-06 14:46:36 | Stage | Epoch[443/600] Valid loss:0.1491
2023-02-06 14:46:36 | Stage | Epoch[443/600] LR:0.001

2023-02-06 14:46:36 | Train | Epoch[444/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 14:46:37 | Train | Epoch[444/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 14:46:37 | Train | Epoch[444/600] Iteration[003/030] Train loss: 0.0081
2023-02-06 14:46:37 | Train | Epoch[444/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:46:37 | Train | Epoch[444/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 14:46:38 | Train | Epoch[444/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:46:38 | Train | Epoch[444/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:46:38 | Train | Epoch[444/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:46:38 | Train | Epoch[444/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:46:38 | Train | Epoch[444/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:46:39 | Train | Epoch[444/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:46:39 | Train | Epoch[444/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:46:39 | Train | Epoch[444/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:46:39 | Train | Epoch[444/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:46:40 | Train | Epoch[444/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:46:40 | Train | Epoch[444/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:46:40 | Train | Epoch[444/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:46:40 | Train | Epoch[444/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:46:40 | Train | Epoch[444/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:46:41 | Train | Epoch[444/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:46:41 | Train | Epoch[444/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:46:41 | Train | Epoch[444/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:46:41 | Train | Epoch[444/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:46:42 | Train | Epoch[444/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:46:42 | Train | Epoch[444/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:46:42 | Train | Epoch[444/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:46:42 | Train | Epoch[444/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:46:42 | Train | Epoch[444/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:46:43 | Train | Epoch[444/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:46:43 | Train | Epoch[444/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:46:43 | Valid | Epoch[444/600] Iteration[001/008] Valid loss: 0.1851
2023-02-06 14:46:43 | Valid | Epoch[444/600] Iteration[002/008] Valid loss: 0.1478
2023-02-06 14:46:43 | Valid | Epoch[444/600] Iteration[003/008] Valid loss: 0.1411
2023-02-06 14:46:43 | Valid | Epoch[444/600] Iteration[004/008] Valid loss: 0.1337
2023-02-06 14:46:43 | Valid | Epoch[444/600] Iteration[005/008] Valid loss: 0.1329
2023-02-06 14:46:43 | Valid | Epoch[444/600] Iteration[006/008] Valid loss: 0.1285
2023-02-06 14:46:43 | Valid | Epoch[444/600] Iteration[007/008] Valid loss: 0.1379
2023-02-06 14:46:43 | Valid | Epoch[444/600] Iteration[008/008] Valid loss: 0.1361
2023-02-06 14:46:44 | Valid | Epoch[444/600] MIou: 0.9310267565119085
2023-02-06 14:46:44 | Valid | Epoch[444/600] Pixel Accuracy: 0.9880396525065104
2023-02-06 14:46:44 | Valid | Epoch[444/600] Mean Pixel Accuracy: 0.9609501878362221
2023-02-06 14:46:44 | Stage | Epoch[444/600] Train loss:0.0078
2023-02-06 14:46:44 | Stage | Epoch[444/600] Valid loss:0.1361
2023-02-06 14:46:44 | Stage | Epoch[444/600] LR:0.001

2023-02-06 14:46:44 | Train | Epoch[445/600] Iteration[001/030] Train loss: 0.0079
2023-02-06 14:46:44 | Train | Epoch[445/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 14:46:44 | Train | Epoch[445/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:46:45 | Train | Epoch[445/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:46:45 | Train | Epoch[445/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:46:45 | Train | Epoch[445/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:46:45 | Train | Epoch[445/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:46:46 | Train | Epoch[445/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:46:46 | Train | Epoch[445/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:46:46 | Train | Epoch[445/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:46:46 | Train | Epoch[445/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 14:46:46 | Train | Epoch[445/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 14:46:47 | Train | Epoch[445/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:46:47 | Train | Epoch[445/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:46:47 | Train | Epoch[445/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:46:47 | Train | Epoch[445/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:46:47 | Train | Epoch[445/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:46:48 | Train | Epoch[445/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:46:48 | Train | Epoch[445/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:46:48 | Train | Epoch[445/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:46:48 | Train | Epoch[445/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:46:49 | Train | Epoch[445/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:46:49 | Train | Epoch[445/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:46:49 | Train | Epoch[445/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:46:49 | Train | Epoch[445/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:46:49 | Train | Epoch[445/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:46:50 | Train | Epoch[445/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:46:50 | Train | Epoch[445/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:46:50 | Train | Epoch[445/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:46:50 | Train | Epoch[445/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:46:51 | Valid | Epoch[445/600] Iteration[001/008] Valid loss: 0.1414
2023-02-06 14:46:51 | Valid | Epoch[445/600] Iteration[002/008] Valid loss: 0.1099
2023-02-06 14:46:51 | Valid | Epoch[445/600] Iteration[003/008] Valid loss: 0.1050
2023-02-06 14:46:51 | Valid | Epoch[445/600] Iteration[004/008] Valid loss: 0.0990
2023-02-06 14:46:51 | Valid | Epoch[445/600] Iteration[005/008] Valid loss: 0.0965
2023-02-06 14:46:51 | Valid | Epoch[445/600] Iteration[006/008] Valid loss: 0.0927
2023-02-06 14:46:51 | Valid | Epoch[445/600] Iteration[007/008] Valid loss: 0.0976
2023-02-06 14:46:51 | Valid | Epoch[445/600] Iteration[008/008] Valid loss: 0.0953
2023-02-06 14:46:51 | Valid | Epoch[445/600] MIou: 0.9254276312606173
2023-02-06 14:46:51 | Valid | Epoch[445/600] Pixel Accuracy: 0.9872754414876302
2023-02-06 14:46:51 | Valid | Epoch[445/600] Mean Pixel Accuracy: 0.9481725658903903
2023-02-06 14:46:51 | Stage | Epoch[445/600] Train loss:0.0077
2023-02-06 14:46:51 | Stage | Epoch[445/600] Valid loss:0.0953
2023-02-06 14:46:51 | Stage | Epoch[445/600] LR:0.001

2023-02-06 14:46:52 | Train | Epoch[446/600] Iteration[001/030] Train loss: 0.0082
2023-02-06 14:46:52 | Train | Epoch[446/600] Iteration[002/030] Train loss: 0.0082
2023-02-06 14:46:52 | Train | Epoch[446/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:46:52 | Train | Epoch[446/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:46:52 | Train | Epoch[446/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:46:53 | Train | Epoch[446/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:46:53 | Train | Epoch[446/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:46:53 | Train | Epoch[446/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:46:53 | Train | Epoch[446/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:46:54 | Train | Epoch[446/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:46:54 | Train | Epoch[446/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:46:54 | Train | Epoch[446/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:46:54 | Train | Epoch[446/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:46:54 | Train | Epoch[446/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:46:55 | Train | Epoch[446/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:46:55 | Train | Epoch[446/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:46:55 | Train | Epoch[446/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:46:55 | Train | Epoch[446/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:46:55 | Train | Epoch[446/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:46:56 | Train | Epoch[446/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:46:56 | Train | Epoch[446/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:46:56 | Train | Epoch[446/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:46:56 | Train | Epoch[446/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:46:57 | Train | Epoch[446/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:46:57 | Train | Epoch[446/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:46:57 | Train | Epoch[446/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:46:57 | Train | Epoch[446/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:46:57 | Train | Epoch[446/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:46:58 | Train | Epoch[446/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:46:58 | Train | Epoch[446/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:46:58 | Valid | Epoch[446/600] Iteration[001/008] Valid loss: 0.1563
2023-02-06 14:46:58 | Valid | Epoch[446/600] Iteration[002/008] Valid loss: 0.1219
2023-02-06 14:46:58 | Valid | Epoch[446/600] Iteration[003/008] Valid loss: 0.1155
2023-02-06 14:46:58 | Valid | Epoch[446/600] Iteration[004/008] Valid loss: 0.1089
2023-02-06 14:46:58 | Valid | Epoch[446/600] Iteration[005/008] Valid loss: 0.1075
2023-02-06 14:46:58 | Valid | Epoch[446/600] Iteration[006/008] Valid loss: 0.1032
2023-02-06 14:46:58 | Valid | Epoch[446/600] Iteration[007/008] Valid loss: 0.1092
2023-02-06 14:46:58 | Valid | Epoch[446/600] Iteration[008/008] Valid loss: 0.1074
2023-02-06 14:46:59 | Valid | Epoch[446/600] MIou: 0.9288894882499972
2023-02-06 14:46:59 | Valid | Epoch[446/600] Pixel Accuracy: 0.9878044128417969
2023-02-06 14:46:59 | Valid | Epoch[446/600] Mean Pixel Accuracy: 0.9537893071768699
2023-02-06 14:46:59 | Stage | Epoch[446/600] Train loss:0.0077
2023-02-06 14:46:59 | Stage | Epoch[446/600] Valid loss:0.1074
2023-02-06 14:46:59 | Stage | Epoch[446/600] LR:0.001

2023-02-06 14:46:59 | Train | Epoch[447/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 14:46:59 | Train | Epoch[447/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:46:59 | Train | Epoch[447/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:47:00 | Train | Epoch[447/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:47:00 | Train | Epoch[447/600] Iteration[005/030] Train loss: 0.0082
2023-02-06 14:47:00 | Train | Epoch[447/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:47:00 | Train | Epoch[447/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:47:01 | Train | Epoch[447/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:47:01 | Train | Epoch[447/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:47:01 | Train | Epoch[447/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:47:01 | Train | Epoch[447/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:47:01 | Train | Epoch[447/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:47:02 | Train | Epoch[447/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:47:02 | Train | Epoch[447/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:47:02 | Train | Epoch[447/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:47:02 | Train | Epoch[447/600] Iteration[016/030] Train loss: 0.0082
2023-02-06 14:47:03 | Train | Epoch[447/600] Iteration[017/030] Train loss: 0.0082
2023-02-06 14:47:03 | Train | Epoch[447/600] Iteration[018/030] Train loss: 0.0082
2023-02-06 14:47:03 | Train | Epoch[447/600] Iteration[019/030] Train loss: 0.0082
2023-02-06 14:47:03 | Train | Epoch[447/600] Iteration[020/030] Train loss: 0.0081
2023-02-06 14:47:03 | Train | Epoch[447/600] Iteration[021/030] Train loss: 0.0081
2023-02-06 14:47:04 | Train | Epoch[447/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:47:04 | Train | Epoch[447/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:47:04 | Train | Epoch[447/600] Iteration[024/030] Train loss: 0.0081
2023-02-06 14:47:04 | Train | Epoch[447/600] Iteration[025/030] Train loss: 0.0081
2023-02-06 14:47:04 | Train | Epoch[447/600] Iteration[026/030] Train loss: 0.0081
2023-02-06 14:47:05 | Train | Epoch[447/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:47:05 | Train | Epoch[447/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:47:05 | Train | Epoch[447/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:47:05 | Train | Epoch[447/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:47:06 | Valid | Epoch[447/600] Iteration[001/008] Valid loss: 0.1237
2023-02-06 14:47:06 | Valid | Epoch[447/600] Iteration[002/008] Valid loss: 0.0974
2023-02-06 14:47:06 | Valid | Epoch[447/600] Iteration[003/008] Valid loss: 0.0930
2023-02-06 14:47:06 | Valid | Epoch[447/600] Iteration[004/008] Valid loss: 0.0881
2023-02-06 14:47:06 | Valid | Epoch[447/600] Iteration[005/008] Valid loss: 0.0857
2023-02-06 14:47:06 | Valid | Epoch[447/600] Iteration[006/008] Valid loss: 0.0824
2023-02-06 14:47:06 | Valid | Epoch[447/600] Iteration[007/008] Valid loss: 0.0850
2023-02-06 14:47:06 | Valid | Epoch[447/600] Iteration[008/008] Valid loss: 0.0828
2023-02-06 14:47:06 | Valid | Epoch[447/600] MIou: 0.920988137366642
2023-02-06 14:47:06 | Valid | Epoch[447/600] Pixel Accuracy: 0.9866218566894531
2023-02-06 14:47:06 | Valid | Epoch[447/600] Mean Pixel Accuracy: 0.9404964236856546
2023-02-06 14:47:06 | Stage | Epoch[447/600] Train loss:0.0080
2023-02-06 14:47:06 | Stage | Epoch[447/600] Valid loss:0.0828
2023-02-06 14:47:06 | Stage | Epoch[447/600] LR:0.001

2023-02-06 14:47:07 | Train | Epoch[448/600] Iteration[001/030] Train loss: 0.0082
2023-02-06 14:47:07 | Train | Epoch[448/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 14:47:07 | Train | Epoch[448/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:47:07 | Train | Epoch[448/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:47:07 | Train | Epoch[448/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 14:47:08 | Train | Epoch[448/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:47:08 | Train | Epoch[448/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:47:08 | Train | Epoch[448/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:47:08 | Train | Epoch[448/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:47:08 | Train | Epoch[448/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:47:09 | Train | Epoch[448/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:47:09 | Train | Epoch[448/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:47:09 | Train | Epoch[448/600] Iteration[013/030] Train loss: 0.0081
2023-02-06 14:47:09 | Train | Epoch[448/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:47:10 | Train | Epoch[448/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:47:10 | Train | Epoch[448/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:47:10 | Train | Epoch[448/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:47:10 | Train | Epoch[448/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:47:10 | Train | Epoch[448/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:47:11 | Train | Epoch[448/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:47:11 | Train | Epoch[448/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:47:11 | Train | Epoch[448/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:47:11 | Train | Epoch[448/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:47:12 | Train | Epoch[448/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:47:12 | Train | Epoch[448/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:47:12 | Train | Epoch[448/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:47:12 | Train | Epoch[448/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:47:12 | Train | Epoch[448/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:47:13 | Train | Epoch[448/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:47:13 | Train | Epoch[448/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:47:13 | Valid | Epoch[448/600] Iteration[001/008] Valid loss: 0.1707
2023-02-06 14:47:13 | Valid | Epoch[448/600] Iteration[002/008] Valid loss: 0.1333
2023-02-06 14:47:13 | Valid | Epoch[448/600] Iteration[003/008] Valid loss: 0.1256
2023-02-06 14:47:13 | Valid | Epoch[448/600] Iteration[004/008] Valid loss: 0.1191
2023-02-06 14:47:13 | Valid | Epoch[448/600] Iteration[005/008] Valid loss: 0.1172
2023-02-06 14:47:13 | Valid | Epoch[448/600] Iteration[006/008] Valid loss: 0.1130
2023-02-06 14:47:13 | Valid | Epoch[448/600] Iteration[007/008] Valid loss: 0.1206
2023-02-06 14:47:13 | Valid | Epoch[448/600] Iteration[008/008] Valid loss: 0.1185
2023-02-06 14:47:14 | Valid | Epoch[448/600] MIou: 0.9292620874947694
2023-02-06 14:47:14 | Valid | Epoch[448/600] Pixel Accuracy: 0.9878120422363281
2023-02-06 14:47:14 | Valid | Epoch[448/600] Mean Pixel Accuracy: 0.9562726249787133
2023-02-06 14:47:14 | Stage | Epoch[448/600] Train loss:0.0079
2023-02-06 14:47:14 | Stage | Epoch[448/600] Valid loss:0.1185
2023-02-06 14:47:14 | Stage | Epoch[448/600] LR:0.001

2023-02-06 14:47:14 | Train | Epoch[449/600] Iteration[001/030] Train loss: 0.0067
2023-02-06 14:47:14 | Train | Epoch[449/600] Iteration[002/030] Train loss: 0.0069
2023-02-06 14:47:14 | Train | Epoch[449/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:47:15 | Train | Epoch[449/600] Iteration[004/030] Train loss: 0.0076
2023-02-06 14:47:15 | Train | Epoch[449/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:47:15 | Train | Epoch[449/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:47:15 | Train | Epoch[449/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:47:16 | Train | Epoch[449/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:47:16 | Train | Epoch[449/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:47:16 | Train | Epoch[449/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:47:16 | Train | Epoch[449/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:47:16 | Train | Epoch[449/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:47:17 | Train | Epoch[449/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:47:17 | Train | Epoch[449/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:47:17 | Train | Epoch[449/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:47:17 | Train | Epoch[449/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:47:18 | Train | Epoch[449/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:47:18 | Train | Epoch[449/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:47:18 | Train | Epoch[449/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:47:18 | Train | Epoch[449/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:47:18 | Train | Epoch[449/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:47:19 | Train | Epoch[449/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:47:19 | Train | Epoch[449/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:47:19 | Train | Epoch[449/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:47:19 | Train | Epoch[449/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:47:20 | Train | Epoch[449/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:47:20 | Train | Epoch[449/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:47:20 | Train | Epoch[449/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:47:20 | Train | Epoch[449/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:47:20 | Train | Epoch[449/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:47:21 | Valid | Epoch[449/600] Iteration[001/008] Valid loss: 0.2131
2023-02-06 14:47:21 | Valid | Epoch[449/600] Iteration[002/008] Valid loss: 0.1705
2023-02-06 14:47:21 | Valid | Epoch[449/600] Iteration[003/008] Valid loss: 0.1644
2023-02-06 14:47:21 | Valid | Epoch[449/600] Iteration[004/008] Valid loss: 0.1557
2023-02-06 14:47:21 | Valid | Epoch[449/600] Iteration[005/008] Valid loss: 0.1564
2023-02-06 14:47:21 | Valid | Epoch[449/600] Iteration[006/008] Valid loss: 0.1526
2023-02-06 14:47:21 | Valid | Epoch[449/600] Iteration[007/008] Valid loss: 0.1642
2023-02-06 14:47:21 | Valid | Epoch[449/600] Iteration[008/008] Valid loss: 0.1632
2023-02-06 14:47:21 | Valid | Epoch[449/600] MIou: 0.9293834826312266
2023-02-06 14:47:21 | Valid | Epoch[449/600] Pixel Accuracy: 0.9876225789388021
2023-02-06 14:47:21 | Valid | Epoch[449/600] Mean Pixel Accuracy: 0.9643793984781222
2023-02-06 14:47:21 | Stage | Epoch[449/600] Train loss:0.0077
2023-02-06 14:47:21 | Stage | Epoch[449/600] Valid loss:0.1632
2023-02-06 14:47:21 | Stage | Epoch[449/600] LR:0.001

2023-02-06 14:47:22 | Train | Epoch[450/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 14:47:22 | Train | Epoch[450/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 14:47:22 | Train | Epoch[450/600] Iteration[003/030] Train loss: 0.0084
2023-02-06 14:47:22 | Train | Epoch[450/600] Iteration[004/030] Train loss: 0.0082
2023-02-06 14:47:22 | Train | Epoch[450/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 14:47:23 | Train | Epoch[450/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:47:23 | Train | Epoch[450/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:47:23 | Train | Epoch[450/600] Iteration[008/030] Train loss: 0.0082
2023-02-06 14:47:23 | Train | Epoch[450/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:47:24 | Train | Epoch[450/600] Iteration[010/030] Train loss: 0.0081
2023-02-06 14:47:24 | Train | Epoch[450/600] Iteration[011/030] Train loss: 0.0081
2023-02-06 14:47:24 | Train | Epoch[450/600] Iteration[012/030] Train loss: 0.0082
2023-02-06 14:47:24 | Train | Epoch[450/600] Iteration[013/030] Train loss: 0.0081
2023-02-06 14:47:24 | Train | Epoch[450/600] Iteration[014/030] Train loss: 0.0081
2023-02-06 14:47:25 | Train | Epoch[450/600] Iteration[015/030] Train loss: 0.0082
2023-02-06 14:47:25 | Train | Epoch[450/600] Iteration[016/030] Train loss: 0.0082
2023-02-06 14:47:25 | Train | Epoch[450/600] Iteration[017/030] Train loss: 0.0081
2023-02-06 14:47:25 | Train | Epoch[450/600] Iteration[018/030] Train loss: 0.0081
2023-02-06 14:47:25 | Train | Epoch[450/600] Iteration[019/030] Train loss: 0.0081
2023-02-06 14:47:26 | Train | Epoch[450/600] Iteration[020/030] Train loss: 0.0082
2023-02-06 14:47:26 | Train | Epoch[450/600] Iteration[021/030] Train loss: 0.0082
2023-02-06 14:47:26 | Train | Epoch[450/600] Iteration[022/030] Train loss: 0.0081
2023-02-06 14:47:26 | Train | Epoch[450/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:47:27 | Train | Epoch[450/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:47:27 | Train | Epoch[450/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:47:27 | Train | Epoch[450/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:47:27 | Train | Epoch[450/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:47:27 | Train | Epoch[450/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:47:28 | Train | Epoch[450/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:47:28 | Train | Epoch[450/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:47:28 | Valid | Epoch[450/600] Iteration[001/008] Valid loss: 0.2270
2023-02-06 14:47:28 | Valid | Epoch[450/600] Iteration[002/008] Valid loss: 0.1806
2023-02-06 14:47:28 | Valid | Epoch[450/600] Iteration[003/008] Valid loss: 0.1740
2023-02-06 14:47:28 | Valid | Epoch[450/600] Iteration[004/008] Valid loss: 0.1660
2023-02-06 14:47:28 | Valid | Epoch[450/600] Iteration[005/008] Valid loss: 0.1666
2023-02-06 14:47:28 | Valid | Epoch[450/600] Iteration[006/008] Valid loss: 0.1624
2023-02-06 14:47:28 | Valid | Epoch[450/600] Iteration[007/008] Valid loss: 0.1753
2023-02-06 14:47:28 | Valid | Epoch[450/600] Iteration[008/008] Valid loss: 0.1746
2023-02-06 14:47:29 | Valid | Epoch[450/600] MIou: 0.9297606522553328
2023-02-06 14:47:29 | Valid | Epoch[450/600] Pixel Accuracy: 0.9876480102539062
2023-02-06 14:47:29 | Valid | Epoch[450/600] Mean Pixel Accuracy: 0.9663081990101708
2023-02-06 14:47:29 | Stage | Epoch[450/600] Train loss:0.0080
2023-02-06 14:47:29 | Stage | Epoch[450/600] Valid loss:0.1746
2023-02-06 14:47:29 | Stage | Epoch[450/600] LR:0.001

2023-02-06 14:47:29 | Train | Epoch[451/600] Iteration[001/030] Train loss: 0.0094
2023-02-06 14:47:29 | Train | Epoch[451/600] Iteration[002/030] Train loss: 0.0087
2023-02-06 14:47:29 | Train | Epoch[451/600] Iteration[003/030] Train loss: 0.0082
2023-02-06 14:47:30 | Train | Epoch[451/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:47:30 | Train | Epoch[451/600] Iteration[005/030] Train loss: 0.0083
2023-02-06 14:47:30 | Train | Epoch[451/600] Iteration[006/030] Train loss: 0.0083
2023-02-06 14:47:30 | Train | Epoch[451/600] Iteration[007/030] Train loss: 0.0082
2023-02-06 14:47:30 | Train | Epoch[451/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:47:31 | Train | Epoch[451/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:47:31 | Train | Epoch[451/600] Iteration[010/030] Train loss: 0.0081
2023-02-06 14:47:31 | Train | Epoch[451/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:47:31 | Train | Epoch[451/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:47:32 | Train | Epoch[451/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:47:32 | Train | Epoch[451/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:47:32 | Train | Epoch[451/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:47:32 | Train | Epoch[451/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:47:32 | Train | Epoch[451/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:47:33 | Train | Epoch[451/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:47:33 | Train | Epoch[451/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:47:33 | Train | Epoch[451/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:47:33 | Train | Epoch[451/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:47:34 | Train | Epoch[451/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:47:34 | Train | Epoch[451/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:47:34 | Train | Epoch[451/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:47:34 | Train | Epoch[451/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:47:34 | Train | Epoch[451/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:47:35 | Train | Epoch[451/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:47:35 | Train | Epoch[451/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:47:35 | Train | Epoch[451/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:47:35 | Train | Epoch[451/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:47:36 | Valid | Epoch[451/600] Iteration[001/008] Valid loss: 0.2486
2023-02-06 14:47:36 | Valid | Epoch[451/600] Iteration[002/008] Valid loss: 0.2003
2023-02-06 14:47:36 | Valid | Epoch[451/600] Iteration[003/008] Valid loss: 0.1934
2023-02-06 14:47:36 | Valid | Epoch[451/600] Iteration[004/008] Valid loss: 0.1853
2023-02-06 14:47:36 | Valid | Epoch[451/600] Iteration[005/008] Valid loss: 0.1868
2023-02-06 14:47:36 | Valid | Epoch[451/600] Iteration[006/008] Valid loss: 0.1822
2023-02-06 14:47:36 | Valid | Epoch[451/600] Iteration[007/008] Valid loss: 0.1971
2023-02-06 14:47:36 | Valid | Epoch[451/600] Iteration[008/008] Valid loss: 0.1976
2023-02-06 14:47:36 | Valid | Epoch[451/600] MIou: 0.9294666634270838
2023-02-06 14:47:36 | Valid | Epoch[451/600] Pixel Accuracy: 0.9875208536783854
2023-02-06 14:47:36 | Valid | Epoch[451/600] Mean Pixel Accuracy: 0.9689013063682413
2023-02-06 14:47:36 | Stage | Epoch[451/600] Train loss:0.0079
2023-02-06 14:47:36 | Stage | Epoch[451/600] Valid loss:0.1976
2023-02-06 14:47:36 | Stage | Epoch[451/600] LR:0.001

2023-02-06 14:47:36 | Train | Epoch[452/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 14:47:37 | Train | Epoch[452/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:47:37 | Train | Epoch[452/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:47:37 | Train | Epoch[452/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:47:37 | Train | Epoch[452/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:47:37 | Train | Epoch[452/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:47:38 | Train | Epoch[452/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:47:38 | Train | Epoch[452/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:47:38 | Train | Epoch[452/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:47:38 | Train | Epoch[452/600] Iteration[010/030] Train loss: 0.0081
2023-02-06 14:47:39 | Train | Epoch[452/600] Iteration[011/030] Train loss: 0.0081
2023-02-06 14:47:39 | Train | Epoch[452/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:47:39 | Train | Epoch[452/600] Iteration[013/030] Train loss: 0.0081
2023-02-06 14:47:39 | Train | Epoch[452/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:47:39 | Train | Epoch[452/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 14:47:40 | Train | Epoch[452/600] Iteration[016/030] Train loss: 0.0081
2023-02-06 14:47:40 | Train | Epoch[452/600] Iteration[017/030] Train loss: 0.0081
2023-02-06 14:47:40 | Train | Epoch[452/600] Iteration[018/030] Train loss: 0.0081
2023-02-06 14:47:40 | Train | Epoch[452/600] Iteration[019/030] Train loss: 0.0081
2023-02-06 14:47:41 | Train | Epoch[452/600] Iteration[020/030] Train loss: 0.0081
2023-02-06 14:47:41 | Train | Epoch[452/600] Iteration[021/030] Train loss: 0.0082
2023-02-06 14:47:41 | Train | Epoch[452/600] Iteration[022/030] Train loss: 0.0082
2023-02-06 14:47:41 | Train | Epoch[452/600] Iteration[023/030] Train loss: 0.0082
2023-02-06 14:47:41 | Train | Epoch[452/600] Iteration[024/030] Train loss: 0.0085
2023-02-06 14:47:42 | Train | Epoch[452/600] Iteration[025/030] Train loss: 0.0084
2023-02-06 14:47:42 | Train | Epoch[452/600] Iteration[026/030] Train loss: 0.0083
2023-02-06 14:47:42 | Train | Epoch[452/600] Iteration[027/030] Train loss: 0.0083
2023-02-06 14:47:42 | Train | Epoch[452/600] Iteration[028/030] Train loss: 0.0083
2023-02-06 14:47:43 | Train | Epoch[452/600] Iteration[029/030] Train loss: 0.0082
2023-02-06 14:47:43 | Train | Epoch[452/600] Iteration[030/030] Train loss: 0.0083
2023-02-06 14:47:43 | Valid | Epoch[452/600] Iteration[001/008] Valid loss: 0.1358
2023-02-06 14:47:43 | Valid | Epoch[452/600] Iteration[002/008] Valid loss: 0.1055
2023-02-06 14:47:43 | Valid | Epoch[452/600] Iteration[003/008] Valid loss: 0.1005
2023-02-06 14:47:43 | Valid | Epoch[452/600] Iteration[004/008] Valid loss: 0.0950
2023-02-06 14:47:43 | Valid | Epoch[452/600] Iteration[005/008] Valid loss: 0.0926
2023-02-06 14:47:43 | Valid | Epoch[452/600] Iteration[006/008] Valid loss: 0.0887
2023-02-06 14:47:43 | Valid | Epoch[452/600] Iteration[007/008] Valid loss: 0.0923
2023-02-06 14:47:43 | Valid | Epoch[452/600] Iteration[008/008] Valid loss: 0.0900
2023-02-06 14:47:43 | Valid | Epoch[452/600] MIou: 0.9249106387266447
2023-02-06 14:47:43 | Valid | Epoch[452/600] Pixel Accuracy: 0.9872360229492188
2023-02-06 14:47:43 | Valid | Epoch[452/600] Mean Pixel Accuracy: 0.9459634371088519
2023-02-06 14:47:43 | Stage | Epoch[452/600] Train loss:0.0083
2023-02-06 14:47:43 | Stage | Epoch[452/600] Valid loss:0.0900
2023-02-06 14:47:43 | Stage | Epoch[452/600] LR:0.001

2023-02-06 14:47:44 | Train | Epoch[453/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:47:44 | Train | Epoch[453/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:47:44 | Train | Epoch[453/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:47:45 | Train | Epoch[453/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 14:47:45 | Train | Epoch[453/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 14:47:45 | Train | Epoch[453/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:47:45 | Train | Epoch[453/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:47:45 | Train | Epoch[453/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:47:46 | Train | Epoch[453/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:47:46 | Train | Epoch[453/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:47:46 | Train | Epoch[453/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:47:46 | Train | Epoch[453/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:47:47 | Train | Epoch[453/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:47:47 | Train | Epoch[453/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:47:47 | Train | Epoch[453/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:47:47 | Train | Epoch[453/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:47:47 | Train | Epoch[453/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:47:48 | Train | Epoch[453/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:47:48 | Train | Epoch[453/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:47:48 | Train | Epoch[453/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:47:48 | Train | Epoch[453/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:47:49 | Train | Epoch[453/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:47:49 | Train | Epoch[453/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:47:49 | Train | Epoch[453/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:47:49 | Train | Epoch[453/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:47:49 | Train | Epoch[453/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:47:50 | Train | Epoch[453/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:47:50 | Train | Epoch[453/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:47:50 | Train | Epoch[453/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:47:50 | Train | Epoch[453/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:47:50 | Valid | Epoch[453/600] Iteration[001/008] Valid loss: 0.2427
2023-02-06 14:47:51 | Valid | Epoch[453/600] Iteration[002/008] Valid loss: 0.1983
2023-02-06 14:47:51 | Valid | Epoch[453/600] Iteration[003/008] Valid loss: 0.1907
2023-02-06 14:47:51 | Valid | Epoch[453/600] Iteration[004/008] Valid loss: 0.1831
2023-02-06 14:47:51 | Valid | Epoch[453/600] Iteration[005/008] Valid loss: 0.1853
2023-02-06 14:47:51 | Valid | Epoch[453/600] Iteration[006/008] Valid loss: 0.1813
2023-02-06 14:47:51 | Valid | Epoch[453/600] Iteration[007/008] Valid loss: 0.1973
2023-02-06 14:47:51 | Valid | Epoch[453/600] Iteration[008/008] Valid loss: 0.1970
2023-02-06 14:47:51 | Valid | Epoch[453/600] MIou: 0.9297097829710332
2023-02-06 14:47:51 | Valid | Epoch[453/600] Pixel Accuracy: 0.9875780741373698
2023-02-06 14:47:51 | Valid | Epoch[453/600] Mean Pixel Accuracy: 0.9685967121827526
2023-02-06 14:47:51 | Stage | Epoch[453/600] Train loss:0.0078
2023-02-06 14:47:51 | Stage | Epoch[453/600] Valid loss:0.1970
2023-02-06 14:47:51 | Stage | Epoch[453/600] LR:0.001

2023-02-06 14:47:51 | Train | Epoch[454/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 14:47:52 | Train | Epoch[454/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 14:47:52 | Train | Epoch[454/600] Iteration[003/030] Train loss: 0.0082
2023-02-06 14:47:52 | Train | Epoch[454/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:47:52 | Train | Epoch[454/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:47:52 | Train | Epoch[454/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:47:53 | Train | Epoch[454/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:47:53 | Train | Epoch[454/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:47:53 | Train | Epoch[454/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:47:53 | Train | Epoch[454/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:47:54 | Train | Epoch[454/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:47:54 | Train | Epoch[454/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:47:54 | Train | Epoch[454/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:47:54 | Train | Epoch[454/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:47:54 | Train | Epoch[454/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:47:55 | Train | Epoch[454/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:47:55 | Train | Epoch[454/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:47:55 | Train | Epoch[454/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:47:55 | Train | Epoch[454/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:47:56 | Train | Epoch[454/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:47:56 | Train | Epoch[454/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:47:56 | Train | Epoch[454/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:47:56 | Train | Epoch[454/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:47:56 | Train | Epoch[454/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:47:57 | Train | Epoch[454/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:47:57 | Train | Epoch[454/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:47:57 | Train | Epoch[454/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:47:57 | Train | Epoch[454/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:47:57 | Train | Epoch[454/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:47:58 | Train | Epoch[454/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:47:58 | Valid | Epoch[454/600] Iteration[001/008] Valid loss: 0.1284
2023-02-06 14:47:58 | Valid | Epoch[454/600] Iteration[002/008] Valid loss: 0.1001
2023-02-06 14:47:58 | Valid | Epoch[454/600] Iteration[003/008] Valid loss: 0.0957
2023-02-06 14:47:58 | Valid | Epoch[454/600] Iteration[004/008] Valid loss: 0.0906
2023-02-06 14:47:58 | Valid | Epoch[454/600] Iteration[005/008] Valid loss: 0.0885
2023-02-06 14:47:58 | Valid | Epoch[454/600] Iteration[006/008] Valid loss: 0.0851
2023-02-06 14:47:58 | Valid | Epoch[454/600] Iteration[007/008] Valid loss: 0.0882
2023-02-06 14:47:58 | Valid | Epoch[454/600] Iteration[008/008] Valid loss: 0.0860
2023-02-06 14:47:58 | Valid | Epoch[454/600] MIou: 0.9231592213843649
2023-02-06 14:47:58 | Valid | Epoch[454/600] Pixel Accuracy: 0.9869600931803385
2023-02-06 14:47:58 | Valid | Epoch[454/600] Mean Pixel Accuracy: 0.9435545664814549
2023-02-06 14:47:58 | Stage | Epoch[454/600] Train loss:0.0078
2023-02-06 14:47:58 | Stage | Epoch[454/600] Valid loss:0.0860
2023-02-06 14:47:58 | Stage | Epoch[454/600] LR:0.001

2023-02-06 14:47:59 | Train | Epoch[455/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 14:47:59 | Train | Epoch[455/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:47:59 | Train | Epoch[455/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:47:59 | Train | Epoch[455/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:48:00 | Train | Epoch[455/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:48:00 | Train | Epoch[455/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:48:00 | Train | Epoch[455/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 14:48:00 | Train | Epoch[455/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:48:01 | Train | Epoch[455/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:48:01 | Train | Epoch[455/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:48:01 | Train | Epoch[455/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:48:01 | Train | Epoch[455/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:48:01 | Train | Epoch[455/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:48:02 | Train | Epoch[455/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:48:02 | Train | Epoch[455/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:48:02 | Train | Epoch[455/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:48:02 | Train | Epoch[455/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:48:02 | Train | Epoch[455/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:48:03 | Train | Epoch[455/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:48:03 | Train | Epoch[455/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:48:03 | Train | Epoch[455/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:48:03 | Train | Epoch[455/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:48:04 | Train | Epoch[455/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:48:04 | Train | Epoch[455/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:48:04 | Train | Epoch[455/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:48:04 | Train | Epoch[455/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:48:04 | Train | Epoch[455/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:48:05 | Train | Epoch[455/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:48:05 | Train | Epoch[455/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:48:05 | Train | Epoch[455/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:48:05 | Valid | Epoch[455/600] Iteration[001/008] Valid loss: 0.2557
2023-02-06 14:48:05 | Valid | Epoch[455/600] Iteration[002/008] Valid loss: 0.2034
2023-02-06 14:48:05 | Valid | Epoch[455/600] Iteration[003/008] Valid loss: 0.1960
2023-02-06 14:48:05 | Valid | Epoch[455/600] Iteration[004/008] Valid loss: 0.1886
2023-02-06 14:48:06 | Valid | Epoch[455/600] Iteration[005/008] Valid loss: 0.1901
2023-02-06 14:48:06 | Valid | Epoch[455/600] Iteration[006/008] Valid loss: 0.1858
2023-02-06 14:48:06 | Valid | Epoch[455/600] Iteration[007/008] Valid loss: 0.2013
2023-02-06 14:48:06 | Valid | Epoch[455/600] Iteration[008/008] Valid loss: 0.2012
2023-02-06 14:48:06 | Valid | Epoch[455/600] MIou: 0.9294028842204631
2023-02-06 14:48:06 | Valid | Epoch[455/600] Pixel Accuracy: 0.9875094095865885
2023-02-06 14:48:06 | Valid | Epoch[455/600] Mean Pixel Accuracy: 0.9688442924352144
2023-02-06 14:48:06 | Stage | Epoch[455/600] Train loss:0.0078
2023-02-06 14:48:06 | Stage | Epoch[455/600] Valid loss:0.2012
2023-02-06 14:48:06 | Stage | Epoch[455/600] LR:0.001

2023-02-06 14:48:06 | Train | Epoch[456/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 14:48:06 | Train | Epoch[456/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:48:07 | Train | Epoch[456/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:48:07 | Train | Epoch[456/600] Iteration[004/030] Train loss: 0.0082
2023-02-06 14:48:07 | Train | Epoch[456/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:48:07 | Train | Epoch[456/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:48:07 | Train | Epoch[456/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:48:08 | Train | Epoch[456/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:48:08 | Train | Epoch[456/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:48:08 | Train | Epoch[456/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:48:08 | Train | Epoch[456/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:48:09 | Train | Epoch[456/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:48:09 | Train | Epoch[456/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:48:09 | Train | Epoch[456/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:48:09 | Train | Epoch[456/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:48:09 | Train | Epoch[456/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:48:10 | Train | Epoch[456/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:48:10 | Train | Epoch[456/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:48:10 | Train | Epoch[456/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:48:10 | Train | Epoch[456/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:48:11 | Train | Epoch[456/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:48:11 | Train | Epoch[456/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:48:11 | Train | Epoch[456/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:48:11 | Train | Epoch[456/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:48:11 | Train | Epoch[456/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:48:12 | Train | Epoch[456/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:48:12 | Train | Epoch[456/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:48:12 | Train | Epoch[456/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:48:12 | Train | Epoch[456/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:48:12 | Train | Epoch[456/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:48:13 | Valid | Epoch[456/600] Iteration[001/008] Valid loss: 0.2086
2023-02-06 14:48:13 | Valid | Epoch[456/600] Iteration[002/008] Valid loss: 0.1659
2023-02-06 14:48:13 | Valid | Epoch[456/600] Iteration[003/008] Valid loss: 0.1584
2023-02-06 14:48:13 | Valid | Epoch[456/600] Iteration[004/008] Valid loss: 0.1507
2023-02-06 14:48:13 | Valid | Epoch[456/600] Iteration[005/008] Valid loss: 0.1496
2023-02-06 14:48:13 | Valid | Epoch[456/600] Iteration[006/008] Valid loss: 0.1453
2023-02-06 14:48:13 | Valid | Epoch[456/600] Iteration[007/008] Valid loss: 0.1569
2023-02-06 14:48:13 | Valid | Epoch[456/600] Iteration[008/008] Valid loss: 0.1547
2023-02-06 14:48:13 | Valid | Epoch[456/600] MIou: 0.9312348897085001
2023-02-06 14:48:13 | Valid | Epoch[456/600] Pixel Accuracy: 0.9880142211914062
2023-02-06 14:48:13 | Valid | Epoch[456/600] Mean Pixel Accuracy: 0.9635611649068225
2023-02-06 14:48:13 | Stage | Epoch[456/600] Train loss:0.0078
2023-02-06 14:48:13 | Stage | Epoch[456/600] Valid loss:0.1547
2023-02-06 14:48:13 | Stage | Epoch[456/600] LR:0.001

2023-02-06 14:48:14 | Train | Epoch[457/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:48:14 | Train | Epoch[457/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:48:14 | Train | Epoch[457/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:48:14 | Train | Epoch[457/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:48:15 | Train | Epoch[457/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:48:15 | Train | Epoch[457/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:48:15 | Train | Epoch[457/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:48:15 | Train | Epoch[457/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:48:15 | Train | Epoch[457/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:48:16 | Train | Epoch[457/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:48:16 | Train | Epoch[457/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:48:16 | Train | Epoch[457/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:48:16 | Train | Epoch[457/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:48:17 | Train | Epoch[457/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:48:17 | Train | Epoch[457/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:48:17 | Train | Epoch[457/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:48:17 | Train | Epoch[457/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:48:17 | Train | Epoch[457/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:48:18 | Train | Epoch[457/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:48:18 | Train | Epoch[457/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:48:18 | Train | Epoch[457/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:48:18 | Train | Epoch[457/600] Iteration[022/030] Train loss: 0.0081
2023-02-06 14:48:19 | Train | Epoch[457/600] Iteration[023/030] Train loss: 0.0081
2023-02-06 14:48:19 | Train | Epoch[457/600] Iteration[024/030] Train loss: 0.0081
2023-02-06 14:48:19 | Train | Epoch[457/600] Iteration[025/030] Train loss: 0.0081
2023-02-06 14:48:19 | Train | Epoch[457/600] Iteration[026/030] Train loss: 0.0081
2023-02-06 14:48:19 | Train | Epoch[457/600] Iteration[027/030] Train loss: 0.0081
2023-02-06 14:48:20 | Train | Epoch[457/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:48:20 | Train | Epoch[457/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:48:20 | Train | Epoch[457/600] Iteration[030/030] Train loss: 0.0080
2023-02-06 14:48:20 | Valid | Epoch[457/600] Iteration[001/008] Valid loss: 0.1232
2023-02-06 14:48:20 | Valid | Epoch[457/600] Iteration[002/008] Valid loss: 0.0982
2023-02-06 14:48:20 | Valid | Epoch[457/600] Iteration[003/008] Valid loss: 0.0951
2023-02-06 14:48:20 | Valid | Epoch[457/600] Iteration[004/008] Valid loss: 0.0900
2023-02-06 14:48:20 | Valid | Epoch[457/600] Iteration[005/008] Valid loss: 0.0871
2023-02-06 14:48:21 | Valid | Epoch[457/600] Iteration[006/008] Valid loss: 0.0838
2023-02-06 14:48:21 | Valid | Epoch[457/600] Iteration[007/008] Valid loss: 0.0865
2023-02-06 14:48:21 | Valid | Epoch[457/600] Iteration[008/008] Valid loss: 0.0844
2023-02-06 14:48:21 | Valid | Epoch[457/600] MIou: 0.9211022819739747
2023-02-06 14:48:21 | Valid | Epoch[457/600] Pixel Accuracy: 0.9866320292154948
2023-02-06 14:48:21 | Valid | Epoch[457/600] Mean Pixel Accuracy: 0.940907805116588
2023-02-06 14:48:21 | Stage | Epoch[457/600] Train loss:0.0080
2023-02-06 14:48:21 | Stage | Epoch[457/600] Valid loss:0.0844
2023-02-06 14:48:21 | Stage | Epoch[457/600] LR:0.001

2023-02-06 14:48:21 | Train | Epoch[458/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:48:21 | Train | Epoch[458/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 14:48:22 | Train | Epoch[458/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 14:48:22 | Train | Epoch[458/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:48:22 | Train | Epoch[458/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:48:22 | Train | Epoch[458/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:48:22 | Train | Epoch[458/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:48:23 | Train | Epoch[458/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:48:23 | Train | Epoch[458/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:48:23 | Train | Epoch[458/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:48:23 | Train | Epoch[458/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:48:24 | Train | Epoch[458/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:48:24 | Train | Epoch[458/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:48:24 | Train | Epoch[458/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:48:24 | Train | Epoch[458/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:48:24 | Train | Epoch[458/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:48:25 | Train | Epoch[458/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:48:25 | Train | Epoch[458/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:48:25 | Train | Epoch[458/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:48:25 | Train | Epoch[458/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:48:26 | Train | Epoch[458/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:48:26 | Train | Epoch[458/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:48:26 | Train | Epoch[458/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:48:26 | Train | Epoch[458/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:48:26 | Train | Epoch[458/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:48:27 | Train | Epoch[458/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:48:27 | Train | Epoch[458/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:48:27 | Train | Epoch[458/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:48:27 | Train | Epoch[458/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:48:27 | Train | Epoch[458/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:48:28 | Valid | Epoch[458/600] Iteration[001/008] Valid loss: 0.1581
2023-02-06 14:48:28 | Valid | Epoch[458/600] Iteration[002/008] Valid loss: 0.1253
2023-02-06 14:48:28 | Valid | Epoch[458/600] Iteration[003/008] Valid loss: 0.1185
2023-02-06 14:48:28 | Valid | Epoch[458/600] Iteration[004/008] Valid loss: 0.1117
2023-02-06 14:48:28 | Valid | Epoch[458/600] Iteration[005/008] Valid loss: 0.1100
2023-02-06 14:48:28 | Valid | Epoch[458/600] Iteration[006/008] Valid loss: 0.1061
2023-02-06 14:48:28 | Valid | Epoch[458/600] Iteration[007/008] Valid loss: 0.1128
2023-02-06 14:48:28 | Valid | Epoch[458/600] Iteration[008/008] Valid loss: 0.1110
2023-02-06 14:48:28 | Valid | Epoch[458/600] MIou: 0.9287727346602057
2023-02-06 14:48:28 | Valid | Epoch[458/600] Pixel Accuracy: 0.9877738952636719
2023-02-06 14:48:28 | Valid | Epoch[458/600] Mean Pixel Accuracy: 0.954070535575457
2023-02-06 14:48:28 | Stage | Epoch[458/600] Train loss:0.0079
2023-02-06 14:48:28 | Stage | Epoch[458/600] Valid loss:0.1110
2023-02-06 14:48:28 | Stage | Epoch[458/600] LR:0.001

2023-02-06 14:48:29 | Train | Epoch[459/600] Iteration[001/030] Train loss: 0.0082
2023-02-06 14:48:29 | Train | Epoch[459/600] Iteration[002/030] Train loss: 0.0085
2023-02-06 14:48:29 | Train | Epoch[459/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:48:29 | Train | Epoch[459/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:48:30 | Train | Epoch[459/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:48:30 | Train | Epoch[459/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:48:30 | Train | Epoch[459/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:48:30 | Train | Epoch[459/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:48:30 | Train | Epoch[459/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:48:31 | Train | Epoch[459/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:48:31 | Train | Epoch[459/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:48:31 | Train | Epoch[459/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:48:31 | Train | Epoch[459/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 14:48:31 | Train | Epoch[459/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:48:32 | Train | Epoch[459/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:48:32 | Train | Epoch[459/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:48:32 | Train | Epoch[459/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:48:32 | Train | Epoch[459/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:48:33 | Train | Epoch[459/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:48:33 | Train | Epoch[459/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:48:33 | Train | Epoch[459/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:48:33 | Train | Epoch[459/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:48:33 | Train | Epoch[459/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:48:34 | Train | Epoch[459/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:48:34 | Train | Epoch[459/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:48:34 | Train | Epoch[459/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:48:34 | Train | Epoch[459/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:48:35 | Train | Epoch[459/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:48:35 | Train | Epoch[459/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:48:35 | Train | Epoch[459/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:48:35 | Valid | Epoch[459/600] Iteration[001/008] Valid loss: 0.2099
2023-02-06 14:48:35 | Valid | Epoch[459/600] Iteration[002/008] Valid loss: 0.1646
2023-02-06 14:48:35 | Valid | Epoch[459/600] Iteration[003/008] Valid loss: 0.1589
2023-02-06 14:48:35 | Valid | Epoch[459/600] Iteration[004/008] Valid loss: 0.1512
2023-02-06 14:48:35 | Valid | Epoch[459/600] Iteration[005/008] Valid loss: 0.1506
2023-02-06 14:48:35 | Valid | Epoch[459/600] Iteration[006/008] Valid loss: 0.1456
2023-02-06 14:48:35 | Valid | Epoch[459/600] Iteration[007/008] Valid loss: 0.1559
2023-02-06 14:48:36 | Valid | Epoch[459/600] Iteration[008/008] Valid loss: 0.1547
2023-02-06 14:48:36 | Valid | Epoch[459/600] MIou: 0.9300112776479077
2023-02-06 14:48:36 | Valid | Epoch[459/600] Pixel Accuracy: 0.9877764383951823
2023-02-06 14:48:36 | Valid | Epoch[459/600] Mean Pixel Accuracy: 0.9633100003820974
2023-02-06 14:48:36 | Stage | Epoch[459/600] Train loss:0.0076
2023-02-06 14:48:36 | Stage | Epoch[459/600] Valid loss:0.1547
2023-02-06 14:48:36 | Stage | Epoch[459/600] LR:0.001

2023-02-06 14:48:36 | Train | Epoch[460/600] Iteration[001/030] Train loss: 0.0074
2023-02-06 14:48:36 | Train | Epoch[460/600] Iteration[002/030] Train loss: 0.0087
2023-02-06 14:48:36 | Train | Epoch[460/600] Iteration[003/030] Train loss: 0.0085
2023-02-06 14:48:37 | Train | Epoch[460/600] Iteration[004/030] Train loss: 0.0082
2023-02-06 14:48:37 | Train | Epoch[460/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:48:37 | Train | Epoch[460/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:48:37 | Train | Epoch[460/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:48:38 | Train | Epoch[460/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:48:38 | Train | Epoch[460/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:48:38 | Train | Epoch[460/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:48:38 | Train | Epoch[460/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:48:39 | Train | Epoch[460/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:48:39 | Train | Epoch[460/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:48:39 | Train | Epoch[460/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:48:39 | Train | Epoch[460/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:48:39 | Train | Epoch[460/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:48:40 | Train | Epoch[460/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:48:40 | Train | Epoch[460/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:48:40 | Train | Epoch[460/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:48:40 | Train | Epoch[460/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:48:40 | Train | Epoch[460/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:48:41 | Train | Epoch[460/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:48:41 | Train | Epoch[460/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:48:41 | Train | Epoch[460/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:48:41 | Train | Epoch[460/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:48:42 | Train | Epoch[460/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:48:42 | Train | Epoch[460/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:48:42 | Train | Epoch[460/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:48:42 | Train | Epoch[460/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:48:42 | Train | Epoch[460/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:48:43 | Valid | Epoch[460/600] Iteration[001/008] Valid loss: 0.1975
2023-02-06 14:48:43 | Valid | Epoch[460/600] Iteration[002/008] Valid loss: 0.1560
2023-02-06 14:48:43 | Valid | Epoch[460/600] Iteration[003/008] Valid loss: 0.1486
2023-02-06 14:48:43 | Valid | Epoch[460/600] Iteration[004/008] Valid loss: 0.1407
2023-02-06 14:48:43 | Valid | Epoch[460/600] Iteration[005/008] Valid loss: 0.1398
2023-02-06 14:48:43 | Valid | Epoch[460/600] Iteration[006/008] Valid loss: 0.1357
2023-02-06 14:48:43 | Valid | Epoch[460/600] Iteration[007/008] Valid loss: 0.1453
2023-02-06 14:48:43 | Valid | Epoch[460/600] Iteration[008/008] Valid loss: 0.1434
2023-02-06 14:48:43 | Valid | Epoch[460/600] MIou: 0.9305799636674761
2023-02-06 14:48:43 | Valid | Epoch[460/600] Pixel Accuracy: 0.987921396891276
2023-02-06 14:48:43 | Valid | Epoch[460/600] Mean Pixel Accuracy: 0.9620962195654165
2023-02-06 14:48:43 | Stage | Epoch[460/600] Train loss:0.0079
2023-02-06 14:48:43 | Stage | Epoch[460/600] Valid loss:0.1434
2023-02-06 14:48:43 | Stage | Epoch[460/600] LR:0.001

2023-02-06 14:48:44 | Train | Epoch[461/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 14:48:44 | Train | Epoch[461/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:48:44 | Train | Epoch[461/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:48:44 | Train | Epoch[461/600] Iteration[004/030] Train loss: 0.0085
2023-02-06 14:48:44 | Train | Epoch[461/600] Iteration[005/030] Train loss: 0.0084
2023-02-06 14:48:45 | Train | Epoch[461/600] Iteration[006/030] Train loss: 0.0087
2023-02-06 14:48:45 | Train | Epoch[461/600] Iteration[007/030] Train loss: 0.0086
2023-02-06 14:48:45 | Train | Epoch[461/600] Iteration[008/030] Train loss: 0.0084
2023-02-06 14:48:45 | Train | Epoch[461/600] Iteration[009/030] Train loss: 0.0085
2023-02-06 14:48:46 | Train | Epoch[461/600] Iteration[010/030] Train loss: 0.0084
2023-02-06 14:48:46 | Train | Epoch[461/600] Iteration[011/030] Train loss: 0.0082
2023-02-06 14:48:46 | Train | Epoch[461/600] Iteration[012/030] Train loss: 0.0082
2023-02-06 14:48:46 | Train | Epoch[461/600] Iteration[013/030] Train loss: 0.0081
2023-02-06 14:48:46 | Train | Epoch[461/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:48:47 | Train | Epoch[461/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 14:48:47 | Train | Epoch[461/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:48:47 | Train | Epoch[461/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:48:47 | Train | Epoch[461/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:48:48 | Train | Epoch[461/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:48:48 | Train | Epoch[461/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:48:48 | Train | Epoch[461/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:48:48 | Train | Epoch[461/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:48:48 | Train | Epoch[461/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:48:49 | Train | Epoch[461/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:48:49 | Train | Epoch[461/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:48:49 | Train | Epoch[461/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:48:49 | Train | Epoch[461/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:48:49 | Train | Epoch[461/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:48:50 | Train | Epoch[461/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:48:50 | Train | Epoch[461/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:48:50 | Valid | Epoch[461/600] Iteration[001/008] Valid loss: 0.1384
2023-02-06 14:48:50 | Valid | Epoch[461/600] Iteration[002/008] Valid loss: 0.1095
2023-02-06 14:48:50 | Valid | Epoch[461/600] Iteration[003/008] Valid loss: 0.1051
2023-02-06 14:48:50 | Valid | Epoch[461/600] Iteration[004/008] Valid loss: 0.0992
2023-02-06 14:48:50 | Valid | Epoch[461/600] Iteration[005/008] Valid loss: 0.0968
2023-02-06 14:48:50 | Valid | Epoch[461/600] Iteration[006/008] Valid loss: 0.0929
2023-02-06 14:48:50 | Valid | Epoch[461/600] Iteration[007/008] Valid loss: 0.0969
2023-02-06 14:48:50 | Valid | Epoch[461/600] Iteration[008/008] Valid loss: 0.0945
2023-02-06 14:48:51 | Valid | Epoch[461/600] MIou: 0.9252762783005883
2023-02-06 14:48:51 | Valid | Epoch[461/600] Pixel Accuracy: 0.9872576395670573
2023-02-06 14:48:51 | Valid | Epoch[461/600] Mean Pixel Accuracy: 0.9477443100758126
2023-02-06 14:48:51 | Stage | Epoch[461/600] Train loss:0.0079
2023-02-06 14:48:51 | Stage | Epoch[461/600] Valid loss:0.0945
2023-02-06 14:48:51 | Stage | Epoch[461/600] LR:0.001

2023-02-06 14:48:51 | Train | Epoch[462/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 14:48:51 | Train | Epoch[462/600] Iteration[002/030] Train loss: 0.0083
2023-02-06 14:48:51 | Train | Epoch[462/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:48:52 | Train | Epoch[462/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:48:52 | Train | Epoch[462/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:48:52 | Train | Epoch[462/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:48:52 | Train | Epoch[462/600] Iteration[007/030] Train loss: 0.0082
2023-02-06 14:48:53 | Train | Epoch[462/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:48:53 | Train | Epoch[462/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:48:53 | Train | Epoch[462/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:48:53 | Train | Epoch[462/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:48:53 | Train | Epoch[462/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:48:54 | Train | Epoch[462/600] Iteration[013/030] Train loss: 0.0082
2023-02-06 14:48:54 | Train | Epoch[462/600] Iteration[014/030] Train loss: 0.0083
2023-02-06 14:48:54 | Train | Epoch[462/600] Iteration[015/030] Train loss: 0.0083
2023-02-06 14:48:54 | Train | Epoch[462/600] Iteration[016/030] Train loss: 0.0083
2023-02-06 14:48:55 | Train | Epoch[462/600] Iteration[017/030] Train loss: 0.0082
2023-02-06 14:48:55 | Train | Epoch[462/600] Iteration[018/030] Train loss: 0.0082
2023-02-06 14:48:55 | Train | Epoch[462/600] Iteration[019/030] Train loss: 0.0081
2023-02-06 14:48:55 | Train | Epoch[462/600] Iteration[020/030] Train loss: 0.0081
2023-02-06 14:48:55 | Train | Epoch[462/600] Iteration[021/030] Train loss: 0.0081
2023-02-06 14:48:56 | Train | Epoch[462/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:48:56 | Train | Epoch[462/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:48:56 | Train | Epoch[462/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:48:56 | Train | Epoch[462/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:48:57 | Train | Epoch[462/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:48:57 | Train | Epoch[462/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:48:57 | Train | Epoch[462/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:48:57 | Train | Epoch[462/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:48:57 | Train | Epoch[462/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:48:58 | Valid | Epoch[462/600] Iteration[001/008] Valid loss: 0.1739
2023-02-06 14:48:58 | Valid | Epoch[462/600] Iteration[002/008] Valid loss: 0.1379
2023-02-06 14:48:58 | Valid | Epoch[462/600] Iteration[003/008] Valid loss: 0.1317
2023-02-06 14:48:58 | Valid | Epoch[462/600] Iteration[004/008] Valid loss: 0.1248
2023-02-06 14:48:58 | Valid | Epoch[462/600] Iteration[005/008] Valid loss: 0.1246
2023-02-06 14:48:58 | Valid | Epoch[462/600] Iteration[006/008] Valid loss: 0.1205
2023-02-06 14:48:58 | Valid | Epoch[462/600] Iteration[007/008] Valid loss: 0.1292
2023-02-06 14:48:58 | Valid | Epoch[462/600] Iteration[008/008] Valid loss: 0.1274
2023-02-06 14:48:58 | Valid | Epoch[462/600] MIou: 0.930889104719725
2023-02-06 14:48:58 | Valid | Epoch[462/600] Pixel Accuracy: 0.9880727132161459
2023-02-06 14:48:58 | Valid | Epoch[462/600] Mean Pixel Accuracy: 0.958603363538237
2023-02-06 14:48:58 | Stage | Epoch[462/600] Train loss:0.0079
2023-02-06 14:48:58 | Stage | Epoch[462/600] Valid loss:0.1274
2023-02-06 14:48:58 | Stage | Epoch[462/600] LR:0.001

2023-02-06 14:48:59 | Train | Epoch[463/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 14:48:59 | Train | Epoch[463/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 14:48:59 | Train | Epoch[463/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:48:59 | Train | Epoch[463/600] Iteration[004/030] Train loss: 0.0083
2023-02-06 14:48:59 | Train | Epoch[463/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:49:00 | Train | Epoch[463/600] Iteration[006/030] Train loss: 0.0082
2023-02-06 14:49:00 | Train | Epoch[463/600] Iteration[007/030] Train loss: 0.0082
2023-02-06 14:49:00 | Train | Epoch[463/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:49:00 | Train | Epoch[463/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:49:00 | Train | Epoch[463/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:49:01 | Train | Epoch[463/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:49:01 | Train | Epoch[463/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:49:01 | Train | Epoch[463/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:49:01 | Train | Epoch[463/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:49:02 | Train | Epoch[463/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:49:02 | Train | Epoch[463/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:49:02 | Train | Epoch[463/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:49:02 | Train | Epoch[463/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:49:02 | Train | Epoch[463/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:49:03 | Train | Epoch[463/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:49:03 | Train | Epoch[463/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:49:03 | Train | Epoch[463/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:49:03 | Train | Epoch[463/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:49:04 | Train | Epoch[463/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:49:04 | Train | Epoch[463/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:49:04 | Train | Epoch[463/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:49:04 | Train | Epoch[463/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:49:04 | Train | Epoch[463/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:49:05 | Train | Epoch[463/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:49:05 | Train | Epoch[463/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:49:05 | Valid | Epoch[463/600] Iteration[001/008] Valid loss: 0.1289
2023-02-06 14:49:05 | Valid | Epoch[463/600] Iteration[002/008] Valid loss: 0.1000
2023-02-06 14:49:05 | Valid | Epoch[463/600] Iteration[003/008] Valid loss: 0.0960
2023-02-06 14:49:05 | Valid | Epoch[463/600] Iteration[004/008] Valid loss: 0.0917
2023-02-06 14:49:05 | Valid | Epoch[463/600] Iteration[005/008] Valid loss: 0.0890
2023-02-06 14:49:05 | Valid | Epoch[463/600] Iteration[006/008] Valid loss: 0.0857
2023-02-06 14:49:05 | Valid | Epoch[463/600] Iteration[007/008] Valid loss: 0.0892
2023-02-06 14:49:05 | Valid | Epoch[463/600] Iteration[008/008] Valid loss: 0.0865
2023-02-06 14:49:06 | Valid | Epoch[463/600] MIou: 0.9211951139350437
2023-02-06 14:49:06 | Valid | Epoch[463/600] Pixel Accuracy: 0.9866472880045573
2023-02-06 14:49:06 | Valid | Epoch[463/600] Mean Pixel Accuracy: 0.9410112990705095
2023-02-06 14:49:06 | Stage | Epoch[463/600] Train loss:0.0079
2023-02-06 14:49:06 | Stage | Epoch[463/600] Valid loss:0.0865
2023-02-06 14:49:06 | Stage | Epoch[463/600] LR:0.001

2023-02-06 14:49:06 | Train | Epoch[464/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 14:49:06 | Train | Epoch[464/600] Iteration[002/030] Train loss: 0.0086
2023-02-06 14:49:06 | Train | Epoch[464/600] Iteration[003/030] Train loss: 0.0082
2023-02-06 14:49:07 | Train | Epoch[464/600] Iteration[004/030] Train loss: 0.0082
2023-02-06 14:49:07 | Train | Epoch[464/600] Iteration[005/030] Train loss: 0.0083
2023-02-06 14:49:07 | Train | Epoch[464/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:49:07 | Train | Epoch[464/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:49:08 | Train | Epoch[464/600] Iteration[008/030] Train loss: 0.0082
2023-02-06 14:49:08 | Train | Epoch[464/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:49:08 | Train | Epoch[464/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:49:08 | Train | Epoch[464/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:49:08 | Train | Epoch[464/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:49:09 | Train | Epoch[464/600] Iteration[013/030] Train loss: 0.0081
2023-02-06 14:49:09 | Train | Epoch[464/600] Iteration[014/030] Train loss: 0.0081
2023-02-06 14:49:09 | Train | Epoch[464/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:49:09 | Train | Epoch[464/600] Iteration[016/030] Train loss: 0.0081
2023-02-06 14:49:10 | Train | Epoch[464/600] Iteration[017/030] Train loss: 0.0081
2023-02-06 14:49:10 | Train | Epoch[464/600] Iteration[018/030] Train loss: 0.0081
2023-02-06 14:49:10 | Train | Epoch[464/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:49:10 | Train | Epoch[464/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:49:10 | Train | Epoch[464/600] Iteration[021/030] Train loss: 0.0081
2023-02-06 14:49:11 | Train | Epoch[464/600] Iteration[022/030] Train loss: 0.0081
2023-02-06 14:49:11 | Train | Epoch[464/600] Iteration[023/030] Train loss: 0.0081
2023-02-06 14:49:11 | Train | Epoch[464/600] Iteration[024/030] Train loss: 0.0081
2023-02-06 14:49:11 | Train | Epoch[464/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:49:12 | Train | Epoch[464/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:49:12 | Train | Epoch[464/600] Iteration[027/030] Train loss: 0.0080
2023-02-06 14:49:12 | Train | Epoch[464/600] Iteration[028/030] Train loss: 0.0080
2023-02-06 14:49:12 | Train | Epoch[464/600] Iteration[029/030] Train loss: 0.0080
2023-02-06 14:49:12 | Train | Epoch[464/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:49:13 | Valid | Epoch[464/600] Iteration[001/008] Valid loss: 0.1320
2023-02-06 14:49:13 | Valid | Epoch[464/600] Iteration[002/008] Valid loss: 0.1054
2023-02-06 14:49:13 | Valid | Epoch[464/600] Iteration[003/008] Valid loss: 0.1008
2023-02-06 14:49:13 | Valid | Epoch[464/600] Iteration[004/008] Valid loss: 0.0957
2023-02-06 14:49:13 | Valid | Epoch[464/600] Iteration[005/008] Valid loss: 0.0933
2023-02-06 14:49:13 | Valid | Epoch[464/600] Iteration[006/008] Valid loss: 0.0898
2023-02-06 14:49:13 | Valid | Epoch[464/600] Iteration[007/008] Valid loss: 0.0936
2023-02-06 14:49:13 | Valid | Epoch[464/600] Iteration[008/008] Valid loss: 0.0909
2023-02-06 14:49:13 | Valid | Epoch[464/600] MIou: 0.924518298086398
2023-02-06 14:49:13 | Valid | Epoch[464/600] Pixel Accuracy: 0.9871788024902344
2023-02-06 14:49:13 | Valid | Epoch[464/600] Mean Pixel Accuracy: 0.94525989632392
2023-02-06 14:49:13 | Stage | Epoch[464/600] Train loss:0.0079
2023-02-06 14:49:13 | Stage | Epoch[464/600] Valid loss:0.0909
2023-02-06 14:49:13 | Stage | Epoch[464/600] LR:0.001

2023-02-06 14:49:14 | Train | Epoch[465/600] Iteration[001/030] Train loss: 0.0074
2023-02-06 14:49:14 | Train | Epoch[465/600] Iteration[002/030] Train loss: 0.0073
2023-02-06 14:49:14 | Train | Epoch[465/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 14:49:14 | Train | Epoch[465/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:49:14 | Train | Epoch[465/600] Iteration[005/030] Train loss: 0.0072
2023-02-06 14:49:15 | Train | Epoch[465/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 14:49:15 | Train | Epoch[465/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:49:15 | Train | Epoch[465/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 14:49:15 | Train | Epoch[465/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:49:16 | Train | Epoch[465/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 14:49:16 | Train | Epoch[465/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:49:16 | Train | Epoch[465/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:49:16 | Train | Epoch[465/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 14:49:16 | Train | Epoch[465/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:49:17 | Train | Epoch[465/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:49:17 | Train | Epoch[465/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:49:17 | Train | Epoch[465/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:49:17 | Train | Epoch[465/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:49:18 | Train | Epoch[465/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:49:18 | Train | Epoch[465/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:49:18 | Train | Epoch[465/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:49:18 | Train | Epoch[465/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:49:18 | Train | Epoch[465/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:49:19 | Train | Epoch[465/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:49:19 | Train | Epoch[465/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:49:19 | Train | Epoch[465/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:49:19 | Train | Epoch[465/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:49:19 | Train | Epoch[465/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:49:20 | Train | Epoch[465/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:49:20 | Train | Epoch[465/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:49:20 | Valid | Epoch[465/600] Iteration[001/008] Valid loss: 0.2624
2023-02-06 14:49:20 | Valid | Epoch[465/600] Iteration[002/008] Valid loss: 0.2146
2023-02-06 14:49:20 | Valid | Epoch[465/600] Iteration[003/008] Valid loss: 0.2072
2023-02-06 14:49:20 | Valid | Epoch[465/600] Iteration[004/008] Valid loss: 0.1982
2023-02-06 14:49:20 | Valid | Epoch[465/600] Iteration[005/008] Valid loss: 0.1998
2023-02-06 14:49:20 | Valid | Epoch[465/600] Iteration[006/008] Valid loss: 0.1957
2023-02-06 14:49:20 | Valid | Epoch[465/600] Iteration[007/008] Valid loss: 0.2117
2023-02-06 14:49:21 | Valid | Epoch[465/600] Iteration[008/008] Valid loss: 0.2131
2023-02-06 14:49:21 | Valid | Epoch[465/600] MIou: 0.927261553184695
2023-02-06 14:49:21 | Valid | Epoch[465/600] Pixel Accuracy: 0.987054189046224
2023-02-06 14:49:21 | Valid | Epoch[465/600] Mean Pixel Accuracy: 0.9695451545383555
2023-02-06 14:49:21 | Stage | Epoch[465/600] Train loss:0.0077
2023-02-06 14:49:21 | Stage | Epoch[465/600] Valid loss:0.2131
2023-02-06 14:49:21 | Stage | Epoch[465/600] LR:0.001

2023-02-06 14:49:21 | Train | Epoch[466/600] Iteration[001/030] Train loss: 0.0067
2023-02-06 14:49:21 | Train | Epoch[466/600] Iteration[002/030] Train loss: 0.0069
2023-02-06 14:49:22 | Train | Epoch[466/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:49:22 | Train | Epoch[466/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:49:22 | Train | Epoch[466/600] Iteration[005/030] Train loss: 0.0072
2023-02-06 14:49:22 | Train | Epoch[466/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 14:49:22 | Train | Epoch[466/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 14:49:23 | Train | Epoch[466/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 14:49:23 | Train | Epoch[466/600] Iteration[009/030] Train loss: 0.0072
2023-02-06 14:49:23 | Train | Epoch[466/600] Iteration[010/030] Train loss: 0.0072
2023-02-06 14:49:23 | Train | Epoch[466/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 14:49:24 | Train | Epoch[466/600] Iteration[012/030] Train loss: 0.0073
2023-02-06 14:49:24 | Train | Epoch[466/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:49:24 | Train | Epoch[466/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:49:24 | Train | Epoch[466/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 14:49:24 | Train | Epoch[466/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 14:49:25 | Train | Epoch[466/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:49:25 | Train | Epoch[466/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:49:25 | Train | Epoch[466/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:49:25 | Train | Epoch[466/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:49:25 | Train | Epoch[466/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:49:26 | Train | Epoch[466/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:49:26 | Train | Epoch[466/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:49:26 | Train | Epoch[466/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:49:26 | Train | Epoch[466/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:49:27 | Train | Epoch[466/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:49:27 | Train | Epoch[466/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:49:27 | Train | Epoch[466/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:49:27 | Train | Epoch[466/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:49:27 | Train | Epoch[466/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:49:28 | Valid | Epoch[466/600] Iteration[001/008] Valid loss: 0.1892
2023-02-06 14:49:28 | Valid | Epoch[466/600] Iteration[002/008] Valid loss: 0.1500
2023-02-06 14:49:28 | Valid | Epoch[466/600] Iteration[003/008] Valid loss: 0.1410
2023-02-06 14:49:28 | Valid | Epoch[466/600] Iteration[004/008] Valid loss: 0.1343
2023-02-06 14:49:28 | Valid | Epoch[466/600] Iteration[005/008] Valid loss: 0.1335
2023-02-06 14:49:28 | Valid | Epoch[466/600] Iteration[006/008] Valid loss: 0.1294
2023-02-06 14:49:28 | Valid | Epoch[466/600] Iteration[007/008] Valid loss: 0.1389
2023-02-06 14:49:28 | Valid | Epoch[466/600] Iteration[008/008] Valid loss: 0.1373
2023-02-06 14:49:28 | Valid | Epoch[466/600] MIou: 0.930945373326179
2023-02-06 14:49:28 | Valid | Epoch[466/600] Pixel Accuracy: 0.9880256652832031
2023-02-06 14:49:28 | Valid | Epoch[466/600] Mean Pixel Accuracy: 0.9608664142036067
2023-02-06 14:49:28 | Stage | Epoch[466/600] Train loss:0.0077
2023-02-06 14:49:28 | Stage | Epoch[466/600] Valid loss:0.1373
2023-02-06 14:49:28 | Stage | Epoch[466/600] LR:0.001

2023-02-06 14:49:29 | Train | Epoch[467/600] Iteration[001/030] Train loss: 0.0082
2023-02-06 14:49:29 | Train | Epoch[467/600] Iteration[002/030] Train loss: 0.0083
2023-02-06 14:49:29 | Train | Epoch[467/600] Iteration[003/030] Train loss: 0.0084
2023-02-06 14:49:29 | Train | Epoch[467/600] Iteration[004/030] Train loss: 0.0084
2023-02-06 14:49:29 | Train | Epoch[467/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:49:30 | Train | Epoch[467/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:49:30 | Train | Epoch[467/600] Iteration[007/030] Train loss: 0.0082
2023-02-06 14:49:30 | Train | Epoch[467/600] Iteration[008/030] Train loss: 0.0082
2023-02-06 14:49:30 | Train | Epoch[467/600] Iteration[009/030] Train loss: 0.0082
2023-02-06 14:49:31 | Train | Epoch[467/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:49:31 | Train | Epoch[467/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:49:31 | Train | Epoch[467/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:49:31 | Train | Epoch[467/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:49:31 | Train | Epoch[467/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:49:32 | Train | Epoch[467/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:49:32 | Train | Epoch[467/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:49:32 | Train | Epoch[467/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:49:32 | Train | Epoch[467/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:49:33 | Train | Epoch[467/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:49:33 | Train | Epoch[467/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:49:33 | Train | Epoch[467/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:49:33 | Train | Epoch[467/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:49:33 | Train | Epoch[467/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:49:34 | Train | Epoch[467/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:49:34 | Train | Epoch[467/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:49:34 | Train | Epoch[467/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:49:34 | Train | Epoch[467/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:49:35 | Train | Epoch[467/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:49:35 | Train | Epoch[467/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:49:35 | Train | Epoch[467/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:49:35 | Valid | Epoch[467/600] Iteration[001/008] Valid loss: 0.1455
2023-02-06 14:49:35 | Valid | Epoch[467/600] Iteration[002/008] Valid loss: 0.1138
2023-02-06 14:49:35 | Valid | Epoch[467/600] Iteration[003/008] Valid loss: 0.1090
2023-02-06 14:49:35 | Valid | Epoch[467/600] Iteration[004/008] Valid loss: 0.1036
2023-02-06 14:49:35 | Valid | Epoch[467/600] Iteration[005/008] Valid loss: 0.1012
2023-02-06 14:49:35 | Valid | Epoch[467/600] Iteration[006/008] Valid loss: 0.0975
2023-02-06 14:49:36 | Valid | Epoch[467/600] Iteration[007/008] Valid loss: 0.1023
2023-02-06 14:49:36 | Valid | Epoch[467/600] Iteration[008/008] Valid loss: 0.1000
2023-02-06 14:49:36 | Valid | Epoch[467/600] MIou: 0.9247922767770875
2023-02-06 14:49:36 | Valid | Epoch[467/600] Pixel Accuracy: 0.9871508280436198
2023-02-06 14:49:36 | Valid | Epoch[467/600] Mean Pixel Accuracy: 0.9481357753844877
2023-02-06 14:49:36 | Stage | Epoch[467/600] Train loss:0.0078
2023-02-06 14:49:36 | Stage | Epoch[467/600] Valid loss:0.1000
2023-02-06 14:49:36 | Stage | Epoch[467/600] LR:0.001

2023-02-06 14:49:36 | Train | Epoch[468/600] Iteration[001/030] Train loss: 0.0089
2023-02-06 14:49:36 | Train | Epoch[468/600] Iteration[002/030] Train loss: 0.0080
2023-02-06 14:49:37 | Train | Epoch[468/600] Iteration[003/030] Train loss: 0.0082
2023-02-06 14:49:37 | Train | Epoch[468/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:49:37 | Train | Epoch[468/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:49:37 | Train | Epoch[468/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 14:49:37 | Train | Epoch[468/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:49:38 | Train | Epoch[468/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:49:38 | Train | Epoch[468/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:49:38 | Train | Epoch[468/600] Iteration[010/030] Train loss: 0.0081
2023-02-06 14:49:38 | Train | Epoch[468/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:49:39 | Train | Epoch[468/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:49:39 | Train | Epoch[468/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:49:39 | Train | Epoch[468/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:49:39 | Train | Epoch[468/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:49:39 | Train | Epoch[468/600] Iteration[016/030] Train loss: 0.0081
2023-02-06 14:49:40 | Train | Epoch[468/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:49:40 | Train | Epoch[468/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:49:40 | Train | Epoch[468/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:49:40 | Train | Epoch[468/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:49:41 | Train | Epoch[468/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:49:41 | Train | Epoch[468/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:49:41 | Train | Epoch[468/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:49:41 | Train | Epoch[468/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:49:41 | Train | Epoch[468/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:49:42 | Train | Epoch[468/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:49:42 | Train | Epoch[468/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:49:42 | Train | Epoch[468/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:49:42 | Train | Epoch[468/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:49:42 | Train | Epoch[468/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:49:43 | Valid | Epoch[468/600] Iteration[001/008] Valid loss: 0.1657
2023-02-06 14:49:43 | Valid | Epoch[468/600] Iteration[002/008] Valid loss: 0.1302
2023-02-06 14:49:43 | Valid | Epoch[468/600] Iteration[003/008] Valid loss: 0.1224
2023-02-06 14:49:43 | Valid | Epoch[468/600] Iteration[004/008] Valid loss: 0.1158
2023-02-06 14:49:43 | Valid | Epoch[468/600] Iteration[005/008] Valid loss: 0.1141
2023-02-06 14:49:43 | Valid | Epoch[468/600] Iteration[006/008] Valid loss: 0.1099
2023-02-06 14:49:43 | Valid | Epoch[468/600] Iteration[007/008] Valid loss: 0.1175
2023-02-06 14:49:43 | Valid | Epoch[468/600] Iteration[008/008] Valid loss: 0.1152
2023-02-06 14:49:43 | Valid | Epoch[468/600] MIou: 0.9288552938550131
2023-02-06 14:49:43 | Valid | Epoch[468/600] Pixel Accuracy: 0.9877726236979166
2023-02-06 14:49:43 | Valid | Epoch[468/600] Mean Pixel Accuracy: 0.9547292457059433
2023-02-06 14:49:43 | Stage | Epoch[468/600] Train loss:0.0079
2023-02-06 14:49:43 | Stage | Epoch[468/600] Valid loss:0.1152
2023-02-06 14:49:43 | Stage | Epoch[468/600] LR:0.001

2023-02-06 14:49:44 | Train | Epoch[469/600] Iteration[001/030] Train loss: 0.0084
2023-02-06 14:49:44 | Train | Epoch[469/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:49:44 | Train | Epoch[469/600] Iteration[003/030] Train loss: 0.0078
2023-02-06 14:49:44 | Train | Epoch[469/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:49:45 | Train | Epoch[469/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:49:45 | Train | Epoch[469/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 14:49:45 | Train | Epoch[469/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:49:45 | Train | Epoch[469/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:49:45 | Train | Epoch[469/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:49:46 | Train | Epoch[469/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:49:46 | Train | Epoch[469/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:49:46 | Train | Epoch[469/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:49:46 | Train | Epoch[469/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:49:47 | Train | Epoch[469/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:49:47 | Train | Epoch[469/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:49:47 | Train | Epoch[469/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:49:47 | Train | Epoch[469/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:49:47 | Train | Epoch[469/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:49:48 | Train | Epoch[469/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:49:48 | Train | Epoch[469/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:49:48 | Train | Epoch[469/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:49:48 | Train | Epoch[469/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:49:48 | Train | Epoch[469/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:49:49 | Train | Epoch[469/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:49:49 | Train | Epoch[469/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:49:49 | Train | Epoch[469/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:49:49 | Train | Epoch[469/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:49:50 | Train | Epoch[469/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:49:50 | Train | Epoch[469/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:49:50 | Train | Epoch[469/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:49:50 | Valid | Epoch[469/600] Iteration[001/008] Valid loss: 0.1687
2023-02-06 14:49:50 | Valid | Epoch[469/600] Iteration[002/008] Valid loss: 0.1338
2023-02-06 14:49:50 | Valid | Epoch[469/600] Iteration[003/008] Valid loss: 0.1252
2023-02-06 14:49:50 | Valid | Epoch[469/600] Iteration[004/008] Valid loss: 0.1190
2023-02-06 14:49:50 | Valid | Epoch[469/600] Iteration[005/008] Valid loss: 0.1170
2023-02-06 14:49:50 | Valid | Epoch[469/600] Iteration[006/008] Valid loss: 0.1127
2023-02-06 14:49:51 | Valid | Epoch[469/600] Iteration[007/008] Valid loss: 0.1207
2023-02-06 14:49:51 | Valid | Epoch[469/600] Iteration[008/008] Valid loss: 0.1188
2023-02-06 14:49:51 | Valid | Epoch[469/600] MIou: 0.92951537679854
2023-02-06 14:49:51 | Valid | Epoch[469/600] Pixel Accuracy: 0.9878590901692709
2023-02-06 14:49:51 | Valid | Epoch[469/600] Mean Pixel Accuracy: 0.9563872511303736
2023-02-06 14:49:51 | Stage | Epoch[469/600] Train loss:0.0077
2023-02-06 14:49:51 | Stage | Epoch[469/600] Valid loss:0.1188
2023-02-06 14:49:51 | Stage | Epoch[469/600] LR:0.001

2023-02-06 14:49:51 | Train | Epoch[470/600] Iteration[001/030] Train loss: 0.0084
2023-02-06 14:49:51 | Train | Epoch[470/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:49:52 | Train | Epoch[470/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 14:49:52 | Train | Epoch[470/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:49:52 | Train | Epoch[470/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 14:49:52 | Train | Epoch[470/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:49:52 | Train | Epoch[470/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:49:53 | Train | Epoch[470/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:49:53 | Train | Epoch[470/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:49:53 | Train | Epoch[470/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:49:53 | Train | Epoch[470/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:49:54 | Train | Epoch[470/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:49:54 | Train | Epoch[470/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:49:54 | Train | Epoch[470/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:49:54 | Train | Epoch[470/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:49:54 | Train | Epoch[470/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:49:55 | Train | Epoch[470/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:49:55 | Train | Epoch[470/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:49:55 | Train | Epoch[470/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:49:55 | Train | Epoch[470/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:49:56 | Train | Epoch[470/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:49:56 | Train | Epoch[470/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:49:56 | Train | Epoch[470/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:49:56 | Train | Epoch[470/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:49:56 | Train | Epoch[470/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:49:57 | Train | Epoch[470/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:49:57 | Train | Epoch[470/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:49:57 | Train | Epoch[470/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:49:57 | Train | Epoch[470/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:49:57 | Train | Epoch[470/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:49:58 | Valid | Epoch[470/600] Iteration[001/008] Valid loss: 0.1901
2023-02-06 14:49:58 | Valid | Epoch[470/600] Iteration[002/008] Valid loss: 0.1493
2023-02-06 14:49:58 | Valid | Epoch[470/600] Iteration[003/008] Valid loss: 0.1406
2023-02-06 14:49:58 | Valid | Epoch[470/600] Iteration[004/008] Valid loss: 0.1338
2023-02-06 14:49:58 | Valid | Epoch[470/600] Iteration[005/008] Valid loss: 0.1334
2023-02-06 14:49:58 | Valid | Epoch[470/600] Iteration[006/008] Valid loss: 0.1288
2023-02-06 14:49:58 | Valid | Epoch[470/600] Iteration[007/008] Valid loss: 0.1379
2023-02-06 14:49:58 | Valid | Epoch[470/600] Iteration[008/008] Valid loss: 0.1362
2023-02-06 14:49:58 | Valid | Epoch[470/600] MIou: 0.9303142672322691
2023-02-06 14:49:58 | Valid | Epoch[470/600] Pixel Accuracy: 0.9879124959309896
2023-02-06 14:49:58 | Valid | Epoch[470/600] Mean Pixel Accuracy: 0.960398421324301
2023-02-06 14:49:58 | Stage | Epoch[470/600] Train loss:0.0078
2023-02-06 14:49:58 | Stage | Epoch[470/600] Valid loss:0.1362
2023-02-06 14:49:58 | Stage | Epoch[470/600] LR:0.001

2023-02-06 14:49:59 | Train | Epoch[471/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 14:49:59 | Train | Epoch[471/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 14:49:59 | Train | Epoch[471/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:49:59 | Train | Epoch[471/600] Iteration[004/030] Train loss: 0.0076
2023-02-06 14:50:00 | Train | Epoch[471/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:50:00 | Train | Epoch[471/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:50:00 | Train | Epoch[471/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:50:00 | Train | Epoch[471/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:50:00 | Train | Epoch[471/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:50:01 | Train | Epoch[471/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:50:01 | Train | Epoch[471/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:50:01 | Train | Epoch[471/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:50:01 | Train | Epoch[471/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:50:01 | Train | Epoch[471/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:50:02 | Train | Epoch[471/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:50:02 | Train | Epoch[471/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:50:02 | Train | Epoch[471/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:50:02 | Train | Epoch[471/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:50:03 | Train | Epoch[471/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:50:03 | Train | Epoch[471/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:50:03 | Train | Epoch[471/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:50:03 | Train | Epoch[471/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:50:03 | Train | Epoch[471/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:50:04 | Train | Epoch[471/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:50:04 | Train | Epoch[471/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:50:04 | Train | Epoch[471/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:50:04 | Train | Epoch[471/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:50:05 | Train | Epoch[471/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:50:05 | Train | Epoch[471/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:50:05 | Train | Epoch[471/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:50:05 | Valid | Epoch[471/600] Iteration[001/008] Valid loss: 0.2044
2023-02-06 14:50:05 | Valid | Epoch[471/600] Iteration[002/008] Valid loss: 0.1627
2023-02-06 14:50:05 | Valid | Epoch[471/600] Iteration[003/008] Valid loss: 0.1556
2023-02-06 14:50:05 | Valid | Epoch[471/600] Iteration[004/008] Valid loss: 0.1466
2023-02-06 14:50:05 | Valid | Epoch[471/600] Iteration[005/008] Valid loss: 0.1449
2023-02-06 14:50:06 | Valid | Epoch[471/600] Iteration[006/008] Valid loss: 0.1408
2023-02-06 14:50:06 | Valid | Epoch[471/600] Iteration[007/008] Valid loss: 0.1514
2023-02-06 14:50:06 | Valid | Epoch[471/600] Iteration[008/008] Valid loss: 0.1497
2023-02-06 14:50:06 | Valid | Epoch[471/600] MIou: 0.9295424802648461
2023-02-06 14:50:06 | Valid | Epoch[471/600] Pixel Accuracy: 0.9877268473307291
2023-02-06 14:50:06 | Valid | Epoch[471/600] Mean Pixel Accuracy: 0.9616215394819012
2023-02-06 14:50:06 | Stage | Epoch[471/600] Train loss:0.0078
2023-02-06 14:50:06 | Stage | Epoch[471/600] Valid loss:0.1497
2023-02-06 14:50:06 | Stage | Epoch[471/600] LR:0.001

2023-02-06 14:50:06 | Train | Epoch[472/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:50:06 | Train | Epoch[472/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 14:50:07 | Train | Epoch[472/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:50:07 | Train | Epoch[472/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:50:07 | Train | Epoch[472/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:50:07 | Train | Epoch[472/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:50:08 | Train | Epoch[472/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:50:08 | Train | Epoch[472/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:50:08 | Train | Epoch[472/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:50:08 | Train | Epoch[472/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 14:50:08 | Train | Epoch[472/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 14:50:09 | Train | Epoch[472/600] Iteration[012/030] Train loss: 0.0073
2023-02-06 14:50:09 | Train | Epoch[472/600] Iteration[013/030] Train loss: 0.0073
2023-02-06 14:50:09 | Train | Epoch[472/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:50:09 | Train | Epoch[472/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:50:10 | Train | Epoch[472/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:50:10 | Train | Epoch[472/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:50:10 | Train | Epoch[472/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:50:10 | Train | Epoch[472/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:50:10 | Train | Epoch[472/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:50:11 | Train | Epoch[472/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:50:11 | Train | Epoch[472/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:50:11 | Train | Epoch[472/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:50:11 | Train | Epoch[472/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:50:11 | Train | Epoch[472/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:50:12 | Train | Epoch[472/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:50:12 | Train | Epoch[472/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:50:12 | Train | Epoch[472/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:50:12 | Train | Epoch[472/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:50:12 | Train | Epoch[472/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:50:13 | Valid | Epoch[472/600] Iteration[001/008] Valid loss: 0.2346
2023-02-06 14:50:13 | Valid | Epoch[472/600] Iteration[002/008] Valid loss: 0.1886
2023-02-06 14:50:13 | Valid | Epoch[472/600] Iteration[003/008] Valid loss: 0.1794
2023-02-06 14:50:13 | Valid | Epoch[472/600] Iteration[004/008] Valid loss: 0.1707
2023-02-06 14:50:13 | Valid | Epoch[472/600] Iteration[005/008] Valid loss: 0.1707
2023-02-06 14:50:13 | Valid | Epoch[472/600] Iteration[006/008] Valid loss: 0.1663
2023-02-06 14:50:13 | Valid | Epoch[472/600] Iteration[007/008] Valid loss: 0.1792
2023-02-06 14:50:13 | Valid | Epoch[472/600] Iteration[008/008] Valid loss: 0.1788
2023-02-06 14:50:13 | Valid | Epoch[472/600] MIou: 0.9299925681102311
2023-02-06 14:50:13 | Valid | Epoch[472/600] Pixel Accuracy: 0.9876810709635416
2023-02-06 14:50:13 | Valid | Epoch[472/600] Mean Pixel Accuracy: 0.966833608307158
2023-02-06 14:50:13 | Stage | Epoch[472/600] Train loss:0.0077
2023-02-06 14:50:13 | Stage | Epoch[472/600] Valid loss:0.1788
2023-02-06 14:50:13 | Stage | Epoch[472/600] LR:0.001

2023-02-06 14:50:14 | Train | Epoch[473/600] Iteration[001/030] Train loss: 0.0070
2023-02-06 14:50:14 | Train | Epoch[473/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:50:14 | Train | Epoch[473/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:50:14 | Train | Epoch[473/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:50:15 | Train | Epoch[473/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:50:15 | Train | Epoch[473/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 14:50:15 | Train | Epoch[473/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:50:15 | Train | Epoch[473/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:50:15 | Train | Epoch[473/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:50:16 | Train | Epoch[473/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:50:16 | Train | Epoch[473/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:50:16 | Train | Epoch[473/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:50:16 | Train | Epoch[473/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:50:17 | Train | Epoch[473/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:50:17 | Train | Epoch[473/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:50:17 | Train | Epoch[473/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:50:17 | Train | Epoch[473/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:50:17 | Train | Epoch[473/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:50:18 | Train | Epoch[473/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:50:18 | Train | Epoch[473/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:50:18 | Train | Epoch[473/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:50:18 | Train | Epoch[473/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:50:19 | Train | Epoch[473/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:50:19 | Train | Epoch[473/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:50:19 | Train | Epoch[473/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:50:19 | Train | Epoch[473/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:50:19 | Train | Epoch[473/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:50:20 | Train | Epoch[473/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:50:20 | Train | Epoch[473/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:50:20 | Train | Epoch[473/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:50:20 | Valid | Epoch[473/600] Iteration[001/008] Valid loss: 0.1581
2023-02-06 14:50:20 | Valid | Epoch[473/600] Iteration[002/008] Valid loss: 0.1242
2023-02-06 14:50:20 | Valid | Epoch[473/600] Iteration[003/008] Valid loss: 0.1171
2023-02-06 14:50:20 | Valid | Epoch[473/600] Iteration[004/008] Valid loss: 0.1115
2023-02-06 14:50:20 | Valid | Epoch[473/600] Iteration[005/008] Valid loss: 0.1092
2023-02-06 14:50:20 | Valid | Epoch[473/600] Iteration[006/008] Valid loss: 0.1047
2023-02-06 14:50:21 | Valid | Epoch[473/600] Iteration[007/008] Valid loss: 0.1106
2023-02-06 14:50:21 | Valid | Epoch[473/600] Iteration[008/008] Valid loss: 0.1088
2023-02-06 14:50:21 | Valid | Epoch[473/600] MIou: 0.9283122921042415
2023-02-06 14:50:21 | Valid | Epoch[473/600] Pixel Accuracy: 0.987695058186849
2023-02-06 14:50:21 | Valid | Epoch[473/600] Mean Pixel Accuracy: 0.953621413178942
2023-02-06 14:50:21 | Stage | Epoch[473/600] Train loss:0.0079
2023-02-06 14:50:21 | Stage | Epoch[473/600] Valid loss:0.1088
2023-02-06 14:50:21 | Stage | Epoch[473/600] LR:0.001

2023-02-06 14:50:21 | Train | Epoch[474/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:50:21 | Train | Epoch[474/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 14:50:22 | Train | Epoch[474/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:50:22 | Train | Epoch[474/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:50:22 | Train | Epoch[474/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:50:22 | Train | Epoch[474/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:50:22 | Train | Epoch[474/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:50:23 | Train | Epoch[474/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:50:23 | Train | Epoch[474/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:50:23 | Train | Epoch[474/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:50:23 | Train | Epoch[474/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:50:24 | Train | Epoch[474/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:50:24 | Train | Epoch[474/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:50:24 | Train | Epoch[474/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:50:24 | Train | Epoch[474/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:50:24 | Train | Epoch[474/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:50:25 | Train | Epoch[474/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:50:25 | Train | Epoch[474/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:50:25 | Train | Epoch[474/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:50:25 | Train | Epoch[474/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:50:26 | Train | Epoch[474/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:50:26 | Train | Epoch[474/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:50:26 | Train | Epoch[474/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:50:26 | Train | Epoch[474/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:50:26 | Train | Epoch[474/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:50:27 | Train | Epoch[474/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:50:27 | Train | Epoch[474/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:50:27 | Train | Epoch[474/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:50:27 | Train | Epoch[474/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:50:27 | Train | Epoch[474/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:50:28 | Valid | Epoch[474/600] Iteration[001/008] Valid loss: 0.1868
2023-02-06 14:50:28 | Valid | Epoch[474/600] Iteration[002/008] Valid loss: 0.1494
2023-02-06 14:50:28 | Valid | Epoch[474/600] Iteration[003/008] Valid loss: 0.1425
2023-02-06 14:50:28 | Valid | Epoch[474/600] Iteration[004/008] Valid loss: 0.1347
2023-02-06 14:50:28 | Valid | Epoch[474/600] Iteration[005/008] Valid loss: 0.1331
2023-02-06 14:50:28 | Valid | Epoch[474/600] Iteration[006/008] Valid loss: 0.1287
2023-02-06 14:50:28 | Valid | Epoch[474/600] Iteration[007/008] Valid loss: 0.1382
2023-02-06 14:50:28 | Valid | Epoch[474/600] Iteration[008/008] Valid loss: 0.1365
2023-02-06 14:50:28 | Valid | Epoch[474/600] MIou: 0.9295300338849615
2023-02-06 14:50:28 | Valid | Epoch[474/600] Pixel Accuracy: 0.9877764383951823
2023-02-06 14:50:28 | Valid | Epoch[474/600] Mean Pixel Accuracy: 0.9596388673766031
2023-02-06 14:50:28 | Stage | Epoch[474/600] Train loss:0.0076
2023-02-06 14:50:28 | Stage | Epoch[474/600] Valid loss:0.1365
2023-02-06 14:50:28 | Stage | Epoch[474/600] LR:0.001

2023-02-06 14:50:29 | Train | Epoch[475/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 14:50:29 | Train | Epoch[475/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 14:50:29 | Train | Epoch[475/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:50:29 | Train | Epoch[475/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:50:30 | Train | Epoch[475/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:50:30 | Train | Epoch[475/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:50:30 | Train | Epoch[475/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:50:30 | Train | Epoch[475/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:50:30 | Train | Epoch[475/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:50:31 | Train | Epoch[475/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:50:31 | Train | Epoch[475/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:50:31 | Train | Epoch[475/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:50:31 | Train | Epoch[475/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:50:32 | Train | Epoch[475/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:50:32 | Train | Epoch[475/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:50:32 | Train | Epoch[475/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:50:32 | Train | Epoch[475/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:50:32 | Train | Epoch[475/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:50:33 | Train | Epoch[475/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:50:33 | Train | Epoch[475/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:50:33 | Train | Epoch[475/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:50:33 | Train | Epoch[475/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:50:33 | Train | Epoch[475/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:50:34 | Train | Epoch[475/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:50:34 | Train | Epoch[475/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:50:34 | Train | Epoch[475/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:50:34 | Train | Epoch[475/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:50:35 | Train | Epoch[475/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:50:35 | Train | Epoch[475/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:50:35 | Train | Epoch[475/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:50:35 | Valid | Epoch[475/600] Iteration[001/008] Valid loss: 0.2642
2023-02-06 14:50:35 | Valid | Epoch[475/600] Iteration[002/008] Valid loss: 0.2118
2023-02-06 14:50:35 | Valid | Epoch[475/600] Iteration[003/008] Valid loss: 0.2036
2023-02-06 14:50:35 | Valid | Epoch[475/600] Iteration[004/008] Valid loss: 0.1960
2023-02-06 14:50:35 | Valid | Epoch[475/600] Iteration[005/008] Valid loss: 0.1990
2023-02-06 14:50:35 | Valid | Epoch[475/600] Iteration[006/008] Valid loss: 0.1941
2023-02-06 14:50:36 | Valid | Epoch[475/600] Iteration[007/008] Valid loss: 0.2102
2023-02-06 14:50:36 | Valid | Epoch[475/600] Iteration[008/008] Valid loss: 0.2106
2023-02-06 14:50:36 | Valid | Epoch[475/600] MIou: 0.929077790671321
2023-02-06 14:50:36 | Valid | Epoch[475/600] Pixel Accuracy: 0.9874216715494791
2023-02-06 14:50:36 | Valid | Epoch[475/600] Mean Pixel Accuracy: 0.9696710529367494
2023-02-06 14:50:36 | Stage | Epoch[475/600] Train loss:0.0078
2023-02-06 14:50:36 | Stage | Epoch[475/600] Valid loss:0.2106
2023-02-06 14:50:36 | Stage | Epoch[475/600] LR:0.001

2023-02-06 14:50:36 | Train | Epoch[476/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 14:50:36 | Train | Epoch[476/600] Iteration[002/030] Train loss: 0.0082
2023-02-06 14:50:37 | Train | Epoch[476/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:50:37 | Train | Epoch[476/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:50:37 | Train | Epoch[476/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:50:37 | Train | Epoch[476/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:50:37 | Train | Epoch[476/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:50:38 | Train | Epoch[476/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:50:38 | Train | Epoch[476/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:50:38 | Train | Epoch[476/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:50:38 | Train | Epoch[476/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:50:39 | Train | Epoch[476/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:50:39 | Train | Epoch[476/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:50:39 | Train | Epoch[476/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:50:39 | Train | Epoch[476/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:50:39 | Train | Epoch[476/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:50:40 | Train | Epoch[476/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:50:40 | Train | Epoch[476/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:50:40 | Train | Epoch[476/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:50:40 | Train | Epoch[476/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:50:41 | Train | Epoch[476/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:50:41 | Train | Epoch[476/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:50:41 | Train | Epoch[476/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:50:41 | Train | Epoch[476/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:50:41 | Train | Epoch[476/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:50:42 | Train | Epoch[476/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:50:42 | Train | Epoch[476/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:50:42 | Train | Epoch[476/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:50:42 | Train | Epoch[476/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:50:42 | Train | Epoch[476/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:50:43 | Valid | Epoch[476/600] Iteration[001/008] Valid loss: 0.1783
2023-02-06 14:50:43 | Valid | Epoch[476/600] Iteration[002/008] Valid loss: 0.1405
2023-02-06 14:50:43 | Valid | Epoch[476/600] Iteration[003/008] Valid loss: 0.1337
2023-02-06 14:50:43 | Valid | Epoch[476/600] Iteration[004/008] Valid loss: 0.1265
2023-02-06 14:50:43 | Valid | Epoch[476/600] Iteration[005/008] Valid loss: 0.1245
2023-02-06 14:50:43 | Valid | Epoch[476/600] Iteration[006/008] Valid loss: 0.1199
2023-02-06 14:50:43 | Valid | Epoch[476/600] Iteration[007/008] Valid loss: 0.1276
2023-02-06 14:50:43 | Valid | Epoch[476/600] Iteration[008/008] Valid loss: 0.1257
2023-02-06 14:50:43 | Valid | Epoch[476/600] MIou: 0.9288069252677169
2023-02-06 14:50:43 | Valid | Epoch[476/600] Pixel Accuracy: 0.9877115885416666
2023-02-06 14:50:43 | Valid | Epoch[476/600] Mean Pixel Accuracy: 0.9566612443497265
2023-02-06 14:50:43 | Stage | Epoch[476/600] Train loss:0.0077
2023-02-06 14:50:43 | Stage | Epoch[476/600] Valid loss:0.1257
2023-02-06 14:50:43 | Stage | Epoch[476/600] LR:0.001

2023-02-06 14:50:44 | Train | Epoch[477/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 14:50:44 | Train | Epoch[477/600] Iteration[002/030] Train loss: 0.0071
2023-02-06 14:50:44 | Train | Epoch[477/600] Iteration[003/030] Train loss: 0.0071
2023-02-06 14:50:44 | Train | Epoch[477/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:50:44 | Train | Epoch[477/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 14:50:45 | Train | Epoch[477/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:50:45 | Train | Epoch[477/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 14:50:45 | Train | Epoch[477/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 14:50:45 | Train | Epoch[477/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:50:46 | Train | Epoch[477/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:50:46 | Train | Epoch[477/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:50:46 | Train | Epoch[477/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:50:46 | Train | Epoch[477/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:50:46 | Train | Epoch[477/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:50:47 | Train | Epoch[477/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:50:47 | Train | Epoch[477/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:50:47 | Train | Epoch[477/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:50:47 | Train | Epoch[477/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:50:48 | Train | Epoch[477/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:50:48 | Train | Epoch[477/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:50:48 | Train | Epoch[477/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:50:48 | Train | Epoch[477/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:50:48 | Train | Epoch[477/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:50:49 | Train | Epoch[477/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:50:49 | Train | Epoch[477/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:50:49 | Train | Epoch[477/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:50:49 | Train | Epoch[477/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:50:50 | Train | Epoch[477/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:50:50 | Train | Epoch[477/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:50:50 | Train | Epoch[477/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:50:50 | Valid | Epoch[477/600] Iteration[001/008] Valid loss: 0.1429
2023-02-06 14:50:50 | Valid | Epoch[477/600] Iteration[002/008] Valid loss: 0.1134
2023-02-06 14:50:50 | Valid | Epoch[477/600] Iteration[003/008] Valid loss: 0.1080
2023-02-06 14:50:50 | Valid | Epoch[477/600] Iteration[004/008] Valid loss: 0.1021
2023-02-06 14:50:50 | Valid | Epoch[477/600] Iteration[005/008] Valid loss: 0.0993
2023-02-06 14:50:50 | Valid | Epoch[477/600] Iteration[006/008] Valid loss: 0.0953
2023-02-06 14:50:51 | Valid | Epoch[477/600] Iteration[007/008] Valid loss: 0.0998
2023-02-06 14:50:51 | Valid | Epoch[477/600] Iteration[008/008] Valid loss: 0.0973
2023-02-06 14:50:51 | Valid | Epoch[477/600] MIou: 0.9262452622765949
2023-02-06 14:50:51 | Valid | Epoch[477/600] Pixel Accuracy: 0.9874267578125
2023-02-06 14:50:51 | Valid | Epoch[477/600] Mean Pixel Accuracy: 0.9485283760710433
2023-02-06 14:50:51 | Stage | Epoch[477/600] Train loss:0.0076
2023-02-06 14:50:51 | Stage | Epoch[477/600] Valid loss:0.0973
2023-02-06 14:50:51 | Stage | Epoch[477/600] LR:0.001

2023-02-06 14:50:51 | Train | Epoch[478/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 14:50:51 | Train | Epoch[478/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:50:52 | Train | Epoch[478/600] Iteration[003/030] Train loss: 0.0083
2023-02-06 14:50:52 | Train | Epoch[478/600] Iteration[004/030] Train loss: 0.0083
2023-02-06 14:50:52 | Train | Epoch[478/600] Iteration[005/030] Train loss: 0.0082
2023-02-06 14:50:52 | Train | Epoch[478/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:50:52 | Train | Epoch[478/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:50:53 | Train | Epoch[478/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:50:53 | Train | Epoch[478/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:50:53 | Train | Epoch[478/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:50:53 | Train | Epoch[478/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:50:54 | Train | Epoch[478/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:50:54 | Train | Epoch[478/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:50:54 | Train | Epoch[478/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:50:54 | Train | Epoch[478/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:50:54 | Train | Epoch[478/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:50:55 | Train | Epoch[478/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:50:55 | Train | Epoch[478/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:50:55 | Train | Epoch[478/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:50:55 | Train | Epoch[478/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:50:56 | Train | Epoch[478/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:50:56 | Train | Epoch[478/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:50:56 | Train | Epoch[478/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:50:56 | Train | Epoch[478/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:50:56 | Train | Epoch[478/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:50:57 | Train | Epoch[478/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:50:57 | Train | Epoch[478/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:50:57 | Train | Epoch[478/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:50:57 | Train | Epoch[478/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:50:57 | Train | Epoch[478/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:50:58 | Valid | Epoch[478/600] Iteration[001/008] Valid loss: 0.1620
2023-02-06 14:50:58 | Valid | Epoch[478/600] Iteration[002/008] Valid loss: 0.1274
2023-02-06 14:50:58 | Valid | Epoch[478/600] Iteration[003/008] Valid loss: 0.1200
2023-02-06 14:50:58 | Valid | Epoch[478/600] Iteration[004/008] Valid loss: 0.1133
2023-02-06 14:50:58 | Valid | Epoch[478/600] Iteration[005/008] Valid loss: 0.1108
2023-02-06 14:50:58 | Valid | Epoch[478/600] Iteration[006/008] Valid loss: 0.1067
2023-02-06 14:50:58 | Valid | Epoch[478/600] Iteration[007/008] Valid loss: 0.1131
2023-02-06 14:50:58 | Valid | Epoch[478/600] Iteration[008/008] Valid loss: 0.1109
2023-02-06 14:50:58 | Valid | Epoch[478/600] MIou: 0.9291819828216726
2023-02-06 14:50:58 | Valid | Epoch[478/600] Pixel Accuracy: 0.9878527323404948
2023-02-06 14:50:58 | Valid | Epoch[478/600] Mean Pixel Accuracy: 0.9541392296812472
2023-02-06 14:50:58 | Stage | Epoch[478/600] Train loss:0.0078
2023-02-06 14:50:58 | Stage | Epoch[478/600] Valid loss:0.1109
2023-02-06 14:50:58 | Stage | Epoch[478/600] LR:0.001

2023-02-06 14:50:59 | Train | Epoch[479/600] Iteration[001/030] Train loss: 0.0093
2023-02-06 14:50:59 | Train | Epoch[479/600] Iteration[002/030] Train loss: 0.0080
2023-02-06 14:50:59 | Train | Epoch[479/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:50:59 | Train | Epoch[479/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:50:59 | Train | Epoch[479/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:51:00 | Train | Epoch[479/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:51:00 | Train | Epoch[479/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:51:00 | Train | Epoch[479/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:51:00 | Train | Epoch[479/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:51:01 | Train | Epoch[479/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:51:01 | Train | Epoch[479/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:51:01 | Train | Epoch[479/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:51:01 | Train | Epoch[479/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:51:01 | Train | Epoch[479/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:51:02 | Train | Epoch[479/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:51:02 | Train | Epoch[479/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:51:02 | Train | Epoch[479/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:51:02 | Train | Epoch[479/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:51:03 | Train | Epoch[479/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:51:03 | Train | Epoch[479/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:51:03 | Train | Epoch[479/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:51:03 | Train | Epoch[479/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:51:03 | Train | Epoch[479/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:51:04 | Train | Epoch[479/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:51:04 | Train | Epoch[479/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:51:04 | Train | Epoch[479/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:51:04 | Train | Epoch[479/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:51:05 | Train | Epoch[479/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:51:05 | Train | Epoch[479/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:51:05 | Train | Epoch[479/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:51:05 | Valid | Epoch[479/600] Iteration[001/008] Valid loss: 0.1820
2023-02-06 14:51:05 | Valid | Epoch[479/600] Iteration[002/008] Valid loss: 0.1451
2023-02-06 14:51:05 | Valid | Epoch[479/600] Iteration[003/008] Valid loss: 0.1392
2023-02-06 14:51:05 | Valid | Epoch[479/600] Iteration[004/008] Valid loss: 0.1320
2023-02-06 14:51:05 | Valid | Epoch[479/600] Iteration[005/008] Valid loss: 0.1296
2023-02-06 14:51:05 | Valid | Epoch[479/600] Iteration[006/008] Valid loss: 0.1256
2023-02-06 14:51:06 | Valid | Epoch[479/600] Iteration[007/008] Valid loss: 0.1335
2023-02-06 14:51:06 | Valid | Epoch[479/600] Iteration[008/008] Valid loss: 0.1317
2023-02-06 14:51:06 | Valid | Epoch[479/600] MIou: 0.9283359840403591
2023-02-06 14:51:06 | Valid | Epoch[479/600] Pixel Accuracy: 0.9875996907552084
2023-02-06 14:51:06 | Valid | Epoch[479/600] Mean Pixel Accuracy: 0.9573479161923892
2023-02-06 14:51:06 | Stage | Epoch[479/600] Train loss:0.0079
2023-02-06 14:51:06 | Stage | Epoch[479/600] Valid loss:0.1317
2023-02-06 14:51:06 | Stage | Epoch[479/600] LR:0.001

2023-02-06 14:51:06 | Train | Epoch[480/600] Iteration[001/030] Train loss: 0.0070
2023-02-06 14:51:06 | Train | Epoch[480/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:51:07 | Train | Epoch[480/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:51:07 | Train | Epoch[480/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:51:07 | Train | Epoch[480/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 14:51:07 | Train | Epoch[480/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:51:07 | Train | Epoch[480/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:51:08 | Train | Epoch[480/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 14:51:08 | Train | Epoch[480/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 14:51:08 | Train | Epoch[480/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:51:08 | Train | Epoch[480/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:51:09 | Train | Epoch[480/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:51:09 | Train | Epoch[480/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:51:09 | Train | Epoch[480/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:51:09 | Train | Epoch[480/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:51:09 | Train | Epoch[480/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:51:10 | Train | Epoch[480/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:51:10 | Train | Epoch[480/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:51:10 | Train | Epoch[480/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:51:10 | Train | Epoch[480/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:51:11 | Train | Epoch[480/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:51:11 | Train | Epoch[480/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:51:11 | Train | Epoch[480/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:51:11 | Train | Epoch[480/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:51:11 | Train | Epoch[480/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:51:12 | Train | Epoch[480/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:51:12 | Train | Epoch[480/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:51:12 | Train | Epoch[480/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:51:12 | Train | Epoch[480/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:51:12 | Train | Epoch[480/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:51:13 | Valid | Epoch[480/600] Iteration[001/008] Valid loss: 0.1621
2023-02-06 14:51:13 | Valid | Epoch[480/600] Iteration[002/008] Valid loss: 0.1294
2023-02-06 14:51:13 | Valid | Epoch[480/600] Iteration[003/008] Valid loss: 0.1217
2023-02-06 14:51:13 | Valid | Epoch[480/600] Iteration[004/008] Valid loss: 0.1159
2023-02-06 14:51:13 | Valid | Epoch[480/600] Iteration[005/008] Valid loss: 0.1146
2023-02-06 14:51:13 | Valid | Epoch[480/600] Iteration[006/008] Valid loss: 0.1099
2023-02-06 14:51:13 | Valid | Epoch[480/600] Iteration[007/008] Valid loss: 0.1163
2023-02-06 14:51:13 | Valid | Epoch[480/600] Iteration[008/008] Valid loss: 0.1143
2023-02-06 14:51:13 | Valid | Epoch[480/600] MIou: 0.9294343192789065
2023-02-06 14:51:13 | Valid | Epoch[480/600] Pixel Accuracy: 0.9878756205240885
2023-02-06 14:51:13 | Valid | Epoch[480/600] Mean Pixel Accuracy: 0.9551536045020164
2023-02-06 14:51:13 | Stage | Epoch[480/600] Train loss:0.0078
2023-02-06 14:51:13 | Stage | Epoch[480/600] Valid loss:0.1143
2023-02-06 14:51:13 | Stage | Epoch[480/600] LR:0.001

2023-02-06 14:51:14 | Train | Epoch[481/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:51:14 | Train | Epoch[481/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 14:51:14 | Train | Epoch[481/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 14:51:14 | Train | Epoch[481/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:51:14 | Train | Epoch[481/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:51:15 | Train | Epoch[481/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 14:51:15 | Train | Epoch[481/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:51:15 | Train | Epoch[481/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:51:15 | Train | Epoch[481/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:51:16 | Train | Epoch[481/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:51:16 | Train | Epoch[481/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:51:16 | Train | Epoch[481/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:51:16 | Train | Epoch[481/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:51:16 | Train | Epoch[481/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:51:17 | Train | Epoch[481/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:51:17 | Train | Epoch[481/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:51:17 | Train | Epoch[481/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:51:17 | Train | Epoch[481/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:51:18 | Train | Epoch[481/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:51:18 | Train | Epoch[481/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:51:18 | Train | Epoch[481/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:51:18 | Train | Epoch[481/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:51:18 | Train | Epoch[481/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:51:19 | Train | Epoch[481/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:51:19 | Train | Epoch[481/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:51:19 | Train | Epoch[481/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:51:19 | Train | Epoch[481/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:51:20 | Train | Epoch[481/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:51:20 | Train | Epoch[481/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:51:20 | Train | Epoch[481/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:51:20 | Valid | Epoch[481/600] Iteration[001/008] Valid loss: 0.1794
2023-02-06 14:51:20 | Valid | Epoch[481/600] Iteration[002/008] Valid loss: 0.1431
2023-02-06 14:51:20 | Valid | Epoch[481/600] Iteration[003/008] Valid loss: 0.1351
2023-02-06 14:51:20 | Valid | Epoch[481/600] Iteration[004/008] Valid loss: 0.1276
2023-02-06 14:51:20 | Valid | Epoch[481/600] Iteration[005/008] Valid loss: 0.1261
2023-02-06 14:51:20 | Valid | Epoch[481/600] Iteration[006/008] Valid loss: 0.1214
2023-02-06 14:51:21 | Valid | Epoch[481/600] Iteration[007/008] Valid loss: 0.1297
2023-02-06 14:51:21 | Valid | Epoch[481/600] Iteration[008/008] Valid loss: 0.1282
2023-02-06 14:51:21 | Valid | Epoch[481/600] MIou: 0.9306258863043807
2023-02-06 14:51:21 | Valid | Epoch[481/600] Pixel Accuracy: 0.9880167643229166
2023-02-06 14:51:21 | Valid | Epoch[481/600] Mean Pixel Accuracy: 0.9587564853142061
2023-02-06 14:51:21 | Stage | Epoch[481/600] Train loss:0.0077
2023-02-06 14:51:21 | Stage | Epoch[481/600] Valid loss:0.1282
2023-02-06 14:51:21 | Stage | Epoch[481/600] LR:0.001

2023-02-06 14:51:21 | Train | Epoch[482/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:51:21 | Train | Epoch[482/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:51:22 | Train | Epoch[482/600] Iteration[003/030] Train loss: 0.0081
2023-02-06 14:51:22 | Train | Epoch[482/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:51:22 | Train | Epoch[482/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 14:51:22 | Train | Epoch[482/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:51:22 | Train | Epoch[482/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:51:23 | Train | Epoch[482/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:51:23 | Train | Epoch[482/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:51:23 | Train | Epoch[482/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:51:23 | Train | Epoch[482/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:51:24 | Train | Epoch[482/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:51:24 | Train | Epoch[482/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:51:24 | Train | Epoch[482/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:51:24 | Train | Epoch[482/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:51:24 | Train | Epoch[482/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:51:25 | Train | Epoch[482/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:51:25 | Train | Epoch[482/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:51:25 | Train | Epoch[482/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:51:25 | Train | Epoch[482/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:51:25 | Train | Epoch[482/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:51:26 | Train | Epoch[482/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:51:26 | Train | Epoch[482/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:51:26 | Train | Epoch[482/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:51:26 | Train | Epoch[482/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:51:27 | Train | Epoch[482/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:51:27 | Train | Epoch[482/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:51:27 | Train | Epoch[482/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:51:27 | Train | Epoch[482/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:51:27 | Train | Epoch[482/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:51:28 | Valid | Epoch[482/600] Iteration[001/008] Valid loss: 0.1544
2023-02-06 14:51:28 | Valid | Epoch[482/600] Iteration[002/008] Valid loss: 0.1212
2023-02-06 14:51:28 | Valid | Epoch[482/600] Iteration[003/008] Valid loss: 0.1145
2023-02-06 14:51:28 | Valid | Epoch[482/600] Iteration[004/008] Valid loss: 0.1081
2023-02-06 14:51:28 | Valid | Epoch[482/600] Iteration[005/008] Valid loss: 0.1060
2023-02-06 14:51:28 | Valid | Epoch[482/600] Iteration[006/008] Valid loss: 0.1016
2023-02-06 14:51:28 | Valid | Epoch[482/600] Iteration[007/008] Valid loss: 0.1066
2023-02-06 14:51:28 | Valid | Epoch[482/600] Iteration[008/008] Valid loss: 0.1045
2023-02-06 14:51:28 | Valid | Epoch[482/600] MIou: 0.9275918087469452
2023-02-06 14:51:28 | Valid | Epoch[482/600] Pixel Accuracy: 0.987616221110026
2023-02-06 14:51:28 | Valid | Epoch[482/600] Mean Pixel Accuracy: 0.9512828302718273
2023-02-06 14:51:28 | Stage | Epoch[482/600] Train loss:0.0078
2023-02-06 14:51:28 | Stage | Epoch[482/600] Valid loss:0.1045
2023-02-06 14:51:28 | Stage | Epoch[482/600] LR:0.001

2023-02-06 14:51:29 | Train | Epoch[483/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 14:51:29 | Train | Epoch[483/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:51:29 | Train | Epoch[483/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:51:29 | Train | Epoch[483/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:51:29 | Train | Epoch[483/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 14:51:30 | Train | Epoch[483/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:51:30 | Train | Epoch[483/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:51:30 | Train | Epoch[483/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:51:30 | Train | Epoch[483/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:51:31 | Train | Epoch[483/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:51:31 | Train | Epoch[483/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:51:31 | Train | Epoch[483/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:51:31 | Train | Epoch[483/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:51:31 | Train | Epoch[483/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:51:32 | Train | Epoch[483/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:51:32 | Train | Epoch[483/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:51:32 | Train | Epoch[483/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:51:32 | Train | Epoch[483/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:51:33 | Train | Epoch[483/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:51:33 | Train | Epoch[483/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:51:33 | Train | Epoch[483/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:51:33 | Train | Epoch[483/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:51:33 | Train | Epoch[483/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:51:34 | Train | Epoch[483/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:51:34 | Train | Epoch[483/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:51:34 | Train | Epoch[483/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:51:34 | Train | Epoch[483/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:51:35 | Train | Epoch[483/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:51:35 | Train | Epoch[483/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:51:35 | Train | Epoch[483/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:51:35 | Valid | Epoch[483/600] Iteration[001/008] Valid loss: 0.2833
2023-02-06 14:51:35 | Valid | Epoch[483/600] Iteration[002/008] Valid loss: 0.2294
2023-02-06 14:51:35 | Valid | Epoch[483/600] Iteration[003/008] Valid loss: 0.2229
2023-02-06 14:51:35 | Valid | Epoch[483/600] Iteration[004/008] Valid loss: 0.2139
2023-02-06 14:51:35 | Valid | Epoch[483/600] Iteration[005/008] Valid loss: 0.2164
2023-02-06 14:51:35 | Valid | Epoch[483/600] Iteration[006/008] Valid loss: 0.2119
2023-02-06 14:51:36 | Valid | Epoch[483/600] Iteration[007/008] Valid loss: 0.2291
2023-02-06 14:51:36 | Valid | Epoch[483/600] Iteration[008/008] Valid loss: 0.2302
2023-02-06 14:51:36 | Valid | Epoch[483/600] MIou: 0.92743556368814
2023-02-06 14:51:36 | Valid | Epoch[483/600] Pixel Accuracy: 0.9870529174804688
2023-02-06 14:51:36 | Valid | Epoch[483/600] Mean Pixel Accuracy: 0.9709139974781948
2023-02-06 14:51:36 | Stage | Epoch[483/600] Train loss:0.0076
2023-02-06 14:51:36 | Stage | Epoch[483/600] Valid loss:0.2302
2023-02-06 14:51:36 | Stage | Epoch[483/600] LR:0.001

2023-02-06 14:51:36 | Train | Epoch[484/600] Iteration[001/030] Train loss: 0.0067
2023-02-06 14:51:36 | Train | Epoch[484/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:51:37 | Train | Epoch[484/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:51:37 | Train | Epoch[484/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 14:51:37 | Train | Epoch[484/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 14:51:37 | Train | Epoch[484/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:51:37 | Train | Epoch[484/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 14:51:38 | Train | Epoch[484/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 14:51:38 | Train | Epoch[484/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 14:51:38 | Train | Epoch[484/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 14:51:38 | Train | Epoch[484/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 14:51:39 | Train | Epoch[484/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 14:51:39 | Train | Epoch[484/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 14:51:39 | Train | Epoch[484/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:51:39 | Train | Epoch[484/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:51:39 | Train | Epoch[484/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:51:40 | Train | Epoch[484/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:51:40 | Train | Epoch[484/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:51:40 | Train | Epoch[484/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 14:51:40 | Train | Epoch[484/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 14:51:41 | Train | Epoch[484/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 14:51:41 | Train | Epoch[484/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 14:51:41 | Train | Epoch[484/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:51:41 | Train | Epoch[484/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:51:41 | Train | Epoch[484/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:51:42 | Train | Epoch[484/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:51:42 | Train | Epoch[484/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:51:42 | Train | Epoch[484/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:51:42 | Train | Epoch[484/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:51:42 | Train | Epoch[484/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:51:43 | Valid | Epoch[484/600] Iteration[001/008] Valid loss: 0.1655
2023-02-06 14:51:43 | Valid | Epoch[484/600] Iteration[002/008] Valid loss: 0.1306
2023-02-06 14:51:43 | Valid | Epoch[484/600] Iteration[003/008] Valid loss: 0.1229
2023-02-06 14:51:43 | Valid | Epoch[484/600] Iteration[004/008] Valid loss: 0.1163
2023-02-06 14:51:43 | Valid | Epoch[484/600] Iteration[005/008] Valid loss: 0.1144
2023-02-06 14:51:43 | Valid | Epoch[484/600] Iteration[006/008] Valid loss: 0.1103
2023-02-06 14:51:43 | Valid | Epoch[484/600] Iteration[007/008] Valid loss: 0.1177
2023-02-06 14:51:43 | Valid | Epoch[484/600] Iteration[008/008] Valid loss: 0.1156
2023-02-06 14:51:43 | Valid | Epoch[484/600] MIou: 0.9288062686284702
2023-02-06 14:51:43 | Valid | Epoch[484/600] Pixel Accuracy: 0.9877700805664062
2023-02-06 14:51:43 | Valid | Epoch[484/600] Mean Pixel Accuracy: 0.9544615480888958
2023-02-06 14:51:43 | Stage | Epoch[484/600] Train loss:0.0077
2023-02-06 14:51:43 | Stage | Epoch[484/600] Valid loss:0.1156
2023-02-06 14:51:43 | Stage | Epoch[484/600] LR:0.001

2023-02-06 14:51:44 | Train | Epoch[485/600] Iteration[001/030] Train loss: 0.0144
2023-02-06 14:51:44 | Train | Epoch[485/600] Iteration[002/030] Train loss: 0.0106
2023-02-06 14:51:44 | Train | Epoch[485/600] Iteration[003/030] Train loss: 0.0098
2023-02-06 14:51:44 | Train | Epoch[485/600] Iteration[004/030] Train loss: 0.0091
2023-02-06 14:51:45 | Train | Epoch[485/600] Iteration[005/030] Train loss: 0.0087
2023-02-06 14:51:45 | Train | Epoch[485/600] Iteration[006/030] Train loss: 0.0085
2023-02-06 14:51:45 | Train | Epoch[485/600] Iteration[007/030] Train loss: 0.0083
2023-02-06 14:51:45 | Train | Epoch[485/600] Iteration[008/030] Train loss: 0.0083
2023-02-06 14:51:45 | Train | Epoch[485/600] Iteration[009/030] Train loss: 0.0082
2023-02-06 14:51:46 | Train | Epoch[485/600] Iteration[010/030] Train loss: 0.0082
2023-02-06 14:51:46 | Train | Epoch[485/600] Iteration[011/030] Train loss: 0.0081
2023-02-06 14:51:46 | Train | Epoch[485/600] Iteration[012/030] Train loss: 0.0083
2023-02-06 14:51:46 | Train | Epoch[485/600] Iteration[013/030] Train loss: 0.0083
2023-02-06 14:51:47 | Train | Epoch[485/600] Iteration[014/030] Train loss: 0.0082
2023-02-06 14:51:47 | Train | Epoch[485/600] Iteration[015/030] Train loss: 0.0082
2023-02-06 14:51:47 | Train | Epoch[485/600] Iteration[016/030] Train loss: 0.0082
2023-02-06 14:51:47 | Train | Epoch[485/600] Iteration[017/030] Train loss: 0.0081
2023-02-06 14:51:47 | Train | Epoch[485/600] Iteration[018/030] Train loss: 0.0081
2023-02-06 14:51:48 | Train | Epoch[485/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:51:48 | Train | Epoch[485/600] Iteration[020/030] Train loss: 0.0081
2023-02-06 14:51:48 | Train | Epoch[485/600] Iteration[021/030] Train loss: 0.0080
2023-02-06 14:51:48 | Train | Epoch[485/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:51:49 | Train | Epoch[485/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:51:49 | Train | Epoch[485/600] Iteration[024/030] Train loss: 0.0080
2023-02-06 14:51:49 | Train | Epoch[485/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 14:51:49 | Train | Epoch[485/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 14:51:49 | Train | Epoch[485/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:51:50 | Train | Epoch[485/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:51:50 | Train | Epoch[485/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 14:51:50 | Train | Epoch[485/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:51:50 | Valid | Epoch[485/600] Iteration[001/008] Valid loss: 0.1492
2023-02-06 14:51:50 | Valid | Epoch[485/600] Iteration[002/008] Valid loss: 0.1188
2023-02-06 14:51:50 | Valid | Epoch[485/600] Iteration[003/008] Valid loss: 0.1125
2023-02-06 14:51:50 | Valid | Epoch[485/600] Iteration[004/008] Valid loss: 0.1065
2023-02-06 14:51:51 | Valid | Epoch[485/600] Iteration[005/008] Valid loss: 0.1039
2023-02-06 14:51:51 | Valid | Epoch[485/600] Iteration[006/008] Valid loss: 0.1002
2023-02-06 14:51:51 | Valid | Epoch[485/600] Iteration[007/008] Valid loss: 0.1057
2023-02-06 14:51:51 | Valid | Epoch[485/600] Iteration[008/008] Valid loss: 0.1035
2023-02-06 14:51:51 | Valid | Epoch[485/600] MIou: 0.9258779587726989
2023-02-06 14:51:51 | Valid | Epoch[485/600] Pixel Accuracy: 0.9873250325520834
2023-02-06 14:51:51 | Valid | Epoch[485/600] Mean Pixel Accuracy: 0.9495757055725429
2023-02-06 14:51:51 | Stage | Epoch[485/600] Train loss:0.0079
2023-02-06 14:51:51 | Stage | Epoch[485/600] Valid loss:0.1035
2023-02-06 14:51:51 | Stage | Epoch[485/600] LR:0.001

2023-02-06 14:51:51 | Train | Epoch[486/600] Iteration[001/030] Train loss: 0.0074
2023-02-06 14:51:51 | Train | Epoch[486/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:51:52 | Train | Epoch[486/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:51:52 | Train | Epoch[486/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:51:52 | Train | Epoch[486/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:51:52 | Train | Epoch[486/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:51:53 | Train | Epoch[486/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:51:53 | Train | Epoch[486/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:51:53 | Train | Epoch[486/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:51:53 | Train | Epoch[486/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:51:53 | Train | Epoch[486/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:51:54 | Train | Epoch[486/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:51:54 | Train | Epoch[486/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:51:54 | Train | Epoch[486/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:51:54 | Train | Epoch[486/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:51:55 | Train | Epoch[486/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:51:55 | Train | Epoch[486/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:51:55 | Train | Epoch[486/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:51:55 | Train | Epoch[486/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:51:55 | Train | Epoch[486/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:51:56 | Train | Epoch[486/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:51:56 | Train | Epoch[486/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:51:56 | Train | Epoch[486/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:51:56 | Train | Epoch[486/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:51:56 | Train | Epoch[486/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:51:57 | Train | Epoch[486/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:51:57 | Train | Epoch[486/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:51:57 | Train | Epoch[486/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:51:57 | Train | Epoch[486/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:51:57 | Train | Epoch[486/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:51:58 | Valid | Epoch[486/600] Iteration[001/008] Valid loss: 0.2220
2023-02-06 14:51:58 | Valid | Epoch[486/600] Iteration[002/008] Valid loss: 0.1787
2023-02-06 14:51:58 | Valid | Epoch[486/600] Iteration[003/008] Valid loss: 0.1707
2023-02-06 14:51:58 | Valid | Epoch[486/600] Iteration[004/008] Valid loss: 0.1622
2023-02-06 14:51:58 | Valid | Epoch[486/600] Iteration[005/008] Valid loss: 0.1627
2023-02-06 14:51:58 | Valid | Epoch[486/600] Iteration[006/008] Valid loss: 0.1593
2023-02-06 14:51:58 | Valid | Epoch[486/600] Iteration[007/008] Valid loss: 0.1723
2023-02-06 14:51:58 | Valid | Epoch[486/600] Iteration[008/008] Valid loss: 0.1705
2023-02-06 14:51:58 | Valid | Epoch[486/600] MIou: 0.9311919884238553
2023-02-06 14:51:58 | Valid | Epoch[486/600] Pixel Accuracy: 0.9879671732584635
2023-02-06 14:51:58 | Valid | Epoch[486/600] Mean Pixel Accuracy: 0.9650696994622547
2023-02-06 14:51:58 | Stage | Epoch[486/600] Train loss:0.0078
2023-02-06 14:51:58 | Stage | Epoch[486/600] Valid loss:0.1705
2023-02-06 14:51:58 | Stage | Epoch[486/600] LR:0.001

2023-02-06 14:51:59 | Train | Epoch[487/600] Iteration[001/030] Train loss: 0.0094
2023-02-06 14:51:59 | Train | Epoch[487/600] Iteration[002/030] Train loss: 0.0088
2023-02-06 14:51:59 | Train | Epoch[487/600] Iteration[003/030] Train loss: 0.0084
2023-02-06 14:51:59 | Train | Epoch[487/600] Iteration[004/030] Train loss: 0.0085
2023-02-06 14:52:00 | Train | Epoch[487/600] Iteration[005/030] Train loss: 0.0083
2023-02-06 14:52:00 | Train | Epoch[487/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:52:00 | Train | Epoch[487/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:52:00 | Train | Epoch[487/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:52:01 | Train | Epoch[487/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:52:01 | Train | Epoch[487/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:52:01 | Train | Epoch[487/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:52:01 | Train | Epoch[487/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:52:01 | Train | Epoch[487/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:52:02 | Train | Epoch[487/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:52:02 | Train | Epoch[487/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:52:02 | Train | Epoch[487/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:52:02 | Train | Epoch[487/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:52:03 | Train | Epoch[487/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:52:03 | Train | Epoch[487/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:52:03 | Train | Epoch[487/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:52:03 | Train | Epoch[487/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:52:03 | Train | Epoch[487/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:52:04 | Train | Epoch[487/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:52:04 | Train | Epoch[487/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:52:04 | Train | Epoch[487/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:52:04 | Train | Epoch[487/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:52:05 | Train | Epoch[487/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:52:05 | Train | Epoch[487/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:52:05 | Train | Epoch[487/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:52:05 | Train | Epoch[487/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 14:52:05 | Valid | Epoch[487/600] Iteration[001/008] Valid loss: 0.1212
2023-02-06 14:52:05 | Valid | Epoch[487/600] Iteration[002/008] Valid loss: 0.0957
2023-02-06 14:52:06 | Valid | Epoch[487/600] Iteration[003/008] Valid loss: 0.0911
2023-02-06 14:52:06 | Valid | Epoch[487/600] Iteration[004/008] Valid loss: 0.0870
2023-02-06 14:52:06 | Valid | Epoch[487/600] Iteration[005/008] Valid loss: 0.0845
2023-02-06 14:52:06 | Valid | Epoch[487/600] Iteration[006/008] Valid loss: 0.0811
2023-02-06 14:52:06 | Valid | Epoch[487/600] Iteration[007/008] Valid loss: 0.0840
2023-02-06 14:52:06 | Valid | Epoch[487/600] Iteration[008/008] Valid loss: 0.0818
2023-02-06 14:52:06 | Valid | Epoch[487/600] MIou: 0.920949253485762
2023-02-06 14:52:06 | Valid | Epoch[487/600] Pixel Accuracy: 0.9866371154785156
2023-02-06 14:52:06 | Valid | Epoch[487/600] Mean Pixel Accuracy: 0.9397376135139333
2023-02-06 14:52:06 | Stage | Epoch[487/600] Train loss:0.0079
2023-02-06 14:52:06 | Stage | Epoch[487/600] Valid loss:0.0818
2023-02-06 14:52:06 | Stage | Epoch[487/600] LR:0.001

2023-02-06 14:52:06 | Train | Epoch[488/600] Iteration[001/030] Train loss: 0.0065
2023-02-06 14:52:07 | Train | Epoch[488/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:52:07 | Train | Epoch[488/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:52:07 | Train | Epoch[488/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:52:07 | Train | Epoch[488/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 14:52:07 | Train | Epoch[488/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:52:08 | Train | Epoch[488/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:52:08 | Train | Epoch[488/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:52:08 | Train | Epoch[488/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:52:08 | Train | Epoch[488/600] Iteration[010/030] Train loss: 0.0082
2023-02-06 14:52:09 | Train | Epoch[488/600] Iteration[011/030] Train loss: 0.0081
2023-02-06 14:52:09 | Train | Epoch[488/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:52:09 | Train | Epoch[488/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:52:09 | Train | Epoch[488/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:52:09 | Train | Epoch[488/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:52:10 | Train | Epoch[488/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:52:10 | Train | Epoch[488/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:52:10 | Train | Epoch[488/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:52:10 | Train | Epoch[488/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:52:11 | Train | Epoch[488/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:52:11 | Train | Epoch[488/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:52:11 | Train | Epoch[488/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:52:11 | Train | Epoch[488/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:52:11 | Train | Epoch[488/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:52:12 | Train | Epoch[488/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:52:12 | Train | Epoch[488/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:52:12 | Train | Epoch[488/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:52:12 | Train | Epoch[488/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:52:12 | Train | Epoch[488/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:52:13 | Train | Epoch[488/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:52:13 | Valid | Epoch[488/600] Iteration[001/008] Valid loss: 0.2112
2023-02-06 14:52:13 | Valid | Epoch[488/600] Iteration[002/008] Valid loss: 0.1683
2023-02-06 14:52:13 | Valid | Epoch[488/600] Iteration[003/008] Valid loss: 0.1615
2023-02-06 14:52:13 | Valid | Epoch[488/600] Iteration[004/008] Valid loss: 0.1535
2023-02-06 14:52:13 | Valid | Epoch[488/600] Iteration[005/008] Valid loss: 0.1539
2023-02-06 14:52:13 | Valid | Epoch[488/600] Iteration[006/008] Valid loss: 0.1497
2023-02-06 14:52:13 | Valid | Epoch[488/600] Iteration[007/008] Valid loss: 0.1614
2023-02-06 14:52:13 | Valid | Epoch[488/600] Iteration[008/008] Valid loss: 0.1598
2023-02-06 14:52:13 | Valid | Epoch[488/600] MIou: 0.9309120874155812
2023-02-06 14:52:13 | Valid | Epoch[488/600] Pixel Accuracy: 0.9879531860351562
2023-02-06 14:52:13 | Valid | Epoch[488/600] Mean Pixel Accuracy: 0.9634325103091799
2023-02-06 14:52:13 | Stage | Epoch[488/600] Train loss:0.0078
2023-02-06 14:52:13 | Stage | Epoch[488/600] Valid loss:0.1598
2023-02-06 14:52:13 | Stage | Epoch[488/600] LR:0.001

2023-02-06 14:52:14 | Train | Epoch[489/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 14:52:14 | Train | Epoch[489/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:52:14 | Train | Epoch[489/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:52:15 | Train | Epoch[489/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 14:52:15 | Train | Epoch[489/600] Iteration[005/030] Train loss: 0.0072
2023-02-06 14:52:15 | Train | Epoch[489/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:52:15 | Train | Epoch[489/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 14:52:15 | Train | Epoch[489/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 14:52:16 | Train | Epoch[489/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:52:16 | Train | Epoch[489/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:52:16 | Train | Epoch[489/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:52:16 | Train | Epoch[489/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:52:17 | Train | Epoch[489/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 14:52:17 | Train | Epoch[489/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:52:17 | Train | Epoch[489/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:52:17 | Train | Epoch[489/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:52:17 | Train | Epoch[489/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:52:18 | Train | Epoch[489/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:52:18 | Train | Epoch[489/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:52:18 | Train | Epoch[489/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:52:18 | Train | Epoch[489/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:52:18 | Train | Epoch[489/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:52:19 | Train | Epoch[489/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:52:19 | Train | Epoch[489/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:52:19 | Train | Epoch[489/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:52:19 | Train | Epoch[489/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:52:20 | Train | Epoch[489/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:52:20 | Train | Epoch[489/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:52:20 | Train | Epoch[489/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:52:20 | Train | Epoch[489/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:52:20 | Valid | Epoch[489/600] Iteration[001/008] Valid loss: 0.2178
2023-02-06 14:52:21 | Valid | Epoch[489/600] Iteration[002/008] Valid loss: 0.1732
2023-02-06 14:52:21 | Valid | Epoch[489/600] Iteration[003/008] Valid loss: 0.1657
2023-02-06 14:52:21 | Valid | Epoch[489/600] Iteration[004/008] Valid loss: 0.1573
2023-02-06 14:52:21 | Valid | Epoch[489/600] Iteration[005/008] Valid loss: 0.1561
2023-02-06 14:52:21 | Valid | Epoch[489/600] Iteration[006/008] Valid loss: 0.1519
2023-02-06 14:52:21 | Valid | Epoch[489/600] Iteration[007/008] Valid loss: 0.1637
2023-02-06 14:52:21 | Valid | Epoch[489/600] Iteration[008/008] Valid loss: 0.1622
2023-02-06 14:52:21 | Valid | Epoch[489/600] MIou: 0.9295006160394361
2023-02-06 14:52:21 | Valid | Epoch[489/600] Pixel Accuracy: 0.9876823425292969
2023-02-06 14:52:21 | Valid | Epoch[489/600] Mean Pixel Accuracy: 0.9629983219491198
2023-02-06 14:52:21 | Stage | Epoch[489/600] Train loss:0.0077
2023-02-06 14:52:21 | Stage | Epoch[489/600] Valid loss:0.1622
2023-02-06 14:52:21 | Stage | Epoch[489/600] LR:0.001

2023-02-06 14:52:21 | Train | Epoch[490/600] Iteration[001/030] Train loss: 0.0069
2023-02-06 14:52:22 | Train | Epoch[490/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:52:22 | Train | Epoch[490/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:52:22 | Train | Epoch[490/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:52:22 | Train | Epoch[490/600] Iteration[005/030] Train loss: 0.0071
2023-02-06 14:52:23 | Train | Epoch[490/600] Iteration[006/030] Train loss: 0.0069
2023-02-06 14:52:23 | Train | Epoch[490/600] Iteration[007/030] Train loss: 0.0070
2023-02-06 14:52:23 | Train | Epoch[490/600] Iteration[008/030] Train loss: 0.0073
2023-02-06 14:52:23 | Train | Epoch[490/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 14:52:23 | Train | Epoch[490/600] Iteration[010/030] Train loss: 0.0072
2023-02-06 14:52:24 | Train | Epoch[490/600] Iteration[011/030] Train loss: 0.0072
2023-02-06 14:52:24 | Train | Epoch[490/600] Iteration[012/030] Train loss: 0.0073
2023-02-06 14:52:24 | Train | Epoch[490/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:52:24 | Train | Epoch[490/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:52:24 | Train | Epoch[490/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 14:52:25 | Train | Epoch[490/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 14:52:25 | Train | Epoch[490/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 14:52:25 | Train | Epoch[490/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:52:25 | Train | Epoch[490/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:52:26 | Train | Epoch[490/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:52:26 | Train | Epoch[490/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:52:26 | Train | Epoch[490/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:52:26 | Train | Epoch[490/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:52:26 | Train | Epoch[490/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:52:27 | Train | Epoch[490/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:52:27 | Train | Epoch[490/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:52:27 | Train | Epoch[490/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:52:27 | Train | Epoch[490/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:52:28 | Train | Epoch[490/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:52:28 | Train | Epoch[490/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:52:28 | Valid | Epoch[490/600] Iteration[001/008] Valid loss: 0.1228
2023-02-06 14:52:28 | Valid | Epoch[490/600] Iteration[002/008] Valid loss: 0.0979
2023-02-06 14:52:28 | Valid | Epoch[490/600] Iteration[003/008] Valid loss: 0.0937
2023-02-06 14:52:28 | Valid | Epoch[490/600] Iteration[004/008] Valid loss: 0.0886
2023-02-06 14:52:28 | Valid | Epoch[490/600] Iteration[005/008] Valid loss: 0.0862
2023-02-06 14:52:28 | Valid | Epoch[490/600] Iteration[006/008] Valid loss: 0.0828
2023-02-06 14:52:28 | Valid | Epoch[490/600] Iteration[007/008] Valid loss: 0.0853
2023-02-06 14:52:28 | Valid | Epoch[490/600] Iteration[008/008] Valid loss: 0.0829
2023-02-06 14:52:28 | Valid | Epoch[490/600] MIou: 0.9215945343165196
2023-02-06 14:52:28 | Valid | Epoch[490/600] Pixel Accuracy: 0.9867451985677084
2023-02-06 14:52:28 | Valid | Epoch[490/600] Mean Pixel Accuracy: 0.9403803439684972
2023-02-06 14:52:28 | Stage | Epoch[490/600] Train loss:0.0076
2023-02-06 14:52:28 | Stage | Epoch[490/600] Valid loss:0.0829
2023-02-06 14:52:28 | Stage | Epoch[490/600] LR:0.001

2023-02-06 14:52:29 | Train | Epoch[491/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 14:52:29 | Train | Epoch[491/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:52:29 | Train | Epoch[491/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:52:30 | Train | Epoch[491/600] Iteration[004/030] Train loss: 0.0076
2023-02-06 14:52:30 | Train | Epoch[491/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:52:30 | Train | Epoch[491/600] Iteration[006/030] Train loss: 0.0082
2023-02-06 14:52:30 | Train | Epoch[491/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:52:31 | Train | Epoch[491/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:52:31 | Train | Epoch[491/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:52:31 | Train | Epoch[491/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:52:31 | Train | Epoch[491/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:52:31 | Train | Epoch[491/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:52:32 | Train | Epoch[491/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:52:32 | Train | Epoch[491/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:52:32 | Train | Epoch[491/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:52:32 | Train | Epoch[491/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:52:32 | Train | Epoch[491/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:52:33 | Train | Epoch[491/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:52:33 | Train | Epoch[491/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:52:33 | Train | Epoch[491/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:52:33 | Train | Epoch[491/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:52:34 | Train | Epoch[491/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:52:34 | Train | Epoch[491/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:52:34 | Train | Epoch[491/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:52:34 | Train | Epoch[491/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:52:34 | Train | Epoch[491/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:52:35 | Train | Epoch[491/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:52:35 | Train | Epoch[491/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:52:35 | Train | Epoch[491/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:52:35 | Train | Epoch[491/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:52:36 | Valid | Epoch[491/600] Iteration[001/008] Valid loss: 0.1713
2023-02-06 14:52:36 | Valid | Epoch[491/600] Iteration[002/008] Valid loss: 0.1356
2023-02-06 14:52:36 | Valid | Epoch[491/600] Iteration[003/008] Valid loss: 0.1279
2023-02-06 14:52:36 | Valid | Epoch[491/600] Iteration[004/008] Valid loss: 0.1214
2023-02-06 14:52:36 | Valid | Epoch[491/600] Iteration[005/008] Valid loss: 0.1198
2023-02-06 14:52:36 | Valid | Epoch[491/600] Iteration[006/008] Valid loss: 0.1154
2023-02-06 14:52:36 | Valid | Epoch[491/600] Iteration[007/008] Valid loss: 0.1228
2023-02-06 14:52:36 | Valid | Epoch[491/600] Iteration[008/008] Valid loss: 0.1209
2023-02-06 14:52:36 | Valid | Epoch[491/600] MIou: 0.9297960322814727
2023-02-06 14:52:36 | Valid | Epoch[491/600] Pixel Accuracy: 0.9879201253255209
2023-02-06 14:52:36 | Valid | Epoch[491/600] Mean Pixel Accuracy: 0.9561735202663639
2023-02-06 14:52:36 | Stage | Epoch[491/600] Train loss:0.0077
2023-02-06 14:52:36 | Stage | Epoch[491/600] Valid loss:0.1209
2023-02-06 14:52:36 | Stage | Epoch[491/600] LR:0.001

2023-02-06 14:52:36 | Train | Epoch[492/600] Iteration[001/030] Train loss: 0.0067
2023-02-06 14:52:37 | Train | Epoch[492/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:52:37 | Train | Epoch[492/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:52:37 | Train | Epoch[492/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:52:37 | Train | Epoch[492/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:52:38 | Train | Epoch[492/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:52:38 | Train | Epoch[492/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:52:38 | Train | Epoch[492/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:52:38 | Train | Epoch[492/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:52:38 | Train | Epoch[492/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:52:39 | Train | Epoch[492/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:52:39 | Train | Epoch[492/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:52:39 | Train | Epoch[492/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:52:39 | Train | Epoch[492/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:52:40 | Train | Epoch[492/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:52:40 | Train | Epoch[492/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:52:40 | Train | Epoch[492/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:52:40 | Train | Epoch[492/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:52:40 | Train | Epoch[492/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:52:41 | Train | Epoch[492/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:52:41 | Train | Epoch[492/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:52:41 | Train | Epoch[492/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:52:41 | Train | Epoch[492/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:52:42 | Train | Epoch[492/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:52:42 | Train | Epoch[492/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:52:42 | Train | Epoch[492/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:52:42 | Train | Epoch[492/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:52:42 | Train | Epoch[492/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:52:43 | Train | Epoch[492/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:52:43 | Train | Epoch[492/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:52:43 | Valid | Epoch[492/600] Iteration[001/008] Valid loss: 0.1574
2023-02-06 14:52:43 | Valid | Epoch[492/600] Iteration[002/008] Valid loss: 0.1243
2023-02-06 14:52:43 | Valid | Epoch[492/600] Iteration[003/008] Valid loss: 0.1172
2023-02-06 14:52:43 | Valid | Epoch[492/600] Iteration[004/008] Valid loss: 0.1100
2023-02-06 14:52:43 | Valid | Epoch[492/600] Iteration[005/008] Valid loss: 0.1084
2023-02-06 14:52:43 | Valid | Epoch[492/600] Iteration[006/008] Valid loss: 0.1045
2023-02-06 14:52:43 | Valid | Epoch[492/600] Iteration[007/008] Valid loss: 0.1108
2023-02-06 14:52:43 | Valid | Epoch[492/600] Iteration[008/008] Valid loss: 0.1094
2023-02-06 14:52:44 | Valid | Epoch[492/600] MIou: 0.9275812929581351
2023-02-06 14:52:44 | Valid | Epoch[492/600] Pixel Accuracy: 0.9875895182291666
2023-02-06 14:52:44 | Valid | Epoch[492/600] Mean Pixel Accuracy: 0.9521875215989082
2023-02-06 14:52:44 | Stage | Epoch[492/600] Train loss:0.0077
2023-02-06 14:52:44 | Stage | Epoch[492/600] Valid loss:0.1094
2023-02-06 14:52:44 | Stage | Epoch[492/600] LR:0.001

2023-02-06 14:52:44 | Train | Epoch[493/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:52:44 | Train | Epoch[493/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 14:52:44 | Train | Epoch[493/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:52:45 | Train | Epoch[493/600] Iteration[004/030] Train loss: 0.0076
2023-02-06 14:52:45 | Train | Epoch[493/600] Iteration[005/030] Train loss: 0.0082
2023-02-06 14:52:45 | Train | Epoch[493/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:52:45 | Train | Epoch[493/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:52:46 | Train | Epoch[493/600] Iteration[008/030] Train loss: 0.0083
2023-02-06 14:52:46 | Train | Epoch[493/600] Iteration[009/030] Train loss: 0.0083
2023-02-06 14:52:46 | Train | Epoch[493/600] Iteration[010/030] Train loss: 0.0082
2023-02-06 14:52:46 | Train | Epoch[493/600] Iteration[011/030] Train loss: 0.0082
2023-02-06 14:52:46 | Train | Epoch[493/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:52:47 | Train | Epoch[493/600] Iteration[013/030] Train loss: 0.0082
2023-02-06 14:52:47 | Train | Epoch[493/600] Iteration[014/030] Train loss: 0.0082
2023-02-06 14:52:47 | Train | Epoch[493/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 14:52:47 | Train | Epoch[493/600] Iteration[016/030] Train loss: 0.0081
2023-02-06 14:52:48 | Train | Epoch[493/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:52:48 | Train | Epoch[493/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:52:48 | Train | Epoch[493/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:52:48 | Train | Epoch[493/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:52:48 | Train | Epoch[493/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:52:49 | Train | Epoch[493/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:52:49 | Train | Epoch[493/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:52:49 | Train | Epoch[493/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:52:49 | Train | Epoch[493/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:52:50 | Train | Epoch[493/600] Iteration[026/030] Train loss: 0.0079
2023-02-06 14:52:50 | Train | Epoch[493/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:52:50 | Train | Epoch[493/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 14:52:50 | Train | Epoch[493/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:52:50 | Train | Epoch[493/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:52:51 | Valid | Epoch[493/600] Iteration[001/008] Valid loss: 0.1607
2023-02-06 14:52:51 | Valid | Epoch[493/600] Iteration[002/008] Valid loss: 0.1281
2023-02-06 14:52:51 | Valid | Epoch[493/600] Iteration[003/008] Valid loss: 0.1211
2023-02-06 14:52:51 | Valid | Epoch[493/600] Iteration[004/008] Valid loss: 0.1146
2023-02-06 14:52:51 | Valid | Epoch[493/600] Iteration[005/008] Valid loss: 0.1132
2023-02-06 14:52:51 | Valid | Epoch[493/600] Iteration[006/008] Valid loss: 0.1087
2023-02-06 14:52:51 | Valid | Epoch[493/600] Iteration[007/008] Valid loss: 0.1158
2023-02-06 14:52:51 | Valid | Epoch[493/600] Iteration[008/008] Valid loss: 0.1138
2023-02-06 14:52:51 | Valid | Epoch[493/600] MIou: 0.9286137798850432
2023-02-06 14:52:51 | Valid | Epoch[493/600] Pixel Accuracy: 0.9877573649088541
2023-02-06 14:52:51 | Valid | Epoch[493/600] Mean Pixel Accuracy: 0.9535161692374077
2023-02-06 14:52:51 | Stage | Epoch[493/600] Train loss:0.0078
2023-02-06 14:52:51 | Stage | Epoch[493/600] Valid loss:0.1138
2023-02-06 14:52:51 | Stage | Epoch[493/600] LR:0.001

2023-02-06 14:52:52 | Train | Epoch[494/600] Iteration[001/030] Train loss: 0.0076
2023-02-06 14:52:52 | Train | Epoch[494/600] Iteration[002/030] Train loss: 0.0089
2023-02-06 14:52:52 | Train | Epoch[494/600] Iteration[003/030] Train loss: 0.0084
2023-02-06 14:52:52 | Train | Epoch[494/600] Iteration[004/030] Train loss: 0.0083
2023-02-06 14:52:52 | Train | Epoch[494/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:52:53 | Train | Epoch[494/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:52:53 | Train | Epoch[494/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:52:53 | Train | Epoch[494/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:52:53 | Train | Epoch[494/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:52:54 | Train | Epoch[494/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:52:54 | Train | Epoch[494/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:52:54 | Train | Epoch[494/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:52:54 | Train | Epoch[494/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:52:54 | Train | Epoch[494/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:52:55 | Train | Epoch[494/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:52:55 | Train | Epoch[494/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:52:55 | Train | Epoch[494/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:52:55 | Train | Epoch[494/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:52:56 | Train | Epoch[494/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:52:56 | Train | Epoch[494/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:52:56 | Train | Epoch[494/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:52:56 | Train | Epoch[494/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:52:56 | Train | Epoch[494/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:52:57 | Train | Epoch[494/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:52:57 | Train | Epoch[494/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:52:57 | Train | Epoch[494/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:52:57 | Train | Epoch[494/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:52:57 | Train | Epoch[494/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:52:58 | Train | Epoch[494/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:52:58 | Train | Epoch[494/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:52:58 | Valid | Epoch[494/600] Iteration[001/008] Valid loss: 0.2763
2023-02-06 14:52:58 | Valid | Epoch[494/600] Iteration[002/008] Valid loss: 0.2221
2023-02-06 14:52:58 | Valid | Epoch[494/600] Iteration[003/008] Valid loss: 0.2161
2023-02-06 14:52:58 | Valid | Epoch[494/600] Iteration[004/008] Valid loss: 0.2088
2023-02-06 14:52:58 | Valid | Epoch[494/600] Iteration[005/008] Valid loss: 0.2119
2023-02-06 14:52:58 | Valid | Epoch[494/600] Iteration[006/008] Valid loss: 0.2076
2023-02-06 14:52:59 | Valid | Epoch[494/600] Iteration[007/008] Valid loss: 0.2252
2023-02-06 14:52:59 | Valid | Epoch[494/600] Iteration[008/008] Valid loss: 0.2264
2023-02-06 14:52:59 | Valid | Epoch[494/600] MIou: 0.9282402423850298
2023-02-06 14:52:59 | Valid | Epoch[494/600] Pixel Accuracy: 0.987237294514974
2023-02-06 14:52:59 | Valid | Epoch[494/600] Mean Pixel Accuracy: 0.9701847371917667
2023-02-06 14:52:59 | Stage | Epoch[494/600] Train loss:0.0077
2023-02-06 14:52:59 | Stage | Epoch[494/600] Valid loss:0.2264
2023-02-06 14:52:59 | Stage | Epoch[494/600] LR:0.001

2023-02-06 14:52:59 | Train | Epoch[495/600] Iteration[001/030] Train loss: 0.0096
2023-02-06 14:52:59 | Train | Epoch[495/600] Iteration[002/030] Train loss: 0.0088
2023-02-06 14:53:00 | Train | Epoch[495/600] Iteration[003/030] Train loss: 0.0085
2023-02-06 14:53:00 | Train | Epoch[495/600] Iteration[004/030] Train loss: 0.0082
2023-02-06 14:53:00 | Train | Epoch[495/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:53:00 | Train | Epoch[495/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:53:00 | Train | Epoch[495/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:53:01 | Train | Epoch[495/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:53:01 | Train | Epoch[495/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:53:01 | Train | Epoch[495/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:53:01 | Train | Epoch[495/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:53:02 | Train | Epoch[495/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:53:02 | Train | Epoch[495/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:53:02 | Train | Epoch[495/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:53:02 | Train | Epoch[495/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:53:02 | Train | Epoch[495/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:53:03 | Train | Epoch[495/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:53:03 | Train | Epoch[495/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:53:03 | Train | Epoch[495/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:53:03 | Train | Epoch[495/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:53:04 | Train | Epoch[495/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:53:04 | Train | Epoch[495/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:53:04 | Train | Epoch[495/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:53:04 | Train | Epoch[495/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:53:04 | Train | Epoch[495/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:53:05 | Train | Epoch[495/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:53:05 | Train | Epoch[495/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:53:05 | Train | Epoch[495/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:53:05 | Train | Epoch[495/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:53:05 | Train | Epoch[495/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:53:06 | Valid | Epoch[495/600] Iteration[001/008] Valid loss: 0.1302
2023-02-06 14:53:06 | Valid | Epoch[495/600] Iteration[002/008] Valid loss: 0.1041
2023-02-06 14:53:06 | Valid | Epoch[495/600] Iteration[003/008] Valid loss: 0.0991
2023-02-06 14:53:06 | Valid | Epoch[495/600] Iteration[004/008] Valid loss: 0.0940
2023-02-06 14:53:06 | Valid | Epoch[495/600] Iteration[005/008] Valid loss: 0.0916
2023-02-06 14:53:06 | Valid | Epoch[495/600] Iteration[006/008] Valid loss: 0.0879
2023-02-06 14:53:06 | Valid | Epoch[495/600] Iteration[007/008] Valid loss: 0.0908
2023-02-06 14:53:06 | Valid | Epoch[495/600] Iteration[008/008] Valid loss: 0.0887
2023-02-06 14:53:06 | Valid | Epoch[495/600] MIou: 0.9229632498699063
2023-02-06 14:53:06 | Valid | Epoch[495/600] Pixel Accuracy: 0.986914316813151
2023-02-06 14:53:06 | Valid | Epoch[495/600] Mean Pixel Accuracy: 0.9437957056412412
2023-02-06 14:53:06 | Stage | Epoch[495/600] Train loss:0.0077
2023-02-06 14:53:06 | Stage | Epoch[495/600] Valid loss:0.0887
2023-02-06 14:53:06 | Stage | Epoch[495/600] LR:0.001

2023-02-06 14:53:07 | Train | Epoch[496/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 14:53:07 | Train | Epoch[496/600] Iteration[002/030] Train loss: 0.0069
2023-02-06 14:53:07 | Train | Epoch[496/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:53:07 | Train | Epoch[496/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:53:07 | Train | Epoch[496/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:53:08 | Train | Epoch[496/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:53:08 | Train | Epoch[496/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:53:08 | Train | Epoch[496/600] Iteration[008/030] Train loss: 0.0082
2023-02-06 14:53:08 | Train | Epoch[496/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:53:09 | Train | Epoch[496/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:53:09 | Train | Epoch[496/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:53:09 | Train | Epoch[496/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:53:09 | Train | Epoch[496/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:53:09 | Train | Epoch[496/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:53:10 | Train | Epoch[496/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:53:10 | Train | Epoch[496/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:53:10 | Train | Epoch[496/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:53:10 | Train | Epoch[496/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:53:11 | Train | Epoch[496/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:53:11 | Train | Epoch[496/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:53:11 | Train | Epoch[496/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:53:11 | Train | Epoch[496/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:53:11 | Train | Epoch[496/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:53:12 | Train | Epoch[496/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:53:12 | Train | Epoch[496/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:53:12 | Train | Epoch[496/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:53:12 | Train | Epoch[496/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:53:12 | Train | Epoch[496/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:53:13 | Train | Epoch[496/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:53:13 | Train | Epoch[496/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:53:13 | Valid | Epoch[496/600] Iteration[001/008] Valid loss: 0.2338
2023-02-06 14:53:13 | Valid | Epoch[496/600] Iteration[002/008] Valid loss: 0.1861
2023-02-06 14:53:13 | Valid | Epoch[496/600] Iteration[003/008] Valid loss: 0.1786
2023-02-06 14:53:13 | Valid | Epoch[496/600] Iteration[004/008] Valid loss: 0.1704
2023-02-06 14:53:13 | Valid | Epoch[496/600] Iteration[005/008] Valid loss: 0.1712
2023-02-06 14:53:13 | Valid | Epoch[496/600] Iteration[006/008] Valid loss: 0.1663
2023-02-06 14:53:14 | Valid | Epoch[496/600] Iteration[007/008] Valid loss: 0.1792
2023-02-06 14:53:14 | Valid | Epoch[496/600] Iteration[008/008] Valid loss: 0.1790
2023-02-06 14:53:14 | Valid | Epoch[496/600] MIou: 0.9302195653532368
2023-02-06 14:53:14 | Valid | Epoch[496/600] Pixel Accuracy: 0.987738291422526
2023-02-06 14:53:14 | Valid | Epoch[496/600] Mean Pixel Accuracy: 0.9663895237484035
2023-02-06 14:53:14 | Stage | Epoch[496/600] Train loss:0.0078
2023-02-06 14:53:14 | Stage | Epoch[496/600] Valid loss:0.1790
2023-02-06 14:53:14 | Stage | Epoch[496/600] LR:0.001

2023-02-06 14:53:14 | Train | Epoch[497/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:53:14 | Train | Epoch[497/600] Iteration[002/030] Train loss: 0.0073
2023-02-06 14:53:15 | Train | Epoch[497/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:53:15 | Train | Epoch[497/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:53:15 | Train | Epoch[497/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:53:15 | Train | Epoch[497/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:53:15 | Train | Epoch[497/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:53:16 | Train | Epoch[497/600] Iteration[008/030] Train loss: 0.0083
2023-02-06 14:53:16 | Train | Epoch[497/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:53:16 | Train | Epoch[497/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:53:16 | Train | Epoch[497/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:53:17 | Train | Epoch[497/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:53:17 | Train | Epoch[497/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:53:17 | Train | Epoch[497/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:53:17 | Train | Epoch[497/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:53:17 | Train | Epoch[497/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:53:18 | Train | Epoch[497/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:53:18 | Train | Epoch[497/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:53:18 | Train | Epoch[497/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:53:18 | Train | Epoch[497/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:53:19 | Train | Epoch[497/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:53:19 | Train | Epoch[497/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:53:19 | Train | Epoch[497/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:53:19 | Train | Epoch[497/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:53:19 | Train | Epoch[497/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:53:20 | Train | Epoch[497/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:53:20 | Train | Epoch[497/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:53:20 | Train | Epoch[497/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:53:20 | Train | Epoch[497/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:53:20 | Train | Epoch[497/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:53:21 | Valid | Epoch[497/600] Iteration[001/008] Valid loss: 0.1680
2023-02-06 14:53:21 | Valid | Epoch[497/600] Iteration[002/008] Valid loss: 0.1339
2023-02-06 14:53:21 | Valid | Epoch[497/600] Iteration[003/008] Valid loss: 0.1273
2023-02-06 14:53:21 | Valid | Epoch[497/600] Iteration[004/008] Valid loss: 0.1211
2023-02-06 14:53:21 | Valid | Epoch[497/600] Iteration[005/008] Valid loss: 0.1183
2023-02-06 14:53:21 | Valid | Epoch[497/600] Iteration[006/008] Valid loss: 0.1142
2023-02-06 14:53:21 | Valid | Epoch[497/600] Iteration[007/008] Valid loss: 0.1213
2023-02-06 14:53:21 | Valid | Epoch[497/600] Iteration[008/008] Valid loss: 0.1194
2023-02-06 14:53:21 | Valid | Epoch[497/600] MIou: 0.9288515481956905
2023-02-06 14:53:21 | Valid | Epoch[497/600] Pixel Accuracy: 0.9877599080403646
2023-02-06 14:53:21 | Valid | Epoch[497/600] Mean Pixel Accuracy: 0.9551787705871126
2023-02-06 14:53:21 | Stage | Epoch[497/600] Train loss:0.0078
2023-02-06 14:53:21 | Stage | Epoch[497/600] Valid loss:0.1194
2023-02-06 14:53:21 | Stage | Epoch[497/600] LR:0.001

2023-02-06 14:53:22 | Train | Epoch[498/600] Iteration[001/030] Train loss: 0.0083
2023-02-06 14:53:22 | Train | Epoch[498/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:53:22 | Train | Epoch[498/600] Iteration[003/030] Train loss: 0.0081
2023-02-06 14:53:22 | Train | Epoch[498/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:53:22 | Train | Epoch[498/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:53:23 | Train | Epoch[498/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:53:23 | Train | Epoch[498/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:53:23 | Train | Epoch[498/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:53:23 | Train | Epoch[498/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:53:24 | Train | Epoch[498/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 14:53:24 | Train | Epoch[498/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 14:53:24 | Train | Epoch[498/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 14:53:24 | Train | Epoch[498/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:53:24 | Train | Epoch[498/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:53:25 | Train | Epoch[498/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 14:53:25 | Train | Epoch[498/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:53:25 | Train | Epoch[498/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 14:53:25 | Train | Epoch[498/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:53:26 | Train | Epoch[498/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 14:53:26 | Train | Epoch[498/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:53:26 | Train | Epoch[498/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:53:26 | Train | Epoch[498/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:53:26 | Train | Epoch[498/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:53:27 | Train | Epoch[498/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:53:27 | Train | Epoch[498/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:53:27 | Train | Epoch[498/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:53:27 | Train | Epoch[498/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:53:28 | Train | Epoch[498/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:53:28 | Train | Epoch[498/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:53:28 | Train | Epoch[498/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:53:28 | Valid | Epoch[498/600] Iteration[001/008] Valid loss: 0.1714
2023-02-06 14:53:28 | Valid | Epoch[498/600] Iteration[002/008] Valid loss: 0.1365
2023-02-06 14:53:28 | Valid | Epoch[498/600] Iteration[003/008] Valid loss: 0.1290
2023-02-06 14:53:28 | Valid | Epoch[498/600] Iteration[004/008] Valid loss: 0.1221
2023-02-06 14:53:28 | Valid | Epoch[498/600] Iteration[005/008] Valid loss: 0.1198
2023-02-06 14:53:28 | Valid | Epoch[498/600] Iteration[006/008] Valid loss: 0.1157
2023-02-06 14:53:28 | Valid | Epoch[498/600] Iteration[007/008] Valid loss: 0.1234
2023-02-06 14:53:29 | Valid | Epoch[498/600] Iteration[008/008] Valid loss: 0.1216
2023-02-06 14:53:29 | Valid | Epoch[498/600] MIou: 0.9289439605450003
2023-02-06 14:53:29 | Valid | Epoch[498/600] Pixel Accuracy: 0.987762451171875
2023-02-06 14:53:29 | Valid | Epoch[498/600] Mean Pixel Accuracy: 0.9557698322512762
2023-02-06 14:53:29 | Stage | Epoch[498/600] Train loss:0.0076
2023-02-06 14:53:29 | Stage | Epoch[498/600] Valid loss:0.1216
2023-02-06 14:53:29 | Stage | Epoch[498/600] LR:0.001

2023-02-06 14:53:29 | Train | Epoch[499/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 14:53:29 | Train | Epoch[499/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:53:30 | Train | Epoch[499/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:53:30 | Train | Epoch[499/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:53:30 | Train | Epoch[499/600] Iteration[005/030] Train loss: 0.0074
2023-02-06 14:53:30 | Train | Epoch[499/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:53:30 | Train | Epoch[499/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:53:31 | Train | Epoch[499/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:53:31 | Train | Epoch[499/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:53:31 | Train | Epoch[499/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:53:31 | Train | Epoch[499/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:53:31 | Train | Epoch[499/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:53:32 | Train | Epoch[499/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:53:32 | Train | Epoch[499/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:53:32 | Train | Epoch[499/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:53:32 | Train | Epoch[499/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:53:33 | Train | Epoch[499/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:53:33 | Train | Epoch[499/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:53:33 | Train | Epoch[499/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:53:33 | Train | Epoch[499/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:53:33 | Train | Epoch[499/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:53:34 | Train | Epoch[499/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:53:34 | Train | Epoch[499/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:53:34 | Train | Epoch[499/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:53:34 | Train | Epoch[499/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:53:35 | Train | Epoch[499/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:53:35 | Train | Epoch[499/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:53:35 | Train | Epoch[499/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:53:35 | Train | Epoch[499/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:53:35 | Train | Epoch[499/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:53:36 | Valid | Epoch[499/600] Iteration[001/008] Valid loss: 0.1785
2023-02-06 14:53:36 | Valid | Epoch[499/600] Iteration[002/008] Valid loss: 0.1417
2023-02-06 14:53:36 | Valid | Epoch[499/600] Iteration[003/008] Valid loss: 0.1326
2023-02-06 14:53:36 | Valid | Epoch[499/600] Iteration[004/008] Valid loss: 0.1257
2023-02-06 14:53:36 | Valid | Epoch[499/600] Iteration[005/008] Valid loss: 0.1245
2023-02-06 14:53:36 | Valid | Epoch[499/600] Iteration[006/008] Valid loss: 0.1208
2023-02-06 14:53:36 | Valid | Epoch[499/600] Iteration[007/008] Valid loss: 0.1296
2023-02-06 14:53:36 | Valid | Epoch[499/600] Iteration[008/008] Valid loss: 0.1275
2023-02-06 14:53:36 | Valid | Epoch[499/600] MIou: 0.9308377200350288
2023-02-06 14:53:36 | Valid | Epoch[499/600] Pixel Accuracy: 0.988073984781901
2023-02-06 14:53:36 | Valid | Epoch[499/600] Mean Pixel Accuracy: 0.9581602294391616
2023-02-06 14:53:36 | Stage | Epoch[499/600] Train loss:0.0077
2023-02-06 14:53:36 | Stage | Epoch[499/600] Valid loss:0.1275
2023-02-06 14:53:36 | Stage | Epoch[499/600] LR:0.001

2023-02-06 14:53:37 | Train | Epoch[500/600] Iteration[001/030] Train loss: 0.0084
2023-02-06 14:53:37 | Train | Epoch[500/600] Iteration[002/030] Train loss: 0.0082
2023-02-06 14:53:37 | Train | Epoch[500/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:53:37 | Train | Epoch[500/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:53:37 | Train | Epoch[500/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:53:38 | Train | Epoch[500/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:53:38 | Train | Epoch[500/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:53:38 | Train | Epoch[500/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:53:38 | Train | Epoch[500/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:53:39 | Train | Epoch[500/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:53:39 | Train | Epoch[500/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:53:39 | Train | Epoch[500/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:53:39 | Train | Epoch[500/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 14:53:39 | Train | Epoch[500/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:53:40 | Train | Epoch[500/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:53:40 | Train | Epoch[500/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:53:40 | Train | Epoch[500/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:53:40 | Train | Epoch[500/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:53:40 | Train | Epoch[500/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:53:41 | Train | Epoch[500/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:53:41 | Train | Epoch[500/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:53:41 | Train | Epoch[500/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:53:41 | Train | Epoch[500/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:53:42 | Train | Epoch[500/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:53:42 | Train | Epoch[500/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:53:42 | Train | Epoch[500/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:53:42 | Train | Epoch[500/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:53:42 | Train | Epoch[500/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:53:43 | Train | Epoch[500/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:53:43 | Train | Epoch[500/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:53:43 | Valid | Epoch[500/600] Iteration[001/008] Valid loss: 0.1630
2023-02-06 14:53:43 | Valid | Epoch[500/600] Iteration[002/008] Valid loss: 0.1283
2023-02-06 14:53:43 | Valid | Epoch[500/600] Iteration[003/008] Valid loss: 0.1201
2023-02-06 14:53:43 | Valid | Epoch[500/600] Iteration[004/008] Valid loss: 0.1139
2023-02-06 14:53:43 | Valid | Epoch[500/600] Iteration[005/008] Valid loss: 0.1111
2023-02-06 14:53:43 | Valid | Epoch[500/600] Iteration[006/008] Valid loss: 0.1075
2023-02-06 14:53:43 | Valid | Epoch[500/600] Iteration[007/008] Valid loss: 0.1142
2023-02-06 14:53:43 | Valid | Epoch[500/600] Iteration[008/008] Valid loss: 0.1121
2023-02-06 14:53:44 | Valid | Epoch[500/600] MIou: 0.927837623695005
2023-02-06 14:53:44 | Valid | Epoch[500/600] Pixel Accuracy: 0.9876352945963541
2023-02-06 14:53:44 | Valid | Epoch[500/600] Mean Pixel Accuracy: 0.9523648535589192
2023-02-06 14:53:44 | Stage | Epoch[500/600] Train loss:0.0077
2023-02-06 14:53:44 | Stage | Epoch[500/600] Valid loss:0.1121
2023-02-06 14:53:44 | Stage | Epoch[500/600] LR:0.001

2023-02-06 14:53:44 | Train | Epoch[501/600] Iteration[001/030] Train loss: 0.0076
2023-02-06 14:53:44 | Train | Epoch[501/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:53:44 | Train | Epoch[501/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:53:45 | Train | Epoch[501/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:53:45 | Train | Epoch[501/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:53:45 | Train | Epoch[501/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:53:45 | Train | Epoch[501/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:53:46 | Train | Epoch[501/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:53:46 | Train | Epoch[501/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:53:46 | Train | Epoch[501/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:53:46 | Train | Epoch[501/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:53:46 | Train | Epoch[501/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:53:47 | Train | Epoch[501/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:53:47 | Train | Epoch[501/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:53:47 | Train | Epoch[501/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:53:47 | Train | Epoch[501/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:53:48 | Train | Epoch[501/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:53:48 | Train | Epoch[501/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:53:48 | Train | Epoch[501/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:53:48 | Train | Epoch[501/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:53:48 | Train | Epoch[501/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:53:49 | Train | Epoch[501/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:53:49 | Train | Epoch[501/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:53:49 | Train | Epoch[501/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:53:49 | Train | Epoch[501/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:53:50 | Train | Epoch[501/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:53:50 | Train | Epoch[501/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:53:50 | Train | Epoch[501/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:53:50 | Train | Epoch[501/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:53:50 | Train | Epoch[501/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:53:51 | Valid | Epoch[501/600] Iteration[001/008] Valid loss: 0.1843
2023-02-06 14:53:51 | Valid | Epoch[501/600] Iteration[002/008] Valid loss: 0.1451
2023-02-06 14:53:51 | Valid | Epoch[501/600] Iteration[003/008] Valid loss: 0.1362
2023-02-06 14:53:51 | Valid | Epoch[501/600] Iteration[004/008] Valid loss: 0.1284
2023-02-06 14:53:51 | Valid | Epoch[501/600] Iteration[005/008] Valid loss: 0.1262
2023-02-06 14:53:51 | Valid | Epoch[501/600] Iteration[006/008] Valid loss: 0.1220
2023-02-06 14:53:51 | Valid | Epoch[501/600] Iteration[007/008] Valid loss: 0.1304
2023-02-06 14:53:51 | Valid | Epoch[501/600] Iteration[008/008] Valid loss: 0.1287
2023-02-06 14:53:51 | Valid | Epoch[501/600] MIou: 0.9295231445477916
2023-02-06 14:53:51 | Valid | Epoch[501/600] Pixel Accuracy: 0.9878349304199219
2023-02-06 14:53:51 | Valid | Epoch[501/600] Mean Pixel Accuracy: 0.9573630854576274
2023-02-06 14:53:51 | Stage | Epoch[501/600] Train loss:0.0075
2023-02-06 14:53:51 | Stage | Epoch[501/600] Valid loss:0.1287
2023-02-06 14:53:51 | Stage | Epoch[501/600] LR:0.0001

2023-02-06 14:53:52 | Train | Epoch[502/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 14:53:52 | Train | Epoch[502/600] Iteration[002/030] Train loss: 0.0082
2023-02-06 14:53:52 | Train | Epoch[502/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:53:52 | Train | Epoch[502/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:53:52 | Train | Epoch[502/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:53:53 | Train | Epoch[502/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:53:53 | Train | Epoch[502/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:53:53 | Train | Epoch[502/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:53:53 | Train | Epoch[502/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:53:54 | Train | Epoch[502/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:53:54 | Train | Epoch[502/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:53:54 | Train | Epoch[502/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:53:54 | Train | Epoch[502/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:53:54 | Train | Epoch[502/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:53:55 | Train | Epoch[502/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:53:55 | Train | Epoch[502/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:53:55 | Train | Epoch[502/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:53:55 | Train | Epoch[502/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:53:56 | Train | Epoch[502/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:53:56 | Train | Epoch[502/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:53:56 | Train | Epoch[502/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:53:56 | Train | Epoch[502/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:53:56 | Train | Epoch[502/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:53:57 | Train | Epoch[502/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:53:57 | Train | Epoch[502/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:53:57 | Train | Epoch[502/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:53:57 | Train | Epoch[502/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:53:57 | Train | Epoch[502/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:53:58 | Train | Epoch[502/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:53:58 | Train | Epoch[502/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:53:58 | Valid | Epoch[502/600] Iteration[001/008] Valid loss: 0.1901
2023-02-06 14:53:58 | Valid | Epoch[502/600] Iteration[002/008] Valid loss: 0.1496
2023-02-06 14:53:58 | Valid | Epoch[502/600] Iteration[003/008] Valid loss: 0.1407
2023-02-06 14:53:58 | Valid | Epoch[502/600] Iteration[004/008] Valid loss: 0.1329
2023-02-06 14:53:58 | Valid | Epoch[502/600] Iteration[005/008] Valid loss: 0.1308
2023-02-06 14:53:58 | Valid | Epoch[502/600] Iteration[006/008] Valid loss: 0.1266
2023-02-06 14:53:58 | Valid | Epoch[502/600] Iteration[007/008] Valid loss: 0.1354
2023-02-06 14:53:59 | Valid | Epoch[502/600] Iteration[008/008] Valid loss: 0.1339
2023-02-06 14:53:59 | Valid | Epoch[502/600] MIou: 0.9297596842503912
2023-02-06 14:53:59 | Valid | Epoch[502/600] Pixel Accuracy: 0.9878527323404948
2023-02-06 14:53:59 | Valid | Epoch[502/600] Mean Pixel Accuracy: 0.9584697717239976
2023-02-06 14:53:59 | Stage | Epoch[502/600] Train loss:0.0077
2023-02-06 14:53:59 | Stage | Epoch[502/600] Valid loss:0.1339
2023-02-06 14:53:59 | Stage | Epoch[502/600] LR:0.0001

2023-02-06 14:53:59 | Train | Epoch[503/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:53:59 | Train | Epoch[503/600] Iteration[002/030] Train loss: 0.0071
2023-02-06 14:54:00 | Train | Epoch[503/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:54:00 | Train | Epoch[503/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:54:00 | Train | Epoch[503/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:54:00 | Train | Epoch[503/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:54:00 | Train | Epoch[503/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:54:01 | Train | Epoch[503/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:54:01 | Train | Epoch[503/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:54:01 | Train | Epoch[503/600] Iteration[010/030] Train loss: 0.0081
2023-02-06 14:54:01 | Train | Epoch[503/600] Iteration[011/030] Train loss: 0.0081
2023-02-06 14:54:02 | Train | Epoch[503/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:54:02 | Train | Epoch[503/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:54:02 | Train | Epoch[503/600] Iteration[014/030] Train loss: 0.0080
2023-02-06 14:54:02 | Train | Epoch[503/600] Iteration[015/030] Train loss: 0.0080
2023-02-06 14:54:02 | Train | Epoch[503/600] Iteration[016/030] Train loss: 0.0079
2023-02-06 14:54:03 | Train | Epoch[503/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:54:03 | Train | Epoch[503/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:54:03 | Train | Epoch[503/600] Iteration[019/030] Train loss: 0.0079
2023-02-06 14:54:03 | Train | Epoch[503/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:54:03 | Train | Epoch[503/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:54:04 | Train | Epoch[503/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:54:04 | Train | Epoch[503/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:54:04 | Train | Epoch[503/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:54:04 | Train | Epoch[503/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:54:05 | Train | Epoch[503/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:54:05 | Train | Epoch[503/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 14:54:05 | Train | Epoch[503/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:54:05 | Train | Epoch[503/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:54:05 | Train | Epoch[503/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:54:06 | Valid | Epoch[503/600] Iteration[001/008] Valid loss: 0.1840
2023-02-06 14:54:06 | Valid | Epoch[503/600] Iteration[002/008] Valid loss: 0.1448
2023-02-06 14:54:06 | Valid | Epoch[503/600] Iteration[003/008] Valid loss: 0.1359
2023-02-06 14:54:06 | Valid | Epoch[503/600] Iteration[004/008] Valid loss: 0.1283
2023-02-06 14:54:06 | Valid | Epoch[503/600] Iteration[005/008] Valid loss: 0.1263
2023-02-06 14:54:06 | Valid | Epoch[503/600] Iteration[006/008] Valid loss: 0.1218
2023-02-06 14:54:06 | Valid | Epoch[503/600] Iteration[007/008] Valid loss: 0.1301
2023-02-06 14:54:06 | Valid | Epoch[503/600] Iteration[008/008] Valid loss: 0.1286
2023-02-06 14:54:06 | Valid | Epoch[503/600] MIou: 0.9295750921152857
2023-02-06 14:54:06 | Valid | Epoch[503/600] Pixel Accuracy: 0.9878412882486979
2023-02-06 14:54:06 | Valid | Epoch[503/600] Mean Pixel Accuracy: 0.9575124108362554
2023-02-06 14:54:06 | Stage | Epoch[503/600] Train loss:0.0078
2023-02-06 14:54:06 | Stage | Epoch[503/600] Valid loss:0.1286
2023-02-06 14:54:06 | Stage | Epoch[503/600] LR:0.0001

2023-02-06 14:54:07 | Train | Epoch[504/600] Iteration[001/030] Train loss: 0.0092
2023-02-06 14:54:07 | Train | Epoch[504/600] Iteration[002/030] Train loss: 0.0090
2023-02-06 14:54:07 | Train | Epoch[504/600] Iteration[003/030] Train loss: 0.0085
2023-02-06 14:54:07 | Train | Epoch[504/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:54:07 | Train | Epoch[504/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 14:54:08 | Train | Epoch[504/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:54:08 | Train | Epoch[504/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:54:08 | Train | Epoch[504/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:54:08 | Train | Epoch[504/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:54:09 | Train | Epoch[504/600] Iteration[010/030] Train loss: 0.0081
2023-02-06 14:54:09 | Train | Epoch[504/600] Iteration[011/030] Train loss: 0.0082
2023-02-06 14:54:09 | Train | Epoch[504/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:54:09 | Train | Epoch[504/600] Iteration[013/030] Train loss: 0.0082
2023-02-06 14:54:09 | Train | Epoch[504/600] Iteration[014/030] Train loss: 0.0082
2023-02-06 14:54:10 | Train | Epoch[504/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 14:54:10 | Train | Epoch[504/600] Iteration[016/030] Train loss: 0.0081
2023-02-06 14:54:10 | Train | Epoch[504/600] Iteration[017/030] Train loss: 0.0080
2023-02-06 14:54:10 | Train | Epoch[504/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 14:54:11 | Train | Epoch[504/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 14:54:11 | Train | Epoch[504/600] Iteration[020/030] Train loss: 0.0080
2023-02-06 14:54:11 | Train | Epoch[504/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:54:11 | Train | Epoch[504/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:54:11 | Train | Epoch[504/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:54:12 | Train | Epoch[504/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:54:12 | Train | Epoch[504/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:54:12 | Train | Epoch[504/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:54:12 | Train | Epoch[504/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:54:13 | Train | Epoch[504/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:54:13 | Train | Epoch[504/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:54:13 | Train | Epoch[504/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:54:13 | Valid | Epoch[504/600] Iteration[001/008] Valid loss: 0.1775
2023-02-06 14:54:13 | Valid | Epoch[504/600] Iteration[002/008] Valid loss: 0.1399
2023-02-06 14:54:13 | Valid | Epoch[504/600] Iteration[003/008] Valid loss: 0.1319
2023-02-06 14:54:13 | Valid | Epoch[504/600] Iteration[004/008] Valid loss: 0.1247
2023-02-06 14:54:13 | Valid | Epoch[504/600] Iteration[005/008] Valid loss: 0.1226
2023-02-06 14:54:14 | Valid | Epoch[504/600] Iteration[006/008] Valid loss: 0.1182
2023-02-06 14:54:14 | Valid | Epoch[504/600] Iteration[007/008] Valid loss: 0.1260
2023-02-06 14:54:14 | Valid | Epoch[504/600] Iteration[008/008] Valid loss: 0.1245
2023-02-06 14:54:14 | Valid | Epoch[504/600] MIou: 0.9293730445644219
2023-02-06 14:54:14 | Valid | Epoch[504/600] Pixel Accuracy: 0.9878247578938802
2023-02-06 14:54:14 | Valid | Epoch[504/600] Mean Pixel Accuracy: 0.9566219995080659
2023-02-06 14:54:14 | Stage | Epoch[504/600] Train loss:0.0077
2023-02-06 14:54:14 | Stage | Epoch[504/600] Valid loss:0.1245
2023-02-06 14:54:14 | Stage | Epoch[504/600] LR:0.0001

2023-02-06 14:54:14 | Train | Epoch[505/600] Iteration[001/030] Train loss: 0.0084
2023-02-06 14:54:14 | Train | Epoch[505/600] Iteration[002/030] Train loss: 0.0080
2023-02-06 14:54:15 | Train | Epoch[505/600] Iteration[003/030] Train loss: 0.0081
2023-02-06 14:54:15 | Train | Epoch[505/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:54:15 | Train | Epoch[505/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:54:15 | Train | Epoch[505/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:54:16 | Train | Epoch[505/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:54:16 | Train | Epoch[505/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:54:16 | Train | Epoch[505/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:54:16 | Train | Epoch[505/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:54:16 | Train | Epoch[505/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:54:17 | Train | Epoch[505/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:54:17 | Train | Epoch[505/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:54:17 | Train | Epoch[505/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:54:17 | Train | Epoch[505/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:54:17 | Train | Epoch[505/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:54:18 | Train | Epoch[505/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:54:18 | Train | Epoch[505/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:54:18 | Train | Epoch[505/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:54:18 | Train | Epoch[505/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:54:19 | Train | Epoch[505/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:54:19 | Train | Epoch[505/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:54:19 | Train | Epoch[505/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:54:19 | Train | Epoch[505/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:54:19 | Train | Epoch[505/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:54:20 | Train | Epoch[505/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:54:20 | Train | Epoch[505/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:54:20 | Train | Epoch[505/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:54:20 | Train | Epoch[505/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:54:20 | Train | Epoch[505/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:54:21 | Valid | Epoch[505/600] Iteration[001/008] Valid loss: 0.1857
2023-02-06 14:54:21 | Valid | Epoch[505/600] Iteration[002/008] Valid loss: 0.1464
2023-02-06 14:54:21 | Valid | Epoch[505/600] Iteration[003/008] Valid loss: 0.1379
2023-02-06 14:54:21 | Valid | Epoch[505/600] Iteration[004/008] Valid loss: 0.1305
2023-02-06 14:54:21 | Valid | Epoch[505/600] Iteration[005/008] Valid loss: 0.1286
2023-02-06 14:54:21 | Valid | Epoch[505/600] Iteration[006/008] Valid loss: 0.1242
2023-02-06 14:54:21 | Valid | Epoch[505/600] Iteration[007/008] Valid loss: 0.1329
2023-02-06 14:54:21 | Valid | Epoch[505/600] Iteration[008/008] Valid loss: 0.1313
2023-02-06 14:54:21 | Valid | Epoch[505/600] MIou: 0.9297450637886211
2023-02-06 14:54:21 | Valid | Epoch[505/600] Pixel Accuracy: 0.987860361735026
2023-02-06 14:54:21 | Valid | Epoch[505/600] Mean Pixel Accuracy: 0.9580681749878448
2023-02-06 14:54:21 | Stage | Epoch[505/600] Train loss:0.0076
2023-02-06 14:54:21 | Stage | Epoch[505/600] Valid loss:0.1313
2023-02-06 14:54:21 | Stage | Epoch[505/600] LR:0.0001

2023-02-06 14:54:22 | Train | Epoch[506/600] Iteration[001/030] Train loss: 0.0063
2023-02-06 14:54:22 | Train | Epoch[506/600] Iteration[002/030] Train loss: 0.0066
2023-02-06 14:54:22 | Train | Epoch[506/600] Iteration[003/030] Train loss: 0.0067
2023-02-06 14:54:22 | Train | Epoch[506/600] Iteration[004/030] Train loss: 0.0069
2023-02-06 14:54:23 | Train | Epoch[506/600] Iteration[005/030] Train loss: 0.0071
2023-02-06 14:54:23 | Train | Epoch[506/600] Iteration[006/030] Train loss: 0.0071
2023-02-06 14:54:23 | Train | Epoch[506/600] Iteration[007/030] Train loss: 0.0072
2023-02-06 14:54:23 | Train | Epoch[506/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 14:54:23 | Train | Epoch[506/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 14:54:24 | Train | Epoch[506/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 14:54:24 | Train | Epoch[506/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 14:54:24 | Train | Epoch[506/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:54:24 | Train | Epoch[506/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:54:25 | Train | Epoch[506/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:54:25 | Train | Epoch[506/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:54:25 | Train | Epoch[506/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:54:25 | Train | Epoch[506/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:54:25 | Train | Epoch[506/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:54:26 | Train | Epoch[506/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:54:26 | Train | Epoch[506/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:54:26 | Train | Epoch[506/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:54:26 | Train | Epoch[506/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 14:54:26 | Train | Epoch[506/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:54:27 | Train | Epoch[506/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:54:27 | Train | Epoch[506/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:54:27 | Train | Epoch[506/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:54:27 | Train | Epoch[506/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:54:28 | Train | Epoch[506/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:54:28 | Train | Epoch[506/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:54:28 | Train | Epoch[506/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:54:28 | Valid | Epoch[506/600] Iteration[001/008] Valid loss: 0.1779
2023-02-06 14:54:28 | Valid | Epoch[506/600] Iteration[002/008] Valid loss: 0.1402
2023-02-06 14:54:28 | Valid | Epoch[506/600] Iteration[003/008] Valid loss: 0.1322
2023-02-06 14:54:28 | Valid | Epoch[506/600] Iteration[004/008] Valid loss: 0.1248
2023-02-06 14:54:28 | Valid | Epoch[506/600] Iteration[005/008] Valid loss: 0.1228
2023-02-06 14:54:28 | Valid | Epoch[506/600] Iteration[006/008] Valid loss: 0.1183
2023-02-06 14:54:29 | Valid | Epoch[506/600] Iteration[007/008] Valid loss: 0.1262
2023-02-06 14:54:29 | Valid | Epoch[506/600] Iteration[008/008] Valid loss: 0.1247
2023-02-06 14:54:29 | Valid | Epoch[506/600] MIou: 0.9292678825664266
2023-02-06 14:54:29 | Valid | Epoch[506/600] Pixel Accuracy: 0.9878044128417969
2023-02-06 14:54:29 | Valid | Epoch[506/600] Mean Pixel Accuracy: 0.9566044765282333
2023-02-06 14:54:29 | Stage | Epoch[506/600] Train loss:0.0076
2023-02-06 14:54:29 | Stage | Epoch[506/600] Valid loss:0.1247
2023-02-06 14:54:29 | Stage | Epoch[506/600] LR:0.0001

2023-02-06 14:54:29 | Train | Epoch[507/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 14:54:29 | Train | Epoch[507/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:54:30 | Train | Epoch[507/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:54:30 | Train | Epoch[507/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:54:30 | Train | Epoch[507/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:54:30 | Train | Epoch[507/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:54:30 | Train | Epoch[507/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 14:54:31 | Train | Epoch[507/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 14:54:31 | Train | Epoch[507/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:54:31 | Train | Epoch[507/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 14:54:31 | Train | Epoch[507/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 14:54:32 | Train | Epoch[507/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 14:54:32 | Train | Epoch[507/600] Iteration[013/030] Train loss: 0.0073
2023-02-06 14:54:32 | Train | Epoch[507/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:54:32 | Train | Epoch[507/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 14:54:32 | Train | Epoch[507/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 14:54:33 | Train | Epoch[507/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 14:54:33 | Train | Epoch[507/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 14:54:33 | Train | Epoch[507/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 14:54:33 | Train | Epoch[507/600] Iteration[020/030] Train loss: 0.0073
2023-02-06 14:54:34 | Train | Epoch[507/600] Iteration[021/030] Train loss: 0.0073
2023-02-06 14:54:34 | Train | Epoch[507/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 14:54:34 | Train | Epoch[507/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 14:54:34 | Train | Epoch[507/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:54:34 | Train | Epoch[507/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:54:35 | Train | Epoch[507/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:54:35 | Train | Epoch[507/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:54:35 | Train | Epoch[507/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:54:35 | Train | Epoch[507/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:54:35 | Train | Epoch[507/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:54:36 | Valid | Epoch[507/600] Iteration[001/008] Valid loss: 0.1850
2023-02-06 14:54:36 | Valid | Epoch[507/600] Iteration[002/008] Valid loss: 0.1461
2023-02-06 14:54:36 | Valid | Epoch[507/600] Iteration[003/008] Valid loss: 0.1383
2023-02-06 14:54:36 | Valid | Epoch[507/600] Iteration[004/008] Valid loss: 0.1305
2023-02-06 14:54:36 | Valid | Epoch[507/600] Iteration[005/008] Valid loss: 0.1285
2023-02-06 14:54:36 | Valid | Epoch[507/600] Iteration[006/008] Valid loss: 0.1242
2023-02-06 14:54:36 | Valid | Epoch[507/600] Iteration[007/008] Valid loss: 0.1328
2023-02-06 14:54:36 | Valid | Epoch[507/600] Iteration[008/008] Valid loss: 0.1312
2023-02-06 14:54:36 | Valid | Epoch[507/600] MIou: 0.9292221381453025
2023-02-06 14:54:36 | Valid | Epoch[507/600] Pixel Accuracy: 0.9877713521321615
2023-02-06 14:54:36 | Valid | Epoch[507/600] Mean Pixel Accuracy: 0.9575120137929762
2023-02-06 14:54:36 | Stage | Epoch[507/600] Train loss:0.0076
2023-02-06 14:54:36 | Stage | Epoch[507/600] Valid loss:0.1312
2023-02-06 14:54:36 | Stage | Epoch[507/600] LR:0.0001

2023-02-06 14:54:37 | Train | Epoch[508/600] Iteration[001/030] Train loss: 0.0069
2023-02-06 14:54:37 | Train | Epoch[508/600] Iteration[002/030] Train loss: 0.0069
2023-02-06 14:54:37 | Train | Epoch[508/600] Iteration[003/030] Train loss: 0.0067
2023-02-06 14:54:37 | Train | Epoch[508/600] Iteration[004/030] Train loss: 0.0070
2023-02-06 14:54:37 | Train | Epoch[508/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 14:54:38 | Train | Epoch[508/600] Iteration[006/030] Train loss: 0.0072
2023-02-06 14:54:38 | Train | Epoch[508/600] Iteration[007/030] Train loss: 0.0072
2023-02-06 14:54:38 | Train | Epoch[508/600] Iteration[008/030] Train loss: 0.0073
2023-02-06 14:54:38 | Train | Epoch[508/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 14:54:38 | Train | Epoch[508/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 14:54:39 | Train | Epoch[508/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 14:54:39 | Train | Epoch[508/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 14:54:39 | Train | Epoch[508/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:54:39 | Train | Epoch[508/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:54:40 | Train | Epoch[508/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:54:40 | Train | Epoch[508/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:54:40 | Train | Epoch[508/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 14:54:40 | Train | Epoch[508/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 14:54:40 | Train | Epoch[508/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 14:54:41 | Train | Epoch[508/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:54:41 | Train | Epoch[508/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:54:41 | Train | Epoch[508/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:54:41 | Train | Epoch[508/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:54:42 | Train | Epoch[508/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:54:42 | Train | Epoch[508/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:54:42 | Train | Epoch[508/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:54:42 | Train | Epoch[508/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:54:42 | Train | Epoch[508/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:54:43 | Train | Epoch[508/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 14:54:43 | Train | Epoch[508/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:54:43 | Valid | Epoch[508/600] Iteration[001/008] Valid loss: 0.1794
2023-02-06 14:54:43 | Valid | Epoch[508/600] Iteration[002/008] Valid loss: 0.1419
2023-02-06 14:54:43 | Valid | Epoch[508/600] Iteration[003/008] Valid loss: 0.1340
2023-02-06 14:54:43 | Valid | Epoch[508/600] Iteration[004/008] Valid loss: 0.1269
2023-02-06 14:54:43 | Valid | Epoch[508/600] Iteration[005/008] Valid loss: 0.1250
2023-02-06 14:54:43 | Valid | Epoch[508/600] Iteration[006/008] Valid loss: 0.1205
2023-02-06 14:54:43 | Valid | Epoch[508/600] Iteration[007/008] Valid loss: 0.1287
2023-02-06 14:54:43 | Valid | Epoch[508/600] Iteration[008/008] Valid loss: 0.1271
2023-02-06 14:54:44 | Valid | Epoch[508/600] MIou: 0.9298282679684906
2023-02-06 14:54:44 | Valid | Epoch[508/600] Pixel Accuracy: 0.9878972371419271
2023-02-06 14:54:44 | Valid | Epoch[508/600] Mean Pixel Accuracy: 0.9572895438736536
2023-02-06 14:54:44 | Stage | Epoch[508/600] Train loss:0.0075
2023-02-06 14:54:44 | Stage | Epoch[508/600] Valid loss:0.1271
2023-02-06 14:54:44 | Stage | Epoch[508/600] LR:0.0001

2023-02-06 14:54:44 | Train | Epoch[509/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 14:54:44 | Train | Epoch[509/600] Iteration[002/030] Train loss: 0.0071
2023-02-06 14:54:44 | Train | Epoch[509/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:54:45 | Train | Epoch[509/600] Iteration[004/030] Train loss: 0.0071
2023-02-06 14:54:45 | Train | Epoch[509/600] Iteration[005/030] Train loss: 0.0074
2023-02-06 14:54:45 | Train | Epoch[509/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:54:45 | Train | Epoch[509/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 14:54:45 | Train | Epoch[509/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 14:54:46 | Train | Epoch[509/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 14:54:46 | Train | Epoch[509/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:54:46 | Train | Epoch[509/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:54:46 | Train | Epoch[509/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:54:47 | Train | Epoch[509/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:54:47 | Train | Epoch[509/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:54:47 | Train | Epoch[509/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:54:47 | Train | Epoch[509/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:54:47 | Train | Epoch[509/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:54:48 | Train | Epoch[509/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:54:48 | Train | Epoch[509/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:54:48 | Train | Epoch[509/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:54:48 | Train | Epoch[509/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:54:49 | Train | Epoch[509/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:54:49 | Train | Epoch[509/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:54:49 | Train | Epoch[509/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:54:49 | Train | Epoch[509/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:54:49 | Train | Epoch[509/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:54:50 | Train | Epoch[509/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:54:50 | Train | Epoch[509/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:54:50 | Train | Epoch[509/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:54:50 | Train | Epoch[509/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:54:50 | Valid | Epoch[509/600] Iteration[001/008] Valid loss: 0.1892
2023-02-06 14:54:51 | Valid | Epoch[509/600] Iteration[002/008] Valid loss: 0.1494
2023-02-06 14:54:51 | Valid | Epoch[509/600] Iteration[003/008] Valid loss: 0.1414
2023-02-06 14:54:51 | Valid | Epoch[509/600] Iteration[004/008] Valid loss: 0.1334
2023-02-06 14:54:51 | Valid | Epoch[509/600] Iteration[005/008] Valid loss: 0.1318
2023-02-06 14:54:51 | Valid | Epoch[509/600] Iteration[006/008] Valid loss: 0.1272
2023-02-06 14:54:51 | Valid | Epoch[509/600] Iteration[007/008] Valid loss: 0.1361
2023-02-06 14:54:51 | Valid | Epoch[509/600] Iteration[008/008] Valid loss: 0.1345
2023-02-06 14:54:51 | Valid | Epoch[509/600] MIou: 0.9303957746575917
2023-02-06 14:54:51 | Valid | Epoch[509/600] Pixel Accuracy: 0.9879582722981771
2023-02-06 14:54:51 | Valid | Epoch[509/600] Mean Pixel Accuracy: 0.9592569352097994
2023-02-06 14:54:51 | Stage | Epoch[509/600] Train loss:0.0077
2023-02-06 14:54:51 | Stage | Epoch[509/600] Valid loss:0.1345
2023-02-06 14:54:51 | Stage | Epoch[509/600] LR:0.0001

2023-02-06 14:54:51 | Train | Epoch[510/600] Iteration[001/030] Train loss: 0.0084
2023-02-06 14:54:52 | Train | Epoch[510/600] Iteration[002/030] Train loss: 0.0082
2023-02-06 14:54:52 | Train | Epoch[510/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:54:52 | Train | Epoch[510/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:54:52 | Train | Epoch[510/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:54:52 | Train | Epoch[510/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:54:53 | Train | Epoch[510/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:54:53 | Train | Epoch[510/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:54:53 | Train | Epoch[510/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:54:53 | Train | Epoch[510/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:54:53 | Train | Epoch[510/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:54:54 | Train | Epoch[510/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:54:54 | Train | Epoch[510/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 14:54:54 | Train | Epoch[510/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:54:54 | Train | Epoch[510/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:54:55 | Train | Epoch[510/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:54:55 | Train | Epoch[510/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:54:55 | Train | Epoch[510/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:54:55 | Train | Epoch[510/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:54:55 | Train | Epoch[510/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:54:56 | Train | Epoch[510/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:54:56 | Train | Epoch[510/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:54:56 | Train | Epoch[510/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:54:56 | Train | Epoch[510/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:54:57 | Train | Epoch[510/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:54:57 | Train | Epoch[510/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:54:57 | Train | Epoch[510/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:54:57 | Train | Epoch[510/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:54:57 | Train | Epoch[510/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:54:58 | Train | Epoch[510/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:54:58 | Valid | Epoch[510/600] Iteration[001/008] Valid loss: 0.1828
2023-02-06 14:54:58 | Valid | Epoch[510/600] Iteration[002/008] Valid loss: 0.1443
2023-02-06 14:54:58 | Valid | Epoch[510/600] Iteration[003/008] Valid loss: 0.1365
2023-02-06 14:54:58 | Valid | Epoch[510/600] Iteration[004/008] Valid loss: 0.1289
2023-02-06 14:54:58 | Valid | Epoch[510/600] Iteration[005/008] Valid loss: 0.1271
2023-02-06 14:54:58 | Valid | Epoch[510/600] Iteration[006/008] Valid loss: 0.1228
2023-02-06 14:54:58 | Valid | Epoch[510/600] Iteration[007/008] Valid loss: 0.1312
2023-02-06 14:54:58 | Valid | Epoch[510/600] Iteration[008/008] Valid loss: 0.1296
2023-02-06 14:54:58 | Valid | Epoch[510/600] MIou: 0.9294662988025164
2023-02-06 14:54:58 | Valid | Epoch[510/600] Pixel Accuracy: 0.9878184000651041
2023-02-06 14:54:58 | Valid | Epoch[510/600] Mean Pixel Accuracy: 0.9575632352295157
2023-02-06 14:54:58 | Stage | Epoch[510/600] Train loss:0.0077
2023-02-06 14:54:58 | Stage | Epoch[510/600] Valid loss:0.1296
2023-02-06 14:54:58 | Stage | Epoch[510/600] LR:0.0001

2023-02-06 14:54:59 | Train | Epoch[511/600] Iteration[001/030] Train loss: 0.0066
2023-02-06 14:54:59 | Train | Epoch[511/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 14:54:59 | Train | Epoch[511/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:54:59 | Train | Epoch[511/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:55:00 | Train | Epoch[511/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:55:00 | Train | Epoch[511/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:55:00 | Train | Epoch[511/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:55:00 | Train | Epoch[511/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:55:00 | Train | Epoch[511/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:55:01 | Train | Epoch[511/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:55:01 | Train | Epoch[511/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:55:01 | Train | Epoch[511/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:55:01 | Train | Epoch[511/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:55:02 | Train | Epoch[511/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:55:02 | Train | Epoch[511/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:55:02 | Train | Epoch[511/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:55:02 | Train | Epoch[511/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:55:02 | Train | Epoch[511/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:55:03 | Train | Epoch[511/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:55:03 | Train | Epoch[511/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:55:03 | Train | Epoch[511/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:55:03 | Train | Epoch[511/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:55:04 | Train | Epoch[511/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:55:04 | Train | Epoch[511/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:55:04 | Train | Epoch[511/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:55:04 | Train | Epoch[511/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:55:04 | Train | Epoch[511/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:55:05 | Train | Epoch[511/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:55:05 | Train | Epoch[511/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:55:05 | Train | Epoch[511/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:55:05 | Valid | Epoch[511/600] Iteration[001/008] Valid loss: 0.1822
2023-02-06 14:55:05 | Valid | Epoch[511/600] Iteration[002/008] Valid loss: 0.1441
2023-02-06 14:55:05 | Valid | Epoch[511/600] Iteration[003/008] Valid loss: 0.1361
2023-02-06 14:55:05 | Valid | Epoch[511/600] Iteration[004/008] Valid loss: 0.1286
2023-02-06 14:55:06 | Valid | Epoch[511/600] Iteration[005/008] Valid loss: 0.1269
2023-02-06 14:55:06 | Valid | Epoch[511/600] Iteration[006/008] Valid loss: 0.1224
2023-02-06 14:55:06 | Valid | Epoch[511/600] Iteration[007/008] Valid loss: 0.1307
2023-02-06 14:55:06 | Valid | Epoch[511/600] Iteration[008/008] Valid loss: 0.1291
2023-02-06 14:55:06 | Valid | Epoch[511/600] MIou: 0.9294015654395644
2023-02-06 14:55:06 | Valid | Epoch[511/600] Pixel Accuracy: 0.9878082275390625
2023-02-06 14:55:06 | Valid | Epoch[511/600] Mean Pixel Accuracy: 0.9574625369026742
2023-02-06 14:55:06 | Stage | Epoch[511/600] Train loss:0.0077
2023-02-06 14:55:06 | Stage | Epoch[511/600] Valid loss:0.1291
2023-02-06 14:55:06 | Stage | Epoch[511/600] LR:0.0001

2023-02-06 14:55:06 | Train | Epoch[512/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:55:06 | Train | Epoch[512/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:55:07 | Train | Epoch[512/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:55:07 | Train | Epoch[512/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:55:07 | Train | Epoch[512/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 14:55:07 | Train | Epoch[512/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:55:08 | Train | Epoch[512/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:55:08 | Train | Epoch[512/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:55:08 | Train | Epoch[512/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:55:08 | Train | Epoch[512/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 14:55:08 | Train | Epoch[512/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:55:09 | Train | Epoch[512/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:55:09 | Train | Epoch[512/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:55:09 | Train | Epoch[512/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:55:09 | Train | Epoch[512/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:55:10 | Train | Epoch[512/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:55:10 | Train | Epoch[512/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:55:10 | Train | Epoch[512/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:55:10 | Train | Epoch[512/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:55:10 | Train | Epoch[512/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:55:11 | Train | Epoch[512/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:55:11 | Train | Epoch[512/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:55:11 | Train | Epoch[512/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:55:11 | Train | Epoch[512/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:55:12 | Train | Epoch[512/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:55:12 | Train | Epoch[512/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:55:12 | Train | Epoch[512/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:55:12 | Train | Epoch[512/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:55:12 | Train | Epoch[512/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:55:12 | Train | Epoch[512/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:55:13 | Valid | Epoch[512/600] Iteration[001/008] Valid loss: 0.1910
2023-02-06 14:55:13 | Valid | Epoch[512/600] Iteration[002/008] Valid loss: 0.1515
2023-02-06 14:55:13 | Valid | Epoch[512/600] Iteration[003/008] Valid loss: 0.1428
2023-02-06 14:55:13 | Valid | Epoch[512/600] Iteration[004/008] Valid loss: 0.1356
2023-02-06 14:55:13 | Valid | Epoch[512/600] Iteration[005/008] Valid loss: 0.1345
2023-02-06 14:55:13 | Valid | Epoch[512/600] Iteration[006/008] Valid loss: 0.1301
2023-02-06 14:55:13 | Valid | Epoch[512/600] Iteration[007/008] Valid loss: 0.1391
2023-02-06 14:55:13 | Valid | Epoch[512/600] Iteration[008/008] Valid loss: 0.1377
2023-02-06 14:55:13 | Valid | Epoch[512/600] MIou: 0.9303402843686992
2023-02-06 14:55:13 | Valid | Epoch[512/600] Pixel Accuracy: 0.9879252115885416
2023-02-06 14:55:13 | Valid | Epoch[512/600] Mean Pixel Accuracy: 0.9601074082309335
2023-02-06 14:55:13 | Stage | Epoch[512/600] Train loss:0.0078
2023-02-06 14:55:13 | Stage | Epoch[512/600] Valid loss:0.1377
2023-02-06 14:55:13 | Stage | Epoch[512/600] LR:0.0001

2023-02-06 14:55:14 | Train | Epoch[513/600] Iteration[001/030] Train loss: 0.0074
2023-02-06 14:55:14 | Train | Epoch[513/600] Iteration[002/030] Train loss: 0.0073
2023-02-06 14:55:14 | Train | Epoch[513/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:55:14 | Train | Epoch[513/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:55:15 | Train | Epoch[513/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:55:15 | Train | Epoch[513/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:55:15 | Train | Epoch[513/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:55:15 | Train | Epoch[513/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:55:16 | Train | Epoch[513/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:55:16 | Train | Epoch[513/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:55:16 | Train | Epoch[513/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:55:16 | Train | Epoch[513/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:55:16 | Train | Epoch[513/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:55:17 | Train | Epoch[513/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:55:17 | Train | Epoch[513/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:55:17 | Train | Epoch[513/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:55:17 | Train | Epoch[513/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:55:18 | Train | Epoch[513/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:55:18 | Train | Epoch[513/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:55:18 | Train | Epoch[513/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:55:18 | Train | Epoch[513/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:55:18 | Train | Epoch[513/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:55:19 | Train | Epoch[513/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:55:19 | Train | Epoch[513/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:55:19 | Train | Epoch[513/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:55:19 | Train | Epoch[513/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:55:20 | Train | Epoch[513/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:55:20 | Train | Epoch[513/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:55:20 | Train | Epoch[513/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:55:20 | Train | Epoch[513/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:55:20 | Valid | Epoch[513/600] Iteration[001/008] Valid loss: 0.1766
2023-02-06 14:55:20 | Valid | Epoch[513/600] Iteration[002/008] Valid loss: 0.1398
2023-02-06 14:55:20 | Valid | Epoch[513/600] Iteration[003/008] Valid loss: 0.1322
2023-02-06 14:55:21 | Valid | Epoch[513/600] Iteration[004/008] Valid loss: 0.1251
2023-02-06 14:55:21 | Valid | Epoch[513/600] Iteration[005/008] Valid loss: 0.1231
2023-02-06 14:55:21 | Valid | Epoch[513/600] Iteration[006/008] Valid loss: 0.1189
2023-02-06 14:55:21 | Valid | Epoch[513/600] Iteration[007/008] Valid loss: 0.1266
2023-02-06 14:55:21 | Valid | Epoch[513/600] Iteration[008/008] Valid loss: 0.1250
2023-02-06 14:55:21 | Valid | Epoch[513/600] MIou: 0.929365528941323
2023-02-06 14:55:21 | Valid | Epoch[513/600] Pixel Accuracy: 0.9878285725911459
2023-02-06 14:55:21 | Valid | Epoch[513/600] Mean Pixel Accuracy: 0.9564212011399895
2023-02-06 14:55:21 | Stage | Epoch[513/600] Train loss:0.0076
2023-02-06 14:55:21 | Stage | Epoch[513/600] Valid loss:0.1250
2023-02-06 14:55:21 | Stage | Epoch[513/600] LR:0.0001

2023-02-06 14:55:21 | Train | Epoch[514/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:55:22 | Train | Epoch[514/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 14:55:22 | Train | Epoch[514/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:55:22 | Train | Epoch[514/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 14:55:22 | Train | Epoch[514/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 14:55:22 | Train | Epoch[514/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 14:55:23 | Train | Epoch[514/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 14:55:23 | Train | Epoch[514/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 14:55:23 | Train | Epoch[514/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 14:55:23 | Train | Epoch[514/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 14:55:24 | Train | Epoch[514/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 14:55:24 | Train | Epoch[514/600] Iteration[012/030] Train loss: 0.0072
2023-02-06 14:55:24 | Train | Epoch[514/600] Iteration[013/030] Train loss: 0.0071
2023-02-06 14:55:24 | Train | Epoch[514/600] Iteration[014/030] Train loss: 0.0072
2023-02-06 14:55:24 | Train | Epoch[514/600] Iteration[015/030] Train loss: 0.0072
2023-02-06 14:55:25 | Train | Epoch[514/600] Iteration[016/030] Train loss: 0.0072
2023-02-06 14:55:25 | Train | Epoch[514/600] Iteration[017/030] Train loss: 0.0073
2023-02-06 14:55:25 | Train | Epoch[514/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 14:55:25 | Train | Epoch[514/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 14:55:25 | Train | Epoch[514/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 14:55:26 | Train | Epoch[514/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 14:55:26 | Train | Epoch[514/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 14:55:26 | Train | Epoch[514/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 14:55:26 | Train | Epoch[514/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:55:27 | Train | Epoch[514/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:55:27 | Train | Epoch[514/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:55:27 | Train | Epoch[514/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:55:27 | Train | Epoch[514/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:55:27 | Train | Epoch[514/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:55:28 | Train | Epoch[514/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:55:28 | Valid | Epoch[514/600] Iteration[001/008] Valid loss: 0.1779
2023-02-06 14:55:28 | Valid | Epoch[514/600] Iteration[002/008] Valid loss: 0.1404
2023-02-06 14:55:28 | Valid | Epoch[514/600] Iteration[003/008] Valid loss: 0.1326
2023-02-06 14:55:28 | Valid | Epoch[514/600] Iteration[004/008] Valid loss: 0.1255
2023-02-06 14:55:28 | Valid | Epoch[514/600] Iteration[005/008] Valid loss: 0.1239
2023-02-06 14:55:28 | Valid | Epoch[514/600] Iteration[006/008] Valid loss: 0.1194
2023-02-06 14:55:28 | Valid | Epoch[514/600] Iteration[007/008] Valid loss: 0.1273
2023-02-06 14:55:28 | Valid | Epoch[514/600] Iteration[008/008] Valid loss: 0.1258
2023-02-06 14:55:28 | Valid | Epoch[514/600] MIou: 0.9298762615335476
2023-02-06 14:55:28 | Valid | Epoch[514/600] Pixel Accuracy: 0.9879074096679688
2023-02-06 14:55:28 | Valid | Epoch[514/600] Mean Pixel Accuracy: 0.9572634327702534
2023-02-06 14:55:28 | Stage | Epoch[514/600] Train loss:0.0075
2023-02-06 14:55:28 | Stage | Epoch[514/600] Valid loss:0.1258
2023-02-06 14:55:28 | Stage | Epoch[514/600] LR:0.0001

2023-02-06 14:55:29 | Train | Epoch[515/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 14:55:29 | Train | Epoch[515/600] Iteration[002/030] Train loss: 0.0073
2023-02-06 14:55:29 | Train | Epoch[515/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 14:55:29 | Train | Epoch[515/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:55:30 | Train | Epoch[515/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 14:55:30 | Train | Epoch[515/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:55:30 | Train | Epoch[515/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:55:30 | Train | Epoch[515/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:55:31 | Train | Epoch[515/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:55:31 | Train | Epoch[515/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:55:31 | Train | Epoch[515/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:55:31 | Train | Epoch[515/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:55:31 | Train | Epoch[515/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:55:32 | Train | Epoch[515/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:55:32 | Train | Epoch[515/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:55:32 | Train | Epoch[515/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:55:32 | Train | Epoch[515/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:55:33 | Train | Epoch[515/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:55:33 | Train | Epoch[515/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:55:33 | Train | Epoch[515/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:55:33 | Train | Epoch[515/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:55:33 | Train | Epoch[515/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:55:34 | Train | Epoch[515/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:55:34 | Train | Epoch[515/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:55:34 | Train | Epoch[515/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:55:34 | Train | Epoch[515/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:55:34 | Train | Epoch[515/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:55:35 | Train | Epoch[515/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:55:35 | Train | Epoch[515/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:55:35 | Train | Epoch[515/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:55:35 | Valid | Epoch[515/600] Iteration[001/008] Valid loss: 0.1833
2023-02-06 14:55:35 | Valid | Epoch[515/600] Iteration[002/008] Valid loss: 0.1453
2023-02-06 14:55:36 | Valid | Epoch[515/600] Iteration[003/008] Valid loss: 0.1373
2023-02-06 14:55:36 | Valid | Epoch[515/600] Iteration[004/008] Valid loss: 0.1298
2023-02-06 14:55:36 | Valid | Epoch[515/600] Iteration[005/008] Valid loss: 0.1284
2023-02-06 14:55:36 | Valid | Epoch[515/600] Iteration[006/008] Valid loss: 0.1240
2023-02-06 14:55:36 | Valid | Epoch[515/600] Iteration[007/008] Valid loss: 0.1326
2023-02-06 14:55:36 | Valid | Epoch[515/600] Iteration[008/008] Valid loss: 0.1311
2023-02-06 14:55:36 | Valid | Epoch[515/600] MIou: 0.9301573244081447
2023-02-06 14:55:36 | Valid | Epoch[515/600] Pixel Accuracy: 0.9879328409830729
2023-02-06 14:55:36 | Valid | Epoch[515/600] Mean Pixel Accuracy: 0.9584186957778283
2023-02-06 14:55:36 | Stage | Epoch[515/600] Train loss:0.0076
2023-02-06 14:55:36 | Stage | Epoch[515/600] Valid loss:0.1311
2023-02-06 14:55:36 | Stage | Epoch[515/600] LR:0.0001

2023-02-06 14:55:36 | Train | Epoch[516/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 14:55:37 | Train | Epoch[516/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:55:37 | Train | Epoch[516/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:55:37 | Train | Epoch[516/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 14:55:37 | Train | Epoch[516/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:55:37 | Train | Epoch[516/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:55:38 | Train | Epoch[516/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:55:38 | Train | Epoch[516/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:55:38 | Train | Epoch[516/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:55:38 | Train | Epoch[516/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:55:38 | Train | Epoch[516/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:55:39 | Train | Epoch[516/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:55:39 | Train | Epoch[516/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:55:39 | Train | Epoch[516/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:55:39 | Train | Epoch[516/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:55:40 | Train | Epoch[516/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:55:40 | Train | Epoch[516/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:55:40 | Train | Epoch[516/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:55:40 | Train | Epoch[516/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:55:40 | Train | Epoch[516/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:55:41 | Train | Epoch[516/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:55:41 | Train | Epoch[516/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:55:41 | Train | Epoch[516/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:55:41 | Train | Epoch[516/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 14:55:42 | Train | Epoch[516/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 14:55:42 | Train | Epoch[516/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 14:55:42 | Train | Epoch[516/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 14:55:42 | Train | Epoch[516/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 14:55:42 | Train | Epoch[516/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 14:55:43 | Train | Epoch[516/600] Iteration[030/030] Train loss: 0.0074
2023-02-06 14:55:43 | Valid | Epoch[516/600] Iteration[001/008] Valid loss: 0.1780
2023-02-06 14:55:43 | Valid | Epoch[516/600] Iteration[002/008] Valid loss: 0.1414
2023-02-06 14:55:43 | Valid | Epoch[516/600] Iteration[003/008] Valid loss: 0.1337
2023-02-06 14:55:43 | Valid | Epoch[516/600] Iteration[004/008] Valid loss: 0.1267
2023-02-06 14:55:43 | Valid | Epoch[516/600] Iteration[005/008] Valid loss: 0.1251
2023-02-06 14:55:43 | Valid | Epoch[516/600] Iteration[006/008] Valid loss: 0.1207
2023-02-06 14:55:43 | Valid | Epoch[516/600] Iteration[007/008] Valid loss: 0.1287
2023-02-06 14:55:43 | Valid | Epoch[516/600] Iteration[008/008] Valid loss: 0.1271
2023-02-06 14:55:43 | Valid | Epoch[516/600] MIou: 0.9300419806291425
2023-02-06 14:55:43 | Valid | Epoch[516/600] Pixel Accuracy: 0.9879328409830729
2023-02-06 14:55:43 | Valid | Epoch[516/600] Mean Pixel Accuracy: 0.9575437107091613
2023-02-06 14:55:43 | Stage | Epoch[516/600] Train loss:0.0074
2023-02-06 14:55:43 | Stage | Epoch[516/600] Valid loss:0.1271
2023-02-06 14:55:43 | Stage | Epoch[516/600] LR:0.0001

2023-02-06 14:55:44 | Train | Epoch[517/600] Iteration[001/030] Train loss: 0.0067
2023-02-06 14:55:44 | Train | Epoch[517/600] Iteration[002/030] Train loss: 0.0066
2023-02-06 14:55:44 | Train | Epoch[517/600] Iteration[003/030] Train loss: 0.0067
2023-02-06 14:55:45 | Train | Epoch[517/600] Iteration[004/030] Train loss: 0.0071
2023-02-06 14:55:45 | Train | Epoch[517/600] Iteration[005/030] Train loss: 0.0071
2023-02-06 14:55:45 | Train | Epoch[517/600] Iteration[006/030] Train loss: 0.0071
2023-02-06 14:55:45 | Train | Epoch[517/600] Iteration[007/030] Train loss: 0.0072
2023-02-06 14:55:45 | Train | Epoch[517/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 14:55:46 | Train | Epoch[517/600] Iteration[009/030] Train loss: 0.0072
2023-02-06 14:55:46 | Train | Epoch[517/600] Iteration[010/030] Train loss: 0.0072
2023-02-06 14:55:46 | Train | Epoch[517/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 14:55:46 | Train | Epoch[517/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 14:55:46 | Train | Epoch[517/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:55:47 | Train | Epoch[517/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:55:47 | Train | Epoch[517/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 14:55:47 | Train | Epoch[517/600] Iteration[016/030] Train loss: 0.0073
2023-02-06 14:55:47 | Train | Epoch[517/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 14:55:48 | Train | Epoch[517/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:55:48 | Train | Epoch[517/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:55:48 | Train | Epoch[517/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:55:48 | Train | Epoch[517/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:55:48 | Train | Epoch[517/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:55:49 | Train | Epoch[517/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:55:49 | Train | Epoch[517/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:55:49 | Train | Epoch[517/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:55:49 | Train | Epoch[517/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:55:50 | Train | Epoch[517/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:55:50 | Train | Epoch[517/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:55:50 | Train | Epoch[517/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:55:50 | Train | Epoch[517/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:55:50 | Valid | Epoch[517/600] Iteration[001/008] Valid loss: 0.1785
2023-02-06 14:55:50 | Valid | Epoch[517/600] Iteration[002/008] Valid loss: 0.1406
2023-02-06 14:55:51 | Valid | Epoch[517/600] Iteration[003/008] Valid loss: 0.1328
2023-02-06 14:55:51 | Valid | Epoch[517/600] Iteration[004/008] Valid loss: 0.1255
2023-02-06 14:55:51 | Valid | Epoch[517/600] Iteration[005/008] Valid loss: 0.1236
2023-02-06 14:55:51 | Valid | Epoch[517/600] Iteration[006/008] Valid loss: 0.1194
2023-02-06 14:55:51 | Valid | Epoch[517/600] Iteration[007/008] Valid loss: 0.1274
2023-02-06 14:55:51 | Valid | Epoch[517/600] Iteration[008/008] Valid loss: 0.1259
2023-02-06 14:55:51 | Valid | Epoch[517/600] MIou: 0.9291848511176928
2023-02-06 14:55:51 | Valid | Epoch[517/600] Pixel Accuracy: 0.9877878824869791
2023-02-06 14:55:51 | Valid | Epoch[517/600] Mean Pixel Accuracy: 0.9566080716832471
2023-02-06 14:55:51 | Stage | Epoch[517/600] Train loss:0.0076
2023-02-06 14:55:51 | Stage | Epoch[517/600] Valid loss:0.1259
2023-02-06 14:55:51 | Stage | Epoch[517/600] LR:0.0001

2023-02-06 14:55:51 | Train | Epoch[518/600] Iteration[001/030] Train loss: 0.0083
2023-02-06 14:55:52 | Train | Epoch[518/600] Iteration[002/030] Train loss: 0.0082
2023-02-06 14:55:52 | Train | Epoch[518/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:55:52 | Train | Epoch[518/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:55:52 | Train | Epoch[518/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 14:55:52 | Train | Epoch[518/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:55:53 | Train | Epoch[518/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:55:53 | Train | Epoch[518/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:55:53 | Train | Epoch[518/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:55:53 | Train | Epoch[518/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:55:54 | Train | Epoch[518/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:55:54 | Train | Epoch[518/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:55:54 | Train | Epoch[518/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:55:54 | Train | Epoch[518/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:55:54 | Train | Epoch[518/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:55:55 | Train | Epoch[518/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:55:55 | Train | Epoch[518/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:55:55 | Train | Epoch[518/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:55:55 | Train | Epoch[518/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:55:55 | Train | Epoch[518/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:55:56 | Train | Epoch[518/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:55:56 | Train | Epoch[518/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:55:56 | Train | Epoch[518/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:55:56 | Train | Epoch[518/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:55:57 | Train | Epoch[518/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:55:57 | Train | Epoch[518/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:55:57 | Train | Epoch[518/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:55:57 | Train | Epoch[518/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:55:57 | Train | Epoch[518/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:55:58 | Train | Epoch[518/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:55:58 | Valid | Epoch[518/600] Iteration[001/008] Valid loss: 0.1870
2023-02-06 14:55:58 | Valid | Epoch[518/600] Iteration[002/008] Valid loss: 0.1482
2023-02-06 14:55:58 | Valid | Epoch[518/600] Iteration[003/008] Valid loss: 0.1405
2023-02-06 14:55:58 | Valid | Epoch[518/600] Iteration[004/008] Valid loss: 0.1328
2023-02-06 14:55:58 | Valid | Epoch[518/600] Iteration[005/008] Valid loss: 0.1312
2023-02-06 14:55:58 | Valid | Epoch[518/600] Iteration[006/008] Valid loss: 0.1270
2023-02-06 14:55:58 | Valid | Epoch[518/600] Iteration[007/008] Valid loss: 0.1361
2023-02-06 14:55:58 | Valid | Epoch[518/600] Iteration[008/008] Valid loss: 0.1345
2023-02-06 14:55:58 | Valid | Epoch[518/600] MIou: 0.9299571239248065
2023-02-06 14:55:58 | Valid | Epoch[518/600] Pixel Accuracy: 0.9878870646158854
2023-02-06 14:55:58 | Valid | Epoch[518/600] Mean Pixel Accuracy: 0.9586534944661025
2023-02-06 14:55:58 | Stage | Epoch[518/600] Train loss:0.0076
2023-02-06 14:55:58 | Stage | Epoch[518/600] Valid loss:0.1345
2023-02-06 14:55:58 | Stage | Epoch[518/600] LR:0.0001

2023-02-06 14:55:59 | Train | Epoch[519/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 14:55:59 | Train | Epoch[519/600] Iteration[002/030] Train loss: 0.0086
2023-02-06 14:55:59 | Train | Epoch[519/600] Iteration[003/030] Train loss: 0.0087
2023-02-06 14:55:59 | Train | Epoch[519/600] Iteration[004/030] Train loss: 0.0084
2023-02-06 14:56:00 | Train | Epoch[519/600] Iteration[005/030] Train loss: 0.0082
2023-02-06 14:56:00 | Train | Epoch[519/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 14:56:00 | Train | Epoch[519/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:56:00 | Train | Epoch[519/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 14:56:01 | Train | Epoch[519/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:56:01 | Train | Epoch[519/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:56:01 | Train | Epoch[519/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:56:01 | Train | Epoch[519/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:56:01 | Train | Epoch[519/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:56:02 | Train | Epoch[519/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:56:02 | Train | Epoch[519/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:56:02 | Train | Epoch[519/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:56:02 | Train | Epoch[519/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:56:03 | Train | Epoch[519/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:56:03 | Train | Epoch[519/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:56:03 | Train | Epoch[519/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:56:03 | Train | Epoch[519/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:56:03 | Train | Epoch[519/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:56:04 | Train | Epoch[519/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:56:04 | Train | Epoch[519/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:56:04 | Train | Epoch[519/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:56:04 | Train | Epoch[519/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:56:04 | Train | Epoch[519/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:56:05 | Train | Epoch[519/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:56:05 | Train | Epoch[519/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:56:05 | Train | Epoch[519/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:56:05 | Valid | Epoch[519/600] Iteration[001/008] Valid loss: 0.1769
2023-02-06 14:56:05 | Valid | Epoch[519/600] Iteration[002/008] Valid loss: 0.1401
2023-02-06 14:56:05 | Valid | Epoch[519/600] Iteration[003/008] Valid loss: 0.1327
2023-02-06 14:56:06 | Valid | Epoch[519/600] Iteration[004/008] Valid loss: 0.1256
2023-02-06 14:56:06 | Valid | Epoch[519/600] Iteration[005/008] Valid loss: 0.1239
2023-02-06 14:56:06 | Valid | Epoch[519/600] Iteration[006/008] Valid loss: 0.1195
2023-02-06 14:56:06 | Valid | Epoch[519/600] Iteration[007/008] Valid loss: 0.1275
2023-02-06 14:56:06 | Valid | Epoch[519/600] Iteration[008/008] Valid loss: 0.1258
2023-02-06 14:56:06 | Valid | Epoch[519/600] MIou: 0.9301542804162678
2023-02-06 14:56:06 | Valid | Epoch[519/600] Pixel Accuracy: 0.9879570007324219
2023-02-06 14:56:06 | Valid | Epoch[519/600] Mean Pixel Accuracy: 0.9574682233366228
2023-02-06 14:56:06 | Stage | Epoch[519/600] Train loss:0.0077
2023-02-06 14:56:06 | Stage | Epoch[519/600] Valid loss:0.1258
2023-02-06 14:56:06 | Stage | Epoch[519/600] LR:0.0001

2023-02-06 14:56:06 | Train | Epoch[520/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:56:07 | Train | Epoch[520/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:56:07 | Train | Epoch[520/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:56:07 | Train | Epoch[520/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 14:56:07 | Train | Epoch[520/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 14:56:07 | Train | Epoch[520/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:56:08 | Train | Epoch[520/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 14:56:08 | Train | Epoch[520/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:56:08 | Train | Epoch[520/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 14:56:08 | Train | Epoch[520/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:56:09 | Train | Epoch[520/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:56:09 | Train | Epoch[520/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:56:09 | Train | Epoch[520/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 14:56:09 | Train | Epoch[520/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:56:09 | Train | Epoch[520/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 14:56:10 | Train | Epoch[520/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:56:10 | Train | Epoch[520/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:56:10 | Train | Epoch[520/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:56:10 | Train | Epoch[520/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:56:10 | Train | Epoch[520/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:56:11 | Train | Epoch[520/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:56:11 | Train | Epoch[520/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:56:11 | Train | Epoch[520/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:56:11 | Train | Epoch[520/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:56:12 | Train | Epoch[520/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:56:12 | Train | Epoch[520/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:56:12 | Train | Epoch[520/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:56:12 | Train | Epoch[520/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:56:12 | Train | Epoch[520/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:56:13 | Train | Epoch[520/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:56:13 | Valid | Epoch[520/600] Iteration[001/008] Valid loss: 0.1807
2023-02-06 14:56:13 | Valid | Epoch[520/600] Iteration[002/008] Valid loss: 0.1433
2023-02-06 14:56:13 | Valid | Epoch[520/600] Iteration[003/008] Valid loss: 0.1354
2023-02-06 14:56:13 | Valid | Epoch[520/600] Iteration[004/008] Valid loss: 0.1283
2023-02-06 14:56:13 | Valid | Epoch[520/600] Iteration[005/008] Valid loss: 0.1268
2023-02-06 14:56:13 | Valid | Epoch[520/600] Iteration[006/008] Valid loss: 0.1224
2023-02-06 14:56:13 | Valid | Epoch[520/600] Iteration[007/008] Valid loss: 0.1307
2023-02-06 14:56:13 | Valid | Epoch[520/600] Iteration[008/008] Valid loss: 0.1290
2023-02-06 14:56:13 | Valid | Epoch[520/600] MIou: 0.9301271139695969
2023-02-06 14:56:13 | Valid | Epoch[520/600] Pixel Accuracy: 0.9879341125488281
2023-02-06 14:56:13 | Valid | Epoch[520/600] Mean Pixel Accuracy: 0.9581404139380669
2023-02-06 14:56:13 | Stage | Epoch[520/600] Train loss:0.0076
2023-02-06 14:56:13 | Stage | Epoch[520/600] Valid loss:0.1290
2023-02-06 14:56:13 | Stage | Epoch[520/600] LR:0.0001

2023-02-06 14:56:14 | Train | Epoch[521/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:56:14 | Train | Epoch[521/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:56:14 | Train | Epoch[521/600] Iteration[003/030] Train loss: 0.0086
2023-02-06 14:56:15 | Train | Epoch[521/600] Iteration[004/030] Train loss: 0.0084
2023-02-06 14:56:15 | Train | Epoch[521/600] Iteration[005/030] Train loss: 0.0084
2023-02-06 14:56:15 | Train | Epoch[521/600] Iteration[006/030] Train loss: 0.0083
2023-02-06 14:56:15 | Train | Epoch[521/600] Iteration[007/030] Train loss: 0.0082
2023-02-06 14:56:15 | Train | Epoch[521/600] Iteration[008/030] Train loss: 0.0082
2023-02-06 14:56:16 | Train | Epoch[521/600] Iteration[009/030] Train loss: 0.0082
2023-02-06 14:56:16 | Train | Epoch[521/600] Iteration[010/030] Train loss: 0.0081
2023-02-06 14:56:16 | Train | Epoch[521/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:56:16 | Train | Epoch[521/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:56:16 | Train | Epoch[521/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:56:17 | Train | Epoch[521/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:56:17 | Train | Epoch[521/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:56:17 | Train | Epoch[521/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:56:17 | Train | Epoch[521/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:56:18 | Train | Epoch[521/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:56:18 | Train | Epoch[521/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:56:18 | Train | Epoch[521/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:56:18 | Train | Epoch[521/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:56:18 | Train | Epoch[521/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:56:19 | Train | Epoch[521/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:56:19 | Train | Epoch[521/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:56:19 | Train | Epoch[521/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:56:19 | Train | Epoch[521/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:56:20 | Train | Epoch[521/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:56:20 | Train | Epoch[521/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:56:20 | Train | Epoch[521/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:56:20 | Train | Epoch[521/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:56:20 | Valid | Epoch[521/600] Iteration[001/008] Valid loss: 0.1762
2023-02-06 14:56:21 | Valid | Epoch[521/600] Iteration[002/008] Valid loss: 0.1392
2023-02-06 14:56:21 | Valid | Epoch[521/600] Iteration[003/008] Valid loss: 0.1316
2023-02-06 14:56:21 | Valid | Epoch[521/600] Iteration[004/008] Valid loss: 0.1244
2023-02-06 14:56:21 | Valid | Epoch[521/600] Iteration[005/008] Valid loss: 0.1228
2023-02-06 14:56:21 | Valid | Epoch[521/600] Iteration[006/008] Valid loss: 0.1184
2023-02-06 14:56:21 | Valid | Epoch[521/600] Iteration[007/008] Valid loss: 0.1262
2023-02-06 14:56:21 | Valid | Epoch[521/600] Iteration[008/008] Valid loss: 0.1246
2023-02-06 14:56:21 | Valid | Epoch[521/600] MIou: 0.9294043164682367
2023-02-06 14:56:21 | Valid | Epoch[521/600] Pixel Accuracy: 0.9878336588541666
2023-02-06 14:56:21 | Valid | Epoch[521/600] Mean Pixel Accuracy: 0.9565191038397508
2023-02-06 14:56:21 | Stage | Epoch[521/600] Train loss:0.0077
2023-02-06 14:56:21 | Stage | Epoch[521/600] Valid loss:0.1246
2023-02-06 14:56:21 | Stage | Epoch[521/600] LR:0.0001

2023-02-06 14:56:21 | Train | Epoch[522/600] Iteration[001/030] Train loss: 0.0067
2023-02-06 14:56:22 | Train | Epoch[522/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:56:22 | Train | Epoch[522/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:56:22 | Train | Epoch[522/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:56:22 | Train | Epoch[522/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:56:23 | Train | Epoch[522/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:56:23 | Train | Epoch[522/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:56:23 | Train | Epoch[522/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:56:23 | Train | Epoch[522/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:56:23 | Train | Epoch[522/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:56:24 | Train | Epoch[522/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:56:24 | Train | Epoch[522/600] Iteration[012/030] Train loss: 0.0081
2023-02-06 14:56:24 | Train | Epoch[522/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:56:24 | Train | Epoch[522/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:56:24 | Train | Epoch[522/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:56:25 | Train | Epoch[522/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:56:25 | Train | Epoch[522/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:56:25 | Train | Epoch[522/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:56:25 | Train | Epoch[522/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:56:26 | Train | Epoch[522/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:56:26 | Train | Epoch[522/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:56:26 | Train | Epoch[522/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:56:26 | Train | Epoch[522/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:56:26 | Train | Epoch[522/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:56:27 | Train | Epoch[522/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:56:27 | Train | Epoch[522/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:56:27 | Train | Epoch[522/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:56:27 | Train | Epoch[522/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:56:28 | Train | Epoch[522/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:56:28 | Train | Epoch[522/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:56:28 | Valid | Epoch[522/600] Iteration[001/008] Valid loss: 0.1739
2023-02-06 14:56:28 | Valid | Epoch[522/600] Iteration[002/008] Valid loss: 0.1379
2023-02-06 14:56:28 | Valid | Epoch[522/600] Iteration[003/008] Valid loss: 0.1302
2023-02-06 14:56:28 | Valid | Epoch[522/600] Iteration[004/008] Valid loss: 0.1233
2023-02-06 14:56:28 | Valid | Epoch[522/600] Iteration[005/008] Valid loss: 0.1215
2023-02-06 14:56:28 | Valid | Epoch[522/600] Iteration[006/008] Valid loss: 0.1172
2023-02-06 14:56:28 | Valid | Epoch[522/600] Iteration[007/008] Valid loss: 0.1249
2023-02-06 14:56:28 | Valid | Epoch[522/600] Iteration[008/008] Valid loss: 0.1233
2023-02-06 14:56:28 | Valid | Epoch[522/600] MIou: 0.9293445169164805
2023-02-06 14:56:28 | Valid | Epoch[522/600] Pixel Accuracy: 0.987823486328125
2023-02-06 14:56:28 | Valid | Epoch[522/600] Mean Pixel Accuracy: 0.9564564483419818
2023-02-06 14:56:28 | Stage | Epoch[522/600] Train loss:0.0076
2023-02-06 14:56:28 | Stage | Epoch[522/600] Valid loss:0.1233
2023-02-06 14:56:28 | Stage | Epoch[522/600] LR:0.0001

2023-02-06 14:56:29 | Train | Epoch[523/600] Iteration[001/030] Train loss: 0.0069
2023-02-06 14:56:29 | Train | Epoch[523/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 14:56:29 | Train | Epoch[523/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:56:30 | Train | Epoch[523/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:56:30 | Train | Epoch[523/600] Iteration[005/030] Train loss: 0.0074
2023-02-06 14:56:30 | Train | Epoch[523/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:56:30 | Train | Epoch[523/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 14:56:30 | Train | Epoch[523/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:56:31 | Train | Epoch[523/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:56:31 | Train | Epoch[523/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:56:31 | Train | Epoch[523/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:56:31 | Train | Epoch[523/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:56:32 | Train | Epoch[523/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:56:32 | Train | Epoch[523/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:56:32 | Train | Epoch[523/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:56:32 | Train | Epoch[523/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:56:32 | Train | Epoch[523/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:56:33 | Train | Epoch[523/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:56:33 | Train | Epoch[523/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:56:33 | Train | Epoch[523/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:56:33 | Train | Epoch[523/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:56:34 | Train | Epoch[523/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:56:34 | Train | Epoch[523/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:56:34 | Train | Epoch[523/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:56:34 | Train | Epoch[523/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:56:34 | Train | Epoch[523/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:56:35 | Train | Epoch[523/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:56:35 | Train | Epoch[523/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:56:35 | Train | Epoch[523/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:56:35 | Train | Epoch[523/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:56:36 | Valid | Epoch[523/600] Iteration[001/008] Valid loss: 0.1658
2023-02-06 14:56:36 | Valid | Epoch[523/600] Iteration[002/008] Valid loss: 0.1316
2023-02-06 14:56:36 | Valid | Epoch[523/600] Iteration[003/008] Valid loss: 0.1239
2023-02-06 14:56:36 | Valid | Epoch[523/600] Iteration[004/008] Valid loss: 0.1171
2023-02-06 14:56:36 | Valid | Epoch[523/600] Iteration[005/008] Valid loss: 0.1153
2023-02-06 14:56:36 | Valid | Epoch[523/600] Iteration[006/008] Valid loss: 0.1110
2023-02-06 14:56:36 | Valid | Epoch[523/600] Iteration[007/008] Valid loss: 0.1182
2023-02-06 14:56:36 | Valid | Epoch[523/600] Iteration[008/008] Valid loss: 0.1167
2023-02-06 14:56:36 | Valid | Epoch[523/600] MIou: 0.9291127814715809
2023-02-06 14:56:36 | Valid | Epoch[523/600] Pixel Accuracy: 0.9878145853678385
2023-02-06 14:56:36 | Valid | Epoch[523/600] Mean Pixel Accuracy: 0.9550629927334462
2023-02-06 14:56:36 | Stage | Epoch[523/600] Train loss:0.0077
2023-02-06 14:56:36 | Stage | Epoch[523/600] Valid loss:0.1167
2023-02-06 14:56:36 | Stage | Epoch[523/600] LR:0.0001

2023-02-06 14:56:36 | Train | Epoch[524/600] Iteration[001/030] Train loss: 0.0086
2023-02-06 14:56:37 | Train | Epoch[524/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:56:37 | Train | Epoch[524/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:56:37 | Train | Epoch[524/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:56:37 | Train | Epoch[524/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 14:56:38 | Train | Epoch[524/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:56:38 | Train | Epoch[524/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:56:38 | Train | Epoch[524/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:56:38 | Train | Epoch[524/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:56:38 | Train | Epoch[524/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:56:39 | Train | Epoch[524/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:56:39 | Train | Epoch[524/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:56:39 | Train | Epoch[524/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:56:39 | Train | Epoch[524/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:56:40 | Train | Epoch[524/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:56:40 | Train | Epoch[524/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:56:40 | Train | Epoch[524/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:56:40 | Train | Epoch[524/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:56:40 | Train | Epoch[524/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:56:41 | Train | Epoch[524/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:56:41 | Train | Epoch[524/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:56:41 | Train | Epoch[524/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:56:41 | Train | Epoch[524/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:56:41 | Train | Epoch[524/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:56:42 | Train | Epoch[524/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:56:42 | Train | Epoch[524/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:56:42 | Train | Epoch[524/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:56:42 | Train | Epoch[524/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:56:43 | Train | Epoch[524/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:56:43 | Train | Epoch[524/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:56:43 | Valid | Epoch[524/600] Iteration[001/008] Valid loss: 0.1721
2023-02-06 14:56:43 | Valid | Epoch[524/600] Iteration[002/008] Valid loss: 0.1365
2023-02-06 14:56:43 | Valid | Epoch[524/600] Iteration[003/008] Valid loss: 0.1292
2023-02-06 14:56:43 | Valid | Epoch[524/600] Iteration[004/008] Valid loss: 0.1226
2023-02-06 14:56:43 | Valid | Epoch[524/600] Iteration[005/008] Valid loss: 0.1209
2023-02-06 14:56:43 | Valid | Epoch[524/600] Iteration[006/008] Valid loss: 0.1165
2023-02-06 14:56:43 | Valid | Epoch[524/600] Iteration[007/008] Valid loss: 0.1243
2023-02-06 14:56:43 | Valid | Epoch[524/600] Iteration[008/008] Valid loss: 0.1226
2023-02-06 14:56:43 | Valid | Epoch[524/600] MIou: 0.9294838224387586
2023-02-06 14:56:43 | Valid | Epoch[524/600] Pixel Accuracy: 0.9878514607747396
2023-02-06 14:56:43 | Valid | Epoch[524/600] Mean Pixel Accuracy: 0.956440121933362
2023-02-06 14:56:43 | Stage | Epoch[524/600] Train loss:0.0075
2023-02-06 14:56:43 | Stage | Epoch[524/600] Valid loss:0.1226
2023-02-06 14:56:43 | Stage | Epoch[524/600] LR:0.0001

2023-02-06 14:56:44 | Train | Epoch[525/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 14:56:44 | Train | Epoch[525/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:56:44 | Train | Epoch[525/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:56:45 | Train | Epoch[525/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:56:45 | Train | Epoch[525/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:56:45 | Train | Epoch[525/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:56:45 | Train | Epoch[525/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:56:45 | Train | Epoch[525/600] Iteration[008/030] Train loss: 0.0082
2023-02-06 14:56:46 | Train | Epoch[525/600] Iteration[009/030] Train loss: 0.0081
2023-02-06 14:56:46 | Train | Epoch[525/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:56:46 | Train | Epoch[525/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:56:46 | Train | Epoch[525/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:56:47 | Train | Epoch[525/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:56:47 | Train | Epoch[525/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:56:47 | Train | Epoch[525/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:56:47 | Train | Epoch[525/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:56:47 | Train | Epoch[525/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:56:48 | Train | Epoch[525/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:56:48 | Train | Epoch[525/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:56:48 | Train | Epoch[525/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:56:48 | Train | Epoch[525/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:56:49 | Train | Epoch[525/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:56:49 | Train | Epoch[525/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:56:49 | Train | Epoch[525/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:56:49 | Train | Epoch[525/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:56:49 | Train | Epoch[525/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:56:50 | Train | Epoch[525/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:56:50 | Train | Epoch[525/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:56:50 | Train | Epoch[525/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:56:50 | Train | Epoch[525/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:56:51 | Valid | Epoch[525/600] Iteration[001/008] Valid loss: 0.1907
2023-02-06 14:56:51 | Valid | Epoch[525/600] Iteration[002/008] Valid loss: 0.1505
2023-02-06 14:56:51 | Valid | Epoch[525/600] Iteration[003/008] Valid loss: 0.1427
2023-02-06 14:56:51 | Valid | Epoch[525/600] Iteration[004/008] Valid loss: 0.1349
2023-02-06 14:56:51 | Valid | Epoch[525/600] Iteration[005/008] Valid loss: 0.1333
2023-02-06 14:56:51 | Valid | Epoch[525/600] Iteration[006/008] Valid loss: 0.1289
2023-02-06 14:56:51 | Valid | Epoch[525/600] Iteration[007/008] Valid loss: 0.1380
2023-02-06 14:56:51 | Valid | Epoch[525/600] Iteration[008/008] Valid loss: 0.1363
2023-02-06 14:56:51 | Valid | Epoch[525/600] MIou: 0.9300469194604631
2023-02-06 14:56:51 | Valid | Epoch[525/600] Pixel Accuracy: 0.9878959655761719
2023-02-06 14:56:51 | Valid | Epoch[525/600] Mean Pixel Accuracy: 0.958994431803633
2023-02-06 14:56:51 | Stage | Epoch[525/600] Train loss:0.0077
2023-02-06 14:56:51 | Stage | Epoch[525/600] Valid loss:0.1363
2023-02-06 14:56:51 | Stage | Epoch[525/600] LR:0.0001

2023-02-06 14:56:51 | Train | Epoch[526/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:56:52 | Train | Epoch[526/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:56:52 | Train | Epoch[526/600] Iteration[003/030] Train loss: 0.0069
2023-02-06 14:56:52 | Train | Epoch[526/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 14:56:52 | Train | Epoch[526/600] Iteration[005/030] Train loss: 0.0070
2023-02-06 14:56:53 | Train | Epoch[526/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 14:56:53 | Train | Epoch[526/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:56:53 | Train | Epoch[526/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:56:53 | Train | Epoch[526/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 14:56:53 | Train | Epoch[526/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 14:56:54 | Train | Epoch[526/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 14:56:54 | Train | Epoch[526/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 14:56:54 | Train | Epoch[526/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:56:54 | Train | Epoch[526/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:56:54 | Train | Epoch[526/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 14:56:55 | Train | Epoch[526/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:56:55 | Train | Epoch[526/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 14:56:55 | Train | Epoch[526/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 14:56:55 | Train | Epoch[526/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 14:56:56 | Train | Epoch[526/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 14:56:56 | Train | Epoch[526/600] Iteration[021/030] Train loss: 0.0073
2023-02-06 14:56:56 | Train | Epoch[526/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 14:56:56 | Train | Epoch[526/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 14:56:56 | Train | Epoch[526/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 14:56:57 | Train | Epoch[526/600] Iteration[025/030] Train loss: 0.0073
2023-02-06 14:56:57 | Train | Epoch[526/600] Iteration[026/030] Train loss: 0.0073
2023-02-06 14:56:57 | Train | Epoch[526/600] Iteration[027/030] Train loss: 0.0073
2023-02-06 14:56:57 | Train | Epoch[526/600] Iteration[028/030] Train loss: 0.0073
2023-02-06 14:56:58 | Train | Epoch[526/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 14:56:58 | Train | Epoch[526/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:56:58 | Valid | Epoch[526/600] Iteration[001/008] Valid loss: 0.1853
2023-02-06 14:56:58 | Valid | Epoch[526/600] Iteration[002/008] Valid loss: 0.1464
2023-02-06 14:56:58 | Valid | Epoch[526/600] Iteration[003/008] Valid loss: 0.1383
2023-02-06 14:56:58 | Valid | Epoch[526/600] Iteration[004/008] Valid loss: 0.1308
2023-02-06 14:56:58 | Valid | Epoch[526/600] Iteration[005/008] Valid loss: 0.1292
2023-02-06 14:56:58 | Valid | Epoch[526/600] Iteration[006/008] Valid loss: 0.1249
2023-02-06 14:56:58 | Valid | Epoch[526/600] Iteration[007/008] Valid loss: 0.1335
2023-02-06 14:56:58 | Valid | Epoch[526/600] Iteration[008/008] Valid loss: 0.1318
2023-02-06 14:56:58 | Valid | Epoch[526/600] MIou: 0.9299309520374912
2023-02-06 14:56:58 | Valid | Epoch[526/600] Pixel Accuracy: 0.9878946940104166
2023-02-06 14:56:58 | Valid | Epoch[526/600] Mean Pixel Accuracy: 0.9581631311287806
2023-02-06 14:56:58 | Stage | Epoch[526/600] Train loss:0.0075
2023-02-06 14:56:58 | Stage | Epoch[526/600] Valid loss:0.1318
2023-02-06 14:56:58 | Stage | Epoch[526/600] LR:0.0001

2023-02-06 14:56:59 | Train | Epoch[527/600] Iteration[001/030] Train loss: 0.0069
2023-02-06 14:56:59 | Train | Epoch[527/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:56:59 | Train | Epoch[527/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:57:00 | Train | Epoch[527/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:57:00 | Train | Epoch[527/600] Iteration[005/030] Train loss: 0.0083
2023-02-06 14:57:00 | Train | Epoch[527/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 14:57:00 | Train | Epoch[527/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 14:57:01 | Train | Epoch[527/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:57:01 | Train | Epoch[527/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:57:01 | Train | Epoch[527/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:57:01 | Train | Epoch[527/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:57:01 | Train | Epoch[527/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:57:02 | Train | Epoch[527/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:57:02 | Train | Epoch[527/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:57:02 | Train | Epoch[527/600] Iteration[015/030] Train loss: 0.0079
2023-02-06 14:57:02 | Train | Epoch[527/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:57:02 | Train | Epoch[527/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:57:03 | Train | Epoch[527/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:57:03 | Train | Epoch[527/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:57:03 | Train | Epoch[527/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:57:03 | Train | Epoch[527/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:57:04 | Train | Epoch[527/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:57:04 | Train | Epoch[527/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:57:04 | Train | Epoch[527/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:57:04 | Train | Epoch[527/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:57:04 | Train | Epoch[527/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:57:05 | Train | Epoch[527/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:57:05 | Train | Epoch[527/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:57:05 | Train | Epoch[527/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:57:05 | Train | Epoch[527/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:57:06 | Valid | Epoch[527/600] Iteration[001/008] Valid loss: 0.1758
2023-02-06 14:57:06 | Valid | Epoch[527/600] Iteration[002/008] Valid loss: 0.1396
2023-02-06 14:57:06 | Valid | Epoch[527/600] Iteration[003/008] Valid loss: 0.1317
2023-02-06 14:57:06 | Valid | Epoch[527/600] Iteration[004/008] Valid loss: 0.1246
2023-02-06 14:57:06 | Valid | Epoch[527/600] Iteration[005/008] Valid loss: 0.1230
2023-02-06 14:57:06 | Valid | Epoch[527/600] Iteration[006/008] Valid loss: 0.1185
2023-02-06 14:57:06 | Valid | Epoch[527/600] Iteration[007/008] Valid loss: 0.1263
2023-02-06 14:57:06 | Valid | Epoch[527/600] Iteration[008/008] Valid loss: 0.1247
2023-02-06 14:57:06 | Valid | Epoch[527/600] MIou: 0.9296950918764049
2023-02-06 14:57:06 | Valid | Epoch[527/600] Pixel Accuracy: 0.987878163655599
2023-02-06 14:57:06 | Valid | Epoch[527/600] Mean Pixel Accuracy: 0.9570127604685958
2023-02-06 14:57:06 | Stage | Epoch[527/600] Train loss:0.0078
2023-02-06 14:57:06 | Stage | Epoch[527/600] Valid loss:0.1247
2023-02-06 14:57:06 | Stage | Epoch[527/600] LR:0.0001

2023-02-06 14:57:06 | Train | Epoch[528/600] Iteration[001/030] Train loss: 0.0081
2023-02-06 14:57:07 | Train | Epoch[528/600] Iteration[002/030] Train loss: 0.0083
2023-02-06 14:57:07 | Train | Epoch[528/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:57:07 | Train | Epoch[528/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:57:07 | Train | Epoch[528/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:57:08 | Train | Epoch[528/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:57:08 | Train | Epoch[528/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:57:08 | Train | Epoch[528/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:57:08 | Train | Epoch[528/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:57:08 | Train | Epoch[528/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:57:09 | Train | Epoch[528/600] Iteration[011/030] Train loss: 0.0080
2023-02-06 14:57:09 | Train | Epoch[528/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:57:09 | Train | Epoch[528/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:57:09 | Train | Epoch[528/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:57:09 | Train | Epoch[528/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:57:10 | Train | Epoch[528/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:57:10 | Train | Epoch[528/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:57:10 | Train | Epoch[528/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:57:10 | Train | Epoch[528/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:57:11 | Train | Epoch[528/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:57:11 | Train | Epoch[528/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:57:11 | Train | Epoch[528/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 14:57:11 | Train | Epoch[528/600] Iteration[023/030] Train loss: 0.0079
2023-02-06 14:57:11 | Train | Epoch[528/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:57:12 | Train | Epoch[528/600] Iteration[025/030] Train loss: 0.0079
2023-02-06 14:57:12 | Train | Epoch[528/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:57:12 | Train | Epoch[528/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:57:12 | Train | Epoch[528/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:57:13 | Train | Epoch[528/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:57:13 | Train | Epoch[528/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:57:13 | Valid | Epoch[528/600] Iteration[001/008] Valid loss: 0.1773
2023-02-06 14:57:13 | Valid | Epoch[528/600] Iteration[002/008] Valid loss: 0.1411
2023-02-06 14:57:13 | Valid | Epoch[528/600] Iteration[003/008] Valid loss: 0.1336
2023-02-06 14:57:13 | Valid | Epoch[528/600] Iteration[004/008] Valid loss: 0.1267
2023-02-06 14:57:13 | Valid | Epoch[528/600] Iteration[005/008] Valid loss: 0.1251
2023-02-06 14:57:13 | Valid | Epoch[528/600] Iteration[006/008] Valid loss: 0.1207
2023-02-06 14:57:13 | Valid | Epoch[528/600] Iteration[007/008] Valid loss: 0.1289
2023-02-06 14:57:13 | Valid | Epoch[528/600] Iteration[008/008] Valid loss: 0.1271
2023-02-06 14:57:13 | Valid | Epoch[528/600] MIou: 0.9302496535310326
2023-02-06 14:57:13 | Valid | Epoch[528/600] Pixel Accuracy: 0.987969716389974
2023-02-06 14:57:13 | Valid | Epoch[528/600] Mean Pixel Accuracy: 0.957703469378758
2023-02-06 14:57:13 | Stage | Epoch[528/600] Train loss:0.0078
2023-02-06 14:57:13 | Stage | Epoch[528/600] Valid loss:0.1271
2023-02-06 14:57:13 | Stage | Epoch[528/600] LR:0.0001

2023-02-06 14:57:14 | Train | Epoch[529/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 14:57:14 | Train | Epoch[529/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:57:14 | Train | Epoch[529/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:57:14 | Train | Epoch[529/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:57:15 | Train | Epoch[529/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:57:15 | Train | Epoch[529/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 14:57:15 | Train | Epoch[529/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:57:15 | Train | Epoch[529/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:57:16 | Train | Epoch[529/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:57:16 | Train | Epoch[529/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:57:16 | Train | Epoch[529/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 14:57:16 | Train | Epoch[529/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:57:16 | Train | Epoch[529/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 14:57:17 | Train | Epoch[529/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:57:17 | Train | Epoch[529/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:57:17 | Train | Epoch[529/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:57:17 | Train | Epoch[529/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:57:18 | Train | Epoch[529/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:57:18 | Train | Epoch[529/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:57:18 | Train | Epoch[529/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:57:18 | Train | Epoch[529/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:57:18 | Train | Epoch[529/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:57:19 | Train | Epoch[529/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:57:19 | Train | Epoch[529/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:57:19 | Train | Epoch[529/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:57:19 | Train | Epoch[529/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:57:20 | Train | Epoch[529/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:57:20 | Train | Epoch[529/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:57:20 | Train | Epoch[529/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:57:20 | Train | Epoch[529/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:57:20 | Valid | Epoch[529/600] Iteration[001/008] Valid loss: 0.1728
2023-02-06 14:57:20 | Valid | Epoch[529/600] Iteration[002/008] Valid loss: 0.1374
2023-02-06 14:57:20 | Valid | Epoch[529/600] Iteration[003/008] Valid loss: 0.1294
2023-02-06 14:57:21 | Valid | Epoch[529/600] Iteration[004/008] Valid loss: 0.1227
2023-02-06 14:57:21 | Valid | Epoch[529/600] Iteration[005/008] Valid loss: 0.1212
2023-02-06 14:57:21 | Valid | Epoch[529/600] Iteration[006/008] Valid loss: 0.1167
2023-02-06 14:57:21 | Valid | Epoch[529/600] Iteration[007/008] Valid loss: 0.1244
2023-02-06 14:57:21 | Valid | Epoch[529/600] Iteration[008/008] Valid loss: 0.1227
2023-02-06 14:57:21 | Valid | Epoch[529/600] MIou: 0.9296129134467972
2023-02-06 14:57:21 | Valid | Epoch[529/600] Pixel Accuracy: 0.9878756205240885
2023-02-06 14:57:21 | Valid | Epoch[529/600] Mean Pixel Accuracy: 0.9564914439910652
2023-02-06 14:57:21 | Stage | Epoch[529/600] Train loss:0.0076
2023-02-06 14:57:21 | Stage | Epoch[529/600] Valid loss:0.1227
2023-02-06 14:57:21 | Stage | Epoch[529/600] LR:0.0001

2023-02-06 14:57:21 | Train | Epoch[530/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 14:57:21 | Train | Epoch[530/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:57:22 | Train | Epoch[530/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:57:22 | Train | Epoch[530/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:57:22 | Train | Epoch[530/600] Iteration[005/030] Train loss: 0.0074
2023-02-06 14:57:22 | Train | Epoch[530/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:57:23 | Train | Epoch[530/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:57:23 | Train | Epoch[530/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:57:23 | Train | Epoch[530/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:57:23 | Train | Epoch[530/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:57:23 | Train | Epoch[530/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:57:24 | Train | Epoch[530/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:57:24 | Train | Epoch[530/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:57:24 | Train | Epoch[530/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:57:24 | Train | Epoch[530/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:57:25 | Train | Epoch[530/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:57:25 | Train | Epoch[530/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:57:25 | Train | Epoch[530/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:57:25 | Train | Epoch[530/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:57:25 | Train | Epoch[530/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:57:26 | Train | Epoch[530/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:57:26 | Train | Epoch[530/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:57:26 | Train | Epoch[530/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:57:26 | Train | Epoch[530/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:57:27 | Train | Epoch[530/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:57:27 | Train | Epoch[530/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:57:27 | Train | Epoch[530/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:57:27 | Train | Epoch[530/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:57:27 | Train | Epoch[530/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:57:27 | Train | Epoch[530/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:57:28 | Valid | Epoch[530/600] Iteration[001/008] Valid loss: 0.1852
2023-02-06 14:57:28 | Valid | Epoch[530/600] Iteration[002/008] Valid loss: 0.1475
2023-02-06 14:57:28 | Valid | Epoch[530/600] Iteration[003/008] Valid loss: 0.1391
2023-02-06 14:57:28 | Valid | Epoch[530/600] Iteration[004/008] Valid loss: 0.1321
2023-02-06 14:57:28 | Valid | Epoch[530/600] Iteration[005/008] Valid loss: 0.1306
2023-02-06 14:57:28 | Valid | Epoch[530/600] Iteration[006/008] Valid loss: 0.1261
2023-02-06 14:57:28 | Valid | Epoch[530/600] Iteration[007/008] Valid loss: 0.1347
2023-02-06 14:57:28 | Valid | Epoch[530/600] Iteration[008/008] Valid loss: 0.1330
2023-02-06 14:57:28 | Valid | Epoch[530/600] MIou: 0.9303054633817447
2023-02-06 14:57:28 | Valid | Epoch[530/600] Pixel Accuracy: 0.9879480997721354
2023-02-06 14:57:28 | Valid | Epoch[530/600] Mean Pixel Accuracy: 0.9589596822660835
2023-02-06 14:57:28 | Stage | Epoch[530/600] Train loss:0.0077
2023-02-06 14:57:28 | Stage | Epoch[530/600] Valid loss:0.1330
2023-02-06 14:57:28 | Stage | Epoch[530/600] LR:0.0001

2023-02-06 14:57:29 | Train | Epoch[531/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:57:29 | Train | Epoch[531/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 14:57:29 | Train | Epoch[531/600] Iteration[003/030] Train loss: 0.0083
2023-02-06 14:57:29 | Train | Epoch[531/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:57:30 | Train | Epoch[531/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 14:57:30 | Train | Epoch[531/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:57:30 | Train | Epoch[531/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:57:30 | Train | Epoch[531/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:57:30 | Train | Epoch[531/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:57:31 | Train | Epoch[531/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:57:31 | Train | Epoch[531/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:57:31 | Train | Epoch[531/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:57:31 | Train | Epoch[531/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:57:32 | Train | Epoch[531/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:57:32 | Train | Epoch[531/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:57:32 | Train | Epoch[531/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:57:32 | Train | Epoch[531/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:57:32 | Train | Epoch[531/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:57:33 | Train | Epoch[531/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:57:33 | Train | Epoch[531/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:57:33 | Train | Epoch[531/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:57:33 | Train | Epoch[531/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:57:34 | Train | Epoch[531/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:57:34 | Train | Epoch[531/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:57:34 | Train | Epoch[531/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:57:34 | Train | Epoch[531/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:57:34 | Train | Epoch[531/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:57:35 | Train | Epoch[531/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:57:35 | Train | Epoch[531/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:57:35 | Train | Epoch[531/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:57:35 | Valid | Epoch[531/600] Iteration[001/008] Valid loss: 0.1727
2023-02-06 14:57:35 | Valid | Epoch[531/600] Iteration[002/008] Valid loss: 0.1369
2023-02-06 14:57:35 | Valid | Epoch[531/600] Iteration[003/008] Valid loss: 0.1294
2023-02-06 14:57:35 | Valid | Epoch[531/600] Iteration[004/008] Valid loss: 0.1225
2023-02-06 14:57:36 | Valid | Epoch[531/600] Iteration[005/008] Valid loss: 0.1206
2023-02-06 14:57:36 | Valid | Epoch[531/600] Iteration[006/008] Valid loss: 0.1164
2023-02-06 14:57:36 | Valid | Epoch[531/600] Iteration[007/008] Valid loss: 0.1239
2023-02-06 14:57:36 | Valid | Epoch[531/600] Iteration[008/008] Valid loss: 0.1222
2023-02-06 14:57:36 | Valid | Epoch[531/600] MIou: 0.9296065010322276
2023-02-06 14:57:36 | Valid | Epoch[531/600] Pixel Accuracy: 0.9878832499186198
2023-02-06 14:57:36 | Valid | Epoch[531/600] Mean Pixel Accuracy: 0.9561532519700331
2023-02-06 14:57:36 | Stage | Epoch[531/600] Train loss:0.0076
2023-02-06 14:57:36 | Stage | Epoch[531/600] Valid loss:0.1222
2023-02-06 14:57:36 | Stage | Epoch[531/600] LR:0.0001

2023-02-06 14:57:36 | Train | Epoch[532/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:57:36 | Train | Epoch[532/600] Iteration[002/030] Train loss: 0.0070
2023-02-06 14:57:37 | Train | Epoch[532/600] Iteration[003/030] Train loss: 0.0070
2023-02-06 14:57:37 | Train | Epoch[532/600] Iteration[004/030] Train loss: 0.0071
2023-02-06 14:57:37 | Train | Epoch[532/600] Iteration[005/030] Train loss: 0.0071
2023-02-06 14:57:37 | Train | Epoch[532/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 14:57:38 | Train | Epoch[532/600] Iteration[007/030] Train loss: 0.0072
2023-02-06 14:57:38 | Train | Epoch[532/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:57:38 | Train | Epoch[532/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 14:57:38 | Train | Epoch[532/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:57:38 | Train | Epoch[532/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:57:39 | Train | Epoch[532/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:57:39 | Train | Epoch[532/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:57:39 | Train | Epoch[532/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:57:39 | Train | Epoch[532/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:57:39 | Train | Epoch[532/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:57:40 | Train | Epoch[532/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:57:40 | Train | Epoch[532/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:57:40 | Train | Epoch[532/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:57:40 | Train | Epoch[532/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:57:41 | Train | Epoch[532/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:57:41 | Train | Epoch[532/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:57:41 | Train | Epoch[532/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:57:41 | Train | Epoch[532/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:57:41 | Train | Epoch[532/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:57:42 | Train | Epoch[532/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:57:42 | Train | Epoch[532/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 14:57:42 | Train | Epoch[532/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:57:42 | Train | Epoch[532/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 14:57:42 | Train | Epoch[532/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:57:43 | Valid | Epoch[532/600] Iteration[001/008] Valid loss: 0.1777
2023-02-06 14:57:43 | Valid | Epoch[532/600] Iteration[002/008] Valid loss: 0.1406
2023-02-06 14:57:43 | Valid | Epoch[532/600] Iteration[003/008] Valid loss: 0.1328
2023-02-06 14:57:43 | Valid | Epoch[532/600] Iteration[004/008] Valid loss: 0.1257
2023-02-06 14:57:43 | Valid | Epoch[532/600] Iteration[005/008] Valid loss: 0.1239
2023-02-06 14:57:43 | Valid | Epoch[532/600] Iteration[006/008] Valid loss: 0.1195
2023-02-06 14:57:43 | Valid | Epoch[532/600] Iteration[007/008] Valid loss: 0.1274
2023-02-06 14:57:43 | Valid | Epoch[532/600] Iteration[008/008] Valid loss: 0.1257
2023-02-06 14:57:43 | Valid | Epoch[532/600] MIou: 0.9298758764491144
2023-02-06 14:57:43 | Valid | Epoch[532/600] Pixel Accuracy: 0.9879099527994791
2023-02-06 14:57:43 | Valid | Epoch[532/600] Mean Pixel Accuracy: 0.9571633830396002
2023-02-06 14:57:43 | Stage | Epoch[532/600] Train loss:0.0077
2023-02-06 14:57:43 | Stage | Epoch[532/600] Valid loss:0.1257
2023-02-06 14:57:43 | Stage | Epoch[532/600] LR:0.0001

2023-02-06 14:57:44 | Train | Epoch[533/600] Iteration[001/030] Train loss: 0.0066
2023-02-06 14:57:44 | Train | Epoch[533/600] Iteration[002/030] Train loss: 0.0069
2023-02-06 14:57:44 | Train | Epoch[533/600] Iteration[003/030] Train loss: 0.0071
2023-02-06 14:57:44 | Train | Epoch[533/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 14:57:45 | Train | Epoch[533/600] Iteration[005/030] Train loss: 0.0074
2023-02-06 14:57:45 | Train | Epoch[533/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 14:57:45 | Train | Epoch[533/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 14:57:45 | Train | Epoch[533/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:57:45 | Train | Epoch[533/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:57:46 | Train | Epoch[533/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:57:46 | Train | Epoch[533/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 14:57:46 | Train | Epoch[533/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 14:57:46 | Train | Epoch[533/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 14:57:47 | Train | Epoch[533/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:57:47 | Train | Epoch[533/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:57:47 | Train | Epoch[533/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:57:47 | Train | Epoch[533/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:57:47 | Train | Epoch[533/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:57:48 | Train | Epoch[533/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:57:48 | Train | Epoch[533/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:57:48 | Train | Epoch[533/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:57:48 | Train | Epoch[533/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:57:48 | Train | Epoch[533/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:57:49 | Train | Epoch[533/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:57:49 | Train | Epoch[533/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:57:49 | Train | Epoch[533/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:57:49 | Train | Epoch[533/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:57:50 | Train | Epoch[533/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:57:50 | Train | Epoch[533/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:57:50 | Train | Epoch[533/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:57:50 | Valid | Epoch[533/600] Iteration[001/008] Valid loss: 0.1799
2023-02-06 14:57:50 | Valid | Epoch[533/600] Iteration[002/008] Valid loss: 0.1427
2023-02-06 14:57:50 | Valid | Epoch[533/600] Iteration[003/008] Valid loss: 0.1347
2023-02-06 14:57:50 | Valid | Epoch[533/600] Iteration[004/008] Valid loss: 0.1276
2023-02-06 14:57:50 | Valid | Epoch[533/600] Iteration[005/008] Valid loss: 0.1258
2023-02-06 14:57:50 | Valid | Epoch[533/600] Iteration[006/008] Valid loss: 0.1216
2023-02-06 14:57:51 | Valid | Epoch[533/600] Iteration[007/008] Valid loss: 0.1300
2023-02-06 14:57:51 | Valid | Epoch[533/600] Iteration[008/008] Valid loss: 0.1285
2023-02-06 14:57:51 | Valid | Epoch[533/600] MIou: 0.929437149069803
2023-02-06 14:57:51 | Valid | Epoch[533/600] Pixel Accuracy: 0.9878209431966146
2023-02-06 14:57:51 | Valid | Epoch[533/600] Mean Pixel Accuracy: 0.9572476094674518
2023-02-06 14:57:51 | Stage | Epoch[533/600] Train loss:0.0076
2023-02-06 14:57:51 | Stage | Epoch[533/600] Valid loss:0.1285
2023-02-06 14:57:51 | Stage | Epoch[533/600] LR:0.0001

2023-02-06 14:57:51 | Train | Epoch[534/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:57:51 | Train | Epoch[534/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 14:57:52 | Train | Epoch[534/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:57:52 | Train | Epoch[534/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 14:57:52 | Train | Epoch[534/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:57:52 | Train | Epoch[534/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:57:52 | Train | Epoch[534/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:57:53 | Train | Epoch[534/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 14:57:53 | Train | Epoch[534/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 14:57:53 | Train | Epoch[534/600] Iteration[010/030] Train loss: 0.0072
2023-02-06 14:57:53 | Train | Epoch[534/600] Iteration[011/030] Train loss: 0.0072
2023-02-06 14:57:54 | Train | Epoch[534/600] Iteration[012/030] Train loss: 0.0072
2023-02-06 14:57:54 | Train | Epoch[534/600] Iteration[013/030] Train loss: 0.0073
2023-02-06 14:57:54 | Train | Epoch[534/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:57:54 | Train | Epoch[534/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 14:57:54 | Train | Epoch[534/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 14:57:55 | Train | Epoch[534/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 14:57:55 | Train | Epoch[534/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:57:55 | Train | Epoch[534/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:57:55 | Train | Epoch[534/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:57:56 | Train | Epoch[534/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:57:56 | Train | Epoch[534/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:57:56 | Train | Epoch[534/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:57:56 | Train | Epoch[534/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:57:56 | Train | Epoch[534/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:57:57 | Train | Epoch[534/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:57:57 | Train | Epoch[534/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:57:57 | Train | Epoch[534/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:57:57 | Train | Epoch[534/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:57:57 | Train | Epoch[534/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:57:58 | Valid | Epoch[534/600] Iteration[001/008] Valid loss: 0.1773
2023-02-06 14:57:58 | Valid | Epoch[534/600] Iteration[002/008] Valid loss: 0.1406
2023-02-06 14:57:58 | Valid | Epoch[534/600] Iteration[003/008] Valid loss: 0.1331
2023-02-06 14:57:58 | Valid | Epoch[534/600] Iteration[004/008] Valid loss: 0.1263
2023-02-06 14:57:58 | Valid | Epoch[534/600] Iteration[005/008] Valid loss: 0.1244
2023-02-06 14:57:58 | Valid | Epoch[534/600] Iteration[006/008] Valid loss: 0.1200
2023-02-06 14:57:58 | Valid | Epoch[534/600] Iteration[007/008] Valid loss: 0.1281
2023-02-06 14:57:58 | Valid | Epoch[534/600] Iteration[008/008] Valid loss: 0.1265
2023-02-06 14:57:58 | Valid | Epoch[534/600] MIou: 0.930273500569368
2023-02-06 14:57:58 | Valid | Epoch[534/600] Pixel Accuracy: 0.9879798889160156
2023-02-06 14:57:58 | Valid | Epoch[534/600] Mean Pixel Accuracy: 0.9574934846015075
2023-02-06 14:57:58 | Stage | Epoch[534/600] Train loss:0.0076
2023-02-06 14:57:58 | Stage | Epoch[534/600] Valid loss:0.1265
2023-02-06 14:57:58 | Stage | Epoch[534/600] LR:0.0001

2023-02-06 14:57:59 | Train | Epoch[535/600] Iteration[001/030] Train loss: 0.0081
2023-02-06 14:57:59 | Train | Epoch[535/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:57:59 | Train | Epoch[535/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 14:57:59 | Train | Epoch[535/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 14:57:59 | Train | Epoch[535/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:58:00 | Train | Epoch[535/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 14:58:00 | Train | Epoch[535/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 14:58:00 | Train | Epoch[535/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:58:00 | Train | Epoch[535/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:58:01 | Train | Epoch[535/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 14:58:01 | Train | Epoch[535/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:58:01 | Train | Epoch[535/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:58:01 | Train | Epoch[535/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:58:01 | Train | Epoch[535/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:58:02 | Train | Epoch[535/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:58:02 | Train | Epoch[535/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:58:02 | Train | Epoch[535/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:58:02 | Train | Epoch[535/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:58:03 | Train | Epoch[535/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:58:03 | Train | Epoch[535/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:58:03 | Train | Epoch[535/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:58:03 | Train | Epoch[535/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:58:03 | Train | Epoch[535/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:58:04 | Train | Epoch[535/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:58:04 | Train | Epoch[535/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:58:04 | Train | Epoch[535/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:58:04 | Train | Epoch[535/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 14:58:04 | Train | Epoch[535/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:58:05 | Train | Epoch[535/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:58:05 | Train | Epoch[535/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:58:05 | Valid | Epoch[535/600] Iteration[001/008] Valid loss: 0.1736
2023-02-06 14:58:05 | Valid | Epoch[535/600] Iteration[002/008] Valid loss: 0.1377
2023-02-06 14:58:05 | Valid | Epoch[535/600] Iteration[003/008] Valid loss: 0.1301
2023-02-06 14:58:05 | Valid | Epoch[535/600] Iteration[004/008] Valid loss: 0.1232
2023-02-06 14:58:05 | Valid | Epoch[535/600] Iteration[005/008] Valid loss: 0.1214
2023-02-06 14:58:05 | Valid | Epoch[535/600] Iteration[006/008] Valid loss: 0.1171
2023-02-06 14:58:05 | Valid | Epoch[535/600] Iteration[007/008] Valid loss: 0.1249
2023-02-06 14:58:05 | Valid | Epoch[535/600] Iteration[008/008] Valid loss: 0.1232
2023-02-06 14:58:06 | Valid | Epoch[535/600] MIou: 0.9295235948535643
2023-02-06 14:58:06 | Valid | Epoch[535/600] Pixel Accuracy: 0.987860361735026
2023-02-06 14:58:06 | Valid | Epoch[535/600] Mean Pixel Accuracy: 0.9564006309801678
2023-02-06 14:58:06 | Stage | Epoch[535/600] Train loss:0.0076
2023-02-06 14:58:06 | Stage | Epoch[535/600] Valid loss:0.1232
2023-02-06 14:58:06 | Stage | Epoch[535/600] LR:0.0001

2023-02-06 14:58:06 | Train | Epoch[536/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:58:06 | Train | Epoch[536/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 14:58:06 | Train | Epoch[536/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:58:07 | Train | Epoch[536/600] Iteration[004/030] Train loss: 0.0076
2023-02-06 14:58:07 | Train | Epoch[536/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 14:58:07 | Train | Epoch[536/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:58:07 | Train | Epoch[536/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 14:58:08 | Train | Epoch[536/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:58:08 | Train | Epoch[536/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 14:58:08 | Train | Epoch[536/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:58:08 | Train | Epoch[536/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:58:08 | Train | Epoch[536/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:58:09 | Train | Epoch[536/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:58:09 | Train | Epoch[536/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:58:09 | Train | Epoch[536/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:58:09 | Train | Epoch[536/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:58:10 | Train | Epoch[536/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:58:10 | Train | Epoch[536/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:58:10 | Train | Epoch[536/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:58:10 | Train | Epoch[536/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:58:10 | Train | Epoch[536/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:58:11 | Train | Epoch[536/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:58:11 | Train | Epoch[536/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:58:11 | Train | Epoch[536/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:58:11 | Train | Epoch[536/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:58:11 | Train | Epoch[536/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:58:12 | Train | Epoch[536/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:58:12 | Train | Epoch[536/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:58:12 | Train | Epoch[536/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:58:12 | Train | Epoch[536/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:58:13 | Valid | Epoch[536/600] Iteration[001/008] Valid loss: 0.1757
2023-02-06 14:58:13 | Valid | Epoch[536/600] Iteration[002/008] Valid loss: 0.1399
2023-02-06 14:58:13 | Valid | Epoch[536/600] Iteration[003/008] Valid loss: 0.1323
2023-02-06 14:58:13 | Valid | Epoch[536/600] Iteration[004/008] Valid loss: 0.1253
2023-02-06 14:58:13 | Valid | Epoch[536/600] Iteration[005/008] Valid loss: 0.1235
2023-02-06 14:58:13 | Valid | Epoch[536/600] Iteration[006/008] Valid loss: 0.1191
2023-02-06 14:58:13 | Valid | Epoch[536/600] Iteration[007/008] Valid loss: 0.1270
2023-02-06 14:58:13 | Valid | Epoch[536/600] Iteration[008/008] Valid loss: 0.1255
2023-02-06 14:58:13 | Valid | Epoch[536/600] MIou: 0.9294956957817821
2023-02-06 14:58:13 | Valid | Epoch[536/600] Pixel Accuracy: 0.9878374735514323
2023-02-06 14:58:13 | Valid | Epoch[536/600] Mean Pixel Accuracy: 0.9570601406385877
2023-02-06 14:58:13 | Stage | Epoch[536/600] Train loss:0.0075
2023-02-06 14:58:13 | Stage | Epoch[536/600] Valid loss:0.1255
2023-02-06 14:58:13 | Stage | Epoch[536/600] LR:0.0001

2023-02-06 14:58:13 | Train | Epoch[537/600] Iteration[001/030] Train loss: 0.0069
2023-02-06 14:58:14 | Train | Epoch[537/600] Iteration[002/030] Train loss: 0.0070
2023-02-06 14:58:14 | Train | Epoch[537/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 14:58:14 | Train | Epoch[537/600] Iteration[004/030] Train loss: 0.0076
2023-02-06 14:58:14 | Train | Epoch[537/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:58:15 | Train | Epoch[537/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:58:15 | Train | Epoch[537/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:58:15 | Train | Epoch[537/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:58:15 | Train | Epoch[537/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:58:15 | Train | Epoch[537/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:58:16 | Train | Epoch[537/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:58:16 | Train | Epoch[537/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:58:16 | Train | Epoch[537/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:58:16 | Train | Epoch[537/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:58:17 | Train | Epoch[537/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:58:17 | Train | Epoch[537/600] Iteration[016/030] Train loss: 0.0080
2023-02-06 14:58:17 | Train | Epoch[537/600] Iteration[017/030] Train loss: 0.0079
2023-02-06 14:58:17 | Train | Epoch[537/600] Iteration[018/030] Train loss: 0.0079
2023-02-06 14:58:17 | Train | Epoch[537/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:58:18 | Train | Epoch[537/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 14:58:18 | Train | Epoch[537/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 14:58:18 | Train | Epoch[537/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 14:58:18 | Train | Epoch[537/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 14:58:18 | Train | Epoch[537/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 14:58:19 | Train | Epoch[537/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 14:58:19 | Train | Epoch[537/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:58:19 | Train | Epoch[537/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:58:19 | Train | Epoch[537/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:58:20 | Train | Epoch[537/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:58:20 | Train | Epoch[537/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:58:20 | Valid | Epoch[537/600] Iteration[001/008] Valid loss: 0.1760
2023-02-06 14:58:20 | Valid | Epoch[537/600] Iteration[002/008] Valid loss: 0.1392
2023-02-06 14:58:20 | Valid | Epoch[537/600] Iteration[003/008] Valid loss: 0.1317
2023-02-06 14:58:20 | Valid | Epoch[537/600] Iteration[004/008] Valid loss: 0.1249
2023-02-06 14:58:20 | Valid | Epoch[537/600] Iteration[005/008] Valid loss: 0.1230
2023-02-06 14:58:20 | Valid | Epoch[537/600] Iteration[006/008] Valid loss: 0.1187
2023-02-06 14:58:20 | Valid | Epoch[537/600] Iteration[007/008] Valid loss: 0.1268
2023-02-06 14:58:20 | Valid | Epoch[537/600] Iteration[008/008] Valid loss: 0.1251
2023-02-06 14:58:20 | Valid | Epoch[537/600] MIou: 0.9296613937163811
2023-02-06 14:58:20 | Valid | Epoch[537/600] Pixel Accuracy: 0.987878163655599
2023-02-06 14:58:20 | Valid | Epoch[537/600] Mean Pixel Accuracy: 0.9567591416081126
2023-02-06 14:58:20 | Stage | Epoch[537/600] Train loss:0.0077
2023-02-06 14:58:20 | Stage | Epoch[537/600] Valid loss:0.1251
2023-02-06 14:58:20 | Stage | Epoch[537/600] LR:0.0001

2023-02-06 14:58:21 | Train | Epoch[538/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 14:58:21 | Train | Epoch[538/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 14:58:21 | Train | Epoch[538/600] Iteration[003/030] Train loss: 0.0071
2023-02-06 14:58:22 | Train | Epoch[538/600] Iteration[004/030] Train loss: 0.0071
2023-02-06 14:58:22 | Train | Epoch[538/600] Iteration[005/030] Train loss: 0.0072
2023-02-06 14:58:22 | Train | Epoch[538/600] Iteration[006/030] Train loss: 0.0070
2023-02-06 14:58:22 | Train | Epoch[538/600] Iteration[007/030] Train loss: 0.0070
2023-02-06 14:58:22 | Train | Epoch[538/600] Iteration[008/030] Train loss: 0.0071
2023-02-06 14:58:23 | Train | Epoch[538/600] Iteration[009/030] Train loss: 0.0071
2023-02-06 14:58:23 | Train | Epoch[538/600] Iteration[010/030] Train loss: 0.0071
2023-02-06 14:58:23 | Train | Epoch[538/600] Iteration[011/030] Train loss: 0.0072
2023-02-06 14:58:23 | Train | Epoch[538/600] Iteration[012/030] Train loss: 0.0071
2023-02-06 14:58:23 | Train | Epoch[538/600] Iteration[013/030] Train loss: 0.0072
2023-02-06 14:58:24 | Train | Epoch[538/600] Iteration[014/030] Train loss: 0.0073
2023-02-06 14:58:24 | Train | Epoch[538/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:58:24 | Train | Epoch[538/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:58:24 | Train | Epoch[538/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:58:25 | Train | Epoch[538/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:58:25 | Train | Epoch[538/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:58:25 | Train | Epoch[538/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:58:25 | Train | Epoch[538/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:58:25 | Train | Epoch[538/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:58:26 | Train | Epoch[538/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:58:26 | Train | Epoch[538/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:58:26 | Train | Epoch[538/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:58:26 | Train | Epoch[538/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 14:58:27 | Train | Epoch[538/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 14:58:27 | Train | Epoch[538/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 14:58:27 | Train | Epoch[538/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 14:58:27 | Train | Epoch[538/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:58:27 | Valid | Epoch[538/600] Iteration[001/008] Valid loss: 0.1772
2023-02-06 14:58:27 | Valid | Epoch[538/600] Iteration[002/008] Valid loss: 0.1406
2023-02-06 14:58:28 | Valid | Epoch[538/600] Iteration[003/008] Valid loss: 0.1332
2023-02-06 14:58:28 | Valid | Epoch[538/600] Iteration[004/008] Valid loss: 0.1262
2023-02-06 14:58:28 | Valid | Epoch[538/600] Iteration[005/008] Valid loss: 0.1243
2023-02-06 14:58:28 | Valid | Epoch[538/600] Iteration[006/008] Valid loss: 0.1201
2023-02-06 14:58:28 | Valid | Epoch[538/600] Iteration[007/008] Valid loss: 0.1283
2023-02-06 14:58:28 | Valid | Epoch[538/600] Iteration[008/008] Valid loss: 0.1266
2023-02-06 14:58:28 | Valid | Epoch[538/600] MIou: 0.9299560651142018
2023-02-06 14:58:28 | Valid | Epoch[538/600] Pixel Accuracy: 0.9879239400227865
2023-02-06 14:58:28 | Valid | Epoch[538/600] Mean Pixel Accuracy: 0.9572344757291913
2023-02-06 14:58:28 | Stage | Epoch[538/600] Train loss:0.0075
2023-02-06 14:58:28 | Stage | Epoch[538/600] Valid loss:0.1266
2023-02-06 14:58:28 | Stage | Epoch[538/600] LR:0.0001

2023-02-06 14:58:28 | Train | Epoch[539/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 14:58:28 | Train | Epoch[539/600] Iteration[002/030] Train loss: 0.0069
2023-02-06 14:58:29 | Train | Epoch[539/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 14:58:29 | Train | Epoch[539/600] Iteration[004/030] Train loss: 0.0076
2023-02-06 14:58:29 | Train | Epoch[539/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 14:58:29 | Train | Epoch[539/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:58:30 | Train | Epoch[539/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:58:30 | Train | Epoch[539/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 14:58:30 | Train | Epoch[539/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:58:30 | Train | Epoch[539/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:58:30 | Train | Epoch[539/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 14:58:31 | Train | Epoch[539/600] Iteration[012/030] Train loss: 0.0080
2023-02-06 14:58:31 | Train | Epoch[539/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:58:31 | Train | Epoch[539/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:58:31 | Train | Epoch[539/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:58:32 | Train | Epoch[539/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:58:32 | Train | Epoch[539/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:58:32 | Train | Epoch[539/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:58:32 | Train | Epoch[539/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:58:32 | Train | Epoch[539/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:58:33 | Train | Epoch[539/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:58:33 | Train | Epoch[539/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:58:33 | Train | Epoch[539/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:58:33 | Train | Epoch[539/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:58:34 | Train | Epoch[539/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:58:34 | Train | Epoch[539/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:58:34 | Train | Epoch[539/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:58:34 | Train | Epoch[539/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:58:34 | Train | Epoch[539/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:58:34 | Train | Epoch[539/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:58:35 | Valid | Epoch[539/600] Iteration[001/008] Valid loss: 0.1739
2023-02-06 14:58:35 | Valid | Epoch[539/600] Iteration[002/008] Valid loss: 0.1379
2023-02-06 14:58:35 | Valid | Epoch[539/600] Iteration[003/008] Valid loss: 0.1309
2023-02-06 14:58:35 | Valid | Epoch[539/600] Iteration[004/008] Valid loss: 0.1241
2023-02-06 14:58:35 | Valid | Epoch[539/600] Iteration[005/008] Valid loss: 0.1221
2023-02-06 14:58:35 | Valid | Epoch[539/600] Iteration[006/008] Valid loss: 0.1178
2023-02-06 14:58:35 | Valid | Epoch[539/600] Iteration[007/008] Valid loss: 0.1256
2023-02-06 14:58:35 | Valid | Epoch[539/600] Iteration[008/008] Valid loss: 0.1237
2023-02-06 14:58:35 | Valid | Epoch[539/600] MIou: 0.9295825146249712
2023-02-06 14:58:35 | Valid | Epoch[539/600] Pixel Accuracy: 0.9878756205240885
2023-02-06 14:58:35 | Valid | Epoch[539/600] Mean Pixel Accuracy: 0.9562631870166303
2023-02-06 14:58:35 | Stage | Epoch[539/600] Train loss:0.0076
2023-02-06 14:58:35 | Stage | Epoch[539/600] Valid loss:0.1237
2023-02-06 14:58:35 | Stage | Epoch[539/600] LR:0.0001

2023-02-06 14:58:36 | Train | Epoch[540/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 14:58:36 | Train | Epoch[540/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 14:58:36 | Train | Epoch[540/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:58:36 | Train | Epoch[540/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:58:37 | Train | Epoch[540/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:58:37 | Train | Epoch[540/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:58:37 | Train | Epoch[540/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 14:58:37 | Train | Epoch[540/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 14:58:38 | Train | Epoch[540/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 14:58:38 | Train | Epoch[540/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:58:38 | Train | Epoch[540/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 14:58:38 | Train | Epoch[540/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 14:58:38 | Train | Epoch[540/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:58:39 | Train | Epoch[540/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:58:39 | Train | Epoch[540/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 14:58:39 | Train | Epoch[540/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:58:39 | Train | Epoch[540/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:58:40 | Train | Epoch[540/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:58:40 | Train | Epoch[540/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:58:40 | Train | Epoch[540/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:58:40 | Train | Epoch[540/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 14:58:40 | Train | Epoch[540/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 14:58:41 | Train | Epoch[540/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 14:58:41 | Train | Epoch[540/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 14:58:41 | Train | Epoch[540/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 14:58:41 | Train | Epoch[540/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 14:58:41 | Train | Epoch[540/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 14:58:42 | Train | Epoch[540/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:58:42 | Train | Epoch[540/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 14:58:42 | Train | Epoch[540/600] Iteration[030/030] Train loss: 0.0074
2023-02-06 14:58:42 | Valid | Epoch[540/600] Iteration[001/008] Valid loss: 0.1687
2023-02-06 14:58:42 | Valid | Epoch[540/600] Iteration[002/008] Valid loss: 0.1343
2023-02-06 14:58:42 | Valid | Epoch[540/600] Iteration[003/008] Valid loss: 0.1271
2023-02-06 14:58:43 | Valid | Epoch[540/600] Iteration[004/008] Valid loss: 0.1203
2023-02-06 14:58:43 | Valid | Epoch[540/600] Iteration[005/008] Valid loss: 0.1184
2023-02-06 14:58:43 | Valid | Epoch[540/600] Iteration[006/008] Valid loss: 0.1141
2023-02-06 14:58:43 | Valid | Epoch[540/600] Iteration[007/008] Valid loss: 0.1216
2023-02-06 14:58:43 | Valid | Epoch[540/600] Iteration[008/008] Valid loss: 0.1200
2023-02-06 14:58:43 | Valid | Epoch[540/600] MIou: 0.9294012152429163
2023-02-06 14:58:43 | Valid | Epoch[540/600] Pixel Accuracy: 0.98785400390625
2023-02-06 14:58:43 | Valid | Epoch[540/600] Mean Pixel Accuracy: 0.9557250464660372
2023-02-06 14:58:43 | Stage | Epoch[540/600] Train loss:0.0074
2023-02-06 14:58:43 | Stage | Epoch[540/600] Valid loss:0.1200
2023-02-06 14:58:43 | Stage | Epoch[540/600] LR:0.0001

2023-02-06 14:58:43 | Train | Epoch[541/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 14:58:44 | Train | Epoch[541/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 14:58:44 | Train | Epoch[541/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 14:58:44 | Train | Epoch[541/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 14:58:44 | Train | Epoch[541/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 14:58:44 | Train | Epoch[541/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 14:58:45 | Train | Epoch[541/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:58:45 | Train | Epoch[541/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:58:45 | Train | Epoch[541/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:58:45 | Train | Epoch[541/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 14:58:45 | Train | Epoch[541/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:58:46 | Train | Epoch[541/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:58:46 | Train | Epoch[541/600] Iteration[013/030] Train loss: 0.0079
2023-02-06 14:58:46 | Train | Epoch[541/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:58:46 | Train | Epoch[541/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:58:47 | Train | Epoch[541/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:58:47 | Train | Epoch[541/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:58:47 | Train | Epoch[541/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:58:47 | Train | Epoch[541/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:58:47 | Train | Epoch[541/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:58:48 | Train | Epoch[541/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 14:58:48 | Train | Epoch[541/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 14:58:48 | Train | Epoch[541/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 14:58:48 | Train | Epoch[541/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 14:58:49 | Train | Epoch[541/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:58:49 | Train | Epoch[541/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:58:49 | Train | Epoch[541/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:58:49 | Train | Epoch[541/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:58:49 | Train | Epoch[541/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:58:50 | Train | Epoch[541/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:58:50 | Valid | Epoch[541/600] Iteration[001/008] Valid loss: 0.1769
2023-02-06 14:58:50 | Valid | Epoch[541/600] Iteration[002/008] Valid loss: 0.1409
2023-02-06 14:58:50 | Valid | Epoch[541/600] Iteration[003/008] Valid loss: 0.1326
2023-02-06 14:58:50 | Valid | Epoch[541/600] Iteration[004/008] Valid loss: 0.1259
2023-02-06 14:58:50 | Valid | Epoch[541/600] Iteration[005/008] Valid loss: 0.1242
2023-02-06 14:58:50 | Valid | Epoch[541/600] Iteration[006/008] Valid loss: 0.1199
2023-02-06 14:58:50 | Valid | Epoch[541/600] Iteration[007/008] Valid loss: 0.1279
2023-02-06 14:58:50 | Valid | Epoch[541/600] Iteration[008/008] Valid loss: 0.1264
2023-02-06 14:58:50 | Valid | Epoch[541/600] MIou: 0.92984603569956
2023-02-06 14:58:50 | Valid | Epoch[541/600] Pixel Accuracy: 0.987890879313151
2023-02-06 14:58:50 | Valid | Epoch[541/600] Mean Pixel Accuracy: 0.9576664776305281
2023-02-06 14:58:50 | Stage | Epoch[541/600] Train loss:0.0076
2023-02-06 14:58:50 | Stage | Epoch[541/600] Valid loss:0.1264
2023-02-06 14:58:50 | Stage | Epoch[541/600] LR:0.0001

2023-02-06 14:58:51 | Train | Epoch[542/600] Iteration[001/030] Train loss: 0.0081
2023-02-06 14:58:51 | Train | Epoch[542/600] Iteration[002/030] Train loss: 0.0083
2023-02-06 14:58:51 | Train | Epoch[542/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:58:51 | Train | Epoch[542/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:58:52 | Train | Epoch[542/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:58:52 | Train | Epoch[542/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:58:52 | Train | Epoch[542/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:58:52 | Train | Epoch[542/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:58:53 | Train | Epoch[542/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 14:58:53 | Train | Epoch[542/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:58:53 | Train | Epoch[542/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:58:53 | Train | Epoch[542/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 14:58:53 | Train | Epoch[542/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 14:58:54 | Train | Epoch[542/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 14:58:54 | Train | Epoch[542/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:58:54 | Train | Epoch[542/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:58:54 | Train | Epoch[542/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:58:55 | Train | Epoch[542/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:58:55 | Train | Epoch[542/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 14:58:55 | Train | Epoch[542/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:58:55 | Train | Epoch[542/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:58:55 | Train | Epoch[542/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:58:56 | Train | Epoch[542/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:58:56 | Train | Epoch[542/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:58:56 | Train | Epoch[542/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:58:56 | Train | Epoch[542/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:58:57 | Train | Epoch[542/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:58:57 | Train | Epoch[542/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:58:57 | Train | Epoch[542/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:58:57 | Train | Epoch[542/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 14:58:57 | Valid | Epoch[542/600] Iteration[001/008] Valid loss: 0.1838
2023-02-06 14:58:57 | Valid | Epoch[542/600] Iteration[002/008] Valid loss: 0.1460
2023-02-06 14:58:57 | Valid | Epoch[542/600] Iteration[003/008] Valid loss: 0.1377
2023-02-06 14:58:57 | Valid | Epoch[542/600] Iteration[004/008] Valid loss: 0.1309
2023-02-06 14:58:58 | Valid | Epoch[542/600] Iteration[005/008] Valid loss: 0.1293
2023-02-06 14:58:58 | Valid | Epoch[542/600] Iteration[006/008] Valid loss: 0.1248
2023-02-06 14:58:58 | Valid | Epoch[542/600] Iteration[007/008] Valid loss: 0.1334
2023-02-06 14:58:58 | Valid | Epoch[542/600] Iteration[008/008] Valid loss: 0.1318
2023-02-06 14:58:58 | Valid | Epoch[542/600] MIou: 0.93043050874777
2023-02-06 14:58:58 | Valid | Epoch[542/600] Pixel Accuracy: 0.98797607421875
2023-02-06 14:58:58 | Valid | Epoch[542/600] Mean Pixel Accuracy: 0.9588355678417584
2023-02-06 14:58:58 | Stage | Epoch[542/600] Train loss:0.0077
2023-02-06 14:58:58 | Stage | Epoch[542/600] Valid loss:0.1318
2023-02-06 14:58:58 | Stage | Epoch[542/600] LR:0.0001

2023-02-06 14:58:58 | Train | Epoch[543/600] Iteration[001/030] Train loss: 0.0071
2023-02-06 14:58:58 | Train | Epoch[543/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:58:59 | Train | Epoch[543/600] Iteration[003/030] Train loss: 0.0078
2023-02-06 14:58:59 | Train | Epoch[543/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 14:58:59 | Train | Epoch[543/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 14:58:59 | Train | Epoch[543/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:59:00 | Train | Epoch[543/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 14:59:00 | Train | Epoch[543/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:59:00 | Train | Epoch[543/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:59:00 | Train | Epoch[543/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 14:59:00 | Train | Epoch[543/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:59:01 | Train | Epoch[543/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:59:01 | Train | Epoch[543/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 14:59:01 | Train | Epoch[543/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:59:01 | Train | Epoch[543/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:59:01 | Train | Epoch[543/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:59:02 | Train | Epoch[543/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:59:02 | Train | Epoch[543/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:59:02 | Train | Epoch[543/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:59:02 | Train | Epoch[543/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:59:03 | Train | Epoch[543/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:59:03 | Train | Epoch[543/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:59:03 | Train | Epoch[543/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 14:59:03 | Train | Epoch[543/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:59:03 | Train | Epoch[543/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:59:04 | Train | Epoch[543/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:59:04 | Train | Epoch[543/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:59:04 | Train | Epoch[543/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:59:04 | Train | Epoch[543/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:59:04 | Train | Epoch[543/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:59:05 | Valid | Epoch[543/600] Iteration[001/008] Valid loss: 0.1800
2023-02-06 14:59:05 | Valid | Epoch[543/600] Iteration[002/008] Valid loss: 0.1437
2023-02-06 14:59:05 | Valid | Epoch[543/600] Iteration[003/008] Valid loss: 0.1354
2023-02-06 14:59:05 | Valid | Epoch[543/600] Iteration[004/008] Valid loss: 0.1288
2023-02-06 14:59:05 | Valid | Epoch[543/600] Iteration[005/008] Valid loss: 0.1273
2023-02-06 14:59:05 | Valid | Epoch[543/600] Iteration[006/008] Valid loss: 0.1227
2023-02-06 14:59:05 | Valid | Epoch[543/600] Iteration[007/008] Valid loss: 0.1311
2023-02-06 14:59:05 | Valid | Epoch[543/600] Iteration[008/008] Valid loss: 0.1294
2023-02-06 14:59:05 | Valid | Epoch[543/600] MIou: 0.9301245838530865
2023-02-06 14:59:05 | Valid | Epoch[543/600] Pixel Accuracy: 0.9879277547200521
2023-02-06 14:59:05 | Valid | Epoch[543/600] Mean Pixel Accuracy: 0.9583651763786516
2023-02-06 14:59:05 | Stage | Epoch[543/600] Train loss:0.0075
2023-02-06 14:59:05 | Stage | Epoch[543/600] Valid loss:0.1294
2023-02-06 14:59:05 | Stage | Epoch[543/600] LR:0.0001

2023-02-06 14:59:06 | Train | Epoch[544/600] Iteration[001/030] Train loss: 0.0088
2023-02-06 14:59:06 | Train | Epoch[544/600] Iteration[002/030] Train loss: 0.0083
2023-02-06 14:59:06 | Train | Epoch[544/600] Iteration[003/030] Train loss: 0.0082
2023-02-06 14:59:06 | Train | Epoch[544/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 14:59:07 | Train | Epoch[544/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 14:59:07 | Train | Epoch[544/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 14:59:07 | Train | Epoch[544/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 14:59:07 | Train | Epoch[544/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 14:59:07 | Train | Epoch[544/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:59:08 | Train | Epoch[544/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:59:08 | Train | Epoch[544/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:59:08 | Train | Epoch[544/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:59:08 | Train | Epoch[544/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:59:09 | Train | Epoch[544/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:59:09 | Train | Epoch[544/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:59:09 | Train | Epoch[544/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:59:09 | Train | Epoch[544/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 14:59:09 | Train | Epoch[544/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 14:59:10 | Train | Epoch[544/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:59:10 | Train | Epoch[544/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:59:10 | Train | Epoch[544/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:59:10 | Train | Epoch[544/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:59:10 | Train | Epoch[544/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:59:11 | Train | Epoch[544/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:59:11 | Train | Epoch[544/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:59:11 | Train | Epoch[544/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:59:11 | Train | Epoch[544/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:59:12 | Train | Epoch[544/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:59:12 | Train | Epoch[544/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:59:12 | Train | Epoch[544/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:59:12 | Valid | Epoch[544/600] Iteration[001/008] Valid loss: 0.1696
2023-02-06 14:59:12 | Valid | Epoch[544/600] Iteration[002/008] Valid loss: 0.1348
2023-02-06 14:59:12 | Valid | Epoch[544/600] Iteration[003/008] Valid loss: 0.1270
2023-02-06 14:59:12 | Valid | Epoch[544/600] Iteration[004/008] Valid loss: 0.1207
2023-02-06 14:59:12 | Valid | Epoch[544/600] Iteration[005/008] Valid loss: 0.1185
2023-02-06 14:59:13 | Valid | Epoch[544/600] Iteration[006/008] Valid loss: 0.1143
2023-02-06 14:59:13 | Valid | Epoch[544/600] Iteration[007/008] Valid loss: 0.1216
2023-02-06 14:59:13 | Valid | Epoch[544/600] Iteration[008/008] Valid loss: 0.1199
2023-02-06 14:59:13 | Valid | Epoch[544/600] MIou: 0.92891150966753
2023-02-06 14:59:13 | Valid | Epoch[544/600] Pixel Accuracy: 0.9877662658691406
2023-02-06 14:59:13 | Valid | Epoch[544/600] Mean Pixel Accuracy: 0.9553851602093494
2023-02-06 14:59:13 | Stage | Epoch[544/600] Train loss:0.0076
2023-02-06 14:59:13 | Stage | Epoch[544/600] Valid loss:0.1199
2023-02-06 14:59:13 | Stage | Epoch[544/600] LR:0.0001

2023-02-06 14:59:13 | Train | Epoch[545/600] Iteration[001/030] Train loss: 0.0060
2023-02-06 14:59:13 | Train | Epoch[545/600] Iteration[002/030] Train loss: 0.0073
2023-02-06 14:59:14 | Train | Epoch[545/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:59:14 | Train | Epoch[545/600] Iteration[004/030] Train loss: 0.0085
2023-02-06 14:59:14 | Train | Epoch[545/600] Iteration[005/030] Train loss: 0.0082
2023-02-06 14:59:14 | Train | Epoch[545/600] Iteration[006/030] Train loss: 0.0082
2023-02-06 14:59:15 | Train | Epoch[545/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:59:15 | Train | Epoch[545/600] Iteration[008/030] Train loss: 0.0081
2023-02-06 14:59:15 | Train | Epoch[545/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 14:59:15 | Train | Epoch[545/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 14:59:15 | Train | Epoch[545/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 14:59:16 | Train | Epoch[545/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 14:59:16 | Train | Epoch[545/600] Iteration[013/030] Train loss: 0.0080
2023-02-06 14:59:16 | Train | Epoch[545/600] Iteration[014/030] Train loss: 0.0079
2023-02-06 14:59:16 | Train | Epoch[545/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 14:59:16 | Train | Epoch[545/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 14:59:17 | Train | Epoch[545/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 14:59:17 | Train | Epoch[545/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 14:59:17 | Train | Epoch[545/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 14:59:17 | Train | Epoch[545/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 14:59:18 | Train | Epoch[545/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 14:59:18 | Train | Epoch[545/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 14:59:18 | Train | Epoch[545/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 14:59:18 | Train | Epoch[545/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 14:59:18 | Train | Epoch[545/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 14:59:19 | Train | Epoch[545/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 14:59:19 | Train | Epoch[545/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 14:59:19 | Train | Epoch[545/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 14:59:19 | Train | Epoch[545/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 14:59:19 | Train | Epoch[545/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 14:59:20 | Valid | Epoch[545/600] Iteration[001/008] Valid loss: 0.1713
2023-02-06 14:59:20 | Valid | Epoch[545/600] Iteration[002/008] Valid loss: 0.1361
2023-02-06 14:59:20 | Valid | Epoch[545/600] Iteration[003/008] Valid loss: 0.1290
2023-02-06 14:59:20 | Valid | Epoch[545/600] Iteration[004/008] Valid loss: 0.1225
2023-02-06 14:59:20 | Valid | Epoch[545/600] Iteration[005/008] Valid loss: 0.1206
2023-02-06 14:59:20 | Valid | Epoch[545/600] Iteration[006/008] Valid loss: 0.1163
2023-02-06 14:59:20 | Valid | Epoch[545/600] Iteration[007/008] Valid loss: 0.1239
2023-02-06 14:59:20 | Valid | Epoch[545/600] Iteration[008/008] Valid loss: 0.1222
2023-02-06 14:59:20 | Valid | Epoch[545/600] MIou: 0.9292948523137279
2023-02-06 14:59:20 | Valid | Epoch[545/600] Pixel Accuracy: 0.9878260294596354
2023-02-06 14:59:20 | Valid | Epoch[545/600] Mean Pixel Accuracy: 0.955988651263628
2023-02-06 14:59:20 | Stage | Epoch[545/600] Train loss:0.0078
2023-02-06 14:59:20 | Stage | Epoch[545/600] Valid loss:0.1222
2023-02-06 14:59:20 | Stage | Epoch[545/600] LR:0.0001

2023-02-06 14:59:21 | Train | Epoch[546/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 14:59:21 | Train | Epoch[546/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 14:59:21 | Train | Epoch[546/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 14:59:21 | Train | Epoch[546/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 14:59:22 | Train | Epoch[546/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:59:22 | Train | Epoch[546/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 14:59:22 | Train | Epoch[546/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 14:59:22 | Train | Epoch[546/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:59:22 | Train | Epoch[546/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 14:59:23 | Train | Epoch[546/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 14:59:23 | Train | Epoch[546/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:59:23 | Train | Epoch[546/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:59:23 | Train | Epoch[546/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:59:24 | Train | Epoch[546/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 14:59:24 | Train | Epoch[546/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:59:24 | Train | Epoch[546/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 14:59:24 | Train | Epoch[546/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:59:24 | Train | Epoch[546/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:59:25 | Train | Epoch[546/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:59:25 | Train | Epoch[546/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 14:59:25 | Train | Epoch[546/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 14:59:25 | Train | Epoch[546/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:59:26 | Train | Epoch[546/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:59:26 | Train | Epoch[546/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:59:26 | Train | Epoch[546/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:59:26 | Train | Epoch[546/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 14:59:26 | Train | Epoch[546/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:59:27 | Train | Epoch[546/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:59:27 | Train | Epoch[546/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:59:27 | Train | Epoch[546/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:59:27 | Valid | Epoch[546/600] Iteration[001/008] Valid loss: 0.1814
2023-02-06 14:59:27 | Valid | Epoch[546/600] Iteration[002/008] Valid loss: 0.1438
2023-02-06 14:59:27 | Valid | Epoch[546/600] Iteration[003/008] Valid loss: 0.1360
2023-02-06 14:59:28 | Valid | Epoch[546/600] Iteration[004/008] Valid loss: 0.1289
2023-02-06 14:59:28 | Valid | Epoch[546/600] Iteration[005/008] Valid loss: 0.1270
2023-02-06 14:59:28 | Valid | Epoch[546/600] Iteration[006/008] Valid loss: 0.1226
2023-02-06 14:59:28 | Valid | Epoch[546/600] Iteration[007/008] Valid loss: 0.1309
2023-02-06 14:59:28 | Valid | Epoch[546/600] Iteration[008/008] Valid loss: 0.1293
2023-02-06 14:59:28 | Valid | Epoch[546/600] MIou: 0.9295484207239542
2023-02-06 14:59:28 | Valid | Epoch[546/600] Pixel Accuracy: 0.9878349304199219
2023-02-06 14:59:28 | Valid | Epoch[546/600] Mean Pixel Accuracy: 0.9575532996029898
2023-02-06 14:59:28 | Stage | Epoch[546/600] Train loss:0.0075
2023-02-06 14:59:28 | Stage | Epoch[546/600] Valid loss:0.1293
2023-02-06 14:59:28 | Stage | Epoch[546/600] LR:0.0001

2023-02-06 14:59:28 | Train | Epoch[547/600] Iteration[001/030] Train loss: 0.0082
2023-02-06 14:59:28 | Train | Epoch[547/600] Iteration[002/030] Train loss: 0.0089
2023-02-06 14:59:29 | Train | Epoch[547/600] Iteration[003/030] Train loss: 0.0087
2023-02-06 14:59:29 | Train | Epoch[547/600] Iteration[004/030] Train loss: 0.0083
2023-02-06 14:59:29 | Train | Epoch[547/600] Iteration[005/030] Train loss: 0.0082
2023-02-06 14:59:29 | Train | Epoch[547/600] Iteration[006/030] Train loss: 0.0082
2023-02-06 14:59:30 | Train | Epoch[547/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 14:59:30 | Train | Epoch[547/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 14:59:30 | Train | Epoch[547/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 14:59:30 | Train | Epoch[547/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 14:59:30 | Train | Epoch[547/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 14:59:31 | Train | Epoch[547/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 14:59:31 | Train | Epoch[547/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 14:59:31 | Train | Epoch[547/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 14:59:31 | Train | Epoch[547/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 14:59:32 | Train | Epoch[547/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 14:59:32 | Train | Epoch[547/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:59:32 | Train | Epoch[547/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:59:32 | Train | Epoch[547/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:59:32 | Train | Epoch[547/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 14:59:33 | Train | Epoch[547/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 14:59:33 | Train | Epoch[547/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 14:59:33 | Train | Epoch[547/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:59:33 | Train | Epoch[547/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:59:34 | Train | Epoch[547/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:59:34 | Train | Epoch[547/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 14:59:34 | Train | Epoch[547/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 14:59:34 | Train | Epoch[547/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 14:59:34 | Train | Epoch[547/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:59:35 | Train | Epoch[547/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:59:35 | Valid | Epoch[547/600] Iteration[001/008] Valid loss: 0.1766
2023-02-06 14:59:35 | Valid | Epoch[547/600] Iteration[002/008] Valid loss: 0.1405
2023-02-06 14:59:35 | Valid | Epoch[547/600] Iteration[003/008] Valid loss: 0.1326
2023-02-06 14:59:35 | Valid | Epoch[547/600] Iteration[004/008] Valid loss: 0.1259
2023-02-06 14:59:35 | Valid | Epoch[547/600] Iteration[005/008] Valid loss: 0.1244
2023-02-06 14:59:35 | Valid | Epoch[547/600] Iteration[006/008] Valid loss: 0.1200
2023-02-06 14:59:35 | Valid | Epoch[547/600] Iteration[007/008] Valid loss: 0.1281
2023-02-06 14:59:35 | Valid | Epoch[547/600] Iteration[008/008] Valid loss: 0.1266
2023-02-06 14:59:35 | Valid | Epoch[547/600] MIou: 0.9294876647010417
2023-02-06 14:59:35 | Valid | Epoch[547/600] Pixel Accuracy: 0.9878260294596354
2023-02-06 14:59:35 | Valid | Epoch[547/600] Mean Pixel Accuracy: 0.9574342787683822
2023-02-06 14:59:35 | Stage | Epoch[547/600] Train loss:0.0075
2023-02-06 14:59:35 | Stage | Epoch[547/600] Valid loss:0.1266
2023-02-06 14:59:35 | Stage | Epoch[547/600] LR:0.0001

2023-02-06 14:59:36 | Train | Epoch[548/600] Iteration[001/030] Train loss: 0.0069
2023-02-06 14:59:36 | Train | Epoch[548/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 14:59:36 | Train | Epoch[548/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 14:59:36 | Train | Epoch[548/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 14:59:37 | Train | Epoch[548/600] Iteration[005/030] Train loss: 0.0071
2023-02-06 14:59:37 | Train | Epoch[548/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 14:59:37 | Train | Epoch[548/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 14:59:37 | Train | Epoch[548/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 14:59:38 | Train | Epoch[548/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:59:38 | Train | Epoch[548/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:59:38 | Train | Epoch[548/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 14:59:38 | Train | Epoch[548/600] Iteration[012/030] Train loss: 0.0073
2023-02-06 14:59:38 | Train | Epoch[548/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:59:39 | Train | Epoch[548/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:59:39 | Train | Epoch[548/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 14:59:39 | Train | Epoch[548/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 14:59:39 | Train | Epoch[548/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 14:59:40 | Train | Epoch[548/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 14:59:40 | Train | Epoch[548/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 14:59:40 | Train | Epoch[548/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 14:59:40 | Train | Epoch[548/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 14:59:40 | Train | Epoch[548/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 14:59:41 | Train | Epoch[548/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 14:59:41 | Train | Epoch[548/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 14:59:41 | Train | Epoch[548/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 14:59:41 | Train | Epoch[548/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 14:59:42 | Train | Epoch[548/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 14:59:42 | Train | Epoch[548/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 14:59:42 | Train | Epoch[548/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 14:59:42 | Train | Epoch[548/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 14:59:42 | Valid | Epoch[548/600] Iteration[001/008] Valid loss: 0.1874
2023-02-06 14:59:42 | Valid | Epoch[548/600] Iteration[002/008] Valid loss: 0.1489
2023-02-06 14:59:43 | Valid | Epoch[548/600] Iteration[003/008] Valid loss: 0.1403
2023-02-06 14:59:43 | Valid | Epoch[548/600] Iteration[004/008] Valid loss: 0.1330
2023-02-06 14:59:43 | Valid | Epoch[548/600] Iteration[005/008] Valid loss: 0.1314
2023-02-06 14:59:43 | Valid | Epoch[548/600] Iteration[006/008] Valid loss: 0.1271
2023-02-06 14:59:43 | Valid | Epoch[548/600] Iteration[007/008] Valid loss: 0.1361
2023-02-06 14:59:43 | Valid | Epoch[548/600] Iteration[008/008] Valid loss: 0.1345
2023-02-06 14:59:43 | Valid | Epoch[548/600] MIou: 0.9300689383420924
2023-02-06 14:59:43 | Valid | Epoch[548/600] Pixel Accuracy: 0.9878997802734375
2023-02-06 14:59:43 | Valid | Epoch[548/600] Mean Pixel Accuracy: 0.9590155499384794
2023-02-06 14:59:43 | Stage | Epoch[548/600] Train loss:0.0075
2023-02-06 14:59:43 | Stage | Epoch[548/600] Valid loss:0.1345
2023-02-06 14:59:43 | Stage | Epoch[548/600] LR:0.0001

2023-02-06 14:59:43 | Train | Epoch[549/600] Iteration[001/030] Train loss: 0.0070
2023-02-06 14:59:44 | Train | Epoch[549/600] Iteration[002/030] Train loss: 0.0068
2023-02-06 14:59:44 | Train | Epoch[549/600] Iteration[003/030] Train loss: 0.0070
2023-02-06 14:59:44 | Train | Epoch[549/600] Iteration[004/030] Train loss: 0.0071
2023-02-06 14:59:44 | Train | Epoch[549/600] Iteration[005/030] Train loss: 0.0071
2023-02-06 14:59:44 | Train | Epoch[549/600] Iteration[006/030] Train loss: 0.0072
2023-02-06 14:59:45 | Train | Epoch[549/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 14:59:45 | Train | Epoch[549/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:59:45 | Train | Epoch[549/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 14:59:45 | Train | Epoch[549/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 14:59:46 | Train | Epoch[549/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 14:59:46 | Train | Epoch[549/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 14:59:46 | Train | Epoch[549/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 14:59:46 | Train | Epoch[549/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 14:59:46 | Train | Epoch[549/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 14:59:47 | Train | Epoch[549/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 14:59:47 | Train | Epoch[549/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 14:59:47 | Train | Epoch[549/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 14:59:47 | Train | Epoch[549/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 14:59:47 | Train | Epoch[549/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 14:59:48 | Train | Epoch[549/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:59:48 | Train | Epoch[549/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:59:48 | Train | Epoch[549/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 14:59:48 | Train | Epoch[549/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 14:59:49 | Train | Epoch[549/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 14:59:49 | Train | Epoch[549/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 14:59:49 | Train | Epoch[549/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:59:49 | Train | Epoch[549/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 14:59:49 | Train | Epoch[549/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:59:50 | Train | Epoch[549/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:59:50 | Valid | Epoch[549/600] Iteration[001/008] Valid loss: 0.1848
2023-02-06 14:59:50 | Valid | Epoch[549/600] Iteration[002/008] Valid loss: 0.1467
2023-02-06 14:59:50 | Valid | Epoch[549/600] Iteration[003/008] Valid loss: 0.1382
2023-02-06 14:59:50 | Valid | Epoch[549/600] Iteration[004/008] Valid loss: 0.1309
2023-02-06 14:59:50 | Valid | Epoch[549/600] Iteration[005/008] Valid loss: 0.1293
2023-02-06 14:59:50 | Valid | Epoch[549/600] Iteration[006/008] Valid loss: 0.1250
2023-02-06 14:59:50 | Valid | Epoch[549/600] Iteration[007/008] Valid loss: 0.1335
2023-02-06 14:59:50 | Valid | Epoch[549/600] Iteration[008/008] Valid loss: 0.1320
2023-02-06 14:59:50 | Valid | Epoch[549/600] MIou: 0.9298245543795692
2023-02-06 14:59:50 | Valid | Epoch[549/600] Pixel Accuracy: 0.9878667195638021
2023-02-06 14:59:50 | Valid | Epoch[549/600] Mean Pixel Accuracy: 0.9584267359263714
2023-02-06 14:59:50 | Stage | Epoch[549/600] Train loss:0.0076
2023-02-06 14:59:50 | Stage | Epoch[549/600] Valid loss:0.1320
2023-02-06 14:59:50 | Stage | Epoch[549/600] LR:0.0001

2023-02-06 14:59:51 | Train | Epoch[550/600] Iteration[001/030] Train loss: 0.0066
2023-02-06 14:59:51 | Train | Epoch[550/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 14:59:51 | Train | Epoch[550/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 14:59:51 | Train | Epoch[550/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 14:59:52 | Train | Epoch[550/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 14:59:52 | Train | Epoch[550/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 14:59:52 | Train | Epoch[550/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 14:59:52 | Train | Epoch[550/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 14:59:53 | Train | Epoch[550/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 14:59:53 | Train | Epoch[550/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 14:59:53 | Train | Epoch[550/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 14:59:53 | Train | Epoch[550/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 14:59:53 | Train | Epoch[550/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 14:59:54 | Train | Epoch[550/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 14:59:54 | Train | Epoch[550/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 14:59:54 | Train | Epoch[550/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 14:59:54 | Train | Epoch[550/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 14:59:55 | Train | Epoch[550/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 14:59:55 | Train | Epoch[550/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 14:59:55 | Train | Epoch[550/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 14:59:55 | Train | Epoch[550/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 14:59:55 | Train | Epoch[550/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 14:59:56 | Train | Epoch[550/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 14:59:56 | Train | Epoch[550/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 14:59:56 | Train | Epoch[550/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 14:59:56 | Train | Epoch[550/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 14:59:56 | Train | Epoch[550/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 14:59:57 | Train | Epoch[550/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 14:59:57 | Train | Epoch[550/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 14:59:57 | Train | Epoch[550/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 14:59:57 | Valid | Epoch[550/600] Iteration[001/008] Valid loss: 0.1812
2023-02-06 14:59:57 | Valid | Epoch[550/600] Iteration[002/008] Valid loss: 0.1435
2023-02-06 14:59:58 | Valid | Epoch[550/600] Iteration[003/008] Valid loss: 0.1354
2023-02-06 14:59:58 | Valid | Epoch[550/600] Iteration[004/008] Valid loss: 0.1284
2023-02-06 14:59:58 | Valid | Epoch[550/600] Iteration[005/008] Valid loss: 0.1268
2023-02-06 14:59:58 | Valid | Epoch[550/600] Iteration[006/008] Valid loss: 0.1225
2023-02-06 14:59:58 | Valid | Epoch[550/600] Iteration[007/008] Valid loss: 0.1308
2023-02-06 14:59:58 | Valid | Epoch[550/600] Iteration[008/008] Valid loss: 0.1292
2023-02-06 14:59:58 | Valid | Epoch[550/600] MIou: 0.9298848793034271
2023-02-06 14:59:58 | Valid | Epoch[550/600] Pixel Accuracy: 0.9878946940104166
2023-02-06 14:59:58 | Valid | Epoch[550/600] Mean Pixel Accuracy: 0.9578144051956161
2023-02-06 14:59:58 | Stage | Epoch[550/600] Train loss:0.0076
2023-02-06 14:59:58 | Stage | Epoch[550/600] Valid loss:0.1292
2023-02-06 14:59:58 | Stage | Epoch[550/600] LR:0.0001

2023-02-06 14:59:58 | Train | Epoch[551/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 14:59:59 | Train | Epoch[551/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 14:59:59 | Train | Epoch[551/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 14:59:59 | Train | Epoch[551/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 14:59:59 | Train | Epoch[551/600] Iteration[005/030] Train loss: 0.0071
2023-02-06 14:59:59 | Train | Epoch[551/600] Iteration[006/030] Train loss: 0.0071
2023-02-06 15:00:00 | Train | Epoch[551/600] Iteration[007/030] Train loss: 0.0071
2023-02-06 15:00:00 | Train | Epoch[551/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 15:00:00 | Train | Epoch[551/600] Iteration[009/030] Train loss: 0.0072
2023-02-06 15:00:00 | Train | Epoch[551/600] Iteration[010/030] Train loss: 0.0072
2023-02-06 15:00:01 | Train | Epoch[551/600] Iteration[011/030] Train loss: 0.0072
2023-02-06 15:00:01 | Train | Epoch[551/600] Iteration[012/030] Train loss: 0.0072
2023-02-06 15:00:01 | Train | Epoch[551/600] Iteration[013/030] Train loss: 0.0073
2023-02-06 15:00:01 | Train | Epoch[551/600] Iteration[014/030] Train loss: 0.0073
2023-02-06 15:00:01 | Train | Epoch[551/600] Iteration[015/030] Train loss: 0.0073
2023-02-06 15:00:02 | Train | Epoch[551/600] Iteration[016/030] Train loss: 0.0073
2023-02-06 15:00:02 | Train | Epoch[551/600] Iteration[017/030] Train loss: 0.0072
2023-02-06 15:00:02 | Train | Epoch[551/600] Iteration[018/030] Train loss: 0.0073
2023-02-06 15:00:02 | Train | Epoch[551/600] Iteration[019/030] Train loss: 0.0073
2023-02-06 15:00:03 | Train | Epoch[551/600] Iteration[020/030] Train loss: 0.0073
2023-02-06 15:00:03 | Train | Epoch[551/600] Iteration[021/030] Train loss: 0.0073
2023-02-06 15:00:03 | Train | Epoch[551/600] Iteration[022/030] Train loss: 0.0073
2023-02-06 15:00:03 | Train | Epoch[551/600] Iteration[023/030] Train loss: 0.0073
2023-02-06 15:00:03 | Train | Epoch[551/600] Iteration[024/030] Train loss: 0.0073
2023-02-06 15:00:04 | Train | Epoch[551/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:00:04 | Train | Epoch[551/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 15:00:04 | Train | Epoch[551/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:00:04 | Train | Epoch[551/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 15:00:05 | Train | Epoch[551/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 15:00:05 | Train | Epoch[551/600] Iteration[030/030] Train loss: 0.0074
2023-02-06 15:00:05 | Valid | Epoch[551/600] Iteration[001/008] Valid loss: 0.1779
2023-02-06 15:00:05 | Valid | Epoch[551/600] Iteration[002/008] Valid loss: 0.1413
2023-02-06 15:00:05 | Valid | Epoch[551/600] Iteration[003/008] Valid loss: 0.1331
2023-02-06 15:00:05 | Valid | Epoch[551/600] Iteration[004/008] Valid loss: 0.1262
2023-02-06 15:00:05 | Valid | Epoch[551/600] Iteration[005/008] Valid loss: 0.1246
2023-02-06 15:00:05 | Valid | Epoch[551/600] Iteration[006/008] Valid loss: 0.1202
2023-02-06 15:00:05 | Valid | Epoch[551/600] Iteration[007/008] Valid loss: 0.1285
2023-02-06 15:00:05 | Valid | Epoch[551/600] Iteration[008/008] Valid loss: 0.1271
2023-02-06 15:00:05 | Valid | Epoch[551/600] MIou: 0.9298006074788792
2023-02-06 15:00:05 | Valid | Epoch[551/600] Pixel Accuracy: 0.9878807067871094
2023-02-06 15:00:05 | Valid | Epoch[551/600] Mean Pixel Accuracy: 0.9577116101484646
2023-02-06 15:00:05 | Stage | Epoch[551/600] Train loss:0.0074
2023-02-06 15:00:05 | Stage | Epoch[551/600] Valid loss:0.1271
2023-02-06 15:00:05 | Stage | Epoch[551/600] LR:0.0001

2023-02-06 15:00:06 | Train | Epoch[552/600] Iteration[001/030] Train loss: 0.0064
2023-02-06 15:00:06 | Train | Epoch[552/600] Iteration[002/030] Train loss: 0.0065
2023-02-06 15:00:06 | Train | Epoch[552/600] Iteration[003/030] Train loss: 0.0065
2023-02-06 15:00:07 | Train | Epoch[552/600] Iteration[004/030] Train loss: 0.0068
2023-02-06 15:00:07 | Train | Epoch[552/600] Iteration[005/030] Train loss: 0.0072
2023-02-06 15:00:07 | Train | Epoch[552/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 15:00:07 | Train | Epoch[552/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 15:00:07 | Train | Epoch[552/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 15:00:08 | Train | Epoch[552/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 15:00:08 | Train | Epoch[552/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 15:00:08 | Train | Epoch[552/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 15:00:08 | Train | Epoch[552/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 15:00:09 | Train | Epoch[552/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 15:00:09 | Train | Epoch[552/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:00:09 | Train | Epoch[552/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:00:09 | Train | Epoch[552/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:00:09 | Train | Epoch[552/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 15:00:10 | Train | Epoch[552/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:00:10 | Train | Epoch[552/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:00:10 | Train | Epoch[552/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:00:10 | Train | Epoch[552/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:00:11 | Train | Epoch[552/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:00:11 | Train | Epoch[552/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:00:11 | Train | Epoch[552/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:00:11 | Train | Epoch[552/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:00:11 | Train | Epoch[552/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:00:12 | Train | Epoch[552/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:00:12 | Train | Epoch[552/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:00:12 | Train | Epoch[552/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:00:12 | Train | Epoch[552/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:00:13 | Valid | Epoch[552/600] Iteration[001/008] Valid loss: 0.1820
2023-02-06 15:00:13 | Valid | Epoch[552/600] Iteration[002/008] Valid loss: 0.1451
2023-02-06 15:00:13 | Valid | Epoch[552/600] Iteration[003/008] Valid loss: 0.1370
2023-02-06 15:00:13 | Valid | Epoch[552/600] Iteration[004/008] Valid loss: 0.1302
2023-02-06 15:00:13 | Valid | Epoch[552/600] Iteration[005/008] Valid loss: 0.1289
2023-02-06 15:00:13 | Valid | Epoch[552/600] Iteration[006/008] Valid loss: 0.1244
2023-02-06 15:00:13 | Valid | Epoch[552/600] Iteration[007/008] Valid loss: 0.1331
2023-02-06 15:00:13 | Valid | Epoch[552/600] Iteration[008/008] Valid loss: 0.1316
2023-02-06 15:00:13 | Valid | Epoch[552/600] MIou: 0.9302433806678421
2023-02-06 15:00:13 | Valid | Epoch[552/600] Pixel Accuracy: 0.9879379272460938
2023-02-06 15:00:13 | Valid | Epoch[552/600] Mean Pixel Accuracy: 0.9588780053537782
2023-02-06 15:00:13 | Stage | Epoch[552/600] Train loss:0.0075
2023-02-06 15:00:13 | Stage | Epoch[552/600] Valid loss:0.1316
2023-02-06 15:00:13 | Stage | Epoch[552/600] LR:0.0001

2023-02-06 15:00:14 | Train | Epoch[553/600] Iteration[001/030] Train loss: 0.0069
2023-02-06 15:00:14 | Train | Epoch[553/600] Iteration[002/030] Train loss: 0.0069
2023-02-06 15:00:14 | Train | Epoch[553/600] Iteration[003/030] Train loss: 0.0071
2023-02-06 15:00:14 | Train | Epoch[553/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 15:00:14 | Train | Epoch[553/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 15:00:15 | Train | Epoch[553/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 15:00:15 | Train | Epoch[553/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 15:00:15 | Train | Epoch[553/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:00:15 | Train | Epoch[553/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 15:00:15 | Train | Epoch[553/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 15:00:16 | Train | Epoch[553/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 15:00:16 | Train | Epoch[553/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:00:16 | Train | Epoch[553/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:00:16 | Train | Epoch[553/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 15:00:17 | Train | Epoch[553/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 15:00:17 | Train | Epoch[553/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 15:00:17 | Train | Epoch[553/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 15:00:17 | Train | Epoch[553/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 15:00:17 | Train | Epoch[553/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 15:00:18 | Train | Epoch[553/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 15:00:18 | Train | Epoch[553/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 15:00:18 | Train | Epoch[553/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 15:00:18 | Train | Epoch[553/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 15:00:19 | Train | Epoch[553/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 15:00:19 | Train | Epoch[553/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 15:00:19 | Train | Epoch[553/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 15:00:19 | Train | Epoch[553/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:00:19 | Train | Epoch[553/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:00:20 | Train | Epoch[553/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:00:20 | Train | Epoch[553/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 15:00:20 | Valid | Epoch[553/600] Iteration[001/008] Valid loss: 0.1897
2023-02-06 15:00:20 | Valid | Epoch[553/600] Iteration[002/008] Valid loss: 0.1515
2023-02-06 15:00:20 | Valid | Epoch[553/600] Iteration[003/008] Valid loss: 0.1430
2023-02-06 15:00:20 | Valid | Epoch[553/600] Iteration[004/008] Valid loss: 0.1359
2023-02-06 15:00:20 | Valid | Epoch[553/600] Iteration[005/008] Valid loss: 0.1347
2023-02-06 15:00:20 | Valid | Epoch[553/600] Iteration[006/008] Valid loss: 0.1304
2023-02-06 15:00:20 | Valid | Epoch[553/600] Iteration[007/008] Valid loss: 0.1395
2023-02-06 15:00:20 | Valid | Epoch[553/600] Iteration[008/008] Valid loss: 0.1380
2023-02-06 15:00:21 | Valid | Epoch[553/600] MIou: 0.9304615190663457
2023-02-06 15:00:21 | Valid | Epoch[553/600] Pixel Accuracy: 0.9879557291666666
2023-02-06 15:00:21 | Valid | Epoch[553/600] Mean Pixel Accuracy: 0.9598578821899069
2023-02-06 15:00:21 | Stage | Epoch[553/600] Train loss:0.0077
2023-02-06 15:00:21 | Stage | Epoch[553/600] Valid loss:0.1380
2023-02-06 15:00:21 | Stage | Epoch[553/600] LR:0.0001

2023-02-06 15:00:21 | Train | Epoch[554/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 15:00:21 | Train | Epoch[554/600] Iteration[002/030] Train loss: 0.0068
2023-02-06 15:00:21 | Train | Epoch[554/600] Iteration[003/030] Train loss: 0.0065
2023-02-06 15:00:22 | Train | Epoch[554/600] Iteration[004/030] Train loss: 0.0066
2023-02-06 15:00:22 | Train | Epoch[554/600] Iteration[005/030] Train loss: 0.0067
2023-02-06 15:00:22 | Train | Epoch[554/600] Iteration[006/030] Train loss: 0.0068
2023-02-06 15:00:22 | Train | Epoch[554/600] Iteration[007/030] Train loss: 0.0069
2023-02-06 15:00:23 | Train | Epoch[554/600] Iteration[008/030] Train loss: 0.0069
2023-02-06 15:00:23 | Train | Epoch[554/600] Iteration[009/030] Train loss: 0.0071
2023-02-06 15:00:23 | Train | Epoch[554/600] Iteration[010/030] Train loss: 0.0071
2023-02-06 15:00:23 | Train | Epoch[554/600] Iteration[011/030] Train loss: 0.0072
2023-02-06 15:00:23 | Train | Epoch[554/600] Iteration[012/030] Train loss: 0.0072
2023-02-06 15:00:24 | Train | Epoch[554/600] Iteration[013/030] Train loss: 0.0072
2023-02-06 15:00:24 | Train | Epoch[554/600] Iteration[014/030] Train loss: 0.0072
2023-02-06 15:00:24 | Train | Epoch[554/600] Iteration[015/030] Train loss: 0.0072
2023-02-06 15:00:24 | Train | Epoch[554/600] Iteration[016/030] Train loss: 0.0072
2023-02-06 15:00:25 | Train | Epoch[554/600] Iteration[017/030] Train loss: 0.0072
2023-02-06 15:00:25 | Train | Epoch[554/600] Iteration[018/030] Train loss: 0.0073
2023-02-06 15:00:25 | Train | Epoch[554/600] Iteration[019/030] Train loss: 0.0073
2023-02-06 15:00:25 | Train | Epoch[554/600] Iteration[020/030] Train loss: 0.0073
2023-02-06 15:00:25 | Train | Epoch[554/600] Iteration[021/030] Train loss: 0.0073
2023-02-06 15:00:26 | Train | Epoch[554/600] Iteration[022/030] Train loss: 0.0073
2023-02-06 15:00:26 | Train | Epoch[554/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:00:26 | Train | Epoch[554/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:00:26 | Train | Epoch[554/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:00:27 | Train | Epoch[554/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 15:00:27 | Train | Epoch[554/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:00:27 | Train | Epoch[554/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 15:00:27 | Train | Epoch[554/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 15:00:27 | Train | Epoch[554/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:00:28 | Valid | Epoch[554/600] Iteration[001/008] Valid loss: 0.1701
2023-02-06 15:00:28 | Valid | Epoch[554/600] Iteration[002/008] Valid loss: 0.1344
2023-02-06 15:00:28 | Valid | Epoch[554/600] Iteration[003/008] Valid loss: 0.1266
2023-02-06 15:00:28 | Valid | Epoch[554/600] Iteration[004/008] Valid loss: 0.1200
2023-02-06 15:00:28 | Valid | Epoch[554/600] Iteration[005/008] Valid loss: 0.1180
2023-02-06 15:00:28 | Valid | Epoch[554/600] Iteration[006/008] Valid loss: 0.1137
2023-02-06 15:00:28 | Valid | Epoch[554/600] Iteration[007/008] Valid loss: 0.1211
2023-02-06 15:00:28 | Valid | Epoch[554/600] Iteration[008/008] Valid loss: 0.1195
2023-02-06 15:00:28 | Valid | Epoch[554/600] MIou: 0.9287241302667952
2023-02-06 15:00:28 | Valid | Epoch[554/600] Pixel Accuracy: 0.9877357482910156
2023-02-06 15:00:28 | Valid | Epoch[554/600] Mean Pixel Accuracy: 0.9551401294724338
2023-02-06 15:00:28 | Stage | Epoch[554/600] Train loss:0.0075
2023-02-06 15:00:28 | Stage | Epoch[554/600] Valid loss:0.1195
2023-02-06 15:00:28 | Stage | Epoch[554/600] LR:0.0001

2023-02-06 15:00:29 | Train | Epoch[555/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 15:00:29 | Train | Epoch[555/600] Iteration[002/030] Train loss: 0.0086
2023-02-06 15:00:29 | Train | Epoch[555/600] Iteration[003/030] Train loss: 0.0084
2023-02-06 15:00:29 | Train | Epoch[555/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 15:00:29 | Train | Epoch[555/600] Iteration[005/030] Train loss: 0.0081
2023-02-06 15:00:30 | Train | Epoch[555/600] Iteration[006/030] Train loss: 0.0082
2023-02-06 15:00:30 | Train | Epoch[555/600] Iteration[007/030] Train loss: 0.0082
2023-02-06 15:00:30 | Train | Epoch[555/600] Iteration[008/030] Train loss: 0.0085
2023-02-06 15:00:30 | Train | Epoch[555/600] Iteration[009/030] Train loss: 0.0084
2023-02-06 15:00:31 | Train | Epoch[555/600] Iteration[010/030] Train loss: 0.0084
2023-02-06 15:00:31 | Train | Epoch[555/600] Iteration[011/030] Train loss: 0.0084
2023-02-06 15:00:31 | Train | Epoch[555/600] Iteration[012/030] Train loss: 0.0083
2023-02-06 15:00:31 | Train | Epoch[555/600] Iteration[013/030] Train loss: 0.0083
2023-02-06 15:00:31 | Train | Epoch[555/600] Iteration[014/030] Train loss: 0.0082
2023-02-06 15:00:32 | Train | Epoch[555/600] Iteration[015/030] Train loss: 0.0081
2023-02-06 15:00:32 | Train | Epoch[555/600] Iteration[016/030] Train loss: 0.0082
2023-02-06 15:00:32 | Train | Epoch[555/600] Iteration[017/030] Train loss: 0.0081
2023-02-06 15:00:32 | Train | Epoch[555/600] Iteration[018/030] Train loss: 0.0080
2023-02-06 15:00:33 | Train | Epoch[555/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 15:00:33 | Train | Epoch[555/600] Iteration[020/030] Train loss: 0.0079
2023-02-06 15:00:33 | Train | Epoch[555/600] Iteration[021/030] Train loss: 0.0079
2023-02-06 15:00:33 | Train | Epoch[555/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 15:00:33 | Train | Epoch[555/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 15:00:34 | Train | Epoch[555/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 15:00:34 | Train | Epoch[555/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 15:00:34 | Train | Epoch[555/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 15:00:34 | Train | Epoch[555/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 15:00:34 | Train | Epoch[555/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 15:00:35 | Train | Epoch[555/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 15:00:35 | Train | Epoch[555/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 15:00:35 | Valid | Epoch[555/600] Iteration[001/008] Valid loss: 0.1851
2023-02-06 15:00:35 | Valid | Epoch[555/600] Iteration[002/008] Valid loss: 0.1473
2023-02-06 15:00:35 | Valid | Epoch[555/600] Iteration[003/008] Valid loss: 0.1393
2023-02-06 15:00:35 | Valid | Epoch[555/600] Iteration[004/008] Valid loss: 0.1322
2023-02-06 15:00:35 | Valid | Epoch[555/600] Iteration[005/008] Valid loss: 0.1308
2023-02-06 15:00:35 | Valid | Epoch[555/600] Iteration[006/008] Valid loss: 0.1264
2023-02-06 15:00:35 | Valid | Epoch[555/600] Iteration[007/008] Valid loss: 0.1352
2023-02-06 15:00:36 | Valid | Epoch[555/600] Iteration[008/008] Valid loss: 0.1335
2023-02-06 15:00:36 | Valid | Epoch[555/600] MIou: 0.9304568293661215
2023-02-06 15:00:36 | Valid | Epoch[555/600] Pixel Accuracy: 0.9879786173502604
2023-02-06 15:00:36 | Valid | Epoch[555/600] Mean Pixel Accuracy: 0.9589384131994917
2023-02-06 15:00:36 | Stage | Epoch[555/600] Train loss:0.0077
2023-02-06 15:00:36 | Stage | Epoch[555/600] Valid loss:0.1335
2023-02-06 15:00:36 | Stage | Epoch[555/600] LR:0.0001

2023-02-06 15:00:36 | Train | Epoch[556/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 15:00:36 | Train | Epoch[556/600] Iteration[002/030] Train loss: 0.0073
2023-02-06 15:00:37 | Train | Epoch[556/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 15:00:37 | Train | Epoch[556/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 15:00:37 | Train | Epoch[556/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 15:00:37 | Train | Epoch[556/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 15:00:37 | Train | Epoch[556/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 15:00:38 | Train | Epoch[556/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:00:38 | Train | Epoch[556/600] Iteration[009/030] Train loss: 0.0077
2023-02-06 15:00:38 | Train | Epoch[556/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 15:00:38 | Train | Epoch[556/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 15:00:39 | Train | Epoch[556/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:00:39 | Train | Epoch[556/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:00:39 | Train | Epoch[556/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:00:39 | Train | Epoch[556/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 15:00:39 | Train | Epoch[556/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 15:00:40 | Train | Epoch[556/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 15:00:40 | Train | Epoch[556/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:00:40 | Train | Epoch[556/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:00:40 | Train | Epoch[556/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:00:41 | Train | Epoch[556/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 15:00:41 | Train | Epoch[556/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:00:41 | Train | Epoch[556/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:00:41 | Train | Epoch[556/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:00:41 | Train | Epoch[556/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:00:42 | Train | Epoch[556/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:00:42 | Train | Epoch[556/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:00:42 | Train | Epoch[556/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:00:42 | Train | Epoch[556/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:00:42 | Train | Epoch[556/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:00:43 | Valid | Epoch[556/600] Iteration[001/008] Valid loss: 0.1889
2023-02-06 15:00:43 | Valid | Epoch[556/600] Iteration[002/008] Valid loss: 0.1502
2023-02-06 15:00:43 | Valid | Epoch[556/600] Iteration[003/008] Valid loss: 0.1420
2023-02-06 15:00:43 | Valid | Epoch[556/600] Iteration[004/008] Valid loss: 0.1345
2023-02-06 15:00:43 | Valid | Epoch[556/600] Iteration[005/008] Valid loss: 0.1330
2023-02-06 15:00:43 | Valid | Epoch[556/600] Iteration[006/008] Valid loss: 0.1289
2023-02-06 15:00:43 | Valid | Epoch[556/600] Iteration[007/008] Valid loss: 0.1379
2023-02-06 15:00:43 | Valid | Epoch[556/600] Iteration[008/008] Valid loss: 0.1364
2023-02-06 15:00:43 | Valid | Epoch[556/600] MIou: 0.9298672356249078
2023-02-06 15:00:43 | Valid | Epoch[556/600] Pixel Accuracy: 0.9878552754720052
2023-02-06 15:00:43 | Valid | Epoch[556/600] Mean Pixel Accuracy: 0.9591876428184027
2023-02-06 15:00:43 | Stage | Epoch[556/600] Train loss:0.0075
2023-02-06 15:00:43 | Stage | Epoch[556/600] Valid loss:0.1364
2023-02-06 15:00:43 | Stage | Epoch[556/600] LR:0.0001

2023-02-06 15:00:44 | Train | Epoch[557/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 15:00:44 | Train | Epoch[557/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 15:00:44 | Train | Epoch[557/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 15:00:44 | Train | Epoch[557/600] Iteration[004/030] Train loss: 0.0086
2023-02-06 15:00:45 | Train | Epoch[557/600] Iteration[005/030] Train loss: 0.0084
2023-02-06 15:00:45 | Train | Epoch[557/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 15:00:45 | Train | Epoch[557/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 15:00:45 | Train | Epoch[557/600] Iteration[008/030] Train loss: 0.0078
2023-02-06 15:00:45 | Train | Epoch[557/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 15:00:46 | Train | Epoch[557/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 15:00:46 | Train | Epoch[557/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 15:00:46 | Train | Epoch[557/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 15:00:46 | Train | Epoch[557/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:00:47 | Train | Epoch[557/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:00:47 | Train | Epoch[557/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:00:47 | Train | Epoch[557/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 15:00:47 | Train | Epoch[557/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 15:00:47 | Train | Epoch[557/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 15:00:48 | Train | Epoch[557/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 15:00:48 | Train | Epoch[557/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 15:00:48 | Train | Epoch[557/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 15:00:48 | Train | Epoch[557/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 15:00:48 | Train | Epoch[557/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 15:00:49 | Train | Epoch[557/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 15:00:49 | Train | Epoch[557/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:00:49 | Train | Epoch[557/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:00:49 | Train | Epoch[557/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:00:50 | Train | Epoch[557/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:00:50 | Train | Epoch[557/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 15:00:50 | Train | Epoch[557/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 15:00:50 | Valid | Epoch[557/600] Iteration[001/008] Valid loss: 0.1823
2023-02-06 15:00:50 | Valid | Epoch[557/600] Iteration[002/008] Valid loss: 0.1437
2023-02-06 15:00:50 | Valid | Epoch[557/600] Iteration[003/008] Valid loss: 0.1355
2023-02-06 15:00:50 | Valid | Epoch[557/600] Iteration[004/008] Valid loss: 0.1284
2023-02-06 15:00:50 | Valid | Epoch[557/600] Iteration[005/008] Valid loss: 0.1268
2023-02-06 15:00:51 | Valid | Epoch[557/600] Iteration[006/008] Valid loss: 0.1225
2023-02-06 15:00:51 | Valid | Epoch[557/600] Iteration[007/008] Valid loss: 0.1309
2023-02-06 15:00:51 | Valid | Epoch[557/600] Iteration[008/008] Valid loss: 0.1293
2023-02-06 15:00:51 | Valid | Epoch[557/600] MIou: 0.929405420354249
2023-02-06 15:00:51 | Valid | Epoch[557/600] Pixel Accuracy: 0.9878056844075521
2023-02-06 15:00:51 | Valid | Epoch[557/600] Mean Pixel Accuracy: 0.9575879485193757
2023-02-06 15:00:51 | Stage | Epoch[557/600] Train loss:0.0077
2023-02-06 15:00:51 | Stage | Epoch[557/600] Valid loss:0.1293
2023-02-06 15:00:51 | Stage | Epoch[557/600] LR:0.0001

2023-02-06 15:00:51 | Train | Epoch[558/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 15:00:51 | Train | Epoch[558/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 15:00:52 | Train | Epoch[558/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 15:00:52 | Train | Epoch[558/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 15:00:52 | Train | Epoch[558/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 15:00:52 | Train | Epoch[558/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 15:00:53 | Train | Epoch[558/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 15:00:53 | Train | Epoch[558/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 15:00:53 | Train | Epoch[558/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 15:00:53 | Train | Epoch[558/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 15:00:53 | Train | Epoch[558/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 15:00:54 | Train | Epoch[558/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 15:00:54 | Train | Epoch[558/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 15:00:54 | Train | Epoch[558/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:00:54 | Train | Epoch[558/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:00:54 | Train | Epoch[558/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:00:55 | Train | Epoch[558/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:00:55 | Train | Epoch[558/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:00:55 | Train | Epoch[558/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:00:55 | Train | Epoch[558/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:00:56 | Train | Epoch[558/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:00:56 | Train | Epoch[558/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:00:56 | Train | Epoch[558/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:00:56 | Train | Epoch[558/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:00:56 | Train | Epoch[558/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:00:57 | Train | Epoch[558/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 15:00:57 | Train | Epoch[558/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:00:57 | Train | Epoch[558/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:00:57 | Train | Epoch[558/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:00:57 | Train | Epoch[558/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:00:58 | Valid | Epoch[558/600] Iteration[001/008] Valid loss: 0.1807
2023-02-06 15:00:58 | Valid | Epoch[558/600] Iteration[002/008] Valid loss: 0.1436
2023-02-06 15:00:58 | Valid | Epoch[558/600] Iteration[003/008] Valid loss: 0.1357
2023-02-06 15:00:58 | Valid | Epoch[558/600] Iteration[004/008] Valid loss: 0.1286
2023-02-06 15:00:58 | Valid | Epoch[558/600] Iteration[005/008] Valid loss: 0.1272
2023-02-06 15:00:58 | Valid | Epoch[558/600] Iteration[006/008] Valid loss: 0.1228
2023-02-06 15:00:58 | Valid | Epoch[558/600] Iteration[007/008] Valid loss: 0.1310
2023-02-06 15:00:58 | Valid | Epoch[558/600] Iteration[008/008] Valid loss: 0.1293
2023-02-06 15:00:58 | Valid | Epoch[558/600] MIou: 0.9300523923716963
2023-02-06 15:00:58 | Valid | Epoch[558/600] Pixel Accuracy: 0.9879239400227865
2023-02-06 15:00:58 | Valid | Epoch[558/600] Mean Pixel Accuracy: 0.9579636299530805
2023-02-06 15:00:58 | Stage | Epoch[558/600] Train loss:0.0075
2023-02-06 15:00:58 | Stage | Epoch[558/600] Valid loss:0.1293
2023-02-06 15:00:58 | Stage | Epoch[558/600] LR:0.0001

2023-02-06 15:00:59 | Train | Epoch[559/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 15:00:59 | Train | Epoch[559/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 15:00:59 | Train | Epoch[559/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 15:00:59 | Train | Epoch[559/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 15:01:00 | Train | Epoch[559/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 15:01:00 | Train | Epoch[559/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 15:01:00 | Train | Epoch[559/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 15:01:00 | Train | Epoch[559/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 15:01:00 | Train | Epoch[559/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 15:01:01 | Train | Epoch[559/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 15:01:01 | Train | Epoch[559/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:01:01 | Train | Epoch[559/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 15:01:01 | Train | Epoch[559/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 15:01:02 | Train | Epoch[559/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 15:01:02 | Train | Epoch[559/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 15:01:02 | Train | Epoch[559/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 15:01:02 | Train | Epoch[559/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 15:01:02 | Train | Epoch[559/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 15:01:03 | Train | Epoch[559/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 15:01:03 | Train | Epoch[559/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 15:01:03 | Train | Epoch[559/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:01:03 | Train | Epoch[559/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:01:04 | Train | Epoch[559/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:01:04 | Train | Epoch[559/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:01:04 | Train | Epoch[559/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:01:04 | Train | Epoch[559/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:01:04 | Train | Epoch[559/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:01:05 | Train | Epoch[559/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:01:05 | Train | Epoch[559/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:01:05 | Train | Epoch[559/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:01:05 | Valid | Epoch[559/600] Iteration[001/008] Valid loss: 0.1829
2023-02-06 15:01:05 | Valid | Epoch[559/600] Iteration[002/008] Valid loss: 0.1458
2023-02-06 15:01:05 | Valid | Epoch[559/600] Iteration[003/008] Valid loss: 0.1377
2023-02-06 15:01:05 | Valid | Epoch[559/600] Iteration[004/008] Valid loss: 0.1308
2023-02-06 15:01:06 | Valid | Epoch[559/600] Iteration[005/008] Valid loss: 0.1292
2023-02-06 15:01:06 | Valid | Epoch[559/600] Iteration[006/008] Valid loss: 0.1249
2023-02-06 15:01:06 | Valid | Epoch[559/600] Iteration[007/008] Valid loss: 0.1334
2023-02-06 15:01:06 | Valid | Epoch[559/600] Iteration[008/008] Valid loss: 0.1318
2023-02-06 15:01:06 | Valid | Epoch[559/600] MIou: 0.9301907413258859
2023-02-06 15:01:06 | Valid | Epoch[559/600] Pixel Accuracy: 0.987939198811849
2023-02-06 15:01:06 | Valid | Epoch[559/600] Mean Pixel Accuracy: 0.9584285307831906
2023-02-06 15:01:06 | Stage | Epoch[559/600] Train loss:0.0075
2023-02-06 15:01:06 | Stage | Epoch[559/600] Valid loss:0.1318
2023-02-06 15:01:06 | Stage | Epoch[559/600] LR:0.0001

2023-02-06 15:01:06 | Train | Epoch[560/600] Iteration[001/030] Train loss: 0.0065
2023-02-06 15:01:06 | Train | Epoch[560/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 15:01:07 | Train | Epoch[560/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 15:01:07 | Train | Epoch[560/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 15:01:07 | Train | Epoch[560/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 15:01:07 | Train | Epoch[560/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 15:01:08 | Train | Epoch[560/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 15:01:08 | Train | Epoch[560/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:01:08 | Train | Epoch[560/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 15:01:08 | Train | Epoch[560/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 15:01:08 | Train | Epoch[560/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 15:01:09 | Train | Epoch[560/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 15:01:09 | Train | Epoch[560/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 15:01:09 | Train | Epoch[560/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:01:09 | Train | Epoch[560/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:01:10 | Train | Epoch[560/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 15:01:10 | Train | Epoch[560/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:01:10 | Train | Epoch[560/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:01:10 | Train | Epoch[560/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:01:10 | Train | Epoch[560/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:01:11 | Train | Epoch[560/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 15:01:11 | Train | Epoch[560/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 15:01:11 | Train | Epoch[560/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 15:01:11 | Train | Epoch[560/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 15:01:11 | Train | Epoch[560/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 15:01:12 | Train | Epoch[560/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 15:01:12 | Train | Epoch[560/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:01:12 | Train | Epoch[560/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:01:12 | Train | Epoch[560/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 15:01:12 | Train | Epoch[560/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:01:13 | Valid | Epoch[560/600] Iteration[001/008] Valid loss: 0.1688
2023-02-06 15:01:13 | Valid | Epoch[560/600] Iteration[002/008] Valid loss: 0.1343
2023-02-06 15:01:13 | Valid | Epoch[560/600] Iteration[003/008] Valid loss: 0.1270
2023-02-06 15:01:13 | Valid | Epoch[560/600] Iteration[004/008] Valid loss: 0.1205
2023-02-06 15:01:13 | Valid | Epoch[560/600] Iteration[005/008] Valid loss: 0.1187
2023-02-06 15:01:13 | Valid | Epoch[560/600] Iteration[006/008] Valid loss: 0.1144
2023-02-06 15:01:13 | Valid | Epoch[560/600] Iteration[007/008] Valid loss: 0.1219
2023-02-06 15:01:13 | Valid | Epoch[560/600] Iteration[008/008] Valid loss: 0.1201
2023-02-06 15:01:13 | Valid | Epoch[560/600] MIou: 0.9293146635914304
2023-02-06 15:01:13 | Valid | Epoch[560/600] Pixel Accuracy: 0.9878412882486979
2023-02-06 15:01:13 | Valid | Epoch[560/600] Mean Pixel Accuracy: 0.9555595456105348
2023-02-06 15:01:13 | Stage | Epoch[560/600] Train loss:0.0076
2023-02-06 15:01:13 | Stage | Epoch[560/600] Valid loss:0.1201
2023-02-06 15:01:13 | Stage | Epoch[560/600] LR:0.0001

2023-02-06 15:01:14 | Train | Epoch[561/600] Iteration[001/030] Train loss: 0.0076
2023-02-06 15:01:14 | Train | Epoch[561/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 15:01:14 | Train | Epoch[561/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 15:01:14 | Train | Epoch[561/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 15:01:15 | Train | Epoch[561/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 15:01:15 | Train | Epoch[561/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 15:01:15 | Train | Epoch[561/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 15:01:15 | Train | Epoch[561/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 15:01:16 | Train | Epoch[561/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 15:01:16 | Train | Epoch[561/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 15:01:16 | Train | Epoch[561/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 15:01:16 | Train | Epoch[561/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 15:01:16 | Train | Epoch[561/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:01:17 | Train | Epoch[561/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:01:17 | Train | Epoch[561/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:01:17 | Train | Epoch[561/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 15:01:17 | Train | Epoch[561/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:01:18 | Train | Epoch[561/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:01:18 | Train | Epoch[561/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 15:01:18 | Train | Epoch[561/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 15:01:18 | Train | Epoch[561/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 15:01:18 | Train | Epoch[561/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 15:01:19 | Train | Epoch[561/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 15:01:19 | Train | Epoch[561/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 15:01:19 | Train | Epoch[561/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 15:01:19 | Train | Epoch[561/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:01:20 | Train | Epoch[561/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:01:20 | Train | Epoch[561/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:01:20 | Train | Epoch[561/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 15:01:20 | Train | Epoch[561/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:01:20 | Valid | Epoch[561/600] Iteration[001/008] Valid loss: 0.1799
2023-02-06 15:01:20 | Valid | Epoch[561/600] Iteration[002/008] Valid loss: 0.1426
2023-02-06 15:01:21 | Valid | Epoch[561/600] Iteration[003/008] Valid loss: 0.1348
2023-02-06 15:01:21 | Valid | Epoch[561/600] Iteration[004/008] Valid loss: 0.1278
2023-02-06 15:01:21 | Valid | Epoch[561/600] Iteration[005/008] Valid loss: 0.1262
2023-02-06 15:01:21 | Valid | Epoch[561/600] Iteration[006/008] Valid loss: 0.1220
2023-02-06 15:01:21 | Valid | Epoch[561/600] Iteration[007/008] Valid loss: 0.1303
2023-02-06 15:01:21 | Valid | Epoch[561/600] Iteration[008/008] Valid loss: 0.1287
2023-02-06 15:01:21 | Valid | Epoch[561/600] MIou: 0.9298695949824151
2023-02-06 15:01:21 | Valid | Epoch[561/600] Pixel Accuracy: 0.9878959655761719
2023-02-06 15:01:21 | Valid | Epoch[561/600] Mean Pixel Accuracy: 0.9576502518430721
2023-02-06 15:01:21 | Stage | Epoch[561/600] Train loss:0.0076
2023-02-06 15:01:21 | Stage | Epoch[561/600] Valid loss:0.1287
2023-02-06 15:01:21 | Stage | Epoch[561/600] LR:0.0001

2023-02-06 15:01:21 | Train | Epoch[562/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 15:01:22 | Train | Epoch[562/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 15:01:22 | Train | Epoch[562/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 15:01:22 | Train | Epoch[562/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 15:01:22 | Train | Epoch[562/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 15:01:22 | Train | Epoch[562/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 15:01:23 | Train | Epoch[562/600] Iteration[007/030] Train loss: 0.0072
2023-02-06 15:01:23 | Train | Epoch[562/600] Iteration[008/030] Train loss: 0.0073
2023-02-06 15:01:23 | Train | Epoch[562/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 15:01:23 | Train | Epoch[562/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 15:01:23 | Train | Epoch[562/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:01:24 | Train | Epoch[562/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:01:24 | Train | Epoch[562/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:01:24 | Train | Epoch[562/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:01:24 | Train | Epoch[562/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 15:01:25 | Train | Epoch[562/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 15:01:25 | Train | Epoch[562/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 15:01:25 | Train | Epoch[562/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:01:25 | Train | Epoch[562/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:01:25 | Train | Epoch[562/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:01:26 | Train | Epoch[562/600] Iteration[021/030] Train loss: 0.0073
2023-02-06 15:01:26 | Train | Epoch[562/600] Iteration[022/030] Train loss: 0.0073
2023-02-06 15:01:26 | Train | Epoch[562/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:01:26 | Train | Epoch[562/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:01:27 | Train | Epoch[562/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:01:27 | Train | Epoch[562/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:01:27 | Train | Epoch[562/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:01:27 | Train | Epoch[562/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:01:27 | Train | Epoch[562/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:01:28 | Train | Epoch[562/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:01:28 | Valid | Epoch[562/600] Iteration[001/008] Valid loss: 0.1804
2023-02-06 15:01:28 | Valid | Epoch[562/600] Iteration[002/008] Valid loss: 0.1426
2023-02-06 15:01:28 | Valid | Epoch[562/600] Iteration[003/008] Valid loss: 0.1348
2023-02-06 15:01:28 | Valid | Epoch[562/600] Iteration[004/008] Valid loss: 0.1276
2023-02-06 15:01:28 | Valid | Epoch[562/600] Iteration[005/008] Valid loss: 0.1257
2023-02-06 15:01:28 | Valid | Epoch[562/600] Iteration[006/008] Valid loss: 0.1216
2023-02-06 15:01:28 | Valid | Epoch[562/600] Iteration[007/008] Valid loss: 0.1298
2023-02-06 15:01:28 | Valid | Epoch[562/600] Iteration[008/008] Valid loss: 0.1281
2023-02-06 15:01:28 | Valid | Epoch[562/600] MIou: 0.9296761631147714
2023-02-06 15:01:28 | Valid | Epoch[562/600] Pixel Accuracy: 0.9878705342610677
2023-02-06 15:01:28 | Valid | Epoch[562/600] Mean Pixel Accuracy: 0.9571607383442655
2023-02-06 15:01:28 | Stage | Epoch[562/600] Train loss:0.0075
2023-02-06 15:01:28 | Stage | Epoch[562/600] Valid loss:0.1281
2023-02-06 15:01:28 | Stage | Epoch[562/600] LR:0.0001

2023-02-06 15:01:29 | Train | Epoch[563/600] Iteration[001/030] Train loss: 0.0076
2023-02-06 15:01:29 | Train | Epoch[563/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 15:01:29 | Train | Epoch[563/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 15:01:29 | Train | Epoch[563/600] Iteration[004/030] Train loss: 0.0100
2023-02-06 15:01:30 | Train | Epoch[563/600] Iteration[005/030] Train loss: 0.0095
2023-02-06 15:01:30 | Train | Epoch[563/600] Iteration[006/030] Train loss: 0.0093
2023-02-06 15:01:30 | Train | Epoch[563/600] Iteration[007/030] Train loss: 0.0090
2023-02-06 15:01:30 | Train | Epoch[563/600] Iteration[008/030] Train loss: 0.0090
2023-02-06 15:01:31 | Train | Epoch[563/600] Iteration[009/030] Train loss: 0.0087
2023-02-06 15:01:31 | Train | Epoch[563/600] Iteration[010/030] Train loss: 0.0086
2023-02-06 15:01:31 | Train | Epoch[563/600] Iteration[011/030] Train loss: 0.0085
2023-02-06 15:01:31 | Train | Epoch[563/600] Iteration[012/030] Train loss: 0.0084
2023-02-06 15:01:31 | Train | Epoch[563/600] Iteration[013/030] Train loss: 0.0083
2023-02-06 15:01:32 | Train | Epoch[563/600] Iteration[014/030] Train loss: 0.0082
2023-02-06 15:01:32 | Train | Epoch[563/600] Iteration[015/030] Train loss: 0.0082
2023-02-06 15:01:32 | Train | Epoch[563/600] Iteration[016/030] Train loss: 0.0082
2023-02-06 15:01:32 | Train | Epoch[563/600] Iteration[017/030] Train loss: 0.0082
2023-02-06 15:01:33 | Train | Epoch[563/600] Iteration[018/030] Train loss: 0.0081
2023-02-06 15:01:33 | Train | Epoch[563/600] Iteration[019/030] Train loss: 0.0080
2023-02-06 15:01:33 | Train | Epoch[563/600] Iteration[020/030] Train loss: 0.0081
2023-02-06 15:01:33 | Train | Epoch[563/600] Iteration[021/030] Train loss: 0.0081
2023-02-06 15:01:33 | Train | Epoch[563/600] Iteration[022/030] Train loss: 0.0080
2023-02-06 15:01:34 | Train | Epoch[563/600] Iteration[023/030] Train loss: 0.0080
2023-02-06 15:01:34 | Train | Epoch[563/600] Iteration[024/030] Train loss: 0.0079
2023-02-06 15:01:34 | Train | Epoch[563/600] Iteration[025/030] Train loss: 0.0080
2023-02-06 15:01:34 | Train | Epoch[563/600] Iteration[026/030] Train loss: 0.0080
2023-02-06 15:01:35 | Train | Epoch[563/600] Iteration[027/030] Train loss: 0.0079
2023-02-06 15:01:35 | Train | Epoch[563/600] Iteration[028/030] Train loss: 0.0079
2023-02-06 15:01:35 | Train | Epoch[563/600] Iteration[029/030] Train loss: 0.0079
2023-02-06 15:01:35 | Train | Epoch[563/600] Iteration[030/030] Train loss: 0.0079
2023-02-06 15:01:35 | Valid | Epoch[563/600] Iteration[001/008] Valid loss: 0.1622
2023-02-06 15:01:35 | Valid | Epoch[563/600] Iteration[002/008] Valid loss: 0.1291
2023-02-06 15:01:36 | Valid | Epoch[563/600] Iteration[003/008] Valid loss: 0.1219
2023-02-06 15:01:36 | Valid | Epoch[563/600] Iteration[004/008] Valid loss: 0.1156
2023-02-06 15:01:36 | Valid | Epoch[563/600] Iteration[005/008] Valid loss: 0.1136
2023-02-06 15:01:36 | Valid | Epoch[563/600] Iteration[006/008] Valid loss: 0.1094
2023-02-06 15:01:36 | Valid | Epoch[563/600] Iteration[007/008] Valid loss: 0.1161
2023-02-06 15:01:36 | Valid | Epoch[563/600] Iteration[008/008] Valid loss: 0.1143
2023-02-06 15:01:36 | Valid | Epoch[563/600] MIou: 0.9292283206861773
2023-02-06 15:01:36 | Valid | Epoch[563/600] Pixel Accuracy: 0.9878514607747396
2023-02-06 15:01:36 | Valid | Epoch[563/600] Mean Pixel Accuracy: 0.9545316400082261
2023-02-06 15:01:36 | Stage | Epoch[563/600] Train loss:0.0079
2023-02-06 15:01:36 | Stage | Epoch[563/600] Valid loss:0.1143
2023-02-06 15:01:36 | Stage | Epoch[563/600] LR:0.0001

2023-02-06 15:01:36 | Train | Epoch[564/600] Iteration[001/030] Train loss: 0.0078
2023-02-06 15:01:37 | Train | Epoch[564/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 15:01:37 | Train | Epoch[564/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 15:01:37 | Train | Epoch[564/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 15:01:37 | Train | Epoch[564/600] Iteration[005/030] Train loss: 0.0072
2023-02-06 15:01:37 | Train | Epoch[564/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 15:01:38 | Train | Epoch[564/600] Iteration[007/030] Train loss: 0.0072
2023-02-06 15:01:38 | Train | Epoch[564/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 15:01:38 | Train | Epoch[564/600] Iteration[009/030] Train loss: 0.0072
2023-02-06 15:01:38 | Train | Epoch[564/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 15:01:39 | Train | Epoch[564/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 15:01:39 | Train | Epoch[564/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 15:01:39 | Train | Epoch[564/600] Iteration[013/030] Train loss: 0.0073
2023-02-06 15:01:39 | Train | Epoch[564/600] Iteration[014/030] Train loss: 0.0073
2023-02-06 15:01:39 | Train | Epoch[564/600] Iteration[015/030] Train loss: 0.0073
2023-02-06 15:01:40 | Train | Epoch[564/600] Iteration[016/030] Train loss: 0.0073
2023-02-06 15:01:40 | Train | Epoch[564/600] Iteration[017/030] Train loss: 0.0073
2023-02-06 15:01:40 | Train | Epoch[564/600] Iteration[018/030] Train loss: 0.0073
2023-02-06 15:01:40 | Train | Epoch[564/600] Iteration[019/030] Train loss: 0.0073
2023-02-06 15:01:41 | Train | Epoch[564/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:01:41 | Train | Epoch[564/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 15:01:41 | Train | Epoch[564/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:01:41 | Train | Epoch[564/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:01:41 | Train | Epoch[564/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:01:42 | Train | Epoch[564/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:01:42 | Train | Epoch[564/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:01:42 | Train | Epoch[564/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:01:42 | Train | Epoch[564/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:01:42 | Train | Epoch[564/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:01:43 | Train | Epoch[564/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:01:43 | Valid | Epoch[564/600] Iteration[001/008] Valid loss: 0.1865
2023-02-06 15:01:43 | Valid | Epoch[564/600] Iteration[002/008] Valid loss: 0.1482
2023-02-06 15:01:43 | Valid | Epoch[564/600] Iteration[003/008] Valid loss: 0.1399
2023-02-06 15:01:43 | Valid | Epoch[564/600] Iteration[004/008] Valid loss: 0.1327
2023-02-06 15:01:43 | Valid | Epoch[564/600] Iteration[005/008] Valid loss: 0.1311
2023-02-06 15:01:43 | Valid | Epoch[564/600] Iteration[006/008] Valid loss: 0.1268
2023-02-06 15:01:43 | Valid | Epoch[564/600] Iteration[007/008] Valid loss: 0.1357
2023-02-06 15:01:43 | Valid | Epoch[564/600] Iteration[008/008] Valid loss: 0.1341
2023-02-06 15:01:43 | Valid | Epoch[564/600] MIou: 0.9301669126510853
2023-02-06 15:01:43 | Valid | Epoch[564/600] Pixel Accuracy: 0.9879226684570312
2023-02-06 15:01:43 | Valid | Epoch[564/600] Mean Pixel Accuracy: 0.9588822994155621
2023-02-06 15:01:43 | Stage | Epoch[564/600] Train loss:0.0075
2023-02-06 15:01:43 | Stage | Epoch[564/600] Valid loss:0.1341
2023-02-06 15:01:43 | Stage | Epoch[564/600] LR:0.0001

2023-02-06 15:01:44 | Train | Epoch[565/600] Iteration[001/030] Train loss: 0.0065
2023-02-06 15:01:44 | Train | Epoch[565/600] Iteration[002/030] Train loss: 0.0067
2023-02-06 15:01:44 | Train | Epoch[565/600] Iteration[003/030] Train loss: 0.0070
2023-02-06 15:01:45 | Train | Epoch[565/600] Iteration[004/030] Train loss: 0.0071
2023-02-06 15:01:45 | Train | Epoch[565/600] Iteration[005/030] Train loss: 0.0070
2023-02-06 15:01:45 | Train | Epoch[565/600] Iteration[006/030] Train loss: 0.0071
2023-02-06 15:01:45 | Train | Epoch[565/600] Iteration[007/030] Train loss: 0.0072
2023-02-06 15:01:45 | Train | Epoch[565/600] Iteration[008/030] Train loss: 0.0073
2023-02-06 15:01:46 | Train | Epoch[565/600] Iteration[009/030] Train loss: 0.0072
2023-02-06 15:01:46 | Train | Epoch[565/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 15:01:46 | Train | Epoch[565/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 15:01:46 | Train | Epoch[565/600] Iteration[012/030] Train loss: 0.0073
2023-02-06 15:01:46 | Train | Epoch[565/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 15:01:47 | Train | Epoch[565/600] Iteration[014/030] Train loss: 0.0073
2023-02-06 15:01:47 | Train | Epoch[565/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 15:01:47 | Train | Epoch[565/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 15:01:47 | Train | Epoch[565/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 15:01:48 | Train | Epoch[565/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:01:48 | Train | Epoch[565/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:01:48 | Train | Epoch[565/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:01:48 | Train | Epoch[565/600] Iteration[021/030] Train loss: 0.0073
2023-02-06 15:01:48 | Train | Epoch[565/600] Iteration[022/030] Train loss: 0.0073
2023-02-06 15:01:49 | Train | Epoch[565/600] Iteration[023/030] Train loss: 0.0073
2023-02-06 15:01:49 | Train | Epoch[565/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:01:49 | Train | Epoch[565/600] Iteration[025/030] Train loss: 0.0073
2023-02-06 15:01:49 | Train | Epoch[565/600] Iteration[026/030] Train loss: 0.0073
2023-02-06 15:01:50 | Train | Epoch[565/600] Iteration[027/030] Train loss: 0.0073
2023-02-06 15:01:50 | Train | Epoch[565/600] Iteration[028/030] Train loss: 0.0073
2023-02-06 15:01:50 | Train | Epoch[565/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 15:01:50 | Train | Epoch[565/600] Iteration[030/030] Train loss: 0.0074
2023-02-06 15:01:50 | Valid | Epoch[565/600] Iteration[001/008] Valid loss: 0.1782
2023-02-06 15:01:51 | Valid | Epoch[565/600] Iteration[002/008] Valid loss: 0.1407
2023-02-06 15:01:51 | Valid | Epoch[565/600] Iteration[003/008] Valid loss: 0.1330
2023-02-06 15:01:51 | Valid | Epoch[565/600] Iteration[004/008] Valid loss: 0.1260
2023-02-06 15:01:51 | Valid | Epoch[565/600] Iteration[005/008] Valid loss: 0.1242
2023-02-06 15:01:51 | Valid | Epoch[565/600] Iteration[006/008] Valid loss: 0.1200
2023-02-06 15:01:51 | Valid | Epoch[565/600] Iteration[007/008] Valid loss: 0.1282
2023-02-06 15:01:51 | Valid | Epoch[565/600] Iteration[008/008] Valid loss: 0.1266
2023-02-06 15:01:51 | Valid | Epoch[565/600] MIou: 0.9293920076165727
2023-02-06 15:01:51 | Valid | Epoch[565/600] Pixel Accuracy: 0.9878273010253906
2023-02-06 15:01:51 | Valid | Epoch[565/600] Mean Pixel Accuracy: 0.9566677806221906
2023-02-06 15:01:51 | Stage | Epoch[565/600] Train loss:0.0074
2023-02-06 15:01:51 | Stage | Epoch[565/600] Valid loss:0.1266
2023-02-06 15:01:51 | Stage | Epoch[565/600] LR:0.0001

2023-02-06 15:01:51 | Train | Epoch[566/600] Iteration[001/030] Train loss: 0.0070
2023-02-06 15:01:52 | Train | Epoch[566/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 15:01:52 | Train | Epoch[566/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 15:01:52 | Train | Epoch[566/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 15:01:52 | Train | Epoch[566/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 15:01:53 | Train | Epoch[566/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 15:01:53 | Train | Epoch[566/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 15:01:53 | Train | Epoch[566/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:01:53 | Train | Epoch[566/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 15:01:53 | Train | Epoch[566/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 15:01:54 | Train | Epoch[566/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:01:54 | Train | Epoch[566/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 15:01:54 | Train | Epoch[566/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 15:01:54 | Train | Epoch[566/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 15:01:54 | Train | Epoch[566/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 15:01:55 | Train | Epoch[566/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 15:01:55 | Train | Epoch[566/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 15:01:55 | Train | Epoch[566/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 15:01:55 | Train | Epoch[566/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 15:01:56 | Train | Epoch[566/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 15:01:56 | Train | Epoch[566/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 15:01:56 | Train | Epoch[566/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 15:01:56 | Train | Epoch[566/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 15:01:56 | Train | Epoch[566/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 15:01:57 | Train | Epoch[566/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 15:01:57 | Train | Epoch[566/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 15:01:57 | Train | Epoch[566/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:01:57 | Train | Epoch[566/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:01:58 | Train | Epoch[566/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:01:58 | Train | Epoch[566/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:01:58 | Valid | Epoch[566/600] Iteration[001/008] Valid loss: 0.1991
2023-02-06 15:01:58 | Valid | Epoch[566/600] Iteration[002/008] Valid loss: 0.1583
2023-02-06 15:01:58 | Valid | Epoch[566/600] Iteration[003/008] Valid loss: 0.1503
2023-02-06 15:01:58 | Valid | Epoch[566/600] Iteration[004/008] Valid loss: 0.1428
2023-02-06 15:01:58 | Valid | Epoch[566/600] Iteration[005/008] Valid loss: 0.1414
2023-02-06 15:01:58 | Valid | Epoch[566/600] Iteration[006/008] Valid loss: 0.1372
2023-02-06 15:01:58 | Valid | Epoch[566/600] Iteration[007/008] Valid loss: 0.1472
2023-02-06 15:01:58 | Valid | Epoch[566/600] Iteration[008/008] Valid loss: 0.1455
2023-02-06 15:01:58 | Valid | Epoch[566/600] MIou: 0.9303982709210974
2023-02-06 15:01:58 | Valid | Epoch[566/600] Pixel Accuracy: 0.9879163106282552
2023-02-06 15:01:58 | Valid | Epoch[566/600] Mean Pixel Accuracy: 0.9608950748225533
2023-02-06 15:01:58 | Stage | Epoch[566/600] Train loss:0.0076
2023-02-06 15:01:58 | Stage | Epoch[566/600] Valid loss:0.1455
2023-02-06 15:01:58 | Stage | Epoch[566/600] LR:0.0001

2023-02-06 15:01:59 | Train | Epoch[567/600] Iteration[001/030] Train loss: 0.0087
2023-02-06 15:01:59 | Train | Epoch[567/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 15:01:59 | Train | Epoch[567/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 15:02:00 | Train | Epoch[567/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 15:02:00 | Train | Epoch[567/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 15:02:00 | Train | Epoch[567/600] Iteration[006/030] Train loss: 0.0082
2023-02-06 15:02:00 | Train | Epoch[567/600] Iteration[007/030] Train loss: 0.0080
2023-02-06 15:02:00 | Train | Epoch[567/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 15:02:01 | Train | Epoch[567/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 15:02:01 | Train | Epoch[567/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 15:02:01 | Train | Epoch[567/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 15:02:01 | Train | Epoch[567/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 15:02:02 | Train | Epoch[567/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 15:02:02 | Train | Epoch[567/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 15:02:02 | Train | Epoch[567/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 15:02:02 | Train | Epoch[567/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 15:02:02 | Train | Epoch[567/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 15:02:03 | Train | Epoch[567/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 15:02:03 | Train | Epoch[567/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 15:02:03 | Train | Epoch[567/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 15:02:03 | Train | Epoch[567/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 15:02:04 | Train | Epoch[567/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 15:02:04 | Train | Epoch[567/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 15:02:04 | Train | Epoch[567/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 15:02:04 | Train | Epoch[567/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 15:02:04 | Train | Epoch[567/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 15:02:05 | Train | Epoch[567/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:02:05 | Train | Epoch[567/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:02:05 | Train | Epoch[567/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 15:02:05 | Train | Epoch[567/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 15:02:06 | Valid | Epoch[567/600] Iteration[001/008] Valid loss: 0.1728
2023-02-06 15:02:06 | Valid | Epoch[567/600] Iteration[002/008] Valid loss: 0.1379
2023-02-06 15:02:06 | Valid | Epoch[567/600] Iteration[003/008] Valid loss: 0.1297
2023-02-06 15:02:06 | Valid | Epoch[567/600] Iteration[004/008] Valid loss: 0.1232
2023-02-06 15:02:06 | Valid | Epoch[567/600] Iteration[005/008] Valid loss: 0.1220
2023-02-06 15:02:06 | Valid | Epoch[567/600] Iteration[006/008] Valid loss: 0.1176
2023-02-06 15:02:06 | Valid | Epoch[567/600] Iteration[007/008] Valid loss: 0.1253
2023-02-06 15:02:06 | Valid | Epoch[567/600] Iteration[008/008] Valid loss: 0.1239
2023-02-06 15:02:06 | Valid | Epoch[567/600] MIou: 0.92994906824964
2023-02-06 15:02:06 | Valid | Epoch[567/600] Pixel Accuracy: 0.9879201253255209
2023-02-06 15:02:06 | Valid | Epoch[567/600] Mean Pixel Accuracy: 0.9573274860815624
2023-02-06 15:02:06 | Stage | Epoch[567/600] Train loss:0.0077
2023-02-06 15:02:06 | Stage | Epoch[567/600] Valid loss:0.1239
2023-02-06 15:02:06 | Stage | Epoch[567/600] LR:0.0001

2023-02-06 15:02:07 | Train | Epoch[568/600] Iteration[001/030] Train loss: 0.0077
2023-02-06 15:02:07 | Train | Epoch[568/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 15:02:07 | Train | Epoch[568/600] Iteration[003/030] Train loss: 0.0080
2023-02-06 15:02:07 | Train | Epoch[568/600] Iteration[004/030] Train loss: 0.0082
2023-02-06 15:02:07 | Train | Epoch[568/600] Iteration[005/030] Train loss: 0.0083
2023-02-06 15:02:08 | Train | Epoch[568/600] Iteration[006/030] Train loss: 0.0081
2023-02-06 15:02:08 | Train | Epoch[568/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 15:02:08 | Train | Epoch[568/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 15:02:08 | Train | Epoch[568/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 15:02:08 | Train | Epoch[568/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 15:02:09 | Train | Epoch[568/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 15:02:09 | Train | Epoch[568/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 15:02:09 | Train | Epoch[568/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 15:02:09 | Train | Epoch[568/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 15:02:10 | Train | Epoch[568/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 15:02:10 | Train | Epoch[568/600] Iteration[016/030] Train loss: 0.0078
2023-02-06 15:02:10 | Train | Epoch[568/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 15:02:10 | Train | Epoch[568/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 15:02:10 | Train | Epoch[568/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 15:02:11 | Train | Epoch[568/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 15:02:11 | Train | Epoch[568/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 15:02:11 | Train | Epoch[568/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:02:11 | Train | Epoch[568/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:02:12 | Train | Epoch[568/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:02:12 | Train | Epoch[568/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:02:12 | Train | Epoch[568/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 15:02:12 | Train | Epoch[568/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:02:12 | Train | Epoch[568/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:02:13 | Train | Epoch[568/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 15:02:13 | Train | Epoch[568/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:02:13 | Valid | Epoch[568/600] Iteration[001/008] Valid loss: 0.1697
2023-02-06 15:02:13 | Valid | Epoch[568/600] Iteration[002/008] Valid loss: 0.1346
2023-02-06 15:02:13 | Valid | Epoch[568/600] Iteration[003/008] Valid loss: 0.1271
2023-02-06 15:02:13 | Valid | Epoch[568/600] Iteration[004/008] Valid loss: 0.1206
2023-02-06 15:02:13 | Valid | Epoch[568/600] Iteration[005/008] Valid loss: 0.1190
2023-02-06 15:02:13 | Valid | Epoch[568/600] Iteration[006/008] Valid loss: 0.1147
2023-02-06 15:02:13 | Valid | Epoch[568/600] Iteration[007/008] Valid loss: 0.1222
2023-02-06 15:02:14 | Valid | Epoch[568/600] Iteration[008/008] Valid loss: 0.1204
2023-02-06 15:02:14 | Valid | Epoch[568/600] MIou: 0.9296622967264674
2023-02-06 15:02:14 | Valid | Epoch[568/600] Pixel Accuracy: 0.9879023234049479
2023-02-06 15:02:14 | Valid | Epoch[568/600] Mean Pixel Accuracy: 0.9558467119959795
2023-02-06 15:02:14 | Stage | Epoch[568/600] Train loss:0.0075
2023-02-06 15:02:14 | Stage | Epoch[568/600] Valid loss:0.1204
2023-02-06 15:02:14 | Stage | Epoch[568/600] LR:0.0001

2023-02-06 15:02:14 | Train | Epoch[569/600] Iteration[001/030] Train loss: 0.0088
2023-02-06 15:02:14 | Train | Epoch[569/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 15:02:15 | Train | Epoch[569/600] Iteration[003/030] Train loss: 0.0082
2023-02-06 15:02:15 | Train | Epoch[569/600] Iteration[004/030] Train loss: 0.0082
2023-02-06 15:02:15 | Train | Epoch[569/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 15:02:15 | Train | Epoch[569/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 15:02:15 | Train | Epoch[569/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 15:02:16 | Train | Epoch[569/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 15:02:16 | Train | Epoch[569/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 15:02:16 | Train | Epoch[569/600] Iteration[010/030] Train loss: 0.0078
2023-02-06 15:02:16 | Train | Epoch[569/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 15:02:17 | Train | Epoch[569/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 15:02:17 | Train | Epoch[569/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 15:02:17 | Train | Epoch[569/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:02:17 | Train | Epoch[569/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:02:17 | Train | Epoch[569/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:02:18 | Train | Epoch[569/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:02:18 | Train | Epoch[569/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:02:18 | Train | Epoch[569/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:02:18 | Train | Epoch[569/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 15:02:19 | Train | Epoch[569/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 15:02:19 | Train | Epoch[569/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 15:02:19 | Train | Epoch[569/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 15:02:19 | Train | Epoch[569/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 15:02:19 | Train | Epoch[569/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 15:02:20 | Train | Epoch[569/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 15:02:20 | Train | Epoch[569/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 15:02:20 | Train | Epoch[569/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 15:02:20 | Train | Epoch[569/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 15:02:20 | Train | Epoch[569/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 15:02:21 | Valid | Epoch[569/600] Iteration[001/008] Valid loss: 0.1748
2023-02-06 15:02:21 | Valid | Epoch[569/600] Iteration[002/008] Valid loss: 0.1383
2023-02-06 15:02:21 | Valid | Epoch[569/600] Iteration[003/008] Valid loss: 0.1305
2023-02-06 15:02:21 | Valid | Epoch[569/600] Iteration[004/008] Valid loss: 0.1237
2023-02-06 15:02:21 | Valid | Epoch[569/600] Iteration[005/008] Valid loss: 0.1218
2023-02-06 15:02:21 | Valid | Epoch[569/600] Iteration[006/008] Valid loss: 0.1175
2023-02-06 15:02:21 | Valid | Epoch[569/600] Iteration[007/008] Valid loss: 0.1253
2023-02-06 15:02:21 | Valid | Epoch[569/600] Iteration[008/008] Valid loss: 0.1237
2023-02-06 15:02:21 | Valid | Epoch[569/600] MIou: 0.9294965006380459
2023-02-06 15:02:21 | Valid | Epoch[569/600] Pixel Accuracy: 0.9878514607747396
2023-02-06 15:02:21 | Valid | Epoch[569/600] Mean Pixel Accuracy: 0.9565352290060434
2023-02-06 15:02:21 | Stage | Epoch[569/600] Train loss:0.0077
2023-02-06 15:02:21 | Stage | Epoch[569/600] Valid loss:0.1237
2023-02-06 15:02:21 | Stage | Epoch[569/600] LR:0.0001

2023-02-06 15:02:22 | Train | Epoch[570/600] Iteration[001/030] Train loss: 0.0067
2023-02-06 15:02:22 | Train | Epoch[570/600] Iteration[002/030] Train loss: 0.0071
2023-02-06 15:02:22 | Train | Epoch[570/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 15:02:22 | Train | Epoch[570/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 15:02:23 | Train | Epoch[570/600] Iteration[005/030] Train loss: 0.0072
2023-02-06 15:02:23 | Train | Epoch[570/600] Iteration[006/030] Train loss: 0.0072
2023-02-06 15:02:23 | Train | Epoch[570/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 15:02:23 | Train | Epoch[570/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 15:02:23 | Train | Epoch[570/600] Iteration[009/030] Train loss: 0.0072
2023-02-06 15:02:24 | Train | Epoch[570/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 15:02:24 | Train | Epoch[570/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 15:02:24 | Train | Epoch[570/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 15:02:24 | Train | Epoch[570/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 15:02:24 | Train | Epoch[570/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 15:02:25 | Train | Epoch[570/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:02:25 | Train | Epoch[570/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:02:25 | Train | Epoch[570/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:02:25 | Train | Epoch[570/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:02:26 | Train | Epoch[570/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:02:26 | Train | Epoch[570/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 15:02:26 | Train | Epoch[570/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 15:02:26 | Train | Epoch[570/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 15:02:26 | Train | Epoch[570/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 15:02:27 | Train | Epoch[570/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 15:02:27 | Train | Epoch[570/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 15:02:27 | Train | Epoch[570/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 15:02:27 | Train | Epoch[570/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 15:02:28 | Train | Epoch[570/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 15:02:28 | Train | Epoch[570/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 15:02:28 | Train | Epoch[570/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 15:02:28 | Valid | Epoch[570/600] Iteration[001/008] Valid loss: 0.1743
2023-02-06 15:02:28 | Valid | Epoch[570/600] Iteration[002/008] Valid loss: 0.1383
2023-02-06 15:02:28 | Valid | Epoch[570/600] Iteration[003/008] Valid loss: 0.1308
2023-02-06 15:02:28 | Valid | Epoch[570/600] Iteration[004/008] Valid loss: 0.1242
2023-02-06 15:02:29 | Valid | Epoch[570/600] Iteration[005/008] Valid loss: 0.1225
2023-02-06 15:02:29 | Valid | Epoch[570/600] Iteration[006/008] Valid loss: 0.1181
2023-02-06 15:02:29 | Valid | Epoch[570/600] Iteration[007/008] Valid loss: 0.1260
2023-02-06 15:02:29 | Valid | Epoch[570/600] Iteration[008/008] Valid loss: 0.1244
2023-02-06 15:02:29 | Valid | Epoch[570/600] MIou: 0.9295933829173557
2023-02-06 15:02:29 | Valid | Epoch[570/600] Pixel Accuracy: 0.9878667195638021
2023-02-06 15:02:29 | Valid | Epoch[570/600] Mean Pixel Accuracy: 0.9566831062605494
2023-02-06 15:02:29 | Stage | Epoch[570/600] Train loss:0.0077
2023-02-06 15:02:29 | Stage | Epoch[570/600] Valid loss:0.1244
2023-02-06 15:02:29 | Stage | Epoch[570/600] LR:0.0001

2023-02-06 15:02:29 | Train | Epoch[571/600] Iteration[001/030] Train loss: 0.0064
2023-02-06 15:02:29 | Train | Epoch[571/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 15:02:30 | Train | Epoch[571/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 15:02:30 | Train | Epoch[571/600] Iteration[004/030] Train loss: 0.0071
2023-02-06 15:02:30 | Train | Epoch[571/600] Iteration[005/030] Train loss: 0.0070
2023-02-06 15:02:30 | Train | Epoch[571/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 15:02:31 | Train | Epoch[571/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 15:02:31 | Train | Epoch[571/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:02:31 | Train | Epoch[571/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 15:02:31 | Train | Epoch[571/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 15:02:31 | Train | Epoch[571/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:02:32 | Train | Epoch[571/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 15:02:32 | Train | Epoch[571/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 15:02:32 | Train | Epoch[571/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:02:32 | Train | Epoch[571/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:02:33 | Train | Epoch[571/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:02:33 | Train | Epoch[571/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:02:33 | Train | Epoch[571/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:02:33 | Train | Epoch[571/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:02:33 | Train | Epoch[571/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:02:34 | Train | Epoch[571/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:02:34 | Train | Epoch[571/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 15:02:34 | Train | Epoch[571/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:02:34 | Train | Epoch[571/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:02:35 | Train | Epoch[571/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:02:35 | Train | Epoch[571/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:02:35 | Train | Epoch[571/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:02:35 | Train | Epoch[571/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:02:35 | Train | Epoch[571/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 15:02:35 | Train | Epoch[571/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:02:36 | Valid | Epoch[571/600] Iteration[001/008] Valid loss: 0.1646
2023-02-06 15:02:36 | Valid | Epoch[571/600] Iteration[002/008] Valid loss: 0.1309
2023-02-06 15:02:36 | Valid | Epoch[571/600] Iteration[003/008] Valid loss: 0.1236
2023-02-06 15:02:36 | Valid | Epoch[571/600] Iteration[004/008] Valid loss: 0.1173
2023-02-06 15:02:36 | Valid | Epoch[571/600] Iteration[005/008] Valid loss: 0.1157
2023-02-06 15:02:36 | Valid | Epoch[571/600] Iteration[006/008] Valid loss: 0.1115
2023-02-06 15:02:36 | Valid | Epoch[571/600] Iteration[007/008] Valid loss: 0.1185
2023-02-06 15:02:36 | Valid | Epoch[571/600] Iteration[008/008] Valid loss: 0.1170
2023-02-06 15:02:36 | Valid | Epoch[571/600] MIou: 0.9291238583013195
2023-02-06 15:02:36 | Valid | Epoch[571/600] Pixel Accuracy: 0.9878145853678385
2023-02-06 15:02:36 | Valid | Epoch[571/600] Mean Pixel Accuracy: 0.9551454188631032
2023-02-06 15:02:36 | Stage | Epoch[571/600] Train loss:0.0076
2023-02-06 15:02:36 | Stage | Epoch[571/600] Valid loss:0.1170
2023-02-06 15:02:36 | Stage | Epoch[571/600] LR:0.0001

2023-02-06 15:02:37 | Train | Epoch[572/600] Iteration[001/030] Train loss: 0.0070
2023-02-06 15:02:37 | Train | Epoch[572/600] Iteration[002/030] Train loss: 0.0068
2023-02-06 15:02:37 | Train | Epoch[572/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 15:02:37 | Train | Epoch[572/600] Iteration[004/030] Train loss: 0.0069
2023-02-06 15:02:38 | Train | Epoch[572/600] Iteration[005/030] Train loss: 0.0069
2023-02-06 15:02:38 | Train | Epoch[572/600] Iteration[006/030] Train loss: 0.0072
2023-02-06 15:02:38 | Train | Epoch[572/600] Iteration[007/030] Train loss: 0.0071
2023-02-06 15:02:38 | Train | Epoch[572/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 15:02:39 | Train | Epoch[572/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 15:02:39 | Train | Epoch[572/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 15:02:39 | Train | Epoch[572/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 15:02:39 | Train | Epoch[572/600] Iteration[012/030] Train loss: 0.0073
2023-02-06 15:02:39 | Train | Epoch[572/600] Iteration[013/030] Train loss: 0.0073
2023-02-06 15:02:40 | Train | Epoch[572/600] Iteration[014/030] Train loss: 0.0073
2023-02-06 15:02:40 | Train | Epoch[572/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 15:02:40 | Train | Epoch[572/600] Iteration[016/030] Train loss: 0.0073
2023-02-06 15:02:40 | Train | Epoch[572/600] Iteration[017/030] Train loss: 0.0073
2023-02-06 15:02:40 | Train | Epoch[572/600] Iteration[018/030] Train loss: 0.0073
2023-02-06 15:02:41 | Train | Epoch[572/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:02:41 | Train | Epoch[572/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:02:41 | Train | Epoch[572/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 15:02:41 | Train | Epoch[572/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:02:42 | Train | Epoch[572/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:02:42 | Train | Epoch[572/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:02:42 | Train | Epoch[572/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:02:42 | Train | Epoch[572/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:02:42 | Train | Epoch[572/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:02:43 | Train | Epoch[572/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 15:02:43 | Train | Epoch[572/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 15:02:43 | Train | Epoch[572/600] Iteration[030/030] Train loss: 0.0074
2023-02-06 15:02:43 | Valid | Epoch[572/600] Iteration[001/008] Valid loss: 0.1797
2023-02-06 15:02:43 | Valid | Epoch[572/600] Iteration[002/008] Valid loss: 0.1428
2023-02-06 15:02:43 | Valid | Epoch[572/600] Iteration[003/008] Valid loss: 0.1350
2023-02-06 15:02:44 | Valid | Epoch[572/600] Iteration[004/008] Valid loss: 0.1280
2023-02-06 15:02:44 | Valid | Epoch[572/600] Iteration[005/008] Valid loss: 0.1261
2023-02-06 15:02:44 | Valid | Epoch[572/600] Iteration[006/008] Valid loss: 0.1220
2023-02-06 15:02:44 | Valid | Epoch[572/600] Iteration[007/008] Valid loss: 0.1304
2023-02-06 15:02:44 | Valid | Epoch[572/600] Iteration[008/008] Valid loss: 0.1289
2023-02-06 15:02:44 | Valid | Epoch[572/600] MIou: 0.9295108040018947
2023-02-06 15:02:44 | Valid | Epoch[572/600] Pixel Accuracy: 0.9878285725911459
2023-02-06 15:02:44 | Valid | Epoch[572/600] Mean Pixel Accuracy: 0.9575117622400672
2023-02-06 15:02:44 | Stage | Epoch[572/600] Train loss:0.0074
2023-02-06 15:02:44 | Stage | Epoch[572/600] Valid loss:0.1289
2023-02-06 15:02:44 | Stage | Epoch[572/600] LR:0.0001

2023-02-06 15:02:44 | Train | Epoch[573/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 15:02:44 | Train | Epoch[573/600] Iteration[002/030] Train loss: 0.0069
2023-02-06 15:02:45 | Train | Epoch[573/600] Iteration[003/030] Train loss: 0.0069
2023-02-06 15:02:45 | Train | Epoch[573/600] Iteration[004/030] Train loss: 0.0069
2023-02-06 15:02:45 | Train | Epoch[573/600] Iteration[005/030] Train loss: 0.0069
2023-02-06 15:02:45 | Train | Epoch[573/600] Iteration[006/030] Train loss: 0.0070
2023-02-06 15:02:46 | Train | Epoch[573/600] Iteration[007/030] Train loss: 0.0071
2023-02-06 15:02:46 | Train | Epoch[573/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 15:02:46 | Train | Epoch[573/600] Iteration[009/030] Train loss: 0.0072
2023-02-06 15:02:46 | Train | Epoch[573/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 15:02:46 | Train | Epoch[573/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 15:02:47 | Train | Epoch[573/600] Iteration[012/030] Train loss: 0.0073
2023-02-06 15:02:47 | Train | Epoch[573/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 15:02:47 | Train | Epoch[573/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:02:47 | Train | Epoch[573/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:02:48 | Train | Epoch[573/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:02:48 | Train | Epoch[573/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:02:48 | Train | Epoch[573/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:02:48 | Train | Epoch[573/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:02:48 | Train | Epoch[573/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:02:49 | Train | Epoch[573/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 15:02:49 | Train | Epoch[573/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:02:49 | Train | Epoch[573/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:02:49 | Train | Epoch[573/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:02:50 | Train | Epoch[573/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:02:50 | Train | Epoch[573/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 15:02:50 | Train | Epoch[573/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:02:50 | Train | Epoch[573/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 15:02:50 | Train | Epoch[573/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:02:50 | Train | Epoch[573/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:02:51 | Valid | Epoch[573/600] Iteration[001/008] Valid loss: 0.1705
2023-02-06 15:02:51 | Valid | Epoch[573/600] Iteration[002/008] Valid loss: 0.1357
2023-02-06 15:02:51 | Valid | Epoch[573/600] Iteration[003/008] Valid loss: 0.1281
2023-02-06 15:02:51 | Valid | Epoch[573/600] Iteration[004/008] Valid loss: 0.1216
2023-02-06 15:02:51 | Valid | Epoch[573/600] Iteration[005/008] Valid loss: 0.1199
2023-02-06 15:02:51 | Valid | Epoch[573/600] Iteration[006/008] Valid loss: 0.1155
2023-02-06 15:02:51 | Valid | Epoch[573/600] Iteration[007/008] Valid loss: 0.1231
2023-02-06 15:02:51 | Valid | Epoch[573/600] Iteration[008/008] Valid loss: 0.1216
2023-02-06 15:02:51 | Valid | Epoch[573/600] MIou: 0.9290928703719209
2023-02-06 15:02:51 | Valid | Epoch[573/600] Pixel Accuracy: 0.98779296875
2023-02-06 15:02:51 | Valid | Epoch[573/600] Mean Pixel Accuracy: 0.9557295417701481
2023-02-06 15:02:51 | Stage | Epoch[573/600] Train loss:0.0075
2023-02-06 15:02:51 | Stage | Epoch[573/600] Valid loss:0.1216
2023-02-06 15:02:51 | Stage | Epoch[573/600] LR:0.0001

2023-02-06 15:02:52 | Train | Epoch[574/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 15:02:52 | Train | Epoch[574/600] Iteration[002/030] Train loss: 0.0071
2023-02-06 15:02:52 | Train | Epoch[574/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 15:02:52 | Train | Epoch[574/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 15:02:53 | Train | Epoch[574/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 15:02:53 | Train | Epoch[574/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 15:02:53 | Train | Epoch[574/600] Iteration[007/030] Train loss: 0.0075
2023-02-06 15:02:53 | Train | Epoch[574/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:02:54 | Train | Epoch[574/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 15:02:54 | Train | Epoch[574/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 15:02:54 | Train | Epoch[574/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:02:54 | Train | Epoch[574/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:02:54 | Train | Epoch[574/600] Iteration[013/030] Train loss: 0.0074
2023-02-06 15:02:55 | Train | Epoch[574/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 15:02:55 | Train | Epoch[574/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 15:02:55 | Train | Epoch[574/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:02:55 | Train | Epoch[574/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:02:56 | Train | Epoch[574/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:02:56 | Train | Epoch[574/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:02:56 | Train | Epoch[574/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:02:56 | Train | Epoch[574/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 15:02:56 | Train | Epoch[574/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:02:57 | Train | Epoch[574/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:02:57 | Train | Epoch[574/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:02:57 | Train | Epoch[574/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:02:57 | Train | Epoch[574/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:02:58 | Train | Epoch[574/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:02:58 | Train | Epoch[574/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 15:02:58 | Train | Epoch[574/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 15:02:58 | Train | Epoch[574/600] Iteration[030/030] Train loss: 0.0074
2023-02-06 15:02:58 | Valid | Epoch[574/600] Iteration[001/008] Valid loss: 0.1795
2023-02-06 15:02:58 | Valid | Epoch[574/600] Iteration[002/008] Valid loss: 0.1430
2023-02-06 15:02:59 | Valid | Epoch[574/600] Iteration[003/008] Valid loss: 0.1352
2023-02-06 15:02:59 | Valid | Epoch[574/600] Iteration[004/008] Valid loss: 0.1283
2023-02-06 15:02:59 | Valid | Epoch[574/600] Iteration[005/008] Valid loss: 0.1265
2023-02-06 15:02:59 | Valid | Epoch[574/600] Iteration[006/008] Valid loss: 0.1221
2023-02-06 15:02:59 | Valid | Epoch[574/600] Iteration[007/008] Valid loss: 0.1306
2023-02-06 15:02:59 | Valid | Epoch[574/600] Iteration[008/008] Valid loss: 0.1291
2023-02-06 15:02:59 | Valid | Epoch[574/600] MIou: 0.9294080756620946
2023-02-06 15:02:59 | Valid | Epoch[574/600] Pixel Accuracy: 0.9878094991048177
2023-02-06 15:02:59 | Valid | Epoch[574/600] Mean Pixel Accuracy: 0.9574632358094443
2023-02-06 15:02:59 | Stage | Epoch[574/600] Train loss:0.0074
2023-02-06 15:02:59 | Stage | Epoch[574/600] Valid loss:0.1291
2023-02-06 15:02:59 | Stage | Epoch[574/600] LR:0.0001

2023-02-06 15:02:59 | Train | Epoch[575/600] Iteration[001/030] Train loss: 0.0130
2023-02-06 15:02:59 | Train | Epoch[575/600] Iteration[002/030] Train loss: 0.0100
2023-02-06 15:03:00 | Train | Epoch[575/600] Iteration[003/030] Train loss: 0.0093
2023-02-06 15:03:00 | Train | Epoch[575/600] Iteration[004/030] Train loss: 0.0089
2023-02-06 15:03:00 | Train | Epoch[575/600] Iteration[005/030] Train loss: 0.0087
2023-02-06 15:03:00 | Train | Epoch[575/600] Iteration[006/030] Train loss: 0.0085
2023-02-06 15:03:01 | Train | Epoch[575/600] Iteration[007/030] Train loss: 0.0086
2023-02-06 15:03:01 | Train | Epoch[575/600] Iteration[008/030] Train loss: 0.0084
2023-02-06 15:03:01 | Train | Epoch[575/600] Iteration[009/030] Train loss: 0.0082
2023-02-06 15:03:01 | Train | Epoch[575/600] Iteration[010/030] Train loss: 0.0080
2023-02-06 15:03:01 | Train | Epoch[575/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 15:03:02 | Train | Epoch[575/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 15:03:02 | Train | Epoch[575/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 15:03:02 | Train | Epoch[575/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 15:03:02 | Train | Epoch[575/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 15:03:03 | Train | Epoch[575/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 15:03:03 | Train | Epoch[575/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 15:03:03 | Train | Epoch[575/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 15:03:03 | Train | Epoch[575/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 15:03:03 | Train | Epoch[575/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 15:03:04 | Train | Epoch[575/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 15:03:04 | Train | Epoch[575/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 15:03:04 | Train | Epoch[575/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 15:03:04 | Train | Epoch[575/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 15:03:05 | Train | Epoch[575/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 15:03:05 | Train | Epoch[575/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 15:03:05 | Train | Epoch[575/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 15:03:05 | Train | Epoch[575/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 15:03:05 | Train | Epoch[575/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 15:03:05 | Train | Epoch[575/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 15:03:06 | Valid | Epoch[575/600] Iteration[001/008] Valid loss: 0.1804
2023-02-06 15:03:06 | Valid | Epoch[575/600] Iteration[002/008] Valid loss: 0.1427
2023-02-06 15:03:06 | Valid | Epoch[575/600] Iteration[003/008] Valid loss: 0.1348
2023-02-06 15:03:06 | Valid | Epoch[575/600] Iteration[004/008] Valid loss: 0.1275
2023-02-06 15:03:06 | Valid | Epoch[575/600] Iteration[005/008] Valid loss: 0.1256
2023-02-06 15:03:06 | Valid | Epoch[575/600] Iteration[006/008] Valid loss: 0.1213
2023-02-06 15:03:06 | Valid | Epoch[575/600] Iteration[007/008] Valid loss: 0.1298
2023-02-06 15:03:06 | Valid | Epoch[575/600] Iteration[008/008] Valid loss: 0.1284
2023-02-06 15:03:06 | Valid | Epoch[575/600] MIou: 0.929536401000449
2023-02-06 15:03:06 | Valid | Epoch[575/600] Pixel Accuracy: 0.9878362019856771
2023-02-06 15:03:06 | Valid | Epoch[575/600] Mean Pixel Accuracy: 0.9574145081364942
2023-02-06 15:03:06 | Stage | Epoch[575/600] Train loss:0.0078
2023-02-06 15:03:06 | Stage | Epoch[575/600] Valid loss:0.1284
2023-02-06 15:03:06 | Stage | Epoch[575/600] LR:0.0001

2023-02-06 15:03:07 | Train | Epoch[576/600] Iteration[001/030] Train loss: 0.0076
2023-02-06 15:03:07 | Train | Epoch[576/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 15:03:07 | Train | Epoch[576/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 15:03:07 | Train | Epoch[576/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 15:03:08 | Train | Epoch[576/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 15:03:08 | Train | Epoch[576/600] Iteration[006/030] Train loss: 0.0080
2023-02-06 15:03:08 | Train | Epoch[576/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 15:03:08 | Train | Epoch[576/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 15:03:09 | Train | Epoch[576/600] Iteration[009/030] Train loss: 0.0079
2023-02-06 15:03:09 | Train | Epoch[576/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 15:03:09 | Train | Epoch[576/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 15:03:09 | Train | Epoch[576/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 15:03:09 | Train | Epoch[576/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 15:03:10 | Train | Epoch[576/600] Iteration[014/030] Train loss: 0.0078
2023-02-06 15:03:10 | Train | Epoch[576/600] Iteration[015/030] Train loss: 0.0078
2023-02-06 15:03:10 | Train | Epoch[576/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 15:03:10 | Train | Epoch[576/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 15:03:11 | Train | Epoch[576/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 15:03:11 | Train | Epoch[576/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 15:03:11 | Train | Epoch[576/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 15:03:11 | Train | Epoch[576/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 15:03:11 | Train | Epoch[576/600] Iteration[022/030] Train loss: 0.0077
2023-02-06 15:03:12 | Train | Epoch[576/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 15:03:12 | Train | Epoch[576/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 15:03:12 | Train | Epoch[576/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 15:03:12 | Train | Epoch[576/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 15:03:13 | Train | Epoch[576/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:03:13 | Train | Epoch[576/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:03:13 | Train | Epoch[576/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 15:03:13 | Train | Epoch[576/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:03:13 | Valid | Epoch[576/600] Iteration[001/008] Valid loss: 0.1757
2023-02-06 15:03:13 | Valid | Epoch[576/600] Iteration[002/008] Valid loss: 0.1393
2023-02-06 15:03:14 | Valid | Epoch[576/600] Iteration[003/008] Valid loss: 0.1318
2023-02-06 15:03:14 | Valid | Epoch[576/600] Iteration[004/008] Valid loss: 0.1252
2023-02-06 15:03:14 | Valid | Epoch[576/600] Iteration[005/008] Valid loss: 0.1235
2023-02-06 15:03:14 | Valid | Epoch[576/600] Iteration[006/008] Valid loss: 0.1191
2023-02-06 15:03:14 | Valid | Epoch[576/600] Iteration[007/008] Valid loss: 0.1271
2023-02-06 15:03:14 | Valid | Epoch[576/600] Iteration[008/008] Valid loss: 0.1255
2023-02-06 15:03:14 | Valid | Epoch[576/600] MIou: 0.9295910761193121
2023-02-06 15:03:14 | Valid | Epoch[576/600] Pixel Accuracy: 0.9878654479980469
2023-02-06 15:03:14 | Valid | Epoch[576/600] Mean Pixel Accuracy: 0.9567141097113399
2023-02-06 15:03:14 | Stage | Epoch[576/600] Train loss:0.0076
2023-02-06 15:03:14 | Stage | Epoch[576/600] Valid loss:0.1255
2023-02-06 15:03:14 | Stage | Epoch[576/600] LR:0.0001

2023-02-06 15:03:14 | Train | Epoch[577/600] Iteration[001/030] Train loss: 0.0069
2023-02-06 15:03:15 | Train | Epoch[577/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 15:03:15 | Train | Epoch[577/600] Iteration[003/030] Train loss: 0.0078
2023-02-06 15:03:15 | Train | Epoch[577/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 15:03:15 | Train | Epoch[577/600] Iteration[005/030] Train loss: 0.0084
2023-02-06 15:03:15 | Train | Epoch[577/600] Iteration[006/030] Train loss: 0.0082
2023-02-06 15:03:16 | Train | Epoch[577/600] Iteration[007/030] Train loss: 0.0082
2023-02-06 15:03:16 | Train | Epoch[577/600] Iteration[008/030] Train loss: 0.0080
2023-02-06 15:03:16 | Train | Epoch[577/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 15:03:16 | Train | Epoch[577/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 15:03:17 | Train | Epoch[577/600] Iteration[011/030] Train loss: 0.0079
2023-02-06 15:03:17 | Train | Epoch[577/600] Iteration[012/030] Train loss: 0.0079
2023-02-06 15:03:17 | Train | Epoch[577/600] Iteration[013/030] Train loss: 0.0078
2023-02-06 15:03:17 | Train | Epoch[577/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 15:03:17 | Train | Epoch[577/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 15:03:18 | Train | Epoch[577/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 15:03:18 | Train | Epoch[577/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 15:03:18 | Train | Epoch[577/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 15:03:18 | Train | Epoch[577/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 15:03:18 | Train | Epoch[577/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 15:03:19 | Train | Epoch[577/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 15:03:19 | Train | Epoch[577/600] Iteration[022/030] Train loss: 0.0078
2023-02-06 15:03:19 | Train | Epoch[577/600] Iteration[023/030] Train loss: 0.0077
2023-02-06 15:03:19 | Train | Epoch[577/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 15:03:20 | Train | Epoch[577/600] Iteration[025/030] Train loss: 0.0077
2023-02-06 15:03:20 | Train | Epoch[577/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 15:03:20 | Train | Epoch[577/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 15:03:20 | Train | Epoch[577/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 15:03:20 | Train | Epoch[577/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 15:03:21 | Train | Epoch[577/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 15:03:21 | Valid | Epoch[577/600] Iteration[001/008] Valid loss: 0.1696
2023-02-06 15:03:21 | Valid | Epoch[577/600] Iteration[002/008] Valid loss: 0.1341
2023-02-06 15:03:21 | Valid | Epoch[577/600] Iteration[003/008] Valid loss: 0.1268
2023-02-06 15:03:21 | Valid | Epoch[577/600] Iteration[004/008] Valid loss: 0.1203
2023-02-06 15:03:21 | Valid | Epoch[577/600] Iteration[005/008] Valid loss: 0.1181
2023-02-06 15:03:21 | Valid | Epoch[577/600] Iteration[006/008] Valid loss: 0.1139
2023-02-06 15:03:21 | Valid | Epoch[577/600] Iteration[007/008] Valid loss: 0.1213
2023-02-06 15:03:21 | Valid | Epoch[577/600] Iteration[008/008] Valid loss: 0.1197
2023-02-06 15:03:21 | Valid | Epoch[577/600] MIou: 0.9291422986534339
2023-02-06 15:03:21 | Valid | Epoch[577/600] Pixel Accuracy: 0.9878120422363281
2023-02-06 15:03:21 | Valid | Epoch[577/600] Mean Pixel Accuracy: 0.9553786184955101
2023-02-06 15:03:21 | Stage | Epoch[577/600] Train loss:0.0077
2023-02-06 15:03:21 | Stage | Epoch[577/600] Valid loss:0.1197
2023-02-06 15:03:21 | Stage | Epoch[577/600] LR:0.0001

2023-02-06 15:03:22 | Train | Epoch[578/600] Iteration[001/030] Train loss: 0.0074
2023-02-06 15:03:22 | Train | Epoch[578/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 15:03:22 | Train | Epoch[578/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 15:03:23 | Train | Epoch[578/600] Iteration[004/030] Train loss: 0.0077
2023-02-06 15:03:23 | Train | Epoch[578/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 15:03:23 | Train | Epoch[578/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 15:03:23 | Train | Epoch[578/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 15:03:23 | Train | Epoch[578/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 15:03:24 | Train | Epoch[578/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 15:03:24 | Train | Epoch[578/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 15:03:24 | Train | Epoch[578/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 15:03:24 | Train | Epoch[578/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:03:25 | Train | Epoch[578/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 15:03:25 | Train | Epoch[578/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 15:03:25 | Train | Epoch[578/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 15:03:25 | Train | Epoch[578/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 15:03:25 | Train | Epoch[578/600] Iteration[017/030] Train loss: 0.0077
2023-02-06 15:03:26 | Train | Epoch[578/600] Iteration[018/030] Train loss: 0.0078
2023-02-06 15:03:26 | Train | Epoch[578/600] Iteration[019/030] Train loss: 0.0078
2023-02-06 15:03:26 | Train | Epoch[578/600] Iteration[020/030] Train loss: 0.0078
2023-02-06 15:03:26 | Train | Epoch[578/600] Iteration[021/030] Train loss: 0.0078
2023-02-06 15:03:26 | Train | Epoch[578/600] Iteration[022/030] Train loss: 0.0079
2023-02-06 15:03:27 | Train | Epoch[578/600] Iteration[023/030] Train loss: 0.0078
2023-02-06 15:03:27 | Train | Epoch[578/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 15:03:27 | Train | Epoch[578/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 15:03:27 | Train | Epoch[578/600] Iteration[026/030] Train loss: 0.0077
2023-02-06 15:03:28 | Train | Epoch[578/600] Iteration[027/030] Train loss: 0.0077
2023-02-06 15:03:28 | Train | Epoch[578/600] Iteration[028/030] Train loss: 0.0077
2023-02-06 15:03:28 | Train | Epoch[578/600] Iteration[029/030] Train loss: 0.0077
2023-02-06 15:03:28 | Train | Epoch[578/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 15:03:28 | Valid | Epoch[578/600] Iteration[001/008] Valid loss: 0.1770
2023-02-06 15:03:29 | Valid | Epoch[578/600] Iteration[002/008] Valid loss: 0.1408
2023-02-06 15:03:29 | Valid | Epoch[578/600] Iteration[003/008] Valid loss: 0.1334
2023-02-06 15:03:29 | Valid | Epoch[578/600] Iteration[004/008] Valid loss: 0.1267
2023-02-06 15:03:29 | Valid | Epoch[578/600] Iteration[005/008] Valid loss: 0.1252
2023-02-06 15:03:29 | Valid | Epoch[578/600] Iteration[006/008] Valid loss: 0.1208
2023-02-06 15:03:29 | Valid | Epoch[578/600] Iteration[007/008] Valid loss: 0.1289
2023-02-06 15:03:29 | Valid | Epoch[578/600] Iteration[008/008] Valid loss: 0.1273
2023-02-06 15:03:29 | Valid | Epoch[578/600] MIou: 0.9298028163680676
2023-02-06 15:03:29 | Valid | Epoch[578/600] Pixel Accuracy: 0.9878934224446615
2023-02-06 15:03:29 | Valid | Epoch[578/600] Mean Pixel Accuracy: 0.9572430638527589
2023-02-06 15:03:29 | Stage | Epoch[578/600] Train loss:0.0077
2023-02-06 15:03:29 | Stage | Epoch[578/600] Valid loss:0.1273
2023-02-06 15:03:29 | Stage | Epoch[578/600] LR:0.0001

2023-02-06 15:03:29 | Train | Epoch[579/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 15:03:30 | Train | Epoch[579/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 15:03:30 | Train | Epoch[579/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 15:03:30 | Train | Epoch[579/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 15:03:30 | Train | Epoch[579/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 15:03:31 | Train | Epoch[579/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 15:03:31 | Train | Epoch[579/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 15:03:31 | Train | Epoch[579/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:03:31 | Train | Epoch[579/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 15:03:31 | Train | Epoch[579/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 15:03:32 | Train | Epoch[579/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:03:32 | Train | Epoch[579/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 15:03:32 | Train | Epoch[579/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:03:32 | Train | Epoch[579/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 15:03:32 | Train | Epoch[579/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:03:33 | Train | Epoch[579/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 15:03:33 | Train | Epoch[579/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 15:03:33 | Train | Epoch[579/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:03:33 | Train | Epoch[579/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:03:34 | Train | Epoch[579/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:03:34 | Train | Epoch[579/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:03:34 | Train | Epoch[579/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:03:34 | Train | Epoch[579/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:03:34 | Train | Epoch[579/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:03:35 | Train | Epoch[579/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:03:35 | Train | Epoch[579/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:03:35 | Train | Epoch[579/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:03:35 | Train | Epoch[579/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:03:36 | Train | Epoch[579/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:03:36 | Train | Epoch[579/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:03:36 | Valid | Epoch[579/600] Iteration[001/008] Valid loss: 0.1757
2023-02-06 15:03:36 | Valid | Epoch[579/600] Iteration[002/008] Valid loss: 0.1394
2023-02-06 15:03:36 | Valid | Epoch[579/600] Iteration[003/008] Valid loss: 0.1322
2023-02-06 15:03:36 | Valid | Epoch[579/600] Iteration[004/008] Valid loss: 0.1253
2023-02-06 15:03:36 | Valid | Epoch[579/600] Iteration[005/008] Valid loss: 0.1236
2023-02-06 15:03:36 | Valid | Epoch[579/600] Iteration[006/008] Valid loss: 0.1192
2023-02-06 15:03:36 | Valid | Epoch[579/600] Iteration[007/008] Valid loss: 0.1272
2023-02-06 15:03:36 | Valid | Epoch[579/600] Iteration[008/008] Valid loss: 0.1256
2023-02-06 15:03:36 | Valid | Epoch[579/600] MIou: 0.9297146631798316
2023-02-06 15:03:36 | Valid | Epoch[579/600] Pixel Accuracy: 0.9878870646158854
2023-02-06 15:03:36 | Valid | Epoch[579/600] Mean Pixel Accuracy: 0.9568210981991114
2023-02-06 15:03:36 | Stage | Epoch[579/600] Train loss:0.0075
2023-02-06 15:03:36 | Stage | Epoch[579/600] Valid loss:0.1256
2023-02-06 15:03:36 | Stage | Epoch[579/600] LR:0.0001

2023-02-06 15:03:37 | Train | Epoch[580/600] Iteration[001/030] Train loss: 0.0090
2023-02-06 15:03:37 | Train | Epoch[580/600] Iteration[002/030] Train loss: 0.0082
2023-02-06 15:03:37 | Train | Epoch[580/600] Iteration[003/030] Train loss: 0.0077
2023-02-06 15:03:38 | Train | Epoch[580/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 15:03:38 | Train | Epoch[580/600] Iteration[005/030] Train loss: 0.0075
2023-02-06 15:03:38 | Train | Epoch[580/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 15:03:38 | Train | Epoch[580/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 15:03:38 | Train | Epoch[580/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 15:03:39 | Train | Epoch[580/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 15:03:39 | Train | Epoch[580/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 15:03:39 | Train | Epoch[580/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:03:39 | Train | Epoch[580/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:03:40 | Train | Epoch[580/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:03:40 | Train | Epoch[580/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:03:40 | Train | Epoch[580/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:03:40 | Train | Epoch[580/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 15:03:40 | Train | Epoch[580/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:03:41 | Train | Epoch[580/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:03:41 | Train | Epoch[580/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:03:41 | Train | Epoch[580/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:03:41 | Train | Epoch[580/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:03:41 | Train | Epoch[580/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:03:42 | Train | Epoch[580/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:03:42 | Train | Epoch[580/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:03:42 | Train | Epoch[580/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:03:42 | Train | Epoch[580/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:03:43 | Train | Epoch[580/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:03:43 | Train | Epoch[580/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:03:43 | Train | Epoch[580/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:03:43 | Train | Epoch[580/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:03:44 | Valid | Epoch[580/600] Iteration[001/008] Valid loss: 0.1799
2023-02-06 15:03:44 | Valid | Epoch[580/600] Iteration[002/008] Valid loss: 0.1430
2023-02-06 15:03:44 | Valid | Epoch[580/600] Iteration[003/008] Valid loss: 0.1351
2023-02-06 15:03:44 | Valid | Epoch[580/600] Iteration[004/008] Valid loss: 0.1283
2023-02-06 15:03:44 | Valid | Epoch[580/600] Iteration[005/008] Valid loss: 0.1267
2023-02-06 15:03:44 | Valid | Epoch[580/600] Iteration[006/008] Valid loss: 0.1223
2023-02-06 15:03:44 | Valid | Epoch[580/600] Iteration[007/008] Valid loss: 0.1306
2023-02-06 15:03:44 | Valid | Epoch[580/600] Iteration[008/008] Valid loss: 0.1292
2023-02-06 15:03:44 | Valid | Epoch[580/600] MIou: 0.929996891604054
2023-02-06 15:03:44 | Valid | Epoch[580/600] Pixel Accuracy: 0.9879137674967448
2023-02-06 15:03:44 | Valid | Epoch[580/600] Mean Pixel Accuracy: 0.957932676812872
2023-02-06 15:03:44 | Stage | Epoch[580/600] Train loss:0.0075
2023-02-06 15:03:44 | Stage | Epoch[580/600] Valid loss:0.1292
2023-02-06 15:03:44 | Stage | Epoch[580/600] LR:0.0001

2023-02-06 15:03:44 | Train | Epoch[581/600] Iteration[001/030] Train loss: 0.0060
2023-02-06 15:03:45 | Train | Epoch[581/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 15:03:45 | Train | Epoch[581/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 15:03:45 | Train | Epoch[581/600] Iteration[004/030] Train loss: 0.0081
2023-02-06 15:03:45 | Train | Epoch[581/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 15:03:46 | Train | Epoch[581/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 15:03:46 | Train | Epoch[581/600] Iteration[007/030] Train loss: 0.0079
2023-02-06 15:03:46 | Train | Epoch[581/600] Iteration[008/030] Train loss: 0.0077
2023-02-06 15:03:46 | Train | Epoch[581/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 15:03:46 | Train | Epoch[581/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 15:03:47 | Train | Epoch[581/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 15:03:47 | Train | Epoch[581/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 15:03:47 | Train | Epoch[581/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 15:03:47 | Train | Epoch[581/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 15:03:48 | Train | Epoch[581/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:03:48 | Train | Epoch[581/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:03:48 | Train | Epoch[581/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:03:48 | Train | Epoch[581/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:03:48 | Train | Epoch[581/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:03:49 | Train | Epoch[581/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:03:49 | Train | Epoch[581/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:03:49 | Train | Epoch[581/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:03:49 | Train | Epoch[581/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:03:50 | Train | Epoch[581/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:03:50 | Train | Epoch[581/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:03:50 | Train | Epoch[581/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:03:50 | Train | Epoch[581/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:03:50 | Train | Epoch[581/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:03:51 | Train | Epoch[581/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 15:03:51 | Train | Epoch[581/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:03:51 | Valid | Epoch[581/600] Iteration[001/008] Valid loss: 0.1819
2023-02-06 15:03:51 | Valid | Epoch[581/600] Iteration[002/008] Valid loss: 0.1439
2023-02-06 15:03:51 | Valid | Epoch[581/600] Iteration[003/008] Valid loss: 0.1358
2023-02-06 15:03:51 | Valid | Epoch[581/600] Iteration[004/008] Valid loss: 0.1289
2023-02-06 15:03:51 | Valid | Epoch[581/600] Iteration[005/008] Valid loss: 0.1274
2023-02-06 15:03:51 | Valid | Epoch[581/600] Iteration[006/008] Valid loss: 0.1229
2023-02-06 15:03:51 | Valid | Epoch[581/600] Iteration[007/008] Valid loss: 0.1312
2023-02-06 15:03:51 | Valid | Epoch[581/600] Iteration[008/008] Valid loss: 0.1297
2023-02-06 15:03:52 | Valid | Epoch[581/600] MIou: 0.9300081199464164
2023-02-06 15:03:52 | Valid | Epoch[581/600] Pixel Accuracy: 0.9879112243652344
2023-02-06 15:03:52 | Valid | Epoch[581/600] Mean Pixel Accuracy: 0.9581151526731821
2023-02-06 15:03:52 | Stage | Epoch[581/600] Train loss:0.0076
2023-02-06 15:03:52 | Stage | Epoch[581/600] Valid loss:0.1297
2023-02-06 15:03:52 | Stage | Epoch[581/600] LR:0.0001

2023-02-06 15:03:52 | Train | Epoch[582/600] Iteration[001/030] Train loss: 0.0072
2023-02-06 15:03:52 | Train | Epoch[582/600] Iteration[002/030] Train loss: 0.0067
2023-02-06 15:03:53 | Train | Epoch[582/600] Iteration[003/030] Train loss: 0.0068
2023-02-06 15:03:53 | Train | Epoch[582/600] Iteration[004/030] Train loss: 0.0067
2023-02-06 15:03:53 | Train | Epoch[582/600] Iteration[005/030] Train loss: 0.0069
2023-02-06 15:03:53 | Train | Epoch[582/600] Iteration[006/030] Train loss: 0.0070
2023-02-06 15:03:53 | Train | Epoch[582/600] Iteration[007/030] Train loss: 0.0071
2023-02-06 15:03:54 | Train | Epoch[582/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 15:03:54 | Train | Epoch[582/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 15:03:54 | Train | Epoch[582/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 15:03:54 | Train | Epoch[582/600] Iteration[011/030] Train loss: 0.0072
2023-02-06 15:03:54 | Train | Epoch[582/600] Iteration[012/030] Train loss: 0.0072
2023-02-06 15:03:55 | Train | Epoch[582/600] Iteration[013/030] Train loss: 0.0072
2023-02-06 15:03:55 | Train | Epoch[582/600] Iteration[014/030] Train loss: 0.0073
2023-02-06 15:03:55 | Train | Epoch[582/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 15:03:55 | Train | Epoch[582/600] Iteration[016/030] Train loss: 0.0073
2023-02-06 15:03:56 | Train | Epoch[582/600] Iteration[017/030] Train loss: 0.0073
2023-02-06 15:03:56 | Train | Epoch[582/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:03:56 | Train | Epoch[582/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:03:56 | Train | Epoch[582/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:03:56 | Train | Epoch[582/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:03:57 | Train | Epoch[582/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:03:57 | Train | Epoch[582/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:03:57 | Train | Epoch[582/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:03:57 | Train | Epoch[582/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:03:58 | Train | Epoch[582/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:03:58 | Train | Epoch[582/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:03:58 | Train | Epoch[582/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:03:58 | Train | Epoch[582/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:03:58 | Train | Epoch[582/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:03:59 | Valid | Epoch[582/600] Iteration[001/008] Valid loss: 0.1782
2023-02-06 15:03:59 | Valid | Epoch[582/600] Iteration[002/008] Valid loss: 0.1417
2023-02-06 15:03:59 | Valid | Epoch[582/600] Iteration[003/008] Valid loss: 0.1339
2023-02-06 15:03:59 | Valid | Epoch[582/600] Iteration[004/008] Valid loss: 0.1272
2023-02-06 15:03:59 | Valid | Epoch[582/600] Iteration[005/008] Valid loss: 0.1258
2023-02-06 15:03:59 | Valid | Epoch[582/600] Iteration[006/008] Valid loss: 0.1213
2023-02-06 15:03:59 | Valid | Epoch[582/600] Iteration[007/008] Valid loss: 0.1295
2023-02-06 15:03:59 | Valid | Epoch[582/600] Iteration[008/008] Valid loss: 0.1280
2023-02-06 15:03:59 | Valid | Epoch[582/600] MIou: 0.9298517807324654
2023-02-06 15:03:59 | Valid | Epoch[582/600] Pixel Accuracy: 0.9878972371419271
2023-02-06 15:03:59 | Valid | Epoch[582/600] Mean Pixel Accuracy: 0.9574670770759918
2023-02-06 15:03:59 | Stage | Epoch[582/600] Train loss:0.0076
2023-02-06 15:03:59 | Stage | Epoch[582/600] Valid loss:0.1280
2023-02-06 15:03:59 | Stage | Epoch[582/600] LR:0.0001

2023-02-06 15:04:00 | Train | Epoch[583/600] Iteration[001/030] Train loss: 0.0059
2023-02-06 15:04:00 | Train | Epoch[583/600] Iteration[002/030] Train loss: 0.0068
2023-02-06 15:04:00 | Train | Epoch[583/600] Iteration[003/030] Train loss: 0.0068
2023-02-06 15:04:00 | Train | Epoch[583/600] Iteration[004/030] Train loss: 0.0069
2023-02-06 15:04:00 | Train | Epoch[583/600] Iteration[005/030] Train loss: 0.0068
2023-02-06 15:04:01 | Train | Epoch[583/600] Iteration[006/030] Train loss: 0.0067
2023-02-06 15:04:01 | Train | Epoch[583/600] Iteration[007/030] Train loss: 0.0069
2023-02-06 15:04:01 | Train | Epoch[583/600] Iteration[008/030] Train loss: 0.0068
2023-02-06 15:04:01 | Train | Epoch[583/600] Iteration[009/030] Train loss: 0.0069
2023-02-06 15:04:02 | Train | Epoch[583/600] Iteration[010/030] Train loss: 0.0070
2023-02-06 15:04:02 | Train | Epoch[583/600] Iteration[011/030] Train loss: 0.0071
2023-02-06 15:04:02 | Train | Epoch[583/600] Iteration[012/030] Train loss: 0.0072
2023-02-06 15:04:02 | Train | Epoch[583/600] Iteration[013/030] Train loss: 0.0072
2023-02-06 15:04:02 | Train | Epoch[583/600] Iteration[014/030] Train loss: 0.0072
2023-02-06 15:04:03 | Train | Epoch[583/600] Iteration[015/030] Train loss: 0.0073
2023-02-06 15:04:03 | Train | Epoch[583/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 15:04:03 | Train | Epoch[583/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:04:03 | Train | Epoch[583/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:04:04 | Train | Epoch[583/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:04:04 | Train | Epoch[583/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:04:04 | Train | Epoch[583/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:04:04 | Train | Epoch[583/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:04:04 | Train | Epoch[583/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:04:05 | Train | Epoch[583/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:04:05 | Train | Epoch[583/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:04:05 | Train | Epoch[583/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:04:05 | Train | Epoch[583/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:04:05 | Train | Epoch[583/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:04:06 | Train | Epoch[583/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:04:06 | Train | Epoch[583/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:04:06 | Valid | Epoch[583/600] Iteration[001/008] Valid loss: 0.1953
2023-02-06 15:04:06 | Valid | Epoch[583/600] Iteration[002/008] Valid loss: 0.1547
2023-02-06 15:04:06 | Valid | Epoch[583/600] Iteration[003/008] Valid loss: 0.1463
2023-02-06 15:04:06 | Valid | Epoch[583/600] Iteration[004/008] Valid loss: 0.1388
2023-02-06 15:04:06 | Valid | Epoch[583/600] Iteration[005/008] Valid loss: 0.1374
2023-02-06 15:04:06 | Valid | Epoch[583/600] Iteration[006/008] Valid loss: 0.1332
2023-02-06 15:04:06 | Valid | Epoch[583/600] Iteration[007/008] Valid loss: 0.1426
2023-02-06 15:04:07 | Valid | Epoch[583/600] Iteration[008/008] Valid loss: 0.1411
2023-02-06 15:04:07 | Valid | Epoch[583/600] MIou: 0.930245585366201
2023-02-06 15:04:07 | Valid | Epoch[583/600] Pixel Accuracy: 0.9879112243652344
2023-02-06 15:04:07 | Valid | Epoch[583/600] Mean Pixel Accuracy: 0.9599221870541249
2023-02-06 15:04:07 | Stage | Epoch[583/600] Train loss:0.0075
2023-02-06 15:04:07 | Stage | Epoch[583/600] Valid loss:0.1411
2023-02-06 15:04:07 | Stage | Epoch[583/600] LR:0.0001

2023-02-06 15:04:07 | Train | Epoch[584/600] Iteration[001/030] Train loss: 0.0087
2023-02-06 15:04:07 | Train | Epoch[584/600] Iteration[002/030] Train loss: 0.0090
2023-02-06 15:04:08 | Train | Epoch[584/600] Iteration[003/030] Train loss: 0.0083
2023-02-06 15:04:08 | Train | Epoch[584/600] Iteration[004/030] Train loss: 0.0079
2023-02-06 15:04:08 | Train | Epoch[584/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 15:04:08 | Train | Epoch[584/600] Iteration[006/030] Train loss: 0.0076
2023-02-06 15:04:08 | Train | Epoch[584/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 15:04:09 | Train | Epoch[584/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:04:09 | Train | Epoch[584/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 15:04:09 | Train | Epoch[584/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 15:04:09 | Train | Epoch[584/600] Iteration[011/030] Train loss: 0.0074
2023-02-06 15:04:10 | Train | Epoch[584/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 15:04:10 | Train | Epoch[584/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:04:10 | Train | Epoch[584/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:04:10 | Train | Epoch[584/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:04:10 | Train | Epoch[584/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:04:11 | Train | Epoch[584/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:04:11 | Train | Epoch[584/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:04:11 | Train | Epoch[584/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:04:11 | Train | Epoch[584/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:04:12 | Train | Epoch[584/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 15:04:12 | Train | Epoch[584/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:04:12 | Train | Epoch[584/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:04:12 | Train | Epoch[584/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:04:12 | Train | Epoch[584/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:04:13 | Train | Epoch[584/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 15:04:13 | Train | Epoch[584/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:04:13 | Train | Epoch[584/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 15:04:13 | Train | Epoch[584/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:04:13 | Train | Epoch[584/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:04:14 | Valid | Epoch[584/600] Iteration[001/008] Valid loss: 0.1777
2023-02-06 15:04:14 | Valid | Epoch[584/600] Iteration[002/008] Valid loss: 0.1415
2023-02-06 15:04:14 | Valid | Epoch[584/600] Iteration[003/008] Valid loss: 0.1341
2023-02-06 15:04:14 | Valid | Epoch[584/600] Iteration[004/008] Valid loss: 0.1274
2023-02-06 15:04:14 | Valid | Epoch[584/600] Iteration[005/008] Valid loss: 0.1259
2023-02-06 15:04:14 | Valid | Epoch[584/600] Iteration[006/008] Valid loss: 0.1216
2023-02-06 15:04:14 | Valid | Epoch[584/600] Iteration[007/008] Valid loss: 0.1299
2023-02-06 15:04:14 | Valid | Epoch[584/600] Iteration[008/008] Valid loss: 0.1283
2023-02-06 15:04:14 | Valid | Epoch[584/600] MIou: 0.9296004886066576
2023-02-06 15:04:14 | Valid | Epoch[584/600] Pixel Accuracy: 0.9878501892089844
2023-02-06 15:04:14 | Valid | Epoch[584/600] Mean Pixel Accuracy: 0.9573651318673557
2023-02-06 15:04:14 | Stage | Epoch[584/600] Train loss:0.0075
2023-02-06 15:04:14 | Stage | Epoch[584/600] Valid loss:0.1283
2023-02-06 15:04:14 | Stage | Epoch[584/600] LR:0.0001

2023-02-06 15:04:15 | Train | Epoch[585/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 15:04:15 | Train | Epoch[585/600] Iteration[002/030] Train loss: 0.0068
2023-02-06 15:04:15 | Train | Epoch[585/600] Iteration[003/030] Train loss: 0.0073
2023-02-06 15:04:15 | Train | Epoch[585/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 15:04:16 | Train | Epoch[585/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 15:04:16 | Train | Epoch[585/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 15:04:16 | Train | Epoch[585/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 15:04:16 | Train | Epoch[585/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 15:04:16 | Train | Epoch[585/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 15:04:17 | Train | Epoch[585/600] Iteration[010/030] Train loss: 0.0072
2023-02-06 15:04:17 | Train | Epoch[585/600] Iteration[011/030] Train loss: 0.0072
2023-02-06 15:04:17 | Train | Epoch[585/600] Iteration[012/030] Train loss: 0.0072
2023-02-06 15:04:17 | Train | Epoch[585/600] Iteration[013/030] Train loss: 0.0073
2023-02-06 15:04:18 | Train | Epoch[585/600] Iteration[014/030] Train loss: 0.0073
2023-02-06 15:04:18 | Train | Epoch[585/600] Iteration[015/030] Train loss: 0.0073
2023-02-06 15:04:18 | Train | Epoch[585/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 15:04:18 | Train | Epoch[585/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 15:04:18 | Train | Epoch[585/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:04:19 | Train | Epoch[585/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:04:19 | Train | Epoch[585/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:04:19 | Train | Epoch[585/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 15:04:19 | Train | Epoch[585/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:04:20 | Train | Epoch[585/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:04:20 | Train | Epoch[585/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:04:20 | Train | Epoch[585/600] Iteration[025/030] Train loss: 0.0073
2023-02-06 15:04:20 | Train | Epoch[585/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 15:04:20 | Train | Epoch[585/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:04:21 | Train | Epoch[585/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 15:04:21 | Train | Epoch[585/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:04:21 | Train | Epoch[585/600] Iteration[030/030] Train loss: 0.0074
2023-02-06 15:04:21 | Valid | Epoch[585/600] Iteration[001/008] Valid loss: 0.1717
2023-02-06 15:04:21 | Valid | Epoch[585/600] Iteration[002/008] Valid loss: 0.1362
2023-02-06 15:04:21 | Valid | Epoch[585/600] Iteration[003/008] Valid loss: 0.1291
2023-02-06 15:04:21 | Valid | Epoch[585/600] Iteration[004/008] Valid loss: 0.1225
2023-02-06 15:04:21 | Valid | Epoch[585/600] Iteration[005/008] Valid loss: 0.1206
2023-02-06 15:04:21 | Valid | Epoch[585/600] Iteration[006/008] Valid loss: 0.1165
2023-02-06 15:04:22 | Valid | Epoch[585/600] Iteration[007/008] Valid loss: 0.1241
2023-02-06 15:04:22 | Valid | Epoch[585/600] Iteration[008/008] Valid loss: 0.1225
2023-02-06 15:04:22 | Valid | Epoch[585/600] MIou: 0.9293612356679554
2023-02-06 15:04:22 | Valid | Epoch[585/600] Pixel Accuracy: 0.9878374735514323
2023-02-06 15:04:22 | Valid | Epoch[585/600] Mean Pixel Accuracy: 0.956052005668167
2023-02-06 15:04:22 | Stage | Epoch[585/600] Train loss:0.0074
2023-02-06 15:04:22 | Stage | Epoch[585/600] Valid loss:0.1225
2023-02-06 15:04:22 | Stage | Epoch[585/600] LR:0.0001

2023-02-06 15:04:22 | Train | Epoch[586/600] Iteration[001/030] Train loss: 0.0076
2023-02-06 15:04:22 | Train | Epoch[586/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 15:04:23 | Train | Epoch[586/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 15:04:23 | Train | Epoch[586/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 15:04:23 | Train | Epoch[586/600] Iteration[005/030] Train loss: 0.0074
2023-02-06 15:04:23 | Train | Epoch[586/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 15:04:23 | Train | Epoch[586/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 15:04:24 | Train | Epoch[586/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 15:04:24 | Train | Epoch[586/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 15:04:24 | Train | Epoch[586/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 15:04:24 | Train | Epoch[586/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:04:25 | Train | Epoch[586/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:04:25 | Train | Epoch[586/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:04:25 | Train | Epoch[586/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 15:04:25 | Train | Epoch[586/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 15:04:25 | Train | Epoch[586/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 15:04:26 | Train | Epoch[586/600] Iteration[017/030] Train loss: 0.0078
2023-02-06 15:04:26 | Train | Epoch[586/600] Iteration[018/030] Train loss: 0.0077
2023-02-06 15:04:26 | Train | Epoch[586/600] Iteration[019/030] Train loss: 0.0077
2023-02-06 15:04:26 | Train | Epoch[586/600] Iteration[020/030] Train loss: 0.0077
2023-02-06 15:04:27 | Train | Epoch[586/600] Iteration[021/030] Train loss: 0.0077
2023-02-06 15:04:27 | Train | Epoch[586/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 15:04:27 | Train | Epoch[586/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 15:04:27 | Train | Epoch[586/600] Iteration[024/030] Train loss: 0.0077
2023-02-06 15:04:27 | Train | Epoch[586/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 15:04:28 | Train | Epoch[586/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 15:04:28 | Train | Epoch[586/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:04:28 | Train | Epoch[586/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:04:28 | Train | Epoch[586/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 15:04:28 | Train | Epoch[586/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 15:04:29 | Valid | Epoch[586/600] Iteration[001/008] Valid loss: 0.1811
2023-02-06 15:04:29 | Valid | Epoch[586/600] Iteration[002/008] Valid loss: 0.1442
2023-02-06 15:04:29 | Valid | Epoch[586/600] Iteration[003/008] Valid loss: 0.1362
2023-02-06 15:04:29 | Valid | Epoch[586/600] Iteration[004/008] Valid loss: 0.1295
2023-02-06 15:04:29 | Valid | Epoch[586/600] Iteration[005/008] Valid loss: 0.1281
2023-02-06 15:04:29 | Valid | Epoch[586/600] Iteration[006/008] Valid loss: 0.1236
2023-02-06 15:04:29 | Valid | Epoch[586/600] Iteration[007/008] Valid loss: 0.1320
2023-02-06 15:04:29 | Valid | Epoch[586/600] Iteration[008/008] Valid loss: 0.1305
2023-02-06 15:04:29 | Valid | Epoch[586/600] MIou: 0.9302732665254442
2023-02-06 15:04:29 | Valid | Epoch[586/600] Pixel Accuracy: 0.9879531860351562
2023-02-06 15:04:29 | Valid | Epoch[586/600] Mean Pixel Accuracy: 0.958518644887318
2023-02-06 15:04:29 | Stage | Epoch[586/600] Train loss:0.0077
2023-02-06 15:04:29 | Stage | Epoch[586/600] Valid loss:0.1305
2023-02-06 15:04:29 | Stage | Epoch[586/600] LR:0.0001

2023-02-06 15:04:30 | Train | Epoch[587/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 15:04:30 | Train | Epoch[587/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 15:04:30 | Train | Epoch[587/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 15:04:30 | Train | Epoch[587/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 15:04:31 | Train | Epoch[587/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 15:04:31 | Train | Epoch[587/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 15:04:31 | Train | Epoch[587/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 15:04:31 | Train | Epoch[587/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 15:04:31 | Train | Epoch[587/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 15:04:32 | Train | Epoch[587/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 15:04:32 | Train | Epoch[587/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 15:04:32 | Train | Epoch[587/600] Iteration[012/030] Train loss: 0.0073
2023-02-06 15:04:32 | Train | Epoch[587/600] Iteration[013/030] Train loss: 0.0072
2023-02-06 15:04:33 | Train | Epoch[587/600] Iteration[014/030] Train loss: 0.0073
2023-02-06 15:04:33 | Train | Epoch[587/600] Iteration[015/030] Train loss: 0.0073
2023-02-06 15:04:33 | Train | Epoch[587/600] Iteration[016/030] Train loss: 0.0073
2023-02-06 15:04:33 | Train | Epoch[587/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 15:04:33 | Train | Epoch[587/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:04:34 | Train | Epoch[587/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:04:34 | Train | Epoch[587/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:04:34 | Train | Epoch[587/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:04:34 | Train | Epoch[587/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:04:35 | Train | Epoch[587/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:04:35 | Train | Epoch[587/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:04:35 | Train | Epoch[587/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:04:35 | Train | Epoch[587/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:04:35 | Train | Epoch[587/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:04:36 | Train | Epoch[587/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 15:04:36 | Train | Epoch[587/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 15:04:36 | Train | Epoch[587/600] Iteration[030/030] Train loss: 0.0074
2023-02-06 15:04:36 | Valid | Epoch[587/600] Iteration[001/008] Valid loss: 0.1861
2023-02-06 15:04:36 | Valid | Epoch[587/600] Iteration[002/008] Valid loss: 0.1473
2023-02-06 15:04:36 | Valid | Epoch[587/600] Iteration[003/008] Valid loss: 0.1397
2023-02-06 15:04:36 | Valid | Epoch[587/600] Iteration[004/008] Valid loss: 0.1321
2023-02-06 15:04:36 | Valid | Epoch[587/600] Iteration[005/008] Valid loss: 0.1304
2023-02-06 15:04:37 | Valid | Epoch[587/600] Iteration[006/008] Valid loss: 0.1262
2023-02-06 15:04:37 | Valid | Epoch[587/600] Iteration[007/008] Valid loss: 0.1351
2023-02-06 15:04:37 | Valid | Epoch[587/600] Iteration[008/008] Valid loss: 0.1335
2023-02-06 15:04:37 | Valid | Epoch[587/600] MIou: 0.9301048542529298
2023-02-06 15:04:37 | Valid | Epoch[587/600] Pixel Accuracy: 0.9879188537597656
2023-02-06 15:04:37 | Valid | Epoch[587/600] Mean Pixel Accuracy: 0.9585568386481359
2023-02-06 15:04:37 | Stage | Epoch[587/600] Train loss:0.0074
2023-02-06 15:04:37 | Stage | Epoch[587/600] Valid loss:0.1335
2023-02-06 15:04:37 | Stage | Epoch[587/600] LR:0.0001

2023-02-06 15:04:37 | Train | Epoch[588/600] Iteration[001/030] Train loss: 0.0074
2023-02-06 15:04:37 | Train | Epoch[588/600] Iteration[002/030] Train loss: 0.0083
2023-02-06 15:04:38 | Train | Epoch[588/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 15:04:38 | Train | Epoch[588/600] Iteration[004/030] Train loss: 0.0076
2023-02-06 15:04:38 | Train | Epoch[588/600] Iteration[005/030] Train loss: 0.0074
2023-02-06 15:04:38 | Train | Epoch[588/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 15:04:39 | Train | Epoch[588/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 15:04:39 | Train | Epoch[588/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 15:04:39 | Train | Epoch[588/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 15:04:39 | Train | Epoch[588/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 15:04:39 | Train | Epoch[588/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 15:04:40 | Train | Epoch[588/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 15:04:40 | Train | Epoch[588/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:04:40 | Train | Epoch[588/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:04:40 | Train | Epoch[588/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 15:04:40 | Train | Epoch[588/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 15:04:41 | Train | Epoch[588/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 15:04:41 | Train | Epoch[588/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:04:41 | Train | Epoch[588/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:04:41 | Train | Epoch[588/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:04:42 | Train | Epoch[588/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:04:42 | Train | Epoch[588/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:04:42 | Train | Epoch[588/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:04:42 | Train | Epoch[588/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:04:42 | Train | Epoch[588/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:04:43 | Train | Epoch[588/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:04:43 | Train | Epoch[588/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:04:43 | Train | Epoch[588/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:04:43 | Train | Epoch[588/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:04:43 | Train | Epoch[588/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:04:44 | Valid | Epoch[588/600] Iteration[001/008] Valid loss: 0.1606
2023-02-06 15:04:44 | Valid | Epoch[588/600] Iteration[002/008] Valid loss: 0.1277
2023-02-06 15:04:44 | Valid | Epoch[588/600] Iteration[003/008] Valid loss: 0.1205
2023-02-06 15:04:44 | Valid | Epoch[588/600] Iteration[004/008] Valid loss: 0.1142
2023-02-06 15:04:44 | Valid | Epoch[588/600] Iteration[005/008] Valid loss: 0.1123
2023-02-06 15:04:44 | Valid | Epoch[588/600] Iteration[006/008] Valid loss: 0.1080
2023-02-06 15:04:44 | Valid | Epoch[588/600] Iteration[007/008] Valid loss: 0.1146
2023-02-06 15:04:44 | Valid | Epoch[588/600] Iteration[008/008] Valid loss: 0.1129
2023-02-06 15:04:44 | Valid | Epoch[588/600] MIou: 0.9290894392847728
2023-02-06 15:04:44 | Valid | Epoch[588/600] Pixel Accuracy: 0.9878349304199219
2023-02-06 15:04:44 | Valid | Epoch[588/600] Mean Pixel Accuracy: 0.9541231045149547
2023-02-06 15:04:44 | Stage | Epoch[588/600] Train loss:0.0076
2023-02-06 15:04:44 | Stage | Epoch[588/600] Valid loss:0.1129
2023-02-06 15:04:44 | Stage | Epoch[588/600] LR:0.0001

2023-02-06 15:04:45 | Train | Epoch[589/600] Iteration[001/030] Train loss: 0.0079
2023-02-06 15:04:45 | Train | Epoch[589/600] Iteration[002/030] Train loss: 0.0077
2023-02-06 15:04:45 | Train | Epoch[589/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 15:04:45 | Train | Epoch[589/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 15:04:46 | Train | Epoch[589/600] Iteration[005/030] Train loss: 0.0078
2023-02-06 15:04:46 | Train | Epoch[589/600] Iteration[006/030] Train loss: 0.0078
2023-02-06 15:04:46 | Train | Epoch[589/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 15:04:46 | Train | Epoch[589/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:04:46 | Train | Epoch[589/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 15:04:47 | Train | Epoch[589/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 15:04:47 | Train | Epoch[589/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:04:47 | Train | Epoch[589/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 15:04:47 | Train | Epoch[589/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:04:48 | Train | Epoch[589/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:04:48 | Train | Epoch[589/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 15:04:48 | Train | Epoch[589/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:04:48 | Train | Epoch[589/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:04:48 | Train | Epoch[589/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:04:49 | Train | Epoch[589/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:04:49 | Train | Epoch[589/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:04:49 | Train | Epoch[589/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:04:49 | Train | Epoch[589/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:04:50 | Train | Epoch[589/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:04:50 | Train | Epoch[589/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:04:50 | Train | Epoch[589/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:04:50 | Train | Epoch[589/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 15:04:50 | Train | Epoch[589/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:04:51 | Train | Epoch[589/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:04:51 | Train | Epoch[589/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 15:04:51 | Train | Epoch[589/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 15:04:51 | Valid | Epoch[589/600] Iteration[001/008] Valid loss: 0.1886
2023-02-06 15:04:51 | Valid | Epoch[589/600] Iteration[002/008] Valid loss: 0.1502
2023-02-06 15:04:51 | Valid | Epoch[589/600] Iteration[003/008] Valid loss: 0.1424
2023-02-06 15:04:51 | Valid | Epoch[589/600] Iteration[004/008] Valid loss: 0.1350
2023-02-06 15:04:51 | Valid | Epoch[589/600] Iteration[005/008] Valid loss: 0.1336
2023-02-06 15:04:52 | Valid | Epoch[589/600] Iteration[006/008] Valid loss: 0.1295
2023-02-06 15:04:52 | Valid | Epoch[589/600] Iteration[007/008] Valid loss: 0.1385
2023-02-06 15:04:52 | Valid | Epoch[589/600] Iteration[008/008] Valid loss: 0.1368
2023-02-06 15:04:52 | Valid | Epoch[589/600] MIou: 0.9301813779692103
2023-02-06 15:04:52 | Valid | Epoch[589/600] Pixel Accuracy: 0.9879201253255209
2023-02-06 15:04:52 | Valid | Epoch[589/600] Mean Pixel Accuracy: 0.9590901371619206
2023-02-06 15:04:52 | Stage | Epoch[589/600] Train loss:0.0078
2023-02-06 15:04:52 | Stage | Epoch[589/600] Valid loss:0.1368
2023-02-06 15:04:52 | Stage | Epoch[589/600] LR:0.0001

2023-02-06 15:04:52 | Train | Epoch[590/600] Iteration[001/030] Train loss: 0.0075
2023-02-06 15:04:52 | Train | Epoch[590/600] Iteration[002/030] Train loss: 0.0075
2023-02-06 15:04:53 | Train | Epoch[590/600] Iteration[003/030] Train loss: 0.0074
2023-02-06 15:04:53 | Train | Epoch[590/600] Iteration[004/030] Train loss: 0.0073
2023-02-06 15:04:53 | Train | Epoch[590/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 15:04:53 | Train | Epoch[590/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 15:04:54 | Train | Epoch[590/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 15:04:54 | Train | Epoch[590/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:04:54 | Train | Epoch[590/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 15:04:54 | Train | Epoch[590/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 15:04:54 | Train | Epoch[590/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 15:04:55 | Train | Epoch[590/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 15:04:55 | Train | Epoch[590/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 15:04:55 | Train | Epoch[590/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 15:04:55 | Train | Epoch[590/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:04:55 | Train | Epoch[590/600] Iteration[016/030] Train loss: 0.0076
2023-02-06 15:04:56 | Train | Epoch[590/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 15:04:56 | Train | Epoch[590/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 15:04:56 | Train | Epoch[590/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:04:56 | Train | Epoch[590/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:04:57 | Train | Epoch[590/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 15:04:57 | Train | Epoch[590/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:04:57 | Train | Epoch[590/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:04:57 | Train | Epoch[590/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:04:57 | Train | Epoch[590/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:04:58 | Train | Epoch[590/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 15:04:58 | Train | Epoch[590/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:04:58 | Train | Epoch[590/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:04:58 | Train | Epoch[590/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 15:04:58 | Train | Epoch[590/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:04:59 | Valid | Epoch[590/600] Iteration[001/008] Valid loss: 0.1776
2023-02-06 15:04:59 | Valid | Epoch[590/600] Iteration[002/008] Valid loss: 0.1405
2023-02-06 15:04:59 | Valid | Epoch[590/600] Iteration[003/008] Valid loss: 0.1332
2023-02-06 15:04:59 | Valid | Epoch[590/600] Iteration[004/008] Valid loss: 0.1264
2023-02-06 15:04:59 | Valid | Epoch[590/600] Iteration[005/008] Valid loss: 0.1249
2023-02-06 15:04:59 | Valid | Epoch[590/600] Iteration[006/008] Valid loss: 0.1204
2023-02-06 15:04:59 | Valid | Epoch[590/600] Iteration[007/008] Valid loss: 0.1284
2023-02-06 15:04:59 | Valid | Epoch[590/600] Iteration[008/008] Valid loss: 0.1268
2023-02-06 15:04:59 | Valid | Epoch[590/600] MIou: 0.9299081304015948
2023-02-06 15:04:59 | Valid | Epoch[590/600] Pixel Accuracy: 0.9879188537597656
2023-02-06 15:04:59 | Valid | Epoch[590/600] Mean Pixel Accuracy: 0.9570668278427972
2023-02-06 15:04:59 | Stage | Epoch[590/600] Train loss:0.0076
2023-02-06 15:04:59 | Stage | Epoch[590/600] Valid loss:0.1268
2023-02-06 15:04:59 | Stage | Epoch[590/600] LR:0.0001

2023-02-06 15:05:00 | Train | Epoch[591/600] Iteration[001/030] Train loss: 0.0084
2023-02-06 15:05:00 | Train | Epoch[591/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 15:05:00 | Train | Epoch[591/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 15:05:00 | Train | Epoch[591/600] Iteration[004/030] Train loss: 0.0075
2023-02-06 15:05:01 | Train | Epoch[591/600] Iteration[005/030] Train loss: 0.0079
2023-02-06 15:05:01 | Train | Epoch[591/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 15:05:01 | Train | Epoch[591/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 15:05:01 | Train | Epoch[591/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 15:05:01 | Train | Epoch[591/600] Iteration[009/030] Train loss: 0.0075
2023-02-06 15:05:02 | Train | Epoch[591/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 15:05:02 | Train | Epoch[591/600] Iteration[011/030] Train loss: 0.0077
2023-02-06 15:05:02 | Train | Epoch[591/600] Iteration[012/030] Train loss: 0.0076
2023-02-06 15:05:02 | Train | Epoch[591/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:05:03 | Train | Epoch[591/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:05:03 | Train | Epoch[591/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:05:03 | Train | Epoch[591/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:05:03 | Train | Epoch[591/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:05:03 | Train | Epoch[591/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:05:04 | Train | Epoch[591/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:05:04 | Train | Epoch[591/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:05:04 | Train | Epoch[591/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 15:05:04 | Train | Epoch[591/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:05:05 | Train | Epoch[591/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:05:05 | Train | Epoch[591/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:05:05 | Train | Epoch[591/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 15:05:05 | Train | Epoch[591/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 15:05:05 | Train | Epoch[591/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:05:06 | Train | Epoch[591/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:05:06 | Train | Epoch[591/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:05:06 | Train | Epoch[591/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:05:06 | Valid | Epoch[591/600] Iteration[001/008] Valid loss: 0.1720
2023-02-06 15:05:06 | Valid | Epoch[591/600] Iteration[002/008] Valid loss: 0.1364
2023-02-06 15:05:06 | Valid | Epoch[591/600] Iteration[003/008] Valid loss: 0.1292
2023-02-06 15:05:06 | Valid | Epoch[591/600] Iteration[004/008] Valid loss: 0.1224
2023-02-06 15:05:07 | Valid | Epoch[591/600] Iteration[005/008] Valid loss: 0.1206
2023-02-06 15:05:07 | Valid | Epoch[591/600] Iteration[006/008] Valid loss: 0.1164
2023-02-06 15:05:07 | Valid | Epoch[591/600] Iteration[007/008] Valid loss: 0.1242
2023-02-06 15:05:07 | Valid | Epoch[591/600] Iteration[008/008] Valid loss: 0.1225
2023-02-06 15:05:07 | Valid | Epoch[591/600] MIou: 0.9293842106917585
2023-02-06 15:05:07 | Valid | Epoch[591/600] Pixel Accuracy: 0.9878412882486979
2023-02-06 15:05:07 | Valid | Epoch[591/600] Mean Pixel Accuracy: 0.9560794642745254
2023-02-06 15:05:07 | Stage | Epoch[591/600] Train loss:0.0075
2023-02-06 15:05:07 | Stage | Epoch[591/600] Valid loss:0.1225
2023-02-06 15:05:07 | Stage | Epoch[591/600] LR:0.0001

2023-02-06 15:05:07 | Train | Epoch[592/600] Iteration[001/030] Train loss: 0.0085
2023-02-06 15:05:07 | Train | Epoch[592/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 15:05:08 | Train | Epoch[592/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 15:05:08 | Train | Epoch[592/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 15:05:08 | Train | Epoch[592/600] Iteration[005/030] Train loss: 0.0080
2023-02-06 15:05:08 | Train | Epoch[592/600] Iteration[006/030] Train loss: 0.0079
2023-02-06 15:05:08 | Train | Epoch[592/600] Iteration[007/030] Train loss: 0.0078
2023-02-06 15:05:09 | Train | Epoch[592/600] Iteration[008/030] Train loss: 0.0076
2023-02-06 15:05:09 | Train | Epoch[592/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 15:05:09 | Train | Epoch[592/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 15:05:09 | Train | Epoch[592/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:05:10 | Train | Epoch[592/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:05:10 | Train | Epoch[592/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:05:10 | Train | Epoch[592/600] Iteration[014/030] Train loss: 0.0076
2023-02-06 15:05:10 | Train | Epoch[592/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 15:05:10 | Train | Epoch[592/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:05:11 | Train | Epoch[592/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:05:11 | Train | Epoch[592/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 15:05:11 | Train | Epoch[592/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 15:05:11 | Train | Epoch[592/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:05:12 | Train | Epoch[592/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:05:12 | Train | Epoch[592/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:05:12 | Train | Epoch[592/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:05:12 | Train | Epoch[592/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:05:12 | Train | Epoch[592/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:05:13 | Train | Epoch[592/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 15:05:13 | Train | Epoch[592/600] Iteration[027/030] Train loss: 0.0076
2023-02-06 15:05:13 | Train | Epoch[592/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:05:13 | Train | Epoch[592/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 15:05:13 | Train | Epoch[592/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:05:14 | Valid | Epoch[592/600] Iteration[001/008] Valid loss: 0.1692
2023-02-06 15:05:14 | Valid | Epoch[592/600] Iteration[002/008] Valid loss: 0.1343
2023-02-06 15:05:14 | Valid | Epoch[592/600] Iteration[003/008] Valid loss: 0.1271
2023-02-06 15:05:14 | Valid | Epoch[592/600] Iteration[004/008] Valid loss: 0.1207
2023-02-06 15:05:14 | Valid | Epoch[592/600] Iteration[005/008] Valid loss: 0.1189
2023-02-06 15:05:14 | Valid | Epoch[592/600] Iteration[006/008] Valid loss: 0.1145
2023-02-06 15:05:14 | Valid | Epoch[592/600] Iteration[007/008] Valid loss: 0.1222
2023-02-06 15:05:14 | Valid | Epoch[592/600] Iteration[008/008] Valid loss: 0.1206
2023-02-06 15:05:14 | Valid | Epoch[592/600] MIou: 0.9292439141237835
2023-02-06 15:05:14 | Valid | Epoch[592/600] Pixel Accuracy: 0.9878260294596354
2023-02-06 15:05:14 | Valid | Epoch[592/600] Mean Pixel Accuracy: 0.9556082229729033
2023-02-06 15:05:14 | Stage | Epoch[592/600] Train loss:0.0076
2023-02-06 15:05:14 | Stage | Epoch[592/600] Valid loss:0.1206
2023-02-06 15:05:14 | Stage | Epoch[592/600] LR:0.0001

2023-02-06 15:05:15 | Train | Epoch[593/600] Iteration[001/030] Train loss: 0.0076
2023-02-06 15:05:15 | Train | Epoch[593/600] Iteration[002/030] Train loss: 0.0072
2023-02-06 15:05:15 | Train | Epoch[593/600] Iteration[003/030] Train loss: 0.0075
2023-02-06 15:05:15 | Train | Epoch[593/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 15:05:16 | Train | Epoch[593/600] Iteration[005/030] Train loss: 0.0074
2023-02-06 15:05:16 | Train | Epoch[593/600] Iteration[006/030] Train loss: 0.0074
2023-02-06 15:05:16 | Train | Epoch[593/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 15:05:16 | Train | Epoch[593/600] Iteration[008/030] Train loss: 0.0074
2023-02-06 15:05:16 | Train | Epoch[593/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 15:05:17 | Train | Epoch[593/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 15:05:17 | Train | Epoch[593/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 15:05:17 | Train | Epoch[593/600] Iteration[012/030] Train loss: 0.0072
2023-02-06 15:05:17 | Train | Epoch[593/600] Iteration[013/030] Train loss: 0.0073
2023-02-06 15:05:18 | Train | Epoch[593/600] Iteration[014/030] Train loss: 0.0072
2023-02-06 15:05:18 | Train | Epoch[593/600] Iteration[015/030] Train loss: 0.0073
2023-02-06 15:05:18 | Train | Epoch[593/600] Iteration[016/030] Train loss: 0.0073
2023-02-06 15:05:18 | Train | Epoch[593/600] Iteration[017/030] Train loss: 0.0073
2023-02-06 15:05:18 | Train | Epoch[593/600] Iteration[018/030] Train loss: 0.0072
2023-02-06 15:05:19 | Train | Epoch[593/600] Iteration[019/030] Train loss: 0.0073
2023-02-06 15:05:19 | Train | Epoch[593/600] Iteration[020/030] Train loss: 0.0073
2023-02-06 15:05:19 | Train | Epoch[593/600] Iteration[021/030] Train loss: 0.0073
2023-02-06 15:05:19 | Train | Epoch[593/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:05:20 | Train | Epoch[593/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:05:20 | Train | Epoch[593/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:05:20 | Train | Epoch[593/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:05:20 | Train | Epoch[593/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 15:05:20 | Train | Epoch[593/600] Iteration[027/030] Train loss: 0.0074
2023-02-06 15:05:21 | Train | Epoch[593/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 15:05:21 | Train | Epoch[593/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 15:05:21 | Train | Epoch[593/600] Iteration[030/030] Train loss: 0.0075
2023-02-06 15:05:21 | Valid | Epoch[593/600] Iteration[001/008] Valid loss: 0.1787
2023-02-06 15:05:21 | Valid | Epoch[593/600] Iteration[002/008] Valid loss: 0.1417
2023-02-06 15:05:21 | Valid | Epoch[593/600] Iteration[003/008] Valid loss: 0.1341
2023-02-06 15:05:21 | Valid | Epoch[593/600] Iteration[004/008] Valid loss: 0.1272
2023-02-06 15:05:21 | Valid | Epoch[593/600] Iteration[005/008] Valid loss: 0.1257
2023-02-06 15:05:22 | Valid | Epoch[593/600] Iteration[006/008] Valid loss: 0.1212
2023-02-06 15:05:22 | Valid | Epoch[593/600] Iteration[007/008] Valid loss: 0.1296
2023-02-06 15:05:22 | Valid | Epoch[593/600] Iteration[008/008] Valid loss: 0.1282
2023-02-06 15:05:22 | Valid | Epoch[593/600] MIou: 0.9299580037442764
2023-02-06 15:05:22 | Valid | Epoch[593/600] Pixel Accuracy: 0.9879163106282552
2023-02-06 15:05:22 | Valid | Epoch[593/600] Mean Pixel Accuracy: 0.9575409653926631
2023-02-06 15:05:22 | Stage | Epoch[593/600] Train loss:0.0075
2023-02-06 15:05:22 | Stage | Epoch[593/600] Valid loss:0.1282
2023-02-06 15:05:22 | Stage | Epoch[593/600] LR:0.0001

2023-02-06 15:05:22 | Train | Epoch[594/600] Iteration[001/030] Train loss: 0.0076
2023-02-06 15:05:22 | Train | Epoch[594/600] Iteration[002/030] Train loss: 0.0080
2023-02-06 15:05:23 | Train | Epoch[594/600] Iteration[003/030] Train loss: 0.0085
2023-02-06 15:05:23 | Train | Epoch[594/600] Iteration[004/030] Train loss: 0.0083
2023-02-06 15:05:23 | Train | Epoch[594/600] Iteration[005/030] Train loss: 0.0084
2023-02-06 15:05:23 | Train | Epoch[594/600] Iteration[006/030] Train loss: 0.0083
2023-02-06 15:05:23 | Train | Epoch[594/600] Iteration[007/030] Train loss: 0.0081
2023-02-06 15:05:24 | Train | Epoch[594/600] Iteration[008/030] Train loss: 0.0079
2023-02-06 15:05:24 | Train | Epoch[594/600] Iteration[009/030] Train loss: 0.0080
2023-02-06 15:05:24 | Train | Epoch[594/600] Iteration[010/030] Train loss: 0.0079
2023-02-06 15:05:24 | Train | Epoch[594/600] Iteration[011/030] Train loss: 0.0078
2023-02-06 15:05:25 | Train | Epoch[594/600] Iteration[012/030] Train loss: 0.0078
2023-02-06 15:05:25 | Train | Epoch[594/600] Iteration[013/030] Train loss: 0.0077
2023-02-06 15:05:25 | Train | Epoch[594/600] Iteration[014/030] Train loss: 0.0077
2023-02-06 15:05:25 | Train | Epoch[594/600] Iteration[015/030] Train loss: 0.0077
2023-02-06 15:05:25 | Train | Epoch[594/600] Iteration[016/030] Train loss: 0.0077
2023-02-06 15:05:26 | Train | Epoch[594/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 15:05:26 | Train | Epoch[594/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 15:05:26 | Train | Epoch[594/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 15:05:26 | Train | Epoch[594/600] Iteration[020/030] Train loss: 0.0076
2023-02-06 15:05:27 | Train | Epoch[594/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 15:05:27 | Train | Epoch[594/600] Iteration[022/030] Train loss: 0.0076
2023-02-06 15:05:27 | Train | Epoch[594/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 15:05:27 | Train | Epoch[594/600] Iteration[024/030] Train loss: 0.0076
2023-02-06 15:05:27 | Train | Epoch[594/600] Iteration[025/030] Train loss: 0.0076
2023-02-06 15:05:28 | Train | Epoch[594/600] Iteration[026/030] Train loss: 0.0076
2023-02-06 15:05:28 | Train | Epoch[594/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:05:28 | Train | Epoch[594/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:05:28 | Train | Epoch[594/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:05:28 | Train | Epoch[594/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:05:29 | Valid | Epoch[594/600] Iteration[001/008] Valid loss: 0.1800
2023-02-06 15:05:29 | Valid | Epoch[594/600] Iteration[002/008] Valid loss: 0.1423
2023-02-06 15:05:29 | Valid | Epoch[594/600] Iteration[003/008] Valid loss: 0.1346
2023-02-06 15:05:29 | Valid | Epoch[594/600] Iteration[004/008] Valid loss: 0.1277
2023-02-06 15:05:29 | Valid | Epoch[594/600] Iteration[005/008] Valid loss: 0.1260
2023-02-06 15:05:29 | Valid | Epoch[594/600] Iteration[006/008] Valid loss: 0.1215
2023-02-06 15:05:29 | Valid | Epoch[594/600] Iteration[007/008] Valid loss: 0.1297
2023-02-06 15:05:29 | Valid | Epoch[594/600] Iteration[008/008] Valid loss: 0.1282
2023-02-06 15:05:29 | Valid | Epoch[594/600] MIou: 0.9298112193838608
2023-02-06 15:05:29 | Valid | Epoch[594/600] Pixel Accuracy: 0.9878934224446615
2023-02-06 15:05:29 | Valid | Epoch[594/600] Mean Pixel Accuracy: 0.9573064685678797
2023-02-06 15:05:29 | Stage | Epoch[594/600] Train loss:0.0076
2023-02-06 15:05:29 | Stage | Epoch[594/600] Valid loss:0.1282
2023-02-06 15:05:29 | Stage | Epoch[594/600] LR:0.0001

2023-02-06 15:05:30 | Train | Epoch[595/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 15:05:30 | Train | Epoch[595/600] Iteration[002/030] Train loss: 0.0081
2023-02-06 15:05:30 | Train | Epoch[595/600] Iteration[003/030] Train loss: 0.0083
2023-02-06 15:05:30 | Train | Epoch[595/600] Iteration[004/030] Train loss: 0.0080
2023-02-06 15:05:31 | Train | Epoch[595/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 15:05:31 | Train | Epoch[595/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 15:05:31 | Train | Epoch[595/600] Iteration[007/030] Train loss: 0.0077
2023-02-06 15:05:31 | Train | Epoch[595/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:05:31 | Train | Epoch[595/600] Iteration[009/030] Train loss: 0.0076
2023-02-06 15:05:32 | Train | Epoch[595/600] Iteration[010/030] Train loss: 0.0076
2023-02-06 15:05:32 | Train | Epoch[595/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 15:05:32 | Train | Epoch[595/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:05:32 | Train | Epoch[595/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:05:33 | Train | Epoch[595/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:05:33 | Train | Epoch[595/600] Iteration[015/030] Train loss: 0.0076
2023-02-06 15:05:33 | Train | Epoch[595/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:05:33 | Train | Epoch[595/600] Iteration[017/030] Train loss: 0.0076
2023-02-06 15:05:33 | Train | Epoch[595/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:05:34 | Train | Epoch[595/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:05:34 | Train | Epoch[595/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:05:34 | Train | Epoch[595/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:05:34 | Train | Epoch[595/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:05:35 | Train | Epoch[595/600] Iteration[023/030] Train loss: 0.0076
2023-02-06 15:05:35 | Train | Epoch[595/600] Iteration[024/030] Train loss: 0.0078
2023-02-06 15:05:35 | Train | Epoch[595/600] Iteration[025/030] Train loss: 0.0078
2023-02-06 15:05:35 | Train | Epoch[595/600] Iteration[026/030] Train loss: 0.0078
2023-02-06 15:05:35 | Train | Epoch[595/600] Iteration[027/030] Train loss: 0.0078
2023-02-06 15:05:36 | Train | Epoch[595/600] Iteration[028/030] Train loss: 0.0078
2023-02-06 15:05:36 | Train | Epoch[595/600] Iteration[029/030] Train loss: 0.0078
2023-02-06 15:05:36 | Train | Epoch[595/600] Iteration[030/030] Train loss: 0.0078
2023-02-06 15:05:36 | Valid | Epoch[595/600] Iteration[001/008] Valid loss: 0.1764
2023-02-06 15:05:36 | Valid | Epoch[595/600] Iteration[002/008] Valid loss: 0.1399
2023-02-06 15:05:36 | Valid | Epoch[595/600] Iteration[003/008] Valid loss: 0.1327
2023-02-06 15:05:36 | Valid | Epoch[595/600] Iteration[004/008] Valid loss: 0.1260
2023-02-06 15:05:37 | Valid | Epoch[595/600] Iteration[005/008] Valid loss: 0.1244
2023-02-06 15:05:37 | Valid | Epoch[595/600] Iteration[006/008] Valid loss: 0.1200
2023-02-06 15:05:37 | Valid | Epoch[595/600] Iteration[007/008] Valid loss: 0.1280
2023-02-06 15:05:37 | Valid | Epoch[595/600] Iteration[008/008] Valid loss: 0.1263
2023-02-06 15:05:37 | Valid | Epoch[595/600] MIou: 0.9296845584481592
2023-02-06 15:05:37 | Valid | Epoch[595/600] Pixel Accuracy: 0.9878807067871094
2023-02-06 15:05:37 | Valid | Epoch[595/600] Mean Pixel Accuracy: 0.9568366250797976
2023-02-06 15:05:37 | Stage | Epoch[595/600] Train loss:0.0078
2023-02-06 15:05:37 | Stage | Epoch[595/600] Valid loss:0.1263
2023-02-06 15:05:37 | Stage | Epoch[595/600] LR:0.0001

2023-02-06 15:05:37 | Train | Epoch[596/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 15:05:37 | Train | Epoch[596/600] Iteration[002/030] Train loss: 0.0068
2023-02-06 15:05:38 | Train | Epoch[596/600] Iteration[003/030] Train loss: 0.0068
2023-02-06 15:05:38 | Train | Epoch[596/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 15:05:38 | Train | Epoch[596/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 15:05:38 | Train | Epoch[596/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 15:05:39 | Train | Epoch[596/600] Iteration[007/030] Train loss: 0.0073
2023-02-06 15:05:39 | Train | Epoch[596/600] Iteration[008/030] Train loss: 0.0073
2023-02-06 15:05:39 | Train | Epoch[596/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 15:05:39 | Train | Epoch[596/600] Iteration[010/030] Train loss: 0.0074
2023-02-06 15:05:39 | Train | Epoch[596/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 15:05:40 | Train | Epoch[596/600] Iteration[012/030] Train loss: 0.0073
2023-02-06 15:05:40 | Train | Epoch[596/600] Iteration[013/030] Train loss: 0.0073
2023-02-06 15:05:40 | Train | Epoch[596/600] Iteration[014/030] Train loss: 0.0073
2023-02-06 15:05:40 | Train | Epoch[596/600] Iteration[015/030] Train loss: 0.0073
2023-02-06 15:05:41 | Train | Epoch[596/600] Iteration[016/030] Train loss: 0.0073
2023-02-06 15:05:41 | Train | Epoch[596/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 15:05:41 | Train | Epoch[596/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:05:41 | Train | Epoch[596/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:05:41 | Train | Epoch[596/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:05:42 | Train | Epoch[596/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 15:05:42 | Train | Epoch[596/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:05:42 | Train | Epoch[596/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:05:42 | Train | Epoch[596/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:05:43 | Train | Epoch[596/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:05:43 | Train | Epoch[596/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:05:43 | Train | Epoch[596/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:05:43 | Train | Epoch[596/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:05:43 | Train | Epoch[596/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:05:43 | Train | Epoch[596/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:05:44 | Valid | Epoch[596/600] Iteration[001/008] Valid loss: 0.1752
2023-02-06 15:05:44 | Valid | Epoch[596/600] Iteration[002/008] Valid loss: 0.1388
2023-02-06 15:05:44 | Valid | Epoch[596/600] Iteration[003/008] Valid loss: 0.1312
2023-02-06 15:05:44 | Valid | Epoch[596/600] Iteration[004/008] Valid loss: 0.1244
2023-02-06 15:05:44 | Valid | Epoch[596/600] Iteration[005/008] Valid loss: 0.1228
2023-02-06 15:05:44 | Valid | Epoch[596/600] Iteration[006/008] Valid loss: 0.1184
2023-02-06 15:05:44 | Valid | Epoch[596/600] Iteration[007/008] Valid loss: 0.1263
2023-02-06 15:05:44 | Valid | Epoch[596/600] Iteration[008/008] Valid loss: 0.1247
2023-02-06 15:05:44 | Valid | Epoch[596/600] MIou: 0.9294509400013534
2023-02-06 15:05:44 | Valid | Epoch[596/600] Pixel Accuracy: 0.9878374735514323
2023-02-06 15:05:44 | Valid | Epoch[596/600] Mean Pixel Accuracy: 0.9567240956484475
2023-02-06 15:05:44 | Stage | Epoch[596/600] Train loss:0.0076
2023-02-06 15:05:44 | Stage | Epoch[596/600] Valid loss:0.1247
2023-02-06 15:05:44 | Stage | Epoch[596/600] LR:0.0001

2023-02-06 15:05:45 | Train | Epoch[597/600] Iteration[001/030] Train loss: 0.0073
2023-02-06 15:05:45 | Train | Epoch[597/600] Iteration[002/030] Train loss: 0.0079
2023-02-06 15:05:45 | Train | Epoch[597/600] Iteration[003/030] Train loss: 0.0079
2023-02-06 15:05:45 | Train | Epoch[597/600] Iteration[004/030] Train loss: 0.0078
2023-02-06 15:05:46 | Train | Epoch[597/600] Iteration[005/030] Train loss: 0.0077
2023-02-06 15:05:46 | Train | Epoch[597/600] Iteration[006/030] Train loss: 0.0077
2023-02-06 15:05:46 | Train | Epoch[597/600] Iteration[007/030] Train loss: 0.0076
2023-02-06 15:05:46 | Train | Epoch[597/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:05:47 | Train | Epoch[597/600] Iteration[009/030] Train loss: 0.0074
2023-02-06 15:05:47 | Train | Epoch[597/600] Iteration[010/030] Train loss: 0.0075
2023-02-06 15:05:47 | Train | Epoch[597/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:05:47 | Train | Epoch[597/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:05:47 | Train | Epoch[597/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:05:48 | Train | Epoch[597/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:05:48 | Train | Epoch[597/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:05:48 | Train | Epoch[597/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:05:48 | Train | Epoch[597/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:05:49 | Train | Epoch[597/600] Iteration[018/030] Train loss: 0.0075
2023-02-06 15:05:49 | Train | Epoch[597/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:05:49 | Train | Epoch[597/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:05:49 | Train | Epoch[597/600] Iteration[021/030] Train loss: 0.0075
2023-02-06 15:05:49 | Train | Epoch[597/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:05:50 | Train | Epoch[597/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:05:50 | Train | Epoch[597/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:05:50 | Train | Epoch[597/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:05:50 | Train | Epoch[597/600] Iteration[026/030] Train loss: 0.0074
2023-02-06 15:05:51 | Train | Epoch[597/600] Iteration[027/030] Train loss: 0.0073
2023-02-06 15:05:51 | Train | Epoch[597/600] Iteration[028/030] Train loss: 0.0073
2023-02-06 15:05:51 | Train | Epoch[597/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 15:05:51 | Train | Epoch[597/600] Iteration[030/030] Train loss: 0.0074
2023-02-06 15:05:51 | Valid | Epoch[597/600] Iteration[001/008] Valid loss: 0.1864
2023-02-06 15:05:51 | Valid | Epoch[597/600] Iteration[002/008] Valid loss: 0.1484
2023-02-06 15:05:52 | Valid | Epoch[597/600] Iteration[003/008] Valid loss: 0.1407
2023-02-06 15:05:52 | Valid | Epoch[597/600] Iteration[004/008] Valid loss: 0.1334
2023-02-06 15:05:52 | Valid | Epoch[597/600] Iteration[005/008] Valid loss: 0.1318
2023-02-06 15:05:52 | Valid | Epoch[597/600] Iteration[006/008] Valid loss: 0.1277
2023-02-06 15:05:52 | Valid | Epoch[597/600] Iteration[007/008] Valid loss: 0.1366
2023-02-06 15:05:52 | Valid | Epoch[597/600] Iteration[008/008] Valid loss: 0.1351
2023-02-06 15:05:52 | Valid | Epoch[597/600] MIou: 0.9298611074206813
2023-02-06 15:05:52 | Valid | Epoch[597/600] Pixel Accuracy: 0.9878629048665365
2023-02-06 15:05:52 | Valid | Epoch[597/600] Mean Pixel Accuracy: 0.9588494507973706
2023-02-06 15:05:52 | Stage | Epoch[597/600] Train loss:0.0074
2023-02-06 15:05:52 | Stage | Epoch[597/600] Valid loss:0.1351
2023-02-06 15:05:52 | Stage | Epoch[597/600] LR:0.0001

2023-02-06 15:05:52 | Train | Epoch[598/600] Iteration[001/030] Train loss: 0.0068
2023-02-06 15:05:53 | Train | Epoch[598/600] Iteration[002/030] Train loss: 0.0074
2023-02-06 15:05:53 | Train | Epoch[598/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 15:05:53 | Train | Epoch[598/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 15:05:53 | Train | Epoch[598/600] Iteration[005/030] Train loss: 0.0074
2023-02-06 15:05:53 | Train | Epoch[598/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 15:05:54 | Train | Epoch[598/600] Iteration[007/030] Train loss: 0.0072
2023-02-06 15:05:54 | Train | Epoch[598/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 15:05:54 | Train | Epoch[598/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 15:05:54 | Train | Epoch[598/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 15:05:55 | Train | Epoch[598/600] Iteration[011/030] Train loss: 0.0075
2023-02-06 15:05:55 | Train | Epoch[598/600] Iteration[012/030] Train loss: 0.0075
2023-02-06 15:05:55 | Train | Epoch[598/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:05:55 | Train | Epoch[598/600] Iteration[014/030] Train loss: 0.0074
2023-02-06 15:05:55 | Train | Epoch[598/600] Iteration[015/030] Train loss: 0.0074
2023-02-06 15:05:56 | Train | Epoch[598/600] Iteration[016/030] Train loss: 0.0074
2023-02-06 15:05:56 | Train | Epoch[598/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 15:05:56 | Train | Epoch[598/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:05:56 | Train | Epoch[598/600] Iteration[019/030] Train loss: 0.0074
2023-02-06 15:05:56 | Train | Epoch[598/600] Iteration[020/030] Train loss: 0.0073
2023-02-06 15:05:57 | Train | Epoch[598/600] Iteration[021/030] Train loss: 0.0073
2023-02-06 15:05:57 | Train | Epoch[598/600] Iteration[022/030] Train loss: 0.0073
2023-02-06 15:05:57 | Train | Epoch[598/600] Iteration[023/030] Train loss: 0.0074
2023-02-06 15:05:57 | Train | Epoch[598/600] Iteration[024/030] Train loss: 0.0074
2023-02-06 15:05:58 | Train | Epoch[598/600] Iteration[025/030] Train loss: 0.0074
2023-02-06 15:05:58 | Train | Epoch[598/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:05:58 | Train | Epoch[598/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:05:58 | Train | Epoch[598/600] Iteration[028/030] Train loss: 0.0075
2023-02-06 15:05:58 | Train | Epoch[598/600] Iteration[029/030] Train loss: 0.0075
2023-02-06 15:05:59 | Train | Epoch[598/600] Iteration[030/030] Train loss: 0.0076
2023-02-06 15:05:59 | Valid | Epoch[598/600] Iteration[001/008] Valid loss: 0.1707
2023-02-06 15:05:59 | Valid | Epoch[598/600] Iteration[002/008] Valid loss: 0.1349
2023-02-06 15:05:59 | Valid | Epoch[598/600] Iteration[003/008] Valid loss: 0.1280
2023-02-06 15:05:59 | Valid | Epoch[598/600] Iteration[004/008] Valid loss: 0.1214
2023-02-06 15:05:59 | Valid | Epoch[598/600] Iteration[005/008] Valid loss: 0.1196
2023-02-06 15:05:59 | Valid | Epoch[598/600] Iteration[006/008] Valid loss: 0.1153
2023-02-06 15:05:59 | Valid | Epoch[598/600] Iteration[007/008] Valid loss: 0.1227
2023-02-06 15:05:59 | Valid | Epoch[598/600] Iteration[008/008] Valid loss: 0.1212
2023-02-06 15:05:59 | Valid | Epoch[598/600] MIou: 0.9291246521462653
2023-02-06 15:05:59 | Valid | Epoch[598/600] Pixel Accuracy: 0.987799326578776
2023-02-06 15:05:59 | Valid | Epoch[598/600] Mean Pixel Accuracy: 0.9557266958324863
2023-02-06 15:05:59 | Stage | Epoch[598/600] Train loss:0.0076
2023-02-06 15:05:59 | Stage | Epoch[598/600] Valid loss:0.1212
2023-02-06 15:05:59 | Stage | Epoch[598/600] LR:0.0001

2023-02-06 15:06:00 | Train | Epoch[599/600] Iteration[001/030] Train loss: 0.0074
2023-02-06 15:06:00 | Train | Epoch[599/600] Iteration[002/030] Train loss: 0.0076
2023-02-06 15:06:00 | Train | Epoch[599/600] Iteration[003/030] Train loss: 0.0072
2023-02-06 15:06:01 | Train | Epoch[599/600] Iteration[004/030] Train loss: 0.0072
2023-02-06 15:06:01 | Train | Epoch[599/600] Iteration[005/030] Train loss: 0.0076
2023-02-06 15:06:01 | Train | Epoch[599/600] Iteration[006/030] Train loss: 0.0075
2023-02-06 15:06:01 | Train | Epoch[599/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 15:06:01 | Train | Epoch[599/600] Iteration[008/030] Train loss: 0.0072
2023-02-06 15:06:02 | Train | Epoch[599/600] Iteration[009/030] Train loss: 0.0073
2023-02-06 15:06:02 | Train | Epoch[599/600] Iteration[010/030] Train loss: 0.0073
2023-02-06 15:06:02 | Train | Epoch[599/600] Iteration[011/030] Train loss: 0.0073
2023-02-06 15:06:02 | Train | Epoch[599/600] Iteration[012/030] Train loss: 0.0074
2023-02-06 15:06:03 | Train | Epoch[599/600] Iteration[013/030] Train loss: 0.0075
2023-02-06 15:06:03 | Train | Epoch[599/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:06:03 | Train | Epoch[599/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:06:03 | Train | Epoch[599/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:06:03 | Train | Epoch[599/600] Iteration[017/030] Train loss: 0.0074
2023-02-06 15:06:04 | Train | Epoch[599/600] Iteration[018/030] Train loss: 0.0074
2023-02-06 15:06:04 | Train | Epoch[599/600] Iteration[019/030] Train loss: 0.0076
2023-02-06 15:06:04 | Train | Epoch[599/600] Iteration[020/030] Train loss: 0.0075
2023-02-06 15:06:04 | Train | Epoch[599/600] Iteration[021/030] Train loss: 0.0076
2023-02-06 15:06:04 | Train | Epoch[599/600] Iteration[022/030] Train loss: 0.0075
2023-02-06 15:06:05 | Train | Epoch[599/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:06:05 | Train | Epoch[599/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:06:05 | Train | Epoch[599/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:06:05 | Train | Epoch[599/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:06:06 | Train | Epoch[599/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:06:06 | Train | Epoch[599/600] Iteration[028/030] Train loss: 0.0074
2023-02-06 15:06:06 | Train | Epoch[599/600] Iteration[029/030] Train loss: 0.0074
2023-02-06 15:06:06 | Train | Epoch[599/600] Iteration[030/030] Train loss: 0.0074
2023-02-06 15:06:07 | Valid | Epoch[599/600] Iteration[001/008] Valid loss: 0.1685
2023-02-06 15:06:07 | Valid | Epoch[599/600] Iteration[002/008] Valid loss: 0.1342
2023-02-06 15:06:07 | Valid | Epoch[599/600] Iteration[003/008] Valid loss: 0.1269
2023-02-06 15:06:07 | Valid | Epoch[599/600] Iteration[004/008] Valid loss: 0.1206
2023-02-06 15:06:07 | Valid | Epoch[599/600] Iteration[005/008] Valid loss: 0.1189
2023-02-06 15:06:07 | Valid | Epoch[599/600] Iteration[006/008] Valid loss: 0.1146
2023-02-06 15:06:07 | Valid | Epoch[599/600] Iteration[007/008] Valid loss: 0.1220
2023-02-06 15:06:07 | Valid | Epoch[599/600] Iteration[008/008] Valid loss: 0.1205
2023-02-06 15:06:07 | Valid | Epoch[599/600] MIou: 0.9292887898145605
2023-02-06 15:06:07 | Valid | Epoch[599/600] Pixel Accuracy: 0.9878349304199219
2023-02-06 15:06:07 | Valid | Epoch[599/600] Mean Pixel Accuracy: 0.9556067748487813
2023-02-06 15:06:07 | Stage | Epoch[599/600] Train loss:0.0074
2023-02-06 15:06:07 | Stage | Epoch[599/600] Valid loss:0.1205
2023-02-06 15:06:07 | Stage | Epoch[599/600] LR:0.0001

2023-02-06 15:06:07 | Train | Epoch[600/600] Iteration[001/030] Train loss: 0.0080
2023-02-06 15:06:08 | Train | Epoch[600/600] Iteration[002/030] Train loss: 0.0078
2023-02-06 15:06:08 | Train | Epoch[600/600] Iteration[003/030] Train loss: 0.0076
2023-02-06 15:06:08 | Train | Epoch[600/600] Iteration[004/030] Train loss: 0.0074
2023-02-06 15:06:08 | Train | Epoch[600/600] Iteration[005/030] Train loss: 0.0073
2023-02-06 15:06:08 | Train | Epoch[600/600] Iteration[006/030] Train loss: 0.0073
2023-02-06 15:06:09 | Train | Epoch[600/600] Iteration[007/030] Train loss: 0.0074
2023-02-06 15:06:09 | Train | Epoch[600/600] Iteration[008/030] Train loss: 0.0075
2023-02-06 15:06:09 | Train | Epoch[600/600] Iteration[009/030] Train loss: 0.0078
2023-02-06 15:06:09 | Train | Epoch[600/600] Iteration[010/030] Train loss: 0.0077
2023-02-06 15:06:10 | Train | Epoch[600/600] Iteration[011/030] Train loss: 0.0076
2023-02-06 15:06:10 | Train | Epoch[600/600] Iteration[012/030] Train loss: 0.0077
2023-02-06 15:06:10 | Train | Epoch[600/600] Iteration[013/030] Train loss: 0.0076
2023-02-06 15:06:10 | Train | Epoch[600/600] Iteration[014/030] Train loss: 0.0075
2023-02-06 15:06:10 | Train | Epoch[600/600] Iteration[015/030] Train loss: 0.0075
2023-02-06 15:06:11 | Train | Epoch[600/600] Iteration[016/030] Train loss: 0.0075
2023-02-06 15:06:11 | Train | Epoch[600/600] Iteration[017/030] Train loss: 0.0075
2023-02-06 15:06:11 | Train | Epoch[600/600] Iteration[018/030] Train loss: 0.0076
2023-02-06 15:06:11 | Train | Epoch[600/600] Iteration[019/030] Train loss: 0.0075
2023-02-06 15:06:12 | Train | Epoch[600/600] Iteration[020/030] Train loss: 0.0074
2023-02-06 15:06:12 | Train | Epoch[600/600] Iteration[021/030] Train loss: 0.0074
2023-02-06 15:06:12 | Train | Epoch[600/600] Iteration[022/030] Train loss: 0.0074
2023-02-06 15:06:12 | Train | Epoch[600/600] Iteration[023/030] Train loss: 0.0075
2023-02-06 15:06:12 | Train | Epoch[600/600] Iteration[024/030] Train loss: 0.0075
2023-02-06 15:06:13 | Train | Epoch[600/600] Iteration[025/030] Train loss: 0.0075
2023-02-06 15:06:13 | Train | Epoch[600/600] Iteration[026/030] Train loss: 0.0075
2023-02-06 15:06:13 | Train | Epoch[600/600] Iteration[027/030] Train loss: 0.0075
2023-02-06 15:06:13 | Train | Epoch[600/600] Iteration[028/030] Train loss: 0.0076
2023-02-06 15:06:14 | Train | Epoch[600/600] Iteration[029/030] Train loss: 0.0076
2023-02-06 15:06:14 | Train | Epoch[600/600] Iteration[030/030] Train loss: 0.0077
2023-02-06 15:06:14 | Valid | Epoch[600/600] Iteration[001/008] Valid loss: 0.1810
2023-02-06 15:06:14 | Valid | Epoch[600/600] Iteration[002/008] Valid loss: 0.1433
2023-02-06 15:06:14 | Valid | Epoch[600/600] Iteration[003/008] Valid loss: 0.1356
2023-02-06 15:06:14 | Valid | Epoch[600/600] Iteration[004/008] Valid loss: 0.1288
2023-02-06 15:06:14 | Valid | Epoch[600/600] Iteration[005/008] Valid loss: 0.1271
2023-02-06 15:06:14 | Valid | Epoch[600/600] Iteration[006/008] Valid loss: 0.1229
2023-02-06 15:06:14 | Valid | Epoch[600/600] Iteration[007/008] Valid loss: 0.1310
2023-02-06 15:06:14 | Valid | Epoch[600/600] Iteration[008/008] Valid loss: 0.1294
2023-02-06 15:06:14 | Valid | Epoch[600/600] MIou: 0.9296282661431827
2023-02-06 15:06:14 | Valid | Epoch[600/600] Pixel Accuracy: 0.9878501892089844
2023-02-06 15:06:14 | Valid | Epoch[600/600] Mean Pixel Accuracy: 0.9575743674272543
2023-02-06 15:06:14 | Stage | Epoch[600/600] Train loss:0.0077
2023-02-06 15:06:14 | Stage | Epoch[600/600] Valid loss:0.1294
2023-02-06 15:06:14 | Stage | Epoch[600/600] LR:0.0001

2023-02-06 15:06:14 | Final | Model training completed!!!
2023-02-06 15:06:14 | Final | Start time: 2023-02-06 13:51:08
2023-02-06 15:06:14 | Final | End time: 2023-02-06 15:06:14
2023-02-06 15:06:14 | Final | Spend time: 4506s
2023-02-06 15:06:14 | Final | Final epoch is 600
2023-02-06 15:06:14 | Final | Each epoch spend 7.51s
