2023-02-06 11:23:10 | Start | Model starts training!!!

2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[001/030] Train loss: 0.8571
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[002/030] Train loss: 0.8406
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[003/030] Train loss: 0.8323
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[004/030] Train loss: 0.8245
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[005/030] Train loss: 0.8152
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[006/030] Train loss: 0.8066
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[007/030] Train loss: 0.7989
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[008/030] Train loss: 0.7919
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[009/030] Train loss: 0.7857
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[010/030] Train loss: 0.7797
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[011/030] Train loss: 0.7736
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[012/030] Train loss: 0.7679
2023-02-06 11:23:15 | Train | Epoch[001/600] Iteration[013/030] Train loss: 0.7629
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[014/030] Train loss: 0.7581
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[015/030] Train loss: 0.7538
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[016/030] Train loss: 0.7495
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[017/030] Train loss: 0.7457
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[018/030] Train loss: 0.7416
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[019/030] Train loss: 0.7379
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[020/030] Train loss: 0.7346
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[021/030] Train loss: 0.7312
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[022/030] Train loss: 0.7280
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[023/030] Train loss: 0.7250
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[024/030] Train loss: 0.7221
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[025/030] Train loss: 0.7194
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[026/030] Train loss: 0.7169
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[027/030] Train loss: 0.7145
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[028/030] Train loss: 0.7121
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[029/030] Train loss: 0.7098
2023-02-06 11:23:16 | Train | Epoch[001/600] Iteration[030/030] Train loss: 0.7076
2023-02-06 11:23:17 | Valid | Epoch[001/600] Iteration[001/008] Valid loss: 0.6500
2023-02-06 11:23:17 | Valid | Epoch[001/600] Iteration[002/008] Valid loss: 0.6498
2023-02-06 11:23:17 | Valid | Epoch[001/600] Iteration[003/008] Valid loss: 0.6497
2023-02-06 11:23:17 | Valid | Epoch[001/600] Iteration[004/008] Valid loss: 0.6498
2023-02-06 11:23:17 | Valid | Epoch[001/600] Iteration[005/008] Valid loss: 0.6496
2023-02-06 11:23:17 | Valid | Epoch[001/600] Iteration[006/008] Valid loss: 0.6493
2023-02-06 11:23:17 | Valid | Epoch[001/600] Iteration[007/008] Valid loss: 0.6489
2023-02-06 11:23:17 | Valid | Epoch[001/600] Iteration[008/008] Valid loss: 0.6490
2023-02-06 11:23:17 | Valid | Epoch[001/600] MIou: 0.6126669684395961
2023-02-06 11:23:17 | Valid | Epoch[001/600] Pixel Accuracy: 0.9351603190104166
2023-02-06 11:23:17 | Valid | Epoch[001/600] Mean Pixel Accuracy: 0.6473187489640875
2023-02-06 11:23:17 | Stage | Epoch[001/600] Train loss:0.7076
2023-02-06 11:23:17 | Stage | Epoch[001/600] Valid loss:0.6490
2023-02-06 11:23:17 | Stage | Epoch[001/600] LR:0.01

2023-02-06 11:23:17 | Train | Epoch[002/600] Iteration[001/030] Train loss: 0.6470
2023-02-06 11:23:17 | Train | Epoch[002/600] Iteration[002/030] Train loss: 0.6441
2023-02-06 11:23:17 | Train | Epoch[002/600] Iteration[003/030] Train loss: 0.6419
2023-02-06 11:23:17 | Train | Epoch[002/600] Iteration[004/030] Train loss: 0.6400
2023-02-06 11:23:17 | Train | Epoch[002/600] Iteration[005/030] Train loss: 0.6393
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[006/030] Train loss: 0.6385
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[007/030] Train loss: 0.6373
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[008/030] Train loss: 0.6363
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[009/030] Train loss: 0.6351
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[010/030] Train loss: 0.6341
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[011/030] Train loss: 0.6334
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[012/030] Train loss: 0.6325
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[013/030] Train loss: 0.6317
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[014/030] Train loss: 0.6310
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[015/030] Train loss: 0.6303
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[016/030] Train loss: 0.6298
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[017/030] Train loss: 0.6294
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[018/030] Train loss: 0.6289
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[019/030] Train loss: 0.6283
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[020/030] Train loss: 0.6278
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[021/030] Train loss: 0.6272
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[022/030] Train loss: 0.6266
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[023/030] Train loss: 0.6261
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[024/030] Train loss: 0.6256
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[025/030] Train loss: 0.6250
2023-02-06 11:23:18 | Train | Epoch[002/600] Iteration[026/030] Train loss: 0.6244
2023-02-06 11:23:19 | Train | Epoch[002/600] Iteration[027/030] Train loss: 0.6240
2023-02-06 11:23:19 | Train | Epoch[002/600] Iteration[028/030] Train loss: 0.6234
2023-02-06 11:23:19 | Train | Epoch[002/600] Iteration[029/030] Train loss: 0.6229
2023-02-06 11:23:19 | Train | Epoch[002/600] Iteration[030/030] Train loss: 0.6223
2023-02-06 11:23:19 | Valid | Epoch[002/600] Iteration[001/008] Valid loss: 0.6624
2023-02-06 11:23:19 | Valid | Epoch[002/600] Iteration[002/008] Valid loss: 0.6599
2023-02-06 11:23:19 | Valid | Epoch[002/600] Iteration[003/008] Valid loss: 0.6599
2023-02-06 11:23:19 | Valid | Epoch[002/600] Iteration[004/008] Valid loss: 0.6598
2023-02-06 11:23:19 | Valid | Epoch[002/600] Iteration[005/008] Valid loss: 0.6599
2023-02-06 11:23:19 | Valid | Epoch[002/600] Iteration[006/008] Valid loss: 0.6608
2023-02-06 11:23:19 | Valid | Epoch[002/600] Iteration[007/008] Valid loss: 0.6614
2023-02-06 11:23:19 | Valid | Epoch[002/600] Iteration[008/008] Valid loss: 0.6609
2023-02-06 11:23:19 | Valid | Epoch[002/600] MIou: 0.5467525269226788
2023-02-06 11:23:19 | Valid | Epoch[002/600] Pixel Accuracy: 0.8691685994466146
2023-02-06 11:23:19 | Valid | Epoch[002/600] Mean Pixel Accuracy: 0.6722070736185758
2023-02-06 11:23:19 | Stage | Epoch[002/600] Train loss:0.6223
2023-02-06 11:23:19 | Stage | Epoch[002/600] Valid loss:0.6609
2023-02-06 11:23:19 | Stage | Epoch[002/600] LR:0.01

2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[001/030] Train loss: 0.6120
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[002/030] Train loss: 0.6075
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[003/030] Train loss: 0.6069
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[004/030] Train loss: 0.6066
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[005/030] Train loss: 0.6061
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[006/030] Train loss: 0.6048
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[007/030] Train loss: 0.6045
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[008/030] Train loss: 0.6043
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[009/030] Train loss: 0.6044
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[010/030] Train loss: 0.6045
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[011/030] Train loss: 0.6044
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[012/030] Train loss: 0.6043
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[013/030] Train loss: 0.6038
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[014/030] Train loss: 0.6034
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[015/030] Train loss: 0.6032
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[016/030] Train loss: 0.6026
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[017/030] Train loss: 0.6023
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[018/030] Train loss: 0.6018
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[019/030] Train loss: 0.6012
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[020/030] Train loss: 0.6007
2023-02-06 11:23:20 | Train | Epoch[003/600] Iteration[021/030] Train loss: 0.6002
2023-02-06 11:23:21 | Train | Epoch[003/600] Iteration[022/030] Train loss: 0.5998
2023-02-06 11:23:21 | Train | Epoch[003/600] Iteration[023/030] Train loss: 0.5992
2023-02-06 11:23:21 | Train | Epoch[003/600] Iteration[024/030] Train loss: 0.5988
2023-02-06 11:23:21 | Train | Epoch[003/600] Iteration[025/030] Train loss: 0.5983
2023-02-06 11:23:21 | Train | Epoch[003/600] Iteration[026/030] Train loss: 0.5979
2023-02-06 11:23:21 | Train | Epoch[003/600] Iteration[027/030] Train loss: 0.5975
2023-02-06 11:23:21 | Train | Epoch[003/600] Iteration[028/030] Train loss: 0.5971
2023-02-06 11:23:21 | Train | Epoch[003/600] Iteration[029/030] Train loss: 0.5967
2023-02-06 11:23:21 | Train | Epoch[003/600] Iteration[030/030] Train loss: 0.5962
2023-02-06 11:23:21 | Valid | Epoch[003/600] Iteration[001/008] Valid loss: 0.5989
2023-02-06 11:23:21 | Valid | Epoch[003/600] Iteration[002/008] Valid loss: 0.5984
2023-02-06 11:23:21 | Valid | Epoch[003/600] Iteration[003/008] Valid loss: 0.5968
2023-02-06 11:23:21 | Valid | Epoch[003/600] Iteration[004/008] Valid loss: 0.5965
2023-02-06 11:23:21 | Valid | Epoch[003/600] Iteration[005/008] Valid loss: 0.5959
2023-02-06 11:23:21 | Valid | Epoch[003/600] Iteration[006/008] Valid loss: 0.5955
2023-02-06 11:23:21 | Valid | Epoch[003/600] Iteration[007/008] Valid loss: 0.5954
2023-02-06 11:23:21 | Valid | Epoch[003/600] Iteration[008/008] Valid loss: 0.5951
2023-02-06 11:23:21 | Valid | Epoch[003/600] MIou: 0.7950093089960113
2023-02-06 11:23:21 | Valid | Epoch[003/600] Pixel Accuracy: 0.9558868408203125
2023-02-06 11:23:21 | Valid | Epoch[003/600] Mean Pixel Accuracy: 0.912811665633692
2023-02-06 11:23:21 | Stage | Epoch[003/600] Train loss:0.5962
2023-02-06 11:23:21 | Stage | Epoch[003/600] Valid loss:0.5951
2023-02-06 11:23:21 | Stage | Epoch[003/600] LR:0.01

2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[001/030] Train loss: 0.5826
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[002/030] Train loss: 0.5829
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[003/030] Train loss: 0.5842
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[004/030] Train loss: 0.5838
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[005/030] Train loss: 0.5838
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[006/030] Train loss: 0.5842
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[007/030] Train loss: 0.5837
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[008/030] Train loss: 0.5831
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[009/030] Train loss: 0.5828
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[010/030] Train loss: 0.5828
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[011/030] Train loss: 0.5822
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[012/030] Train loss: 0.5824
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[013/030] Train loss: 0.5816
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[014/030] Train loss: 0.5811
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[015/030] Train loss: 0.5809
2023-02-06 11:23:22 | Train | Epoch[004/600] Iteration[016/030] Train loss: 0.5807
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[017/030] Train loss: 0.5803
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[018/030] Train loss: 0.5802
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[019/030] Train loss: 0.5798
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[020/030] Train loss: 0.5794
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[021/030] Train loss: 0.5790
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[022/030] Train loss: 0.5787
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[023/030] Train loss: 0.5785
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[024/030] Train loss: 0.5783
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[025/030] Train loss: 0.5779
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[026/030] Train loss: 0.5776
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[027/030] Train loss: 0.5773
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[028/030] Train loss: 0.5770
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[029/030] Train loss: 0.5765
2023-02-06 11:23:23 | Train | Epoch[004/600] Iteration[030/030] Train loss: 0.5760
2023-02-06 11:23:23 | Valid | Epoch[004/600] Iteration[001/008] Valid loss: 0.5858
2023-02-06 11:23:23 | Valid | Epoch[004/600] Iteration[002/008] Valid loss: 0.5863
2023-02-06 11:23:24 | Valid | Epoch[004/600] Iteration[003/008] Valid loss: 0.5857
2023-02-06 11:23:24 | Valid | Epoch[004/600] Iteration[004/008] Valid loss: 0.5852
2023-02-06 11:23:24 | Valid | Epoch[004/600] Iteration[005/008] Valid loss: 0.5842
2023-02-06 11:23:24 | Valid | Epoch[004/600] Iteration[006/008] Valid loss: 0.5829
2023-02-06 11:23:24 | Valid | Epoch[004/600] Iteration[007/008] Valid loss: 0.5833
2023-02-06 11:23:24 | Valid | Epoch[004/600] Iteration[008/008] Valid loss: 0.5836
2023-02-06 11:23:24 | Valid | Epoch[004/600] MIou: 0.77400015874643
2023-02-06 11:23:24 | Valid | Epoch[004/600] Pixel Accuracy: 0.9450785319010416
2023-02-06 11:23:24 | Valid | Epoch[004/600] Mean Pixel Accuracy: 0.9442797400097052
2023-02-06 11:23:24 | Stage | Epoch[004/600] Train loss:0.5760
2023-02-06 11:23:24 | Stage | Epoch[004/600] Valid loss:0.5836
2023-02-06 11:23:24 | Stage | Epoch[004/600] LR:0.01

2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[001/030] Train loss: 0.5678
2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[002/030] Train loss: 0.5660
2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[003/030] Train loss: 0.5663
2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[004/030] Train loss: 0.5656
2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[005/030] Train loss: 0.5656
2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[006/030] Train loss: 0.5648
2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[007/030] Train loss: 0.5644
2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[008/030] Train loss: 0.5639
2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[009/030] Train loss: 0.5637
2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[010/030] Train loss: 0.5632
2023-02-06 11:23:24 | Train | Epoch[005/600] Iteration[011/030] Train loss: 0.5631
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[012/030] Train loss: 0.5630
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[013/030] Train loss: 0.5624
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[014/030] Train loss: 0.5622
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[015/030] Train loss: 0.5617
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[016/030] Train loss: 0.5614
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[017/030] Train loss: 0.5610
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[018/030] Train loss: 0.5603
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[019/030] Train loss: 0.5601
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[020/030] Train loss: 0.5596
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[021/030] Train loss: 0.5593
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[022/030] Train loss: 0.5589
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[023/030] Train loss: 0.5585
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[024/030] Train loss: 0.5581
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[025/030] Train loss: 0.5577
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[026/030] Train loss: 0.5573
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[027/030] Train loss: 0.5569
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[028/030] Train loss: 0.5564
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[029/030] Train loss: 0.5561
2023-02-06 11:23:25 | Train | Epoch[005/600] Iteration[030/030] Train loss: 0.5559
2023-02-06 11:23:26 | Valid | Epoch[005/600] Iteration[001/008] Valid loss: 0.5459
2023-02-06 11:23:26 | Valid | Epoch[005/600] Iteration[002/008] Valid loss: 0.5461
2023-02-06 11:23:26 | Valid | Epoch[005/600] Iteration[003/008] Valid loss: 0.5448
2023-02-06 11:23:26 | Valid | Epoch[005/600] Iteration[004/008] Valid loss: 0.5444
2023-02-06 11:23:26 | Valid | Epoch[005/600] Iteration[005/008] Valid loss: 0.5439
2023-02-06 11:23:26 | Valid | Epoch[005/600] Iteration[006/008] Valid loss: 0.5434
2023-02-06 11:23:26 | Valid | Epoch[005/600] Iteration[007/008] Valid loss: 0.5433
2023-02-06 11:23:26 | Valid | Epoch[005/600] Iteration[008/008] Valid loss: 0.5428
2023-02-06 11:23:26 | Valid | Epoch[005/600] MIou: 0.88571294124625
2023-02-06 11:23:26 | Valid | Epoch[005/600] Pixel Accuracy: 0.9792925516764323
2023-02-06 11:23:26 | Valid | Epoch[005/600] Mean Pixel Accuracy: 0.9360684753579389
2023-02-06 11:23:26 | Stage | Epoch[005/600] Train loss:0.5559
2023-02-06 11:23:26 | Stage | Epoch[005/600] Valid loss:0.5428
2023-02-06 11:23:26 | Stage | Epoch[005/600] LR:0.01

2023-02-06 11:23:26 | Train | Epoch[006/600] Iteration[001/030] Train loss: 0.5490
2023-02-06 11:23:26 | Train | Epoch[006/600] Iteration[002/030] Train loss: 0.5455
2023-02-06 11:23:26 | Train | Epoch[006/600] Iteration[003/030] Train loss: 0.5443
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[004/030] Train loss: 0.5451
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[005/030] Train loss: 0.5441
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[006/030] Train loss: 0.5440
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[007/030] Train loss: 0.5435
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[008/030] Train loss: 0.5431
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[009/030] Train loss: 0.5425
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[010/030] Train loss: 0.5421
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[011/030] Train loss: 0.5416
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[012/030] Train loss: 0.5411
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[013/030] Train loss: 0.5409
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[014/030] Train loss: 0.5408
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[015/030] Train loss: 0.5406
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[016/030] Train loss: 0.5402
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[017/030] Train loss: 0.5399
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[018/030] Train loss: 0.5395
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[019/030] Train loss: 0.5390
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[020/030] Train loss: 0.5387
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[021/030] Train loss: 0.5384
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[022/030] Train loss: 0.5379
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[023/030] Train loss: 0.5376
2023-02-06 11:23:27 | Train | Epoch[006/600] Iteration[024/030] Train loss: 0.5372
2023-02-06 11:23:28 | Train | Epoch[006/600] Iteration[025/030] Train loss: 0.5373
2023-02-06 11:23:28 | Train | Epoch[006/600] Iteration[026/030] Train loss: 0.5369
2023-02-06 11:23:28 | Train | Epoch[006/600] Iteration[027/030] Train loss: 0.5368
2023-02-06 11:23:28 | Train | Epoch[006/600] Iteration[028/030] Train loss: 0.5363
2023-02-06 11:23:28 | Train | Epoch[006/600] Iteration[029/030] Train loss: 0.5359
2023-02-06 11:23:28 | Train | Epoch[006/600] Iteration[030/030] Train loss: 0.5357
2023-02-06 11:23:28 | Valid | Epoch[006/600] Iteration[001/008] Valid loss: 0.5478
2023-02-06 11:23:28 | Valid | Epoch[006/600] Iteration[002/008] Valid loss: 0.5475
2023-02-06 11:23:28 | Valid | Epoch[006/600] Iteration[003/008] Valid loss: 0.5472
2023-02-06 11:23:28 | Valid | Epoch[006/600] Iteration[004/008] Valid loss: 0.5467
2023-02-06 11:23:28 | Valid | Epoch[006/600] Iteration[005/008] Valid loss: 0.5470
2023-02-06 11:23:28 | Valid | Epoch[006/600] Iteration[006/008] Valid loss: 0.5468
2023-02-06 11:23:28 | Valid | Epoch[006/600] Iteration[007/008] Valid loss: 0.5465
2023-02-06 11:23:28 | Valid | Epoch[006/600] Iteration[008/008] Valid loss: 0.5466
2023-02-06 11:23:28 | Valid | Epoch[006/600] MIou: 0.7174612491068753
2023-02-06 11:23:28 | Valid | Epoch[006/600] Pixel Accuracy: 0.9533220926920573
2023-02-06 11:23:28 | Valid | Epoch[006/600] Mean Pixel Accuracy: 0.7420733384769376
2023-02-06 11:23:28 | Stage | Epoch[006/600] Train loss:0.5357
2023-02-06 11:23:28 | Stage | Epoch[006/600] Valid loss:0.5466
2023-02-06 11:23:28 | Stage | Epoch[006/600] LR:0.01

2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[001/030] Train loss: 0.5201
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[002/030] Train loss: 0.5221
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[003/030] Train loss: 0.5233
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[004/030] Train loss: 0.5226
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[005/030] Train loss: 0.5229
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[006/030] Train loss: 0.5228
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[007/030] Train loss: 0.5230
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[008/030] Train loss: 0.5231
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[009/030] Train loss: 0.5228
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[010/030] Train loss: 0.5220
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[011/030] Train loss: 0.5222
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[012/030] Train loss: 0.5218
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[013/030] Train loss: 0.5215
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[014/030] Train loss: 0.5209
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[015/030] Train loss: 0.5206
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[016/030] Train loss: 0.5202
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[017/030] Train loss: 0.5196
2023-02-06 11:23:29 | Train | Epoch[007/600] Iteration[018/030] Train loss: 0.5191
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[019/030] Train loss: 0.5186
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[020/030] Train loss: 0.5182
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[021/030] Train loss: 0.5179
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[022/030] Train loss: 0.5175
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[023/030] Train loss: 0.5170
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[024/030] Train loss: 0.5165
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[025/030] Train loss: 0.5164
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[026/030] Train loss: 0.5161
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[027/030] Train loss: 0.5157
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[028/030] Train loss: 0.5153
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[029/030] Train loss: 0.5150
2023-02-06 11:23:30 | Train | Epoch[007/600] Iteration[030/030] Train loss: 0.5147
2023-02-06 11:23:30 | Valid | Epoch[007/600] Iteration[001/008] Valid loss: 0.5304
2023-02-06 11:23:30 | Valid | Epoch[007/600] Iteration[002/008] Valid loss: 0.5303
2023-02-06 11:23:30 | Valid | Epoch[007/600] Iteration[003/008] Valid loss: 0.5305
2023-02-06 11:23:30 | Valid | Epoch[007/600] Iteration[004/008] Valid loss: 0.5299
2023-02-06 11:23:30 | Valid | Epoch[007/600] Iteration[005/008] Valid loss: 0.5306
2023-02-06 11:23:30 | Valid | Epoch[007/600] Iteration[006/008] Valid loss: 0.5302
2023-02-06 11:23:31 | Valid | Epoch[007/600] Iteration[007/008] Valid loss: 0.5300
2023-02-06 11:23:31 | Valid | Epoch[007/600] Iteration[008/008] Valid loss: 0.5303
2023-02-06 11:23:31 | Valid | Epoch[007/600] MIou: 0.6268188805695383
2023-02-06 11:23:31 | Valid | Epoch[007/600] Pixel Accuracy: 0.9382985432942709
2023-02-06 11:23:31 | Valid | Epoch[007/600] Mean Pixel Accuracy: 0.658630443798787
2023-02-06 11:23:31 | Stage | Epoch[007/600] Train loss:0.5147
2023-02-06 11:23:31 | Stage | Epoch[007/600] Valid loss:0.5303
2023-02-06 11:23:31 | Stage | Epoch[007/600] LR:0.01

2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[001/030] Train loss: 0.4993
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[002/030] Train loss: 0.4990
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[003/030] Train loss: 0.4993
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[004/030] Train loss: 0.4989
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[005/030] Train loss: 0.5000
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[006/030] Train loss: 0.5003
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[007/030] Train loss: 0.4997
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[008/030] Train loss: 0.4995
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[009/030] Train loss: 0.4990
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[010/030] Train loss: 0.4984
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[011/030] Train loss: 0.4977
2023-02-06 11:23:31 | Train | Epoch[008/600] Iteration[012/030] Train loss: 0.4974
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[013/030] Train loss: 0.4975
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[014/030] Train loss: 0.4976
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[015/030] Train loss: 0.4975
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[016/030] Train loss: 0.4971
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[017/030] Train loss: 0.4965
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[018/030] Train loss: 0.4964
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[019/030] Train loss: 0.4960
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[020/030] Train loss: 0.4954
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[021/030] Train loss: 0.4954
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[022/030] Train loss: 0.4948
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[023/030] Train loss: 0.4946
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[024/030] Train loss: 0.4944
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[025/030] Train loss: 0.4941
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[026/030] Train loss: 0.4940
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[027/030] Train loss: 0.4939
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[028/030] Train loss: 0.4938
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[029/030] Train loss: 0.4936
2023-02-06 11:23:32 | Train | Epoch[008/600] Iteration[030/030] Train loss: 0.4932
2023-02-06 11:23:33 | Valid | Epoch[008/600] Iteration[001/008] Valid loss: 0.4915
2023-02-06 11:23:33 | Valid | Epoch[008/600] Iteration[002/008] Valid loss: 0.4923
2023-02-06 11:23:33 | Valid | Epoch[008/600] Iteration[003/008] Valid loss: 0.4896
2023-02-06 11:23:33 | Valid | Epoch[008/600] Iteration[004/008] Valid loss: 0.4895
2023-02-06 11:23:33 | Valid | Epoch[008/600] Iteration[005/008] Valid loss: 0.4898
2023-02-06 11:23:33 | Valid | Epoch[008/600] Iteration[006/008] Valid loss: 0.4891
2023-02-06 11:23:33 | Valid | Epoch[008/600] Iteration[007/008] Valid loss: 0.4902
2023-02-06 11:23:33 | Valid | Epoch[008/600] Iteration[008/008] Valid loss: 0.4893
2023-02-06 11:23:33 | Valid | Epoch[008/600] MIou: 0.8986063190849318
2023-02-06 11:23:33 | Valid | Epoch[008/600] Pixel Accuracy: 0.9804356892903646
2023-02-06 11:23:33 | Valid | Epoch[008/600] Mean Pixel Accuracy: 0.9793364634629328
2023-02-06 11:23:33 | Stage | Epoch[008/600] Train loss:0.4932
2023-02-06 11:23:33 | Stage | Epoch[008/600] Valid loss:0.4893
2023-02-06 11:23:33 | Stage | Epoch[008/600] LR:0.01

2023-02-06 11:23:33 | Train | Epoch[009/600] Iteration[001/030] Train loss: 0.4833
2023-02-06 11:23:33 | Train | Epoch[009/600] Iteration[002/030] Train loss: 0.4838
2023-02-06 11:23:33 | Train | Epoch[009/600] Iteration[003/030] Train loss: 0.4825
2023-02-06 11:23:33 | Train | Epoch[009/600] Iteration[004/030] Train loss: 0.4811
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[005/030] Train loss: 0.4813
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[006/030] Train loss: 0.4808
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[007/030] Train loss: 0.4797
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[008/030] Train loss: 0.4800
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[009/030] Train loss: 0.4799
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[010/030] Train loss: 0.4798
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[011/030] Train loss: 0.4794
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[012/030] Train loss: 0.4795
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[013/030] Train loss: 0.4792
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[014/030] Train loss: 0.4796
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[015/030] Train loss: 0.4792
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[016/030] Train loss: 0.4788
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[017/030] Train loss: 0.4784
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[018/030] Train loss: 0.4780
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[019/030] Train loss: 0.4774
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[020/030] Train loss: 0.4772
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[021/030] Train loss: 0.4769
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[022/030] Train loss: 0.4766
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[023/030] Train loss: 0.4763
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[024/030] Train loss: 0.4759
2023-02-06 11:23:34 | Train | Epoch[009/600] Iteration[025/030] Train loss: 0.4756
2023-02-06 11:23:35 | Train | Epoch[009/600] Iteration[026/030] Train loss: 0.4751
2023-02-06 11:23:35 | Train | Epoch[009/600] Iteration[027/030] Train loss: 0.4748
2023-02-06 11:23:35 | Train | Epoch[009/600] Iteration[028/030] Train loss: 0.4743
2023-02-06 11:23:35 | Train | Epoch[009/600] Iteration[029/030] Train loss: 0.4740
2023-02-06 11:23:35 | Train | Epoch[009/600] Iteration[030/030] Train loss: 0.4737
2023-02-06 11:23:35 | Valid | Epoch[009/600] Iteration[001/008] Valid loss: 0.4930
2023-02-06 11:23:35 | Valid | Epoch[009/600] Iteration[002/008] Valid loss: 0.4957
2023-02-06 11:23:35 | Valid | Epoch[009/600] Iteration[003/008] Valid loss: 0.4933
2023-02-06 11:23:35 | Valid | Epoch[009/600] Iteration[004/008] Valid loss: 0.4936
2023-02-06 11:23:35 | Valid | Epoch[009/600] Iteration[005/008] Valid loss: 0.4942
2023-02-06 11:23:35 | Valid | Epoch[009/600] Iteration[006/008] Valid loss: 0.4929
2023-02-06 11:23:35 | Valid | Epoch[009/600] Iteration[007/008] Valid loss: 0.4947
2023-02-06 11:23:35 | Valid | Epoch[009/600] Iteration[008/008] Valid loss: 0.4944
2023-02-06 11:23:35 | Valid | Epoch[009/600] MIou: 0.8562103363228843
2023-02-06 11:23:35 | Valid | Epoch[009/600] Pixel Accuracy: 0.9695281982421875
2023-02-06 11:23:35 | Valid | Epoch[009/600] Mean Pixel Accuracy: 0.9788828132911704
2023-02-06 11:23:35 | Stage | Epoch[009/600] Train loss:0.4737
2023-02-06 11:23:35 | Stage | Epoch[009/600] Valid loss:0.4944
2023-02-06 11:23:35 | Stage | Epoch[009/600] LR:0.01

2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[001/030] Train loss: 0.4650
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[002/030] Train loss: 0.4652
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[003/030] Train loss: 0.4662
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[004/030] Train loss: 0.4657
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[005/030] Train loss: 0.4647
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[006/030] Train loss: 0.4651
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[007/030] Train loss: 0.4642
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[008/030] Train loss: 0.4634
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[009/030] Train loss: 0.4625
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[010/030] Train loss: 0.4630
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[011/030] Train loss: 0.4628
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[012/030] Train loss: 0.4625
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[013/030] Train loss: 0.4621
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[014/030] Train loss: 0.4617
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[015/030] Train loss: 0.4612
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[016/030] Train loss: 0.4608
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[017/030] Train loss: 0.4602
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[018/030] Train loss: 0.4596
2023-02-06 11:23:36 | Train | Epoch[010/600] Iteration[019/030] Train loss: 0.4593
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[020/030] Train loss: 0.4586
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[021/030] Train loss: 0.4584
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[022/030] Train loss: 0.4580
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[023/030] Train loss: 0.4580
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[024/030] Train loss: 0.4576
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[025/030] Train loss: 0.4573
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[026/030] Train loss: 0.4569
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[027/030] Train loss: 0.4565
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[028/030] Train loss: 0.4560
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[029/030] Train loss: 0.4556
2023-02-06 11:23:37 | Train | Epoch[010/600] Iteration[030/030] Train loss: 0.4552
2023-02-06 11:23:37 | Valid | Epoch[010/600] Iteration[001/008] Valid loss: 0.4754
2023-02-06 11:23:37 | Valid | Epoch[010/600] Iteration[002/008] Valid loss: 0.4770
2023-02-06 11:23:37 | Valid | Epoch[010/600] Iteration[003/008] Valid loss: 0.4774
2023-02-06 11:23:37 | Valid | Epoch[010/600] Iteration[004/008] Valid loss: 0.4771
2023-02-06 11:23:37 | Valid | Epoch[010/600] Iteration[005/008] Valid loss: 0.4783
2023-02-06 11:23:38 | Valid | Epoch[010/600] Iteration[006/008] Valid loss: 0.4779
2023-02-06 11:23:38 | Valid | Epoch[010/600] Iteration[007/008] Valid loss: 0.4777
2023-02-06 11:23:38 | Valid | Epoch[010/600] Iteration[008/008] Valid loss: 0.4786
2023-02-06 11:23:38 | Valid | Epoch[010/600] MIou: 0.5745772690736092
2023-02-06 11:23:38 | Valid | Epoch[010/600] Pixel Accuracy: 0.9296277364095052
2023-02-06 11:23:38 | Valid | Epoch[010/600] Mean Pixel Accuracy: 0.6104894329198123
2023-02-06 11:23:38 | Stage | Epoch[010/600] Train loss:0.4552
2023-02-06 11:23:38 | Stage | Epoch[010/600] Valid loss:0.4786
2023-02-06 11:23:38 | Stage | Epoch[010/600] LR:0.01

2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[001/030] Train loss: 0.4424
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[002/030] Train loss: 0.4470
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[003/030] Train loss: 0.4462
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[004/030] Train loss: 0.4456
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[005/030] Train loss: 0.4449
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[006/030] Train loss: 0.4444
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[007/030] Train loss: 0.4442
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[008/030] Train loss: 0.4440
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[009/030] Train loss: 0.4438
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[010/030] Train loss: 0.4435
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[011/030] Train loss: 0.4432
2023-02-06 11:23:38 | Train | Epoch[011/600] Iteration[012/030] Train loss: 0.4432
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[013/030] Train loss: 0.4434
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[014/030] Train loss: 0.4429
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[015/030] Train loss: 0.4425
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[016/030] Train loss: 0.4417
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[017/030] Train loss: 0.4414
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[018/030] Train loss: 0.4411
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[019/030] Train loss: 0.4407
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[020/030] Train loss: 0.4403
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[021/030] Train loss: 0.4400
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[022/030] Train loss: 0.4399
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[023/030] Train loss: 0.4396
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[024/030] Train loss: 0.4392
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[025/030] Train loss: 0.4390
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[026/030] Train loss: 0.4387
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[027/030] Train loss: 0.4384
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[028/030] Train loss: 0.4381
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[029/030] Train loss: 0.4376
2023-02-06 11:23:39 | Train | Epoch[011/600] Iteration[030/030] Train loss: 0.4373
2023-02-06 11:23:40 | Valid | Epoch[011/600] Iteration[001/008] Valid loss: 0.4392
2023-02-06 11:23:40 | Valid | Epoch[011/600] Iteration[002/008] Valid loss: 0.4383
2023-02-06 11:23:40 | Valid | Epoch[011/600] Iteration[003/008] Valid loss: 0.4365
2023-02-06 11:23:40 | Valid | Epoch[011/600] Iteration[004/008] Valid loss: 0.4366
2023-02-06 11:23:40 | Valid | Epoch[011/600] Iteration[005/008] Valid loss: 0.4368
2023-02-06 11:23:40 | Valid | Epoch[011/600] Iteration[006/008] Valid loss: 0.4366
2023-02-06 11:23:40 | Valid | Epoch[011/600] Iteration[007/008] Valid loss: 0.4377
2023-02-06 11:23:40 | Valid | Epoch[011/600] Iteration[008/008] Valid loss: 0.4368
2023-02-06 11:23:40 | Valid | Epoch[011/600] MIou: 0.9161644848576831
2023-02-06 11:23:40 | Valid | Epoch[011/600] Pixel Accuracy: 0.9846967061360677
2023-02-06 11:23:40 | Valid | Epoch[011/600] Mean Pixel Accuracy: 0.9705192701880438
2023-02-06 11:23:40 | Stage | Epoch[011/600] Train loss:0.4373
2023-02-06 11:23:40 | Stage | Epoch[011/600] Valid loss:0.4368
2023-02-06 11:23:40 | Stage | Epoch[011/600] LR:0.01

2023-02-06 11:23:40 | Train | Epoch[012/600] Iteration[001/030] Train loss: 0.4242
2023-02-06 11:23:40 | Train | Epoch[012/600] Iteration[002/030] Train loss: 0.4255
2023-02-06 11:23:40 | Train | Epoch[012/600] Iteration[003/030] Train loss: 0.4267
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[004/030] Train loss: 0.4255
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[005/030] Train loss: 0.4256
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[006/030] Train loss: 0.4254
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[007/030] Train loss: 0.4259
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[008/030] Train loss: 0.4254
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[009/030] Train loss: 0.4254
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[010/030] Train loss: 0.4256
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[011/030] Train loss: 0.4253
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[012/030] Train loss: 0.4250
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[013/030] Train loss: 0.4248
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[014/030] Train loss: 0.4249
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[015/030] Train loss: 0.4246
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[016/030] Train loss: 0.4242
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[017/030] Train loss: 0.4237
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[018/030] Train loss: 0.4232
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[019/030] Train loss: 0.4229
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[020/030] Train loss: 0.4225
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[021/030] Train loss: 0.4222
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[022/030] Train loss: 0.4222
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[023/030] Train loss: 0.4218
2023-02-06 11:23:41 | Train | Epoch[012/600] Iteration[024/030] Train loss: 0.4218
2023-02-06 11:23:42 | Train | Epoch[012/600] Iteration[025/030] Train loss: 0.4217
2023-02-06 11:23:42 | Train | Epoch[012/600] Iteration[026/030] Train loss: 0.4214
2023-02-06 11:23:42 | Train | Epoch[012/600] Iteration[027/030] Train loss: 0.4210
2023-02-06 11:23:42 | Train | Epoch[012/600] Iteration[028/030] Train loss: 0.4207
2023-02-06 11:23:42 | Train | Epoch[012/600] Iteration[029/030] Train loss: 0.4209
2023-02-06 11:23:42 | Train | Epoch[012/600] Iteration[030/030] Train loss: 0.4205
2023-02-06 11:23:42 | Valid | Epoch[012/600] Iteration[001/008] Valid loss: 0.4241
2023-02-06 11:23:42 | Valid | Epoch[012/600] Iteration[002/008] Valid loss: 0.4248
2023-02-06 11:23:42 | Valid | Epoch[012/600] Iteration[003/008] Valid loss: 0.4231
2023-02-06 11:23:42 | Valid | Epoch[012/600] Iteration[004/008] Valid loss: 0.4231
2023-02-06 11:23:42 | Valid | Epoch[012/600] Iteration[005/008] Valid loss: 0.4234
2023-02-06 11:23:42 | Valid | Epoch[012/600] Iteration[006/008] Valid loss: 0.4228
2023-02-06 11:23:42 | Valid | Epoch[012/600] Iteration[007/008] Valid loss: 0.4238
2023-02-06 11:23:42 | Valid | Epoch[012/600] Iteration[008/008] Valid loss: 0.4234
2023-02-06 11:23:42 | Valid | Epoch[012/600] MIou: 0.9020479900264389
2023-02-06 11:23:42 | Valid | Epoch[012/600] Pixel Accuracy: 0.9812965393066406
2023-02-06 11:23:42 | Valid | Epoch[012/600] Mean Pixel Accuracy: 0.9778187152914503
2023-02-06 11:23:42 | Stage | Epoch[012/600] Train loss:0.4205
2023-02-06 11:23:42 | Stage | Epoch[012/600] Valid loss:0.4234
2023-02-06 11:23:42 | Stage | Epoch[012/600] LR:0.01

2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[001/030] Train loss: 0.4088
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[002/030] Train loss: 0.4078
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[003/030] Train loss: 0.4117
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[004/030] Train loss: 0.4116
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[005/030] Train loss: 0.4120
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[006/030] Train loss: 0.4107
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[007/030] Train loss: 0.4107
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[008/030] Train loss: 0.4107
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[009/030] Train loss: 0.4099
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[010/030] Train loss: 0.4094
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[011/030] Train loss: 0.4087
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[012/030] Train loss: 0.4082
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[013/030] Train loss: 0.4081
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[014/030] Train loss: 0.4080
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[015/030] Train loss: 0.4077
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[016/030] Train loss: 0.4075
2023-02-06 11:23:43 | Train | Epoch[013/600] Iteration[017/030] Train loss: 0.4072
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[018/030] Train loss: 0.4068
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[019/030] Train loss: 0.4067
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[020/030] Train loss: 0.4063
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[021/030] Train loss: 0.4060
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[022/030] Train loss: 0.4060
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[023/030] Train loss: 0.4058
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[024/030] Train loss: 0.4054
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[025/030] Train loss: 0.4051
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[026/030] Train loss: 0.4050
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[027/030] Train loss: 0.4046
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[028/030] Train loss: 0.4047
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[029/030] Train loss: 0.4044
2023-02-06 11:23:44 | Train | Epoch[013/600] Iteration[030/030] Train loss: 0.4040
2023-02-06 11:23:44 | Valid | Epoch[013/600] Iteration[001/008] Valid loss: 0.4295
2023-02-06 11:23:44 | Valid | Epoch[013/600] Iteration[002/008] Valid loss: 0.4298
2023-02-06 11:23:44 | Valid | Epoch[013/600] Iteration[003/008] Valid loss: 0.4276
2023-02-06 11:23:45 | Valid | Epoch[013/600] Iteration[004/008] Valid loss: 0.4277
2023-02-06 11:23:45 | Valid | Epoch[013/600] Iteration[005/008] Valid loss: 0.4286
2023-02-06 11:23:45 | Valid | Epoch[013/600] Iteration[006/008] Valid loss: 0.4269
2023-02-06 11:23:45 | Valid | Epoch[013/600] Iteration[007/008] Valid loss: 0.4288
2023-02-06 11:23:45 | Valid | Epoch[013/600] Iteration[008/008] Valid loss: 0.4292
2023-02-06 11:23:45 | Valid | Epoch[013/600] MIou: 0.8732855683824612
2023-02-06 11:23:45 | Valid | Epoch[013/600] Pixel Accuracy: 0.9741071065266927
2023-02-06 11:23:45 | Valid | Epoch[013/600] Mean Pixel Accuracy: 0.9801251417961216
2023-02-06 11:23:45 | Stage | Epoch[013/600] Train loss:0.4040
2023-02-06 11:23:45 | Stage | Epoch[013/600] Valid loss:0.4292
2023-02-06 11:23:45 | Stage | Epoch[013/600] LR:0.01

2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[001/030] Train loss: 0.3975
2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[002/030] Train loss: 0.3996
2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[003/030] Train loss: 0.3978
2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[004/030] Train loss: 0.3973
2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[005/030] Train loss: 0.3960
2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[006/030] Train loss: 0.3955
2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[007/030] Train loss: 0.3951
2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[008/030] Train loss: 0.3955
2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[009/030] Train loss: 0.3948
2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[010/030] Train loss: 0.3944
2023-02-06 11:23:45 | Train | Epoch[014/600] Iteration[011/030] Train loss: 0.3941
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[012/030] Train loss: 0.3936
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[013/030] Train loss: 0.3930
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[014/030] Train loss: 0.3928
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[015/030] Train loss: 0.3929
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[016/030] Train loss: 0.3925
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[017/030] Train loss: 0.3921
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[018/030] Train loss: 0.3920
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[019/030] Train loss: 0.3919
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[020/030] Train loss: 0.3915
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[021/030] Train loss: 0.3910
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[022/030] Train loss: 0.3911
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[023/030] Train loss: 0.3907
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[024/030] Train loss: 0.3903
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[025/030] Train loss: 0.3899
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[026/030] Train loss: 0.3895
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[027/030] Train loss: 0.3893
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[028/030] Train loss: 0.3890
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[029/030] Train loss: 0.3887
2023-02-06 11:23:46 | Train | Epoch[014/600] Iteration[030/030] Train loss: 0.3884
2023-02-06 11:23:47 | Valid | Epoch[014/600] Iteration[001/008] Valid loss: 0.4529
2023-02-06 11:23:47 | Valid | Epoch[014/600] Iteration[002/008] Valid loss: 0.4497
2023-02-06 11:23:47 | Valid | Epoch[014/600] Iteration[003/008] Valid loss: 0.4482
2023-02-06 11:23:47 | Valid | Epoch[014/600] Iteration[004/008] Valid loss: 0.4507
2023-02-06 11:23:47 | Valid | Epoch[014/600] Iteration[005/008] Valid loss: 0.4523
2023-02-06 11:23:47 | Valid | Epoch[014/600] Iteration[006/008] Valid loss: 0.4510
2023-02-06 11:23:47 | Valid | Epoch[014/600] Iteration[007/008] Valid loss: 0.4548
2023-02-06 11:23:47 | Valid | Epoch[014/600] Iteration[008/008] Valid loss: 0.4560
2023-02-06 11:23:47 | Valid | Epoch[014/600] MIou: 0.840635649257977
2023-02-06 11:23:47 | Valid | Epoch[014/600] Pixel Accuracy: 0.9650001525878906
2023-02-06 11:23:47 | Valid | Epoch[014/600] Mean Pixel Accuracy: 0.9785687880117359
2023-02-06 11:23:47 | Stage | Epoch[014/600] Train loss:0.3884
2023-02-06 11:23:47 | Stage | Epoch[014/600] Valid loss:0.4560
2023-02-06 11:23:47 | Stage | Epoch[014/600] LR:0.01

2023-02-06 11:23:47 | Train | Epoch[015/600] Iteration[001/030] Train loss: 0.3795
2023-02-06 11:23:47 | Train | Epoch[015/600] Iteration[002/030] Train loss: 0.3801
2023-02-06 11:23:47 | Train | Epoch[015/600] Iteration[003/030] Train loss: 0.3799
2023-02-06 11:23:47 | Train | Epoch[015/600] Iteration[004/030] Train loss: 0.3792
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[005/030] Train loss: 0.3785
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[006/030] Train loss: 0.3787
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[007/030] Train loss: 0.3782
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[008/030] Train loss: 0.3785
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[009/030] Train loss: 0.3783
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[010/030] Train loss: 0.3783
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[011/030] Train loss: 0.3782
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[012/030] Train loss: 0.3782
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[013/030] Train loss: 0.3781
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[014/030] Train loss: 0.3779
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[015/030] Train loss: 0.3778
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[016/030] Train loss: 0.3773
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[017/030] Train loss: 0.3773
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[018/030] Train loss: 0.3770
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[019/030] Train loss: 0.3769
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[020/030] Train loss: 0.3766
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[021/030] Train loss: 0.3763
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[022/030] Train loss: 0.3759
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[023/030] Train loss: 0.3755
2023-02-06 11:23:48 | Train | Epoch[015/600] Iteration[024/030] Train loss: 0.3755
2023-02-06 11:23:49 | Train | Epoch[015/600] Iteration[025/030] Train loss: 0.3752
2023-02-06 11:23:49 | Train | Epoch[015/600] Iteration[026/030] Train loss: 0.3749
2023-02-06 11:23:49 | Train | Epoch[015/600] Iteration[027/030] Train loss: 0.3745
2023-02-06 11:23:49 | Train | Epoch[015/600] Iteration[028/030] Train loss: 0.3743
2023-02-06 11:23:49 | Train | Epoch[015/600] Iteration[029/030] Train loss: 0.3743
2023-02-06 11:23:49 | Train | Epoch[015/600] Iteration[030/030] Train loss: 0.3741
2023-02-06 11:23:49 | Valid | Epoch[015/600] Iteration[001/008] Valid loss: 0.3882
2023-02-06 11:23:49 | Valid | Epoch[015/600] Iteration[002/008] Valid loss: 0.3890
2023-02-06 11:23:49 | Valid | Epoch[015/600] Iteration[003/008] Valid loss: 0.3852
2023-02-06 11:23:49 | Valid | Epoch[015/600] Iteration[004/008] Valid loss: 0.3871
2023-02-06 11:23:49 | Valid | Epoch[015/600] Iteration[005/008] Valid loss: 0.3867
2023-02-06 11:23:49 | Valid | Epoch[015/600] Iteration[006/008] Valid loss: 0.3865
2023-02-06 11:23:49 | Valid | Epoch[015/600] Iteration[007/008] Valid loss: 0.3887
2023-02-06 11:23:49 | Valid | Epoch[015/600] Iteration[008/008] Valid loss: 0.3878
2023-02-06 11:23:50 | Valid | Epoch[015/600] MIou: 0.8969282137260701
2023-02-06 11:23:50 | Valid | Epoch[015/600] Pixel Accuracy: 0.9814682006835938
2023-02-06 11:23:50 | Valid | Epoch[015/600] Mean Pixel Accuracy: 0.9439217999291445
2023-02-06 11:23:50 | Stage | Epoch[015/600] Train loss:0.3741
2023-02-06 11:23:50 | Stage | Epoch[015/600] Valid loss:0.3878
2023-02-06 11:23:50 | Stage | Epoch[015/600] LR:0.01

2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[001/030] Train loss: 0.3620
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[002/030] Train loss: 0.3634
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[003/030] Train loss: 0.3629
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[004/030] Train loss: 0.3641
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[005/030] Train loss: 0.3632
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[006/030] Train loss: 0.3634
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[007/030] Train loss: 0.3631
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[008/030] Train loss: 0.3638
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[009/030] Train loss: 0.3631
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[010/030] Train loss: 0.3628
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[011/030] Train loss: 0.3623
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[012/030] Train loss: 0.3618
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[013/030] Train loss: 0.3619
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[014/030] Train loss: 0.3621
2023-02-06 11:23:50 | Train | Epoch[016/600] Iteration[015/030] Train loss: 0.3618
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[016/030] Train loss: 0.3616
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[017/030] Train loss: 0.3611
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[018/030] Train loss: 0.3612
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[019/030] Train loss: 0.3608
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[020/030] Train loss: 0.3609
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[021/030] Train loss: 0.3606
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[022/030] Train loss: 0.3605
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[023/030] Train loss: 0.3606
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[024/030] Train loss: 0.3602
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[025/030] Train loss: 0.3601
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[026/030] Train loss: 0.3597
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[027/030] Train loss: 0.3595
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[028/030] Train loss: 0.3593
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[029/030] Train loss: 0.3591
2023-02-06 11:23:51 | Train | Epoch[016/600] Iteration[030/030] Train loss: 0.3589
2023-02-06 11:23:52 | Valid | Epoch[016/600] Iteration[001/008] Valid loss: 0.3553
2023-02-06 11:23:52 | Valid | Epoch[016/600] Iteration[002/008] Valid loss: 0.3543
2023-02-06 11:23:52 | Valid | Epoch[016/600] Iteration[003/008] Valid loss: 0.3531
2023-02-06 11:23:52 | Valid | Epoch[016/600] Iteration[004/008] Valid loss: 0.3528
2023-02-06 11:23:52 | Valid | Epoch[016/600] Iteration[005/008] Valid loss: 0.3530
2023-02-06 11:23:52 | Valid | Epoch[016/600] Iteration[006/008] Valid loss: 0.3531
2023-02-06 11:23:52 | Valid | Epoch[016/600] Iteration[007/008] Valid loss: 0.3535
2023-02-06 11:23:52 | Valid | Epoch[016/600] Iteration[008/008] Valid loss: 0.3529
2023-02-06 11:23:52 | Valid | Epoch[016/600] MIou: 0.9157736257769438
2023-02-06 11:23:52 | Valid | Epoch[016/600] Pixel Accuracy: 0.985870361328125
2023-02-06 11:23:52 | Valid | Epoch[016/600] Mean Pixel Accuracy: 0.9315364141862832
2023-02-06 11:23:52 | Stage | Epoch[016/600] Train loss:0.3589
2023-02-06 11:23:52 | Stage | Epoch[016/600] Valid loss:0.3529
2023-02-06 11:23:52 | Stage | Epoch[016/600] LR:0.01

2023-02-06 11:23:52 | Train | Epoch[017/600] Iteration[001/030] Train loss: 0.3515
2023-02-06 11:23:52 | Train | Epoch[017/600] Iteration[002/030] Train loss: 0.3547
2023-02-06 11:23:52 | Train | Epoch[017/600] Iteration[003/030] Train loss: 0.3527
2023-02-06 11:23:52 | Train | Epoch[017/600] Iteration[004/030] Train loss: 0.3508
2023-02-06 11:23:52 | Train | Epoch[017/600] Iteration[005/030] Train loss: 0.3511
2023-02-06 11:23:52 | Train | Epoch[017/600] Iteration[006/030] Train loss: 0.3516
2023-02-06 11:23:52 | Train | Epoch[017/600] Iteration[007/030] Train loss: 0.3508
2023-02-06 11:23:52 | Train | Epoch[017/600] Iteration[008/030] Train loss: 0.3502
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[009/030] Train loss: 0.3496
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[010/030] Train loss: 0.3493
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[011/030] Train loss: 0.3491
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[012/030] Train loss: 0.3492
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[013/030] Train loss: 0.3487
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[014/030] Train loss: 0.3484
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[015/030] Train loss: 0.3483
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[016/030] Train loss: 0.3478
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[017/030] Train loss: 0.3476
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[018/030] Train loss: 0.3472
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[019/030] Train loss: 0.3471
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[020/030] Train loss: 0.3468
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[021/030] Train loss: 0.3463
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[022/030] Train loss: 0.3461
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[023/030] Train loss: 0.3460
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[024/030] Train loss: 0.3457
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[025/030] Train loss: 0.3455
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[026/030] Train loss: 0.3453
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[027/030] Train loss: 0.3453
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[028/030] Train loss: 0.3452
2023-02-06 11:23:53 | Train | Epoch[017/600] Iteration[029/030] Train loss: 0.3450
2023-02-06 11:23:54 | Train | Epoch[017/600] Iteration[030/030] Train loss: 0.3450
2023-02-06 11:23:54 | Valid | Epoch[017/600] Iteration[001/008] Valid loss: 0.3938
2023-02-06 11:23:54 | Valid | Epoch[017/600] Iteration[002/008] Valid loss: 0.3886
2023-02-06 11:23:54 | Valid | Epoch[017/600] Iteration[003/008] Valid loss: 0.3871
2023-02-06 11:23:54 | Valid | Epoch[017/600] Iteration[004/008] Valid loss: 0.3881
2023-02-06 11:23:54 | Valid | Epoch[017/600] Iteration[005/008] Valid loss: 0.3900
2023-02-06 11:23:54 | Valid | Epoch[017/600] Iteration[006/008] Valid loss: 0.3898
2023-02-06 11:23:54 | Valid | Epoch[017/600] Iteration[007/008] Valid loss: 0.3923
2023-02-06 11:23:54 | Valid | Epoch[017/600] Iteration[008/008] Valid loss: 0.3921
2023-02-06 11:23:54 | Valid | Epoch[017/600] MIou: 0.8787965000153927
2023-02-06 11:23:54 | Valid | Epoch[017/600] Pixel Accuracy: 0.9754447937011719
2023-02-06 11:23:54 | Valid | Epoch[017/600] Mean Pixel Accuracy: 0.9820333789479283
2023-02-06 11:23:54 | Stage | Epoch[017/600] Train loss:0.3450
2023-02-06 11:23:54 | Stage | Epoch[017/600] Valid loss:0.3921
2023-02-06 11:23:54 | Stage | Epoch[017/600] LR:0.01

2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[001/030] Train loss: 0.3380
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[002/030] Train loss: 0.3358
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[003/030] Train loss: 0.3360
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[004/030] Train loss: 0.3363
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[005/030] Train loss: 0.3369
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[006/030] Train loss: 0.3376
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[007/030] Train loss: 0.3370
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[008/030] Train loss: 0.3368
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[009/030] Train loss: 0.3367
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[010/030] Train loss: 0.3365
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[011/030] Train loss: 0.3360
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[012/030] Train loss: 0.3355
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[013/030] Train loss: 0.3361
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[014/030] Train loss: 0.3359
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[015/030] Train loss: 0.3355
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[016/030] Train loss: 0.3351
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[017/030] Train loss: 0.3351
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[018/030] Train loss: 0.3352
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[019/030] Train loss: 0.3348
2023-02-06 11:23:55 | Train | Epoch[018/600] Iteration[020/030] Train loss: 0.3345
2023-02-06 11:23:56 | Train | Epoch[018/600] Iteration[021/030] Train loss: 0.3343
2023-02-06 11:23:56 | Train | Epoch[018/600] Iteration[022/030] Train loss: 0.3340
2023-02-06 11:23:56 | Train | Epoch[018/600] Iteration[023/030] Train loss: 0.3337
2023-02-06 11:23:56 | Train | Epoch[018/600] Iteration[024/030] Train loss: 0.3334
2023-02-06 11:23:56 | Train | Epoch[018/600] Iteration[025/030] Train loss: 0.3330
2023-02-06 11:23:56 | Train | Epoch[018/600] Iteration[026/030] Train loss: 0.3328
2023-02-06 11:23:56 | Train | Epoch[018/600] Iteration[027/030] Train loss: 0.3325
2023-02-06 11:23:56 | Train | Epoch[018/600] Iteration[028/030] Train loss: 0.3324
2023-02-06 11:23:56 | Train | Epoch[018/600] Iteration[029/030] Train loss: 0.3321
2023-02-06 11:23:56 | Train | Epoch[018/600] Iteration[030/030] Train loss: 0.3321
2023-02-06 11:23:56 | Valid | Epoch[018/600] Iteration[001/008] Valid loss: 0.3935
2023-02-06 11:23:56 | Valid | Epoch[018/600] Iteration[002/008] Valid loss: 0.3873
2023-02-06 11:23:56 | Valid | Epoch[018/600] Iteration[003/008] Valid loss: 0.3865
2023-02-06 11:23:56 | Valid | Epoch[018/600] Iteration[004/008] Valid loss: 0.3879
2023-02-06 11:23:56 | Valid | Epoch[018/600] Iteration[005/008] Valid loss: 0.3905
2023-02-06 11:23:56 | Valid | Epoch[018/600] Iteration[006/008] Valid loss: 0.3903
2023-02-06 11:23:56 | Valid | Epoch[018/600] Iteration[007/008] Valid loss: 0.3931
2023-02-06 11:23:56 | Valid | Epoch[018/600] Iteration[008/008] Valid loss: 0.3937
2023-02-06 11:23:57 | Valid | Epoch[018/600] MIou: 0.8656468708056816
2023-02-06 11:23:57 | Valid | Epoch[018/600] Pixel Accuracy: 0.9720191955566406
2023-02-06 11:23:57 | Valid | Epoch[018/600] Mean Pixel Accuracy: 0.9810381901211578
2023-02-06 11:23:57 | Stage | Epoch[018/600] Train loss:0.3321
2023-02-06 11:23:57 | Stage | Epoch[018/600] Valid loss:0.3937
2023-02-06 11:23:57 | Stage | Epoch[018/600] LR:0.01

2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[001/030] Train loss: 0.3247
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[002/030] Train loss: 0.3240
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[003/030] Train loss: 0.3267
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[004/030] Train loss: 0.3277
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[005/030] Train loss: 0.3269
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[006/030] Train loss: 0.3255
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[007/030] Train loss: 0.3248
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[008/030] Train loss: 0.3248
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[009/030] Train loss: 0.3243
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[010/030] Train loss: 0.3242
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[011/030] Train loss: 0.3235
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[012/030] Train loss: 0.3232
2023-02-06 11:23:57 | Train | Epoch[019/600] Iteration[013/030] Train loss: 0.3228
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[014/030] Train loss: 0.3226
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[015/030] Train loss: 0.3221
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[016/030] Train loss: 0.3221
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[017/030] Train loss: 0.3219
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[018/030] Train loss: 0.3219
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[019/030] Train loss: 0.3217
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[020/030] Train loss: 0.3214
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[021/030] Train loss: 0.3214
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[022/030] Train loss: 0.3211
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[023/030] Train loss: 0.3208
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[024/030] Train loss: 0.3206
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[025/030] Train loss: 0.3203
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[026/030] Train loss: 0.3203
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[027/030] Train loss: 0.3199
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[028/030] Train loss: 0.3196
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[029/030] Train loss: 0.3195
2023-02-06 11:23:58 | Train | Epoch[019/600] Iteration[030/030] Train loss: 0.3192
2023-02-06 11:23:59 | Valid | Epoch[019/600] Iteration[001/008] Valid loss: 0.3141
2023-02-06 11:23:59 | Valid | Epoch[019/600] Iteration[002/008] Valid loss: 0.3117
2023-02-06 11:23:59 | Valid | Epoch[019/600] Iteration[003/008] Valid loss: 0.3109
2023-02-06 11:23:59 | Valid | Epoch[019/600] Iteration[004/008] Valid loss: 0.3104
2023-02-06 11:23:59 | Valid | Epoch[019/600] Iteration[005/008] Valid loss: 0.3111
2023-02-06 11:23:59 | Valid | Epoch[019/600] Iteration[006/008] Valid loss: 0.3109
2023-02-06 11:23:59 | Valid | Epoch[019/600] Iteration[007/008] Valid loss: 0.3120
2023-02-06 11:23:59 | Valid | Epoch[019/600] Iteration[008/008] Valid loss: 0.3114
2023-02-06 11:23:59 | Valid | Epoch[019/600] MIou: 0.9326657937745362
2023-02-06 11:23:59 | Valid | Epoch[019/600] Pixel Accuracy: 0.9883600870768229
2023-02-06 11:23:59 | Valid | Epoch[019/600] Mean Pixel Accuracy: 0.9610882695131973
2023-02-06 11:23:59 | Stage | Epoch[019/600] Train loss:0.3192
2023-02-06 11:23:59 | Stage | Epoch[019/600] Valid loss:0.3114
2023-02-06 11:23:59 | Stage | Epoch[019/600] LR:0.01

2023-02-06 11:23:59 | Train | Epoch[020/600] Iteration[001/030] Train loss: 0.3105
2023-02-06 11:23:59 | Train | Epoch[020/600] Iteration[002/030] Train loss: 0.3090
2023-02-06 11:23:59 | Train | Epoch[020/600] Iteration[003/030] Train loss: 0.3086
2023-02-06 11:23:59 | Train | Epoch[020/600] Iteration[004/030] Train loss: 0.3086
2023-02-06 11:23:59 | Train | Epoch[020/600] Iteration[005/030] Train loss: 0.3090
2023-02-06 11:23:59 | Train | Epoch[020/600] Iteration[006/030] Train loss: 0.3098
2023-02-06 11:23:59 | Train | Epoch[020/600] Iteration[007/030] Train loss: 0.3097
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[008/030] Train loss: 0.3093
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[009/030] Train loss: 0.3096
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[010/030] Train loss: 0.3100
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[011/030] Train loss: 0.3107
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[012/030] Train loss: 0.3108
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[013/030] Train loss: 0.3104
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[014/030] Train loss: 0.3107
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[015/030] Train loss: 0.3107
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[016/030] Train loss: 0.3104
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[017/030] Train loss: 0.3101
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[018/030] Train loss: 0.3098
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[019/030] Train loss: 0.3095
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[020/030] Train loss: 0.3091
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[021/030] Train loss: 0.3092
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[022/030] Train loss: 0.3090
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[023/030] Train loss: 0.3086
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[024/030] Train loss: 0.3085
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[025/030] Train loss: 0.3083
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[026/030] Train loss: 0.3082
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[027/030] Train loss: 0.3080
2023-02-06 11:24:00 | Train | Epoch[020/600] Iteration[028/030] Train loss: 0.3079
2023-02-06 11:24:01 | Train | Epoch[020/600] Iteration[029/030] Train loss: 0.3077
2023-02-06 11:24:01 | Train | Epoch[020/600] Iteration[030/030] Train loss: 0.3076
2023-02-06 11:24:01 | Valid | Epoch[020/600] Iteration[001/008] Valid loss: 0.4547
2023-02-06 11:24:01 | Valid | Epoch[020/600] Iteration[002/008] Valid loss: 0.4595
2023-02-06 11:24:01 | Valid | Epoch[020/600] Iteration[003/008] Valid loss: 0.4620
2023-02-06 11:24:01 | Valid | Epoch[020/600] Iteration[004/008] Valid loss: 0.4649
2023-02-06 11:24:01 | Valid | Epoch[020/600] Iteration[005/008] Valid loss: 0.4656
2023-02-06 11:24:01 | Valid | Epoch[020/600] Iteration[006/008] Valid loss: 0.4619
2023-02-06 11:24:01 | Valid | Epoch[020/600] Iteration[007/008] Valid loss: 0.4653
2023-02-06 11:24:01 | Valid | Epoch[020/600] Iteration[008/008] Valid loss: 0.4717
2023-02-06 11:24:01 | Valid | Epoch[020/600] MIou: 0.7854842087808123
2023-02-06 11:24:01 | Valid | Epoch[020/600] Pixel Accuracy: 0.9469795227050781
2023-02-06 11:24:01 | Valid | Epoch[020/600] Mean Pixel Accuracy: 0.9691774594593446
2023-02-06 11:24:01 | Stage | Epoch[020/600] Train loss:0.3076
2023-02-06 11:24:01 | Stage | Epoch[020/600] Valid loss:0.4717
2023-02-06 11:24:01 | Stage | Epoch[020/600] LR:0.01

2023-02-06 11:24:01 | Train | Epoch[021/600] Iteration[001/030] Train loss: 0.3003
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[002/030] Train loss: 0.3040
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[003/030] Train loss: 0.3040
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[004/030] Train loss: 0.3040
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[005/030] Train loss: 0.3034
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[006/030] Train loss: 0.3024
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[007/030] Train loss: 0.3026
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[008/030] Train loss: 0.3016
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[009/030] Train loss: 0.3012
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[010/030] Train loss: 0.3008
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[011/030] Train loss: 0.3007
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[012/030] Train loss: 0.3004
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[013/030] Train loss: 0.2997
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[014/030] Train loss: 0.2994
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[015/030] Train loss: 0.2991
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[016/030] Train loss: 0.2991
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[017/030] Train loss: 0.2990
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[018/030] Train loss: 0.2989
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[019/030] Train loss: 0.2987
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[020/030] Train loss: 0.2985
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[021/030] Train loss: 0.2983
2023-02-06 11:24:02 | Train | Epoch[021/600] Iteration[022/030] Train loss: 0.2980
2023-02-06 11:24:03 | Train | Epoch[021/600] Iteration[023/030] Train loss: 0.2983
2023-02-06 11:24:03 | Train | Epoch[021/600] Iteration[024/030] Train loss: 0.2979
2023-02-06 11:24:03 | Train | Epoch[021/600] Iteration[025/030] Train loss: 0.2977
2023-02-06 11:24:03 | Train | Epoch[021/600] Iteration[026/030] Train loss: 0.2978
2023-02-06 11:24:03 | Train | Epoch[021/600] Iteration[027/030] Train loss: 0.2976
2023-02-06 11:24:03 | Train | Epoch[021/600] Iteration[028/030] Train loss: 0.2975
2023-02-06 11:24:03 | Train | Epoch[021/600] Iteration[029/030] Train loss: 0.2974
2023-02-06 11:24:03 | Train | Epoch[021/600] Iteration[030/030] Train loss: 0.2972
2023-02-06 11:24:03 | Valid | Epoch[021/600] Iteration[001/008] Valid loss: 0.7605
2023-02-06 11:24:03 | Valid | Epoch[021/600] Iteration[002/008] Valid loss: 0.7697
2023-02-06 11:24:03 | Valid | Epoch[021/600] Iteration[003/008] Valid loss: 0.7711
2023-02-06 11:24:03 | Valid | Epoch[021/600] Iteration[004/008] Valid loss: 0.7778
2023-02-06 11:24:03 | Valid | Epoch[021/600] Iteration[005/008] Valid loss: 0.7780
2023-02-06 11:24:03 | Valid | Epoch[021/600] Iteration[006/008] Valid loss: 0.7609
2023-02-06 11:24:03 | Valid | Epoch[021/600] Iteration[007/008] Valid loss: 0.7690
2023-02-06 11:24:03 | Valid | Epoch[021/600] Iteration[008/008] Valid loss: 0.7951
2023-02-06 11:24:04 | Valid | Epoch[021/600] MIou: 0.6395682868657374
2023-02-06 11:24:04 | Valid | Epoch[021/600] Pixel Accuracy: 0.874114990234375
2023-02-06 11:24:04 | Valid | Epoch[021/600] Mean Pixel Accuracy: 0.9303643967611528
2023-02-06 11:24:04 | Stage | Epoch[021/600] Train loss:0.2972
2023-02-06 11:24:04 | Stage | Epoch[021/600] Valid loss:0.7951
2023-02-06 11:24:04 | Stage | Epoch[021/600] LR:0.01

2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[001/030] Train loss: 0.2988
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[002/030] Train loss: 0.2933
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[003/030] Train loss: 0.2939
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[004/030] Train loss: 0.2923
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[005/030] Train loss: 0.2916
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[006/030] Train loss: 0.2910
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[007/030] Train loss: 0.2909
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[008/030] Train loss: 0.2902
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[009/030] Train loss: 0.2898
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[010/030] Train loss: 0.2898
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[011/030] Train loss: 0.2899
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[012/030] Train loss: 0.2898
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[013/030] Train loss: 0.2904
2023-02-06 11:24:04 | Train | Epoch[022/600] Iteration[014/030] Train loss: 0.2900
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[015/030] Train loss: 0.2899
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[016/030] Train loss: 0.2897
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[017/030] Train loss: 0.2895
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[018/030] Train loss: 0.2894
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[019/030] Train loss: 0.2891
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[020/030] Train loss: 0.2888
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[021/030] Train loss: 0.2883
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[022/030] Train loss: 0.2882
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[023/030] Train loss: 0.2879
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[024/030] Train loss: 0.2876
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[025/030] Train loss: 0.2872
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[026/030] Train loss: 0.2872
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[027/030] Train loss: 0.2869
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[028/030] Train loss: 0.2868
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[029/030] Train loss: 0.2865
2023-02-06 11:24:05 | Train | Epoch[022/600] Iteration[030/030] Train loss: 0.2862
2023-02-06 11:24:06 | Valid | Epoch[022/600] Iteration[001/008] Valid loss: 0.4356
2023-02-06 11:24:06 | Valid | Epoch[022/600] Iteration[002/008] Valid loss: 0.4297
2023-02-06 11:24:06 | Valid | Epoch[022/600] Iteration[003/008] Valid loss: 0.4241
2023-02-06 11:24:06 | Valid | Epoch[022/600] Iteration[004/008] Valid loss: 0.4245
2023-02-06 11:24:06 | Valid | Epoch[022/600] Iteration[005/008] Valid loss: 0.4247
2023-02-06 11:24:06 | Valid | Epoch[022/600] Iteration[006/008] Valid loss: 0.4193
2023-02-06 11:24:06 | Valid | Epoch[022/600] Iteration[007/008] Valid loss: 0.4225
2023-02-06 11:24:06 | Valid | Epoch[022/600] Iteration[008/008] Valid loss: 0.4318
2023-02-06 11:24:06 | Valid | Epoch[022/600] MIou: 0.8275438119765848
2023-02-06 11:24:06 | Valid | Epoch[022/600] Pixel Accuracy: 0.9611918131510416
2023-02-06 11:24:06 | Valid | Epoch[022/600] Mean Pixel Accuracy: 0.974960189544108
2023-02-06 11:24:06 | Stage | Epoch[022/600] Train loss:0.2862
2023-02-06 11:24:06 | Stage | Epoch[022/600] Valid loss:0.4318
2023-02-06 11:24:06 | Stage | Epoch[022/600] LR:0.01

2023-02-06 11:24:06 | Train | Epoch[023/600] Iteration[001/030] Train loss: 0.2835
2023-02-06 11:24:06 | Train | Epoch[023/600] Iteration[002/030] Train loss: 0.2807
2023-02-06 11:24:06 | Train | Epoch[023/600] Iteration[003/030] Train loss: 0.2785
2023-02-06 11:24:06 | Train | Epoch[023/600] Iteration[004/030] Train loss: 0.2784
2023-02-06 11:24:06 | Train | Epoch[023/600] Iteration[005/030] Train loss: 0.2796
2023-02-06 11:24:06 | Train | Epoch[023/600] Iteration[006/030] Train loss: 0.2788
2023-02-06 11:24:06 | Train | Epoch[023/600] Iteration[007/030] Train loss: 0.2791
2023-02-06 11:24:06 | Train | Epoch[023/600] Iteration[008/030] Train loss: 0.2787
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[009/030] Train loss: 0.2785
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[010/030] Train loss: 0.2792
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[011/030] Train loss: 0.2788
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[012/030] Train loss: 0.2785
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[013/030] Train loss: 0.2781
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[014/030] Train loss: 0.2779
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[015/030] Train loss: 0.2775
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[016/030] Train loss: 0.2776
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[017/030] Train loss: 0.2775
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[018/030] Train loss: 0.2773
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[019/030] Train loss: 0.2771
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[020/030] Train loss: 0.2770
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[021/030] Train loss: 0.2767
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[022/030] Train loss: 0.2766
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[023/030] Train loss: 0.2766
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[024/030] Train loss: 0.2764
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[025/030] Train loss: 0.2763
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[026/030] Train loss: 0.2761
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[027/030] Train loss: 0.2759
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[028/030] Train loss: 0.2758
2023-02-06 11:24:07 | Train | Epoch[023/600] Iteration[029/030] Train loss: 0.2756
2023-02-06 11:24:08 | Train | Epoch[023/600] Iteration[030/030] Train loss: 0.2756
2023-02-06 11:24:08 | Valid | Epoch[023/600] Iteration[001/008] Valid loss: 0.2830
2023-02-06 11:24:08 | Valid | Epoch[023/600] Iteration[002/008] Valid loss: 0.2821
2023-02-06 11:24:08 | Valid | Epoch[023/600] Iteration[003/008] Valid loss: 0.2815
2023-02-06 11:24:08 | Valid | Epoch[023/600] Iteration[004/008] Valid loss: 0.2809
2023-02-06 11:24:08 | Valid | Epoch[023/600] Iteration[005/008] Valid loss: 0.2813
2023-02-06 11:24:08 | Valid | Epoch[023/600] Iteration[006/008] Valid loss: 0.2815
2023-02-06 11:24:08 | Valid | Epoch[023/600] Iteration[007/008] Valid loss: 0.2816
2023-02-06 11:24:08 | Valid | Epoch[023/600] Iteration[008/008] Valid loss: 0.2811
2023-02-06 11:24:08 | Valid | Epoch[023/600] MIou: 0.9105291457211397
2023-02-06 11:24:08 | Valid | Epoch[023/600] Pixel Accuracy: 0.9851862589518229
2023-02-06 11:24:08 | Valid | Epoch[023/600] Mean Pixel Accuracy: 0.9210600312252637
2023-02-06 11:24:08 | Stage | Epoch[023/600] Train loss:0.2756
2023-02-06 11:24:08 | Stage | Epoch[023/600] Valid loss:0.2811
2023-02-06 11:24:08 | Stage | Epoch[023/600] LR:0.01

2023-02-06 11:24:08 | Train | Epoch[024/600] Iteration[001/030] Train loss: 0.2672
2023-02-06 11:24:08 | Train | Epoch[024/600] Iteration[002/030] Train loss: 0.2678
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[003/030] Train loss: 0.2684
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[004/030] Train loss: 0.2695
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[005/030] Train loss: 0.2695
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[006/030] Train loss: 0.2695
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[007/030] Train loss: 0.2692
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[008/030] Train loss: 0.2687
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[009/030] Train loss: 0.2683
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[010/030] Train loss: 0.2682
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[011/030] Train loss: 0.2676
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[012/030] Train loss: 0.2680
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[013/030] Train loss: 0.2679
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[014/030] Train loss: 0.2675
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[015/030] Train loss: 0.2674
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[016/030] Train loss: 0.2672
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[017/030] Train loss: 0.2670
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[018/030] Train loss: 0.2667
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[019/030] Train loss: 0.2667
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[020/030] Train loss: 0.2668
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[021/030] Train loss: 0.2667
2023-02-06 11:24:09 | Train | Epoch[024/600] Iteration[022/030] Train loss: 0.2666
2023-02-06 11:24:10 | Train | Epoch[024/600] Iteration[023/030] Train loss: 0.2666
2023-02-06 11:24:10 | Train | Epoch[024/600] Iteration[024/030] Train loss: 0.2663
2023-02-06 11:24:10 | Train | Epoch[024/600] Iteration[025/030] Train loss: 0.2660
2023-02-06 11:24:10 | Train | Epoch[024/600] Iteration[026/030] Train loss: 0.2659
2023-02-06 11:24:10 | Train | Epoch[024/600] Iteration[027/030] Train loss: 0.2660
2023-02-06 11:24:10 | Train | Epoch[024/600] Iteration[028/030] Train loss: 0.2659
2023-02-06 11:24:10 | Train | Epoch[024/600] Iteration[029/030] Train loss: 0.2658
2023-02-06 11:24:10 | Train | Epoch[024/600] Iteration[030/030] Train loss: 0.2657
2023-02-06 11:24:10 | Valid | Epoch[024/600] Iteration[001/008] Valid loss: 0.4043
2023-02-06 11:24:10 | Valid | Epoch[024/600] Iteration[002/008] Valid loss: 0.4067
2023-02-06 11:24:10 | Valid | Epoch[024/600] Iteration[003/008] Valid loss: 0.4045
2023-02-06 11:24:10 | Valid | Epoch[024/600] Iteration[004/008] Valid loss: 0.4074
2023-02-06 11:24:10 | Valid | Epoch[024/600] Iteration[005/008] Valid loss: 0.4083
2023-02-06 11:24:10 | Valid | Epoch[024/600] Iteration[006/008] Valid loss: 0.4035
2023-02-06 11:24:10 | Valid | Epoch[024/600] Iteration[007/008] Valid loss: 0.4074
2023-02-06 11:24:10 | Valid | Epoch[024/600] Iteration[008/008] Valid loss: 0.4133
2023-02-06 11:24:10 | Valid | Epoch[024/600] MIou: 0.8093016516060378
2023-02-06 11:24:10 | Valid | Epoch[024/600] Pixel Accuracy: 0.9552790323893229
2023-02-06 11:24:10 | Valid | Epoch[024/600] Mean Pixel Accuracy: 0.97321296481183
2023-02-06 11:24:10 | Stage | Epoch[024/600] Train loss:0.2657
2023-02-06 11:24:10 | Stage | Epoch[024/600] Valid loss:0.4133
2023-02-06 11:24:10 | Stage | Epoch[024/600] LR:0.01

2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[001/030] Train loss: 0.2607
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[002/030] Train loss: 0.2589
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[003/030] Train loss: 0.2588
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[004/030] Train loss: 0.2591
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[005/030] Train loss: 0.2592
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[006/030] Train loss: 0.2599
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[007/030] Train loss: 0.2591
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[008/030] Train loss: 0.2587
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[009/030] Train loss: 0.2587
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[010/030] Train loss: 0.2593
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[011/030] Train loss: 0.2589
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[012/030] Train loss: 0.2587
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[013/030] Train loss: 0.2585
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[014/030] Train loss: 0.2586
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[015/030] Train loss: 0.2586
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[016/030] Train loss: 0.2585
2023-02-06 11:24:11 | Train | Epoch[025/600] Iteration[017/030] Train loss: 0.2582
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[018/030] Train loss: 0.2584
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[019/030] Train loss: 0.2582
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[020/030] Train loss: 0.2579
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[021/030] Train loss: 0.2577
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[022/030] Train loss: 0.2576
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[023/030] Train loss: 0.2574
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[024/030] Train loss: 0.2572
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[025/030] Train loss: 0.2574
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[026/030] Train loss: 0.2572
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[027/030] Train loss: 0.2574
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[028/030] Train loss: 0.2572
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[029/030] Train loss: 0.2570
2023-02-06 11:24:12 | Train | Epoch[025/600] Iteration[030/030] Train loss: 0.2567
2023-02-06 11:24:12 | Valid | Epoch[025/600] Iteration[001/008] Valid loss: 0.3286
2023-02-06 11:24:12 | Valid | Epoch[025/600] Iteration[002/008] Valid loss: 0.3174
2023-02-06 11:24:13 | Valid | Epoch[025/600] Iteration[003/008] Valid loss: 0.3132
2023-02-06 11:24:13 | Valid | Epoch[025/600] Iteration[004/008] Valid loss: 0.3123
2023-02-06 11:24:13 | Valid | Epoch[025/600] Iteration[005/008] Valid loss: 0.3138
2023-02-06 11:24:13 | Valid | Epoch[025/600] Iteration[006/008] Valid loss: 0.3110
2023-02-06 11:24:13 | Valid | Epoch[025/600] Iteration[007/008] Valid loss: 0.3131
2023-02-06 11:24:13 | Valid | Epoch[025/600] Iteration[008/008] Valid loss: 0.3157
2023-02-06 11:24:13 | Valid | Epoch[025/600] MIou: 0.8846286271729489
2023-02-06 11:24:13 | Valid | Epoch[025/600] Pixel Accuracy: 0.9770825703938802
2023-02-06 11:24:13 | Valid | Epoch[025/600] Mean Pixel Accuracy: 0.9785840074104406
2023-02-06 11:24:13 | Stage | Epoch[025/600] Train loss:0.2567
2023-02-06 11:24:13 | Stage | Epoch[025/600] Valid loss:0.3157
2023-02-06 11:24:13 | Stage | Epoch[025/600] LR:0.01

2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[001/030] Train loss: 0.2511
2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[002/030] Train loss: 0.2512
2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[003/030] Train loss: 0.2508
2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[004/030] Train loss: 0.2518
2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[005/030] Train loss: 0.2526
2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[006/030] Train loss: 0.2525
2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[007/030] Train loss: 0.2517
2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[008/030] Train loss: 0.2513
2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[009/030] Train loss: 0.2515
2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[010/030] Train loss: 0.2512
2023-02-06 11:24:13 | Train | Epoch[026/600] Iteration[011/030] Train loss: 0.2508
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[012/030] Train loss: 0.2506
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[013/030] Train loss: 0.2503
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[014/030] Train loss: 0.2502
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[015/030] Train loss: 0.2500
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[016/030] Train loss: 0.2496
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[017/030] Train loss: 0.2496
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[018/030] Train loss: 0.2496
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[019/030] Train loss: 0.2496
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[020/030] Train loss: 0.2494
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[021/030] Train loss: 0.2492
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[022/030] Train loss: 0.2493
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[023/030] Train loss: 0.2491
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[024/030] Train loss: 0.2488
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[025/030] Train loss: 0.2485
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[026/030] Train loss: 0.2482
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[027/030] Train loss: 0.2480
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[028/030] Train loss: 0.2478
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[029/030] Train loss: 0.2476
2023-02-06 11:24:14 | Train | Epoch[026/600] Iteration[030/030] Train loss: 0.2478
2023-02-06 11:24:15 | Valid | Epoch[026/600] Iteration[001/008] Valid loss: 0.2751
2023-02-06 11:24:15 | Valid | Epoch[026/600] Iteration[002/008] Valid loss: 0.2749
2023-02-06 11:24:15 | Valid | Epoch[026/600] Iteration[003/008] Valid loss: 0.2731
2023-02-06 11:24:15 | Valid | Epoch[026/600] Iteration[004/008] Valid loss: 0.2729
2023-02-06 11:24:15 | Valid | Epoch[026/600] Iteration[005/008] Valid loss: 0.2736
2023-02-06 11:24:15 | Valid | Epoch[026/600] Iteration[006/008] Valid loss: 0.2738
2023-02-06 11:24:15 | Valid | Epoch[026/600] Iteration[007/008] Valid loss: 0.2751
2023-02-06 11:24:15 | Valid | Epoch[026/600] Iteration[008/008] Valid loss: 0.2740
2023-02-06 11:24:15 | Valid | Epoch[026/600] MIou: 0.9337261438560311
2023-02-06 11:24:15 | Valid | Epoch[026/600] Pixel Accuracy: 0.9880854288736979
2023-02-06 11:24:15 | Valid | Epoch[026/600] Mean Pixel Accuracy: 0.9808971099708979
2023-02-06 11:24:15 | Stage | Epoch[026/600] Train loss:0.2478
2023-02-06 11:24:15 | Stage | Epoch[026/600] Valid loss:0.2740
2023-02-06 11:24:15 | Stage | Epoch[026/600] LR:0.01

2023-02-06 11:24:15 | Train | Epoch[027/600] Iteration[001/030] Train loss: 0.2435
2023-02-06 11:24:15 | Train | Epoch[027/600] Iteration[002/030] Train loss: 0.2430
2023-02-06 11:24:15 | Train | Epoch[027/600] Iteration[003/030] Train loss: 0.2436
2023-02-06 11:24:15 | Train | Epoch[027/600] Iteration[004/030] Train loss: 0.2435
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[005/030] Train loss: 0.2433
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[006/030] Train loss: 0.2434
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[007/030] Train loss: 0.2427
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[008/030] Train loss: 0.2424
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[009/030] Train loss: 0.2422
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[010/030] Train loss: 0.2421
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[011/030] Train loss: 0.2417
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[012/030] Train loss: 0.2413
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[013/030] Train loss: 0.2413
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[014/030] Train loss: 0.2410
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[015/030] Train loss: 0.2408
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[016/030] Train loss: 0.2405
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[017/030] Train loss: 0.2402
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[018/030] Train loss: 0.2400
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[019/030] Train loss: 0.2399
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[020/030] Train loss: 0.2400
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[021/030] Train loss: 0.2397
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[022/030] Train loss: 0.2395
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[023/030] Train loss: 0.2393
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[024/030] Train loss: 0.2391
2023-02-06 11:24:16 | Train | Epoch[027/600] Iteration[025/030] Train loss: 0.2393
2023-02-06 11:24:17 | Train | Epoch[027/600] Iteration[026/030] Train loss: 0.2391
2023-02-06 11:24:17 | Train | Epoch[027/600] Iteration[027/030] Train loss: 0.2390
2023-02-06 11:24:17 | Train | Epoch[027/600] Iteration[028/030] Train loss: 0.2393
2023-02-06 11:24:17 | Train | Epoch[027/600] Iteration[029/030] Train loss: 0.2392
2023-02-06 11:24:17 | Train | Epoch[027/600] Iteration[030/030] Train loss: 0.2390
2023-02-06 11:24:17 | Valid | Epoch[027/600] Iteration[001/008] Valid loss: 0.2441
2023-02-06 11:24:17 | Valid | Epoch[027/600] Iteration[002/008] Valid loss: 0.2439
2023-02-06 11:24:17 | Valid | Epoch[027/600] Iteration[003/008] Valid loss: 0.2435
2023-02-06 11:24:17 | Valid | Epoch[027/600] Iteration[004/008] Valid loss: 0.2431
2023-02-06 11:24:17 | Valid | Epoch[027/600] Iteration[005/008] Valid loss: 0.2436
2023-02-06 11:24:17 | Valid | Epoch[027/600] Iteration[006/008] Valid loss: 0.2438
2023-02-06 11:24:17 | Valid | Epoch[027/600] Iteration[007/008] Valid loss: 0.2436
2023-02-06 11:24:17 | Valid | Epoch[027/600] Iteration[008/008] Valid loss: 0.2433
2023-02-06 11:24:17 | Valid | Epoch[027/600] MIou: 0.862102278266621
2023-02-06 11:24:17 | Valid | Epoch[027/600] Pixel Accuracy: 0.9772682189941406
2023-02-06 11:24:17 | Valid | Epoch[027/600] Mean Pixel Accuracy: 0.8746452507571474
2023-02-06 11:24:17 | Stage | Epoch[027/600] Train loss:0.2390
2023-02-06 11:24:17 | Stage | Epoch[027/600] Valid loss:0.2433
2023-02-06 11:24:17 | Stage | Epoch[027/600] LR:0.01

2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[001/030] Train loss: 0.2331
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[002/030] Train loss: 0.2313
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[003/030] Train loss: 0.2330
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[004/030] Train loss: 0.2343
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[005/030] Train loss: 0.2338
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[006/030] Train loss: 0.2349
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[007/030] Train loss: 0.2345
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[008/030] Train loss: 0.2339
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[009/030] Train loss: 0.2335
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[010/030] Train loss: 0.2330
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[011/030] Train loss: 0.2327
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[012/030] Train loss: 0.2327
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[013/030] Train loss: 0.2326
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[014/030] Train loss: 0.2325
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[015/030] Train loss: 0.2325
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[016/030] Train loss: 0.2323
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[017/030] Train loss: 0.2323
2023-02-06 11:24:18 | Train | Epoch[028/600] Iteration[018/030] Train loss: 0.2325
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[019/030] Train loss: 0.2327
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[020/030] Train loss: 0.2326
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[021/030] Train loss: 0.2327
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[022/030] Train loss: 0.2327
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[023/030] Train loss: 0.2326
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[024/030] Train loss: 0.2324
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[025/030] Train loss: 0.2321
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[026/030] Train loss: 0.2320
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[027/030] Train loss: 0.2317
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[028/030] Train loss: 0.2315
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[029/030] Train loss: 0.2314
2023-02-06 11:24:19 | Train | Epoch[028/600] Iteration[030/030] Train loss: 0.2312
2023-02-06 11:24:19 | Valid | Epoch[028/600] Iteration[001/008] Valid loss: 0.2717
2023-02-06 11:24:19 | Valid | Epoch[028/600] Iteration[002/008] Valid loss: 0.2669
2023-02-06 11:24:19 | Valid | Epoch[028/600] Iteration[003/008] Valid loss: 0.2627
2023-02-06 11:24:19 | Valid | Epoch[028/600] Iteration[004/008] Valid loss: 0.2662
2023-02-06 11:24:19 | Valid | Epoch[028/600] Iteration[005/008] Valid loss: 0.2660
2023-02-06 11:24:20 | Valid | Epoch[028/600] Iteration[006/008] Valid loss: 0.2677
2023-02-06 11:24:20 | Valid | Epoch[028/600] Iteration[007/008] Valid loss: 0.2704
2023-02-06 11:24:20 | Valid | Epoch[028/600] Iteration[008/008] Valid loss: 0.2688
2023-02-06 11:24:20 | Valid | Epoch[028/600] MIou: 0.9066113847103006
2023-02-06 11:24:20 | Valid | Epoch[028/600] Pixel Accuracy: 0.9827957153320312
2023-02-06 11:24:20 | Valid | Epoch[028/600] Mean Pixel Accuracy: 0.9651248411095619
2023-02-06 11:24:20 | Stage | Epoch[028/600] Train loss:0.2312
2023-02-06 11:24:20 | Stage | Epoch[028/600] Valid loss:0.2688
2023-02-06 11:24:20 | Stage | Epoch[028/600] LR:0.01

2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[001/030] Train loss: 0.2269
2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[002/030] Train loss: 0.2254
2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[003/030] Train loss: 0.2273
2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[004/030] Train loss: 0.2261
2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[005/030] Train loss: 0.2264
2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[006/030] Train loss: 0.2255
2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[007/030] Train loss: 0.2260
2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[008/030] Train loss: 0.2254
2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[009/030] Train loss: 0.2253
2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[010/030] Train loss: 0.2255
2023-02-06 11:24:20 | Train | Epoch[029/600] Iteration[011/030] Train loss: 0.2254
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[012/030] Train loss: 0.2252
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[013/030] Train loss: 0.2250
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[014/030] Train loss: 0.2256
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[015/030] Train loss: 0.2256
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[016/030] Train loss: 0.2256
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[017/030] Train loss: 0.2253
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[018/030] Train loss: 0.2251
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[019/030] Train loss: 0.2251
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[020/030] Train loss: 0.2248
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[021/030] Train loss: 0.2246
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[022/030] Train loss: 0.2247
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[023/030] Train loss: 0.2246
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[024/030] Train loss: 0.2244
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[025/030] Train loss: 0.2241
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[026/030] Train loss: 0.2239
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[027/030] Train loss: 0.2237
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[028/030] Train loss: 0.2234
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[029/030] Train loss: 0.2233
2023-02-06 11:24:21 | Train | Epoch[029/600] Iteration[030/030] Train loss: 0.2230
2023-02-06 11:24:22 | Valid | Epoch[029/600] Iteration[001/008] Valid loss: 0.2626
2023-02-06 11:24:22 | Valid | Epoch[029/600] Iteration[002/008] Valid loss: 0.2557
2023-02-06 11:24:22 | Valid | Epoch[029/600] Iteration[003/008] Valid loss: 0.2533
2023-02-06 11:24:22 | Valid | Epoch[029/600] Iteration[004/008] Valid loss: 0.2543
2023-02-06 11:24:22 | Valid | Epoch[029/600] Iteration[005/008] Valid loss: 0.2557
2023-02-06 11:24:22 | Valid | Epoch[029/600] Iteration[006/008] Valid loss: 0.2548
2023-02-06 11:24:22 | Valid | Epoch[029/600] Iteration[007/008] Valid loss: 0.2576
2023-02-06 11:24:22 | Valid | Epoch[029/600] Iteration[008/008] Valid loss: 0.2572
2023-02-06 11:24:22 | Valid | Epoch[029/600] MIou: 0.9106115710304448
2023-02-06 11:24:22 | Valid | Epoch[029/600] Pixel Accuracy: 0.9831110636393229
2023-02-06 11:24:22 | Valid | Epoch[029/600] Mean Pixel Accuracy: 0.9816692674327194
2023-02-06 11:24:22 | Stage | Epoch[029/600] Train loss:0.2230
2023-02-06 11:24:22 | Stage | Epoch[029/600] Valid loss:0.2572
2023-02-06 11:24:22 | Stage | Epoch[029/600] LR:0.01

2023-02-06 11:24:22 | Train | Epoch[030/600] Iteration[001/030] Train loss: 0.2233
2023-02-06 11:24:22 | Train | Epoch[030/600] Iteration[002/030] Train loss: 0.2225
2023-02-06 11:24:22 | Train | Epoch[030/600] Iteration[003/030] Train loss: 0.2213
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[004/030] Train loss: 0.2207
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[005/030] Train loss: 0.2201
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[006/030] Train loss: 0.2197
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[007/030] Train loss: 0.2191
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[008/030] Train loss: 0.2198
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[009/030] Train loss: 0.2200
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[010/030] Train loss: 0.2199
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[011/030] Train loss: 0.2201
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[012/030] Train loss: 0.2198
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[013/030] Train loss: 0.2197
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[014/030] Train loss: 0.2194
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[015/030] Train loss: 0.2189
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[016/030] Train loss: 0.2187
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[017/030] Train loss: 0.2187
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[018/030] Train loss: 0.2186
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[019/030] Train loss: 0.2185
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[020/030] Train loss: 0.2187
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[021/030] Train loss: 0.2184
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[022/030] Train loss: 0.2182
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[023/030] Train loss: 0.2181
2023-02-06 11:24:23 | Train | Epoch[030/600] Iteration[024/030] Train loss: 0.2180
2023-02-06 11:24:24 | Train | Epoch[030/600] Iteration[025/030] Train loss: 0.2178
2023-02-06 11:24:24 | Train | Epoch[030/600] Iteration[026/030] Train loss: 0.2177
2023-02-06 11:24:24 | Train | Epoch[030/600] Iteration[027/030] Train loss: 0.2177
2023-02-06 11:24:24 | Train | Epoch[030/600] Iteration[028/030] Train loss: 0.2176
2023-02-06 11:24:24 | Train | Epoch[030/600] Iteration[029/030] Train loss: 0.2174
2023-02-06 11:24:24 | Train | Epoch[030/600] Iteration[030/030] Train loss: 0.2171
2023-02-06 11:24:24 | Valid | Epoch[030/600] Iteration[001/008] Valid loss: 0.2187
2023-02-06 11:24:24 | Valid | Epoch[030/600] Iteration[002/008] Valid loss: 0.2184
2023-02-06 11:24:24 | Valid | Epoch[030/600] Iteration[003/008] Valid loss: 0.2184
2023-02-06 11:24:24 | Valid | Epoch[030/600] Iteration[004/008] Valid loss: 0.2178
2023-02-06 11:24:24 | Valid | Epoch[030/600] Iteration[005/008] Valid loss: 0.2184
2023-02-06 11:24:24 | Valid | Epoch[030/600] Iteration[006/008] Valid loss: 0.2180
2023-02-06 11:24:24 | Valid | Epoch[030/600] Iteration[007/008] Valid loss: 0.2173
2023-02-06 11:24:24 | Valid | Epoch[030/600] Iteration[008/008] Valid loss: 0.2176
2023-02-06 11:24:24 | Valid | Epoch[030/600] MIou: 0.8334390052490924
2023-02-06 11:24:24 | Valid | Epoch[030/600] Pixel Accuracy: 0.9724515279134115
2023-02-06 11:24:24 | Valid | Epoch[030/600] Mean Pixel Accuracy: 0.8494193728577564
2023-02-06 11:24:24 | Stage | Epoch[030/600] Train loss:0.2171
2023-02-06 11:24:24 | Stage | Epoch[030/600] Valid loss:0.2176
2023-02-06 11:24:24 | Stage | Epoch[030/600] LR:0.01

2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[001/030] Train loss: 0.2109
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[002/030] Train loss: 0.2096
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[003/030] Train loss: 0.2093
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[004/030] Train loss: 0.2085
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[005/030] Train loss: 0.2088
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[006/030] Train loss: 0.2094
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[007/030] Train loss: 0.2104
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[008/030] Train loss: 0.2105
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[009/030] Train loss: 0.2113
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[010/030] Train loss: 0.2114
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[011/030] Train loss: 0.2112
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[012/030] Train loss: 0.2111
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[013/030] Train loss: 0.2111
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[014/030] Train loss: 0.2108
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[015/030] Train loss: 0.2109
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[016/030] Train loss: 0.2109
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[017/030] Train loss: 0.2107
2023-02-06 11:24:25 | Train | Epoch[031/600] Iteration[018/030] Train loss: 0.2106
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[019/030] Train loss: 0.2104
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[020/030] Train loss: 0.2102
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[021/030] Train loss: 0.2103
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[022/030] Train loss: 0.2101
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[023/030] Train loss: 0.2098
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[024/030] Train loss: 0.2096
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[025/030] Train loss: 0.2095
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[026/030] Train loss: 0.2094
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[027/030] Train loss: 0.2093
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[028/030] Train loss: 0.2091
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[029/030] Train loss: 0.2089
2023-02-06 11:24:26 | Train | Epoch[031/600] Iteration[030/030] Train loss: 0.2091
2023-02-06 11:24:26 | Valid | Epoch[031/600] Iteration[001/008] Valid loss: 0.4593
2023-02-06 11:24:26 | Valid | Epoch[031/600] Iteration[002/008] Valid loss: 0.4131
2023-02-06 11:24:26 | Valid | Epoch[031/600] Iteration[003/008] Valid loss: 0.4073
2023-02-06 11:24:26 | Valid | Epoch[031/600] Iteration[004/008] Valid loss: 0.4149
2023-02-06 11:24:26 | Valid | Epoch[031/600] Iteration[005/008] Valid loss: 0.4240
2023-02-06 11:24:27 | Valid | Epoch[031/600] Iteration[006/008] Valid loss: 0.4138
2023-02-06 11:24:27 | Valid | Epoch[031/600] Iteration[007/008] Valid loss: 0.4225
2023-02-06 11:24:27 | Valid | Epoch[031/600] Iteration[008/008] Valid loss: 0.4329
2023-02-06 11:24:27 | Valid | Epoch[031/600] MIou: 0.83441695635184
2023-02-06 11:24:27 | Valid | Epoch[031/600] Pixel Accuracy: 0.9631512959798177
2023-02-06 11:24:27 | Valid | Epoch[031/600] Mean Pixel Accuracy: 0.9777618131280104
2023-02-06 11:24:27 | Stage | Epoch[031/600] Train loss:0.2091
2023-02-06 11:24:27 | Stage | Epoch[031/600] Valid loss:0.4329
2023-02-06 11:24:27 | Stage | Epoch[031/600] LR:0.01

2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[001/030] Train loss: 0.2053
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[002/030] Train loss: 0.2054
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[003/030] Train loss: 0.2058
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[004/030] Train loss: 0.2058
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[005/030] Train loss: 0.2050
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[006/030] Train loss: 0.2049
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[007/030] Train loss: 0.2054
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[008/030] Train loss: 0.2048
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[009/030] Train loss: 0.2045
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[010/030] Train loss: 0.2041
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[011/030] Train loss: 0.2040
2023-02-06 11:24:27 | Train | Epoch[032/600] Iteration[012/030] Train loss: 0.2046
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[013/030] Train loss: 0.2042
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[014/030] Train loss: 0.2041
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[015/030] Train loss: 0.2039
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[016/030] Train loss: 0.2037
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[017/030] Train loss: 0.2036
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[018/030] Train loss: 0.2036
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[019/030] Train loss: 0.2035
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[020/030] Train loss: 0.2033
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[021/030] Train loss: 0.2033
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[022/030] Train loss: 0.2031
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[023/030] Train loss: 0.2030
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[024/030] Train loss: 0.2028
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[025/030] Train loss: 0.2027
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[026/030] Train loss: 0.2029
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[027/030] Train loss: 0.2027
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[028/030] Train loss: 0.2026
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[029/030] Train loss: 0.2025
2023-02-06 11:24:28 | Train | Epoch[032/600] Iteration[030/030] Train loss: 0.2025
2023-02-06 11:24:29 | Valid | Epoch[032/600] Iteration[001/008] Valid loss: 0.2056
2023-02-06 11:24:29 | Valid | Epoch[032/600] Iteration[002/008] Valid loss: 0.2049
2023-02-06 11:24:29 | Valid | Epoch[032/600] Iteration[003/008] Valid loss: 0.2046
2023-02-06 11:24:29 | Valid | Epoch[032/600] Iteration[004/008] Valid loss: 0.2038
2023-02-06 11:24:29 | Valid | Epoch[032/600] Iteration[005/008] Valid loss: 0.2046
2023-02-06 11:24:29 | Valid | Epoch[032/600] Iteration[006/008] Valid loss: 0.2041
2023-02-06 11:24:29 | Valid | Epoch[032/600] Iteration[007/008] Valid loss: 0.2034
2023-02-06 11:24:29 | Valid | Epoch[032/600] Iteration[008/008] Valid loss: 0.2036
2023-02-06 11:24:29 | Valid | Epoch[032/600] MIou: 0.8469899694676359
2023-02-06 11:24:29 | Valid | Epoch[032/600] Pixel Accuracy: 0.9747200012207031
2023-02-06 11:24:29 | Valid | Epoch[032/600] Mean Pixel Accuracy: 0.8615464716502195
2023-02-06 11:24:29 | Stage | Epoch[032/600] Train loss:0.2025
2023-02-06 11:24:29 | Stage | Epoch[032/600] Valid loss:0.2036
2023-02-06 11:24:29 | Stage | Epoch[032/600] LR:0.01

2023-02-06 11:24:29 | Train | Epoch[033/600] Iteration[001/030] Train loss: 0.1972
2023-02-06 11:24:29 | Train | Epoch[033/600] Iteration[002/030] Train loss: 0.1990
2023-02-06 11:24:29 | Train | Epoch[033/600] Iteration[003/030] Train loss: 0.1990
2023-02-06 11:24:29 | Train | Epoch[033/600] Iteration[004/030] Train loss: 0.1984
2023-02-06 11:24:29 | Train | Epoch[033/600] Iteration[005/030] Train loss: 0.1984
2023-02-06 11:24:29 | Train | Epoch[033/600] Iteration[006/030] Train loss: 0.1985
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[007/030] Train loss: 0.1984
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[008/030] Train loss: 0.1978
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[009/030] Train loss: 0.1979
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[010/030] Train loss: 0.1974
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[011/030] Train loss: 0.1970
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[012/030] Train loss: 0.1970
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[013/030] Train loss: 0.1969
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[014/030] Train loss: 0.1968
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[015/030] Train loss: 0.1971
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[016/030] Train loss: 0.1969
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[017/030] Train loss: 0.1968
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[018/030] Train loss: 0.1967
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[019/030] Train loss: 0.1967
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[020/030] Train loss: 0.1968
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[021/030] Train loss: 0.1969
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[022/030] Train loss: 0.1968
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[023/030] Train loss: 0.1967
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[024/030] Train loss: 0.1966
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[025/030] Train loss: 0.1965
2023-02-06 11:24:30 | Train | Epoch[033/600] Iteration[026/030] Train loss: 0.1963
2023-02-06 11:24:31 | Train | Epoch[033/600] Iteration[027/030] Train loss: 0.1962
2023-02-06 11:24:31 | Train | Epoch[033/600] Iteration[028/030] Train loss: 0.1962
2023-02-06 11:24:31 | Train | Epoch[033/600] Iteration[029/030] Train loss: 0.1960
2023-02-06 11:24:31 | Train | Epoch[033/600] Iteration[030/030] Train loss: 0.1961
2023-02-06 11:24:31 | Valid | Epoch[033/600] Iteration[001/008] Valid loss: 0.2667
2023-02-06 11:24:31 | Valid | Epoch[033/600] Iteration[002/008] Valid loss: 0.2662
2023-02-06 11:24:31 | Valid | Epoch[033/600] Iteration[003/008] Valid loss: 0.2702
2023-02-06 11:24:31 | Valid | Epoch[033/600] Iteration[004/008] Valid loss: 0.2703
2023-02-06 11:24:31 | Valid | Epoch[033/600] Iteration[005/008] Valid loss: 0.2735
2023-02-06 11:24:31 | Valid | Epoch[033/600] Iteration[006/008] Valid loss: 0.2729
2023-02-06 11:24:31 | Valid | Epoch[033/600] Iteration[007/008] Valid loss: 0.2722
2023-02-06 11:24:31 | Valid | Epoch[033/600] Iteration[008/008] Valid loss: 0.2751
2023-02-06 11:24:31 | Valid | Epoch[033/600] MIou: 0.45848242512127346
2023-02-06 11:24:31 | Valid | Epoch[033/600] Pixel Accuracy: 0.9102897644042969
2023-02-06 11:24:31 | Valid | Epoch[033/600] Mean Pixel Accuracy: 0.5033648228188486
2023-02-06 11:24:31 | Stage | Epoch[033/600] Train loss:0.1961
2023-02-06 11:24:31 | Stage | Epoch[033/600] Valid loss:0.2751
2023-02-06 11:24:31 | Stage | Epoch[033/600] LR:0.01

2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[001/030] Train loss: 0.1911
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[002/030] Train loss: 0.1943
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[003/030] Train loss: 0.1926
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[004/030] Train loss: 0.1915
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[005/030] Train loss: 0.1915
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[006/030] Train loss: 0.1927
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[007/030] Train loss: 0.1925
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[008/030] Train loss: 0.1931
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[009/030] Train loss: 0.1929
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[010/030] Train loss: 0.1925
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[011/030] Train loss: 0.1921
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[012/030] Train loss: 0.1917
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[013/030] Train loss: 0.1918
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[014/030] Train loss: 0.1919
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[015/030] Train loss: 0.1919
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[016/030] Train loss: 0.1918
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[017/030] Train loss: 0.1917
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[018/030] Train loss: 0.1917
2023-02-06 11:24:32 | Train | Epoch[034/600] Iteration[019/030] Train loss: 0.1917
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[020/030] Train loss: 0.1918
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[021/030] Train loss: 0.1915
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[022/030] Train loss: 0.1913
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[023/030] Train loss: 0.1911
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[024/030] Train loss: 0.1911
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[025/030] Train loss: 0.1908
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[026/030] Train loss: 0.1907
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[027/030] Train loss: 0.1907
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[028/030] Train loss: 0.1906
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[029/030] Train loss: 0.1904
2023-02-06 11:24:33 | Train | Epoch[034/600] Iteration[030/030] Train loss: 0.1903
2023-02-06 11:24:33 | Valid | Epoch[034/600] Iteration[001/008] Valid loss: 0.9027
2023-02-06 11:24:33 | Valid | Epoch[034/600] Iteration[002/008] Valid loss: 0.8946
2023-02-06 11:24:33 | Valid | Epoch[034/600] Iteration[003/008] Valid loss: 0.8851
2023-02-06 11:24:33 | Valid | Epoch[034/600] Iteration[004/008] Valid loss: 0.8850
2023-02-06 11:24:33 | Valid | Epoch[034/600] Iteration[005/008] Valid loss: 0.9022
2023-02-06 11:24:33 | Valid | Epoch[034/600] Iteration[006/008] Valid loss: 0.8729
2023-02-06 11:24:33 | Valid | Epoch[034/600] Iteration[007/008] Valid loss: 0.8949
2023-02-06 11:24:33 | Valid | Epoch[034/600] Iteration[008/008] Valid loss: 0.9283
2023-02-06 11:24:34 | Valid | Epoch[034/600] MIou: 0.7815342076205714
2023-02-06 11:24:34 | Valid | Epoch[034/600] Pixel Accuracy: 0.9454231262207031
2023-02-06 11:24:34 | Valid | Epoch[034/600] Mean Pixel Accuracy: 0.969469622916514
2023-02-06 11:24:34 | Stage | Epoch[034/600] Train loss:0.1903
2023-02-06 11:24:34 | Stage | Epoch[034/600] Valid loss:0.9283
2023-02-06 11:24:34 | Stage | Epoch[034/600] LR:0.01

2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[001/030] Train loss: 0.1903
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[002/030] Train loss: 0.1896
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[003/030] Train loss: 0.1886
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[004/030] Train loss: 0.1871
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[005/030] Train loss: 0.1879
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[006/030] Train loss: 0.1877
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[007/030] Train loss: 0.1877
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[008/030] Train loss: 0.1871
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[009/030] Train loss: 0.1870
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[010/030] Train loss: 0.1867
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[011/030] Train loss: 0.1868
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[012/030] Train loss: 0.1866
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[013/030] Train loss: 0.1861
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[014/030] Train loss: 0.1860
2023-02-06 11:24:34 | Train | Epoch[035/600] Iteration[015/030] Train loss: 0.1864
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[016/030] Train loss: 0.1864
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[017/030] Train loss: 0.1869
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[018/030] Train loss: 0.1866
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[019/030] Train loss: 0.1864
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[020/030] Train loss: 0.1863
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[021/030] Train loss: 0.1862
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[022/030] Train loss: 0.1861
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[023/030] Train loss: 0.1860
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[024/030] Train loss: 0.1857
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[025/030] Train loss: 0.1855
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[026/030] Train loss: 0.1853
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[027/030] Train loss: 0.1852
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[028/030] Train loss: 0.1851
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[029/030] Train loss: 0.1850
2023-02-06 11:24:35 | Train | Epoch[035/600] Iteration[030/030] Train loss: 0.1849
2023-02-06 11:24:36 | Valid | Epoch[035/600] Iteration[001/008] Valid loss: 0.2749
2023-02-06 11:24:36 | Valid | Epoch[035/600] Iteration[002/008] Valid loss: 0.2638
2023-02-06 11:24:36 | Valid | Epoch[035/600] Iteration[003/008] Valid loss: 0.2580
2023-02-06 11:24:36 | Valid | Epoch[035/600] Iteration[004/008] Valid loss: 0.2569
2023-02-06 11:24:36 | Valid | Epoch[035/600] Iteration[005/008] Valid loss: 0.2609
2023-02-06 11:24:36 | Valid | Epoch[035/600] Iteration[006/008] Valid loss: 0.2572
2023-02-06 11:24:36 | Valid | Epoch[035/600] Iteration[007/008] Valid loss: 0.2585
2023-02-06 11:24:36 | Valid | Epoch[035/600] Iteration[008/008] Valid loss: 0.2606
2023-02-06 11:24:36 | Valid | Epoch[035/600] MIou: 0.8907839686387707
2023-02-06 11:24:36 | Valid | Epoch[035/600] Pixel Accuracy: 0.9784660339355469
2023-02-06 11:24:36 | Valid | Epoch[035/600] Mean Pixel Accuracy: 0.9816586900781427
2023-02-06 11:24:36 | Stage | Epoch[035/600] Train loss:0.1849
2023-02-06 11:24:36 | Stage | Epoch[035/600] Valid loss:0.2606
2023-02-06 11:24:36 | Stage | Epoch[035/600] LR:0.01

2023-02-06 11:24:36 | Train | Epoch[036/600] Iteration[001/030] Train loss: 0.1801
2023-02-06 11:24:36 | Train | Epoch[036/600] Iteration[002/030] Train loss: 0.1816
2023-02-06 11:24:36 | Train | Epoch[036/600] Iteration[003/030] Train loss: 0.1809
2023-02-06 11:24:36 | Train | Epoch[036/600] Iteration[004/030] Train loss: 0.1811
2023-02-06 11:24:36 | Train | Epoch[036/600] Iteration[005/030] Train loss: 0.1815
2023-02-06 11:24:36 | Train | Epoch[036/600] Iteration[006/030] Train loss: 0.1818
2023-02-06 11:24:36 | Train | Epoch[036/600] Iteration[007/030] Train loss: 0.1824
2023-02-06 11:24:36 | Train | Epoch[036/600] Iteration[008/030] Train loss: 0.1822
2023-02-06 11:24:36 | Train | Epoch[036/600] Iteration[009/030] Train loss: 0.1820
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[010/030] Train loss: 0.1817
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[011/030] Train loss: 0.1818
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[012/030] Train loss: 0.1815
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[013/030] Train loss: 0.1812
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[014/030] Train loss: 0.1810
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[015/030] Train loss: 0.1806
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[016/030] Train loss: 0.1805
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[017/030] Train loss: 0.1802
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[018/030] Train loss: 0.1800
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[019/030] Train loss: 0.1802
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[020/030] Train loss: 0.1802
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[021/030] Train loss: 0.1800
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[022/030] Train loss: 0.1800
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[023/030] Train loss: 0.1798
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[024/030] Train loss: 0.1795
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[025/030] Train loss: 0.1794
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[026/030] Train loss: 0.1793
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[027/030] Train loss: 0.1792
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[028/030] Train loss: 0.1791
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[029/030] Train loss: 0.1790
2023-02-06 11:24:37 | Train | Epoch[036/600] Iteration[030/030] Train loss: 0.1788
2023-02-06 11:24:38 | Valid | Epoch[036/600] Iteration[001/008] Valid loss: 0.1983
2023-02-06 11:24:38 | Valid | Epoch[036/600] Iteration[002/008] Valid loss: 0.1928
2023-02-06 11:24:38 | Valid | Epoch[036/600] Iteration[003/008] Valid loss: 0.1909
2023-02-06 11:24:38 | Valid | Epoch[036/600] Iteration[004/008] Valid loss: 0.1902
2023-02-06 11:24:38 | Valid | Epoch[036/600] Iteration[005/008] Valid loss: 0.1918
2023-02-06 11:24:38 | Valid | Epoch[036/600] Iteration[006/008] Valid loss: 0.1909
2023-02-06 11:24:38 | Valid | Epoch[036/600] Iteration[007/008] Valid loss: 0.1917
2023-02-06 11:24:38 | Valid | Epoch[036/600] Iteration[008/008] Valid loss: 0.1916
2023-02-06 11:24:38 | Valid | Epoch[036/600] MIou: 0.926793651107575
2023-02-06 11:24:38 | Valid | Epoch[036/600] Pixel Accuracy: 0.9868888854980469
2023-02-06 11:24:38 | Valid | Epoch[036/600] Mean Pixel Accuracy: 0.9720919328072768
2023-02-06 11:24:38 | Stage | Epoch[036/600] Train loss:0.1788
2023-02-06 11:24:38 | Stage | Epoch[036/600] Valid loss:0.1916
2023-02-06 11:24:38 | Stage | Epoch[036/600] LR:0.01

2023-02-06 11:24:38 | Train | Epoch[037/600] Iteration[001/030] Train loss: 0.1746
2023-02-06 11:24:38 | Train | Epoch[037/600] Iteration[002/030] Train loss: 0.1730
2023-02-06 11:24:38 | Train | Epoch[037/600] Iteration[003/030] Train loss: 0.1725
2023-02-06 11:24:38 | Train | Epoch[037/600] Iteration[004/030] Train loss: 0.1724
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[005/030] Train loss: 0.1729
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[006/030] Train loss: 0.1745
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[007/030] Train loss: 0.1743
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[008/030] Train loss: 0.1741
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[009/030] Train loss: 0.1741
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[010/030] Train loss: 0.1741
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[011/030] Train loss: 0.1739
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[012/030] Train loss: 0.1736
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[013/030] Train loss: 0.1737
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[014/030] Train loss: 0.1738
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[015/030] Train loss: 0.1738
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[016/030] Train loss: 0.1736
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[017/030] Train loss: 0.1737
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[018/030] Train loss: 0.1735
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[019/030] Train loss: 0.1735
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[020/030] Train loss: 0.1735
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[021/030] Train loss: 0.1734
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[022/030] Train loss: 0.1734
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[023/030] Train loss: 0.1734
2023-02-06 11:24:39 | Train | Epoch[037/600] Iteration[024/030] Train loss: 0.1734
2023-02-06 11:24:40 | Train | Epoch[037/600] Iteration[025/030] Train loss: 0.1735
2023-02-06 11:24:40 | Train | Epoch[037/600] Iteration[026/030] Train loss: 0.1735
2023-02-06 11:24:40 | Train | Epoch[037/600] Iteration[027/030] Train loss: 0.1736
2023-02-06 11:24:40 | Train | Epoch[037/600] Iteration[028/030] Train loss: 0.1735
2023-02-06 11:24:40 | Train | Epoch[037/600] Iteration[029/030] Train loss: 0.1734
2023-02-06 11:24:40 | Train | Epoch[037/600] Iteration[030/030] Train loss: 0.1734
2023-02-06 11:24:40 | Valid | Epoch[037/600] Iteration[001/008] Valid loss: 0.2402
2023-02-06 11:24:40 | Valid | Epoch[037/600] Iteration[002/008] Valid loss: 0.2226
2023-02-06 11:24:40 | Valid | Epoch[037/600] Iteration[003/008] Valid loss: 0.2168
2023-02-06 11:24:40 | Valid | Epoch[037/600] Iteration[004/008] Valid loss: 0.2186
2023-02-06 11:24:40 | Valid | Epoch[037/600] Iteration[005/008] Valid loss: 0.2195
2023-02-06 11:24:40 | Valid | Epoch[037/600] Iteration[006/008] Valid loss: 0.2179
2023-02-06 11:24:40 | Valid | Epoch[037/600] Iteration[007/008] Valid loss: 0.2216
2023-02-06 11:24:40 | Valid | Epoch[037/600] Iteration[008/008] Valid loss: 0.2206
2023-02-06 11:24:40 | Valid | Epoch[037/600] MIou: 0.9129624130774483
2023-02-06 11:24:40 | Valid | Epoch[037/600] Pixel Accuracy: 0.9837252298990885
2023-02-06 11:24:40 | Valid | Epoch[037/600] Mean Pixel Accuracy: 0.97897609401987
2023-02-06 11:24:40 | Stage | Epoch[037/600] Train loss:0.1734
2023-02-06 11:24:40 | Stage | Epoch[037/600] Valid loss:0.2206
2023-02-06 11:24:40 | Stage | Epoch[037/600] LR:0.01

2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[001/030] Train loss: 0.1709
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[002/030] Train loss: 0.1721
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[003/030] Train loss: 0.1713
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[004/030] Train loss: 0.1711
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[005/030] Train loss: 0.1710
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[006/030] Train loss: 0.1722
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[007/030] Train loss: 0.1716
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[008/030] Train loss: 0.1723
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[009/030] Train loss: 0.1721
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[010/030] Train loss: 0.1718
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[011/030] Train loss: 0.1719
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[012/030] Train loss: 0.1717
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[013/030] Train loss: 0.1714
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[014/030] Train loss: 0.1711
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[015/030] Train loss: 0.1707
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[016/030] Train loss: 0.1706
2023-02-06 11:24:41 | Train | Epoch[038/600] Iteration[017/030] Train loss: 0.1705
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[018/030] Train loss: 0.1703
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[019/030] Train loss: 0.1699
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[020/030] Train loss: 0.1697
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[021/030] Train loss: 0.1694
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[022/030] Train loss: 0.1692
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[023/030] Train loss: 0.1690
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[024/030] Train loss: 0.1691
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[025/030] Train loss: 0.1688
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[026/030] Train loss: 0.1688
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[027/030] Train loss: 0.1687
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[028/030] Train loss: 0.1688
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[029/030] Train loss: 0.1686
2023-02-06 11:24:42 | Train | Epoch[038/600] Iteration[030/030] Train loss: 0.1685
2023-02-06 11:24:42 | Valid | Epoch[038/600] Iteration[001/008] Valid loss: 0.1937
2023-02-06 11:24:42 | Valid | Epoch[038/600] Iteration[002/008] Valid loss: 0.1904
2023-02-06 11:24:42 | Valid | Epoch[038/600] Iteration[003/008] Valid loss: 0.1877
2023-02-06 11:24:42 | Valid | Epoch[038/600] Iteration[004/008] Valid loss: 0.1871
2023-02-06 11:24:43 | Valid | Epoch[038/600] Iteration[005/008] Valid loss: 0.1883
2023-02-06 11:24:43 | Valid | Epoch[038/600] Iteration[006/008] Valid loss: 0.1880
2023-02-06 11:24:43 | Valid | Epoch[038/600] Iteration[007/008] Valid loss: 0.1887
2023-02-06 11:24:43 | Valid | Epoch[038/600] Iteration[008/008] Valid loss: 0.1880
2023-02-06 11:24:43 | Valid | Epoch[038/600] MIou: 0.936634594898818
2023-02-06 11:24:43 | Valid | Epoch[038/600] Pixel Accuracy: 0.9889361063639323
2023-02-06 11:24:43 | Valid | Epoch[038/600] Mean Pixel Accuracy: 0.9696538277172368
2023-02-06 11:24:43 | Stage | Epoch[038/600] Train loss:0.1685
2023-02-06 11:24:43 | Stage | Epoch[038/600] Valid loss:0.1880
2023-02-06 11:24:43 | Stage | Epoch[038/600] LR:0.01

2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[001/030] Train loss: 0.1678
2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[002/030] Train loss: 0.1656
2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[003/030] Train loss: 0.1657
2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[004/030] Train loss: 0.1651
2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[005/030] Train loss: 0.1655
2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[006/030] Train loss: 0.1649
2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[007/030] Train loss: 0.1653
2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[008/030] Train loss: 0.1659
2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[009/030] Train loss: 0.1658
2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[010/030] Train loss: 0.1659
2023-02-06 11:24:43 | Train | Epoch[039/600] Iteration[011/030] Train loss: 0.1658
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[012/030] Train loss: 0.1658
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[013/030] Train loss: 0.1656
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[014/030] Train loss: 0.1657
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[015/030] Train loss: 0.1656
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[016/030] Train loss: 0.1654
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[017/030] Train loss: 0.1652
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[018/030] Train loss: 0.1650
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[019/030] Train loss: 0.1653
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[020/030] Train loss: 0.1654
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[021/030] Train loss: 0.1654
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[022/030] Train loss: 0.1651
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[023/030] Train loss: 0.1651
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[024/030] Train loss: 0.1651
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[025/030] Train loss: 0.1649
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[026/030] Train loss: 0.1648
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[027/030] Train loss: 0.1648
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[028/030] Train loss: 0.1647
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[029/030] Train loss: 0.1645
2023-02-06 11:24:44 | Train | Epoch[039/600] Iteration[030/030] Train loss: 0.1644
2023-02-06 11:24:45 | Valid | Epoch[039/600] Iteration[001/008] Valid loss: 0.2181
2023-02-06 11:24:45 | Valid | Epoch[039/600] Iteration[002/008] Valid loss: 0.2165
2023-02-06 11:24:45 | Valid | Epoch[039/600] Iteration[003/008] Valid loss: 0.2188
2023-02-06 11:24:45 | Valid | Epoch[039/600] Iteration[004/008] Valid loss: 0.2182
2023-02-06 11:24:45 | Valid | Epoch[039/600] Iteration[005/008] Valid loss: 0.2208
2023-02-06 11:24:45 | Valid | Epoch[039/600] Iteration[006/008] Valid loss: 0.2208
2023-02-06 11:24:45 | Valid | Epoch[039/600] Iteration[007/008] Valid loss: 0.2196
2023-02-06 11:24:45 | Valid | Epoch[039/600] Iteration[008/008] Valid loss: 0.2216
2023-02-06 11:24:45 | Valid | Epoch[039/600] MIou: 0.5546375530868609
2023-02-06 11:24:45 | Valid | Epoch[039/600] Pixel Accuracy: 0.9263178507486979
2023-02-06 11:24:45 | Valid | Epoch[039/600] Mean Pixel Accuracy: 0.5921025265363589
2023-02-06 11:24:45 | Stage | Epoch[039/600] Train loss:0.1644
2023-02-06 11:24:45 | Stage | Epoch[039/600] Valid loss:0.2216
2023-02-06 11:24:45 | Stage | Epoch[039/600] LR:0.01

2023-02-06 11:24:45 | Train | Epoch[040/600] Iteration[001/030] Train loss: 0.1615
2023-02-06 11:24:45 | Train | Epoch[040/600] Iteration[002/030] Train loss: 0.1646
2023-02-06 11:24:45 | Train | Epoch[040/600] Iteration[003/030] Train loss: 0.1639
2023-02-06 11:24:45 | Train | Epoch[040/600] Iteration[004/030] Train loss: 0.1627
2023-02-06 11:24:45 | Train | Epoch[040/600] Iteration[005/030] Train loss: 0.1623
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[006/030] Train loss: 0.1626
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[007/030] Train loss: 0.1618
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[008/030] Train loss: 0.1623
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[009/030] Train loss: 0.1617
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[010/030] Train loss: 0.1615
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[011/030] Train loss: 0.1611
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[012/030] Train loss: 0.1607
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[013/030] Train loss: 0.1606
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[014/030] Train loss: 0.1603
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[015/030] Train loss: 0.1600
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[016/030] Train loss: 0.1598
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[017/030] Train loss: 0.1598
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[018/030] Train loss: 0.1597
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[019/030] Train loss: 0.1596
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[020/030] Train loss: 0.1598
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[021/030] Train loss: 0.1596
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[022/030] Train loss: 0.1595
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[023/030] Train loss: 0.1594
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[024/030] Train loss: 0.1597
2023-02-06 11:24:46 | Train | Epoch[040/600] Iteration[025/030] Train loss: 0.1595
2023-02-06 11:24:47 | Train | Epoch[040/600] Iteration[026/030] Train loss: 0.1594
2023-02-06 11:24:47 | Train | Epoch[040/600] Iteration[027/030] Train loss: 0.1593
2023-02-06 11:24:47 | Train | Epoch[040/600] Iteration[028/030] Train loss: 0.1593
2023-02-06 11:24:47 | Train | Epoch[040/600] Iteration[029/030] Train loss: 0.1594
2023-02-06 11:24:47 | Train | Epoch[040/600] Iteration[030/030] Train loss: 0.1593
2023-02-06 11:24:47 | Valid | Epoch[040/600] Iteration[001/008] Valid loss: 0.1713
2023-02-06 11:24:47 | Valid | Epoch[040/600] Iteration[002/008] Valid loss: 0.1722
2023-02-06 11:24:47 | Valid | Epoch[040/600] Iteration[003/008] Valid loss: 0.1727
2023-02-06 11:24:47 | Valid | Epoch[040/600] Iteration[004/008] Valid loss: 0.1718
2023-02-06 11:24:47 | Valid | Epoch[040/600] Iteration[005/008] Valid loss: 0.1731
2023-02-06 11:24:47 | Valid | Epoch[040/600] Iteration[006/008] Valid loss: 0.1725
2023-02-06 11:24:47 | Valid | Epoch[040/600] Iteration[007/008] Valid loss: 0.1716
2023-02-06 11:24:47 | Valid | Epoch[040/600] Iteration[008/008] Valid loss: 0.1722
2023-02-06 11:24:47 | Valid | Epoch[040/600] MIou: 0.8042863446420221
2023-02-06 11:24:47 | Valid | Epoch[040/600] Pixel Accuracy: 0.9676933288574219
2023-02-06 11:24:47 | Valid | Epoch[040/600] Mean Pixel Accuracy: 0.8218733297388052
2023-02-06 11:24:47 | Stage | Epoch[040/600] Train loss:0.1593
2023-02-06 11:24:47 | Stage | Epoch[040/600] Valid loss:0.1722
2023-02-06 11:24:47 | Stage | Epoch[040/600] LR:0.01

2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[001/030] Train loss: 0.1544
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[002/030] Train loss: 0.1552
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[003/030] Train loss: 0.1549
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[004/030] Train loss: 0.1551
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[005/030] Train loss: 0.1550
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[006/030] Train loss: 0.1552
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[007/030] Train loss: 0.1553
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[008/030] Train loss: 0.1557
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[009/030] Train loss: 0.1556
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[010/030] Train loss: 0.1556
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[011/030] Train loss: 0.1555
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[012/030] Train loss: 0.1553
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[013/030] Train loss: 0.1550
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[014/030] Train loss: 0.1549
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[015/030] Train loss: 0.1546
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[016/030] Train loss: 0.1545
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[017/030] Train loss: 0.1543
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[018/030] Train loss: 0.1543
2023-02-06 11:24:48 | Train | Epoch[041/600] Iteration[019/030] Train loss: 0.1541
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[020/030] Train loss: 0.1543
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[021/030] Train loss: 0.1542
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[022/030] Train loss: 0.1543
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[023/030] Train loss: 0.1545
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[024/030] Train loss: 0.1545
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[025/030] Train loss: 0.1545
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[026/030] Train loss: 0.1544
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[027/030] Train loss: 0.1544
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[028/030] Train loss: 0.1544
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[029/030] Train loss: 0.1543
2023-02-06 11:24:49 | Train | Epoch[041/600] Iteration[030/030] Train loss: 0.1543
2023-02-06 11:24:49 | Valid | Epoch[041/600] Iteration[001/008] Valid loss: 0.2276
2023-02-06 11:24:49 | Valid | Epoch[041/600] Iteration[002/008] Valid loss: 0.2254
2023-02-06 11:24:49 | Valid | Epoch[041/600] Iteration[003/008] Valid loss: 0.2286
2023-02-06 11:24:49 | Valid | Epoch[041/600] Iteration[004/008] Valid loss: 0.2284
2023-02-06 11:24:49 | Valid | Epoch[041/600] Iteration[005/008] Valid loss: 0.2302
2023-02-06 11:24:49 | Valid | Epoch[041/600] Iteration[006/008] Valid loss: 0.2300
2023-02-06 11:24:50 | Valid | Epoch[041/600] Iteration[007/008] Valid loss: 0.2288
2023-02-06 11:24:50 | Valid | Epoch[041/600] Iteration[008/008] Valid loss: 0.2309
2023-02-06 11:24:50 | Valid | Epoch[041/600] MIou: 0.5458650579767578
2023-02-06 11:24:50 | Valid | Epoch[041/600] Pixel Accuracy: 0.9248580932617188
2023-02-06 11:24:50 | Valid | Epoch[041/600] Mean Pixel Accuracy: 0.5840149797969844
2023-02-06 11:24:50 | Stage | Epoch[041/600] Train loss:0.1543
2023-02-06 11:24:50 | Stage | Epoch[041/600] Valid loss:0.2309
2023-02-06 11:24:50 | Stage | Epoch[041/600] LR:0.01

2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[001/030] Train loss: 0.1519
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[002/030] Train loss: 0.1503
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[003/030] Train loss: 0.1508
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[004/030] Train loss: 0.1508
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[005/030] Train loss: 0.1507
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[006/030] Train loss: 0.1508
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[007/030] Train loss: 0.1508
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[008/030] Train loss: 0.1504
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[009/030] Train loss: 0.1509
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[010/030] Train loss: 0.1513
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[011/030] Train loss: 0.1510
2023-02-06 11:24:50 | Train | Epoch[042/600] Iteration[012/030] Train loss: 0.1512
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[013/030] Train loss: 0.1509
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[014/030] Train loss: 0.1509
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[015/030] Train loss: 0.1510
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[016/030] Train loss: 0.1511
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[017/030] Train loss: 0.1511
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[018/030] Train loss: 0.1510
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[019/030] Train loss: 0.1509
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[020/030] Train loss: 0.1510
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[021/030] Train loss: 0.1508
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[022/030] Train loss: 0.1511
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[023/030] Train loss: 0.1510
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[024/030] Train loss: 0.1509
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[025/030] Train loss: 0.1510
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[026/030] Train loss: 0.1508
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[027/030] Train loss: 0.1506
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[028/030] Train loss: 0.1505
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[029/030] Train loss: 0.1505
2023-02-06 11:24:51 | Train | Epoch[042/600] Iteration[030/030] Train loss: 0.1504
2023-02-06 11:24:52 | Valid | Epoch[042/600] Iteration[001/008] Valid loss: 0.1684
2023-02-06 11:24:52 | Valid | Epoch[042/600] Iteration[002/008] Valid loss: 0.1691
2023-02-06 11:24:52 | Valid | Epoch[042/600] Iteration[003/008] Valid loss: 0.1684
2023-02-06 11:24:52 | Valid | Epoch[042/600] Iteration[004/008] Valid loss: 0.1677
2023-02-06 11:24:52 | Valid | Epoch[042/600] Iteration[005/008] Valid loss: 0.1687
2023-02-06 11:24:52 | Valid | Epoch[042/600] Iteration[006/008] Valid loss: 0.1681
2023-02-06 11:24:52 | Valid | Epoch[042/600] Iteration[007/008] Valid loss: 0.1676
2023-02-06 11:24:52 | Valid | Epoch[042/600] Iteration[008/008] Valid loss: 0.1681
2023-02-06 11:24:52 | Valid | Epoch[042/600] MIou: 0.8359239913825711
2023-02-06 11:24:52 | Valid | Epoch[042/600] Pixel Accuracy: 0.9727923075358073
2023-02-06 11:24:52 | Valid | Epoch[042/600] Mean Pixel Accuracy: 0.8526184038403625
2023-02-06 11:24:52 | Stage | Epoch[042/600] Train loss:0.1504
2023-02-06 11:24:52 | Stage | Epoch[042/600] Valid loss:0.1681
2023-02-06 11:24:52 | Stage | Epoch[042/600] LR:0.01

2023-02-06 11:24:52 | Train | Epoch[043/600] Iteration[001/030] Train loss: 0.1474
2023-02-06 11:24:52 | Train | Epoch[043/600] Iteration[002/030] Train loss: 0.1471
2023-02-06 11:24:52 | Train | Epoch[043/600] Iteration[003/030] Train loss: 0.1482
2023-02-06 11:24:52 | Train | Epoch[043/600] Iteration[004/030] Train loss: 0.1495
2023-02-06 11:24:52 | Train | Epoch[043/600] Iteration[005/030] Train loss: 0.1492
2023-02-06 11:24:52 | Train | Epoch[043/600] Iteration[006/030] Train loss: 0.1489
2023-02-06 11:24:52 | Train | Epoch[043/600] Iteration[007/030] Train loss: 0.1489
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[008/030] Train loss: 0.1487
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[009/030] Train loss: 0.1484
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[010/030] Train loss: 0.1480
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[011/030] Train loss: 0.1479
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[012/030] Train loss: 0.1480
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[013/030] Train loss: 0.1480
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[014/030] Train loss: 0.1480
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[015/030] Train loss: 0.1480
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[016/030] Train loss: 0.1477
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[017/030] Train loss: 0.1478
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[018/030] Train loss: 0.1478
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[019/030] Train loss: 0.1476
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[020/030] Train loss: 0.1473
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[021/030] Train loss: 0.1470
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[022/030] Train loss: 0.1470
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[023/030] Train loss: 0.1468
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[024/030] Train loss: 0.1467
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[025/030] Train loss: 0.1466
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[026/030] Train loss: 0.1465
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[027/030] Train loss: 0.1464
2023-02-06 11:24:53 | Train | Epoch[043/600] Iteration[028/030] Train loss: 0.1464
2023-02-06 11:24:54 | Train | Epoch[043/600] Iteration[029/030] Train loss: 0.1464
2023-02-06 11:24:54 | Train | Epoch[043/600] Iteration[030/030] Train loss: 0.1464
2023-02-06 11:24:54 | Valid | Epoch[043/600] Iteration[001/008] Valid loss: 0.1951
2023-02-06 11:24:54 | Valid | Epoch[043/600] Iteration[002/008] Valid loss: 0.1923
2023-02-06 11:24:54 | Valid | Epoch[043/600] Iteration[003/008] Valid loss: 0.1904
2023-02-06 11:24:54 | Valid | Epoch[043/600] Iteration[004/008] Valid loss: 0.1924
2023-02-06 11:24:54 | Valid | Epoch[043/600] Iteration[005/008] Valid loss: 0.1941
2023-02-06 11:24:54 | Valid | Epoch[043/600] Iteration[006/008] Valid loss: 0.1922
2023-02-06 11:24:54 | Valid | Epoch[043/600] Iteration[007/008] Valid loss: 0.1949
2023-02-06 11:24:54 | Valid | Epoch[043/600] Iteration[008/008] Valid loss: 0.1947
2023-02-06 11:24:54 | Valid | Epoch[043/600] MIou: 0.9046060566629726
2023-02-06 11:24:54 | Valid | Epoch[043/600] Pixel Accuracy: 0.981744130452474
2023-02-06 11:24:54 | Valid | Epoch[043/600] Mean Pixel Accuracy: 0.9816787992363865
2023-02-06 11:24:54 | Stage | Epoch[043/600] Train loss:0.1464
2023-02-06 11:24:54 | Stage | Epoch[043/600] Valid loss:0.1947
2023-02-06 11:24:54 | Stage | Epoch[043/600] LR:0.01

2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[001/030] Train loss: 0.1428
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[002/030] Train loss: 0.1429
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[003/030] Train loss: 0.1437
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[004/030] Train loss: 0.1438
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[005/030] Train loss: 0.1436
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[006/030] Train loss: 0.1439
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[007/030] Train loss: 0.1440
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[008/030] Train loss: 0.1439
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[009/030] Train loss: 0.1437
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[010/030] Train loss: 0.1435
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[011/030] Train loss: 0.1434
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[012/030] Train loss: 0.1432
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[013/030] Train loss: 0.1431
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[014/030] Train loss: 0.1433
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[015/030] Train loss: 0.1434
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[016/030] Train loss: 0.1432
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[017/030] Train loss: 0.1437
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[018/030] Train loss: 0.1435
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[019/030] Train loss: 0.1434
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[020/030] Train loss: 0.1436
2023-02-06 11:24:55 | Train | Epoch[044/600] Iteration[021/030] Train loss: 0.1434
2023-02-06 11:24:56 | Train | Epoch[044/600] Iteration[022/030] Train loss: 0.1433
2023-02-06 11:24:56 | Train | Epoch[044/600] Iteration[023/030] Train loss: 0.1433
2023-02-06 11:24:56 | Train | Epoch[044/600] Iteration[024/030] Train loss: 0.1431
2023-02-06 11:24:56 | Train | Epoch[044/600] Iteration[025/030] Train loss: 0.1432
2023-02-06 11:24:56 | Train | Epoch[044/600] Iteration[026/030] Train loss: 0.1431
2023-02-06 11:24:56 | Train | Epoch[044/600] Iteration[027/030] Train loss: 0.1430
2023-02-06 11:24:56 | Train | Epoch[044/600] Iteration[028/030] Train loss: 0.1429
2023-02-06 11:24:56 | Train | Epoch[044/600] Iteration[029/030] Train loss: 0.1429
2023-02-06 11:24:56 | Train | Epoch[044/600] Iteration[030/030] Train loss: 0.1428
2023-02-06 11:24:56 | Valid | Epoch[044/600] Iteration[001/008] Valid loss: 0.1821
2023-02-06 11:24:56 | Valid | Epoch[044/600] Iteration[002/008] Valid loss: 0.1707
2023-02-06 11:24:56 | Valid | Epoch[044/600] Iteration[003/008] Valid loss: 0.1680
2023-02-06 11:24:56 | Valid | Epoch[044/600] Iteration[004/008] Valid loss: 0.1693
2023-02-06 11:24:56 | Valid | Epoch[044/600] Iteration[005/008] Valid loss: 0.1708
2023-02-06 11:24:56 | Valid | Epoch[044/600] Iteration[006/008] Valid loss: 0.1692
2023-02-06 11:24:56 | Valid | Epoch[044/600] Iteration[007/008] Valid loss: 0.1723
2023-02-06 11:24:56 | Valid | Epoch[044/600] Iteration[008/008] Valid loss: 0.1710
2023-02-06 11:24:56 | Valid | Epoch[044/600] MIou: 0.9328577122538919
2023-02-06 11:24:56 | Valid | Epoch[044/600] Pixel Accuracy: 0.9879913330078125
2023-02-06 11:24:56 | Valid | Epoch[044/600] Mean Pixel Accuracy: 0.9775039623830496
2023-02-06 11:24:57 | Stage | Epoch[044/600] Train loss:0.1428
2023-02-06 11:24:57 | Stage | Epoch[044/600] Valid loss:0.1710
2023-02-06 11:24:57 | Stage | Epoch[044/600] LR:0.01

2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[001/030] Train loss: 0.1455
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[002/030] Train loss: 0.1428
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[003/030] Train loss: 0.1419
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[004/030] Train loss: 0.1417
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[005/030] Train loss: 0.1408
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[006/030] Train loss: 0.1407
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[007/030] Train loss: 0.1402
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[008/030] Train loss: 0.1406
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[009/030] Train loss: 0.1404
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[010/030] Train loss: 0.1403
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[011/030] Train loss: 0.1400
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[012/030] Train loss: 0.1397
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[013/030] Train loss: 0.1393
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[014/030] Train loss: 0.1393
2023-02-06 11:24:57 | Train | Epoch[045/600] Iteration[015/030] Train loss: 0.1395
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[016/030] Train loss: 0.1394
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[017/030] Train loss: 0.1393
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[018/030] Train loss: 0.1392
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[019/030] Train loss: 0.1391
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[020/030] Train loss: 0.1399
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[021/030] Train loss: 0.1401
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[022/030] Train loss: 0.1399
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[023/030] Train loss: 0.1398
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[024/030] Train loss: 0.1396
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[025/030] Train loss: 0.1396
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[026/030] Train loss: 0.1395
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[027/030] Train loss: 0.1395
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[028/030] Train loss: 0.1394
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[029/030] Train loss: 0.1392
2023-02-06 11:24:58 | Train | Epoch[045/600] Iteration[030/030] Train loss: 0.1393
2023-02-06 11:24:59 | Valid | Epoch[045/600] Iteration[001/008] Valid loss: 0.2393
2023-02-06 11:24:59 | Valid | Epoch[045/600] Iteration[002/008] Valid loss: 0.2417
2023-02-06 11:24:59 | Valid | Epoch[045/600] Iteration[003/008] Valid loss: 0.2477
2023-02-06 11:24:59 | Valid | Epoch[045/600] Iteration[004/008] Valid loss: 0.2474
2023-02-06 11:24:59 | Valid | Epoch[045/600] Iteration[005/008] Valid loss: 0.2514
2023-02-06 11:24:59 | Valid | Epoch[045/600] Iteration[006/008] Valid loss: 0.2499
2023-02-06 11:24:59 | Valid | Epoch[045/600] Iteration[007/008] Valid loss: 0.2491
2023-02-06 11:24:59 | Valid | Epoch[045/600] Iteration[008/008] Valid loss: 0.2534
2023-02-06 11:24:59 | Valid | Epoch[045/600] MIou: 0.46029565611080264
2023-02-06 11:24:59 | Valid | Epoch[045/600] Pixel Accuracy: 0.9105923970540365
2023-02-06 11:24:59 | Valid | Epoch[045/600] Mean Pixel Accuracy: 0.5050401948499909
2023-02-06 11:24:59 | Stage | Epoch[045/600] Train loss:0.1393
2023-02-06 11:24:59 | Stage | Epoch[045/600] Valid loss:0.2534
2023-02-06 11:24:59 | Stage | Epoch[045/600] LR:0.01

2023-02-06 11:24:59 | Train | Epoch[046/600] Iteration[001/030] Train loss: 0.1383
2023-02-06 11:24:59 | Train | Epoch[046/600] Iteration[002/030] Train loss: 0.1361
2023-02-06 11:24:59 | Train | Epoch[046/600] Iteration[003/030] Train loss: 0.1356
2023-02-06 11:24:59 | Train | Epoch[046/600] Iteration[004/030] Train loss: 0.1358
2023-02-06 11:24:59 | Train | Epoch[046/600] Iteration[005/030] Train loss: 0.1356
2023-02-06 11:24:59 | Train | Epoch[046/600] Iteration[006/030] Train loss: 0.1359
2023-02-06 11:24:59 | Train | Epoch[046/600] Iteration[007/030] Train loss: 0.1364
2023-02-06 11:24:59 | Train | Epoch[046/600] Iteration[008/030] Train loss: 0.1363
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[009/030] Train loss: 0.1365
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[010/030] Train loss: 0.1381
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[011/030] Train loss: 0.1376
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[012/030] Train loss: 0.1375
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[013/030] Train loss: 0.1371
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[014/030] Train loss: 0.1370
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[015/030] Train loss: 0.1370
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[016/030] Train loss: 0.1367
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[017/030] Train loss: 0.1365
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[018/030] Train loss: 0.1364
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[019/030] Train loss: 0.1364
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[020/030] Train loss: 0.1363
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[021/030] Train loss: 0.1362
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[022/030] Train loss: 0.1361
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[023/030] Train loss: 0.1360
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[024/030] Train loss: 0.1359
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[025/030] Train loss: 0.1358
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[026/030] Train loss: 0.1356
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[027/030] Train loss: 0.1356
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[028/030] Train loss: 0.1356
2023-02-06 11:25:00 | Train | Epoch[046/600] Iteration[029/030] Train loss: 0.1354
2023-02-06 11:25:01 | Train | Epoch[046/600] Iteration[030/030] Train loss: 0.1355
2023-02-06 11:25:01 | Valid | Epoch[046/600] Iteration[001/008] Valid loss: 0.1476
2023-02-06 11:25:01 | Valid | Epoch[046/600] Iteration[002/008] Valid loss: 0.1475
2023-02-06 11:25:01 | Valid | Epoch[046/600] Iteration[003/008] Valid loss: 0.1477
2023-02-06 11:25:01 | Valid | Epoch[046/600] Iteration[004/008] Valid loss: 0.1470
2023-02-06 11:25:01 | Valid | Epoch[046/600] Iteration[005/008] Valid loss: 0.1478
2023-02-06 11:25:01 | Valid | Epoch[046/600] Iteration[006/008] Valid loss: 0.1473
2023-02-06 11:25:01 | Valid | Epoch[046/600] Iteration[007/008] Valid loss: 0.1467
2023-02-06 11:25:01 | Valid | Epoch[046/600] Iteration[008/008] Valid loss: 0.1471
2023-02-06 11:25:01 | Valid | Epoch[046/600] MIou: 0.8445545405953234
2023-02-06 11:25:01 | Valid | Epoch[046/600] Pixel Accuracy: 0.9743639628092448
2023-02-06 11:25:01 | Valid | Epoch[046/600] Mean Pixel Accuracy: 0.8586560773619771
2023-02-06 11:25:01 | Stage | Epoch[046/600] Train loss:0.1355
2023-02-06 11:25:01 | Stage | Epoch[046/600] Valid loss:0.1471
2023-02-06 11:25:01 | Stage | Epoch[046/600] LR:0.01

2023-02-06 11:25:01 | Train | Epoch[047/600] Iteration[001/030] Train loss: 0.1381
2023-02-06 11:25:01 | Train | Epoch[047/600] Iteration[002/030] Train loss: 0.1362
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[003/030] Train loss: 0.1354
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[004/030] Train loss: 0.1362
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[005/030] Train loss: 0.1356
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[006/030] Train loss: 0.1355
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[007/030] Train loss: 0.1350
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[008/030] Train loss: 0.1351
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[009/030] Train loss: 0.1350
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[010/030] Train loss: 0.1348
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[011/030] Train loss: 0.1346
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[012/030] Train loss: 0.1341
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[013/030] Train loss: 0.1342
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[014/030] Train loss: 0.1341
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[015/030] Train loss: 0.1340
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[016/030] Train loss: 0.1339
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[017/030] Train loss: 0.1337
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[018/030] Train loss: 0.1336
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[019/030] Train loss: 0.1335
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[020/030] Train loss: 0.1336
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[021/030] Train loss: 0.1333
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[022/030] Train loss: 0.1332
2023-02-06 11:25:02 | Train | Epoch[047/600] Iteration[023/030] Train loss: 0.1331
2023-02-06 11:25:03 | Train | Epoch[047/600] Iteration[024/030] Train loss: 0.1330
2023-02-06 11:25:03 | Train | Epoch[047/600] Iteration[025/030] Train loss: 0.1332
2023-02-06 11:25:03 | Train | Epoch[047/600] Iteration[026/030] Train loss: 0.1331
2023-02-06 11:25:03 | Train | Epoch[047/600] Iteration[027/030] Train loss: 0.1330
2023-02-06 11:25:03 | Train | Epoch[047/600] Iteration[028/030] Train loss: 0.1329
2023-02-06 11:25:03 | Train | Epoch[047/600] Iteration[029/030] Train loss: 0.1327
2023-02-06 11:25:03 | Train | Epoch[047/600] Iteration[030/030] Train loss: 0.1327
2023-02-06 11:25:03 | Valid | Epoch[047/600] Iteration[001/008] Valid loss: 0.1597
2023-02-06 11:25:03 | Valid | Epoch[047/600] Iteration[002/008] Valid loss: 0.1555
2023-02-06 11:25:03 | Valid | Epoch[047/600] Iteration[003/008] Valid loss: 0.1542
2023-02-06 11:25:03 | Valid | Epoch[047/600] Iteration[004/008] Valid loss: 0.1545
2023-02-06 11:25:03 | Valid | Epoch[047/600] Iteration[005/008] Valid loss: 0.1553
2023-02-06 11:25:03 | Valid | Epoch[047/600] Iteration[006/008] Valid loss: 0.1550
2023-02-06 11:25:03 | Valid | Epoch[047/600] Iteration[007/008] Valid loss: 0.1557
2023-02-06 11:25:03 | Valid | Epoch[047/600] Iteration[008/008] Valid loss: 0.1550
2023-02-06 11:25:03 | Valid | Epoch[047/600] MIou: 0.937356209039858
2023-02-06 11:25:03 | Valid | Epoch[047/600] Pixel Accuracy: 0.9891815185546875
2023-02-06 11:25:03 | Valid | Epoch[047/600] Mean Pixel Accuracy: 0.9651601725200344
2023-02-06 11:25:03 | Stage | Epoch[047/600] Train loss:0.1327
2023-02-06 11:25:03 | Stage | Epoch[047/600] Valid loss:0.1550
2023-02-06 11:25:03 | Stage | Epoch[047/600] LR:0.01

2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[001/030] Train loss: 0.1280
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[002/030] Train loss: 0.1278
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[003/030] Train loss: 0.1288
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[004/030] Train loss: 0.1286
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[005/030] Train loss: 0.1298
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[006/030] Train loss: 0.1296
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[007/030] Train loss: 0.1293
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[008/030] Train loss: 0.1292
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[009/030] Train loss: 0.1290
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[010/030] Train loss: 0.1291
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[011/030] Train loss: 0.1289
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[012/030] Train loss: 0.1289
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[013/030] Train loss: 0.1293
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[014/030] Train loss: 0.1290
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[015/030] Train loss: 0.1292
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[016/030] Train loss: 0.1293
2023-02-06 11:25:04 | Train | Epoch[048/600] Iteration[017/030] Train loss: 0.1290
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[018/030] Train loss: 0.1291
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[019/030] Train loss: 0.1292
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[020/030] Train loss: 0.1292
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[021/030] Train loss: 0.1291
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[022/030] Train loss: 0.1289
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[023/030] Train loss: 0.1288
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[024/030] Train loss: 0.1291
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[025/030] Train loss: 0.1293
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[026/030] Train loss: 0.1292
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[027/030] Train loss: 0.1292
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[028/030] Train loss: 0.1292
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[029/030] Train loss: 0.1292
2023-02-06 11:25:05 | Train | Epoch[048/600] Iteration[030/030] Train loss: 0.1292
2023-02-06 11:25:05 | Valid | Epoch[048/600] Iteration[001/008] Valid loss: 1.4920
2023-02-06 11:25:05 | Valid | Epoch[048/600] Iteration[002/008] Valid loss: 1.5056
2023-02-06 11:25:05 | Valid | Epoch[048/600] Iteration[003/008] Valid loss: 1.5270
2023-02-06 11:25:06 | Valid | Epoch[048/600] Iteration[004/008] Valid loss: 1.5486
2023-02-06 11:25:06 | Valid | Epoch[048/600] Iteration[005/008] Valid loss: 1.5831
2023-02-06 11:25:06 | Valid | Epoch[048/600] Iteration[006/008] Valid loss: 1.5387
2023-02-06 11:25:06 | Valid | Epoch[048/600] Iteration[007/008] Valid loss: 1.5778
2023-02-06 11:25:06 | Valid | Epoch[048/600] Iteration[008/008] Valid loss: 1.6509
2023-02-06 11:25:06 | Valid | Epoch[048/600] MIou: 0.7575579777277937
2023-02-06 11:25:06 | Valid | Epoch[048/600] Pixel Accuracy: 0.9360771179199219
2023-02-06 11:25:06 | Valid | Epoch[048/600] Mean Pixel Accuracy: 0.9645228723021535
2023-02-06 11:25:06 | Stage | Epoch[048/600] Train loss:0.1292
2023-02-06 11:25:06 | Stage | Epoch[048/600] Valid loss:1.6509
2023-02-06 11:25:06 | Stage | Epoch[048/600] LR:0.01

2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[001/030] Train loss: 0.1292
2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[002/030] Train loss: 0.1300
2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[003/030] Train loss: 0.1284
2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[004/030] Train loss: 0.1279
2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[005/030] Train loss: 0.1282
2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[006/030] Train loss: 0.1286
2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[007/030] Train loss: 0.1283
2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[008/030] Train loss: 0.1277
2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[009/030] Train loss: 0.1273
2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[010/030] Train loss: 0.1277
2023-02-06 11:25:06 | Train | Epoch[049/600] Iteration[011/030] Train loss: 0.1278
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[012/030] Train loss: 0.1276
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[013/030] Train loss: 0.1275
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[014/030] Train loss: 0.1274
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[015/030] Train loss: 0.1274
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[016/030] Train loss: 0.1272
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[017/030] Train loss: 0.1271
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[018/030] Train loss: 0.1268
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[019/030] Train loss: 0.1268
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[020/030] Train loss: 0.1267
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[021/030] Train loss: 0.1267
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[022/030] Train loss: 0.1265
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[023/030] Train loss: 0.1264
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[024/030] Train loss: 0.1264
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[025/030] Train loss: 0.1263
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[026/030] Train loss: 0.1264
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[027/030] Train loss: 0.1264
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[028/030] Train loss: 0.1264
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[029/030] Train loss: 0.1263
2023-02-06 11:25:07 | Train | Epoch[049/600] Iteration[030/030] Train loss: 0.1261
2023-02-06 11:25:08 | Valid | Epoch[049/600] Iteration[001/008] Valid loss: 0.2299
2023-02-06 11:25:08 | Valid | Epoch[049/600] Iteration[002/008] Valid loss: 0.2293
2023-02-06 11:25:08 | Valid | Epoch[049/600] Iteration[003/008] Valid loss: 0.2347
2023-02-06 11:25:08 | Valid | Epoch[049/600] Iteration[004/008] Valid loss: 0.2350
2023-02-06 11:25:08 | Valid | Epoch[049/600] Iteration[005/008] Valid loss: 0.2380
2023-02-06 11:25:08 | Valid | Epoch[049/600] Iteration[006/008] Valid loss: 0.2369
2023-02-06 11:25:08 | Valid | Epoch[049/600] Iteration[007/008] Valid loss: 0.2353
2023-02-06 11:25:08 | Valid | Epoch[049/600] Iteration[008/008] Valid loss: 0.2388
2023-02-06 11:25:08 | Valid | Epoch[049/600] MIou: 0.4630689945369983
2023-02-06 11:25:08 | Valid | Epoch[049/600] Pixel Accuracy: 0.9110552469889323
2023-02-06 11:25:08 | Valid | Epoch[049/600] Mean Pixel Accuracy: 0.5076025285446789
2023-02-06 11:25:08 | Stage | Epoch[049/600] Train loss:0.1261
2023-02-06 11:25:08 | Stage | Epoch[049/600] Valid loss:0.2388
2023-02-06 11:25:08 | Stage | Epoch[049/600] LR:0.01

2023-02-06 11:25:08 | Train | Epoch[050/600] Iteration[001/030] Train loss: 0.1230
2023-02-06 11:25:08 | Train | Epoch[050/600] Iteration[002/030] Train loss: 0.1248
2023-02-06 11:25:08 | Train | Epoch[050/600] Iteration[003/030] Train loss: 0.1242
2023-02-06 11:25:08 | Train | Epoch[050/600] Iteration[004/030] Train loss: 0.1237
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[005/030] Train loss: 0.1239
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[006/030] Train loss: 0.1239
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[007/030] Train loss: 0.1240
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[008/030] Train loss: 0.1237
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[009/030] Train loss: 0.1233
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[010/030] Train loss: 0.1234
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[011/030] Train loss: 0.1230
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[012/030] Train loss: 0.1228
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[013/030] Train loss: 0.1228
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[014/030] Train loss: 0.1230
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[015/030] Train loss: 0.1228
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[016/030] Train loss: 0.1230
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[017/030] Train loss: 0.1229
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[018/030] Train loss: 0.1230
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[019/030] Train loss: 0.1229
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[020/030] Train loss: 0.1229
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[021/030] Train loss: 0.1230
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[022/030] Train loss: 0.1229
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[023/030] Train loss: 0.1228
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[024/030] Train loss: 0.1226
2023-02-06 11:25:09 | Train | Epoch[050/600] Iteration[025/030] Train loss: 0.1228
2023-02-06 11:25:10 | Train | Epoch[050/600] Iteration[026/030] Train loss: 0.1226
2023-02-06 11:25:10 | Train | Epoch[050/600] Iteration[027/030] Train loss: 0.1227
2023-02-06 11:25:10 | Train | Epoch[050/600] Iteration[028/030] Train loss: 0.1225
2023-02-06 11:25:10 | Train | Epoch[050/600] Iteration[029/030] Train loss: 0.1224
2023-02-06 11:25:10 | Train | Epoch[050/600] Iteration[030/030] Train loss: 0.1224
2023-02-06 11:25:10 | Valid | Epoch[050/600] Iteration[001/008] Valid loss: 0.2567
2023-02-06 11:25:10 | Valid | Epoch[050/600] Iteration[002/008] Valid loss: 0.2276
2023-02-06 11:25:10 | Valid | Epoch[050/600] Iteration[003/008] Valid loss: 0.2184
2023-02-06 11:25:10 | Valid | Epoch[050/600] Iteration[004/008] Valid loss: 0.2197
2023-02-06 11:25:10 | Valid | Epoch[050/600] Iteration[005/008] Valid loss: 0.2242
2023-02-06 11:25:10 | Valid | Epoch[050/600] Iteration[006/008] Valid loss: 0.2233
2023-02-06 11:25:10 | Valid | Epoch[050/600] Iteration[007/008] Valid loss: 0.2262
2023-02-06 11:25:10 | Valid | Epoch[050/600] Iteration[008/008] Valid loss: 0.2254
2023-02-06 11:25:10 | Valid | Epoch[050/600] MIou: 0.8964396618728014
2023-02-06 11:25:10 | Valid | Epoch[050/600] Pixel Accuracy: 0.9797808329264323
2023-02-06 11:25:10 | Valid | Epoch[050/600] Mean Pixel Accuracy: 0.9829076188138566
2023-02-06 11:25:10 | Stage | Epoch[050/600] Train loss:0.1224
2023-02-06 11:25:10 | Stage | Epoch[050/600] Valid loss:0.2254
2023-02-06 11:25:10 | Stage | Epoch[050/600] LR:0.01

2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[001/030] Train loss: 0.1183
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[002/030] Train loss: 0.1201
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[003/030] Train loss: 0.1192
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[004/030] Train loss: 0.1201
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[005/030] Train loss: 0.1197
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[006/030] Train loss: 0.1199
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[007/030] Train loss: 0.1195
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[008/030] Train loss: 0.1190
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[009/030] Train loss: 0.1191
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[010/030] Train loss: 0.1191
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[011/030] Train loss: 0.1192
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[012/030] Train loss: 0.1193
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[013/030] Train loss: 0.1192
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[014/030] Train loss: 0.1192
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[015/030] Train loss: 0.1191
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[016/030] Train loss: 0.1193
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[017/030] Train loss: 0.1194
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[018/030] Train loss: 0.1193
2023-02-06 11:25:11 | Train | Epoch[051/600] Iteration[019/030] Train loss: 0.1194
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[020/030] Train loss: 0.1193
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[021/030] Train loss: 0.1194
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[022/030] Train loss: 0.1195
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[023/030] Train loss: 0.1195
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[024/030] Train loss: 0.1194
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[025/030] Train loss: 0.1193
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[026/030] Train loss: 0.1194
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[027/030] Train loss: 0.1193
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[028/030] Train loss: 0.1193
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[029/030] Train loss: 0.1192
2023-02-06 11:25:12 | Train | Epoch[051/600] Iteration[030/030] Train loss: 0.1194
2023-02-06 11:25:12 | Valid | Epoch[051/600] Iteration[001/008] Valid loss: 0.1302
2023-02-06 11:25:12 | Valid | Epoch[051/600] Iteration[002/008] Valid loss: 0.1259
2023-02-06 11:25:12 | Valid | Epoch[051/600] Iteration[003/008] Valid loss: 0.1247
2023-02-06 11:25:12 | Valid | Epoch[051/600] Iteration[004/008] Valid loss: 0.1245
2023-02-06 11:25:12 | Valid | Epoch[051/600] Iteration[005/008] Valid loss: 0.1254
2023-02-06 11:25:12 | Valid | Epoch[051/600] Iteration[006/008] Valid loss: 0.1253
2023-02-06 11:25:12 | Valid | Epoch[051/600] Iteration[007/008] Valid loss: 0.1258
2023-02-06 11:25:12 | Valid | Epoch[051/600] Iteration[008/008] Valid loss: 0.1253
2023-02-06 11:25:13 | Valid | Epoch[051/600] MIou: 0.9258957616565471
2023-02-06 11:25:13 | Valid | Epoch[051/600] Pixel Accuracy: 0.987572987874349
2023-02-06 11:25:13 | Valid | Epoch[051/600] Mean Pixel Accuracy: 0.9408606941618354
2023-02-06 11:25:13 | Stage | Epoch[051/600] Train loss:0.1194
2023-02-06 11:25:13 | Stage | Epoch[051/600] Valid loss:0.1253
2023-02-06 11:25:13 | Stage | Epoch[051/600] LR:0.01

2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[001/030] Train loss: 0.1140
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[002/030] Train loss: 0.1153
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[003/030] Train loss: 0.1169
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[004/030] Train loss: 0.1175
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[005/030] Train loss: 0.1178
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[006/030] Train loss: 0.1170
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[007/030] Train loss: 0.1173
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[008/030] Train loss: 0.1173
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[009/030] Train loss: 0.1178
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[010/030] Train loss: 0.1176
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[011/030] Train loss: 0.1179
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[012/030] Train loss: 0.1177
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[013/030] Train loss: 0.1177
2023-02-06 11:25:13 | Train | Epoch[052/600] Iteration[014/030] Train loss: 0.1180
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[015/030] Train loss: 0.1179
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[016/030] Train loss: 0.1177
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[017/030] Train loss: 0.1175
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[018/030] Train loss: 0.1174
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[019/030] Train loss: 0.1171
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[020/030] Train loss: 0.1171
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[021/030] Train loss: 0.1172
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[022/030] Train loss: 0.1171
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[023/030] Train loss: 0.1169
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[024/030] Train loss: 0.1171
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[025/030] Train loss: 0.1170
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[026/030] Train loss: 0.1170
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[027/030] Train loss: 0.1169
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[028/030] Train loss: 0.1168
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[029/030] Train loss: 0.1168
2023-02-06 11:25:14 | Train | Epoch[052/600] Iteration[030/030] Train loss: 0.1167
2023-02-06 11:25:15 | Valid | Epoch[052/600] Iteration[001/008] Valid loss: 0.1845
2023-02-06 11:25:15 | Valid | Epoch[052/600] Iteration[002/008] Valid loss: 0.1728
2023-02-06 11:25:15 | Valid | Epoch[052/600] Iteration[003/008] Valid loss: 0.1672
2023-02-06 11:25:15 | Valid | Epoch[052/600] Iteration[004/008] Valid loss: 0.1666
2023-02-06 11:25:15 | Valid | Epoch[052/600] Iteration[005/008] Valid loss: 0.1679
2023-02-06 11:25:15 | Valid | Epoch[052/600] Iteration[006/008] Valid loss: 0.1669
2023-02-06 11:25:15 | Valid | Epoch[052/600] Iteration[007/008] Valid loss: 0.1683
2023-02-06 11:25:15 | Valid | Epoch[052/600] Iteration[008/008] Valid loss: 0.1680
2023-02-06 11:25:15 | Valid | Epoch[052/600] MIou: 0.923444068998583
2023-02-06 11:25:15 | Valid | Epoch[052/600] Pixel Accuracy: 0.9859390258789062
2023-02-06 11:25:15 | Valid | Epoch[052/600] Mean Pixel Accuracy: 0.9809981305885268
2023-02-06 11:25:15 | Stage | Epoch[052/600] Train loss:0.1167
2023-02-06 11:25:15 | Stage | Epoch[052/600] Valid loss:0.1680
2023-02-06 11:25:15 | Stage | Epoch[052/600] LR:0.01

2023-02-06 11:25:15 | Train | Epoch[053/600] Iteration[001/030] Train loss: 0.1098
2023-02-06 11:25:15 | Train | Epoch[053/600] Iteration[002/030] Train loss: 0.1120
2023-02-06 11:25:15 | Train | Epoch[053/600] Iteration[003/030] Train loss: 0.1138
2023-02-06 11:25:15 | Train | Epoch[053/600] Iteration[004/030] Train loss: 0.1140
2023-02-06 11:25:15 | Train | Epoch[053/600] Iteration[005/030] Train loss: 0.1145
2023-02-06 11:25:15 | Train | Epoch[053/600] Iteration[006/030] Train loss: 0.1154
2023-02-06 11:25:15 | Train | Epoch[053/600] Iteration[007/030] Train loss: 0.1155
2023-02-06 11:25:15 | Train | Epoch[053/600] Iteration[008/030] Train loss: 0.1154
2023-02-06 11:25:15 | Train | Epoch[053/600] Iteration[009/030] Train loss: 0.1155
2023-02-06 11:25:15 | Train | Epoch[053/600] Iteration[010/030] Train loss: 0.1152
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[011/030] Train loss: 0.1150
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[012/030] Train loss: 0.1146
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[013/030] Train loss: 0.1144
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[014/030] Train loss: 0.1143
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[015/030] Train loss: 0.1143
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[016/030] Train loss: 0.1142
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[017/030] Train loss: 0.1141
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[018/030] Train loss: 0.1143
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[019/030] Train loss: 0.1142
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[020/030] Train loss: 0.1141
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[021/030] Train loss: 0.1141
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[022/030] Train loss: 0.1140
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[023/030] Train loss: 0.1140
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[024/030] Train loss: 0.1143
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[025/030] Train loss: 0.1143
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[026/030] Train loss: 0.1144
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[027/030] Train loss: 0.1144
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[028/030] Train loss: 0.1144
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[029/030] Train loss: 0.1146
2023-02-06 11:25:16 | Train | Epoch[053/600] Iteration[030/030] Train loss: 0.1146
2023-02-06 11:25:17 | Valid | Epoch[053/600] Iteration[001/008] Valid loss: 0.1240
2023-02-06 11:25:17 | Valid | Epoch[053/600] Iteration[002/008] Valid loss: 0.1187
2023-02-06 11:25:17 | Valid | Epoch[053/600] Iteration[003/008] Valid loss: 0.1175
2023-02-06 11:25:17 | Valid | Epoch[053/600] Iteration[004/008] Valid loss: 0.1200
2023-02-06 11:25:17 | Valid | Epoch[053/600] Iteration[005/008] Valid loss: 0.1209
2023-02-06 11:25:17 | Valid | Epoch[053/600] Iteration[006/008] Valid loss: 0.1201
2023-02-06 11:25:17 | Valid | Epoch[053/600] Iteration[007/008] Valid loss: 0.1208
2023-02-06 11:25:17 | Valid | Epoch[053/600] Iteration[008/008] Valid loss: 0.1199
2023-02-06 11:25:17 | Valid | Epoch[053/600] MIou: 0.9307256671006799
2023-02-06 11:25:17 | Valid | Epoch[053/600] Pixel Accuracy: 0.9881515502929688
2023-02-06 11:25:17 | Valid | Epoch[053/600] Mean Pixel Accuracy: 0.9543034727722043
2023-02-06 11:25:17 | Stage | Epoch[053/600] Train loss:0.1146
2023-02-06 11:25:17 | Stage | Epoch[053/600] Valid loss:0.1199
2023-02-06 11:25:17 | Stage | Epoch[053/600] LR:0.01

2023-02-06 11:25:17 | Train | Epoch[054/600] Iteration[001/030] Train loss: 0.1151
2023-02-06 11:25:17 | Train | Epoch[054/600] Iteration[002/030] Train loss: 0.1155
2023-02-06 11:25:17 | Train | Epoch[054/600] Iteration[003/030] Train loss: 0.1149
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[004/030] Train loss: 0.1143
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[005/030] Train loss: 0.1133
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[006/030] Train loss: 0.1126
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[007/030] Train loss: 0.1122
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[008/030] Train loss: 0.1117
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[009/030] Train loss: 0.1114
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[010/030] Train loss: 0.1117
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[011/030] Train loss: 0.1119
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[012/030] Train loss: 0.1120
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[013/030] Train loss: 0.1119
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[014/030] Train loss: 0.1119
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[015/030] Train loss: 0.1118
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[016/030] Train loss: 0.1120
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[017/030] Train loss: 0.1118
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[018/030] Train loss: 0.1117
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[019/030] Train loss: 0.1115
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[020/030] Train loss: 0.1117
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[021/030] Train loss: 0.1115
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[022/030] Train loss: 0.1114
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[023/030] Train loss: 0.1115
2023-02-06 11:25:18 | Train | Epoch[054/600] Iteration[024/030] Train loss: 0.1115
2023-02-06 11:25:19 | Train | Epoch[054/600] Iteration[025/030] Train loss: 0.1115
2023-02-06 11:25:19 | Train | Epoch[054/600] Iteration[026/030] Train loss: 0.1114
2023-02-06 11:25:19 | Train | Epoch[054/600] Iteration[027/030] Train loss: 0.1113
2023-02-06 11:25:19 | Train | Epoch[054/600] Iteration[028/030] Train loss: 0.1116
2023-02-06 11:25:19 | Train | Epoch[054/600] Iteration[029/030] Train loss: 0.1115
2023-02-06 11:25:19 | Train | Epoch[054/600] Iteration[030/030] Train loss: 0.1114
2023-02-06 11:25:19 | Valid | Epoch[054/600] Iteration[001/008] Valid loss: 0.8363
2023-02-06 11:25:19 | Valid | Epoch[054/600] Iteration[002/008] Valid loss: 0.8395
2023-02-06 11:25:19 | Valid | Epoch[054/600] Iteration[003/008] Valid loss: 0.8491
2023-02-06 11:25:19 | Valid | Epoch[054/600] Iteration[004/008] Valid loss: 0.8520
2023-02-06 11:25:19 | Valid | Epoch[054/600] Iteration[005/008] Valid loss: 0.8679
2023-02-06 11:25:19 | Valid | Epoch[054/600] Iteration[006/008] Valid loss: 0.8397
2023-02-06 11:25:19 | Valid | Epoch[054/600] Iteration[007/008] Valid loss: 0.8619
2023-02-06 11:25:19 | Valid | Epoch[054/600] Iteration[008/008] Valid loss: 0.8975
2023-02-06 11:25:19 | Valid | Epoch[054/600] MIou: 0.8238583969933351
2023-02-06 11:25:19 | Valid | Epoch[054/600] Pixel Accuracy: 0.9598808288574219
2023-02-06 11:25:19 | Valid | Epoch[054/600] Mean Pixel Accuracy: 0.976642655367285
2023-02-06 11:25:19 | Stage | Epoch[054/600] Train loss:0.1114
2023-02-06 11:25:19 | Stage | Epoch[054/600] Valid loss:0.8975
2023-02-06 11:25:19 | Stage | Epoch[054/600] LR:0.01

2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[001/030] Train loss: 0.1136
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[002/030] Train loss: 0.1112
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[003/030] Train loss: 0.1105
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[004/030] Train loss: 0.1096
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[005/030] Train loss: 0.1093
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[006/030] Train loss: 0.1094
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[007/030] Train loss: 0.1093
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[008/030] Train loss: 0.1095
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[009/030] Train loss: 0.1094
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[010/030] Train loss: 0.1092
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[011/030] Train loss: 0.1095
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[012/030] Train loss: 0.1095
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[013/030] Train loss: 0.1094
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[014/030] Train loss: 0.1095
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[015/030] Train loss: 0.1094
2023-02-06 11:25:20 | Train | Epoch[055/600] Iteration[016/030] Train loss: 0.1093
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[017/030] Train loss: 0.1094
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[018/030] Train loss: 0.1095
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[019/030] Train loss: 0.1095
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[020/030] Train loss: 0.1095
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[021/030] Train loss: 0.1094
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[022/030] Train loss: 0.1092
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[023/030] Train loss: 0.1092
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[024/030] Train loss: 0.1090
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[025/030] Train loss: 0.1090
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[026/030] Train loss: 0.1091
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[027/030] Train loss: 0.1091
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[028/030] Train loss: 0.1090
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[029/030] Train loss: 0.1090
2023-02-06 11:25:21 | Train | Epoch[055/600] Iteration[030/030] Train loss: 0.1091
2023-02-06 11:25:22 | Valid | Epoch[055/600] Iteration[001/008] Valid loss: 0.1163
2023-02-06 11:25:22 | Valid | Epoch[055/600] Iteration[002/008] Valid loss: 0.1152
2023-02-06 11:25:22 | Valid | Epoch[055/600] Iteration[003/008] Valid loss: 0.1148
2023-02-06 11:25:22 | Valid | Epoch[055/600] Iteration[004/008] Valid loss: 0.1138
2023-02-06 11:25:22 | Valid | Epoch[055/600] Iteration[005/008] Valid loss: 0.1146
2023-02-06 11:25:22 | Valid | Epoch[055/600] Iteration[006/008] Valid loss: 0.1141
2023-02-06 11:25:22 | Valid | Epoch[055/600] Iteration[007/008] Valid loss: 0.1137
2023-02-06 11:25:22 | Valid | Epoch[055/600] Iteration[008/008] Valid loss: 0.1140
2023-02-06 11:25:22 | Valid | Epoch[055/600] MIou: 0.8685226175351568
2023-02-06 11:25:22 | Valid | Epoch[055/600] Pixel Accuracy: 0.9782524108886719
2023-02-06 11:25:22 | Valid | Epoch[055/600] Mean Pixel Accuracy: 0.8818500401563467
2023-02-06 11:25:22 | Stage | Epoch[055/600] Train loss:0.1091
2023-02-06 11:25:22 | Stage | Epoch[055/600] Valid loss:0.1140
2023-02-06 11:25:22 | Stage | Epoch[055/600] LR:0.01

2023-02-06 11:25:22 | Train | Epoch[056/600] Iteration[001/030] Train loss: 0.1104
2023-02-06 11:25:22 | Train | Epoch[056/600] Iteration[002/030] Train loss: 0.1081
2023-02-06 11:25:22 | Train | Epoch[056/600] Iteration[003/030] Train loss: 0.1075
2023-02-06 11:25:22 | Train | Epoch[056/600] Iteration[004/030] Train loss: 0.1076
2023-02-06 11:25:22 | Train | Epoch[056/600] Iteration[005/030] Train loss: 0.1073
2023-02-06 11:25:22 | Train | Epoch[056/600] Iteration[006/030] Train loss: 0.1073
2023-02-06 11:25:22 | Train | Epoch[056/600] Iteration[007/030] Train loss: 0.1074
2023-02-06 11:25:22 | Train | Epoch[056/600] Iteration[008/030] Train loss: 0.1072
2023-02-06 11:25:22 | Train | Epoch[056/600] Iteration[009/030] Train loss: 0.1069
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[010/030] Train loss: 0.1068
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[011/030] Train loss: 0.1066
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[012/030] Train loss: 0.1066
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[013/030] Train loss: 0.1070
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[014/030] Train loss: 0.1076
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[015/030] Train loss: 0.1076
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[016/030] Train loss: 0.1075
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[017/030] Train loss: 0.1074
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[018/030] Train loss: 0.1074
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[019/030] Train loss: 0.1077
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[020/030] Train loss: 0.1076
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[021/030] Train loss: 0.1077
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[022/030] Train loss: 0.1077
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[023/030] Train loss: 0.1077
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[024/030] Train loss: 0.1076
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[025/030] Train loss: 0.1075
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[026/030] Train loss: 0.1075
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[027/030] Train loss: 0.1074
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[028/030] Train loss: 0.1072
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[029/030] Train loss: 0.1071
2023-02-06 11:25:23 | Train | Epoch[056/600] Iteration[030/030] Train loss: 0.1071
2023-02-06 11:25:24 | Valid | Epoch[056/600] Iteration[001/008] Valid loss: 0.2270
2023-02-06 11:25:24 | Valid | Epoch[056/600] Iteration[002/008] Valid loss: 0.2193
2023-02-06 11:25:24 | Valid | Epoch[056/600] Iteration[003/008] Valid loss: 0.2069
2023-02-06 11:25:24 | Valid | Epoch[056/600] Iteration[004/008] Valid loss: 0.2021
2023-02-06 11:25:24 | Valid | Epoch[056/600] Iteration[005/008] Valid loss: 0.2091
2023-02-06 11:25:24 | Valid | Epoch[056/600] Iteration[006/008] Valid loss: 0.2024
2023-02-06 11:25:24 | Valid | Epoch[056/600] Iteration[007/008] Valid loss: 0.2042
2023-02-06 11:25:24 | Valid | Epoch[056/600] Iteration[008/008] Valid loss: 0.2074
2023-02-06 11:25:24 | Valid | Epoch[056/600] MIou: 0.899712081067497
2023-02-06 11:25:24 | Valid | Epoch[056/600] Pixel Accuracy: 0.981146494547526
2023-02-06 11:25:24 | Valid | Epoch[056/600] Mean Pixel Accuracy: 0.9676929374174522
2023-02-06 11:25:24 | Stage | Epoch[056/600] Train loss:0.1071
2023-02-06 11:25:24 | Stage | Epoch[056/600] Valid loss:0.2074
2023-02-06 11:25:24 | Stage | Epoch[056/600] LR:0.01

2023-02-06 11:25:24 | Train | Epoch[057/600] Iteration[001/030] Train loss: 0.1097
2023-02-06 11:25:24 | Train | Epoch[057/600] Iteration[002/030] Train loss: 0.1064
2023-02-06 11:25:24 | Train | Epoch[057/600] Iteration[003/030] Train loss: 0.1063
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[004/030] Train loss: 0.1057
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[005/030] Train loss: 0.1053
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[006/030] Train loss: 0.1050
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[007/030] Train loss: 0.1046
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[008/030] Train loss: 0.1052
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[009/030] Train loss: 0.1049
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[010/030] Train loss: 0.1048
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[011/030] Train loss: 0.1048
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[012/030] Train loss: 0.1047
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[013/030] Train loss: 0.1050
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[014/030] Train loss: 0.1050
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[015/030] Train loss: 0.1047
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[016/030] Train loss: 0.1047
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[017/030] Train loss: 0.1046
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[018/030] Train loss: 0.1048
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[019/030] Train loss: 0.1050
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[020/030] Train loss: 0.1048
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[021/030] Train loss: 0.1048
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[022/030] Train loss: 0.1046
2023-02-06 11:25:25 | Train | Epoch[057/600] Iteration[023/030] Train loss: 0.1046
2023-02-06 11:25:26 | Train | Epoch[057/600] Iteration[024/030] Train loss: 0.1044
2023-02-06 11:25:26 | Train | Epoch[057/600] Iteration[025/030] Train loss: 0.1044
2023-02-06 11:25:26 | Train | Epoch[057/600] Iteration[026/030] Train loss: 0.1046
2023-02-06 11:25:26 | Train | Epoch[057/600] Iteration[027/030] Train loss: 0.1046
2023-02-06 11:25:26 | Train | Epoch[057/600] Iteration[028/030] Train loss: 0.1046
2023-02-06 11:25:26 | Train | Epoch[057/600] Iteration[029/030] Train loss: 0.1045
2023-02-06 11:25:26 | Train | Epoch[057/600] Iteration[030/030] Train loss: 0.1044
2023-02-06 11:25:26 | Valid | Epoch[057/600] Iteration[001/008] Valid loss: 0.1166
2023-02-06 11:25:26 | Valid | Epoch[057/600] Iteration[002/008] Valid loss: 0.1150
2023-02-06 11:25:26 | Valid | Epoch[057/600] Iteration[003/008] Valid loss: 0.1155
2023-02-06 11:25:26 | Valid | Epoch[057/600] Iteration[004/008] Valid loss: 0.1143
2023-02-06 11:25:26 | Valid | Epoch[057/600] Iteration[005/008] Valid loss: 0.1151
2023-02-06 11:25:26 | Valid | Epoch[057/600] Iteration[006/008] Valid loss: 0.1143
2023-02-06 11:25:26 | Valid | Epoch[057/600] Iteration[007/008] Valid loss: 0.1134
2023-02-06 11:25:26 | Valid | Epoch[057/600] Iteration[008/008] Valid loss: 0.1140
2023-02-06 11:25:26 | Valid | Epoch[057/600] MIou: 0.8487192279197489
2023-02-06 11:25:26 | Valid | Epoch[057/600] Pixel Accuracy: 0.9749806722005209
2023-02-06 11:25:26 | Valid | Epoch[057/600] Mean Pixel Accuracy: 0.8635031223905305
2023-02-06 11:25:26 | Stage | Epoch[057/600] Train loss:0.1044
2023-02-06 11:25:26 | Stage | Epoch[057/600] Valid loss:0.1140
2023-02-06 11:25:26 | Stage | Epoch[057/600] LR:0.01

2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[001/030] Train loss: 0.1017
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[002/030] Train loss: 0.1026
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[003/030] Train loss: 0.1023
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[004/030] Train loss: 0.1027
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[005/030] Train loss: 0.1028
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[006/030] Train loss: 0.1027
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[007/030] Train loss: 0.1031
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[008/030] Train loss: 0.1038
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[009/030] Train loss: 0.1035
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[010/030] Train loss: 0.1034
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[011/030] Train loss: 0.1033
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[012/030] Train loss: 0.1031
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[013/030] Train loss: 0.1029
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[014/030] Train loss: 0.1027
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[015/030] Train loss: 0.1025
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[016/030] Train loss: 0.1023
2023-02-06 11:25:27 | Train | Epoch[058/600] Iteration[017/030] Train loss: 0.1023
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[018/030] Train loss: 0.1021
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[019/030] Train loss: 0.1021
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[020/030] Train loss: 0.1020
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[021/030] Train loss: 0.1019
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[022/030] Train loss: 0.1018
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[023/030] Train loss: 0.1017
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[024/030] Train loss: 0.1018
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[025/030] Train loss: 0.1018
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[026/030] Train loss: 0.1017
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[027/030] Train loss: 0.1016
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[028/030] Train loss: 0.1016
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[029/030] Train loss: 0.1016
2023-02-06 11:25:28 | Train | Epoch[058/600] Iteration[030/030] Train loss: 0.1014
2023-02-06 11:25:28 | Valid | Epoch[058/600] Iteration[001/008] Valid loss: 0.1260
2023-02-06 11:25:28 | Valid | Epoch[058/600] Iteration[002/008] Valid loss: 0.1179
2023-02-06 11:25:28 | Valid | Epoch[058/600] Iteration[003/008] Valid loss: 0.1152
2023-02-06 11:25:28 | Valid | Epoch[058/600] Iteration[004/008] Valid loss: 0.1149
2023-02-06 11:25:28 | Valid | Epoch[058/600] Iteration[005/008] Valid loss: 0.1161
2023-02-06 11:25:29 | Valid | Epoch[058/600] Iteration[006/008] Valid loss: 0.1158
2023-02-06 11:25:29 | Valid | Epoch[058/600] Iteration[007/008] Valid loss: 0.1167
2023-02-06 11:25:29 | Valid | Epoch[058/600] Iteration[008/008] Valid loss: 0.1158
2023-02-06 11:25:29 | Valid | Epoch[058/600] MIou: 0.9401099133807671
2023-02-06 11:25:29 | Valid | Epoch[058/600] Pixel Accuracy: 0.9896710713704427
2023-02-06 11:25:29 | Valid | Epoch[058/600] Mean Pixel Accuracy: 0.96717922176383
2023-02-06 11:25:29 | Stage | Epoch[058/600] Train loss:0.1014
2023-02-06 11:25:29 | Stage | Epoch[058/600] Valid loss:0.1158
2023-02-06 11:25:29 | Stage | Epoch[058/600] LR:0.01

2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[001/030] Train loss: 0.0962
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[002/030] Train loss: 0.0968
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[003/030] Train loss: 0.0985
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[004/030] Train loss: 0.0987
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[005/030] Train loss: 0.0989
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[006/030] Train loss: 0.0989
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[007/030] Train loss: 0.0994
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[008/030] Train loss: 0.0995
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[009/030] Train loss: 0.0995
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[010/030] Train loss: 0.0998
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[011/030] Train loss: 0.0998
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[012/030] Train loss: 0.0998
2023-02-06 11:25:29 | Train | Epoch[059/600] Iteration[013/030] Train loss: 0.0996
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[014/030] Train loss: 0.0995
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[015/030] Train loss: 0.0993
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[016/030] Train loss: 0.0995
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[017/030] Train loss: 0.0994
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[018/030] Train loss: 0.0998
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[019/030] Train loss: 0.0997
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[020/030] Train loss: 0.0997
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[021/030] Train loss: 0.0997
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[022/030] Train loss: 0.0996
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[023/030] Train loss: 0.0997
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[024/030] Train loss: 0.0996
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[025/030] Train loss: 0.0996
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[026/030] Train loss: 0.0998
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[027/030] Train loss: 0.0999
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[028/030] Train loss: 0.0999
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[029/030] Train loss: 0.0999
2023-02-06 11:25:30 | Train | Epoch[059/600] Iteration[030/030] Train loss: 0.0999
2023-02-06 11:25:31 | Valid | Epoch[059/600] Iteration[001/008] Valid loss: 1.2706
2023-02-06 11:25:31 | Valid | Epoch[059/600] Iteration[002/008] Valid loss: 1.2675
2023-02-06 11:25:31 | Valid | Epoch[059/600] Iteration[003/008] Valid loss: 1.3022
2023-02-06 11:25:31 | Valid | Epoch[059/600] Iteration[004/008] Valid loss: 1.3191
2023-02-06 11:25:31 | Valid | Epoch[059/600] Iteration[005/008] Valid loss: 1.3538
2023-02-06 11:25:31 | Valid | Epoch[059/600] Iteration[006/008] Valid loss: 1.3081
2023-02-06 11:25:31 | Valid | Epoch[059/600] Iteration[007/008] Valid loss: 1.3469
2023-02-06 11:25:31 | Valid | Epoch[059/600] Iteration[008/008] Valid loss: 1.4029
2023-02-06 11:25:31 | Valid | Epoch[059/600] MIou: 0.7849812549373243
2023-02-06 11:25:31 | Valid | Epoch[059/600] Pixel Accuracy: 0.9467137654622396
2023-02-06 11:25:31 | Valid | Epoch[059/600] Mean Pixel Accuracy: 0.9699253944276116
2023-02-06 11:25:31 | Stage | Epoch[059/600] Train loss:0.0999
2023-02-06 11:25:31 | Stage | Epoch[059/600] Valid loss:1.4029
2023-02-06 11:25:31 | Stage | Epoch[059/600] LR:0.01

2023-02-06 11:25:31 | Train | Epoch[060/600] Iteration[001/030] Train loss: 0.0964
2023-02-06 11:25:31 | Train | Epoch[060/600] Iteration[002/030] Train loss: 0.0967
2023-02-06 11:25:31 | Train | Epoch[060/600] Iteration[003/030] Train loss: 0.0970
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[004/030] Train loss: 0.0979
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[005/030] Train loss: 0.0992
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[006/030] Train loss: 0.0990
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[007/030] Train loss: 0.0987
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[008/030] Train loss: 0.0988
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[009/030] Train loss: 0.0988
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[010/030] Train loss: 0.0986
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[011/030] Train loss: 0.0984
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[012/030] Train loss: 0.0983
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[013/030] Train loss: 0.0982
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[014/030] Train loss: 0.0984
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[015/030] Train loss: 0.0984
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[016/030] Train loss: 0.0984
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[017/030] Train loss: 0.0985
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[018/030] Train loss: 0.0983
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[019/030] Train loss: 0.0983
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[020/030] Train loss: 0.0982
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[021/030] Train loss: 0.0983
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[022/030] Train loss: 0.0983
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[023/030] Train loss: 0.0982
2023-02-06 11:25:32 | Train | Epoch[060/600] Iteration[024/030] Train loss: 0.0982
2023-02-06 11:25:33 | Train | Epoch[060/600] Iteration[025/030] Train loss: 0.0982
2023-02-06 11:25:33 | Train | Epoch[060/600] Iteration[026/030] Train loss: 0.0982
2023-02-06 11:25:33 | Train | Epoch[060/600] Iteration[027/030] Train loss: 0.0982
2023-02-06 11:25:33 | Train | Epoch[060/600] Iteration[028/030] Train loss: 0.0982
2023-02-06 11:25:33 | Train | Epoch[060/600] Iteration[029/030] Train loss: 0.0981
2023-02-06 11:25:33 | Train | Epoch[060/600] Iteration[030/030] Train loss: 0.0981
2023-02-06 11:25:33 | Valid | Epoch[060/600] Iteration[001/008] Valid loss: 0.1417
2023-02-06 11:25:33 | Valid | Epoch[060/600] Iteration[002/008] Valid loss: 0.1414
2023-02-06 11:25:33 | Valid | Epoch[060/600] Iteration[003/008] Valid loss: 0.1444
2023-02-06 11:25:33 | Valid | Epoch[060/600] Iteration[004/008] Valid loss: 0.1433
2023-02-06 11:25:33 | Valid | Epoch[060/600] Iteration[005/008] Valid loss: 0.1460
2023-02-06 11:25:33 | Valid | Epoch[060/600] Iteration[006/008] Valid loss: 0.1450
2023-02-06 11:25:33 | Valid | Epoch[060/600] Iteration[007/008] Valid loss: 0.1431
2023-02-06 11:25:33 | Valid | Epoch[060/600] Iteration[008/008] Valid loss: 0.1455
2023-02-06 11:25:33 | Valid | Epoch[060/600] MIou: 0.6626223728295592
2023-02-06 11:25:33 | Valid | Epoch[060/600] Pixel Accuracy: 0.9442710876464844
2023-02-06 11:25:33 | Valid | Epoch[060/600] Mean Pixel Accuracy: 0.6914851680299596
2023-02-06 11:25:33 | Stage | Epoch[060/600] Train loss:0.0981
2023-02-06 11:25:33 | Stage | Epoch[060/600] Valid loss:0.1455
2023-02-06 11:25:33 | Stage | Epoch[060/600] LR:0.01

2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[001/030] Train loss: 0.0932
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[002/030] Train loss: 0.0963
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[003/030] Train loss: 0.0959
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[004/030] Train loss: 0.0968
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[005/030] Train loss: 0.0967
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[006/030] Train loss: 0.0963
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[007/030] Train loss: 0.0962
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[008/030] Train loss: 0.0966
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[009/030] Train loss: 0.0966
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[010/030] Train loss: 0.0963
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[011/030] Train loss: 0.0961
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[012/030] Train loss: 0.0960
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[013/030] Train loss: 0.0958
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[014/030] Train loss: 0.0959
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[015/030] Train loss: 0.0959
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[016/030] Train loss: 0.0958
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[017/030] Train loss: 0.0957
2023-02-06 11:25:34 | Train | Epoch[061/600] Iteration[018/030] Train loss: 0.0958
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[019/030] Train loss: 0.0957
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[020/030] Train loss: 0.0956
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[021/030] Train loss: 0.0957
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[022/030] Train loss: 0.0957
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[023/030] Train loss: 0.0957
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[024/030] Train loss: 0.0958
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[025/030] Train loss: 0.0957
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[026/030] Train loss: 0.0957
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[027/030] Train loss: 0.0956
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[028/030] Train loss: 0.0955
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[029/030] Train loss: 0.0955
2023-02-06 11:25:35 | Train | Epoch[061/600] Iteration[030/030] Train loss: 0.0954
2023-02-06 11:25:35 | Valid | Epoch[061/600] Iteration[001/008] Valid loss: 0.1364
2023-02-06 11:25:35 | Valid | Epoch[061/600] Iteration[002/008] Valid loss: 0.1367
2023-02-06 11:25:35 | Valid | Epoch[061/600] Iteration[003/008] Valid loss: 0.1388
2023-02-06 11:25:35 | Valid | Epoch[061/600] Iteration[004/008] Valid loss: 0.1374
2023-02-06 11:25:35 | Valid | Epoch[061/600] Iteration[005/008] Valid loss: 0.1392
2023-02-06 11:25:35 | Valid | Epoch[061/600] Iteration[006/008] Valid loss: 0.1380
2023-02-06 11:25:36 | Valid | Epoch[061/600] Iteration[007/008] Valid loss: 0.1362
2023-02-06 11:25:36 | Valid | Epoch[061/600] Iteration[008/008] Valid loss: 0.1385
2023-02-06 11:25:36 | Valid | Epoch[061/600] MIou: 0.6910060012009572
2023-02-06 11:25:36 | Valid | Epoch[061/600] Pixel Accuracy: 0.948980967203776
2023-02-06 11:25:36 | Valid | Epoch[061/600] Mean Pixel Accuracy: 0.7175590251868955
2023-02-06 11:25:36 | Stage | Epoch[061/600] Train loss:0.0954
2023-02-06 11:25:36 | Stage | Epoch[061/600] Valid loss:0.1385
2023-02-06 11:25:36 | Stage | Epoch[061/600] LR:0.01

2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[001/030] Train loss: 0.0906
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[002/030] Train loss: 0.0947
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[003/030] Train loss: 0.0956
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[004/030] Train loss: 0.0954
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[005/030] Train loss: 0.0952
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[006/030] Train loss: 0.0951
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[007/030] Train loss: 0.0954
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[008/030] Train loss: 0.0955
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[009/030] Train loss: 0.0956
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[010/030] Train loss: 0.0955
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[011/030] Train loss: 0.0955
2023-02-06 11:25:36 | Train | Epoch[062/600] Iteration[012/030] Train loss: 0.0959
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[013/030] Train loss: 0.0956
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[014/030] Train loss: 0.0957
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[015/030] Train loss: 0.0955
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[016/030] Train loss: 0.0955
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[017/030] Train loss: 0.0954
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[018/030] Train loss: 0.0954
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[019/030] Train loss: 0.0952
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[020/030] Train loss: 0.0951
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[021/030] Train loss: 0.0950
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[022/030] Train loss: 0.0950
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[023/030] Train loss: 0.0950
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[024/030] Train loss: 0.0949
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[025/030] Train loss: 0.0948
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[026/030] Train loss: 0.0948
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[027/030] Train loss: 0.0948
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[028/030] Train loss: 0.0948
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[029/030] Train loss: 0.0947
2023-02-06 11:25:37 | Train | Epoch[062/600] Iteration[030/030] Train loss: 0.0947
2023-02-06 11:25:38 | Valid | Epoch[062/600] Iteration[001/008] Valid loss: 0.1185
2023-02-06 11:25:38 | Valid | Epoch[062/600] Iteration[002/008] Valid loss: 0.1178
2023-02-06 11:25:38 | Valid | Epoch[062/600] Iteration[003/008] Valid loss: 0.1190
2023-02-06 11:25:38 | Valid | Epoch[062/600] Iteration[004/008] Valid loss: 0.1178
2023-02-06 11:25:38 | Valid | Epoch[062/600] Iteration[005/008] Valid loss: 0.1190
2023-02-06 11:25:38 | Valid | Epoch[062/600] Iteration[006/008] Valid loss: 0.1183
2023-02-06 11:25:38 | Valid | Epoch[062/600] Iteration[007/008] Valid loss: 0.1171
2023-02-06 11:25:38 | Valid | Epoch[062/600] Iteration[008/008] Valid loss: 0.1182
2023-02-06 11:25:38 | Valid | Epoch[062/600] MIou: 0.7896256588260415
2023-02-06 11:25:38 | Valid | Epoch[062/600] Pixel Accuracy: 0.9653155008951823
2023-02-06 11:25:38 | Valid | Epoch[062/600] Mean Pixel Accuracy: 0.8079932190703942
2023-02-06 11:25:38 | Stage | Epoch[062/600] Train loss:0.0947
2023-02-06 11:25:38 | Stage | Epoch[062/600] Valid loss:0.1182
2023-02-06 11:25:38 | Stage | Epoch[062/600] LR:0.01

2023-02-06 11:25:38 | Train | Epoch[063/600] Iteration[001/030] Train loss: 0.0919
2023-02-06 11:25:38 | Train | Epoch[063/600] Iteration[002/030] Train loss: 0.0913
2023-02-06 11:25:38 | Train | Epoch[063/600] Iteration[003/030] Train loss: 0.0914
2023-02-06 11:25:38 | Train | Epoch[063/600] Iteration[004/030] Train loss: 0.0916
2023-02-06 11:25:38 | Train | Epoch[063/600] Iteration[005/030] Train loss: 0.0912
2023-02-06 11:25:38 | Train | Epoch[063/600] Iteration[006/030] Train loss: 0.0921
2023-02-06 11:25:38 | Train | Epoch[063/600] Iteration[007/030] Train loss: 0.0920
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[008/030] Train loss: 0.0930
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[009/030] Train loss: 0.0927
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[010/030] Train loss: 0.0925
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[011/030] Train loss: 0.0924
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[012/030] Train loss: 0.0926
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[013/030] Train loss: 0.0924
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[014/030] Train loss: 0.0924
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[015/030] Train loss: 0.0923
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[016/030] Train loss: 0.0927
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[017/030] Train loss: 0.0927
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[018/030] Train loss: 0.0928
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[019/030] Train loss: 0.0926
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[020/030] Train loss: 0.0927
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[021/030] Train loss: 0.0926
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[022/030] Train loss: 0.0925
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[023/030] Train loss: 0.0925
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[024/030] Train loss: 0.0923
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[025/030] Train loss: 0.0921
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[026/030] Train loss: 0.0920
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[027/030] Train loss: 0.0921
2023-02-06 11:25:39 | Train | Epoch[063/600] Iteration[028/030] Train loss: 0.0921
2023-02-06 11:25:40 | Train | Epoch[063/600] Iteration[029/030] Train loss: 0.0921
2023-02-06 11:25:40 | Train | Epoch[063/600] Iteration[030/030] Train loss: 0.0921
2023-02-06 11:25:40 | Valid | Epoch[063/600] Iteration[001/008] Valid loss: 0.3764
2023-02-06 11:25:40 | Valid | Epoch[063/600] Iteration[002/008] Valid loss: 0.3239
2023-02-06 11:25:40 | Valid | Epoch[063/600] Iteration[003/008] Valid loss: 0.3098
2023-02-06 11:25:40 | Valid | Epoch[063/600] Iteration[004/008] Valid loss: 0.3086
2023-02-06 11:25:40 | Valid | Epoch[063/600] Iteration[005/008] Valid loss: 0.3220
2023-02-06 11:25:40 | Valid | Epoch[063/600] Iteration[006/008] Valid loss: 0.3105
2023-02-06 11:25:40 | Valid | Epoch[063/600] Iteration[007/008] Valid loss: 0.3194
2023-02-06 11:25:40 | Valid | Epoch[063/600] Iteration[008/008] Valid loss: 0.3243
2023-02-06 11:25:40 | Valid | Epoch[063/600] MIou: 0.8886489233110384
2023-02-06 11:25:40 | Valid | Epoch[063/600] Pixel Accuracy: 0.9778493245442709
2023-02-06 11:25:40 | Valid | Epoch[063/600] Mean Pixel Accuracy: 0.9837988446559012
2023-02-06 11:25:40 | Stage | Epoch[063/600] Train loss:0.0921
2023-02-06 11:25:40 | Stage | Epoch[063/600] Valid loss:0.3243
2023-02-06 11:25:40 | Stage | Epoch[063/600] LR:0.01

2023-02-06 11:25:40 | Train | Epoch[064/600] Iteration[001/030] Train loss: 0.0894
2023-02-06 11:25:40 | Train | Epoch[064/600] Iteration[002/030] Train loss: 0.0908
2023-02-06 11:25:40 | Train | Epoch[064/600] Iteration[003/030] Train loss: 0.0911
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[004/030] Train loss: 0.0910
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[005/030] Train loss: 0.0911
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[006/030] Train loss: 0.0908
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[007/030] Train loss: 0.0902
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[008/030] Train loss: 0.0905
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[009/030] Train loss: 0.0904
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[010/030] Train loss: 0.0905
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[011/030] Train loss: 0.0903
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[012/030] Train loss: 0.0902
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[013/030] Train loss: 0.0901
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[014/030] Train loss: 0.0900
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[015/030] Train loss: 0.0901
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[016/030] Train loss: 0.0902
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[017/030] Train loss: 0.0901
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[018/030] Train loss: 0.0899
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[019/030] Train loss: 0.0902
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[020/030] Train loss: 0.0901
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[021/030] Train loss: 0.0900
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[022/030] Train loss: 0.0900
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[023/030] Train loss: 0.0901
2023-02-06 11:25:41 | Train | Epoch[064/600] Iteration[024/030] Train loss: 0.0900
2023-02-06 11:25:42 | Train | Epoch[064/600] Iteration[025/030] Train loss: 0.0900
2023-02-06 11:25:42 | Train | Epoch[064/600] Iteration[026/030] Train loss: 0.0900
2023-02-06 11:25:42 | Train | Epoch[064/600] Iteration[027/030] Train loss: 0.0900
2023-02-06 11:25:42 | Train | Epoch[064/600] Iteration[028/030] Train loss: 0.0900
2023-02-06 11:25:42 | Train | Epoch[064/600] Iteration[029/030] Train loss: 0.0900
2023-02-06 11:25:42 | Train | Epoch[064/600] Iteration[030/030] Train loss: 0.0900
2023-02-06 11:25:42 | Valid | Epoch[064/600] Iteration[001/008] Valid loss: 0.3024
2023-02-06 11:25:42 | Valid | Epoch[064/600] Iteration[002/008] Valid loss: 0.2944
2023-02-06 11:25:42 | Valid | Epoch[064/600] Iteration[003/008] Valid loss: 0.2730
2023-02-06 11:25:42 | Valid | Epoch[064/600] Iteration[004/008] Valid loss: 0.2683
2023-02-06 11:25:42 | Valid | Epoch[064/600] Iteration[005/008] Valid loss: 0.2742
2023-02-06 11:25:42 | Valid | Epoch[064/600] Iteration[006/008] Valid loss: 0.2618
2023-02-06 11:25:42 | Valid | Epoch[064/600] Iteration[007/008] Valid loss: 0.2657
2023-02-06 11:25:42 | Valid | Epoch[064/600] Iteration[008/008] Valid loss: 0.2724
2023-02-06 11:25:42 | Valid | Epoch[064/600] MIou: 0.8903431175382897
2023-02-06 11:25:42 | Valid | Epoch[064/600] Pixel Accuracy: 0.9783541361490885
2023-02-06 11:25:42 | Valid | Epoch[064/600] Mean Pixel Accuracy: 0.981755698070182
2023-02-06 11:25:42 | Stage | Epoch[064/600] Train loss:0.0900
2023-02-06 11:25:42 | Stage | Epoch[064/600] Valid loss:0.2724
2023-02-06 11:25:42 | Stage | Epoch[064/600] LR:0.01

2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[001/030] Train loss: 0.0867
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[002/030] Train loss: 0.0865
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[003/030] Train loss: 0.0881
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[004/030] Train loss: 0.0885
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[005/030] Train loss: 0.0893
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[006/030] Train loss: 0.0896
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[007/030] Train loss: 0.0893
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[008/030] Train loss: 0.0887
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[009/030] Train loss: 0.0887
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[010/030] Train loss: 0.0886
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[011/030] Train loss: 0.0883
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[012/030] Train loss: 0.0884
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[013/030] Train loss: 0.0880
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[014/030] Train loss: 0.0880
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[015/030] Train loss: 0.0880
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[016/030] Train loss: 0.0881
2023-02-06 11:25:43 | Train | Epoch[065/600] Iteration[017/030] Train loss: 0.0880
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[018/030] Train loss: 0.0878
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[019/030] Train loss: 0.0879
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[020/030] Train loss: 0.0878
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[021/030] Train loss: 0.0879
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[022/030] Train loss: 0.0878
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[023/030] Train loss: 0.0882
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[024/030] Train loss: 0.0881
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[025/030] Train loss: 0.0882
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[026/030] Train loss: 0.0882
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[027/030] Train loss: 0.0881
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[028/030] Train loss: 0.0882
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[029/030] Train loss: 0.0883
2023-02-06 11:25:44 | Train | Epoch[065/600] Iteration[030/030] Train loss: 0.0884
2023-02-06 11:25:44 | Valid | Epoch[065/600] Iteration[001/008] Valid loss: 0.3705
2023-02-06 11:25:44 | Valid | Epoch[065/600] Iteration[002/008] Valid loss: 0.3097
2023-02-06 11:25:44 | Valid | Epoch[065/600] Iteration[003/008] Valid loss: 0.2983
2023-02-06 11:25:45 | Valid | Epoch[065/600] Iteration[004/008] Valid loss: 0.2962
2023-02-06 11:25:45 | Valid | Epoch[065/600] Iteration[005/008] Valid loss: 0.3085
2023-02-06 11:25:45 | Valid | Epoch[065/600] Iteration[006/008] Valid loss: 0.2973
2023-02-06 11:25:45 | Valid | Epoch[065/600] Iteration[007/008] Valid loss: 0.3116
2023-02-06 11:25:45 | Valid | Epoch[065/600] Iteration[008/008] Valid loss: 0.3124
2023-02-06 11:25:45 | Valid | Epoch[065/600] MIou: 0.8853042603566343
2023-02-06 11:25:45 | Valid | Epoch[065/600] Pixel Accuracy: 0.9770533243815104
2023-02-06 11:25:45 | Valid | Epoch[065/600] Mean Pixel Accuracy: 0.9829682197841132
2023-02-06 11:25:45 | Stage | Epoch[065/600] Train loss:0.0884
2023-02-06 11:25:45 | Stage | Epoch[065/600] Valid loss:0.3124
2023-02-06 11:25:45 | Stage | Epoch[065/600] LR:0.01

2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[001/030] Train loss: 0.0878
2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[002/030] Train loss: 0.0862
2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[003/030] Train loss: 0.0868
2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[004/030] Train loss: 0.0876
2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[005/030] Train loss: 0.0876
2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[006/030] Train loss: 0.0875
2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[007/030] Train loss: 0.0875
2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[008/030] Train loss: 0.0875
2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[009/030] Train loss: 0.0876
2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[010/030] Train loss: 0.0877
2023-02-06 11:25:45 | Train | Epoch[066/600] Iteration[011/030] Train loss: 0.0873
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[012/030] Train loss: 0.0871
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[013/030] Train loss: 0.0870
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[014/030] Train loss: 0.0870
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[015/030] Train loss: 0.0869
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[016/030] Train loss: 0.0872
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[017/030] Train loss: 0.0873
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[018/030] Train loss: 0.0872
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[019/030] Train loss: 0.0872
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[020/030] Train loss: 0.0873
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[021/030] Train loss: 0.0871
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[022/030] Train loss: 0.0872
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[023/030] Train loss: 0.0872
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[024/030] Train loss: 0.0870
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[025/030] Train loss: 0.0869
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[026/030] Train loss: 0.0868
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[027/030] Train loss: 0.0867
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[028/030] Train loss: 0.0868
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[029/030] Train loss: 0.0868
2023-02-06 11:25:46 | Train | Epoch[066/600] Iteration[030/030] Train loss: 0.0868
2023-02-06 11:25:47 | Valid | Epoch[066/600] Iteration[001/008] Valid loss: 0.2278
2023-02-06 11:25:47 | Valid | Epoch[066/600] Iteration[002/008] Valid loss: 0.1846
2023-02-06 11:25:47 | Valid | Epoch[066/600] Iteration[003/008] Valid loss: 0.1757
2023-02-06 11:25:47 | Valid | Epoch[066/600] Iteration[004/008] Valid loss: 0.1776
2023-02-06 11:25:47 | Valid | Epoch[066/600] Iteration[005/008] Valid loss: 0.1829
2023-02-06 11:25:47 | Valid | Epoch[066/600] Iteration[006/008] Valid loss: 0.1794
2023-02-06 11:25:47 | Valid | Epoch[066/600] Iteration[007/008] Valid loss: 0.1862
2023-02-06 11:25:47 | Valid | Epoch[066/600] Iteration[008/008] Valid loss: 0.1840
2023-02-06 11:25:47 | Valid | Epoch[066/600] MIou: 0.9115648166363182
2023-02-06 11:25:47 | Valid | Epoch[066/600] Pixel Accuracy: 0.9832534790039062
2023-02-06 11:25:47 | Valid | Epoch[066/600] Mean Pixel Accuracy: 0.9838081982323887
2023-02-06 11:25:47 | Stage | Epoch[066/600] Train loss:0.0868
2023-02-06 11:25:47 | Stage | Epoch[066/600] Valid loss:0.1840
2023-02-06 11:25:47 | Stage | Epoch[066/600] LR:0.01

2023-02-06 11:25:47 | Train | Epoch[067/600] Iteration[001/030] Train loss: 0.0856
2023-02-06 11:25:47 | Train | Epoch[067/600] Iteration[002/030] Train loss: 0.0852
2023-02-06 11:25:47 | Train | Epoch[067/600] Iteration[003/030] Train loss: 0.0851
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[004/030] Train loss: 0.0848
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[005/030] Train loss: 0.0846
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[006/030] Train loss: 0.0852
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[007/030] Train loss: 0.0859
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[008/030] Train loss: 0.0857
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[009/030] Train loss: 0.0857
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[010/030] Train loss: 0.0858
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[011/030] Train loss: 0.0856
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[012/030] Train loss: 0.0858
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[013/030] Train loss: 0.0860
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[014/030] Train loss: 0.0860
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[015/030] Train loss: 0.0862
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[016/030] Train loss: 0.0865
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[017/030] Train loss: 0.0865
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[018/030] Train loss: 0.0866
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[019/030] Train loss: 0.0867
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[020/030] Train loss: 0.0865
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[021/030] Train loss: 0.0864
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[022/030] Train loss: 0.0863
2023-02-06 11:25:48 | Train | Epoch[067/600] Iteration[023/030] Train loss: 0.0862
2023-02-06 11:25:49 | Train | Epoch[067/600] Iteration[024/030] Train loss: 0.0861
2023-02-06 11:25:49 | Train | Epoch[067/600] Iteration[025/030] Train loss: 0.0860
2023-02-06 11:25:49 | Train | Epoch[067/600] Iteration[026/030] Train loss: 0.0860
2023-02-06 11:25:49 | Train | Epoch[067/600] Iteration[027/030] Train loss: 0.0860
2023-02-06 11:25:49 | Train | Epoch[067/600] Iteration[028/030] Train loss: 0.0860
2023-02-06 11:25:49 | Train | Epoch[067/600] Iteration[029/030] Train loss: 0.0859
2023-02-06 11:25:49 | Train | Epoch[067/600] Iteration[030/030] Train loss: 0.0860
2023-02-06 11:25:49 | Valid | Epoch[067/600] Iteration[001/008] Valid loss: 0.0955
2023-02-06 11:25:49 | Valid | Epoch[067/600] Iteration[002/008] Valid loss: 0.0932
2023-02-06 11:25:49 | Valid | Epoch[067/600] Iteration[003/008] Valid loss: 0.0928
2023-02-06 11:25:49 | Valid | Epoch[067/600] Iteration[004/008] Valid loss: 0.0916
2023-02-06 11:25:49 | Valid | Epoch[067/600] Iteration[005/008] Valid loss: 0.0923
2023-02-06 11:25:49 | Valid | Epoch[067/600] Iteration[006/008] Valid loss: 0.0919
2023-02-06 11:25:49 | Valid | Epoch[067/600] Iteration[007/008] Valid loss: 0.0911
2023-02-06 11:25:49 | Valid | Epoch[067/600] Iteration[008/008] Valid loss: 0.0915
2023-02-06 11:25:49 | Valid | Epoch[067/600] MIou: 0.8750406941161215
2023-02-06 11:25:49 | Valid | Epoch[067/600] Pixel Accuracy: 0.9792709350585938
2023-02-06 11:25:49 | Valid | Epoch[067/600] Mean Pixel Accuracy: 0.8889849334371678
2023-02-06 11:25:49 | Stage | Epoch[067/600] Train loss:0.0860
2023-02-06 11:25:49 | Stage | Epoch[067/600] Valid loss:0.0915
2023-02-06 11:25:49 | Stage | Epoch[067/600] LR:0.01

2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[001/030] Train loss: 0.0844
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[002/030] Train loss: 0.0849
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[003/030] Train loss: 0.0846
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[004/030] Train loss: 0.0849
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[005/030] Train loss: 0.0847
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[006/030] Train loss: 0.0850
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[007/030] Train loss: 0.0861
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[008/030] Train loss: 0.0858
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[009/030] Train loss: 0.0861
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[010/030] Train loss: 0.0861
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[011/030] Train loss: 0.0859
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[012/030] Train loss: 0.0861
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[013/030] Train loss: 0.0860
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[014/030] Train loss: 0.0860
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[015/030] Train loss: 0.0862
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[016/030] Train loss: 0.0864
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[017/030] Train loss: 0.0864
2023-02-06 11:25:50 | Train | Epoch[068/600] Iteration[018/030] Train loss: 0.0861
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[019/030] Train loss: 0.0862
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[020/030] Train loss: 0.0863
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[021/030] Train loss: 0.0861
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[022/030] Train loss: 0.0860
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[023/030] Train loss: 0.0860
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[024/030] Train loss: 0.0860
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[025/030] Train loss: 0.0859
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[026/030] Train loss: 0.0859
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[027/030] Train loss: 0.0857
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[028/030] Train loss: 0.0856
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[029/030] Train loss: 0.0856
2023-02-06 11:25:51 | Train | Epoch[068/600] Iteration[030/030] Train loss: 0.0856
2023-02-06 11:25:51 | Valid | Epoch[068/600] Iteration[001/008] Valid loss: 0.0994
2023-02-06 11:25:51 | Valid | Epoch[068/600] Iteration[002/008] Valid loss: 0.0949
2023-02-06 11:25:51 | Valid | Epoch[068/600] Iteration[003/008] Valid loss: 0.0945
2023-02-06 11:25:51 | Valid | Epoch[068/600] Iteration[004/008] Valid loss: 0.0927
2023-02-06 11:25:52 | Valid | Epoch[068/600] Iteration[005/008] Valid loss: 0.0939
2023-02-06 11:25:52 | Valid | Epoch[068/600] Iteration[006/008] Valid loss: 0.0929
2023-02-06 11:25:52 | Valid | Epoch[068/600] Iteration[007/008] Valid loss: 0.0920
2023-02-06 11:25:52 | Valid | Epoch[068/600] Iteration[008/008] Valid loss: 0.0926
2023-02-06 11:25:52 | Valid | Epoch[068/600] MIou: 0.8610419354213749
2023-02-06 11:25:52 | Valid | Epoch[068/600] Pixel Accuracy: 0.9767786661783854
2023-02-06 11:25:52 | Valid | Epoch[068/600] Mean Pixel Accuracy: 0.8787827993515813
2023-02-06 11:25:52 | Stage | Epoch[068/600] Train loss:0.0856
2023-02-06 11:25:52 | Stage | Epoch[068/600] Valid loss:0.0926
2023-02-06 11:25:52 | Stage | Epoch[068/600] LR:0.01

2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[001/030] Train loss: 0.0868
2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[002/030] Train loss: 0.0855
2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[003/030] Train loss: 0.0862
2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[004/030] Train loss: 0.0859
2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[005/030] Train loss: 0.0855
2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[006/030] Train loss: 0.0847
2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[007/030] Train loss: 0.0844
2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[008/030] Train loss: 0.0839
2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[009/030] Train loss: 0.0837
2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[010/030] Train loss: 0.0836
2023-02-06 11:25:52 | Train | Epoch[069/600] Iteration[011/030] Train loss: 0.0834
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[012/030] Train loss: 0.0833
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[013/030] Train loss: 0.0832
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[014/030] Train loss: 0.0833
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[015/030] Train loss: 0.0831
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[016/030] Train loss: 0.0830
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[017/030] Train loss: 0.0830
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[018/030] Train loss: 0.0830
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[019/030] Train loss: 0.0830
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[020/030] Train loss: 0.0833
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[021/030] Train loss: 0.0832
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[022/030] Train loss: 0.0830
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[023/030] Train loss: 0.0830
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[024/030] Train loss: 0.0829
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[025/030] Train loss: 0.0828
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[026/030] Train loss: 0.0827
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[027/030] Train loss: 0.0827
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[028/030] Train loss: 0.0827
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[029/030] Train loss: 0.0825
2023-02-06 11:25:53 | Train | Epoch[069/600] Iteration[030/030] Train loss: 0.0825
2023-02-06 11:25:54 | Valid | Epoch[069/600] Iteration[001/008] Valid loss: 0.1027
2023-02-06 11:25:54 | Valid | Epoch[069/600] Iteration[002/008] Valid loss: 0.0944
2023-02-06 11:25:54 | Valid | Epoch[069/600] Iteration[003/008] Valid loss: 0.0927
2023-02-06 11:25:54 | Valid | Epoch[069/600] Iteration[004/008] Valid loss: 0.0927
2023-02-06 11:25:54 | Valid | Epoch[069/600] Iteration[005/008] Valid loss: 0.0939
2023-02-06 11:25:54 | Valid | Epoch[069/600] Iteration[006/008] Valid loss: 0.0937
2023-02-06 11:25:54 | Valid | Epoch[069/600] Iteration[007/008] Valid loss: 0.0946
2023-02-06 11:25:54 | Valid | Epoch[069/600] Iteration[008/008] Valid loss: 0.0934
2023-02-06 11:25:54 | Valid | Epoch[069/600] MIou: 0.9425758687052044
2023-02-06 11:25:54 | Valid | Epoch[069/600] Pixel Accuracy: 0.990264892578125
2023-02-06 11:25:54 | Valid | Epoch[069/600] Mean Pixel Accuracy: 0.9615011847034947
2023-02-06 11:25:54 | Stage | Epoch[069/600] Train loss:0.0825
2023-02-06 11:25:54 | Stage | Epoch[069/600] Valid loss:0.0934
2023-02-06 11:25:54 | Stage | Epoch[069/600] LR:0.01

2023-02-06 11:25:54 | Train | Epoch[070/600] Iteration[001/030] Train loss: 0.0805
2023-02-06 11:25:54 | Train | Epoch[070/600] Iteration[002/030] Train loss: 0.0833
2023-02-06 11:25:54 | Train | Epoch[070/600] Iteration[003/030] Train loss: 0.0826
2023-02-06 11:25:54 | Train | Epoch[070/600] Iteration[004/030] Train loss: 0.0818
2023-02-06 11:25:54 | Train | Epoch[070/600] Iteration[005/030] Train loss: 0.0813
2023-02-06 11:25:54 | Train | Epoch[070/600] Iteration[006/030] Train loss: 0.0809
2023-02-06 11:25:54 | Train | Epoch[070/600] Iteration[007/030] Train loss: 0.0815
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[008/030] Train loss: 0.0812
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[009/030] Train loss: 0.0809
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[010/030] Train loss: 0.0809
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[011/030] Train loss: 0.0807
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[012/030] Train loss: 0.0806
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[013/030] Train loss: 0.0805
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[014/030] Train loss: 0.0804
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[015/030] Train loss: 0.0803
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[016/030] Train loss: 0.0803
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[017/030] Train loss: 0.0802
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[018/030] Train loss: 0.0802
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[019/030] Train loss: 0.0802
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[020/030] Train loss: 0.0802
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[021/030] Train loss: 0.0805
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[022/030] Train loss: 0.0805
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[023/030] Train loss: 0.0805
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[024/030] Train loss: 0.0806
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[025/030] Train loss: 0.0807
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[026/030] Train loss: 0.0807
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[027/030] Train loss: 0.0806
2023-02-06 11:25:55 | Train | Epoch[070/600] Iteration[028/030] Train loss: 0.0807
2023-02-06 11:25:56 | Train | Epoch[070/600] Iteration[029/030] Train loss: 0.0807
2023-02-06 11:25:56 | Train | Epoch[070/600] Iteration[030/030] Train loss: 0.0806
2023-02-06 11:25:56 | Valid | Epoch[070/600] Iteration[001/008] Valid loss: 0.1488
2023-02-06 11:25:56 | Valid | Epoch[070/600] Iteration[002/008] Valid loss: 0.1503
2023-02-06 11:25:56 | Valid | Epoch[070/600] Iteration[003/008] Valid loss: 0.1559
2023-02-06 11:25:56 | Valid | Epoch[070/600] Iteration[004/008] Valid loss: 0.1537
2023-02-06 11:25:56 | Valid | Epoch[070/600] Iteration[005/008] Valid loss: 0.1574
2023-02-06 11:25:56 | Valid | Epoch[070/600] Iteration[006/008] Valid loss: 0.1563
2023-02-06 11:25:56 | Valid | Epoch[070/600] Iteration[007/008] Valid loss: 0.1544
2023-02-06 11:25:56 | Valid | Epoch[070/600] Iteration[008/008] Valid loss: 0.1587
2023-02-06 11:25:56 | Valid | Epoch[070/600] MIou: 0.5567627739223832
2023-02-06 11:25:56 | Valid | Epoch[070/600] Pixel Accuracy: 0.926672617594401
2023-02-06 11:25:56 | Valid | Epoch[070/600] Mean Pixel Accuracy: 0.5940601726055554
2023-02-06 11:25:56 | Stage | Epoch[070/600] Train loss:0.0806
2023-02-06 11:25:56 | Stage | Epoch[070/600] Valid loss:0.1587
2023-02-06 11:25:56 | Stage | Epoch[070/600] LR:0.01

2023-02-06 11:25:56 | Train | Epoch[071/600] Iteration[001/030] Train loss: 0.0793
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[002/030] Train loss: 0.0805
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[003/030] Train loss: 0.0802
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[004/030] Train loss: 0.0801
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[005/030] Train loss: 0.0796
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[006/030] Train loss: 0.0797
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[007/030] Train loss: 0.0795
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[008/030] Train loss: 0.0792
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[009/030] Train loss: 0.0792
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[010/030] Train loss: 0.0792
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[011/030] Train loss: 0.0791
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[012/030] Train loss: 0.0789
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[013/030] Train loss: 0.0788
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[014/030] Train loss: 0.0789
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[015/030] Train loss: 0.0787
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[016/030] Train loss: 0.0786
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[017/030] Train loss: 0.0786
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[018/030] Train loss: 0.0785
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[019/030] Train loss: 0.0785
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[020/030] Train loss: 0.0784
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[021/030] Train loss: 0.0785
2023-02-06 11:25:57 | Train | Epoch[071/600] Iteration[022/030] Train loss: 0.0784
2023-02-06 11:25:58 | Train | Epoch[071/600] Iteration[023/030] Train loss: 0.0786
2023-02-06 11:25:58 | Train | Epoch[071/600] Iteration[024/030] Train loss: 0.0786
2023-02-06 11:25:58 | Train | Epoch[071/600] Iteration[025/030] Train loss: 0.0788
2023-02-06 11:25:58 | Train | Epoch[071/600] Iteration[026/030] Train loss: 0.0789
2023-02-06 11:25:58 | Train | Epoch[071/600] Iteration[027/030] Train loss: 0.0788
2023-02-06 11:25:58 | Train | Epoch[071/600] Iteration[028/030] Train loss: 0.0787
2023-02-06 11:25:58 | Train | Epoch[071/600] Iteration[029/030] Train loss: 0.0786
2023-02-06 11:25:58 | Train | Epoch[071/600] Iteration[030/030] Train loss: 0.0787
2023-02-06 11:25:58 | Valid | Epoch[071/600] Iteration[001/008] Valid loss: 0.1206
2023-02-06 11:25:58 | Valid | Epoch[071/600] Iteration[002/008] Valid loss: 0.1153
2023-02-06 11:25:58 | Valid | Epoch[071/600] Iteration[003/008] Valid loss: 0.1112
2023-02-06 11:25:58 | Valid | Epoch[071/600] Iteration[004/008] Valid loss: 0.1083
2023-02-06 11:25:58 | Valid | Epoch[071/600] Iteration[005/008] Valid loss: 0.1118
2023-02-06 11:25:58 | Valid | Epoch[071/600] Iteration[006/008] Valid loss: 0.1089
2023-02-06 11:25:58 | Valid | Epoch[071/600] Iteration[007/008] Valid loss: 0.1083
2023-02-06 11:25:58 | Valid | Epoch[071/600] Iteration[008/008] Valid loss: 0.1095
2023-02-06 11:25:58 | Valid | Epoch[071/600] MIou: 0.9036208870394505
2023-02-06 11:25:58 | Valid | Epoch[071/600] Pixel Accuracy: 0.9831352233886719
2023-02-06 11:25:58 | Valid | Epoch[071/600] Mean Pixel Accuracy: 0.938383466705357
2023-02-06 11:25:58 | Stage | Epoch[071/600] Train loss:0.0787
2023-02-06 11:25:58 | Stage | Epoch[071/600] Valid loss:0.1095
2023-02-06 11:25:58 | Stage | Epoch[071/600] LR:0.01

2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[001/030] Train loss: 0.0732
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[002/030] Train loss: 0.0749
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[003/030] Train loss: 0.0750
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[004/030] Train loss: 0.0759
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[005/030] Train loss: 0.0762
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[006/030] Train loss: 0.0764
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[007/030] Train loss: 0.0775
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[008/030] Train loss: 0.0774
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[009/030] Train loss: 0.0776
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[010/030] Train loss: 0.0776
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[011/030] Train loss: 0.0776
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[012/030] Train loss: 0.0778
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[013/030] Train loss: 0.0777
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[014/030] Train loss: 0.0779
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[015/030] Train loss: 0.0780
2023-02-06 11:25:59 | Train | Epoch[072/600] Iteration[016/030] Train loss: 0.0781
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[017/030] Train loss: 0.0781
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[018/030] Train loss: 0.0780
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[019/030] Train loss: 0.0779
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[020/030] Train loss: 0.0778
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[021/030] Train loss: 0.0779
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[022/030] Train loss: 0.0779
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[023/030] Train loss: 0.0780
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[024/030] Train loss: 0.0781
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[025/030] Train loss: 0.0780
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[026/030] Train loss: 0.0780
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[027/030] Train loss: 0.0781
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[028/030] Train loss: 0.0780
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[029/030] Train loss: 0.0779
2023-02-06 11:26:00 | Train | Epoch[072/600] Iteration[030/030] Train loss: 0.0780
2023-02-06 11:26:00 | Valid | Epoch[072/600] Iteration[001/008] Valid loss: 0.1253
2023-02-06 11:26:00 | Valid | Epoch[072/600] Iteration[002/008] Valid loss: 0.1126
2023-02-06 11:26:00 | Valid | Epoch[072/600] Iteration[003/008] Valid loss: 0.1088
2023-02-06 11:26:00 | Valid | Epoch[072/600] Iteration[004/008] Valid loss: 0.1085
2023-02-06 11:26:01 | Valid | Epoch[072/600] Iteration[005/008] Valid loss: 0.1101
2023-02-06 11:26:01 | Valid | Epoch[072/600] Iteration[006/008] Valid loss: 0.1083
2023-02-06 11:26:01 | Valid | Epoch[072/600] Iteration[007/008] Valid loss: 0.1099
2023-02-06 11:26:01 | Valid | Epoch[072/600] Iteration[008/008] Valid loss: 0.1086
2023-02-06 11:26:01 | Valid | Epoch[072/600] MIou: 0.9397083922347624
2023-02-06 11:26:01 | Valid | Epoch[072/600] Pixel Accuracy: 0.989355723063151
2023-02-06 11:26:01 | Valid | Epoch[072/600] Mean Pixel Accuracy: 0.9779939300152969
2023-02-06 11:26:01 | Stage | Epoch[072/600] Train loss:0.0780
2023-02-06 11:26:01 | Stage | Epoch[072/600] Valid loss:0.1086
2023-02-06 11:26:01 | Stage | Epoch[072/600] LR:0.01

2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[001/030] Train loss: 0.0754
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[002/030] Train loss: 0.0771
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[003/030] Train loss: 0.0770
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[004/030] Train loss: 0.0764
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[005/030] Train loss: 0.0773
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[006/030] Train loss: 0.0772
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[007/030] Train loss: 0.0767
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[008/030] Train loss: 0.0765
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[009/030] Train loss: 0.0766
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[010/030] Train loss: 0.0767
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[011/030] Train loss: 0.0768
2023-02-06 11:26:01 | Train | Epoch[073/600] Iteration[012/030] Train loss: 0.0768
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[013/030] Train loss: 0.0768
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[014/030] Train loss: 0.0766
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[015/030] Train loss: 0.0767
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[016/030] Train loss: 0.0766
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[017/030] Train loss: 0.0767
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[018/030] Train loss: 0.0769
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[019/030] Train loss: 0.0769
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[020/030] Train loss: 0.0769
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[021/030] Train loss: 0.0770
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[022/030] Train loss: 0.0769
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[023/030] Train loss: 0.0768
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[024/030] Train loss: 0.0769
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[025/030] Train loss: 0.0768
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[026/030] Train loss: 0.0768
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[027/030] Train loss: 0.0767
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[028/030] Train loss: 0.0768
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[029/030] Train loss: 0.0767
2023-02-06 11:26:02 | Train | Epoch[073/600] Iteration[030/030] Train loss: 0.0766
2023-02-06 11:26:03 | Valid | Epoch[073/600] Iteration[001/008] Valid loss: 0.3397
2023-02-06 11:26:03 | Valid | Epoch[073/600] Iteration[002/008] Valid loss: 0.2859
2023-02-06 11:26:03 | Valid | Epoch[073/600] Iteration[003/008] Valid loss: 0.2805
2023-02-06 11:26:03 | Valid | Epoch[073/600] Iteration[004/008] Valid loss: 0.2797
2023-02-06 11:26:03 | Valid | Epoch[073/600] Iteration[005/008] Valid loss: 0.2913
2023-02-06 11:26:03 | Valid | Epoch[073/600] Iteration[006/008] Valid loss: 0.2790
2023-02-06 11:26:03 | Valid | Epoch[073/600] Iteration[007/008] Valid loss: 0.2946
2023-02-06 11:26:03 | Valid | Epoch[073/600] Iteration[008/008] Valid loss: 0.2970
2023-02-06 11:26:03 | Valid | Epoch[073/600] MIou: 0.8882126925772196
2023-02-06 11:26:03 | Valid | Epoch[073/600] Pixel Accuracy: 0.9778251647949219
2023-02-06 11:26:03 | Valid | Epoch[073/600] Mean Pixel Accuracy: 0.9818770835021347
2023-02-06 11:26:03 | Stage | Epoch[073/600] Train loss:0.0766
2023-02-06 11:26:03 | Stage | Epoch[073/600] Valid loss:0.2970
2023-02-06 11:26:03 | Stage | Epoch[073/600] LR:0.01

2023-02-06 11:26:03 | Train | Epoch[074/600] Iteration[001/030] Train loss: 0.0781
2023-02-06 11:26:03 | Train | Epoch[074/600] Iteration[002/030] Train loss: 0.0769
2023-02-06 11:26:03 | Train | Epoch[074/600] Iteration[003/030] Train loss: 0.0759
2023-02-06 11:26:03 | Train | Epoch[074/600] Iteration[004/030] Train loss: 0.0755
2023-02-06 11:26:03 | Train | Epoch[074/600] Iteration[005/030] Train loss: 0.0755
2023-02-06 11:26:03 | Train | Epoch[074/600] Iteration[006/030] Train loss: 0.0750
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[007/030] Train loss: 0.0750
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[008/030] Train loss: 0.0757
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[009/030] Train loss: 0.0755
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[010/030] Train loss: 0.0754
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[011/030] Train loss: 0.0755
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[012/030] Train loss: 0.0755
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[013/030] Train loss: 0.0754
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[014/030] Train loss: 0.0751
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[015/030] Train loss: 0.0750
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[016/030] Train loss: 0.0749
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[017/030] Train loss: 0.0748
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[018/030] Train loss: 0.0749
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[019/030] Train loss: 0.0749
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[020/030] Train loss: 0.0753
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[021/030] Train loss: 0.0753
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[022/030] Train loss: 0.0754
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[023/030] Train loss: 0.0753
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[024/030] Train loss: 0.0757
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[025/030] Train loss: 0.0757
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[026/030] Train loss: 0.0757
2023-02-06 11:26:04 | Train | Epoch[074/600] Iteration[027/030] Train loss: 0.0755
2023-02-06 11:26:05 | Train | Epoch[074/600] Iteration[028/030] Train loss: 0.0755
2023-02-06 11:26:05 | Train | Epoch[074/600] Iteration[029/030] Train loss: 0.0755
2023-02-06 11:26:05 | Train | Epoch[074/600] Iteration[030/030] Train loss: 0.0755
2023-02-06 11:26:05 | Valid | Epoch[074/600] Iteration[001/008] Valid loss: 0.2341
2023-02-06 11:26:05 | Valid | Epoch[074/600] Iteration[002/008] Valid loss: 0.2394
2023-02-06 11:26:05 | Valid | Epoch[074/600] Iteration[003/008] Valid loss: 0.2524
2023-02-06 11:26:05 | Valid | Epoch[074/600] Iteration[004/008] Valid loss: 0.2491
2023-02-06 11:26:05 | Valid | Epoch[074/600] Iteration[005/008] Valid loss: 0.2547
2023-02-06 11:26:05 | Valid | Epoch[074/600] Iteration[006/008] Valid loss: 0.2522
2023-02-06 11:26:05 | Valid | Epoch[074/600] Iteration[007/008] Valid loss: 0.2504
2023-02-06 11:26:05 | Valid | Epoch[074/600] Iteration[008/008] Valid loss: 0.2599
2023-02-06 11:26:05 | Valid | Epoch[074/600] MIou: 0.47305158660209357
2023-02-06 11:26:05 | Valid | Epoch[074/600] Pixel Accuracy: 0.9127209981282552
2023-02-06 11:26:05 | Valid | Epoch[074/600] Mean Pixel Accuracy: 0.5168241140942432
2023-02-06 11:26:05 | Stage | Epoch[074/600] Train loss:0.0755
2023-02-06 11:26:05 | Stage | Epoch[074/600] Valid loss:0.2599
2023-02-06 11:26:05 | Stage | Epoch[074/600] LR:0.01

2023-02-06 11:26:05 | Train | Epoch[075/600] Iteration[001/030] Train loss: 0.0726
2023-02-06 11:26:05 | Train | Epoch[075/600] Iteration[002/030] Train loss: 0.0740
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[003/030] Train loss: 0.0733
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[004/030] Train loss: 0.0736
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[005/030] Train loss: 0.0733
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[006/030] Train loss: 0.0737
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[007/030] Train loss: 0.0739
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[008/030] Train loss: 0.0739
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[009/030] Train loss: 0.0737
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[010/030] Train loss: 0.0739
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[011/030] Train loss: 0.0740
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[012/030] Train loss: 0.0744
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[013/030] Train loss: 0.0744
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[014/030] Train loss: 0.0742
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[015/030] Train loss: 0.0741
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[016/030] Train loss: 0.0740
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[017/030] Train loss: 0.0740
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[018/030] Train loss: 0.0740
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[019/030] Train loss: 0.0739
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[020/030] Train loss: 0.0739
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[021/030] Train loss: 0.0738
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[022/030] Train loss: 0.0739
2023-02-06 11:26:06 | Train | Epoch[075/600] Iteration[023/030] Train loss: 0.0739
2023-02-06 11:26:07 | Train | Epoch[075/600] Iteration[024/030] Train loss: 0.0738
2023-02-06 11:26:07 | Train | Epoch[075/600] Iteration[025/030] Train loss: 0.0737
2023-02-06 11:26:07 | Train | Epoch[075/600] Iteration[026/030] Train loss: 0.0737
2023-02-06 11:26:07 | Train | Epoch[075/600] Iteration[027/030] Train loss: 0.0737
2023-02-06 11:26:07 | Train | Epoch[075/600] Iteration[028/030] Train loss: 0.0737
2023-02-06 11:26:07 | Train | Epoch[075/600] Iteration[029/030] Train loss: 0.0736
2023-02-06 11:26:07 | Train | Epoch[075/600] Iteration[030/030] Train loss: 0.0738
2023-02-06 11:26:07 | Valid | Epoch[075/600] Iteration[001/008] Valid loss: 0.6168
2023-02-06 11:26:07 | Valid | Epoch[075/600] Iteration[002/008] Valid loss: 0.5682
2023-02-06 11:26:07 | Valid | Epoch[075/600] Iteration[003/008] Valid loss: 0.5671
2023-02-06 11:26:07 | Valid | Epoch[075/600] Iteration[004/008] Valid loss: 0.5728
2023-02-06 11:26:07 | Valid | Epoch[075/600] Iteration[005/008] Valid loss: 0.5916
2023-02-06 11:26:07 | Valid | Epoch[075/600] Iteration[006/008] Valid loss: 0.5690
2023-02-06 11:26:07 | Valid | Epoch[075/600] Iteration[007/008] Valid loss: 0.5968
2023-02-06 11:26:07 | Valid | Epoch[075/600] Iteration[008/008] Valid loss: 0.6102
2023-02-06 11:26:07 | Valid | Epoch[075/600] MIou: 0.8515541786074854
2023-02-06 11:26:07 | Valid | Epoch[075/600] Pixel Accuracy: 0.9681574503580729
2023-02-06 11:26:07 | Valid | Epoch[075/600] Mean Pixel Accuracy: 0.9795940407123682
2023-02-06 11:26:07 | Stage | Epoch[075/600] Train loss:0.0738
2023-02-06 11:26:07 | Stage | Epoch[075/600] Valid loss:0.6102
2023-02-06 11:26:07 | Stage | Epoch[075/600] LR:0.01

2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[001/030] Train loss: 0.0726
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[002/030] Train loss: 0.0747
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[003/030] Train loss: 0.0735
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[004/030] Train loss: 0.0734
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[005/030] Train loss: 0.0734
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[006/030] Train loss: 0.0731
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[007/030] Train loss: 0.0729
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[008/030] Train loss: 0.0729
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[009/030] Train loss: 0.0731
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[010/030] Train loss: 0.0730
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[011/030] Train loss: 0.0728
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[012/030] Train loss: 0.0726
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[013/030] Train loss: 0.0727
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[014/030] Train loss: 0.0726
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[015/030] Train loss: 0.0725
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[016/030] Train loss: 0.0724
2023-02-06 11:26:08 | Train | Epoch[076/600] Iteration[017/030] Train loss: 0.0723
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[018/030] Train loss: 0.0723
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[019/030] Train loss: 0.0727
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[020/030] Train loss: 0.0728
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[021/030] Train loss: 0.0728
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[022/030] Train loss: 0.0729
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[023/030] Train loss: 0.0729
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[024/030] Train loss: 0.0730
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[025/030] Train loss: 0.0730
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[026/030] Train loss: 0.0730
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[027/030] Train loss: 0.0729
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[028/030] Train loss: 0.0729
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[029/030] Train loss: 0.0729
2023-02-06 11:26:09 | Train | Epoch[076/600] Iteration[030/030] Train loss: 0.0729
2023-02-06 11:26:09 | Valid | Epoch[076/600] Iteration[001/008] Valid loss: 0.0885
2023-02-06 11:26:10 | Valid | Epoch[076/600] Iteration[002/008] Valid loss: 0.0840
2023-02-06 11:26:10 | Valid | Epoch[076/600] Iteration[003/008] Valid loss: 0.0821
2023-02-06 11:26:10 | Valid | Epoch[076/600] Iteration[004/008] Valid loss: 0.0818
2023-02-06 11:26:10 | Valid | Epoch[076/600] Iteration[005/008] Valid loss: 0.0825
2023-02-06 11:26:10 | Valid | Epoch[076/600] Iteration[006/008] Valid loss: 0.0819
2023-02-06 11:26:10 | Valid | Epoch[076/600] Iteration[007/008] Valid loss: 0.0825
2023-02-06 11:26:10 | Valid | Epoch[076/600] Iteration[008/008] Valid loss: 0.0823
2023-02-06 11:26:10 | Valid | Epoch[076/600] MIou: 0.8995365973109182
2023-02-06 11:26:10 | Valid | Epoch[076/600] Pixel Accuracy: 0.9832738240559896
2023-02-06 11:26:10 | Valid | Epoch[076/600] Mean Pixel Accuracy: 0.9131738471531161
2023-02-06 11:26:10 | Stage | Epoch[076/600] Train loss:0.0729
2023-02-06 11:26:10 | Stage | Epoch[076/600] Valid loss:0.0823
2023-02-06 11:26:10 | Stage | Epoch[076/600] LR:0.01

2023-02-06 11:26:10 | Train | Epoch[077/600] Iteration[001/030] Train loss: 0.0739
2023-02-06 11:26:10 | Train | Epoch[077/600] Iteration[002/030] Train loss: 0.0735
2023-02-06 11:26:10 | Train | Epoch[077/600] Iteration[003/030] Train loss: 0.0724
2023-02-06 11:26:10 | Train | Epoch[077/600] Iteration[004/030] Train loss: 0.0713
2023-02-06 11:26:10 | Train | Epoch[077/600] Iteration[005/030] Train loss: 0.0713
2023-02-06 11:26:10 | Train | Epoch[077/600] Iteration[006/030] Train loss: 0.0716
2023-02-06 11:26:10 | Train | Epoch[077/600] Iteration[007/030] Train loss: 0.0712
2023-02-06 11:26:10 | Train | Epoch[077/600] Iteration[008/030] Train loss: 0.0711
2023-02-06 11:26:10 | Train | Epoch[077/600] Iteration[009/030] Train loss: 0.0716
2023-02-06 11:26:10 | Train | Epoch[077/600] Iteration[010/030] Train loss: 0.0713
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[011/030] Train loss: 0.0712
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[012/030] Train loss: 0.0711
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[013/030] Train loss: 0.0712
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[014/030] Train loss: 0.0713
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[015/030] Train loss: 0.0712
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[016/030] Train loss: 0.0712
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[017/030] Train loss: 0.0711
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[018/030] Train loss: 0.0712
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[019/030] Train loss: 0.0713
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[020/030] Train loss: 0.0712
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[021/030] Train loss: 0.0711
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[022/030] Train loss: 0.0710
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[023/030] Train loss: 0.0711
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[024/030] Train loss: 0.0712
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[025/030] Train loss: 0.0713
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[026/030] Train loss: 0.0712
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[027/030] Train loss: 0.0711
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[028/030] Train loss: 0.0711
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[029/030] Train loss: 0.0710
2023-02-06 11:26:11 | Train | Epoch[077/600] Iteration[030/030] Train loss: 0.0711
2023-02-06 11:26:12 | Valid | Epoch[077/600] Iteration[001/008] Valid loss: 0.0980
2023-02-06 11:26:12 | Valid | Epoch[077/600] Iteration[002/008] Valid loss: 0.0991
2023-02-06 11:26:12 | Valid | Epoch[077/600] Iteration[003/008] Valid loss: 0.1005
2023-02-06 11:26:12 | Valid | Epoch[077/600] Iteration[004/008] Valid loss: 0.0992
2023-02-06 11:26:12 | Valid | Epoch[077/600] Iteration[005/008] Valid loss: 0.1010
2023-02-06 11:26:12 | Valid | Epoch[077/600] Iteration[006/008] Valid loss: 0.1000
2023-02-06 11:26:12 | Valid | Epoch[077/600] Iteration[007/008] Valid loss: 0.0988
2023-02-06 11:26:12 | Valid | Epoch[077/600] Iteration[008/008] Valid loss: 0.1007
2023-02-06 11:26:12 | Valid | Epoch[077/600] MIou: 0.7646264748320009
2023-02-06 11:26:12 | Valid | Epoch[077/600] Pixel Accuracy: 0.9611790974934896
2023-02-06 11:26:12 | Valid | Epoch[077/600] Mean Pixel Accuracy: 0.78509412151869
2023-02-06 11:26:12 | Stage | Epoch[077/600] Train loss:0.0711
2023-02-06 11:26:12 | Stage | Epoch[077/600] Valid loss:0.1007
2023-02-06 11:26:12 | Stage | Epoch[077/600] LR:0.01

2023-02-06 11:26:12 | Train | Epoch[078/600] Iteration[001/030] Train loss: 0.0703
2023-02-06 11:26:12 | Train | Epoch[078/600] Iteration[002/030] Train loss: 0.0700
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[003/030] Train loss: 0.0702
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[004/030] Train loss: 0.0702
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[005/030] Train loss: 0.0712
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[006/030] Train loss: 0.0705
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[007/030] Train loss: 0.0704
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[008/030] Train loss: 0.0705
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[009/030] Train loss: 0.0708
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[010/030] Train loss: 0.0710
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[011/030] Train loss: 0.0707
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[012/030] Train loss: 0.0708
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[013/030] Train loss: 0.0708
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[014/030] Train loss: 0.0711
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[015/030] Train loss: 0.0711
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[016/030] Train loss: 0.0710
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[017/030] Train loss: 0.0709
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[018/030] Train loss: 0.0708
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[019/030] Train loss: 0.0707
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[020/030] Train loss: 0.0706
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[021/030] Train loss: 0.0706
2023-02-06 11:26:13 | Train | Epoch[078/600] Iteration[022/030] Train loss: 0.0705
2023-02-06 11:26:14 | Train | Epoch[078/600] Iteration[023/030] Train loss: 0.0704
2023-02-06 11:26:14 | Train | Epoch[078/600] Iteration[024/030] Train loss: 0.0704
2023-02-06 11:26:14 | Train | Epoch[078/600] Iteration[025/030] Train loss: 0.0704
2023-02-06 11:26:14 | Train | Epoch[078/600] Iteration[026/030] Train loss: 0.0703
2023-02-06 11:26:14 | Train | Epoch[078/600] Iteration[027/030] Train loss: 0.0702
2023-02-06 11:26:14 | Train | Epoch[078/600] Iteration[028/030] Train loss: 0.0703
2023-02-06 11:26:14 | Train | Epoch[078/600] Iteration[029/030] Train loss: 0.0703
2023-02-06 11:26:14 | Train | Epoch[078/600] Iteration[030/030] Train loss: 0.0702
2023-02-06 11:26:14 | Valid | Epoch[078/600] Iteration[001/008] Valid loss: 0.0762
2023-02-06 11:26:14 | Valid | Epoch[078/600] Iteration[002/008] Valid loss: 0.0736
2023-02-06 11:26:14 | Valid | Epoch[078/600] Iteration[003/008] Valid loss: 0.0731
2023-02-06 11:26:14 | Valid | Epoch[078/600] Iteration[004/008] Valid loss: 0.0725
2023-02-06 11:26:14 | Valid | Epoch[078/600] Iteration[005/008] Valid loss: 0.0735
2023-02-06 11:26:14 | Valid | Epoch[078/600] Iteration[006/008] Valid loss: 0.0731
2023-02-06 11:26:14 | Valid | Epoch[078/600] Iteration[007/008] Valid loss: 0.0729
2023-02-06 11:26:14 | Valid | Epoch[078/600] Iteration[008/008] Valid loss: 0.0728
2023-02-06 11:26:14 | Valid | Epoch[078/600] MIou: 0.9121498999489708
2023-02-06 11:26:14 | Valid | Epoch[078/600] Pixel Accuracy: 0.9854138692220052
2023-02-06 11:26:14 | Valid | Epoch[078/600] Mean Pixel Accuracy: 0.9237403455564672
2023-02-06 11:26:14 | Stage | Epoch[078/600] Train loss:0.0702
2023-02-06 11:26:14 | Stage | Epoch[078/600] Valid loss:0.0728
2023-02-06 11:26:14 | Stage | Epoch[078/600] LR:0.01

2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[001/030] Train loss: 0.0672
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[002/030] Train loss: 0.0677
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[003/030] Train loss: 0.0677
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[004/030] Train loss: 0.0678
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[005/030] Train loss: 0.0686
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[006/030] Train loss: 0.0684
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[007/030] Train loss: 0.0683
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[008/030] Train loss: 0.0682
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[009/030] Train loss: 0.0692
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[010/030] Train loss: 0.0695
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[011/030] Train loss: 0.0692
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[012/030] Train loss: 0.0691
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[013/030] Train loss: 0.0691
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[014/030] Train loss: 0.0692
2023-02-06 11:26:15 | Train | Epoch[079/600] Iteration[015/030] Train loss: 0.0691
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[016/030] Train loss: 0.0692
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[017/030] Train loss: 0.0691
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[018/030] Train loss: 0.0691
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[019/030] Train loss: 0.0691
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[020/030] Train loss: 0.0691
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[021/030] Train loss: 0.0689
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[022/030] Train loss: 0.0691
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[023/030] Train loss: 0.0692
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[024/030] Train loss: 0.0692
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[025/030] Train loss: 0.0692
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[026/030] Train loss: 0.0692
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[027/030] Train loss: 0.0692
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[028/030] Train loss: 0.0691
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[029/030] Train loss: 0.0691
2023-02-06 11:26:16 | Train | Epoch[079/600] Iteration[030/030] Train loss: 0.0691
2023-02-06 11:26:16 | Valid | Epoch[079/600] Iteration[001/008] Valid loss: 0.1016
2023-02-06 11:26:17 | Valid | Epoch[079/600] Iteration[002/008] Valid loss: 0.1008
2023-02-06 11:26:17 | Valid | Epoch[079/600] Iteration[003/008] Valid loss: 0.1027
2023-02-06 11:26:17 | Valid | Epoch[079/600] Iteration[004/008] Valid loss: 0.1015
2023-02-06 11:26:17 | Valid | Epoch[079/600] Iteration[005/008] Valid loss: 0.1034
2023-02-06 11:26:17 | Valid | Epoch[079/600] Iteration[006/008] Valid loss: 0.1029
2023-02-06 11:26:17 | Valid | Epoch[079/600] Iteration[007/008] Valid loss: 0.1016
2023-02-06 11:26:17 | Valid | Epoch[079/600] Iteration[008/008] Valid loss: 0.1032
2023-02-06 11:26:17 | Valid | Epoch[079/600] MIou: 0.7624815924367673
2023-02-06 11:26:17 | Valid | Epoch[079/600] Pixel Accuracy: 0.9608230590820312
2023-02-06 11:26:17 | Valid | Epoch[079/600] Mean Pixel Accuracy: 0.7831357765427234
2023-02-06 11:26:17 | Stage | Epoch[079/600] Train loss:0.0691
2023-02-06 11:26:17 | Stage | Epoch[079/600] Valid loss:0.1032
2023-02-06 11:26:17 | Stage | Epoch[079/600] LR:0.01

2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[001/030] Train loss: 0.0688
2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[002/030] Train loss: 0.0682
2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[003/030] Train loss: 0.0682
2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[004/030] Train loss: 0.0682
2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[005/030] Train loss: 0.0680
2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[006/030] Train loss: 0.0681
2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[007/030] Train loss: 0.0680
2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[008/030] Train loss: 0.0679
2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[009/030] Train loss: 0.0681
2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[010/030] Train loss: 0.0679
2023-02-06 11:26:17 | Train | Epoch[080/600] Iteration[011/030] Train loss: 0.0684
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[012/030] Train loss: 0.0683
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[013/030] Train loss: 0.0681
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[014/030] Train loss: 0.0680
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[015/030] Train loss: 0.0681
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[016/030] Train loss: 0.0680
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[017/030] Train loss: 0.0680
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[018/030] Train loss: 0.0679
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[019/030] Train loss: 0.0680
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[020/030] Train loss: 0.0680
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[021/030] Train loss: 0.0679
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[022/030] Train loss: 0.0678
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[023/030] Train loss: 0.0676
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[024/030] Train loss: 0.0678
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[025/030] Train loss: 0.0677
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[026/030] Train loss: 0.0678
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[027/030] Train loss: 0.0678
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[028/030] Train loss: 0.0677
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[029/030] Train loss: 0.0677
2023-02-06 11:26:18 | Train | Epoch[080/600] Iteration[030/030] Train loss: 0.0676
2023-02-06 11:26:19 | Valid | Epoch[080/600] Iteration[001/008] Valid loss: 0.0779
2023-02-06 11:26:19 | Valid | Epoch[080/600] Iteration[002/008] Valid loss: 0.0765
2023-02-06 11:26:19 | Valid | Epoch[080/600] Iteration[003/008] Valid loss: 0.0749
2023-02-06 11:26:19 | Valid | Epoch[080/600] Iteration[004/008] Valid loss: 0.0746
2023-02-06 11:26:19 | Valid | Epoch[080/600] Iteration[005/008] Valid loss: 0.0751
2023-02-06 11:26:19 | Valid | Epoch[080/600] Iteration[006/008] Valid loss: 0.0750
2023-02-06 11:26:19 | Valid | Epoch[080/600] Iteration[007/008] Valid loss: 0.0751
2023-02-06 11:26:19 | Valid | Epoch[080/600] Iteration[008/008] Valid loss: 0.0748
2023-02-06 11:26:19 | Valid | Epoch[080/600] MIou: 0.9251861264896818
2023-02-06 11:26:19 | Valid | Epoch[080/600] Pixel Accuracy: 0.9874725341796875
2023-02-06 11:26:19 | Valid | Epoch[080/600] Mean Pixel Accuracy: 0.9395437266960991
2023-02-06 11:26:19 | Stage | Epoch[080/600] Train loss:0.0676
2023-02-06 11:26:19 | Stage | Epoch[080/600] Valid loss:0.0748
2023-02-06 11:26:19 | Stage | Epoch[080/600] LR:0.01

2023-02-06 11:26:19 | Train | Epoch[081/600] Iteration[001/030] Train loss: 0.0672
2023-02-06 11:26:19 | Train | Epoch[081/600] Iteration[002/030] Train loss: 0.0673
2023-02-06 11:26:19 | Train | Epoch[081/600] Iteration[003/030] Train loss: 0.0667
2023-02-06 11:26:19 | Train | Epoch[081/600] Iteration[004/030] Train loss: 0.0664
2023-02-06 11:26:19 | Train | Epoch[081/600] Iteration[005/030] Train loss: 0.0665
2023-02-06 11:26:19 | Train | Epoch[081/600] Iteration[006/030] Train loss: 0.0669
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[007/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[008/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[009/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[010/030] Train loss: 0.0668
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[011/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[012/030] Train loss: 0.0669
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[013/030] Train loss: 0.0672
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[014/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[015/030] Train loss: 0.0669
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[016/030] Train loss: 0.0668
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[017/030] Train loss: 0.0668
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[018/030] Train loss: 0.0668
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[019/030] Train loss: 0.0667
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[020/030] Train loss: 0.0668
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[021/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[022/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[023/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[024/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[025/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[026/030] Train loss: 0.0670
2023-02-06 11:26:20 | Train | Epoch[081/600] Iteration[027/030] Train loss: 0.0671
2023-02-06 11:26:21 | Train | Epoch[081/600] Iteration[028/030] Train loss: 0.0674
2023-02-06 11:26:21 | Train | Epoch[081/600] Iteration[029/030] Train loss: 0.0673
2023-02-06 11:26:21 | Train | Epoch[081/600] Iteration[030/030] Train loss: 0.0672
2023-02-06 11:26:21 | Valid | Epoch[081/600] Iteration[001/008] Valid loss: 0.0732
2023-02-06 11:26:21 | Valid | Epoch[081/600] Iteration[002/008] Valid loss: 0.0692
2023-02-06 11:26:21 | Valid | Epoch[081/600] Iteration[003/008] Valid loss: 0.0693
2023-02-06 11:26:21 | Valid | Epoch[081/600] Iteration[004/008] Valid loss: 0.0682
2023-02-06 11:26:21 | Valid | Epoch[081/600] Iteration[005/008] Valid loss: 0.0694
2023-02-06 11:26:21 | Valid | Epoch[081/600] Iteration[006/008] Valid loss: 0.0689
2023-02-06 11:26:21 | Valid | Epoch[081/600] Iteration[007/008] Valid loss: 0.0688
2023-02-06 11:26:21 | Valid | Epoch[081/600] Iteration[008/008] Valid loss: 0.0689
2023-02-06 11:26:21 | Valid | Epoch[081/600] MIou: 0.8909762695685516
2023-02-06 11:26:21 | Valid | Epoch[081/600] Pixel Accuracy: 0.9819628397623698
2023-02-06 11:26:21 | Valid | Epoch[081/600] Mean Pixel Accuracy: 0.9026699267300756
2023-02-06 11:26:21 | Stage | Epoch[081/600] Train loss:0.0672
2023-02-06 11:26:21 | Stage | Epoch[081/600] Valid loss:0.0689
2023-02-06 11:26:21 | Stage | Epoch[081/600] LR:0.01

2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[001/030] Train loss: 0.0675
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[002/030] Train loss: 0.0666
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[003/030] Train loss: 0.0655
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[004/030] Train loss: 0.0655
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[005/030] Train loss: 0.0653
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[006/030] Train loss: 0.0659
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[007/030] Train loss: 0.0660
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[008/030] Train loss: 0.0657
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[009/030] Train loss: 0.0660
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[010/030] Train loss: 0.0661
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[011/030] Train loss: 0.0662
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[012/030] Train loss: 0.0661
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[013/030] Train loss: 0.0662
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[014/030] Train loss: 0.0662
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[015/030] Train loss: 0.0662
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[016/030] Train loss: 0.0662
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[017/030] Train loss: 0.0661
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[018/030] Train loss: 0.0661
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[019/030] Train loss: 0.0661
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[020/030] Train loss: 0.0660
2023-02-06 11:26:22 | Train | Epoch[082/600] Iteration[021/030] Train loss: 0.0663
2023-02-06 11:26:23 | Train | Epoch[082/600] Iteration[022/030] Train loss: 0.0664
2023-02-06 11:26:23 | Train | Epoch[082/600] Iteration[023/030] Train loss: 0.0664
2023-02-06 11:26:23 | Train | Epoch[082/600] Iteration[024/030] Train loss: 0.0664
2023-02-06 11:26:23 | Train | Epoch[082/600] Iteration[025/030] Train loss: 0.0663
2023-02-06 11:26:23 | Train | Epoch[082/600] Iteration[026/030] Train loss: 0.0663
2023-02-06 11:26:23 | Train | Epoch[082/600] Iteration[027/030] Train loss: 0.0662
2023-02-06 11:26:23 | Train | Epoch[082/600] Iteration[028/030] Train loss: 0.0662
2023-02-06 11:26:23 | Train | Epoch[082/600] Iteration[029/030] Train loss: 0.0662
2023-02-06 11:26:23 | Train | Epoch[082/600] Iteration[030/030] Train loss: 0.0664
2023-02-06 11:26:23 | Valid | Epoch[082/600] Iteration[001/008] Valid loss: 0.1147
2023-02-06 11:26:23 | Valid | Epoch[082/600] Iteration[002/008] Valid loss: 0.1158
2023-02-06 11:26:23 | Valid | Epoch[082/600] Iteration[003/008] Valid loss: 0.1190
2023-02-06 11:26:23 | Valid | Epoch[082/600] Iteration[004/008] Valid loss: 0.1179
2023-02-06 11:26:23 | Valid | Epoch[082/600] Iteration[005/008] Valid loss: 0.1199
2023-02-06 11:26:23 | Valid | Epoch[082/600] Iteration[006/008] Valid loss: 0.1190
2023-02-06 11:26:23 | Valid | Epoch[082/600] Iteration[007/008] Valid loss: 0.1171
2023-02-06 11:26:23 | Valid | Epoch[082/600] Iteration[008/008] Valid loss: 0.1196
2023-02-06 11:26:24 | Valid | Epoch[082/600] MIou: 0.6975227213528863
2023-02-06 11:26:24 | Valid | Epoch[082/600] Pixel Accuracy: 0.9500617980957031
2023-02-06 11:26:24 | Valid | Epoch[082/600] Mean Pixel Accuracy: 0.7235424967266891
2023-02-06 11:26:24 | Stage | Epoch[082/600] Train loss:0.0664
2023-02-06 11:26:24 | Stage | Epoch[082/600] Valid loss:0.1196
2023-02-06 11:26:24 | Stage | Epoch[082/600] LR:0.01

2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[001/030] Train loss: 0.0668
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[002/030] Train loss: 0.0662
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[003/030] Train loss: 0.0661
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[004/030] Train loss: 0.0656
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[005/030] Train loss: 0.0652
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[006/030] Train loss: 0.0648
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[007/030] Train loss: 0.0649
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[008/030] Train loss: 0.0646
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[009/030] Train loss: 0.0646
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[010/030] Train loss: 0.0647
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[011/030] Train loss: 0.0656
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[012/030] Train loss: 0.0657
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[013/030] Train loss: 0.0658
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[014/030] Train loss: 0.0657
2023-02-06 11:26:24 | Train | Epoch[083/600] Iteration[015/030] Train loss: 0.0658
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[016/030] Train loss: 0.0657
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[017/030] Train loss: 0.0656
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[018/030] Train loss: 0.0655
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[019/030] Train loss: 0.0655
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[020/030] Train loss: 0.0655
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[021/030] Train loss: 0.0655
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[022/030] Train loss: 0.0655
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[023/030] Train loss: 0.0656
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[024/030] Train loss: 0.0658
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[025/030] Train loss: 0.0658
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[026/030] Train loss: 0.0658
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[027/030] Train loss: 0.0658
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[028/030] Train loss: 0.0659
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[029/030] Train loss: 0.0659
2023-02-06 11:26:25 | Train | Epoch[083/600] Iteration[030/030] Train loss: 0.0658
2023-02-06 11:26:26 | Valid | Epoch[083/600] Iteration[001/008] Valid loss: 0.2189
2023-02-06 11:26:26 | Valid | Epoch[083/600] Iteration[002/008] Valid loss: 0.2241
2023-02-06 11:26:26 | Valid | Epoch[083/600] Iteration[003/008] Valid loss: 0.2363
2023-02-06 11:26:26 | Valid | Epoch[083/600] Iteration[004/008] Valid loss: 0.2326
2023-02-06 11:26:26 | Valid | Epoch[083/600] Iteration[005/008] Valid loss: 0.2401
2023-02-06 11:26:26 | Valid | Epoch[083/600] Iteration[006/008] Valid loss: 0.2378
2023-02-06 11:26:26 | Valid | Epoch[083/600] Iteration[007/008] Valid loss: 0.2358
2023-02-06 11:26:26 | Valid | Epoch[083/600] Iteration[008/008] Valid loss: 0.2455
2023-02-06 11:26:26 | Valid | Epoch[083/600] MIou: 0.4610118291751578
2023-02-06 11:26:26 | Valid | Epoch[083/600] Pixel Accuracy: 0.910711924235026
2023-02-06 11:26:26 | Valid | Epoch[083/600] Mean Pixel Accuracy: 0.5057018964085092
2023-02-06 11:26:26 | Stage | Epoch[083/600] Train loss:0.0658
2023-02-06 11:26:26 | Stage | Epoch[083/600] Valid loss:0.2455
2023-02-06 11:26:26 | Stage | Epoch[083/600] LR:0.01

2023-02-06 11:26:26 | Train | Epoch[084/600] Iteration[001/030] Train loss: 0.0649
2023-02-06 11:26:26 | Train | Epoch[084/600] Iteration[002/030] Train loss: 0.0638
2023-02-06 11:26:26 | Train | Epoch[084/600] Iteration[003/030] Train loss: 0.0637
2023-02-06 11:26:26 | Train | Epoch[084/600] Iteration[004/030] Train loss: 0.0645
2023-02-06 11:26:26 | Train | Epoch[084/600] Iteration[005/030] Train loss: 0.0644
2023-02-06 11:26:26 | Train | Epoch[084/600] Iteration[006/030] Train loss: 0.0644
2023-02-06 11:26:26 | Train | Epoch[084/600] Iteration[007/030] Train loss: 0.0646
2023-02-06 11:26:26 | Train | Epoch[084/600] Iteration[008/030] Train loss: 0.0645
2023-02-06 11:26:26 | Train | Epoch[084/600] Iteration[009/030] Train loss: 0.0643
2023-02-06 11:26:26 | Train | Epoch[084/600] Iteration[010/030] Train loss: 0.0642
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[011/030] Train loss: 0.0643
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[012/030] Train loss: 0.0643
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[013/030] Train loss: 0.0643
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[014/030] Train loss: 0.0645
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[015/030] Train loss: 0.0646
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[016/030] Train loss: 0.0645
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[017/030] Train loss: 0.0645
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[018/030] Train loss: 0.0646
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[019/030] Train loss: 0.0646
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[020/030] Train loss: 0.0645
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[021/030] Train loss: 0.0645
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[022/030] Train loss: 0.0644
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[023/030] Train loss: 0.0644
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[024/030] Train loss: 0.0644
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[025/030] Train loss: 0.0644
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[026/030] Train loss: 0.0644
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[027/030] Train loss: 0.0643
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[028/030] Train loss: 0.0644
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[029/030] Train loss: 0.0643
2023-02-06 11:26:27 | Train | Epoch[084/600] Iteration[030/030] Train loss: 0.0644
2023-02-06 11:26:28 | Valid | Epoch[084/600] Iteration[001/008] Valid loss: 0.0799
2023-02-06 11:26:28 | Valid | Epoch[084/600] Iteration[002/008] Valid loss: 0.0767
2023-02-06 11:26:28 | Valid | Epoch[084/600] Iteration[003/008] Valid loss: 0.0743
2023-02-06 11:26:28 | Valid | Epoch[084/600] Iteration[004/008] Valid loss: 0.0737
2023-02-06 11:26:28 | Valid | Epoch[084/600] Iteration[005/008] Valid loss: 0.0743
2023-02-06 11:26:28 | Valid | Epoch[084/600] Iteration[006/008] Valid loss: 0.0739
2023-02-06 11:26:28 | Valid | Epoch[084/600] Iteration[007/008] Valid loss: 0.0742
2023-02-06 11:26:28 | Valid | Epoch[084/600] Iteration[008/008] Valid loss: 0.0743
2023-02-06 11:26:28 | Valid | Epoch[084/600] MIou: 0.9304101674645526
2023-02-06 11:26:28 | Valid | Epoch[084/600] Pixel Accuracy: 0.988135019938151
2023-02-06 11:26:28 | Valid | Epoch[084/600] Mean Pixel Accuracy: 0.9525634382613961
2023-02-06 11:26:28 | Stage | Epoch[084/600] Train loss:0.0644
2023-02-06 11:26:28 | Stage | Epoch[084/600] Valid loss:0.0743
2023-02-06 11:26:28 | Stage | Epoch[084/600] LR:0.01

2023-02-06 11:26:28 | Train | Epoch[085/600] Iteration[001/030] Train loss: 0.0611
2023-02-06 11:26:28 | Train | Epoch[085/600] Iteration[002/030] Train loss: 0.0610
2023-02-06 11:26:28 | Train | Epoch[085/600] Iteration[003/030] Train loss: 0.0611
2023-02-06 11:26:28 | Train | Epoch[085/600] Iteration[004/030] Train loss: 0.0621
2023-02-06 11:26:28 | Train | Epoch[085/600] Iteration[005/030] Train loss: 0.0621
2023-02-06 11:26:28 | Train | Epoch[085/600] Iteration[006/030] Train loss: 0.0623
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[007/030] Train loss: 0.0624
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[008/030] Train loss: 0.0628
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[009/030] Train loss: 0.0628
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[010/030] Train loss: 0.0627
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[011/030] Train loss: 0.0631
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[012/030] Train loss: 0.0631
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[013/030] Train loss: 0.0632
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[014/030] Train loss: 0.0633
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[015/030] Train loss: 0.0633
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[016/030] Train loss: 0.0633
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[017/030] Train loss: 0.0633
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[018/030] Train loss: 0.0633
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[019/030] Train loss: 0.0632
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[020/030] Train loss: 0.0631
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[021/030] Train loss: 0.0632
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[022/030] Train loss: 0.0630
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[023/030] Train loss: 0.0633
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[024/030] Train loss: 0.0634
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[025/030] Train loss: 0.0632
2023-02-06 11:26:29 | Train | Epoch[085/600] Iteration[026/030] Train loss: 0.0633
2023-02-06 11:26:30 | Train | Epoch[085/600] Iteration[027/030] Train loss: 0.0633
2023-02-06 11:26:30 | Train | Epoch[085/600] Iteration[028/030] Train loss: 0.0633
2023-02-06 11:26:30 | Train | Epoch[085/600] Iteration[029/030] Train loss: 0.0634
2023-02-06 11:26:30 | Train | Epoch[085/600] Iteration[030/030] Train loss: 0.0634
2023-02-06 11:26:30 | Valid | Epoch[085/600] Iteration[001/008] Valid loss: 1.8612
2023-02-06 11:26:30 | Valid | Epoch[085/600] Iteration[002/008] Valid loss: 1.8151
2023-02-06 11:26:30 | Valid | Epoch[085/600] Iteration[003/008] Valid loss: 1.8493
2023-02-06 11:26:30 | Valid | Epoch[085/600] Iteration[004/008] Valid loss: 1.8991
2023-02-06 11:26:30 | Valid | Epoch[085/600] Iteration[005/008] Valid loss: 1.9394
2023-02-06 11:26:30 | Valid | Epoch[085/600] Iteration[006/008] Valid loss: 1.8955
2023-02-06 11:26:30 | Valid | Epoch[085/600] Iteration[007/008] Valid loss: 1.9473
2023-02-06 11:26:30 | Valid | Epoch[085/600] Iteration[008/008] Valid loss: 2.0163
2023-02-06 11:26:30 | Valid | Epoch[085/600] MIou: 0.7680855684525676
2023-02-06 11:26:30 | Valid | Epoch[085/600] Pixel Accuracy: 0.9402961730957031
2023-02-06 11:26:30 | Valid | Epoch[085/600] Mean Pixel Accuracy: 0.9667403974209208
2023-02-06 11:26:30 | Stage | Epoch[085/600] Train loss:0.0634
2023-02-06 11:26:30 | Stage | Epoch[085/600] Valid loss:2.0163
2023-02-06 11:26:30 | Stage | Epoch[085/600] LR:0.01

2023-02-06 11:26:30 | Train | Epoch[086/600] Iteration[001/030] Train loss: 0.0681
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[002/030] Train loss: 0.0654
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[003/030] Train loss: 0.0643
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[004/030] Train loss: 0.0639
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[005/030] Train loss: 0.0638
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[006/030] Train loss: 0.0637
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[007/030] Train loss: 0.0639
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[008/030] Train loss: 0.0636
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[009/030] Train loss: 0.0637
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[010/030] Train loss: 0.0634
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[011/030] Train loss: 0.0632
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[012/030] Train loss: 0.0628
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[013/030] Train loss: 0.0629
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[014/030] Train loss: 0.0628
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[015/030] Train loss: 0.0629
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[016/030] Train loss: 0.0630
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[017/030] Train loss: 0.0629
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[018/030] Train loss: 0.0628
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[019/030] Train loss: 0.0626
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[020/030] Train loss: 0.0624
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[021/030] Train loss: 0.0624
2023-02-06 11:26:31 | Train | Epoch[086/600] Iteration[022/030] Train loss: 0.0624
2023-02-06 11:26:32 | Train | Epoch[086/600] Iteration[023/030] Train loss: 0.0625
2023-02-06 11:26:32 | Train | Epoch[086/600] Iteration[024/030] Train loss: 0.0626
2023-02-06 11:26:32 | Train | Epoch[086/600] Iteration[025/030] Train loss: 0.0625
2023-02-06 11:26:32 | Train | Epoch[086/600] Iteration[026/030] Train loss: 0.0625
2023-02-06 11:26:32 | Train | Epoch[086/600] Iteration[027/030] Train loss: 0.0625
2023-02-06 11:26:32 | Train | Epoch[086/600] Iteration[028/030] Train loss: 0.0625
2023-02-06 11:26:32 | Train | Epoch[086/600] Iteration[029/030] Train loss: 0.0625
2023-02-06 11:26:32 | Train | Epoch[086/600] Iteration[030/030] Train loss: 0.0632
2023-02-06 11:26:32 | Valid | Epoch[086/600] Iteration[001/008] Valid loss: 0.4594
2023-02-06 11:26:32 | Valid | Epoch[086/600] Iteration[002/008] Valid loss: 0.3967
2023-02-06 11:26:32 | Valid | Epoch[086/600] Iteration[003/008] Valid loss: 0.3878
2023-02-06 11:26:32 | Valid | Epoch[086/600] Iteration[004/008] Valid loss: 0.3929
2023-02-06 11:26:32 | Valid | Epoch[086/600] Iteration[005/008] Valid loss: 0.4082
2023-02-06 11:26:32 | Valid | Epoch[086/600] Iteration[006/008] Valid loss: 0.3969
2023-02-06 11:26:32 | Valid | Epoch[086/600] Iteration[007/008] Valid loss: 0.4140
2023-02-06 11:26:32 | Valid | Epoch[086/600] Iteration[008/008] Valid loss: 0.4167
2023-02-06 11:26:32 | Valid | Epoch[086/600] MIou: 0.8745376028436816
2023-02-06 11:26:32 | Valid | Epoch[086/600] Pixel Accuracy: 0.9743245442708334
2023-02-06 11:26:32 | Valid | Epoch[086/600] Mean Pixel Accuracy: 0.982330669981271
2023-02-06 11:26:32 | Stage | Epoch[086/600] Train loss:0.0632
2023-02-06 11:26:32 | Stage | Epoch[086/600] Valid loss:0.4167
2023-02-06 11:26:32 | Stage | Epoch[086/600] LR:0.01

2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[001/030] Train loss: 0.0630
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[002/030] Train loss: 0.0638
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[003/030] Train loss: 0.0632
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[004/030] Train loss: 0.0656
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[005/030] Train loss: 0.0661
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[006/030] Train loss: 0.0668
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[007/030] Train loss: 0.0668
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[008/030] Train loss: 0.0665
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[009/030] Train loss: 0.0672
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[010/030] Train loss: 0.0673
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[011/030] Train loss: 0.0674
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[012/030] Train loss: 0.0674
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[013/030] Train loss: 0.0675
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[014/030] Train loss: 0.0674
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[015/030] Train loss: 0.0674
2023-02-06 11:26:33 | Train | Epoch[087/600] Iteration[016/030] Train loss: 0.0676
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[017/030] Train loss: 0.0677
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[018/030] Train loss: 0.0674
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[019/030] Train loss: 0.0672
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[020/030] Train loss: 0.0669
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[021/030] Train loss: 0.0667
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[022/030] Train loss: 0.0664
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[023/030] Train loss: 0.0662
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[024/030] Train loss: 0.0660
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[025/030] Train loss: 0.0659
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[026/030] Train loss: 0.0658
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[027/030] Train loss: 0.0656
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[028/030] Train loss: 0.0655
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[029/030] Train loss: 0.0654
2023-02-06 11:26:34 | Train | Epoch[087/600] Iteration[030/030] Train loss: 0.0652
2023-02-06 11:26:34 | Valid | Epoch[087/600] Iteration[001/008] Valid loss: 0.2881
2023-02-06 11:26:35 | Valid | Epoch[087/600] Iteration[002/008] Valid loss: 0.2884
2023-02-06 11:26:35 | Valid | Epoch[087/600] Iteration[003/008] Valid loss: 0.3051
2023-02-06 11:26:35 | Valid | Epoch[087/600] Iteration[004/008] Valid loss: 0.3035
2023-02-06 11:26:35 | Valid | Epoch[087/600] Iteration[005/008] Valid loss: 0.3137
2023-02-06 11:26:35 | Valid | Epoch[087/600] Iteration[006/008] Valid loss: 0.3122
2023-02-06 11:26:35 | Valid | Epoch[087/600] Iteration[007/008] Valid loss: 0.3120
2023-02-06 11:26:35 | Valid | Epoch[087/600] Iteration[008/008] Valid loss: 0.3224
2023-02-06 11:26:35 | Valid | Epoch[087/600] MIou: 0.4553056627714958
2023-02-06 11:26:35 | Valid | Epoch[087/600] Pixel Accuracy: 0.909759521484375
2023-02-06 11:26:35 | Valid | Epoch[087/600] Mean Pixel Accuracy: 0.5004294020752087
2023-02-06 11:26:35 | Stage | Epoch[087/600] Train loss:0.0652
2023-02-06 11:26:35 | Stage | Epoch[087/600] Valid loss:0.3224
2023-02-06 11:26:35 | Stage | Epoch[087/600] LR:0.01

2023-02-06 11:26:35 | Train | Epoch[088/600] Iteration[001/030] Train loss: 0.0636
2023-02-06 11:26:35 | Train | Epoch[088/600] Iteration[002/030] Train loss: 0.0628
2023-02-06 11:26:35 | Train | Epoch[088/600] Iteration[003/030] Train loss: 0.0620
2023-02-06 11:26:35 | Train | Epoch[088/600] Iteration[004/030] Train loss: 0.0617
2023-02-06 11:26:35 | Train | Epoch[088/600] Iteration[005/030] Train loss: 0.0623
2023-02-06 11:26:35 | Train | Epoch[088/600] Iteration[006/030] Train loss: 0.0622
2023-02-06 11:26:35 | Train | Epoch[088/600] Iteration[007/030] Train loss: 0.0619
2023-02-06 11:26:35 | Train | Epoch[088/600] Iteration[008/030] Train loss: 0.0620
2023-02-06 11:26:35 | Train | Epoch[088/600] Iteration[009/030] Train loss: 0.0616
2023-02-06 11:26:35 | Train | Epoch[088/600] Iteration[010/030] Train loss: 0.0615
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[011/030] Train loss: 0.0614
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[012/030] Train loss: 0.0617
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[013/030] Train loss: 0.0616
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[014/030] Train loss: 0.0617
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[015/030] Train loss: 0.0616
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[016/030] Train loss: 0.0617
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[017/030] Train loss: 0.0615
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[018/030] Train loss: 0.0615
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[019/030] Train loss: 0.0614
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[020/030] Train loss: 0.0614
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[021/030] Train loss: 0.0613
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[022/030] Train loss: 0.0612
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[023/030] Train loss: 0.0611
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[024/030] Train loss: 0.0611
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[025/030] Train loss: 0.0611
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[026/030] Train loss: 0.0612
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[027/030] Train loss: 0.0612
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[028/030] Train loss: 0.0612
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[029/030] Train loss: 0.0611
2023-02-06 11:26:36 | Train | Epoch[088/600] Iteration[030/030] Train loss: 0.0610
2023-02-06 11:26:37 | Valid | Epoch[088/600] Iteration[001/008] Valid loss: 0.0701
2023-02-06 11:26:37 | Valid | Epoch[088/600] Iteration[002/008] Valid loss: 0.0632
2023-02-06 11:26:37 | Valid | Epoch[088/600] Iteration[003/008] Valid loss: 0.0621
2023-02-06 11:26:37 | Valid | Epoch[088/600] Iteration[004/008] Valid loss: 0.0609
2023-02-06 11:26:37 | Valid | Epoch[088/600] Iteration[005/008] Valid loss: 0.0619
2023-02-06 11:26:37 | Valid | Epoch[088/600] Iteration[006/008] Valid loss: 0.0615
2023-02-06 11:26:37 | Valid | Epoch[088/600] Iteration[007/008] Valid loss: 0.0618
2023-02-06 11:26:37 | Valid | Epoch[088/600] Iteration[008/008] Valid loss: 0.0614
2023-02-06 11:26:37 | Valid | Epoch[088/600] MIou: 0.9253879290096677
2023-02-06 11:26:37 | Valid | Epoch[088/600] Pixel Accuracy: 0.9875628153483073
2023-02-06 11:26:37 | Valid | Epoch[088/600] Mean Pixel Accuracy: 0.9377419313952439
2023-02-06 11:26:37 | Stage | Epoch[088/600] Train loss:0.0610
2023-02-06 11:26:37 | Stage | Epoch[088/600] Valid loss:0.0614
2023-02-06 11:26:37 | Stage | Epoch[088/600] LR:0.01

2023-02-06 11:26:37 | Train | Epoch[089/600] Iteration[001/030] Train loss: 0.0613
2023-02-06 11:26:37 | Train | Epoch[089/600] Iteration[002/030] Train loss: 0.0620
2023-02-06 11:26:37 | Train | Epoch[089/600] Iteration[003/030] Train loss: 0.0619
2023-02-06 11:26:37 | Train | Epoch[089/600] Iteration[004/030] Train loss: 0.0616
2023-02-06 11:26:37 | Train | Epoch[089/600] Iteration[005/030] Train loss: 0.0614
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[006/030] Train loss: 0.0619
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[007/030] Train loss: 0.0617
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[008/030] Train loss: 0.0616
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[009/030] Train loss: 0.0611
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[010/030] Train loss: 0.0612
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[011/030] Train loss: 0.0611
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[012/030] Train loss: 0.0613
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[013/030] Train loss: 0.0613
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[014/030] Train loss: 0.0615
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[015/030] Train loss: 0.0615
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[016/030] Train loss: 0.0614
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[017/030] Train loss: 0.0614
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[018/030] Train loss: 0.0613
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[019/030] Train loss: 0.0613
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[020/030] Train loss: 0.0612
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[021/030] Train loss: 0.0612
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[022/030] Train loss: 0.0610
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[023/030] Train loss: 0.0610
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[024/030] Train loss: 0.0609
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[025/030] Train loss: 0.0609
2023-02-06 11:26:38 | Train | Epoch[089/600] Iteration[026/030] Train loss: 0.0608
2023-02-06 11:26:39 | Train | Epoch[089/600] Iteration[027/030] Train loss: 0.0607
2023-02-06 11:26:39 | Train | Epoch[089/600] Iteration[028/030] Train loss: 0.0606
2023-02-06 11:26:39 | Train | Epoch[089/600] Iteration[029/030] Train loss: 0.0605
2023-02-06 11:26:39 | Train | Epoch[089/600] Iteration[030/030] Train loss: 0.0605
2023-02-06 11:26:39 | Valid | Epoch[089/600] Iteration[001/008] Valid loss: 0.4844
2023-02-06 11:26:39 | Valid | Epoch[089/600] Iteration[002/008] Valid loss: 0.4515
2023-02-06 11:26:39 | Valid | Epoch[089/600] Iteration[003/008] Valid loss: 0.4462
2023-02-06 11:26:39 | Valid | Epoch[089/600] Iteration[004/008] Valid loss: 0.4441
2023-02-06 11:26:39 | Valid | Epoch[089/600] Iteration[005/008] Valid loss: 0.4552
2023-02-06 11:26:39 | Valid | Epoch[089/600] Iteration[006/008] Valid loss: 0.4345
2023-02-06 11:26:39 | Valid | Epoch[089/600] Iteration[007/008] Valid loss: 0.4545
2023-02-06 11:26:39 | Valid | Epoch[089/600] Iteration[008/008] Valid loss: 0.4670
2023-02-06 11:26:39 | Valid | Epoch[089/600] MIou: 0.8761092249870741
2023-02-06 11:26:39 | Valid | Epoch[089/600] Pixel Accuracy: 0.9747746785481771
2023-02-06 11:26:39 | Valid | Epoch[089/600] Mean Pixel Accuracy: 0.9815255647068566
2023-02-06 11:26:39 | Stage | Epoch[089/600] Train loss:0.0605
2023-02-06 11:26:39 | Stage | Epoch[089/600] Valid loss:0.4670
2023-02-06 11:26:39 | Stage | Epoch[089/600] LR:0.01

2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[001/030] Train loss: 0.0591
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[002/030] Train loss: 0.0604
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[003/030] Train loss: 0.0601
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[004/030] Train loss: 0.0597
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[005/030] Train loss: 0.0595
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[006/030] Train loss: 0.0594
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[007/030] Train loss: 0.0600
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[008/030] Train loss: 0.0598
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[009/030] Train loss: 0.0598
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[010/030] Train loss: 0.0596
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[011/030] Train loss: 0.0597
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[012/030] Train loss: 0.0594
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[013/030] Train loss: 0.0593
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[014/030] Train loss: 0.0591
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[015/030] Train loss: 0.0590
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[016/030] Train loss: 0.0589
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[017/030] Train loss: 0.0589
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[018/030] Train loss: 0.0589
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[019/030] Train loss: 0.0587
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[020/030] Train loss: 0.0588
2023-02-06 11:26:40 | Train | Epoch[090/600] Iteration[021/030] Train loss: 0.0586
2023-02-06 11:26:41 | Train | Epoch[090/600] Iteration[022/030] Train loss: 0.0585
2023-02-06 11:26:41 | Train | Epoch[090/600] Iteration[023/030] Train loss: 0.0586
2023-02-06 11:26:41 | Train | Epoch[090/600] Iteration[024/030] Train loss: 0.0584
2023-02-06 11:26:41 | Train | Epoch[090/600] Iteration[025/030] Train loss: 0.0585
2023-02-06 11:26:41 | Train | Epoch[090/600] Iteration[026/030] Train loss: 0.0585
2023-02-06 11:26:41 | Train | Epoch[090/600] Iteration[027/030] Train loss: 0.0589
2023-02-06 11:26:41 | Train | Epoch[090/600] Iteration[028/030] Train loss: 0.0588
2023-02-06 11:26:41 | Train | Epoch[090/600] Iteration[029/030] Train loss: 0.0588
2023-02-06 11:26:41 | Train | Epoch[090/600] Iteration[030/030] Train loss: 0.0588
2023-02-06 11:26:41 | Valid | Epoch[090/600] Iteration[001/008] Valid loss: 0.8177
2023-02-06 11:26:41 | Valid | Epoch[090/600] Iteration[002/008] Valid loss: 0.7657
2023-02-06 11:26:41 | Valid | Epoch[090/600] Iteration[003/008] Valid loss: 0.7666
2023-02-06 11:26:41 | Valid | Epoch[090/600] Iteration[004/008] Valid loss: 0.7829
2023-02-06 11:26:41 | Valid | Epoch[090/600] Iteration[005/008] Valid loss: 0.8072
2023-02-06 11:26:41 | Valid | Epoch[090/600] Iteration[006/008] Valid loss: 0.7837
2023-02-06 11:26:41 | Valid | Epoch[090/600] Iteration[007/008] Valid loss: 0.8186
2023-02-06 11:26:41 | Valid | Epoch[090/600] Iteration[008/008] Valid loss: 0.8357
2023-02-06 11:26:42 | Valid | Epoch[090/600] MIou: 0.8455346431432188
2023-02-06 11:26:42 | Valid | Epoch[090/600] Pixel Accuracy: 0.966406504313151
2023-02-06 11:26:42 | Valid | Epoch[090/600] Mean Pixel Accuracy: 0.979468588329631
2023-02-06 11:26:42 | Stage | Epoch[090/600] Train loss:0.0588
2023-02-06 11:26:42 | Stage | Epoch[090/600] Valid loss:0.8357
2023-02-06 11:26:42 | Stage | Epoch[090/600] LR:0.01

2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[001/030] Train loss: 0.0593
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[002/030] Train loss: 0.0602
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[003/030] Train loss: 0.0603
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[004/030] Train loss: 0.0593
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[005/030] Train loss: 0.0595
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[006/030] Train loss: 0.0589
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[007/030] Train loss: 0.0590
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[008/030] Train loss: 0.0588
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[009/030] Train loss: 0.0589
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[010/030] Train loss: 0.0587
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[011/030] Train loss: 0.0586
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[012/030] Train loss: 0.0585
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[013/030] Train loss: 0.0587
2023-02-06 11:26:42 | Train | Epoch[091/600] Iteration[014/030] Train loss: 0.0588
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[015/030] Train loss: 0.0587
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[016/030] Train loss: 0.0585
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[017/030] Train loss: 0.0585
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[018/030] Train loss: 0.0584
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[019/030] Train loss: 0.0583
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[020/030] Train loss: 0.0583
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[021/030] Train loss: 0.0583
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[022/030] Train loss: 0.0585
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[023/030] Train loss: 0.0584
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[024/030] Train loss: 0.0583
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[025/030] Train loss: 0.0584
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[026/030] Train loss: 0.0584
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[027/030] Train loss: 0.0584
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[028/030] Train loss: 0.0583
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[029/030] Train loss: 0.0582
2023-02-06 11:26:43 | Train | Epoch[091/600] Iteration[030/030] Train loss: 0.0582
2023-02-06 11:26:44 | Valid | Epoch[091/600] Iteration[001/008] Valid loss: 0.0791
2023-02-06 11:26:44 | Valid | Epoch[091/600] Iteration[002/008] Valid loss: 0.0683
2023-02-06 11:26:44 | Valid | Epoch[091/600] Iteration[003/008] Valid loss: 0.0662
2023-02-06 11:26:44 | Valid | Epoch[091/600] Iteration[004/008] Valid loss: 0.0651
2023-02-06 11:26:44 | Valid | Epoch[091/600] Iteration[005/008] Valid loss: 0.0664
2023-02-06 11:26:44 | Valid | Epoch[091/600] Iteration[006/008] Valid loss: 0.0658
2023-02-06 11:26:44 | Valid | Epoch[091/600] Iteration[007/008] Valid loss: 0.0663
2023-02-06 11:26:44 | Valid | Epoch[091/600] Iteration[008/008] Valid loss: 0.0657
2023-02-06 11:26:44 | Valid | Epoch[091/600] MIou: 0.9336359970558602
2023-02-06 11:26:44 | Valid | Epoch[091/600] Pixel Accuracy: 0.9888025919596354
2023-02-06 11:26:44 | Valid | Epoch[091/600] Mean Pixel Accuracy: 0.9508760515457482
2023-02-06 11:26:44 | Stage | Epoch[091/600] Train loss:0.0582
2023-02-06 11:26:44 | Stage | Epoch[091/600] Valid loss:0.0657
2023-02-06 11:26:44 | Stage | Epoch[091/600] LR:0.01

2023-02-06 11:26:44 | Train | Epoch[092/600] Iteration[001/030] Train loss: 0.0596
2023-02-06 11:26:44 | Train | Epoch[092/600] Iteration[002/030] Train loss: 0.0579
2023-02-06 11:26:44 | Train | Epoch[092/600] Iteration[003/030] Train loss: 0.0577
2023-02-06 11:26:44 | Train | Epoch[092/600] Iteration[004/030] Train loss: 0.0575
2023-02-06 11:26:44 | Train | Epoch[092/600] Iteration[005/030] Train loss: 0.0576
2023-02-06 11:26:44 | Train | Epoch[092/600] Iteration[006/030] Train loss: 0.0574
2023-02-06 11:26:44 | Train | Epoch[092/600] Iteration[007/030] Train loss: 0.0580
2023-02-06 11:26:44 | Train | Epoch[092/600] Iteration[008/030] Train loss: 0.0579
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[009/030] Train loss: 0.0577
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[010/030] Train loss: 0.0578
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[011/030] Train loss: 0.0576
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[012/030] Train loss: 0.0576
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[013/030] Train loss: 0.0577
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[014/030] Train loss: 0.0576
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[015/030] Train loss: 0.0575
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[016/030] Train loss: 0.0574
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[017/030] Train loss: 0.0573
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[018/030] Train loss: 0.0572
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[019/030] Train loss: 0.0572
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[020/030] Train loss: 0.0571
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[021/030] Train loss: 0.0571
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[022/030] Train loss: 0.0571
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[023/030] Train loss: 0.0575
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[024/030] Train loss: 0.0576
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[025/030] Train loss: 0.0576
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[026/030] Train loss: 0.0576
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[027/030] Train loss: 0.0575
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[028/030] Train loss: 0.0576
2023-02-06 11:26:45 | Train | Epoch[092/600] Iteration[029/030] Train loss: 0.0574
2023-02-06 11:26:46 | Train | Epoch[092/600] Iteration[030/030] Train loss: 0.0575
2023-02-06 11:26:46 | Valid | Epoch[092/600] Iteration[001/008] Valid loss: 0.1366
2023-02-06 11:26:46 | Valid | Epoch[092/600] Iteration[002/008] Valid loss: 0.1068
2023-02-06 11:26:46 | Valid | Epoch[092/600] Iteration[003/008] Valid loss: 0.0997
2023-02-06 11:26:46 | Valid | Epoch[092/600] Iteration[004/008] Valid loss: 0.1010
2023-02-06 11:26:46 | Valid | Epoch[092/600] Iteration[005/008] Valid loss: 0.1051
2023-02-06 11:26:46 | Valid | Epoch[092/600] Iteration[006/008] Valid loss: 0.1009
2023-02-06 11:26:46 | Valid | Epoch[092/600] Iteration[007/008] Valid loss: 0.1048
2023-02-06 11:26:46 | Valid | Epoch[092/600] Iteration[008/008] Valid loss: 0.1021
2023-02-06 11:26:46 | Valid | Epoch[092/600] MIou: 0.9367745364621283
2023-02-06 11:26:46 | Valid | Epoch[092/600] Pixel Accuracy: 0.9888013203938802
2023-02-06 11:26:46 | Valid | Epoch[092/600] Mean Pixel Accuracy: 0.9766747312216308
2023-02-06 11:26:46 | Stage | Epoch[092/600] Train loss:0.0575
2023-02-06 11:26:46 | Stage | Epoch[092/600] Valid loss:0.1021
2023-02-06 11:26:46 | Stage | Epoch[092/600] LR:0.01

2023-02-06 11:26:46 | Train | Epoch[093/600] Iteration[001/030] Train loss: 0.0579
2023-02-06 11:26:46 | Train | Epoch[093/600] Iteration[002/030] Train loss: 0.0570
2023-02-06 11:26:46 | Train | Epoch[093/600] Iteration[003/030] Train loss: 0.0585
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[004/030] Train loss: 0.0587
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[005/030] Train loss: 0.0577
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[006/030] Train loss: 0.0576
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[007/030] Train loss: 0.0574
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[008/030] Train loss: 0.0569
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[009/030] Train loss: 0.0568
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[010/030] Train loss: 0.0568
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[011/030] Train loss: 0.0567
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[012/030] Train loss: 0.0568
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[013/030] Train loss: 0.0568
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[014/030] Train loss: 0.0567
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[015/030] Train loss: 0.0567
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[016/030] Train loss: 0.0566
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[017/030] Train loss: 0.0566
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[018/030] Train loss: 0.0565
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[019/030] Train loss: 0.0564
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[020/030] Train loss: 0.0564
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[021/030] Train loss: 0.0564
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[022/030] Train loss: 0.0564
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[023/030] Train loss: 0.0565
2023-02-06 11:26:47 | Train | Epoch[093/600] Iteration[024/030] Train loss: 0.0566
2023-02-06 11:26:48 | Train | Epoch[093/600] Iteration[025/030] Train loss: 0.0568
2023-02-06 11:26:48 | Train | Epoch[093/600] Iteration[026/030] Train loss: 0.0567
2023-02-06 11:26:48 | Train | Epoch[093/600] Iteration[027/030] Train loss: 0.0566
2023-02-06 11:26:48 | Train | Epoch[093/600] Iteration[028/030] Train loss: 0.0565
2023-02-06 11:26:48 | Train | Epoch[093/600] Iteration[029/030] Train loss: 0.0566
2023-02-06 11:26:48 | Train | Epoch[093/600] Iteration[030/030] Train loss: 0.0565
2023-02-06 11:26:48 | Valid | Epoch[093/600] Iteration[001/008] Valid loss: 0.0667
2023-02-06 11:26:48 | Valid | Epoch[093/600] Iteration[002/008] Valid loss: 0.0648
2023-02-06 11:26:48 | Valid | Epoch[093/600] Iteration[003/008] Valid loss: 0.0645
2023-02-06 11:26:48 | Valid | Epoch[093/600] Iteration[004/008] Valid loss: 0.0640
2023-02-06 11:26:48 | Valid | Epoch[093/600] Iteration[005/008] Valid loss: 0.0652
2023-02-06 11:26:48 | Valid | Epoch[093/600] Iteration[006/008] Valid loss: 0.0650
2023-02-06 11:26:48 | Valid | Epoch[093/600] Iteration[007/008] Valid loss: 0.0647
2023-02-06 11:26:48 | Valid | Epoch[093/600] Iteration[008/008] Valid loss: 0.0647
2023-02-06 11:26:48 | Valid | Epoch[093/600] MIou: 0.9069731554201622
2023-02-06 11:26:48 | Valid | Epoch[093/600] Pixel Accuracy: 0.9845441182454427
2023-02-06 11:26:48 | Valid | Epoch[093/600] Mean Pixel Accuracy: 0.9192170725010596
2023-02-06 11:26:48 | Stage | Epoch[093/600] Train loss:0.0565
2023-02-06 11:26:48 | Stage | Epoch[093/600] Valid loss:0.0647
2023-02-06 11:26:48 | Stage | Epoch[093/600] LR:0.01

2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[001/030] Train loss: 0.0575
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[002/030] Train loss: 0.0572
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[003/030] Train loss: 0.0554
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[004/030] Train loss: 0.0557
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[005/030] Train loss: 0.0552
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[006/030] Train loss: 0.0559
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[007/030] Train loss: 0.0558
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[008/030] Train loss: 0.0560
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[009/030] Train loss: 0.0557
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[010/030] Train loss: 0.0555
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[011/030] Train loss: 0.0561
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[012/030] Train loss: 0.0559
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[013/030] Train loss: 0.0560
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[014/030] Train loss: 0.0559
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[015/030] Train loss: 0.0557
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[016/030] Train loss: 0.0556
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[017/030] Train loss: 0.0556
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[018/030] Train loss: 0.0555
2023-02-06 11:26:49 | Train | Epoch[094/600] Iteration[019/030] Train loss: 0.0555
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[020/030] Train loss: 0.0556
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[021/030] Train loss: 0.0556
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[022/030] Train loss: 0.0558
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[023/030] Train loss: 0.0557
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[024/030] Train loss: 0.0556
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[025/030] Train loss: 0.0556
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[026/030] Train loss: 0.0557
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[027/030] Train loss: 0.0557
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[028/030] Train loss: 0.0558
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[029/030] Train loss: 0.0557
2023-02-06 11:26:50 | Train | Epoch[094/600] Iteration[030/030] Train loss: 0.0557
2023-02-06 11:26:50 | Valid | Epoch[094/600] Iteration[001/008] Valid loss: 0.4712
2023-02-06 11:26:50 | Valid | Epoch[094/600] Iteration[002/008] Valid loss: 0.4223
2023-02-06 11:26:50 | Valid | Epoch[094/600] Iteration[003/008] Valid loss: 0.4100
2023-02-06 11:26:50 | Valid | Epoch[094/600] Iteration[004/008] Valid loss: 0.4118
2023-02-06 11:26:50 | Valid | Epoch[094/600] Iteration[005/008] Valid loss: 0.4252
2023-02-06 11:26:50 | Valid | Epoch[094/600] Iteration[006/008] Valid loss: 0.4118
2023-02-06 11:26:50 | Valid | Epoch[094/600] Iteration[007/008] Valid loss: 0.4313
2023-02-06 11:26:50 | Valid | Epoch[094/600] Iteration[008/008] Valid loss: 0.4344
2023-02-06 11:26:51 | Valid | Epoch[094/600] MIou: 0.8691171507116209
2023-02-06 11:26:51 | Valid | Epoch[094/600] Pixel Accuracy: 0.9728660583496094
2023-02-06 11:26:51 | Valid | Epoch[094/600] Mean Pixel Accuracy: 0.9827337135033414
2023-02-06 11:26:51 | Stage | Epoch[094/600] Train loss:0.0557
2023-02-06 11:26:51 | Stage | Epoch[094/600] Valid loss:0.4344
2023-02-06 11:26:51 | Stage | Epoch[094/600] LR:0.01

2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[001/030] Train loss: 0.0544
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[002/030] Train loss: 0.0557
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[003/030] Train loss: 0.0564
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[004/030] Train loss: 0.0564
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[005/030] Train loss: 0.0562
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[006/030] Train loss: 0.0560
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[007/030] Train loss: 0.0559
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[008/030] Train loss: 0.0554
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[009/030] Train loss: 0.0558
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[010/030] Train loss: 0.0559
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[011/030] Train loss: 0.0558
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[012/030] Train loss: 0.0558
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[013/030] Train loss: 0.0556
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[014/030] Train loss: 0.0555
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[015/030] Train loss: 0.0553
2023-02-06 11:26:51 | Train | Epoch[095/600] Iteration[016/030] Train loss: 0.0554
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[017/030] Train loss: 0.0554
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[018/030] Train loss: 0.0555
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[019/030] Train loss: 0.0554
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[020/030] Train loss: 0.0554
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[021/030] Train loss: 0.0555
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[022/030] Train loss: 0.0555
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[023/030] Train loss: 0.0554
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[024/030] Train loss: 0.0553
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[025/030] Train loss: 0.0551
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[026/030] Train loss: 0.0550
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[027/030] Train loss: 0.0551
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[028/030] Train loss: 0.0550
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[029/030] Train loss: 0.0550
2023-02-06 11:26:52 | Train | Epoch[095/600] Iteration[030/030] Train loss: 0.0549
2023-02-06 11:26:52 | Valid | Epoch[095/600] Iteration[001/008] Valid loss: 0.0634
2023-02-06 11:26:52 | Valid | Epoch[095/600] Iteration[002/008] Valid loss: 0.0603
2023-02-06 11:26:52 | Valid | Epoch[095/600] Iteration[003/008] Valid loss: 0.0603
2023-02-06 11:26:53 | Valid | Epoch[095/600] Iteration[004/008] Valid loss: 0.0593
2023-02-06 11:26:53 | Valid | Epoch[095/600] Iteration[005/008] Valid loss: 0.0603
2023-02-06 11:26:53 | Valid | Epoch[095/600] Iteration[006/008] Valid loss: 0.0599
2023-02-06 11:26:53 | Valid | Epoch[095/600] Iteration[007/008] Valid loss: 0.0595
2023-02-06 11:26:53 | Valid | Epoch[095/600] Iteration[008/008] Valid loss: 0.0597
2023-02-06 11:26:53 | Valid | Epoch[095/600] MIou: 0.8882380034314943
2023-02-06 11:26:53 | Valid | Epoch[095/600] Pixel Accuracy: 0.9815661112467448
2023-02-06 11:26:53 | Valid | Epoch[095/600] Mean Pixel Accuracy: 0.8989265656571098
2023-02-06 11:26:53 | Stage | Epoch[095/600] Train loss:0.0549
2023-02-06 11:26:53 | Stage | Epoch[095/600] Valid loss:0.0597
2023-02-06 11:26:53 | Stage | Epoch[095/600] LR:0.01

2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[001/030] Train loss: 0.0545
2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[002/030] Train loss: 0.0543
2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[003/030] Train loss: 0.0539
2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[004/030] Train loss: 0.0542
2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[005/030] Train loss: 0.0545
2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[006/030] Train loss: 0.0549
2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[007/030] Train loss: 0.0547
2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[008/030] Train loss: 0.0546
2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[009/030] Train loss: 0.0544
2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[010/030] Train loss: 0.0548
2023-02-06 11:26:53 | Train | Epoch[096/600] Iteration[011/030] Train loss: 0.0547
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[012/030] Train loss: 0.0546
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[013/030] Train loss: 0.0546
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[014/030] Train loss: 0.0545
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[015/030] Train loss: 0.0548
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[016/030] Train loss: 0.0548
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[017/030] Train loss: 0.0549
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[018/030] Train loss: 0.0548
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[019/030] Train loss: 0.0546
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[020/030] Train loss: 0.0547
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[021/030] Train loss: 0.0547
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[022/030] Train loss: 0.0546
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[023/030] Train loss: 0.0545
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[024/030] Train loss: 0.0544
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[025/030] Train loss: 0.0544
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[026/030] Train loss: 0.0543
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[027/030] Train loss: 0.0543
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[028/030] Train loss: 0.0544
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[029/030] Train loss: 0.0544
2023-02-06 11:26:54 | Train | Epoch[096/600] Iteration[030/030] Train loss: 0.0543
2023-02-06 11:26:55 | Valid | Epoch[096/600] Iteration[001/008] Valid loss: 0.0725
2023-02-06 11:26:55 | Valid | Epoch[096/600] Iteration[002/008] Valid loss: 0.0641
2023-02-06 11:26:55 | Valid | Epoch[096/600] Iteration[003/008] Valid loss: 0.0627
2023-02-06 11:26:55 | Valid | Epoch[096/600] Iteration[004/008] Valid loss: 0.0624
2023-02-06 11:26:55 | Valid | Epoch[096/600] Iteration[005/008] Valid loss: 0.0639
2023-02-06 11:26:55 | Valid | Epoch[096/600] Iteration[006/008] Valid loss: 0.0638
2023-02-06 11:26:55 | Valid | Epoch[096/600] Iteration[007/008] Valid loss: 0.0647
2023-02-06 11:26:55 | Valid | Epoch[096/600] Iteration[008/008] Valid loss: 0.0638
2023-02-06 11:26:55 | Valid | Epoch[096/600] MIou: 0.9355710990337003
2023-02-06 11:26:55 | Valid | Epoch[096/600] Pixel Accuracy: 0.9891103108723959
2023-02-06 11:26:55 | Valid | Epoch[096/600] Mean Pixel Accuracy: 0.9534862685162462
2023-02-06 11:26:55 | Stage | Epoch[096/600] Train loss:0.0543
2023-02-06 11:26:55 | Stage | Epoch[096/600] Valid loss:0.0638
2023-02-06 11:26:55 | Stage | Epoch[096/600] LR:0.01

2023-02-06 11:26:55 | Train | Epoch[097/600] Iteration[001/030] Train loss: 0.0510
2023-02-06 11:26:55 | Train | Epoch[097/600] Iteration[002/030] Train loss: 0.0526
2023-02-06 11:26:55 | Train | Epoch[097/600] Iteration[003/030] Train loss: 0.0532
2023-02-06 11:26:55 | Train | Epoch[097/600] Iteration[004/030] Train loss: 0.0535
2023-02-06 11:26:55 | Train | Epoch[097/600] Iteration[005/030] Train loss: 0.0532
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[006/030] Train loss: 0.0532
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[007/030] Train loss: 0.0541
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[008/030] Train loss: 0.0539
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[009/030] Train loss: 0.0540
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[010/030] Train loss: 0.0540
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[011/030] Train loss: 0.0542
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[012/030] Train loss: 0.0541
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[013/030] Train loss: 0.0541
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[014/030] Train loss: 0.0543
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[015/030] Train loss: 0.0541
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[016/030] Train loss: 0.0540
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[017/030] Train loss: 0.0539
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[018/030] Train loss: 0.0542
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[019/030] Train loss: 0.0541
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[020/030] Train loss: 0.0541
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[021/030] Train loss: 0.0542
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[022/030] Train loss: 0.0543
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[023/030] Train loss: 0.0543
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[024/030] Train loss: 0.0544
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[025/030] Train loss: 0.0544
2023-02-06 11:26:56 | Train | Epoch[097/600] Iteration[026/030] Train loss: 0.0543
2023-02-06 11:26:57 | Train | Epoch[097/600] Iteration[027/030] Train loss: 0.0543
2023-02-06 11:26:57 | Train | Epoch[097/600] Iteration[028/030] Train loss: 0.0542
2023-02-06 11:26:57 | Train | Epoch[097/600] Iteration[029/030] Train loss: 0.0542
2023-02-06 11:26:57 | Train | Epoch[097/600] Iteration[030/030] Train loss: 0.0542
2023-02-06 11:26:57 | Valid | Epoch[097/600] Iteration[001/008] Valid loss: 0.0848
2023-02-06 11:26:57 | Valid | Epoch[097/600] Iteration[002/008] Valid loss: 0.0727
2023-02-06 11:26:57 | Valid | Epoch[097/600] Iteration[003/008] Valid loss: 0.0692
2023-02-06 11:26:57 | Valid | Epoch[097/600] Iteration[004/008] Valid loss: 0.0688
2023-02-06 11:26:57 | Valid | Epoch[097/600] Iteration[005/008] Valid loss: 0.0704
2023-02-06 11:26:57 | Valid | Epoch[097/600] Iteration[006/008] Valid loss: 0.0689
2023-02-06 11:26:57 | Valid | Epoch[097/600] Iteration[007/008] Valid loss: 0.0693
2023-02-06 11:26:57 | Valid | Epoch[097/600] Iteration[008/008] Valid loss: 0.0684
2023-02-06 11:26:57 | Valid | Epoch[097/600] MIou: 0.9360283285240878
2023-02-06 11:26:57 | Valid | Epoch[097/600] Pixel Accuracy: 0.9890098571777344
2023-02-06 11:26:57 | Valid | Epoch[097/600] Mean Pixel Accuracy: 0.9614327299296586
2023-02-06 11:26:57 | Stage | Epoch[097/600] Train loss:0.0542
2023-02-06 11:26:57 | Stage | Epoch[097/600] Valid loss:0.0684
2023-02-06 11:26:57 | Stage | Epoch[097/600] LR:0.01

2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[001/030] Train loss: 0.0512
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[002/030] Train loss: 0.0507
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[003/030] Train loss: 0.0527
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[004/030] Train loss: 0.0539
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[005/030] Train loss: 0.0534
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[006/030] Train loss: 0.0535
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[007/030] Train loss: 0.0537
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[008/030] Train loss: 0.0538
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[009/030] Train loss: 0.0537
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[010/030] Train loss: 0.0540
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[011/030] Train loss: 0.0537
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[012/030] Train loss: 0.0537
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[013/030] Train loss: 0.0537
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[014/030] Train loss: 0.0535
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[015/030] Train loss: 0.0535
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[016/030] Train loss: 0.0539
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[017/030] Train loss: 0.0539
2023-02-06 11:26:58 | Train | Epoch[098/600] Iteration[018/030] Train loss: 0.0539
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[019/030] Train loss: 0.0539
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[020/030] Train loss: 0.0539
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[021/030] Train loss: 0.0538
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[022/030] Train loss: 0.0539
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[023/030] Train loss: 0.0538
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[024/030] Train loss: 0.0537
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[025/030] Train loss: 0.0536
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[026/030] Train loss: 0.0534
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[027/030] Train loss: 0.0533
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[028/030] Train loss: 0.0532
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[029/030] Train loss: 0.0533
2023-02-06 11:26:59 | Train | Epoch[098/600] Iteration[030/030] Train loss: 0.0533
2023-02-06 11:26:59 | Valid | Epoch[098/600] Iteration[001/008] Valid loss: 0.1414
2023-02-06 11:26:59 | Valid | Epoch[098/600] Iteration[002/008] Valid loss: 0.1466
2023-02-06 11:26:59 | Valid | Epoch[098/600] Iteration[003/008] Valid loss: 0.1530
2023-02-06 11:26:59 | Valid | Epoch[098/600] Iteration[004/008] Valid loss: 0.1502
2023-02-06 11:26:59 | Valid | Epoch[098/600] Iteration[005/008] Valid loss: 0.1536
2023-02-06 11:27:00 | Valid | Epoch[098/600] Iteration[006/008] Valid loss: 0.1512
2023-02-06 11:27:00 | Valid | Epoch[098/600] Iteration[007/008] Valid loss: 0.1491
2023-02-06 11:27:00 | Valid | Epoch[098/600] Iteration[008/008] Valid loss: 0.1541
2023-02-06 11:27:00 | Valid | Epoch[098/600] MIou: 0.6000565323154232
2023-02-06 11:27:00 | Valid | Epoch[098/600] Pixel Accuracy: 0.9338760375976562
2023-02-06 11:27:00 | Valid | Epoch[098/600] Mean Pixel Accuracy: 0.6339382505737093
2023-02-06 11:27:00 | Stage | Epoch[098/600] Train loss:0.0533
2023-02-06 11:27:00 | Stage | Epoch[098/600] Valid loss:0.1541
2023-02-06 11:27:00 | Stage | Epoch[098/600] LR:0.01

2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[001/030] Train loss: 0.0515
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[002/030] Train loss: 0.0531
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[003/030] Train loss: 0.0526
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[004/030] Train loss: 0.0524
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[005/030] Train loss: 0.0523
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[006/030] Train loss: 0.0519
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[007/030] Train loss: 0.0520
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[008/030] Train loss: 0.0521
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[009/030] Train loss: 0.0521
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[010/030] Train loss: 0.0519
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[011/030] Train loss: 0.0520
2023-02-06 11:27:00 | Train | Epoch[099/600] Iteration[012/030] Train loss: 0.0521
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[013/030] Train loss: 0.0522
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[014/030] Train loss: 0.0522
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[015/030] Train loss: 0.0521
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[016/030] Train loss: 0.0520
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[017/030] Train loss: 0.0520
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[018/030] Train loss: 0.0525
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[019/030] Train loss: 0.0524
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[020/030] Train loss: 0.0525
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[021/030] Train loss: 0.0526
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[022/030] Train loss: 0.0524
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[023/030] Train loss: 0.0523
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[024/030] Train loss: 0.0524
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[025/030] Train loss: 0.0524
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[026/030] Train loss: 0.0525
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[027/030] Train loss: 0.0526
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[028/030] Train loss: 0.0527
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[029/030] Train loss: 0.0527
2023-02-06 11:27:01 | Train | Epoch[099/600] Iteration[030/030] Train loss: 0.0527
2023-02-06 11:27:02 | Valid | Epoch[099/600] Iteration[001/008] Valid loss: 0.1189
2023-02-06 11:27:02 | Valid | Epoch[099/600] Iteration[002/008] Valid loss: 0.0979
2023-02-06 11:27:02 | Valid | Epoch[099/600] Iteration[003/008] Valid loss: 0.0925
2023-02-06 11:27:02 | Valid | Epoch[099/600] Iteration[004/008] Valid loss: 0.0899
2023-02-06 11:27:02 | Valid | Epoch[099/600] Iteration[005/008] Valid loss: 0.0955
2023-02-06 11:27:02 | Valid | Epoch[099/600] Iteration[006/008] Valid loss: 0.0930
2023-02-06 11:27:02 | Valid | Epoch[099/600] Iteration[007/008] Valid loss: 0.0927
2023-02-06 11:27:02 | Valid | Epoch[099/600] Iteration[008/008] Valid loss: 0.0919
2023-02-06 11:27:02 | Valid | Epoch[099/600] MIou: 0.9302919589866837
2023-02-06 11:27:02 | Valid | Epoch[099/600] Pixel Accuracy: 0.9876899719238281
2023-02-06 11:27:02 | Valid | Epoch[099/600] Mean Pixel Accuracy: 0.9688230682378293
2023-02-06 11:27:02 | Stage | Epoch[099/600] Train loss:0.0527
2023-02-06 11:27:02 | Stage | Epoch[099/600] Valid loss:0.0919
2023-02-06 11:27:02 | Stage | Epoch[099/600] LR:0.01

2023-02-06 11:27:02 | Train | Epoch[100/600] Iteration[001/030] Train loss: 0.0549
2023-02-06 11:27:02 | Train | Epoch[100/600] Iteration[002/030] Train loss: 0.0534
2023-02-06 11:27:02 | Train | Epoch[100/600] Iteration[003/030] Train loss: 0.0537
2023-02-06 11:27:02 | Train | Epoch[100/600] Iteration[004/030] Train loss: 0.0535
2023-02-06 11:27:02 | Train | Epoch[100/600] Iteration[005/030] Train loss: 0.0532
2023-02-06 11:27:02 | Train | Epoch[100/600] Iteration[006/030] Train loss: 0.0529
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[007/030] Train loss: 0.0525
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[008/030] Train loss: 0.0527
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[009/030] Train loss: 0.0527
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[010/030] Train loss: 0.0524
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[011/030] Train loss: 0.0524
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[012/030] Train loss: 0.0522
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[013/030] Train loss: 0.0523
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[014/030] Train loss: 0.0521
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[015/030] Train loss: 0.0520
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[016/030] Train loss: 0.0520
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[017/030] Train loss: 0.0520
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[018/030] Train loss: 0.0518
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[019/030] Train loss: 0.0517
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[020/030] Train loss: 0.0518
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[021/030] Train loss: 0.0518
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[022/030] Train loss: 0.0517
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[023/030] Train loss: 0.0519
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[024/030] Train loss: 0.0519
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[025/030] Train loss: 0.0520
2023-02-06 11:27:03 | Train | Epoch[100/600] Iteration[026/030] Train loss: 0.0520
2023-02-06 11:27:04 | Train | Epoch[100/600] Iteration[027/030] Train loss: 0.0520
2023-02-06 11:27:04 | Train | Epoch[100/600] Iteration[028/030] Train loss: 0.0519
2023-02-06 11:27:04 | Train | Epoch[100/600] Iteration[029/030] Train loss: 0.0519
2023-02-06 11:27:04 | Train | Epoch[100/600] Iteration[030/030] Train loss: 0.0518
2023-02-06 11:27:04 | Valid | Epoch[100/600] Iteration[001/008] Valid loss: 0.2544
2023-02-06 11:27:04 | Valid | Epoch[100/600] Iteration[002/008] Valid loss: 0.2646
2023-02-06 11:27:04 | Valid | Epoch[100/600] Iteration[003/008] Valid loss: 0.2822
2023-02-06 11:27:04 | Valid | Epoch[100/600] Iteration[004/008] Valid loss: 0.2789
2023-02-06 11:27:04 | Valid | Epoch[100/600] Iteration[005/008] Valid loss: 0.2893
2023-02-06 11:27:04 | Valid | Epoch[100/600] Iteration[006/008] Valid loss: 0.2862
2023-02-06 11:27:04 | Valid | Epoch[100/600] Iteration[007/008] Valid loss: 0.2845
2023-02-06 11:27:04 | Valid | Epoch[100/600] Iteration[008/008] Valid loss: 0.2968
2023-02-06 11:27:04 | Valid | Epoch[100/600] MIou: 0.4601889931525039
2023-02-06 11:27:04 | Valid | Epoch[100/600] Pixel Accuracy: 0.9105745951334635
2023-02-06 11:27:04 | Valid | Epoch[100/600] Mean Pixel Accuracy: 0.5049416435540413
2023-02-06 11:27:04 | Stage | Epoch[100/600] Train loss:0.0518
2023-02-06 11:27:04 | Stage | Epoch[100/600] Valid loss:0.2968
2023-02-06 11:27:04 | Stage | Epoch[100/600] LR:0.01

2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[001/030] Train loss: 0.0509
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[002/030] Train loss: 0.0509
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[003/030] Train loss: 0.0506
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[004/030] Train loss: 0.0500
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[005/030] Train loss: 0.0501
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[006/030] Train loss: 0.0498
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[007/030] Train loss: 0.0503
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[008/030] Train loss: 0.0505
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[009/030] Train loss: 0.0504
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[010/030] Train loss: 0.0505
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[011/030] Train loss: 0.0509
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[012/030] Train loss: 0.0509
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[013/030] Train loss: 0.0507
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[014/030] Train loss: 0.0511
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[015/030] Train loss: 0.0511
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[016/030] Train loss: 0.0511
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[017/030] Train loss: 0.0510
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[018/030] Train loss: 0.0509
2023-02-06 11:27:05 | Train | Epoch[101/600] Iteration[019/030] Train loss: 0.0508
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[020/030] Train loss: 0.0507
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[021/030] Train loss: 0.0505
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[022/030] Train loss: 0.0504
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[023/030] Train loss: 0.0506
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[024/030] Train loss: 0.0506
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[025/030] Train loss: 0.0506
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[026/030] Train loss: 0.0506
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[027/030] Train loss: 0.0507
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[028/030] Train loss: 0.0507
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[029/030] Train loss: 0.0508
2023-02-06 11:27:06 | Train | Epoch[101/600] Iteration[030/030] Train loss: 0.0508
2023-02-06 11:27:06 | Valid | Epoch[101/600] Iteration[001/008] Valid loss: 0.0639
2023-02-06 11:27:06 | Valid | Epoch[101/600] Iteration[002/008] Valid loss: 0.0606
2023-02-06 11:27:06 | Valid | Epoch[101/600] Iteration[003/008] Valid loss: 0.0603
2023-02-06 11:27:06 | Valid | Epoch[101/600] Iteration[004/008] Valid loss: 0.0590
2023-02-06 11:27:06 | Valid | Epoch[101/600] Iteration[005/008] Valid loss: 0.0600
2023-02-06 11:27:06 | Valid | Epoch[101/600] Iteration[006/008] Valid loss: 0.0594
2023-02-06 11:27:06 | Valid | Epoch[101/600] Iteration[007/008] Valid loss: 0.0587
2023-02-06 11:27:07 | Valid | Epoch[101/600] Iteration[008/008] Valid loss: 0.0591
2023-02-06 11:27:07 | Valid | Epoch[101/600] MIou: 0.8866924351013714
2023-02-06 11:27:07 | Valid | Epoch[101/600] Pixel Accuracy: 0.9812533060709635
2023-02-06 11:27:07 | Valid | Epoch[101/600] Mean Pixel Accuracy: 0.8987292727056341
2023-02-06 11:27:07 | Stage | Epoch[101/600] Train loss:0.0508
2023-02-06 11:27:07 | Stage | Epoch[101/600] Valid loss:0.0591
2023-02-06 11:27:07 | Stage | Epoch[101/600] LR:0.01

2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[001/030] Train loss: 0.0471
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[002/030] Train loss: 0.0489
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[003/030] Train loss: 0.0486
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[004/030] Train loss: 0.0489
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[005/030] Train loss: 0.0496
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[006/030] Train loss: 0.0494
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[007/030] Train loss: 0.0493
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[008/030] Train loss: 0.0495
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[009/030] Train loss: 0.0494
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[010/030] Train loss: 0.0498
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[011/030] Train loss: 0.0498
2023-02-06 11:27:07 | Train | Epoch[102/600] Iteration[012/030] Train loss: 0.0498
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[013/030] Train loss: 0.0497
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[014/030] Train loss: 0.0497
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[015/030] Train loss: 0.0496
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[016/030] Train loss: 0.0496
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[017/030] Train loss: 0.0497
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[018/030] Train loss: 0.0496
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[019/030] Train loss: 0.0501
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[020/030] Train loss: 0.0501
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[021/030] Train loss: 0.0501
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[022/030] Train loss: 0.0499
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[023/030] Train loss: 0.0500
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[024/030] Train loss: 0.0500
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[025/030] Train loss: 0.0499
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[026/030] Train loss: 0.0501
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[027/030] Train loss: 0.0502
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[028/030] Train loss: 0.0503
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[029/030] Train loss: 0.0503
2023-02-06 11:27:08 | Train | Epoch[102/600] Iteration[030/030] Train loss: 0.0503
2023-02-06 11:27:09 | Valid | Epoch[102/600] Iteration[001/008] Valid loss: 0.0730
2023-02-06 11:27:09 | Valid | Epoch[102/600] Iteration[002/008] Valid loss: 0.0729
2023-02-06 11:27:09 | Valid | Epoch[102/600] Iteration[003/008] Valid loss: 0.0737
2023-02-06 11:27:09 | Valid | Epoch[102/600] Iteration[004/008] Valid loss: 0.0723
2023-02-06 11:27:09 | Valid | Epoch[102/600] Iteration[005/008] Valid loss: 0.0737
2023-02-06 11:27:09 | Valid | Epoch[102/600] Iteration[006/008] Valid loss: 0.0727
2023-02-06 11:27:09 | Valid | Epoch[102/600] Iteration[007/008] Valid loss: 0.0713
2023-02-06 11:27:09 | Valid | Epoch[102/600] Iteration[008/008] Valid loss: 0.0727
2023-02-06 11:27:09 | Valid | Epoch[102/600] MIou: 0.8101554480261984
2023-02-06 11:27:09 | Valid | Epoch[102/600] Pixel Accuracy: 0.9687093098958334
2023-02-06 11:27:09 | Valid | Epoch[102/600] Mean Pixel Accuracy: 0.8267940006483703
2023-02-06 11:27:09 | Stage | Epoch[102/600] Train loss:0.0503
2023-02-06 11:27:09 | Stage | Epoch[102/600] Valid loss:0.0727
2023-02-06 11:27:09 | Stage | Epoch[102/600] LR:0.01

2023-02-06 11:27:09 | Train | Epoch[103/600] Iteration[001/030] Train loss: 0.0492
2023-02-06 11:27:09 | Train | Epoch[103/600] Iteration[002/030] Train loss: 0.0496
2023-02-06 11:27:09 | Train | Epoch[103/600] Iteration[003/030] Train loss: 0.0493
2023-02-06 11:27:09 | Train | Epoch[103/600] Iteration[004/030] Train loss: 0.0490
2023-02-06 11:27:09 | Train | Epoch[103/600] Iteration[005/030] Train loss: 0.0490
2023-02-06 11:27:09 | Train | Epoch[103/600] Iteration[006/030] Train loss: 0.0489
2023-02-06 11:27:09 | Train | Epoch[103/600] Iteration[007/030] Train loss: 0.0492
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[008/030] Train loss: 0.0491
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[009/030] Train loss: 0.0494
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[010/030] Train loss: 0.0491
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[011/030] Train loss: 0.0494
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[012/030] Train loss: 0.0494
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[013/030] Train loss: 0.0494
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[014/030] Train loss: 0.0494
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[015/030] Train loss: 0.0492
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[016/030] Train loss: 0.0496
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[017/030] Train loss: 0.0498
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[018/030] Train loss: 0.0497
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[019/030] Train loss: 0.0496
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[020/030] Train loss: 0.0495
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[021/030] Train loss: 0.0495
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[022/030] Train loss: 0.0497
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[023/030] Train loss: 0.0498
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[024/030] Train loss: 0.0497
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[025/030] Train loss: 0.0497
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[026/030] Train loss: 0.0497
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[027/030] Train loss: 0.0496
2023-02-06 11:27:10 | Train | Epoch[103/600] Iteration[028/030] Train loss: 0.0497
2023-02-06 11:27:11 | Train | Epoch[103/600] Iteration[029/030] Train loss: 0.0497
2023-02-06 11:27:11 | Train | Epoch[103/600] Iteration[030/030] Train loss: 0.0496
2023-02-06 11:27:11 | Valid | Epoch[103/600] Iteration[001/008] Valid loss: 0.2170
2023-02-06 11:27:11 | Valid | Epoch[103/600] Iteration[002/008] Valid loss: 0.1710
2023-02-06 11:27:11 | Valid | Epoch[103/600] Iteration[003/008] Valid loss: 0.1566
2023-02-06 11:27:11 | Valid | Epoch[103/600] Iteration[004/008] Valid loss: 0.1524
2023-02-06 11:27:11 | Valid | Epoch[103/600] Iteration[005/008] Valid loss: 0.1569
2023-02-06 11:27:11 | Valid | Epoch[103/600] Iteration[006/008] Valid loss: 0.1512
2023-02-06 11:27:11 | Valid | Epoch[103/600] Iteration[007/008] Valid loss: 0.1557
2023-02-06 11:27:11 | Valid | Epoch[103/600] Iteration[008/008] Valid loss: 0.1565
2023-02-06 11:27:11 | Valid | Epoch[103/600] MIou: 0.9222804402466298
2023-02-06 11:27:11 | Valid | Epoch[103/600] Pixel Accuracy: 0.9856770833333334
2023-02-06 11:27:11 | Valid | Epoch[103/600] Mean Pixel Accuracy: 0.9814691815305723
2023-02-06 11:27:11 | Stage | Epoch[103/600] Train loss:0.0496
2023-02-06 11:27:11 | Stage | Epoch[103/600] Valid loss:0.1565
2023-02-06 11:27:11 | Stage | Epoch[103/600] LR:0.01

2023-02-06 11:27:11 | Train | Epoch[104/600] Iteration[001/030] Train loss: 0.0490
2023-02-06 11:27:11 | Train | Epoch[104/600] Iteration[002/030] Train loss: 0.0474
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[003/030] Train loss: 0.0473
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[004/030] Train loss: 0.0480
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[005/030] Train loss: 0.0484
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[006/030] Train loss: 0.0486
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[007/030] Train loss: 0.0484
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[008/030] Train loss: 0.0484
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[009/030] Train loss: 0.0484
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[010/030] Train loss: 0.0487
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[011/030] Train loss: 0.0485
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[012/030] Train loss: 0.0487
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[013/030] Train loss: 0.0486
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[014/030] Train loss: 0.0489
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[015/030] Train loss: 0.0490
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[016/030] Train loss: 0.0490
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[017/030] Train loss: 0.0492
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[018/030] Train loss: 0.0491
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[019/030] Train loss: 0.0489
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[020/030] Train loss: 0.0490
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[021/030] Train loss: 0.0490
2023-02-06 11:27:12 | Train | Epoch[104/600] Iteration[022/030] Train loss: 0.0491
2023-02-06 11:27:13 | Train | Epoch[104/600] Iteration[023/030] Train loss: 0.0492
2023-02-06 11:27:13 | Train | Epoch[104/600] Iteration[024/030] Train loss: 0.0492
2023-02-06 11:27:13 | Train | Epoch[104/600] Iteration[025/030] Train loss: 0.0492
2023-02-06 11:27:13 | Train | Epoch[104/600] Iteration[026/030] Train loss: 0.0493
2023-02-06 11:27:13 | Train | Epoch[104/600] Iteration[027/030] Train loss: 0.0494
2023-02-06 11:27:13 | Train | Epoch[104/600] Iteration[028/030] Train loss: 0.0495
2023-02-06 11:27:13 | Train | Epoch[104/600] Iteration[029/030] Train loss: 0.0497
2023-02-06 11:27:13 | Train | Epoch[104/600] Iteration[030/030] Train loss: 0.0497
2023-02-06 11:27:13 | Valid | Epoch[104/600] Iteration[001/008] Valid loss: 0.0587
2023-02-06 11:27:13 | Valid | Epoch[104/600] Iteration[002/008] Valid loss: 0.0568
2023-02-06 11:27:13 | Valid | Epoch[104/600] Iteration[003/008] Valid loss: 0.0551
2023-02-06 11:27:13 | Valid | Epoch[104/600] Iteration[004/008] Valid loss: 0.0543
2023-02-06 11:27:13 | Valid | Epoch[104/600] Iteration[005/008] Valid loss: 0.0551
2023-02-06 11:27:13 | Valid | Epoch[104/600] Iteration[006/008] Valid loss: 0.0547
2023-02-06 11:27:13 | Valid | Epoch[104/600] Iteration[007/008] Valid loss: 0.0543
2023-02-06 11:27:13 | Valid | Epoch[104/600] Iteration[008/008] Valid loss: 0.0542
2023-02-06 11:27:14 | Valid | Epoch[104/600] MIou: 0.9117981183764575
2023-02-06 11:27:14 | Valid | Epoch[104/600] Pixel Accuracy: 0.9853019714355469
2023-02-06 11:27:14 | Valid | Epoch[104/600] Mean Pixel Accuracy: 0.9249596170061447
2023-02-06 11:27:14 | Stage | Epoch[104/600] Train loss:0.0497
2023-02-06 11:27:14 | Stage | Epoch[104/600] Valid loss:0.0542
2023-02-06 11:27:14 | Stage | Epoch[104/600] LR:0.01

2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[001/030] Train loss: 0.0486
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[002/030] Train loss: 0.0485
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[003/030] Train loss: 0.0484
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[004/030] Train loss: 0.0486
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[005/030] Train loss: 0.0485
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[006/030] Train loss: 0.0491
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[007/030] Train loss: 0.0496
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[008/030] Train loss: 0.0495
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[009/030] Train loss: 0.0493
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[010/030] Train loss: 0.0492
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[011/030] Train loss: 0.0492
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[012/030] Train loss: 0.0492
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[013/030] Train loss: 0.0490
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[014/030] Train loss: 0.0488
2023-02-06 11:27:14 | Train | Epoch[105/600] Iteration[015/030] Train loss: 0.0489
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[016/030] Train loss: 0.0489
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[017/030] Train loss: 0.0488
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[018/030] Train loss: 0.0489
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[019/030] Train loss: 0.0490
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[020/030] Train loss: 0.0489
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[021/030] Train loss: 0.0489
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[022/030] Train loss: 0.0490
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[023/030] Train loss: 0.0492
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[024/030] Train loss: 0.0491
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[025/030] Train loss: 0.0490
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[026/030] Train loss: 0.0489
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[027/030] Train loss: 0.0490
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[028/030] Train loss: 0.0490
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[029/030] Train loss: 0.0490
2023-02-06 11:27:15 | Train | Epoch[105/600] Iteration[030/030] Train loss: 0.0489
2023-02-06 11:27:16 | Valid | Epoch[105/600] Iteration[001/008] Valid loss: 0.2419
2023-02-06 11:27:16 | Valid | Epoch[105/600] Iteration[002/008] Valid loss: 0.2458
2023-02-06 11:27:16 | Valid | Epoch[105/600] Iteration[003/008] Valid loss: 0.2593
2023-02-06 11:27:16 | Valid | Epoch[105/600] Iteration[004/008] Valid loss: 0.2571
2023-02-06 11:27:16 | Valid | Epoch[105/600] Iteration[005/008] Valid loss: 0.2645
2023-02-06 11:27:16 | Valid | Epoch[105/600] Iteration[006/008] Valid loss: 0.2616
2023-02-06 11:27:16 | Valid | Epoch[105/600] Iteration[007/008] Valid loss: 0.2595
2023-02-06 11:27:16 | Valid | Epoch[105/600] Iteration[008/008] Valid loss: 0.2692
2023-02-06 11:27:16 | Valid | Epoch[105/600] MIou: 0.45728634785282696
2023-02-06 11:27:16 | Valid | Epoch[105/600] Pixel Accuracy: 0.9100901285807291
2023-02-06 11:27:16 | Valid | Epoch[105/600] Mean Pixel Accuracy: 0.5022596404285573
2023-02-06 11:27:16 | Stage | Epoch[105/600] Train loss:0.0489
2023-02-06 11:27:16 | Stage | Epoch[105/600] Valid loss:0.2692
2023-02-06 11:27:16 | Stage | Epoch[105/600] LR:0.01

2023-02-06 11:27:16 | Train | Epoch[106/600] Iteration[001/030] Train loss: 0.0493
2023-02-06 11:27:16 | Train | Epoch[106/600] Iteration[002/030] Train loss: 0.0496
2023-02-06 11:27:16 | Train | Epoch[106/600] Iteration[003/030] Train loss: 0.0482
2023-02-06 11:27:16 | Train | Epoch[106/600] Iteration[004/030] Train loss: 0.0486
2023-02-06 11:27:16 | Train | Epoch[106/600] Iteration[005/030] Train loss: 0.0481
2023-02-06 11:27:16 | Train | Epoch[106/600] Iteration[006/030] Train loss: 0.0475
2023-02-06 11:27:16 | Train | Epoch[106/600] Iteration[007/030] Train loss: 0.0471
2023-02-06 11:27:16 | Train | Epoch[106/600] Iteration[008/030] Train loss: 0.0474
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[009/030] Train loss: 0.0477
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[010/030] Train loss: 0.0481
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[011/030] Train loss: 0.0480
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[012/030] Train loss: 0.0481
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[013/030] Train loss: 0.0481
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[014/030] Train loss: 0.0481
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[015/030] Train loss: 0.0483
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[016/030] Train loss: 0.0482
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[017/030] Train loss: 0.0482
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[018/030] Train loss: 0.0481
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[019/030] Train loss: 0.0480
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[020/030] Train loss: 0.0480
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[021/030] Train loss: 0.0482
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[022/030] Train loss: 0.0483
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[023/030] Train loss: 0.0483
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[024/030] Train loss: 0.0484
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[025/030] Train loss: 0.0483
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[026/030] Train loss: 0.0484
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[027/030] Train loss: 0.0484
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[028/030] Train loss: 0.0483
2023-02-06 11:27:17 | Train | Epoch[106/600] Iteration[029/030] Train loss: 0.0483
2023-02-06 11:27:18 | Train | Epoch[106/600] Iteration[030/030] Train loss: 0.0482
2023-02-06 11:27:18 | Valid | Epoch[106/600] Iteration[001/008] Valid loss: 0.0996
2023-02-06 11:27:18 | Valid | Epoch[106/600] Iteration[002/008] Valid loss: 0.1046
2023-02-06 11:27:18 | Valid | Epoch[106/600] Iteration[003/008] Valid loss: 0.1080
2023-02-06 11:27:18 | Valid | Epoch[106/600] Iteration[004/008] Valid loss: 0.1062
2023-02-06 11:27:18 | Valid | Epoch[106/600] Iteration[005/008] Valid loss: 0.1092
2023-02-06 11:27:18 | Valid | Epoch[106/600] Iteration[006/008] Valid loss: 0.1076
2023-02-06 11:27:18 | Valid | Epoch[106/600] Iteration[007/008] Valid loss: 0.1057
2023-02-06 11:27:18 | Valid | Epoch[106/600] Iteration[008/008] Valid loss: 0.1091
2023-02-06 11:27:18 | Valid | Epoch[106/600] MIou: 0.6701069001133569
2023-02-06 11:27:18 | Valid | Epoch[106/600] Pixel Accuracy: 0.9455134073893229
2023-02-06 11:27:18 | Valid | Epoch[106/600] Mean Pixel Accuracy: 0.6983626406115812
2023-02-06 11:27:18 | Stage | Epoch[106/600] Train loss:0.0482
2023-02-06 11:27:18 | Stage | Epoch[106/600] Valid loss:0.1091
2023-02-06 11:27:18 | Stage | Epoch[106/600] LR:0.01

2023-02-06 11:27:18 | Train | Epoch[107/600] Iteration[001/030] Train loss: 0.0483
2023-02-06 11:27:18 | Train | Epoch[107/600] Iteration[002/030] Train loss: 0.0478
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[003/030] Train loss: 0.0485
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[004/030] Train loss: 0.0483
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[005/030] Train loss: 0.0484
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[006/030] Train loss: 0.0481
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[007/030] Train loss: 0.0479
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[008/030] Train loss: 0.0475
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[009/030] Train loss: 0.0483
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[010/030] Train loss: 0.0482
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[011/030] Train loss: 0.0484
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[012/030] Train loss: 0.0482
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[013/030] Train loss: 0.0481
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[014/030] Train loss: 0.0481
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[015/030] Train loss: 0.0479
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[016/030] Train loss: 0.0479
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[017/030] Train loss: 0.0478
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[018/030] Train loss: 0.0481
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[019/030] Train loss: 0.0481
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[020/030] Train loss: 0.0480
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[021/030] Train loss: 0.0480
2023-02-06 11:27:19 | Train | Epoch[107/600] Iteration[022/030] Train loss: 0.0479
2023-02-06 11:27:20 | Train | Epoch[107/600] Iteration[023/030] Train loss: 0.0478
2023-02-06 11:27:20 | Train | Epoch[107/600] Iteration[024/030] Train loss: 0.0477
2023-02-06 11:27:20 | Train | Epoch[107/600] Iteration[025/030] Train loss: 0.0477
2023-02-06 11:27:20 | Train | Epoch[107/600] Iteration[026/030] Train loss: 0.0477
2023-02-06 11:27:20 | Train | Epoch[107/600] Iteration[027/030] Train loss: 0.0477
2023-02-06 11:27:20 | Train | Epoch[107/600] Iteration[028/030] Train loss: 0.0477
2023-02-06 11:27:20 | Train | Epoch[107/600] Iteration[029/030] Train loss: 0.0476
2023-02-06 11:27:20 | Train | Epoch[107/600] Iteration[030/030] Train loss: 0.0476
2023-02-06 11:27:20 | Valid | Epoch[107/600] Iteration[001/008] Valid loss: 0.0577
2023-02-06 11:27:20 | Valid | Epoch[107/600] Iteration[002/008] Valid loss: 0.0546
2023-02-06 11:27:20 | Valid | Epoch[107/600] Iteration[003/008] Valid loss: 0.0542
2023-02-06 11:27:20 | Valid | Epoch[107/600] Iteration[004/008] Valid loss: 0.0535
2023-02-06 11:27:20 | Valid | Epoch[107/600] Iteration[005/008] Valid loss: 0.0545
2023-02-06 11:27:20 | Valid | Epoch[107/600] Iteration[006/008] Valid loss: 0.0541
2023-02-06 11:27:20 | Valid | Epoch[107/600] Iteration[007/008] Valid loss: 0.0541
2023-02-06 11:27:20 | Valid | Epoch[107/600] Iteration[008/008] Valid loss: 0.0541
2023-02-06 11:27:20 | Valid | Epoch[107/600] MIou: 0.9058565847125122
2023-02-06 11:27:20 | Valid | Epoch[107/600] Pixel Accuracy: 0.9844169616699219
2023-02-06 11:27:20 | Valid | Epoch[107/600] Mean Pixel Accuracy: 0.9166236741622489
2023-02-06 11:27:20 | Stage | Epoch[107/600] Train loss:0.0476
2023-02-06 11:27:20 | Stage | Epoch[107/600] Valid loss:0.0541
2023-02-06 11:27:20 | Stage | Epoch[107/600] LR:0.01

2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[001/030] Train loss: 0.0444
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[002/030] Train loss: 0.0462
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[003/030] Train loss: 0.0473
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[004/030] Train loss: 0.0473
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[005/030] Train loss: 0.0473
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[006/030] Train loss: 0.0471
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[007/030] Train loss: 0.0474
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[008/030] Train loss: 0.0472
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[009/030] Train loss: 0.0472
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[010/030] Train loss: 0.0470
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[011/030] Train loss: 0.0470
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[012/030] Train loss: 0.0471
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[013/030] Train loss: 0.0472
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[014/030] Train loss: 0.0471
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[015/030] Train loss: 0.0471
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[016/030] Train loss: 0.0471
2023-02-06 11:27:21 | Train | Epoch[108/600] Iteration[017/030] Train loss: 0.0472
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[018/030] Train loss: 0.0471
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[019/030] Train loss: 0.0472
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[020/030] Train loss: 0.0471
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[021/030] Train loss: 0.0471
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[022/030] Train loss: 0.0472
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[023/030] Train loss: 0.0471
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[024/030] Train loss: 0.0470
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[025/030] Train loss: 0.0471
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[026/030] Train loss: 0.0472
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[027/030] Train loss: 0.0473
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[028/030] Train loss: 0.0473
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[029/030] Train loss: 0.0472
2023-02-06 11:27:22 | Train | Epoch[108/600] Iteration[030/030] Train loss: 0.0474
2023-02-06 11:27:22 | Valid | Epoch[108/600] Iteration[001/008] Valid loss: 0.0646
2023-02-06 11:27:22 | Valid | Epoch[108/600] Iteration[002/008] Valid loss: 0.0567
2023-02-06 11:27:22 | Valid | Epoch[108/600] Iteration[003/008] Valid loss: 0.0549
2023-02-06 11:27:22 | Valid | Epoch[108/600] Iteration[004/008] Valid loss: 0.0543
2023-02-06 11:27:22 | Valid | Epoch[108/600] Iteration[005/008] Valid loss: 0.0556
2023-02-06 11:27:23 | Valid | Epoch[108/600] Iteration[006/008] Valid loss: 0.0551
2023-02-06 11:27:23 | Valid | Epoch[108/600] Iteration[007/008] Valid loss: 0.0560
2023-02-06 11:27:23 | Valid | Epoch[108/600] Iteration[008/008] Valid loss: 0.0553
2023-02-06 11:27:23 | Valid | Epoch[108/600] MIou: 0.9373186816168901
2023-02-06 11:27:23 | Valid | Epoch[108/600] Pixel Accuracy: 0.9893760681152344
2023-02-06 11:27:23 | Valid | Epoch[108/600] Mean Pixel Accuracy: 0.9564158070249856
2023-02-06 11:27:23 | Stage | Epoch[108/600] Train loss:0.0474
2023-02-06 11:27:23 | Stage | Epoch[108/600] Valid loss:0.0553
2023-02-06 11:27:23 | Stage | Epoch[108/600] LR:0.01

2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[001/030] Train loss: 0.0444
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[002/030] Train loss: 0.0453
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[003/030] Train loss: 0.0449
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[004/030] Train loss: 0.0453
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[005/030] Train loss: 0.0453
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[006/030] Train loss: 0.0453
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[007/030] Train loss: 0.0458
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[008/030] Train loss: 0.0461
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[009/030] Train loss: 0.0460
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[010/030] Train loss: 0.0463
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[011/030] Train loss: 0.0462
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[012/030] Train loss: 0.0463
2023-02-06 11:27:23 | Train | Epoch[109/600] Iteration[013/030] Train loss: 0.0461
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[014/030] Train loss: 0.0464
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[015/030] Train loss: 0.0463
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[016/030] Train loss: 0.0464
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[017/030] Train loss: 0.0463
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[018/030] Train loss: 0.0466
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[019/030] Train loss: 0.0467
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[020/030] Train loss: 0.0466
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[021/030] Train loss: 0.0465
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[022/030] Train loss: 0.0466
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[023/030] Train loss: 0.0466
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[024/030] Train loss: 0.0466
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[025/030] Train loss: 0.0465
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[026/030] Train loss: 0.0467
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[027/030] Train loss: 0.0466
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[028/030] Train loss: 0.0466
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[029/030] Train loss: 0.0466
2023-02-06 11:27:24 | Train | Epoch[109/600] Iteration[030/030] Train loss: 0.0466
2023-02-06 11:27:25 | Valid | Epoch[109/600] Iteration[001/008] Valid loss: 0.0605
2023-02-06 11:27:25 | Valid | Epoch[109/600] Iteration[002/008] Valid loss: 0.0568
2023-02-06 11:27:25 | Valid | Epoch[109/600] Iteration[003/008] Valid loss: 0.0567
2023-02-06 11:27:25 | Valid | Epoch[109/600] Iteration[004/008] Valid loss: 0.0557
2023-02-06 11:27:25 | Valid | Epoch[109/600] Iteration[005/008] Valid loss: 0.0566
2023-02-06 11:27:25 | Valid | Epoch[109/600] Iteration[006/008] Valid loss: 0.0563
2023-02-06 11:27:25 | Valid | Epoch[109/600] Iteration[007/008] Valid loss: 0.0559
2023-02-06 11:27:25 | Valid | Epoch[109/600] Iteration[008/008] Valid loss: 0.0561
2023-02-06 11:27:25 | Valid | Epoch[109/600] MIou: 0.8914236789997882
2023-02-06 11:27:25 | Valid | Epoch[109/600] Pixel Accuracy: 0.9820874532063802
2023-02-06 11:27:25 | Valid | Epoch[109/600] Mean Pixel Accuracy: 0.9019522011260408
2023-02-06 11:27:25 | Stage | Epoch[109/600] Train loss:0.0466
2023-02-06 11:27:25 | Stage | Epoch[109/600] Valid loss:0.0561
2023-02-06 11:27:25 | Stage | Epoch[109/600] LR:0.01

2023-02-06 11:27:25 | Train | Epoch[110/600] Iteration[001/030] Train loss: 0.0434
2023-02-06 11:27:25 | Train | Epoch[110/600] Iteration[002/030] Train loss: 0.0470
2023-02-06 11:27:25 | Train | Epoch[110/600] Iteration[003/030] Train loss: 0.0463
2023-02-06 11:27:25 | Train | Epoch[110/600] Iteration[004/030] Train loss: 0.0461
2023-02-06 11:27:25 | Train | Epoch[110/600] Iteration[005/030] Train loss: 0.0459
2023-02-06 11:27:25 | Train | Epoch[110/600] Iteration[006/030] Train loss: 0.0465
2023-02-06 11:27:25 | Train | Epoch[110/600] Iteration[007/030] Train loss: 0.0467
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[008/030] Train loss: 0.0467
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[009/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[010/030] Train loss: 0.0474
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[011/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[012/030] Train loss: 0.0470
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[013/030] Train loss: 0.0470
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[014/030] Train loss: 0.0474
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[015/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[016/030] Train loss: 0.0469
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[017/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[018/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[019/030] Train loss: 0.0470
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[020/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[021/030] Train loss: 0.0472
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[022/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[023/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[024/030] Train loss: 0.0472
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[025/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[026/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[027/030] Train loss: 0.0471
2023-02-06 11:27:26 | Train | Epoch[110/600] Iteration[028/030] Train loss: 0.0470
2023-02-06 11:27:27 | Train | Epoch[110/600] Iteration[029/030] Train loss: 0.0470
2023-02-06 11:27:27 | Train | Epoch[110/600] Iteration[030/030] Train loss: 0.0469
2023-02-06 11:27:27 | Valid | Epoch[110/600] Iteration[001/008] Valid loss: 0.0727
2023-02-06 11:27:27 | Valid | Epoch[110/600] Iteration[002/008] Valid loss: 0.0717
2023-02-06 11:27:27 | Valid | Epoch[110/600] Iteration[003/008] Valid loss: 0.0718
2023-02-06 11:27:27 | Valid | Epoch[110/600] Iteration[004/008] Valid loss: 0.0701
2023-02-06 11:27:27 | Valid | Epoch[110/600] Iteration[005/008] Valid loss: 0.0712
2023-02-06 11:27:27 | Valid | Epoch[110/600] Iteration[006/008] Valid loss: 0.0711
2023-02-06 11:27:27 | Valid | Epoch[110/600] Iteration[007/008] Valid loss: 0.0702
2023-02-06 11:27:27 | Valid | Epoch[110/600] Iteration[008/008] Valid loss: 0.0713
2023-02-06 11:27:27 | Valid | Epoch[110/600] MIou: 0.8190807703344158
2023-02-06 11:27:27 | Valid | Epoch[110/600] Pixel Accuracy: 0.9701156616210938
2023-02-06 11:27:27 | Valid | Epoch[110/600] Mean Pixel Accuracy: 0.8357271783720706
2023-02-06 11:27:27 | Stage | Epoch[110/600] Train loss:0.0469
2023-02-06 11:27:27 | Stage | Epoch[110/600] Valid loss:0.0713
2023-02-06 11:27:27 | Stage | Epoch[110/600] LR:0.01

2023-02-06 11:27:27 | Train | Epoch[111/600] Iteration[001/030] Train loss: 0.0436
2023-02-06 11:27:27 | Train | Epoch[111/600] Iteration[002/030] Train loss: 0.0444
2023-02-06 11:27:27 | Train | Epoch[111/600] Iteration[003/030] Train loss: 0.0447
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[004/030] Train loss: 0.0453
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[005/030] Train loss: 0.0466
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[006/030] Train loss: 0.0459
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[007/030] Train loss: 0.0460
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[008/030] Train loss: 0.0463
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[009/030] Train loss: 0.0460
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[010/030] Train loss: 0.0462
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[011/030] Train loss: 0.0462
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[012/030] Train loss: 0.0463
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[013/030] Train loss: 0.0461
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[014/030] Train loss: 0.0459
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[015/030] Train loss: 0.0460
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[016/030] Train loss: 0.0458
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[017/030] Train loss: 0.0457
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[018/030] Train loss: 0.0457
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[019/030] Train loss: 0.0455
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[020/030] Train loss: 0.0455
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[021/030] Train loss: 0.0455
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[022/030] Train loss: 0.0454
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[023/030] Train loss: 0.0456
2023-02-06 11:27:28 | Train | Epoch[111/600] Iteration[024/030] Train loss: 0.0456
2023-02-06 11:27:29 | Train | Epoch[111/600] Iteration[025/030] Train loss: 0.0456
2023-02-06 11:27:29 | Train | Epoch[111/600] Iteration[026/030] Train loss: 0.0457
2023-02-06 11:27:29 | Train | Epoch[111/600] Iteration[027/030] Train loss: 0.0457
2023-02-06 11:27:29 | Train | Epoch[111/600] Iteration[028/030] Train loss: 0.0459
2023-02-06 11:27:29 | Train | Epoch[111/600] Iteration[029/030] Train loss: 0.0461
2023-02-06 11:27:29 | Train | Epoch[111/600] Iteration[030/030] Train loss: 0.0463
2023-02-06 11:27:29 | Valid | Epoch[111/600] Iteration[001/008] Valid loss: 0.5320
2023-02-06 11:27:29 | Valid | Epoch[111/600] Iteration[002/008] Valid loss: 0.4607
2023-02-06 11:27:29 | Valid | Epoch[111/600] Iteration[003/008] Valid loss: 0.4634
2023-02-06 11:27:29 | Valid | Epoch[111/600] Iteration[004/008] Valid loss: 0.4683
2023-02-06 11:27:29 | Valid | Epoch[111/600] Iteration[005/008] Valid loss: 0.4892
2023-02-06 11:27:29 | Valid | Epoch[111/600] Iteration[006/008] Valid loss: 0.4657
2023-02-06 11:27:29 | Valid | Epoch[111/600] Iteration[007/008] Valid loss: 0.4934
2023-02-06 11:27:29 | Valid | Epoch[111/600] Iteration[008/008] Valid loss: 0.5052
2023-02-06 11:27:29 | Valid | Epoch[111/600] MIou: 0.8817622535994984
2023-02-06 11:27:29 | Valid | Epoch[111/600] Pixel Accuracy: 0.9762598673502604
2023-02-06 11:27:29 | Valid | Epoch[111/600] Mean Pixel Accuracy: 0.9808074937083286
2023-02-06 11:27:29 | Stage | Epoch[111/600] Train loss:0.0463
2023-02-06 11:27:29 | Stage | Epoch[111/600] Valid loss:0.5052
2023-02-06 11:27:29 | Stage | Epoch[111/600] LR:0.01

2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[001/030] Train loss: 0.0469
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[002/030] Train loss: 0.0457
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[003/030] Train loss: 0.0461
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[004/030] Train loss: 0.0475
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[005/030] Train loss: 0.0471
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[006/030] Train loss: 0.0466
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[007/030] Train loss: 0.0468
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[008/030] Train loss: 0.0465
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[009/030] Train loss: 0.0464
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[010/030] Train loss: 0.0461
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[011/030] Train loss: 0.0462
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[012/030] Train loss: 0.0462
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[013/030] Train loss: 0.0462
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[014/030] Train loss: 0.0461
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[015/030] Train loss: 0.0462
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[016/030] Train loss: 0.0460
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[017/030] Train loss: 0.0458
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[018/030] Train loss: 0.0457
2023-02-06 11:27:30 | Train | Epoch[112/600] Iteration[019/030] Train loss: 0.0457
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[020/030] Train loss: 0.0459
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[021/030] Train loss: 0.0458
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[022/030] Train loss: 0.0458
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[023/030] Train loss: 0.0459
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[024/030] Train loss: 0.0459
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[025/030] Train loss: 0.0457
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[026/030] Train loss: 0.0457
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[027/030] Train loss: 0.0456
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[028/030] Train loss: 0.0456
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[029/030] Train loss: 0.0455
2023-02-06 11:27:31 | Train | Epoch[112/600] Iteration[030/030] Train loss: 0.0456
2023-02-06 11:27:31 | Valid | Epoch[112/600] Iteration[001/008] Valid loss: 0.0662
2023-02-06 11:27:31 | Valid | Epoch[112/600] Iteration[002/008] Valid loss: 0.0601
2023-02-06 11:27:31 | Valid | Epoch[112/600] Iteration[003/008] Valid loss: 0.0587
2023-02-06 11:27:31 | Valid | Epoch[112/600] Iteration[004/008] Valid loss: 0.0575
2023-02-06 11:27:31 | Valid | Epoch[112/600] Iteration[005/008] Valid loss: 0.0585
2023-02-06 11:27:31 | Valid | Epoch[112/600] Iteration[006/008] Valid loss: 0.0578
2023-02-06 11:27:31 | Valid | Epoch[112/600] Iteration[007/008] Valid loss: 0.0583
2023-02-06 11:27:31 | Valid | Epoch[112/600] Iteration[008/008] Valid loss: 0.0582
2023-02-06 11:27:32 | Valid | Epoch[112/600] MIou: 0.9008890877340201
2023-02-06 11:27:32 | Valid | Epoch[112/600] Pixel Accuracy: 0.9834747314453125
2023-02-06 11:27:32 | Valid | Epoch[112/600] Mean Pixel Accuracy: 0.915040585031627
2023-02-06 11:27:32 | Stage | Epoch[112/600] Train loss:0.0456
2023-02-06 11:27:32 | Stage | Epoch[112/600] Valid loss:0.0582
2023-02-06 11:27:32 | Stage | Epoch[112/600] LR:0.01

2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[001/030] Train loss: 0.0426
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[002/030] Train loss: 0.0429
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[003/030] Train loss: 0.0427
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[004/030] Train loss: 0.0434
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[005/030] Train loss: 0.0439
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[006/030] Train loss: 0.0442
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[007/030] Train loss: 0.0443
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[008/030] Train loss: 0.0442
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[009/030] Train loss: 0.0447
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[010/030] Train loss: 0.0447
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[011/030] Train loss: 0.0447
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[012/030] Train loss: 0.0444
2023-02-06 11:27:32 | Train | Epoch[113/600] Iteration[013/030] Train loss: 0.0446
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[014/030] Train loss: 0.0445
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[015/030] Train loss: 0.0446
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[016/030] Train loss: 0.0448
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[017/030] Train loss: 0.0448
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[018/030] Train loss: 0.0447
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[019/030] Train loss: 0.0447
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[020/030] Train loss: 0.0446
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[021/030] Train loss: 0.0444
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[022/030] Train loss: 0.0446
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[023/030] Train loss: 0.0448
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[024/030] Train loss: 0.0450
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[025/030] Train loss: 0.0450
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[026/030] Train loss: 0.0451
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[027/030] Train loss: 0.0450
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[028/030] Train loss: 0.0450
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[029/030] Train loss: 0.0449
2023-02-06 11:27:33 | Train | Epoch[113/600] Iteration[030/030] Train loss: 0.0449
2023-02-06 11:27:34 | Valid | Epoch[113/600] Iteration[001/008] Valid loss: 0.4224
2023-02-06 11:27:34 | Valid | Epoch[113/600] Iteration[002/008] Valid loss: 0.3728
2023-02-06 11:27:34 | Valid | Epoch[113/600] Iteration[003/008] Valid loss: 0.3604
2023-02-06 11:27:34 | Valid | Epoch[113/600] Iteration[004/008] Valid loss: 0.3686
2023-02-06 11:27:34 | Valid | Epoch[113/600] Iteration[005/008] Valid loss: 0.3817
2023-02-06 11:27:34 | Valid | Epoch[113/600] Iteration[006/008] Valid loss: 0.3718
2023-02-06 11:27:34 | Valid | Epoch[113/600] Iteration[007/008] Valid loss: 0.3873
2023-02-06 11:27:34 | Valid | Epoch[113/600] Iteration[008/008] Valid loss: 0.3894
2023-02-06 11:27:34 | Valid | Epoch[113/600] MIou: 0.8766457864344589
2023-02-06 11:27:34 | Valid | Epoch[113/600] Pixel Accuracy: 0.9748344421386719
2023-02-06 11:27:34 | Valid | Epoch[113/600] Mean Pixel Accuracy: 0.9831498716745799
2023-02-06 11:27:34 | Stage | Epoch[113/600] Train loss:0.0449
2023-02-06 11:27:34 | Stage | Epoch[113/600] Valid loss:0.3894
2023-02-06 11:27:34 | Stage | Epoch[113/600] LR:0.01

2023-02-06 11:27:34 | Train | Epoch[114/600] Iteration[001/030] Train loss: 0.0421
2023-02-06 11:27:34 | Train | Epoch[114/600] Iteration[002/030] Train loss: 0.0430
2023-02-06 11:27:34 | Train | Epoch[114/600] Iteration[003/030] Train loss: 0.0433
2023-02-06 11:27:34 | Train | Epoch[114/600] Iteration[004/030] Train loss: 0.0433
2023-02-06 11:27:34 | Train | Epoch[114/600] Iteration[005/030] Train loss: 0.0437
2023-02-06 11:27:34 | Train | Epoch[114/600] Iteration[006/030] Train loss: 0.0440
2023-02-06 11:27:34 | Train | Epoch[114/600] Iteration[007/030] Train loss: 0.0441
2023-02-06 11:27:34 | Train | Epoch[114/600] Iteration[008/030] Train loss: 0.0437
2023-02-06 11:27:34 | Train | Epoch[114/600] Iteration[009/030] Train loss: 0.0438
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[010/030] Train loss: 0.0438
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[011/030] Train loss: 0.0440
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[012/030] Train loss: 0.0441
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[013/030] Train loss: 0.0441
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[014/030] Train loss: 0.0439
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[015/030] Train loss: 0.0438
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[016/030] Train loss: 0.0437
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[017/030] Train loss: 0.0439
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[018/030] Train loss: 0.0440
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[019/030] Train loss: 0.0438
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[020/030] Train loss: 0.0440
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[021/030] Train loss: 0.0441
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[022/030] Train loss: 0.0440
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[023/030] Train loss: 0.0440
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[024/030] Train loss: 0.0441
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[025/030] Train loss: 0.0440
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[026/030] Train loss: 0.0442
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[027/030] Train loss: 0.0443
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[028/030] Train loss: 0.0443
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[029/030] Train loss: 0.0444
2023-02-06 11:27:35 | Train | Epoch[114/600] Iteration[030/030] Train loss: 0.0443
2023-02-06 11:27:36 | Valid | Epoch[114/600] Iteration[001/008] Valid loss: 0.3989
2023-02-06 11:27:36 | Valid | Epoch[114/600] Iteration[002/008] Valid loss: 0.3413
2023-02-06 11:27:36 | Valid | Epoch[114/600] Iteration[003/008] Valid loss: 0.3322
2023-02-06 11:27:36 | Valid | Epoch[114/600] Iteration[004/008] Valid loss: 0.3269
2023-02-06 11:27:36 | Valid | Epoch[114/600] Iteration[005/008] Valid loss: 0.3409
2023-02-06 11:27:36 | Valid | Epoch[114/600] Iteration[006/008] Valid loss: 0.3263
2023-02-06 11:27:36 | Valid | Epoch[114/600] Iteration[007/008] Valid loss: 0.3411
2023-02-06 11:27:36 | Valid | Epoch[114/600] Iteration[008/008] Valid loss: 0.3504
2023-02-06 11:27:36 | Valid | Epoch[114/600] MIou: 0.8990885947690705
2023-02-06 11:27:36 | Valid | Epoch[114/600] Pixel Accuracy: 0.9804598490397135
2023-02-06 11:27:36 | Valid | Epoch[114/600] Mean Pixel Accuracy: 0.9816323124359121
2023-02-06 11:27:36 | Stage | Epoch[114/600] Train loss:0.0443
2023-02-06 11:27:36 | Stage | Epoch[114/600] Valid loss:0.3504
2023-02-06 11:27:36 | Stage | Epoch[114/600] LR:0.01

2023-02-06 11:27:36 | Train | Epoch[115/600] Iteration[001/030] Train loss: 0.0431
2023-02-06 11:27:36 | Train | Epoch[115/600] Iteration[002/030] Train loss: 0.0456
2023-02-06 11:27:36 | Train | Epoch[115/600] Iteration[003/030] Train loss: 0.0452
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[004/030] Train loss: 0.0456
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[005/030] Train loss: 0.0449
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[006/030] Train loss: 0.0446
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[007/030] Train loss: 0.0444
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[008/030] Train loss: 0.0443
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[009/030] Train loss: 0.0449
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[010/030] Train loss: 0.0454
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[011/030] Train loss: 0.0452
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[012/030] Train loss: 0.0451
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[013/030] Train loss: 0.0454
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[014/030] Train loss: 0.0453
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[015/030] Train loss: 0.0451
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[016/030] Train loss: 0.0452
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[017/030] Train loss: 0.0450
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[018/030] Train loss: 0.0449
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[019/030] Train loss: 0.0449
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[020/030] Train loss: 0.0447
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[021/030] Train loss: 0.0446
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[022/030] Train loss: 0.0444
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[023/030] Train loss: 0.0445
2023-02-06 11:27:37 | Train | Epoch[115/600] Iteration[024/030] Train loss: 0.0444
2023-02-06 11:27:38 | Train | Epoch[115/600] Iteration[025/030] Train loss: 0.0443
2023-02-06 11:27:38 | Train | Epoch[115/600] Iteration[026/030] Train loss: 0.0444
2023-02-06 11:27:38 | Train | Epoch[115/600] Iteration[027/030] Train loss: 0.0445
2023-02-06 11:27:38 | Train | Epoch[115/600] Iteration[028/030] Train loss: 0.0444
2023-02-06 11:27:38 | Train | Epoch[115/600] Iteration[029/030] Train loss: 0.0443
2023-02-06 11:27:38 | Train | Epoch[115/600] Iteration[030/030] Train loss: 0.0443
2023-02-06 11:27:38 | Valid | Epoch[115/600] Iteration[001/008] Valid loss: 0.0595
2023-02-06 11:27:38 | Valid | Epoch[115/600] Iteration[002/008] Valid loss: 0.0581
2023-02-06 11:27:38 | Valid | Epoch[115/600] Iteration[003/008] Valid loss: 0.0575
2023-02-06 11:27:38 | Valid | Epoch[115/600] Iteration[004/008] Valid loss: 0.0562
2023-02-06 11:27:38 | Valid | Epoch[115/600] Iteration[005/008] Valid loss: 0.0569
2023-02-06 11:27:38 | Valid | Epoch[115/600] Iteration[006/008] Valid loss: 0.0566
2023-02-06 11:27:38 | Valid | Epoch[115/600] Iteration[007/008] Valid loss: 0.0557
2023-02-06 11:27:38 | Valid | Epoch[115/600] Iteration[008/008] Valid loss: 0.0563
2023-02-06 11:27:38 | Valid | Epoch[115/600] MIou: 0.8684810457764907
2023-02-06 11:27:38 | Valid | Epoch[115/600] Pixel Accuracy: 0.9782524108886719
2023-02-06 11:27:38 | Valid | Epoch[115/600] Mean Pixel Accuracy: 0.8816915283685448
2023-02-06 11:27:38 | Stage | Epoch[115/600] Train loss:0.0443
2023-02-06 11:27:38 | Stage | Epoch[115/600] Valid loss:0.0563
2023-02-06 11:27:38 | Stage | Epoch[115/600] LR:0.01

2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[001/030] Train loss: 0.0439
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[002/030] Train loss: 0.0435
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[003/030] Train loss: 0.0434
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[004/030] Train loss: 0.0443
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[005/030] Train loss: 0.0436
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[006/030] Train loss: 0.0434
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[007/030] Train loss: 0.0429
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[008/030] Train loss: 0.0432
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[009/030] Train loss: 0.0434
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[010/030] Train loss: 0.0434
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[011/030] Train loss: 0.0436
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[012/030] Train loss: 0.0438
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[013/030] Train loss: 0.0440
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[014/030] Train loss: 0.0441
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[015/030] Train loss: 0.0443
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[016/030] Train loss: 0.0442
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[017/030] Train loss: 0.0441
2023-02-06 11:27:39 | Train | Epoch[116/600] Iteration[018/030] Train loss: 0.0440
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[019/030] Train loss: 0.0442
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[020/030] Train loss: 0.0442
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[021/030] Train loss: 0.0441
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[022/030] Train loss: 0.0440
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[023/030] Train loss: 0.0441
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[024/030] Train loss: 0.0442
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[025/030] Train loss: 0.0440
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[026/030] Train loss: 0.0440
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[027/030] Train loss: 0.0439
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[028/030] Train loss: 0.0439
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[029/030] Train loss: 0.0439
2023-02-06 11:27:40 | Train | Epoch[116/600] Iteration[030/030] Train loss: 0.0439
2023-02-06 11:27:40 | Valid | Epoch[116/600] Iteration[001/008] Valid loss: 0.2846
2023-02-06 11:27:40 | Valid | Epoch[116/600] Iteration[002/008] Valid loss: 0.2521
2023-02-06 11:27:40 | Valid | Epoch[116/600] Iteration[003/008] Valid loss: 0.2387
2023-02-06 11:27:41 | Valid | Epoch[116/600] Iteration[004/008] Valid loss: 0.2379
2023-02-06 11:27:41 | Valid | Epoch[116/600] Iteration[005/008] Valid loss: 0.2446
2023-02-06 11:27:41 | Valid | Epoch[116/600] Iteration[006/008] Valid loss: 0.2349
2023-02-06 11:27:41 | Valid | Epoch[116/600] Iteration[007/008] Valid loss: 0.2434
2023-02-06 11:27:41 | Valid | Epoch[116/600] Iteration[008/008] Valid loss: 0.2500
2023-02-06 11:27:41 | Valid | Epoch[116/600] MIou: 0.8985201186398195
2023-02-06 11:27:41 | Valid | Epoch[116/600] Pixel Accuracy: 0.9803047180175781
2023-02-06 11:27:41 | Valid | Epoch[116/600] Mean Pixel Accuracy: 0.9821684120181522
2023-02-06 11:27:41 | Stage | Epoch[116/600] Train loss:0.0439
2023-02-06 11:27:41 | Stage | Epoch[116/600] Valid loss:0.2500
2023-02-06 11:27:41 | Stage | Epoch[116/600] LR:0.01

2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[001/030] Train loss: 0.0439
2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[002/030] Train loss: 0.0437
2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[003/030] Train loss: 0.0457
2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[004/030] Train loss: 0.0445
2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[005/030] Train loss: 0.0439
2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[006/030] Train loss: 0.0448
2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[007/030] Train loss: 0.0443
2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[008/030] Train loss: 0.0443
2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[009/030] Train loss: 0.0444
2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[010/030] Train loss: 0.0441
2023-02-06 11:27:41 | Train | Epoch[117/600] Iteration[011/030] Train loss: 0.0439
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[012/030] Train loss: 0.0439
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[013/030] Train loss: 0.0438
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[014/030] Train loss: 0.0440
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[015/030] Train loss: 0.0440
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[016/030] Train loss: 0.0439
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[017/030] Train loss: 0.0439
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[018/030] Train loss: 0.0437
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[019/030] Train loss: 0.0438
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[020/030] Train loss: 0.0437
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[021/030] Train loss: 0.0436
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[022/030] Train loss: 0.0435
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[023/030] Train loss: 0.0433
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[024/030] Train loss: 0.0433
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[025/030] Train loss: 0.0433
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[026/030] Train loss: 0.0434
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[027/030] Train loss: 0.0434
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[028/030] Train loss: 0.0434
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[029/030] Train loss: 0.0434
2023-02-06 11:27:42 | Train | Epoch[117/600] Iteration[030/030] Train loss: 0.0435
2023-02-06 11:27:43 | Valid | Epoch[117/600] Iteration[001/008] Valid loss: 0.0670
2023-02-06 11:27:43 | Valid | Epoch[117/600] Iteration[002/008] Valid loss: 0.0658
2023-02-06 11:27:43 | Valid | Epoch[117/600] Iteration[003/008] Valid loss: 0.0661
2023-02-06 11:27:43 | Valid | Epoch[117/600] Iteration[004/008] Valid loss: 0.0651
2023-02-06 11:27:43 | Valid | Epoch[117/600] Iteration[005/008] Valid loss: 0.0662
2023-02-06 11:27:43 | Valid | Epoch[117/600] Iteration[006/008] Valid loss: 0.0654
2023-02-06 11:27:43 | Valid | Epoch[117/600] Iteration[007/008] Valid loss: 0.0648
2023-02-06 11:27:43 | Valid | Epoch[117/600] Iteration[008/008] Valid loss: 0.0655
2023-02-06 11:27:43 | Valid | Epoch[117/600] MIou: 0.841660029938821
2023-02-06 11:27:43 | Valid | Epoch[117/600] Pixel Accuracy: 0.9738807678222656
2023-02-06 11:27:43 | Valid | Epoch[117/600] Mean Pixel Accuracy: 0.8560698802159443
2023-02-06 11:27:43 | Stage | Epoch[117/600] Train loss:0.0435
2023-02-06 11:27:43 | Stage | Epoch[117/600] Valid loss:0.0655
2023-02-06 11:27:43 | Stage | Epoch[117/600] LR:0.01

2023-02-06 11:27:43 | Train | Epoch[118/600] Iteration[001/030] Train loss: 0.0388
2023-02-06 11:27:43 | Train | Epoch[118/600] Iteration[002/030] Train loss: 0.0405
2023-02-06 11:27:43 | Train | Epoch[118/600] Iteration[003/030] Train loss: 0.0417
2023-02-06 11:27:43 | Train | Epoch[118/600] Iteration[004/030] Train loss: 0.0419
2023-02-06 11:27:43 | Train | Epoch[118/600] Iteration[005/030] Train loss: 0.0420
2023-02-06 11:27:43 | Train | Epoch[118/600] Iteration[006/030] Train loss: 0.0419
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[007/030] Train loss: 0.0424
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[008/030] Train loss: 0.0426
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[009/030] Train loss: 0.0425
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[010/030] Train loss: 0.0426
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[011/030] Train loss: 0.0424
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[012/030] Train loss: 0.0426
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[013/030] Train loss: 0.0426
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[014/030] Train loss: 0.0425
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[015/030] Train loss: 0.0426
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[016/030] Train loss: 0.0426
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[017/030] Train loss: 0.0426
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[018/030] Train loss: 0.0430
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[019/030] Train loss: 0.0429
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[020/030] Train loss: 0.0427
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[021/030] Train loss: 0.0429
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[022/030] Train loss: 0.0428
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[023/030] Train loss: 0.0427
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[024/030] Train loss: 0.0426
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[025/030] Train loss: 0.0426
2023-02-06 11:27:44 | Train | Epoch[118/600] Iteration[026/030] Train loss: 0.0427
2023-02-06 11:27:45 | Train | Epoch[118/600] Iteration[027/030] Train loss: 0.0429
2023-02-06 11:27:45 | Train | Epoch[118/600] Iteration[028/030] Train loss: 0.0429
2023-02-06 11:27:45 | Train | Epoch[118/600] Iteration[029/030] Train loss: 0.0428
2023-02-06 11:27:45 | Train | Epoch[118/600] Iteration[030/030] Train loss: 0.0427
2023-02-06 11:27:45 | Valid | Epoch[118/600] Iteration[001/008] Valid loss: 0.1209
2023-02-06 11:27:45 | Valid | Epoch[118/600] Iteration[002/008] Valid loss: 0.1222
2023-02-06 11:27:45 | Valid | Epoch[118/600] Iteration[003/008] Valid loss: 0.1270
2023-02-06 11:27:45 | Valid | Epoch[118/600] Iteration[004/008] Valid loss: 0.1254
2023-02-06 11:27:45 | Valid | Epoch[118/600] Iteration[005/008] Valid loss: 0.1280
2023-02-06 11:27:45 | Valid | Epoch[118/600] Iteration[006/008] Valid loss: 0.1268
2023-02-06 11:27:45 | Valid | Epoch[118/600] Iteration[007/008] Valid loss: 0.1241
2023-02-06 11:27:45 | Valid | Epoch[118/600] Iteration[008/008] Valid loss: 0.1275
2023-02-06 11:27:45 | Valid | Epoch[118/600] MIou: 0.6554151068389478
2023-02-06 11:27:45 | Valid | Epoch[118/600] Pixel Accuracy: 0.9430745442708334
2023-02-06 11:27:45 | Valid | Epoch[118/600] Mean Pixel Accuracy: 0.684861113066494
2023-02-06 11:27:45 | Stage | Epoch[118/600] Train loss:0.0427
2023-02-06 11:27:45 | Stage | Epoch[118/600] Valid loss:0.1275
2023-02-06 11:27:45 | Stage | Epoch[118/600] LR:0.01

2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[001/030] Train loss: 0.0417
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[002/030] Train loss: 0.0414
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[003/030] Train loss: 0.0418
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[004/030] Train loss: 0.0434
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[005/030] Train loss: 0.0428
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[006/030] Train loss: 0.0425
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[007/030] Train loss: 0.0422
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[008/030] Train loss: 0.0425
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[009/030] Train loss: 0.0424
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[010/030] Train loss: 0.0425
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[011/030] Train loss: 0.0425
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[012/030] Train loss: 0.0424
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[013/030] Train loss: 0.0423
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[014/030] Train loss: 0.0423
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[015/030] Train loss: 0.0421
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[016/030] Train loss: 0.0420
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[017/030] Train loss: 0.0423
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[018/030] Train loss: 0.0421
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[019/030] Train loss: 0.0420
2023-02-06 11:27:46 | Train | Epoch[119/600] Iteration[020/030] Train loss: 0.0421
2023-02-06 11:27:47 | Train | Epoch[119/600] Iteration[021/030] Train loss: 0.0421
2023-02-06 11:27:47 | Train | Epoch[119/600] Iteration[022/030] Train loss: 0.0420
2023-02-06 11:27:47 | Train | Epoch[119/600] Iteration[023/030] Train loss: 0.0420
2023-02-06 11:27:47 | Train | Epoch[119/600] Iteration[024/030] Train loss: 0.0419
2023-02-06 11:27:47 | Train | Epoch[119/600] Iteration[025/030] Train loss: 0.0422
2023-02-06 11:27:47 | Train | Epoch[119/600] Iteration[026/030] Train loss: 0.0422
2023-02-06 11:27:47 | Train | Epoch[119/600] Iteration[027/030] Train loss: 0.0423
2023-02-06 11:27:47 | Train | Epoch[119/600] Iteration[028/030] Train loss: 0.0423
2023-02-06 11:27:47 | Train | Epoch[119/600] Iteration[029/030] Train loss: 0.0422
2023-02-06 11:27:47 | Train | Epoch[119/600] Iteration[030/030] Train loss: 0.0422
2023-02-06 11:27:47 | Valid | Epoch[119/600] Iteration[001/008] Valid loss: 0.1291
2023-02-06 11:27:47 | Valid | Epoch[119/600] Iteration[002/008] Valid loss: 0.1319
2023-02-06 11:27:47 | Valid | Epoch[119/600] Iteration[003/008] Valid loss: 0.1376
2023-02-06 11:27:47 | Valid | Epoch[119/600] Iteration[004/008] Valid loss: 0.1355
2023-02-06 11:27:47 | Valid | Epoch[119/600] Iteration[005/008] Valid loss: 0.1391
2023-02-06 11:27:47 | Valid | Epoch[119/600] Iteration[006/008] Valid loss: 0.1371
2023-02-06 11:27:47 | Valid | Epoch[119/600] Iteration[007/008] Valid loss: 0.1344
2023-02-06 11:27:47 | Valid | Epoch[119/600] Iteration[008/008] Valid loss: 0.1387
2023-02-06 11:27:48 | Valid | Epoch[119/600] MIou: 0.599743015924094
2023-02-06 11:27:48 | Valid | Epoch[119/600] Pixel Accuracy: 0.9338239034016927
2023-02-06 11:27:48 | Valid | Epoch[119/600] Mean Pixel Accuracy: 0.6336496360641428
2023-02-06 11:27:48 | Stage | Epoch[119/600] Train loss:0.0422
2023-02-06 11:27:48 | Stage | Epoch[119/600] Valid loss:0.1387
2023-02-06 11:27:48 | Stage | Epoch[119/600] LR:0.01

2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[001/030] Train loss: 0.0414
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[002/030] Train loss: 0.0420
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[003/030] Train loss: 0.0415
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[004/030] Train loss: 0.0416
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[005/030] Train loss: 0.0415
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[006/030] Train loss: 0.0414
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[007/030] Train loss: 0.0423
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[008/030] Train loss: 0.0423
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[009/030] Train loss: 0.0423
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[010/030] Train loss: 0.0418
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[011/030] Train loss: 0.0418
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[012/030] Train loss: 0.0414
2023-02-06 11:27:48 | Train | Epoch[120/600] Iteration[013/030] Train loss: 0.0414
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[014/030] Train loss: 0.0414
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[015/030] Train loss: 0.0414
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[016/030] Train loss: 0.0419
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[017/030] Train loss: 0.0418
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[018/030] Train loss: 0.0419
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[019/030] Train loss: 0.0419
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[020/030] Train loss: 0.0418
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[021/030] Train loss: 0.0418
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[022/030] Train loss: 0.0419
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[023/030] Train loss: 0.0421
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[024/030] Train loss: 0.0422
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[025/030] Train loss: 0.0422
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[026/030] Train loss: 0.0421
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[027/030] Train loss: 0.0422
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[028/030] Train loss: 0.0423
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[029/030] Train loss: 0.0423
2023-02-06 11:27:49 | Train | Epoch[120/600] Iteration[030/030] Train loss: 0.0424
2023-02-06 11:27:50 | Valid | Epoch[120/600] Iteration[001/008] Valid loss: 0.1717
2023-02-06 11:27:50 | Valid | Epoch[120/600] Iteration[002/008] Valid loss: 0.1298
2023-02-06 11:27:50 | Valid | Epoch[120/600] Iteration[003/008] Valid loss: 0.1216
2023-02-06 11:27:50 | Valid | Epoch[120/600] Iteration[004/008] Valid loss: 0.1222
2023-02-06 11:27:50 | Valid | Epoch[120/600] Iteration[005/008] Valid loss: 0.1267
2023-02-06 11:27:50 | Valid | Epoch[120/600] Iteration[006/008] Valid loss: 0.1199
2023-02-06 11:27:50 | Valid | Epoch[120/600] Iteration[007/008] Valid loss: 0.1293
2023-02-06 11:27:50 | Valid | Epoch[120/600] Iteration[008/008] Valid loss: 0.1274
2023-02-06 11:27:50 | Valid | Epoch[120/600] MIou: 0.9273686190787469
2023-02-06 11:27:50 | Valid | Epoch[120/600] Pixel Accuracy: 0.9868558247884115
2023-02-06 11:27:50 | Valid | Epoch[120/600] Mean Pixel Accuracy: 0.9777231213485191
2023-02-06 11:27:50 | Stage | Epoch[120/600] Train loss:0.0424
2023-02-06 11:27:50 | Stage | Epoch[120/600] Valid loss:0.1274
2023-02-06 11:27:50 | Stage | Epoch[120/600] LR:0.01

2023-02-06 11:27:50 | Train | Epoch[121/600] Iteration[001/030] Train loss: 0.0420
2023-02-06 11:27:50 | Train | Epoch[121/600] Iteration[002/030] Train loss: 0.0426
2023-02-06 11:27:50 | Train | Epoch[121/600] Iteration[003/030] Train loss: 0.0428
2023-02-06 11:27:50 | Train | Epoch[121/600] Iteration[004/030] Train loss: 0.0434
2023-02-06 11:27:50 | Train | Epoch[121/600] Iteration[005/030] Train loss: 0.0431
2023-02-06 11:27:50 | Train | Epoch[121/600] Iteration[006/030] Train loss: 0.0425
2023-02-06 11:27:50 | Train | Epoch[121/600] Iteration[007/030] Train loss: 0.0421
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[008/030] Train loss: 0.0416
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[009/030] Train loss: 0.0415
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[010/030] Train loss: 0.0415
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[011/030] Train loss: 0.0415
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[012/030] Train loss: 0.0414
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[013/030] Train loss: 0.0414
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[014/030] Train loss: 0.0415
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[015/030] Train loss: 0.0417
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[016/030] Train loss: 0.0417
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[017/030] Train loss: 0.0418
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[018/030] Train loss: 0.0417
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[019/030] Train loss: 0.0417
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[020/030] Train loss: 0.0417
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[021/030] Train loss: 0.0417
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[022/030] Train loss: 0.0416
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[023/030] Train loss: 0.0417
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[024/030] Train loss: 0.0417
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[025/030] Train loss: 0.0418
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[026/030] Train loss: 0.0417
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[027/030] Train loss: 0.0417
2023-02-06 11:27:51 | Train | Epoch[121/600] Iteration[028/030] Train loss: 0.0417
2023-02-06 11:27:52 | Train | Epoch[121/600] Iteration[029/030] Train loss: 0.0417
2023-02-06 11:27:52 | Train | Epoch[121/600] Iteration[030/030] Train loss: 0.0420
2023-02-06 11:27:52 | Valid | Epoch[121/600] Iteration[001/008] Valid loss: 0.4852
2023-02-06 11:27:52 | Valid | Epoch[121/600] Iteration[002/008] Valid loss: 0.3882
2023-02-06 11:27:52 | Valid | Epoch[121/600] Iteration[003/008] Valid loss: 0.3756
2023-02-06 11:27:52 | Valid | Epoch[121/600] Iteration[004/008] Valid loss: 0.3802
2023-02-06 11:27:52 | Valid | Epoch[121/600] Iteration[005/008] Valid loss: 0.3983
2023-02-06 11:27:52 | Valid | Epoch[121/600] Iteration[006/008] Valid loss: 0.3886
2023-02-06 11:27:52 | Valid | Epoch[121/600] Iteration[007/008] Valid loss: 0.4113
2023-02-06 11:27:52 | Valid | Epoch[121/600] Iteration[008/008] Valid loss: 0.4174
2023-02-06 11:27:52 | Valid | Epoch[121/600] MIou: 0.9005172639183491
2023-02-06 11:27:52 | Valid | Epoch[121/600] Pixel Accuracy: 0.9808184305826823
2023-02-06 11:27:52 | Valid | Epoch[121/600] Mean Pixel Accuracy: 0.9810368452060507
2023-02-06 11:27:52 | Stage | Epoch[121/600] Train loss:0.0420
2023-02-06 11:27:52 | Stage | Epoch[121/600] Valid loss:0.4174
2023-02-06 11:27:52 | Stage | Epoch[121/600] LR:0.01

2023-02-06 11:27:52 | Train | Epoch[122/600] Iteration[001/030] Train loss: 0.0422
2023-02-06 11:27:52 | Train | Epoch[122/600] Iteration[002/030] Train loss: 0.0434
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[003/030] Train loss: 0.0428
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[004/030] Train loss: 0.0442
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[005/030] Train loss: 0.0438
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[006/030] Train loss: 0.0432
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[007/030] Train loss: 0.0426
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[008/030] Train loss: 0.0427
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[009/030] Train loss: 0.0424
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[010/030] Train loss: 0.0424
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[011/030] Train loss: 0.0426
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[012/030] Train loss: 0.0423
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[013/030] Train loss: 0.0422
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[014/030] Train loss: 0.0423
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[015/030] Train loss: 0.0421
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[016/030] Train loss: 0.0421
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[017/030] Train loss: 0.0420
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[018/030] Train loss: 0.0420
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[019/030] Train loss: 0.0420
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[020/030] Train loss: 0.0420
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[021/030] Train loss: 0.0419
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[022/030] Train loss: 0.0417
2023-02-06 11:27:53 | Train | Epoch[122/600] Iteration[023/030] Train loss: 0.0418
2023-02-06 11:27:54 | Train | Epoch[122/600] Iteration[024/030] Train loss: 0.0417
2023-02-06 11:27:54 | Train | Epoch[122/600] Iteration[025/030] Train loss: 0.0417
2023-02-06 11:27:54 | Train | Epoch[122/600] Iteration[026/030] Train loss: 0.0419
2023-02-06 11:27:54 | Train | Epoch[122/600] Iteration[027/030] Train loss: 0.0420
2023-02-06 11:27:54 | Train | Epoch[122/600] Iteration[028/030] Train loss: 0.0420
2023-02-06 11:27:54 | Train | Epoch[122/600] Iteration[029/030] Train loss: 0.0419
2023-02-06 11:27:54 | Train | Epoch[122/600] Iteration[030/030] Train loss: 0.0417
2023-02-06 11:27:54 | Valid | Epoch[122/600] Iteration[001/008] Valid loss: 0.0682
2023-02-06 11:27:54 | Valid | Epoch[122/600] Iteration[002/008] Valid loss: 0.0682
2023-02-06 11:27:54 | Valid | Epoch[122/600] Iteration[003/008] Valid loss: 0.0686
2023-02-06 11:27:54 | Valid | Epoch[122/600] Iteration[004/008] Valid loss: 0.0673
2023-02-06 11:27:54 | Valid | Epoch[122/600] Iteration[005/008] Valid loss: 0.0690
2023-02-06 11:27:54 | Valid | Epoch[122/600] Iteration[006/008] Valid loss: 0.0685
2023-02-06 11:27:54 | Valid | Epoch[122/600] Iteration[007/008] Valid loss: 0.0673
2023-02-06 11:27:54 | Valid | Epoch[122/600] Iteration[008/008] Valid loss: 0.0687
2023-02-06 11:27:54 | Valid | Epoch[122/600] MIou: 0.8000820577371988
2023-02-06 11:27:54 | Valid | Epoch[122/600] Pixel Accuracy: 0.9670308430989584
2023-02-06 11:27:54 | Valid | Epoch[122/600] Mean Pixel Accuracy: 0.8176985759328594
2023-02-06 11:27:54 | Stage | Epoch[122/600] Train loss:0.0417
2023-02-06 11:27:54 | Stage | Epoch[122/600] Valid loss:0.0687
2023-02-06 11:27:54 | Stage | Epoch[122/600] LR:0.01

2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[001/030] Train loss: 0.0404
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[002/030] Train loss: 0.0407
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[003/030] Train loss: 0.0411
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[004/030] Train loss: 0.0408
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[005/030] Train loss: 0.0415
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[006/030] Train loss: 0.0416
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[007/030] Train loss: 0.0412
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[008/030] Train loss: 0.0408
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[009/030] Train loss: 0.0406
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[010/030] Train loss: 0.0411
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[011/030] Train loss: 0.0411
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[012/030] Train loss: 0.0409
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[013/030] Train loss: 0.0407
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[014/030] Train loss: 0.0406
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[015/030] Train loss: 0.0406
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[016/030] Train loss: 0.0406
2023-02-06 11:27:55 | Train | Epoch[123/600] Iteration[017/030] Train loss: 0.0404
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[018/030] Train loss: 0.0405
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[019/030] Train loss: 0.0404
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[020/030] Train loss: 0.0406
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[021/030] Train loss: 0.0405
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[022/030] Train loss: 0.0407
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[023/030] Train loss: 0.0406
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[024/030] Train loss: 0.0407
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[025/030] Train loss: 0.0407
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[026/030] Train loss: 0.0408
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[027/030] Train loss: 0.0409
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[028/030] Train loss: 0.0410
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[029/030] Train loss: 0.0410
2023-02-06 11:27:56 | Train | Epoch[123/600] Iteration[030/030] Train loss: 0.0409
2023-02-06 11:27:56 | Valid | Epoch[123/600] Iteration[001/008] Valid loss: 0.2139
2023-02-06 11:27:56 | Valid | Epoch[123/600] Iteration[002/008] Valid loss: 0.1623
2023-02-06 11:27:56 | Valid | Epoch[123/600] Iteration[003/008] Valid loss: 0.1513
2023-02-06 11:27:56 | Valid | Epoch[123/600] Iteration[004/008] Valid loss: 0.1508
2023-02-06 11:27:56 | Valid | Epoch[123/600] Iteration[005/008] Valid loss: 0.1572
2023-02-06 11:27:57 | Valid | Epoch[123/600] Iteration[006/008] Valid loss: 0.1504
2023-02-06 11:27:57 | Valid | Epoch[123/600] Iteration[007/008] Valid loss: 0.1589
2023-02-06 11:27:57 | Valid | Epoch[123/600] Iteration[008/008] Valid loss: 0.1599
2023-02-06 11:27:57 | Valid | Epoch[123/600] MIou: 0.9173288056813756
2023-02-06 11:27:57 | Valid | Epoch[123/600] Pixel Accuracy: 0.9846280415852865
2023-02-06 11:27:57 | Valid | Epoch[123/600] Mean Pixel Accuracy: 0.9807594335435437
2023-02-06 11:27:57 | Stage | Epoch[123/600] Train loss:0.0409
2023-02-06 11:27:57 | Stage | Epoch[123/600] Valid loss:0.1599
2023-02-06 11:27:57 | Stage | Epoch[123/600] LR:0.01

2023-02-06 11:27:57 | Train | Epoch[124/600] Iteration[001/030] Train loss: 0.0453
2023-02-06 11:27:57 | Train | Epoch[124/600] Iteration[002/030] Train loss: 0.0420
2023-02-06 11:27:57 | Train | Epoch[124/600] Iteration[003/030] Train loss: 0.0408
2023-02-06 11:27:57 | Train | Epoch[124/600] Iteration[004/030] Train loss: 0.0408
2023-02-06 11:27:57 | Train | Epoch[124/600] Iteration[005/030] Train loss: 0.0403
2023-02-06 11:27:57 | Train | Epoch[124/600] Iteration[006/030] Train loss: 0.0402
2023-02-06 11:27:57 | Train | Epoch[124/600] Iteration[007/030] Train loss: 0.0403
2023-02-06 11:27:57 | Train | Epoch[124/600] Iteration[008/030] Train loss: 0.0400
2023-02-06 11:27:57 | Train | Epoch[124/600] Iteration[009/030] Train loss: 0.0399
2023-02-06 11:27:57 | Train | Epoch[124/600] Iteration[010/030] Train loss: 0.0399
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[011/030] Train loss: 0.0398
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[012/030] Train loss: 0.0398
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[013/030] Train loss: 0.0398
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[014/030] Train loss: 0.0398
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[015/030] Train loss: 0.0398
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[016/030] Train loss: 0.0398
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[017/030] Train loss: 0.0397
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[018/030] Train loss: 0.0397
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[019/030] Train loss: 0.0398
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[020/030] Train loss: 0.0398
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[021/030] Train loss: 0.0397
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[022/030] Train loss: 0.0400
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[023/030] Train loss: 0.0401
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[024/030] Train loss: 0.0402
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[025/030] Train loss: 0.0401
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[026/030] Train loss: 0.0401
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[027/030] Train loss: 0.0402
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[028/030] Train loss: 0.0401
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[029/030] Train loss: 0.0402
2023-02-06 11:27:58 | Train | Epoch[124/600] Iteration[030/030] Train loss: 0.0403
2023-02-06 11:27:59 | Valid | Epoch[124/600] Iteration[001/008] Valid loss: 0.4069
2023-02-06 11:27:59 | Valid | Epoch[124/600] Iteration[002/008] Valid loss: 0.3178
2023-02-06 11:27:59 | Valid | Epoch[124/600] Iteration[003/008] Valid loss: 0.3095
2023-02-06 11:27:59 | Valid | Epoch[124/600] Iteration[004/008] Valid loss: 0.3092
2023-02-06 11:27:59 | Valid | Epoch[124/600] Iteration[005/008] Valid loss: 0.3277
2023-02-06 11:27:59 | Valid | Epoch[124/600] Iteration[006/008] Valid loss: 0.3166
2023-02-06 11:27:59 | Valid | Epoch[124/600] Iteration[007/008] Valid loss: 0.3357
2023-02-06 11:27:59 | Valid | Epoch[124/600] Iteration[008/008] Valid loss: 0.3422
2023-02-06 11:27:59 | Valid | Epoch[124/600] MIou: 0.8990569191976467
2023-02-06 11:27:59 | Valid | Epoch[124/600] Pixel Accuracy: 0.9803988138834635
2023-02-06 11:27:59 | Valid | Epoch[124/600] Mean Pixel Accuracy: 0.9830126900581444
2023-02-06 11:27:59 | Stage | Epoch[124/600] Train loss:0.0403
2023-02-06 11:27:59 | Stage | Epoch[124/600] Valid loss:0.3422
2023-02-06 11:27:59 | Stage | Epoch[124/600] LR:0.01

2023-02-06 11:27:59 | Train | Epoch[125/600] Iteration[001/030] Train loss: 0.0388
2023-02-06 11:27:59 | Train | Epoch[125/600] Iteration[002/030] Train loss: 0.0385
2023-02-06 11:27:59 | Train | Epoch[125/600] Iteration[003/030] Train loss: 0.0386
2023-02-06 11:27:59 | Train | Epoch[125/600] Iteration[004/030] Train loss: 0.0382
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[005/030] Train loss: 0.0383
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[006/030] Train loss: 0.0387
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[007/030] Train loss: 0.0386
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[008/030] Train loss: 0.0385
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[009/030] Train loss: 0.0385
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[010/030] Train loss: 0.0389
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[011/030] Train loss: 0.0388
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[012/030] Train loss: 0.0394
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[013/030] Train loss: 0.0393
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[014/030] Train loss: 0.0394
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[015/030] Train loss: 0.0397
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[016/030] Train loss: 0.0397
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[017/030] Train loss: 0.0397
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[018/030] Train loss: 0.0398
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[019/030] Train loss: 0.0398
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[020/030] Train loss: 0.0397
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[021/030] Train loss: 0.0396
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[022/030] Train loss: 0.0396
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[023/030] Train loss: 0.0396
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[024/030] Train loss: 0.0396
2023-02-06 11:28:00 | Train | Epoch[125/600] Iteration[025/030] Train loss: 0.0396
2023-02-06 11:28:01 | Train | Epoch[125/600] Iteration[026/030] Train loss: 0.0395
2023-02-06 11:28:01 | Train | Epoch[125/600] Iteration[027/030] Train loss: 0.0395
2023-02-06 11:28:01 | Train | Epoch[125/600] Iteration[028/030] Train loss: 0.0396
2023-02-06 11:28:01 | Train | Epoch[125/600] Iteration[029/030] Train loss: 0.0397
2023-02-06 11:28:01 | Train | Epoch[125/600] Iteration[030/030] Train loss: 0.0399
2023-02-06 11:28:01 | Valid | Epoch[125/600] Iteration[001/008] Valid loss: 0.1188
2023-02-06 11:28:01 | Valid | Epoch[125/600] Iteration[002/008] Valid loss: 0.0880
2023-02-06 11:28:01 | Valid | Epoch[125/600] Iteration[003/008] Valid loss: 0.0790
2023-02-06 11:28:01 | Valid | Epoch[125/600] Iteration[004/008] Valid loss: 0.0829
2023-02-06 11:28:01 | Valid | Epoch[125/600] Iteration[005/008] Valid loss: 0.0856
2023-02-06 11:28:01 | Valid | Epoch[125/600] Iteration[006/008] Valid loss: 0.0822
2023-02-06 11:28:01 | Valid | Epoch[125/600] Iteration[007/008] Valid loss: 0.0876
2023-02-06 11:28:01 | Valid | Epoch[125/600] Iteration[008/008] Valid loss: 0.0843
2023-02-06 11:28:01 | Valid | Epoch[125/600] MIou: 0.936437991554186
2023-02-06 11:28:01 | Valid | Epoch[125/600] Pixel Accuracy: 0.9890085856119791
2023-02-06 11:28:01 | Valid | Epoch[125/600] Mean Pixel Accuracy: 0.964887587996972
2023-02-06 11:28:01 | Stage | Epoch[125/600] Train loss:0.0399
2023-02-06 11:28:01 | Stage | Epoch[125/600] Valid loss:0.0843
2023-02-06 11:28:01 | Stage | Epoch[125/600] LR:0.01

2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[001/030] Train loss: 0.0388
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[002/030] Train loss: 0.0405
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[003/030] Train loss: 0.0406
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[004/030] Train loss: 0.0407
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[005/030] Train loss: 0.0403
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[006/030] Train loss: 0.0401
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[007/030] Train loss: 0.0399
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[008/030] Train loss: 0.0397
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[009/030] Train loss: 0.0397
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[010/030] Train loss: 0.0394
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[011/030] Train loss: 0.0395
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[012/030] Train loss: 0.0399
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[013/030] Train loss: 0.0399
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[014/030] Train loss: 0.0396
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[015/030] Train loss: 0.0396
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[016/030] Train loss: 0.0395
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[017/030] Train loss: 0.0396
2023-02-06 11:28:02 | Train | Epoch[126/600] Iteration[018/030] Train loss: 0.0394
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[019/030] Train loss: 0.0395
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[020/030] Train loss: 0.0394
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[021/030] Train loss: 0.0394
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[022/030] Train loss: 0.0395
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[023/030] Train loss: 0.0395
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[024/030] Train loss: 0.0394
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[025/030] Train loss: 0.0397
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[026/030] Train loss: 0.0396
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[027/030] Train loss: 0.0396
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[028/030] Train loss: 0.0396
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[029/030] Train loss: 0.0397
2023-02-06 11:28:03 | Train | Epoch[126/600] Iteration[030/030] Train loss: 0.0396
2023-02-06 11:28:03 | Valid | Epoch[126/600] Iteration[001/008] Valid loss: 0.2354
2023-02-06 11:28:03 | Valid | Epoch[126/600] Iteration[002/008] Valid loss: 0.1726
2023-02-06 11:28:03 | Valid | Epoch[126/600] Iteration[003/008] Valid loss: 0.1582
2023-02-06 11:28:03 | Valid | Epoch[126/600] Iteration[004/008] Valid loss: 0.1620
2023-02-06 11:28:03 | Valid | Epoch[126/600] Iteration[005/008] Valid loss: 0.1707
2023-02-06 11:28:04 | Valid | Epoch[126/600] Iteration[006/008] Valid loss: 0.1674
2023-02-06 11:28:04 | Valid | Epoch[126/600] Iteration[007/008] Valid loss: 0.1737
2023-02-06 11:28:04 | Valid | Epoch[126/600] Iteration[008/008] Valid loss: 0.1706
2023-02-06 11:28:04 | Valid | Epoch[126/600] MIou: 0.9240550804217307
2023-02-06 11:28:04 | Valid | Epoch[126/600] Pixel Accuracy: 0.9859720865885416
2023-02-06 11:28:04 | Valid | Epoch[126/600] Mean Pixel Accuracy: 0.9844401567810708
2023-02-06 11:28:04 | Stage | Epoch[126/600] Train loss:0.0396
2023-02-06 11:28:04 | Stage | Epoch[126/600] Valid loss:0.1706
2023-02-06 11:28:04 | Stage | Epoch[126/600] LR:0.01

2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[001/030] Train loss: 0.0350
2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[002/030] Train loss: 0.0366
2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[003/030] Train loss: 0.0367
2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[004/030] Train loss: 0.0378
2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[005/030] Train loss: 0.0379
2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[006/030] Train loss: 0.0380
2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[007/030] Train loss: 0.0384
2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[008/030] Train loss: 0.0386
2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[009/030] Train loss: 0.0388
2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[010/030] Train loss: 0.0395
2023-02-06 11:28:04 | Train | Epoch[127/600] Iteration[011/030] Train loss: 0.0394
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[012/030] Train loss: 0.0396
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[013/030] Train loss: 0.0395
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[014/030] Train loss: 0.0394
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[015/030] Train loss: 0.0396
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[016/030] Train loss: 0.0395
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[017/030] Train loss: 0.0396
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[018/030] Train loss: 0.0396
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[019/030] Train loss: 0.0395
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[020/030] Train loss: 0.0395
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[021/030] Train loss: 0.0394
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[022/030] Train loss: 0.0397
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[023/030] Train loss: 0.0397
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[024/030] Train loss: 0.0396
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[025/030] Train loss: 0.0397
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[026/030] Train loss: 0.0397
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[027/030] Train loss: 0.0398
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[028/030] Train loss: 0.0399
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[029/030] Train loss: 0.0400
2023-02-06 11:28:05 | Train | Epoch[127/600] Iteration[030/030] Train loss: 0.0400
2023-02-06 11:28:06 | Valid | Epoch[127/600] Iteration[001/008] Valid loss: 0.1606
2023-02-06 11:28:06 | Valid | Epoch[127/600] Iteration[002/008] Valid loss: 0.1208
2023-02-06 11:28:06 | Valid | Epoch[127/600] Iteration[003/008] Valid loss: 0.1137
2023-02-06 11:28:06 | Valid | Epoch[127/600] Iteration[004/008] Valid loss: 0.1154
2023-02-06 11:28:06 | Valid | Epoch[127/600] Iteration[005/008] Valid loss: 0.1198
2023-02-06 11:28:06 | Valid | Epoch[127/600] Iteration[006/008] Valid loss: 0.1150
2023-02-06 11:28:06 | Valid | Epoch[127/600] Iteration[007/008] Valid loss: 0.1198
2023-02-06 11:28:06 | Valid | Epoch[127/600] Iteration[008/008] Valid loss: 0.1175
2023-02-06 11:28:06 | Valid | Epoch[127/600] MIou: 0.9330619658419872
2023-02-06 11:28:06 | Valid | Epoch[127/600] Pixel Accuracy: 0.9879913330078125
2023-02-06 11:28:06 | Valid | Epoch[127/600] Mean Pixel Accuracy: 0.9791968682767749
2023-02-06 11:28:06 | Stage | Epoch[127/600] Train loss:0.0400
2023-02-06 11:28:06 | Stage | Epoch[127/600] Valid loss:0.1175
2023-02-06 11:28:06 | Stage | Epoch[127/600] LR:0.01

2023-02-06 11:28:06 | Train | Epoch[128/600] Iteration[001/030] Train loss: 0.0442
2023-02-06 11:28:06 | Train | Epoch[128/600] Iteration[002/030] Train loss: 0.0404
2023-02-06 11:28:06 | Train | Epoch[128/600] Iteration[003/030] Train loss: 0.0397
2023-02-06 11:28:06 | Train | Epoch[128/600] Iteration[004/030] Train loss: 0.0391
2023-02-06 11:28:06 | Train | Epoch[128/600] Iteration[005/030] Train loss: 0.0387
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[006/030] Train loss: 0.0392
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[007/030] Train loss: 0.0396
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[008/030] Train loss: 0.0401
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[009/030] Train loss: 0.0400
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[010/030] Train loss: 0.0401
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[011/030] Train loss: 0.0401
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[012/030] Train loss: 0.0405
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[013/030] Train loss: 0.0403
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[014/030] Train loss: 0.0403
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[015/030] Train loss: 0.0405
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[016/030] Train loss: 0.0405
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[017/030] Train loss: 0.0406
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[018/030] Train loss: 0.0406
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[019/030] Train loss: 0.0406
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[020/030] Train loss: 0.0405
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[021/030] Train loss: 0.0403
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[022/030] Train loss: 0.0402
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[023/030] Train loss: 0.0401
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[024/030] Train loss: 0.0400
2023-02-06 11:28:07 | Train | Epoch[128/600] Iteration[025/030] Train loss: 0.0401
2023-02-06 11:28:08 | Train | Epoch[128/600] Iteration[026/030] Train loss: 0.0401
2023-02-06 11:28:08 | Train | Epoch[128/600] Iteration[027/030] Train loss: 0.0400
2023-02-06 11:28:08 | Train | Epoch[128/600] Iteration[028/030] Train loss: 0.0399
2023-02-06 11:28:08 | Train | Epoch[128/600] Iteration[029/030] Train loss: 0.0399
2023-02-06 11:28:08 | Train | Epoch[128/600] Iteration[030/030] Train loss: 0.0398
2023-02-06 11:28:08 | Valid | Epoch[128/600] Iteration[001/008] Valid loss: 0.0618
2023-02-06 11:28:08 | Valid | Epoch[128/600] Iteration[002/008] Valid loss: 0.0605
2023-02-06 11:28:08 | Valid | Epoch[128/600] Iteration[003/008] Valid loss: 0.0605
2023-02-06 11:28:08 | Valid | Epoch[128/600] Iteration[004/008] Valid loss: 0.0592
2023-02-06 11:28:08 | Valid | Epoch[128/600] Iteration[005/008] Valid loss: 0.0602
2023-02-06 11:28:08 | Valid | Epoch[128/600] Iteration[006/008] Valid loss: 0.0597
2023-02-06 11:28:08 | Valid | Epoch[128/600] Iteration[007/008] Valid loss: 0.0585
2023-02-06 11:28:08 | Valid | Epoch[128/600] Iteration[008/008] Valid loss: 0.0594
2023-02-06 11:28:08 | Valid | Epoch[128/600] MIou: 0.8363769255060083
2023-02-06 11:28:08 | Valid | Epoch[128/600] Pixel Accuracy: 0.9730046590169271
2023-02-06 11:28:08 | Valid | Epoch[128/600] Mean Pixel Accuracy: 0.851264131880155
2023-02-06 11:28:08 | Stage | Epoch[128/600] Train loss:0.0398
2023-02-06 11:28:08 | Stage | Epoch[128/600] Valid loss:0.0594
2023-02-06 11:28:08 | Stage | Epoch[128/600] LR:0.01

2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[001/030] Train loss: 0.0393
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[002/030] Train loss: 0.0390
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[003/030] Train loss: 0.0388
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[004/030] Train loss: 0.0385
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[005/030] Train loss: 0.0389
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[006/030] Train loss: 0.0387
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[007/030] Train loss: 0.0388
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[008/030] Train loss: 0.0387
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[009/030] Train loss: 0.0387
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[010/030] Train loss: 0.0388
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[011/030] Train loss: 0.0386
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[012/030] Train loss: 0.0384
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[013/030] Train loss: 0.0382
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[014/030] Train loss: 0.0384
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[015/030] Train loss: 0.0382
2023-02-06 11:28:09 | Train | Epoch[129/600] Iteration[016/030] Train loss: 0.0383
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[017/030] Train loss: 0.0383
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[018/030] Train loss: 0.0384
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[019/030] Train loss: 0.0384
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[020/030] Train loss: 0.0384
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[021/030] Train loss: 0.0384
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[022/030] Train loss: 0.0387
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[023/030] Train loss: 0.0388
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[024/030] Train loss: 0.0387
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[025/030] Train loss: 0.0388
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[026/030] Train loss: 0.0389
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[027/030] Train loss: 0.0391
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[028/030] Train loss: 0.0390
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[029/030] Train loss: 0.0392
2023-02-06 11:28:10 | Train | Epoch[129/600] Iteration[030/030] Train loss: 0.0393
2023-02-06 11:28:11 | Valid | Epoch[129/600] Iteration[001/008] Valid loss: 2.8120
2023-02-06 11:28:11 | Valid | Epoch[129/600] Iteration[002/008] Valid loss: 2.6526
2023-02-06 11:28:11 | Valid | Epoch[129/600] Iteration[003/008] Valid loss: 2.8230
2023-02-06 11:28:11 | Valid | Epoch[129/600] Iteration[004/008] Valid loss: 2.9197
2023-02-06 11:28:11 | Valid | Epoch[129/600] Iteration[005/008] Valid loss: 2.9662
2023-02-06 11:28:11 | Valid | Epoch[129/600] Iteration[006/008] Valid loss: 2.9004
2023-02-06 11:28:11 | Valid | Epoch[129/600] Iteration[007/008] Valid loss: 2.9511
2023-02-06 11:28:11 | Valid | Epoch[129/600] Iteration[008/008] Valid loss: 3.0839
2023-02-06 11:28:11 | Valid | Epoch[129/600] MIou: 0.7174471036138508
2023-02-06 11:28:11 | Valid | Epoch[129/600] Pixel Accuracy: 0.9183273315429688
2023-02-06 11:28:11 | Valid | Epoch[129/600] Mean Pixel Accuracy: 0.9542532545068219
2023-02-06 11:28:11 | Stage | Epoch[129/600] Train loss:0.0393
2023-02-06 11:28:11 | Stage | Epoch[129/600] Valid loss:3.0839
2023-02-06 11:28:11 | Stage | Epoch[129/600] LR:0.01

2023-02-06 11:28:11 | Train | Epoch[130/600] Iteration[001/030] Train loss: 0.0389
2023-02-06 11:28:11 | Train | Epoch[130/600] Iteration[002/030] Train loss: 0.0392
2023-02-06 11:28:11 | Train | Epoch[130/600] Iteration[003/030] Train loss: 0.0406
2023-02-06 11:28:11 | Train | Epoch[130/600] Iteration[004/030] Train loss: 0.0405
2023-02-06 11:28:11 | Train | Epoch[130/600] Iteration[005/030] Train loss: 0.0406
2023-02-06 11:28:11 | Train | Epoch[130/600] Iteration[006/030] Train loss: 0.0407
2023-02-06 11:28:11 | Train | Epoch[130/600] Iteration[007/030] Train loss: 0.0407
2023-02-06 11:28:11 | Train | Epoch[130/600] Iteration[008/030] Train loss: 0.0405
2023-02-06 11:28:11 | Train | Epoch[130/600] Iteration[009/030] Train loss: 0.0406
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[010/030] Train loss: 0.0401
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[011/030] Train loss: 0.0406
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[012/030] Train loss: 0.0402
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[013/030] Train loss: 0.0405
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[014/030] Train loss: 0.0404
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[015/030] Train loss: 0.0402
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[016/030] Train loss: 0.0402
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[017/030] Train loss: 0.0402
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[018/030] Train loss: 0.0399
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[019/030] Train loss: 0.0399
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[020/030] Train loss: 0.0399
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[021/030] Train loss: 0.0398
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[022/030] Train loss: 0.0397
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[023/030] Train loss: 0.0397
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[024/030] Train loss: 0.0395
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[025/030] Train loss: 0.0397
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[026/030] Train loss: 0.0395
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[027/030] Train loss: 0.0394
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[028/030] Train loss: 0.0394
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[029/030] Train loss: 0.0393
2023-02-06 11:28:12 | Train | Epoch[130/600] Iteration[030/030] Train loss: 0.0392
2023-02-06 11:28:13 | Valid | Epoch[130/600] Iteration[001/008] Valid loss: 0.3219
2023-02-06 11:28:13 | Valid | Epoch[130/600] Iteration[002/008] Valid loss: 0.3206
2023-02-06 11:28:13 | Valid | Epoch[130/600] Iteration[003/008] Valid loss: 0.3008
2023-02-06 11:28:13 | Valid | Epoch[130/600] Iteration[004/008] Valid loss: 0.3043
2023-02-06 11:28:13 | Valid | Epoch[130/600] Iteration[005/008] Valid loss: 0.3082
2023-02-06 11:28:13 | Valid | Epoch[130/600] Iteration[006/008] Valid loss: 0.2972
2023-02-06 11:28:13 | Valid | Epoch[130/600] Iteration[007/008] Valid loss: 0.3054
2023-02-06 11:28:13 | Valid | Epoch[130/600] Iteration[008/008] Valid loss: 0.3141
2023-02-06 11:28:13 | Valid | Epoch[130/600] MIou: 0.8914251154950538
2023-02-06 11:28:13 | Valid | Epoch[130/600] Pixel Accuracy: 0.9786109924316406
2023-02-06 11:28:13 | Valid | Epoch[130/600] Mean Pixel Accuracy: 0.9819285795952886
2023-02-06 11:28:13 | Stage | Epoch[130/600] Train loss:0.0392
2023-02-06 11:28:13 | Stage | Epoch[130/600] Valid loss:0.3141
2023-02-06 11:28:13 | Stage | Epoch[130/600] LR:0.01

2023-02-06 11:28:13 | Train | Epoch[131/600] Iteration[001/030] Train loss: 0.0363
2023-02-06 11:28:13 | Train | Epoch[131/600] Iteration[002/030] Train loss: 0.0396
2023-02-06 11:28:13 | Train | Epoch[131/600] Iteration[003/030] Train loss: 0.0383
2023-02-06 11:28:13 | Train | Epoch[131/600] Iteration[004/030] Train loss: 0.0379
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[005/030] Train loss: 0.0379
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[006/030] Train loss: 0.0378
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[007/030] Train loss: 0.0381
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[008/030] Train loss: 0.0377
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[009/030] Train loss: 0.0380
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[010/030] Train loss: 0.0379
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[011/030] Train loss: 0.0379
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[012/030] Train loss: 0.0379
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[013/030] Train loss: 0.0377
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[014/030] Train loss: 0.0376
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[015/030] Train loss: 0.0379
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[016/030] Train loss: 0.0379
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[017/030] Train loss: 0.0378
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[018/030] Train loss: 0.0379
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[019/030] Train loss: 0.0378
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[020/030] Train loss: 0.0378
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[021/030] Train loss: 0.0378
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[022/030] Train loss: 0.0378
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[023/030] Train loss: 0.0378
2023-02-06 11:28:14 | Train | Epoch[131/600] Iteration[024/030] Train loss: 0.0379
2023-02-06 11:28:15 | Train | Epoch[131/600] Iteration[025/030] Train loss: 0.0379
2023-02-06 11:28:15 | Train | Epoch[131/600] Iteration[026/030] Train loss: 0.0380
2023-02-06 11:28:15 | Train | Epoch[131/600] Iteration[027/030] Train loss: 0.0380
2023-02-06 11:28:15 | Train | Epoch[131/600] Iteration[028/030] Train loss: 0.0380
2023-02-06 11:28:15 | Train | Epoch[131/600] Iteration[029/030] Train loss: 0.0381
2023-02-06 11:28:15 | Train | Epoch[131/600] Iteration[030/030] Train loss: 0.0380
2023-02-06 11:28:15 | Valid | Epoch[131/600] Iteration[001/008] Valid loss: 0.8625
2023-02-06 11:28:15 | Valid | Epoch[131/600] Iteration[002/008] Valid loss: 0.9026
2023-02-06 11:28:15 | Valid | Epoch[131/600] Iteration[003/008] Valid loss: 0.9095
2023-02-06 11:28:15 | Valid | Epoch[131/600] Iteration[004/008] Valid loss: 0.9307
2023-02-06 11:28:15 | Valid | Epoch[131/600] Iteration[005/008] Valid loss: 0.9484
2023-02-06 11:28:15 | Valid | Epoch[131/600] Iteration[006/008] Valid loss: 0.9221
2023-02-06 11:28:15 | Valid | Epoch[131/600] Iteration[007/008] Valid loss: 0.9586
2023-02-06 11:28:15 | Valid | Epoch[131/600] Iteration[008/008] Valid loss: 0.9784
2023-02-06 11:28:15 | Valid | Epoch[131/600] MIou: 0.8359590634154594
2023-02-06 11:28:15 | Valid | Epoch[131/600] Pixel Accuracy: 0.9635772705078125
2023-02-06 11:28:15 | Valid | Epoch[131/600] Mean Pixel Accuracy: 0.9784968441454249
2023-02-06 11:28:15 | Stage | Epoch[131/600] Train loss:0.0380
2023-02-06 11:28:15 | Stage | Epoch[131/600] Valid loss:0.9784
2023-02-06 11:28:15 | Stage | Epoch[131/600] LR:0.01

2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[001/030] Train loss: 0.0361
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[002/030] Train loss: 0.0367
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[003/030] Train loss: 0.0371
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[004/030] Train loss: 0.0374
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[005/030] Train loss: 0.0383
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[006/030] Train loss: 0.0379
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[007/030] Train loss: 0.0377
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[008/030] Train loss: 0.0375
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[009/030] Train loss: 0.0376
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[010/030] Train loss: 0.0375
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[011/030] Train loss: 0.0373
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[012/030] Train loss: 0.0372
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[013/030] Train loss: 0.0375
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[014/030] Train loss: 0.0374
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[015/030] Train loss: 0.0375
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[016/030] Train loss: 0.0375
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[017/030] Train loss: 0.0376
2023-02-06 11:28:16 | Train | Epoch[132/600] Iteration[018/030] Train loss: 0.0376
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[019/030] Train loss: 0.0376
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[020/030] Train loss: 0.0377
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[021/030] Train loss: 0.0377
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[022/030] Train loss: 0.0377
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[023/030] Train loss: 0.0376
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[024/030] Train loss: 0.0374
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[025/030] Train loss: 0.0376
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[026/030] Train loss: 0.0378
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[027/030] Train loss: 0.0378
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[028/030] Train loss: 0.0381
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[029/030] Train loss: 0.0382
2023-02-06 11:28:17 | Train | Epoch[132/600] Iteration[030/030] Train loss: 0.0382
2023-02-06 11:28:17 | Valid | Epoch[132/600] Iteration[001/008] Valid loss: 0.0584
2023-02-06 11:28:17 | Valid | Epoch[132/600] Iteration[002/008] Valid loss: 0.0565
2023-02-06 11:28:17 | Valid | Epoch[132/600] Iteration[003/008] Valid loss: 0.0565
2023-02-06 11:28:17 | Valid | Epoch[132/600] Iteration[004/008] Valid loss: 0.0549
2023-02-06 11:28:17 | Valid | Epoch[132/600] Iteration[005/008] Valid loss: 0.0557
2023-02-06 11:28:17 | Valid | Epoch[132/600] Iteration[006/008] Valid loss: 0.0548
2023-02-06 11:28:18 | Valid | Epoch[132/600] Iteration[007/008] Valid loss: 0.0537
2023-02-06 11:28:18 | Valid | Epoch[132/600] Iteration[008/008] Valid loss: 0.0545
2023-02-06 11:28:18 | Valid | Epoch[132/600] MIou: 0.8545941885414958
2023-02-06 11:28:18 | Valid | Epoch[132/600] Pixel Accuracy: 0.9760335286458334
2023-02-06 11:28:18 | Valid | Epoch[132/600] Mean Pixel Accuracy: 0.867689545486489
2023-02-06 11:28:18 | Stage | Epoch[132/600] Train loss:0.0382
2023-02-06 11:28:18 | Stage | Epoch[132/600] Valid loss:0.0545
2023-02-06 11:28:18 | Stage | Epoch[132/600] LR:0.01

2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[001/030] Train loss: 0.0376
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[002/030] Train loss: 0.0374
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[003/030] Train loss: 0.0368
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[004/030] Train loss: 0.0381
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[005/030] Train loss: 0.0382
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[006/030] Train loss: 0.0384
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[007/030] Train loss: 0.0381
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[008/030] Train loss: 0.0379
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[009/030] Train loss: 0.0378
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[010/030] Train loss: 0.0380
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[011/030] Train loss: 0.0380
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[012/030] Train loss: 0.0380
2023-02-06 11:28:18 | Train | Epoch[133/600] Iteration[013/030] Train loss: 0.0382
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[014/030] Train loss: 0.0382
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[015/030] Train loss: 0.0382
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[016/030] Train loss: 0.0380
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[017/030] Train loss: 0.0387
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[018/030] Train loss: 0.0385
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[019/030] Train loss: 0.0386
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[020/030] Train loss: 0.0384
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[021/030] Train loss: 0.0385
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[022/030] Train loss: 0.0384
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[023/030] Train loss: 0.0384
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[024/030] Train loss: 0.0382
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[025/030] Train loss: 0.0381
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[026/030] Train loss: 0.0381
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[027/030] Train loss: 0.0382
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[028/030] Train loss: 0.0382
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[029/030] Train loss: 0.0380
2023-02-06 11:28:19 | Train | Epoch[133/600] Iteration[030/030] Train loss: 0.0381
2023-02-06 11:28:20 | Valid | Epoch[133/600] Iteration[001/008] Valid loss: 0.0717
2023-02-06 11:28:20 | Valid | Epoch[133/600] Iteration[002/008] Valid loss: 0.0732
2023-02-06 11:28:20 | Valid | Epoch[133/600] Iteration[003/008] Valid loss: 0.0743
2023-02-06 11:28:20 | Valid | Epoch[133/600] Iteration[004/008] Valid loss: 0.0727
2023-02-06 11:28:20 | Valid | Epoch[133/600] Iteration[005/008] Valid loss: 0.0740
2023-02-06 11:28:20 | Valid | Epoch[133/600] Iteration[006/008] Valid loss: 0.0729
2023-02-06 11:28:20 | Valid | Epoch[133/600] Iteration[007/008] Valid loss: 0.0713
2023-02-06 11:28:20 | Valid | Epoch[133/600] Iteration[008/008] Valid loss: 0.0730
2023-02-06 11:28:20 | Valid | Epoch[133/600] MIou: 0.7835347191699805
2023-02-06 11:28:20 | Valid | Epoch[133/600] Pixel Accuracy: 0.9643084208170573
2023-02-06 11:28:20 | Valid | Epoch[133/600] Mean Pixel Accuracy: 0.802411690999451
2023-02-06 11:28:20 | Stage | Epoch[133/600] Train loss:0.0381
2023-02-06 11:28:20 | Stage | Epoch[133/600] Valid loss:0.0730
2023-02-06 11:28:20 | Stage | Epoch[133/600] LR:0.01

2023-02-06 11:28:20 | Train | Epoch[134/600] Iteration[001/030] Train loss: 0.0370
2023-02-06 11:28:20 | Train | Epoch[134/600] Iteration[002/030] Train loss: 0.0366
2023-02-06 11:28:20 | Train | Epoch[134/600] Iteration[003/030] Train loss: 0.0374
2023-02-06 11:28:20 | Train | Epoch[134/600] Iteration[004/030] Train loss: 0.0370
2023-02-06 11:28:20 | Train | Epoch[134/600] Iteration[005/030] Train loss: 0.0367
2023-02-06 11:28:20 | Train | Epoch[134/600] Iteration[006/030] Train loss: 0.0377
2023-02-06 11:28:20 | Train | Epoch[134/600] Iteration[007/030] Train loss: 0.0379
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[008/030] Train loss: 0.0377
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[009/030] Train loss: 0.0375
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[010/030] Train loss: 0.0378
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[011/030] Train loss: 0.0380
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[012/030] Train loss: 0.0380
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[013/030] Train loss: 0.0387
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[014/030] Train loss: 0.0389
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[015/030] Train loss: 0.0393
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[016/030] Train loss: 0.0397
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[017/030] Train loss: 0.0396
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[018/030] Train loss: 0.0399
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[019/030] Train loss: 0.0399
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[020/030] Train loss: 0.0401
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[021/030] Train loss: 0.0400
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[022/030] Train loss: 0.0400
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[023/030] Train loss: 0.0399
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[024/030] Train loss: 0.0398
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[025/030] Train loss: 0.0398
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[026/030] Train loss: 0.0397
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[027/030] Train loss: 0.0397
2023-02-06 11:28:21 | Train | Epoch[134/600] Iteration[028/030] Train loss: 0.0397
2023-02-06 11:28:22 | Train | Epoch[134/600] Iteration[029/030] Train loss: 0.0396
2023-02-06 11:28:22 | Train | Epoch[134/600] Iteration[030/030] Train loss: 0.0397
2023-02-06 11:28:22 | Valid | Epoch[134/600] Iteration[001/008] Valid loss: 0.3101
2023-02-06 11:28:22 | Valid | Epoch[134/600] Iteration[002/008] Valid loss: 0.3138
2023-02-06 11:28:22 | Valid | Epoch[134/600] Iteration[003/008] Valid loss: 0.3337
2023-02-06 11:28:22 | Valid | Epoch[134/600] Iteration[004/008] Valid loss: 0.3298
2023-02-06 11:28:22 | Valid | Epoch[134/600] Iteration[005/008] Valid loss: 0.3426
2023-02-06 11:28:22 | Valid | Epoch[134/600] Iteration[006/008] Valid loss: 0.3394
2023-02-06 11:28:22 | Valid | Epoch[134/600] Iteration[007/008] Valid loss: 0.3393
2023-02-06 11:28:22 | Valid | Epoch[134/600] Iteration[008/008] Valid loss: 0.3543
2023-02-06 11:28:22 | Valid | Epoch[134/600] MIou: 0.455366605444381
2023-02-06 11:28:22 | Valid | Epoch[134/600] Pixel Accuracy: 0.9097696940104166
2023-02-06 11:28:22 | Valid | Epoch[134/600] Mean Pixel Accuracy: 0.5004857171014656
2023-02-06 11:28:22 | Stage | Epoch[134/600] Train loss:0.0397
2023-02-06 11:28:22 | Stage | Epoch[134/600] Valid loss:0.3543
2023-02-06 11:28:22 | Stage | Epoch[134/600] LR:0.01

2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[001/030] Train loss: 0.0335
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[002/030] Train loss: 0.0365
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[003/030] Train loss: 0.0365
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[004/030] Train loss: 0.0378
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[005/030] Train loss: 0.0376
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[006/030] Train loss: 0.0378
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[007/030] Train loss: 0.0377
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[008/030] Train loss: 0.0378
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[009/030] Train loss: 0.0376
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[010/030] Train loss: 0.0377
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[011/030] Train loss: 0.0375
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[012/030] Train loss: 0.0375
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[013/030] Train loss: 0.0375
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[014/030] Train loss: 0.0376
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[015/030] Train loss: 0.0377
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[016/030] Train loss: 0.0377
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[017/030] Train loss: 0.0378
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[018/030] Train loss: 0.0378
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[019/030] Train loss: 0.0379
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[020/030] Train loss: 0.0380
2023-02-06 11:28:23 | Train | Epoch[135/600] Iteration[021/030] Train loss: 0.0378
2023-02-06 11:28:24 | Train | Epoch[135/600] Iteration[022/030] Train loss: 0.0377
2023-02-06 11:28:24 | Train | Epoch[135/600] Iteration[023/030] Train loss: 0.0378
2023-02-06 11:28:24 | Train | Epoch[135/600] Iteration[024/030] Train loss: 0.0377
2023-02-06 11:28:24 | Train | Epoch[135/600] Iteration[025/030] Train loss: 0.0377
2023-02-06 11:28:24 | Train | Epoch[135/600] Iteration[026/030] Train loss: 0.0376
2023-02-06 11:28:24 | Train | Epoch[135/600] Iteration[027/030] Train loss: 0.0377
2023-02-06 11:28:24 | Train | Epoch[135/600] Iteration[028/030] Train loss: 0.0377
2023-02-06 11:28:24 | Train | Epoch[135/600] Iteration[029/030] Train loss: 0.0376
2023-02-06 11:28:24 | Train | Epoch[135/600] Iteration[030/030] Train loss: 0.0375
2023-02-06 11:28:24 | Valid | Epoch[135/600] Iteration[001/008] Valid loss: 0.0802
2023-02-06 11:28:24 | Valid | Epoch[135/600] Iteration[002/008] Valid loss: 0.0651
2023-02-06 11:28:24 | Valid | Epoch[135/600] Iteration[003/008] Valid loss: 0.0594
2023-02-06 11:28:24 | Valid | Epoch[135/600] Iteration[004/008] Valid loss: 0.0569
2023-02-06 11:28:24 | Valid | Epoch[135/600] Iteration[005/008] Valid loss: 0.0581
2023-02-06 11:28:24 | Valid | Epoch[135/600] Iteration[006/008] Valid loss: 0.0566
2023-02-06 11:28:24 | Valid | Epoch[135/600] Iteration[007/008] Valid loss: 0.0566
2023-02-06 11:28:24 | Valid | Epoch[135/600] Iteration[008/008] Valid loss: 0.0571
2023-02-06 11:28:25 | Valid | Epoch[135/600] MIou: 0.9218242030177679
2023-02-06 11:28:25 | Valid | Epoch[135/600] Pixel Accuracy: 0.9866320292154948
2023-02-06 11:28:25 | Valid | Epoch[135/600] Mean Pixel Accuracy: 0.9456948611082082
2023-02-06 11:28:25 | Stage | Epoch[135/600] Train loss:0.0375
2023-02-06 11:28:25 | Stage | Epoch[135/600] Valid loss:0.0571
2023-02-06 11:28:25 | Stage | Epoch[135/600] LR:0.01

2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[001/030] Train loss: 0.0365
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[002/030] Train loss: 0.0366
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[003/030] Train loss: 0.0362
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[004/030] Train loss: 0.0362
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[005/030] Train loss: 0.0370
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[006/030] Train loss: 0.0371
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[007/030] Train loss: 0.0372
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[008/030] Train loss: 0.0372
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[009/030] Train loss: 0.0368
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[010/030] Train loss: 0.0368
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[011/030] Train loss: 0.0368
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[012/030] Train loss: 0.0370
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[013/030] Train loss: 0.0371
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[014/030] Train loss: 0.0374
2023-02-06 11:28:25 | Train | Epoch[136/600] Iteration[015/030] Train loss: 0.0372
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[016/030] Train loss: 0.0371
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[017/030] Train loss: 0.0370
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[018/030] Train loss: 0.0369
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[019/030] Train loss: 0.0368
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[020/030] Train loss: 0.0370
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[021/030] Train loss: 0.0369
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[022/030] Train loss: 0.0370
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[023/030] Train loss: 0.0370
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[024/030] Train loss: 0.0368
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[025/030] Train loss: 0.0367
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[026/030] Train loss: 0.0369
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[027/030] Train loss: 0.0373
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[028/030] Train loss: 0.0372
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[029/030] Train loss: 0.0373
2023-02-06 11:28:26 | Train | Epoch[136/600] Iteration[030/030] Train loss: 0.0373
2023-02-06 11:28:27 | Valid | Epoch[136/600] Iteration[001/008] Valid loss: 0.0544
2023-02-06 11:28:27 | Valid | Epoch[136/600] Iteration[002/008] Valid loss: 0.0472
2023-02-06 11:28:27 | Valid | Epoch[136/600] Iteration[003/008] Valid loss: 0.0460
2023-02-06 11:28:27 | Valid | Epoch[136/600] Iteration[004/008] Valid loss: 0.0441
2023-02-06 11:28:27 | Valid | Epoch[136/600] Iteration[005/008] Valid loss: 0.0448
2023-02-06 11:28:27 | Valid | Epoch[136/600] Iteration[006/008] Valid loss: 0.0445
2023-02-06 11:28:27 | Valid | Epoch[136/600] Iteration[007/008] Valid loss: 0.0440
2023-02-06 11:28:27 | Valid | Epoch[136/600] Iteration[008/008] Valid loss: 0.0439
2023-02-06 11:28:27 | Valid | Epoch[136/600] MIou: 0.9053764214870563
2023-02-06 11:28:27 | Valid | Epoch[136/600] Pixel Accuracy: 0.9843355814615885
2023-02-06 11:28:27 | Valid | Epoch[136/600] Mean Pixel Accuracy: 0.9162302181958024
2023-02-06 11:28:27 | Stage | Epoch[136/600] Train loss:0.0373
2023-02-06 11:28:27 | Stage | Epoch[136/600] Valid loss:0.0439
2023-02-06 11:28:27 | Stage | Epoch[136/600] LR:0.01

2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[001/030] Train loss: 0.0383
2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[002/030] Train loss: 0.0372
2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[003/030] Train loss: 0.0365
2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[004/030] Train loss: 0.0372
2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[005/030] Train loss: 0.0367
2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[006/030] Train loss: 0.0368
2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[007/030] Train loss: 0.0367
2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[008/030] Train loss: 0.0381
2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[009/030] Train loss: 0.0377
2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[010/030] Train loss: 0.0377
2023-02-06 11:28:27 | Train | Epoch[137/600] Iteration[011/030] Train loss: 0.0380
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[012/030] Train loss: 0.0380
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[013/030] Train loss: 0.0381
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[014/030] Train loss: 0.0381
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[015/030] Train loss: 0.0381
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[016/030] Train loss: 0.0379
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[017/030] Train loss: 0.0379
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[018/030] Train loss: 0.0379
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[019/030] Train loss: 0.0377
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[020/030] Train loss: 0.0377
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[021/030] Train loss: 0.0377
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[022/030] Train loss: 0.0376
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[023/030] Train loss: 0.0376
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[024/030] Train loss: 0.0377
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[025/030] Train loss: 0.0376
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[026/030] Train loss: 0.0375
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[027/030] Train loss: 0.0375
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[028/030] Train loss: 0.0375
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[029/030] Train loss: 0.0374
2023-02-06 11:28:28 | Train | Epoch[137/600] Iteration[030/030] Train loss: 0.0373
2023-02-06 11:28:29 | Valid | Epoch[137/600] Iteration[001/008] Valid loss: 0.0973
2023-02-06 11:28:29 | Valid | Epoch[137/600] Iteration[002/008] Valid loss: 0.0977
2023-02-06 11:28:29 | Valid | Epoch[137/600] Iteration[003/008] Valid loss: 0.1005
2023-02-06 11:28:29 | Valid | Epoch[137/600] Iteration[004/008] Valid loss: 0.0981
2023-02-06 11:28:29 | Valid | Epoch[137/600] Iteration[005/008] Valid loss: 0.1006
2023-02-06 11:28:29 | Valid | Epoch[137/600] Iteration[006/008] Valid loss: 0.0994
2023-02-06 11:28:29 | Valid | Epoch[137/600] Iteration[007/008] Valid loss: 0.0970
2023-02-06 11:28:29 | Valid | Epoch[137/600] Iteration[008/008] Valid loss: 0.1005
2023-02-06 11:28:29 | Valid | Epoch[137/600] MIou: 0.6811299402339309
2023-02-06 11:28:29 | Valid | Epoch[137/600] Pixel Accuracy: 0.9473419189453125
2023-02-06 11:28:29 | Valid | Epoch[137/600] Mean Pixel Accuracy: 0.7084916070527676
2023-02-06 11:28:29 | Stage | Epoch[137/600] Train loss:0.0373
2023-02-06 11:28:29 | Stage | Epoch[137/600] Valid loss:0.1005
2023-02-06 11:28:29 | Stage | Epoch[137/600] LR:0.01

2023-02-06 11:28:29 | Train | Epoch[138/600] Iteration[001/030] Train loss: 0.0365
2023-02-06 11:28:29 | Train | Epoch[138/600] Iteration[002/030] Train loss: 0.0349
2023-02-06 11:28:29 | Train | Epoch[138/600] Iteration[003/030] Train loss: 0.0345
2023-02-06 11:28:29 | Train | Epoch[138/600] Iteration[004/030] Train loss: 0.0344
2023-02-06 11:28:29 | Train | Epoch[138/600] Iteration[005/030] Train loss: 0.0350
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[006/030] Train loss: 0.0356
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[007/030] Train loss: 0.0360
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[008/030] Train loss: 0.0362
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[009/030] Train loss: 0.0362
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[010/030] Train loss: 0.0362
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[011/030] Train loss: 0.0361
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[012/030] Train loss: 0.0359
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[013/030] Train loss: 0.0360
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[014/030] Train loss: 0.0361
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[015/030] Train loss: 0.0362
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[016/030] Train loss: 0.0361
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[017/030] Train loss: 0.0359
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[018/030] Train loss: 0.0360
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[019/030] Train loss: 0.0361
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[020/030] Train loss: 0.0361
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[021/030] Train loss: 0.0362
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[022/030] Train loss: 0.0362
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[023/030] Train loss: 0.0361
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[024/030] Train loss: 0.0360
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[025/030] Train loss: 0.0359
2023-02-06 11:28:30 | Train | Epoch[138/600] Iteration[026/030] Train loss: 0.0361
2023-02-06 11:28:31 | Train | Epoch[138/600] Iteration[027/030] Train loss: 0.0363
2023-02-06 11:28:31 | Train | Epoch[138/600] Iteration[028/030] Train loss: 0.0363
2023-02-06 11:28:31 | Train | Epoch[138/600] Iteration[029/030] Train loss: 0.0365
2023-02-06 11:28:31 | Train | Epoch[138/600] Iteration[030/030] Train loss: 0.0364
2023-02-06 11:28:31 | Valid | Epoch[138/600] Iteration[001/008] Valid loss: 0.2629
2023-02-06 11:28:31 | Valid | Epoch[138/600] Iteration[002/008] Valid loss: 0.2671
2023-02-06 11:28:31 | Valid | Epoch[138/600] Iteration[003/008] Valid loss: 0.2833
2023-02-06 11:28:31 | Valid | Epoch[138/600] Iteration[004/008] Valid loss: 0.2817
2023-02-06 11:28:31 | Valid | Epoch[138/600] Iteration[005/008] Valid loss: 0.2904
2023-02-06 11:28:31 | Valid | Epoch[138/600] Iteration[006/008] Valid loss: 0.2879
2023-02-06 11:28:31 | Valid | Epoch[138/600] Iteration[007/008] Valid loss: 0.2859
2023-02-06 11:28:31 | Valid | Epoch[138/600] Iteration[008/008] Valid loss: 0.2972
2023-02-06 11:28:31 | Valid | Epoch[138/600] MIou: 0.45506951080337316
2023-02-06 11:28:31 | Valid | Epoch[138/600] Pixel Accuracy: 0.9097201029459635
2023-02-06 11:28:31 | Valid | Epoch[138/600] Mean Pixel Accuracy: 0.5002111813484633
2023-02-06 11:28:31 | Stage | Epoch[138/600] Train loss:0.0364
2023-02-06 11:28:31 | Stage | Epoch[138/600] Valid loss:0.2972
2023-02-06 11:28:31 | Stage | Epoch[138/600] LR:0.01

2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[001/030] Train loss: 0.0351
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[002/030] Train loss: 0.0346
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[003/030] Train loss: 0.0364
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[004/030] Train loss: 0.0375
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[005/030] Train loss: 0.0368
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[006/030] Train loss: 0.0368
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[007/030] Train loss: 0.0367
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[008/030] Train loss: 0.0369
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[009/030] Train loss: 0.0369
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[010/030] Train loss: 0.0367
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[011/030] Train loss: 0.0368
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[012/030] Train loss: 0.0368
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[013/030] Train loss: 0.0365
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[014/030] Train loss: 0.0364
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[015/030] Train loss: 0.0363
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[016/030] Train loss: 0.0361
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[017/030] Train loss: 0.0362
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[018/030] Train loss: 0.0363
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[019/030] Train loss: 0.0364
2023-02-06 11:28:32 | Train | Epoch[139/600] Iteration[020/030] Train loss: 0.0364
2023-02-06 11:28:33 | Train | Epoch[139/600] Iteration[021/030] Train loss: 0.0364
2023-02-06 11:28:33 | Train | Epoch[139/600] Iteration[022/030] Train loss: 0.0364
2023-02-06 11:28:33 | Train | Epoch[139/600] Iteration[023/030] Train loss: 0.0365
2023-02-06 11:28:33 | Train | Epoch[139/600] Iteration[024/030] Train loss: 0.0364
2023-02-06 11:28:33 | Train | Epoch[139/600] Iteration[025/030] Train loss: 0.0366
2023-02-06 11:28:33 | Train | Epoch[139/600] Iteration[026/030] Train loss: 0.0365
2023-02-06 11:28:33 | Train | Epoch[139/600] Iteration[027/030] Train loss: 0.0365
2023-02-06 11:28:33 | Train | Epoch[139/600] Iteration[028/030] Train loss: 0.0365
2023-02-06 11:28:33 | Train | Epoch[139/600] Iteration[029/030] Train loss: 0.0363
2023-02-06 11:28:33 | Train | Epoch[139/600] Iteration[030/030] Train loss: 0.0362
2023-02-06 11:28:33 | Valid | Epoch[139/600] Iteration[001/008] Valid loss: 0.1052
2023-02-06 11:28:33 | Valid | Epoch[139/600] Iteration[002/008] Valid loss: 0.1099
2023-02-06 11:28:33 | Valid | Epoch[139/600] Iteration[003/008] Valid loss: 0.1138
2023-02-06 11:28:33 | Valid | Epoch[139/600] Iteration[004/008] Valid loss: 0.1120
2023-02-06 11:28:33 | Valid | Epoch[139/600] Iteration[005/008] Valid loss: 0.1147
2023-02-06 11:28:33 | Valid | Epoch[139/600] Iteration[006/008] Valid loss: 0.1133
2023-02-06 11:28:33 | Valid | Epoch[139/600] Iteration[007/008] Valid loss: 0.1108
2023-02-06 11:28:34 | Valid | Epoch[139/600] Iteration[008/008] Valid loss: 0.1142
2023-02-06 11:28:34 | Valid | Epoch[139/600] MIou: 0.6622470384978238
2023-02-06 11:28:34 | Valid | Epoch[139/600] Pixel Accuracy: 0.9442087809244791
2023-02-06 11:28:34 | Valid | Epoch[139/600] Mean Pixel Accuracy: 0.6911402384941362
2023-02-06 11:28:34 | Stage | Epoch[139/600] Train loss:0.0362
2023-02-06 11:28:34 | Stage | Epoch[139/600] Valid loss:0.1142
2023-02-06 11:28:34 | Stage | Epoch[139/600] LR:0.01

2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[001/030] Train loss: 0.0354
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[002/030] Train loss: 0.0344
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[003/030] Train loss: 0.0332
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[004/030] Train loss: 0.0337
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[005/030] Train loss: 0.0336
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[006/030] Train loss: 0.0337
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[007/030] Train loss: 0.0344
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[008/030] Train loss: 0.0344
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[009/030] Train loss: 0.0347
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[010/030] Train loss: 0.0344
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[011/030] Train loss: 0.0344
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[012/030] Train loss: 0.0347
2023-02-06 11:28:34 | Train | Epoch[140/600] Iteration[013/030] Train loss: 0.0349
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[014/030] Train loss: 0.0349
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[015/030] Train loss: 0.0349
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[016/030] Train loss: 0.0351
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[017/030] Train loss: 0.0352
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[018/030] Train loss: 0.0352
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[019/030] Train loss: 0.0354
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[020/030] Train loss: 0.0354
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[021/030] Train loss: 0.0354
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[022/030] Train loss: 0.0356
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[023/030] Train loss: 0.0357
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[024/030] Train loss: 0.0357
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[025/030] Train loss: 0.0357
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[026/030] Train loss: 0.0356
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[027/030] Train loss: 0.0355
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[028/030] Train loss: 0.0354
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[029/030] Train loss: 0.0354
2023-02-06 11:28:35 | Train | Epoch[140/600] Iteration[030/030] Train loss: 0.0354
2023-02-06 11:28:36 | Valid | Epoch[140/600] Iteration[001/008] Valid loss: 0.0501
2023-02-06 11:28:36 | Valid | Epoch[140/600] Iteration[002/008] Valid loss: 0.0441
2023-02-06 11:28:36 | Valid | Epoch[140/600] Iteration[003/008] Valid loss: 0.0432
2023-02-06 11:28:36 | Valid | Epoch[140/600] Iteration[004/008] Valid loss: 0.0417
2023-02-06 11:28:36 | Valid | Epoch[140/600] Iteration[005/008] Valid loss: 0.0428
2023-02-06 11:28:36 | Valid | Epoch[140/600] Iteration[006/008] Valid loss: 0.0427
2023-02-06 11:28:36 | Valid | Epoch[140/600] Iteration[007/008] Valid loss: 0.0423
2023-02-06 11:28:36 | Valid | Epoch[140/600] Iteration[008/008] Valid loss: 0.0424
2023-02-06 11:28:36 | Valid | Epoch[140/600] MIou: 0.9043493948882795
2023-02-06 11:28:36 | Valid | Epoch[140/600] Pixel Accuracy: 0.9841423034667969
2023-02-06 11:28:36 | Valid | Epoch[140/600] Mean Pixel Accuracy: 0.9158893869208109
2023-02-06 11:28:36 | Stage | Epoch[140/600] Train loss:0.0354
2023-02-06 11:28:36 | Stage | Epoch[140/600] Valid loss:0.0424
2023-02-06 11:28:36 | Stage | Epoch[140/600] LR:0.01

2023-02-06 11:28:36 | Train | Epoch[141/600] Iteration[001/030] Train loss: 0.0340
2023-02-06 11:28:36 | Train | Epoch[141/600] Iteration[002/030] Train loss: 0.0355
2023-02-06 11:28:36 | Train | Epoch[141/600] Iteration[003/030] Train loss: 0.0353
2023-02-06 11:28:36 | Train | Epoch[141/600] Iteration[004/030] Train loss: 0.0351
2023-02-06 11:28:36 | Train | Epoch[141/600] Iteration[005/030] Train loss: 0.0345
2023-02-06 11:28:36 | Train | Epoch[141/600] Iteration[006/030] Train loss: 0.0347
2023-02-06 11:28:36 | Train | Epoch[141/600] Iteration[007/030] Train loss: 0.0343
2023-02-06 11:28:36 | Train | Epoch[141/600] Iteration[008/030] Train loss: 0.0347
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[009/030] Train loss: 0.0344
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[010/030] Train loss: 0.0344
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[011/030] Train loss: 0.0353
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[012/030] Train loss: 0.0353
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[013/030] Train loss: 0.0353
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[014/030] Train loss: 0.0355
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[015/030] Train loss: 0.0357
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[016/030] Train loss: 0.0362
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[017/030] Train loss: 0.0363
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[018/030] Train loss: 0.0364
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[019/030] Train loss: 0.0365
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[020/030] Train loss: 0.0364
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[021/030] Train loss: 0.0364
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[022/030] Train loss: 0.0364
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[023/030] Train loss: 0.0366
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[024/030] Train loss: 0.0366
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[025/030] Train loss: 0.0366
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[026/030] Train loss: 0.0366
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[027/030] Train loss: 0.0367
2023-02-06 11:28:37 | Train | Epoch[141/600] Iteration[028/030] Train loss: 0.0367
2023-02-06 11:28:38 | Train | Epoch[141/600] Iteration[029/030] Train loss: 0.0367
2023-02-06 11:28:38 | Train | Epoch[141/600] Iteration[030/030] Train loss: 0.0367
2023-02-06 11:28:38 | Valid | Epoch[141/600] Iteration[001/008] Valid loss: 0.1608
2023-02-06 11:28:38 | Valid | Epoch[141/600] Iteration[002/008] Valid loss: 0.1572
2023-02-06 11:28:38 | Valid | Epoch[141/600] Iteration[003/008] Valid loss: 0.1626
2023-02-06 11:28:38 | Valid | Epoch[141/600] Iteration[004/008] Valid loss: 0.1606
2023-02-06 11:28:38 | Valid | Epoch[141/600] Iteration[005/008] Valid loss: 0.1626
2023-02-06 11:28:38 | Valid | Epoch[141/600] Iteration[006/008] Valid loss: 0.1608
2023-02-06 11:28:38 | Valid | Epoch[141/600] Iteration[007/008] Valid loss: 0.1584
2023-02-06 11:28:38 | Valid | Epoch[141/600] Iteration[008/008] Valid loss: 0.1631
2023-02-06 11:28:38 | Valid | Epoch[141/600] MIou: 0.62067035633102
2023-02-06 11:28:38 | Valid | Epoch[141/600] Pixel Accuracy: 0.9373029073079427
2023-02-06 11:28:38 | Valid | Epoch[141/600] Mean Pixel Accuracy: 0.6529093750439962
2023-02-06 11:28:38 | Stage | Epoch[141/600] Train loss:0.0367
2023-02-06 11:28:38 | Stage | Epoch[141/600] Valid loss:0.1631
2023-02-06 11:28:38 | Stage | Epoch[141/600] LR:0.01

2023-02-06 11:28:38 | Train | Epoch[142/600] Iteration[001/030] Train loss: 0.0398
2023-02-06 11:28:38 | Train | Epoch[142/600] Iteration[002/030] Train loss: 0.0382
2023-02-06 11:28:38 | Train | Epoch[142/600] Iteration[003/030] Train loss: 0.0365
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[004/030] Train loss: 0.0358
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[005/030] Train loss: 0.0355
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[006/030] Train loss: 0.0351
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[007/030] Train loss: 0.0356
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[008/030] Train loss: 0.0352
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[009/030] Train loss: 0.0351
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[010/030] Train loss: 0.0347
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[011/030] Train loss: 0.0352
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[012/030] Train loss: 0.0351
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[013/030] Train loss: 0.0351
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[014/030] Train loss: 0.0349
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[015/030] Train loss: 0.0350
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[016/030] Train loss: 0.0352
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[017/030] Train loss: 0.0354
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[018/030] Train loss: 0.0354
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[019/030] Train loss: 0.0353
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[020/030] Train loss: 0.0353
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[021/030] Train loss: 0.0352
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[022/030] Train loss: 0.0353
2023-02-06 11:28:39 | Train | Epoch[142/600] Iteration[023/030] Train loss: 0.0352
2023-02-06 11:28:40 | Train | Epoch[142/600] Iteration[024/030] Train loss: 0.0353
2023-02-06 11:28:40 | Train | Epoch[142/600] Iteration[025/030] Train loss: 0.0353
2023-02-06 11:28:40 | Train | Epoch[142/600] Iteration[026/030] Train loss: 0.0354
2023-02-06 11:28:40 | Train | Epoch[142/600] Iteration[027/030] Train loss: 0.0354
2023-02-06 11:28:40 | Train | Epoch[142/600] Iteration[028/030] Train loss: 0.0354
2023-02-06 11:28:40 | Train | Epoch[142/600] Iteration[029/030] Train loss: 0.0356
2023-02-06 11:28:40 | Train | Epoch[142/600] Iteration[030/030] Train loss: 0.0354
2023-02-06 11:28:40 | Valid | Epoch[142/600] Iteration[001/008] Valid loss: 0.1224
2023-02-06 11:28:40 | Valid | Epoch[142/600] Iteration[002/008] Valid loss: 0.0887
2023-02-06 11:28:40 | Valid | Epoch[142/600] Iteration[003/008] Valid loss: 0.0789
2023-02-06 11:28:40 | Valid | Epoch[142/600] Iteration[004/008] Valid loss: 0.0792
2023-02-06 11:28:40 | Valid | Epoch[142/600] Iteration[005/008] Valid loss: 0.0806
2023-02-06 11:28:40 | Valid | Epoch[142/600] Iteration[006/008] Valid loss: 0.0771
2023-02-06 11:28:40 | Valid | Epoch[142/600] Iteration[007/008] Valid loss: 0.0794
2023-02-06 11:28:40 | Valid | Epoch[142/600] Iteration[008/008] Valid loss: 0.0779
2023-02-06 11:28:40 | Valid | Epoch[142/600] MIou: 0.9404595934880353
2023-02-06 11:28:40 | Valid | Epoch[142/600] Pixel Accuracy: 0.9895807902018229
2023-02-06 11:28:40 | Valid | Epoch[142/600] Mean Pixel Accuracy: 0.9744591844511221
2023-02-06 11:28:40 | Stage | Epoch[142/600] Train loss:0.0354
2023-02-06 11:28:40 | Stage | Epoch[142/600] Valid loss:0.0779
2023-02-06 11:28:40 | Stage | Epoch[142/600] LR:0.01

2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[001/030] Train loss: 0.0375
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[002/030] Train loss: 0.0362
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[003/030] Train loss: 0.0348
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[004/030] Train loss: 0.0346
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[005/030] Train loss: 0.0342
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[006/030] Train loss: 0.0344
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[007/030] Train loss: 0.0342
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[008/030] Train loss: 0.0341
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[009/030] Train loss: 0.0341
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[010/030] Train loss: 0.0340
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[011/030] Train loss: 0.0343
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[012/030] Train loss: 0.0341
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[013/030] Train loss: 0.0341
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[014/030] Train loss: 0.0342
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[015/030] Train loss: 0.0343
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[016/030] Train loss: 0.0345
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[017/030] Train loss: 0.0345
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[018/030] Train loss: 0.0344
2023-02-06 11:28:41 | Train | Epoch[143/600] Iteration[019/030] Train loss: 0.0343
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[020/030] Train loss: 0.0341
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[021/030] Train loss: 0.0341
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[022/030] Train loss: 0.0341
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[023/030] Train loss: 0.0342
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[024/030] Train loss: 0.0343
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[025/030] Train loss: 0.0343
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[026/030] Train loss: 0.0344
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[027/030] Train loss: 0.0344
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[028/030] Train loss: 0.0345
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[029/030] Train loss: 0.0346
2023-02-06 11:28:42 | Train | Epoch[143/600] Iteration[030/030] Train loss: 0.0347
2023-02-06 11:28:42 | Valid | Epoch[143/600] Iteration[001/008] Valid loss: 0.0792
2023-02-06 11:28:42 | Valid | Epoch[143/600] Iteration[002/008] Valid loss: 0.0613
2023-02-06 11:28:42 | Valid | Epoch[143/600] Iteration[003/008] Valid loss: 0.0567
2023-02-06 11:28:42 | Valid | Epoch[143/600] Iteration[004/008] Valid loss: 0.0572
2023-02-06 11:28:42 | Valid | Epoch[143/600] Iteration[005/008] Valid loss: 0.0573
2023-02-06 11:28:42 | Valid | Epoch[143/600] Iteration[006/008] Valid loss: 0.0567
2023-02-06 11:28:42 | Valid | Epoch[143/600] Iteration[007/008] Valid loss: 0.0576
2023-02-06 11:28:43 | Valid | Epoch[143/600] Iteration[008/008] Valid loss: 0.0562
2023-02-06 11:28:43 | Valid | Epoch[143/600] MIou: 0.942568593001158
2023-02-06 11:28:43 | Valid | Epoch[143/600] Pixel Accuracy: 0.9901440938313802
2023-02-06 11:28:43 | Valid | Epoch[143/600] Mean Pixel Accuracy: 0.9672046176363345
2023-02-06 11:28:43 | Stage | Epoch[143/600] Train loss:0.0347
2023-02-06 11:28:43 | Stage | Epoch[143/600] Valid loss:0.0562
2023-02-06 11:28:43 | Stage | Epoch[143/600] LR:0.01

2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[001/030] Train loss: 0.0372
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[002/030] Train loss: 0.0349
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[003/030] Train loss: 0.0342
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[004/030] Train loss: 0.0340
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[005/030] Train loss: 0.0343
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[006/030] Train loss: 0.0340
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[007/030] Train loss: 0.0342
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[008/030] Train loss: 0.0342
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[009/030] Train loss: 0.0342
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[010/030] Train loss: 0.0343
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[011/030] Train loss: 0.0344
2023-02-06 11:28:43 | Train | Epoch[144/600] Iteration[012/030] Train loss: 0.0343
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[013/030] Train loss: 0.0342
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[014/030] Train loss: 0.0346
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[015/030] Train loss: 0.0345
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[016/030] Train loss: 0.0344
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[017/030] Train loss: 0.0342
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[018/030] Train loss: 0.0343
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[019/030] Train loss: 0.0343
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[020/030] Train loss: 0.0344
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[021/030] Train loss: 0.0344
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[022/030] Train loss: 0.0345
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[023/030] Train loss: 0.0345
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[024/030] Train loss: 0.0346
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[025/030] Train loss: 0.0345
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[026/030] Train loss: 0.0346
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[027/030] Train loss: 0.0348
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[028/030] Train loss: 0.0349
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[029/030] Train loss: 0.0349
2023-02-06 11:28:44 | Train | Epoch[144/600] Iteration[030/030] Train loss: 0.0349
2023-02-06 11:28:45 | Valid | Epoch[144/600] Iteration[001/008] Valid loss: 1.4174
2023-02-06 11:28:45 | Valid | Epoch[144/600] Iteration[002/008] Valid loss: 1.3811
2023-02-06 11:28:45 | Valid | Epoch[144/600] Iteration[003/008] Valid loss: 1.3978
2023-02-06 11:28:45 | Valid | Epoch[144/600] Iteration[004/008] Valid loss: 1.4337
2023-02-06 11:28:45 | Valid | Epoch[144/600] Iteration[005/008] Valid loss: 1.4641
2023-02-06 11:28:45 | Valid | Epoch[144/600] Iteration[006/008] Valid loss: 1.4319
2023-02-06 11:28:45 | Valid | Epoch[144/600] Iteration[007/008] Valid loss: 1.4756
2023-02-06 11:28:45 | Valid | Epoch[144/600] Iteration[008/008] Valid loss: 1.5274
2023-02-06 11:28:45 | Valid | Epoch[144/600] MIou: 0.8156824531086401
2023-02-06 11:28:45 | Valid | Epoch[144/600] Pixel Accuracy: 0.9572868347167969
2023-02-06 11:28:45 | Valid | Epoch[144/600] Mean Pixel Accuracy: 0.9752485879139835
2023-02-06 11:28:45 | Stage | Epoch[144/600] Train loss:0.0349
2023-02-06 11:28:45 | Stage | Epoch[144/600] Valid loss:1.5274
2023-02-06 11:28:45 | Stage | Epoch[144/600] LR:0.01

2023-02-06 11:28:45 | Train | Epoch[145/600] Iteration[001/030] Train loss: 0.0380
2023-02-06 11:28:45 | Train | Epoch[145/600] Iteration[002/030] Train loss: 0.0365
2023-02-06 11:28:45 | Train | Epoch[145/600] Iteration[003/030] Train loss: 0.0359
2023-02-06 11:28:45 | Train | Epoch[145/600] Iteration[004/030] Train loss: 0.0354
2023-02-06 11:28:45 | Train | Epoch[145/600] Iteration[005/030] Train loss: 0.0353
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[006/030] Train loss: 0.0351
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[007/030] Train loss: 0.0355
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[008/030] Train loss: 0.0353
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[009/030] Train loss: 0.0351
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[010/030] Train loss: 0.0350
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[011/030] Train loss: 0.0349
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[012/030] Train loss: 0.0351
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[013/030] Train loss: 0.0353
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[014/030] Train loss: 0.0350
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[015/030] Train loss: 0.0350
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[016/030] Train loss: 0.0351
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[017/030] Train loss: 0.0350
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[018/030] Train loss: 0.0351
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[019/030] Train loss: 0.0352
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[020/030] Train loss: 0.0353
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[021/030] Train loss: 0.0353
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[022/030] Train loss: 0.0352
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[023/030] Train loss: 0.0352
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[024/030] Train loss: 0.0353
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[025/030] Train loss: 0.0353
2023-02-06 11:28:46 | Train | Epoch[145/600] Iteration[026/030] Train loss: 0.0354
2023-02-06 11:28:47 | Train | Epoch[145/600] Iteration[027/030] Train loss: 0.0353
2023-02-06 11:28:47 | Train | Epoch[145/600] Iteration[028/030] Train loss: 0.0353
2023-02-06 11:28:47 | Train | Epoch[145/600] Iteration[029/030] Train loss: 0.0352
2023-02-06 11:28:47 | Train | Epoch[145/600] Iteration[030/030] Train loss: 0.0353
2023-02-06 11:28:47 | Valid | Epoch[145/600] Iteration[001/008] Valid loss: 0.0578
2023-02-06 11:28:47 | Valid | Epoch[145/600] Iteration[002/008] Valid loss: 0.0558
2023-02-06 11:28:47 | Valid | Epoch[145/600] Iteration[003/008] Valid loss: 0.0549
2023-02-06 11:28:47 | Valid | Epoch[145/600] Iteration[004/008] Valid loss: 0.0550
2023-02-06 11:28:47 | Valid | Epoch[145/600] Iteration[005/008] Valid loss: 0.0556
2023-02-06 11:28:47 | Valid | Epoch[145/600] Iteration[006/008] Valid loss: 0.0549
2023-02-06 11:28:47 | Valid | Epoch[145/600] Iteration[007/008] Valid loss: 0.0538
2023-02-06 11:28:47 | Valid | Epoch[145/600] Iteration[008/008] Valid loss: 0.0542
2023-02-06 11:28:47 | Valid | Epoch[145/600] MIou: 0.8674702463652063
2023-02-06 11:28:47 | Valid | Epoch[145/600] Pixel Accuracy: 0.9780565897623698
2023-02-06 11:28:47 | Valid | Epoch[145/600] Mean Pixel Accuracy: 0.881254192207332
2023-02-06 11:28:47 | Stage | Epoch[145/600] Train loss:0.0353
2023-02-06 11:28:47 | Stage | Epoch[145/600] Valid loss:0.0542
2023-02-06 11:28:47 | Stage | Epoch[145/600] LR:0.01

2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[001/030] Train loss: 0.0326
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[002/030] Train loss: 0.0346
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[003/030] Train loss: 0.0348
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[004/030] Train loss: 0.0367
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[005/030] Train loss: 0.0361
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[006/030] Train loss: 0.0362
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[007/030] Train loss: 0.0357
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[008/030] Train loss: 0.0354
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[009/030] Train loss: 0.0356
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[010/030] Train loss: 0.0355
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[011/030] Train loss: 0.0355
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[012/030] Train loss: 0.0354
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[013/030] Train loss: 0.0350
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[014/030] Train loss: 0.0348
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[015/030] Train loss: 0.0350
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[016/030] Train loss: 0.0350
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[017/030] Train loss: 0.0347
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[018/030] Train loss: 0.0348
2023-02-06 11:28:48 | Train | Epoch[146/600] Iteration[019/030] Train loss: 0.0348
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[020/030] Train loss: 0.0348
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[021/030] Train loss: 0.0348
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[022/030] Train loss: 0.0346
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[023/030] Train loss: 0.0348
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[024/030] Train loss: 0.0346
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[025/030] Train loss: 0.0346
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[026/030] Train loss: 0.0346
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[027/030] Train loss: 0.0345
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[028/030] Train loss: 0.0345
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[029/030] Train loss: 0.0344
2023-02-06 11:28:49 | Train | Epoch[146/600] Iteration[030/030] Train loss: 0.0344
2023-02-06 11:28:49 | Valid | Epoch[146/600] Iteration[001/008] Valid loss: 0.2728
2023-02-06 11:28:49 | Valid | Epoch[146/600] Iteration[002/008] Valid loss: 0.2076
2023-02-06 11:28:49 | Valid | Epoch[146/600] Iteration[003/008] Valid loss: 0.1922
2023-02-06 11:28:49 | Valid | Epoch[146/600] Iteration[004/008] Valid loss: 0.2034
2023-02-06 11:28:49 | Valid | Epoch[146/600] Iteration[005/008] Valid loss: 0.2132
2023-02-06 11:28:49 | Valid | Epoch[146/600] Iteration[006/008] Valid loss: 0.2051
2023-02-06 11:28:49 | Valid | Epoch[146/600] Iteration[007/008] Valid loss: 0.2228
2023-02-06 11:28:49 | Valid | Epoch[146/600] Iteration[008/008] Valid loss: 0.2199
2023-02-06 11:28:50 | Valid | Epoch[146/600] MIou: 0.920920598123514
2023-02-06 11:28:50 | Valid | Epoch[146/600] Pixel Accuracy: 0.9854965209960938
2023-02-06 11:28:50 | Valid | Epoch[146/600] Mean Pixel Accuracy: 0.9776924632922217
2023-02-06 11:28:50 | Stage | Epoch[146/600] Train loss:0.0344
2023-02-06 11:28:50 | Stage | Epoch[146/600] Valid loss:0.2199
2023-02-06 11:28:50 | Stage | Epoch[146/600] LR:0.01

2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[001/030] Train loss: 0.0326
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[002/030] Train loss: 0.0337
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[003/030] Train loss: 0.0338
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[004/030] Train loss: 0.0342
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[005/030] Train loss: 0.0341
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[006/030] Train loss: 0.0350
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[007/030] Train loss: 0.0350
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[008/030] Train loss: 0.0350
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[009/030] Train loss: 0.0346
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[010/030] Train loss: 0.0342
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[011/030] Train loss: 0.0340
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[012/030] Train loss: 0.0343
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[013/030] Train loss: 0.0342
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[014/030] Train loss: 0.0342
2023-02-06 11:28:50 | Train | Epoch[147/600] Iteration[015/030] Train loss: 0.0344
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[016/030] Train loss: 0.0342
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[017/030] Train loss: 0.0343
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[018/030] Train loss: 0.0346
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[019/030] Train loss: 0.0346
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[020/030] Train loss: 0.0347
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[021/030] Train loss: 0.0347
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[022/030] Train loss: 0.0349
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[023/030] Train loss: 0.0349
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[024/030] Train loss: 0.0348
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[025/030] Train loss: 0.0348
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[026/030] Train loss: 0.0347
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[027/030] Train loss: 0.0347
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[028/030] Train loss: 0.0347
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[029/030] Train loss: 0.0346
2023-02-06 11:28:51 | Train | Epoch[147/600] Iteration[030/030] Train loss: 0.0346
2023-02-06 11:28:52 | Valid | Epoch[147/600] Iteration[001/008] Valid loss: 0.0844
2023-02-06 11:28:52 | Valid | Epoch[147/600] Iteration[002/008] Valid loss: 0.0618
2023-02-06 11:28:52 | Valid | Epoch[147/600] Iteration[003/008] Valid loss: 0.0558
2023-02-06 11:28:52 | Valid | Epoch[147/600] Iteration[004/008] Valid loss: 0.0564
2023-02-06 11:28:52 | Valid | Epoch[147/600] Iteration[005/008] Valid loss: 0.0575
2023-02-06 11:28:52 | Valid | Epoch[147/600] Iteration[006/008] Valid loss: 0.0551
2023-02-06 11:28:52 | Valid | Epoch[147/600] Iteration[007/008] Valid loss: 0.0574
2023-02-06 11:28:52 | Valid | Epoch[147/600] Iteration[008/008] Valid loss: 0.0560
2023-02-06 11:28:52 | Valid | Epoch[147/600] MIou: 0.9281941930923173
2023-02-06 11:28:52 | Valid | Epoch[147/600] Pixel Accuracy: 0.9878209431966146
2023-02-06 11:28:52 | Valid | Epoch[147/600] Mean Pixel Accuracy: 0.9480919686040086
2023-02-06 11:28:52 | Stage | Epoch[147/600] Train loss:0.0346
2023-02-06 11:28:52 | Stage | Epoch[147/600] Valid loss:0.0560
2023-02-06 11:28:52 | Stage | Epoch[147/600] LR:0.01

2023-02-06 11:28:52 | Train | Epoch[148/600] Iteration[001/030] Train loss: 0.0313
2023-02-06 11:28:52 | Train | Epoch[148/600] Iteration[002/030] Train loss: 0.0318
2023-02-06 11:28:52 | Train | Epoch[148/600] Iteration[003/030] Train loss: 0.0313
2023-02-06 11:28:52 | Train | Epoch[148/600] Iteration[004/030] Train loss: 0.0323
2023-02-06 11:28:52 | Train | Epoch[148/600] Iteration[005/030] Train loss: 0.0319
2023-02-06 11:28:52 | Train | Epoch[148/600] Iteration[006/030] Train loss: 0.0328
2023-02-06 11:28:52 | Train | Epoch[148/600] Iteration[007/030] Train loss: 0.0338
2023-02-06 11:28:52 | Train | Epoch[148/600] Iteration[008/030] Train loss: 0.0336
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[009/030] Train loss: 0.0335
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[010/030] Train loss: 0.0341
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[011/030] Train loss: 0.0339
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[012/030] Train loss: 0.0339
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[013/030] Train loss: 0.0338
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[014/030] Train loss: 0.0336
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[015/030] Train loss: 0.0336
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[016/030] Train loss: 0.0336
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[017/030] Train loss: 0.0335
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[018/030] Train loss: 0.0338
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[019/030] Train loss: 0.0339
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[020/030] Train loss: 0.0338
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[021/030] Train loss: 0.0339
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[022/030] Train loss: 0.0339
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[023/030] Train loss: 0.0338
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[024/030] Train loss: 0.0339
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[025/030] Train loss: 0.0339
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[026/030] Train loss: 0.0338
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[027/030] Train loss: 0.0340
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[028/030] Train loss: 0.0339
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[029/030] Train loss: 0.0338
2023-02-06 11:28:53 | Train | Epoch[148/600] Iteration[030/030] Train loss: 0.0339
2023-02-06 11:28:54 | Valid | Epoch[148/600] Iteration[001/008] Valid loss: 0.1825
2023-02-06 11:28:54 | Valid | Epoch[148/600] Iteration[002/008] Valid loss: 0.1312
2023-02-06 11:28:54 | Valid | Epoch[148/600] Iteration[003/008] Valid loss: 0.1243
2023-02-06 11:28:54 | Valid | Epoch[148/600] Iteration[004/008] Valid loss: 0.1278
2023-02-06 11:28:54 | Valid | Epoch[148/600] Iteration[005/008] Valid loss: 0.1328
2023-02-06 11:28:54 | Valid | Epoch[148/600] Iteration[006/008] Valid loss: 0.1279
2023-02-06 11:28:54 | Valid | Epoch[148/600] Iteration[007/008] Valid loss: 0.1401
2023-02-06 11:28:54 | Valid | Epoch[148/600] Iteration[008/008] Valid loss: 0.1356
2023-02-06 11:28:54 | Valid | Epoch[148/600] MIou: 0.929598976054536
2023-02-06 11:28:54 | Valid | Epoch[148/600] Pixel Accuracy: 0.9873021443684896
2023-02-06 11:28:54 | Valid | Epoch[148/600] Mean Pixel Accuracy: 0.9783361849725004
2023-02-06 11:28:54 | Stage | Epoch[148/600] Train loss:0.0339
2023-02-06 11:28:54 | Stage | Epoch[148/600] Valid loss:0.1356
2023-02-06 11:28:54 | Stage | Epoch[148/600] LR:0.01

2023-02-06 11:28:54 | Train | Epoch[149/600] Iteration[001/030] Train loss: 0.0306
2023-02-06 11:28:54 | Train | Epoch[149/600] Iteration[002/030] Train loss: 0.0340
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[003/030] Train loss: 0.0334
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[004/030] Train loss: 0.0337
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[005/030] Train loss: 0.0334
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[006/030] Train loss: 0.0334
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[007/030] Train loss: 0.0339
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[008/030] Train loss: 0.0339
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[009/030] Train loss: 0.0342
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[010/030] Train loss: 0.0338
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[011/030] Train loss: 0.0339
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[012/030] Train loss: 0.0338
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[013/030] Train loss: 0.0336
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[014/030] Train loss: 0.0335
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[015/030] Train loss: 0.0335
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[016/030] Train loss: 0.0336
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[017/030] Train loss: 0.0336
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[018/030] Train loss: 0.0337
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[019/030] Train loss: 0.0336
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[020/030] Train loss: 0.0344
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[021/030] Train loss: 0.0343
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[022/030] Train loss: 0.0345
2023-02-06 11:28:55 | Train | Epoch[149/600] Iteration[023/030] Train loss: 0.0344
2023-02-06 11:28:56 | Train | Epoch[149/600] Iteration[024/030] Train loss: 0.0344
2023-02-06 11:28:56 | Train | Epoch[149/600] Iteration[025/030] Train loss: 0.0344
2023-02-06 11:28:56 | Train | Epoch[149/600] Iteration[026/030] Train loss: 0.0344
2023-02-06 11:28:56 | Train | Epoch[149/600] Iteration[027/030] Train loss: 0.0345
2023-02-06 11:28:56 | Train | Epoch[149/600] Iteration[028/030] Train loss: 0.0344
2023-02-06 11:28:56 | Train | Epoch[149/600] Iteration[029/030] Train loss: 0.0344
2023-02-06 11:28:56 | Train | Epoch[149/600] Iteration[030/030] Train loss: 0.0342
2023-02-06 11:28:56 | Valid | Epoch[149/600] Iteration[001/008] Valid loss: 0.3326
2023-02-06 11:28:56 | Valid | Epoch[149/600] Iteration[002/008] Valid loss: 0.2683
2023-02-06 11:28:56 | Valid | Epoch[149/600] Iteration[003/008] Valid loss: 0.2590
2023-02-06 11:28:56 | Valid | Epoch[149/600] Iteration[004/008] Valid loss: 0.2585
2023-02-06 11:28:56 | Valid | Epoch[149/600] Iteration[005/008] Valid loss: 0.2689
2023-02-06 11:28:56 | Valid | Epoch[149/600] Iteration[006/008] Valid loss: 0.2603
2023-02-06 11:28:56 | Valid | Epoch[149/600] Iteration[007/008] Valid loss: 0.2696
2023-02-06 11:28:56 | Valid | Epoch[149/600] Iteration[008/008] Valid loss: 0.2753
2023-02-06 11:28:56 | Valid | Epoch[149/600] MIou: 0.9016945086237463
2023-02-06 11:28:56 | Valid | Epoch[149/600] Pixel Accuracy: 0.9810969034830729
2023-02-06 11:28:56 | Valid | Epoch[149/600] Mean Pixel Accuracy: 0.9809426273997162
2023-02-06 11:28:56 | Stage | Epoch[149/600] Train loss:0.0342
2023-02-06 11:28:56 | Stage | Epoch[149/600] Valid loss:0.2753
2023-02-06 11:28:56 | Stage | Epoch[149/600] LR:0.01

2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[001/030] Train loss: 0.0353
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[002/030] Train loss: 0.0334
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[003/030] Train loss: 0.0339
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[004/030] Train loss: 0.0338
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[005/030] Train loss: 0.0345
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[006/030] Train loss: 0.0344
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[007/030] Train loss: 0.0345
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[008/030] Train loss: 0.0351
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[009/030] Train loss: 0.0351
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[010/030] Train loss: 0.0348
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[011/030] Train loss: 0.0346
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[012/030] Train loss: 0.0343
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[013/030] Train loss: 0.0341
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[014/030] Train loss: 0.0340
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[015/030] Train loss: 0.0338
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[016/030] Train loss: 0.0339
2023-02-06 11:28:57 | Train | Epoch[150/600] Iteration[017/030] Train loss: 0.0340
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[018/030] Train loss: 0.0340
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[019/030] Train loss: 0.0340
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[020/030] Train loss: 0.0341
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[021/030] Train loss: 0.0341
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[022/030] Train loss: 0.0342
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[023/030] Train loss: 0.0342
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[024/030] Train loss: 0.0342
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[025/030] Train loss: 0.0340
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[026/030] Train loss: 0.0341
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[027/030] Train loss: 0.0341
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[028/030] Train loss: 0.0342
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[029/030] Train loss: 0.0342
2023-02-06 11:28:58 | Train | Epoch[150/600] Iteration[030/030] Train loss: 0.0341
2023-02-06 11:28:58 | Valid | Epoch[150/600] Iteration[001/008] Valid loss: 1.5307
2023-02-06 11:28:58 | Valid | Epoch[150/600] Iteration[002/008] Valid loss: 1.4591
2023-02-06 11:28:59 | Valid | Epoch[150/600] Iteration[003/008] Valid loss: 1.4889
2023-02-06 11:28:59 | Valid | Epoch[150/600] Iteration[004/008] Valid loss: 1.5406
2023-02-06 11:28:59 | Valid | Epoch[150/600] Iteration[005/008] Valid loss: 1.5773
2023-02-06 11:28:59 | Valid | Epoch[150/600] Iteration[006/008] Valid loss: 1.5488
2023-02-06 11:28:59 | Valid | Epoch[150/600] Iteration[007/008] Valid loss: 1.5950
2023-02-06 11:28:59 | Valid | Epoch[150/600] Iteration[008/008] Valid loss: 1.6420
2023-02-06 11:28:59 | Valid | Epoch[150/600] MIou: 0.8114550568501303
2023-02-06 11:28:59 | Valid | Epoch[150/600] Pixel Accuracy: 0.9558982849121094
2023-02-06 11:28:59 | Valid | Epoch[150/600] Mean Pixel Accuracy: 0.9746755958664728
2023-02-06 11:28:59 | Stage | Epoch[150/600] Train loss:0.0341
2023-02-06 11:28:59 | Stage | Epoch[150/600] Valid loss:1.6420
2023-02-06 11:28:59 | Stage | Epoch[150/600] LR:0.01

2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[001/030] Train loss: 0.0355
2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[002/030] Train loss: 0.0347
2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[003/030] Train loss: 0.0347
2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[004/030] Train loss: 0.0336
2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[005/030] Train loss: 0.0330
2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[006/030] Train loss: 0.0330
2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[007/030] Train loss: 0.0330
2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[008/030] Train loss: 0.0329
2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[009/030] Train loss: 0.0329
2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[010/030] Train loss: 0.0328
2023-02-06 11:28:59 | Train | Epoch[151/600] Iteration[011/030] Train loss: 0.0329
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[012/030] Train loss: 0.0328
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[013/030] Train loss: 0.0327
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[014/030] Train loss: 0.0329
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[015/030] Train loss: 0.0329
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[016/030] Train loss: 0.0329
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[017/030] Train loss: 0.0331
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[018/030] Train loss: 0.0332
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[019/030] Train loss: 0.0332
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[020/030] Train loss: 0.0334
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[021/030] Train loss: 0.0333
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[022/030] Train loss: 0.0334
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[023/030] Train loss: 0.0335
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[024/030] Train loss: 0.0334
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[025/030] Train loss: 0.0334
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[026/030] Train loss: 0.0333
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[027/030] Train loss: 0.0336
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[028/030] Train loss: 0.0336
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[029/030] Train loss: 0.0336
2023-02-06 11:29:00 | Train | Epoch[151/600] Iteration[030/030] Train loss: 0.0337
2023-02-06 11:29:01 | Valid | Epoch[151/600] Iteration[001/008] Valid loss: 0.2076
2023-02-06 11:29:01 | Valid | Epoch[151/600] Iteration[002/008] Valid loss: 0.1504
2023-02-06 11:29:01 | Valid | Epoch[151/600] Iteration[003/008] Valid loss: 0.1385
2023-02-06 11:29:01 | Valid | Epoch[151/600] Iteration[004/008] Valid loss: 0.1419
2023-02-06 11:29:01 | Valid | Epoch[151/600] Iteration[005/008] Valid loss: 0.1499
2023-02-06 11:29:01 | Valid | Epoch[151/600] Iteration[006/008] Valid loss: 0.1441
2023-02-06 11:29:01 | Valid | Epoch[151/600] Iteration[007/008] Valid loss: 0.1558
2023-02-06 11:29:01 | Valid | Epoch[151/600] Iteration[008/008] Valid loss: 0.1522
2023-02-06 11:29:01 | Valid | Epoch[151/600] MIou: 0.9267267857655929
2023-02-06 11:29:01 | Valid | Epoch[151/600] Pixel Accuracy: 0.9866422017415365
2023-02-06 11:29:01 | Valid | Epoch[151/600] Mean Pixel Accuracy: 0.9806681527514887
2023-02-06 11:29:01 | Stage | Epoch[151/600] Train loss:0.0337
2023-02-06 11:29:01 | Stage | Epoch[151/600] Valid loss:0.1522
2023-02-06 11:29:01 | Stage | Epoch[151/600] LR:0.01

2023-02-06 11:29:01 | Train | Epoch[152/600] Iteration[001/030] Train loss: 0.0313
2023-02-06 11:29:01 | Train | Epoch[152/600] Iteration[002/030] Train loss: 0.0307
2023-02-06 11:29:01 | Train | Epoch[152/600] Iteration[003/030] Train loss: 0.0323
2023-02-06 11:29:01 | Train | Epoch[152/600] Iteration[004/030] Train loss: 0.0321
2023-02-06 11:29:01 | Train | Epoch[152/600] Iteration[005/030] Train loss: 0.0322
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[006/030] Train loss: 0.0326
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[007/030] Train loss: 0.0322
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[008/030] Train loss: 0.0320
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[009/030] Train loss: 0.0320
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[010/030] Train loss: 0.0325
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[011/030] Train loss: 0.0325
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[012/030] Train loss: 0.0327
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[013/030] Train loss: 0.0326
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[014/030] Train loss: 0.0327
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[015/030] Train loss: 0.0328
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[016/030] Train loss: 0.0327
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[017/030] Train loss: 0.0329
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[018/030] Train loss: 0.0328
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[019/030] Train loss: 0.0327
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[020/030] Train loss: 0.0328
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[021/030] Train loss: 0.0329
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[022/030] Train loss: 0.0328
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[023/030] Train loss: 0.0327
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[024/030] Train loss: 0.0331
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[025/030] Train loss: 0.0331
2023-02-06 11:29:02 | Train | Epoch[152/600] Iteration[026/030] Train loss: 0.0331
2023-02-06 11:29:03 | Train | Epoch[152/600] Iteration[027/030] Train loss: 0.0332
2023-02-06 11:29:03 | Train | Epoch[152/600] Iteration[028/030] Train loss: 0.0332
2023-02-06 11:29:03 | Train | Epoch[152/600] Iteration[029/030] Train loss: 0.0331
2023-02-06 11:29:03 | Train | Epoch[152/600] Iteration[030/030] Train loss: 0.0331
2023-02-06 11:29:03 | Valid | Epoch[152/600] Iteration[001/008] Valid loss: 0.0518
2023-02-06 11:29:03 | Valid | Epoch[152/600] Iteration[002/008] Valid loss: 0.0512
2023-02-06 11:29:03 | Valid | Epoch[152/600] Iteration[003/008] Valid loss: 0.0514
2023-02-06 11:29:03 | Valid | Epoch[152/600] Iteration[004/008] Valid loss: 0.0499
2023-02-06 11:29:03 | Valid | Epoch[152/600] Iteration[005/008] Valid loss: 0.0513
2023-02-06 11:29:03 | Valid | Epoch[152/600] Iteration[006/008] Valid loss: 0.0508
2023-02-06 11:29:03 | Valid | Epoch[152/600] Iteration[007/008] Valid loss: 0.0496
2023-02-06 11:29:03 | Valid | Epoch[152/600] Iteration[008/008] Valid loss: 0.0504
2023-02-06 11:29:03 | Valid | Epoch[152/600] MIou: 0.8548006898657992
2023-02-06 11:29:03 | Valid | Epoch[152/600] Pixel Accuracy: 0.9760258992513021
2023-02-06 11:29:03 | Valid | Epoch[152/600] Mean Pixel Accuracy: 0.8685159538139513
2023-02-06 11:29:03 | Stage | Epoch[152/600] Train loss:0.0331
2023-02-06 11:29:03 | Stage | Epoch[152/600] Valid loss:0.0504
2023-02-06 11:29:03 | Stage | Epoch[152/600] LR:0.01

2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[001/030] Train loss: 0.0314
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[002/030] Train loss: 0.0323
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[003/030] Train loss: 0.0338
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[004/030] Train loss: 0.0332
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[005/030] Train loss: 0.0328
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[006/030] Train loss: 0.0326
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[007/030] Train loss: 0.0329
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[008/030] Train loss: 0.0328
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[009/030] Train loss: 0.0331
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[010/030] Train loss: 0.0330
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[011/030] Train loss: 0.0328
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[012/030] Train loss: 0.0329
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[013/030] Train loss: 0.0327
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[014/030] Train loss: 0.0327
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[015/030] Train loss: 0.0332
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[016/030] Train loss: 0.0331
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[017/030] Train loss: 0.0333
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[018/030] Train loss: 0.0333
2023-02-06 11:29:04 | Train | Epoch[153/600] Iteration[019/030] Train loss: 0.0334
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[020/030] Train loss: 0.0333
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[021/030] Train loss: 0.0331
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[022/030] Train loss: 0.0330
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[023/030] Train loss: 0.0329
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[024/030] Train loss: 0.0329
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[025/030] Train loss: 0.0329
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[026/030] Train loss: 0.0328
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[027/030] Train loss: 0.0328
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[028/030] Train loss: 0.0327
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[029/030] Train loss: 0.0327
2023-02-06 11:29:05 | Train | Epoch[153/600] Iteration[030/030] Train loss: 0.0327
2023-02-06 11:29:05 | Valid | Epoch[153/600] Iteration[001/008] Valid loss: 0.0596
2023-02-06 11:29:05 | Valid | Epoch[153/600] Iteration[002/008] Valid loss: 0.0484
2023-02-06 11:29:05 | Valid | Epoch[153/600] Iteration[003/008] Valid loss: 0.0454
2023-02-06 11:29:05 | Valid | Epoch[153/600] Iteration[004/008] Valid loss: 0.0451
2023-02-06 11:29:05 | Valid | Epoch[153/600] Iteration[005/008] Valid loss: 0.0455
2023-02-06 11:29:05 | Valid | Epoch[153/600] Iteration[006/008] Valid loss: 0.0450
2023-02-06 11:29:05 | Valid | Epoch[153/600] Iteration[007/008] Valid loss: 0.0452
2023-02-06 11:29:06 | Valid | Epoch[153/600] Iteration[008/008] Valid loss: 0.0443
2023-02-06 11:29:06 | Valid | Epoch[153/600] MIou: 0.9382865310395212
2023-02-06 11:29:06 | Valid | Epoch[153/600] Pixel Accuracy: 0.9895668029785156
2023-02-06 11:29:06 | Valid | Epoch[153/600] Mean Pixel Accuracy: 0.9561592361643017
2023-02-06 11:29:06 | Stage | Epoch[153/600] Train loss:0.0327
2023-02-06 11:29:06 | Stage | Epoch[153/600] Valid loss:0.0443
2023-02-06 11:29:06 | Stage | Epoch[153/600] LR:0.01

2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[001/030] Train loss: 0.0324
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[002/030] Train loss: 0.0332
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[003/030] Train loss: 0.0320
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[004/030] Train loss: 0.0319
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[005/030] Train loss: 0.0318
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[006/030] Train loss: 0.0314
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[007/030] Train loss: 0.0315
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[008/030] Train loss: 0.0316
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[009/030] Train loss: 0.0314
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[010/030] Train loss: 0.0319
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[011/030] Train loss: 0.0317
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[012/030] Train loss: 0.0317
2023-02-06 11:29:06 | Train | Epoch[154/600] Iteration[013/030] Train loss: 0.0318
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[014/030] Train loss: 0.0318
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[015/030] Train loss: 0.0320
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[016/030] Train loss: 0.0320
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[017/030] Train loss: 0.0320
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[018/030] Train loss: 0.0318
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[019/030] Train loss: 0.0320
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[020/030] Train loss: 0.0321
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[021/030] Train loss: 0.0321
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[022/030] Train loss: 0.0321
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[023/030] Train loss: 0.0322
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[024/030] Train loss: 0.0323
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[025/030] Train loss: 0.0323
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[026/030] Train loss: 0.0326
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[027/030] Train loss: 0.0326
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[028/030] Train loss: 0.0325
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[029/030] Train loss: 0.0325
2023-02-06 11:29:07 | Train | Epoch[154/600] Iteration[030/030] Train loss: 0.0324
2023-02-06 11:29:08 | Valid | Epoch[154/600] Iteration[001/008] Valid loss: 0.0509
2023-02-06 11:29:08 | Valid | Epoch[154/600] Iteration[002/008] Valid loss: 0.0490
2023-02-06 11:29:08 | Valid | Epoch[154/600] Iteration[003/008] Valid loss: 0.0486
2023-02-06 11:29:08 | Valid | Epoch[154/600] Iteration[004/008] Valid loss: 0.0473
2023-02-06 11:29:08 | Valid | Epoch[154/600] Iteration[005/008] Valid loss: 0.0481
2023-02-06 11:29:08 | Valid | Epoch[154/600] Iteration[006/008] Valid loss: 0.0478
2023-02-06 11:29:08 | Valid | Epoch[154/600] Iteration[007/008] Valid loss: 0.0467
2023-02-06 11:29:08 | Valid | Epoch[154/600] Iteration[008/008] Valid loss: 0.0476
2023-02-06 11:29:08 | Valid | Epoch[154/600] MIou: 0.8544831333330074
2023-02-06 11:29:08 | Valid | Epoch[154/600] Pixel Accuracy: 0.9759941101074219
2023-02-06 11:29:08 | Valid | Epoch[154/600] Mean Pixel Accuracy: 0.8679088172940771
2023-02-06 11:29:08 | Stage | Epoch[154/600] Train loss:0.0324
2023-02-06 11:29:08 | Stage | Epoch[154/600] Valid loss:0.0476
2023-02-06 11:29:08 | Stage | Epoch[154/600] LR:0.01

2023-02-06 11:29:08 | Train | Epoch[155/600] Iteration[001/030] Train loss: 0.0326
2023-02-06 11:29:08 | Train | Epoch[155/600] Iteration[002/030] Train loss: 0.0317
2023-02-06 11:29:08 | Train | Epoch[155/600] Iteration[003/030] Train loss: 0.0322
2023-02-06 11:29:08 | Train | Epoch[155/600] Iteration[004/030] Train loss: 0.0326
2023-02-06 11:29:08 | Train | Epoch[155/600] Iteration[005/030] Train loss: 0.0336
2023-02-06 11:29:08 | Train | Epoch[155/600] Iteration[006/030] Train loss: 0.0338
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[007/030] Train loss: 0.0332
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[008/030] Train loss: 0.0334
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[009/030] Train loss: 0.0331
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[010/030] Train loss: 0.0333
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[011/030] Train loss: 0.0329
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[012/030] Train loss: 0.0328
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[013/030] Train loss: 0.0325
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[014/030] Train loss: 0.0327
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[015/030] Train loss: 0.0327
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[016/030] Train loss: 0.0328
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[017/030] Train loss: 0.0325
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[018/030] Train loss: 0.0325
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[019/030] Train loss: 0.0324
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[020/030] Train loss: 0.0323
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[021/030] Train loss: 0.0322
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[022/030] Train loss: 0.0321
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[023/030] Train loss: 0.0320
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[024/030] Train loss: 0.0322
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[025/030] Train loss: 0.0323
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[026/030] Train loss: 0.0323
2023-02-06 11:29:09 | Train | Epoch[155/600] Iteration[027/030] Train loss: 0.0323
2023-02-06 11:29:10 | Train | Epoch[155/600] Iteration[028/030] Train loss: 0.0323
2023-02-06 11:29:10 | Train | Epoch[155/600] Iteration[029/030] Train loss: 0.0322
2023-02-06 11:29:10 | Train | Epoch[155/600] Iteration[030/030] Train loss: 0.0322
2023-02-06 11:29:10 | Valid | Epoch[155/600] Iteration[001/008] Valid loss: 1.0921
2023-02-06 11:29:10 | Valid | Epoch[155/600] Iteration[002/008] Valid loss: 1.0592
2023-02-06 11:29:10 | Valid | Epoch[155/600] Iteration[003/008] Valid loss: 1.0730
2023-02-06 11:29:10 | Valid | Epoch[155/600] Iteration[004/008] Valid loss: 1.1031
2023-02-06 11:29:10 | Valid | Epoch[155/600] Iteration[005/008] Valid loss: 1.1350
2023-02-06 11:29:10 | Valid | Epoch[155/600] Iteration[006/008] Valid loss: 1.1012
2023-02-06 11:29:10 | Valid | Epoch[155/600] Iteration[007/008] Valid loss: 1.1418
2023-02-06 11:29:10 | Valid | Epoch[155/600] Iteration[008/008] Valid loss: 1.1721
2023-02-06 11:29:10 | Valid | Epoch[155/600] MIou: 0.8385211212657
2023-02-06 11:29:10 | Valid | Epoch[155/600] Pixel Accuracy: 0.964361826578776
2023-02-06 11:29:10 | Valid | Epoch[155/600] Mean Pixel Accuracy: 0.9785159389742484
2023-02-06 11:29:10 | Stage | Epoch[155/600] Train loss:0.0322
2023-02-06 11:29:10 | Stage | Epoch[155/600] Valid loss:1.1721
2023-02-06 11:29:10 | Stage | Epoch[155/600] LR:0.01

2023-02-06 11:29:10 | Train | Epoch[156/600] Iteration[001/030] Train loss: 0.0307
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[002/030] Train loss: 0.0324
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[003/030] Train loss: 0.0321
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[004/030] Train loss: 0.0333
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[005/030] Train loss: 0.0327
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[006/030] Train loss: 0.0328
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[007/030] Train loss: 0.0325
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[008/030] Train loss: 0.0326
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[009/030] Train loss: 0.0327
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[010/030] Train loss: 0.0325
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[011/030] Train loss: 0.0326
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[012/030] Train loss: 0.0327
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[013/030] Train loss: 0.0326
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[014/030] Train loss: 0.0326
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[015/030] Train loss: 0.0330
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[016/030] Train loss: 0.0329
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[017/030] Train loss: 0.0329
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[018/030] Train loss: 0.0329
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[019/030] Train loss: 0.0328
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[020/030] Train loss: 0.0326
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[021/030] Train loss: 0.0328
2023-02-06 11:29:11 | Train | Epoch[156/600] Iteration[022/030] Train loss: 0.0328
2023-02-06 11:29:12 | Train | Epoch[156/600] Iteration[023/030] Train loss: 0.0328
2023-02-06 11:29:12 | Train | Epoch[156/600] Iteration[024/030] Train loss: 0.0330
2023-02-06 11:29:12 | Train | Epoch[156/600] Iteration[025/030] Train loss: 0.0329
2023-02-06 11:29:12 | Train | Epoch[156/600] Iteration[026/030] Train loss: 0.0330
2023-02-06 11:29:12 | Train | Epoch[156/600] Iteration[027/030] Train loss: 0.0329
2023-02-06 11:29:12 | Train | Epoch[156/600] Iteration[028/030] Train loss: 0.0329
2023-02-06 11:29:12 | Train | Epoch[156/600] Iteration[029/030] Train loss: 0.0330
2023-02-06 11:29:12 | Train | Epoch[156/600] Iteration[030/030] Train loss: 0.0330
2023-02-06 11:29:12 | Valid | Epoch[156/600] Iteration[001/008] Valid loss: 0.3837
2023-02-06 11:29:12 | Valid | Epoch[156/600] Iteration[002/008] Valid loss: 0.3007
2023-02-06 11:29:12 | Valid | Epoch[156/600] Iteration[003/008] Valid loss: 0.2957
2023-02-06 11:29:12 | Valid | Epoch[156/600] Iteration[004/008] Valid loss: 0.2988
2023-02-06 11:29:12 | Valid | Epoch[156/600] Iteration[005/008] Valid loss: 0.3163
2023-02-06 11:29:12 | Valid | Epoch[156/600] Iteration[006/008] Valid loss: 0.3043
2023-02-06 11:29:12 | Valid | Epoch[156/600] Iteration[007/008] Valid loss: 0.3255
2023-02-06 11:29:12 | Valid | Epoch[156/600] Iteration[008/008] Valid loss: 0.3234
2023-02-06 11:29:12 | Valid | Epoch[156/600] MIou: 0.9111073069038778
2023-02-06 11:29:12 | Valid | Epoch[156/600] Pixel Accuracy: 0.983154296875
2023-02-06 11:29:12 | Valid | Epoch[156/600] Mean Pixel Accuracy: 0.9836966192607177
2023-02-06 11:29:12 | Stage | Epoch[156/600] Train loss:0.0330
2023-02-06 11:29:12 | Stage | Epoch[156/600] Valid loss:0.3234
2023-02-06 11:29:12 | Stage | Epoch[156/600] LR:0.01

2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[001/030] Train loss: 0.0333
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[002/030] Train loss: 0.0315
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[003/030] Train loss: 0.0338
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[004/030] Train loss: 0.0343
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[005/030] Train loss: 0.0338
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[006/030] Train loss: 0.0337
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[007/030] Train loss: 0.0335
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[008/030] Train loss: 0.0331
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[009/030] Train loss: 0.0328
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[010/030] Train loss: 0.0327
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[011/030] Train loss: 0.0332
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[012/030] Train loss: 0.0331
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[013/030] Train loss: 0.0329
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[014/030] Train loss: 0.0331
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[015/030] Train loss: 0.0331
2023-02-06 11:29:13 | Train | Epoch[157/600] Iteration[016/030] Train loss: 0.0330
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[017/030] Train loss: 0.0329
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[018/030] Train loss: 0.0329
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[019/030] Train loss: 0.0328
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[020/030] Train loss: 0.0327
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[021/030] Train loss: 0.0326
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[022/030] Train loss: 0.0325
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[023/030] Train loss: 0.0325
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[024/030] Train loss: 0.0325
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[025/030] Train loss: 0.0324
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[026/030] Train loss: 0.0325
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[027/030] Train loss: 0.0324
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[028/030] Train loss: 0.0325
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[029/030] Train loss: 0.0325
2023-02-06 11:29:14 | Train | Epoch[157/600] Iteration[030/030] Train loss: 0.0324
2023-02-06 11:29:15 | Valid | Epoch[157/600] Iteration[001/008] Valid loss: 0.0515
2023-02-06 11:29:15 | Valid | Epoch[157/600] Iteration[002/008] Valid loss: 0.0428
2023-02-06 11:29:15 | Valid | Epoch[157/600] Iteration[003/008] Valid loss: 0.0408
2023-02-06 11:29:15 | Valid | Epoch[157/600] Iteration[004/008] Valid loss: 0.0401
2023-02-06 11:29:15 | Valid | Epoch[157/600] Iteration[005/008] Valid loss: 0.0411
2023-02-06 11:29:15 | Valid | Epoch[157/600] Iteration[006/008] Valid loss: 0.0410
2023-02-06 11:29:15 | Valid | Epoch[157/600] Iteration[007/008] Valid loss: 0.0413
2023-02-06 11:29:15 | Valid | Epoch[157/600] Iteration[008/008] Valid loss: 0.0406
2023-02-06 11:29:15 | Valid | Epoch[157/600] MIou: 0.9336853140126702
2023-02-06 11:29:15 | Valid | Epoch[157/600] Pixel Accuracy: 0.9888801574707031
2023-02-06 11:29:15 | Valid | Epoch[157/600] Mean Pixel Accuracy: 0.9481225369218929
2023-02-06 11:29:15 | Stage | Epoch[157/600] Train loss:0.0324
2023-02-06 11:29:15 | Stage | Epoch[157/600] Valid loss:0.0406
2023-02-06 11:29:15 | Stage | Epoch[157/600] LR:0.01

2023-02-06 11:29:15 | Train | Epoch[158/600] Iteration[001/030] Train loss: 0.0322
2023-02-06 11:29:15 | Train | Epoch[158/600] Iteration[002/030] Train loss: 0.0310
2023-02-06 11:29:15 | Train | Epoch[158/600] Iteration[003/030] Train loss: 0.0311
2023-02-06 11:29:15 | Train | Epoch[158/600] Iteration[004/030] Train loss: 0.0311
2023-02-06 11:29:15 | Train | Epoch[158/600] Iteration[005/030] Train loss: 0.0311
2023-02-06 11:29:15 | Train | Epoch[158/600] Iteration[006/030] Train loss: 0.0314
2023-02-06 11:29:15 | Train | Epoch[158/600] Iteration[007/030] Train loss: 0.0315
2023-02-06 11:29:15 | Train | Epoch[158/600] Iteration[008/030] Train loss: 0.0314
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[009/030] Train loss: 0.0320
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[010/030] Train loss: 0.0318
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[011/030] Train loss: 0.0319
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[012/030] Train loss: 0.0318
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[013/030] Train loss: 0.0317
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[014/030] Train loss: 0.0320
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[015/030] Train loss: 0.0321
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[016/030] Train loss: 0.0321
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[017/030] Train loss: 0.0320
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[018/030] Train loss: 0.0321
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[019/030] Train loss: 0.0320
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[020/030] Train loss: 0.0323
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[021/030] Train loss: 0.0322
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[022/030] Train loss: 0.0321
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[023/030] Train loss: 0.0322
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[024/030] Train loss: 0.0322
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[025/030] Train loss: 0.0323
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[026/030] Train loss: 0.0323
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[027/030] Train loss: 0.0322
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[028/030] Train loss: 0.0322
2023-02-06 11:29:16 | Train | Epoch[158/600] Iteration[029/030] Train loss: 0.0322
2023-02-06 11:29:17 | Train | Epoch[158/600] Iteration[030/030] Train loss: 0.0323
2023-02-06 11:29:17 | Valid | Epoch[158/600] Iteration[001/008] Valid loss: 0.0584
2023-02-06 11:29:17 | Valid | Epoch[158/600] Iteration[002/008] Valid loss: 0.0532
2023-02-06 11:29:17 | Valid | Epoch[158/600] Iteration[003/008] Valid loss: 0.0498
2023-02-06 11:29:17 | Valid | Epoch[158/600] Iteration[004/008] Valid loss: 0.0493
2023-02-06 11:29:17 | Valid | Epoch[158/600] Iteration[005/008] Valid loss: 0.0496
2023-02-06 11:29:17 | Valid | Epoch[158/600] Iteration[006/008] Valid loss: 0.0497
2023-02-06 11:29:17 | Valid | Epoch[158/600] Iteration[007/008] Valid loss: 0.0497
2023-02-06 11:29:17 | Valid | Epoch[158/600] Iteration[008/008] Valid loss: 0.0491
2023-02-06 11:29:17 | Valid | Epoch[158/600] MIou: 0.9246945468868651
2023-02-06 11:29:17 | Valid | Epoch[158/600] Pixel Accuracy: 0.9872144063313802
2023-02-06 11:29:17 | Valid | Epoch[158/600] Mean Pixel Accuracy: 0.9452287419413843
2023-02-06 11:29:17 | Stage | Epoch[158/600] Train loss:0.0323
2023-02-06 11:29:17 | Stage | Epoch[158/600] Valid loss:0.0491
2023-02-06 11:29:17 | Stage | Epoch[158/600] LR:0.01

2023-02-06 11:29:17 | Train | Epoch[159/600] Iteration[001/030] Train loss: 0.0327
2023-02-06 11:29:17 | Train | Epoch[159/600] Iteration[002/030] Train loss: 0.0323
2023-02-06 11:29:17 | Train | Epoch[159/600] Iteration[003/030] Train loss: 0.0311
2023-02-06 11:29:17 | Train | Epoch[159/600] Iteration[004/030] Train loss: 0.0308
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[005/030] Train loss: 0.0315
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[006/030] Train loss: 0.0322
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[007/030] Train loss: 0.0319
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[008/030] Train loss: 0.0317
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[009/030] Train loss: 0.0316
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[010/030] Train loss: 0.0315
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[011/030] Train loss: 0.0317
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[012/030] Train loss: 0.0315
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[013/030] Train loss: 0.0313
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[014/030] Train loss: 0.0314
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[015/030] Train loss: 0.0315
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[016/030] Train loss: 0.0315
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[017/030] Train loss: 0.0315
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[018/030] Train loss: 0.0318
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[019/030] Train loss: 0.0318
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[020/030] Train loss: 0.0317
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[021/030] Train loss: 0.0317
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[022/030] Train loss: 0.0318
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[023/030] Train loss: 0.0318
2023-02-06 11:29:18 | Train | Epoch[159/600] Iteration[024/030] Train loss: 0.0318
2023-02-06 11:29:19 | Train | Epoch[159/600] Iteration[025/030] Train loss: 0.0319
2023-02-06 11:29:19 | Train | Epoch[159/600] Iteration[026/030] Train loss: 0.0320
2023-02-06 11:29:19 | Train | Epoch[159/600] Iteration[027/030] Train loss: 0.0320
2023-02-06 11:29:19 | Train | Epoch[159/600] Iteration[028/030] Train loss: 0.0320
2023-02-06 11:29:19 | Train | Epoch[159/600] Iteration[029/030] Train loss: 0.0319
2023-02-06 11:29:19 | Train | Epoch[159/600] Iteration[030/030] Train loss: 0.0318
2023-02-06 11:29:19 | Valid | Epoch[159/600] Iteration[001/008] Valid loss: 0.1950
2023-02-06 11:29:19 | Valid | Epoch[159/600] Iteration[002/008] Valid loss: 0.1328
2023-02-06 11:29:19 | Valid | Epoch[159/600] Iteration[003/008] Valid loss: 0.1208
2023-02-06 11:29:19 | Valid | Epoch[159/600] Iteration[004/008] Valid loss: 0.1211
2023-02-06 11:29:19 | Valid | Epoch[159/600] Iteration[005/008] Valid loss: 0.1276
2023-02-06 11:29:19 | Valid | Epoch[159/600] Iteration[006/008] Valid loss: 0.1209
2023-02-06 11:29:19 | Valid | Epoch[159/600] Iteration[007/008] Valid loss: 0.1329
2023-02-06 11:29:19 | Valid | Epoch[159/600] Iteration[008/008] Valid loss: 0.1291
2023-02-06 11:29:19 | Valid | Epoch[159/600] MIou: 0.930294934476496
2023-02-06 11:29:19 | Valid | Epoch[159/600] Pixel Accuracy: 0.9875920613606771
2023-02-06 11:29:19 | Valid | Epoch[159/600] Mean Pixel Accuracy: 0.9726432805104177
2023-02-06 11:29:19 | Stage | Epoch[159/600] Train loss:0.0318
2023-02-06 11:29:19 | Stage | Epoch[159/600] Valid loss:0.1291
2023-02-06 11:29:19 | Stage | Epoch[159/600] LR:0.01

2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[001/030] Train loss: 0.0359
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[002/030] Train loss: 0.0347
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[003/030] Train loss: 0.0335
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[004/030] Train loss: 0.0334
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[005/030] Train loss: 0.0325
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[006/030] Train loss: 0.0323
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[007/030] Train loss: 0.0326
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[008/030] Train loss: 0.0324
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[009/030] Train loss: 0.0325
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[010/030] Train loss: 0.0323
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[011/030] Train loss: 0.0324
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[012/030] Train loss: 0.0319
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[013/030] Train loss: 0.0319
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[014/030] Train loss: 0.0323
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[015/030] Train loss: 0.0323
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[016/030] Train loss: 0.0323
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[017/030] Train loss: 0.0322
2023-02-06 11:29:20 | Train | Epoch[160/600] Iteration[018/030] Train loss: 0.0319
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[019/030] Train loss: 0.0319
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[020/030] Train loss: 0.0320
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[021/030] Train loss: 0.0320
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[022/030] Train loss: 0.0319
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[023/030] Train loss: 0.0319
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[024/030] Train loss: 0.0320
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[025/030] Train loss: 0.0319
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[026/030] Train loss: 0.0318
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[027/030] Train loss: 0.0317
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[028/030] Train loss: 0.0316
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[029/030] Train loss: 0.0318
2023-02-06 11:29:21 | Train | Epoch[160/600] Iteration[030/030] Train loss: 0.0317
2023-02-06 11:29:21 | Valid | Epoch[160/600] Iteration[001/008] Valid loss: 0.0678
2023-02-06 11:29:21 | Valid | Epoch[160/600] Iteration[002/008] Valid loss: 0.0529
2023-02-06 11:29:21 | Valid | Epoch[160/600] Iteration[003/008] Valid loss: 0.0484
2023-02-06 11:29:21 | Valid | Epoch[160/600] Iteration[004/008] Valid loss: 0.0466
2023-02-06 11:29:21 | Valid | Epoch[160/600] Iteration[005/008] Valid loss: 0.0472
2023-02-06 11:29:21 | Valid | Epoch[160/600] Iteration[006/008] Valid loss: 0.0465
2023-02-06 11:29:22 | Valid | Epoch[160/600] Iteration[007/008] Valid loss: 0.0463
2023-02-06 11:29:22 | Valid | Epoch[160/600] Iteration[008/008] Valid loss: 0.0455
2023-02-06 11:29:22 | Valid | Epoch[160/600] MIou: 0.9329314966578892
2023-02-06 11:29:22 | Valid | Epoch[160/600] Pixel Accuracy: 0.9886703491210938
2023-02-06 11:29:22 | Valid | Epoch[160/600] Mean Pixel Accuracy: 0.9507463009980563
2023-02-06 11:29:22 | Stage | Epoch[160/600] Train loss:0.0317
2023-02-06 11:29:22 | Stage | Epoch[160/600] Valid loss:0.0455
2023-02-06 11:29:22 | Stage | Epoch[160/600] LR:0.01

2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[001/030] Train loss: 0.0325
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[002/030] Train loss: 0.0307
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[003/030] Train loss: 0.0312
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[004/030] Train loss: 0.0311
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[005/030] Train loss: 0.0310
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[006/030] Train loss: 0.0306
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[007/030] Train loss: 0.0309
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[008/030] Train loss: 0.0311
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[009/030] Train loss: 0.0308
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[010/030] Train loss: 0.0313
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[011/030] Train loss: 0.0310
2023-02-06 11:29:22 | Train | Epoch[161/600] Iteration[012/030] Train loss: 0.0313
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[013/030] Train loss: 0.0315
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[014/030] Train loss: 0.0315
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[015/030] Train loss: 0.0316
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[016/030] Train loss: 0.0316
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[017/030] Train loss: 0.0316
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[018/030] Train loss: 0.0315
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[019/030] Train loss: 0.0314
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[020/030] Train loss: 0.0315
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[021/030] Train loss: 0.0317
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[022/030] Train loss: 0.0315
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[023/030] Train loss: 0.0314
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[024/030] Train loss: 0.0314
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[025/030] Train loss: 0.0313
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[026/030] Train loss: 0.0313
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[027/030] Train loss: 0.0313
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[028/030] Train loss: 0.0313
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[029/030] Train loss: 0.0312
2023-02-06 11:29:23 | Train | Epoch[161/600] Iteration[030/030] Train loss: 0.0312
2023-02-06 11:29:24 | Valid | Epoch[161/600] Iteration[001/008] Valid loss: 0.2244
2023-02-06 11:29:24 | Valid | Epoch[161/600] Iteration[002/008] Valid loss: 0.1539
2023-02-06 11:29:24 | Valid | Epoch[161/600] Iteration[003/008] Valid loss: 0.1414
2023-02-06 11:29:24 | Valid | Epoch[161/600] Iteration[004/008] Valid loss: 0.1404
2023-02-06 11:29:24 | Valid | Epoch[161/600] Iteration[005/008] Valid loss: 0.1485
2023-02-06 11:29:24 | Valid | Epoch[161/600] Iteration[006/008] Valid loss: 0.1445
2023-02-06 11:29:24 | Valid | Epoch[161/600] Iteration[007/008] Valid loss: 0.1543
2023-02-06 11:29:24 | Valid | Epoch[161/600] Iteration[008/008] Valid loss: 0.1523
2023-02-06 11:29:24 | Valid | Epoch[161/600] MIou: 0.9321722354320472
2023-02-06 11:29:24 | Valid | Epoch[161/600] Pixel Accuracy: 0.987762451171875
2023-02-06 11:29:24 | Valid | Epoch[161/600] Mean Pixel Accuracy: 0.9810873349990108
2023-02-06 11:29:24 | Stage | Epoch[161/600] Train loss:0.0312
2023-02-06 11:29:24 | Stage | Epoch[161/600] Valid loss:0.1523
2023-02-06 11:29:24 | Stage | Epoch[161/600] LR:0.01

2023-02-06 11:29:24 | Train | Epoch[162/600] Iteration[001/030] Train loss: 0.0307
2023-02-06 11:29:24 | Train | Epoch[162/600] Iteration[002/030] Train loss: 0.0305
2023-02-06 11:29:24 | Train | Epoch[162/600] Iteration[003/030] Train loss: 0.0322
2023-02-06 11:29:24 | Train | Epoch[162/600] Iteration[004/030] Train loss: 0.0320
2023-02-06 11:29:24 | Train | Epoch[162/600] Iteration[005/030] Train loss: 0.0314
2023-02-06 11:29:24 | Train | Epoch[162/600] Iteration[006/030] Train loss: 0.0311
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[007/030] Train loss: 0.0309
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[008/030] Train loss: 0.0319
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[009/030] Train loss: 0.0316
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[010/030] Train loss: 0.0316
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[011/030] Train loss: 0.0316
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[012/030] Train loss: 0.0315
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[013/030] Train loss: 0.0313
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[014/030] Train loss: 0.0316
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[015/030] Train loss: 0.0319
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[016/030] Train loss: 0.0321
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[017/030] Train loss: 0.0320
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[018/030] Train loss: 0.0319
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[019/030] Train loss: 0.0317
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[020/030] Train loss: 0.0316
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[021/030] Train loss: 0.0316
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[022/030] Train loss: 0.0317
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[023/030] Train loss: 0.0317
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[024/030] Train loss: 0.0317
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[025/030] Train loss: 0.0316
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[026/030] Train loss: 0.0315
2023-02-06 11:29:25 | Train | Epoch[162/600] Iteration[027/030] Train loss: 0.0316
2023-02-06 11:29:26 | Train | Epoch[162/600] Iteration[028/030] Train loss: 0.0316
2023-02-06 11:29:26 | Train | Epoch[162/600] Iteration[029/030] Train loss: 0.0318
2023-02-06 11:29:26 | Train | Epoch[162/600] Iteration[030/030] Train loss: 0.0318
2023-02-06 11:29:26 | Valid | Epoch[162/600] Iteration[001/008] Valid loss: 0.0661
2023-02-06 11:29:26 | Valid | Epoch[162/600] Iteration[002/008] Valid loss: 0.0561
2023-02-06 11:29:26 | Valid | Epoch[162/600] Iteration[003/008] Valid loss: 0.0532
2023-02-06 11:29:26 | Valid | Epoch[162/600] Iteration[004/008] Valid loss: 0.0521
2023-02-06 11:29:26 | Valid | Epoch[162/600] Iteration[005/008] Valid loss: 0.0547
2023-02-06 11:29:26 | Valid | Epoch[162/600] Iteration[006/008] Valid loss: 0.0542
2023-02-06 11:29:26 | Valid | Epoch[162/600] Iteration[007/008] Valid loss: 0.0537
2023-02-06 11:29:26 | Valid | Epoch[162/600] Iteration[008/008] Valid loss: 0.0529
2023-02-06 11:29:26 | Valid | Epoch[162/600] MIou: 0.9231154837989278
2023-02-06 11:29:26 | Valid | Epoch[162/600] Pixel Accuracy: 0.9869028727213541
2023-02-06 11:29:26 | Valid | Epoch[162/600] Mean Pixel Accuracy: 0.9452160215705288
2023-02-06 11:29:26 | Stage | Epoch[162/600] Train loss:0.0318
2023-02-06 11:29:26 | Stage | Epoch[162/600] Valid loss:0.0529
2023-02-06 11:29:26 | Stage | Epoch[162/600] LR:0.01

2023-02-06 11:29:26 | Train | Epoch[163/600] Iteration[001/030] Train loss: 0.0309
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[002/030] Train loss: 0.0311
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[003/030] Train loss: 0.0301
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[004/030] Train loss: 0.0294
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[005/030] Train loss: 0.0291
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[006/030] Train loss: 0.0299
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[007/030] Train loss: 0.0300
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[008/030] Train loss: 0.0303
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[009/030] Train loss: 0.0303
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[010/030] Train loss: 0.0302
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[011/030] Train loss: 0.0301
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[012/030] Train loss: 0.0301
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[013/030] Train loss: 0.0300
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[014/030] Train loss: 0.0300
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[015/030] Train loss: 0.0304
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[016/030] Train loss: 0.0304
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[017/030] Train loss: 0.0304
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[018/030] Train loss: 0.0304
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[019/030] Train loss: 0.0304
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[020/030] Train loss: 0.0305
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[021/030] Train loss: 0.0305
2023-02-06 11:29:27 | Train | Epoch[163/600] Iteration[022/030] Train loss: 0.0304
2023-02-06 11:29:28 | Train | Epoch[163/600] Iteration[023/030] Train loss: 0.0305
2023-02-06 11:29:28 | Train | Epoch[163/600] Iteration[024/030] Train loss: 0.0305
2023-02-06 11:29:28 | Train | Epoch[163/600] Iteration[025/030] Train loss: 0.0306
2023-02-06 11:29:28 | Train | Epoch[163/600] Iteration[026/030] Train loss: 0.0307
2023-02-06 11:29:28 | Train | Epoch[163/600] Iteration[027/030] Train loss: 0.0308
2023-02-06 11:29:28 | Train | Epoch[163/600] Iteration[028/030] Train loss: 0.0307
2023-02-06 11:29:28 | Train | Epoch[163/600] Iteration[029/030] Train loss: 0.0306
2023-02-06 11:29:28 | Train | Epoch[163/600] Iteration[030/030] Train loss: 0.0308
2023-02-06 11:29:28 | Valid | Epoch[163/600] Iteration[001/008] Valid loss: 0.0686
2023-02-06 11:29:28 | Valid | Epoch[163/600] Iteration[002/008] Valid loss: 0.0584
2023-02-06 11:29:28 | Valid | Epoch[163/600] Iteration[003/008] Valid loss: 0.0535
2023-02-06 11:29:28 | Valid | Epoch[163/600] Iteration[004/008] Valid loss: 0.0506
2023-02-06 11:29:28 | Valid | Epoch[163/600] Iteration[005/008] Valid loss: 0.0516
2023-02-06 11:29:28 | Valid | Epoch[163/600] Iteration[006/008] Valid loss: 0.0501
2023-02-06 11:29:28 | Valid | Epoch[163/600] Iteration[007/008] Valid loss: 0.0491
2023-02-06 11:29:28 | Valid | Epoch[163/600] Iteration[008/008] Valid loss: 0.0499
2023-02-06 11:29:28 | Valid | Epoch[163/600] MIou: 0.9070224375147138
2023-02-06 11:29:28 | Valid | Epoch[163/600] Pixel Accuracy: 0.9842109680175781
2023-02-06 11:29:28 | Valid | Epoch[163/600] Mean Pixel Accuracy: 0.9285446661954314
2023-02-06 11:29:28 | Stage | Epoch[163/600] Train loss:0.0308
2023-02-06 11:29:28 | Stage | Epoch[163/600] Valid loss:0.0499
2023-02-06 11:29:28 | Stage | Epoch[163/600] LR:0.01

2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[001/030] Train loss: 0.0309
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[002/030] Train loss: 0.0310
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[003/030] Train loss: 0.0317
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[004/030] Train loss: 0.0305
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[005/030] Train loss: 0.0312
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[006/030] Train loss: 0.0310
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[007/030] Train loss: 0.0310
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[008/030] Train loss: 0.0309
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[009/030] Train loss: 0.0309
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[010/030] Train loss: 0.0309
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[011/030] Train loss: 0.0309
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[012/030] Train loss: 0.0309
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[013/030] Train loss: 0.0307
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[014/030] Train loss: 0.0307
2023-02-06 11:29:29 | Train | Epoch[164/600] Iteration[015/030] Train loss: 0.0308
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[016/030] Train loss: 0.0310
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[017/030] Train loss: 0.0311
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[018/030] Train loss: 0.0309
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[019/030] Train loss: 0.0309
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[020/030] Train loss: 0.0309
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[021/030] Train loss: 0.0309
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[022/030] Train loss: 0.0308
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[023/030] Train loss: 0.0308
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[024/030] Train loss: 0.0308
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[025/030] Train loss: 0.0307
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[026/030] Train loss: 0.0306
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[027/030] Train loss: 0.0307
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[028/030] Train loss: 0.0307
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[029/030] Train loss: 0.0310
2023-02-06 11:29:30 | Train | Epoch[164/600] Iteration[030/030] Train loss: 0.0309
2023-02-06 11:29:31 | Valid | Epoch[164/600] Iteration[001/008] Valid loss: 0.0478
2023-02-06 11:29:31 | Valid | Epoch[164/600] Iteration[002/008] Valid loss: 0.0421
2023-02-06 11:29:31 | Valid | Epoch[164/600] Iteration[003/008] Valid loss: 0.0403
2023-02-06 11:29:31 | Valid | Epoch[164/600] Iteration[004/008] Valid loss: 0.0394
2023-02-06 11:29:31 | Valid | Epoch[164/600] Iteration[005/008] Valid loss: 0.0403
2023-02-06 11:29:31 | Valid | Epoch[164/600] Iteration[006/008] Valid loss: 0.0403
2023-02-06 11:29:31 | Valid | Epoch[164/600] Iteration[007/008] Valid loss: 0.0399
2023-02-06 11:29:31 | Valid | Epoch[164/600] Iteration[008/008] Valid loss: 0.0396
2023-02-06 11:29:31 | Valid | Epoch[164/600] MIou: 0.9203513333502872
2023-02-06 11:29:31 | Valid | Epoch[164/600] Pixel Accuracy: 0.9867108662923177
2023-02-06 11:29:31 | Valid | Epoch[164/600] Mean Pixel Accuracy: 0.9334567000090515
2023-02-06 11:29:31 | Stage | Epoch[164/600] Train loss:0.0309
2023-02-06 11:29:31 | Stage | Epoch[164/600] Valid loss:0.0396
2023-02-06 11:29:31 | Stage | Epoch[164/600] LR:0.01

2023-02-06 11:29:31 | Train | Epoch[165/600] Iteration[001/030] Train loss: 0.0297
2023-02-06 11:29:31 | Train | Epoch[165/600] Iteration[002/030] Train loss: 0.0302
2023-02-06 11:29:31 | Train | Epoch[165/600] Iteration[003/030] Train loss: 0.0302
2023-02-06 11:29:31 | Train | Epoch[165/600] Iteration[004/030] Train loss: 0.0298
2023-02-06 11:29:31 | Train | Epoch[165/600] Iteration[005/030] Train loss: 0.0297
2023-02-06 11:29:31 | Train | Epoch[165/600] Iteration[006/030] Train loss: 0.0290
2023-02-06 11:29:31 | Train | Epoch[165/600] Iteration[007/030] Train loss: 0.0293
2023-02-06 11:29:31 | Train | Epoch[165/600] Iteration[008/030] Train loss: 0.0294
2023-02-06 11:29:31 | Train | Epoch[165/600] Iteration[009/030] Train loss: 0.0295
2023-02-06 11:29:31 | Train | Epoch[165/600] Iteration[010/030] Train loss: 0.0295
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[011/030] Train loss: 0.0292
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[012/030] Train loss: 0.0294
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[013/030] Train loss: 0.0294
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[014/030] Train loss: 0.0295
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[015/030] Train loss: 0.0295
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[016/030] Train loss: 0.0296
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[017/030] Train loss: 0.0296
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[018/030] Train loss: 0.0297
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[019/030] Train loss: 0.0299
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[020/030] Train loss: 0.0298
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[021/030] Train loss: 0.0301
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[022/030] Train loss: 0.0301
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[023/030] Train loss: 0.0301
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[024/030] Train loss: 0.0302
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[025/030] Train loss: 0.0304
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[026/030] Train loss: 0.0303
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[027/030] Train loss: 0.0304
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[028/030] Train loss: 0.0305
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[029/030] Train loss: 0.0304
2023-02-06 11:29:32 | Train | Epoch[165/600] Iteration[030/030] Train loss: 0.0303
2023-02-06 11:29:33 | Valid | Epoch[165/600] Iteration[001/008] Valid loss: 0.3670
2023-02-06 11:29:33 | Valid | Epoch[165/600] Iteration[002/008] Valid loss: 0.3114
2023-02-06 11:29:33 | Valid | Epoch[165/600] Iteration[003/008] Valid loss: 0.2988
2023-02-06 11:29:33 | Valid | Epoch[165/600] Iteration[004/008] Valid loss: 0.3012
2023-02-06 11:29:33 | Valid | Epoch[165/600] Iteration[005/008] Valid loss: 0.3120
2023-02-06 11:29:33 | Valid | Epoch[165/600] Iteration[006/008] Valid loss: 0.3060
2023-02-06 11:29:33 | Valid | Epoch[165/600] Iteration[007/008] Valid loss: 0.3227
2023-02-06 11:29:33 | Valid | Epoch[165/600] Iteration[008/008] Valid loss: 0.3238
2023-02-06 11:29:33 | Valid | Epoch[165/600] MIou: 0.8956322725269095
2023-02-06 11:29:33 | Valid | Epoch[165/600] Pixel Accuracy: 0.9795265197753906
2023-02-06 11:29:33 | Valid | Epoch[165/600] Mean Pixel Accuracy: 0.9844227005245034
2023-02-06 11:29:33 | Stage | Epoch[165/600] Train loss:0.0303
2023-02-06 11:29:33 | Stage | Epoch[165/600] Valid loss:0.3238
2023-02-06 11:29:33 | Stage | Epoch[165/600] LR:0.01

2023-02-06 11:29:33 | Train | Epoch[166/600] Iteration[001/030] Train loss: 0.0298
2023-02-06 11:29:33 | Train | Epoch[166/600] Iteration[002/030] Train loss: 0.0306
2023-02-06 11:29:33 | Train | Epoch[166/600] Iteration[003/030] Train loss: 0.0300
2023-02-06 11:29:33 | Train | Epoch[166/600] Iteration[004/030] Train loss: 0.0297
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[005/030] Train loss: 0.0300
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[006/030] Train loss: 0.0294
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[007/030] Train loss: 0.0297
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[008/030] Train loss: 0.0301
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[009/030] Train loss: 0.0303
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[010/030] Train loss: 0.0301
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[011/030] Train loss: 0.0302
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[012/030] Train loss: 0.0303
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[013/030] Train loss: 0.0303
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[014/030] Train loss: 0.0302
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[015/030] Train loss: 0.0304
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[016/030] Train loss: 0.0303
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[017/030] Train loss: 0.0303
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[018/030] Train loss: 0.0303
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[019/030] Train loss: 0.0303
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[020/030] Train loss: 0.0304
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[021/030] Train loss: 0.0303
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[022/030] Train loss: 0.0303
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[023/030] Train loss: 0.0302
2023-02-06 11:29:34 | Train | Epoch[166/600] Iteration[024/030] Train loss: 0.0303
2023-02-06 11:29:35 | Train | Epoch[166/600] Iteration[025/030] Train loss: 0.0303
2023-02-06 11:29:35 | Train | Epoch[166/600] Iteration[026/030] Train loss: 0.0302
2023-02-06 11:29:35 | Train | Epoch[166/600] Iteration[027/030] Train loss: 0.0302
2023-02-06 11:29:35 | Train | Epoch[166/600] Iteration[028/030] Train loss: 0.0303
2023-02-06 11:29:35 | Train | Epoch[166/600] Iteration[029/030] Train loss: 0.0303
2023-02-06 11:29:35 | Train | Epoch[166/600] Iteration[030/030] Train loss: 0.0303
2023-02-06 11:29:35 | Valid | Epoch[166/600] Iteration[001/008] Valid loss: 0.1651
2023-02-06 11:29:35 | Valid | Epoch[166/600] Iteration[002/008] Valid loss: 0.1186
2023-02-06 11:29:35 | Valid | Epoch[166/600] Iteration[003/008] Valid loss: 0.1056
2023-02-06 11:29:35 | Valid | Epoch[166/600] Iteration[004/008] Valid loss: 0.1059
2023-02-06 11:29:35 | Valid | Epoch[166/600] Iteration[005/008] Valid loss: 0.1072
2023-02-06 11:29:35 | Valid | Epoch[166/600] Iteration[006/008] Valid loss: 0.1069
2023-02-06 11:29:35 | Valid | Epoch[166/600] Iteration[007/008] Valid loss: 0.1098
2023-02-06 11:29:35 | Valid | Epoch[166/600] Iteration[008/008] Valid loss: 0.1077
2023-02-06 11:29:35 | Valid | Epoch[166/600] MIou: 0.9324877824518004
2023-02-06 11:29:35 | Valid | Epoch[166/600] Pixel Accuracy: 0.9879582722981771
2023-02-06 11:29:35 | Valid | Epoch[166/600] Mean Pixel Accuracy: 0.9757992253848156
2023-02-06 11:29:35 | Stage | Epoch[166/600] Train loss:0.0303
2023-02-06 11:29:35 | Stage | Epoch[166/600] Valid loss:0.1077
2023-02-06 11:29:35 | Stage | Epoch[166/600] LR:0.01

2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[001/030] Train loss: 0.0298
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[002/030] Train loss: 0.0307
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[003/030] Train loss: 0.0307
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[004/030] Train loss: 0.0309
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[005/030] Train loss: 0.0308
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[006/030] Train loss: 0.0308
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[007/030] Train loss: 0.0310
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[008/030] Train loss: 0.0310
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[009/030] Train loss: 0.0314
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[010/030] Train loss: 0.0313
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[011/030] Train loss: 0.0312
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[012/030] Train loss: 0.0313
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[013/030] Train loss: 0.0309
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[014/030] Train loss: 0.0309
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[015/030] Train loss: 0.0310
2023-02-06 11:29:36 | Train | Epoch[167/600] Iteration[016/030] Train loss: 0.0308
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[017/030] Train loss: 0.0307
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[018/030] Train loss: 0.0307
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[019/030] Train loss: 0.0306
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[020/030] Train loss: 0.0306
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[021/030] Train loss: 0.0304
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[022/030] Train loss: 0.0305
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[023/030] Train loss: 0.0305
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[024/030] Train loss: 0.0305
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[025/030] Train loss: 0.0307
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[026/030] Train loss: 0.0305
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[027/030] Train loss: 0.0305
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[028/030] Train loss: 0.0305
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[029/030] Train loss: 0.0304
2023-02-06 11:29:37 | Train | Epoch[167/600] Iteration[030/030] Train loss: 0.0305
2023-02-06 11:29:37 | Valid | Epoch[167/600] Iteration[001/008] Valid loss: 0.1098
2023-02-06 11:29:37 | Valid | Epoch[167/600] Iteration[002/008] Valid loss: 0.0748
2023-02-06 11:29:37 | Valid | Epoch[167/600] Iteration[003/008] Valid loss: 0.0652
2023-02-06 11:29:38 | Valid | Epoch[167/600] Iteration[004/008] Valid loss: 0.0657
2023-02-06 11:29:38 | Valid | Epoch[167/600] Iteration[005/008] Valid loss: 0.0668
2023-02-06 11:29:38 | Valid | Epoch[167/600] Iteration[006/008] Valid loss: 0.0644
2023-02-06 11:29:38 | Valid | Epoch[167/600] Iteration[007/008] Valid loss: 0.0663
2023-02-06 11:29:38 | Valid | Epoch[167/600] Iteration[008/008] Valid loss: 0.0642
2023-02-06 11:29:38 | Valid | Epoch[167/600] MIou: 0.9392820333263062
2023-02-06 11:29:38 | Valid | Epoch[167/600] Pixel Accuracy: 0.9895273844401041
2023-02-06 11:29:38 | Valid | Epoch[167/600] Mean Pixel Accuracy: 0.966421814847024
2023-02-06 11:29:38 | Stage | Epoch[167/600] Train loss:0.0305
2023-02-06 11:29:38 | Stage | Epoch[167/600] Valid loss:0.0642
2023-02-06 11:29:38 | Stage | Epoch[167/600] LR:0.01

2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[001/030] Train loss: 0.0284
2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[002/030] Train loss: 0.0271
2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[003/030] Train loss: 0.0269
2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[004/030] Train loss: 0.0273
2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[005/030] Train loss: 0.0277
2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[006/030] Train loss: 0.0281
2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[007/030] Train loss: 0.0287
2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[008/030] Train loss: 0.0285
2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[009/030] Train loss: 0.0291
2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[010/030] Train loss: 0.0292
2023-02-06 11:29:38 | Train | Epoch[168/600] Iteration[011/030] Train loss: 0.0292
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[012/030] Train loss: 0.0290
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[013/030] Train loss: 0.0293
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[014/030] Train loss: 0.0292
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[015/030] Train loss: 0.0294
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[016/030] Train loss: 0.0294
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[017/030] Train loss: 0.0295
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[018/030] Train loss: 0.0298
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[019/030] Train loss: 0.0298
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[020/030] Train loss: 0.0298
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[021/030] Train loss: 0.0298
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[022/030] Train loss: 0.0298
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[023/030] Train loss: 0.0299
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[024/030] Train loss: 0.0300
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[025/030] Train loss: 0.0300
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[026/030] Train loss: 0.0300
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[027/030] Train loss: 0.0301
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[028/030] Train loss: 0.0301
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[029/030] Train loss: 0.0301
2023-02-06 11:29:39 | Train | Epoch[168/600] Iteration[030/030] Train loss: 0.0302
2023-02-06 11:29:40 | Valid | Epoch[168/600] Iteration[001/008] Valid loss: 0.0510
2023-02-06 11:29:40 | Valid | Epoch[168/600] Iteration[002/008] Valid loss: 0.0426
2023-02-06 11:29:40 | Valid | Epoch[168/600] Iteration[003/008] Valid loss: 0.0407
2023-02-06 11:29:40 | Valid | Epoch[168/600] Iteration[004/008] Valid loss: 0.0397
2023-02-06 11:29:40 | Valid | Epoch[168/600] Iteration[005/008] Valid loss: 0.0409
2023-02-06 11:29:40 | Valid | Epoch[168/600] Iteration[006/008] Valid loss: 0.0408
2023-02-06 11:29:40 | Valid | Epoch[168/600] Iteration[007/008] Valid loss: 0.0402
2023-02-06 11:29:40 | Valid | Epoch[168/600] Iteration[008/008] Valid loss: 0.0399
2023-02-06 11:29:40 | Valid | Epoch[168/600] MIou: 0.9182861758994602
2023-02-06 11:29:40 | Valid | Epoch[168/600] Pixel Accuracy: 0.9863675435384115
2023-02-06 11:29:40 | Valid | Epoch[168/600] Mean Pixel Accuracy: 0.9314926631577609
2023-02-06 11:29:40 | Stage | Epoch[168/600] Train loss:0.0302
2023-02-06 11:29:40 | Stage | Epoch[168/600] Valid loss:0.0399
2023-02-06 11:29:40 | Stage | Epoch[168/600] LR:0.01

2023-02-06 11:29:40 | Train | Epoch[169/600] Iteration[001/030] Train loss: 0.0323
2023-02-06 11:29:40 | Train | Epoch[169/600] Iteration[002/030] Train loss: 0.0301
2023-02-06 11:29:40 | Train | Epoch[169/600] Iteration[003/030] Train loss: 0.0308
2023-02-06 11:29:40 | Train | Epoch[169/600] Iteration[004/030] Train loss: 0.0319
2023-02-06 11:29:40 | Train | Epoch[169/600] Iteration[005/030] Train loss: 0.0317
2023-02-06 11:29:40 | Train | Epoch[169/600] Iteration[006/030] Train loss: 0.0314
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[007/030] Train loss: 0.0307
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[008/030] Train loss: 0.0304
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[009/030] Train loss: 0.0302
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[010/030] Train loss: 0.0300
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[011/030] Train loss: 0.0298
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[012/030] Train loss: 0.0299
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[013/030] Train loss: 0.0300
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[014/030] Train loss: 0.0302
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[015/030] Train loss: 0.0303
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[016/030] Train loss: 0.0303
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[017/030] Train loss: 0.0301
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[018/030] Train loss: 0.0300
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[019/030] Train loss: 0.0300
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[020/030] Train loss: 0.0300
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[021/030] Train loss: 0.0299
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[022/030] Train loss: 0.0299
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[023/030] Train loss: 0.0297
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[024/030] Train loss: 0.0298
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[025/030] Train loss: 0.0297
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[026/030] Train loss: 0.0297
2023-02-06 11:29:41 | Train | Epoch[169/600] Iteration[027/030] Train loss: 0.0297
2023-02-06 11:29:42 | Train | Epoch[169/600] Iteration[028/030] Train loss: 0.0298
2023-02-06 11:29:42 | Train | Epoch[169/600] Iteration[029/030] Train loss: 0.0298
2023-02-06 11:29:42 | Train | Epoch[169/600] Iteration[030/030] Train loss: 0.0298
2023-02-06 11:29:42 | Valid | Epoch[169/600] Iteration[001/008] Valid loss: 0.0533
2023-02-06 11:29:42 | Valid | Epoch[169/600] Iteration[002/008] Valid loss: 0.0431
2023-02-06 11:29:42 | Valid | Epoch[169/600] Iteration[003/008] Valid loss: 0.0403
2023-02-06 11:29:42 | Valid | Epoch[169/600] Iteration[004/008] Valid loss: 0.0387
2023-02-06 11:29:42 | Valid | Epoch[169/600] Iteration[005/008] Valid loss: 0.0395
2023-02-06 11:29:42 | Valid | Epoch[169/600] Iteration[006/008] Valid loss: 0.0389
2023-02-06 11:29:42 | Valid | Epoch[169/600] Iteration[007/008] Valid loss: 0.0384
2023-02-06 11:29:42 | Valid | Epoch[169/600] Iteration[008/008] Valid loss: 0.0382
2023-02-06 11:29:42 | Valid | Epoch[169/600] MIou: 0.9226772429962011
2023-02-06 11:29:42 | Valid | Epoch[169/600] Pixel Accuracy: 0.9870923360188802
2023-02-06 11:29:42 | Valid | Epoch[169/600] Mean Pixel Accuracy: 0.9358474942402161
2023-02-06 11:29:42 | Stage | Epoch[169/600] Train loss:0.0298
2023-02-06 11:29:42 | Stage | Epoch[169/600] Valid loss:0.0382
2023-02-06 11:29:42 | Stage | Epoch[169/600] LR:0.01

2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[001/030] Train loss: 0.0343
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[002/030] Train loss: 0.0310
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[003/030] Train loss: 0.0307
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[004/030] Train loss: 0.0303
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[005/030] Train loss: 0.0308
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[006/030] Train loss: 0.0308
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[007/030] Train loss: 0.0303
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[008/030] Train loss: 0.0303
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[009/030] Train loss: 0.0306
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[010/030] Train loss: 0.0311
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[011/030] Train loss: 0.0308
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[012/030] Train loss: 0.0309
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[013/030] Train loss: 0.0305
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[014/030] Train loss: 0.0305
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[015/030] Train loss: 0.0306
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[016/030] Train loss: 0.0305
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[017/030] Train loss: 0.0302
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[018/030] Train loss: 0.0301
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[019/030] Train loss: 0.0301
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[020/030] Train loss: 0.0299
2023-02-06 11:29:43 | Train | Epoch[170/600] Iteration[021/030] Train loss: 0.0298
2023-02-06 11:29:44 | Train | Epoch[170/600] Iteration[022/030] Train loss: 0.0298
2023-02-06 11:29:44 | Train | Epoch[170/600] Iteration[023/030] Train loss: 0.0299
2023-02-06 11:29:44 | Train | Epoch[170/600] Iteration[024/030] Train loss: 0.0298
2023-02-06 11:29:44 | Train | Epoch[170/600] Iteration[025/030] Train loss: 0.0298
2023-02-06 11:29:44 | Train | Epoch[170/600] Iteration[026/030] Train loss: 0.0297
2023-02-06 11:29:44 | Train | Epoch[170/600] Iteration[027/030] Train loss: 0.0297
2023-02-06 11:29:44 | Train | Epoch[170/600] Iteration[028/030] Train loss: 0.0296
2023-02-06 11:29:44 | Train | Epoch[170/600] Iteration[029/030] Train loss: 0.0296
2023-02-06 11:29:44 | Train | Epoch[170/600] Iteration[030/030] Train loss: 0.0297
2023-02-06 11:29:44 | Valid | Epoch[170/600] Iteration[001/008] Valid loss: 0.0499
2023-02-06 11:29:44 | Valid | Epoch[170/600] Iteration[002/008] Valid loss: 0.0412
2023-02-06 11:29:44 | Valid | Epoch[170/600] Iteration[003/008] Valid loss: 0.0393
2023-02-06 11:29:44 | Valid | Epoch[170/600] Iteration[004/008] Valid loss: 0.0377
2023-02-06 11:29:44 | Valid | Epoch[170/600] Iteration[005/008] Valid loss: 0.0384
2023-02-06 11:29:44 | Valid | Epoch[170/600] Iteration[006/008] Valid loss: 0.0379
2023-02-06 11:29:44 | Valid | Epoch[170/600] Iteration[007/008] Valid loss: 0.0375
2023-02-06 11:29:44 | Valid | Epoch[170/600] Iteration[008/008] Valid loss: 0.0375
2023-02-06 11:29:45 | Valid | Epoch[170/600] MIou: 0.9087058701371087
2023-02-06 11:29:45 | Valid | Epoch[170/600] Pixel Accuracy: 0.9848963419596354
2023-02-06 11:29:45 | Valid | Epoch[170/600] Mean Pixel Accuracy: 0.9190429223286574
2023-02-06 11:29:45 | Stage | Epoch[170/600] Train loss:0.0297
2023-02-06 11:29:45 | Stage | Epoch[170/600] Valid loss:0.0375
2023-02-06 11:29:45 | Stage | Epoch[170/600] LR:0.01

2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[001/030] Train loss: 0.0309
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[002/030] Train loss: 0.0314
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[003/030] Train loss: 0.0329
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[004/030] Train loss: 0.0326
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[005/030] Train loss: 0.0316
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[006/030] Train loss: 0.0309
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[007/030] Train loss: 0.0309
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[008/030] Train loss: 0.0307
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[009/030] Train loss: 0.0307
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[010/030] Train loss: 0.0304
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[011/030] Train loss: 0.0303
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[012/030] Train loss: 0.0300
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[013/030] Train loss: 0.0300
2023-02-06 11:29:45 | Train | Epoch[171/600] Iteration[014/030] Train loss: 0.0300
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[015/030] Train loss: 0.0299
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[016/030] Train loss: 0.0299
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[017/030] Train loss: 0.0298
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[018/030] Train loss: 0.0296
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[019/030] Train loss: 0.0297
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[020/030] Train loss: 0.0297
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[021/030] Train loss: 0.0297
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[022/030] Train loss: 0.0296
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[023/030] Train loss: 0.0297
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[024/030] Train loss: 0.0297
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[025/030] Train loss: 0.0297
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[026/030] Train loss: 0.0296
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[027/030] Train loss: 0.0295
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[028/030] Train loss: 0.0296
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[029/030] Train loss: 0.0296
2023-02-06 11:29:46 | Train | Epoch[171/600] Iteration[030/030] Train loss: 0.0295
2023-02-06 11:29:47 | Valid | Epoch[171/600] Iteration[001/008] Valid loss: 0.1214
2023-02-06 11:29:47 | Valid | Epoch[171/600] Iteration[002/008] Valid loss: 0.0844
2023-02-06 11:29:47 | Valid | Epoch[171/600] Iteration[003/008] Valid loss: 0.0754
2023-02-06 11:29:47 | Valid | Epoch[171/600] Iteration[004/008] Valid loss: 0.0748
2023-02-06 11:29:47 | Valid | Epoch[171/600] Iteration[005/008] Valid loss: 0.0772
2023-02-06 11:29:47 | Valid | Epoch[171/600] Iteration[006/008] Valid loss: 0.0731
2023-02-06 11:29:47 | Valid | Epoch[171/600] Iteration[007/008] Valid loss: 0.0750
2023-02-06 11:29:47 | Valid | Epoch[171/600] Iteration[008/008] Valid loss: 0.0740
2023-02-06 11:29:47 | Valid | Epoch[171/600] MIou: 0.9388706389013934
2023-02-06 11:29:47 | Valid | Epoch[171/600] Pixel Accuracy: 0.9893379211425781
2023-02-06 11:29:47 | Valid | Epoch[171/600] Mean Pixel Accuracy: 0.9713266502328326
2023-02-06 11:29:47 | Stage | Epoch[171/600] Train loss:0.0295
2023-02-06 11:29:47 | Stage | Epoch[171/600] Valid loss:0.0740
2023-02-06 11:29:47 | Stage | Epoch[171/600] LR:0.01

2023-02-06 11:29:47 | Train | Epoch[172/600] Iteration[001/030] Train loss: 0.0282
2023-02-06 11:29:47 | Train | Epoch[172/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 11:29:47 | Train | Epoch[172/600] Iteration[003/030] Train loss: 0.0294
2023-02-06 11:29:47 | Train | Epoch[172/600] Iteration[004/030] Train loss: 0.0295
2023-02-06 11:29:47 | Train | Epoch[172/600] Iteration[005/030] Train loss: 0.0293
2023-02-06 11:29:47 | Train | Epoch[172/600] Iteration[006/030] Train loss: 0.0293
2023-02-06 11:29:47 | Train | Epoch[172/600] Iteration[007/030] Train loss: 0.0294
2023-02-06 11:29:47 | Train | Epoch[172/600] Iteration[008/030] Train loss: 0.0297
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[009/030] Train loss: 0.0295
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[010/030] Train loss: 0.0294
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[011/030] Train loss: 0.0293
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[012/030] Train loss: 0.0293
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[013/030] Train loss: 0.0293
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[014/030] Train loss: 0.0297
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[015/030] Train loss: 0.0298
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[016/030] Train loss: 0.0299
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[017/030] Train loss: 0.0299
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[018/030] Train loss: 0.0298
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[019/030] Train loss: 0.0298
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[020/030] Train loss: 0.0297
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[021/030] Train loss: 0.0296
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[022/030] Train loss: 0.0296
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[023/030] Train loss: 0.0296
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[024/030] Train loss: 0.0295
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[025/030] Train loss: 0.0297
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[026/030] Train loss: 0.0297
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[027/030] Train loss: 0.0297
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[028/030] Train loss: 0.0298
2023-02-06 11:29:48 | Train | Epoch[172/600] Iteration[029/030] Train loss: 0.0296
2023-02-06 11:29:49 | Train | Epoch[172/600] Iteration[030/030] Train loss: 0.0297
2023-02-06 11:29:49 | Valid | Epoch[172/600] Iteration[001/008] Valid loss: 0.0445
2023-02-06 11:29:49 | Valid | Epoch[172/600] Iteration[002/008] Valid loss: 0.0421
2023-02-06 11:29:49 | Valid | Epoch[172/600] Iteration[003/008] Valid loss: 0.0417
2023-02-06 11:29:49 | Valid | Epoch[172/600] Iteration[004/008] Valid loss: 0.0403
2023-02-06 11:29:49 | Valid | Epoch[172/600] Iteration[005/008] Valid loss: 0.0412
2023-02-06 11:29:49 | Valid | Epoch[172/600] Iteration[006/008] Valid loss: 0.0410
2023-02-06 11:29:49 | Valid | Epoch[172/600] Iteration[007/008] Valid loss: 0.0401
2023-02-06 11:29:49 | Valid | Epoch[172/600] Iteration[008/008] Valid loss: 0.0407
2023-02-06 11:29:49 | Valid | Epoch[172/600] MIou: 0.8749378833562687
2023-02-06 11:29:49 | Valid | Epoch[172/600] Pixel Accuracy: 0.9793853759765625
2023-02-06 11:29:49 | Valid | Epoch[172/600] Mean Pixel Accuracy: 0.8864355607834937
2023-02-06 11:29:49 | Stage | Epoch[172/600] Train loss:0.0297
2023-02-06 11:29:49 | Stage | Epoch[172/600] Valid loss:0.0407
2023-02-06 11:29:49 | Stage | Epoch[172/600] LR:0.01

2023-02-06 11:29:49 | Train | Epoch[173/600] Iteration[001/030] Train loss: 0.0288
2023-02-06 11:29:49 | Train | Epoch[173/600] Iteration[002/030] Train loss: 0.0281
2023-02-06 11:29:49 | Train | Epoch[173/600] Iteration[003/030] Train loss: 0.0278
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[004/030] Train loss: 0.0279
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[005/030] Train loss: 0.0285
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[006/030] Train loss: 0.0281
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[007/030] Train loss: 0.0284
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[008/030] Train loss: 0.0284
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[009/030] Train loss: 0.0285
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[010/030] Train loss: 0.0288
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[011/030] Train loss: 0.0287
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[012/030] Train loss: 0.0287
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[013/030] Train loss: 0.0287
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[014/030] Train loss: 0.0287
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[015/030] Train loss: 0.0287
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[016/030] Train loss: 0.0286
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[017/030] Train loss: 0.0286
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[018/030] Train loss: 0.0286
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[019/030] Train loss: 0.0288
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[020/030] Train loss: 0.0289
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[021/030] Train loss: 0.0292
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[022/030] Train loss: 0.0292
2023-02-06 11:29:50 | Train | Epoch[173/600] Iteration[023/030] Train loss: 0.0293
2023-02-06 11:29:51 | Train | Epoch[173/600] Iteration[024/030] Train loss: 0.0293
2023-02-06 11:29:51 | Train | Epoch[173/600] Iteration[025/030] Train loss: 0.0291
2023-02-06 11:29:51 | Train | Epoch[173/600] Iteration[026/030] Train loss: 0.0292
2023-02-06 11:29:51 | Train | Epoch[173/600] Iteration[027/030] Train loss: 0.0292
2023-02-06 11:29:51 | Train | Epoch[173/600] Iteration[028/030] Train loss: 0.0292
2023-02-06 11:29:51 | Train | Epoch[173/600] Iteration[029/030] Train loss: 0.0293
2023-02-06 11:29:51 | Train | Epoch[173/600] Iteration[030/030] Train loss: 0.0293
2023-02-06 11:29:51 | Valid | Epoch[173/600] Iteration[001/008] Valid loss: 0.0588
2023-02-06 11:29:51 | Valid | Epoch[173/600] Iteration[002/008] Valid loss: 0.0449
2023-02-06 11:29:51 | Valid | Epoch[173/600] Iteration[003/008] Valid loss: 0.0411
2023-02-06 11:29:51 | Valid | Epoch[173/600] Iteration[004/008] Valid loss: 0.0403
2023-02-06 11:29:51 | Valid | Epoch[173/600] Iteration[005/008] Valid loss: 0.0406
2023-02-06 11:29:51 | Valid | Epoch[173/600] Iteration[006/008] Valid loss: 0.0398
2023-02-06 11:29:51 | Valid | Epoch[173/600] Iteration[007/008] Valid loss: 0.0398
2023-02-06 11:29:51 | Valid | Epoch[173/600] Iteration[008/008] Valid loss: 0.0390
2023-02-06 11:29:51 | Valid | Epoch[173/600] MIou: 0.9311142125500196
2023-02-06 11:29:51 | Valid | Epoch[173/600] Pixel Accuracy: 0.988457997639974
2023-02-06 11:29:51 | Valid | Epoch[173/600] Mean Pixel Accuracy: 0.945366992212435
2023-02-06 11:29:51 | Stage | Epoch[173/600] Train loss:0.0293
2023-02-06 11:29:51 | Stage | Epoch[173/600] Valid loss:0.0390
2023-02-06 11:29:51 | Stage | Epoch[173/600] LR:0.01

2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[002/030] Train loss: 0.0321
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[003/030] Train loss: 0.0304
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[004/030] Train loss: 0.0309
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[005/030] Train loss: 0.0314
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[006/030] Train loss: 0.0312
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[007/030] Train loss: 0.0312
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[008/030] Train loss: 0.0307
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[009/030] Train loss: 0.0305
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[010/030] Train loss: 0.0304
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[011/030] Train loss: 0.0300
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[012/030] Train loss: 0.0299
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[013/030] Train loss: 0.0298
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[014/030] Train loss: 0.0297
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[015/030] Train loss: 0.0297
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[016/030] Train loss: 0.0298
2023-02-06 11:29:52 | Train | Epoch[174/600] Iteration[017/030] Train loss: 0.0297
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[018/030] Train loss: 0.0294
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[019/030] Train loss: 0.0294
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[020/030] Train loss: 0.0296
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[021/030] Train loss: 0.0296
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[022/030] Train loss: 0.0294
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[023/030] Train loss: 0.0295
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[024/030] Train loss: 0.0293
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[025/030] Train loss: 0.0293
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[026/030] Train loss: 0.0292
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[027/030] Train loss: 0.0292
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[028/030] Train loss: 0.0292
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[029/030] Train loss: 0.0293
2023-02-06 11:29:53 | Train | Epoch[174/600] Iteration[030/030] Train loss: 0.0293
2023-02-06 11:29:53 | Valid | Epoch[174/600] Iteration[001/008] Valid loss: 0.0477
2023-02-06 11:29:53 | Valid | Epoch[174/600] Iteration[002/008] Valid loss: 0.0441
2023-02-06 11:29:53 | Valid | Epoch[174/600] Iteration[003/008] Valid loss: 0.0427
2023-02-06 11:29:54 | Valid | Epoch[174/600] Iteration[004/008] Valid loss: 0.0414
2023-02-06 11:29:54 | Valid | Epoch[174/600] Iteration[005/008] Valid loss: 0.0422
2023-02-06 11:29:54 | Valid | Epoch[174/600] Iteration[006/008] Valid loss: 0.0417
2023-02-06 11:29:54 | Valid | Epoch[174/600] Iteration[007/008] Valid loss: 0.0407
2023-02-06 11:29:54 | Valid | Epoch[174/600] Iteration[008/008] Valid loss: 0.0412
2023-02-06 11:29:54 | Valid | Epoch[174/600] MIou: 0.8888506659711426
2023-02-06 11:29:54 | Valid | Epoch[174/600] Pixel Accuracy: 0.9815635681152344
2023-02-06 11:29:54 | Valid | Epoch[174/600] Mean Pixel Accuracy: 0.9017403371949332
2023-02-06 11:29:54 | Stage | Epoch[174/600] Train loss:0.0293
2023-02-06 11:29:54 | Stage | Epoch[174/600] Valid loss:0.0412
2023-02-06 11:29:54 | Stage | Epoch[174/600] LR:0.01

2023-02-06 11:29:54 | Train | Epoch[175/600] Iteration[001/030] Train loss: 0.0268
2023-02-06 11:29:54 | Train | Epoch[175/600] Iteration[002/030] Train loss: 0.0274
2023-02-06 11:29:54 | Train | Epoch[175/600] Iteration[003/030] Train loss: 0.0286
2023-02-06 11:29:54 | Train | Epoch[175/600] Iteration[004/030] Train loss: 0.0287
2023-02-06 11:29:54 | Train | Epoch[175/600] Iteration[005/030] Train loss: 0.0295
2023-02-06 11:29:54 | Train | Epoch[175/600] Iteration[006/030] Train loss: 0.0299
2023-02-06 11:29:54 | Train | Epoch[175/600] Iteration[007/030] Train loss: 0.0297
2023-02-06 11:29:54 | Train | Epoch[175/600] Iteration[008/030] Train loss: 0.0293
2023-02-06 11:29:54 | Train | Epoch[175/600] Iteration[009/030] Train loss: 0.0290
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[010/030] Train loss: 0.0289
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[011/030] Train loss: 0.0290
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[012/030] Train loss: 0.0287
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[013/030] Train loss: 0.0286
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[014/030] Train loss: 0.0284
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[015/030] Train loss: 0.0284
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[016/030] Train loss: 0.0285
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[017/030] Train loss: 0.0282
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[018/030] Train loss: 0.0284
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[019/030] Train loss: 0.0285
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[020/030] Train loss: 0.0287
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[021/030] Train loss: 0.0287
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[022/030] Train loss: 0.0288
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[023/030] Train loss: 0.0289
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[024/030] Train loss: 0.0289
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[025/030] Train loss: 0.0289
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[026/030] Train loss: 0.0289
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[027/030] Train loss: 0.0289
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[028/030] Train loss: 0.0289
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[029/030] Train loss: 0.0288
2023-02-06 11:29:55 | Train | Epoch[175/600] Iteration[030/030] Train loss: 0.0288
2023-02-06 11:29:56 | Valid | Epoch[175/600] Iteration[001/008] Valid loss: 0.0532
2023-02-06 11:29:56 | Valid | Epoch[175/600] Iteration[002/008] Valid loss: 0.0529
2023-02-06 11:29:56 | Valid | Epoch[175/600] Iteration[003/008] Valid loss: 0.0528
2023-02-06 11:29:56 | Valid | Epoch[175/600] Iteration[004/008] Valid loss: 0.0510
2023-02-06 11:29:56 | Valid | Epoch[175/600] Iteration[005/008] Valid loss: 0.0518
2023-02-06 11:29:56 | Valid | Epoch[175/600] Iteration[006/008] Valid loss: 0.0508
2023-02-06 11:29:56 | Valid | Epoch[175/600] Iteration[007/008] Valid loss: 0.0493
2023-02-06 11:29:56 | Valid | Epoch[175/600] Iteration[008/008] Valid loss: 0.0506
2023-02-06 11:29:56 | Valid | Epoch[175/600] MIou: 0.8382491719202096
2023-02-06 11:29:56 | Valid | Epoch[175/600] Pixel Accuracy: 0.9733136494954427
2023-02-06 11:29:56 | Valid | Epoch[175/600] Mean Pixel Accuracy: 0.852987381745732
2023-02-06 11:29:56 | Stage | Epoch[175/600] Train loss:0.0288
2023-02-06 11:29:56 | Stage | Epoch[175/600] Valid loss:0.0506
2023-02-06 11:29:56 | Stage | Epoch[175/600] LR:0.01

2023-02-06 11:29:56 | Train | Epoch[176/600] Iteration[001/030] Train loss: 0.0294
2023-02-06 11:29:56 | Train | Epoch[176/600] Iteration[002/030] Train loss: 0.0303
2023-02-06 11:29:56 | Train | Epoch[176/600] Iteration[003/030] Train loss: 0.0297
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[004/030] Train loss: 0.0297
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[005/030] Train loss: 0.0296
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[006/030] Train loss: 0.0297
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[007/030] Train loss: 0.0294
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[008/030] Train loss: 0.0290
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[009/030] Train loss: 0.0289
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[010/030] Train loss: 0.0291
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[011/030] Train loss: 0.0291
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[012/030] Train loss: 0.0292
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[013/030] Train loss: 0.0290
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[014/030] Train loss: 0.0291
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[015/030] Train loss: 0.0288
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[016/030] Train loss: 0.0288
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[017/030] Train loss: 0.0287
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[018/030] Train loss: 0.0288
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[019/030] Train loss: 0.0288
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[020/030] Train loss: 0.0287
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[021/030] Train loss: 0.0287
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[022/030] Train loss: 0.0290
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[023/030] Train loss: 0.0289
2023-02-06 11:29:57 | Train | Epoch[176/600] Iteration[024/030] Train loss: 0.0289
2023-02-06 11:29:58 | Train | Epoch[176/600] Iteration[025/030] Train loss: 0.0289
2023-02-06 11:29:58 | Train | Epoch[176/600] Iteration[026/030] Train loss: 0.0288
2023-02-06 11:29:58 | Train | Epoch[176/600] Iteration[027/030] Train loss: 0.0288
2023-02-06 11:29:58 | Train | Epoch[176/600] Iteration[028/030] Train loss: 0.0289
2023-02-06 11:29:58 | Train | Epoch[176/600] Iteration[029/030] Train loss: 0.0291
2023-02-06 11:29:58 | Train | Epoch[176/600] Iteration[030/030] Train loss: 0.0292
2023-02-06 11:29:58 | Valid | Epoch[176/600] Iteration[001/008] Valid loss: 0.0591
2023-02-06 11:29:58 | Valid | Epoch[176/600] Iteration[002/008] Valid loss: 0.0459
2023-02-06 11:29:58 | Valid | Epoch[176/600] Iteration[003/008] Valid loss: 0.0430
2023-02-06 11:29:58 | Valid | Epoch[176/600] Iteration[004/008] Valid loss: 0.0429
2023-02-06 11:29:58 | Valid | Epoch[176/600] Iteration[005/008] Valid loss: 0.0439
2023-02-06 11:29:58 | Valid | Epoch[176/600] Iteration[006/008] Valid loss: 0.0430
2023-02-06 11:29:58 | Valid | Epoch[176/600] Iteration[007/008] Valid loss: 0.0439
2023-02-06 11:29:58 | Valid | Epoch[176/600] Iteration[008/008] Valid loss: 0.0433
2023-02-06 11:29:58 | Valid | Epoch[176/600] MIou: 0.9165949701351699
2023-02-06 11:29:58 | Valid | Epoch[176/600] Pixel Accuracy: 0.9860712687174479
2023-02-06 11:29:58 | Valid | Epoch[176/600] Mean Pixel Accuracy: 0.9303533852674837
2023-02-06 11:29:58 | Stage | Epoch[176/600] Train loss:0.0292
2023-02-06 11:29:58 | Stage | Epoch[176/600] Valid loss:0.0433
2023-02-06 11:29:58 | Stage | Epoch[176/600] LR:0.01

2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[003/030] Train loss: 0.0270
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[004/030] Train loss: 0.0278
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[005/030] Train loss: 0.0275
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[006/030] Train loss: 0.0278
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[007/030] Train loss: 0.0278
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[008/030] Train loss: 0.0274
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[009/030] Train loss: 0.0277
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[010/030] Train loss: 0.0280
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[011/030] Train loss: 0.0281
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[012/030] Train loss: 0.0281
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[013/030] Train loss: 0.0283
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[014/030] Train loss: 0.0287
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[015/030] Train loss: 0.0285
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[016/030] Train loss: 0.0284
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[017/030] Train loss: 0.0285
2023-02-06 11:29:59 | Train | Epoch[177/600] Iteration[018/030] Train loss: 0.0284
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[019/030] Train loss: 0.0286
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[020/030] Train loss: 0.0284
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[021/030] Train loss: 0.0286
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[022/030] Train loss: 0.0286
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[023/030] Train loss: 0.0290
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[024/030] Train loss: 0.0289
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[025/030] Train loss: 0.0289
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[026/030] Train loss: 0.0289
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[027/030] Train loss: 0.0290
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[028/030] Train loss: 0.0291
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[029/030] Train loss: 0.0292
2023-02-06 11:30:00 | Train | Epoch[177/600] Iteration[030/030] Train loss: 0.0292
2023-02-06 11:30:00 | Valid | Epoch[177/600] Iteration[001/008] Valid loss: 0.1936
2023-02-06 11:30:00 | Valid | Epoch[177/600] Iteration[002/008] Valid loss: 0.1962
2023-02-06 11:30:00 | Valid | Epoch[177/600] Iteration[003/008] Valid loss: 0.2043
2023-02-06 11:30:00 | Valid | Epoch[177/600] Iteration[004/008] Valid loss: 0.2024
2023-02-06 11:30:00 | Valid | Epoch[177/600] Iteration[005/008] Valid loss: 0.2072
2023-02-06 11:30:00 | Valid | Epoch[177/600] Iteration[006/008] Valid loss: 0.2058
2023-02-06 11:30:01 | Valid | Epoch[177/600] Iteration[007/008] Valid loss: 0.2021
2023-02-06 11:30:01 | Valid | Epoch[177/600] Iteration[008/008] Valid loss: 0.2093
2023-02-06 11:30:01 | Valid | Epoch[177/600] MIou: 0.5014054032142103
2023-02-06 11:30:01 | Valid | Epoch[177/600] Pixel Accuracy: 0.917449951171875
2023-02-06 11:30:01 | Valid | Epoch[177/600] Mean Pixel Accuracy: 0.5430035619254108
2023-02-06 11:30:01 | Stage | Epoch[177/600] Train loss:0.0292
2023-02-06 11:30:01 | Stage | Epoch[177/600] Valid loss:0.2093
2023-02-06 11:30:01 | Stage | Epoch[177/600] LR:0.01

2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[001/030] Train loss: 0.0305
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[002/030] Train loss: 0.0318
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[003/030] Train loss: 0.0304
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[004/030] Train loss: 0.0306
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[005/030] Train loss: 0.0300
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[006/030] Train loss: 0.0297
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[007/030] Train loss: 0.0292
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[008/030] Train loss: 0.0291
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[009/030] Train loss: 0.0292
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[010/030] Train loss: 0.0298
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[011/030] Train loss: 0.0293
2023-02-06 11:30:01 | Train | Epoch[178/600] Iteration[012/030] Train loss: 0.0289
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[013/030] Train loss: 0.0289
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[014/030] Train loss: 0.0288
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[015/030] Train loss: 0.0286
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[016/030] Train loss: 0.0290
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[017/030] Train loss: 0.0289
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[018/030] Train loss: 0.0290
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[019/030] Train loss: 0.0290
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[020/030] Train loss: 0.0290
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[021/030] Train loss: 0.0290
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[022/030] Train loss: 0.0291
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[023/030] Train loss: 0.0293
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[024/030] Train loss: 0.0294
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[025/030] Train loss: 0.0294
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[026/030] Train loss: 0.0294
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[027/030] Train loss: 0.0294
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[028/030] Train loss: 0.0296
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[029/030] Train loss: 0.0296
2023-02-06 11:30:02 | Train | Epoch[178/600] Iteration[030/030] Train loss: 0.0296
2023-02-06 11:30:03 | Valid | Epoch[178/600] Iteration[001/008] Valid loss: 0.0500
2023-02-06 11:30:03 | Valid | Epoch[178/600] Iteration[002/008] Valid loss: 0.0474
2023-02-06 11:30:03 | Valid | Epoch[178/600] Iteration[003/008] Valid loss: 0.0469
2023-02-06 11:30:03 | Valid | Epoch[178/600] Iteration[004/008] Valid loss: 0.0452
2023-02-06 11:30:03 | Valid | Epoch[178/600] Iteration[005/008] Valid loss: 0.0463
2023-02-06 11:30:03 | Valid | Epoch[178/600] Iteration[006/008] Valid loss: 0.0458
2023-02-06 11:30:03 | Valid | Epoch[178/600] Iteration[007/008] Valid loss: 0.0448
2023-02-06 11:30:03 | Valid | Epoch[178/600] Iteration[008/008] Valid loss: 0.0459
2023-02-06 11:30:03 | Valid | Epoch[178/600] MIou: 0.8505404192873169
2023-02-06 11:30:03 | Valid | Epoch[178/600] Pixel Accuracy: 0.9753456115722656
2023-02-06 11:30:03 | Valid | Epoch[178/600] Mean Pixel Accuracy: 0.8642489891835681
2023-02-06 11:30:03 | Stage | Epoch[178/600] Train loss:0.0296
2023-02-06 11:30:03 | Stage | Epoch[178/600] Valid loss:0.0459
2023-02-06 11:30:03 | Stage | Epoch[178/600] LR:0.01

2023-02-06 11:30:03 | Train | Epoch[179/600] Iteration[001/030] Train loss: 0.0260
2023-02-06 11:30:03 | Train | Epoch[179/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 11:30:03 | Train | Epoch[179/600] Iteration[003/030] Train loss: 0.0294
2023-02-06 11:30:03 | Train | Epoch[179/600] Iteration[004/030] Train loss: 0.0292
2023-02-06 11:30:03 | Train | Epoch[179/600] Iteration[005/030] Train loss: 0.0293
2023-02-06 11:30:03 | Train | Epoch[179/600] Iteration[006/030] Train loss: 0.0289
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[007/030] Train loss: 0.0285
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[008/030] Train loss: 0.0283
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[009/030] Train loss: 0.0282
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[010/030] Train loss: 0.0281
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[011/030] Train loss: 0.0281
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[012/030] Train loss: 0.0283
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[013/030] Train loss: 0.0282
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[014/030] Train loss: 0.0283
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[015/030] Train loss: 0.0283
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[016/030] Train loss: 0.0285
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[017/030] Train loss: 0.0283
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[018/030] Train loss: 0.0284
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[019/030] Train loss: 0.0283
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[020/030] Train loss: 0.0282
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[021/030] Train loss: 0.0283
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[022/030] Train loss: 0.0285
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[024/030] Train loss: 0.0288
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[025/030] Train loss: 0.0289
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[026/030] Train loss: 0.0290
2023-02-06 11:30:04 | Train | Epoch[179/600] Iteration[027/030] Train loss: 0.0289
2023-02-06 11:30:05 | Train | Epoch[179/600] Iteration[028/030] Train loss: 0.0291
2023-02-06 11:30:05 | Train | Epoch[179/600] Iteration[029/030] Train loss: 0.0289
2023-02-06 11:30:05 | Train | Epoch[179/600] Iteration[030/030] Train loss: 0.0288
2023-02-06 11:30:05 | Valid | Epoch[179/600] Iteration[001/008] Valid loss: 0.3741
2023-02-06 11:30:05 | Valid | Epoch[179/600] Iteration[002/008] Valid loss: 0.2903
2023-02-06 11:30:05 | Valid | Epoch[179/600] Iteration[003/008] Valid loss: 0.2902
2023-02-06 11:30:05 | Valid | Epoch[179/600] Iteration[004/008] Valid loss: 0.2902
2023-02-06 11:30:05 | Valid | Epoch[179/600] Iteration[005/008] Valid loss: 0.3063
2023-02-06 11:30:05 | Valid | Epoch[179/600] Iteration[006/008] Valid loss: 0.2957
2023-02-06 11:30:05 | Valid | Epoch[179/600] Iteration[007/008] Valid loss: 0.3205
2023-02-06 11:30:05 | Valid | Epoch[179/600] Iteration[008/008] Valid loss: 0.3205
2023-02-06 11:30:05 | Valid | Epoch[179/600] MIou: 0.9110344623026572
2023-02-06 11:30:05 | Valid | Epoch[179/600] Pixel Accuracy: 0.9831860860188802
2023-02-06 11:30:05 | Valid | Epoch[179/600] Mean Pixel Accuracy: 0.9822621239537022
2023-02-06 11:30:05 | Stage | Epoch[179/600] Train loss:0.0288
2023-02-06 11:30:05 | Stage | Epoch[179/600] Valid loss:0.3205
2023-02-06 11:30:05 | Stage | Epoch[179/600] LR:0.01

2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[001/030] Train loss: 0.0286
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[002/030] Train loss: 0.0277
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[003/030] Train loss: 0.0270
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[004/030] Train loss: 0.0285
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[005/030] Train loss: 0.0292
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[006/030] Train loss: 0.0297
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[007/030] Train loss: 0.0294
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[008/030] Train loss: 0.0291
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[009/030] Train loss: 0.0288
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[010/030] Train loss: 0.0290
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[011/030] Train loss: 0.0289
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[012/030] Train loss: 0.0289
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[013/030] Train loss: 0.0287
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[014/030] Train loss: 0.0289
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[015/030] Train loss: 0.0289
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[016/030] Train loss: 0.0290
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[017/030] Train loss: 0.0289
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[018/030] Train loss: 0.0290
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[019/030] Train loss: 0.0289
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[020/030] Train loss: 0.0291
2023-02-06 11:30:06 | Train | Epoch[180/600] Iteration[021/030] Train loss: 0.0291
2023-02-06 11:30:07 | Train | Epoch[180/600] Iteration[022/030] Train loss: 0.0292
2023-02-06 11:30:07 | Train | Epoch[180/600] Iteration[023/030] Train loss: 0.0291
2023-02-06 11:30:07 | Train | Epoch[180/600] Iteration[024/030] Train loss: 0.0291
2023-02-06 11:30:07 | Train | Epoch[180/600] Iteration[025/030] Train loss: 0.0290
2023-02-06 11:30:07 | Train | Epoch[180/600] Iteration[026/030] Train loss: 0.0290
2023-02-06 11:30:07 | Train | Epoch[180/600] Iteration[027/030] Train loss: 0.0290
2023-02-06 11:30:07 | Train | Epoch[180/600] Iteration[028/030] Train loss: 0.0289
2023-02-06 11:30:07 | Train | Epoch[180/600] Iteration[029/030] Train loss: 0.0288
2023-02-06 11:30:07 | Train | Epoch[180/600] Iteration[030/030] Train loss: 0.0288
2023-02-06 11:30:07 | Valid | Epoch[180/600] Iteration[001/008] Valid loss: 0.0580
2023-02-06 11:30:07 | Valid | Epoch[180/600] Iteration[002/008] Valid loss: 0.0442
2023-02-06 11:30:07 | Valid | Epoch[180/600] Iteration[003/008] Valid loss: 0.0410
2023-02-06 11:30:07 | Valid | Epoch[180/600] Iteration[004/008] Valid loss: 0.0412
2023-02-06 11:30:07 | Valid | Epoch[180/600] Iteration[005/008] Valid loss: 0.0418
2023-02-06 11:30:07 | Valid | Epoch[180/600] Iteration[006/008] Valid loss: 0.0409
2023-02-06 11:30:07 | Valid | Epoch[180/600] Iteration[007/008] Valid loss: 0.0412
2023-02-06 11:30:07 | Valid | Epoch[180/600] Iteration[008/008] Valid loss: 0.0403
2023-02-06 11:30:08 | Valid | Epoch[180/600] MIou: 0.930442647500471
2023-02-06 11:30:08 | Valid | Epoch[180/600] Pixel Accuracy: 0.988318125406901
2023-02-06 11:30:08 | Valid | Epoch[180/600] Mean Pixel Accuracy: 0.945784669245674
2023-02-06 11:30:08 | Stage | Epoch[180/600] Train loss:0.0288
2023-02-06 11:30:08 | Stage | Epoch[180/600] Valid loss:0.0403
2023-02-06 11:30:08 | Stage | Epoch[180/600] LR:0.01

2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[001/030] Train loss: 0.0223
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[005/030] Train loss: 0.0270
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[007/030] Train loss: 0.0280
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[008/030] Train loss: 0.0285
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[009/030] Train loss: 0.0288
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[010/030] Train loss: 0.0288
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[011/030] Train loss: 0.0288
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[012/030] Train loss: 0.0287
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[013/030] Train loss: 0.0285
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[014/030] Train loss: 0.0288
2023-02-06 11:30:08 | Train | Epoch[181/600] Iteration[015/030] Train loss: 0.0288
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[016/030] Train loss: 0.0288
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[017/030] Train loss: 0.0287
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[018/030] Train loss: 0.0289
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[019/030] Train loss: 0.0287
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[020/030] Train loss: 0.0288
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[021/030] Train loss: 0.0287
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[022/030] Train loss: 0.0286
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[023/030] Train loss: 0.0287
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[024/030] Train loss: 0.0285
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[025/030] Train loss: 0.0284
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[026/030] Train loss: 0.0284
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[027/030] Train loss: 0.0284
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[028/030] Train loss: 0.0285
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[029/030] Train loss: 0.0284
2023-02-06 11:30:09 | Train | Epoch[181/600] Iteration[030/030] Train loss: 0.0284
2023-02-06 11:30:10 | Valid | Epoch[181/600] Iteration[001/008] Valid loss: 0.1603
2023-02-06 11:30:10 | Valid | Epoch[181/600] Iteration[002/008] Valid loss: 0.1650
2023-02-06 11:30:10 | Valid | Epoch[181/600] Iteration[003/008] Valid loss: 0.1740
2023-02-06 11:30:10 | Valid | Epoch[181/600] Iteration[004/008] Valid loss: 0.1712
2023-02-06 11:30:10 | Valid | Epoch[181/600] Iteration[005/008] Valid loss: 0.1768
2023-02-06 11:30:10 | Valid | Epoch[181/600] Iteration[006/008] Valid loss: 0.1751
2023-02-06 11:30:10 | Valid | Epoch[181/600] Iteration[007/008] Valid loss: 0.1714
2023-02-06 11:30:10 | Valid | Epoch[181/600] Iteration[008/008] Valid loss: 0.1796
2023-02-06 11:30:10 | Valid | Epoch[181/600] MIou: 0.49513665735352835
2023-02-06 11:30:10 | Valid | Epoch[181/600] Pixel Accuracy: 0.9164047241210938
2023-02-06 11:30:10 | Valid | Epoch[181/600] Mean Pixel Accuracy: 0.5372171929775162
2023-02-06 11:30:10 | Stage | Epoch[181/600] Train loss:0.0284
2023-02-06 11:30:10 | Stage | Epoch[181/600] Valid loss:0.1796
2023-02-06 11:30:10 | Stage | Epoch[181/600] LR:0.01

2023-02-06 11:30:10 | Train | Epoch[182/600] Iteration[001/030] Train loss: 0.0279
2023-02-06 11:30:10 | Train | Epoch[182/600] Iteration[002/030] Train loss: 0.0298
2023-02-06 11:30:10 | Train | Epoch[182/600] Iteration[003/030] Train loss: 0.0283
2023-02-06 11:30:10 | Train | Epoch[182/600] Iteration[004/030] Train loss: 0.0278
2023-02-06 11:30:10 | Train | Epoch[182/600] Iteration[005/030] Train loss: 0.0281
2023-02-06 11:30:10 | Train | Epoch[182/600] Iteration[006/030] Train loss: 0.0282
2023-02-06 11:30:10 | Train | Epoch[182/600] Iteration[007/030] Train loss: 0.0284
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[008/030] Train loss: 0.0286
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[009/030] Train loss: 0.0286
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[010/030] Train loss: 0.0285
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[011/030] Train loss: 0.0285
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[012/030] Train loss: 0.0283
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[013/030] Train loss: 0.0283
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[014/030] Train loss: 0.0281
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[015/030] Train loss: 0.0282
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[016/030] Train loss: 0.0283
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[017/030] Train loss: 0.0285
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[018/030] Train loss: 0.0286
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[019/030] Train loss: 0.0286
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[020/030] Train loss: 0.0288
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[021/030] Train loss: 0.0289
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[022/030] Train loss: 0.0287
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[023/030] Train loss: 0.0287
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[024/030] Train loss: 0.0287
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[025/030] Train loss: 0.0287
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[026/030] Train loss: 0.0287
2023-02-06 11:30:11 | Train | Epoch[182/600] Iteration[027/030] Train loss: 0.0286
2023-02-06 11:30:12 | Train | Epoch[182/600] Iteration[028/030] Train loss: 0.0286
2023-02-06 11:30:12 | Train | Epoch[182/600] Iteration[029/030] Train loss: 0.0286
2023-02-06 11:30:12 | Train | Epoch[182/600] Iteration[030/030] Train loss: 0.0285
2023-02-06 11:30:12 | Valid | Epoch[182/600] Iteration[001/008] Valid loss: 0.0748
2023-02-06 11:30:12 | Valid | Epoch[182/600] Iteration[002/008] Valid loss: 0.0546
2023-02-06 11:30:12 | Valid | Epoch[182/600] Iteration[003/008] Valid loss: 0.0487
2023-02-06 11:30:12 | Valid | Epoch[182/600] Iteration[004/008] Valid loss: 0.0495
2023-02-06 11:30:12 | Valid | Epoch[182/600] Iteration[005/008] Valid loss: 0.0507
2023-02-06 11:30:12 | Valid | Epoch[182/600] Iteration[006/008] Valid loss: 0.0496
2023-02-06 11:30:12 | Valid | Epoch[182/600] Iteration[007/008] Valid loss: 0.0511
2023-02-06 11:30:12 | Valid | Epoch[182/600] Iteration[008/008] Valid loss: 0.0498
2023-02-06 11:30:12 | Valid | Epoch[182/600] MIou: 0.9219450354052992
2023-02-06 11:30:12 | Valid | Epoch[182/600] Pixel Accuracy: 0.9868558247884115
2023-02-06 11:30:12 | Valid | Epoch[182/600] Mean Pixel Accuracy: 0.9389891808812236
2023-02-06 11:30:12 | Stage | Epoch[182/600] Train loss:0.0285
2023-02-06 11:30:12 | Stage | Epoch[182/600] Valid loss:0.0498
2023-02-06 11:30:12 | Stage | Epoch[182/600] LR:0.01

2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[001/030] Train loss: 0.0303
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[002/030] Train loss: 0.0306
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[003/030] Train loss: 0.0294
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[004/030] Train loss: 0.0305
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[005/030] Train loss: 0.0301
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[006/030] Train loss: 0.0295
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[007/030] Train loss: 0.0296
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[008/030] Train loss: 0.0297
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[009/030] Train loss: 0.0295
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[010/030] Train loss: 0.0295
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[011/030] Train loss: 0.0294
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[012/030] Train loss: 0.0292
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[013/030] Train loss: 0.0293
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[014/030] Train loss: 0.0290
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[015/030] Train loss: 0.0289
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[016/030] Train loss: 0.0289
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[017/030] Train loss: 0.0287
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[018/030] Train loss: 0.0286
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[019/030] Train loss: 0.0286
2023-02-06 11:30:13 | Train | Epoch[183/600] Iteration[020/030] Train loss: 0.0285
2023-02-06 11:30:14 | Train | Epoch[183/600] Iteration[021/030] Train loss: 0.0284
2023-02-06 11:30:14 | Train | Epoch[183/600] Iteration[022/030] Train loss: 0.0285
2023-02-06 11:30:14 | Train | Epoch[183/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 11:30:14 | Train | Epoch[183/600] Iteration[024/030] Train loss: 0.0285
2023-02-06 11:30:14 | Train | Epoch[183/600] Iteration[025/030] Train loss: 0.0287
2023-02-06 11:30:14 | Train | Epoch[183/600] Iteration[026/030] Train loss: 0.0285
2023-02-06 11:30:14 | Train | Epoch[183/600] Iteration[027/030] Train loss: 0.0284
2023-02-06 11:30:14 | Train | Epoch[183/600] Iteration[028/030] Train loss: 0.0284
2023-02-06 11:30:14 | Train | Epoch[183/600] Iteration[029/030] Train loss: 0.0283
2023-02-06 11:30:14 | Train | Epoch[183/600] Iteration[030/030] Train loss: 0.0282
2023-02-06 11:30:14 | Valid | Epoch[183/600] Iteration[001/008] Valid loss: 0.0627
2023-02-06 11:30:14 | Valid | Epoch[183/600] Iteration[002/008] Valid loss: 0.0626
2023-02-06 11:30:14 | Valid | Epoch[183/600] Iteration[003/008] Valid loss: 0.0629
2023-02-06 11:30:14 | Valid | Epoch[183/600] Iteration[004/008] Valid loss: 0.0615
2023-02-06 11:30:14 | Valid | Epoch[183/600] Iteration[005/008] Valid loss: 0.0631
2023-02-06 11:30:14 | Valid | Epoch[183/600] Iteration[006/008] Valid loss: 0.0625
2023-02-06 11:30:14 | Valid | Epoch[183/600] Iteration[007/008] Valid loss: 0.0609
2023-02-06 11:30:15 | Valid | Epoch[183/600] Iteration[008/008] Valid loss: 0.0626
2023-02-06 11:30:15 | Valid | Epoch[183/600] MIou: 0.8021757534420046
2023-02-06 11:30:15 | Valid | Epoch[183/600] Pixel Accuracy: 0.9673792521158854
2023-02-06 11:30:15 | Valid | Epoch[183/600] Mean Pixel Accuracy: 0.8195956632245972
2023-02-06 11:30:15 | Stage | Epoch[183/600] Train loss:0.0282
2023-02-06 11:30:15 | Stage | Epoch[183/600] Valid loss:0.0626
2023-02-06 11:30:15 | Stage | Epoch[183/600] LR:0.01

2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[003/030] Train loss: 0.0258
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[005/030] Train loss: 0.0260
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[008/030] Train loss: 0.0268
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[009/030] Train loss: 0.0274
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[010/030] Train loss: 0.0273
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[011/030] Train loss: 0.0274
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 11:30:15 | Train | Epoch[184/600] Iteration[014/030] Train loss: 0.0277
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[015/030] Train loss: 0.0276
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[016/030] Train loss: 0.0275
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[017/030] Train loss: 0.0276
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[018/030] Train loss: 0.0276
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[020/030] Train loss: 0.0277
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[022/030] Train loss: 0.0275
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[023/030] Train loss: 0.0275
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[024/030] Train loss: 0.0276
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[025/030] Train loss: 0.0276
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[026/030] Train loss: 0.0276
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[027/030] Train loss: 0.0277
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[028/030] Train loss: 0.0276
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[029/030] Train loss: 0.0277
2023-02-06 11:30:16 | Train | Epoch[184/600] Iteration[030/030] Train loss: 0.0278
2023-02-06 11:30:17 | Valid | Epoch[184/600] Iteration[001/008] Valid loss: 0.0510
2023-02-06 11:30:17 | Valid | Epoch[184/600] Iteration[002/008] Valid loss: 0.0454
2023-02-06 11:30:17 | Valid | Epoch[184/600] Iteration[003/008] Valid loss: 0.0440
2023-02-06 11:30:17 | Valid | Epoch[184/600] Iteration[004/008] Valid loss: 0.0429
2023-02-06 11:30:17 | Valid | Epoch[184/600] Iteration[005/008] Valid loss: 0.0440
2023-02-06 11:30:17 | Valid | Epoch[184/600] Iteration[006/008] Valid loss: 0.0438
2023-02-06 11:30:17 | Valid | Epoch[184/600] Iteration[007/008] Valid loss: 0.0429
2023-02-06 11:30:17 | Valid | Epoch[184/600] Iteration[008/008] Valid loss: 0.0435
2023-02-06 11:30:17 | Valid | Epoch[184/600] MIou: 0.882431683434808
2023-02-06 11:30:17 | Valid | Epoch[184/600] Pixel Accuracy: 0.9803746541341146
2023-02-06 11:30:17 | Valid | Epoch[184/600] Mean Pixel Accuracy: 0.8983097328426639
2023-02-06 11:30:17 | Stage | Epoch[184/600] Train loss:0.0278
2023-02-06 11:30:17 | Stage | Epoch[184/600] Valid loss:0.0435
2023-02-06 11:30:17 | Stage | Epoch[184/600] LR:0.01

2023-02-06 11:30:17 | Train | Epoch[185/600] Iteration[001/030] Train loss: 0.0260
2023-02-06 11:30:17 | Train | Epoch[185/600] Iteration[002/030] Train loss: 0.0265
2023-02-06 11:30:17 | Train | Epoch[185/600] Iteration[003/030] Train loss: 0.0274
2023-02-06 11:30:17 | Train | Epoch[185/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 11:30:17 | Train | Epoch[185/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 11:30:17 | Train | Epoch[185/600] Iteration[006/030] Train loss: 0.0266
2023-02-06 11:30:17 | Train | Epoch[185/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[010/030] Train loss: 0.0266
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[014/030] Train loss: 0.0270
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[015/030] Train loss: 0.0271
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[016/030] Train loss: 0.0271
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[017/030] Train loss: 0.0274
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[018/030] Train loss: 0.0274
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[019/030] Train loss: 0.0279
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[020/030] Train loss: 0.0278
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[021/030] Train loss: 0.0278
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[022/030] Train loss: 0.0277
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[023/030] Train loss: 0.0277
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[024/030] Train loss: 0.0276
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[025/030] Train loss: 0.0278
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[026/030] Train loss: 0.0279
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[027/030] Train loss: 0.0280
2023-02-06 11:30:18 | Train | Epoch[185/600] Iteration[028/030] Train loss: 0.0281
2023-02-06 11:30:19 | Train | Epoch[185/600] Iteration[029/030] Train loss: 0.0281
2023-02-06 11:30:19 | Train | Epoch[185/600] Iteration[030/030] Train loss: 0.0283
2023-02-06 11:30:19 | Valid | Epoch[185/600] Iteration[001/008] Valid loss: 0.0461
2023-02-06 11:30:19 | Valid | Epoch[185/600] Iteration[002/008] Valid loss: 0.0440
2023-02-06 11:30:19 | Valid | Epoch[185/600] Iteration[003/008] Valid loss: 0.0426
2023-02-06 11:30:19 | Valid | Epoch[185/600] Iteration[004/008] Valid loss: 0.0413
2023-02-06 11:30:19 | Valid | Epoch[185/600] Iteration[005/008] Valid loss: 0.0416
2023-02-06 11:30:19 | Valid | Epoch[185/600] Iteration[006/008] Valid loss: 0.0416
2023-02-06 11:30:19 | Valid | Epoch[185/600] Iteration[007/008] Valid loss: 0.0407
2023-02-06 11:30:19 | Valid | Epoch[185/600] Iteration[008/008] Valid loss: 0.0412
2023-02-06 11:30:19 | Valid | Epoch[185/600] MIou: 0.8797073973081346
2023-02-06 11:30:19 | Valid | Epoch[185/600] Pixel Accuracy: 0.9800440470377604
2023-02-06 11:30:19 | Valid | Epoch[185/600] Mean Pixel Accuracy: 0.8933282801478115
2023-02-06 11:30:19 | Stage | Epoch[185/600] Train loss:0.0283
2023-02-06 11:30:19 | Stage | Epoch[185/600] Valid loss:0.0412
2023-02-06 11:30:19 | Stage | Epoch[185/600] LR:0.01

2023-02-06 11:30:19 | Train | Epoch[186/600] Iteration[001/030] Train loss: 0.0290
2023-02-06 11:30:19 | Train | Epoch[186/600] Iteration[002/030] Train loss: 0.0319
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[003/030] Train loss: 0.0306
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[004/030] Train loss: 0.0301
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[005/030] Train loss: 0.0295
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[006/030] Train loss: 0.0288
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[007/030] Train loss: 0.0288
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[008/030] Train loss: 0.0290
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[009/030] Train loss: 0.0291
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[010/030] Train loss: 0.0289
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[011/030] Train loss: 0.0288
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[012/030] Train loss: 0.0289
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[013/030] Train loss: 0.0289
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[014/030] Train loss: 0.0285
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[015/030] Train loss: 0.0286
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[016/030] Train loss: 0.0285
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[017/030] Train loss: 0.0284
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[018/030] Train loss: 0.0284
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[019/030] Train loss: 0.0283
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[020/030] Train loss: 0.0283
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[021/030] Train loss: 0.0283
2023-02-06 11:30:20 | Train | Epoch[186/600] Iteration[022/030] Train loss: 0.0285
2023-02-06 11:30:21 | Train | Epoch[186/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 11:30:21 | Train | Epoch[186/600] Iteration[024/030] Train loss: 0.0285
2023-02-06 11:30:21 | Train | Epoch[186/600] Iteration[025/030] Train loss: 0.0284
2023-02-06 11:30:21 | Train | Epoch[186/600] Iteration[026/030] Train loss: 0.0288
2023-02-06 11:30:21 | Train | Epoch[186/600] Iteration[027/030] Train loss: 0.0288
2023-02-06 11:30:21 | Train | Epoch[186/600] Iteration[028/030] Train loss: 0.0288
2023-02-06 11:30:21 | Train | Epoch[186/600] Iteration[029/030] Train loss: 0.0287
2023-02-06 11:30:21 | Train | Epoch[186/600] Iteration[030/030] Train loss: 0.0286
2023-02-06 11:30:21 | Valid | Epoch[186/600] Iteration[001/008] Valid loss: 0.0530
2023-02-06 11:30:21 | Valid | Epoch[186/600] Iteration[002/008] Valid loss: 0.0422
2023-02-06 11:30:21 | Valid | Epoch[186/600] Iteration[003/008] Valid loss: 0.0396
2023-02-06 11:30:21 | Valid | Epoch[186/600] Iteration[004/008] Valid loss: 0.0377
2023-02-06 11:30:21 | Valid | Epoch[186/600] Iteration[005/008] Valid loss: 0.0383
2023-02-06 11:30:21 | Valid | Epoch[186/600] Iteration[006/008] Valid loss: 0.0376
2023-02-06 11:30:21 | Valid | Epoch[186/600] Iteration[007/008] Valid loss: 0.0370
2023-02-06 11:30:21 | Valid | Epoch[186/600] Iteration[008/008] Valid loss: 0.0370
2023-02-06 11:30:22 | Valid | Epoch[186/600] MIou: 0.911524759636229
2023-02-06 11:30:22 | Valid | Epoch[186/600] Pixel Accuracy: 0.9852689107259115
2023-02-06 11:30:22 | Valid | Epoch[186/600] Mean Pixel Accuracy: 0.9243454411079884
2023-02-06 11:30:22 | Stage | Epoch[186/600] Train loss:0.0286
2023-02-06 11:30:22 | Stage | Epoch[186/600] Valid loss:0.0370
2023-02-06 11:30:22 | Stage | Epoch[186/600] LR:0.01

2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[001/030] Train loss: 0.0277
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[002/030] Train loss: 0.0290
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[003/030] Train loss: 0.0284
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[004/030] Train loss: 0.0279
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[005/030] Train loss: 0.0289
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[006/030] Train loss: 0.0284
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[007/030] Train loss: 0.0284
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[008/030] Train loss: 0.0285
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[009/030] Train loss: 0.0284
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[010/030] Train loss: 0.0282
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[011/030] Train loss: 0.0284
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[012/030] Train loss: 0.0281
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[013/030] Train loss: 0.0285
2023-02-06 11:30:22 | Train | Epoch[187/600] Iteration[014/030] Train loss: 0.0283
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[015/030] Train loss: 0.0283
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[016/030] Train loss: 0.0285
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[017/030] Train loss: 0.0285
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[018/030] Train loss: 0.0286
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[019/030] Train loss: 0.0287
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[020/030] Train loss: 0.0289
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[021/030] Train loss: 0.0290
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[022/030] Train loss: 0.0289
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[023/030] Train loss: 0.0291
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[024/030] Train loss: 0.0291
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[025/030] Train loss: 0.0291
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[026/030] Train loss: 0.0292
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[027/030] Train loss: 0.0291
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[028/030] Train loss: 0.0290
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[029/030] Train loss: 0.0291
2023-02-06 11:30:23 | Train | Epoch[187/600] Iteration[030/030] Train loss: 0.0290
2023-02-06 11:30:24 | Valid | Epoch[187/600] Iteration[001/008] Valid loss: 0.0955
2023-02-06 11:30:24 | Valid | Epoch[187/600] Iteration[002/008] Valid loss: 0.0669
2023-02-06 11:30:24 | Valid | Epoch[187/600] Iteration[003/008] Valid loss: 0.0595
2023-02-06 11:30:24 | Valid | Epoch[187/600] Iteration[004/008] Valid loss: 0.0626
2023-02-06 11:30:24 | Valid | Epoch[187/600] Iteration[005/008] Valid loss: 0.0654
2023-02-06 11:30:24 | Valid | Epoch[187/600] Iteration[006/008] Valid loss: 0.0632
2023-02-06 11:30:24 | Valid | Epoch[187/600] Iteration[007/008] Valid loss: 0.0667
2023-02-06 11:30:24 | Valid | Epoch[187/600] Iteration[008/008] Valid loss: 0.0643
2023-02-06 11:30:24 | Valid | Epoch[187/600] MIou: 0.9411422937551173
2023-02-06 11:30:24 | Valid | Epoch[187/600] Pixel Accuracy: 0.9898821512858073
2023-02-06 11:30:24 | Valid | Epoch[187/600] Mean Pixel Accuracy: 0.9666358312503989
2023-02-06 11:30:24 | Stage | Epoch[187/600] Train loss:0.0290
2023-02-06 11:30:24 | Stage | Epoch[187/600] Valid loss:0.0643
2023-02-06 11:30:24 | Stage | Epoch[187/600] LR:0.01

2023-02-06 11:30:24 | Train | Epoch[188/600] Iteration[001/030] Train loss: 0.0247
2023-02-06 11:30:24 | Train | Epoch[188/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 11:30:24 | Train | Epoch[188/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 11:30:24 | Train | Epoch[188/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 11:30:24 | Train | Epoch[188/600] Iteration[005/030] Train loss: 0.0265
2023-02-06 11:30:24 | Train | Epoch[188/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 11:30:24 | Train | Epoch[188/600] Iteration[007/030] Train loss: 0.0277
2023-02-06 11:30:24 | Train | Epoch[188/600] Iteration[008/030] Train loss: 0.0279
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[009/030] Train loss: 0.0279
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[010/030] Train loss: 0.0279
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[011/030] Train loss: 0.0279
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[012/030] Train loss: 0.0280
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[013/030] Train loss: 0.0282
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[014/030] Train loss: 0.0283
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[015/030] Train loss: 0.0281
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[016/030] Train loss: 0.0281
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[017/030] Train loss: 0.0279
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[018/030] Train loss: 0.0279
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[020/030] Train loss: 0.0277
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[021/030] Train loss: 0.0278
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[022/030] Train loss: 0.0279
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[023/030] Train loss: 0.0282
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[024/030] Train loss: 0.0282
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[025/030] Train loss: 0.0282
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[026/030] Train loss: 0.0281
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[027/030] Train loss: 0.0280
2023-02-06 11:30:25 | Train | Epoch[188/600] Iteration[028/030] Train loss: 0.0280
2023-02-06 11:30:26 | Train | Epoch[188/600] Iteration[029/030] Train loss: 0.0280
2023-02-06 11:30:26 | Train | Epoch[188/600] Iteration[030/030] Train loss: 0.0280
2023-02-06 11:30:26 | Valid | Epoch[188/600] Iteration[001/008] Valid loss: 0.0438
2023-02-06 11:30:26 | Valid | Epoch[188/600] Iteration[002/008] Valid loss: 0.0410
2023-02-06 11:30:26 | Valid | Epoch[188/600] Iteration[003/008] Valid loss: 0.0404
2023-02-06 11:30:26 | Valid | Epoch[188/600] Iteration[004/008] Valid loss: 0.0391
2023-02-06 11:30:26 | Valid | Epoch[188/600] Iteration[005/008] Valid loss: 0.0398
2023-02-06 11:30:26 | Valid | Epoch[188/600] Iteration[006/008] Valid loss: 0.0398
2023-02-06 11:30:26 | Valid | Epoch[188/600] Iteration[007/008] Valid loss: 0.0389
2023-02-06 11:30:26 | Valid | Epoch[188/600] Iteration[008/008] Valid loss: 0.0395
2023-02-06 11:30:26 | Valid | Epoch[188/600] MIou: 0.8787275030848651
2023-02-06 11:30:26 | Valid | Epoch[188/600] Pixel Accuracy: 0.9799919128417969
2023-02-06 11:30:26 | Valid | Epoch[188/600] Mean Pixel Accuracy: 0.8902752200589783
2023-02-06 11:30:26 | Stage | Epoch[188/600] Train loss:0.0280
2023-02-06 11:30:26 | Stage | Epoch[188/600] Valid loss:0.0395
2023-02-06 11:30:26 | Stage | Epoch[188/600] LR:0.01

2023-02-06 11:30:26 | Train | Epoch[189/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 11:30:26 | Train | Epoch[189/600] Iteration[002/030] Train loss: 0.0293
2023-02-06 11:30:26 | Train | Epoch[189/600] Iteration[003/030] Train loss: 0.0279
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[004/030] Train loss: 0.0275
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[005/030] Train loss: 0.0288
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[006/030] Train loss: 0.0278
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[007/030] Train loss: 0.0273
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[010/030] Train loss: 0.0276
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[011/030] Train loss: 0.0276
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[012/030] Train loss: 0.0278
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[013/030] Train loss: 0.0277
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[014/030] Train loss: 0.0278
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[015/030] Train loss: 0.0278
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[016/030] Train loss: 0.0279
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[017/030] Train loss: 0.0277
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[018/030] Train loss: 0.0276
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[020/030] Train loss: 0.0276
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[022/030] Train loss: 0.0276
2023-02-06 11:30:27 | Train | Epoch[189/600] Iteration[023/030] Train loss: 0.0275
2023-02-06 11:30:28 | Train | Epoch[189/600] Iteration[024/030] Train loss: 0.0274
2023-02-06 11:30:28 | Train | Epoch[189/600] Iteration[025/030] Train loss: 0.0276
2023-02-06 11:30:28 | Train | Epoch[189/600] Iteration[026/030] Train loss: 0.0276
2023-02-06 11:30:28 | Train | Epoch[189/600] Iteration[027/030] Train loss: 0.0275
2023-02-06 11:30:28 | Train | Epoch[189/600] Iteration[028/030] Train loss: 0.0275
2023-02-06 11:30:28 | Train | Epoch[189/600] Iteration[029/030] Train loss: 0.0275
2023-02-06 11:30:28 | Train | Epoch[189/600] Iteration[030/030] Train loss: 0.0275
2023-02-06 11:30:28 | Valid | Epoch[189/600] Iteration[001/008] Valid loss: 0.0443
2023-02-06 11:30:28 | Valid | Epoch[189/600] Iteration[002/008] Valid loss: 0.0422
2023-02-06 11:30:28 | Valid | Epoch[189/600] Iteration[003/008] Valid loss: 0.0420
2023-02-06 11:30:28 | Valid | Epoch[189/600] Iteration[004/008] Valid loss: 0.0403
2023-02-06 11:30:28 | Valid | Epoch[189/600] Iteration[005/008] Valid loss: 0.0411
2023-02-06 11:30:28 | Valid | Epoch[189/600] Iteration[006/008] Valid loss: 0.0409
2023-02-06 11:30:28 | Valid | Epoch[189/600] Iteration[007/008] Valid loss: 0.0398
2023-02-06 11:30:28 | Valid | Epoch[189/600] Iteration[008/008] Valid loss: 0.0404
2023-02-06 11:30:28 | Valid | Epoch[189/600] MIou: 0.8756741215083147
2023-02-06 11:30:28 | Valid | Epoch[189/600] Pixel Accuracy: 0.9794845581054688
2023-02-06 11:30:28 | Valid | Epoch[189/600] Mean Pixel Accuracy: 0.8875299128395371
2023-02-06 11:30:28 | Stage | Epoch[189/600] Train loss:0.0275
2023-02-06 11:30:28 | Stage | Epoch[189/600] Valid loss:0.0404
2023-02-06 11:30:28 | Stage | Epoch[189/600] LR:0.01

2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[001/030] Train loss: 0.0272
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[004/030] Train loss: 0.0258
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[005/030] Train loss: 0.0260
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[006/030] Train loss: 0.0262
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[007/030] Train loss: 0.0265
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[009/030] Train loss: 0.0276
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[010/030] Train loss: 0.0273
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[011/030] Train loss: 0.0274
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[012/030] Train loss: 0.0276
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[013/030] Train loss: 0.0277
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[014/030] Train loss: 0.0275
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[015/030] Train loss: 0.0278
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[016/030] Train loss: 0.0277
2023-02-06 11:30:29 | Train | Epoch[190/600] Iteration[017/030] Train loss: 0.0275
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[018/030] Train loss: 0.0275
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[019/030] Train loss: 0.0278
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[020/030] Train loss: 0.0277
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[021/030] Train loss: 0.0277
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[022/030] Train loss: 0.0276
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[023/030] Train loss: 0.0275
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[024/030] Train loss: 0.0276
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[025/030] Train loss: 0.0277
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[026/030] Train loss: 0.0277
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[028/030] Train loss: 0.0280
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[029/030] Train loss: 0.0279
2023-02-06 11:30:30 | Train | Epoch[190/600] Iteration[030/030] Train loss: 0.0278
2023-02-06 11:30:30 | Valid | Epoch[190/600] Iteration[001/008] Valid loss: 0.0712
2023-02-06 11:30:30 | Valid | Epoch[190/600] Iteration[002/008] Valid loss: 0.0700
2023-02-06 11:30:30 | Valid | Epoch[190/600] Iteration[003/008] Valid loss: 0.0708
2023-02-06 11:30:30 | Valid | Epoch[190/600] Iteration[004/008] Valid loss: 0.0684
2023-02-06 11:30:31 | Valid | Epoch[190/600] Iteration[005/008] Valid loss: 0.0695
2023-02-06 11:30:31 | Valid | Epoch[190/600] Iteration[006/008] Valid loss: 0.0684
2023-02-06 11:30:31 | Valid | Epoch[190/600] Iteration[007/008] Valid loss: 0.0663
2023-02-06 11:30:31 | Valid | Epoch[190/600] Iteration[008/008] Valid loss: 0.0682
2023-02-06 11:30:31 | Valid | Epoch[190/600] MIou: 0.7967481818755331
2023-02-06 11:30:31 | Valid | Epoch[190/600] Pixel Accuracy: 0.9664878845214844
2023-02-06 11:30:31 | Valid | Epoch[190/600] Mean Pixel Accuracy: 0.8145659519761568
2023-02-06 11:30:31 | Stage | Epoch[190/600] Train loss:0.0278
2023-02-06 11:30:31 | Stage | Epoch[190/600] Valid loss:0.0682
2023-02-06 11:30:31 | Stage | Epoch[190/600] LR:0.01

2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[001/030] Train loss: 0.0249
2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[002/030] Train loss: 0.0271
2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[003/030] Train loss: 0.0270
2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[004/030] Train loss: 0.0272
2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[005/030] Train loss: 0.0271
2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[007/030] Train loss: 0.0272
2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 11:30:31 | Train | Epoch[191/600] Iteration[011/030] Train loss: 0.0270
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[012/030] Train loss: 0.0270
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[013/030] Train loss: 0.0271
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[014/030] Train loss: 0.0270
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[015/030] Train loss: 0.0270
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[016/030] Train loss: 0.0269
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[017/030] Train loss: 0.0271
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[018/030] Train loss: 0.0269
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[020/030] Train loss: 0.0269
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[021/030] Train loss: 0.0272
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[022/030] Train loss: 0.0273
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[023/030] Train loss: 0.0273
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[024/030] Train loss: 0.0272
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[025/030] Train loss: 0.0272
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[026/030] Train loss: 0.0272
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[027/030] Train loss: 0.0274
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[028/030] Train loss: 0.0273
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[029/030] Train loss: 0.0274
2023-02-06 11:30:32 | Train | Epoch[191/600] Iteration[030/030] Train loss: 0.0273
2023-02-06 11:30:33 | Valid | Epoch[191/600] Iteration[001/008] Valid loss: 0.1620
2023-02-06 11:30:33 | Valid | Epoch[191/600] Iteration[002/008] Valid loss: 0.1113
2023-02-06 11:30:33 | Valid | Epoch[191/600] Iteration[003/008] Valid loss: 0.0984
2023-02-06 11:30:33 | Valid | Epoch[191/600] Iteration[004/008] Valid loss: 0.1069
2023-02-06 11:30:33 | Valid | Epoch[191/600] Iteration[005/008] Valid loss: 0.1118
2023-02-06 11:30:33 | Valid | Epoch[191/600] Iteration[006/008] Valid loss: 0.1073
2023-02-06 11:30:33 | Valid | Epoch[191/600] Iteration[007/008] Valid loss: 0.1172
2023-02-06 11:30:33 | Valid | Epoch[191/600] Iteration[008/008] Valid loss: 0.1148
2023-02-06 11:30:33 | Valid | Epoch[191/600] MIou: 0.9303262369832483
2023-02-06 11:30:33 | Valid | Epoch[191/600] Pixel Accuracy: 0.987707773844401
2023-02-06 11:30:33 | Valid | Epoch[191/600] Mean Pixel Accuracy: 0.9684017008697883
2023-02-06 11:30:33 | Stage | Epoch[191/600] Train loss:0.0273
2023-02-06 11:30:33 | Stage | Epoch[191/600] Valid loss:0.1148
2023-02-06 11:30:33 | Stage | Epoch[191/600] LR:0.01

2023-02-06 11:30:33 | Train | Epoch[192/600] Iteration[001/030] Train loss: 0.0269
2023-02-06 11:30:33 | Train | Epoch[192/600] Iteration[002/030] Train loss: 0.0276
2023-02-06 11:30:33 | Train | Epoch[192/600] Iteration[003/030] Train loss: 0.0270
2023-02-06 11:30:33 | Train | Epoch[192/600] Iteration[004/030] Train loss: 0.0282
2023-02-06 11:30:33 | Train | Epoch[192/600] Iteration[005/030] Train loss: 0.0281
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[006/030] Train loss: 0.0277
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[007/030] Train loss: 0.0279
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[008/030] Train loss: 0.0276
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[009/030] Train loss: 0.0276
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[010/030] Train loss: 0.0274
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[013/030] Train loss: 0.0273
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[014/030] Train loss: 0.0270
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[015/030] Train loss: 0.0268
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[016/030] Train loss: 0.0270
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[017/030] Train loss: 0.0274
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[018/030] Train loss: 0.0275
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[019/030] Train loss: 0.0275
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[020/030] Train loss: 0.0276
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[022/030] Train loss: 0.0276
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[023/030] Train loss: 0.0276
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[024/030] Train loss: 0.0277
2023-02-06 11:30:34 | Train | Epoch[192/600] Iteration[025/030] Train loss: 0.0277
2023-02-06 11:30:35 | Train | Epoch[192/600] Iteration[026/030] Train loss: 0.0276
2023-02-06 11:30:35 | Train | Epoch[192/600] Iteration[027/030] Train loss: 0.0274
2023-02-06 11:30:35 | Train | Epoch[192/600] Iteration[028/030] Train loss: 0.0275
2023-02-06 11:30:35 | Train | Epoch[192/600] Iteration[029/030] Train loss: 0.0274
2023-02-06 11:30:35 | Train | Epoch[192/600] Iteration[030/030] Train loss: 0.0274
2023-02-06 11:30:35 | Valid | Epoch[192/600] Iteration[001/008] Valid loss: 0.0448
2023-02-06 11:30:35 | Valid | Epoch[192/600] Iteration[002/008] Valid loss: 0.0427
2023-02-06 11:30:35 | Valid | Epoch[192/600] Iteration[003/008] Valid loss: 0.0424
2023-02-06 11:30:35 | Valid | Epoch[192/600] Iteration[004/008] Valid loss: 0.0413
2023-02-06 11:30:35 | Valid | Epoch[192/600] Iteration[005/008] Valid loss: 0.0422
2023-02-06 11:30:35 | Valid | Epoch[192/600] Iteration[006/008] Valid loss: 0.0419
2023-02-06 11:30:35 | Valid | Epoch[192/600] Iteration[007/008] Valid loss: 0.0412
2023-02-06 11:30:35 | Valid | Epoch[192/600] Iteration[008/008] Valid loss: 0.0419
2023-02-06 11:30:35 | Valid | Epoch[192/600] MIou: 0.8663847573294468
2023-02-06 11:30:35 | Valid | Epoch[192/600] Pixel Accuracy: 0.9779268900553385
2023-02-06 11:30:35 | Valid | Epoch[192/600] Mean Pixel Accuracy: 0.8793948907503824
2023-02-06 11:30:35 | Stage | Epoch[192/600] Train loss:0.0274
2023-02-06 11:30:35 | Stage | Epoch[192/600] Valid loss:0.0419
2023-02-06 11:30:35 | Stage | Epoch[192/600] LR:0.01

2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[001/030] Train loss: 0.0282
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[002/030] Train loss: 0.0270
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[003/030] Train loss: 0.0265
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[004/030] Train loss: 0.0263
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[007/030] Train loss: 0.0274
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[008/030] Train loss: 0.0283
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[009/030] Train loss: 0.0281
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[010/030] Train loss: 0.0282
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[011/030] Train loss: 0.0280
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[012/030] Train loss: 0.0279
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[013/030] Train loss: 0.0280
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[014/030] Train loss: 0.0280
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[015/030] Train loss: 0.0280
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[016/030] Train loss: 0.0279
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[017/030] Train loss: 0.0281
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[018/030] Train loss: 0.0278
2023-02-06 11:30:36 | Train | Epoch[193/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[020/030] Train loss: 0.0276
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[021/030] Train loss: 0.0275
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[022/030] Train loss: 0.0276
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[023/030] Train loss: 0.0276
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[024/030] Train loss: 0.0276
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[025/030] Train loss: 0.0277
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[026/030] Train loss: 0.0277
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[027/030] Train loss: 0.0277
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[028/030] Train loss: 0.0277
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[029/030] Train loss: 0.0281
2023-02-06 11:30:37 | Train | Epoch[193/600] Iteration[030/030] Train loss: 0.0281
2023-02-06 11:30:37 | Valid | Epoch[193/600] Iteration[001/008] Valid loss: 0.5321
2023-02-06 11:30:37 | Valid | Epoch[193/600] Iteration[002/008] Valid loss: 0.4540
2023-02-06 11:30:37 | Valid | Epoch[193/600] Iteration[003/008] Valid loss: 0.4504
2023-02-06 11:30:37 | Valid | Epoch[193/600] Iteration[004/008] Valid loss: 0.4599
2023-02-06 11:30:37 | Valid | Epoch[193/600] Iteration[005/008] Valid loss: 0.4812
2023-02-06 11:30:37 | Valid | Epoch[193/600] Iteration[006/008] Valid loss: 0.4730
2023-02-06 11:30:38 | Valid | Epoch[193/600] Iteration[007/008] Valid loss: 0.5016
2023-02-06 11:30:38 | Valid | Epoch[193/600] Iteration[008/008] Valid loss: 0.5078
2023-02-06 11:30:38 | Valid | Epoch[193/600] MIou: 0.8891016289055755
2023-02-06 11:30:38 | Valid | Epoch[193/600] Pixel Accuracy: 0.9779650370279948
2023-02-06 11:30:38 | Valid | Epoch[193/600] Mean Pixel Accuracy: 0.983710273855684
2023-02-06 11:30:38 | Stage | Epoch[193/600] Train loss:0.0281
2023-02-06 11:30:38 | Stage | Epoch[193/600] Valid loss:0.5078
2023-02-06 11:30:38 | Stage | Epoch[193/600] LR:0.01

2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[001/030] Train loss: 0.0249
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[004/030] Train loss: 0.0257
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[005/030] Train loss: 0.0268
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[006/030] Train loss: 0.0264
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[007/030] Train loss: 0.0270
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[009/030] Train loss: 0.0270
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[011/030] Train loss: 0.0268
2023-02-06 11:30:38 | Train | Epoch[194/600] Iteration[012/030] Train loss: 0.0269
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[013/030] Train loss: 0.0272
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[014/030] Train loss: 0.0272
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[015/030] Train loss: 0.0272
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[016/030] Train loss: 0.0273
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[017/030] Train loss: 0.0271
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[018/030] Train loss: 0.0271
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[019/030] Train loss: 0.0270
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[020/030] Train loss: 0.0271
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[021/030] Train loss: 0.0272
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[022/030] Train loss: 0.0272
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[023/030] Train loss: 0.0277
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[024/030] Train loss: 0.0276
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[025/030] Train loss: 0.0278
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[026/030] Train loss: 0.0279
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[028/030] Train loss: 0.0278
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[029/030] Train loss: 0.0278
2023-02-06 11:30:39 | Train | Epoch[194/600] Iteration[030/030] Train loss: 0.0279
2023-02-06 11:30:40 | Valid | Epoch[194/600] Iteration[001/008] Valid loss: 1.9216
2023-02-06 11:30:40 | Valid | Epoch[194/600] Iteration[002/008] Valid loss: 1.7831
2023-02-06 11:30:40 | Valid | Epoch[194/600] Iteration[003/008] Valid loss: 1.8393
2023-02-06 11:30:40 | Valid | Epoch[194/600] Iteration[004/008] Valid loss: 1.9177
2023-02-06 11:30:40 | Valid | Epoch[194/600] Iteration[005/008] Valid loss: 1.9642
2023-02-06 11:30:40 | Valid | Epoch[194/600] Iteration[006/008] Valid loss: 1.9265
2023-02-06 11:30:40 | Valid | Epoch[194/600] Iteration[007/008] Valid loss: 1.9748
2023-02-06 11:30:40 | Valid | Epoch[194/600] Iteration[008/008] Valid loss: 2.0419
2023-02-06 11:30:40 | Valid | Epoch[194/600] MIou: 0.7875187403260901
2023-02-06 11:30:40 | Valid | Epoch[194/600] Pixel Accuracy: 0.9476534525553385
2023-02-06 11:30:40 | Valid | Epoch[194/600] Mean Pixel Accuracy: 0.9702389914422774
2023-02-06 11:30:40 | Stage | Epoch[194/600] Train loss:0.0279
2023-02-06 11:30:40 | Stage | Epoch[194/600] Valid loss:2.0419
2023-02-06 11:30:40 | Stage | Epoch[194/600] LR:0.01

2023-02-06 11:30:40 | Train | Epoch[195/600] Iteration[001/030] Train loss: 0.0247
2023-02-06 11:30:40 | Train | Epoch[195/600] Iteration[002/030] Train loss: 0.0274
2023-02-06 11:30:40 | Train | Epoch[195/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 11:30:40 | Train | Epoch[195/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 11:30:40 | Train | Epoch[195/600] Iteration[005/030] Train loss: 0.0270
2023-02-06 11:30:40 | Train | Epoch[195/600] Iteration[006/030] Train loss: 0.0278
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[007/030] Train loss: 0.0275
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[008/030] Train loss: 0.0275
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[009/030] Train loss: 0.0274
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[010/030] Train loss: 0.0274
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[014/030] Train loss: 0.0273
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[015/030] Train loss: 0.0273
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[016/030] Train loss: 0.0276
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[017/030] Train loss: 0.0274
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[018/030] Train loss: 0.0274
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[020/030] Train loss: 0.0274
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[021/030] Train loss: 0.0273
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[022/030] Train loss: 0.0276
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[023/030] Train loss: 0.0277
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[024/030] Train loss: 0.0278
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[025/030] Train loss: 0.0280
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[026/030] Train loss: 0.0278
2023-02-06 11:30:41 | Train | Epoch[195/600] Iteration[027/030] Train loss: 0.0278
2023-02-06 11:30:42 | Train | Epoch[195/600] Iteration[028/030] Train loss: 0.0279
2023-02-06 11:30:42 | Train | Epoch[195/600] Iteration[029/030] Train loss: 0.0277
2023-02-06 11:30:42 | Train | Epoch[195/600] Iteration[030/030] Train loss: 0.0277
2023-02-06 11:30:42 | Valid | Epoch[195/600] Iteration[001/008] Valid loss: 0.3135
2023-02-06 11:30:42 | Valid | Epoch[195/600] Iteration[002/008] Valid loss: 0.3135
2023-02-06 11:30:42 | Valid | Epoch[195/600] Iteration[003/008] Valid loss: 0.3319
2023-02-06 11:30:42 | Valid | Epoch[195/600] Iteration[004/008] Valid loss: 0.3310
2023-02-06 11:30:42 | Valid | Epoch[195/600] Iteration[005/008] Valid loss: 0.3425
2023-02-06 11:30:42 | Valid | Epoch[195/600] Iteration[006/008] Valid loss: 0.3402
2023-02-06 11:30:42 | Valid | Epoch[195/600] Iteration[007/008] Valid loss: 0.3385
2023-02-06 11:30:42 | Valid | Epoch[195/600] Iteration[008/008] Valid loss: 0.3527
2023-02-06 11:30:42 | Valid | Epoch[195/600] MIou: 0.45494000871136137
2023-02-06 11:30:42 | Valid | Epoch[195/600] Pixel Accuracy: 0.909698486328125
2023-02-06 11:30:42 | Valid | Epoch[195/600] Mean Pixel Accuracy: 0.5000915119176674
2023-02-06 11:30:42 | Stage | Epoch[195/600] Train loss:0.0277
2023-02-06 11:30:42 | Stage | Epoch[195/600] Valid loss:0.3527
2023-02-06 11:30:42 | Stage | Epoch[195/600] LR:0.01

2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[001/030] Train loss: 0.0288
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[002/030] Train loss: 0.0290
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[003/030] Train loss: 0.0270
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[004/030] Train loss: 0.0277
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[005/030] Train loss: 0.0280
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[006/030] Train loss: 0.0287
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[007/030] Train loss: 0.0293
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[008/030] Train loss: 0.0290
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[009/030] Train loss: 0.0290
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[010/030] Train loss: 0.0286
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[011/030] Train loss: 0.0284
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[012/030] Train loss: 0.0283
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[013/030] Train loss: 0.0284
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[014/030] Train loss: 0.0283
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[015/030] Train loss: 0.0282
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[016/030] Train loss: 0.0282
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[017/030] Train loss: 0.0279
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[018/030] Train loss: 0.0280
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[019/030] Train loss: 0.0279
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[020/030] Train loss: 0.0280
2023-02-06 11:30:43 | Train | Epoch[196/600] Iteration[021/030] Train loss: 0.0281
2023-02-06 11:30:44 | Train | Epoch[196/600] Iteration[022/030] Train loss: 0.0281
2023-02-06 11:30:44 | Train | Epoch[196/600] Iteration[023/030] Train loss: 0.0280
2023-02-06 11:30:44 | Train | Epoch[196/600] Iteration[024/030] Train loss: 0.0278
2023-02-06 11:30:44 | Train | Epoch[196/600] Iteration[025/030] Train loss: 0.0277
2023-02-06 11:30:44 | Train | Epoch[196/600] Iteration[026/030] Train loss: 0.0277
2023-02-06 11:30:44 | Train | Epoch[196/600] Iteration[027/030] Train loss: 0.0276
2023-02-06 11:30:44 | Train | Epoch[196/600] Iteration[028/030] Train loss: 0.0278
2023-02-06 11:30:44 | Train | Epoch[196/600] Iteration[029/030] Train loss: 0.0277
2023-02-06 11:30:44 | Train | Epoch[196/600] Iteration[030/030] Train loss: 0.0281
2023-02-06 11:30:44 | Valid | Epoch[196/600] Iteration[001/008] Valid loss: 0.1340
2023-02-06 11:30:44 | Valid | Epoch[196/600] Iteration[002/008] Valid loss: 0.0923
2023-02-06 11:30:44 | Valid | Epoch[196/600] Iteration[003/008] Valid loss: 0.0839
2023-02-06 11:30:44 | Valid | Epoch[196/600] Iteration[004/008] Valid loss: 0.0870
2023-02-06 11:30:44 | Valid | Epoch[196/600] Iteration[005/008] Valid loss: 0.0921
2023-02-06 11:30:44 | Valid | Epoch[196/600] Iteration[006/008] Valid loss: 0.0894
2023-02-06 11:30:44 | Valid | Epoch[196/600] Iteration[007/008] Valid loss: 0.0931
2023-02-06 11:30:44 | Valid | Epoch[196/600] Iteration[008/008] Valid loss: 0.0911
2023-02-06 11:30:45 | Valid | Epoch[196/600] MIou: 0.9381423062919862
2023-02-06 11:30:45 | Valid | Epoch[196/600] Pixel Accuracy: 0.989098866780599
2023-02-06 11:30:45 | Valid | Epoch[196/600] Mean Pixel Accuracy: 0.9755765215749141
2023-02-06 11:30:45 | Stage | Epoch[196/600] Train loss:0.0281
2023-02-06 11:30:45 | Stage | Epoch[196/600] Valid loss:0.0911
2023-02-06 11:30:45 | Stage | Epoch[196/600] LR:0.01

2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[001/030] Train loss: 0.0268
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[004/030] Train loss: 0.0258
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[008/030] Train loss: 0.0270
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[010/030] Train loss: 0.0272
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[011/030] Train loss: 0.0272
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[012/030] Train loss: 0.0275
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[013/030] Train loss: 0.0278
2023-02-06 11:30:45 | Train | Epoch[197/600] Iteration[014/030] Train loss: 0.0276
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[015/030] Train loss: 0.0277
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[016/030] Train loss: 0.0279
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[017/030] Train loss: 0.0279
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[018/030] Train loss: 0.0278
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[019/030] Train loss: 0.0280
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[020/030] Train loss: 0.0280
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[021/030] Train loss: 0.0282
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[022/030] Train loss: 0.0282
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[023/030] Train loss: 0.0281
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[024/030] Train loss: 0.0282
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[025/030] Train loss: 0.0280
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[026/030] Train loss: 0.0279
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[028/030] Train loss: 0.0281
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[029/030] Train loss: 0.0281
2023-02-06 11:30:46 | Train | Epoch[197/600] Iteration[030/030] Train loss: 0.0281
2023-02-06 11:30:47 | Valid | Epoch[197/600] Iteration[001/008] Valid loss: 0.2356
2023-02-06 11:30:47 | Valid | Epoch[197/600] Iteration[002/008] Valid loss: 0.1716
2023-02-06 11:30:47 | Valid | Epoch[197/600] Iteration[003/008] Valid loss: 0.1570
2023-02-06 11:30:47 | Valid | Epoch[197/600] Iteration[004/008] Valid loss: 0.1579
2023-02-06 11:30:47 | Valid | Epoch[197/600] Iteration[005/008] Valid loss: 0.1640
2023-02-06 11:30:47 | Valid | Epoch[197/600] Iteration[006/008] Valid loss: 0.1612
2023-02-06 11:30:47 | Valid | Epoch[197/600] Iteration[007/008] Valid loss: 0.1714
2023-02-06 11:30:47 | Valid | Epoch[197/600] Iteration[008/008] Valid loss: 0.1704
2023-02-06 11:30:47 | Valid | Epoch[197/600] MIou: 0.9257012677791197
2023-02-06 11:30:47 | Valid | Epoch[197/600] Pixel Accuracy: 0.9864107767740885
2023-02-06 11:30:47 | Valid | Epoch[197/600] Mean Pixel Accuracy: 0.9812384035856718
2023-02-06 11:30:47 | Stage | Epoch[197/600] Train loss:0.0281
2023-02-06 11:30:47 | Stage | Epoch[197/600] Valid loss:0.1704
2023-02-06 11:30:47 | Stage | Epoch[197/600] LR:0.01

2023-02-06 11:30:47 | Train | Epoch[198/600] Iteration[001/030] Train loss: 0.0242
2023-02-06 11:30:47 | Train | Epoch[198/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 11:30:47 | Train | Epoch[198/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 11:30:47 | Train | Epoch[198/600] Iteration[004/030] Train loss: 0.0258
2023-02-06 11:30:47 | Train | Epoch[198/600] Iteration[005/030] Train loss: 0.0257
2023-02-06 11:30:47 | Train | Epoch[198/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 11:30:47 | Train | Epoch[198/600] Iteration[007/030] Train loss: 0.0265
2023-02-06 11:30:47 | Train | Epoch[198/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[009/030] Train loss: 0.0260
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[010/030] Train loss: 0.0264
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[013/030] Train loss: 0.0268
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[014/030] Train loss: 0.0269
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[016/030] Train loss: 0.0269
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[018/030] Train loss: 0.0268
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[021/030] Train loss: 0.0269
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[022/030] Train loss: 0.0268
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[023/030] Train loss: 0.0268
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[024/030] Train loss: 0.0268
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[025/030] Train loss: 0.0268
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[026/030] Train loss: 0.0269
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[027/030] Train loss: 0.0268
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 11:30:48 | Train | Epoch[198/600] Iteration[029/030] Train loss: 0.0270
2023-02-06 11:30:49 | Train | Epoch[198/600] Iteration[030/030] Train loss: 0.0269
2023-02-06 11:30:49 | Valid | Epoch[198/600] Iteration[001/008] Valid loss: 0.0475
2023-02-06 11:30:49 | Valid | Epoch[198/600] Iteration[002/008] Valid loss: 0.0459
2023-02-06 11:30:49 | Valid | Epoch[198/600] Iteration[003/008] Valid loss: 0.0456
2023-02-06 11:30:49 | Valid | Epoch[198/600] Iteration[004/008] Valid loss: 0.0439
2023-02-06 11:30:49 | Valid | Epoch[198/600] Iteration[005/008] Valid loss: 0.0447
2023-02-06 11:30:49 | Valid | Epoch[198/600] Iteration[006/008] Valid loss: 0.0442
2023-02-06 11:30:49 | Valid | Epoch[198/600] Iteration[007/008] Valid loss: 0.0431
2023-02-06 11:30:49 | Valid | Epoch[198/600] Iteration[008/008] Valid loss: 0.0442
2023-02-06 11:30:49 | Valid | Epoch[198/600] MIou: 0.8529711619354499
2023-02-06 11:30:49 | Valid | Epoch[198/600] Pixel Accuracy: 0.9757499694824219
2023-02-06 11:30:49 | Valid | Epoch[198/600] Mean Pixel Accuracy: 0.8664367877051824
2023-02-06 11:30:49 | Stage | Epoch[198/600] Train loss:0.0269
2023-02-06 11:30:49 | Stage | Epoch[198/600] Valid loss:0.0442
2023-02-06 11:30:49 | Stage | Epoch[198/600] LR:0.01

2023-02-06 11:30:49 | Train | Epoch[199/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 11:30:49 | Train | Epoch[199/600] Iteration[002/030] Train loss: 0.0252
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[003/030] Train loss: 0.0248
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[006/030] Train loss: 0.0256
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[008/030] Train loss: 0.0258
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[017/030] Train loss: 0.0263
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[018/030] Train loss: 0.0263
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[019/030] Train loss: 0.0263
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[021/030] Train loss: 0.0262
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[022/030] Train loss: 0.0261
2023-02-06 11:30:50 | Train | Epoch[199/600] Iteration[023/030] Train loss: 0.0266
2023-02-06 11:30:51 | Train | Epoch[199/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 11:30:51 | Train | Epoch[199/600] Iteration[025/030] Train loss: 0.0268
2023-02-06 11:30:51 | Train | Epoch[199/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 11:30:51 | Train | Epoch[199/600] Iteration[027/030] Train loss: 0.0269
2023-02-06 11:30:51 | Train | Epoch[199/600] Iteration[028/030] Train loss: 0.0269
2023-02-06 11:30:51 | Train | Epoch[199/600] Iteration[029/030] Train loss: 0.0268
2023-02-06 11:30:51 | Train | Epoch[199/600] Iteration[030/030] Train loss: 0.0268
2023-02-06 11:30:51 | Valid | Epoch[199/600] Iteration[001/008] Valid loss: 0.0816
2023-02-06 11:30:51 | Valid | Epoch[199/600] Iteration[002/008] Valid loss: 0.0563
2023-02-06 11:30:51 | Valid | Epoch[199/600] Iteration[003/008] Valid loss: 0.0493
2023-02-06 11:30:51 | Valid | Epoch[199/600] Iteration[004/008] Valid loss: 0.0475
2023-02-06 11:30:51 | Valid | Epoch[199/600] Iteration[005/008] Valid loss: 0.0476
2023-02-06 11:30:51 | Valid | Epoch[199/600] Iteration[006/008] Valid loss: 0.0461
2023-02-06 11:30:51 | Valid | Epoch[199/600] Iteration[007/008] Valid loss: 0.0472
2023-02-06 11:30:51 | Valid | Epoch[199/600] Iteration[008/008] Valid loss: 0.0466
2023-02-06 11:30:51 | Valid | Epoch[199/600] MIou: 0.9374830814548225
2023-02-06 11:30:51 | Valid | Epoch[199/600] Pixel Accuracy: 0.989355723063151
2023-02-06 11:30:51 | Valid | Epoch[199/600] Mean Pixel Accuracy: 0.9586618323749656
2023-02-06 11:30:51 | Stage | Epoch[199/600] Train loss:0.0268
2023-02-06 11:30:51 | Stage | Epoch[199/600] Valid loss:0.0466
2023-02-06 11:30:51 | Stage | Epoch[199/600] LR:0.01

2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[002/030] Train loss: 0.0247
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[015/030] Train loss: 0.0264
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 11:30:52 | Train | Epoch[200/600] Iteration[018/030] Train loss: 0.0266
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[020/030] Train loss: 0.0263
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[021/030] Train loss: 0.0262
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[022/030] Train loss: 0.0261
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[023/030] Train loss: 0.0261
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[024/030] Train loss: 0.0262
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[025/030] Train loss: 0.0261
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[029/030] Train loss: 0.0261
2023-02-06 11:30:53 | Train | Epoch[200/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 11:30:53 | Valid | Epoch[200/600] Iteration[001/008] Valid loss: 0.1017
2023-02-06 11:30:53 | Valid | Epoch[200/600] Iteration[002/008] Valid loss: 0.0669
2023-02-06 11:30:53 | Valid | Epoch[200/600] Iteration[003/008] Valid loss: 0.0576
2023-02-06 11:30:53 | Valid | Epoch[200/600] Iteration[004/008] Valid loss: 0.0608
2023-02-06 11:30:53 | Valid | Epoch[200/600] Iteration[005/008] Valid loss: 0.0630
2023-02-06 11:30:53 | Valid | Epoch[200/600] Iteration[006/008] Valid loss: 0.0608
2023-02-06 11:30:54 | Valid | Epoch[200/600] Iteration[007/008] Valid loss: 0.0655
2023-02-06 11:30:54 | Valid | Epoch[200/600] Iteration[008/008] Valid loss: 0.0629
2023-02-06 11:30:54 | Valid | Epoch[200/600] MIou: 0.9325200130612672
2023-02-06 11:30:54 | Valid | Epoch[200/600] Pixel Accuracy: 0.9884961446126302
2023-02-06 11:30:54 | Valid | Epoch[200/600] Mean Pixel Accuracy: 0.9545182383929308
2023-02-06 11:30:54 | Stage | Epoch[200/600] Train loss:0.0263
2023-02-06 11:30:54 | Stage | Epoch[200/600] Valid loss:0.0629
2023-02-06 11:30:54 | Stage | Epoch[200/600] LR:0.01

2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[001/030] Train loss: 0.0275
2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[005/030] Train loss: 0.0264
2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[006/030] Train loss: 0.0262
2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[007/030] Train loss: 0.0261
2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 11:30:54 | Train | Epoch[201/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[021/030] Train loss: 0.0263
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[023/030] Train loss: 0.0263
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[024/030] Train loss: 0.0263
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 11:30:55 | Train | Epoch[201/600] Iteration[030/030] Train loss: 0.0264
2023-02-06 11:30:56 | Valid | Epoch[201/600] Iteration[001/008] Valid loss: 0.0419
2023-02-06 11:30:56 | Valid | Epoch[201/600] Iteration[002/008] Valid loss: 0.0362
2023-02-06 11:30:56 | Valid | Epoch[201/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:30:56 | Valid | Epoch[201/600] Iteration[004/008] Valid loss: 0.0340
2023-02-06 11:30:56 | Valid | Epoch[201/600] Iteration[005/008] Valid loss: 0.0347
2023-02-06 11:30:56 | Valid | Epoch[201/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:30:56 | Valid | Epoch[201/600] Iteration[007/008] Valid loss: 0.0343
2023-02-06 11:30:56 | Valid | Epoch[201/600] Iteration[008/008] Valid loss: 0.0343
2023-02-06 11:30:56 | Valid | Epoch[201/600] MIou: 0.9109796886139896
2023-02-06 11:30:56 | Valid | Epoch[201/600] Pixel Accuracy: 0.9852282206217448
2023-02-06 11:30:56 | Valid | Epoch[201/600] Mean Pixel Accuracy: 0.9224082536946994
2023-02-06 11:30:56 | Stage | Epoch[201/600] Train loss:0.0264
2023-02-06 11:30:56 | Stage | Epoch[201/600] Valid loss:0.0343
2023-02-06 11:30:56 | Stage | Epoch[201/600] LR:0.01

2023-02-06 11:30:56 | Train | Epoch[202/600] Iteration[001/030] Train loss: 0.0262
2023-02-06 11:30:56 | Train | Epoch[202/600] Iteration[002/030] Train loss: 0.0281
2023-02-06 11:30:56 | Train | Epoch[202/600] Iteration[003/030] Train loss: 0.0271
2023-02-06 11:30:56 | Train | Epoch[202/600] Iteration[004/030] Train loss: 0.0269
2023-02-06 11:30:56 | Train | Epoch[202/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[007/030] Train loss: 0.0270
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[010/030] Train loss: 0.0264
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[013/030] Train loss: 0.0267
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[016/030] Train loss: 0.0266
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[017/030] Train loss: 0.0266
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[018/030] Train loss: 0.0264
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[019/030] Train loss: 0.0263
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[020/030] Train loss: 0.0263
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[021/030] Train loss: 0.0263
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[022/030] Train loss: 0.0264
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[024/030] Train loss: 0.0265
2023-02-06 11:30:57 | Train | Epoch[202/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 11:30:58 | Train | Epoch[202/600] Iteration[026/030] Train loss: 0.0266
2023-02-06 11:30:58 | Train | Epoch[202/600] Iteration[027/030] Train loss: 0.0265
2023-02-06 11:30:58 | Train | Epoch[202/600] Iteration[028/030] Train loss: 0.0266
2023-02-06 11:30:58 | Train | Epoch[202/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 11:30:58 | Train | Epoch[202/600] Iteration[030/030] Train loss: 0.0266
2023-02-06 11:30:58 | Valid | Epoch[202/600] Iteration[001/008] Valid loss: 0.7317
2023-02-06 11:30:58 | Valid | Epoch[202/600] Iteration[002/008] Valid loss: 0.6941
2023-02-06 11:30:58 | Valid | Epoch[202/600] Iteration[003/008] Valid loss: 0.6983
2023-02-06 11:30:58 | Valid | Epoch[202/600] Iteration[004/008] Valid loss: 0.7237
2023-02-06 11:30:58 | Valid | Epoch[202/600] Iteration[005/008] Valid loss: 0.7460
2023-02-06 11:30:58 | Valid | Epoch[202/600] Iteration[006/008] Valid loss: 0.7276
2023-02-06 11:30:58 | Valid | Epoch[202/600] Iteration[007/008] Valid loss: 0.7647
2023-02-06 11:30:58 | Valid | Epoch[202/600] Iteration[008/008] Valid loss: 0.7781
2023-02-06 11:30:58 | Valid | Epoch[202/600] MIou: 0.864873986928993
2023-02-06 11:30:58 | Valid | Epoch[202/600] Pixel Accuracy: 0.971764882405599
2023-02-06 11:30:58 | Valid | Epoch[202/600] Mean Pixel Accuracy: 0.9818431390224516
2023-02-06 11:30:58 | Stage | Epoch[202/600] Train loss:0.0266
2023-02-06 11:30:58 | Stage | Epoch[202/600] Valid loss:0.7781
2023-02-06 11:30:58 | Stage | Epoch[202/600] LR:0.01

2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[001/030] Train loss: 0.0248
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[005/030] Train loss: 0.0265
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[007/030] Train loss: 0.0260
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[009/030] Train loss: 0.0263
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[015/030] Train loss: 0.0260
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[016/030] Train loss: 0.0261
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[017/030] Train loss: 0.0259
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 11:30:59 | Train | Epoch[203/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[023/030] Train loss: 0.0259
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[024/030] Train loss: 0.0260
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[025/030] Train loss: 0.0260
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[026/030] Train loss: 0.0260
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[029/030] Train loss: 0.0264
2023-02-06 11:31:00 | Train | Epoch[203/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 11:31:00 | Valid | Epoch[203/600] Iteration[001/008] Valid loss: 0.0682
2023-02-06 11:31:00 | Valid | Epoch[203/600] Iteration[002/008] Valid loss: 0.0662
2023-02-06 11:31:00 | Valid | Epoch[203/600] Iteration[003/008] Valid loss: 0.0660
2023-02-06 11:31:00 | Valid | Epoch[203/600] Iteration[004/008] Valid loss: 0.0637
2023-02-06 11:31:00 | Valid | Epoch[203/600] Iteration[005/008] Valid loss: 0.0649
2023-02-06 11:31:00 | Valid | Epoch[203/600] Iteration[006/008] Valid loss: 0.0638
2023-02-06 11:31:00 | Valid | Epoch[203/600] Iteration[007/008] Valid loss: 0.0621
2023-02-06 11:31:00 | Valid | Epoch[203/600] Iteration[008/008] Valid loss: 0.0646
2023-02-06 11:31:01 | Valid | Epoch[203/600] MIou: 0.7783397921234594
2023-02-06 11:31:01 | Valid | Epoch[203/600] Pixel Accuracy: 0.9634246826171875
2023-02-06 11:31:01 | Valid | Epoch[203/600] Mean Pixel Accuracy: 0.7978490276120125
2023-02-06 11:31:01 | Stage | Epoch[203/600] Train loss:0.0263
2023-02-06 11:31:01 | Stage | Epoch[203/600] Valid loss:0.0646
2023-02-06 11:31:01 | Stage | Epoch[203/600] LR:0.01

2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[001/030] Train loss: 0.0262
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[004/030] Train loss: 0.0254
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[006/030] Train loss: 0.0256
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 11:31:01 | Train | Epoch[204/600] Iteration[013/030] Train loss: 0.0258
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[016/030] Train loss: 0.0260
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[022/030] Train loss: 0.0258
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[023/030] Train loss: 0.0258
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[025/030] Train loss: 0.0258
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[026/030] Train loss: 0.0259
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[028/030] Train loss: 0.0258
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[029/030] Train loss: 0.0258
2023-02-06 11:31:02 | Train | Epoch[204/600] Iteration[030/030] Train loss: 0.0258
2023-02-06 11:31:03 | Valid | Epoch[204/600] Iteration[001/008] Valid loss: 0.0405
2023-02-06 11:31:03 | Valid | Epoch[204/600] Iteration[002/008] Valid loss: 0.0353
2023-02-06 11:31:03 | Valid | Epoch[204/600] Iteration[003/008] Valid loss: 0.0342
2023-02-06 11:31:03 | Valid | Epoch[204/600] Iteration[004/008] Valid loss: 0.0331
2023-02-06 11:31:03 | Valid | Epoch[204/600] Iteration[005/008] Valid loss: 0.0338
2023-02-06 11:31:03 | Valid | Epoch[204/600] Iteration[006/008] Valid loss: 0.0337
2023-02-06 11:31:03 | Valid | Epoch[204/600] Iteration[007/008] Valid loss: 0.0333
2023-02-06 11:31:03 | Valid | Epoch[204/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 11:31:03 | Valid | Epoch[204/600] MIou: 0.9055794006637015
2023-02-06 11:31:03 | Valid | Epoch[204/600] Pixel Accuracy: 0.984368642171224
2023-02-06 11:31:03 | Valid | Epoch[204/600] Mean Pixel Accuracy: 0.9164322634456736
2023-02-06 11:31:03 | Stage | Epoch[204/600] Train loss:0.0258
2023-02-06 11:31:03 | Stage | Epoch[204/600] Valid loss:0.0334
2023-02-06 11:31:03 | Stage | Epoch[204/600] LR:0.01

2023-02-06 11:31:03 | Train | Epoch[205/600] Iteration[001/030] Train loss: 0.0257
2023-02-06 11:31:03 | Train | Epoch[205/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 11:31:03 | Train | Epoch[205/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 11:31:03 | Train | Epoch[205/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 11:31:03 | Train | Epoch[205/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 11:31:03 | Train | Epoch[205/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[007/030] Train loss: 0.0244
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[009/030] Train loss: 0.0246
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[010/030] Train loss: 0.0248
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[013/030] Train loss: 0.0247
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 11:31:04 | Train | Epoch[205/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 11:31:05 | Train | Epoch[205/600] Iteration[027/030] Train loss: 0.0256
2023-02-06 11:31:05 | Train | Epoch[205/600] Iteration[028/030] Train loss: 0.0256
2023-02-06 11:31:05 | Train | Epoch[205/600] Iteration[029/030] Train loss: 0.0256
2023-02-06 11:31:05 | Train | Epoch[205/600] Iteration[030/030] Train loss: 0.0258
2023-02-06 11:31:05 | Valid | Epoch[205/600] Iteration[001/008] Valid loss: 0.0594
2023-02-06 11:31:05 | Valid | Epoch[205/600] Iteration[002/008] Valid loss: 0.0442
2023-02-06 11:31:05 | Valid | Epoch[205/600] Iteration[003/008] Valid loss: 0.0405
2023-02-06 11:31:05 | Valid | Epoch[205/600] Iteration[004/008] Valid loss: 0.0396
2023-02-06 11:31:05 | Valid | Epoch[205/600] Iteration[005/008] Valid loss: 0.0402
2023-02-06 11:31:05 | Valid | Epoch[205/600] Iteration[006/008] Valid loss: 0.0403
2023-02-06 11:31:05 | Valid | Epoch[205/600] Iteration[007/008] Valid loss: 0.0406
2023-02-06 11:31:05 | Valid | Epoch[205/600] Iteration[008/008] Valid loss: 0.0401
2023-02-06 11:31:05 | Valid | Epoch[205/600] MIou: 0.9248982968295216
2023-02-06 11:31:05 | Valid | Epoch[205/600] Pixel Accuracy: 0.9873428344726562
2023-02-06 11:31:05 | Valid | Epoch[205/600] Mean Pixel Accuracy: 0.9421290957691174
2023-02-06 11:31:05 | Stage | Epoch[205/600] Train loss:0.0258
2023-02-06 11:31:05 | Stage | Epoch[205/600] Valid loss:0.0401
2023-02-06 11:31:05 | Stage | Epoch[205/600] LR:0.01

2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[001/030] Train loss: 0.0241
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[002/030] Train loss: 0.0265
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[005/030] Train loss: 0.0258
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[007/030] Train loss: 0.0260
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[008/030] Train loss: 0.0259
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[010/030] Train loss: 0.0266
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[011/030] Train loss: 0.0266
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[015/030] Train loss: 0.0260
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[016/030] Train loss: 0.0259
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[017/030] Train loss: 0.0259
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 11:31:06 | Train | Epoch[206/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 11:31:07 | Train | Epoch[206/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 11:31:07 | Train | Epoch[206/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 11:31:07 | Train | Epoch[206/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 11:31:07 | Train | Epoch[206/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 11:31:07 | Train | Epoch[206/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 11:31:07 | Train | Epoch[206/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 11:31:07 | Train | Epoch[206/600] Iteration[027/030] Train loss: 0.0256
2023-02-06 11:31:07 | Train | Epoch[206/600] Iteration[028/030] Train loss: 0.0258
2023-02-06 11:31:07 | Train | Epoch[206/600] Iteration[029/030] Train loss: 0.0258
2023-02-06 11:31:07 | Train | Epoch[206/600] Iteration[030/030] Train loss: 0.0258
2023-02-06 11:31:07 | Valid | Epoch[206/600] Iteration[001/008] Valid loss: 0.0776
2023-02-06 11:31:07 | Valid | Epoch[206/600] Iteration[002/008] Valid loss: 0.0556
2023-02-06 11:31:07 | Valid | Epoch[206/600] Iteration[003/008] Valid loss: 0.0492
2023-02-06 11:31:07 | Valid | Epoch[206/600] Iteration[004/008] Valid loss: 0.0491
2023-02-06 11:31:07 | Valid | Epoch[206/600] Iteration[005/008] Valid loss: 0.0504
2023-02-06 11:31:07 | Valid | Epoch[206/600] Iteration[006/008] Valid loss: 0.0491
2023-02-06 11:31:07 | Valid | Epoch[206/600] Iteration[007/008] Valid loss: 0.0498
2023-02-06 11:31:07 | Valid | Epoch[206/600] Iteration[008/008] Valid loss: 0.0484
2023-02-06 11:31:08 | Valid | Epoch[206/600] MIou: 0.9389293163138412
2023-02-06 11:31:08 | Valid | Epoch[206/600] Pixel Accuracy: 0.9895896911621094
2023-02-06 11:31:08 | Valid | Epoch[206/600] Mean Pixel Accuracy: 0.9605847846585697
2023-02-06 11:31:08 | Stage | Epoch[206/600] Train loss:0.0258
2023-02-06 11:31:08 | Stage | Epoch[206/600] Valid loss:0.0484
2023-02-06 11:31:08 | Stage | Epoch[206/600] LR:0.01

2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[002/030] Train loss: 0.0265
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[013/030] Train loss: 0.0258
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 11:31:08 | Train | Epoch[207/600] Iteration[015/030] Train loss: 0.0258
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[019/030] Train loss: 0.0260
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[020/030] Train loss: 0.0260
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[021/030] Train loss: 0.0260
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[022/030] Train loss: 0.0261
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[024/030] Train loss: 0.0261
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[025/030] Train loss: 0.0261
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[026/030] Train loss: 0.0261
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 11:31:09 | Train | Epoch[207/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 11:31:09 | Valid | Epoch[207/600] Iteration[001/008] Valid loss: 0.1965
2023-02-06 11:31:10 | Valid | Epoch[207/600] Iteration[002/008] Valid loss: 0.1322
2023-02-06 11:31:10 | Valid | Epoch[207/600] Iteration[003/008] Valid loss: 0.1195
2023-02-06 11:31:10 | Valid | Epoch[207/600] Iteration[004/008] Valid loss: 0.1236
2023-02-06 11:31:10 | Valid | Epoch[207/600] Iteration[005/008] Valid loss: 0.1319
2023-02-06 11:31:10 | Valid | Epoch[207/600] Iteration[006/008] Valid loss: 0.1290
2023-02-06 11:31:10 | Valid | Epoch[207/600] Iteration[007/008] Valid loss: 0.1415
2023-02-06 11:31:10 | Valid | Epoch[207/600] Iteration[008/008] Valid loss: 0.1378
2023-02-06 11:31:10 | Valid | Epoch[207/600] MIou: 0.9325045251112647
2023-02-06 11:31:10 | Valid | Epoch[207/600] Pixel Accuracy: 0.9880663553873698
2023-02-06 11:31:10 | Valid | Epoch[207/600] Mean Pixel Accuracy: 0.9715851546611263
2023-02-06 11:31:10 | Stage | Epoch[207/600] Train loss:0.0262
2023-02-06 11:31:10 | Stage | Epoch[207/600] Valid loss:0.1378
2023-02-06 11:31:10 | Stage | Epoch[207/600] LR:0.01

2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[001/030] Train loss: 0.0286
2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[002/030] Train loss: 0.0278
2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[004/030] Train loss: 0.0262
2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[005/030] Train loss: 0.0264
2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 11:31:10 | Train | Epoch[208/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[021/030] Train loss: 0.0260
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[024/030] Train loss: 0.0263
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[025/030] Train loss: 0.0262
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 11:31:11 | Train | Epoch[208/600] Iteration[030/030] Train loss: 0.0261
2023-02-06 11:31:12 | Valid | Epoch[208/600] Iteration[001/008] Valid loss: 1.3900
2023-02-06 11:31:12 | Valid | Epoch[208/600] Iteration[002/008] Valid loss: 1.3350
2023-02-06 11:31:12 | Valid | Epoch[208/600] Iteration[003/008] Valid loss: 1.3631
2023-02-06 11:31:12 | Valid | Epoch[208/600] Iteration[004/008] Valid loss: 1.4105
2023-02-06 11:31:12 | Valid | Epoch[208/600] Iteration[005/008] Valid loss: 1.4468
2023-02-06 11:31:12 | Valid | Epoch[208/600] Iteration[006/008] Valid loss: 1.4107
2023-02-06 11:31:12 | Valid | Epoch[208/600] Iteration[007/008] Valid loss: 1.4562
2023-02-06 11:31:12 | Valid | Epoch[208/600] Iteration[008/008] Valid loss: 1.4994
2023-02-06 11:31:12 | Valid | Epoch[208/600] MIou: 0.8233799034794489
2023-02-06 11:31:12 | Valid | Epoch[208/600] Pixel Accuracy: 0.9597282409667969
2023-02-06 11:31:12 | Valid | Epoch[208/600] Mean Pixel Accuracy: 0.9766031698554659
2023-02-06 11:31:12 | Stage | Epoch[208/600] Train loss:0.0261
2023-02-06 11:31:12 | Stage | Epoch[208/600] Valid loss:1.4994
2023-02-06 11:31:12 | Stage | Epoch[208/600] LR:0.01

2023-02-06 11:31:12 | Train | Epoch[209/600] Iteration[001/030] Train loss: 0.0285
2023-02-06 11:31:12 | Train | Epoch[209/600] Iteration[002/030] Train loss: 0.0274
2023-02-06 11:31:12 | Train | Epoch[209/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 11:31:12 | Train | Epoch[209/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 11:31:12 | Train | Epoch[209/600] Iteration[005/030] Train loss: 0.0264
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[006/030] Train loss: 0.0262
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[008/030] Train loss: 0.0258
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[013/030] Train loss: 0.0258
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[019/030] Train loss: 0.0258
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[025/030] Train loss: 0.0259
2023-02-06 11:31:13 | Train | Epoch[209/600] Iteration[026/030] Train loss: 0.0260
2023-02-06 11:31:14 | Train | Epoch[209/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 11:31:14 | Train | Epoch[209/600] Iteration[028/030] Train loss: 0.0260
2023-02-06 11:31:14 | Train | Epoch[209/600] Iteration[029/030] Train loss: 0.0260
2023-02-06 11:31:14 | Train | Epoch[209/600] Iteration[030/030] Train loss: 0.0260
2023-02-06 11:31:14 | Valid | Epoch[209/600] Iteration[001/008] Valid loss: 0.0498
2023-02-06 11:31:14 | Valid | Epoch[209/600] Iteration[002/008] Valid loss: 0.0478
2023-02-06 11:31:14 | Valid | Epoch[209/600] Iteration[003/008] Valid loss: 0.0476
2023-02-06 11:31:14 | Valid | Epoch[209/600] Iteration[004/008] Valid loss: 0.0455
2023-02-06 11:31:14 | Valid | Epoch[209/600] Iteration[005/008] Valid loss: 0.0462
2023-02-06 11:31:14 | Valid | Epoch[209/600] Iteration[006/008] Valid loss: 0.0455
2023-02-06 11:31:14 | Valid | Epoch[209/600] Iteration[007/008] Valid loss: 0.0443
2023-02-06 11:31:14 | Valid | Epoch[209/600] Iteration[008/008] Valid loss: 0.0450
2023-02-06 11:31:14 | Valid | Epoch[209/600] MIou: 0.8616185588497403
2023-02-06 11:31:14 | Valid | Epoch[209/600] Pixel Accuracy: 0.9771703084309896
2023-02-06 11:31:14 | Valid | Epoch[209/600] Mean Pixel Accuracy: 0.8744963278631739
2023-02-06 11:31:14 | Stage | Epoch[209/600] Train loss:0.0260
2023-02-06 11:31:14 | Stage | Epoch[209/600] Valid loss:0.0450
2023-02-06 11:31:14 | Stage | Epoch[209/600] LR:0.01

2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[001/030] Train loss: 0.0281
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[003/030] Train loss: 0.0261
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 11:31:15 | Train | Epoch[210/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 11:31:16 | Train | Epoch[210/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 11:31:16 | Valid | Epoch[210/600] Iteration[001/008] Valid loss: 0.1021
2023-02-06 11:31:16 | Valid | Epoch[210/600] Iteration[002/008] Valid loss: 0.0729
2023-02-06 11:31:16 | Valid | Epoch[210/600] Iteration[003/008] Valid loss: 0.0643
2023-02-06 11:31:16 | Valid | Epoch[210/600] Iteration[004/008] Valid loss: 0.0654
2023-02-06 11:31:16 | Valid | Epoch[210/600] Iteration[005/008] Valid loss: 0.0675
2023-02-06 11:31:16 | Valid | Epoch[210/600] Iteration[006/008] Valid loss: 0.0657
2023-02-06 11:31:17 | Valid | Epoch[210/600] Iteration[007/008] Valid loss: 0.0668
2023-02-06 11:31:17 | Valid | Epoch[210/600] Iteration[008/008] Valid loss: 0.0658
2023-02-06 11:31:17 | Valid | Epoch[210/600] MIou: 0.9387432645657618
2023-02-06 11:31:17 | Valid | Epoch[210/600] Pixel Accuracy: 0.9893531799316406
2023-02-06 11:31:17 | Valid | Epoch[210/600] Mean Pixel Accuracy: 0.9695280027331302
2023-02-06 11:31:17 | Stage | Epoch[210/600] Train loss:0.0254
2023-02-06 11:31:17 | Stage | Epoch[210/600] Valid loss:0.0658
2023-02-06 11:31:17 | Stage | Epoch[210/600] LR:0.01

2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[002/030] Train loss: 0.0237
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[004/030] Train loss: 0.0257
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[005/030] Train loss: 0.0258
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 11:31:17 | Train | Epoch[211/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[022/030] Train loss: 0.0256
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[027/030] Train loss: 0.0257
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[028/030] Train loss: 0.0258
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[029/030] Train loss: 0.0258
2023-02-06 11:31:18 | Train | Epoch[211/600] Iteration[030/030] Train loss: 0.0258
2023-02-06 11:31:19 | Valid | Epoch[211/600] Iteration[001/008] Valid loss: 0.2970
2023-02-06 11:31:19 | Valid | Epoch[211/600] Iteration[002/008] Valid loss: 0.2112
2023-02-06 11:31:19 | Valid | Epoch[211/600] Iteration[003/008] Valid loss: 0.2032
2023-02-06 11:31:19 | Valid | Epoch[211/600] Iteration[004/008] Valid loss: 0.2086
2023-02-06 11:31:19 | Valid | Epoch[211/600] Iteration[005/008] Valid loss: 0.2210
2023-02-06 11:31:19 | Valid | Epoch[211/600] Iteration[006/008] Valid loss: 0.2183
2023-02-06 11:31:19 | Valid | Epoch[211/600] Iteration[007/008] Valid loss: 0.2302
2023-02-06 11:31:19 | Valid | Epoch[211/600] Iteration[008/008] Valid loss: 0.2324
2023-02-06 11:31:19 | Valid | Epoch[211/600] MIou: 0.9108127480711556
2023-02-06 11:31:19 | Valid | Epoch[211/600] Pixel Accuracy: 0.9831415812174479
2023-02-06 11:31:19 | Valid | Epoch[211/600] Mean Pixel Accuracy: 0.9821045123149974
2023-02-06 11:31:19 | Stage | Epoch[211/600] Train loss:0.0258
2023-02-06 11:31:19 | Stage | Epoch[211/600] Valid loss:0.2324
2023-02-06 11:31:19 | Stage | Epoch[211/600] LR:0.01

2023-02-06 11:31:19 | Train | Epoch[212/600] Iteration[001/030] Train loss: 0.0228
2023-02-06 11:31:19 | Train | Epoch[212/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 11:31:19 | Train | Epoch[212/600] Iteration[003/030] Train loss: 0.0237
2023-02-06 11:31:19 | Train | Epoch[212/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 11:31:19 | Train | Epoch[212/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 11:31:19 | Train | Epoch[212/600] Iteration[006/030] Train loss: 0.0238
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[014/030] Train loss: 0.0259
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[020/030] Train loss: 0.0256
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[021/030] Train loss: 0.0257
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[022/030] Train loss: 0.0256
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[025/030] Train loss: 0.0259
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[026/030] Train loss: 0.0259
2023-02-06 11:31:20 | Train | Epoch[212/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 11:31:21 | Train | Epoch[212/600] Iteration[028/030] Train loss: 0.0258
2023-02-06 11:31:21 | Train | Epoch[212/600] Iteration[029/030] Train loss: 0.0260
2023-02-06 11:31:21 | Train | Epoch[212/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 11:31:21 | Valid | Epoch[212/600] Iteration[001/008] Valid loss: 0.4122
2023-02-06 11:31:21 | Valid | Epoch[212/600] Iteration[002/008] Valid loss: 0.3739
2023-02-06 11:31:21 | Valid | Epoch[212/600] Iteration[003/008] Valid loss: 0.3670
2023-02-06 11:31:21 | Valid | Epoch[212/600] Iteration[004/008] Valid loss: 0.3658
2023-02-06 11:31:21 | Valid | Epoch[212/600] Iteration[005/008] Valid loss: 0.3802
2023-02-06 11:31:21 | Valid | Epoch[212/600] Iteration[006/008] Valid loss: 0.3685
2023-02-06 11:31:21 | Valid | Epoch[212/600] Iteration[007/008] Valid loss: 0.3910
2023-02-06 11:31:21 | Valid | Epoch[212/600] Iteration[008/008] Valid loss: 0.3957
2023-02-06 11:31:21 | Valid | Epoch[212/600] MIou: 0.902355899690945
2023-02-06 11:31:21 | Valid | Epoch[212/600] Pixel Accuracy: 0.9811617533365885
2023-02-06 11:31:21 | Valid | Epoch[212/600] Mean Pixel Accuracy: 0.9833242461044572
2023-02-06 11:31:21 | Stage | Epoch[212/600] Train loss:0.0263
2023-02-06 11:31:21 | Stage | Epoch[212/600] Valid loss:0.3957
2023-02-06 11:31:21 | Stage | Epoch[212/600] LR:0.01

2023-02-06 11:31:21 | Train | Epoch[213/600] Iteration[001/030] Train loss: 0.0212
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[002/030] Train loss: 0.0270
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[003/030] Train loss: 0.0284
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[004/030] Train loss: 0.0284
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[005/030] Train loss: 0.0297
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[006/030] Train loss: 0.0291
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[007/030] Train loss: 0.0292
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[008/030] Train loss: 0.0293
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[009/030] Train loss: 0.0291
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[010/030] Train loss: 0.0285
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[011/030] Train loss: 0.0288
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[012/030] Train loss: 0.0288
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[013/030] Train loss: 0.0287
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[014/030] Train loss: 0.0285
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[015/030] Train loss: 0.0282
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[016/030] Train loss: 0.0282
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[017/030] Train loss: 0.0280
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[018/030] Train loss: 0.0281
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[019/030] Train loss: 0.0280
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[020/030] Train loss: 0.0281
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[021/030] Train loss: 0.0281
2023-02-06 11:31:22 | Train | Epoch[213/600] Iteration[022/030] Train loss: 0.0281
2023-02-06 11:31:23 | Train | Epoch[213/600] Iteration[023/030] Train loss: 0.0280
2023-02-06 11:31:23 | Train | Epoch[213/600] Iteration[024/030] Train loss: 0.0278
2023-02-06 11:31:23 | Train | Epoch[213/600] Iteration[025/030] Train loss: 0.0279
2023-02-06 11:31:23 | Train | Epoch[213/600] Iteration[026/030] Train loss: 0.0279
2023-02-06 11:31:23 | Train | Epoch[213/600] Iteration[027/030] Train loss: 0.0278
2023-02-06 11:31:23 | Train | Epoch[213/600] Iteration[028/030] Train loss: 0.0278
2023-02-06 11:31:23 | Train | Epoch[213/600] Iteration[029/030] Train loss: 0.0277
2023-02-06 11:31:23 | Train | Epoch[213/600] Iteration[030/030] Train loss: 0.0277
2023-02-06 11:31:23 | Valid | Epoch[213/600] Iteration[001/008] Valid loss: 0.1252
2023-02-06 11:31:23 | Valid | Epoch[213/600] Iteration[002/008] Valid loss: 0.1193
2023-02-06 11:31:23 | Valid | Epoch[213/600] Iteration[003/008] Valid loss: 0.1216
2023-02-06 11:31:23 | Valid | Epoch[213/600] Iteration[004/008] Valid loss: 0.1190
2023-02-06 11:31:23 | Valid | Epoch[213/600] Iteration[005/008] Valid loss: 0.1217
2023-02-06 11:31:23 | Valid | Epoch[213/600] Iteration[006/008] Valid loss: 0.1199
2023-02-06 11:31:23 | Valid | Epoch[213/600] Iteration[007/008] Valid loss: 0.1179
2023-02-06 11:31:23 | Valid | Epoch[213/600] Iteration[008/008] Valid loss: 0.1234
2023-02-06 11:31:23 | Valid | Epoch[213/600] MIou: 0.621642054162632
2023-02-06 11:31:23 | Valid | Epoch[213/600] Pixel Accuracy: 0.9374643961588541
2023-02-06 11:31:23 | Valid | Epoch[213/600] Mean Pixel Accuracy: 0.6538033760858241
2023-02-06 11:31:23 | Stage | Epoch[213/600] Train loss:0.0277
2023-02-06 11:31:23 | Stage | Epoch[213/600] Valid loss:0.1234
2023-02-06 11:31:23 | Stage | Epoch[213/600] LR:0.01

2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[001/030] Train loss: 0.0288
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[004/030] Train loss: 0.0262
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 11:31:24 | Train | Epoch[214/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[026/030] Train loss: 0.0257
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[028/030] Train loss: 0.0257
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[029/030] Train loss: 0.0255
2023-02-06 11:31:25 | Train | Epoch[214/600] Iteration[030/030] Train loss: 0.0256
2023-02-06 11:31:25 | Valid | Epoch[214/600] Iteration[001/008] Valid loss: 0.1218
2023-02-06 11:31:25 | Valid | Epoch[214/600] Iteration[002/008] Valid loss: 0.1176
2023-02-06 11:31:26 | Valid | Epoch[214/600] Iteration[003/008] Valid loss: 0.1200
2023-02-06 11:31:26 | Valid | Epoch[214/600] Iteration[004/008] Valid loss: 0.1179
2023-02-06 11:31:26 | Valid | Epoch[214/600] Iteration[005/008] Valid loss: 0.1197
2023-02-06 11:31:26 | Valid | Epoch[214/600] Iteration[006/008] Valid loss: 0.1190
2023-02-06 11:31:26 | Valid | Epoch[214/600] Iteration[007/008] Valid loss: 0.1162
2023-02-06 11:31:26 | Valid | Epoch[214/600] Iteration[008/008] Valid loss: 0.1191
2023-02-06 11:31:26 | Valid | Epoch[214/600] MIou: 0.6948852217427784
2023-02-06 11:31:26 | Valid | Epoch[214/600] Pixel Accuracy: 0.9496243794759115
2023-02-06 11:31:26 | Valid | Epoch[214/600] Mean Pixel Accuracy: 0.7211209505976433
2023-02-06 11:31:26 | Stage | Epoch[214/600] Train loss:0.0256
2023-02-06 11:31:26 | Stage | Epoch[214/600] Valid loss:0.1191
2023-02-06 11:31:26 | Stage | Epoch[214/600] LR:0.01

2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[002/030] Train loss: 0.0269
2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[004/030] Train loss: 0.0266
2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[006/030] Train loss: 0.0262
2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[010/030] Train loss: 0.0263
2023-02-06 11:31:26 | Train | Epoch[215/600] Iteration[011/030] Train loss: 0.0262
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[019/030] Train loss: 0.0258
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 11:31:27 | Train | Epoch[215/600] Iteration[030/030] Train loss: 0.0255
2023-02-06 11:31:28 | Valid | Epoch[215/600] Iteration[001/008] Valid loss: 0.0514
2023-02-06 11:31:28 | Valid | Epoch[215/600] Iteration[002/008] Valid loss: 0.0498
2023-02-06 11:31:28 | Valid | Epoch[215/600] Iteration[003/008] Valid loss: 0.0502
2023-02-06 11:31:28 | Valid | Epoch[215/600] Iteration[004/008] Valid loss: 0.0483
2023-02-06 11:31:28 | Valid | Epoch[215/600] Iteration[005/008] Valid loss: 0.0492
2023-02-06 11:31:28 | Valid | Epoch[215/600] Iteration[006/008] Valid loss: 0.0486
2023-02-06 11:31:28 | Valid | Epoch[215/600] Iteration[007/008] Valid loss: 0.0472
2023-02-06 11:31:28 | Valid | Epoch[215/600] Iteration[008/008] Valid loss: 0.0481
2023-02-06 11:31:28 | Valid | Epoch[215/600] MIou: 0.8514306579505186
2023-02-06 11:31:28 | Valid | Epoch[215/600] Pixel Accuracy: 0.9755096435546875
2023-02-06 11:31:28 | Valid | Epoch[215/600] Mean Pixel Accuracy: 0.8648146835203079
2023-02-06 11:31:28 | Stage | Epoch[215/600] Train loss:0.0255
2023-02-06 11:31:28 | Stage | Epoch[215/600] Valid loss:0.0481
2023-02-06 11:31:28 | Stage | Epoch[215/600] LR:0.01

2023-02-06 11:31:28 | Train | Epoch[216/600] Iteration[001/030] Train loss: 0.0243
2023-02-06 11:31:28 | Train | Epoch[216/600] Iteration[002/030] Train loss: 0.0265
2023-02-06 11:31:28 | Train | Epoch[216/600] Iteration[003/030] Train loss: 0.0261
2023-02-06 11:31:28 | Train | Epoch[216/600] Iteration[004/030] Train loss: 0.0262
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[005/030] Train loss: 0.0257
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[006/030] Train loss: 0.0253
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[008/030] Train loss: 0.0259
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[015/030] Train loss: 0.0264
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[017/030] Train loss: 0.0261
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[022/030] Train loss: 0.0260
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[024/030] Train loss: 0.0260
2023-02-06 11:31:29 | Train | Epoch[216/600] Iteration[025/030] Train loss: 0.0260
2023-02-06 11:31:30 | Train | Epoch[216/600] Iteration[026/030] Train loss: 0.0259
2023-02-06 11:31:30 | Train | Epoch[216/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 11:31:30 | Train | Epoch[216/600] Iteration[028/030] Train loss: 0.0257
2023-02-06 11:31:30 | Train | Epoch[216/600] Iteration[029/030] Train loss: 0.0257
2023-02-06 11:31:30 | Train | Epoch[216/600] Iteration[030/030] Train loss: 0.0257
2023-02-06 11:31:30 | Valid | Epoch[216/600] Iteration[001/008] Valid loss: 0.2489
2023-02-06 11:31:30 | Valid | Epoch[216/600] Iteration[002/008] Valid loss: 0.1758
2023-02-06 11:31:30 | Valid | Epoch[216/600] Iteration[003/008] Valid loss: 0.1649
2023-02-06 11:31:30 | Valid | Epoch[216/600] Iteration[004/008] Valid loss: 0.1713
2023-02-06 11:31:30 | Valid | Epoch[216/600] Iteration[005/008] Valid loss: 0.1809
2023-02-06 11:31:30 | Valid | Epoch[216/600] Iteration[006/008] Valid loss: 0.1762
2023-02-06 11:31:30 | Valid | Epoch[216/600] Iteration[007/008] Valid loss: 0.1941
2023-02-06 11:31:30 | Valid | Epoch[216/600] Iteration[008/008] Valid loss: 0.1892
2023-02-06 11:31:30 | Valid | Epoch[216/600] MIou: 0.9227107391182359
2023-02-06 11:31:30 | Valid | Epoch[216/600] Pixel Accuracy: 0.9857393900553385
2023-02-06 11:31:30 | Valid | Epoch[216/600] Mean Pixel Accuracy: 0.9825052224612124
2023-02-06 11:31:30 | Stage | Epoch[216/600] Train loss:0.0257
2023-02-06 11:31:30 | Stage | Epoch[216/600] Valid loss:0.1892
2023-02-06 11:31:30 | Stage | Epoch[216/600] LR:0.01

2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[001/030] Train loss: 0.0279
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[006/030] Train loss: 0.0248
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[007/030] Train loss: 0.0248
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:31:31 | Train | Epoch[217/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:31:32 | Train | Epoch[217/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 11:31:32 | Valid | Epoch[217/600] Iteration[001/008] Valid loss: 0.0531
2023-02-06 11:31:32 | Valid | Epoch[217/600] Iteration[002/008] Valid loss: 0.0495
2023-02-06 11:31:32 | Valid | Epoch[217/600] Iteration[003/008] Valid loss: 0.0491
2023-02-06 11:31:32 | Valid | Epoch[217/600] Iteration[004/008] Valid loss: 0.0470
2023-02-06 11:31:32 | Valid | Epoch[217/600] Iteration[005/008] Valid loss: 0.0476
2023-02-06 11:31:33 | Valid | Epoch[217/600] Iteration[006/008] Valid loss: 0.0469
2023-02-06 11:31:33 | Valid | Epoch[217/600] Iteration[007/008] Valid loss: 0.0455
2023-02-06 11:31:33 | Valid | Epoch[217/600] Iteration[008/008] Valid loss: 0.0465
2023-02-06 11:31:33 | Valid | Epoch[217/600] MIou: 0.8592861061350656
2023-02-06 11:31:33 | Valid | Epoch[217/600] Pixel Accuracy: 0.9767964680989584
2023-02-06 11:31:33 | Valid | Epoch[217/600] Mean Pixel Accuracy: 0.8721731317877504
2023-02-06 11:31:33 | Stage | Epoch[217/600] Train loss:0.0250
2023-02-06 11:31:33 | Stage | Epoch[217/600] Valid loss:0.0465
2023-02-06 11:31:33 | Stage | Epoch[217/600] LR:0.01

2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[006/030] Train loss: 0.0248
2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 11:31:33 | Train | Epoch[218/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[013/030] Train loss: 0.0253
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[027/030] Train loss: 0.0256
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[028/030] Train loss: 0.0257
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[029/030] Train loss: 0.0257
2023-02-06 11:31:34 | Train | Epoch[218/600] Iteration[030/030] Train loss: 0.0257
2023-02-06 11:31:35 | Valid | Epoch[218/600] Iteration[001/008] Valid loss: 0.0610
2023-02-06 11:31:35 | Valid | Epoch[218/600] Iteration[002/008] Valid loss: 0.0441
2023-02-06 11:31:35 | Valid | Epoch[218/600] Iteration[003/008] Valid loss: 0.0395
2023-02-06 11:31:35 | Valid | Epoch[218/600] Iteration[004/008] Valid loss: 0.0391
2023-02-06 11:31:35 | Valid | Epoch[218/600] Iteration[005/008] Valid loss: 0.0400
2023-02-06 11:31:35 | Valid | Epoch[218/600] Iteration[006/008] Valid loss: 0.0394
2023-02-06 11:31:35 | Valid | Epoch[218/600] Iteration[007/008] Valid loss: 0.0400
2023-02-06 11:31:35 | Valid | Epoch[218/600] Iteration[008/008] Valid loss: 0.0390
2023-02-06 11:31:35 | Valid | Epoch[218/600] MIou: 0.9334854417667753
2023-02-06 11:31:35 | Valid | Epoch[218/600] Pixel Accuracy: 0.9887771606445312
2023-02-06 11:31:35 | Valid | Epoch[218/600] Mean Pixel Accuracy: 0.9507352639801059
2023-02-06 11:31:35 | Stage | Epoch[218/600] Train loss:0.0257
2023-02-06 11:31:35 | Stage | Epoch[218/600] Valid loss:0.0390
2023-02-06 11:31:35 | Stage | Epoch[218/600] LR:0.01

2023-02-06 11:31:35 | Train | Epoch[219/600] Iteration[001/030] Train loss: 0.0243
2023-02-06 11:31:35 | Train | Epoch[219/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 11:31:35 | Train | Epoch[219/600] Iteration[003/030] Train loss: 0.0240
2023-02-06 11:31:35 | Train | Epoch[219/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 11:31:35 | Train | Epoch[219/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[006/030] Train loss: 0.0248
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 11:31:36 | Train | Epoch[219/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 11:31:37 | Train | Epoch[219/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 11:31:37 | Train | Epoch[219/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 11:31:37 | Train | Epoch[219/600] Iteration[029/030] Train loss: 0.0256
2023-02-06 11:31:37 | Train | Epoch[219/600] Iteration[030/030] Train loss: 0.0258
2023-02-06 11:31:37 | Valid | Epoch[219/600] Iteration[001/008] Valid loss: 0.0999
2023-02-06 11:31:37 | Valid | Epoch[219/600] Iteration[002/008] Valid loss: 0.0691
2023-02-06 11:31:37 | Valid | Epoch[219/600] Iteration[003/008] Valid loss: 0.0604
2023-02-06 11:31:37 | Valid | Epoch[219/600] Iteration[004/008] Valid loss: 0.0622
2023-02-06 11:31:37 | Valid | Epoch[219/600] Iteration[005/008] Valid loss: 0.0633
2023-02-06 11:31:37 | Valid | Epoch[219/600] Iteration[006/008] Valid loss: 0.0634
2023-02-06 11:31:37 | Valid | Epoch[219/600] Iteration[007/008] Valid loss: 0.0657
2023-02-06 11:31:37 | Valid | Epoch[219/600] Iteration[008/008] Valid loss: 0.0640
2023-02-06 11:31:37 | Valid | Epoch[219/600] MIou: 0.9399846225165722
2023-02-06 11:31:37 | Valid | Epoch[219/600] Pixel Accuracy: 0.9896049499511719
2023-02-06 11:31:37 | Valid | Epoch[219/600] Mean Pixel Accuracy: 0.9690894033659969
2023-02-06 11:31:37 | Stage | Epoch[219/600] Train loss:0.0258
2023-02-06 11:31:37 | Stage | Epoch[219/600] Valid loss:0.0640
2023-02-06 11:31:37 | Stage | Epoch[219/600] LR:0.01

2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[001/030] Train loss: 0.0242
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[002/030] Train loss: 0.0250
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[004/030] Train loss: 0.0265
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[005/030] Train loss: 0.0274
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[016/030] Train loss: 0.0261
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[017/030] Train loss: 0.0262
2023-02-06 11:31:38 | Train | Epoch[220/600] Iteration[018/030] Train loss: 0.0262
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[019/030] Train loss: 0.0262
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[021/030] Train loss: 0.0263
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[023/030] Train loss: 0.0264
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[024/030] Train loss: 0.0265
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[028/030] Train loss: 0.0261
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 11:31:39 | Train | Epoch[220/600] Iteration[030/030] Train loss: 0.0261
2023-02-06 11:31:39 | Valid | Epoch[220/600] Iteration[001/008] Valid loss: 0.0495
2023-02-06 11:31:39 | Valid | Epoch[220/600] Iteration[002/008] Valid loss: 0.0391
2023-02-06 11:31:39 | Valid | Epoch[220/600] Iteration[003/008] Valid loss: 0.0366
2023-02-06 11:31:39 | Valid | Epoch[220/600] Iteration[004/008] Valid loss: 0.0357
2023-02-06 11:31:39 | Valid | Epoch[220/600] Iteration[005/008] Valid loss: 0.0369
2023-02-06 11:31:39 | Valid | Epoch[220/600] Iteration[006/008] Valid loss: 0.0362
2023-02-06 11:31:40 | Valid | Epoch[220/600] Iteration[007/008] Valid loss: 0.0358
2023-02-06 11:31:40 | Valid | Epoch[220/600] Iteration[008/008] Valid loss: 0.0353
2023-02-06 11:31:40 | Valid | Epoch[220/600] MIou: 0.9194920020315949
2023-02-06 11:31:40 | Valid | Epoch[220/600] Pixel Accuracy: 0.9865709940592448
2023-02-06 11:31:40 | Valid | Epoch[220/600] Mean Pixel Accuracy: 0.9325428780247537
2023-02-06 11:31:40 | Stage | Epoch[220/600] Train loss:0.0261
2023-02-06 11:31:40 | Stage | Epoch[220/600] Valid loss:0.0353
2023-02-06 11:31:40 | Stage | Epoch[220/600] LR:0.01

2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[002/030] Train loss: 0.0250
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[003/030] Train loss: 0.0236
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[004/030] Train loss: 0.0236
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[005/030] Train loss: 0.0235
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[009/030] Train loss: 0.0246
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[010/030] Train loss: 0.0248
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 11:31:40 | Train | Epoch[221/600] Iteration[012/030] Train loss: 0.0247
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 11:31:41 | Train | Epoch[221/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:31:42 | Valid | Epoch[221/600] Iteration[001/008] Valid loss: 0.2143
2023-02-06 11:31:42 | Valid | Epoch[221/600] Iteration[002/008] Valid loss: 0.1568
2023-02-06 11:31:42 | Valid | Epoch[221/600] Iteration[003/008] Valid loss: 0.1404
2023-02-06 11:31:42 | Valid | Epoch[221/600] Iteration[004/008] Valid loss: 0.1460
2023-02-06 11:31:42 | Valid | Epoch[221/600] Iteration[005/008] Valid loss: 0.1529
2023-02-06 11:31:42 | Valid | Epoch[221/600] Iteration[006/008] Valid loss: 0.1507
2023-02-06 11:31:42 | Valid | Epoch[221/600] Iteration[007/008] Valid loss: 0.1578
2023-02-06 11:31:42 | Valid | Epoch[221/600] Iteration[008/008] Valid loss: 0.1561
2023-02-06 11:31:42 | Valid | Epoch[221/600] MIou: 0.9270246390619981
2023-02-06 11:31:42 | Valid | Epoch[221/600] Pixel Accuracy: 0.986639658610026
2023-02-06 11:31:42 | Valid | Epoch[221/600] Mean Pixel Accuracy: 0.983082474584051
2023-02-06 11:31:42 | Stage | Epoch[221/600] Train loss:0.0252
2023-02-06 11:31:42 | Stage | Epoch[221/600] Valid loss:0.1561
2023-02-06 11:31:42 | Stage | Epoch[221/600] LR:0.01

2023-02-06 11:31:42 | Train | Epoch[222/600] Iteration[001/030] Train loss: 0.0238
2023-02-06 11:31:42 | Train | Epoch[222/600] Iteration[002/030] Train loss: 0.0234
2023-02-06 11:31:42 | Train | Epoch[222/600] Iteration[003/030] Train loss: 0.0229
2023-02-06 11:31:42 | Train | Epoch[222/600] Iteration[004/030] Train loss: 0.0234
2023-02-06 11:31:42 | Train | Epoch[222/600] Iteration[005/030] Train loss: 0.0239
2023-02-06 11:31:42 | Train | Epoch[222/600] Iteration[006/030] Train loss: 0.0245
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[010/030] Train loss: 0.0244
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[012/030] Train loss: 0.0245
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[013/030] Train loss: 0.0244
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[014/030] Train loss: 0.0243
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[015/030] Train loss: 0.0242
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[017/030] Train loss: 0.0245
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[018/030] Train loss: 0.0244
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[024/030] Train loss: 0.0248
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[026/030] Train loss: 0.0247
2023-02-06 11:31:43 | Train | Epoch[222/600] Iteration[027/030] Train loss: 0.0246
2023-02-06 11:31:44 | Train | Epoch[222/600] Iteration[028/030] Train loss: 0.0246
2023-02-06 11:31:44 | Train | Epoch[222/600] Iteration[029/030] Train loss: 0.0246
2023-02-06 11:31:44 | Train | Epoch[222/600] Iteration[030/030] Train loss: 0.0246
2023-02-06 11:31:44 | Valid | Epoch[222/600] Iteration[001/008] Valid loss: 0.1786
2023-02-06 11:31:44 | Valid | Epoch[222/600] Iteration[002/008] Valid loss: 0.1209
2023-02-06 11:31:44 | Valid | Epoch[222/600] Iteration[003/008] Valid loss: 0.1076
2023-02-06 11:31:44 | Valid | Epoch[222/600] Iteration[004/008] Valid loss: 0.1088
2023-02-06 11:31:44 | Valid | Epoch[222/600] Iteration[005/008] Valid loss: 0.1164
2023-02-06 11:31:44 | Valid | Epoch[222/600] Iteration[006/008] Valid loss: 0.1124
2023-02-06 11:31:44 | Valid | Epoch[222/600] Iteration[007/008] Valid loss: 0.1194
2023-02-06 11:31:44 | Valid | Epoch[222/600] Iteration[008/008] Valid loss: 0.1191
2023-02-06 11:31:44 | Valid | Epoch[222/600] MIou: 0.9349115951213194
2023-02-06 11:31:44 | Valid | Epoch[222/600] Pixel Accuracy: 0.9884071350097656
2023-02-06 11:31:44 | Valid | Epoch[222/600] Mean Pixel Accuracy: 0.9775232693369509
2023-02-06 11:31:44 | Stage | Epoch[222/600] Train loss:0.0246
2023-02-06 11:31:44 | Stage | Epoch[222/600] Valid loss:0.1191
2023-02-06 11:31:44 | Stage | Epoch[222/600] LR:0.01

2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[001/030] Train loss: 0.0227
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[002/030] Train loss: 0.0225
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[003/030] Train loss: 0.0231
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[004/030] Train loss: 0.0231
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[012/030] Train loss: 0.0247
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[013/030] Train loss: 0.0245
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[015/030] Train loss: 0.0245
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 11:31:45 | Train | Epoch[223/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:31:46 | Train | Epoch[223/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 11:31:46 | Train | Epoch[223/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:31:46 | Train | Epoch[223/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:31:46 | Train | Epoch[223/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 11:31:46 | Train | Epoch[223/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 11:31:46 | Train | Epoch[223/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 11:31:46 | Train | Epoch[223/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:31:46 | Train | Epoch[223/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 11:31:46 | Train | Epoch[223/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:31:46 | Train | Epoch[223/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:31:46 | Valid | Epoch[223/600] Iteration[001/008] Valid loss: 0.0526
2023-02-06 11:31:46 | Valid | Epoch[223/600] Iteration[002/008] Valid loss: 0.0518
2023-02-06 11:31:46 | Valid | Epoch[223/600] Iteration[003/008] Valid loss: 0.0516
2023-02-06 11:31:46 | Valid | Epoch[223/600] Iteration[004/008] Valid loss: 0.0496
2023-02-06 11:31:46 | Valid | Epoch[223/600] Iteration[005/008] Valid loss: 0.0505
2023-02-06 11:31:46 | Valid | Epoch[223/600] Iteration[006/008] Valid loss: 0.0496
2023-02-06 11:31:47 | Valid | Epoch[223/600] Iteration[007/008] Valid loss: 0.0481
2023-02-06 11:31:47 | Valid | Epoch[223/600] Iteration[008/008] Valid loss: 0.0493
2023-02-06 11:31:47 | Valid | Epoch[223/600] MIou: 0.8328133447647967
2023-02-06 11:31:47 | Valid | Epoch[223/600] Pixel Accuracy: 0.972436269124349
2023-02-06 11:31:47 | Valid | Epoch[223/600] Mean Pixel Accuracy: 0.847737101497327
2023-02-06 11:31:47 | Stage | Epoch[223/600] Train loss:0.0251
2023-02-06 11:31:47 | Stage | Epoch[223/600] Valid loss:0.0493
2023-02-06 11:31:47 | Stage | Epoch[223/600] LR:0.01

2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[001/030] Train loss: 0.0241
2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[002/030] Train loss: 0.0261
2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[004/030] Train loss: 0.0254
2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[007/030] Train loss: 0.0248
2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 11:31:47 | Train | Epoch[224/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[012/030] Train loss: 0.0247
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[013/030] Train loss: 0.0244
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[022/030] Train loss: 0.0247
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:31:48 | Train | Epoch[224/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:31:49 | Valid | Epoch[224/600] Iteration[001/008] Valid loss: 0.0434
2023-02-06 11:31:49 | Valid | Epoch[224/600] Iteration[002/008] Valid loss: 0.0359
2023-02-06 11:31:49 | Valid | Epoch[224/600] Iteration[003/008] Valid loss: 0.0342
2023-02-06 11:31:49 | Valid | Epoch[224/600] Iteration[004/008] Valid loss: 0.0328
2023-02-06 11:31:49 | Valid | Epoch[224/600] Iteration[005/008] Valid loss: 0.0336
2023-02-06 11:31:49 | Valid | Epoch[224/600] Iteration[006/008] Valid loss: 0.0332
2023-02-06 11:31:49 | Valid | Epoch[224/600] Iteration[007/008] Valid loss: 0.0327
2023-02-06 11:31:49 | Valid | Epoch[224/600] Iteration[008/008] Valid loss: 0.0327
2023-02-06 11:31:49 | Valid | Epoch[224/600] MIou: 0.9135966088926435
2023-02-06 11:31:49 | Valid | Epoch[224/600] Pixel Accuracy: 0.9856592814127604
2023-02-06 11:31:49 | Valid | Epoch[224/600] Mean Pixel Accuracy: 0.9249277528340883
2023-02-06 11:31:49 | Stage | Epoch[224/600] Train loss:0.0251
2023-02-06 11:31:49 | Stage | Epoch[224/600] Valid loss:0.0327
2023-02-06 11:31:49 | Stage | Epoch[224/600] LR:0.01

2023-02-06 11:31:49 | Train | Epoch[225/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 11:31:49 | Train | Epoch[225/600] Iteration[002/030] Train loss: 0.0270
2023-02-06 11:31:49 | Train | Epoch[225/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 11:31:49 | Train | Epoch[225/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 11:31:49 | Train | Epoch[225/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[013/030] Train loss: 0.0245
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[014/030] Train loss: 0.0245
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[015/030] Train loss: 0.0245
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[017/030] Train loss: 0.0245
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[019/030] Train loss: 0.0244
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[020/030] Train loss: 0.0246
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[025/030] Train loss: 0.0246
2023-02-06 11:31:50 | Train | Epoch[225/600] Iteration[026/030] Train loss: 0.0246
2023-02-06 11:31:51 | Train | Epoch[225/600] Iteration[027/030] Train loss: 0.0245
2023-02-06 11:31:51 | Train | Epoch[225/600] Iteration[028/030] Train loss: 0.0246
2023-02-06 11:31:51 | Train | Epoch[225/600] Iteration[029/030] Train loss: 0.0246
2023-02-06 11:31:51 | Train | Epoch[225/600] Iteration[030/030] Train loss: 0.0246
2023-02-06 11:31:51 | Valid | Epoch[225/600] Iteration[001/008] Valid loss: 0.5008
2023-02-06 11:31:51 | Valid | Epoch[225/600] Iteration[002/008] Valid loss: 0.4231
2023-02-06 11:31:51 | Valid | Epoch[225/600] Iteration[003/008] Valid loss: 0.4201
2023-02-06 11:31:51 | Valid | Epoch[225/600] Iteration[004/008] Valid loss: 0.4343
2023-02-06 11:31:51 | Valid | Epoch[225/600] Iteration[005/008] Valid loss: 0.4545
2023-02-06 11:31:51 | Valid | Epoch[225/600] Iteration[006/008] Valid loss: 0.4434
2023-02-06 11:31:51 | Valid | Epoch[225/600] Iteration[007/008] Valid loss: 0.4730
2023-02-06 11:31:51 | Valid | Epoch[225/600] Iteration[008/008] Valid loss: 0.4742
2023-02-06 11:31:51 | Valid | Epoch[225/600] MIou: 0.8953966220773495
2023-02-06 11:31:51 | Valid | Epoch[225/600] Pixel Accuracy: 0.979485829671224
2023-02-06 11:31:51 | Valid | Epoch[225/600] Mean Pixel Accuracy: 0.9840262476886497
2023-02-06 11:31:51 | Stage | Epoch[225/600] Train loss:0.0246
2023-02-06 11:31:51 | Stage | Epoch[225/600] Valid loss:0.4742
2023-02-06 11:31:51 | Stage | Epoch[225/600] LR:0.01

2023-02-06 11:31:51 | Train | Epoch[226/600] Iteration[001/030] Train loss: 0.0223
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[002/030] Train loss: 0.0245
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[003/030] Train loss: 0.0244
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[004/030] Train loss: 0.0263
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[005/030] Train loss: 0.0260
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[009/030] Train loss: 0.0247
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[010/030] Train loss: 0.0244
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[011/030] Train loss: 0.0241
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[012/030] Train loss: 0.0242
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[014/030] Train loss: 0.0240
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[015/030] Train loss: 0.0244
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 11:31:52 | Train | Epoch[226/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 11:31:53 | Train | Epoch[226/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 11:31:53 | Train | Epoch[226/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 11:31:53 | Train | Epoch[226/600] Iteration[025/030] Train loss: 0.0247
2023-02-06 11:31:53 | Train | Epoch[226/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 11:31:53 | Train | Epoch[226/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 11:31:53 | Train | Epoch[226/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 11:31:53 | Train | Epoch[226/600] Iteration[029/030] Train loss: 0.0248
2023-02-06 11:31:53 | Train | Epoch[226/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:31:53 | Valid | Epoch[226/600] Iteration[001/008] Valid loss: 0.1355
2023-02-06 11:31:53 | Valid | Epoch[226/600] Iteration[002/008] Valid loss: 0.0877
2023-02-06 11:31:53 | Valid | Epoch[226/600] Iteration[003/008] Valid loss: 0.0755
2023-02-06 11:31:53 | Valid | Epoch[226/600] Iteration[004/008] Valid loss: 0.0785
2023-02-06 11:31:53 | Valid | Epoch[226/600] Iteration[005/008] Valid loss: 0.0829
2023-02-06 11:31:53 | Valid | Epoch[226/600] Iteration[006/008] Valid loss: 0.0797
2023-02-06 11:31:53 | Valid | Epoch[226/600] Iteration[007/008] Valid loss: 0.0848
2023-02-06 11:31:53 | Valid | Epoch[226/600] Iteration[008/008] Valid loss: 0.0819
2023-02-06 11:31:53 | Valid | Epoch[226/600] MIou: 0.9404326422488323
2023-02-06 11:31:53 | Valid | Epoch[226/600] Pixel Accuracy: 0.9896494547526041
2023-02-06 11:31:53 | Valid | Epoch[226/600] Mean Pixel Accuracy: 0.9710477089141324
2023-02-06 11:31:53 | Stage | Epoch[226/600] Train loss:0.0252
2023-02-06 11:31:53 | Stage | Epoch[226/600] Valid loss:0.0819
2023-02-06 11:31:53 | Stage | Epoch[226/600] LR:0.01

2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[001/030] Train loss: 0.0251
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[002/030] Train loss: 0.0233
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[003/030] Train loss: 0.0226
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[004/030] Train loss: 0.0231
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[005/030] Train loss: 0.0231
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[006/030] Train loss: 0.0227
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[008/030] Train loss: 0.0235
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[010/030] Train loss: 0.0236
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[011/030] Train loss: 0.0238
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[012/030] Train loss: 0.0238
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[013/030] Train loss: 0.0237
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[014/030] Train loss: 0.0238
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[015/030] Train loss: 0.0239
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[016/030] Train loss: 0.0241
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[017/030] Train loss: 0.0239
2023-02-06 11:31:54 | Train | Epoch[227/600] Iteration[018/030] Train loss: 0.0240
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[019/030] Train loss: 0.0243
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[020/030] Train loss: 0.0244
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[021/030] Train loss: 0.0244
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[023/030] Train loss: 0.0244
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[024/030] Train loss: 0.0245
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[025/030] Train loss: 0.0246
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[026/030] Train loss: 0.0245
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[027/030] Train loss: 0.0246
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[028/030] Train loss: 0.0247
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[029/030] Train loss: 0.0247
2023-02-06 11:31:55 | Train | Epoch[227/600] Iteration[030/030] Train loss: 0.0247
2023-02-06 11:31:55 | Valid | Epoch[227/600] Iteration[001/008] Valid loss: 0.0534
2023-02-06 11:31:55 | Valid | Epoch[227/600] Iteration[002/008] Valid loss: 0.0470
2023-02-06 11:31:55 | Valid | Epoch[227/600] Iteration[003/008] Valid loss: 0.0452
2023-02-06 11:31:55 | Valid | Epoch[227/600] Iteration[004/008] Valid loss: 0.0437
2023-02-06 11:31:55 | Valid | Epoch[227/600] Iteration[005/008] Valid loss: 0.0444
2023-02-06 11:31:56 | Valid | Epoch[227/600] Iteration[006/008] Valid loss: 0.0434
2023-02-06 11:31:56 | Valid | Epoch[227/600] Iteration[007/008] Valid loss: 0.0427
2023-02-06 11:31:56 | Valid | Epoch[227/600] Iteration[008/008] Valid loss: 0.0430
2023-02-06 11:31:56 | Valid | Epoch[227/600] MIou: 0.8823740919875622
2023-02-06 11:31:56 | Valid | Epoch[227/600] Pixel Accuracy: 0.9805323282877604
2023-02-06 11:31:56 | Valid | Epoch[227/600] Mean Pixel Accuracy: 0.8948710951214313
2023-02-06 11:31:56 | Stage | Epoch[227/600] Train loss:0.0247
2023-02-06 11:31:56 | Stage | Epoch[227/600] Valid loss:0.0430
2023-02-06 11:31:56 | Stage | Epoch[227/600] LR:0.01

2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[002/030] Train loss: 0.0228
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 11:31:56 | Train | Epoch[228/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[020/030] Train loss: 0.0256
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 11:31:57 | Train | Epoch[228/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 11:31:58 | Valid | Epoch[228/600] Iteration[001/008] Valid loss: 0.0857
2023-02-06 11:31:58 | Valid | Epoch[228/600] Iteration[002/008] Valid loss: 0.0620
2023-02-06 11:31:58 | Valid | Epoch[228/600] Iteration[003/008] Valid loss: 0.0541
2023-02-06 11:31:58 | Valid | Epoch[228/600] Iteration[004/008] Valid loss: 0.0601
2023-02-06 11:31:58 | Valid | Epoch[228/600] Iteration[005/008] Valid loss: 0.0639
2023-02-06 11:31:58 | Valid | Epoch[228/600] Iteration[006/008] Valid loss: 0.0616
2023-02-06 11:31:58 | Valid | Epoch[228/600] Iteration[007/008] Valid loss: 0.0659
2023-02-06 11:31:58 | Valid | Epoch[228/600] Iteration[008/008] Valid loss: 0.0634
2023-02-06 11:31:58 | Valid | Epoch[228/600] MIou: 0.9371471069702546
2023-02-06 11:31:58 | Valid | Epoch[228/600] Pixel Accuracy: 0.9892463684082031
2023-02-06 11:31:58 | Valid | Epoch[228/600] Mean Pixel Accuracy: 0.960592634447536
2023-02-06 11:31:58 | Stage | Epoch[228/600] Train loss:0.0253
2023-02-06 11:31:58 | Stage | Epoch[228/600] Valid loss:0.0634
2023-02-06 11:31:58 | Stage | Epoch[228/600] LR:0.01

2023-02-06 11:31:58 | Train | Epoch[229/600] Iteration[001/030] Train loss: 0.0250
2023-02-06 11:31:58 | Train | Epoch[229/600] Iteration[002/030] Train loss: 0.0247
2023-02-06 11:31:58 | Train | Epoch[229/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 11:31:58 | Train | Epoch[229/600] Iteration[004/030] Train loss: 0.0250
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[007/030] Train loss: 0.0260
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[008/030] Train loss: 0.0264
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[009/030] Train loss: 0.0280
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[010/030] Train loss: 0.0274
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[012/030] Train loss: 0.0271
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[013/030] Train loss: 0.0273
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[014/030] Train loss: 0.0273
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[015/030] Train loss: 0.0275
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[016/030] Train loss: 0.0277
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[017/030] Train loss: 0.0276
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[018/030] Train loss: 0.0276
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[020/030] Train loss: 0.0280
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[021/030] Train loss: 0.0281
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[022/030] Train loss: 0.0281
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[023/030] Train loss: 0.0281
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[024/030] Train loss: 0.0283
2023-02-06 11:31:59 | Train | Epoch[229/600] Iteration[025/030] Train loss: 0.0284
2023-02-06 11:32:00 | Train | Epoch[229/600] Iteration[026/030] Train loss: 0.0284
2023-02-06 11:32:00 | Train | Epoch[229/600] Iteration[027/030] Train loss: 0.0283
2023-02-06 11:32:00 | Train | Epoch[229/600] Iteration[028/030] Train loss: 0.0281
2023-02-06 11:32:00 | Train | Epoch[229/600] Iteration[029/030] Train loss: 0.0282
2023-02-06 11:32:00 | Train | Epoch[229/600] Iteration[030/030] Train loss: 0.0282
2023-02-06 11:32:00 | Valid | Epoch[229/600] Iteration[001/008] Valid loss: 0.1171
2023-02-06 11:32:00 | Valid | Epoch[229/600] Iteration[002/008] Valid loss: 0.1077
2023-02-06 11:32:00 | Valid | Epoch[229/600] Iteration[003/008] Valid loss: 0.1091
2023-02-06 11:32:00 | Valid | Epoch[229/600] Iteration[004/008] Valid loss: 0.1069
2023-02-06 11:32:00 | Valid | Epoch[229/600] Iteration[005/008] Valid loss: 0.1074
2023-02-06 11:32:00 | Valid | Epoch[229/600] Iteration[006/008] Valid loss: 0.1060
2023-02-06 11:32:00 | Valid | Epoch[229/600] Iteration[007/008] Valid loss: 0.1034
2023-02-06 11:32:00 | Valid | Epoch[229/600] Iteration[008/008] Valid loss: 0.1056
2023-02-06 11:32:00 | Valid | Epoch[229/600] MIou: 0.738712331189934
2023-02-06 11:32:00 | Valid | Epoch[229/600] Pixel Accuracy: 0.9568875630696615
2023-02-06 11:32:00 | Valid | Epoch[229/600] Mean Pixel Accuracy: 0.7613425602880803
2023-02-06 11:32:00 | Stage | Epoch[229/600] Train loss:0.0282
2023-02-06 11:32:00 | Stage | Epoch[229/600] Valid loss:0.1056
2023-02-06 11:32:00 | Stage | Epoch[229/600] LR:0.01

2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[001/030] Train loss: 0.0281
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[005/030] Train loss: 0.0274
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[006/030] Train loss: 0.0274
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[008/030] Train loss: 0.0267
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 11:32:01 | Train | Epoch[230/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[022/030] Train loss: 0.0256
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:32:02 | Train | Epoch[230/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:32:02 | Valid | Epoch[230/600] Iteration[001/008] Valid loss: 0.0775
2023-02-06 11:32:02 | Valid | Epoch[230/600] Iteration[002/008] Valid loss: 0.0782
2023-02-06 11:32:02 | Valid | Epoch[230/600] Iteration[003/008] Valid loss: 0.0801
2023-02-06 11:32:02 | Valid | Epoch[230/600] Iteration[004/008] Valid loss: 0.0782
2023-02-06 11:32:03 | Valid | Epoch[230/600] Iteration[005/008] Valid loss: 0.0799
2023-02-06 11:32:03 | Valid | Epoch[230/600] Iteration[006/008] Valid loss: 0.0790
2023-02-06 11:32:03 | Valid | Epoch[230/600] Iteration[007/008] Valid loss: 0.0770
2023-02-06 11:32:03 | Valid | Epoch[230/600] Iteration[008/008] Valid loss: 0.0789
2023-02-06 11:32:03 | Valid | Epoch[230/600] MIou: 0.7749730275212692
2023-02-06 11:32:03 | Valid | Epoch[230/600] Pixel Accuracy: 0.9628918965657552
2023-02-06 11:32:03 | Valid | Epoch[230/600] Mean Pixel Accuracy: 0.7945698235931802
2023-02-06 11:32:03 | Stage | Epoch[230/600] Train loss:0.0251
2023-02-06 11:32:03 | Stage | Epoch[230/600] Valid loss:0.0789
2023-02-06 11:32:03 | Stage | Epoch[230/600] LR:0.01

2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[001/030] Train loss: 0.0226
2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[003/030] Train loss: 0.0231
2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[004/030] Train loss: 0.0241
2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[007/030] Train loss: 0.0248
2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 11:32:03 | Train | Epoch[231/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:32:04 | Train | Epoch[231/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:32:05 | Valid | Epoch[231/600] Iteration[001/008] Valid loss: 0.0398
2023-02-06 11:32:05 | Valid | Epoch[231/600] Iteration[002/008] Valid loss: 0.0347
2023-02-06 11:32:05 | Valid | Epoch[231/600] Iteration[003/008] Valid loss: 0.0336
2023-02-06 11:32:05 | Valid | Epoch[231/600] Iteration[004/008] Valid loss: 0.0327
2023-02-06 11:32:05 | Valid | Epoch[231/600] Iteration[005/008] Valid loss: 0.0334
2023-02-06 11:32:05 | Valid | Epoch[231/600] Iteration[006/008] Valid loss: 0.0334
2023-02-06 11:32:05 | Valid | Epoch[231/600] Iteration[007/008] Valid loss: 0.0330
2023-02-06 11:32:05 | Valid | Epoch[231/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:32:05 | Valid | Epoch[231/600] MIou: 0.9069606435973455
2023-02-06 11:32:05 | Valid | Epoch[231/600] Pixel Accuracy: 0.9845377604166666
2023-02-06 11:32:05 | Valid | Epoch[231/600] Mean Pixel Accuracy: 0.9193213659829148
2023-02-06 11:32:05 | Stage | Epoch[231/600] Train loss:0.0251
2023-02-06 11:32:05 | Stage | Epoch[231/600] Valid loss:0.0331
2023-02-06 11:32:05 | Stage | Epoch[231/600] LR:0.01

2023-02-06 11:32:05 | Train | Epoch[232/600] Iteration[001/030] Train loss: 0.0227
2023-02-06 11:32:05 | Train | Epoch[232/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 11:32:05 | Train | Epoch[232/600] Iteration[003/030] Train loss: 0.0250
2023-02-06 11:32:05 | Train | Epoch[232/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 11:32:05 | Train | Epoch[232/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 11:32:05 | Train | Epoch[232/600] Iteration[006/030] Train loss: 0.0246
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[010/030] Train loss: 0.0245
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[014/030] Train loss: 0.0242
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[015/030] Train loss: 0.0242
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[016/030] Train loss: 0.0240
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[017/030] Train loss: 0.0241
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[018/030] Train loss: 0.0241
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[019/030] Train loss: 0.0242
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[020/030] Train loss: 0.0243
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[021/030] Train loss: 0.0242
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[022/030] Train loss: 0.0242
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[023/030] Train loss: 0.0241
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[024/030] Train loss: 0.0242
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[025/030] Train loss: 0.0241
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[026/030] Train loss: 0.0242
2023-02-06 11:32:06 | Train | Epoch[232/600] Iteration[027/030] Train loss: 0.0242
2023-02-06 11:32:07 | Train | Epoch[232/600] Iteration[028/030] Train loss: 0.0243
2023-02-06 11:32:07 | Train | Epoch[232/600] Iteration[029/030] Train loss: 0.0244
2023-02-06 11:32:07 | Train | Epoch[232/600] Iteration[030/030] Train loss: 0.0244
2023-02-06 11:32:07 | Valid | Epoch[232/600] Iteration[001/008] Valid loss: 0.0440
2023-02-06 11:32:07 | Valid | Epoch[232/600] Iteration[002/008] Valid loss: 0.0411
2023-02-06 11:32:07 | Valid | Epoch[232/600] Iteration[003/008] Valid loss: 0.0410
2023-02-06 11:32:07 | Valid | Epoch[232/600] Iteration[004/008] Valid loss: 0.0391
2023-02-06 11:32:07 | Valid | Epoch[232/600] Iteration[005/008] Valid loss: 0.0398
2023-02-06 11:32:07 | Valid | Epoch[232/600] Iteration[006/008] Valid loss: 0.0392
2023-02-06 11:32:07 | Valid | Epoch[232/600] Iteration[007/008] Valid loss: 0.0382
2023-02-06 11:32:07 | Valid | Epoch[232/600] Iteration[008/008] Valid loss: 0.0390
2023-02-06 11:32:07 | Valid | Epoch[232/600] MIou: 0.8700559665652291
2023-02-06 11:32:07 | Valid | Epoch[232/600] Pixel Accuracy: 0.9785550435384115
2023-02-06 11:32:07 | Valid | Epoch[232/600] Mean Pixel Accuracy: 0.8823968082583389
2023-02-06 11:32:07 | Stage | Epoch[232/600] Train loss:0.0244
2023-02-06 11:32:07 | Stage | Epoch[232/600] Valid loss:0.0390
2023-02-06 11:32:07 | Stage | Epoch[232/600] LR:0.01

2023-02-06 11:32:07 | Train | Epoch[233/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[002/030] Train loss: 0.0228
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[003/030] Train loss: 0.0228
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[009/030] Train loss: 0.0247
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 11:32:08 | Train | Epoch[233/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 11:32:09 | Train | Epoch[233/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 11:32:09 | Train | Epoch[233/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:32:09 | Train | Epoch[233/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:32:09 | Train | Epoch[233/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 11:32:09 | Train | Epoch[233/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:32:09 | Train | Epoch[233/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:32:09 | Train | Epoch[233/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:32:09 | Train | Epoch[233/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:32:09 | Train | Epoch[233/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:32:09 | Valid | Epoch[233/600] Iteration[001/008] Valid loss: 0.0831
2023-02-06 11:32:09 | Valid | Epoch[233/600] Iteration[002/008] Valid loss: 0.0817
2023-02-06 11:32:09 | Valid | Epoch[233/600] Iteration[003/008] Valid loss: 0.0829
2023-02-06 11:32:09 | Valid | Epoch[233/600] Iteration[004/008] Valid loss: 0.0812
2023-02-06 11:32:09 | Valid | Epoch[233/600] Iteration[005/008] Valid loss: 0.0829
2023-02-06 11:32:09 | Valid | Epoch[233/600] Iteration[006/008] Valid loss: 0.0814
2023-02-06 11:32:09 | Valid | Epoch[233/600] Iteration[007/008] Valid loss: 0.0790
2023-02-06 11:32:09 | Valid | Epoch[233/600] Iteration[008/008] Valid loss: 0.0810
2023-02-06 11:32:10 | Valid | Epoch[233/600] MIou: 0.7562453056937488
2023-02-06 11:32:10 | Valid | Epoch[233/600] Pixel Accuracy: 0.9597829182942709
2023-02-06 11:32:10 | Valid | Epoch[233/600] Mean Pixel Accuracy: 0.7774726721806384
2023-02-06 11:32:10 | Stage | Epoch[233/600] Train loss:0.0252
2023-02-06 11:32:10 | Stage | Epoch[233/600] Valid loss:0.0810
2023-02-06 11:32:10 | Stage | Epoch[233/600] LR:0.01

2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[001/030] Train loss: 0.0267
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[003/030] Train loss: 0.0261
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[007/030] Train loss: 0.0241
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[010/030] Train loss: 0.0243
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[013/030] Train loss: 0.0244
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[014/030] Train loss: 0.0244
2023-02-06 11:32:10 | Train | Epoch[234/600] Iteration[015/030] Train loss: 0.0242
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[017/030] Train loss: 0.0241
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[018/030] Train loss: 0.0243
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[019/030] Train loss: 0.0244
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[020/030] Train loss: 0.0245
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[021/030] Train loss: 0.0245
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[023/030] Train loss: 0.0245
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 11:32:11 | Train | Epoch[234/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 11:32:12 | Valid | Epoch[234/600] Iteration[001/008] Valid loss: 0.0504
2023-02-06 11:32:12 | Valid | Epoch[234/600] Iteration[002/008] Valid loss: 0.0409
2023-02-06 11:32:12 | Valid | Epoch[234/600] Iteration[003/008] Valid loss: 0.0389
2023-02-06 11:32:12 | Valid | Epoch[234/600] Iteration[004/008] Valid loss: 0.0368
2023-02-06 11:32:12 | Valid | Epoch[234/600] Iteration[005/008] Valid loss: 0.0374
2023-02-06 11:32:12 | Valid | Epoch[234/600] Iteration[006/008] Valid loss: 0.0365
2023-02-06 11:32:12 | Valid | Epoch[234/600] Iteration[007/008] Valid loss: 0.0359
2023-02-06 11:32:12 | Valid | Epoch[234/600] Iteration[008/008] Valid loss: 0.0362
2023-02-06 11:32:12 | Valid | Epoch[234/600] MIou: 0.8954332365583554
2023-02-06 11:32:12 | Valid | Epoch[234/600] Pixel Accuracy: 0.9827003479003906
2023-02-06 11:32:12 | Valid | Epoch[234/600] Mean Pixel Accuracy: 0.9067844684912599
2023-02-06 11:32:12 | Stage | Epoch[234/600] Train loss:0.0249
2023-02-06 11:32:12 | Stage | Epoch[234/600] Valid loss:0.0362
2023-02-06 11:32:12 | Stage | Epoch[234/600] LR:0.01

2023-02-06 11:32:12 | Train | Epoch[235/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 11:32:12 | Train | Epoch[235/600] Iteration[002/030] Train loss: 0.0246
2023-02-06 11:32:12 | Train | Epoch[235/600] Iteration[003/030] Train loss: 0.0245
2023-02-06 11:32:12 | Train | Epoch[235/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 11:32:12 | Train | Epoch[235/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 11:32:12 | Train | Epoch[235/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 11:32:12 | Train | Epoch[235/600] Iteration[007/030] Train loss: 0.0241
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[008/030] Train loss: 0.0239
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[009/030] Train loss: 0.0238
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[010/030] Train loss: 0.0237
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[011/030] Train loss: 0.0239
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[012/030] Train loss: 0.0240
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[014/030] Train loss: 0.0241
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[015/030] Train loss: 0.0240
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[016/030] Train loss: 0.0240
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[018/030] Train loss: 0.0242
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[019/030] Train loss: 0.0241
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[020/030] Train loss: 0.0242
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[021/030] Train loss: 0.0240
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[022/030] Train loss: 0.0244
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[023/030] Train loss: 0.0245
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[024/030] Train loss: 0.0244
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[025/030] Train loss: 0.0245
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[026/030] Train loss: 0.0245
2023-02-06 11:32:13 | Train | Epoch[235/600] Iteration[027/030] Train loss: 0.0246
2023-02-06 11:32:14 | Train | Epoch[235/600] Iteration[028/030] Train loss: 0.0246
2023-02-06 11:32:14 | Train | Epoch[235/600] Iteration[029/030] Train loss: 0.0246
2023-02-06 11:32:14 | Train | Epoch[235/600] Iteration[030/030] Train loss: 0.0245
2023-02-06 11:32:14 | Valid | Epoch[235/600] Iteration[001/008] Valid loss: 0.0422
2023-02-06 11:32:14 | Valid | Epoch[235/600] Iteration[002/008] Valid loss: 0.0352
2023-02-06 11:32:14 | Valid | Epoch[235/600] Iteration[003/008] Valid loss: 0.0336
2023-02-06 11:32:14 | Valid | Epoch[235/600] Iteration[004/008] Valid loss: 0.0322
2023-02-06 11:32:14 | Valid | Epoch[235/600] Iteration[005/008] Valid loss: 0.0331
2023-02-06 11:32:14 | Valid | Epoch[235/600] Iteration[006/008] Valid loss: 0.0328
2023-02-06 11:32:14 | Valid | Epoch[235/600] Iteration[007/008] Valid loss: 0.0325
2023-02-06 11:32:14 | Valid | Epoch[235/600] Iteration[008/008] Valid loss: 0.0325
2023-02-06 11:32:14 | Valid | Epoch[235/600] MIou: 0.9116613264112696
2023-02-06 11:32:14 | Valid | Epoch[235/600] Pixel Accuracy: 0.9853350321451823
2023-02-06 11:32:14 | Valid | Epoch[235/600] Mean Pixel Accuracy: 0.9232214779733194
2023-02-06 11:32:14 | Stage | Epoch[235/600] Train loss:0.0245
2023-02-06 11:32:14 | Stage | Epoch[235/600] Valid loss:0.0325
2023-02-06 11:32:14 | Stage | Epoch[235/600] LR:0.01

2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[001/030] Train loss: 0.0227
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[003/030] Train loss: 0.0221
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[004/030] Train loss: 0.0219
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[005/030] Train loss: 0.0219
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[006/030] Train loss: 0.0221
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[007/030] Train loss: 0.0219
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[008/030] Train loss: 0.0223
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[009/030] Train loss: 0.0223
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[011/030] Train loss: 0.0224
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[013/030] Train loss: 0.0229
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[014/030] Train loss: 0.0229
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[015/030] Train loss: 0.0230
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[016/030] Train loss: 0.0233
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[017/030] Train loss: 0.0234
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[018/030] Train loss: 0.0235
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[019/030] Train loss: 0.0233
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[020/030] Train loss: 0.0235
2023-02-06 11:32:15 | Train | Epoch[236/600] Iteration[021/030] Train loss: 0.0238
2023-02-06 11:32:16 | Train | Epoch[236/600] Iteration[022/030] Train loss: 0.0238
2023-02-06 11:32:16 | Train | Epoch[236/600] Iteration[023/030] Train loss: 0.0238
2023-02-06 11:32:16 | Train | Epoch[236/600] Iteration[024/030] Train loss: 0.0239
2023-02-06 11:32:16 | Train | Epoch[236/600] Iteration[025/030] Train loss: 0.0239
2023-02-06 11:32:16 | Train | Epoch[236/600] Iteration[026/030] Train loss: 0.0239
2023-02-06 11:32:16 | Train | Epoch[236/600] Iteration[027/030] Train loss: 0.0240
2023-02-06 11:32:16 | Train | Epoch[236/600] Iteration[028/030] Train loss: 0.0240
2023-02-06 11:32:16 | Train | Epoch[236/600] Iteration[029/030] Train loss: 0.0241
2023-02-06 11:32:16 | Train | Epoch[236/600] Iteration[030/030] Train loss: 0.0241
2023-02-06 11:32:16 | Valid | Epoch[236/600] Iteration[001/008] Valid loss: 0.0470
2023-02-06 11:32:16 | Valid | Epoch[236/600] Iteration[002/008] Valid loss: 0.0446
2023-02-06 11:32:16 | Valid | Epoch[236/600] Iteration[003/008] Valid loss: 0.0443
2023-02-06 11:32:16 | Valid | Epoch[236/600] Iteration[004/008] Valid loss: 0.0424
2023-02-06 11:32:16 | Valid | Epoch[236/600] Iteration[005/008] Valid loss: 0.0431
2023-02-06 11:32:16 | Valid | Epoch[236/600] Iteration[006/008] Valid loss: 0.0424
2023-02-06 11:32:16 | Valid | Epoch[236/600] Iteration[007/008] Valid loss: 0.0411
2023-02-06 11:32:16 | Valid | Epoch[236/600] Iteration[008/008] Valid loss: 0.0421
2023-02-06 11:32:17 | Valid | Epoch[236/600] MIou: 0.8580130641749775
2023-02-06 11:32:17 | Valid | Epoch[236/600] Pixel Accuracy: 0.9765726725260416
2023-02-06 11:32:17 | Valid | Epoch[236/600] Mean Pixel Accuracy: 0.8712195224281426
2023-02-06 11:32:17 | Stage | Epoch[236/600] Train loss:0.0241
2023-02-06 11:32:17 | Stage | Epoch[236/600] Valid loss:0.0421
2023-02-06 11:32:17 | Stage | Epoch[236/600] LR:0.01

2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[001/030] Train loss: 0.0265
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[003/030] Train loss: 0.0229
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[005/030] Train loss: 0.0234
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[006/030] Train loss: 0.0235
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[007/030] Train loss: 0.0234
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[008/030] Train loss: 0.0237
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[009/030] Train loss: 0.0234
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[010/030] Train loss: 0.0237
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[011/030] Train loss: 0.0240
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[012/030] Train loss: 0.0241
2023-02-06 11:32:17 | Train | Epoch[237/600] Iteration[013/030] Train loss: 0.0240
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[014/030] Train loss: 0.0240
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[015/030] Train loss: 0.0242
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[018/030] Train loss: 0.0242
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[019/030] Train loss: 0.0241
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[020/030] Train loss: 0.0242
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[021/030] Train loss: 0.0244
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[022/030] Train loss: 0.0244
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[023/030] Train loss: 0.0243
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[024/030] Train loss: 0.0242
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[025/030] Train loss: 0.0241
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[026/030] Train loss: 0.0241
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[027/030] Train loss: 0.0243
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[028/030] Train loss: 0.0243
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[029/030] Train loss: 0.0243
2023-02-06 11:32:18 | Train | Epoch[237/600] Iteration[030/030] Train loss: 0.0243
2023-02-06 11:32:19 | Valid | Epoch[237/600] Iteration[001/008] Valid loss: 0.0475
2023-02-06 11:32:19 | Valid | Epoch[237/600] Iteration[002/008] Valid loss: 0.0456
2023-02-06 11:32:19 | Valid | Epoch[237/600] Iteration[003/008] Valid loss: 0.0454
2023-02-06 11:32:19 | Valid | Epoch[237/600] Iteration[004/008] Valid loss: 0.0437
2023-02-06 11:32:19 | Valid | Epoch[237/600] Iteration[005/008] Valid loss: 0.0447
2023-02-06 11:32:19 | Valid | Epoch[237/600] Iteration[006/008] Valid loss: 0.0438
2023-02-06 11:32:19 | Valid | Epoch[237/600] Iteration[007/008] Valid loss: 0.0425
2023-02-06 11:32:19 | Valid | Epoch[237/600] Iteration[008/008] Valid loss: 0.0436
2023-02-06 11:32:19 | Valid | Epoch[237/600] MIou: 0.8526408078805687
2023-02-06 11:32:19 | Valid | Epoch[237/600] Pixel Accuracy: 0.9756749471028646
2023-02-06 11:32:19 | Valid | Epoch[237/600] Mean Pixel Accuracy: 0.8664399355063352
2023-02-06 11:32:19 | Stage | Epoch[237/600] Train loss:0.0243
2023-02-06 11:32:19 | Stage | Epoch[237/600] Valid loss:0.0436
2023-02-06 11:32:19 | Stage | Epoch[237/600] LR:0.01

2023-02-06 11:32:19 | Train | Epoch[238/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 11:32:19 | Train | Epoch[238/600] Iteration[002/030] Train loss: 0.0239
2023-02-06 11:32:19 | Train | Epoch[238/600] Iteration[003/030] Train loss: 0.0240
2023-02-06 11:32:19 | Train | Epoch[238/600] Iteration[004/030] Train loss: 0.0232
2023-02-06 11:32:19 | Train | Epoch[238/600] Iteration[005/030] Train loss: 0.0232
2023-02-06 11:32:19 | Train | Epoch[238/600] Iteration[006/030] Train loss: 0.0235
2023-02-06 11:32:19 | Train | Epoch[238/600] Iteration[007/030] Train loss: 0.0237
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[008/030] Train loss: 0.0236
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[009/030] Train loss: 0.0235
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[010/030] Train loss: 0.0233
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[011/030] Train loss: 0.0237
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[012/030] Train loss: 0.0235
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[013/030] Train loss: 0.0233
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[014/030] Train loss: 0.0234
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[015/030] Train loss: 0.0235
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[016/030] Train loss: 0.0235
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[017/030] Train loss: 0.0238
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[018/030] Train loss: 0.0239
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[019/030] Train loss: 0.0241
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[020/030] Train loss: 0.0242
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[021/030] Train loss: 0.0240
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[022/030] Train loss: 0.0241
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[023/030] Train loss: 0.0240
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[024/030] Train loss: 0.0240
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[025/030] Train loss: 0.0240
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[026/030] Train loss: 0.0241
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[027/030] Train loss: 0.0241
2023-02-06 11:32:20 | Train | Epoch[238/600] Iteration[028/030] Train loss: 0.0242
2023-02-06 11:32:21 | Train | Epoch[238/600] Iteration[029/030] Train loss: 0.0243
2023-02-06 11:32:21 | Train | Epoch[238/600] Iteration[030/030] Train loss: 0.0244
2023-02-06 11:32:21 | Valid | Epoch[238/600] Iteration[001/008] Valid loss: 0.3943
2023-02-06 11:32:21 | Valid | Epoch[238/600] Iteration[002/008] Valid loss: 0.3075
2023-02-06 11:32:21 | Valid | Epoch[238/600] Iteration[003/008] Valid loss: 0.2941
2023-02-06 11:32:21 | Valid | Epoch[238/600] Iteration[004/008] Valid loss: 0.2966
2023-02-06 11:32:21 | Valid | Epoch[238/600] Iteration[005/008] Valid loss: 0.3132
2023-02-06 11:32:21 | Valid | Epoch[238/600] Iteration[006/008] Valid loss: 0.3054
2023-02-06 11:32:21 | Valid | Epoch[238/600] Iteration[007/008] Valid loss: 0.3290
2023-02-06 11:32:21 | Valid | Epoch[238/600] Iteration[008/008] Valid loss: 0.3289
2023-02-06 11:32:21 | Valid | Epoch[238/600] MIou: 0.9024311089842636
2023-02-06 11:32:21 | Valid | Epoch[238/600] Pixel Accuracy: 0.9811363220214844
2023-02-06 11:32:21 | Valid | Epoch[238/600] Mean Pixel Accuracy: 0.9844769147272794
2023-02-06 11:32:21 | Stage | Epoch[238/600] Train loss:0.0244
2023-02-06 11:32:21 | Stage | Epoch[238/600] Valid loss:0.3289
2023-02-06 11:32:21 | Stage | Epoch[238/600] LR:0.01

2023-02-06 11:32:21 | Train | Epoch[239/600] Iteration[001/030] Train loss: 0.0241
2023-02-06 11:32:21 | Train | Epoch[239/600] Iteration[002/030] Train loss: 0.0253
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[006/030] Train loss: 0.0260
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[014/030] Train loss: 0.0244
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[015/030] Train loss: 0.0241
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[016/030] Train loss: 0.0240
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[018/030] Train loss: 0.0243
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[019/030] Train loss: 0.0241
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[020/030] Train loss: 0.0242
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[021/030] Train loss: 0.0241
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[022/030] Train loss: 0.0241
2023-02-06 11:32:22 | Train | Epoch[239/600] Iteration[023/030] Train loss: 0.0240
2023-02-06 11:32:23 | Train | Epoch[239/600] Iteration[024/030] Train loss: 0.0240
2023-02-06 11:32:23 | Train | Epoch[239/600] Iteration[025/030] Train loss: 0.0239
2023-02-06 11:32:23 | Train | Epoch[239/600] Iteration[026/030] Train loss: 0.0239
2023-02-06 11:32:23 | Train | Epoch[239/600] Iteration[027/030] Train loss: 0.0239
2023-02-06 11:32:23 | Train | Epoch[239/600] Iteration[028/030] Train loss: 0.0241
2023-02-06 11:32:23 | Train | Epoch[239/600] Iteration[029/030] Train loss: 0.0241
2023-02-06 11:32:23 | Train | Epoch[239/600] Iteration[030/030] Train loss: 0.0241
2023-02-06 11:32:23 | Valid | Epoch[239/600] Iteration[001/008] Valid loss: 0.0598
2023-02-06 11:32:23 | Valid | Epoch[239/600] Iteration[002/008] Valid loss: 0.0585
2023-02-06 11:32:23 | Valid | Epoch[239/600] Iteration[003/008] Valid loss: 0.0591
2023-02-06 11:32:23 | Valid | Epoch[239/600] Iteration[004/008] Valid loss: 0.0574
2023-02-06 11:32:23 | Valid | Epoch[239/600] Iteration[005/008] Valid loss: 0.0587
2023-02-06 11:32:23 | Valid | Epoch[239/600] Iteration[006/008] Valid loss: 0.0578
2023-02-06 11:32:23 | Valid | Epoch[239/600] Iteration[007/008] Valid loss: 0.0559
2023-02-06 11:32:23 | Valid | Epoch[239/600] Iteration[008/008] Valid loss: 0.0577
2023-02-06 11:32:23 | Valid | Epoch[239/600] MIou: 0.8028041396362267
2023-02-06 11:32:23 | Valid | Epoch[239/600] Pixel Accuracy: 0.9674873352050781
2023-02-06 11:32:23 | Valid | Epoch[239/600] Mean Pixel Accuracy: 0.8201306056634557
2023-02-06 11:32:23 | Stage | Epoch[239/600] Train loss:0.0241
2023-02-06 11:32:23 | Stage | Epoch[239/600] Valid loss:0.0577
2023-02-06 11:32:23 | Stage | Epoch[239/600] LR:0.01

2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[001/030] Train loss: 0.0231
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[002/030] Train loss: 0.0225
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[003/030] Train loss: 0.0229
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[004/030] Train loss: 0.0231
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[005/030] Train loss: 0.0231
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[006/030] Train loss: 0.0234
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[007/030] Train loss: 0.0231
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[008/030] Train loss: 0.0232
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[009/030] Train loss: 0.0233
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[010/030] Train loss: 0.0233
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[011/030] Train loss: 0.0235
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[012/030] Train loss: 0.0233
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[013/030] Train loss: 0.0234
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[014/030] Train loss: 0.0234
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[015/030] Train loss: 0.0232
2023-02-06 11:32:24 | Train | Epoch[240/600] Iteration[016/030] Train loss: 0.0233
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[017/030] Train loss: 0.0234
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[018/030] Train loss: 0.0237
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[019/030] Train loss: 0.0239
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[020/030] Train loss: 0.0238
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[021/030] Train loss: 0.0238
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[022/030] Train loss: 0.0239
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[023/030] Train loss: 0.0239
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[024/030] Train loss: 0.0239
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[025/030] Train loss: 0.0239
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[026/030] Train loss: 0.0239
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[027/030] Train loss: 0.0239
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[028/030] Train loss: 0.0241
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[029/030] Train loss: 0.0240
2023-02-06 11:32:25 | Train | Epoch[240/600] Iteration[030/030] Train loss: 0.0240
2023-02-06 11:32:26 | Valid | Epoch[240/600] Iteration[001/008] Valid loss: 0.2332
2023-02-06 11:32:26 | Valid | Epoch[240/600] Iteration[002/008] Valid loss: 0.1592
2023-02-06 11:32:26 | Valid | Epoch[240/600] Iteration[003/008] Valid loss: 0.1461
2023-02-06 11:32:26 | Valid | Epoch[240/600] Iteration[004/008] Valid loss: 0.1449
2023-02-06 11:32:26 | Valid | Epoch[240/600] Iteration[005/008] Valid loss: 0.1535
2023-02-06 11:32:26 | Valid | Epoch[240/600] Iteration[006/008] Valid loss: 0.1487
2023-02-06 11:32:26 | Valid | Epoch[240/600] Iteration[007/008] Valid loss: 0.1622
2023-02-06 11:32:26 | Valid | Epoch[240/600] Iteration[008/008] Valid loss: 0.1617
2023-02-06 11:32:26 | Valid | Epoch[240/600] MIou: 0.931891931225342
2023-02-06 11:32:26 | Valid | Epoch[240/600] Pixel Accuracy: 0.9877357482910156
2023-02-06 11:32:26 | Valid | Epoch[240/600] Mean Pixel Accuracy: 0.9798489469550088
2023-02-06 11:32:26 | Stage | Epoch[240/600] Train loss:0.0240
2023-02-06 11:32:26 | Stage | Epoch[240/600] Valid loss:0.1617
2023-02-06 11:32:26 | Stage | Epoch[240/600] LR:0.01

2023-02-06 11:32:26 | Train | Epoch[241/600] Iteration[001/030] Train loss: 0.0298
2023-02-06 11:32:26 | Train | Epoch[241/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 11:32:26 | Train | Epoch[241/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 11:32:26 | Train | Epoch[241/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 11:32:26 | Train | Epoch[241/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 11:32:26 | Train | Epoch[241/600] Iteration[006/030] Train loss: 0.0253
2023-02-06 11:32:26 | Train | Epoch[241/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 11:32:26 | Train | Epoch[241/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[013/030] Train loss: 0.0247
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[015/030] Train loss: 0.0244
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[019/030] Train loss: 0.0245
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[020/030] Train loss: 0.0246
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[022/030] Train loss: 0.0247
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[025/030] Train loss: 0.0247
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[026/030] Train loss: 0.0246
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[027/030] Train loss: 0.0246
2023-02-06 11:32:27 | Train | Epoch[241/600] Iteration[028/030] Train loss: 0.0245
2023-02-06 11:32:28 | Train | Epoch[241/600] Iteration[029/030] Train loss: 0.0245
2023-02-06 11:32:28 | Train | Epoch[241/600] Iteration[030/030] Train loss: 0.0244
2023-02-06 11:32:28 | Valid | Epoch[241/600] Iteration[001/008] Valid loss: 0.0399
2023-02-06 11:32:28 | Valid | Epoch[241/600] Iteration[002/008] Valid loss: 0.0355
2023-02-06 11:32:28 | Valid | Epoch[241/600] Iteration[003/008] Valid loss: 0.0344
2023-02-06 11:32:28 | Valid | Epoch[241/600] Iteration[004/008] Valid loss: 0.0333
2023-02-06 11:32:28 | Valid | Epoch[241/600] Iteration[005/008] Valid loss: 0.0344
2023-02-06 11:32:28 | Valid | Epoch[241/600] Iteration[006/008] Valid loss: 0.0342
2023-02-06 11:32:28 | Valid | Epoch[241/600] Iteration[007/008] Valid loss: 0.0337
2023-02-06 11:32:28 | Valid | Epoch[241/600] Iteration[008/008] Valid loss: 0.0338
2023-02-06 11:32:28 | Valid | Epoch[241/600] MIou: 0.9036865332321592
2023-02-06 11:32:28 | Valid | Epoch[241/600] Pixel Accuracy: 0.9840227762858073
2023-02-06 11:32:28 | Valid | Epoch[241/600] Mean Pixel Accuracy: 0.9155256875233604
2023-02-06 11:32:28 | Stage | Epoch[241/600] Train loss:0.0244
2023-02-06 11:32:28 | Stage | Epoch[241/600] Valid loss:0.0338
2023-02-06 11:32:28 | Stage | Epoch[241/600] LR:0.01

2023-02-06 11:32:28 | Train | Epoch[242/600] Iteration[001/030] Train loss: 0.0228
2023-02-06 11:32:28 | Train | Epoch[242/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[003/030] Train loss: 0.0236
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[005/030] Train loss: 0.0232
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[006/030] Train loss: 0.0237
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[007/030] Train loss: 0.0238
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[008/030] Train loss: 0.0238
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[009/030] Train loss: 0.0238
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[010/030] Train loss: 0.0239
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[011/030] Train loss: 0.0240
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[012/030] Train loss: 0.0236
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[013/030] Train loss: 0.0234
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[014/030] Train loss: 0.0234
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[015/030] Train loss: 0.0235
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[016/030] Train loss: 0.0234
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[017/030] Train loss: 0.0233
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[018/030] Train loss: 0.0235
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[019/030] Train loss: 0.0235
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[020/030] Train loss: 0.0236
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[021/030] Train loss: 0.0236
2023-02-06 11:32:29 | Train | Epoch[242/600] Iteration[022/030] Train loss: 0.0236
2023-02-06 11:32:30 | Train | Epoch[242/600] Iteration[023/030] Train loss: 0.0237
2023-02-06 11:32:30 | Train | Epoch[242/600] Iteration[024/030] Train loss: 0.0238
2023-02-06 11:32:30 | Train | Epoch[242/600] Iteration[025/030] Train loss: 0.0237
2023-02-06 11:32:30 | Train | Epoch[242/600] Iteration[026/030] Train loss: 0.0238
2023-02-06 11:32:30 | Train | Epoch[242/600] Iteration[027/030] Train loss: 0.0239
2023-02-06 11:32:30 | Train | Epoch[242/600] Iteration[028/030] Train loss: 0.0239
2023-02-06 11:32:30 | Train | Epoch[242/600] Iteration[029/030] Train loss: 0.0239
2023-02-06 11:32:30 | Train | Epoch[242/600] Iteration[030/030] Train loss: 0.0239
2023-02-06 11:32:30 | Valid | Epoch[242/600] Iteration[001/008] Valid loss: 0.0869
2023-02-06 11:32:30 | Valid | Epoch[242/600] Iteration[002/008] Valid loss: 0.0854
2023-02-06 11:32:30 | Valid | Epoch[242/600] Iteration[003/008] Valid loss: 0.0866
2023-02-06 11:32:30 | Valid | Epoch[242/600] Iteration[004/008] Valid loss: 0.0844
2023-02-06 11:32:30 | Valid | Epoch[242/600] Iteration[005/008] Valid loss: 0.0856
2023-02-06 11:32:30 | Valid | Epoch[242/600] Iteration[006/008] Valid loss: 0.0840
2023-02-06 11:32:30 | Valid | Epoch[242/600] Iteration[007/008] Valid loss: 0.0817
2023-02-06 11:32:30 | Valid | Epoch[242/600] Iteration[008/008] Valid loss: 0.0846
2023-02-06 11:32:31 | Valid | Epoch[242/600] MIou: 0.7413925391174259
2023-02-06 11:32:31 | Valid | Epoch[242/600] Pixel Accuracy: 0.9573326110839844
2023-02-06 11:32:31 | Valid | Epoch[242/600] Mean Pixel Accuracy: 0.7637936617437948
2023-02-06 11:32:31 | Stage | Epoch[242/600] Train loss:0.0239
2023-02-06 11:32:31 | Stage | Epoch[242/600] Valid loss:0.0846
2023-02-06 11:32:31 | Stage | Epoch[242/600] LR:0.01

2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[003/030] Train loss: 0.0242
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[006/030] Train loss: 0.0245
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[008/030] Train loss: 0.0236
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[009/030] Train loss: 0.0237
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[010/030] Train loss: 0.0236
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[011/030] Train loss: 0.0240
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[012/030] Train loss: 0.0241
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[014/030] Train loss: 0.0242
2023-02-06 11:32:31 | Train | Epoch[243/600] Iteration[015/030] Train loss: 0.0243
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[017/030] Train loss: 0.0243
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[018/030] Train loss: 0.0242
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[019/030] Train loss: 0.0243
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[020/030] Train loss: 0.0241
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[021/030] Train loss: 0.0241
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[022/030] Train loss: 0.0240
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[023/030] Train loss: 0.0240
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[024/030] Train loss: 0.0240
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[025/030] Train loss: 0.0240
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[026/030] Train loss: 0.0240
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[027/030] Train loss: 0.0240
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[028/030] Train loss: 0.0239
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[029/030] Train loss: 0.0240
2023-02-06 11:32:32 | Train | Epoch[243/600] Iteration[030/030] Train loss: 0.0241
2023-02-06 11:32:33 | Valid | Epoch[243/600] Iteration[001/008] Valid loss: 0.3749
2023-02-06 11:32:33 | Valid | Epoch[243/600] Iteration[002/008] Valid loss: 0.3049
2023-02-06 11:32:33 | Valid | Epoch[243/600] Iteration[003/008] Valid loss: 0.2961
2023-02-06 11:32:33 | Valid | Epoch[243/600] Iteration[004/008] Valid loss: 0.2990
2023-02-06 11:32:33 | Valid | Epoch[243/600] Iteration[005/008] Valid loss: 0.3157
2023-02-06 11:32:33 | Valid | Epoch[243/600] Iteration[006/008] Valid loss: 0.3081
2023-02-06 11:32:33 | Valid | Epoch[243/600] Iteration[007/008] Valid loss: 0.3280
2023-02-06 11:32:33 | Valid | Epoch[243/600] Iteration[008/008] Valid loss: 0.3302
2023-02-06 11:32:33 | Valid | Epoch[243/600] MIou: 0.9039889376475392
2023-02-06 11:32:33 | Valid | Epoch[243/600] Pixel Accuracy: 0.9815050760904948
2023-02-06 11:32:33 | Valid | Epoch[243/600] Mean Pixel Accuracy: 0.9843181908143996
2023-02-06 11:32:33 | Stage | Epoch[243/600] Train loss:0.0241
2023-02-06 11:32:33 | Stage | Epoch[243/600] Valid loss:0.3302
2023-02-06 11:32:33 | Stage | Epoch[243/600] LR:0.01

2023-02-06 11:32:33 | Train | Epoch[244/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 11:32:33 | Train | Epoch[244/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 11:32:33 | Train | Epoch[244/600] Iteration[003/030] Train loss: 0.0236
2023-02-06 11:32:33 | Train | Epoch[244/600] Iteration[004/030] Train loss: 0.0236
2023-02-06 11:32:33 | Train | Epoch[244/600] Iteration[005/030] Train loss: 0.0231
2023-02-06 11:32:33 | Train | Epoch[244/600] Iteration[006/030] Train loss: 0.0232
2023-02-06 11:32:33 | Train | Epoch[244/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[008/030] Train loss: 0.0230
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[009/030] Train loss: 0.0240
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[010/030] Train loss: 0.0240
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[012/030] Train loss: 0.0241
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[014/030] Train loss: 0.0242
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[015/030] Train loss: 0.0242
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[016/030] Train loss: 0.0241
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[017/030] Train loss: 0.0241
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[018/030] Train loss: 0.0240
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[019/030] Train loss: 0.0241
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[020/030] Train loss: 0.0244
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[021/030] Train loss: 0.0243
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[022/030] Train loss: 0.0243
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[023/030] Train loss: 0.0244
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[024/030] Train loss: 0.0243
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[025/030] Train loss: 0.0242
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[026/030] Train loss: 0.0243
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[027/030] Train loss: 0.0243
2023-02-06 11:32:34 | Train | Epoch[244/600] Iteration[028/030] Train loss: 0.0242
2023-02-06 11:32:35 | Train | Epoch[244/600] Iteration[029/030] Train loss: 0.0242
2023-02-06 11:32:35 | Train | Epoch[244/600] Iteration[030/030] Train loss: 0.0241
2023-02-06 11:32:35 | Valid | Epoch[244/600] Iteration[001/008] Valid loss: 0.1238
2023-02-06 11:32:35 | Valid | Epoch[244/600] Iteration[002/008] Valid loss: 0.0793
2023-02-06 11:32:35 | Valid | Epoch[244/600] Iteration[003/008] Valid loss: 0.0686
2023-02-06 11:32:35 | Valid | Epoch[244/600] Iteration[004/008] Valid loss: 0.0663
2023-02-06 11:32:35 | Valid | Epoch[244/600] Iteration[005/008] Valid loss: 0.0682
2023-02-06 11:32:35 | Valid | Epoch[244/600] Iteration[006/008] Valid loss: 0.0652
2023-02-06 11:32:35 | Valid | Epoch[244/600] Iteration[007/008] Valid loss: 0.0676
2023-02-06 11:32:35 | Valid | Epoch[244/600] Iteration[008/008] Valid loss: 0.0670
2023-02-06 11:32:35 | Valid | Epoch[244/600] MIou: 0.9348715528934197
2023-02-06 11:32:35 | Valid | Epoch[244/600] Pixel Accuracy: 0.9887110392252604
2023-02-06 11:32:35 | Valid | Epoch[244/600] Mean Pixel Accuracy: 0.9644831058953258
2023-02-06 11:32:35 | Stage | Epoch[244/600] Train loss:0.0241
2023-02-06 11:32:35 | Stage | Epoch[244/600] Valid loss:0.0670
2023-02-06 11:32:35 | Stage | Epoch[244/600] LR:0.01

2023-02-06 11:32:35 | Train | Epoch[245/600] Iteration[001/030] Train loss: 0.0271
2023-02-06 11:32:35 | Train | Epoch[245/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[006/030] Train loss: 0.0242
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[007/030] Train loss: 0.0236
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[008/030] Train loss: 0.0237
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[009/030] Train loss: 0.0237
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[010/030] Train loss: 0.0240
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[011/030] Train loss: 0.0240
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[012/030] Train loss: 0.0241
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[013/030] Train loss: 0.0240
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[014/030] Train loss: 0.0241
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[015/030] Train loss: 0.0243
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[018/030] Train loss: 0.0244
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[019/030] Train loss: 0.0242
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[020/030] Train loss: 0.0242
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[021/030] Train loss: 0.0241
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[022/030] Train loss: 0.0242
2023-02-06 11:32:36 | Train | Epoch[245/600] Iteration[023/030] Train loss: 0.0241
2023-02-06 11:32:37 | Train | Epoch[245/600] Iteration[024/030] Train loss: 0.0241
2023-02-06 11:32:37 | Train | Epoch[245/600] Iteration[025/030] Train loss: 0.0240
2023-02-06 11:32:37 | Train | Epoch[245/600] Iteration[026/030] Train loss: 0.0240
2023-02-06 11:32:37 | Train | Epoch[245/600] Iteration[027/030] Train loss: 0.0239
2023-02-06 11:32:37 | Train | Epoch[245/600] Iteration[028/030] Train loss: 0.0240
2023-02-06 11:32:37 | Train | Epoch[245/600] Iteration[029/030] Train loss: 0.0239
2023-02-06 11:32:37 | Train | Epoch[245/600] Iteration[030/030] Train loss: 0.0240
2023-02-06 11:32:37 | Valid | Epoch[245/600] Iteration[001/008] Valid loss: 0.2953
2023-02-06 11:32:37 | Valid | Epoch[245/600] Iteration[002/008] Valid loss: 0.2069
2023-02-06 11:32:37 | Valid | Epoch[245/600] Iteration[003/008] Valid loss: 0.1928
2023-02-06 11:32:37 | Valid | Epoch[245/600] Iteration[004/008] Valid loss: 0.1916
2023-02-06 11:32:37 | Valid | Epoch[245/600] Iteration[005/008] Valid loss: 0.2071
2023-02-06 11:32:37 | Valid | Epoch[245/600] Iteration[006/008] Valid loss: 0.2012
2023-02-06 11:32:37 | Valid | Epoch[245/600] Iteration[007/008] Valid loss: 0.2134
2023-02-06 11:32:37 | Valid | Epoch[245/600] Iteration[008/008] Valid loss: 0.2142
2023-02-06 11:32:37 | Valid | Epoch[245/600] MIou: 0.9247261504368038
2023-02-06 11:32:37 | Valid | Epoch[245/600] Pixel Accuracy: 0.9861780802408854
2023-02-06 11:32:37 | Valid | Epoch[245/600] Mean Pixel Accuracy: 0.9821883838038099
2023-02-06 11:32:37 | Stage | Epoch[245/600] Train loss:0.0240
2023-02-06 11:32:37 | Stage | Epoch[245/600] Valid loss:0.2142
2023-02-06 11:32:37 | Stage | Epoch[245/600] LR:0.01

2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[001/030] Train loss: 0.0250
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[003/030] Train loss: 0.0227
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[004/030] Train loss: 0.0227
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[005/030] Train loss: 0.0224
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[006/030] Train loss: 0.0220
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[007/030] Train loss: 0.0225
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[008/030] Train loss: 0.0223
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[009/030] Train loss: 0.0221
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[011/030] Train loss: 0.0224
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[014/030] Train loss: 0.0230
2023-02-06 11:32:38 | Train | Epoch[246/600] Iteration[015/030] Train loss: 0.0230
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[016/030] Train loss: 0.0231
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[017/030] Train loss: 0.0232
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[018/030] Train loss: 0.0231
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[019/030] Train loss: 0.0233
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[020/030] Train loss: 0.0233
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[021/030] Train loss: 0.0234
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[022/030] Train loss: 0.0233
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[023/030] Train loss: 0.0235
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[024/030] Train loss: 0.0234
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[025/030] Train loss: 0.0234
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[026/030] Train loss: 0.0235
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[027/030] Train loss: 0.0235
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[028/030] Train loss: 0.0237
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[029/030] Train loss: 0.0238
2023-02-06 11:32:39 | Train | Epoch[246/600] Iteration[030/030] Train loss: 0.0237
2023-02-06 11:32:40 | Valid | Epoch[246/600] Iteration[001/008] Valid loss: 0.0495
2023-02-06 11:32:40 | Valid | Epoch[246/600] Iteration[002/008] Valid loss: 0.0477
2023-02-06 11:32:40 | Valid | Epoch[246/600] Iteration[003/008] Valid loss: 0.0477
2023-02-06 11:32:40 | Valid | Epoch[246/600] Iteration[004/008] Valid loss: 0.0459
2023-02-06 11:32:40 | Valid | Epoch[246/600] Iteration[005/008] Valid loss: 0.0468
2023-02-06 11:32:40 | Valid | Epoch[246/600] Iteration[006/008] Valid loss: 0.0460
2023-02-06 11:32:40 | Valid | Epoch[246/600] Iteration[007/008] Valid loss: 0.0448
2023-02-06 11:32:40 | Valid | Epoch[246/600] Iteration[008/008] Valid loss: 0.0459
2023-02-06 11:32:40 | Valid | Epoch[246/600] MIou: 0.8459417498964243
2023-02-06 11:32:40 | Valid | Epoch[246/600] Pixel Accuracy: 0.9746042887369791
2023-02-06 11:32:40 | Valid | Epoch[246/600] Mean Pixel Accuracy: 0.8597709438258851
2023-02-06 11:32:40 | Stage | Epoch[246/600] Train loss:0.0237
2023-02-06 11:32:40 | Stage | Epoch[246/600] Valid loss:0.0459
2023-02-06 11:32:40 | Stage | Epoch[246/600] LR:0.01

2023-02-06 11:32:40 | Train | Epoch[247/600] Iteration[001/030] Train loss: 0.0250
2023-02-06 11:32:40 | Train | Epoch[247/600] Iteration[002/030] Train loss: 0.0263
2023-02-06 11:32:40 | Train | Epoch[247/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 11:32:40 | Train | Epoch[247/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 11:32:40 | Train | Epoch[247/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 11:32:40 | Train | Epoch[247/600] Iteration[006/030] Train loss: 0.0246
2023-02-06 11:32:40 | Train | Epoch[247/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 11:32:40 | Train | Epoch[247/600] Iteration[008/030] Train loss: 0.0236
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[009/030] Train loss: 0.0232
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[010/030] Train loss: 0.0233
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[011/030] Train loss: 0.0236
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[012/030] Train loss: 0.0233
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[013/030] Train loss: 0.0234
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[014/030] Train loss: 0.0231
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[015/030] Train loss: 0.0229
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[016/030] Train loss: 0.0231
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[017/030] Train loss: 0.0231
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[018/030] Train loss: 0.0233
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[019/030] Train loss: 0.0232
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[020/030] Train loss: 0.0231
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[021/030] Train loss: 0.0232
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[022/030] Train loss: 0.0234
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[023/030] Train loss: 0.0234
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[024/030] Train loss: 0.0232
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[025/030] Train loss: 0.0234
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[026/030] Train loss: 0.0235
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[027/030] Train loss: 0.0234
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[028/030] Train loss: 0.0236
2023-02-06 11:32:41 | Train | Epoch[247/600] Iteration[029/030] Train loss: 0.0235
2023-02-06 11:32:42 | Train | Epoch[247/600] Iteration[030/030] Train loss: 0.0235
2023-02-06 11:32:42 | Valid | Epoch[247/600] Iteration[001/008] Valid loss: 0.0506
2023-02-06 11:32:42 | Valid | Epoch[247/600] Iteration[002/008] Valid loss: 0.0479
2023-02-06 11:32:42 | Valid | Epoch[247/600] Iteration[003/008] Valid loss: 0.0481
2023-02-06 11:32:42 | Valid | Epoch[247/600] Iteration[004/008] Valid loss: 0.0464
2023-02-06 11:32:42 | Valid | Epoch[247/600] Iteration[005/008] Valid loss: 0.0473
2023-02-06 11:32:42 | Valid | Epoch[247/600] Iteration[006/008] Valid loss: 0.0467
2023-02-06 11:32:42 | Valid | Epoch[247/600] Iteration[007/008] Valid loss: 0.0454
2023-02-06 11:32:42 | Valid | Epoch[247/600] Iteration[008/008] Valid loss: 0.0463
2023-02-06 11:32:42 | Valid | Epoch[247/600] MIou: 0.8454839656181703
2023-02-06 11:32:42 | Valid | Epoch[247/600] Pixel Accuracy: 0.9745279947916666
2023-02-06 11:32:42 | Valid | Epoch[247/600] Mean Pixel Accuracy: 0.8593612620719827
2023-02-06 11:32:42 | Stage | Epoch[247/600] Train loss:0.0235
2023-02-06 11:32:42 | Stage | Epoch[247/600] Valid loss:0.0463
2023-02-06 11:32:42 | Stage | Epoch[247/600] LR:0.01

2023-02-06 11:32:42 | Train | Epoch[248/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[002/030] Train loss: 0.0232
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[003/030] Train loss: 0.0242
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[008/030] Train loss: 0.0240
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[009/030] Train loss: 0.0241
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[012/030] Train loss: 0.0240
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[013/030] Train loss: 0.0240
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[014/030] Train loss: 0.0238
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[015/030] Train loss: 0.0238
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[016/030] Train loss: 0.0236
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[017/030] Train loss: 0.0237
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[018/030] Train loss: 0.0235
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[019/030] Train loss: 0.0234
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[020/030] Train loss: 0.0234
2023-02-06 11:32:43 | Train | Epoch[248/600] Iteration[021/030] Train loss: 0.0236
2023-02-06 11:32:44 | Train | Epoch[248/600] Iteration[022/030] Train loss: 0.0236
2023-02-06 11:32:44 | Train | Epoch[248/600] Iteration[023/030] Train loss: 0.0236
2023-02-06 11:32:44 | Train | Epoch[248/600] Iteration[024/030] Train loss: 0.0235
2023-02-06 11:32:44 | Train | Epoch[248/600] Iteration[025/030] Train loss: 0.0237
2023-02-06 11:32:44 | Train | Epoch[248/600] Iteration[026/030] Train loss: 0.0235
2023-02-06 11:32:44 | Train | Epoch[248/600] Iteration[027/030] Train loss: 0.0236
2023-02-06 11:32:44 | Train | Epoch[248/600] Iteration[028/030] Train loss: 0.0236
2023-02-06 11:32:44 | Train | Epoch[248/600] Iteration[029/030] Train loss: 0.0236
2023-02-06 11:32:44 | Train | Epoch[248/600] Iteration[030/030] Train loss: 0.0235
2023-02-06 11:32:44 | Valid | Epoch[248/600] Iteration[001/008] Valid loss: 0.0635
2023-02-06 11:32:44 | Valid | Epoch[248/600] Iteration[002/008] Valid loss: 0.0456
2023-02-06 11:32:44 | Valid | Epoch[248/600] Iteration[003/008] Valid loss: 0.0406
2023-02-06 11:32:44 | Valid | Epoch[248/600] Iteration[004/008] Valid loss: 0.0396
2023-02-06 11:32:44 | Valid | Epoch[248/600] Iteration[005/008] Valid loss: 0.0403
2023-02-06 11:32:44 | Valid | Epoch[248/600] Iteration[006/008] Valid loss: 0.0395
2023-02-06 11:32:44 | Valid | Epoch[248/600] Iteration[007/008] Valid loss: 0.0402
2023-02-06 11:32:44 | Valid | Epoch[248/600] Iteration[008/008] Valid loss: 0.0396
2023-02-06 11:32:45 | Valid | Epoch[248/600] MIou: 0.9364384118702129
2023-02-06 11:32:45 | Valid | Epoch[248/600] Pixel Accuracy: 0.9892323811848959
2023-02-06 11:32:45 | Valid | Epoch[248/600] Mean Pixel Accuracy: 0.9553477170040877
2023-02-06 11:32:45 | Stage | Epoch[248/600] Train loss:0.0235
2023-02-06 11:32:45 | Stage | Epoch[248/600] Valid loss:0.0396
2023-02-06 11:32:45 | Stage | Epoch[248/600] LR:0.01

2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[002/030] Train loss: 0.0224
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[003/030] Train loss: 0.0228
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[004/030] Train loss: 0.0233
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[005/030] Train loss: 0.0233
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[006/030] Train loss: 0.0230
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[008/030] Train loss: 0.0231
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[010/030] Train loss: 0.0232
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[011/030] Train loss: 0.0232
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[012/030] Train loss: 0.0232
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[013/030] Train loss: 0.0234
2023-02-06 11:32:45 | Train | Epoch[249/600] Iteration[014/030] Train loss: 0.0235
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[015/030] Train loss: 0.0234
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[016/030] Train loss: 0.0236
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[017/030] Train loss: 0.0238
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[018/030] Train loss: 0.0237
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[019/030] Train loss: 0.0237
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[020/030] Train loss: 0.0237
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[021/030] Train loss: 0.0236
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[022/030] Train loss: 0.0236
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[023/030] Train loss: 0.0238
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[024/030] Train loss: 0.0238
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[025/030] Train loss: 0.0237
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[026/030] Train loss: 0.0237
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[027/030] Train loss: 0.0236
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[028/030] Train loss: 0.0236
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[029/030] Train loss: 0.0237
2023-02-06 11:32:46 | Train | Epoch[249/600] Iteration[030/030] Train loss: 0.0237
2023-02-06 11:32:47 | Valid | Epoch[249/600] Iteration[001/008] Valid loss: 0.0424
2023-02-06 11:32:47 | Valid | Epoch[249/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:32:47 | Valid | Epoch[249/600] Iteration[003/008] Valid loss: 0.0379
2023-02-06 11:32:47 | Valid | Epoch[249/600] Iteration[004/008] Valid loss: 0.0362
2023-02-06 11:32:47 | Valid | Epoch[249/600] Iteration[005/008] Valid loss: 0.0368
2023-02-06 11:32:47 | Valid | Epoch[249/600] Iteration[006/008] Valid loss: 0.0362
2023-02-06 11:32:47 | Valid | Epoch[249/600] Iteration[007/008] Valid loss: 0.0353
2023-02-06 11:32:47 | Valid | Epoch[249/600] Iteration[008/008] Valid loss: 0.0357
2023-02-06 11:32:47 | Valid | Epoch[249/600] MIou: 0.8879208288099916
2023-02-06 11:32:47 | Valid | Epoch[249/600] Pixel Accuracy: 0.9815012613932291
2023-02-06 11:32:47 | Valid | Epoch[249/600] Mean Pixel Accuracy: 0.8989036023548624
2023-02-06 11:32:47 | Stage | Epoch[249/600] Train loss:0.0237
2023-02-06 11:32:47 | Stage | Epoch[249/600] Valid loss:0.0357
2023-02-06 11:32:47 | Stage | Epoch[249/600] LR:0.01

2023-02-06 11:32:47 | Train | Epoch[250/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 11:32:47 | Train | Epoch[250/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:32:47 | Train | Epoch[250/600] Iteration[003/030] Train loss: 0.0213
2023-02-06 11:32:47 | Train | Epoch[250/600] Iteration[004/030] Train loss: 0.0225
2023-02-06 11:32:47 | Train | Epoch[250/600] Iteration[005/030] Train loss: 0.0222
2023-02-06 11:32:47 | Train | Epoch[250/600] Iteration[006/030] Train loss: 0.0217
2023-02-06 11:32:47 | Train | Epoch[250/600] Iteration[007/030] Train loss: 0.0217
2023-02-06 11:32:47 | Train | Epoch[250/600] Iteration[008/030] Train loss: 0.0221
2023-02-06 11:32:47 | Train | Epoch[250/600] Iteration[009/030] Train loss: 0.0219
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[011/030] Train loss: 0.0226
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[013/030] Train loss: 0.0227
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[014/030] Train loss: 0.0231
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[015/030] Train loss: 0.0232
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[016/030] Train loss: 0.0232
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[017/030] Train loss: 0.0233
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[018/030] Train loss: 0.0232
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[019/030] Train loss: 0.0232
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[020/030] Train loss: 0.0233
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[021/030] Train loss: 0.0233
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[022/030] Train loss: 0.0234
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[023/030] Train loss: 0.0233
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[024/030] Train loss: 0.0233
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[025/030] Train loss: 0.0236
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[026/030] Train loss: 0.0235
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[027/030] Train loss: 0.0234
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[028/030] Train loss: 0.0235
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[029/030] Train loss: 0.0235
2023-02-06 11:32:48 | Train | Epoch[250/600] Iteration[030/030] Train loss: 0.0235
2023-02-06 11:32:49 | Valid | Epoch[250/600] Iteration[001/008] Valid loss: 0.0427
2023-02-06 11:32:49 | Valid | Epoch[250/600] Iteration[002/008] Valid loss: 0.0371
2023-02-06 11:32:49 | Valid | Epoch[250/600] Iteration[003/008] Valid loss: 0.0358
2023-02-06 11:32:49 | Valid | Epoch[250/600] Iteration[004/008] Valid loss: 0.0343
2023-02-06 11:32:49 | Valid | Epoch[250/600] Iteration[005/008] Valid loss: 0.0349
2023-02-06 11:32:49 | Valid | Epoch[250/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 11:32:49 | Valid | Epoch[250/600] Iteration[007/008] Valid loss: 0.0338
2023-02-06 11:32:49 | Valid | Epoch[250/600] Iteration[008/008] Valid loss: 0.0342
2023-02-06 11:32:49 | Valid | Epoch[250/600] MIou: 0.8946901797516531
2023-02-06 11:32:49 | Valid | Epoch[250/600] Pixel Accuracy: 0.98260498046875
2023-02-06 11:32:49 | Valid | Epoch[250/600] Mean Pixel Accuracy: 0.9054576157095796
2023-02-06 11:32:49 | Stage | Epoch[250/600] Train loss:0.0235
2023-02-06 11:32:49 | Stage | Epoch[250/600] Valid loss:0.0342
2023-02-06 11:32:49 | Stage | Epoch[250/600] LR:0.01

2023-02-06 11:32:49 | Train | Epoch[251/600] Iteration[001/030] Train loss: 0.0222
2023-02-06 11:32:49 | Train | Epoch[251/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:32:49 | Train | Epoch[251/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:32:49 | Train | Epoch[251/600] Iteration[004/030] Train loss: 0.0236
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[005/030] Train loss: 0.0231
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[006/030] Train loss: 0.0229
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[007/030] Train loss: 0.0229
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[008/030] Train loss: 0.0223
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[011/030] Train loss: 0.0230
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[012/030] Train loss: 0.0235
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[013/030] Train loss: 0.0234
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[014/030] Train loss: 0.0234
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[015/030] Train loss: 0.0233
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[016/030] Train loss: 0.0233
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[017/030] Train loss: 0.0232
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[018/030] Train loss: 0.0233
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[019/030] Train loss: 0.0233
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[020/030] Train loss: 0.0233
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[021/030] Train loss: 0.0233
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[022/030] Train loss: 0.0234
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[023/030] Train loss: 0.0233
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[024/030] Train loss: 0.0233
2023-02-06 11:32:50 | Train | Epoch[251/600] Iteration[025/030] Train loss: 0.0234
2023-02-06 11:32:51 | Train | Epoch[251/600] Iteration[026/030] Train loss: 0.0234
2023-02-06 11:32:51 | Train | Epoch[251/600] Iteration[027/030] Train loss: 0.0234
2023-02-06 11:32:51 | Train | Epoch[251/600] Iteration[028/030] Train loss: 0.0235
2023-02-06 11:32:51 | Train | Epoch[251/600] Iteration[029/030] Train loss: 0.0234
2023-02-06 11:32:51 | Train | Epoch[251/600] Iteration[030/030] Train loss: 0.0234
2023-02-06 11:32:51 | Valid | Epoch[251/600] Iteration[001/008] Valid loss: 0.0700
2023-02-06 11:32:51 | Valid | Epoch[251/600] Iteration[002/008] Valid loss: 0.0494
2023-02-06 11:32:51 | Valid | Epoch[251/600] Iteration[003/008] Valid loss: 0.0441
2023-02-06 11:32:51 | Valid | Epoch[251/600] Iteration[004/008] Valid loss: 0.0420
2023-02-06 11:32:51 | Valid | Epoch[251/600] Iteration[005/008] Valid loss: 0.0461
2023-02-06 11:32:51 | Valid | Epoch[251/600] Iteration[006/008] Valid loss: 0.0453
2023-02-06 11:32:51 | Valid | Epoch[251/600] Iteration[007/008] Valid loss: 0.0449
2023-02-06 11:32:51 | Valid | Epoch[251/600] Iteration[008/008] Valid loss: 0.0446
2023-02-06 11:32:51 | Valid | Epoch[251/600] MIou: 0.928507304109343
2023-02-06 11:32:51 | Valid | Epoch[251/600] Pixel Accuracy: 0.9878196716308594
2023-02-06 11:32:51 | Valid | Epoch[251/600] Mean Pixel Accuracy: 0.9504118822706598
2023-02-06 11:32:51 | Stage | Epoch[251/600] Train loss:0.0234
2023-02-06 11:32:51 | Stage | Epoch[251/600] Valid loss:0.0446
2023-02-06 11:32:51 | Stage | Epoch[251/600] LR:0.01

2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[001/030] Train loss: 0.0253
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[004/030] Train loss: 0.0230
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[005/030] Train loss: 0.0228
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[006/030] Train loss: 0.0227
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[007/030] Train loss: 0.0229
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[009/030] Train loss: 0.0224
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[011/030] Train loss: 0.0225
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[013/030] Train loss: 0.0225
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[014/030] Train loss: 0.0225
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[015/030] Train loss: 0.0228
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[016/030] Train loss: 0.0227
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[017/030] Train loss: 0.0228
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[018/030] Train loss: 0.0230
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[019/030] Train loss: 0.0230
2023-02-06 11:32:52 | Train | Epoch[252/600] Iteration[020/030] Train loss: 0.0230
2023-02-06 11:32:53 | Train | Epoch[252/600] Iteration[021/030] Train loss: 0.0229
2023-02-06 11:32:53 | Train | Epoch[252/600] Iteration[022/030] Train loss: 0.0229
2023-02-06 11:32:53 | Train | Epoch[252/600] Iteration[023/030] Train loss: 0.0229
2023-02-06 11:32:53 | Train | Epoch[252/600] Iteration[024/030] Train loss: 0.0230
2023-02-06 11:32:53 | Train | Epoch[252/600] Iteration[025/030] Train loss: 0.0230
2023-02-06 11:32:53 | Train | Epoch[252/600] Iteration[026/030] Train loss: 0.0229
2023-02-06 11:32:53 | Train | Epoch[252/600] Iteration[027/030] Train loss: 0.0230
2023-02-06 11:32:53 | Train | Epoch[252/600] Iteration[028/030] Train loss: 0.0231
2023-02-06 11:32:53 | Train | Epoch[252/600] Iteration[029/030] Train loss: 0.0232
2023-02-06 11:32:53 | Train | Epoch[252/600] Iteration[030/030] Train loss: 0.0233
2023-02-06 11:32:53 | Valid | Epoch[252/600] Iteration[001/008] Valid loss: 0.0442
2023-02-06 11:32:53 | Valid | Epoch[252/600] Iteration[002/008] Valid loss: 0.0417
2023-02-06 11:32:53 | Valid | Epoch[252/600] Iteration[003/008] Valid loss: 0.0414
2023-02-06 11:32:53 | Valid | Epoch[252/600] Iteration[004/008] Valid loss: 0.0399
2023-02-06 11:32:53 | Valid | Epoch[252/600] Iteration[005/008] Valid loss: 0.0407
2023-02-06 11:32:53 | Valid | Epoch[252/600] Iteration[006/008] Valid loss: 0.0401
2023-02-06 11:32:53 | Valid | Epoch[252/600] Iteration[007/008] Valid loss: 0.0389
2023-02-06 11:32:54 | Valid | Epoch[252/600] Iteration[008/008] Valid loss: 0.0395
2023-02-06 11:32:54 | Valid | Epoch[252/600] MIou: 0.8730121301329039
2023-02-06 11:32:54 | Valid | Epoch[252/600] Pixel Accuracy: 0.9790598551432291
2023-02-06 11:32:54 | Valid | Epoch[252/600] Mean Pixel Accuracy: 0.8848110131456117
2023-02-06 11:32:54 | Stage | Epoch[252/600] Train loss:0.0233
2023-02-06 11:32:54 | Stage | Epoch[252/600] Valid loss:0.0395
2023-02-06 11:32:54 | Stage | Epoch[252/600] LR:0.01

2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[001/030] Train loss: 0.0270
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[002/030] Train loss: 0.0249
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[003/030] Train loss: 0.0238
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[005/030] Train loss: 0.0237
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[006/030] Train loss: 0.0234
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[007/030] Train loss: 0.0229
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[010/030] Train loss: 0.0227
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[011/030] Train loss: 0.0228
2023-02-06 11:32:54 | Train | Epoch[253/600] Iteration[012/030] Train loss: 0.0225
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[013/030] Train loss: 0.0224
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[014/030] Train loss: 0.0226
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[016/030] Train loss: 0.0226
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[017/030] Train loss: 0.0225
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[018/030] Train loss: 0.0234
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[019/030] Train loss: 0.0234
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[020/030] Train loss: 0.0235
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[021/030] Train loss: 0.0234
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[022/030] Train loss: 0.0237
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[023/030] Train loss: 0.0237
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[024/030] Train loss: 0.0239
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[025/030] Train loss: 0.0239
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[026/030] Train loss: 0.0241
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[027/030] Train loss: 0.0243
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[028/030] Train loss: 0.0244
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[029/030] Train loss: 0.0244
2023-02-06 11:32:55 | Train | Epoch[253/600] Iteration[030/030] Train loss: 0.0243
2023-02-06 11:32:56 | Valid | Epoch[253/600] Iteration[001/008] Valid loss: 0.9202
2023-02-06 11:32:56 | Valid | Epoch[253/600] Iteration[002/008] Valid loss: 0.8190
2023-02-06 11:32:56 | Valid | Epoch[253/600] Iteration[003/008] Valid loss: 0.8317
2023-02-06 11:32:56 | Valid | Epoch[253/600] Iteration[004/008] Valid loss: 0.8565
2023-02-06 11:32:56 | Valid | Epoch[253/600] Iteration[005/008] Valid loss: 0.8880
2023-02-06 11:32:56 | Valid | Epoch[253/600] Iteration[006/008] Valid loss: 0.8655
2023-02-06 11:32:56 | Valid | Epoch[253/600] Iteration[007/008] Valid loss: 0.9102
2023-02-06 11:32:56 | Valid | Epoch[253/600] Iteration[008/008] Valid loss: 0.9322
2023-02-06 11:32:56 | Valid | Epoch[253/600] MIou: 0.8517217358052509
2023-02-06 11:32:56 | Valid | Epoch[253/600] Pixel Accuracy: 0.9682146708170573
2023-02-06 11:32:56 | Valid | Epoch[253/600] Mean Pixel Accuracy: 0.9794479583146813
2023-02-06 11:32:56 | Stage | Epoch[253/600] Train loss:0.0243
2023-02-06 11:32:56 | Stage | Epoch[253/600] Valid loss:0.9322
2023-02-06 11:32:56 | Stage | Epoch[253/600] LR:0.01

2023-02-06 11:32:56 | Train | Epoch[254/600] Iteration[001/030] Train loss: 0.0267
2023-02-06 11:32:56 | Train | Epoch[254/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 11:32:56 | Train | Epoch[254/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 11:32:56 | Train | Epoch[254/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 11:32:56 | Train | Epoch[254/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 11:32:56 | Train | Epoch[254/600] Iteration[006/030] Train loss: 0.0253
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[008/030] Train loss: 0.0251
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[016/030] Train loss: 0.0245
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[017/030] Train loss: 0.0245
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[018/030] Train loss: 0.0244
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[019/030] Train loss: 0.0245
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[020/030] Train loss: 0.0246
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[021/030] Train loss: 0.0244
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[022/030] Train loss: 0.0243
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[023/030] Train loss: 0.0242
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[024/030] Train loss: 0.0245
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[025/030] Train loss: 0.0245
2023-02-06 11:32:57 | Train | Epoch[254/600] Iteration[026/030] Train loss: 0.0245
2023-02-06 11:32:58 | Train | Epoch[254/600] Iteration[027/030] Train loss: 0.0243
2023-02-06 11:32:58 | Train | Epoch[254/600] Iteration[028/030] Train loss: 0.0243
2023-02-06 11:32:58 | Train | Epoch[254/600] Iteration[029/030] Train loss: 0.0242
2023-02-06 11:32:58 | Train | Epoch[254/600] Iteration[030/030] Train loss: 0.0240
2023-02-06 11:32:58 | Valid | Epoch[254/600] Iteration[001/008] Valid loss: 0.0408
2023-02-06 11:32:58 | Valid | Epoch[254/600] Iteration[002/008] Valid loss: 0.0359
2023-02-06 11:32:58 | Valid | Epoch[254/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:32:58 | Valid | Epoch[254/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:32:58 | Valid | Epoch[254/600] Iteration[005/008] Valid loss: 0.0347
2023-02-06 11:32:58 | Valid | Epoch[254/600] Iteration[006/008] Valid loss: 0.0342
2023-02-06 11:32:58 | Valid | Epoch[254/600] Iteration[007/008] Valid loss: 0.0334
2023-02-06 11:32:58 | Valid | Epoch[254/600] Iteration[008/008] Valid loss: 0.0335
2023-02-06 11:32:58 | Valid | Epoch[254/600] MIou: 0.9014993614579524
2023-02-06 11:32:58 | Valid | Epoch[254/600] Pixel Accuracy: 0.9836540222167969
2023-02-06 11:32:58 | Valid | Epoch[254/600] Mean Pixel Accuracy: 0.9136491200808625
2023-02-06 11:32:58 | Stage | Epoch[254/600] Train loss:0.0240
2023-02-06 11:32:58 | Stage | Epoch[254/600] Valid loss:0.0335
2023-02-06 11:32:58 | Stage | Epoch[254/600] LR:0.01

2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[001/030] Train loss: 0.0207
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[005/030] Train loss: 0.0227
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[006/030] Train loss: 0.0226
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[007/030] Train loss: 0.0228
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[008/030] Train loss: 0.0231
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[010/030] Train loss: 0.0230
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[011/030] Train loss: 0.0230
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[012/030] Train loss: 0.0232
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[013/030] Train loss: 0.0233
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[014/030] Train loss: 0.0231
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[015/030] Train loss: 0.0231
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[016/030] Train loss: 0.0232
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[017/030] Train loss: 0.0231
2023-02-06 11:32:59 | Train | Epoch[255/600] Iteration[018/030] Train loss: 0.0232
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[019/030] Train loss: 0.0231
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[020/030] Train loss: 0.0231
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[021/030] Train loss: 0.0231
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[022/030] Train loss: 0.0231
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[023/030] Train loss: 0.0233
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[024/030] Train loss: 0.0232
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[025/030] Train loss: 0.0232
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[026/030] Train loss: 0.0233
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[027/030] Train loss: 0.0232
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[028/030] Train loss: 0.0232
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[029/030] Train loss: 0.0233
2023-02-06 11:33:00 | Train | Epoch[255/600] Iteration[030/030] Train loss: 0.0233
2023-02-06 11:33:00 | Valid | Epoch[255/600] Iteration[001/008] Valid loss: 0.0664
2023-02-06 11:33:00 | Valid | Epoch[255/600] Iteration[002/008] Valid loss: 0.0468
2023-02-06 11:33:00 | Valid | Epoch[255/600] Iteration[003/008] Valid loss: 0.0413
2023-02-06 11:33:00 | Valid | Epoch[255/600] Iteration[004/008] Valid loss: 0.0397
2023-02-06 11:33:00 | Valid | Epoch[255/600] Iteration[005/008] Valid loss: 0.0412
2023-02-06 11:33:00 | Valid | Epoch[255/600] Iteration[006/008] Valid loss: 0.0407
2023-02-06 11:33:01 | Valid | Epoch[255/600] Iteration[007/008] Valid loss: 0.0413
2023-02-06 11:33:01 | Valid | Epoch[255/600] Iteration[008/008] Valid loss: 0.0402
2023-02-06 11:33:01 | Valid | Epoch[255/600] MIou: 0.938178050167799
2023-02-06 11:33:01 | Valid | Epoch[255/600] Pixel Accuracy: 0.9895401000976562
2023-02-06 11:33:01 | Valid | Epoch[255/600] Mean Pixel Accuracy: 0.9564235398686625
2023-02-06 11:33:01 | Stage | Epoch[255/600] Train loss:0.0233
2023-02-06 11:33:01 | Stage | Epoch[255/600] Valid loss:0.0402
2023-02-06 11:33:01 | Stage | Epoch[255/600] LR:0.01

2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[002/030] Train loss: 0.0220
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[004/030] Train loss: 0.0223
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[005/030] Train loss: 0.0223
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[007/030] Train loss: 0.0222
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[008/030] Train loss: 0.0223
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[009/030] Train loss: 0.0226
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[011/030] Train loss: 0.0225
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[012/030] Train loss: 0.0224
2023-02-06 11:33:01 | Train | Epoch[256/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[014/030] Train loss: 0.0226
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[015/030] Train loss: 0.0227
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[016/030] Train loss: 0.0227
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[017/030] Train loss: 0.0226
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[018/030] Train loss: 0.0226
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[019/030] Train loss: 0.0227
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[020/030] Train loss: 0.0228
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[021/030] Train loss: 0.0227
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[022/030] Train loss: 0.0228
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[023/030] Train loss: 0.0227
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[024/030] Train loss: 0.0227
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[025/030] Train loss: 0.0230
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[026/030] Train loss: 0.0231
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[027/030] Train loss: 0.0232
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[028/030] Train loss: 0.0233
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[029/030] Train loss: 0.0232
2023-02-06 11:33:02 | Train | Epoch[256/600] Iteration[030/030] Train loss: 0.0232
2023-02-06 11:33:03 | Valid | Epoch[256/600] Iteration[001/008] Valid loss: 1.0298
2023-02-06 11:33:03 | Valid | Epoch[256/600] Iteration[002/008] Valid loss: 0.9858
2023-02-06 11:33:03 | Valid | Epoch[256/600] Iteration[003/008] Valid loss: 0.9963
2023-02-06 11:33:03 | Valid | Epoch[256/600] Iteration[004/008] Valid loss: 1.0312
2023-02-06 11:33:03 | Valid | Epoch[256/600] Iteration[005/008] Valid loss: 1.0705
2023-02-06 11:33:03 | Valid | Epoch[256/600] Iteration[006/008] Valid loss: 1.0524
2023-02-06 11:33:03 | Valid | Epoch[256/600] Iteration[007/008] Valid loss: 1.1038
2023-02-06 11:33:03 | Valid | Epoch[256/600] Iteration[008/008] Valid loss: 1.1238
2023-02-06 11:33:03 | Valid | Epoch[256/600] MIou: 0.8318964559576361
2023-02-06 11:33:03 | Valid | Epoch[256/600] Pixel Accuracy: 0.9623692830403646
2023-02-06 11:33:03 | Valid | Epoch[256/600] Mean Pixel Accuracy: 0.9776997328121424
2023-02-06 11:33:03 | Stage | Epoch[256/600] Train loss:0.0232
2023-02-06 11:33:03 | Stage | Epoch[256/600] Valid loss:1.1238
2023-02-06 11:33:03 | Stage | Epoch[256/600] LR:0.01

2023-02-06 11:33:03 | Train | Epoch[257/600] Iteration[001/030] Train loss: 0.0201
2023-02-06 11:33:03 | Train | Epoch[257/600] Iteration[002/030] Train loss: 0.0209
2023-02-06 11:33:03 | Train | Epoch[257/600] Iteration[003/030] Train loss: 0.0221
2023-02-06 11:33:03 | Train | Epoch[257/600] Iteration[004/030] Train loss: 0.0221
2023-02-06 11:33:03 | Train | Epoch[257/600] Iteration[005/030] Train loss: 0.0223
2023-02-06 11:33:03 | Train | Epoch[257/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[007/030] Train loss: 0.0227
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[008/030] Train loss: 0.0224
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[009/030] Train loss: 0.0224
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[011/030] Train loss: 0.0224
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[012/030] Train loss: 0.0225
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[014/030] Train loss: 0.0229
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[015/030] Train loss: 0.0228
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[016/030] Train loss: 0.0229
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[017/030] Train loss: 0.0229
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[018/030] Train loss: 0.0229
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[019/030] Train loss: 0.0231
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[020/030] Train loss: 0.0233
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[021/030] Train loss: 0.0233
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[022/030] Train loss: 0.0233
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[023/030] Train loss: 0.0233
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[024/030] Train loss: 0.0233
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[025/030] Train loss: 0.0232
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[026/030] Train loss: 0.0232
2023-02-06 11:33:04 | Train | Epoch[257/600] Iteration[027/030] Train loss: 0.0231
2023-02-06 11:33:05 | Train | Epoch[257/600] Iteration[028/030] Train loss: 0.0232
2023-02-06 11:33:05 | Train | Epoch[257/600] Iteration[029/030] Train loss: 0.0231
2023-02-06 11:33:05 | Train | Epoch[257/600] Iteration[030/030] Train loss: 0.0231
2023-02-06 11:33:05 | Valid | Epoch[257/600] Iteration[001/008] Valid loss: 0.1908
2023-02-06 11:33:05 | Valid | Epoch[257/600] Iteration[002/008] Valid loss: 0.1256
2023-02-06 11:33:05 | Valid | Epoch[257/600] Iteration[003/008] Valid loss: 0.1095
2023-02-06 11:33:05 | Valid | Epoch[257/600] Iteration[004/008] Valid loss: 0.1035
2023-02-06 11:33:05 | Valid | Epoch[257/600] Iteration[005/008] Valid loss: 0.1140
2023-02-06 11:33:05 | Valid | Epoch[257/600] Iteration[006/008] Valid loss: 0.1097
2023-02-06 11:33:05 | Valid | Epoch[257/600] Iteration[007/008] Valid loss: 0.1124
2023-02-06 11:33:05 | Valid | Epoch[257/600] Iteration[008/008] Valid loss: 0.1117
2023-02-06 11:33:05 | Valid | Epoch[257/600] MIou: 0.933869542965442
2023-02-06 11:33:05 | Valid | Epoch[257/600] Pixel Accuracy: 0.9883232116699219
2023-02-06 11:33:05 | Valid | Epoch[257/600] Mean Pixel Accuracy: 0.9722969762647597
2023-02-06 11:33:05 | Stage | Epoch[257/600] Train loss:0.0231
2023-02-06 11:33:05 | Stage | Epoch[257/600] Valid loss:0.1117
2023-02-06 11:33:05 | Stage | Epoch[257/600] LR:0.01

2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[001/030] Train loss: 0.0242
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[002/030] Train loss: 0.0266
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[004/030] Train loss: 0.0241
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[005/030] Train loss: 0.0235
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[006/030] Train loss: 0.0236
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[007/030] Train loss: 0.0234
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[008/030] Train loss: 0.0237
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[009/030] Train loss: 0.0237
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[010/030] Train loss: 0.0235
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[011/030] Train loss: 0.0235
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[012/030] Train loss: 0.0233
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[013/030] Train loss: 0.0234
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[014/030] Train loss: 0.0234
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[015/030] Train loss: 0.0233
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[016/030] Train loss: 0.0233
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[017/030] Train loss: 0.0232
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[018/030] Train loss: 0.0234
2023-02-06 11:33:06 | Train | Epoch[258/600] Iteration[019/030] Train loss: 0.0234
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[020/030] Train loss: 0.0236
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[021/030] Train loss: 0.0236
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[022/030] Train loss: 0.0235
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[023/030] Train loss: 0.0235
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[024/030] Train loss: 0.0234
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[025/030] Train loss: 0.0235
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[026/030] Train loss: 0.0235
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[027/030] Train loss: 0.0236
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[028/030] Train loss: 0.0234
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[029/030] Train loss: 0.0235
2023-02-06 11:33:07 | Train | Epoch[258/600] Iteration[030/030] Train loss: 0.0235
2023-02-06 11:33:07 | Valid | Epoch[258/600] Iteration[001/008] Valid loss: 0.0878
2023-02-06 11:33:07 | Valid | Epoch[258/600] Iteration[002/008] Valid loss: 0.0595
2023-02-06 11:33:07 | Valid | Epoch[258/600] Iteration[003/008] Valid loss: 0.0521
2023-02-06 11:33:07 | Valid | Epoch[258/600] Iteration[004/008] Valid loss: 0.0521
2023-02-06 11:33:07 | Valid | Epoch[258/600] Iteration[005/008] Valid loss: 0.0547
2023-02-06 11:33:07 | Valid | Epoch[258/600] Iteration[006/008] Valid loss: 0.0539
2023-02-06 11:33:08 | Valid | Epoch[258/600] Iteration[007/008] Valid loss: 0.0560
2023-02-06 11:33:08 | Valid | Epoch[258/600] Iteration[008/008] Valid loss: 0.0541
2023-02-06 11:33:08 | Valid | Epoch[258/600] MIou: 0.9405165967659992
2023-02-06 11:33:08 | Valid | Epoch[258/600] Pixel Accuracy: 0.9897753397623698
2023-02-06 11:33:08 | Valid | Epoch[258/600] Mean Pixel Accuracy: 0.966000140174117
2023-02-06 11:33:08 | Stage | Epoch[258/600] Train loss:0.0235
2023-02-06 11:33:08 | Stage | Epoch[258/600] Valid loss:0.0541
2023-02-06 11:33:08 | Stage | Epoch[258/600] LR:0.01

2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[001/030] Train loss: 0.0233
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[005/030] Train loss: 0.0238
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[006/030] Train loss: 0.0233
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[007/030] Train loss: 0.0228
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[009/030] Train loss: 0.0232
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[010/030] Train loss: 0.0235
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[011/030] Train loss: 0.0236
2023-02-06 11:33:08 | Train | Epoch[259/600] Iteration[012/030] Train loss: 0.0234
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[013/030] Train loss: 0.0234
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[014/030] Train loss: 0.0236
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[015/030] Train loss: 0.0237
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[016/030] Train loss: 0.0237
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[017/030] Train loss: 0.0237
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[018/030] Train loss: 0.0235
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[019/030] Train loss: 0.0234
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[020/030] Train loss: 0.0234
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[021/030] Train loss: 0.0235
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[022/030] Train loss: 0.0237
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[023/030] Train loss: 0.0237
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[024/030] Train loss: 0.0237
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[025/030] Train loss: 0.0237
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[026/030] Train loss: 0.0239
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[027/030] Train loss: 0.0237
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[028/030] Train loss: 0.0239
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[029/030] Train loss: 0.0238
2023-02-06 11:33:09 | Train | Epoch[259/600] Iteration[030/030] Train loss: 0.0238
2023-02-06 11:33:10 | Valid | Epoch[259/600] Iteration[001/008] Valid loss: 0.1350
2023-02-06 11:33:10 | Valid | Epoch[259/600] Iteration[002/008] Valid loss: 0.0869
2023-02-06 11:33:10 | Valid | Epoch[259/600] Iteration[003/008] Valid loss: 0.0755
2023-02-06 11:33:10 | Valid | Epoch[259/600] Iteration[004/008] Valid loss: 0.0764
2023-02-06 11:33:10 | Valid | Epoch[259/600] Iteration[005/008] Valid loss: 0.0806
2023-02-06 11:33:10 | Valid | Epoch[259/600] Iteration[006/008] Valid loss: 0.0778
2023-02-06 11:33:10 | Valid | Epoch[259/600] Iteration[007/008] Valid loss: 0.0818
2023-02-06 11:33:10 | Valid | Epoch[259/600] Iteration[008/008] Valid loss: 0.0787
2023-02-06 11:33:10 | Valid | Epoch[259/600] MIou: 0.9394812693885091
2023-02-06 11:33:10 | Valid | Epoch[259/600] Pixel Accuracy: 0.9894739786783854
2023-02-06 11:33:10 | Valid | Epoch[259/600] Mean Pixel Accuracy: 0.9705835124321676
2023-02-06 11:33:10 | Stage | Epoch[259/600] Train loss:0.0238
2023-02-06 11:33:10 | Stage | Epoch[259/600] Valid loss:0.0787
2023-02-06 11:33:10 | Stage | Epoch[259/600] LR:0.01

2023-02-06 11:33:10 | Train | Epoch[260/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:33:10 | Train | Epoch[260/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:33:10 | Train | Epoch[260/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:33:10 | Train | Epoch[260/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:33:10 | Train | Epoch[260/600] Iteration[005/030] Train loss: 0.0230
2023-02-06 11:33:10 | Train | Epoch[260/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[007/030] Train loss: 0.0224
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[008/030] Train loss: 0.0222
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[009/030] Train loss: 0.0226
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[011/030] Train loss: 0.0227
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[012/030] Train loss: 0.0227
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[013/030] Train loss: 0.0229
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[014/030] Train loss: 0.0228
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[015/030] Train loss: 0.0227
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[016/030] Train loss: 0.0230
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[017/030] Train loss: 0.0230
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[018/030] Train loss: 0.0230
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[019/030] Train loss: 0.0230
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[020/030] Train loss: 0.0230
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[021/030] Train loss: 0.0229
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[022/030] Train loss: 0.0229
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[023/030] Train loss: 0.0230
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[024/030] Train loss: 0.0232
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[025/030] Train loss: 0.0231
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[026/030] Train loss: 0.0232
2023-02-06 11:33:11 | Train | Epoch[260/600] Iteration[027/030] Train loss: 0.0234
2023-02-06 11:33:12 | Train | Epoch[260/600] Iteration[028/030] Train loss: 0.0233
2023-02-06 11:33:12 | Train | Epoch[260/600] Iteration[029/030] Train loss: 0.0234
2023-02-06 11:33:12 | Train | Epoch[260/600] Iteration[030/030] Train loss: 0.0234
2023-02-06 11:33:12 | Valid | Epoch[260/600] Iteration[001/008] Valid loss: 0.3173
2023-02-06 11:33:12 | Valid | Epoch[260/600] Iteration[002/008] Valid loss: 0.2280
2023-02-06 11:33:12 | Valid | Epoch[260/600] Iteration[003/008] Valid loss: 0.2174
2023-02-06 11:33:12 | Valid | Epoch[260/600] Iteration[004/008] Valid loss: 0.2164
2023-02-06 11:33:12 | Valid | Epoch[260/600] Iteration[005/008] Valid loss: 0.2311
2023-02-06 11:33:12 | Valid | Epoch[260/600] Iteration[006/008] Valid loss: 0.2248
2023-02-06 11:33:12 | Valid | Epoch[260/600] Iteration[007/008] Valid loss: 0.2467
2023-02-06 11:33:12 | Valid | Epoch[260/600] Iteration[008/008] Valid loss: 0.2449
2023-02-06 11:33:12 | Valid | Epoch[260/600] MIou: 0.9215590473020627
2023-02-06 11:33:12 | Valid | Epoch[260/600] Pixel Accuracy: 0.9855308532714844
2023-02-06 11:33:12 | Valid | Epoch[260/600] Mean Pixel Accuracy: 0.9811795716921201
2023-02-06 11:33:12 | Stage | Epoch[260/600] Train loss:0.0234
2023-02-06 11:33:12 | Stage | Epoch[260/600] Valid loss:0.2449
2023-02-06 11:33:12 | Stage | Epoch[260/600] LR:0.01

2023-02-06 11:33:12 | Train | Epoch[261/600] Iteration[001/030] Train loss: 0.0217
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[002/030] Train loss: 0.0226
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[003/030] Train loss: 0.0224
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[004/030] Train loss: 0.0226
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[005/030] Train loss: 0.0233
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[006/030] Train loss: 0.0231
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[007/030] Train loss: 0.0231
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[008/030] Train loss: 0.0232
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[009/030] Train loss: 0.0230
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[010/030] Train loss: 0.0230
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[011/030] Train loss: 0.0232
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[012/030] Train loss: 0.0229
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[014/030] Train loss: 0.0225
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[015/030] Train loss: 0.0224
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[016/030] Train loss: 0.0224
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[017/030] Train loss: 0.0223
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[018/030] Train loss: 0.0224
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[019/030] Train loss: 0.0225
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[020/030] Train loss: 0.0228
2023-02-06 11:33:13 | Train | Epoch[261/600] Iteration[021/030] Train loss: 0.0230
2023-02-06 11:33:14 | Train | Epoch[261/600] Iteration[022/030] Train loss: 0.0232
2023-02-06 11:33:14 | Train | Epoch[261/600] Iteration[023/030] Train loss: 0.0233
2023-02-06 11:33:14 | Train | Epoch[261/600] Iteration[024/030] Train loss: 0.0234
2023-02-06 11:33:14 | Train | Epoch[261/600] Iteration[025/030] Train loss: 0.0234
2023-02-06 11:33:14 | Train | Epoch[261/600] Iteration[026/030] Train loss: 0.0233
2023-02-06 11:33:14 | Train | Epoch[261/600] Iteration[027/030] Train loss: 0.0232
2023-02-06 11:33:14 | Train | Epoch[261/600] Iteration[028/030] Train loss: 0.0232
2023-02-06 11:33:14 | Train | Epoch[261/600] Iteration[029/030] Train loss: 0.0233
2023-02-06 11:33:14 | Train | Epoch[261/600] Iteration[030/030] Train loss: 0.0232
2023-02-06 11:33:14 | Valid | Epoch[261/600] Iteration[001/008] Valid loss: 0.2692
2023-02-06 11:33:14 | Valid | Epoch[261/600] Iteration[002/008] Valid loss: 0.1835
2023-02-06 11:33:14 | Valid | Epoch[261/600] Iteration[003/008] Valid loss: 0.1650
2023-02-06 11:33:14 | Valid | Epoch[261/600] Iteration[004/008] Valid loss: 0.1721
2023-02-06 11:33:14 | Valid | Epoch[261/600] Iteration[005/008] Valid loss: 0.1835
2023-02-06 11:33:14 | Valid | Epoch[261/600] Iteration[006/008] Valid loss: 0.1788
2023-02-06 11:33:14 | Valid | Epoch[261/600] Iteration[007/008] Valid loss: 0.1948
2023-02-06 11:33:14 | Valid | Epoch[261/600] Iteration[008/008] Valid loss: 0.1909
2023-02-06 11:33:14 | Valid | Epoch[261/600] MIou: 0.9267706693255122
2023-02-06 11:33:14 | Valid | Epoch[261/600] Pixel Accuracy: 0.9866536458333334
2023-02-06 11:33:14 | Valid | Epoch[261/600] Mean Pixel Accuracy: 0.9805856763112497
2023-02-06 11:33:14 | Stage | Epoch[261/600] Train loss:0.0232
2023-02-06 11:33:14 | Stage | Epoch[261/600] Valid loss:0.1909
2023-02-06 11:33:14 | Stage | Epoch[261/600] LR:0.01

2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[001/030] Train loss: 0.0240
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[002/030] Train loss: 0.0228
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[003/030] Train loss: 0.0227
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[004/030] Train loss: 0.0228
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[005/030] Train loss: 0.0224
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[007/030] Train loss: 0.0225
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[008/030] Train loss: 0.0225
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[009/030] Train loss: 0.0223
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[011/030] Train loss: 0.0223
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[012/030] Train loss: 0.0225
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[013/030] Train loss: 0.0224
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[014/030] Train loss: 0.0224
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[015/030] Train loss: 0.0223
2023-02-06 11:33:15 | Train | Epoch[262/600] Iteration[016/030] Train loss: 0.0223
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[017/030] Train loss: 0.0225
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[018/030] Train loss: 0.0229
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[019/030] Train loss: 0.0231
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[020/030] Train loss: 0.0232
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[021/030] Train loss: 0.0231
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[022/030] Train loss: 0.0232
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[023/030] Train loss: 0.0233
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[024/030] Train loss: 0.0232
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[025/030] Train loss: 0.0231
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[026/030] Train loss: 0.0231
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[027/030] Train loss: 0.0231
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[028/030] Train loss: 0.0230
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[029/030] Train loss: 0.0231
2023-02-06 11:33:16 | Train | Epoch[262/600] Iteration[030/030] Train loss: 0.0230
2023-02-06 11:33:16 | Valid | Epoch[262/600] Iteration[001/008] Valid loss: 0.0959
2023-02-06 11:33:16 | Valid | Epoch[262/600] Iteration[002/008] Valid loss: 0.0640
2023-02-06 11:33:17 | Valid | Epoch[262/600] Iteration[003/008] Valid loss: 0.0551
2023-02-06 11:33:17 | Valid | Epoch[262/600] Iteration[004/008] Valid loss: 0.0530
2023-02-06 11:33:17 | Valid | Epoch[262/600] Iteration[005/008] Valid loss: 0.0543
2023-02-06 11:33:17 | Valid | Epoch[262/600] Iteration[006/008] Valid loss: 0.0525
2023-02-06 11:33:17 | Valid | Epoch[262/600] Iteration[007/008] Valid loss: 0.0551
2023-02-06 11:33:17 | Valid | Epoch[262/600] Iteration[008/008] Valid loss: 0.0537
2023-02-06 11:33:17 | Valid | Epoch[262/600] MIou: 0.9403313738136174
2023-02-06 11:33:17 | Valid | Epoch[262/600] Pixel Accuracy: 0.989782969156901
2023-02-06 11:33:17 | Valid | Epoch[262/600] Mean Pixel Accuracy: 0.9640134255599442
2023-02-06 11:33:17 | Stage | Epoch[262/600] Train loss:0.0230
2023-02-06 11:33:17 | Stage | Epoch[262/600] Valid loss:0.0537
2023-02-06 11:33:17 | Stage | Epoch[262/600] LR:0.01

2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[002/030] Train loss: 0.0225
2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[003/030] Train loss: 0.0219
2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[004/030] Train loss: 0.0216
2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[006/030] Train loss: 0.0225
2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[007/030] Train loss: 0.0231
2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[008/030] Train loss: 0.0232
2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[009/030] Train loss: 0.0231
2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 11:33:17 | Train | Epoch[263/600] Iteration[011/030] Train loss: 0.0225
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[012/030] Train loss: 0.0224
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[013/030] Train loss: 0.0229
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[014/030] Train loss: 0.0227
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[015/030] Train loss: 0.0228
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[016/030] Train loss: 0.0228
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[017/030] Train loss: 0.0231
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[018/030] Train loss: 0.0233
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[019/030] Train loss: 0.0232
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[020/030] Train loss: 0.0231
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[021/030] Train loss: 0.0231
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[022/030] Train loss: 0.0233
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[023/030] Train loss: 0.0238
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[024/030] Train loss: 0.0237
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[025/030] Train loss: 0.0237
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[026/030] Train loss: 0.0237
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[027/030] Train loss: 0.0238
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[028/030] Train loss: 0.0238
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[029/030] Train loss: 0.0238
2023-02-06 11:33:18 | Train | Epoch[263/600] Iteration[030/030] Train loss: 0.0239
2023-02-06 11:33:19 | Valid | Epoch[263/600] Iteration[001/008] Valid loss: 0.1160
2023-02-06 11:33:19 | Valid | Epoch[263/600] Iteration[002/008] Valid loss: 0.0783
2023-02-06 11:33:19 | Valid | Epoch[263/600] Iteration[003/008] Valid loss: 0.0669
2023-02-06 11:33:19 | Valid | Epoch[263/600] Iteration[004/008] Valid loss: 0.0614
2023-02-06 11:33:19 | Valid | Epoch[263/600] Iteration[005/008] Valid loss: 0.0652
2023-02-06 11:33:19 | Valid | Epoch[263/600] Iteration[006/008] Valid loss: 0.0624
2023-02-06 11:33:19 | Valid | Epoch[263/600] Iteration[007/008] Valid loss: 0.0631
2023-02-06 11:33:19 | Valid | Epoch[263/600] Iteration[008/008] Valid loss: 0.0626
2023-02-06 11:33:19 | Valid | Epoch[263/600] MIou: 0.9344399625097315
2023-02-06 11:33:19 | Valid | Epoch[263/600] Pixel Accuracy: 0.9887110392252604
2023-02-06 11:33:19 | Valid | Epoch[263/600] Mean Pixel Accuracy: 0.9609768251491457
2023-02-06 11:33:19 | Stage | Epoch[263/600] Train loss:0.0239
2023-02-06 11:33:19 | Stage | Epoch[263/600] Valid loss:0.0626
2023-02-06 11:33:19 | Stage | Epoch[263/600] LR:0.01

2023-02-06 11:33:19 | Train | Epoch[264/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 11:33:19 | Train | Epoch[264/600] Iteration[002/030] Train loss: 0.0237
2023-02-06 11:33:19 | Train | Epoch[264/600] Iteration[003/030] Train loss: 0.0242
2023-02-06 11:33:19 | Train | Epoch[264/600] Iteration[004/030] Train loss: 0.0234
2023-02-06 11:33:19 | Train | Epoch[264/600] Iteration[005/030] Train loss: 0.0231
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[006/030] Train loss: 0.0229
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[007/030] Train loss: 0.0228
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[008/030] Train loss: 0.0230
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[009/030] Train loss: 0.0231
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[010/030] Train loss: 0.0233
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[011/030] Train loss: 0.0232
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[012/030] Train loss: 0.0232
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[013/030] Train loss: 0.0234
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[014/030] Train loss: 0.0233
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[015/030] Train loss: 0.0233
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[016/030] Train loss: 0.0234
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[017/030] Train loss: 0.0232
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[018/030] Train loss: 0.0234
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[019/030] Train loss: 0.0235
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[020/030] Train loss: 0.0235
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[021/030] Train loss: 0.0233
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[022/030] Train loss: 0.0231
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[023/030] Train loss: 0.0231
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[024/030] Train loss: 0.0232
2023-02-06 11:33:20 | Train | Epoch[264/600] Iteration[025/030] Train loss: 0.0231
2023-02-06 11:33:21 | Train | Epoch[264/600] Iteration[026/030] Train loss: 0.0231
2023-02-06 11:33:21 | Train | Epoch[264/600] Iteration[027/030] Train loss: 0.0231
2023-02-06 11:33:21 | Train | Epoch[264/600] Iteration[028/030] Train loss: 0.0232
2023-02-06 11:33:21 | Train | Epoch[264/600] Iteration[029/030] Train loss: 0.0232
2023-02-06 11:33:21 | Train | Epoch[264/600] Iteration[030/030] Train loss: 0.0233
2023-02-06 11:33:21 | Valid | Epoch[264/600] Iteration[001/008] Valid loss: 0.0656
2023-02-06 11:33:21 | Valid | Epoch[264/600] Iteration[002/008] Valid loss: 0.0651
2023-02-06 11:33:21 | Valid | Epoch[264/600] Iteration[003/008] Valid loss: 0.0657
2023-02-06 11:33:21 | Valid | Epoch[264/600] Iteration[004/008] Valid loss: 0.0636
2023-02-06 11:33:21 | Valid | Epoch[264/600] Iteration[005/008] Valid loss: 0.0660
2023-02-06 11:33:21 | Valid | Epoch[264/600] Iteration[006/008] Valid loss: 0.0643
2023-02-06 11:33:21 | Valid | Epoch[264/600] Iteration[007/008] Valid loss: 0.0621
2023-02-06 11:33:21 | Valid | Epoch[264/600] Iteration[008/008] Valid loss: 0.0641
2023-02-06 11:33:21 | Valid | Epoch[264/600] MIou: 0.796229553252173
2023-02-06 11:33:21 | Valid | Epoch[264/600] Pixel Accuracy: 0.9663798014322916
2023-02-06 11:33:21 | Valid | Epoch[264/600] Mean Pixel Accuracy: 0.8142973093408056
2023-02-06 11:33:21 | Stage | Epoch[264/600] Train loss:0.0233
2023-02-06 11:33:21 | Stage | Epoch[264/600] Valid loss:0.0641
2023-02-06 11:33:21 | Stage | Epoch[264/600] LR:0.01

2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[001/030] Train loss: 0.0257
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[002/030] Train loss: 0.0245
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[003/030] Train loss: 0.0232
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[004/030] Train loss: 0.0228
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[005/030] Train loss: 0.0221
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[006/030] Train loss: 0.0230
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[008/030] Train loss: 0.0232
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[010/030] Train loss: 0.0229
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[011/030] Train loss: 0.0228
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[012/030] Train loss: 0.0230
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[013/030] Train loss: 0.0231
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[014/030] Train loss: 0.0233
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[015/030] Train loss: 0.0232
2023-02-06 11:33:22 | Train | Epoch[265/600] Iteration[016/030] Train loss: 0.0231
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[017/030] Train loss: 0.0230
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[018/030] Train loss: 0.0230
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[019/030] Train loss: 0.0230
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[020/030] Train loss: 0.0230
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[021/030] Train loss: 0.0229
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[022/030] Train loss: 0.0229
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[023/030] Train loss: 0.0229
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[024/030] Train loss: 0.0229
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[025/030] Train loss: 0.0229
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[026/030] Train loss: 0.0228
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[027/030] Train loss: 0.0229
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[028/030] Train loss: 0.0229
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[029/030] Train loss: 0.0229
2023-02-06 11:33:23 | Train | Epoch[265/600] Iteration[030/030] Train loss: 0.0229
2023-02-06 11:33:23 | Valid | Epoch[265/600] Iteration[001/008] Valid loss: 0.0429
2023-02-06 11:33:24 | Valid | Epoch[265/600] Iteration[002/008] Valid loss: 0.0368
2023-02-06 11:33:24 | Valid | Epoch[265/600] Iteration[003/008] Valid loss: 0.0357
2023-02-06 11:33:24 | Valid | Epoch[265/600] Iteration[004/008] Valid loss: 0.0340
2023-02-06 11:33:24 | Valid | Epoch[265/600] Iteration[005/008] Valid loss: 0.0350
2023-02-06 11:33:24 | Valid | Epoch[265/600] Iteration[006/008] Valid loss: 0.0344
2023-02-06 11:33:24 | Valid | Epoch[265/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 11:33:24 | Valid | Epoch[265/600] Iteration[008/008] Valid loss: 0.0341
2023-02-06 11:33:24 | Valid | Epoch[265/600] MIou: 0.8984080811972044
2023-02-06 11:33:24 | Valid | Epoch[265/600] Pixel Accuracy: 0.9831873575846354
2023-02-06 11:33:24 | Valid | Epoch[265/600] Mean Pixel Accuracy: 0.9096580835756463
2023-02-06 11:33:24 | Stage | Epoch[265/600] Train loss:0.0229
2023-02-06 11:33:24 | Stage | Epoch[265/600] Valid loss:0.0341
2023-02-06 11:33:24 | Stage | Epoch[265/600] LR:0.01

2023-02-06 11:33:24 | Train | Epoch[266/600] Iteration[001/030] Train loss: 0.0193
2023-02-06 11:33:24 | Train | Epoch[266/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 11:33:24 | Train | Epoch[266/600] Iteration[003/030] Train loss: 0.0218
2023-02-06 11:33:24 | Train | Epoch[266/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:33:24 | Train | Epoch[266/600] Iteration[005/030] Train loss: 0.0221
2023-02-06 11:33:24 | Train | Epoch[266/600] Iteration[006/030] Train loss: 0.0219
2023-02-06 11:33:24 | Train | Epoch[266/600] Iteration[007/030] Train loss: 0.0221
2023-02-06 11:33:24 | Train | Epoch[266/600] Iteration[008/030] Train loss: 0.0219
2023-02-06 11:33:24 | Train | Epoch[266/600] Iteration[009/030] Train loss: 0.0221
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[010/030] Train loss: 0.0223
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[011/030] Train loss: 0.0225
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[012/030] Train loss: 0.0224
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[013/030] Train loss: 0.0224
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[014/030] Train loss: 0.0224
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[015/030] Train loss: 0.0225
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[016/030] Train loss: 0.0226
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[017/030] Train loss: 0.0228
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[018/030] Train loss: 0.0231
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[019/030] Train loss: 0.0234
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[020/030] Train loss: 0.0233
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[021/030] Train loss: 0.0232
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[022/030] Train loss: 0.0232
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[023/030] Train loss: 0.0233
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[024/030] Train loss: 0.0231
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[025/030] Train loss: 0.0231
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[026/030] Train loss: 0.0231
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[027/030] Train loss: 0.0233
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[028/030] Train loss: 0.0233
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[029/030] Train loss: 0.0232
2023-02-06 11:33:25 | Train | Epoch[266/600] Iteration[030/030] Train loss: 0.0233
2023-02-06 11:33:26 | Valid | Epoch[266/600] Iteration[001/008] Valid loss: 0.2392
2023-02-06 11:33:26 | Valid | Epoch[266/600] Iteration[002/008] Valid loss: 0.1651
2023-02-06 11:33:26 | Valid | Epoch[266/600] Iteration[003/008] Valid loss: 0.1468
2023-02-06 11:33:26 | Valid | Epoch[266/600] Iteration[004/008] Valid loss: 0.1458
2023-02-06 11:33:26 | Valid | Epoch[266/600] Iteration[005/008] Valid loss: 0.1570
2023-02-06 11:33:26 | Valid | Epoch[266/600] Iteration[006/008] Valid loss: 0.1553
2023-02-06 11:33:26 | Valid | Epoch[266/600] Iteration[007/008] Valid loss: 0.1637
2023-02-06 11:33:26 | Valid | Epoch[266/600] Iteration[008/008] Valid loss: 0.1614
2023-02-06 11:33:26 | Valid | Epoch[266/600] MIou: 0.9307154663730881
2023-02-06 11:33:26 | Valid | Epoch[266/600] Pixel Accuracy: 0.9874839782714844
2023-02-06 11:33:26 | Valid | Epoch[266/600] Mean Pixel Accuracy: 0.9802304820785334
2023-02-06 11:33:26 | Stage | Epoch[266/600] Train loss:0.0233
2023-02-06 11:33:26 | Stage | Epoch[266/600] Valid loss:0.1614
2023-02-06 11:33:26 | Stage | Epoch[266/600] LR:0.01

2023-02-06 11:33:26 | Train | Epoch[267/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 11:33:26 | Train | Epoch[267/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[003/030] Train loss: 0.0225
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[004/030] Train loss: 0.0222
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[005/030] Train loss: 0.0221
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[006/030] Train loss: 0.0220
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[007/030] Train loss: 0.0227
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[008/030] Train loss: 0.0227
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[010/030] Train loss: 0.0227
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[011/030] Train loss: 0.0228
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[012/030] Train loss: 0.0229
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[013/030] Train loss: 0.0229
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[014/030] Train loss: 0.0231
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[015/030] Train loss: 0.0229
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[016/030] Train loss: 0.0230
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[017/030] Train loss: 0.0231
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[018/030] Train loss: 0.0230
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[019/030] Train loss: 0.0229
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[020/030] Train loss: 0.0230
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[021/030] Train loss: 0.0231
2023-02-06 11:33:27 | Train | Epoch[267/600] Iteration[022/030] Train loss: 0.0230
2023-02-06 11:33:28 | Train | Epoch[267/600] Iteration[023/030] Train loss: 0.0230
2023-02-06 11:33:28 | Train | Epoch[267/600] Iteration[024/030] Train loss: 0.0230
2023-02-06 11:33:28 | Train | Epoch[267/600] Iteration[025/030] Train loss: 0.0230
2023-02-06 11:33:28 | Train | Epoch[267/600] Iteration[026/030] Train loss: 0.0231
2023-02-06 11:33:28 | Train | Epoch[267/600] Iteration[027/030] Train loss: 0.0231
2023-02-06 11:33:28 | Train | Epoch[267/600] Iteration[028/030] Train loss: 0.0231
2023-02-06 11:33:28 | Train | Epoch[267/600] Iteration[029/030] Train loss: 0.0230
2023-02-06 11:33:28 | Train | Epoch[267/600] Iteration[030/030] Train loss: 0.0229
2023-02-06 11:33:28 | Valid | Epoch[267/600] Iteration[001/008] Valid loss: 0.0496
2023-02-06 11:33:28 | Valid | Epoch[267/600] Iteration[002/008] Valid loss: 0.0460
2023-02-06 11:33:28 | Valid | Epoch[267/600] Iteration[003/008] Valid loss: 0.0456
2023-02-06 11:33:28 | Valid | Epoch[267/600] Iteration[004/008] Valid loss: 0.0437
2023-02-06 11:33:28 | Valid | Epoch[267/600] Iteration[005/008] Valid loss: 0.0448
2023-02-06 11:33:28 | Valid | Epoch[267/600] Iteration[006/008] Valid loss: 0.0440
2023-02-06 11:33:28 | Valid | Epoch[267/600] Iteration[007/008] Valid loss: 0.0434
2023-02-06 11:33:28 | Valid | Epoch[267/600] Iteration[008/008] Valid loss: 0.0442
2023-02-06 11:33:28 | Valid | Epoch[267/600] MIou: 0.8601235991881044
2023-02-06 11:33:28 | Valid | Epoch[267/600] Pixel Accuracy: 0.9769058227539062
2023-02-06 11:33:28 | Valid | Epoch[267/600] Mean Pixel Accuracy: 0.8734062249997077
2023-02-06 11:33:28 | Stage | Epoch[267/600] Train loss:0.0229
2023-02-06 11:33:28 | Stage | Epoch[267/600] Valid loss:0.0442
2023-02-06 11:33:28 | Stage | Epoch[267/600] LR:0.01

2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[002/030] Train loss: 0.0216
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[004/030] Train loss: 0.0215
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[005/030] Train loss: 0.0216
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[007/030] Train loss: 0.0227
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[011/030] Train loss: 0.0226
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[014/030] Train loss: 0.0227
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 11:33:29 | Train | Epoch[268/600] Iteration[016/030] Train loss: 0.0226
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[017/030] Train loss: 0.0227
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[018/030] Train loss: 0.0232
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[019/030] Train loss: 0.0231
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[020/030] Train loss: 0.0230
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[021/030] Train loss: 0.0228
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[022/030] Train loss: 0.0228
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[023/030] Train loss: 0.0229
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[024/030] Train loss: 0.0230
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[025/030] Train loss: 0.0230
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[026/030] Train loss: 0.0229
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[027/030] Train loss: 0.0228
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[028/030] Train loss: 0.0230
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[029/030] Train loss: 0.0228
2023-02-06 11:33:30 | Train | Epoch[268/600] Iteration[030/030] Train loss: 0.0230
2023-02-06 11:33:30 | Valid | Epoch[268/600] Iteration[001/008] Valid loss: 0.3238
2023-02-06 11:33:30 | Valid | Epoch[268/600] Iteration[002/008] Valid loss: 0.2475
2023-02-06 11:33:30 | Valid | Epoch[268/600] Iteration[003/008] Valid loss: 0.2374
2023-02-06 11:33:31 | Valid | Epoch[268/600] Iteration[004/008] Valid loss: 0.2385
2023-02-06 11:33:31 | Valid | Epoch[268/600] Iteration[005/008] Valid loss: 0.2528
2023-02-06 11:33:31 | Valid | Epoch[268/600] Iteration[006/008] Valid loss: 0.2424
2023-02-06 11:33:31 | Valid | Epoch[268/600] Iteration[007/008] Valid loss: 0.2659
2023-02-06 11:33:31 | Valid | Epoch[268/600] Iteration[008/008] Valid loss: 0.2647
2023-02-06 11:33:31 | Valid | Epoch[268/600] MIou: 0.9170345880903
2023-02-06 11:33:31 | Valid | Epoch[268/600] Pixel Accuracy: 0.9845466613769531
2023-02-06 11:33:31 | Valid | Epoch[268/600] Mean Pixel Accuracy: 0.9813107078323973
2023-02-06 11:33:31 | Stage | Epoch[268/600] Train loss:0.0230
2023-02-06 11:33:31 | Stage | Epoch[268/600] Valid loss:0.2647
2023-02-06 11:33:31 | Stage | Epoch[268/600] LR:0.01

2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[002/030] Train loss: 0.0210
2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[004/030] Train loss: 0.0224
2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[005/030] Train loss: 0.0233
2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[006/030] Train loss: 0.0234
2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[007/030] Train loss: 0.0231
2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[008/030] Train loss: 0.0234
2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[009/030] Train loss: 0.0235
2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[010/030] Train loss: 0.0235
2023-02-06 11:33:31 | Train | Epoch[269/600] Iteration[011/030] Train loss: 0.0234
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[012/030] Train loss: 0.0232
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[013/030] Train loss: 0.0231
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[014/030] Train loss: 0.0229
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[015/030] Train loss: 0.0230
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[016/030] Train loss: 0.0230
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[017/030] Train loss: 0.0230
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[018/030] Train loss: 0.0231
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[019/030] Train loss: 0.0231
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[020/030] Train loss: 0.0231
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[021/030] Train loss: 0.0231
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[022/030] Train loss: 0.0229
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[023/030] Train loss: 0.0229
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[024/030] Train loss: 0.0228
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[025/030] Train loss: 0.0228
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[026/030] Train loss: 0.0230
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[027/030] Train loss: 0.0231
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[028/030] Train loss: 0.0230
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[029/030] Train loss: 0.0230
2023-02-06 11:33:32 | Train | Epoch[269/600] Iteration[030/030] Train loss: 0.0229
2023-02-06 11:33:33 | Valid | Epoch[269/600] Iteration[001/008] Valid loss: 0.0472
2023-02-06 11:33:33 | Valid | Epoch[269/600] Iteration[002/008] Valid loss: 0.0372
2023-02-06 11:33:33 | Valid | Epoch[269/600] Iteration[003/008] Valid loss: 0.0343
2023-02-06 11:33:33 | Valid | Epoch[269/600] Iteration[004/008] Valid loss: 0.0331
2023-02-06 11:33:33 | Valid | Epoch[269/600] Iteration[005/008] Valid loss: 0.0341
2023-02-06 11:33:33 | Valid | Epoch[269/600] Iteration[006/008] Valid loss: 0.0334
2023-02-06 11:33:33 | Valid | Epoch[269/600] Iteration[007/008] Valid loss: 0.0335
2023-02-06 11:33:33 | Valid | Epoch[269/600] Iteration[008/008] Valid loss: 0.0330
2023-02-06 11:33:33 | Valid | Epoch[269/600] MIou: 0.923762292125391
2023-02-06 11:33:33 | Valid | Epoch[269/600] Pixel Accuracy: 0.9872703552246094
2023-02-06 11:33:33 | Valid | Epoch[269/600] Mean Pixel Accuracy: 0.9369661571014651
2023-02-06 11:33:33 | Stage | Epoch[269/600] Train loss:0.0229
2023-02-06 11:33:33 | Stage | Epoch[269/600] Valid loss:0.0330
2023-02-06 11:33:33 | Stage | Epoch[269/600] LR:0.01

2023-02-06 11:33:33 | Train | Epoch[270/600] Iteration[001/030] Train loss: 0.0290
2023-02-06 11:33:33 | Train | Epoch[270/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 11:33:33 | Train | Epoch[270/600] Iteration[003/030] Train loss: 0.0248
2023-02-06 11:33:33 | Train | Epoch[270/600] Iteration[004/030] Train loss: 0.0241
2023-02-06 11:33:33 | Train | Epoch[270/600] Iteration[005/030] Train loss: 0.0245
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[008/030] Train loss: 0.0239
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[009/030] Train loss: 0.0238
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[010/030] Train loss: 0.0237
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[011/030] Train loss: 0.0236
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[012/030] Train loss: 0.0238
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[013/030] Train loss: 0.0237
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[014/030] Train loss: 0.0235
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[015/030] Train loss: 0.0232
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[016/030] Train loss: 0.0232
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[017/030] Train loss: 0.0231
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[018/030] Train loss: 0.0231
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[019/030] Train loss: 0.0233
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[020/030] Train loss: 0.0233
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[021/030] Train loss: 0.0232
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[022/030] Train loss: 0.0231
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[023/030] Train loss: 0.0230
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[024/030] Train loss: 0.0230
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[025/030] Train loss: 0.0232
2023-02-06 11:33:34 | Train | Epoch[270/600] Iteration[026/030] Train loss: 0.0231
2023-02-06 11:33:35 | Train | Epoch[270/600] Iteration[027/030] Train loss: 0.0233
2023-02-06 11:33:35 | Train | Epoch[270/600] Iteration[028/030] Train loss: 0.0234
2023-02-06 11:33:35 | Train | Epoch[270/600] Iteration[029/030] Train loss: 0.0235
2023-02-06 11:33:35 | Train | Epoch[270/600] Iteration[030/030] Train loss: 0.0235
2023-02-06 11:33:35 | Valid | Epoch[270/600] Iteration[001/008] Valid loss: 0.4515
2023-02-06 11:33:35 | Valid | Epoch[270/600] Iteration[002/008] Valid loss: 0.3675
2023-02-06 11:33:35 | Valid | Epoch[270/600] Iteration[003/008] Valid loss: 0.3613
2023-02-06 11:33:35 | Valid | Epoch[270/600] Iteration[004/008] Valid loss: 0.3615
2023-02-06 11:33:35 | Valid | Epoch[270/600] Iteration[005/008] Valid loss: 0.3836
2023-02-06 11:33:35 | Valid | Epoch[270/600] Iteration[006/008] Valid loss: 0.3727
2023-02-06 11:33:35 | Valid | Epoch[270/600] Iteration[007/008] Valid loss: 0.3988
2023-02-06 11:33:35 | Valid | Epoch[270/600] Iteration[008/008] Valid loss: 0.3997
2023-02-06 11:33:35 | Valid | Epoch[270/600] MIou: 0.9052559448430135
2023-02-06 11:33:35 | Valid | Epoch[270/600] Pixel Accuracy: 0.9817911783854166
2023-02-06 11:33:35 | Valid | Epoch[270/600] Mean Pixel Accuracy: 0.984519828138241
2023-02-06 11:33:35 | Stage | Epoch[270/600] Train loss:0.0235
2023-02-06 11:33:35 | Stage | Epoch[270/600] Valid loss:0.3997
2023-02-06 11:33:35 | Stage | Epoch[270/600] LR:0.01

2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[001/030] Train loss: 0.0333
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[002/030] Train loss: 0.0308
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[003/030] Train loss: 0.0282
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[007/030] Train loss: 0.0264
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[009/030] Train loss: 0.0263
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 11:33:36 | Train | Epoch[271/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:33:37 | Train | Epoch[271/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 11:33:37 | Train | Epoch[271/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 11:33:37 | Train | Epoch[271/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 11:33:37 | Train | Epoch[271/600] Iteration[024/030] Train loss: 0.0248
2023-02-06 11:33:37 | Train | Epoch[271/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 11:33:37 | Train | Epoch[271/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 11:33:37 | Train | Epoch[271/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 11:33:37 | Train | Epoch[271/600] Iteration[028/030] Train loss: 0.0247
2023-02-06 11:33:37 | Train | Epoch[271/600] Iteration[029/030] Train loss: 0.0245
2023-02-06 11:33:37 | Train | Epoch[271/600] Iteration[030/030] Train loss: 0.0244
2023-02-06 11:33:37 | Valid | Epoch[271/600] Iteration[001/008] Valid loss: 0.0590
2023-02-06 11:33:37 | Valid | Epoch[271/600] Iteration[002/008] Valid loss: 0.0572
2023-02-06 11:33:37 | Valid | Epoch[271/600] Iteration[003/008] Valid loss: 0.0583
2023-02-06 11:33:37 | Valid | Epoch[271/600] Iteration[004/008] Valid loss: 0.0566
2023-02-06 11:33:37 | Valid | Epoch[271/600] Iteration[005/008] Valid loss: 0.0580
2023-02-06 11:33:37 | Valid | Epoch[271/600] Iteration[006/008] Valid loss: 0.0574
2023-02-06 11:33:37 | Valid | Epoch[271/600] Iteration[007/008] Valid loss: 0.0558
2023-02-06 11:33:37 | Valid | Epoch[271/600] Iteration[008/008] Valid loss: 0.0577
2023-02-06 11:33:38 | Valid | Epoch[271/600] MIou: 0.7919478957775539
2023-02-06 11:33:38 | Valid | Epoch[271/600] Pixel Accuracy: 0.9656842549641927
2023-02-06 11:33:38 | Valid | Epoch[271/600] Mean Pixel Accuracy: 0.810256555275129
2023-02-06 11:33:38 | Stage | Epoch[271/600] Train loss:0.0244
2023-02-06 11:33:38 | Stage | Epoch[271/600] Valid loss:0.0577
2023-02-06 11:33:38 | Stage | Epoch[271/600] LR:0.01

2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[002/030] Train loss: 0.0226
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[003/030] Train loss: 0.0216
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[004/030] Train loss: 0.0224
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[005/030] Train loss: 0.0222
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[006/030] Train loss: 0.0226
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[008/030] Train loss: 0.0228
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[010/030] Train loss: 0.0223
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[011/030] Train loss: 0.0229
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[012/030] Train loss: 0.0228
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 11:33:38 | Train | Epoch[272/600] Iteration[014/030] Train loss: 0.0229
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[015/030] Train loss: 0.0229
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[016/030] Train loss: 0.0227
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[017/030] Train loss: 0.0225
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[018/030] Train loss: 0.0226
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[019/030] Train loss: 0.0227
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[020/030] Train loss: 0.0226
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[021/030] Train loss: 0.0227
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[022/030] Train loss: 0.0228
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[023/030] Train loss: 0.0228
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[024/030] Train loss: 0.0228
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[025/030] Train loss: 0.0228
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[026/030] Train loss: 0.0227
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[028/030] Train loss: 0.0226
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[029/030] Train loss: 0.0226
2023-02-06 11:33:39 | Train | Epoch[272/600] Iteration[030/030] Train loss: 0.0227
2023-02-06 11:33:40 | Valid | Epoch[272/600] Iteration[001/008] Valid loss: 0.0476
2023-02-06 11:33:40 | Valid | Epoch[272/600] Iteration[002/008] Valid loss: 0.0455
2023-02-06 11:33:40 | Valid | Epoch[272/600] Iteration[003/008] Valid loss: 0.0458
2023-02-06 11:33:40 | Valid | Epoch[272/600] Iteration[004/008] Valid loss: 0.0439
2023-02-06 11:33:40 | Valid | Epoch[272/600] Iteration[005/008] Valid loss: 0.0448
2023-02-06 11:33:40 | Valid | Epoch[272/600] Iteration[006/008] Valid loss: 0.0442
2023-02-06 11:33:40 | Valid | Epoch[272/600] Iteration[007/008] Valid loss: 0.0427
2023-02-06 11:33:40 | Valid | Epoch[272/600] Iteration[008/008] Valid loss: 0.0437
2023-02-06 11:33:40 | Valid | Epoch[272/600] MIou: 0.8548235071668986
2023-02-06 11:33:40 | Valid | Epoch[272/600] Pixel Accuracy: 0.9760653177897135
2023-02-06 11:33:40 | Valid | Epoch[272/600] Mean Pixel Accuracy: 0.8679923393737834
2023-02-06 11:33:40 | Stage | Epoch[272/600] Train loss:0.0227
2023-02-06 11:33:40 | Stage | Epoch[272/600] Valid loss:0.0437
2023-02-06 11:33:40 | Stage | Epoch[272/600] LR:0.01

2023-02-06 11:33:40 | Train | Epoch[273/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 11:33:40 | Train | Epoch[273/600] Iteration[002/030] Train loss: 0.0226
2023-02-06 11:33:40 | Train | Epoch[273/600] Iteration[003/030] Train loss: 0.0230
2023-02-06 11:33:40 | Train | Epoch[273/600] Iteration[004/030] Train loss: 0.0234
2023-02-06 11:33:40 | Train | Epoch[273/600] Iteration[005/030] Train loss: 0.0229
2023-02-06 11:33:40 | Train | Epoch[273/600] Iteration[006/030] Train loss: 0.0228
2023-02-06 11:33:40 | Train | Epoch[273/600] Iteration[007/030] Train loss: 0.0233
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[008/030] Train loss: 0.0234
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[009/030] Train loss: 0.0230
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[010/030] Train loss: 0.0231
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[011/030] Train loss: 0.0230
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[012/030] Train loss: 0.0228
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[013/030] Train loss: 0.0229
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[014/030] Train loss: 0.0227
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[016/030] Train loss: 0.0227
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[017/030] Train loss: 0.0227
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[018/030] Train loss: 0.0233
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[019/030] Train loss: 0.0233
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[020/030] Train loss: 0.0233
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[021/030] Train loss: 0.0233
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[022/030] Train loss: 0.0233
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[023/030] Train loss: 0.0232
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[024/030] Train loss: 0.0232
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[025/030] Train loss: 0.0233
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[026/030] Train loss: 0.0231
2023-02-06 11:33:41 | Train | Epoch[273/600] Iteration[027/030] Train loss: 0.0233
2023-02-06 11:33:42 | Train | Epoch[273/600] Iteration[028/030] Train loss: 0.0233
2023-02-06 11:33:42 | Train | Epoch[273/600] Iteration[029/030] Train loss: 0.0232
2023-02-06 11:33:42 | Train | Epoch[273/600] Iteration[030/030] Train loss: 0.0233
2023-02-06 11:33:42 | Valid | Epoch[273/600] Iteration[001/008] Valid loss: 0.3985
2023-02-06 11:33:42 | Valid | Epoch[273/600] Iteration[002/008] Valid loss: 0.4050
2023-02-06 11:33:42 | Valid | Epoch[273/600] Iteration[003/008] Valid loss: 0.4267
2023-02-06 11:33:42 | Valid | Epoch[273/600] Iteration[004/008] Valid loss: 0.4262
2023-02-06 11:33:42 | Valid | Epoch[273/600] Iteration[005/008] Valid loss: 0.4404
2023-02-06 11:33:42 | Valid | Epoch[273/600] Iteration[006/008] Valid loss: 0.4374
2023-02-06 11:33:42 | Valid | Epoch[273/600] Iteration[007/008] Valid loss: 0.4369
2023-02-06 11:33:42 | Valid | Epoch[273/600] Iteration[008/008] Valid loss: 0.4554
2023-02-06 11:33:42 | Valid | Epoch[273/600] MIou: 0.4548409779866536
2023-02-06 11:33:42 | Valid | Epoch[273/600] Pixel Accuracy: 0.9096819559733073
2023-02-06 11:33:42 | Valid | Epoch[273/600] Mean Pixel Accuracy: 0.5
2023-02-06 11:33:42 | Stage | Epoch[273/600] Train loss:0.0233
2023-02-06 11:33:42 | Stage | Epoch[273/600] Valid loss:0.4554
2023-02-06 11:33:42 | Stage | Epoch[273/600] LR:0.01

2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[002/030] Train loss: 0.0236
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[005/030] Train loss: 0.0240
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[006/030] Train loss: 0.0234
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[007/030] Train loss: 0.0233
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[008/030] Train loss: 0.0235
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[009/030] Train loss: 0.0233
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[010/030] Train loss: 0.0230
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[011/030] Train loss: 0.0228
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[012/030] Train loss: 0.0230
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[014/030] Train loss: 0.0224
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[015/030] Train loss: 0.0223
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[016/030] Train loss: 0.0226
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[018/030] Train loss: 0.0225
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[019/030] Train loss: 0.0224
2023-02-06 11:33:43 | Train | Epoch[274/600] Iteration[020/030] Train loss: 0.0223
2023-02-06 11:33:44 | Train | Epoch[274/600] Iteration[021/030] Train loss: 0.0223
2023-02-06 11:33:44 | Train | Epoch[274/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:33:44 | Train | Epoch[274/600] Iteration[023/030] Train loss: 0.0225
2023-02-06 11:33:44 | Train | Epoch[274/600] Iteration[024/030] Train loss: 0.0225
2023-02-06 11:33:44 | Train | Epoch[274/600] Iteration[025/030] Train loss: 0.0225
2023-02-06 11:33:44 | Train | Epoch[274/600] Iteration[026/030] Train loss: 0.0226
2023-02-06 11:33:44 | Train | Epoch[274/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:33:44 | Train | Epoch[274/600] Iteration[028/030] Train loss: 0.0227
2023-02-06 11:33:44 | Train | Epoch[274/600] Iteration[029/030] Train loss: 0.0229
2023-02-06 11:33:44 | Train | Epoch[274/600] Iteration[030/030] Train loss: 0.0232
2023-02-06 11:33:44 | Valid | Epoch[274/600] Iteration[001/008] Valid loss: 1.2823
2023-02-06 11:33:44 | Valid | Epoch[274/600] Iteration[002/008] Valid loss: 1.2415
2023-02-06 11:33:44 | Valid | Epoch[274/600] Iteration[003/008] Valid loss: 1.2684
2023-02-06 11:33:44 | Valid | Epoch[274/600] Iteration[004/008] Valid loss: 1.3016
2023-02-06 11:33:44 | Valid | Epoch[274/600] Iteration[005/008] Valid loss: 1.3489
2023-02-06 11:33:44 | Valid | Epoch[274/600] Iteration[006/008] Valid loss: 1.3217
2023-02-06 11:33:44 | Valid | Epoch[274/600] Iteration[007/008] Valid loss: 1.3788
2023-02-06 11:33:44 | Valid | Epoch[274/600] Iteration[008/008] Valid loss: 1.4178
2023-02-06 11:33:45 | Valid | Epoch[274/600] MIou: 0.8282890527649972
2023-02-06 11:33:45 | Valid | Epoch[274/600] Pixel Accuracy: 0.961273193359375
2023-02-06 11:33:45 | Valid | Epoch[274/600] Mean Pixel Accuracy: 0.9770845942333521
2023-02-06 11:33:45 | Stage | Epoch[274/600] Train loss:0.0232
2023-02-06 11:33:45 | Stage | Epoch[274/600] Valid loss:1.4178
2023-02-06 11:33:45 | Stage | Epoch[274/600] LR:0.01

2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[001/030] Train loss: 0.0272
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[008/030] Train loss: 0.0242
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[009/030] Train loss: 0.0238
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[010/030] Train loss: 0.0243
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[011/030] Train loss: 0.0241
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 11:33:45 | Train | Epoch[275/600] Iteration[014/030] Train loss: 0.0240
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[015/030] Train loss: 0.0238
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[016/030] Train loss: 0.0237
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[017/030] Train loss: 0.0237
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[018/030] Train loss: 0.0236
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[019/030] Train loss: 0.0236
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[020/030] Train loss: 0.0236
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[021/030] Train loss: 0.0237
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[022/030] Train loss: 0.0235
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[023/030] Train loss: 0.0236
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[024/030] Train loss: 0.0237
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[025/030] Train loss: 0.0239
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[026/030] Train loss: 0.0239
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[027/030] Train loss: 0.0238
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[028/030] Train loss: 0.0238
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[029/030] Train loss: 0.0238
2023-02-06 11:33:46 | Train | Epoch[275/600] Iteration[030/030] Train loss: 0.0238
2023-02-06 11:33:47 | Valid | Epoch[275/600] Iteration[001/008] Valid loss: 0.1604
2023-02-06 11:33:47 | Valid | Epoch[275/600] Iteration[002/008] Valid loss: 0.1666
2023-02-06 11:33:47 | Valid | Epoch[275/600] Iteration[003/008] Valid loss: 0.1754
2023-02-06 11:33:47 | Valid | Epoch[275/600] Iteration[004/008] Valid loss: 0.1722
2023-02-06 11:33:47 | Valid | Epoch[275/600] Iteration[005/008] Valid loss: 0.1767
2023-02-06 11:33:47 | Valid | Epoch[275/600] Iteration[006/008] Valid loss: 0.1745
2023-02-06 11:33:47 | Valid | Epoch[275/600] Iteration[007/008] Valid loss: 0.1702
2023-02-06 11:33:47 | Valid | Epoch[275/600] Iteration[008/008] Valid loss: 0.1781
2023-02-06 11:33:47 | Valid | Epoch[275/600] MIou: 0.5095517171921784
2023-02-06 11:33:47 | Valid | Epoch[275/600] Pixel Accuracy: 0.9188079833984375
2023-02-06 11:33:47 | Valid | Epoch[275/600] Mean Pixel Accuracy: 0.5505216179307043
2023-02-06 11:33:47 | Stage | Epoch[275/600] Train loss:0.0238
2023-02-06 11:33:47 | Stage | Epoch[275/600] Valid loss:0.1781
2023-02-06 11:33:47 | Stage | Epoch[275/600] LR:0.01

2023-02-06 11:33:47 | Train | Epoch[276/600] Iteration[001/030] Train loss: 0.0238
2023-02-06 11:33:47 | Train | Epoch[276/600] Iteration[002/030] Train loss: 0.0253
2023-02-06 11:33:47 | Train | Epoch[276/600] Iteration[003/030] Train loss: 0.0248
2023-02-06 11:33:47 | Train | Epoch[276/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 11:33:47 | Train | Epoch[276/600] Iteration[005/030] Train loss: 0.0241
2023-02-06 11:33:47 | Train | Epoch[276/600] Iteration[006/030] Train loss: 0.0238
2023-02-06 11:33:47 | Train | Epoch[276/600] Iteration[007/030] Train loss: 0.0232
2023-02-06 11:33:47 | Train | Epoch[276/600] Iteration[008/030] Train loss: 0.0231
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[009/030] Train loss: 0.0231
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[010/030] Train loss: 0.0232
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[011/030] Train loss: 0.0236
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[012/030] Train loss: 0.0236
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[013/030] Train loss: 0.0235
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[014/030] Train loss: 0.0234
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[015/030] Train loss: 0.0234
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[016/030] Train loss: 0.0235
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[017/030] Train loss: 0.0234
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[018/030] Train loss: 0.0234
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[019/030] Train loss: 0.0232
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[020/030] Train loss: 0.0232
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[021/030] Train loss: 0.0231
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[022/030] Train loss: 0.0232
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[023/030] Train loss: 0.0231
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[024/030] Train loss: 0.0231
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[025/030] Train loss: 0.0232
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[026/030] Train loss: 0.0231
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[027/030] Train loss: 0.0231
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[028/030] Train loss: 0.0231
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[029/030] Train loss: 0.0230
2023-02-06 11:33:48 | Train | Epoch[276/600] Iteration[030/030] Train loss: 0.0230
2023-02-06 11:33:49 | Valid | Epoch[276/600] Iteration[001/008] Valid loss: 0.0423
2023-02-06 11:33:49 | Valid | Epoch[276/600] Iteration[002/008] Valid loss: 0.0389
2023-02-06 11:33:49 | Valid | Epoch[276/600] Iteration[003/008] Valid loss: 0.0385
2023-02-06 11:33:49 | Valid | Epoch[276/600] Iteration[004/008] Valid loss: 0.0366
2023-02-06 11:33:49 | Valid | Epoch[276/600] Iteration[005/008] Valid loss: 0.0371
2023-02-06 11:33:49 | Valid | Epoch[276/600] Iteration[006/008] Valid loss: 0.0371
2023-02-06 11:33:49 | Valid | Epoch[276/600] Iteration[007/008] Valid loss: 0.0363
2023-02-06 11:33:49 | Valid | Epoch[276/600] Iteration[008/008] Valid loss: 0.0370
2023-02-06 11:33:49 | Valid | Epoch[276/600] MIou: 0.8735564020936029
2023-02-06 11:33:49 | Valid | Epoch[276/600] Pixel Accuracy: 0.9791145324707031
2023-02-06 11:33:49 | Valid | Epoch[276/600] Mean Pixel Accuracy: 0.8859569891228491
2023-02-06 11:33:49 | Stage | Epoch[276/600] Train loss:0.0230
2023-02-06 11:33:49 | Stage | Epoch[276/600] Valid loss:0.0370
2023-02-06 11:33:49 | Stage | Epoch[276/600] LR:0.01

2023-02-06 11:33:49 | Train | Epoch[277/600] Iteration[001/030] Train loss: 0.0262
2023-02-06 11:33:49 | Train | Epoch[277/600] Iteration[002/030] Train loss: 0.0239
2023-02-06 11:33:49 | Train | Epoch[277/600] Iteration[003/030] Train loss: 0.0235
2023-02-06 11:33:49 | Train | Epoch[277/600] Iteration[004/030] Train loss: 0.0230
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[005/030] Train loss: 0.0229
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[006/030] Train loss: 0.0231
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[007/030] Train loss: 0.0234
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[008/030] Train loss: 0.0232
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[009/030] Train loss: 0.0228
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[011/030] Train loss: 0.0225
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[012/030] Train loss: 0.0225
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[014/030] Train loss: 0.0227
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[015/030] Train loss: 0.0225
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[016/030] Train loss: 0.0224
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[018/030] Train loss: 0.0223
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[019/030] Train loss: 0.0224
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[020/030] Train loss: 0.0225
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[021/030] Train loss: 0.0226
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[023/030] Train loss: 0.0223
2023-02-06 11:33:50 | Train | Epoch[277/600] Iteration[024/030] Train loss: 0.0223
2023-02-06 11:33:51 | Train | Epoch[277/600] Iteration[025/030] Train loss: 0.0226
2023-02-06 11:33:51 | Train | Epoch[277/600] Iteration[026/030] Train loss: 0.0226
2023-02-06 11:33:51 | Train | Epoch[277/600] Iteration[027/030] Train loss: 0.0225
2023-02-06 11:33:51 | Train | Epoch[277/600] Iteration[028/030] Train loss: 0.0226
2023-02-06 11:33:51 | Train | Epoch[277/600] Iteration[029/030] Train loss: 0.0226
2023-02-06 11:33:51 | Train | Epoch[277/600] Iteration[030/030] Train loss: 0.0228
2023-02-06 11:33:51 | Valid | Epoch[277/600] Iteration[001/008] Valid loss: 0.0661
2023-02-06 11:33:51 | Valid | Epoch[277/600] Iteration[002/008] Valid loss: 0.0641
2023-02-06 11:33:51 | Valid | Epoch[277/600] Iteration[003/008] Valid loss: 0.0645
2023-02-06 11:33:51 | Valid | Epoch[277/600] Iteration[004/008] Valid loss: 0.0622
2023-02-06 11:33:51 | Valid | Epoch[277/600] Iteration[005/008] Valid loss: 0.0629
2023-02-06 11:33:51 | Valid | Epoch[277/600] Iteration[006/008] Valid loss: 0.0612
2023-02-06 11:33:51 | Valid | Epoch[277/600] Iteration[007/008] Valid loss: 0.0592
2023-02-06 11:33:51 | Valid | Epoch[277/600] Iteration[008/008] Valid loss: 0.0611
2023-02-06 11:33:51 | Valid | Epoch[277/600] MIou: 0.8091085068856239
2023-02-06 11:33:51 | Valid | Epoch[277/600] Pixel Accuracy: 0.9685338338216146
2023-02-06 11:33:51 | Valid | Epoch[277/600] Mean Pixel Accuracy: 0.8258606092745115
2023-02-06 11:33:51 | Stage | Epoch[277/600] Train loss:0.0228
2023-02-06 11:33:51 | Stage | Epoch[277/600] Valid loss:0.0611
2023-02-06 11:33:51 | Stage | Epoch[277/600] LR:0.01

2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[001/030] Train loss: 0.0223
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[002/030] Train loss: 0.0219
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[003/030] Train loss: 0.0221
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[004/030] Train loss: 0.0223
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[005/030] Train loss: 0.0222
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[006/030] Train loss: 0.0223
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[007/030] Train loss: 0.0224
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[008/030] Train loss: 0.0223
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[009/030] Train loss: 0.0223
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[010/030] Train loss: 0.0221
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[012/030] Train loss: 0.0217
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[013/030] Train loss: 0.0217
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[014/030] Train loss: 0.0219
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[017/030] Train loss: 0.0218
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[018/030] Train loss: 0.0218
2023-02-06 11:33:52 | Train | Epoch[278/600] Iteration[019/030] Train loss: 0.0218
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[020/030] Train loss: 0.0218
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[021/030] Train loss: 0.0219
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[023/030] Train loss: 0.0222
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[024/030] Train loss: 0.0224
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[025/030] Train loss: 0.0224
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[029/030] Train loss: 0.0226
2023-02-06 11:33:53 | Train | Epoch[278/600] Iteration[030/030] Train loss: 0.0225
2023-02-06 11:33:53 | Valid | Epoch[278/600] Iteration[001/008] Valid loss: 0.8291
2023-02-06 11:33:53 | Valid | Epoch[278/600] Iteration[002/008] Valid loss: 0.7633
2023-02-06 11:33:53 | Valid | Epoch[278/600] Iteration[003/008] Valid loss: 0.7603
2023-02-06 11:33:53 | Valid | Epoch[278/600] Iteration[004/008] Valid loss: 0.7761
2023-02-06 11:33:53 | Valid | Epoch[278/600] Iteration[005/008] Valid loss: 0.8106
2023-02-06 11:33:53 | Valid | Epoch[278/600] Iteration[006/008] Valid loss: 0.7952
2023-02-06 11:33:53 | Valid | Epoch[278/600] Iteration[007/008] Valid loss: 0.8326
2023-02-06 11:33:54 | Valid | Epoch[278/600] Iteration[008/008] Valid loss: 0.8428
2023-02-06 11:33:54 | Valid | Epoch[278/600] MIou: 0.8677906676669315
2023-02-06 11:33:54 | Valid | Epoch[278/600] Pixel Accuracy: 0.9725151062011719
2023-02-06 11:33:54 | Valid | Epoch[278/600] Mean Pixel Accuracy: 0.982616900892958
2023-02-06 11:33:54 | Stage | Epoch[278/600] Train loss:0.0225
2023-02-06 11:33:54 | Stage | Epoch[278/600] Valid loss:0.8428
2023-02-06 11:33:54 | Stage | Epoch[278/600] LR:0.01

2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[001/030] Train loss: 0.0227
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[003/030] Train loss: 0.0251
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[004/030] Train loss: 0.0240
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[005/030] Train loss: 0.0234
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[006/030] Train loss: 0.0228
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[007/030] Train loss: 0.0228
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[009/030] Train loss: 0.0226
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[010/030] Train loss: 0.0227
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[011/030] Train loss: 0.0228
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:33:54 | Train | Epoch[279/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[014/030] Train loss: 0.0225
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[015/030] Train loss: 0.0224
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[016/030] Train loss: 0.0221
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[017/030] Train loss: 0.0223
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[018/030] Train loss: 0.0223
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[019/030] Train loss: 0.0224
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[020/030] Train loss: 0.0225
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[021/030] Train loss: 0.0223
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[023/030] Train loss: 0.0226
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[024/030] Train loss: 0.0226
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[025/030] Train loss: 0.0227
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[026/030] Train loss: 0.0227
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[028/030] Train loss: 0.0227
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 11:33:55 | Train | Epoch[279/600] Iteration[030/030] Train loss: 0.0224
2023-02-06 11:33:56 | Valid | Epoch[279/600] Iteration[001/008] Valid loss: 0.1461
2023-02-06 11:33:56 | Valid | Epoch[279/600] Iteration[002/008] Valid loss: 0.1001
2023-02-06 11:33:56 | Valid | Epoch[279/600] Iteration[003/008] Valid loss: 0.0878
2023-02-06 11:33:56 | Valid | Epoch[279/600] Iteration[004/008] Valid loss: 0.0880
2023-02-06 11:33:56 | Valid | Epoch[279/600] Iteration[005/008] Valid loss: 0.0921
2023-02-06 11:33:56 | Valid | Epoch[279/600] Iteration[006/008] Valid loss: 0.0915
2023-02-06 11:33:56 | Valid | Epoch[279/600] Iteration[007/008] Valid loss: 0.0967
2023-02-06 11:33:56 | Valid | Epoch[279/600] Iteration[008/008] Valid loss: 0.0935
2023-02-06 11:33:56 | Valid | Epoch[279/600] MIou: 0.9393821799902716
2023-02-06 11:33:56 | Valid | Epoch[279/600] Pixel Accuracy: 0.9892896016438802
2023-02-06 11:33:56 | Valid | Epoch[279/600] Mean Pixel Accuracy: 0.9780590344074486
2023-02-06 11:33:56 | Stage | Epoch[279/600] Train loss:0.0224
2023-02-06 11:33:56 | Stage | Epoch[279/600] Valid loss:0.0935
2023-02-06 11:33:56 | Stage | Epoch[279/600] LR:0.01

2023-02-06 11:33:56 | Train | Epoch[280/600] Iteration[001/030] Train loss: 0.0174
2023-02-06 11:33:56 | Train | Epoch[280/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:33:56 | Train | Epoch[280/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:33:56 | Train | Epoch[280/600] Iteration[004/030] Train loss: 0.0216
2023-02-06 11:33:56 | Train | Epoch[280/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:33:56 | Train | Epoch[280/600] Iteration[006/030] Train loss: 0.0217
2023-02-06 11:33:56 | Train | Epoch[280/600] Iteration[007/030] Train loss: 0.0221
2023-02-06 11:33:56 | Train | Epoch[280/600] Iteration[008/030] Train loss: 0.0221
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[009/030] Train loss: 0.0221
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[011/030] Train loss: 0.0223
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[012/030] Train loss: 0.0223
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[013/030] Train loss: 0.0222
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[014/030] Train loss: 0.0224
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[015/030] Train loss: 0.0223
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[016/030] Train loss: 0.0224
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[018/030] Train loss: 0.0224
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[019/030] Train loss: 0.0222
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[020/030] Train loss: 0.0222
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[021/030] Train loss: 0.0222
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[022/030] Train loss: 0.0222
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[023/030] Train loss: 0.0223
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[024/030] Train loss: 0.0225
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[025/030] Train loss: 0.0225
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[026/030] Train loss: 0.0225
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:33:57 | Train | Epoch[280/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:33:58 | Train | Epoch[280/600] Iteration[029/030] Train loss: 0.0224
2023-02-06 11:33:58 | Train | Epoch[280/600] Iteration[030/030] Train loss: 0.0225
2023-02-06 11:33:58 | Valid | Epoch[280/600] Iteration[001/008] Valid loss: 0.1294
2023-02-06 11:33:58 | Valid | Epoch[280/600] Iteration[002/008] Valid loss: 0.0861
2023-02-06 11:33:58 | Valid | Epoch[280/600] Iteration[003/008] Valid loss: 0.0741
2023-02-06 11:33:58 | Valid | Epoch[280/600] Iteration[004/008] Valid loss: 0.0735
2023-02-06 11:33:58 | Valid | Epoch[280/600] Iteration[005/008] Valid loss: 0.0848
2023-02-06 11:33:58 | Valid | Epoch[280/600] Iteration[006/008] Valid loss: 0.0831
2023-02-06 11:33:58 | Valid | Epoch[280/600] Iteration[007/008] Valid loss: 0.0842
2023-02-06 11:33:58 | Valid | Epoch[280/600] Iteration[008/008] Valid loss: 0.0812
2023-02-06 11:33:58 | Valid | Epoch[280/600] MIou: 0.9388082343021393
2023-02-06 11:33:58 | Valid | Epoch[280/600] Pixel Accuracy: 0.9893315633138021
2023-02-06 11:33:58 | Valid | Epoch[280/600] Mean Pixel Accuracy: 0.9710631963669872
2023-02-06 11:33:58 | Stage | Epoch[280/600] Train loss:0.0225
2023-02-06 11:33:58 | Stage | Epoch[280/600] Valid loss:0.0812
2023-02-06 11:33:58 | Stage | Epoch[280/600] LR:0.01

2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[003/030] Train loss: 0.0214
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[007/030] Train loss: 0.0213
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[008/030] Train loss: 0.0217
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[009/030] Train loss: 0.0219
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[010/030] Train loss: 0.0219
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[012/030] Train loss: 0.0217
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[013/030] Train loss: 0.0220
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[014/030] Train loss: 0.0219
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[015/030] Train loss: 0.0219
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[016/030] Train loss: 0.0222
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[017/030] Train loss: 0.0223
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[018/030] Train loss: 0.0226
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[019/030] Train loss: 0.0226
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[020/030] Train loss: 0.0226
2023-02-06 11:33:59 | Train | Epoch[281/600] Iteration[021/030] Train loss: 0.0225
2023-02-06 11:34:00 | Train | Epoch[281/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:34:00 | Train | Epoch[281/600] Iteration[023/030] Train loss: 0.0224
2023-02-06 11:34:00 | Train | Epoch[281/600] Iteration[024/030] Train loss: 0.0224
2023-02-06 11:34:00 | Train | Epoch[281/600] Iteration[025/030] Train loss: 0.0225
2023-02-06 11:34:00 | Train | Epoch[281/600] Iteration[026/030] Train loss: 0.0226
2023-02-06 11:34:00 | Train | Epoch[281/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:34:00 | Train | Epoch[281/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:34:00 | Train | Epoch[281/600] Iteration[029/030] Train loss: 0.0224
2023-02-06 11:34:00 | Train | Epoch[281/600] Iteration[030/030] Train loss: 0.0227
2023-02-06 11:34:00 | Valid | Epoch[281/600] Iteration[001/008] Valid loss: 0.0951
2023-02-06 11:34:00 | Valid | Epoch[281/600] Iteration[002/008] Valid loss: 0.0626
2023-02-06 11:34:00 | Valid | Epoch[281/600] Iteration[003/008] Valid loss: 0.0541
2023-02-06 11:34:00 | Valid | Epoch[281/600] Iteration[004/008] Valid loss: 0.0510
2023-02-06 11:34:00 | Valid | Epoch[281/600] Iteration[005/008] Valid loss: 0.0532
2023-02-06 11:34:00 | Valid | Epoch[281/600] Iteration[006/008] Valid loss: 0.0522
2023-02-06 11:34:00 | Valid | Epoch[281/600] Iteration[007/008] Valid loss: 0.0531
2023-02-06 11:34:00 | Valid | Epoch[281/600] Iteration[008/008] Valid loss: 0.0518
2023-02-06 11:34:01 | Valid | Epoch[281/600] MIou: 0.936338254540268
2023-02-06 11:34:01 | Valid | Epoch[281/600] Pixel Accuracy: 0.9891204833984375
2023-02-06 11:34:01 | Valid | Epoch[281/600] Mean Pixel Accuracy: 0.9592870507324474
2023-02-06 11:34:01 | Stage | Epoch[281/600] Train loss:0.0227
2023-02-06 11:34:01 | Stage | Epoch[281/600] Valid loss:0.0518
2023-02-06 11:34:01 | Stage | Epoch[281/600] LR:0.01

2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[004/030] Train loss: 0.0220
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[005/030] Train loss: 0.0222
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[006/030] Train loss: 0.0218
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[007/030] Train loss: 0.0221
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[008/030] Train loss: 0.0220
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[009/030] Train loss: 0.0222
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[010/030] Train loss: 0.0219
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[011/030] Train loss: 0.0217
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[012/030] Train loss: 0.0218
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[013/030] Train loss: 0.0217
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[014/030] Train loss: 0.0221
2023-02-06 11:34:01 | Train | Epoch[282/600] Iteration[015/030] Train loss: 0.0220
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[016/030] Train loss: 0.0221
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[017/030] Train loss: 0.0223
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[018/030] Train loss: 0.0222
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[019/030] Train loss: 0.0223
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[020/030] Train loss: 0.0222
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[021/030] Train loss: 0.0223
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[023/030] Train loss: 0.0225
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[024/030] Train loss: 0.0225
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[025/030] Train loss: 0.0225
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 11:34:02 | Train | Epoch[282/600] Iteration[030/030] Train loss: 0.0225
2023-02-06 11:34:03 | Valid | Epoch[282/600] Iteration[001/008] Valid loss: 0.0844
2023-02-06 11:34:03 | Valid | Epoch[282/600] Iteration[002/008] Valid loss: 0.0564
2023-02-06 11:34:03 | Valid | Epoch[282/600] Iteration[003/008] Valid loss: 0.0498
2023-02-06 11:34:03 | Valid | Epoch[282/600] Iteration[004/008] Valid loss: 0.0507
2023-02-06 11:34:03 | Valid | Epoch[282/600] Iteration[005/008] Valid loss: 0.0564
2023-02-06 11:34:03 | Valid | Epoch[282/600] Iteration[006/008] Valid loss: 0.0543
2023-02-06 11:34:03 | Valid | Epoch[282/600] Iteration[007/008] Valid loss: 0.0549
2023-02-06 11:34:03 | Valid | Epoch[282/600] Iteration[008/008] Valid loss: 0.0535
2023-02-06 11:34:03 | Valid | Epoch[282/600] MIou: 0.9343234977226202
2023-02-06 11:34:03 | Valid | Epoch[282/600] Pixel Accuracy: 0.9887619018554688
2023-02-06 11:34:03 | Valid | Epoch[282/600] Mean Pixel Accuracy: 0.9579486741511245
2023-02-06 11:34:03 | Stage | Epoch[282/600] Train loss:0.0225
2023-02-06 11:34:03 | Stage | Epoch[282/600] Valid loss:0.0535
2023-02-06 11:34:03 | Stage | Epoch[282/600] LR:0.01

2023-02-06 11:34:03 | Train | Epoch[283/600] Iteration[001/030] Train loss: 0.0264
2023-02-06 11:34:03 | Train | Epoch[283/600] Iteration[002/030] Train loss: 0.0246
2023-02-06 11:34:03 | Train | Epoch[283/600] Iteration[003/030] Train loss: 0.0235
2023-02-06 11:34:03 | Train | Epoch[283/600] Iteration[004/030] Train loss: 0.0227
2023-02-06 11:34:03 | Train | Epoch[283/600] Iteration[005/030] Train loss: 0.0229
2023-02-06 11:34:03 | Train | Epoch[283/600] Iteration[006/030] Train loss: 0.0229
2023-02-06 11:34:03 | Train | Epoch[283/600] Iteration[007/030] Train loss: 0.0229
2023-02-06 11:34:03 | Train | Epoch[283/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[009/030] Train loss: 0.0225
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[011/030] Train loss: 0.0225
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[012/030] Train loss: 0.0223
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[013/030] Train loss: 0.0221
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[014/030] Train loss: 0.0221
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[015/030] Train loss: 0.0225
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[016/030] Train loss: 0.0224
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[017/030] Train loss: 0.0225
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[018/030] Train loss: 0.0223
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[019/030] Train loss: 0.0226
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[020/030] Train loss: 0.0225
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[021/030] Train loss: 0.0227
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[022/030] Train loss: 0.0225
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[023/030] Train loss: 0.0225
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[024/030] Train loss: 0.0224
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[025/030] Train loss: 0.0225
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:34:04 | Train | Epoch[283/600] Iteration[028/030] Train loss: 0.0226
2023-02-06 11:34:05 | Train | Epoch[283/600] Iteration[029/030] Train loss: 0.0226
2023-02-06 11:34:05 | Train | Epoch[283/600] Iteration[030/030] Train loss: 0.0226
2023-02-06 11:34:05 | Valid | Epoch[283/600] Iteration[001/008] Valid loss: 0.0492
2023-02-06 11:34:05 | Valid | Epoch[283/600] Iteration[002/008] Valid loss: 0.0476
2023-02-06 11:34:05 | Valid | Epoch[283/600] Iteration[003/008] Valid loss: 0.0473
2023-02-06 11:34:05 | Valid | Epoch[283/600] Iteration[004/008] Valid loss: 0.0454
2023-02-06 11:34:05 | Valid | Epoch[283/600] Iteration[005/008] Valid loss: 0.0461
2023-02-06 11:34:05 | Valid | Epoch[283/600] Iteration[006/008] Valid loss: 0.0455
2023-02-06 11:34:05 | Valid | Epoch[283/600] Iteration[007/008] Valid loss: 0.0440
2023-02-06 11:34:05 | Valid | Epoch[283/600] Iteration[008/008] Valid loss: 0.0450
2023-02-06 11:34:05 | Valid | Epoch[283/600] MIou: 0.8469997406450233
2023-02-06 11:34:05 | Valid | Epoch[283/600] Pixel Accuracy: 0.9747810363769531
2023-02-06 11:34:05 | Valid | Epoch[283/600] Mean Pixel Accuracy: 0.8607113745780259
2023-02-06 11:34:05 | Stage | Epoch[283/600] Train loss:0.0226
2023-02-06 11:34:05 | Stage | Epoch[283/600] Valid loss:0.0450
2023-02-06 11:34:05 | Stage | Epoch[283/600] LR:0.01

2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[001/030] Train loss: 0.0219
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[003/030] Train loss: 0.0238
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[004/030] Train loss: 0.0240
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[005/030] Train loss: 0.0234
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[006/030] Train loss: 0.0232
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[007/030] Train loss: 0.0228
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[008/030] Train loss: 0.0227
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[009/030] Train loss: 0.0225
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[011/030] Train loss: 0.0225
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[012/030] Train loss: 0.0225
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[013/030] Train loss: 0.0223
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[014/030] Train loss: 0.0228
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[015/030] Train loss: 0.0227
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[016/030] Train loss: 0.0227
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[017/030] Train loss: 0.0225
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[018/030] Train loss: 0.0223
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[019/030] Train loss: 0.0223
2023-02-06 11:34:06 | Train | Epoch[284/600] Iteration[020/030] Train loss: 0.0222
2023-02-06 11:34:07 | Train | Epoch[284/600] Iteration[021/030] Train loss: 0.0222
2023-02-06 11:34:07 | Train | Epoch[284/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:34:07 | Train | Epoch[284/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:34:07 | Train | Epoch[284/600] Iteration[024/030] Train loss: 0.0221
2023-02-06 11:34:07 | Train | Epoch[284/600] Iteration[025/030] Train loss: 0.0221
2023-02-06 11:34:07 | Train | Epoch[284/600] Iteration[026/030] Train loss: 0.0223
2023-02-06 11:34:07 | Train | Epoch[284/600] Iteration[027/030] Train loss: 0.0222
2023-02-06 11:34:07 | Train | Epoch[284/600] Iteration[028/030] Train loss: 0.0221
2023-02-06 11:34:07 | Train | Epoch[284/600] Iteration[029/030] Train loss: 0.0222
2023-02-06 11:34:07 | Train | Epoch[284/600] Iteration[030/030] Train loss: 0.0220
2023-02-06 11:34:07 | Valid | Epoch[284/600] Iteration[001/008] Valid loss: 0.1528
2023-02-06 11:34:07 | Valid | Epoch[284/600] Iteration[002/008] Valid loss: 0.1005
2023-02-06 11:34:07 | Valid | Epoch[284/600] Iteration[003/008] Valid loss: 0.0882
2023-02-06 11:34:07 | Valid | Epoch[284/600] Iteration[004/008] Valid loss: 0.0896
2023-02-06 11:34:07 | Valid | Epoch[284/600] Iteration[005/008] Valid loss: 0.0949
2023-02-06 11:34:07 | Valid | Epoch[284/600] Iteration[006/008] Valid loss: 0.0925
2023-02-06 11:34:07 | Valid | Epoch[284/600] Iteration[007/008] Valid loss: 0.0998
2023-02-06 11:34:08 | Valid | Epoch[284/600] Iteration[008/008] Valid loss: 0.0961
2023-02-06 11:34:08 | Valid | Epoch[284/600] MIou: 0.9375361198937526
2023-02-06 11:34:08 | Valid | Epoch[284/600] Pixel Accuracy: 0.9889348347981771
2023-02-06 11:34:08 | Valid | Epoch[284/600] Mean Pixel Accuracy: 0.9774899515993973
2023-02-06 11:34:08 | Stage | Epoch[284/600] Train loss:0.0220
2023-02-06 11:34:08 | Stage | Epoch[284/600] Valid loss:0.0961
2023-02-06 11:34:08 | Stage | Epoch[284/600] LR:0.01

2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[001/030] Train loss: 0.0192
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[002/030] Train loss: 0.0206
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[003/030] Train loss: 0.0218
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[006/030] Train loss: 0.0209
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[007/030] Train loss: 0.0212
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[009/030] Train loss: 0.0214
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[011/030] Train loss: 0.0214
2023-02-06 11:34:08 | Train | Epoch[285/600] Iteration[012/030] Train loss: 0.0215
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[016/030] Train loss: 0.0217
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[017/030] Train loss: 0.0217
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[019/030] Train loss: 0.0221
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[020/030] Train loss: 0.0223
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[021/030] Train loss: 0.0222
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[022/030] Train loss: 0.0222
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[023/030] Train loss: 0.0223
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[025/030] Train loss: 0.0221
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[027/030] Train loss: 0.0222
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[028/030] Train loss: 0.0222
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[029/030] Train loss: 0.0223
2023-02-06 11:34:09 | Train | Epoch[285/600] Iteration[030/030] Train loss: 0.0223
2023-02-06 11:34:10 | Valid | Epoch[285/600] Iteration[001/008] Valid loss: 0.0763
2023-02-06 11:34:10 | Valid | Epoch[285/600] Iteration[002/008] Valid loss: 0.0513
2023-02-06 11:34:10 | Valid | Epoch[285/600] Iteration[003/008] Valid loss: 0.0452
2023-02-06 11:34:10 | Valid | Epoch[285/600] Iteration[004/008] Valid loss: 0.0433
2023-02-06 11:34:10 | Valid | Epoch[285/600] Iteration[005/008] Valid loss: 0.0458
2023-02-06 11:34:10 | Valid | Epoch[285/600] Iteration[006/008] Valid loss: 0.0449
2023-02-06 11:34:10 | Valid | Epoch[285/600] Iteration[007/008] Valid loss: 0.0452
2023-02-06 11:34:10 | Valid | Epoch[285/600] Iteration[008/008] Valid loss: 0.0437
2023-02-06 11:34:10 | Valid | Epoch[285/600] MIou: 0.9331546477132691
2023-02-06 11:34:10 | Valid | Epoch[285/600] Pixel Accuracy: 0.9887008666992188
2023-02-06 11:34:10 | Valid | Epoch[285/600] Mean Pixel Accuracy: 0.9512449505954551
2023-02-06 11:34:10 | Stage | Epoch[285/600] Train loss:0.0223
2023-02-06 11:34:10 | Stage | Epoch[285/600] Valid loss:0.0437
2023-02-06 11:34:10 | Stage | Epoch[285/600] LR:0.01

2023-02-06 11:34:10 | Train | Epoch[286/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 11:34:10 | Train | Epoch[286/600] Iteration[002/030] Train loss: 0.0214
2023-02-06 11:34:10 | Train | Epoch[286/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:34:10 | Train | Epoch[286/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[010/030] Train loss: 0.0219
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[011/030] Train loss: 0.0217
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[012/030] Train loss: 0.0220
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[013/030] Train loss: 0.0220
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[014/030] Train loss: 0.0219
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[016/030] Train loss: 0.0217
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[018/030] Train loss: 0.0221
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[019/030] Train loss: 0.0221
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[020/030] Train loss: 0.0222
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[021/030] Train loss: 0.0221
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[023/030] Train loss: 0.0223
2023-02-06 11:34:11 | Train | Epoch[286/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:34:12 | Train | Epoch[286/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:34:12 | Train | Epoch[286/600] Iteration[026/030] Train loss: 0.0225
2023-02-06 11:34:12 | Train | Epoch[286/600] Iteration[027/030] Train loss: 0.0225
2023-02-06 11:34:12 | Train | Epoch[286/600] Iteration[028/030] Train loss: 0.0226
2023-02-06 11:34:12 | Train | Epoch[286/600] Iteration[029/030] Train loss: 0.0226
2023-02-06 11:34:12 | Train | Epoch[286/600] Iteration[030/030] Train loss: 0.0225
2023-02-06 11:34:12 | Valid | Epoch[286/600] Iteration[001/008] Valid loss: 0.6885
2023-02-06 11:34:12 | Valid | Epoch[286/600] Iteration[002/008] Valid loss: 0.6709
2023-02-06 11:34:12 | Valid | Epoch[286/600] Iteration[003/008] Valid loss: 0.6704
2023-02-06 11:34:12 | Valid | Epoch[286/600] Iteration[004/008] Valid loss: 0.6805
2023-02-06 11:34:12 | Valid | Epoch[286/600] Iteration[005/008] Valid loss: 0.7050
2023-02-06 11:34:12 | Valid | Epoch[286/600] Iteration[006/008] Valid loss: 0.6937
2023-02-06 11:34:12 | Valid | Epoch[286/600] Iteration[007/008] Valid loss: 0.7328
2023-02-06 11:34:12 | Valid | Epoch[286/600] Iteration[008/008] Valid loss: 0.7409
2023-02-06 11:34:12 | Valid | Epoch[286/600] MIou: 0.8661880934886035
2023-02-06 11:34:12 | Valid | Epoch[286/600] Pixel Accuracy: 0.9720967610677084
2023-02-06 11:34:12 | Valid | Epoch[286/600] Mean Pixel Accuracy: 0.9823235558504972
2023-02-06 11:34:12 | Stage | Epoch[286/600] Train loss:0.0225
2023-02-06 11:34:12 | Stage | Epoch[286/600] Valid loss:0.7409
2023-02-06 11:34:12 | Stage | Epoch[286/600] LR:0.01

2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[002/030] Train loss: 0.0233
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[004/030] Train loss: 0.0234
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[005/030] Train loss: 0.0235
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[006/030] Train loss: 0.0237
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[010/030] Train loss: 0.0223
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[011/030] Train loss: 0.0227
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[012/030] Train loss: 0.0224
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[013/030] Train loss: 0.0227
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[014/030] Train loss: 0.0227
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[016/030] Train loss: 0.0226
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[017/030] Train loss: 0.0223
2023-02-06 11:34:13 | Train | Epoch[287/600] Iteration[018/030] Train loss: 0.0224
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[019/030] Train loss: 0.0223
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[020/030] Train loss: 0.0223
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[021/030] Train loss: 0.0223
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[022/030] Train loss: 0.0223
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[023/030] Train loss: 0.0223
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[025/030] Train loss: 0.0221
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[026/030] Train loss: 0.0223
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[027/030] Train loss: 0.0223
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[028/030] Train loss: 0.0224
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[029/030] Train loss: 0.0223
2023-02-06 11:34:14 | Train | Epoch[287/600] Iteration[030/030] Train loss: 0.0222
2023-02-06 11:34:14 | Valid | Epoch[287/600] Iteration[001/008] Valid loss: 0.1049
2023-02-06 11:34:14 | Valid | Epoch[287/600] Iteration[002/008] Valid loss: 0.1100
2023-02-06 11:34:14 | Valid | Epoch[287/600] Iteration[003/008] Valid loss: 0.1139
2023-02-06 11:34:15 | Valid | Epoch[287/600] Iteration[004/008] Valid loss: 0.1109
2023-02-06 11:34:15 | Valid | Epoch[287/600] Iteration[005/008] Valid loss: 0.1135
2023-02-06 11:34:15 | Valid | Epoch[287/600] Iteration[006/008] Valid loss: 0.1115
2023-02-06 11:34:15 | Valid | Epoch[287/600] Iteration[007/008] Valid loss: 0.1083
2023-02-06 11:34:15 | Valid | Epoch[287/600] Iteration[008/008] Valid loss: 0.1139
2023-02-06 11:34:15 | Valid | Epoch[287/600] MIou: 0.6197028100204773
2023-02-06 11:34:15 | Valid | Epoch[287/600] Pixel Accuracy: 0.9371388753255209
2023-02-06 11:34:15 | Valid | Epoch[287/600] Mean Pixel Accuracy: 0.6520266571316522
2023-02-06 11:34:15 | Stage | Epoch[287/600] Train loss:0.0222
2023-02-06 11:34:15 | Stage | Epoch[287/600] Valid loss:0.1139
2023-02-06 11:34:15 | Stage | Epoch[287/600] LR:0.01

2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[001/030] Train loss: 0.0231
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[002/030] Train loss: 0.0250
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[003/030] Train loss: 0.0237
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[004/030] Train loss: 0.0234
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[005/030] Train loss: 0.0230
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[006/030] Train loss: 0.0228
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[007/030] Train loss: 0.0229
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[008/030] Train loss: 0.0233
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[009/030] Train loss: 0.0234
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[010/030] Train loss: 0.0231
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[011/030] Train loss: 0.0233
2023-02-06 11:34:15 | Train | Epoch[288/600] Iteration[012/030] Train loss: 0.0232
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[013/030] Train loss: 0.0236
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[014/030] Train loss: 0.0233
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[015/030] Train loss: 0.0231
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[016/030] Train loss: 0.0229
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[017/030] Train loss: 0.0230
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[018/030] Train loss: 0.0230
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[019/030] Train loss: 0.0227
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[020/030] Train loss: 0.0226
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[021/030] Train loss: 0.0225
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[022/030] Train loss: 0.0226
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[023/030] Train loss: 0.0226
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[024/030] Train loss: 0.0225
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[025/030] Train loss: 0.0225
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[026/030] Train loss: 0.0225
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 11:34:16 | Train | Epoch[288/600] Iteration[030/030] Train loss: 0.0225
2023-02-06 11:34:17 | Valid | Epoch[288/600] Iteration[001/008] Valid loss: 0.0768
2023-02-06 11:34:17 | Valid | Epoch[288/600] Iteration[002/008] Valid loss: 0.0752
2023-02-06 11:34:17 | Valid | Epoch[288/600] Iteration[003/008] Valid loss: 0.0770
2023-02-06 11:34:17 | Valid | Epoch[288/600] Iteration[004/008] Valid loss: 0.0752
2023-02-06 11:34:17 | Valid | Epoch[288/600] Iteration[005/008] Valid loss: 0.0766
2023-02-06 11:34:17 | Valid | Epoch[288/600] Iteration[006/008] Valid loss: 0.0753
2023-02-06 11:34:17 | Valid | Epoch[288/600] Iteration[007/008] Valid loss: 0.0730
2023-02-06 11:34:17 | Valid | Epoch[288/600] Iteration[008/008] Valid loss: 0.0754
2023-02-06 11:34:17 | Valid | Epoch[288/600] MIou: 0.7683217870540184
2023-02-06 11:34:17 | Valid | Epoch[288/600] Pixel Accuracy: 0.9617907206217448
2023-02-06 11:34:17 | Valid | Epoch[288/600] Mean Pixel Accuracy: 0.788480062472385
2023-02-06 11:34:17 | Stage | Epoch[288/600] Train loss:0.0225
2023-02-06 11:34:17 | Stage | Epoch[288/600] Valid loss:0.0754
2023-02-06 11:34:17 | Stage | Epoch[288/600] LR:0.01

2023-02-06 11:34:17 | Train | Epoch[289/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:34:17 | Train | Epoch[289/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 11:34:17 | Train | Epoch[289/600] Iteration[003/030] Train loss: 0.0212
2023-02-06 11:34:17 | Train | Epoch[289/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[007/030] Train loss: 0.0213
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[008/030] Train loss: 0.0213
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[009/030] Train loss: 0.0216
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[010/030] Train loss: 0.0216
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[011/030] Train loss: 0.0215
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[012/030] Train loss: 0.0215
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[013/030] Train loss: 0.0217
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[016/030] Train loss: 0.0219
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[017/030] Train loss: 0.0222
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[018/030] Train loss: 0.0219
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[019/030] Train loss: 0.0221
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[020/030] Train loss: 0.0221
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[021/030] Train loss: 0.0222
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[023/030] Train loss: 0.0221
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[024/030] Train loss: 0.0224
2023-02-06 11:34:18 | Train | Epoch[289/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:34:19 | Train | Epoch[289/600] Iteration[026/030] Train loss: 0.0223
2023-02-06 11:34:19 | Train | Epoch[289/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:34:19 | Train | Epoch[289/600] Iteration[028/030] Train loss: 0.0223
2023-02-06 11:34:19 | Train | Epoch[289/600] Iteration[029/030] Train loss: 0.0222
2023-02-06 11:34:19 | Train | Epoch[289/600] Iteration[030/030] Train loss: 0.0223
2023-02-06 11:34:19 | Valid | Epoch[289/600] Iteration[001/008] Valid loss: 2.0221
2023-02-06 11:34:19 | Valid | Epoch[289/600] Iteration[002/008] Valid loss: 1.9514
2023-02-06 11:34:19 | Valid | Epoch[289/600] Iteration[003/008] Valid loss: 2.0001
2023-02-06 11:34:19 | Valid | Epoch[289/600] Iteration[004/008] Valid loss: 2.0734
2023-02-06 11:34:19 | Valid | Epoch[289/600] Iteration[005/008] Valid loss: 2.1469
2023-02-06 11:34:19 | Valid | Epoch[289/600] Iteration[006/008] Valid loss: 2.1125
2023-02-06 11:34:19 | Valid | Epoch[289/600] Iteration[007/008] Valid loss: 2.1758
2023-02-06 11:34:19 | Valid | Epoch[289/600] Iteration[008/008] Valid loss: 2.2356
2023-02-06 11:34:19 | Valid | Epoch[289/600] MIou: 0.7894356925959736
2023-02-06 11:34:19 | Valid | Epoch[289/600] Pixel Accuracy: 0.9482892354329427
2023-02-06 11:34:19 | Valid | Epoch[289/600] Mean Pixel Accuracy: 0.9711844491494281
2023-02-06 11:34:19 | Stage | Epoch[289/600] Train loss:0.0223
2023-02-06 11:34:19 | Stage | Epoch[289/600] Valid loss:2.2356
2023-02-06 11:34:19 | Stage | Epoch[289/600] LR:0.01

2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[001/030] Train loss: 0.0267
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[003/030] Train loss: 0.0250
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[007/030] Train loss: 0.0236
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[008/030] Train loss: 0.0238
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[009/030] Train loss: 0.0240
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[010/030] Train loss: 0.0242
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[011/030] Train loss: 0.0238
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[014/030] Train loss: 0.0240
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[015/030] Train loss: 0.0236
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[016/030] Train loss: 0.0235
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[017/030] Train loss: 0.0232
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[018/030] Train loss: 0.0231
2023-02-06 11:34:20 | Train | Epoch[290/600] Iteration[019/030] Train loss: 0.0232
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[020/030] Train loss: 0.0233
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[021/030] Train loss: 0.0236
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[022/030] Train loss: 0.0237
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[023/030] Train loss: 0.0235
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[024/030] Train loss: 0.0234
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[025/030] Train loss: 0.0234
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[026/030] Train loss: 0.0234
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[027/030] Train loss: 0.0234
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[028/030] Train loss: 0.0234
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[029/030] Train loss: 0.0235
2023-02-06 11:34:21 | Train | Epoch[290/600] Iteration[030/030] Train loss: 0.0235
2023-02-06 11:34:21 | Valid | Epoch[290/600] Iteration[001/008] Valid loss: 0.2581
2023-02-06 11:34:21 | Valid | Epoch[290/600] Iteration[002/008] Valid loss: 0.1845
2023-02-06 11:34:21 | Valid | Epoch[290/600] Iteration[003/008] Valid loss: 0.1746
2023-02-06 11:34:21 | Valid | Epoch[290/600] Iteration[004/008] Valid loss: 0.1754
2023-02-06 11:34:21 | Valid | Epoch[290/600] Iteration[005/008] Valid loss: 0.1933
2023-02-06 11:34:22 | Valid | Epoch[290/600] Iteration[006/008] Valid loss: 0.1913
2023-02-06 11:34:22 | Valid | Epoch[290/600] Iteration[007/008] Valid loss: 0.2019
2023-02-06 11:34:22 | Valid | Epoch[290/600] Iteration[008/008] Valid loss: 0.2013
2023-02-06 11:34:22 | Valid | Epoch[290/600] MIou: 0.9189502913875063
2023-02-06 11:34:22 | Valid | Epoch[290/600] Pixel Accuracy: 0.9849344889322916
2023-02-06 11:34:22 | Valid | Epoch[290/600] Mean Pixel Accuracy: 0.9822847309787059
2023-02-06 11:34:22 | Stage | Epoch[290/600] Train loss:0.0235
2023-02-06 11:34:22 | Stage | Epoch[290/600] Valid loss:0.2013
2023-02-06 11:34:22 | Stage | Epoch[290/600] LR:0.01

2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[003/030] Train loss: 0.0229
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[004/030] Train loss: 0.0231
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[005/030] Train loss: 0.0234
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[006/030] Train loss: 0.0231
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[007/030] Train loss: 0.0235
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[008/030] Train loss: 0.0227
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[009/030] Train loss: 0.0232
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[010/030] Train loss: 0.0227
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[011/030] Train loss: 0.0229
2023-02-06 11:34:22 | Train | Epoch[291/600] Iteration[012/030] Train loss: 0.0227
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[013/030] Train loss: 0.0229
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[014/030] Train loss: 0.0228
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[015/030] Train loss: 0.0227
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[016/030] Train loss: 0.0230
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[017/030] Train loss: 0.0230
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[018/030] Train loss: 0.0228
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[019/030] Train loss: 0.0227
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[020/030] Train loss: 0.0227
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[021/030] Train loss: 0.0230
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[022/030] Train loss: 0.0230
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[023/030] Train loss: 0.0229
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[024/030] Train loss: 0.0229
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[025/030] Train loss: 0.0228
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[026/030] Train loss: 0.0229
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[027/030] Train loss: 0.0228
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[028/030] Train loss: 0.0229
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[029/030] Train loss: 0.0229
2023-02-06 11:34:23 | Train | Epoch[291/600] Iteration[030/030] Train loss: 0.0228
2023-02-06 11:34:24 | Valid | Epoch[291/600] Iteration[001/008] Valid loss: 0.0600
2023-02-06 11:34:24 | Valid | Epoch[291/600] Iteration[002/008] Valid loss: 0.0592
2023-02-06 11:34:24 | Valid | Epoch[291/600] Iteration[003/008] Valid loss: 0.0603
2023-02-06 11:34:24 | Valid | Epoch[291/600] Iteration[004/008] Valid loss: 0.0580
2023-02-06 11:34:24 | Valid | Epoch[291/600] Iteration[005/008] Valid loss: 0.0590
2023-02-06 11:34:24 | Valid | Epoch[291/600] Iteration[006/008] Valid loss: 0.0581
2023-02-06 11:34:24 | Valid | Epoch[291/600] Iteration[007/008] Valid loss: 0.0563
2023-02-06 11:34:24 | Valid | Epoch[291/600] Iteration[008/008] Valid loss: 0.0586
2023-02-06 11:34:24 | Valid | Epoch[291/600] MIou: 0.7800998578580725
2023-02-06 11:34:24 | Valid | Epoch[291/600] Pixel Accuracy: 0.9637285868326823
2023-02-06 11:34:24 | Valid | Epoch[291/600] Mean Pixel Accuracy: 0.7993602462906106
2023-02-06 11:34:24 | Stage | Epoch[291/600] Train loss:0.0228
2023-02-06 11:34:24 | Stage | Epoch[291/600] Valid loss:0.0586
2023-02-06 11:34:24 | Stage | Epoch[291/600] LR:0.01

2023-02-06 11:34:24 | Train | Epoch[292/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 11:34:24 | Train | Epoch[292/600] Iteration[002/030] Train loss: 0.0239
2023-02-06 11:34:24 | Train | Epoch[292/600] Iteration[003/030] Train loss: 0.0229
2023-02-06 11:34:24 | Train | Epoch[292/600] Iteration[004/030] Train loss: 0.0221
2023-02-06 11:34:24 | Train | Epoch[292/600] Iteration[005/030] Train loss: 0.0220
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[007/030] Train loss: 0.0227
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[008/030] Train loss: 0.0225
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[011/030] Train loss: 0.0223
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[012/030] Train loss: 0.0223
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[013/030] Train loss: 0.0222
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[014/030] Train loss: 0.0221
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[016/030] Train loss: 0.0218
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[017/030] Train loss: 0.0219
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[019/030] Train loss: 0.0220
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[020/030] Train loss: 0.0222
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[021/030] Train loss: 0.0224
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[023/030] Train loss: 0.0223
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[024/030] Train loss: 0.0223
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:34:25 | Train | Epoch[292/600] Iteration[026/030] Train loss: 0.0223
2023-02-06 11:34:26 | Train | Epoch[292/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:34:26 | Train | Epoch[292/600] Iteration[028/030] Train loss: 0.0224
2023-02-06 11:34:26 | Train | Epoch[292/600] Iteration[029/030] Train loss: 0.0223
2023-02-06 11:34:26 | Train | Epoch[292/600] Iteration[030/030] Train loss: 0.0222
2023-02-06 11:34:26 | Valid | Epoch[292/600] Iteration[001/008] Valid loss: 0.3248
2023-02-06 11:34:26 | Valid | Epoch[292/600] Iteration[002/008] Valid loss: 0.2424
2023-02-06 11:34:26 | Valid | Epoch[292/600] Iteration[003/008] Valid loss: 0.2307
2023-02-06 11:34:26 | Valid | Epoch[292/600] Iteration[004/008] Valid loss: 0.2337
2023-02-06 11:34:26 | Valid | Epoch[292/600] Iteration[005/008] Valid loss: 0.2483
2023-02-06 11:34:26 | Valid | Epoch[292/600] Iteration[006/008] Valid loss: 0.2462
2023-02-06 11:34:26 | Valid | Epoch[292/600] Iteration[007/008] Valid loss: 0.2667
2023-02-06 11:34:26 | Valid | Epoch[292/600] Iteration[008/008] Valid loss: 0.2648
2023-02-06 11:34:26 | Valid | Epoch[292/600] MIou: 0.909065482411781
2023-02-06 11:34:26 | Valid | Epoch[292/600] Pixel Accuracy: 0.9826558430989584
2023-02-06 11:34:26 | Valid | Epoch[292/600] Mean Pixel Accuracy: 0.9847668277674266
2023-02-06 11:34:26 | Stage | Epoch[292/600] Train loss:0.0222
2023-02-06 11:34:26 | Stage | Epoch[292/600] Valid loss:0.2648
2023-02-06 11:34:26 | Stage | Epoch[292/600] LR:0.01

2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[002/030] Train loss: 0.0218
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[004/030] Train loss: 0.0229
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[005/030] Train loss: 0.0230
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[006/030] Train loss: 0.0231
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[008/030] Train loss: 0.0228
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[011/030] Train loss: 0.0227
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[013/030] Train loss: 0.0224
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[014/030] Train loss: 0.0225
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[016/030] Train loss: 0.0227
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[018/030] Train loss: 0.0225
2023-02-06 11:34:27 | Train | Epoch[293/600] Iteration[019/030] Train loss: 0.0227
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[020/030] Train loss: 0.0229
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[021/030] Train loss: 0.0228
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[022/030] Train loss: 0.0227
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[023/030] Train loss: 0.0228
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[024/030] Train loss: 0.0227
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[025/030] Train loss: 0.0228
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[026/030] Train loss: 0.0228
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[027/030] Train loss: 0.0227
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[028/030] Train loss: 0.0226
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[029/030] Train loss: 0.0227
2023-02-06 11:34:28 | Train | Epoch[293/600] Iteration[030/030] Train loss: 0.0227
2023-02-06 11:34:28 | Valid | Epoch[293/600] Iteration[001/008] Valid loss: 0.3200
2023-02-06 11:34:28 | Valid | Epoch[293/600] Iteration[002/008] Valid loss: 0.2372
2023-02-06 11:34:28 | Valid | Epoch[293/600] Iteration[003/008] Valid loss: 0.2278
2023-02-06 11:34:28 | Valid | Epoch[293/600] Iteration[004/008] Valid loss: 0.2289
2023-02-06 11:34:28 | Valid | Epoch[293/600] Iteration[005/008] Valid loss: 0.2491
2023-02-06 11:34:29 | Valid | Epoch[293/600] Iteration[006/008] Valid loss: 0.2449
2023-02-06 11:34:29 | Valid | Epoch[293/600] Iteration[007/008] Valid loss: 0.2617
2023-02-06 11:34:29 | Valid | Epoch[293/600] Iteration[008/008] Valid loss: 0.2625
2023-02-06 11:34:29 | Valid | Epoch[293/600] MIou: 0.9169475213617798
2023-02-06 11:34:29 | Valid | Epoch[293/600] Pixel Accuracy: 0.9844474792480469
2023-02-06 11:34:29 | Valid | Epoch[293/600] Mean Pixel Accuracy: 0.983887488781848
2023-02-06 11:34:29 | Stage | Epoch[293/600] Train loss:0.0227
2023-02-06 11:34:29 | Stage | Epoch[293/600] Valid loss:0.2625
2023-02-06 11:34:29 | Stage | Epoch[293/600] LR:0.01

2023-02-06 11:34:29 | Train | Epoch[294/600] Iteration[001/030] Train loss: 0.0245
2023-02-06 11:34:29 | Train | Epoch[294/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 11:34:29 | Train | Epoch[294/600] Iteration[003/030] Train loss: 0.0240
2023-02-06 11:34:29 | Train | Epoch[294/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 11:34:29 | Train | Epoch[294/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 11:34:29 | Train | Epoch[294/600] Iteration[006/030] Train loss: 0.0242
2023-02-06 11:34:29 | Train | Epoch[294/600] Iteration[007/030] Train loss: 0.0241
2023-02-06 11:34:29 | Train | Epoch[294/600] Iteration[008/030] Train loss: 0.0237
2023-02-06 11:34:29 | Train | Epoch[294/600] Iteration[009/030] Train loss: 0.0234
2023-02-06 11:34:29 | Train | Epoch[294/600] Iteration[010/030] Train loss: 0.0233
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[011/030] Train loss: 0.0231
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[013/030] Train loss: 0.0227
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[014/030] Train loss: 0.0227
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[015/030] Train loss: 0.0228
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[016/030] Train loss: 0.0228
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[017/030] Train loss: 0.0229
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[018/030] Train loss: 0.0229
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[019/030] Train loss: 0.0228
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[020/030] Train loss: 0.0228
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[021/030] Train loss: 0.0226
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[022/030] Train loss: 0.0226
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[023/030] Train loss: 0.0226
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[024/030] Train loss: 0.0227
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[025/030] Train loss: 0.0226
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[026/030] Train loss: 0.0225
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 11:34:30 | Train | Epoch[294/600] Iteration[030/030] Train loss: 0.0225
2023-02-06 11:34:31 | Valid | Epoch[294/600] Iteration[001/008] Valid loss: 0.0452
2023-02-06 11:34:31 | Valid | Epoch[294/600] Iteration[002/008] Valid loss: 0.0433
2023-02-06 11:34:31 | Valid | Epoch[294/600] Iteration[003/008] Valid loss: 0.0429
2023-02-06 11:34:31 | Valid | Epoch[294/600] Iteration[004/008] Valid loss: 0.0414
2023-02-06 11:34:31 | Valid | Epoch[294/600] Iteration[005/008] Valid loss: 0.0426
2023-02-06 11:34:31 | Valid | Epoch[294/600] Iteration[006/008] Valid loss: 0.0417
2023-02-06 11:34:31 | Valid | Epoch[294/600] Iteration[007/008] Valid loss: 0.0404
2023-02-06 11:34:31 | Valid | Epoch[294/600] Iteration[008/008] Valid loss: 0.0413
2023-02-06 11:34:31 | Valid | Epoch[294/600] MIou: 0.8611287221240207
2023-02-06 11:34:31 | Valid | Epoch[294/600] Pixel Accuracy: 0.9770762125651041
2023-02-06 11:34:31 | Valid | Epoch[294/600] Mean Pixel Accuracy: 0.8742607350883413
2023-02-06 11:34:31 | Stage | Epoch[294/600] Train loss:0.0225
2023-02-06 11:34:31 | Stage | Epoch[294/600] Valid loss:0.0413
2023-02-06 11:34:31 | Stage | Epoch[294/600] LR:0.01

2023-02-06 11:34:31 | Train | Epoch[295/600] Iteration[001/030] Train loss: 0.0223
2023-02-06 11:34:31 | Train | Epoch[295/600] Iteration[002/030] Train loss: 0.0225
2023-02-06 11:34:31 | Train | Epoch[295/600] Iteration[003/030] Train loss: 0.0217
2023-02-06 11:34:31 | Train | Epoch[295/600] Iteration[004/030] Train loss: 0.0208
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[006/030] Train loss: 0.0217
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[007/030] Train loss: 0.0220
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[008/030] Train loss: 0.0218
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[009/030] Train loss: 0.0217
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[010/030] Train loss: 0.0222
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[011/030] Train loss: 0.0221
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[012/030] Train loss: 0.0220
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[013/030] Train loss: 0.0221
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[014/030] Train loss: 0.0222
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[015/030] Train loss: 0.0222
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[016/030] Train loss: 0.0221
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[018/030] Train loss: 0.0222
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[019/030] Train loss: 0.0222
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[020/030] Train loss: 0.0223
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[021/030] Train loss: 0.0225
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[022/030] Train loss: 0.0223
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[023/030] Train loss: 0.0224
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[024/030] Train loss: 0.0223
2023-02-06 11:34:32 | Train | Epoch[295/600] Iteration[025/030] Train loss: 0.0224
2023-02-06 11:34:33 | Train | Epoch[295/600] Iteration[026/030] Train loss: 0.0223
2023-02-06 11:34:33 | Train | Epoch[295/600] Iteration[027/030] Train loss: 0.0224
2023-02-06 11:34:33 | Train | Epoch[295/600] Iteration[028/030] Train loss: 0.0223
2023-02-06 11:34:33 | Train | Epoch[295/600] Iteration[029/030] Train loss: 0.0223
2023-02-06 11:34:33 | Train | Epoch[295/600] Iteration[030/030] Train loss: 0.0222
2023-02-06 11:34:33 | Valid | Epoch[295/600] Iteration[001/008] Valid loss: 0.6420
2023-02-06 11:34:33 | Valid | Epoch[295/600] Iteration[002/008] Valid loss: 0.5756
2023-02-06 11:34:33 | Valid | Epoch[295/600] Iteration[003/008] Valid loss: 0.5812
2023-02-06 11:34:33 | Valid | Epoch[295/600] Iteration[004/008] Valid loss: 0.5887
2023-02-06 11:34:33 | Valid | Epoch[295/600] Iteration[005/008] Valid loss: 0.6152
2023-02-06 11:34:33 | Valid | Epoch[295/600] Iteration[006/008] Valid loss: 0.6013
2023-02-06 11:34:33 | Valid | Epoch[295/600] Iteration[007/008] Valid loss: 0.6374
2023-02-06 11:34:33 | Valid | Epoch[295/600] Iteration[008/008] Valid loss: 0.6479
2023-02-06 11:34:33 | Valid | Epoch[295/600] MIou: 0.8739201536821983
2023-02-06 11:34:33 | Valid | Epoch[295/600] Pixel Accuracy: 0.9741541544596354
2023-02-06 11:34:33 | Valid | Epoch[295/600] Mean Pixel Accuracy: 0.9824969758060822
2023-02-06 11:34:33 | Stage | Epoch[295/600] Train loss:0.0222
2023-02-06 11:34:33 | Stage | Epoch[295/600] Valid loss:0.6479
2023-02-06 11:34:33 | Stage | Epoch[295/600] LR:0.01

2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[001/030] Train loss: 0.0231
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[004/030] Train loss: 0.0228
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[005/030] Train loss: 0.0226
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[006/030] Train loss: 0.0222
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[007/030] Train loss: 0.0221
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[008/030] Train loss: 0.0219
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[009/030] Train loss: 0.0219
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[010/030] Train loss: 0.0217
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[012/030] Train loss: 0.0218
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[013/030] Train loss: 0.0218
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[015/030] Train loss: 0.0215
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[017/030] Train loss: 0.0217
2023-02-06 11:34:34 | Train | Epoch[296/600] Iteration[018/030] Train loss: 0.0216
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[019/030] Train loss: 0.0216
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[020/030] Train loss: 0.0215
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[021/030] Train loss: 0.0217
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[022/030] Train loss: 0.0217
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[023/030] Train loss: 0.0218
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[025/030] Train loss: 0.0219
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[026/030] Train loss: 0.0220
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[027/030] Train loss: 0.0222
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[028/030] Train loss: 0.0223
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[029/030] Train loss: 0.0223
2023-02-06 11:34:35 | Train | Epoch[296/600] Iteration[030/030] Train loss: 0.0222
2023-02-06 11:34:36 | Valid | Epoch[296/600] Iteration[001/008] Valid loss: 0.0683
2023-02-06 11:34:36 | Valid | Epoch[296/600] Iteration[002/008] Valid loss: 0.0681
2023-02-06 11:34:36 | Valid | Epoch[296/600] Iteration[003/008] Valid loss: 0.0690
2023-02-06 11:34:36 | Valid | Epoch[296/600] Iteration[004/008] Valid loss: 0.0669
2023-02-06 11:34:36 | Valid | Epoch[296/600] Iteration[005/008] Valid loss: 0.0681
2023-02-06 11:34:36 | Valid | Epoch[296/600] Iteration[006/008] Valid loss: 0.0669
2023-02-06 11:34:36 | Valid | Epoch[296/600] Iteration[007/008] Valid loss: 0.0650
2023-02-06 11:34:36 | Valid | Epoch[296/600] Iteration[008/008] Valid loss: 0.0675
2023-02-06 11:34:36 | Valid | Epoch[296/600] MIou: 0.7679908304345254
2023-02-06 11:34:36 | Valid | Epoch[296/600] Pixel Accuracy: 0.9617335001627604
2023-02-06 11:34:36 | Valid | Epoch[296/600] Mean Pixel Accuracy: 0.7881949928072505
2023-02-06 11:34:36 | Stage | Epoch[296/600] Train loss:0.0222
2023-02-06 11:34:36 | Stage | Epoch[296/600] Valid loss:0.0675
2023-02-06 11:34:36 | Stage | Epoch[296/600] LR:0.01

2023-02-06 11:34:36 | Train | Epoch[297/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 11:34:36 | Train | Epoch[297/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 11:34:36 | Train | Epoch[297/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 11:34:36 | Train | Epoch[297/600] Iteration[004/030] Train loss: 0.0238
2023-02-06 11:34:36 | Train | Epoch[297/600] Iteration[005/030] Train loss: 0.0228
2023-02-06 11:34:36 | Train | Epoch[297/600] Iteration[006/030] Train loss: 0.0232
2023-02-06 11:34:36 | Train | Epoch[297/600] Iteration[007/030] Train loss: 0.0232
2023-02-06 11:34:36 | Train | Epoch[297/600] Iteration[008/030] Train loss: 0.0227
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[009/030] Train loss: 0.0226
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[010/030] Train loss: 0.0224
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[011/030] Train loss: 0.0226
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[013/030] Train loss: 0.0227
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[014/030] Train loss: 0.0223
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[015/030] Train loss: 0.0223
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[016/030] Train loss: 0.0225
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[018/030] Train loss: 0.0225
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[019/030] Train loss: 0.0226
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[020/030] Train loss: 0.0226
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[021/030] Train loss: 0.0226
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[022/030] Train loss: 0.0225
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[023/030] Train loss: 0.0225
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[024/030] Train loss: 0.0225
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[025/030] Train loss: 0.0226
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[026/030] Train loss: 0.0226
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:34:37 | Train | Epoch[297/600] Iteration[029/030] Train loss: 0.0224
2023-02-06 11:34:38 | Train | Epoch[297/600] Iteration[030/030] Train loss: 0.0224
2023-02-06 11:34:38 | Valid | Epoch[297/600] Iteration[001/008] Valid loss: 0.0754
2023-02-06 11:34:38 | Valid | Epoch[297/600] Iteration[002/008] Valid loss: 0.0762
2023-02-06 11:34:38 | Valid | Epoch[297/600] Iteration[003/008] Valid loss: 0.0770
2023-02-06 11:34:38 | Valid | Epoch[297/600] Iteration[004/008] Valid loss: 0.0748
2023-02-06 11:34:38 | Valid | Epoch[297/600] Iteration[005/008] Valid loss: 0.0761
2023-02-06 11:34:38 | Valid | Epoch[297/600] Iteration[006/008] Valid loss: 0.0749
2023-02-06 11:34:38 | Valid | Epoch[297/600] Iteration[007/008] Valid loss: 0.0727
2023-02-06 11:34:38 | Valid | Epoch[297/600] Iteration[008/008] Valid loss: 0.0743
2023-02-06 11:34:38 | Valid | Epoch[297/600] MIou: 0.7963635147570548
2023-02-06 11:34:38 | Valid | Epoch[297/600] Pixel Accuracy: 0.9664281209309896
2023-02-06 11:34:38 | Valid | Epoch[297/600] Mean Pixel Accuracy: 0.8141780369532889
2023-02-06 11:34:38 | Stage | Epoch[297/600] Train loss:0.0224
2023-02-06 11:34:38 | Stage | Epoch[297/600] Valid loss:0.0743
2023-02-06 11:34:38 | Stage | Epoch[297/600] LR:0.01

2023-02-06 11:34:38 | Train | Epoch[298/600] Iteration[001/030] Train loss: 0.0252
2023-02-06 11:34:38 | Train | Epoch[298/600] Iteration[002/030] Train loss: 0.0246
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[004/030] Train loss: 0.0240
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[005/030] Train loss: 0.0237
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[006/030] Train loss: 0.0238
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[007/030] Train loss: 0.0238
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[008/030] Train loss: 0.0231
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[009/030] Train loss: 0.0230
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[010/030] Train loss: 0.0232
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[011/030] Train loss: 0.0230
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[012/030] Train loss: 0.0228
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[013/030] Train loss: 0.0225
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[014/030] Train loss: 0.0222
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[015/030] Train loss: 0.0223
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[016/030] Train loss: 0.0223
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[018/030] Train loss: 0.0223
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[019/030] Train loss: 0.0224
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[020/030] Train loss: 0.0223
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[021/030] Train loss: 0.0224
2023-02-06 11:34:39 | Train | Epoch[298/600] Iteration[022/030] Train loss: 0.0225
2023-02-06 11:34:40 | Train | Epoch[298/600] Iteration[023/030] Train loss: 0.0224
2023-02-06 11:34:40 | Train | Epoch[298/600] Iteration[024/030] Train loss: 0.0223
2023-02-06 11:34:40 | Train | Epoch[298/600] Iteration[025/030] Train loss: 0.0224
2023-02-06 11:34:40 | Train | Epoch[298/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:34:40 | Train | Epoch[298/600] Iteration[027/030] Train loss: 0.0223
2023-02-06 11:34:40 | Train | Epoch[298/600] Iteration[028/030] Train loss: 0.0224
2023-02-06 11:34:40 | Train | Epoch[298/600] Iteration[029/030] Train loss: 0.0224
2023-02-06 11:34:40 | Train | Epoch[298/600] Iteration[030/030] Train loss: 0.0223
2023-02-06 11:34:40 | Valid | Epoch[298/600] Iteration[001/008] Valid loss: 0.0529
2023-02-06 11:34:40 | Valid | Epoch[298/600] Iteration[002/008] Valid loss: 0.0388
2023-02-06 11:34:40 | Valid | Epoch[298/600] Iteration[003/008] Valid loss: 0.0350
2023-02-06 11:34:40 | Valid | Epoch[298/600] Iteration[004/008] Valid loss: 0.0340
2023-02-06 11:34:40 | Valid | Epoch[298/600] Iteration[005/008] Valid loss: 0.0353
2023-02-06 11:34:40 | Valid | Epoch[298/600] Iteration[006/008] Valid loss: 0.0347
2023-02-06 11:34:40 | Valid | Epoch[298/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 11:34:40 | Valid | Epoch[298/600] Iteration[008/008] Valid loss: 0.0341
2023-02-06 11:34:40 | Valid | Epoch[298/600] MIou: 0.9277781377725448
2023-02-06 11:34:40 | Valid | Epoch[298/600] Pixel Accuracy: 0.9878985087076823
2023-02-06 11:34:40 | Valid | Epoch[298/600] Mean Pixel Accuracy: 0.9422633252967945
2023-02-06 11:34:40 | Stage | Epoch[298/600] Train loss:0.0223
2023-02-06 11:34:40 | Stage | Epoch[298/600] Valid loss:0.0341
2023-02-06 11:34:40 | Stage | Epoch[298/600] LR:0.01

2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[004/030] Train loss: 0.0208
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[005/030] Train loss: 0.0210
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[006/030] Train loss: 0.0216
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[007/030] Train loss: 0.0213
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[009/030] Train loss: 0.0211
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[012/030] Train loss: 0.0213
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[013/030] Train loss: 0.0213
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[014/030] Train loss: 0.0215
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[015/030] Train loss: 0.0215
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[016/030] Train loss: 0.0218
2023-02-06 11:34:41 | Train | Epoch[299/600] Iteration[017/030] Train loss: 0.0219
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[018/030] Train loss: 0.0218
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[019/030] Train loss: 0.0219
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[020/030] Train loss: 0.0220
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[021/030] Train loss: 0.0221
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[026/030] Train loss: 0.0219
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[027/030] Train loss: 0.0219
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[028/030] Train loss: 0.0219
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[029/030] Train loss: 0.0219
2023-02-06 11:34:42 | Train | Epoch[299/600] Iteration[030/030] Train loss: 0.0219
2023-02-06 11:34:42 | Valid | Epoch[299/600] Iteration[001/008] Valid loss: 0.1073
2023-02-06 11:34:42 | Valid | Epoch[299/600] Iteration[002/008] Valid loss: 0.0703
2023-02-06 11:34:42 | Valid | Epoch[299/600] Iteration[003/008] Valid loss: 0.0661
2023-02-06 11:34:42 | Valid | Epoch[299/600] Iteration[004/008] Valid loss: 0.0622
2023-02-06 11:34:43 | Valid | Epoch[299/600] Iteration[005/008] Valid loss: 0.0780
2023-02-06 11:34:43 | Valid | Epoch[299/600] Iteration[006/008] Valid loss: 0.0757
2023-02-06 11:34:43 | Valid | Epoch[299/600] Iteration[007/008] Valid loss: 0.0737
2023-02-06 11:34:43 | Valid | Epoch[299/600] Iteration[008/008] Valid loss: 0.0725
2023-02-06 11:34:43 | Valid | Epoch[299/600] MIou: 0.9273234056858591
2023-02-06 11:34:43 | Valid | Epoch[299/600] Pixel Accuracy: 0.9874852498372396
2023-02-06 11:34:43 | Valid | Epoch[299/600] Mean Pixel Accuracy: 0.9541401407130949
2023-02-06 11:34:43 | Stage | Epoch[299/600] Train loss:0.0219
2023-02-06 11:34:43 | Stage | Epoch[299/600] Valid loss:0.0725
2023-02-06 11:34:43 | Stage | Epoch[299/600] LR:0.01

2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[003/030] Train loss: 0.0225
2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[004/030] Train loss: 0.0217
2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[005/030] Train loss: 0.0216
2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[006/030] Train loss: 0.0233
2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[007/030] Train loss: 0.0229
2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[008/030] Train loss: 0.0228
2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 11:34:43 | Train | Epoch[300/600] Iteration[011/030] Train loss: 0.0227
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[013/030] Train loss: 0.0223
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[014/030] Train loss: 0.0223
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[015/030] Train loss: 0.0224
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[016/030] Train loss: 0.0225
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[017/030] Train loss: 0.0226
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[018/030] Train loss: 0.0226
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[019/030] Train loss: 0.0225
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[020/030] Train loss: 0.0225
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[021/030] Train loss: 0.0227
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[022/030] Train loss: 0.0226
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[023/030] Train loss: 0.0228
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[024/030] Train loss: 0.0230
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[025/030] Train loss: 0.0227
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[026/030] Train loss: 0.0227
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[027/030] Train loss: 0.0226
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[028/030] Train loss: 0.0226
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 11:34:44 | Train | Epoch[300/600] Iteration[030/030] Train loss: 0.0226
2023-02-06 11:34:45 | Valid | Epoch[300/600] Iteration[001/008] Valid loss: 0.0414
2023-02-06 11:34:45 | Valid | Epoch[300/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:34:45 | Valid | Epoch[300/600] Iteration[003/008] Valid loss: 0.0372
2023-02-06 11:34:45 | Valid | Epoch[300/600] Iteration[004/008] Valid loss: 0.0361
2023-02-06 11:34:45 | Valid | Epoch[300/600] Iteration[005/008] Valid loss: 0.0364
2023-02-06 11:34:45 | Valid | Epoch[300/600] Iteration[006/008] Valid loss: 0.0366
2023-02-06 11:34:45 | Valid | Epoch[300/600] Iteration[007/008] Valid loss: 0.0359
2023-02-06 11:34:45 | Valid | Epoch[300/600] Iteration[008/008] Valid loss: 0.0363
2023-02-06 11:34:45 | Valid | Epoch[300/600] MIou: 0.8876748887569632
2023-02-06 11:34:45 | Valid | Epoch[300/600] Pixel Accuracy: 0.9813550313313802
2023-02-06 11:34:45 | Valid | Epoch[300/600] Mean Pixel Accuracy: 0.9009409455613436
2023-02-06 11:34:45 | Stage | Epoch[300/600] Train loss:0.0226
2023-02-06 11:34:45 | Stage | Epoch[300/600] Valid loss:0.0363
2023-02-06 11:34:45 | Stage | Epoch[300/600] LR:0.01

2023-02-06 11:34:45 | Train | Epoch[301/600] Iteration[001/030] Train loss: 0.0195
2023-02-06 11:34:45 | Train | Epoch[301/600] Iteration[002/030] Train loss: 0.0221
2023-02-06 11:34:45 | Train | Epoch[301/600] Iteration[003/030] Train loss: 0.0217
2023-02-06 11:34:45 | Train | Epoch[301/600] Iteration[004/030] Train loss: 0.0220
2023-02-06 11:34:45 | Train | Epoch[301/600] Iteration[005/030] Train loss: 0.0222
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[006/030] Train loss: 0.0219
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[007/030] Train loss: 0.0217
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[008/030] Train loss: 0.0217
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[009/030] Train loss: 0.0214
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[012/030] Train loss: 0.0214
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[014/030] Train loss: 0.0216
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[016/030] Train loss: 0.0218
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[018/030] Train loss: 0.0218
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[019/030] Train loss: 0.0219
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[020/030] Train loss: 0.0220
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[021/030] Train loss: 0.0222
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[023/030] Train loss: 0.0224
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[024/030] Train loss: 0.0224
2023-02-06 11:34:46 | Train | Epoch[301/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:34:47 | Train | Epoch[301/600] Iteration[026/030] Train loss: 0.0224
2023-02-06 11:34:47 | Train | Epoch[301/600] Iteration[027/030] Train loss: 0.0223
2023-02-06 11:34:47 | Train | Epoch[301/600] Iteration[028/030] Train loss: 0.0221
2023-02-06 11:34:47 | Train | Epoch[301/600] Iteration[029/030] Train loss: 0.0221
2023-02-06 11:34:47 | Train | Epoch[301/600] Iteration[030/030] Train loss: 0.0221
2023-02-06 11:34:47 | Valid | Epoch[301/600] Iteration[001/008] Valid loss: 0.0485
2023-02-06 11:34:47 | Valid | Epoch[301/600] Iteration[002/008] Valid loss: 0.0463
2023-02-06 11:34:47 | Valid | Epoch[301/600] Iteration[003/008] Valid loss: 0.0455
2023-02-06 11:34:47 | Valid | Epoch[301/600] Iteration[004/008] Valid loss: 0.0440
2023-02-06 11:34:47 | Valid | Epoch[301/600] Iteration[005/008] Valid loss: 0.0447
2023-02-06 11:34:47 | Valid | Epoch[301/600] Iteration[006/008] Valid loss: 0.0440
2023-02-06 11:34:47 | Valid | Epoch[301/600] Iteration[007/008] Valid loss: 0.0427
2023-02-06 11:34:47 | Valid | Epoch[301/600] Iteration[008/008] Valid loss: 0.0433
2023-02-06 11:34:47 | Valid | Epoch[301/600] MIou: 0.8708423421605995
2023-02-06 11:34:47 | Valid | Epoch[301/600] Pixel Accuracy: 0.9786961873372396
2023-02-06 11:34:47 | Valid | Epoch[301/600] Mean Pixel Accuracy: 0.8829182199156578
2023-02-06 11:34:47 | Stage | Epoch[301/600] Train loss:0.0221
2023-02-06 11:34:47 | Stage | Epoch[301/600] Valid loss:0.0433
2023-02-06 11:34:47 | Stage | Epoch[301/600] LR:0.01

2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[001/030] Train loss: 0.0235
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[002/030] Train loss: 0.0224
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[004/030] Train loss: 0.0225
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[005/030] Train loss: 0.0220
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[006/030] Train loss: 0.0223
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[007/030] Train loss: 0.0225
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[008/030] Train loss: 0.0230
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[009/030] Train loss: 0.0226
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[010/030] Train loss: 0.0223
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[011/030] Train loss: 0.0222
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[012/030] Train loss: 0.0221
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[013/030] Train loss: 0.0222
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[014/030] Train loss: 0.0222
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[015/030] Train loss: 0.0220
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[016/030] Train loss: 0.0223
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[017/030] Train loss: 0.0223
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[018/030] Train loss: 0.0222
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[019/030] Train loss: 0.0221
2023-02-06 11:34:48 | Train | Epoch[302/600] Iteration[020/030] Train loss: 0.0220
2023-02-06 11:34:49 | Train | Epoch[302/600] Iteration[021/030] Train loss: 0.0220
2023-02-06 11:34:49 | Train | Epoch[302/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:34:49 | Train | Epoch[302/600] Iteration[023/030] Train loss: 0.0221
2023-02-06 11:34:49 | Train | Epoch[302/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:34:49 | Train | Epoch[302/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:34:49 | Train | Epoch[302/600] Iteration[026/030] Train loss: 0.0223
2023-02-06 11:34:49 | Train | Epoch[302/600] Iteration[027/030] Train loss: 0.0222
2023-02-06 11:34:49 | Train | Epoch[302/600] Iteration[028/030] Train loss: 0.0223
2023-02-06 11:34:49 | Train | Epoch[302/600] Iteration[029/030] Train loss: 0.0224
2023-02-06 11:34:49 | Train | Epoch[302/600] Iteration[030/030] Train loss: 0.0223
2023-02-06 11:34:49 | Valid | Epoch[302/600] Iteration[001/008] Valid loss: 0.3040
2023-02-06 11:34:49 | Valid | Epoch[302/600] Iteration[002/008] Valid loss: 0.2209
2023-02-06 11:34:49 | Valid | Epoch[302/600] Iteration[003/008] Valid loss: 0.2043
2023-02-06 11:34:49 | Valid | Epoch[302/600] Iteration[004/008] Valid loss: 0.2042
2023-02-06 11:34:49 | Valid | Epoch[302/600] Iteration[005/008] Valid loss: 0.2198
2023-02-06 11:34:49 | Valid | Epoch[302/600] Iteration[006/008] Valid loss: 0.2190
2023-02-06 11:34:50 | Valid | Epoch[302/600] Iteration[007/008] Valid loss: 0.2324
2023-02-06 11:34:50 | Valid | Epoch[302/600] Iteration[008/008] Valid loss: 0.2309
2023-02-06 11:34:50 | Valid | Epoch[302/600] MIou: 0.910097668462532
2023-02-06 11:34:50 | Valid | Epoch[302/600] Pixel Accuracy: 0.9829216003417969
2023-02-06 11:34:50 | Valid | Epoch[302/600] Mean Pixel Accuracy: 0.9838413595968216
2023-02-06 11:34:50 | Stage | Epoch[302/600] Train loss:0.0223
2023-02-06 11:34:50 | Stage | Epoch[302/600] Valid loss:0.2309
2023-02-06 11:34:50 | Stage | Epoch[302/600] LR:0.01

2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[002/030] Train loss: 0.0219
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[003/030] Train loss: 0.0208
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[011/030] Train loss: 0.0208
2023-02-06 11:34:50 | Train | Epoch[303/600] Iteration[012/030] Train loss: 0.0206
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[015/030] Train loss: 0.0213
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[017/030] Train loss: 0.0213
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[018/030] Train loss: 0.0215
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[019/030] Train loss: 0.0215
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[022/030] Train loss: 0.0218
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[023/030] Train loss: 0.0218
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[025/030] Train loss: 0.0217
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[026/030] Train loss: 0.0219
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[027/030] Train loss: 0.0220
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[028/030] Train loss: 0.0220
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[029/030] Train loss: 0.0220
2023-02-06 11:34:51 | Train | Epoch[303/600] Iteration[030/030] Train loss: 0.0220
2023-02-06 11:34:52 | Valid | Epoch[303/600] Iteration[001/008] Valid loss: 0.0580
2023-02-06 11:34:52 | Valid | Epoch[303/600] Iteration[002/008] Valid loss: 0.0428
2023-02-06 11:34:52 | Valid | Epoch[303/600] Iteration[003/008] Valid loss: 0.0384
2023-02-06 11:34:52 | Valid | Epoch[303/600] Iteration[004/008] Valid loss: 0.0362
2023-02-06 11:34:52 | Valid | Epoch[303/600] Iteration[005/008] Valid loss: 0.0376
2023-02-06 11:34:52 | Valid | Epoch[303/600] Iteration[006/008] Valid loss: 0.0374
2023-02-06 11:34:52 | Valid | Epoch[303/600] Iteration[007/008] Valid loss: 0.0373
2023-02-06 11:34:52 | Valid | Epoch[303/600] Iteration[008/008] Valid loss: 0.0368
2023-02-06 11:34:52 | Valid | Epoch[303/600] MIou: 0.9249625522254734
2023-02-06 11:34:52 | Valid | Epoch[303/600] Pixel Accuracy: 0.9873555501302084
2023-02-06 11:34:52 | Valid | Epoch[303/600] Mean Pixel Accuracy: 0.9421234038937936
2023-02-06 11:34:52 | Stage | Epoch[303/600] Train loss:0.0220
2023-02-06 11:34:52 | Stage | Epoch[303/600] Valid loss:0.0368
2023-02-06 11:34:52 | Stage | Epoch[303/600] LR:0.01

2023-02-06 11:34:52 | Train | Epoch[304/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 11:34:52 | Train | Epoch[304/600] Iteration[002/030] Train loss: 0.0214
2023-02-06 11:34:52 | Train | Epoch[304/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:34:52 | Train | Epoch[304/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:34:52 | Train | Epoch[304/600] Iteration[005/030] Train loss: 0.0216
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[006/030] Train loss: 0.0215
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[007/030] Train loss: 0.0222
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[008/030] Train loss: 0.0222
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[009/030] Train loss: 0.0221
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[010/030] Train loss: 0.0219
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[011/030] Train loss: 0.0222
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[012/030] Train loss: 0.0219
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[013/030] Train loss: 0.0222
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[014/030] Train loss: 0.0221
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[015/030] Train loss: 0.0220
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[016/030] Train loss: 0.0222
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[019/030] Train loss: 0.0220
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[020/030] Train loss: 0.0220
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[021/030] Train loss: 0.0221
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[022/030] Train loss: 0.0223
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[023/030] Train loss: 0.0223
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:34:53 | Train | Epoch[304/600] Iteration[025/030] Train loss: 0.0222
2023-02-06 11:34:54 | Train | Epoch[304/600] Iteration[026/030] Train loss: 0.0222
2023-02-06 11:34:54 | Train | Epoch[304/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:34:54 | Train | Epoch[304/600] Iteration[028/030] Train loss: 0.0220
2023-02-06 11:34:54 | Train | Epoch[304/600] Iteration[029/030] Train loss: 0.0221
2023-02-06 11:34:54 | Train | Epoch[304/600] Iteration[030/030] Train loss: 0.0220
2023-02-06 11:34:54 | Valid | Epoch[304/600] Iteration[001/008] Valid loss: 0.1079
2023-02-06 11:34:54 | Valid | Epoch[304/600] Iteration[002/008] Valid loss: 0.1078
2023-02-06 11:34:54 | Valid | Epoch[304/600] Iteration[003/008] Valid loss: 0.1108
2023-02-06 11:34:54 | Valid | Epoch[304/600] Iteration[004/008] Valid loss: 0.1090
2023-02-06 11:34:54 | Valid | Epoch[304/600] Iteration[005/008] Valid loss: 0.1104
2023-02-06 11:34:54 | Valid | Epoch[304/600] Iteration[006/008] Valid loss: 0.1087
2023-02-06 11:34:54 | Valid | Epoch[304/600] Iteration[007/008] Valid loss: 0.1055
2023-02-06 11:34:54 | Valid | Epoch[304/600] Iteration[008/008] Valid loss: 0.1093
2023-02-06 11:34:54 | Valid | Epoch[304/600] MIou: 0.6807120245686297
2023-02-06 11:34:54 | Valid | Epoch[304/600] Pixel Accuracy: 0.9472732543945312
2023-02-06 11:34:54 | Valid | Epoch[304/600] Mean Pixel Accuracy: 0.7081051401540216
2023-02-06 11:34:54 | Stage | Epoch[304/600] Train loss:0.0220
2023-02-06 11:34:54 | Stage | Epoch[304/600] Valid loss:0.1093
2023-02-06 11:34:54 | Stage | Epoch[304/600] LR:0.01

2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[003/030] Train loss: 0.0219
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[004/030] Train loss: 0.0230
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[005/030] Train loss: 0.0232
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[006/030] Train loss: 0.0229
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[007/030] Train loss: 0.0228
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[008/030] Train loss: 0.0223
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[009/030] Train loss: 0.0224
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[010/030] Train loss: 0.0222
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[011/030] Train loss: 0.0222
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[012/030] Train loss: 0.0220
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[013/030] Train loss: 0.0218
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[016/030] Train loss: 0.0221
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[017/030] Train loss: 0.0221
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 11:34:55 | Train | Epoch[305/600] Iteration[019/030] Train loss: 0.0220
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[020/030] Train loss: 0.0221
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[021/030] Train loss: 0.0221
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[023/030] Train loss: 0.0221
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[028/030] Train loss: 0.0221
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[029/030] Train loss: 0.0221
2023-02-06 11:34:56 | Train | Epoch[305/600] Iteration[030/030] Train loss: 0.0221
2023-02-06 11:34:56 | Valid | Epoch[305/600] Iteration[001/008] Valid loss: 0.2150
2023-02-06 11:34:56 | Valid | Epoch[305/600] Iteration[002/008] Valid loss: 0.1498
2023-02-06 11:34:56 | Valid | Epoch[305/600] Iteration[003/008] Valid loss: 0.1351
2023-02-06 11:34:56 | Valid | Epoch[305/600] Iteration[004/008] Valid loss: 0.1391
2023-02-06 11:34:56 | Valid | Epoch[305/600] Iteration[005/008] Valid loss: 0.1525
2023-02-06 11:34:56 | Valid | Epoch[305/600] Iteration[006/008] Valid loss: 0.1469
2023-02-06 11:34:57 | Valid | Epoch[305/600] Iteration[007/008] Valid loss: 0.1610
2023-02-06 11:34:57 | Valid | Epoch[305/600] Iteration[008/008] Valid loss: 0.1572
2023-02-06 11:34:57 | Valid | Epoch[305/600] MIou: 0.9326303103544371
2023-02-06 11:34:57 | Valid | Epoch[305/600] Pixel Accuracy: 0.9879035949707031
2023-02-06 11:34:57 | Valid | Epoch[305/600] Mean Pixel Accuracy: 0.9791803460672033
2023-02-06 11:34:57 | Stage | Epoch[305/600] Train loss:0.0221
2023-02-06 11:34:57 | Stage | Epoch[305/600] Valid loss:0.1572
2023-02-06 11:34:57 | Stage | Epoch[305/600] LR:0.01

2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[003/030] Train loss: 0.0219
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[004/030] Train loss: 0.0225
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[005/030] Train loss: 0.0229
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[006/030] Train loss: 0.0235
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[007/030] Train loss: 0.0234
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[008/030] Train loss: 0.0229
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[009/030] Train loss: 0.0228
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[010/030] Train loss: 0.0223
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[011/030] Train loss: 0.0222
2023-02-06 11:34:57 | Train | Epoch[306/600] Iteration[012/030] Train loss: 0.0221
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[013/030] Train loss: 0.0221
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[014/030] Train loss: 0.0221
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[015/030] Train loss: 0.0222
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[016/030] Train loss: 0.0220
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[017/030] Train loss: 0.0222
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[018/030] Train loss: 0.0224
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[019/030] Train loss: 0.0224
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[020/030] Train loss: 0.0225
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[021/030] Train loss: 0.0222
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[025/030] Train loss: 0.0221
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[026/030] Train loss: 0.0220
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[027/030] Train loss: 0.0220
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[028/030] Train loss: 0.0221
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[029/030] Train loss: 0.0222
2023-02-06 11:34:58 | Train | Epoch[306/600] Iteration[030/030] Train loss: 0.0222
2023-02-06 11:34:59 | Valid | Epoch[306/600] Iteration[001/008] Valid loss: 0.0452
2023-02-06 11:34:59 | Valid | Epoch[306/600] Iteration[002/008] Valid loss: 0.0436
2023-02-06 11:34:59 | Valid | Epoch[306/600] Iteration[003/008] Valid loss: 0.0437
2023-02-06 11:34:59 | Valid | Epoch[306/600] Iteration[004/008] Valid loss: 0.0420
2023-02-06 11:34:59 | Valid | Epoch[306/600] Iteration[005/008] Valid loss: 0.0430
2023-02-06 11:34:59 | Valid | Epoch[306/600] Iteration[006/008] Valid loss: 0.0421
2023-02-06 11:34:59 | Valid | Epoch[306/600] Iteration[007/008] Valid loss: 0.0407
2023-02-06 11:34:59 | Valid | Epoch[306/600] Iteration[008/008] Valid loss: 0.0419
2023-02-06 11:34:59 | Valid | Epoch[306/600] MIou: 0.8540616856613155
2023-02-06 11:34:59 | Valid | Epoch[306/600] Pixel Accuracy: 0.9759394327799479
2023-02-06 11:34:59 | Valid | Epoch[306/600] Mean Pixel Accuracy: 0.8672954409238545
2023-02-06 11:34:59 | Stage | Epoch[306/600] Train loss:0.0222
2023-02-06 11:34:59 | Stage | Epoch[306/600] Valid loss:0.0419
2023-02-06 11:34:59 | Stage | Epoch[306/600] LR:0.01

2023-02-06 11:34:59 | Train | Epoch[307/600] Iteration[001/030] Train loss: 0.0240
2023-02-06 11:34:59 | Train | Epoch[307/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:34:59 | Train | Epoch[307/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:34:59 | Train | Epoch[307/600] Iteration[004/030] Train loss: 0.0219
2023-02-06 11:34:59 | Train | Epoch[307/600] Iteration[005/030] Train loss: 0.0224
2023-02-06 11:34:59 | Train | Epoch[307/600] Iteration[006/030] Train loss: 0.0221
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[007/030] Train loss: 0.0221
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[008/030] Train loss: 0.0216
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[009/030] Train loss: 0.0218
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[010/030] Train loss: 0.0217
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[012/030] Train loss: 0.0219
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[013/030] Train loss: 0.0219
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[014/030] Train loss: 0.0216
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[015/030] Train loss: 0.0217
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[016/030] Train loss: 0.0218
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[017/030] Train loss: 0.0217
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[018/030] Train loss: 0.0219
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[019/030] Train loss: 0.0221
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[020/030] Train loss: 0.0219
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[022/030] Train loss: 0.0218
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[025/030] Train loss: 0.0217
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:35:00 | Train | Epoch[307/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:35:01 | Train | Epoch[307/600] Iteration[028/030] Train loss: 0.0221
2023-02-06 11:35:01 | Train | Epoch[307/600] Iteration[029/030] Train loss: 0.0221
2023-02-06 11:35:01 | Train | Epoch[307/600] Iteration[030/030] Train loss: 0.0221
2023-02-06 11:35:01 | Valid | Epoch[307/600] Iteration[001/008] Valid loss: 0.3734
2023-02-06 11:35:01 | Valid | Epoch[307/600] Iteration[002/008] Valid loss: 0.3815
2023-02-06 11:35:01 | Valid | Epoch[307/600] Iteration[003/008] Valid loss: 0.4075
2023-02-06 11:35:01 | Valid | Epoch[307/600] Iteration[004/008] Valid loss: 0.4052
2023-02-06 11:35:01 | Valid | Epoch[307/600] Iteration[005/008] Valid loss: 0.4192
2023-02-06 11:35:01 | Valid | Epoch[307/600] Iteration[006/008] Valid loss: 0.4147
2023-02-06 11:35:01 | Valid | Epoch[307/600] Iteration[007/008] Valid loss: 0.4127
2023-02-06 11:35:01 | Valid | Epoch[307/600] Iteration[008/008] Valid loss: 0.4323
2023-02-06 11:35:01 | Valid | Epoch[307/600] MIou: 0.4548485957258829
2023-02-06 11:35:01 | Valid | Epoch[307/600] Pixel Accuracy: 0.9096832275390625
2023-02-06 11:35:01 | Valid | Epoch[307/600] Mean Pixel Accuracy: 0.5000070393782821
2023-02-06 11:35:01 | Stage | Epoch[307/600] Train loss:0.0221
2023-02-06 11:35:01 | Stage | Epoch[307/600] Valid loss:0.4323
2023-02-06 11:35:01 | Stage | Epoch[307/600] LR:0.01

2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[002/030] Train loss: 0.0203
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[003/030] Train loss: 0.0214
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[010/030] Train loss: 0.0211
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[011/030] Train loss: 0.0217
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[012/030] Train loss: 0.0215
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[013/030] Train loss: 0.0216
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[015/030] Train loss: 0.0214
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 11:35:02 | Train | Epoch[308/600] Iteration[018/030] Train loss: 0.0219
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[019/030] Train loss: 0.0222
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[020/030] Train loss: 0.0220
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[021/030] Train loss: 0.0219
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[022/030] Train loss: 0.0219
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[025/030] Train loss: 0.0220
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[026/030] Train loss: 0.0222
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[028/030] Train loss: 0.0222
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[029/030] Train loss: 0.0223
2023-02-06 11:35:03 | Train | Epoch[308/600] Iteration[030/030] Train loss: 0.0222
2023-02-06 11:35:03 | Valid | Epoch[308/600] Iteration[001/008] Valid loss: 0.0826
2023-02-06 11:35:03 | Valid | Epoch[308/600] Iteration[002/008] Valid loss: 0.0574
2023-02-06 11:35:03 | Valid | Epoch[308/600] Iteration[003/008] Valid loss: 0.0495
2023-02-06 11:35:04 | Valid | Epoch[308/600] Iteration[004/008] Valid loss: 0.0512
2023-02-06 11:35:04 | Valid | Epoch[308/600] Iteration[005/008] Valid loss: 0.0530
2023-02-06 11:35:04 | Valid | Epoch[308/600] Iteration[006/008] Valid loss: 0.0504
2023-02-06 11:35:04 | Valid | Epoch[308/600] Iteration[007/008] Valid loss: 0.0536
2023-02-06 11:35:04 | Valid | Epoch[308/600] Iteration[008/008] Valid loss: 0.0520
2023-02-06 11:35:04 | Valid | Epoch[308/600] MIou: 0.9302467107555483
2023-02-06 11:35:04 | Valid | Epoch[308/600] Pixel Accuracy: 0.988122304280599
2023-02-06 11:35:04 | Valid | Epoch[308/600] Mean Pixel Accuracy: 0.9518272949698066
2023-02-06 11:35:04 | Stage | Epoch[308/600] Train loss:0.0222
2023-02-06 11:35:04 | Stage | Epoch[308/600] Valid loss:0.0520
2023-02-06 11:35:04 | Stage | Epoch[308/600] LR:0.01

2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[002/030] Train loss: 0.0224
2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[003/030] Train loss: 0.0237
2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[004/030] Train loss: 0.0229
2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[005/030] Train loss: 0.0229
2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[006/030] Train loss: 0.0221
2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[007/030] Train loss: 0.0216
2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[008/030] Train loss: 0.0217
2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:35:04 | Train | Epoch[309/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[012/030] Train loss: 0.0214
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[013/030] Train loss: 0.0219
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[014/030] Train loss: 0.0219
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[015/030] Train loss: 0.0221
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[016/030] Train loss: 0.0221
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[018/030] Train loss: 0.0221
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[019/030] Train loss: 0.0220
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[020/030] Train loss: 0.0218
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[021/030] Train loss: 0.0219
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[023/030] Train loss: 0.0221
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[025/030] Train loss: 0.0222
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[028/030] Train loss: 0.0219
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[029/030] Train loss: 0.0219
2023-02-06 11:35:05 | Train | Epoch[309/600] Iteration[030/030] Train loss: 0.0221
2023-02-06 11:35:06 | Valid | Epoch[309/600] Iteration[001/008] Valid loss: 0.0429
2023-02-06 11:35:06 | Valid | Epoch[309/600] Iteration[002/008] Valid loss: 0.0404
2023-02-06 11:35:06 | Valid | Epoch[309/600] Iteration[003/008] Valid loss: 0.0403
2023-02-06 11:35:06 | Valid | Epoch[309/600] Iteration[004/008] Valid loss: 0.0388
2023-02-06 11:35:06 | Valid | Epoch[309/600] Iteration[005/008] Valid loss: 0.0398
2023-02-06 11:35:06 | Valid | Epoch[309/600] Iteration[006/008] Valid loss: 0.0391
2023-02-06 11:35:06 | Valid | Epoch[309/600] Iteration[007/008] Valid loss: 0.0380
2023-02-06 11:35:06 | Valid | Epoch[309/600] Iteration[008/008] Valid loss: 0.0388
2023-02-06 11:35:06 | Valid | Epoch[309/600] MIou: 0.8714487818366908
2023-02-06 11:35:06 | Valid | Epoch[309/600] Pixel Accuracy: 0.9788093566894531
2023-02-06 11:35:06 | Valid | Epoch[309/600] Mean Pixel Accuracy: 0.8832403819501857
2023-02-06 11:35:06 | Stage | Epoch[309/600] Train loss:0.0221
2023-02-06 11:35:06 | Stage | Epoch[309/600] Valid loss:0.0388
2023-02-06 11:35:06 | Stage | Epoch[309/600] LR:0.01

2023-02-06 11:35:06 | Train | Epoch[310/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 11:35:06 | Train | Epoch[310/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:35:06 | Train | Epoch[310/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[005/030] Train loss: 0.0218
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[006/030] Train loss: 0.0219
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[007/030] Train loss: 0.0216
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[008/030] Train loss: 0.0213
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[012/030] Train loss: 0.0214
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[014/030] Train loss: 0.0214
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[018/030] Train loss: 0.0217
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[019/030] Train loss: 0.0215
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[021/030] Train loss: 0.0217
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[022/030] Train loss: 0.0218
2023-02-06 11:35:07 | Train | Epoch[310/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:35:08 | Train | Epoch[310/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:35:08 | Train | Epoch[310/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:35:08 | Train | Epoch[310/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:35:08 | Train | Epoch[310/600] Iteration[027/030] Train loss: 0.0218
2023-02-06 11:35:08 | Train | Epoch[310/600] Iteration[028/030] Train loss: 0.0218
2023-02-06 11:35:08 | Train | Epoch[310/600] Iteration[029/030] Train loss: 0.0218
2023-02-06 11:35:08 | Train | Epoch[310/600] Iteration[030/030] Train loss: 0.0219
2023-02-06 11:35:08 | Valid | Epoch[310/600] Iteration[001/008] Valid loss: 0.2751
2023-02-06 11:35:08 | Valid | Epoch[310/600] Iteration[002/008] Valid loss: 0.1906
2023-02-06 11:35:08 | Valid | Epoch[310/600] Iteration[003/008] Valid loss: 0.1852
2023-02-06 11:35:08 | Valid | Epoch[310/600] Iteration[004/008] Valid loss: 0.1877
2023-02-06 11:35:08 | Valid | Epoch[310/600] Iteration[005/008] Valid loss: 0.2097
2023-02-06 11:35:08 | Valid | Epoch[310/600] Iteration[006/008] Valid loss: 0.2037
2023-02-06 11:35:08 | Valid | Epoch[310/600] Iteration[007/008] Valid loss: 0.2128
2023-02-06 11:35:08 | Valid | Epoch[310/600] Iteration[008/008] Valid loss: 0.2155
2023-02-06 11:35:08 | Valid | Epoch[310/600] MIou: 0.9243409316408919
2023-02-06 11:35:08 | Valid | Epoch[310/600] Pixel Accuracy: 0.9861882527669271
2023-02-06 11:35:08 | Valid | Epoch[310/600] Mean Pixel Accuracy: 0.9789096108147128
2023-02-06 11:35:08 | Stage | Epoch[310/600] Train loss:0.0219
2023-02-06 11:35:08 | Stage | Epoch[310/600] Valid loss:0.2155
2023-02-06 11:35:08 | Stage | Epoch[310/600] LR:0.01

2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[003/030] Train loss: 0.0230
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[004/030] Train loss: 0.0223
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[005/030] Train loss: 0.0224
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[006/030] Train loss: 0.0222
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[007/030] Train loss: 0.0220
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[008/030] Train loss: 0.0219
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[009/030] Train loss: 0.0219
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[010/030] Train loss: 0.0216
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[012/030] Train loss: 0.0220
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[013/030] Train loss: 0.0221
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[014/030] Train loss: 0.0222
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[015/030] Train loss: 0.0220
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[016/030] Train loss: 0.0219
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[017/030] Train loss: 0.0218
2023-02-06 11:35:09 | Train | Epoch[311/600] Iteration[018/030] Train loss: 0.0218
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[019/030] Train loss: 0.0220
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[020/030] Train loss: 0.0221
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[021/030] Train loss: 0.0222
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[025/030] Train loss: 0.0220
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[026/030] Train loss: 0.0220
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[028/030] Train loss: 0.0221
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[029/030] Train loss: 0.0220
2023-02-06 11:35:10 | Train | Epoch[311/600] Iteration[030/030] Train loss: 0.0221
2023-02-06 11:35:10 | Valid | Epoch[311/600] Iteration[001/008] Valid loss: 0.1449
2023-02-06 11:35:10 | Valid | Epoch[311/600] Iteration[002/008] Valid loss: 0.0979
2023-02-06 11:35:10 | Valid | Epoch[311/600] Iteration[003/008] Valid loss: 0.0865
2023-02-06 11:35:10 | Valid | Epoch[311/600] Iteration[004/008] Valid loss: 0.0885
2023-02-06 11:35:10 | Valid | Epoch[311/600] Iteration[005/008] Valid loss: 0.0971
2023-02-06 11:35:11 | Valid | Epoch[311/600] Iteration[006/008] Valid loss: 0.0973
2023-02-06 11:35:11 | Valid | Epoch[311/600] Iteration[007/008] Valid loss: 0.1025
2023-02-06 11:35:11 | Valid | Epoch[311/600] Iteration[008/008] Valid loss: 0.0982
2023-02-06 11:35:11 | Valid | Epoch[311/600] MIou: 0.9400514302695435
2023-02-06 11:35:11 | Valid | Epoch[311/600] Pixel Accuracy: 0.9894549051920573
2023-02-06 11:35:11 | Valid | Epoch[311/600] Mean Pixel Accuracy: 0.9765584339380204
2023-02-06 11:35:11 | Stage | Epoch[311/600] Train loss:0.0221
2023-02-06 11:35:11 | Stage | Epoch[311/600] Valid loss:0.0982
2023-02-06 11:35:11 | Stage | Epoch[311/600] LR:0.01

2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[001/030] Train loss: 0.0230
2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[002/030] Train loss: 0.0236
2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[003/030] Train loss: 0.0229
2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[005/030] Train loss: 0.0228
2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[006/030] Train loss: 0.0226
2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[007/030] Train loss: 0.0223
2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[008/030] Train loss: 0.0221
2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[009/030] Train loss: 0.0222
2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:35:11 | Train | Epoch[312/600] Iteration[011/030] Train loss: 0.0221
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[012/030] Train loss: 0.0219
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[013/030] Train loss: 0.0220
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[014/030] Train loss: 0.0222
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[015/030] Train loss: 0.0223
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[016/030] Train loss: 0.0224
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[017/030] Train loss: 0.0223
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[018/030] Train loss: 0.0226
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[019/030] Train loss: 0.0223
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[020/030] Train loss: 0.0224
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[021/030] Train loss: 0.0222
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[024/030] Train loss: 0.0220
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[026/030] Train loss: 0.0219
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[027/030] Train loss: 0.0219
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[028/030] Train loss: 0.0220
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[029/030] Train loss: 0.0220
2023-02-06 11:35:12 | Train | Epoch[312/600] Iteration[030/030] Train loss: 0.0219
2023-02-06 11:35:13 | Valid | Epoch[312/600] Iteration[001/008] Valid loss: 0.0475
2023-02-06 11:35:13 | Valid | Epoch[312/600] Iteration[002/008] Valid loss: 0.0378
2023-02-06 11:35:13 | Valid | Epoch[312/600] Iteration[003/008] Valid loss: 0.0356
2023-02-06 11:35:13 | Valid | Epoch[312/600] Iteration[004/008] Valid loss: 0.0334
2023-02-06 11:35:13 | Valid | Epoch[312/600] Iteration[005/008] Valid loss: 0.0336
2023-02-06 11:35:13 | Valid | Epoch[312/600] Iteration[006/008] Valid loss: 0.0331
2023-02-06 11:35:13 | Valid | Epoch[312/600] Iteration[007/008] Valid loss: 0.0325
2023-02-06 11:35:13 | Valid | Epoch[312/600] Iteration[008/008] Valid loss: 0.0325
2023-02-06 11:35:13 | Valid | Epoch[312/600] MIou: 0.9087193879732847
2023-02-06 11:35:13 | Valid | Epoch[312/600] Pixel Accuracy: 0.98486328125
2023-02-06 11:35:13 | Valid | Epoch[312/600] Mean Pixel Accuracy: 0.9200328857230573
2023-02-06 11:35:13 | Stage | Epoch[312/600] Train loss:0.0219
2023-02-06 11:35:13 | Stage | Epoch[312/600] Valid loss:0.0325
2023-02-06 11:35:13 | Stage | Epoch[312/600] LR:0.01

2023-02-06 11:35:13 | Train | Epoch[313/600] Iteration[001/030] Train loss: 0.0195
2023-02-06 11:35:13 | Train | Epoch[313/600] Iteration[002/030] Train loss: 0.0226
2023-02-06 11:35:13 | Train | Epoch[313/600] Iteration[003/030] Train loss: 0.0219
2023-02-06 11:35:13 | Train | Epoch[313/600] Iteration[004/030] Train loss: 0.0222
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[005/030] Train loss: 0.0223
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[006/030] Train loss: 0.0227
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[007/030] Train loss: 0.0223
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[008/030] Train loss: 0.0225
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[009/030] Train loss: 0.0221
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[010/030] Train loss: 0.0220
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[011/030] Train loss: 0.0218
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[012/030] Train loss: 0.0217
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[013/030] Train loss: 0.0216
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[014/030] Train loss: 0.0216
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[015/030] Train loss: 0.0217
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[018/030] Train loss: 0.0217
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[019/030] Train loss: 0.0215
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[020/030] Train loss: 0.0215
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[021/030] Train loss: 0.0217
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[022/030] Train loss: 0.0216
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 11:35:14 | Train | Epoch[313/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 11:35:15 | Train | Epoch[313/600] Iteration[025/030] Train loss: 0.0215
2023-02-06 11:35:15 | Train | Epoch[313/600] Iteration[026/030] Train loss: 0.0215
2023-02-06 11:35:15 | Train | Epoch[313/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:35:15 | Train | Epoch[313/600] Iteration[028/030] Train loss: 0.0218
2023-02-06 11:35:15 | Train | Epoch[313/600] Iteration[029/030] Train loss: 0.0218
2023-02-06 11:35:15 | Train | Epoch[313/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:35:15 | Valid | Epoch[313/600] Iteration[001/008] Valid loss: 0.0761
2023-02-06 11:35:15 | Valid | Epoch[313/600] Iteration[002/008] Valid loss: 0.0754
2023-02-06 11:35:15 | Valid | Epoch[313/600] Iteration[003/008] Valid loss: 0.0766
2023-02-06 11:35:15 | Valid | Epoch[313/600] Iteration[004/008] Valid loss: 0.0744
2023-02-06 11:35:15 | Valid | Epoch[313/600] Iteration[005/008] Valid loss: 0.0757
2023-02-06 11:35:15 | Valid | Epoch[313/600] Iteration[006/008] Valid loss: 0.0742
2023-02-06 11:35:15 | Valid | Epoch[313/600] Iteration[007/008] Valid loss: 0.0720
2023-02-06 11:35:15 | Valid | Epoch[313/600] Iteration[008/008] Valid loss: 0.0743
2023-02-06 11:35:15 | Valid | Epoch[313/600] MIou: 0.7707851922419061
2023-02-06 11:35:15 | Valid | Epoch[313/600] Pixel Accuracy: 0.9621988932291666
2023-02-06 11:35:15 | Valid | Epoch[313/600] Mean Pixel Accuracy: 0.7907333624294302
2023-02-06 11:35:15 | Stage | Epoch[313/600] Train loss:0.0217
2023-02-06 11:35:15 | Stage | Epoch[313/600] Valid loss:0.0743
2023-02-06 11:35:15 | Stage | Epoch[313/600] LR:0.01

2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[002/030] Train loss: 0.0209
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[007/030] Train loss: 0.0214
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[008/030] Train loss: 0.0219
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[009/030] Train loss: 0.0218
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[010/030] Train loss: 0.0220
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[011/030] Train loss: 0.0215
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[012/030] Train loss: 0.0218
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[013/030] Train loss: 0.0218
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[014/030] Train loss: 0.0219
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:35:16 | Train | Epoch[314/600] Iteration[016/030] Train loss: 0.0217
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[018/030] Train loss: 0.0219
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[019/030] Train loss: 0.0219
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[020/030] Train loss: 0.0219
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[021/030] Train loss: 0.0219
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[024/030] Train loss: 0.0221
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[025/030] Train loss: 0.0219
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[026/030] Train loss: 0.0219
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[027/030] Train loss: 0.0218
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[028/030] Train loss: 0.0219
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[029/030] Train loss: 0.0220
2023-02-06 11:35:17 | Train | Epoch[314/600] Iteration[030/030] Train loss: 0.0220
2023-02-06 11:35:17 | Valid | Epoch[314/600] Iteration[001/008] Valid loss: 0.9477
2023-02-06 11:35:18 | Valid | Epoch[314/600] Iteration[002/008] Valid loss: 0.8720
2023-02-06 11:35:18 | Valid | Epoch[314/600] Iteration[003/008] Valid loss: 0.8857
2023-02-06 11:35:18 | Valid | Epoch[314/600] Iteration[004/008] Valid loss: 0.9108
2023-02-06 11:35:18 | Valid | Epoch[314/600] Iteration[005/008] Valid loss: 0.9477
2023-02-06 11:35:18 | Valid | Epoch[314/600] Iteration[006/008] Valid loss: 0.9332
2023-02-06 11:35:18 | Valid | Epoch[314/600] Iteration[007/008] Valid loss: 0.9767
2023-02-06 11:35:18 | Valid | Epoch[314/600] Iteration[008/008] Valid loss: 0.9962
2023-02-06 11:35:18 | Valid | Epoch[314/600] MIou: 0.8465194279195594
2023-02-06 11:35:18 | Valid | Epoch[314/600] Pixel Accuracy: 0.9666786193847656
2023-02-06 11:35:18 | Valid | Epoch[314/600] Mean Pixel Accuracy: 0.9797639852231953
2023-02-06 11:35:18 | Stage | Epoch[314/600] Train loss:0.0220
2023-02-06 11:35:18 | Stage | Epoch[314/600] Valid loss:0.9962
2023-02-06 11:35:18 | Stage | Epoch[314/600] LR:0.01

2023-02-06 11:35:18 | Train | Epoch[315/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 11:35:18 | Train | Epoch[315/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 11:35:18 | Train | Epoch[315/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 11:35:18 | Train | Epoch[315/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:35:18 | Train | Epoch[315/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 11:35:18 | Train | Epoch[315/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:35:18 | Train | Epoch[315/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:35:18 | Train | Epoch[315/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:35:18 | Train | Epoch[315/600] Iteration[009/030] Train loss: 0.0211
2023-02-06 11:35:18 | Train | Epoch[315/600] Iteration[010/030] Train loss: 0.0211
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[012/030] Train loss: 0.0213
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[014/030] Train loss: 0.0212
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[015/030] Train loss: 0.0213
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[016/030] Train loss: 0.0211
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[017/030] Train loss: 0.0213
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[018/030] Train loss: 0.0216
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[020/030] Train loss: 0.0218
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[022/030] Train loss: 0.0218
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[025/030] Train loss: 0.0222
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[027/030] Train loss: 0.0223
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[028/030] Train loss: 0.0222
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[029/030] Train loss: 0.0221
2023-02-06 11:35:19 | Train | Epoch[315/600] Iteration[030/030] Train loss: 0.0222
2023-02-06 11:35:20 | Valid | Epoch[315/600] Iteration[001/008] Valid loss: 0.3278
2023-02-06 11:35:20 | Valid | Epoch[315/600] Iteration[002/008] Valid loss: 0.2625
2023-02-06 11:35:20 | Valid | Epoch[315/600] Iteration[003/008] Valid loss: 0.2506
2023-02-06 11:35:20 | Valid | Epoch[315/600] Iteration[004/008] Valid loss: 0.2512
2023-02-06 11:35:20 | Valid | Epoch[315/600] Iteration[005/008] Valid loss: 0.2628
2023-02-06 11:35:20 | Valid | Epoch[315/600] Iteration[006/008] Valid loss: 0.2586
2023-02-06 11:35:20 | Valid | Epoch[315/600] Iteration[007/008] Valid loss: 0.2771
2023-02-06 11:35:20 | Valid | Epoch[315/600] Iteration[008/008] Valid loss: 0.2806
2023-02-06 11:35:20 | Valid | Epoch[315/600] MIou: 0.9143990696811148
2023-02-06 11:35:20 | Valid | Epoch[315/600] Pixel Accuracy: 0.9839286804199219
2023-02-06 11:35:20 | Valid | Epoch[315/600] Mean Pixel Accuracy: 0.9825054332480858
2023-02-06 11:35:20 | Stage | Epoch[315/600] Train loss:0.0222
2023-02-06 11:35:20 | Stage | Epoch[315/600] Valid loss:0.2806
2023-02-06 11:35:20 | Stage | Epoch[315/600] LR:0.01

2023-02-06 11:35:20 | Train | Epoch[316/600] Iteration[001/030] Train loss: 0.0213
2023-02-06 11:35:20 | Train | Epoch[316/600] Iteration[002/030] Train loss: 0.0219
2023-02-06 11:35:20 | Train | Epoch[316/600] Iteration[003/030] Train loss: 0.0219
2023-02-06 11:35:20 | Train | Epoch[316/600] Iteration[004/030] Train loss: 0.0222
2023-02-06 11:35:20 | Train | Epoch[316/600] Iteration[005/030] Train loss: 0.0216
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[006/030] Train loss: 0.0217
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[007/030] Train loss: 0.0216
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[008/030] Train loss: 0.0219
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[009/030] Train loss: 0.0221
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[010/030] Train loss: 0.0217
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[011/030] Train loss: 0.0217
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[012/030] Train loss: 0.0216
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[013/030] Train loss: 0.0216
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[015/030] Train loss: 0.0219
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[016/030] Train loss: 0.0219
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[019/030] Train loss: 0.0219
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[020/030] Train loss: 0.0219
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[022/030] Train loss: 0.0217
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 11:35:21 | Train | Epoch[316/600] Iteration[025/030] Train loss: 0.0217
2023-02-06 11:35:22 | Train | Epoch[316/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 11:35:22 | Train | Epoch[316/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 11:35:22 | Train | Epoch[316/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:35:22 | Train | Epoch[316/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:35:22 | Train | Epoch[316/600] Iteration[030/030] Train loss: 0.0215
2023-02-06 11:35:22 | Valid | Epoch[316/600] Iteration[001/008] Valid loss: 0.3999
2023-02-06 11:35:22 | Valid | Epoch[316/600] Iteration[002/008] Valid loss: 0.3183
2023-02-06 11:35:22 | Valid | Epoch[316/600] Iteration[003/008] Valid loss: 0.3025
2023-02-06 11:35:22 | Valid | Epoch[316/600] Iteration[004/008] Valid loss: 0.2999
2023-02-06 11:35:22 | Valid | Epoch[316/600] Iteration[005/008] Valid loss: 0.3187
2023-02-06 11:35:22 | Valid | Epoch[316/600] Iteration[006/008] Valid loss: 0.3112
2023-02-06 11:35:22 | Valid | Epoch[316/600] Iteration[007/008] Valid loss: 0.3317
2023-02-06 11:35:22 | Valid | Epoch[316/600] Iteration[008/008] Valid loss: 0.3338
2023-02-06 11:35:22 | Valid | Epoch[316/600] MIou: 0.907213666514071
2023-02-06 11:35:22 | Valid | Epoch[316/600] Pixel Accuracy: 0.9822718302408854
2023-02-06 11:35:22 | Valid | Epoch[316/600] Mean Pixel Accuracy: 0.9836617514396744
2023-02-06 11:35:22 | Stage | Epoch[316/600] Train loss:0.0215
2023-02-06 11:35:22 | Stage | Epoch[316/600] Valid loss:0.3338
2023-02-06 11:35:22 | Stage | Epoch[316/600] LR:0.01

2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[002/030] Train loss: 0.0228
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[004/030] Train loss: 0.0226
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[005/030] Train loss: 0.0221
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[006/030] Train loss: 0.0231
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[007/030] Train loss: 0.0229
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[008/030] Train loss: 0.0227
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[009/030] Train loss: 0.0226
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[010/030] Train loss: 0.0220
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[011/030] Train loss: 0.0221
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[012/030] Train loss: 0.0223
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[013/030] Train loss: 0.0220
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[014/030] Train loss: 0.0222
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[015/030] Train loss: 0.0222
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[016/030] Train loss: 0.0221
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[017/030] Train loss: 0.0221
2023-02-06 11:35:23 | Train | Epoch[317/600] Iteration[018/030] Train loss: 0.0222
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[019/030] Train loss: 0.0222
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[020/030] Train loss: 0.0222
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[021/030] Train loss: 0.0221
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[024/030] Train loss: 0.0220
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[025/030] Train loss: 0.0221
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[027/030] Train loss: 0.0223
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[028/030] Train loss: 0.0223
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[029/030] Train loss: 0.0223
2023-02-06 11:35:24 | Train | Epoch[317/600] Iteration[030/030] Train loss: 0.0224
2023-02-06 11:35:24 | Valid | Epoch[317/600] Iteration[001/008] Valid loss: 0.0628
2023-02-06 11:35:24 | Valid | Epoch[317/600] Iteration[002/008] Valid loss: 0.0468
2023-02-06 11:35:24 | Valid | Epoch[317/600] Iteration[003/008] Valid loss: 0.0425
2023-02-06 11:35:24 | Valid | Epoch[317/600] Iteration[004/008] Valid loss: 0.0415
2023-02-06 11:35:25 | Valid | Epoch[317/600] Iteration[005/008] Valid loss: 0.0454
2023-02-06 11:35:25 | Valid | Epoch[317/600] Iteration[006/008] Valid loss: 0.0460
2023-02-06 11:35:25 | Valid | Epoch[317/600] Iteration[007/008] Valid loss: 0.0473
2023-02-06 11:35:25 | Valid | Epoch[317/600] Iteration[008/008] Valid loss: 0.0457
2023-02-06 11:35:25 | Valid | Epoch[317/600] MIou: 0.9355438434151551
2023-02-06 11:35:25 | Valid | Epoch[317/600] Pixel Accuracy: 0.9890213012695312
2023-02-06 11:35:25 | Valid | Epoch[317/600] Mean Pixel Accuracy: 0.9569943495606208
2023-02-06 11:35:25 | Stage | Epoch[317/600] Train loss:0.0224
2023-02-06 11:35:25 | Stage | Epoch[317/600] Valid loss:0.0457
2023-02-06 11:35:25 | Stage | Epoch[317/600] LR:0.01

2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[003/030] Train loss: 0.0208
2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[005/030] Train loss: 0.0223
2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[007/030] Train loss: 0.0224
2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[008/030] Train loss: 0.0221
2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[009/030] Train loss: 0.0223
2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[010/030] Train loss: 0.0226
2023-02-06 11:35:25 | Train | Epoch[318/600] Iteration[011/030] Train loss: 0.0224
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[012/030] Train loss: 0.0222
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[013/030] Train loss: 0.0219
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[014/030] Train loss: 0.0221
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[016/030] Train loss: 0.0218
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[018/030] Train loss: 0.0221
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[019/030] Train loss: 0.0224
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[020/030] Train loss: 0.0225
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[021/030] Train loss: 0.0225
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[023/030] Train loss: 0.0226
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[024/030] Train loss: 0.0226
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[025/030] Train loss: 0.0226
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[026/030] Train loss: 0.0225
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[027/030] Train loss: 0.0225
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[028/030] Train loss: 0.0224
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[029/030] Train loss: 0.0225
2023-02-06 11:35:26 | Train | Epoch[318/600] Iteration[030/030] Train loss: 0.0225
2023-02-06 11:35:27 | Valid | Epoch[318/600] Iteration[001/008] Valid loss: 0.0630
2023-02-06 11:35:27 | Valid | Epoch[318/600] Iteration[002/008] Valid loss: 0.0602
2023-02-06 11:35:27 | Valid | Epoch[318/600] Iteration[003/008] Valid loss: 0.0595
2023-02-06 11:35:27 | Valid | Epoch[318/600] Iteration[004/008] Valid loss: 0.0571
2023-02-06 11:35:27 | Valid | Epoch[318/600] Iteration[005/008] Valid loss: 0.0590
2023-02-06 11:35:27 | Valid | Epoch[318/600] Iteration[006/008] Valid loss: 0.0575
2023-02-06 11:35:27 | Valid | Epoch[318/600] Iteration[007/008] Valid loss: 0.0555
2023-02-06 11:35:27 | Valid | Epoch[318/600] Iteration[008/008] Valid loss: 0.0566
2023-02-06 11:35:27 | Valid | Epoch[318/600] MIou: 0.8290272579321065
2023-02-06 11:35:27 | Valid | Epoch[318/600] Pixel Accuracy: 0.97174072265625
2023-02-06 11:35:27 | Valid | Epoch[318/600] Mean Pixel Accuracy: 0.8451166130503562
2023-02-06 11:35:27 | Stage | Epoch[318/600] Train loss:0.0225
2023-02-06 11:35:27 | Stage | Epoch[318/600] Valid loss:0.0566
2023-02-06 11:35:27 | Stage | Epoch[318/600] LR:0.01

2023-02-06 11:35:27 | Train | Epoch[319/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 11:35:27 | Train | Epoch[319/600] Iteration[002/030] Train loss: 0.0231
2023-02-06 11:35:27 | Train | Epoch[319/600] Iteration[003/030] Train loss: 0.0225
2023-02-06 11:35:27 | Train | Epoch[319/600] Iteration[004/030] Train loss: 0.0221
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[005/030] Train loss: 0.0222
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[006/030] Train loss: 0.0222
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[008/030] Train loss: 0.0215
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[009/030] Train loss: 0.0221
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[010/030] Train loss: 0.0227
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[011/030] Train loss: 0.0226
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[012/030] Train loss: 0.0225
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[014/030] Train loss: 0.0225
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[015/030] Train loss: 0.0223
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[016/030] Train loss: 0.0225
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[017/030] Train loss: 0.0225
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[018/030] Train loss: 0.0225
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[019/030] Train loss: 0.0223
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[020/030] Train loss: 0.0223
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[021/030] Train loss: 0.0223
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[022/030] Train loss: 0.0223
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[023/030] Train loss: 0.0222
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:35:28 | Train | Epoch[319/600] Iteration[025/030] Train loss: 0.0222
2023-02-06 11:35:29 | Train | Epoch[319/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:35:29 | Train | Epoch[319/600] Iteration[027/030] Train loss: 0.0222
2023-02-06 11:35:29 | Train | Epoch[319/600] Iteration[028/030] Train loss: 0.0224
2023-02-06 11:35:29 | Train | Epoch[319/600] Iteration[029/030] Train loss: 0.0223
2023-02-06 11:35:29 | Train | Epoch[319/600] Iteration[030/030] Train loss: 0.0221
2023-02-06 11:35:29 | Valid | Epoch[319/600] Iteration[001/008] Valid loss: 0.0937
2023-02-06 11:35:29 | Valid | Epoch[319/600] Iteration[002/008] Valid loss: 0.0966
2023-02-06 11:35:29 | Valid | Epoch[319/600] Iteration[003/008] Valid loss: 0.0987
2023-02-06 11:35:29 | Valid | Epoch[319/600] Iteration[004/008] Valid loss: 0.0975
2023-02-06 11:35:29 | Valid | Epoch[319/600] Iteration[005/008] Valid loss: 0.0988
2023-02-06 11:35:29 | Valid | Epoch[319/600] Iteration[006/008] Valid loss: 0.0969
2023-02-06 11:35:29 | Valid | Epoch[319/600] Iteration[007/008] Valid loss: 0.0938
2023-02-06 11:35:29 | Valid | Epoch[319/600] Iteration[008/008] Valid loss: 0.0967
2023-02-06 11:35:29 | Valid | Epoch[319/600] MIou: 0.723187321636381
2023-02-06 11:35:29 | Valid | Epoch[319/600] Pixel Accuracy: 0.9543164571126302
2023-02-06 11:35:29 | Valid | Epoch[319/600] Mean Pixel Accuracy: 0.7470962564586295
2023-02-06 11:35:29 | Stage | Epoch[319/600] Train loss:0.0221
2023-02-06 11:35:29 | Stage | Epoch[319/600] Valid loss:0.0967
2023-02-06 11:35:29 | Stage | Epoch[319/600] LR:0.01

2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[002/030] Train loss: 0.0206
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[004/030] Train loss: 0.0213
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[005/030] Train loss: 0.0212
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[007/030] Train loss: 0.0214
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[008/030] Train loss: 0.0216
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[009/030] Train loss: 0.0218
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[010/030] Train loss: 0.0215
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[011/030] Train loss: 0.0218
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[012/030] Train loss: 0.0216
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[013/030] Train loss: 0.0219
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[015/030] Train loss: 0.0217
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[016/030] Train loss: 0.0217
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[018/030] Train loss: 0.0215
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[019/030] Train loss: 0.0215
2023-02-06 11:35:30 | Train | Epoch[320/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 11:35:31 | Train | Epoch[320/600] Iteration[021/030] Train loss: 0.0216
2023-02-06 11:35:31 | Train | Epoch[320/600] Iteration[022/030] Train loss: 0.0218
2023-02-06 11:35:31 | Train | Epoch[320/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:35:31 | Train | Epoch[320/600] Iteration[024/030] Train loss: 0.0221
2023-02-06 11:35:31 | Train | Epoch[320/600] Iteration[025/030] Train loss: 0.0221
2023-02-06 11:35:31 | Train | Epoch[320/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:35:31 | Train | Epoch[320/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:35:31 | Train | Epoch[320/600] Iteration[028/030] Train loss: 0.0220
2023-02-06 11:35:31 | Train | Epoch[320/600] Iteration[029/030] Train loss: 0.0220
2023-02-06 11:35:31 | Train | Epoch[320/600] Iteration[030/030] Train loss: 0.0219
2023-02-06 11:35:31 | Valid | Epoch[320/600] Iteration[001/008] Valid loss: 0.1096
2023-02-06 11:35:31 | Valid | Epoch[320/600] Iteration[002/008] Valid loss: 0.1103
2023-02-06 11:35:31 | Valid | Epoch[320/600] Iteration[003/008] Valid loss: 0.1141
2023-02-06 11:35:31 | Valid | Epoch[320/600] Iteration[004/008] Valid loss: 0.1116
2023-02-06 11:35:31 | Valid | Epoch[320/600] Iteration[005/008] Valid loss: 0.1140
2023-02-06 11:35:31 | Valid | Epoch[320/600] Iteration[006/008] Valid loss: 0.1124
2023-02-06 11:35:31 | Valid | Epoch[320/600] Iteration[007/008] Valid loss: 0.1093
2023-02-06 11:35:31 | Valid | Epoch[320/600] Iteration[008/008] Valid loss: 0.1140
2023-02-06 11:35:32 | Valid | Epoch[320/600] MIou: 0.6509275703005315
2023-02-06 11:35:32 | Valid | Epoch[320/600] Pixel Accuracy: 0.9423294067382812
2023-02-06 11:35:32 | Valid | Epoch[320/600] Mean Pixel Accuracy: 0.6807360373931775
2023-02-06 11:35:32 | Stage | Epoch[320/600] Train loss:0.0219
2023-02-06 11:35:32 | Stage | Epoch[320/600] Valid loss:0.1140
2023-02-06 11:35:32 | Stage | Epoch[320/600] LR:0.01

2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[001/030] Train loss: 0.0223
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[002/030] Train loss: 0.0227
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[003/030] Train loss: 0.0227
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[004/030] Train loss: 0.0223
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[005/030] Train loss: 0.0220
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[006/030] Train loss: 0.0215
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[007/030] Train loss: 0.0212
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[010/030] Train loss: 0.0218
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[011/030] Train loss: 0.0217
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[012/030] Train loss: 0.0221
2023-02-06 11:35:32 | Train | Epoch[321/600] Iteration[013/030] Train loss: 0.0220
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[014/030] Train loss: 0.0219
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[015/030] Train loss: 0.0219
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[016/030] Train loss: 0.0219
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[017/030] Train loss: 0.0221
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[018/030] Train loss: 0.0219
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[019/030] Train loss: 0.0220
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[020/030] Train loss: 0.0221
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[021/030] Train loss: 0.0221
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[023/030] Train loss: 0.0221
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[024/030] Train loss: 0.0220
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[025/030] Train loss: 0.0220
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[027/030] Train loss: 0.0220
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[028/030] Train loss: 0.0220
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[029/030] Train loss: 0.0220
2023-02-06 11:35:33 | Train | Epoch[321/600] Iteration[030/030] Train loss: 0.0220
2023-02-06 11:35:34 | Valid | Epoch[321/600] Iteration[001/008] Valid loss: 0.1841
2023-02-06 11:35:34 | Valid | Epoch[321/600] Iteration[002/008] Valid loss: 0.1213
2023-02-06 11:35:34 | Valid | Epoch[321/600] Iteration[003/008] Valid loss: 0.1082
2023-02-06 11:35:34 | Valid | Epoch[321/600] Iteration[004/008] Valid loss: 0.1073
2023-02-06 11:35:34 | Valid | Epoch[321/600] Iteration[005/008] Valid loss: 0.1251
2023-02-06 11:35:34 | Valid | Epoch[321/600] Iteration[006/008] Valid loss: 0.1271
2023-02-06 11:35:34 | Valid | Epoch[321/600] Iteration[007/008] Valid loss: 0.1307
2023-02-06 11:35:34 | Valid | Epoch[321/600] Iteration[008/008] Valid loss: 0.1289
2023-02-06 11:35:34 | Valid | Epoch[321/600] MIou: 0.9289514273183507
2023-02-06 11:35:34 | Valid | Epoch[321/600] Pixel Accuracy: 0.9872856140136719
2023-02-06 11:35:34 | Valid | Epoch[321/600] Mean Pixel Accuracy: 0.9738634072399859
2023-02-06 11:35:34 | Stage | Epoch[321/600] Train loss:0.0220
2023-02-06 11:35:34 | Stage | Epoch[321/600] Valid loss:0.1289
2023-02-06 11:35:34 | Stage | Epoch[321/600] LR:0.01

2023-02-06 11:35:34 | Train | Epoch[322/600] Iteration[001/030] Train loss: 0.0207
2023-02-06 11:35:34 | Train | Epoch[322/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 11:35:34 | Train | Epoch[322/600] Iteration[003/030] Train loss: 0.0230
2023-02-06 11:35:34 | Train | Epoch[322/600] Iteration[004/030] Train loss: 0.0217
2023-02-06 11:35:34 | Train | Epoch[322/600] Iteration[005/030] Train loss: 0.0213
2023-02-06 11:35:34 | Train | Epoch[322/600] Iteration[006/030] Train loss: 0.0209
2023-02-06 11:35:34 | Train | Epoch[322/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[008/030] Train loss: 0.0214
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[011/030] Train loss: 0.0212
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[012/030] Train loss: 0.0213
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[014/030] Train loss: 0.0216
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[015/030] Train loss: 0.0224
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[016/030] Train loss: 0.0224
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[018/030] Train loss: 0.0224
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[019/030] Train loss: 0.0226
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[020/030] Train loss: 0.0225
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[021/030] Train loss: 0.0227
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[022/030] Train loss: 0.0226
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[023/030] Train loss: 0.0228
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[024/030] Train loss: 0.0228
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[025/030] Train loss: 0.0227
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[026/030] Train loss: 0.0228
2023-02-06 11:35:35 | Train | Epoch[322/600] Iteration[027/030] Train loss: 0.0228
2023-02-06 11:35:36 | Train | Epoch[322/600] Iteration[028/030] Train loss: 0.0227
2023-02-06 11:35:36 | Train | Epoch[322/600] Iteration[029/030] Train loss: 0.0228
2023-02-06 11:35:36 | Train | Epoch[322/600] Iteration[030/030] Train loss: 0.0227
2023-02-06 11:35:36 | Valid | Epoch[322/600] Iteration[001/008] Valid loss: 0.0511
2023-02-06 11:35:36 | Valid | Epoch[322/600] Iteration[002/008] Valid loss: 0.0485
2023-02-06 11:35:36 | Valid | Epoch[322/600] Iteration[003/008] Valid loss: 0.0494
2023-02-06 11:35:36 | Valid | Epoch[322/600] Iteration[004/008] Valid loss: 0.0477
2023-02-06 11:35:36 | Valid | Epoch[322/600] Iteration[005/008] Valid loss: 0.0481
2023-02-06 11:35:36 | Valid | Epoch[322/600] Iteration[006/008] Valid loss: 0.0474
2023-02-06 11:35:36 | Valid | Epoch[322/600] Iteration[007/008] Valid loss: 0.0458
2023-02-06 11:35:36 | Valid | Epoch[322/600] Iteration[008/008] Valid loss: 0.0470
2023-02-06 11:35:36 | Valid | Epoch[322/600] MIou: 0.8446766074188182
2023-02-06 11:35:36 | Valid | Epoch[322/600] Pixel Accuracy: 0.9743906656901041
2023-02-06 11:35:36 | Valid | Epoch[322/600] Mean Pixel Accuracy: 0.8586770948756598
2023-02-06 11:35:36 | Stage | Epoch[322/600] Train loss:0.0227
2023-02-06 11:35:36 | Stage | Epoch[322/600] Valid loss:0.0470
2023-02-06 11:35:36 | Stage | Epoch[322/600] LR:0.01

2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[001/030] Train loss: 0.0205
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[005/030] Train loss: 0.0220
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[007/030] Train loss: 0.0213
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[008/030] Train loss: 0.0214
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[010/030] Train loss: 0.0215
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[012/030] Train loss: 0.0211
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[015/030] Train loss: 0.0219
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[016/030] Train loss: 0.0219
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[017/030] Train loss: 0.0219
2023-02-06 11:35:37 | Train | Epoch[323/600] Iteration[018/030] Train loss: 0.0217
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[019/030] Train loss: 0.0215
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[020/030] Train loss: 0.0214
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[021/030] Train loss: 0.0214
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[022/030] Train loss: 0.0215
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[025/030] Train loss: 0.0216
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:35:38 | Train | Epoch[323/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:35:38 | Valid | Epoch[323/600] Iteration[001/008] Valid loss: 0.0462
2023-02-06 11:35:38 | Valid | Epoch[323/600] Iteration[002/008] Valid loss: 0.0438
2023-02-06 11:35:38 | Valid | Epoch[323/600] Iteration[003/008] Valid loss: 0.0439
2023-02-06 11:35:38 | Valid | Epoch[323/600] Iteration[004/008] Valid loss: 0.0422
2023-02-06 11:35:38 | Valid | Epoch[323/600] Iteration[005/008] Valid loss: 0.0431
2023-02-06 11:35:39 | Valid | Epoch[323/600] Iteration[006/008] Valid loss: 0.0424
2023-02-06 11:35:39 | Valid | Epoch[323/600] Iteration[007/008] Valid loss: 0.0411
2023-02-06 11:35:39 | Valid | Epoch[323/600] Iteration[008/008] Valid loss: 0.0422
2023-02-06 11:35:39 | Valid | Epoch[323/600] MIou: 0.8523042647599146
2023-02-06 11:35:39 | Valid | Epoch[323/600] Pixel Accuracy: 0.9756546020507812
2023-02-06 11:35:39 | Valid | Epoch[323/600] Mean Pixel Accuracy: 0.8656044917014444
2023-02-06 11:35:39 | Stage | Epoch[323/600] Train loss:0.0216
2023-02-06 11:35:39 | Stage | Epoch[323/600] Valid loss:0.0422
2023-02-06 11:35:39 | Stage | Epoch[323/600] LR:0.01

2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[005/030] Train loss: 0.0224
2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[006/030] Train loss: 0.0222
2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[007/030] Train loss: 0.0221
2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[008/030] Train loss: 0.0219
2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[009/030] Train loss: 0.0224
2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:35:39 | Train | Epoch[324/600] Iteration[011/030] Train loss: 0.0224
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[012/030] Train loss: 0.0226
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[013/030] Train loss: 0.0225
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[014/030] Train loss: 0.0227
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[015/030] Train loss: 0.0229
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[016/030] Train loss: 0.0228
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[017/030] Train loss: 0.0227
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[018/030] Train loss: 0.0227
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[019/030] Train loss: 0.0228
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[020/030] Train loss: 0.0229
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[021/030] Train loss: 0.0229
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[022/030] Train loss: 0.0228
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[023/030] Train loss: 0.0230
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[024/030] Train loss: 0.0229
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[025/030] Train loss: 0.0229
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[026/030] Train loss: 0.0229
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[027/030] Train loss: 0.0228
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[028/030] Train loss: 0.0229
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[029/030] Train loss: 0.0229
2023-02-06 11:35:40 | Train | Epoch[324/600] Iteration[030/030] Train loss: 0.0228
2023-02-06 11:35:41 | Valid | Epoch[324/600] Iteration[001/008] Valid loss: 0.3104
2023-02-06 11:35:41 | Valid | Epoch[324/600] Iteration[002/008] Valid loss: 0.3170
2023-02-06 11:35:41 | Valid | Epoch[324/600] Iteration[003/008] Valid loss: 0.3348
2023-02-06 11:35:41 | Valid | Epoch[324/600] Iteration[004/008] Valid loss: 0.3320
2023-02-06 11:35:41 | Valid | Epoch[324/600] Iteration[005/008] Valid loss: 0.3419
2023-02-06 11:35:41 | Valid | Epoch[324/600] Iteration[006/008] Valid loss: 0.3386
2023-02-06 11:35:41 | Valid | Epoch[324/600] Iteration[007/008] Valid loss: 0.3356
2023-02-06 11:35:41 | Valid | Epoch[324/600] Iteration[008/008] Valid loss: 0.3500
2023-02-06 11:35:41 | Valid | Epoch[324/600] MIou: 0.45668451378472147
2023-02-06 11:35:41 | Valid | Epoch[324/600] Pixel Accuracy: 0.9099896748860677
2023-02-06 11:35:41 | Valid | Epoch[324/600] Mean Pixel Accuracy: 0.5017035295442707
2023-02-06 11:35:41 | Stage | Epoch[324/600] Train loss:0.0228
2023-02-06 11:35:41 | Stage | Epoch[324/600] Valid loss:0.3500
2023-02-06 11:35:41 | Stage | Epoch[324/600] LR:0.01

2023-02-06 11:35:41 | Train | Epoch[325/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 11:35:41 | Train | Epoch[325/600] Iteration[002/030] Train loss: 0.0221
2023-02-06 11:35:41 | Train | Epoch[325/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:35:41 | Train | Epoch[325/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[005/030] Train loss: 0.0212
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[009/030] Train loss: 0.0209
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[012/030] Train loss: 0.0211
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[014/030] Train loss: 0.0215
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[018/030] Train loss: 0.0213
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[020/030] Train loss: 0.0215
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[021/030] Train loss: 0.0215
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[022/030] Train loss: 0.0216
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[023/030] Train loss: 0.0218
2023-02-06 11:35:42 | Train | Epoch[325/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:35:43 | Train | Epoch[325/600] Iteration[025/030] Train loss: 0.0220
2023-02-06 11:35:43 | Train | Epoch[325/600] Iteration[026/030] Train loss: 0.0219
2023-02-06 11:35:43 | Train | Epoch[325/600] Iteration[027/030] Train loss: 0.0219
2023-02-06 11:35:43 | Train | Epoch[325/600] Iteration[028/030] Train loss: 0.0218
2023-02-06 11:35:43 | Train | Epoch[325/600] Iteration[029/030] Train loss: 0.0219
2023-02-06 11:35:43 | Train | Epoch[325/600] Iteration[030/030] Train loss: 0.0220
2023-02-06 11:35:43 | Valid | Epoch[325/600] Iteration[001/008] Valid loss: 0.2179
2023-02-06 11:35:43 | Valid | Epoch[325/600] Iteration[002/008] Valid loss: 0.2257
2023-02-06 11:35:43 | Valid | Epoch[325/600] Iteration[003/008] Valid loss: 0.2386
2023-02-06 11:35:43 | Valid | Epoch[325/600] Iteration[004/008] Valid loss: 0.2351
2023-02-06 11:35:43 | Valid | Epoch[325/600] Iteration[005/008] Valid loss: 0.2421
2023-02-06 11:35:43 | Valid | Epoch[325/600] Iteration[006/008] Valid loss: 0.2396
2023-02-06 11:35:43 | Valid | Epoch[325/600] Iteration[007/008] Valid loss: 0.2366
2023-02-06 11:35:43 | Valid | Epoch[325/600] Iteration[008/008] Valid loss: 0.2487
2023-02-06 11:35:43 | Valid | Epoch[325/600] MIou: 0.46791518754546835
2023-02-06 11:35:43 | Valid | Epoch[325/600] Pixel Accuracy: 0.9118639628092448
2023-02-06 11:35:43 | Valid | Epoch[325/600] Mean Pixel Accuracy: 0.512079573132101
2023-02-06 11:35:43 | Stage | Epoch[325/600] Train loss:0.0220
2023-02-06 11:35:43 | Stage | Epoch[325/600] Valid loss:0.2487
2023-02-06 11:35:43 | Stage | Epoch[325/600] LR:0.01

2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[001/030] Train loss: 0.0190
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[005/030] Train loss: 0.0217
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[006/030] Train loss: 0.0217
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[007/030] Train loss: 0.0219
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[008/030] Train loss: 0.0215
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[009/030] Train loss: 0.0218
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[010/030] Train loss: 0.0215
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[012/030] Train loss: 0.0217
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[013/030] Train loss: 0.0218
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:35:44 | Train | Epoch[326/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[018/030] Train loss: 0.0215
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[020/030] Train loss: 0.0220
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[021/030] Train loss: 0.0220
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[024/030] Train loss: 0.0221
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[025/030] Train loss: 0.0222
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[026/030] Train loss: 0.0222
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[027/030] Train loss: 0.0222
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[028/030] Train loss: 0.0222
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[029/030] Train loss: 0.0222
2023-02-06 11:35:45 | Train | Epoch[326/600] Iteration[030/030] Train loss: 0.0223
2023-02-06 11:35:45 | Valid | Epoch[326/600] Iteration[001/008] Valid loss: 0.1370
2023-02-06 11:35:45 | Valid | Epoch[326/600] Iteration[002/008] Valid loss: 0.1394
2023-02-06 11:35:45 | Valid | Epoch[326/600] Iteration[003/008] Valid loss: 0.1459
2023-02-06 11:35:45 | Valid | Epoch[326/600] Iteration[004/008] Valid loss: 0.1433
2023-02-06 11:35:46 | Valid | Epoch[326/600] Iteration[005/008] Valid loss: 0.1462
2023-02-06 11:35:46 | Valid | Epoch[326/600] Iteration[006/008] Valid loss: 0.1438
2023-02-06 11:35:46 | Valid | Epoch[326/600] Iteration[007/008] Valid loss: 0.1400
2023-02-06 11:35:46 | Valid | Epoch[326/600] Iteration[008/008] Valid loss: 0.1465
2023-02-06 11:35:46 | Valid | Epoch[326/600] MIou: 0.5639660071053794
2023-02-06 11:35:46 | Valid | Epoch[326/600] Pixel Accuracy: 0.9278717041015625
2023-02-06 11:35:46 | Valid | Epoch[326/600] Mean Pixel Accuracy: 0.6006983063255853
2023-02-06 11:35:46 | Stage | Epoch[326/600] Train loss:0.0223
2023-02-06 11:35:46 | Stage | Epoch[326/600] Valid loss:0.1465
2023-02-06 11:35:46 | Stage | Epoch[326/600] LR:0.01

2023-02-06 11:35:46 | Train | Epoch[327/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 11:35:46 | Train | Epoch[327/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 11:35:46 | Train | Epoch[327/600] Iteration[003/030] Train loss: 0.0245
2023-02-06 11:35:46 | Train | Epoch[327/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 11:35:46 | Train | Epoch[327/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 11:35:46 | Train | Epoch[327/600] Iteration[006/030] Train loss: 0.0246
2023-02-06 11:35:46 | Train | Epoch[327/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 11:35:46 | Train | Epoch[327/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 11:35:46 | Train | Epoch[327/600] Iteration[009/030] Train loss: 0.0246
2023-02-06 11:35:46 | Train | Epoch[327/600] Iteration[010/030] Train loss: 0.0244
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[011/030] Train loss: 0.0244
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[014/030] Train loss: 0.0238
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[015/030] Train loss: 0.0235
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[016/030] Train loss: 0.0237
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[017/030] Train loss: 0.0234
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[018/030] Train loss: 0.0234
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[019/030] Train loss: 0.0232
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[020/030] Train loss: 0.0231
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[021/030] Train loss: 0.0230
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[022/030] Train loss: 0.0230
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[023/030] Train loss: 0.0230
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[024/030] Train loss: 0.0230
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[025/030] Train loss: 0.0229
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[026/030] Train loss: 0.0229
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[027/030] Train loss: 0.0228
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[028/030] Train loss: 0.0228
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[029/030] Train loss: 0.0227
2023-02-06 11:35:47 | Train | Epoch[327/600] Iteration[030/030] Train loss: 0.0228
2023-02-06 11:35:48 | Valid | Epoch[327/600] Iteration[001/008] Valid loss: 0.0434
2023-02-06 11:35:48 | Valid | Epoch[327/600] Iteration[002/008] Valid loss: 0.0370
2023-02-06 11:35:48 | Valid | Epoch[327/600] Iteration[003/008] Valid loss: 0.0352
2023-02-06 11:35:48 | Valid | Epoch[327/600] Iteration[004/008] Valid loss: 0.0333
2023-02-06 11:35:48 | Valid | Epoch[327/600] Iteration[005/008] Valid loss: 0.0361
2023-02-06 11:35:48 | Valid | Epoch[327/600] Iteration[006/008] Valid loss: 0.0355
2023-02-06 11:35:48 | Valid | Epoch[327/600] Iteration[007/008] Valid loss: 0.0345
2023-02-06 11:35:48 | Valid | Epoch[327/600] Iteration[008/008] Valid loss: 0.0343
2023-02-06 11:35:48 | Valid | Epoch[327/600] MIou: 0.9028240606126845
2023-02-06 11:35:48 | Valid | Epoch[327/600] Pixel Accuracy: 0.9838689168294271
2023-02-06 11:35:48 | Valid | Epoch[327/600] Mean Pixel Accuracy: 0.9150036272698532
2023-02-06 11:35:48 | Stage | Epoch[327/600] Train loss:0.0228
2023-02-06 11:35:48 | Stage | Epoch[327/600] Valid loss:0.0343
2023-02-06 11:35:48 | Stage | Epoch[327/600] LR:0.01

2023-02-06 11:35:48 | Train | Epoch[328/600] Iteration[001/030] Train loss: 0.0267
2023-02-06 11:35:48 | Train | Epoch[328/600] Iteration[002/030] Train loss: 0.0231
2023-02-06 11:35:48 | Train | Epoch[328/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:35:48 | Train | Epoch[328/600] Iteration[004/030] Train loss: 0.0226
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[005/030] Train loss: 0.0218
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[007/030] Train loss: 0.0214
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[008/030] Train loss: 0.0213
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[009/030] Train loss: 0.0211
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[012/030] Train loss: 0.0218
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[013/030] Train loss: 0.0216
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[014/030] Train loss: 0.0216
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[015/030] Train loss: 0.0215
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[016/030] Train loss: 0.0214
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[017/030] Train loss: 0.0217
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[018/030] Train loss: 0.0217
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[019/030] Train loss: 0.0216
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[020/030] Train loss: 0.0215
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[021/030] Train loss: 0.0215
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[022/030] Train loss: 0.0215
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[023/030] Train loss: 0.0214
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[024/030] Train loss: 0.0214
2023-02-06 11:35:49 | Train | Epoch[328/600] Iteration[025/030] Train loss: 0.0215
2023-02-06 11:35:50 | Train | Epoch[328/600] Iteration[026/030] Train loss: 0.0215
2023-02-06 11:35:50 | Train | Epoch[328/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 11:35:50 | Train | Epoch[328/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:35:50 | Train | Epoch[328/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:35:50 | Train | Epoch[328/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:35:50 | Valid | Epoch[328/600] Iteration[001/008] Valid loss: 0.0730
2023-02-06 11:35:50 | Valid | Epoch[328/600] Iteration[002/008] Valid loss: 0.0500
2023-02-06 11:35:50 | Valid | Epoch[328/600] Iteration[003/008] Valid loss: 0.0431
2023-02-06 11:35:50 | Valid | Epoch[328/600] Iteration[004/008] Valid loss: 0.0427
2023-02-06 11:35:50 | Valid | Epoch[328/600] Iteration[005/008] Valid loss: 0.0443
2023-02-06 11:35:50 | Valid | Epoch[328/600] Iteration[006/008] Valid loss: 0.0423
2023-02-06 11:35:50 | Valid | Epoch[328/600] Iteration[007/008] Valid loss: 0.0437
2023-02-06 11:35:50 | Valid | Epoch[328/600] Iteration[008/008] Valid loss: 0.0421
2023-02-06 11:35:50 | Valid | Epoch[328/600] MIou: 0.9310140467217759
2023-02-06 11:35:50 | Valid | Epoch[328/600] Pixel Accuracy: 0.9883867899576823
2023-02-06 11:35:50 | Valid | Epoch[328/600] Mean Pixel Accuracy: 0.9473758257317151
2023-02-06 11:35:50 | Stage | Epoch[328/600] Train loss:0.0216
2023-02-06 11:35:50 | Stage | Epoch[328/600] Valid loss:0.0421
2023-02-06 11:35:50 | Stage | Epoch[328/600] LR:0.01

2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[009/030] Train loss: 0.0214
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[010/030] Train loss: 0.0214
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[011/030] Train loss: 0.0212
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[012/030] Train loss: 0.0216
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[015/030] Train loss: 0.0211
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[016/030] Train loss: 0.0214
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:35:51 | Train | Epoch[329/600] Iteration[018/030] Train loss: 0.0216
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[020/030] Train loss: 0.0218
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[021/030] Train loss: 0.0220
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[024/030] Train loss: 0.0221
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[025/030] Train loss: 0.0222
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[026/030] Train loss: 0.0222
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[027/030] Train loss: 0.0223
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[028/030] Train loss: 0.0223
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[029/030] Train loss: 0.0224
2023-02-06 11:35:52 | Train | Epoch[329/600] Iteration[030/030] Train loss: 0.0223
2023-02-06 11:35:52 | Valid | Epoch[329/600] Iteration[001/008] Valid loss: 0.3029
2023-02-06 11:35:52 | Valid | Epoch[329/600] Iteration[002/008] Valid loss: 0.2255
2023-02-06 11:35:52 | Valid | Epoch[329/600] Iteration[003/008] Valid loss: 0.2094
2023-02-06 11:35:52 | Valid | Epoch[329/600] Iteration[004/008] Valid loss: 0.2047
2023-02-06 11:35:52 | Valid | Epoch[329/600] Iteration[005/008] Valid loss: 0.2224
2023-02-06 11:35:52 | Valid | Epoch[329/600] Iteration[006/008] Valid loss: 0.2194
2023-02-06 11:35:52 | Valid | Epoch[329/600] Iteration[007/008] Valid loss: 0.2310
2023-02-06 11:35:53 | Valid | Epoch[329/600] Iteration[008/008] Valid loss: 0.2316
2023-02-06 11:35:53 | Valid | Epoch[329/600] MIou: 0.9156375997868238
2023-02-06 11:35:53 | Valid | Epoch[329/600] Pixel Accuracy: 0.9841995239257812
2023-02-06 11:35:53 | Valid | Epoch[329/600] Mean Pixel Accuracy: 0.9825972361464935
2023-02-06 11:35:53 | Stage | Epoch[329/600] Train loss:0.0223
2023-02-06 11:35:53 | Stage | Epoch[329/600] Valid loss:0.2316
2023-02-06 11:35:53 | Stage | Epoch[329/600] LR:0.01

2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[002/030] Train loss: 0.0206
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[004/030] Train loss: 0.0221
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[005/030] Train loss: 0.0218
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[006/030] Train loss: 0.0221
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[008/030] Train loss: 0.0218
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[009/030] Train loss: 0.0213
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[012/030] Train loss: 0.0213
2023-02-06 11:35:53 | Train | Epoch[330/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[016/030] Train loss: 0.0219
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[017/030] Train loss: 0.0219
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[018/030] Train loss: 0.0219
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[019/030] Train loss: 0.0223
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[020/030] Train loss: 0.0221
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[021/030] Train loss: 0.0220
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[024/030] Train loss: 0.0217
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[025/030] Train loss: 0.0215
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:35:54 | Train | Epoch[330/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:35:55 | Valid | Epoch[330/600] Iteration[001/008] Valid loss: 0.0747
2023-02-06 11:35:55 | Valid | Epoch[330/600] Iteration[002/008] Valid loss: 0.0518
2023-02-06 11:35:55 | Valid | Epoch[330/600] Iteration[003/008] Valid loss: 0.0448
2023-02-06 11:35:55 | Valid | Epoch[330/600] Iteration[004/008] Valid loss: 0.0434
2023-02-06 11:35:55 | Valid | Epoch[330/600] Iteration[005/008] Valid loss: 0.0460
2023-02-06 11:35:55 | Valid | Epoch[330/600] Iteration[006/008] Valid loss: 0.0458
2023-02-06 11:35:55 | Valid | Epoch[330/600] Iteration[007/008] Valid loss: 0.0471
2023-02-06 11:35:55 | Valid | Epoch[330/600] Iteration[008/008] Valid loss: 0.0454
2023-02-06 11:35:55 | Valid | Epoch[330/600] MIou: 0.9387087786461057
2023-02-06 11:35:55 | Valid | Epoch[330/600] Pixel Accuracy: 0.989556630452474
2023-02-06 11:35:55 | Valid | Epoch[330/600] Mean Pixel Accuracy: 0.9601735038488
2023-02-06 11:35:55 | Stage | Epoch[330/600] Train loss:0.0217
2023-02-06 11:35:55 | Stage | Epoch[330/600] Valid loss:0.0454
2023-02-06 11:35:55 | Stage | Epoch[330/600] LR:0.01

2023-02-06 11:35:55 | Train | Epoch[331/600] Iteration[001/030] Train loss: 0.0215
2023-02-06 11:35:55 | Train | Epoch[331/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 11:35:55 | Train | Epoch[331/600] Iteration[003/030] Train loss: 0.0218
2023-02-06 11:35:55 | Train | Epoch[331/600] Iteration[004/030] Train loss: 0.0219
2023-02-06 11:35:55 | Train | Epoch[331/600] Iteration[005/030] Train loss: 0.0223
2023-02-06 11:35:55 | Train | Epoch[331/600] Iteration[006/030] Train loss: 0.0221
2023-02-06 11:35:55 | Train | Epoch[331/600] Iteration[007/030] Train loss: 0.0219
2023-02-06 11:35:55 | Train | Epoch[331/600] Iteration[008/030] Train loss: 0.0217
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[012/030] Train loss: 0.0216
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[013/030] Train loss: 0.0216
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[015/030] Train loss: 0.0217
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[016/030] Train loss: 0.0218
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[017/030] Train loss: 0.0218
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[018/030] Train loss: 0.0218
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[019/030] Train loss: 0.0218
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[020/030] Train loss: 0.0218
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[024/030] Train loss: 0.0220
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[027/030] Train loss: 0.0218
2023-02-06 11:35:56 | Train | Epoch[331/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:35:57 | Train | Epoch[331/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:35:57 | Train | Epoch[331/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:35:57 | Valid | Epoch[331/600] Iteration[001/008] Valid loss: 0.0457
2023-02-06 11:35:57 | Valid | Epoch[331/600] Iteration[002/008] Valid loss: 0.0418
2023-02-06 11:35:57 | Valid | Epoch[331/600] Iteration[003/008] Valid loss: 0.0417
2023-02-06 11:35:57 | Valid | Epoch[331/600] Iteration[004/008] Valid loss: 0.0400
2023-02-06 11:35:57 | Valid | Epoch[331/600] Iteration[005/008] Valid loss: 0.0408
2023-02-06 11:35:57 | Valid | Epoch[331/600] Iteration[006/008] Valid loss: 0.0401
2023-02-06 11:35:57 | Valid | Epoch[331/600] Iteration[007/008] Valid loss: 0.0390
2023-02-06 11:35:57 | Valid | Epoch[331/600] Iteration[008/008] Valid loss: 0.0399
2023-02-06 11:35:57 | Valid | Epoch[331/600] MIou: 0.8645529963453087
2023-02-06 11:35:57 | Valid | Epoch[331/600] Pixel Accuracy: 0.9776611328125
2023-02-06 11:35:57 | Valid | Epoch[331/600] Mean Pixel Accuracy: 0.8770867184498268
2023-02-06 11:35:57 | Stage | Epoch[331/600] Train loss:0.0216
2023-02-06 11:35:57 | Stage | Epoch[331/600] Valid loss:0.0399
2023-02-06 11:35:57 | Stage | Epoch[331/600] LR:0.01

2023-02-06 11:35:57 | Train | Epoch[332/600] Iteration[001/030] Train loss: 0.0217
2023-02-06 11:35:57 | Train | Epoch[332/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:35:57 | Train | Epoch[332/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[004/030] Train loss: 0.0223
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[005/030] Train loss: 0.0223
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[006/030] Train loss: 0.0222
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[007/030] Train loss: 0.0221
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[008/030] Train loss: 0.0221
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[009/030] Train loss: 0.0222
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[011/030] Train loss: 0.0223
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[012/030] Train loss: 0.0221
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[013/030] Train loss: 0.0221
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[014/030] Train loss: 0.0224
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[015/030] Train loss: 0.0222
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[016/030] Train loss: 0.0223
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[017/030] Train loss: 0.0224
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[018/030] Train loss: 0.0224
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[019/030] Train loss: 0.0223
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[020/030] Train loss: 0.0222
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[021/030] Train loss: 0.0222
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[022/030] Train loss: 0.0222
2023-02-06 11:35:58 | Train | Epoch[332/600] Iteration[023/030] Train loss: 0.0222
2023-02-06 11:35:59 | Train | Epoch[332/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:35:59 | Train | Epoch[332/600] Iteration[025/030] Train loss: 0.0222
2023-02-06 11:35:59 | Train | Epoch[332/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:35:59 | Train | Epoch[332/600] Iteration[027/030] Train loss: 0.0220
2023-02-06 11:35:59 | Train | Epoch[332/600] Iteration[028/030] Train loss: 0.0220
2023-02-06 11:35:59 | Train | Epoch[332/600] Iteration[029/030] Train loss: 0.0220
2023-02-06 11:35:59 | Train | Epoch[332/600] Iteration[030/030] Train loss: 0.0219
2023-02-06 11:35:59 | Valid | Epoch[332/600] Iteration[001/008] Valid loss: 0.0489
2023-02-06 11:35:59 | Valid | Epoch[332/600] Iteration[002/008] Valid loss: 0.0377
2023-02-06 11:35:59 | Valid | Epoch[332/600] Iteration[003/008] Valid loss: 0.0351
2023-02-06 11:35:59 | Valid | Epoch[332/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 11:35:59 | Valid | Epoch[332/600] Iteration[005/008] Valid loss: 0.0335
2023-02-06 11:35:59 | Valid | Epoch[332/600] Iteration[006/008] Valid loss: 0.0331
2023-02-06 11:35:59 | Valid | Epoch[332/600] Iteration[007/008] Valid loss: 0.0325
2023-02-06 11:35:59 | Valid | Epoch[332/600] Iteration[008/008] Valid loss: 0.0322
2023-02-06 11:35:59 | Valid | Epoch[332/600] MIou: 0.9156718791126601
2023-02-06 11:35:59 | Valid | Epoch[332/600] Pixel Accuracy: 0.9859797159830729
2023-02-06 11:35:59 | Valid | Epoch[332/600] Mean Pixel Accuracy: 0.9275830017013592
2023-02-06 11:35:59 | Stage | Epoch[332/600] Train loss:0.0219
2023-02-06 11:35:59 | Stage | Epoch[332/600] Valid loss:0.0322
2023-02-06 11:35:59 | Stage | Epoch[332/600] LR:0.01

2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[003/030] Train loss: 0.0201
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[004/030] Train loss: 0.0202
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[006/030] Train loss: 0.0204
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[012/030] Train loss: 0.0214
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[013/030] Train loss: 0.0212
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[015/030] Train loss: 0.0214
2023-02-06 11:36:00 | Train | Epoch[333/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[017/030] Train loss: 0.0218
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[018/030] Train loss: 0.0223
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[019/030] Train loss: 0.0225
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[020/030] Train loss: 0.0224
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[021/030] Train loss: 0.0224
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[022/030] Train loss: 0.0224
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[023/030] Train loss: 0.0223
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[025/030] Train loss: 0.0222
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[028/030] Train loss: 0.0221
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[029/030] Train loss: 0.0221
2023-02-06 11:36:01 | Train | Epoch[333/600] Iteration[030/030] Train loss: 0.0221
2023-02-06 11:36:02 | Valid | Epoch[333/600] Iteration[001/008] Valid loss: 0.0964
2023-02-06 11:36:02 | Valid | Epoch[333/600] Iteration[002/008] Valid loss: 0.0924
2023-02-06 11:36:02 | Valid | Epoch[333/600] Iteration[003/008] Valid loss: 0.0950
2023-02-06 11:36:02 | Valid | Epoch[333/600] Iteration[004/008] Valid loss: 0.0929
2023-02-06 11:36:02 | Valid | Epoch[333/600] Iteration[005/008] Valid loss: 0.0944
2023-02-06 11:36:02 | Valid | Epoch[333/600] Iteration[006/008] Valid loss: 0.0930
2023-02-06 11:36:02 | Valid | Epoch[333/600] Iteration[007/008] Valid loss: 0.0905
2023-02-06 11:36:02 | Valid | Epoch[333/600] Iteration[008/008] Valid loss: 0.0938
2023-02-06 11:36:02 | Valid | Epoch[333/600] MIou: 0.719888069141581
2023-02-06 11:36:02 | Valid | Epoch[333/600] Pixel Accuracy: 0.9537696838378906
2023-02-06 11:36:02 | Valid | Epoch[333/600] Mean Pixel Accuracy: 0.7440693237973222
2023-02-06 11:36:02 | Stage | Epoch[333/600] Train loss:0.0221
2023-02-06 11:36:02 | Stage | Epoch[333/600] Valid loss:0.0938
2023-02-06 11:36:02 | Stage | Epoch[333/600] LR:0.01

2023-02-06 11:36:02 | Train | Epoch[334/600] Iteration[001/030] Train loss: 0.0213
2023-02-06 11:36:02 | Train | Epoch[334/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:36:02 | Train | Epoch[334/600] Iteration[003/030] Train loss: 0.0214
2023-02-06 11:36:02 | Train | Epoch[334/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:36:02 | Train | Epoch[334/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:36:02 | Train | Epoch[334/600] Iteration[006/030] Train loss: 0.0214
2023-02-06 11:36:02 | Train | Epoch[334/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:36:02 | Train | Epoch[334/600] Iteration[008/030] Train loss: 0.0214
2023-02-06 11:36:02 | Train | Epoch[334/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:36:02 | Train | Epoch[334/600] Iteration[010/030] Train loss: 0.0211
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[012/030] Train loss: 0.0214
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[013/030] Train loss: 0.0213
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[014/030] Train loss: 0.0215
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[015/030] Train loss: 0.0215
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[018/030] Train loss: 0.0215
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[019/030] Train loss: 0.0215
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[020/030] Train loss: 0.0214
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[021/030] Train loss: 0.0215
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[025/030] Train loss: 0.0214
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[027/030] Train loss: 0.0218
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:36:03 | Train | Epoch[334/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:36:04 | Valid | Epoch[334/600] Iteration[001/008] Valid loss: 0.1020
2023-02-06 11:36:04 | Valid | Epoch[334/600] Iteration[002/008] Valid loss: 0.1015
2023-02-06 11:36:04 | Valid | Epoch[334/600] Iteration[003/008] Valid loss: 0.1048
2023-02-06 11:36:04 | Valid | Epoch[334/600] Iteration[004/008] Valid loss: 0.1022
2023-02-06 11:36:04 | Valid | Epoch[334/600] Iteration[005/008] Valid loss: 0.1038
2023-02-06 11:36:04 | Valid | Epoch[334/600] Iteration[006/008] Valid loss: 0.1017
2023-02-06 11:36:04 | Valid | Epoch[334/600] Iteration[007/008] Valid loss: 0.0989
2023-02-06 11:36:04 | Valid | Epoch[334/600] Iteration[008/008] Valid loss: 0.1034
2023-02-06 11:36:04 | Valid | Epoch[334/600] MIou: 0.6724360794284175
2023-02-06 11:36:04 | Valid | Epoch[334/600] Pixel Accuracy: 0.9458999633789062
2023-02-06 11:36:04 | Valid | Epoch[334/600] Mean Pixel Accuracy: 0.7005026116093427
2023-02-06 11:36:04 | Stage | Epoch[334/600] Train loss:0.0217
2023-02-06 11:36:04 | Stage | Epoch[334/600] Valid loss:0.1034
2023-02-06 11:36:04 | Stage | Epoch[334/600] LR:0.01

2023-02-06 11:36:04 | Train | Epoch[335/600] Iteration[001/030] Train loss: 0.0258
2023-02-06 11:36:04 | Train | Epoch[335/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 11:36:04 | Train | Epoch[335/600] Iteration[003/030] Train loss: 0.0237
2023-02-06 11:36:04 | Train | Epoch[335/600] Iteration[004/030] Train loss: 0.0231
2023-02-06 11:36:04 | Train | Epoch[335/600] Iteration[005/030] Train loss: 0.0223
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[006/030] Train loss: 0.0227
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[007/030] Train loss: 0.0227
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[008/030] Train loss: 0.0225
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[009/030] Train loss: 0.0220
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[010/030] Train loss: 0.0219
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[011/030] Train loss: 0.0220
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[012/030] Train loss: 0.0217
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[013/030] Train loss: 0.0218
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[015/030] Train loss: 0.0217
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[018/030] Train loss: 0.0212
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[019/030] Train loss: 0.0212
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[021/030] Train loss: 0.0214
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[022/030] Train loss: 0.0215
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[025/030] Train loss: 0.0216
2023-02-06 11:36:05 | Train | Epoch[335/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 11:36:06 | Train | Epoch[335/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 11:36:06 | Train | Epoch[335/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:36:06 | Train | Epoch[335/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 11:36:06 | Train | Epoch[335/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 11:36:06 | Valid | Epoch[335/600] Iteration[001/008] Valid loss: 0.1365
2023-02-06 11:36:06 | Valid | Epoch[335/600] Iteration[002/008] Valid loss: 0.1416
2023-02-06 11:36:06 | Valid | Epoch[335/600] Iteration[003/008] Valid loss: 0.1486
2023-02-06 11:36:06 | Valid | Epoch[335/600] Iteration[004/008] Valid loss: 0.1449
2023-02-06 11:36:06 | Valid | Epoch[335/600] Iteration[005/008] Valid loss: 0.1493
2023-02-06 11:36:06 | Valid | Epoch[335/600] Iteration[006/008] Valid loss: 0.1467
2023-02-06 11:36:06 | Valid | Epoch[335/600] Iteration[007/008] Valid loss: 0.1442
2023-02-06 11:36:06 | Valid | Epoch[335/600] Iteration[008/008] Valid loss: 0.1531
2023-02-06 11:36:06 | Valid | Epoch[335/600] MIou: 0.5322683113174496
2023-02-06 11:36:06 | Valid | Epoch[335/600] Pixel Accuracy: 0.9225934346516927
2023-02-06 11:36:06 | Valid | Epoch[335/600] Mean Pixel Accuracy: 0.5714778470765463
2023-02-06 11:36:06 | Stage | Epoch[335/600] Train loss:0.0214
2023-02-06 11:36:06 | Stage | Epoch[335/600] Valid loss:0.1531
2023-02-06 11:36:06 | Stage | Epoch[335/600] LR:0.01

2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[001/030] Train loss: 0.0212
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[002/030] Train loss: 0.0220
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[003/030] Train loss: 0.0234
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[005/030] Train loss: 0.0224
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[006/030] Train loss: 0.0227
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[007/030] Train loss: 0.0234
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[008/030] Train loss: 0.0235
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[010/030] Train loss: 0.0234
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[011/030] Train loss: 0.0231
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[012/030] Train loss: 0.0229
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[013/030] Train loss: 0.0230
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[014/030] Train loss: 0.0231
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[015/030] Train loss: 0.0233
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[016/030] Train loss: 0.0230
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[017/030] Train loss: 0.0229
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[018/030] Train loss: 0.0226
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[019/030] Train loss: 0.0225
2023-02-06 11:36:07 | Train | Epoch[336/600] Iteration[020/030] Train loss: 0.0226
2023-02-06 11:36:08 | Train | Epoch[336/600] Iteration[021/030] Train loss: 0.0228
2023-02-06 11:36:08 | Train | Epoch[336/600] Iteration[022/030] Train loss: 0.0226
2023-02-06 11:36:08 | Train | Epoch[336/600] Iteration[023/030] Train loss: 0.0231
2023-02-06 11:36:08 | Train | Epoch[336/600] Iteration[024/030] Train loss: 0.0230
2023-02-06 11:36:08 | Train | Epoch[336/600] Iteration[025/030] Train loss: 0.0229
2023-02-06 11:36:08 | Train | Epoch[336/600] Iteration[026/030] Train loss: 0.0228
2023-02-06 11:36:08 | Train | Epoch[336/600] Iteration[027/030] Train loss: 0.0229
2023-02-06 11:36:08 | Train | Epoch[336/600] Iteration[028/030] Train loss: 0.0229
2023-02-06 11:36:08 | Train | Epoch[336/600] Iteration[029/030] Train loss: 0.0227
2023-02-06 11:36:08 | Train | Epoch[336/600] Iteration[030/030] Train loss: 0.0228
2023-02-06 11:36:08 | Valid | Epoch[336/600] Iteration[001/008] Valid loss: 0.0667
2023-02-06 11:36:08 | Valid | Epoch[336/600] Iteration[002/008] Valid loss: 0.0663
2023-02-06 11:36:08 | Valid | Epoch[336/600] Iteration[003/008] Valid loss: 0.0672
2023-02-06 11:36:08 | Valid | Epoch[336/600] Iteration[004/008] Valid loss: 0.0651
2023-02-06 11:36:08 | Valid | Epoch[336/600] Iteration[005/008] Valid loss: 0.0660
2023-02-06 11:36:08 | Valid | Epoch[336/600] Iteration[006/008] Valid loss: 0.0647
2023-02-06 11:36:08 | Valid | Epoch[336/600] Iteration[007/008] Valid loss: 0.0625
2023-02-06 11:36:08 | Valid | Epoch[336/600] Iteration[008/008] Valid loss: 0.0647
2023-02-06 11:36:09 | Valid | Epoch[336/600] MIou: 0.7849183188673305
2023-02-06 11:36:09 | Valid | Epoch[336/600] Pixel Accuracy: 0.9645373026529948
2023-02-06 11:36:09 | Valid | Epoch[336/600] Mean Pixel Accuracy: 0.8036787790902308
2023-02-06 11:36:09 | Stage | Epoch[336/600] Train loss:0.0228
2023-02-06 11:36:09 | Stage | Epoch[336/600] Valid loss:0.0647
2023-02-06 11:36:09 | Stage | Epoch[336/600] LR:0.01

2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[001/030] Train loss: 0.0222
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[007/030] Train loss: 0.0212
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[010/030] Train loss: 0.0218
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[012/030] Train loss: 0.0218
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[013/030] Train loss: 0.0218
2023-02-06 11:36:09 | Train | Epoch[337/600] Iteration[014/030] Train loss: 0.0220
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[015/030] Train loss: 0.0220
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[016/030] Train loss: 0.0220
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[017/030] Train loss: 0.0221
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[018/030] Train loss: 0.0219
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[021/030] Train loss: 0.0219
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[022/030] Train loss: 0.0217
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[023/030] Train loss: 0.0218
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[025/030] Train loss: 0.0219
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[027/030] Train loss: 0.0218
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[028/030] Train loss: 0.0219
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[029/030] Train loss: 0.0219
2023-02-06 11:36:10 | Train | Epoch[337/600] Iteration[030/030] Train loss: 0.0218
2023-02-06 11:36:11 | Valid | Epoch[337/600] Iteration[001/008] Valid loss: 0.0592
2023-02-06 11:36:11 | Valid | Epoch[337/600] Iteration[002/008] Valid loss: 0.0425
2023-02-06 11:36:11 | Valid | Epoch[337/600] Iteration[003/008] Valid loss: 0.0378
2023-02-06 11:36:11 | Valid | Epoch[337/600] Iteration[004/008] Valid loss: 0.0355
2023-02-06 11:36:11 | Valid | Epoch[337/600] Iteration[005/008] Valid loss: 0.0356
2023-02-06 11:36:11 | Valid | Epoch[337/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 11:36:11 | Valid | Epoch[337/600] Iteration[007/008] Valid loss: 0.0346
2023-02-06 11:36:11 | Valid | Epoch[337/600] Iteration[008/008] Valid loss: 0.0338
2023-02-06 11:36:11 | Valid | Epoch[337/600] MIou: 0.9221628405550406
2023-02-06 11:36:11 | Valid | Epoch[337/600] Pixel Accuracy: 0.987036387125651
2023-02-06 11:36:11 | Valid | Epoch[337/600] Mean Pixel Accuracy: 0.9343647743660685
2023-02-06 11:36:11 | Stage | Epoch[337/600] Train loss:0.0218
2023-02-06 11:36:11 | Stage | Epoch[337/600] Valid loss:0.0338
2023-02-06 11:36:11 | Stage | Epoch[337/600] LR:0.01

2023-02-06 11:36:11 | Train | Epoch[338/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 11:36:11 | Train | Epoch[338/600] Iteration[002/030] Train loss: 0.0183
2023-02-06 11:36:11 | Train | Epoch[338/600] Iteration[003/030] Train loss: 0.0196
2023-02-06 11:36:11 | Train | Epoch[338/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:36:11 | Train | Epoch[338/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:36:11 | Train | Epoch[338/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[013/030] Train loss: 0.0213
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[015/030] Train loss: 0.0212
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[016/030] Train loss: 0.0213
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[018/030] Train loss: 0.0214
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[019/030] Train loss: 0.0214
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[020/030] Train loss: 0.0214
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[021/030] Train loss: 0.0215
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[022/030] Train loss: 0.0215
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[025/030] Train loss: 0.0216
2023-02-06 11:36:12 | Train | Epoch[338/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 11:36:13 | Train | Epoch[338/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:36:13 | Train | Epoch[338/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:36:13 | Train | Epoch[338/600] Iteration[029/030] Train loss: 0.0218
2023-02-06 11:36:13 | Train | Epoch[338/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:36:13 | Valid | Epoch[338/600] Iteration[001/008] Valid loss: 0.0434
2023-02-06 11:36:13 | Valid | Epoch[338/600] Iteration[002/008] Valid loss: 0.0410
2023-02-06 11:36:13 | Valid | Epoch[338/600] Iteration[003/008] Valid loss: 0.0407
2023-02-06 11:36:13 | Valid | Epoch[338/600] Iteration[004/008] Valid loss: 0.0389
2023-02-06 11:36:13 | Valid | Epoch[338/600] Iteration[005/008] Valid loss: 0.0406
2023-02-06 11:36:13 | Valid | Epoch[338/600] Iteration[006/008] Valid loss: 0.0397
2023-02-06 11:36:13 | Valid | Epoch[338/600] Iteration[007/008] Valid loss: 0.0384
2023-02-06 11:36:13 | Valid | Epoch[338/600] Iteration[008/008] Valid loss: 0.0391
2023-02-06 11:36:13 | Valid | Epoch[338/600] MIou: 0.8709408876356857
2023-02-06 11:36:13 | Valid | Epoch[338/600] Pixel Accuracy: 0.9786783854166666
2023-02-06 11:36:13 | Valid | Epoch[338/600] Mean Pixel Accuracy: 0.8836185680302302
2023-02-06 11:36:13 | Stage | Epoch[338/600] Train loss:0.0217
2023-02-06 11:36:13 | Stage | Epoch[338/600] Valid loss:0.0391
2023-02-06 11:36:13 | Stage | Epoch[338/600] LR:0.01

2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[005/030] Train loss: 0.0220
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[006/030] Train loss: 0.0216
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[007/030] Train loss: 0.0214
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[008/030] Train loss: 0.0213
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[010/030] Train loss: 0.0216
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[011/030] Train loss: 0.0214
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[012/030] Train loss: 0.0217
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[013/030] Train loss: 0.0217
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[018/030] Train loss: 0.0217
2023-02-06 11:36:14 | Train | Epoch[339/600] Iteration[019/030] Train loss: 0.0216
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[020/030] Train loss: 0.0218
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[022/030] Train loss: 0.0216
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[024/030] Train loss: 0.0217
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[025/030] Train loss: 0.0216
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 11:36:15 | Train | Epoch[339/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:36:15 | Valid | Epoch[339/600] Iteration[001/008] Valid loss: 0.0530
2023-02-06 11:36:15 | Valid | Epoch[339/600] Iteration[002/008] Valid loss: 0.0508
2023-02-06 11:36:15 | Valid | Epoch[339/600] Iteration[003/008] Valid loss: 0.0509
2023-02-06 11:36:15 | Valid | Epoch[339/600] Iteration[004/008] Valid loss: 0.0488
2023-02-06 11:36:16 | Valid | Epoch[339/600] Iteration[005/008] Valid loss: 0.0496
2023-02-06 11:36:16 | Valid | Epoch[339/600] Iteration[006/008] Valid loss: 0.0486
2023-02-06 11:36:16 | Valid | Epoch[339/600] Iteration[007/008] Valid loss: 0.0470
2023-02-06 11:36:16 | Valid | Epoch[339/600] Iteration[008/008] Valid loss: 0.0482
2023-02-06 11:36:16 | Valid | Epoch[339/600] MIou: 0.8372710092168425
2023-02-06 11:36:16 | Valid | Epoch[339/600] Pixel Accuracy: 0.9731788635253906
2023-02-06 11:36:16 | Valid | Epoch[339/600] Mean Pixel Accuracy: 0.851740310398374
2023-02-06 11:36:16 | Stage | Epoch[339/600] Train loss:0.0216
2023-02-06 11:36:16 | Stage | Epoch[339/600] Valid loss:0.0482
2023-02-06 11:36:16 | Stage | Epoch[339/600] LR:0.01

2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[002/030] Train loss: 0.0213
2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:36:16 | Train | Epoch[340/600] Iteration[011/030] Train loss: 0.0212
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[012/030] Train loss: 0.0213
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[018/030] Train loss: 0.0214
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[019/030] Train loss: 0.0214
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[020/030] Train loss: 0.0214
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[021/030] Train loss: 0.0214
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[022/030] Train loss: 0.0216
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[025/030] Train loss: 0.0216
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:36:17 | Train | Epoch[340/600] Iteration[030/030] Train loss: 0.0215
2023-02-06 11:36:18 | Valid | Epoch[340/600] Iteration[001/008] Valid loss: 0.0681
2023-02-06 11:36:18 | Valid | Epoch[340/600] Iteration[002/008] Valid loss: 0.0668
2023-02-06 11:36:18 | Valid | Epoch[340/600] Iteration[003/008] Valid loss: 0.0682
2023-02-06 11:36:18 | Valid | Epoch[340/600] Iteration[004/008] Valid loss: 0.0657
2023-02-06 11:36:18 | Valid | Epoch[340/600] Iteration[005/008] Valid loss: 0.0669
2023-02-06 11:36:18 | Valid | Epoch[340/600] Iteration[006/008] Valid loss: 0.0658
2023-02-06 11:36:18 | Valid | Epoch[340/600] Iteration[007/008] Valid loss: 0.0636
2023-02-06 11:36:18 | Valid | Epoch[340/600] Iteration[008/008] Valid loss: 0.0660
2023-02-06 11:36:18 | Valid | Epoch[340/600] MIou: 0.7895689338699619
2023-02-06 11:36:18 | Valid | Epoch[340/600] Pixel Accuracy: 0.9652976989746094
2023-02-06 11:36:18 | Valid | Epoch[340/600] Mean Pixel Accuracy: 0.8080151367331743
2023-02-06 11:36:18 | Stage | Epoch[340/600] Train loss:0.0215
2023-02-06 11:36:18 | Stage | Epoch[340/600] Valid loss:0.0660
2023-02-06 11:36:18 | Stage | Epoch[340/600] LR:0.01

2023-02-06 11:36:18 | Train | Epoch[341/600] Iteration[001/030] Train loss: 0.0226
2023-02-06 11:36:18 | Train | Epoch[341/600] Iteration[002/030] Train loss: 0.0221
2023-02-06 11:36:18 | Train | Epoch[341/600] Iteration[003/030] Train loss: 0.0216
2023-02-06 11:36:18 | Train | Epoch[341/600] Iteration[004/030] Train loss: 0.0213
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[005/030] Train loss: 0.0218
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[006/030] Train loss: 0.0220
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[008/030] Train loss: 0.0219
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[009/030] Train loss: 0.0224
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[010/030] Train loss: 0.0225
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[011/030] Train loss: 0.0227
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[012/030] Train loss: 0.0230
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[013/030] Train loss: 0.0228
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[014/030] Train loss: 0.0226
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[015/030] Train loss: 0.0224
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[016/030] Train loss: 0.0223
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[017/030] Train loss: 0.0221
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[018/030] Train loss: 0.0221
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[019/030] Train loss: 0.0222
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[020/030] Train loss: 0.0221
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[021/030] Train loss: 0.0220
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[022/030] Train loss: 0.0219
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[024/030] Train loss: 0.0220
2023-02-06 11:36:19 | Train | Epoch[341/600] Iteration[025/030] Train loss: 0.0223
2023-02-06 11:36:20 | Train | Epoch[341/600] Iteration[026/030] Train loss: 0.0223
2023-02-06 11:36:20 | Train | Epoch[341/600] Iteration[027/030] Train loss: 0.0225
2023-02-06 11:36:20 | Train | Epoch[341/600] Iteration[028/030] Train loss: 0.0225
2023-02-06 11:36:20 | Train | Epoch[341/600] Iteration[029/030] Train loss: 0.0224
2023-02-06 11:36:20 | Train | Epoch[341/600] Iteration[030/030] Train loss: 0.0224
2023-02-06 11:36:20 | Valid | Epoch[341/600] Iteration[001/008] Valid loss: 0.0802
2023-02-06 11:36:20 | Valid | Epoch[341/600] Iteration[002/008] Valid loss: 0.0569
2023-02-06 11:36:20 | Valid | Epoch[341/600] Iteration[003/008] Valid loss: 0.0513
2023-02-06 11:36:20 | Valid | Epoch[341/600] Iteration[004/008] Valid loss: 0.0515
2023-02-06 11:36:20 | Valid | Epoch[341/600] Iteration[005/008] Valid loss: 0.0582
2023-02-06 11:36:20 | Valid | Epoch[341/600] Iteration[006/008] Valid loss: 0.0584
2023-02-06 11:36:20 | Valid | Epoch[341/600] Iteration[007/008] Valid loss: 0.0590
2023-02-06 11:36:20 | Valid | Epoch[341/600] Iteration[008/008] Valid loss: 0.0568
2023-02-06 11:36:20 | Valid | Epoch[341/600] MIou: 0.933897629110392
2023-02-06 11:36:20 | Valid | Epoch[341/600] Pixel Accuracy: 0.9886525472005209
2023-02-06 11:36:20 | Valid | Epoch[341/600] Mean Pixel Accuracy: 0.9590298530410764
2023-02-06 11:36:20 | Stage | Epoch[341/600] Train loss:0.0224
2023-02-06 11:36:20 | Stage | Epoch[341/600] Valid loss:0.0568
2023-02-06 11:36:20 | Stage | Epoch[341/600] LR:0.01

2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[003/030] Train loss: 0.0212
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[005/030] Train loss: 0.0217
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[008/030] Train loss: 0.0218
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[009/030] Train loss: 0.0217
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[010/030] Train loss: 0.0219
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[012/030] Train loss: 0.0219
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[013/030] Train loss: 0.0222
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[014/030] Train loss: 0.0224
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[015/030] Train loss: 0.0221
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[016/030] Train loss: 0.0221
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:36:21 | Train | Epoch[342/600] Iteration[018/030] Train loss: 0.0218
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[020/030] Train loss: 0.0219
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[021/030] Train loss: 0.0220
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[022/030] Train loss: 0.0218
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 11:36:22 | Train | Epoch[342/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:36:22 | Valid | Epoch[342/600] Iteration[001/008] Valid loss: 0.3268
2023-02-06 11:36:22 | Valid | Epoch[342/600] Iteration[002/008] Valid loss: 0.2437
2023-02-06 11:36:22 | Valid | Epoch[342/600] Iteration[003/008] Valid loss: 0.2298
2023-02-06 11:36:22 | Valid | Epoch[342/600] Iteration[004/008] Valid loss: 0.2281
2023-02-06 11:36:23 | Valid | Epoch[342/600] Iteration[005/008] Valid loss: 0.2392
2023-02-06 11:36:23 | Valid | Epoch[342/600] Iteration[006/008] Valid loss: 0.2332
2023-02-06 11:36:23 | Valid | Epoch[342/600] Iteration[007/008] Valid loss: 0.2548
2023-02-06 11:36:23 | Valid | Epoch[342/600] Iteration[008/008] Valid loss: 0.2535
2023-02-06 11:36:23 | Valid | Epoch[342/600] MIou: 0.9182306914719791
2023-02-06 11:36:23 | Valid | Epoch[342/600] Pixel Accuracy: 0.9847501118977865
2023-02-06 11:36:23 | Valid | Epoch[342/600] Mean Pixel Accuracy: 0.9831915244674723
2023-02-06 11:36:23 | Stage | Epoch[342/600] Train loss:0.0216
2023-02-06 11:36:23 | Stage | Epoch[342/600] Valid loss:0.2535
2023-02-06 11:36:23 | Stage | Epoch[342/600] LR:0.01

2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[003/030] Train loss: 0.0221
2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[005/030] Train loss: 0.0210
2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[010/030] Train loss: 0.0209
2023-02-06 11:36:23 | Train | Epoch[343/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[013/030] Train loss: 0.0212
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[015/030] Train loss: 0.0213
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[018/030] Train loss: 0.0212
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[019/030] Train loss: 0.0212
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[020/030] Train loss: 0.0211
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[021/030] Train loss: 0.0211
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[022/030] Train loss: 0.0212
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[024/030] Train loss: 0.0213
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[025/030] Train loss: 0.0211
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[026/030] Train loss: 0.0211
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[027/030] Train loss: 0.0211
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:36:24 | Train | Epoch[343/600] Iteration[030/030] Train loss: 0.0213
2023-02-06 11:36:25 | Valid | Epoch[343/600] Iteration[001/008] Valid loss: 0.1303
2023-02-06 11:36:25 | Valid | Epoch[343/600] Iteration[002/008] Valid loss: 0.1331
2023-02-06 11:36:25 | Valid | Epoch[343/600] Iteration[003/008] Valid loss: 0.1381
2023-02-06 11:36:25 | Valid | Epoch[343/600] Iteration[004/008] Valid loss: 0.1359
2023-02-06 11:36:25 | Valid | Epoch[343/600] Iteration[005/008] Valid loss: 0.1387
2023-02-06 11:36:25 | Valid | Epoch[343/600] Iteration[006/008] Valid loss: 0.1360
2023-02-06 11:36:25 | Valid | Epoch[343/600] Iteration[007/008] Valid loss: 0.1325
2023-02-06 11:36:25 | Valid | Epoch[343/600] Iteration[008/008] Valid loss: 0.1379
2023-02-06 11:36:25 | Valid | Epoch[343/600] MIou: 0.597227334349031
2023-02-06 11:36:25 | Valid | Epoch[343/600] Pixel Accuracy: 0.9334055582682291
2023-02-06 11:36:25 | Valid | Epoch[343/600] Mean Pixel Accuracy: 0.6313336806093286
2023-02-06 11:36:25 | Stage | Epoch[343/600] Train loss:0.0213
2023-02-06 11:36:25 | Stage | Epoch[343/600] Valid loss:0.1379
2023-02-06 11:36:25 | Stage | Epoch[343/600] LR:0.01

2023-02-06 11:36:25 | Train | Epoch[344/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 11:36:25 | Train | Epoch[344/600] Iteration[002/030] Train loss: 0.0213
2023-02-06 11:36:25 | Train | Epoch[344/600] Iteration[003/030] Train loss: 0.0249
2023-02-06 11:36:25 | Train | Epoch[344/600] Iteration[004/030] Train loss: 0.0240
2023-02-06 11:36:25 | Train | Epoch[344/600] Iteration[005/030] Train loss: 0.0234
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[006/030] Train loss: 0.0233
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[008/030] Train loss: 0.0226
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[009/030] Train loss: 0.0232
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[010/030] Train loss: 0.0228
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[011/030] Train loss: 0.0230
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[012/030] Train loss: 0.0229
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[014/030] Train loss: 0.0230
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[015/030] Train loss: 0.0229
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[016/030] Train loss: 0.0231
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[017/030] Train loss: 0.0232
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[018/030] Train loss: 0.0233
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[019/030] Train loss: 0.0231
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[020/030] Train loss: 0.0229
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[021/030] Train loss: 0.0229
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[022/030] Train loss: 0.0230
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[023/030] Train loss: 0.0230
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[024/030] Train loss: 0.0229
2023-02-06 11:36:26 | Train | Epoch[344/600] Iteration[025/030] Train loss: 0.0229
2023-02-06 11:36:27 | Train | Epoch[344/600] Iteration[026/030] Train loss: 0.0229
2023-02-06 11:36:27 | Train | Epoch[344/600] Iteration[027/030] Train loss: 0.0230
2023-02-06 11:36:27 | Train | Epoch[344/600] Iteration[028/030] Train loss: 0.0229
2023-02-06 11:36:27 | Train | Epoch[344/600] Iteration[029/030] Train loss: 0.0227
2023-02-06 11:36:27 | Train | Epoch[344/600] Iteration[030/030] Train loss: 0.0227
2023-02-06 11:36:27 | Valid | Epoch[344/600] Iteration[001/008] Valid loss: 0.3212
2023-02-06 11:36:27 | Valid | Epoch[344/600] Iteration[002/008] Valid loss: 0.3260
2023-02-06 11:36:27 | Valid | Epoch[344/600] Iteration[003/008] Valid loss: 0.3437
2023-02-06 11:36:27 | Valid | Epoch[344/600] Iteration[004/008] Valid loss: 0.3415
2023-02-06 11:36:27 | Valid | Epoch[344/600] Iteration[005/008] Valid loss: 0.3495
2023-02-06 11:36:27 | Valid | Epoch[344/600] Iteration[006/008] Valid loss: 0.3448
2023-02-06 11:36:27 | Valid | Epoch[344/600] Iteration[007/008] Valid loss: 0.3408
2023-02-06 11:36:27 | Valid | Epoch[344/600] Iteration[008/008] Valid loss: 0.3542
2023-02-06 11:36:27 | Valid | Epoch[344/600] MIou: 0.46076040523164447
2023-02-06 11:36:27 | Valid | Epoch[344/600] Pixel Accuracy: 0.9106699625651041
2023-02-06 11:36:27 | Valid | Epoch[344/600] Mean Pixel Accuracy: 0.5054695969251995
2023-02-06 11:36:27 | Stage | Epoch[344/600] Train loss:0.0227
2023-02-06 11:36:27 | Stage | Epoch[344/600] Valid loss:0.3542
2023-02-06 11:36:27 | Stage | Epoch[344/600] LR:0.01

2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[001/030] Train loss: 0.0208
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[011/030] Train loss: 0.0208
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[013/030] Train loss: 0.0207
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[015/030] Train loss: 0.0212
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 11:36:28 | Train | Epoch[345/600] Iteration[018/030] Train loss: 0.0217
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[023/030] Train loss: 0.0222
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[025/030] Train loss: 0.0221
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[026/030] Train loss: 0.0222
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[028/030] Train loss: 0.0220
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[029/030] Train loss: 0.0221
2023-02-06 11:36:29 | Train | Epoch[345/600] Iteration[030/030] Train loss: 0.0222
2023-02-06 11:36:29 | Valid | Epoch[345/600] Iteration[001/008] Valid loss: 0.7642
2023-02-06 11:36:29 | Valid | Epoch[345/600] Iteration[002/008] Valid loss: 0.7142
2023-02-06 11:36:29 | Valid | Epoch[345/600] Iteration[003/008] Valid loss: 0.7146
2023-02-06 11:36:29 | Valid | Epoch[345/600] Iteration[004/008] Valid loss: 0.7287
2023-02-06 11:36:29 | Valid | Epoch[345/600] Iteration[005/008] Valid loss: 0.7550
2023-02-06 11:36:30 | Valid | Epoch[345/600] Iteration[006/008] Valid loss: 0.7337
2023-02-06 11:36:30 | Valid | Epoch[345/600] Iteration[007/008] Valid loss: 0.7760
2023-02-06 11:36:30 | Valid | Epoch[345/600] Iteration[008/008] Valid loss: 0.7917
2023-02-06 11:36:30 | Valid | Epoch[345/600] MIou: 0.8714350002251107
2023-02-06 11:36:30 | Valid | Epoch[345/600] Pixel Accuracy: 0.9734967549641927
2023-02-06 11:36:30 | Valid | Epoch[345/600] Mean Pixel Accuracy: 0.9825097288251893
2023-02-06 11:36:30 | Stage | Epoch[345/600] Train loss:0.0222
2023-02-06 11:36:30 | Stage | Epoch[345/600] Valid loss:0.7917
2023-02-06 11:36:30 | Stage | Epoch[345/600] LR:0.01

2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[001/030] Train loss: 0.0190
2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[002/030] Train loss: 0.0202
2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[003/030] Train loss: 0.0213
2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[004/030] Train loss: 0.0222
2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[005/030] Train loss: 0.0221
2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[006/030] Train loss: 0.0220
2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[007/030] Train loss: 0.0216
2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[008/030] Train loss: 0.0218
2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[009/030] Train loss: 0.0229
2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[010/030] Train loss: 0.0227
2023-02-06 11:36:30 | Train | Epoch[346/600] Iteration[011/030] Train loss: 0.0228
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[012/030] Train loss: 0.0227
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[013/030] Train loss: 0.0227
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[014/030] Train loss: 0.0228
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[015/030] Train loss: 0.0228
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[016/030] Train loss: 0.0226
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[017/030] Train loss: 0.0225
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[018/030] Train loss: 0.0225
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[019/030] Train loss: 0.0224
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[020/030] Train loss: 0.0223
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[021/030] Train loss: 0.0224
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[022/030] Train loss: 0.0222
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[023/030] Train loss: 0.0222
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[024/030] Train loss: 0.0221
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[025/030] Train loss: 0.0221
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[026/030] Train loss: 0.0220
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[027/030] Train loss: 0.0219
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[028/030] Train loss: 0.0220
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[029/030] Train loss: 0.0221
2023-02-06 11:36:31 | Train | Epoch[346/600] Iteration[030/030] Train loss: 0.0221
2023-02-06 11:36:32 | Valid | Epoch[346/600] Iteration[001/008] Valid loss: 0.1236
2023-02-06 11:36:32 | Valid | Epoch[346/600] Iteration[002/008] Valid loss: 0.1263
2023-02-06 11:36:32 | Valid | Epoch[346/600] Iteration[003/008] Valid loss: 0.1308
2023-02-06 11:36:32 | Valid | Epoch[346/600] Iteration[004/008] Valid loss: 0.1277
2023-02-06 11:36:32 | Valid | Epoch[346/600] Iteration[005/008] Valid loss: 0.1302
2023-02-06 11:36:32 | Valid | Epoch[346/600] Iteration[006/008] Valid loss: 0.1278
2023-02-06 11:36:32 | Valid | Epoch[346/600] Iteration[007/008] Valid loss: 0.1251
2023-02-06 11:36:32 | Valid | Epoch[346/600] Iteration[008/008] Valid loss: 0.1309
2023-02-06 11:36:32 | Valid | Epoch[346/600] MIou: 0.5984278054162906
2023-02-06 11:36:32 | Valid | Epoch[346/600] Pixel Accuracy: 0.9336051940917969
2023-02-06 11:36:32 | Valid | Epoch[346/600] Mean Pixel Accuracy: 0.6324388629996198
2023-02-06 11:36:32 | Stage | Epoch[346/600] Train loss:0.0221
2023-02-06 11:36:32 | Stage | Epoch[346/600] Valid loss:0.1309
2023-02-06 11:36:32 | Stage | Epoch[346/600] LR:0.01

2023-02-06 11:36:32 | Train | Epoch[347/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 11:36:32 | Train | Epoch[347/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 11:36:32 | Train | Epoch[347/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[006/030] Train loss: 0.0216
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[007/030] Train loss: 0.0213
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[008/030] Train loss: 0.0217
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[011/030] Train loss: 0.0210
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[013/030] Train loss: 0.0207
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[015/030] Train loss: 0.0210
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[016/030] Train loss: 0.0210
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[018/030] Train loss: 0.0212
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[019/030] Train loss: 0.0215
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[020/030] Train loss: 0.0215
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[021/030] Train loss: 0.0216
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[022/030] Train loss: 0.0217
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[023/030] Train loss: 0.0218
2023-02-06 11:36:33 | Train | Epoch[347/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:36:34 | Train | Epoch[347/600] Iteration[025/030] Train loss: 0.0219
2023-02-06 11:36:34 | Train | Epoch[347/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:36:34 | Train | Epoch[347/600] Iteration[027/030] Train loss: 0.0218
2023-02-06 11:36:34 | Train | Epoch[347/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:36:34 | Train | Epoch[347/600] Iteration[029/030] Train loss: 0.0217
2023-02-06 11:36:34 | Train | Epoch[347/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:36:34 | Valid | Epoch[347/600] Iteration[001/008] Valid loss: 0.1926
2023-02-06 11:36:34 | Valid | Epoch[347/600] Iteration[002/008] Valid loss: 0.1308
2023-02-06 11:36:34 | Valid | Epoch[347/600] Iteration[003/008] Valid loss: 0.1166
2023-02-06 11:36:34 | Valid | Epoch[347/600] Iteration[004/008] Valid loss: 0.1168
2023-02-06 11:36:34 | Valid | Epoch[347/600] Iteration[005/008] Valid loss: 0.1240
2023-02-06 11:36:34 | Valid | Epoch[347/600] Iteration[006/008] Valid loss: 0.1260
2023-02-06 11:36:34 | Valid | Epoch[347/600] Iteration[007/008] Valid loss: 0.1352
2023-02-06 11:36:34 | Valid | Epoch[347/600] Iteration[008/008] Valid loss: 0.1321
2023-02-06 11:36:34 | Valid | Epoch[347/600] MIou: 0.930106061825215
2023-02-06 11:36:34 | Valid | Epoch[347/600] Pixel Accuracy: 0.9874165852864584
2023-02-06 11:36:34 | Valid | Epoch[347/600] Mean Pixel Accuracy: 0.9779552535759575
2023-02-06 11:36:34 | Stage | Epoch[347/600] Train loss:0.0216
2023-02-06 11:36:34 | Stage | Epoch[347/600] Valid loss:0.1321
2023-02-06 11:36:34 | Stage | Epoch[347/600] LR:0.01

2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[001/030] Train loss: 0.0235
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[002/030] Train loss: 0.0233
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[003/030] Train loss: 0.0224
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[004/030] Train loss: 0.0219
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[005/030] Train loss: 0.0214
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[006/030] Train loss: 0.0215
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[007/030] Train loss: 0.0212
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[010/030] Train loss: 0.0215
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[011/030] Train loss: 0.0220
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[012/030] Train loss: 0.0217
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[013/030] Train loss: 0.0216
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[016/030] Train loss: 0.0217
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[017/030] Train loss: 0.0218
2023-02-06 11:36:35 | Train | Epoch[348/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[019/030] Train loss: 0.0219
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[020/030] Train loss: 0.0219
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[021/030] Train loss: 0.0219
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[022/030] Train loss: 0.0219
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:36:36 | Train | Epoch[348/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:36:36 | Valid | Epoch[348/600] Iteration[001/008] Valid loss: 0.0495
2023-02-06 11:36:36 | Valid | Epoch[348/600] Iteration[002/008] Valid loss: 0.0464
2023-02-06 11:36:36 | Valid | Epoch[348/600] Iteration[003/008] Valid loss: 0.0465
2023-02-06 11:36:36 | Valid | Epoch[348/600] Iteration[004/008] Valid loss: 0.0448
2023-02-06 11:36:36 | Valid | Epoch[348/600] Iteration[005/008] Valid loss: 0.0455
2023-02-06 11:36:37 | Valid | Epoch[348/600] Iteration[006/008] Valid loss: 0.0449
2023-02-06 11:36:37 | Valid | Epoch[348/600] Iteration[007/008] Valid loss: 0.0435
2023-02-06 11:36:37 | Valid | Epoch[348/600] Iteration[008/008] Valid loss: 0.0443
2023-02-06 11:36:37 | Valid | Epoch[348/600] MIou: 0.8519483494861686
2023-02-06 11:36:37 | Valid | Epoch[348/600] Pixel Accuracy: 0.9755961100260416
2023-02-06 11:36:37 | Valid | Epoch[348/600] Mean Pixel Accuracy: 0.8652743398289552
2023-02-06 11:36:37 | Stage | Epoch[348/600] Train loss:0.0217
2023-02-06 11:36:37 | Stage | Epoch[348/600] Valid loss:0.0443
2023-02-06 11:36:37 | Stage | Epoch[348/600] LR:0.01

2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[002/030] Train loss: 0.0203
2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:36:37 | Train | Epoch[349/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[012/030] Train loss: 0.0206
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[017/030] Train loss: 0.0206
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[018/030] Train loss: 0.0207
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[021/030] Train loss: 0.0207
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[022/030] Train loss: 0.0208
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[023/030] Train loss: 0.0209
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[024/030] Train loss: 0.0210
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[025/030] Train loss: 0.0209
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[026/030] Train loss: 0.0210
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[027/030] Train loss: 0.0209
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[028/030] Train loss: 0.0210
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[029/030] Train loss: 0.0211
2023-02-06 11:36:38 | Train | Epoch[349/600] Iteration[030/030] Train loss: 0.0213
2023-02-06 11:36:39 | Valid | Epoch[349/600] Iteration[001/008] Valid loss: 0.4654
2023-02-06 11:36:39 | Valid | Epoch[349/600] Iteration[002/008] Valid loss: 0.3809
2023-02-06 11:36:39 | Valid | Epoch[349/600] Iteration[003/008] Valid loss: 0.3757
2023-02-06 11:36:39 | Valid | Epoch[349/600] Iteration[004/008] Valid loss: 0.3760
2023-02-06 11:36:39 | Valid | Epoch[349/600] Iteration[005/008] Valid loss: 0.4019
2023-02-06 11:36:39 | Valid | Epoch[349/600] Iteration[006/008] Valid loss: 0.3961
2023-02-06 11:36:39 | Valid | Epoch[349/600] Iteration[007/008] Valid loss: 0.4221
2023-02-06 11:36:39 | Valid | Epoch[349/600] Iteration[008/008] Valid loss: 0.4258
2023-02-06 11:36:39 | Valid | Epoch[349/600] MIou: 0.8973823073240769
2023-02-06 11:36:39 | Valid | Epoch[349/600] Pixel Accuracy: 0.9800097147623698
2023-02-06 11:36:39 | Valid | Epoch[349/600] Mean Pixel Accuracy: 0.9828051650580272
2023-02-06 11:36:39 | Stage | Epoch[349/600] Train loss:0.0213
2023-02-06 11:36:39 | Stage | Epoch[349/600] Valid loss:0.4258
2023-02-06 11:36:39 | Stage | Epoch[349/600] LR:0.01

2023-02-06 11:36:39 | Train | Epoch[350/600] Iteration[001/030] Train loss: 0.0245
2023-02-06 11:36:39 | Train | Epoch[350/600] Iteration[002/030] Train loss: 0.0221
2023-02-06 11:36:39 | Train | Epoch[350/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 11:36:39 | Train | Epoch[350/600] Iteration[004/030] Train loss: 0.0222
2023-02-06 11:36:39 | Train | Epoch[350/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 11:36:39 | Train | Epoch[350/600] Iteration[006/030] Train loss: 0.0226
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[007/030] Train loss: 0.0224
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[008/030] Train loss: 0.0225
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[009/030] Train loss: 0.0225
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[010/030] Train loss: 0.0223
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[011/030] Train loss: 0.0222
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[012/030] Train loss: 0.0220
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[013/030] Train loss: 0.0223
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[014/030] Train loss: 0.0222
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[015/030] Train loss: 0.0222
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[016/030] Train loss: 0.0221
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[019/030] Train loss: 0.0220
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[020/030] Train loss: 0.0219
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[021/030] Train loss: 0.0217
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[022/030] Train loss: 0.0216
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[025/030] Train loss: 0.0214
2023-02-06 11:36:40 | Train | Epoch[350/600] Iteration[026/030] Train loss: 0.0213
2023-02-06 11:36:41 | Train | Epoch[350/600] Iteration[027/030] Train loss: 0.0214
2023-02-06 11:36:41 | Train | Epoch[350/600] Iteration[028/030] Train loss: 0.0213
2023-02-06 11:36:41 | Train | Epoch[350/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:36:41 | Train | Epoch[350/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 11:36:41 | Valid | Epoch[350/600] Iteration[001/008] Valid loss: 0.0618
2023-02-06 11:36:41 | Valid | Epoch[350/600] Iteration[002/008] Valid loss: 0.0448
2023-02-06 11:36:41 | Valid | Epoch[350/600] Iteration[003/008] Valid loss: 0.0397
2023-02-06 11:36:41 | Valid | Epoch[350/600] Iteration[004/008] Valid loss: 0.0391
2023-02-06 11:36:41 | Valid | Epoch[350/600] Iteration[005/008] Valid loss: 0.0417
2023-02-06 11:36:41 | Valid | Epoch[350/600] Iteration[006/008] Valid loss: 0.0411
2023-02-06 11:36:41 | Valid | Epoch[350/600] Iteration[007/008] Valid loss: 0.0415
2023-02-06 11:36:41 | Valid | Epoch[350/600] Iteration[008/008] Valid loss: 0.0400
2023-02-06 11:36:41 | Valid | Epoch[350/600] MIou: 0.9352156341611761
2023-02-06 11:36:41 | Valid | Epoch[350/600] Pixel Accuracy: 0.9890708923339844
2023-02-06 11:36:41 | Valid | Epoch[350/600] Mean Pixel Accuracy: 0.9522916151766405
2023-02-06 11:36:41 | Stage | Epoch[350/600] Train loss:0.0214
2023-02-06 11:36:41 | Stage | Epoch[350/600] Valid loss:0.0400
2023-02-06 11:36:41 | Stage | Epoch[350/600] LR:0.01

2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[001/030] Train loss: 0.0201
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[002/030] Train loss: 0.0213
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[003/030] Train loss: 0.0212
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[004/030] Train loss: 0.0216
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[005/030] Train loss: 0.0219
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[007/030] Train loss: 0.0222
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[008/030] Train loss: 0.0221
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[009/030] Train loss: 0.0220
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[010/030] Train loss: 0.0219
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[012/030] Train loss: 0.0218
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[014/030] Train loss: 0.0214
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[015/030] Train loss: 0.0214
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:36:42 | Train | Epoch[351/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:36:43 | Train | Epoch[351/600] Iteration[021/030] Train loss: 0.0213
2023-02-06 11:36:43 | Train | Epoch[351/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:36:43 | Train | Epoch[351/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:36:43 | Train | Epoch[351/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:36:43 | Train | Epoch[351/600] Iteration[025/030] Train loss: 0.0213
2023-02-06 11:36:43 | Train | Epoch[351/600] Iteration[026/030] Train loss: 0.0213
2023-02-06 11:36:43 | Train | Epoch[351/600] Iteration[027/030] Train loss: 0.0213
2023-02-06 11:36:43 | Train | Epoch[351/600] Iteration[028/030] Train loss: 0.0213
2023-02-06 11:36:43 | Train | Epoch[351/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:36:43 | Train | Epoch[351/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:36:43 | Valid | Epoch[351/600] Iteration[001/008] Valid loss: 0.2783
2023-02-06 11:36:43 | Valid | Epoch[351/600] Iteration[002/008] Valid loss: 0.1957
2023-02-06 11:36:43 | Valid | Epoch[351/600] Iteration[003/008] Valid loss: 0.1806
2023-02-06 11:36:43 | Valid | Epoch[351/600] Iteration[004/008] Valid loss: 0.1816
2023-02-06 11:36:44 | Valid | Epoch[351/600] Iteration[005/008] Valid loss: 0.1939
2023-02-06 11:36:44 | Valid | Epoch[351/600] Iteration[006/008] Valid loss: 0.1925
2023-02-06 11:36:44 | Valid | Epoch[351/600] Iteration[007/008] Valid loss: 0.2082
2023-02-06 11:36:44 | Valid | Epoch[351/600] Iteration[008/008] Valid loss: 0.2034
2023-02-06 11:36:44 | Valid | Epoch[351/600] MIou: 0.9262122582772698
2023-02-06 11:36:44 | Valid | Epoch[351/600] Pixel Accuracy: 0.9864578247070312
2023-02-06 11:36:44 | Valid | Epoch[351/600] Mean Pixel Accuracy: 0.9834644067508547
2023-02-06 11:36:44 | Stage | Epoch[351/600] Train loss:0.0216
2023-02-06 11:36:44 | Stage | Epoch[351/600] Valid loss:0.2034
2023-02-06 11:36:44 | Stage | Epoch[351/600] LR:0.01

2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:36:44 | Train | Epoch[352/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[012/030] Train loss: 0.0212
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[013/030] Train loss: 0.0213
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[014/030] Train loss: 0.0212
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[015/030] Train loss: 0.0212
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[016/030] Train loss: 0.0211
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[017/030] Train loss: 0.0210
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[018/030] Train loss: 0.0210
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[019/030] Train loss: 0.0209
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[021/030] Train loss: 0.0209
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[022/030] Train loss: 0.0209
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[023/030] Train loss: 0.0209
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[024/030] Train loss: 0.0210
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[025/030] Train loss: 0.0211
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[026/030] Train loss: 0.0211
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[027/030] Train loss: 0.0211
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[028/030] Train loss: 0.0214
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:36:45 | Train | Epoch[352/600] Iteration[030/030] Train loss: 0.0215
2023-02-06 11:36:46 | Valid | Epoch[352/600] Iteration[001/008] Valid loss: 0.1203
2023-02-06 11:36:46 | Valid | Epoch[352/600] Iteration[002/008] Valid loss: 0.0804
2023-02-06 11:36:46 | Valid | Epoch[352/600] Iteration[003/008] Valid loss: 0.0700
2023-02-06 11:36:46 | Valid | Epoch[352/600] Iteration[004/008] Valid loss: 0.0691
2023-02-06 11:36:46 | Valid | Epoch[352/600] Iteration[005/008] Valid loss: 0.0744
2023-02-06 11:36:46 | Valid | Epoch[352/600] Iteration[006/008] Valid loss: 0.0737
2023-02-06 11:36:46 | Valid | Epoch[352/600] Iteration[007/008] Valid loss: 0.0768
2023-02-06 11:36:46 | Valid | Epoch[352/600] Iteration[008/008] Valid loss: 0.0743
2023-02-06 11:36:46 | Valid | Epoch[352/600] MIou: 0.9387574023627352
2023-02-06 11:36:46 | Valid | Epoch[352/600] Pixel Accuracy: 0.9893264770507812
2023-02-06 11:36:46 | Valid | Epoch[352/600] Mean Pixel Accuracy: 0.9708448247084964
2023-02-06 11:36:46 | Stage | Epoch[352/600] Train loss:0.0215
2023-02-06 11:36:46 | Stage | Epoch[352/600] Valid loss:0.0743
2023-02-06 11:36:46 | Stage | Epoch[352/600] LR:0.01

2023-02-06 11:36:46 | Train | Epoch[353/600] Iteration[001/030] Train loss: 0.0210
2023-02-06 11:36:46 | Train | Epoch[353/600] Iteration[002/030] Train loss: 0.0206
2023-02-06 11:36:46 | Train | Epoch[353/600] Iteration[003/030] Train loss: 0.0218
2023-02-06 11:36:46 | Train | Epoch[353/600] Iteration[004/030] Train loss: 0.0220
2023-02-06 11:36:46 | Train | Epoch[353/600] Iteration[005/030] Train loss: 0.0229
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[006/030] Train loss: 0.0225
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[007/030] Train loss: 0.0226
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[008/030] Train loss: 0.0221
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[009/030] Train loss: 0.0223
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[010/030] Train loss: 0.0222
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[011/030] Train loss: 0.0221
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[012/030] Train loss: 0.0218
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[013/030] Train loss: 0.0216
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[014/030] Train loss: 0.0214
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[015/030] Train loss: 0.0214
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[016/030] Train loss: 0.0213
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[018/030] Train loss: 0.0212
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[019/030] Train loss: 0.0212
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[021/030] Train loss: 0.0211
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[024/030] Train loss: 0.0213
2023-02-06 11:36:47 | Train | Epoch[353/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:36:48 | Train | Epoch[353/600] Iteration[026/030] Train loss: 0.0212
2023-02-06 11:36:48 | Train | Epoch[353/600] Iteration[027/030] Train loss: 0.0212
2023-02-06 11:36:48 | Train | Epoch[353/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:36:48 | Train | Epoch[353/600] Iteration[029/030] Train loss: 0.0211
2023-02-06 11:36:48 | Train | Epoch[353/600] Iteration[030/030] Train loss: 0.0213
2023-02-06 11:36:48 | Valid | Epoch[353/600] Iteration[001/008] Valid loss: 0.0426
2023-02-06 11:36:48 | Valid | Epoch[353/600] Iteration[002/008] Valid loss: 0.0398
2023-02-06 11:36:48 | Valid | Epoch[353/600] Iteration[003/008] Valid loss: 0.0393
2023-02-06 11:36:48 | Valid | Epoch[353/600] Iteration[004/008] Valid loss: 0.0377
2023-02-06 11:36:48 | Valid | Epoch[353/600] Iteration[005/008] Valid loss: 0.0384
2023-02-06 11:36:48 | Valid | Epoch[353/600] Iteration[006/008] Valid loss: 0.0381
2023-02-06 11:36:48 | Valid | Epoch[353/600] Iteration[007/008] Valid loss: 0.0369
2023-02-06 11:36:48 | Valid | Epoch[353/600] Iteration[008/008] Valid loss: 0.0377
2023-02-06 11:36:48 | Valid | Epoch[353/600] MIou: 0.8708944072531848
2023-02-06 11:36:48 | Valid | Epoch[353/600] Pixel Accuracy: 0.9787012736002604
2023-02-06 11:36:48 | Valid | Epoch[353/600] Mean Pixel Accuracy: 0.8830288035584433
2023-02-06 11:36:48 | Stage | Epoch[353/600] Train loss:0.0213
2023-02-06 11:36:48 | Stage | Epoch[353/600] Valid loss:0.0377
2023-02-06 11:36:48 | Stage | Epoch[353/600] LR:0.01

2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[001/030] Train loss: 0.0192
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[002/030] Train loss: 0.0214
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[004/030] Train loss: 0.0224
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[006/030] Train loss: 0.0218
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[009/030] Train loss: 0.0217
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[010/030] Train loss: 0.0216
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[011/030] Train loss: 0.0215
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[012/030] Train loss: 0.0214
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[015/030] Train loss: 0.0219
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[016/030] Train loss: 0.0217
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[018/030] Train loss: 0.0217
2023-02-06 11:36:49 | Train | Epoch[354/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[021/030] Train loss: 0.0215
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[022/030] Train loss: 0.0214
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[024/030] Train loss: 0.0213
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[025/030] Train loss: 0.0214
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[026/030] Train loss: 0.0214
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[027/030] Train loss: 0.0214
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[028/030] Train loss: 0.0214
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:36:50 | Train | Epoch[354/600] Iteration[030/030] Train loss: 0.0215
2023-02-06 11:36:50 | Valid | Epoch[354/600] Iteration[001/008] Valid loss: 0.0460
2023-02-06 11:36:50 | Valid | Epoch[354/600] Iteration[002/008] Valid loss: 0.0434
2023-02-06 11:36:50 | Valid | Epoch[354/600] Iteration[003/008] Valid loss: 0.0432
2023-02-06 11:36:50 | Valid | Epoch[354/600] Iteration[004/008] Valid loss: 0.0413
2023-02-06 11:36:50 | Valid | Epoch[354/600] Iteration[005/008] Valid loss: 0.0433
2023-02-06 11:36:50 | Valid | Epoch[354/600] Iteration[006/008] Valid loss: 0.0423
2023-02-06 11:36:50 | Valid | Epoch[354/600] Iteration[007/008] Valid loss: 0.0406
2023-02-06 11:36:51 | Valid | Epoch[354/600] Iteration[008/008] Valid loss: 0.0415
2023-02-06 11:36:51 | Valid | Epoch[354/600] MIou: 0.8676016122247628
2023-02-06 11:36:51 | Valid | Epoch[354/600] Pixel Accuracy: 0.978118896484375
2023-02-06 11:36:51 | Valid | Epoch[354/600] Mean Pixel Accuracy: 0.8806734129023917
2023-02-06 11:36:51 | Stage | Epoch[354/600] Train loss:0.0215
2023-02-06 11:36:51 | Stage | Epoch[354/600] Valid loss:0.0415
2023-02-06 11:36:51 | Stage | Epoch[354/600] LR:0.01

2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[010/030] Train loss: 0.0209
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[011/030] Train loss: 0.0210
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:36:51 | Train | Epoch[355/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[015/030] Train loss: 0.0214
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[016/030] Train loss: 0.0213
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[018/030] Train loss: 0.0216
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[019/030] Train loss: 0.0216
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[020/030] Train loss: 0.0215
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[021/030] Train loss: 0.0214
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[022/030] Train loss: 0.0216
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[025/030] Train loss: 0.0215
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[026/030] Train loss: 0.0215
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[027/030] Train loss: 0.0215
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:36:52 | Train | Epoch[355/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:36:53 | Valid | Epoch[355/600] Iteration[001/008] Valid loss: 1.5600
2023-02-06 11:36:53 | Valid | Epoch[355/600] Iteration[002/008] Valid loss: 1.5335
2023-02-06 11:36:53 | Valid | Epoch[355/600] Iteration[003/008] Valid loss: 1.5705
2023-02-06 11:36:53 | Valid | Epoch[355/600] Iteration[004/008] Valid loss: 1.6107
2023-02-06 11:36:53 | Valid | Epoch[355/600] Iteration[005/008] Valid loss: 1.6601
2023-02-06 11:36:53 | Valid | Epoch[355/600] Iteration[006/008] Valid loss: 1.6233
2023-02-06 11:36:53 | Valid | Epoch[355/600] Iteration[007/008] Valid loss: 1.6850
2023-02-06 11:36:53 | Valid | Epoch[355/600] Iteration[008/008] Valid loss: 1.7382
2023-02-06 11:36:53 | Valid | Epoch[355/600] MIou: 0.8121233827220871
2023-02-06 11:36:53 | Valid | Epoch[355/600] Pixel Accuracy: 0.9561195373535156
2023-02-06 11:36:53 | Valid | Epoch[355/600] Mean Pixel Accuracy: 0.9747655032868976
2023-02-06 11:36:53 | Stage | Epoch[355/600] Train loss:0.0217
2023-02-06 11:36:53 | Stage | Epoch[355/600] Valid loss:1.7382
2023-02-06 11:36:53 | Stage | Epoch[355/600] LR:0.01

2023-02-06 11:36:53 | Train | Epoch[356/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 11:36:53 | Train | Epoch[356/600] Iteration[002/030] Train loss: 0.0235
2023-02-06 11:36:53 | Train | Epoch[356/600] Iteration[003/030] Train loss: 0.0239
2023-02-06 11:36:53 | Train | Epoch[356/600] Iteration[004/030] Train loss: 0.0238
2023-02-06 11:36:53 | Train | Epoch[356/600] Iteration[005/030] Train loss: 0.0232
2023-02-06 11:36:53 | Train | Epoch[356/600] Iteration[006/030] Train loss: 0.0228
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[007/030] Train loss: 0.0226
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[008/030] Train loss: 0.0221
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[009/030] Train loss: 0.0225
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[010/030] Train loss: 0.0223
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[011/030] Train loss: 0.0222
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[012/030] Train loss: 0.0220
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[013/030] Train loss: 0.0220
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[015/030] Train loss: 0.0217
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[016/030] Train loss: 0.0218
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[017/030] Train loss: 0.0220
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[019/030] Train loss: 0.0219
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[020/030] Train loss: 0.0219
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[021/030] Train loss: 0.0220
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[022/030] Train loss: 0.0220
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 11:36:54 | Train | Epoch[356/600] Iteration[027/030] Train loss: 0.0218
2023-02-06 11:36:55 | Train | Epoch[356/600] Iteration[028/030] Train loss: 0.0219
2023-02-06 11:36:55 | Train | Epoch[356/600] Iteration[029/030] Train loss: 0.0219
2023-02-06 11:36:55 | Train | Epoch[356/600] Iteration[030/030] Train loss: 0.0218
2023-02-06 11:36:55 | Valid | Epoch[356/600] Iteration[001/008] Valid loss: 0.0804
2023-02-06 11:36:55 | Valid | Epoch[356/600] Iteration[002/008] Valid loss: 0.0561
2023-02-06 11:36:55 | Valid | Epoch[356/600] Iteration[003/008] Valid loss: 0.0487
2023-02-06 11:36:55 | Valid | Epoch[356/600] Iteration[004/008] Valid loss: 0.0474
2023-02-06 11:36:55 | Valid | Epoch[356/600] Iteration[005/008] Valid loss: 0.0557
2023-02-06 11:36:55 | Valid | Epoch[356/600] Iteration[006/008] Valid loss: 0.0563
2023-02-06 11:36:55 | Valid | Epoch[356/600] Iteration[007/008] Valid loss: 0.0567
2023-02-06 11:36:55 | Valid | Epoch[356/600] Iteration[008/008] Valid loss: 0.0545
2023-02-06 11:36:55 | Valid | Epoch[356/600] MIou: 0.9373296725184606
2023-02-06 11:36:55 | Valid | Epoch[356/600] Pixel Accuracy: 0.9893213907877604
2023-02-06 11:36:55 | Valid | Epoch[356/600] Mean Pixel Accuracy: 0.9588712188666095
2023-02-06 11:36:55 | Stage | Epoch[356/600] Train loss:0.0218
2023-02-06 11:36:55 | Stage | Epoch[356/600] Valid loss:0.0545
2023-02-06 11:36:55 | Stage | Epoch[356/600] LR:0.01

2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[001/030] Train loss: 0.0245
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[003/030] Train loss: 0.0217
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[005/030] Train loss: 0.0216
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[006/030] Train loss: 0.0216
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[011/030] Train loss: 0.0210
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[015/030] Train loss: 0.0210
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[018/030] Train loss: 0.0210
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:36:56 | Train | Epoch[357/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:36:57 | Train | Epoch[357/600] Iteration[021/030] Train loss: 0.0210
2023-02-06 11:36:57 | Train | Epoch[357/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:36:57 | Train | Epoch[357/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:36:57 | Train | Epoch[357/600] Iteration[024/030] Train loss: 0.0213
2023-02-06 11:36:57 | Train | Epoch[357/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:36:57 | Train | Epoch[357/600] Iteration[026/030] Train loss: 0.0214
2023-02-06 11:36:57 | Train | Epoch[357/600] Iteration[027/030] Train loss: 0.0215
2023-02-06 11:36:57 | Train | Epoch[357/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:36:57 | Train | Epoch[357/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 11:36:57 | Train | Epoch[357/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:36:57 | Valid | Epoch[357/600] Iteration[001/008] Valid loss: 3.3427
2023-02-06 11:36:57 | Valid | Epoch[357/600] Iteration[002/008] Valid loss: 3.2108
2023-02-06 11:36:57 | Valid | Epoch[357/600] Iteration[003/008] Valid loss: 3.3636
2023-02-06 11:36:57 | Valid | Epoch[357/600] Iteration[004/008] Valid loss: 3.4867
2023-02-06 11:36:57 | Valid | Epoch[357/600] Iteration[005/008] Valid loss: 3.5851
2023-02-06 11:36:57 | Valid | Epoch[357/600] Iteration[006/008] Valid loss: 3.5448
2023-02-06 11:36:57 | Valid | Epoch[357/600] Iteration[007/008] Valid loss: 3.6270
2023-02-06 11:36:57 | Valid | Epoch[357/600] Iteration[008/008] Valid loss: 3.7369
2023-02-06 11:36:58 | Valid | Epoch[357/600] MIou: 0.7186881083886343
2023-02-06 11:36:58 | Valid | Epoch[357/600] Pixel Accuracy: 0.9188219706217448
2023-02-06 11:36:58 | Valid | Epoch[357/600] Mean Pixel Accuracy: 0.9553176881793737
2023-02-06 11:36:58 | Stage | Epoch[357/600] Train loss:0.0216
2023-02-06 11:36:58 | Stage | Epoch[357/600] Valid loss:3.7369
2023-02-06 11:36:58 | Stage | Epoch[357/600] LR:0.01

2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[002/030] Train loss: 0.0221
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[004/030] Train loss: 0.0208
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[005/030] Train loss: 0.0214
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[006/030] Train loss: 0.0215
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[008/030] Train loss: 0.0215
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[009/030] Train loss: 0.0216
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[010/030] Train loss: 0.0216
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[012/030] Train loss: 0.0216
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:36:58 | Train | Epoch[358/600] Iteration[014/030] Train loss: 0.0214
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[015/030] Train loss: 0.0212
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[018/030] Train loss: 0.0213
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[020/030] Train loss: 0.0214
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[021/030] Train loss: 0.0214
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[023/030] Train loss: 0.0214
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[025/030] Train loss: 0.0214
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[026/030] Train loss: 0.0213
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[027/030] Train loss: 0.0213
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[028/030] Train loss: 0.0214
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 11:36:59 | Train | Epoch[358/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:37:00 | Valid | Epoch[358/600] Iteration[001/008] Valid loss: 0.1600
2023-02-06 11:37:00 | Valid | Epoch[358/600] Iteration[002/008] Valid loss: 0.1071
2023-02-06 11:37:00 | Valid | Epoch[358/600] Iteration[003/008] Valid loss: 0.0927
2023-02-06 11:37:00 | Valid | Epoch[358/600] Iteration[004/008] Valid loss: 0.0924
2023-02-06 11:37:00 | Valid | Epoch[358/600] Iteration[005/008] Valid loss: 0.0973
2023-02-06 11:37:00 | Valid | Epoch[358/600] Iteration[006/008] Valid loss: 0.0959
2023-02-06 11:37:00 | Valid | Epoch[358/600] Iteration[007/008] Valid loss: 0.1040
2023-02-06 11:37:00 | Valid | Epoch[358/600] Iteration[008/008] Valid loss: 0.1000
2023-02-06 11:37:00 | Valid | Epoch[358/600] MIou: 0.938938462131765
2023-02-06 11:37:00 | Valid | Epoch[358/600] Pixel Accuracy: 0.9892361958821615
2023-02-06 11:37:00 | Valid | Epoch[358/600] Mean Pixel Accuracy: 0.9764952862171841
2023-02-06 11:37:00 | Stage | Epoch[358/600] Train loss:0.0216
2023-02-06 11:37:00 | Stage | Epoch[358/600] Valid loss:0.1000
2023-02-06 11:37:00 | Stage | Epoch[358/600] LR:0.01

2023-02-06 11:37:00 | Train | Epoch[359/600] Iteration[001/030] Train loss: 0.0241
2023-02-06 11:37:00 | Train | Epoch[359/600] Iteration[002/030] Train loss: 0.0224
2023-02-06 11:37:00 | Train | Epoch[359/600] Iteration[003/030] Train loss: 0.0230
2023-02-06 11:37:00 | Train | Epoch[359/600] Iteration[004/030] Train loss: 0.0227
2023-02-06 11:37:00 | Train | Epoch[359/600] Iteration[005/030] Train loss: 0.0228
2023-02-06 11:37:00 | Train | Epoch[359/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:37:00 | Train | Epoch[359/600] Iteration[007/030] Train loss: 0.0222
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[011/030] Train loss: 0.0241
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[012/030] Train loss: 0.0237
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[013/030] Train loss: 0.0236
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[014/030] Train loss: 0.0235
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[015/030] Train loss: 0.0234
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[016/030] Train loss: 0.0236
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[017/030] Train loss: 0.0234
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[018/030] Train loss: 0.0234
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[019/030] Train loss: 0.0234
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[020/030] Train loss: 0.0231
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[021/030] Train loss: 0.0232
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[022/030] Train loss: 0.0231
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[023/030] Train loss: 0.0232
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[024/030] Train loss: 0.0231
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[025/030] Train loss: 0.0229
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[026/030] Train loss: 0.0228
2023-02-06 11:37:01 | Train | Epoch[359/600] Iteration[027/030] Train loss: 0.0227
2023-02-06 11:37:02 | Train | Epoch[359/600] Iteration[028/030] Train loss: 0.0228
2023-02-06 11:37:02 | Train | Epoch[359/600] Iteration[029/030] Train loss: 0.0229
2023-02-06 11:37:02 | Train | Epoch[359/600] Iteration[030/030] Train loss: 0.0227
2023-02-06 11:37:02 | Valid | Epoch[359/600] Iteration[001/008] Valid loss: 0.0642
2023-02-06 11:37:02 | Valid | Epoch[359/600] Iteration[002/008] Valid loss: 0.0470
2023-02-06 11:37:02 | Valid | Epoch[359/600] Iteration[003/008] Valid loss: 0.0420
2023-02-06 11:37:02 | Valid | Epoch[359/600] Iteration[004/008] Valid loss: 0.0394
2023-02-06 11:37:02 | Valid | Epoch[359/600] Iteration[005/008] Valid loss: 0.0400
2023-02-06 11:37:02 | Valid | Epoch[359/600] Iteration[006/008] Valid loss: 0.0400
2023-02-06 11:37:02 | Valid | Epoch[359/600] Iteration[007/008] Valid loss: 0.0410
2023-02-06 11:37:02 | Valid | Epoch[359/600] Iteration[008/008] Valid loss: 0.0409
2023-02-06 11:37:02 | Valid | Epoch[359/600] MIou: 0.9303032656649544
2023-02-06 11:37:02 | Valid | Epoch[359/600] Pixel Accuracy: 0.9881795247395834
2023-02-06 11:37:02 | Valid | Epoch[359/600] Mean Pixel Accuracy: 0.9500580518650273
2023-02-06 11:37:02 | Stage | Epoch[359/600] Train loss:0.0227
2023-02-06 11:37:02 | Stage | Epoch[359/600] Valid loss:0.0409
2023-02-06 11:37:02 | Stage | Epoch[359/600] LR:0.01

2023-02-06 11:37:02 | Train | Epoch[360/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 11:37:02 | Train | Epoch[360/600] Iteration[002/030] Train loss: 0.0209
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[009/030] Train loss: 0.0213
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[010/030] Train loss: 0.0216
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[011/030] Train loss: 0.0217
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[012/030] Train loss: 0.0219
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[014/030] Train loss: 0.0214
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[015/030] Train loss: 0.0212
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[017/030] Train loss: 0.0217
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[018/030] Train loss: 0.0215
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[019/030] Train loss: 0.0217
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[021/030] Train loss: 0.0215
2023-02-06 11:37:03 | Train | Epoch[360/600] Iteration[022/030] Train loss: 0.0216
2023-02-06 11:37:04 | Train | Epoch[360/600] Iteration[023/030] Train loss: 0.0217
2023-02-06 11:37:04 | Train | Epoch[360/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:37:04 | Train | Epoch[360/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:37:04 | Train | Epoch[360/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:37:04 | Train | Epoch[360/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:37:04 | Train | Epoch[360/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:37:04 | Train | Epoch[360/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:37:04 | Train | Epoch[360/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:37:04 | Valid | Epoch[360/600] Iteration[001/008] Valid loss: 0.2507
2023-02-06 11:37:04 | Valid | Epoch[360/600] Iteration[002/008] Valid loss: 0.1833
2023-02-06 11:37:04 | Valid | Epoch[360/600] Iteration[003/008] Valid loss: 0.1633
2023-02-06 11:37:04 | Valid | Epoch[360/600] Iteration[004/008] Valid loss: 0.1615
2023-02-06 11:37:04 | Valid | Epoch[360/600] Iteration[005/008] Valid loss: 0.1670
2023-02-06 11:37:04 | Valid | Epoch[360/600] Iteration[006/008] Valid loss: 0.1659
2023-02-06 11:37:04 | Valid | Epoch[360/600] Iteration[007/008] Valid loss: 0.1778
2023-02-06 11:37:04 | Valid | Epoch[360/600] Iteration[008/008] Valid loss: 0.1752
2023-02-06 11:37:04 | Valid | Epoch[360/600] MIou: 0.9266887805084689
2023-02-06 11:37:04 | Valid | Epoch[360/600] Pixel Accuracy: 0.9866015116373698
2023-02-06 11:37:04 | Valid | Epoch[360/600] Mean Pixel Accuracy: 0.9818758392081911
2023-02-06 11:37:04 | Stage | Epoch[360/600] Train loss:0.0216
2023-02-06 11:37:04 | Stage | Epoch[360/600] Valid loss:0.1752
2023-02-06 11:37:04 | Stage | Epoch[360/600] LR:0.01

2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[001/030] Train loss: 0.0219
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[004/030] Train loss: 0.0216
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[005/030] Train loss: 0.0214
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:37:05 | Train | Epoch[361/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[021/030] Train loss: 0.0209
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[022/030] Train loss: 0.0210
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[023/030] Train loss: 0.0211
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[024/030] Train loss: 0.0210
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[026/030] Train loss: 0.0212
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[027/030] Train loss: 0.0211
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[028/030] Train loss: 0.0210
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[029/030] Train loss: 0.0211
2023-02-06 11:37:06 | Train | Epoch[361/600] Iteration[030/030] Train loss: 0.0210
2023-02-06 11:37:06 | Valid | Epoch[361/600] Iteration[001/008] Valid loss: 0.0970
2023-02-06 11:37:06 | Valid | Epoch[361/600] Iteration[002/008] Valid loss: 0.0968
2023-02-06 11:37:07 | Valid | Epoch[361/600] Iteration[003/008] Valid loss: 0.0999
2023-02-06 11:37:07 | Valid | Epoch[361/600] Iteration[004/008] Valid loss: 0.0976
2023-02-06 11:37:07 | Valid | Epoch[361/600] Iteration[005/008] Valid loss: 0.0991
2023-02-06 11:37:07 | Valid | Epoch[361/600] Iteration[006/008] Valid loss: 0.0973
2023-02-06 11:37:07 | Valid | Epoch[361/600] Iteration[007/008] Valid loss: 0.0946
2023-02-06 11:37:07 | Valid | Epoch[361/600] Iteration[008/008] Valid loss: 0.0984
2023-02-06 11:37:07 | Valid | Epoch[361/600] MIou: 0.6964301666980146
2023-02-06 11:37:07 | Valid | Epoch[361/600] Pixel Accuracy: 0.9498799641927084
2023-02-06 11:37:07 | Valid | Epoch[361/600] Mean Pixel Accuracy: 0.7225422061038594
2023-02-06 11:37:07 | Stage | Epoch[361/600] Train loss:0.0210
2023-02-06 11:37:07 | Stage | Epoch[361/600] Valid loss:0.0984
2023-02-06 11:37:07 | Stage | Epoch[361/600] LR:0.01

2023-02-06 11:37:07 | Train | Epoch[362/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 11:37:07 | Train | Epoch[362/600] Iteration[002/030] Train loss: 0.0203
2023-02-06 11:37:07 | Train | Epoch[362/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 11:37:07 | Train | Epoch[362/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:37:07 | Train | Epoch[362/600] Iteration[005/030] Train loss: 0.0214
2023-02-06 11:37:07 | Train | Epoch[362/600] Iteration[006/030] Train loss: 0.0215
2023-02-06 11:37:07 | Train | Epoch[362/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 11:37:07 | Train | Epoch[362/600] Iteration[008/030] Train loss: 0.0220
2023-02-06 11:37:07 | Train | Epoch[362/600] Iteration[009/030] Train loss: 0.0217
2023-02-06 11:37:07 | Train | Epoch[362/600] Iteration[010/030] Train loss: 0.0216
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[011/030] Train loss: 0.0214
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[012/030] Train loss: 0.0216
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[015/030] Train loss: 0.0210
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[016/030] Train loss: 0.0211
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[018/030] Train loss: 0.0212
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[019/030] Train loss: 0.0212
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[021/030] Train loss: 0.0211
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[024/030] Train loss: 0.0212
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[026/030] Train loss: 0.0213
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[027/030] Train loss: 0.0214
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[029/030] Train loss: 0.0212
2023-02-06 11:37:08 | Train | Epoch[362/600] Iteration[030/030] Train loss: 0.0212
2023-02-06 11:37:09 | Valid | Epoch[362/600] Iteration[001/008] Valid loss: 0.0425
2023-02-06 11:37:09 | Valid | Epoch[362/600] Iteration[002/008] Valid loss: 0.0349
2023-02-06 11:37:09 | Valid | Epoch[362/600] Iteration[003/008] Valid loss: 0.0328
2023-02-06 11:37:09 | Valid | Epoch[362/600] Iteration[004/008] Valid loss: 0.0316
2023-02-06 11:37:09 | Valid | Epoch[362/600] Iteration[005/008] Valid loss: 0.0322
2023-02-06 11:37:09 | Valid | Epoch[362/600] Iteration[006/008] Valid loss: 0.0322
2023-02-06 11:37:09 | Valid | Epoch[362/600] Iteration[007/008] Valid loss: 0.0319
2023-02-06 11:37:09 | Valid | Epoch[362/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 11:37:09 | Valid | Epoch[362/600] MIou: 0.9112814613026559
2023-02-06 11:37:09 | Valid | Epoch[362/600] Pixel Accuracy: 0.9852778116861979
2023-02-06 11:37:09 | Valid | Epoch[362/600] Mean Pixel Accuracy: 0.9227018108622378
2023-02-06 11:37:09 | Stage | Epoch[362/600] Train loss:0.0212
2023-02-06 11:37:09 | Stage | Epoch[362/600] Valid loss:0.0316
2023-02-06 11:37:09 | Stage | Epoch[362/600] LR:0.01

2023-02-06 11:37:09 | Train | Epoch[363/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 11:37:09 | Train | Epoch[363/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 11:37:09 | Train | Epoch[363/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 11:37:09 | Train | Epoch[363/600] Iteration[004/030] Train loss: 0.0226
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[005/030] Train loss: 0.0217
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[007/030] Train loss: 0.0217
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[008/030] Train loss: 0.0216
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[010/030] Train loss: 0.0211
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[011/030] Train loss: 0.0210
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[012/030] Train loss: 0.0212
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[015/030] Train loss: 0.0212
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[016/030] Train loss: 0.0211
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[019/030] Train loss: 0.0212
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[021/030] Train loss: 0.0214
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[022/030] Train loss: 0.0214
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:37:10 | Train | Epoch[363/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:37:11 | Train | Epoch[363/600] Iteration[025/030] Train loss: 0.0215
2023-02-06 11:37:11 | Train | Epoch[363/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 11:37:11 | Train | Epoch[363/600] Iteration[027/030] Train loss: 0.0215
2023-02-06 11:37:11 | Train | Epoch[363/600] Iteration[028/030] Train loss: 0.0214
2023-02-06 11:37:11 | Train | Epoch[363/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:37:11 | Train | Epoch[363/600] Iteration[030/030] Train loss: 0.0213
2023-02-06 11:37:11 | Valid | Epoch[363/600] Iteration[001/008] Valid loss: 0.1081
2023-02-06 11:37:11 | Valid | Epoch[363/600] Iteration[002/008] Valid loss: 0.0737
2023-02-06 11:37:11 | Valid | Epoch[363/600] Iteration[003/008] Valid loss: 0.0645
2023-02-06 11:37:11 | Valid | Epoch[363/600] Iteration[004/008] Valid loss: 0.0623
2023-02-06 11:37:11 | Valid | Epoch[363/600] Iteration[005/008] Valid loss: 0.0659
2023-02-06 11:37:11 | Valid | Epoch[363/600] Iteration[006/008] Valid loss: 0.0652
2023-02-06 11:37:11 | Valid | Epoch[363/600] Iteration[007/008] Valid loss: 0.0672
2023-02-06 11:37:11 | Valid | Epoch[363/600] Iteration[008/008] Valid loss: 0.0671
2023-02-06 11:37:11 | Valid | Epoch[363/600] MIou: 0.9352328483291228
2023-02-06 11:37:11 | Valid | Epoch[363/600] Pixel Accuracy: 0.9887657165527344
2023-02-06 11:37:11 | Valid | Epoch[363/600] Mean Pixel Accuracy: 0.9651662274521814
2023-02-06 11:37:11 | Stage | Epoch[363/600] Train loss:0.0213
2023-02-06 11:37:11 | Stage | Epoch[363/600] Valid loss:0.0671
2023-02-06 11:37:11 | Stage | Epoch[363/600] LR:0.01

2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[001/030] Train loss: 0.0193
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[002/030] Train loss: 0.0210
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[003/030] Train loss: 0.0218
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[004/030] Train loss: 0.0213
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[005/030] Train loss: 0.0222
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[006/030] Train loss: 0.0225
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[008/030] Train loss: 0.0226
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[009/030] Train loss: 0.0223
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[010/030] Train loss: 0.0219
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[011/030] Train loss: 0.0219
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[012/030] Train loss: 0.0219
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[013/030] Train loss: 0.0217
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[014/030] Train loss: 0.0216
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[016/030] Train loss: 0.0214
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[017/030] Train loss: 0.0213
2023-02-06 11:37:12 | Train | Epoch[364/600] Iteration[018/030] Train loss: 0.0213
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[020/030] Train loss: 0.0214
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[021/030] Train loss: 0.0215
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[022/030] Train loss: 0.0214
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[025/030] Train loss: 0.0214
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[026/030] Train loss: 0.0214
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[029/030] Train loss: 0.0217
2023-02-06 11:37:13 | Train | Epoch[364/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:37:13 | Valid | Epoch[364/600] Iteration[001/008] Valid loss: 0.7971
2023-02-06 11:37:13 | Valid | Epoch[364/600] Iteration[002/008] Valid loss: 0.7148
2023-02-06 11:37:13 | Valid | Epoch[364/600] Iteration[003/008] Valid loss: 0.7167
2023-02-06 11:37:13 | Valid | Epoch[364/600] Iteration[004/008] Valid loss: 0.7314
2023-02-06 11:37:13 | Valid | Epoch[364/600] Iteration[005/008] Valid loss: 0.7609
2023-02-06 11:37:13 | Valid | Epoch[364/600] Iteration[006/008] Valid loss: 0.7425
2023-02-06 11:37:14 | Valid | Epoch[364/600] Iteration[007/008] Valid loss: 0.7803
2023-02-06 11:37:14 | Valid | Epoch[364/600] Iteration[008/008] Valid loss: 0.7951
2023-02-06 11:37:14 | Valid | Epoch[364/600] MIou: 0.8694974752995621
2023-02-06 11:37:14 | Valid | Epoch[364/600] Pixel Accuracy: 0.9729881286621094
2023-02-06 11:37:14 | Valid | Epoch[364/600] Mean Pixel Accuracy: 0.9823506350759066
2023-02-06 11:37:14 | Stage | Epoch[364/600] Train loss:0.0217
2023-02-06 11:37:14 | Stage | Epoch[364/600] Valid loss:0.7951
2023-02-06 11:37:14 | Stage | Epoch[364/600] LR:0.01

2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[003/030] Train loss: 0.0189
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[004/030] Train loss: 0.0183
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[006/030] Train loss: 0.0190
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:37:14 | Train | Epoch[365/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[015/030] Train loss: 0.0210
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[016/030] Train loss: 0.0209
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[017/030] Train loss: 0.0210
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[021/030] Train loss: 0.0213
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[022/030] Train loss: 0.0215
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[025/030] Train loss: 0.0216
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[026/030] Train loss: 0.0215
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[027/030] Train loss: 0.0215
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:37:15 | Train | Epoch[365/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:37:16 | Valid | Epoch[365/600] Iteration[001/008] Valid loss: 0.1021
2023-02-06 11:37:16 | Valid | Epoch[365/600] Iteration[002/008] Valid loss: 0.1016
2023-02-06 11:37:16 | Valid | Epoch[365/600] Iteration[003/008] Valid loss: 0.1055
2023-02-06 11:37:16 | Valid | Epoch[365/600] Iteration[004/008] Valid loss: 0.1025
2023-02-06 11:37:16 | Valid | Epoch[365/600] Iteration[005/008] Valid loss: 0.1048
2023-02-06 11:37:16 | Valid | Epoch[365/600] Iteration[006/008] Valid loss: 0.1026
2023-02-06 11:37:16 | Valid | Epoch[365/600] Iteration[007/008] Valid loss: 0.1004
2023-02-06 11:37:16 | Valid | Epoch[365/600] Iteration[008/008] Valid loss: 0.1052
2023-02-06 11:37:16 | Valid | Epoch[365/600] MIou: 0.6393085608030235
2023-02-06 11:37:16 | Valid | Epoch[365/600] Pixel Accuracy: 0.9403966267903646
2023-02-06 11:37:16 | Valid | Epoch[365/600] Mean Pixel Accuracy: 0.6700615442904183
2023-02-06 11:37:16 | Stage | Epoch[365/600] Train loss:0.0216
2023-02-06 11:37:16 | Stage | Epoch[365/600] Valid loss:0.1052
2023-02-06 11:37:16 | Stage | Epoch[365/600] LR:0.01

2023-02-06 11:37:16 | Train | Epoch[366/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 11:37:16 | Train | Epoch[366/600] Iteration[002/030] Train loss: 0.0210
2023-02-06 11:37:16 | Train | Epoch[366/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:37:16 | Train | Epoch[366/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:37:16 | Train | Epoch[366/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:37:16 | Train | Epoch[366/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[007/030] Train loss: 0.0212
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[009/030] Train loss: 0.0209
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[010/030] Train loss: 0.0209
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[012/030] Train loss: 0.0212
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[013/030] Train loss: 0.0213
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[014/030] Train loss: 0.0214
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[017/030] Train loss: 0.0213
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[018/030] Train loss: 0.0212
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[020/030] Train loss: 0.0211
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[023/030] Train loss: 0.0210
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[024/030] Train loss: 0.0210
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[025/030] Train loss: 0.0210
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[026/030] Train loss: 0.0209
2023-02-06 11:37:17 | Train | Epoch[366/600] Iteration[027/030] Train loss: 0.0210
2023-02-06 11:37:18 | Train | Epoch[366/600] Iteration[028/030] Train loss: 0.0211
2023-02-06 11:37:18 | Train | Epoch[366/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 11:37:18 | Train | Epoch[366/600] Iteration[030/030] Train loss: 0.0212
2023-02-06 11:37:18 | Valid | Epoch[366/600] Iteration[001/008] Valid loss: 0.0494
2023-02-06 11:37:18 | Valid | Epoch[366/600] Iteration[002/008] Valid loss: 0.0478
2023-02-06 11:37:18 | Valid | Epoch[366/600] Iteration[003/008] Valid loss: 0.0483
2023-02-06 11:37:18 | Valid | Epoch[366/600] Iteration[004/008] Valid loss: 0.0467
2023-02-06 11:37:18 | Valid | Epoch[366/600] Iteration[005/008] Valid loss: 0.0474
2023-02-06 11:37:18 | Valid | Epoch[366/600] Iteration[006/008] Valid loss: 0.0470
2023-02-06 11:37:18 | Valid | Epoch[366/600] Iteration[007/008] Valid loss: 0.0455
2023-02-06 11:37:18 | Valid | Epoch[366/600] Iteration[008/008] Valid loss: 0.0465
2023-02-06 11:37:18 | Valid | Epoch[366/600] MIou: 0.8372612447686398
2023-02-06 11:37:18 | Valid | Epoch[366/600] Pixel Accuracy: 0.9731775919596354
2023-02-06 11:37:18 | Valid | Epoch[366/600] Mean Pixel Accuracy: 0.8517269305485797
2023-02-06 11:37:18 | Stage | Epoch[366/600] Train loss:0.0212
2023-02-06 11:37:18 | Stage | Epoch[366/600] Valid loss:0.0465
2023-02-06 11:37:18 | Stage | Epoch[366/600] LR:0.01

2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[002/030] Train loss: 0.0212
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[004/030] Train loss: 0.0202
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[006/030] Train loss: 0.0214
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[011/030] Train loss: 0.0212
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[012/030] Train loss: 0.0211
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[013/030] Train loss: 0.0213
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[016/030] Train loss: 0.0210
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[018/030] Train loss: 0.0210
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:37:19 | Train | Epoch[367/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:37:20 | Train | Epoch[367/600] Iteration[021/030] Train loss: 0.0213
2023-02-06 11:37:20 | Train | Epoch[367/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:37:20 | Train | Epoch[367/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:37:20 | Train | Epoch[367/600] Iteration[024/030] Train loss: 0.0210
2023-02-06 11:37:20 | Train | Epoch[367/600] Iteration[025/030] Train loss: 0.0210
2023-02-06 11:37:20 | Train | Epoch[367/600] Iteration[026/030] Train loss: 0.0210
2023-02-06 11:37:20 | Train | Epoch[367/600] Iteration[027/030] Train loss: 0.0210
2023-02-06 11:37:20 | Train | Epoch[367/600] Iteration[028/030] Train loss: 0.0210
2023-02-06 11:37:20 | Train | Epoch[367/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 11:37:20 | Train | Epoch[367/600] Iteration[030/030] Train loss: 0.0209
2023-02-06 11:37:20 | Valid | Epoch[367/600] Iteration[001/008] Valid loss: 0.0394
2023-02-06 11:37:20 | Valid | Epoch[367/600] Iteration[002/008] Valid loss: 0.0354
2023-02-06 11:37:20 | Valid | Epoch[367/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:37:20 | Valid | Epoch[367/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:37:20 | Valid | Epoch[367/600] Iteration[005/008] Valid loss: 0.0339
2023-02-06 11:37:20 | Valid | Epoch[367/600] Iteration[006/008] Valid loss: 0.0336
2023-02-06 11:37:20 | Valid | Epoch[367/600] Iteration[007/008] Valid loss: 0.0330
2023-02-06 11:37:20 | Valid | Epoch[367/600] Iteration[008/008] Valid loss: 0.0332
2023-02-06 11:37:21 | Valid | Epoch[367/600] MIou: 0.8934563871103324
2023-02-06 11:37:21 | Valid | Epoch[367/600] Pixel Accuracy: 0.982397715250651
2023-02-06 11:37:21 | Valid | Epoch[367/600] Mean Pixel Accuracy: 0.9043989636507648
2023-02-06 11:37:21 | Stage | Epoch[367/600] Train loss:0.0209
2023-02-06 11:37:21 | Stage | Epoch[367/600] Valid loss:0.0332
2023-02-06 11:37:21 | Stage | Epoch[367/600] LR:0.01

2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[007/030] Train loss: 0.0204
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[010/030] Train loss: 0.0209
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[012/030] Train loss: 0.0208
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[013/030] Train loss: 0.0207
2023-02-06 11:37:21 | Train | Epoch[368/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[015/030] Train loss: 0.0207
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[018/030] Train loss: 0.0206
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[019/030] Train loss: 0.0209
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[024/030] Train loss: 0.0212
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[025/030] Train loss: 0.0213
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[026/030] Train loss: 0.0212
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[027/030] Train loss: 0.0211
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[028/030] Train loss: 0.0210
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 11:37:22 | Train | Epoch[368/600] Iteration[030/030] Train loss: 0.0211
2023-02-06 11:37:23 | Valid | Epoch[368/600] Iteration[001/008] Valid loss: 0.0542
2023-02-06 11:37:23 | Valid | Epoch[368/600] Iteration[002/008] Valid loss: 0.0430
2023-02-06 11:37:23 | Valid | Epoch[368/600] Iteration[003/008] Valid loss: 0.0398
2023-02-06 11:37:23 | Valid | Epoch[368/600] Iteration[004/008] Valid loss: 0.0385
2023-02-06 11:37:23 | Valid | Epoch[368/600] Iteration[005/008] Valid loss: 0.0390
2023-02-06 11:37:23 | Valid | Epoch[368/600] Iteration[006/008] Valid loss: 0.0376
2023-02-06 11:37:23 | Valid | Epoch[368/600] Iteration[007/008] Valid loss: 0.0379
2023-02-06 11:37:23 | Valid | Epoch[368/600] Iteration[008/008] Valid loss: 0.0374
2023-02-06 11:37:23 | Valid | Epoch[368/600] MIou: 0.9073761833055731
2023-02-06 11:37:23 | Valid | Epoch[368/600] Pixel Accuracy: 0.9846165974934896
2023-02-06 11:37:23 | Valid | Epoch[368/600] Mean Pixel Accuracy: 0.9194407838608016
2023-02-06 11:37:23 | Stage | Epoch[368/600] Train loss:0.0211
2023-02-06 11:37:23 | Stage | Epoch[368/600] Valid loss:0.0374
2023-02-06 11:37:23 | Stage | Epoch[368/600] LR:0.01

2023-02-06 11:37:23 | Train | Epoch[369/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 11:37:23 | Train | Epoch[369/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 11:37:23 | Train | Epoch[369/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:37:23 | Train | Epoch[369/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:37:23 | Train | Epoch[369/600] Iteration[005/030] Train loss: 0.0212
2023-02-06 11:37:23 | Train | Epoch[369/600] Iteration[006/030] Train loss: 0.0209
2023-02-06 11:37:23 | Train | Epoch[369/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:37:23 | Train | Epoch[369/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[019/030] Train loss: 0.0207
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[020/030] Train loss: 0.0207
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[021/030] Train loss: 0.0208
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[022/030] Train loss: 0.0210
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[023/030] Train loss: 0.0210
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[024/030] Train loss: 0.0212
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[025/030] Train loss: 0.0213
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[026/030] Train loss: 0.0213
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[027/030] Train loss: 0.0213
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:37:24 | Train | Epoch[369/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:37:25 | Train | Epoch[369/600] Iteration[030/030] Train loss: 0.0212
2023-02-06 11:37:25 | Valid | Epoch[369/600] Iteration[001/008] Valid loss: 0.4072
2023-02-06 11:37:25 | Valid | Epoch[369/600] Iteration[002/008] Valid loss: 0.3313
2023-02-06 11:37:25 | Valid | Epoch[369/600] Iteration[003/008] Valid loss: 0.3158
2023-02-06 11:37:25 | Valid | Epoch[369/600] Iteration[004/008] Valid loss: 0.3192
2023-02-06 11:37:25 | Valid | Epoch[369/600] Iteration[005/008] Valid loss: 0.3339
2023-02-06 11:37:25 | Valid | Epoch[369/600] Iteration[006/008] Valid loss: 0.3246
2023-02-06 11:37:25 | Valid | Epoch[369/600] Iteration[007/008] Valid loss: 0.3527
2023-02-06 11:37:25 | Valid | Epoch[369/600] Iteration[008/008] Valid loss: 0.3499
2023-02-06 11:37:25 | Valid | Epoch[369/600] MIou: 0.9009270559238232
2023-02-06 11:37:25 | Valid | Epoch[369/600] Pixel Accuracy: 0.9808184305826823
2023-02-06 11:37:25 | Valid | Epoch[369/600] Mean Pixel Accuracy: 0.9835603528678585
2023-02-06 11:37:25 | Stage | Epoch[369/600] Train loss:0.0212
2023-02-06 11:37:25 | Stage | Epoch[369/600] Valid loss:0.3499
2023-02-06 11:37:25 | Stage | Epoch[369/600] LR:0.01

2023-02-06 11:37:25 | Train | Epoch[370/600] Iteration[001/030] Train loss: 0.0219
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[002/030] Train loss: 0.0213
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[004/030] Train loss: 0.0211
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[008/030] Train loss: 0.0217
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[010/030] Train loss: 0.0216
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[011/030] Train loss: 0.0217
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[012/030] Train loss: 0.0216
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[013/030] Train loss: 0.0216
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[014/030] Train loss: 0.0216
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[017/030] Train loss: 0.0214
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[018/030] Train loss: 0.0212
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[020/030] Train loss: 0.0216
2023-02-06 11:37:26 | Train | Epoch[370/600] Iteration[021/030] Train loss: 0.0216
2023-02-06 11:37:27 | Train | Epoch[370/600] Iteration[022/030] Train loss: 0.0216
2023-02-06 11:37:27 | Train | Epoch[370/600] Iteration[023/030] Train loss: 0.0217
2023-02-06 11:37:27 | Train | Epoch[370/600] Iteration[024/030] Train loss: 0.0216
2023-02-06 11:37:27 | Train | Epoch[370/600] Iteration[025/030] Train loss: 0.0217
2023-02-06 11:37:27 | Train | Epoch[370/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:37:27 | Train | Epoch[370/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:37:27 | Train | Epoch[370/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:37:27 | Train | Epoch[370/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 11:37:27 | Train | Epoch[370/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:37:27 | Valid | Epoch[370/600] Iteration[001/008] Valid loss: 0.0690
2023-02-06 11:37:27 | Valid | Epoch[370/600] Iteration[002/008] Valid loss: 0.0490
2023-02-06 11:37:27 | Valid | Epoch[370/600] Iteration[003/008] Valid loss: 0.0426
2023-02-06 11:37:27 | Valid | Epoch[370/600] Iteration[004/008] Valid loss: 0.0392
2023-02-06 11:37:27 | Valid | Epoch[370/600] Iteration[005/008] Valid loss: 0.0428
2023-02-06 11:37:27 | Valid | Epoch[370/600] Iteration[006/008] Valid loss: 0.0422
2023-02-06 11:37:27 | Valid | Epoch[370/600] Iteration[007/008] Valid loss: 0.0424
2023-02-06 11:37:27 | Valid | Epoch[370/600] Iteration[008/008] Valid loss: 0.0419
2023-02-06 11:37:28 | Valid | Epoch[370/600] MIou: 0.9274597320800071
2023-02-06 11:37:28 | Valid | Epoch[370/600] Pixel Accuracy: 0.9877230326334635
2023-02-06 11:37:28 | Valid | Epoch[370/600] Mean Pixel Accuracy: 0.9464213325471358
2023-02-06 11:37:28 | Stage | Epoch[370/600] Train loss:0.0216
2023-02-06 11:37:28 | Stage | Epoch[370/600] Valid loss:0.0419
2023-02-06 11:37:28 | Stage | Epoch[370/600] LR:0.01

2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[002/030] Train loss: 0.0218
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[003/030] Train loss: 0.0208
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[006/030] Train loss: 0.0207
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[011/030] Train loss: 0.0208
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[012/030] Train loss: 0.0211
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[013/030] Train loss: 0.0213
2023-02-06 11:37:28 | Train | Epoch[371/600] Iteration[014/030] Train loss: 0.0215
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[015/030] Train loss: 0.0213
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[016/030] Train loss: 0.0213
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[017/030] Train loss: 0.0213
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[018/030] Train loss: 0.0215
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[019/030] Train loss: 0.0216
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[021/030] Train loss: 0.0215
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[022/030] Train loss: 0.0215
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[025/030] Train loss: 0.0214
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[026/030] Train loss: 0.0214
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[027/030] Train loss: 0.0215
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[028/030] Train loss: 0.0214
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:37:29 | Train | Epoch[371/600] Iteration[030/030] Train loss: 0.0215
2023-02-06 11:37:30 | Valid | Epoch[371/600] Iteration[001/008] Valid loss: 0.0485
2023-02-06 11:37:30 | Valid | Epoch[371/600] Iteration[002/008] Valid loss: 0.0471
2023-02-06 11:37:30 | Valid | Epoch[371/600] Iteration[003/008] Valid loss: 0.0473
2023-02-06 11:37:30 | Valid | Epoch[371/600] Iteration[004/008] Valid loss: 0.0456
2023-02-06 11:37:30 | Valid | Epoch[371/600] Iteration[005/008] Valid loss: 0.0462
2023-02-06 11:37:30 | Valid | Epoch[371/600] Iteration[006/008] Valid loss: 0.0457
2023-02-06 11:37:30 | Valid | Epoch[371/600] Iteration[007/008] Valid loss: 0.0441
2023-02-06 11:37:30 | Valid | Epoch[371/600] Iteration[008/008] Valid loss: 0.0453
2023-02-06 11:37:30 | Valid | Epoch[371/600] MIou: 0.8416037971797766
2023-02-06 11:37:30 | Valid | Epoch[371/600] Pixel Accuracy: 0.9738947550455729
2023-02-06 11:37:30 | Valid | Epoch[371/600] Mean Pixel Accuracy: 0.8557034803712019
2023-02-06 11:37:30 | Stage | Epoch[371/600] Train loss:0.0215
2023-02-06 11:37:30 | Stage | Epoch[371/600] Valid loss:0.0453
2023-02-06 11:37:30 | Stage | Epoch[371/600] LR:0.01

2023-02-06 11:37:30 | Train | Epoch[372/600] Iteration[001/030] Train loss: 0.0249
2023-02-06 11:37:30 | Train | Epoch[372/600] Iteration[002/030] Train loss: 0.0221
2023-02-06 11:37:30 | Train | Epoch[372/600] Iteration[003/030] Train loss: 0.0216
2023-02-06 11:37:30 | Train | Epoch[372/600] Iteration[004/030] Train loss: 0.0220
2023-02-06 11:37:30 | Train | Epoch[372/600] Iteration[005/030] Train loss: 0.0223
2023-02-06 11:37:30 | Train | Epoch[372/600] Iteration[006/030] Train loss: 0.0224
2023-02-06 11:37:30 | Train | Epoch[372/600] Iteration[007/030] Train loss: 0.0222
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[008/030] Train loss: 0.0219
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[009/030] Train loss: 0.0223
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[010/030] Train loss: 0.0222
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[011/030] Train loss: 0.0222
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[012/030] Train loss: 0.0222
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[013/030] Train loss: 0.0226
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[014/030] Train loss: 0.0224
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[015/030] Train loss: 0.0223
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[016/030] Train loss: 0.0223
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[017/030] Train loss: 0.0223
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[018/030] Train loss: 0.0224
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[019/030] Train loss: 0.0223
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[020/030] Train loss: 0.0222
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[021/030] Train loss: 0.0224
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[022/030] Train loss: 0.0223
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[023/030] Train loss: 0.0223
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[024/030] Train loss: 0.0222
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[025/030] Train loss: 0.0222
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[026/030] Train loss: 0.0221
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[027/030] Train loss: 0.0221
2023-02-06 11:37:31 | Train | Epoch[372/600] Iteration[028/030] Train loss: 0.0220
2023-02-06 11:37:32 | Train | Epoch[372/600] Iteration[029/030] Train loss: 0.0220
2023-02-06 11:37:32 | Train | Epoch[372/600] Iteration[030/030] Train loss: 0.0220
2023-02-06 11:37:32 | Valid | Epoch[372/600] Iteration[001/008] Valid loss: 0.1133
2023-02-06 11:37:32 | Valid | Epoch[372/600] Iteration[002/008] Valid loss: 0.1093
2023-02-06 11:37:32 | Valid | Epoch[372/600] Iteration[003/008] Valid loss: 0.1112
2023-02-06 11:37:32 | Valid | Epoch[372/600] Iteration[004/008] Valid loss: 0.1089
2023-02-06 11:37:32 | Valid | Epoch[372/600] Iteration[005/008] Valid loss: 0.1100
2023-02-06 11:37:32 | Valid | Epoch[372/600] Iteration[006/008] Valid loss: 0.1082
2023-02-06 11:37:32 | Valid | Epoch[372/600] Iteration[007/008] Valid loss: 0.1056
2023-02-06 11:37:32 | Valid | Epoch[372/600] Iteration[008/008] Valid loss: 0.1089
2023-02-06 11:37:32 | Valid | Epoch[372/600] MIou: 0.694747218459938
2023-02-06 11:37:32 | Valid | Epoch[372/600] Pixel Accuracy: 0.9496014912923177
2023-02-06 11:37:32 | Valid | Epoch[372/600] Mean Pixel Accuracy: 0.7209942417885652
2023-02-06 11:37:32 | Stage | Epoch[372/600] Train loss:0.0220
2023-02-06 11:37:32 | Stage | Epoch[372/600] Valid loss:0.1089
2023-02-06 11:37:32 | Stage | Epoch[372/600] LR:0.01

2023-02-06 11:37:32 | Train | Epoch[373/600] Iteration[001/030] Train loss: 0.0183
2023-02-06 11:37:32 | Train | Epoch[373/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[012/030] Train loss: 0.0216
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[013/030] Train loss: 0.0217
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[015/030] Train loss: 0.0220
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[016/030] Train loss: 0.0222
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[017/030] Train loss: 0.0221
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[019/030] Train loss: 0.0219
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[020/030] Train loss: 0.0220
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 11:37:33 | Train | Epoch[373/600] Iteration[022/030] Train loss: 0.0219
2023-02-06 11:37:34 | Train | Epoch[373/600] Iteration[023/030] Train loss: 0.0218
2023-02-06 11:37:34 | Train | Epoch[373/600] Iteration[024/030] Train loss: 0.0217
2023-02-06 11:37:34 | Train | Epoch[373/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:37:34 | Train | Epoch[373/600] Iteration[026/030] Train loss: 0.0220
2023-02-06 11:37:34 | Train | Epoch[373/600] Iteration[027/030] Train loss: 0.0220
2023-02-06 11:37:34 | Train | Epoch[373/600] Iteration[028/030] Train loss: 0.0220
2023-02-06 11:37:34 | Train | Epoch[373/600] Iteration[029/030] Train loss: 0.0220
2023-02-06 11:37:34 | Train | Epoch[373/600] Iteration[030/030] Train loss: 0.0219
2023-02-06 11:37:34 | Valid | Epoch[373/600] Iteration[001/008] Valid loss: 0.3531
2023-02-06 11:37:34 | Valid | Epoch[373/600] Iteration[002/008] Valid loss: 0.2598
2023-02-06 11:37:34 | Valid | Epoch[373/600] Iteration[003/008] Valid loss: 0.2434
2023-02-06 11:37:34 | Valid | Epoch[373/600] Iteration[004/008] Valid loss: 0.2381
2023-02-06 11:37:34 | Valid | Epoch[373/600] Iteration[005/008] Valid loss: 0.2512
2023-02-06 11:37:34 | Valid | Epoch[373/600] Iteration[006/008] Valid loss: 0.2467
2023-02-06 11:37:34 | Valid | Epoch[373/600] Iteration[007/008] Valid loss: 0.2638
2023-02-06 11:37:34 | Valid | Epoch[373/600] Iteration[008/008] Valid loss: 0.2647
2023-02-06 11:37:34 | Valid | Epoch[373/600] MIou: 0.9149372161385332
2023-02-06 11:37:34 | Valid | Epoch[373/600] Pixel Accuracy: 0.9840469360351562
2023-02-06 11:37:34 | Valid | Epoch[373/600] Mean Pixel Accuracy: 0.9825323887486261
2023-02-06 11:37:34 | Stage | Epoch[373/600] Train loss:0.0219
2023-02-06 11:37:34 | Stage | Epoch[373/600] Valid loss:0.2647
2023-02-06 11:37:34 | Stage | Epoch[373/600] LR:0.01

2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[001/030] Train loss: 0.0226
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[002/030] Train loss: 0.0219
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[004/030] Train loss: 0.0213
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[010/030] Train loss: 0.0211
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[011/030] Train loss: 0.0212
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[013/030] Train loss: 0.0210
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[015/030] Train loss: 0.0214
2023-02-06 11:37:35 | Train | Epoch[374/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[018/030] Train loss: 0.0215
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[021/030] Train loss: 0.0211
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[022/030] Train loss: 0.0210
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[024/030] Train loss: 0.0212
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[026/030] Train loss: 0.0214
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[027/030] Train loss: 0.0215
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[028/030] Train loss: 0.0215
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[029/030] Train loss: 0.0217
2023-02-06 11:37:36 | Train | Epoch[374/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:37:37 | Valid | Epoch[374/600] Iteration[001/008] Valid loss: 0.4742
2023-02-06 11:37:37 | Valid | Epoch[374/600] Iteration[002/008] Valid loss: 0.4231
2023-02-06 11:37:37 | Valid | Epoch[374/600] Iteration[003/008] Valid loss: 0.4109
2023-02-06 11:37:37 | Valid | Epoch[374/600] Iteration[004/008] Valid loss: 0.4157
2023-02-06 11:37:37 | Valid | Epoch[374/600] Iteration[005/008] Valid loss: 0.4312
2023-02-06 11:37:37 | Valid | Epoch[374/600] Iteration[006/008] Valid loss: 0.4271
2023-02-06 11:37:37 | Valid | Epoch[374/600] Iteration[007/008] Valid loss: 0.4591
2023-02-06 11:37:37 | Valid | Epoch[374/600] Iteration[008/008] Valid loss: 0.4561
2023-02-06 11:37:37 | Valid | Epoch[374/600] MIou: 0.8930079019856589
2023-02-06 11:37:37 | Valid | Epoch[374/600] Pixel Accuracy: 0.9788729349772135
2023-02-06 11:37:37 | Valid | Epoch[374/600] Mean Pixel Accuracy: 0.9848813832697662
2023-02-06 11:37:37 | Stage | Epoch[374/600] Train loss:0.0217
2023-02-06 11:37:37 | Stage | Epoch[374/600] Valid loss:0.4561
2023-02-06 11:37:37 | Stage | Epoch[374/600] LR:0.01

2023-02-06 11:37:37 | Train | Epoch[375/600] Iteration[001/030] Train loss: 0.0183
2023-02-06 11:37:37 | Train | Epoch[375/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:37:37 | Train | Epoch[375/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:37:37 | Train | Epoch[375/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:37:37 | Train | Epoch[375/600] Iteration[005/030] Train loss: 0.0212
2023-02-06 11:37:37 | Train | Epoch[375/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:37:37 | Train | Epoch[375/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:37:37 | Train | Epoch[375/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 11:37:37 | Train | Epoch[375/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:37:37 | Train | Epoch[375/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[012/030] Train loss: 0.0206
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[013/030] Train loss: 0.0207
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[014/030] Train loss: 0.0208
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[016/030] Train loss: 0.0210
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[017/030] Train loss: 0.0210
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[023/030] Train loss: 0.0210
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[024/030] Train loss: 0.0211
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[026/030] Train loss: 0.0211
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[027/030] Train loss: 0.0212
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[028/030] Train loss: 0.0213
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:37:38 | Train | Epoch[375/600] Iteration[030/030] Train loss: 0.0212
2023-02-06 11:37:39 | Valid | Epoch[375/600] Iteration[001/008] Valid loss: 0.1052
2023-02-06 11:37:39 | Valid | Epoch[375/600] Iteration[002/008] Valid loss: 0.1043
2023-02-06 11:37:39 | Valid | Epoch[375/600] Iteration[003/008] Valid loss: 0.1077
2023-02-06 11:37:39 | Valid | Epoch[375/600] Iteration[004/008] Valid loss: 0.1056
2023-02-06 11:37:39 | Valid | Epoch[375/600] Iteration[005/008] Valid loss: 0.1072
2023-02-06 11:37:39 | Valid | Epoch[375/600] Iteration[006/008] Valid loss: 0.1052
2023-02-06 11:37:39 | Valid | Epoch[375/600] Iteration[007/008] Valid loss: 0.1024
2023-02-06 11:37:39 | Valid | Epoch[375/600] Iteration[008/008] Valid loss: 0.1063
2023-02-06 11:37:39 | Valid | Epoch[375/600] MIou: 0.6822141614441171
2023-02-06 11:37:39 | Valid | Epoch[375/600] Pixel Accuracy: 0.9475224812825521
2023-02-06 11:37:39 | Valid | Epoch[375/600] Mean Pixel Accuracy: 0.7094848582973152
2023-02-06 11:37:39 | Stage | Epoch[375/600] Train loss:0.0212
2023-02-06 11:37:39 | Stage | Epoch[375/600] Valid loss:0.1063
2023-02-06 11:37:39 | Stage | Epoch[375/600] LR:0.01

2023-02-06 11:37:39 | Train | Epoch[376/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 11:37:39 | Train | Epoch[376/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:37:39 | Train | Epoch[376/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:37:39 | Train | Epoch[376/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[005/030] Train loss: 0.0217
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[006/030] Train loss: 0.0220
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[007/030] Train loss: 0.0219
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[008/030] Train loss: 0.0217
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[009/030] Train loss: 0.0217
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[010/030] Train loss: 0.0215
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[011/030] Train loss: 0.0214
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[012/030] Train loss: 0.0215
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[015/030] Train loss: 0.0213
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[018/030] Train loss: 0.0216
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[019/030] Train loss: 0.0215
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[020/030] Train loss: 0.0217
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[021/030] Train loss: 0.0217
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[022/030] Train loss: 0.0218
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[023/030] Train loss: 0.0217
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:37:40 | Train | Epoch[376/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:37:41 | Train | Epoch[376/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 11:37:41 | Train | Epoch[376/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:37:41 | Train | Epoch[376/600] Iteration[028/030] Train loss: 0.0216
2023-02-06 11:37:41 | Train | Epoch[376/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:37:41 | Train | Epoch[376/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 11:37:41 | Valid | Epoch[376/600] Iteration[001/008] Valid loss: 0.0837
2023-02-06 11:37:41 | Valid | Epoch[376/600] Iteration[002/008] Valid loss: 0.0582
2023-02-06 11:37:41 | Valid | Epoch[376/600] Iteration[003/008] Valid loss: 0.0496
2023-02-06 11:37:41 | Valid | Epoch[376/600] Iteration[004/008] Valid loss: 0.0516
2023-02-06 11:37:41 | Valid | Epoch[376/600] Iteration[005/008] Valid loss: 0.0550
2023-02-06 11:37:41 | Valid | Epoch[376/600] Iteration[006/008] Valid loss: 0.0524
2023-02-06 11:37:41 | Valid | Epoch[376/600] Iteration[007/008] Valid loss: 0.0550
2023-02-06 11:37:41 | Valid | Epoch[376/600] Iteration[008/008] Valid loss: 0.0523
2023-02-06 11:37:41 | Valid | Epoch[376/600] MIou: 0.9391584117218692
2023-02-06 11:37:41 | Valid | Epoch[376/600] Pixel Accuracy: 0.9896672566731771
2023-02-06 11:37:41 | Valid | Epoch[376/600] Mean Pixel Accuracy: 0.959080342922594
2023-02-06 11:37:41 | Stage | Epoch[376/600] Train loss:0.0214
2023-02-06 11:37:41 | Stage | Epoch[376/600] Valid loss:0.0523
2023-02-06 11:37:41 | Stage | Epoch[376/600] LR:0.01

2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[002/030] Train loss: 0.0219
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[004/030] Train loss: 0.0222
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[005/030] Train loss: 0.0216
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[006/030] Train loss: 0.0215
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[007/030] Train loss: 0.0216
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[008/030] Train loss: 0.0214
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[009/030] Train loss: 0.0217
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[010/030] Train loss: 0.0215
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[012/030] Train loss: 0.0212
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[015/030] Train loss: 0.0212
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[016/030] Train loss: 0.0210
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[018/030] Train loss: 0.0213
2023-02-06 11:37:42 | Train | Epoch[377/600] Iteration[019/030] Train loss: 0.0214
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[024/030] Train loss: 0.0214
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[025/030] Train loss: 0.0215
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[026/030] Train loss: 0.0215
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[027/030] Train loss: 0.0215
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[028/030] Train loss: 0.0215
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[029/030] Train loss: 0.0216
2023-02-06 11:37:43 | Train | Epoch[377/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:37:43 | Valid | Epoch[377/600] Iteration[001/008] Valid loss: 0.1188
2023-02-06 11:37:43 | Valid | Epoch[377/600] Iteration[002/008] Valid loss: 0.0785
2023-02-06 11:37:43 | Valid | Epoch[377/600] Iteration[003/008] Valid loss: 0.0695
2023-02-06 11:37:43 | Valid | Epoch[377/600] Iteration[004/008] Valid loss: 0.0712
2023-02-06 11:37:43 | Valid | Epoch[377/600] Iteration[005/008] Valid loss: 0.0751
2023-02-06 11:37:43 | Valid | Epoch[377/600] Iteration[006/008] Valid loss: 0.0743
2023-02-06 11:37:44 | Valid | Epoch[377/600] Iteration[007/008] Valid loss: 0.0807
2023-02-06 11:37:44 | Valid | Epoch[377/600] Iteration[008/008] Valid loss: 0.0773
2023-02-06 11:37:44 | Valid | Epoch[377/600] MIou: 0.9369277117684562
2023-02-06 11:37:44 | Valid | Epoch[377/600] Pixel Accuracy: 0.9890454610188802
2023-02-06 11:37:44 | Valid | Epoch[377/600] Mean Pixel Accuracy: 0.9674250234835986
2023-02-06 11:37:44 | Stage | Epoch[377/600] Train loss:0.0217
2023-02-06 11:37:44 | Stage | Epoch[377/600] Valid loss:0.0773
2023-02-06 11:37:44 | Stage | Epoch[377/600] LR:0.01

2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[006/030] Train loss: 0.0216
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[007/030] Train loss: 0.0214
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[008/030] Train loss: 0.0213
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[009/030] Train loss: 0.0213
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[010/030] Train loss: 0.0214
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[012/030] Train loss: 0.0215
2023-02-06 11:37:44 | Train | Epoch[378/600] Iteration[013/030] Train loss: 0.0218
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[015/030] Train loss: 0.0218
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[017/030] Train loss: 0.0216
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[018/030] Train loss: 0.0218
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[019/030] Train loss: 0.0218
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[020/030] Train loss: 0.0218
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[021/030] Train loss: 0.0218
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[022/030] Train loss: 0.0219
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[025/030] Train loss: 0.0217
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[026/030] Train loss: 0.0217
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[028/030] Train loss: 0.0218
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[029/030] Train loss: 0.0218
2023-02-06 11:37:45 | Train | Epoch[378/600] Iteration[030/030] Train loss: 0.0217
2023-02-06 11:37:46 | Valid | Epoch[378/600] Iteration[001/008] Valid loss: 0.0863
2023-02-06 11:37:46 | Valid | Epoch[378/600] Iteration[002/008] Valid loss: 0.0587
2023-02-06 11:37:46 | Valid | Epoch[378/600] Iteration[003/008] Valid loss: 0.0514
2023-02-06 11:37:46 | Valid | Epoch[378/600] Iteration[004/008] Valid loss: 0.0499
2023-02-06 11:37:46 | Valid | Epoch[378/600] Iteration[005/008] Valid loss: 0.0526
2023-02-06 11:37:46 | Valid | Epoch[378/600] Iteration[006/008] Valid loss: 0.0533
2023-02-06 11:37:46 | Valid | Epoch[378/600] Iteration[007/008] Valid loss: 0.0555
2023-02-06 11:37:46 | Valid | Epoch[378/600] Iteration[008/008] Valid loss: 0.0533
2023-02-06 11:37:46 | Valid | Epoch[378/600] MIou: 0.9390659322494287
2023-02-06 11:37:46 | Valid | Epoch[378/600] Pixel Accuracy: 0.9895528157552084
2023-02-06 11:37:46 | Valid | Epoch[378/600] Mean Pixel Accuracy: 0.9634050475996506
2023-02-06 11:37:46 | Stage | Epoch[378/600] Train loss:0.0217
2023-02-06 11:37:46 | Stage | Epoch[378/600] Valid loss:0.0533
2023-02-06 11:37:46 | Stage | Epoch[378/600] LR:0.01

2023-02-06 11:37:46 | Train | Epoch[379/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 11:37:46 | Train | Epoch[379/600] Iteration[002/030] Train loss: 0.0190
2023-02-06 11:37:46 | Train | Epoch[379/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:37:46 | Train | Epoch[379/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:37:46 | Train | Epoch[379/600] Iteration[005/030] Train loss: 0.0210
2023-02-06 11:37:46 | Train | Epoch[379/600] Iteration[006/030] Train loss: 0.0207
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[013/030] Train loss: 0.0207
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[016/030] Train loss: 0.0208
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[018/030] Train loss: 0.0210
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[019/030] Train loss: 0.0210
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[021/030] Train loss: 0.0210
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[023/030] Train loss: 0.0211
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[024/030] Train loss: 0.0210
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[025/030] Train loss: 0.0209
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[026/030] Train loss: 0.0209
2023-02-06 11:37:47 | Train | Epoch[379/600] Iteration[027/030] Train loss: 0.0208
2023-02-06 11:37:48 | Train | Epoch[379/600] Iteration[028/030] Train loss: 0.0207
2023-02-06 11:37:48 | Train | Epoch[379/600] Iteration[029/030] Train loss: 0.0207
2023-02-06 11:37:48 | Train | Epoch[379/600] Iteration[030/030] Train loss: 0.0209
2023-02-06 11:37:48 | Valid | Epoch[379/600] Iteration[001/008] Valid loss: 0.0436
2023-02-06 11:37:48 | Valid | Epoch[379/600] Iteration[002/008] Valid loss: 0.0380
2023-02-06 11:37:48 | Valid | Epoch[379/600] Iteration[003/008] Valid loss: 0.0365
2023-02-06 11:37:48 | Valid | Epoch[379/600] Iteration[004/008] Valid loss: 0.0351
2023-02-06 11:37:48 | Valid | Epoch[379/600] Iteration[005/008] Valid loss: 0.0362
2023-02-06 11:37:48 | Valid | Epoch[379/600] Iteration[006/008] Valid loss: 0.0356
2023-02-06 11:37:48 | Valid | Epoch[379/600] Iteration[007/008] Valid loss: 0.0348
2023-02-06 11:37:48 | Valid | Epoch[379/600] Iteration[008/008] Valid loss: 0.0352
2023-02-06 11:37:48 | Valid | Epoch[379/600] MIou: 0.8865700401548005
2023-02-06 11:37:48 | Valid | Epoch[379/600] Pixel Accuracy: 0.9811909993489584
2023-02-06 11:37:48 | Valid | Epoch[379/600] Mean Pixel Accuracy: 0.8995066066274489
2023-02-06 11:37:48 | Stage | Epoch[379/600] Train loss:0.0209
2023-02-06 11:37:48 | Stage | Epoch[379/600] Valid loss:0.0352
2023-02-06 11:37:48 | Stage | Epoch[379/600] LR:0.01

2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[001/030] Train loss: 0.0207
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[002/030] Train loss: 0.0218
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[003/030] Train loss: 0.0208
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[018/030] Train loss: 0.0209
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[019/030] Train loss: 0.0209
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[020/030] Train loss: 0.0209
2023-02-06 11:37:49 | Train | Epoch[380/600] Iteration[021/030] Train loss: 0.0209
2023-02-06 11:37:50 | Train | Epoch[380/600] Iteration[022/030] Train loss: 0.0209
2023-02-06 11:37:50 | Train | Epoch[380/600] Iteration[023/030] Train loss: 0.0209
2023-02-06 11:37:50 | Train | Epoch[380/600] Iteration[024/030] Train loss: 0.0208
2023-02-06 11:37:50 | Train | Epoch[380/600] Iteration[025/030] Train loss: 0.0208
2023-02-06 11:37:50 | Train | Epoch[380/600] Iteration[026/030] Train loss: 0.0208
2023-02-06 11:37:50 | Train | Epoch[380/600] Iteration[027/030] Train loss: 0.0209
2023-02-06 11:37:50 | Train | Epoch[380/600] Iteration[028/030] Train loss: 0.0208
2023-02-06 11:37:50 | Train | Epoch[380/600] Iteration[029/030] Train loss: 0.0209
2023-02-06 11:37:50 | Train | Epoch[380/600] Iteration[030/030] Train loss: 0.0210
2023-02-06 11:37:50 | Valid | Epoch[380/600] Iteration[001/008] Valid loss: 0.0725
2023-02-06 11:37:50 | Valid | Epoch[380/600] Iteration[002/008] Valid loss: 0.0719
2023-02-06 11:37:50 | Valid | Epoch[380/600] Iteration[003/008] Valid loss: 0.0723
2023-02-06 11:37:50 | Valid | Epoch[380/600] Iteration[004/008] Valid loss: 0.0699
2023-02-06 11:37:50 | Valid | Epoch[380/600] Iteration[005/008] Valid loss: 0.0709
2023-02-06 11:37:50 | Valid | Epoch[380/600] Iteration[006/008] Valid loss: 0.0692
2023-02-06 11:37:50 | Valid | Epoch[380/600] Iteration[007/008] Valid loss: 0.0672
2023-02-06 11:37:50 | Valid | Epoch[380/600] Iteration[008/008] Valid loss: 0.0696
2023-02-06 11:37:51 | Valid | Epoch[380/600] MIou: 0.7601799816927266
2023-02-06 11:37:51 | Valid | Epoch[380/600] Pixel Accuracy: 0.9603894551595052
2023-02-06 11:37:51 | Valid | Epoch[380/600] Mean Pixel Accuracy: 0.78139475758578
2023-02-06 11:37:51 | Stage | Epoch[380/600] Train loss:0.0210
2023-02-06 11:37:51 | Stage | Epoch[380/600] Valid loss:0.0696
2023-02-06 11:37:51 | Stage | Epoch[380/600] LR:0.01

2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[001/030] Train loss: 0.0201
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[002/030] Train loss: 0.0220
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[006/030] Train loss: 0.0214
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[007/030] Train loss: 0.0213
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[010/030] Train loss: 0.0214
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[012/030] Train loss: 0.0215
2023-02-06 11:37:51 | Train | Epoch[381/600] Iteration[013/030] Train loss: 0.0213
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[014/030] Train loss: 0.0212
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[015/030] Train loss: 0.0211
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[016/030] Train loss: 0.0211
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[017/030] Train loss: 0.0213
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[018/030] Train loss: 0.0214
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[021/030] Train loss: 0.0213
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[025/030] Train loss: 0.0216
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[026/030] Train loss: 0.0215
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[028/030] Train loss: 0.0215
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 11:37:52 | Train | Epoch[381/600] Iteration[030/030] Train loss: 0.0213
2023-02-06 11:37:53 | Valid | Epoch[381/600] Iteration[001/008] Valid loss: 0.0406
2023-02-06 11:37:53 | Valid | Epoch[381/600] Iteration[002/008] Valid loss: 0.0346
2023-02-06 11:37:53 | Valid | Epoch[381/600] Iteration[003/008] Valid loss: 0.0334
2023-02-06 11:37:53 | Valid | Epoch[381/600] Iteration[004/008] Valid loss: 0.0318
2023-02-06 11:37:53 | Valid | Epoch[381/600] Iteration[005/008] Valid loss: 0.0332
2023-02-06 11:37:53 | Valid | Epoch[381/600] Iteration[006/008] Valid loss: 0.0328
2023-02-06 11:37:53 | Valid | Epoch[381/600] Iteration[007/008] Valid loss: 0.0321
2023-02-06 11:37:53 | Valid | Epoch[381/600] Iteration[008/008] Valid loss: 0.0321
2023-02-06 11:37:53 | Valid | Epoch[381/600] MIou: 0.905941239009853
2023-02-06 11:37:53 | Valid | Epoch[381/600] Pixel Accuracy: 0.9843826293945312
2023-02-06 11:37:53 | Valid | Epoch[381/600] Mean Pixel Accuracy: 0.9179933669406035
2023-02-06 11:37:53 | Stage | Epoch[381/600] Train loss:0.0213
2023-02-06 11:37:53 | Stage | Epoch[381/600] Valid loss:0.0321
2023-02-06 11:37:53 | Stage | Epoch[381/600] LR:0.01

2023-02-06 11:37:53 | Train | Epoch[382/600] Iteration[001/030] Train loss: 0.0192
2023-02-06 11:37:53 | Train | Epoch[382/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:37:53 | Train | Epoch[382/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:37:53 | Train | Epoch[382/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:37:53 | Train | Epoch[382/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 11:37:53 | Train | Epoch[382/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[016/030] Train loss: 0.0204
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[022/030] Train loss: 0.0207
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[023/030] Train loss: 0.0206
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[025/030] Train loss: 0.0207
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[026/030] Train loss: 0.0209
2023-02-06 11:37:54 | Train | Epoch[382/600] Iteration[027/030] Train loss: 0.0208
2023-02-06 11:37:55 | Train | Epoch[382/600] Iteration[028/030] Train loss: 0.0208
2023-02-06 11:37:55 | Train | Epoch[382/600] Iteration[029/030] Train loss: 0.0208
2023-02-06 11:37:55 | Train | Epoch[382/600] Iteration[030/030] Train loss: 0.0209
2023-02-06 11:37:55 | Valid | Epoch[382/600] Iteration[001/008] Valid loss: 0.1537
2023-02-06 11:37:55 | Valid | Epoch[382/600] Iteration[002/008] Valid loss: 0.0982
2023-02-06 11:37:55 | Valid | Epoch[382/600] Iteration[003/008] Valid loss: 0.0855
2023-02-06 11:37:55 | Valid | Epoch[382/600] Iteration[004/008] Valid loss: 0.0820
2023-02-06 11:37:55 | Valid | Epoch[382/600] Iteration[005/008] Valid loss: 0.0919
2023-02-06 11:37:55 | Valid | Epoch[382/600] Iteration[006/008] Valid loss: 0.0908
2023-02-06 11:37:55 | Valid | Epoch[382/600] Iteration[007/008] Valid loss: 0.0928
2023-02-06 11:37:55 | Valid | Epoch[382/600] Iteration[008/008] Valid loss: 0.0899
2023-02-06 11:37:55 | Valid | Epoch[382/600] MIou: 0.9377976010979207
2023-02-06 11:37:55 | Valid | Epoch[382/600] Pixel Accuracy: 0.9891077677408854
2023-02-06 11:37:55 | Valid | Epoch[382/600] Mean Pixel Accuracy: 0.9721702402488053
2023-02-06 11:37:55 | Stage | Epoch[382/600] Train loss:0.0209
2023-02-06 11:37:55 | Stage | Epoch[382/600] Valid loss:0.0899
2023-02-06 11:37:55 | Stage | Epoch[382/600] LR:0.01

2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[002/030] Train loss: 0.0224
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[003/030] Train loss: 0.0213
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[005/030] Train loss: 0.0213
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[007/030] Train loss: 0.0214
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[008/030] Train loss: 0.0215
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[009/030] Train loss: 0.0214
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[011/030] Train loss: 0.0208
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[012/030] Train loss: 0.0211
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[013/030] Train loss: 0.0212
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[015/030] Train loss: 0.0211
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[016/030] Train loss: 0.0214
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[018/030] Train loss: 0.0214
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[019/030] Train loss: 0.0215
2023-02-06 11:37:56 | Train | Epoch[383/600] Iteration[020/030] Train loss: 0.0215
2023-02-06 11:37:57 | Train | Epoch[383/600] Iteration[021/030] Train loss: 0.0216
2023-02-06 11:37:57 | Train | Epoch[383/600] Iteration[022/030] Train loss: 0.0217
2023-02-06 11:37:57 | Train | Epoch[383/600] Iteration[023/030] Train loss: 0.0216
2023-02-06 11:37:57 | Train | Epoch[383/600] Iteration[024/030] Train loss: 0.0214
2023-02-06 11:37:57 | Train | Epoch[383/600] Iteration[025/030] Train loss: 0.0214
2023-02-06 11:37:57 | Train | Epoch[383/600] Iteration[026/030] Train loss: 0.0214
2023-02-06 11:37:57 | Train | Epoch[383/600] Iteration[027/030] Train loss: 0.0215
2023-02-06 11:37:57 | Train | Epoch[383/600] Iteration[028/030] Train loss: 0.0214
2023-02-06 11:37:57 | Train | Epoch[383/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:37:57 | Train | Epoch[383/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 11:37:57 | Valid | Epoch[383/600] Iteration[001/008] Valid loss: 0.1713
2023-02-06 11:37:57 | Valid | Epoch[383/600] Iteration[002/008] Valid loss: 0.1168
2023-02-06 11:37:57 | Valid | Epoch[383/600] Iteration[003/008] Valid loss: 0.1033
2023-02-06 11:37:57 | Valid | Epoch[383/600] Iteration[004/008] Valid loss: 0.1055
2023-02-06 11:37:57 | Valid | Epoch[383/600] Iteration[005/008] Valid loss: 0.1144
2023-02-06 11:37:57 | Valid | Epoch[383/600] Iteration[006/008] Valid loss: 0.1127
2023-02-06 11:37:57 | Valid | Epoch[383/600] Iteration[007/008] Valid loss: 0.1213
2023-02-06 11:37:58 | Valid | Epoch[383/600] Iteration[008/008] Valid loss: 0.1181
2023-02-06 11:37:58 | Valid | Epoch[383/600] MIou: 0.931993233385813
2023-02-06 11:37:58 | Valid | Epoch[383/600] Pixel Accuracy: 0.9877738952636719
2023-02-06 11:37:58 | Valid | Epoch[383/600] Mean Pixel Accuracy: 0.9791534408772447
2023-02-06 11:37:58 | Stage | Epoch[383/600] Train loss:0.0214
2023-02-06 11:37:58 | Stage | Epoch[383/600] Valid loss:0.1181
2023-02-06 11:37:58 | Stage | Epoch[383/600] LR:0.01

2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[001/030] Train loss: 0.0174
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[002/030] Train loss: 0.0191
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[004/030] Train loss: 0.0190
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:37:58 | Train | Epoch[384/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[015/030] Train loss: 0.0207
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[018/030] Train loss: 0.0209
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[021/030] Train loss: 0.0209
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[022/030] Train loss: 0.0209
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[023/030] Train loss: 0.0209
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[024/030] Train loss: 0.0211
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[025/030] Train loss: 0.0211
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[026/030] Train loss: 0.0211
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[027/030] Train loss: 0.0212
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[028/030] Train loss: 0.0211
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[029/030] Train loss: 0.0212
2023-02-06 11:37:59 | Train | Epoch[384/600] Iteration[030/030] Train loss: 0.0212
2023-02-06 11:38:00 | Valid | Epoch[384/600] Iteration[001/008] Valid loss: 0.5056
2023-02-06 11:38:00 | Valid | Epoch[384/600] Iteration[002/008] Valid loss: 0.4436
2023-02-06 11:38:00 | Valid | Epoch[384/600] Iteration[003/008] Valid loss: 0.4354
2023-02-06 11:38:00 | Valid | Epoch[384/600] Iteration[004/008] Valid loss: 0.4378
2023-02-06 11:38:00 | Valid | Epoch[384/600] Iteration[005/008] Valid loss: 0.4573
2023-02-06 11:38:00 | Valid | Epoch[384/600] Iteration[006/008] Valid loss: 0.4434
2023-02-06 11:38:00 | Valid | Epoch[384/600] Iteration[007/008] Valid loss: 0.4733
2023-02-06 11:38:00 | Valid | Epoch[384/600] Iteration[008/008] Valid loss: 0.4800
2023-02-06 11:38:00 | Valid | Epoch[384/600] MIou: 0.8957079991433297
2023-02-06 11:38:00 | Valid | Epoch[384/600] Pixel Accuracy: 0.9795583089192709
2023-02-06 11:38:00 | Valid | Epoch[384/600] Mean Pixel Accuracy: 0.9840851067890777
2023-02-06 11:38:00 | Stage | Epoch[384/600] Train loss:0.0212
2023-02-06 11:38:00 | Stage | Epoch[384/600] Valid loss:0.4800
2023-02-06 11:38:00 | Stage | Epoch[384/600] LR:0.01

2023-02-06 11:38:00 | Train | Epoch[385/600] Iteration[001/030] Train loss: 0.0271
2023-02-06 11:38:00 | Train | Epoch[385/600] Iteration[002/030] Train loss: 0.0227
2023-02-06 11:38:00 | Train | Epoch[385/600] Iteration[003/030] Train loss: 0.0212
2023-02-06 11:38:00 | Train | Epoch[385/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:38:00 | Train | Epoch[385/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:38:00 | Train | Epoch[385/600] Iteration[006/030] Train loss: 0.0214
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[010/030] Train loss: 0.0209
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[012/030] Train loss: 0.0211
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[015/030] Train loss: 0.0214
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[016/030] Train loss: 0.0214
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[017/030] Train loss: 0.0214
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[018/030] Train loss: 0.0213
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[020/030] Train loss: 0.0211
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[023/030] Train loss: 0.0214
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[024/030] Train loss: 0.0213
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[026/030] Train loss: 0.0211
2023-02-06 11:38:01 | Train | Epoch[385/600] Iteration[027/030] Train loss: 0.0212
2023-02-06 11:38:02 | Train | Epoch[385/600] Iteration[028/030] Train loss: 0.0212
2023-02-06 11:38:02 | Train | Epoch[385/600] Iteration[029/030] Train loss: 0.0212
2023-02-06 11:38:02 | Train | Epoch[385/600] Iteration[030/030] Train loss: 0.0211
2023-02-06 11:38:02 | Valid | Epoch[385/600] Iteration[001/008] Valid loss: 0.0920
2023-02-06 11:38:02 | Valid | Epoch[385/600] Iteration[002/008] Valid loss: 0.0641
2023-02-06 11:38:02 | Valid | Epoch[385/600] Iteration[003/008] Valid loss: 0.0556
2023-02-06 11:38:02 | Valid | Epoch[385/600] Iteration[004/008] Valid loss: 0.0550
2023-02-06 11:38:02 | Valid | Epoch[385/600] Iteration[005/008] Valid loss: 0.0603
2023-02-06 11:38:02 | Valid | Epoch[385/600] Iteration[006/008] Valid loss: 0.0596
2023-02-06 11:38:02 | Valid | Epoch[385/600] Iteration[007/008] Valid loss: 0.0611
2023-02-06 11:38:02 | Valid | Epoch[385/600] Iteration[008/008] Valid loss: 0.0581
2023-02-06 11:38:02 | Valid | Epoch[385/600] MIou: 0.9413211484748474
2023-02-06 11:38:02 | Valid | Epoch[385/600] Pixel Accuracy: 0.9899024963378906
2023-02-06 11:38:02 | Valid | Epoch[385/600] Mean Pixel Accuracy: 0.9672937418529515
2023-02-06 11:38:02 | Stage | Epoch[385/600] Train loss:0.0211
2023-02-06 11:38:02 | Stage | Epoch[385/600] Valid loss:0.0581
2023-02-06 11:38:02 | Stage | Epoch[385/600] LR:0.01

2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[005/030] Train loss: 0.0213
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[006/030] Train loss: 0.0218
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[007/030] Train loss: 0.0222
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[008/030] Train loss: 0.0225
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[009/030] Train loss: 0.0219
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[010/030] Train loss: 0.0221
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[011/030] Train loss: 0.0225
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[012/030] Train loss: 0.0224
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[013/030] Train loss: 0.0221
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[014/030] Train loss: 0.0222
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[015/030] Train loss: 0.0223
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[016/030] Train loss: 0.0222
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[017/030] Train loss: 0.0221
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[018/030] Train loss: 0.0221
2023-02-06 11:38:03 | Train | Epoch[386/600] Iteration[019/030] Train loss: 0.0221
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[020/030] Train loss: 0.0221
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[021/030] Train loss: 0.0221
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[023/030] Train loss: 0.0220
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[024/030] Train loss: 0.0220
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[025/030] Train loss: 0.0220
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[026/030] Train loss: 0.0220
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[027/030] Train loss: 0.0218
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[028/030] Train loss: 0.0219
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[029/030] Train loss: 0.0219
2023-02-06 11:38:04 | Train | Epoch[386/600] Iteration[030/030] Train loss: 0.0219
2023-02-06 11:38:04 | Valid | Epoch[386/600] Iteration[001/008] Valid loss: 0.3700
2023-02-06 11:38:04 | Valid | Epoch[386/600] Iteration[002/008] Valid loss: 0.3089
2023-02-06 11:38:04 | Valid | Epoch[386/600] Iteration[003/008] Valid loss: 0.2979
2023-02-06 11:38:04 | Valid | Epoch[386/600] Iteration[004/008] Valid loss: 0.3051
2023-02-06 11:38:05 | Valid | Epoch[386/600] Iteration[005/008] Valid loss: 0.3180
2023-02-06 11:38:05 | Valid | Epoch[386/600] Iteration[006/008] Valid loss: 0.3167
2023-02-06 11:38:05 | Valid | Epoch[386/600] Iteration[007/008] Valid loss: 0.3381
2023-02-06 11:38:05 | Valid | Epoch[386/600] Iteration[008/008] Valid loss: 0.3358
2023-02-06 11:38:05 | Valid | Epoch[386/600] MIou: 0.8917250835579609
2023-02-06 11:38:05 | Valid | Epoch[386/600] Pixel Accuracy: 0.978600819905599
2023-02-06 11:38:05 | Valid | Epoch[386/600] Mean Pixel Accuracy: 0.9839075559244093
2023-02-06 11:38:05 | Stage | Epoch[386/600] Train loss:0.0219
2023-02-06 11:38:05 | Stage | Epoch[386/600] Valid loss:0.3358
2023-02-06 11:38:05 | Stage | Epoch[386/600] LR:0.01

2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[003/030] Train loss: 0.0219
2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[004/030] Train loss: 0.0223
2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[005/030] Train loss: 0.0218
2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[006/030] Train loss: 0.0217
2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[007/030] Train loss: 0.0217
2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[008/030] Train loss: 0.0216
2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:38:05 | Train | Epoch[387/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[012/030] Train loss: 0.0214
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[013/030] Train loss: 0.0216
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[016/030] Train loss: 0.0215
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[018/030] Train loss: 0.0215
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[019/030] Train loss: 0.0214
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[021/030] Train loss: 0.0213
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[024/030] Train loss: 0.0213
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[025/030] Train loss: 0.0214
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[026/030] Train loss: 0.0215
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[027/030] Train loss: 0.0214
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[028/030] Train loss: 0.0215
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 11:38:06 | Train | Epoch[387/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:38:07 | Valid | Epoch[387/600] Iteration[001/008] Valid loss: 0.1250
2023-02-06 11:38:07 | Valid | Epoch[387/600] Iteration[002/008] Valid loss: 0.0815
2023-02-06 11:38:07 | Valid | Epoch[387/600] Iteration[003/008] Valid loss: 0.0748
2023-02-06 11:38:07 | Valid | Epoch[387/600] Iteration[004/008] Valid loss: 0.0735
2023-02-06 11:38:07 | Valid | Epoch[387/600] Iteration[005/008] Valid loss: 0.0910
2023-02-06 11:38:07 | Valid | Epoch[387/600] Iteration[006/008] Valid loss: 0.0903
2023-02-06 11:38:07 | Valid | Epoch[387/600] Iteration[007/008] Valid loss: 0.0886
2023-02-06 11:38:07 | Valid | Epoch[387/600] Iteration[008/008] Valid loss: 0.0857
2023-02-06 11:38:07 | Valid | Epoch[387/600] MIou: 0.9362869939174463
2023-02-06 11:38:07 | Valid | Epoch[387/600] Pixel Accuracy: 0.9889996846516927
2023-02-06 11:38:07 | Valid | Epoch[387/600] Mean Pixel Accuracy: 0.9640077105809148
2023-02-06 11:38:07 | Stage | Epoch[387/600] Train loss:0.0216
2023-02-06 11:38:07 | Stage | Epoch[387/600] Valid loss:0.0857
2023-02-06 11:38:07 | Stage | Epoch[387/600] LR:0.01

2023-02-06 11:38:07 | Train | Epoch[388/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:38:07 | Train | Epoch[388/600] Iteration[002/030] Train loss: 0.0220
2023-02-06 11:38:07 | Train | Epoch[388/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:38:07 | Train | Epoch[388/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:38:07 | Train | Epoch[388/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[006/030] Train loss: 0.0207
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[009/030] Train loss: 0.0217
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[010/030] Train loss: 0.0216
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[011/030] Train loss: 0.0216
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[012/030] Train loss: 0.0212
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[013/030] Train loss: 0.0210
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[014/030] Train loss: 0.0213
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[015/030] Train loss: 0.0213
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[016/030] Train loss: 0.0212
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[017/030] Train loss: 0.0214
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[018/030] Train loss: 0.0213
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[019/030] Train loss: 0.0213
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[020/030] Train loss: 0.0215
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[021/030] Train loss: 0.0213
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[024/030] Train loss: 0.0213
2023-02-06 11:38:08 | Train | Epoch[388/600] Iteration[025/030] Train loss: 0.0212
2023-02-06 11:38:09 | Train | Epoch[388/600] Iteration[026/030] Train loss: 0.0212
2023-02-06 11:38:09 | Train | Epoch[388/600] Iteration[027/030] Train loss: 0.0212
2023-02-06 11:38:09 | Train | Epoch[388/600] Iteration[028/030] Train loss: 0.0213
2023-02-06 11:38:09 | Train | Epoch[388/600] Iteration[029/030] Train loss: 0.0213
2023-02-06 11:38:09 | Train | Epoch[388/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 11:38:09 | Valid | Epoch[388/600] Iteration[001/008] Valid loss: 0.0482
2023-02-06 11:38:09 | Valid | Epoch[388/600] Iteration[002/008] Valid loss: 0.0464
2023-02-06 11:38:09 | Valid | Epoch[388/600] Iteration[003/008] Valid loss: 0.0463
2023-02-06 11:38:09 | Valid | Epoch[388/600] Iteration[004/008] Valid loss: 0.0444
2023-02-06 11:38:09 | Valid | Epoch[388/600] Iteration[005/008] Valid loss: 0.0452
2023-02-06 11:38:09 | Valid | Epoch[388/600] Iteration[006/008] Valid loss: 0.0442
2023-02-06 11:38:09 | Valid | Epoch[388/600] Iteration[007/008] Valid loss: 0.0426
2023-02-06 11:38:09 | Valid | Epoch[388/600] Iteration[008/008] Valid loss: 0.0437
2023-02-06 11:38:09 | Valid | Epoch[388/600] MIou: 0.8469786889983166
2023-02-06 11:38:09 | Valid | Epoch[388/600] Pixel Accuracy: 0.9747454325358073
2023-02-06 11:38:09 | Valid | Epoch[388/600] Mean Pixel Accuracy: 0.8611483191373349
2023-02-06 11:38:09 | Stage | Epoch[388/600] Train loss:0.0214
2023-02-06 11:38:09 | Stage | Epoch[388/600] Valid loss:0.0437
2023-02-06 11:38:09 | Stage | Epoch[388/600] LR:0.01

2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[010/030] Train loss: 0.0214
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[012/030] Train loss: 0.0212
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[015/030] Train loss: 0.0216
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[016/030] Train loss: 0.0216
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:38:10 | Train | Epoch[389/600] Iteration[018/030] Train loss: 0.0215
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[019/030] Train loss: 0.0214
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[021/030] Train loss: 0.0213
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[024/030] Train loss: 0.0210
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[025/030] Train loss: 0.0210
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[026/030] Train loss: 0.0210
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[027/030] Train loss: 0.0210
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[028/030] Train loss: 0.0210
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[029/030] Train loss: 0.0212
2023-02-06 11:38:11 | Train | Epoch[389/600] Iteration[030/030] Train loss: 0.0213
2023-02-06 11:38:11 | Valid | Epoch[389/600] Iteration[001/008] Valid loss: 0.1112
2023-02-06 11:38:11 | Valid | Epoch[389/600] Iteration[002/008] Valid loss: 0.1104
2023-02-06 11:38:11 | Valid | Epoch[389/600] Iteration[003/008] Valid loss: 0.1130
2023-02-06 11:38:11 | Valid | Epoch[389/600] Iteration[004/008] Valid loss: 0.1111
2023-02-06 11:38:11 | Valid | Epoch[389/600] Iteration[005/008] Valid loss: 0.1121
2023-02-06 11:38:11 | Valid | Epoch[389/600] Iteration[006/008] Valid loss: 0.1099
2023-02-06 11:38:12 | Valid | Epoch[389/600] Iteration[007/008] Valid loss: 0.1067
2023-02-06 11:38:12 | Valid | Epoch[389/600] Iteration[008/008] Valid loss: 0.1102
2023-02-06 11:38:12 | Valid | Epoch[389/600] MIou: 0.7093478908263435
2023-02-06 11:38:12 | Valid | Epoch[389/600] Pixel Accuracy: 0.9520225524902344
2023-02-06 11:38:12 | Valid | Epoch[389/600] Mean Pixel Accuracy: 0.734397218037703
2023-02-06 11:38:12 | Stage | Epoch[389/600] Train loss:0.0213
2023-02-06 11:38:12 | Stage | Epoch[389/600] Valid loss:0.1102
2023-02-06 11:38:12 | Stage | Epoch[389/600] LR:0.01

2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[003/030] Train loss: 0.0183
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[004/030] Train loss: 0.0195
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:38:12 | Train | Epoch[390/600] Iteration[012/030] Train loss: 0.0206
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[014/030] Train loss: 0.0208
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[016/030] Train loss: 0.0208
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[017/030] Train loss: 0.0210
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[018/030] Train loss: 0.0209
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[021/030] Train loss: 0.0213
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[024/030] Train loss: 0.0212
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[025/030] Train loss: 0.0211
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[026/030] Train loss: 0.0211
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[027/030] Train loss: 0.0211
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[028/030] Train loss: 0.0211
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 11:38:13 | Train | Epoch[390/600] Iteration[030/030] Train loss: 0.0211
2023-02-06 11:38:14 | Valid | Epoch[390/600] Iteration[001/008] Valid loss: 0.0558
2023-02-06 11:38:14 | Valid | Epoch[390/600] Iteration[002/008] Valid loss: 0.0549
2023-02-06 11:38:14 | Valid | Epoch[390/600] Iteration[003/008] Valid loss: 0.0554
2023-02-06 11:38:14 | Valid | Epoch[390/600] Iteration[004/008] Valid loss: 0.0533
2023-02-06 11:38:14 | Valid | Epoch[390/600] Iteration[005/008] Valid loss: 0.0540
2023-02-06 11:38:14 | Valid | Epoch[390/600] Iteration[006/008] Valid loss: 0.0530
2023-02-06 11:38:14 | Valid | Epoch[390/600] Iteration[007/008] Valid loss: 0.0512
2023-02-06 11:38:14 | Valid | Epoch[390/600] Iteration[008/008] Valid loss: 0.0528
2023-02-06 11:38:14 | Valid | Epoch[390/600] MIou: 0.8192812406379781
2023-02-06 11:38:14 | Valid | Epoch[390/600] Pixel Accuracy: 0.9702161153157552
2023-02-06 11:38:14 | Valid | Epoch[390/600] Mean Pixel Accuracy: 0.8351610257987192
2023-02-06 11:38:14 | Stage | Epoch[390/600] Train loss:0.0211
2023-02-06 11:38:14 | Stage | Epoch[390/600] Valid loss:0.0528
2023-02-06 11:38:14 | Stage | Epoch[390/600] LR:0.01

2023-02-06 11:38:14 | Train | Epoch[391/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 11:38:14 | Train | Epoch[391/600] Iteration[002/030] Train loss: 0.0228
2023-02-06 11:38:14 | Train | Epoch[391/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[004/030] Train loss: 0.0219
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[006/030] Train loss: 0.0225
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[008/030] Train loss: 0.0227
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[009/030] Train loss: 0.0227
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[010/030] Train loss: 0.0222
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[011/030] Train loss: 0.0221
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[012/030] Train loss: 0.0222
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[013/030] Train loss: 0.0227
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[014/030] Train loss: 0.0225
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[015/030] Train loss: 0.0226
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[016/030] Train loss: 0.0224
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[017/030] Train loss: 0.0222
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[018/030] Train loss: 0.0219
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[019/030] Train loss: 0.0220
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[020/030] Train loss: 0.0220
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[021/030] Train loss: 0.0220
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[022/030] Train loss: 0.0221
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[023/030] Train loss: 0.0219
2023-02-06 11:38:15 | Train | Epoch[391/600] Iteration[024/030] Train loss: 0.0219
2023-02-06 11:38:16 | Train | Epoch[391/600] Iteration[025/030] Train loss: 0.0218
2023-02-06 11:38:16 | Train | Epoch[391/600] Iteration[026/030] Train loss: 0.0218
2023-02-06 11:38:16 | Train | Epoch[391/600] Iteration[027/030] Train loss: 0.0217
2023-02-06 11:38:16 | Train | Epoch[391/600] Iteration[028/030] Train loss: 0.0217
2023-02-06 11:38:16 | Train | Epoch[391/600] Iteration[029/030] Train loss: 0.0217
2023-02-06 11:38:16 | Train | Epoch[391/600] Iteration[030/030] Train loss: 0.0216
2023-02-06 11:38:16 | Valid | Epoch[391/600] Iteration[001/008] Valid loss: 0.6857
2023-02-06 11:38:16 | Valid | Epoch[391/600] Iteration[002/008] Valid loss: 0.6472
2023-02-06 11:38:16 | Valid | Epoch[391/600] Iteration[003/008] Valid loss: 0.6367
2023-02-06 11:38:16 | Valid | Epoch[391/600] Iteration[004/008] Valid loss: 0.6498
2023-02-06 11:38:16 | Valid | Epoch[391/600] Iteration[005/008] Valid loss: 0.6717
2023-02-06 11:38:16 | Valid | Epoch[391/600] Iteration[006/008] Valid loss: 0.6556
2023-02-06 11:38:16 | Valid | Epoch[391/600] Iteration[007/008] Valid loss: 0.6957
2023-02-06 11:38:16 | Valid | Epoch[391/600] Iteration[008/008] Valid loss: 0.7044
2023-02-06 11:38:16 | Valid | Epoch[391/600] MIou: 0.8786976755165552
2023-02-06 11:38:16 | Valid | Epoch[391/600] Pixel Accuracy: 0.9753367106119791
2023-02-06 11:38:16 | Valid | Epoch[391/600] Mean Pixel Accuracy: 0.9837556443673701
2023-02-06 11:38:16 | Stage | Epoch[391/600] Train loss:0.0216
2023-02-06 11:38:16 | Stage | Epoch[391/600] Valid loss:0.7044
2023-02-06 11:38:16 | Stage | Epoch[391/600] LR:0.01

2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[002/030] Train loss: 0.0202
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[004/030] Train loss: 0.0220
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[005/030] Train loss: 0.0221
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[006/030] Train loss: 0.0223
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[007/030] Train loss: 0.0217
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[008/030] Train loss: 0.0216
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[012/030] Train loss: 0.0215
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[014/030] Train loss: 0.0215
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[015/030] Train loss: 0.0213
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[016/030] Train loss: 0.0211
2023-02-06 11:38:17 | Train | Epoch[392/600] Iteration[017/030] Train loss: 0.0210
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[019/030] Train loss: 0.0212
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[021/030] Train loss: 0.0210
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[022/030] Train loss: 0.0209
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[023/030] Train loss: 0.0211
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[024/030] Train loss: 0.0211
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[025/030] Train loss: 0.0210
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[026/030] Train loss: 0.0211
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[027/030] Train loss: 0.0212
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[028/030] Train loss: 0.0214
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:38:18 | Train | Epoch[392/600] Iteration[030/030] Train loss: 0.0212
2023-02-06 11:38:18 | Valid | Epoch[392/600] Iteration[001/008] Valid loss: 0.0465
2023-02-06 11:38:18 | Valid | Epoch[392/600] Iteration[002/008] Valid loss: 0.0452
2023-02-06 11:38:18 | Valid | Epoch[392/600] Iteration[003/008] Valid loss: 0.0446
2023-02-06 11:38:18 | Valid | Epoch[392/600] Iteration[004/008] Valid loss: 0.0430
2023-02-06 11:38:19 | Valid | Epoch[392/600] Iteration[005/008] Valid loss: 0.0437
2023-02-06 11:38:19 | Valid | Epoch[392/600] Iteration[006/008] Valid loss: 0.0428
2023-02-06 11:38:19 | Valid | Epoch[392/600] Iteration[007/008] Valid loss: 0.0413
2023-02-06 11:38:19 | Valid | Epoch[392/600] Iteration[008/008] Valid loss: 0.0421
2023-02-06 11:38:19 | Valid | Epoch[392/600] MIou: 0.8580837689635985
2023-02-06 11:38:19 | Valid | Epoch[392/600] Pixel Accuracy: 0.9765739440917969
2023-02-06 11:38:19 | Valid | Epoch[392/600] Mean Pixel Accuracy: 0.8714484783093475
2023-02-06 11:38:19 | Stage | Epoch[392/600] Train loss:0.0212
2023-02-06 11:38:19 | Stage | Epoch[392/600] Valid loss:0.0421
2023-02-06 11:38:19 | Stage | Epoch[392/600] LR:0.01

2023-02-06 11:38:19 | Train | Epoch[393/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 11:38:19 | Train | Epoch[393/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 11:38:19 | Train | Epoch[393/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:38:19 | Train | Epoch[393/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:38:19 | Train | Epoch[393/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:38:19 | Train | Epoch[393/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:38:19 | Train | Epoch[393/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 11:38:19 | Train | Epoch[393/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:38:19 | Train | Epoch[393/600] Iteration[009/030] Train loss: 0.0214
2023-02-06 11:38:19 | Train | Epoch[393/600] Iteration[010/030] Train loss: 0.0219
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[011/030] Train loss: 0.0217
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[012/030] Train loss: 0.0215
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[013/030] Train loss: 0.0212
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[014/030] Train loss: 0.0208
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[018/030] Train loss: 0.0210
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[019/030] Train loss: 0.0209
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[021/030] Train loss: 0.0209
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[022/030] Train loss: 0.0209
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[023/030] Train loss: 0.0210
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[024/030] Train loss: 0.0210
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[025/030] Train loss: 0.0210
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[026/030] Train loss: 0.0208
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[027/030] Train loss: 0.0208
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[028/030] Train loss: 0.0209
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[029/030] Train loss: 0.0209
2023-02-06 11:38:20 | Train | Epoch[393/600] Iteration[030/030] Train loss: 0.0209
2023-02-06 11:38:21 | Valid | Epoch[393/600] Iteration[001/008] Valid loss: 0.6251
2023-02-06 11:38:21 | Valid | Epoch[393/600] Iteration[002/008] Valid loss: 0.5471
2023-02-06 11:38:21 | Valid | Epoch[393/600] Iteration[003/008] Valid loss: 0.5416
2023-02-06 11:38:21 | Valid | Epoch[393/600] Iteration[004/008] Valid loss: 0.5553
2023-02-06 11:38:21 | Valid | Epoch[393/600] Iteration[005/008] Valid loss: 0.5799
2023-02-06 11:38:21 | Valid | Epoch[393/600] Iteration[006/008] Valid loss: 0.5677
2023-02-06 11:38:21 | Valid | Epoch[393/600] Iteration[007/008] Valid loss: 0.6073
2023-02-06 11:38:21 | Valid | Epoch[393/600] Iteration[008/008] Valid loss: 0.6093
2023-02-06 11:38:21 | Valid | Epoch[393/600] MIou: 0.8865722515472558
2023-02-06 11:38:21 | Valid | Epoch[393/600] Pixel Accuracy: 0.9772961934407552
2023-02-06 11:38:21 | Valid | Epoch[393/600] Mean Pixel Accuracy: 0.9846361050831123
2023-02-06 11:38:21 | Stage | Epoch[393/600] Train loss:0.0209
2023-02-06 11:38:21 | Stage | Epoch[393/600] Valid loss:0.6093
2023-02-06 11:38:21 | Stage | Epoch[393/600] LR:0.01

2023-02-06 11:38:21 | Train | Epoch[394/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 11:38:21 | Train | Epoch[394/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:38:21 | Train | Epoch[394/600] Iteration[003/030] Train loss: 0.0214
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[006/030] Train loss: 0.0199
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[010/030] Train loss: 0.0209
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[014/030] Train loss: 0.0210
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[015/030] Train loss: 0.0211
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[016/030] Train loss: 0.0213
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[018/030] Train loss: 0.0210
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[020/030] Train loss: 0.0211
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[022/030] Train loss: 0.0213
2023-02-06 11:38:22 | Train | Epoch[394/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:38:23 | Train | Epoch[394/600] Iteration[024/030] Train loss: 0.0212
2023-02-06 11:38:23 | Train | Epoch[394/600] Iteration[025/030] Train loss: 0.0211
2023-02-06 11:38:23 | Train | Epoch[394/600] Iteration[026/030] Train loss: 0.0211
2023-02-06 11:38:23 | Train | Epoch[394/600] Iteration[027/030] Train loss: 0.0211
2023-02-06 11:38:23 | Train | Epoch[394/600] Iteration[028/030] Train loss: 0.0210
2023-02-06 11:38:23 | Train | Epoch[394/600] Iteration[029/030] Train loss: 0.0211
2023-02-06 11:38:23 | Train | Epoch[394/600] Iteration[030/030] Train loss: 0.0212
2023-02-06 11:38:23 | Valid | Epoch[394/600] Iteration[001/008] Valid loss: 0.0749
2023-02-06 11:38:23 | Valid | Epoch[394/600] Iteration[002/008] Valid loss: 0.0754
2023-02-06 11:38:23 | Valid | Epoch[394/600] Iteration[003/008] Valid loss: 0.0768
2023-02-06 11:38:23 | Valid | Epoch[394/600] Iteration[004/008] Valid loss: 0.0746
2023-02-06 11:38:23 | Valid | Epoch[394/600] Iteration[005/008] Valid loss: 0.0757
2023-02-06 11:38:23 | Valid | Epoch[394/600] Iteration[006/008] Valid loss: 0.0742
2023-02-06 11:38:23 | Valid | Epoch[394/600] Iteration[007/008] Valid loss: 0.0720
2023-02-06 11:38:23 | Valid | Epoch[394/600] Iteration[008/008] Valid loss: 0.0751
2023-02-06 11:38:23 | Valid | Epoch[394/600] MIou: 0.7416623436354652
2023-02-06 11:38:23 | Valid | Epoch[394/600] Pixel Accuracy: 0.9573745727539062
2023-02-06 11:38:23 | Valid | Epoch[394/600] Mean Pixel Accuracy: 0.7640576635846648
2023-02-06 11:38:23 | Stage | Epoch[394/600] Train loss:0.0212
2023-02-06 11:38:23 | Stage | Epoch[394/600] Valid loss:0.0751
2023-02-06 11:38:23 | Stage | Epoch[394/600] LR:0.01

2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[001/030] Train loss: 0.0195
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[002/030] Train loss: 0.0209
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[003/030] Train loss: 0.0225
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[009/030] Train loss: 0.0209
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[011/030] Train loss: 0.0210
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[012/030] Train loss: 0.0211
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[013/030] Train loss: 0.0215
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[014/030] Train loss: 0.0217
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[015/030] Train loss: 0.0217
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[016/030] Train loss: 0.0218
2023-02-06 11:38:24 | Train | Epoch[395/600] Iteration[017/030] Train loss: 0.0215
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[018/030] Train loss: 0.0214
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[019/030] Train loss: 0.0214
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[022/030] Train loss: 0.0212
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[024/030] Train loss: 0.0214
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[025/030] Train loss: 0.0215
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[026/030] Train loss: 0.0215
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[027/030] Train loss: 0.0214
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[028/030] Train loss: 0.0214
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:38:25 | Train | Epoch[395/600] Iteration[030/030] Train loss: 0.0213
2023-02-06 11:38:25 | Valid | Epoch[395/600] Iteration[001/008] Valid loss: 1.2633
2023-02-06 11:38:25 | Valid | Epoch[395/600] Iteration[002/008] Valid loss: 1.2098
2023-02-06 11:38:25 | Valid | Epoch[395/600] Iteration[003/008] Valid loss: 1.2305
2023-02-06 11:38:25 | Valid | Epoch[395/600] Iteration[004/008] Valid loss: 1.2604
2023-02-06 11:38:26 | Valid | Epoch[395/600] Iteration[005/008] Valid loss: 1.3044
2023-02-06 11:38:26 | Valid | Epoch[395/600] Iteration[006/008] Valid loss: 1.2806
2023-02-06 11:38:26 | Valid | Epoch[395/600] Iteration[007/008] Valid loss: 1.3338
2023-02-06 11:38:26 | Valid | Epoch[395/600] Iteration[008/008] Valid loss: 1.3706
2023-02-06 11:38:26 | Valid | Epoch[395/600] MIou: 0.8318758689214458
2023-02-06 11:38:26 | Valid | Epoch[395/600] Pixel Accuracy: 0.9623235066731771
2023-02-06 11:38:26 | Valid | Epoch[395/600] Mean Pixel Accuracy: 0.9782515550760206
2023-02-06 11:38:26 | Stage | Epoch[395/600] Train loss:0.0213
2023-02-06 11:38:26 | Stage | Epoch[395/600] Valid loss:1.3706
2023-02-06 11:38:26 | Stage | Epoch[395/600] LR:0.01

2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[001/030] Train loss: 0.0176
2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[004/030] Train loss: 0.0191
2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[005/030] Train loss: 0.0193
2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[006/030] Train loss: 0.0191
2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[010/030] Train loss: 0.0209
2023-02-06 11:38:26 | Train | Epoch[396/600] Iteration[011/030] Train loss: 0.0210
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[014/030] Train loss: 0.0208
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[016/030] Train loss: 0.0211
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[017/030] Train loss: 0.0211
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[022/030] Train loss: 0.0214
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[023/030] Train loss: 0.0215
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[024/030] Train loss: 0.0215
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[025/030] Train loss: 0.0215
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[026/030] Train loss: 0.0215
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[027/030] Train loss: 0.0215
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[028/030] Train loss: 0.0215
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:38:27 | Train | Epoch[396/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 11:38:28 | Valid | Epoch[396/600] Iteration[001/008] Valid loss: 0.1130
2023-02-06 11:38:28 | Valid | Epoch[396/600] Iteration[002/008] Valid loss: 0.0854
2023-02-06 11:38:28 | Valid | Epoch[396/600] Iteration[003/008] Valid loss: 0.0930
2023-02-06 11:38:28 | Valid | Epoch[396/600] Iteration[004/008] Valid loss: 0.0902
2023-02-06 11:38:28 | Valid | Epoch[396/600] Iteration[005/008] Valid loss: 0.1140
2023-02-06 11:38:28 | Valid | Epoch[396/600] Iteration[006/008] Valid loss: 0.1176
2023-02-06 11:38:28 | Valid | Epoch[396/600] Iteration[007/008] Valid loss: 0.1154
2023-02-06 11:38:28 | Valid | Epoch[396/600] Iteration[008/008] Valid loss: 0.1133
2023-02-06 11:38:28 | Valid | Epoch[396/600] MIou: 0.9131342667701929
2023-02-06 11:38:28 | Valid | Epoch[396/600] Pixel Accuracy: 0.9847971598307291
2023-02-06 11:38:28 | Valid | Epoch[396/600] Mean Pixel Accuracy: 0.9477741482654374
2023-02-06 11:38:28 | Stage | Epoch[396/600] Train loss:0.0214
2023-02-06 11:38:28 | Stage | Epoch[396/600] Valid loss:0.1133
2023-02-06 11:38:28 | Stage | Epoch[396/600] LR:0.01

2023-02-06 11:38:28 | Train | Epoch[397/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 11:38:28 | Train | Epoch[397/600] Iteration[002/030] Train loss: 0.0202
2023-02-06 11:38:28 | Train | Epoch[397/600] Iteration[003/030] Train loss: 0.0205
2023-02-06 11:38:28 | Train | Epoch[397/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:38:28 | Train | Epoch[397/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:38:28 | Train | Epoch[397/600] Iteration[006/030] Train loss: 0.0207
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[009/030] Train loss: 0.0209
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[015/030] Train loss: 0.0212
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[016/030] Train loss: 0.0213
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[017/030] Train loss: 0.0212
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[018/030] Train loss: 0.0216
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[019/030] Train loss: 0.0216
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[020/030] Train loss: 0.0213
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[021/030] Train loss: 0.0213
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[022/030] Train loss: 0.0211
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[023/030] Train loss: 0.0213
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[024/030] Train loss: 0.0214
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[025/030] Train loss: 0.0215
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[026/030] Train loss: 0.0213
2023-02-06 11:38:29 | Train | Epoch[397/600] Iteration[027/030] Train loss: 0.0214
2023-02-06 11:38:30 | Train | Epoch[397/600] Iteration[028/030] Train loss: 0.0215
2023-02-06 11:38:30 | Train | Epoch[397/600] Iteration[029/030] Train loss: 0.0215
2023-02-06 11:38:30 | Train | Epoch[397/600] Iteration[030/030] Train loss: 0.0215
2023-02-06 11:38:30 | Valid | Epoch[397/600] Iteration[001/008] Valid loss: 0.1169
2023-02-06 11:38:30 | Valid | Epoch[397/600] Iteration[002/008] Valid loss: 0.1149
2023-02-06 11:38:30 | Valid | Epoch[397/600] Iteration[003/008] Valid loss: 0.1171
2023-02-06 11:38:30 | Valid | Epoch[397/600] Iteration[004/008] Valid loss: 0.1155
2023-02-06 11:38:30 | Valid | Epoch[397/600] Iteration[005/008] Valid loss: 0.1166
2023-02-06 11:38:30 | Valid | Epoch[397/600] Iteration[006/008] Valid loss: 0.1154
2023-02-06 11:38:30 | Valid | Epoch[397/600] Iteration[007/008] Valid loss: 0.1121
2023-02-06 11:38:30 | Valid | Epoch[397/600] Iteration[008/008] Valid loss: 0.1147
2023-02-06 11:38:30 | Valid | Epoch[397/600] MIou: 0.7183766551664676
2023-02-06 11:38:30 | Valid | Epoch[397/600] Pixel Accuracy: 0.9535191853841146
2023-02-06 11:38:30 | Valid | Epoch[397/600] Mean Pixel Accuracy: 0.7426825662757466
2023-02-06 11:38:30 | Stage | Epoch[397/600] Train loss:0.0215
2023-02-06 11:38:30 | Stage | Epoch[397/600] Valid loss:0.1147
2023-02-06 11:38:30 | Stage | Epoch[397/600] LR:0.01

2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[003/030] Train loss: 0.0216
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[005/030] Train loss: 0.0217
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[006/030] Train loss: 0.0222
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[007/030] Train loss: 0.0220
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[008/030] Train loss: 0.0216
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[009/030] Train loss: 0.0219
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[010/030] Train loss: 0.0220
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[011/030] Train loss: 0.0223
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[012/030] Train loss: 0.0221
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[013/030] Train loss: 0.0221
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[014/030] Train loss: 0.0218
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[015/030] Train loss: 0.0219
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[016/030] Train loss: 0.0220
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[017/030] Train loss: 0.0223
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[018/030] Train loss: 0.0220
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[019/030] Train loss: 0.0219
2023-02-06 11:38:31 | Train | Epoch[398/600] Iteration[020/030] Train loss: 0.0222
2023-02-06 11:38:32 | Train | Epoch[398/600] Iteration[021/030] Train loss: 0.0220
2023-02-06 11:38:32 | Train | Epoch[398/600] Iteration[022/030] Train loss: 0.0219
2023-02-06 11:38:32 | Train | Epoch[398/600] Iteration[023/030] Train loss: 0.0218
2023-02-06 11:38:32 | Train | Epoch[398/600] Iteration[024/030] Train loss: 0.0218
2023-02-06 11:38:32 | Train | Epoch[398/600] Iteration[025/030] Train loss: 0.0217
2023-02-06 11:38:32 | Train | Epoch[398/600] Iteration[026/030] Train loss: 0.0216
2023-02-06 11:38:32 | Train | Epoch[398/600] Iteration[027/030] Train loss: 0.0216
2023-02-06 11:38:32 | Train | Epoch[398/600] Iteration[028/030] Train loss: 0.0215
2023-02-06 11:38:32 | Train | Epoch[398/600] Iteration[029/030] Train loss: 0.0214
2023-02-06 11:38:32 | Train | Epoch[398/600] Iteration[030/030] Train loss: 0.0214
2023-02-06 11:38:32 | Valid | Epoch[398/600] Iteration[001/008] Valid loss: 0.0494
2023-02-06 11:38:32 | Valid | Epoch[398/600] Iteration[002/008] Valid loss: 0.0388
2023-02-06 11:38:32 | Valid | Epoch[398/600] Iteration[003/008] Valid loss: 0.0359
2023-02-06 11:38:32 | Valid | Epoch[398/600] Iteration[004/008] Valid loss: 0.0338
2023-02-06 11:38:32 | Valid | Epoch[398/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:38:32 | Valid | Epoch[398/600] Iteration[006/008] Valid loss: 0.0336
2023-02-06 11:38:32 | Valid | Epoch[398/600] Iteration[007/008] Valid loss: 0.0330
2023-02-06 11:38:33 | Valid | Epoch[398/600] Iteration[008/008] Valid loss: 0.0327
2023-02-06 11:38:33 | Valid | Epoch[398/600] MIou: 0.9072482897956873
2023-02-06 11:38:33 | Valid | Epoch[398/600] Pixel Accuracy: 0.9846216837565104
2023-02-06 11:38:33 | Valid | Epoch[398/600] Mean Pixel Accuracy: 0.9186066372482873
2023-02-06 11:38:33 | Stage | Epoch[398/600] Train loss:0.0214
2023-02-06 11:38:33 | Stage | Epoch[398/600] Valid loss:0.0327
2023-02-06 11:38:33 | Stage | Epoch[398/600] LR:0.01

2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[002/030] Train loss: 0.0227
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[003/030] Train loss: 0.0217
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[004/030] Train loss: 0.0213
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[005/030] Train loss: 0.0219
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[008/030] Train loss: 0.0213
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[009/030] Train loss: 0.0215
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:38:33 | Train | Epoch[399/600] Iteration[012/030] Train loss: 0.0212
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[013/030] Train loss: 0.0214
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[014/030] Train loss: 0.0211
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[015/030] Train loss: 0.0210
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[016/030] Train loss: 0.0211
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[017/030] Train loss: 0.0213
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[018/030] Train loss: 0.0214
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[019/030] Train loss: 0.0212
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[020/030] Train loss: 0.0212
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[021/030] Train loss: 0.0212
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[022/030] Train loss: 0.0212
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[023/030] Train loss: 0.0212
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[024/030] Train loss: 0.0211
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[025/030] Train loss: 0.0211
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[026/030] Train loss: 0.0211
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[027/030] Train loss: 0.0211
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[028/030] Train loss: 0.0211
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 11:38:34 | Train | Epoch[399/600] Iteration[030/030] Train loss: 0.0210
2023-02-06 11:38:35 | Valid | Epoch[399/600] Iteration[001/008] Valid loss: 0.0656
2023-02-06 11:38:35 | Valid | Epoch[399/600] Iteration[002/008] Valid loss: 0.0639
2023-02-06 11:38:35 | Valid | Epoch[399/600] Iteration[003/008] Valid loss: 0.0646
2023-02-06 11:38:35 | Valid | Epoch[399/600] Iteration[004/008] Valid loss: 0.0624
2023-02-06 11:38:35 | Valid | Epoch[399/600] Iteration[005/008] Valid loss: 0.0635
2023-02-06 11:38:35 | Valid | Epoch[399/600] Iteration[006/008] Valid loss: 0.0626
2023-02-06 11:38:35 | Valid | Epoch[399/600] Iteration[007/008] Valid loss: 0.0606
2023-02-06 11:38:35 | Valid | Epoch[399/600] Iteration[008/008] Valid loss: 0.0619
2023-02-06 11:38:35 | Valid | Epoch[399/600] MIou: 0.8098866528106752
2023-02-06 11:38:35 | Valid | Epoch[399/600] Pixel Accuracy: 0.9686660766601562
2023-02-06 11:38:35 | Valid | Epoch[399/600] Mean Pixel Accuracy: 0.8265356403722424
2023-02-06 11:38:35 | Stage | Epoch[399/600] Train loss:0.0210
2023-02-06 11:38:35 | Stage | Epoch[399/600] Valid loss:0.0619
2023-02-06 11:38:35 | Stage | Epoch[399/600] LR:0.01

2023-02-06 11:38:35 | Train | Epoch[400/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:38:35 | Train | Epoch[400/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:38:35 | Train | Epoch[400/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:38:35 | Train | Epoch[400/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:38:35 | Train | Epoch[400/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[015/030] Train loss: 0.0211
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[016/030] Train loss: 0.0210
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[017/030] Train loss: 0.0210
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[018/030] Train loss: 0.0211
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[019/030] Train loss: 0.0211
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[021/030] Train loss: 0.0209
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[022/030] Train loss: 0.0209
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[023/030] Train loss: 0.0210
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[024/030] Train loss: 0.0210
2023-02-06 11:38:36 | Train | Epoch[400/600] Iteration[025/030] Train loss: 0.0210
2023-02-06 11:38:37 | Train | Epoch[400/600] Iteration[026/030] Train loss: 0.0209
2023-02-06 11:38:37 | Train | Epoch[400/600] Iteration[027/030] Train loss: 0.0209
2023-02-06 11:38:37 | Train | Epoch[400/600] Iteration[028/030] Train loss: 0.0209
2023-02-06 11:38:37 | Train | Epoch[400/600] Iteration[029/030] Train loss: 0.0210
2023-02-06 11:38:37 | Train | Epoch[400/600] Iteration[030/030] Train loss: 0.0211
2023-02-06 11:38:37 | Valid | Epoch[400/600] Iteration[001/008] Valid loss: 0.0734
2023-02-06 11:38:37 | Valid | Epoch[400/600] Iteration[002/008] Valid loss: 0.0503
2023-02-06 11:38:37 | Valid | Epoch[400/600] Iteration[003/008] Valid loss: 0.0440
2023-02-06 11:38:37 | Valid | Epoch[400/600] Iteration[004/008] Valid loss: 0.0441
2023-02-06 11:38:37 | Valid | Epoch[400/600] Iteration[005/008] Valid loss: 0.0460
2023-02-06 11:38:37 | Valid | Epoch[400/600] Iteration[006/008] Valid loss: 0.0450
2023-02-06 11:38:37 | Valid | Epoch[400/600] Iteration[007/008] Valid loss: 0.0466
2023-02-06 11:38:37 | Valid | Epoch[400/600] Iteration[008/008] Valid loss: 0.0447
2023-02-06 11:38:37 | Valid | Epoch[400/600] MIou: 0.9389081099866871
2023-02-06 11:38:37 | Valid | Epoch[400/600] Pixel Accuracy: 0.9896380106608073
2023-02-06 11:38:37 | Valid | Epoch[400/600] Mean Pixel Accuracy: 0.9582526877133372
2023-02-06 11:38:37 | Stage | Epoch[400/600] Train loss:0.0211
2023-02-06 11:38:37 | Stage | Epoch[400/600] Valid loss:0.0447
2023-02-06 11:38:37 | Stage | Epoch[400/600] LR:0.01

2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[004/030] Train loss: 0.0198
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[006/030] Train loss: 0.0209
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[011/030] Train loss: 0.0213
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[012/030] Train loss: 0.0214
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[013/030] Train loss: 0.0213
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[014/030] Train loss: 0.0214
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[015/030] Train loss: 0.0211
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[016/030] Train loss: 0.0210
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:38:38 | Train | Epoch[401/600] Iteration[018/030] Train loss: 0.0209
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[019/030] Train loss: 0.0209
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[020/030] Train loss: 0.0210
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[021/030] Train loss: 0.0210
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[022/030] Train loss: 0.0209
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[023/030] Train loss: 0.0209
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[024/030] Train loss: 0.0208
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[025/030] Train loss: 0.0206
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[026/030] Train loss: 0.0207
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[027/030] Train loss: 0.0207
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[028/030] Train loss: 0.0206
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[029/030] Train loss: 0.0207
2023-02-06 11:38:39 | Train | Epoch[401/600] Iteration[030/030] Train loss: 0.0205
2023-02-06 11:38:39 | Valid | Epoch[401/600] Iteration[001/008] Valid loss: 0.0416
2023-02-06 11:38:39 | Valid | Epoch[401/600] Iteration[002/008] Valid loss: 0.0357
2023-02-06 11:38:39 | Valid | Epoch[401/600] Iteration[003/008] Valid loss: 0.0343
2023-02-06 11:38:39 | Valid | Epoch[401/600] Iteration[004/008] Valid loss: 0.0326
2023-02-06 11:38:39 | Valid | Epoch[401/600] Iteration[005/008] Valid loss: 0.0333
2023-02-06 11:38:39 | Valid | Epoch[401/600] Iteration[006/008] Valid loss: 0.0329
2023-02-06 11:38:40 | Valid | Epoch[401/600] Iteration[007/008] Valid loss: 0.0321
2023-02-06 11:38:40 | Valid | Epoch[401/600] Iteration[008/008] Valid loss: 0.0322
2023-02-06 11:38:40 | Valid | Epoch[401/600] MIou: 0.9006609526908572
2023-02-06 11:38:40 | Valid | Epoch[401/600] Pixel Accuracy: 0.9835611979166666
2023-02-06 11:38:40 | Valid | Epoch[401/600] Mean Pixel Accuracy: 0.9117149798475626
2023-02-06 11:38:40 | Stage | Epoch[401/600] Train loss:0.0205
2023-02-06 11:38:40 | Stage | Epoch[401/600] Valid loss:0.0322
2023-02-06 11:38:40 | Stage | Epoch[401/600] LR:0.001

2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[003/030] Train loss: 0.0216
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[004/030] Train loss: 0.0218
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[005/030] Train loss: 0.0216
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[006/030] Train loss: 0.0216
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[007/030] Train loss: 0.0215
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[009/030] Train loss: 0.0213
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[010/030] Train loss: 0.0209
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:38:40 | Train | Epoch[402/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[013/030] Train loss: 0.0206
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[017/030] Train loss: 0.0208
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[018/030] Train loss: 0.0207
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[020/030] Train loss: 0.0206
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:38:41 | Train | Epoch[402/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:38:42 | Valid | Epoch[402/600] Iteration[001/008] Valid loss: 0.0749
2023-02-06 11:38:42 | Valid | Epoch[402/600] Iteration[002/008] Valid loss: 0.0512
2023-02-06 11:38:42 | Valid | Epoch[402/600] Iteration[003/008] Valid loss: 0.0443
2023-02-06 11:38:42 | Valid | Epoch[402/600] Iteration[004/008] Valid loss: 0.0438
2023-02-06 11:38:42 | Valid | Epoch[402/600] Iteration[005/008] Valid loss: 0.0462
2023-02-06 11:38:42 | Valid | Epoch[402/600] Iteration[006/008] Valid loss: 0.0459
2023-02-06 11:38:42 | Valid | Epoch[402/600] Iteration[007/008] Valid loss: 0.0476
2023-02-06 11:38:42 | Valid | Epoch[402/600] Iteration[008/008] Valid loss: 0.0455
2023-02-06 11:38:42 | Valid | Epoch[402/600] MIou: 0.9402156046095926
2023-02-06 11:38:42 | Valid | Epoch[402/600] Pixel Accuracy: 0.9898541768391927
2023-02-06 11:38:42 | Valid | Epoch[402/600] Mean Pixel Accuracy: 0.9597473841823636
2023-02-06 11:38:42 | Stage | Epoch[402/600] Train loss:0.0202
2023-02-06 11:38:42 | Stage | Epoch[402/600] Valid loss:0.0455
2023-02-06 11:38:42 | Stage | Epoch[402/600] LR:0.001

2023-02-06 11:38:42 | Train | Epoch[403/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 11:38:42 | Train | Epoch[403/600] Iteration[002/030] Train loss: 0.0185
2023-02-06 11:38:42 | Train | Epoch[403/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 11:38:42 | Train | Epoch[403/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[006/030] Train loss: 0.0204
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[007/030] Train loss: 0.0200
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[010/030] Train loss: 0.0193
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:38:43 | Train | Epoch[403/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:38:44 | Train | Epoch[403/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:38:44 | Train | Epoch[403/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:38:44 | Train | Epoch[403/600] Iteration[028/030] Train loss: 0.0204
2023-02-06 11:38:44 | Train | Epoch[403/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:38:44 | Train | Epoch[403/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:38:44 | Valid | Epoch[403/600] Iteration[001/008] Valid loss: 0.0440
2023-02-06 11:38:44 | Valid | Epoch[403/600] Iteration[002/008] Valid loss: 0.0357
2023-02-06 11:38:44 | Valid | Epoch[403/600] Iteration[003/008] Valid loss: 0.0336
2023-02-06 11:38:44 | Valid | Epoch[403/600] Iteration[004/008] Valid loss: 0.0319
2023-02-06 11:38:44 | Valid | Epoch[403/600] Iteration[005/008] Valid loss: 0.0326
2023-02-06 11:38:44 | Valid | Epoch[403/600] Iteration[006/008] Valid loss: 0.0324
2023-02-06 11:38:44 | Valid | Epoch[403/600] Iteration[007/008] Valid loss: 0.0318
2023-02-06 11:38:44 | Valid | Epoch[403/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 11:38:44 | Valid | Epoch[403/600] MIou: 0.9110715118518826
2023-02-06 11:38:44 | Valid | Epoch[403/600] Pixel Accuracy: 0.9852434794108073
2023-02-06 11:38:44 | Valid | Epoch[403/600] Mean Pixel Accuracy: 0.9224927262340847
2023-02-06 11:38:44 | Stage | Epoch[403/600] Train loss:0.0203
2023-02-06 11:38:44 | Stage | Epoch[403/600] Valid loss:0.0316
2023-02-06 11:38:44 | Stage | Epoch[403/600] LR:0.001

2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[001/030] Train loss: 0.0212
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:38:45 | Train | Epoch[404/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:38:46 | Train | Epoch[404/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:38:46 | Valid | Epoch[404/600] Iteration[001/008] Valid loss: 0.0847
2023-02-06 11:38:46 | Valid | Epoch[404/600] Iteration[002/008] Valid loss: 0.0572
2023-02-06 11:38:46 | Valid | Epoch[404/600] Iteration[003/008] Valid loss: 0.0492
2023-02-06 11:38:46 | Valid | Epoch[404/600] Iteration[004/008] Valid loss: 0.0488
2023-02-06 11:38:46 | Valid | Epoch[404/600] Iteration[005/008] Valid loss: 0.0518
2023-02-06 11:38:47 | Valid | Epoch[404/600] Iteration[006/008] Valid loss: 0.0518
2023-02-06 11:38:47 | Valid | Epoch[404/600] Iteration[007/008] Valid loss: 0.0540
2023-02-06 11:38:47 | Valid | Epoch[404/600] Iteration[008/008] Valid loss: 0.0514
2023-02-06 11:38:47 | Valid | Epoch[404/600] MIou: 0.9419036960768473
2023-02-06 11:38:47 | Valid | Epoch[404/600] Pixel Accuracy: 0.9900868733723959
2023-02-06 11:38:47 | Valid | Epoch[404/600] Mean Pixel Accuracy: 0.9638824621169135
2023-02-06 11:38:47 | Stage | Epoch[404/600] Train loss:0.0201
2023-02-06 11:38:47 | Stage | Epoch[404/600] Valid loss:0.0514
2023-02-06 11:38:47 | Stage | Epoch[404/600] LR:0.001

2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[001/030] Train loss: 0.0181
2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[002/030] Train loss: 0.0192
2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[003/030] Train loss: 0.0197
2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:38:47 | Train | Epoch[405/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[018/030] Train loss: 0.0195
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[020/030] Train loss: 0.0196
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:38:48 | Train | Epoch[405/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:38:49 | Valid | Epoch[405/600] Iteration[001/008] Valid loss: 0.0426
2023-02-06 11:38:49 | Valid | Epoch[405/600] Iteration[002/008] Valid loss: 0.0353
2023-02-06 11:38:49 | Valid | Epoch[405/600] Iteration[003/008] Valid loss: 0.0334
2023-02-06 11:38:49 | Valid | Epoch[405/600] Iteration[004/008] Valid loss: 0.0317
2023-02-06 11:38:49 | Valid | Epoch[405/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 11:38:49 | Valid | Epoch[405/600] Iteration[006/008] Valid loss: 0.0322
2023-02-06 11:38:49 | Valid | Epoch[405/600] Iteration[007/008] Valid loss: 0.0316
2023-02-06 11:38:49 | Valid | Epoch[405/600] Iteration[008/008] Valid loss: 0.0314
2023-02-06 11:38:49 | Valid | Epoch[405/600] MIou: 0.9088097460440452
2023-02-06 11:38:49 | Valid | Epoch[405/600] Pixel Accuracy: 0.9848798116048177
2023-02-06 11:38:49 | Valid | Epoch[405/600] Mean Pixel Accuracy: 0.9200736738686282
2023-02-06 11:38:49 | Stage | Epoch[405/600] Train loss:0.0202
2023-02-06 11:38:49 | Stage | Epoch[405/600] Valid loss:0.0314
2023-02-06 11:38:49 | Stage | Epoch[405/600] LR:0.001

2023-02-06 11:38:49 | Train | Epoch[406/600] Iteration[001/030] Train loss: 0.0173
2023-02-06 11:38:49 | Train | Epoch[406/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 11:38:49 | Train | Epoch[406/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 11:38:49 | Train | Epoch[406/600] Iteration[004/030] Train loss: 0.0195
2023-02-06 11:38:49 | Train | Epoch[406/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[017/030] Train loss: 0.0196
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:38:50 | Train | Epoch[406/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:38:51 | Train | Epoch[406/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:38:51 | Train | Epoch[406/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:38:51 | Train | Epoch[406/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:38:51 | Train | Epoch[406/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:38:51 | Valid | Epoch[406/600] Iteration[001/008] Valid loss: 0.1154
2023-02-06 11:38:51 | Valid | Epoch[406/600] Iteration[002/008] Valid loss: 0.0764
2023-02-06 11:38:51 | Valid | Epoch[406/600] Iteration[003/008] Valid loss: 0.0656
2023-02-06 11:38:51 | Valid | Epoch[406/600] Iteration[004/008] Valid loss: 0.0663
2023-02-06 11:38:51 | Valid | Epoch[406/600] Iteration[005/008] Valid loss: 0.0709
2023-02-06 11:38:51 | Valid | Epoch[406/600] Iteration[006/008] Valid loss: 0.0700
2023-02-06 11:38:51 | Valid | Epoch[406/600] Iteration[007/008] Valid loss: 0.0742
2023-02-06 11:38:51 | Valid | Epoch[406/600] Iteration[008/008] Valid loss: 0.0707
2023-02-06 11:38:51 | Valid | Epoch[406/600] MIou: 0.9421574674362261
2023-02-06 11:38:51 | Valid | Epoch[406/600] Pixel Accuracy: 0.9899813334147135
2023-02-06 11:38:51 | Valid | Epoch[406/600] Mean Pixel Accuracy: 0.9711920807520378
2023-02-06 11:38:51 | Stage | Epoch[406/600] Train loss:0.0203
2023-02-06 11:38:51 | Stage | Epoch[406/600] Valid loss:0.0707
2023-02-06 11:38:51 | Stage | Epoch[406/600] LR:0.001

2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[001/030] Train loss: 0.0203
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[003/030] Train loss: 0.0201
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:38:52 | Train | Epoch[407/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:38:53 | Train | Epoch[407/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:38:53 | Train | Epoch[407/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:38:53 | Train | Epoch[407/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:38:53 | Train | Epoch[407/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:38:53 | Train | Epoch[407/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:38:53 | Train | Epoch[407/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:38:53 | Train | Epoch[407/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:38:53 | Train | Epoch[407/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:38:53 | Train | Epoch[407/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:38:53 | Train | Epoch[407/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:38:53 | Valid | Epoch[407/600] Iteration[001/008] Valid loss: 0.0479
2023-02-06 11:38:53 | Valid | Epoch[407/600] Iteration[002/008] Valid loss: 0.0368
2023-02-06 11:38:53 | Valid | Epoch[407/600] Iteration[003/008] Valid loss: 0.0337
2023-02-06 11:38:53 | Valid | Epoch[407/600] Iteration[004/008] Valid loss: 0.0320
2023-02-06 11:38:53 | Valid | Epoch[407/600] Iteration[005/008] Valid loss: 0.0328
2023-02-06 11:38:53 | Valid | Epoch[407/600] Iteration[006/008] Valid loss: 0.0326
2023-02-06 11:38:53 | Valid | Epoch[407/600] Iteration[007/008] Valid loss: 0.0324
2023-02-06 11:38:54 | Valid | Epoch[407/600] Iteration[008/008] Valid loss: 0.0319
2023-02-06 11:38:54 | Valid | Epoch[407/600] MIou: 0.9213540917897254
2023-02-06 11:38:54 | Valid | Epoch[407/600] Pixel Accuracy: 0.9868939717610677
2023-02-06 11:38:54 | Valid | Epoch[407/600] Mean Pixel Accuracy: 0.9338680256880278
2023-02-06 11:38:54 | Stage | Epoch[407/600] Train loss:0.0202
2023-02-06 11:38:54 | Stage | Epoch[407/600] Valid loss:0.0319
2023-02-06 11:38:54 | Stage | Epoch[407/600] LR:0.001

2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[004/030] Train loss: 0.0195
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[011/030] Train loss: 0.0204
2023-02-06 11:38:54 | Train | Epoch[408/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:38:55 | Train | Epoch[408/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:38:56 | Valid | Epoch[408/600] Iteration[001/008] Valid loss: 0.0566
2023-02-06 11:38:56 | Valid | Epoch[408/600] Iteration[002/008] Valid loss: 0.0407
2023-02-06 11:38:56 | Valid | Epoch[408/600] Iteration[003/008] Valid loss: 0.0363
2023-02-06 11:38:56 | Valid | Epoch[408/600] Iteration[004/008] Valid loss: 0.0348
2023-02-06 11:38:56 | Valid | Epoch[408/600] Iteration[005/008] Valid loss: 0.0359
2023-02-06 11:38:56 | Valid | Epoch[408/600] Iteration[006/008] Valid loss: 0.0358
2023-02-06 11:38:56 | Valid | Epoch[408/600] Iteration[007/008] Valid loss: 0.0363
2023-02-06 11:38:56 | Valid | Epoch[408/600] Iteration[008/008] Valid loss: 0.0352
2023-02-06 11:38:56 | Valid | Epoch[408/600] MIou: 0.9313521979611519
2023-02-06 11:38:56 | Valid | Epoch[408/600] Pixel Accuracy: 0.9884910583496094
2023-02-06 11:38:56 | Valid | Epoch[408/600] Mean Pixel Accuracy: 0.9458543586803497
2023-02-06 11:38:56 | Stage | Epoch[408/600] Train loss:0.0200
2023-02-06 11:38:56 | Stage | Epoch[408/600] Valid loss:0.0352
2023-02-06 11:38:56 | Stage | Epoch[408/600] LR:0.001

2023-02-06 11:38:56 | Train | Epoch[409/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 11:38:56 | Train | Epoch[409/600] Iteration[002/030] Train loss: 0.0205
2023-02-06 11:38:56 | Train | Epoch[409/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:38:56 | Train | Epoch[409/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:38:56 | Train | Epoch[409/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:38:56 | Train | Epoch[409/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:38:56 | Train | Epoch[409/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:38:57 | Train | Epoch[409/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:38:58 | Train | Epoch[409/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:38:58 | Train | Epoch[409/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:38:58 | Train | Epoch[409/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:38:58 | Valid | Epoch[409/600] Iteration[001/008] Valid loss: 0.0419
2023-02-06 11:38:58 | Valid | Epoch[409/600] Iteration[002/008] Valid loss: 0.0351
2023-02-06 11:38:58 | Valid | Epoch[409/600] Iteration[003/008] Valid loss: 0.0333
2023-02-06 11:38:58 | Valid | Epoch[409/600] Iteration[004/008] Valid loss: 0.0318
2023-02-06 11:38:58 | Valid | Epoch[409/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 11:38:58 | Valid | Epoch[409/600] Iteration[006/008] Valid loss: 0.0322
2023-02-06 11:38:58 | Valid | Epoch[409/600] Iteration[007/008] Valid loss: 0.0316
2023-02-06 11:38:58 | Valid | Epoch[409/600] Iteration[008/008] Valid loss: 0.0315
2023-02-06 11:38:58 | Valid | Epoch[409/600] MIou: 0.9078425939144437
2023-02-06 11:38:58 | Valid | Epoch[409/600] Pixel Accuracy: 0.9847259521484375
2023-02-06 11:38:58 | Valid | Epoch[409/600] Mean Pixel Accuracy: 0.9189999925935699
2023-02-06 11:38:58 | Stage | Epoch[409/600] Train loss:0.0201
2023-02-06 11:38:58 | Stage | Epoch[409/600] Valid loss:0.0315
2023-02-06 11:38:58 | Stage | Epoch[409/600] LR:0.001

2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[001/030] Train loss: 0.0205
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[003/030] Train loss: 0.0201
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[004/030] Train loss: 0.0201
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[006/030] Train loss: 0.0204
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[018/030] Train loss: 0.0194
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[019/030] Train loss: 0.0194
2023-02-06 11:38:59 | Train | Epoch[410/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 11:39:00 | Train | Epoch[410/600] Iteration[021/030] Train loss: 0.0195
2023-02-06 11:39:00 | Train | Epoch[410/600] Iteration[022/030] Train loss: 0.0194
2023-02-06 11:39:00 | Train | Epoch[410/600] Iteration[023/030] Train loss: 0.0194
2023-02-06 11:39:00 | Train | Epoch[410/600] Iteration[024/030] Train loss: 0.0195
2023-02-06 11:39:00 | Train | Epoch[410/600] Iteration[025/030] Train loss: 0.0196
2023-02-06 11:39:00 | Train | Epoch[410/600] Iteration[026/030] Train loss: 0.0196
2023-02-06 11:39:00 | Train | Epoch[410/600] Iteration[027/030] Train loss: 0.0197
2023-02-06 11:39:00 | Train | Epoch[410/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 11:39:00 | Train | Epoch[410/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:39:00 | Train | Epoch[410/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:39:00 | Valid | Epoch[410/600] Iteration[001/008] Valid loss: 0.0743
2023-02-06 11:39:00 | Valid | Epoch[410/600] Iteration[002/008] Valid loss: 0.0507
2023-02-06 11:39:00 | Valid | Epoch[410/600] Iteration[003/008] Valid loss: 0.0438
2023-02-06 11:39:00 | Valid | Epoch[410/600] Iteration[004/008] Valid loss: 0.0432
2023-02-06 11:39:00 | Valid | Epoch[410/600] Iteration[005/008] Valid loss: 0.0450
2023-02-06 11:39:00 | Valid | Epoch[410/600] Iteration[006/008] Valid loss: 0.0446
2023-02-06 11:39:00 | Valid | Epoch[410/600] Iteration[007/008] Valid loss: 0.0463
2023-02-06 11:39:00 | Valid | Epoch[410/600] Iteration[008/008] Valid loss: 0.0443
2023-02-06 11:39:01 | Valid | Epoch[410/600] MIou: 0.9398214547747603
2023-02-06 11:39:01 | Valid | Epoch[410/600] Pixel Accuracy: 0.9897969563802084
2023-02-06 11:39:01 | Valid | Epoch[410/600] Mean Pixel Accuracy: 0.9589360553817264
2023-02-06 11:39:01 | Stage | Epoch[410/600] Train loss:0.0200
2023-02-06 11:39:01 | Stage | Epoch[410/600] Valid loss:0.0443
2023-02-06 11:39:01 | Stage | Epoch[410/600] LR:0.001

2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[001/030] Train loss: 0.0208
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[006/030] Train loss: 0.0199
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[011/030] Train loss: 0.0204
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:39:01 | Train | Epoch[411/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:39:02 | Train | Epoch[411/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:39:03 | Valid | Epoch[411/600] Iteration[001/008] Valid loss: 0.0542
2023-02-06 11:39:03 | Valid | Epoch[411/600] Iteration[002/008] Valid loss: 0.0396
2023-02-06 11:39:03 | Valid | Epoch[411/600] Iteration[003/008] Valid loss: 0.0354
2023-02-06 11:39:03 | Valid | Epoch[411/600] Iteration[004/008] Valid loss: 0.0339
2023-02-06 11:39:03 | Valid | Epoch[411/600] Iteration[005/008] Valid loss: 0.0350
2023-02-06 11:39:03 | Valid | Epoch[411/600] Iteration[006/008] Valid loss: 0.0350
2023-02-06 11:39:03 | Valid | Epoch[411/600] Iteration[007/008] Valid loss: 0.0353
2023-02-06 11:39:03 | Valid | Epoch[411/600] Iteration[008/008] Valid loss: 0.0343
2023-02-06 11:39:03 | Valid | Epoch[411/600] MIou: 0.9289765975075012
2023-02-06 11:39:03 | Valid | Epoch[411/600] Pixel Accuracy: 0.9881121317545573
2023-02-06 11:39:03 | Valid | Epoch[411/600] Mean Pixel Accuracy: 0.9429070007696622
2023-02-06 11:39:03 | Stage | Epoch[411/600] Train loss:0.0201
2023-02-06 11:39:03 | Stage | Epoch[411/600] Valid loss:0.0343
2023-02-06 11:39:03 | Stage | Epoch[411/600] LR:0.001

2023-02-06 11:39:03 | Train | Epoch[412/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 11:39:03 | Train | Epoch[412/600] Iteration[002/030] Train loss: 0.0212
2023-02-06 11:39:03 | Train | Epoch[412/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:39:03 | Train | Epoch[412/600] Iteration[004/030] Train loss: 0.0217
2023-02-06 11:39:03 | Train | Epoch[412/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 11:39:03 | Train | Epoch[412/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:39:03 | Train | Epoch[412/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:39:04 | Train | Epoch[412/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:39:05 | Train | Epoch[412/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:39:05 | Train | Epoch[412/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:39:05 | Valid | Epoch[412/600] Iteration[001/008] Valid loss: 0.0604
2023-02-06 11:39:05 | Valid | Epoch[412/600] Iteration[002/008] Valid loss: 0.0430
2023-02-06 11:39:05 | Valid | Epoch[412/600] Iteration[003/008] Valid loss: 0.0379
2023-02-06 11:39:05 | Valid | Epoch[412/600] Iteration[004/008] Valid loss: 0.0367
2023-02-06 11:39:05 | Valid | Epoch[412/600] Iteration[005/008] Valid loss: 0.0382
2023-02-06 11:39:05 | Valid | Epoch[412/600] Iteration[006/008] Valid loss: 0.0381
2023-02-06 11:39:05 | Valid | Epoch[412/600] Iteration[007/008] Valid loss: 0.0388
2023-02-06 11:39:05 | Valid | Epoch[412/600] Iteration[008/008] Valid loss: 0.0374
2023-02-06 11:39:05 | Valid | Epoch[412/600] MIou: 0.9340189598225759
2023-02-06 11:39:05 | Valid | Epoch[412/600] Pixel Accuracy: 0.9889043172200521
2023-02-06 11:39:05 | Valid | Epoch[412/600] Mean Pixel Accuracy: 0.9497272745000553
2023-02-06 11:39:05 | Stage | Epoch[412/600] Train loss:0.0202
2023-02-06 11:39:05 | Stage | Epoch[412/600] Valid loss:0.0374
2023-02-06 11:39:05 | Stage | Epoch[412/600] LR:0.001

2023-02-06 11:39:05 | Train | Epoch[413/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[002/030] Train loss: 0.0191
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[003/030] Train loss: 0.0201
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:39:06 | Train | Epoch[413/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:39:07 | Train | Epoch[413/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:39:07 | Train | Epoch[413/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:39:07 | Train | Epoch[413/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:39:07 | Train | Epoch[413/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:39:07 | Train | Epoch[413/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:39:07 | Train | Epoch[413/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:39:07 | Train | Epoch[413/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:39:07 | Train | Epoch[413/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:39:07 | Train | Epoch[413/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:39:07 | Valid | Epoch[413/600] Iteration[001/008] Valid loss: 0.0563
2023-02-06 11:39:07 | Valid | Epoch[413/600] Iteration[002/008] Valid loss: 0.0407
2023-02-06 11:39:07 | Valid | Epoch[413/600] Iteration[003/008] Valid loss: 0.0362
2023-02-06 11:39:07 | Valid | Epoch[413/600] Iteration[004/008] Valid loss: 0.0347
2023-02-06 11:39:07 | Valid | Epoch[413/600] Iteration[005/008] Valid loss: 0.0357
2023-02-06 11:39:07 | Valid | Epoch[413/600] Iteration[006/008] Valid loss: 0.0357
2023-02-06 11:39:07 | Valid | Epoch[413/600] Iteration[007/008] Valid loss: 0.0362
2023-02-06 11:39:07 | Valid | Epoch[413/600] Iteration[008/008] Valid loss: 0.0351
2023-02-06 11:39:08 | Valid | Epoch[413/600] MIou: 0.9315071834650865
2023-02-06 11:39:08 | Valid | Epoch[413/600] Pixel Accuracy: 0.9885152180989584
2023-02-06 11:39:08 | Valid | Epoch[413/600] Mean Pixel Accuracy: 0.9460705329973669
2023-02-06 11:39:08 | Stage | Epoch[413/600] Train loss:0.0203
2023-02-06 11:39:08 | Stage | Epoch[413/600] Valid loss:0.0351
2023-02-06 11:39:08 | Stage | Epoch[413/600] LR:0.001

2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[007/030] Train loss: 0.0200
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:39:08 | Train | Epoch[414/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:39:09 | Train | Epoch[414/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:39:10 | Valid | Epoch[414/600] Iteration[001/008] Valid loss: 0.0463
2023-02-06 11:39:10 | Valid | Epoch[414/600] Iteration[002/008] Valid loss: 0.0363
2023-02-06 11:39:10 | Valid | Epoch[414/600] Iteration[003/008] Valid loss: 0.0335
2023-02-06 11:39:10 | Valid | Epoch[414/600] Iteration[004/008] Valid loss: 0.0318
2023-02-06 11:39:10 | Valid | Epoch[414/600] Iteration[005/008] Valid loss: 0.0324
2023-02-06 11:39:10 | Valid | Epoch[414/600] Iteration[006/008] Valid loss: 0.0323
2023-02-06 11:39:10 | Valid | Epoch[414/600] Iteration[007/008] Valid loss: 0.0321
2023-02-06 11:39:10 | Valid | Epoch[414/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 11:39:10 | Valid | Epoch[414/600] MIou: 0.9187494998026414
2023-02-06 11:39:10 | Valid | Epoch[414/600] Pixel Accuracy: 0.9864883422851562
2023-02-06 11:39:10 | Valid | Epoch[414/600] Mean Pixel Accuracy: 0.930538243387469
2023-02-06 11:39:10 | Stage | Epoch[414/600] Train loss:0.0202
2023-02-06 11:39:10 | Stage | Epoch[414/600] Valid loss:0.0316
2023-02-06 11:39:10 | Stage | Epoch[414/600] LR:0.001

2023-02-06 11:39:10 | Train | Epoch[415/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:39:10 | Train | Epoch[415/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 11:39:10 | Train | Epoch[415/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:39:10 | Train | Epoch[415/600] Iteration[004/030] Train loss: 0.0219
2023-02-06 11:39:10 | Train | Epoch[415/600] Iteration[005/030] Train loss: 0.0212
2023-02-06 11:39:10 | Train | Epoch[415/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:39:10 | Train | Epoch[415/600] Iteration[007/030] Train loss: 0.0204
2023-02-06 11:39:10 | Train | Epoch[415/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:39:11 | Train | Epoch[415/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:39:12 | Train | Epoch[415/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:39:12 | Valid | Epoch[415/600] Iteration[001/008] Valid loss: 0.0460
2023-02-06 11:39:12 | Valid | Epoch[415/600] Iteration[002/008] Valid loss: 0.0363
2023-02-06 11:39:12 | Valid | Epoch[415/600] Iteration[003/008] Valid loss: 0.0335
2023-02-06 11:39:12 | Valid | Epoch[415/600] Iteration[004/008] Valid loss: 0.0318
2023-02-06 11:39:12 | Valid | Epoch[415/600] Iteration[005/008] Valid loss: 0.0326
2023-02-06 11:39:12 | Valid | Epoch[415/600] Iteration[006/008] Valid loss: 0.0323
2023-02-06 11:39:12 | Valid | Epoch[415/600] Iteration[007/008] Valid loss: 0.0320
2023-02-06 11:39:12 | Valid | Epoch[415/600] Iteration[008/008] Valid loss: 0.0315
2023-02-06 11:39:12 | Valid | Epoch[415/600] MIou: 0.9183265197587651
2023-02-06 11:39:12 | Valid | Epoch[415/600] Pixel Accuracy: 0.9864158630371094
2023-02-06 11:39:12 | Valid | Epoch[415/600] Mean Pixel Accuracy: 0.9302130844835337
2023-02-06 11:39:12 | Stage | Epoch[415/600] Train loss:0.0202
2023-02-06 11:39:12 | Stage | Epoch[415/600] Valid loss:0.0315
2023-02-06 11:39:12 | Stage | Epoch[415/600] LR:0.001

2023-02-06 11:39:12 | Train | Epoch[416/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 11:39:12 | Train | Epoch[416/600] Iteration[002/030] Train loss: 0.0210
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[007/030] Train loss: 0.0204
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[013/030] Train loss: 0.0207
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[015/030] Train loss: 0.0207
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[017/030] Train loss: 0.0206
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[018/030] Train loss: 0.0207
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[020/030] Train loss: 0.0207
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[021/030] Train loss: 0.0207
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[022/030] Train loss: 0.0206
2023-02-06 11:39:13 | Train | Epoch[416/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:39:14 | Train | Epoch[416/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:39:14 | Train | Epoch[416/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:39:14 | Train | Epoch[416/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:39:14 | Train | Epoch[416/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:39:14 | Train | Epoch[416/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:39:14 | Train | Epoch[416/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:39:14 | Train | Epoch[416/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:39:14 | Valid | Epoch[416/600] Iteration[001/008] Valid loss: 0.0846
2023-02-06 11:39:14 | Valid | Epoch[416/600] Iteration[002/008] Valid loss: 0.0570
2023-02-06 11:39:14 | Valid | Epoch[416/600] Iteration[003/008] Valid loss: 0.0490
2023-02-06 11:39:14 | Valid | Epoch[416/600] Iteration[004/008] Valid loss: 0.0489
2023-02-06 11:39:14 | Valid | Epoch[416/600] Iteration[005/008] Valid loss: 0.0513
2023-02-06 11:39:14 | Valid | Epoch[416/600] Iteration[006/008] Valid loss: 0.0512
2023-02-06 11:39:14 | Valid | Epoch[416/600] Iteration[007/008] Valid loss: 0.0535
2023-02-06 11:39:14 | Valid | Epoch[416/600] Iteration[008/008] Valid loss: 0.0511
2023-02-06 11:39:14 | Valid | Epoch[416/600] MIou: 0.9415793500768959
2023-02-06 11:39:14 | Valid | Epoch[416/600] Pixel Accuracy: 0.9900372823079427
2023-02-06 11:39:14 | Valid | Epoch[416/600] Mean Pixel Accuracy: 0.9633035837313315
2023-02-06 11:39:14 | Stage | Epoch[416/600] Train loss:0.0203
2023-02-06 11:39:14 | Stage | Epoch[416/600] Valid loss:0.0511
2023-02-06 11:39:14 | Stage | Epoch[416/600] LR:0.001

2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[001/030] Train loss: 0.0192
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[002/030] Train loss: 0.0212
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[014/030] Train loss: 0.0210
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:39:15 | Train | Epoch[417/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:39:16 | Train | Epoch[417/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:39:16 | Valid | Epoch[417/600] Iteration[001/008] Valid loss: 0.0408
2023-02-06 11:39:16 | Valid | Epoch[417/600] Iteration[002/008] Valid loss: 0.0361
2023-02-06 11:39:16 | Valid | Epoch[417/600] Iteration[003/008] Valid loss: 0.0351
2023-02-06 11:39:17 | Valid | Epoch[417/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:39:17 | Valid | Epoch[417/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 11:39:17 | Valid | Epoch[417/600] Iteration[006/008] Valid loss: 0.0337
2023-02-06 11:39:17 | Valid | Epoch[417/600] Iteration[007/008] Valid loss: 0.0329
2023-02-06 11:39:17 | Valid | Epoch[417/600] Iteration[008/008] Valid loss: 0.0330
2023-02-06 11:39:17 | Valid | Epoch[417/600] MIou: 0.8954915166579236
2023-02-06 11:39:17 | Valid | Epoch[417/600] Pixel Accuracy: 0.982733408610026
2023-02-06 11:39:17 | Valid | Epoch[417/600] Mean Pixel Accuracy: 0.9062890618748023
2023-02-06 11:39:17 | Stage | Epoch[417/600] Train loss:0.0202
2023-02-06 11:39:17 | Stage | Epoch[417/600] Valid loss:0.0330
2023-02-06 11:39:17 | Stage | Epoch[417/600] LR:0.001

2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[003/030] Train loss: 0.0201
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[006/030] Train loss: 0.0191
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[010/030] Train loss: 0.0191
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[011/030] Train loss: 0.0192
2023-02-06 11:39:17 | Train | Epoch[418/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[014/030] Train loss: 0.0194
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:39:18 | Train | Epoch[418/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:39:19 | Valid | Epoch[418/600] Iteration[001/008] Valid loss: 0.0606
2023-02-06 11:39:19 | Valid | Epoch[418/600] Iteration[002/008] Valid loss: 0.0429
2023-02-06 11:39:19 | Valid | Epoch[418/600] Iteration[003/008] Valid loss: 0.0378
2023-02-06 11:39:19 | Valid | Epoch[418/600] Iteration[004/008] Valid loss: 0.0367
2023-02-06 11:39:19 | Valid | Epoch[418/600] Iteration[005/008] Valid loss: 0.0382
2023-02-06 11:39:19 | Valid | Epoch[418/600] Iteration[006/008] Valid loss: 0.0379
2023-02-06 11:39:19 | Valid | Epoch[418/600] Iteration[007/008] Valid loss: 0.0387
2023-02-06 11:39:19 | Valid | Epoch[418/600] Iteration[008/008] Valid loss: 0.0373
2023-02-06 11:39:19 | Valid | Epoch[418/600] MIou: 0.9343286372463195
2023-02-06 11:39:19 | Valid | Epoch[418/600] Pixel Accuracy: 0.9889564514160156
2023-02-06 11:39:19 | Valid | Epoch[418/600] Mean Pixel Accuracy: 0.950015889009622
2023-02-06 11:39:19 | Stage | Epoch[418/600] Train loss:0.0201
2023-02-06 11:39:19 | Stage | Epoch[418/600] Valid loss:0.0373
2023-02-06 11:39:19 | Stage | Epoch[418/600] LR:0.001

2023-02-06 11:39:19 | Train | Epoch[419/600] Iteration[001/030] Train loss: 0.0176
2023-02-06 11:39:19 | Train | Epoch[419/600] Iteration[002/030] Train loss: 0.0185
2023-02-06 11:39:19 | Train | Epoch[419/600] Iteration[003/030] Train loss: 0.0185
2023-02-06 11:39:19 | Train | Epoch[419/600] Iteration[004/030] Train loss: 0.0185
2023-02-06 11:39:19 | Train | Epoch[419/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 11:39:19 | Train | Epoch[419/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:39:19 | Train | Epoch[419/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[022/030] Train loss: 0.0206
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[023/030] Train loss: 0.0206
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[024/030] Train loss: 0.0207
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[025/030] Train loss: 0.0205
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[026/030] Train loss: 0.0205
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[027/030] Train loss: 0.0205
2023-02-06 11:39:20 | Train | Epoch[419/600] Iteration[028/030] Train loss: 0.0205
2023-02-06 11:39:21 | Train | Epoch[419/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:39:21 | Train | Epoch[419/600] Iteration[030/030] Train loss: 0.0205
2023-02-06 11:39:21 | Valid | Epoch[419/600] Iteration[001/008] Valid loss: 0.0740
2023-02-06 11:39:21 | Valid | Epoch[419/600] Iteration[002/008] Valid loss: 0.0508
2023-02-06 11:39:21 | Valid | Epoch[419/600] Iteration[003/008] Valid loss: 0.0439
2023-02-06 11:39:21 | Valid | Epoch[419/600] Iteration[004/008] Valid loss: 0.0436
2023-02-06 11:39:21 | Valid | Epoch[419/600] Iteration[005/008] Valid loss: 0.0455
2023-02-06 11:39:21 | Valid | Epoch[419/600] Iteration[006/008] Valid loss: 0.0453
2023-02-06 11:39:21 | Valid | Epoch[419/600] Iteration[007/008] Valid loss: 0.0470
2023-02-06 11:39:21 | Valid | Epoch[419/600] Iteration[008/008] Valid loss: 0.0449
2023-02-06 11:39:21 | Valid | Epoch[419/600] MIou: 0.9400370989500442
2023-02-06 11:39:21 | Valid | Epoch[419/600] Pixel Accuracy: 0.9898325602213541
2023-02-06 11:39:21 | Valid | Epoch[419/600] Mean Pixel Accuracy: 0.9591838817457221
2023-02-06 11:39:21 | Stage | Epoch[419/600] Train loss:0.0205
2023-02-06 11:39:21 | Stage | Epoch[419/600] Valid loss:0.0449
2023-02-06 11:39:21 | Stage | Epoch[419/600] LR:0.001

2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[001/030] Train loss: 0.0207
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[004/030] Train loss: 0.0195
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:39:22 | Train | Epoch[420/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:39:23 | Train | Epoch[420/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:39:23 | Train | Epoch[420/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:39:23 | Train | Epoch[420/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:39:23 | Train | Epoch[420/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:39:23 | Train | Epoch[420/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:39:23 | Train | Epoch[420/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:39:23 | Train | Epoch[420/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:39:23 | Train | Epoch[420/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:39:23 | Train | Epoch[420/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:39:23 | Valid | Epoch[420/600] Iteration[001/008] Valid loss: 0.0432
2023-02-06 11:39:23 | Valid | Epoch[420/600] Iteration[002/008] Valid loss: 0.0410
2023-02-06 11:39:23 | Valid | Epoch[420/600] Iteration[003/008] Valid loss: 0.0407
2023-02-06 11:39:23 | Valid | Epoch[420/600] Iteration[004/008] Valid loss: 0.0390
2023-02-06 11:39:23 | Valid | Epoch[420/600] Iteration[005/008] Valid loss: 0.0397
2023-02-06 11:39:23 | Valid | Epoch[420/600] Iteration[006/008] Valid loss: 0.0391
2023-02-06 11:39:23 | Valid | Epoch[420/600] Iteration[007/008] Valid loss: 0.0378
2023-02-06 11:39:23 | Valid | Epoch[420/600] Iteration[008/008] Valid loss: 0.0385
2023-02-06 11:39:24 | Valid | Epoch[420/600] MIou: 0.8685702821967609
2023-02-06 11:39:24 | Valid | Epoch[420/600] Pixel Accuracy: 0.978326161702474
2023-02-06 11:39:24 | Valid | Epoch[420/600] Mean Pixel Accuracy: 0.8807429514053221
2023-02-06 11:39:24 | Stage | Epoch[420/600] Train loss:0.0203
2023-02-06 11:39:24 | Stage | Epoch[420/600] Valid loss:0.0385
2023-02-06 11:39:24 | Stage | Epoch[420/600] LR:0.001

2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:39:24 | Train | Epoch[421/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:39:25 | Train | Epoch[421/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:39:26 | Valid | Epoch[421/600] Iteration[001/008] Valid loss: 0.0621
2023-02-06 11:39:26 | Valid | Epoch[421/600] Iteration[002/008] Valid loss: 0.0437
2023-02-06 11:39:26 | Valid | Epoch[421/600] Iteration[003/008] Valid loss: 0.0383
2023-02-06 11:39:26 | Valid | Epoch[421/600] Iteration[004/008] Valid loss: 0.0373
2023-02-06 11:39:26 | Valid | Epoch[421/600] Iteration[005/008] Valid loss: 0.0386
2023-02-06 11:39:26 | Valid | Epoch[421/600] Iteration[006/008] Valid loss: 0.0383
2023-02-06 11:39:26 | Valid | Epoch[421/600] Iteration[007/008] Valid loss: 0.0390
2023-02-06 11:39:26 | Valid | Epoch[421/600] Iteration[008/008] Valid loss: 0.0377
2023-02-06 11:39:26 | Valid | Epoch[421/600] MIou: 0.935165885355158
2023-02-06 11:39:26 | Valid | Epoch[421/600] Pixel Accuracy: 0.9890874226888021
2023-02-06 11:39:26 | Valid | Epoch[421/600] Mean Pixel Accuracy: 0.9512101398645731
2023-02-06 11:39:26 | Stage | Epoch[421/600] Train loss:0.0200
2023-02-06 11:39:26 | Stage | Epoch[421/600] Valid loss:0.0377
2023-02-06 11:39:26 | Stage | Epoch[421/600] LR:0.001

2023-02-06 11:39:26 | Train | Epoch[422/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 11:39:26 | Train | Epoch[422/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:39:26 | Train | Epoch[422/600] Iteration[003/030] Train loss: 0.0212
2023-02-06 11:39:26 | Train | Epoch[422/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:39:26 | Train | Epoch[422/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:39:26 | Train | Epoch[422/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:39:26 | Train | Epoch[422/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[010/030] Train loss: 0.0199
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[027/030] Train loss: 0.0204
2023-02-06 11:39:27 | Train | Epoch[422/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:39:28 | Train | Epoch[422/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:39:28 | Train | Epoch[422/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:39:28 | Valid | Epoch[422/600] Iteration[001/008] Valid loss: 0.0509
2023-02-06 11:39:28 | Valid | Epoch[422/600] Iteration[002/008] Valid loss: 0.0381
2023-02-06 11:39:28 | Valid | Epoch[422/600] Iteration[003/008] Valid loss: 0.0344
2023-02-06 11:39:28 | Valid | Epoch[422/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:39:28 | Valid | Epoch[422/600] Iteration[005/008] Valid loss: 0.0338
2023-02-06 11:39:28 | Valid | Epoch[422/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 11:39:28 | Valid | Epoch[422/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 11:39:28 | Valid | Epoch[422/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:39:28 | Valid | Epoch[422/600] MIou: 0.9261374897467929
2023-02-06 11:39:28 | Valid | Epoch[422/600] Pixel Accuracy: 0.9876683553059896
2023-02-06 11:39:28 | Valid | Epoch[422/600] Mean Pixel Accuracy: 0.9391314396746931
2023-02-06 11:39:28 | Stage | Epoch[422/600] Train loss:0.0201
2023-02-06 11:39:28 | Stage | Epoch[422/600] Valid loss:0.0331
2023-02-06 11:39:28 | Stage | Epoch[422/600] LR:0.001

2023-02-06 11:39:28 | Train | Epoch[423/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[003/030] Train loss: 0.0193
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[004/030] Train loss: 0.0195
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:39:29 | Train | Epoch[423/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:39:30 | Train | Epoch[423/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:39:30 | Train | Epoch[423/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:39:30 | Train | Epoch[423/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:39:30 | Train | Epoch[423/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:39:30 | Train | Epoch[423/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:39:30 | Train | Epoch[423/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:39:30 | Train | Epoch[423/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:39:30 | Train | Epoch[423/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:39:30 | Valid | Epoch[423/600] Iteration[001/008] Valid loss: 0.0804
2023-02-06 11:39:30 | Valid | Epoch[423/600] Iteration[002/008] Valid loss: 0.0547
2023-02-06 11:39:30 | Valid | Epoch[423/600] Iteration[003/008] Valid loss: 0.0470
2023-02-06 11:39:30 | Valid | Epoch[423/600] Iteration[004/008] Valid loss: 0.0464
2023-02-06 11:39:30 | Valid | Epoch[423/600] Iteration[005/008] Valid loss: 0.0487
2023-02-06 11:39:30 | Valid | Epoch[423/600] Iteration[006/008] Valid loss: 0.0482
2023-02-06 11:39:30 | Valid | Epoch[423/600] Iteration[007/008] Valid loss: 0.0501
2023-02-06 11:39:30 | Valid | Epoch[423/600] Iteration[008/008] Valid loss: 0.0480
2023-02-06 11:39:30 | Valid | Epoch[423/600] MIou: 0.9412802609768101
2023-02-06 11:39:30 | Valid | Epoch[423/600] Pixel Accuracy: 0.9900016784667969
2023-02-06 11:39:30 | Valid | Epoch[423/600] Mean Pixel Accuracy: 0.9623012412573984
2023-02-06 11:39:30 | Stage | Epoch[423/600] Train loss:0.0202
2023-02-06 11:39:30 | Stage | Epoch[423/600] Valid loss:0.0480
2023-02-06 11:39:30 | Stage | Epoch[423/600] LR:0.001

2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[001/030] Train loss: 0.0164
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[002/030] Train loss: 0.0171
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[003/030] Train loss: 0.0185
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 11:39:31 | Train | Epoch[424/600] Iteration[017/030] Train loss: 0.0196
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:39:32 | Train | Epoch[424/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:39:32 | Valid | Epoch[424/600] Iteration[001/008] Valid loss: 0.0444
2023-02-06 11:39:32 | Valid | Epoch[424/600] Iteration[002/008] Valid loss: 0.0358
2023-02-06 11:39:32 | Valid | Epoch[424/600] Iteration[003/008] Valid loss: 0.0335
2023-02-06 11:39:33 | Valid | Epoch[424/600] Iteration[004/008] Valid loss: 0.0319
2023-02-06 11:39:33 | Valid | Epoch[424/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 11:39:33 | Valid | Epoch[424/600] Iteration[006/008] Valid loss: 0.0323
2023-02-06 11:39:33 | Valid | Epoch[424/600] Iteration[007/008] Valid loss: 0.0318
2023-02-06 11:39:33 | Valid | Epoch[424/600] Iteration[008/008] Valid loss: 0.0315
2023-02-06 11:39:33 | Valid | Epoch[424/600] MIou: 0.9134402637903858
2023-02-06 11:39:33 | Valid | Epoch[424/600] Pixel Accuracy: 0.9856313069661459
2023-02-06 11:39:33 | Valid | Epoch[424/600] Mean Pixel Accuracy: 0.9248426316985148
2023-02-06 11:39:33 | Stage | Epoch[424/600] Train loss:0.0200
2023-02-06 11:39:33 | Stage | Epoch[424/600] Valid loss:0.0315
2023-02-06 11:39:33 | Stage | Epoch[424/600] LR:0.001

2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[003/030] Train loss: 0.0201
2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[006/030] Train loss: 0.0209
2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:39:33 | Train | Epoch[425/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[028/030] Train loss: 0.0204
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:39:34 | Train | Epoch[425/600] Iteration[030/030] Train loss: 0.0204
2023-02-06 11:39:35 | Valid | Epoch[425/600] Iteration[001/008] Valid loss: 0.0419
2023-02-06 11:39:35 | Valid | Epoch[425/600] Iteration[002/008] Valid loss: 0.0359
2023-02-06 11:39:35 | Valid | Epoch[425/600] Iteration[003/008] Valid loss: 0.0343
2023-02-06 11:39:35 | Valid | Epoch[425/600] Iteration[004/008] Valid loss: 0.0327
2023-02-06 11:39:35 | Valid | Epoch[425/600] Iteration[005/008] Valid loss: 0.0333
2023-02-06 11:39:35 | Valid | Epoch[425/600] Iteration[006/008] Valid loss: 0.0329
2023-02-06 11:39:35 | Valid | Epoch[425/600] Iteration[007/008] Valid loss: 0.0322
2023-02-06 11:39:35 | Valid | Epoch[425/600] Iteration[008/008] Valid loss: 0.0322
2023-02-06 11:39:35 | Valid | Epoch[425/600] MIou: 0.9022260431608877
2023-02-06 11:39:35 | Valid | Epoch[425/600] Pixel Accuracy: 0.9838205973307291
2023-02-06 11:39:35 | Valid | Epoch[425/600] Mean Pixel Accuracy: 0.913151013017113
2023-02-06 11:39:35 | Stage | Epoch[425/600] Train loss:0.0204
2023-02-06 11:39:35 | Stage | Epoch[425/600] Valid loss:0.0322
2023-02-06 11:39:35 | Stage | Epoch[425/600] LR:0.001

2023-02-06 11:39:35 | Train | Epoch[426/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 11:39:35 | Train | Epoch[426/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 11:39:35 | Train | Epoch[426/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:39:35 | Train | Epoch[426/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:39:35 | Train | Epoch[426/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:39:35 | Train | Epoch[426/600] Iteration[006/030] Train loss: 0.0190
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[020/030] Train loss: 0.0206
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[021/030] Train loss: 0.0207
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[025/030] Train loss: 0.0205
2023-02-06 11:39:36 | Train | Epoch[426/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:39:37 | Train | Epoch[426/600] Iteration[027/030] Train loss: 0.0205
2023-02-06 11:39:37 | Train | Epoch[426/600] Iteration[028/030] Train loss: 0.0205
2023-02-06 11:39:37 | Train | Epoch[426/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:39:37 | Train | Epoch[426/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:39:37 | Valid | Epoch[426/600] Iteration[001/008] Valid loss: 0.0518
2023-02-06 11:39:37 | Valid | Epoch[426/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:39:37 | Valid | Epoch[426/600] Iteration[003/008] Valid loss: 0.0348
2023-02-06 11:39:37 | Valid | Epoch[426/600] Iteration[004/008] Valid loss: 0.0334
2023-02-06 11:39:37 | Valid | Epoch[426/600] Iteration[005/008] Valid loss: 0.0344
2023-02-06 11:39:37 | Valid | Epoch[426/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:39:37 | Valid | Epoch[426/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 11:39:37 | Valid | Epoch[426/600] Iteration[008/008] Valid loss: 0.0337
2023-02-06 11:39:37 | Valid | Epoch[426/600] MIou: 0.9278890767611938
2023-02-06 11:39:37 | Valid | Epoch[426/600] Pixel Accuracy: 0.987939198811849
2023-02-06 11:39:37 | Valid | Epoch[426/600] Mean Pixel Accuracy: 0.9415565360895463
2023-02-06 11:39:37 | Stage | Epoch[426/600] Train loss:0.0203
2023-02-06 11:39:37 | Stage | Epoch[426/600] Valid loss:0.0337
2023-02-06 11:39:37 | Stage | Epoch[426/600] LR:0.001

2023-02-06 11:39:37 | Train | Epoch[427/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[003/030] Train loss: 0.0197
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[009/030] Train loss: 0.0196
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[016/030] Train loss: 0.0204
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[018/030] Train loss: 0.0206
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:39:38 | Train | Epoch[427/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:39:39 | Train | Epoch[427/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:39:39 | Train | Epoch[427/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:39:39 | Train | Epoch[427/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:39:39 | Train | Epoch[427/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:39:39 | Train | Epoch[427/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:39:39 | Train | Epoch[427/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:39:39 | Train | Epoch[427/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:39:39 | Train | Epoch[427/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:39:39 | Train | Epoch[427/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:39:39 | Valid | Epoch[427/600] Iteration[001/008] Valid loss: 0.0638
2023-02-06 11:39:39 | Valid | Epoch[427/600] Iteration[002/008] Valid loss: 0.0449
2023-02-06 11:39:39 | Valid | Epoch[427/600] Iteration[003/008] Valid loss: 0.0393
2023-02-06 11:39:39 | Valid | Epoch[427/600] Iteration[004/008] Valid loss: 0.0384
2023-02-06 11:39:39 | Valid | Epoch[427/600] Iteration[005/008] Valid loss: 0.0398
2023-02-06 11:39:39 | Valid | Epoch[427/600] Iteration[006/008] Valid loss: 0.0400
2023-02-06 11:39:39 | Valid | Epoch[427/600] Iteration[007/008] Valid loss: 0.0408
2023-02-06 11:39:39 | Valid | Epoch[427/600] Iteration[008/008] Valid loss: 0.0393
2023-02-06 11:39:39 | Valid | Epoch[427/600] MIou: 0.936825706382021
2023-02-06 11:39:39 | Valid | Epoch[427/600] Pixel Accuracy: 0.989349365234375
2023-02-06 11:39:39 | Valid | Epoch[427/600] Mean Pixel Accuracy: 0.9535162154448187
2023-02-06 11:39:39 | Stage | Epoch[427/600] Train loss:0.0200
2023-02-06 11:39:39 | Stage | Epoch[427/600] Valid loss:0.0393
2023-02-06 11:39:39 | Stage | Epoch[427/600] LR:0.001

2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[001/030] Train loss: 0.0183
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[004/030] Train loss: 0.0198
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:39:40 | Train | Epoch[428/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:39:41 | Train | Epoch[428/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:39:42 | Valid | Epoch[428/600] Iteration[001/008] Valid loss: 0.0558
2023-02-06 11:39:42 | Valid | Epoch[428/600] Iteration[002/008] Valid loss: 0.0404
2023-02-06 11:39:42 | Valid | Epoch[428/600] Iteration[003/008] Valid loss: 0.0360
2023-02-06 11:39:42 | Valid | Epoch[428/600] Iteration[004/008] Valid loss: 0.0347
2023-02-06 11:39:42 | Valid | Epoch[428/600] Iteration[005/008] Valid loss: 0.0357
2023-02-06 11:39:42 | Valid | Epoch[428/600] Iteration[006/008] Valid loss: 0.0355
2023-02-06 11:39:42 | Valid | Epoch[428/600] Iteration[007/008] Valid loss: 0.0358
2023-02-06 11:39:42 | Valid | Epoch[428/600] Iteration[008/008] Valid loss: 0.0348
2023-02-06 11:39:42 | Valid | Epoch[428/600] MIou: 0.9317285439433087
2023-02-06 11:39:42 | Valid | Epoch[428/600] Pixel Accuracy: 0.9885520935058594
2023-02-06 11:39:42 | Valid | Epoch[428/600] Mean Pixel Accuracy: 0.9462873559105722
2023-02-06 11:39:42 | Stage | Epoch[428/600] Train loss:0.0201
2023-02-06 11:39:42 | Stage | Epoch[428/600] Valid loss:0.0348
2023-02-06 11:39:42 | Stage | Epoch[428/600] LR:0.001

2023-02-06 11:39:42 | Train | Epoch[429/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:39:42 | Train | Epoch[429/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:39:42 | Train | Epoch[429/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:39:42 | Train | Epoch[429/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:39:42 | Train | Epoch[429/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:39:42 | Train | Epoch[429/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:39:42 | Train | Epoch[429/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:39:42 | Train | Epoch[429/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:39:42 | Train | Epoch[429/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[013/030] Train loss: 0.0206
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[015/030] Train loss: 0.0206
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[016/030] Train loss: 0.0204
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[023/030] Train loss: 0.0206
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:39:43 | Train | Epoch[429/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:39:44 | Train | Epoch[429/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:39:44 | Valid | Epoch[429/600] Iteration[001/008] Valid loss: 0.0406
2023-02-06 11:39:44 | Valid | Epoch[429/600] Iteration[002/008] Valid loss: 0.0362
2023-02-06 11:39:44 | Valid | Epoch[429/600] Iteration[003/008] Valid loss: 0.0352
2023-02-06 11:39:44 | Valid | Epoch[429/600] Iteration[004/008] Valid loss: 0.0336
2023-02-06 11:39:44 | Valid | Epoch[429/600] Iteration[005/008] Valid loss: 0.0343
2023-02-06 11:39:44 | Valid | Epoch[429/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 11:39:44 | Valid | Epoch[429/600] Iteration[007/008] Valid loss: 0.0330
2023-02-06 11:39:44 | Valid | Epoch[429/600] Iteration[008/008] Valid loss: 0.0332
2023-02-06 11:39:44 | Valid | Epoch[429/600] MIou: 0.8942374425482157
2023-02-06 11:39:44 | Valid | Epoch[429/600] Pixel Accuracy: 0.9825274149576823
2023-02-06 11:39:44 | Valid | Epoch[429/600] Mean Pixel Accuracy: 0.9051042992925158
2023-02-06 11:39:44 | Stage | Epoch[429/600] Train loss:0.0202
2023-02-06 11:39:44 | Stage | Epoch[429/600] Valid loss:0.0332
2023-02-06 11:39:44 | Stage | Epoch[429/600] LR:0.001

2023-02-06 11:39:44 | Train | Epoch[430/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:39:45 | Train | Epoch[430/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:39:46 | Train | Epoch[430/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:39:46 | Train | Epoch[430/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:39:46 | Train | Epoch[430/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:39:46 | Train | Epoch[430/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:39:46 | Train | Epoch[430/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:39:46 | Train | Epoch[430/600] Iteration[028/030] Train loss: 0.0204
2023-02-06 11:39:46 | Train | Epoch[430/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:39:46 | Train | Epoch[430/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:39:46 | Valid | Epoch[430/600] Iteration[001/008] Valid loss: 0.0672
2023-02-06 11:39:46 | Valid | Epoch[430/600] Iteration[002/008] Valid loss: 0.0466
2023-02-06 11:39:46 | Valid | Epoch[430/600] Iteration[003/008] Valid loss: 0.0406
2023-02-06 11:39:46 | Valid | Epoch[430/600] Iteration[004/008] Valid loss: 0.0397
2023-02-06 11:39:46 | Valid | Epoch[430/600] Iteration[005/008] Valid loss: 0.0415
2023-02-06 11:39:46 | Valid | Epoch[430/600] Iteration[006/008] Valid loss: 0.0413
2023-02-06 11:39:46 | Valid | Epoch[430/600] Iteration[007/008] Valid loss: 0.0423
2023-02-06 11:39:46 | Valid | Epoch[430/600] Iteration[008/008] Valid loss: 0.0407
2023-02-06 11:39:46 | Valid | Epoch[430/600] MIou: 0.9372666719221884
2023-02-06 11:39:47 | Valid | Epoch[430/600] Pixel Accuracy: 0.9894014994303385
2023-02-06 11:39:47 | Valid | Epoch[430/600] Mean Pixel Accuracy: 0.9548890505829508
2023-02-06 11:39:47 | Stage | Epoch[430/600] Train loss:0.0203
2023-02-06 11:39:47 | Stage | Epoch[430/600] Valid loss:0.0407
2023-02-06 11:39:47 | Stage | Epoch[430/600] LR:0.001

2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[001/030] Train loss: 0.0208
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[002/030] Train loss: 0.0205
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[003/030] Train loss: 0.0214
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[005/030] Train loss: 0.0209
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:39:47 | Train | Epoch[431/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:39:48 | Train | Epoch[431/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:39:49 | Valid | Epoch[431/600] Iteration[001/008] Valid loss: 0.0498
2023-02-06 11:39:49 | Valid | Epoch[431/600] Iteration[002/008] Valid loss: 0.0377
2023-02-06 11:39:49 | Valid | Epoch[431/600] Iteration[003/008] Valid loss: 0.0342
2023-02-06 11:39:49 | Valid | Epoch[431/600] Iteration[004/008] Valid loss: 0.0325
2023-02-06 11:39:49 | Valid | Epoch[431/600] Iteration[005/008] Valid loss: 0.0333
2023-02-06 11:39:49 | Valid | Epoch[431/600] Iteration[006/008] Valid loss: 0.0330
2023-02-06 11:39:49 | Valid | Epoch[431/600] Iteration[007/008] Valid loss: 0.0331
2023-02-06 11:39:49 | Valid | Epoch[431/600] Iteration[008/008] Valid loss: 0.0323
2023-02-06 11:39:49 | Valid | Epoch[431/600] MIou: 0.9244362571470062
2023-02-06 11:39:49 | Valid | Epoch[431/600] Pixel Accuracy: 0.9873987833658854
2023-02-06 11:39:49 | Valid | Epoch[431/600] Mean Pixel Accuracy: 0.9370430871567503
2023-02-06 11:39:49 | Stage | Epoch[431/600] Train loss:0.0202
2023-02-06 11:39:49 | Stage | Epoch[431/600] Valid loss:0.0323
2023-02-06 11:39:49 | Stage | Epoch[431/600] LR:0.001

2023-02-06 11:39:49 | Train | Epoch[432/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 11:39:49 | Train | Epoch[432/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:39:49 | Train | Epoch[432/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 11:39:49 | Train | Epoch[432/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:39:49 | Train | Epoch[432/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:39:49 | Train | Epoch[432/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:39:49 | Train | Epoch[432/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:39:49 | Train | Epoch[432/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:39:49 | Train | Epoch[432/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[015/030] Train loss: 0.0207
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[020/030] Train loss: 0.0206
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:39:50 | Train | Epoch[432/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:39:51 | Valid | Epoch[432/600] Iteration[001/008] Valid loss: 0.0575
2023-02-06 11:39:51 | Valid | Epoch[432/600] Iteration[002/008] Valid loss: 0.0413
2023-02-06 11:39:51 | Valid | Epoch[432/600] Iteration[003/008] Valid loss: 0.0366
2023-02-06 11:39:51 | Valid | Epoch[432/600] Iteration[004/008] Valid loss: 0.0357
2023-02-06 11:39:51 | Valid | Epoch[432/600] Iteration[005/008] Valid loss: 0.0366
2023-02-06 11:39:51 | Valid | Epoch[432/600] Iteration[006/008] Valid loss: 0.0363
2023-02-06 11:39:51 | Valid | Epoch[432/600] Iteration[007/008] Valid loss: 0.0368
2023-02-06 11:39:51 | Valid | Epoch[432/600] Iteration[008/008] Valid loss: 0.0356
2023-02-06 11:39:51 | Valid | Epoch[432/600] MIou: 0.9319633746003346
2023-02-06 11:39:51 | Valid | Epoch[432/600] Pixel Accuracy: 0.9885902404785156
2023-02-06 11:39:51 | Valid | Epoch[432/600] Mean Pixel Accuracy: 0.9465556015026442
2023-02-06 11:39:51 | Stage | Epoch[432/600] Train loss:0.0202
2023-02-06 11:39:51 | Stage | Epoch[432/600] Valid loss:0.0356
2023-02-06 11:39:51 | Stage | Epoch[432/600] LR:0.001

2023-02-06 11:39:51 | Train | Epoch[433/600] Iteration[001/030] Train loss: 0.0207
2023-02-06 11:39:51 | Train | Epoch[433/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 11:39:51 | Train | Epoch[433/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[008/030] Train loss: 0.0215
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[009/030] Train loss: 0.0213
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:39:52 | Train | Epoch[433/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:39:53 | Train | Epoch[433/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:39:53 | Train | Epoch[433/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:39:53 | Train | Epoch[433/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:39:53 | Train | Epoch[433/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:39:53 | Train | Epoch[433/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:39:53 | Train | Epoch[433/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:39:53 | Train | Epoch[433/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:39:53 | Valid | Epoch[433/600] Iteration[001/008] Valid loss: 0.0429
2023-02-06 11:39:53 | Valid | Epoch[433/600] Iteration[002/008] Valid loss: 0.0356
2023-02-06 11:39:53 | Valid | Epoch[433/600] Iteration[003/008] Valid loss: 0.0337
2023-02-06 11:39:53 | Valid | Epoch[433/600] Iteration[004/008] Valid loss: 0.0321
2023-02-06 11:39:53 | Valid | Epoch[433/600] Iteration[005/008] Valid loss: 0.0327
2023-02-06 11:39:53 | Valid | Epoch[433/600] Iteration[006/008] Valid loss: 0.0323
2023-02-06 11:39:53 | Valid | Epoch[433/600] Iteration[007/008] Valid loss: 0.0317
2023-02-06 11:39:53 | Valid | Epoch[433/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 11:39:53 | Valid | Epoch[433/600] MIou: 0.908920115923314
2023-02-06 11:39:53 | Valid | Epoch[433/600] Pixel Accuracy: 0.9849065144856771
2023-02-06 11:39:53 | Valid | Epoch[433/600] Mean Pixel Accuracy: 0.919942520066021
2023-02-06 11:39:53 | Stage | Epoch[433/600] Train loss:0.0201
2023-02-06 11:39:53 | Stage | Epoch[433/600] Valid loss:0.0316
2023-02-06 11:39:53 | Stage | Epoch[433/600] LR:0.001

2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[001/030] Train loss: 0.0260
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[003/030] Train loss: 0.0225
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[004/030] Train loss: 0.0216
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[005/030] Train loss: 0.0221
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[006/030] Train loss: 0.0217
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[007/030] Train loss: 0.0214
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[008/030] Train loss: 0.0214
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[009/030] Train loss: 0.0211
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[010/030] Train loss: 0.0215
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[011/030] Train loss: 0.0215
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[012/030] Train loss: 0.0212
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[013/030] Train loss: 0.0210
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[014/030] Train loss: 0.0210
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[015/030] Train loss: 0.0210
2023-02-06 11:39:54 | Train | Epoch[434/600] Iteration[016/030] Train loss: 0.0210
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[017/030] Train loss: 0.0208
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[018/030] Train loss: 0.0208
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[019/030] Train loss: 0.0207
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[021/030] Train loss: 0.0210
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[022/030] Train loss: 0.0210
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[023/030] Train loss: 0.0210
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[024/030] Train loss: 0.0207
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[025/030] Train loss: 0.0206
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[026/030] Train loss: 0.0206
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[027/030] Train loss: 0.0205
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[028/030] Train loss: 0.0205
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:39:55 | Train | Epoch[434/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:39:55 | Valid | Epoch[434/600] Iteration[001/008] Valid loss: 0.1102
2023-02-06 11:39:56 | Valid | Epoch[434/600] Iteration[002/008] Valid loss: 0.0732
2023-02-06 11:39:56 | Valid | Epoch[434/600] Iteration[003/008] Valid loss: 0.0629
2023-02-06 11:39:56 | Valid | Epoch[434/600] Iteration[004/008] Valid loss: 0.0636
2023-02-06 11:39:56 | Valid | Epoch[434/600] Iteration[005/008] Valid loss: 0.0675
2023-02-06 11:39:56 | Valid | Epoch[434/600] Iteration[006/008] Valid loss: 0.0668
2023-02-06 11:39:56 | Valid | Epoch[434/600] Iteration[007/008] Valid loss: 0.0704
2023-02-06 11:39:56 | Valid | Epoch[434/600] Iteration[008/008] Valid loss: 0.0671
2023-02-06 11:39:56 | Valid | Epoch[434/600] MIou: 0.9422746385082961
2023-02-06 11:39:56 | Valid | Epoch[434/600] Pixel Accuracy: 0.9900220235188802
2023-02-06 11:39:56 | Valid | Epoch[434/600] Mean Pixel Accuracy: 0.9703331202284997
2023-02-06 11:39:56 | Stage | Epoch[434/600] Train loss:0.0203
2023-02-06 11:39:56 | Stage | Epoch[434/600] Valid loss:0.0671
2023-02-06 11:39:56 | Stage | Epoch[434/600] LR:0.001

2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[001/030] Train loss: 0.0212
2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:39:56 | Train | Epoch[435/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[016/030] Train loss: 0.0204
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[027/030] Train loss: 0.0205
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[028/030] Train loss: 0.0204
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:39:57 | Train | Epoch[435/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:39:58 | Valid | Epoch[435/600] Iteration[001/008] Valid loss: 0.0453
2023-02-06 11:39:58 | Valid | Epoch[435/600] Iteration[002/008] Valid loss: 0.0361
2023-02-06 11:39:58 | Valid | Epoch[435/600] Iteration[003/008] Valid loss: 0.0336
2023-02-06 11:39:58 | Valid | Epoch[435/600] Iteration[004/008] Valid loss: 0.0320
2023-02-06 11:39:58 | Valid | Epoch[435/600] Iteration[005/008] Valid loss: 0.0327
2023-02-06 11:39:58 | Valid | Epoch[435/600] Iteration[006/008] Valid loss: 0.0324
2023-02-06 11:39:58 | Valid | Epoch[435/600] Iteration[007/008] Valid loss: 0.0321
2023-02-06 11:39:58 | Valid | Epoch[435/600] Iteration[008/008] Valid loss: 0.0317
2023-02-06 11:39:58 | Valid | Epoch[435/600] MIou: 0.9155620676422845
2023-02-06 11:39:58 | Valid | Epoch[435/600] Pixel Accuracy: 0.9859695434570312
2023-02-06 11:39:58 | Valid | Epoch[435/600] Mean Pixel Accuracy: 0.9272350249855467
2023-02-06 11:39:58 | Stage | Epoch[435/600] Train loss:0.0203
2023-02-06 11:39:58 | Stage | Epoch[435/600] Valid loss:0.0317
2023-02-06 11:39:58 | Stage | Epoch[435/600] LR:0.001

2023-02-06 11:39:58 | Train | Epoch[436/600] Iteration[001/030] Train loss: 0.0248
2023-02-06 11:39:58 | Train | Epoch[436/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 11:39:58 | Train | Epoch[436/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:39:58 | Train | Epoch[436/600] Iteration[004/030] Train loss: 0.0213
2023-02-06 11:39:58 | Train | Epoch[436/600] Iteration[005/030] Train loss: 0.0214
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:39:59 | Train | Epoch[436/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:40:00 | Train | Epoch[436/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:40:00 | Train | Epoch[436/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:40:00 | Train | Epoch[436/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:40:00 | Train | Epoch[436/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:40:00 | Valid | Epoch[436/600] Iteration[001/008] Valid loss: 0.0515
2023-02-06 11:40:00 | Valid | Epoch[436/600] Iteration[002/008] Valid loss: 0.0384
2023-02-06 11:40:00 | Valid | Epoch[436/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:40:00 | Valid | Epoch[436/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:40:00 | Valid | Epoch[436/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 11:40:00 | Valid | Epoch[436/600] Iteration[006/008] Valid loss: 0.0342
2023-02-06 11:40:00 | Valid | Epoch[436/600] Iteration[007/008] Valid loss: 0.0343
2023-02-06 11:40:00 | Valid | Epoch[436/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 11:40:00 | Valid | Epoch[436/600] MIou: 0.9273504820758494
2023-02-06 11:40:00 | Valid | Epoch[436/600] Pixel Accuracy: 0.987860361735026
2023-02-06 11:40:00 | Valid | Epoch[436/600] Mean Pixel Accuracy: 0.9406445592726494
2023-02-06 11:40:00 | Stage | Epoch[436/600] Train loss:0.0200
2023-02-06 11:40:00 | Stage | Epoch[436/600] Valid loss:0.0334
2023-02-06 11:40:00 | Stage | Epoch[436/600] LR:0.001

2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[001/030] Train loss: 0.0270
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[003/030] Train loss: 0.0225
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[004/030] Train loss: 0.0223
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[005/030] Train loss: 0.0219
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[006/030] Train loss: 0.0218
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[008/030] Train loss: 0.0218
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[009/030] Train loss: 0.0216
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[010/030] Train loss: 0.0214
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[011/030] Train loss: 0.0212
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[012/030] Train loss: 0.0213
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[014/030] Train loss: 0.0210
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[016/030] Train loss: 0.0208
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[018/030] Train loss: 0.0209
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[019/030] Train loss: 0.0208
2023-02-06 11:40:01 | Train | Epoch[437/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:40:02 | Train | Epoch[437/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:40:02 | Train | Epoch[437/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:40:02 | Train | Epoch[437/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:40:02 | Train | Epoch[437/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 11:40:02 | Train | Epoch[437/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:40:02 | Train | Epoch[437/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:40:02 | Train | Epoch[437/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:40:02 | Train | Epoch[437/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:40:02 | Train | Epoch[437/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:40:02 | Train | Epoch[437/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:40:02 | Valid | Epoch[437/600] Iteration[001/008] Valid loss: 0.0544
2023-02-06 11:40:02 | Valid | Epoch[437/600] Iteration[002/008] Valid loss: 0.0398
2023-02-06 11:40:02 | Valid | Epoch[437/600] Iteration[003/008] Valid loss: 0.0355
2023-02-06 11:40:02 | Valid | Epoch[437/600] Iteration[004/008] Valid loss: 0.0339
2023-02-06 11:40:02 | Valid | Epoch[437/600] Iteration[005/008] Valid loss: 0.0349
2023-02-06 11:40:02 | Valid | Epoch[437/600] Iteration[006/008] Valid loss: 0.0350
2023-02-06 11:40:02 | Valid | Epoch[437/600] Iteration[007/008] Valid loss: 0.0353
2023-02-06 11:40:02 | Valid | Epoch[437/600] Iteration[008/008] Valid loss: 0.0343
2023-02-06 11:40:03 | Valid | Epoch[437/600] MIou: 0.92925943682723
2023-02-06 11:40:03 | Valid | Epoch[437/600] Pixel Accuracy: 0.9881579081217448
2023-02-06 11:40:03 | Valid | Epoch[437/600] Mean Pixel Accuracy: 0.9432301635744511
2023-02-06 11:40:03 | Stage | Epoch[437/600] Train loss:0.0202
2023-02-06 11:40:03 | Stage | Epoch[437/600] Valid loss:0.0343
2023-02-06 11:40:03 | Stage | Epoch[437/600] LR:0.001

2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[002/030] Train loss: 0.0205
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:40:03 | Train | Epoch[438/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:40:04 | Train | Epoch[438/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:40:05 | Valid | Epoch[438/600] Iteration[001/008] Valid loss: 0.0486
2023-02-06 11:40:05 | Valid | Epoch[438/600] Iteration[002/008] Valid loss: 0.0372
2023-02-06 11:40:05 | Valid | Epoch[438/600] Iteration[003/008] Valid loss: 0.0339
2023-02-06 11:40:05 | Valid | Epoch[438/600] Iteration[004/008] Valid loss: 0.0322
2023-02-06 11:40:05 | Valid | Epoch[438/600] Iteration[005/008] Valid loss: 0.0330
2023-02-06 11:40:05 | Valid | Epoch[438/600] Iteration[006/008] Valid loss: 0.0329
2023-02-06 11:40:05 | Valid | Epoch[438/600] Iteration[007/008] Valid loss: 0.0327
2023-02-06 11:40:05 | Valid | Epoch[438/600] Iteration[008/008] Valid loss: 0.0321
2023-02-06 11:40:05 | Valid | Epoch[438/600] MIou: 0.9216054509874505
2023-02-06 11:40:05 | Valid | Epoch[438/600] Pixel Accuracy: 0.9869422912597656
2023-02-06 11:40:05 | Valid | Epoch[438/600] Mean Pixel Accuracy: 0.9338882436737769
2023-02-06 11:40:05 | Stage | Epoch[438/600] Train loss:0.0201
2023-02-06 11:40:05 | Stage | Epoch[438/600] Valid loss:0.0321
2023-02-06 11:40:05 | Stage | Epoch[438/600] LR:0.001

2023-02-06 11:40:05 | Train | Epoch[439/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 11:40:05 | Train | Epoch[439/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 11:40:05 | Train | Epoch[439/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 11:40:05 | Train | Epoch[439/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:40:05 | Train | Epoch[439/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 11:40:05 | Train | Epoch[439/600] Iteration[006/030] Train loss: 0.0186
2023-02-06 11:40:05 | Train | Epoch[439/600] Iteration[007/030] Train loss: 0.0189
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[009/030] Train loss: 0.0190
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:40:06 | Train | Epoch[439/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:40:07 | Train | Epoch[439/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:40:07 | Train | Epoch[439/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:40:07 | Train | Epoch[439/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:40:07 | Valid | Epoch[439/600] Iteration[001/008] Valid loss: 0.0744
2023-02-06 11:40:07 | Valid | Epoch[439/600] Iteration[002/008] Valid loss: 0.0507
2023-02-06 11:40:07 | Valid | Epoch[439/600] Iteration[003/008] Valid loss: 0.0437
2023-02-06 11:40:07 | Valid | Epoch[439/600] Iteration[004/008] Valid loss: 0.0429
2023-02-06 11:40:07 | Valid | Epoch[439/600] Iteration[005/008] Valid loss: 0.0452
2023-02-06 11:40:07 | Valid | Epoch[439/600] Iteration[006/008] Valid loss: 0.0449
2023-02-06 11:40:07 | Valid | Epoch[439/600] Iteration[007/008] Valid loss: 0.0464
2023-02-06 11:40:07 | Valid | Epoch[439/600] Iteration[008/008] Valid loss: 0.0444
2023-02-06 11:40:07 | Valid | Epoch[439/600] MIou: 0.9391562062488183
2023-02-06 11:40:07 | Valid | Epoch[439/600] Pixel Accuracy: 0.98968505859375
2023-02-06 11:40:07 | Valid | Epoch[439/600] Mean Pixel Accuracy: 0.9582658663208041
2023-02-06 11:40:07 | Stage | Epoch[439/600] Train loss:0.0200
2023-02-06 11:40:07 | Stage | Epoch[439/600] Valid loss:0.0444
2023-02-06 11:40:07 | Stage | Epoch[439/600] LR:0.001

2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[013/030] Train loss: 0.0193
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[017/030] Train loss: 0.0194
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 11:40:08 | Train | Epoch[440/600] Iteration[020/030] Train loss: 0.0196
2023-02-06 11:40:09 | Train | Epoch[440/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 11:40:09 | Train | Epoch[440/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:40:09 | Train | Epoch[440/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:40:09 | Train | Epoch[440/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:40:09 | Train | Epoch[440/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:40:09 | Train | Epoch[440/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:40:09 | Train | Epoch[440/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:40:09 | Train | Epoch[440/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:40:09 | Train | Epoch[440/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:40:09 | Train | Epoch[440/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:40:09 | Valid | Epoch[440/600] Iteration[001/008] Valid loss: 0.0680
2023-02-06 11:40:09 | Valid | Epoch[440/600] Iteration[002/008] Valid loss: 0.0470
2023-02-06 11:40:09 | Valid | Epoch[440/600] Iteration[003/008] Valid loss: 0.0408
2023-02-06 11:40:09 | Valid | Epoch[440/600] Iteration[004/008] Valid loss: 0.0398
2023-02-06 11:40:09 | Valid | Epoch[440/600] Iteration[005/008] Valid loss: 0.0415
2023-02-06 11:40:09 | Valid | Epoch[440/600] Iteration[006/008] Valid loss: 0.0412
2023-02-06 11:40:09 | Valid | Epoch[440/600] Iteration[007/008] Valid loss: 0.0423
2023-02-06 11:40:09 | Valid | Epoch[440/600] Iteration[008/008] Valid loss: 0.0406
2023-02-06 11:40:10 | Valid | Epoch[440/600] MIou: 0.9369338564612211
2023-02-06 11:40:10 | Valid | Epoch[440/600] Pixel Accuracy: 0.9893480936686198
2023-02-06 11:40:10 | Valid | Epoch[440/600] Mean Pixel Accuracy: 0.9544539063218365
2023-02-06 11:40:10 | Stage | Epoch[440/600] Train loss:0.0199
2023-02-06 11:40:10 | Stage | Epoch[440/600] Valid loss:0.0406
2023-02-06 11:40:10 | Stage | Epoch[440/600] LR:0.001

2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[004/030] Train loss: 0.0202
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[005/030] Train loss: 0.0193
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:40:10 | Train | Epoch[441/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:40:11 | Train | Epoch[441/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:40:12 | Valid | Epoch[441/600] Iteration[001/008] Valid loss: 0.0713
2023-02-06 11:40:12 | Valid | Epoch[441/600] Iteration[002/008] Valid loss: 0.0490
2023-02-06 11:40:12 | Valid | Epoch[441/600] Iteration[003/008] Valid loss: 0.0423
2023-02-06 11:40:12 | Valid | Epoch[441/600] Iteration[004/008] Valid loss: 0.0418
2023-02-06 11:40:12 | Valid | Epoch[441/600] Iteration[005/008] Valid loss: 0.0437
2023-02-06 11:40:12 | Valid | Epoch[441/600] Iteration[006/008] Valid loss: 0.0436
2023-02-06 11:40:12 | Valid | Epoch[441/600] Iteration[007/008] Valid loss: 0.0449
2023-02-06 11:40:12 | Valid | Epoch[441/600] Iteration[008/008] Valid loss: 0.0429
2023-02-06 11:40:12 | Valid | Epoch[441/600] MIou: 0.9387058106878523
2023-02-06 11:40:12 | Valid | Epoch[441/600] Pixel Accuracy: 0.9896341959635416
2023-02-06 11:40:12 | Valid | Epoch[441/600] Mean Pixel Accuracy: 0.9567098564155917
2023-02-06 11:40:12 | Stage | Epoch[441/600] Train loss:0.0200
2023-02-06 11:40:12 | Stage | Epoch[441/600] Valid loss:0.0429
2023-02-06 11:40:12 | Stage | Epoch[441/600] LR:0.001

2023-02-06 11:40:12 | Train | Epoch[442/600] Iteration[001/030] Train loss: 0.0205
2023-02-06 11:40:12 | Train | Epoch[442/600] Iteration[002/030] Train loss: 0.0203
2023-02-06 11:40:12 | Train | Epoch[442/600] Iteration[003/030] Train loss: 0.0205
2023-02-06 11:40:12 | Train | Epoch[442/600] Iteration[004/030] Train loss: 0.0202
2023-02-06 11:40:12 | Train | Epoch[442/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 11:40:12 | Train | Epoch[442/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 11:40:12 | Train | Epoch[442/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 11:40:12 | Train | Epoch[442/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[009/030] Train loss: 0.0191
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[010/030] Train loss: 0.0191
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:40:13 | Train | Epoch[442/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:40:14 | Train | Epoch[442/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:40:14 | Train | Epoch[442/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:40:14 | Valid | Epoch[442/600] Iteration[001/008] Valid loss: 0.0621
2023-02-06 11:40:14 | Valid | Epoch[442/600] Iteration[002/008] Valid loss: 0.0438
2023-02-06 11:40:14 | Valid | Epoch[442/600] Iteration[003/008] Valid loss: 0.0384
2023-02-06 11:40:14 | Valid | Epoch[442/600] Iteration[004/008] Valid loss: 0.0375
2023-02-06 11:40:14 | Valid | Epoch[442/600] Iteration[005/008] Valid loss: 0.0383
2023-02-06 11:40:14 | Valid | Epoch[442/600] Iteration[006/008] Valid loss: 0.0383
2023-02-06 11:40:14 | Valid | Epoch[442/600] Iteration[007/008] Valid loss: 0.0391
2023-02-06 11:40:14 | Valid | Epoch[442/600] Iteration[008/008] Valid loss: 0.0377
2023-02-06 11:40:14 | Valid | Epoch[442/600] MIou: 0.9349589298106371
2023-02-06 11:40:14 | Valid | Epoch[442/600] Pixel Accuracy: 0.9890658060709635
2023-02-06 11:40:14 | Valid | Epoch[442/600] Mean Pixel Accuracy: 0.9504691042255935
2023-02-06 11:40:14 | Stage | Epoch[442/600] Train loss:0.0201
2023-02-06 11:40:14 | Stage | Epoch[442/600] Valid loss:0.0377
2023-02-06 11:40:14 | Stage | Epoch[442/600] LR:0.001

2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[002/030] Train loss: 0.0206
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[007/030] Train loss: 0.0191
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[008/030] Train loss: 0.0189
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[009/030] Train loss: 0.0189
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[010/030] Train loss: 0.0190
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[011/030] Train loss: 0.0189
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[012/030] Train loss: 0.0189
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[013/030] Train loss: 0.0188
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[014/030] Train loss: 0.0191
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[016/030] Train loss: 0.0193
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[017/030] Train loss: 0.0193
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[018/030] Train loss: 0.0193
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[019/030] Train loss: 0.0194
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 11:40:15 | Train | Epoch[443/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:40:16 | Train | Epoch[443/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:40:16 | Train | Epoch[443/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:40:16 | Train | Epoch[443/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:40:16 | Train | Epoch[443/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:40:16 | Train | Epoch[443/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:40:16 | Train | Epoch[443/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:40:16 | Train | Epoch[443/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:40:16 | Train | Epoch[443/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:40:16 | Train | Epoch[443/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:40:16 | Valid | Epoch[443/600] Iteration[001/008] Valid loss: 0.0583
2023-02-06 11:40:16 | Valid | Epoch[443/600] Iteration[002/008] Valid loss: 0.0417
2023-02-06 11:40:16 | Valid | Epoch[443/600] Iteration[003/008] Valid loss: 0.0369
2023-02-06 11:40:16 | Valid | Epoch[443/600] Iteration[004/008] Valid loss: 0.0355
2023-02-06 11:40:16 | Valid | Epoch[443/600] Iteration[005/008] Valid loss: 0.0364
2023-02-06 11:40:16 | Valid | Epoch[443/600] Iteration[006/008] Valid loss: 0.0363
2023-02-06 11:40:16 | Valid | Epoch[443/600] Iteration[007/008] Valid loss: 0.0368
2023-02-06 11:40:16 | Valid | Epoch[443/600] Iteration[008/008] Valid loss: 0.0356
2023-02-06 11:40:16 | Valid | Epoch[443/600] MIou: 0.9316991400522309
2023-02-06 11:40:16 | Valid | Epoch[443/600] Pixel Accuracy: 0.9885457356770834
2023-02-06 11:40:16 | Valid | Epoch[443/600] Mean Pixel Accuracy: 0.9463155637342824
2023-02-06 11:40:16 | Stage | Epoch[443/600] Train loss:0.0202
2023-02-06 11:40:16 | Stage | Epoch[443/600] Valid loss:0.0356
2023-02-06 11:40:16 | Stage | Epoch[443/600] LR:0.001

2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[005/030] Train loss: 0.0193
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:40:17 | Train | Epoch[444/600] Iteration[015/030] Train loss: 0.0207
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[027/030] Train loss: 0.0204
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:40:18 | Train | Epoch[444/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:40:19 | Valid | Epoch[444/600] Iteration[001/008] Valid loss: 0.1140
2023-02-06 11:40:19 | Valid | Epoch[444/600] Iteration[002/008] Valid loss: 0.0757
2023-02-06 11:40:19 | Valid | Epoch[444/600] Iteration[003/008] Valid loss: 0.0654
2023-02-06 11:40:19 | Valid | Epoch[444/600] Iteration[004/008] Valid loss: 0.0662
2023-02-06 11:40:19 | Valid | Epoch[444/600] Iteration[005/008] Valid loss: 0.0703
2023-02-06 11:40:19 | Valid | Epoch[444/600] Iteration[006/008] Valid loss: 0.0691
2023-02-06 11:40:19 | Valid | Epoch[444/600] Iteration[007/008] Valid loss: 0.0739
2023-02-06 11:40:19 | Valid | Epoch[444/600] Iteration[008/008] Valid loss: 0.0705
2023-02-06 11:40:19 | Valid | Epoch[444/600] MIou: 0.9423115342300745
2023-02-06 11:40:19 | Valid | Epoch[444/600] Pixel Accuracy: 0.9900156656901041
2023-02-06 11:40:19 | Valid | Epoch[444/600] Mean Pixel Accuracy: 0.9709763537888817
2023-02-06 11:40:19 | Stage | Epoch[444/600] Train loss:0.0203
2023-02-06 11:40:19 | Stage | Epoch[444/600] Valid loss:0.0705
2023-02-06 11:40:19 | Stage | Epoch[444/600] LR:0.001

2023-02-06 11:40:19 | Train | Epoch[445/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 11:40:19 | Train | Epoch[445/600] Iteration[002/030] Train loss: 0.0188
2023-02-06 11:40:19 | Train | Epoch[445/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 11:40:19 | Train | Epoch[445/600] Iteration[004/030] Train loss: 0.0185
2023-02-06 11:40:19 | Train | Epoch[445/600] Iteration[005/030] Train loss: 0.0182
2023-02-06 11:40:19 | Train | Epoch[445/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 11:40:19 | Train | Epoch[445/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:40:19 | Train | Epoch[445/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[009/030] Train loss: 0.0196
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[013/030] Train loss: 0.0193
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[014/030] Train loss: 0.0195
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:40:20 | Train | Epoch[445/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:40:21 | Train | Epoch[445/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:40:21 | Train | Epoch[445/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:40:21 | Valid | Epoch[445/600] Iteration[001/008] Valid loss: 0.0534
2023-02-06 11:40:21 | Valid | Epoch[445/600] Iteration[002/008] Valid loss: 0.0393
2023-02-06 11:40:21 | Valid | Epoch[445/600] Iteration[003/008] Valid loss: 0.0353
2023-02-06 11:40:21 | Valid | Epoch[445/600] Iteration[004/008] Valid loss: 0.0336
2023-02-06 11:40:21 | Valid | Epoch[445/600] Iteration[005/008] Valid loss: 0.0347
2023-02-06 11:40:21 | Valid | Epoch[445/600] Iteration[006/008] Valid loss: 0.0349
2023-02-06 11:40:21 | Valid | Epoch[445/600] Iteration[007/008] Valid loss: 0.0352
2023-02-06 11:40:21 | Valid | Epoch[445/600] Iteration[008/008] Valid loss: 0.0342
2023-02-06 11:40:21 | Valid | Epoch[445/600] MIou: 0.9282218459255938
2023-02-06 11:40:21 | Valid | Epoch[445/600] Pixel Accuracy: 0.9879913330078125
2023-02-06 11:40:21 | Valid | Epoch[445/600] Mean Pixel Accuracy: 0.9419973219154028
2023-02-06 11:40:21 | Stage | Epoch[445/600] Train loss:0.0200
2023-02-06 11:40:21 | Stage | Epoch[445/600] Valid loss:0.0342
2023-02-06 11:40:21 | Stage | Epoch[445/600] LR:0.001

2023-02-06 11:40:21 | Train | Epoch[446/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 11:40:21 | Train | Epoch[446/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[004/030] Train loss: 0.0201
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[009/030] Train loss: 0.0213
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[014/030] Train loss: 0.0208
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[015/030] Train loss: 0.0207
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[016/030] Train loss: 0.0204
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:40:22 | Train | Epoch[446/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:40:23 | Train | Epoch[446/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:40:23 | Train | Epoch[446/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:40:23 | Train | Epoch[446/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:40:23 | Train | Epoch[446/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:40:23 | Train | Epoch[446/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:40:23 | Train | Epoch[446/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:40:23 | Train | Epoch[446/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:40:23 | Valid | Epoch[446/600] Iteration[001/008] Valid loss: 0.0719
2023-02-06 11:40:23 | Valid | Epoch[446/600] Iteration[002/008] Valid loss: 0.0494
2023-02-06 11:40:23 | Valid | Epoch[446/600] Iteration[003/008] Valid loss: 0.0427
2023-02-06 11:40:23 | Valid | Epoch[446/600] Iteration[004/008] Valid loss: 0.0419
2023-02-06 11:40:23 | Valid | Epoch[446/600] Iteration[005/008] Valid loss: 0.0439
2023-02-06 11:40:23 | Valid | Epoch[446/600] Iteration[006/008] Valid loss: 0.0436
2023-02-06 11:40:23 | Valid | Epoch[446/600] Iteration[007/008] Valid loss: 0.0451
2023-02-06 11:40:23 | Valid | Epoch[446/600] Iteration[008/008] Valid loss: 0.0432
2023-02-06 11:40:23 | Valid | Epoch[446/600] MIou: 0.9392871652606232
2023-02-06 11:40:23 | Valid | Epoch[446/600] Pixel Accuracy: 0.9897181193033854
2023-02-06 11:40:23 | Valid | Epoch[446/600] Mean Pixel Accuracy: 0.9579036096061001
2023-02-06 11:40:23 | Stage | Epoch[446/600] Train loss:0.0199
2023-02-06 11:40:23 | Stage | Epoch[446/600] Valid loss:0.0432
2023-02-06 11:40:23 | Stage | Epoch[446/600] LR:0.001

2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[007/030] Train loss: 0.0213
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[009/030] Train loss: 0.0211
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[013/030] Train loss: 0.0207
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[015/030] Train loss: 0.0207
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[017/030] Train loss: 0.0206
2023-02-06 11:40:24 | Train | Epoch[447/600] Iteration[018/030] Train loss: 0.0208
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[019/030] Train loss: 0.0208
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:40:25 | Train | Epoch[447/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:40:25 | Valid | Epoch[447/600] Iteration[001/008] Valid loss: 0.0505
2023-02-06 11:40:25 | Valid | Epoch[447/600] Iteration[002/008] Valid loss: 0.0380
2023-02-06 11:40:25 | Valid | Epoch[447/600] Iteration[003/008] Valid loss: 0.0344
2023-02-06 11:40:25 | Valid | Epoch[447/600] Iteration[004/008] Valid loss: 0.0327
2023-02-06 11:40:25 | Valid | Epoch[447/600] Iteration[005/008] Valid loss: 0.0337
2023-02-06 11:40:25 | Valid | Epoch[447/600] Iteration[006/008] Valid loss: 0.0336
2023-02-06 11:40:25 | Valid | Epoch[447/600] Iteration[007/008] Valid loss: 0.0337
2023-02-06 11:40:26 | Valid | Epoch[447/600] Iteration[008/008] Valid loss: 0.0329
2023-02-06 11:40:26 | Valid | Epoch[447/600] MIou: 0.9252779096627688
2023-02-06 11:40:26 | Valid | Epoch[447/600] Pixel Accuracy: 0.987524668375651
2023-02-06 11:40:26 | Valid | Epoch[447/600] Mean Pixel Accuracy: 0.9383359899288147
2023-02-06 11:40:26 | Stage | Epoch[447/600] Train loss:0.0200
2023-02-06 11:40:26 | Stage | Epoch[447/600] Valid loss:0.0329
2023-02-06 11:40:26 | Stage | Epoch[447/600] LR:0.001

2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[001/030] Train loss: 0.0215
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:40:26 | Train | Epoch[448/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:40:27 | Train | Epoch[448/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:40:28 | Valid | Epoch[448/600] Iteration[001/008] Valid loss: 0.0861
2023-02-06 11:40:28 | Valid | Epoch[448/600] Iteration[002/008] Valid loss: 0.0584
2023-02-06 11:40:28 | Valid | Epoch[448/600] Iteration[003/008] Valid loss: 0.0501
2023-02-06 11:40:28 | Valid | Epoch[448/600] Iteration[004/008] Valid loss: 0.0500
2023-02-06 11:40:28 | Valid | Epoch[448/600] Iteration[005/008] Valid loss: 0.0536
2023-02-06 11:40:28 | Valid | Epoch[448/600] Iteration[006/008] Valid loss: 0.0534
2023-02-06 11:40:28 | Valid | Epoch[448/600] Iteration[007/008] Valid loss: 0.0558
2023-02-06 11:40:28 | Valid | Epoch[448/600] Iteration[008/008] Valid loss: 0.0533
2023-02-06 11:40:28 | Valid | Epoch[448/600] MIou: 0.9415229672551327
2023-02-06 11:40:28 | Valid | Epoch[448/600] Pixel Accuracy: 0.9900054931640625
2023-02-06 11:40:28 | Valid | Epoch[448/600] Mean Pixel Accuracy: 0.9642879055609894
2023-02-06 11:40:28 | Stage | Epoch[448/600] Train loss:0.0202
2023-02-06 11:40:28 | Stage | Epoch[448/600] Valid loss:0.0533
2023-02-06 11:40:28 | Stage | Epoch[448/600] LR:0.001

2023-02-06 11:40:28 | Train | Epoch[449/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 11:40:28 | Train | Epoch[449/600] Iteration[002/030] Train loss: 0.0234
2023-02-06 11:40:28 | Train | Epoch[449/600] Iteration[003/030] Train loss: 0.0235
2023-02-06 11:40:28 | Train | Epoch[449/600] Iteration[004/030] Train loss: 0.0221
2023-02-06 11:40:28 | Train | Epoch[449/600] Iteration[005/030] Train loss: 0.0220
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[017/030] Train loss: 0.0208
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[018/030] Train loss: 0.0208
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[020/030] Train loss: 0.0207
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[022/030] Train loss: 0.0207
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 11:40:29 | Train | Epoch[449/600] Iteration[025/030] Train loss: 0.0205
2023-02-06 11:40:30 | Train | Epoch[449/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:40:30 | Train | Epoch[449/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:40:30 | Train | Epoch[449/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:40:30 | Train | Epoch[449/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:40:30 | Train | Epoch[449/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:40:30 | Valid | Epoch[449/600] Iteration[001/008] Valid loss: 0.0415
2023-02-06 11:40:30 | Valid | Epoch[449/600] Iteration[002/008] Valid loss: 0.0388
2023-02-06 11:40:30 | Valid | Epoch[449/600] Iteration[003/008] Valid loss: 0.0383
2023-02-06 11:40:30 | Valid | Epoch[449/600] Iteration[004/008] Valid loss: 0.0368
2023-02-06 11:40:30 | Valid | Epoch[449/600] Iteration[005/008] Valid loss: 0.0373
2023-02-06 11:40:30 | Valid | Epoch[449/600] Iteration[006/008] Valid loss: 0.0369
2023-02-06 11:40:30 | Valid | Epoch[449/600] Iteration[007/008] Valid loss: 0.0358
2023-02-06 11:40:30 | Valid | Epoch[449/600] Iteration[008/008] Valid loss: 0.0363
2023-02-06 11:40:30 | Valid | Epoch[449/600] MIou: 0.8764886611671672
2023-02-06 11:40:30 | Valid | Epoch[449/600] Pixel Accuracy: 0.9796257019042969
2023-02-06 11:40:30 | Valid | Epoch[449/600] Mean Pixel Accuracy: 0.8881527720410494
2023-02-06 11:40:30 | Stage | Epoch[449/600] Train loss:0.0202
2023-02-06 11:40:30 | Stage | Epoch[449/600] Valid loss:0.0363
2023-02-06 11:40:30 | Stage | Epoch[449/600] LR:0.001

2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[001/030] Train loss: 0.0227
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[004/030] Train loss: 0.0215
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[011/030] Train loss: 0.0204
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:40:31 | Train | Epoch[450/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:40:32 | Train | Epoch[450/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:40:32 | Train | Epoch[450/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:40:32 | Train | Epoch[450/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:40:32 | Train | Epoch[450/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:40:32 | Train | Epoch[450/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:40:32 | Train | Epoch[450/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:40:32 | Train | Epoch[450/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:40:32 | Train | Epoch[450/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:40:32 | Train | Epoch[450/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:40:32 | Train | Epoch[450/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:40:32 | Valid | Epoch[450/600] Iteration[001/008] Valid loss: 0.0437
2023-02-06 11:40:32 | Valid | Epoch[450/600] Iteration[002/008] Valid loss: 0.0355
2023-02-06 11:40:32 | Valid | Epoch[450/600] Iteration[003/008] Valid loss: 0.0334
2023-02-06 11:40:32 | Valid | Epoch[450/600] Iteration[004/008] Valid loss: 0.0318
2023-02-06 11:40:32 | Valid | Epoch[450/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 11:40:32 | Valid | Epoch[450/600] Iteration[006/008] Valid loss: 0.0322
2023-02-06 11:40:32 | Valid | Epoch[450/600] Iteration[007/008] Valid loss: 0.0318
2023-02-06 11:40:32 | Valid | Epoch[450/600] Iteration[008/008] Valid loss: 0.0315
2023-02-06 11:40:33 | Valid | Epoch[450/600] MIou: 0.9129976859964102
2023-02-06 11:40:33 | Valid | Epoch[450/600] Pixel Accuracy: 0.9855600992838541
2023-02-06 11:40:33 | Valid | Epoch[450/600] Mean Pixel Accuracy: 0.9243660003850596
2023-02-06 11:40:33 | Stage | Epoch[450/600] Train loss:0.0201
2023-02-06 11:40:33 | Stage | Epoch[450/600] Valid loss:0.0315
2023-02-06 11:40:33 | Stage | Epoch[450/600] LR:0.001

2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[002/030] Train loss: 0.0197
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[011/030] Train loss: 0.0193
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:40:33 | Train | Epoch[451/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:40:34 | Train | Epoch[451/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:40:35 | Valid | Epoch[451/600] Iteration[001/008] Valid loss: 0.0484
2023-02-06 11:40:35 | Valid | Epoch[451/600] Iteration[002/008] Valid loss: 0.0371
2023-02-06 11:40:35 | Valid | Epoch[451/600] Iteration[003/008] Valid loss: 0.0339
2023-02-06 11:40:35 | Valid | Epoch[451/600] Iteration[004/008] Valid loss: 0.0322
2023-02-06 11:40:35 | Valid | Epoch[451/600] Iteration[005/008] Valid loss: 0.0331
2023-02-06 11:40:35 | Valid | Epoch[451/600] Iteration[006/008] Valid loss: 0.0328
2023-02-06 11:40:35 | Valid | Epoch[451/600] Iteration[007/008] Valid loss: 0.0329
2023-02-06 11:40:35 | Valid | Epoch[451/600] Iteration[008/008] Valid loss: 0.0322
2023-02-06 11:40:35 | Valid | Epoch[451/600] MIou: 0.9225749689659697
2023-02-06 11:40:35 | Valid | Epoch[451/600] Pixel Accuracy: 0.9871012369791666
2023-02-06 11:40:35 | Valid | Epoch[451/600] Mean Pixel Accuracy: 0.934875953974746
2023-02-06 11:40:35 | Stage | Epoch[451/600] Train loss:0.0200
2023-02-06 11:40:35 | Stage | Epoch[451/600] Valid loss:0.0322
2023-02-06 11:40:35 | Stage | Epoch[451/600] LR:0.001

2023-02-06 11:40:35 | Train | Epoch[452/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:40:35 | Train | Epoch[452/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 11:40:35 | Train | Epoch[452/600] Iteration[003/030] Train loss: 0.0214
2023-02-06 11:40:35 | Train | Epoch[452/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:40:35 | Train | Epoch[452/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 11:40:35 | Train | Epoch[452/600] Iteration[006/030] Train loss: 0.0209
2023-02-06 11:40:35 | Train | Epoch[452/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:40:35 | Train | Epoch[452/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:40:35 | Train | Epoch[452/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:40:35 | Train | Epoch[452/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:40:36 | Train | Epoch[452/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:40:37 | Valid | Epoch[452/600] Iteration[001/008] Valid loss: 0.0434
2023-02-06 11:40:37 | Valid | Epoch[452/600] Iteration[002/008] Valid loss: 0.0354
2023-02-06 11:40:37 | Valid | Epoch[452/600] Iteration[003/008] Valid loss: 0.0332
2023-02-06 11:40:37 | Valid | Epoch[452/600] Iteration[004/008] Valid loss: 0.0317
2023-02-06 11:40:37 | Valid | Epoch[452/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 11:40:37 | Valid | Epoch[452/600] Iteration[006/008] Valid loss: 0.0323
2023-02-06 11:40:37 | Valid | Epoch[452/600] Iteration[007/008] Valid loss: 0.0319
2023-02-06 11:40:37 | Valid | Epoch[452/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 11:40:37 | Valid | Epoch[452/600] MIou: 0.9139525363408465
2023-02-06 11:40:37 | Valid | Epoch[452/600] Pixel Accuracy: 0.9857126871744791
2023-02-06 11:40:37 | Valid | Epoch[452/600] Mean Pixel Accuracy: 0.9254263018103235
2023-02-06 11:40:37 | Stage | Epoch[452/600] Train loss:0.0200
2023-02-06 11:40:37 | Stage | Epoch[452/600] Valid loss:0.0316
2023-02-06 11:40:37 | Stage | Epoch[452/600] LR:0.001

2023-02-06 11:40:37 | Train | Epoch[453/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 11:40:37 | Train | Epoch[453/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:40:37 | Train | Epoch[453/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:40:38 | Train | Epoch[453/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:40:39 | Train | Epoch[453/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:40:39 | Train | Epoch[453/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:40:39 | Train | Epoch[453/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:40:39 | Train | Epoch[453/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:40:39 | Train | Epoch[453/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:40:39 | Train | Epoch[453/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:40:39 | Valid | Epoch[453/600] Iteration[001/008] Valid loss: 0.0511
2023-02-06 11:40:39 | Valid | Epoch[453/600] Iteration[002/008] Valid loss: 0.0382
2023-02-06 11:40:39 | Valid | Epoch[453/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:40:39 | Valid | Epoch[453/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:40:39 | Valid | Epoch[453/600] Iteration[005/008] Valid loss: 0.0340
2023-02-06 11:40:39 | Valid | Epoch[453/600] Iteration[006/008] Valid loss: 0.0339
2023-02-06 11:40:39 | Valid | Epoch[453/600] Iteration[007/008] Valid loss: 0.0340
2023-02-06 11:40:39 | Valid | Epoch[453/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:40:39 | Valid | Epoch[453/600] MIou: 0.9267180944435951
2023-02-06 11:40:39 | Valid | Epoch[453/600] Pixel Accuracy: 0.9877599080403646
2023-02-06 11:40:39 | Valid | Epoch[453/600] Mean Pixel Accuracy: 0.93986653188544
2023-02-06 11:40:39 | Stage | Epoch[453/600] Train loss:0.0201
2023-02-06 11:40:39 | Stage | Epoch[453/600] Valid loss:0.0331
2023-02-06 11:40:39 | Stage | Epoch[453/600] LR:0.001

2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[002/030] Train loss: 0.0210
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[006/030] Train loss: 0.0207
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[008/030] Train loss: 0.0212
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:40:40 | Train | Epoch[454/600] Iteration[020/030] Train loss: 0.0206
2023-02-06 11:40:41 | Train | Epoch[454/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:40:41 | Train | Epoch[454/600] Iteration[022/030] Train loss: 0.0206
2023-02-06 11:40:41 | Train | Epoch[454/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:40:41 | Train | Epoch[454/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:40:41 | Train | Epoch[454/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:40:41 | Train | Epoch[454/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:40:41 | Train | Epoch[454/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:40:41 | Train | Epoch[454/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:40:41 | Train | Epoch[454/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:40:41 | Train | Epoch[454/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:40:41 | Valid | Epoch[454/600] Iteration[001/008] Valid loss: 0.0541
2023-02-06 11:40:41 | Valid | Epoch[454/600] Iteration[002/008] Valid loss: 0.0396
2023-02-06 11:40:41 | Valid | Epoch[454/600] Iteration[003/008] Valid loss: 0.0354
2023-02-06 11:40:41 | Valid | Epoch[454/600] Iteration[004/008] Valid loss: 0.0341
2023-02-06 11:40:41 | Valid | Epoch[454/600] Iteration[005/008] Valid loss: 0.0349
2023-02-06 11:40:41 | Valid | Epoch[454/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 11:40:41 | Valid | Epoch[454/600] Iteration[007/008] Valid loss: 0.0350
2023-02-06 11:40:41 | Valid | Epoch[454/600] Iteration[008/008] Valid loss: 0.0339
2023-02-06 11:40:42 | Valid | Epoch[454/600] MIou: 0.9296829612567551
2023-02-06 11:40:42 | Valid | Epoch[454/600] Pixel Accuracy: 0.9882392883300781
2023-02-06 11:40:42 | Valid | Epoch[454/600] Mean Pixel Accuracy: 0.9432305103071483
2023-02-06 11:40:42 | Stage | Epoch[454/600] Train loss:0.0201
2023-02-06 11:40:42 | Stage | Epoch[454/600] Valid loss:0.0339
2023-02-06 11:40:42 | Stage | Epoch[454/600] LR:0.001

2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:40:42 | Train | Epoch[455/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:40:43 | Train | Epoch[455/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:40:44 | Valid | Epoch[455/600] Iteration[001/008] Valid loss: 0.0451
2023-02-06 11:40:44 | Valid | Epoch[455/600] Iteration[002/008] Valid loss: 0.0359
2023-02-06 11:40:44 | Valid | Epoch[455/600] Iteration[003/008] Valid loss: 0.0334
2023-02-06 11:40:44 | Valid | Epoch[455/600] Iteration[004/008] Valid loss: 0.0317
2023-02-06 11:40:44 | Valid | Epoch[455/600] Iteration[005/008] Valid loss: 0.0324
2023-02-06 11:40:44 | Valid | Epoch[455/600] Iteration[006/008] Valid loss: 0.0322
2023-02-06 11:40:44 | Valid | Epoch[455/600] Iteration[007/008] Valid loss: 0.0319
2023-02-06 11:40:44 | Valid | Epoch[455/600] Iteration[008/008] Valid loss: 0.0315
2023-02-06 11:40:44 | Valid | Epoch[455/600] MIou: 0.9163054553753984
2023-02-06 11:40:44 | Valid | Epoch[455/600] Pixel Accuracy: 0.9860928853352865
2023-02-06 11:40:44 | Valid | Epoch[455/600] Mean Pixel Accuracy: 0.9279305256219355
2023-02-06 11:40:44 | Stage | Epoch[455/600] Train loss:0.0202
2023-02-06 11:40:44 | Stage | Epoch[455/600] Valid loss:0.0315
2023-02-06 11:40:44 | Stage | Epoch[455/600] LR:0.001

2023-02-06 11:40:44 | Train | Epoch[456/600] Iteration[001/030] Train loss: 0.0212
2023-02-06 11:40:44 | Train | Epoch[456/600] Iteration[002/030] Train loss: 0.0206
2023-02-06 11:40:44 | Train | Epoch[456/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:40:44 | Train | Epoch[456/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:40:44 | Train | Epoch[456/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:40:44 | Train | Epoch[456/600] Iteration[006/030] Train loss: 0.0204
2023-02-06 11:40:44 | Train | Epoch[456/600] Iteration[007/030] Train loss: 0.0204
2023-02-06 11:40:44 | Train | Epoch[456/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[027/030] Train loss: 0.0204
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:40:45 | Train | Epoch[456/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:40:46 | Train | Epoch[456/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:40:46 | Valid | Epoch[456/600] Iteration[001/008] Valid loss: 0.0882
2023-02-06 11:40:46 | Valid | Epoch[456/600] Iteration[002/008] Valid loss: 0.0593
2023-02-06 11:40:46 | Valid | Epoch[456/600] Iteration[003/008] Valid loss: 0.0509
2023-02-06 11:40:46 | Valid | Epoch[456/600] Iteration[004/008] Valid loss: 0.0517
2023-02-06 11:40:46 | Valid | Epoch[456/600] Iteration[005/008] Valid loss: 0.0544
2023-02-06 11:40:46 | Valid | Epoch[456/600] Iteration[006/008] Valid loss: 0.0534
2023-02-06 11:40:46 | Valid | Epoch[456/600] Iteration[007/008] Valid loss: 0.0559
2023-02-06 11:40:46 | Valid | Epoch[456/600] Iteration[008/008] Valid loss: 0.0535
2023-02-06 11:40:46 | Valid | Epoch[456/600] MIou: 0.9410549195840893
2023-02-06 11:40:46 | Valid | Epoch[456/600] Pixel Accuracy: 0.98992919921875
2023-02-06 11:40:46 | Valid | Epoch[456/600] Mean Pixel Accuracy: 0.9636689882471883
2023-02-06 11:40:46 | Stage | Epoch[456/600] Train loss:0.0203
2023-02-06 11:40:46 | Stage | Epoch[456/600] Valid loss:0.0535
2023-02-06 11:40:46 | Stage | Epoch[456/600] LR:0.001

2023-02-06 11:40:46 | Train | Epoch[457/600] Iteration[001/030] Train loss: 0.0212
2023-02-06 11:40:46 | Train | Epoch[457/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 11:40:46 | Train | Epoch[457/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[004/030] Train loss: 0.0202
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:40:47 | Train | Epoch[457/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:40:48 | Train | Epoch[457/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:40:48 | Train | Epoch[457/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:40:48 | Train | Epoch[457/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:40:48 | Train | Epoch[457/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:40:48 | Train | Epoch[457/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:40:48 | Train | Epoch[457/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:40:48 | Valid | Epoch[457/600] Iteration[001/008] Valid loss: 0.0401
2023-02-06 11:40:48 | Valid | Epoch[457/600] Iteration[002/008] Valid loss: 0.0373
2023-02-06 11:40:48 | Valid | Epoch[457/600] Iteration[003/008] Valid loss: 0.0367
2023-02-06 11:40:48 | Valid | Epoch[457/600] Iteration[004/008] Valid loss: 0.0352
2023-02-06 11:40:48 | Valid | Epoch[457/600] Iteration[005/008] Valid loss: 0.0359
2023-02-06 11:40:48 | Valid | Epoch[457/600] Iteration[006/008] Valid loss: 0.0355
2023-02-06 11:40:48 | Valid | Epoch[457/600] Iteration[007/008] Valid loss: 0.0345
2023-02-06 11:40:48 | Valid | Epoch[457/600] Iteration[008/008] Valid loss: 0.0350
2023-02-06 11:40:48 | Valid | Epoch[457/600] MIou: 0.8816698847315589
2023-02-06 11:40:48 | Valid | Epoch[457/600] Pixel Accuracy: 0.9804725646972656
2023-02-06 11:40:48 | Valid | Epoch[457/600] Mean Pixel Accuracy: 0.8930819358943938
2023-02-06 11:40:48 | Stage | Epoch[457/600] Train loss:0.0201
2023-02-06 11:40:48 | Stage | Epoch[457/600] Valid loss:0.0350
2023-02-06 11:40:48 | Stage | Epoch[457/600] LR:0.001

2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[001/030] Train loss: 0.0226
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[002/030] Train loss: 0.0206
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[004/030] Train loss: 0.0190
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[007/030] Train loss: 0.0192
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[012/030] Train loss: 0.0194
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:40:49 | Train | Epoch[458/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:40:50 | Train | Epoch[458/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:40:50 | Valid | Epoch[458/600] Iteration[001/008] Valid loss: 0.0461
2023-02-06 11:40:50 | Valid | Epoch[458/600] Iteration[002/008] Valid loss: 0.0361
2023-02-06 11:40:50 | Valid | Epoch[458/600] Iteration[003/008] Valid loss: 0.0333
2023-02-06 11:40:50 | Valid | Epoch[458/600] Iteration[004/008] Valid loss: 0.0316
2023-02-06 11:40:50 | Valid | Epoch[458/600] Iteration[005/008] Valid loss: 0.0323
2023-02-06 11:40:51 | Valid | Epoch[458/600] Iteration[006/008] Valid loss: 0.0321
2023-02-06 11:40:51 | Valid | Epoch[458/600] Iteration[007/008] Valid loss: 0.0320
2023-02-06 11:40:51 | Valid | Epoch[458/600] Iteration[008/008] Valid loss: 0.0314
2023-02-06 11:40:51 | Valid | Epoch[458/600] MIou: 0.9195652840935025
2023-02-06 11:40:51 | Valid | Epoch[458/600] Pixel Accuracy: 0.9866193135579427
2023-02-06 11:40:51 | Valid | Epoch[458/600] Mean Pixel Accuracy: 0.9314471730243767
2023-02-06 11:40:51 | Stage | Epoch[458/600] Train loss:0.0202
2023-02-06 11:40:51 | Stage | Epoch[458/600] Valid loss:0.0314
2023-02-06 11:40:51 | Stage | Epoch[458/600] LR:0.001

2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[001/030] Train loss: 0.0177
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[005/030] Train loss: 0.0193
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[010/030] Train loss: 0.0199
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:40:51 | Train | Epoch[459/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:40:52 | Train | Epoch[459/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:40:53 | Valid | Epoch[459/600] Iteration[001/008] Valid loss: 0.0629
2023-02-06 11:40:53 | Valid | Epoch[459/600] Iteration[002/008] Valid loss: 0.0441
2023-02-06 11:40:53 | Valid | Epoch[459/600] Iteration[003/008] Valid loss: 0.0386
2023-02-06 11:40:53 | Valid | Epoch[459/600] Iteration[004/008] Valid loss: 0.0377
2023-02-06 11:40:53 | Valid | Epoch[459/600] Iteration[005/008] Valid loss: 0.0393
2023-02-06 11:40:53 | Valid | Epoch[459/600] Iteration[006/008] Valid loss: 0.0392
2023-02-06 11:40:53 | Valid | Epoch[459/600] Iteration[007/008] Valid loss: 0.0400
2023-02-06 11:40:53 | Valid | Epoch[459/600] Iteration[008/008] Valid loss: 0.0386
2023-02-06 11:40:53 | Valid | Epoch[459/600] MIou: 0.9346135757189259
2023-02-06 11:40:53 | Valid | Epoch[459/600] Pixel Accuracy: 0.9889882405598959
2023-02-06 11:40:53 | Valid | Epoch[459/600] Mean Pixel Accuracy: 0.9509463895766121
2023-02-06 11:40:53 | Stage | Epoch[459/600] Train loss:0.0203
2023-02-06 11:40:53 | Stage | Epoch[459/600] Valid loss:0.0386
2023-02-06 11:40:53 | Stage | Epoch[459/600] LR:0.001

2023-02-06 11:40:53 | Train | Epoch[460/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 11:40:53 | Train | Epoch[460/600] Iteration[002/030] Train loss: 0.0224
2023-02-06 11:40:53 | Train | Epoch[460/600] Iteration[003/030] Train loss: 0.0208
2023-02-06 11:40:53 | Train | Epoch[460/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:40:53 | Train | Epoch[460/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:40:53 | Train | Epoch[460/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:40:53 | Train | Epoch[460/600] Iteration[007/030] Train loss: 0.0211
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[027/030] Train loss: 0.0204
2023-02-06 11:40:54 | Train | Epoch[460/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:40:55 | Train | Epoch[460/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:40:55 | Train | Epoch[460/600] Iteration[030/030] Train loss: 0.0204
2023-02-06 11:40:55 | Valid | Epoch[460/600] Iteration[001/008] Valid loss: 0.0487
2023-02-06 11:40:55 | Valid | Epoch[460/600] Iteration[002/008] Valid loss: 0.0371
2023-02-06 11:40:55 | Valid | Epoch[460/600] Iteration[003/008] Valid loss: 0.0338
2023-02-06 11:40:55 | Valid | Epoch[460/600] Iteration[004/008] Valid loss: 0.0321
2023-02-06 11:40:55 | Valid | Epoch[460/600] Iteration[005/008] Valid loss: 0.0330
2023-02-06 11:40:55 | Valid | Epoch[460/600] Iteration[006/008] Valid loss: 0.0328
2023-02-06 11:40:55 | Valid | Epoch[460/600] Iteration[007/008] Valid loss: 0.0328
2023-02-06 11:40:55 | Valid | Epoch[460/600] Iteration[008/008] Valid loss: 0.0321
2023-02-06 11:40:55 | Valid | Epoch[460/600] MIou: 0.923869868274867
2023-02-06 11:40:55 | Valid | Epoch[460/600] Pixel Accuracy: 0.9873059590657552
2023-02-06 11:40:55 | Valid | Epoch[460/600] Mean Pixel Accuracy: 0.9364594673555233
2023-02-06 11:40:55 | Stage | Epoch[460/600] Train loss:0.0204
2023-02-06 11:40:55 | Stage | Epoch[460/600] Valid loss:0.0321
2023-02-06 11:40:55 | Stage | Epoch[460/600] LR:0.001

2023-02-06 11:40:55 | Train | Epoch[461/600] Iteration[001/030] Train loss: 0.0195
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[002/030] Train loss: 0.0191
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:40:56 | Train | Epoch[461/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:40:57 | Train | Epoch[461/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:40:57 | Train | Epoch[461/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:40:57 | Train | Epoch[461/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:40:57 | Train | Epoch[461/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:40:57 | Train | Epoch[461/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:40:57 | Train | Epoch[461/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:40:57 | Train | Epoch[461/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:40:57 | Train | Epoch[461/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:40:57 | Valid | Epoch[461/600] Iteration[001/008] Valid loss: 0.0722
2023-02-06 11:40:57 | Valid | Epoch[461/600] Iteration[002/008] Valid loss: 0.0495
2023-02-06 11:40:57 | Valid | Epoch[461/600] Iteration[003/008] Valid loss: 0.0428
2023-02-06 11:40:57 | Valid | Epoch[461/600] Iteration[004/008] Valid loss: 0.0424
2023-02-06 11:40:57 | Valid | Epoch[461/600] Iteration[005/008] Valid loss: 0.0442
2023-02-06 11:40:57 | Valid | Epoch[461/600] Iteration[006/008] Valid loss: 0.0442
2023-02-06 11:40:57 | Valid | Epoch[461/600] Iteration[007/008] Valid loss: 0.0457
2023-02-06 11:40:57 | Valid | Epoch[461/600] Iteration[008/008] Valid loss: 0.0437
2023-02-06 11:40:58 | Valid | Epoch[461/600] MIou: 0.9395625703673312
2023-02-06 11:40:58 | Valid | Epoch[461/600] Pixel Accuracy: 0.9897664388020834
2023-02-06 11:40:58 | Valid | Epoch[461/600] Mean Pixel Accuracy: 0.9580886798511632
2023-02-06 11:40:58 | Stage | Epoch[461/600] Train loss:0.0201
2023-02-06 11:40:58 | Stage | Epoch[461/600] Valid loss:0.0437
2023-02-06 11:40:58 | Stage | Epoch[461/600] LR:0.001

2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[002/030] Train loss: 0.0214
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[005/030] Train loss: 0.0210
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:40:58 | Train | Epoch[462/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:40:59 | Train | Epoch[462/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:41:00 | Valid | Epoch[462/600] Iteration[001/008] Valid loss: 0.0536
2023-02-06 11:41:00 | Valid | Epoch[462/600] Iteration[002/008] Valid loss: 0.0394
2023-02-06 11:41:00 | Valid | Epoch[462/600] Iteration[003/008] Valid loss: 0.0352
2023-02-06 11:41:00 | Valid | Epoch[462/600] Iteration[004/008] Valid loss: 0.0336
2023-02-06 11:41:00 | Valid | Epoch[462/600] Iteration[005/008] Valid loss: 0.0347
2023-02-06 11:41:00 | Valid | Epoch[462/600] Iteration[006/008] Valid loss: 0.0348
2023-02-06 11:41:00 | Valid | Epoch[462/600] Iteration[007/008] Valid loss: 0.0351
2023-02-06 11:41:00 | Valid | Epoch[462/600] Iteration[008/008] Valid loss: 0.0341
2023-02-06 11:41:00 | Valid | Epoch[462/600] MIou: 0.9291251736506185
2023-02-06 11:41:00 | Valid | Epoch[462/600] Pixel Accuracy: 0.9881362915039062
2023-02-06 11:41:00 | Valid | Epoch[462/600] Mean Pixel Accuracy: 0.9430724513145827
2023-02-06 11:41:00 | Stage | Epoch[462/600] Train loss:0.0203
2023-02-06 11:41:00 | Stage | Epoch[462/600] Valid loss:0.0341
2023-02-06 11:41:00 | Stage | Epoch[462/600] LR:0.001

2023-02-06 11:41:00 | Train | Epoch[463/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 11:41:00 | Train | Epoch[463/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:41:00 | Train | Epoch[463/600] Iteration[003/030] Train loss: 0.0214
2023-02-06 11:41:00 | Train | Epoch[463/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:41:00 | Train | Epoch[463/600] Iteration[005/030] Train loss: 0.0210
2023-02-06 11:41:00 | Train | Epoch[463/600] Iteration[006/030] Train loss: 0.0209
2023-02-06 11:41:00 | Train | Epoch[463/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:41:00 | Train | Epoch[463/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:41:00 | Train | Epoch[463/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[017/030] Train loss: 0.0196
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:41:01 | Train | Epoch[463/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:41:02 | Valid | Epoch[463/600] Iteration[001/008] Valid loss: 0.0554
2023-02-06 11:41:02 | Valid | Epoch[463/600] Iteration[002/008] Valid loss: 0.0403
2023-02-06 11:41:02 | Valid | Epoch[463/600] Iteration[003/008] Valid loss: 0.0360
2023-02-06 11:41:02 | Valid | Epoch[463/600] Iteration[004/008] Valid loss: 0.0349
2023-02-06 11:41:02 | Valid | Epoch[463/600] Iteration[005/008] Valid loss: 0.0358
2023-02-06 11:41:02 | Valid | Epoch[463/600] Iteration[006/008] Valid loss: 0.0356
2023-02-06 11:41:02 | Valid | Epoch[463/600] Iteration[007/008] Valid loss: 0.0359
2023-02-06 11:41:02 | Valid | Epoch[463/600] Iteration[008/008] Valid loss: 0.0348
2023-02-06 11:41:02 | Valid | Epoch[463/600] MIou: 0.9303241850953827
2023-02-06 11:41:02 | Valid | Epoch[463/600] Pixel Accuracy: 0.9883308410644531
2023-02-06 11:41:02 | Valid | Epoch[463/600] Mean Pixel Accuracy: 0.944428456938277
2023-02-06 11:41:02 | Stage | Epoch[463/600] Train loss:0.0198
2023-02-06 11:41:02 | Stage | Epoch[463/600] Valid loss:0.0348
2023-02-06 11:41:02 | Stage | Epoch[463/600] LR:0.001

2023-02-06 11:41:02 | Train | Epoch[464/600] Iteration[001/030] Train loss: 0.0176
2023-02-06 11:41:02 | Train | Epoch[464/600] Iteration[002/030] Train loss: 0.0178
2023-02-06 11:41:02 | Train | Epoch[464/600] Iteration[003/030] Train loss: 0.0189
2023-02-06 11:41:02 | Train | Epoch[464/600] Iteration[004/030] Train loss: 0.0189
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[005/030] Train loss: 0.0190
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:41:03 | Train | Epoch[464/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:41:04 | Train | Epoch[464/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:41:04 | Train | Epoch[464/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:41:04 | Train | Epoch[464/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:41:04 | Train | Epoch[464/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:41:04 | Train | Epoch[464/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:41:04 | Valid | Epoch[464/600] Iteration[001/008] Valid loss: 0.0453
2023-02-06 11:41:04 | Valid | Epoch[464/600] Iteration[002/008] Valid loss: 0.0360
2023-02-06 11:41:04 | Valid | Epoch[464/600] Iteration[003/008] Valid loss: 0.0334
2023-02-06 11:41:04 | Valid | Epoch[464/600] Iteration[004/008] Valid loss: 0.0318
2023-02-06 11:41:04 | Valid | Epoch[464/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 11:41:04 | Valid | Epoch[464/600] Iteration[006/008] Valid loss: 0.0324
2023-02-06 11:41:04 | Valid | Epoch[464/600] Iteration[007/008] Valid loss: 0.0321
2023-02-06 11:41:04 | Valid | Epoch[464/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 11:41:04 | Valid | Epoch[464/600] MIou: 0.9168980687054448
2023-02-06 11:41:04 | Valid | Epoch[464/600] Pixel Accuracy: 0.9861907958984375
2023-02-06 11:41:04 | Valid | Epoch[464/600] Mean Pixel Accuracy: 0.9284979196357063
2023-02-06 11:41:04 | Stage | Epoch[464/600] Train loss:0.0201
2023-02-06 11:41:04 | Stage | Epoch[464/600] Valid loss:0.0316
2023-02-06 11:41:04 | Stage | Epoch[464/600] LR:0.001

2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[002/030] Train loss: 0.0170
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[003/030] Train loss: 0.0181
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[009/030] Train loss: 0.0192
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:41:05 | Train | Epoch[465/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:41:06 | Train | Epoch[465/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:41:06 | Train | Epoch[465/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:41:06 | Train | Epoch[465/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:41:06 | Train | Epoch[465/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:41:06 | Train | Epoch[465/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:41:06 | Train | Epoch[465/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:41:06 | Train | Epoch[465/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:41:06 | Train | Epoch[465/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:41:06 | Train | Epoch[465/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:41:06 | Train | Epoch[465/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:41:06 | Valid | Epoch[465/600] Iteration[001/008] Valid loss: 0.0866
2023-02-06 11:41:06 | Valid | Epoch[465/600] Iteration[002/008] Valid loss: 0.0585
2023-02-06 11:41:06 | Valid | Epoch[465/600] Iteration[003/008] Valid loss: 0.0503
2023-02-06 11:41:06 | Valid | Epoch[465/600] Iteration[004/008] Valid loss: 0.0506
2023-02-06 11:41:06 | Valid | Epoch[465/600] Iteration[005/008] Valid loss: 0.0535
2023-02-06 11:41:06 | Valid | Epoch[465/600] Iteration[006/008] Valid loss: 0.0530
2023-02-06 11:41:06 | Valid | Epoch[465/600] Iteration[007/008] Valid loss: 0.0554
2023-02-06 11:41:06 | Valid | Epoch[465/600] Iteration[008/008] Valid loss: 0.0529
2023-02-06 11:41:07 | Valid | Epoch[465/600] MIou: 0.9415265120631312
2023-02-06 11:41:07 | Valid | Epoch[465/600] Pixel Accuracy: 0.9900156656901041
2023-02-06 11:41:07 | Valid | Epoch[465/600] Mean Pixel Accuracy: 0.9638433233377919
2023-02-06 11:41:07 | Stage | Epoch[465/600] Train loss:0.0200
2023-02-06 11:41:07 | Stage | Epoch[465/600] Valid loss:0.0529
2023-02-06 11:41:07 | Stage | Epoch[465/600] LR:0.001

2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:41:07 | Train | Epoch[466/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[018/030] Train loss: 0.0195
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:41:08 | Train | Epoch[466/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:41:09 | Valid | Epoch[466/600] Iteration[001/008] Valid loss: 0.0559
2023-02-06 11:41:09 | Valid | Epoch[466/600] Iteration[002/008] Valid loss: 0.0408
2023-02-06 11:41:09 | Valid | Epoch[466/600] Iteration[003/008] Valid loss: 0.0363
2023-02-06 11:41:09 | Valid | Epoch[466/600] Iteration[004/008] Valid loss: 0.0347
2023-02-06 11:41:09 | Valid | Epoch[466/600] Iteration[005/008] Valid loss: 0.0361
2023-02-06 11:41:09 | Valid | Epoch[466/600] Iteration[006/008] Valid loss: 0.0360
2023-02-06 11:41:09 | Valid | Epoch[466/600] Iteration[007/008] Valid loss: 0.0364
2023-02-06 11:41:09 | Valid | Epoch[466/600] Iteration[008/008] Valid loss: 0.0353
2023-02-06 11:41:09 | Valid | Epoch[466/600] MIou: 0.9299150475315066
2023-02-06 11:41:09 | Valid | Epoch[466/600] Pixel Accuracy: 0.9882558186848959
2023-02-06 11:41:09 | Valid | Epoch[466/600] Mean Pixel Accuracy: 0.944292114366164
2023-02-06 11:41:09 | Stage | Epoch[466/600] Train loss:0.0201
2023-02-06 11:41:09 | Stage | Epoch[466/600] Valid loss:0.0353
2023-02-06 11:41:09 | Stage | Epoch[466/600] LR:0.001

2023-02-06 11:41:09 | Train | Epoch[467/600] Iteration[001/030] Train loss: 0.0181
2023-02-06 11:41:09 | Train | Epoch[467/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:41:09 | Train | Epoch[467/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 11:41:09 | Train | Epoch[467/600] Iteration[004/030] Train loss: 0.0188
2023-02-06 11:41:09 | Train | Epoch[467/600] Iteration[005/030] Train loss: 0.0190
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:41:10 | Train | Epoch[467/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:41:11 | Train | Epoch[467/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:41:11 | Train | Epoch[467/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:41:11 | Train | Epoch[467/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:41:11 | Train | Epoch[467/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:41:11 | Valid | Epoch[467/600] Iteration[001/008] Valid loss: 0.0846
2023-02-06 11:41:11 | Valid | Epoch[467/600] Iteration[002/008] Valid loss: 0.0571
2023-02-06 11:41:11 | Valid | Epoch[467/600] Iteration[003/008] Valid loss: 0.0489
2023-02-06 11:41:11 | Valid | Epoch[467/600] Iteration[004/008] Valid loss: 0.0491
2023-02-06 11:41:11 | Valid | Epoch[467/600] Iteration[005/008] Valid loss: 0.0522
2023-02-06 11:41:11 | Valid | Epoch[467/600] Iteration[006/008] Valid loss: 0.0517
2023-02-06 11:41:11 | Valid | Epoch[467/600] Iteration[007/008] Valid loss: 0.0539
2023-02-06 11:41:11 | Valid | Epoch[467/600] Iteration[008/008] Valid loss: 0.0515
2023-02-06 11:41:11 | Valid | Epoch[467/600] MIou: 0.9411310042106897
2023-02-06 11:41:11 | Valid | Epoch[467/600] Pixel Accuracy: 0.9899520874023438
2023-02-06 11:41:11 | Valid | Epoch[467/600] Mean Pixel Accuracy: 0.9632821188637878
2023-02-06 11:41:11 | Stage | Epoch[467/600] Train loss:0.0199
2023-02-06 11:41:11 | Stage | Epoch[467/600] Valid loss:0.0515
2023-02-06 11:41:11 | Stage | Epoch[467/600] LR:0.001

2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 11:41:12 | Train | Epoch[468/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:41:13 | Train | Epoch[468/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:41:13 | Valid | Epoch[468/600] Iteration[001/008] Valid loss: 0.0508
2023-02-06 11:41:13 | Valid | Epoch[468/600] Iteration[002/008] Valid loss: 0.0381
2023-02-06 11:41:13 | Valid | Epoch[468/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:41:13 | Valid | Epoch[468/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 11:41:13 | Valid | Epoch[468/600] Iteration[005/008] Valid loss: 0.0337
2023-02-06 11:41:13 | Valid | Epoch[468/600] Iteration[006/008] Valid loss: 0.0336
2023-02-06 11:41:13 | Valid | Epoch[468/600] Iteration[007/008] Valid loss: 0.0338
2023-02-06 11:41:13 | Valid | Epoch[468/600] Iteration[008/008] Valid loss: 0.0330
2023-02-06 11:41:14 | Valid | Epoch[468/600] MIou: 0.9252440512757012
2023-02-06 11:41:14 | Valid | Epoch[468/600] Pixel Accuracy: 0.9875221252441406
2023-02-06 11:41:14 | Valid | Epoch[468/600] Mean Pixel Accuracy: 0.9381951017420089
2023-02-06 11:41:14 | Stage | Epoch[468/600] Train loss:0.0201
2023-02-06 11:41:14 | Stage | Epoch[468/600] Valid loss:0.0330
2023-02-06 11:41:14 | Stage | Epoch[468/600] LR:0.001

2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[003/030] Train loss: 0.0193
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[007/030] Train loss: 0.0200
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[011/030] Train loss: 0.0204
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:41:14 | Train | Epoch[469/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:41:15 | Train | Epoch[469/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:41:16 | Valid | Epoch[469/600] Iteration[001/008] Valid loss: 0.0558
2023-02-06 11:41:16 | Valid | Epoch[469/600] Iteration[002/008] Valid loss: 0.0404
2023-02-06 11:41:16 | Valid | Epoch[469/600] Iteration[003/008] Valid loss: 0.0360
2023-02-06 11:41:16 | Valid | Epoch[469/600] Iteration[004/008] Valid loss: 0.0345
2023-02-06 11:41:16 | Valid | Epoch[469/600] Iteration[005/008] Valid loss: 0.0356
2023-02-06 11:41:16 | Valid | Epoch[469/600] Iteration[006/008] Valid loss: 0.0356
2023-02-06 11:41:16 | Valid | Epoch[469/600] Iteration[007/008] Valid loss: 0.0361
2023-02-06 11:41:16 | Valid | Epoch[469/600] Iteration[008/008] Valid loss: 0.0350
2023-02-06 11:41:16 | Valid | Epoch[469/600] MIou: 0.9302842946527492
2023-02-06 11:41:16 | Valid | Epoch[469/600] Pixel Accuracy: 0.9883206685384115
2023-02-06 11:41:16 | Valid | Epoch[469/600] Mean Pixel Accuracy: 0.9445243132283101
2023-02-06 11:41:16 | Stage | Epoch[469/600] Train loss:0.0202
2023-02-06 11:41:16 | Stage | Epoch[469/600] Valid loss:0.0350
2023-02-06 11:41:16 | Stage | Epoch[469/600] LR:0.001

2023-02-06 11:41:16 | Train | Epoch[470/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 11:41:16 | Train | Epoch[470/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:41:16 | Train | Epoch[470/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:41:16 | Train | Epoch[470/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:41:16 | Train | Epoch[470/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:41:16 | Train | Epoch[470/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:41:16 | Train | Epoch[470/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:41:17 | Train | Epoch[470/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:41:18 | Train | Epoch[470/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:41:18 | Train | Epoch[470/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:41:18 | Train | Epoch[470/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:41:18 | Valid | Epoch[470/600] Iteration[001/008] Valid loss: 0.0439
2023-02-06 11:41:18 | Valid | Epoch[470/600] Iteration[002/008] Valid loss: 0.0358
2023-02-06 11:41:18 | Valid | Epoch[470/600] Iteration[003/008] Valid loss: 0.0335
2023-02-06 11:41:18 | Valid | Epoch[470/600] Iteration[004/008] Valid loss: 0.0319
2023-02-06 11:41:18 | Valid | Epoch[470/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 11:41:18 | Valid | Epoch[470/600] Iteration[006/008] Valid loss: 0.0323
2023-02-06 11:41:18 | Valid | Epoch[470/600] Iteration[007/008] Valid loss: 0.0319
2023-02-06 11:41:18 | Valid | Epoch[470/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 11:41:18 | Valid | Epoch[470/600] MIou: 0.9126280429418339
2023-02-06 11:41:18 | Valid | Epoch[470/600] Pixel Accuracy: 0.9855066935221354
2023-02-06 11:41:18 | Valid | Epoch[470/600] Mean Pixel Accuracy: 0.9237913657506795
2023-02-06 11:41:18 | Stage | Epoch[470/600] Train loss:0.0202
2023-02-06 11:41:18 | Stage | Epoch[470/600] Valid loss:0.0316
2023-02-06 11:41:18 | Stage | Epoch[470/600] LR:0.001

2023-02-06 11:41:18 | Train | Epoch[471/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[002/030] Train loss: 0.0202
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:41:19 | Train | Epoch[471/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:41:20 | Train | Epoch[471/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:41:20 | Train | Epoch[471/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:41:20 | Train | Epoch[471/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:41:20 | Train | Epoch[471/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:41:20 | Train | Epoch[471/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:41:20 | Train | Epoch[471/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:41:20 | Train | Epoch[471/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:41:20 | Train | Epoch[471/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:41:20 | Train | Epoch[471/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:41:20 | Valid | Epoch[471/600] Iteration[001/008] Valid loss: 0.0663
2023-02-06 11:41:20 | Valid | Epoch[471/600] Iteration[002/008] Valid loss: 0.0460
2023-02-06 11:41:20 | Valid | Epoch[471/600] Iteration[003/008] Valid loss: 0.0400
2023-02-06 11:41:20 | Valid | Epoch[471/600] Iteration[004/008] Valid loss: 0.0392
2023-02-06 11:41:20 | Valid | Epoch[471/600] Iteration[005/008] Valid loss: 0.0408
2023-02-06 11:41:20 | Valid | Epoch[471/600] Iteration[006/008] Valid loss: 0.0402
2023-02-06 11:41:20 | Valid | Epoch[471/600] Iteration[007/008] Valid loss: 0.0414
2023-02-06 11:41:20 | Valid | Epoch[471/600] Iteration[008/008] Valid loss: 0.0398
2023-02-06 11:41:21 | Valid | Epoch[471/600] MIou: 0.9357182182822172
2023-02-06 11:41:21 | Valid | Epoch[471/600] Pixel Accuracy: 0.9891649881998698
2023-02-06 11:41:21 | Valid | Epoch[471/600] Mean Pixel Accuracy: 0.9523750366351831
2023-02-06 11:41:21 | Stage | Epoch[471/600] Train loss:0.0200
2023-02-06 11:41:21 | Stage | Epoch[471/600] Valid loss:0.0398
2023-02-06 11:41:21 | Stage | Epoch[471/600] LR:0.001

2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[001/030] Train loss: 0.0190
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[004/030] Train loss: 0.0213
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:41:21 | Train | Epoch[472/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:41:22 | Train | Epoch[472/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:41:23 | Valid | Epoch[472/600] Iteration[001/008] Valid loss: 0.0702
2023-02-06 11:41:23 | Valid | Epoch[472/600] Iteration[002/008] Valid loss: 0.0484
2023-02-06 11:41:23 | Valid | Epoch[472/600] Iteration[003/008] Valid loss: 0.0418
2023-02-06 11:41:23 | Valid | Epoch[472/600] Iteration[004/008] Valid loss: 0.0411
2023-02-06 11:41:23 | Valid | Epoch[472/600] Iteration[005/008] Valid loss: 0.0432
2023-02-06 11:41:23 | Valid | Epoch[472/600] Iteration[006/008] Valid loss: 0.0429
2023-02-06 11:41:23 | Valid | Epoch[472/600] Iteration[007/008] Valid loss: 0.0443
2023-02-06 11:41:23 | Valid | Epoch[472/600] Iteration[008/008] Valid loss: 0.0424
2023-02-06 11:41:23 | Valid | Epoch[472/600] MIou: 0.9385781670753697
2023-02-06 11:41:23 | Valid | Epoch[472/600] Pixel Accuracy: 0.9896100362141927
2023-02-06 11:41:23 | Valid | Epoch[472/600] Mean Pixel Accuracy: 0.9567029176584732
2023-02-06 11:41:23 | Stage | Epoch[472/600] Train loss:0.0202
2023-02-06 11:41:23 | Stage | Epoch[472/600] Valid loss:0.0424
2023-02-06 11:41:23 | Stage | Epoch[472/600] LR:0.001

2023-02-06 11:41:23 | Train | Epoch[473/600] Iteration[001/030] Train loss: 0.0220
2023-02-06 11:41:23 | Train | Epoch[473/600] Iteration[002/030] Train loss: 0.0229
2023-02-06 11:41:23 | Train | Epoch[473/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:41:23 | Train | Epoch[473/600] Iteration[004/030] Train loss: 0.0219
2023-02-06 11:41:23 | Train | Epoch[473/600] Iteration[005/030] Train loss: 0.0217
2023-02-06 11:41:23 | Train | Epoch[473/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:41:23 | Train | Epoch[473/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:41:23 | Train | Epoch[473/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:41:23 | Train | Epoch[473/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[027/030] Train loss: 0.0204
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:41:24 | Train | Epoch[473/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:41:25 | Valid | Epoch[473/600] Iteration[001/008] Valid loss: 0.0440
2023-02-06 11:41:25 | Valid | Epoch[473/600] Iteration[002/008] Valid loss: 0.0357
2023-02-06 11:41:25 | Valid | Epoch[473/600] Iteration[003/008] Valid loss: 0.0334
2023-02-06 11:41:25 | Valid | Epoch[473/600] Iteration[004/008] Valid loss: 0.0319
2023-02-06 11:41:25 | Valid | Epoch[473/600] Iteration[005/008] Valid loss: 0.0326
2023-02-06 11:41:25 | Valid | Epoch[473/600] Iteration[006/008] Valid loss: 0.0323
2023-02-06 11:41:25 | Valid | Epoch[473/600] Iteration[007/008] Valid loss: 0.0319
2023-02-06 11:41:25 | Valid | Epoch[473/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 11:41:25 | Valid | Epoch[473/600] MIou: 0.9130118913849018
2023-02-06 11:41:25 | Valid | Epoch[473/600] Pixel Accuracy: 0.9855639139811198
2023-02-06 11:41:25 | Valid | Epoch[473/600] Mean Pixel Accuracy: 0.9243363947478094
2023-02-06 11:41:25 | Stage | Epoch[473/600] Train loss:0.0202
2023-02-06 11:41:25 | Stage | Epoch[473/600] Valid loss:0.0316
2023-02-06 11:41:25 | Stage | Epoch[473/600] LR:0.001

2023-02-06 11:41:25 | Train | Epoch[474/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 11:41:25 | Train | Epoch[474/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:41:25 | Train | Epoch[474/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[007/030] Train loss: 0.0191
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[009/030] Train loss: 0.0196
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[011/030] Train loss: 0.0191
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:41:26 | Train | Epoch[474/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:41:27 | Train | Epoch[474/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:41:27 | Train | Epoch[474/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:41:27 | Train | Epoch[474/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:41:27 | Train | Epoch[474/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:41:27 | Train | Epoch[474/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:41:27 | Train | Epoch[474/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:41:27 | Valid | Epoch[474/600] Iteration[001/008] Valid loss: 0.0418
2023-02-06 11:41:27 | Valid | Epoch[474/600] Iteration[002/008] Valid loss: 0.0360
2023-02-06 11:41:27 | Valid | Epoch[474/600] Iteration[003/008] Valid loss: 0.0346
2023-02-06 11:41:27 | Valid | Epoch[474/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:41:27 | Valid | Epoch[474/600] Iteration[005/008] Valid loss: 0.0336
2023-02-06 11:41:27 | Valid | Epoch[474/600] Iteration[006/008] Valid loss: 0.0334
2023-02-06 11:41:27 | Valid | Epoch[474/600] Iteration[007/008] Valid loss: 0.0326
2023-02-06 11:41:27 | Valid | Epoch[474/600] Iteration[008/008] Valid loss: 0.0327
2023-02-06 11:41:27 | Valid | Epoch[474/600] MIou: 0.9001550597946575
2023-02-06 11:41:27 | Valid | Epoch[474/600] Pixel Accuracy: 0.9834823608398438
2023-02-06 11:41:27 | Valid | Epoch[474/600] Mean Pixel Accuracy: 0.9111263670777818
2023-02-06 11:41:27 | Stage | Epoch[474/600] Train loss:0.0199
2023-02-06 11:41:27 | Stage | Epoch[474/600] Valid loss:0.0327
2023-02-06 11:41:27 | Stage | Epoch[474/600] LR:0.001

2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[001/030] Train loss: 0.0220
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[004/030] Train loss: 0.0201
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:41:28 | Train | Epoch[475/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[022/030] Train loss: 0.0206
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:41:29 | Train | Epoch[475/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:41:29 | Valid | Epoch[475/600] Iteration[001/008] Valid loss: 0.0594
2023-02-06 11:41:29 | Valid | Epoch[475/600] Iteration[002/008] Valid loss: 0.0424
2023-02-06 11:41:29 | Valid | Epoch[475/600] Iteration[003/008] Valid loss: 0.0374
2023-02-06 11:41:29 | Valid | Epoch[475/600] Iteration[004/008] Valid loss: 0.0363
2023-02-06 11:41:29 | Valid | Epoch[475/600] Iteration[005/008] Valid loss: 0.0378
2023-02-06 11:41:29 | Valid | Epoch[475/600] Iteration[006/008] Valid loss: 0.0379
2023-02-06 11:41:29 | Valid | Epoch[475/600] Iteration[007/008] Valid loss: 0.0385
2023-02-06 11:41:29 | Valid | Epoch[475/600] Iteration[008/008] Valid loss: 0.0371
2023-02-06 11:41:30 | Valid | Epoch[475/600] MIou: 0.9340135155712295
2023-02-06 11:41:30 | Valid | Epoch[475/600] Pixel Accuracy: 0.9889106750488281
2023-02-06 11:41:30 | Valid | Epoch[475/600] Mean Pixel Accuracy: 0.9494264264013257
2023-02-06 11:41:30 | Stage | Epoch[475/600] Train loss:0.0203
2023-02-06 11:41:30 | Stage | Epoch[475/600] Valid loss:0.0371
2023-02-06 11:41:30 | Stage | Epoch[475/600] LR:0.001

2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[002/030] Train loss: 0.0185
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[004/030] Train loss: 0.0198
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:41:30 | Train | Epoch[476/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[018/030] Train loss: 0.0206
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[022/030] Train loss: 0.0208
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[023/030] Train loss: 0.0207
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[024/030] Train loss: 0.0206
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:41:31 | Train | Epoch[476/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:41:32 | Valid | Epoch[476/600] Iteration[001/008] Valid loss: 0.0594
2023-02-06 11:41:32 | Valid | Epoch[476/600] Iteration[002/008] Valid loss: 0.0423
2023-02-06 11:41:32 | Valid | Epoch[476/600] Iteration[003/008] Valid loss: 0.0373
2023-02-06 11:41:32 | Valid | Epoch[476/600] Iteration[004/008] Valid loss: 0.0363
2023-02-06 11:41:32 | Valid | Epoch[476/600] Iteration[005/008] Valid loss: 0.0374
2023-02-06 11:41:32 | Valid | Epoch[476/600] Iteration[006/008] Valid loss: 0.0373
2023-02-06 11:41:32 | Valid | Epoch[476/600] Iteration[007/008] Valid loss: 0.0379
2023-02-06 11:41:32 | Valid | Epoch[476/600] Iteration[008/008] Valid loss: 0.0366
2023-02-06 11:41:32 | Valid | Epoch[476/600] MIou: 0.9335098834127356
2023-02-06 11:41:32 | Valid | Epoch[476/600] Pixel Accuracy: 0.9888343811035156
2023-02-06 11:41:32 | Valid | Epoch[476/600] Mean Pixel Accuracy: 0.9486172949421623
2023-02-06 11:41:32 | Stage | Epoch[476/600] Train loss:0.0201
2023-02-06 11:41:32 | Stage | Epoch[476/600] Valid loss:0.0366
2023-02-06 11:41:32 | Stage | Epoch[476/600] LR:0.001

2023-02-06 11:41:32 | Train | Epoch[477/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 11:41:32 | Train | Epoch[477/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 11:41:32 | Train | Epoch[477/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:41:32 | Train | Epoch[477/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 11:41:32 | Train | Epoch[477/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:41:32 | Train | Epoch[477/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:41:32 | Train | Epoch[477/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:41:33 | Train | Epoch[477/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:41:34 | Train | Epoch[477/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:41:34 | Train | Epoch[477/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:41:34 | Train | Epoch[477/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:41:34 | Valid | Epoch[477/600] Iteration[001/008] Valid loss: 0.0419
2023-02-06 11:41:34 | Valid | Epoch[477/600] Iteration[002/008] Valid loss: 0.0353
2023-02-06 11:41:34 | Valid | Epoch[477/600] Iteration[003/008] Valid loss: 0.0336
2023-02-06 11:41:34 | Valid | Epoch[477/600] Iteration[004/008] Valid loss: 0.0320
2023-02-06 11:41:34 | Valid | Epoch[477/600] Iteration[005/008] Valid loss: 0.0329
2023-02-06 11:41:34 | Valid | Epoch[477/600] Iteration[006/008] Valid loss: 0.0326
2023-02-06 11:41:34 | Valid | Epoch[477/600] Iteration[007/008] Valid loss: 0.0320
2023-02-06 11:41:34 | Valid | Epoch[477/600] Iteration[008/008] Valid loss: 0.0319
2023-02-06 11:41:34 | Valid | Epoch[477/600] MIou: 0.9070822689295748
2023-02-06 11:41:34 | Valid | Epoch[477/600] Pixel Accuracy: 0.9845962524414062
2023-02-06 11:41:34 | Valid | Epoch[477/600] Mean Pixel Accuracy: 0.9183961044960122
2023-02-06 11:41:34 | Stage | Epoch[477/600] Train loss:0.0201
2023-02-06 11:41:34 | Stage | Epoch[477/600] Valid loss:0.0319
2023-02-06 11:41:34 | Stage | Epoch[477/600] LR:0.001

2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[001/030] Train loss: 0.0215
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[002/030] Train loss: 0.0203
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[006/030] Train loss: 0.0199
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:41:35 | Train | Epoch[478/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:41:36 | Train | Epoch[478/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:41:36 | Train | Epoch[478/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:41:36 | Train | Epoch[478/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:41:36 | Train | Epoch[478/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:41:36 | Train | Epoch[478/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:41:36 | Train | Epoch[478/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:41:36 | Train | Epoch[478/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:41:36 | Train | Epoch[478/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:41:36 | Train | Epoch[478/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:41:36 | Valid | Epoch[478/600] Iteration[001/008] Valid loss: 0.0445
2023-02-06 11:41:36 | Valid | Epoch[478/600] Iteration[002/008] Valid loss: 0.0423
2023-02-06 11:41:36 | Valid | Epoch[478/600] Iteration[003/008] Valid loss: 0.0421
2023-02-06 11:41:36 | Valid | Epoch[478/600] Iteration[004/008] Valid loss: 0.0403
2023-02-06 11:41:36 | Valid | Epoch[478/600] Iteration[005/008] Valid loss: 0.0409
2023-02-06 11:41:36 | Valid | Epoch[478/600] Iteration[006/008] Valid loss: 0.0403
2023-02-06 11:41:36 | Valid | Epoch[478/600] Iteration[007/008] Valid loss: 0.0390
2023-02-06 11:41:36 | Valid | Epoch[478/600] Iteration[008/008] Valid loss: 0.0398
2023-02-06 11:41:37 | Valid | Epoch[478/600] MIou: 0.8640061738139453
2023-02-06 11:41:37 | Valid | Epoch[478/600] Pixel Accuracy: 0.9775810241699219
2023-02-06 11:41:37 | Valid | Epoch[478/600] Mean Pixel Accuracy: 0.876414980643619
2023-02-06 11:41:37 | Stage | Epoch[478/600] Train loss:0.0201
2023-02-06 11:41:37 | Stage | Epoch[478/600] Valid loss:0.0398
2023-02-06 11:41:37 | Stage | Epoch[478/600] LR:0.001

2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[006/030] Train loss: 0.0211
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[007/030] Train loss: 0.0216
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[008/030] Train loss: 0.0211
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[012/030] Train loss: 0.0206
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:41:37 | Train | Epoch[479/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[017/030] Train loss: 0.0206
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:41:38 | Train | Epoch[479/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:41:39 | Valid | Epoch[479/600] Iteration[001/008] Valid loss: 0.0803
2023-02-06 11:41:39 | Valid | Epoch[479/600] Iteration[002/008] Valid loss: 0.0545
2023-02-06 11:41:39 | Valid | Epoch[479/600] Iteration[003/008] Valid loss: 0.0469
2023-02-06 11:41:39 | Valid | Epoch[479/600] Iteration[004/008] Valid loss: 0.0470
2023-02-06 11:41:39 | Valid | Epoch[479/600] Iteration[005/008] Valid loss: 0.0494
2023-02-06 11:41:39 | Valid | Epoch[479/600] Iteration[006/008] Valid loss: 0.0493
2023-02-06 11:41:39 | Valid | Epoch[479/600] Iteration[007/008] Valid loss: 0.0515
2023-02-06 11:41:39 | Valid | Epoch[479/600] Iteration[008/008] Valid loss: 0.0491
2023-02-06 11:41:39 | Valid | Epoch[479/600] MIou: 0.941220801495074
2023-02-06 11:41:39 | Valid | Epoch[479/600] Pixel Accuracy: 0.9899953206380209
2023-02-06 11:41:39 | Valid | Epoch[479/600] Mean Pixel Accuracy: 0.9620694897491132
2023-02-06 11:41:39 | Stage | Epoch[479/600] Train loss:0.0202
2023-02-06 11:41:39 | Stage | Epoch[479/600] Valid loss:0.0491
2023-02-06 11:41:39 | Stage | Epoch[479/600] LR:0.001

2023-02-06 11:41:39 | Train | Epoch[480/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 11:41:39 | Train | Epoch[480/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 11:41:39 | Train | Epoch[480/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:41:39 | Train | Epoch[480/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:41:39 | Train | Epoch[480/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:41:39 | Train | Epoch[480/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:41:39 | Train | Epoch[480/600] Iteration[007/030] Train loss: 0.0200
2023-02-06 11:41:39 | Train | Epoch[480/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[017/030] Train loss: 0.0206
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[025/030] Train loss: 0.0205
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:41:40 | Train | Epoch[480/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:41:41 | Valid | Epoch[480/600] Iteration[001/008] Valid loss: 0.0512
2023-02-06 11:41:41 | Valid | Epoch[480/600] Iteration[002/008] Valid loss: 0.0382
2023-02-06 11:41:41 | Valid | Epoch[480/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:41:41 | Valid | Epoch[480/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:41:41 | Valid | Epoch[480/600] Iteration[005/008] Valid loss: 0.0341
2023-02-06 11:41:41 | Valid | Epoch[480/600] Iteration[006/008] Valid loss: 0.0339
2023-02-06 11:41:41 | Valid | Epoch[480/600] Iteration[007/008] Valid loss: 0.0340
2023-02-06 11:41:41 | Valid | Epoch[480/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:41:41 | Valid | Epoch[480/600] MIou: 0.9258350605186485
2023-02-06 11:41:41 | Valid | Epoch[480/600] Pixel Accuracy: 0.9876174926757812
2023-02-06 11:41:41 | Valid | Epoch[480/600] Mean Pixel Accuracy: 0.9388625454864329
2023-02-06 11:41:41 | Stage | Epoch[480/600] Train loss:0.0202
2023-02-06 11:41:41 | Stage | Epoch[480/600] Valid loss:0.0331
2023-02-06 11:41:41 | Stage | Epoch[480/600] LR:0.001

2023-02-06 11:41:41 | Train | Epoch[481/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 11:41:41 | Train | Epoch[481/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 11:41:41 | Train | Epoch[481/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[004/030] Train loss: 0.0185
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[006/030] Train loss: 0.0187
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[007/030] Train loss: 0.0190
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:41:42 | Train | Epoch[481/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:41:43 | Train | Epoch[481/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:41:43 | Train | Epoch[481/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:41:43 | Train | Epoch[481/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:41:43 | Train | Epoch[481/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:41:43 | Train | Epoch[481/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:41:43 | Train | Epoch[481/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:41:43 | Valid | Epoch[481/600] Iteration[001/008] Valid loss: 0.0862
2023-02-06 11:41:43 | Valid | Epoch[481/600] Iteration[002/008] Valid loss: 0.0582
2023-02-06 11:41:43 | Valid | Epoch[481/600] Iteration[003/008] Valid loss: 0.0499
2023-02-06 11:41:43 | Valid | Epoch[481/600] Iteration[004/008] Valid loss: 0.0502
2023-02-06 11:41:43 | Valid | Epoch[481/600] Iteration[005/008] Valid loss: 0.0530
2023-02-06 11:41:43 | Valid | Epoch[481/600] Iteration[006/008] Valid loss: 0.0524
2023-02-06 11:41:43 | Valid | Epoch[481/600] Iteration[007/008] Valid loss: 0.0550
2023-02-06 11:41:43 | Valid | Epoch[481/600] Iteration[008/008] Valid loss: 0.0525
2023-02-06 11:41:43 | Valid | Epoch[481/600] MIou: 0.9417290095946197
2023-02-06 11:41:43 | Valid | Epoch[481/600] Pixel Accuracy: 0.9900436401367188
2023-02-06 11:41:43 | Valid | Epoch[481/600] Mean Pixel Accuracy: 0.9643469155931628
2023-02-06 11:41:43 | Stage | Epoch[481/600] Train loss:0.0202
2023-02-06 11:41:43 | Stage | Epoch[481/600] Valid loss:0.0525
2023-02-06 11:41:43 | Stage | Epoch[481/600] LR:0.001

2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[001/030] Train loss: 0.0249
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[002/030] Train loss: 0.0237
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[003/030] Train loss: 0.0235
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[004/030] Train loss: 0.0226
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[006/030] Train loss: 0.0217
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[008/030] Train loss: 0.0213
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[009/030] Train loss: 0.0211
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[013/030] Train loss: 0.0207
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:41:44 | Train | Epoch[482/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:41:45 | Train | Epoch[482/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:41:45 | Valid | Epoch[482/600] Iteration[001/008] Valid loss: 0.0404
2023-02-06 11:41:45 | Valid | Epoch[482/600] Iteration[002/008] Valid loss: 0.0362
2023-02-06 11:41:45 | Valid | Epoch[482/600] Iteration[003/008] Valid loss: 0.0353
2023-02-06 11:41:45 | Valid | Epoch[482/600] Iteration[004/008] Valid loss: 0.0338
2023-02-06 11:41:45 | Valid | Epoch[482/600] Iteration[005/008] Valid loss: 0.0344
2023-02-06 11:41:45 | Valid | Epoch[482/600] Iteration[006/008] Valid loss: 0.0341
2023-02-06 11:41:45 | Valid | Epoch[482/600] Iteration[007/008] Valid loss: 0.0333
2023-02-06 11:41:45 | Valid | Epoch[482/600] Iteration[008/008] Valid loss: 0.0335
2023-02-06 11:41:46 | Valid | Epoch[482/600] MIou: 0.8930560297787588
2023-02-06 11:41:46 | Valid | Epoch[482/600] Pixel Accuracy: 0.9823379516601562
2023-02-06 11:41:46 | Valid | Epoch[482/600] Mean Pixel Accuracy: 0.9038842391976553
2023-02-06 11:41:46 | Stage | Epoch[482/600] Train loss:0.0202
2023-02-06 11:41:46 | Stage | Epoch[482/600] Valid loss:0.0335
2023-02-06 11:41:46 | Stage | Epoch[482/600] LR:0.001

2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:41:46 | Train | Epoch[483/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[028/030] Train loss: 0.0204
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:41:47 | Train | Epoch[483/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:41:48 | Valid | Epoch[483/600] Iteration[001/008] Valid loss: 0.0486
2023-02-06 11:41:48 | Valid | Epoch[483/600] Iteration[002/008] Valid loss: 0.0370
2023-02-06 11:41:48 | Valid | Epoch[483/600] Iteration[003/008] Valid loss: 0.0338
2023-02-06 11:41:48 | Valid | Epoch[483/600] Iteration[004/008] Valid loss: 0.0322
2023-02-06 11:41:48 | Valid | Epoch[483/600] Iteration[005/008] Valid loss: 0.0330
2023-02-06 11:41:48 | Valid | Epoch[483/600] Iteration[006/008] Valid loss: 0.0331
2023-02-06 11:41:48 | Valid | Epoch[483/600] Iteration[007/008] Valid loss: 0.0331
2023-02-06 11:41:48 | Valid | Epoch[483/600] Iteration[008/008] Valid loss: 0.0324
2023-02-06 11:41:48 | Valid | Epoch[483/600] MIou: 0.9236975652534372
2023-02-06 11:41:48 | Valid | Epoch[483/600] Pixel Accuracy: 0.987274169921875
2023-02-06 11:41:48 | Valid | Epoch[483/600] Mean Pixel Accuracy: 0.9364039518572002
2023-02-06 11:41:48 | Stage | Epoch[483/600] Train loss:0.0203
2023-02-06 11:41:48 | Stage | Epoch[483/600] Valid loss:0.0324
2023-02-06 11:41:48 | Stage | Epoch[483/600] LR:0.001

2023-02-06 11:41:48 | Train | Epoch[484/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 11:41:48 | Train | Epoch[484/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:41:48 | Train | Epoch[484/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 11:41:48 | Train | Epoch[484/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:41:48 | Train | Epoch[484/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:41:48 | Train | Epoch[484/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:41:48 | Train | Epoch[484/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:41:48 | Train | Epoch[484/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:41:48 | Train | Epoch[484/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:41:48 | Train | Epoch[484/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:41:49 | Train | Epoch[484/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:41:50 | Valid | Epoch[484/600] Iteration[001/008] Valid loss: 0.0427
2023-02-06 11:41:50 | Valid | Epoch[484/600] Iteration[002/008] Valid loss: 0.0353
2023-02-06 11:41:50 | Valid | Epoch[484/600] Iteration[003/008] Valid loss: 0.0333
2023-02-06 11:41:50 | Valid | Epoch[484/600] Iteration[004/008] Valid loss: 0.0319
2023-02-06 11:41:50 | Valid | Epoch[484/600] Iteration[005/008] Valid loss: 0.0326
2023-02-06 11:41:50 | Valid | Epoch[484/600] Iteration[006/008] Valid loss: 0.0326
2023-02-06 11:41:50 | Valid | Epoch[484/600] Iteration[007/008] Valid loss: 0.0321
2023-02-06 11:41:50 | Valid | Epoch[484/600] Iteration[008/008] Valid loss: 0.0319
2023-02-06 11:41:50 | Valid | Epoch[484/600] MIou: 0.9107283955486913
2023-02-06 11:41:50 | Valid | Epoch[484/600] Pixel Accuracy: 0.985192616780599
2023-02-06 11:41:50 | Valid | Epoch[484/600] Mean Pixel Accuracy: 0.9220019155429016
2023-02-06 11:41:50 | Stage | Epoch[484/600] Train loss:0.0201
2023-02-06 11:41:50 | Stage | Epoch[484/600] Valid loss:0.0319
2023-02-06 11:41:50 | Stage | Epoch[484/600] LR:0.001

2023-02-06 11:41:50 | Train | Epoch[485/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 11:41:50 | Train | Epoch[485/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 11:41:50 | Train | Epoch[485/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:41:50 | Train | Epoch[485/600] Iteration[004/030] Train loss: 0.0190
2023-02-06 11:41:50 | Train | Epoch[485/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[011/030] Train loss: 0.0204
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:41:51 | Train | Epoch[485/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:41:52 | Train | Epoch[485/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:41:52 | Train | Epoch[485/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:41:52 | Train | Epoch[485/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:41:52 | Train | Epoch[485/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:41:52 | Valid | Epoch[485/600] Iteration[001/008] Valid loss: 0.0806
2023-02-06 11:41:52 | Valid | Epoch[485/600] Iteration[002/008] Valid loss: 0.0544
2023-02-06 11:41:52 | Valid | Epoch[485/600] Iteration[003/008] Valid loss: 0.0467
2023-02-06 11:41:52 | Valid | Epoch[485/600] Iteration[004/008] Valid loss: 0.0464
2023-02-06 11:41:52 | Valid | Epoch[485/600] Iteration[005/008] Valid loss: 0.0491
2023-02-06 11:41:52 | Valid | Epoch[485/600] Iteration[006/008] Valid loss: 0.0486
2023-02-06 11:41:52 | Valid | Epoch[485/600] Iteration[007/008] Valid loss: 0.0509
2023-02-06 11:41:52 | Valid | Epoch[485/600] Iteration[008/008] Valid loss: 0.0486
2023-02-06 11:41:52 | Valid | Epoch[485/600] MIou: 0.9406410913414438
2023-02-06 11:41:52 | Valid | Epoch[485/600] Pixel Accuracy: 0.9898935953776041
2023-02-06 11:41:52 | Valid | Epoch[485/600] Mean Pixel Accuracy: 0.9616585108028344
2023-02-06 11:41:52 | Stage | Epoch[485/600] Train loss:0.0201
2023-02-06 11:41:52 | Stage | Epoch[485/600] Valid loss:0.0486
2023-02-06 11:41:52 | Stage | Epoch[485/600] LR:0.001

2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[004/030] Train loss: 0.0189
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[007/030] Train loss: 0.0200
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:41:53 | Train | Epoch[486/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:41:54 | Train | Epoch[486/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:41:54 | Train | Epoch[486/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:41:54 | Train | Epoch[486/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:41:54 | Train | Epoch[486/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:41:54 | Train | Epoch[486/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:41:54 | Train | Epoch[486/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:41:54 | Train | Epoch[486/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:41:54 | Train | Epoch[486/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:41:54 | Train | Epoch[486/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:41:54 | Valid | Epoch[486/600] Iteration[001/008] Valid loss: 0.0463
2023-02-06 11:41:54 | Valid | Epoch[486/600] Iteration[002/008] Valid loss: 0.0363
2023-02-06 11:41:54 | Valid | Epoch[486/600] Iteration[003/008] Valid loss: 0.0335
2023-02-06 11:41:54 | Valid | Epoch[486/600] Iteration[004/008] Valid loss: 0.0318
2023-02-06 11:41:54 | Valid | Epoch[486/600] Iteration[005/008] Valid loss: 0.0327
2023-02-06 11:41:54 | Valid | Epoch[486/600] Iteration[006/008] Valid loss: 0.0326
2023-02-06 11:41:54 | Valid | Epoch[486/600] Iteration[007/008] Valid loss: 0.0324
2023-02-06 11:41:54 | Valid | Epoch[486/600] Iteration[008/008] Valid loss: 0.0318
2023-02-06 11:41:55 | Valid | Epoch[486/600] MIou: 0.9195806686048089
2023-02-06 11:41:55 | Valid | Epoch[486/600] Pixel Accuracy: 0.9866154988606771
2023-02-06 11:41:55 | Valid | Epoch[486/600] Mean Pixel Accuracy: 0.9316669928069894
2023-02-06 11:41:55 | Stage | Epoch[486/600] Train loss:0.0199
2023-02-06 11:41:55 | Stage | Epoch[486/600] Valid loss:0.0318
2023-02-06 11:41:55 | Stage | Epoch[486/600] LR:0.001

2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:41:55 | Train | Epoch[487/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:41:56 | Train | Epoch[487/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:41:57 | Valid | Epoch[487/600] Iteration[001/008] Valid loss: 0.1279
2023-02-06 11:41:57 | Valid | Epoch[487/600] Iteration[002/008] Valid loss: 0.0848
2023-02-06 11:41:57 | Valid | Epoch[487/600] Iteration[003/008] Valid loss: 0.0733
2023-02-06 11:41:57 | Valid | Epoch[487/600] Iteration[004/008] Valid loss: 0.0741
2023-02-06 11:41:57 | Valid | Epoch[487/600] Iteration[005/008] Valid loss: 0.0787
2023-02-06 11:41:57 | Valid | Epoch[487/600] Iteration[006/008] Valid loss: 0.0778
2023-02-06 11:41:57 | Valid | Epoch[487/600] Iteration[007/008] Valid loss: 0.0836
2023-02-06 11:41:57 | Valid | Epoch[487/600] Iteration[008/008] Valid loss: 0.0799
2023-02-06 11:41:57 | Valid | Epoch[487/600] MIou: 0.941094611467492
2023-02-06 11:41:57 | Valid | Epoch[487/600] Pixel Accuracy: 0.9897232055664062
2023-02-06 11:41:57 | Valid | Epoch[487/600] Mean Pixel Accuracy: 0.973618093640114
2023-02-06 11:41:57 | Stage | Epoch[487/600] Train loss:0.0200
2023-02-06 11:41:57 | Stage | Epoch[487/600] Valid loss:0.0799
2023-02-06 11:41:57 | Stage | Epoch[487/600] LR:0.001

2023-02-06 11:41:57 | Train | Epoch[488/600] Iteration[001/030] Train loss: 0.0208
2023-02-06 11:41:57 | Train | Epoch[488/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:41:57 | Train | Epoch[488/600] Iteration[003/030] Train loss: 0.0205
2023-02-06 11:41:57 | Train | Epoch[488/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:41:57 | Train | Epoch[488/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 11:41:57 | Train | Epoch[488/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 11:41:57 | Train | Epoch[488/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[009/030] Train loss: 0.0196
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[010/030] Train loss: 0.0199
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[020/030] Train loss: 0.0196
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:41:58 | Train | Epoch[488/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:41:59 | Train | Epoch[488/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:41:59 | Train | Epoch[488/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:41:59 | Valid | Epoch[488/600] Iteration[001/008] Valid loss: 0.0695
2023-02-06 11:41:59 | Valid | Epoch[488/600] Iteration[002/008] Valid loss: 0.0479
2023-02-06 11:41:59 | Valid | Epoch[488/600] Iteration[003/008] Valid loss: 0.0416
2023-02-06 11:41:59 | Valid | Epoch[488/600] Iteration[004/008] Valid loss: 0.0408
2023-02-06 11:41:59 | Valid | Epoch[488/600] Iteration[005/008] Valid loss: 0.0427
2023-02-06 11:41:59 | Valid | Epoch[488/600] Iteration[006/008] Valid loss: 0.0425
2023-02-06 11:41:59 | Valid | Epoch[488/600] Iteration[007/008] Valid loss: 0.0440
2023-02-06 11:41:59 | Valid | Epoch[488/600] Iteration[008/008] Valid loss: 0.0421
2023-02-06 11:41:59 | Valid | Epoch[488/600] MIou: 0.9376118490859915
2023-02-06 11:41:59 | Valid | Epoch[488/600] Pixel Accuracy: 0.9894523620605469
2023-02-06 11:41:59 | Valid | Epoch[488/600] Mean Pixel Accuracy: 0.9555383730619359
2023-02-06 11:41:59 | Stage | Epoch[488/600] Train loss:0.0201
2023-02-06 11:41:59 | Stage | Epoch[488/600] Valid loss:0.0421
2023-02-06 11:41:59 | Stage | Epoch[488/600] LR:0.001

2023-02-06 11:41:59 | Train | Epoch[489/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[002/030] Train loss: 0.0191
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[004/030] Train loss: 0.0202
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:42:00 | Train | Epoch[489/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:42:01 | Train | Epoch[489/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:42:01 | Train | Epoch[489/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:42:01 | Train | Epoch[489/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:42:01 | Train | Epoch[489/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:42:01 | Train | Epoch[489/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:42:01 | Train | Epoch[489/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:42:01 | Train | Epoch[489/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:42:01 | Train | Epoch[489/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:42:01 | Valid | Epoch[489/600] Iteration[001/008] Valid loss: 0.0482
2023-02-06 11:42:01 | Valid | Epoch[489/600] Iteration[002/008] Valid loss: 0.0370
2023-02-06 11:42:01 | Valid | Epoch[489/600] Iteration[003/008] Valid loss: 0.0338
2023-02-06 11:42:01 | Valid | Epoch[489/600] Iteration[004/008] Valid loss: 0.0322
2023-02-06 11:42:01 | Valid | Epoch[489/600] Iteration[005/008] Valid loss: 0.0331
2023-02-06 11:42:01 | Valid | Epoch[489/600] Iteration[006/008] Valid loss: 0.0331
2023-02-06 11:42:01 | Valid | Epoch[489/600] Iteration[007/008] Valid loss: 0.0331
2023-02-06 11:42:01 | Valid | Epoch[489/600] Iteration[008/008] Valid loss: 0.0324
2023-02-06 11:42:01 | Valid | Epoch[489/600] MIou: 0.9235451075702361
2023-02-06 11:42:01 | Valid | Epoch[489/600] Pixel Accuracy: 0.9872576395670573
2023-02-06 11:42:01 | Valid | Epoch[489/600] Mean Pixel Accuracy: 0.9359573735348562
2023-02-06 11:42:01 | Stage | Epoch[489/600] Train loss:0.0200
2023-02-06 11:42:01 | Stage | Epoch[489/600] Valid loss:0.0324
2023-02-06 11:42:01 | Stage | Epoch[489/600] LR:0.001

2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[002/030] Train loss: 0.0202
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[004/030] Train loss: 0.0202
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:42:02 | Train | Epoch[490/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:42:03 | Train | Epoch[490/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:42:04 | Valid | Epoch[490/600] Iteration[001/008] Valid loss: 0.0437
2023-02-06 11:42:04 | Valid | Epoch[490/600] Iteration[002/008] Valid loss: 0.0357
2023-02-06 11:42:04 | Valid | Epoch[490/600] Iteration[003/008] Valid loss: 0.0335
2023-02-06 11:42:04 | Valid | Epoch[490/600] Iteration[004/008] Valid loss: 0.0319
2023-02-06 11:42:04 | Valid | Epoch[490/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 11:42:04 | Valid | Epoch[490/600] Iteration[006/008] Valid loss: 0.0322
2023-02-06 11:42:04 | Valid | Epoch[490/600] Iteration[007/008] Valid loss: 0.0317
2023-02-06 11:42:04 | Valid | Epoch[490/600] Iteration[008/008] Valid loss: 0.0315
2023-02-06 11:42:04 | Valid | Epoch[490/600] MIou: 0.9126171294586105
2023-02-06 11:42:04 | Valid | Epoch[490/600] Pixel Accuracy: 0.985504150390625
2023-02-06 11:42:04 | Valid | Epoch[490/600] Mean Pixel Accuracy: 0.9238026488801636
2023-02-06 11:42:04 | Stage | Epoch[490/600] Train loss:0.0201
2023-02-06 11:42:04 | Stage | Epoch[490/600] Valid loss:0.0315
2023-02-06 11:42:04 | Stage | Epoch[490/600] LR:0.001

2023-02-06 11:42:04 | Train | Epoch[491/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 11:42:04 | Train | Epoch[491/600] Iteration[002/030] Train loss: 0.0180
2023-02-06 11:42:04 | Train | Epoch[491/600] Iteration[003/030] Train loss: 0.0178
2023-02-06 11:42:04 | Train | Epoch[491/600] Iteration[004/030] Train loss: 0.0177
2023-02-06 11:42:04 | Train | Epoch[491/600] Iteration[005/030] Train loss: 0.0188
2023-02-06 11:42:04 | Train | Epoch[491/600] Iteration[006/030] Train loss: 0.0186
2023-02-06 11:42:04 | Train | Epoch[491/600] Iteration[007/030] Train loss: 0.0187
2023-02-06 11:42:04 | Train | Epoch[491/600] Iteration[008/030] Train loss: 0.0187
2023-02-06 11:42:04 | Train | Epoch[491/600] Iteration[009/030] Train loss: 0.0188
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[011/030] Train loss: 0.0192
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:42:05 | Train | Epoch[491/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:42:06 | Valid | Epoch[491/600] Iteration[001/008] Valid loss: 0.0464
2023-02-06 11:42:06 | Valid | Epoch[491/600] Iteration[002/008] Valid loss: 0.0361
2023-02-06 11:42:06 | Valid | Epoch[491/600] Iteration[003/008] Valid loss: 0.0333
2023-02-06 11:42:06 | Valid | Epoch[491/600] Iteration[004/008] Valid loss: 0.0317
2023-02-06 11:42:06 | Valid | Epoch[491/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 11:42:06 | Valid | Epoch[491/600] Iteration[006/008] Valid loss: 0.0327
2023-02-06 11:42:06 | Valid | Epoch[491/600] Iteration[007/008] Valid loss: 0.0325
2023-02-06 11:42:06 | Valid | Epoch[491/600] Iteration[008/008] Valid loss: 0.0319
2023-02-06 11:42:06 | Valid | Epoch[491/600] MIou: 0.9206528277669084
2023-02-06 11:42:06 | Valid | Epoch[491/600] Pixel Accuracy: 0.9867897033691406
2023-02-06 11:42:06 | Valid | Epoch[491/600] Mean Pixel Accuracy: 0.9328025803624647
2023-02-06 11:42:06 | Stage | Epoch[491/600] Train loss:0.0198
2023-02-06 11:42:06 | Stage | Epoch[491/600] Valid loss:0.0319
2023-02-06 11:42:06 | Stage | Epoch[491/600] LR:0.001

2023-02-06 11:42:06 | Train | Epoch[492/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 11:42:06 | Train | Epoch[492/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:42:06 | Train | Epoch[492/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[005/030] Train loss: 0.0193
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[010/030] Train loss: 0.0193
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[012/030] Train loss: 0.0194
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:42:07 | Train | Epoch[492/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:42:08 | Train | Epoch[492/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:42:08 | Train | Epoch[492/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:42:08 | Train | Epoch[492/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:42:08 | Train | Epoch[492/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:42:08 | Train | Epoch[492/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:42:08 | Train | Epoch[492/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:42:08 | Valid | Epoch[492/600] Iteration[001/008] Valid loss: 0.0453
2023-02-06 11:42:08 | Valid | Epoch[492/600] Iteration[002/008] Valid loss: 0.0433
2023-02-06 11:42:08 | Valid | Epoch[492/600] Iteration[003/008] Valid loss: 0.0431
2023-02-06 11:42:08 | Valid | Epoch[492/600] Iteration[004/008] Valid loss: 0.0414
2023-02-06 11:42:08 | Valid | Epoch[492/600] Iteration[005/008] Valid loss: 0.0419
2023-02-06 11:42:08 | Valid | Epoch[492/600] Iteration[006/008] Valid loss: 0.0413
2023-02-06 11:42:08 | Valid | Epoch[492/600] Iteration[007/008] Valid loss: 0.0399
2023-02-06 11:42:08 | Valid | Epoch[492/600] Iteration[008/008] Valid loss: 0.0408
2023-02-06 11:42:08 | Valid | Epoch[492/600] MIou: 0.8596108710781492
2023-02-06 11:42:08 | Valid | Epoch[492/600] Pixel Accuracy: 0.9768575032552084
2023-02-06 11:42:08 | Valid | Epoch[492/600] Mean Pixel Accuracy: 0.8723525101574896
2023-02-06 11:42:08 | Stage | Epoch[492/600] Train loss:0.0201
2023-02-06 11:42:08 | Stage | Epoch[492/600] Valid loss:0.0408
2023-02-06 11:42:08 | Stage | Epoch[492/600] LR:0.001

2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[002/030] Train loss: 0.0184
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[004/030] Train loss: 0.0217
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:42:09 | Train | Epoch[493/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[026/030] Train loss: 0.0205
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[027/030] Train loss: 0.0205
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[028/030] Train loss: 0.0205
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[029/030] Train loss: 0.0205
2023-02-06 11:42:10 | Train | Epoch[493/600] Iteration[030/030] Train loss: 0.0205
2023-02-06 11:42:10 | Valid | Epoch[493/600] Iteration[001/008] Valid loss: 0.0494
2023-02-06 11:42:10 | Valid | Epoch[493/600] Iteration[002/008] Valid loss: 0.0375
2023-02-06 11:42:10 | Valid | Epoch[493/600] Iteration[003/008] Valid loss: 0.0341
2023-02-06 11:42:10 | Valid | Epoch[493/600] Iteration[004/008] Valid loss: 0.0326
2023-02-06 11:42:11 | Valid | Epoch[493/600] Iteration[005/008] Valid loss: 0.0335
2023-02-06 11:42:11 | Valid | Epoch[493/600] Iteration[006/008] Valid loss: 0.0333
2023-02-06 11:42:11 | Valid | Epoch[493/600] Iteration[007/008] Valid loss: 0.0334
2023-02-06 11:42:11 | Valid | Epoch[493/600] Iteration[008/008] Valid loss: 0.0327
2023-02-06 11:42:11 | Valid | Epoch[493/600] MIou: 0.9242144165028714
2023-02-06 11:42:11 | Valid | Epoch[493/600] Pixel Accuracy: 0.9873606363932291
2023-02-06 11:42:11 | Valid | Epoch[493/600] Mean Pixel Accuracy: 0.9368762891088716
2023-02-06 11:42:11 | Stage | Epoch[493/600] Train loss:0.0205
2023-02-06 11:42:11 | Stage | Epoch[493/600] Valid loss:0.0327
2023-02-06 11:42:11 | Stage | Epoch[493/600] LR:0.001

2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[002/030] Train loss: 0.0231
2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[003/030] Train loss: 0.0228
2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[004/030] Train loss: 0.0227
2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[005/030] Train loss: 0.0218
2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:42:11 | Train | Epoch[494/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:42:12 | Train | Epoch[494/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:42:13 | Valid | Epoch[494/600] Iteration[001/008] Valid loss: 0.0508
2023-02-06 11:42:13 | Valid | Epoch[494/600] Iteration[002/008] Valid loss: 0.0382
2023-02-06 11:42:13 | Valid | Epoch[494/600] Iteration[003/008] Valid loss: 0.0346
2023-02-06 11:42:13 | Valid | Epoch[494/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:42:13 | Valid | Epoch[494/600] Iteration[005/008] Valid loss: 0.0339
2023-02-06 11:42:13 | Valid | Epoch[494/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 11:42:13 | Valid | Epoch[494/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 11:42:13 | Valid | Epoch[494/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:42:13 | Valid | Epoch[494/600] MIou: 0.9244276324662591
2023-02-06 11:42:13 | Valid | Epoch[494/600] Pixel Accuracy: 0.987396240234375
2023-02-06 11:42:13 | Valid | Epoch[494/600] Mean Pixel Accuracy: 0.9370733917007706
2023-02-06 11:42:13 | Stage | Epoch[494/600] Train loss:0.0201
2023-02-06 11:42:13 | Stage | Epoch[494/600] Valid loss:0.0331
2023-02-06 11:42:13 | Stage | Epoch[494/600] LR:0.001

2023-02-06 11:42:13 | Train | Epoch[495/600] Iteration[001/030] Train loss: 0.0171
2023-02-06 11:42:13 | Train | Epoch[495/600] Iteration[002/030] Train loss: 0.0174
2023-02-06 11:42:13 | Train | Epoch[495/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 11:42:13 | Train | Epoch[495/600] Iteration[004/030] Train loss: 0.0190
2023-02-06 11:42:13 | Train | Epoch[495/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 11:42:13 | Train | Epoch[495/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[007/030] Train loss: 0.0182
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[008/030] Train loss: 0.0186
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[009/030] Train loss: 0.0186
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[010/030] Train loss: 0.0184
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[011/030] Train loss: 0.0187
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[012/030] Train loss: 0.0187
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[013/030] Train loss: 0.0190
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:42:14 | Train | Epoch[495/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:42:15 | Train | Epoch[495/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:42:15 | Train | Epoch[495/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:42:15 | Train | Epoch[495/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:42:15 | Train | Epoch[495/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:42:15 | Valid | Epoch[495/600] Iteration[001/008] Valid loss: 0.0474
2023-02-06 11:42:15 | Valid | Epoch[495/600] Iteration[002/008] Valid loss: 0.0367
2023-02-06 11:42:15 | Valid | Epoch[495/600] Iteration[003/008] Valid loss: 0.0337
2023-02-06 11:42:15 | Valid | Epoch[495/600] Iteration[004/008] Valid loss: 0.0320
2023-02-06 11:42:15 | Valid | Epoch[495/600] Iteration[005/008] Valid loss: 0.0327
2023-02-06 11:42:15 | Valid | Epoch[495/600] Iteration[006/008] Valid loss: 0.0326
2023-02-06 11:42:15 | Valid | Epoch[495/600] Iteration[007/008] Valid loss: 0.0325
2023-02-06 11:42:15 | Valid | Epoch[495/600] Iteration[008/008] Valid loss: 0.0320
2023-02-06 11:42:15 | Valid | Epoch[495/600] MIou: 0.920531778995463
2023-02-06 11:42:15 | Valid | Epoch[495/600] Pixel Accuracy: 0.9867693583170573
2023-02-06 11:42:15 | Valid | Epoch[495/600] Mean Pixel Accuracy: 0.9326962907814629
2023-02-06 11:42:15 | Stage | Epoch[495/600] Train loss:0.0202
2023-02-06 11:42:15 | Stage | Epoch[495/600] Valid loss:0.0320
2023-02-06 11:42:15 | Stage | Epoch[495/600] LR:0.001

2023-02-06 11:42:15 | Train | Epoch[496/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[003/030] Train loss: 0.0200
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[004/030] Train loss: 0.0211
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[005/030] Train loss: 0.0213
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[006/030] Train loss: 0.0215
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[007/030] Train loss: 0.0213
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[009/030] Train loss: 0.0209
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:42:16 | Train | Epoch[496/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:42:17 | Train | Epoch[496/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:42:17 | Train | Epoch[496/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:42:17 | Train | Epoch[496/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:42:17 | Train | Epoch[496/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:42:17 | Train | Epoch[496/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:42:17 | Train | Epoch[496/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:42:17 | Train | Epoch[496/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:42:17 | Train | Epoch[496/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:42:17 | Train | Epoch[496/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:42:17 | Valid | Epoch[496/600] Iteration[001/008] Valid loss: 0.0432
2023-02-06 11:42:17 | Valid | Epoch[496/600] Iteration[002/008] Valid loss: 0.0355
2023-02-06 11:42:17 | Valid | Epoch[496/600] Iteration[003/008] Valid loss: 0.0334
2023-02-06 11:42:17 | Valid | Epoch[496/600] Iteration[004/008] Valid loss: 0.0319
2023-02-06 11:42:17 | Valid | Epoch[496/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 11:42:17 | Valid | Epoch[496/600] Iteration[006/008] Valid loss: 0.0323
2023-02-06 11:42:17 | Valid | Epoch[496/600] Iteration[007/008] Valid loss: 0.0319
2023-02-06 11:42:17 | Valid | Epoch[496/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 11:42:17 | Valid | Epoch[496/600] MIou: 0.9112900989813525
2023-02-06 11:42:17 | Valid | Epoch[496/600] Pixel Accuracy: 0.9852892557779948
2023-02-06 11:42:17 | Valid | Epoch[496/600] Mean Pixel Accuracy: 0.9224227798051245
2023-02-06 11:42:17 | Stage | Epoch[496/600] Train loss:0.0202
2023-02-06 11:42:17 | Stage | Epoch[496/600] Valid loss:0.0316
2023-02-06 11:42:17 | Stage | Epoch[496/600] LR:0.001

2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[001/030] Train loss: 0.0155
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[005/030] Train loss: 0.0211
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[012/030] Train loss: 0.0206
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:42:18 | Train | Epoch[497/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[024/030] Train loss: 0.0205
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[027/030] Train loss: 0.0204
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[028/030] Train loss: 0.0204
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[029/030] Train loss: 0.0204
2023-02-06 11:42:19 | Train | Epoch[497/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:42:19 | Valid | Epoch[497/600] Iteration[001/008] Valid loss: 0.0409
2023-02-06 11:42:20 | Valid | Epoch[497/600] Iteration[002/008] Valid loss: 0.0353
2023-02-06 11:42:20 | Valid | Epoch[497/600] Iteration[003/008] Valid loss: 0.0339
2023-02-06 11:42:20 | Valid | Epoch[497/600] Iteration[004/008] Valid loss: 0.0324
2023-02-06 11:42:20 | Valid | Epoch[497/600] Iteration[005/008] Valid loss: 0.0331
2023-02-06 11:42:20 | Valid | Epoch[497/600] Iteration[006/008] Valid loss: 0.0328
2023-02-06 11:42:20 | Valid | Epoch[497/600] Iteration[007/008] Valid loss: 0.0322
2023-02-06 11:42:20 | Valid | Epoch[497/600] Iteration[008/008] Valid loss: 0.0322
2023-02-06 11:42:20 | Valid | Epoch[497/600] MIou: 0.9017019864601927
2023-02-06 11:42:20 | Valid | Epoch[497/600] Pixel Accuracy: 0.9837417602539062
2023-02-06 11:42:20 | Valid | Epoch[497/600] Mean Pixel Accuracy: 0.9124672931746511
2023-02-06 11:42:20 | Stage | Epoch[497/600] Train loss:0.0203
2023-02-06 11:42:20 | Stage | Epoch[497/600] Valid loss:0.0322
2023-02-06 11:42:20 | Stage | Epoch[497/600] LR:0.001

2023-02-06 11:42:20 | Train | Epoch[498/600] Iteration[001/030] Train loss: 0.0208
2023-02-06 11:42:20 | Train | Epoch[498/600] Iteration[002/030] Train loss: 0.0206
2023-02-06 11:42:20 | Train | Epoch[498/600] Iteration[003/030] Train loss: 0.0212
2023-02-06 11:42:20 | Train | Epoch[498/600] Iteration[004/030] Train loss: 0.0198
2023-02-06 11:42:20 | Train | Epoch[498/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:42:20 | Train | Epoch[498/600] Iteration[006/030] Train loss: 0.0199
2023-02-06 11:42:20 | Train | Epoch[498/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:42:20 | Train | Epoch[498/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 11:42:20 | Train | Epoch[498/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[014/030] Train loss: 0.0195
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[017/030] Train loss: 0.0194
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[018/030] Train loss: 0.0194
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[019/030] Train loss: 0.0194
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:42:21 | Train | Epoch[498/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:42:22 | Valid | Epoch[498/600] Iteration[001/008] Valid loss: 0.0495
2023-02-06 11:42:22 | Valid | Epoch[498/600] Iteration[002/008] Valid loss: 0.0377
2023-02-06 11:42:22 | Valid | Epoch[498/600] Iteration[003/008] Valid loss: 0.0342
2023-02-06 11:42:22 | Valid | Epoch[498/600] Iteration[004/008] Valid loss: 0.0326
2023-02-06 11:42:22 | Valid | Epoch[498/600] Iteration[005/008] Valid loss: 0.0333
2023-02-06 11:42:22 | Valid | Epoch[498/600] Iteration[006/008] Valid loss: 0.0332
2023-02-06 11:42:22 | Valid | Epoch[498/600] Iteration[007/008] Valid loss: 0.0333
2023-02-06 11:42:22 | Valid | Epoch[498/600] Iteration[008/008] Valid loss: 0.0326
2023-02-06 11:42:22 | Valid | Epoch[498/600] MIou: 0.923169751137948
2023-02-06 11:42:22 | Valid | Epoch[498/600] Pixel Accuracy: 0.9871966044108073
2023-02-06 11:42:22 | Valid | Epoch[498/600] Mean Pixel Accuracy: 0.9355560786621941
2023-02-06 11:42:22 | Stage | Epoch[498/600] Train loss:0.0200
2023-02-06 11:42:22 | Stage | Epoch[498/600] Valid loss:0.0326
2023-02-06 11:42:22 | Stage | Epoch[498/600] LR:0.001

2023-02-06 11:42:22 | Train | Epoch[499/600] Iteration[001/030] Train loss: 0.0181
2023-02-06 11:42:22 | Train | Epoch[499/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:42:23 | Train | Epoch[499/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:42:24 | Train | Epoch[499/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:42:24 | Train | Epoch[499/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:42:24 | Train | Epoch[499/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:42:24 | Train | Epoch[499/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:42:24 | Train | Epoch[499/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:42:24 | Train | Epoch[499/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:42:24 | Train | Epoch[499/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:42:24 | Valid | Epoch[499/600] Iteration[001/008] Valid loss: 0.0498
2023-02-06 11:42:24 | Valid | Epoch[499/600] Iteration[002/008] Valid loss: 0.0376
2023-02-06 11:42:24 | Valid | Epoch[499/600] Iteration[003/008] Valid loss: 0.0341
2023-02-06 11:42:24 | Valid | Epoch[499/600] Iteration[004/008] Valid loss: 0.0325
2023-02-06 11:42:24 | Valid | Epoch[499/600] Iteration[005/008] Valid loss: 0.0335
2023-02-06 11:42:24 | Valid | Epoch[499/600] Iteration[006/008] Valid loss: 0.0337
2023-02-06 11:42:24 | Valid | Epoch[499/600] Iteration[007/008] Valid loss: 0.0338
2023-02-06 11:42:24 | Valid | Epoch[499/600] Iteration[008/008] Valid loss: 0.0330
2023-02-06 11:42:24 | Valid | Epoch[499/600] MIou: 0.9254517669069117
2023-02-06 11:42:24 | Valid | Epoch[499/600] Pixel Accuracy: 0.9875526428222656
2023-02-06 11:42:24 | Valid | Epoch[499/600] Mean Pixel Accuracy: 0.9385352395516058
2023-02-06 11:42:24 | Stage | Epoch[499/600] Train loss:0.0201
2023-02-06 11:42:24 | Stage | Epoch[499/600] Valid loss:0.0330
2023-02-06 11:42:24 | Stage | Epoch[499/600] LR:0.001

2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[001/030] Train loss: 0.0208
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[004/030] Train loss: 0.0212
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[015/030] Train loss: 0.0206
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:42:25 | Train | Epoch[500/600] Iteration[017/030] Train loss: 0.0206
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[018/030] Train loss: 0.0207
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:42:26 | Train | Epoch[500/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:42:26 | Valid | Epoch[500/600] Iteration[001/008] Valid loss: 0.0405
2023-02-06 11:42:27 | Valid | Epoch[500/600] Iteration[002/008] Valid loss: 0.0358
2023-02-06 11:42:27 | Valid | Epoch[500/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:42:27 | Valid | Epoch[500/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:42:27 | Valid | Epoch[500/600] Iteration[005/008] Valid loss: 0.0339
2023-02-06 11:42:27 | Valid | Epoch[500/600] Iteration[006/008] Valid loss: 0.0335
2023-02-06 11:42:27 | Valid | Epoch[500/600] Iteration[007/008] Valid loss: 0.0328
2023-02-06 11:42:27 | Valid | Epoch[500/600] Iteration[008/008] Valid loss: 0.0329
2023-02-06 11:42:27 | Valid | Epoch[500/600] MIou: 0.8973096456988217
2023-02-06 11:42:27 | Valid | Epoch[500/600] Pixel Accuracy: 0.9830233256022135
2023-02-06 11:42:27 | Valid | Epoch[500/600] Mean Pixel Accuracy: 0.9082174041702394
2023-02-06 11:42:27 | Stage | Epoch[500/600] Train loss:0.0201
2023-02-06 11:42:27 | Stage | Epoch[500/600] Valid loss:0.0329
2023-02-06 11:42:27 | Stage | Epoch[500/600] LR:0.001

2023-02-06 11:42:27 | Train | Epoch[501/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 11:42:27 | Train | Epoch[501/600] Iteration[002/030] Train loss: 0.0205
2023-02-06 11:42:27 | Train | Epoch[501/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:42:27 | Train | Epoch[501/600] Iteration[004/030] Train loss: 0.0201
2023-02-06 11:42:27 | Train | Epoch[501/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:42:27 | Train | Epoch[501/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 11:42:27 | Train | Epoch[501/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:42:27 | Train | Epoch[501/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 11:42:27 | Train | Epoch[501/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 11:42:27 | Train | Epoch[501/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:42:28 | Train | Epoch[501/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:42:29 | Valid | Epoch[501/600] Iteration[001/008] Valid loss: 0.0522
2023-02-06 11:42:29 | Valid | Epoch[501/600] Iteration[002/008] Valid loss: 0.0388
2023-02-06 11:42:29 | Valid | Epoch[501/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:42:29 | Valid | Epoch[501/600] Iteration[004/008] Valid loss: 0.0333
2023-02-06 11:42:29 | Valid | Epoch[501/600] Iteration[005/008] Valid loss: 0.0343
2023-02-06 11:42:29 | Valid | Epoch[501/600] Iteration[006/008] Valid loss: 0.0343
2023-02-06 11:42:29 | Valid | Epoch[501/600] Iteration[007/008] Valid loss: 0.0346
2023-02-06 11:42:29 | Valid | Epoch[501/600] Iteration[008/008] Valid loss: 0.0336
2023-02-06 11:42:29 | Valid | Epoch[501/600] MIou: 0.9273645986856838
2023-02-06 11:42:29 | Valid | Epoch[501/600] Pixel Accuracy: 0.9878654479980469
2023-02-06 11:42:29 | Valid | Epoch[501/600] Mean Pixel Accuracy: 0.9405585882985605
2023-02-06 11:42:29 | Stage | Epoch[501/600] Train loss:0.0200
2023-02-06 11:42:29 | Stage | Epoch[501/600] Valid loss:0.0336
2023-02-06 11:42:29 | Stage | Epoch[501/600] LR:0.0001

2023-02-06 11:42:29 | Train | Epoch[502/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 11:42:29 | Train | Epoch[502/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:42:29 | Train | Epoch[502/600] Iteration[003/030] Train loss: 0.0189
2023-02-06 11:42:29 | Train | Epoch[502/600] Iteration[004/030] Train loss: 0.0182
2023-02-06 11:42:29 | Train | Epoch[502/600] Iteration[005/030] Train loss: 0.0183
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[006/030] Train loss: 0.0187
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[007/030] Train loss: 0.0187
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[008/030] Train loss: 0.0189
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[009/030] Train loss: 0.0192
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[015/030] Train loss: 0.0206
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:42:30 | Train | Epoch[502/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:42:31 | Train | Epoch[502/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:42:31 | Train | Epoch[502/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:42:31 | Train | Epoch[502/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:42:31 | Train | Epoch[502/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:42:31 | Train | Epoch[502/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:42:31 | Valid | Epoch[502/600] Iteration[001/008] Valid loss: 0.0579
2023-02-06 11:42:31 | Valid | Epoch[502/600] Iteration[002/008] Valid loss: 0.0416
2023-02-06 11:42:31 | Valid | Epoch[502/600] Iteration[003/008] Valid loss: 0.0368
2023-02-06 11:42:31 | Valid | Epoch[502/600] Iteration[004/008] Valid loss: 0.0356
2023-02-06 11:42:31 | Valid | Epoch[502/600] Iteration[005/008] Valid loss: 0.0368
2023-02-06 11:42:31 | Valid | Epoch[502/600] Iteration[006/008] Valid loss: 0.0367
2023-02-06 11:42:31 | Valid | Epoch[502/600] Iteration[007/008] Valid loss: 0.0373
2023-02-06 11:42:31 | Valid | Epoch[502/600] Iteration[008/008] Valid loss: 0.0360
2023-02-06 11:42:31 | Valid | Epoch[502/600] MIou: 0.9323243328369748
2023-02-06 11:42:31 | Valid | Epoch[502/600] Pixel Accuracy: 0.9886474609375
2023-02-06 11:42:31 | Valid | Epoch[502/600] Mean Pixel Accuracy: 0.947024544841629
2023-02-06 11:42:31 | Stage | Epoch[502/600] Train loss:0.0200
2023-02-06 11:42:31 | Stage | Epoch[502/600] Valid loss:0.0360
2023-02-06 11:42:31 | Stage | Epoch[502/600] LR:0.0001

2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[001/030] Train loss: 0.0222
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[004/030] Train loss: 0.0211
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:42:32 | Train | Epoch[503/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:42:33 | Train | Epoch[503/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:42:33 | Train | Epoch[503/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:42:33 | Train | Epoch[503/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:42:33 | Train | Epoch[503/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:42:33 | Train | Epoch[503/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:42:33 | Train | Epoch[503/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:42:33 | Train | Epoch[503/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:42:33 | Train | Epoch[503/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:42:33 | Train | Epoch[503/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:42:33 | Train | Epoch[503/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:42:33 | Valid | Epoch[503/600] Iteration[001/008] Valid loss: 0.0590
2023-02-06 11:42:33 | Valid | Epoch[503/600] Iteration[002/008] Valid loss: 0.0421
2023-02-06 11:42:33 | Valid | Epoch[503/600] Iteration[003/008] Valid loss: 0.0372
2023-02-06 11:42:33 | Valid | Epoch[503/600] Iteration[004/008] Valid loss: 0.0360
2023-02-06 11:42:33 | Valid | Epoch[503/600] Iteration[005/008] Valid loss: 0.0373
2023-02-06 11:42:33 | Valid | Epoch[503/600] Iteration[006/008] Valid loss: 0.0372
2023-02-06 11:42:33 | Valid | Epoch[503/600] Iteration[007/008] Valid loss: 0.0379
2023-02-06 11:42:33 | Valid | Epoch[503/600] Iteration[008/008] Valid loss: 0.0366
2023-02-06 11:42:34 | Valid | Epoch[503/600] MIou: 0.9330731781605626
2023-02-06 11:42:34 | Valid | Epoch[503/600] Pixel Accuracy: 0.9887644449869791
2023-02-06 11:42:34 | Valid | Epoch[503/600] Mean Pixel Accuracy: 0.9480716173488442
2023-02-06 11:42:34 | Stage | Epoch[503/600] Train loss:0.0201
2023-02-06 11:42:34 | Stage | Epoch[503/600] Valid loss:0.0366
2023-02-06 11:42:34 | Stage | Epoch[503/600] LR:0.0001

2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[002/030] Train loss: 0.0203
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:42:34 | Train | Epoch[504/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:42:35 | Train | Epoch[504/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:42:35 | Valid | Epoch[504/600] Iteration[001/008] Valid loss: 0.0519
2023-02-06 11:42:36 | Valid | Epoch[504/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:42:36 | Valid | Epoch[504/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:42:36 | Valid | Epoch[504/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:42:36 | Valid | Epoch[504/600] Iteration[005/008] Valid loss: 0.0343
2023-02-06 11:42:36 | Valid | Epoch[504/600] Iteration[006/008] Valid loss: 0.0342
2023-02-06 11:42:36 | Valid | Epoch[504/600] Iteration[007/008] Valid loss: 0.0345
2023-02-06 11:42:36 | Valid | Epoch[504/600] Iteration[008/008] Valid loss: 0.0335
2023-02-06 11:42:36 | Valid | Epoch[504/600] MIou: 0.9279227430967005
2023-02-06 11:42:36 | Valid | Epoch[504/600] Pixel Accuracy: 0.9879570007324219
2023-02-06 11:42:36 | Valid | Epoch[504/600] Mean Pixel Accuracy: 0.9411415091930173
2023-02-06 11:42:36 | Stage | Epoch[504/600] Train loss:0.0200
2023-02-06 11:42:36 | Stage | Epoch[504/600] Valid loss:0.0335
2023-02-06 11:42:36 | Stage | Epoch[504/600] LR:0.0001

2023-02-06 11:42:36 | Train | Epoch[505/600] Iteration[001/030] Train loss: 0.0190
2023-02-06 11:42:36 | Train | Epoch[505/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 11:42:36 | Train | Epoch[505/600] Iteration[003/030] Train loss: 0.0187
2023-02-06 11:42:36 | Train | Epoch[505/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 11:42:36 | Train | Epoch[505/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 11:42:36 | Train | Epoch[505/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:42:36 | Train | Epoch[505/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:42:36 | Train | Epoch[505/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:42:36 | Train | Epoch[505/600] Iteration[009/030] Train loss: 0.0196
2023-02-06 11:42:36 | Train | Epoch[505/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[012/030] Train loss: 0.0194
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[014/030] Train loss: 0.0194
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:42:37 | Train | Epoch[505/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:42:38 | Valid | Epoch[505/600] Iteration[001/008] Valid loss: 0.0486
2023-02-06 11:42:38 | Valid | Epoch[505/600] Iteration[002/008] Valid loss: 0.0372
2023-02-06 11:42:38 | Valid | Epoch[505/600] Iteration[003/008] Valid loss: 0.0339
2023-02-06 11:42:38 | Valid | Epoch[505/600] Iteration[004/008] Valid loss: 0.0323
2023-02-06 11:42:38 | Valid | Epoch[505/600] Iteration[005/008] Valid loss: 0.0333
2023-02-06 11:42:38 | Valid | Epoch[505/600] Iteration[006/008] Valid loss: 0.0331
2023-02-06 11:42:38 | Valid | Epoch[505/600] Iteration[007/008] Valid loss: 0.0331
2023-02-06 11:42:38 | Valid | Epoch[505/600] Iteration[008/008] Valid loss: 0.0324
2023-02-06 11:42:38 | Valid | Epoch[505/600] MIou: 0.9234479622775815
2023-02-06 11:42:38 | Valid | Epoch[505/600] Pixel Accuracy: 0.9872411092122396
2023-02-06 11:42:38 | Valid | Epoch[505/600] Mean Pixel Accuracy: 0.935878542560213
2023-02-06 11:42:38 | Stage | Epoch[505/600] Train loss:0.0200
2023-02-06 11:42:38 | Stage | Epoch[505/600] Valid loss:0.0324
2023-02-06 11:42:38 | Stage | Epoch[505/600] LR:0.0001

2023-02-06 11:42:38 | Train | Epoch[506/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 11:42:38 | Train | Epoch[506/600] Iteration[002/030] Train loss: 0.0184
2023-02-06 11:42:38 | Train | Epoch[506/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 11:42:38 | Train | Epoch[506/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 11:42:38 | Train | Epoch[506/600] Iteration[005/030] Train loss: 0.0184
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[007/030] Train loss: 0.0191
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[009/030] Train loss: 0.0190
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:42:39 | Train | Epoch[506/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:42:40 | Train | Epoch[506/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:42:40 | Train | Epoch[506/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:42:40 | Train | Epoch[506/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:42:40 | Train | Epoch[506/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:42:40 | Valid | Epoch[506/600] Iteration[001/008] Valid loss: 0.0546
2023-02-06 11:42:40 | Valid | Epoch[506/600] Iteration[002/008] Valid loss: 0.0399
2023-02-06 11:42:40 | Valid | Epoch[506/600] Iteration[003/008] Valid loss: 0.0356
2023-02-06 11:42:40 | Valid | Epoch[506/600] Iteration[004/008] Valid loss: 0.0343
2023-02-06 11:42:40 | Valid | Epoch[506/600] Iteration[005/008] Valid loss: 0.0354
2023-02-06 11:42:40 | Valid | Epoch[506/600] Iteration[006/008] Valid loss: 0.0354
2023-02-06 11:42:40 | Valid | Epoch[506/600] Iteration[007/008] Valid loss: 0.0357
2023-02-06 11:42:40 | Valid | Epoch[506/600] Iteration[008/008] Valid loss: 0.0346
2023-02-06 11:42:40 | Valid | Epoch[506/600] MIou: 0.9300355335791834
2023-02-06 11:42:40 | Valid | Epoch[506/600] Pixel Accuracy: 0.9882850646972656
2023-02-06 11:42:40 | Valid | Epoch[506/600] Mean Pixel Accuracy: 0.9440609108329037
2023-02-06 11:42:40 | Stage | Epoch[506/600] Train loss:0.0201
2023-02-06 11:42:40 | Stage | Epoch[506/600] Valid loss:0.0346
2023-02-06 11:42:40 | Stage | Epoch[506/600] LR:0.0001

2023-02-06 11:42:40 | Train | Epoch[507/600] Iteration[001/030] Train loss: 0.0193
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[002/030] Train loss: 0.0205
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[004/030] Train loss: 0.0191
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[005/030] Train loss: 0.0187
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 11:42:41 | Train | Epoch[507/600] Iteration[021/030] Train loss: 0.0194
2023-02-06 11:42:42 | Train | Epoch[507/600] Iteration[022/030] Train loss: 0.0195
2023-02-06 11:42:42 | Train | Epoch[507/600] Iteration[023/030] Train loss: 0.0195
2023-02-06 11:42:42 | Train | Epoch[507/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:42:42 | Train | Epoch[507/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:42:42 | Train | Epoch[507/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:42:42 | Train | Epoch[507/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:42:42 | Train | Epoch[507/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:42:42 | Train | Epoch[507/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:42:42 | Train | Epoch[507/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:42:42 | Valid | Epoch[507/600] Iteration[001/008] Valid loss: 0.0519
2023-02-06 11:42:42 | Valid | Epoch[507/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:42:42 | Valid | Epoch[507/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:42:42 | Valid | Epoch[507/600] Iteration[004/008] Valid loss: 0.0334
2023-02-06 11:42:42 | Valid | Epoch[507/600] Iteration[005/008] Valid loss: 0.0343
2023-02-06 11:42:42 | Valid | Epoch[507/600] Iteration[006/008] Valid loss: 0.0343
2023-02-06 11:42:42 | Valid | Epoch[507/600] Iteration[007/008] Valid loss: 0.0344
2023-02-06 11:42:42 | Valid | Epoch[507/600] Iteration[008/008] Valid loss: 0.0335
2023-02-06 11:42:43 | Valid | Epoch[507/600] MIou: 0.9271882772027222
2023-02-06 11:42:43 | Valid | Epoch[507/600] Pixel Accuracy: 0.9878374735514323
2023-02-06 11:42:43 | Valid | Epoch[507/600] Mean Pixel Accuracy: 0.9403403172612332
2023-02-06 11:42:43 | Stage | Epoch[507/600] Train loss:0.0198
2023-02-06 11:42:43 | Stage | Epoch[507/600] Valid loss:0.0335
2023-02-06 11:42:43 | Stage | Epoch[507/600] LR:0.0001

2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[004/030] Train loss: 0.0189
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[005/030] Train loss: 0.0188
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[007/030] Train loss: 0.0187
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[010/030] Train loss: 0.0199
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:42:43 | Train | Epoch[508/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:42:44 | Train | Epoch[508/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:42:45 | Valid | Epoch[508/600] Iteration[001/008] Valid loss: 0.0504
2023-02-06 11:42:45 | Valid | Epoch[508/600] Iteration[002/008] Valid loss: 0.0379
2023-02-06 11:42:45 | Valid | Epoch[508/600] Iteration[003/008] Valid loss: 0.0343
2023-02-06 11:42:45 | Valid | Epoch[508/600] Iteration[004/008] Valid loss: 0.0328
2023-02-06 11:42:45 | Valid | Epoch[508/600] Iteration[005/008] Valid loss: 0.0337
2023-02-06 11:42:45 | Valid | Epoch[508/600] Iteration[006/008] Valid loss: 0.0336
2023-02-06 11:42:45 | Valid | Epoch[508/600] Iteration[007/008] Valid loss: 0.0337
2023-02-06 11:42:45 | Valid | Epoch[508/600] Iteration[008/008] Valid loss: 0.0329
2023-02-06 11:42:45 | Valid | Epoch[508/600] MIou: 0.9254394237861983
2023-02-06 11:42:45 | Valid | Epoch[508/600] Pixel Accuracy: 0.9875577290852865
2023-02-06 11:42:45 | Valid | Epoch[508/600] Mean Pixel Accuracy: 0.9382717353751784
2023-02-06 11:42:45 | Stage | Epoch[508/600] Train loss:0.0200
2023-02-06 11:42:45 | Stage | Epoch[508/600] Valid loss:0.0329
2023-02-06 11:42:45 | Stage | Epoch[508/600] LR:0.0001

2023-02-06 11:42:45 | Train | Epoch[509/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 11:42:45 | Train | Epoch[509/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 11:42:45 | Train | Epoch[509/600] Iteration[003/030] Train loss: 0.0187
2023-02-06 11:42:45 | Train | Epoch[509/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:42:45 | Train | Epoch[509/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:42:45 | Train | Epoch[509/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:42:45 | Train | Epoch[509/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:42:45 | Train | Epoch[509/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:42:45 | Train | Epoch[509/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:42:46 | Train | Epoch[509/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:42:47 | Valid | Epoch[509/600] Iteration[001/008] Valid loss: 0.0519
2023-02-06 11:42:47 | Valid | Epoch[509/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:42:47 | Valid | Epoch[509/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:42:47 | Valid | Epoch[509/600] Iteration[004/008] Valid loss: 0.0333
2023-02-06 11:42:47 | Valid | Epoch[509/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 11:42:47 | Valid | Epoch[509/600] Iteration[006/008] Valid loss: 0.0342
2023-02-06 11:42:47 | Valid | Epoch[509/600] Iteration[007/008] Valid loss: 0.0344
2023-02-06 11:42:47 | Valid | Epoch[509/600] Iteration[008/008] Valid loss: 0.0335
2023-02-06 11:42:47 | Valid | Epoch[509/600] MIou: 0.9271173570446414
2023-02-06 11:42:47 | Valid | Epoch[509/600] Pixel Accuracy: 0.987823486328125
2023-02-06 11:42:47 | Valid | Epoch[509/600] Mean Pixel Accuracy: 0.9403516507012992
2023-02-06 11:42:47 | Stage | Epoch[509/600] Train loss:0.0200
2023-02-06 11:42:47 | Stage | Epoch[509/600] Valid loss:0.0335
2023-02-06 11:42:47 | Stage | Epoch[509/600] LR:0.0001

2023-02-06 11:42:47 | Train | Epoch[510/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:42:47 | Train | Epoch[510/600] Iteration[002/030] Train loss: 0.0191
2023-02-06 11:42:47 | Train | Epoch[510/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[006/030] Train loss: 0.0199
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[018/030] Train loss: 0.0194
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:42:48 | Train | Epoch[510/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:42:49 | Train | Epoch[510/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:42:49 | Train | Epoch[510/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:42:49 | Train | Epoch[510/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:42:49 | Train | Epoch[510/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 11:42:49 | Train | Epoch[510/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:42:49 | Train | Epoch[510/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:42:49 | Valid | Epoch[510/600] Iteration[001/008] Valid loss: 0.0518
2023-02-06 11:42:49 | Valid | Epoch[510/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:42:49 | Valid | Epoch[510/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:42:49 | Valid | Epoch[510/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:42:49 | Valid | Epoch[510/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 11:42:49 | Valid | Epoch[510/600] Iteration[006/008] Valid loss: 0.0342
2023-02-06 11:42:49 | Valid | Epoch[510/600] Iteration[007/008] Valid loss: 0.0344
2023-02-06 11:42:49 | Valid | Epoch[510/600] Iteration[008/008] Valid loss: 0.0335
2023-02-06 11:42:49 | Valid | Epoch[510/600] MIou: 0.9275398312427217
2023-02-06 11:42:49 | Valid | Epoch[510/600] Pixel Accuracy: 0.9878959655761719
2023-02-06 11:42:49 | Valid | Epoch[510/600] Mean Pixel Accuracy: 0.9406768096052345
2023-02-06 11:42:49 | Stage | Epoch[510/600] Train loss:0.0198
2023-02-06 11:42:49 | Stage | Epoch[510/600] Valid loss:0.0335
2023-02-06 11:42:49 | Stage | Epoch[510/600] LR:0.0001

2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:42:50 | Train | Epoch[511/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:42:51 | Train | Epoch[511/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:42:51 | Valid | Epoch[511/600] Iteration[001/008] Valid loss: 0.0513
2023-02-06 11:42:51 | Valid | Epoch[511/600] Iteration[002/008] Valid loss: 0.0383
2023-02-06 11:42:51 | Valid | Epoch[511/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:42:51 | Valid | Epoch[511/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:42:51 | Valid | Epoch[511/600] Iteration[005/008] Valid loss: 0.0340
2023-02-06 11:42:52 | Valid | Epoch[511/600] Iteration[006/008] Valid loss: 0.0339
2023-02-06 11:42:52 | Valid | Epoch[511/600] Iteration[007/008] Valid loss: 0.0340
2023-02-06 11:42:52 | Valid | Epoch[511/600] Iteration[008/008] Valid loss: 0.0332
2023-02-06 11:42:52 | Valid | Epoch[511/600] MIou: 0.9265656689418795
2023-02-06 11:42:52 | Valid | Epoch[511/600] Pixel Accuracy: 0.9877370198567709
2023-02-06 11:42:52 | Valid | Epoch[511/600] Mean Pixel Accuracy: 0.9396320350606566
2023-02-06 11:42:52 | Stage | Epoch[511/600] Train loss:0.0202
2023-02-06 11:42:52 | Stage | Epoch[511/600] Valid loss:0.0332
2023-02-06 11:42:52 | Stage | Epoch[511/600] LR:0.0001

2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[001/030] Train loss: 0.0219
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[002/030] Train loss: 0.0217
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[004/030] Train loss: 0.0219
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[005/030] Train loss: 0.0219
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[008/030] Train loss: 0.0213
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[009/030] Train loss: 0.0212
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[011/030] Train loss: 0.0207
2023-02-06 11:42:52 | Train | Epoch[512/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:42:53 | Train | Epoch[512/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:42:54 | Valid | Epoch[512/600] Iteration[001/008] Valid loss: 0.0523
2023-02-06 11:42:54 | Valid | Epoch[512/600] Iteration[002/008] Valid loss: 0.0388
2023-02-06 11:42:54 | Valid | Epoch[512/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:42:54 | Valid | Epoch[512/600] Iteration[004/008] Valid loss: 0.0334
2023-02-06 11:42:54 | Valid | Epoch[512/600] Iteration[005/008] Valid loss: 0.0344
2023-02-06 11:42:54 | Valid | Epoch[512/600] Iteration[006/008] Valid loss: 0.0343
2023-02-06 11:42:54 | Valid | Epoch[512/600] Iteration[007/008] Valid loss: 0.0345
2023-02-06 11:42:54 | Valid | Epoch[512/600] Iteration[008/008] Valid loss: 0.0336
2023-02-06 11:42:54 | Valid | Epoch[512/600] MIou: 0.9279952134173148
2023-02-06 11:42:54 | Valid | Epoch[512/600] Pixel Accuracy: 0.9879671732584635
2023-02-06 11:42:54 | Valid | Epoch[512/600] Mean Pixel Accuracy: 0.9412802503489313
2023-02-06 11:42:54 | Stage | Epoch[512/600] Train loss:0.0199
2023-02-06 11:42:54 | Stage | Epoch[512/600] Valid loss:0.0336
2023-02-06 11:42:54 | Stage | Epoch[512/600] LR:0.0001

2023-02-06 11:42:54 | Train | Epoch[513/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 11:42:54 | Train | Epoch[513/600] Iteration[002/030] Train loss: 0.0220
2023-02-06 11:42:54 | Train | Epoch[513/600] Iteration[003/030] Train loss: 0.0216
2023-02-06 11:42:54 | Train | Epoch[513/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:42:54 | Train | Epoch[513/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:42:54 | Train | Epoch[513/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[007/030] Train loss: 0.0200
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:42:55 | Train | Epoch[513/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:42:56 | Train | Epoch[513/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:42:56 | Train | Epoch[513/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:42:56 | Train | Epoch[513/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:42:56 | Train | Epoch[513/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:42:56 | Valid | Epoch[513/600] Iteration[001/008] Valid loss: 0.0493
2023-02-06 11:42:56 | Valid | Epoch[513/600] Iteration[002/008] Valid loss: 0.0374
2023-02-06 11:42:56 | Valid | Epoch[513/600] Iteration[003/008] Valid loss: 0.0340
2023-02-06 11:42:56 | Valid | Epoch[513/600] Iteration[004/008] Valid loss: 0.0325
2023-02-06 11:42:56 | Valid | Epoch[513/600] Iteration[005/008] Valid loss: 0.0333
2023-02-06 11:42:56 | Valid | Epoch[513/600] Iteration[006/008] Valid loss: 0.0333
2023-02-06 11:42:56 | Valid | Epoch[513/600] Iteration[007/008] Valid loss: 0.0333
2023-02-06 11:42:56 | Valid | Epoch[513/600] Iteration[008/008] Valid loss: 0.0325
2023-02-06 11:42:56 | Valid | Epoch[513/600] MIou: 0.9243600431285817
2023-02-06 11:42:56 | Valid | Epoch[513/600] Pixel Accuracy: 0.9873847961425781
2023-02-06 11:42:56 | Valid | Epoch[513/600] Mean Pixel Accuracy: 0.9370163777677438
2023-02-06 11:42:56 | Stage | Epoch[513/600] Train loss:0.0201
2023-02-06 11:42:56 | Stage | Epoch[513/600] Valid loss:0.0325
2023-02-06 11:42:56 | Stage | Epoch[513/600] LR:0.0001

2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[002/030] Train loss: 0.0210
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[004/030] Train loss: 0.0221
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[005/030] Train loss: 0.0213
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[006/030] Train loss: 0.0215
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[007/030] Train loss: 0.0218
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[008/030] Train loss: 0.0216
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[009/030] Train loss: 0.0214
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[010/030] Train loss: 0.0212
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[012/030] Train loss: 0.0211
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[013/030] Train loss: 0.0211
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[014/030] Train loss: 0.0212
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[015/030] Train loss: 0.0210
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[016/030] Train loss: 0.0211
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[018/030] Train loss: 0.0208
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[019/030] Train loss: 0.0207
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:42:57 | Train | Epoch[514/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:42:58 | Train | Epoch[514/600] Iteration[022/030] Train loss: 0.0206
2023-02-06 11:42:58 | Train | Epoch[514/600] Iteration[023/030] Train loss: 0.0206
2023-02-06 11:42:58 | Train | Epoch[514/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:42:58 | Train | Epoch[514/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:42:58 | Train | Epoch[514/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:42:58 | Train | Epoch[514/600] Iteration[027/030] Train loss: 0.0204
2023-02-06 11:42:58 | Train | Epoch[514/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:42:58 | Train | Epoch[514/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:42:58 | Train | Epoch[514/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:42:58 | Valid | Epoch[514/600] Iteration[001/008] Valid loss: 0.0517
2023-02-06 11:42:58 | Valid | Epoch[514/600] Iteration[002/008] Valid loss: 0.0385
2023-02-06 11:42:58 | Valid | Epoch[514/600] Iteration[003/008] Valid loss: 0.0346
2023-02-06 11:42:58 | Valid | Epoch[514/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:42:58 | Valid | Epoch[514/600] Iteration[005/008] Valid loss: 0.0341
2023-02-06 11:42:58 | Valid | Epoch[514/600] Iteration[006/008] Valid loss: 0.0341
2023-02-06 11:42:58 | Valid | Epoch[514/600] Iteration[007/008] Valid loss: 0.0343
2023-02-06 11:42:58 | Valid | Epoch[514/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 11:42:58 | Valid | Epoch[514/600] MIou: 0.9270043082583614
2023-02-06 11:42:58 | Valid | Epoch[514/600] Pixel Accuracy: 0.9878082275390625
2023-02-06 11:42:58 | Valid | Epoch[514/600] Mean Pixel Accuracy: 0.9401150068456239
2023-02-06 11:42:58 | Stage | Epoch[514/600] Train loss:0.0202
2023-02-06 11:42:58 | Stage | Epoch[514/600] Valid loss:0.0334
2023-02-06 11:42:58 | Stage | Epoch[514/600] LR:0.0001

2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[001/030] Train loss: 0.0190
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[003/030] Train loss: 0.0205
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[015/030] Train loss: 0.0206
2023-02-06 11:42:59 | Train | Epoch[515/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:43:00 | Train | Epoch[515/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:43:00 | Valid | Epoch[515/600] Iteration[001/008] Valid loss: 0.0526
2023-02-06 11:43:00 | Valid | Epoch[515/600] Iteration[002/008] Valid loss: 0.0389
2023-02-06 11:43:00 | Valid | Epoch[515/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:43:01 | Valid | Epoch[515/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:43:01 | Valid | Epoch[515/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:43:01 | Valid | Epoch[515/600] Iteration[006/008] Valid loss: 0.0344
2023-02-06 11:43:01 | Valid | Epoch[515/600] Iteration[007/008] Valid loss: 0.0346
2023-02-06 11:43:01 | Valid | Epoch[515/600] Iteration[008/008] Valid loss: 0.0337
2023-02-06 11:43:01 | Valid | Epoch[515/600] MIou: 0.9283420816255992
2023-02-06 11:43:01 | Valid | Epoch[515/600] Pixel Accuracy: 0.9880205790201823
2023-02-06 11:43:01 | Valid | Epoch[515/600] Mean Pixel Accuracy: 0.9417724588536543
2023-02-06 11:43:01 | Stage | Epoch[515/600] Train loss:0.0200
2023-02-06 11:43:01 | Stage | Epoch[515/600] Valid loss:0.0337
2023-02-06 11:43:01 | Stage | Epoch[515/600] LR:0.0001

2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[002/030] Train loss: 0.0179
2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[004/030] Train loss: 0.0188
2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[005/030] Train loss: 0.0190
2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:43:01 | Train | Epoch[516/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[012/030] Train loss: 0.0208
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[015/030] Train loss: 0.0206
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[018/030] Train loss: 0.0206
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:43:02 | Train | Epoch[516/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:43:03 | Valid | Epoch[516/600] Iteration[001/008] Valid loss: 0.0546
2023-02-06 11:43:03 | Valid | Epoch[516/600] Iteration[002/008] Valid loss: 0.0399
2023-02-06 11:43:03 | Valid | Epoch[516/600] Iteration[003/008] Valid loss: 0.0356
2023-02-06 11:43:03 | Valid | Epoch[516/600] Iteration[004/008] Valid loss: 0.0343
2023-02-06 11:43:03 | Valid | Epoch[516/600] Iteration[005/008] Valid loss: 0.0353
2023-02-06 11:43:03 | Valid | Epoch[516/600] Iteration[006/008] Valid loss: 0.0352
2023-02-06 11:43:03 | Valid | Epoch[516/600] Iteration[007/008] Valid loss: 0.0355
2023-02-06 11:43:03 | Valid | Epoch[516/600] Iteration[008/008] Valid loss: 0.0345
2023-02-06 11:43:03 | Valid | Epoch[516/600] MIou: 0.9296691372715635
2023-02-06 11:43:03 | Valid | Epoch[516/600] Pixel Accuracy: 0.988226572672526
2023-02-06 11:43:03 | Valid | Epoch[516/600] Mean Pixel Accuracy: 0.943610290001685
2023-02-06 11:43:03 | Stage | Epoch[516/600] Train loss:0.0202
2023-02-06 11:43:03 | Stage | Epoch[516/600] Valid loss:0.0345
2023-02-06 11:43:03 | Stage | Epoch[516/600] LR:0.0001

2023-02-06 11:43:03 | Train | Epoch[517/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 11:43:03 | Train | Epoch[517/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:43:03 | Train | Epoch[517/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:43:03 | Train | Epoch[517/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:43:03 | Train | Epoch[517/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[018/030] Train loss: 0.0195
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[020/030] Train loss: 0.0196
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:43:04 | Train | Epoch[517/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:43:05 | Train | Epoch[517/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:43:05 | Train | Epoch[517/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:43:05 | Train | Epoch[517/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:43:05 | Train | Epoch[517/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:43:05 | Valid | Epoch[517/600] Iteration[001/008] Valid loss: 0.0544
2023-02-06 11:43:05 | Valid | Epoch[517/600] Iteration[002/008] Valid loss: 0.0398
2023-02-06 11:43:05 | Valid | Epoch[517/600] Iteration[003/008] Valid loss: 0.0355
2023-02-06 11:43:05 | Valid | Epoch[517/600] Iteration[004/008] Valid loss: 0.0342
2023-02-06 11:43:05 | Valid | Epoch[517/600] Iteration[005/008] Valid loss: 0.0351
2023-02-06 11:43:05 | Valid | Epoch[517/600] Iteration[006/008] Valid loss: 0.0351
2023-02-06 11:43:05 | Valid | Epoch[517/600] Iteration[007/008] Valid loss: 0.0354
2023-02-06 11:43:05 | Valid | Epoch[517/600] Iteration[008/008] Valid loss: 0.0344
2023-02-06 11:43:05 | Valid | Epoch[517/600] MIou: 0.9299023432972047
2023-02-06 11:43:05 | Valid | Epoch[517/600] Pixel Accuracy: 0.9882672627766927
2023-02-06 11:43:05 | Valid | Epoch[517/600] Mean Pixel Accuracy: 0.9437658049200797
2023-02-06 11:43:05 | Stage | Epoch[517/600] Train loss:0.0200
2023-02-06 11:43:05 | Stage | Epoch[517/600] Valid loss:0.0344
2023-02-06 11:43:05 | Stage | Epoch[517/600] LR:0.0001

2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[002/030] Train loss: 0.0178
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[003/030] Train loss: 0.0186
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[004/030] Train loss: 0.0185
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[009/030] Train loss: 0.0196
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[010/030] Train loss: 0.0199
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:43:06 | Train | Epoch[518/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[026/030] Train loss: 0.0204
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:43:07 | Train | Epoch[518/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:43:07 | Valid | Epoch[518/600] Iteration[001/008] Valid loss: 0.0524
2023-02-06 11:43:07 | Valid | Epoch[518/600] Iteration[002/008] Valid loss: 0.0388
2023-02-06 11:43:07 | Valid | Epoch[518/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:43:07 | Valid | Epoch[518/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:43:07 | Valid | Epoch[518/600] Iteration[005/008] Valid loss: 0.0344
2023-02-06 11:43:07 | Valid | Epoch[518/600] Iteration[006/008] Valid loss: 0.0343
2023-02-06 11:43:07 | Valid | Epoch[518/600] Iteration[007/008] Valid loss: 0.0346
2023-02-06 11:43:07 | Valid | Epoch[518/600] Iteration[008/008] Valid loss: 0.0336
2023-02-06 11:43:08 | Valid | Epoch[518/600] MIou: 0.9276086415663537
2023-02-06 11:43:08 | Valid | Epoch[518/600] Pixel Accuracy: 0.9878997802734375
2023-02-06 11:43:08 | Valid | Epoch[518/600] Mean Pixel Accuracy: 0.9410212917871968
2023-02-06 11:43:08 | Stage | Epoch[518/600] Train loss:0.0201
2023-02-06 11:43:08 | Stage | Epoch[518/600] Valid loss:0.0336
2023-02-06 11:43:08 | Stage | Epoch[518/600] LR:0.0001

2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[001/030] Train loss: 0.0175
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[003/030] Train loss: 0.0208
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[005/030] Train loss: 0.0214
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[007/030] Train loss: 0.0214
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:43:08 | Train | Epoch[519/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:43:09 | Train | Epoch[519/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:43:10 | Valid | Epoch[519/600] Iteration[001/008] Valid loss: 0.0516
2023-02-06 11:43:10 | Valid | Epoch[519/600] Iteration[002/008] Valid loss: 0.0384
2023-02-06 11:43:10 | Valid | Epoch[519/600] Iteration[003/008] Valid loss: 0.0346
2023-02-06 11:43:10 | Valid | Epoch[519/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:43:10 | Valid | Epoch[519/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 11:43:10 | Valid | Epoch[519/600] Iteration[006/008] Valid loss: 0.0342
2023-02-06 11:43:10 | Valid | Epoch[519/600] Iteration[007/008] Valid loss: 0.0344
2023-02-06 11:43:10 | Valid | Epoch[519/600] Iteration[008/008] Valid loss: 0.0335
2023-02-06 11:43:10 | Valid | Epoch[519/600] MIou: 0.9269325475504735
2023-02-06 11:43:10 | Valid | Epoch[519/600] Pixel Accuracy: 0.9877980550130209
2023-02-06 11:43:10 | Valid | Epoch[519/600] Mean Pixel Accuracy: 0.939982606161222
2023-02-06 11:43:10 | Stage | Epoch[519/600] Train loss:0.0201
2023-02-06 11:43:10 | Stage | Epoch[519/600] Valid loss:0.0335
2023-02-06 11:43:10 | Stage | Epoch[519/600] LR:0.0001

2023-02-06 11:43:10 | Train | Epoch[520/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 11:43:10 | Train | Epoch[520/600] Iteration[002/030] Train loss: 0.0209
2023-02-06 11:43:10 | Train | Epoch[520/600] Iteration[003/030] Train loss: 0.0201
2023-02-06 11:43:10 | Train | Epoch[520/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:43:10 | Train | Epoch[520/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:43:10 | Train | Epoch[520/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:43:10 | Train | Epoch[520/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:43:10 | Train | Epoch[520/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 11:43:10 | Train | Epoch[520/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[010/030] Train loss: 0.0207
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[011/030] Train loss: 0.0208
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[013/030] Train loss: 0.0206
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[016/030] Train loss: 0.0209
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[017/030] Train loss: 0.0208
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[018/030] Train loss: 0.0208
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[019/030] Train loss: 0.0207
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[020/030] Train loss: 0.0208
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[021/030] Train loss: 0.0207
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[022/030] Train loss: 0.0205
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[023/030] Train loss: 0.0205
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:43:11 | Train | Epoch[520/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:43:12 | Valid | Epoch[520/600] Iteration[001/008] Valid loss: 0.0524
2023-02-06 11:43:12 | Valid | Epoch[520/600] Iteration[002/008] Valid loss: 0.0388
2023-02-06 11:43:12 | Valid | Epoch[520/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:43:12 | Valid | Epoch[520/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:43:12 | Valid | Epoch[520/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:43:12 | Valid | Epoch[520/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:43:12 | Valid | Epoch[520/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 11:43:12 | Valid | Epoch[520/600] Iteration[008/008] Valid loss: 0.0338
2023-02-06 11:43:12 | Valid | Epoch[520/600] MIou: 0.9280341099762826
2023-02-06 11:43:12 | Valid | Epoch[520/600] Pixel Accuracy: 0.9879735310872396
2023-02-06 11:43:12 | Valid | Epoch[520/600] Mean Pixel Accuracy: 0.9413217877118538
2023-02-06 11:43:12 | Stage | Epoch[520/600] Train loss:0.0202
2023-02-06 11:43:12 | Stage | Epoch[520/600] Valid loss:0.0338
2023-02-06 11:43:12 | Stage | Epoch[520/600] LR:0.0001

2023-02-06 11:43:12 | Train | Epoch[521/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 11:43:12 | Train | Epoch[521/600] Iteration[002/030] Train loss: 0.0213
2023-02-06 11:43:12 | Train | Epoch[521/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:43:12 | Train | Epoch[521/600] Iteration[004/030] Train loss: 0.0217
2023-02-06 11:43:12 | Train | Epoch[521/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[011/030] Train loss: 0.0208
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[012/030] Train loss: 0.0208
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[013/030] Train loss: 0.0206
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[015/030] Train loss: 0.0209
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:43:13 | Train | Epoch[521/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:43:14 | Train | Epoch[521/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:43:14 | Train | Epoch[521/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:43:14 | Train | Epoch[521/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:43:14 | Train | Epoch[521/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:43:14 | Valid | Epoch[521/600] Iteration[001/008] Valid loss: 0.0535
2023-02-06 11:43:14 | Valid | Epoch[521/600] Iteration[002/008] Valid loss: 0.0393
2023-02-06 11:43:14 | Valid | Epoch[521/600] Iteration[003/008] Valid loss: 0.0352
2023-02-06 11:43:14 | Valid | Epoch[521/600] Iteration[004/008] Valid loss: 0.0339
2023-02-06 11:43:14 | Valid | Epoch[521/600] Iteration[005/008] Valid loss: 0.0349
2023-02-06 11:43:14 | Valid | Epoch[521/600] Iteration[006/008] Valid loss: 0.0349
2023-02-06 11:43:14 | Valid | Epoch[521/600] Iteration[007/008] Valid loss: 0.0351
2023-02-06 11:43:14 | Valid | Epoch[521/600] Iteration[008/008] Valid loss: 0.0341
2023-02-06 11:43:14 | Valid | Epoch[521/600] MIou: 0.928676651111743
2023-02-06 11:43:14 | Valid | Epoch[521/600] Pixel Accuracy: 0.9880727132161459
2023-02-06 11:43:14 | Valid | Epoch[521/600] Mean Pixel Accuracy: 0.9422259256225349
2023-02-06 11:43:14 | Stage | Epoch[521/600] Train loss:0.0200
2023-02-06 11:43:14 | Stage | Epoch[521/600] Valid loss:0.0341
2023-02-06 11:43:14 | Stage | Epoch[521/600] LR:0.0001

2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[001/030] Train loss: 0.0207
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[002/030] Train loss: 0.0200
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[003/030] Train loss: 0.0188
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:43:15 | Train | Epoch[522/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:43:16 | Train | Epoch[522/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:43:16 | Train | Epoch[522/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:43:16 | Train | Epoch[522/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:43:16 | Train | Epoch[522/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:43:16 | Train | Epoch[522/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:43:16 | Train | Epoch[522/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:43:16 | Train | Epoch[522/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:43:16 | Train | Epoch[522/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:43:16 | Train | Epoch[522/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:43:16 | Train | Epoch[522/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:43:16 | Valid | Epoch[522/600] Iteration[001/008] Valid loss: 0.0528
2023-02-06 11:43:16 | Valid | Epoch[522/600] Iteration[002/008] Valid loss: 0.0390
2023-02-06 11:43:16 | Valid | Epoch[522/600] Iteration[003/008] Valid loss: 0.0350
2023-02-06 11:43:16 | Valid | Epoch[522/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:43:16 | Valid | Epoch[522/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:43:16 | Valid | Epoch[522/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:43:16 | Valid | Epoch[522/600] Iteration[007/008] Valid loss: 0.0348
2023-02-06 11:43:16 | Valid | Epoch[522/600] Iteration[008/008] Valid loss: 0.0338
2023-02-06 11:43:17 | Valid | Epoch[522/600] MIou: 0.9281222028476094
2023-02-06 11:43:17 | Valid | Epoch[522/600] Pixel Accuracy: 0.9879849751790365
2023-02-06 11:43:17 | Valid | Epoch[522/600] Mean Pixel Accuracy: 0.9415246324896587
2023-02-06 11:43:17 | Stage | Epoch[522/600] Train loss:0.0199
2023-02-06 11:43:17 | Stage | Epoch[522/600] Valid loss:0.0338
2023-02-06 11:43:17 | Stage | Epoch[522/600] LR:0.0001

2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[004/030] Train loss: 0.0191
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[007/030] Train loss: 0.0189
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:43:17 | Train | Epoch[523/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:43:18 | Train | Epoch[523/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:43:19 | Valid | Epoch[523/600] Iteration[001/008] Valid loss: 0.0553
2023-02-06 11:43:19 | Valid | Epoch[523/600] Iteration[002/008] Valid loss: 0.0403
2023-02-06 11:43:19 | Valid | Epoch[523/600] Iteration[003/008] Valid loss: 0.0359
2023-02-06 11:43:19 | Valid | Epoch[523/600] Iteration[004/008] Valid loss: 0.0345
2023-02-06 11:43:19 | Valid | Epoch[523/600] Iteration[005/008] Valid loss: 0.0356
2023-02-06 11:43:19 | Valid | Epoch[523/600] Iteration[006/008] Valid loss: 0.0355
2023-02-06 11:43:19 | Valid | Epoch[523/600] Iteration[007/008] Valid loss: 0.0359
2023-02-06 11:43:19 | Valid | Epoch[523/600] Iteration[008/008] Valid loss: 0.0348
2023-02-06 11:43:19 | Valid | Epoch[523/600] MIou: 0.9303029586200661
2023-02-06 11:43:19 | Valid | Epoch[523/600] Pixel Accuracy: 0.9883282979329427
2023-02-06 11:43:19 | Valid | Epoch[523/600] Mean Pixel Accuracy: 0.9443699948811282
2023-02-06 11:43:19 | Stage | Epoch[523/600] Train loss:0.0203
2023-02-06 11:43:19 | Stage | Epoch[523/600] Valid loss:0.0348
2023-02-06 11:43:19 | Stage | Epoch[523/600] LR:0.0001

2023-02-06 11:43:19 | Train | Epoch[524/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 11:43:19 | Train | Epoch[524/600] Iteration[002/030] Train loss: 0.0204
2023-02-06 11:43:19 | Train | Epoch[524/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:43:19 | Train | Epoch[524/600] Iteration[004/030] Train loss: 0.0208
2023-02-06 11:43:19 | Train | Epoch[524/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:43:19 | Train | Epoch[524/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:43:19 | Train | Epoch[524/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:43:19 | Train | Epoch[524/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 11:43:19 | Train | Epoch[524/600] Iteration[009/030] Train loss: 0.0192
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[013/030] Train loss: 0.0193
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[014/030] Train loss: 0.0192
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[021/030] Train loss: 0.0195
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[022/030] Train loss: 0.0196
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:43:20 | Train | Epoch[524/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:43:21 | Valid | Epoch[524/600] Iteration[001/008] Valid loss: 0.0519
2023-02-06 11:43:21 | Valid | Epoch[524/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:43:21 | Valid | Epoch[524/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:43:21 | Valid | Epoch[524/600] Iteration[004/008] Valid loss: 0.0333
2023-02-06 11:43:21 | Valid | Epoch[524/600] Iteration[005/008] Valid loss: 0.0343
2023-02-06 11:43:21 | Valid | Epoch[524/600] Iteration[006/008] Valid loss: 0.0341
2023-02-06 11:43:21 | Valid | Epoch[524/600] Iteration[007/008] Valid loss: 0.0343
2023-02-06 11:43:21 | Valid | Epoch[524/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 11:43:21 | Valid | Epoch[524/600] MIou: 0.9273931985206623
2023-02-06 11:43:21 | Valid | Epoch[524/600] Pixel Accuracy: 0.9878705342610677
2023-02-06 11:43:21 | Valid | Epoch[524/600] Mean Pixel Accuracy: 0.9405740648686647
2023-02-06 11:43:21 | Stage | Epoch[524/600] Train loss:0.0199
2023-02-06 11:43:21 | Stage | Epoch[524/600] Valid loss:0.0334
2023-02-06 11:43:21 | Stage | Epoch[524/600] LR:0.0001

2023-02-06 11:43:21 | Train | Epoch[525/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 11:43:21 | Train | Epoch[525/600] Iteration[002/030] Train loss: 0.0220
2023-02-06 11:43:21 | Train | Epoch[525/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:43:22 | Train | Epoch[525/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:43:23 | Train | Epoch[525/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:43:23 | Train | Epoch[525/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:43:23 | Train | Epoch[525/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:43:23 | Train | Epoch[525/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:43:23 | Train | Epoch[525/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:43:23 | Train | Epoch[525/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:43:23 | Valid | Epoch[525/600] Iteration[001/008] Valid loss: 0.0504
2023-02-06 11:43:23 | Valid | Epoch[525/600] Iteration[002/008] Valid loss: 0.0379
2023-02-06 11:43:23 | Valid | Epoch[525/600] Iteration[003/008] Valid loss: 0.0343
2023-02-06 11:43:23 | Valid | Epoch[525/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 11:43:23 | Valid | Epoch[525/600] Iteration[005/008] Valid loss: 0.0338
2023-02-06 11:43:23 | Valid | Epoch[525/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 11:43:23 | Valid | Epoch[525/600] Iteration[007/008] Valid loss: 0.0338
2023-02-06 11:43:23 | Valid | Epoch[525/600] Iteration[008/008] Valid loss: 0.0330
2023-02-06 11:43:23 | Valid | Epoch[525/600] MIou: 0.9258102866495094
2023-02-06 11:43:23 | Valid | Epoch[525/600] Pixel Accuracy: 0.9876187642415365
2023-02-06 11:43:23 | Valid | Epoch[525/600] Mean Pixel Accuracy: 0.9386476683617923
2023-02-06 11:43:23 | Stage | Epoch[525/600] Train loss:0.0200
2023-02-06 11:43:23 | Stage | Epoch[525/600] Valid loss:0.0330
2023-02-06 11:43:23 | Stage | Epoch[525/600] LR:0.0001

2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[001/030] Train loss: 0.0203
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[006/030] Train loss: 0.0191
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:43:24 | Train | Epoch[526/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:43:25 | Train | Epoch[526/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:43:25 | Valid | Epoch[526/600] Iteration[001/008] Valid loss: 0.0490
2023-02-06 11:43:25 | Valid | Epoch[526/600] Iteration[002/008] Valid loss: 0.0373
2023-02-06 11:43:25 | Valid | Epoch[526/600] Iteration[003/008] Valid loss: 0.0340
2023-02-06 11:43:25 | Valid | Epoch[526/600] Iteration[004/008] Valid loss: 0.0323
2023-02-06 11:43:25 | Valid | Epoch[526/600] Iteration[005/008] Valid loss: 0.0332
2023-02-06 11:43:26 | Valid | Epoch[526/600] Iteration[006/008] Valid loss: 0.0331
2023-02-06 11:43:26 | Valid | Epoch[526/600] Iteration[007/008] Valid loss: 0.0332
2023-02-06 11:43:26 | Valid | Epoch[526/600] Iteration[008/008] Valid loss: 0.0324
2023-02-06 11:43:26 | Valid | Epoch[526/600] MIou: 0.9234956508804923
2023-02-06 11:43:26 | Valid | Epoch[526/600] Pixel Accuracy: 0.9872461954752604
2023-02-06 11:43:26 | Valid | Epoch[526/600] Mean Pixel Accuracy: 0.9360208285605589
2023-02-06 11:43:26 | Stage | Epoch[526/600] Train loss:0.0200
2023-02-06 11:43:26 | Stage | Epoch[526/600] Valid loss:0.0324
2023-02-06 11:43:26 | Stage | Epoch[526/600] LR:0.0001

2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[001/030] Train loss: 0.0201
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[003/030] Train loss: 0.0197
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:43:26 | Train | Epoch[527/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:43:27 | Train | Epoch[527/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:43:28 | Valid | Epoch[527/600] Iteration[001/008] Valid loss: 0.0504
2023-02-06 11:43:28 | Valid | Epoch[527/600] Iteration[002/008] Valid loss: 0.0379
2023-02-06 11:43:28 | Valid | Epoch[527/600] Iteration[003/008] Valid loss: 0.0343
2023-02-06 11:43:28 | Valid | Epoch[527/600] Iteration[004/008] Valid loss: 0.0328
2023-02-06 11:43:28 | Valid | Epoch[527/600] Iteration[005/008] Valid loss: 0.0337
2023-02-06 11:43:28 | Valid | Epoch[527/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 11:43:28 | Valid | Epoch[527/600] Iteration[007/008] Valid loss: 0.0338
2023-02-06 11:43:28 | Valid | Epoch[527/600] Iteration[008/008] Valid loss: 0.0330
2023-02-06 11:43:28 | Valid | Epoch[527/600] MIou: 0.9253336504965869
2023-02-06 11:43:28 | Valid | Epoch[527/600] Pixel Accuracy: 0.9875386555989584
2023-02-06 11:43:28 | Valid | Epoch[527/600] Mean Pixel Accuracy: 0.9382232089445555
2023-02-06 11:43:28 | Stage | Epoch[527/600] Train loss:0.0199
2023-02-06 11:43:28 | Stage | Epoch[527/600] Valid loss:0.0330
2023-02-06 11:43:28 | Stage | Epoch[527/600] LR:0.0001

2023-02-06 11:43:28 | Train | Epoch[528/600] Iteration[001/030] Train loss: 0.0213
2023-02-06 11:43:28 | Train | Epoch[528/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:43:28 | Train | Epoch[528/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:43:28 | Train | Epoch[528/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:43:28 | Train | Epoch[528/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:43:28 | Train | Epoch[528/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 11:43:29 | Train | Epoch[528/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:43:30 | Train | Epoch[528/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:43:30 | Train | Epoch[528/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:43:30 | Train | Epoch[528/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:43:30 | Valid | Epoch[528/600] Iteration[001/008] Valid loss: 0.0543
2023-02-06 11:43:30 | Valid | Epoch[528/600] Iteration[002/008] Valid loss: 0.0398
2023-02-06 11:43:30 | Valid | Epoch[528/600] Iteration[003/008] Valid loss: 0.0355
2023-02-06 11:43:30 | Valid | Epoch[528/600] Iteration[004/008] Valid loss: 0.0341
2023-02-06 11:43:30 | Valid | Epoch[528/600] Iteration[005/008] Valid loss: 0.0351
2023-02-06 11:43:30 | Valid | Epoch[528/600] Iteration[006/008] Valid loss: 0.0350
2023-02-06 11:43:30 | Valid | Epoch[528/600] Iteration[007/008] Valid loss: 0.0354
2023-02-06 11:43:30 | Valid | Epoch[528/600] Iteration[008/008] Valid loss: 0.0344
2023-02-06 11:43:30 | Valid | Epoch[528/600] MIou: 0.9293255706247949
2023-02-06 11:43:30 | Valid | Epoch[528/600] Pixel Accuracy: 0.9881744384765625
2023-02-06 11:43:30 | Valid | Epoch[528/600] Mean Pixel Accuracy: 0.9430870780461715
2023-02-06 11:43:30 | Stage | Epoch[528/600] Train loss:0.0200
2023-02-06 11:43:30 | Stage | Epoch[528/600] Valid loss:0.0344
2023-02-06 11:43:30 | Stage | Epoch[528/600] LR:0.0001

2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[002/030] Train loss: 0.0220
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[003/030] Train loss: 0.0217
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[004/030] Train loss: 0.0221
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[005/030] Train loss: 0.0219
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[006/030] Train loss: 0.0213
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:43:31 | Train | Epoch[529/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:43:32 | Train | Epoch[529/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:43:32 | Train | Epoch[529/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:43:32 | Train | Epoch[529/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:43:32 | Train | Epoch[529/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:43:32 | Train | Epoch[529/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:43:32 | Train | Epoch[529/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:43:32 | Train | Epoch[529/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:43:32 | Train | Epoch[529/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:43:32 | Train | Epoch[529/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:43:32 | Train | Epoch[529/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:43:32 | Valid | Epoch[529/600] Iteration[001/008] Valid loss: 0.0517
2023-02-06 11:43:32 | Valid | Epoch[529/600] Iteration[002/008] Valid loss: 0.0385
2023-02-06 11:43:32 | Valid | Epoch[529/600] Iteration[003/008] Valid loss: 0.0346
2023-02-06 11:43:32 | Valid | Epoch[529/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:43:32 | Valid | Epoch[529/600] Iteration[005/008] Valid loss: 0.0341
2023-02-06 11:43:32 | Valid | Epoch[529/600] Iteration[006/008] Valid loss: 0.0341
2023-02-06 11:43:32 | Valid | Epoch[529/600] Iteration[007/008] Valid loss: 0.0343
2023-02-06 11:43:32 | Valid | Epoch[529/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 11:43:33 | Valid | Epoch[529/600] MIou: 0.9267722331949237
2023-02-06 11:43:33 | Valid | Epoch[529/600] Pixel Accuracy: 0.987768809000651
2023-02-06 11:43:33 | Valid | Epoch[529/600] Mean Pixel Accuracy: 0.9399221480049269
2023-02-06 11:43:33 | Stage | Epoch[529/600] Train loss:0.0200
2023-02-06 11:43:33 | Stage | Epoch[529/600] Valid loss:0.0334
2023-02-06 11:43:33 | Stage | Epoch[529/600] LR:0.0001

2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[002/030] Train loss: 0.0216
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[008/030] Train loss: 0.0209
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[011/030] Train loss: 0.0209
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:43:33 | Train | Epoch[530/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:43:34 | Train | Epoch[530/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:43:35 | Valid | Epoch[530/600] Iteration[001/008] Valid loss: 0.0533
2023-02-06 11:43:35 | Valid | Epoch[530/600] Iteration[002/008] Valid loss: 0.0393
2023-02-06 11:43:35 | Valid | Epoch[530/600] Iteration[003/008] Valid loss: 0.0352
2023-02-06 11:43:35 | Valid | Epoch[530/600] Iteration[004/008] Valid loss: 0.0338
2023-02-06 11:43:35 | Valid | Epoch[530/600] Iteration[005/008] Valid loss: 0.0347
2023-02-06 11:43:35 | Valid | Epoch[530/600] Iteration[006/008] Valid loss: 0.0347
2023-02-06 11:43:35 | Valid | Epoch[530/600] Iteration[007/008] Valid loss: 0.0350
2023-02-06 11:43:35 | Valid | Epoch[530/600] Iteration[008/008] Valid loss: 0.0340
2023-02-06 11:43:35 | Valid | Epoch[530/600] MIou: 0.9285729902990223
2023-02-06 11:43:35 | Valid | Epoch[530/600] Pixel Accuracy: 0.9880549112955729
2023-02-06 11:43:35 | Valid | Epoch[530/600] Mean Pixel Accuracy: 0.9421463957411216
2023-02-06 11:43:35 | Stage | Epoch[530/600] Train loss:0.0201
2023-02-06 11:43:35 | Stage | Epoch[530/600] Valid loss:0.0340
2023-02-06 11:43:35 | Stage | Epoch[530/600] LR:0.0001

2023-02-06 11:43:35 | Train | Epoch[531/600] Iteration[001/030] Train loss: 0.0217
2023-02-06 11:43:35 | Train | Epoch[531/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 11:43:35 | Train | Epoch[531/600] Iteration[003/030] Train loss: 0.0201
2023-02-06 11:43:35 | Train | Epoch[531/600] Iteration[004/030] Train loss: 0.0201
2023-02-06 11:43:35 | Train | Epoch[531/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:43:35 | Train | Epoch[531/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:43:35 | Train | Epoch[531/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 11:43:35 | Train | Epoch[531/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:43:36 | Train | Epoch[531/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:43:37 | Train | Epoch[531/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:43:37 | Valid | Epoch[531/600] Iteration[001/008] Valid loss: 0.0531
2023-02-06 11:43:37 | Valid | Epoch[531/600] Iteration[002/008] Valid loss: 0.0391
2023-02-06 11:43:37 | Valid | Epoch[531/600] Iteration[003/008] Valid loss: 0.0351
2023-02-06 11:43:37 | Valid | Epoch[531/600] Iteration[004/008] Valid loss: 0.0337
2023-02-06 11:43:37 | Valid | Epoch[531/600] Iteration[005/008] Valid loss: 0.0348
2023-02-06 11:43:37 | Valid | Epoch[531/600] Iteration[006/008] Valid loss: 0.0347
2023-02-06 11:43:37 | Valid | Epoch[531/600] Iteration[007/008] Valid loss: 0.0350
2023-02-06 11:43:37 | Valid | Epoch[531/600] Iteration[008/008] Valid loss: 0.0340
2023-02-06 11:43:37 | Valid | Epoch[531/600] MIou: 0.9291286170340639
2023-02-06 11:43:37 | Valid | Epoch[531/600] Pixel Accuracy: 0.9881464640299479
2023-02-06 11:43:37 | Valid | Epoch[531/600] Mean Pixel Accuracy: 0.9427166356925544
2023-02-06 11:43:37 | Stage | Epoch[531/600] Train loss:0.0199
2023-02-06 11:43:37 | Stage | Epoch[531/600] Valid loss:0.0340
2023-02-06 11:43:37 | Stage | Epoch[531/600] LR:0.0001

2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[001/030] Train loss: 0.0172
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[002/030] Train loss: 0.0172
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[003/030] Train loss: 0.0177
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[004/030] Train loss: 0.0173
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[005/030] Train loss: 0.0179
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[007/030] Train loss: 0.0192
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:43:38 | Train | Epoch[532/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:43:39 | Train | Epoch[532/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:43:39 | Train | Epoch[532/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:43:39 | Train | Epoch[532/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:43:39 | Train | Epoch[532/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:43:39 | Train | Epoch[532/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:43:39 | Train | Epoch[532/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:43:39 | Train | Epoch[532/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:43:39 | Train | Epoch[532/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:43:39 | Train | Epoch[532/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:43:39 | Valid | Epoch[532/600] Iteration[001/008] Valid loss: 0.0547
2023-02-06 11:43:39 | Valid | Epoch[532/600] Iteration[002/008] Valid loss: 0.0399
2023-02-06 11:43:39 | Valid | Epoch[532/600] Iteration[003/008] Valid loss: 0.0356
2023-02-06 11:43:39 | Valid | Epoch[532/600] Iteration[004/008] Valid loss: 0.0343
2023-02-06 11:43:39 | Valid | Epoch[532/600] Iteration[005/008] Valid loss: 0.0353
2023-02-06 11:43:39 | Valid | Epoch[532/600] Iteration[006/008] Valid loss: 0.0352
2023-02-06 11:43:39 | Valid | Epoch[532/600] Iteration[007/008] Valid loss: 0.0356
2023-02-06 11:43:39 | Valid | Epoch[532/600] Iteration[008/008] Valid loss: 0.0345
2023-02-06 11:43:40 | Valid | Epoch[532/600] MIou: 0.9296644875753692
2023-02-06 11:43:40 | Valid | Epoch[532/600] Pixel Accuracy: 0.9882278442382812
2023-02-06 11:43:40 | Valid | Epoch[532/600] Mean Pixel Accuracy: 0.9435285627787979
2023-02-06 11:43:40 | Stage | Epoch[532/600] Train loss:0.0202
2023-02-06 11:43:40 | Stage | Epoch[532/600] Valid loss:0.0345
2023-02-06 11:43:40 | Stage | Epoch[532/600] LR:0.0001

2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[001/030] Train loss: 0.0215
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[002/030] Train loss: 0.0214
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[005/030] Train loss: 0.0210
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[006/030] Train loss: 0.0204
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:43:40 | Train | Epoch[533/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:43:41 | Train | Epoch[533/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:43:42 | Valid | Epoch[533/600] Iteration[001/008] Valid loss: 0.0548
2023-02-06 11:43:42 | Valid | Epoch[533/600] Iteration[002/008] Valid loss: 0.0400
2023-02-06 11:43:42 | Valid | Epoch[533/600] Iteration[003/008] Valid loss: 0.0356
2023-02-06 11:43:42 | Valid | Epoch[533/600] Iteration[004/008] Valid loss: 0.0344
2023-02-06 11:43:42 | Valid | Epoch[533/600] Iteration[005/008] Valid loss: 0.0355
2023-02-06 11:43:42 | Valid | Epoch[533/600] Iteration[006/008] Valid loss: 0.0354
2023-02-06 11:43:42 | Valid | Epoch[533/600] Iteration[007/008] Valid loss: 0.0358
2023-02-06 11:43:42 | Valid | Epoch[533/600] Iteration[008/008] Valid loss: 0.0347
2023-02-06 11:43:42 | Valid | Epoch[533/600] MIou: 0.9301369717431495
2023-02-06 11:43:42 | Valid | Epoch[533/600] Pixel Accuracy: 0.9883003234863281
2023-02-06 11:43:42 | Valid | Epoch[533/600] Mean Pixel Accuracy: 0.9442214690304339
2023-02-06 11:43:42 | Stage | Epoch[533/600] Train loss:0.0199
2023-02-06 11:43:42 | Stage | Epoch[533/600] Valid loss:0.0347
2023-02-06 11:43:42 | Stage | Epoch[533/600] LR:0.0001

2023-02-06 11:43:42 | Train | Epoch[534/600] Iteration[001/030] Train loss: 0.0174
2023-02-06 11:43:42 | Train | Epoch[534/600] Iteration[002/030] Train loss: 0.0178
2023-02-06 11:43:42 | Train | Epoch[534/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 11:43:42 | Train | Epoch[534/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:43:42 | Train | Epoch[534/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:43:42 | Train | Epoch[534/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:43:42 | Train | Epoch[534/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:43:42 | Train | Epoch[534/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[018/030] Train loss: 0.0206
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[020/030] Train loss: 0.0207
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[021/030] Train loss: 0.0206
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[022/030] Train loss: 0.0206
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[023/030] Train loss: 0.0206
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[024/030] Train loss: 0.0204
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:43:43 | Train | Epoch[534/600] Iteration[028/030] Train loss: 0.0203
2023-02-06 11:43:44 | Train | Epoch[534/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:43:44 | Train | Epoch[534/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:43:44 | Valid | Epoch[534/600] Iteration[001/008] Valid loss: 0.0535
2023-02-06 11:43:44 | Valid | Epoch[534/600] Iteration[002/008] Valid loss: 0.0394
2023-02-06 11:43:44 | Valid | Epoch[534/600] Iteration[003/008] Valid loss: 0.0352
2023-02-06 11:43:44 | Valid | Epoch[534/600] Iteration[004/008] Valid loss: 0.0338
2023-02-06 11:43:44 | Valid | Epoch[534/600] Iteration[005/008] Valid loss: 0.0348
2023-02-06 11:43:44 | Valid | Epoch[534/600] Iteration[006/008] Valid loss: 0.0348
2023-02-06 11:43:44 | Valid | Epoch[534/600] Iteration[007/008] Valid loss: 0.0351
2023-02-06 11:43:44 | Valid | Epoch[534/600] Iteration[008/008] Valid loss: 0.0341
2023-02-06 11:43:44 | Valid | Epoch[534/600] MIou: 0.928958021136997
2023-02-06 11:43:44 | Valid | Epoch[534/600] Pixel Accuracy: 0.9881184895833334
2023-02-06 11:43:44 | Valid | Epoch[534/600] Mean Pixel Accuracy: 0.9425364074842997
2023-02-06 11:43:44 | Stage | Epoch[534/600] Train loss:0.0202
2023-02-06 11:43:44 | Stage | Epoch[534/600] Valid loss:0.0341
2023-02-06 11:43:44 | Stage | Epoch[534/600] LR:0.0001

2023-02-06 11:43:44 | Train | Epoch[535/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[002/030] Train loss: 0.0178
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[003/030] Train loss: 0.0187
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[004/030] Train loss: 0.0188
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[005/030] Train loss: 0.0193
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:43:45 | Train | Epoch[535/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:43:46 | Train | Epoch[535/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:43:46 | Train | Epoch[535/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:43:46 | Train | Epoch[535/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:43:46 | Train | Epoch[535/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:43:46 | Train | Epoch[535/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:43:46 | Train | Epoch[535/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 11:43:46 | Train | Epoch[535/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:43:46 | Train | Epoch[535/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:43:46 | Valid | Epoch[535/600] Iteration[001/008] Valid loss: 0.0529
2023-02-06 11:43:46 | Valid | Epoch[535/600] Iteration[002/008] Valid loss: 0.0390
2023-02-06 11:43:46 | Valid | Epoch[535/600] Iteration[003/008] Valid loss: 0.0350
2023-02-06 11:43:46 | Valid | Epoch[535/600] Iteration[004/008] Valid loss: 0.0336
2023-02-06 11:43:46 | Valid | Epoch[535/600] Iteration[005/008] Valid loss: 0.0346
2023-02-06 11:43:46 | Valid | Epoch[535/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 11:43:46 | Valid | Epoch[535/600] Iteration[007/008] Valid loss: 0.0349
2023-02-06 11:43:46 | Valid | Epoch[535/600] Iteration[008/008] Valid loss: 0.0339
2023-02-06 11:43:47 | Valid | Epoch[535/600] MIou: 0.9284841118271703
2023-02-06 11:43:47 | Valid | Epoch[535/600] Pixel Accuracy: 0.9880409240722656
2023-02-06 11:43:47 | Valid | Epoch[535/600] Mean Pixel Accuracy: 0.942030919750946
2023-02-06 11:43:47 | Stage | Epoch[535/600] Train loss:0.0198
2023-02-06 11:43:47 | Stage | Epoch[535/600] Valid loss:0.0339
2023-02-06 11:43:47 | Stage | Epoch[535/600] LR:0.0001

2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[001/030] Train loss: 0.0175
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[010/030] Train loss: 0.0192
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[011/030] Train loss: 0.0192
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[013/030] Train loss: 0.0193
2023-02-06 11:43:47 | Train | Epoch[536/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[016/030] Train loss: 0.0195
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[017/030] Train loss: 0.0194
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[018/030] Train loss: 0.0193
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[019/030] Train loss: 0.0194
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[021/030] Train loss: 0.0195
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[022/030] Train loss: 0.0195
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[023/030] Train loss: 0.0195
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[024/030] Train loss: 0.0196
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[025/030] Train loss: 0.0196
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[026/030] Train loss: 0.0196
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[027/030] Train loss: 0.0196
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[029/030] Train loss: 0.0196
2023-02-06 11:43:48 | Train | Epoch[536/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:43:49 | Valid | Epoch[536/600] Iteration[001/008] Valid loss: 0.0498
2023-02-06 11:43:49 | Valid | Epoch[536/600] Iteration[002/008] Valid loss: 0.0376
2023-02-06 11:43:49 | Valid | Epoch[536/600] Iteration[003/008] Valid loss: 0.0342
2023-02-06 11:43:49 | Valid | Epoch[536/600] Iteration[004/008] Valid loss: 0.0326
2023-02-06 11:43:49 | Valid | Epoch[536/600] Iteration[005/008] Valid loss: 0.0335
2023-02-06 11:43:49 | Valid | Epoch[536/600] Iteration[006/008] Valid loss: 0.0334
2023-02-06 11:43:49 | Valid | Epoch[536/600] Iteration[007/008] Valid loss: 0.0334
2023-02-06 11:43:49 | Valid | Epoch[536/600] Iteration[008/008] Valid loss: 0.0327
2023-02-06 11:43:49 | Valid | Epoch[536/600] MIou: 0.9243647653593722
2023-02-06 11:43:49 | Valid | Epoch[536/600] Pixel Accuracy: 0.9873847961425781
2023-02-06 11:43:49 | Valid | Epoch[536/600] Mean Pixel Accuracy: 0.937048080125304
2023-02-06 11:43:49 | Stage | Epoch[536/600] Train loss:0.0198
2023-02-06 11:43:49 | Stage | Epoch[536/600] Valid loss:0.0327
2023-02-06 11:43:49 | Stage | Epoch[536/600] LR:0.0001

2023-02-06 11:43:49 | Train | Epoch[537/600] Iteration[001/030] Train loss: 0.0185
2023-02-06 11:43:49 | Train | Epoch[537/600] Iteration[002/030] Train loss: 0.0209
2023-02-06 11:43:49 | Train | Epoch[537/600] Iteration[003/030] Train loss: 0.0218
2023-02-06 11:43:49 | Train | Epoch[537/600] Iteration[004/030] Train loss: 0.0222
2023-02-06 11:43:49 | Train | Epoch[537/600] Iteration[005/030] Train loss: 0.0222
2023-02-06 11:43:49 | Train | Epoch[537/600] Iteration[006/030] Train loss: 0.0220
2023-02-06 11:43:49 | Train | Epoch[537/600] Iteration[007/030] Train loss: 0.0214
2023-02-06 11:43:49 | Train | Epoch[537/600] Iteration[008/030] Train loss: 0.0213
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[009/030] Train loss: 0.0211
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[010/030] Train loss: 0.0211
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[011/030] Train loss: 0.0210
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:43:50 | Train | Epoch[537/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:43:51 | Train | Epoch[537/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:43:51 | Valid | Epoch[537/600] Iteration[001/008] Valid loss: 0.0523
2023-02-06 11:43:51 | Valid | Epoch[537/600] Iteration[002/008] Valid loss: 0.0388
2023-02-06 11:43:51 | Valid | Epoch[537/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:43:51 | Valid | Epoch[537/600] Iteration[004/008] Valid loss: 0.0334
2023-02-06 11:43:51 | Valid | Epoch[537/600] Iteration[005/008] Valid loss: 0.0343
2023-02-06 11:43:51 | Valid | Epoch[537/600] Iteration[006/008] Valid loss: 0.0343
2023-02-06 11:43:51 | Valid | Epoch[537/600] Iteration[007/008] Valid loss: 0.0346
2023-02-06 11:43:51 | Valid | Epoch[537/600] Iteration[008/008] Valid loss: 0.0336
2023-02-06 11:43:51 | Valid | Epoch[537/600] MIou: 0.9272836917960579
2023-02-06 11:43:51 | Valid | Epoch[537/600] Pixel Accuracy: 0.9878514607747396
2023-02-06 11:43:51 | Valid | Epoch[537/600] Mean Pixel Accuracy: 0.9405001765519935
2023-02-06 11:43:51 | Stage | Epoch[537/600] Train loss:0.0198
2023-02-06 11:43:51 | Stage | Epoch[537/600] Valid loss:0.0336
2023-02-06 11:43:51 | Stage | Epoch[537/600] LR:0.0001

2023-02-06 11:43:51 | Train | Epoch[538/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 11:43:51 | Train | Epoch[538/600] Iteration[002/030] Train loss: 0.0212
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[006/030] Train loss: 0.0204
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[007/030] Train loss: 0.0205
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[012/030] Train loss: 0.0206
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:43:52 | Train | Epoch[538/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:43:53 | Train | Epoch[538/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:43:53 | Train | Epoch[538/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:43:53 | Train | Epoch[538/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:43:53 | Train | Epoch[538/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:43:53 | Train | Epoch[538/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:43:53 | Train | Epoch[538/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:43:53 | Train | Epoch[538/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:43:53 | Valid | Epoch[538/600] Iteration[001/008] Valid loss: 0.0519
2023-02-06 11:43:53 | Valid | Epoch[538/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:43:53 | Valid | Epoch[538/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:43:53 | Valid | Epoch[538/600] Iteration[004/008] Valid loss: 0.0333
2023-02-06 11:43:53 | Valid | Epoch[538/600] Iteration[005/008] Valid loss: 0.0343
2023-02-06 11:43:53 | Valid | Epoch[538/600] Iteration[006/008] Valid loss: 0.0343
2023-02-06 11:43:53 | Valid | Epoch[538/600] Iteration[007/008] Valid loss: 0.0345
2023-02-06 11:43:53 | Valid | Epoch[538/600] Iteration[008/008] Valid loss: 0.0336
2023-02-06 11:43:53 | Valid | Epoch[538/600] MIou: 0.9276033622411708
2023-02-06 11:43:53 | Valid | Epoch[538/600] Pixel Accuracy: 0.9879061381022135
2023-02-06 11:43:53 | Valid | Epoch[538/600] Mean Pixel Accuracy: 0.9407521460460275
2023-02-06 11:43:53 | Stage | Epoch[538/600] Train loss:0.0201
2023-02-06 11:43:53 | Stage | Epoch[538/600] Valid loss:0.0336
2023-02-06 11:43:53 | Stage | Epoch[538/600] LR:0.0001

2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[003/030] Train loss: 0.0189
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[004/030] Train loss: 0.0188
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[005/030] Train loss: 0.0190
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[006/030] Train loss: 0.0193
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 11:43:54 | Train | Epoch[539/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[017/030] Train loss: 0.0196
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:43:55 | Train | Epoch[539/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:43:55 | Valid | Epoch[539/600] Iteration[001/008] Valid loss: 0.0515
2023-02-06 11:43:56 | Valid | Epoch[539/600] Iteration[002/008] Valid loss: 0.0384
2023-02-06 11:43:56 | Valid | Epoch[539/600] Iteration[003/008] Valid loss: 0.0346
2023-02-06 11:43:56 | Valid | Epoch[539/600] Iteration[004/008] Valid loss: 0.0331
2023-02-06 11:43:56 | Valid | Epoch[539/600] Iteration[005/008] Valid loss: 0.0340
2023-02-06 11:43:56 | Valid | Epoch[539/600] Iteration[006/008] Valid loss: 0.0339
2023-02-06 11:43:56 | Valid | Epoch[539/600] Iteration[007/008] Valid loss: 0.0341
2023-02-06 11:43:56 | Valid | Epoch[539/600] Iteration[008/008] Valid loss: 0.0332
2023-02-06 11:43:56 | Valid | Epoch[539/600] MIou: 0.9259339483556372
2023-02-06 11:43:56 | Valid | Epoch[539/600] Pixel Accuracy: 0.987634023030599
2023-02-06 11:43:56 | Valid | Epoch[539/600] Mean Pixel Accuracy: 0.9389540574041003
2023-02-06 11:43:56 | Stage | Epoch[539/600] Train loss:0.0202
2023-02-06 11:43:56 | Stage | Epoch[539/600] Valid loss:0.0332
2023-02-06 11:43:56 | Stage | Epoch[539/600] LR:0.0001

2023-02-06 11:43:56 | Train | Epoch[540/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 11:43:56 | Train | Epoch[540/600] Iteration[002/030] Train loss: 0.0183
2023-02-06 11:43:56 | Train | Epoch[540/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:43:56 | Train | Epoch[540/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:43:56 | Train | Epoch[540/600] Iteration[005/030] Train loss: 0.0198
2023-02-06 11:43:56 | Train | Epoch[540/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:43:56 | Train | Epoch[540/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:43:56 | Train | Epoch[540/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 11:43:56 | Train | Epoch[540/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:43:57 | Train | Epoch[540/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:43:58 | Train | Epoch[540/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:43:58 | Valid | Epoch[540/600] Iteration[001/008] Valid loss: 0.0509
2023-02-06 11:43:58 | Valid | Epoch[540/600] Iteration[002/008] Valid loss: 0.0381
2023-02-06 11:43:58 | Valid | Epoch[540/600] Iteration[003/008] Valid loss: 0.0344
2023-02-06 11:43:58 | Valid | Epoch[540/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 11:43:58 | Valid | Epoch[540/600] Iteration[005/008] Valid loss: 0.0338
2023-02-06 11:43:58 | Valid | Epoch[540/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 11:43:58 | Valid | Epoch[540/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 11:43:58 | Valid | Epoch[540/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:43:58 | Valid | Epoch[540/600] MIou: 0.9256641958688097
2023-02-06 11:43:58 | Valid | Epoch[540/600] Pixel Accuracy: 0.9875907897949219
2023-02-06 11:43:58 | Valid | Epoch[540/600] Mean Pixel Accuracy: 0.9386386328843637
2023-02-06 11:43:58 | Stage | Epoch[540/600] Train loss:0.0199
2023-02-06 11:43:58 | Stage | Epoch[540/600] Valid loss:0.0331
2023-02-06 11:43:58 | Stage | Epoch[540/600] LR:0.0001

2023-02-06 11:43:58 | Train | Epoch[541/600] Iteration[001/030] Train loss: 0.0192
2023-02-06 11:43:58 | Train | Epoch[541/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[007/030] Train loss: 0.0191
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[010/030] Train loss: 0.0191
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[011/030] Train loss: 0.0190
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[012/030] Train loss: 0.0190
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[013/030] Train loss: 0.0190
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[014/030] Train loss: 0.0192
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[020/030] Train loss: 0.0196
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[021/030] Train loss: 0.0194
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:43:59 | Train | Epoch[541/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 11:44:00 | Train | Epoch[541/600] Iteration[024/030] Train loss: 0.0196
2023-02-06 11:44:00 | Train | Epoch[541/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:44:00 | Train | Epoch[541/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 11:44:00 | Train | Epoch[541/600] Iteration[027/030] Train loss: 0.0197
2023-02-06 11:44:00 | Train | Epoch[541/600] Iteration[028/030] Train loss: 0.0196
2023-02-06 11:44:00 | Train | Epoch[541/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:44:00 | Train | Epoch[541/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:44:00 | Valid | Epoch[541/600] Iteration[001/008] Valid loss: 0.0508
2023-02-06 11:44:00 | Valid | Epoch[541/600] Iteration[002/008] Valid loss: 0.0381
2023-02-06 11:44:00 | Valid | Epoch[541/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:44:00 | Valid | Epoch[541/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 11:44:00 | Valid | Epoch[541/600] Iteration[005/008] Valid loss: 0.0338
2023-02-06 11:44:00 | Valid | Epoch[541/600] Iteration[006/008] Valid loss: 0.0337
2023-02-06 11:44:00 | Valid | Epoch[541/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 11:44:00 | Valid | Epoch[541/600] Iteration[008/008] Valid loss: 0.0330
2023-02-06 11:44:00 | Valid | Epoch[541/600] MIou: 0.9256313568220158
2023-02-06 11:44:00 | Valid | Epoch[541/600] Pixel Accuracy: 0.9875882466634115
2023-02-06 11:44:00 | Valid | Epoch[541/600] Mean Pixel Accuracy: 0.9385040851690698
2023-02-06 11:44:00 | Stage | Epoch[541/600] Train loss:0.0198
2023-02-06 11:44:00 | Stage | Epoch[541/600] Valid loss:0.0330
2023-02-06 11:44:00 | Stage | Epoch[541/600] LR:0.0001

2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[001/030] Train loss: 0.0205
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[004/030] Train loss: 0.0196
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:44:01 | Train | Epoch[542/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[021/030] Train loss: 0.0194
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:44:02 | Train | Epoch[542/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:44:02 | Valid | Epoch[542/600] Iteration[001/008] Valid loss: 0.0527
2023-02-06 11:44:02 | Valid | Epoch[542/600] Iteration[002/008] Valid loss: 0.0390
2023-02-06 11:44:02 | Valid | Epoch[542/600] Iteration[003/008] Valid loss: 0.0350
2023-02-06 11:44:02 | Valid | Epoch[542/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:44:02 | Valid | Epoch[542/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:44:03 | Valid | Epoch[542/600] Iteration[006/008] Valid loss: 0.0344
2023-02-06 11:44:03 | Valid | Epoch[542/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 11:44:03 | Valid | Epoch[542/600] Iteration[008/008] Valid loss: 0.0337
2023-02-06 11:44:03 | Valid | Epoch[542/600] MIou: 0.928248225423045
2023-02-06 11:44:03 | Valid | Epoch[542/600] Pixel Accuracy: 0.9880027770996094
2023-02-06 11:44:03 | Valid | Epoch[542/600] Mean Pixel Accuracy: 0.9417626741588739
2023-02-06 11:44:03 | Stage | Epoch[542/600] Train loss:0.0198
2023-02-06 11:44:03 | Stage | Epoch[542/600] Valid loss:0.0337
2023-02-06 11:44:03 | Stage | Epoch[542/600] LR:0.0001

2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[001/030] Train loss: 0.0227
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[003/030] Train loss: 0.0215
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[011/030] Train loss: 0.0204
2023-02-06 11:44:03 | Train | Epoch[543/600] Iteration[012/030] Train loss: 0.0206
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:44:04 | Train | Epoch[543/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:44:05 | Valid | Epoch[543/600] Iteration[001/008] Valid loss: 0.0505
2023-02-06 11:44:05 | Valid | Epoch[543/600] Iteration[002/008] Valid loss: 0.0380
2023-02-06 11:44:05 | Valid | Epoch[543/600] Iteration[003/008] Valid loss: 0.0344
2023-02-06 11:44:05 | Valid | Epoch[543/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:44:05 | Valid | Epoch[543/600] Iteration[005/008] Valid loss: 0.0339
2023-02-06 11:44:05 | Valid | Epoch[543/600] Iteration[006/008] Valid loss: 0.0339
2023-02-06 11:44:05 | Valid | Epoch[543/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 11:44:05 | Valid | Epoch[543/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:44:05 | Valid | Epoch[543/600] MIou: 0.9252112529620653
2023-02-06 11:44:05 | Valid | Epoch[543/600] Pixel Accuracy: 0.9875208536783854
2023-02-06 11:44:05 | Valid | Epoch[543/600] Mean Pixel Accuracy: 0.9380168696329007
2023-02-06 11:44:05 | Stage | Epoch[543/600] Train loss:0.0200
2023-02-06 11:44:05 | Stage | Epoch[543/600] Valid loss:0.0331
2023-02-06 11:44:05 | Stage | Epoch[543/600] LR:0.0001

2023-02-06 11:44:05 | Train | Epoch[544/600] Iteration[001/030] Train loss: 0.0195
2023-02-06 11:44:05 | Train | Epoch[544/600] Iteration[002/030] Train loss: 0.0222
2023-02-06 11:44:05 | Train | Epoch[544/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:44:05 | Train | Epoch[544/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:44:05 | Train | Epoch[544/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 11:44:05 | Train | Epoch[544/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:44:05 | Train | Epoch[544/600] Iteration[007/030] Train loss: 0.0200
2023-02-06 11:44:05 | Train | Epoch[544/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:44:06 | Train | Epoch[544/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:44:07 | Train | Epoch[544/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:44:07 | Train | Epoch[544/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:44:07 | Valid | Epoch[544/600] Iteration[001/008] Valid loss: 0.0503
2023-02-06 11:44:07 | Valid | Epoch[544/600] Iteration[002/008] Valid loss: 0.0378
2023-02-06 11:44:07 | Valid | Epoch[544/600] Iteration[003/008] Valid loss: 0.0342
2023-02-06 11:44:07 | Valid | Epoch[544/600] Iteration[004/008] Valid loss: 0.0327
2023-02-06 11:44:07 | Valid | Epoch[544/600] Iteration[005/008] Valid loss: 0.0337
2023-02-06 11:44:07 | Valid | Epoch[544/600] Iteration[006/008] Valid loss: 0.0336
2023-02-06 11:44:07 | Valid | Epoch[544/600] Iteration[007/008] Valid loss: 0.0337
2023-02-06 11:44:07 | Valid | Epoch[544/600] Iteration[008/008] Valid loss: 0.0329
2023-02-06 11:44:07 | Valid | Epoch[544/600] MIou: 0.9255222106814973
2023-02-06 11:44:07 | Valid | Epoch[544/600] Pixel Accuracy: 0.9875717163085938
2023-02-06 11:44:07 | Valid | Epoch[544/600] Mean Pixel Accuracy: 0.9383428280647697
2023-02-06 11:44:07 | Stage | Epoch[544/600] Train loss:0.0199
2023-02-06 11:44:07 | Stage | Epoch[544/600] Valid loss:0.0329
2023-02-06 11:44:07 | Stage | Epoch[544/600] LR:0.0001

2023-02-06 11:44:07 | Train | Epoch[545/600] Iteration[001/030] Train loss: 0.0187
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[002/030] Train loss: 0.0203
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[003/030] Train loss: 0.0209
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[004/030] Train loss: 0.0204
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[013/030] Train loss: 0.0193
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[020/030] Train loss: 0.0196
2023-02-06 11:44:08 | Train | Epoch[545/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:44:09 | Train | Epoch[545/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:44:09 | Train | Epoch[545/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:44:09 | Train | Epoch[545/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:44:09 | Train | Epoch[545/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:44:09 | Train | Epoch[545/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:44:09 | Train | Epoch[545/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:44:09 | Train | Epoch[545/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:44:09 | Train | Epoch[545/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:44:09 | Train | Epoch[545/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:44:09 | Valid | Epoch[545/600] Iteration[001/008] Valid loss: 0.0527
2023-02-06 11:44:09 | Valid | Epoch[545/600] Iteration[002/008] Valid loss: 0.0390
2023-02-06 11:44:09 | Valid | Epoch[545/600] Iteration[003/008] Valid loss: 0.0350
2023-02-06 11:44:09 | Valid | Epoch[545/600] Iteration[004/008] Valid loss: 0.0337
2023-02-06 11:44:09 | Valid | Epoch[545/600] Iteration[005/008] Valid loss: 0.0346
2023-02-06 11:44:09 | Valid | Epoch[545/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 11:44:09 | Valid | Epoch[545/600] Iteration[007/008] Valid loss: 0.0348
2023-02-06 11:44:09 | Valid | Epoch[545/600] Iteration[008/008] Valid loss: 0.0338
2023-02-06 11:44:10 | Valid | Epoch[545/600] MIou: 0.9282410713489935
2023-02-06 11:44:10 | Valid | Epoch[545/600] Pixel Accuracy: 0.988000233968099
2023-02-06 11:44:10 | Valid | Epoch[545/600] Mean Pixel Accuracy: 0.9418056596459184
2023-02-06 11:44:10 | Stage | Epoch[545/600] Train loss:0.0201
2023-02-06 11:44:10 | Stage | Epoch[545/600] Valid loss:0.0338
2023-02-06 11:44:10 | Stage | Epoch[545/600] LR:0.0001

2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:44:10 | Train | Epoch[546/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:44:11 | Train | Epoch[546/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:44:12 | Valid | Epoch[546/600] Iteration[001/008] Valid loss: 0.0518
2023-02-06 11:44:12 | Valid | Epoch[546/600] Iteration[002/008] Valid loss: 0.0385
2023-02-06 11:44:12 | Valid | Epoch[546/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:44:12 | Valid | Epoch[546/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:44:12 | Valid | Epoch[546/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 11:44:12 | Valid | Epoch[546/600] Iteration[006/008] Valid loss: 0.0341
2023-02-06 11:44:12 | Valid | Epoch[546/600] Iteration[007/008] Valid loss: 0.0343
2023-02-06 11:44:12 | Valid | Epoch[546/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 11:44:12 | Valid | Epoch[546/600] MIou: 0.9269635570381979
2023-02-06 11:44:12 | Valid | Epoch[546/600] Pixel Accuracy: 0.9878018697102865
2023-02-06 11:44:12 | Valid | Epoch[546/600] Mean Pixel Accuracy: 0.9400607885396771
2023-02-06 11:44:12 | Stage | Epoch[546/600] Train loss:0.0200
2023-02-06 11:44:12 | Stage | Epoch[546/600] Valid loss:0.0334
2023-02-06 11:44:12 | Stage | Epoch[546/600] LR:0.0001

2023-02-06 11:44:12 | Train | Epoch[547/600] Iteration[001/030] Train loss: 0.0161
2023-02-06 11:44:12 | Train | Epoch[547/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 11:44:12 | Train | Epoch[547/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:44:12 | Train | Epoch[547/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:44:12 | Train | Epoch[547/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:44:12 | Train | Epoch[547/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:44:12 | Train | Epoch[547/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:44:12 | Train | Epoch[547/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[010/030] Train loss: 0.0199
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[015/030] Train loss: 0.0196
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:44:13 | Train | Epoch[547/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:44:14 | Train | Epoch[547/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:44:14 | Valid | Epoch[547/600] Iteration[001/008] Valid loss: 0.0508
2023-02-06 11:44:14 | Valid | Epoch[547/600] Iteration[002/008] Valid loss: 0.0380
2023-02-06 11:44:14 | Valid | Epoch[547/600] Iteration[003/008] Valid loss: 0.0344
2023-02-06 11:44:14 | Valid | Epoch[547/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 11:44:14 | Valid | Epoch[547/600] Iteration[005/008] Valid loss: 0.0339
2023-02-06 11:44:14 | Valid | Epoch[547/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 11:44:14 | Valid | Epoch[547/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 11:44:14 | Valid | Epoch[547/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:44:14 | Valid | Epoch[547/600] MIou: 0.9257707058839858
2023-02-06 11:44:14 | Valid | Epoch[547/600] Pixel Accuracy: 0.9876085917154948
2023-02-06 11:44:14 | Valid | Epoch[547/600] Mean Pixel Accuracy: 0.9387371841803132
2023-02-06 11:44:14 | Stage | Epoch[547/600] Train loss:0.0199
2023-02-06 11:44:14 | Stage | Epoch[547/600] Valid loss:0.0331
2023-02-06 11:44:14 | Stage | Epoch[547/600] LR:0.0001

2023-02-06 11:44:14 | Train | Epoch[548/600] Iteration[001/030] Train loss: 0.0165
2023-02-06 11:44:14 | Train | Epoch[548/600] Iteration[002/030] Train loss: 0.0169
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[003/030] Train loss: 0.0193
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[007/030] Train loss: 0.0204
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[009/030] Train loss: 0.0196
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[010/030] Train loss: 0.0194
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[012/030] Train loss: 0.0194
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:44:15 | Train | Epoch[548/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:44:16 | Train | Epoch[548/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:44:16 | Train | Epoch[548/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:44:16 | Train | Epoch[548/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:44:16 | Train | Epoch[548/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:44:16 | Train | Epoch[548/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:44:16 | Train | Epoch[548/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:44:16 | Train | Epoch[548/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:44:16 | Train | Epoch[548/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:44:16 | Valid | Epoch[548/600] Iteration[001/008] Valid loss: 0.0585
2023-02-06 11:44:16 | Valid | Epoch[548/600] Iteration[002/008] Valid loss: 0.0419
2023-02-06 11:44:16 | Valid | Epoch[548/600] Iteration[003/008] Valid loss: 0.0370
2023-02-06 11:44:16 | Valid | Epoch[548/600] Iteration[004/008] Valid loss: 0.0359
2023-02-06 11:44:16 | Valid | Epoch[548/600] Iteration[005/008] Valid loss: 0.0372
2023-02-06 11:44:16 | Valid | Epoch[548/600] Iteration[006/008] Valid loss: 0.0372
2023-02-06 11:44:16 | Valid | Epoch[548/600] Iteration[007/008] Valid loss: 0.0378
2023-02-06 11:44:16 | Valid | Epoch[548/600] Iteration[008/008] Valid loss: 0.0365
2023-02-06 11:44:16 | Valid | Epoch[548/600] MIou: 0.9324403462753759
2023-02-06 11:44:16 | Valid | Epoch[548/600] Pixel Accuracy: 0.9886639912923177
2023-02-06 11:44:16 | Valid | Epoch[548/600] Mean Pixel Accuracy: 0.9472492066610502
2023-02-06 11:44:16 | Stage | Epoch[548/600] Train loss:0.0200
2023-02-06 11:44:16 | Stage | Epoch[548/600] Valid loss:0.0365
2023-02-06 11:44:16 | Stage | Epoch[548/600] LR:0.0001

2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[002/030] Train loss: 0.0205
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[004/030] Train loss: 0.0202
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[006/030] Train loss: 0.0207
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:44:17 | Train | Epoch[549/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:44:18 | Train | Epoch[549/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:44:18 | Valid | Epoch[549/600] Iteration[001/008] Valid loss: 0.0569
2023-02-06 11:44:19 | Valid | Epoch[549/600] Iteration[002/008] Valid loss: 0.0410
2023-02-06 11:44:19 | Valid | Epoch[549/600] Iteration[003/008] Valid loss: 0.0364
2023-02-06 11:44:19 | Valid | Epoch[549/600] Iteration[004/008] Valid loss: 0.0352
2023-02-06 11:44:19 | Valid | Epoch[549/600] Iteration[005/008] Valid loss: 0.0363
2023-02-06 11:44:19 | Valid | Epoch[549/600] Iteration[006/008] Valid loss: 0.0362
2023-02-06 11:44:19 | Valid | Epoch[549/600] Iteration[007/008] Valid loss: 0.0367
2023-02-06 11:44:19 | Valid | Epoch[549/600] Iteration[008/008] Valid loss: 0.0355
2023-02-06 11:44:19 | Valid | Epoch[549/600] MIou: 0.9323765821234271
2023-02-06 11:44:19 | Valid | Epoch[549/600] Pixel Accuracy: 0.9886601765950521
2023-02-06 11:44:19 | Valid | Epoch[549/600] Mean Pixel Accuracy: 0.9469174054221119
2023-02-06 11:44:19 | Stage | Epoch[549/600] Train loss:0.0199
2023-02-06 11:44:19 | Stage | Epoch[549/600] Valid loss:0.0355
2023-02-06 11:44:19 | Stage | Epoch[549/600] LR:0.0001

2023-02-06 11:44:19 | Train | Epoch[550/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 11:44:19 | Train | Epoch[550/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 11:44:19 | Train | Epoch[550/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:44:19 | Train | Epoch[550/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:44:19 | Train | Epoch[550/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:44:19 | Train | Epoch[550/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 11:44:19 | Train | Epoch[550/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 11:44:19 | Train | Epoch[550/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 11:44:19 | Train | Epoch[550/600] Iteration[009/030] Train loss: 0.0192
2023-02-06 11:44:19 | Train | Epoch[550/600] Iteration[010/030] Train loss: 0.0192
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[011/030] Train loss: 0.0197
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[018/030] Train loss: 0.0195
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[021/030] Train loss: 0.0195
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[022/030] Train loss: 0.0196
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[025/030] Train loss: 0.0196
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[027/030] Train loss: 0.0197
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[028/030] Train loss: 0.0196
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[029/030] Train loss: 0.0197
2023-02-06 11:44:20 | Train | Epoch[550/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:44:21 | Valid | Epoch[550/600] Iteration[001/008] Valid loss: 0.0490
2023-02-06 11:44:21 | Valid | Epoch[550/600] Iteration[002/008] Valid loss: 0.0373
2023-02-06 11:44:21 | Valid | Epoch[550/600] Iteration[003/008] Valid loss: 0.0339
2023-02-06 11:44:21 | Valid | Epoch[550/600] Iteration[004/008] Valid loss: 0.0324
2023-02-06 11:44:21 | Valid | Epoch[550/600] Iteration[005/008] Valid loss: 0.0332
2023-02-06 11:44:21 | Valid | Epoch[550/600] Iteration[006/008] Valid loss: 0.0331
2023-02-06 11:44:21 | Valid | Epoch[550/600] Iteration[007/008] Valid loss: 0.0331
2023-02-06 11:44:21 | Valid | Epoch[550/600] Iteration[008/008] Valid loss: 0.0324
2023-02-06 11:44:21 | Valid | Epoch[550/600] MIou: 0.9236775506162966
2023-02-06 11:44:21 | Valid | Epoch[550/600] Pixel Accuracy: 0.987274169921875
2023-02-06 11:44:21 | Valid | Epoch[550/600] Mean Pixel Accuracy: 0.9362708019554464
2023-02-06 11:44:21 | Stage | Epoch[550/600] Train loss:0.0198
2023-02-06 11:44:21 | Stage | Epoch[550/600] Valid loss:0.0324
2023-02-06 11:44:21 | Stage | Epoch[550/600] LR:0.0001

2023-02-06 11:44:21 | Train | Epoch[551/600] Iteration[001/030] Train loss: 0.0174
2023-02-06 11:44:21 | Train | Epoch[551/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 11:44:21 | Train | Epoch[551/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:44:21 | Train | Epoch[551/600] Iteration[004/030] Train loss: 0.0201
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[007/030] Train loss: 0.0203
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[018/030] Train loss: 0.0196
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:44:22 | Train | Epoch[551/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:44:23 | Train | Epoch[551/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:44:23 | Train | Epoch[551/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:44:23 | Train | Epoch[551/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:44:23 | Train | Epoch[551/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:44:23 | Train | Epoch[551/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:44:23 | Valid | Epoch[551/600] Iteration[001/008] Valid loss: 0.0498
2023-02-06 11:44:23 | Valid | Epoch[551/600] Iteration[002/008] Valid loss: 0.0377
2023-02-06 11:44:23 | Valid | Epoch[551/600] Iteration[003/008] Valid loss: 0.0342
2023-02-06 11:44:23 | Valid | Epoch[551/600] Iteration[004/008] Valid loss: 0.0326
2023-02-06 11:44:23 | Valid | Epoch[551/600] Iteration[005/008] Valid loss: 0.0335
2023-02-06 11:44:23 | Valid | Epoch[551/600] Iteration[006/008] Valid loss: 0.0334
2023-02-06 11:44:23 | Valid | Epoch[551/600] Iteration[007/008] Valid loss: 0.0335
2023-02-06 11:44:23 | Valid | Epoch[551/600] Iteration[008/008] Valid loss: 0.0327
2023-02-06 11:44:23 | Valid | Epoch[551/600] MIou: 0.9245131330441119
2023-02-06 11:44:23 | Valid | Epoch[551/600] Pixel Accuracy: 0.9874076843261719
2023-02-06 11:44:23 | Valid | Epoch[551/600] Mean Pixel Accuracy: 0.937250874592527
2023-02-06 11:44:23 | Stage | Epoch[551/600] Train loss:0.0201
2023-02-06 11:44:23 | Stage | Epoch[551/600] Valid loss:0.0327
2023-02-06 11:44:23 | Stage | Epoch[551/600] LR:0.0001

2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[001/030] Train loss: 0.0217
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[005/030] Train loss: 0.0208
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[006/030] Train loss: 0.0214
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[007/030] Train loss: 0.0210
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:44:24 | Train | Epoch[552/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:44:25 | Train | Epoch[552/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:44:25 | Valid | Epoch[552/600] Iteration[001/008] Valid loss: 0.0523
2023-02-06 11:44:25 | Valid | Epoch[552/600] Iteration[002/008] Valid loss: 0.0387
2023-02-06 11:44:25 | Valid | Epoch[552/600] Iteration[003/008] Valid loss: 0.0348
2023-02-06 11:44:25 | Valid | Epoch[552/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:44:25 | Valid | Epoch[552/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:44:25 | Valid | Epoch[552/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:44:26 | Valid | Epoch[552/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 11:44:26 | Valid | Epoch[552/600] Iteration[008/008] Valid loss: 0.0337
2023-02-06 11:44:26 | Valid | Epoch[552/600] MIou: 0.927770407430891
2023-02-06 11:44:26 | Valid | Epoch[552/600] Pixel Accuracy: 0.9879277547200521
2023-02-06 11:44:26 | Valid | Epoch[552/600] Mean Pixel Accuracy: 0.9411381152803309
2023-02-06 11:44:26 | Stage | Epoch[552/600] Train loss:0.0201
2023-02-06 11:44:26 | Stage | Epoch[552/600] Valid loss:0.0337
2023-02-06 11:44:26 | Stage | Epoch[552/600] LR:0.0001

2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[001/030] Train loss: 0.0203
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[002/030] Train loss: 0.0225
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[011/030] Train loss: 0.0204
2023-02-06 11:44:26 | Train | Epoch[553/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:44:27 | Train | Epoch[553/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:44:28 | Valid | Epoch[553/600] Iteration[001/008] Valid loss: 0.0510
2023-02-06 11:44:28 | Valid | Epoch[553/600] Iteration[002/008] Valid loss: 0.0382
2023-02-06 11:44:28 | Valid | Epoch[553/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:44:28 | Valid | Epoch[553/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:44:28 | Valid | Epoch[553/600] Iteration[005/008] Valid loss: 0.0340
2023-02-06 11:44:28 | Valid | Epoch[553/600] Iteration[006/008] Valid loss: 0.0340
2023-02-06 11:44:28 | Valid | Epoch[553/600] Iteration[007/008] Valid loss: 0.0340
2023-02-06 11:44:28 | Valid | Epoch[553/600] Iteration[008/008] Valid loss: 0.0332
2023-02-06 11:44:28 | Valid | Epoch[553/600] MIou: 0.9259678091393404
2023-02-06 11:44:28 | Valid | Epoch[553/600] Pixel Accuracy: 0.9876429239908854
2023-02-06 11:44:28 | Valid | Epoch[553/600] Mean Pixel Accuracy: 0.9388701831503214
2023-02-06 11:44:28 | Stage | Epoch[553/600] Train loss:0.0200
2023-02-06 11:44:28 | Stage | Epoch[553/600] Valid loss:0.0332
2023-02-06 11:44:28 | Stage | Epoch[553/600] LR:0.0001

2023-02-06 11:44:28 | Train | Epoch[554/600] Iteration[001/030] Train loss: 0.0169
2023-02-06 11:44:28 | Train | Epoch[554/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 11:44:28 | Train | Epoch[554/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 11:44:28 | Train | Epoch[554/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 11:44:28 | Train | Epoch[554/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:44:28 | Train | Epoch[554/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:44:28 | Train | Epoch[554/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[008/030] Train loss: 0.0195
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:44:29 | Train | Epoch[554/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:44:30 | Train | Epoch[554/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:44:30 | Train | Epoch[554/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:44:30 | Valid | Epoch[554/600] Iteration[001/008] Valid loss: 0.0508
2023-02-06 11:44:30 | Valid | Epoch[554/600] Iteration[002/008] Valid loss: 0.0381
2023-02-06 11:44:30 | Valid | Epoch[554/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:44:30 | Valid | Epoch[554/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 11:44:30 | Valid | Epoch[554/600] Iteration[005/008] Valid loss: 0.0338
2023-02-06 11:44:30 | Valid | Epoch[554/600] Iteration[006/008] Valid loss: 0.0337
2023-02-06 11:44:30 | Valid | Epoch[554/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 11:44:30 | Valid | Epoch[554/600] Iteration[008/008] Valid loss: 0.0330
2023-02-06 11:44:30 | Valid | Epoch[554/600] MIou: 0.9256892597075204
2023-02-06 11:44:30 | Valid | Epoch[554/600] Pixel Accuracy: 0.9875971476236979
2023-02-06 11:44:30 | Valid | Epoch[554/600] Mean Pixel Accuracy: 0.9385850631746051
2023-02-06 11:44:30 | Stage | Epoch[554/600] Train loss:0.0200
2023-02-06 11:44:30 | Stage | Epoch[554/600] Valid loss:0.0330
2023-02-06 11:44:30 | Stage | Epoch[554/600] LR:0.0001

2023-02-06 11:44:30 | Train | Epoch[555/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[002/030] Train loss: 0.0225
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[003/030] Train loss: 0.0212
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:44:31 | Train | Epoch[555/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:44:32 | Train | Epoch[555/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:44:32 | Train | Epoch[555/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:44:32 | Train | Epoch[555/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:44:32 | Train | Epoch[555/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:44:32 | Train | Epoch[555/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:44:32 | Train | Epoch[555/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:44:32 | Train | Epoch[555/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:44:32 | Train | Epoch[555/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:44:32 | Train | Epoch[555/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:44:32 | Valid | Epoch[555/600] Iteration[001/008] Valid loss: 0.0515
2023-02-06 11:44:32 | Valid | Epoch[555/600] Iteration[002/008] Valid loss: 0.0384
2023-02-06 11:44:32 | Valid | Epoch[555/600] Iteration[003/008] Valid loss: 0.0346
2023-02-06 11:44:32 | Valid | Epoch[555/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 11:44:32 | Valid | Epoch[555/600] Iteration[005/008] Valid loss: 0.0341
2023-02-06 11:44:32 | Valid | Epoch[555/600] Iteration[006/008] Valid loss: 0.0340
2023-02-06 11:44:32 | Valid | Epoch[555/600] Iteration[007/008] Valid loss: 0.0342
2023-02-06 11:44:32 | Valid | Epoch[555/600] Iteration[008/008] Valid loss: 0.0333
2023-02-06 11:44:33 | Valid | Epoch[555/600] MIou: 0.9267923070699917
2023-02-06 11:44:33 | Valid | Epoch[555/600] Pixel Accuracy: 0.9877726236979166
2023-02-06 11:44:33 | Valid | Epoch[555/600] Mean Pixel Accuracy: 0.939924244725237
2023-02-06 11:44:33 | Stage | Epoch[555/600] Train loss:0.0201
2023-02-06 11:44:33 | Stage | Epoch[555/600] Valid loss:0.0333
2023-02-06 11:44:33 | Stage | Epoch[555/600] LR:0.0001

2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[002/030] Train loss: 0.0203
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[005/030] Train loss: 0.0209
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[006/030] Train loss: 0.0210
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[009/030] Train loss: 0.0210
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[010/030] Train loss: 0.0210
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[013/030] Train loss: 0.0206
2023-02-06 11:44:33 | Train | Epoch[556/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[016/030] Train loss: 0.0203
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:44:34 | Train | Epoch[556/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:44:35 | Valid | Epoch[556/600] Iteration[001/008] Valid loss: 0.0515
2023-02-06 11:44:35 | Valid | Epoch[556/600] Iteration[002/008] Valid loss: 0.0384
2023-02-06 11:44:35 | Valid | Epoch[556/600] Iteration[003/008] Valid loss: 0.0346
2023-02-06 11:44:35 | Valid | Epoch[556/600] Iteration[004/008] Valid loss: 0.0333
2023-02-06 11:44:35 | Valid | Epoch[556/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 11:44:35 | Valid | Epoch[556/600] Iteration[006/008] Valid loss: 0.0342
2023-02-06 11:44:35 | Valid | Epoch[556/600] Iteration[007/008] Valid loss: 0.0343
2023-02-06 11:44:35 | Valid | Epoch[556/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 11:44:35 | Valid | Epoch[556/600] MIou: 0.9264646949629647
2023-02-06 11:44:35 | Valid | Epoch[556/600] Pixel Accuracy: 0.9877192179361979
2023-02-06 11:44:35 | Valid | Epoch[556/600] Mean Pixel Accuracy: 0.9395715265937795
2023-02-06 11:44:35 | Stage | Epoch[556/600] Train loss:0.0201
2023-02-06 11:44:35 | Stage | Epoch[556/600] Valid loss:0.0334
2023-02-06 11:44:35 | Stage | Epoch[556/600] LR:0.0001

2023-02-06 11:44:35 | Train | Epoch[557/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:44:35 | Train | Epoch[557/600] Iteration[002/030] Train loss: 0.0197
2023-02-06 11:44:35 | Train | Epoch[557/600] Iteration[003/030] Train loss: 0.0191
2023-02-06 11:44:35 | Train | Epoch[557/600] Iteration[004/030] Train loss: 0.0203
2023-02-06 11:44:35 | Train | Epoch[557/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 11:44:35 | Train | Epoch[557/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 11:44:35 | Train | Epoch[557/600] Iteration[007/030] Train loss: 0.0190
2023-02-06 11:44:35 | Train | Epoch[557/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:44:36 | Train | Epoch[557/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:44:37 | Train | Epoch[557/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:44:37 | Valid | Epoch[557/600] Iteration[001/008] Valid loss: 0.0522
2023-02-06 11:44:37 | Valid | Epoch[557/600] Iteration[002/008] Valid loss: 0.0387
2023-02-06 11:44:37 | Valid | Epoch[557/600] Iteration[003/008] Valid loss: 0.0348
2023-02-06 11:44:37 | Valid | Epoch[557/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:44:37 | Valid | Epoch[557/600] Iteration[005/008] Valid loss: 0.0344
2023-02-06 11:44:37 | Valid | Epoch[557/600] Iteration[006/008] Valid loss: 0.0344
2023-02-06 11:44:37 | Valid | Epoch[557/600] Iteration[007/008] Valid loss: 0.0346
2023-02-06 11:44:37 | Valid | Epoch[557/600] Iteration[008/008] Valid loss: 0.0336
2023-02-06 11:44:37 | Valid | Epoch[557/600] MIou: 0.9277269113529585
2023-02-06 11:44:37 | Valid | Epoch[557/600] Pixel Accuracy: 0.9879239400227865
2023-02-06 11:44:37 | Valid | Epoch[557/600] Mean Pixel Accuracy: 0.9409711663007067
2023-02-06 11:44:37 | Stage | Epoch[557/600] Train loss:0.0202
2023-02-06 11:44:37 | Stage | Epoch[557/600] Valid loss:0.0336
2023-02-06 11:44:37 | Stage | Epoch[557/600] LR:0.0001

2023-02-06 11:44:37 | Train | Epoch[558/600] Iteration[001/030] Train loss: 0.0157
2023-02-06 11:44:37 | Train | Epoch[558/600] Iteration[002/030] Train loss: 0.0177
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[004/030] Train loss: 0.0189
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[016/030] Train loss: 0.0204
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:44:38 | Train | Epoch[558/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:44:39 | Train | Epoch[558/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:44:39 | Train | Epoch[558/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:44:39 | Train | Epoch[558/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:44:39 | Train | Epoch[558/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:44:39 | Train | Epoch[558/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:44:39 | Train | Epoch[558/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:44:39 | Train | Epoch[558/600] Iteration[029/030] Train loss: 0.0203
2023-02-06 11:44:39 | Train | Epoch[558/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:44:39 | Valid | Epoch[558/600] Iteration[001/008] Valid loss: 0.0509
2023-02-06 11:44:39 | Valid | Epoch[558/600] Iteration[002/008] Valid loss: 0.0382
2023-02-06 11:44:39 | Valid | Epoch[558/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:44:39 | Valid | Epoch[558/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 11:44:39 | Valid | Epoch[558/600] Iteration[005/008] Valid loss: 0.0339
2023-02-06 11:44:39 | Valid | Epoch[558/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 11:44:39 | Valid | Epoch[558/600] Iteration[007/008] Valid loss: 0.0340
2023-02-06 11:44:39 | Valid | Epoch[558/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:44:39 | Valid | Epoch[558/600] MIou: 0.9259438401874308
2023-02-06 11:44:39 | Valid | Epoch[558/600] Pixel Accuracy: 0.9876378377278646
2023-02-06 11:44:39 | Valid | Epoch[558/600] Mean Pixel Accuracy: 0.9388864089377775
2023-02-06 11:44:39 | Stage | Epoch[558/600] Train loss:0.0202
2023-02-06 11:44:39 | Stage | Epoch[558/600] Valid loss:0.0331
2023-02-06 11:44:39 | Stage | Epoch[558/600] LR:0.0001

2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[001/030] Train loss: 0.0183
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[002/030] Train loss: 0.0179
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[004/030] Train loss: 0.0199
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[006/030] Train loss: 0.0191
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[008/030] Train loss: 0.0192
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[010/030] Train loss: 0.0191
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[011/030] Train loss: 0.0193
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 11:44:40 | Train | Epoch[559/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[018/030] Train loss: 0.0194
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[019/030] Train loss: 0.0194
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[022/030] Train loss: 0.0195
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[024/030] Train loss: 0.0196
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:44:41 | Train | Epoch[559/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:44:41 | Valid | Epoch[559/600] Iteration[001/008] Valid loss: 0.0518
2023-02-06 11:44:42 | Valid | Epoch[559/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:44:42 | Valid | Epoch[559/600] Iteration[003/008] Valid loss: 0.0348
2023-02-06 11:44:42 | Valid | Epoch[559/600] Iteration[004/008] Valid loss: 0.0333
2023-02-06 11:44:42 | Valid | Epoch[559/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 11:44:42 | Valid | Epoch[559/600] Iteration[006/008] Valid loss: 0.0341
2023-02-06 11:44:42 | Valid | Epoch[559/600] Iteration[007/008] Valid loss: 0.0343
2023-02-06 11:44:42 | Valid | Epoch[559/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 11:44:42 | Valid | Epoch[559/600] MIou: 0.9263584902896327
2023-02-06 11:44:42 | Valid | Epoch[559/600] Pixel Accuracy: 0.9877026875813802
2023-02-06 11:44:42 | Valid | Epoch[559/600] Mean Pixel Accuracy: 0.9394292909040155
2023-02-06 11:44:42 | Stage | Epoch[559/600] Train loss:0.0199
2023-02-06 11:44:42 | Stage | Epoch[559/600] Valid loss:0.0334
2023-02-06 11:44:42 | Stage | Epoch[559/600] LR:0.0001

2023-02-06 11:44:42 | Train | Epoch[560/600] Iteration[001/030] Train loss: 0.0188
2023-02-06 11:44:42 | Train | Epoch[560/600] Iteration[002/030] Train loss: 0.0185
2023-02-06 11:44:42 | Train | Epoch[560/600] Iteration[003/030] Train loss: 0.0179
2023-02-06 11:44:42 | Train | Epoch[560/600] Iteration[004/030] Train loss: 0.0180
2023-02-06 11:44:42 | Train | Epoch[560/600] Iteration[005/030] Train loss: 0.0181
2023-02-06 11:44:42 | Train | Epoch[560/600] Iteration[006/030] Train loss: 0.0181
2023-02-06 11:44:42 | Train | Epoch[560/600] Iteration[007/030] Train loss: 0.0184
2023-02-06 11:44:42 | Train | Epoch[560/600] Iteration[008/030] Train loss: 0.0183
2023-02-06 11:44:42 | Train | Epoch[560/600] Iteration[009/030] Train loss: 0.0184
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[010/030] Train loss: 0.0186
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[011/030] Train loss: 0.0190
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[012/030] Train loss: 0.0190
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[013/030] Train loss: 0.0191
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[014/030] Train loss: 0.0194
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[015/030] Train loss: 0.0193
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[017/030] Train loss: 0.0193
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[018/030] Train loss: 0.0194
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[019/030] Train loss: 0.0194
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[020/030] Train loss: 0.0194
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[021/030] Train loss: 0.0193
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[022/030] Train loss: 0.0195
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[023/030] Train loss: 0.0195
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[024/030] Train loss: 0.0196
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[025/030] Train loss: 0.0195
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[026/030] Train loss: 0.0195
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[027/030] Train loss: 0.0195
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[028/030] Train loss: 0.0195
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[029/030] Train loss: 0.0196
2023-02-06 11:44:43 | Train | Epoch[560/600] Iteration[030/030] Train loss: 0.0196
2023-02-06 11:44:44 | Valid | Epoch[560/600] Iteration[001/008] Valid loss: 0.0508
2023-02-06 11:44:44 | Valid | Epoch[560/600] Iteration[002/008] Valid loss: 0.0381
2023-02-06 11:44:44 | Valid | Epoch[560/600] Iteration[003/008] Valid loss: 0.0344
2023-02-06 11:44:44 | Valid | Epoch[560/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:44:44 | Valid | Epoch[560/600] Iteration[005/008] Valid loss: 0.0339
2023-02-06 11:44:44 | Valid | Epoch[560/600] Iteration[006/008] Valid loss: 0.0339
2023-02-06 11:44:44 | Valid | Epoch[560/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 11:44:44 | Valid | Epoch[560/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:44:44 | Valid | Epoch[560/600] MIou: 0.9253449856825042
2023-02-06 11:44:44 | Valid | Epoch[560/600] Pixel Accuracy: 0.9875399271647135
2023-02-06 11:44:44 | Valid | Epoch[560/600] Mean Pixel Accuracy: 0.9382556102088859
2023-02-06 11:44:44 | Stage | Epoch[560/600] Train loss:0.0196
2023-02-06 11:44:44 | Stage | Epoch[560/600] Valid loss:0.0331
2023-02-06 11:44:44 | Stage | Epoch[560/600] LR:0.0001

2023-02-06 11:44:44 | Train | Epoch[561/600] Iteration[001/030] Train loss: 0.0199
2023-02-06 11:44:44 | Train | Epoch[561/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 11:44:44 | Train | Epoch[561/600] Iteration[003/030] Train loss: 0.0196
2023-02-06 11:44:44 | Train | Epoch[561/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 11:44:44 | Train | Epoch[561/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[016/030] Train loss: 0.0204
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:44:45 | Train | Epoch[561/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:44:46 | Train | Epoch[561/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:44:46 | Train | Epoch[561/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:44:46 | Train | Epoch[561/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:44:46 | Train | Epoch[561/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:44:46 | Valid | Epoch[561/600] Iteration[001/008] Valid loss: 0.0531
2023-02-06 11:44:46 | Valid | Epoch[561/600] Iteration[002/008] Valid loss: 0.0391
2023-02-06 11:44:46 | Valid | Epoch[561/600] Iteration[003/008] Valid loss: 0.0351
2023-02-06 11:44:46 | Valid | Epoch[561/600] Iteration[004/008] Valid loss: 0.0338
2023-02-06 11:44:46 | Valid | Epoch[561/600] Iteration[005/008] Valid loss: 0.0347
2023-02-06 11:44:46 | Valid | Epoch[561/600] Iteration[006/008] Valid loss: 0.0347
2023-02-06 11:44:46 | Valid | Epoch[561/600] Iteration[007/008] Valid loss: 0.0349
2023-02-06 11:44:46 | Valid | Epoch[561/600] Iteration[008/008] Valid loss: 0.0340
2023-02-06 11:44:46 | Valid | Epoch[561/600] MIou: 0.9282808312093772
2023-02-06 11:44:46 | Valid | Epoch[561/600] Pixel Accuracy: 0.988006591796875
2023-02-06 11:44:46 | Valid | Epoch[561/600] Mean Pixel Accuracy: 0.9418535374803532
2023-02-06 11:44:46 | Stage | Epoch[561/600] Train loss:0.0200
2023-02-06 11:44:46 | Stage | Epoch[561/600] Valid loss:0.0340
2023-02-06 11:44:46 | Stage | Epoch[561/600] LR:0.0001

2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[001/030] Train loss: 0.0235
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[002/030] Train loss: 0.0220
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[004/030] Train loss: 0.0211
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[005/030] Train loss: 0.0213
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[008/030] Train loss: 0.0206
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[010/030] Train loss: 0.0199
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[015/030] Train loss: 0.0202
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:44:47 | Train | Epoch[562/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:44:48 | Train | Epoch[562/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:44:48 | Train | Epoch[562/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:44:48 | Train | Epoch[562/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:44:48 | Train | Epoch[562/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:44:48 | Train | Epoch[562/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:44:48 | Train | Epoch[562/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:44:48 | Train | Epoch[562/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:44:48 | Train | Epoch[562/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:44:48 | Train | Epoch[562/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:44:48 | Train | Epoch[562/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:44:48 | Valid | Epoch[562/600] Iteration[001/008] Valid loss: 0.0551
2023-02-06 11:44:48 | Valid | Epoch[562/600] Iteration[002/008] Valid loss: 0.0401
2023-02-06 11:44:48 | Valid | Epoch[562/600] Iteration[003/008] Valid loss: 0.0358
2023-02-06 11:44:48 | Valid | Epoch[562/600] Iteration[004/008] Valid loss: 0.0345
2023-02-06 11:44:48 | Valid | Epoch[562/600] Iteration[005/008] Valid loss: 0.0356
2023-02-06 11:44:48 | Valid | Epoch[562/600] Iteration[006/008] Valid loss: 0.0356
2023-02-06 11:44:48 | Valid | Epoch[562/600] Iteration[007/008] Valid loss: 0.0360
2023-02-06 11:44:48 | Valid | Epoch[562/600] Iteration[008/008] Valid loss: 0.0349
2023-02-06 11:44:49 | Valid | Epoch[562/600] MIou: 0.9303786035374274
2023-02-06 11:44:49 | Valid | Epoch[562/600] Pixel Accuracy: 0.98834228515625
2023-02-06 11:44:49 | Valid | Epoch[562/600] Mean Pixel Accuracy: 0.9443903637986227
2023-02-06 11:44:49 | Stage | Epoch[562/600] Train loss:0.0201
2023-02-06 11:44:49 | Stage | Epoch[562/600] Valid loss:0.0349
2023-02-06 11:44:49 | Stage | Epoch[562/600] LR:0.0001

2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[002/030] Train loss: 0.0197
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[003/030] Train loss: 0.0199
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[007/030] Train loss: 0.0197
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[010/030] Train loss: 0.0199
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:44:49 | Train | Epoch[563/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:44:50 | Train | Epoch[563/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:44:50 | Valid | Epoch[563/600] Iteration[001/008] Valid loss: 0.0562
2023-02-06 11:44:51 | Valid | Epoch[563/600] Iteration[002/008] Valid loss: 0.0407
2023-02-06 11:44:51 | Valid | Epoch[563/600] Iteration[003/008] Valid loss: 0.0361
2023-02-06 11:44:51 | Valid | Epoch[563/600] Iteration[004/008] Valid loss: 0.0348
2023-02-06 11:44:51 | Valid | Epoch[563/600] Iteration[005/008] Valid loss: 0.0358
2023-02-06 11:44:51 | Valid | Epoch[563/600] Iteration[006/008] Valid loss: 0.0357
2023-02-06 11:44:51 | Valid | Epoch[563/600] Iteration[007/008] Valid loss: 0.0361
2023-02-06 11:44:51 | Valid | Epoch[563/600] Iteration[008/008] Valid loss: 0.0350
2023-02-06 11:44:51 | Valid | Epoch[563/600] MIou: 0.9303873701546375
2023-02-06 11:44:51 | Valid | Epoch[563/600] Pixel Accuracy: 0.988335927327474
2023-02-06 11:44:51 | Valid | Epoch[563/600] Mean Pixel Accuracy: 0.9446975523688645
2023-02-06 11:44:51 | Stage | Epoch[563/600] Train loss:0.0202
2023-02-06 11:44:51 | Stage | Epoch[563/600] Valid loss:0.0350
2023-02-06 11:44:51 | Stage | Epoch[563/600] LR:0.0001

2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[002/030] Train loss: 0.0185
2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[004/030] Train loss: 0.0188
2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[007/030] Train loss: 0.0185
2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[008/030] Train loss: 0.0188
2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[009/030] Train loss: 0.0187
2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[010/030] Train loss: 0.0188
2023-02-06 11:44:51 | Train | Epoch[564/600] Iteration[011/030] Train loss: 0.0190
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[012/030] Train loss: 0.0190
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[015/030] Train loss: 0.0194
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[020/030] Train loss: 0.0196
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:44:52 | Train | Epoch[564/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:44:53 | Valid | Epoch[564/600] Iteration[001/008] Valid loss: 0.0560
2023-02-06 11:44:53 | Valid | Epoch[564/600] Iteration[002/008] Valid loss: 0.0407
2023-02-06 11:44:53 | Valid | Epoch[564/600] Iteration[003/008] Valid loss: 0.0361
2023-02-06 11:44:53 | Valid | Epoch[564/600] Iteration[004/008] Valid loss: 0.0348
2023-02-06 11:44:53 | Valid | Epoch[564/600] Iteration[005/008] Valid loss: 0.0359
2023-02-06 11:44:53 | Valid | Epoch[564/600] Iteration[006/008] Valid loss: 0.0358
2023-02-06 11:44:53 | Valid | Epoch[564/600] Iteration[007/008] Valid loss: 0.0363
2023-02-06 11:44:53 | Valid | Epoch[564/600] Iteration[008/008] Valid loss: 0.0352
2023-02-06 11:44:53 | Valid | Epoch[564/600] MIou: 0.9310360876367367
2023-02-06 11:44:53 | Valid | Epoch[564/600] Pixel Accuracy: 0.9884427388509115
2023-02-06 11:44:53 | Valid | Epoch[564/600] Mean Pixel Accuracy: 0.9453776267457309
2023-02-06 11:44:53 | Stage | Epoch[564/600] Train loss:0.0199
2023-02-06 11:44:53 | Stage | Epoch[564/600] Valid loss:0.0352
2023-02-06 11:44:53 | Stage | Epoch[564/600] LR:0.0001

2023-02-06 11:44:53 | Train | Epoch[565/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 11:44:53 | Train | Epoch[565/600] Iteration[002/030] Train loss: 0.0233
2023-02-06 11:44:53 | Train | Epoch[565/600] Iteration[003/030] Train loss: 0.0223
2023-02-06 11:44:53 | Train | Epoch[565/600] Iteration[004/030] Train loss: 0.0214
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[005/030] Train loss: 0.0213
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[008/030] Train loss: 0.0208
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[009/030] Train loss: 0.0208
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[010/030] Train loss: 0.0213
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[011/030] Train loss: 0.0211
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[012/030] Train loss: 0.0209
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[013/030] Train loss: 0.0209
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[015/030] Train loss: 0.0206
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:44:54 | Train | Epoch[565/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:44:55 | Train | Epoch[565/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:44:55 | Train | Epoch[565/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:44:55 | Train | Epoch[565/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:44:55 | Train | Epoch[565/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:44:55 | Train | Epoch[565/600] Iteration[030/030] Train loss: 0.0204
2023-02-06 11:44:55 | Valid | Epoch[565/600] Iteration[001/008] Valid loss: 0.0532
2023-02-06 11:44:55 | Valid | Epoch[565/600] Iteration[002/008] Valid loss: 0.0392
2023-02-06 11:44:55 | Valid | Epoch[565/600] Iteration[003/008] Valid loss: 0.0351
2023-02-06 11:44:55 | Valid | Epoch[565/600] Iteration[004/008] Valid loss: 0.0338
2023-02-06 11:44:55 | Valid | Epoch[565/600] Iteration[005/008] Valid loss: 0.0347
2023-02-06 11:44:55 | Valid | Epoch[565/600] Iteration[006/008] Valid loss: 0.0347
2023-02-06 11:44:55 | Valid | Epoch[565/600] Iteration[007/008] Valid loss: 0.0349
2023-02-06 11:44:55 | Valid | Epoch[565/600] Iteration[008/008] Valid loss: 0.0339
2023-02-06 11:44:55 | Valid | Epoch[565/600] MIou: 0.9282812865218366
2023-02-06 11:44:55 | Valid | Epoch[565/600] Pixel Accuracy: 0.9880078633626302
2023-02-06 11:44:55 | Valid | Epoch[565/600] Mean Pixel Accuracy: 0.9418098530865386
2023-02-06 11:44:55 | Stage | Epoch[565/600] Train loss:0.0204
2023-02-06 11:44:55 | Stage | Epoch[565/600] Valid loss:0.0339
2023-02-06 11:44:55 | Stage | Epoch[565/600] LR:0.0001

2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[002/030] Train loss: 0.0182
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[004/030] Train loss: 0.0191
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[008/030] Train loss: 0.0194
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[014/030] Train loss: 0.0196
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:44:56 | Train | Epoch[566/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:44:57 | Train | Epoch[566/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:44:57 | Valid | Epoch[566/600] Iteration[001/008] Valid loss: 0.0505
2023-02-06 11:44:57 | Valid | Epoch[566/600] Iteration[002/008] Valid loss: 0.0380
2023-02-06 11:44:58 | Valid | Epoch[566/600] Iteration[003/008] Valid loss: 0.0343
2023-02-06 11:44:58 | Valid | Epoch[566/600] Iteration[004/008] Valid loss: 0.0328
2023-02-06 11:44:58 | Valid | Epoch[566/600] Iteration[005/008] Valid loss: 0.0338
2023-02-06 11:44:58 | Valid | Epoch[566/600] Iteration[006/008] Valid loss: 0.0337
2023-02-06 11:44:58 | Valid | Epoch[566/600] Iteration[007/008] Valid loss: 0.0337
2023-02-06 11:44:58 | Valid | Epoch[566/600] Iteration[008/008] Valid loss: 0.0329
2023-02-06 11:44:58 | Valid | Epoch[566/600] MIou: 0.9249361947613199
2023-02-06 11:44:58 | Valid | Epoch[566/600] Pixel Accuracy: 0.9874738057454427
2023-02-06 11:44:58 | Valid | Epoch[566/600] Mean Pixel Accuracy: 0.9378007959370471
2023-02-06 11:44:58 | Stage | Epoch[566/600] Train loss:0.0200
2023-02-06 11:44:58 | Stage | Epoch[566/600] Valid loss:0.0329
2023-02-06 11:44:58 | Stage | Epoch[566/600] LR:0.0001

2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[002/030] Train loss: 0.0176
2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[003/030] Train loss: 0.0180
2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[005/030] Train loss: 0.0184
2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[006/030] Train loss: 0.0188
2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[007/030] Train loss: 0.0193
2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[009/030] Train loss: 0.0203
2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:44:58 | Train | Epoch[567/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:44:59 | Train | Epoch[567/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:45:00 | Valid | Epoch[567/600] Iteration[001/008] Valid loss: 0.0532
2023-02-06 11:45:00 | Valid | Epoch[567/600] Iteration[002/008] Valid loss: 0.0392
2023-02-06 11:45:00 | Valid | Epoch[567/600] Iteration[003/008] Valid loss: 0.0351
2023-02-06 11:45:00 | Valid | Epoch[567/600] Iteration[004/008] Valid loss: 0.0337
2023-02-06 11:45:00 | Valid | Epoch[567/600] Iteration[005/008] Valid loss: 0.0347
2023-02-06 11:45:00 | Valid | Epoch[567/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 11:45:00 | Valid | Epoch[567/600] Iteration[007/008] Valid loss: 0.0349
2023-02-06 11:45:00 | Valid | Epoch[567/600] Iteration[008/008] Valid loss: 0.0339
2023-02-06 11:45:00 | Valid | Epoch[567/600] MIou: 0.9283970446713907
2023-02-06 11:45:00 | Valid | Epoch[567/600] Pixel Accuracy: 0.9880294799804688
2023-02-06 11:45:00 | Valid | Epoch[567/600] Mean Pixel Accuracy: 0.9418344154446533
2023-02-06 11:45:00 | Stage | Epoch[567/600] Train loss:0.0199
2023-02-06 11:45:00 | Stage | Epoch[567/600] Valid loss:0.0339
2023-02-06 11:45:00 | Stage | Epoch[567/600] LR:0.0001

2023-02-06 11:45:00 | Train | Epoch[568/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:45:00 | Train | Epoch[568/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 11:45:00 | Train | Epoch[568/600] Iteration[003/030] Train loss: 0.0201
2023-02-06 11:45:00 | Train | Epoch[568/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:45:00 | Train | Epoch[568/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 11:45:00 | Train | Epoch[568/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[012/030] Train loss: 0.0196
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[013/030] Train loss: 0.0194
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[014/030] Train loss: 0.0195
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:45:01 | Train | Epoch[568/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:45:02 | Train | Epoch[568/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:45:02 | Train | Epoch[568/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 11:45:02 | Train | Epoch[568/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:45:02 | Train | Epoch[568/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:45:02 | Valid | Epoch[568/600] Iteration[001/008] Valid loss: 0.0528
2023-02-06 11:45:02 | Valid | Epoch[568/600] Iteration[002/008] Valid loss: 0.0390
2023-02-06 11:45:02 | Valid | Epoch[568/600] Iteration[003/008] Valid loss: 0.0350
2023-02-06 11:45:02 | Valid | Epoch[568/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:45:02 | Valid | Epoch[568/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:45:02 | Valid | Epoch[568/600] Iteration[006/008] Valid loss: 0.0344
2023-02-06 11:45:02 | Valid | Epoch[568/600] Iteration[007/008] Valid loss: 0.0346
2023-02-06 11:45:02 | Valid | Epoch[568/600] Iteration[008/008] Valid loss: 0.0337
2023-02-06 11:45:02 | Valid | Epoch[568/600] MIou: 0.9279180175806534
2023-02-06 11:45:02 | Valid | Epoch[568/600] Pixel Accuracy: 0.9879480997721354
2023-02-06 11:45:02 | Valid | Epoch[568/600] Mean Pixel Accuracy: 0.9414346190066949
2023-02-06 11:45:02 | Stage | Epoch[568/600] Train loss:0.0198
2023-02-06 11:45:02 | Stage | Epoch[568/600] Valid loss:0.0337
2023-02-06 11:45:02 | Stage | Epoch[568/600] LR:0.0001

2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[001/030] Train loss: 0.0210
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[002/030] Train loss: 0.0199
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[004/030] Train loss: 0.0195
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[005/030] Train loss: 0.0204
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[006/030] Train loss: 0.0203
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[013/030] Train loss: 0.0199
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[017/030] Train loss: 0.0198
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[019/030] Train loss: 0.0197
2023-02-06 11:45:03 | Train | Epoch[569/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:45:04 | Train | Epoch[569/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:45:04 | Train | Epoch[569/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:45:04 | Train | Epoch[569/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:45:04 | Train | Epoch[569/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:45:04 | Train | Epoch[569/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:45:04 | Train | Epoch[569/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:45:04 | Train | Epoch[569/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:45:04 | Train | Epoch[569/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:45:04 | Train | Epoch[569/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:45:04 | Train | Epoch[569/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:45:04 | Valid | Epoch[569/600] Iteration[001/008] Valid loss: 0.0518
2023-02-06 11:45:04 | Valid | Epoch[569/600] Iteration[002/008] Valid loss: 0.0385
2023-02-06 11:45:04 | Valid | Epoch[569/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:45:04 | Valid | Epoch[569/600] Iteration[004/008] Valid loss: 0.0331
2023-02-06 11:45:04 | Valid | Epoch[569/600] Iteration[005/008] Valid loss: 0.0341
2023-02-06 11:45:04 | Valid | Epoch[569/600] Iteration[006/008] Valid loss: 0.0341
2023-02-06 11:45:04 | Valid | Epoch[569/600] Iteration[007/008] Valid loss: 0.0343
2023-02-06 11:45:04 | Valid | Epoch[569/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 11:45:05 | Valid | Epoch[569/600] MIou: 0.9275015905459372
2023-02-06 11:45:05 | Valid | Epoch[569/600] Pixel Accuracy: 0.9878857930501302
2023-02-06 11:45:05 | Valid | Epoch[569/600] Mean Pixel Accuracy: 0.9407790063667796
2023-02-06 11:45:05 | Stage | Epoch[569/600] Train loss:0.0198
2023-02-06 11:45:05 | Stage | Epoch[569/600] Valid loss:0.0334
2023-02-06 11:45:05 | Stage | Epoch[569/600] LR:0.0001

2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[001/030] Train loss: 0.0194
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[002/030] Train loss: 0.0189
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[003/030] Train loss: 0.0188
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[006/030] Train loss: 0.0196
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[007/030] Train loss: 0.0196
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[014/030] Train loss: 0.0197
2023-02-06 11:45:05 | Train | Epoch[570/600] Iteration[015/030] Train loss: 0.0197
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[017/030] Train loss: 0.0197
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:45:06 | Train | Epoch[570/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:45:07 | Valid | Epoch[570/600] Iteration[001/008] Valid loss: 0.0548
2023-02-06 11:45:07 | Valid | Epoch[570/600] Iteration[002/008] Valid loss: 0.0400
2023-02-06 11:45:07 | Valid | Epoch[570/600] Iteration[003/008] Valid loss: 0.0357
2023-02-06 11:45:07 | Valid | Epoch[570/600] Iteration[004/008] Valid loss: 0.0343
2023-02-06 11:45:07 | Valid | Epoch[570/600] Iteration[005/008] Valid loss: 0.0353
2023-02-06 11:45:07 | Valid | Epoch[570/600] Iteration[006/008] Valid loss: 0.0353
2023-02-06 11:45:07 | Valid | Epoch[570/600] Iteration[007/008] Valid loss: 0.0356
2023-02-06 11:45:07 | Valid | Epoch[570/600] Iteration[008/008] Valid loss: 0.0345
2023-02-06 11:45:07 | Valid | Epoch[570/600] MIou: 0.9297143861297094
2023-02-06 11:45:07 | Valid | Epoch[570/600] Pixel Accuracy: 0.9882354736328125
2023-02-06 11:45:07 | Valid | Epoch[570/600] Mean Pixel Accuracy: 0.943602501406051
2023-02-06 11:45:07 | Stage | Epoch[570/600] Train loss:0.0201
2023-02-06 11:45:07 | Stage | Epoch[570/600] Valid loss:0.0345
2023-02-06 11:45:07 | Stage | Epoch[570/600] LR:0.0001

2023-02-06 11:45:07 | Train | Epoch[571/600] Iteration[001/030] Train loss: 0.0180
2023-02-06 11:45:07 | Train | Epoch[571/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 11:45:07 | Train | Epoch[571/600] Iteration[003/030] Train loss: 0.0195
2023-02-06 11:45:07 | Train | Epoch[571/600] Iteration[004/030] Train loss: 0.0198
2023-02-06 11:45:07 | Train | Epoch[571/600] Iteration[005/030] Train loss: 0.0195
2023-02-06 11:45:07 | Train | Epoch[571/600] Iteration[006/030] Train loss: 0.0194
2023-02-06 11:45:07 | Train | Epoch[571/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:45:07 | Train | Epoch[571/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:45:07 | Train | Epoch[571/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:45:08 | Train | Epoch[571/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:45:09 | Valid | Epoch[571/600] Iteration[001/008] Valid loss: 0.0501
2023-02-06 11:45:09 | Valid | Epoch[571/600] Iteration[002/008] Valid loss: 0.0378
2023-02-06 11:45:09 | Valid | Epoch[571/600] Iteration[003/008] Valid loss: 0.0342
2023-02-06 11:45:09 | Valid | Epoch[571/600] Iteration[004/008] Valid loss: 0.0328
2023-02-06 11:45:09 | Valid | Epoch[571/600] Iteration[005/008] Valid loss: 0.0336
2023-02-06 11:45:09 | Valid | Epoch[571/600] Iteration[006/008] Valid loss: 0.0336
2023-02-06 11:45:09 | Valid | Epoch[571/600] Iteration[007/008] Valid loss: 0.0336
2023-02-06 11:45:09 | Valid | Epoch[571/600] Iteration[008/008] Valid loss: 0.0328
2023-02-06 11:45:09 | Valid | Epoch[571/600] MIou: 0.9247482032818801
2023-02-06 11:45:09 | Valid | Epoch[571/600] Pixel Accuracy: 0.9874471028645834
2023-02-06 11:45:09 | Valid | Epoch[571/600] Mean Pixel Accuracy: 0.9374627548477604
2023-02-06 11:45:09 | Stage | Epoch[571/600] Train loss:0.0200
2023-02-06 11:45:09 | Stage | Epoch[571/600] Valid loss:0.0328
2023-02-06 11:45:09 | Stage | Epoch[571/600] LR:0.0001

2023-02-06 11:45:09 | Train | Epoch[572/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 11:45:09 | Train | Epoch[572/600] Iteration[002/030] Train loss: 0.0224
2023-02-06 11:45:09 | Train | Epoch[572/600] Iteration[003/030] Train loss: 0.0217
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[004/030] Train loss: 0.0221
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[005/030] Train loss: 0.0215
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[006/030] Train loss: 0.0219
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[007/030] Train loss: 0.0219
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[008/030] Train loss: 0.0219
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[009/030] Train loss: 0.0214
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[010/030] Train loss: 0.0211
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[011/030] Train loss: 0.0212
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[012/030] Train loss: 0.0211
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[014/030] Train loss: 0.0207
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[015/030] Train loss: 0.0206
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[016/030] Train loss: 0.0207
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[017/030] Train loss: 0.0207
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[018/030] Train loss: 0.0205
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[019/030] Train loss: 0.0205
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[020/030] Train loss: 0.0206
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:45:10 | Train | Epoch[572/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:45:11 | Train | Epoch[572/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:45:11 | Train | Epoch[572/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:45:11 | Train | Epoch[572/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:45:11 | Train | Epoch[572/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:45:11 | Train | Epoch[572/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:45:11 | Train | Epoch[572/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:45:11 | Valid | Epoch[572/600] Iteration[001/008] Valid loss: 0.0509
2023-02-06 11:45:11 | Valid | Epoch[572/600] Iteration[002/008] Valid loss: 0.0381
2023-02-06 11:45:11 | Valid | Epoch[572/600] Iteration[003/008] Valid loss: 0.0344
2023-02-06 11:45:11 | Valid | Epoch[572/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:45:11 | Valid | Epoch[572/600] Iteration[005/008] Valid loss: 0.0338
2023-02-06 11:45:11 | Valid | Epoch[572/600] Iteration[006/008] Valid loss: 0.0337
2023-02-06 11:45:11 | Valid | Epoch[572/600] Iteration[007/008] Valid loss: 0.0337
2023-02-06 11:45:11 | Valid | Epoch[572/600] Iteration[008/008] Valid loss: 0.0329
2023-02-06 11:45:11 | Valid | Epoch[572/600] MIou: 0.9255378271195818
2023-02-06 11:45:11 | Valid | Epoch[572/600] Pixel Accuracy: 0.9875704447428385
2023-02-06 11:45:11 | Valid | Epoch[572/600] Mean Pixel Accuracy: 0.9384943004742894
2023-02-06 11:45:11 | Stage | Epoch[572/600] Train loss:0.0201
2023-02-06 11:45:11 | Stage | Epoch[572/600] Valid loss:0.0329
2023-02-06 11:45:11 | Stage | Epoch[572/600] LR:0.0001

2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[001/030] Train loss: 0.0201
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[002/030] Train loss: 0.0218
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[004/030] Train loss: 0.0215
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[005/030] Train loss: 0.0209
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[008/030] Train loss: 0.0205
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:45:12 | Train | Epoch[573/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:45:13 | Train | Epoch[573/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:45:13 | Valid | Epoch[573/600] Iteration[001/008] Valid loss: 0.0542
2023-02-06 11:45:13 | Valid | Epoch[573/600] Iteration[002/008] Valid loss: 0.0397
2023-02-06 11:45:14 | Valid | Epoch[573/600] Iteration[003/008] Valid loss: 0.0355
2023-02-06 11:45:14 | Valid | Epoch[573/600] Iteration[004/008] Valid loss: 0.0341
2023-02-06 11:45:14 | Valid | Epoch[573/600] Iteration[005/008] Valid loss: 0.0352
2023-02-06 11:45:14 | Valid | Epoch[573/600] Iteration[006/008] Valid loss: 0.0352
2023-02-06 11:45:14 | Valid | Epoch[573/600] Iteration[007/008] Valid loss: 0.0355
2023-02-06 11:45:14 | Valid | Epoch[573/600] Iteration[008/008] Valid loss: 0.0344
2023-02-06 11:45:14 | Valid | Epoch[573/600] MIou: 0.9294470190917239
2023-02-06 11:45:14 | Valid | Epoch[573/600] Pixel Accuracy: 0.9881947835286459
2023-02-06 11:45:14 | Valid | Epoch[573/600] Mean Pixel Accuracy: 0.9431997080986853
2023-02-06 11:45:14 | Stage | Epoch[573/600] Train loss:0.0199
2023-02-06 11:45:14 | Stage | Epoch[573/600] Valid loss:0.0344
2023-02-06 11:45:14 | Stage | Epoch[573/600] LR:0.0001

2023-02-06 11:45:14 | Train | Epoch[574/600] Iteration[001/030] Train loss: 0.0200
2023-02-06 11:45:14 | Train | Epoch[574/600] Iteration[002/030] Train loss: 0.0207
2023-02-06 11:45:14 | Train | Epoch[574/600] Iteration[003/030] Train loss: 0.0207
2023-02-06 11:45:14 | Train | Epoch[574/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:45:14 | Train | Epoch[574/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 11:45:14 | Train | Epoch[574/600] Iteration[006/030] Train loss: 0.0206
2023-02-06 11:45:14 | Train | Epoch[574/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:45:14 | Train | Epoch[574/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:45:14 | Train | Epoch[574/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:45:14 | Train | Epoch[574/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[013/030] Train loss: 0.0206
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[027/030] Train loss: 0.0197
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:45:15 | Train | Epoch[574/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:45:16 | Valid | Epoch[574/600] Iteration[001/008] Valid loss: 0.0550
2023-02-06 11:45:16 | Valid | Epoch[574/600] Iteration[002/008] Valid loss: 0.0401
2023-02-06 11:45:16 | Valid | Epoch[574/600] Iteration[003/008] Valid loss: 0.0357
2023-02-06 11:45:16 | Valid | Epoch[574/600] Iteration[004/008] Valid loss: 0.0344
2023-02-06 11:45:16 | Valid | Epoch[574/600] Iteration[005/008] Valid loss: 0.0355
2023-02-06 11:45:16 | Valid | Epoch[574/600] Iteration[006/008] Valid loss: 0.0354
2023-02-06 11:45:16 | Valid | Epoch[574/600] Iteration[007/008] Valid loss: 0.0358
2023-02-06 11:45:16 | Valid | Epoch[574/600] Iteration[008/008] Valid loss: 0.0347
2023-02-06 11:45:16 | Valid | Epoch[574/600] MIou: 0.9303567130994442
2023-02-06 11:45:16 | Valid | Epoch[574/600] Pixel Accuracy: 0.9883384704589844
2023-02-06 11:45:16 | Valid | Epoch[574/600] Mean Pixel Accuracy: 0.9443755861352885
2023-02-06 11:45:16 | Stage | Epoch[574/600] Train loss:0.0199
2023-02-06 11:45:16 | Stage | Epoch[574/600] Valid loss:0.0347
2023-02-06 11:45:16 | Stage | Epoch[574/600] LR:0.0001

2023-02-06 11:45:16 | Train | Epoch[575/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 11:45:16 | Train | Epoch[575/600] Iteration[002/030] Train loss: 0.0209
2023-02-06 11:45:16 | Train | Epoch[575/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:45:16 | Train | Epoch[575/600] Iteration[004/030] Train loss: 0.0215
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[005/030] Train loss: 0.0209
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[006/030] Train loss: 0.0209
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[007/030] Train loss: 0.0207
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[014/030] Train loss: 0.0204
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[015/030] Train loss: 0.0204
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:45:17 | Train | Epoch[575/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:45:18 | Train | Epoch[575/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:45:18 | Train | Epoch[575/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:45:18 | Train | Epoch[575/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:45:18 | Train | Epoch[575/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:45:18 | Train | Epoch[575/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:45:18 | Valid | Epoch[575/600] Iteration[001/008] Valid loss: 0.0546
2023-02-06 11:45:18 | Valid | Epoch[575/600] Iteration[002/008] Valid loss: 0.0399
2023-02-06 11:45:18 | Valid | Epoch[575/600] Iteration[003/008] Valid loss: 0.0356
2023-02-06 11:45:18 | Valid | Epoch[575/600] Iteration[004/008] Valid loss: 0.0344
2023-02-06 11:45:18 | Valid | Epoch[575/600] Iteration[005/008] Valid loss: 0.0354
2023-02-06 11:45:18 | Valid | Epoch[575/600] Iteration[006/008] Valid loss: 0.0354
2023-02-06 11:45:18 | Valid | Epoch[575/600] Iteration[007/008] Valid loss: 0.0356
2023-02-06 11:45:18 | Valid | Epoch[575/600] Iteration[008/008] Valid loss: 0.0346
2023-02-06 11:45:18 | Valid | Epoch[575/600] MIou: 0.9292185336194563
2023-02-06 11:45:18 | Valid | Epoch[575/600] Pixel Accuracy: 0.988152821858724
2023-02-06 11:45:18 | Valid | Epoch[575/600] Mean Pixel Accuracy: 0.9431259204031777
2023-02-06 11:45:18 | Stage | Epoch[575/600] Train loss:0.0200
2023-02-06 11:45:18 | Stage | Epoch[575/600] Valid loss:0.0346
2023-02-06 11:45:18 | Stage | Epoch[575/600] LR:0.0001

2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[001/030] Train loss: 0.0191
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[002/030] Train loss: 0.0195
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[004/030] Train loss: 0.0198
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[006/030] Train loss: 0.0199
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[009/030] Train loss: 0.0196
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[010/030] Train loss: 0.0199
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[011/030] Train loss: 0.0202
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:45:19 | Train | Epoch[576/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[024/030] Train loss: 0.0197
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[025/030] Train loss: 0.0197
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:45:20 | Train | Epoch[576/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:45:20 | Valid | Epoch[576/600] Iteration[001/008] Valid loss: 0.0550
2023-02-06 11:45:20 | Valid | Epoch[576/600] Iteration[002/008] Valid loss: 0.0401
2023-02-06 11:45:20 | Valid | Epoch[576/600] Iteration[003/008] Valid loss: 0.0357
2023-02-06 11:45:20 | Valid | Epoch[576/600] Iteration[004/008] Valid loss: 0.0345
2023-02-06 11:45:20 | Valid | Epoch[576/600] Iteration[005/008] Valid loss: 0.0355
2023-02-06 11:45:20 | Valid | Epoch[576/600] Iteration[006/008] Valid loss: 0.0355
2023-02-06 11:45:20 | Valid | Epoch[576/600] Iteration[007/008] Valid loss: 0.0358
2023-02-06 11:45:20 | Valid | Epoch[576/600] Iteration[008/008] Valid loss: 0.0347
2023-02-06 11:45:21 | Valid | Epoch[576/600] MIou: 0.9297648142383927
2023-02-06 11:45:21 | Valid | Epoch[576/600] Pixel Accuracy: 0.9882405598958334
2023-02-06 11:45:21 | Valid | Epoch[576/600] Mean Pixel Accuracy: 0.9437764897639573
2023-02-06 11:45:21 | Stage | Epoch[576/600] Train loss:0.0199
2023-02-06 11:45:21 | Stage | Epoch[576/600] Valid loss:0.0347
2023-02-06 11:45:21 | Stage | Epoch[576/600] LR:0.0001

2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[001/030] Train loss: 0.0208
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[002/030] Train loss: 0.0206
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[004/030] Train loss: 0.0202
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[009/030] Train loss: 0.0194
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[010/030] Train loss: 0.0193
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[011/030] Train loss: 0.0196
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:45:21 | Train | Epoch[577/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[021/030] Train loss: 0.0205
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:45:22 | Train | Epoch[577/600] Iteration[030/030] Train loss: 0.0203
2023-02-06 11:45:23 | Valid | Epoch[577/600] Iteration[001/008] Valid loss: 0.0494
2023-02-06 11:45:23 | Valid | Epoch[577/600] Iteration[002/008] Valid loss: 0.0374
2023-02-06 11:45:23 | Valid | Epoch[577/600] Iteration[003/008] Valid loss: 0.0340
2023-02-06 11:45:23 | Valid | Epoch[577/600] Iteration[004/008] Valid loss: 0.0325
2023-02-06 11:45:23 | Valid | Epoch[577/600] Iteration[005/008] Valid loss: 0.0334
2023-02-06 11:45:23 | Valid | Epoch[577/600] Iteration[006/008] Valid loss: 0.0333
2023-02-06 11:45:23 | Valid | Epoch[577/600] Iteration[007/008] Valid loss: 0.0333
2023-02-06 11:45:23 | Valid | Epoch[577/600] Iteration[008/008] Valid loss: 0.0326
2023-02-06 11:45:23 | Valid | Epoch[577/600] MIou: 0.9241392882867427
2023-02-06 11:45:23 | Valid | Epoch[577/600] Pixel Accuracy: 0.9873504638671875
2023-02-06 11:45:23 | Valid | Epoch[577/600] Mean Pixel Accuracy: 0.9367248670099335
2023-02-06 11:45:23 | Stage | Epoch[577/600] Train loss:0.0203
2023-02-06 11:45:23 | Stage | Epoch[577/600] Valid loss:0.0326
2023-02-06 11:45:23 | Stage | Epoch[577/600] LR:0.0001

2023-02-06 11:45:23 | Train | Epoch[578/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 11:45:23 | Train | Epoch[578/600] Iteration[002/030] Train loss: 0.0184
2023-02-06 11:45:23 | Train | Epoch[578/600] Iteration[003/030] Train loss: 0.0192
2023-02-06 11:45:23 | Train | Epoch[578/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 11:45:23 | Train | Epoch[578/600] Iteration[005/030] Train loss: 0.0199
2023-02-06 11:45:23 | Train | Epoch[578/600] Iteration[006/030] Train loss: 0.0198
2023-02-06 11:45:23 | Train | Epoch[578/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:45:23 | Train | Epoch[578/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:45:23 | Train | Epoch[578/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[010/030] Train loss: 0.0197
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[023/030] Train loss: 0.0204
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:45:24 | Train | Epoch[578/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:45:25 | Train | Epoch[578/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:45:25 | Valid | Epoch[578/600] Iteration[001/008] Valid loss: 0.0526
2023-02-06 11:45:25 | Valid | Epoch[578/600] Iteration[002/008] Valid loss: 0.0389
2023-02-06 11:45:25 | Valid | Epoch[578/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:45:25 | Valid | Epoch[578/600] Iteration[004/008] Valid loss: 0.0336
2023-02-06 11:45:25 | Valid | Epoch[578/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:45:25 | Valid | Epoch[578/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 11:45:25 | Valid | Epoch[578/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 11:45:25 | Valid | Epoch[578/600] Iteration[008/008] Valid loss: 0.0338
2023-02-06 11:45:25 | Valid | Epoch[578/600] MIou: 0.9278110984104972
2023-02-06 11:45:25 | Valid | Epoch[578/600] Pixel Accuracy: 0.9879341125488281
2023-02-06 11:45:25 | Valid | Epoch[578/600] Mean Pixel Accuracy: 0.9411923335862776
2023-02-06 11:45:25 | Stage | Epoch[578/600] Train loss:0.0200
2023-02-06 11:45:25 | Stage | Epoch[578/600] Valid loss:0.0338
2023-02-06 11:45:25 | Stage | Epoch[578/600] LR:0.0001

2023-02-06 11:45:25 | Train | Epoch[579/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 11:45:25 | Train | Epoch[579/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[003/030] Train loss: 0.0183
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[006/030] Train loss: 0.0191
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[012/030] Train loss: 0.0200
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:45:26 | Train | Epoch[579/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:45:27 | Train | Epoch[579/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:45:27 | Train | Epoch[579/600] Iteration[025/030] Train loss: 0.0203
2023-02-06 11:45:27 | Train | Epoch[579/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:45:27 | Train | Epoch[579/600] Iteration[027/030] Train loss: 0.0201
2023-02-06 11:45:27 | Train | Epoch[579/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:45:27 | Train | Epoch[579/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:45:27 | Train | Epoch[579/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:45:27 | Valid | Epoch[579/600] Iteration[001/008] Valid loss: 0.0511
2023-02-06 11:45:27 | Valid | Epoch[579/600] Iteration[002/008] Valid loss: 0.0382
2023-02-06 11:45:27 | Valid | Epoch[579/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:45:27 | Valid | Epoch[579/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 11:45:27 | Valid | Epoch[579/600] Iteration[005/008] Valid loss: 0.0339
2023-02-06 11:45:27 | Valid | Epoch[579/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 11:45:27 | Valid | Epoch[579/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 11:45:27 | Valid | Epoch[579/600] Iteration[008/008] Valid loss: 0.0331
2023-02-06 11:45:27 | Valid | Epoch[579/600] MIou: 0.9256007339175554
2023-02-06 11:45:27 | Valid | Epoch[579/600] Pixel Accuracy: 0.9875818888346354
2023-02-06 11:45:27 | Valid | Epoch[579/600] Mean Pixel Accuracy: 0.938519612049756
2023-02-06 11:45:27 | Stage | Epoch[579/600] Train loss:0.0202
2023-02-06 11:45:27 | Stage | Epoch[579/600] Valid loss:0.0331
2023-02-06 11:45:27 | Stage | Epoch[579/600] LR:0.0001

2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[001/030] Train loss: 0.0202
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[002/030] Train loss: 0.0190
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[003/030] Train loss: 0.0196
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[004/030] Train loss: 0.0193
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[007/030] Train loss: 0.0194
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[008/030] Train loss: 0.0197
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[009/030] Train loss: 0.0197
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[013/030] Train loss: 0.0198
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:45:28 | Train | Epoch[580/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[026/030] Train loss: 0.0202
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:45:29 | Train | Epoch[580/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:45:29 | Valid | Epoch[580/600] Iteration[001/008] Valid loss: 0.0549
2023-02-06 11:45:29 | Valid | Epoch[580/600] Iteration[002/008] Valid loss: 0.0400
2023-02-06 11:45:30 | Valid | Epoch[580/600] Iteration[003/008] Valid loss: 0.0357
2023-02-06 11:45:30 | Valid | Epoch[580/600] Iteration[004/008] Valid loss: 0.0343
2023-02-06 11:45:30 | Valid | Epoch[580/600] Iteration[005/008] Valid loss: 0.0354
2023-02-06 11:45:30 | Valid | Epoch[580/600] Iteration[006/008] Valid loss: 0.0353
2023-02-06 11:45:30 | Valid | Epoch[580/600] Iteration[007/008] Valid loss: 0.0357
2023-02-06 11:45:30 | Valid | Epoch[580/600] Iteration[008/008] Valid loss: 0.0346
2023-02-06 11:45:30 | Valid | Epoch[580/600] MIou: 0.9297111660327937
2023-02-06 11:45:30 | Valid | Epoch[580/600] Pixel Accuracy: 0.9882342020670573
2023-02-06 11:45:30 | Valid | Epoch[580/600] Mean Pixel Accuracy: 0.9436271643853293
2023-02-06 11:45:30 | Stage | Epoch[580/600] Train loss:0.0201
2023-02-06 11:45:30 | Stage | Epoch[580/600] Valid loss:0.0346
2023-02-06 11:45:30 | Stage | Epoch[580/600] LR:0.0001

2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[001/030] Train loss: 0.0179
2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[002/030] Train loss: 0.0194
2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[003/030] Train loss: 0.0187
2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[004/030] Train loss: 0.0191
2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[005/030] Train loss: 0.0196
2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[006/030] Train loss: 0.0201
2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[008/030] Train loss: 0.0204
2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[010/030] Train loss: 0.0205
2023-02-06 11:45:30 | Train | Epoch[581/600] Iteration[011/030] Train loss: 0.0204
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[022/030] Train loss: 0.0198
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:45:31 | Train | Epoch[581/600] Iteration[030/030] Train loss: 0.0198
2023-02-06 11:45:32 | Valid | Epoch[581/600] Iteration[001/008] Valid loss: 0.0526
2023-02-06 11:45:32 | Valid | Epoch[581/600] Iteration[002/008] Valid loss: 0.0389
2023-02-06 11:45:32 | Valid | Epoch[581/600] Iteration[003/008] Valid loss: 0.0350
2023-02-06 11:45:32 | Valid | Epoch[581/600] Iteration[004/008] Valid loss: 0.0334
2023-02-06 11:45:32 | Valid | Epoch[581/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:45:32 | Valid | Epoch[581/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:45:32 | Valid | Epoch[581/600] Iteration[007/008] Valid loss: 0.0348
2023-02-06 11:45:32 | Valid | Epoch[581/600] Iteration[008/008] Valid loss: 0.0338
2023-02-06 11:45:32 | Valid | Epoch[581/600] MIou: 0.9285905262034353
2023-02-06 11:45:32 | Valid | Epoch[581/600] Pixel Accuracy: 0.988061269124349
2023-02-06 11:45:32 | Valid | Epoch[581/600] Mean Pixel Accuracy: 0.9420357617877544
2023-02-06 11:45:32 | Stage | Epoch[581/600] Train loss:0.0198
2023-02-06 11:45:32 | Stage | Epoch[581/600] Valid loss:0.0338
2023-02-06 11:45:32 | Stage | Epoch[581/600] LR:0.0001

2023-02-06 11:45:32 | Train | Epoch[582/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 11:45:32 | Train | Epoch[582/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 11:45:32 | Train | Epoch[582/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[004/030] Train loss: 0.0201
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[006/030] Train loss: 0.0199
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[008/030] Train loss: 0.0202
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[012/030] Train loss: 0.0201
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:45:33 | Train | Epoch[582/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:45:34 | Train | Epoch[582/600] Iteration[025/030] Train loss: 0.0198
2023-02-06 11:45:34 | Train | Epoch[582/600] Iteration[026/030] Train loss: 0.0197
2023-02-06 11:45:34 | Train | Epoch[582/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:45:34 | Train | Epoch[582/600] Iteration[028/030] Train loss: 0.0198
2023-02-06 11:45:34 | Train | Epoch[582/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:45:34 | Train | Epoch[582/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:45:34 | Valid | Epoch[582/600] Iteration[001/008] Valid loss: 0.0527
2023-02-06 11:45:34 | Valid | Epoch[582/600] Iteration[002/008] Valid loss: 0.0389
2023-02-06 11:45:34 | Valid | Epoch[582/600] Iteration[003/008] Valid loss: 0.0350
2023-02-06 11:45:34 | Valid | Epoch[582/600] Iteration[004/008] Valid loss: 0.0336
2023-02-06 11:45:34 | Valid | Epoch[582/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:45:34 | Valid | Epoch[582/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:45:34 | Valid | Epoch[582/600] Iteration[007/008] Valid loss: 0.0348
2023-02-06 11:45:34 | Valid | Epoch[582/600] Iteration[008/008] Valid loss: 0.0338
2023-02-06 11:45:34 | Valid | Epoch[582/600] MIou: 0.928327779435048
2023-02-06 11:45:34 | Valid | Epoch[582/600] Pixel Accuracy: 0.9880180358886719
2023-02-06 11:45:34 | Valid | Epoch[582/600] Mean Pixel Accuracy: 0.9417647205686022
2023-02-06 11:45:34 | Stage | Epoch[582/600] Train loss:0.0199
2023-02-06 11:45:34 | Stage | Epoch[582/600] Valid loss:0.0338
2023-02-06 11:45:34 | Stage | Epoch[582/600] LR:0.0001

2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[001/030] Train loss: 0.0181
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[002/030] Train loss: 0.0179
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[003/030] Train loss: 0.0179
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[004/030] Train loss: 0.0184
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[005/030] Train loss: 0.0194
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[006/030] Train loss: 0.0195
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[008/030] Train loss: 0.0198
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[011/030] Train loss: 0.0203
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[012/030] Train loss: 0.0203
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[014/030] Train loss: 0.0203
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:45:35 | Train | Epoch[583/600] Iteration[017/030] Train loss: 0.0203
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:45:36 | Train | Epoch[583/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:45:36 | Valid | Epoch[583/600] Iteration[001/008] Valid loss: 0.0522
2023-02-06 11:45:36 | Valid | Epoch[583/600] Iteration[002/008] Valid loss: 0.0387
2023-02-06 11:45:36 | Valid | Epoch[583/600] Iteration[003/008] Valid loss: 0.0348
2023-02-06 11:45:36 | Valid | Epoch[583/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:45:37 | Valid | Epoch[583/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:45:37 | Valid | Epoch[583/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:45:37 | Valid | Epoch[583/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 11:45:37 | Valid | Epoch[583/600] Iteration[008/008] Valid loss: 0.0338
2023-02-06 11:45:37 | Valid | Epoch[583/600] MIou: 0.9282692423260286
2023-02-06 11:45:37 | Valid | Epoch[583/600] Pixel Accuracy: 0.9880091349283854
2023-02-06 11:45:37 | Valid | Epoch[583/600] Mean Pixel Accuracy: 0.9416774020915549
2023-02-06 11:45:37 | Stage | Epoch[583/600] Train loss:0.0201
2023-02-06 11:45:37 | Stage | Epoch[583/600] Valid loss:0.0338
2023-02-06 11:45:37 | Stage | Epoch[583/600] LR:0.0001

2023-02-06 11:45:37 | Train | Epoch[584/600] Iteration[001/030] Train loss: 0.0222
2023-02-06 11:45:37 | Train | Epoch[584/600] Iteration[002/030] Train loss: 0.0210
2023-02-06 11:45:37 | Train | Epoch[584/600] Iteration[003/030] Train loss: 0.0210
2023-02-06 11:45:37 | Train | Epoch[584/600] Iteration[004/030] Train loss: 0.0211
2023-02-06 11:45:37 | Train | Epoch[584/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 11:45:37 | Train | Epoch[584/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:45:37 | Train | Epoch[584/600] Iteration[007/030] Train loss: 0.0206
2023-02-06 11:45:37 | Train | Epoch[584/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:45:37 | Train | Epoch[584/600] Iteration[009/030] Train loss: 0.0205
2023-02-06 11:45:37 | Train | Epoch[584/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[013/030] Train loss: 0.0204
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[015/030] Train loss: 0.0206
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[016/030] Train loss: 0.0206
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[017/030] Train loss: 0.0206
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[020/030] Train loss: 0.0204
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[021/030] Train loss: 0.0203
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[025/030] Train loss: 0.0204
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:45:38 | Train | Epoch[584/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:45:39 | Valid | Epoch[584/600] Iteration[001/008] Valid loss: 0.0512
2023-02-06 11:45:39 | Valid | Epoch[584/600] Iteration[002/008] Valid loss: 0.0383
2023-02-06 11:45:39 | Valid | Epoch[584/600] Iteration[003/008] Valid loss: 0.0346
2023-02-06 11:45:39 | Valid | Epoch[584/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:45:39 | Valid | Epoch[584/600] Iteration[005/008] Valid loss: 0.0340
2023-02-06 11:45:39 | Valid | Epoch[584/600] Iteration[006/008] Valid loss: 0.0339
2023-02-06 11:45:39 | Valid | Epoch[584/600] Iteration[007/008] Valid loss: 0.0340
2023-02-06 11:45:39 | Valid | Epoch[584/600] Iteration[008/008] Valid loss: 0.0332
2023-02-06 11:45:39 | Valid | Epoch[584/600] MIou: 0.9259242768980448
2023-02-06 11:45:39 | Valid | Epoch[584/600] Pixel Accuracy: 0.9876314798990885
2023-02-06 11:45:39 | Valid | Epoch[584/600] Mean Pixel Accuracy: 0.9389780214766086
2023-02-06 11:45:39 | Stage | Epoch[584/600] Train loss:0.0200
2023-02-06 11:45:39 | Stage | Epoch[584/600] Valid loss:0.0332
2023-02-06 11:45:39 | Stage | Epoch[584/600] LR:0.0001

2023-02-06 11:45:39 | Train | Epoch[585/600] Iteration[001/030] Train loss: 0.0184
2023-02-06 11:45:39 | Train | Epoch[585/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 11:45:39 | Train | Epoch[585/600] Iteration[003/030] Train loss: 0.0181
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[005/030] Train loss: 0.0185
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[006/030] Train loss: 0.0185
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[007/030] Train loss: 0.0189
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[013/030] Train loss: 0.0203
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[018/030] Train loss: 0.0201
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[020/030] Train loss: 0.0203
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:45:40 | Train | Epoch[585/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:45:41 | Train | Epoch[585/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:45:41 | Train | Epoch[585/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:45:41 | Train | Epoch[585/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:45:41 | Train | Epoch[585/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:45:41 | Train | Epoch[585/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:45:41 | Train | Epoch[585/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:45:41 | Valid | Epoch[585/600] Iteration[001/008] Valid loss: 0.0524
2023-02-06 11:45:41 | Valid | Epoch[585/600] Iteration[002/008] Valid loss: 0.0388
2023-02-06 11:45:41 | Valid | Epoch[585/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:45:41 | Valid | Epoch[585/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:45:41 | Valid | Epoch[585/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:45:41 | Valid | Epoch[585/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:45:41 | Valid | Epoch[585/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 11:45:41 | Valid | Epoch[585/600] Iteration[008/008] Valid loss: 0.0337
2023-02-06 11:45:41 | Valid | Epoch[585/600] MIou: 0.9280399869864727
2023-02-06 11:45:41 | Valid | Epoch[585/600] Pixel Accuracy: 0.987969716389974
2023-02-06 11:45:41 | Valid | Epoch[585/600] Mean Pixel Accuracy: 0.9415035646653941
2023-02-06 11:45:41 | Stage | Epoch[585/600] Train loss:0.0200
2023-02-06 11:45:41 | Stage | Epoch[585/600] Valid loss:0.0337
2023-02-06 11:45:41 | Stage | Epoch[585/600] LR:0.0001

2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[001/030] Train loss: 0.0195
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[004/030] Train loss: 0.0198
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[005/030] Train loss: 0.0203
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[009/030] Train loss: 0.0199
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[010/030] Train loss: 0.0198
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[011/030] Train loss: 0.0201
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[012/030] Train loss: 0.0204
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[015/030] Train loss: 0.0207
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[016/030] Train loss: 0.0205
2023-02-06 11:45:42 | Train | Epoch[586/600] Iteration[017/030] Train loss: 0.0205
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[018/030] Train loss: 0.0204
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[019/030] Train loss: 0.0204
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[022/030] Train loss: 0.0202
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[027/030] Train loss: 0.0203
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:45:43 | Train | Epoch[586/600] Iteration[030/030] Train loss: 0.0202
2023-02-06 11:45:43 | Valid | Epoch[586/600] Iteration[001/008] Valid loss: 0.0540
2023-02-06 11:45:44 | Valid | Epoch[586/600] Iteration[002/008] Valid loss: 0.0396
2023-02-06 11:45:44 | Valid | Epoch[586/600] Iteration[003/008] Valid loss: 0.0355
2023-02-06 11:45:44 | Valid | Epoch[586/600] Iteration[004/008] Valid loss: 0.0340
2023-02-06 11:45:44 | Valid | Epoch[586/600] Iteration[005/008] Valid loss: 0.0351
2023-02-06 11:45:44 | Valid | Epoch[586/600] Iteration[006/008] Valid loss: 0.0351
2023-02-06 11:45:44 | Valid | Epoch[586/600] Iteration[007/008] Valid loss: 0.0355
2023-02-06 11:45:44 | Valid | Epoch[586/600] Iteration[008/008] Valid loss: 0.0344
2023-02-06 11:45:44 | Valid | Epoch[586/600] MIou: 0.9287340175459737
2023-02-06 11:45:44 | Valid | Epoch[586/600] Pixel Accuracy: 0.9880765279134115
2023-02-06 11:45:44 | Valid | Epoch[586/600] Mean Pixel Accuracy: 0.9424943221463524
2023-02-06 11:45:44 | Stage | Epoch[586/600] Train loss:0.0202
2023-02-06 11:45:44 | Stage | Epoch[586/600] Valid loss:0.0344
2023-02-06 11:45:44 | Stage | Epoch[586/600] LR:0.0001

2023-02-06 11:45:44 | Train | Epoch[587/600] Iteration[001/030] Train loss: 0.0231
2023-02-06 11:45:44 | Train | Epoch[587/600] Iteration[002/030] Train loss: 0.0218
2023-02-06 11:45:44 | Train | Epoch[587/600] Iteration[003/030] Train loss: 0.0219
2023-02-06 11:45:44 | Train | Epoch[587/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:45:44 | Train | Epoch[587/600] Iteration[005/030] Train loss: 0.0205
2023-02-06 11:45:44 | Train | Epoch[587/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:45:44 | Train | Epoch[587/600] Iteration[007/030] Train loss: 0.0202
2023-02-06 11:45:44 | Train | Epoch[587/600] Iteration[008/030] Train loss: 0.0200
2023-02-06 11:45:44 | Train | Epoch[587/600] Iteration[009/030] Train loss: 0.0202
2023-02-06 11:45:44 | Train | Epoch[587/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[012/030] Train loss: 0.0199
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[016/030] Train loss: 0.0197
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[018/030] Train loss: 0.0198
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[021/030] Train loss: 0.0196
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[022/030] Train loss: 0.0197
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[023/030] Train loss: 0.0196
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[024/030] Train loss: 0.0196
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[025/030] Train loss: 0.0196
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[027/030] Train loss: 0.0198
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:45:45 | Train | Epoch[587/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:45:46 | Valid | Epoch[587/600] Iteration[001/008] Valid loss: 0.0502
2023-02-06 11:45:46 | Valid | Epoch[587/600] Iteration[002/008] Valid loss: 0.0379
2023-02-06 11:45:46 | Valid | Epoch[587/600] Iteration[003/008] Valid loss: 0.0343
2023-02-06 11:45:46 | Valid | Epoch[587/600] Iteration[004/008] Valid loss: 0.0327
2023-02-06 11:45:46 | Valid | Epoch[587/600] Iteration[005/008] Valid loss: 0.0336
2023-02-06 11:45:46 | Valid | Epoch[587/600] Iteration[006/008] Valid loss: 0.0335
2023-02-06 11:45:46 | Valid | Epoch[587/600] Iteration[007/008] Valid loss: 0.0337
2023-02-06 11:45:46 | Valid | Epoch[587/600] Iteration[008/008] Valid loss: 0.0328
2023-02-06 11:45:46 | Valid | Epoch[587/600] MIou: 0.9251912198365704
2023-02-06 11:45:46 | Valid | Epoch[587/600] Pixel Accuracy: 0.9875170389811198
2023-02-06 11:45:46 | Valid | Epoch[587/600] Mean Pixel Accuracy: 0.9380147729125905
2023-02-06 11:45:46 | Stage | Epoch[587/600] Train loss:0.0199
2023-02-06 11:45:46 | Stage | Epoch[587/600] Valid loss:0.0328
2023-02-06 11:45:46 | Stage | Epoch[587/600] LR:0.0001

2023-02-06 11:45:46 | Train | Epoch[588/600] Iteration[001/030] Train loss: 0.0167
2023-02-06 11:45:46 | Train | Epoch[588/600] Iteration[002/030] Train loss: 0.0186
2023-02-06 11:45:46 | Train | Epoch[588/600] Iteration[003/030] Train loss: 0.0194
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[004/030] Train loss: 0.0197
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[005/030] Train loss: 0.0201
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[009/030] Train loss: 0.0201
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[010/030] Train loss: 0.0201
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[011/030] Train loss: 0.0199
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[013/030] Train loss: 0.0201
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[016/030] Train loss: 0.0199
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[019/030] Train loss: 0.0199
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[020/030] Train loss: 0.0198
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[021/030] Train loss: 0.0198
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:45:47 | Train | Epoch[588/600] Iteration[024/030] Train loss: 0.0198
2023-02-06 11:45:48 | Train | Epoch[588/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:45:48 | Train | Epoch[588/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:45:48 | Train | Epoch[588/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:45:48 | Train | Epoch[588/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:45:48 | Train | Epoch[588/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:45:48 | Train | Epoch[588/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:45:48 | Valid | Epoch[588/600] Iteration[001/008] Valid loss: 0.0527
2023-02-06 11:45:48 | Valid | Epoch[588/600] Iteration[002/008] Valid loss: 0.0390
2023-02-06 11:45:48 | Valid | Epoch[588/600] Iteration[003/008] Valid loss: 0.0350
2023-02-06 11:45:48 | Valid | Epoch[588/600] Iteration[004/008] Valid loss: 0.0336
2023-02-06 11:45:48 | Valid | Epoch[588/600] Iteration[005/008] Valid loss: 0.0346
2023-02-06 11:45:48 | Valid | Epoch[588/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 11:45:48 | Valid | Epoch[588/600] Iteration[007/008] Valid loss: 0.0349
2023-02-06 11:45:48 | Valid | Epoch[588/600] Iteration[008/008] Valid loss: 0.0339
2023-02-06 11:45:48 | Valid | Epoch[588/600] MIou: 0.9283567793527838
2023-02-06 11:45:48 | Valid | Epoch[588/600] Pixel Accuracy: 0.9880193074544271
2023-02-06 11:45:48 | Valid | Epoch[588/600] Mean Pixel Accuracy: 0.9419239312631742
2023-02-06 11:45:48 | Stage | Epoch[588/600] Train loss:0.0200
2023-02-06 11:45:48 | Stage | Epoch[588/600] Valid loss:0.0339
2023-02-06 11:45:48 | Stage | Epoch[588/600] LR:0.0001

2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[001/030] Train loss: 0.0228
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[003/030] Train loss: 0.0219
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[004/030] Train loss: 0.0209
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[006/030] Train loss: 0.0205
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[007/030] Train loss: 0.0208
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[008/030] Train loss: 0.0207
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[010/030] Train loss: 0.0206
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[011/030] Train loss: 0.0205
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[012/030] Train loss: 0.0205
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[013/030] Train loss: 0.0205
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[014/030] Train loss: 0.0205
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[015/030] Train loss: 0.0205
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[016/030] Train loss: 0.0204
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[017/030] Train loss: 0.0204
2023-02-06 11:45:49 | Train | Epoch[589/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[024/030] Train loss: 0.0202
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[026/030] Train loss: 0.0203
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:45:50 | Train | Epoch[589/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:45:50 | Valid | Epoch[589/600] Iteration[001/008] Valid loss: 0.0509
2023-02-06 11:45:50 | Valid | Epoch[589/600] Iteration[002/008] Valid loss: 0.0381
2023-02-06 11:45:50 | Valid | Epoch[589/600] Iteration[003/008] Valid loss: 0.0345
2023-02-06 11:45:50 | Valid | Epoch[589/600] Iteration[004/008] Valid loss: 0.0330
2023-02-06 11:45:51 | Valid | Epoch[589/600] Iteration[005/008] Valid loss: 0.0339
2023-02-06 11:45:51 | Valid | Epoch[589/600] Iteration[006/008] Valid loss: 0.0340
2023-02-06 11:45:51 | Valid | Epoch[589/600] Iteration[007/008] Valid loss: 0.0341
2023-02-06 11:45:51 | Valid | Epoch[589/600] Iteration[008/008] Valid loss: 0.0332
2023-02-06 11:45:51 | Valid | Epoch[589/600] MIou: 0.9260199213290415
2023-02-06 11:45:51 | Valid | Epoch[589/600] Pixel Accuracy: 0.9876505533854166
2023-02-06 11:45:51 | Valid | Epoch[589/600] Mean Pixel Accuracy: 0.9389568027205986
2023-02-06 11:45:51 | Stage | Epoch[589/600] Train loss:0.0199
2023-02-06 11:45:51 | Stage | Epoch[589/600] Valid loss:0.0332
2023-02-06 11:45:51 | Stage | Epoch[589/600] LR:0.0001

2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[001/030] Train loss: 0.0210
2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[002/030] Train loss: 0.0201
2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[003/030] Train loss: 0.0202
2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[004/030] Train loss: 0.0200
2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[005/030] Train loss: 0.0200
2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[006/030] Train loss: 0.0200
2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[008/030] Train loss: 0.0201
2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[009/030] Train loss: 0.0198
2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:45:51 | Train | Epoch[590/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[013/030] Train loss: 0.0191
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[014/030] Train loss: 0.0190
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[015/030] Train loss: 0.0191
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[016/030] Train loss: 0.0194
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[017/030] Train loss: 0.0195
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[018/030] Train loss: 0.0194
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[019/030] Train loss: 0.0195
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[020/030] Train loss: 0.0193
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[021/030] Train loss: 0.0194
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[022/030] Train loss: 0.0194
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[023/030] Train loss: 0.0194
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[024/030] Train loss: 0.0195
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[025/030] Train loss: 0.0196
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[026/030] Train loss: 0.0196
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[027/030] Train loss: 0.0197
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[028/030] Train loss: 0.0197
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:45:52 | Train | Epoch[590/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:45:53 | Valid | Epoch[590/600] Iteration[001/008] Valid loss: 0.0532
2023-02-06 11:45:53 | Valid | Epoch[590/600] Iteration[002/008] Valid loss: 0.0392
2023-02-06 11:45:53 | Valid | Epoch[590/600] Iteration[003/008] Valid loss: 0.0351
2023-02-06 11:45:53 | Valid | Epoch[590/600] Iteration[004/008] Valid loss: 0.0336
2023-02-06 11:45:53 | Valid | Epoch[590/600] Iteration[005/008] Valid loss: 0.0346
2023-02-06 11:45:53 | Valid | Epoch[590/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 11:45:53 | Valid | Epoch[590/600] Iteration[007/008] Valid loss: 0.0349
2023-02-06 11:45:53 | Valid | Epoch[590/600] Iteration[008/008] Valid loss: 0.0339
2023-02-06 11:45:53 | Valid | Epoch[590/600] MIou: 0.9282518085887218
2023-02-06 11:45:53 | Valid | Epoch[590/600] Pixel Accuracy: 0.9880053202311198
2023-02-06 11:45:53 | Valid | Epoch[590/600] Mean Pixel Accuracy: 0.9416943267857811
2023-02-06 11:45:53 | Stage | Epoch[590/600] Train loss:0.0199
2023-02-06 11:45:53 | Stage | Epoch[590/600] Valid loss:0.0339
2023-02-06 11:45:53 | Stage | Epoch[590/600] LR:0.0001

2023-02-06 11:45:53 | Train | Epoch[591/600] Iteration[001/030] Train loss: 0.0189
2023-02-06 11:45:53 | Train | Epoch[591/600] Iteration[002/030] Train loss: 0.0181
2023-02-06 11:45:53 | Train | Epoch[591/600] Iteration[003/030] Train loss: 0.0180
2023-02-06 11:45:53 | Train | Epoch[591/600] Iteration[004/030] Train loss: 0.0188
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[005/030] Train loss: 0.0197
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[006/030] Train loss: 0.0199
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[009/030] Train loss: 0.0196
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[010/030] Train loss: 0.0195
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[011/030] Train loss: 0.0195
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[014/030] Train loss: 0.0201
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[015/030] Train loss: 0.0201
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[019/030] Train loss: 0.0202
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[023/030] Train loss: 0.0199
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:45:54 | Train | Epoch[591/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:45:55 | Train | Epoch[591/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:45:55 | Train | Epoch[591/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:45:55 | Train | Epoch[591/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:45:55 | Train | Epoch[591/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:45:55 | Train | Epoch[591/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:45:55 | Valid | Epoch[591/600] Iteration[001/008] Valid loss: 0.0538
2023-02-06 11:45:55 | Valid | Epoch[591/600] Iteration[002/008] Valid loss: 0.0395
2023-02-06 11:45:55 | Valid | Epoch[591/600] Iteration[003/008] Valid loss: 0.0353
2023-02-06 11:45:55 | Valid | Epoch[591/600] Iteration[004/008] Valid loss: 0.0340
2023-02-06 11:45:55 | Valid | Epoch[591/600] Iteration[005/008] Valid loss: 0.0350
2023-02-06 11:45:55 | Valid | Epoch[591/600] Iteration[006/008] Valid loss: 0.0349
2023-02-06 11:45:55 | Valid | Epoch[591/600] Iteration[007/008] Valid loss: 0.0353
2023-02-06 11:45:55 | Valid | Epoch[591/600] Iteration[008/008] Valid loss: 0.0342
2023-02-06 11:45:55 | Valid | Epoch[591/600] MIou: 0.929433286558295
2023-02-06 11:45:55 | Valid | Epoch[591/600] Pixel Accuracy: 0.9881935119628906
2023-02-06 11:45:55 | Valid | Epoch[591/600] Mean Pixel Accuracy: 0.9431482854198185
2023-02-06 11:45:55 | Stage | Epoch[591/600] Train loss:0.0200
2023-02-06 11:45:55 | Stage | Epoch[591/600] Valid loss:0.0342
2023-02-06 11:45:55 | Stage | Epoch[591/600] LR:0.0001

2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[001/030] Train loss: 0.0178
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[002/030] Train loss: 0.0184
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[003/030] Train loss: 0.0182
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[004/030] Train loss: 0.0187
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[005/030] Train loss: 0.0189
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[006/030] Train loss: 0.0185
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[007/030] Train loss: 0.0190
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[008/030] Train loss: 0.0193
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[009/030] Train loss: 0.0190
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[010/030] Train loss: 0.0189
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[011/030] Train loss: 0.0189
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[012/030] Train loss: 0.0193
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[013/030] Train loss: 0.0193
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[014/030] Train loss: 0.0194
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[015/030] Train loss: 0.0195
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[016/030] Train loss: 0.0196
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[017/030] Train loss: 0.0196
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[018/030] Train loss: 0.0197
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:45:56 | Train | Epoch[592/600] Iteration[020/030] Train loss: 0.0199
2023-02-06 11:45:57 | Train | Epoch[592/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:45:57 | Train | Epoch[592/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:45:57 | Train | Epoch[592/600] Iteration[023/030] Train loss: 0.0200
2023-02-06 11:45:57 | Train | Epoch[592/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:45:57 | Train | Epoch[592/600] Iteration[025/030] Train loss: 0.0201
2023-02-06 11:45:57 | Train | Epoch[592/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:45:57 | Train | Epoch[592/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:45:57 | Train | Epoch[592/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:45:57 | Train | Epoch[592/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:45:57 | Train | Epoch[592/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:45:57 | Valid | Epoch[592/600] Iteration[001/008] Valid loss: 0.0494
2023-02-06 11:45:57 | Valid | Epoch[592/600] Iteration[002/008] Valid loss: 0.0375
2023-02-06 11:45:57 | Valid | Epoch[592/600] Iteration[003/008] Valid loss: 0.0341
2023-02-06 11:45:57 | Valid | Epoch[592/600] Iteration[004/008] Valid loss: 0.0325
2023-02-06 11:45:57 | Valid | Epoch[592/600] Iteration[005/008] Valid loss: 0.0334
2023-02-06 11:45:57 | Valid | Epoch[592/600] Iteration[006/008] Valid loss: 0.0333
2023-02-06 11:45:57 | Valid | Epoch[592/600] Iteration[007/008] Valid loss: 0.0334
2023-02-06 11:45:57 | Valid | Epoch[592/600] Iteration[008/008] Valid loss: 0.0326
2023-02-06 11:45:58 | Valid | Epoch[592/600] MIou: 0.9241658866811873
2023-02-06 11:45:58 | Valid | Epoch[592/600] Pixel Accuracy: 0.9873530069986979
2023-02-06 11:45:58 | Valid | Epoch[592/600] Mean Pixel Accuracy: 0.9368150314246426
2023-02-06 11:45:58 | Stage | Epoch[592/600] Train loss:0.0200
2023-02-06 11:45:58 | Stage | Epoch[592/600] Valid loss:0.0326
2023-02-06 11:45:58 | Stage | Epoch[592/600] LR:0.0001

2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[001/030] Train loss: 0.0174
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[002/030] Train loss: 0.0205
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[003/030] Train loss: 0.0203
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[004/030] Train loss: 0.0205
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[005/030] Train loss: 0.0213
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[006/030] Train loss: 0.0209
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[007/030] Train loss: 0.0212
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[010/030] Train loss: 0.0208
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[011/030] Train loss: 0.0208
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[012/030] Train loss: 0.0210
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[013/030] Train loss: 0.0208
2023-02-06 11:45:58 | Train | Epoch[593/600] Iteration[014/030] Train loss: 0.0206
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[015/030] Train loss: 0.0203
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[017/030] Train loss: 0.0202
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[018/030] Train loss: 0.0203
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[021/030] Train loss: 0.0200
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:45:59 | Train | Epoch[593/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:46:00 | Valid | Epoch[593/600] Iteration[001/008] Valid loss: 0.0541
2023-02-06 11:46:00 | Valid | Epoch[593/600] Iteration[002/008] Valid loss: 0.0397
2023-02-06 11:46:00 | Valid | Epoch[593/600] Iteration[003/008] Valid loss: 0.0355
2023-02-06 11:46:00 | Valid | Epoch[593/600] Iteration[004/008] Valid loss: 0.0342
2023-02-06 11:46:00 | Valid | Epoch[593/600] Iteration[005/008] Valid loss: 0.0352
2023-02-06 11:46:00 | Valid | Epoch[593/600] Iteration[006/008] Valid loss: 0.0352
2023-02-06 11:46:00 | Valid | Epoch[593/600] Iteration[007/008] Valid loss: 0.0354
2023-02-06 11:46:00 | Valid | Epoch[593/600] Iteration[008/008] Valid loss: 0.0344
2023-02-06 11:46:00 | Valid | Epoch[593/600] MIou: 0.9291366894717219
2023-02-06 11:46:00 | Valid | Epoch[593/600] Pixel Accuracy: 0.9881426493326823
2023-02-06 11:46:00 | Valid | Epoch[593/600] Mean Pixel Accuracy: 0.9429174340606308
2023-02-06 11:46:00 | Stage | Epoch[593/600] Train loss:0.0201
2023-02-06 11:46:00 | Stage | Epoch[593/600] Valid loss:0.0344
2023-02-06 11:46:00 | Stage | Epoch[593/600] LR:0.0001

2023-02-06 11:46:00 | Train | Epoch[594/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:46:00 | Train | Epoch[594/600] Iteration[002/030] Train loss: 0.0193
2023-02-06 11:46:00 | Train | Epoch[594/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:46:00 | Train | Epoch[594/600] Iteration[004/030] Train loss: 0.0190
2023-02-06 11:46:00 | Train | Epoch[594/600] Iteration[005/030] Train loss: 0.0192
2023-02-06 11:46:00 | Train | Epoch[594/600] Iteration[006/030] Train loss: 0.0197
2023-02-06 11:46:00 | Train | Epoch[594/600] Iteration[007/030] Train loss: 0.0198
2023-02-06 11:46:00 | Train | Epoch[594/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[009/030] Train loss: 0.0193
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[010/030] Train loss: 0.0193
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[011/030] Train loss: 0.0191
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[012/030] Train loss: 0.0192
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[013/030] Train loss: 0.0192
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[014/030] Train loss: 0.0193
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[015/030] Train loss: 0.0192
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[016/030] Train loss: 0.0192
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[017/030] Train loss: 0.0193
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[018/030] Train loss: 0.0195
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[019/030] Train loss: 0.0196
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[020/030] Train loss: 0.0195
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[021/030] Train loss: 0.0197
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[022/030] Train loss: 0.0196
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[023/030] Train loss: 0.0197
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:46:01 | Train | Epoch[594/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:46:02 | Train | Epoch[594/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:46:02 | Train | Epoch[594/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:46:02 | Valid | Epoch[594/600] Iteration[001/008] Valid loss: 0.0506
2023-02-06 11:46:02 | Valid | Epoch[594/600] Iteration[002/008] Valid loss: 0.0380
2023-02-06 11:46:02 | Valid | Epoch[594/600] Iteration[003/008] Valid loss: 0.0343
2023-02-06 11:46:02 | Valid | Epoch[594/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 11:46:02 | Valid | Epoch[594/600] Iteration[005/008] Valid loss: 0.0338
2023-02-06 11:46:02 | Valid | Epoch[594/600] Iteration[006/008] Valid loss: 0.0337
2023-02-06 11:46:02 | Valid | Epoch[594/600] Iteration[007/008] Valid loss: 0.0337
2023-02-06 11:46:02 | Valid | Epoch[594/600] Iteration[008/008] Valid loss: 0.0329
2023-02-06 11:46:02 | Valid | Epoch[594/600] MIou: 0.9254498249415701
2023-02-06 11:46:02 | Valid | Epoch[594/600] Pixel Accuracy: 0.9875590006510416
2023-02-06 11:46:02 | Valid | Epoch[594/600] Mean Pixel Accuracy: 0.9382977961679968
2023-02-06 11:46:02 | Stage | Epoch[594/600] Train loss:0.0200
2023-02-06 11:46:02 | Stage | Epoch[594/600] Valid loss:0.0329
2023-02-06 11:46:02 | Stage | Epoch[594/600] LR:0.0001

2023-02-06 11:46:02 | Train | Epoch[595/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:46:02 | Train | Epoch[595/600] Iteration[002/030] Train loss: 0.0198
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[003/030] Train loss: 0.0211
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[004/030] Train loss: 0.0207
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[007/030] Train loss: 0.0199
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[008/030] Train loss: 0.0199
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[009/030] Train loss: 0.0200
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[010/030] Train loss: 0.0200
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[013/030] Train loss: 0.0197
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[016/030] Train loss: 0.0202
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[020/030] Train loss: 0.0200
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[022/030] Train loss: 0.0200
2023-02-06 11:46:03 | Train | Epoch[595/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:46:04 | Train | Epoch[595/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:46:04 | Train | Epoch[595/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:46:04 | Train | Epoch[595/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:46:04 | Train | Epoch[595/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:46:04 | Train | Epoch[595/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:46:04 | Train | Epoch[595/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:46:04 | Train | Epoch[595/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:46:04 | Valid | Epoch[595/600] Iteration[001/008] Valid loss: 0.0523
2023-02-06 11:46:04 | Valid | Epoch[595/600] Iteration[002/008] Valid loss: 0.0387
2023-02-06 11:46:04 | Valid | Epoch[595/600] Iteration[003/008] Valid loss: 0.0348
2023-02-06 11:46:04 | Valid | Epoch[595/600] Iteration[004/008] Valid loss: 0.0334
2023-02-06 11:46:04 | Valid | Epoch[595/600] Iteration[005/008] Valid loss: 0.0344
2023-02-06 11:46:04 | Valid | Epoch[595/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:46:04 | Valid | Epoch[595/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 11:46:04 | Valid | Epoch[595/600] Iteration[008/008] Valid loss: 0.0337
2023-02-06 11:46:04 | Valid | Epoch[595/600] MIou: 0.9281003043011007
2023-02-06 11:46:04 | Valid | Epoch[595/600] Pixel Accuracy: 0.9879811604817709
2023-02-06 11:46:04 | Valid | Epoch[595/600] Mean Pixel Accuracy: 0.9415098548263243
2023-02-06 11:46:04 | Stage | Epoch[595/600] Train loss:0.0200
2023-02-06 11:46:04 | Stage | Epoch[595/600] Valid loss:0.0337
2023-02-06 11:46:04 | Stage | Epoch[595/600] LR:0.0001

2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[001/030] Train loss: 0.0207
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[002/030] Train loss: 0.0208
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[003/030] Train loss: 0.0206
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[004/030] Train loss: 0.0210
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[005/030] Train loss: 0.0206
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[006/030] Train loss: 0.0212
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[007/030] Train loss: 0.0209
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[009/030] Train loss: 0.0204
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[010/030] Train loss: 0.0202
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[012/030] Train loss: 0.0202
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[013/030] Train loss: 0.0202
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[014/030] Train loss: 0.0200
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[015/030] Train loss: 0.0199
2023-02-06 11:46:05 | Train | Epoch[596/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[019/030] Train loss: 0.0198
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[020/030] Train loss: 0.0197
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[021/030] Train loss: 0.0199
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[022/030] Train loss: 0.0199
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[023/030] Train loss: 0.0198
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[025/030] Train loss: 0.0199
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[026/030] Train loss: 0.0198
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[027/030] Train loss: 0.0199
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[029/030] Train loss: 0.0199
2023-02-06 11:46:06 | Train | Epoch[596/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:46:07 | Valid | Epoch[596/600] Iteration[001/008] Valid loss: 0.0494
2023-02-06 11:46:07 | Valid | Epoch[596/600] Iteration[002/008] Valid loss: 0.0375
2023-02-06 11:46:07 | Valid | Epoch[596/600] Iteration[003/008] Valid loss: 0.0341
2023-02-06 11:46:07 | Valid | Epoch[596/600] Iteration[004/008] Valid loss: 0.0325
2023-02-06 11:46:07 | Valid | Epoch[596/600] Iteration[005/008] Valid loss: 0.0334
2023-02-06 11:46:07 | Valid | Epoch[596/600] Iteration[006/008] Valid loss: 0.0333
2023-02-06 11:46:07 | Valid | Epoch[596/600] Iteration[007/008] Valid loss: 0.0333
2023-02-06 11:46:07 | Valid | Epoch[596/600] Iteration[008/008] Valid loss: 0.0325
2023-02-06 11:46:07 | Valid | Epoch[596/600] MIou: 0.9238879422325397
2023-02-06 11:46:07 | Valid | Epoch[596/600] Pixel Accuracy: 0.9873072306315104
2023-02-06 11:46:07 | Valid | Epoch[596/600] Mean Pixel Accuracy: 0.9365362519204383
2023-02-06 11:46:07 | Stage | Epoch[596/600] Train loss:0.0201
2023-02-06 11:46:07 | Stage | Epoch[596/600] Valid loss:0.0325
2023-02-06 11:46:07 | Stage | Epoch[596/600] LR:0.0001

2023-02-06 11:46:07 | Train | Epoch[597/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 11:46:07 | Train | Epoch[597/600] Iteration[002/030] Train loss: 0.0196
2023-02-06 11:46:07 | Train | Epoch[597/600] Iteration[003/030] Train loss: 0.0204
2023-02-06 11:46:07 | Train | Epoch[597/600] Iteration[004/030] Train loss: 0.0194
2023-02-06 11:46:07 | Train | Epoch[597/600] Iteration[005/030] Train loss: 0.0202
2023-02-06 11:46:07 | Train | Epoch[597/600] Iteration[006/030] Train loss: 0.0202
2023-02-06 11:46:07 | Train | Epoch[597/600] Iteration[007/030] Train loss: 0.0201
2023-02-06 11:46:07 | Train | Epoch[597/600] Iteration[008/030] Train loss: 0.0203
2023-02-06 11:46:07 | Train | Epoch[597/600] Iteration[009/030] Train loss: 0.0206
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[010/030] Train loss: 0.0204
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[011/030] Train loss: 0.0206
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[012/030] Train loss: 0.0207
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[013/030] Train loss: 0.0210
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[014/030] Train loss: 0.0209
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[015/030] Train loss: 0.0208
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[016/030] Train loss: 0.0208
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[017/030] Train loss: 0.0209
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[018/030] Train loss: 0.0207
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[019/030] Train loss: 0.0206
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[020/030] Train loss: 0.0205
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[021/030] Train loss: 0.0204
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[022/030] Train loss: 0.0204
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[023/030] Train loss: 0.0203
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[024/030] Train loss: 0.0201
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[026/030] Train loss: 0.0199
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[028/030] Train loss: 0.0199
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[029/030] Train loss: 0.0198
2023-02-06 11:46:08 | Train | Epoch[597/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:46:09 | Valid | Epoch[597/600] Iteration[001/008] Valid loss: 0.0519
2023-02-06 11:46:09 | Valid | Epoch[597/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 11:46:09 | Valid | Epoch[597/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 11:46:09 | Valid | Epoch[597/600] Iteration[004/008] Valid loss: 0.0333
2023-02-06 11:46:09 | Valid | Epoch[597/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 11:46:09 | Valid | Epoch[597/600] Iteration[006/008] Valid loss: 0.0342
2023-02-06 11:46:09 | Valid | Epoch[597/600] Iteration[007/008] Valid loss: 0.0344
2023-02-06 11:46:09 | Valid | Epoch[597/600] Iteration[008/008] Valid loss: 0.0335
2023-02-06 11:46:09 | Valid | Epoch[597/600] MIou: 0.9277283127014251
2023-02-06 11:46:09 | Valid | Epoch[597/600] Pixel Accuracy: 0.9879226684570312
2023-02-06 11:46:09 | Valid | Epoch[597/600] Mean Pixel Accuracy: 0.9410275316375454
2023-02-06 11:46:09 | Stage | Epoch[597/600] Train loss:0.0199
2023-02-06 11:46:09 | Stage | Epoch[597/600] Valid loss:0.0335
2023-02-06 11:46:09 | Stage | Epoch[597/600] LR:0.0001

2023-02-06 11:46:09 | Train | Epoch[598/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[002/030] Train loss: 0.0197
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[003/030] Train loss: 0.0190
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[004/030] Train loss: 0.0192
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[005/030] Train loss: 0.0191
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[006/030] Train loss: 0.0192
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[007/030] Train loss: 0.0195
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[008/030] Train loss: 0.0196
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[009/030] Train loss: 0.0195
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[010/030] Train loss: 0.0196
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[011/030] Train loss: 0.0198
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[012/030] Train loss: 0.0197
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[013/030] Train loss: 0.0195
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[014/030] Train loss: 0.0198
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[016/030] Train loss: 0.0201
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[017/030] Train loss: 0.0199
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[018/030] Train loss: 0.0199
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[019/030] Train loss: 0.0201
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:46:10 | Train | Epoch[598/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:46:11 | Train | Epoch[598/600] Iteration[022/030] Train loss: 0.0201
2023-02-06 11:46:11 | Train | Epoch[598/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:46:11 | Train | Epoch[598/600] Iteration[024/030] Train loss: 0.0199
2023-02-06 11:46:11 | Train | Epoch[598/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:46:11 | Train | Epoch[598/600] Iteration[026/030] Train loss: 0.0200
2023-02-06 11:46:11 | Train | Epoch[598/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:46:11 | Train | Epoch[598/600] Iteration[028/030] Train loss: 0.0200
2023-02-06 11:46:11 | Train | Epoch[598/600] Iteration[029/030] Train loss: 0.0200
2023-02-06 11:46:11 | Train | Epoch[598/600] Iteration[030/030] Train loss: 0.0199
2023-02-06 11:46:11 | Valid | Epoch[598/600] Iteration[001/008] Valid loss: 0.0526
2023-02-06 11:46:11 | Valid | Epoch[598/600] Iteration[002/008] Valid loss: 0.0389
2023-02-06 11:46:11 | Valid | Epoch[598/600] Iteration[003/008] Valid loss: 0.0349
2023-02-06 11:46:11 | Valid | Epoch[598/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 11:46:11 | Valid | Epoch[598/600] Iteration[005/008] Valid loss: 0.0345
2023-02-06 11:46:11 | Valid | Epoch[598/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 11:46:11 | Valid | Epoch[598/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 11:46:11 | Valid | Epoch[598/600] Iteration[008/008] Valid loss: 0.0338
2023-02-06 11:46:12 | Valid | Epoch[598/600] MIou: 0.9284752699612286
2023-02-06 11:46:12 | Valid | Epoch[598/600] Pixel Accuracy: 0.988043467203776
2023-02-06 11:46:12 | Valid | Epoch[598/600] Mean Pixel Accuracy: 0.941873805776684
2023-02-06 11:46:12 | Stage | Epoch[598/600] Train loss:0.0199
2023-02-06 11:46:12 | Stage | Epoch[598/600] Valid loss:0.0338
2023-02-06 11:46:12 | Stage | Epoch[598/600] LR:0.0001

2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[001/030] Train loss: 0.0206
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[002/030] Train loss: 0.0187
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[003/030] Train loss: 0.0184
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[004/030] Train loss: 0.0186
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[005/030] Train loss: 0.0186
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[006/030] Train loss: 0.0186
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[007/030] Train loss: 0.0191
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[008/030] Train loss: 0.0191
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[009/030] Train loss: 0.0189
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[010/030] Train loss: 0.0191
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[011/030] Train loss: 0.0194
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[012/030] Train loss: 0.0195
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[013/030] Train loss: 0.0196
2023-02-06 11:46:12 | Train | Epoch[599/600] Iteration[014/030] Train loss: 0.0199
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[015/030] Train loss: 0.0198
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[016/030] Train loss: 0.0200
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[017/030] Train loss: 0.0201
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[018/030] Train loss: 0.0202
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[019/030] Train loss: 0.0203
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[020/030] Train loss: 0.0202
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[021/030] Train loss: 0.0201
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[023/030] Train loss: 0.0201
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[024/030] Train loss: 0.0200
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[025/030] Train loss: 0.0200
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[027/030] Train loss: 0.0200
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[028/030] Train loss: 0.0201
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[029/030] Train loss: 0.0201
2023-02-06 11:46:13 | Train | Epoch[599/600] Iteration[030/030] Train loss: 0.0200
2023-02-06 11:46:14 | Valid | Epoch[599/600] Iteration[001/008] Valid loss: 0.0527
2023-02-06 11:46:14 | Valid | Epoch[599/600] Iteration[002/008] Valid loss: 0.0390
2023-02-06 11:46:14 | Valid | Epoch[599/600] Iteration[003/008] Valid loss: 0.0350
2023-02-06 11:46:14 | Valid | Epoch[599/600] Iteration[004/008] Valid loss: 0.0337
2023-02-06 11:46:14 | Valid | Epoch[599/600] Iteration[005/008] Valid loss: 0.0347
2023-02-06 11:46:14 | Valid | Epoch[599/600] Iteration[006/008] Valid loss: 0.0347
2023-02-06 11:46:14 | Valid | Epoch[599/600] Iteration[007/008] Valid loss: 0.0349
2023-02-06 11:46:14 | Valid | Epoch[599/600] Iteration[008/008] Valid loss: 0.0339
2023-02-06 11:46:14 | Valid | Epoch[599/600] MIou: 0.9283277518959447
2023-02-06 11:46:14 | Valid | Epoch[599/600] Pixel Accuracy: 0.9880154927571615
2023-02-06 11:46:14 | Valid | Epoch[599/600] Mean Pixel Accuracy: 0.9418584298277433
2023-02-06 11:46:14 | Stage | Epoch[599/600] Train loss:0.0200
2023-02-06 11:46:14 | Stage | Epoch[599/600] Valid loss:0.0339
2023-02-06 11:46:14 | Stage | Epoch[599/600] LR:0.0001

2023-02-06 11:46:14 | Train | Epoch[600/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 11:46:14 | Train | Epoch[600/600] Iteration[002/030] Train loss: 0.0210
2023-02-06 11:46:14 | Train | Epoch[600/600] Iteration[003/030] Train loss: 0.0198
2023-02-06 11:46:14 | Train | Epoch[600/600] Iteration[004/030] Train loss: 0.0206
2023-02-06 11:46:14 | Train | Epoch[600/600] Iteration[005/030] Train loss: 0.0207
2023-02-06 11:46:14 | Train | Epoch[600/600] Iteration[006/030] Train loss: 0.0208
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[007/030] Train loss: 0.0212
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[008/030] Train loss: 0.0210
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[009/030] Train loss: 0.0207
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[010/030] Train loss: 0.0203
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[011/030] Train loss: 0.0200
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[012/030] Train loss: 0.0198
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[013/030] Train loss: 0.0200
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[014/030] Train loss: 0.0202
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[015/030] Train loss: 0.0200
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[016/030] Train loss: 0.0198
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[017/030] Train loss: 0.0200
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[018/030] Train loss: 0.0200
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[019/030] Train loss: 0.0200
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[020/030] Train loss: 0.0201
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[021/030] Train loss: 0.0202
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[022/030] Train loss: 0.0203
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[023/030] Train loss: 0.0202
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[024/030] Train loss: 0.0203
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[025/030] Train loss: 0.0202
2023-02-06 11:46:15 | Train | Epoch[600/600] Iteration[026/030] Train loss: 0.0201
2023-02-06 11:46:16 | Train | Epoch[600/600] Iteration[027/030] Train loss: 0.0202
2023-02-06 11:46:16 | Train | Epoch[600/600] Iteration[028/030] Train loss: 0.0202
2023-02-06 11:46:16 | Train | Epoch[600/600] Iteration[029/030] Train loss: 0.0202
2023-02-06 11:46:16 | Train | Epoch[600/600] Iteration[030/030] Train loss: 0.0201
2023-02-06 11:46:16 | Valid | Epoch[600/600] Iteration[001/008] Valid loss: 0.0503
2023-02-06 11:46:16 | Valid | Epoch[600/600] Iteration[002/008] Valid loss: 0.0378
2023-02-06 11:46:16 | Valid | Epoch[600/600] Iteration[003/008] Valid loss: 0.0342
2023-02-06 11:46:16 | Valid | Epoch[600/600] Iteration[004/008] Valid loss: 0.0328
2023-02-06 11:46:16 | Valid | Epoch[600/600] Iteration[005/008] Valid loss: 0.0337
2023-02-06 11:46:16 | Valid | Epoch[600/600] Iteration[006/008] Valid loss: 0.0336
2023-02-06 11:46:16 | Valid | Epoch[600/600] Iteration[007/008] Valid loss: 0.0337
2023-02-06 11:46:16 | Valid | Epoch[600/600] Iteration[008/008] Valid loss: 0.0329
2023-02-06 11:46:16 | Valid | Epoch[600/600] MIou: 0.9257967141361125
2023-02-06 11:46:16 | Valid | Epoch[600/600] Pixel Accuracy: 0.9876149495442709
2023-02-06 11:46:16 | Valid | Epoch[600/600] Mean Pixel Accuracy: 0.9386899549420666
2023-02-06 11:46:16 | Stage | Epoch[600/600] Train loss:0.0201
2023-02-06 11:46:16 | Stage | Epoch[600/600] Valid loss:0.0329
2023-02-06 11:46:16 | Stage | Epoch[600/600] LR:0.0001

2023-02-06 11:46:16 | Final | Model training completed!!!
2023-02-06 11:46:16 | Final | Start time: 2023-02-06 11:23:14
2023-02-06 11:46:16 | Final | End time: 2023-02-06 11:46:16
2023-02-06 11:46:16 | Final | Spend time: 1381s
2023-02-06 11:46:16 | Final | Final epoch is 600
2023-02-06 11:46:16 | Final | Each epoch spend 2.3016666666666667s
