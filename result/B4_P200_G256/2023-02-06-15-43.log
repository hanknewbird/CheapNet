2023-02-06 15:43:05 | Start | Model starts training!!!

2023-02-06 15:43:22 | Train | Epoch[001/200] Iteration[001/030] Train loss: 0.8841
2023-02-06 15:43:22 | Train | Epoch[001/200] Iteration[002/030] Train loss: 0.8577
2023-02-06 15:43:23 | Train | Epoch[001/200] Iteration[003/030] Train loss: 0.8465
2023-02-06 15:43:23 | Train | Epoch[001/200] Iteration[004/030] Train loss: 0.8402
2023-02-06 15:43:24 | Train | Epoch[001/200] Iteration[005/030] Train loss: 0.8334
2023-02-06 15:43:24 | Train | Epoch[001/200] Iteration[006/030] Train loss: 0.8295
2023-02-06 15:43:25 | Train | Epoch[001/200] Iteration[007/030] Train loss: 0.8235
2023-02-06 15:43:25 | Train | Epoch[001/200] Iteration[008/030] Train loss: 0.8188
2023-02-06 15:43:26 | Train | Epoch[001/200] Iteration[009/030] Train loss: 0.8129
2023-02-06 15:43:26 | Train | Epoch[001/200] Iteration[010/030] Train loss: 0.8076
2023-02-06 15:43:26 | Train | Epoch[001/200] Iteration[011/030] Train loss: 0.8028
2023-02-06 15:43:27 | Train | Epoch[001/200] Iteration[012/030] Train loss: 0.7974
2023-02-06 15:43:27 | Train | Epoch[001/200] Iteration[013/030] Train loss: 0.7910
2023-02-06 15:43:28 | Train | Epoch[001/200] Iteration[014/030] Train loss: 0.7857
2023-02-06 15:43:28 | Train | Epoch[001/200] Iteration[015/030] Train loss: 0.7793
2023-02-06 15:43:29 | Train | Epoch[001/200] Iteration[016/030] Train loss: 0.7737
2023-02-06 15:43:29 | Train | Epoch[001/200] Iteration[017/030] Train loss: 0.7683
2023-02-06 15:43:29 | Train | Epoch[001/200] Iteration[018/030] Train loss: 0.7633
2023-02-06 15:43:30 | Train | Epoch[001/200] Iteration[019/030] Train loss: 0.7588
2023-02-06 15:43:30 | Train | Epoch[001/200] Iteration[020/030] Train loss: 0.7541
2023-02-06 15:43:31 | Train | Epoch[001/200] Iteration[021/030] Train loss: 0.7490
2023-02-06 15:43:31 | Train | Epoch[001/200] Iteration[022/030] Train loss: 0.7446
2023-02-06 15:43:32 | Train | Epoch[001/200] Iteration[023/030] Train loss: 0.7402
2023-02-06 15:43:32 | Train | Epoch[001/200] Iteration[024/030] Train loss: 0.7360
2023-02-06 15:43:32 | Train | Epoch[001/200] Iteration[025/030] Train loss: 0.7323
2023-02-06 15:43:33 | Train | Epoch[001/200] Iteration[026/030] Train loss: 0.7288
2023-02-06 15:43:33 | Train | Epoch[001/200] Iteration[027/030] Train loss: 0.7252
2023-02-06 15:43:34 | Train | Epoch[001/200] Iteration[028/030] Train loss: 0.7218
2023-02-06 15:43:34 | Train | Epoch[001/200] Iteration[029/030] Train loss: 0.7185
2023-02-06 15:43:34 | Train | Epoch[001/200] Iteration[030/030] Train loss: 0.7156
2023-02-06 15:43:35 | Valid | Epoch[001/200] Iteration[001/008] Valid loss: 0.6485
2023-02-06 15:43:35 | Valid | Epoch[001/200] Iteration[002/008] Valid loss: 0.6469
2023-02-06 15:43:35 | Valid | Epoch[001/200] Iteration[003/008] Valid loss: 0.6469
2023-02-06 15:43:35 | Valid | Epoch[001/200] Iteration[004/008] Valid loss: 0.6470
2023-02-06 15:43:35 | Valid | Epoch[001/200] Iteration[005/008] Valid loss: 0.6468
2023-02-06 15:43:35 | Valid | Epoch[001/200] Iteration[006/008] Valid loss: 0.6471
2023-02-06 15:43:35 | Valid | Epoch[001/200] Iteration[007/008] Valid loss: 0.6472
2023-02-06 15:43:36 | Valid | Epoch[001/200] Iteration[008/008] Valid loss: 0.6468
2023-02-06 15:43:36 | Valid | Epoch[001/200] MIou: 0.6516499309238467
2023-02-06 15:43:36 | Valid | Epoch[001/200] Pixel Accuracy: 0.9405670166015625
2023-02-06 15:43:36 | Valid | Epoch[001/200] Mean Pixel Accuracy: 0.6871983852220729
2023-02-06 15:43:36 | Stage | Epoch[001/200] Train loss:0.7156
2023-02-06 15:43:36 | Stage | Epoch[001/200] Valid loss:0.6468
2023-02-06 15:43:36 | Stage | Epoch[001/200] LR:0.01

2023-02-06 15:43:37 | Train | Epoch[002/200] Iteration[001/030] Train loss: 0.6252
2023-02-06 15:43:37 | Train | Epoch[002/200] Iteration[002/030] Train loss: 0.6281
2023-02-06 15:43:37 | Train | Epoch[002/200] Iteration[003/030] Train loss: 0.6258
2023-02-06 15:43:38 | Train | Epoch[002/200] Iteration[004/030] Train loss: 0.6252
2023-02-06 15:43:38 | Train | Epoch[002/200] Iteration[005/030] Train loss: 0.6244
2023-02-06 15:43:39 | Train | Epoch[002/200] Iteration[006/030] Train loss: 0.6242
2023-02-06 15:43:39 | Train | Epoch[002/200] Iteration[007/030] Train loss: 0.6229
2023-02-06 15:43:40 | Train | Epoch[002/200] Iteration[008/030] Train loss: 0.6222
2023-02-06 15:43:40 | Train | Epoch[002/200] Iteration[009/030] Train loss: 0.6220
2023-02-06 15:43:40 | Train | Epoch[002/200] Iteration[010/030] Train loss: 0.6213
2023-02-06 15:43:41 | Train | Epoch[002/200] Iteration[011/030] Train loss: 0.6205
2023-02-06 15:43:41 | Train | Epoch[002/200] Iteration[012/030] Train loss: 0.6198
2023-02-06 15:43:42 | Train | Epoch[002/200] Iteration[013/030] Train loss: 0.6192
2023-02-06 15:43:42 | Train | Epoch[002/200] Iteration[014/030] Train loss: 0.6185
2023-02-06 15:43:43 | Train | Epoch[002/200] Iteration[015/030] Train loss: 0.6183
2023-02-06 15:43:43 | Train | Epoch[002/200] Iteration[016/030] Train loss: 0.6176
2023-02-06 15:43:43 | Train | Epoch[002/200] Iteration[017/030] Train loss: 0.6171
2023-02-06 15:43:44 | Train | Epoch[002/200] Iteration[018/030] Train loss: 0.6164
2023-02-06 15:43:44 | Train | Epoch[002/200] Iteration[019/030] Train loss: 0.6160
2023-02-06 15:43:45 | Train | Epoch[002/200] Iteration[020/030] Train loss: 0.6154
2023-02-06 15:43:45 | Train | Epoch[002/200] Iteration[021/030] Train loss: 0.6148
2023-02-06 15:43:46 | Train | Epoch[002/200] Iteration[022/030] Train loss: 0.6144
2023-02-06 15:43:46 | Train | Epoch[002/200] Iteration[023/030] Train loss: 0.6139
2023-02-06 15:43:46 | Train | Epoch[002/200] Iteration[024/030] Train loss: 0.6136
2023-02-06 15:43:47 | Train | Epoch[002/200] Iteration[025/030] Train loss: 0.6132
2023-02-06 15:43:47 | Train | Epoch[002/200] Iteration[026/030] Train loss: 0.6129
2023-02-06 15:43:48 | Train | Epoch[002/200] Iteration[027/030] Train loss: 0.6125
2023-02-06 15:43:48 | Train | Epoch[002/200] Iteration[028/030] Train loss: 0.6120
2023-02-06 15:43:49 | Train | Epoch[002/200] Iteration[029/030] Train loss: 0.6117
2023-02-06 15:43:49 | Train | Epoch[002/200] Iteration[030/030] Train loss: 0.6112
2023-02-06 15:43:49 | Valid | Epoch[002/200] Iteration[001/008] Valid loss: 0.6234
2023-02-06 15:43:49 | Valid | Epoch[002/200] Iteration[002/008] Valid loss: 0.6220
2023-02-06 15:43:50 | Valid | Epoch[002/200] Iteration[003/008] Valid loss: 0.6216
2023-02-06 15:43:50 | Valid | Epoch[002/200] Iteration[004/008] Valid loss: 0.6214
2023-02-06 15:43:50 | Valid | Epoch[002/200] Iteration[005/008] Valid loss: 0.6212
2023-02-06 15:43:50 | Valid | Epoch[002/200] Iteration[006/008] Valid loss: 0.6213
2023-02-06 15:43:50 | Valid | Epoch[002/200] Iteration[007/008] Valid loss: 0.6213
2023-02-06 15:43:50 | Valid | Epoch[002/200] Iteration[008/008] Valid loss: 0.6210
2023-02-06 15:43:50 | Valid | Epoch[002/200] MIou: 0.7547758619538383
2023-02-06 15:43:50 | Valid | Epoch[002/200] Pixel Accuracy: 0.9592997233072916
2023-02-06 15:43:50 | Valid | Epoch[002/200] Mean Pixel Accuracy: 0.7777396872150416
2023-02-06 15:43:50 | Stage | Epoch[002/200] Train loss:0.6112
2023-02-06 15:43:50 | Stage | Epoch[002/200] Valid loss:0.6210
2023-02-06 15:43:50 | Stage | Epoch[002/200] LR:0.01

2023-02-06 15:43:51 | Train | Epoch[003/200] Iteration[001/030] Train loss: 0.5969
2023-02-06 15:43:51 | Train | Epoch[003/200] Iteration[002/030] Train loss: 0.5996
2023-02-06 15:43:52 | Train | Epoch[003/200] Iteration[003/030] Train loss: 0.5992
2023-02-06 15:43:52 | Train | Epoch[003/200] Iteration[004/030] Train loss: 0.5990
2023-02-06 15:43:53 | Train | Epoch[003/200] Iteration[005/030] Train loss: 0.5986
2023-02-06 15:43:53 | Train | Epoch[003/200] Iteration[006/030] Train loss: 0.5976
2023-02-06 15:43:53 | Train | Epoch[003/200] Iteration[007/030] Train loss: 0.5970
2023-02-06 15:43:54 | Train | Epoch[003/200] Iteration[008/030] Train loss: 0.5971
2023-02-06 15:43:54 | Train | Epoch[003/200] Iteration[009/030] Train loss: 0.5967
2023-02-06 15:43:55 | Train | Epoch[003/200] Iteration[010/030] Train loss: 0.5960
2023-02-06 15:43:55 | Train | Epoch[003/200] Iteration[011/030] Train loss: 0.5958
2023-02-06 15:43:56 | Train | Epoch[003/200] Iteration[012/030] Train loss: 0.5955
2023-02-06 15:43:56 | Train | Epoch[003/200] Iteration[013/030] Train loss: 0.5953
2023-02-06 15:43:56 | Train | Epoch[003/200] Iteration[014/030] Train loss: 0.5952
2023-02-06 15:43:57 | Train | Epoch[003/200] Iteration[015/030] Train loss: 0.5949
2023-02-06 15:43:57 | Train | Epoch[003/200] Iteration[016/030] Train loss: 0.5947
2023-02-06 15:43:58 | Train | Epoch[003/200] Iteration[017/030] Train loss: 0.5944
2023-02-06 15:43:58 | Train | Epoch[003/200] Iteration[018/030] Train loss: 0.5940
2023-02-06 15:43:59 | Train | Epoch[003/200] Iteration[019/030] Train loss: 0.5938
2023-02-06 15:43:59 | Train | Epoch[003/200] Iteration[020/030] Train loss: 0.5934
2023-02-06 15:43:59 | Train | Epoch[003/200] Iteration[021/030] Train loss: 0.5931
2023-02-06 15:44:00 | Train | Epoch[003/200] Iteration[022/030] Train loss: 0.5930
2023-02-06 15:44:00 | Train | Epoch[003/200] Iteration[023/030] Train loss: 0.5926
2023-02-06 15:44:01 | Train | Epoch[003/200] Iteration[024/030] Train loss: 0.5923
2023-02-06 15:44:01 | Train | Epoch[003/200] Iteration[025/030] Train loss: 0.5920
2023-02-06 15:44:02 | Train | Epoch[003/200] Iteration[026/030] Train loss: 0.5916
2023-02-06 15:44:02 | Train | Epoch[003/200] Iteration[027/030] Train loss: 0.5917
2023-02-06 15:44:03 | Train | Epoch[003/200] Iteration[028/030] Train loss: 0.5914
2023-02-06 15:44:03 | Train | Epoch[003/200] Iteration[029/030] Train loss: 0.5911
2023-02-06 15:44:03 | Train | Epoch[003/200] Iteration[030/030] Train loss: 0.5907
2023-02-06 15:44:04 | Valid | Epoch[003/200] Iteration[001/008] Valid loss: 0.5959
2023-02-06 15:44:04 | Valid | Epoch[003/200] Iteration[002/008] Valid loss: 0.5944
2023-02-06 15:44:04 | Valid | Epoch[003/200] Iteration[003/008] Valid loss: 0.5935
2023-02-06 15:44:04 | Valid | Epoch[003/200] Iteration[004/008] Valid loss: 0.5931
2023-02-06 15:44:04 | Valid | Epoch[003/200] Iteration[005/008] Valid loss: 0.5926
2023-02-06 15:44:04 | Valid | Epoch[003/200] Iteration[006/008] Valid loss: 0.5926
2023-02-06 15:44:04 | Valid | Epoch[003/200] Iteration[007/008] Valid loss: 0.5926
2023-02-06 15:44:04 | Valid | Epoch[003/200] Iteration[008/008] Valid loss: 0.5919
2023-02-06 15:44:04 | Valid | Epoch[003/200] MIou: 0.8525241176864954
2023-02-06 15:44:04 | Valid | Epoch[003/200] Pixel Accuracy: 0.9745801289876302
2023-02-06 15:44:04 | Valid | Epoch[003/200] Mean Pixel Accuracy: 0.8825262977971331
2023-02-06 15:44:04 | Stage | Epoch[003/200] Train loss:0.5907
2023-02-06 15:44:04 | Stage | Epoch[003/200] Valid loss:0.5919
2023-02-06 15:44:04 | Stage | Epoch[003/200] LR:0.01

2023-02-06 15:44:05 | Train | Epoch[004/200] Iteration[001/030] Train loss: 0.5794
2023-02-06 15:44:06 | Train | Epoch[004/200] Iteration[002/030] Train loss: 0.5791
2023-02-06 15:44:06 | Train | Epoch[004/200] Iteration[003/030] Train loss: 0.5785
2023-02-06 15:44:07 | Train | Epoch[004/200] Iteration[004/030] Train loss: 0.5783
2023-02-06 15:44:07 | Train | Epoch[004/200] Iteration[005/030] Train loss: 0.5775
2023-02-06 15:44:07 | Train | Epoch[004/200] Iteration[006/030] Train loss: 0.5775
2023-02-06 15:44:08 | Train | Epoch[004/200] Iteration[007/030] Train loss: 0.5778
2023-02-06 15:44:08 | Train | Epoch[004/200] Iteration[008/030] Train loss: 0.5778
2023-02-06 15:44:09 | Train | Epoch[004/200] Iteration[009/030] Train loss: 0.5772
2023-02-06 15:44:09 | Train | Epoch[004/200] Iteration[010/030] Train loss: 0.5768
2023-02-06 15:44:10 | Train | Epoch[004/200] Iteration[011/030] Train loss: 0.5767
2023-02-06 15:44:10 | Train | Epoch[004/200] Iteration[012/030] Train loss: 0.5764
2023-02-06 15:44:10 | Train | Epoch[004/200] Iteration[013/030] Train loss: 0.5759
2023-02-06 15:44:11 | Train | Epoch[004/200] Iteration[014/030] Train loss: 0.5757
2023-02-06 15:44:11 | Train | Epoch[004/200] Iteration[015/030] Train loss: 0.5755
2023-02-06 15:44:12 | Train | Epoch[004/200] Iteration[016/030] Train loss: 0.5750
2023-02-06 15:44:12 | Train | Epoch[004/200] Iteration[017/030] Train loss: 0.5745
2023-02-06 15:44:13 | Train | Epoch[004/200] Iteration[018/030] Train loss: 0.5741
2023-02-06 15:44:13 | Train | Epoch[004/200] Iteration[019/030] Train loss: 0.5739
2023-02-06 15:44:13 | Train | Epoch[004/200] Iteration[020/030] Train loss: 0.5736
2023-02-06 15:44:14 | Train | Epoch[004/200] Iteration[021/030] Train loss: 0.5732
2023-02-06 15:44:14 | Train | Epoch[004/200] Iteration[022/030] Train loss: 0.5729
2023-02-06 15:44:15 | Train | Epoch[004/200] Iteration[023/030] Train loss: 0.5726
2023-02-06 15:44:15 | Train | Epoch[004/200] Iteration[024/030] Train loss: 0.5722
2023-02-06 15:44:16 | Train | Epoch[004/200] Iteration[025/030] Train loss: 0.5721
2023-02-06 15:44:16 | Train | Epoch[004/200] Iteration[026/030] Train loss: 0.5719
2023-02-06 15:44:17 | Train | Epoch[004/200] Iteration[027/030] Train loss: 0.5717
2023-02-06 15:44:17 | Train | Epoch[004/200] Iteration[028/030] Train loss: 0.5713
2023-02-06 15:44:17 | Train | Epoch[004/200] Iteration[029/030] Train loss: 0.5711
2023-02-06 15:44:18 | Train | Epoch[004/200] Iteration[030/030] Train loss: 0.5707
2023-02-06 15:44:18 | Valid | Epoch[004/200] Iteration[001/008] Valid loss: 0.5934
2023-02-06 15:44:18 | Valid | Epoch[004/200] Iteration[002/008] Valid loss: 0.5927
2023-02-06 15:44:18 | Valid | Epoch[004/200] Iteration[003/008] Valid loss: 0.5930
2023-02-06 15:44:18 | Valid | Epoch[004/200] Iteration[004/008] Valid loss: 0.5927
2023-02-06 15:44:18 | Valid | Epoch[004/200] Iteration[005/008] Valid loss: 0.5930
2023-02-06 15:44:19 | Valid | Epoch[004/200] Iteration[006/008] Valid loss: 0.5930
2023-02-06 15:44:19 | Valid | Epoch[004/200] Iteration[007/008] Valid loss: 0.5930
2023-02-06 15:44:19 | Valid | Epoch[004/200] Iteration[008/008] Valid loss: 0.5931
2023-02-06 15:44:19 | Valid | Epoch[004/200] MIou: 0.6283900239795874
2023-02-06 15:44:19 | Valid | Epoch[004/200] Pixel Accuracy: 0.9385833740234375
2023-02-06 15:44:19 | Valid | Epoch[004/200] Mean Pixel Accuracy: 0.6600170503886172
2023-02-06 15:44:19 | Stage | Epoch[004/200] Train loss:0.5707
2023-02-06 15:44:19 | Stage | Epoch[004/200] Valid loss:0.5931
2023-02-06 15:44:19 | Stage | Epoch[004/200] LR:0.01

2023-02-06 15:44:20 | Train | Epoch[005/200] Iteration[001/030] Train loss: 0.5587
2023-02-06 15:44:20 | Train | Epoch[005/200] Iteration[002/030] Train loss: 0.5605
2023-02-06 15:44:20 | Train | Epoch[005/200] Iteration[003/030] Train loss: 0.5587
2023-02-06 15:44:21 | Train | Epoch[005/200] Iteration[004/030] Train loss: 0.5578
2023-02-06 15:44:21 | Train | Epoch[005/200] Iteration[005/030] Train loss: 0.5572
2023-02-06 15:44:22 | Train | Epoch[005/200] Iteration[006/030] Train loss: 0.5575
2023-02-06 15:44:22 | Train | Epoch[005/200] Iteration[007/030] Train loss: 0.5571
2023-02-06 15:44:23 | Train | Epoch[005/200] Iteration[008/030] Train loss: 0.5563
2023-02-06 15:44:23 | Train | Epoch[005/200] Iteration[009/030] Train loss: 0.5564
2023-02-06 15:44:23 | Train | Epoch[005/200] Iteration[010/030] Train loss: 0.5560
2023-02-06 15:44:24 | Train | Epoch[005/200] Iteration[011/030] Train loss: 0.5563
2023-02-06 15:44:24 | Train | Epoch[005/200] Iteration[012/030] Train loss: 0.5558
2023-02-06 15:44:25 | Train | Epoch[005/200] Iteration[013/030] Train loss: 0.5558
2023-02-06 15:44:25 | Train | Epoch[005/200] Iteration[014/030] Train loss: 0.5558
2023-02-06 15:44:26 | Train | Epoch[005/200] Iteration[015/030] Train loss: 0.5557
2023-02-06 15:44:26 | Train | Epoch[005/200] Iteration[016/030] Train loss: 0.5556
2023-02-06 15:44:26 | Train | Epoch[005/200] Iteration[017/030] Train loss: 0.5552
2023-02-06 15:44:27 | Train | Epoch[005/200] Iteration[018/030] Train loss: 0.5549
2023-02-06 15:44:27 | Train | Epoch[005/200] Iteration[019/030] Train loss: 0.5546
2023-02-06 15:44:28 | Train | Epoch[005/200] Iteration[020/030] Train loss: 0.5543
2023-02-06 15:44:28 | Train | Epoch[005/200] Iteration[021/030] Train loss: 0.5539
2023-02-06 15:44:29 | Train | Epoch[005/200] Iteration[022/030] Train loss: 0.5536
2023-02-06 15:44:29 | Train | Epoch[005/200] Iteration[023/030] Train loss: 0.5532
2023-02-06 15:44:30 | Train | Epoch[005/200] Iteration[024/030] Train loss: 0.5530
2023-02-06 15:44:30 | Train | Epoch[005/200] Iteration[025/030] Train loss: 0.5527
2023-02-06 15:44:30 | Train | Epoch[005/200] Iteration[026/030] Train loss: 0.5523
2023-02-06 15:44:31 | Train | Epoch[005/200] Iteration[027/030] Train loss: 0.5521
2023-02-06 15:44:31 | Train | Epoch[005/200] Iteration[028/030] Train loss: 0.5516
2023-02-06 15:44:32 | Train | Epoch[005/200] Iteration[029/030] Train loss: 0.5513
2023-02-06 15:44:32 | Train | Epoch[005/200] Iteration[030/030] Train loss: 0.5513
2023-02-06 15:44:32 | Valid | Epoch[005/200] Iteration[001/008] Valid loss: 0.5434
2023-02-06 15:44:32 | Valid | Epoch[005/200] Iteration[002/008] Valid loss: 0.5433
2023-02-06 15:44:33 | Valid | Epoch[005/200] Iteration[003/008] Valid loss: 0.5421
2023-02-06 15:44:33 | Valid | Epoch[005/200] Iteration[004/008] Valid loss: 0.5411
2023-02-06 15:44:33 | Valid | Epoch[005/200] Iteration[005/008] Valid loss: 0.5406
2023-02-06 15:44:33 | Valid | Epoch[005/200] Iteration[006/008] Valid loss: 0.5405
2023-02-06 15:44:33 | Valid | Epoch[005/200] Iteration[007/008] Valid loss: 0.5408
2023-02-06 15:44:33 | Valid | Epoch[005/200] Iteration[008/008] Valid loss: 0.5402
2023-02-06 15:44:33 | Valid | Epoch[005/200] MIou: 0.898082329767887
2023-02-06 15:44:33 | Valid | Epoch[005/200] Pixel Accuracy: 0.9809710184733073
2023-02-06 15:44:33 | Valid | Epoch[005/200] Mean Pixel Accuracy: 0.9626826228613262
2023-02-06 15:44:33 | Stage | Epoch[005/200] Train loss:0.5513
2023-02-06 15:44:33 | Stage | Epoch[005/200] Valid loss:0.5402
2023-02-06 15:44:33 | Stage | Epoch[005/200] LR:0.01

2023-02-06 15:44:34 | Train | Epoch[006/200] Iteration[001/030] Train loss: 0.5419
2023-02-06 15:44:34 | Train | Epoch[006/200] Iteration[002/030] Train loss: 0.5441
2023-02-06 15:44:35 | Train | Epoch[006/200] Iteration[003/030] Train loss: 0.5429
2023-02-06 15:44:35 | Train | Epoch[006/200] Iteration[004/030] Train loss: 0.5417
2023-02-06 15:44:36 | Train | Epoch[006/200] Iteration[005/030] Train loss: 0.5412
2023-02-06 15:44:36 | Train | Epoch[006/200] Iteration[006/030] Train loss: 0.5402
2023-02-06 15:44:36 | Train | Epoch[006/200] Iteration[007/030] Train loss: 0.5393
2023-02-06 15:44:37 | Train | Epoch[006/200] Iteration[008/030] Train loss: 0.5391
2023-02-06 15:44:37 | Train | Epoch[006/200] Iteration[009/030] Train loss: 0.5385
2023-02-06 15:44:38 | Train | Epoch[006/200] Iteration[010/030] Train loss: 0.5375
2023-02-06 15:44:38 | Train | Epoch[006/200] Iteration[011/030] Train loss: 0.5374
2023-02-06 15:44:39 | Train | Epoch[006/200] Iteration[012/030] Train loss: 0.5370
2023-02-06 15:44:39 | Train | Epoch[006/200] Iteration[013/030] Train loss: 0.5365
2023-02-06 15:44:39 | Train | Epoch[006/200] Iteration[014/030] Train loss: 0.5362
2023-02-06 15:44:40 | Train | Epoch[006/200] Iteration[015/030] Train loss: 0.5360
2023-02-06 15:44:40 | Train | Epoch[006/200] Iteration[016/030] Train loss: 0.5361
2023-02-06 15:44:41 | Train | Epoch[006/200] Iteration[017/030] Train loss: 0.5356
2023-02-06 15:44:41 | Train | Epoch[006/200] Iteration[018/030] Train loss: 0.5352
2023-02-06 15:44:42 | Train | Epoch[006/200] Iteration[019/030] Train loss: 0.5347
2023-02-06 15:44:42 | Train | Epoch[006/200] Iteration[020/030] Train loss: 0.5345
2023-02-06 15:44:42 | Train | Epoch[006/200] Iteration[021/030] Train loss: 0.5343
2023-02-06 15:44:43 | Train | Epoch[006/200] Iteration[022/030] Train loss: 0.5340
2023-02-06 15:44:43 | Train | Epoch[006/200] Iteration[023/030] Train loss: 0.5336
2023-02-06 15:44:44 | Train | Epoch[006/200] Iteration[024/030] Train loss: 0.5333
2023-02-06 15:44:44 | Train | Epoch[006/200] Iteration[025/030] Train loss: 0.5330
2023-02-06 15:44:45 | Train | Epoch[006/200] Iteration[026/030] Train loss: 0.5326
2023-02-06 15:44:45 | Train | Epoch[006/200] Iteration[027/030] Train loss: 0.5327
2023-02-06 15:44:45 | Train | Epoch[006/200] Iteration[028/030] Train loss: 0.5322
2023-02-06 15:44:46 | Train | Epoch[006/200] Iteration[029/030] Train loss: 0.5319
2023-02-06 15:44:46 | Train | Epoch[006/200] Iteration[030/030] Train loss: 0.5315
2023-02-06 15:44:47 | Valid | Epoch[006/200] Iteration[001/008] Valid loss: 0.5512
2023-02-06 15:44:47 | Valid | Epoch[006/200] Iteration[002/008] Valid loss: 0.5529
2023-02-06 15:44:47 | Valid | Epoch[006/200] Iteration[003/008] Valid loss: 0.5516
2023-02-06 15:44:47 | Valid | Epoch[006/200] Iteration[004/008] Valid loss: 0.5518
2023-02-06 15:44:47 | Valid | Epoch[006/200] Iteration[005/008] Valid loss: 0.5510
2023-02-06 15:44:47 | Valid | Epoch[006/200] Iteration[006/008] Valid loss: 0.5508
2023-02-06 15:44:47 | Valid | Epoch[006/200] Iteration[007/008] Valid loss: 0.5506
2023-02-06 15:44:47 | Valid | Epoch[006/200] Iteration[008/008] Valid loss: 0.5506
2023-02-06 15:44:47 | Valid | Epoch[006/200] MIou: 0.8548001845680959
2023-02-06 15:44:47 | Valid | Epoch[006/200] Pixel Accuracy: 0.9715054829915365
2023-02-06 15:44:47 | Valid | Epoch[006/200] Mean Pixel Accuracy: 0.9396759168593005
2023-02-06 15:44:47 | Stage | Epoch[006/200] Train loss:0.5315
2023-02-06 15:44:47 | Stage | Epoch[006/200] Valid loss:0.5506
2023-02-06 15:44:47 | Stage | Epoch[006/200] LR:0.01

2023-02-06 15:44:48 | Train | Epoch[007/200] Iteration[001/030] Train loss: 0.5260
2023-02-06 15:44:49 | Train | Epoch[007/200] Iteration[002/030] Train loss: 0.5243
2023-02-06 15:44:49 | Train | Epoch[007/200] Iteration[003/030] Train loss: 0.5226
2023-02-06 15:44:50 | Train | Epoch[007/200] Iteration[004/030] Train loss: 0.5209
2023-02-06 15:44:50 | Train | Epoch[007/200] Iteration[005/030] Train loss: 0.5204
2023-02-06 15:44:50 | Train | Epoch[007/200] Iteration[006/030] Train loss: 0.5210
2023-02-06 15:44:51 | Train | Epoch[007/200] Iteration[007/030] Train loss: 0.5200
2023-02-06 15:44:51 | Train | Epoch[007/200] Iteration[008/030] Train loss: 0.5196
2023-02-06 15:44:52 | Train | Epoch[007/200] Iteration[009/030] Train loss: 0.5194
2023-02-06 15:44:52 | Train | Epoch[007/200] Iteration[010/030] Train loss: 0.5188
2023-02-06 15:44:53 | Train | Epoch[007/200] Iteration[011/030] Train loss: 0.5184
2023-02-06 15:44:53 | Train | Epoch[007/200] Iteration[012/030] Train loss: 0.5178
2023-02-06 15:44:53 | Train | Epoch[007/200] Iteration[013/030] Train loss: 0.5174
2023-02-06 15:44:54 | Train | Epoch[007/200] Iteration[014/030] Train loss: 0.5169
2023-02-06 15:44:54 | Train | Epoch[007/200] Iteration[015/030] Train loss: 0.5164
2023-02-06 15:44:55 | Train | Epoch[007/200] Iteration[016/030] Train loss: 0.5160
2023-02-06 15:44:55 | Train | Epoch[007/200] Iteration[017/030] Train loss: 0.5155
2023-02-06 15:44:56 | Train | Epoch[007/200] Iteration[018/030] Train loss: 0.5153
2023-02-06 15:44:56 | Train | Epoch[007/200] Iteration[019/030] Train loss: 0.5150
2023-02-06 15:44:56 | Train | Epoch[007/200] Iteration[020/030] Train loss: 0.5145
2023-02-06 15:44:57 | Train | Epoch[007/200] Iteration[021/030] Train loss: 0.5144
2023-02-06 15:44:57 | Train | Epoch[007/200] Iteration[022/030] Train loss: 0.5140
2023-02-06 15:44:58 | Train | Epoch[007/200] Iteration[023/030] Train loss: 0.5137
2023-02-06 15:44:58 | Train | Epoch[007/200] Iteration[024/030] Train loss: 0.5133
2023-02-06 15:44:59 | Train | Epoch[007/200] Iteration[025/030] Train loss: 0.5130
2023-02-06 15:44:59 | Train | Epoch[007/200] Iteration[026/030] Train loss: 0.5127
2023-02-06 15:44:59 | Train | Epoch[007/200] Iteration[027/030] Train loss: 0.5124
2023-02-06 15:45:00 | Train | Epoch[007/200] Iteration[028/030] Train loss: 0.5122
2023-02-06 15:45:00 | Train | Epoch[007/200] Iteration[029/030] Train loss: 0.5121
2023-02-06 15:45:01 | Train | Epoch[007/200] Iteration[030/030] Train loss: 0.5116
2023-02-06 15:45:01 | Valid | Epoch[007/200] Iteration[001/008] Valid loss: 0.5115
2023-02-06 15:45:01 | Valid | Epoch[007/200] Iteration[002/008] Valid loss: 0.5122
2023-02-06 15:45:01 | Valid | Epoch[007/200] Iteration[003/008] Valid loss: 0.5107
2023-02-06 15:45:01 | Valid | Epoch[007/200] Iteration[004/008] Valid loss: 0.5098
2023-02-06 15:45:01 | Valid | Epoch[007/200] Iteration[005/008] Valid loss: 0.5094
2023-02-06 15:45:02 | Valid | Epoch[007/200] Iteration[006/008] Valid loss: 0.5095
2023-02-06 15:45:02 | Valid | Epoch[007/200] Iteration[007/008] Valid loss: 0.5098
2023-02-06 15:45:02 | Valid | Epoch[007/200] Iteration[008/008] Valid loss: 0.5090
2023-02-06 15:45:02 | Valid | Epoch[007/200] MIou: 0.9190649521318383
2023-02-06 15:45:02 | Valid | Epoch[007/200] Pixel Accuracy: 0.9851900736490885
2023-02-06 15:45:02 | Valid | Epoch[007/200] Mean Pixel Accuracy: 0.9746708145802085
2023-02-06 15:45:02 | Stage | Epoch[007/200] Train loss:0.5116
2023-02-06 15:45:02 | Stage | Epoch[007/200] Valid loss:0.5090
2023-02-06 15:45:02 | Stage | Epoch[007/200] LR:0.01

2023-02-06 15:45:03 | Train | Epoch[008/200] Iteration[001/030] Train loss: 0.5014
2023-02-06 15:45:03 | Train | Epoch[008/200] Iteration[002/030] Train loss: 0.5014
2023-02-06 15:45:04 | Train | Epoch[008/200] Iteration[003/030] Train loss: 0.5010
2023-02-06 15:45:04 | Train | Epoch[008/200] Iteration[004/030] Train loss: 0.5002
2023-02-06 15:45:04 | Train | Epoch[008/200] Iteration[005/030] Train loss: 0.5008
2023-02-06 15:45:05 | Train | Epoch[008/200] Iteration[006/030] Train loss: 0.5007
2023-02-06 15:45:05 | Train | Epoch[008/200] Iteration[007/030] Train loss: 0.5012
2023-02-06 15:45:06 | Train | Epoch[008/200] Iteration[008/030] Train loss: 0.5011
2023-02-06 15:45:06 | Train | Epoch[008/200] Iteration[009/030] Train loss: 0.5011
2023-02-06 15:45:07 | Train | Epoch[008/200] Iteration[010/030] Train loss: 0.5008
2023-02-06 15:45:07 | Train | Epoch[008/200] Iteration[011/030] Train loss: 0.5007
2023-02-06 15:45:07 | Train | Epoch[008/200] Iteration[012/030] Train loss: 0.5003
2023-02-06 15:45:08 | Train | Epoch[008/200] Iteration[013/030] Train loss: 0.4998
2023-02-06 15:45:08 | Train | Epoch[008/200] Iteration[014/030] Train loss: 0.4991
2023-02-06 15:45:09 | Train | Epoch[008/200] Iteration[015/030] Train loss: 0.4985
2023-02-06 15:45:09 | Train | Epoch[008/200] Iteration[016/030] Train loss: 0.4984
2023-02-06 15:45:10 | Train | Epoch[008/200] Iteration[017/030] Train loss: 0.4981
2023-02-06 15:45:10 | Train | Epoch[008/200] Iteration[018/030] Train loss: 0.4977
2023-02-06 15:45:10 | Train | Epoch[008/200] Iteration[019/030] Train loss: 0.4973
2023-02-06 15:45:11 | Train | Epoch[008/200] Iteration[020/030] Train loss: 0.4968
2023-02-06 15:45:11 | Train | Epoch[008/200] Iteration[021/030] Train loss: 0.4965
2023-02-06 15:45:12 | Train | Epoch[008/200] Iteration[022/030] Train loss: 0.4961
2023-02-06 15:45:12 | Train | Epoch[008/200] Iteration[023/030] Train loss: 0.4958
2023-02-06 15:45:13 | Train | Epoch[008/200] Iteration[024/030] Train loss: 0.4953
2023-02-06 15:45:13 | Train | Epoch[008/200] Iteration[025/030] Train loss: 0.4951
2023-02-06 15:45:13 | Train | Epoch[008/200] Iteration[026/030] Train loss: 0.4947
2023-02-06 15:45:14 | Train | Epoch[008/200] Iteration[027/030] Train loss: 0.4943
2023-02-06 15:45:14 | Train | Epoch[008/200] Iteration[028/030] Train loss: 0.4939
2023-02-06 15:45:15 | Train | Epoch[008/200] Iteration[029/030] Train loss: 0.4934
2023-02-06 15:45:15 | Train | Epoch[008/200] Iteration[030/030] Train loss: 0.4930
2023-02-06 15:45:15 | Valid | Epoch[008/200] Iteration[001/008] Valid loss: 0.5225
2023-02-06 15:45:16 | Valid | Epoch[008/200] Iteration[002/008] Valid loss: 0.5226
2023-02-06 15:45:16 | Valid | Epoch[008/200] Iteration[003/008] Valid loss: 0.5220
2023-02-06 15:45:16 | Valid | Epoch[008/200] Iteration[004/008] Valid loss: 0.5219
2023-02-06 15:45:16 | Valid | Epoch[008/200] Iteration[005/008] Valid loss: 0.5221
2023-02-06 15:45:16 | Valid | Epoch[008/200] Iteration[006/008] Valid loss: 0.5224
2023-02-06 15:45:16 | Valid | Epoch[008/200] Iteration[007/008] Valid loss: 0.5240
2023-02-06 15:45:16 | Valid | Epoch[008/200] Iteration[008/008] Valid loss: 0.5234
2023-02-06 15:45:16 | Valid | Epoch[008/200] MIou: 0.8391160022453047
2023-02-06 15:45:16 | Valid | Epoch[008/200] Pixel Accuracy: 0.9648056030273438
2023-02-06 15:45:16 | Valid | Epoch[008/200] Mean Pixel Accuracy: 0.974632210482625
2023-02-06 15:45:16 | Stage | Epoch[008/200] Train loss:0.4930
2023-02-06 15:45:16 | Stage | Epoch[008/200] Valid loss:0.5234
2023-02-06 15:45:16 | Stage | Epoch[008/200] LR:0.01

2023-02-06 15:45:17 | Train | Epoch[009/200] Iteration[001/030] Train loss: 0.4800
2023-02-06 15:45:17 | Train | Epoch[009/200] Iteration[002/030] Train loss: 0.4816
2023-02-06 15:45:18 | Train | Epoch[009/200] Iteration[003/030] Train loss: 0.4807
2023-02-06 15:45:18 | Train | Epoch[009/200] Iteration[004/030] Train loss: 0.4803
2023-02-06 15:45:19 | Train | Epoch[009/200] Iteration[005/030] Train loss: 0.4813
2023-02-06 15:45:19 | Train | Epoch[009/200] Iteration[006/030] Train loss: 0.4807
2023-02-06 15:45:19 | Train | Epoch[009/200] Iteration[007/030] Train loss: 0.4808
2023-02-06 15:45:20 | Train | Epoch[009/200] Iteration[008/030] Train loss: 0.4810
2023-02-06 15:45:20 | Train | Epoch[009/200] Iteration[009/030] Train loss: 0.4806
2023-02-06 15:45:21 | Train | Epoch[009/200] Iteration[010/030] Train loss: 0.4799
2023-02-06 15:45:21 | Train | Epoch[009/200] Iteration[011/030] Train loss: 0.4795
2023-02-06 15:45:22 | Train | Epoch[009/200] Iteration[012/030] Train loss: 0.4794
2023-02-06 15:45:22 | Train | Epoch[009/200] Iteration[013/030] Train loss: 0.4800
2023-02-06 15:45:23 | Train | Epoch[009/200] Iteration[014/030] Train loss: 0.4796
2023-02-06 15:45:23 | Train | Epoch[009/200] Iteration[015/030] Train loss: 0.4794
2023-02-06 15:45:23 | Train | Epoch[009/200] Iteration[016/030] Train loss: 0.4790
2023-02-06 15:45:24 | Train | Epoch[009/200] Iteration[017/030] Train loss: 0.4788
2023-02-06 15:45:24 | Train | Epoch[009/200] Iteration[018/030] Train loss: 0.4783
2023-02-06 15:45:25 | Train | Epoch[009/200] Iteration[019/030] Train loss: 0.4778
2023-02-06 15:45:25 | Train | Epoch[009/200] Iteration[020/030] Train loss: 0.4774
2023-02-06 15:45:26 | Train | Epoch[009/200] Iteration[021/030] Train loss: 0.4770
2023-02-06 15:45:26 | Train | Epoch[009/200] Iteration[022/030] Train loss: 0.4764
2023-02-06 15:45:26 | Train | Epoch[009/200] Iteration[023/030] Train loss: 0.4764
2023-02-06 15:45:27 | Train | Epoch[009/200] Iteration[024/030] Train loss: 0.4762
2023-02-06 15:45:27 | Train | Epoch[009/200] Iteration[025/030] Train loss: 0.4759
2023-02-06 15:45:28 | Train | Epoch[009/200] Iteration[026/030] Train loss: 0.4756
2023-02-06 15:45:28 | Train | Epoch[009/200] Iteration[027/030] Train loss: 0.4754
2023-02-06 15:45:29 | Train | Epoch[009/200] Iteration[028/030] Train loss: 0.4749
2023-02-06 15:45:29 | Train | Epoch[009/200] Iteration[029/030] Train loss: 0.4749
2023-02-06 15:45:29 | Train | Epoch[009/200] Iteration[030/030] Train loss: 0.4746
2023-02-06 15:45:30 | Valid | Epoch[009/200] Iteration[001/008] Valid loss: 0.4912
2023-02-06 15:45:30 | Valid | Epoch[009/200] Iteration[002/008] Valid loss: 0.4914
2023-02-06 15:45:30 | Valid | Epoch[009/200] Iteration[003/008] Valid loss: 0.4907
2023-02-06 15:45:30 | Valid | Epoch[009/200] Iteration[004/008] Valid loss: 0.4900
2023-02-06 15:45:30 | Valid | Epoch[009/200] Iteration[005/008] Valid loss: 0.4900
2023-02-06 15:45:30 | Valid | Epoch[009/200] Iteration[006/008] Valid loss: 0.4901
2023-02-06 15:45:30 | Valid | Epoch[009/200] Iteration[007/008] Valid loss: 0.4912
2023-02-06 15:45:30 | Valid | Epoch[009/200] Iteration[008/008] Valid loss: 0.4905
2023-02-06 15:45:30 | Valid | Epoch[009/200] MIou: 0.8850638380554905
2023-02-06 15:45:30 | Valid | Epoch[009/200] Pixel Accuracy: 0.9774386088053385
2023-02-06 15:45:30 | Valid | Epoch[009/200] Mean Pixel Accuracy: 0.9731176602457619
2023-02-06 15:45:30 | Stage | Epoch[009/200] Train loss:0.4746
2023-02-06 15:45:30 | Stage | Epoch[009/200] Valid loss:0.4905
2023-02-06 15:45:30 | Stage | Epoch[009/200] LR:0.01

2023-02-06 15:45:31 | Train | Epoch[010/200] Iteration[001/030] Train loss: 0.4648
2023-02-06 15:45:32 | Train | Epoch[010/200] Iteration[002/030] Train loss: 0.4670
2023-02-06 15:45:32 | Train | Epoch[010/200] Iteration[003/030] Train loss: 0.4667
2023-02-06 15:45:33 | Train | Epoch[010/200] Iteration[004/030] Train loss: 0.4655
2023-02-06 15:45:33 | Train | Epoch[010/200] Iteration[005/030] Train loss: 0.4648
2023-02-06 15:45:33 | Train | Epoch[010/200] Iteration[006/030] Train loss: 0.4644
2023-02-06 15:45:34 | Train | Epoch[010/200] Iteration[007/030] Train loss: 0.4638
2023-02-06 15:45:34 | Train | Epoch[010/200] Iteration[008/030] Train loss: 0.4632
2023-02-06 15:45:35 | Train | Epoch[010/200] Iteration[009/030] Train loss: 0.4633
2023-02-06 15:45:35 | Train | Epoch[010/200] Iteration[010/030] Train loss: 0.4631
2023-02-06 15:45:36 | Train | Epoch[010/200] Iteration[011/030] Train loss: 0.4626
2023-02-06 15:45:36 | Train | Epoch[010/200] Iteration[012/030] Train loss: 0.4621
2023-02-06 15:45:36 | Train | Epoch[010/200] Iteration[013/030] Train loss: 0.4618
2023-02-06 15:45:37 | Train | Epoch[010/200] Iteration[014/030] Train loss: 0.4613
2023-02-06 15:45:37 | Train | Epoch[010/200] Iteration[015/030] Train loss: 0.4609
2023-02-06 15:45:38 | Train | Epoch[010/200] Iteration[016/030] Train loss: 0.4606
2023-02-06 15:45:38 | Train | Epoch[010/200] Iteration[017/030] Train loss: 0.4603
2023-02-06 15:45:39 | Train | Epoch[010/200] Iteration[018/030] Train loss: 0.4602
2023-02-06 15:45:39 | Train | Epoch[010/200] Iteration[019/030] Train loss: 0.4600
2023-02-06 15:45:39 | Train | Epoch[010/200] Iteration[020/030] Train loss: 0.4596
2023-02-06 15:45:40 | Train | Epoch[010/200] Iteration[021/030] Train loss: 0.4590
2023-02-06 15:45:40 | Train | Epoch[010/200] Iteration[022/030] Train loss: 0.4589
2023-02-06 15:45:41 | Train | Epoch[010/200] Iteration[023/030] Train loss: 0.4586
2023-02-06 15:45:41 | Train | Epoch[010/200] Iteration[024/030] Train loss: 0.4584
2023-02-06 15:45:42 | Train | Epoch[010/200] Iteration[025/030] Train loss: 0.4581
2023-02-06 15:45:42 | Train | Epoch[010/200] Iteration[026/030] Train loss: 0.4578
2023-02-06 15:45:43 | Train | Epoch[010/200] Iteration[027/030] Train loss: 0.4574
2023-02-06 15:45:43 | Train | Epoch[010/200] Iteration[028/030] Train loss: 0.4570
2023-02-06 15:45:43 | Train | Epoch[010/200] Iteration[029/030] Train loss: 0.4567
2023-02-06 15:45:44 | Train | Epoch[010/200] Iteration[030/030] Train loss: 0.4562
2023-02-06 15:45:44 | Valid | Epoch[010/200] Iteration[001/008] Valid loss: 0.4515
2023-02-06 15:45:44 | Valid | Epoch[010/200] Iteration[002/008] Valid loss: 0.4516
2023-02-06 15:45:44 | Valid | Epoch[010/200] Iteration[003/008] Valid loss: 0.4507
2023-02-06 15:45:44 | Valid | Epoch[010/200] Iteration[004/008] Valid loss: 0.4498
2023-02-06 15:45:44 | Valid | Epoch[010/200] Iteration[005/008] Valid loss: 0.4499
2023-02-06 15:45:44 | Valid | Epoch[010/200] Iteration[006/008] Valid loss: 0.4500
2023-02-06 15:45:45 | Valid | Epoch[010/200] Iteration[007/008] Valid loss: 0.4501
2023-02-06 15:45:45 | Valid | Epoch[010/200] Iteration[008/008] Valid loss: 0.4495
2023-02-06 15:45:45 | Valid | Epoch[010/200] MIou: 0.9253768616033756
2023-02-06 15:45:45 | Valid | Epoch[010/200] Pixel Accuracy: 0.9875272115071615
2023-02-06 15:45:45 | Valid | Epoch[010/200] Mean Pixel Accuracy: 0.9389207111214661
2023-02-06 15:45:45 | Stage | Epoch[010/200] Train loss:0.4562
2023-02-06 15:45:45 | Stage | Epoch[010/200] Valid loss:0.4495
2023-02-06 15:45:45 | Stage | Epoch[010/200] LR:0.01

2023-02-06 15:45:46 | Train | Epoch[011/200] Iteration[001/030] Train loss: 0.4482
2023-02-06 15:45:46 | Train | Epoch[011/200] Iteration[002/030] Train loss: 0.4455
2023-02-06 15:45:46 | Train | Epoch[011/200] Iteration[003/030] Train loss: 0.4473
2023-02-06 15:45:47 | Train | Epoch[011/200] Iteration[004/030] Train loss: 0.4472
2023-02-06 15:45:47 | Train | Epoch[011/200] Iteration[005/030] Train loss: 0.4481
2023-02-06 15:45:48 | Train | Epoch[011/200] Iteration[006/030] Train loss: 0.4479
2023-02-06 15:45:48 | Train | Epoch[011/200] Iteration[007/030] Train loss: 0.4472
2023-02-06 15:45:49 | Train | Epoch[011/200] Iteration[008/030] Train loss: 0.4472
2023-02-06 15:45:49 | Train | Epoch[011/200] Iteration[009/030] Train loss: 0.4466
2023-02-06 15:45:49 | Train | Epoch[011/200] Iteration[010/030] Train loss: 0.4462
2023-02-06 15:45:50 | Train | Epoch[011/200] Iteration[011/030] Train loss: 0.4459
2023-02-06 15:45:50 | Train | Epoch[011/200] Iteration[012/030] Train loss: 0.4453
2023-02-06 15:45:51 | Train | Epoch[011/200] Iteration[013/030] Train loss: 0.4453
2023-02-06 15:45:51 | Train | Epoch[011/200] Iteration[014/030] Train loss: 0.4446
2023-02-06 15:45:52 | Train | Epoch[011/200] Iteration[015/030] Train loss: 0.4441
2023-02-06 15:45:52 | Train | Epoch[011/200] Iteration[016/030] Train loss: 0.4435
2023-02-06 15:45:52 | Train | Epoch[011/200] Iteration[017/030] Train loss: 0.4433
2023-02-06 15:45:53 | Train | Epoch[011/200] Iteration[018/030] Train loss: 0.4429
2023-02-06 15:45:53 | Train | Epoch[011/200] Iteration[019/030] Train loss: 0.4429
2023-02-06 15:45:54 | Train | Epoch[011/200] Iteration[020/030] Train loss: 0.4424
2023-02-06 15:45:54 | Train | Epoch[011/200] Iteration[021/030] Train loss: 0.4421
2023-02-06 15:45:55 | Train | Epoch[011/200] Iteration[022/030] Train loss: 0.4416
2023-02-06 15:45:55 | Train | Epoch[011/200] Iteration[023/030] Train loss: 0.4412
2023-02-06 15:45:55 | Train | Epoch[011/200] Iteration[024/030] Train loss: 0.4407
2023-02-06 15:45:56 | Train | Epoch[011/200] Iteration[025/030] Train loss: 0.4403
2023-02-06 15:45:56 | Train | Epoch[011/200] Iteration[026/030] Train loss: 0.4400
2023-02-06 15:45:57 | Train | Epoch[011/200] Iteration[027/030] Train loss: 0.4396
2023-02-06 15:45:57 | Train | Epoch[011/200] Iteration[028/030] Train loss: 0.4395
2023-02-06 15:45:58 | Train | Epoch[011/200] Iteration[029/030] Train loss: 0.4394
2023-02-06 15:45:58 | Train | Epoch[011/200] Iteration[030/030] Train loss: 0.4391
2023-02-06 15:45:58 | Valid | Epoch[011/200] Iteration[001/008] Valid loss: 0.4698
2023-02-06 15:45:58 | Valid | Epoch[011/200] Iteration[002/008] Valid loss: 0.4677
2023-02-06 15:45:59 | Valid | Epoch[011/200] Iteration[003/008] Valid loss: 0.4680
2023-02-06 15:45:59 | Valid | Epoch[011/200] Iteration[004/008] Valid loss: 0.4674
2023-02-06 15:45:59 | Valid | Epoch[011/200] Iteration[005/008] Valid loss: 0.4690
2023-02-06 15:45:59 | Valid | Epoch[011/200] Iteration[006/008] Valid loss: 0.4698
2023-02-06 15:45:59 | Valid | Epoch[011/200] Iteration[007/008] Valid loss: 0.4716
2023-02-06 15:45:59 | Valid | Epoch[011/200] Iteration[008/008] Valid loss: 0.4712
2023-02-06 15:45:59 | Valid | Epoch[011/200] MIou: 0.8597574163328371
2023-02-06 15:45:59 | Valid | Epoch[011/200] Pixel Accuracy: 0.9710184733072916
2023-02-06 15:45:59 | Valid | Epoch[011/200] Mean Pixel Accuracy: 0.9702165866435746
2023-02-06 15:45:59 | Stage | Epoch[011/200] Train loss:0.4391
2023-02-06 15:45:59 | Stage | Epoch[011/200] Valid loss:0.4712
2023-02-06 15:45:59 | Stage | Epoch[011/200] LR:0.01

2023-02-06 15:46:00 | Train | Epoch[012/200] Iteration[001/030] Train loss: 0.4276
2023-02-06 15:46:00 | Train | Epoch[012/200] Iteration[002/030] Train loss: 0.4274
2023-02-06 15:46:01 | Train | Epoch[012/200] Iteration[003/030] Train loss: 0.4265
2023-02-06 15:46:01 | Train | Epoch[012/200] Iteration[004/030] Train loss: 0.4287
2023-02-06 15:46:02 | Train | Epoch[012/200] Iteration[005/030] Train loss: 0.4298
2023-02-06 15:46:02 | Train | Epoch[012/200] Iteration[006/030] Train loss: 0.4294
2023-02-06 15:46:03 | Train | Epoch[012/200] Iteration[007/030] Train loss: 0.4291
2023-02-06 15:46:03 | Train | Epoch[012/200] Iteration[008/030] Train loss: 0.4300
2023-02-06 15:46:03 | Train | Epoch[012/200] Iteration[009/030] Train loss: 0.4294
2023-02-06 15:46:04 | Train | Epoch[012/200] Iteration[010/030] Train loss: 0.4293
2023-02-06 15:46:04 | Train | Epoch[012/200] Iteration[011/030] Train loss: 0.4289
2023-02-06 15:46:05 | Train | Epoch[012/200] Iteration[012/030] Train loss: 0.4281
2023-02-06 15:46:05 | Train | Epoch[012/200] Iteration[013/030] Train loss: 0.4278
2023-02-06 15:46:06 | Train | Epoch[012/200] Iteration[014/030] Train loss: 0.4275
2023-02-06 15:46:06 | Train | Epoch[012/200] Iteration[015/030] Train loss: 0.4270
2023-02-06 15:46:06 | Train | Epoch[012/200] Iteration[016/030] Train loss: 0.4266
2023-02-06 15:46:07 | Train | Epoch[012/200] Iteration[017/030] Train loss: 0.4265
2023-02-06 15:46:07 | Train | Epoch[012/200] Iteration[018/030] Train loss: 0.4259
2023-02-06 15:46:08 | Train | Epoch[012/200] Iteration[019/030] Train loss: 0.4258
2023-02-06 15:46:08 | Train | Epoch[012/200] Iteration[020/030] Train loss: 0.4255
2023-02-06 15:46:09 | Train | Epoch[012/200] Iteration[021/030] Train loss: 0.4251
2023-02-06 15:46:09 | Train | Epoch[012/200] Iteration[022/030] Train loss: 0.4250
2023-02-06 15:46:09 | Train | Epoch[012/200] Iteration[023/030] Train loss: 0.4249
2023-02-06 15:46:10 | Train | Epoch[012/200] Iteration[024/030] Train loss: 0.4246
2023-02-06 15:46:10 | Train | Epoch[012/200] Iteration[025/030] Train loss: 0.4242
2023-02-06 15:46:11 | Train | Epoch[012/200] Iteration[026/030] Train loss: 0.4240
2023-02-06 15:46:11 | Train | Epoch[012/200] Iteration[027/030] Train loss: 0.4236
2023-02-06 15:46:12 | Train | Epoch[012/200] Iteration[028/030] Train loss: 0.4234
2023-02-06 15:46:12 | Train | Epoch[012/200] Iteration[029/030] Train loss: 0.4230
2023-02-06 15:46:12 | Train | Epoch[012/200] Iteration[030/030] Train loss: 0.4229
2023-02-06 15:46:13 | Valid | Epoch[012/200] Iteration[001/008] Valid loss: 0.6156
2023-02-06 15:46:13 | Valid | Epoch[012/200] Iteration[002/008] Valid loss: 0.6142
2023-02-06 15:46:13 | Valid | Epoch[012/200] Iteration[003/008] Valid loss: 0.6130
2023-02-06 15:46:13 | Valid | Epoch[012/200] Iteration[004/008] Valid loss: 0.6171
2023-02-06 15:46:13 | Valid | Epoch[012/200] Iteration[005/008] Valid loss: 0.6171
2023-02-06 15:46:13 | Valid | Epoch[012/200] Iteration[006/008] Valid loss: 0.6136
2023-02-06 15:46:13 | Valid | Epoch[012/200] Iteration[007/008] Valid loss: 0.6171
2023-02-06 15:46:13 | Valid | Epoch[012/200] Iteration[008/008] Valid loss: 0.6227
2023-02-06 15:46:13 | Valid | Epoch[012/200] MIou: 0.6647514731079612
2023-02-06 15:46:13 | Valid | Epoch[012/200] Pixel Accuracy: 0.8903605143229166
2023-02-06 15:46:13 | Valid | Epoch[012/200] Mean Pixel Accuracy: 0.93657990784789
2023-02-06 15:46:13 | Stage | Epoch[012/200] Train loss:0.4229
2023-02-06 15:46:13 | Stage | Epoch[012/200] Valid loss:0.6227
2023-02-06 15:46:13 | Stage | Epoch[012/200] LR:0.01

2023-02-06 15:46:14 | Train | Epoch[013/200] Iteration[001/030] Train loss: 0.4092
2023-02-06 15:46:15 | Train | Epoch[013/200] Iteration[002/030] Train loss: 0.4096
2023-02-06 15:46:15 | Train | Epoch[013/200] Iteration[003/030] Train loss: 0.4137
2023-02-06 15:46:15 | Train | Epoch[013/200] Iteration[004/030] Train loss: 0.4132
2023-02-06 15:46:16 | Train | Epoch[013/200] Iteration[005/030] Train loss: 0.4132
2023-02-06 15:46:16 | Train | Epoch[013/200] Iteration[006/030] Train loss: 0.4138
2023-02-06 15:46:17 | Train | Epoch[013/200] Iteration[007/030] Train loss: 0.4133
2023-02-06 15:46:17 | Train | Epoch[013/200] Iteration[008/030] Train loss: 0.4131
2023-02-06 15:46:18 | Train | Epoch[013/200] Iteration[009/030] Train loss: 0.4125
2023-02-06 15:46:18 | Train | Epoch[013/200] Iteration[010/030] Train loss: 0.4118
2023-02-06 15:46:18 | Train | Epoch[013/200] Iteration[011/030] Train loss: 0.4116
2023-02-06 15:46:19 | Train | Epoch[013/200] Iteration[012/030] Train loss: 0.4121
2023-02-06 15:46:19 | Train | Epoch[013/200] Iteration[013/030] Train loss: 0.4118
2023-02-06 15:46:20 | Train | Epoch[013/200] Iteration[014/030] Train loss: 0.4112
2023-02-06 15:46:20 | Train | Epoch[013/200] Iteration[015/030] Train loss: 0.4109
2023-02-06 15:46:21 | Train | Epoch[013/200] Iteration[016/030] Train loss: 0.4103
2023-02-06 15:46:21 | Train | Epoch[013/200] Iteration[017/030] Train loss: 0.4101
2023-02-06 15:46:22 | Train | Epoch[013/200] Iteration[018/030] Train loss: 0.4096
2023-02-06 15:46:22 | Train | Epoch[013/200] Iteration[019/030] Train loss: 0.4093
2023-02-06 15:46:22 | Train | Epoch[013/200] Iteration[020/030] Train loss: 0.4092
2023-02-06 15:46:23 | Train | Epoch[013/200] Iteration[021/030] Train loss: 0.4092
2023-02-06 15:46:23 | Train | Epoch[013/200] Iteration[022/030] Train loss: 0.4091
2023-02-06 15:46:24 | Train | Epoch[013/200] Iteration[023/030] Train loss: 0.4090
2023-02-06 15:46:24 | Train | Epoch[013/200] Iteration[024/030] Train loss: 0.4089
2023-02-06 15:46:25 | Train | Epoch[013/200] Iteration[025/030] Train loss: 0.4087
2023-02-06 15:46:25 | Train | Epoch[013/200] Iteration[026/030] Train loss: 0.4084
2023-02-06 15:46:25 | Train | Epoch[013/200] Iteration[027/030] Train loss: 0.4084
2023-02-06 15:46:26 | Train | Epoch[013/200] Iteration[028/030] Train loss: 0.4080
2023-02-06 15:46:26 | Train | Epoch[013/200] Iteration[029/030] Train loss: 0.4076
2023-02-06 15:46:26 | Train | Epoch[013/200] Iteration[030/030] Train loss: 0.4073
2023-02-06 15:46:27 | Valid | Epoch[013/200] Iteration[001/008] Valid loss: 0.6542
2023-02-06 15:46:27 | Valid | Epoch[013/200] Iteration[002/008] Valid loss: 0.6400
2023-02-06 15:46:27 | Valid | Epoch[013/200] Iteration[003/008] Valid loss: 0.6508
2023-02-06 15:46:27 | Valid | Epoch[013/200] Iteration[004/008] Valid loss: 0.6542
2023-02-06 15:46:27 | Valid | Epoch[013/200] Iteration[005/008] Valid loss: 0.6620
2023-02-06 15:46:27 | Valid | Epoch[013/200] Iteration[006/008] Valid loss: 0.6602
2023-02-06 15:46:27 | Valid | Epoch[013/200] Iteration[007/008] Valid loss: 0.6679
2023-02-06 15:46:28 | Valid | Epoch[013/200] Iteration[008/008] Valid loss: 0.6743
2023-02-06 15:46:28 | Valid | Epoch[013/200] MIou: 0.7003350229165515
2023-02-06 15:46:28 | Valid | Epoch[013/200] Pixel Accuracy: 0.90972900390625
2023-02-06 15:46:28 | Valid | Epoch[013/200] Mean Pixel Accuracy: 0.9499583989906983
2023-02-06 15:46:28 | Stage | Epoch[013/200] Train loss:0.4073
2023-02-06 15:46:28 | Stage | Epoch[013/200] Valid loss:0.6743
2023-02-06 15:46:28 | Stage | Epoch[013/200] LR:0.01

2023-02-06 15:46:28 | Train | Epoch[014/200] Iteration[001/030] Train loss: 0.4024
2023-02-06 15:46:29 | Train | Epoch[014/200] Iteration[002/030] Train loss: 0.4019
2023-02-06 15:46:29 | Train | Epoch[014/200] Iteration[003/030] Train loss: 0.4008
2023-02-06 15:46:30 | Train | Epoch[014/200] Iteration[004/030] Train loss: 0.4011
2023-02-06 15:46:30 | Train | Epoch[014/200] Iteration[005/030] Train loss: 0.4006
2023-02-06 15:46:31 | Train | Epoch[014/200] Iteration[006/030] Train loss: 0.3996
2023-02-06 15:46:31 | Train | Epoch[014/200] Iteration[007/030] Train loss: 0.3990
2023-02-06 15:46:31 | Train | Epoch[014/200] Iteration[008/030] Train loss: 0.3980
2023-02-06 15:46:32 | Train | Epoch[014/200] Iteration[009/030] Train loss: 0.3980
2023-02-06 15:46:32 | Train | Epoch[014/200] Iteration[010/030] Train loss: 0.3976
2023-02-06 15:46:33 | Train | Epoch[014/200] Iteration[011/030] Train loss: 0.3975
2023-02-06 15:46:33 | Train | Epoch[014/200] Iteration[012/030] Train loss: 0.3971
2023-02-06 15:46:34 | Train | Epoch[014/200] Iteration[013/030] Train loss: 0.3966
2023-02-06 15:46:34 | Train | Epoch[014/200] Iteration[014/030] Train loss: 0.3961
2023-02-06 15:46:34 | Train | Epoch[014/200] Iteration[015/030] Train loss: 0.3958
2023-02-06 15:46:35 | Train | Epoch[014/200] Iteration[016/030] Train loss: 0.3954
2023-02-06 15:46:35 | Train | Epoch[014/200] Iteration[017/030] Train loss: 0.3948
2023-02-06 15:46:36 | Train | Epoch[014/200] Iteration[018/030] Train loss: 0.3947
2023-02-06 15:46:36 | Train | Epoch[014/200] Iteration[019/030] Train loss: 0.3947
2023-02-06 15:46:37 | Train | Epoch[014/200] Iteration[020/030] Train loss: 0.3946
2023-02-06 15:46:37 | Train | Epoch[014/200] Iteration[021/030] Train loss: 0.3942
2023-02-06 15:46:37 | Train | Epoch[014/200] Iteration[022/030] Train loss: 0.3937
2023-02-06 15:46:38 | Train | Epoch[014/200] Iteration[023/030] Train loss: 0.3935
2023-02-06 15:46:38 | Train | Epoch[014/200] Iteration[024/030] Train loss: 0.3933
2023-02-06 15:46:39 | Train | Epoch[014/200] Iteration[025/030] Train loss: 0.3930
2023-02-06 15:46:39 | Train | Epoch[014/200] Iteration[026/030] Train loss: 0.3928
2023-02-06 15:46:40 | Train | Epoch[014/200] Iteration[027/030] Train loss: 0.3927
2023-02-06 15:46:40 | Train | Epoch[014/200] Iteration[028/030] Train loss: 0.3923
2023-02-06 15:46:41 | Train | Epoch[014/200] Iteration[029/030] Train loss: 0.3919
2023-02-06 15:46:41 | Train | Epoch[014/200] Iteration[030/030] Train loss: 0.3915
2023-02-06 15:46:41 | Valid | Epoch[014/200] Iteration[001/008] Valid loss: 0.4330
2023-02-06 15:46:41 | Valid | Epoch[014/200] Iteration[002/008] Valid loss: 0.4309
2023-02-06 15:46:41 | Valid | Epoch[014/200] Iteration[003/008] Valid loss: 0.4332
2023-02-06 15:46:41 | Valid | Epoch[014/200] Iteration[004/008] Valid loss: 0.4332
2023-02-06 15:46:42 | Valid | Epoch[014/200] Iteration[005/008] Valid loss: 0.4343
2023-02-06 15:46:42 | Valid | Epoch[014/200] Iteration[006/008] Valid loss: 0.4343
2023-02-06 15:46:42 | Valid | Epoch[014/200] Iteration[007/008] Valid loss: 0.4344
2023-02-06 15:46:42 | Valid | Epoch[014/200] Iteration[008/008] Valid loss: 0.4355
2023-02-06 15:46:42 | Valid | Epoch[014/200] MIou: 0.5102654950090867
2023-02-06 15:46:42 | Valid | Epoch[014/200] Pixel Accuracy: 0.918860117594401
2023-02-06 15:46:42 | Valid | Epoch[014/200] Mean Pixel Accuracy: 0.5512160226170439
2023-02-06 15:46:42 | Stage | Epoch[014/200] Train loss:0.3915
2023-02-06 15:46:42 | Stage | Epoch[014/200] Valid loss:0.4355
2023-02-06 15:46:42 | Stage | Epoch[014/200] LR:0.01

2023-02-06 15:46:43 | Train | Epoch[015/200] Iteration[001/030] Train loss: 0.3836
2023-02-06 15:46:43 | Train | Epoch[015/200] Iteration[002/030] Train loss: 0.3822
2023-02-06 15:46:44 | Train | Epoch[015/200] Iteration[003/030] Train loss: 0.3812
2023-02-06 15:46:44 | Train | Epoch[015/200] Iteration[004/030] Train loss: 0.3810
2023-02-06 15:46:44 | Train | Epoch[015/200] Iteration[005/030] Train loss: 0.3817
2023-02-06 15:46:45 | Train | Epoch[015/200] Iteration[006/030] Train loss: 0.3817
2023-02-06 15:46:45 | Train | Epoch[015/200] Iteration[007/030] Train loss: 0.3820
2023-02-06 15:46:46 | Train | Epoch[015/200] Iteration[008/030] Train loss: 0.3812
2023-02-06 15:46:46 | Train | Epoch[015/200] Iteration[009/030] Train loss: 0.3804
2023-02-06 15:46:47 | Train | Epoch[015/200] Iteration[010/030] Train loss: 0.3798
2023-02-06 15:46:47 | Train | Epoch[015/200] Iteration[011/030] Train loss: 0.3799
2023-02-06 15:46:48 | Train | Epoch[015/200] Iteration[012/030] Train loss: 0.3798
2023-02-06 15:46:48 | Train | Epoch[015/200] Iteration[013/030] Train loss: 0.3793
2023-02-06 15:46:48 | Train | Epoch[015/200] Iteration[014/030] Train loss: 0.3793
2023-02-06 15:46:49 | Train | Epoch[015/200] Iteration[015/030] Train loss: 0.3793
2023-02-06 15:46:49 | Train | Epoch[015/200] Iteration[016/030] Train loss: 0.3791
2023-02-06 15:46:50 | Train | Epoch[015/200] Iteration[017/030] Train loss: 0.3789
2023-02-06 15:46:50 | Train | Epoch[015/200] Iteration[018/030] Train loss: 0.3790
2023-02-06 15:46:51 | Train | Epoch[015/200] Iteration[019/030] Train loss: 0.3788
2023-02-06 15:46:51 | Train | Epoch[015/200] Iteration[020/030] Train loss: 0.3784
2023-02-06 15:46:51 | Train | Epoch[015/200] Iteration[021/030] Train loss: 0.3782
2023-02-06 15:46:52 | Train | Epoch[015/200] Iteration[022/030] Train loss: 0.3782
2023-02-06 15:46:52 | Train | Epoch[015/200] Iteration[023/030] Train loss: 0.3779
2023-02-06 15:46:53 | Train | Epoch[015/200] Iteration[024/030] Train loss: 0.3777
2023-02-06 15:46:53 | Train | Epoch[015/200] Iteration[025/030] Train loss: 0.3774
2023-02-06 15:46:54 | Train | Epoch[015/200] Iteration[026/030] Train loss: 0.3772
2023-02-06 15:46:54 | Train | Epoch[015/200] Iteration[027/030] Train loss: 0.3771
2023-02-06 15:46:54 | Train | Epoch[015/200] Iteration[028/030] Train loss: 0.3768
2023-02-06 15:46:55 | Train | Epoch[015/200] Iteration[029/030] Train loss: 0.3765
2023-02-06 15:46:55 | Train | Epoch[015/200] Iteration[030/030] Train loss: 0.3764
2023-02-06 15:46:55 | Valid | Epoch[015/200] Iteration[001/008] Valid loss: 0.8317
2023-02-06 15:46:56 | Valid | Epoch[015/200] Iteration[002/008] Valid loss: 0.7920
2023-02-06 15:46:56 | Valid | Epoch[015/200] Iteration[003/008] Valid loss: 0.8093
2023-02-06 15:46:56 | Valid | Epoch[015/200] Iteration[004/008] Valid loss: 0.8083
2023-02-06 15:46:56 | Valid | Epoch[015/200] Iteration[005/008] Valid loss: 0.8225
2023-02-06 15:46:56 | Valid | Epoch[015/200] Iteration[006/008] Valid loss: 0.8086
2023-02-06 15:46:56 | Valid | Epoch[015/200] Iteration[007/008] Valid loss: 0.8225
2023-02-06 15:46:56 | Valid | Epoch[015/200] Iteration[008/008] Valid loss: 0.8371
2023-02-06 15:46:56 | Valid | Epoch[015/200] MIou: 0.6860810240074324
2023-02-06 15:46:56 | Valid | Epoch[015/200] Pixel Accuracy: 0.9021186828613281
2023-02-06 15:46:56 | Valid | Epoch[015/200] Mean Pixel Accuracy: 0.9459276132883567
2023-02-06 15:46:56 | Stage | Epoch[015/200] Train loss:0.3764
2023-02-06 15:46:56 | Stage | Epoch[015/200] Valid loss:0.8371
2023-02-06 15:46:56 | Stage | Epoch[015/200] LR:0.01

2023-02-06 15:46:57 | Train | Epoch[016/200] Iteration[001/030] Train loss: 0.3644
2023-02-06 15:46:57 | Train | Epoch[016/200] Iteration[002/030] Train loss: 0.3656
2023-02-06 15:46:58 | Train | Epoch[016/200] Iteration[003/030] Train loss: 0.3668
2023-02-06 15:46:58 | Train | Epoch[016/200] Iteration[004/030] Train loss: 0.3677
2023-02-06 15:46:59 | Train | Epoch[016/200] Iteration[005/030] Train loss: 0.3675
2023-02-06 15:46:59 | Train | Epoch[016/200] Iteration[006/030] Train loss: 0.3672
2023-02-06 15:47:00 | Train | Epoch[016/200] Iteration[007/030] Train loss: 0.3678
2023-02-06 15:47:00 | Train | Epoch[016/200] Iteration[008/030] Train loss: 0.3675
2023-02-06 15:47:00 | Train | Epoch[016/200] Iteration[009/030] Train loss: 0.3672
2023-02-06 15:47:01 | Train | Epoch[016/200] Iteration[010/030] Train loss: 0.3670
2023-02-06 15:47:01 | Train | Epoch[016/200] Iteration[011/030] Train loss: 0.3663
2023-02-06 15:47:02 | Train | Epoch[016/200] Iteration[012/030] Train loss: 0.3663
2023-02-06 15:47:02 | Train | Epoch[016/200] Iteration[013/030] Train loss: 0.3664
2023-02-06 15:47:03 | Train | Epoch[016/200] Iteration[014/030] Train loss: 0.3664
2023-02-06 15:47:03 | Train | Epoch[016/200] Iteration[015/030] Train loss: 0.3665
2023-02-06 15:47:03 | Train | Epoch[016/200] Iteration[016/030] Train loss: 0.3662
2023-02-06 15:47:04 | Train | Epoch[016/200] Iteration[017/030] Train loss: 0.3661
2023-02-06 15:47:04 | Train | Epoch[016/200] Iteration[018/030] Train loss: 0.3658
2023-02-06 15:47:05 | Train | Epoch[016/200] Iteration[019/030] Train loss: 0.3654
2023-02-06 15:47:05 | Train | Epoch[016/200] Iteration[020/030] Train loss: 0.3652
2023-02-06 15:47:06 | Train | Epoch[016/200] Iteration[021/030] Train loss: 0.3648
2023-02-06 15:47:06 | Train | Epoch[016/200] Iteration[022/030] Train loss: 0.3645
2023-02-06 15:47:07 | Train | Epoch[016/200] Iteration[023/030] Train loss: 0.3642
2023-02-06 15:47:07 | Train | Epoch[016/200] Iteration[024/030] Train loss: 0.3638
2023-02-06 15:47:07 | Train | Epoch[016/200] Iteration[025/030] Train loss: 0.3636
2023-02-06 15:47:08 | Train | Epoch[016/200] Iteration[026/030] Train loss: 0.3632
2023-02-06 15:47:08 | Train | Epoch[016/200] Iteration[027/030] Train loss: 0.3630
2023-02-06 15:47:09 | Train | Epoch[016/200] Iteration[028/030] Train loss: 0.3627
2023-02-06 15:47:09 | Train | Epoch[016/200] Iteration[029/030] Train loss: 0.3626
2023-02-06 15:47:09 | Train | Epoch[016/200] Iteration[030/030] Train loss: 0.3623
2023-02-06 15:47:10 | Valid | Epoch[016/200] Iteration[001/008] Valid loss: 0.5342
2023-02-06 15:47:10 | Valid | Epoch[016/200] Iteration[002/008] Valid loss: 0.5266
2023-02-06 15:47:10 | Valid | Epoch[016/200] Iteration[003/008] Valid loss: 0.5263
2023-02-06 15:47:10 | Valid | Epoch[016/200] Iteration[004/008] Valid loss: 0.5266
2023-02-06 15:47:10 | Valid | Epoch[016/200] Iteration[005/008] Valid loss: 0.5261
2023-02-06 15:47:10 | Valid | Epoch[016/200] Iteration[006/008] Valid loss: 0.5223
2023-02-06 15:47:10 | Valid | Epoch[016/200] Iteration[007/008] Valid loss: 0.5244
2023-02-06 15:47:10 | Valid | Epoch[016/200] Iteration[008/008] Valid loss: 0.5297
2023-02-06 15:47:10 | Valid | Epoch[016/200] MIou: 0.7602333010652702
2023-02-06 15:47:10 | Valid | Epoch[016/200] Pixel Accuracy: 0.9374427795410156
2023-02-06 15:47:10 | Valid | Epoch[016/200] Mean Pixel Accuracy: 0.9626358620241409
2023-02-06 15:47:10 | Stage | Epoch[016/200] Train loss:0.3623
2023-02-06 15:47:10 | Stage | Epoch[016/200] Valid loss:0.5297
2023-02-06 15:47:10 | Stage | Epoch[016/200] LR:0.01

2023-02-06 15:47:11 | Train | Epoch[017/200] Iteration[001/030] Train loss: 0.3568
2023-02-06 15:47:12 | Train | Epoch[017/200] Iteration[002/030] Train loss: 0.3539
2023-02-06 15:47:12 | Train | Epoch[017/200] Iteration[003/030] Train loss: 0.3521
2023-02-06 15:47:12 | Train | Epoch[017/200] Iteration[004/030] Train loss: 0.3545
2023-02-06 15:47:13 | Train | Epoch[017/200] Iteration[005/030] Train loss: 0.3548
2023-02-06 15:47:13 | Train | Epoch[017/200] Iteration[006/030] Train loss: 0.3535
2023-02-06 15:47:14 | Train | Epoch[017/200] Iteration[007/030] Train loss: 0.3531
2023-02-06 15:47:14 | Train | Epoch[017/200] Iteration[008/030] Train loss: 0.3526
2023-02-06 15:47:15 | Train | Epoch[017/200] Iteration[009/030] Train loss: 0.3524
2023-02-06 15:47:15 | Train | Epoch[017/200] Iteration[010/030] Train loss: 0.3520
2023-02-06 15:47:16 | Train | Epoch[017/200] Iteration[011/030] Train loss: 0.3514
2023-02-06 15:47:16 | Train | Epoch[017/200] Iteration[012/030] Train loss: 0.3510
2023-02-06 15:47:16 | Train | Epoch[017/200] Iteration[013/030] Train loss: 0.3511
2023-02-06 15:47:17 | Train | Epoch[017/200] Iteration[014/030] Train loss: 0.3510
2023-02-06 15:47:17 | Train | Epoch[017/200] Iteration[015/030] Train loss: 0.3508
2023-02-06 15:47:18 | Train | Epoch[017/200] Iteration[016/030] Train loss: 0.3508
2023-02-06 15:47:18 | Train | Epoch[017/200] Iteration[017/030] Train loss: 0.3509
2023-02-06 15:47:19 | Train | Epoch[017/200] Iteration[018/030] Train loss: 0.3506
2023-02-06 15:47:19 | Train | Epoch[017/200] Iteration[019/030] Train loss: 0.3504
2023-02-06 15:47:19 | Train | Epoch[017/200] Iteration[020/030] Train loss: 0.3502
2023-02-06 15:47:20 | Train | Epoch[017/200] Iteration[021/030] Train loss: 0.3501
2023-02-06 15:47:20 | Train | Epoch[017/200] Iteration[022/030] Train loss: 0.3500
2023-02-06 15:47:21 | Train | Epoch[017/200] Iteration[023/030] Train loss: 0.3498
2023-02-06 15:47:21 | Train | Epoch[017/200] Iteration[024/030] Train loss: 0.3497
2023-02-06 15:47:22 | Train | Epoch[017/200] Iteration[025/030] Train loss: 0.3496
2023-02-06 15:47:22 | Train | Epoch[017/200] Iteration[026/030] Train loss: 0.3493
2023-02-06 15:47:22 | Train | Epoch[017/200] Iteration[027/030] Train loss: 0.3490
2023-02-06 15:47:23 | Train | Epoch[017/200] Iteration[028/030] Train loss: 0.3487
2023-02-06 15:47:23 | Train | Epoch[017/200] Iteration[029/030] Train loss: 0.3486
2023-02-06 15:47:23 | Train | Epoch[017/200] Iteration[030/030] Train loss: 0.3483
2023-02-06 15:47:24 | Valid | Epoch[017/200] Iteration[001/008] Valid loss: 0.3916
2023-02-06 15:47:24 | Valid | Epoch[017/200] Iteration[002/008] Valid loss: 0.3881
2023-02-06 15:47:24 | Valid | Epoch[017/200] Iteration[003/008] Valid loss: 0.3871
2023-02-06 15:47:24 | Valid | Epoch[017/200] Iteration[004/008] Valid loss: 0.3874
2023-02-06 15:47:24 | Valid | Epoch[017/200] Iteration[005/008] Valid loss: 0.3885
2023-02-06 15:47:24 | Valid | Epoch[017/200] Iteration[006/008] Valid loss: 0.3894
2023-02-06 15:47:25 | Valid | Epoch[017/200] Iteration[007/008] Valid loss: 0.3923
2023-02-06 15:47:25 | Valid | Epoch[017/200] Iteration[008/008] Valid loss: 0.3904
2023-02-06 15:47:25 | Valid | Epoch[017/200] MIou: 0.895153563183889
2023-02-06 15:47:25 | Valid | Epoch[017/200] Pixel Accuracy: 0.9794286092122396
2023-02-06 15:47:25 | Valid | Epoch[017/200] Mean Pixel Accuracy: 0.9839947968839984
2023-02-06 15:47:25 | Stage | Epoch[017/200] Train loss:0.3483
2023-02-06 15:47:25 | Stage | Epoch[017/200] Valid loss:0.3904
2023-02-06 15:47:25 | Stage | Epoch[017/200] LR:0.01

2023-02-06 15:47:25 | Train | Epoch[018/200] Iteration[001/030] Train loss: 0.3400
2023-02-06 15:47:26 | Train | Epoch[018/200] Iteration[002/030] Train loss: 0.3423
2023-02-06 15:47:26 | Train | Epoch[018/200] Iteration[003/030] Train loss: 0.3411
2023-02-06 15:47:27 | Train | Epoch[018/200] Iteration[004/030] Train loss: 0.3397
2023-02-06 15:47:27 | Train | Epoch[018/200] Iteration[005/030] Train loss: 0.3389
2023-02-06 15:47:28 | Train | Epoch[018/200] Iteration[006/030] Train loss: 0.3383
2023-02-06 15:47:28 | Train | Epoch[018/200] Iteration[007/030] Train loss: 0.3384
2023-02-06 15:47:29 | Train | Epoch[018/200] Iteration[008/030] Train loss: 0.3387
2023-02-06 15:47:29 | Train | Epoch[018/200] Iteration[009/030] Train loss: 0.3392
2023-02-06 15:47:29 | Train | Epoch[018/200] Iteration[010/030] Train loss: 0.3394
2023-02-06 15:47:30 | Train | Epoch[018/200] Iteration[011/030] Train loss: 0.3388
2023-02-06 15:47:30 | Train | Epoch[018/200] Iteration[012/030] Train loss: 0.3384
2023-02-06 15:47:31 | Train | Epoch[018/200] Iteration[013/030] Train loss: 0.3385
2023-02-06 15:47:31 | Train | Epoch[018/200] Iteration[014/030] Train loss: 0.3381
2023-02-06 15:47:32 | Train | Epoch[018/200] Iteration[015/030] Train loss: 0.3377
2023-02-06 15:47:32 | Train | Epoch[018/200] Iteration[016/030] Train loss: 0.3379
2023-02-06 15:47:32 | Train | Epoch[018/200] Iteration[017/030] Train loss: 0.3378
2023-02-06 15:47:33 | Train | Epoch[018/200] Iteration[018/030] Train loss: 0.3379
2023-02-06 15:47:33 | Train | Epoch[018/200] Iteration[019/030] Train loss: 0.3376
2023-02-06 15:47:34 | Train | Epoch[018/200] Iteration[020/030] Train loss: 0.3375
2023-02-06 15:47:34 | Train | Epoch[018/200] Iteration[021/030] Train loss: 0.3372
2023-02-06 15:47:35 | Train | Epoch[018/200] Iteration[022/030] Train loss: 0.3369
2023-02-06 15:47:35 | Train | Epoch[018/200] Iteration[023/030] Train loss: 0.3367
2023-02-06 15:47:35 | Train | Epoch[018/200] Iteration[024/030] Train loss: 0.3369
2023-02-06 15:47:36 | Train | Epoch[018/200] Iteration[025/030] Train loss: 0.3367
2023-02-06 15:47:36 | Train | Epoch[018/200] Iteration[026/030] Train loss: 0.3364
2023-02-06 15:47:37 | Train | Epoch[018/200] Iteration[027/030] Train loss: 0.3361
2023-02-06 15:47:37 | Train | Epoch[018/200] Iteration[028/030] Train loss: 0.3359
2023-02-06 15:47:38 | Train | Epoch[018/200] Iteration[029/030] Train loss: 0.3357
2023-02-06 15:47:38 | Train | Epoch[018/200] Iteration[030/030] Train loss: 0.3354
2023-02-06 15:47:38 | Valid | Epoch[018/200] Iteration[001/008] Valid loss: 0.3567
2023-02-06 15:47:38 | Valid | Epoch[018/200] Iteration[002/008] Valid loss: 0.3562
2023-02-06 15:47:38 | Valid | Epoch[018/200] Iteration[003/008] Valid loss: 0.3554
2023-02-06 15:47:39 | Valid | Epoch[018/200] Iteration[004/008] Valid loss: 0.3547
2023-02-06 15:47:39 | Valid | Epoch[018/200] Iteration[005/008] Valid loss: 0.3547
2023-02-06 15:47:39 | Valid | Epoch[018/200] Iteration[006/008] Valid loss: 0.3558
2023-02-06 15:47:39 | Valid | Epoch[018/200] Iteration[007/008] Valid loss: 0.3565
2023-02-06 15:47:39 | Valid | Epoch[018/200] Iteration[008/008] Valid loss: 0.3561
2023-02-06 15:47:39 | Valid | Epoch[018/200] MIou: 0.9174539478112029
2023-02-06 15:47:39 | Valid | Epoch[018/200] Pixel Accuracy: 0.9846992492675781
2023-02-06 15:47:39 | Valid | Epoch[018/200] Mean Pixel Accuracy: 0.9793402638748869
2023-02-06 15:47:39 | Stage | Epoch[018/200] Train loss:0.3354
2023-02-06 15:47:39 | Stage | Epoch[018/200] Valid loss:0.3561
2023-02-06 15:47:39 | Stage | Epoch[018/200] LR:0.01

2023-02-06 15:47:40 | Train | Epoch[019/200] Iteration[001/030] Train loss: 0.3261
2023-02-06 15:47:40 | Train | Epoch[019/200] Iteration[002/030] Train loss: 0.3258
2023-02-06 15:47:41 | Train | Epoch[019/200] Iteration[003/030] Train loss: 0.3255
2023-02-06 15:47:41 | Train | Epoch[019/200] Iteration[004/030] Train loss: 0.3246
2023-02-06 15:47:41 | Train | Epoch[019/200] Iteration[005/030] Train loss: 0.3246
2023-02-06 15:47:42 | Train | Epoch[019/200] Iteration[006/030] Train loss: 0.3242
2023-02-06 15:47:42 | Train | Epoch[019/200] Iteration[007/030] Train loss: 0.3247
2023-02-06 15:47:43 | Train | Epoch[019/200] Iteration[008/030] Train loss: 0.3248
2023-02-06 15:47:43 | Train | Epoch[019/200] Iteration[009/030] Train loss: 0.3244
2023-02-06 15:47:44 | Train | Epoch[019/200] Iteration[010/030] Train loss: 0.3242
2023-02-06 15:47:44 | Train | Epoch[019/200] Iteration[011/030] Train loss: 0.3245
2023-02-06 15:47:45 | Train | Epoch[019/200] Iteration[012/030] Train loss: 0.3245
2023-02-06 15:47:45 | Train | Epoch[019/200] Iteration[013/030] Train loss: 0.3249
2023-02-06 15:47:45 | Train | Epoch[019/200] Iteration[014/030] Train loss: 0.3244
2023-02-06 15:47:46 | Train | Epoch[019/200] Iteration[015/030] Train loss: 0.3244
2023-02-06 15:47:46 | Train | Epoch[019/200] Iteration[016/030] Train loss: 0.3244
2023-02-06 15:47:47 | Train | Epoch[019/200] Iteration[017/030] Train loss: 0.3243
2023-02-06 15:47:47 | Train | Epoch[019/200] Iteration[018/030] Train loss: 0.3242
2023-02-06 15:47:48 | Train | Epoch[019/200] Iteration[019/030] Train loss: 0.3240
2023-02-06 15:47:48 | Train | Epoch[019/200] Iteration[020/030] Train loss: 0.3237
2023-02-06 15:47:48 | Train | Epoch[019/200] Iteration[021/030] Train loss: 0.3235
2023-02-06 15:47:49 | Train | Epoch[019/200] Iteration[022/030] Train loss: 0.3234
2023-02-06 15:47:49 | Train | Epoch[019/200] Iteration[023/030] Train loss: 0.3234
2023-02-06 15:47:50 | Train | Epoch[019/200] Iteration[024/030] Train loss: 0.3234
2023-02-06 15:47:50 | Train | Epoch[019/200] Iteration[025/030] Train loss: 0.3231
2023-02-06 15:47:51 | Train | Epoch[019/200] Iteration[026/030] Train loss: 0.3231
2023-02-06 15:47:51 | Train | Epoch[019/200] Iteration[027/030] Train loss: 0.3230
2023-02-06 15:47:51 | Train | Epoch[019/200] Iteration[028/030] Train loss: 0.3227
2023-02-06 15:47:52 | Train | Epoch[019/200] Iteration[029/030] Train loss: 0.3227
2023-02-06 15:47:52 | Train | Epoch[019/200] Iteration[030/030] Train loss: 0.3227
2023-02-06 15:47:53 | Valid | Epoch[019/200] Iteration[001/008] Valid loss: 0.3272
2023-02-06 15:47:53 | Valid | Epoch[019/200] Iteration[002/008] Valid loss: 0.3256
2023-02-06 15:47:53 | Valid | Epoch[019/200] Iteration[003/008] Valid loss: 0.3260
2023-02-06 15:47:53 | Valid | Epoch[019/200] Iteration[004/008] Valid loss: 0.3247
2023-02-06 15:47:53 | Valid | Epoch[019/200] Iteration[005/008] Valid loss: 0.3259
2023-02-06 15:47:53 | Valid | Epoch[019/200] Iteration[006/008] Valid loss: 0.3262
2023-02-06 15:47:53 | Valid | Epoch[019/200] Iteration[007/008] Valid loss: 0.3261
2023-02-06 15:47:53 | Valid | Epoch[019/200] Iteration[008/008] Valid loss: 0.3264
2023-02-06 15:47:53 | Valid | Epoch[019/200] MIou: 0.8399175831577486
2023-02-06 15:47:53 | Valid | Epoch[019/200] Pixel Accuracy: 0.9732844034830729
2023-02-06 15:47:53 | Valid | Epoch[019/200] Mean Pixel Accuracy: 0.858588964649724
2023-02-06 15:47:53 | Stage | Epoch[019/200] Train loss:0.3227
2023-02-06 15:47:53 | Stage | Epoch[019/200] Valid loss:0.3264
2023-02-06 15:47:53 | Stage | Epoch[019/200] LR:0.01

2023-02-06 15:47:54 | Train | Epoch[020/200] Iteration[001/030] Train loss: 0.3128
2023-02-06 15:47:55 | Train | Epoch[020/200] Iteration[002/030] Train loss: 0.3121
2023-02-06 15:47:55 | Train | Epoch[020/200] Iteration[003/030] Train loss: 0.3140
2023-02-06 15:47:55 | Train | Epoch[020/200] Iteration[004/030] Train loss: 0.3153
2023-02-06 15:47:56 | Train | Epoch[020/200] Iteration[005/030] Train loss: 0.3152
2023-02-06 15:47:56 | Train | Epoch[020/200] Iteration[006/030] Train loss: 0.3146
2023-02-06 15:47:57 | Train | Epoch[020/200] Iteration[007/030] Train loss: 0.3145
2023-02-06 15:47:57 | Train | Epoch[020/200] Iteration[008/030] Train loss: 0.3141
2023-02-06 15:47:58 | Train | Epoch[020/200] Iteration[009/030] Train loss: 0.3143
2023-02-06 15:47:58 | Train | Epoch[020/200] Iteration[010/030] Train loss: 0.3141
2023-02-06 15:47:58 | Train | Epoch[020/200] Iteration[011/030] Train loss: 0.3144
2023-02-06 15:47:59 | Train | Epoch[020/200] Iteration[012/030] Train loss: 0.3140
2023-02-06 15:47:59 | Train | Epoch[020/200] Iteration[013/030] Train loss: 0.3142
2023-02-06 15:48:00 | Train | Epoch[020/200] Iteration[014/030] Train loss: 0.3141
2023-02-06 15:48:00 | Train | Epoch[020/200] Iteration[015/030] Train loss: 0.3141
2023-02-06 15:48:01 | Train | Epoch[020/200] Iteration[016/030] Train loss: 0.3139
2023-02-06 15:48:01 | Train | Epoch[020/200] Iteration[017/030] Train loss: 0.3137
2023-02-06 15:48:02 | Train | Epoch[020/200] Iteration[018/030] Train loss: 0.3136
2023-02-06 15:48:02 | Train | Epoch[020/200] Iteration[019/030] Train loss: 0.3133
2023-02-06 15:48:02 | Train | Epoch[020/200] Iteration[020/030] Train loss: 0.3130
2023-02-06 15:48:03 | Train | Epoch[020/200] Iteration[021/030] Train loss: 0.3130
2023-02-06 15:48:03 | Train | Epoch[020/200] Iteration[022/030] Train loss: 0.3127
2023-02-06 15:48:04 | Train | Epoch[020/200] Iteration[023/030] Train loss: 0.3125
2023-02-06 15:48:04 | Train | Epoch[020/200] Iteration[024/030] Train loss: 0.3124
2023-02-06 15:48:05 | Train | Epoch[020/200] Iteration[025/030] Train loss: 0.3121
2023-02-06 15:48:05 | Train | Epoch[020/200] Iteration[026/030] Train loss: 0.3119
2023-02-06 15:48:05 | Train | Epoch[020/200] Iteration[027/030] Train loss: 0.3116
2023-02-06 15:48:06 | Train | Epoch[020/200] Iteration[028/030] Train loss: 0.3113
2023-02-06 15:48:06 | Train | Epoch[020/200] Iteration[029/030] Train loss: 0.3110
2023-02-06 15:48:06 | Train | Epoch[020/200] Iteration[030/030] Train loss: 0.3109
2023-02-06 15:48:07 | Valid | Epoch[020/200] Iteration[001/008] Valid loss: 0.3598
2023-02-06 15:48:07 | Valid | Epoch[020/200] Iteration[002/008] Valid loss: 0.3614
2023-02-06 15:48:07 | Valid | Epoch[020/200] Iteration[003/008] Valid loss: 0.3598
2023-02-06 15:48:07 | Valid | Epoch[020/200] Iteration[004/008] Valid loss: 0.3596
2023-02-06 15:48:07 | Valid | Epoch[020/200] Iteration[005/008] Valid loss: 0.3597
2023-02-06 15:48:07 | Valid | Epoch[020/200] Iteration[006/008] Valid loss: 0.3598
2023-02-06 15:48:07 | Valid | Epoch[020/200] Iteration[007/008] Valid loss: 0.3614
2023-02-06 15:48:08 | Valid | Epoch[020/200] Iteration[008/008] Valid loss: 0.3620
2023-02-06 15:48:08 | Valid | Epoch[020/200] MIou: 0.8757812400923035
2023-02-06 15:48:08 | Valid | Epoch[020/200] Pixel Accuracy: 0.9762611389160156
2023-02-06 15:48:08 | Valid | Epoch[020/200] Mean Pixel Accuracy: 0.9501012890820961
2023-02-06 15:48:08 | Stage | Epoch[020/200] Train loss:0.3109
2023-02-06 15:48:08 | Stage | Epoch[020/200] Valid loss:0.3620
2023-02-06 15:48:08 | Stage | Epoch[020/200] LR:0.01

2023-02-06 15:48:08 | Train | Epoch[021/200] Iteration[001/030] Train loss: 0.3110
2023-02-06 15:48:09 | Train | Epoch[021/200] Iteration[002/030] Train loss: 0.3076
2023-02-06 15:48:09 | Train | Epoch[021/200] Iteration[003/030] Train loss: 0.3048
2023-02-06 15:48:10 | Train | Epoch[021/200] Iteration[004/030] Train loss: 0.3039
2023-02-06 15:48:10 | Train | Epoch[021/200] Iteration[005/030] Train loss: 0.3033
2023-02-06 15:48:11 | Train | Epoch[021/200] Iteration[006/030] Train loss: 0.3035
2023-02-06 15:48:11 | Train | Epoch[021/200] Iteration[007/030] Train loss: 0.3030
2023-02-06 15:48:11 | Train | Epoch[021/200] Iteration[008/030] Train loss: 0.3029
2023-02-06 15:48:12 | Train | Epoch[021/200] Iteration[009/030] Train loss: 0.3024
2023-02-06 15:48:12 | Train | Epoch[021/200] Iteration[010/030] Train loss: 0.3023
2023-02-06 15:48:13 | Train | Epoch[021/200] Iteration[011/030] Train loss: 0.3026
2023-02-06 15:48:13 | Train | Epoch[021/200] Iteration[012/030] Train loss: 0.3022
2023-02-06 15:48:14 | Train | Epoch[021/200] Iteration[013/030] Train loss: 0.3020
2023-02-06 15:48:14 | Train | Epoch[021/200] Iteration[014/030] Train loss: 0.3020
2023-02-06 15:48:14 | Train | Epoch[021/200] Iteration[015/030] Train loss: 0.3017
2023-02-06 15:48:15 | Train | Epoch[021/200] Iteration[016/030] Train loss: 0.3014
2023-02-06 15:48:15 | Train | Epoch[021/200] Iteration[017/030] Train loss: 0.3012
2023-02-06 15:48:16 | Train | Epoch[021/200] Iteration[018/030] Train loss: 0.3010
2023-02-06 15:48:16 | Train | Epoch[021/200] Iteration[019/030] Train loss: 0.3009
2023-02-06 15:48:17 | Train | Epoch[021/200] Iteration[020/030] Train loss: 0.3007
2023-02-06 15:48:17 | Train | Epoch[021/200] Iteration[021/030] Train loss: 0.3004
2023-02-06 15:48:17 | Train | Epoch[021/200] Iteration[022/030] Train loss: 0.3002
2023-02-06 15:48:18 | Train | Epoch[021/200] Iteration[023/030] Train loss: 0.3002
2023-02-06 15:48:18 | Train | Epoch[021/200] Iteration[024/030] Train loss: 0.3001
2023-02-06 15:48:19 | Train | Epoch[021/200] Iteration[025/030] Train loss: 0.2999
2023-02-06 15:48:19 | Train | Epoch[021/200] Iteration[026/030] Train loss: 0.2997
2023-02-06 15:48:20 | Train | Epoch[021/200] Iteration[027/030] Train loss: 0.2996
2023-02-06 15:48:20 | Train | Epoch[021/200] Iteration[028/030] Train loss: 0.2997
2023-02-06 15:48:21 | Train | Epoch[021/200] Iteration[029/030] Train loss: 0.2996
2023-02-06 15:48:21 | Train | Epoch[021/200] Iteration[030/030] Train loss: 0.2993
2023-02-06 15:48:21 | Valid | Epoch[021/200] Iteration[001/008] Valid loss: 0.3012
2023-02-06 15:48:21 | Valid | Epoch[021/200] Iteration[002/008] Valid loss: 0.2993
2023-02-06 15:48:21 | Valid | Epoch[021/200] Iteration[003/008] Valid loss: 0.2987
2023-02-06 15:48:21 | Valid | Epoch[021/200] Iteration[004/008] Valid loss: 0.2980
2023-02-06 15:48:22 | Valid | Epoch[021/200] Iteration[005/008] Valid loss: 0.2986
2023-02-06 15:48:22 | Valid | Epoch[021/200] Iteration[006/008] Valid loss: 0.2990
2023-02-06 15:48:22 | Valid | Epoch[021/200] Iteration[007/008] Valid loss: 0.2994
2023-02-06 15:48:22 | Valid | Epoch[021/200] Iteration[008/008] Valid loss: 0.2988
2023-02-06 15:48:22 | Valid | Epoch[021/200] MIou: 0.9165097127692992
2023-02-06 15:48:22 | Valid | Epoch[021/200] Pixel Accuracy: 0.9859644571940104
2023-02-06 15:48:22 | Valid | Epoch[021/200] Mean Pixel Accuracy: 0.9331352083362129
2023-02-06 15:48:22 | Stage | Epoch[021/200] Train loss:0.2993
2023-02-06 15:48:22 | Stage | Epoch[021/200] Valid loss:0.2988
2023-02-06 15:48:22 | Stage | Epoch[021/200] LR:0.01

2023-02-06 15:48:23 | Train | Epoch[022/200] Iteration[001/030] Train loss: 0.2922
2023-02-06 15:48:23 | Train | Epoch[022/200] Iteration[002/030] Train loss: 0.2916
2023-02-06 15:48:23 | Train | Epoch[022/200] Iteration[003/030] Train loss: 0.2921
2023-02-06 15:48:24 | Train | Epoch[022/200] Iteration[004/030] Train loss: 0.2929
2023-02-06 15:48:24 | Train | Epoch[022/200] Iteration[005/030] Train loss: 0.2932
2023-02-06 15:48:25 | Train | Epoch[022/200] Iteration[006/030] Train loss: 0.2931
2023-02-06 15:48:25 | Train | Epoch[022/200] Iteration[007/030] Train loss: 0.2938
2023-02-06 15:48:26 | Train | Epoch[022/200] Iteration[008/030] Train loss: 0.2932
2023-02-06 15:48:26 | Train | Epoch[022/200] Iteration[009/030] Train loss: 0.2929
2023-02-06 15:48:27 | Train | Epoch[022/200] Iteration[010/030] Train loss: 0.2925
2023-02-06 15:48:27 | Train | Epoch[022/200] Iteration[011/030] Train loss: 0.2927
2023-02-06 15:48:27 | Train | Epoch[022/200] Iteration[012/030] Train loss: 0.2923
2023-02-06 15:48:28 | Train | Epoch[022/200] Iteration[013/030] Train loss: 0.2917
2023-02-06 15:48:28 | Train | Epoch[022/200] Iteration[014/030] Train loss: 0.2915
2023-02-06 15:48:29 | Train | Epoch[022/200] Iteration[015/030] Train loss: 0.2912
2023-02-06 15:48:29 | Train | Epoch[022/200] Iteration[016/030] Train loss: 0.2910
2023-02-06 15:48:30 | Train | Epoch[022/200] Iteration[017/030] Train loss: 0.2906
2023-02-06 15:48:30 | Train | Epoch[022/200] Iteration[018/030] Train loss: 0.2906
2023-02-06 15:48:30 | Train | Epoch[022/200] Iteration[019/030] Train loss: 0.2907
2023-02-06 15:48:31 | Train | Epoch[022/200] Iteration[020/030] Train loss: 0.2905
2023-02-06 15:48:31 | Train | Epoch[022/200] Iteration[021/030] Train loss: 0.2904
2023-02-06 15:48:32 | Train | Epoch[022/200] Iteration[022/030] Train loss: 0.2901
2023-02-06 15:48:32 | Train | Epoch[022/200] Iteration[023/030] Train loss: 0.2898
2023-02-06 15:48:33 | Train | Epoch[022/200] Iteration[024/030] Train loss: 0.2895
2023-02-06 15:48:33 | Train | Epoch[022/200] Iteration[025/030] Train loss: 0.2895
2023-02-06 15:48:33 | Train | Epoch[022/200] Iteration[026/030] Train loss: 0.2893
2023-02-06 15:48:34 | Train | Epoch[022/200] Iteration[027/030] Train loss: 0.2891
2023-02-06 15:48:34 | Train | Epoch[022/200] Iteration[028/030] Train loss: 0.2891
2023-02-06 15:48:35 | Train | Epoch[022/200] Iteration[029/030] Train loss: 0.2890
2023-02-06 15:48:35 | Train | Epoch[022/200] Iteration[030/030] Train loss: 0.2887
2023-02-06 15:48:35 | Valid | Epoch[022/200] Iteration[001/008] Valid loss: 0.3932
2023-02-06 15:48:36 | Valid | Epoch[022/200] Iteration[002/008] Valid loss: 0.3862
2023-02-06 15:48:36 | Valid | Epoch[022/200] Iteration[003/008] Valid loss: 0.3869
2023-02-06 15:48:36 | Valid | Epoch[022/200] Iteration[004/008] Valid loss: 0.3870
2023-02-06 15:48:36 | Valid | Epoch[022/200] Iteration[005/008] Valid loss: 0.3904
2023-02-06 15:48:36 | Valid | Epoch[022/200] Iteration[006/008] Valid loss: 0.3850
2023-02-06 15:48:36 | Valid | Epoch[022/200] Iteration[007/008] Valid loss: 0.3890
2023-02-06 15:48:36 | Valid | Epoch[022/200] Iteration[008/008] Valid loss: 0.3946
2023-02-06 15:48:36 | Valid | Epoch[022/200] MIou: 0.8452219089715878
2023-02-06 15:48:36 | Valid | Epoch[022/200] Pixel Accuracy: 0.9663556416829427
2023-02-06 15:48:36 | Valid | Epoch[022/200] Mean Pixel Accuracy: 0.9788192658506459
2023-02-06 15:48:36 | Stage | Epoch[022/200] Train loss:0.2887
2023-02-06 15:48:36 | Stage | Epoch[022/200] Valid loss:0.3946
2023-02-06 15:48:36 | Stage | Epoch[022/200] LR:0.01

2023-02-06 15:48:37 | Train | Epoch[023/200] Iteration[001/030] Train loss: 0.2863
2023-02-06 15:48:37 | Train | Epoch[023/200] Iteration[002/030] Train loss: 0.2838
2023-02-06 15:48:38 | Train | Epoch[023/200] Iteration[003/030] Train loss: 0.2841
2023-02-06 15:48:38 | Train | Epoch[023/200] Iteration[004/030] Train loss: 0.2829
2023-02-06 15:48:39 | Train | Epoch[023/200] Iteration[005/030] Train loss: 0.2832
2023-02-06 15:48:39 | Train | Epoch[023/200] Iteration[006/030] Train loss: 0.2827
2023-02-06 15:48:40 | Train | Epoch[023/200] Iteration[007/030] Train loss: 0.2817
2023-02-06 15:48:40 | Train | Epoch[023/200] Iteration[008/030] Train loss: 0.2819
2023-02-06 15:48:40 | Train | Epoch[023/200] Iteration[009/030] Train loss: 0.2823
2023-02-06 15:48:41 | Train | Epoch[023/200] Iteration[010/030] Train loss: 0.2818
2023-02-06 15:48:41 | Train | Epoch[023/200] Iteration[011/030] Train loss: 0.2821
2023-02-06 15:48:42 | Train | Epoch[023/200] Iteration[012/030] Train loss: 0.2817
2023-02-06 15:48:42 | Train | Epoch[023/200] Iteration[013/030] Train loss: 0.2813
2023-02-06 15:48:43 | Train | Epoch[023/200] Iteration[014/030] Train loss: 0.2812
2023-02-06 15:48:43 | Train | Epoch[023/200] Iteration[015/030] Train loss: 0.2812
2023-02-06 15:48:44 | Train | Epoch[023/200] Iteration[016/030] Train loss: 0.2808
2023-02-06 15:48:44 | Train | Epoch[023/200] Iteration[017/030] Train loss: 0.2804
2023-02-06 15:48:44 | Train | Epoch[023/200] Iteration[018/030] Train loss: 0.2803
2023-02-06 15:48:45 | Train | Epoch[023/200] Iteration[019/030] Train loss: 0.2800
2023-02-06 15:48:45 | Train | Epoch[023/200] Iteration[020/030] Train loss: 0.2800
2023-02-06 15:48:46 | Train | Epoch[023/200] Iteration[021/030] Train loss: 0.2799
2023-02-06 15:48:46 | Train | Epoch[023/200] Iteration[022/030] Train loss: 0.2798
2023-02-06 15:48:47 | Train | Epoch[023/200] Iteration[023/030] Train loss: 0.2797
2023-02-06 15:48:47 | Train | Epoch[023/200] Iteration[024/030] Train loss: 0.2795
2023-02-06 15:48:47 | Train | Epoch[023/200] Iteration[025/030] Train loss: 0.2793
2023-02-06 15:48:48 | Train | Epoch[023/200] Iteration[026/030] Train loss: 0.2793
2023-02-06 15:48:48 | Train | Epoch[023/200] Iteration[027/030] Train loss: 0.2790
2023-02-06 15:48:49 | Train | Epoch[023/200] Iteration[028/030] Train loss: 0.2788
2023-02-06 15:48:49 | Train | Epoch[023/200] Iteration[029/030] Train loss: 0.2787
2023-02-06 15:48:49 | Train | Epoch[023/200] Iteration[030/030] Train loss: 0.2787
2023-02-06 15:48:50 | Valid | Epoch[023/200] Iteration[001/008] Valid loss: 0.3782
2023-02-06 15:48:50 | Valid | Epoch[023/200] Iteration[002/008] Valid loss: 0.3656
2023-02-06 15:48:50 | Valid | Epoch[023/200] Iteration[003/008] Valid loss: 0.3634
2023-02-06 15:48:50 | Valid | Epoch[023/200] Iteration[004/008] Valid loss: 0.3623
2023-02-06 15:48:50 | Valid | Epoch[023/200] Iteration[005/008] Valid loss: 0.3638
2023-02-06 15:48:50 | Valid | Epoch[023/200] Iteration[006/008] Valid loss: 0.3602
2023-02-06 15:48:50 | Valid | Epoch[023/200] Iteration[007/008] Valid loss: 0.3627
2023-02-06 15:48:51 | Valid | Epoch[023/200] Iteration[008/008] Valid loss: 0.3652
2023-02-06 15:48:51 | Valid | Epoch[023/200] MIou: 0.8635075233987686
2023-02-06 15:48:51 | Valid | Epoch[023/200] Pixel Accuracy: 0.9716110229492188
2023-02-06 15:48:51 | Valid | Epoch[023/200] Mean Pixel Accuracy: 0.9778591813233488
2023-02-06 15:48:51 | Stage | Epoch[023/200] Train loss:0.2787
2023-02-06 15:48:51 | Stage | Epoch[023/200] Valid loss:0.3652
2023-02-06 15:48:51 | Stage | Epoch[023/200] LR:0.01

2023-02-06 15:48:51 | Train | Epoch[024/200] Iteration[001/030] Train loss: 0.2776
2023-02-06 15:48:52 | Train | Epoch[024/200] Iteration[002/030] Train loss: 0.2745
2023-02-06 15:48:52 | Train | Epoch[024/200] Iteration[003/030] Train loss: 0.2732
2023-02-06 15:48:53 | Train | Epoch[024/200] Iteration[004/030] Train loss: 0.2725
2023-02-06 15:48:53 | Train | Epoch[024/200] Iteration[005/030] Train loss: 0.2717
2023-02-06 15:48:54 | Train | Epoch[024/200] Iteration[006/030] Train loss: 0.2710
2023-02-06 15:48:54 | Train | Epoch[024/200] Iteration[007/030] Train loss: 0.2708
2023-02-06 15:48:54 | Train | Epoch[024/200] Iteration[008/030] Train loss: 0.2709
2023-02-06 15:48:55 | Train | Epoch[024/200] Iteration[009/030] Train loss: 0.2703
2023-02-06 15:48:55 | Train | Epoch[024/200] Iteration[010/030] Train loss: 0.2702
2023-02-06 15:48:56 | Train | Epoch[024/200] Iteration[011/030] Train loss: 0.2699
2023-02-06 15:48:56 | Train | Epoch[024/200] Iteration[012/030] Train loss: 0.2699
2023-02-06 15:48:57 | Train | Epoch[024/200] Iteration[013/030] Train loss: 0.2698
2023-02-06 15:48:57 | Train | Epoch[024/200] Iteration[014/030] Train loss: 0.2699
2023-02-06 15:48:57 | Train | Epoch[024/200] Iteration[015/030] Train loss: 0.2705
2023-02-06 15:48:58 | Train | Epoch[024/200] Iteration[016/030] Train loss: 0.2703
2023-02-06 15:48:58 | Train | Epoch[024/200] Iteration[017/030] Train loss: 0.2702
2023-02-06 15:48:59 | Train | Epoch[024/200] Iteration[018/030] Train loss: 0.2701
2023-02-06 15:48:59 | Train | Epoch[024/200] Iteration[019/030] Train loss: 0.2701
2023-02-06 15:49:00 | Train | Epoch[024/200] Iteration[020/030] Train loss: 0.2701
2023-02-06 15:49:00 | Train | Epoch[024/200] Iteration[021/030] Train loss: 0.2699
2023-02-06 15:49:01 | Train | Epoch[024/200] Iteration[022/030] Train loss: 0.2697
2023-02-06 15:49:01 | Train | Epoch[024/200] Iteration[023/030] Train loss: 0.2697
2023-02-06 15:49:01 | Train | Epoch[024/200] Iteration[024/030] Train loss: 0.2693
2023-02-06 15:49:02 | Train | Epoch[024/200] Iteration[025/030] Train loss: 0.2691
2023-02-06 15:49:02 | Train | Epoch[024/200] Iteration[026/030] Train loss: 0.2691
2023-02-06 15:49:03 | Train | Epoch[024/200] Iteration[027/030] Train loss: 0.2689
2023-02-06 15:49:03 | Train | Epoch[024/200] Iteration[028/030] Train loss: 0.2688
2023-02-06 15:49:04 | Train | Epoch[024/200] Iteration[029/030] Train loss: 0.2686
2023-02-06 15:49:04 | Train | Epoch[024/200] Iteration[030/030] Train loss: 0.2685
2023-02-06 15:49:04 | Valid | Epoch[024/200] Iteration[001/008] Valid loss: 0.4354
2023-02-06 15:49:04 | Valid | Epoch[024/200] Iteration[002/008] Valid loss: 0.4296
2023-02-06 15:49:04 | Valid | Epoch[024/200] Iteration[003/008] Valid loss: 0.4333
2023-02-06 15:49:04 | Valid | Epoch[024/200] Iteration[004/008] Valid loss: 0.4340
2023-02-06 15:49:05 | Valid | Epoch[024/200] Iteration[005/008] Valid loss: 0.4397
2023-02-06 15:49:05 | Valid | Epoch[024/200] Iteration[006/008] Valid loss: 0.4380
2023-02-06 15:49:05 | Valid | Epoch[024/200] Iteration[007/008] Valid loss: 0.4435
2023-02-06 15:49:05 | Valid | Epoch[024/200] Iteration[008/008] Valid loss: 0.4454
2023-02-06 15:49:05 | Valid | Epoch[024/200] MIou: 0.8055894698599909
2023-02-06 15:49:05 | Valid | Epoch[024/200] Pixel Accuracy: 0.9540799458821615
2023-02-06 15:49:05 | Valid | Epoch[024/200] Mean Pixel Accuracy: 0.9721227436648698
2023-02-06 15:49:05 | Stage | Epoch[024/200] Train loss:0.2685
2023-02-06 15:49:05 | Stage | Epoch[024/200] Valid loss:0.4454
2023-02-06 15:49:05 | Stage | Epoch[024/200] LR:0.01

2023-02-06 15:49:06 | Train | Epoch[025/200] Iteration[001/030] Train loss: 0.2642
2023-02-06 15:49:06 | Train | Epoch[025/200] Iteration[002/030] Train loss: 0.2624
2023-02-06 15:49:07 | Train | Epoch[025/200] Iteration[003/030] Train loss: 0.2617
2023-02-06 15:49:07 | Train | Epoch[025/200] Iteration[004/030] Train loss: 0.2628
2023-02-06 15:49:07 | Train | Epoch[025/200] Iteration[005/030] Train loss: 0.2624
2023-02-06 15:49:08 | Train | Epoch[025/200] Iteration[006/030] Train loss: 0.2628
2023-02-06 15:49:08 | Train | Epoch[025/200] Iteration[007/030] Train loss: 0.2628
2023-02-06 15:49:09 | Train | Epoch[025/200] Iteration[008/030] Train loss: 0.2624
2023-02-06 15:49:09 | Train | Epoch[025/200] Iteration[009/030] Train loss: 0.2622
2023-02-06 15:49:10 | Train | Epoch[025/200] Iteration[010/030] Train loss: 0.2621
2023-02-06 15:49:10 | Train | Epoch[025/200] Iteration[011/030] Train loss: 0.2619
2023-02-06 15:49:10 | Train | Epoch[025/200] Iteration[012/030] Train loss: 0.2616
2023-02-06 15:49:11 | Train | Epoch[025/200] Iteration[013/030] Train loss: 0.2613
2023-02-06 15:49:11 | Train | Epoch[025/200] Iteration[014/030] Train loss: 0.2610
2023-02-06 15:49:12 | Train | Epoch[025/200] Iteration[015/030] Train loss: 0.2608
2023-02-06 15:49:12 | Train | Epoch[025/200] Iteration[016/030] Train loss: 0.2603
2023-02-06 15:49:13 | Train | Epoch[025/200] Iteration[017/030] Train loss: 0.2601
2023-02-06 15:49:13 | Train | Epoch[025/200] Iteration[018/030] Train loss: 0.2600
2023-02-06 15:49:13 | Train | Epoch[025/200] Iteration[019/030] Train loss: 0.2601
2023-02-06 15:49:14 | Train | Epoch[025/200] Iteration[020/030] Train loss: 0.2601
2023-02-06 15:49:14 | Train | Epoch[025/200] Iteration[021/030] Train loss: 0.2598
2023-02-06 15:49:15 | Train | Epoch[025/200] Iteration[022/030] Train loss: 0.2595
2023-02-06 15:49:15 | Train | Epoch[025/200] Iteration[023/030] Train loss: 0.2595
2023-02-06 15:49:16 | Train | Epoch[025/200] Iteration[024/030] Train loss: 0.2595
2023-02-06 15:49:16 | Train | Epoch[025/200] Iteration[025/030] Train loss: 0.2593
2023-02-06 15:49:16 | Train | Epoch[025/200] Iteration[026/030] Train loss: 0.2593
2023-02-06 15:49:17 | Train | Epoch[025/200] Iteration[027/030] Train loss: 0.2593
2023-02-06 15:49:17 | Train | Epoch[025/200] Iteration[028/030] Train loss: 0.2591
2023-02-06 15:49:18 | Train | Epoch[025/200] Iteration[029/030] Train loss: 0.2591
2023-02-06 15:49:18 | Train | Epoch[025/200] Iteration[030/030] Train loss: 0.2589
2023-02-06 15:49:18 | Valid | Epoch[025/200] Iteration[001/008] Valid loss: 0.3029
2023-02-06 15:49:19 | Valid | Epoch[025/200] Iteration[002/008] Valid loss: 0.2969
2023-02-06 15:49:19 | Valid | Epoch[025/200] Iteration[003/008] Valid loss: 0.2965
2023-02-06 15:49:19 | Valid | Epoch[025/200] Iteration[004/008] Valid loss: 0.2963
2023-02-06 15:49:19 | Valid | Epoch[025/200] Iteration[005/008] Valid loss: 0.2973
2023-02-06 15:49:19 | Valid | Epoch[025/200] Iteration[006/008] Valid loss: 0.2985
2023-02-06 15:49:19 | Valid | Epoch[025/200] Iteration[007/008] Valid loss: 0.2995
2023-02-06 15:49:19 | Valid | Epoch[025/200] Iteration[008/008] Valid loss: 0.2997
2023-02-06 15:49:19 | Valid | Epoch[025/200] MIou: 0.8539617152802255
2023-02-06 15:49:19 | Valid | Epoch[025/200] Pixel Accuracy: 0.9740308125813802
2023-02-06 15:49:19 | Valid | Epoch[025/200] Mean Pixel Accuracy: 0.8962241311711523
2023-02-06 15:49:19 | Stage | Epoch[025/200] Train loss:0.2589
2023-02-06 15:49:19 | Stage | Epoch[025/200] Valid loss:0.2997
2023-02-06 15:49:19 | Stage | Epoch[025/200] LR:0.01

2023-02-06 15:49:20 | Train | Epoch[026/200] Iteration[001/030] Train loss: 0.2547
2023-02-06 15:49:20 | Train | Epoch[026/200] Iteration[002/030] Train loss: 0.2540
2023-02-06 15:49:21 | Train | Epoch[026/200] Iteration[003/030] Train loss: 0.2537
2023-02-06 15:49:21 | Train | Epoch[026/200] Iteration[004/030] Train loss: 0.2527
2023-02-06 15:49:22 | Train | Epoch[026/200] Iteration[005/030] Train loss: 0.2522
2023-02-06 15:49:22 | Train | Epoch[026/200] Iteration[006/030] Train loss: 0.2532
2023-02-06 15:49:22 | Train | Epoch[026/200] Iteration[007/030] Train loss: 0.2532
2023-02-06 15:49:23 | Train | Epoch[026/200] Iteration[008/030] Train loss: 0.2533
2023-02-06 15:49:23 | Train | Epoch[026/200] Iteration[009/030] Train loss: 0.2538
2023-02-06 15:49:24 | Train | Epoch[026/200] Iteration[010/030] Train loss: 0.2535
2023-02-06 15:49:24 | Train | Epoch[026/200] Iteration[011/030] Train loss: 0.2533
2023-02-06 15:49:25 | Train | Epoch[026/200] Iteration[012/030] Train loss: 0.2533
2023-02-06 15:49:25 | Train | Epoch[026/200] Iteration[013/030] Train loss: 0.2531
2023-02-06 15:49:26 | Train | Epoch[026/200] Iteration[014/030] Train loss: 0.2539
2023-02-06 15:49:26 | Train | Epoch[026/200] Iteration[015/030] Train loss: 0.2537
2023-02-06 15:49:26 | Train | Epoch[026/200] Iteration[016/030] Train loss: 0.2534
2023-02-06 15:49:27 | Train | Epoch[026/200] Iteration[017/030] Train loss: 0.2534
2023-02-06 15:49:27 | Train | Epoch[026/200] Iteration[018/030] Train loss: 0.2531
2023-02-06 15:49:28 | Train | Epoch[026/200] Iteration[019/030] Train loss: 0.2528
2023-02-06 15:49:28 | Train | Epoch[026/200] Iteration[020/030] Train loss: 0.2526
2023-02-06 15:49:29 | Train | Epoch[026/200] Iteration[021/030] Train loss: 0.2523
2023-02-06 15:49:29 | Train | Epoch[026/200] Iteration[022/030] Train loss: 0.2524
2023-02-06 15:49:29 | Train | Epoch[026/200] Iteration[023/030] Train loss: 0.2521
2023-02-06 15:49:30 | Train | Epoch[026/200] Iteration[024/030] Train loss: 0.2518
2023-02-06 15:49:30 | Train | Epoch[026/200] Iteration[025/030] Train loss: 0.2515
2023-02-06 15:49:31 | Train | Epoch[026/200] Iteration[026/030] Train loss: 0.2513
2023-02-06 15:49:31 | Train | Epoch[026/200] Iteration[027/030] Train loss: 0.2512
2023-02-06 15:49:32 | Train | Epoch[026/200] Iteration[028/030] Train loss: 0.2511
2023-02-06 15:49:32 | Train | Epoch[026/200] Iteration[029/030] Train loss: 0.2510
2023-02-06 15:49:32 | Train | Epoch[026/200] Iteration[030/030] Train loss: 0.2508
2023-02-06 15:49:33 | Valid | Epoch[026/200] Iteration[001/008] Valid loss: 0.2806
2023-02-06 15:49:33 | Valid | Epoch[026/200] Iteration[002/008] Valid loss: 0.2794
2023-02-06 15:49:33 | Valid | Epoch[026/200] Iteration[003/008] Valid loss: 0.2798
2023-02-06 15:49:33 | Valid | Epoch[026/200] Iteration[004/008] Valid loss: 0.2799
2023-02-06 15:49:33 | Valid | Epoch[026/200] Iteration[005/008] Valid loss: 0.2801
2023-02-06 15:49:33 | Valid | Epoch[026/200] Iteration[006/008] Valid loss: 0.2805
2023-02-06 15:49:33 | Valid | Epoch[026/200] Iteration[007/008] Valid loss: 0.2808
2023-02-06 15:49:33 | Valid | Epoch[026/200] Iteration[008/008] Valid loss: 0.2815
2023-02-06 15:49:33 | Valid | Epoch[026/200] MIou: 0.8902309088770879
2023-02-06 15:49:33 | Valid | Epoch[026/200] Pixel Accuracy: 0.9800224304199219
2023-02-06 15:49:33 | Valid | Epoch[026/200] Mean Pixel Accuracy: 0.9426642885112382
2023-02-06 15:49:33 | Stage | Epoch[026/200] Train loss:0.2508
2023-02-06 15:49:33 | Stage | Epoch[026/200] Valid loss:0.2815
2023-02-06 15:49:33 | Stage | Epoch[026/200] LR:0.01

2023-02-06 15:49:34 | Train | Epoch[027/200] Iteration[001/030] Train loss: 0.2438
2023-02-06 15:49:35 | Train | Epoch[027/200] Iteration[002/030] Train loss: 0.2454
2023-02-06 15:49:35 | Train | Epoch[027/200] Iteration[003/030] Train loss: 0.2461
2023-02-06 15:49:36 | Train | Epoch[027/200] Iteration[004/030] Train loss: 0.2462
2023-02-06 15:49:36 | Train | Epoch[027/200] Iteration[005/030] Train loss: 0.2457
2023-02-06 15:49:36 | Train | Epoch[027/200] Iteration[006/030] Train loss: 0.2451
2023-02-06 15:49:37 | Train | Epoch[027/200] Iteration[007/030] Train loss: 0.2447
2023-02-06 15:49:37 | Train | Epoch[027/200] Iteration[008/030] Train loss: 0.2443
2023-02-06 15:49:38 | Train | Epoch[027/200] Iteration[009/030] Train loss: 0.2443
2023-02-06 15:49:38 | Train | Epoch[027/200] Iteration[010/030] Train loss: 0.2438
2023-02-06 15:49:39 | Train | Epoch[027/200] Iteration[011/030] Train loss: 0.2435
2023-02-06 15:49:39 | Train | Epoch[027/200] Iteration[012/030] Train loss: 0.2432
2023-02-06 15:49:40 | Train | Epoch[027/200] Iteration[013/030] Train loss: 0.2431
2023-02-06 15:49:40 | Train | Epoch[027/200] Iteration[014/030] Train loss: 0.2430
2023-02-06 15:49:40 | Train | Epoch[027/200] Iteration[015/030] Train loss: 0.2427
2023-02-06 15:49:41 | Train | Epoch[027/200] Iteration[016/030] Train loss: 0.2427
2023-02-06 15:49:41 | Train | Epoch[027/200] Iteration[017/030] Train loss: 0.2430
2023-02-06 15:49:42 | Train | Epoch[027/200] Iteration[018/030] Train loss: 0.2427
2023-02-06 15:49:42 | Train | Epoch[027/200] Iteration[019/030] Train loss: 0.2424
2023-02-06 15:49:43 | Train | Epoch[027/200] Iteration[020/030] Train loss: 0.2422
2023-02-06 15:49:43 | Train | Epoch[027/200] Iteration[021/030] Train loss: 0.2420
2023-02-06 15:49:43 | Train | Epoch[027/200] Iteration[022/030] Train loss: 0.2424
2023-02-06 15:49:44 | Train | Epoch[027/200] Iteration[023/030] Train loss: 0.2422
2023-02-06 15:49:44 | Train | Epoch[027/200] Iteration[024/030] Train loss: 0.2421
2023-02-06 15:49:45 | Train | Epoch[027/200] Iteration[025/030] Train loss: 0.2421
2023-02-06 15:49:45 | Train | Epoch[027/200] Iteration[026/030] Train loss: 0.2421
2023-02-06 15:49:46 | Train | Epoch[027/200] Iteration[027/030] Train loss: 0.2419
2023-02-06 15:49:46 | Train | Epoch[027/200] Iteration[028/030] Train loss: 0.2417
2023-02-06 15:49:46 | Train | Epoch[027/200] Iteration[029/030] Train loss: 0.2416
2023-02-06 15:49:47 | Train | Epoch[027/200] Iteration[030/030] Train loss: 0.2413
2023-02-06 15:49:47 | Valid | Epoch[027/200] Iteration[001/008] Valid loss: 0.2983
2023-02-06 15:49:47 | Valid | Epoch[027/200] Iteration[002/008] Valid loss: 0.3004
2023-02-06 15:49:47 | Valid | Epoch[027/200] Iteration[003/008] Valid loss: 0.3046
2023-02-06 15:49:47 | Valid | Epoch[027/200] Iteration[004/008] Valid loss: 0.3038
2023-02-06 15:49:47 | Valid | Epoch[027/200] Iteration[005/008] Valid loss: 0.3067
2023-02-06 15:49:48 | Valid | Epoch[027/200] Iteration[006/008] Valid loss: 0.3060
2023-02-06 15:49:48 | Valid | Epoch[027/200] Iteration[007/008] Valid loss: 0.3061
2023-02-06 15:49:48 | Valid | Epoch[027/200] Iteration[008/008] Valid loss: 0.3092
2023-02-06 15:49:48 | Valid | Epoch[027/200] MIou: 0.5419655542365391
2023-02-06 15:49:48 | Valid | Epoch[027/200] Pixel Accuracy: 0.9231847127278646
2023-02-06 15:49:48 | Valid | Epoch[027/200] Mean Pixel Accuracy: 0.5814149935369233
2023-02-06 15:49:48 | Stage | Epoch[027/200] Train loss:0.2413
2023-02-06 15:49:48 | Stage | Epoch[027/200] Valid loss:0.3092
2023-02-06 15:49:48 | Stage | Epoch[027/200] LR:0.01

2023-02-06 15:49:49 | Train | Epoch[028/200] Iteration[001/030] Train loss: 0.2368
2023-02-06 15:49:49 | Train | Epoch[028/200] Iteration[002/030] Train loss: 0.2362
2023-02-06 15:49:50 | Train | Epoch[028/200] Iteration[003/030] Train loss: 0.2373
2023-02-06 15:49:50 | Train | Epoch[028/200] Iteration[004/030] Train loss: 0.2377
2023-02-06 15:49:50 | Train | Epoch[028/200] Iteration[005/030] Train loss: 0.2368
2023-02-06 15:49:51 | Train | Epoch[028/200] Iteration[006/030] Train loss: 0.2362
2023-02-06 15:49:51 | Train | Epoch[028/200] Iteration[007/030] Train loss: 0.2359
2023-02-06 15:49:52 | Train | Epoch[028/200] Iteration[008/030] Train loss: 0.2357
2023-02-06 15:49:52 | Train | Epoch[028/200] Iteration[009/030] Train loss: 0.2355
2023-02-06 15:49:53 | Train | Epoch[028/200] Iteration[010/030] Train loss: 0.2353
2023-02-06 15:49:53 | Train | Epoch[028/200] Iteration[011/030] Train loss: 0.2350
2023-02-06 15:49:53 | Train | Epoch[028/200] Iteration[012/030] Train loss: 0.2347
2023-02-06 15:49:54 | Train | Epoch[028/200] Iteration[013/030] Train loss: 0.2347
2023-02-06 15:49:54 | Train | Epoch[028/200] Iteration[014/030] Train loss: 0.2346
2023-02-06 15:49:55 | Train | Epoch[028/200] Iteration[015/030] Train loss: 0.2342
2023-02-06 15:49:55 | Train | Epoch[028/200] Iteration[016/030] Train loss: 0.2341
2023-02-06 15:49:56 | Train | Epoch[028/200] Iteration[017/030] Train loss: 0.2340
2023-02-06 15:49:56 | Train | Epoch[028/200] Iteration[018/030] Train loss: 0.2342
2023-02-06 15:49:56 | Train | Epoch[028/200] Iteration[019/030] Train loss: 0.2341
2023-02-06 15:49:57 | Train | Epoch[028/200] Iteration[020/030] Train loss: 0.2339
2023-02-06 15:49:57 | Train | Epoch[028/200] Iteration[021/030] Train loss: 0.2337
2023-02-06 15:49:58 | Train | Epoch[028/200] Iteration[022/030] Train loss: 0.2336
2023-02-06 15:49:58 | Train | Epoch[028/200] Iteration[023/030] Train loss: 0.2334
2023-02-06 15:49:59 | Train | Epoch[028/200] Iteration[024/030] Train loss: 0.2332
2023-02-06 15:49:59 | Train | Epoch[028/200] Iteration[025/030] Train loss: 0.2332
2023-02-06 15:50:00 | Train | Epoch[028/200] Iteration[026/030] Train loss: 0.2332
2023-02-06 15:50:00 | Train | Epoch[028/200] Iteration[027/030] Train loss: 0.2331
2023-02-06 15:50:00 | Train | Epoch[028/200] Iteration[028/030] Train loss: 0.2329
2023-02-06 15:50:01 | Train | Epoch[028/200] Iteration[029/030] Train loss: 0.2328
2023-02-06 15:50:01 | Train | Epoch[028/200] Iteration[030/030] Train loss: 0.2326
2023-02-06 15:50:01 | Valid | Epoch[028/200] Iteration[001/008] Valid loss: 0.2540
2023-02-06 15:50:02 | Valid | Epoch[028/200] Iteration[002/008] Valid loss: 0.2494
2023-02-06 15:50:02 | Valid | Epoch[028/200] Iteration[003/008] Valid loss: 0.2473
2023-02-06 15:50:02 | Valid | Epoch[028/200] Iteration[004/008] Valid loss: 0.2462
2023-02-06 15:50:02 | Valid | Epoch[028/200] Iteration[005/008] Valid loss: 0.2468
2023-02-06 15:50:02 | Valid | Epoch[028/200] Iteration[006/008] Valid loss: 0.2470
2023-02-06 15:50:02 | Valid | Epoch[028/200] Iteration[007/008] Valid loss: 0.2475
2023-02-06 15:50:02 | Valid | Epoch[028/200] Iteration[008/008] Valid loss: 0.2472
2023-02-06 15:50:02 | Valid | Epoch[028/200] MIou: 0.9283707486804389
2023-02-06 15:50:02 | Valid | Epoch[028/200] Pixel Accuracy: 0.987616221110026
2023-02-06 15:50:02 | Valid | Epoch[028/200] Mean Pixel Accuracy: 0.956989254632699
2023-02-06 15:50:02 | Stage | Epoch[028/200] Train loss:0.2326
2023-02-06 15:50:02 | Stage | Epoch[028/200] Valid loss:0.2472
2023-02-06 15:50:02 | Stage | Epoch[028/200] LR:0.01

2023-02-06 15:50:03 | Train | Epoch[029/200] Iteration[001/030] Train loss: 0.2292
2023-02-06 15:50:03 | Train | Epoch[029/200] Iteration[002/030] Train loss: 0.2277
2023-02-06 15:50:04 | Train | Epoch[029/200] Iteration[003/030] Train loss: 0.2279
2023-02-06 15:50:04 | Train | Epoch[029/200] Iteration[004/030] Train loss: 0.2275
2023-02-06 15:50:05 | Train | Epoch[029/200] Iteration[005/030] Train loss: 0.2274
2023-02-06 15:50:05 | Train | Epoch[029/200] Iteration[006/030] Train loss: 0.2276
2023-02-06 15:50:06 | Train | Epoch[029/200] Iteration[007/030] Train loss: 0.2276
2023-02-06 15:50:06 | Train | Epoch[029/200] Iteration[008/030] Train loss: 0.2274
2023-02-06 15:50:06 | Train | Epoch[029/200] Iteration[009/030] Train loss: 0.2271
2023-02-06 15:50:07 | Train | Epoch[029/200] Iteration[010/030] Train loss: 0.2269
2023-02-06 15:50:07 | Train | Epoch[029/200] Iteration[011/030] Train loss: 0.2265
2023-02-06 15:50:08 | Train | Epoch[029/200] Iteration[012/030] Train loss: 0.2260
2023-02-06 15:50:08 | Train | Epoch[029/200] Iteration[013/030] Train loss: 0.2258
2023-02-06 15:50:09 | Train | Epoch[029/200] Iteration[014/030] Train loss: 0.2256
2023-02-06 15:50:09 | Train | Epoch[029/200] Iteration[015/030] Train loss: 0.2257
2023-02-06 15:50:09 | Train | Epoch[029/200] Iteration[016/030] Train loss: 0.2262
2023-02-06 15:50:10 | Train | Epoch[029/200] Iteration[017/030] Train loss: 0.2264
2023-02-06 15:50:10 | Train | Epoch[029/200] Iteration[018/030] Train loss: 0.2264
2023-02-06 15:50:11 | Train | Epoch[029/200] Iteration[019/030] Train loss: 0.2262
2023-02-06 15:50:11 | Train | Epoch[029/200] Iteration[020/030] Train loss: 0.2261
2023-02-06 15:50:12 | Train | Epoch[029/200] Iteration[021/030] Train loss: 0.2258
2023-02-06 15:50:12 | Train | Epoch[029/200] Iteration[022/030] Train loss: 0.2255
2023-02-06 15:50:12 | Train | Epoch[029/200] Iteration[023/030] Train loss: 0.2254
2023-02-06 15:50:13 | Train | Epoch[029/200] Iteration[024/030] Train loss: 0.2251
2023-02-06 15:50:13 | Train | Epoch[029/200] Iteration[025/030] Train loss: 0.2251
2023-02-06 15:50:14 | Train | Epoch[029/200] Iteration[026/030] Train loss: 0.2249
2023-02-06 15:50:14 | Train | Epoch[029/200] Iteration[027/030] Train loss: 0.2250
2023-02-06 15:50:15 | Train | Epoch[029/200] Iteration[028/030] Train loss: 0.2251
2023-02-06 15:50:15 | Train | Epoch[029/200] Iteration[029/030] Train loss: 0.2250
2023-02-06 15:50:15 | Train | Epoch[029/200] Iteration[030/030] Train loss: 0.2249
2023-02-06 15:50:16 | Valid | Epoch[029/200] Iteration[001/008] Valid loss: 0.2749
2023-02-06 15:50:16 | Valid | Epoch[029/200] Iteration[002/008] Valid loss: 0.2681
2023-02-06 15:50:16 | Valid | Epoch[029/200] Iteration[003/008] Valid loss: 0.2672
2023-02-06 15:50:16 | Valid | Epoch[029/200] Iteration[004/008] Valid loss: 0.2664
2023-02-06 15:50:16 | Valid | Epoch[029/200] Iteration[005/008] Valid loss: 0.2684
2023-02-06 15:50:16 | Valid | Epoch[029/200] Iteration[006/008] Valid loss: 0.2670
2023-02-06 15:50:16 | Valid | Epoch[029/200] Iteration[007/008] Valid loss: 0.2701
2023-02-06 15:50:16 | Valid | Epoch[029/200] Iteration[008/008] Valid loss: 0.2704
2023-02-06 15:50:16 | Valid | Epoch[029/200] MIou: 0.9062436142275456
2023-02-06 15:50:16 | Valid | Epoch[029/200] Pixel Accuracy: 0.9820785522460938
2023-02-06 15:50:16 | Valid | Epoch[029/200] Mean Pixel Accuracy: 0.9828453848012768
2023-02-06 15:50:17 | Stage | Epoch[029/200] Train loss:0.2249
2023-02-06 15:50:17 | Stage | Epoch[029/200] Valid loss:0.2704
2023-02-06 15:50:17 | Stage | Epoch[029/200] LR:0.01

2023-02-06 15:50:17 | Train | Epoch[030/200] Iteration[001/030] Train loss: 0.2268
2023-02-06 15:50:18 | Train | Epoch[030/200] Iteration[002/030] Train loss: 0.2242
2023-02-06 15:50:18 | Train | Epoch[030/200] Iteration[003/030] Train loss: 0.2233
2023-02-06 15:50:19 | Train | Epoch[030/200] Iteration[004/030] Train loss: 0.2224
2023-02-06 15:50:19 | Train | Epoch[030/200] Iteration[005/030] Train loss: 0.2211
2023-02-06 15:50:19 | Train | Epoch[030/200] Iteration[006/030] Train loss: 0.2213
2023-02-06 15:50:20 | Train | Epoch[030/200] Iteration[007/030] Train loss: 0.2207
2023-02-06 15:50:20 | Train | Epoch[030/200] Iteration[008/030] Train loss: 0.2204
2023-02-06 15:50:21 | Train | Epoch[030/200] Iteration[009/030] Train loss: 0.2199
2023-02-06 15:50:21 | Train | Epoch[030/200] Iteration[010/030] Train loss: 0.2195
2023-02-06 15:50:22 | Train | Epoch[030/200] Iteration[011/030] Train loss: 0.2194
2023-02-06 15:50:22 | Train | Epoch[030/200] Iteration[012/030] Train loss: 0.2196
2023-02-06 15:50:23 | Train | Epoch[030/200] Iteration[013/030] Train loss: 0.2196
2023-02-06 15:50:23 | Train | Epoch[030/200] Iteration[014/030] Train loss: 0.2195
2023-02-06 15:50:23 | Train | Epoch[030/200] Iteration[015/030] Train loss: 0.2193
2023-02-06 15:50:24 | Train | Epoch[030/200] Iteration[016/030] Train loss: 0.2192
2023-02-06 15:50:24 | Train | Epoch[030/200] Iteration[017/030] Train loss: 0.2196
2023-02-06 15:50:25 | Train | Epoch[030/200] Iteration[018/030] Train loss: 0.2195
2023-02-06 15:50:25 | Train | Epoch[030/200] Iteration[019/030] Train loss: 0.2192
2023-02-06 15:50:26 | Train | Epoch[030/200] Iteration[020/030] Train loss: 0.2190
2023-02-06 15:50:26 | Train | Epoch[030/200] Iteration[021/030] Train loss: 0.2188
2023-02-06 15:50:26 | Train | Epoch[030/200] Iteration[022/030] Train loss: 0.2187
2023-02-06 15:50:27 | Train | Epoch[030/200] Iteration[023/030] Train loss: 0.2186
2023-02-06 15:50:27 | Train | Epoch[030/200] Iteration[024/030] Train loss: 0.2183
2023-02-06 15:50:28 | Train | Epoch[030/200] Iteration[025/030] Train loss: 0.2181
2023-02-06 15:50:28 | Train | Epoch[030/200] Iteration[026/030] Train loss: 0.2179
2023-02-06 15:50:29 | Train | Epoch[030/200] Iteration[027/030] Train loss: 0.2176
2023-02-06 15:50:29 | Train | Epoch[030/200] Iteration[028/030] Train loss: 0.2175
2023-02-06 15:50:29 | Train | Epoch[030/200] Iteration[029/030] Train loss: 0.2173
2023-02-06 15:50:30 | Train | Epoch[030/200] Iteration[030/030] Train loss: 0.2171
2023-02-06 15:50:30 | Valid | Epoch[030/200] Iteration[001/008] Valid loss: 0.3462
2023-02-06 15:50:30 | Valid | Epoch[030/200] Iteration[002/008] Valid loss: 0.3360
2023-02-06 15:50:30 | Valid | Epoch[030/200] Iteration[003/008] Valid loss: 0.3419
2023-02-06 15:50:30 | Valid | Epoch[030/200] Iteration[004/008] Valid loss: 0.3402
2023-02-06 15:50:30 | Valid | Epoch[030/200] Iteration[005/008] Valid loss: 0.3481
2023-02-06 15:50:31 | Valid | Epoch[030/200] Iteration[006/008] Valid loss: 0.3461
2023-02-06 15:50:31 | Valid | Epoch[030/200] Iteration[007/008] Valid loss: 0.3518
2023-02-06 15:50:31 | Valid | Epoch[030/200] Iteration[008/008] Valid loss: 0.3554
2023-02-06 15:50:31 | Valid | Epoch[030/200] MIou: 0.8523000516417795
2023-02-06 15:50:31 | Valid | Epoch[030/200] Pixel Accuracy: 0.9682668050130209
2023-02-06 15:50:31 | Valid | Epoch[030/200] Mean Pixel Accuracy: 0.98132803117378
2023-02-06 15:50:31 | Stage | Epoch[030/200] Train loss:0.2171
2023-02-06 15:50:31 | Stage | Epoch[030/200] Valid loss:0.3554
2023-02-06 15:50:31 | Stage | Epoch[030/200] LR:0.01

2023-02-06 15:50:32 | Train | Epoch[031/200] Iteration[001/030] Train loss: 0.2102
2023-02-06 15:50:32 | Train | Epoch[031/200] Iteration[002/030] Train loss: 0.2104
2023-02-06 15:50:32 | Train | Epoch[031/200] Iteration[003/030] Train loss: 0.2139
2023-02-06 15:50:33 | Train | Epoch[031/200] Iteration[004/030] Train loss: 0.2132
2023-02-06 15:50:33 | Train | Epoch[031/200] Iteration[005/030] Train loss: 0.2129
2023-02-06 15:50:34 | Train | Epoch[031/200] Iteration[006/030] Train loss: 0.2129
2023-02-06 15:50:34 | Train | Epoch[031/200] Iteration[007/030] Train loss: 0.2129
2023-02-06 15:50:35 | Train | Epoch[031/200] Iteration[008/030] Train loss: 0.2125
2023-02-06 15:50:35 | Train | Epoch[031/200] Iteration[009/030] Train loss: 0.2133
2023-02-06 15:50:35 | Train | Epoch[031/200] Iteration[010/030] Train loss: 0.2132
2023-02-06 15:50:36 | Train | Epoch[031/200] Iteration[011/030] Train loss: 0.2132
2023-02-06 15:50:36 | Train | Epoch[031/200] Iteration[012/030] Train loss: 0.2128
2023-02-06 15:50:37 | Train | Epoch[031/200] Iteration[013/030] Train loss: 0.2126
2023-02-06 15:50:37 | Train | Epoch[031/200] Iteration[014/030] Train loss: 0.2126
2023-02-06 15:50:38 | Train | Epoch[031/200] Iteration[015/030] Train loss: 0.2125
2023-02-06 15:50:38 | Train | Epoch[031/200] Iteration[016/030] Train loss: 0.2124
2023-02-06 15:50:38 | Train | Epoch[031/200] Iteration[017/030] Train loss: 0.2121
2023-02-06 15:50:39 | Train | Epoch[031/200] Iteration[018/030] Train loss: 0.2120
2023-02-06 15:50:39 | Train | Epoch[031/200] Iteration[019/030] Train loss: 0.2119
2023-02-06 15:50:40 | Train | Epoch[031/200] Iteration[020/030] Train loss: 0.2116
2023-02-06 15:50:40 | Train | Epoch[031/200] Iteration[021/030] Train loss: 0.2116
2023-02-06 15:50:41 | Train | Epoch[031/200] Iteration[022/030] Train loss: 0.2115
2023-02-06 15:50:41 | Train | Epoch[031/200] Iteration[023/030] Train loss: 0.2112
2023-02-06 15:50:42 | Train | Epoch[031/200] Iteration[024/030] Train loss: 0.2111
2023-02-06 15:50:42 | Train | Epoch[031/200] Iteration[025/030] Train loss: 0.2110
2023-02-06 15:50:42 | Train | Epoch[031/200] Iteration[026/030] Train loss: 0.2109
2023-02-06 15:50:43 | Train | Epoch[031/200] Iteration[027/030] Train loss: 0.2107
2023-02-06 15:50:43 | Train | Epoch[031/200] Iteration[028/030] Train loss: 0.2105
2023-02-06 15:50:44 | Train | Epoch[031/200] Iteration[029/030] Train loss: 0.2103
2023-02-06 15:50:44 | Train | Epoch[031/200] Iteration[030/030] Train loss: 0.2102
2023-02-06 15:50:44 | Valid | Epoch[031/200] Iteration[001/008] Valid loss: 0.3285
2023-02-06 15:50:44 | Valid | Epoch[031/200] Iteration[002/008] Valid loss: 0.3079
2023-02-06 15:50:45 | Valid | Epoch[031/200] Iteration[003/008] Valid loss: 0.3026
2023-02-06 15:50:45 | Valid | Epoch[031/200] Iteration[004/008] Valid loss: 0.3017
2023-02-06 15:50:45 | Valid | Epoch[031/200] Iteration[005/008] Valid loss: 0.3039
2023-02-06 15:50:45 | Valid | Epoch[031/200] Iteration[006/008] Valid loss: 0.3048
2023-02-06 15:50:45 | Valid | Epoch[031/200] Iteration[007/008] Valid loss: 0.3089
2023-02-06 15:50:45 | Valid | Epoch[031/200] Iteration[008/008] Valid loss: 0.3094
2023-02-06 15:50:45 | Valid | Epoch[031/200] MIou: 0.877777291101717
2023-02-06 15:50:45 | Valid | Epoch[031/200] Pixel Accuracy: 0.9751739501953125
2023-02-06 15:50:45 | Valid | Epoch[031/200] Mean Pixel Accuracy: 0.9822015353815158
2023-02-06 15:50:45 | Stage | Epoch[031/200] Train loss:0.2102
2023-02-06 15:50:45 | Stage | Epoch[031/200] Valid loss:0.3094
2023-02-06 15:50:45 | Stage | Epoch[031/200] LR:0.01

2023-02-06 15:50:46 | Train | Epoch[032/200] Iteration[001/030] Train loss: 0.2079
2023-02-06 15:50:46 | Train | Epoch[032/200] Iteration[002/030] Train loss: 0.2060
2023-02-06 15:50:47 | Train | Epoch[032/200] Iteration[003/030] Train loss: 0.2062
2023-02-06 15:50:47 | Train | Epoch[032/200] Iteration[004/030] Train loss: 0.2054
2023-02-06 15:50:48 | Train | Epoch[032/200] Iteration[005/030] Train loss: 0.2050
2023-02-06 15:50:48 | Train | Epoch[032/200] Iteration[006/030] Train loss: 0.2055
2023-02-06 15:50:48 | Train | Epoch[032/200] Iteration[007/030] Train loss: 0.2054
2023-02-06 15:50:49 | Train | Epoch[032/200] Iteration[008/030] Train loss: 0.2050
2023-02-06 15:50:49 | Train | Epoch[032/200] Iteration[009/030] Train loss: 0.2050
2023-02-06 15:50:50 | Train | Epoch[032/200] Iteration[010/030] Train loss: 0.2050
2023-02-06 15:50:50 | Train | Epoch[032/200] Iteration[011/030] Train loss: 0.2048
2023-02-06 15:50:51 | Train | Epoch[032/200] Iteration[012/030] Train loss: 0.2053
2023-02-06 15:50:51 | Train | Epoch[032/200] Iteration[013/030] Train loss: 0.2051
2023-02-06 15:50:52 | Train | Epoch[032/200] Iteration[014/030] Train loss: 0.2050
2023-02-06 15:50:52 | Train | Epoch[032/200] Iteration[015/030] Train loss: 0.2049
2023-02-06 15:50:52 | Train | Epoch[032/200] Iteration[016/030] Train loss: 0.2049
2023-02-06 15:50:53 | Train | Epoch[032/200] Iteration[017/030] Train loss: 0.2048
2023-02-06 15:50:53 | Train | Epoch[032/200] Iteration[018/030] Train loss: 0.2045
2023-02-06 15:50:54 | Train | Epoch[032/200] Iteration[019/030] Train loss: 0.2042
2023-02-06 15:50:54 | Train | Epoch[032/200] Iteration[020/030] Train loss: 0.2041
2023-02-06 15:50:55 | Train | Epoch[032/200] Iteration[021/030] Train loss: 0.2039
2023-02-06 15:50:55 | Train | Epoch[032/200] Iteration[022/030] Train loss: 0.2038
2023-02-06 15:50:55 | Train | Epoch[032/200] Iteration[023/030] Train loss: 0.2035
2023-02-06 15:50:56 | Train | Epoch[032/200] Iteration[024/030] Train loss: 0.2034
2023-02-06 15:50:56 | Train | Epoch[032/200] Iteration[025/030] Train loss: 0.2032
2023-02-06 15:50:57 | Train | Epoch[032/200] Iteration[026/030] Train loss: 0.2033
2023-02-06 15:50:57 | Train | Epoch[032/200] Iteration[027/030] Train loss: 0.2031
2023-02-06 15:50:58 | Train | Epoch[032/200] Iteration[028/030] Train loss: 0.2033
2023-02-06 15:50:58 | Train | Epoch[032/200] Iteration[029/030] Train loss: 0.2033
2023-02-06 15:50:58 | Train | Epoch[032/200] Iteration[030/030] Train loss: 0.2031
2023-02-06 15:50:59 | Valid | Epoch[032/200] Iteration[001/008] Valid loss: 0.2167
2023-02-06 15:50:59 | Valid | Epoch[032/200] Iteration[002/008] Valid loss: 0.2149
2023-02-06 15:50:59 | Valid | Epoch[032/200] Iteration[003/008] Valid loss: 0.2155
2023-02-06 15:50:59 | Valid | Epoch[032/200] Iteration[004/008] Valid loss: 0.2151
2023-02-06 15:50:59 | Valid | Epoch[032/200] Iteration[005/008] Valid loss: 0.2149
2023-02-06 15:50:59 | Valid | Epoch[032/200] Iteration[006/008] Valid loss: 0.2152
2023-02-06 15:50:59 | Valid | Epoch[032/200] Iteration[007/008] Valid loss: 0.2147
2023-02-06 15:50:59 | Valid | Epoch[032/200] Iteration[008/008] Valid loss: 0.2149
2023-02-06 15:50:59 | Valid | Epoch[032/200] MIou: 0.8653006932744761
2023-02-06 15:50:59 | Valid | Epoch[032/200] Pixel Accuracy: 0.9773241678873698
2023-02-06 15:50:59 | Valid | Epoch[032/200] Mean Pixel Accuracy: 0.8855816136558061
2023-02-06 15:50:59 | Stage | Epoch[032/200] Train loss:0.2031
2023-02-06 15:50:59 | Stage | Epoch[032/200] Valid loss:0.2149
2023-02-06 15:50:59 | Stage | Epoch[032/200] LR:0.01

2023-02-06 15:51:00 | Train | Epoch[033/200] Iteration[001/030] Train loss: 0.1996
2023-02-06 15:51:01 | Train | Epoch[033/200] Iteration[002/030] Train loss: 0.1991
2023-02-06 15:51:01 | Train | Epoch[033/200] Iteration[003/030] Train loss: 0.1989
2023-02-06 15:51:02 | Train | Epoch[033/200] Iteration[004/030] Train loss: 0.1988
2023-02-06 15:51:02 | Train | Epoch[033/200] Iteration[005/030] Train loss: 0.1999
2023-02-06 15:51:02 | Train | Epoch[033/200] Iteration[006/030] Train loss: 0.1995
2023-02-06 15:51:03 | Train | Epoch[033/200] Iteration[007/030] Train loss: 0.1997
2023-02-06 15:51:03 | Train | Epoch[033/200] Iteration[008/030] Train loss: 0.1993
2023-02-06 15:51:04 | Train | Epoch[033/200] Iteration[009/030] Train loss: 0.1994
2023-02-06 15:51:04 | Train | Epoch[033/200] Iteration[010/030] Train loss: 0.1993
2023-02-06 15:51:05 | Train | Epoch[033/200] Iteration[011/030] Train loss: 0.1991
2023-02-06 15:51:05 | Train | Epoch[033/200] Iteration[012/030] Train loss: 0.1992
2023-02-06 15:51:05 | Train | Epoch[033/200] Iteration[013/030] Train loss: 0.1991
2023-02-06 15:51:06 | Train | Epoch[033/200] Iteration[014/030] Train loss: 0.1991
2023-02-06 15:51:06 | Train | Epoch[033/200] Iteration[015/030] Train loss: 0.1988
2023-02-06 15:51:07 | Train | Epoch[033/200] Iteration[016/030] Train loss: 0.1986
2023-02-06 15:51:07 | Train | Epoch[033/200] Iteration[017/030] Train loss: 0.1985
2023-02-06 15:51:08 | Train | Epoch[033/200] Iteration[018/030] Train loss: 0.1983
2023-02-06 15:51:08 | Train | Epoch[033/200] Iteration[019/030] Train loss: 0.1980
2023-02-06 15:51:09 | Train | Epoch[033/200] Iteration[020/030] Train loss: 0.1978
2023-02-06 15:51:09 | Train | Epoch[033/200] Iteration[021/030] Train loss: 0.1978
2023-02-06 15:51:09 | Train | Epoch[033/200] Iteration[022/030] Train loss: 0.1981
2023-02-06 15:51:10 | Train | Epoch[033/200] Iteration[023/030] Train loss: 0.1978
2023-02-06 15:51:10 | Train | Epoch[033/200] Iteration[024/030] Train loss: 0.1979
2023-02-06 15:51:11 | Train | Epoch[033/200] Iteration[025/030] Train loss: 0.1978
2023-02-06 15:51:11 | Train | Epoch[033/200] Iteration[026/030] Train loss: 0.1978
2023-02-06 15:51:12 | Train | Epoch[033/200] Iteration[027/030] Train loss: 0.1979
2023-02-06 15:51:12 | Train | Epoch[033/200] Iteration[028/030] Train loss: 0.1979
2023-02-06 15:51:12 | Train | Epoch[033/200] Iteration[029/030] Train loss: 0.1978
2023-02-06 15:51:13 | Train | Epoch[033/200] Iteration[030/030] Train loss: 0.1976
2023-02-06 15:51:13 | Valid | Epoch[033/200] Iteration[001/008] Valid loss: 0.2434
2023-02-06 15:51:13 | Valid | Epoch[033/200] Iteration[002/008] Valid loss: 0.2456
2023-02-06 15:51:13 | Valid | Epoch[033/200] Iteration[003/008] Valid loss: 0.2502
2023-02-06 15:51:13 | Valid | Epoch[033/200] Iteration[004/008] Valid loss: 0.2502
2023-02-06 15:51:13 | Valid | Epoch[033/200] Iteration[005/008] Valid loss: 0.2530
2023-02-06 15:51:13 | Valid | Epoch[033/200] Iteration[006/008] Valid loss: 0.2528
2023-02-06 15:51:14 | Valid | Epoch[033/200] Iteration[007/008] Valid loss: 0.2526
2023-02-06 15:51:14 | Valid | Epoch[033/200] Iteration[008/008] Valid loss: 0.2554
2023-02-06 15:51:14 | Valid | Epoch[033/200] MIou: 0.5330034294930833
2023-02-06 15:51:14 | Valid | Epoch[033/200] Pixel Accuracy: 0.922552744547526
2023-02-06 15:51:14 | Valid | Epoch[033/200] Mean Pixel Accuracy: 0.5722924242994998
2023-02-06 15:51:14 | Stage | Epoch[033/200] Train loss:0.1976
2023-02-06 15:51:14 | Stage | Epoch[033/200] Valid loss:0.2554
2023-02-06 15:51:14 | Stage | Epoch[033/200] LR:0.01

2023-02-06 15:51:15 | Train | Epoch[034/200] Iteration[001/030] Train loss: 0.2032
2023-02-06 15:51:15 | Train | Epoch[034/200] Iteration[002/030] Train loss: 0.1980
2023-02-06 15:51:15 | Train | Epoch[034/200] Iteration[003/030] Train loss: 0.1964
2023-02-06 15:51:16 | Train | Epoch[034/200] Iteration[004/030] Train loss: 0.1960
2023-02-06 15:51:16 | Train | Epoch[034/200] Iteration[005/030] Train loss: 0.1949
2023-02-06 15:51:17 | Train | Epoch[034/200] Iteration[006/030] Train loss: 0.1951
2023-02-06 15:51:17 | Train | Epoch[034/200] Iteration[007/030] Train loss: 0.1945
2023-02-06 15:51:18 | Train | Epoch[034/200] Iteration[008/030] Train loss: 0.1942
2023-02-06 15:51:18 | Train | Epoch[034/200] Iteration[009/030] Train loss: 0.1939
2023-02-06 15:51:18 | Train | Epoch[034/200] Iteration[010/030] Train loss: 0.1932
2023-02-06 15:51:19 | Train | Epoch[034/200] Iteration[011/030] Train loss: 0.1931
2023-02-06 15:51:19 | Train | Epoch[034/200] Iteration[012/030] Train loss: 0.1928
2023-02-06 15:51:20 | Train | Epoch[034/200] Iteration[013/030] Train loss: 0.1927
2023-02-06 15:51:20 | Train | Epoch[034/200] Iteration[014/030] Train loss: 0.1926
2023-02-06 15:51:21 | Train | Epoch[034/200] Iteration[015/030] Train loss: 0.1925
2023-02-06 15:51:21 | Train | Epoch[034/200] Iteration[016/030] Train loss: 0.1923
2023-02-06 15:51:21 | Train | Epoch[034/200] Iteration[017/030] Train loss: 0.1923
2023-02-06 15:51:22 | Train | Epoch[034/200] Iteration[018/030] Train loss: 0.1922
2023-02-06 15:51:22 | Train | Epoch[034/200] Iteration[019/030] Train loss: 0.1921
2023-02-06 15:51:23 | Train | Epoch[034/200] Iteration[020/030] Train loss: 0.1921
2023-02-06 15:51:23 | Train | Epoch[034/200] Iteration[021/030] Train loss: 0.1919
2023-02-06 15:51:24 | Train | Epoch[034/200] Iteration[022/030] Train loss: 0.1918
2023-02-06 15:51:24 | Train | Epoch[034/200] Iteration[023/030] Train loss: 0.1916
2023-02-06 15:51:24 | Train | Epoch[034/200] Iteration[024/030] Train loss: 0.1916
2023-02-06 15:51:25 | Train | Epoch[034/200] Iteration[025/030] Train loss: 0.1914
2023-02-06 15:51:25 | Train | Epoch[034/200] Iteration[026/030] Train loss: 0.1913
2023-02-06 15:51:26 | Train | Epoch[034/200] Iteration[027/030] Train loss: 0.1911
2023-02-06 15:51:26 | Train | Epoch[034/200] Iteration[028/030] Train loss: 0.1910
2023-02-06 15:51:27 | Train | Epoch[034/200] Iteration[029/030] Train loss: 0.1909
2023-02-06 15:51:27 | Train | Epoch[034/200] Iteration[030/030] Train loss: 0.1909
2023-02-06 15:51:27 | Valid | Epoch[034/200] Iteration[001/008] Valid loss: 0.4031
2023-02-06 15:51:27 | Valid | Epoch[034/200] Iteration[002/008] Valid loss: 0.3824
2023-02-06 15:51:27 | Valid | Epoch[034/200] Iteration[003/008] Valid loss: 0.3729
2023-02-06 15:51:28 | Valid | Epoch[034/200] Iteration[004/008] Valid loss: 0.3723
2023-02-06 15:51:28 | Valid | Epoch[034/200] Iteration[005/008] Valid loss: 0.3747
2023-02-06 15:51:28 | Valid | Epoch[034/200] Iteration[006/008] Valid loss: 0.3782
2023-02-06 15:51:28 | Valid | Epoch[034/200] Iteration[007/008] Valid loss: 0.3851
2023-02-06 15:51:28 | Valid | Epoch[034/200] Iteration[008/008] Valid loss: 0.3905
2023-02-06 15:51:28 | Valid | Epoch[034/200] MIou: 0.8357926050648858
2023-02-06 15:51:28 | Valid | Epoch[034/200] Pixel Accuracy: 0.963568369547526
2023-02-06 15:51:28 | Valid | Epoch[034/200] Mean Pixel Accuracy: 0.9778832665328749
2023-02-06 15:51:28 | Stage | Epoch[034/200] Train loss:0.1909
2023-02-06 15:51:28 | Stage | Epoch[034/200] Valid loss:0.3905
2023-02-06 15:51:28 | Stage | Epoch[034/200] LR:0.01

2023-02-06 15:51:29 | Train | Epoch[035/200] Iteration[001/030] Train loss: 0.1886
2023-02-06 15:51:29 | Train | Epoch[035/200] Iteration[002/030] Train loss: 0.1882
2023-02-06 15:51:30 | Train | Epoch[035/200] Iteration[003/030] Train loss: 0.1879
2023-02-06 15:51:30 | Train | Epoch[035/200] Iteration[004/030] Train loss: 0.1873
2023-02-06 15:51:30 | Train | Epoch[035/200] Iteration[005/030] Train loss: 0.1867
2023-02-06 15:51:31 | Train | Epoch[035/200] Iteration[006/030] Train loss: 0.1860
2023-02-06 15:51:31 | Train | Epoch[035/200] Iteration[007/030] Train loss: 0.1859
2023-02-06 15:51:32 | Train | Epoch[035/200] Iteration[008/030] Train loss: 0.1858
2023-02-06 15:51:32 | Train | Epoch[035/200] Iteration[009/030] Train loss: 0.1858
2023-02-06 15:51:33 | Train | Epoch[035/200] Iteration[010/030] Train loss: 0.1858
2023-02-06 15:51:33 | Train | Epoch[035/200] Iteration[011/030] Train loss: 0.1856
2023-02-06 15:51:34 | Train | Epoch[035/200] Iteration[012/030] Train loss: 0.1855
2023-02-06 15:51:34 | Train | Epoch[035/200] Iteration[013/030] Train loss: 0.1852
2023-02-06 15:51:34 | Train | Epoch[035/200] Iteration[014/030] Train loss: 0.1850
2023-02-06 15:51:35 | Train | Epoch[035/200] Iteration[015/030] Train loss: 0.1854
2023-02-06 15:51:35 | Train | Epoch[035/200] Iteration[016/030] Train loss: 0.1855
2023-02-06 15:51:36 | Train | Epoch[035/200] Iteration[017/030] Train loss: 0.1854
2023-02-06 15:51:36 | Train | Epoch[035/200] Iteration[018/030] Train loss: 0.1855
2023-02-06 15:51:37 | Train | Epoch[035/200] Iteration[019/030] Train loss: 0.1853
2023-02-06 15:51:37 | Train | Epoch[035/200] Iteration[020/030] Train loss: 0.1851
2023-02-06 15:51:37 | Train | Epoch[035/200] Iteration[021/030] Train loss: 0.1851
2023-02-06 15:51:38 | Train | Epoch[035/200] Iteration[022/030] Train loss: 0.1850
2023-02-06 15:51:38 | Train | Epoch[035/200] Iteration[023/030] Train loss: 0.1850
2023-02-06 15:51:39 | Train | Epoch[035/200] Iteration[024/030] Train loss: 0.1850
2023-02-06 15:51:39 | Train | Epoch[035/200] Iteration[025/030] Train loss: 0.1849
2023-02-06 15:51:40 | Train | Epoch[035/200] Iteration[026/030] Train loss: 0.1849
2023-02-06 15:51:40 | Train | Epoch[035/200] Iteration[027/030] Train loss: 0.1848
2023-02-06 15:51:40 | Train | Epoch[035/200] Iteration[028/030] Train loss: 0.1846
2023-02-06 15:51:41 | Train | Epoch[035/200] Iteration[029/030] Train loss: 0.1844
2023-02-06 15:51:41 | Train | Epoch[035/200] Iteration[030/030] Train loss: 0.1845
2023-02-06 15:51:42 | Valid | Epoch[035/200] Iteration[001/008] Valid loss: 0.2042
2023-02-06 15:51:42 | Valid | Epoch[035/200] Iteration[002/008] Valid loss: 0.2008
2023-02-06 15:51:42 | Valid | Epoch[035/200] Iteration[003/008] Valid loss: 0.1990
2023-02-06 15:51:42 | Valid | Epoch[035/200] Iteration[004/008] Valid loss: 0.1983
2023-02-06 15:51:42 | Valid | Epoch[035/200] Iteration[005/008] Valid loss: 0.1990
2023-02-06 15:51:42 | Valid | Epoch[035/200] Iteration[006/008] Valid loss: 0.1999
2023-02-06 15:51:42 | Valid | Epoch[035/200] Iteration[007/008] Valid loss: 0.2015
2023-02-06 15:51:42 | Valid | Epoch[035/200] Iteration[008/008] Valid loss: 0.2004
2023-02-06 15:51:42 | Valid | Epoch[035/200] MIou: 0.9385462764389729
2023-02-06 15:51:42 | Valid | Epoch[035/200] Pixel Accuracy: 0.9892692565917969
2023-02-06 15:51:42 | Valid | Epoch[035/200] Mean Pixel Accuracy: 0.9715488685992463
2023-02-06 15:51:42 | Stage | Epoch[035/200] Train loss:0.1845
2023-02-06 15:51:42 | Stage | Epoch[035/200] Valid loss:0.2004
2023-02-06 15:51:42 | Stage | Epoch[035/200] LR:0.01

2023-02-06 15:51:43 | Train | Epoch[036/200] Iteration[001/030] Train loss: 0.1819
2023-02-06 15:51:44 | Train | Epoch[036/200] Iteration[002/030] Train loss: 0.1815
2023-02-06 15:51:44 | Train | Epoch[036/200] Iteration[003/030] Train loss: 0.1800
2023-02-06 15:51:44 | Train | Epoch[036/200] Iteration[004/030] Train loss: 0.1796
2023-02-06 15:51:45 | Train | Epoch[036/200] Iteration[005/030] Train loss: 0.1802
2023-02-06 15:51:45 | Train | Epoch[036/200] Iteration[006/030] Train loss: 0.1803
2023-02-06 15:51:46 | Train | Epoch[036/200] Iteration[007/030] Train loss: 0.1800
2023-02-06 15:51:46 | Train | Epoch[036/200] Iteration[008/030] Train loss: 0.1799
2023-02-06 15:51:47 | Train | Epoch[036/200] Iteration[009/030] Train loss: 0.1796
2023-02-06 15:51:47 | Train | Epoch[036/200] Iteration[010/030] Train loss: 0.1799
2023-02-06 15:51:48 | Train | Epoch[036/200] Iteration[011/030] Train loss: 0.1797
2023-02-06 15:51:48 | Train | Epoch[036/200] Iteration[012/030] Train loss: 0.1795
2023-02-06 15:51:48 | Train | Epoch[036/200] Iteration[013/030] Train loss: 0.1793
2023-02-06 15:51:49 | Train | Epoch[036/200] Iteration[014/030] Train loss: 0.1793
2023-02-06 15:51:49 | Train | Epoch[036/200] Iteration[015/030] Train loss: 0.1790
2023-02-06 15:51:50 | Train | Epoch[036/200] Iteration[016/030] Train loss: 0.1789
2023-02-06 15:51:50 | Train | Epoch[036/200] Iteration[017/030] Train loss: 0.1793
2023-02-06 15:51:51 | Train | Epoch[036/200] Iteration[018/030] Train loss: 0.1792
2023-02-06 15:51:51 | Train | Epoch[036/200] Iteration[019/030] Train loss: 0.1790
2023-02-06 15:51:51 | Train | Epoch[036/200] Iteration[020/030] Train loss: 0.1790
2023-02-06 15:51:52 | Train | Epoch[036/200] Iteration[021/030] Train loss: 0.1790
2023-02-06 15:51:52 | Train | Epoch[036/200] Iteration[022/030] Train loss: 0.1791
2023-02-06 15:51:53 | Train | Epoch[036/200] Iteration[023/030] Train loss: 0.1791
2023-02-06 15:51:53 | Train | Epoch[036/200] Iteration[024/030] Train loss: 0.1790
2023-02-06 15:51:54 | Train | Epoch[036/200] Iteration[025/030] Train loss: 0.1790
2023-02-06 15:51:54 | Train | Epoch[036/200] Iteration[026/030] Train loss: 0.1789
2023-02-06 15:51:54 | Train | Epoch[036/200] Iteration[027/030] Train loss: 0.1788
2023-02-06 15:51:55 | Train | Epoch[036/200] Iteration[028/030] Train loss: 0.1787
2023-02-06 15:51:55 | Train | Epoch[036/200] Iteration[029/030] Train loss: 0.1786
2023-02-06 15:51:56 | Train | Epoch[036/200] Iteration[030/030] Train loss: 0.1785
2023-02-06 15:51:56 | Valid | Epoch[036/200] Iteration[001/008] Valid loss: 0.1930
2023-02-06 15:51:56 | Valid | Epoch[036/200] Iteration[002/008] Valid loss: 0.1921
2023-02-06 15:51:56 | Valid | Epoch[036/200] Iteration[003/008] Valid loss: 0.1922
2023-02-06 15:51:56 | Valid | Epoch[036/200] Iteration[004/008] Valid loss: 0.1917
2023-02-06 15:51:56 | Valid | Epoch[036/200] Iteration[005/008] Valid loss: 0.1922
2023-02-06 15:51:56 | Valid | Epoch[036/200] Iteration[006/008] Valid loss: 0.1921
2023-02-06 15:51:57 | Valid | Epoch[036/200] Iteration[007/008] Valid loss: 0.1915
2023-02-06 15:51:57 | Valid | Epoch[036/200] Iteration[008/008] Valid loss: 0.1918
2023-02-06 15:51:57 | Valid | Epoch[036/200] MIou: 0.8591587173706206
2023-02-06 15:51:57 | Valid | Epoch[036/200] Pixel Accuracy: 0.9767786661783854
2023-02-06 15:51:57 | Valid | Epoch[036/200] Mean Pixel Accuracy: 0.8720048353051679
2023-02-06 15:51:57 | Stage | Epoch[036/200] Train loss:0.1785
2023-02-06 15:51:57 | Stage | Epoch[036/200] Valid loss:0.1918
2023-02-06 15:51:57 | Stage | Epoch[036/200] LR:0.01

2023-02-06 15:51:57 | Train | Epoch[037/200] Iteration[001/030] Train loss: 0.1753
2023-02-06 15:51:58 | Train | Epoch[037/200] Iteration[002/030] Train loss: 0.1739
2023-02-06 15:51:58 | Train | Epoch[037/200] Iteration[003/030] Train loss: 0.1749
2023-02-06 15:51:59 | Train | Epoch[037/200] Iteration[004/030] Train loss: 0.1745
2023-02-06 15:51:59 | Train | Epoch[037/200] Iteration[005/030] Train loss: 0.1748
2023-02-06 15:52:00 | Train | Epoch[037/200] Iteration[006/030] Train loss: 0.1748
2023-02-06 15:52:00 | Train | Epoch[037/200] Iteration[007/030] Train loss: 0.1748
2023-02-06 15:52:01 | Train | Epoch[037/200] Iteration[008/030] Train loss: 0.1747
2023-02-06 15:52:01 | Train | Epoch[037/200] Iteration[009/030] Train loss: 0.1747
2023-02-06 15:52:01 | Train | Epoch[037/200] Iteration[010/030] Train loss: 0.1744
2023-02-06 15:52:02 | Train | Epoch[037/200] Iteration[011/030] Train loss: 0.1742
2023-02-06 15:52:02 | Train | Epoch[037/200] Iteration[012/030] Train loss: 0.1740
2023-02-06 15:52:03 | Train | Epoch[037/200] Iteration[013/030] Train loss: 0.1737
2023-02-06 15:52:03 | Train | Epoch[037/200] Iteration[014/030] Train loss: 0.1735
2023-02-06 15:52:04 | Train | Epoch[037/200] Iteration[015/030] Train loss: 0.1734
2023-02-06 15:52:04 | Train | Epoch[037/200] Iteration[016/030] Train loss: 0.1742
2023-02-06 15:52:04 | Train | Epoch[037/200] Iteration[017/030] Train loss: 0.1741
2023-02-06 15:52:05 | Train | Epoch[037/200] Iteration[018/030] Train loss: 0.1741
2023-02-06 15:52:05 | Train | Epoch[037/200] Iteration[019/030] Train loss: 0.1740
2023-02-06 15:52:06 | Train | Epoch[037/200] Iteration[020/030] Train loss: 0.1739
2023-02-06 15:52:06 | Train | Epoch[037/200] Iteration[021/030] Train loss: 0.1739
2023-02-06 15:52:07 | Train | Epoch[037/200] Iteration[022/030] Train loss: 0.1739
2023-02-06 15:52:07 | Train | Epoch[037/200] Iteration[023/030] Train loss: 0.1738
2023-02-06 15:52:07 | Train | Epoch[037/200] Iteration[024/030] Train loss: 0.1738
2023-02-06 15:52:08 | Train | Epoch[037/200] Iteration[025/030] Train loss: 0.1737
2023-02-06 15:52:08 | Train | Epoch[037/200] Iteration[026/030] Train loss: 0.1736
2023-02-06 15:52:09 | Train | Epoch[037/200] Iteration[027/030] Train loss: 0.1734
2023-02-06 15:52:09 | Train | Epoch[037/200] Iteration[028/030] Train loss: 0.1733
2023-02-06 15:52:10 | Train | Epoch[037/200] Iteration[029/030] Train loss: 0.1732
2023-02-06 15:52:10 | Train | Epoch[037/200] Iteration[030/030] Train loss: 0.1732
2023-02-06 15:52:10 | Valid | Epoch[037/200] Iteration[001/008] Valid loss: 0.5041
2023-02-06 15:52:10 | Valid | Epoch[037/200] Iteration[002/008] Valid loss: 0.4754
2023-02-06 15:52:11 | Valid | Epoch[037/200] Iteration[003/008] Valid loss: 0.4586
2023-02-06 15:52:11 | Valid | Epoch[037/200] Iteration[004/008] Valid loss: 0.4692
2023-02-06 15:52:11 | Valid | Epoch[037/200] Iteration[005/008] Valid loss: 0.4764
2023-02-06 15:52:11 | Valid | Epoch[037/200] Iteration[006/008] Valid loss: 0.4762
2023-02-06 15:52:11 | Valid | Epoch[037/200] Iteration[007/008] Valid loss: 0.4959
2023-02-06 15:52:11 | Valid | Epoch[037/200] Iteration[008/008] Valid loss: 0.5044
2023-02-06 15:52:11 | Valid | Epoch[037/200] MIou: 0.8324212327746144
2023-02-06 15:52:11 | Valid | Epoch[037/200] Pixel Accuracy: 0.9624989827473959
2023-02-06 15:52:11 | Valid | Epoch[037/200] Mean Pixel Accuracy: 0.9781894924224828
2023-02-06 15:52:11 | Stage | Epoch[037/200] Train loss:0.1732
2023-02-06 15:52:11 | Stage | Epoch[037/200] Valid loss:0.5044
2023-02-06 15:52:11 | Stage | Epoch[037/200] LR:0.01

2023-02-06 15:52:12 | Train | Epoch[038/200] Iteration[001/030] Train loss: 0.1720
2023-02-06 15:52:12 | Train | Epoch[038/200] Iteration[002/030] Train loss: 0.1697
2023-02-06 15:52:13 | Train | Epoch[038/200] Iteration[003/030] Train loss: 0.1706
2023-02-06 15:52:13 | Train | Epoch[038/200] Iteration[004/030] Train loss: 0.1700
2023-02-06 15:52:14 | Train | Epoch[038/200] Iteration[005/030] Train loss: 0.1702
2023-02-06 15:52:14 | Train | Epoch[038/200] Iteration[006/030] Train loss: 0.1704
2023-02-06 15:52:15 | Train | Epoch[038/200] Iteration[007/030] Train loss: 0.1700
2023-02-06 15:52:15 | Train | Epoch[038/200] Iteration[008/030] Train loss: 0.1708
2023-02-06 15:52:15 | Train | Epoch[038/200] Iteration[009/030] Train loss: 0.1706
2023-02-06 15:52:16 | Train | Epoch[038/200] Iteration[010/030] Train loss: 0.1705
2023-02-06 15:52:16 | Train | Epoch[038/200] Iteration[011/030] Train loss: 0.1703
2023-02-06 15:52:17 | Train | Epoch[038/200] Iteration[012/030] Train loss: 0.1701
2023-02-06 15:52:17 | Train | Epoch[038/200] Iteration[013/030] Train loss: 0.1699
2023-02-06 15:52:18 | Train | Epoch[038/200] Iteration[014/030] Train loss: 0.1700
2023-02-06 15:52:18 | Train | Epoch[038/200] Iteration[015/030] Train loss: 0.1698
2023-02-06 15:52:18 | Train | Epoch[038/200] Iteration[016/030] Train loss: 0.1696
2023-02-06 15:52:19 | Train | Epoch[038/200] Iteration[017/030] Train loss: 0.1695
2023-02-06 15:52:19 | Train | Epoch[038/200] Iteration[018/030] Train loss: 0.1694
2023-02-06 15:52:20 | Train | Epoch[038/200] Iteration[019/030] Train loss: 0.1694
2023-02-06 15:52:20 | Train | Epoch[038/200] Iteration[020/030] Train loss: 0.1692
2023-02-06 15:52:21 | Train | Epoch[038/200] Iteration[021/030] Train loss: 0.1692
2023-02-06 15:52:21 | Train | Epoch[038/200] Iteration[022/030] Train loss: 0.1691
2023-02-06 15:52:21 | Train | Epoch[038/200] Iteration[023/030] Train loss: 0.1689
2023-02-06 15:52:22 | Train | Epoch[038/200] Iteration[024/030] Train loss: 0.1688
2023-02-06 15:52:22 | Train | Epoch[038/200] Iteration[025/030] Train loss: 0.1688
2023-02-06 15:52:23 | Train | Epoch[038/200] Iteration[026/030] Train loss: 0.1686
2023-02-06 15:52:23 | Train | Epoch[038/200] Iteration[027/030] Train loss: 0.1685
2023-02-06 15:52:24 | Train | Epoch[038/200] Iteration[028/030] Train loss: 0.1684
2023-02-06 15:52:24 | Train | Epoch[038/200] Iteration[029/030] Train loss: 0.1683
2023-02-06 15:52:24 | Train | Epoch[038/200] Iteration[030/030] Train loss: 0.1683
2023-02-06 15:52:25 | Valid | Epoch[038/200] Iteration[001/008] Valid loss: 0.1987
2023-02-06 15:52:25 | Valid | Epoch[038/200] Iteration[002/008] Valid loss: 0.1960
2023-02-06 15:52:25 | Valid | Epoch[038/200] Iteration[003/008] Valid loss: 0.1967
2023-02-06 15:52:25 | Valid | Epoch[038/200] Iteration[004/008] Valid loss: 0.1963
2023-02-06 15:52:25 | Valid | Epoch[038/200] Iteration[005/008] Valid loss: 0.1972
2023-02-06 15:52:25 | Valid | Epoch[038/200] Iteration[006/008] Valid loss: 0.1968
2023-02-06 15:52:25 | Valid | Epoch[038/200] Iteration[007/008] Valid loss: 0.1977
2023-02-06 15:52:25 | Valid | Epoch[038/200] Iteration[008/008] Valid loss: 0.1984
2023-02-06 15:52:26 | Valid | Epoch[038/200] MIou: 0.8656360200917501
2023-02-06 15:52:26 | Valid | Epoch[038/200] Pixel Accuracy: 0.9765777587890625
2023-02-06 15:52:26 | Valid | Epoch[038/200] Mean Pixel Accuracy: 0.8996783542014368
2023-02-06 15:52:26 | Stage | Epoch[038/200] Train loss:0.1683
2023-02-06 15:52:26 | Stage | Epoch[038/200] Valid loss:0.1984
2023-02-06 15:52:26 | Stage | Epoch[038/200] LR:0.01

2023-02-06 15:52:26 | Train | Epoch[039/200] Iteration[001/030] Train loss: 0.1633
2023-02-06 15:52:27 | Train | Epoch[039/200] Iteration[002/030] Train loss: 0.1630
2023-02-06 15:52:27 | Train | Epoch[039/200] Iteration[003/030] Train loss: 0.1630
2023-02-06 15:52:28 | Train | Epoch[039/200] Iteration[004/030] Train loss: 0.1630
2023-02-06 15:52:28 | Train | Epoch[039/200] Iteration[005/030] Train loss: 0.1628
2023-02-06 15:52:28 | Train | Epoch[039/200] Iteration[006/030] Train loss: 0.1626
2023-02-06 15:52:29 | Train | Epoch[039/200] Iteration[007/030] Train loss: 0.1628
2023-02-06 15:52:29 | Train | Epoch[039/200] Iteration[008/030] Train loss: 0.1631
2023-02-06 15:52:30 | Train | Epoch[039/200] Iteration[009/030] Train loss: 0.1629
2023-02-06 15:52:30 | Train | Epoch[039/200] Iteration[010/030] Train loss: 0.1629
2023-02-06 15:52:31 | Train | Epoch[039/200] Iteration[011/030] Train loss: 0.1641
2023-02-06 15:52:31 | Train | Epoch[039/200] Iteration[012/030] Train loss: 0.1639
2023-02-06 15:52:31 | Train | Epoch[039/200] Iteration[013/030] Train loss: 0.1639
2023-02-06 15:52:32 | Train | Epoch[039/200] Iteration[014/030] Train loss: 0.1637
2023-02-06 15:52:32 | Train | Epoch[039/200] Iteration[015/030] Train loss: 0.1637
2023-02-06 15:52:33 | Train | Epoch[039/200] Iteration[016/030] Train loss: 0.1637
2023-02-06 15:52:33 | Train | Epoch[039/200] Iteration[017/030] Train loss: 0.1638
2023-02-06 15:52:34 | Train | Epoch[039/200] Iteration[018/030] Train loss: 0.1639
2023-02-06 15:52:34 | Train | Epoch[039/200] Iteration[019/030] Train loss: 0.1639
2023-02-06 15:52:35 | Train | Epoch[039/200] Iteration[020/030] Train loss: 0.1639
2023-02-06 15:52:35 | Train | Epoch[039/200] Iteration[021/030] Train loss: 0.1639
2023-02-06 15:52:35 | Train | Epoch[039/200] Iteration[022/030] Train loss: 0.1639
2023-02-06 15:52:36 | Train | Epoch[039/200] Iteration[023/030] Train loss: 0.1638
2023-02-06 15:52:36 | Train | Epoch[039/200] Iteration[024/030] Train loss: 0.1636
2023-02-06 15:52:37 | Train | Epoch[039/200] Iteration[025/030] Train loss: 0.1636
2023-02-06 15:52:37 | Train | Epoch[039/200] Iteration[026/030] Train loss: 0.1635
2023-02-06 15:52:38 | Train | Epoch[039/200] Iteration[027/030] Train loss: 0.1635
2023-02-06 15:52:38 | Train | Epoch[039/200] Iteration[028/030] Train loss: 0.1633
2023-02-06 15:52:38 | Train | Epoch[039/200] Iteration[029/030] Train loss: 0.1632
2023-02-06 15:52:39 | Train | Epoch[039/200] Iteration[030/030] Train loss: 0.1634
2023-02-06 15:52:39 | Valid | Epoch[039/200] Iteration[001/008] Valid loss: 0.9255
2023-02-06 15:52:39 | Valid | Epoch[039/200] Iteration[002/008] Valid loss: 0.9046
2023-02-06 15:52:39 | Valid | Epoch[039/200] Iteration[003/008] Valid loss: 0.9081
2023-02-06 15:52:39 | Valid | Epoch[039/200] Iteration[004/008] Valid loss: 0.9251
2023-02-06 15:52:39 | Valid | Epoch[039/200] Iteration[005/008] Valid loss: 0.9484
2023-02-06 15:52:40 | Valid | Epoch[039/200] Iteration[006/008] Valid loss: 0.9499
2023-02-06 15:52:40 | Valid | Epoch[039/200] Iteration[007/008] Valid loss: 0.9895
2023-02-06 15:52:40 | Valid | Epoch[039/200] Iteration[008/008] Valid loss: 1.0095
2023-02-06 15:52:40 | Valid | Epoch[039/200] MIou: 0.726742666554306
2023-02-06 15:52:40 | Valid | Epoch[039/200] Pixel Accuracy: 0.9227383931477865
2023-02-06 15:52:40 | Valid | Epoch[039/200] Mean Pixel Accuracy: 0.956525590775767
2023-02-06 15:52:40 | Stage | Epoch[039/200] Train loss:0.1634
2023-02-06 15:52:40 | Stage | Epoch[039/200] Valid loss:1.0095
2023-02-06 15:52:40 | Stage | Epoch[039/200] LR:0.01

2023-02-06 15:52:41 | Train | Epoch[040/200] Iteration[001/030] Train loss: 0.1583
2023-02-06 15:52:41 | Train | Epoch[040/200] Iteration[002/030] Train loss: 0.1616
2023-02-06 15:52:41 | Train | Epoch[040/200] Iteration[003/030] Train loss: 0.1605
2023-02-06 15:52:42 | Train | Epoch[040/200] Iteration[004/030] Train loss: 0.1607
2023-02-06 15:52:42 | Train | Epoch[040/200] Iteration[005/030] Train loss: 0.1603
2023-02-06 15:52:43 | Train | Epoch[040/200] Iteration[006/030] Train loss: 0.1600
2023-02-06 15:52:43 | Train | Epoch[040/200] Iteration[007/030] Train loss: 0.1603
2023-02-06 15:52:44 | Train | Epoch[040/200] Iteration[008/030] Train loss: 0.1599
2023-02-06 15:52:44 | Train | Epoch[040/200] Iteration[009/030] Train loss: 0.1598
2023-02-06 15:52:44 | Train | Epoch[040/200] Iteration[010/030] Train loss: 0.1597
2023-02-06 15:52:45 | Train | Epoch[040/200] Iteration[011/030] Train loss: 0.1600
2023-02-06 15:52:45 | Train | Epoch[040/200] Iteration[012/030] Train loss: 0.1597
2023-02-06 15:52:46 | Train | Epoch[040/200] Iteration[013/030] Train loss: 0.1595
2023-02-06 15:52:46 | Train | Epoch[040/200] Iteration[014/030] Train loss: 0.1593
2023-02-06 15:52:47 | Train | Epoch[040/200] Iteration[015/030] Train loss: 0.1590
2023-02-06 15:52:47 | Train | Epoch[040/200] Iteration[016/030] Train loss: 0.1590
2023-02-06 15:52:47 | Train | Epoch[040/200] Iteration[017/030] Train loss: 0.1591
2023-02-06 15:52:48 | Train | Epoch[040/200] Iteration[018/030] Train loss: 0.1588
2023-02-06 15:52:48 | Train | Epoch[040/200] Iteration[019/030] Train loss: 0.1588
2023-02-06 15:52:49 | Train | Epoch[040/200] Iteration[020/030] Train loss: 0.1587
2023-02-06 15:52:49 | Train | Epoch[040/200] Iteration[021/030] Train loss: 0.1587
2023-02-06 15:52:50 | Train | Epoch[040/200] Iteration[022/030] Train loss: 0.1585
2023-02-06 15:52:50 | Train | Epoch[040/200] Iteration[023/030] Train loss: 0.1586
2023-02-06 15:52:50 | Train | Epoch[040/200] Iteration[024/030] Train loss: 0.1585
2023-02-06 15:52:51 | Train | Epoch[040/200] Iteration[025/030] Train loss: 0.1585
2023-02-06 15:52:51 | Train | Epoch[040/200] Iteration[026/030] Train loss: 0.1584
2023-02-06 15:52:52 | Train | Epoch[040/200] Iteration[027/030] Train loss: 0.1582
2023-02-06 15:52:52 | Train | Epoch[040/200] Iteration[028/030] Train loss: 0.1582
2023-02-06 15:52:53 | Train | Epoch[040/200] Iteration[029/030] Train loss: 0.1581
2023-02-06 15:52:53 | Train | Epoch[040/200] Iteration[030/030] Train loss: 0.1581
2023-02-06 15:52:53 | Valid | Epoch[040/200] Iteration[001/008] Valid loss: 0.2972
2023-02-06 15:52:53 | Valid | Epoch[040/200] Iteration[002/008] Valid loss: 0.2831
2023-02-06 15:52:53 | Valid | Epoch[040/200] Iteration[003/008] Valid loss: 0.2840
2023-02-06 15:52:54 | Valid | Epoch[040/200] Iteration[004/008] Valid loss: 0.2843
2023-02-06 15:52:54 | Valid | Epoch[040/200] Iteration[005/008] Valid loss: 0.2897
2023-02-06 15:52:54 | Valid | Epoch[040/200] Iteration[006/008] Valid loss: 0.2866
2023-02-06 15:52:54 | Valid | Epoch[040/200] Iteration[007/008] Valid loss: 0.2921
2023-02-06 15:52:54 | Valid | Epoch[040/200] Iteration[008/008] Valid loss: 0.2936
2023-02-06 15:52:54 | Valid | Epoch[040/200] MIou: 0.8586546046626822
2023-02-06 15:52:54 | Valid | Epoch[040/200] Pixel Accuracy: 0.9703712463378906
2023-02-06 15:52:54 | Valid | Epoch[040/200] Mean Pixel Accuracy: 0.9761632717806366
2023-02-06 15:52:54 | Stage | Epoch[040/200] Train loss:0.1581
2023-02-06 15:52:54 | Stage | Epoch[040/200] Valid loss:0.2936
2023-02-06 15:52:54 | Stage | Epoch[040/200] LR:0.01

2023-02-06 15:52:55 | Train | Epoch[041/200] Iteration[001/030] Train loss: 0.1562
2023-02-06 15:52:55 | Train | Epoch[041/200] Iteration[002/030] Train loss: 0.1569
2023-02-06 15:52:56 | Train | Epoch[041/200] Iteration[003/030] Train loss: 0.1556
2023-02-06 15:52:56 | Train | Epoch[041/200] Iteration[004/030] Train loss: 0.1553
2023-02-06 15:52:56 | Train | Epoch[041/200] Iteration[005/030] Train loss: 0.1548
2023-02-06 15:52:57 | Train | Epoch[041/200] Iteration[006/030] Train loss: 0.1547
2023-02-06 15:52:57 | Train | Epoch[041/200] Iteration[007/030] Train loss: 0.1549
2023-02-06 15:52:58 | Train | Epoch[041/200] Iteration[008/030] Train loss: 0.1546
2023-02-06 15:52:58 | Train | Epoch[041/200] Iteration[009/030] Train loss: 0.1544
2023-02-06 15:52:59 | Train | Epoch[041/200] Iteration[010/030] Train loss: 0.1544
2023-02-06 15:52:59 | Train | Epoch[041/200] Iteration[011/030] Train loss: 0.1542
2023-02-06 15:52:59 | Train | Epoch[041/200] Iteration[012/030] Train loss: 0.1544
2023-02-06 15:53:00 | Train | Epoch[041/200] Iteration[013/030] Train loss: 0.1543
2023-02-06 15:53:00 | Train | Epoch[041/200] Iteration[014/030] Train loss: 0.1541
2023-02-06 15:53:01 | Train | Epoch[041/200] Iteration[015/030] Train loss: 0.1541
2023-02-06 15:53:01 | Train | Epoch[041/200] Iteration[016/030] Train loss: 0.1541
2023-02-06 15:53:02 | Train | Epoch[041/200] Iteration[017/030] Train loss: 0.1539
2023-02-06 15:53:02 | Train | Epoch[041/200] Iteration[018/030] Train loss: 0.1537
2023-02-06 15:53:03 | Train | Epoch[041/200] Iteration[019/030] Train loss: 0.1536
2023-02-06 15:53:03 | Train | Epoch[041/200] Iteration[020/030] Train loss: 0.1534
2023-02-06 15:53:03 | Train | Epoch[041/200] Iteration[021/030] Train loss: 0.1533
2023-02-06 15:53:04 | Train | Epoch[041/200] Iteration[022/030] Train loss: 0.1532
2023-02-06 15:53:04 | Train | Epoch[041/200] Iteration[023/030] Train loss: 0.1531
2023-02-06 15:53:05 | Train | Epoch[041/200] Iteration[024/030] Train loss: 0.1530
2023-02-06 15:53:05 | Train | Epoch[041/200] Iteration[025/030] Train loss: 0.1528
2023-02-06 15:53:06 | Train | Epoch[041/200] Iteration[026/030] Train loss: 0.1530
2023-02-06 15:53:06 | Train | Epoch[041/200] Iteration[027/030] Train loss: 0.1529
2023-02-06 15:53:06 | Train | Epoch[041/200] Iteration[028/030] Train loss: 0.1531
2023-02-06 15:53:07 | Train | Epoch[041/200] Iteration[029/030] Train loss: 0.1530
2023-02-06 15:53:07 | Train | Epoch[041/200] Iteration[030/030] Train loss: 0.1530
2023-02-06 15:53:07 | Valid | Epoch[041/200] Iteration[001/008] Valid loss: 0.7350
2023-02-06 15:53:08 | Valid | Epoch[041/200] Iteration[002/008] Valid loss: 0.6719
2023-02-06 15:53:08 | Valid | Epoch[041/200] Iteration[003/008] Valid loss: 0.6589
2023-02-06 15:53:08 | Valid | Epoch[041/200] Iteration[004/008] Valid loss: 0.6705
2023-02-06 15:53:08 | Valid | Epoch[041/200] Iteration[005/008] Valid loss: 0.6927
2023-02-06 15:53:08 | Valid | Epoch[041/200] Iteration[006/008] Valid loss: 0.6789
2023-02-06 15:53:08 | Valid | Epoch[041/200] Iteration[007/008] Valid loss: 0.7094
2023-02-06 15:53:08 | Valid | Epoch[041/200] Iteration[008/008] Valid loss: 0.7271
2023-02-06 15:53:08 | Valid | Epoch[041/200] MIou: 0.8118046414968124
2023-02-06 15:53:08 | Valid | Epoch[041/200] Pixel Accuracy: 0.9560038248697916
2023-02-06 15:53:08 | Valid | Epoch[041/200] Mean Pixel Accuracy: 0.9748477336156027
2023-02-06 15:53:08 | Stage | Epoch[041/200] Train loss:0.1530
2023-02-06 15:53:08 | Stage | Epoch[041/200] Valid loss:0.7271
2023-02-06 15:53:08 | Stage | Epoch[041/200] LR:0.01

2023-02-06 15:53:09 | Train | Epoch[042/200] Iteration[001/030] Train loss: 0.1533
2023-02-06 15:53:09 | Train | Epoch[042/200] Iteration[002/030] Train loss: 0.1520
2023-02-06 15:53:10 | Train | Epoch[042/200] Iteration[003/030] Train loss: 0.1527
2023-02-06 15:53:10 | Train | Epoch[042/200] Iteration[004/030] Train loss: 0.1521
2023-02-06 15:53:11 | Train | Epoch[042/200] Iteration[005/030] Train loss: 0.1515
2023-02-06 15:53:11 | Train | Epoch[042/200] Iteration[006/030] Train loss: 0.1514
2023-02-06 15:53:11 | Train | Epoch[042/200] Iteration[007/030] Train loss: 0.1511
2023-02-06 15:53:12 | Train | Epoch[042/200] Iteration[008/030] Train loss: 0.1511
2023-02-06 15:53:12 | Train | Epoch[042/200] Iteration[009/030] Train loss: 0.1507
2023-02-06 15:53:13 | Train | Epoch[042/200] Iteration[010/030] Train loss: 0.1505
2023-02-06 15:53:13 | Train | Epoch[042/200] Iteration[011/030] Train loss: 0.1506
2023-02-06 15:53:14 | Train | Epoch[042/200] Iteration[012/030] Train loss: 0.1503
2023-02-06 15:53:14 | Train | Epoch[042/200] Iteration[013/030] Train loss: 0.1504
2023-02-06 15:53:15 | Train | Epoch[042/200] Iteration[014/030] Train loss: 0.1501
2023-02-06 15:53:15 | Train | Epoch[042/200] Iteration[015/030] Train loss: 0.1500
2023-02-06 15:53:15 | Train | Epoch[042/200] Iteration[016/030] Train loss: 0.1498
2023-02-06 15:53:16 | Train | Epoch[042/200] Iteration[017/030] Train loss: 0.1498
2023-02-06 15:53:16 | Train | Epoch[042/200] Iteration[018/030] Train loss: 0.1496
2023-02-06 15:53:17 | Train | Epoch[042/200] Iteration[019/030] Train loss: 0.1495
2023-02-06 15:53:17 | Train | Epoch[042/200] Iteration[020/030] Train loss: 0.1497
2023-02-06 15:53:18 | Train | Epoch[042/200] Iteration[021/030] Train loss: 0.1497
2023-02-06 15:53:18 | Train | Epoch[042/200] Iteration[022/030] Train loss: 0.1495
2023-02-06 15:53:18 | Train | Epoch[042/200] Iteration[023/030] Train loss: 0.1493
2023-02-06 15:53:19 | Train | Epoch[042/200] Iteration[024/030] Train loss: 0.1493
2023-02-06 15:53:19 | Train | Epoch[042/200] Iteration[025/030] Train loss: 0.1491
2023-02-06 15:53:20 | Train | Epoch[042/200] Iteration[026/030] Train loss: 0.1491
2023-02-06 15:53:20 | Train | Epoch[042/200] Iteration[027/030] Train loss: 0.1489
2023-02-06 15:53:21 | Train | Epoch[042/200] Iteration[028/030] Train loss: 0.1489
2023-02-06 15:53:21 | Train | Epoch[042/200] Iteration[029/030] Train loss: 0.1488
2023-02-06 15:53:21 | Train | Epoch[042/200] Iteration[030/030] Train loss: 0.1488
2023-02-06 15:53:22 | Valid | Epoch[042/200] Iteration[001/008] Valid loss: 0.2384
2023-02-06 15:53:22 | Valid | Epoch[042/200] Iteration[002/008] Valid loss: 0.2215
2023-02-06 15:53:22 | Valid | Epoch[042/200] Iteration[003/008] Valid loss: 0.2178
2023-02-06 15:53:22 | Valid | Epoch[042/200] Iteration[004/008] Valid loss: 0.2168
2023-02-06 15:53:22 | Valid | Epoch[042/200] Iteration[005/008] Valid loss: 0.2185
2023-02-06 15:53:22 | Valid | Epoch[042/200] Iteration[006/008] Valid loss: 0.2204
2023-02-06 15:53:22 | Valid | Epoch[042/200] Iteration[007/008] Valid loss: 0.2234
2023-02-06 15:53:22 | Valid | Epoch[042/200] Iteration[008/008] Valid loss: 0.2227
2023-02-06 15:53:22 | Valid | Epoch[042/200] MIou: 0.9004359323565383
2023-02-06 15:53:22 | Valid | Epoch[042/200] Pixel Accuracy: 0.9809519449869791
2023-02-06 15:53:22 | Valid | Epoch[042/200] Mean Pixel Accuracy: 0.9770523286491728
2023-02-06 15:53:22 | Stage | Epoch[042/200] Train loss:0.1488
2023-02-06 15:53:22 | Stage | Epoch[042/200] Valid loss:0.2227
2023-02-06 15:53:22 | Stage | Epoch[042/200] LR:0.01

2023-02-06 15:53:23 | Train | Epoch[043/200] Iteration[001/030] Train loss: 0.1465
2023-02-06 15:53:23 | Train | Epoch[043/200] Iteration[002/030] Train loss: 0.1449
2023-02-06 15:53:24 | Train | Epoch[043/200] Iteration[003/030] Train loss: 0.1455
2023-02-06 15:53:24 | Train | Epoch[043/200] Iteration[004/030] Train loss: 0.1452
2023-02-06 15:53:25 | Train | Epoch[043/200] Iteration[005/030] Train loss: 0.1450
2023-02-06 15:53:25 | Train | Epoch[043/200] Iteration[006/030] Train loss: 0.1449
2023-02-06 15:53:26 | Train | Epoch[043/200] Iteration[007/030] Train loss: 0.1447
2023-02-06 15:53:26 | Train | Epoch[043/200] Iteration[008/030] Train loss: 0.1451
2023-02-06 15:53:27 | Train | Epoch[043/200] Iteration[009/030] Train loss: 0.1454
2023-02-06 15:53:27 | Train | Epoch[043/200] Iteration[010/030] Train loss: 0.1453
2023-02-06 15:53:27 | Train | Epoch[043/200] Iteration[011/030] Train loss: 0.1451
2023-02-06 15:53:28 | Train | Epoch[043/200] Iteration[012/030] Train loss: 0.1450
2023-02-06 15:53:28 | Train | Epoch[043/200] Iteration[013/030] Train loss: 0.1449
2023-02-06 15:53:29 | Train | Epoch[043/200] Iteration[014/030] Train loss: 0.1450
2023-02-06 15:53:29 | Train | Epoch[043/200] Iteration[015/030] Train loss: 0.1450
2023-02-06 15:53:30 | Train | Epoch[043/200] Iteration[016/030] Train loss: 0.1449
2023-02-06 15:53:30 | Train | Epoch[043/200] Iteration[017/030] Train loss: 0.1449
2023-02-06 15:53:30 | Train | Epoch[043/200] Iteration[018/030] Train loss: 0.1448
2023-02-06 15:53:31 | Train | Epoch[043/200] Iteration[019/030] Train loss: 0.1447
2023-02-06 15:53:31 | Train | Epoch[043/200] Iteration[020/030] Train loss: 0.1448
2023-02-06 15:53:32 | Train | Epoch[043/200] Iteration[021/030] Train loss: 0.1447
2023-02-06 15:53:32 | Train | Epoch[043/200] Iteration[022/030] Train loss: 0.1448
2023-02-06 15:53:33 | Train | Epoch[043/200] Iteration[023/030] Train loss: 0.1447
2023-02-06 15:53:33 | Train | Epoch[043/200] Iteration[024/030] Train loss: 0.1445
2023-02-06 15:53:33 | Train | Epoch[043/200] Iteration[025/030] Train loss: 0.1445
2023-02-06 15:53:34 | Train | Epoch[043/200] Iteration[026/030] Train loss: 0.1443
2023-02-06 15:53:34 | Train | Epoch[043/200] Iteration[027/030] Train loss: 0.1442
2023-02-06 15:53:35 | Train | Epoch[043/200] Iteration[028/030] Train loss: 0.1443
2023-02-06 15:53:35 | Train | Epoch[043/200] Iteration[029/030] Train loss: 0.1443
2023-02-06 15:53:35 | Train | Epoch[043/200] Iteration[030/030] Train loss: 0.1443
2023-02-06 15:53:36 | Valid | Epoch[043/200] Iteration[001/008] Valid loss: 0.3430
2023-02-06 15:53:36 | Valid | Epoch[043/200] Iteration[002/008] Valid loss: 0.3137
2023-02-06 15:53:36 | Valid | Epoch[043/200] Iteration[003/008] Valid loss: 0.3023
2023-02-06 15:53:36 | Valid | Epoch[043/200] Iteration[004/008] Valid loss: 0.3077
2023-02-06 15:53:36 | Valid | Epoch[043/200] Iteration[005/008] Valid loss: 0.3150
2023-02-06 15:53:36 | Valid | Epoch[043/200] Iteration[006/008] Valid loss: 0.3125
2023-02-06 15:53:36 | Valid | Epoch[043/200] Iteration[007/008] Valid loss: 0.3254
2023-02-06 15:53:36 | Valid | Epoch[043/200] Iteration[008/008] Valid loss: 0.3286
2023-02-06 15:53:36 | Valid | Epoch[043/200] MIou: 0.8580910103507238
2023-02-06 15:53:36 | Valid | Epoch[043/200] Pixel Accuracy: 0.9699694315592448
2023-02-06 15:53:36 | Valid | Epoch[043/200] Mean Pixel Accuracy: 0.9803870877712748
2023-02-06 15:53:36 | Stage | Epoch[043/200] Train loss:0.1443
2023-02-06 15:53:36 | Stage | Epoch[043/200] Valid loss:0.3286
2023-02-06 15:53:36 | Stage | Epoch[043/200] LR:0.01

2023-02-06 15:53:37 | Train | Epoch[044/200] Iteration[001/030] Train loss: 0.1429
2023-02-06 15:53:38 | Train | Epoch[044/200] Iteration[002/030] Train loss: 0.1425
2023-02-06 15:53:38 | Train | Epoch[044/200] Iteration[003/030] Train loss: 0.1428
2023-02-06 15:53:38 | Train | Epoch[044/200] Iteration[004/030] Train loss: 0.1427
2023-02-06 15:53:39 | Train | Epoch[044/200] Iteration[005/030] Train loss: 0.1420
2023-02-06 15:53:39 | Train | Epoch[044/200] Iteration[006/030] Train loss: 0.1417
2023-02-06 15:53:40 | Train | Epoch[044/200] Iteration[007/030] Train loss: 0.1413
2023-02-06 15:53:40 | Train | Epoch[044/200] Iteration[008/030] Train loss: 0.1413
2023-02-06 15:53:41 | Train | Epoch[044/200] Iteration[009/030] Train loss: 0.1414
2023-02-06 15:53:41 | Train | Epoch[044/200] Iteration[010/030] Train loss: 0.1410
2023-02-06 15:53:42 | Train | Epoch[044/200] Iteration[011/030] Train loss: 0.1409
2023-02-06 15:53:42 | Train | Epoch[044/200] Iteration[012/030] Train loss: 0.1408
2023-02-06 15:53:42 | Train | Epoch[044/200] Iteration[013/030] Train loss: 0.1409
2023-02-06 15:53:43 | Train | Epoch[044/200] Iteration[014/030] Train loss: 0.1409
2023-02-06 15:53:43 | Train | Epoch[044/200] Iteration[015/030] Train loss: 0.1409
2023-02-06 15:53:44 | Train | Epoch[044/200] Iteration[016/030] Train loss: 0.1409
2023-02-06 15:53:44 | Train | Epoch[044/200] Iteration[017/030] Train loss: 0.1409
2023-02-06 15:53:45 | Train | Epoch[044/200] Iteration[018/030] Train loss: 0.1409
2023-02-06 15:53:45 | Train | Epoch[044/200] Iteration[019/030] Train loss: 0.1407
2023-02-06 15:53:45 | Train | Epoch[044/200] Iteration[020/030] Train loss: 0.1406
2023-02-06 15:53:46 | Train | Epoch[044/200] Iteration[021/030] Train loss: 0.1405
2023-02-06 15:53:46 | Train | Epoch[044/200] Iteration[022/030] Train loss: 0.1405
2023-02-06 15:53:47 | Train | Epoch[044/200] Iteration[023/030] Train loss: 0.1405
2023-02-06 15:53:47 | Train | Epoch[044/200] Iteration[024/030] Train loss: 0.1404
2023-02-06 15:53:48 | Train | Epoch[044/200] Iteration[025/030] Train loss: 0.1404
2023-02-06 15:53:48 | Train | Epoch[044/200] Iteration[026/030] Train loss: 0.1403
2023-02-06 15:53:48 | Train | Epoch[044/200] Iteration[027/030] Train loss: 0.1402
2023-02-06 15:53:49 | Train | Epoch[044/200] Iteration[028/030] Train loss: 0.1402
2023-02-06 15:53:49 | Train | Epoch[044/200] Iteration[029/030] Train loss: 0.1401
2023-02-06 15:53:49 | Train | Epoch[044/200] Iteration[030/030] Train loss: 0.1402
2023-02-06 15:53:50 | Valid | Epoch[044/200] Iteration[001/008] Valid loss: 0.1678
2023-02-06 15:53:50 | Valid | Epoch[044/200] Iteration[002/008] Valid loss: 0.1614
2023-02-06 15:53:50 | Valid | Epoch[044/200] Iteration[003/008] Valid loss: 0.1601
2023-02-06 15:53:50 | Valid | Epoch[044/200] Iteration[004/008] Valid loss: 0.1587
2023-02-06 15:53:50 | Valid | Epoch[044/200] Iteration[005/008] Valid loss: 0.1605
2023-02-06 15:53:50 | Valid | Epoch[044/200] Iteration[006/008] Valid loss: 0.1605
2023-02-06 15:53:50 | Valid | Epoch[044/200] Iteration[007/008] Valid loss: 0.1621
2023-02-06 15:53:51 | Valid | Epoch[044/200] Iteration[008/008] Valid loss: 0.1615
2023-02-06 15:53:51 | Valid | Epoch[044/200] MIou: 0.9316495186718232
2023-02-06 15:53:51 | Valid | Epoch[044/200] Pixel Accuracy: 0.9880116780598959
2023-02-06 15:53:51 | Valid | Epoch[044/200] Mean Pixel Accuracy: 0.9669202169946848
2023-02-06 15:53:51 | Stage | Epoch[044/200] Train loss:0.1402
2023-02-06 15:53:51 | Stage | Epoch[044/200] Valid loss:0.1615
2023-02-06 15:53:51 | Stage | Epoch[044/200] LR:0.01

2023-02-06 15:53:51 | Train | Epoch[045/200] Iteration[001/030] Train loss: 0.1378
2023-02-06 15:53:52 | Train | Epoch[045/200] Iteration[002/030] Train loss: 0.1372
2023-02-06 15:53:52 | Train | Epoch[045/200] Iteration[003/030] Train loss: 0.1384
2023-02-06 15:53:53 | Train | Epoch[045/200] Iteration[004/030] Train loss: 0.1387
2023-02-06 15:53:53 | Train | Epoch[045/200] Iteration[005/030] Train loss: 0.1379
2023-02-06 15:53:54 | Train | Epoch[045/200] Iteration[006/030] Train loss: 0.1374
2023-02-06 15:53:54 | Train | Epoch[045/200] Iteration[007/030] Train loss: 0.1374
2023-02-06 15:53:54 | Train | Epoch[045/200] Iteration[008/030] Train loss: 0.1374
2023-02-06 15:53:55 | Train | Epoch[045/200] Iteration[009/030] Train loss: 0.1373
2023-02-06 15:53:55 | Train | Epoch[045/200] Iteration[010/030] Train loss: 0.1377
2023-02-06 15:53:56 | Train | Epoch[045/200] Iteration[011/030] Train loss: 0.1374
2023-02-06 15:53:56 | Train | Epoch[045/200] Iteration[012/030] Train loss: 0.1373
2023-02-06 15:53:57 | Train | Epoch[045/200] Iteration[013/030] Train loss: 0.1373
2023-02-06 15:53:57 | Train | Epoch[045/200] Iteration[014/030] Train loss: 0.1371
2023-02-06 15:53:57 | Train | Epoch[045/200] Iteration[015/030] Train loss: 0.1374
2023-02-06 15:53:58 | Train | Epoch[045/200] Iteration[016/030] Train loss: 0.1372
2023-02-06 15:53:58 | Train | Epoch[045/200] Iteration[017/030] Train loss: 0.1371
2023-02-06 15:53:59 | Train | Epoch[045/200] Iteration[018/030] Train loss: 0.1370
2023-02-06 15:53:59 | Train | Epoch[045/200] Iteration[019/030] Train loss: 0.1368
2023-02-06 15:54:00 | Train | Epoch[045/200] Iteration[020/030] Train loss: 0.1369
2023-02-06 15:54:00 | Train | Epoch[045/200] Iteration[021/030] Train loss: 0.1368
2023-02-06 15:54:00 | Train | Epoch[045/200] Iteration[022/030] Train loss: 0.1367
2023-02-06 15:54:01 | Train | Epoch[045/200] Iteration[023/030] Train loss: 0.1366
2023-02-06 15:54:01 | Train | Epoch[045/200] Iteration[024/030] Train loss: 0.1365
2023-02-06 15:54:02 | Train | Epoch[045/200] Iteration[025/030] Train loss: 0.1365
2023-02-06 15:54:02 | Train | Epoch[045/200] Iteration[026/030] Train loss: 0.1365
2023-02-06 15:54:03 | Train | Epoch[045/200] Iteration[027/030] Train loss: 0.1364
2023-02-06 15:54:03 | Train | Epoch[045/200] Iteration[028/030] Train loss: 0.1363
2023-02-06 15:54:03 | Train | Epoch[045/200] Iteration[029/030] Train loss: 0.1362
2023-02-06 15:54:04 | Train | Epoch[045/200] Iteration[030/030] Train loss: 0.1363
2023-02-06 15:54:04 | Valid | Epoch[045/200] Iteration[001/008] Valid loss: 0.1678
2023-02-06 15:54:04 | Valid | Epoch[045/200] Iteration[002/008] Valid loss: 0.1594
2023-02-06 15:54:04 | Valid | Epoch[045/200] Iteration[003/008] Valid loss: 0.1567
2023-02-06 15:54:04 | Valid | Epoch[045/200] Iteration[004/008] Valid loss: 0.1548
2023-02-06 15:54:05 | Valid | Epoch[045/200] Iteration[005/008] Valid loss: 0.1556
2023-02-06 15:54:05 | Valid | Epoch[045/200] Iteration[006/008] Valid loss: 0.1550
2023-02-06 15:54:05 | Valid | Epoch[045/200] Iteration[007/008] Valid loss: 0.1563
2023-02-06 15:54:05 | Valid | Epoch[045/200] Iteration[008/008] Valid loss: 0.1560
2023-02-06 15:54:05 | Valid | Epoch[045/200] MIou: 0.9349882158053798
2023-02-06 15:54:05 | Valid | Epoch[045/200] Pixel Accuracy: 0.9886792500813802
2023-02-06 15:54:05 | Valid | Epoch[045/200] Mean Pixel Accuracy: 0.9667672243849601
2023-02-06 15:54:05 | Stage | Epoch[045/200] Train loss:0.1363
2023-02-06 15:54:05 | Stage | Epoch[045/200] Valid loss:0.1560
2023-02-06 15:54:05 | Stage | Epoch[045/200] LR:0.01

2023-02-06 15:54:06 | Train | Epoch[046/200] Iteration[001/030] Train loss: 0.1337
2023-02-06 15:54:06 | Train | Epoch[046/200] Iteration[002/030] Train loss: 0.1340
2023-02-06 15:54:06 | Train | Epoch[046/200] Iteration[003/030] Train loss: 0.1334
2023-02-06 15:54:07 | Train | Epoch[046/200] Iteration[004/030] Train loss: 0.1331
2023-02-06 15:54:07 | Train | Epoch[046/200] Iteration[005/030] Train loss: 0.1333
2023-02-06 15:54:08 | Train | Epoch[046/200] Iteration[006/030] Train loss: 0.1332
2023-02-06 15:54:08 | Train | Epoch[046/200] Iteration[007/030] Train loss: 0.1331
2023-02-06 15:54:09 | Train | Epoch[046/200] Iteration[008/030] Train loss: 0.1330
2023-02-06 15:54:09 | Train | Epoch[046/200] Iteration[009/030] Train loss: 0.1328
2023-02-06 15:54:10 | Train | Epoch[046/200] Iteration[010/030] Train loss: 0.1327
2023-02-06 15:54:10 | Train | Epoch[046/200] Iteration[011/030] Train loss: 0.1326
2023-02-06 15:54:10 | Train | Epoch[046/200] Iteration[012/030] Train loss: 0.1323
2023-02-06 15:54:11 | Train | Epoch[046/200] Iteration[013/030] Train loss: 0.1326
2023-02-06 15:54:11 | Train | Epoch[046/200] Iteration[014/030] Train loss: 0.1326
2023-02-06 15:54:12 | Train | Epoch[046/200] Iteration[015/030] Train loss: 0.1326
2023-02-06 15:54:12 | Train | Epoch[046/200] Iteration[016/030] Train loss: 0.1326
2023-02-06 15:54:13 | Train | Epoch[046/200] Iteration[017/030] Train loss: 0.1326
2023-02-06 15:54:13 | Train | Epoch[046/200] Iteration[018/030] Train loss: 0.1325
2023-02-06 15:54:13 | Train | Epoch[046/200] Iteration[019/030] Train loss: 0.1324
2023-02-06 15:54:14 | Train | Epoch[046/200] Iteration[020/030] Train loss: 0.1323
2023-02-06 15:54:14 | Train | Epoch[046/200] Iteration[021/030] Train loss: 0.1324
2023-02-06 15:54:15 | Train | Epoch[046/200] Iteration[022/030] Train loss: 0.1323
2023-02-06 15:54:15 | Train | Epoch[046/200] Iteration[023/030] Train loss: 0.1322
2023-02-06 15:54:16 | Train | Epoch[046/200] Iteration[024/030] Train loss: 0.1321
2023-02-06 15:54:16 | Train | Epoch[046/200] Iteration[025/030] Train loss: 0.1321
2023-02-06 15:54:16 | Train | Epoch[046/200] Iteration[026/030] Train loss: 0.1321
2023-02-06 15:54:17 | Train | Epoch[046/200] Iteration[027/030] Train loss: 0.1320
2023-02-06 15:54:17 | Train | Epoch[046/200] Iteration[028/030] Train loss: 0.1322
2023-02-06 15:54:18 | Train | Epoch[046/200] Iteration[029/030] Train loss: 0.1321
2023-02-06 15:54:18 | Train | Epoch[046/200] Iteration[030/030] Train loss: 0.1324
2023-02-06 15:54:18 | Valid | Epoch[046/200] Iteration[001/008] Valid loss: 0.4880
2023-02-06 15:54:18 | Valid | Epoch[046/200] Iteration[002/008] Valid loss: 0.4477
2023-02-06 15:54:19 | Valid | Epoch[046/200] Iteration[003/008] Valid loss: 0.4355
2023-02-06 15:54:19 | Valid | Epoch[046/200] Iteration[004/008] Valid loss: 0.4470
2023-02-06 15:54:19 | Valid | Epoch[046/200] Iteration[005/008] Valid loss: 0.4589
2023-02-06 15:54:19 | Valid | Epoch[046/200] Iteration[006/008] Valid loss: 0.4558
2023-02-06 15:54:19 | Valid | Epoch[046/200] Iteration[007/008] Valid loss: 0.4794
2023-02-06 15:54:19 | Valid | Epoch[046/200] Iteration[008/008] Valid loss: 0.4809
2023-02-06 15:54:19 | Valid | Epoch[046/200] MIou: 0.8581499948108915
2023-02-06 15:54:19 | Valid | Epoch[046/200] Pixel Accuracy: 0.9699211120605469
2023-02-06 15:54:19 | Valid | Epoch[046/200] Mean Pixel Accuracy: 0.9815081546577001
2023-02-06 15:54:19 | Stage | Epoch[046/200] Train loss:0.1324
2023-02-06 15:54:19 | Stage | Epoch[046/200] Valid loss:0.4809
2023-02-06 15:54:19 | Stage | Epoch[046/200] LR:0.01

2023-02-06 15:54:20 | Train | Epoch[047/200] Iteration[001/030] Train loss: 0.1339
2023-02-06 15:54:20 | Train | Epoch[047/200] Iteration[002/030] Train loss: 0.1326
2023-02-06 15:54:21 | Train | Epoch[047/200] Iteration[003/030] Train loss: 0.1318
2023-02-06 15:54:21 | Train | Epoch[047/200] Iteration[004/030] Train loss: 0.1313
2023-02-06 15:54:22 | Train | Epoch[047/200] Iteration[005/030] Train loss: 0.1313
2023-02-06 15:54:22 | Train | Epoch[047/200] Iteration[006/030] Train loss: 0.1322
2023-02-06 15:54:22 | Train | Epoch[047/200] Iteration[007/030] Train loss: 0.1320
2023-02-06 15:54:23 | Train | Epoch[047/200] Iteration[008/030] Train loss: 0.1316
2023-02-06 15:54:23 | Train | Epoch[047/200] Iteration[009/030] Train loss: 0.1319
2023-02-06 15:54:24 | Train | Epoch[047/200] Iteration[010/030] Train loss: 0.1316
2023-02-06 15:54:24 | Train | Epoch[047/200] Iteration[011/030] Train loss: 0.1315
2023-02-06 15:54:25 | Train | Epoch[047/200] Iteration[012/030] Train loss: 0.1312
2023-02-06 15:54:25 | Train | Epoch[047/200] Iteration[013/030] Train loss: 0.1309
2023-02-06 15:54:25 | Train | Epoch[047/200] Iteration[014/030] Train loss: 0.1308
2023-02-06 15:54:26 | Train | Epoch[047/200] Iteration[015/030] Train loss: 0.1306
2023-02-06 15:54:26 | Train | Epoch[047/200] Iteration[016/030] Train loss: 0.1304
2023-02-06 15:54:27 | Train | Epoch[047/200] Iteration[017/030] Train loss: 0.1303
2023-02-06 15:54:27 | Train | Epoch[047/200] Iteration[018/030] Train loss: 0.1300
2023-02-06 15:54:28 | Train | Epoch[047/200] Iteration[019/030] Train loss: 0.1298
2023-02-06 15:54:28 | Train | Epoch[047/200] Iteration[020/030] Train loss: 0.1297
2023-02-06 15:54:29 | Train | Epoch[047/200] Iteration[021/030] Train loss: 0.1295
2023-02-06 15:54:29 | Train | Epoch[047/200] Iteration[022/030] Train loss: 0.1296
2023-02-06 15:54:29 | Train | Epoch[047/200] Iteration[023/030] Train loss: 0.1296
2023-02-06 15:54:30 | Train | Epoch[047/200] Iteration[024/030] Train loss: 0.1295
2023-02-06 15:54:30 | Train | Epoch[047/200] Iteration[025/030] Train loss: 0.1294
2023-02-06 15:54:31 | Train | Epoch[047/200] Iteration[026/030] Train loss: 0.1293
2023-02-06 15:54:31 | Train | Epoch[047/200] Iteration[027/030] Train loss: 0.1292
2023-02-06 15:54:32 | Train | Epoch[047/200] Iteration[028/030] Train loss: 0.1291
2023-02-06 15:54:32 | Train | Epoch[047/200] Iteration[029/030] Train loss: 0.1290
2023-02-06 15:54:32 | Train | Epoch[047/200] Iteration[030/030] Train loss: 0.1289
2023-02-06 15:54:33 | Valid | Epoch[047/200] Iteration[001/008] Valid loss: 0.1482
2023-02-06 15:54:33 | Valid | Epoch[047/200] Iteration[002/008] Valid loss: 0.1414
2023-02-06 15:54:33 | Valid | Epoch[047/200] Iteration[003/008] Valid loss: 0.1393
2023-02-06 15:54:33 | Valid | Epoch[047/200] Iteration[004/008] Valid loss: 0.1378
2023-02-06 15:54:33 | Valid | Epoch[047/200] Iteration[005/008] Valid loss: 0.1378
2023-02-06 15:54:33 | Valid | Epoch[047/200] Iteration[006/008] Valid loss: 0.1389
2023-02-06 15:54:33 | Valid | Epoch[047/200] Iteration[007/008] Valid loss: 0.1393
2023-02-06 15:54:33 | Valid | Epoch[047/200] Iteration[008/008] Valid loss: 0.1392
2023-02-06 15:54:33 | Valid | Epoch[047/200] MIou: 0.9174534540175602
2023-02-06 15:54:33 | Valid | Epoch[047/200] Pixel Accuracy: 0.9859453837076823
2023-02-06 15:54:33 | Valid | Epoch[047/200] Mean Pixel Accuracy: 0.9396046866200078
2023-02-06 15:54:33 | Stage | Epoch[047/200] Train loss:0.1289
2023-02-06 15:54:33 | Stage | Epoch[047/200] Valid loss:0.1392
2023-02-06 15:54:33 | Stage | Epoch[047/200] LR:0.01

2023-02-06 15:54:34 | Train | Epoch[048/200] Iteration[001/030] Train loss: 0.1258
2023-02-06 15:54:34 | Train | Epoch[048/200] Iteration[002/030] Train loss: 0.1279
2023-02-06 15:54:35 | Train | Epoch[048/200] Iteration[003/030] Train loss: 0.1277
2023-02-06 15:54:35 | Train | Epoch[048/200] Iteration[004/030] Train loss: 0.1281
2023-02-06 15:54:36 | Train | Epoch[048/200] Iteration[005/030] Train loss: 0.1277
2023-02-06 15:54:36 | Train | Epoch[048/200] Iteration[006/030] Train loss: 0.1275
2023-02-06 15:54:37 | Train | Epoch[048/200] Iteration[007/030] Train loss: 0.1272
2023-02-06 15:54:37 | Train | Epoch[048/200] Iteration[008/030] Train loss: 0.1272
2023-02-06 15:54:38 | Train | Epoch[048/200] Iteration[009/030] Train loss: 0.1271
2023-02-06 15:54:38 | Train | Epoch[048/200] Iteration[010/030] Train loss: 0.1272
2023-02-06 15:54:38 | Train | Epoch[048/200] Iteration[011/030] Train loss: 0.1272
2023-02-06 15:54:39 | Train | Epoch[048/200] Iteration[012/030] Train loss: 0.1273
2023-02-06 15:54:39 | Train | Epoch[048/200] Iteration[013/030] Train loss: 0.1271
2023-02-06 15:54:40 | Train | Epoch[048/200] Iteration[014/030] Train loss: 0.1269
2023-02-06 15:54:40 | Train | Epoch[048/200] Iteration[015/030] Train loss: 0.1267
2023-02-06 15:54:41 | Train | Epoch[048/200] Iteration[016/030] Train loss: 0.1267
2023-02-06 15:54:41 | Train | Epoch[048/200] Iteration[017/030] Train loss: 0.1267
2023-02-06 15:54:41 | Train | Epoch[048/200] Iteration[018/030] Train loss: 0.1267
2023-02-06 15:54:42 | Train | Epoch[048/200] Iteration[019/030] Train loss: 0.1266
2023-02-06 15:54:42 | Train | Epoch[048/200] Iteration[020/030] Train loss: 0.1264
2023-02-06 15:54:43 | Train | Epoch[048/200] Iteration[021/030] Train loss: 0.1264
2023-02-06 15:54:43 | Train | Epoch[048/200] Iteration[022/030] Train loss: 0.1263
2023-02-06 15:54:44 | Train | Epoch[048/200] Iteration[023/030] Train loss: 0.1263
2023-02-06 15:54:44 | Train | Epoch[048/200] Iteration[024/030] Train loss: 0.1261
2023-02-06 15:54:44 | Train | Epoch[048/200] Iteration[025/030] Train loss: 0.1261
2023-02-06 15:54:45 | Train | Epoch[048/200] Iteration[026/030] Train loss: 0.1261
2023-02-06 15:54:45 | Train | Epoch[048/200] Iteration[027/030] Train loss: 0.1260
2023-02-06 15:54:46 | Train | Epoch[048/200] Iteration[028/030] Train loss: 0.1260
2023-02-06 15:54:46 | Train | Epoch[048/200] Iteration[029/030] Train loss: 0.1259
2023-02-06 15:54:46 | Train | Epoch[048/200] Iteration[030/030] Train loss: 0.1258
2023-02-06 15:54:47 | Valid | Epoch[048/200] Iteration[001/008] Valid loss: 0.1689
2023-02-06 15:54:47 | Valid | Epoch[048/200] Iteration[002/008] Valid loss: 0.1688
2023-02-06 15:54:47 | Valid | Epoch[048/200] Iteration[003/008] Valid loss: 0.1722
2023-02-06 15:54:47 | Valid | Epoch[048/200] Iteration[004/008] Valid loss: 0.1717
2023-02-06 15:54:47 | Valid | Epoch[048/200] Iteration[005/008] Valid loss: 0.1737
2023-02-06 15:54:47 | Valid | Epoch[048/200] Iteration[006/008] Valid loss: 0.1738
2023-02-06 15:54:47 | Valid | Epoch[048/200] Iteration[007/008] Valid loss: 0.1738
2023-02-06 15:54:47 | Valid | Epoch[048/200] Iteration[008/008] Valid loss: 0.1762
2023-02-06 15:54:48 | Valid | Epoch[048/200] MIou: 0.661098557608123
2023-02-06 15:54:48 | Valid | Epoch[048/200] Pixel Accuracy: 0.9432767232259115
2023-02-06 15:54:48 | Valid | Epoch[048/200] Mean Pixel Accuracy: 0.69253642175684
2023-02-06 15:54:48 | Stage | Epoch[048/200] Train loss:0.1258
2023-02-06 15:54:48 | Stage | Epoch[048/200] Valid loss:0.1762
2023-02-06 15:54:48 | Stage | Epoch[048/200] LR:0.01

2023-02-06 15:54:48 | Train | Epoch[049/200] Iteration[001/030] Train loss: 0.1250
2023-02-06 15:54:49 | Train | Epoch[049/200] Iteration[002/030] Train loss: 0.1253
2023-02-06 15:54:49 | Train | Epoch[049/200] Iteration[003/030] Train loss: 0.1249
2023-02-06 15:54:50 | Train | Epoch[049/200] Iteration[004/030] Train loss: 0.1239
2023-02-06 15:54:50 | Train | Epoch[049/200] Iteration[005/030] Train loss: 0.1238
2023-02-06 15:54:51 | Train | Epoch[049/200] Iteration[006/030] Train loss: 0.1236
2023-02-06 15:54:51 | Train | Epoch[049/200] Iteration[007/030] Train loss: 0.1236
2023-02-06 15:54:51 | Train | Epoch[049/200] Iteration[008/030] Train loss: 0.1233
2023-02-06 15:54:52 | Train | Epoch[049/200] Iteration[009/030] Train loss: 0.1231
2023-02-06 15:54:52 | Train | Epoch[049/200] Iteration[010/030] Train loss: 0.1231
2023-02-06 15:54:53 | Train | Epoch[049/200] Iteration[011/030] Train loss: 0.1232
2023-02-06 15:54:53 | Train | Epoch[049/200] Iteration[012/030] Train loss: 0.1234
2023-02-06 15:54:54 | Train | Epoch[049/200] Iteration[013/030] Train loss: 0.1237
2023-02-06 15:54:54 | Train | Epoch[049/200] Iteration[014/030] Train loss: 0.1234
2023-02-06 15:54:54 | Train | Epoch[049/200] Iteration[015/030] Train loss: 0.1232
2023-02-06 15:54:55 | Train | Epoch[049/200] Iteration[016/030] Train loss: 0.1231
2023-02-06 15:54:55 | Train | Epoch[049/200] Iteration[017/030] Train loss: 0.1230
2023-02-06 15:54:56 | Train | Epoch[049/200] Iteration[018/030] Train loss: 0.1235
2023-02-06 15:54:56 | Train | Epoch[049/200] Iteration[019/030] Train loss: 0.1235
2023-02-06 15:54:57 | Train | Epoch[049/200] Iteration[020/030] Train loss: 0.1235
2023-02-06 15:54:57 | Train | Epoch[049/200] Iteration[021/030] Train loss: 0.1235
2023-02-06 15:54:57 | Train | Epoch[049/200] Iteration[022/030] Train loss: 0.1235
2023-02-06 15:54:58 | Train | Epoch[049/200] Iteration[023/030] Train loss: 0.1234
2023-02-06 15:54:58 | Train | Epoch[049/200] Iteration[024/030] Train loss: 0.1233
2023-02-06 15:54:59 | Train | Epoch[049/200] Iteration[025/030] Train loss: 0.1232
2023-02-06 15:54:59 | Train | Epoch[049/200] Iteration[026/030] Train loss: 0.1232
2023-02-06 15:55:00 | Train | Epoch[049/200] Iteration[027/030] Train loss: 0.1231
2023-02-06 15:55:00 | Train | Epoch[049/200] Iteration[028/030] Train loss: 0.1231
2023-02-06 15:55:01 | Train | Epoch[049/200] Iteration[029/030] Train loss: 0.1229
2023-02-06 15:55:01 | Train | Epoch[049/200] Iteration[030/030] Train loss: 0.1229
2023-02-06 15:55:01 | Valid | Epoch[049/200] Iteration[001/008] Valid loss: 0.8448
2023-02-06 15:55:01 | Valid | Epoch[049/200] Iteration[002/008] Valid loss: 0.8061
2023-02-06 15:55:01 | Valid | Epoch[049/200] Iteration[003/008] Valid loss: 0.8215
2023-02-06 15:55:01 | Valid | Epoch[049/200] Iteration[004/008] Valid loss: 0.8483
2023-02-06 15:55:02 | Valid | Epoch[049/200] Iteration[005/008] Valid loss: 0.8635
2023-02-06 15:55:02 | Valid | Epoch[049/200] Iteration[006/008] Valid loss: 0.8677
2023-02-06 15:55:02 | Valid | Epoch[049/200] Iteration[007/008] Valid loss: 0.9041
2023-02-06 15:55:02 | Valid | Epoch[049/200] Iteration[008/008] Valid loss: 0.9280
2023-02-06 15:55:02 | Valid | Epoch[049/200] MIou: 0.7935679742033028
2023-02-06 15:55:02 | Valid | Epoch[049/200] Pixel Accuracy: 0.9497909545898438
2023-02-06 15:55:02 | Valid | Epoch[049/200] Mean Pixel Accuracy: 0.9716421106971332
2023-02-06 15:55:02 | Stage | Epoch[049/200] Train loss:0.1229
2023-02-06 15:55:02 | Stage | Epoch[049/200] Valid loss:0.9280
2023-02-06 15:55:02 | Stage | Epoch[049/200] LR:0.01

2023-02-06 15:55:03 | Train | Epoch[050/200] Iteration[001/030] Train loss: 0.1211
2023-02-06 15:55:03 | Train | Epoch[050/200] Iteration[002/030] Train loss: 0.1196
2023-02-06 15:55:03 | Train | Epoch[050/200] Iteration[003/030] Train loss: 0.1190
2023-02-06 15:55:04 | Train | Epoch[050/200] Iteration[004/030] Train loss: 0.1188
2023-02-06 15:55:04 | Train | Epoch[050/200] Iteration[005/030] Train loss: 0.1189
2023-02-06 15:55:05 | Train | Epoch[050/200] Iteration[006/030] Train loss: 0.1188
2023-02-06 15:55:05 | Train | Epoch[050/200] Iteration[007/030] Train loss: 0.1187
2023-02-06 15:55:06 | Train | Epoch[050/200] Iteration[008/030] Train loss: 0.1193
2023-02-06 15:55:06 | Train | Epoch[050/200] Iteration[009/030] Train loss: 0.1194
2023-02-06 15:55:07 | Train | Epoch[050/200] Iteration[010/030] Train loss: 0.1199
2023-02-06 15:55:07 | Train | Epoch[050/200] Iteration[011/030] Train loss: 0.1200
2023-02-06 15:55:07 | Train | Epoch[050/200] Iteration[012/030] Train loss: 0.1199
2023-02-06 15:55:08 | Train | Epoch[050/200] Iteration[013/030] Train loss: 0.1199
2023-02-06 15:55:08 | Train | Epoch[050/200] Iteration[014/030] Train loss: 0.1199
2023-02-06 15:55:09 | Train | Epoch[050/200] Iteration[015/030] Train loss: 0.1200
2023-02-06 15:55:09 | Train | Epoch[050/200] Iteration[016/030] Train loss: 0.1200
2023-02-06 15:55:10 | Train | Epoch[050/200] Iteration[017/030] Train loss: 0.1200
2023-02-06 15:55:10 | Train | Epoch[050/200] Iteration[018/030] Train loss: 0.1198
2023-02-06 15:55:10 | Train | Epoch[050/200] Iteration[019/030] Train loss: 0.1198
2023-02-06 15:55:11 | Train | Epoch[050/200] Iteration[020/030] Train loss: 0.1198
2023-02-06 15:55:11 | Train | Epoch[050/200] Iteration[021/030] Train loss: 0.1198
2023-02-06 15:55:12 | Train | Epoch[050/200] Iteration[022/030] Train loss: 0.1197
2023-02-06 15:55:12 | Train | Epoch[050/200] Iteration[023/030] Train loss: 0.1197
2023-02-06 15:55:13 | Train | Epoch[050/200] Iteration[024/030] Train loss: 0.1196
2023-02-06 15:55:13 | Train | Epoch[050/200] Iteration[025/030] Train loss: 0.1196
2023-02-06 15:55:13 | Train | Epoch[050/200] Iteration[026/030] Train loss: 0.1195
2023-02-06 15:55:14 | Train | Epoch[050/200] Iteration[027/030] Train loss: 0.1195
2023-02-06 15:55:14 | Train | Epoch[050/200] Iteration[028/030] Train loss: 0.1195
2023-02-06 15:55:15 | Train | Epoch[050/200] Iteration[029/030] Train loss: 0.1194
2023-02-06 15:55:15 | Train | Epoch[050/200] Iteration[030/030] Train loss: 0.1193
2023-02-06 15:55:15 | Valid | Epoch[050/200] Iteration[001/008] Valid loss: 0.9840
2023-02-06 15:55:16 | Valid | Epoch[050/200] Iteration[002/008] Valid loss: 0.9861
2023-02-06 15:55:16 | Valid | Epoch[050/200] Iteration[003/008] Valid loss: 1.0146
2023-02-06 15:55:16 | Valid | Epoch[050/200] Iteration[004/008] Valid loss: 1.0324
2023-02-06 15:55:16 | Valid | Epoch[050/200] Iteration[005/008] Valid loss: 1.0735
2023-02-06 15:55:16 | Valid | Epoch[050/200] Iteration[006/008] Valid loss: 1.0478
2023-02-06 15:55:16 | Valid | Epoch[050/200] Iteration[007/008] Valid loss: 1.1006
2023-02-06 15:55:16 | Valid | Epoch[050/200] Iteration[008/008] Valid loss: 1.1324
2023-02-06 15:55:16 | Valid | Epoch[050/200] MIou: 0.7627810817933951
2023-02-06 15:55:16 | Valid | Epoch[050/200] Pixel Accuracy: 0.9382540384928385
2023-02-06 15:55:16 | Valid | Epoch[050/200] Mean Pixel Accuracy: 0.9650853535412375
2023-02-06 15:55:16 | Stage | Epoch[050/200] Train loss:0.1193
2023-02-06 15:55:16 | Stage | Epoch[050/200] Valid loss:1.1324
2023-02-06 15:55:16 | Stage | Epoch[050/200] LR:0.01

2023-02-06 15:55:17 | Train | Epoch[051/200] Iteration[001/030] Train loss: 0.1178
2023-02-06 15:55:17 | Train | Epoch[051/200] Iteration[002/030] Train loss: 0.1186
2023-02-06 15:55:18 | Train | Epoch[051/200] Iteration[003/030] Train loss: 0.1185
2023-02-06 15:55:18 | Train | Epoch[051/200] Iteration[004/030] Train loss: 0.1178
2023-02-06 15:55:19 | Train | Epoch[051/200] Iteration[005/030] Train loss: 0.1178
2023-02-06 15:55:19 | Train | Epoch[051/200] Iteration[006/030] Train loss: 0.1177
2023-02-06 15:55:20 | Train | Epoch[051/200] Iteration[007/030] Train loss: 0.1176
2023-02-06 15:55:20 | Train | Epoch[051/200] Iteration[008/030] Train loss: 0.1174
2023-02-06 15:55:21 | Train | Epoch[051/200] Iteration[009/030] Train loss: 0.1172
2023-02-06 15:55:21 | Train | Epoch[051/200] Iteration[010/030] Train loss: 0.1173
2023-02-06 15:55:21 | Train | Epoch[051/200] Iteration[011/030] Train loss: 0.1171
2023-02-06 15:55:22 | Train | Epoch[051/200] Iteration[012/030] Train loss: 0.1172
2023-02-06 15:55:22 | Train | Epoch[051/200] Iteration[013/030] Train loss: 0.1171
2023-02-06 15:55:23 | Train | Epoch[051/200] Iteration[014/030] Train loss: 0.1170
2023-02-06 15:55:23 | Train | Epoch[051/200] Iteration[015/030] Train loss: 0.1169
2023-02-06 15:55:24 | Train | Epoch[051/200] Iteration[016/030] Train loss: 0.1170
2023-02-06 15:55:24 | Train | Epoch[051/200] Iteration[017/030] Train loss: 0.1170
2023-02-06 15:55:24 | Train | Epoch[051/200] Iteration[018/030] Train loss: 0.1169
2023-02-06 15:55:25 | Train | Epoch[051/200] Iteration[019/030] Train loss: 0.1170
2023-02-06 15:55:25 | Train | Epoch[051/200] Iteration[020/030] Train loss: 0.1169
2023-02-06 15:55:26 | Train | Epoch[051/200] Iteration[021/030] Train loss: 0.1169
2023-02-06 15:55:26 | Train | Epoch[051/200] Iteration[022/030] Train loss: 0.1169
2023-02-06 15:55:27 | Train | Epoch[051/200] Iteration[023/030] Train loss: 0.1167
2023-02-06 15:55:27 | Train | Epoch[051/200] Iteration[024/030] Train loss: 0.1166
2023-02-06 15:55:27 | Train | Epoch[051/200] Iteration[025/030] Train loss: 0.1165
2023-02-06 15:55:28 | Train | Epoch[051/200] Iteration[026/030] Train loss: 0.1164
2023-02-06 15:55:28 | Train | Epoch[051/200] Iteration[027/030] Train loss: 0.1162
2023-02-06 15:55:29 | Train | Epoch[051/200] Iteration[028/030] Train loss: 0.1161
2023-02-06 15:55:29 | Train | Epoch[051/200] Iteration[029/030] Train loss: 0.1162
2023-02-06 15:55:29 | Train | Epoch[051/200] Iteration[030/030] Train loss: 0.1161
2023-02-06 15:55:30 | Valid | Epoch[051/200] Iteration[001/008] Valid loss: 0.1433
2023-02-06 15:55:30 | Valid | Epoch[051/200] Iteration[002/008] Valid loss: 0.1389
2023-02-06 15:55:30 | Valid | Epoch[051/200] Iteration[003/008] Valid loss: 0.1399
2023-02-06 15:55:30 | Valid | Epoch[051/200] Iteration[004/008] Valid loss: 0.1385
2023-02-06 15:55:30 | Valid | Epoch[051/200] Iteration[005/008] Valid loss: 0.1393
2023-02-06 15:55:30 | Valid | Epoch[051/200] Iteration[006/008] Valid loss: 0.1394
2023-02-06 15:55:30 | Valid | Epoch[051/200] Iteration[007/008] Valid loss: 0.1391
2023-02-06 15:55:31 | Valid | Epoch[051/200] Iteration[008/008] Valid loss: 0.1394
2023-02-06 15:55:31 | Valid | Epoch[051/200] MIou: 0.8740107613392907
2023-02-06 15:55:31 | Valid | Epoch[051/200] Pixel Accuracy: 0.9787254333496094
2023-02-06 15:55:31 | Valid | Epoch[051/200] Mean Pixel Accuracy: 0.8949811906443201
2023-02-06 15:55:31 | Stage | Epoch[051/200] Train loss:0.1161
2023-02-06 15:55:31 | Stage | Epoch[051/200] Valid loss:0.1394
2023-02-06 15:55:31 | Stage | Epoch[051/200] LR:0.01

2023-02-06 15:55:31 | Train | Epoch[052/200] Iteration[001/030] Train loss: 0.1142
2023-02-06 15:55:32 | Train | Epoch[052/200] Iteration[002/030] Train loss: 0.1139
2023-02-06 15:55:32 | Train | Epoch[052/200] Iteration[003/030] Train loss: 0.1134
2023-02-06 15:55:33 | Train | Epoch[052/200] Iteration[004/030] Train loss: 0.1128
2023-02-06 15:55:33 | Train | Epoch[052/200] Iteration[005/030] Train loss: 0.1132
2023-02-06 15:55:34 | Train | Epoch[052/200] Iteration[006/030] Train loss: 0.1132
2023-02-06 15:55:34 | Train | Epoch[052/200] Iteration[007/030] Train loss: 0.1130
2023-02-06 15:55:34 | Train | Epoch[052/200] Iteration[008/030] Train loss: 0.1134
2023-02-06 15:55:35 | Train | Epoch[052/200] Iteration[009/030] Train loss: 0.1135
2023-02-06 15:55:35 | Train | Epoch[052/200] Iteration[010/030] Train loss: 0.1134
2023-02-06 15:55:36 | Train | Epoch[052/200] Iteration[011/030] Train loss: 0.1132
2023-02-06 15:55:36 | Train | Epoch[052/200] Iteration[012/030] Train loss: 0.1133
2023-02-06 15:55:37 | Train | Epoch[052/200] Iteration[013/030] Train loss: 0.1132
2023-02-06 15:55:37 | Train | Epoch[052/200] Iteration[014/030] Train loss: 0.1131
2023-02-06 15:55:38 | Train | Epoch[052/200] Iteration[015/030] Train loss: 0.1132
2023-02-06 15:55:38 | Train | Epoch[052/200] Iteration[016/030] Train loss: 0.1131
2023-02-06 15:55:38 | Train | Epoch[052/200] Iteration[017/030] Train loss: 0.1130
2023-02-06 15:55:39 | Train | Epoch[052/200] Iteration[018/030] Train loss: 0.1132
2023-02-06 15:55:39 | Train | Epoch[052/200] Iteration[019/030] Train loss: 0.1132
2023-02-06 15:55:40 | Train | Epoch[052/200] Iteration[020/030] Train loss: 0.1134
2023-02-06 15:55:40 | Train | Epoch[052/200] Iteration[021/030] Train loss: 0.1134
2023-02-06 15:55:41 | Train | Epoch[052/200] Iteration[022/030] Train loss: 0.1133
2023-02-06 15:55:41 | Train | Epoch[052/200] Iteration[023/030] Train loss: 0.1133
2023-02-06 15:55:41 | Train | Epoch[052/200] Iteration[024/030] Train loss: 0.1132
2023-02-06 15:55:42 | Train | Epoch[052/200] Iteration[025/030] Train loss: 0.1131
2023-02-06 15:55:42 | Train | Epoch[052/200] Iteration[026/030] Train loss: 0.1131
2023-02-06 15:55:43 | Train | Epoch[052/200] Iteration[027/030] Train loss: 0.1131
2023-02-06 15:55:43 | Train | Epoch[052/200] Iteration[028/030] Train loss: 0.1131
2023-02-06 15:55:44 | Train | Epoch[052/200] Iteration[029/030] Train loss: 0.1130
2023-02-06 15:55:44 | Train | Epoch[052/200] Iteration[030/030] Train loss: 0.1129
2023-02-06 15:55:44 | Valid | Epoch[052/200] Iteration[001/008] Valid loss: 0.5696
2023-02-06 15:55:44 | Valid | Epoch[052/200] Iteration[002/008] Valid loss: 0.5695
2023-02-06 15:55:44 | Valid | Epoch[052/200] Iteration[003/008] Valid loss: 0.5461
2023-02-06 15:55:44 | Valid | Epoch[052/200] Iteration[004/008] Valid loss: 0.5631
2023-02-06 15:55:45 | Valid | Epoch[052/200] Iteration[005/008] Valid loss: 0.5608
2023-02-06 15:55:45 | Valid | Epoch[052/200] Iteration[006/008] Valid loss: 0.5585
2023-02-06 15:55:45 | Valid | Epoch[052/200] Iteration[007/008] Valid loss: 0.5812
2023-02-06 15:55:45 | Valid | Epoch[052/200] Iteration[008/008] Valid loss: 0.5943
2023-02-06 15:55:45 | Valid | Epoch[052/200] MIou: 0.8459449834885251
2023-02-06 15:55:45 | Valid | Epoch[052/200] Pixel Accuracy: 0.9665845235188802
2023-02-06 15:55:45 | Valid | Epoch[052/200] Mean Pixel Accuracy: 0.9785836621930628
2023-02-06 15:55:45 | Stage | Epoch[052/200] Train loss:0.1129
2023-02-06 15:55:45 | Stage | Epoch[052/200] Valid loss:0.5943
2023-02-06 15:55:45 | Stage | Epoch[052/200] LR:0.01

2023-02-06 15:55:46 | Train | Epoch[053/200] Iteration[001/030] Train loss: 0.1102
2023-02-06 15:55:46 | Train | Epoch[053/200] Iteration[002/030] Train loss: 0.1103
2023-02-06 15:55:47 | Train | Epoch[053/200] Iteration[003/030] Train loss: 0.1102
2023-02-06 15:55:47 | Train | Epoch[053/200] Iteration[004/030] Train loss: 0.1105
2023-02-06 15:55:47 | Train | Epoch[053/200] Iteration[005/030] Train loss: 0.1112
2023-02-06 15:55:48 | Train | Epoch[053/200] Iteration[006/030] Train loss: 0.1113
2023-02-06 15:55:48 | Train | Epoch[053/200] Iteration[007/030] Train loss: 0.1116
2023-02-06 15:55:49 | Train | Epoch[053/200] Iteration[008/030] Train loss: 0.1114
2023-02-06 15:55:49 | Train | Epoch[053/200] Iteration[009/030] Train loss: 0.1112
2023-02-06 15:55:50 | Train | Epoch[053/200] Iteration[010/030] Train loss: 0.1111
2023-02-06 15:55:50 | Train | Epoch[053/200] Iteration[011/030] Train loss: 0.1109
2023-02-06 15:55:50 | Train | Epoch[053/200] Iteration[012/030] Train loss: 0.1109
2023-02-06 15:55:51 | Train | Epoch[053/200] Iteration[013/030] Train loss: 0.1107
2023-02-06 15:55:51 | Train | Epoch[053/200] Iteration[014/030] Train loss: 0.1106
2023-02-06 15:55:52 | Train | Epoch[053/200] Iteration[015/030] Train loss: 0.1106
2023-02-06 15:55:52 | Train | Epoch[053/200] Iteration[016/030] Train loss: 0.1105
2023-02-06 15:55:53 | Train | Epoch[053/200] Iteration[017/030] Train loss: 0.1105
2023-02-06 15:55:53 | Train | Epoch[053/200] Iteration[018/030] Train loss: 0.1104
2023-02-06 15:55:53 | Train | Epoch[053/200] Iteration[019/030] Train loss: 0.1103
2023-02-06 15:55:54 | Train | Epoch[053/200] Iteration[020/030] Train loss: 0.1102
2023-02-06 15:55:54 | Train | Epoch[053/200] Iteration[021/030] Train loss: 0.1101
2023-02-06 15:55:55 | Train | Epoch[053/200] Iteration[022/030] Train loss: 0.1102
2023-02-06 15:55:55 | Train | Epoch[053/200] Iteration[023/030] Train loss: 0.1101
2023-02-06 15:55:56 | Train | Epoch[053/200] Iteration[024/030] Train loss: 0.1099
2023-02-06 15:55:56 | Train | Epoch[053/200] Iteration[025/030] Train loss: 0.1099
2023-02-06 15:55:56 | Train | Epoch[053/200] Iteration[026/030] Train loss: 0.1098
2023-02-06 15:55:57 | Train | Epoch[053/200] Iteration[027/030] Train loss: 0.1099
2023-02-06 15:55:57 | Train | Epoch[053/200] Iteration[028/030] Train loss: 0.1099
2023-02-06 15:55:58 | Train | Epoch[053/200] Iteration[029/030] Train loss: 0.1098
2023-02-06 15:55:58 | Train | Epoch[053/200] Iteration[030/030] Train loss: 0.1098
2023-02-06 15:55:58 | Valid | Epoch[053/200] Iteration[001/008] Valid loss: 0.1364
2023-02-06 15:55:59 | Valid | Epoch[053/200] Iteration[002/008] Valid loss: 0.1352
2023-02-06 15:55:59 | Valid | Epoch[053/200] Iteration[003/008] Valid loss: 0.1360
2023-02-06 15:55:59 | Valid | Epoch[053/200] Iteration[004/008] Valid loss: 0.1351
2023-02-06 15:55:59 | Valid | Epoch[053/200] Iteration[005/008] Valid loss: 0.1358
2023-02-06 15:55:59 | Valid | Epoch[053/200] Iteration[006/008] Valid loss: 0.1363
2023-02-06 15:55:59 | Valid | Epoch[053/200] Iteration[007/008] Valid loss: 0.1362
2023-02-06 15:55:59 | Valid | Epoch[053/200] Iteration[008/008] Valid loss: 0.1365
2023-02-06 15:55:59 | Valid | Epoch[053/200] MIou: 0.8202640883726169
2023-02-06 15:55:59 | Valid | Epoch[053/200] Pixel Accuracy: 0.9702542622884115
2023-02-06 15:55:59 | Valid | Epoch[053/200] Mean Pixel Accuracy: 0.8374582222746567
2023-02-06 15:55:59 | Stage | Epoch[053/200] Train loss:0.1098
2023-02-06 15:55:59 | Stage | Epoch[053/200] Valid loss:0.1365
2023-02-06 15:55:59 | Stage | Epoch[053/200] LR:0.01

2023-02-06 15:56:00 | Train | Epoch[054/200] Iteration[001/030] Train loss: 0.1078
2023-02-06 15:56:00 | Train | Epoch[054/200] Iteration[002/030] Train loss: 0.1082
2023-02-06 15:56:01 | Train | Epoch[054/200] Iteration[003/030] Train loss: 0.1075
2023-02-06 15:56:01 | Train | Epoch[054/200] Iteration[004/030] Train loss: 0.1075
2023-02-06 15:56:02 | Train | Epoch[054/200] Iteration[005/030] Train loss: 0.1075
2023-02-06 15:56:02 | Train | Epoch[054/200] Iteration[006/030] Train loss: 0.1085
2023-02-06 15:56:02 | Train | Epoch[054/200] Iteration[007/030] Train loss: 0.1086
2023-02-06 15:56:03 | Train | Epoch[054/200] Iteration[008/030] Train loss: 0.1087
2023-02-06 15:56:03 | Train | Epoch[054/200] Iteration[009/030] Train loss: 0.1088
2023-02-06 15:56:04 | Train | Epoch[054/200] Iteration[010/030] Train loss: 0.1087
2023-02-06 15:56:04 | Train | Epoch[054/200] Iteration[011/030] Train loss: 0.1088
2023-02-06 15:56:05 | Train | Epoch[054/200] Iteration[012/030] Train loss: 0.1086
2023-02-06 15:56:05 | Train | Epoch[054/200] Iteration[013/030] Train loss: 0.1085
2023-02-06 15:56:06 | Train | Epoch[054/200] Iteration[014/030] Train loss: 0.1082
2023-02-06 15:56:06 | Train | Epoch[054/200] Iteration[015/030] Train loss: 0.1081
2023-02-06 15:56:06 | Train | Epoch[054/200] Iteration[016/030] Train loss: 0.1079
2023-02-06 15:56:07 | Train | Epoch[054/200] Iteration[017/030] Train loss: 0.1080
2023-02-06 15:56:07 | Train | Epoch[054/200] Iteration[018/030] Train loss: 0.1079
2023-02-06 15:56:08 | Train | Epoch[054/200] Iteration[019/030] Train loss: 0.1078
2023-02-06 15:56:08 | Train | Epoch[054/200] Iteration[020/030] Train loss: 0.1079
2023-02-06 15:56:09 | Train | Epoch[054/200] Iteration[021/030] Train loss: 0.1079
2023-02-06 15:56:09 | Train | Epoch[054/200] Iteration[022/030] Train loss: 0.1079
2023-02-06 15:56:09 | Train | Epoch[054/200] Iteration[023/030] Train loss: 0.1079
2023-02-06 15:56:10 | Train | Epoch[054/200] Iteration[024/030] Train loss: 0.1078
2023-02-06 15:56:10 | Train | Epoch[054/200] Iteration[025/030] Train loss: 0.1079
2023-02-06 15:56:11 | Train | Epoch[054/200] Iteration[026/030] Train loss: 0.1078
2023-02-06 15:56:11 | Train | Epoch[054/200] Iteration[027/030] Train loss: 0.1078
2023-02-06 15:56:12 | Train | Epoch[054/200] Iteration[028/030] Train loss: 0.1078
2023-02-06 15:56:12 | Train | Epoch[054/200] Iteration[029/030] Train loss: 0.1078
2023-02-06 15:56:12 | Train | Epoch[054/200] Iteration[030/030] Train loss: 0.1077
2023-02-06 15:56:13 | Valid | Epoch[054/200] Iteration[001/008] Valid loss: 0.2085
2023-02-06 15:56:13 | Valid | Epoch[054/200] Iteration[002/008] Valid loss: 0.1944
2023-02-06 15:56:13 | Valid | Epoch[054/200] Iteration[003/008] Valid loss: 0.1970
2023-02-06 15:56:13 | Valid | Epoch[054/200] Iteration[004/008] Valid loss: 0.1948
2023-02-06 15:56:13 | Valid | Epoch[054/200] Iteration[005/008] Valid loss: 0.1991
2023-02-06 15:56:13 | Valid | Epoch[054/200] Iteration[006/008] Valid loss: 0.1992
2023-02-06 15:56:13 | Valid | Epoch[054/200] Iteration[007/008] Valid loss: 0.2015
2023-02-06 15:56:13 | Valid | Epoch[054/200] Iteration[008/008] Valid loss: 0.2021
2023-02-06 15:56:13 | Valid | Epoch[054/200] MIou: 0.7783651036032384
2023-02-06 15:56:13 | Valid | Epoch[054/200] Pixel Accuracy: 0.9596468607584635
2023-02-06 15:56:13 | Valid | Epoch[054/200] Mean Pixel Accuracy: 0.8288825178343332
2023-02-06 15:56:13 | Stage | Epoch[054/200] Train loss:0.1077
2023-02-06 15:56:13 | Stage | Epoch[054/200] Valid loss:0.2021
2023-02-06 15:56:13 | Stage | Epoch[054/200] LR:0.01

2023-02-06 15:56:14 | Train | Epoch[055/200] Iteration[001/030] Train loss: 0.1068
2023-02-06 15:56:15 | Train | Epoch[055/200] Iteration[002/030] Train loss: 0.1065
2023-02-06 15:56:15 | Train | Epoch[055/200] Iteration[003/030] Train loss: 0.1058
2023-02-06 15:56:15 | Train | Epoch[055/200] Iteration[004/030] Train loss: 0.1053
2023-02-06 15:56:16 | Train | Epoch[055/200] Iteration[005/030] Train loss: 0.1051
2023-02-06 15:56:16 | Train | Epoch[055/200] Iteration[006/030] Train loss: 0.1053
2023-02-06 15:56:17 | Train | Epoch[055/200] Iteration[007/030] Train loss: 0.1053
2023-02-06 15:56:17 | Train | Epoch[055/200] Iteration[008/030] Train loss: 0.1055
2023-02-06 15:56:18 | Train | Epoch[055/200] Iteration[009/030] Train loss: 0.1055
2023-02-06 15:56:18 | Train | Epoch[055/200] Iteration[010/030] Train loss: 0.1058
2023-02-06 15:56:18 | Train | Epoch[055/200] Iteration[011/030] Train loss: 0.1060
2023-02-06 15:56:19 | Train | Epoch[055/200] Iteration[012/030] Train loss: 0.1059
2023-02-06 15:56:19 | Train | Epoch[055/200] Iteration[013/030] Train loss: 0.1057
2023-02-06 15:56:20 | Train | Epoch[055/200] Iteration[014/030] Train loss: 0.1058
2023-02-06 15:56:20 | Train | Epoch[055/200] Iteration[015/030] Train loss: 0.1057
2023-02-06 15:56:21 | Train | Epoch[055/200] Iteration[016/030] Train loss: 0.1058
2023-02-06 15:56:21 | Train | Epoch[055/200] Iteration[017/030] Train loss: 0.1058
2023-02-06 15:56:21 | Train | Epoch[055/200] Iteration[018/030] Train loss: 0.1057
2023-02-06 15:56:22 | Train | Epoch[055/200] Iteration[019/030] Train loss: 0.1056
2023-02-06 15:56:22 | Train | Epoch[055/200] Iteration[020/030] Train loss: 0.1056
2023-02-06 15:56:23 | Train | Epoch[055/200] Iteration[021/030] Train loss: 0.1055
2023-02-06 15:56:23 | Train | Epoch[055/200] Iteration[022/030] Train loss: 0.1055
2023-02-06 15:56:24 | Train | Epoch[055/200] Iteration[023/030] Train loss: 0.1055
2023-02-06 15:56:24 | Train | Epoch[055/200] Iteration[024/030] Train loss: 0.1054
2023-02-06 15:56:25 | Train | Epoch[055/200] Iteration[025/030] Train loss: 0.1055
2023-02-06 15:56:25 | Train | Epoch[055/200] Iteration[026/030] Train loss: 0.1054
2023-02-06 15:56:25 | Train | Epoch[055/200] Iteration[027/030] Train loss: 0.1053
2023-02-06 15:56:26 | Train | Epoch[055/200] Iteration[028/030] Train loss: 0.1052
2023-02-06 15:56:26 | Train | Epoch[055/200] Iteration[029/030] Train loss: 0.1052
2023-02-06 15:56:26 | Train | Epoch[055/200] Iteration[030/030] Train loss: 0.1051
2023-02-06 15:56:27 | Valid | Epoch[055/200] Iteration[001/008] Valid loss: 0.1516
2023-02-06 15:56:27 | Valid | Epoch[055/200] Iteration[002/008] Valid loss: 0.1392
2023-02-06 15:56:27 | Valid | Epoch[055/200] Iteration[003/008] Valid loss: 0.1354
2023-02-06 15:56:27 | Valid | Epoch[055/200] Iteration[004/008] Valid loss: 0.1336
2023-02-06 15:56:27 | Valid | Epoch[055/200] Iteration[005/008] Valid loss: 0.1341
2023-02-06 15:56:27 | Valid | Epoch[055/200] Iteration[006/008] Valid loss: 0.1343
2023-02-06 15:56:27 | Valid | Epoch[055/200] Iteration[007/008] Valid loss: 0.1363
2023-02-06 15:56:28 | Valid | Epoch[055/200] Iteration[008/008] Valid loss: 0.1356
2023-02-06 15:56:28 | Valid | Epoch[055/200] MIou: 0.9349164159223591
2023-02-06 15:56:28 | Valid | Epoch[055/200] Pixel Accuracy: 0.9885711669921875
2023-02-06 15:56:28 | Valid | Epoch[055/200] Mean Pixel Accuracy: 0.9706896334190936
2023-02-06 15:56:28 | Stage | Epoch[055/200] Train loss:0.1051
2023-02-06 15:56:28 | Stage | Epoch[055/200] Valid loss:0.1356
2023-02-06 15:56:28 | Stage | Epoch[055/200] LR:0.01

2023-02-06 15:56:28 | Train | Epoch[056/200] Iteration[001/030] Train loss: 0.1037
2023-02-06 15:56:29 | Train | Epoch[056/200] Iteration[002/030] Train loss: 0.1029
2023-02-06 15:56:29 | Train | Epoch[056/200] Iteration[003/030] Train loss: 0.1025
2023-02-06 15:56:30 | Train | Epoch[056/200] Iteration[004/030] Train loss: 0.1026
2023-02-06 15:56:30 | Train | Epoch[056/200] Iteration[005/030] Train loss: 0.1027
2023-02-06 15:56:31 | Train | Epoch[056/200] Iteration[006/030] Train loss: 0.1024
2023-02-06 15:56:31 | Train | Epoch[056/200] Iteration[007/030] Train loss: 0.1023
2023-02-06 15:56:31 | Train | Epoch[056/200] Iteration[008/030] Train loss: 0.1023
2023-02-06 15:56:32 | Train | Epoch[056/200] Iteration[009/030] Train loss: 0.1023
2023-02-06 15:56:32 | Train | Epoch[056/200] Iteration[010/030] Train loss: 0.1022
2023-02-06 15:56:33 | Train | Epoch[056/200] Iteration[011/030] Train loss: 0.1023
2023-02-06 15:56:33 | Train | Epoch[056/200] Iteration[012/030] Train loss: 0.1026
2023-02-06 15:56:34 | Train | Epoch[056/200] Iteration[013/030] Train loss: 0.1027
2023-02-06 15:56:34 | Train | Epoch[056/200] Iteration[014/030] Train loss: 0.1026
2023-02-06 15:56:34 | Train | Epoch[056/200] Iteration[015/030] Train loss: 0.1025
2023-02-06 15:56:35 | Train | Epoch[056/200] Iteration[016/030] Train loss: 0.1025
2023-02-06 15:56:35 | Train | Epoch[056/200] Iteration[017/030] Train loss: 0.1024
2023-02-06 15:56:36 | Train | Epoch[056/200] Iteration[018/030] Train loss: 0.1024
2023-02-06 15:56:36 | Train | Epoch[056/200] Iteration[019/030] Train loss: 0.1024
2023-02-06 15:56:37 | Train | Epoch[056/200] Iteration[020/030] Train loss: 0.1023
2023-02-06 15:56:37 | Train | Epoch[056/200] Iteration[021/030] Train loss: 0.1021
2023-02-06 15:56:37 | Train | Epoch[056/200] Iteration[022/030] Train loss: 0.1021
2023-02-06 15:56:38 | Train | Epoch[056/200] Iteration[023/030] Train loss: 0.1024
2023-02-06 15:56:38 | Train | Epoch[056/200] Iteration[024/030] Train loss: 0.1023
2023-02-06 15:56:39 | Train | Epoch[056/200] Iteration[025/030] Train loss: 0.1022
2023-02-06 15:56:39 | Train | Epoch[056/200] Iteration[026/030] Train loss: 0.1022
2023-02-06 15:56:40 | Train | Epoch[056/200] Iteration[027/030] Train loss: 0.1022
2023-02-06 15:56:40 | Train | Epoch[056/200] Iteration[028/030] Train loss: 0.1023
2023-02-06 15:56:40 | Train | Epoch[056/200] Iteration[029/030] Train loss: 0.1023
2023-02-06 15:56:41 | Train | Epoch[056/200] Iteration[030/030] Train loss: 0.1023
2023-02-06 15:56:41 | Valid | Epoch[056/200] Iteration[001/008] Valid loss: 1.3038
2023-02-06 15:56:41 | Valid | Epoch[056/200] Iteration[002/008] Valid loss: 1.2643
2023-02-06 15:56:41 | Valid | Epoch[056/200] Iteration[003/008] Valid loss: 1.3183
2023-02-06 15:56:41 | Valid | Epoch[056/200] Iteration[004/008] Valid loss: 1.3240
2023-02-06 15:56:42 | Valid | Epoch[056/200] Iteration[005/008] Valid loss: 1.3334
2023-02-06 15:56:42 | Valid | Epoch[056/200] Iteration[006/008] Valid loss: 1.2961
2023-02-06 15:56:42 | Valid | Epoch[056/200] Iteration[007/008] Valid loss: 1.3141
2023-02-06 15:56:42 | Valid | Epoch[056/200] Iteration[008/008] Valid loss: 1.3408
2023-02-06 15:56:42 | Valid | Epoch[056/200] MIou: 0.5557019196325698
2023-02-06 15:56:42 | Valid | Epoch[056/200] Pixel Accuracy: 0.8092244466145834
2023-02-06 15:56:42 | Valid | Epoch[056/200] Mean Pixel Accuracy: 0.8947104674159898
2023-02-06 15:56:42 | Stage | Epoch[056/200] Train loss:0.1023
2023-02-06 15:56:42 | Stage | Epoch[056/200] Valid loss:1.3408
2023-02-06 15:56:42 | Stage | Epoch[056/200] LR:0.01

2023-02-06 15:56:43 | Train | Epoch[057/200] Iteration[001/030] Train loss: 0.1029
2023-02-06 15:56:43 | Train | Epoch[057/200] Iteration[002/030] Train loss: 0.1010
2023-02-06 15:56:44 | Train | Epoch[057/200] Iteration[003/030] Train loss: 0.1009
2023-02-06 15:56:44 | Train | Epoch[057/200] Iteration[004/030] Train loss: 0.1009
2023-02-06 15:56:45 | Train | Epoch[057/200] Iteration[005/030] Train loss: 0.1017
2023-02-06 15:56:45 | Train | Epoch[057/200] Iteration[006/030] Train loss: 0.1013
2023-02-06 15:56:45 | Train | Epoch[057/200] Iteration[007/030] Train loss: 0.1010
2023-02-06 15:56:46 | Train | Epoch[057/200] Iteration[008/030] Train loss: 0.1013
2023-02-06 15:56:46 | Train | Epoch[057/200] Iteration[009/030] Train loss: 0.1010
2023-02-06 15:56:47 | Train | Epoch[057/200] Iteration[010/030] Train loss: 0.1009
2023-02-06 15:56:47 | Train | Epoch[057/200] Iteration[011/030] Train loss: 0.1009
2023-02-06 15:56:48 | Train | Epoch[057/200] Iteration[012/030] Train loss: 0.1008
2023-02-06 15:56:48 | Train | Epoch[057/200] Iteration[013/030] Train loss: 0.1007
2023-02-06 15:56:48 | Train | Epoch[057/200] Iteration[014/030] Train loss: 0.1006
2023-02-06 15:56:49 | Train | Epoch[057/200] Iteration[015/030] Train loss: 0.1006
2023-02-06 15:56:49 | Train | Epoch[057/200] Iteration[016/030] Train loss: 0.1006
2023-02-06 15:56:50 | Train | Epoch[057/200] Iteration[017/030] Train loss: 0.1005
2023-02-06 15:56:50 | Train | Epoch[057/200] Iteration[018/030] Train loss: 0.1004
2023-02-06 15:56:51 | Train | Epoch[057/200] Iteration[019/030] Train loss: 0.1003
2023-02-06 15:56:51 | Train | Epoch[057/200] Iteration[020/030] Train loss: 0.1003
2023-02-06 15:56:51 | Train | Epoch[057/200] Iteration[021/030] Train loss: 0.1002
2023-02-06 15:56:52 | Train | Epoch[057/200] Iteration[022/030] Train loss: 0.1001
2023-02-06 15:56:52 | Train | Epoch[057/200] Iteration[023/030] Train loss: 0.1001
2023-02-06 15:56:53 | Train | Epoch[057/200] Iteration[024/030] Train loss: 0.1000
2023-02-06 15:56:53 | Train | Epoch[057/200] Iteration[025/030] Train loss: 0.1000
2023-02-06 15:56:54 | Train | Epoch[057/200] Iteration[026/030] Train loss: 0.1001
2023-02-06 15:56:54 | Train | Epoch[057/200] Iteration[027/030] Train loss: 0.1000
2023-02-06 15:56:54 | Train | Epoch[057/200] Iteration[028/030] Train loss: 0.1001
2023-02-06 15:56:55 | Train | Epoch[057/200] Iteration[029/030] Train loss: 0.1001
2023-02-06 15:56:55 | Train | Epoch[057/200] Iteration[030/030] Train loss: 0.1001
2023-02-06 15:56:56 | Valid | Epoch[057/200] Iteration[001/008] Valid loss: 0.1428
2023-02-06 15:56:56 | Valid | Epoch[057/200] Iteration[002/008] Valid loss: 0.1394
2023-02-06 15:56:56 | Valid | Epoch[057/200] Iteration[003/008] Valid loss: 0.1430
2023-02-06 15:56:56 | Valid | Epoch[057/200] Iteration[004/008] Valid loss: 0.1426
2023-02-06 15:56:56 | Valid | Epoch[057/200] Iteration[005/008] Valid loss: 0.1450
2023-02-06 15:56:56 | Valid | Epoch[057/200] Iteration[006/008] Valid loss: 0.1444
2023-02-06 15:56:56 | Valid | Epoch[057/200] Iteration[007/008] Valid loss: 0.1437
2023-02-06 15:56:56 | Valid | Epoch[057/200] Iteration[008/008] Valid loss: 0.1452
2023-02-06 15:56:56 | Valid | Epoch[057/200] MIou: 0.7155012527480338
2023-02-06 15:56:56 | Valid | Epoch[057/200] Pixel Accuracy: 0.952569325764974
2023-02-06 15:56:56 | Valid | Epoch[057/200] Mean Pixel Accuracy: 0.7424204422505292
2023-02-06 15:56:56 | Stage | Epoch[057/200] Train loss:0.1001
2023-02-06 15:56:56 | Stage | Epoch[057/200] Valid loss:0.1452
2023-02-06 15:56:56 | Stage | Epoch[057/200] LR:0.01

2023-02-06 15:56:57 | Train | Epoch[058/200] Iteration[001/030] Train loss: 0.0995
2023-02-06 15:56:57 | Train | Epoch[058/200] Iteration[002/030] Train loss: 0.0996
2023-02-06 15:56:58 | Train | Epoch[058/200] Iteration[003/030] Train loss: 0.0983
2023-02-06 15:56:58 | Train | Epoch[058/200] Iteration[004/030] Train loss: 0.0982
2023-02-06 15:56:59 | Train | Epoch[058/200] Iteration[005/030] Train loss: 0.0978
2023-02-06 15:56:59 | Train | Epoch[058/200] Iteration[006/030] Train loss: 0.0975
2023-02-06 15:57:00 | Train | Epoch[058/200] Iteration[007/030] Train loss: 0.0975
2023-02-06 15:57:00 | Train | Epoch[058/200] Iteration[008/030] Train loss: 0.0979
2023-02-06 15:57:00 | Train | Epoch[058/200] Iteration[009/030] Train loss: 0.0980
2023-02-06 15:57:01 | Train | Epoch[058/200] Iteration[010/030] Train loss: 0.0977
2023-02-06 15:57:01 | Train | Epoch[058/200] Iteration[011/030] Train loss: 0.0979
2023-02-06 15:57:02 | Train | Epoch[058/200] Iteration[012/030] Train loss: 0.0978
2023-02-06 15:57:02 | Train | Epoch[058/200] Iteration[013/030] Train loss: 0.0980
2023-02-06 15:57:03 | Train | Epoch[058/200] Iteration[014/030] Train loss: 0.0980
2023-02-06 15:57:03 | Train | Epoch[058/200] Iteration[015/030] Train loss: 0.0980
2023-02-06 15:57:03 | Train | Epoch[058/200] Iteration[016/030] Train loss: 0.0979
2023-02-06 15:57:04 | Train | Epoch[058/200] Iteration[017/030] Train loss: 0.0978
2023-02-06 15:57:04 | Train | Epoch[058/200] Iteration[018/030] Train loss: 0.0978
2023-02-06 15:57:05 | Train | Epoch[058/200] Iteration[019/030] Train loss: 0.0977
2023-02-06 15:57:05 | Train | Epoch[058/200] Iteration[020/030] Train loss: 0.0977
2023-02-06 15:57:06 | Train | Epoch[058/200] Iteration[021/030] Train loss: 0.0976
2023-02-06 15:57:06 | Train | Epoch[058/200] Iteration[022/030] Train loss: 0.0975
2023-02-06 15:57:07 | Train | Epoch[058/200] Iteration[023/030] Train loss: 0.0974
2023-02-06 15:57:07 | Train | Epoch[058/200] Iteration[024/030] Train loss: 0.0974
2023-02-06 15:57:07 | Train | Epoch[058/200] Iteration[025/030] Train loss: 0.0974
2023-02-06 15:57:08 | Train | Epoch[058/200] Iteration[026/030] Train loss: 0.0974
2023-02-06 15:57:08 | Train | Epoch[058/200] Iteration[027/030] Train loss: 0.0973
2023-02-06 15:57:09 | Train | Epoch[058/200] Iteration[028/030] Train loss: 0.0973
2023-02-06 15:57:09 | Train | Epoch[058/200] Iteration[029/030] Train loss: 0.0973
2023-02-06 15:57:09 | Train | Epoch[058/200] Iteration[030/030] Train loss: 0.0973
2023-02-06 15:57:10 | Valid | Epoch[058/200] Iteration[001/008] Valid loss: 0.1590
2023-02-06 15:57:10 | Valid | Epoch[058/200] Iteration[002/008] Valid loss: 0.1505
2023-02-06 15:57:10 | Valid | Epoch[058/200] Iteration[003/008] Valid loss: 0.1520
2023-02-06 15:57:10 | Valid | Epoch[058/200] Iteration[004/008] Valid loss: 0.1501
2023-02-06 15:57:10 | Valid | Epoch[058/200] Iteration[005/008] Valid loss: 0.1513
2023-02-06 15:57:10 | Valid | Epoch[058/200] Iteration[006/008] Valid loss: 0.1514
2023-02-06 15:57:10 | Valid | Epoch[058/200] Iteration[007/008] Valid loss: 0.1511
2023-02-06 15:57:10 | Valid | Epoch[058/200] Iteration[008/008] Valid loss: 0.1525
2023-02-06 15:57:10 | Valid | Epoch[058/200] MIou: 0.8019684209076804
2023-02-06 15:57:10 | Valid | Epoch[058/200] Pixel Accuracy: 0.9655596415201823
2023-02-06 15:57:10 | Valid | Epoch[058/200] Mean Pixel Accuracy: 0.8368497451199616
2023-02-06 15:57:10 | Stage | Epoch[058/200] Train loss:0.0973
2023-02-06 15:57:10 | Stage | Epoch[058/200] Valid loss:0.1525
2023-02-06 15:57:10 | Stage | Epoch[058/200] LR:0.01

2023-02-06 15:57:11 | Train | Epoch[059/200] Iteration[001/030] Train loss: 0.0947
2023-02-06 15:57:12 | Train | Epoch[059/200] Iteration[002/030] Train loss: 0.0951
2023-02-06 15:57:12 | Train | Epoch[059/200] Iteration[003/030] Train loss: 0.0953
2023-02-06 15:57:13 | Train | Epoch[059/200] Iteration[004/030] Train loss: 0.0951
2023-02-06 15:57:13 | Train | Epoch[059/200] Iteration[005/030] Train loss: 0.0949
2023-02-06 15:57:13 | Train | Epoch[059/200] Iteration[006/030] Train loss: 0.0951
2023-02-06 15:57:14 | Train | Epoch[059/200] Iteration[007/030] Train loss: 0.0950
2023-02-06 15:57:14 | Train | Epoch[059/200] Iteration[008/030] Train loss: 0.0957
2023-02-06 15:57:15 | Train | Epoch[059/200] Iteration[009/030] Train loss: 0.0957
2023-02-06 15:57:15 | Train | Epoch[059/200] Iteration[010/030] Train loss: 0.0955
2023-02-06 15:57:16 | Train | Epoch[059/200] Iteration[011/030] Train loss: 0.0953
2023-02-06 15:57:16 | Train | Epoch[059/200] Iteration[012/030] Train loss: 0.0950
2023-02-06 15:57:16 | Train | Epoch[059/200] Iteration[013/030] Train loss: 0.0950
2023-02-06 15:57:17 | Train | Epoch[059/200] Iteration[014/030] Train loss: 0.0951
2023-02-06 15:57:17 | Train | Epoch[059/200] Iteration[015/030] Train loss: 0.0949
2023-02-06 15:57:18 | Train | Epoch[059/200] Iteration[016/030] Train loss: 0.0949
2023-02-06 15:57:18 | Train | Epoch[059/200] Iteration[017/030] Train loss: 0.0950
2023-02-06 15:57:19 | Train | Epoch[059/200] Iteration[018/030] Train loss: 0.0952
2023-02-06 15:57:19 | Train | Epoch[059/200] Iteration[019/030] Train loss: 0.0951
2023-02-06 15:57:19 | Train | Epoch[059/200] Iteration[020/030] Train loss: 0.0950
2023-02-06 15:57:20 | Train | Epoch[059/200] Iteration[021/030] Train loss: 0.0950
2023-02-06 15:57:20 | Train | Epoch[059/200] Iteration[022/030] Train loss: 0.0950
2023-02-06 15:57:21 | Train | Epoch[059/200] Iteration[023/030] Train loss: 0.0950
2023-02-06 15:57:21 | Train | Epoch[059/200] Iteration[024/030] Train loss: 0.0949
2023-02-06 15:57:22 | Train | Epoch[059/200] Iteration[025/030] Train loss: 0.0949
2023-02-06 15:57:22 | Train | Epoch[059/200] Iteration[026/030] Train loss: 0.0949
2023-02-06 15:57:22 | Train | Epoch[059/200] Iteration[027/030] Train loss: 0.0949
2023-02-06 15:57:23 | Train | Epoch[059/200] Iteration[028/030] Train loss: 0.0948
2023-02-06 15:57:23 | Train | Epoch[059/200] Iteration[029/030] Train loss: 0.0949
2023-02-06 15:57:24 | Train | Epoch[059/200] Iteration[030/030] Train loss: 0.0949
2023-02-06 15:57:24 | Valid | Epoch[059/200] Iteration[001/008] Valid loss: 0.1315
2023-02-06 15:57:24 | Valid | Epoch[059/200] Iteration[002/008] Valid loss: 0.1278
2023-02-06 15:57:24 | Valid | Epoch[059/200] Iteration[003/008] Valid loss: 0.1258
2023-02-06 15:57:24 | Valid | Epoch[059/200] Iteration[004/008] Valid loss: 0.1256
2023-02-06 15:57:24 | Valid | Epoch[059/200] Iteration[005/008] Valid loss: 0.1254
2023-02-06 15:57:24 | Valid | Epoch[059/200] Iteration[006/008] Valid loss: 0.1276
2023-02-06 15:57:25 | Valid | Epoch[059/200] Iteration[007/008] Valid loss: 0.1297
2023-02-06 15:57:25 | Valid | Epoch[059/200] Iteration[008/008] Valid loss: 0.1293
2023-02-06 15:57:25 | Valid | Epoch[059/200] MIou: 0.9047228779609087
2023-02-06 15:57:25 | Valid | Epoch[059/200] Pixel Accuracy: 0.9833704630533854
2023-02-06 15:57:25 | Valid | Epoch[059/200] Mean Pixel Accuracy: 0.9383288907839623
2023-02-06 15:57:25 | Stage | Epoch[059/200] Train loss:0.0949
2023-02-06 15:57:25 | Stage | Epoch[059/200] Valid loss:0.1293
2023-02-06 15:57:25 | Stage | Epoch[059/200] LR:0.01

2023-02-06 15:57:25 | Train | Epoch[060/200] Iteration[001/030] Train loss: 0.0944
2023-02-06 15:57:26 | Train | Epoch[060/200] Iteration[002/030] Train loss: 0.0934
2023-02-06 15:57:26 | Train | Epoch[060/200] Iteration[003/030] Train loss: 0.0929
2023-02-06 15:57:27 | Train | Epoch[060/200] Iteration[004/030] Train loss: 0.0931
2023-02-06 15:57:27 | Train | Epoch[060/200] Iteration[005/030] Train loss: 0.0930
2023-02-06 15:57:28 | Train | Epoch[060/200] Iteration[006/030] Train loss: 0.0931
2023-02-06 15:57:28 | Train | Epoch[060/200] Iteration[007/030] Train loss: 0.0929
2023-02-06 15:57:29 | Train | Epoch[060/200] Iteration[008/030] Train loss: 0.0929
2023-02-06 15:57:29 | Train | Epoch[060/200] Iteration[009/030] Train loss: 0.0928
2023-02-06 15:57:29 | Train | Epoch[060/200] Iteration[010/030] Train loss: 0.0928
2023-02-06 15:57:30 | Train | Epoch[060/200] Iteration[011/030] Train loss: 0.0926
2023-02-06 15:57:30 | Train | Epoch[060/200] Iteration[012/030] Train loss: 0.0925
2023-02-06 15:57:31 | Train | Epoch[060/200] Iteration[013/030] Train loss: 0.0925
2023-02-06 15:57:31 | Train | Epoch[060/200] Iteration[014/030] Train loss: 0.0924
2023-02-06 15:57:32 | Train | Epoch[060/200] Iteration[015/030] Train loss: 0.0923
2023-02-06 15:57:32 | Train | Epoch[060/200] Iteration[016/030] Train loss: 0.0925
2023-02-06 15:57:32 | Train | Epoch[060/200] Iteration[017/030] Train loss: 0.0923
2023-02-06 15:57:33 | Train | Epoch[060/200] Iteration[018/030] Train loss: 0.0924
2023-02-06 15:57:33 | Train | Epoch[060/200] Iteration[019/030] Train loss: 0.0925
2023-02-06 15:57:34 | Train | Epoch[060/200] Iteration[020/030] Train loss: 0.0924
2023-02-06 15:57:34 | Train | Epoch[060/200] Iteration[021/030] Train loss: 0.0926
2023-02-06 15:57:35 | Train | Epoch[060/200] Iteration[022/030] Train loss: 0.0925
2023-02-06 15:57:35 | Train | Epoch[060/200] Iteration[023/030] Train loss: 0.0926
2023-02-06 15:57:35 | Train | Epoch[060/200] Iteration[024/030] Train loss: 0.0927
2023-02-06 15:57:36 | Train | Epoch[060/200] Iteration[025/030] Train loss: 0.0927
2023-02-06 15:57:36 | Train | Epoch[060/200] Iteration[026/030] Train loss: 0.0926
2023-02-06 15:57:37 | Train | Epoch[060/200] Iteration[027/030] Train loss: 0.0926
2023-02-06 15:57:37 | Train | Epoch[060/200] Iteration[028/030] Train loss: 0.0926
2023-02-06 15:57:38 | Train | Epoch[060/200] Iteration[029/030] Train loss: 0.0927
2023-02-06 15:57:38 | Train | Epoch[060/200] Iteration[030/030] Train loss: 0.0926
2023-02-06 15:57:38 | Valid | Epoch[060/200] Iteration[001/008] Valid loss: 0.1189
2023-02-06 15:57:38 | Valid | Epoch[060/200] Iteration[002/008] Valid loss: 0.1144
2023-02-06 15:57:38 | Valid | Epoch[060/200] Iteration[003/008] Valid loss: 0.1149
2023-02-06 15:57:39 | Valid | Epoch[060/200] Iteration[004/008] Valid loss: 0.1138
2023-02-06 15:57:39 | Valid | Epoch[060/200] Iteration[005/008] Valid loss: 0.1143
2023-02-06 15:57:39 | Valid | Epoch[060/200] Iteration[006/008] Valid loss: 0.1142
2023-02-06 15:57:39 | Valid | Epoch[060/200] Iteration[007/008] Valid loss: 0.1137
2023-02-06 15:57:39 | Valid | Epoch[060/200] Iteration[008/008] Valid loss: 0.1138
2023-02-06 15:57:39 | Valid | Epoch[060/200] MIou: 0.8678509503659946
2023-02-06 15:57:39 | Valid | Epoch[060/200] Pixel Accuracy: 0.9781341552734375
2023-02-06 15:57:39 | Valid | Epoch[060/200] Mean Pixel Accuracy: 0.8813538897639126
2023-02-06 15:57:39 | Stage | Epoch[060/200] Train loss:0.0926
2023-02-06 15:57:39 | Stage | Epoch[060/200] Valid loss:0.1138
2023-02-06 15:57:39 | Stage | Epoch[060/200] LR:0.01

2023-02-06 15:57:40 | Train | Epoch[061/200] Iteration[001/030] Train loss: 0.0895
2023-02-06 15:57:40 | Train | Epoch[061/200] Iteration[002/030] Train loss: 0.0900
2023-02-06 15:57:41 | Train | Epoch[061/200] Iteration[003/030] Train loss: 0.0903
2023-02-06 15:57:41 | Train | Epoch[061/200] Iteration[004/030] Train loss: 0.0905
2023-02-06 15:57:41 | Train | Epoch[061/200] Iteration[005/030] Train loss: 0.0906
2023-02-06 15:57:42 | Train | Epoch[061/200] Iteration[006/030] Train loss: 0.0909
2023-02-06 15:57:42 | Train | Epoch[061/200] Iteration[007/030] Train loss: 0.0908
2023-02-06 15:57:43 | Train | Epoch[061/200] Iteration[008/030] Train loss: 0.0906
2023-02-06 15:57:43 | Train | Epoch[061/200] Iteration[009/030] Train loss: 0.0907
2023-02-06 15:57:44 | Train | Epoch[061/200] Iteration[010/030] Train loss: 0.0910
2023-02-06 15:57:44 | Train | Epoch[061/200] Iteration[011/030] Train loss: 0.0908
2023-02-06 15:57:45 | Train | Epoch[061/200] Iteration[012/030] Train loss: 0.0909
2023-02-06 15:57:45 | Train | Epoch[061/200] Iteration[013/030] Train loss: 0.0908
2023-02-06 15:57:45 | Train | Epoch[061/200] Iteration[014/030] Train loss: 0.0908
2023-02-06 15:57:46 | Train | Epoch[061/200] Iteration[015/030] Train loss: 0.0907
2023-02-06 15:57:46 | Train | Epoch[061/200] Iteration[016/030] Train loss: 0.0906
2023-02-06 15:57:47 | Train | Epoch[061/200] Iteration[017/030] Train loss: 0.0906
2023-02-06 15:57:47 | Train | Epoch[061/200] Iteration[018/030] Train loss: 0.0906
2023-02-06 15:57:48 | Train | Epoch[061/200] Iteration[019/030] Train loss: 0.0906
2023-02-06 15:57:48 | Train | Epoch[061/200] Iteration[020/030] Train loss: 0.0907
2023-02-06 15:57:48 | Train | Epoch[061/200] Iteration[021/030] Train loss: 0.0907
2023-02-06 15:57:49 | Train | Epoch[061/200] Iteration[022/030] Train loss: 0.0907
2023-02-06 15:57:49 | Train | Epoch[061/200] Iteration[023/030] Train loss: 0.0906
2023-02-06 15:57:50 | Train | Epoch[061/200] Iteration[024/030] Train loss: 0.0905
2023-02-06 15:57:50 | Train | Epoch[061/200] Iteration[025/030] Train loss: 0.0905
2023-02-06 15:57:51 | Train | Epoch[061/200] Iteration[026/030] Train loss: 0.0904
2023-02-06 15:57:51 | Train | Epoch[061/200] Iteration[027/030] Train loss: 0.0904
2023-02-06 15:57:51 | Train | Epoch[061/200] Iteration[028/030] Train loss: 0.0903
2023-02-06 15:57:52 | Train | Epoch[061/200] Iteration[029/030] Train loss: 0.0902
2023-02-06 15:57:52 | Train | Epoch[061/200] Iteration[030/030] Train loss: 0.0901
2023-02-06 15:57:53 | Valid | Epoch[061/200] Iteration[001/008] Valid loss: 0.5243
2023-02-06 15:57:53 | Valid | Epoch[061/200] Iteration[002/008] Valid loss: 0.4836
2023-02-06 15:57:53 | Valid | Epoch[061/200] Iteration[003/008] Valid loss: 0.4865
2023-02-06 15:57:53 | Valid | Epoch[061/200] Iteration[004/008] Valid loss: 0.4870
2023-02-06 15:57:53 | Valid | Epoch[061/200] Iteration[005/008] Valid loss: 0.5003
2023-02-06 15:57:53 | Valid | Epoch[061/200] Iteration[006/008] Valid loss: 0.4906
2023-02-06 15:57:53 | Valid | Epoch[061/200] Iteration[007/008] Valid loss: 0.5164
2023-02-06 15:57:53 | Valid | Epoch[061/200] Iteration[008/008] Valid loss: 0.5294
2023-02-06 15:57:53 | Valid | Epoch[061/200] MIou: 0.8472677074028385
2023-02-06 15:57:53 | Valid | Epoch[061/200] Pixel Accuracy: 0.9669710795084635
2023-02-06 15:57:53 | Valid | Epoch[061/200] Mean Pixel Accuracy: 0.9786249371203259
2023-02-06 15:57:53 | Stage | Epoch[061/200] Train loss:0.0901
2023-02-06 15:57:53 | Stage | Epoch[061/200] Valid loss:0.5294
2023-02-06 15:57:53 | Stage | Epoch[061/200] LR:0.01

2023-02-06 15:57:54 | Train | Epoch[062/200] Iteration[001/030] Train loss: 0.0889
2023-02-06 15:57:55 | Train | Epoch[062/200] Iteration[002/030] Train loss: 0.0881
2023-02-06 15:57:55 | Train | Epoch[062/200] Iteration[003/030] Train loss: 0.0880
2023-02-06 15:57:55 | Train | Epoch[062/200] Iteration[004/030] Train loss: 0.0881
2023-02-06 15:57:56 | Train | Epoch[062/200] Iteration[005/030] Train loss: 0.0881
2023-02-06 15:57:56 | Train | Epoch[062/200] Iteration[006/030] Train loss: 0.0880
2023-02-06 15:57:57 | Train | Epoch[062/200] Iteration[007/030] Train loss: 0.0878
2023-02-06 15:57:57 | Train | Epoch[062/200] Iteration[008/030] Train loss: 0.0879
2023-02-06 15:57:58 | Train | Epoch[062/200] Iteration[009/030] Train loss: 0.0880
2023-02-06 15:57:58 | Train | Epoch[062/200] Iteration[010/030] Train loss: 0.0880
2023-02-06 15:57:58 | Train | Epoch[062/200] Iteration[011/030] Train loss: 0.0878
2023-02-06 15:57:59 | Train | Epoch[062/200] Iteration[012/030] Train loss: 0.0881
2023-02-06 15:57:59 | Train | Epoch[062/200] Iteration[013/030] Train loss: 0.0881
2023-02-06 15:58:00 | Train | Epoch[062/200] Iteration[014/030] Train loss: 0.0880
2023-02-06 15:58:00 | Train | Epoch[062/200] Iteration[015/030] Train loss: 0.0880
2023-02-06 15:58:01 | Train | Epoch[062/200] Iteration[016/030] Train loss: 0.0882
2023-02-06 15:58:01 | Train | Epoch[062/200] Iteration[017/030] Train loss: 0.0880
2023-02-06 15:58:01 | Train | Epoch[062/200] Iteration[018/030] Train loss: 0.0882
2023-02-06 15:58:02 | Train | Epoch[062/200] Iteration[019/030] Train loss: 0.0882
2023-02-06 15:58:02 | Train | Epoch[062/200] Iteration[020/030] Train loss: 0.0882
2023-02-06 15:58:03 | Train | Epoch[062/200] Iteration[021/030] Train loss: 0.0883
2023-02-06 15:58:03 | Train | Epoch[062/200] Iteration[022/030] Train loss: 0.0883
2023-02-06 15:58:04 | Train | Epoch[062/200] Iteration[023/030] Train loss: 0.0882
2023-02-06 15:58:04 | Train | Epoch[062/200] Iteration[024/030] Train loss: 0.0882
2023-02-06 15:58:05 | Train | Epoch[062/200] Iteration[025/030] Train loss: 0.0881
2023-02-06 15:58:05 | Train | Epoch[062/200] Iteration[026/030] Train loss: 0.0882
2023-02-06 15:58:05 | Train | Epoch[062/200] Iteration[027/030] Train loss: 0.0882
2023-02-06 15:58:06 | Train | Epoch[062/200] Iteration[028/030] Train loss: 0.0881
2023-02-06 15:58:06 | Train | Epoch[062/200] Iteration[029/030] Train loss: 0.0881
2023-02-06 15:58:06 | Train | Epoch[062/200] Iteration[030/030] Train loss: 0.0881
2023-02-06 15:58:07 | Valid | Epoch[062/200] Iteration[001/008] Valid loss: 0.3625
2023-02-06 15:58:07 | Valid | Epoch[062/200] Iteration[002/008] Valid loss: 0.3181
2023-02-06 15:58:07 | Valid | Epoch[062/200] Iteration[003/008] Valid loss: 0.3010
2023-02-06 15:58:07 | Valid | Epoch[062/200] Iteration[004/008] Valid loss: 0.3017
2023-02-06 15:58:07 | Valid | Epoch[062/200] Iteration[005/008] Valid loss: 0.3097
2023-02-06 15:58:07 | Valid | Epoch[062/200] Iteration[006/008] Valid loss: 0.3124
2023-02-06 15:58:07 | Valid | Epoch[062/200] Iteration[007/008] Valid loss: 0.3309
2023-02-06 15:58:07 | Valid | Epoch[062/200] Iteration[008/008] Valid loss: 0.3318
2023-02-06 15:58:08 | Valid | Epoch[062/200] MIou: 0.8853751618250878
2023-02-06 15:58:08 | Valid | Epoch[062/200] Pixel Accuracy: 0.9770851135253906
2023-02-06 15:58:08 | Valid | Epoch[062/200] Mean Pixel Accuracy: 0.9826559879347359
2023-02-06 15:58:08 | Stage | Epoch[062/200] Train loss:0.0881
2023-02-06 15:58:08 | Stage | Epoch[062/200] Valid loss:0.3318
2023-02-06 15:58:08 | Stage | Epoch[062/200] LR:0.01

2023-02-06 15:58:08 | Train | Epoch[063/200] Iteration[001/030] Train loss: 0.0863
2023-02-06 15:58:09 | Train | Epoch[063/200] Iteration[002/030] Train loss: 0.0865
2023-02-06 15:58:09 | Train | Epoch[063/200] Iteration[003/030] Train loss: 0.0867
2023-02-06 15:58:10 | Train | Epoch[063/200] Iteration[004/030] Train loss: 0.0869
2023-02-06 15:58:10 | Train | Epoch[063/200] Iteration[005/030] Train loss: 0.0868
2023-02-06 15:58:11 | Train | Epoch[063/200] Iteration[006/030] Train loss: 0.0867
2023-02-06 15:58:11 | Train | Epoch[063/200] Iteration[007/030] Train loss: 0.0873
2023-02-06 15:58:11 | Train | Epoch[063/200] Iteration[008/030] Train loss: 0.0871
2023-02-06 15:58:12 | Train | Epoch[063/200] Iteration[009/030] Train loss: 0.0869
2023-02-06 15:58:12 | Train | Epoch[063/200] Iteration[010/030] Train loss: 0.0867
2023-02-06 15:58:13 | Train | Epoch[063/200] Iteration[011/030] Train loss: 0.0866
2023-02-06 15:58:13 | Train | Epoch[063/200] Iteration[012/030] Train loss: 0.0866
2023-02-06 15:58:14 | Train | Epoch[063/200] Iteration[013/030] Train loss: 0.0867
2023-02-06 15:58:14 | Train | Epoch[063/200] Iteration[014/030] Train loss: 0.0868
2023-02-06 15:58:14 | Train | Epoch[063/200] Iteration[015/030] Train loss: 0.0868
2023-02-06 15:58:15 | Train | Epoch[063/200] Iteration[016/030] Train loss: 0.0866
2023-02-06 15:58:15 | Train | Epoch[063/200] Iteration[017/030] Train loss: 0.0865
2023-02-06 15:58:16 | Train | Epoch[063/200] Iteration[018/030] Train loss: 0.0866
2023-02-06 15:58:16 | Train | Epoch[063/200] Iteration[019/030] Train loss: 0.0866
2023-02-06 15:58:17 | Train | Epoch[063/200] Iteration[020/030] Train loss: 0.0865
2023-02-06 15:58:17 | Train | Epoch[063/200] Iteration[021/030] Train loss: 0.0865
2023-02-06 15:58:17 | Train | Epoch[063/200] Iteration[022/030] Train loss: 0.0866
2023-02-06 15:58:18 | Train | Epoch[063/200] Iteration[023/030] Train loss: 0.0865
2023-02-06 15:58:18 | Train | Epoch[063/200] Iteration[024/030] Train loss: 0.0866
2023-02-06 15:58:19 | Train | Epoch[063/200] Iteration[025/030] Train loss: 0.0865
2023-02-06 15:58:19 | Train | Epoch[063/200] Iteration[026/030] Train loss: 0.0864
2023-02-06 15:58:20 | Train | Epoch[063/200] Iteration[027/030] Train loss: 0.0863
2023-02-06 15:58:20 | Train | Epoch[063/200] Iteration[028/030] Train loss: 0.0864
2023-02-06 15:58:20 | Train | Epoch[063/200] Iteration[029/030] Train loss: 0.0864
2023-02-06 15:58:21 | Train | Epoch[063/200] Iteration[030/030] Train loss: 0.0863
2023-02-06 15:58:21 | Valid | Epoch[063/200] Iteration[001/008] Valid loss: 0.4487
2023-02-06 15:58:21 | Valid | Epoch[063/200] Iteration[002/008] Valid loss: 0.3991
2023-02-06 15:58:21 | Valid | Epoch[063/200] Iteration[003/008] Valid loss: 0.3877
2023-02-06 15:58:21 | Valid | Epoch[063/200] Iteration[004/008] Valid loss: 0.3897
2023-02-06 15:58:22 | Valid | Epoch[063/200] Iteration[005/008] Valid loss: 0.4016
2023-02-06 15:58:22 | Valid | Epoch[063/200] Iteration[006/008] Valid loss: 0.3989
2023-02-06 15:58:22 | Valid | Epoch[063/200] Iteration[007/008] Valid loss: 0.4256
2023-02-06 15:58:22 | Valid | Epoch[063/200] Iteration[008/008] Valid loss: 0.4252
2023-02-06 15:58:22 | Valid | Epoch[063/200] MIou: 0.8571478757206837
2023-02-06 15:58:22 | Valid | Epoch[063/200] Pixel Accuracy: 0.9697825113932291
2023-02-06 15:58:22 | Valid | Epoch[063/200] Mean Pixel Accuracy: 0.9790479565312249
2023-02-06 15:58:22 | Stage | Epoch[063/200] Train loss:0.0863
2023-02-06 15:58:22 | Stage | Epoch[063/200] Valid loss:0.4252
2023-02-06 15:58:22 | Stage | Epoch[063/200] LR:0.01

2023-02-06 15:58:23 | Train | Epoch[064/200] Iteration[001/030] Train loss: 0.0833
2023-02-06 15:58:23 | Train | Epoch[064/200] Iteration[002/030] Train loss: 0.0867
2023-02-06 15:58:24 | Train | Epoch[064/200] Iteration[003/030] Train loss: 0.0873
2023-02-06 15:58:24 | Train | Epoch[064/200] Iteration[004/030] Train loss: 0.0863
2023-02-06 15:58:24 | Train | Epoch[064/200] Iteration[005/030] Train loss: 0.0859
2023-02-06 15:58:25 | Train | Epoch[064/200] Iteration[006/030] Train loss: 0.0858
2023-02-06 15:58:25 | Train | Epoch[064/200] Iteration[007/030] Train loss: 0.0854
2023-02-06 15:58:26 | Train | Epoch[064/200] Iteration[008/030] Train loss: 0.0854
2023-02-06 15:58:26 | Train | Epoch[064/200] Iteration[009/030] Train loss: 0.0854
2023-02-06 15:58:27 | Train | Epoch[064/200] Iteration[010/030] Train loss: 0.0855
2023-02-06 15:58:27 | Train | Epoch[064/200] Iteration[011/030] Train loss: 0.0856
2023-02-06 15:58:27 | Train | Epoch[064/200] Iteration[012/030] Train loss: 0.0853
2023-02-06 15:58:28 | Train | Epoch[064/200] Iteration[013/030] Train loss: 0.0853
2023-02-06 15:58:28 | Train | Epoch[064/200] Iteration[014/030] Train loss: 0.0853
2023-02-06 15:58:29 | Train | Epoch[064/200] Iteration[015/030] Train loss: 0.0852
2023-02-06 15:58:29 | Train | Epoch[064/200] Iteration[016/030] Train loss: 0.0851
2023-02-06 15:58:30 | Train | Epoch[064/200] Iteration[017/030] Train loss: 0.0850
2023-02-06 15:58:30 | Train | Epoch[064/200] Iteration[018/030] Train loss: 0.0850
2023-02-06 15:58:31 | Train | Epoch[064/200] Iteration[019/030] Train loss: 0.0849
2023-02-06 15:58:31 | Train | Epoch[064/200] Iteration[020/030] Train loss: 0.0848
2023-02-06 15:58:31 | Train | Epoch[064/200] Iteration[021/030] Train loss: 0.0847
2023-02-06 15:58:32 | Train | Epoch[064/200] Iteration[022/030] Train loss: 0.0846
2023-02-06 15:58:32 | Train | Epoch[064/200] Iteration[023/030] Train loss: 0.0846
2023-02-06 15:58:33 | Train | Epoch[064/200] Iteration[024/030] Train loss: 0.0845
2023-02-06 15:58:33 | Train | Epoch[064/200] Iteration[025/030] Train loss: 0.0844
2023-02-06 15:58:34 | Train | Epoch[064/200] Iteration[026/030] Train loss: 0.0844
2023-02-06 15:58:34 | Train | Epoch[064/200] Iteration[027/030] Train loss: 0.0845
2023-02-06 15:58:34 | Train | Epoch[064/200] Iteration[028/030] Train loss: 0.0844
2023-02-06 15:58:35 | Train | Epoch[064/200] Iteration[029/030] Train loss: 0.0844
2023-02-06 15:58:35 | Train | Epoch[064/200] Iteration[030/030] Train loss: 0.0844
2023-02-06 15:58:36 | Valid | Epoch[064/200] Iteration[001/008] Valid loss: 0.1108
2023-02-06 15:58:36 | Valid | Epoch[064/200] Iteration[002/008] Valid loss: 0.1059
2023-02-06 15:58:36 | Valid | Epoch[064/200] Iteration[003/008] Valid loss: 0.1059
2023-02-06 15:58:36 | Valid | Epoch[064/200] Iteration[004/008] Valid loss: 0.1047
2023-02-06 15:58:36 | Valid | Epoch[064/200] Iteration[005/008] Valid loss: 0.1051
2023-02-06 15:58:36 | Valid | Epoch[064/200] Iteration[006/008] Valid loss: 0.1052
2023-02-06 15:58:36 | Valid | Epoch[064/200] Iteration[007/008] Valid loss: 0.1056
2023-02-06 15:58:36 | Valid | Epoch[064/200] Iteration[008/008] Valid loss: 0.1057
2023-02-06 15:58:36 | Valid | Epoch[064/200] MIou: 0.8791833706431954
2023-02-06 15:58:36 | Valid | Epoch[064/200] Pixel Accuracy: 0.9797541300455729
2023-02-06 15:58:36 | Valid | Epoch[064/200] Mean Pixel Accuracy: 0.8968147005236906
2023-02-06 15:58:36 | Stage | Epoch[064/200] Train loss:0.0844
2023-02-06 15:58:36 | Stage | Epoch[064/200] Valid loss:0.1057
2023-02-06 15:58:36 | Stage | Epoch[064/200] LR:0.01

2023-02-06 15:58:37 | Train | Epoch[065/200] Iteration[001/030] Train loss: 0.0820
2023-02-06 15:58:37 | Train | Epoch[065/200] Iteration[002/030] Train loss: 0.0824
2023-02-06 15:58:38 | Train | Epoch[065/200] Iteration[003/030] Train loss: 0.0823
2023-02-06 15:58:38 | Train | Epoch[065/200] Iteration[004/030] Train loss: 0.0826
2023-02-06 15:58:39 | Train | Epoch[065/200] Iteration[005/030] Train loss: 0.0824
2023-02-06 15:58:39 | Train | Epoch[065/200] Iteration[006/030] Train loss: 0.0824
2023-02-06 15:58:40 | Train | Epoch[065/200] Iteration[007/030] Train loss: 0.0826
2023-02-06 15:58:40 | Train | Epoch[065/200] Iteration[008/030] Train loss: 0.0824
2023-02-06 15:58:40 | Train | Epoch[065/200] Iteration[009/030] Train loss: 0.0827
2023-02-06 15:58:41 | Train | Epoch[065/200] Iteration[010/030] Train loss: 0.0825
2023-02-06 15:58:41 | Train | Epoch[065/200] Iteration[011/030] Train loss: 0.0825
2023-02-06 15:58:42 | Train | Epoch[065/200] Iteration[012/030] Train loss: 0.0825
2023-02-06 15:58:42 | Train | Epoch[065/200] Iteration[013/030] Train loss: 0.0823
2023-02-06 15:58:43 | Train | Epoch[065/200] Iteration[014/030] Train loss: 0.0823
2023-02-06 15:58:43 | Train | Epoch[065/200] Iteration[015/030] Train loss: 0.0822
2023-02-06 15:58:43 | Train | Epoch[065/200] Iteration[016/030] Train loss: 0.0824
2023-02-06 15:58:44 | Train | Epoch[065/200] Iteration[017/030] Train loss: 0.0825
2023-02-06 15:58:44 | Train | Epoch[065/200] Iteration[018/030] Train loss: 0.0825
2023-02-06 15:58:45 | Train | Epoch[065/200] Iteration[019/030] Train loss: 0.0824
2023-02-06 15:58:45 | Train | Epoch[065/200] Iteration[020/030] Train loss: 0.0824
2023-02-06 15:58:46 | Train | Epoch[065/200] Iteration[021/030] Train loss: 0.0825
2023-02-06 15:58:46 | Train | Epoch[065/200] Iteration[022/030] Train loss: 0.0824
2023-02-06 15:58:46 | Train | Epoch[065/200] Iteration[023/030] Train loss: 0.0823
2023-02-06 15:58:47 | Train | Epoch[065/200] Iteration[024/030] Train loss: 0.0823
2023-02-06 15:58:47 | Train | Epoch[065/200] Iteration[025/030] Train loss: 0.0823
2023-02-06 15:58:48 | Train | Epoch[065/200] Iteration[026/030] Train loss: 0.0822
2023-02-06 15:58:48 | Train | Epoch[065/200] Iteration[027/030] Train loss: 0.0825
2023-02-06 15:58:49 | Train | Epoch[065/200] Iteration[028/030] Train loss: 0.0825
2023-02-06 15:58:49 | Train | Epoch[065/200] Iteration[029/030] Train loss: 0.0824
2023-02-06 15:58:49 | Train | Epoch[065/200] Iteration[030/030] Train loss: 0.0824
2023-02-06 15:58:50 | Valid | Epoch[065/200] Iteration[001/008] Valid loss: 3.5244
2023-02-06 15:58:50 | Valid | Epoch[065/200] Iteration[002/008] Valid loss: 3.5107
2023-02-06 15:58:50 | Valid | Epoch[065/200] Iteration[003/008] Valid loss: 3.6540
2023-02-06 15:58:50 | Valid | Epoch[065/200] Iteration[004/008] Valid loss: 3.7478
2023-02-06 15:58:50 | Valid | Epoch[065/200] Iteration[005/008] Valid loss: 3.8146
2023-02-06 15:58:50 | Valid | Epoch[065/200] Iteration[006/008] Valid loss: 3.7340
2023-02-06 15:58:50 | Valid | Epoch[065/200] Iteration[007/008] Valid loss: 3.7890
2023-02-06 15:58:50 | Valid | Epoch[065/200] Iteration[008/008] Valid loss: 3.9430
2023-02-06 15:58:51 | Valid | Epoch[065/200] MIou: 0.4239276831717367
2023-02-06 15:58:51 | Valid | Epoch[065/200] Pixel Accuracy: 0.6673711140950521
2023-02-06 15:58:51 | Valid | Epoch[065/200] Mean Pixel Accuracy: 0.8170525090690395
2023-02-06 15:58:51 | Stage | Epoch[065/200] Train loss:0.0824
2023-02-06 15:58:51 | Stage | Epoch[065/200] Valid loss:3.9430
2023-02-06 15:58:51 | Stage | Epoch[065/200] LR:0.01

2023-02-06 15:58:51 | Train | Epoch[066/200] Iteration[001/030] Train loss: 0.0816
2023-02-06 15:58:52 | Train | Epoch[066/200] Iteration[002/030] Train loss: 0.0819
2023-02-06 15:58:52 | Train | Epoch[066/200] Iteration[003/030] Train loss: 0.0817
2023-02-06 15:58:53 | Train | Epoch[066/200] Iteration[004/030] Train loss: 0.0818
2023-02-06 15:58:53 | Train | Epoch[066/200] Iteration[005/030] Train loss: 0.0822
2023-02-06 15:58:54 | Train | Epoch[066/200] Iteration[006/030] Train loss: 0.0818
2023-02-06 15:58:54 | Train | Epoch[066/200] Iteration[007/030] Train loss: 0.0822
2023-02-06 15:58:54 | Train | Epoch[066/200] Iteration[008/030] Train loss: 0.0819
2023-02-06 15:58:55 | Train | Epoch[066/200] Iteration[009/030] Train loss: 0.0819
2023-02-06 15:58:55 | Train | Epoch[066/200] Iteration[010/030] Train loss: 0.0818
2023-02-06 15:58:56 | Train | Epoch[066/200] Iteration[011/030] Train loss: 0.0817
2023-02-06 15:58:56 | Train | Epoch[066/200] Iteration[012/030] Train loss: 0.0815
2023-02-06 15:58:57 | Train | Epoch[066/200] Iteration[013/030] Train loss: 0.0814
2023-02-06 15:58:57 | Train | Epoch[066/200] Iteration[014/030] Train loss: 0.0814
2023-02-06 15:58:57 | Train | Epoch[066/200] Iteration[015/030] Train loss: 0.0814
2023-02-06 15:58:58 | Train | Epoch[066/200] Iteration[016/030] Train loss: 0.0814
2023-02-06 15:58:58 | Train | Epoch[066/200] Iteration[017/030] Train loss: 0.0813
2023-02-06 15:58:59 | Train | Epoch[066/200] Iteration[018/030] Train loss: 0.0812
2023-02-06 15:58:59 | Train | Epoch[066/200] Iteration[019/030] Train loss: 0.0811
2023-02-06 15:59:00 | Train | Epoch[066/200] Iteration[020/030] Train loss: 0.0810
2023-02-06 15:59:00 | Train | Epoch[066/200] Iteration[021/030] Train loss: 0.0813
2023-02-06 15:59:01 | Train | Epoch[066/200] Iteration[022/030] Train loss: 0.0812
2023-02-06 15:59:01 | Train | Epoch[066/200] Iteration[023/030] Train loss: 0.0813
2023-02-06 15:59:01 | Train | Epoch[066/200] Iteration[024/030] Train loss: 0.0813
2023-02-06 15:59:02 | Train | Epoch[066/200] Iteration[025/030] Train loss: 0.0813
2023-02-06 15:59:02 | Train | Epoch[066/200] Iteration[026/030] Train loss: 0.0814
2023-02-06 15:59:03 | Train | Epoch[066/200] Iteration[027/030] Train loss: 0.0813
2023-02-06 15:59:03 | Train | Epoch[066/200] Iteration[028/030] Train loss: 0.0814
2023-02-06 15:59:04 | Train | Epoch[066/200] Iteration[029/030] Train loss: 0.0814
2023-02-06 15:59:04 | Train | Epoch[066/200] Iteration[030/030] Train loss: 0.0814
2023-02-06 15:59:04 | Valid | Epoch[066/200] Iteration[001/008] Valid loss: 0.1554
2023-02-06 15:59:04 | Valid | Epoch[066/200] Iteration[002/008] Valid loss: 0.1565
2023-02-06 15:59:04 | Valid | Epoch[066/200] Iteration[003/008] Valid loss: 0.1606
2023-02-06 15:59:04 | Valid | Epoch[066/200] Iteration[004/008] Valid loss: 0.1600
2023-02-06 15:59:05 | Valid | Epoch[066/200] Iteration[005/008] Valid loss: 0.1624
2023-02-06 15:59:05 | Valid | Epoch[066/200] Iteration[006/008] Valid loss: 0.1608
2023-02-06 15:59:05 | Valid | Epoch[066/200] Iteration[007/008] Valid loss: 0.1598
2023-02-06 15:59:05 | Valid | Epoch[066/200] Iteration[008/008] Valid loss: 0.1624
2023-02-06 15:59:05 | Valid | Epoch[066/200] MIou: 0.636272753271683
2023-02-06 15:59:05 | Valid | Epoch[066/200] Pixel Accuracy: 0.9398244222005209
2023-02-06 15:59:05 | Valid | Epoch[066/200] Mean Pixel Accuracy: 0.6674517855565318
2023-02-06 15:59:05 | Stage | Epoch[066/200] Train loss:0.0814
2023-02-06 15:59:05 | Stage | Epoch[066/200] Valid loss:0.1624
2023-02-06 15:59:05 | Stage | Epoch[066/200] LR:0.01

2023-02-06 15:59:06 | Train | Epoch[067/200] Iteration[001/030] Train loss: 0.0800
2023-02-06 15:59:06 | Train | Epoch[067/200] Iteration[002/030] Train loss: 0.0796
2023-02-06 15:59:07 | Train | Epoch[067/200] Iteration[003/030] Train loss: 0.0799
2023-02-06 15:59:07 | Train | Epoch[067/200] Iteration[004/030] Train loss: 0.0801
2023-02-06 15:59:07 | Train | Epoch[067/200] Iteration[005/030] Train loss: 0.0798
2023-02-06 15:59:08 | Train | Epoch[067/200] Iteration[006/030] Train loss: 0.0796
2023-02-06 15:59:08 | Train | Epoch[067/200] Iteration[007/030] Train loss: 0.0795
2023-02-06 15:59:09 | Train | Epoch[067/200] Iteration[008/030] Train loss: 0.0795
2023-02-06 15:59:09 | Train | Epoch[067/200] Iteration[009/030] Train loss: 0.0793
2023-02-06 15:59:10 | Train | Epoch[067/200] Iteration[010/030] Train loss: 0.0794
2023-02-06 15:59:10 | Train | Epoch[067/200] Iteration[011/030] Train loss: 0.0792
2023-02-06 15:59:11 | Train | Epoch[067/200] Iteration[012/030] Train loss: 0.0793
2023-02-06 15:59:11 | Train | Epoch[067/200] Iteration[013/030] Train loss: 0.0795
2023-02-06 15:59:11 | Train | Epoch[067/200] Iteration[014/030] Train loss: 0.0793
2023-02-06 15:59:12 | Train | Epoch[067/200] Iteration[015/030] Train loss: 0.0793
2023-02-06 15:59:12 | Train | Epoch[067/200] Iteration[016/030] Train loss: 0.0793
2023-02-06 15:59:13 | Train | Epoch[067/200] Iteration[017/030] Train loss: 0.0793
2023-02-06 15:59:13 | Train | Epoch[067/200] Iteration[018/030] Train loss: 0.0793
2023-02-06 15:59:14 | Train | Epoch[067/200] Iteration[019/030] Train loss: 0.0793
2023-02-06 15:59:14 | Train | Epoch[067/200] Iteration[020/030] Train loss: 0.0792
2023-02-06 15:59:14 | Train | Epoch[067/200] Iteration[021/030] Train loss: 0.0791
2023-02-06 15:59:15 | Train | Epoch[067/200] Iteration[022/030] Train loss: 0.0791
2023-02-06 15:59:15 | Train | Epoch[067/200] Iteration[023/030] Train loss: 0.0790
2023-02-06 15:59:16 | Train | Epoch[067/200] Iteration[024/030] Train loss: 0.0791
2023-02-06 15:59:16 | Train | Epoch[067/200] Iteration[025/030] Train loss: 0.0790
2023-02-06 15:59:17 | Train | Epoch[067/200] Iteration[026/030] Train loss: 0.0791
2023-02-06 15:59:17 | Train | Epoch[067/200] Iteration[027/030] Train loss: 0.0791
2023-02-06 15:59:17 | Train | Epoch[067/200] Iteration[028/030] Train loss: 0.0791
2023-02-06 15:59:18 | Train | Epoch[067/200] Iteration[029/030] Train loss: 0.0790
2023-02-06 15:59:18 | Train | Epoch[067/200] Iteration[030/030] Train loss: 0.0792
2023-02-06 15:59:19 | Valid | Epoch[067/200] Iteration[001/008] Valid loss: 0.1271
2023-02-06 15:59:19 | Valid | Epoch[067/200] Iteration[002/008] Valid loss: 0.1118
2023-02-06 15:59:19 | Valid | Epoch[067/200] Iteration[003/008] Valid loss: 0.1075
2023-02-06 15:59:19 | Valid | Epoch[067/200] Iteration[004/008] Valid loss: 0.1055
2023-02-06 15:59:19 | Valid | Epoch[067/200] Iteration[005/008] Valid loss: 0.1059
2023-02-06 15:59:19 | Valid | Epoch[067/200] Iteration[006/008] Valid loss: 0.1052
2023-02-06 15:59:19 | Valid | Epoch[067/200] Iteration[007/008] Valid loss: 0.1066
2023-02-06 15:59:19 | Valid | Epoch[067/200] Iteration[008/008] Valid loss: 0.1061
2023-02-06 15:59:19 | Valid | Epoch[067/200] MIou: 0.9222802668110485
2023-02-06 15:59:19 | Valid | Epoch[067/200] Pixel Accuracy: 0.9866943359375
2023-02-06 15:59:19 | Valid | Epoch[067/200] Mean Pixel Accuracy: 0.9466611568522154
2023-02-06 15:59:19 | Stage | Epoch[067/200] Train loss:0.0792
2023-02-06 15:59:19 | Stage | Epoch[067/200] Valid loss:0.1061
2023-02-06 15:59:19 | Stage | Epoch[067/200] LR:0.01

2023-02-06 15:59:20 | Train | Epoch[068/200] Iteration[001/030] Train loss: 0.0768
2023-02-06 15:59:20 | Train | Epoch[068/200] Iteration[002/030] Train loss: 0.0775
2023-02-06 15:59:21 | Train | Epoch[068/200] Iteration[003/030] Train loss: 0.0771
2023-02-06 15:59:21 | Train | Epoch[068/200] Iteration[004/030] Train loss: 0.0777
2023-02-06 15:59:22 | Train | Epoch[068/200] Iteration[005/030] Train loss: 0.0777
2023-02-06 15:59:22 | Train | Epoch[068/200] Iteration[006/030] Train loss: 0.0775
2023-02-06 15:59:23 | Train | Epoch[068/200] Iteration[007/030] Train loss: 0.0776
2023-02-06 15:59:23 | Train | Epoch[068/200] Iteration[008/030] Train loss: 0.0777
2023-02-06 15:59:23 | Train | Epoch[068/200] Iteration[009/030] Train loss: 0.0779
2023-02-06 15:59:24 | Train | Epoch[068/200] Iteration[010/030] Train loss: 0.0779
2023-02-06 15:59:24 | Train | Epoch[068/200] Iteration[011/030] Train loss: 0.0779
2023-02-06 15:59:25 | Train | Epoch[068/200] Iteration[012/030] Train loss: 0.0781
2023-02-06 15:59:25 | Train | Epoch[068/200] Iteration[013/030] Train loss: 0.0781
2023-02-06 15:59:26 | Train | Epoch[068/200] Iteration[014/030] Train loss: 0.0779
2023-02-06 15:59:26 | Train | Epoch[068/200] Iteration[015/030] Train loss: 0.0778
2023-02-06 15:59:26 | Train | Epoch[068/200] Iteration[016/030] Train loss: 0.0777
2023-02-06 15:59:27 | Train | Epoch[068/200] Iteration[017/030] Train loss: 0.0776
2023-02-06 15:59:27 | Train | Epoch[068/200] Iteration[018/030] Train loss: 0.0775
2023-02-06 15:59:28 | Train | Epoch[068/200] Iteration[019/030] Train loss: 0.0774
2023-02-06 15:59:28 | Train | Epoch[068/200] Iteration[020/030] Train loss: 0.0773
2023-02-06 15:59:29 | Train | Epoch[068/200] Iteration[021/030] Train loss: 0.0773
2023-02-06 15:59:29 | Train | Epoch[068/200] Iteration[022/030] Train loss: 0.0772
2023-02-06 15:59:30 | Train | Epoch[068/200] Iteration[023/030] Train loss: 0.0773
2023-02-06 15:59:30 | Train | Epoch[068/200] Iteration[024/030] Train loss: 0.0772
2023-02-06 15:59:30 | Train | Epoch[068/200] Iteration[025/030] Train loss: 0.0772
2023-02-06 15:59:31 | Train | Epoch[068/200] Iteration[026/030] Train loss: 0.0773
2023-02-06 15:59:31 | Train | Epoch[068/200] Iteration[027/030] Train loss: 0.0773
2023-02-06 15:59:32 | Train | Epoch[068/200] Iteration[028/030] Train loss: 0.0772
2023-02-06 15:59:32 | Train | Epoch[068/200] Iteration[029/030] Train loss: 0.0772
2023-02-06 15:59:32 | Train | Epoch[068/200] Iteration[030/030] Train loss: 0.0772
2023-02-06 15:59:33 | Valid | Epoch[068/200] Iteration[001/008] Valid loss: 0.1573
2023-02-06 15:59:33 | Valid | Epoch[068/200] Iteration[002/008] Valid loss: 0.1311
2023-02-06 15:59:33 | Valid | Epoch[068/200] Iteration[003/008] Valid loss: 0.1210
2023-02-06 15:59:33 | Valid | Epoch[068/200] Iteration[004/008] Valid loss: 0.1179
2023-02-06 15:59:33 | Valid | Epoch[068/200] Iteration[005/008] Valid loss: 0.1177
2023-02-06 15:59:33 | Valid | Epoch[068/200] Iteration[006/008] Valid loss: 0.1192
2023-02-06 15:59:33 | Valid | Epoch[068/200] Iteration[007/008] Valid loss: 0.1216
2023-02-06 15:59:33 | Valid | Epoch[068/200] Iteration[008/008] Valid loss: 0.1202
2023-02-06 15:59:33 | Valid | Epoch[068/200] MIou: 0.9303886658280012
2023-02-06 15:59:33 | Valid | Epoch[068/200] Pixel Accuracy: 0.9877293904622396
2023-02-06 15:59:33 | Valid | Epoch[068/200] Mean Pixel Accuracy: 0.9680521754086902
2023-02-06 15:59:33 | Stage | Epoch[068/200] Train loss:0.0772
2023-02-06 15:59:33 | Stage | Epoch[068/200] Valid loss:0.1202
2023-02-06 15:59:33 | Stage | Epoch[068/200] LR:0.01

2023-02-06 15:59:34 | Train | Epoch[069/200] Iteration[001/030] Train loss: 0.0734
2023-02-06 15:59:35 | Train | Epoch[069/200] Iteration[002/030] Train loss: 0.0758
2023-02-06 15:59:35 | Train | Epoch[069/200] Iteration[003/030] Train loss: 0.0754
2023-02-06 15:59:36 | Train | Epoch[069/200] Iteration[004/030] Train loss: 0.0755
2023-02-06 15:59:36 | Train | Epoch[069/200] Iteration[005/030] Train loss: 0.0755
2023-02-06 15:59:36 | Train | Epoch[069/200] Iteration[006/030] Train loss: 0.0754
2023-02-06 15:59:37 | Train | Epoch[069/200] Iteration[007/030] Train loss: 0.0752
2023-02-06 15:59:37 | Train | Epoch[069/200] Iteration[008/030] Train loss: 0.0754
2023-02-06 15:59:38 | Train | Epoch[069/200] Iteration[009/030] Train loss: 0.0753
2023-02-06 15:59:38 | Train | Epoch[069/200] Iteration[010/030] Train loss: 0.0754
2023-02-06 15:59:39 | Train | Epoch[069/200] Iteration[011/030] Train loss: 0.0759
2023-02-06 15:59:39 | Train | Epoch[069/200] Iteration[012/030] Train loss: 0.0759
2023-02-06 15:59:39 | Train | Epoch[069/200] Iteration[013/030] Train loss: 0.0757
2023-02-06 15:59:40 | Train | Epoch[069/200] Iteration[014/030] Train loss: 0.0757
2023-02-06 15:59:40 | Train | Epoch[069/200] Iteration[015/030] Train loss: 0.0757
2023-02-06 15:59:41 | Train | Epoch[069/200] Iteration[016/030] Train loss: 0.0757
2023-02-06 15:59:41 | Train | Epoch[069/200] Iteration[017/030] Train loss: 0.0757
2023-02-06 15:59:42 | Train | Epoch[069/200] Iteration[018/030] Train loss: 0.0756
2023-02-06 15:59:42 | Train | Epoch[069/200] Iteration[019/030] Train loss: 0.0756
2023-02-06 15:59:42 | Train | Epoch[069/200] Iteration[020/030] Train loss: 0.0758
2023-02-06 15:59:43 | Train | Epoch[069/200] Iteration[021/030] Train loss: 0.0758
2023-02-06 15:59:43 | Train | Epoch[069/200] Iteration[022/030] Train loss: 0.0758
2023-02-06 15:59:44 | Train | Epoch[069/200] Iteration[023/030] Train loss: 0.0757
2023-02-06 15:59:44 | Train | Epoch[069/200] Iteration[024/030] Train loss: 0.0758
2023-02-06 15:59:45 | Train | Epoch[069/200] Iteration[025/030] Train loss: 0.0757
2023-02-06 15:59:45 | Train | Epoch[069/200] Iteration[026/030] Train loss: 0.0757
2023-02-06 15:59:45 | Train | Epoch[069/200] Iteration[027/030] Train loss: 0.0757
2023-02-06 15:59:46 | Train | Epoch[069/200] Iteration[028/030] Train loss: 0.0757
2023-02-06 15:59:46 | Train | Epoch[069/200] Iteration[029/030] Train loss: 0.0757
2023-02-06 15:59:46 | Train | Epoch[069/200] Iteration[030/030] Train loss: 0.0757
2023-02-06 15:59:47 | Valid | Epoch[069/200] Iteration[001/008] Valid loss: 0.4828
2023-02-06 15:59:47 | Valid | Epoch[069/200] Iteration[002/008] Valid loss: 0.4563
2023-02-06 15:59:47 | Valid | Epoch[069/200] Iteration[003/008] Valid loss: 0.4519
2023-02-06 15:59:47 | Valid | Epoch[069/200] Iteration[004/008] Valid loss: 0.4480
2023-02-06 15:59:47 | Valid | Epoch[069/200] Iteration[005/008] Valid loss: 0.4538
2023-02-06 15:59:48 | Valid | Epoch[069/200] Iteration[006/008] Valid loss: 0.4464
2023-02-06 15:59:48 | Valid | Epoch[069/200] Iteration[007/008] Valid loss: 0.4690
2023-02-06 15:59:48 | Valid | Epoch[069/200] Iteration[008/008] Valid loss: 0.4730
2023-02-06 15:59:48 | Valid | Epoch[069/200] MIou: 0.8708871380243035
2023-02-06 15:59:48 | Valid | Epoch[069/200] Pixel Accuracy: 0.973443349202474
2023-02-06 15:59:48 | Valid | Epoch[069/200] Mean Pixel Accuracy: 0.9807240641320019
2023-02-06 15:59:48 | Stage | Epoch[069/200] Train loss:0.0757
2023-02-06 15:59:48 | Stage | Epoch[069/200] Valid loss:0.4730
2023-02-06 15:59:48 | Stage | Epoch[069/200] LR:0.01

2023-02-06 15:59:49 | Train | Epoch[070/200] Iteration[001/030] Train loss: 0.0737
2023-02-06 15:59:49 | Train | Epoch[070/200] Iteration[002/030] Train loss: 0.0737
2023-02-06 15:59:49 | Train | Epoch[070/200] Iteration[003/030] Train loss: 0.0732
2023-02-06 15:59:50 | Train | Epoch[070/200] Iteration[004/030] Train loss: 0.0732
2023-02-06 15:59:50 | Train | Epoch[070/200] Iteration[005/030] Train loss: 0.0732
2023-02-06 15:59:51 | Train | Epoch[070/200] Iteration[006/030] Train loss: 0.0732
2023-02-06 15:59:51 | Train | Epoch[070/200] Iteration[007/030] Train loss: 0.0736
2023-02-06 15:59:52 | Train | Epoch[070/200] Iteration[008/030] Train loss: 0.0734
2023-02-06 15:59:52 | Train | Epoch[070/200] Iteration[009/030] Train loss: 0.0733
2023-02-06 15:59:52 | Train | Epoch[070/200] Iteration[010/030] Train loss: 0.0733
2023-02-06 15:59:53 | Train | Epoch[070/200] Iteration[011/030] Train loss: 0.0733
2023-02-06 15:59:53 | Train | Epoch[070/200] Iteration[012/030] Train loss: 0.0733
2023-02-06 15:59:54 | Train | Epoch[070/200] Iteration[013/030] Train loss: 0.0733
2023-02-06 15:59:54 | Train | Epoch[070/200] Iteration[014/030] Train loss: 0.0733
2023-02-06 15:59:55 | Train | Epoch[070/200] Iteration[015/030] Train loss: 0.0732
2023-02-06 15:59:55 | Train | Epoch[070/200] Iteration[016/030] Train loss: 0.0733
2023-02-06 15:59:55 | Train | Epoch[070/200] Iteration[017/030] Train loss: 0.0733
2023-02-06 15:59:56 | Train | Epoch[070/200] Iteration[018/030] Train loss: 0.0733
2023-02-06 15:59:56 | Train | Epoch[070/200] Iteration[019/030] Train loss: 0.0732
2023-02-06 15:59:57 | Train | Epoch[070/200] Iteration[020/030] Train loss: 0.0732
2023-02-06 15:59:57 | Train | Epoch[070/200] Iteration[021/030] Train loss: 0.0733
2023-02-06 15:59:58 | Train | Epoch[070/200] Iteration[022/030] Train loss: 0.0734
2023-02-06 15:59:58 | Train | Epoch[070/200] Iteration[023/030] Train loss: 0.0734
2023-02-06 15:59:58 | Train | Epoch[070/200] Iteration[024/030] Train loss: 0.0735
2023-02-06 15:59:59 | Train | Epoch[070/200] Iteration[025/030] Train loss: 0.0735
2023-02-06 15:59:59 | Train | Epoch[070/200] Iteration[026/030] Train loss: 0.0735
2023-02-06 16:00:00 | Train | Epoch[070/200] Iteration[027/030] Train loss: 0.0735
2023-02-06 16:00:00 | Train | Epoch[070/200] Iteration[028/030] Train loss: 0.0737
2023-02-06 16:00:01 | Train | Epoch[070/200] Iteration[029/030] Train loss: 0.0737
2023-02-06 16:00:01 | Train | Epoch[070/200] Iteration[030/030] Train loss: 0.0737
2023-02-06 16:00:01 | Valid | Epoch[070/200] Iteration[001/008] Valid loss: 0.1567
2023-02-06 16:00:01 | Valid | Epoch[070/200] Iteration[002/008] Valid loss: 0.1344
2023-02-06 16:00:01 | Valid | Epoch[070/200] Iteration[003/008] Valid loss: 0.1251
2023-02-06 16:00:02 | Valid | Epoch[070/200] Iteration[004/008] Valid loss: 0.1224
2023-02-06 16:00:02 | Valid | Epoch[070/200] Iteration[005/008] Valid loss: 0.1241
2023-02-06 16:00:02 | Valid | Epoch[070/200] Iteration[006/008] Valid loss: 0.1239
2023-02-06 16:00:02 | Valid | Epoch[070/200] Iteration[007/008] Valid loss: 0.1280
2023-02-06 16:00:02 | Valid | Epoch[070/200] Iteration[008/008] Valid loss: 0.1271
2023-02-06 16:00:02 | Valid | Epoch[070/200] MIou: 0.9250603631715664
2023-02-06 16:00:02 | Valid | Epoch[070/200] Pixel Accuracy: 0.9867032368977865
2023-02-06 16:00:02 | Valid | Epoch[070/200] Mean Pixel Accuracy: 0.9658966992957436
2023-02-06 16:00:02 | Stage | Epoch[070/200] Train loss:0.0737
2023-02-06 16:00:02 | Stage | Epoch[070/200] Valid loss:0.1271
2023-02-06 16:00:02 | Stage | Epoch[070/200] LR:0.01

2023-02-06 16:00:03 | Train | Epoch[071/200] Iteration[001/030] Train loss: 0.0727
2023-02-06 16:00:03 | Train | Epoch[071/200] Iteration[002/030] Train loss: 0.0730
2023-02-06 16:00:04 | Train | Epoch[071/200] Iteration[003/030] Train loss: 0.0732
2023-02-06 16:00:04 | Train | Epoch[071/200] Iteration[004/030] Train loss: 0.0729
2023-02-06 16:00:04 | Train | Epoch[071/200] Iteration[005/030] Train loss: 0.0725
2023-02-06 16:00:05 | Train | Epoch[071/200] Iteration[006/030] Train loss: 0.0727
2023-02-06 16:00:05 | Train | Epoch[071/200] Iteration[007/030] Train loss: 0.0724
2023-02-06 16:00:06 | Train | Epoch[071/200] Iteration[008/030] Train loss: 0.0723
2023-02-06 16:00:06 | Train | Epoch[071/200] Iteration[009/030] Train loss: 0.0725
2023-02-06 16:00:07 | Train | Epoch[071/200] Iteration[010/030] Train loss: 0.0725
2023-02-06 16:00:07 | Train | Epoch[071/200] Iteration[011/030] Train loss: 0.0725
2023-02-06 16:00:08 | Train | Epoch[071/200] Iteration[012/030] Train loss: 0.0725
2023-02-06 16:00:08 | Train | Epoch[071/200] Iteration[013/030] Train loss: 0.0724
2023-02-06 16:00:08 | Train | Epoch[071/200] Iteration[014/030] Train loss: 0.0726
2023-02-06 16:00:09 | Train | Epoch[071/200] Iteration[015/030] Train loss: 0.0725
2023-02-06 16:00:09 | Train | Epoch[071/200] Iteration[016/030] Train loss: 0.0724
2023-02-06 16:00:10 | Train | Epoch[071/200] Iteration[017/030] Train loss: 0.0723
2023-02-06 16:00:10 | Train | Epoch[071/200] Iteration[018/030] Train loss: 0.0724
2023-02-06 16:00:11 | Train | Epoch[071/200] Iteration[019/030] Train loss: 0.0723
2023-02-06 16:00:11 | Train | Epoch[071/200] Iteration[020/030] Train loss: 0.0723
2023-02-06 16:00:11 | Train | Epoch[071/200] Iteration[021/030] Train loss: 0.0722
2023-02-06 16:00:12 | Train | Epoch[071/200] Iteration[022/030] Train loss: 0.0722
2023-02-06 16:00:12 | Train | Epoch[071/200] Iteration[023/030] Train loss: 0.0722
2023-02-06 16:00:13 | Train | Epoch[071/200] Iteration[024/030] Train loss: 0.0722
2023-02-06 16:00:13 | Train | Epoch[071/200] Iteration[025/030] Train loss: 0.0722
2023-02-06 16:00:14 | Train | Epoch[071/200] Iteration[026/030] Train loss: 0.0722
2023-02-06 16:00:14 | Train | Epoch[071/200] Iteration[027/030] Train loss: 0.0722
2023-02-06 16:00:14 | Train | Epoch[071/200] Iteration[028/030] Train loss: 0.0722
2023-02-06 16:00:15 | Train | Epoch[071/200] Iteration[029/030] Train loss: 0.0722
2023-02-06 16:00:15 | Train | Epoch[071/200] Iteration[030/030] Train loss: 0.0722
2023-02-06 16:00:16 | Valid | Epoch[071/200] Iteration[001/008] Valid loss: 0.4506
2023-02-06 16:00:16 | Valid | Epoch[071/200] Iteration[002/008] Valid loss: 0.4117
2023-02-06 16:00:16 | Valid | Epoch[071/200] Iteration[003/008] Valid loss: 0.3769
2023-02-06 16:00:16 | Valid | Epoch[071/200] Iteration[004/008] Valid loss: 0.3850
2023-02-06 16:00:16 | Valid | Epoch[071/200] Iteration[005/008] Valid loss: 0.3890
2023-02-06 16:00:16 | Valid | Epoch[071/200] Iteration[006/008] Valid loss: 0.3908
2023-02-06 16:00:16 | Valid | Epoch[071/200] Iteration[007/008] Valid loss: 0.4120
2023-02-06 16:00:16 | Valid | Epoch[071/200] Iteration[008/008] Valid loss: 0.4273
2023-02-06 16:00:16 | Valid | Epoch[071/200] MIou: 0.8791150761776816
2023-02-06 16:00:16 | Valid | Epoch[071/200] Pixel Accuracy: 0.9756177266438802
2023-02-06 16:00:16 | Valid | Epoch[071/200] Mean Pixel Accuracy: 0.9801311817423473
2023-02-06 16:00:16 | Stage | Epoch[071/200] Train loss:0.0722
2023-02-06 16:00:16 | Stage | Epoch[071/200] Valid loss:0.4273
2023-02-06 16:00:16 | Stage | Epoch[071/200] LR:0.01

2023-02-06 16:00:17 | Train | Epoch[072/200] Iteration[001/030] Train loss: 0.0715
2023-02-06 16:00:18 | Train | Epoch[072/200] Iteration[002/030] Train loss: 0.0713
2023-02-06 16:00:18 | Train | Epoch[072/200] Iteration[003/030] Train loss: 0.0711
2023-02-06 16:00:18 | Train | Epoch[072/200] Iteration[004/030] Train loss: 0.0707
2023-02-06 16:00:19 | Train | Epoch[072/200] Iteration[005/030] Train loss: 0.0705
2023-02-06 16:00:19 | Train | Epoch[072/200] Iteration[006/030] Train loss: 0.0706
2023-02-06 16:00:20 | Train | Epoch[072/200] Iteration[007/030] Train loss: 0.0706
2023-02-06 16:00:20 | Train | Epoch[072/200] Iteration[008/030] Train loss: 0.0708
2023-02-06 16:00:21 | Train | Epoch[072/200] Iteration[009/030] Train loss: 0.0706
2023-02-06 16:00:21 | Train | Epoch[072/200] Iteration[010/030] Train loss: 0.0706
2023-02-06 16:00:21 | Train | Epoch[072/200] Iteration[011/030] Train loss: 0.0714
2023-02-06 16:00:22 | Train | Epoch[072/200] Iteration[012/030] Train loss: 0.0713
2023-02-06 16:00:22 | Train | Epoch[072/200] Iteration[013/030] Train loss: 0.0713
2023-02-06 16:00:23 | Train | Epoch[072/200] Iteration[014/030] Train loss: 0.0713
2023-02-06 16:00:23 | Train | Epoch[072/200] Iteration[015/030] Train loss: 0.0714
2023-02-06 16:00:24 | Train | Epoch[072/200] Iteration[016/030] Train loss: 0.0713
2023-02-06 16:00:24 | Train | Epoch[072/200] Iteration[017/030] Train loss: 0.0715
2023-02-06 16:00:25 | Train | Epoch[072/200] Iteration[018/030] Train loss: 0.0715
2023-02-06 16:00:25 | Train | Epoch[072/200] Iteration[019/030] Train loss: 0.0715
2023-02-06 16:00:25 | Train | Epoch[072/200] Iteration[020/030] Train loss: 0.0715
2023-02-06 16:00:26 | Train | Epoch[072/200] Iteration[021/030] Train loss: 0.0714
2023-02-06 16:00:26 | Train | Epoch[072/200] Iteration[022/030] Train loss: 0.0714
2023-02-06 16:00:27 | Train | Epoch[072/200] Iteration[023/030] Train loss: 0.0714
2023-02-06 16:00:27 | Train | Epoch[072/200] Iteration[024/030] Train loss: 0.0714
2023-02-06 16:00:28 | Train | Epoch[072/200] Iteration[025/030] Train loss: 0.0713
2023-02-06 16:00:28 | Train | Epoch[072/200] Iteration[026/030] Train loss: 0.0713
2023-02-06 16:00:28 | Train | Epoch[072/200] Iteration[027/030] Train loss: 0.0713
2023-02-06 16:00:29 | Train | Epoch[072/200] Iteration[028/030] Train loss: 0.0713
2023-02-06 16:00:29 | Train | Epoch[072/200] Iteration[029/030] Train loss: 0.0712
2023-02-06 16:00:29 | Train | Epoch[072/200] Iteration[030/030] Train loss: 0.0712
2023-02-06 16:00:30 | Valid | Epoch[072/200] Iteration[001/008] Valid loss: 1.5572
2023-02-06 16:00:30 | Valid | Epoch[072/200] Iteration[002/008] Valid loss: 1.5388
2023-02-06 16:00:30 | Valid | Epoch[072/200] Iteration[003/008] Valid loss: 1.5555
2023-02-06 16:00:30 | Valid | Epoch[072/200] Iteration[004/008] Valid loss: 1.6392
2023-02-06 16:00:30 | Valid | Epoch[072/200] Iteration[005/008] Valid loss: 1.6917
2023-02-06 16:00:30 | Valid | Epoch[072/200] Iteration[006/008] Valid loss: 1.6889
2023-02-06 16:00:31 | Valid | Epoch[072/200] Iteration[007/008] Valid loss: 1.7466
2023-02-06 16:00:31 | Valid | Epoch[072/200] Iteration[008/008] Valid loss: 1.7823
2023-02-06 16:00:31 | Valid | Epoch[072/200] MIou: 0.7829386211347478
2023-02-06 16:00:31 | Valid | Epoch[072/200] Pixel Accuracy: 0.9459279378255209
2023-02-06 16:00:31 | Valid | Epoch[072/200] Mean Pixel Accuracy: 0.9698929197489938
2023-02-06 16:00:31 | Stage | Epoch[072/200] Train loss:0.0712
2023-02-06 16:00:31 | Stage | Epoch[072/200] Valid loss:1.7823
2023-02-06 16:00:31 | Stage | Epoch[072/200] LR:0.01

2023-02-06 16:00:32 | Train | Epoch[073/200] Iteration[001/030] Train loss: 0.0680
2023-02-06 16:00:32 | Train | Epoch[073/200] Iteration[002/030] Train loss: 0.0689
2023-02-06 16:00:32 | Train | Epoch[073/200] Iteration[003/030] Train loss: 0.0690
2023-02-06 16:00:33 | Train | Epoch[073/200] Iteration[004/030] Train loss: 0.0693
2023-02-06 16:00:33 | Train | Epoch[073/200] Iteration[005/030] Train loss: 0.0695
2023-02-06 16:00:34 | Train | Epoch[073/200] Iteration[006/030] Train loss: 0.0694
2023-02-06 16:00:34 | Train | Epoch[073/200] Iteration[007/030] Train loss: 0.0693
2023-02-06 16:00:35 | Train | Epoch[073/200] Iteration[008/030] Train loss: 0.0695
2023-02-06 16:00:35 | Train | Epoch[073/200] Iteration[009/030] Train loss: 0.0696
2023-02-06 16:00:36 | Train | Epoch[073/200] Iteration[010/030] Train loss: 0.0696
2023-02-06 16:00:36 | Train | Epoch[073/200] Iteration[011/030] Train loss: 0.0697
2023-02-06 16:00:36 | Train | Epoch[073/200] Iteration[012/030] Train loss: 0.0698
2023-02-06 16:00:37 | Train | Epoch[073/200] Iteration[013/030] Train loss: 0.0699
2023-02-06 16:00:37 | Train | Epoch[073/200] Iteration[014/030] Train loss: 0.0698
2023-02-06 16:00:38 | Train | Epoch[073/200] Iteration[015/030] Train loss: 0.0699
2023-02-06 16:00:38 | Train | Epoch[073/200] Iteration[016/030] Train loss: 0.0699
2023-02-06 16:00:39 | Train | Epoch[073/200] Iteration[017/030] Train loss: 0.0700
2023-02-06 16:00:39 | Train | Epoch[073/200] Iteration[018/030] Train loss: 0.0699
2023-02-06 16:00:39 | Train | Epoch[073/200] Iteration[019/030] Train loss: 0.0698
2023-02-06 16:00:40 | Train | Epoch[073/200] Iteration[020/030] Train loss: 0.0698
2023-02-06 16:00:40 | Train | Epoch[073/200] Iteration[021/030] Train loss: 0.0698
2023-02-06 16:00:41 | Train | Epoch[073/200] Iteration[022/030] Train loss: 0.0698
2023-02-06 16:00:41 | Train | Epoch[073/200] Iteration[023/030] Train loss: 0.0698
2023-02-06 16:00:42 | Train | Epoch[073/200] Iteration[024/030] Train loss: 0.0698
2023-02-06 16:00:42 | Train | Epoch[073/200] Iteration[025/030] Train loss: 0.0698
2023-02-06 16:00:42 | Train | Epoch[073/200] Iteration[026/030] Train loss: 0.0698
2023-02-06 16:00:43 | Train | Epoch[073/200] Iteration[027/030] Train loss: 0.0697
2023-02-06 16:00:43 | Train | Epoch[073/200] Iteration[028/030] Train loss: 0.0696
2023-02-06 16:00:44 | Train | Epoch[073/200] Iteration[029/030] Train loss: 0.0696
2023-02-06 16:00:44 | Train | Epoch[073/200] Iteration[030/030] Train loss: 0.0695
2023-02-06 16:00:44 | Valid | Epoch[073/200] Iteration[001/008] Valid loss: 0.1523
2023-02-06 16:00:45 | Valid | Epoch[073/200] Iteration[002/008] Valid loss: 0.1238
2023-02-06 16:00:45 | Valid | Epoch[073/200] Iteration[003/008] Valid loss: 0.1143
2023-02-06 16:00:45 | Valid | Epoch[073/200] Iteration[004/008] Valid loss: 0.1106
2023-02-06 16:00:45 | Valid | Epoch[073/200] Iteration[005/008] Valid loss: 0.1097
2023-02-06 16:00:45 | Valid | Epoch[073/200] Iteration[006/008] Valid loss: 0.1084
2023-02-06 16:00:45 | Valid | Epoch[073/200] Iteration[007/008] Valid loss: 0.1105
2023-02-06 16:00:45 | Valid | Epoch[073/200] Iteration[008/008] Valid loss: 0.1098
2023-02-06 16:00:45 | Valid | Epoch[073/200] MIou: 0.933090831790018
2023-02-06 16:00:45 | Valid | Epoch[073/200] Pixel Accuracy: 0.9883232116699219
2023-02-06 16:00:45 | Valid | Epoch[073/200] Mean Pixel Accuracy: 0.9659565047526799
2023-02-06 16:00:45 | Stage | Epoch[073/200] Train loss:0.0695
2023-02-06 16:00:45 | Stage | Epoch[073/200] Valid loss:0.1098
2023-02-06 16:00:45 | Stage | Epoch[073/200] LR:0.01

2023-02-06 16:00:46 | Train | Epoch[074/200] Iteration[001/030] Train loss: 0.0659
2023-02-06 16:00:46 | Train | Epoch[074/200] Iteration[002/030] Train loss: 0.0664
2023-02-06 16:00:47 | Train | Epoch[074/200] Iteration[003/030] Train loss: 0.0666
2023-02-06 16:00:47 | Train | Epoch[074/200] Iteration[004/030] Train loss: 0.0666
2023-02-06 16:00:48 | Train | Epoch[074/200] Iteration[005/030] Train loss: 0.0669
2023-02-06 16:00:48 | Train | Epoch[074/200] Iteration[006/030] Train loss: 0.0668
2023-02-06 16:00:49 | Train | Epoch[074/200] Iteration[007/030] Train loss: 0.0668
2023-02-06 16:00:49 | Train | Epoch[074/200] Iteration[008/030] Train loss: 0.0667
2023-02-06 16:00:49 | Train | Epoch[074/200] Iteration[009/030] Train loss: 0.0668
2023-02-06 16:00:50 | Train | Epoch[074/200] Iteration[010/030] Train loss: 0.0669
2023-02-06 16:00:50 | Train | Epoch[074/200] Iteration[011/030] Train loss: 0.0670
2023-02-06 16:00:51 | Train | Epoch[074/200] Iteration[012/030] Train loss: 0.0671
2023-02-06 16:00:51 | Train | Epoch[074/200] Iteration[013/030] Train loss: 0.0672
2023-02-06 16:00:52 | Train | Epoch[074/200] Iteration[014/030] Train loss: 0.0673
2023-02-06 16:00:52 | Train | Epoch[074/200] Iteration[015/030] Train loss: 0.0673
2023-02-06 16:00:52 | Train | Epoch[074/200] Iteration[016/030] Train loss: 0.0673
2023-02-06 16:00:53 | Train | Epoch[074/200] Iteration[017/030] Train loss: 0.0673
2023-02-06 16:00:53 | Train | Epoch[074/200] Iteration[018/030] Train loss: 0.0677
2023-02-06 16:00:54 | Train | Epoch[074/200] Iteration[019/030] Train loss: 0.0678
2023-02-06 16:00:54 | Train | Epoch[074/200] Iteration[020/030] Train loss: 0.0679
2023-02-06 16:00:55 | Train | Epoch[074/200] Iteration[021/030] Train loss: 0.0679
2023-02-06 16:00:55 | Train | Epoch[074/200] Iteration[022/030] Train loss: 0.0678
2023-02-06 16:00:56 | Train | Epoch[074/200] Iteration[023/030] Train loss: 0.0678
2023-02-06 16:00:56 | Train | Epoch[074/200] Iteration[024/030] Train loss: 0.0678
2023-02-06 16:00:56 | Train | Epoch[074/200] Iteration[025/030] Train loss: 0.0678
2023-02-06 16:00:57 | Train | Epoch[074/200] Iteration[026/030] Train loss: 0.0678
2023-02-06 16:00:57 | Train | Epoch[074/200] Iteration[027/030] Train loss: 0.0678
2023-02-06 16:00:58 | Train | Epoch[074/200] Iteration[028/030] Train loss: 0.0678
2023-02-06 16:00:58 | Train | Epoch[074/200] Iteration[029/030] Train loss: 0.0680
2023-02-06 16:00:58 | Train | Epoch[074/200] Iteration[030/030] Train loss: 0.0681
2023-02-06 16:00:59 | Valid | Epoch[074/200] Iteration[001/008] Valid loss: 1.1994
2023-02-06 16:00:59 | Valid | Epoch[074/200] Iteration[002/008] Valid loss: 1.2403
2023-02-06 16:00:59 | Valid | Epoch[074/200] Iteration[003/008] Valid loss: 1.2551
2023-02-06 16:00:59 | Valid | Epoch[074/200] Iteration[004/008] Valid loss: 1.2886
2023-02-06 16:00:59 | Valid | Epoch[074/200] Iteration[005/008] Valid loss: 1.3261
2023-02-06 16:00:59 | Valid | Epoch[074/200] Iteration[006/008] Valid loss: 1.2978
2023-02-06 16:00:59 | Valid | Epoch[074/200] Iteration[007/008] Valid loss: 1.3425
2023-02-06 16:00:59 | Valid | Epoch[074/200] Iteration[008/008] Valid loss: 1.3963
2023-02-06 16:01:00 | Valid | Epoch[074/200] MIou: 0.8129795764474873
2023-02-06 16:01:00 | Valid | Epoch[074/200] Pixel Accuracy: 0.9564488728841146
2023-02-06 16:01:00 | Valid | Epoch[074/200] Mean Pixel Accuracy: 0.9743061325176154
2023-02-06 16:01:00 | Stage | Epoch[074/200] Train loss:0.0681
2023-02-06 16:01:00 | Stage | Epoch[074/200] Valid loss:1.3963
2023-02-06 16:01:00 | Stage | Epoch[074/200] LR:0.01

2023-02-06 16:01:00 | Train | Epoch[075/200] Iteration[001/030] Train loss: 0.0670
2023-02-06 16:01:01 | Train | Epoch[075/200] Iteration[002/030] Train loss: 0.0670
2023-02-06 16:01:01 | Train | Epoch[075/200] Iteration[003/030] Train loss: 0.0675
2023-02-06 16:01:02 | Train | Epoch[075/200] Iteration[004/030] Train loss: 0.0679
2023-02-06 16:01:02 | Train | Epoch[075/200] Iteration[005/030] Train loss: 0.0680
2023-02-06 16:01:02 | Train | Epoch[075/200] Iteration[006/030] Train loss: 0.0678
2023-02-06 16:01:03 | Train | Epoch[075/200] Iteration[007/030] Train loss: 0.0676
2023-02-06 16:01:03 | Train | Epoch[075/200] Iteration[008/030] Train loss: 0.0675
2023-02-06 16:01:04 | Train | Epoch[075/200] Iteration[009/030] Train loss: 0.0679
2023-02-06 16:01:04 | Train | Epoch[075/200] Iteration[010/030] Train loss: 0.0678
2023-02-06 16:01:05 | Train | Epoch[075/200] Iteration[011/030] Train loss: 0.0678
2023-02-06 16:01:05 | Train | Epoch[075/200] Iteration[012/030] Train loss: 0.0676
2023-02-06 16:01:05 | Train | Epoch[075/200] Iteration[013/030] Train loss: 0.0677
2023-02-06 16:01:06 | Train | Epoch[075/200] Iteration[014/030] Train loss: 0.0677
2023-02-06 16:01:06 | Train | Epoch[075/200] Iteration[015/030] Train loss: 0.0676
2023-02-06 16:01:07 | Train | Epoch[075/200] Iteration[016/030] Train loss: 0.0676
2023-02-06 16:01:07 | Train | Epoch[075/200] Iteration[017/030] Train loss: 0.0675
2023-02-06 16:01:08 | Train | Epoch[075/200] Iteration[018/030] Train loss: 0.0675
2023-02-06 16:01:08 | Train | Epoch[075/200] Iteration[019/030] Train loss: 0.0675
2023-02-06 16:01:09 | Train | Epoch[075/200] Iteration[020/030] Train loss: 0.0674
2023-02-06 16:01:09 | Train | Epoch[075/200] Iteration[021/030] Train loss: 0.0674
2023-02-06 16:01:09 | Train | Epoch[075/200] Iteration[022/030] Train loss: 0.0673
2023-02-06 16:01:10 | Train | Epoch[075/200] Iteration[023/030] Train loss: 0.0672
2023-02-06 16:01:10 | Train | Epoch[075/200] Iteration[024/030] Train loss: 0.0672
2023-02-06 16:01:11 | Train | Epoch[075/200] Iteration[025/030] Train loss: 0.0672
2023-02-06 16:01:11 | Train | Epoch[075/200] Iteration[026/030] Train loss: 0.0672
2023-02-06 16:01:12 | Train | Epoch[075/200] Iteration[027/030] Train loss: 0.0674
2023-02-06 16:01:12 | Train | Epoch[075/200] Iteration[028/030] Train loss: 0.0673
2023-02-06 16:01:12 | Train | Epoch[075/200] Iteration[029/030] Train loss: 0.0673
2023-02-06 16:01:13 | Train | Epoch[075/200] Iteration[030/030] Train loss: 0.0675
2023-02-06 16:01:13 | Valid | Epoch[075/200] Iteration[001/008] Valid loss: 0.1153
2023-02-06 16:01:13 | Valid | Epoch[075/200] Iteration[002/008] Valid loss: 0.1089
2023-02-06 16:01:13 | Valid | Epoch[075/200] Iteration[003/008] Valid loss: 0.1064
2023-02-06 16:01:13 | Valid | Epoch[075/200] Iteration[004/008] Valid loss: 0.1057
2023-02-06 16:01:13 | Valid | Epoch[075/200] Iteration[005/008] Valid loss: 0.1050
2023-02-06 16:01:13 | Valid | Epoch[075/200] Iteration[006/008] Valid loss: 0.1048
2023-02-06 16:01:14 | Valid | Epoch[075/200] Iteration[007/008] Valid loss: 0.1045
2023-02-06 16:01:14 | Valid | Epoch[075/200] Iteration[008/008] Valid loss: 0.1036
2023-02-06 16:01:14 | Valid | Epoch[075/200] MIou: 0.8783077395929654
2023-02-06 16:01:14 | Valid | Epoch[075/200] Pixel Accuracy: 0.9795735677083334
2023-02-06 16:01:14 | Valid | Epoch[075/200] Mean Pixel Accuracy: 0.8966520510472255
2023-02-06 16:01:14 | Stage | Epoch[075/200] Train loss:0.0675
2023-02-06 16:01:14 | Stage | Epoch[075/200] Valid loss:0.1036
2023-02-06 16:01:14 | Stage | Epoch[075/200] LR:0.01

2023-02-06 16:01:15 | Train | Epoch[076/200] Iteration[001/030] Train loss: 0.0668
2023-02-06 16:01:15 | Train | Epoch[076/200] Iteration[002/030] Train loss: 0.0661
2023-02-06 16:01:15 | Train | Epoch[076/200] Iteration[003/030] Train loss: 0.0658
2023-02-06 16:01:16 | Train | Epoch[076/200] Iteration[004/030] Train loss: 0.0657
2023-02-06 16:01:16 | Train | Epoch[076/200] Iteration[005/030] Train loss: 0.0655
2023-02-06 16:01:17 | Train | Epoch[076/200] Iteration[006/030] Train loss: 0.0654
2023-02-06 16:01:17 | Train | Epoch[076/200] Iteration[007/030] Train loss: 0.0655
2023-02-06 16:01:18 | Train | Epoch[076/200] Iteration[008/030] Train loss: 0.0657
2023-02-06 16:01:18 | Train | Epoch[076/200] Iteration[009/030] Train loss: 0.0657
2023-02-06 16:01:18 | Train | Epoch[076/200] Iteration[010/030] Train loss: 0.0658
2023-02-06 16:01:19 | Train | Epoch[076/200] Iteration[011/030] Train loss: 0.0658
2023-02-06 16:01:19 | Train | Epoch[076/200] Iteration[012/030] Train loss: 0.0658
2023-02-06 16:01:20 | Train | Epoch[076/200] Iteration[013/030] Train loss: 0.0659
2023-02-06 16:01:20 | Train | Epoch[076/200] Iteration[014/030] Train loss: 0.0659
2023-02-06 16:01:21 | Train | Epoch[076/200] Iteration[015/030] Train loss: 0.0658
2023-02-06 16:01:21 | Train | Epoch[076/200] Iteration[016/030] Train loss: 0.0657
2023-02-06 16:01:21 | Train | Epoch[076/200] Iteration[017/030] Train loss: 0.0659
2023-02-06 16:01:22 | Train | Epoch[076/200] Iteration[018/030] Train loss: 0.0661
2023-02-06 16:01:22 | Train | Epoch[076/200] Iteration[019/030] Train loss: 0.0660
2023-02-06 16:01:23 | Train | Epoch[076/200] Iteration[020/030] Train loss: 0.0660
2023-02-06 16:01:23 | Train | Epoch[076/200] Iteration[021/030] Train loss: 0.0661
2023-02-06 16:01:24 | Train | Epoch[076/200] Iteration[022/030] Train loss: 0.0660
2023-02-06 16:01:24 | Train | Epoch[076/200] Iteration[023/030] Train loss: 0.0660
2023-02-06 16:01:24 | Train | Epoch[076/200] Iteration[024/030] Train loss: 0.0660
2023-02-06 16:01:25 | Train | Epoch[076/200] Iteration[025/030] Train loss: 0.0661
2023-02-06 16:01:25 | Train | Epoch[076/200] Iteration[026/030] Train loss: 0.0661
2023-02-06 16:01:26 | Train | Epoch[076/200] Iteration[027/030] Train loss: 0.0661
2023-02-06 16:01:26 | Train | Epoch[076/200] Iteration[028/030] Train loss: 0.0662
2023-02-06 16:01:27 | Train | Epoch[076/200] Iteration[029/030] Train loss: 0.0661
2023-02-06 16:01:27 | Train | Epoch[076/200] Iteration[030/030] Train loss: 0.0660
2023-02-06 16:01:27 | Valid | Epoch[076/200] Iteration[001/008] Valid loss: 0.1389
2023-02-06 16:01:27 | Valid | Epoch[076/200] Iteration[002/008] Valid loss: 0.1435
2023-02-06 16:01:27 | Valid | Epoch[076/200] Iteration[003/008] Valid loss: 0.1507
2023-02-06 16:01:28 | Valid | Epoch[076/200] Iteration[004/008] Valid loss: 0.1490
2023-02-06 16:01:28 | Valid | Epoch[076/200] Iteration[005/008] Valid loss: 0.1538
2023-02-06 16:01:28 | Valid | Epoch[076/200] Iteration[006/008] Valid loss: 0.1534
2023-02-06 16:01:28 | Valid | Epoch[076/200] Iteration[007/008] Valid loss: 0.1525
2023-02-06 16:01:28 | Valid | Epoch[076/200] Iteration[008/008] Valid loss: 0.1586
2023-02-06 16:01:28 | Valid | Epoch[076/200] MIou: 0.5500756469116047
2023-02-06 16:01:28 | Valid | Epoch[076/200] Pixel Accuracy: 0.9250958760579427
2023-02-06 16:01:28 | Valid | Epoch[076/200] Mean Pixel Accuracy: 0.5884001317475855
2023-02-06 16:01:28 | Stage | Epoch[076/200] Train loss:0.0660
2023-02-06 16:01:28 | Stage | Epoch[076/200] Valid loss:0.1586
2023-02-06 16:01:28 | Stage | Epoch[076/200] LR:0.01

2023-02-06 16:01:29 | Train | Epoch[077/200] Iteration[001/030] Train loss: 0.0629
2023-02-06 16:01:29 | Train | Epoch[077/200] Iteration[002/030] Train loss: 0.0640
2023-02-06 16:01:30 | Train | Epoch[077/200] Iteration[003/030] Train loss: 0.0639
2023-02-06 16:01:30 | Train | Epoch[077/200] Iteration[004/030] Train loss: 0.0646
2023-02-06 16:01:30 | Train | Epoch[077/200] Iteration[005/030] Train loss: 0.0642
2023-02-06 16:01:31 | Train | Epoch[077/200] Iteration[006/030] Train loss: 0.0642
2023-02-06 16:01:31 | Train | Epoch[077/200] Iteration[007/030] Train loss: 0.0641
2023-02-06 16:01:32 | Train | Epoch[077/200] Iteration[008/030] Train loss: 0.0640
2023-02-06 16:01:32 | Train | Epoch[077/200] Iteration[009/030] Train loss: 0.0640
2023-02-06 16:01:33 | Train | Epoch[077/200] Iteration[010/030] Train loss: 0.0640
2023-02-06 16:01:33 | Train | Epoch[077/200] Iteration[011/030] Train loss: 0.0639
2023-02-06 16:01:34 | Train | Epoch[077/200] Iteration[012/030] Train loss: 0.0639
2023-02-06 16:01:34 | Train | Epoch[077/200] Iteration[013/030] Train loss: 0.0639
2023-02-06 16:01:34 | Train | Epoch[077/200] Iteration[014/030] Train loss: 0.0638
2023-02-06 16:01:35 | Train | Epoch[077/200] Iteration[015/030] Train loss: 0.0638
2023-02-06 16:01:35 | Train | Epoch[077/200] Iteration[016/030] Train loss: 0.0638
2023-02-06 16:01:36 | Train | Epoch[077/200] Iteration[017/030] Train loss: 0.0638
2023-02-06 16:01:36 | Train | Epoch[077/200] Iteration[018/030] Train loss: 0.0639
2023-02-06 16:01:37 | Train | Epoch[077/200] Iteration[019/030] Train loss: 0.0640
2023-02-06 16:01:37 | Train | Epoch[077/200] Iteration[020/030] Train loss: 0.0641
2023-02-06 16:01:37 | Train | Epoch[077/200] Iteration[021/030] Train loss: 0.0641
2023-02-06 16:01:38 | Train | Epoch[077/200] Iteration[022/030] Train loss: 0.0642
2023-02-06 16:01:38 | Train | Epoch[077/200] Iteration[023/030] Train loss: 0.0642
2023-02-06 16:01:39 | Train | Epoch[077/200] Iteration[024/030] Train loss: 0.0641
2023-02-06 16:01:39 | Train | Epoch[077/200] Iteration[025/030] Train loss: 0.0642
2023-02-06 16:01:40 | Train | Epoch[077/200] Iteration[026/030] Train loss: 0.0642
2023-02-06 16:01:40 | Train | Epoch[077/200] Iteration[027/030] Train loss: 0.0642
2023-02-06 16:01:40 | Train | Epoch[077/200] Iteration[028/030] Train loss: 0.0641
2023-02-06 16:01:41 | Train | Epoch[077/200] Iteration[029/030] Train loss: 0.0641
2023-02-06 16:01:41 | Train | Epoch[077/200] Iteration[030/030] Train loss: 0.0641
2023-02-06 16:01:42 | Valid | Epoch[077/200] Iteration[001/008] Valid loss: 0.1263
2023-02-06 16:01:42 | Valid | Epoch[077/200] Iteration[002/008] Valid loss: 0.1049
2023-02-06 16:01:42 | Valid | Epoch[077/200] Iteration[003/008] Valid loss: 0.0971
2023-02-06 16:01:42 | Valid | Epoch[077/200] Iteration[004/008] Valid loss: 0.0938
2023-02-06 16:01:42 | Valid | Epoch[077/200] Iteration[005/008] Valid loss: 0.0942
2023-02-06 16:01:42 | Valid | Epoch[077/200] Iteration[006/008] Valid loss: 0.0929
2023-02-06 16:01:42 | Valid | Epoch[077/200] Iteration[007/008] Valid loss: 0.0954
2023-02-06 16:01:42 | Valid | Epoch[077/200] Iteration[008/008] Valid loss: 0.0944
2023-02-06 16:01:42 | Valid | Epoch[077/200] MIou: 0.929816628505129
2023-02-06 16:01:42 | Valid | Epoch[077/200] Pixel Accuracy: 0.9880294799804688
2023-02-06 16:01:42 | Valid | Epoch[077/200] Mean Pixel Accuracy: 0.9521630435378312
2023-02-06 16:01:42 | Stage | Epoch[077/200] Train loss:0.0641
2023-02-06 16:01:42 | Stage | Epoch[077/200] Valid loss:0.0944
2023-02-06 16:01:42 | Stage | Epoch[077/200] LR:0.01

2023-02-06 16:01:43 | Train | Epoch[078/200] Iteration[001/030] Train loss: 0.0630
2023-02-06 16:01:43 | Train | Epoch[078/200] Iteration[002/030] Train loss: 0.0626
2023-02-06 16:01:44 | Train | Epoch[078/200] Iteration[003/030] Train loss: 0.0619
2023-02-06 16:01:44 | Train | Epoch[078/200] Iteration[004/030] Train loss: 0.0622
2023-02-06 16:01:45 | Train | Epoch[078/200] Iteration[005/030] Train loss: 0.0624
2023-02-06 16:01:45 | Train | Epoch[078/200] Iteration[006/030] Train loss: 0.0622
2023-02-06 16:01:46 | Train | Epoch[078/200] Iteration[007/030] Train loss: 0.0623
2023-02-06 16:01:46 | Train | Epoch[078/200] Iteration[008/030] Train loss: 0.0622
2023-02-06 16:01:46 | Train | Epoch[078/200] Iteration[009/030] Train loss: 0.0623
2023-02-06 16:01:47 | Train | Epoch[078/200] Iteration[010/030] Train loss: 0.0625
2023-02-06 16:01:47 | Train | Epoch[078/200] Iteration[011/030] Train loss: 0.0632
2023-02-06 16:01:48 | Train | Epoch[078/200] Iteration[012/030] Train loss: 0.0632
2023-02-06 16:01:48 | Train | Epoch[078/200] Iteration[013/030] Train loss: 0.0632
2023-02-06 16:01:49 | Train | Epoch[078/200] Iteration[014/030] Train loss: 0.0633
2023-02-06 16:01:49 | Train | Epoch[078/200] Iteration[015/030] Train loss: 0.0633
2023-02-06 16:01:49 | Train | Epoch[078/200] Iteration[016/030] Train loss: 0.0632
2023-02-06 16:01:50 | Train | Epoch[078/200] Iteration[017/030] Train loss: 0.0632
2023-02-06 16:01:50 | Train | Epoch[078/200] Iteration[018/030] Train loss: 0.0632
2023-02-06 16:01:51 | Train | Epoch[078/200] Iteration[019/030] Train loss: 0.0632
2023-02-06 16:01:51 | Train | Epoch[078/200] Iteration[020/030] Train loss: 0.0631
2023-02-06 16:01:52 | Train | Epoch[078/200] Iteration[021/030] Train loss: 0.0630
2023-02-06 16:01:52 | Train | Epoch[078/200] Iteration[022/030] Train loss: 0.0631
2023-02-06 16:01:53 | Train | Epoch[078/200] Iteration[023/030] Train loss: 0.0631
2023-02-06 16:01:53 | Train | Epoch[078/200] Iteration[024/030] Train loss: 0.0631
2023-02-06 16:01:53 | Train | Epoch[078/200] Iteration[025/030] Train loss: 0.0632
2023-02-06 16:01:54 | Train | Epoch[078/200] Iteration[026/030] Train loss: 0.0631
2023-02-06 16:01:54 | Train | Epoch[078/200] Iteration[027/030] Train loss: 0.0632
2023-02-06 16:01:55 | Train | Epoch[078/200] Iteration[028/030] Train loss: 0.0632
2023-02-06 16:01:55 | Train | Epoch[078/200] Iteration[029/030] Train loss: 0.0631
2023-02-06 16:01:55 | Train | Epoch[078/200] Iteration[030/030] Train loss: 0.0630
2023-02-06 16:01:56 | Valid | Epoch[078/200] Iteration[001/008] Valid loss: 0.1223
2023-02-06 16:01:56 | Valid | Epoch[078/200] Iteration[002/008] Valid loss: 0.1152
2023-02-06 16:01:56 | Valid | Epoch[078/200] Iteration[003/008] Valid loss: 0.1144
2023-02-06 16:01:56 | Valid | Epoch[078/200] Iteration[004/008] Valid loss: 0.1130
2023-02-06 16:01:56 | Valid | Epoch[078/200] Iteration[005/008] Valid loss: 0.1136
2023-02-06 16:01:56 | Valid | Epoch[078/200] Iteration[006/008] Valid loss: 0.1139
2023-02-06 16:01:56 | Valid | Epoch[078/200] Iteration[007/008] Valid loss: 0.1144
2023-02-06 16:01:56 | Valid | Epoch[078/200] Iteration[008/008] Valid loss: 0.1144
2023-02-06 16:01:56 | Valid | Epoch[078/200] MIou: 0.8907535600825502
2023-02-06 16:01:56 | Valid | Epoch[078/200] Pixel Accuracy: 0.9813003540039062
2023-02-06 16:01:56 | Valid | Epoch[078/200] Mean Pixel Accuracy: 0.9164196858887794
2023-02-06 16:01:56 | Stage | Epoch[078/200] Train loss:0.0630
2023-02-06 16:01:56 | Stage | Epoch[078/200] Valid loss:0.1144
2023-02-06 16:01:56 | Stage | Epoch[078/200] LR:0.01

2023-02-06 16:01:57 | Train | Epoch[079/200] Iteration[001/030] Train loss: 0.0632
2023-02-06 16:01:58 | Train | Epoch[079/200] Iteration[002/030] Train loss: 0.0620
2023-02-06 16:01:58 | Train | Epoch[079/200] Iteration[003/030] Train loss: 0.0625
2023-02-06 16:01:58 | Train | Epoch[079/200] Iteration[004/030] Train loss: 0.0620
2023-02-06 16:01:59 | Train | Epoch[079/200] Iteration[005/030] Train loss: 0.0619
2023-02-06 16:01:59 | Train | Epoch[079/200] Iteration[006/030] Train loss: 0.0617
2023-02-06 16:02:00 | Train | Epoch[079/200] Iteration[007/030] Train loss: 0.0615
2023-02-06 16:02:00 | Train | Epoch[079/200] Iteration[008/030] Train loss: 0.0615
2023-02-06 16:02:01 | Train | Epoch[079/200] Iteration[009/030] Train loss: 0.0614
2023-02-06 16:02:01 | Train | Epoch[079/200] Iteration[010/030] Train loss: 0.0614
2023-02-06 16:02:02 | Train | Epoch[079/200] Iteration[011/030] Train loss: 0.0614
2023-02-06 16:02:02 | Train | Epoch[079/200] Iteration[012/030] Train loss: 0.0613
2023-02-06 16:02:02 | Train | Epoch[079/200] Iteration[013/030] Train loss: 0.0613
2023-02-06 16:02:03 | Train | Epoch[079/200] Iteration[014/030] Train loss: 0.0613
2023-02-06 16:02:03 | Train | Epoch[079/200] Iteration[015/030] Train loss: 0.0614
2023-02-06 16:02:04 | Train | Epoch[079/200] Iteration[016/030] Train loss: 0.0614
2023-02-06 16:02:04 | Train | Epoch[079/200] Iteration[017/030] Train loss: 0.0614
2023-02-06 16:02:05 | Train | Epoch[079/200] Iteration[018/030] Train loss: 0.0615
2023-02-06 16:02:05 | Train | Epoch[079/200] Iteration[019/030] Train loss: 0.0614
2023-02-06 16:02:05 | Train | Epoch[079/200] Iteration[020/030] Train loss: 0.0614
2023-02-06 16:02:06 | Train | Epoch[079/200] Iteration[021/030] Train loss: 0.0613
2023-02-06 16:02:06 | Train | Epoch[079/200] Iteration[022/030] Train loss: 0.0613
2023-02-06 16:02:07 | Train | Epoch[079/200] Iteration[023/030] Train loss: 0.0616
2023-02-06 16:02:07 | Train | Epoch[079/200] Iteration[024/030] Train loss: 0.0617
2023-02-06 16:02:08 | Train | Epoch[079/200] Iteration[025/030] Train loss: 0.0616
2023-02-06 16:02:08 | Train | Epoch[079/200] Iteration[026/030] Train loss: 0.0616
2023-02-06 16:02:08 | Train | Epoch[079/200] Iteration[027/030] Train loss: 0.0615
2023-02-06 16:02:09 | Train | Epoch[079/200] Iteration[028/030] Train loss: 0.0616
2023-02-06 16:02:09 | Train | Epoch[079/200] Iteration[029/030] Train loss: 0.0616
2023-02-06 16:02:09 | Train | Epoch[079/200] Iteration[030/030] Train loss: 0.0616
2023-02-06 16:02:10 | Valid | Epoch[079/200] Iteration[001/008] Valid loss: 0.1030
2023-02-06 16:02:10 | Valid | Epoch[079/200] Iteration[002/008] Valid loss: 0.0992
2023-02-06 16:02:10 | Valid | Epoch[079/200] Iteration[003/008] Valid loss: 0.1018
2023-02-06 16:02:10 | Valid | Epoch[079/200] Iteration[004/008] Valid loss: 0.1001
2023-02-06 16:02:10 | Valid | Epoch[079/200] Iteration[005/008] Valid loss: 0.1016
2023-02-06 16:02:11 | Valid | Epoch[079/200] Iteration[006/008] Valid loss: 0.1016
2023-02-06 16:02:11 | Valid | Epoch[079/200] Iteration[007/008] Valid loss: 0.1016
2023-02-06 16:02:11 | Valid | Epoch[079/200] Iteration[008/008] Valid loss: 0.1034
2023-02-06 16:02:11 | Valid | Epoch[079/200] MIou: 0.7929705202301858
2023-02-06 16:02:11 | Valid | Epoch[079/200] Pixel Accuracy: 0.9653091430664062
2023-02-06 16:02:11 | Valid | Epoch[079/200] Mean Pixel Accuracy: 0.8161118685435182
2023-02-06 16:02:11 | Stage | Epoch[079/200] Train loss:0.0616
2023-02-06 16:02:11 | Stage | Epoch[079/200] Valid loss:0.1034
2023-02-06 16:02:11 | Stage | Epoch[079/200] LR:0.01

2023-02-06 16:02:12 | Train | Epoch[080/200] Iteration[001/030] Train loss: 0.0614
2023-02-06 16:02:12 | Train | Epoch[080/200] Iteration[002/030] Train loss: 0.0603
2023-02-06 16:02:12 | Train | Epoch[080/200] Iteration[003/030] Train loss: 0.0600
2023-02-06 16:02:13 | Train | Epoch[080/200] Iteration[004/030] Train loss: 0.0606
2023-02-06 16:02:13 | Train | Epoch[080/200] Iteration[005/030] Train loss: 0.0604
2023-02-06 16:02:14 | Train | Epoch[080/200] Iteration[006/030] Train loss: 0.0609
2023-02-06 16:02:14 | Train | Epoch[080/200] Iteration[007/030] Train loss: 0.0612
2023-02-06 16:02:15 | Train | Epoch[080/200] Iteration[008/030] Train loss: 0.0613
2023-02-06 16:02:15 | Train | Epoch[080/200] Iteration[009/030] Train loss: 0.0613
2023-02-06 16:02:15 | Train | Epoch[080/200] Iteration[010/030] Train loss: 0.0615
2023-02-06 16:02:16 | Train | Epoch[080/200] Iteration[011/030] Train loss: 0.0614
2023-02-06 16:02:16 | Train | Epoch[080/200] Iteration[012/030] Train loss: 0.0612
2023-02-06 16:02:17 | Train | Epoch[080/200] Iteration[013/030] Train loss: 0.0612
2023-02-06 16:02:17 | Train | Epoch[080/200] Iteration[014/030] Train loss: 0.0611
2023-02-06 16:02:18 | Train | Epoch[080/200] Iteration[015/030] Train loss: 0.0610
2023-02-06 16:02:18 | Train | Epoch[080/200] Iteration[016/030] Train loss: 0.0609
2023-02-06 16:02:19 | Train | Epoch[080/200] Iteration[017/030] Train loss: 0.0608
2023-02-06 16:02:19 | Train | Epoch[080/200] Iteration[018/030] Train loss: 0.0608
2023-02-06 16:02:19 | Train | Epoch[080/200] Iteration[019/030] Train loss: 0.0609
2023-02-06 16:02:20 | Train | Epoch[080/200] Iteration[020/030] Train loss: 0.0608
2023-02-06 16:02:20 | Train | Epoch[080/200] Iteration[021/030] Train loss: 0.0607
2023-02-06 16:02:21 | Train | Epoch[080/200] Iteration[022/030] Train loss: 0.0606
2023-02-06 16:02:21 | Train | Epoch[080/200] Iteration[023/030] Train loss: 0.0606
2023-02-06 16:02:22 | Train | Epoch[080/200] Iteration[024/030] Train loss: 0.0606
2023-02-06 16:02:22 | Train | Epoch[080/200] Iteration[025/030] Train loss: 0.0606
2023-02-06 16:02:22 | Train | Epoch[080/200] Iteration[026/030] Train loss: 0.0605
2023-02-06 16:02:23 | Train | Epoch[080/200] Iteration[027/030] Train loss: 0.0605
2023-02-06 16:02:23 | Train | Epoch[080/200] Iteration[028/030] Train loss: 0.0604
2023-02-06 16:02:24 | Train | Epoch[080/200] Iteration[029/030] Train loss: 0.0604
2023-02-06 16:02:24 | Train | Epoch[080/200] Iteration[030/030] Train loss: 0.0604
2023-02-06 16:02:24 | Valid | Epoch[080/200] Iteration[001/008] Valid loss: 0.1025
2023-02-06 16:02:25 | Valid | Epoch[080/200] Iteration[002/008] Valid loss: 0.0885
2023-02-06 16:02:25 | Valid | Epoch[080/200] Iteration[003/008] Valid loss: 0.0839
2023-02-06 16:02:25 | Valid | Epoch[080/200] Iteration[004/008] Valid loss: 0.0811
2023-02-06 16:02:25 | Valid | Epoch[080/200] Iteration[005/008] Valid loss: 0.0807
2023-02-06 16:02:25 | Valid | Epoch[080/200] Iteration[006/008] Valid loss: 0.0798
2023-02-06 16:02:25 | Valid | Epoch[080/200] Iteration[007/008] Valid loss: 0.0809
2023-02-06 16:02:25 | Valid | Epoch[080/200] Iteration[008/008] Valid loss: 0.0811
2023-02-06 16:02:25 | Valid | Epoch[080/200] MIou: 0.9204509574815505
2023-02-06 16:02:25 | Valid | Epoch[080/200] Pixel Accuracy: 0.9865595499674479
2023-02-06 16:02:25 | Valid | Epoch[080/200] Mean Pixel Accuracy: 0.9390482521067294
2023-02-06 16:02:25 | Stage | Epoch[080/200] Train loss:0.0604
2023-02-06 16:02:25 | Stage | Epoch[080/200] Valid loss:0.0811
2023-02-06 16:02:25 | Stage | Epoch[080/200] LR:0.01

2023-02-06 16:02:26 | Train | Epoch[081/200] Iteration[001/030] Train loss: 0.0592
2023-02-06 16:02:26 | Train | Epoch[081/200] Iteration[002/030] Train loss: 0.0584
2023-02-06 16:02:27 | Train | Epoch[081/200] Iteration[003/030] Train loss: 0.0596
2023-02-06 16:02:27 | Train | Epoch[081/200] Iteration[004/030] Train loss: 0.0597
2023-02-06 16:02:28 | Train | Epoch[081/200] Iteration[005/030] Train loss: 0.0598
2023-02-06 16:02:28 | Train | Epoch[081/200] Iteration[006/030] Train loss: 0.0597
2023-02-06 16:02:29 | Train | Epoch[081/200] Iteration[007/030] Train loss: 0.0596
2023-02-06 16:02:29 | Train | Epoch[081/200] Iteration[008/030] Train loss: 0.0596
2023-02-06 16:02:29 | Train | Epoch[081/200] Iteration[009/030] Train loss: 0.0594
2023-02-06 16:02:30 | Train | Epoch[081/200] Iteration[010/030] Train loss: 0.0595
2023-02-06 16:02:30 | Train | Epoch[081/200] Iteration[011/030] Train loss: 0.0593
2023-02-06 16:02:31 | Train | Epoch[081/200] Iteration[012/030] Train loss: 0.0593
2023-02-06 16:02:31 | Train | Epoch[081/200] Iteration[013/030] Train loss: 0.0592
2023-02-06 16:02:32 | Train | Epoch[081/200] Iteration[014/030] Train loss: 0.0591
2023-02-06 16:02:32 | Train | Epoch[081/200] Iteration[015/030] Train loss: 0.0593
2023-02-06 16:02:32 | Train | Epoch[081/200] Iteration[016/030] Train loss: 0.0596
2023-02-06 16:02:33 | Train | Epoch[081/200] Iteration[017/030] Train loss: 0.0596
2023-02-06 16:02:33 | Train | Epoch[081/200] Iteration[018/030] Train loss: 0.0596
2023-02-06 16:02:34 | Train | Epoch[081/200] Iteration[019/030] Train loss: 0.0596
2023-02-06 16:02:34 | Train | Epoch[081/200] Iteration[020/030] Train loss: 0.0596
2023-02-06 16:02:35 | Train | Epoch[081/200] Iteration[021/030] Train loss: 0.0596
2023-02-06 16:02:35 | Train | Epoch[081/200] Iteration[022/030] Train loss: 0.0596
2023-02-06 16:02:35 | Train | Epoch[081/200] Iteration[023/030] Train loss: 0.0596
2023-02-06 16:02:36 | Train | Epoch[081/200] Iteration[024/030] Train loss: 0.0595
2023-02-06 16:02:36 | Train | Epoch[081/200] Iteration[025/030] Train loss: 0.0595
2023-02-06 16:02:37 | Train | Epoch[081/200] Iteration[026/030] Train loss: 0.0595
2023-02-06 16:02:37 | Train | Epoch[081/200] Iteration[027/030] Train loss: 0.0595
2023-02-06 16:02:38 | Train | Epoch[081/200] Iteration[028/030] Train loss: 0.0595
2023-02-06 16:02:38 | Train | Epoch[081/200] Iteration[029/030] Train loss: 0.0594
2023-02-06 16:02:38 | Train | Epoch[081/200] Iteration[030/030] Train loss: 0.0594
2023-02-06 16:02:39 | Valid | Epoch[081/200] Iteration[001/008] Valid loss: 0.5463
2023-02-06 16:02:39 | Valid | Epoch[081/200] Iteration[002/008] Valid loss: 0.4824
2023-02-06 16:02:39 | Valid | Epoch[081/200] Iteration[003/008] Valid loss: 0.4785
2023-02-06 16:02:39 | Valid | Epoch[081/200] Iteration[004/008] Valid loss: 0.4831
2023-02-06 16:02:39 | Valid | Epoch[081/200] Iteration[005/008] Valid loss: 0.4908
2023-02-06 16:02:39 | Valid | Epoch[081/200] Iteration[006/008] Valid loss: 0.4776
2023-02-06 16:02:39 | Valid | Epoch[081/200] Iteration[007/008] Valid loss: 0.5070
2023-02-06 16:02:39 | Valid | Epoch[081/200] Iteration[008/008] Valid loss: 0.5137
2023-02-06 16:02:39 | Valid | Epoch[081/200] MIou: 0.8446005438485716
2023-02-06 16:02:39 | Valid | Epoch[081/200] Pixel Accuracy: 0.9663263956705729
2023-02-06 16:02:39 | Valid | Epoch[081/200] Mean Pixel Accuracy: 0.9764255141779052
2023-02-06 16:02:39 | Stage | Epoch[081/200] Train loss:0.0594
2023-02-06 16:02:39 | Stage | Epoch[081/200] Valid loss:0.5137
2023-02-06 16:02:39 | Stage | Epoch[081/200] LR:0.01

2023-02-06 16:02:40 | Train | Epoch[082/200] Iteration[001/030] Train loss: 0.0573
2023-02-06 16:02:41 | Train | Epoch[082/200] Iteration[002/030] Train loss: 0.0579
2023-02-06 16:02:41 | Train | Epoch[082/200] Iteration[003/030] Train loss: 0.0577
2023-02-06 16:02:42 | Train | Epoch[082/200] Iteration[004/030] Train loss: 0.0578
2023-02-06 16:02:42 | Train | Epoch[082/200] Iteration[005/030] Train loss: 0.0582
2023-02-06 16:02:42 | Train | Epoch[082/200] Iteration[006/030] Train loss: 0.0591
2023-02-06 16:02:43 | Train | Epoch[082/200] Iteration[007/030] Train loss: 0.0590
2023-02-06 16:02:43 | Train | Epoch[082/200] Iteration[008/030] Train loss: 0.0587
2023-02-06 16:02:44 | Train | Epoch[082/200] Iteration[009/030] Train loss: 0.0586
2023-02-06 16:02:44 | Train | Epoch[082/200] Iteration[010/030] Train loss: 0.0584
2023-02-06 16:02:45 | Train | Epoch[082/200] Iteration[011/030] Train loss: 0.0583
2023-02-06 16:02:45 | Train | Epoch[082/200] Iteration[012/030] Train loss: 0.0584
2023-02-06 16:02:45 | Train | Epoch[082/200] Iteration[013/030] Train loss: 0.0584
2023-02-06 16:02:46 | Train | Epoch[082/200] Iteration[014/030] Train loss: 0.0584
2023-02-06 16:02:46 | Train | Epoch[082/200] Iteration[015/030] Train loss: 0.0583
2023-02-06 16:02:47 | Train | Epoch[082/200] Iteration[016/030] Train loss: 0.0583
2023-02-06 16:02:47 | Train | Epoch[082/200] Iteration[017/030] Train loss: 0.0583
2023-02-06 16:02:48 | Train | Epoch[082/200] Iteration[018/030] Train loss: 0.0583
2023-02-06 16:02:48 | Train | Epoch[082/200] Iteration[019/030] Train loss: 0.0581
2023-02-06 16:02:48 | Train | Epoch[082/200] Iteration[020/030] Train loss: 0.0581
2023-02-06 16:02:49 | Train | Epoch[082/200] Iteration[021/030] Train loss: 0.0581
2023-02-06 16:02:49 | Train | Epoch[082/200] Iteration[022/030] Train loss: 0.0580
2023-02-06 16:02:50 | Train | Epoch[082/200] Iteration[023/030] Train loss: 0.0580
2023-02-06 16:02:50 | Train | Epoch[082/200] Iteration[024/030] Train loss: 0.0583
2023-02-06 16:02:51 | Train | Epoch[082/200] Iteration[025/030] Train loss: 0.0582
2023-02-06 16:02:51 | Train | Epoch[082/200] Iteration[026/030] Train loss: 0.0582
2023-02-06 16:02:51 | Train | Epoch[082/200] Iteration[027/030] Train loss: 0.0582
2023-02-06 16:02:52 | Train | Epoch[082/200] Iteration[028/030] Train loss: 0.0582
2023-02-06 16:02:52 | Train | Epoch[082/200] Iteration[029/030] Train loss: 0.0582
2023-02-06 16:02:53 | Train | Epoch[082/200] Iteration[030/030] Train loss: 0.0582
2023-02-06 16:02:53 | Valid | Epoch[082/200] Iteration[001/008] Valid loss: 0.3125
2023-02-06 16:02:53 | Valid | Epoch[082/200] Iteration[002/008] Valid loss: 0.2731
2023-02-06 16:02:53 | Valid | Epoch[082/200] Iteration[003/008] Valid loss: 0.2496
2023-02-06 16:02:53 | Valid | Epoch[082/200] Iteration[004/008] Valid loss: 0.2448
2023-02-06 16:02:53 | Valid | Epoch[082/200] Iteration[005/008] Valid loss: 0.2468
2023-02-06 16:02:53 | Valid | Epoch[082/200] Iteration[006/008] Valid loss: 0.2438
2023-02-06 16:02:54 | Valid | Epoch[082/200] Iteration[007/008] Valid loss: 0.2554
2023-02-06 16:02:54 | Valid | Epoch[082/200] Iteration[008/008] Valid loss: 0.2661
2023-02-06 16:02:54 | Valid | Epoch[082/200] MIou: 0.8967215864537561
2023-02-06 16:02:54 | Valid | Epoch[082/200] Pixel Accuracy: 0.979974110921224
2023-02-06 16:02:54 | Valid | Epoch[082/200] Mean Pixel Accuracy: 0.9797485098141802
2023-02-06 16:02:54 | Stage | Epoch[082/200] Train loss:0.0582
2023-02-06 16:02:54 | Stage | Epoch[082/200] Valid loss:0.2661
2023-02-06 16:02:54 | Stage | Epoch[082/200] LR:0.01

2023-02-06 16:02:54 | Train | Epoch[083/200] Iteration[001/030] Train loss: 0.0594
2023-02-06 16:02:55 | Train | Epoch[083/200] Iteration[002/030] Train loss: 0.0584
2023-02-06 16:02:55 | Train | Epoch[083/200] Iteration[003/030] Train loss: 0.0577
2023-02-06 16:02:56 | Train | Epoch[083/200] Iteration[004/030] Train loss: 0.0574
2023-02-06 16:02:56 | Train | Epoch[083/200] Iteration[005/030] Train loss: 0.0572
2023-02-06 16:02:57 | Train | Epoch[083/200] Iteration[006/030] Train loss: 0.0571
2023-02-06 16:02:57 | Train | Epoch[083/200] Iteration[007/030] Train loss: 0.0571
2023-02-06 16:02:57 | Train | Epoch[083/200] Iteration[008/030] Train loss: 0.0570
2023-02-06 16:02:58 | Train | Epoch[083/200] Iteration[009/030] Train loss: 0.0568
2023-02-06 16:02:58 | Train | Epoch[083/200] Iteration[010/030] Train loss: 0.0568
2023-02-06 16:02:59 | Train | Epoch[083/200] Iteration[011/030] Train loss: 0.0571
2023-02-06 16:02:59 | Train | Epoch[083/200] Iteration[012/030] Train loss: 0.0573
2023-02-06 16:03:00 | Train | Epoch[083/200] Iteration[013/030] Train loss: 0.0573
2023-02-06 16:03:00 | Train | Epoch[083/200] Iteration[014/030] Train loss: 0.0573
2023-02-06 16:03:01 | Train | Epoch[083/200] Iteration[015/030] Train loss: 0.0573
2023-02-06 16:03:01 | Train | Epoch[083/200] Iteration[016/030] Train loss: 0.0573
2023-02-06 16:03:01 | Train | Epoch[083/200] Iteration[017/030] Train loss: 0.0572
2023-02-06 16:03:02 | Train | Epoch[083/200] Iteration[018/030] Train loss: 0.0574
2023-02-06 16:03:02 | Train | Epoch[083/200] Iteration[019/030] Train loss: 0.0573
2023-02-06 16:03:03 | Train | Epoch[083/200] Iteration[020/030] Train loss: 0.0573
2023-02-06 16:03:03 | Train | Epoch[083/200] Iteration[021/030] Train loss: 0.0573
2023-02-06 16:03:04 | Train | Epoch[083/200] Iteration[022/030] Train loss: 0.0573
2023-02-06 16:03:04 | Train | Epoch[083/200] Iteration[023/030] Train loss: 0.0573
2023-02-06 16:03:04 | Train | Epoch[083/200] Iteration[024/030] Train loss: 0.0572
2023-02-06 16:03:05 | Train | Epoch[083/200] Iteration[025/030] Train loss: 0.0572
2023-02-06 16:03:05 | Train | Epoch[083/200] Iteration[026/030] Train loss: 0.0571
2023-02-06 16:03:06 | Train | Epoch[083/200] Iteration[027/030] Train loss: 0.0571
2023-02-06 16:03:06 | Train | Epoch[083/200] Iteration[028/030] Train loss: 0.0571
2023-02-06 16:03:07 | Train | Epoch[083/200] Iteration[029/030] Train loss: 0.0571
2023-02-06 16:03:07 | Train | Epoch[083/200] Iteration[030/030] Train loss: 0.0571
2023-02-06 16:03:07 | Valid | Epoch[083/200] Iteration[001/008] Valid loss: 0.1747
2023-02-06 16:03:07 | Valid | Epoch[083/200] Iteration[002/008] Valid loss: 0.1297
2023-02-06 16:03:07 | Valid | Epoch[083/200] Iteration[003/008] Valid loss: 0.1193
2023-02-06 16:03:07 | Valid | Epoch[083/200] Iteration[004/008] Valid loss: 0.1119
2023-02-06 16:03:08 | Valid | Epoch[083/200] Iteration[005/008] Valid loss: 0.1105
2023-02-06 16:03:08 | Valid | Epoch[083/200] Iteration[006/008] Valid loss: 0.1069
2023-02-06 16:03:08 | Valid | Epoch[083/200] Iteration[007/008] Valid loss: 0.1104
2023-02-06 16:03:08 | Valid | Epoch[083/200] Iteration[008/008] Valid loss: 0.1088
2023-02-06 16:03:08 | Valid | Epoch[083/200] MIou: 0.9304411111235985
2023-02-06 16:03:08 | Valid | Epoch[083/200] Pixel Accuracy: 0.9878514607747396
2023-02-06 16:03:08 | Valid | Epoch[083/200] Mean Pixel Accuracy: 0.963731664172254
2023-02-06 16:03:08 | Stage | Epoch[083/200] Train loss:0.0571
2023-02-06 16:03:08 | Stage | Epoch[083/200] Valid loss:0.1088
2023-02-06 16:03:08 | Stage | Epoch[083/200] LR:0.01

2023-02-06 16:03:09 | Train | Epoch[084/200] Iteration[001/030] Train loss: 0.0569
2023-02-06 16:03:09 | Train | Epoch[084/200] Iteration[002/030] Train loss: 0.0557
2023-02-06 16:03:10 | Train | Epoch[084/200] Iteration[003/030] Train loss: 0.0559
2023-02-06 16:03:10 | Train | Epoch[084/200] Iteration[004/030] Train loss: 0.0560
2023-02-06 16:03:10 | Train | Epoch[084/200] Iteration[005/030] Train loss: 0.0561
2023-02-06 16:03:11 | Train | Epoch[084/200] Iteration[006/030] Train loss: 0.0563
2023-02-06 16:03:11 | Train | Epoch[084/200] Iteration[007/030] Train loss: 0.0568
2023-02-06 16:03:12 | Train | Epoch[084/200] Iteration[008/030] Train loss: 0.0569
2023-02-06 16:03:12 | Train | Epoch[084/200] Iteration[009/030] Train loss: 0.0567
2023-02-06 16:03:13 | Train | Epoch[084/200] Iteration[010/030] Train loss: 0.0567
2023-02-06 16:03:13 | Train | Epoch[084/200] Iteration[011/030] Train loss: 0.0566
2023-02-06 16:03:13 | Train | Epoch[084/200] Iteration[012/030] Train loss: 0.0567
2023-02-06 16:03:14 | Train | Epoch[084/200] Iteration[013/030] Train loss: 0.0565
2023-02-06 16:03:14 | Train | Epoch[084/200] Iteration[014/030] Train loss: 0.0566
2023-02-06 16:03:15 | Train | Epoch[084/200] Iteration[015/030] Train loss: 0.0566
2023-02-06 16:03:15 | Train | Epoch[084/200] Iteration[016/030] Train loss: 0.0566
2023-02-06 16:03:16 | Train | Epoch[084/200] Iteration[017/030] Train loss: 0.0565
2023-02-06 16:03:16 | Train | Epoch[084/200] Iteration[018/030] Train loss: 0.0565
2023-02-06 16:03:16 | Train | Epoch[084/200] Iteration[019/030] Train loss: 0.0564
2023-02-06 16:03:17 | Train | Epoch[084/200] Iteration[020/030] Train loss: 0.0563
2023-02-06 16:03:17 | Train | Epoch[084/200] Iteration[021/030] Train loss: 0.0563
2023-02-06 16:03:18 | Train | Epoch[084/200] Iteration[022/030] Train loss: 0.0562
2023-02-06 16:03:18 | Train | Epoch[084/200] Iteration[023/030] Train loss: 0.0561
2023-02-06 16:03:19 | Train | Epoch[084/200] Iteration[024/030] Train loss: 0.0561
2023-02-06 16:03:19 | Train | Epoch[084/200] Iteration[025/030] Train loss: 0.0560
2023-02-06 16:03:19 | Train | Epoch[084/200] Iteration[026/030] Train loss: 0.0560
2023-02-06 16:03:20 | Train | Epoch[084/200] Iteration[027/030] Train loss: 0.0561
2023-02-06 16:03:20 | Train | Epoch[084/200] Iteration[028/030] Train loss: 0.0561
2023-02-06 16:03:21 | Train | Epoch[084/200] Iteration[029/030] Train loss: 0.0561
2023-02-06 16:03:21 | Train | Epoch[084/200] Iteration[030/030] Train loss: 0.0561
2023-02-06 16:03:22 | Valid | Epoch[084/200] Iteration[001/008] Valid loss: 0.0870
2023-02-06 16:03:22 | Valid | Epoch[084/200] Iteration[002/008] Valid loss: 0.0798
2023-02-06 16:03:22 | Valid | Epoch[084/200] Iteration[003/008] Valid loss: 0.0781
2023-02-06 16:03:22 | Valid | Epoch[084/200] Iteration[004/008] Valid loss: 0.0761
2023-02-06 16:03:22 | Valid | Epoch[084/200] Iteration[005/008] Valid loss: 0.0765
2023-02-06 16:03:22 | Valid | Epoch[084/200] Iteration[006/008] Valid loss: 0.0762
2023-02-06 16:03:22 | Valid | Epoch[084/200] Iteration[007/008] Valid loss: 0.0758
2023-02-06 16:03:22 | Valid | Epoch[084/200] Iteration[008/008] Valid loss: 0.0760
2023-02-06 16:03:22 | Valid | Epoch[084/200] MIou: 0.8805063458736397
2023-02-06 16:03:22 | Valid | Epoch[084/200] Pixel Accuracy: 0.9801495869954427
2023-02-06 16:03:22 | Valid | Epoch[084/200] Mean Pixel Accuracy: 0.8946036599400435
2023-02-06 16:03:22 | Stage | Epoch[084/200] Train loss:0.0561
2023-02-06 16:03:22 | Stage | Epoch[084/200] Valid loss:0.0760
2023-02-06 16:03:22 | Stage | Epoch[084/200] LR:0.01

2023-02-06 16:03:23 | Train | Epoch[085/200] Iteration[001/030] Train loss: 0.0550
2023-02-06 16:03:23 | Train | Epoch[085/200] Iteration[002/030] Train loss: 0.0563
2023-02-06 16:03:24 | Train | Epoch[085/200] Iteration[003/030] Train loss: 0.0555
2023-02-06 16:03:24 | Train | Epoch[085/200] Iteration[004/030] Train loss: 0.0552
2023-02-06 16:03:25 | Train | Epoch[085/200] Iteration[005/030] Train loss: 0.0551
2023-02-06 16:03:25 | Train | Epoch[085/200] Iteration[006/030] Train loss: 0.0548
2023-02-06 16:03:26 | Train | Epoch[085/200] Iteration[007/030] Train loss: 0.0550
2023-02-06 16:03:26 | Train | Epoch[085/200] Iteration[008/030] Train loss: 0.0549
2023-02-06 16:03:27 | Train | Epoch[085/200] Iteration[009/030] Train loss: 0.0549
2023-02-06 16:03:27 | Train | Epoch[085/200] Iteration[010/030] Train loss: 0.0549
2023-02-06 16:03:27 | Train | Epoch[085/200] Iteration[011/030] Train loss: 0.0549
2023-02-06 16:03:28 | Train | Epoch[085/200] Iteration[012/030] Train loss: 0.0549
2023-02-06 16:03:28 | Train | Epoch[085/200] Iteration[013/030] Train loss: 0.0550
2023-02-06 16:03:29 | Train | Epoch[085/200] Iteration[014/030] Train loss: 0.0550
2023-02-06 16:03:29 | Train | Epoch[085/200] Iteration[015/030] Train loss: 0.0549
2023-02-06 16:03:30 | Train | Epoch[085/200] Iteration[016/030] Train loss: 0.0549
2023-02-06 16:03:30 | Train | Epoch[085/200] Iteration[017/030] Train loss: 0.0549
2023-02-06 16:03:30 | Train | Epoch[085/200] Iteration[018/030] Train loss: 0.0549
2023-02-06 16:03:31 | Train | Epoch[085/200] Iteration[019/030] Train loss: 0.0548
2023-02-06 16:03:31 | Train | Epoch[085/200] Iteration[020/030] Train loss: 0.0547
2023-02-06 16:03:32 | Train | Epoch[085/200] Iteration[021/030] Train loss: 0.0547
2023-02-06 16:03:32 | Train | Epoch[085/200] Iteration[022/030] Train loss: 0.0548
2023-02-06 16:03:33 | Train | Epoch[085/200] Iteration[023/030] Train loss: 0.0547
2023-02-06 16:03:33 | Train | Epoch[085/200] Iteration[024/030] Train loss: 0.0548
2023-02-06 16:03:33 | Train | Epoch[085/200] Iteration[025/030] Train loss: 0.0548
2023-02-06 16:03:34 | Train | Epoch[085/200] Iteration[026/030] Train loss: 0.0548
2023-02-06 16:03:34 | Train | Epoch[085/200] Iteration[027/030] Train loss: 0.0548
2023-02-06 16:03:35 | Train | Epoch[085/200] Iteration[028/030] Train loss: 0.0548
2023-02-06 16:03:35 | Train | Epoch[085/200] Iteration[029/030] Train loss: 0.0548
2023-02-06 16:03:35 | Train | Epoch[085/200] Iteration[030/030] Train loss: 0.0547
2023-02-06 16:03:36 | Valid | Epoch[085/200] Iteration[001/008] Valid loss: 0.1600
2023-02-06 16:03:36 | Valid | Epoch[085/200] Iteration[002/008] Valid loss: 0.1280
2023-02-06 16:03:36 | Valid | Epoch[085/200] Iteration[003/008] Valid loss: 0.1213
2023-02-06 16:03:36 | Valid | Epoch[085/200] Iteration[004/008] Valid loss: 0.1155
2023-02-06 16:03:36 | Valid | Epoch[085/200] Iteration[005/008] Valid loss: 0.1156
2023-02-06 16:03:36 | Valid | Epoch[085/200] Iteration[006/008] Valid loss: 0.1154
2023-02-06 16:03:36 | Valid | Epoch[085/200] Iteration[007/008] Valid loss: 0.1194
2023-02-06 16:03:36 | Valid | Epoch[085/200] Iteration[008/008] Valid loss: 0.1174
2023-02-06 16:03:37 | Valid | Epoch[085/200] MIou: 0.919195918366166
2023-02-06 16:03:37 | Valid | Epoch[085/200] Pixel Accuracy: 0.9856135050455729
2023-02-06 16:03:37 | Valid | Epoch[085/200] Mean Pixel Accuracy: 0.9616836674319422
2023-02-06 16:03:37 | Stage | Epoch[085/200] Train loss:0.0547
2023-02-06 16:03:37 | Stage | Epoch[085/200] Valid loss:0.1174
2023-02-06 16:03:37 | Stage | Epoch[085/200] LR:0.01

2023-02-06 16:03:37 | Train | Epoch[086/200] Iteration[001/030] Train loss: 0.0546
2023-02-06 16:03:38 | Train | Epoch[086/200] Iteration[002/030] Train loss: 0.0541
2023-02-06 16:03:38 | Train | Epoch[086/200] Iteration[003/030] Train loss: 0.0540
2023-02-06 16:03:39 | Train | Epoch[086/200] Iteration[004/030] Train loss: 0.0539
2023-02-06 16:03:39 | Train | Epoch[086/200] Iteration[005/030] Train loss: 0.0541
2023-02-06 16:03:39 | Train | Epoch[086/200] Iteration[006/030] Train loss: 0.0542
2023-02-06 16:03:40 | Train | Epoch[086/200] Iteration[007/030] Train loss: 0.0540
2023-02-06 16:03:40 | Train | Epoch[086/200] Iteration[008/030] Train loss: 0.0539
2023-02-06 16:03:41 | Train | Epoch[086/200] Iteration[009/030] Train loss: 0.0538
2023-02-06 16:03:41 | Train | Epoch[086/200] Iteration[010/030] Train loss: 0.0538
2023-02-06 16:03:42 | Train | Epoch[086/200] Iteration[011/030] Train loss: 0.0538
2023-02-06 16:03:42 | Train | Epoch[086/200] Iteration[012/030] Train loss: 0.0537
2023-02-06 16:03:42 | Train | Epoch[086/200] Iteration[013/030] Train loss: 0.0537
2023-02-06 16:03:43 | Train | Epoch[086/200] Iteration[014/030] Train loss: 0.0536
2023-02-06 16:03:43 | Train | Epoch[086/200] Iteration[015/030] Train loss: 0.0536
2023-02-06 16:03:44 | Train | Epoch[086/200] Iteration[016/030] Train loss: 0.0538
2023-02-06 16:03:44 | Train | Epoch[086/200] Iteration[017/030] Train loss: 0.0538
2023-02-06 16:03:45 | Train | Epoch[086/200] Iteration[018/030] Train loss: 0.0538
2023-02-06 16:03:45 | Train | Epoch[086/200] Iteration[019/030] Train loss: 0.0538
2023-02-06 16:03:46 | Train | Epoch[086/200] Iteration[020/030] Train loss: 0.0538
2023-02-06 16:03:46 | Train | Epoch[086/200] Iteration[021/030] Train loss: 0.0538
2023-02-06 16:03:46 | Train | Epoch[086/200] Iteration[022/030] Train loss: 0.0538
2023-02-06 16:03:47 | Train | Epoch[086/200] Iteration[023/030] Train loss: 0.0541
2023-02-06 16:03:47 | Train | Epoch[086/200] Iteration[024/030] Train loss: 0.0541
2023-02-06 16:03:48 | Train | Epoch[086/200] Iteration[025/030] Train loss: 0.0541
2023-02-06 16:03:48 | Train | Epoch[086/200] Iteration[026/030] Train loss: 0.0541
2023-02-06 16:03:49 | Train | Epoch[086/200] Iteration[027/030] Train loss: 0.0541
2023-02-06 16:03:49 | Train | Epoch[086/200] Iteration[028/030] Train loss: 0.0541
2023-02-06 16:03:49 | Train | Epoch[086/200] Iteration[029/030] Train loss: 0.0541
2023-02-06 16:03:50 | Train | Epoch[086/200] Iteration[030/030] Train loss: 0.0541
2023-02-06 16:03:50 | Valid | Epoch[086/200] Iteration[001/008] Valid loss: 0.4729
2023-02-06 16:03:50 | Valid | Epoch[086/200] Iteration[002/008] Valid loss: 0.4477
2023-02-06 16:03:50 | Valid | Epoch[086/200] Iteration[003/008] Valid loss: 0.4416
2023-02-06 16:03:50 | Valid | Epoch[086/200] Iteration[004/008] Valid loss: 0.4506
2023-02-06 16:03:50 | Valid | Epoch[086/200] Iteration[005/008] Valid loss: 0.4534
2023-02-06 16:03:51 | Valid | Epoch[086/200] Iteration[006/008] Valid loss: 0.4368
2023-02-06 16:03:51 | Valid | Epoch[086/200] Iteration[007/008] Valid loss: 0.4663
2023-02-06 16:03:51 | Valid | Epoch[086/200] Iteration[008/008] Valid loss: 0.4723
2023-02-06 16:03:51 | Valid | Epoch[086/200] MIou: 0.8621572523216096
2023-02-06 16:03:51 | Valid | Epoch[086/200] Pixel Accuracy: 0.97113037109375
2023-02-06 16:03:51 | Valid | Epoch[086/200] Mean Pixel Accuracy: 0.9798458619510657
2023-02-06 16:03:51 | Stage | Epoch[086/200] Train loss:0.0541
2023-02-06 16:03:51 | Stage | Epoch[086/200] Valid loss:0.4723
2023-02-06 16:03:51 | Stage | Epoch[086/200] LR:0.01

2023-02-06 16:03:52 | Train | Epoch[087/200] Iteration[001/030] Train loss: 0.0534
2023-02-06 16:03:52 | Train | Epoch[087/200] Iteration[002/030] Train loss: 0.0531
2023-02-06 16:03:52 | Train | Epoch[087/200] Iteration[003/030] Train loss: 0.0534
2023-02-06 16:03:53 | Train | Epoch[087/200] Iteration[004/030] Train loss: 0.0535
2023-02-06 16:03:53 | Train | Epoch[087/200] Iteration[005/030] Train loss: 0.0534
2023-02-06 16:03:54 | Train | Epoch[087/200] Iteration[006/030] Train loss: 0.0541
2023-02-06 16:03:54 | Train | Epoch[087/200] Iteration[007/030] Train loss: 0.0540
2023-02-06 16:03:55 | Train | Epoch[087/200] Iteration[008/030] Train loss: 0.0539
2023-02-06 16:03:55 | Train | Epoch[087/200] Iteration[009/030] Train loss: 0.0538
2023-02-06 16:03:55 | Train | Epoch[087/200] Iteration[010/030] Train loss: 0.0537
2023-02-06 16:03:56 | Train | Epoch[087/200] Iteration[011/030] Train loss: 0.0538
2023-02-06 16:03:56 | Train | Epoch[087/200] Iteration[012/030] Train loss: 0.0538
2023-02-06 16:03:57 | Train | Epoch[087/200] Iteration[013/030] Train loss: 0.0538
2023-02-06 16:03:57 | Train | Epoch[087/200] Iteration[014/030] Train loss: 0.0536
2023-02-06 16:03:58 | Train | Epoch[087/200] Iteration[015/030] Train loss: 0.0535
2023-02-06 16:03:58 | Train | Epoch[087/200] Iteration[016/030] Train loss: 0.0535
2023-02-06 16:03:59 | Train | Epoch[087/200] Iteration[017/030] Train loss: 0.0535
2023-02-06 16:03:59 | Train | Epoch[087/200] Iteration[018/030] Train loss: 0.0535
2023-02-06 16:03:59 | Train | Epoch[087/200] Iteration[019/030] Train loss: 0.0535
2023-02-06 16:04:00 | Train | Epoch[087/200] Iteration[020/030] Train loss: 0.0534
2023-02-06 16:04:00 | Train | Epoch[087/200] Iteration[021/030] Train loss: 0.0534
2023-02-06 16:04:01 | Train | Epoch[087/200] Iteration[022/030] Train loss: 0.0534
2023-02-06 16:04:01 | Train | Epoch[087/200] Iteration[023/030] Train loss: 0.0533
2023-02-06 16:04:02 | Train | Epoch[087/200] Iteration[024/030] Train loss: 0.0534
2023-02-06 16:04:02 | Train | Epoch[087/200] Iteration[025/030] Train loss: 0.0533
2023-02-06 16:04:02 | Train | Epoch[087/200] Iteration[026/030] Train loss: 0.0534
2023-02-06 16:04:03 | Train | Epoch[087/200] Iteration[027/030] Train loss: 0.0534
2023-02-06 16:04:03 | Train | Epoch[087/200] Iteration[028/030] Train loss: 0.0535
2023-02-06 16:04:04 | Train | Epoch[087/200] Iteration[029/030] Train loss: 0.0534
2023-02-06 16:04:04 | Train | Epoch[087/200] Iteration[030/030] Train loss: 0.0534
2023-02-06 16:04:04 | Valid | Epoch[087/200] Iteration[001/008] Valid loss: 0.1904
2023-02-06 16:04:05 | Valid | Epoch[087/200] Iteration[002/008] Valid loss: 0.1522
2023-02-06 16:04:05 | Valid | Epoch[087/200] Iteration[003/008] Valid loss: 0.1408
2023-02-06 16:04:05 | Valid | Epoch[087/200] Iteration[004/008] Valid loss: 0.1355
2023-02-06 16:04:05 | Valid | Epoch[087/200] Iteration[005/008] Valid loss: 0.1366
2023-02-06 16:04:05 | Valid | Epoch[087/200] Iteration[006/008] Valid loss: 0.1308
2023-02-06 16:04:05 | Valid | Epoch[087/200] Iteration[007/008] Valid loss: 0.1362
2023-02-06 16:04:05 | Valid | Epoch[087/200] Iteration[008/008] Valid loss: 0.1350
2023-02-06 16:04:05 | Valid | Epoch[087/200] MIou: 0.9209779081925755
2023-02-06 16:04:05 | Valid | Epoch[087/200] Pixel Accuracy: 0.9856719970703125
2023-02-06 16:04:05 | Valid | Epoch[087/200] Mean Pixel Accuracy: 0.9721712546667832
2023-02-06 16:04:05 | Stage | Epoch[087/200] Train loss:0.0534
2023-02-06 16:04:05 | Stage | Epoch[087/200] Valid loss:0.1350
2023-02-06 16:04:05 | Stage | Epoch[087/200] LR:0.01

2023-02-06 16:04:06 | Train | Epoch[088/200] Iteration[001/030] Train loss: 0.0546
2023-02-06 16:04:06 | Train | Epoch[088/200] Iteration[002/030] Train loss: 0.0546
2023-02-06 16:04:07 | Train | Epoch[088/200] Iteration[003/030] Train loss: 0.0540
2023-02-06 16:04:07 | Train | Epoch[088/200] Iteration[004/030] Train loss: 0.0537
2023-02-06 16:04:08 | Train | Epoch[088/200] Iteration[005/030] Train loss: 0.0537
2023-02-06 16:04:08 | Train | Epoch[088/200] Iteration[006/030] Train loss: 0.0535
2023-02-06 16:04:09 | Train | Epoch[088/200] Iteration[007/030] Train loss: 0.0535
2023-02-06 16:04:09 | Train | Epoch[088/200] Iteration[008/030] Train loss: 0.0535
2023-02-06 16:04:09 | Train | Epoch[088/200] Iteration[009/030] Train loss: 0.0534
2023-02-06 16:04:10 | Train | Epoch[088/200] Iteration[010/030] Train loss: 0.0538
2023-02-06 16:04:10 | Train | Epoch[088/200] Iteration[011/030] Train loss: 0.0535
2023-02-06 16:04:11 | Train | Epoch[088/200] Iteration[012/030] Train loss: 0.0534
2023-02-06 16:04:11 | Train | Epoch[088/200] Iteration[013/030] Train loss: 0.0533
2023-02-06 16:04:12 | Train | Epoch[088/200] Iteration[014/030] Train loss: 0.0533
2023-02-06 16:04:12 | Train | Epoch[088/200] Iteration[015/030] Train loss: 0.0533
2023-02-06 16:04:13 | Train | Epoch[088/200] Iteration[016/030] Train loss: 0.0531
2023-02-06 16:04:13 | Train | Epoch[088/200] Iteration[017/030] Train loss: 0.0531
2023-02-06 16:04:13 | Train | Epoch[088/200] Iteration[018/030] Train loss: 0.0530
2023-02-06 16:04:14 | Train | Epoch[088/200] Iteration[019/030] Train loss: 0.0529
2023-02-06 16:04:14 | Train | Epoch[088/200] Iteration[020/030] Train loss: 0.0528
2023-02-06 16:04:15 | Train | Epoch[088/200] Iteration[021/030] Train loss: 0.0528
2023-02-06 16:04:15 | Train | Epoch[088/200] Iteration[022/030] Train loss: 0.0528
2023-02-06 16:04:16 | Train | Epoch[088/200] Iteration[023/030] Train loss: 0.0527
2023-02-06 16:04:16 | Train | Epoch[088/200] Iteration[024/030] Train loss: 0.0527
2023-02-06 16:04:16 | Train | Epoch[088/200] Iteration[025/030] Train loss: 0.0527
2023-02-06 16:04:17 | Train | Epoch[088/200] Iteration[026/030] Train loss: 0.0527
2023-02-06 16:04:17 | Train | Epoch[088/200] Iteration[027/030] Train loss: 0.0526
2023-02-06 16:04:18 | Train | Epoch[088/200] Iteration[028/030] Train loss: 0.0526
2023-02-06 16:04:18 | Train | Epoch[088/200] Iteration[029/030] Train loss: 0.0526
2023-02-06 16:04:18 | Train | Epoch[088/200] Iteration[030/030] Train loss: 0.0526
2023-02-06 16:04:19 | Valid | Epoch[088/200] Iteration[001/008] Valid loss: 0.3265
2023-02-06 16:04:19 | Valid | Epoch[088/200] Iteration[002/008] Valid loss: 0.2614
2023-02-06 16:04:19 | Valid | Epoch[088/200] Iteration[003/008] Valid loss: 0.2411
2023-02-06 16:04:19 | Valid | Epoch[088/200] Iteration[004/008] Valid loss: 0.2360
2023-02-06 16:04:19 | Valid | Epoch[088/200] Iteration[005/008] Valid loss: 0.2485
2023-02-06 16:04:19 | Valid | Epoch[088/200] Iteration[006/008] Valid loss: 0.2377
2023-02-06 16:04:19 | Valid | Epoch[088/200] Iteration[007/008] Valid loss: 0.2571
2023-02-06 16:04:19 | Valid | Epoch[088/200] Iteration[008/008] Valid loss: 0.2700
2023-02-06 16:04:20 | Valid | Epoch[088/200] MIou: 0.8966121169195076
2023-02-06 16:04:20 | Valid | Epoch[088/200] Pixel Accuracy: 0.9799588521321615
2023-02-06 16:04:20 | Valid | Epoch[088/200] Mean Pixel Accuracy: 0.9794801636009445
2023-02-06 16:04:20 | Stage | Epoch[088/200] Train loss:0.0526
2023-02-06 16:04:20 | Stage | Epoch[088/200] Valid loss:0.2700
2023-02-06 16:04:20 | Stage | Epoch[088/200] LR:0.01

2023-02-06 16:04:20 | Train | Epoch[089/200] Iteration[001/030] Train loss: 0.0505
2023-02-06 16:04:21 | Train | Epoch[089/200] Iteration[002/030] Train loss: 0.0506
2023-02-06 16:04:21 | Train | Epoch[089/200] Iteration[003/030] Train loss: 0.0526
2023-02-06 16:04:22 | Train | Epoch[089/200] Iteration[004/030] Train loss: 0.0519
2023-02-06 16:04:22 | Train | Epoch[089/200] Iteration[005/030] Train loss: 0.0516
2023-02-06 16:04:23 | Train | Epoch[089/200] Iteration[006/030] Train loss: 0.0515
2023-02-06 16:04:23 | Train | Epoch[089/200] Iteration[007/030] Train loss: 0.0515
2023-02-06 16:04:23 | Train | Epoch[089/200] Iteration[008/030] Train loss: 0.0515
2023-02-06 16:04:24 | Train | Epoch[089/200] Iteration[009/030] Train loss: 0.0513
2023-02-06 16:04:24 | Train | Epoch[089/200] Iteration[010/030] Train loss: 0.0514
2023-02-06 16:04:25 | Train | Epoch[089/200] Iteration[011/030] Train loss: 0.0517
2023-02-06 16:04:25 | Train | Epoch[089/200] Iteration[012/030] Train loss: 0.0515
2023-02-06 16:04:26 | Train | Epoch[089/200] Iteration[013/030] Train loss: 0.0514
2023-02-06 16:04:26 | Train | Epoch[089/200] Iteration[014/030] Train loss: 0.0514
2023-02-06 16:04:26 | Train | Epoch[089/200] Iteration[015/030] Train loss: 0.0515
2023-02-06 16:04:27 | Train | Epoch[089/200] Iteration[016/030] Train loss: 0.0515
2023-02-06 16:04:27 | Train | Epoch[089/200] Iteration[017/030] Train loss: 0.0515
2023-02-06 16:04:28 | Train | Epoch[089/200] Iteration[018/030] Train loss: 0.0515
2023-02-06 16:04:28 | Train | Epoch[089/200] Iteration[019/030] Train loss: 0.0514
2023-02-06 16:04:29 | Train | Epoch[089/200] Iteration[020/030] Train loss: 0.0514
2023-02-06 16:04:29 | Train | Epoch[089/200] Iteration[021/030] Train loss: 0.0514
2023-02-06 16:04:30 | Train | Epoch[089/200] Iteration[022/030] Train loss: 0.0513
2023-02-06 16:04:30 | Train | Epoch[089/200] Iteration[023/030] Train loss: 0.0513
2023-02-06 16:04:30 | Train | Epoch[089/200] Iteration[024/030] Train loss: 0.0512
2023-02-06 16:04:31 | Train | Epoch[089/200] Iteration[025/030] Train loss: 0.0513
2023-02-06 16:04:31 | Train | Epoch[089/200] Iteration[026/030] Train loss: 0.0514
2023-02-06 16:04:32 | Train | Epoch[089/200] Iteration[027/030] Train loss: 0.0513
2023-02-06 16:04:32 | Train | Epoch[089/200] Iteration[028/030] Train loss: 0.0513
2023-02-06 16:04:33 | Train | Epoch[089/200] Iteration[029/030] Train loss: 0.0513
2023-02-06 16:04:33 | Train | Epoch[089/200] Iteration[030/030] Train loss: 0.0513
2023-02-06 16:04:33 | Valid | Epoch[089/200] Iteration[001/008] Valid loss: 0.1234
2023-02-06 16:04:33 | Valid | Epoch[089/200] Iteration[002/008] Valid loss: 0.1129
2023-02-06 16:04:33 | Valid | Epoch[089/200] Iteration[003/008] Valid loss: 0.1059
2023-02-06 16:04:33 | Valid | Epoch[089/200] Iteration[004/008] Valid loss: 0.1077
2023-02-06 16:04:34 | Valid | Epoch[089/200] Iteration[005/008] Valid loss: 0.1035
2023-02-06 16:04:34 | Valid | Epoch[089/200] Iteration[006/008] Valid loss: 0.1077
2023-02-06 16:04:34 | Valid | Epoch[089/200] Iteration[007/008] Valid loss: 0.1107
2023-02-06 16:04:34 | Valid | Epoch[089/200] Iteration[008/008] Valid loss: 0.1082
2023-02-06 16:04:34 | Valid | Epoch[089/200] MIou: 0.8853965564794908
2023-02-06 16:04:34 | Valid | Epoch[089/200] Pixel Accuracy: 0.98046875
2023-02-06 16:04:34 | Valid | Epoch[089/200] Mean Pixel Accuracy: 0.9094953199188582
2023-02-06 16:04:34 | Stage | Epoch[089/200] Train loss:0.0513
2023-02-06 16:04:34 | Stage | Epoch[089/200] Valid loss:0.1082
2023-02-06 16:04:34 | Stage | Epoch[089/200] LR:0.01

2023-02-06 16:04:35 | Train | Epoch[090/200] Iteration[001/030] Train loss: 0.0511
2023-02-06 16:04:35 | Train | Epoch[090/200] Iteration[002/030] Train loss: 0.0514
2023-02-06 16:04:36 | Train | Epoch[090/200] Iteration[003/030] Train loss: 0.0510
2023-02-06 16:04:36 | Train | Epoch[090/200] Iteration[004/030] Train loss: 0.0510
2023-02-06 16:04:36 | Train | Epoch[090/200] Iteration[005/030] Train loss: 0.0507
2023-02-06 16:04:37 | Train | Epoch[090/200] Iteration[006/030] Train loss: 0.0506
2023-02-06 16:04:37 | Train | Epoch[090/200] Iteration[007/030] Train loss: 0.0504
2023-02-06 16:04:38 | Train | Epoch[090/200] Iteration[008/030] Train loss: 0.0505
2023-02-06 16:04:38 | Train | Epoch[090/200] Iteration[009/030] Train loss: 0.0504
2023-02-06 16:04:39 | Train | Epoch[090/200] Iteration[010/030] Train loss: 0.0504
2023-02-06 16:04:39 | Train | Epoch[090/200] Iteration[011/030] Train loss: 0.0503
2023-02-06 16:04:39 | Train | Epoch[090/200] Iteration[012/030] Train loss: 0.0505
2023-02-06 16:04:40 | Train | Epoch[090/200] Iteration[013/030] Train loss: 0.0504
2023-02-06 16:04:40 | Train | Epoch[090/200] Iteration[014/030] Train loss: 0.0504
2023-02-06 16:04:41 | Train | Epoch[090/200] Iteration[015/030] Train loss: 0.0503
2023-02-06 16:04:41 | Train | Epoch[090/200] Iteration[016/030] Train loss: 0.0503
2023-02-06 16:04:42 | Train | Epoch[090/200] Iteration[017/030] Train loss: 0.0502
2023-02-06 16:04:42 | Train | Epoch[090/200] Iteration[018/030] Train loss: 0.0501
2023-02-06 16:04:42 | Train | Epoch[090/200] Iteration[019/030] Train loss: 0.0501
2023-02-06 16:04:43 | Train | Epoch[090/200] Iteration[020/030] Train loss: 0.0504
2023-02-06 16:04:43 | Train | Epoch[090/200] Iteration[021/030] Train loss: 0.0504
2023-02-06 16:04:44 | Train | Epoch[090/200] Iteration[022/030] Train loss: 0.0505
2023-02-06 16:04:44 | Train | Epoch[090/200] Iteration[023/030] Train loss: 0.0505
2023-02-06 16:04:45 | Train | Epoch[090/200] Iteration[024/030] Train loss: 0.0506
2023-02-06 16:04:45 | Train | Epoch[090/200] Iteration[025/030] Train loss: 0.0505
2023-02-06 16:04:46 | Train | Epoch[090/200] Iteration[026/030] Train loss: 0.0505
2023-02-06 16:04:46 | Train | Epoch[090/200] Iteration[027/030] Train loss: 0.0506
2023-02-06 16:04:46 | Train | Epoch[090/200] Iteration[028/030] Train loss: 0.0505
2023-02-06 16:04:47 | Train | Epoch[090/200] Iteration[029/030] Train loss: 0.0505
2023-02-06 16:04:47 | Train | Epoch[090/200] Iteration[030/030] Train loss: 0.0506
2023-02-06 16:04:48 | Valid | Epoch[090/200] Iteration[001/008] Valid loss: 0.0868
2023-02-06 16:04:48 | Valid | Epoch[090/200] Iteration[002/008] Valid loss: 0.0767
2023-02-06 16:04:48 | Valid | Epoch[090/200] Iteration[003/008] Valid loss: 0.0759
2023-02-06 16:04:48 | Valid | Epoch[090/200] Iteration[004/008] Valid loss: 0.0743
2023-02-06 16:04:48 | Valid | Epoch[090/200] Iteration[005/008] Valid loss: 0.0759
2023-02-06 16:04:48 | Valid | Epoch[090/200] Iteration[006/008] Valid loss: 0.0755
2023-02-06 16:04:48 | Valid | Epoch[090/200] Iteration[007/008] Valid loss: 0.0763
2023-02-06 16:04:48 | Valid | Epoch[090/200] Iteration[008/008] Valid loss: 0.0766
2023-02-06 16:04:48 | Valid | Epoch[090/200] MIou: 0.8819457055979978
2023-02-06 16:04:48 | Valid | Epoch[090/200] Pixel Accuracy: 0.9800529479980469
2023-02-06 16:04:48 | Valid | Epoch[090/200] Mean Pixel Accuracy: 0.9027170703330799
2023-02-06 16:04:48 | Stage | Epoch[090/200] Train loss:0.0506
2023-02-06 16:04:48 | Stage | Epoch[090/200] Valid loss:0.0766
2023-02-06 16:04:48 | Stage | Epoch[090/200] LR:0.01

2023-02-06 16:04:49 | Train | Epoch[091/200] Iteration[001/030] Train loss: 0.0485
2023-02-06 16:04:50 | Train | Epoch[091/200] Iteration[002/030] Train loss: 0.0503
2023-02-06 16:04:50 | Train | Epoch[091/200] Iteration[003/030] Train loss: 0.0505
2023-02-06 16:04:50 | Train | Epoch[091/200] Iteration[004/030] Train loss: 0.0502
2023-02-06 16:04:51 | Train | Epoch[091/200] Iteration[005/030] Train loss: 0.0502
2023-02-06 16:04:51 | Train | Epoch[091/200] Iteration[006/030] Train loss: 0.0503
2023-02-06 16:04:52 | Train | Epoch[091/200] Iteration[007/030] Train loss: 0.0502
2023-02-06 16:04:52 | Train | Epoch[091/200] Iteration[008/030] Train loss: 0.0500
2023-02-06 16:04:53 | Train | Epoch[091/200] Iteration[009/030] Train loss: 0.0499
2023-02-06 16:04:53 | Train | Epoch[091/200] Iteration[010/030] Train loss: 0.0497
2023-02-06 16:04:53 | Train | Epoch[091/200] Iteration[011/030] Train loss: 0.0496
2023-02-06 16:04:54 | Train | Epoch[091/200] Iteration[012/030] Train loss: 0.0496
2023-02-06 16:04:54 | Train | Epoch[091/200] Iteration[013/030] Train loss: 0.0496
2023-02-06 16:04:55 | Train | Epoch[091/200] Iteration[014/030] Train loss: 0.0496
2023-02-06 16:04:55 | Train | Epoch[091/200] Iteration[015/030] Train loss: 0.0500
2023-02-06 16:04:56 | Train | Epoch[091/200] Iteration[016/030] Train loss: 0.0500
2023-02-06 16:04:56 | Train | Epoch[091/200] Iteration[017/030] Train loss: 0.0500
2023-02-06 16:04:56 | Train | Epoch[091/200] Iteration[018/030] Train loss: 0.0501
2023-02-06 16:04:57 | Train | Epoch[091/200] Iteration[019/030] Train loss: 0.0502
2023-02-06 16:04:57 | Train | Epoch[091/200] Iteration[020/030] Train loss: 0.0502
2023-02-06 16:04:58 | Train | Epoch[091/200] Iteration[021/030] Train loss: 0.0501
2023-02-06 16:04:58 | Train | Epoch[091/200] Iteration[022/030] Train loss: 0.0501
2023-02-06 16:04:59 | Train | Epoch[091/200] Iteration[023/030] Train loss: 0.0501
2023-02-06 16:04:59 | Train | Epoch[091/200] Iteration[024/030] Train loss: 0.0501
2023-02-06 16:04:59 | Train | Epoch[091/200] Iteration[025/030] Train loss: 0.0500
2023-02-06 16:05:00 | Train | Epoch[091/200] Iteration[026/030] Train loss: 0.0499
2023-02-06 16:05:00 | Train | Epoch[091/200] Iteration[027/030] Train loss: 0.0500
2023-02-06 16:05:01 | Train | Epoch[091/200] Iteration[028/030] Train loss: 0.0501
2023-02-06 16:05:01 | Train | Epoch[091/200] Iteration[029/030] Train loss: 0.0501
2023-02-06 16:05:01 | Train | Epoch[091/200] Iteration[030/030] Train loss: 0.0500
2023-02-06 16:05:02 | Valid | Epoch[091/200] Iteration[001/008] Valid loss: 0.1665
2023-02-06 16:05:02 | Valid | Epoch[091/200] Iteration[002/008] Valid loss: 0.1282
2023-02-06 16:05:02 | Valid | Epoch[091/200] Iteration[003/008] Valid loss: 0.1181
2023-02-06 16:05:02 | Valid | Epoch[091/200] Iteration[004/008] Valid loss: 0.1100
2023-02-06 16:05:02 | Valid | Epoch[091/200] Iteration[005/008] Valid loss: 0.1138
2023-02-06 16:05:02 | Valid | Epoch[091/200] Iteration[006/008] Valid loss: 0.1105
2023-02-06 16:05:02 | Valid | Epoch[091/200] Iteration[007/008] Valid loss: 0.1143
2023-02-06 16:05:02 | Valid | Epoch[091/200] Iteration[008/008] Valid loss: 0.1133
2023-02-06 16:05:03 | Valid | Epoch[091/200] MIou: 0.9206201930867994
2023-02-06 16:05:03 | Valid | Epoch[091/200] Pixel Accuracy: 0.9860941569010416
2023-02-06 16:05:03 | Valid | Epoch[091/200] Mean Pixel Accuracy: 0.955537637492301
2023-02-06 16:05:03 | Stage | Epoch[091/200] Train loss:0.0500
2023-02-06 16:05:03 | Stage | Epoch[091/200] Valid loss:0.1133
2023-02-06 16:05:03 | Stage | Epoch[091/200] LR:0.01

2023-02-06 16:05:03 | Train | Epoch[092/200] Iteration[001/030] Train loss: 0.0505
2023-02-06 16:05:04 | Train | Epoch[092/200] Iteration[002/030] Train loss: 0.0497
2023-02-06 16:05:04 | Train | Epoch[092/200] Iteration[003/030] Train loss: 0.0498
2023-02-06 16:05:05 | Train | Epoch[092/200] Iteration[004/030] Train loss: 0.0499
2023-02-06 16:05:05 | Train | Epoch[092/200] Iteration[005/030] Train loss: 0.0498
2023-02-06 16:05:05 | Train | Epoch[092/200] Iteration[006/030] Train loss: 0.0497
2023-02-06 16:05:06 | Train | Epoch[092/200] Iteration[007/030] Train loss: 0.0495
2023-02-06 16:05:06 | Train | Epoch[092/200] Iteration[008/030] Train loss: 0.0495
2023-02-06 16:05:07 | Train | Epoch[092/200] Iteration[009/030] Train loss: 0.0494
2023-02-06 16:05:07 | Train | Epoch[092/200] Iteration[010/030] Train loss: 0.0493
2023-02-06 16:05:08 | Train | Epoch[092/200] Iteration[011/030] Train loss: 0.0493
2023-02-06 16:05:08 | Train | Epoch[092/200] Iteration[012/030] Train loss: 0.0493
2023-02-06 16:05:09 | Train | Epoch[092/200] Iteration[013/030] Train loss: 0.0492
2023-02-06 16:05:09 | Train | Epoch[092/200] Iteration[014/030] Train loss: 0.0493
2023-02-06 16:05:09 | Train | Epoch[092/200] Iteration[015/030] Train loss: 0.0495
2023-02-06 16:05:10 | Train | Epoch[092/200] Iteration[016/030] Train loss: 0.0493
2023-02-06 16:05:10 | Train | Epoch[092/200] Iteration[017/030] Train loss: 0.0495
2023-02-06 16:05:11 | Train | Epoch[092/200] Iteration[018/030] Train loss: 0.0495
2023-02-06 16:05:11 | Train | Epoch[092/200] Iteration[019/030] Train loss: 0.0495
2023-02-06 16:05:12 | Train | Epoch[092/200] Iteration[020/030] Train loss: 0.0495
2023-02-06 16:05:12 | Train | Epoch[092/200] Iteration[021/030] Train loss: 0.0495
2023-02-06 16:05:12 | Train | Epoch[092/200] Iteration[022/030] Train loss: 0.0495
2023-02-06 16:05:13 | Train | Epoch[092/200] Iteration[023/030] Train loss: 0.0495
2023-02-06 16:05:13 | Train | Epoch[092/200] Iteration[024/030] Train loss: 0.0494
2023-02-06 16:05:14 | Train | Epoch[092/200] Iteration[025/030] Train loss: 0.0494
2023-02-06 16:05:14 | Train | Epoch[092/200] Iteration[026/030] Train loss: 0.0494
2023-02-06 16:05:15 | Train | Epoch[092/200] Iteration[027/030] Train loss: 0.0494
2023-02-06 16:05:15 | Train | Epoch[092/200] Iteration[028/030] Train loss: 0.0494
2023-02-06 16:05:15 | Train | Epoch[092/200] Iteration[029/030] Train loss: 0.0494
2023-02-06 16:05:16 | Train | Epoch[092/200] Iteration[030/030] Train loss: 0.0493
2023-02-06 16:05:16 | Valid | Epoch[092/200] Iteration[001/008] Valid loss: 0.1255
2023-02-06 16:05:16 | Valid | Epoch[092/200] Iteration[002/008] Valid loss: 0.1019
2023-02-06 16:05:16 | Valid | Epoch[092/200] Iteration[003/008] Valid loss: 0.0955
2023-02-06 16:05:16 | Valid | Epoch[092/200] Iteration[004/008] Valid loss: 0.0932
2023-02-06 16:05:16 | Valid | Epoch[092/200] Iteration[005/008] Valid loss: 0.0931
2023-02-06 16:05:17 | Valid | Epoch[092/200] Iteration[006/008] Valid loss: 0.0908
2023-02-06 16:05:17 | Valid | Epoch[092/200] Iteration[007/008] Valid loss: 0.0943
2023-02-06 16:05:17 | Valid | Epoch[092/200] Iteration[008/008] Valid loss: 0.0936
2023-02-06 16:05:17 | Valid | Epoch[092/200] MIou: 0.9231838191708533
2023-02-06 16:05:17 | Valid | Epoch[092/200] Pixel Accuracy: 0.9866612752278646
2023-02-06 16:05:17 | Valid | Epoch[092/200] Mean Pixel Accuracy: 0.953978910815671
2023-02-06 16:05:17 | Stage | Epoch[092/200] Train loss:0.0493
2023-02-06 16:05:17 | Stage | Epoch[092/200] Valid loss:0.0936
2023-02-06 16:05:17 | Stage | Epoch[092/200] LR:0.01

2023-02-06 16:05:18 | Train | Epoch[093/200] Iteration[001/030] Train loss: 0.0476
2023-02-06 16:05:18 | Train | Epoch[093/200] Iteration[002/030] Train loss: 0.0476
2023-02-06 16:05:18 | Train | Epoch[093/200] Iteration[003/030] Train loss: 0.0477
2023-02-06 16:05:19 | Train | Epoch[093/200] Iteration[004/030] Train loss: 0.0475
2023-02-06 16:05:19 | Train | Epoch[093/200] Iteration[005/030] Train loss: 0.0472
2023-02-06 16:05:20 | Train | Epoch[093/200] Iteration[006/030] Train loss: 0.0475
2023-02-06 16:05:20 | Train | Epoch[093/200] Iteration[007/030] Train loss: 0.0477
2023-02-06 16:05:21 | Train | Epoch[093/200] Iteration[008/030] Train loss: 0.0476
2023-02-06 16:05:21 | Train | Epoch[093/200] Iteration[009/030] Train loss: 0.0478
2023-02-06 16:05:21 | Train | Epoch[093/200] Iteration[010/030] Train loss: 0.0479
2023-02-06 16:05:22 | Train | Epoch[093/200] Iteration[011/030] Train loss: 0.0479
2023-02-06 16:05:22 | Train | Epoch[093/200] Iteration[012/030] Train loss: 0.0480
2023-02-06 16:05:23 | Train | Epoch[093/200] Iteration[013/030] Train loss: 0.0482
2023-02-06 16:05:23 | Train | Epoch[093/200] Iteration[014/030] Train loss: 0.0484
2023-02-06 16:05:24 | Train | Epoch[093/200] Iteration[015/030] Train loss: 0.0485
2023-02-06 16:05:24 | Train | Epoch[093/200] Iteration[016/030] Train loss: 0.0485
2023-02-06 16:05:24 | Train | Epoch[093/200] Iteration[017/030] Train loss: 0.0484
2023-02-06 16:05:25 | Train | Epoch[093/200] Iteration[018/030] Train loss: 0.0484
2023-02-06 16:05:25 | Train | Epoch[093/200] Iteration[019/030] Train loss: 0.0484
2023-02-06 16:05:26 | Train | Epoch[093/200] Iteration[020/030] Train loss: 0.0483
2023-02-06 16:05:26 | Train | Epoch[093/200] Iteration[021/030] Train loss: 0.0482
2023-02-06 16:05:27 | Train | Epoch[093/200] Iteration[022/030] Train loss: 0.0482
2023-02-06 16:05:27 | Train | Epoch[093/200] Iteration[023/030] Train loss: 0.0484
2023-02-06 16:05:27 | Train | Epoch[093/200] Iteration[024/030] Train loss: 0.0484
2023-02-06 16:05:28 | Train | Epoch[093/200] Iteration[025/030] Train loss: 0.0483
2023-02-06 16:05:28 | Train | Epoch[093/200] Iteration[026/030] Train loss: 0.0483
2023-02-06 16:05:29 | Train | Epoch[093/200] Iteration[027/030] Train loss: 0.0483
2023-02-06 16:05:29 | Train | Epoch[093/200] Iteration[028/030] Train loss: 0.0483
2023-02-06 16:05:30 | Train | Epoch[093/200] Iteration[029/030] Train loss: 0.0483
2023-02-06 16:05:30 | Train | Epoch[093/200] Iteration[030/030] Train loss: 0.0483
2023-02-06 16:05:30 | Valid | Epoch[093/200] Iteration[001/008] Valid loss: 0.0907
2023-02-06 16:05:30 | Valid | Epoch[093/200] Iteration[002/008] Valid loss: 0.0790
2023-02-06 16:05:30 | Valid | Epoch[093/200] Iteration[003/008] Valid loss: 0.0750
2023-02-06 16:05:31 | Valid | Epoch[093/200] Iteration[004/008] Valid loss: 0.0729
2023-02-06 16:05:31 | Valid | Epoch[093/200] Iteration[005/008] Valid loss: 0.0755
2023-02-06 16:05:31 | Valid | Epoch[093/200] Iteration[006/008] Valid loss: 0.0753
2023-02-06 16:05:31 | Valid | Epoch[093/200] Iteration[007/008] Valid loss: 0.0768
2023-02-06 16:05:31 | Valid | Epoch[093/200] Iteration[008/008] Valid loss: 0.0764
2023-02-06 16:05:31 | Valid | Epoch[093/200] MIou: 0.9194457298472537
2023-02-06 16:05:31 | Valid | Epoch[093/200] Pixel Accuracy: 0.9859339396158854
2023-02-06 16:05:31 | Valid | Epoch[093/200] Mean Pixel Accuracy: 0.9529007056914212
2023-02-06 16:05:31 | Stage | Epoch[093/200] Train loss:0.0483
2023-02-06 16:05:31 | Stage | Epoch[093/200] Valid loss:0.0764
2023-02-06 16:05:31 | Stage | Epoch[093/200] LR:0.01

2023-02-06 16:05:32 | Train | Epoch[094/200] Iteration[001/030] Train loss: 0.0475
2023-02-06 16:05:32 | Train | Epoch[094/200] Iteration[002/030] Train loss: 0.0469
2023-02-06 16:05:33 | Train | Epoch[094/200] Iteration[003/030] Train loss: 0.0472
2023-02-06 16:05:33 | Train | Epoch[094/200] Iteration[004/030] Train loss: 0.0471
2023-02-06 16:05:33 | Train | Epoch[094/200] Iteration[005/030] Train loss: 0.0470
2023-02-06 16:05:34 | Train | Epoch[094/200] Iteration[006/030] Train loss: 0.0469
2023-02-06 16:05:34 | Train | Epoch[094/200] Iteration[007/030] Train loss: 0.0468
2023-02-06 16:05:35 | Train | Epoch[094/200] Iteration[008/030] Train loss: 0.0468
2023-02-06 16:05:35 | Train | Epoch[094/200] Iteration[009/030] Train loss: 0.0466
2023-02-06 16:05:36 | Train | Epoch[094/200] Iteration[010/030] Train loss: 0.0464
2023-02-06 16:05:36 | Train | Epoch[094/200] Iteration[011/030] Train loss: 0.0464
2023-02-06 16:05:36 | Train | Epoch[094/200] Iteration[012/030] Train loss: 0.0465
2023-02-06 16:05:37 | Train | Epoch[094/200] Iteration[013/030] Train loss: 0.0465
2023-02-06 16:05:37 | Train | Epoch[094/200] Iteration[014/030] Train loss: 0.0465
2023-02-06 16:05:38 | Train | Epoch[094/200] Iteration[015/030] Train loss: 0.0464
2023-02-06 16:05:38 | Train | Epoch[094/200] Iteration[016/030] Train loss: 0.0464
2023-02-06 16:05:39 | Train | Epoch[094/200] Iteration[017/030] Train loss: 0.0464
2023-02-06 16:05:39 | Train | Epoch[094/200] Iteration[018/030] Train loss: 0.0465
2023-02-06 16:05:40 | Train | Epoch[094/200] Iteration[019/030] Train loss: 0.0464
2023-02-06 16:05:40 | Train | Epoch[094/200] Iteration[020/030] Train loss: 0.0464
2023-02-06 16:05:40 | Train | Epoch[094/200] Iteration[021/030] Train loss: 0.0464
2023-02-06 16:05:41 | Train | Epoch[094/200] Iteration[022/030] Train loss: 0.0464
2023-02-06 16:05:41 | Train | Epoch[094/200] Iteration[023/030] Train loss: 0.0465
2023-02-06 16:05:42 | Train | Epoch[094/200] Iteration[024/030] Train loss: 0.0465
2023-02-06 16:05:42 | Train | Epoch[094/200] Iteration[025/030] Train loss: 0.0465
2023-02-06 16:05:43 | Train | Epoch[094/200] Iteration[026/030] Train loss: 0.0465
2023-02-06 16:05:43 | Train | Epoch[094/200] Iteration[027/030] Train loss: 0.0464
2023-02-06 16:05:43 | Train | Epoch[094/200] Iteration[028/030] Train loss: 0.0464
2023-02-06 16:05:44 | Train | Epoch[094/200] Iteration[029/030] Train loss: 0.0465
2023-02-06 16:05:44 | Train | Epoch[094/200] Iteration[030/030] Train loss: 0.0464
2023-02-06 16:05:44 | Valid | Epoch[094/200] Iteration[001/008] Valid loss: 0.2176
2023-02-06 16:05:45 | Valid | Epoch[094/200] Iteration[002/008] Valid loss: 0.1674
2023-02-06 16:05:45 | Valid | Epoch[094/200] Iteration[003/008] Valid loss: 0.1489
2023-02-06 16:05:45 | Valid | Epoch[094/200] Iteration[004/008] Valid loss: 0.1418
2023-02-06 16:05:45 | Valid | Epoch[094/200] Iteration[005/008] Valid loss: 0.1415
2023-02-06 16:05:45 | Valid | Epoch[094/200] Iteration[006/008] Valid loss: 0.1388
2023-02-06 16:05:45 | Valid | Epoch[094/200] Iteration[007/008] Valid loss: 0.1488
2023-02-06 16:05:45 | Valid | Epoch[094/200] Iteration[008/008] Valid loss: 0.1476
2023-02-06 16:05:45 | Valid | Epoch[094/200] MIou: 0.9241950088211346
2023-02-06 16:05:45 | Valid | Epoch[094/200] Pixel Accuracy: 0.9862467447916666
2023-02-06 16:05:45 | Valid | Epoch[094/200] Mean Pixel Accuracy: 0.9757398224125339
2023-02-06 16:05:45 | Stage | Epoch[094/200] Train loss:0.0464
2023-02-06 16:05:45 | Stage | Epoch[094/200] Valid loss:0.1476
2023-02-06 16:05:45 | Stage | Epoch[094/200] LR:0.01

2023-02-06 16:05:46 | Train | Epoch[095/200] Iteration[001/030] Train loss: 0.0455
2023-02-06 16:05:46 | Train | Epoch[095/200] Iteration[002/030] Train loss: 0.0454
2023-02-06 16:05:47 | Train | Epoch[095/200] Iteration[003/030] Train loss: 0.0454
2023-02-06 16:05:47 | Train | Epoch[095/200] Iteration[004/030] Train loss: 0.0453
2023-02-06 16:05:48 | Train | Epoch[095/200] Iteration[005/030] Train loss: 0.0455
2023-02-06 16:05:48 | Train | Epoch[095/200] Iteration[006/030] Train loss: 0.0456
2023-02-06 16:05:49 | Train | Epoch[095/200] Iteration[007/030] Train loss: 0.0455
2023-02-06 16:05:49 | Train | Epoch[095/200] Iteration[008/030] Train loss: 0.0455
2023-02-06 16:05:49 | Train | Epoch[095/200] Iteration[009/030] Train loss: 0.0455
2023-02-06 16:05:50 | Train | Epoch[095/200] Iteration[010/030] Train loss: 0.0454
2023-02-06 16:05:50 | Train | Epoch[095/200] Iteration[011/030] Train loss: 0.0455
2023-02-06 16:05:51 | Train | Epoch[095/200] Iteration[012/030] Train loss: 0.0455
2023-02-06 16:05:51 | Train | Epoch[095/200] Iteration[013/030] Train loss: 0.0454
2023-02-06 16:05:52 | Train | Epoch[095/200] Iteration[014/030] Train loss: 0.0454
2023-02-06 16:05:52 | Train | Epoch[095/200] Iteration[015/030] Train loss: 0.0455
2023-02-06 16:05:52 | Train | Epoch[095/200] Iteration[016/030] Train loss: 0.0455
2023-02-06 16:05:53 | Train | Epoch[095/200] Iteration[017/030] Train loss: 0.0455
2023-02-06 16:05:53 | Train | Epoch[095/200] Iteration[018/030] Train loss: 0.0455
2023-02-06 16:05:54 | Train | Epoch[095/200] Iteration[019/030] Train loss: 0.0455
2023-02-06 16:05:54 | Train | Epoch[095/200] Iteration[020/030] Train loss: 0.0455
2023-02-06 16:05:55 | Train | Epoch[095/200] Iteration[021/030] Train loss: 0.0455
2023-02-06 16:05:55 | Train | Epoch[095/200] Iteration[022/030] Train loss: 0.0456
2023-02-06 16:05:55 | Train | Epoch[095/200] Iteration[023/030] Train loss: 0.0456
2023-02-06 16:05:56 | Train | Epoch[095/200] Iteration[024/030] Train loss: 0.0456
2023-02-06 16:05:56 | Train | Epoch[095/200] Iteration[025/030] Train loss: 0.0456
2023-02-06 16:05:57 | Train | Epoch[095/200] Iteration[026/030] Train loss: 0.0456
2023-02-06 16:05:57 | Train | Epoch[095/200] Iteration[027/030] Train loss: 0.0456
2023-02-06 16:05:58 | Train | Epoch[095/200] Iteration[028/030] Train loss: 0.0456
2023-02-06 16:05:58 | Train | Epoch[095/200] Iteration[029/030] Train loss: 0.0456
2023-02-06 16:05:58 | Train | Epoch[095/200] Iteration[030/030] Train loss: 0.0456
2023-02-06 16:05:59 | Valid | Epoch[095/200] Iteration[001/008] Valid loss: 0.1181
2023-02-06 16:05:59 | Valid | Epoch[095/200] Iteration[002/008] Valid loss: 0.0926
2023-02-06 16:05:59 | Valid | Epoch[095/200] Iteration[003/008] Valid loss: 0.0896
2023-02-06 16:05:59 | Valid | Epoch[095/200] Iteration[004/008] Valid loss: 0.0854
2023-02-06 16:05:59 | Valid | Epoch[095/200] Iteration[005/008] Valid loss: 0.0859
2023-02-06 16:05:59 | Valid | Epoch[095/200] Iteration[006/008] Valid loss: 0.0841
2023-02-06 16:05:59 | Valid | Epoch[095/200] Iteration[007/008] Valid loss: 0.0883
2023-02-06 16:05:59 | Valid | Epoch[095/200] Iteration[008/008] Valid loss: 0.0884
2023-02-06 16:05:59 | Valid | Epoch[095/200] MIou: 0.9266454311566055
2023-02-06 16:05:59 | Valid | Epoch[095/200] Pixel Accuracy: 0.9871991475423177
2023-02-06 16:05:59 | Valid | Epoch[095/200] Mean Pixel Accuracy: 0.9596385872786133
2023-02-06 16:05:59 | Stage | Epoch[095/200] Train loss:0.0456
2023-02-06 16:05:59 | Stage | Epoch[095/200] Valid loss:0.0884
2023-02-06 16:05:59 | Stage | Epoch[095/200] LR:0.01

2023-02-06 16:06:00 | Train | Epoch[096/200] Iteration[001/030] Train loss: 0.0447
2023-02-06 16:06:01 | Train | Epoch[096/200] Iteration[002/030] Train loss: 0.0448
2023-02-06 16:06:01 | Train | Epoch[096/200] Iteration[003/030] Train loss: 0.0446
2023-02-06 16:06:01 | Train | Epoch[096/200] Iteration[004/030] Train loss: 0.0446
2023-02-06 16:06:02 | Train | Epoch[096/200] Iteration[005/030] Train loss: 0.0451
2023-02-06 16:06:02 | Train | Epoch[096/200] Iteration[006/030] Train loss: 0.0450
2023-02-06 16:06:03 | Train | Epoch[096/200] Iteration[007/030] Train loss: 0.0450
2023-02-06 16:06:03 | Train | Epoch[096/200] Iteration[008/030] Train loss: 0.0453
2023-02-06 16:06:04 | Train | Epoch[096/200] Iteration[009/030] Train loss: 0.0453
2023-02-06 16:06:04 | Train | Epoch[096/200] Iteration[010/030] Train loss: 0.0454
2023-02-06 16:06:04 | Train | Epoch[096/200] Iteration[011/030] Train loss: 0.0454
2023-02-06 16:06:05 | Train | Epoch[096/200] Iteration[012/030] Train loss: 0.0455
2023-02-06 16:06:05 | Train | Epoch[096/200] Iteration[013/030] Train loss: 0.0455
2023-02-06 16:06:06 | Train | Epoch[096/200] Iteration[014/030] Train loss: 0.0454
2023-02-06 16:06:06 | Train | Epoch[096/200] Iteration[015/030] Train loss: 0.0453
2023-02-06 16:06:07 | Train | Epoch[096/200] Iteration[016/030] Train loss: 0.0453
2023-02-06 16:06:07 | Train | Epoch[096/200] Iteration[017/030] Train loss: 0.0453
2023-02-06 16:06:08 | Train | Epoch[096/200] Iteration[018/030] Train loss: 0.0453
2023-02-06 16:06:08 | Train | Epoch[096/200] Iteration[019/030] Train loss: 0.0453
2023-02-06 16:06:08 | Train | Epoch[096/200] Iteration[020/030] Train loss: 0.0454
2023-02-06 16:06:09 | Train | Epoch[096/200] Iteration[021/030] Train loss: 0.0454
2023-02-06 16:06:09 | Train | Epoch[096/200] Iteration[022/030] Train loss: 0.0454
2023-02-06 16:06:10 | Train | Epoch[096/200] Iteration[023/030] Train loss: 0.0455
2023-02-06 16:06:10 | Train | Epoch[096/200] Iteration[024/030] Train loss: 0.0456
2023-02-06 16:06:11 | Train | Epoch[096/200] Iteration[025/030] Train loss: 0.0456
2023-02-06 16:06:11 | Train | Epoch[096/200] Iteration[026/030] Train loss: 0.0457
2023-02-06 16:06:11 | Train | Epoch[096/200] Iteration[027/030] Train loss: 0.0457
2023-02-06 16:06:12 | Train | Epoch[096/200] Iteration[028/030] Train loss: 0.0458
2023-02-06 16:06:12 | Train | Epoch[096/200] Iteration[029/030] Train loss: 0.0458
2023-02-06 16:06:12 | Train | Epoch[096/200] Iteration[030/030] Train loss: 0.0457
2023-02-06 16:06:13 | Valid | Epoch[096/200] Iteration[001/008] Valid loss: 0.2134
2023-02-06 16:06:13 | Valid | Epoch[096/200] Iteration[002/008] Valid loss: 0.2238
2023-02-06 16:06:13 | Valid | Epoch[096/200] Iteration[003/008] Valid loss: 0.2407
2023-02-06 16:06:13 | Valid | Epoch[096/200] Iteration[004/008] Valid loss: 0.2398
2023-02-06 16:06:13 | Valid | Epoch[096/200] Iteration[005/008] Valid loss: 0.2496
2023-02-06 16:06:13 | Valid | Epoch[096/200] Iteration[006/008] Valid loss: 0.2466
2023-02-06 16:06:13 | Valid | Epoch[096/200] Iteration[007/008] Valid loss: 0.2468
2023-02-06 16:06:14 | Valid | Epoch[096/200] Iteration[008/008] Valid loss: 0.2593
2023-02-06 16:06:14 | Valid | Epoch[096/200] MIou: 0.47598413452501837
2023-02-06 16:06:14 | Valid | Epoch[096/200] Pixel Accuracy: 0.9130961100260416
2023-02-06 16:06:14 | Valid | Epoch[096/200] Mean Pixel Accuracy: 0.5195474587816978
2023-02-06 16:06:14 | Stage | Epoch[096/200] Train loss:0.0457
2023-02-06 16:06:14 | Stage | Epoch[096/200] Valid loss:0.2593
2023-02-06 16:06:14 | Stage | Epoch[096/200] LR:0.01

2023-02-06 16:06:14 | Train | Epoch[097/200] Iteration[001/030] Train loss: 0.0445
2023-02-06 16:06:15 | Train | Epoch[097/200] Iteration[002/030] Train loss: 0.0442
2023-02-06 16:06:15 | Train | Epoch[097/200] Iteration[003/030] Train loss: 0.0446
2023-02-06 16:06:16 | Train | Epoch[097/200] Iteration[004/030] Train loss: 0.0454
2023-02-06 16:06:16 | Train | Epoch[097/200] Iteration[005/030] Train loss: 0.0450
2023-02-06 16:06:17 | Train | Epoch[097/200] Iteration[006/030] Train loss: 0.0448
2023-02-06 16:06:17 | Train | Epoch[097/200] Iteration[007/030] Train loss: 0.0448
2023-02-06 16:06:17 | Train | Epoch[097/200] Iteration[008/030] Train loss: 0.0450
2023-02-06 16:06:18 | Train | Epoch[097/200] Iteration[009/030] Train loss: 0.0450
2023-02-06 16:06:18 | Train | Epoch[097/200] Iteration[010/030] Train loss: 0.0449
2023-02-06 16:06:19 | Train | Epoch[097/200] Iteration[011/030] Train loss: 0.0449
2023-02-06 16:06:19 | Train | Epoch[097/200] Iteration[012/030] Train loss: 0.0449
2023-02-06 16:06:20 | Train | Epoch[097/200] Iteration[013/030] Train loss: 0.0449
2023-02-06 16:06:20 | Train | Epoch[097/200] Iteration[014/030] Train loss: 0.0449
2023-02-06 16:06:20 | Train | Epoch[097/200] Iteration[015/030] Train loss: 0.0449
2023-02-06 16:06:21 | Train | Epoch[097/200] Iteration[016/030] Train loss: 0.0450
2023-02-06 16:06:21 | Train | Epoch[097/200] Iteration[017/030] Train loss: 0.0451
2023-02-06 16:06:22 | Train | Epoch[097/200] Iteration[018/030] Train loss: 0.0451
2023-02-06 16:06:22 | Train | Epoch[097/200] Iteration[019/030] Train loss: 0.0451
2023-02-06 16:06:23 | Train | Epoch[097/200] Iteration[020/030] Train loss: 0.0451
2023-02-06 16:06:23 | Train | Epoch[097/200] Iteration[021/030] Train loss: 0.0451
2023-02-06 16:06:23 | Train | Epoch[097/200] Iteration[022/030] Train loss: 0.0450
2023-02-06 16:06:24 | Train | Epoch[097/200] Iteration[023/030] Train loss: 0.0450
2023-02-06 16:06:24 | Train | Epoch[097/200] Iteration[024/030] Train loss: 0.0450
2023-02-06 16:06:25 | Train | Epoch[097/200] Iteration[025/030] Train loss: 0.0450
2023-02-06 16:06:25 | Train | Epoch[097/200] Iteration[026/030] Train loss: 0.0451
2023-02-06 16:06:26 | Train | Epoch[097/200] Iteration[027/030] Train loss: 0.0451
2023-02-06 16:06:26 | Train | Epoch[097/200] Iteration[028/030] Train loss: 0.0452
2023-02-06 16:06:26 | Train | Epoch[097/200] Iteration[029/030] Train loss: 0.0452
2023-02-06 16:06:27 | Train | Epoch[097/200] Iteration[030/030] Train loss: 0.0452
2023-02-06 16:06:27 | Valid | Epoch[097/200] Iteration[001/008] Valid loss: 0.1127
2023-02-06 16:06:27 | Valid | Epoch[097/200] Iteration[002/008] Valid loss: 0.1047
2023-02-06 16:06:27 | Valid | Epoch[097/200] Iteration[003/008] Valid loss: 0.1027
2023-02-06 16:06:27 | Valid | Epoch[097/200] Iteration[004/008] Valid loss: 0.1009
2023-02-06 16:06:28 | Valid | Epoch[097/200] Iteration[005/008] Valid loss: 0.1007
2023-02-06 16:06:28 | Valid | Epoch[097/200] Iteration[006/008] Valid loss: 0.0994
2023-02-06 16:06:28 | Valid | Epoch[097/200] Iteration[007/008] Valid loss: 0.0991
2023-02-06 16:06:28 | Valid | Epoch[097/200] Iteration[008/008] Valid loss: 0.1002
2023-02-06 16:06:28 | Valid | Epoch[097/200] MIou: 0.7902337453363475
2023-02-06 16:06:28 | Valid | Epoch[097/200] Pixel Accuracy: 0.9648551940917969
2023-02-06 16:06:28 | Valid | Epoch[097/200] Mean Pixel Accuracy: 0.8135100438956359
2023-02-06 16:06:28 | Stage | Epoch[097/200] Train loss:0.0452
2023-02-06 16:06:28 | Stage | Epoch[097/200] Valid loss:0.1002
2023-02-06 16:06:28 | Stage | Epoch[097/200] LR:0.01

2023-02-06 16:06:29 | Train | Epoch[098/200] Iteration[001/030] Train loss: 0.0448
2023-02-06 16:06:29 | Train | Epoch[098/200] Iteration[002/030] Train loss: 0.0445
2023-02-06 16:06:30 | Train | Epoch[098/200] Iteration[003/030] Train loss: 0.0446
2023-02-06 16:06:30 | Train | Epoch[098/200] Iteration[004/030] Train loss: 0.0445
2023-02-06 16:06:30 | Train | Epoch[098/200] Iteration[005/030] Train loss: 0.0446
2023-02-06 16:06:31 | Train | Epoch[098/200] Iteration[006/030] Train loss: 0.0445
2023-02-06 16:06:31 | Train | Epoch[098/200] Iteration[007/030] Train loss: 0.0445
2023-02-06 16:06:32 | Train | Epoch[098/200] Iteration[008/030] Train loss: 0.0445
2023-02-06 16:06:32 | Train | Epoch[098/200] Iteration[009/030] Train loss: 0.0444
2023-02-06 16:06:33 | Train | Epoch[098/200] Iteration[010/030] Train loss: 0.0445
2023-02-06 16:06:33 | Train | Epoch[098/200] Iteration[011/030] Train loss: 0.0444
2023-02-06 16:06:34 | Train | Epoch[098/200] Iteration[012/030] Train loss: 0.0444
2023-02-06 16:06:34 | Train | Epoch[098/200] Iteration[013/030] Train loss: 0.0443
2023-02-06 16:06:34 | Train | Epoch[098/200] Iteration[014/030] Train loss: 0.0443
2023-02-06 16:06:35 | Train | Epoch[098/200] Iteration[015/030] Train loss: 0.0442
2023-02-06 16:06:35 | Train | Epoch[098/200] Iteration[016/030] Train loss: 0.0443
2023-02-06 16:06:36 | Train | Epoch[098/200] Iteration[017/030] Train loss: 0.0443
2023-02-06 16:06:36 | Train | Epoch[098/200] Iteration[018/030] Train loss: 0.0443
2023-02-06 16:06:37 | Train | Epoch[098/200] Iteration[019/030] Train loss: 0.0442
2023-02-06 16:06:37 | Train | Epoch[098/200] Iteration[020/030] Train loss: 0.0441
2023-02-06 16:06:37 | Train | Epoch[098/200] Iteration[021/030] Train loss: 0.0441
2023-02-06 16:06:38 | Train | Epoch[098/200] Iteration[022/030] Train loss: 0.0441
2023-02-06 16:06:38 | Train | Epoch[098/200] Iteration[023/030] Train loss: 0.0440
2023-02-06 16:06:39 | Train | Epoch[098/200] Iteration[024/030] Train loss: 0.0440
2023-02-06 16:06:39 | Train | Epoch[098/200] Iteration[025/030] Train loss: 0.0440
2023-02-06 16:06:40 | Train | Epoch[098/200] Iteration[026/030] Train loss: 0.0440
2023-02-06 16:06:40 | Train | Epoch[098/200] Iteration[027/030] Train loss: 0.0440
2023-02-06 16:06:40 | Train | Epoch[098/200] Iteration[028/030] Train loss: 0.0440
2023-02-06 16:06:41 | Train | Epoch[098/200] Iteration[029/030] Train loss: 0.0440
2023-02-06 16:06:41 | Train | Epoch[098/200] Iteration[030/030] Train loss: 0.0439
2023-02-06 16:06:41 | Valid | Epoch[098/200] Iteration[001/008] Valid loss: 0.0838
2023-02-06 16:06:42 | Valid | Epoch[098/200] Iteration[002/008] Valid loss: 0.0750
2023-02-06 16:06:42 | Valid | Epoch[098/200] Iteration[003/008] Valid loss: 0.0736
2023-02-06 16:06:42 | Valid | Epoch[098/200] Iteration[004/008] Valid loss: 0.0726
2023-02-06 16:06:42 | Valid | Epoch[098/200] Iteration[005/008] Valid loss: 0.0721
2023-02-06 16:06:42 | Valid | Epoch[098/200] Iteration[006/008] Valid loss: 0.0716
2023-02-06 16:06:42 | Valid | Epoch[098/200] Iteration[007/008] Valid loss: 0.0715
2023-02-06 16:06:42 | Valid | Epoch[098/200] Iteration[008/008] Valid loss: 0.0719
2023-02-06 16:06:42 | Valid | Epoch[098/200] MIou: 0.8654506926178627
2023-02-06 16:06:42 | Valid | Epoch[098/200] Pixel Accuracy: 0.9776763916015625
2023-02-06 16:06:42 | Valid | Epoch[098/200] Mean Pixel Accuracy: 0.8801638935429138
2023-02-06 16:06:42 | Stage | Epoch[098/200] Train loss:0.0439
2023-02-06 16:06:42 | Stage | Epoch[098/200] Valid loss:0.0719
2023-02-06 16:06:42 | Stage | Epoch[098/200] LR:0.01

2023-02-06 16:06:43 | Train | Epoch[099/200] Iteration[001/030] Train loss: 0.0453
2023-02-06 16:06:43 | Train | Epoch[099/200] Iteration[002/030] Train loss: 0.0457
2023-02-06 16:06:44 | Train | Epoch[099/200] Iteration[003/030] Train loss: 0.0446
2023-02-06 16:06:44 | Train | Epoch[099/200] Iteration[004/030] Train loss: 0.0442
2023-02-06 16:06:45 | Train | Epoch[099/200] Iteration[005/030] Train loss: 0.0439
2023-02-06 16:06:45 | Train | Epoch[099/200] Iteration[006/030] Train loss: 0.0436
2023-02-06 16:06:46 | Train | Epoch[099/200] Iteration[007/030] Train loss: 0.0437
2023-02-06 16:06:46 | Train | Epoch[099/200] Iteration[008/030] Train loss: 0.0436
2023-02-06 16:06:46 | Train | Epoch[099/200] Iteration[009/030] Train loss: 0.0439
2023-02-06 16:06:47 | Train | Epoch[099/200] Iteration[010/030] Train loss: 0.0440
2023-02-06 16:06:47 | Train | Epoch[099/200] Iteration[011/030] Train loss: 0.0439
2023-02-06 16:06:48 | Train | Epoch[099/200] Iteration[012/030] Train loss: 0.0438
2023-02-06 16:06:48 | Train | Epoch[099/200] Iteration[013/030] Train loss: 0.0437
2023-02-06 16:06:49 | Train | Epoch[099/200] Iteration[014/030] Train loss: 0.0436
2023-02-06 16:06:49 | Train | Epoch[099/200] Iteration[015/030] Train loss: 0.0437
2023-02-06 16:06:49 | Train | Epoch[099/200] Iteration[016/030] Train loss: 0.0436
2023-02-06 16:06:50 | Train | Epoch[099/200] Iteration[017/030] Train loss: 0.0435
2023-02-06 16:06:50 | Train | Epoch[099/200] Iteration[018/030] Train loss: 0.0436
2023-02-06 16:06:51 | Train | Epoch[099/200] Iteration[019/030] Train loss: 0.0435
2023-02-06 16:06:51 | Train | Epoch[099/200] Iteration[020/030] Train loss: 0.0434
2023-02-06 16:06:52 | Train | Epoch[099/200] Iteration[021/030] Train loss: 0.0434
2023-02-06 16:06:52 | Train | Epoch[099/200] Iteration[022/030] Train loss: 0.0435
2023-02-06 16:06:52 | Train | Epoch[099/200] Iteration[023/030] Train loss: 0.0434
2023-02-06 16:06:53 | Train | Epoch[099/200] Iteration[024/030] Train loss: 0.0434
2023-02-06 16:06:53 | Train | Epoch[099/200] Iteration[025/030] Train loss: 0.0434
2023-02-06 16:06:54 | Train | Epoch[099/200] Iteration[026/030] Train loss: 0.0434
2023-02-06 16:06:54 | Train | Epoch[099/200] Iteration[027/030] Train loss: 0.0434
2023-02-06 16:06:55 | Train | Epoch[099/200] Iteration[028/030] Train loss: 0.0434
2023-02-06 16:06:55 | Train | Epoch[099/200] Iteration[029/030] Train loss: 0.0434
2023-02-06 16:06:55 | Train | Epoch[099/200] Iteration[030/030] Train loss: 0.0433
2023-02-06 16:06:56 | Valid | Epoch[099/200] Iteration[001/008] Valid loss: 0.1063
2023-02-06 16:06:56 | Valid | Epoch[099/200] Iteration[002/008] Valid loss: 0.0858
2023-02-06 16:06:56 | Valid | Epoch[099/200] Iteration[003/008] Valid loss: 0.0808
2023-02-06 16:06:56 | Valid | Epoch[099/200] Iteration[004/008] Valid loss: 0.0781
2023-02-06 16:06:56 | Valid | Epoch[099/200] Iteration[005/008] Valid loss: 0.0794
2023-02-06 16:06:56 | Valid | Epoch[099/200] Iteration[006/008] Valid loss: 0.0813
2023-02-06 16:06:56 | Valid | Epoch[099/200] Iteration[007/008] Valid loss: 0.0833
2023-02-06 16:06:56 | Valid | Epoch[099/200] Iteration[008/008] Valid loss: 0.0825
2023-02-06 16:06:56 | Valid | Epoch[099/200] MIou: 0.9155485084751049
2023-02-06 16:06:56 | Valid | Epoch[099/200] Pixel Accuracy: 0.9854240417480469
2023-02-06 16:06:56 | Valid | Epoch[099/200] Mean Pixel Accuracy: 0.9438388910324085
2023-02-06 16:06:56 | Stage | Epoch[099/200] Train loss:0.0433
2023-02-06 16:06:56 | Stage | Epoch[099/200] Valid loss:0.0825
2023-02-06 16:06:56 | Stage | Epoch[099/200] LR:0.01

2023-02-06 16:06:57 | Train | Epoch[100/200] Iteration[001/030] Train loss: 0.0420
2023-02-06 16:06:58 | Train | Epoch[100/200] Iteration[002/030] Train loss: 0.0420
2023-02-06 16:06:58 | Train | Epoch[100/200] Iteration[003/030] Train loss: 0.0418
2023-02-06 16:06:58 | Train | Epoch[100/200] Iteration[004/030] Train loss: 0.0421
2023-02-06 16:06:59 | Train | Epoch[100/200] Iteration[005/030] Train loss: 0.0417
2023-02-06 16:06:59 | Train | Epoch[100/200] Iteration[006/030] Train loss: 0.0418
2023-02-06 16:07:00 | Train | Epoch[100/200] Iteration[007/030] Train loss: 0.0417
2023-02-06 16:07:00 | Train | Epoch[100/200] Iteration[008/030] Train loss: 0.0416
2023-02-06 16:07:01 | Train | Epoch[100/200] Iteration[009/030] Train loss: 0.0423
2023-02-06 16:07:01 | Train | Epoch[100/200] Iteration[010/030] Train loss: 0.0424
2023-02-06 16:07:01 | Train | Epoch[100/200] Iteration[011/030] Train loss: 0.0424
2023-02-06 16:07:02 | Train | Epoch[100/200] Iteration[012/030] Train loss: 0.0425
2023-02-06 16:07:02 | Train | Epoch[100/200] Iteration[013/030] Train loss: 0.0426
2023-02-06 16:07:03 | Train | Epoch[100/200] Iteration[014/030] Train loss: 0.0426
2023-02-06 16:07:03 | Train | Epoch[100/200] Iteration[015/030] Train loss: 0.0428
2023-02-06 16:07:04 | Train | Epoch[100/200] Iteration[016/030] Train loss: 0.0428
2023-02-06 16:07:04 | Train | Epoch[100/200] Iteration[017/030] Train loss: 0.0427
2023-02-06 16:07:05 | Train | Epoch[100/200] Iteration[018/030] Train loss: 0.0426
2023-02-06 16:07:05 | Train | Epoch[100/200] Iteration[019/030] Train loss: 0.0426
2023-02-06 16:07:05 | Train | Epoch[100/200] Iteration[020/030] Train loss: 0.0426
2023-02-06 16:07:06 | Train | Epoch[100/200] Iteration[021/030] Train loss: 0.0426
2023-02-06 16:07:06 | Train | Epoch[100/200] Iteration[022/030] Train loss: 0.0426
2023-02-06 16:07:07 | Train | Epoch[100/200] Iteration[023/030] Train loss: 0.0426
2023-02-06 16:07:07 | Train | Epoch[100/200] Iteration[024/030] Train loss: 0.0426
2023-02-06 16:07:08 | Train | Epoch[100/200] Iteration[025/030] Train loss: 0.0426
2023-02-06 16:07:08 | Train | Epoch[100/200] Iteration[026/030] Train loss: 0.0426
2023-02-06 16:07:08 | Train | Epoch[100/200] Iteration[027/030] Train loss: 0.0426
2023-02-06 16:07:09 | Train | Epoch[100/200] Iteration[028/030] Train loss: 0.0426
2023-02-06 16:07:09 | Train | Epoch[100/200] Iteration[029/030] Train loss: 0.0426
2023-02-06 16:07:09 | Train | Epoch[100/200] Iteration[030/030] Train loss: 0.0426
2023-02-06 16:07:10 | Valid | Epoch[100/200] Iteration[001/008] Valid loss: 0.1011
2023-02-06 16:07:10 | Valid | Epoch[100/200] Iteration[002/008] Valid loss: 0.0989
2023-02-06 16:07:10 | Valid | Epoch[100/200] Iteration[003/008] Valid loss: 0.1020
2023-02-06 16:07:10 | Valid | Epoch[100/200] Iteration[004/008] Valid loss: 0.1015
2023-02-06 16:07:10 | Valid | Epoch[100/200] Iteration[005/008] Valid loss: 0.1033
2023-02-06 16:07:10 | Valid | Epoch[100/200] Iteration[006/008] Valid loss: 0.1030
2023-02-06 16:07:11 | Valid | Epoch[100/200] Iteration[007/008] Valid loss: 0.1013
2023-02-06 16:07:11 | Valid | Epoch[100/200] Iteration[008/008] Valid loss: 0.1038
2023-02-06 16:07:11 | Valid | Epoch[100/200] MIou: 0.7193200526284684
2023-02-06 16:07:11 | Valid | Epoch[100/200] Pixel Accuracy: 0.95361328125
2023-02-06 16:07:11 | Valid | Epoch[100/200] Mean Pixel Accuracy: 0.743869229777391
2023-02-06 16:07:11 | Stage | Epoch[100/200] Train loss:0.0426
2023-02-06 16:07:11 | Stage | Epoch[100/200] Valid loss:0.1038
2023-02-06 16:07:11 | Stage | Epoch[100/200] LR:0.01

2023-02-06 16:07:12 | Train | Epoch[101/200] Iteration[001/030] Train loss: 0.0420
2023-02-06 16:07:12 | Train | Epoch[101/200] Iteration[002/030] Train loss: 0.0425
2023-02-06 16:07:12 | Train | Epoch[101/200] Iteration[003/030] Train loss: 0.0423
2023-02-06 16:07:13 | Train | Epoch[101/200] Iteration[004/030] Train loss: 0.0426
2023-02-06 16:07:13 | Train | Epoch[101/200] Iteration[005/030] Train loss: 0.0429
2023-02-06 16:07:14 | Train | Epoch[101/200] Iteration[006/030] Train loss: 0.0427
2023-02-06 16:07:14 | Train | Epoch[101/200] Iteration[007/030] Train loss: 0.0426
2023-02-06 16:07:15 | Train | Epoch[101/200] Iteration[008/030] Train loss: 0.0424
2023-02-06 16:07:15 | Train | Epoch[101/200] Iteration[009/030] Train loss: 0.0423
2023-02-06 16:07:15 | Train | Epoch[101/200] Iteration[010/030] Train loss: 0.0422
2023-02-06 16:07:16 | Train | Epoch[101/200] Iteration[011/030] Train loss: 0.0426
2023-02-06 16:07:16 | Train | Epoch[101/200] Iteration[012/030] Train loss: 0.0425
2023-02-06 16:07:17 | Train | Epoch[101/200] Iteration[013/030] Train loss: 0.0424
2023-02-06 16:07:17 | Train | Epoch[101/200] Iteration[014/030] Train loss: 0.0424
2023-02-06 16:07:18 | Train | Epoch[101/200] Iteration[015/030] Train loss: 0.0423
2023-02-06 16:07:18 | Train | Epoch[101/200] Iteration[016/030] Train loss: 0.0422
2023-02-06 16:07:19 | Train | Epoch[101/200] Iteration[017/030] Train loss: 0.0422
2023-02-06 16:07:19 | Train | Epoch[101/200] Iteration[018/030] Train loss: 0.0423
2023-02-06 16:07:19 | Train | Epoch[101/200] Iteration[019/030] Train loss: 0.0421
2023-02-06 16:07:20 | Train | Epoch[101/200] Iteration[020/030] Train loss: 0.0421
2023-02-06 16:07:20 | Train | Epoch[101/200] Iteration[021/030] Train loss: 0.0422
2023-02-06 16:07:21 | Train | Epoch[101/200] Iteration[022/030] Train loss: 0.0422
2023-02-06 16:07:21 | Train | Epoch[101/200] Iteration[023/030] Train loss: 0.0423
2023-02-06 16:07:22 | Train | Epoch[101/200] Iteration[024/030] Train loss: 0.0423
2023-02-06 16:07:22 | Train | Epoch[101/200] Iteration[025/030] Train loss: 0.0423
2023-02-06 16:07:22 | Train | Epoch[101/200] Iteration[026/030] Train loss: 0.0422
2023-02-06 16:07:23 | Train | Epoch[101/200] Iteration[027/030] Train loss: 0.0422
2023-02-06 16:07:23 | Train | Epoch[101/200] Iteration[028/030] Train loss: 0.0422
2023-02-06 16:07:24 | Train | Epoch[101/200] Iteration[029/030] Train loss: 0.0421
2023-02-06 16:07:24 | Train | Epoch[101/200] Iteration[030/030] Train loss: 0.0421
2023-02-06 16:07:24 | Valid | Epoch[101/200] Iteration[001/008] Valid loss: 0.1037
2023-02-06 16:07:25 | Valid | Epoch[101/200] Iteration[002/008] Valid loss: 0.0918
2023-02-06 16:07:25 | Valid | Epoch[101/200] Iteration[003/008] Valid loss: 0.0948
2023-02-06 16:07:25 | Valid | Epoch[101/200] Iteration[004/008] Valid loss: 0.0928
2023-02-06 16:07:25 | Valid | Epoch[101/200] Iteration[005/008] Valid loss: 0.0960
2023-02-06 16:07:25 | Valid | Epoch[101/200] Iteration[006/008] Valid loss: 0.0989
2023-02-06 16:07:25 | Valid | Epoch[101/200] Iteration[007/008] Valid loss: 0.1022
2023-02-06 16:07:25 | Valid | Epoch[101/200] Iteration[008/008] Valid loss: 0.1017
2023-02-06 16:07:25 | Valid | Epoch[101/200] MIou: 0.8690389678605306
2023-02-06 16:07:25 | Valid | Epoch[101/200] Pixel Accuracy: 0.9773432413736979
2023-02-06 16:07:25 | Valid | Epoch[101/200] Mean Pixel Accuracy: 0.8999215628746569
2023-02-06 16:07:25 | Stage | Epoch[101/200] Train loss:0.0421
2023-02-06 16:07:25 | Stage | Epoch[101/200] Valid loss:0.1017
2023-02-06 16:07:25 | Stage | Epoch[101/200] LR:0.01

2023-02-06 16:07:26 | Train | Epoch[102/200] Iteration[001/030] Train loss: 0.0401
2023-02-06 16:07:26 | Train | Epoch[102/200] Iteration[002/030] Train loss: 0.0403
2023-02-06 16:07:27 | Train | Epoch[102/200] Iteration[003/030] Train loss: 0.0413
2023-02-06 16:07:27 | Train | Epoch[102/200] Iteration[004/030] Train loss: 0.0409
2023-02-06 16:07:28 | Train | Epoch[102/200] Iteration[005/030] Train loss: 0.0407
2023-02-06 16:07:28 | Train | Epoch[102/200] Iteration[006/030] Train loss: 0.0409
2023-02-06 16:07:29 | Train | Epoch[102/200] Iteration[007/030] Train loss: 0.0409
2023-02-06 16:07:29 | Train | Epoch[102/200] Iteration[008/030] Train loss: 0.0412
2023-02-06 16:07:29 | Train | Epoch[102/200] Iteration[009/030] Train loss: 0.0412
2023-02-06 16:07:30 | Train | Epoch[102/200] Iteration[010/030] Train loss: 0.0412
2023-02-06 16:07:30 | Train | Epoch[102/200] Iteration[011/030] Train loss: 0.0414
2023-02-06 16:07:31 | Train | Epoch[102/200] Iteration[012/030] Train loss: 0.0413
2023-02-06 16:07:31 | Train | Epoch[102/200] Iteration[013/030] Train loss: 0.0413
2023-02-06 16:07:32 | Train | Epoch[102/200] Iteration[014/030] Train loss: 0.0412
2023-02-06 16:07:32 | Train | Epoch[102/200] Iteration[015/030] Train loss: 0.0414
2023-02-06 16:07:32 | Train | Epoch[102/200] Iteration[016/030] Train loss: 0.0413
2023-02-06 16:07:33 | Train | Epoch[102/200] Iteration[017/030] Train loss: 0.0414
2023-02-06 16:07:33 | Train | Epoch[102/200] Iteration[018/030] Train loss: 0.0414
2023-02-06 16:07:34 | Train | Epoch[102/200] Iteration[019/030] Train loss: 0.0414
2023-02-06 16:07:34 | Train | Epoch[102/200] Iteration[020/030] Train loss: 0.0414
2023-02-06 16:07:35 | Train | Epoch[102/200] Iteration[021/030] Train loss: 0.0414
2023-02-06 16:07:35 | Train | Epoch[102/200] Iteration[022/030] Train loss: 0.0415
2023-02-06 16:07:36 | Train | Epoch[102/200] Iteration[023/030] Train loss: 0.0414
2023-02-06 16:07:36 | Train | Epoch[102/200] Iteration[024/030] Train loss: 0.0415
2023-02-06 16:07:36 | Train | Epoch[102/200] Iteration[025/030] Train loss: 0.0414
2023-02-06 16:07:37 | Train | Epoch[102/200] Iteration[026/030] Train loss: 0.0414
2023-02-06 16:07:37 | Train | Epoch[102/200] Iteration[027/030] Train loss: 0.0414
2023-02-06 16:07:38 | Train | Epoch[102/200] Iteration[028/030] Train loss: 0.0414
2023-02-06 16:07:38 | Train | Epoch[102/200] Iteration[029/030] Train loss: 0.0414
2023-02-06 16:07:38 | Train | Epoch[102/200] Iteration[030/030] Train loss: 0.0414
2023-02-06 16:07:39 | Valid | Epoch[102/200] Iteration[001/008] Valid loss: 0.5629
2023-02-06 16:07:39 | Valid | Epoch[102/200] Iteration[002/008] Valid loss: 0.5035
2023-02-06 16:07:39 | Valid | Epoch[102/200] Iteration[003/008] Valid loss: 0.4992
2023-02-06 16:07:39 | Valid | Epoch[102/200] Iteration[004/008] Valid loss: 0.5071
2023-02-06 16:07:39 | Valid | Epoch[102/200] Iteration[005/008] Valid loss: 0.5247
2023-02-06 16:07:39 | Valid | Epoch[102/200] Iteration[006/008] Valid loss: 0.5193
2023-02-06 16:07:39 | Valid | Epoch[102/200] Iteration[007/008] Valid loss: 0.5561
2023-02-06 16:07:39 | Valid | Epoch[102/200] Iteration[008/008] Valid loss: 0.5613
2023-02-06 16:07:39 | Valid | Epoch[102/200] MIou: 0.8529833420754
2023-02-06 16:07:39 | Valid | Epoch[102/200] Pixel Accuracy: 0.9686597188313802
2023-02-06 16:07:39 | Valid | Epoch[102/200] Mean Pixel Accuracy: 0.9780820959201237
2023-02-06 16:07:40 | Stage | Epoch[102/200] Train loss:0.0414
2023-02-06 16:07:40 | Stage | Epoch[102/200] Valid loss:0.5613
2023-02-06 16:07:40 | Stage | Epoch[102/200] LR:0.01

2023-02-06 16:07:40 | Train | Epoch[103/200] Iteration[001/030] Train loss: 0.0405
2023-02-06 16:07:41 | Train | Epoch[103/200] Iteration[002/030] Train loss: 0.0403
2023-02-06 16:07:41 | Train | Epoch[103/200] Iteration[003/030] Train loss: 0.0408
2023-02-06 16:07:42 | Train | Epoch[103/200] Iteration[004/030] Train loss: 0.0407
2023-02-06 16:07:42 | Train | Epoch[103/200] Iteration[005/030] Train loss: 0.0409
2023-02-06 16:07:42 | Train | Epoch[103/200] Iteration[006/030] Train loss: 0.0408
2023-02-06 16:07:43 | Train | Epoch[103/200] Iteration[007/030] Train loss: 0.0409
2023-02-06 16:07:43 | Train | Epoch[103/200] Iteration[008/030] Train loss: 0.0407
2023-02-06 16:07:44 | Train | Epoch[103/200] Iteration[009/030] Train loss: 0.0407
2023-02-06 16:07:44 | Train | Epoch[103/200] Iteration[010/030] Train loss: 0.0408
2023-02-06 16:07:45 | Train | Epoch[103/200] Iteration[011/030] Train loss: 0.0406
2023-02-06 16:07:45 | Train | Epoch[103/200] Iteration[012/030] Train loss: 0.0406
2023-02-06 16:07:46 | Train | Epoch[103/200] Iteration[013/030] Train loss: 0.0407
2023-02-06 16:07:46 | Train | Epoch[103/200] Iteration[014/030] Train loss: 0.0406
2023-02-06 16:07:46 | Train | Epoch[103/200] Iteration[015/030] Train loss: 0.0406
2023-02-06 16:07:47 | Train | Epoch[103/200] Iteration[016/030] Train loss: 0.0407
2023-02-06 16:07:47 | Train | Epoch[103/200] Iteration[017/030] Train loss: 0.0407
2023-02-06 16:07:48 | Train | Epoch[103/200] Iteration[018/030] Train loss: 0.0406
2023-02-06 16:07:48 | Train | Epoch[103/200] Iteration[019/030] Train loss: 0.0406
2023-02-06 16:07:49 | Train | Epoch[103/200] Iteration[020/030] Train loss: 0.0406
2023-02-06 16:07:49 | Train | Epoch[103/200] Iteration[021/030] Train loss: 0.0406
2023-02-06 16:07:49 | Train | Epoch[103/200] Iteration[022/030] Train loss: 0.0407
2023-02-06 16:07:50 | Train | Epoch[103/200] Iteration[023/030] Train loss: 0.0407
2023-02-06 16:07:50 | Train | Epoch[103/200] Iteration[024/030] Train loss: 0.0407
2023-02-06 16:07:51 | Train | Epoch[103/200] Iteration[025/030] Train loss: 0.0407
2023-02-06 16:07:51 | Train | Epoch[103/200] Iteration[026/030] Train loss: 0.0407
2023-02-06 16:07:52 | Train | Epoch[103/200] Iteration[027/030] Train loss: 0.0407
2023-02-06 16:07:52 | Train | Epoch[103/200] Iteration[028/030] Train loss: 0.0407
2023-02-06 16:07:52 | Train | Epoch[103/200] Iteration[029/030] Train loss: 0.0407
2023-02-06 16:07:53 | Train | Epoch[103/200] Iteration[030/030] Train loss: 0.0407
2023-02-06 16:07:53 | Valid | Epoch[103/200] Iteration[001/008] Valid loss: 0.0775
2023-02-06 16:07:53 | Valid | Epoch[103/200] Iteration[002/008] Valid loss: 0.0713
2023-02-06 16:07:53 | Valid | Epoch[103/200] Iteration[003/008] Valid loss: 0.0722
2023-02-06 16:07:53 | Valid | Epoch[103/200] Iteration[004/008] Valid loss: 0.0700
2023-02-06 16:07:53 | Valid | Epoch[103/200] Iteration[005/008] Valid loss: 0.0709
2023-02-06 16:07:54 | Valid | Epoch[103/200] Iteration[006/008] Valid loss: 0.0711
2023-02-06 16:07:54 | Valid | Epoch[103/200] Iteration[007/008] Valid loss: 0.0713
2023-02-06 16:07:54 | Valid | Epoch[103/200] Iteration[008/008] Valid loss: 0.0727
2023-02-06 16:07:54 | Valid | Epoch[103/200] MIou: 0.8286845130862812
2023-02-06 16:07:54 | Valid | Epoch[103/200] Pixel Accuracy: 0.9714330037434896
2023-02-06 16:07:54 | Valid | Epoch[103/200] Mean Pixel Accuracy: 0.8478387326215173
2023-02-06 16:07:54 | Stage | Epoch[103/200] Train loss:0.0407
2023-02-06 16:07:54 | Stage | Epoch[103/200] Valid loss:0.0727
2023-02-06 16:07:54 | Stage | Epoch[103/200] LR:0.01

2023-02-06 16:07:55 | Train | Epoch[104/200] Iteration[001/030] Train loss: 0.0389
2023-02-06 16:07:55 | Train | Epoch[104/200] Iteration[002/030] Train loss: 0.0393
2023-02-06 16:07:55 | Train | Epoch[104/200] Iteration[003/030] Train loss: 0.0393
2023-02-06 16:07:56 | Train | Epoch[104/200] Iteration[004/030] Train loss: 0.0399
2023-02-06 16:07:56 | Train | Epoch[104/200] Iteration[005/030] Train loss: 0.0398
2023-02-06 16:07:57 | Train | Epoch[104/200] Iteration[006/030] Train loss: 0.0397
2023-02-06 16:07:57 | Train | Epoch[104/200] Iteration[007/030] Train loss: 0.0394
2023-02-06 16:07:58 | Train | Epoch[104/200] Iteration[008/030] Train loss: 0.0398
2023-02-06 16:07:58 | Train | Epoch[104/200] Iteration[009/030] Train loss: 0.0401
2023-02-06 16:07:58 | Train | Epoch[104/200] Iteration[010/030] Train loss: 0.0401
2023-02-06 16:07:59 | Train | Epoch[104/200] Iteration[011/030] Train loss: 0.0400
2023-02-06 16:07:59 | Train | Epoch[104/200] Iteration[012/030] Train loss: 0.0399
2023-02-06 16:08:00 | Train | Epoch[104/200] Iteration[013/030] Train loss: 0.0399
2023-02-06 16:08:00 | Train | Epoch[104/200] Iteration[014/030] Train loss: 0.0399
2023-02-06 16:08:01 | Train | Epoch[104/200] Iteration[015/030] Train loss: 0.0399
2023-02-06 16:08:01 | Train | Epoch[104/200] Iteration[016/030] Train loss: 0.0399
2023-02-06 16:08:01 | Train | Epoch[104/200] Iteration[017/030] Train loss: 0.0399
2023-02-06 16:08:02 | Train | Epoch[104/200] Iteration[018/030] Train loss: 0.0399
2023-02-06 16:08:02 | Train | Epoch[104/200] Iteration[019/030] Train loss: 0.0399
2023-02-06 16:08:03 | Train | Epoch[104/200] Iteration[020/030] Train loss: 0.0398
2023-02-06 16:08:03 | Train | Epoch[104/200] Iteration[021/030] Train loss: 0.0401
2023-02-06 16:08:04 | Train | Epoch[104/200] Iteration[022/030] Train loss: 0.0401
2023-02-06 16:08:04 | Train | Epoch[104/200] Iteration[023/030] Train loss: 0.0401
2023-02-06 16:08:04 | Train | Epoch[104/200] Iteration[024/030] Train loss: 0.0401
2023-02-06 16:08:05 | Train | Epoch[104/200] Iteration[025/030] Train loss: 0.0402
2023-02-06 16:08:05 | Train | Epoch[104/200] Iteration[026/030] Train loss: 0.0402
2023-02-06 16:08:06 | Train | Epoch[104/200] Iteration[027/030] Train loss: 0.0402
2023-02-06 16:08:06 | Train | Epoch[104/200] Iteration[028/030] Train loss: 0.0402
2023-02-06 16:08:07 | Train | Epoch[104/200] Iteration[029/030] Train loss: 0.0402
2023-02-06 16:08:07 | Train | Epoch[104/200] Iteration[030/030] Train loss: 0.0402
2023-02-06 16:08:07 | Valid | Epoch[104/200] Iteration[001/008] Valid loss: 0.1776
2023-02-06 16:08:07 | Valid | Epoch[104/200] Iteration[002/008] Valid loss: 0.1428
2023-02-06 16:08:07 | Valid | Epoch[104/200] Iteration[003/008] Valid loss: 0.1314
2023-02-06 16:08:08 | Valid | Epoch[104/200] Iteration[004/008] Valid loss: 0.1284
2023-02-06 16:08:08 | Valid | Epoch[104/200] Iteration[005/008] Valid loss: 0.1332
2023-02-06 16:08:08 | Valid | Epoch[104/200] Iteration[006/008] Valid loss: 0.1290
2023-02-06 16:08:08 | Valid | Epoch[104/200] Iteration[007/008] Valid loss: 0.1373
2023-02-06 16:08:08 | Valid | Epoch[104/200] Iteration[008/008] Valid loss: 0.1350
2023-02-06 16:08:08 | Valid | Epoch[104/200] MIou: 0.902058907522439
2023-02-06 16:08:08 | Valid | Epoch[104/200] Pixel Accuracy: 0.9821866353352865
2023-02-06 16:08:08 | Valid | Epoch[104/200] Mean Pixel Accuracy: 0.9544107129014426
2023-02-06 16:08:08 | Stage | Epoch[104/200] Train loss:0.0402
2023-02-06 16:08:08 | Stage | Epoch[104/200] Valid loss:0.1350
2023-02-06 16:08:08 | Stage | Epoch[104/200] LR:0.01

2023-02-06 16:08:09 | Train | Epoch[105/200] Iteration[001/030] Train loss: 0.0401
2023-02-06 16:08:09 | Train | Epoch[105/200] Iteration[002/030] Train loss: 0.0396
2023-02-06 16:08:10 | Train | Epoch[105/200] Iteration[003/030] Train loss: 0.0393
2023-02-06 16:08:10 | Train | Epoch[105/200] Iteration[004/030] Train loss: 0.0391
2023-02-06 16:08:10 | Train | Epoch[105/200] Iteration[005/030] Train loss: 0.0393
2023-02-06 16:08:11 | Train | Epoch[105/200] Iteration[006/030] Train loss: 0.0398
2023-02-06 16:08:11 | Train | Epoch[105/200] Iteration[007/030] Train loss: 0.0396
2023-02-06 16:08:12 | Train | Epoch[105/200] Iteration[008/030] Train loss: 0.0396
2023-02-06 16:08:12 | Train | Epoch[105/200] Iteration[009/030] Train loss: 0.0394
2023-02-06 16:08:13 | Train | Epoch[105/200] Iteration[010/030] Train loss: 0.0393
2023-02-06 16:08:13 | Train | Epoch[105/200] Iteration[011/030] Train loss: 0.0394
2023-02-06 16:08:13 | Train | Epoch[105/200] Iteration[012/030] Train loss: 0.0394
2023-02-06 16:08:14 | Train | Epoch[105/200] Iteration[013/030] Train loss: 0.0394
2023-02-06 16:08:14 | Train | Epoch[105/200] Iteration[014/030] Train loss: 0.0395
2023-02-06 16:08:15 | Train | Epoch[105/200] Iteration[015/030] Train loss: 0.0395
2023-02-06 16:08:15 | Train | Epoch[105/200] Iteration[016/030] Train loss: 0.0394
2023-02-06 16:08:16 | Train | Epoch[105/200] Iteration[017/030] Train loss: 0.0394
2023-02-06 16:08:16 | Train | Epoch[105/200] Iteration[018/030] Train loss: 0.0394
2023-02-06 16:08:16 | Train | Epoch[105/200] Iteration[019/030] Train loss: 0.0395
2023-02-06 16:08:17 | Train | Epoch[105/200] Iteration[020/030] Train loss: 0.0395
2023-02-06 16:08:17 | Train | Epoch[105/200] Iteration[021/030] Train loss: 0.0395
2023-02-06 16:08:18 | Train | Epoch[105/200] Iteration[022/030] Train loss: 0.0395
2023-02-06 16:08:18 | Train | Epoch[105/200] Iteration[023/030] Train loss: 0.0394
2023-02-06 16:08:19 | Train | Epoch[105/200] Iteration[024/030] Train loss: 0.0395
2023-02-06 16:08:19 | Train | Epoch[105/200] Iteration[025/030] Train loss: 0.0396
2023-02-06 16:08:20 | Train | Epoch[105/200] Iteration[026/030] Train loss: 0.0395
2023-02-06 16:08:20 | Train | Epoch[105/200] Iteration[027/030] Train loss: 0.0395
2023-02-06 16:08:20 | Train | Epoch[105/200] Iteration[028/030] Train loss: 0.0395
2023-02-06 16:08:21 | Train | Epoch[105/200] Iteration[029/030] Train loss: 0.0394
2023-02-06 16:08:21 | Train | Epoch[105/200] Iteration[030/030] Train loss: 0.0394
2023-02-06 16:08:21 | Valid | Epoch[105/200] Iteration[001/008] Valid loss: 0.4659
2023-02-06 16:08:22 | Valid | Epoch[105/200] Iteration[002/008] Valid loss: 0.4080
2023-02-06 16:08:22 | Valid | Epoch[105/200] Iteration[003/008] Valid loss: 0.3946
2023-02-06 16:08:22 | Valid | Epoch[105/200] Iteration[004/008] Valid loss: 0.3881
2023-02-06 16:08:22 | Valid | Epoch[105/200] Iteration[005/008] Valid loss: 0.4020
2023-02-06 16:08:22 | Valid | Epoch[105/200] Iteration[006/008] Valid loss: 0.3889
2023-02-06 16:08:22 | Valid | Epoch[105/200] Iteration[007/008] Valid loss: 0.4173
2023-02-06 16:08:22 | Valid | Epoch[105/200] Iteration[008/008] Valid loss: 0.4335
2023-02-06 16:08:22 | Valid | Epoch[105/200] MIou: 0.8776388557299624
2023-02-06 16:08:22 | Valid | Epoch[105/200] Pixel Accuracy: 0.9752629597981771
2023-02-06 16:08:22 | Valid | Epoch[105/200] Mean Pixel Accuracy: 0.979631844120929
2023-02-06 16:08:22 | Stage | Epoch[105/200] Train loss:0.0394
2023-02-06 16:08:22 | Stage | Epoch[105/200] Valid loss:0.4335
2023-02-06 16:08:22 | Stage | Epoch[105/200] LR:0.01

2023-02-06 16:08:23 | Train | Epoch[106/200] Iteration[001/030] Train loss: 0.0388
2023-02-06 16:08:23 | Train | Epoch[106/200] Iteration[002/030] Train loss: 0.0378
2023-02-06 16:08:24 | Train | Epoch[106/200] Iteration[003/030] Train loss: 0.0377
2023-02-06 16:08:24 | Train | Epoch[106/200] Iteration[004/030] Train loss: 0.0378
2023-02-06 16:08:25 | Train | Epoch[106/200] Iteration[005/030] Train loss: 0.0381
2023-02-06 16:08:25 | Train | Epoch[106/200] Iteration[006/030] Train loss: 0.0381
2023-02-06 16:08:26 | Train | Epoch[106/200] Iteration[007/030] Train loss: 0.0380
2023-02-06 16:08:26 | Train | Epoch[106/200] Iteration[008/030] Train loss: 0.0379
2023-02-06 16:08:26 | Train | Epoch[106/200] Iteration[009/030] Train loss: 0.0380
2023-02-06 16:08:27 | Train | Epoch[106/200] Iteration[010/030] Train loss: 0.0380
2023-02-06 16:08:27 | Train | Epoch[106/200] Iteration[011/030] Train loss: 0.0381
2023-02-06 16:08:28 | Train | Epoch[106/200] Iteration[012/030] Train loss: 0.0381
2023-02-06 16:08:28 | Train | Epoch[106/200] Iteration[013/030] Train loss: 0.0382
2023-02-06 16:08:29 | Train | Epoch[106/200] Iteration[014/030] Train loss: 0.0383
2023-02-06 16:08:29 | Train | Epoch[106/200] Iteration[015/030] Train loss: 0.0384
2023-02-06 16:08:29 | Train | Epoch[106/200] Iteration[016/030] Train loss: 0.0383
2023-02-06 16:08:30 | Train | Epoch[106/200] Iteration[017/030] Train loss: 0.0385
2023-02-06 16:08:30 | Train | Epoch[106/200] Iteration[018/030] Train loss: 0.0386
2023-02-06 16:08:31 | Train | Epoch[106/200] Iteration[019/030] Train loss: 0.0385
2023-02-06 16:08:31 | Train | Epoch[106/200] Iteration[020/030] Train loss: 0.0385
2023-02-06 16:08:32 | Train | Epoch[106/200] Iteration[021/030] Train loss: 0.0385
2023-02-06 16:08:32 | Train | Epoch[106/200] Iteration[022/030] Train loss: 0.0385
2023-02-06 16:08:32 | Train | Epoch[106/200] Iteration[023/030] Train loss: 0.0385
2023-02-06 16:08:33 | Train | Epoch[106/200] Iteration[024/030] Train loss: 0.0385
2023-02-06 16:08:33 | Train | Epoch[106/200] Iteration[025/030] Train loss: 0.0385
2023-02-06 16:08:34 | Train | Epoch[106/200] Iteration[026/030] Train loss: 0.0386
2023-02-06 16:08:34 | Train | Epoch[106/200] Iteration[027/030] Train loss: 0.0385
2023-02-06 16:08:35 | Train | Epoch[106/200] Iteration[028/030] Train loss: 0.0385
2023-02-06 16:08:35 | Train | Epoch[106/200] Iteration[029/030] Train loss: 0.0385
2023-02-06 16:08:35 | Train | Epoch[106/200] Iteration[030/030] Train loss: 0.0385
2023-02-06 16:08:36 | Valid | Epoch[106/200] Iteration[001/008] Valid loss: 0.4776
2023-02-06 16:08:36 | Valid | Epoch[106/200] Iteration[002/008] Valid loss: 0.4216
2023-02-06 16:08:36 | Valid | Epoch[106/200] Iteration[003/008] Valid loss: 0.3989
2023-02-06 16:08:36 | Valid | Epoch[106/200] Iteration[004/008] Valid loss: 0.4120
2023-02-06 16:08:36 | Valid | Epoch[106/200] Iteration[005/008] Valid loss: 0.4234
2023-02-06 16:08:36 | Valid | Epoch[106/200] Iteration[006/008] Valid loss: 0.4192
2023-02-06 16:08:36 | Valid | Epoch[106/200] Iteration[007/008] Valid loss: 0.4449
2023-02-06 16:08:36 | Valid | Epoch[106/200] Iteration[008/008] Valid loss: 0.4616
2023-02-06 16:08:36 | Valid | Epoch[106/200] MIou: 0.8847535637851601
2023-02-06 16:08:36 | Valid | Epoch[106/200] Pixel Accuracy: 0.9769910176595052
2023-02-06 16:08:36 | Valid | Epoch[106/200] Mean Pixel Accuracy: 0.981291791230753
2023-02-06 16:08:36 | Stage | Epoch[106/200] Train loss:0.0385
2023-02-06 16:08:36 | Stage | Epoch[106/200] Valid loss:0.4616
2023-02-06 16:08:36 | Stage | Epoch[106/200] LR:0.01

2023-02-06 16:08:37 | Train | Epoch[107/200] Iteration[001/030] Train loss: 0.0376
2023-02-06 16:08:38 | Train | Epoch[107/200] Iteration[002/030] Train loss: 0.0378
2023-02-06 16:08:38 | Train | Epoch[107/200] Iteration[003/030] Train loss: 0.0375
2023-02-06 16:08:38 | Train | Epoch[107/200] Iteration[004/030] Train loss: 0.0374
2023-02-06 16:08:39 | Train | Epoch[107/200] Iteration[005/030] Train loss: 0.0375
2023-02-06 16:08:39 | Train | Epoch[107/200] Iteration[006/030] Train loss: 0.0375
2023-02-06 16:08:40 | Train | Epoch[107/200] Iteration[007/030] Train loss: 0.0375
2023-02-06 16:08:40 | Train | Epoch[107/200] Iteration[008/030] Train loss: 0.0379
2023-02-06 16:08:41 | Train | Epoch[107/200] Iteration[009/030] Train loss: 0.0377
2023-02-06 16:08:41 | Train | Epoch[107/200] Iteration[010/030] Train loss: 0.0378
2023-02-06 16:08:41 | Train | Epoch[107/200] Iteration[011/030] Train loss: 0.0383
2023-02-06 16:08:42 | Train | Epoch[107/200] Iteration[012/030] Train loss: 0.0382
2023-02-06 16:08:42 | Train | Epoch[107/200] Iteration[013/030] Train loss: 0.0383
2023-02-06 16:08:43 | Train | Epoch[107/200] Iteration[014/030] Train loss: 0.0384
2023-02-06 16:08:43 | Train | Epoch[107/200] Iteration[015/030] Train loss: 0.0384
2023-02-06 16:08:44 | Train | Epoch[107/200] Iteration[016/030] Train loss: 0.0384
2023-02-06 16:08:44 | Train | Epoch[107/200] Iteration[017/030] Train loss: 0.0384
2023-02-06 16:08:44 | Train | Epoch[107/200] Iteration[018/030] Train loss: 0.0383
2023-02-06 16:08:45 | Train | Epoch[107/200] Iteration[019/030] Train loss: 0.0383
2023-02-06 16:08:45 | Train | Epoch[107/200] Iteration[020/030] Train loss: 0.0382
2023-02-06 16:08:46 | Train | Epoch[107/200] Iteration[021/030] Train loss: 0.0382
2023-02-06 16:08:46 | Train | Epoch[107/200] Iteration[022/030] Train loss: 0.0383
2023-02-06 16:08:47 | Train | Epoch[107/200] Iteration[023/030] Train loss: 0.0382
2023-02-06 16:08:47 | Train | Epoch[107/200] Iteration[024/030] Train loss: 0.0383
2023-02-06 16:08:48 | Train | Epoch[107/200] Iteration[025/030] Train loss: 0.0383
2023-02-06 16:08:48 | Train | Epoch[107/200] Iteration[026/030] Train loss: 0.0383
2023-02-06 16:08:48 | Train | Epoch[107/200] Iteration[027/030] Train loss: 0.0383
2023-02-06 16:08:49 | Train | Epoch[107/200] Iteration[028/030] Train loss: 0.0383
2023-02-06 16:08:49 | Train | Epoch[107/200] Iteration[029/030] Train loss: 0.0383
2023-02-06 16:08:49 | Train | Epoch[107/200] Iteration[030/030] Train loss: 0.0383
2023-02-06 16:08:50 | Valid | Epoch[107/200] Iteration[001/008] Valid loss: 0.0825
2023-02-06 16:08:50 | Valid | Epoch[107/200] Iteration[002/008] Valid loss: 0.0731
2023-02-06 16:08:50 | Valid | Epoch[107/200] Iteration[003/008] Valid loss: 0.0696
2023-02-06 16:08:50 | Valid | Epoch[107/200] Iteration[004/008] Valid loss: 0.0680
2023-02-06 16:08:50 | Valid | Epoch[107/200] Iteration[005/008] Valid loss: 0.0679
2023-02-06 16:08:50 | Valid | Epoch[107/200] Iteration[006/008] Valid loss: 0.0670
2023-02-06 16:08:50 | Valid | Epoch[107/200] Iteration[007/008] Valid loss: 0.0674
2023-02-06 16:08:51 | Valid | Epoch[107/200] Iteration[008/008] Valid loss: 0.0676
2023-02-06 16:08:51 | Valid | Epoch[107/200] MIou: 0.8667379371164732
2023-02-06 16:08:51 | Valid | Epoch[107/200] Pixel Accuracy: 0.9776420593261719
2023-02-06 16:08:51 | Valid | Epoch[107/200] Mean Pixel Accuracy: 0.8856231904465599
2023-02-06 16:08:51 | Stage | Epoch[107/200] Train loss:0.0383
2023-02-06 16:08:51 | Stage | Epoch[107/200] Valid loss:0.0676
2023-02-06 16:08:51 | Stage | Epoch[107/200] LR:0.01

2023-02-06 16:08:51 | Train | Epoch[108/200] Iteration[001/030] Train loss: 0.0382
2023-02-06 16:08:52 | Train | Epoch[108/200] Iteration[002/030] Train loss: 0.0384
2023-02-06 16:08:52 | Train | Epoch[108/200] Iteration[003/030] Train loss: 0.0380
2023-02-06 16:08:53 | Train | Epoch[108/200] Iteration[004/030] Train loss: 0.0380
2023-02-06 16:08:53 | Train | Epoch[108/200] Iteration[005/030] Train loss: 0.0380
2023-02-06 16:08:54 | Train | Epoch[108/200] Iteration[006/030] Train loss: 0.0379
2023-02-06 16:08:54 | Train | Epoch[108/200] Iteration[007/030] Train loss: 0.0378
2023-02-06 16:08:54 | Train | Epoch[108/200] Iteration[008/030] Train loss: 0.0379
2023-02-06 16:08:55 | Train | Epoch[108/200] Iteration[009/030] Train loss: 0.0377
2023-02-06 16:08:55 | Train | Epoch[108/200] Iteration[010/030] Train loss: 0.0376
2023-02-06 16:08:56 | Train | Epoch[108/200] Iteration[011/030] Train loss: 0.0377
2023-02-06 16:08:56 | Train | Epoch[108/200] Iteration[012/030] Train loss: 0.0377
2023-02-06 16:08:57 | Train | Epoch[108/200] Iteration[013/030] Train loss: 0.0378
2023-02-06 16:08:57 | Train | Epoch[108/200] Iteration[014/030] Train loss: 0.0379
2023-02-06 16:08:57 | Train | Epoch[108/200] Iteration[015/030] Train loss: 0.0379
2023-02-06 16:08:58 | Train | Epoch[108/200] Iteration[016/030] Train loss: 0.0379
2023-02-06 16:08:58 | Train | Epoch[108/200] Iteration[017/030] Train loss: 0.0379
2023-02-06 16:08:59 | Train | Epoch[108/200] Iteration[018/030] Train loss: 0.0379
2023-02-06 16:08:59 | Train | Epoch[108/200] Iteration[019/030] Train loss: 0.0379
2023-02-06 16:09:00 | Train | Epoch[108/200] Iteration[020/030] Train loss: 0.0379
2023-02-06 16:09:00 | Train | Epoch[108/200] Iteration[021/030] Train loss: 0.0378
2023-02-06 16:09:00 | Train | Epoch[108/200] Iteration[022/030] Train loss: 0.0378
2023-02-06 16:09:01 | Train | Epoch[108/200] Iteration[023/030] Train loss: 0.0378
2023-02-06 16:09:01 | Train | Epoch[108/200] Iteration[024/030] Train loss: 0.0377
2023-02-06 16:09:02 | Train | Epoch[108/200] Iteration[025/030] Train loss: 0.0377
2023-02-06 16:09:02 | Train | Epoch[108/200] Iteration[026/030] Train loss: 0.0376
2023-02-06 16:09:03 | Train | Epoch[108/200] Iteration[027/030] Train loss: 0.0376
2023-02-06 16:09:03 | Train | Epoch[108/200] Iteration[028/030] Train loss: 0.0375
2023-02-06 16:09:03 | Train | Epoch[108/200] Iteration[029/030] Train loss: 0.0377
2023-02-06 16:09:04 | Train | Epoch[108/200] Iteration[030/030] Train loss: 0.0376
2023-02-06 16:09:04 | Valid | Epoch[108/200] Iteration[001/008] Valid loss: 0.4743
2023-02-06 16:09:04 | Valid | Epoch[108/200] Iteration[002/008] Valid loss: 0.4227
2023-02-06 16:09:04 | Valid | Epoch[108/200] Iteration[003/008] Valid loss: 0.4131
2023-02-06 16:09:04 | Valid | Epoch[108/200] Iteration[004/008] Valid loss: 0.4057
2023-02-06 16:09:04 | Valid | Epoch[108/200] Iteration[005/008] Valid loss: 0.4224
2023-02-06 16:09:05 | Valid | Epoch[108/200] Iteration[006/008] Valid loss: 0.4059
2023-02-06 16:09:05 | Valid | Epoch[108/200] Iteration[007/008] Valid loss: 0.4365
2023-02-06 16:09:05 | Valid | Epoch[108/200] Iteration[008/008] Valid loss: 0.4561
2023-02-06 16:09:05 | Valid | Epoch[108/200] MIou: 0.8885393874339333
2023-02-06 16:09:05 | Valid | Epoch[108/200] Pixel Accuracy: 0.977972666422526
2023-02-06 16:09:05 | Valid | Epoch[108/200] Mean Pixel Accuracy: 0.9803413364518778
2023-02-06 16:09:05 | Stage | Epoch[108/200] Train loss:0.0376
2023-02-06 16:09:05 | Stage | Epoch[108/200] Valid loss:0.4561
2023-02-06 16:09:05 | Stage | Epoch[108/200] LR:0.01

2023-02-06 16:09:06 | Train | Epoch[109/200] Iteration[001/030] Train loss: 0.0369
2023-02-06 16:09:06 | Train | Epoch[109/200] Iteration[002/030] Train loss: 0.0374
2023-02-06 16:09:06 | Train | Epoch[109/200] Iteration[003/030] Train loss: 0.0383
2023-02-06 16:09:07 | Train | Epoch[109/200] Iteration[004/030] Train loss: 0.0379
2023-02-06 16:09:07 | Train | Epoch[109/200] Iteration[005/030] Train loss: 0.0377
2023-02-06 16:09:08 | Train | Epoch[109/200] Iteration[006/030] Train loss: 0.0374
2023-02-06 16:09:08 | Train | Epoch[109/200] Iteration[007/030] Train loss: 0.0378
2023-02-06 16:09:09 | Train | Epoch[109/200] Iteration[008/030] Train loss: 0.0375
2023-02-06 16:09:09 | Train | Epoch[109/200] Iteration[009/030] Train loss: 0.0375
2023-02-06 16:09:09 | Train | Epoch[109/200] Iteration[010/030] Train loss: 0.0374
2023-02-06 16:09:10 | Train | Epoch[109/200] Iteration[011/030] Train loss: 0.0376
2023-02-06 16:09:10 | Train | Epoch[109/200] Iteration[012/030] Train loss: 0.0375
2023-02-06 16:09:11 | Train | Epoch[109/200] Iteration[013/030] Train loss: 0.0374
2023-02-06 16:09:11 | Train | Epoch[109/200] Iteration[014/030] Train loss: 0.0373
2023-02-06 16:09:12 | Train | Epoch[109/200] Iteration[015/030] Train loss: 0.0373
2023-02-06 16:09:12 | Train | Epoch[109/200] Iteration[016/030] Train loss: 0.0374
2023-02-06 16:09:13 | Train | Epoch[109/200] Iteration[017/030] Train loss: 0.0374
2023-02-06 16:09:13 | Train | Epoch[109/200] Iteration[018/030] Train loss: 0.0374
2023-02-06 16:09:13 | Train | Epoch[109/200] Iteration[019/030] Train loss: 0.0374
2023-02-06 16:09:14 | Train | Epoch[109/200] Iteration[020/030] Train loss: 0.0374
2023-02-06 16:09:14 | Train | Epoch[109/200] Iteration[021/030] Train loss: 0.0374
2023-02-06 16:09:15 | Train | Epoch[109/200] Iteration[022/030] Train loss: 0.0374
2023-02-06 16:09:15 | Train | Epoch[109/200] Iteration[023/030] Train loss: 0.0373
2023-02-06 16:09:16 | Train | Epoch[109/200] Iteration[024/030] Train loss: 0.0373
2023-02-06 16:09:16 | Train | Epoch[109/200] Iteration[025/030] Train loss: 0.0372
2023-02-06 16:09:16 | Train | Epoch[109/200] Iteration[026/030] Train loss: 0.0372
2023-02-06 16:09:17 | Train | Epoch[109/200] Iteration[027/030] Train loss: 0.0371
2023-02-06 16:09:17 | Train | Epoch[109/200] Iteration[028/030] Train loss: 0.0371
2023-02-06 16:09:18 | Train | Epoch[109/200] Iteration[029/030] Train loss: 0.0372
2023-02-06 16:09:18 | Train | Epoch[109/200] Iteration[030/030] Train loss: 0.0372
2023-02-06 16:09:18 | Valid | Epoch[109/200] Iteration[001/008] Valid loss: 0.5655
2023-02-06 16:09:19 | Valid | Epoch[109/200] Iteration[002/008] Valid loss: 0.5405
2023-02-06 16:09:19 | Valid | Epoch[109/200] Iteration[003/008] Valid loss: 0.5322
2023-02-06 16:09:19 | Valid | Epoch[109/200] Iteration[004/008] Valid loss: 0.5315
2023-02-06 16:09:19 | Valid | Epoch[109/200] Iteration[005/008] Valid loss: 0.5507
2023-02-06 16:09:19 | Valid | Epoch[109/200] Iteration[006/008] Valid loss: 0.5451
2023-02-06 16:09:19 | Valid | Epoch[109/200] Iteration[007/008] Valid loss: 0.5795
2023-02-06 16:09:19 | Valid | Epoch[109/200] Iteration[008/008] Valid loss: 0.5904
2023-02-06 16:09:19 | Valid | Epoch[109/200] MIou: 0.8754485722626518
2023-02-06 16:09:19 | Valid | Epoch[109/200] Pixel Accuracy: 0.9745941162109375
2023-02-06 16:09:19 | Valid | Epoch[109/200] Mean Pixel Accuracy: 0.9816989602205317
2023-02-06 16:09:19 | Stage | Epoch[109/200] Train loss:0.0372
2023-02-06 16:09:19 | Stage | Epoch[109/200] Valid loss:0.5904
2023-02-06 16:09:19 | Stage | Epoch[109/200] LR:0.01

2023-02-06 16:09:20 | Train | Epoch[110/200] Iteration[001/030] Train loss: 0.0376
2023-02-06 16:09:20 | Train | Epoch[110/200] Iteration[002/030] Train loss: 0.0374
2023-02-06 16:09:21 | Train | Epoch[110/200] Iteration[003/030] Train loss: 0.0369
2023-02-06 16:09:21 | Train | Epoch[110/200] Iteration[004/030] Train loss: 0.0368
2023-02-06 16:09:22 | Train | Epoch[110/200] Iteration[005/030] Train loss: 0.0369
2023-02-06 16:09:22 | Train | Epoch[110/200] Iteration[006/030] Train loss: 0.0366
2023-02-06 16:09:23 | Train | Epoch[110/200] Iteration[007/030] Train loss: 0.0366
2023-02-06 16:09:23 | Train | Epoch[110/200] Iteration[008/030] Train loss: 0.0366
2023-02-06 16:09:23 | Train | Epoch[110/200] Iteration[009/030] Train loss: 0.0365
2023-02-06 16:09:24 | Train | Epoch[110/200] Iteration[010/030] Train loss: 0.0364
2023-02-06 16:09:24 | Train | Epoch[110/200] Iteration[011/030] Train loss: 0.0365
2023-02-06 16:09:25 | Train | Epoch[110/200] Iteration[012/030] Train loss: 0.0364
2023-02-06 16:09:25 | Train | Epoch[110/200] Iteration[013/030] Train loss: 0.0365
2023-02-06 16:09:26 | Train | Epoch[110/200] Iteration[014/030] Train loss: 0.0364
2023-02-06 16:09:26 | Train | Epoch[110/200] Iteration[015/030] Train loss: 0.0364
2023-02-06 16:09:26 | Train | Epoch[110/200] Iteration[016/030] Train loss: 0.0364
2023-02-06 16:09:27 | Train | Epoch[110/200] Iteration[017/030] Train loss: 0.0364
2023-02-06 16:09:27 | Train | Epoch[110/200] Iteration[018/030] Train loss: 0.0363
2023-02-06 16:09:28 | Train | Epoch[110/200] Iteration[019/030] Train loss: 0.0364
2023-02-06 16:09:28 | Train | Epoch[110/200] Iteration[020/030] Train loss: 0.0364
2023-02-06 16:09:29 | Train | Epoch[110/200] Iteration[021/030] Train loss: 0.0363
2023-02-06 16:09:29 | Train | Epoch[110/200] Iteration[022/030] Train loss: 0.0365
2023-02-06 16:09:30 | Train | Epoch[110/200] Iteration[023/030] Train loss: 0.0365
2023-02-06 16:09:30 | Train | Epoch[110/200] Iteration[024/030] Train loss: 0.0365
2023-02-06 16:09:30 | Train | Epoch[110/200] Iteration[025/030] Train loss: 0.0365
2023-02-06 16:09:31 | Train | Epoch[110/200] Iteration[026/030] Train loss: 0.0366
2023-02-06 16:09:31 | Train | Epoch[110/200] Iteration[027/030] Train loss: 0.0366
2023-02-06 16:09:32 | Train | Epoch[110/200] Iteration[028/030] Train loss: 0.0366
2023-02-06 16:09:32 | Train | Epoch[110/200] Iteration[029/030] Train loss: 0.0366
2023-02-06 16:09:32 | Train | Epoch[110/200] Iteration[030/030] Train loss: 0.0365
2023-02-06 16:09:33 | Valid | Epoch[110/200] Iteration[001/008] Valid loss: 0.1582
2023-02-06 16:09:33 | Valid | Epoch[110/200] Iteration[002/008] Valid loss: 0.1196
2023-02-06 16:09:33 | Valid | Epoch[110/200] Iteration[003/008] Valid loss: 0.1026
2023-02-06 16:09:33 | Valid | Epoch[110/200] Iteration[004/008] Valid loss: 0.0985
2023-02-06 16:09:33 | Valid | Epoch[110/200] Iteration[005/008] Valid loss: 0.0974
2023-02-06 16:09:33 | Valid | Epoch[110/200] Iteration[006/008] Valid loss: 0.0974
2023-02-06 16:09:33 | Valid | Epoch[110/200] Iteration[007/008] Valid loss: 0.1022
2023-02-06 16:09:33 | Valid | Epoch[110/200] Iteration[008/008] Valid loss: 0.0995
2023-02-06 16:09:33 | Valid | Epoch[110/200] MIou: 0.9362931793875379
2023-02-06 16:09:33 | Valid | Epoch[110/200] Pixel Accuracy: 0.988922119140625
2023-02-06 16:09:33 | Valid | Epoch[110/200] Mean Pixel Accuracy: 0.9673699104699298
2023-02-06 16:09:33 | Stage | Epoch[110/200] Train loss:0.0365
2023-02-06 16:09:33 | Stage | Epoch[110/200] Valid loss:0.0995
2023-02-06 16:09:33 | Stage | Epoch[110/200] LR:0.01

2023-02-06 16:09:34 | Train | Epoch[111/200] Iteration[001/030] Train loss: 0.0342
2023-02-06 16:09:35 | Train | Epoch[111/200] Iteration[002/030] Train loss: 0.0348
2023-02-06 16:09:35 | Train | Epoch[111/200] Iteration[003/030] Train loss: 0.0346
2023-02-06 16:09:35 | Train | Epoch[111/200] Iteration[004/030] Train loss: 0.0352
2023-02-06 16:09:36 | Train | Epoch[111/200] Iteration[005/030] Train loss: 0.0358
2023-02-06 16:09:36 | Train | Epoch[111/200] Iteration[006/030] Train loss: 0.0362
2023-02-06 16:09:37 | Train | Epoch[111/200] Iteration[007/030] Train loss: 0.0360
2023-02-06 16:09:37 | Train | Epoch[111/200] Iteration[008/030] Train loss: 0.0358
2023-02-06 16:09:38 | Train | Epoch[111/200] Iteration[009/030] Train loss: 0.0359
2023-02-06 16:09:38 | Train | Epoch[111/200] Iteration[010/030] Train loss: 0.0359
2023-02-06 16:09:39 | Train | Epoch[111/200] Iteration[011/030] Train loss: 0.0359
2023-02-06 16:09:39 | Train | Epoch[111/200] Iteration[012/030] Train loss: 0.0358
2023-02-06 16:09:39 | Train | Epoch[111/200] Iteration[013/030] Train loss: 0.0357
2023-02-06 16:09:40 | Train | Epoch[111/200] Iteration[014/030] Train loss: 0.0357
2023-02-06 16:09:40 | Train | Epoch[111/200] Iteration[015/030] Train loss: 0.0356
2023-02-06 16:09:41 | Train | Epoch[111/200] Iteration[016/030] Train loss: 0.0356
2023-02-06 16:09:41 | Train | Epoch[111/200] Iteration[017/030] Train loss: 0.0355
2023-02-06 16:09:42 | Train | Epoch[111/200] Iteration[018/030] Train loss: 0.0357
2023-02-06 16:09:42 | Train | Epoch[111/200] Iteration[019/030] Train loss: 0.0358
2023-02-06 16:09:42 | Train | Epoch[111/200] Iteration[020/030] Train loss: 0.0358
2023-02-06 16:09:43 | Train | Epoch[111/200] Iteration[021/030] Train loss: 0.0358
2023-02-06 16:09:43 | Train | Epoch[111/200] Iteration[022/030] Train loss: 0.0358
2023-02-06 16:09:44 | Train | Epoch[111/200] Iteration[023/030] Train loss: 0.0358
2023-02-06 16:09:44 | Train | Epoch[111/200] Iteration[024/030] Train loss: 0.0358
2023-02-06 16:09:45 | Train | Epoch[111/200] Iteration[025/030] Train loss: 0.0358
2023-02-06 16:09:45 | Train | Epoch[111/200] Iteration[026/030] Train loss: 0.0358
2023-02-06 16:09:45 | Train | Epoch[111/200] Iteration[027/030] Train loss: 0.0358
2023-02-06 16:09:46 | Train | Epoch[111/200] Iteration[028/030] Train loss: 0.0358
2023-02-06 16:09:46 | Train | Epoch[111/200] Iteration[029/030] Train loss: 0.0358
2023-02-06 16:09:46 | Train | Epoch[111/200] Iteration[030/030] Train loss: 0.0359
2023-02-06 16:09:47 | Valid | Epoch[111/200] Iteration[001/008] Valid loss: 0.1013
2023-02-06 16:09:47 | Valid | Epoch[111/200] Iteration[002/008] Valid loss: 0.1040
2023-02-06 16:09:47 | Valid | Epoch[111/200] Iteration[003/008] Valid loss: 0.1077
2023-02-06 16:09:47 | Valid | Epoch[111/200] Iteration[004/008] Valid loss: 0.1065
2023-02-06 16:09:47 | Valid | Epoch[111/200] Iteration[005/008] Valid loss: 0.1087
2023-02-06 16:09:47 | Valid | Epoch[111/200] Iteration[006/008] Valid loss: 0.1079
2023-02-06 16:09:47 | Valid | Epoch[111/200] Iteration[007/008] Valid loss: 0.1062
2023-02-06 16:09:48 | Valid | Epoch[111/200] Iteration[008/008] Valid loss: 0.1089
2023-02-06 16:09:48 | Valid | Epoch[111/200] MIou: 0.6940230927110285
2023-02-06 16:09:48 | Valid | Epoch[111/200] Pixel Accuracy: 0.9493319193522135
2023-02-06 16:09:48 | Valid | Epoch[111/200] Mean Pixel Accuracy: 0.7209665425120483
2023-02-06 16:09:48 | Stage | Epoch[111/200] Train loss:0.0359
2023-02-06 16:09:48 | Stage | Epoch[111/200] Valid loss:0.1089
2023-02-06 16:09:48 | Stage | Epoch[111/200] LR:0.01

2023-02-06 16:09:48 | Train | Epoch[112/200] Iteration[001/030] Train loss: 0.0352
2023-02-06 16:09:49 | Train | Epoch[112/200] Iteration[002/030] Train loss: 0.0349
2023-02-06 16:09:49 | Train | Epoch[112/200] Iteration[003/030] Train loss: 0.0347
2023-02-06 16:09:50 | Train | Epoch[112/200] Iteration[004/030] Train loss: 0.0373
2023-02-06 16:09:50 | Train | Epoch[112/200] Iteration[005/030] Train loss: 0.0367
2023-02-06 16:09:51 | Train | Epoch[112/200] Iteration[006/030] Train loss: 0.0365
2023-02-06 16:09:51 | Train | Epoch[112/200] Iteration[007/030] Train loss: 0.0365
2023-02-06 16:09:51 | Train | Epoch[112/200] Iteration[008/030] Train loss: 0.0366
2023-02-06 16:09:52 | Train | Epoch[112/200] Iteration[009/030] Train loss: 0.0368
2023-02-06 16:09:52 | Train | Epoch[112/200] Iteration[010/030] Train loss: 0.0367
2023-02-06 16:09:53 | Train | Epoch[112/200] Iteration[011/030] Train loss: 0.0367
2023-02-06 16:09:53 | Train | Epoch[112/200] Iteration[012/030] Train loss: 0.0366
2023-02-06 16:09:54 | Train | Epoch[112/200] Iteration[013/030] Train loss: 0.0366
2023-02-06 16:09:54 | Train | Epoch[112/200] Iteration[014/030] Train loss: 0.0365
2023-02-06 16:09:55 | Train | Epoch[112/200] Iteration[015/030] Train loss: 0.0365
2023-02-06 16:09:55 | Train | Epoch[112/200] Iteration[016/030] Train loss: 0.0364
2023-02-06 16:09:55 | Train | Epoch[112/200] Iteration[017/030] Train loss: 0.0363
2023-02-06 16:09:56 | Train | Epoch[112/200] Iteration[018/030] Train loss: 0.0362
2023-02-06 16:09:56 | Train | Epoch[112/200] Iteration[019/030] Train loss: 0.0362
2023-02-06 16:09:57 | Train | Epoch[112/200] Iteration[020/030] Train loss: 0.0361
2023-02-06 16:09:57 | Train | Epoch[112/200] Iteration[021/030] Train loss: 0.0361
2023-02-06 16:09:58 | Train | Epoch[112/200] Iteration[022/030] Train loss: 0.0361
2023-02-06 16:09:58 | Train | Epoch[112/200] Iteration[023/030] Train loss: 0.0361
2023-02-06 16:09:58 | Train | Epoch[112/200] Iteration[024/030] Train loss: 0.0361
2023-02-06 16:09:59 | Train | Epoch[112/200] Iteration[025/030] Train loss: 0.0361
2023-02-06 16:09:59 | Train | Epoch[112/200] Iteration[026/030] Train loss: 0.0361
2023-02-06 16:10:00 | Train | Epoch[112/200] Iteration[027/030] Train loss: 0.0361
2023-02-06 16:10:00 | Train | Epoch[112/200] Iteration[028/030] Train loss: 0.0360
2023-02-06 16:10:01 | Train | Epoch[112/200] Iteration[029/030] Train loss: 0.0360
2023-02-06 16:10:01 | Train | Epoch[112/200] Iteration[030/030] Train loss: 0.0360
2023-02-06 16:10:01 | Valid | Epoch[112/200] Iteration[001/008] Valid loss: 0.0994
2023-02-06 16:10:01 | Valid | Epoch[112/200] Iteration[002/008] Valid loss: 0.0845
2023-02-06 16:10:01 | Valid | Epoch[112/200] Iteration[003/008] Valid loss: 0.0812
2023-02-06 16:10:01 | Valid | Epoch[112/200] Iteration[004/008] Valid loss: 0.0792
2023-02-06 16:10:02 | Valid | Epoch[112/200] Iteration[005/008] Valid loss: 0.0797
2023-02-06 16:10:02 | Valid | Epoch[112/200] Iteration[006/008] Valid loss: 0.0782
2023-02-06 16:10:02 | Valid | Epoch[112/200] Iteration[007/008] Valid loss: 0.0788
2023-02-06 16:10:02 | Valid | Epoch[112/200] Iteration[008/008] Valid loss: 0.0792
2023-02-06 16:10:02 | Valid | Epoch[112/200] MIou: 0.8673105600190016
2023-02-06 16:10:02 | Valid | Epoch[112/200] Pixel Accuracy: 0.9773483276367188
2023-02-06 16:10:02 | Valid | Epoch[112/200] Mean Pixel Accuracy: 0.892937158895425
2023-02-06 16:10:02 | Stage | Epoch[112/200] Train loss:0.0360
2023-02-06 16:10:02 | Stage | Epoch[112/200] Valid loss:0.0792
2023-02-06 16:10:02 | Stage | Epoch[112/200] LR:0.01

2023-02-06 16:10:03 | Train | Epoch[113/200] Iteration[001/030] Train loss: 0.0339
2023-02-06 16:10:03 | Train | Epoch[113/200] Iteration[002/030] Train loss: 0.0347
2023-02-06 16:10:04 | Train | Epoch[113/200] Iteration[003/030] Train loss: 0.0347
2023-02-06 16:10:04 | Train | Epoch[113/200] Iteration[004/030] Train loss: 0.0346
2023-02-06 16:10:04 | Train | Epoch[113/200] Iteration[005/030] Train loss: 0.0347
2023-02-06 16:10:05 | Train | Epoch[113/200] Iteration[006/030] Train loss: 0.0346
2023-02-06 16:10:05 | Train | Epoch[113/200] Iteration[007/030] Train loss: 0.0345
2023-02-06 16:10:06 | Train | Epoch[113/200] Iteration[008/030] Train loss: 0.0345
2023-02-06 16:10:06 | Train | Epoch[113/200] Iteration[009/030] Train loss: 0.0345
2023-02-06 16:10:07 | Train | Epoch[113/200] Iteration[010/030] Train loss: 0.0345
2023-02-06 16:10:07 | Train | Epoch[113/200] Iteration[011/030] Train loss: 0.0345
2023-02-06 16:10:08 | Train | Epoch[113/200] Iteration[012/030] Train loss: 0.0346
2023-02-06 16:10:08 | Train | Epoch[113/200] Iteration[013/030] Train loss: 0.0345
2023-02-06 16:10:08 | Train | Epoch[113/200] Iteration[014/030] Train loss: 0.0345
2023-02-06 16:10:09 | Train | Epoch[113/200] Iteration[015/030] Train loss: 0.0346
2023-02-06 16:10:09 | Train | Epoch[113/200] Iteration[016/030] Train loss: 0.0351
2023-02-06 16:10:10 | Train | Epoch[113/200] Iteration[017/030] Train loss: 0.0351
2023-02-06 16:10:10 | Train | Epoch[113/200] Iteration[018/030] Train loss: 0.0350
2023-02-06 16:10:11 | Train | Epoch[113/200] Iteration[019/030] Train loss: 0.0350
2023-02-06 16:10:11 | Train | Epoch[113/200] Iteration[020/030] Train loss: 0.0350
2023-02-06 16:10:11 | Train | Epoch[113/200] Iteration[021/030] Train loss: 0.0350
2023-02-06 16:10:12 | Train | Epoch[113/200] Iteration[022/030] Train loss: 0.0351
2023-02-06 16:10:12 | Train | Epoch[113/200] Iteration[023/030] Train loss: 0.0351
2023-02-06 16:10:13 | Train | Epoch[113/200] Iteration[024/030] Train loss: 0.0352
2023-02-06 16:10:13 | Train | Epoch[113/200] Iteration[025/030] Train loss: 0.0351
2023-02-06 16:10:14 | Train | Epoch[113/200] Iteration[026/030] Train loss: 0.0351
2023-02-06 16:10:14 | Train | Epoch[113/200] Iteration[027/030] Train loss: 0.0352
2023-02-06 16:10:14 | Train | Epoch[113/200] Iteration[028/030] Train loss: 0.0352
2023-02-06 16:10:15 | Train | Epoch[113/200] Iteration[029/030] Train loss: 0.0352
2023-02-06 16:10:15 | Train | Epoch[113/200] Iteration[030/030] Train loss: 0.0352
2023-02-06 16:10:16 | Valid | Epoch[113/200] Iteration[001/008] Valid loss: 0.3061
2023-02-06 16:10:16 | Valid | Epoch[113/200] Iteration[002/008] Valid loss: 0.2451
2023-02-06 16:10:16 | Valid | Epoch[113/200] Iteration[003/008] Valid loss: 0.2114
2023-02-06 16:10:16 | Valid | Epoch[113/200] Iteration[004/008] Valid loss: 0.2133
2023-02-06 16:10:16 | Valid | Epoch[113/200] Iteration[005/008] Valid loss: 0.2147
2023-02-06 16:10:16 | Valid | Epoch[113/200] Iteration[006/008] Valid loss: 0.2175
2023-02-06 16:10:16 | Valid | Epoch[113/200] Iteration[007/008] Valid loss: 0.2326
2023-02-06 16:10:16 | Valid | Epoch[113/200] Iteration[008/008] Valid loss: 0.2288
2023-02-06 16:10:16 | Valid | Epoch[113/200] MIou: 0.9151147742172103
2023-02-06 16:10:16 | Valid | Epoch[113/200] Pixel Accuracy: 0.9842948913574219
2023-02-06 16:10:16 | Valid | Epoch[113/200] Mean Pixel Accuracy: 0.9759984995380742
2023-02-06 16:10:16 | Stage | Epoch[113/200] Train loss:0.0352
2023-02-06 16:10:16 | Stage | Epoch[113/200] Valid loss:0.2288
2023-02-06 16:10:16 | Stage | Epoch[113/200] LR:0.01

2023-02-06 16:10:17 | Train | Epoch[114/200] Iteration[001/030] Train loss: 0.0361
2023-02-06 16:10:18 | Train | Epoch[114/200] Iteration[002/030] Train loss: 0.0348
2023-02-06 16:10:18 | Train | Epoch[114/200] Iteration[003/030] Train loss: 0.0345
2023-02-06 16:10:18 | Train | Epoch[114/200] Iteration[004/030] Train loss: 0.0344
2023-02-06 16:10:19 | Train | Epoch[114/200] Iteration[005/030] Train loss: 0.0344
2023-02-06 16:10:19 | Train | Epoch[114/200] Iteration[006/030] Train loss: 0.0343
2023-02-06 16:10:20 | Train | Epoch[114/200] Iteration[007/030] Train loss: 0.0344
2023-02-06 16:10:20 | Train | Epoch[114/200] Iteration[008/030] Train loss: 0.0345
2023-02-06 16:10:21 | Train | Epoch[114/200] Iteration[009/030] Train loss: 0.0344
2023-02-06 16:10:21 | Train | Epoch[114/200] Iteration[010/030] Train loss: 0.0344
2023-02-06 16:10:21 | Train | Epoch[114/200] Iteration[011/030] Train loss: 0.0344
2023-02-06 16:10:22 | Train | Epoch[114/200] Iteration[012/030] Train loss: 0.0343
2023-02-06 16:10:22 | Train | Epoch[114/200] Iteration[013/030] Train loss: 0.0342
2023-02-06 16:10:23 | Train | Epoch[114/200] Iteration[014/030] Train loss: 0.0342
2023-02-06 16:10:23 | Train | Epoch[114/200] Iteration[015/030] Train loss: 0.0343
2023-02-06 16:10:24 | Train | Epoch[114/200] Iteration[016/030] Train loss: 0.0343
2023-02-06 16:10:24 | Train | Epoch[114/200] Iteration[017/030] Train loss: 0.0344
2023-02-06 16:10:24 | Train | Epoch[114/200] Iteration[018/030] Train loss: 0.0344
2023-02-06 16:10:25 | Train | Epoch[114/200] Iteration[019/030] Train loss: 0.0345
2023-02-06 16:10:25 | Train | Epoch[114/200] Iteration[020/030] Train loss: 0.0346
2023-02-06 16:10:26 | Train | Epoch[114/200] Iteration[021/030] Train loss: 0.0347
2023-02-06 16:10:26 | Train | Epoch[114/200] Iteration[022/030] Train loss: 0.0347
2023-02-06 16:10:27 | Train | Epoch[114/200] Iteration[023/030] Train loss: 0.0348
2023-02-06 16:10:27 | Train | Epoch[114/200] Iteration[024/030] Train loss: 0.0348
2023-02-06 16:10:27 | Train | Epoch[114/200] Iteration[025/030] Train loss: 0.0348
2023-02-06 16:10:28 | Train | Epoch[114/200] Iteration[026/030] Train loss: 0.0348
2023-02-06 16:10:28 | Train | Epoch[114/200] Iteration[027/030] Train loss: 0.0348
2023-02-06 16:10:29 | Train | Epoch[114/200] Iteration[028/030] Train loss: 0.0348
2023-02-06 16:10:29 | Train | Epoch[114/200] Iteration[029/030] Train loss: 0.0348
2023-02-06 16:10:29 | Train | Epoch[114/200] Iteration[030/030] Train loss: 0.0348
2023-02-06 16:10:30 | Valid | Epoch[114/200] Iteration[001/008] Valid loss: 0.7235
2023-02-06 16:10:30 | Valid | Epoch[114/200] Iteration[002/008] Valid loss: 0.7243
2023-02-06 16:10:30 | Valid | Epoch[114/200] Iteration[003/008] Valid loss: 0.7198
2023-02-06 16:10:30 | Valid | Epoch[114/200] Iteration[004/008] Valid loss: 0.7335
2023-02-06 16:10:30 | Valid | Epoch[114/200] Iteration[005/008] Valid loss: 0.7588
2023-02-06 16:10:30 | Valid | Epoch[114/200] Iteration[006/008] Valid loss: 0.7247
2023-02-06 16:10:30 | Valid | Epoch[114/200] Iteration[007/008] Valid loss: 0.7625
2023-02-06 16:10:30 | Valid | Epoch[114/200] Iteration[008/008] Valid loss: 0.8061
2023-02-06 16:10:31 | Valid | Epoch[114/200] MIou: 0.8475489521323776
2023-02-06 16:10:31 | Valid | Epoch[114/200] Pixel Accuracy: 0.9672660827636719
2023-02-06 16:10:31 | Valid | Epoch[114/200] Mean Pixel Accuracy: 0.9752681218017687
2023-02-06 16:10:31 | Stage | Epoch[114/200] Train loss:0.0348
2023-02-06 16:10:31 | Stage | Epoch[114/200] Valid loss:0.8061
2023-02-06 16:10:31 | Stage | Epoch[114/200] LR:0.01

2023-02-06 16:10:31 | Train | Epoch[115/200] Iteration[001/030] Train loss: 0.0356
2023-02-06 16:10:32 | Train | Epoch[115/200] Iteration[002/030] Train loss: 0.0348
2023-02-06 16:10:32 | Train | Epoch[115/200] Iteration[003/030] Train loss: 0.0344
2023-02-06 16:10:33 | Train | Epoch[115/200] Iteration[004/030] Train loss: 0.0346
2023-02-06 16:10:33 | Train | Epoch[115/200] Iteration[005/030] Train loss: 0.0343
2023-02-06 16:10:33 | Train | Epoch[115/200] Iteration[006/030] Train loss: 0.0343
2023-02-06 16:10:34 | Train | Epoch[115/200] Iteration[007/030] Train loss: 0.0342
2023-02-06 16:10:34 | Train | Epoch[115/200] Iteration[008/030] Train loss: 0.0340
2023-02-06 16:10:35 | Train | Epoch[115/200] Iteration[009/030] Train loss: 0.0341
2023-02-06 16:10:35 | Train | Epoch[115/200] Iteration[010/030] Train loss: 0.0341
2023-02-06 16:10:36 | Train | Epoch[115/200] Iteration[011/030] Train loss: 0.0341
2023-02-06 16:10:36 | Train | Epoch[115/200] Iteration[012/030] Train loss: 0.0341
2023-02-06 16:10:36 | Train | Epoch[115/200] Iteration[013/030] Train loss: 0.0342
2023-02-06 16:10:37 | Train | Epoch[115/200] Iteration[014/030] Train loss: 0.0341
2023-02-06 16:10:37 | Train | Epoch[115/200] Iteration[015/030] Train loss: 0.0342
2023-02-06 16:10:38 | Train | Epoch[115/200] Iteration[016/030] Train loss: 0.0342
2023-02-06 16:10:38 | Train | Epoch[115/200] Iteration[017/030] Train loss: 0.0342
2023-02-06 16:10:39 | Train | Epoch[115/200] Iteration[018/030] Train loss: 0.0341
2023-02-06 16:10:39 | Train | Epoch[115/200] Iteration[019/030] Train loss: 0.0341
2023-02-06 16:10:40 | Train | Epoch[115/200] Iteration[020/030] Train loss: 0.0342
2023-02-06 16:10:40 | Train | Epoch[115/200] Iteration[021/030] Train loss: 0.0342
2023-02-06 16:10:40 | Train | Epoch[115/200] Iteration[022/030] Train loss: 0.0342
2023-02-06 16:10:41 | Train | Epoch[115/200] Iteration[023/030] Train loss: 0.0342
2023-02-06 16:10:41 | Train | Epoch[115/200] Iteration[024/030] Train loss: 0.0342
2023-02-06 16:10:42 | Train | Epoch[115/200] Iteration[025/030] Train loss: 0.0342
2023-02-06 16:10:42 | Train | Epoch[115/200] Iteration[026/030] Train loss: 0.0341
2023-02-06 16:10:43 | Train | Epoch[115/200] Iteration[027/030] Train loss: 0.0341
2023-02-06 16:10:43 | Train | Epoch[115/200] Iteration[028/030] Train loss: 0.0341
2023-02-06 16:10:43 | Train | Epoch[115/200] Iteration[029/030] Train loss: 0.0341
2023-02-06 16:10:44 | Train | Epoch[115/200] Iteration[030/030] Train loss: 0.0340
2023-02-06 16:10:44 | Valid | Epoch[115/200] Iteration[001/008] Valid loss: 0.0850
2023-02-06 16:10:44 | Valid | Epoch[115/200] Iteration[002/008] Valid loss: 0.0768
2023-02-06 16:10:44 | Valid | Epoch[115/200] Iteration[003/008] Valid loss: 0.0710
2023-02-06 16:10:44 | Valid | Epoch[115/200] Iteration[004/008] Valid loss: 0.0678
2023-02-06 16:10:44 | Valid | Epoch[115/200] Iteration[005/008] Valid loss: 0.0698
2023-02-06 16:10:45 | Valid | Epoch[115/200] Iteration[006/008] Valid loss: 0.0689
2023-02-06 16:10:45 | Valid | Epoch[115/200] Iteration[007/008] Valid loss: 0.0702
2023-02-06 16:10:45 | Valid | Epoch[115/200] Iteration[008/008] Valid loss: 0.0704
2023-02-06 16:10:45 | Valid | Epoch[115/200] MIou: 0.9128091863353567
2023-02-06 16:10:45 | Valid | Epoch[115/200] Pixel Accuracy: 0.9848200480143229
2023-02-06 16:10:45 | Valid | Epoch[115/200] Mean Pixel Accuracy: 0.9450856877231519
2023-02-06 16:10:45 | Stage | Epoch[115/200] Train loss:0.0340
2023-02-06 16:10:45 | Stage | Epoch[115/200] Valid loss:0.0704
2023-02-06 16:10:45 | Stage | Epoch[115/200] LR:0.01

2023-02-06 16:10:46 | Train | Epoch[116/200] Iteration[001/030] Train loss: 0.0332
2023-02-06 16:10:46 | Train | Epoch[116/200] Iteration[002/030] Train loss: 0.0343
2023-02-06 16:10:46 | Train | Epoch[116/200] Iteration[003/030] Train loss: 0.0338
2023-02-06 16:10:47 | Train | Epoch[116/200] Iteration[004/030] Train loss: 0.0339
2023-02-06 16:10:47 | Train | Epoch[116/200] Iteration[005/030] Train loss: 0.0336
2023-02-06 16:10:48 | Train | Epoch[116/200] Iteration[006/030] Train loss: 0.0335
2023-02-06 16:10:48 | Train | Epoch[116/200] Iteration[007/030] Train loss: 0.0334
2023-02-06 16:10:49 | Train | Epoch[116/200] Iteration[008/030] Train loss: 0.0333
2023-02-06 16:10:49 | Train | Epoch[116/200] Iteration[009/030] Train loss: 0.0335
2023-02-06 16:10:50 | Train | Epoch[116/200] Iteration[010/030] Train loss: 0.0336
2023-02-06 16:10:50 | Train | Epoch[116/200] Iteration[011/030] Train loss: 0.0336
2023-02-06 16:10:50 | Train | Epoch[116/200] Iteration[012/030] Train loss: 0.0337
2023-02-06 16:10:51 | Train | Epoch[116/200] Iteration[013/030] Train loss: 0.0337
2023-02-06 16:10:51 | Train | Epoch[116/200] Iteration[014/030] Train loss: 0.0336
2023-02-06 16:10:52 | Train | Epoch[116/200] Iteration[015/030] Train loss: 0.0336
2023-02-06 16:10:52 | Train | Epoch[116/200] Iteration[016/030] Train loss: 0.0336
2023-02-06 16:10:53 | Train | Epoch[116/200] Iteration[017/030] Train loss: 0.0335
2023-02-06 16:10:53 | Train | Epoch[116/200] Iteration[018/030] Train loss: 0.0336
2023-02-06 16:10:53 | Train | Epoch[116/200] Iteration[019/030] Train loss: 0.0335
2023-02-06 16:10:54 | Train | Epoch[116/200] Iteration[020/030] Train loss: 0.0335
2023-02-06 16:10:54 | Train | Epoch[116/200] Iteration[021/030] Train loss: 0.0335
2023-02-06 16:10:55 | Train | Epoch[116/200] Iteration[022/030] Train loss: 0.0335
2023-02-06 16:10:55 | Train | Epoch[116/200] Iteration[023/030] Train loss: 0.0334
2023-02-06 16:10:56 | Train | Epoch[116/200] Iteration[024/030] Train loss: 0.0335
2023-02-06 16:10:56 | Train | Epoch[116/200] Iteration[025/030] Train loss: 0.0334
2023-02-06 16:10:56 | Train | Epoch[116/200] Iteration[026/030] Train loss: 0.0334
2023-02-06 16:10:57 | Train | Epoch[116/200] Iteration[027/030] Train loss: 0.0334
2023-02-06 16:10:57 | Train | Epoch[116/200] Iteration[028/030] Train loss: 0.0334
2023-02-06 16:10:58 | Train | Epoch[116/200] Iteration[029/030] Train loss: 0.0334
2023-02-06 16:10:58 | Train | Epoch[116/200] Iteration[030/030] Train loss: 0.0335
2023-02-06 16:10:58 | Valid | Epoch[116/200] Iteration[001/008] Valid loss: 0.1352
2023-02-06 16:10:58 | Valid | Epoch[116/200] Iteration[002/008] Valid loss: 0.1025
2023-02-06 16:10:59 | Valid | Epoch[116/200] Iteration[003/008] Valid loss: 0.0888
2023-02-06 16:10:59 | Valid | Epoch[116/200] Iteration[004/008] Valid loss: 0.0868
2023-02-06 16:10:59 | Valid | Epoch[116/200] Iteration[005/008] Valid loss: 0.0870
2023-02-06 16:10:59 | Valid | Epoch[116/200] Iteration[006/008] Valid loss: 0.0850
2023-02-06 16:10:59 | Valid | Epoch[116/200] Iteration[007/008] Valid loss: 0.0890
2023-02-06 16:10:59 | Valid | Epoch[116/200] Iteration[008/008] Valid loss: 0.0874
2023-02-06 16:10:59 | Valid | Epoch[116/200] MIou: 0.929707747071093
2023-02-06 16:10:59 | Valid | Epoch[116/200] Pixel Accuracy: 0.9877777099609375
2023-02-06 16:10:59 | Valid | Epoch[116/200] Mean Pixel Accuracy: 0.9609393629433495
2023-02-06 16:10:59 | Stage | Epoch[116/200] Train loss:0.0335
2023-02-06 16:10:59 | Stage | Epoch[116/200] Valid loss:0.0874
2023-02-06 16:10:59 | Stage | Epoch[116/200] LR:0.01

2023-02-06 16:11:00 | Train | Epoch[117/200] Iteration[001/030] Train loss: 0.0340
2023-02-06 16:11:00 | Train | Epoch[117/200] Iteration[002/030] Train loss: 0.0332
2023-02-06 16:11:01 | Train | Epoch[117/200] Iteration[003/030] Train loss: 0.0333
2023-02-06 16:11:01 | Train | Epoch[117/200] Iteration[004/030] Train loss: 0.0333
2023-02-06 16:11:02 | Train | Epoch[117/200] Iteration[005/030] Train loss: 0.0331
2023-02-06 16:11:02 | Train | Epoch[117/200] Iteration[006/030] Train loss: 0.0333
2023-02-06 16:11:02 | Train | Epoch[117/200] Iteration[007/030] Train loss: 0.0333
2023-02-06 16:11:03 | Train | Epoch[117/200] Iteration[008/030] Train loss: 0.0332
2023-02-06 16:11:03 | Train | Epoch[117/200] Iteration[009/030] Train loss: 0.0331
2023-02-06 16:11:04 | Train | Epoch[117/200] Iteration[010/030] Train loss: 0.0331
2023-02-06 16:11:04 | Train | Epoch[117/200] Iteration[011/030] Train loss: 0.0330
2023-02-06 16:11:05 | Train | Epoch[117/200] Iteration[012/030] Train loss: 0.0331
2023-02-06 16:11:05 | Train | Epoch[117/200] Iteration[013/030] Train loss: 0.0331
2023-02-06 16:11:05 | Train | Epoch[117/200] Iteration[014/030] Train loss: 0.0331
2023-02-06 16:11:06 | Train | Epoch[117/200] Iteration[015/030] Train loss: 0.0331
2023-02-06 16:11:06 | Train | Epoch[117/200] Iteration[016/030] Train loss: 0.0331
2023-02-06 16:11:07 | Train | Epoch[117/200] Iteration[017/030] Train loss: 0.0330
2023-02-06 16:11:07 | Train | Epoch[117/200] Iteration[018/030] Train loss: 0.0330
2023-02-06 16:11:08 | Train | Epoch[117/200] Iteration[019/030] Train loss: 0.0329
2023-02-06 16:11:08 | Train | Epoch[117/200] Iteration[020/030] Train loss: 0.0330
2023-02-06 16:11:08 | Train | Epoch[117/200] Iteration[021/030] Train loss: 0.0329
2023-02-06 16:11:09 | Train | Epoch[117/200] Iteration[022/030] Train loss: 0.0329
2023-02-06 16:11:09 | Train | Epoch[117/200] Iteration[023/030] Train loss: 0.0329
2023-02-06 16:11:10 | Train | Epoch[117/200] Iteration[024/030] Train loss: 0.0329
2023-02-06 16:11:10 | Train | Epoch[117/200] Iteration[025/030] Train loss: 0.0329
2023-02-06 16:11:11 | Train | Epoch[117/200] Iteration[026/030] Train loss: 0.0329
2023-02-06 16:11:11 | Train | Epoch[117/200] Iteration[027/030] Train loss: 0.0329
2023-02-06 16:11:12 | Train | Epoch[117/200] Iteration[028/030] Train loss: 0.0329
2023-02-06 16:11:12 | Train | Epoch[117/200] Iteration[029/030] Train loss: 0.0329
2023-02-06 16:11:12 | Train | Epoch[117/200] Iteration[030/030] Train loss: 0.0329
2023-02-06 16:11:13 | Valid | Epoch[117/200] Iteration[001/008] Valid loss: 0.0790
2023-02-06 16:11:13 | Valid | Epoch[117/200] Iteration[002/008] Valid loss: 0.0748
2023-02-06 16:11:13 | Valid | Epoch[117/200] Iteration[003/008] Valid loss: 0.0757
2023-02-06 16:11:13 | Valid | Epoch[117/200] Iteration[004/008] Valid loss: 0.0744
2023-02-06 16:11:13 | Valid | Epoch[117/200] Iteration[005/008] Valid loss: 0.0758
2023-02-06 16:11:13 | Valid | Epoch[117/200] Iteration[006/008] Valid loss: 0.0749
2023-02-06 16:11:13 | Valid | Epoch[117/200] Iteration[007/008] Valid loss: 0.0735
2023-02-06 16:11:13 | Valid | Epoch[117/200] Iteration[008/008] Valid loss: 0.0751
2023-02-06 16:11:13 | Valid | Epoch[117/200] MIou: 0.8184589794914688
2023-02-06 16:11:13 | Valid | Epoch[117/200] Pixel Accuracy: 0.9700126647949219
2023-02-06 16:11:13 | Valid | Epoch[117/200] Mean Pixel Accuracy: 0.8351569887312196
2023-02-06 16:11:13 | Stage | Epoch[117/200] Train loss:0.0329
2023-02-06 16:11:13 | Stage | Epoch[117/200] Valid loss:0.0751
2023-02-06 16:11:13 | Stage | Epoch[117/200] LR:0.01

2023-02-06 16:11:14 | Train | Epoch[118/200] Iteration[001/030] Train loss: 0.0320
2023-02-06 16:11:15 | Train | Epoch[118/200] Iteration[002/030] Train loss: 0.0328
2023-02-06 16:11:15 | Train | Epoch[118/200] Iteration[003/030] Train loss: 0.0324
2023-02-06 16:11:16 | Train | Epoch[118/200] Iteration[004/030] Train loss: 0.0323
2023-02-06 16:11:16 | Train | Epoch[118/200] Iteration[005/030] Train loss: 0.0324
2023-02-06 16:11:16 | Train | Epoch[118/200] Iteration[006/030] Train loss: 0.0327
2023-02-06 16:11:17 | Train | Epoch[118/200] Iteration[007/030] Train loss: 0.0327
2023-02-06 16:11:17 | Train | Epoch[118/200] Iteration[008/030] Train loss: 0.0329
2023-02-06 16:11:18 | Train | Epoch[118/200] Iteration[009/030] Train loss: 0.0329
2023-02-06 16:11:18 | Train | Epoch[118/200] Iteration[010/030] Train loss: 0.0328
2023-02-06 16:11:19 | Train | Epoch[118/200] Iteration[011/030] Train loss: 0.0328
2023-02-06 16:11:19 | Train | Epoch[118/200] Iteration[012/030] Train loss: 0.0327
2023-02-06 16:11:19 | Train | Epoch[118/200] Iteration[013/030] Train loss: 0.0327
2023-02-06 16:11:20 | Train | Epoch[118/200] Iteration[014/030] Train loss: 0.0326
2023-02-06 16:11:20 | Train | Epoch[118/200] Iteration[015/030] Train loss: 0.0327
2023-02-06 16:11:21 | Train | Epoch[118/200] Iteration[016/030] Train loss: 0.0328
2023-02-06 16:11:21 | Train | Epoch[118/200] Iteration[017/030] Train loss: 0.0327
2023-02-06 16:11:22 | Train | Epoch[118/200] Iteration[018/030] Train loss: 0.0327
2023-02-06 16:11:22 | Train | Epoch[118/200] Iteration[019/030] Train loss: 0.0326
2023-02-06 16:11:22 | Train | Epoch[118/200] Iteration[020/030] Train loss: 0.0325
2023-02-06 16:11:23 | Train | Epoch[118/200] Iteration[021/030] Train loss: 0.0325
2023-02-06 16:11:23 | Train | Epoch[118/200] Iteration[022/030] Train loss: 0.0324
2023-02-06 16:11:24 | Train | Epoch[118/200] Iteration[023/030] Train loss: 0.0325
2023-02-06 16:11:24 | Train | Epoch[118/200] Iteration[024/030] Train loss: 0.0324
2023-02-06 16:11:25 | Train | Epoch[118/200] Iteration[025/030] Train loss: 0.0324
2023-02-06 16:11:25 | Train | Epoch[118/200] Iteration[026/030] Train loss: 0.0324
2023-02-06 16:11:25 | Train | Epoch[118/200] Iteration[027/030] Train loss: 0.0324
2023-02-06 16:11:26 | Train | Epoch[118/200] Iteration[028/030] Train loss: 0.0324
2023-02-06 16:11:26 | Train | Epoch[118/200] Iteration[029/030] Train loss: 0.0324
2023-02-06 16:11:27 | Train | Epoch[118/200] Iteration[030/030] Train loss: 0.0324
2023-02-06 16:11:27 | Valid | Epoch[118/200] Iteration[001/008] Valid loss: 0.2353
2023-02-06 16:11:27 | Valid | Epoch[118/200] Iteration[002/008] Valid loss: 0.1788
2023-02-06 16:11:27 | Valid | Epoch[118/200] Iteration[003/008] Valid loss: 0.1566
2023-02-06 16:11:27 | Valid | Epoch[118/200] Iteration[004/008] Valid loss: 0.1519
2023-02-06 16:11:27 | Valid | Epoch[118/200] Iteration[005/008] Valid loss: 0.1498
2023-02-06 16:11:28 | Valid | Epoch[118/200] Iteration[006/008] Valid loss: 0.1490
2023-02-06 16:11:28 | Valid | Epoch[118/200] Iteration[007/008] Valid loss: 0.1590
2023-02-06 16:11:28 | Valid | Epoch[118/200] Iteration[008/008] Valid loss: 0.1552
2023-02-06 16:11:28 | Valid | Epoch[118/200] MIou: 0.9153786742267196
2023-02-06 16:11:28 | Valid | Epoch[118/200] Pixel Accuracy: 0.9843864440917969
2023-02-06 16:11:28 | Valid | Epoch[118/200] Mean Pixel Accuracy: 0.9749328978393902
2023-02-06 16:11:28 | Stage | Epoch[118/200] Train loss:0.0324
2023-02-06 16:11:28 | Stage | Epoch[118/200] Valid loss:0.1552
2023-02-06 16:11:28 | Stage | Epoch[118/200] LR:0.01

2023-02-06 16:11:29 | Train | Epoch[119/200] Iteration[001/030] Train loss: 0.0320
2023-02-06 16:11:29 | Train | Epoch[119/200] Iteration[002/030] Train loss: 0.0316
2023-02-06 16:11:29 | Train | Epoch[119/200] Iteration[003/030] Train loss: 0.0318
2023-02-06 16:11:30 | Train | Epoch[119/200] Iteration[004/030] Train loss: 0.0322
2023-02-06 16:11:30 | Train | Epoch[119/200] Iteration[005/030] Train loss: 0.0321
2023-02-06 16:11:31 | Train | Epoch[119/200] Iteration[006/030] Train loss: 0.0320
2023-02-06 16:11:31 | Train | Epoch[119/200] Iteration[007/030] Train loss: 0.0320
2023-02-06 16:11:32 | Train | Epoch[119/200] Iteration[008/030] Train loss: 0.0319
2023-02-06 16:11:32 | Train | Epoch[119/200] Iteration[009/030] Train loss: 0.0318
2023-02-06 16:11:32 | Train | Epoch[119/200] Iteration[010/030] Train loss: 0.0319
2023-02-06 16:11:33 | Train | Epoch[119/200] Iteration[011/030] Train loss: 0.0319
2023-02-06 16:11:33 | Train | Epoch[119/200] Iteration[012/030] Train loss: 0.0318
2023-02-06 16:11:34 | Train | Epoch[119/200] Iteration[013/030] Train loss: 0.0317
2023-02-06 16:11:34 | Train | Epoch[119/200] Iteration[014/030] Train loss: 0.0316
2023-02-06 16:11:35 | Train | Epoch[119/200] Iteration[015/030] Train loss: 0.0318
2023-02-06 16:11:35 | Train | Epoch[119/200] Iteration[016/030] Train loss: 0.0318
2023-02-06 16:11:35 | Train | Epoch[119/200] Iteration[017/030] Train loss: 0.0318
2023-02-06 16:11:36 | Train | Epoch[119/200] Iteration[018/030] Train loss: 0.0317
2023-02-06 16:11:36 | Train | Epoch[119/200] Iteration[019/030] Train loss: 0.0318
2023-02-06 16:11:37 | Train | Epoch[119/200] Iteration[020/030] Train loss: 0.0318
2023-02-06 16:11:37 | Train | Epoch[119/200] Iteration[021/030] Train loss: 0.0319
2023-02-06 16:11:38 | Train | Epoch[119/200] Iteration[022/030] Train loss: 0.0319
2023-02-06 16:11:38 | Train | Epoch[119/200] Iteration[023/030] Train loss: 0.0319
2023-02-06 16:11:38 | Train | Epoch[119/200] Iteration[024/030] Train loss: 0.0319
2023-02-06 16:11:39 | Train | Epoch[119/200] Iteration[025/030] Train loss: 0.0319
2023-02-06 16:11:39 | Train | Epoch[119/200] Iteration[026/030] Train loss: 0.0319
2023-02-06 16:11:40 | Train | Epoch[119/200] Iteration[027/030] Train loss: 0.0320
2023-02-06 16:11:40 | Train | Epoch[119/200] Iteration[028/030] Train loss: 0.0320
2023-02-06 16:11:41 | Train | Epoch[119/200] Iteration[029/030] Train loss: 0.0321
2023-02-06 16:11:41 | Train | Epoch[119/200] Iteration[030/030] Train loss: 0.0320
2023-02-06 16:11:41 | Valid | Epoch[119/200] Iteration[001/008] Valid loss: 0.2725
2023-02-06 16:11:41 | Valid | Epoch[119/200] Iteration[002/008] Valid loss: 0.2236
2023-02-06 16:11:42 | Valid | Epoch[119/200] Iteration[003/008] Valid loss: 0.2042
2023-02-06 16:11:42 | Valid | Epoch[119/200] Iteration[004/008] Valid loss: 0.2034
2023-02-06 16:11:42 | Valid | Epoch[119/200] Iteration[005/008] Valid loss: 0.2106
2023-02-06 16:11:42 | Valid | Epoch[119/200] Iteration[006/008] Valid loss: 0.2064
2023-02-06 16:11:42 | Valid | Epoch[119/200] Iteration[007/008] Valid loss: 0.2244
2023-02-06 16:11:42 | Valid | Epoch[119/200] Iteration[008/008] Valid loss: 0.2293
2023-02-06 16:11:42 | Valid | Epoch[119/200] MIou: 0.9085969261475195
2023-02-06 16:11:42 | Valid | Epoch[119/200] Pixel Accuracy: 0.9828008015950521
2023-02-06 16:11:42 | Valid | Epoch[119/200] Mean Pixel Accuracy: 0.9775105775997338
2023-02-06 16:11:42 | Stage | Epoch[119/200] Train loss:0.0320
2023-02-06 16:11:42 | Stage | Epoch[119/200] Valid loss:0.2293
2023-02-06 16:11:42 | Stage | Epoch[119/200] LR:0.01

2023-02-06 16:11:43 | Train | Epoch[120/200] Iteration[001/030] Train loss: 0.0312
2023-02-06 16:11:43 | Train | Epoch[120/200] Iteration[002/030] Train loss: 0.0317
2023-02-06 16:11:44 | Train | Epoch[120/200] Iteration[003/030] Train loss: 0.0316
2023-02-06 16:11:44 | Train | Epoch[120/200] Iteration[004/030] Train loss: 0.0317
2023-02-06 16:11:45 | Train | Epoch[120/200] Iteration[005/030] Train loss: 0.0314
2023-02-06 16:11:45 | Train | Epoch[120/200] Iteration[006/030] Train loss: 0.0312
2023-02-06 16:11:46 | Train | Epoch[120/200] Iteration[007/030] Train loss: 0.0313
2023-02-06 16:11:46 | Train | Epoch[120/200] Iteration[008/030] Train loss: 0.0313
2023-02-06 16:11:46 | Train | Epoch[120/200] Iteration[009/030] Train loss: 0.0314
2023-02-06 16:11:47 | Train | Epoch[120/200] Iteration[010/030] Train loss: 0.0314
2023-02-06 16:11:47 | Train | Epoch[120/200] Iteration[011/030] Train loss: 0.0315
2023-02-06 16:11:48 | Train | Epoch[120/200] Iteration[012/030] Train loss: 0.0316
2023-02-06 16:11:48 | Train | Epoch[120/200] Iteration[013/030] Train loss: 0.0315
2023-02-06 16:11:49 | Train | Epoch[120/200] Iteration[014/030] Train loss: 0.0314
2023-02-06 16:11:49 | Train | Epoch[120/200] Iteration[015/030] Train loss: 0.0314
2023-02-06 16:11:49 | Train | Epoch[120/200] Iteration[016/030] Train loss: 0.0316
2023-02-06 16:11:50 | Train | Epoch[120/200] Iteration[017/030] Train loss: 0.0316
2023-02-06 16:11:50 | Train | Epoch[120/200] Iteration[018/030] Train loss: 0.0315
2023-02-06 16:11:51 | Train | Epoch[120/200] Iteration[019/030] Train loss: 0.0315
2023-02-06 16:11:51 | Train | Epoch[120/200] Iteration[020/030] Train loss: 0.0315
2023-02-06 16:11:52 | Train | Epoch[120/200] Iteration[021/030] Train loss: 0.0315
2023-02-06 16:11:52 | Train | Epoch[120/200] Iteration[022/030] Train loss: 0.0315
2023-02-06 16:11:52 | Train | Epoch[120/200] Iteration[023/030] Train loss: 0.0315
2023-02-06 16:11:53 | Train | Epoch[120/200] Iteration[024/030] Train loss: 0.0315
2023-02-06 16:11:53 | Train | Epoch[120/200] Iteration[025/030] Train loss: 0.0315
2023-02-06 16:11:54 | Train | Epoch[120/200] Iteration[026/030] Train loss: 0.0315
2023-02-06 16:11:54 | Train | Epoch[120/200] Iteration[027/030] Train loss: 0.0315
2023-02-06 16:11:55 | Train | Epoch[120/200] Iteration[028/030] Train loss: 0.0315
2023-02-06 16:11:55 | Train | Epoch[120/200] Iteration[029/030] Train loss: 0.0314
2023-02-06 16:11:55 | Train | Epoch[120/200] Iteration[030/030] Train loss: 0.0314
2023-02-06 16:11:56 | Valid | Epoch[120/200] Iteration[001/008] Valid loss: 0.1425
2023-02-06 16:11:56 | Valid | Epoch[120/200] Iteration[002/008] Valid loss: 0.1218
2023-02-06 16:11:56 | Valid | Epoch[120/200] Iteration[003/008] Valid loss: 0.1093
2023-02-06 16:11:56 | Valid | Epoch[120/200] Iteration[004/008] Valid loss: 0.1089
2023-02-06 16:11:56 | Valid | Epoch[120/200] Iteration[005/008] Valid loss: 0.1138
2023-02-06 16:11:56 | Valid | Epoch[120/200] Iteration[006/008] Valid loss: 0.1131
2023-02-06 16:11:56 | Valid | Epoch[120/200] Iteration[007/008] Valid loss: 0.1198
2023-02-06 16:11:56 | Valid | Epoch[120/200] Iteration[008/008] Valid loss: 0.1223
2023-02-06 16:11:56 | Valid | Epoch[120/200] MIou: 0.9242384757329061
2023-02-06 16:11:56 | Valid | Epoch[120/200] Pixel Accuracy: 0.9864349365234375
2023-02-06 16:11:56 | Valid | Epoch[120/200] Mean Pixel Accuracy: 0.9694013415582252
2023-02-06 16:11:56 | Stage | Epoch[120/200] Train loss:0.0314
2023-02-06 16:11:56 | Stage | Epoch[120/200] Valid loss:0.1223
2023-02-06 16:11:56 | Stage | Epoch[120/200] LR:0.01

2023-02-06 16:11:57 | Train | Epoch[121/200] Iteration[001/030] Train loss: 0.0300
2023-02-06 16:11:58 | Train | Epoch[121/200] Iteration[002/030] Train loss: 0.0301
2023-02-06 16:11:58 | Train | Epoch[121/200] Iteration[003/030] Train loss: 0.0301
2023-02-06 16:11:58 | Train | Epoch[121/200] Iteration[004/030] Train loss: 0.0310
2023-02-06 16:11:59 | Train | Epoch[121/200] Iteration[005/030] Train loss: 0.0315
2023-02-06 16:11:59 | Train | Epoch[121/200] Iteration[006/030] Train loss: 0.0314
2023-02-06 16:12:00 | Train | Epoch[121/200] Iteration[007/030] Train loss: 0.0314
2023-02-06 16:12:00 | Train | Epoch[121/200] Iteration[008/030] Train loss: 0.0314
2023-02-06 16:12:01 | Train | Epoch[121/200] Iteration[009/030] Train loss: 0.0312
2023-02-06 16:12:01 | Train | Epoch[121/200] Iteration[010/030] Train loss: 0.0312
2023-02-06 16:12:02 | Train | Epoch[121/200] Iteration[011/030] Train loss: 0.0312
2023-02-06 16:12:02 | Train | Epoch[121/200] Iteration[012/030] Train loss: 0.0312
2023-02-06 16:12:02 | Train | Epoch[121/200] Iteration[013/030] Train loss: 0.0311
2023-02-06 16:12:03 | Train | Epoch[121/200] Iteration[014/030] Train loss: 0.0311
2023-02-06 16:12:03 | Train | Epoch[121/200] Iteration[015/030] Train loss: 0.0311
2023-02-06 16:12:04 | Train | Epoch[121/200] Iteration[016/030] Train loss: 0.0313
2023-02-06 16:12:04 | Train | Epoch[121/200] Iteration[017/030] Train loss: 0.0313
2023-02-06 16:12:05 | Train | Epoch[121/200] Iteration[018/030] Train loss: 0.0313
2023-02-06 16:12:05 | Train | Epoch[121/200] Iteration[019/030] Train loss: 0.0313
2023-02-06 16:12:05 | Train | Epoch[121/200] Iteration[020/030] Train loss: 0.0313
2023-02-06 16:12:06 | Train | Epoch[121/200] Iteration[021/030] Train loss: 0.0313
2023-02-06 16:12:06 | Train | Epoch[121/200] Iteration[022/030] Train loss: 0.0312
2023-02-06 16:12:07 | Train | Epoch[121/200] Iteration[023/030] Train loss: 0.0312
2023-02-06 16:12:07 | Train | Epoch[121/200] Iteration[024/030] Train loss: 0.0312
2023-02-06 16:12:08 | Train | Epoch[121/200] Iteration[025/030] Train loss: 0.0312
2023-02-06 16:12:08 | Train | Epoch[121/200] Iteration[026/030] Train loss: 0.0312
2023-02-06 16:12:08 | Train | Epoch[121/200] Iteration[027/030] Train loss: 0.0312
2023-02-06 16:12:09 | Train | Epoch[121/200] Iteration[028/030] Train loss: 0.0312
2023-02-06 16:12:09 | Train | Epoch[121/200] Iteration[029/030] Train loss: 0.0312
2023-02-06 16:12:09 | Train | Epoch[121/200] Iteration[030/030] Train loss: 0.0312
2023-02-06 16:12:10 | Valid | Epoch[121/200] Iteration[001/008] Valid loss: 0.2276
2023-02-06 16:12:10 | Valid | Epoch[121/200] Iteration[002/008] Valid loss: 0.2027
2023-02-06 16:12:10 | Valid | Epoch[121/200] Iteration[003/008] Valid loss: 0.1778
2023-02-06 16:12:10 | Valid | Epoch[121/200] Iteration[004/008] Valid loss: 0.1797
2023-02-06 16:12:10 | Valid | Epoch[121/200] Iteration[005/008] Valid loss: 0.1857
2023-02-06 16:12:10 | Valid | Epoch[121/200] Iteration[006/008] Valid loss: 0.1791
2023-02-06 16:12:11 | Valid | Epoch[121/200] Iteration[007/008] Valid loss: 0.1910
2023-02-06 16:12:11 | Valid | Epoch[121/200] Iteration[008/008] Valid loss: 0.1956
2023-02-06 16:12:11 | Valid | Epoch[121/200] MIou: 0.9091423645404892
2023-02-06 16:12:11 | Valid | Epoch[121/200] Pixel Accuracy: 0.9828694661458334
2023-02-06 16:12:11 | Valid | Epoch[121/200] Mean Pixel Accuracy: 0.9790700317282146
2023-02-06 16:12:11 | Stage | Epoch[121/200] Train loss:0.0312
2023-02-06 16:12:11 | Stage | Epoch[121/200] Valid loss:0.1956
2023-02-06 16:12:11 | Stage | Epoch[121/200] LR:0.01

2023-02-06 16:12:12 | Train | Epoch[122/200] Iteration[001/030] Train loss: 0.0335
2023-02-06 16:12:12 | Train | Epoch[122/200] Iteration[002/030] Train loss: 0.0317
2023-02-06 16:12:12 | Train | Epoch[122/200] Iteration[003/030] Train loss: 0.0309
2023-02-06 16:12:13 | Train | Epoch[122/200] Iteration[004/030] Train loss: 0.0309
2023-02-06 16:12:13 | Train | Epoch[122/200] Iteration[005/030] Train loss: 0.0308
2023-02-06 16:12:14 | Train | Epoch[122/200] Iteration[006/030] Train loss: 0.0310
2023-02-06 16:12:14 | Train | Epoch[122/200] Iteration[007/030] Train loss: 0.0312
2023-02-06 16:12:15 | Train | Epoch[122/200] Iteration[008/030] Train loss: 0.0312
2023-02-06 16:12:15 | Train | Epoch[122/200] Iteration[009/030] Train loss: 0.0312
2023-02-06 16:12:15 | Train | Epoch[122/200] Iteration[010/030] Train loss: 0.0312
2023-02-06 16:12:16 | Train | Epoch[122/200] Iteration[011/030] Train loss: 0.0313
2023-02-06 16:12:16 | Train | Epoch[122/200] Iteration[012/030] Train loss: 0.0312
2023-02-06 16:12:17 | Train | Epoch[122/200] Iteration[013/030] Train loss: 0.0313
2023-02-06 16:12:17 | Train | Epoch[122/200] Iteration[014/030] Train loss: 0.0312
2023-02-06 16:12:18 | Train | Epoch[122/200] Iteration[015/030] Train loss: 0.0312
2023-02-06 16:12:18 | Train | Epoch[122/200] Iteration[016/030] Train loss: 0.0312
2023-02-06 16:12:18 | Train | Epoch[122/200] Iteration[017/030] Train loss: 0.0312
2023-02-06 16:12:19 | Train | Epoch[122/200] Iteration[018/030] Train loss: 0.0312
2023-02-06 16:12:19 | Train | Epoch[122/200] Iteration[019/030] Train loss: 0.0311
2023-02-06 16:12:20 | Train | Epoch[122/200] Iteration[020/030] Train loss: 0.0311
2023-02-06 16:12:20 | Train | Epoch[122/200] Iteration[021/030] Train loss: 0.0310
2023-02-06 16:12:21 | Train | Epoch[122/200] Iteration[022/030] Train loss: 0.0310
2023-02-06 16:12:21 | Train | Epoch[122/200] Iteration[023/030] Train loss: 0.0311
2023-02-06 16:12:22 | Train | Epoch[122/200] Iteration[024/030] Train loss: 0.0311
2023-02-06 16:12:22 | Train | Epoch[122/200] Iteration[025/030] Train loss: 0.0311
2023-02-06 16:12:22 | Train | Epoch[122/200] Iteration[026/030] Train loss: 0.0311
2023-02-06 16:12:23 | Train | Epoch[122/200] Iteration[027/030] Train loss: 0.0311
2023-02-06 16:12:23 | Train | Epoch[122/200] Iteration[028/030] Train loss: 0.0311
2023-02-06 16:12:24 | Train | Epoch[122/200] Iteration[029/030] Train loss: 0.0311
2023-02-06 16:12:24 | Train | Epoch[122/200] Iteration[030/030] Train loss: 0.0311
2023-02-06 16:12:24 | Valid | Epoch[122/200] Iteration[001/008] Valid loss: 0.1976
2023-02-06 16:12:24 | Valid | Epoch[122/200] Iteration[002/008] Valid loss: 0.1680
2023-02-06 16:12:24 | Valid | Epoch[122/200] Iteration[003/008] Valid loss: 0.1455
2023-02-06 16:12:25 | Valid | Epoch[122/200] Iteration[004/008] Valid loss: 0.1420
2023-02-06 16:12:25 | Valid | Epoch[122/200] Iteration[005/008] Valid loss: 0.1422
2023-02-06 16:12:25 | Valid | Epoch[122/200] Iteration[006/008] Valid loss: 0.1380
2023-02-06 16:12:25 | Valid | Epoch[122/200] Iteration[007/008] Valid loss: 0.1421
2023-02-06 16:12:25 | Valid | Epoch[122/200] Iteration[008/008] Valid loss: 0.1431
2023-02-06 16:12:25 | Valid | Epoch[122/200] MIou: 0.9157362193034193
2023-02-06 16:12:25 | Valid | Epoch[122/200] Pixel Accuracy: 0.9847145080566406
2023-02-06 16:12:25 | Valid | Epoch[122/200] Mean Pixel Accuracy: 0.9670734979087409
2023-02-06 16:12:25 | Stage | Epoch[122/200] Train loss:0.0311
2023-02-06 16:12:25 | Stage | Epoch[122/200] Valid loss:0.1431
2023-02-06 16:12:25 | Stage | Epoch[122/200] LR:0.01

2023-02-06 16:12:26 | Train | Epoch[123/200] Iteration[001/030] Train loss: 0.0303
2023-02-06 16:12:26 | Train | Epoch[123/200] Iteration[002/030] Train loss: 0.0300
2023-02-06 16:12:27 | Train | Epoch[123/200] Iteration[003/030] Train loss: 0.0299
2023-02-06 16:12:27 | Train | Epoch[123/200] Iteration[004/030] Train loss: 0.0298
2023-02-06 16:12:28 | Train | Epoch[123/200] Iteration[005/030] Train loss: 0.0300
2023-02-06 16:12:28 | Train | Epoch[123/200] Iteration[006/030] Train loss: 0.0300
2023-02-06 16:12:28 | Train | Epoch[123/200] Iteration[007/030] Train loss: 0.0299
2023-02-06 16:12:29 | Train | Epoch[123/200] Iteration[008/030] Train loss: 0.0301
2023-02-06 16:12:29 | Train | Epoch[123/200] Iteration[009/030] Train loss: 0.0301
2023-02-06 16:12:30 | Train | Epoch[123/200] Iteration[010/030] Train loss: 0.0301
2023-02-06 16:12:30 | Train | Epoch[123/200] Iteration[011/030] Train loss: 0.0301
2023-02-06 16:12:31 | Train | Epoch[123/200] Iteration[012/030] Train loss: 0.0301
2023-02-06 16:12:31 | Train | Epoch[123/200] Iteration[013/030] Train loss: 0.0300
2023-02-06 16:12:31 | Train | Epoch[123/200] Iteration[014/030] Train loss: 0.0299
2023-02-06 16:12:32 | Train | Epoch[123/200] Iteration[015/030] Train loss: 0.0299
2023-02-06 16:12:32 | Train | Epoch[123/200] Iteration[016/030] Train loss: 0.0299
2023-02-06 16:12:33 | Train | Epoch[123/200] Iteration[017/030] Train loss: 0.0299
2023-02-06 16:12:33 | Train | Epoch[123/200] Iteration[018/030] Train loss: 0.0299
2023-02-06 16:12:34 | Train | Epoch[123/200] Iteration[019/030] Train loss: 0.0299
2023-02-06 16:12:34 | Train | Epoch[123/200] Iteration[020/030] Train loss: 0.0299
2023-02-06 16:12:35 | Train | Epoch[123/200] Iteration[021/030] Train loss: 0.0299
2023-02-06 16:12:35 | Train | Epoch[123/200] Iteration[022/030] Train loss: 0.0298
2023-02-06 16:12:35 | Train | Epoch[123/200] Iteration[023/030] Train loss: 0.0299
2023-02-06 16:12:36 | Train | Epoch[123/200] Iteration[024/030] Train loss: 0.0300
2023-02-06 16:12:36 | Train | Epoch[123/200] Iteration[025/030] Train loss: 0.0299
2023-02-06 16:12:37 | Train | Epoch[123/200] Iteration[026/030] Train loss: 0.0300
2023-02-06 16:12:37 | Train | Epoch[123/200] Iteration[027/030] Train loss: 0.0300
2023-02-06 16:12:38 | Train | Epoch[123/200] Iteration[028/030] Train loss: 0.0300
2023-02-06 16:12:38 | Train | Epoch[123/200] Iteration[029/030] Train loss: 0.0301
2023-02-06 16:12:38 | Train | Epoch[123/200] Iteration[030/030] Train loss: 0.0301
2023-02-06 16:12:39 | Valid | Epoch[123/200] Iteration[001/008] Valid loss: 0.1362
2023-02-06 16:12:39 | Valid | Epoch[123/200] Iteration[002/008] Valid loss: 0.0967
2023-02-06 16:12:39 | Valid | Epoch[123/200] Iteration[003/008] Valid loss: 0.0845
2023-02-06 16:12:39 | Valid | Epoch[123/200] Iteration[004/008] Valid loss: 0.0788
2023-02-06 16:12:39 | Valid | Epoch[123/200] Iteration[005/008] Valid loss: 0.0783
2023-02-06 16:12:39 | Valid | Epoch[123/200] Iteration[006/008] Valid loss: 0.0765
2023-02-06 16:12:39 | Valid | Epoch[123/200] Iteration[007/008] Valid loss: 0.0786
2023-02-06 16:12:39 | Valid | Epoch[123/200] Iteration[008/008] Valid loss: 0.0778
2023-02-06 16:12:39 | Valid | Epoch[123/200] MIou: 0.9307159747837774
2023-02-06 16:12:39 | Valid | Epoch[123/200] Pixel Accuracy: 0.988165537516276
2023-02-06 16:12:39 | Valid | Epoch[123/200] Mean Pixel Accuracy: 0.9536897945384908
2023-02-06 16:12:39 | Stage | Epoch[123/200] Train loss:0.0301
2023-02-06 16:12:39 | Stage | Epoch[123/200] Valid loss:0.0778
2023-02-06 16:12:39 | Stage | Epoch[123/200] LR:0.01

2023-02-06 16:12:40 | Train | Epoch[124/200] Iteration[001/030] Train loss: 0.0288
2023-02-06 16:12:41 | Train | Epoch[124/200] Iteration[002/030] Train loss: 0.0289
2023-02-06 16:12:41 | Train | Epoch[124/200] Iteration[003/030] Train loss: 0.0290
2023-02-06 16:12:41 | Train | Epoch[124/200] Iteration[004/030] Train loss: 0.0293
2023-02-06 16:12:42 | Train | Epoch[124/200] Iteration[005/030] Train loss: 0.0293
2023-02-06 16:12:42 | Train | Epoch[124/200] Iteration[006/030] Train loss: 0.0294
2023-02-06 16:12:43 | Train | Epoch[124/200] Iteration[007/030] Train loss: 0.0294
2023-02-06 16:12:43 | Train | Epoch[124/200] Iteration[008/030] Train loss: 0.0294
2023-02-06 16:12:44 | Train | Epoch[124/200] Iteration[009/030] Train loss: 0.0294
2023-02-06 16:12:44 | Train | Epoch[124/200] Iteration[010/030] Train loss: 0.0296
2023-02-06 16:12:44 | Train | Epoch[124/200] Iteration[011/030] Train loss: 0.0296
2023-02-06 16:12:45 | Train | Epoch[124/200] Iteration[012/030] Train loss: 0.0295
2023-02-06 16:12:45 | Train | Epoch[124/200] Iteration[013/030] Train loss: 0.0295
2023-02-06 16:12:46 | Train | Epoch[124/200] Iteration[014/030] Train loss: 0.0294
2023-02-06 16:12:46 | Train | Epoch[124/200] Iteration[015/030] Train loss: 0.0294
2023-02-06 16:12:47 | Train | Epoch[124/200] Iteration[016/030] Train loss: 0.0295
2023-02-06 16:12:47 | Train | Epoch[124/200] Iteration[017/030] Train loss: 0.0295
2023-02-06 16:12:47 | Train | Epoch[124/200] Iteration[018/030] Train loss: 0.0294
2023-02-06 16:12:48 | Train | Epoch[124/200] Iteration[019/030] Train loss: 0.0294
2023-02-06 16:12:48 | Train | Epoch[124/200] Iteration[020/030] Train loss: 0.0295
2023-02-06 16:12:49 | Train | Epoch[124/200] Iteration[021/030] Train loss: 0.0294
2023-02-06 16:12:49 | Train | Epoch[124/200] Iteration[022/030] Train loss: 0.0296
2023-02-06 16:12:50 | Train | Epoch[124/200] Iteration[023/030] Train loss: 0.0296
2023-02-06 16:12:50 | Train | Epoch[124/200] Iteration[024/030] Train loss: 0.0296
2023-02-06 16:12:51 | Train | Epoch[124/200] Iteration[025/030] Train loss: 0.0296
2023-02-06 16:12:51 | Train | Epoch[124/200] Iteration[026/030] Train loss: 0.0296
2023-02-06 16:12:51 | Train | Epoch[124/200] Iteration[027/030] Train loss: 0.0297
2023-02-06 16:12:52 | Train | Epoch[124/200] Iteration[028/030] Train loss: 0.0298
2023-02-06 16:12:52 | Train | Epoch[124/200] Iteration[029/030] Train loss: 0.0298
2023-02-06 16:12:52 | Train | Epoch[124/200] Iteration[030/030] Train loss: 0.0298
2023-02-06 16:12:53 | Valid | Epoch[124/200] Iteration[001/008] Valid loss: 0.1084
2023-02-06 16:12:53 | Valid | Epoch[124/200] Iteration[002/008] Valid loss: 0.0864
2023-02-06 16:12:53 | Valid | Epoch[124/200] Iteration[003/008] Valid loss: 0.0786
2023-02-06 16:12:53 | Valid | Epoch[124/200] Iteration[004/008] Valid loss: 0.0763
2023-02-06 16:12:53 | Valid | Epoch[124/200] Iteration[005/008] Valid loss: 0.0737
2023-02-06 16:12:53 | Valid | Epoch[124/200] Iteration[006/008] Valid loss: 0.0788
2023-02-06 16:12:53 | Valid | Epoch[124/200] Iteration[007/008] Valid loss: 0.0817
2023-02-06 16:12:53 | Valid | Epoch[124/200] Iteration[008/008] Valid loss: 0.0789
2023-02-06 16:12:54 | Valid | Epoch[124/200] MIou: 0.912468952118755
2023-02-06 16:12:54 | Valid | Epoch[124/200] Pixel Accuracy: 0.9850870768229166
2023-02-06 16:12:54 | Valid | Epoch[124/200] Mean Pixel Accuracy: 0.9351447679691393
2023-02-06 16:12:54 | Stage | Epoch[124/200] Train loss:0.0298
2023-02-06 16:12:54 | Stage | Epoch[124/200] Valid loss:0.0789
2023-02-06 16:12:54 | Stage | Epoch[124/200] LR:0.01

2023-02-06 16:12:54 | Train | Epoch[125/200] Iteration[001/030] Train loss: 0.0292
2023-02-06 16:12:55 | Train | Epoch[125/200] Iteration[002/030] Train loss: 0.0298
2023-02-06 16:12:55 | Train | Epoch[125/200] Iteration[003/030] Train loss: 0.0295
2023-02-06 16:12:56 | Train | Epoch[125/200] Iteration[004/030] Train loss: 0.0294
2023-02-06 16:12:56 | Train | Epoch[125/200] Iteration[005/030] Train loss: 0.0292
2023-02-06 16:12:56 | Train | Epoch[125/200] Iteration[006/030] Train loss: 0.0292
2023-02-06 16:12:57 | Train | Epoch[125/200] Iteration[007/030] Train loss: 0.0291
2023-02-06 16:12:57 | Train | Epoch[125/200] Iteration[008/030] Train loss: 0.0292
2023-02-06 16:12:58 | Train | Epoch[125/200] Iteration[009/030] Train loss: 0.0292
2023-02-06 16:12:58 | Train | Epoch[125/200] Iteration[010/030] Train loss: 0.0292
2023-02-06 16:12:59 | Train | Epoch[125/200] Iteration[011/030] Train loss: 0.0292
2023-02-06 16:12:59 | Train | Epoch[125/200] Iteration[012/030] Train loss: 0.0291
2023-02-06 16:12:59 | Train | Epoch[125/200] Iteration[013/030] Train loss: 0.0291
2023-02-06 16:13:00 | Train | Epoch[125/200] Iteration[014/030] Train loss: 0.0290
2023-02-06 16:13:00 | Train | Epoch[125/200] Iteration[015/030] Train loss: 0.0291
2023-02-06 16:13:01 | Train | Epoch[125/200] Iteration[016/030] Train loss: 0.0292
2023-02-06 16:13:01 | Train | Epoch[125/200] Iteration[017/030] Train loss: 0.0292
2023-02-06 16:13:02 | Train | Epoch[125/200] Iteration[018/030] Train loss: 0.0292
2023-02-06 16:13:02 | Train | Epoch[125/200] Iteration[019/030] Train loss: 0.0291
2023-02-06 16:13:03 | Train | Epoch[125/200] Iteration[020/030] Train loss: 0.0291
2023-02-06 16:13:03 | Train | Epoch[125/200] Iteration[021/030] Train loss: 0.0291
2023-02-06 16:13:03 | Train | Epoch[125/200] Iteration[022/030] Train loss: 0.0291
2023-02-06 16:13:04 | Train | Epoch[125/200] Iteration[023/030] Train loss: 0.0292
2023-02-06 16:13:04 | Train | Epoch[125/200] Iteration[024/030] Train loss: 0.0293
2023-02-06 16:13:05 | Train | Epoch[125/200] Iteration[025/030] Train loss: 0.0293
2023-02-06 16:13:05 | Train | Epoch[125/200] Iteration[026/030] Train loss: 0.0293
2023-02-06 16:13:06 | Train | Epoch[125/200] Iteration[027/030] Train loss: 0.0293
2023-02-06 16:13:06 | Train | Epoch[125/200] Iteration[028/030] Train loss: 0.0293
2023-02-06 16:13:06 | Train | Epoch[125/200] Iteration[029/030] Train loss: 0.0293
2023-02-06 16:13:07 | Train | Epoch[125/200] Iteration[030/030] Train loss: 0.0293
2023-02-06 16:13:07 | Valid | Epoch[125/200] Iteration[001/008] Valid loss: 0.1077
2023-02-06 16:13:07 | Valid | Epoch[125/200] Iteration[002/008] Valid loss: 0.0826
2023-02-06 16:13:07 | Valid | Epoch[125/200] Iteration[003/008] Valid loss: 0.0725
2023-02-06 16:13:07 | Valid | Epoch[125/200] Iteration[004/008] Valid loss: 0.0698
2023-02-06 16:13:07 | Valid | Epoch[125/200] Iteration[005/008] Valid loss: 0.0702
2023-02-06 16:13:08 | Valid | Epoch[125/200] Iteration[006/008] Valid loss: 0.0674
2023-02-06 16:13:08 | Valid | Epoch[125/200] Iteration[007/008] Valid loss: 0.0706
2023-02-06 16:13:08 | Valid | Epoch[125/200] Iteration[008/008] Valid loss: 0.0695
2023-02-06 16:13:08 | Valid | Epoch[125/200] MIou: 0.9244388861428299
2023-02-06 16:13:08 | Valid | Epoch[125/200] Pixel Accuracy: 0.9869956970214844
2023-02-06 16:13:08 | Valid | Epoch[125/200] Mean Pixel Accuracy: 0.9511129564988785
2023-02-06 16:13:08 | Stage | Epoch[125/200] Train loss:0.0293
2023-02-06 16:13:08 | Stage | Epoch[125/200] Valid loss:0.0695
2023-02-06 16:13:08 | Stage | Epoch[125/200] LR:0.01

2023-02-06 16:13:08 | Train | Epoch[126/200] Iteration[001/030] Train loss: 0.0289
2023-02-06 16:13:09 | Train | Epoch[126/200] Iteration[002/030] Train loss: 0.0288
2023-02-06 16:13:09 | Train | Epoch[126/200] Iteration[003/030] Train loss: 0.0288
2023-02-06 16:13:10 | Train | Epoch[126/200] Iteration[004/030] Train loss: 0.0292
2023-02-06 16:13:10 | Train | Epoch[126/200] Iteration[005/030] Train loss: 0.0290
2023-02-06 16:13:11 | Train | Epoch[126/200] Iteration[006/030] Train loss: 0.0288
2023-02-06 16:13:11 | Train | Epoch[126/200] Iteration[007/030] Train loss: 0.0288
2023-02-06 16:13:12 | Train | Epoch[126/200] Iteration[008/030] Train loss: 0.0287
2023-02-06 16:13:12 | Train | Epoch[126/200] Iteration[009/030] Train loss: 0.0287
2023-02-06 16:13:12 | Train | Epoch[126/200] Iteration[010/030] Train loss: 0.0286
2023-02-06 16:13:13 | Train | Epoch[126/200] Iteration[011/030] Train loss: 0.0288
2023-02-06 16:13:13 | Train | Epoch[126/200] Iteration[012/030] Train loss: 0.0287
2023-02-06 16:13:14 | Train | Epoch[126/200] Iteration[013/030] Train loss: 0.0287
2023-02-06 16:13:14 | Train | Epoch[126/200] Iteration[014/030] Train loss: 0.0290
2023-02-06 16:13:15 | Train | Epoch[126/200] Iteration[015/030] Train loss: 0.0291
2023-02-06 16:13:15 | Train | Epoch[126/200] Iteration[016/030] Train loss: 0.0290
2023-02-06 16:13:15 | Train | Epoch[126/200] Iteration[017/030] Train loss: 0.0291
2023-02-06 16:13:16 | Train | Epoch[126/200] Iteration[018/030] Train loss: 0.0292
2023-02-06 16:13:16 | Train | Epoch[126/200] Iteration[019/030] Train loss: 0.0291
2023-02-06 16:13:17 | Train | Epoch[126/200] Iteration[020/030] Train loss: 0.0291
2023-02-06 16:13:17 | Train | Epoch[126/200] Iteration[021/030] Train loss: 0.0291
2023-02-06 16:13:18 | Train | Epoch[126/200] Iteration[022/030] Train loss: 0.0294
2023-02-06 16:13:18 | Train | Epoch[126/200] Iteration[023/030] Train loss: 0.0294
2023-02-06 16:13:18 | Train | Epoch[126/200] Iteration[024/030] Train loss: 0.0294
2023-02-06 16:13:19 | Train | Epoch[126/200] Iteration[025/030] Train loss: 0.0294
2023-02-06 16:13:19 | Train | Epoch[126/200] Iteration[026/030] Train loss: 0.0294
2023-02-06 16:13:20 | Train | Epoch[126/200] Iteration[027/030] Train loss: 0.0294
2023-02-06 16:13:20 | Train | Epoch[126/200] Iteration[028/030] Train loss: 0.0294
2023-02-06 16:13:21 | Train | Epoch[126/200] Iteration[029/030] Train loss: 0.0294
2023-02-06 16:13:21 | Train | Epoch[126/200] Iteration[030/030] Train loss: 0.0294
2023-02-06 16:13:21 | Valid | Epoch[126/200] Iteration[001/008] Valid loss: 0.1303
2023-02-06 16:13:21 | Valid | Epoch[126/200] Iteration[002/008] Valid loss: 0.1209
2023-02-06 16:13:21 | Valid | Epoch[126/200] Iteration[003/008] Valid loss: 0.1128
2023-02-06 16:13:22 | Valid | Epoch[126/200] Iteration[004/008] Valid loss: 0.1095
2023-02-06 16:13:22 | Valid | Epoch[126/200] Iteration[005/008] Valid loss: 0.1065
2023-02-06 16:13:22 | Valid | Epoch[126/200] Iteration[006/008] Valid loss: 0.1058
2023-02-06 16:13:22 | Valid | Epoch[126/200] Iteration[007/008] Valid loss: 0.1057
2023-02-06 16:13:22 | Valid | Epoch[126/200] Iteration[008/008] Valid loss: 0.1030
2023-02-06 16:13:22 | Valid | Epoch[126/200] MIou: 0.8651945724710144
2023-02-06 16:13:22 | Valid | Epoch[126/200] Pixel Accuracy: 0.9770342508951823
2023-02-06 16:13:22 | Valid | Epoch[126/200] Mean Pixel Accuracy: 0.8901142118311782
2023-02-06 16:13:22 | Stage | Epoch[126/200] Train loss:0.0294
2023-02-06 16:13:22 | Stage | Epoch[126/200] Valid loss:0.1030
2023-02-06 16:13:22 | Stage | Epoch[126/200] LR:0.01

2023-02-06 16:13:23 | Train | Epoch[127/200] Iteration[001/030] Train loss: 0.0292
2023-02-06 16:13:23 | Train | Epoch[127/200] Iteration[002/030] Train loss: 0.0294
2023-02-06 16:13:24 | Train | Epoch[127/200] Iteration[003/030] Train loss: 0.0296
2023-02-06 16:13:24 | Train | Epoch[127/200] Iteration[004/030] Train loss: 0.0290
2023-02-06 16:13:24 | Train | Epoch[127/200] Iteration[005/030] Train loss: 0.0290
2023-02-06 16:13:25 | Train | Epoch[127/200] Iteration[006/030] Train loss: 0.0287
2023-02-06 16:13:25 | Train | Epoch[127/200] Iteration[007/030] Train loss: 0.0290
2023-02-06 16:13:26 | Train | Epoch[127/200] Iteration[008/030] Train loss: 0.0290
2023-02-06 16:13:26 | Train | Epoch[127/200] Iteration[009/030] Train loss: 0.0292
2023-02-06 16:13:27 | Train | Epoch[127/200] Iteration[010/030] Train loss: 0.0291
2023-02-06 16:13:27 | Train | Epoch[127/200] Iteration[011/030] Train loss: 0.0291
2023-02-06 16:13:27 | Train | Epoch[127/200] Iteration[012/030] Train loss: 0.0291
2023-02-06 16:13:28 | Train | Epoch[127/200] Iteration[013/030] Train loss: 0.0291
2023-02-06 16:13:28 | Train | Epoch[127/200] Iteration[014/030] Train loss: 0.0291
2023-02-06 16:13:29 | Train | Epoch[127/200] Iteration[015/030] Train loss: 0.0291
2023-02-06 16:13:29 | Train | Epoch[127/200] Iteration[016/030] Train loss: 0.0292
2023-02-06 16:13:30 | Train | Epoch[127/200] Iteration[017/030] Train loss: 0.0292
2023-02-06 16:13:30 | Train | Epoch[127/200] Iteration[018/030] Train loss: 0.0291
2023-02-06 16:13:31 | Train | Epoch[127/200] Iteration[019/030] Train loss: 0.0291
2023-02-06 16:13:31 | Train | Epoch[127/200] Iteration[020/030] Train loss: 0.0291
2023-02-06 16:13:31 | Train | Epoch[127/200] Iteration[021/030] Train loss: 0.0292
2023-02-06 16:13:32 | Train | Epoch[127/200] Iteration[022/030] Train loss: 0.0291
2023-02-06 16:13:32 | Train | Epoch[127/200] Iteration[023/030] Train loss: 0.0290
2023-02-06 16:13:33 | Train | Epoch[127/200] Iteration[024/030] Train loss: 0.0291
2023-02-06 16:13:33 | Train | Epoch[127/200] Iteration[025/030] Train loss: 0.0292
2023-02-06 16:13:34 | Train | Epoch[127/200] Iteration[026/030] Train loss: 0.0292
2023-02-06 16:13:34 | Train | Epoch[127/200] Iteration[027/030] Train loss: 0.0291
2023-02-06 16:13:34 | Train | Epoch[127/200] Iteration[028/030] Train loss: 0.0291
2023-02-06 16:13:35 | Train | Epoch[127/200] Iteration[029/030] Train loss: 0.0292
2023-02-06 16:13:35 | Train | Epoch[127/200] Iteration[030/030] Train loss: 0.0292
2023-02-06 16:13:35 | Valid | Epoch[127/200] Iteration[001/008] Valid loss: 0.1105
2023-02-06 16:13:36 | Valid | Epoch[127/200] Iteration[002/008] Valid loss: 0.0867
2023-02-06 16:13:36 | Valid | Epoch[127/200] Iteration[003/008] Valid loss: 0.0763
2023-02-06 16:13:36 | Valid | Epoch[127/200] Iteration[004/008] Valid loss: 0.0753
2023-02-06 16:13:36 | Valid | Epoch[127/200] Iteration[005/008] Valid loss: 0.0757
2023-02-06 16:13:36 | Valid | Epoch[127/200] Iteration[006/008] Valid loss: 0.0762
2023-02-06 16:13:36 | Valid | Epoch[127/200] Iteration[007/008] Valid loss: 0.0786
2023-02-06 16:13:36 | Valid | Epoch[127/200] Iteration[008/008] Valid loss: 0.0766
2023-02-06 16:13:36 | Valid | Epoch[127/200] MIou: 0.9232362532253626
2023-02-06 16:13:36 | Valid | Epoch[127/200] Pixel Accuracy: 0.9868354797363281
2023-02-06 16:13:36 | Valid | Epoch[127/200] Mean Pixel Accuracy: 0.9483492152677571
2023-02-06 16:13:36 | Stage | Epoch[127/200] Train loss:0.0292
2023-02-06 16:13:36 | Stage | Epoch[127/200] Valid loss:0.0766
2023-02-06 16:13:36 | Stage | Epoch[127/200] LR:0.01

2023-02-06 16:13:37 | Train | Epoch[128/200] Iteration[001/030] Train loss: 0.0286
2023-02-06 16:13:37 | Train | Epoch[128/200] Iteration[002/030] Train loss: 0.0292
2023-02-06 16:13:38 | Train | Epoch[128/200] Iteration[003/030] Train loss: 0.0288
2023-02-06 16:13:38 | Train | Epoch[128/200] Iteration[004/030] Train loss: 0.0290
2023-02-06 16:13:39 | Train | Epoch[128/200] Iteration[005/030] Train loss: 0.0290
2023-02-06 16:13:39 | Train | Epoch[128/200] Iteration[006/030] Train loss: 0.0296
2023-02-06 16:13:40 | Train | Epoch[128/200] Iteration[007/030] Train loss: 0.0295
2023-02-06 16:13:40 | Train | Epoch[128/200] Iteration[008/030] Train loss: 0.0297
2023-02-06 16:13:40 | Train | Epoch[128/200] Iteration[009/030] Train loss: 0.0295
2023-02-06 16:13:41 | Train | Epoch[128/200] Iteration[010/030] Train loss: 0.0295
2023-02-06 16:13:41 | Train | Epoch[128/200] Iteration[011/030] Train loss: 0.0293
2023-02-06 16:13:42 | Train | Epoch[128/200] Iteration[012/030] Train loss: 0.0293
2023-02-06 16:13:42 | Train | Epoch[128/200] Iteration[013/030] Train loss: 0.0291
2023-02-06 16:13:43 | Train | Epoch[128/200] Iteration[014/030] Train loss: 0.0293
2023-02-06 16:13:43 | Train | Epoch[128/200] Iteration[015/030] Train loss: 0.0293
2023-02-06 16:13:43 | Train | Epoch[128/200] Iteration[016/030] Train loss: 0.0293
2023-02-06 16:13:44 | Train | Epoch[128/200] Iteration[017/030] Train loss: 0.0293
2023-02-06 16:13:44 | Train | Epoch[128/200] Iteration[018/030] Train loss: 0.0292
2023-02-06 16:13:45 | Train | Epoch[128/200] Iteration[019/030] Train loss: 0.0293
2023-02-06 16:13:45 | Train | Epoch[128/200] Iteration[020/030] Train loss: 0.0293
2023-02-06 16:13:46 | Train | Epoch[128/200] Iteration[021/030] Train loss: 0.0294
2023-02-06 16:13:46 | Train | Epoch[128/200] Iteration[022/030] Train loss: 0.0294
2023-02-06 16:13:46 | Train | Epoch[128/200] Iteration[023/030] Train loss: 0.0294
2023-02-06 16:13:47 | Train | Epoch[128/200] Iteration[024/030] Train loss: 0.0293
2023-02-06 16:13:47 | Train | Epoch[128/200] Iteration[025/030] Train loss: 0.0293
2023-02-06 16:13:48 | Train | Epoch[128/200] Iteration[026/030] Train loss: 0.0293
2023-02-06 16:13:48 | Train | Epoch[128/200] Iteration[027/030] Train loss: 0.0293
2023-02-06 16:13:49 | Train | Epoch[128/200] Iteration[028/030] Train loss: 0.0293
2023-02-06 16:13:49 | Train | Epoch[128/200] Iteration[029/030] Train loss: 0.0293
2023-02-06 16:13:49 | Train | Epoch[128/200] Iteration[030/030] Train loss: 0.0293
2023-02-06 16:13:50 | Valid | Epoch[128/200] Iteration[001/008] Valid loss: 0.0929
2023-02-06 16:13:50 | Valid | Epoch[128/200] Iteration[002/008] Valid loss: 0.0730
2023-02-06 16:13:50 | Valid | Epoch[128/200] Iteration[003/008] Valid loss: 0.0657
2023-02-06 16:13:50 | Valid | Epoch[128/200] Iteration[004/008] Valid loss: 0.0616
2023-02-06 16:13:50 | Valid | Epoch[128/200] Iteration[005/008] Valid loss: 0.0606
2023-02-06 16:13:50 | Valid | Epoch[128/200] Iteration[006/008] Valid loss: 0.0593
2023-02-06 16:13:50 | Valid | Epoch[128/200] Iteration[007/008] Valid loss: 0.0601
2023-02-06 16:13:50 | Valid | Epoch[128/200] Iteration[008/008] Valid loss: 0.0612
2023-02-06 16:13:50 | Valid | Epoch[128/200] MIou: 0.9100170035236582
2023-02-06 16:13:50 | Valid | Epoch[128/200] Pixel Accuracy: 0.9847971598307291
2023-02-06 16:13:50 | Valid | Epoch[128/200] Mean Pixel Accuracy: 0.9291838857920194
2023-02-06 16:13:50 | Stage | Epoch[128/200] Train loss:0.0293
2023-02-06 16:13:50 | Stage | Epoch[128/200] Valid loss:0.0612
2023-02-06 16:13:50 | Stage | Epoch[128/200] LR:0.01

2023-02-06 16:13:51 | Train | Epoch[129/200] Iteration[001/030] Train loss: 0.0274
2023-02-06 16:13:52 | Train | Epoch[129/200] Iteration[002/030] Train loss: 0.0289
2023-02-06 16:13:52 | Train | Epoch[129/200] Iteration[003/030] Train loss: 0.0288
2023-02-06 16:13:52 | Train | Epoch[129/200] Iteration[004/030] Train loss: 0.0288
2023-02-06 16:13:53 | Train | Epoch[129/200] Iteration[005/030] Train loss: 0.0285
2023-02-06 16:13:53 | Train | Epoch[129/200] Iteration[006/030] Train loss: 0.0284
2023-02-06 16:13:54 | Train | Epoch[129/200] Iteration[007/030] Train loss: 0.0284
2023-02-06 16:13:54 | Train | Epoch[129/200] Iteration[008/030] Train loss: 0.0283
2023-02-06 16:13:55 | Train | Epoch[129/200] Iteration[009/030] Train loss: 0.0282
2023-02-06 16:13:55 | Train | Epoch[129/200] Iteration[010/030] Train loss: 0.0281
2023-02-06 16:13:55 | Train | Epoch[129/200] Iteration[011/030] Train loss: 0.0281
2023-02-06 16:13:56 | Train | Epoch[129/200] Iteration[012/030] Train loss: 0.0280
2023-02-06 16:13:56 | Train | Epoch[129/200] Iteration[013/030] Train loss: 0.0280
2023-02-06 16:13:57 | Train | Epoch[129/200] Iteration[014/030] Train loss: 0.0280
2023-02-06 16:13:57 | Train | Epoch[129/200] Iteration[015/030] Train loss: 0.0280
2023-02-06 16:13:58 | Train | Epoch[129/200] Iteration[016/030] Train loss: 0.0280
2023-02-06 16:13:58 | Train | Epoch[129/200] Iteration[017/030] Train loss: 0.0281
2023-02-06 16:13:58 | Train | Epoch[129/200] Iteration[018/030] Train loss: 0.0281
2023-02-06 16:13:59 | Train | Epoch[129/200] Iteration[019/030] Train loss: 0.0283
2023-02-06 16:13:59 | Train | Epoch[129/200] Iteration[020/030] Train loss: 0.0282
2023-02-06 16:14:00 | Train | Epoch[129/200] Iteration[021/030] Train loss: 0.0282
2023-02-06 16:14:00 | Train | Epoch[129/200] Iteration[022/030] Train loss: 0.0282
2023-02-06 16:14:01 | Train | Epoch[129/200] Iteration[023/030] Train loss: 0.0283
2023-02-06 16:14:01 | Train | Epoch[129/200] Iteration[024/030] Train loss: 0.0283
2023-02-06 16:14:02 | Train | Epoch[129/200] Iteration[025/030] Train loss: 0.0284
2023-02-06 16:14:02 | Train | Epoch[129/200] Iteration[026/030] Train loss: 0.0284
2023-02-06 16:14:02 | Train | Epoch[129/200] Iteration[027/030] Train loss: 0.0284
2023-02-06 16:14:03 | Train | Epoch[129/200] Iteration[028/030] Train loss: 0.0284
2023-02-06 16:14:03 | Train | Epoch[129/200] Iteration[029/030] Train loss: 0.0284
2023-02-06 16:14:03 | Train | Epoch[129/200] Iteration[030/030] Train loss: 0.0285
2023-02-06 16:14:04 | Valid | Epoch[129/200] Iteration[001/008] Valid loss: 0.4479
2023-02-06 16:14:04 | Valid | Epoch[129/200] Iteration[002/008] Valid loss: 0.3995
2023-02-06 16:14:04 | Valid | Epoch[129/200] Iteration[003/008] Valid loss: 0.3869
2023-02-06 16:14:04 | Valid | Epoch[129/200] Iteration[004/008] Valid loss: 0.3812
2023-02-06 16:14:04 | Valid | Epoch[129/200] Iteration[005/008] Valid loss: 0.3985
2023-02-06 16:14:04 | Valid | Epoch[129/200] Iteration[006/008] Valid loss: 0.3801
2023-02-06 16:14:04 | Valid | Epoch[129/200] Iteration[007/008] Valid loss: 0.4074
2023-02-06 16:14:04 | Valid | Epoch[129/200] Iteration[008/008] Valid loss: 0.4216
2023-02-06 16:14:05 | Valid | Epoch[129/200] MIou: 0.8947136643802067
2023-02-06 16:14:05 | Valid | Epoch[129/200] Pixel Accuracy: 0.9794921875
2023-02-06 16:14:05 | Valid | Epoch[129/200] Mean Pixel Accuracy: 0.979832350081503
2023-02-06 16:14:05 | Stage | Epoch[129/200] Train loss:0.0285
2023-02-06 16:14:05 | Stage | Epoch[129/200] Valid loss:0.4216
2023-02-06 16:14:05 | Stage | Epoch[129/200] LR:0.01

2023-02-06 16:14:05 | Train | Epoch[130/200] Iteration[001/030] Train loss: 0.0264
2023-02-06 16:14:06 | Train | Epoch[130/200] Iteration[002/030] Train loss: 0.0269
2023-02-06 16:14:06 | Train | Epoch[130/200] Iteration[003/030] Train loss: 0.0271
2023-02-06 16:14:07 | Train | Epoch[130/200] Iteration[004/030] Train loss: 0.0274
2023-02-06 16:14:07 | Train | Epoch[130/200] Iteration[005/030] Train loss: 0.0274
2023-02-06 16:14:08 | Train | Epoch[130/200] Iteration[006/030] Train loss: 0.0277
2023-02-06 16:14:08 | Train | Epoch[130/200] Iteration[007/030] Train loss: 0.0278
2023-02-06 16:14:08 | Train | Epoch[130/200] Iteration[008/030] Train loss: 0.0279
2023-02-06 16:14:09 | Train | Epoch[130/200] Iteration[009/030] Train loss: 0.0279
2023-02-06 16:14:09 | Train | Epoch[130/200] Iteration[010/030] Train loss: 0.0279
2023-02-06 16:14:10 | Train | Epoch[130/200] Iteration[011/030] Train loss: 0.0281
2023-02-06 16:14:10 | Train | Epoch[130/200] Iteration[012/030] Train loss: 0.0280
2023-02-06 16:14:11 | Train | Epoch[130/200] Iteration[013/030] Train loss: 0.0280
2023-02-06 16:14:11 | Train | Epoch[130/200] Iteration[014/030] Train loss: 0.0279
2023-02-06 16:14:11 | Train | Epoch[130/200] Iteration[015/030] Train loss: 0.0278
2023-02-06 16:14:12 | Train | Epoch[130/200] Iteration[016/030] Train loss: 0.0279
2023-02-06 16:14:12 | Train | Epoch[130/200] Iteration[017/030] Train loss: 0.0279
2023-02-06 16:14:13 | Train | Epoch[130/200] Iteration[018/030] Train loss: 0.0279
2023-02-06 16:14:13 | Train | Epoch[130/200] Iteration[019/030] Train loss: 0.0279
2023-02-06 16:14:14 | Train | Epoch[130/200] Iteration[020/030] Train loss: 0.0279
2023-02-06 16:14:14 | Train | Epoch[130/200] Iteration[021/030] Train loss: 0.0279
2023-02-06 16:14:14 | Train | Epoch[130/200] Iteration[022/030] Train loss: 0.0279
2023-02-06 16:14:15 | Train | Epoch[130/200] Iteration[023/030] Train loss: 0.0279
2023-02-06 16:14:15 | Train | Epoch[130/200] Iteration[024/030] Train loss: 0.0278
2023-02-06 16:14:16 | Train | Epoch[130/200] Iteration[025/030] Train loss: 0.0279
2023-02-06 16:14:16 | Train | Epoch[130/200] Iteration[026/030] Train loss: 0.0279
2023-02-06 16:14:17 | Train | Epoch[130/200] Iteration[027/030] Train loss: 0.0279
2023-02-06 16:14:17 | Train | Epoch[130/200] Iteration[028/030] Train loss: 0.0279
2023-02-06 16:14:17 | Train | Epoch[130/200] Iteration[029/030] Train loss: 0.0279
2023-02-06 16:14:18 | Train | Epoch[130/200] Iteration[030/030] Train loss: 0.0278
2023-02-06 16:14:18 | Valid | Epoch[130/200] Iteration[001/008] Valid loss: 0.4074
2023-02-06 16:14:18 | Valid | Epoch[130/200] Iteration[002/008] Valid loss: 0.3445
2023-02-06 16:14:18 | Valid | Epoch[130/200] Iteration[003/008] Valid loss: 0.3169
2023-02-06 16:14:18 | Valid | Epoch[130/200] Iteration[004/008] Valid loss: 0.3144
2023-02-06 16:14:18 | Valid | Epoch[130/200] Iteration[005/008] Valid loss: 0.3225
2023-02-06 16:14:19 | Valid | Epoch[130/200] Iteration[006/008] Valid loss: 0.3209
2023-02-06 16:14:19 | Valid | Epoch[130/200] Iteration[007/008] Valid loss: 0.3442
2023-02-06 16:14:19 | Valid | Epoch[130/200] Iteration[008/008] Valid loss: 0.3423
2023-02-06 16:14:19 | Valid | Epoch[130/200] MIou: 0.8990745576781372
2023-02-06 16:14:19 | Valid | Epoch[130/200] Pixel Accuracy: 0.980462392171224
2023-02-06 16:14:19 | Valid | Epoch[130/200] Mean Pixel Accuracy: 0.9814815389331623
2023-02-06 16:14:19 | Stage | Epoch[130/200] Train loss:0.0278
2023-02-06 16:14:19 | Stage | Epoch[130/200] Valid loss:0.3423
2023-02-06 16:14:19 | Stage | Epoch[130/200] LR:0.01

2023-02-06 16:14:20 | Train | Epoch[131/200] Iteration[001/030] Train loss: 0.0265
2023-02-06 16:14:20 | Train | Epoch[131/200] Iteration[002/030] Train loss: 0.0270
2023-02-06 16:14:21 | Train | Epoch[131/200] Iteration[003/030] Train loss: 0.0270
2023-02-06 16:14:21 | Train | Epoch[131/200] Iteration[004/030] Train loss: 0.0269
2023-02-06 16:14:21 | Train | Epoch[131/200] Iteration[005/030] Train loss: 0.0272
2023-02-06 16:14:22 | Train | Epoch[131/200] Iteration[006/030] Train loss: 0.0271
2023-02-06 16:14:22 | Train | Epoch[131/200] Iteration[007/030] Train loss: 0.0271
2023-02-06 16:14:23 | Train | Epoch[131/200] Iteration[008/030] Train loss: 0.0271
2023-02-06 16:14:23 | Train | Epoch[131/200] Iteration[009/030] Train loss: 0.0270
2023-02-06 16:14:24 | Train | Epoch[131/200] Iteration[010/030] Train loss: 0.0269
2023-02-06 16:14:24 | Train | Epoch[131/200] Iteration[011/030] Train loss: 0.0271
2023-02-06 16:14:24 | Train | Epoch[131/200] Iteration[012/030] Train loss: 0.0271
2023-02-06 16:14:25 | Train | Epoch[131/200] Iteration[013/030] Train loss: 0.0271
2023-02-06 16:14:25 | Train | Epoch[131/200] Iteration[014/030] Train loss: 0.0270
2023-02-06 16:14:26 | Train | Epoch[131/200] Iteration[015/030] Train loss: 0.0270
2023-02-06 16:14:26 | Train | Epoch[131/200] Iteration[016/030] Train loss: 0.0271
2023-02-06 16:14:27 | Train | Epoch[131/200] Iteration[017/030] Train loss: 0.0272
2023-02-06 16:14:27 | Train | Epoch[131/200] Iteration[018/030] Train loss: 0.0272
2023-02-06 16:14:27 | Train | Epoch[131/200] Iteration[019/030] Train loss: 0.0272
2023-02-06 16:14:28 | Train | Epoch[131/200] Iteration[020/030] Train loss: 0.0272
2023-02-06 16:14:28 | Train | Epoch[131/200] Iteration[021/030] Train loss: 0.0271
2023-02-06 16:14:29 | Train | Epoch[131/200] Iteration[022/030] Train loss: 0.0271
2023-02-06 16:14:29 | Train | Epoch[131/200] Iteration[023/030] Train loss: 0.0272
2023-02-06 16:14:30 | Train | Epoch[131/200] Iteration[024/030] Train loss: 0.0273
2023-02-06 16:14:30 | Train | Epoch[131/200] Iteration[025/030] Train loss: 0.0272
2023-02-06 16:14:30 | Train | Epoch[131/200] Iteration[026/030] Train loss: 0.0272
2023-02-06 16:14:31 | Train | Epoch[131/200] Iteration[027/030] Train loss: 0.0272
2023-02-06 16:14:31 | Train | Epoch[131/200] Iteration[028/030] Train loss: 0.0273
2023-02-06 16:14:32 | Train | Epoch[131/200] Iteration[029/030] Train loss: 0.0273
2023-02-06 16:14:32 | Train | Epoch[131/200] Iteration[030/030] Train loss: 0.0272
2023-02-06 16:14:32 | Valid | Epoch[131/200] Iteration[001/008] Valid loss: 0.2253
2023-02-06 16:14:33 | Valid | Epoch[131/200] Iteration[002/008] Valid loss: 0.1696
2023-02-06 16:14:33 | Valid | Epoch[131/200] Iteration[003/008] Valid loss: 0.1498
2023-02-06 16:14:33 | Valid | Epoch[131/200] Iteration[004/008] Valid loss: 0.1486
2023-02-06 16:14:33 | Valid | Epoch[131/200] Iteration[005/008] Valid loss: 0.1483
2023-02-06 16:14:33 | Valid | Epoch[131/200] Iteration[006/008] Valid loss: 0.1440
2023-02-06 16:14:33 | Valid | Epoch[131/200] Iteration[007/008] Valid loss: 0.1595
2023-02-06 16:14:33 | Valid | Epoch[131/200] Iteration[008/008] Valid loss: 0.1553
2023-02-06 16:14:33 | Valid | Epoch[131/200] MIou: 0.916962583760077
2023-02-06 16:14:33 | Valid | Epoch[131/200] Pixel Accuracy: 0.9848683675130209
2023-02-06 16:14:33 | Valid | Epoch[131/200] Mean Pixel Accuracy: 0.9705058345862927
2023-02-06 16:14:33 | Stage | Epoch[131/200] Train loss:0.0272
2023-02-06 16:14:33 | Stage | Epoch[131/200] Valid loss:0.1553
2023-02-06 16:14:33 | Stage | Epoch[131/200] LR:0.01

2023-02-06 16:14:34 | Train | Epoch[132/200] Iteration[001/030] Train loss: 0.0267
2023-02-06 16:14:34 | Train | Epoch[132/200] Iteration[002/030] Train loss: 0.0276
2023-02-06 16:14:35 | Train | Epoch[132/200] Iteration[003/030] Train loss: 0.0272
2023-02-06 16:14:35 | Train | Epoch[132/200] Iteration[004/030] Train loss: 0.0268
2023-02-06 16:14:36 | Train | Epoch[132/200] Iteration[005/030] Train loss: 0.0266
2023-02-06 16:14:36 | Train | Epoch[132/200] Iteration[006/030] Train loss: 0.0266
2023-02-06 16:14:37 | Train | Epoch[132/200] Iteration[007/030] Train loss: 0.0265
2023-02-06 16:14:37 | Train | Epoch[132/200] Iteration[008/030] Train loss: 0.0264
2023-02-06 16:14:37 | Train | Epoch[132/200] Iteration[009/030] Train loss: 0.0263
2023-02-06 16:14:38 | Train | Epoch[132/200] Iteration[010/030] Train loss: 0.0263
2023-02-06 16:14:38 | Train | Epoch[132/200] Iteration[011/030] Train loss: 0.0262
2023-02-06 16:14:39 | Train | Epoch[132/200] Iteration[012/030] Train loss: 0.0262
2023-02-06 16:14:39 | Train | Epoch[132/200] Iteration[013/030] Train loss: 0.0261
2023-02-06 16:14:40 | Train | Epoch[132/200] Iteration[014/030] Train loss: 0.0263
2023-02-06 16:14:40 | Train | Epoch[132/200] Iteration[015/030] Train loss: 0.0265
2023-02-06 16:14:41 | Train | Epoch[132/200] Iteration[016/030] Train loss: 0.0265
2023-02-06 16:14:41 | Train | Epoch[132/200] Iteration[017/030] Train loss: 0.0264
2023-02-06 16:14:41 | Train | Epoch[132/200] Iteration[018/030] Train loss: 0.0265
2023-02-06 16:14:42 | Train | Epoch[132/200] Iteration[019/030] Train loss: 0.0265
2023-02-06 16:14:42 | Train | Epoch[132/200] Iteration[020/030] Train loss: 0.0266
2023-02-06 16:14:43 | Train | Epoch[132/200] Iteration[021/030] Train loss: 0.0266
2023-02-06 16:14:43 | Train | Epoch[132/200] Iteration[022/030] Train loss: 0.0267
2023-02-06 16:14:44 | Train | Epoch[132/200] Iteration[023/030] Train loss: 0.0266
2023-02-06 16:14:44 | Train | Epoch[132/200] Iteration[024/030] Train loss: 0.0266
2023-02-06 16:14:44 | Train | Epoch[132/200] Iteration[025/030] Train loss: 0.0267
2023-02-06 16:14:45 | Train | Epoch[132/200] Iteration[026/030] Train loss: 0.0267
2023-02-06 16:14:45 | Train | Epoch[132/200] Iteration[027/030] Train loss: 0.0267
2023-02-06 16:14:46 | Train | Epoch[132/200] Iteration[028/030] Train loss: 0.0268
2023-02-06 16:14:46 | Train | Epoch[132/200] Iteration[029/030] Train loss: 0.0268
2023-02-06 16:14:46 | Train | Epoch[132/200] Iteration[030/030] Train loss: 0.0269
2023-02-06 16:14:47 | Valid | Epoch[132/200] Iteration[001/008] Valid loss: 0.4647
2023-02-06 16:14:47 | Valid | Epoch[132/200] Iteration[002/008] Valid loss: 0.4313
2023-02-06 16:14:47 | Valid | Epoch[132/200] Iteration[003/008] Valid loss: 0.4252
2023-02-06 16:14:47 | Valid | Epoch[132/200] Iteration[004/008] Valid loss: 0.4223
2023-02-06 16:14:47 | Valid | Epoch[132/200] Iteration[005/008] Valid loss: 0.4336
2023-02-06 16:14:47 | Valid | Epoch[132/200] Iteration[006/008] Valid loss: 0.4209
2023-02-06 16:14:47 | Valid | Epoch[132/200] Iteration[007/008] Valid loss: 0.4523
2023-02-06 16:14:47 | Valid | Epoch[132/200] Iteration[008/008] Valid loss: 0.4681
2023-02-06 16:14:48 | Valid | Epoch[132/200] MIou: 0.8946226787502963
2023-02-06 16:14:48 | Valid | Epoch[132/200] Pixel Accuracy: 0.9793357849121094
2023-02-06 16:14:48 | Valid | Epoch[132/200] Mean Pixel Accuracy: 0.9831321963362399
2023-02-06 16:14:48 | Stage | Epoch[132/200] Train loss:0.0269
2023-02-06 16:14:48 | Stage | Epoch[132/200] Valid loss:0.4681
2023-02-06 16:14:48 | Stage | Epoch[132/200] LR:0.01

2023-02-06 16:14:48 | Train | Epoch[133/200] Iteration[001/030] Train loss: 0.0263
2023-02-06 16:14:49 | Train | Epoch[133/200] Iteration[002/030] Train loss: 0.0265
2023-02-06 16:14:49 | Train | Epoch[133/200] Iteration[003/030] Train loss: 0.0265
2023-02-06 16:14:50 | Train | Epoch[133/200] Iteration[004/030] Train loss: 0.0266
2023-02-06 16:14:50 | Train | Epoch[133/200] Iteration[005/030] Train loss: 0.0266
2023-02-06 16:14:50 | Train | Epoch[133/200] Iteration[006/030] Train loss: 0.0265
2023-02-06 16:14:51 | Train | Epoch[133/200] Iteration[007/030] Train loss: 0.0268
2023-02-06 16:14:51 | Train | Epoch[133/200] Iteration[008/030] Train loss: 0.0269
2023-02-06 16:14:52 | Train | Epoch[133/200] Iteration[009/030] Train loss: 0.0271
2023-02-06 16:14:52 | Train | Epoch[133/200] Iteration[010/030] Train loss: 0.0272
2023-02-06 16:14:53 | Train | Epoch[133/200] Iteration[011/030] Train loss: 0.0272
2023-02-06 16:14:53 | Train | Epoch[133/200] Iteration[012/030] Train loss: 0.0275
2023-02-06 16:14:53 | Train | Epoch[133/200] Iteration[013/030] Train loss: 0.0276
2023-02-06 16:14:54 | Train | Epoch[133/200] Iteration[014/030] Train loss: 0.0276
2023-02-06 16:14:54 | Train | Epoch[133/200] Iteration[015/030] Train loss: 0.0276
2023-02-06 16:14:55 | Train | Epoch[133/200] Iteration[016/030] Train loss: 0.0276
2023-02-06 16:14:55 | Train | Epoch[133/200] Iteration[017/030] Train loss: 0.0277
2023-02-06 16:14:56 | Train | Epoch[133/200] Iteration[018/030] Train loss: 0.0276
2023-02-06 16:14:56 | Train | Epoch[133/200] Iteration[019/030] Train loss: 0.0277
2023-02-06 16:14:57 | Train | Epoch[133/200] Iteration[020/030] Train loss: 0.0276
2023-02-06 16:14:57 | Train | Epoch[133/200] Iteration[021/030] Train loss: 0.0277
2023-02-06 16:14:57 | Train | Epoch[133/200] Iteration[022/030] Train loss: 0.0278
2023-02-06 16:14:58 | Train | Epoch[133/200] Iteration[023/030] Train loss: 0.0278
2023-02-06 16:14:58 | Train | Epoch[133/200] Iteration[024/030] Train loss: 0.0278
2023-02-06 16:14:59 | Train | Epoch[133/200] Iteration[025/030] Train loss: 0.0277
2023-02-06 16:14:59 | Train | Epoch[133/200] Iteration[026/030] Train loss: 0.0277
2023-02-06 16:15:00 | Train | Epoch[133/200] Iteration[027/030] Train loss: 0.0277
2023-02-06 16:15:00 | Train | Epoch[133/200] Iteration[028/030] Train loss: 0.0278
2023-02-06 16:15:00 | Train | Epoch[133/200] Iteration[029/030] Train loss: 0.0279
2023-02-06 16:15:01 | Train | Epoch[133/200] Iteration[030/030] Train loss: 0.0279
2023-02-06 16:15:01 | Valid | Epoch[133/200] Iteration[001/008] Valid loss: 0.1202
2023-02-06 16:15:01 | Valid | Epoch[133/200] Iteration[002/008] Valid loss: 0.1177
2023-02-06 16:15:01 | Valid | Epoch[133/200] Iteration[003/008] Valid loss: 0.1223
2023-02-06 16:15:01 | Valid | Epoch[133/200] Iteration[004/008] Valid loss: 0.1192
2023-02-06 16:15:01 | Valid | Epoch[133/200] Iteration[005/008] Valid loss: 0.1233
2023-02-06 16:15:02 | Valid | Epoch[133/200] Iteration[006/008] Valid loss: 0.1206
2023-02-06 16:15:02 | Valid | Epoch[133/200] Iteration[007/008] Valid loss: 0.1186
2023-02-06 16:15:02 | Valid | Epoch[133/200] Iteration[008/008] Valid loss: 0.1215
2023-02-06 16:15:02 | Valid | Epoch[133/200] MIou: 0.7043766676012765
2023-02-06 16:15:02 | Valid | Epoch[133/200] Pixel Accuracy: 0.9510396321614584
2023-02-06 16:15:02 | Valid | Epoch[133/200] Mean Pixel Accuracy: 0.7305662583897001
2023-02-06 16:15:02 | Stage | Epoch[133/200] Train loss:0.0279
2023-02-06 16:15:02 | Stage | Epoch[133/200] Valid loss:0.1215
2023-02-06 16:15:02 | Stage | Epoch[133/200] LR:0.01

2023-02-06 16:15:03 | Train | Epoch[134/200] Iteration[001/030] Train loss: 0.0266
2023-02-06 16:15:03 | Train | Epoch[134/200] Iteration[002/030] Train loss: 0.0269
2023-02-06 16:15:04 | Train | Epoch[134/200] Iteration[003/030] Train loss: 0.0271
2023-02-06 16:15:04 | Train | Epoch[134/200] Iteration[004/030] Train loss: 0.0271
2023-02-06 16:15:04 | Train | Epoch[134/200] Iteration[005/030] Train loss: 0.0271
2023-02-06 16:15:05 | Train | Epoch[134/200] Iteration[006/030] Train loss: 0.0271
2023-02-06 16:15:05 | Train | Epoch[134/200] Iteration[007/030] Train loss: 0.0270
2023-02-06 16:15:06 | Train | Epoch[134/200] Iteration[008/030] Train loss: 0.0269
2023-02-06 16:15:06 | Train | Epoch[134/200] Iteration[009/030] Train loss: 0.0271
2023-02-06 16:15:07 | Train | Epoch[134/200] Iteration[010/030] Train loss: 0.0270
2023-02-06 16:15:07 | Train | Epoch[134/200] Iteration[011/030] Train loss: 0.0269
2023-02-06 16:15:07 | Train | Epoch[134/200] Iteration[012/030] Train loss: 0.0269
2023-02-06 16:15:08 | Train | Epoch[134/200] Iteration[013/030] Train loss: 0.0270
2023-02-06 16:15:08 | Train | Epoch[134/200] Iteration[014/030] Train loss: 0.0270
2023-02-06 16:15:09 | Train | Epoch[134/200] Iteration[015/030] Train loss: 0.0270
2023-02-06 16:15:09 | Train | Epoch[134/200] Iteration[016/030] Train loss: 0.0269
2023-02-06 16:15:10 | Train | Epoch[134/200] Iteration[017/030] Train loss: 0.0269
2023-02-06 16:15:10 | Train | Epoch[134/200] Iteration[018/030] Train loss: 0.0271
2023-02-06 16:15:10 | Train | Epoch[134/200] Iteration[019/030] Train loss: 0.0270
2023-02-06 16:15:11 | Train | Epoch[134/200] Iteration[020/030] Train loss: 0.0270
2023-02-06 16:15:11 | Train | Epoch[134/200] Iteration[021/030] Train loss: 0.0270
2023-02-06 16:15:12 | Train | Epoch[134/200] Iteration[022/030] Train loss: 0.0270
2023-02-06 16:15:12 | Train | Epoch[134/200] Iteration[023/030] Train loss: 0.0269
2023-02-06 16:15:13 | Train | Epoch[134/200] Iteration[024/030] Train loss: 0.0269
2023-02-06 16:15:13 | Train | Epoch[134/200] Iteration[025/030] Train loss: 0.0269
2023-02-06 16:15:14 | Train | Epoch[134/200] Iteration[026/030] Train loss: 0.0269
2023-02-06 16:15:14 | Train | Epoch[134/200] Iteration[027/030] Train loss: 0.0269
2023-02-06 16:15:14 | Train | Epoch[134/200] Iteration[028/030] Train loss: 0.0269
2023-02-06 16:15:15 | Train | Epoch[134/200] Iteration[029/030] Train loss: 0.0270
2023-02-06 16:15:15 | Train | Epoch[134/200] Iteration[030/030] Train loss: 0.0270
2023-02-06 16:15:15 | Valid | Epoch[134/200] Iteration[001/008] Valid loss: 0.8732
2023-02-06 16:15:16 | Valid | Epoch[134/200] Iteration[002/008] Valid loss: 0.8800
2023-02-06 16:15:16 | Valid | Epoch[134/200] Iteration[003/008] Valid loss: 0.9104
2023-02-06 16:15:16 | Valid | Epoch[134/200] Iteration[004/008] Valid loss: 0.9398
2023-02-06 16:15:16 | Valid | Epoch[134/200] Iteration[005/008] Valid loss: 0.9575
2023-02-06 16:15:16 | Valid | Epoch[134/200] Iteration[006/008] Valid loss: 0.9416
2023-02-06 16:15:16 | Valid | Epoch[134/200] Iteration[007/008] Valid loss: 0.9898
2023-02-06 16:15:16 | Valid | Epoch[134/200] Iteration[008/008] Valid loss: 1.0501
2023-02-06 16:15:16 | Valid | Epoch[134/200] MIou: 0.8494667950861791
2023-02-06 16:15:16 | Valid | Epoch[134/200] Pixel Accuracy: 0.9675712585449219
2023-02-06 16:15:16 | Valid | Epoch[134/200] Mean Pixel Accuracy: 0.9792972065774326
2023-02-06 16:15:16 | Stage | Epoch[134/200] Train loss:0.0270
2023-02-06 16:15:16 | Stage | Epoch[134/200] Valid loss:1.0501
2023-02-06 16:15:16 | Stage | Epoch[134/200] LR:0.01

2023-02-06 16:15:17 | Train | Epoch[135/200] Iteration[001/030] Train loss: 0.0279
2023-02-06 16:15:17 | Train | Epoch[135/200] Iteration[002/030] Train loss: 0.0270
2023-02-06 16:15:18 | Train | Epoch[135/200] Iteration[003/030] Train loss: 0.0270
2023-02-06 16:15:18 | Train | Epoch[135/200] Iteration[004/030] Train loss: 0.0267
2023-02-06 16:15:19 | Train | Epoch[135/200] Iteration[005/030] Train loss: 0.0266
2023-02-06 16:15:19 | Train | Epoch[135/200] Iteration[006/030] Train loss: 0.0265
2023-02-06 16:15:19 | Train | Epoch[135/200] Iteration[007/030] Train loss: 0.0269
2023-02-06 16:15:20 | Train | Epoch[135/200] Iteration[008/030] Train loss: 0.0270
2023-02-06 16:15:20 | Train | Epoch[135/200] Iteration[009/030] Train loss: 0.0269
2023-02-06 16:15:21 | Train | Epoch[135/200] Iteration[010/030] Train loss: 0.0268
2023-02-06 16:15:21 | Train | Epoch[135/200] Iteration[011/030] Train loss: 0.0268
2023-02-06 16:15:22 | Train | Epoch[135/200] Iteration[012/030] Train loss: 0.0269
2023-02-06 16:15:22 | Train | Epoch[135/200] Iteration[013/030] Train loss: 0.0268
2023-02-06 16:15:22 | Train | Epoch[135/200] Iteration[014/030] Train loss: 0.0267
2023-02-06 16:15:23 | Train | Epoch[135/200] Iteration[015/030] Train loss: 0.0266
2023-02-06 16:15:23 | Train | Epoch[135/200] Iteration[016/030] Train loss: 0.0267
2023-02-06 16:15:24 | Train | Epoch[135/200] Iteration[017/030] Train loss: 0.0266
2023-02-06 16:15:24 | Train | Epoch[135/200] Iteration[018/030] Train loss: 0.0265
2023-02-06 16:15:25 | Train | Epoch[135/200] Iteration[019/030] Train loss: 0.0267
2023-02-06 16:15:25 | Train | Epoch[135/200] Iteration[020/030] Train loss: 0.0267
2023-02-06 16:15:26 | Train | Epoch[135/200] Iteration[021/030] Train loss: 0.0266
2023-02-06 16:15:26 | Train | Epoch[135/200] Iteration[022/030] Train loss: 0.0266
2023-02-06 16:15:26 | Train | Epoch[135/200] Iteration[023/030] Train loss: 0.0267
2023-02-06 16:15:27 | Train | Epoch[135/200] Iteration[024/030] Train loss: 0.0267
2023-02-06 16:15:27 | Train | Epoch[135/200] Iteration[025/030] Train loss: 0.0267
2023-02-06 16:15:28 | Train | Epoch[135/200] Iteration[026/030] Train loss: 0.0268
2023-02-06 16:15:28 | Train | Epoch[135/200] Iteration[027/030] Train loss: 0.0267
2023-02-06 16:15:29 | Train | Epoch[135/200] Iteration[028/030] Train loss: 0.0267
2023-02-06 16:15:29 | Train | Epoch[135/200] Iteration[029/030] Train loss: 0.0269
2023-02-06 16:15:29 | Train | Epoch[135/200] Iteration[030/030] Train loss: 0.0269
2023-02-06 16:15:30 | Valid | Epoch[135/200] Iteration[001/008] Valid loss: 0.0807
2023-02-06 16:15:30 | Valid | Epoch[135/200] Iteration[002/008] Valid loss: 0.0732
2023-02-06 16:15:30 | Valid | Epoch[135/200] Iteration[003/008] Valid loss: 0.0710
2023-02-06 16:15:30 | Valid | Epoch[135/200] Iteration[004/008] Valid loss: 0.0691
2023-02-06 16:15:30 | Valid | Epoch[135/200] Iteration[005/008] Valid loss: 0.0693
2023-02-06 16:15:30 | Valid | Epoch[135/200] Iteration[006/008] Valid loss: 0.0696
2023-02-06 16:15:30 | Valid | Epoch[135/200] Iteration[007/008] Valid loss: 0.0691
2023-02-06 16:15:30 | Valid | Epoch[135/200] Iteration[008/008] Valid loss: 0.0693
2023-02-06 16:15:30 | Valid | Epoch[135/200] MIou: 0.8444512152248387
2023-02-06 16:15:30 | Valid | Epoch[135/200] Pixel Accuracy: 0.9741083780924479
2023-02-06 16:15:30 | Valid | Epoch[135/200] Mean Pixel Accuracy: 0.8618760470026032
2023-02-06 16:15:30 | Stage | Epoch[135/200] Train loss:0.0269
2023-02-06 16:15:30 | Stage | Epoch[135/200] Valid loss:0.0693
2023-02-06 16:15:30 | Stage | Epoch[135/200] LR:0.01

2023-02-06 16:15:31 | Train | Epoch[136/200] Iteration[001/030] Train loss: 0.0256
2023-02-06 16:15:31 | Train | Epoch[136/200] Iteration[002/030] Train loss: 0.0252
2023-02-06 16:15:32 | Train | Epoch[136/200] Iteration[003/030] Train loss: 0.0256
2023-02-06 16:15:32 | Train | Epoch[136/200] Iteration[004/030] Train loss: 0.0260
2023-02-06 16:15:33 | Train | Epoch[136/200] Iteration[005/030] Train loss: 0.0261
2023-02-06 16:15:33 | Train | Epoch[136/200] Iteration[006/030] Train loss: 0.0259
2023-02-06 16:15:34 | Train | Epoch[136/200] Iteration[007/030] Train loss: 0.0258
2023-02-06 16:15:34 | Train | Epoch[136/200] Iteration[008/030] Train loss: 0.0257
2023-02-06 16:15:35 | Train | Epoch[136/200] Iteration[009/030] Train loss: 0.0260
2023-02-06 16:15:35 | Train | Epoch[136/200] Iteration[010/030] Train loss: 0.0259
2023-02-06 16:15:35 | Train | Epoch[136/200] Iteration[011/030] Train loss: 0.0259
2023-02-06 16:15:36 | Train | Epoch[136/200] Iteration[012/030] Train loss: 0.0258
2023-02-06 16:15:36 | Train | Epoch[136/200] Iteration[013/030] Train loss: 0.0258
2023-02-06 16:15:37 | Train | Epoch[136/200] Iteration[014/030] Train loss: 0.0259
2023-02-06 16:15:37 | Train | Epoch[136/200] Iteration[015/030] Train loss: 0.0258
2023-02-06 16:15:38 | Train | Epoch[136/200] Iteration[016/030] Train loss: 0.0258
2023-02-06 16:15:38 | Train | Epoch[136/200] Iteration[017/030] Train loss: 0.0258
2023-02-06 16:15:38 | Train | Epoch[136/200] Iteration[018/030] Train loss: 0.0257
2023-02-06 16:15:39 | Train | Epoch[136/200] Iteration[019/030] Train loss: 0.0257
2023-02-06 16:15:39 | Train | Epoch[136/200] Iteration[020/030] Train loss: 0.0257
2023-02-06 16:15:40 | Train | Epoch[136/200] Iteration[021/030] Train loss: 0.0257
2023-02-06 16:15:40 | Train | Epoch[136/200] Iteration[022/030] Train loss: 0.0258
2023-02-06 16:15:41 | Train | Epoch[136/200] Iteration[023/030] Train loss: 0.0258
2023-02-06 16:15:41 | Train | Epoch[136/200] Iteration[024/030] Train loss: 0.0259
2023-02-06 16:15:41 | Train | Epoch[136/200] Iteration[025/030] Train loss: 0.0259
2023-02-06 16:15:42 | Train | Epoch[136/200] Iteration[026/030] Train loss: 0.0259
2023-02-06 16:15:42 | Train | Epoch[136/200] Iteration[027/030] Train loss: 0.0259
2023-02-06 16:15:43 | Train | Epoch[136/200] Iteration[028/030] Train loss: 0.0258
2023-02-06 16:15:43 | Train | Epoch[136/200] Iteration[029/030] Train loss: 0.0259
2023-02-06 16:15:43 | Train | Epoch[136/200] Iteration[030/030] Train loss: 0.0259
2023-02-06 16:15:44 | Valid | Epoch[136/200] Iteration[001/008] Valid loss: 0.1828
2023-02-06 16:15:44 | Valid | Epoch[136/200] Iteration[002/008] Valid loss: 0.1292
2023-02-06 16:15:44 | Valid | Epoch[136/200] Iteration[003/008] Valid loss: 0.1114
2023-02-06 16:15:44 | Valid | Epoch[136/200] Iteration[004/008] Valid loss: 0.1044
2023-02-06 16:15:44 | Valid | Epoch[136/200] Iteration[005/008] Valid loss: 0.1032
2023-02-06 16:15:44 | Valid | Epoch[136/200] Iteration[006/008] Valid loss: 0.1018
2023-02-06 16:15:44 | Valid | Epoch[136/200] Iteration[007/008] Valid loss: 0.1096
2023-02-06 16:15:45 | Valid | Epoch[136/200] Iteration[008/008] Valid loss: 0.1069
2023-02-06 16:15:45 | Valid | Epoch[136/200] MIou: 0.9321739366802899
2023-02-06 16:15:45 | Valid | Epoch[136/200] Pixel Accuracy: 0.9880790710449219
2023-02-06 16:15:45 | Valid | Epoch[136/200] Mean Pixel Accuracy: 0.9684155675012747
2023-02-06 16:15:45 | Stage | Epoch[136/200] Train loss:0.0259
2023-02-06 16:15:45 | Stage | Epoch[136/200] Valid loss:0.1069
2023-02-06 16:15:45 | Stage | Epoch[136/200] LR:0.01

2023-02-06 16:15:45 | Train | Epoch[137/200] Iteration[001/030] Train loss: 0.0251
2023-02-06 16:15:46 | Train | Epoch[137/200] Iteration[002/030] Train loss: 0.0247
2023-02-06 16:15:46 | Train | Epoch[137/200] Iteration[003/030] Train loss: 0.0246
2023-02-06 16:15:47 | Train | Epoch[137/200] Iteration[004/030] Train loss: 0.0246
2023-02-06 16:15:47 | Train | Epoch[137/200] Iteration[005/030] Train loss: 0.0249
2023-02-06 16:15:48 | Train | Epoch[137/200] Iteration[006/030] Train loss: 0.0251
2023-02-06 16:15:48 | Train | Epoch[137/200] Iteration[007/030] Train loss: 0.0251
2023-02-06 16:15:48 | Train | Epoch[137/200] Iteration[008/030] Train loss: 0.0252
2023-02-06 16:15:49 | Train | Epoch[137/200] Iteration[009/030] Train loss: 0.0251
2023-02-06 16:15:49 | Train | Epoch[137/200] Iteration[010/030] Train loss: 0.0251
2023-02-06 16:15:50 | Train | Epoch[137/200] Iteration[011/030] Train loss: 0.0250
2023-02-06 16:15:50 | Train | Epoch[137/200] Iteration[012/030] Train loss: 0.0251
2023-02-06 16:15:51 | Train | Epoch[137/200] Iteration[013/030] Train loss: 0.0251
2023-02-06 16:15:51 | Train | Epoch[137/200] Iteration[014/030] Train loss: 0.0253
2023-02-06 16:15:51 | Train | Epoch[137/200] Iteration[015/030] Train loss: 0.0253
2023-02-06 16:15:52 | Train | Epoch[137/200] Iteration[016/030] Train loss: 0.0253
2023-02-06 16:15:52 | Train | Epoch[137/200] Iteration[017/030] Train loss: 0.0252
2023-02-06 16:15:53 | Train | Epoch[137/200] Iteration[018/030] Train loss: 0.0252
2023-02-06 16:15:53 | Train | Epoch[137/200] Iteration[019/030] Train loss: 0.0252
2023-02-06 16:15:54 | Train | Epoch[137/200] Iteration[020/030] Train loss: 0.0252
2023-02-06 16:15:54 | Train | Epoch[137/200] Iteration[021/030] Train loss: 0.0252
2023-02-06 16:15:54 | Train | Epoch[137/200] Iteration[022/030] Train loss: 0.0252
2023-02-06 16:15:55 | Train | Epoch[137/200] Iteration[023/030] Train loss: 0.0251
2023-02-06 16:15:55 | Train | Epoch[137/200] Iteration[024/030] Train loss: 0.0251
2023-02-06 16:15:56 | Train | Epoch[137/200] Iteration[025/030] Train loss: 0.0251
2023-02-06 16:15:56 | Train | Epoch[137/200] Iteration[026/030] Train loss: 0.0251
2023-02-06 16:15:57 | Train | Epoch[137/200] Iteration[027/030] Train loss: 0.0251
2023-02-06 16:15:57 | Train | Epoch[137/200] Iteration[028/030] Train loss: 0.0251
2023-02-06 16:15:58 | Train | Epoch[137/200] Iteration[029/030] Train loss: 0.0251
2023-02-06 16:15:58 | Train | Epoch[137/200] Iteration[030/030] Train loss: 0.0251
2023-02-06 16:15:58 | Valid | Epoch[137/200] Iteration[001/008] Valid loss: 0.0730
2023-02-06 16:15:58 | Valid | Epoch[137/200] Iteration[002/008] Valid loss: 0.0620
2023-02-06 16:15:58 | Valid | Epoch[137/200] Iteration[003/008] Valid loss: 0.0594
2023-02-06 16:15:58 | Valid | Epoch[137/200] Iteration[004/008] Valid loss: 0.0566
2023-02-06 16:15:59 | Valid | Epoch[137/200] Iteration[005/008] Valid loss: 0.0569
2023-02-06 16:15:59 | Valid | Epoch[137/200] Iteration[006/008] Valid loss: 0.0565
2023-02-06 16:15:59 | Valid | Epoch[137/200] Iteration[007/008] Valid loss: 0.0564
2023-02-06 16:15:59 | Valid | Epoch[137/200] Iteration[008/008] Valid loss: 0.0564
2023-02-06 16:15:59 | Valid | Epoch[137/200] MIou: 0.8967418350901797
2023-02-06 16:15:59 | Valid | Epoch[137/200] Pixel Accuracy: 0.9827740987141927
2023-02-06 16:15:59 | Valid | Epoch[137/200] Mean Pixel Accuracy: 0.9113964850441312
2023-02-06 16:15:59 | Stage | Epoch[137/200] Train loss:0.0251
2023-02-06 16:15:59 | Stage | Epoch[137/200] Valid loss:0.0564
2023-02-06 16:15:59 | Stage | Epoch[137/200] LR:0.01

2023-02-06 16:16:00 | Train | Epoch[138/200] Iteration[001/030] Train loss: 0.0240
2023-02-06 16:16:00 | Train | Epoch[138/200] Iteration[002/030] Train loss: 0.0242
2023-02-06 16:16:00 | Train | Epoch[138/200] Iteration[003/030] Train loss: 0.0240
2023-02-06 16:16:01 | Train | Epoch[138/200] Iteration[004/030] Train loss: 0.0241
2023-02-06 16:16:01 | Train | Epoch[138/200] Iteration[005/030] Train loss: 0.0241
2023-02-06 16:16:02 | Train | Epoch[138/200] Iteration[006/030] Train loss: 0.0241
2023-02-06 16:16:02 | Train | Epoch[138/200] Iteration[007/030] Train loss: 0.0249
2023-02-06 16:16:03 | Train | Epoch[138/200] Iteration[008/030] Train loss: 0.0247
2023-02-06 16:16:03 | Train | Epoch[138/200] Iteration[009/030] Train loss: 0.0251
2023-02-06 16:16:04 | Train | Epoch[138/200] Iteration[010/030] Train loss: 0.0251
2023-02-06 16:16:04 | Train | Epoch[138/200] Iteration[011/030] Train loss: 0.0250
2023-02-06 16:16:04 | Train | Epoch[138/200] Iteration[012/030] Train loss: 0.0250
2023-02-06 16:16:05 | Train | Epoch[138/200] Iteration[013/030] Train loss: 0.0250
2023-02-06 16:16:05 | Train | Epoch[138/200] Iteration[014/030] Train loss: 0.0251
2023-02-06 16:16:06 | Train | Epoch[138/200] Iteration[015/030] Train loss: 0.0251
2023-02-06 16:16:06 | Train | Epoch[138/200] Iteration[016/030] Train loss: 0.0251
2023-02-06 16:16:07 | Train | Epoch[138/200] Iteration[017/030] Train loss: 0.0251
2023-02-06 16:16:07 | Train | Epoch[138/200] Iteration[018/030] Train loss: 0.0251
2023-02-06 16:16:07 | Train | Epoch[138/200] Iteration[019/030] Train loss: 0.0251
2023-02-06 16:16:08 | Train | Epoch[138/200] Iteration[020/030] Train loss: 0.0251
2023-02-06 16:16:08 | Train | Epoch[138/200] Iteration[021/030] Train loss: 0.0250
2023-02-06 16:16:09 | Train | Epoch[138/200] Iteration[022/030] Train loss: 0.0250
2023-02-06 16:16:09 | Train | Epoch[138/200] Iteration[023/030] Train loss: 0.0250
2023-02-06 16:16:10 | Train | Epoch[138/200] Iteration[024/030] Train loss: 0.0250
2023-02-06 16:16:10 | Train | Epoch[138/200] Iteration[025/030] Train loss: 0.0251
2023-02-06 16:16:10 | Train | Epoch[138/200] Iteration[026/030] Train loss: 0.0251
2023-02-06 16:16:11 | Train | Epoch[138/200] Iteration[027/030] Train loss: 0.0251
2023-02-06 16:16:11 | Train | Epoch[138/200] Iteration[028/030] Train loss: 0.0251
2023-02-06 16:16:12 | Train | Epoch[138/200] Iteration[029/030] Train loss: 0.0251
2023-02-06 16:16:12 | Train | Epoch[138/200] Iteration[030/030] Train loss: 0.0251
2023-02-06 16:16:12 | Valid | Epoch[138/200] Iteration[001/008] Valid loss: 0.1558
2023-02-06 16:16:13 | Valid | Epoch[138/200] Iteration[002/008] Valid loss: 0.1150
2023-02-06 16:16:13 | Valid | Epoch[138/200] Iteration[003/008] Valid loss: 0.0977
2023-02-06 16:16:13 | Valid | Epoch[138/200] Iteration[004/008] Valid loss: 0.0939
2023-02-06 16:16:13 | Valid | Epoch[138/200] Iteration[005/008] Valid loss: 0.0955
2023-02-06 16:16:13 | Valid | Epoch[138/200] Iteration[006/008] Valid loss: 0.0971
2023-02-06 16:16:13 | Valid | Epoch[138/200] Iteration[007/008] Valid loss: 0.1014
2023-02-06 16:16:13 | Valid | Epoch[138/200] Iteration[008/008] Valid loss: 0.0987
2023-02-06 16:16:13 | Valid | Epoch[138/200] MIou: 0.931808796662803
2023-02-06 16:16:13 | Valid | Epoch[138/200] Pixel Accuracy: 0.9881757100423177
2023-02-06 16:16:13 | Valid | Epoch[138/200] Mean Pixel Accuracy: 0.9616907203693836
2023-02-06 16:16:13 | Stage | Epoch[138/200] Train loss:0.0251
2023-02-06 16:16:13 | Stage | Epoch[138/200] Valid loss:0.0987
2023-02-06 16:16:13 | Stage | Epoch[138/200] LR:0.01

2023-02-06 16:16:14 | Train | Epoch[139/200] Iteration[001/030] Train loss: 0.0241
2023-02-06 16:16:14 | Train | Epoch[139/200] Iteration[002/030] Train loss: 0.0243
2023-02-06 16:16:15 | Train | Epoch[139/200] Iteration[003/030] Train loss: 0.0243
2023-02-06 16:16:15 | Train | Epoch[139/200] Iteration[004/030] Train loss: 0.0242
2023-02-06 16:16:16 | Train | Epoch[139/200] Iteration[005/030] Train loss: 0.0241
2023-02-06 16:16:16 | Train | Epoch[139/200] Iteration[006/030] Train loss: 0.0241
2023-02-06 16:16:16 | Train | Epoch[139/200] Iteration[007/030] Train loss: 0.0241
2023-02-06 16:16:17 | Train | Epoch[139/200] Iteration[008/030] Train loss: 0.0242
2023-02-06 16:16:17 | Train | Epoch[139/200] Iteration[009/030] Train loss: 0.0241
2023-02-06 16:16:18 | Train | Epoch[139/200] Iteration[010/030] Train loss: 0.0241
2023-02-06 16:16:18 | Train | Epoch[139/200] Iteration[011/030] Train loss: 0.0242
2023-02-06 16:16:19 | Train | Epoch[139/200] Iteration[012/030] Train loss: 0.0242
2023-02-06 16:16:19 | Train | Epoch[139/200] Iteration[013/030] Train loss: 0.0241
2023-02-06 16:16:19 | Train | Epoch[139/200] Iteration[014/030] Train loss: 0.0242
2023-02-06 16:16:20 | Train | Epoch[139/200] Iteration[015/030] Train loss: 0.0242
2023-02-06 16:16:20 | Train | Epoch[139/200] Iteration[016/030] Train loss: 0.0241
2023-02-06 16:16:21 | Train | Epoch[139/200] Iteration[017/030] Train loss: 0.0241
2023-02-06 16:16:21 | Train | Epoch[139/200] Iteration[018/030] Train loss: 0.0242
2023-02-06 16:16:22 | Train | Epoch[139/200] Iteration[019/030] Train loss: 0.0242
2023-02-06 16:16:22 | Train | Epoch[139/200] Iteration[020/030] Train loss: 0.0242
2023-02-06 16:16:23 | Train | Epoch[139/200] Iteration[021/030] Train loss: 0.0242
2023-02-06 16:16:23 | Train | Epoch[139/200] Iteration[022/030] Train loss: 0.0243
2023-02-06 16:16:23 | Train | Epoch[139/200] Iteration[023/030] Train loss: 0.0242
2023-02-06 16:16:24 | Train | Epoch[139/200] Iteration[024/030] Train loss: 0.0242
2023-02-06 16:16:24 | Train | Epoch[139/200] Iteration[025/030] Train loss: 0.0242
2023-02-06 16:16:25 | Train | Epoch[139/200] Iteration[026/030] Train loss: 0.0243
2023-02-06 16:16:25 | Train | Epoch[139/200] Iteration[027/030] Train loss: 0.0243
2023-02-06 16:16:26 | Train | Epoch[139/200] Iteration[028/030] Train loss: 0.0243
2023-02-06 16:16:26 | Train | Epoch[139/200] Iteration[029/030] Train loss: 0.0243
2023-02-06 16:16:26 | Train | Epoch[139/200] Iteration[030/030] Train loss: 0.0243
2023-02-06 16:16:27 | Valid | Epoch[139/200] Iteration[001/008] Valid loss: 0.2114
2023-02-06 16:16:27 | Valid | Epoch[139/200] Iteration[002/008] Valid loss: 0.1471
2023-02-06 16:16:27 | Valid | Epoch[139/200] Iteration[003/008] Valid loss: 0.1254
2023-02-06 16:16:27 | Valid | Epoch[139/200] Iteration[004/008] Valid loss: 0.1167
2023-02-06 16:16:27 | Valid | Epoch[139/200] Iteration[005/008] Valid loss: 0.1183
2023-02-06 16:16:27 | Valid | Epoch[139/200] Iteration[006/008] Valid loss: 0.1136
2023-02-06 16:16:27 | Valid | Epoch[139/200] Iteration[007/008] Valid loss: 0.1261
2023-02-06 16:16:27 | Valid | Epoch[139/200] Iteration[008/008] Valid loss: 0.1227
2023-02-06 16:16:27 | Valid | Epoch[139/200] MIou: 0.9331822255848554
2023-02-06 16:16:27 | Valid | Epoch[139/200] Pixel Accuracy: 0.98828125
2023-02-06 16:16:27 | Valid | Epoch[139/200] Mean Pixel Accuracy: 0.9683935437759559
2023-02-06 16:16:27 | Stage | Epoch[139/200] Train loss:0.0243
2023-02-06 16:16:27 | Stage | Epoch[139/200] Valid loss:0.1227
2023-02-06 16:16:27 | Stage | Epoch[139/200] LR:0.01

2023-02-06 16:16:28 | Train | Epoch[140/200] Iteration[001/030] Train loss: 0.0242
2023-02-06 16:16:29 | Train | Epoch[140/200] Iteration[002/030] Train loss: 0.0244
2023-02-06 16:16:29 | Train | Epoch[140/200] Iteration[003/030] Train loss: 0.0243
2023-02-06 16:16:29 | Train | Epoch[140/200] Iteration[004/030] Train loss: 0.0241
2023-02-06 16:16:30 | Train | Epoch[140/200] Iteration[005/030] Train loss: 0.0242
2023-02-06 16:16:30 | Train | Epoch[140/200] Iteration[006/030] Train loss: 0.0240
2023-02-06 16:16:31 | Train | Epoch[140/200] Iteration[007/030] Train loss: 0.0240
2023-02-06 16:16:31 | Train | Epoch[140/200] Iteration[008/030] Train loss: 0.0245
2023-02-06 16:16:32 | Train | Epoch[140/200] Iteration[009/030] Train loss: 0.0244
2023-02-06 16:16:32 | Train | Epoch[140/200] Iteration[010/030] Train loss: 0.0244
2023-02-06 16:16:32 | Train | Epoch[140/200] Iteration[011/030] Train loss: 0.0243
2023-02-06 16:16:33 | Train | Epoch[140/200] Iteration[012/030] Train loss: 0.0244
2023-02-06 16:16:33 | Train | Epoch[140/200] Iteration[013/030] Train loss: 0.0245
2023-02-06 16:16:34 | Train | Epoch[140/200] Iteration[014/030] Train loss: 0.0247
2023-02-06 16:16:34 | Train | Epoch[140/200] Iteration[015/030] Train loss: 0.0247
2023-02-06 16:16:35 | Train | Epoch[140/200] Iteration[016/030] Train loss: 0.0247
2023-02-06 16:16:35 | Train | Epoch[140/200] Iteration[017/030] Train loss: 0.0247
2023-02-06 16:16:35 | Train | Epoch[140/200] Iteration[018/030] Train loss: 0.0247
2023-02-06 16:16:36 | Train | Epoch[140/200] Iteration[019/030] Train loss: 0.0247
2023-02-06 16:16:36 | Train | Epoch[140/200] Iteration[020/030] Train loss: 0.0247
2023-02-06 16:16:37 | Train | Epoch[140/200] Iteration[021/030] Train loss: 0.0246
2023-02-06 16:16:37 | Train | Epoch[140/200] Iteration[022/030] Train loss: 0.0246
2023-02-06 16:16:38 | Train | Epoch[140/200] Iteration[023/030] Train loss: 0.0246
2023-02-06 16:16:38 | Train | Epoch[140/200] Iteration[024/030] Train loss: 0.0245
2023-02-06 16:16:38 | Train | Epoch[140/200] Iteration[025/030] Train loss: 0.0246
2023-02-06 16:16:39 | Train | Epoch[140/200] Iteration[026/030] Train loss: 0.0246
2023-02-06 16:16:39 | Train | Epoch[140/200] Iteration[027/030] Train loss: 0.0246
2023-02-06 16:16:40 | Train | Epoch[140/200] Iteration[028/030] Train loss: 0.0246
2023-02-06 16:16:40 | Train | Epoch[140/200] Iteration[029/030] Train loss: 0.0246
2023-02-06 16:16:40 | Train | Epoch[140/200] Iteration[030/030] Train loss: 0.0245
2023-02-06 16:16:41 | Valid | Epoch[140/200] Iteration[001/008] Valid loss: 0.0911
2023-02-06 16:16:41 | Valid | Epoch[140/200] Iteration[002/008] Valid loss: 0.0754
2023-02-06 16:16:41 | Valid | Epoch[140/200] Iteration[003/008] Valid loss: 0.0725
2023-02-06 16:16:41 | Valid | Epoch[140/200] Iteration[004/008] Valid loss: 0.0722
2023-02-06 16:16:41 | Valid | Epoch[140/200] Iteration[005/008] Valid loss: 0.0712
2023-02-06 16:16:41 | Valid | Epoch[140/200] Iteration[006/008] Valid loss: 0.0709
2023-02-06 16:16:41 | Valid | Epoch[140/200] Iteration[007/008] Valid loss: 0.0711
2023-02-06 16:16:42 | Valid | Epoch[140/200] Iteration[008/008] Valid loss: 0.0710
2023-02-06 16:16:42 | Valid | Epoch[140/200] MIou: 0.850589968217162
2023-02-06 16:16:42 | Valid | Epoch[140/200] Pixel Accuracy: 0.9749234517415365
2023-02-06 16:16:42 | Valid | Epoch[140/200] Mean Pixel Accuracy: 0.8706300639230172
2023-02-06 16:16:42 | Stage | Epoch[140/200] Train loss:0.0245
2023-02-06 16:16:42 | Stage | Epoch[140/200] Valid loss:0.0710
2023-02-06 16:16:42 | Stage | Epoch[140/200] LR:0.01

2023-02-06 16:16:42 | Train | Epoch[141/200] Iteration[001/030] Train loss: 0.0240
2023-02-06 16:16:43 | Train | Epoch[141/200] Iteration[002/030] Train loss: 0.0243
2023-02-06 16:16:43 | Train | Epoch[141/200] Iteration[003/030] Train loss: 0.0241
2023-02-06 16:16:44 | Train | Epoch[141/200] Iteration[004/030] Train loss: 0.0246
2023-02-06 16:16:44 | Train | Epoch[141/200] Iteration[005/030] Train loss: 0.0245
2023-02-06 16:16:45 | Train | Epoch[141/200] Iteration[006/030] Train loss: 0.0246
2023-02-06 16:16:45 | Train | Epoch[141/200] Iteration[007/030] Train loss: 0.0246
2023-02-06 16:16:46 | Train | Epoch[141/200] Iteration[008/030] Train loss: 0.0246
2023-02-06 16:16:46 | Train | Epoch[141/200] Iteration[009/030] Train loss: 0.0246
2023-02-06 16:16:46 | Train | Epoch[141/200] Iteration[010/030] Train loss: 0.0248
2023-02-06 16:16:47 | Train | Epoch[141/200] Iteration[011/030] Train loss: 0.0247
2023-02-06 16:16:47 | Train | Epoch[141/200] Iteration[012/030] Train loss: 0.0246
2023-02-06 16:16:48 | Train | Epoch[141/200] Iteration[013/030] Train loss: 0.0246
2023-02-06 16:16:48 | Train | Epoch[141/200] Iteration[014/030] Train loss: 0.0246
2023-02-06 16:16:49 | Train | Epoch[141/200] Iteration[015/030] Train loss: 0.0246
2023-02-06 16:16:49 | Train | Epoch[141/200] Iteration[016/030] Train loss: 0.0245
2023-02-06 16:16:49 | Train | Epoch[141/200] Iteration[017/030] Train loss: 0.0244
2023-02-06 16:16:50 | Train | Epoch[141/200] Iteration[018/030] Train loss: 0.0244
2023-02-06 16:16:50 | Train | Epoch[141/200] Iteration[019/030] Train loss: 0.0244
2023-02-06 16:16:51 | Train | Epoch[141/200] Iteration[020/030] Train loss: 0.0244
2023-02-06 16:16:51 | Train | Epoch[141/200] Iteration[021/030] Train loss: 0.0243
2023-02-06 16:16:52 | Train | Epoch[141/200] Iteration[022/030] Train loss: 0.0243
2023-02-06 16:16:52 | Train | Epoch[141/200] Iteration[023/030] Train loss: 0.0243
2023-02-06 16:16:52 | Train | Epoch[141/200] Iteration[024/030] Train loss: 0.0243
2023-02-06 16:16:53 | Train | Epoch[141/200] Iteration[025/030] Train loss: 0.0243
2023-02-06 16:16:53 | Train | Epoch[141/200] Iteration[026/030] Train loss: 0.0243
2023-02-06 16:16:54 | Train | Epoch[141/200] Iteration[027/030] Train loss: 0.0243
2023-02-06 16:16:54 | Train | Epoch[141/200] Iteration[028/030] Train loss: 0.0243
2023-02-06 16:16:55 | Train | Epoch[141/200] Iteration[029/030] Train loss: 0.0243
2023-02-06 16:16:55 | Train | Epoch[141/200] Iteration[030/030] Train loss: 0.0243
2023-02-06 16:16:55 | Valid | Epoch[141/200] Iteration[001/008] Valid loss: 0.0773
2023-02-06 16:16:55 | Valid | Epoch[141/200] Iteration[002/008] Valid loss: 0.0691
2023-02-06 16:16:55 | Valid | Epoch[141/200] Iteration[003/008] Valid loss: 0.0649
2023-02-06 16:16:56 | Valid | Epoch[141/200] Iteration[004/008] Valid loss: 0.0622
2023-02-06 16:16:56 | Valid | Epoch[141/200] Iteration[005/008] Valid loss: 0.0625
2023-02-06 16:16:56 | Valid | Epoch[141/200] Iteration[006/008] Valid loss: 0.0609
2023-02-06 16:16:56 | Valid | Epoch[141/200] Iteration[007/008] Valid loss: 0.0619
2023-02-06 16:16:56 | Valid | Epoch[141/200] Iteration[008/008] Valid loss: 0.0618
2023-02-06 16:16:56 | Valid | Epoch[141/200] MIou: 0.8748447703671121
2023-02-06 16:16:56 | Valid | Epoch[141/200] Pixel Accuracy: 0.9790967305501302
2023-02-06 16:16:56 | Valid | Epoch[141/200] Mean Pixel Accuracy: 0.8914507337005539
2023-02-06 16:16:56 | Stage | Epoch[141/200] Train loss:0.0243
2023-02-06 16:16:56 | Stage | Epoch[141/200] Valid loss:0.0618
2023-02-06 16:16:56 | Stage | Epoch[141/200] LR:0.01

2023-02-06 16:16:57 | Train | Epoch[142/200] Iteration[001/030] Train loss: 0.0242
2023-02-06 16:16:57 | Train | Epoch[142/200] Iteration[002/030] Train loss: 0.0237
2023-02-06 16:16:58 | Train | Epoch[142/200] Iteration[003/030] Train loss: 0.0238
2023-02-06 16:16:58 | Train | Epoch[142/200] Iteration[004/030] Train loss: 0.0236
2023-02-06 16:16:59 | Train | Epoch[142/200] Iteration[005/030] Train loss: 0.0236
2023-02-06 16:16:59 | Train | Epoch[142/200] Iteration[006/030] Train loss: 0.0236
2023-02-06 16:16:59 | Train | Epoch[142/200] Iteration[007/030] Train loss: 0.0235
2023-02-06 16:17:00 | Train | Epoch[142/200] Iteration[008/030] Train loss: 0.0237
2023-02-06 16:17:00 | Train | Epoch[142/200] Iteration[009/030] Train loss: 0.0237
2023-02-06 16:17:01 | Train | Epoch[142/200] Iteration[010/030] Train loss: 0.0236
2023-02-06 16:17:01 | Train | Epoch[142/200] Iteration[011/030] Train loss: 0.0235
2023-02-06 16:17:02 | Train | Epoch[142/200] Iteration[012/030] Train loss: 0.0236
2023-02-06 16:17:02 | Train | Epoch[142/200] Iteration[013/030] Train loss: 0.0237
2023-02-06 16:17:02 | Train | Epoch[142/200] Iteration[014/030] Train loss: 0.0237
2023-02-06 16:17:03 | Train | Epoch[142/200] Iteration[015/030] Train loss: 0.0237
2023-02-06 16:17:03 | Train | Epoch[142/200] Iteration[016/030] Train loss: 0.0238
2023-02-06 16:17:04 | Train | Epoch[142/200] Iteration[017/030] Train loss: 0.0238
2023-02-06 16:17:04 | Train | Epoch[142/200] Iteration[018/030] Train loss: 0.0238
2023-02-06 16:17:05 | Train | Epoch[142/200] Iteration[019/030] Train loss: 0.0237
2023-02-06 16:17:05 | Train | Epoch[142/200] Iteration[020/030] Train loss: 0.0237
2023-02-06 16:17:05 | Train | Epoch[142/200] Iteration[021/030] Train loss: 0.0238
2023-02-06 16:17:06 | Train | Epoch[142/200] Iteration[022/030] Train loss: 0.0238
2023-02-06 16:17:06 | Train | Epoch[142/200] Iteration[023/030] Train loss: 0.0238
2023-02-06 16:17:07 | Train | Epoch[142/200] Iteration[024/030] Train loss: 0.0238
2023-02-06 16:17:07 | Train | Epoch[142/200] Iteration[025/030] Train loss: 0.0238
2023-02-06 16:17:08 | Train | Epoch[142/200] Iteration[026/030] Train loss: 0.0237
2023-02-06 16:17:08 | Train | Epoch[142/200] Iteration[027/030] Train loss: 0.0237
2023-02-06 16:17:08 | Train | Epoch[142/200] Iteration[028/030] Train loss: 0.0237
2023-02-06 16:17:09 | Train | Epoch[142/200] Iteration[029/030] Train loss: 0.0237
2023-02-06 16:17:09 | Train | Epoch[142/200] Iteration[030/030] Train loss: 0.0238
2023-02-06 16:17:10 | Valid | Epoch[142/200] Iteration[001/008] Valid loss: 0.2485
2023-02-06 16:17:10 | Valid | Epoch[142/200] Iteration[002/008] Valid loss: 0.2005
2023-02-06 16:17:10 | Valid | Epoch[142/200] Iteration[003/008] Valid loss: 0.1816
2023-02-06 16:17:10 | Valid | Epoch[142/200] Iteration[004/008] Valid loss: 0.1775
2023-02-06 16:17:10 | Valid | Epoch[142/200] Iteration[005/008] Valid loss: 0.1848
2023-02-06 16:17:10 | Valid | Epoch[142/200] Iteration[006/008] Valid loss: 0.1723
2023-02-06 16:17:10 | Valid | Epoch[142/200] Iteration[007/008] Valid loss: 0.1881
2023-02-06 16:17:10 | Valid | Epoch[142/200] Iteration[008/008] Valid loss: 0.1954
2023-02-06 16:17:10 | Valid | Epoch[142/200] MIou: 0.9186258287378068
2023-02-06 16:17:10 | Valid | Epoch[142/200] Pixel Accuracy: 0.985137939453125
2023-02-06 16:17:10 | Valid | Epoch[142/200] Mean Pixel Accuracy: 0.9732979794420764
2023-02-06 16:17:10 | Stage | Epoch[142/200] Train loss:0.0238
2023-02-06 16:17:10 | Stage | Epoch[142/200] Valid loss:0.1954
2023-02-06 16:17:10 | Stage | Epoch[142/200] LR:0.01

2023-02-06 16:17:11 | Train | Epoch[143/200] Iteration[001/030] Train loss: 0.0227
2023-02-06 16:17:11 | Train | Epoch[143/200] Iteration[002/030] Train loss: 0.0228
2023-02-06 16:17:12 | Train | Epoch[143/200] Iteration[003/030] Train loss: 0.0228
2023-02-06 16:17:12 | Train | Epoch[143/200] Iteration[004/030] Train loss: 0.0230
2023-02-06 16:17:13 | Train | Epoch[143/200] Iteration[005/030] Train loss: 0.0232
2023-02-06 16:17:13 | Train | Epoch[143/200] Iteration[006/030] Train loss: 0.0232
2023-02-06 16:17:14 | Train | Epoch[143/200] Iteration[007/030] Train loss: 0.0232
2023-02-06 16:17:14 | Train | Epoch[143/200] Iteration[008/030] Train loss: 0.0231
2023-02-06 16:17:14 | Train | Epoch[143/200] Iteration[009/030] Train loss: 0.0231
2023-02-06 16:17:15 | Train | Epoch[143/200] Iteration[010/030] Train loss: 0.0230
2023-02-06 16:17:15 | Train | Epoch[143/200] Iteration[011/030] Train loss: 0.0231
2023-02-06 16:17:16 | Train | Epoch[143/200] Iteration[012/030] Train loss: 0.0231
2023-02-06 16:17:16 | Train | Epoch[143/200] Iteration[013/030] Train loss: 0.0231
2023-02-06 16:17:17 | Train | Epoch[143/200] Iteration[014/030] Train loss: 0.0231
2023-02-06 16:17:17 | Train | Epoch[143/200] Iteration[015/030] Train loss: 0.0233
2023-02-06 16:17:17 | Train | Epoch[143/200] Iteration[016/030] Train loss: 0.0235
2023-02-06 16:17:18 | Train | Epoch[143/200] Iteration[017/030] Train loss: 0.0235
2023-02-06 16:17:18 | Train | Epoch[143/200] Iteration[018/030] Train loss: 0.0235
2023-02-06 16:17:19 | Train | Epoch[143/200] Iteration[019/030] Train loss: 0.0235
2023-02-06 16:17:19 | Train | Epoch[143/200] Iteration[020/030] Train loss: 0.0237
2023-02-06 16:17:20 | Train | Epoch[143/200] Iteration[021/030] Train loss: 0.0236
2023-02-06 16:17:20 | Train | Epoch[143/200] Iteration[022/030] Train loss: 0.0237
2023-02-06 16:17:21 | Train | Epoch[143/200] Iteration[023/030] Train loss: 0.0237
2023-02-06 16:17:21 | Train | Epoch[143/200] Iteration[024/030] Train loss: 0.0237
2023-02-06 16:17:21 | Train | Epoch[143/200] Iteration[025/030] Train loss: 0.0237
2023-02-06 16:17:22 | Train | Epoch[143/200] Iteration[026/030] Train loss: 0.0237
2023-02-06 16:17:22 | Train | Epoch[143/200] Iteration[027/030] Train loss: 0.0237
2023-02-06 16:17:23 | Train | Epoch[143/200] Iteration[028/030] Train loss: 0.0237
2023-02-06 16:17:23 | Train | Epoch[143/200] Iteration[029/030] Train loss: 0.0237
2023-02-06 16:17:23 | Train | Epoch[143/200] Iteration[030/030] Train loss: 0.0237
2023-02-06 16:17:24 | Valid | Epoch[143/200] Iteration[001/008] Valid loss: 0.6474
2023-02-06 16:17:24 | Valid | Epoch[143/200] Iteration[002/008] Valid loss: 0.6459
2023-02-06 16:17:24 | Valid | Epoch[143/200] Iteration[003/008] Valid loss: 0.6392
2023-02-06 16:17:24 | Valid | Epoch[143/200] Iteration[004/008] Valid loss: 0.6418
2023-02-06 16:17:24 | Valid | Epoch[143/200] Iteration[005/008] Valid loss: 0.6647
2023-02-06 16:17:24 | Valid | Epoch[143/200] Iteration[006/008] Valid loss: 0.6443
2023-02-06 16:17:24 | Valid | Epoch[143/200] Iteration[007/008] Valid loss: 0.6829
2023-02-06 16:17:24 | Valid | Epoch[143/200] Iteration[008/008] Valid loss: 0.6907
2023-02-06 16:17:24 | Valid | Epoch[143/200] MIou: 0.866791327388927
2023-02-06 16:17:24 | Valid | Epoch[143/200] Pixel Accuracy: 0.9724349975585938
2023-02-06 16:17:24 | Valid | Epoch[143/200] Mean Pixel Accuracy: 0.979072929491778
2023-02-06 16:17:24 | Stage | Epoch[143/200] Train loss:0.0237
2023-02-06 16:17:24 | Stage | Epoch[143/200] Valid loss:0.6907
2023-02-06 16:17:24 | Stage | Epoch[143/200] LR:0.01

2023-02-06 16:17:25 | Train | Epoch[144/200] Iteration[001/030] Train loss: 0.0240
2023-02-06 16:17:26 | Train | Epoch[144/200] Iteration[002/030] Train loss: 0.0236
2023-02-06 16:17:26 | Train | Epoch[144/200] Iteration[003/030] Train loss: 0.0239
2023-02-06 16:17:26 | Train | Epoch[144/200] Iteration[004/030] Train loss: 0.0241
2023-02-06 16:17:27 | Train | Epoch[144/200] Iteration[005/030] Train loss: 0.0237
2023-02-06 16:17:27 | Train | Epoch[144/200] Iteration[006/030] Train loss: 0.0236
2023-02-06 16:17:28 | Train | Epoch[144/200] Iteration[007/030] Train loss: 0.0235
2023-02-06 16:17:28 | Train | Epoch[144/200] Iteration[008/030] Train loss: 0.0239
2023-02-06 16:17:29 | Train | Epoch[144/200] Iteration[009/030] Train loss: 0.0238
2023-02-06 16:17:29 | Train | Epoch[144/200] Iteration[010/030] Train loss: 0.0238
2023-02-06 16:17:30 | Train | Epoch[144/200] Iteration[011/030] Train loss: 0.0239
2023-02-06 16:17:30 | Train | Epoch[144/200] Iteration[012/030] Train loss: 0.0238
2023-02-06 16:17:30 | Train | Epoch[144/200] Iteration[013/030] Train loss: 0.0237
2023-02-06 16:17:31 | Train | Epoch[144/200] Iteration[014/030] Train loss: 0.0237
2023-02-06 16:17:31 | Train | Epoch[144/200] Iteration[015/030] Train loss: 0.0236
2023-02-06 16:17:32 | Train | Epoch[144/200] Iteration[016/030] Train loss: 0.0236
2023-02-06 16:17:32 | Train | Epoch[144/200] Iteration[017/030] Train loss: 0.0236
2023-02-06 16:17:33 | Train | Epoch[144/200] Iteration[018/030] Train loss: 0.0235
2023-02-06 16:17:33 | Train | Epoch[144/200] Iteration[019/030] Train loss: 0.0236
2023-02-06 16:17:33 | Train | Epoch[144/200] Iteration[020/030] Train loss: 0.0236
2023-02-06 16:17:34 | Train | Epoch[144/200] Iteration[021/030] Train loss: 0.0236
2023-02-06 16:17:34 | Train | Epoch[144/200] Iteration[022/030] Train loss: 0.0236
2023-02-06 16:17:35 | Train | Epoch[144/200] Iteration[023/030] Train loss: 0.0235
2023-02-06 16:17:35 | Train | Epoch[144/200] Iteration[024/030] Train loss: 0.0236
2023-02-06 16:17:36 | Train | Epoch[144/200] Iteration[025/030] Train loss: 0.0236
2023-02-06 16:17:36 | Train | Epoch[144/200] Iteration[026/030] Train loss: 0.0236
2023-02-06 16:17:36 | Train | Epoch[144/200] Iteration[027/030] Train loss: 0.0237
2023-02-06 16:17:37 | Train | Epoch[144/200] Iteration[028/030] Train loss: 0.0237
2023-02-06 16:17:37 | Train | Epoch[144/200] Iteration[029/030] Train loss: 0.0237
2023-02-06 16:17:37 | Train | Epoch[144/200] Iteration[030/030] Train loss: 0.0237
2023-02-06 16:17:38 | Valid | Epoch[144/200] Iteration[001/008] Valid loss: 0.0896
2023-02-06 16:17:38 | Valid | Epoch[144/200] Iteration[002/008] Valid loss: 0.0817
2023-02-06 16:17:38 | Valid | Epoch[144/200] Iteration[003/008] Valid loss: 0.0829
2023-02-06 16:17:38 | Valid | Epoch[144/200] Iteration[004/008] Valid loss: 0.0812
2023-02-06 16:17:38 | Valid | Epoch[144/200] Iteration[005/008] Valid loss: 0.0828
2023-02-06 16:17:38 | Valid | Epoch[144/200] Iteration[006/008] Valid loss: 0.0817
2023-02-06 16:17:38 | Valid | Epoch[144/200] Iteration[007/008] Valid loss: 0.0804
2023-02-06 16:17:39 | Valid | Epoch[144/200] Iteration[008/008] Valid loss: 0.0821
2023-02-06 16:17:39 | Valid | Epoch[144/200] MIou: 0.7808706260538332
2023-02-06 16:17:39 | Valid | Epoch[144/200] Pixel Accuracy: 0.9637158711751302
2023-02-06 16:17:39 | Valid | Epoch[144/200] Mean Pixel Accuracy: 0.8012173558474618
2023-02-06 16:17:39 | Stage | Epoch[144/200] Train loss:0.0237
2023-02-06 16:17:39 | Stage | Epoch[144/200] Valid loss:0.0821
2023-02-06 16:17:39 | Stage | Epoch[144/200] LR:0.01

2023-02-06 16:17:39 | Train | Epoch[145/200] Iteration[001/030] Train loss: 0.0226
2023-02-06 16:17:40 | Train | Epoch[145/200] Iteration[002/030] Train loss: 0.0228
2023-02-06 16:17:40 | Train | Epoch[145/200] Iteration[003/030] Train loss: 0.0232
2023-02-06 16:17:41 | Train | Epoch[145/200] Iteration[004/030] Train loss: 0.0230
2023-02-06 16:17:41 | Train | Epoch[145/200] Iteration[005/030] Train loss: 0.0231
2023-02-06 16:17:42 | Train | Epoch[145/200] Iteration[006/030] Train loss: 0.0229
2023-02-06 16:17:42 | Train | Epoch[145/200] Iteration[007/030] Train loss: 0.0228
2023-02-06 16:17:42 | Train | Epoch[145/200] Iteration[008/030] Train loss: 0.0228
2023-02-06 16:17:43 | Train | Epoch[145/200] Iteration[009/030] Train loss: 0.0228
2023-02-06 16:17:43 | Train | Epoch[145/200] Iteration[010/030] Train loss: 0.0228
2023-02-06 16:17:44 | Train | Epoch[145/200] Iteration[011/030] Train loss: 0.0230
2023-02-06 16:17:44 | Train | Epoch[145/200] Iteration[012/030] Train loss: 0.0231
2023-02-06 16:17:45 | Train | Epoch[145/200] Iteration[013/030] Train loss: 0.0231
2023-02-06 16:17:45 | Train | Epoch[145/200] Iteration[014/030] Train loss: 0.0232
2023-02-06 16:17:45 | Train | Epoch[145/200] Iteration[015/030] Train loss: 0.0232
2023-02-06 16:17:46 | Train | Epoch[145/200] Iteration[016/030] Train loss: 0.0232
2023-02-06 16:17:46 | Train | Epoch[145/200] Iteration[017/030] Train loss: 0.0232
2023-02-06 16:17:47 | Train | Epoch[145/200] Iteration[018/030] Train loss: 0.0232
2023-02-06 16:17:47 | Train | Epoch[145/200] Iteration[019/030] Train loss: 0.0232
2023-02-06 16:17:48 | Train | Epoch[145/200] Iteration[020/030] Train loss: 0.0232
2023-02-06 16:17:48 | Train | Epoch[145/200] Iteration[021/030] Train loss: 0.0233
2023-02-06 16:17:49 | Train | Epoch[145/200] Iteration[022/030] Train loss: 0.0233
2023-02-06 16:17:49 | Train | Epoch[145/200] Iteration[023/030] Train loss: 0.0233
2023-02-06 16:17:49 | Train | Epoch[145/200] Iteration[024/030] Train loss: 0.0233
2023-02-06 16:17:50 | Train | Epoch[145/200] Iteration[025/030] Train loss: 0.0233
2023-02-06 16:17:50 | Train | Epoch[145/200] Iteration[026/030] Train loss: 0.0233
2023-02-06 16:17:51 | Train | Epoch[145/200] Iteration[027/030] Train loss: 0.0233
2023-02-06 16:17:51 | Train | Epoch[145/200] Iteration[028/030] Train loss: 0.0233
2023-02-06 16:17:52 | Train | Epoch[145/200] Iteration[029/030] Train loss: 0.0233
2023-02-06 16:17:52 | Train | Epoch[145/200] Iteration[030/030] Train loss: 0.0234
2023-02-06 16:17:52 | Valid | Epoch[145/200] Iteration[001/008] Valid loss: 0.0996
2023-02-06 16:17:52 | Valid | Epoch[145/200] Iteration[002/008] Valid loss: 0.0815
2023-02-06 16:17:52 | Valid | Epoch[145/200] Iteration[003/008] Valid loss: 0.0747
2023-02-06 16:17:53 | Valid | Epoch[145/200] Iteration[004/008] Valid loss: 0.0705
2023-02-06 16:17:53 | Valid | Epoch[145/200] Iteration[005/008] Valid loss: 0.0701
2023-02-06 16:17:53 | Valid | Epoch[145/200] Iteration[006/008] Valid loss: 0.0685
2023-02-06 16:17:53 | Valid | Epoch[145/200] Iteration[007/008] Valid loss: 0.0712
2023-02-06 16:17:53 | Valid | Epoch[145/200] Iteration[008/008] Valid loss: 0.0706
2023-02-06 16:17:53 | Valid | Epoch[145/200] MIou: 0.9142420398408382
2023-02-06 16:17:53 | Valid | Epoch[145/200] Pixel Accuracy: 0.9853846232096354
2023-02-06 16:17:53 | Valid | Epoch[145/200] Mean Pixel Accuracy: 0.9369695156894913
2023-02-06 16:17:53 | Stage | Epoch[145/200] Train loss:0.0234
2023-02-06 16:17:53 | Stage | Epoch[145/200] Valid loss:0.0706
2023-02-06 16:17:53 | Stage | Epoch[145/200] LR:0.01

2023-02-06 16:17:54 | Train | Epoch[146/200] Iteration[001/030] Train loss: 0.0229
2023-02-06 16:17:54 | Train | Epoch[146/200] Iteration[002/030] Train loss: 0.0223
2023-02-06 16:17:55 | Train | Epoch[146/200] Iteration[003/030] Train loss: 0.0220
2023-02-06 16:17:55 | Train | Epoch[146/200] Iteration[004/030] Train loss: 0.0225
2023-02-06 16:17:56 | Train | Epoch[146/200] Iteration[005/030] Train loss: 0.0223
2023-02-06 16:17:56 | Train | Epoch[146/200] Iteration[006/030] Train loss: 0.0223
2023-02-06 16:17:56 | Train | Epoch[146/200] Iteration[007/030] Train loss: 0.0224
2023-02-06 16:17:57 | Train | Epoch[146/200] Iteration[008/030] Train loss: 0.0226
2023-02-06 16:17:57 | Train | Epoch[146/200] Iteration[009/030] Train loss: 0.0226
2023-02-06 16:17:58 | Train | Epoch[146/200] Iteration[010/030] Train loss: 0.0227
2023-02-06 16:17:58 | Train | Epoch[146/200] Iteration[011/030] Train loss: 0.0227
2023-02-06 16:17:59 | Train | Epoch[146/200] Iteration[012/030] Train loss: 0.0228
2023-02-06 16:17:59 | Train | Epoch[146/200] Iteration[013/030] Train loss: 0.0228
2023-02-06 16:17:59 | Train | Epoch[146/200] Iteration[014/030] Train loss: 0.0228
2023-02-06 16:18:00 | Train | Epoch[146/200] Iteration[015/030] Train loss: 0.0227
2023-02-06 16:18:00 | Train | Epoch[146/200] Iteration[016/030] Train loss: 0.0227
2023-02-06 16:18:01 | Train | Epoch[146/200] Iteration[017/030] Train loss: 0.0227
2023-02-06 16:18:01 | Train | Epoch[146/200] Iteration[018/030] Train loss: 0.0227
2023-02-06 16:18:02 | Train | Epoch[146/200] Iteration[019/030] Train loss: 0.0226
2023-02-06 16:18:02 | Train | Epoch[146/200] Iteration[020/030] Train loss: 0.0226
2023-02-06 16:18:02 | Train | Epoch[146/200] Iteration[021/030] Train loss: 0.0226
2023-02-06 16:18:03 | Train | Epoch[146/200] Iteration[022/030] Train loss: 0.0226
2023-02-06 16:18:03 | Train | Epoch[146/200] Iteration[023/030] Train loss: 0.0226
2023-02-06 16:18:04 | Train | Epoch[146/200] Iteration[024/030] Train loss: 0.0226
2023-02-06 16:18:04 | Train | Epoch[146/200] Iteration[025/030] Train loss: 0.0226
2023-02-06 16:18:05 | Train | Epoch[146/200] Iteration[026/030] Train loss: 0.0226
2023-02-06 16:18:05 | Train | Epoch[146/200] Iteration[027/030] Train loss: 0.0226
2023-02-06 16:18:06 | Train | Epoch[146/200] Iteration[028/030] Train loss: 0.0226
2023-02-06 16:18:06 | Train | Epoch[146/200] Iteration[029/030] Train loss: 0.0226
2023-02-06 16:18:06 | Train | Epoch[146/200] Iteration[030/030] Train loss: 0.0227
2023-02-06 16:18:07 | Valid | Epoch[146/200] Iteration[001/008] Valid loss: 0.1686
2023-02-06 16:18:07 | Valid | Epoch[146/200] Iteration[002/008] Valid loss: 0.1409
2023-02-06 16:18:07 | Valid | Epoch[146/200] Iteration[003/008] Valid loss: 0.1227
2023-02-06 16:18:07 | Valid | Epoch[146/200] Iteration[004/008] Valid loss: 0.1198
2023-02-06 16:18:07 | Valid | Epoch[146/200] Iteration[005/008] Valid loss: 0.1184
2023-02-06 16:18:07 | Valid | Epoch[146/200] Iteration[006/008] Valid loss: 0.1172
2023-02-06 16:18:07 | Valid | Epoch[146/200] Iteration[007/008] Valid loss: 0.1239
2023-02-06 16:18:07 | Valid | Epoch[146/200] Iteration[008/008] Valid loss: 0.1260
2023-02-06 16:18:07 | Valid | Epoch[146/200] MIou: 0.924135846472826
2023-02-06 16:18:07 | Valid | Epoch[146/200] Pixel Accuracy: 0.9864896138509115
2023-02-06 16:18:07 | Valid | Epoch[146/200] Mean Pixel Accuracy: 0.9667240132136785
2023-02-06 16:18:07 | Stage | Epoch[146/200] Train loss:0.0227
2023-02-06 16:18:07 | Stage | Epoch[146/200] Valid loss:0.1260
2023-02-06 16:18:07 | Stage | Epoch[146/200] LR:0.01

2023-02-06 16:18:08 | Train | Epoch[147/200] Iteration[001/030] Train loss: 0.0216
2023-02-06 16:18:09 | Train | Epoch[147/200] Iteration[002/030] Train loss: 0.0219
2023-02-06 16:18:09 | Train | Epoch[147/200] Iteration[003/030] Train loss: 0.0216
2023-02-06 16:18:09 | Train | Epoch[147/200] Iteration[004/030] Train loss: 0.0216
2023-02-06 16:18:10 | Train | Epoch[147/200] Iteration[005/030] Train loss: 0.0215
2023-02-06 16:18:10 | Train | Epoch[147/200] Iteration[006/030] Train loss: 0.0227
2023-02-06 16:18:11 | Train | Epoch[147/200] Iteration[007/030] Train loss: 0.0230
2023-02-06 16:18:11 | Train | Epoch[147/200] Iteration[008/030] Train loss: 0.0229
2023-02-06 16:18:12 | Train | Epoch[147/200] Iteration[009/030] Train loss: 0.0229
2023-02-06 16:18:12 | Train | Epoch[147/200] Iteration[010/030] Train loss: 0.0230
2023-02-06 16:18:12 | Train | Epoch[147/200] Iteration[011/030] Train loss: 0.0232
2023-02-06 16:18:13 | Train | Epoch[147/200] Iteration[012/030] Train loss: 0.0235
2023-02-06 16:18:13 | Train | Epoch[147/200] Iteration[013/030] Train loss: 0.0238
2023-02-06 16:18:14 | Train | Epoch[147/200] Iteration[014/030] Train loss: 0.0238
2023-02-06 16:18:14 | Train | Epoch[147/200] Iteration[015/030] Train loss: 0.0238
2023-02-06 16:18:15 | Train | Epoch[147/200] Iteration[016/030] Train loss: 0.0238
2023-02-06 16:18:15 | Train | Epoch[147/200] Iteration[017/030] Train loss: 0.0238
2023-02-06 16:18:16 | Train | Epoch[147/200] Iteration[018/030] Train loss: 0.0239
2023-02-06 16:18:16 | Train | Epoch[147/200] Iteration[019/030] Train loss: 0.0238
2023-02-06 16:18:16 | Train | Epoch[147/200] Iteration[020/030] Train loss: 0.0238
2023-02-06 16:18:17 | Train | Epoch[147/200] Iteration[021/030] Train loss: 0.0237
2023-02-06 16:18:17 | Train | Epoch[147/200] Iteration[022/030] Train loss: 0.0237
2023-02-06 16:18:18 | Train | Epoch[147/200] Iteration[023/030] Train loss: 0.0236
2023-02-06 16:18:18 | Train | Epoch[147/200] Iteration[024/030] Train loss: 0.0236
2023-02-06 16:18:19 | Train | Epoch[147/200] Iteration[025/030] Train loss: 0.0235
2023-02-06 16:18:19 | Train | Epoch[147/200] Iteration[026/030] Train loss: 0.0235
2023-02-06 16:18:19 | Train | Epoch[147/200] Iteration[027/030] Train loss: 0.0234
2023-02-06 16:18:20 | Train | Epoch[147/200] Iteration[028/030] Train loss: 0.0234
2023-02-06 16:18:20 | Train | Epoch[147/200] Iteration[029/030] Train loss: 0.0234
2023-02-06 16:18:20 | Train | Epoch[147/200] Iteration[030/030] Train loss: 0.0234
2023-02-06 16:18:21 | Valid | Epoch[147/200] Iteration[001/008] Valid loss: 0.0920
2023-02-06 16:18:21 | Valid | Epoch[147/200] Iteration[002/008] Valid loss: 0.0860
2023-02-06 16:18:21 | Valid | Epoch[147/200] Iteration[003/008] Valid loss: 0.0890
2023-02-06 16:18:21 | Valid | Epoch[147/200] Iteration[004/008] Valid loss: 0.0865
2023-02-06 16:18:21 | Valid | Epoch[147/200] Iteration[005/008] Valid loss: 0.0891
2023-02-06 16:18:21 | Valid | Epoch[147/200] Iteration[006/008] Valid loss: 0.0901
2023-02-06 16:18:21 | Valid | Epoch[147/200] Iteration[007/008] Valid loss: 0.0885
2023-02-06 16:18:22 | Valid | Epoch[147/200] Iteration[008/008] Valid loss: 0.0915
2023-02-06 16:18:22 | Valid | Epoch[147/200] MIou: 0.7536432219106284
2023-02-06 16:18:22 | Valid | Epoch[147/200] Pixel Accuracy: 0.9590466817220052
2023-02-06 16:18:22 | Valid | Epoch[147/200] Mean Pixel Accuracy: 0.7771250694043996
2023-02-06 16:18:22 | Stage | Epoch[147/200] Train loss:0.0234
2023-02-06 16:18:22 | Stage | Epoch[147/200] Valid loss:0.0915
2023-02-06 16:18:22 | Stage | Epoch[147/200] LR:0.01

2023-02-06 16:18:22 | Train | Epoch[148/200] Iteration[001/030] Train loss: 0.0215
2023-02-06 16:18:23 | Train | Epoch[148/200] Iteration[002/030] Train loss: 0.0221
2023-02-06 16:18:23 | Train | Epoch[148/200] Iteration[003/030] Train loss: 0.0222
2023-02-06 16:18:24 | Train | Epoch[148/200] Iteration[004/030] Train loss: 0.0227
2023-02-06 16:18:24 | Train | Epoch[148/200] Iteration[005/030] Train loss: 0.0225
2023-02-06 16:18:25 | Train | Epoch[148/200] Iteration[006/030] Train loss: 0.0222
2023-02-06 16:18:25 | Train | Epoch[148/200] Iteration[007/030] Train loss: 0.0222
2023-02-06 16:18:25 | Train | Epoch[148/200] Iteration[008/030] Train loss: 0.0224
2023-02-06 16:18:26 | Train | Epoch[148/200] Iteration[009/030] Train loss: 0.0224
2023-02-06 16:18:26 | Train | Epoch[148/200] Iteration[010/030] Train loss: 0.0225
2023-02-06 16:18:27 | Train | Epoch[148/200] Iteration[011/030] Train loss: 0.0225
2023-02-06 16:18:27 | Train | Epoch[148/200] Iteration[012/030] Train loss: 0.0225
2023-02-06 16:18:28 | Train | Epoch[148/200] Iteration[013/030] Train loss: 0.0225
2023-02-06 16:18:28 | Train | Epoch[148/200] Iteration[014/030] Train loss: 0.0225
2023-02-06 16:18:28 | Train | Epoch[148/200] Iteration[015/030] Train loss: 0.0225
2023-02-06 16:18:29 | Train | Epoch[148/200] Iteration[016/030] Train loss: 0.0224
2023-02-06 16:18:29 | Train | Epoch[148/200] Iteration[017/030] Train loss: 0.0225
2023-02-06 16:18:30 | Train | Epoch[148/200] Iteration[018/030] Train loss: 0.0225
2023-02-06 16:18:30 | Train | Epoch[148/200] Iteration[019/030] Train loss: 0.0225
2023-02-06 16:18:31 | Train | Epoch[148/200] Iteration[020/030] Train loss: 0.0228
2023-02-06 16:18:31 | Train | Epoch[148/200] Iteration[021/030] Train loss: 0.0228
2023-02-06 16:18:31 | Train | Epoch[148/200] Iteration[022/030] Train loss: 0.0227
2023-02-06 16:18:32 | Train | Epoch[148/200] Iteration[023/030] Train loss: 0.0227
2023-02-06 16:18:32 | Train | Epoch[148/200] Iteration[024/030] Train loss: 0.0227
2023-02-06 16:18:33 | Train | Epoch[148/200] Iteration[025/030] Train loss: 0.0228
2023-02-06 16:18:33 | Train | Epoch[148/200] Iteration[026/030] Train loss: 0.0228
2023-02-06 16:18:34 | Train | Epoch[148/200] Iteration[027/030] Train loss: 0.0228
2023-02-06 16:18:34 | Train | Epoch[148/200] Iteration[028/030] Train loss: 0.0228
2023-02-06 16:18:35 | Train | Epoch[148/200] Iteration[029/030] Train loss: 0.0228
2023-02-06 16:18:35 | Train | Epoch[148/200] Iteration[030/030] Train loss: 0.0228
2023-02-06 16:18:35 | Valid | Epoch[148/200] Iteration[001/008] Valid loss: 0.2649
2023-02-06 16:18:35 | Valid | Epoch[148/200] Iteration[002/008] Valid loss: 0.1940
2023-02-06 16:18:35 | Valid | Epoch[148/200] Iteration[003/008] Valid loss: 0.1767
2023-02-06 16:18:35 | Valid | Epoch[148/200] Iteration[004/008] Valid loss: 0.1680
2023-02-06 16:18:36 | Valid | Epoch[148/200] Iteration[005/008] Valid loss: 0.1734
2023-02-06 16:18:36 | Valid | Epoch[148/200] Iteration[006/008] Valid loss: 0.1710
2023-02-06 16:18:36 | Valid | Epoch[148/200] Iteration[007/008] Valid loss: 0.1832
2023-02-06 16:18:36 | Valid | Epoch[148/200] Iteration[008/008] Valid loss: 0.1766
2023-02-06 16:18:36 | Valid | Epoch[148/200] MIou: 0.9224496894995943
2023-02-06 16:18:36 | Valid | Epoch[148/200] Pixel Accuracy: 0.9860115051269531
2023-02-06 16:18:36 | Valid | Epoch[148/200] Mean Pixel Accuracy: 0.9711595136585982
2023-02-06 16:18:36 | Stage | Epoch[148/200] Train loss:0.0228
2023-02-06 16:18:36 | Stage | Epoch[148/200] Valid loss:0.1766
2023-02-06 16:18:36 | Stage | Epoch[148/200] LR:0.01

2023-02-06 16:18:37 | Train | Epoch[149/200] Iteration[001/030] Train loss: 0.0216
2023-02-06 16:18:37 | Train | Epoch[149/200] Iteration[002/030] Train loss: 0.0218
2023-02-06 16:18:37 | Train | Epoch[149/200] Iteration[003/030] Train loss: 0.0218
2023-02-06 16:18:38 | Train | Epoch[149/200] Iteration[004/030] Train loss: 0.0219
2023-02-06 16:18:38 | Train | Epoch[149/200] Iteration[005/030] Train loss: 0.0219
2023-02-06 16:18:39 | Train | Epoch[149/200] Iteration[006/030] Train loss: 0.0219
2023-02-06 16:18:39 | Train | Epoch[149/200] Iteration[007/030] Train loss: 0.0221
2023-02-06 16:18:40 | Train | Epoch[149/200] Iteration[008/030] Train loss: 0.0221
2023-02-06 16:18:40 | Train | Epoch[149/200] Iteration[009/030] Train loss: 0.0220
2023-02-06 16:18:41 | Train | Epoch[149/200] Iteration[010/030] Train loss: 0.0221
2023-02-06 16:18:41 | Train | Epoch[149/200] Iteration[011/030] Train loss: 0.0221
2023-02-06 16:18:41 | Train | Epoch[149/200] Iteration[012/030] Train loss: 0.0221
2023-02-06 16:18:42 | Train | Epoch[149/200] Iteration[013/030] Train loss: 0.0220
2023-02-06 16:18:42 | Train | Epoch[149/200] Iteration[014/030] Train loss: 0.0222
2023-02-06 16:18:43 | Train | Epoch[149/200] Iteration[015/030] Train loss: 0.0221
2023-02-06 16:18:43 | Train | Epoch[149/200] Iteration[016/030] Train loss: 0.0222
2023-02-06 16:18:44 | Train | Epoch[149/200] Iteration[017/030] Train loss: 0.0222
2023-02-06 16:18:44 | Train | Epoch[149/200] Iteration[018/030] Train loss: 0.0222
2023-02-06 16:18:44 | Train | Epoch[149/200] Iteration[019/030] Train loss: 0.0224
2023-02-06 16:18:45 | Train | Epoch[149/200] Iteration[020/030] Train loss: 0.0224
2023-02-06 16:18:45 | Train | Epoch[149/200] Iteration[021/030] Train loss: 0.0224
2023-02-06 16:18:46 | Train | Epoch[149/200] Iteration[022/030] Train loss: 0.0224
2023-02-06 16:18:46 | Train | Epoch[149/200] Iteration[023/030] Train loss: 0.0226
2023-02-06 16:18:47 | Train | Epoch[149/200] Iteration[024/030] Train loss: 0.0226
2023-02-06 16:18:47 | Train | Epoch[149/200] Iteration[025/030] Train loss: 0.0226
2023-02-06 16:18:47 | Train | Epoch[149/200] Iteration[026/030] Train loss: 0.0226
2023-02-06 16:18:48 | Train | Epoch[149/200] Iteration[027/030] Train loss: 0.0226
2023-02-06 16:18:48 | Train | Epoch[149/200] Iteration[028/030] Train loss: 0.0225
2023-02-06 16:18:49 | Train | Epoch[149/200] Iteration[029/030] Train loss: 0.0225
2023-02-06 16:18:49 | Train | Epoch[149/200] Iteration[030/030] Train loss: 0.0225
2023-02-06 16:18:49 | Valid | Epoch[149/200] Iteration[001/008] Valid loss: 0.4193
2023-02-06 16:18:49 | Valid | Epoch[149/200] Iteration[002/008] Valid loss: 0.3381
2023-02-06 16:18:50 | Valid | Epoch[149/200] Iteration[003/008] Valid loss: 0.3018
2023-02-06 16:18:50 | Valid | Epoch[149/200] Iteration[004/008] Valid loss: 0.3010
2023-02-06 16:18:50 | Valid | Epoch[149/200] Iteration[005/008] Valid loss: 0.3090
2023-02-06 16:18:50 | Valid | Epoch[149/200] Iteration[006/008] Valid loss: 0.3065
2023-02-06 16:18:50 | Valid | Epoch[149/200] Iteration[007/008] Valid loss: 0.3290
2023-02-06 16:18:50 | Valid | Epoch[149/200] Iteration[008/008] Valid loss: 0.3313
2023-02-06 16:18:50 | Valid | Epoch[149/200] MIou: 0.9078479659972866
2023-02-06 16:18:50 | Valid | Epoch[149/200] Pixel Accuracy: 0.982611338297526
2023-02-06 16:18:50 | Valid | Epoch[149/200] Mean Pixel Accuracy: 0.9781038923573281
2023-02-06 16:18:50 | Stage | Epoch[149/200] Train loss:0.0225
2023-02-06 16:18:50 | Stage | Epoch[149/200] Valid loss:0.3313
2023-02-06 16:18:50 | Stage | Epoch[149/200] LR:0.01

2023-02-06 16:18:51 | Train | Epoch[150/200] Iteration[001/030] Train loss: 0.0218
2023-02-06 16:18:51 | Train | Epoch[150/200] Iteration[002/030] Train loss: 0.0218
2023-02-06 16:18:52 | Train | Epoch[150/200] Iteration[003/030] Train loss: 0.0216
2023-02-06 16:18:52 | Train | Epoch[150/200] Iteration[004/030] Train loss: 0.0217
2023-02-06 16:18:53 | Train | Epoch[150/200] Iteration[005/030] Train loss: 0.0217
2023-02-06 16:18:53 | Train | Epoch[150/200] Iteration[006/030] Train loss: 0.0218
2023-02-06 16:18:54 | Train | Epoch[150/200] Iteration[007/030] Train loss: 0.0218
2023-02-06 16:18:54 | Train | Epoch[150/200] Iteration[008/030] Train loss: 0.0217
2023-02-06 16:18:54 | Train | Epoch[150/200] Iteration[009/030] Train loss: 0.0217
2023-02-06 16:18:55 | Train | Epoch[150/200] Iteration[010/030] Train loss: 0.0217
2023-02-06 16:18:55 | Train | Epoch[150/200] Iteration[011/030] Train loss: 0.0216
2023-02-06 16:18:56 | Train | Epoch[150/200] Iteration[012/030] Train loss: 0.0216
2023-02-06 16:18:56 | Train | Epoch[150/200] Iteration[013/030] Train loss: 0.0216
2023-02-06 16:18:57 | Train | Epoch[150/200] Iteration[014/030] Train loss: 0.0216
2023-02-06 16:18:57 | Train | Epoch[150/200] Iteration[015/030] Train loss: 0.0216
2023-02-06 16:18:57 | Train | Epoch[150/200] Iteration[016/030] Train loss: 0.0217
2023-02-06 16:18:58 | Train | Epoch[150/200] Iteration[017/030] Train loss: 0.0218
2023-02-06 16:18:58 | Train | Epoch[150/200] Iteration[018/030] Train loss: 0.0217
2023-02-06 16:18:59 | Train | Epoch[150/200] Iteration[019/030] Train loss: 0.0217
2023-02-06 16:18:59 | Train | Epoch[150/200] Iteration[020/030] Train loss: 0.0218
2023-02-06 16:19:00 | Train | Epoch[150/200] Iteration[021/030] Train loss: 0.0217
2023-02-06 16:19:00 | Train | Epoch[150/200] Iteration[022/030] Train loss: 0.0217
2023-02-06 16:19:00 | Train | Epoch[150/200] Iteration[023/030] Train loss: 0.0218
2023-02-06 16:19:01 | Train | Epoch[150/200] Iteration[024/030] Train loss: 0.0218
2023-02-06 16:19:01 | Train | Epoch[150/200] Iteration[025/030] Train loss: 0.0218
2023-02-06 16:19:02 | Train | Epoch[150/200] Iteration[026/030] Train loss: 0.0218
2023-02-06 16:19:02 | Train | Epoch[150/200] Iteration[027/030] Train loss: 0.0219
2023-02-06 16:19:03 | Train | Epoch[150/200] Iteration[028/030] Train loss: 0.0218
2023-02-06 16:19:03 | Train | Epoch[150/200] Iteration[029/030] Train loss: 0.0218
2023-02-06 16:19:03 | Train | Epoch[150/200] Iteration[030/030] Train loss: 0.0218
2023-02-06 16:19:04 | Valid | Epoch[150/200] Iteration[001/008] Valid loss: 0.2152
2023-02-06 16:19:04 | Valid | Epoch[150/200] Iteration[002/008] Valid loss: 0.1677
2023-02-06 16:19:04 | Valid | Epoch[150/200] Iteration[003/008] Valid loss: 0.1417
2023-02-06 16:19:04 | Valid | Epoch[150/200] Iteration[004/008] Valid loss: 0.1320
2023-02-06 16:19:04 | Valid | Epoch[150/200] Iteration[005/008] Valid loss: 0.1351
2023-02-06 16:19:04 | Valid | Epoch[150/200] Iteration[006/008] Valid loss: 0.1294
2023-02-06 16:19:04 | Valid | Epoch[150/200] Iteration[007/008] Valid loss: 0.1392
2023-02-06 16:19:04 | Valid | Epoch[150/200] Iteration[008/008] Valid loss: 0.1370
2023-02-06 16:19:04 | Valid | Epoch[150/200] MIou: 0.9292262033048487
2023-02-06 16:19:04 | Valid | Epoch[150/200] Pixel Accuracy: 0.9874191284179688
2023-02-06 16:19:04 | Valid | Epoch[150/200] Mean Pixel Accuracy: 0.970918728011089
2023-02-06 16:19:04 | Stage | Epoch[150/200] Train loss:0.0218
2023-02-06 16:19:04 | Stage | Epoch[150/200] Valid loss:0.1370
2023-02-06 16:19:04 | Stage | Epoch[150/200] LR:0.01

2023-02-06 16:19:05 | Train | Epoch[151/200] Iteration[001/030] Train loss: 0.0211
2023-02-06 16:19:06 | Train | Epoch[151/200] Iteration[002/030] Train loss: 0.0218
2023-02-06 16:19:06 | Train | Epoch[151/200] Iteration[003/030] Train loss: 0.0223
2023-02-06 16:19:06 | Train | Epoch[151/200] Iteration[004/030] Train loss: 0.0219
2023-02-06 16:19:07 | Train | Epoch[151/200] Iteration[005/030] Train loss: 0.0218
2023-02-06 16:19:07 | Train | Epoch[151/200] Iteration[006/030] Train loss: 0.0218
2023-02-06 16:19:08 | Train | Epoch[151/200] Iteration[007/030] Train loss: 0.0216
2023-02-06 16:19:08 | Train | Epoch[151/200] Iteration[008/030] Train loss: 0.0216
2023-02-06 16:19:09 | Train | Epoch[151/200] Iteration[009/030] Train loss: 0.0216
2023-02-06 16:19:09 | Train | Epoch[151/200] Iteration[010/030] Train loss: 0.0217
2023-02-06 16:19:09 | Train | Epoch[151/200] Iteration[011/030] Train loss: 0.0216
2023-02-06 16:19:10 | Train | Epoch[151/200] Iteration[012/030] Train loss: 0.0216
2023-02-06 16:19:10 | Train | Epoch[151/200] Iteration[013/030] Train loss: 0.0215
2023-02-06 16:19:11 | Train | Epoch[151/200] Iteration[014/030] Train loss: 0.0215
2023-02-06 16:19:11 | Train | Epoch[151/200] Iteration[015/030] Train loss: 0.0215
2023-02-06 16:19:12 | Train | Epoch[151/200] Iteration[016/030] Train loss: 0.0215
2023-02-06 16:19:12 | Train | Epoch[151/200] Iteration[017/030] Train loss: 0.0215
2023-02-06 16:19:12 | Train | Epoch[151/200] Iteration[018/030] Train loss: 0.0215
2023-02-06 16:19:13 | Train | Epoch[151/200] Iteration[019/030] Train loss: 0.0215
2023-02-06 16:19:13 | Train | Epoch[151/200] Iteration[020/030] Train loss: 0.0215
2023-02-06 16:19:14 | Train | Epoch[151/200] Iteration[021/030] Train loss: 0.0215
2023-02-06 16:19:14 | Train | Epoch[151/200] Iteration[022/030] Train loss: 0.0216
2023-02-06 16:19:15 | Train | Epoch[151/200] Iteration[023/030] Train loss: 0.0216
2023-02-06 16:19:15 | Train | Epoch[151/200] Iteration[024/030] Train loss: 0.0217
2023-02-06 16:19:16 | Train | Epoch[151/200] Iteration[025/030] Train loss: 0.0216
2023-02-06 16:19:16 | Train | Epoch[151/200] Iteration[026/030] Train loss: 0.0216
2023-02-06 16:19:16 | Train | Epoch[151/200] Iteration[027/030] Train loss: 0.0216
2023-02-06 16:19:17 | Train | Epoch[151/200] Iteration[028/030] Train loss: 0.0217
2023-02-06 16:19:17 | Train | Epoch[151/200] Iteration[029/030] Train loss: 0.0217
2023-02-06 16:19:17 | Train | Epoch[151/200] Iteration[030/030] Train loss: 0.0218
2023-02-06 16:19:18 | Valid | Epoch[151/200] Iteration[001/008] Valid loss: 0.2061
2023-02-06 16:19:18 | Valid | Epoch[151/200] Iteration[002/008] Valid loss: 0.1724
2023-02-06 16:19:18 | Valid | Epoch[151/200] Iteration[003/008] Valid loss: 0.1459
2023-02-06 16:19:18 | Valid | Epoch[151/200] Iteration[004/008] Valid loss: 0.1437
2023-02-06 16:19:18 | Valid | Epoch[151/200] Iteration[005/008] Valid loss: 0.1431
2023-02-06 16:19:18 | Valid | Epoch[151/200] Iteration[006/008] Valid loss: 0.1367
2023-02-06 16:19:18 | Valid | Epoch[151/200] Iteration[007/008] Valid loss: 0.1475
2023-02-06 16:19:19 | Valid | Epoch[151/200] Iteration[008/008] Valid loss: 0.1464
2023-02-06 16:19:19 | Valid | Epoch[151/200] MIou: 0.9122372626445601
2023-02-06 16:19:19 | Valid | Epoch[151/200] Pixel Accuracy: 0.9838943481445312
2023-02-06 16:19:19 | Valid | Epoch[151/200] Mean Pixel Accuracy: 0.969063784574222
2023-02-06 16:19:19 | Stage | Epoch[151/200] Train loss:0.0218
2023-02-06 16:19:19 | Stage | Epoch[151/200] Valid loss:0.1464
2023-02-06 16:19:19 | Stage | Epoch[151/200] LR:0.01

2023-02-06 16:19:19 | Train | Epoch[152/200] Iteration[001/030] Train loss: 0.0215
2023-02-06 16:19:20 | Train | Epoch[152/200] Iteration[002/030] Train loss: 0.0214
2023-02-06 16:19:20 | Train | Epoch[152/200] Iteration[003/030] Train loss: 0.0214
2023-02-06 16:19:21 | Train | Epoch[152/200] Iteration[004/030] Train loss: 0.0213
2023-02-06 16:19:21 | Train | Epoch[152/200] Iteration[005/030] Train loss: 0.0213
2023-02-06 16:19:22 | Train | Epoch[152/200] Iteration[006/030] Train loss: 0.0217
2023-02-06 16:19:22 | Train | Epoch[152/200] Iteration[007/030] Train loss: 0.0218
2023-02-06 16:19:22 | Train | Epoch[152/200] Iteration[008/030] Train loss: 0.0222
2023-02-06 16:19:23 | Train | Epoch[152/200] Iteration[009/030] Train loss: 0.0221
2023-02-06 16:19:23 | Train | Epoch[152/200] Iteration[010/030] Train loss: 0.0221
2023-02-06 16:19:24 | Train | Epoch[152/200] Iteration[011/030] Train loss: 0.0223
2023-02-06 16:19:24 | Train | Epoch[152/200] Iteration[012/030] Train loss: 0.0223
2023-02-06 16:19:25 | Train | Epoch[152/200] Iteration[013/030] Train loss: 0.0224
2023-02-06 16:19:25 | Train | Epoch[152/200] Iteration[014/030] Train loss: 0.0223
2023-02-06 16:19:25 | Train | Epoch[152/200] Iteration[015/030] Train loss: 0.0224
2023-02-06 16:19:26 | Train | Epoch[152/200] Iteration[016/030] Train loss: 0.0223
2023-02-06 16:19:26 | Train | Epoch[152/200] Iteration[017/030] Train loss: 0.0222
2023-02-06 16:19:27 | Train | Epoch[152/200] Iteration[018/030] Train loss: 0.0222
2023-02-06 16:19:27 | Train | Epoch[152/200] Iteration[019/030] Train loss: 0.0222
2023-02-06 16:19:28 | Train | Epoch[152/200] Iteration[020/030] Train loss: 0.0221
2023-02-06 16:19:28 | Train | Epoch[152/200] Iteration[021/030] Train loss: 0.0222
2023-02-06 16:19:28 | Train | Epoch[152/200] Iteration[022/030] Train loss: 0.0222
2023-02-06 16:19:29 | Train | Epoch[152/200] Iteration[023/030] Train loss: 0.0221
2023-02-06 16:19:29 | Train | Epoch[152/200] Iteration[024/030] Train loss: 0.0222
2023-02-06 16:19:30 | Train | Epoch[152/200] Iteration[025/030] Train loss: 0.0222
2023-02-06 16:19:30 | Train | Epoch[152/200] Iteration[026/030] Train loss: 0.0222
2023-02-06 16:19:31 | Train | Epoch[152/200] Iteration[027/030] Train loss: 0.0222
2023-02-06 16:19:31 | Train | Epoch[152/200] Iteration[028/030] Train loss: 0.0222
2023-02-06 16:19:31 | Train | Epoch[152/200] Iteration[029/030] Train loss: 0.0222
2023-02-06 16:19:32 | Train | Epoch[152/200] Iteration[030/030] Train loss: 0.0223
2023-02-06 16:19:32 | Valid | Epoch[152/200] Iteration[001/008] Valid loss: 0.4469
2023-02-06 16:19:32 | Valid | Epoch[152/200] Iteration[002/008] Valid loss: 0.4112
2023-02-06 16:19:32 | Valid | Epoch[152/200] Iteration[003/008] Valid loss: 0.3820
2023-02-06 16:19:32 | Valid | Epoch[152/200] Iteration[004/008] Valid loss: 0.3854
2023-02-06 16:19:33 | Valid | Epoch[152/200] Iteration[005/008] Valid loss: 0.3991
2023-02-06 16:19:33 | Valid | Epoch[152/200] Iteration[006/008] Valid loss: 0.3930
2023-02-06 16:19:33 | Valid | Epoch[152/200] Iteration[007/008] Valid loss: 0.4150
2023-02-06 16:19:33 | Valid | Epoch[152/200] Iteration[008/008] Valid loss: 0.4317
2023-02-06 16:19:33 | Valid | Epoch[152/200] MIou: 0.9004574479890615
2023-02-06 16:19:33 | Valid | Epoch[152/200] Pixel Accuracy: 0.9808120727539062
2023-02-06 16:19:33 | Valid | Epoch[152/200] Mean Pixel Accuracy: 0.980836796055326
2023-02-06 16:19:33 | Stage | Epoch[152/200] Train loss:0.0223
2023-02-06 16:19:33 | Stage | Epoch[152/200] Valid loss:0.4317
2023-02-06 16:19:33 | Stage | Epoch[152/200] LR:0.01

2023-02-06 16:19:34 | Train | Epoch[153/200] Iteration[001/030] Train loss: 0.0210
2023-02-06 16:19:34 | Train | Epoch[153/200] Iteration[002/030] Train loss: 0.0205
2023-02-06 16:19:35 | Train | Epoch[153/200] Iteration[003/030] Train loss: 0.0225
2023-02-06 16:19:35 | Train | Epoch[153/200] Iteration[004/030] Train loss: 0.0220
2023-02-06 16:19:35 | Train | Epoch[153/200] Iteration[005/030] Train loss: 0.0218
2023-02-06 16:19:36 | Train | Epoch[153/200] Iteration[006/030] Train loss: 0.0217
2023-02-06 16:19:36 | Train | Epoch[153/200] Iteration[007/030] Train loss: 0.0217
2023-02-06 16:19:37 | Train | Epoch[153/200] Iteration[008/030] Train loss: 0.0216
2023-02-06 16:19:37 | Train | Epoch[153/200] Iteration[009/030] Train loss: 0.0215
2023-02-06 16:19:38 | Train | Epoch[153/200] Iteration[010/030] Train loss: 0.0216
2023-02-06 16:19:38 | Train | Epoch[153/200] Iteration[011/030] Train loss: 0.0216
2023-02-06 16:19:39 | Train | Epoch[153/200] Iteration[012/030] Train loss: 0.0216
2023-02-06 16:19:39 | Train | Epoch[153/200] Iteration[013/030] Train loss: 0.0215
2023-02-06 16:19:39 | Train | Epoch[153/200] Iteration[014/030] Train loss: 0.0216
2023-02-06 16:19:40 | Train | Epoch[153/200] Iteration[015/030] Train loss: 0.0215
2023-02-06 16:19:40 | Train | Epoch[153/200] Iteration[016/030] Train loss: 0.0215
2023-02-06 16:19:41 | Train | Epoch[153/200] Iteration[017/030] Train loss: 0.0215
2023-02-06 16:19:41 | Train | Epoch[153/200] Iteration[018/030] Train loss: 0.0215
2023-02-06 16:19:42 | Train | Epoch[153/200] Iteration[019/030] Train loss: 0.0216
2023-02-06 16:19:42 | Train | Epoch[153/200] Iteration[020/030] Train loss: 0.0215
2023-02-06 16:19:42 | Train | Epoch[153/200] Iteration[021/030] Train loss: 0.0215
2023-02-06 16:19:43 | Train | Epoch[153/200] Iteration[022/030] Train loss: 0.0215
2023-02-06 16:19:43 | Train | Epoch[153/200] Iteration[023/030] Train loss: 0.0215
2023-02-06 16:19:44 | Train | Epoch[153/200] Iteration[024/030] Train loss: 0.0214
2023-02-06 16:19:44 | Train | Epoch[153/200] Iteration[025/030] Train loss: 0.0215
2023-02-06 16:19:45 | Train | Epoch[153/200] Iteration[026/030] Train loss: 0.0215
2023-02-06 16:19:45 | Train | Epoch[153/200] Iteration[027/030] Train loss: 0.0216
2023-02-06 16:19:45 | Train | Epoch[153/200] Iteration[028/030] Train loss: 0.0215
2023-02-06 16:19:46 | Train | Epoch[153/200] Iteration[029/030] Train loss: 0.0215
2023-02-06 16:19:46 | Train | Epoch[153/200] Iteration[030/030] Train loss: 0.0215
2023-02-06 16:19:47 | Valid | Epoch[153/200] Iteration[001/008] Valid loss: 0.2147
2023-02-06 16:19:47 | Valid | Epoch[153/200] Iteration[002/008] Valid loss: 0.1817
2023-02-06 16:19:47 | Valid | Epoch[153/200] Iteration[003/008] Valid loss: 0.1581
2023-02-06 16:19:47 | Valid | Epoch[153/200] Iteration[004/008] Valid loss: 0.1504
2023-02-06 16:19:47 | Valid | Epoch[153/200] Iteration[005/008] Valid loss: 0.1562
2023-02-06 16:19:47 | Valid | Epoch[153/200] Iteration[006/008] Valid loss: 0.1467
2023-02-06 16:19:47 | Valid | Epoch[153/200] Iteration[007/008] Valid loss: 0.1602
2023-02-06 16:19:47 | Valid | Epoch[153/200] Iteration[008/008] Valid loss: 0.1581
2023-02-06 16:19:47 | Valid | Epoch[153/200] MIou: 0.9168397660461505
2023-02-06 16:19:47 | Valid | Epoch[153/200] Pixel Accuracy: 0.9851710001627604
2023-02-06 16:19:47 | Valid | Epoch[153/200] Mean Pixel Accuracy: 0.9600645655578504
2023-02-06 16:19:47 | Stage | Epoch[153/200] Train loss:0.0215
2023-02-06 16:19:47 | Stage | Epoch[153/200] Valid loss:0.1581
2023-02-06 16:19:47 | Stage | Epoch[153/200] LR:0.01

2023-02-06 16:19:48 | Train | Epoch[154/200] Iteration[001/030] Train loss: 0.0207
2023-02-06 16:19:49 | Train | Epoch[154/200] Iteration[002/030] Train loss: 0.0210
2023-02-06 16:19:49 | Train | Epoch[154/200] Iteration[003/030] Train loss: 0.0206
2023-02-06 16:19:49 | Train | Epoch[154/200] Iteration[004/030] Train loss: 0.0206
2023-02-06 16:19:50 | Train | Epoch[154/200] Iteration[005/030] Train loss: 0.0205
2023-02-06 16:19:50 | Train | Epoch[154/200] Iteration[006/030] Train loss: 0.0205
2023-02-06 16:19:51 | Train | Epoch[154/200] Iteration[007/030] Train loss: 0.0204
2023-02-06 16:19:51 | Train | Epoch[154/200] Iteration[008/030] Train loss: 0.0205
2023-02-06 16:19:52 | Train | Epoch[154/200] Iteration[009/030] Train loss: 0.0205
2023-02-06 16:19:52 | Train | Epoch[154/200] Iteration[010/030] Train loss: 0.0205
2023-02-06 16:19:52 | Train | Epoch[154/200] Iteration[011/030] Train loss: 0.0205
2023-02-06 16:19:53 | Train | Epoch[154/200] Iteration[012/030] Train loss: 0.0207
2023-02-06 16:19:53 | Train | Epoch[154/200] Iteration[013/030] Train loss: 0.0207
2023-02-06 16:19:54 | Train | Epoch[154/200] Iteration[014/030] Train loss: 0.0207
2023-02-06 16:19:54 | Train | Epoch[154/200] Iteration[015/030] Train loss: 0.0208
2023-02-06 16:19:55 | Train | Epoch[154/200] Iteration[016/030] Train loss: 0.0209
2023-02-06 16:19:55 | Train | Epoch[154/200] Iteration[017/030] Train loss: 0.0209
2023-02-06 16:19:55 | Train | Epoch[154/200] Iteration[018/030] Train loss: 0.0209
2023-02-06 16:19:56 | Train | Epoch[154/200] Iteration[019/030] Train loss: 0.0210
2023-02-06 16:19:56 | Train | Epoch[154/200] Iteration[020/030] Train loss: 0.0210
2023-02-06 16:19:57 | Train | Epoch[154/200] Iteration[021/030] Train loss: 0.0210
2023-02-06 16:19:57 | Train | Epoch[154/200] Iteration[022/030] Train loss: 0.0210
2023-02-06 16:19:58 | Train | Epoch[154/200] Iteration[023/030] Train loss: 0.0210
2023-02-06 16:19:58 | Train | Epoch[154/200] Iteration[024/030] Train loss: 0.0210
2023-02-06 16:19:58 | Train | Epoch[154/200] Iteration[025/030] Train loss: 0.0210
2023-02-06 16:19:59 | Train | Epoch[154/200] Iteration[026/030] Train loss: 0.0210
2023-02-06 16:19:59 | Train | Epoch[154/200] Iteration[027/030] Train loss: 0.0210
2023-02-06 16:20:00 | Train | Epoch[154/200] Iteration[028/030] Train loss: 0.0211
2023-02-06 16:20:00 | Train | Epoch[154/200] Iteration[029/030] Train loss: 0.0210
2023-02-06 16:20:00 | Train | Epoch[154/200] Iteration[030/030] Train loss: 0.0210
2023-02-06 16:20:01 | Valid | Epoch[154/200] Iteration[001/008] Valid loss: 0.0907
2023-02-06 16:20:01 | Valid | Epoch[154/200] Iteration[002/008] Valid loss: 0.0857
2023-02-06 16:20:01 | Valid | Epoch[154/200] Iteration[003/008] Valid loss: 0.0872
2023-02-06 16:20:01 | Valid | Epoch[154/200] Iteration[004/008] Valid loss: 0.0855
2023-02-06 16:20:01 | Valid | Epoch[154/200] Iteration[005/008] Valid loss: 0.0869
2023-02-06 16:20:01 | Valid | Epoch[154/200] Iteration[006/008] Valid loss: 0.0861
2023-02-06 16:20:01 | Valid | Epoch[154/200] Iteration[007/008] Valid loss: 0.0842
2023-02-06 16:20:02 | Valid | Epoch[154/200] Iteration[008/008] Valid loss: 0.0858
2023-02-06 16:20:02 | Valid | Epoch[154/200] MIou: 0.779468653471098
2023-02-06 16:20:02 | Valid | Epoch[154/200] Pixel Accuracy: 0.963616689046224
2023-02-06 16:20:02 | Valid | Epoch[154/200] Mean Pixel Accuracy: 0.7988422285459783
2023-02-06 16:20:02 | Stage | Epoch[154/200] Train loss:0.0210
2023-02-06 16:20:02 | Stage | Epoch[154/200] Valid loss:0.0858
2023-02-06 16:20:02 | Stage | Epoch[154/200] LR:0.01

2023-02-06 16:20:02 | Train | Epoch[155/200] Iteration[001/030] Train loss: 0.0207
2023-02-06 16:20:03 | Train | Epoch[155/200] Iteration[002/030] Train loss: 0.0205
2023-02-06 16:20:03 | Train | Epoch[155/200] Iteration[003/030] Train loss: 0.0202
2023-02-06 16:20:04 | Train | Epoch[155/200] Iteration[004/030] Train loss: 0.0201
2023-02-06 16:20:04 | Train | Epoch[155/200] Iteration[005/030] Train loss: 0.0201
2023-02-06 16:20:05 | Train | Epoch[155/200] Iteration[006/030] Train loss: 0.0201
2023-02-06 16:20:05 | Train | Epoch[155/200] Iteration[007/030] Train loss: 0.0203
2023-02-06 16:20:05 | Train | Epoch[155/200] Iteration[008/030] Train loss: 0.0205
2023-02-06 16:20:06 | Train | Epoch[155/200] Iteration[009/030] Train loss: 0.0204
2023-02-06 16:20:06 | Train | Epoch[155/200] Iteration[010/030] Train loss: 0.0203
2023-02-06 16:20:07 | Train | Epoch[155/200] Iteration[011/030] Train loss: 0.0203
2023-02-06 16:20:07 | Train | Epoch[155/200] Iteration[012/030] Train loss: 0.0202
2023-02-06 16:20:08 | Train | Epoch[155/200] Iteration[013/030] Train loss: 0.0202
2023-02-06 16:20:08 | Train | Epoch[155/200] Iteration[014/030] Train loss: 0.0202
2023-02-06 16:20:09 | Train | Epoch[155/200] Iteration[015/030] Train loss: 0.0202
2023-02-06 16:20:09 | Train | Epoch[155/200] Iteration[016/030] Train loss: 0.0203
2023-02-06 16:20:09 | Train | Epoch[155/200] Iteration[017/030] Train loss: 0.0203
2023-02-06 16:20:10 | Train | Epoch[155/200] Iteration[018/030] Train loss: 0.0204
2023-02-06 16:20:10 | Train | Epoch[155/200] Iteration[019/030] Train loss: 0.0204
2023-02-06 16:20:11 | Train | Epoch[155/200] Iteration[020/030] Train loss: 0.0204
2023-02-06 16:20:11 | Train | Epoch[155/200] Iteration[021/030] Train loss: 0.0204
2023-02-06 16:20:12 | Train | Epoch[155/200] Iteration[022/030] Train loss: 0.0204
2023-02-06 16:20:12 | Train | Epoch[155/200] Iteration[023/030] Train loss: 0.0204
2023-02-06 16:20:12 | Train | Epoch[155/200] Iteration[024/030] Train loss: 0.0204
2023-02-06 16:20:13 | Train | Epoch[155/200] Iteration[025/030] Train loss: 0.0204
2023-02-06 16:20:13 | Train | Epoch[155/200] Iteration[026/030] Train loss: 0.0205
2023-02-06 16:20:14 | Train | Epoch[155/200] Iteration[027/030] Train loss: 0.0205
2023-02-06 16:20:14 | Train | Epoch[155/200] Iteration[028/030] Train loss: 0.0205
2023-02-06 16:20:15 | Train | Epoch[155/200] Iteration[029/030] Train loss: 0.0206
2023-02-06 16:20:15 | Train | Epoch[155/200] Iteration[030/030] Train loss: 0.0206
2023-02-06 16:20:15 | Valid | Epoch[155/200] Iteration[001/008] Valid loss: 0.2333
2023-02-06 16:20:15 | Valid | Epoch[155/200] Iteration[002/008] Valid loss: 0.1793
2023-02-06 16:20:15 | Valid | Epoch[155/200] Iteration[003/008] Valid loss: 0.1518
2023-02-06 16:20:16 | Valid | Epoch[155/200] Iteration[004/008] Valid loss: 0.1430
2023-02-06 16:20:16 | Valid | Epoch[155/200] Iteration[005/008] Valid loss: 0.1463
2023-02-06 16:20:16 | Valid | Epoch[155/200] Iteration[006/008] Valid loss: 0.1403
2023-02-06 16:20:16 | Valid | Epoch[155/200] Iteration[007/008] Valid loss: 0.1491
2023-02-06 16:20:16 | Valid | Epoch[155/200] Iteration[008/008] Valid loss: 0.1484
2023-02-06 16:20:16 | Valid | Epoch[155/200] MIou: 0.9325794502902309
2023-02-06 16:20:16 | Valid | Epoch[155/200] Pixel Accuracy: 0.9880447387695312
2023-02-06 16:20:16 | Valid | Epoch[155/200] Mean Pixel Accuracy: 0.9730632840513747
2023-02-06 16:20:16 | Stage | Epoch[155/200] Train loss:0.0206
2023-02-06 16:20:16 | Stage | Epoch[155/200] Valid loss:0.1484
2023-02-06 16:20:16 | Stage | Epoch[155/200] LR:0.01

2023-02-06 16:20:17 | Train | Epoch[156/200] Iteration[001/030] Train loss: 0.0220
2023-02-06 16:20:17 | Train | Epoch[156/200] Iteration[002/030] Train loss: 0.0224
2023-02-06 16:20:18 | Train | Epoch[156/200] Iteration[003/030] Train loss: 0.0226
2023-02-06 16:20:18 | Train | Epoch[156/200] Iteration[004/030] Train loss: 0.0225
2023-02-06 16:20:19 | Train | Epoch[156/200] Iteration[005/030] Train loss: 0.0222
2023-02-06 16:20:19 | Train | Epoch[156/200] Iteration[006/030] Train loss: 0.0218
2023-02-06 16:20:19 | Train | Epoch[156/200] Iteration[007/030] Train loss: 0.0216
2023-02-06 16:20:20 | Train | Epoch[156/200] Iteration[008/030] Train loss: 0.0215
2023-02-06 16:20:20 | Train | Epoch[156/200] Iteration[009/030] Train loss: 0.0213
2023-02-06 16:20:21 | Train | Epoch[156/200] Iteration[010/030] Train loss: 0.0213
2023-02-06 16:20:21 | Train | Epoch[156/200] Iteration[011/030] Train loss: 0.0212
2023-02-06 16:20:22 | Train | Epoch[156/200] Iteration[012/030] Train loss: 0.0212
2023-02-06 16:20:22 | Train | Epoch[156/200] Iteration[013/030] Train loss: 0.0215
2023-02-06 16:20:22 | Train | Epoch[156/200] Iteration[014/030] Train loss: 0.0214
2023-02-06 16:20:23 | Train | Epoch[156/200] Iteration[015/030] Train loss: 0.0213
2023-02-06 16:20:23 | Train | Epoch[156/200] Iteration[016/030] Train loss: 0.0213
2023-02-06 16:20:24 | Train | Epoch[156/200] Iteration[017/030] Train loss: 0.0213
2023-02-06 16:20:24 | Train | Epoch[156/200] Iteration[018/030] Train loss: 0.0213
2023-02-06 16:20:25 | Train | Epoch[156/200] Iteration[019/030] Train loss: 0.0213
2023-02-06 16:20:25 | Train | Epoch[156/200] Iteration[020/030] Train loss: 0.0214
2023-02-06 16:20:25 | Train | Epoch[156/200] Iteration[021/030] Train loss: 0.0213
2023-02-06 16:20:26 | Train | Epoch[156/200] Iteration[022/030] Train loss: 0.0213
2023-02-06 16:20:26 | Train | Epoch[156/200] Iteration[023/030] Train loss: 0.0213
2023-02-06 16:20:27 | Train | Epoch[156/200] Iteration[024/030] Train loss: 0.0212
2023-02-06 16:20:27 | Train | Epoch[156/200] Iteration[025/030] Train loss: 0.0212
2023-02-06 16:20:28 | Train | Epoch[156/200] Iteration[026/030] Train loss: 0.0212
2023-02-06 16:20:28 | Train | Epoch[156/200] Iteration[027/030] Train loss: 0.0213
2023-02-06 16:20:28 | Train | Epoch[156/200] Iteration[028/030] Train loss: 0.0213
2023-02-06 16:20:29 | Train | Epoch[156/200] Iteration[029/030] Train loss: 0.0213
2023-02-06 16:20:29 | Train | Epoch[156/200] Iteration[030/030] Train loss: 0.0213
2023-02-06 16:20:30 | Valid | Epoch[156/200] Iteration[001/008] Valid loss: 0.3234
2023-02-06 16:20:30 | Valid | Epoch[156/200] Iteration[002/008] Valid loss: 0.2960
2023-02-06 16:20:30 | Valid | Epoch[156/200] Iteration[003/008] Valid loss: 0.2676
2023-02-06 16:20:30 | Valid | Epoch[156/200] Iteration[004/008] Valid loss: 0.2647
2023-02-06 16:20:30 | Valid | Epoch[156/200] Iteration[005/008] Valid loss: 0.2761
2023-02-06 16:20:30 | Valid | Epoch[156/200] Iteration[006/008] Valid loss: 0.2713
2023-02-06 16:20:30 | Valid | Epoch[156/200] Iteration[007/008] Valid loss: 0.2860
2023-02-06 16:20:30 | Valid | Epoch[156/200] Iteration[008/008] Valid loss: 0.2937
2023-02-06 16:20:30 | Valid | Epoch[156/200] MIou: 0.9071975193374788
2023-02-06 16:20:30 | Valid | Epoch[156/200] Pixel Accuracy: 0.9824358622233073
2023-02-06 16:20:30 | Valid | Epoch[156/200] Mean Pixel Accuracy: 0.9789077901777792
2023-02-06 16:20:30 | Stage | Epoch[156/200] Train loss:0.0213
2023-02-06 16:20:30 | Stage | Epoch[156/200] Valid loss:0.2937
2023-02-06 16:20:30 | Stage | Epoch[156/200] LR:0.01

2023-02-06 16:20:31 | Train | Epoch[157/200] Iteration[001/030] Train loss: 0.0203
2023-02-06 16:20:31 | Train | Epoch[157/200] Iteration[002/030] Train loss: 0.0202
2023-02-06 16:20:32 | Train | Epoch[157/200] Iteration[003/030] Train loss: 0.0204
2023-02-06 16:20:32 | Train | Epoch[157/200] Iteration[004/030] Train loss: 0.0203
2023-02-06 16:20:33 | Train | Epoch[157/200] Iteration[005/030] Train loss: 0.0203
2023-02-06 16:20:33 | Train | Epoch[157/200] Iteration[006/030] Train loss: 0.0204
2023-02-06 16:20:34 | Train | Epoch[157/200] Iteration[007/030] Train loss: 0.0204
2023-02-06 16:20:34 | Train | Epoch[157/200] Iteration[008/030] Train loss: 0.0204
2023-02-06 16:20:34 | Train | Epoch[157/200] Iteration[009/030] Train loss: 0.0204
2023-02-06 16:20:35 | Train | Epoch[157/200] Iteration[010/030] Train loss: 0.0205
2023-02-06 16:20:35 | Train | Epoch[157/200] Iteration[011/030] Train loss: 0.0205
2023-02-06 16:20:36 | Train | Epoch[157/200] Iteration[012/030] Train loss: 0.0205
2023-02-06 16:20:36 | Train | Epoch[157/200] Iteration[013/030] Train loss: 0.0205
2023-02-06 16:20:37 | Train | Epoch[157/200] Iteration[014/030] Train loss: 0.0207
2023-02-06 16:20:37 | Train | Epoch[157/200] Iteration[015/030] Train loss: 0.0207
2023-02-06 16:20:37 | Train | Epoch[157/200] Iteration[016/030] Train loss: 0.0207
2023-02-06 16:20:38 | Train | Epoch[157/200] Iteration[017/030] Train loss: 0.0208
2023-02-06 16:20:38 | Train | Epoch[157/200] Iteration[018/030] Train loss: 0.0208
2023-02-06 16:20:39 | Train | Epoch[157/200] Iteration[019/030] Train loss: 0.0207
2023-02-06 16:20:39 | Train | Epoch[157/200] Iteration[020/030] Train loss: 0.0207
2023-02-06 16:20:40 | Train | Epoch[157/200] Iteration[021/030] Train loss: 0.0208
2023-02-06 16:20:40 | Train | Epoch[157/200] Iteration[022/030] Train loss: 0.0208
2023-02-06 16:20:40 | Train | Epoch[157/200] Iteration[023/030] Train loss: 0.0208
2023-02-06 16:20:41 | Train | Epoch[157/200] Iteration[024/030] Train loss: 0.0208
2023-02-06 16:20:41 | Train | Epoch[157/200] Iteration[025/030] Train loss: 0.0208
2023-02-06 16:20:42 | Train | Epoch[157/200] Iteration[026/030] Train loss: 0.0208
2023-02-06 16:20:42 | Train | Epoch[157/200] Iteration[027/030] Train loss: 0.0207
2023-02-06 16:20:43 | Train | Epoch[157/200] Iteration[028/030] Train loss: 0.0207
2023-02-06 16:20:43 | Train | Epoch[157/200] Iteration[029/030] Train loss: 0.0207
2023-02-06 16:20:43 | Train | Epoch[157/200] Iteration[030/030] Train loss: 0.0207
2023-02-06 16:20:44 | Valid | Epoch[157/200] Iteration[001/008] Valid loss: 0.2301
2023-02-06 16:20:44 | Valid | Epoch[157/200] Iteration[002/008] Valid loss: 0.1644
2023-02-06 16:20:44 | Valid | Epoch[157/200] Iteration[003/008] Valid loss: 0.1400
2023-02-06 16:20:44 | Valid | Epoch[157/200] Iteration[004/008] Valid loss: 0.1387
2023-02-06 16:20:44 | Valid | Epoch[157/200] Iteration[005/008] Valid loss: 0.1392
2023-02-06 16:20:44 | Valid | Epoch[157/200] Iteration[006/008] Valid loss: 0.1467
2023-02-06 16:20:44 | Valid | Epoch[157/200] Iteration[007/008] Valid loss: 0.1555
2023-02-06 16:20:44 | Valid | Epoch[157/200] Iteration[008/008] Valid loss: 0.1492
2023-02-06 16:20:44 | Valid | Epoch[157/200] MIou: 0.9169064744839075
2023-02-06 16:20:44 | Valid | Epoch[157/200] Pixel Accuracy: 0.9851900736490885
2023-02-06 16:20:44 | Valid | Epoch[157/200] Mean Pixel Accuracy: 0.9599038564285747
2023-02-06 16:20:44 | Stage | Epoch[157/200] Train loss:0.0207
2023-02-06 16:20:44 | Stage | Epoch[157/200] Valid loss:0.1492
2023-02-06 16:20:44 | Stage | Epoch[157/200] LR:0.01

2023-02-06 16:20:45 | Train | Epoch[158/200] Iteration[001/030] Train loss: 0.0194
2023-02-06 16:20:46 | Train | Epoch[158/200] Iteration[002/030] Train loss: 0.0206
2023-02-06 16:20:46 | Train | Epoch[158/200] Iteration[003/030] Train loss: 0.0203
2023-02-06 16:20:47 | Train | Epoch[158/200] Iteration[004/030] Train loss: 0.0203
2023-02-06 16:20:47 | Train | Epoch[158/200] Iteration[005/030] Train loss: 0.0201
2023-02-06 16:20:47 | Train | Epoch[158/200] Iteration[006/030] Train loss: 0.0205
2023-02-06 16:20:48 | Train | Epoch[158/200] Iteration[007/030] Train loss: 0.0204
2023-02-06 16:20:48 | Train | Epoch[158/200] Iteration[008/030] Train loss: 0.0204
2023-02-06 16:20:49 | Train | Epoch[158/200] Iteration[009/030] Train loss: 0.0203
2023-02-06 16:20:49 | Train | Epoch[158/200] Iteration[010/030] Train loss: 0.0204
2023-02-06 16:20:50 | Train | Epoch[158/200] Iteration[011/030] Train loss: 0.0204
2023-02-06 16:20:50 | Train | Epoch[158/200] Iteration[012/030] Train loss: 0.0203
2023-02-06 16:20:50 | Train | Epoch[158/200] Iteration[013/030] Train loss: 0.0204
2023-02-06 16:20:51 | Train | Epoch[158/200] Iteration[014/030] Train loss: 0.0203
2023-02-06 16:20:51 | Train | Epoch[158/200] Iteration[015/030] Train loss: 0.0204
2023-02-06 16:20:52 | Train | Epoch[158/200] Iteration[016/030] Train loss: 0.0205
2023-02-06 16:20:52 | Train | Epoch[158/200] Iteration[017/030] Train loss: 0.0205
2023-02-06 16:20:53 | Train | Epoch[158/200] Iteration[018/030] Train loss: 0.0205
2023-02-06 16:20:53 | Train | Epoch[158/200] Iteration[019/030] Train loss: 0.0205
2023-02-06 16:20:53 | Train | Epoch[158/200] Iteration[020/030] Train loss: 0.0205
2023-02-06 16:20:54 | Train | Epoch[158/200] Iteration[021/030] Train loss: 0.0204
2023-02-06 16:20:54 | Train | Epoch[158/200] Iteration[022/030] Train loss: 0.0204
2023-02-06 16:20:55 | Train | Epoch[158/200] Iteration[023/030] Train loss: 0.0205
2023-02-06 16:20:55 | Train | Epoch[158/200] Iteration[024/030] Train loss: 0.0205
2023-02-06 16:20:56 | Train | Epoch[158/200] Iteration[025/030] Train loss: 0.0205
2023-02-06 16:20:56 | Train | Epoch[158/200] Iteration[026/030] Train loss: 0.0205
2023-02-06 16:20:56 | Train | Epoch[158/200] Iteration[027/030] Train loss: 0.0204
2023-02-06 16:20:57 | Train | Epoch[158/200] Iteration[028/030] Train loss: 0.0204
2023-02-06 16:20:57 | Train | Epoch[158/200] Iteration[029/030] Train loss: 0.0204
2023-02-06 16:20:57 | Train | Epoch[158/200] Iteration[030/030] Train loss: 0.0205
2023-02-06 16:20:58 | Valid | Epoch[158/200] Iteration[001/008] Valid loss: 0.8828
2023-02-06 16:20:58 | Valid | Epoch[158/200] Iteration[002/008] Valid loss: 0.8652
2023-02-06 16:20:58 | Valid | Epoch[158/200] Iteration[003/008] Valid loss: 0.8411
2023-02-06 16:20:58 | Valid | Epoch[158/200] Iteration[004/008] Valid loss: 0.8650
2023-02-06 16:20:58 | Valid | Epoch[158/200] Iteration[005/008] Valid loss: 0.8961
2023-02-06 16:20:58 | Valid | Epoch[158/200] Iteration[006/008] Valid loss: 0.8835
2023-02-06 16:20:59 | Valid | Epoch[158/200] Iteration[007/008] Valid loss: 0.9281
2023-02-06 16:20:59 | Valid | Epoch[158/200] Iteration[008/008] Valid loss: 0.9527
2023-02-06 16:20:59 | Valid | Epoch[158/200] MIou: 0.8661552917126483
2023-02-06 16:20:59 | Valid | Epoch[158/200] Pixel Accuracy: 0.9721705118815104
2023-02-06 16:20:59 | Valid | Epoch[158/200] Mean Pixel Accuracy: 0.9807916555081633
2023-02-06 16:20:59 | Stage | Epoch[158/200] Train loss:0.0205
2023-02-06 16:20:59 | Stage | Epoch[158/200] Valid loss:0.9527
2023-02-06 16:20:59 | Stage | Epoch[158/200] LR:0.01

2023-02-06 16:20:59 | Train | Epoch[159/200] Iteration[001/030] Train loss: 0.0195
2023-02-06 16:21:00 | Train | Epoch[159/200] Iteration[002/030] Train loss: 0.0194
2023-02-06 16:21:00 | Train | Epoch[159/200] Iteration[003/030] Train loss: 0.0193
2023-02-06 16:21:01 | Train | Epoch[159/200] Iteration[004/030] Train loss: 0.0193
2023-02-06 16:21:01 | Train | Epoch[159/200] Iteration[005/030] Train loss: 0.0194
2023-02-06 16:21:02 | Train | Epoch[159/200] Iteration[006/030] Train loss: 0.0194
2023-02-06 16:21:02 | Train | Epoch[159/200] Iteration[007/030] Train loss: 0.0195
2023-02-06 16:21:02 | Train | Epoch[159/200] Iteration[008/030] Train loss: 0.0194
2023-02-06 16:21:03 | Train | Epoch[159/200] Iteration[009/030] Train loss: 0.0196
2023-02-06 16:21:03 | Train | Epoch[159/200] Iteration[010/030] Train loss: 0.0199
2023-02-06 16:21:04 | Train | Epoch[159/200] Iteration[011/030] Train loss: 0.0198
2023-02-06 16:21:04 | Train | Epoch[159/200] Iteration[012/030] Train loss: 0.0198
2023-02-06 16:21:05 | Train | Epoch[159/200] Iteration[013/030] Train loss: 0.0197
2023-02-06 16:21:05 | Train | Epoch[159/200] Iteration[014/030] Train loss: 0.0197
2023-02-06 16:21:05 | Train | Epoch[159/200] Iteration[015/030] Train loss: 0.0198
2023-02-06 16:21:06 | Train | Epoch[159/200] Iteration[016/030] Train loss: 0.0199
2023-02-06 16:21:06 | Train | Epoch[159/200] Iteration[017/030] Train loss: 0.0198
2023-02-06 16:21:07 | Train | Epoch[159/200] Iteration[018/030] Train loss: 0.0198
2023-02-06 16:21:07 | Train | Epoch[159/200] Iteration[019/030] Train loss: 0.0198
2023-02-06 16:21:08 | Train | Epoch[159/200] Iteration[020/030] Train loss: 0.0198
2023-02-06 16:21:08 | Train | Epoch[159/200] Iteration[021/030] Train loss: 0.0197
2023-02-06 16:21:09 | Train | Epoch[159/200] Iteration[022/030] Train loss: 0.0197
2023-02-06 16:21:09 | Train | Epoch[159/200] Iteration[023/030] Train loss: 0.0197
2023-02-06 16:21:09 | Train | Epoch[159/200] Iteration[024/030] Train loss: 0.0198
2023-02-06 16:21:10 | Train | Epoch[159/200] Iteration[025/030] Train loss: 0.0197
2023-02-06 16:21:10 | Train | Epoch[159/200] Iteration[026/030] Train loss: 0.0197
2023-02-06 16:21:11 | Train | Epoch[159/200] Iteration[027/030] Train loss: 0.0197
2023-02-06 16:21:11 | Train | Epoch[159/200] Iteration[028/030] Train loss: 0.0197
2023-02-06 16:21:12 | Train | Epoch[159/200] Iteration[029/030] Train loss: 0.0197
2023-02-06 16:21:12 | Train | Epoch[159/200] Iteration[030/030] Train loss: 0.0197
2023-02-06 16:21:12 | Valid | Epoch[159/200] Iteration[001/008] Valid loss: 0.4279
2023-02-06 16:21:12 | Valid | Epoch[159/200] Iteration[002/008] Valid loss: 0.3838
2023-02-06 16:21:12 | Valid | Epoch[159/200] Iteration[003/008] Valid loss: 0.3519
2023-02-06 16:21:12 | Valid | Epoch[159/200] Iteration[004/008] Valid loss: 0.3549
2023-02-06 16:21:13 | Valid | Epoch[159/200] Iteration[005/008] Valid loss: 0.3606
2023-02-06 16:21:13 | Valid | Epoch[159/200] Iteration[006/008] Valid loss: 0.3532
2023-02-06 16:21:13 | Valid | Epoch[159/200] Iteration[007/008] Valid loss: 0.3735
2023-02-06 16:21:13 | Valid | Epoch[159/200] Iteration[008/008] Valid loss: 0.3882
2023-02-06 16:21:13 | Valid | Epoch[159/200] MIou: 0.8997572864104705
2023-02-06 16:21:13 | Valid | Epoch[159/200] Pixel Accuracy: 0.9807751973470052
2023-02-06 16:21:13 | Valid | Epoch[159/200] Mean Pixel Accuracy: 0.97753850398725
2023-02-06 16:21:13 | Stage | Epoch[159/200] Train loss:0.0197
2023-02-06 16:21:13 | Stage | Epoch[159/200] Valid loss:0.3882
2023-02-06 16:21:13 | Stage | Epoch[159/200] LR:0.01

2023-02-06 16:21:14 | Train | Epoch[160/200] Iteration[001/030] Train loss: 0.0187
2023-02-06 16:21:14 | Train | Epoch[160/200] Iteration[002/030] Train loss: 0.0190
2023-02-06 16:21:14 | Train | Epoch[160/200] Iteration[003/030] Train loss: 0.0190
2023-02-06 16:21:15 | Train | Epoch[160/200] Iteration[004/030] Train loss: 0.0190
2023-02-06 16:21:15 | Train | Epoch[160/200] Iteration[005/030] Train loss: 0.0188
2023-02-06 16:21:16 | Train | Epoch[160/200] Iteration[006/030] Train loss: 0.0190
2023-02-06 16:21:16 | Train | Epoch[160/200] Iteration[007/030] Train loss: 0.0192
2023-02-06 16:21:17 | Train | Epoch[160/200] Iteration[008/030] Train loss: 0.0192
2023-02-06 16:21:17 | Train | Epoch[160/200] Iteration[009/030] Train loss: 0.0191
2023-02-06 16:21:17 | Train | Epoch[160/200] Iteration[010/030] Train loss: 0.0191
2023-02-06 16:21:18 | Train | Epoch[160/200] Iteration[011/030] Train loss: 0.0190
2023-02-06 16:21:18 | Train | Epoch[160/200] Iteration[012/030] Train loss: 0.0190
2023-02-06 16:21:19 | Train | Epoch[160/200] Iteration[013/030] Train loss: 0.0190
2023-02-06 16:21:19 | Train | Epoch[160/200] Iteration[014/030] Train loss: 0.0190
2023-02-06 16:21:20 | Train | Epoch[160/200] Iteration[015/030] Train loss: 0.0191
2023-02-06 16:21:20 | Train | Epoch[160/200] Iteration[016/030] Train loss: 0.0192
2023-02-06 16:21:21 | Train | Epoch[160/200] Iteration[017/030] Train loss: 0.0193
2023-02-06 16:21:21 | Train | Epoch[160/200] Iteration[018/030] Train loss: 0.0193
2023-02-06 16:21:21 | Train | Epoch[160/200] Iteration[019/030] Train loss: 0.0193
2023-02-06 16:21:22 | Train | Epoch[160/200] Iteration[020/030] Train loss: 0.0193
2023-02-06 16:21:22 | Train | Epoch[160/200] Iteration[021/030] Train loss: 0.0193
2023-02-06 16:21:23 | Train | Epoch[160/200] Iteration[022/030] Train loss: 0.0194
2023-02-06 16:21:23 | Train | Epoch[160/200] Iteration[023/030] Train loss: 0.0195
2023-02-06 16:21:24 | Train | Epoch[160/200] Iteration[024/030] Train loss: 0.0197
2023-02-06 16:21:24 | Train | Epoch[160/200] Iteration[025/030] Train loss: 0.0197
2023-02-06 16:21:24 | Train | Epoch[160/200] Iteration[026/030] Train loss: 0.0197
2023-02-06 16:21:25 | Train | Epoch[160/200] Iteration[027/030] Train loss: 0.0197
2023-02-06 16:21:25 | Train | Epoch[160/200] Iteration[028/030] Train loss: 0.0196
2023-02-06 16:21:26 | Train | Epoch[160/200] Iteration[029/030] Train loss: 0.0196
2023-02-06 16:21:26 | Train | Epoch[160/200] Iteration[030/030] Train loss: 0.0196
2023-02-06 16:21:26 | Valid | Epoch[160/200] Iteration[001/008] Valid loss: 0.1261
2023-02-06 16:21:26 | Valid | Epoch[160/200] Iteration[002/008] Valid loss: 0.0931
2023-02-06 16:21:27 | Valid | Epoch[160/200] Iteration[003/008] Valid loss: 0.0807
2023-02-06 16:21:27 | Valid | Epoch[160/200] Iteration[004/008] Valid loss: 0.0773
2023-02-06 16:21:27 | Valid | Epoch[160/200] Iteration[005/008] Valid loss: 0.0777
2023-02-06 16:21:27 | Valid | Epoch[160/200] Iteration[006/008] Valid loss: 0.0751
2023-02-06 16:21:27 | Valid | Epoch[160/200] Iteration[007/008] Valid loss: 0.0779
2023-02-06 16:21:27 | Valid | Epoch[160/200] Iteration[008/008] Valid loss: 0.0771
2023-02-06 16:21:27 | Valid | Epoch[160/200] MIou: 0.9227713957005981
2023-02-06 16:21:27 | Valid | Epoch[160/200] Pixel Accuracy: 0.9866765340169271
2023-02-06 16:21:27 | Valid | Epoch[160/200] Mean Pixel Accuracy: 0.9506078263809727
2023-02-06 16:21:27 | Stage | Epoch[160/200] Train loss:0.0196
2023-02-06 16:21:27 | Stage | Epoch[160/200] Valid loss:0.0771
2023-02-06 16:21:27 | Stage | Epoch[160/200] LR:0.01

2023-02-06 16:21:28 | Train | Epoch[161/200] Iteration[001/030] Train loss: 0.0232
2023-02-06 16:21:28 | Train | Epoch[161/200] Iteration[002/030] Train loss: 0.0209
2023-02-06 16:21:29 | Train | Epoch[161/200] Iteration[003/030] Train loss: 0.0204
2023-02-06 16:21:29 | Train | Epoch[161/200] Iteration[004/030] Train loss: 0.0206
2023-02-06 16:21:30 | Train | Epoch[161/200] Iteration[005/030] Train loss: 0.0204
2023-02-06 16:21:30 | Train | Epoch[161/200] Iteration[006/030] Train loss: 0.0202
2023-02-06 16:21:30 | Train | Epoch[161/200] Iteration[007/030] Train loss: 0.0200
2023-02-06 16:21:31 | Train | Epoch[161/200] Iteration[008/030] Train loss: 0.0200
2023-02-06 16:21:31 | Train | Epoch[161/200] Iteration[009/030] Train loss: 0.0201
2023-02-06 16:21:32 | Train | Epoch[161/200] Iteration[010/030] Train loss: 0.0203
2023-02-06 16:21:32 | Train | Epoch[161/200] Iteration[011/030] Train loss: 0.0203
2023-02-06 16:21:33 | Train | Epoch[161/200] Iteration[012/030] Train loss: 0.0204
2023-02-06 16:21:33 | Train | Epoch[161/200] Iteration[013/030] Train loss: 0.0203
2023-02-06 16:21:33 | Train | Epoch[161/200] Iteration[014/030] Train loss: 0.0205
2023-02-06 16:21:34 | Train | Epoch[161/200] Iteration[015/030] Train loss: 0.0204
2023-02-06 16:21:34 | Train | Epoch[161/200] Iteration[016/030] Train loss: 0.0204
2023-02-06 16:21:35 | Train | Epoch[161/200] Iteration[017/030] Train loss: 0.0204
2023-02-06 16:21:35 | Train | Epoch[161/200] Iteration[018/030] Train loss: 0.0203
2023-02-06 16:21:36 | Train | Epoch[161/200] Iteration[019/030] Train loss: 0.0203
2023-02-06 16:21:36 | Train | Epoch[161/200] Iteration[020/030] Train loss: 0.0202
2023-02-06 16:21:36 | Train | Epoch[161/200] Iteration[021/030] Train loss: 0.0202
2023-02-06 16:21:37 | Train | Epoch[161/200] Iteration[022/030] Train loss: 0.0202
2023-02-06 16:21:37 | Train | Epoch[161/200] Iteration[023/030] Train loss: 0.0202
2023-02-06 16:21:38 | Train | Epoch[161/200] Iteration[024/030] Train loss: 0.0202
2023-02-06 16:21:38 | Train | Epoch[161/200] Iteration[025/030] Train loss: 0.0202
2023-02-06 16:21:39 | Train | Epoch[161/200] Iteration[026/030] Train loss: 0.0201
2023-02-06 16:21:39 | Train | Epoch[161/200] Iteration[027/030] Train loss: 0.0201
2023-02-06 16:21:40 | Train | Epoch[161/200] Iteration[028/030] Train loss: 0.0201
2023-02-06 16:21:40 | Train | Epoch[161/200] Iteration[029/030] Train loss: 0.0201
2023-02-06 16:21:40 | Train | Epoch[161/200] Iteration[030/030] Train loss: 0.0201
2023-02-06 16:21:41 | Valid | Epoch[161/200] Iteration[001/008] Valid loss: 0.1341
2023-02-06 16:21:41 | Valid | Epoch[161/200] Iteration[002/008] Valid loss: 0.0973
2023-02-06 16:21:41 | Valid | Epoch[161/200] Iteration[003/008] Valid loss: 0.0822
2023-02-06 16:21:41 | Valid | Epoch[161/200] Iteration[004/008] Valid loss: 0.0757
2023-02-06 16:21:41 | Valid | Epoch[161/200] Iteration[005/008] Valid loss: 0.0735
2023-02-06 16:21:41 | Valid | Epoch[161/200] Iteration[006/008] Valid loss: 0.0721
2023-02-06 16:21:41 | Valid | Epoch[161/200] Iteration[007/008] Valid loss: 0.0736
2023-02-06 16:21:41 | Valid | Epoch[161/200] Iteration[008/008] Valid loss: 0.0709
2023-02-06 16:21:41 | Valid | Epoch[161/200] MIou: 0.9269565904403303
2023-02-06 16:21:41 | Valid | Epoch[161/200] Pixel Accuracy: 0.9875704447428385
2023-02-06 16:21:41 | Valid | Epoch[161/200] Mean Pixel Accuracy: 0.948391776504646
2023-02-06 16:21:41 | Stage | Epoch[161/200] Train loss:0.0201
2023-02-06 16:21:41 | Stage | Epoch[161/200] Valid loss:0.0709
2023-02-06 16:21:41 | Stage | Epoch[161/200] LR:0.01

2023-02-06 16:21:42 | Train | Epoch[162/200] Iteration[001/030] Train loss: 0.0180
2023-02-06 16:21:43 | Train | Epoch[162/200] Iteration[002/030] Train loss: 0.0184
2023-02-06 16:21:43 | Train | Epoch[162/200] Iteration[003/030] Train loss: 0.0186
2023-02-06 16:21:43 | Train | Epoch[162/200] Iteration[004/030] Train loss: 0.0187
2023-02-06 16:21:44 | Train | Epoch[162/200] Iteration[005/030] Train loss: 0.0188
2023-02-06 16:21:44 | Train | Epoch[162/200] Iteration[006/030] Train loss: 0.0189
2023-02-06 16:21:45 | Train | Epoch[162/200] Iteration[007/030] Train loss: 0.0194
2023-02-06 16:21:45 | Train | Epoch[162/200] Iteration[008/030] Train loss: 0.0193
2023-02-06 16:21:46 | Train | Epoch[162/200] Iteration[009/030] Train loss: 0.0193
2023-02-06 16:21:46 | Train | Epoch[162/200] Iteration[010/030] Train loss: 0.0193
2023-02-06 16:21:46 | Train | Epoch[162/200] Iteration[011/030] Train loss: 0.0193
2023-02-06 16:21:47 | Train | Epoch[162/200] Iteration[012/030] Train loss: 0.0194
2023-02-06 16:21:47 | Train | Epoch[162/200] Iteration[013/030] Train loss: 0.0193
2023-02-06 16:21:48 | Train | Epoch[162/200] Iteration[014/030] Train loss: 0.0192
2023-02-06 16:21:48 | Train | Epoch[162/200] Iteration[015/030] Train loss: 0.0192
2023-02-06 16:21:49 | Train | Epoch[162/200] Iteration[016/030] Train loss: 0.0191
2023-02-06 16:21:49 | Train | Epoch[162/200] Iteration[017/030] Train loss: 0.0191
2023-02-06 16:21:49 | Train | Epoch[162/200] Iteration[018/030] Train loss: 0.0193
2023-02-06 16:21:50 | Train | Epoch[162/200] Iteration[019/030] Train loss: 0.0193
2023-02-06 16:21:50 | Train | Epoch[162/200] Iteration[020/030] Train loss: 0.0193
2023-02-06 16:21:51 | Train | Epoch[162/200] Iteration[021/030] Train loss: 0.0192
2023-02-06 16:21:51 | Train | Epoch[162/200] Iteration[022/030] Train loss: 0.0193
2023-02-06 16:21:52 | Train | Epoch[162/200] Iteration[023/030] Train loss: 0.0193
2023-02-06 16:21:52 | Train | Epoch[162/200] Iteration[024/030] Train loss: 0.0193
2023-02-06 16:21:53 | Train | Epoch[162/200] Iteration[025/030] Train loss: 0.0192
2023-02-06 16:21:53 | Train | Epoch[162/200] Iteration[026/030] Train loss: 0.0192
2023-02-06 16:21:53 | Train | Epoch[162/200] Iteration[027/030] Train loss: 0.0193
2023-02-06 16:21:54 | Train | Epoch[162/200] Iteration[028/030] Train loss: 0.0193
2023-02-06 16:21:54 | Train | Epoch[162/200] Iteration[029/030] Train loss: 0.0193
2023-02-06 16:21:54 | Train | Epoch[162/200] Iteration[030/030] Train loss: 0.0193
2023-02-06 16:21:55 | Valid | Epoch[162/200] Iteration[001/008] Valid loss: 0.2420
2023-02-06 16:21:55 | Valid | Epoch[162/200] Iteration[002/008] Valid loss: 0.1871
2023-02-06 16:21:55 | Valid | Epoch[162/200] Iteration[003/008] Valid loss: 0.1533
2023-02-06 16:21:55 | Valid | Epoch[162/200] Iteration[004/008] Valid loss: 0.1527
2023-02-06 16:21:55 | Valid | Epoch[162/200] Iteration[005/008] Valid loss: 0.1542
2023-02-06 16:21:55 | Valid | Epoch[162/200] Iteration[006/008] Valid loss: 0.1509
2023-02-06 16:21:55 | Valid | Epoch[162/200] Iteration[007/008] Valid loss: 0.1654
2023-02-06 16:21:55 | Valid | Epoch[162/200] Iteration[008/008] Valid loss: 0.1656
2023-02-06 16:21:56 | Valid | Epoch[162/200] MIou: 0.930291123430151
2023-02-06 16:21:56 | Valid | Epoch[162/200] Pixel Accuracy: 0.9875373840332031
2023-02-06 16:21:56 | Valid | Epoch[162/200] Mean Pixel Accuracy: 0.9747372854758531
2023-02-06 16:21:56 | Stage | Epoch[162/200] Train loss:0.0193
2023-02-06 16:21:56 | Stage | Epoch[162/200] Valid loss:0.1656
2023-02-06 16:21:56 | Stage | Epoch[162/200] LR:0.01

2023-02-06 16:21:56 | Train | Epoch[163/200] Iteration[001/030] Train loss: 0.0189
2023-02-06 16:21:57 | Train | Epoch[163/200] Iteration[002/030] Train loss: 0.0189
2023-02-06 16:21:57 | Train | Epoch[163/200] Iteration[003/030] Train loss: 0.0188
2023-02-06 16:21:58 | Train | Epoch[163/200] Iteration[004/030] Train loss: 0.0191
2023-02-06 16:21:58 | Train | Epoch[163/200] Iteration[005/030] Train loss: 0.0190
2023-02-06 16:21:58 | Train | Epoch[163/200] Iteration[006/030] Train loss: 0.0188
2023-02-06 16:21:59 | Train | Epoch[163/200] Iteration[007/030] Train loss: 0.0188
2023-02-06 16:21:59 | Train | Epoch[163/200] Iteration[008/030] Train loss: 0.0188
2023-02-06 16:22:00 | Train | Epoch[163/200] Iteration[009/030] Train loss: 0.0188
2023-02-06 16:22:00 | Train | Epoch[163/200] Iteration[010/030] Train loss: 0.0188
2023-02-06 16:22:01 | Train | Epoch[163/200] Iteration[011/030] Train loss: 0.0188
2023-02-06 16:22:01 | Train | Epoch[163/200] Iteration[012/030] Train loss: 0.0187
2023-02-06 16:22:02 | Train | Epoch[163/200] Iteration[013/030] Train loss: 0.0187
2023-02-06 16:22:02 | Train | Epoch[163/200] Iteration[014/030] Train loss: 0.0187
2023-02-06 16:22:02 | Train | Epoch[163/200] Iteration[015/030] Train loss: 0.0186
2023-02-06 16:22:03 | Train | Epoch[163/200] Iteration[016/030] Train loss: 0.0187
2023-02-06 16:22:03 | Train | Epoch[163/200] Iteration[017/030] Train loss: 0.0187
2023-02-06 16:22:04 | Train | Epoch[163/200] Iteration[018/030] Train loss: 0.0187
2023-02-06 16:22:04 | Train | Epoch[163/200] Iteration[019/030] Train loss: 0.0187
2023-02-06 16:22:05 | Train | Epoch[163/200] Iteration[020/030] Train loss: 0.0186
2023-02-06 16:22:05 | Train | Epoch[163/200] Iteration[021/030] Train loss: 0.0186
2023-02-06 16:22:05 | Train | Epoch[163/200] Iteration[022/030] Train loss: 0.0186
2023-02-06 16:22:06 | Train | Epoch[163/200] Iteration[023/030] Train loss: 0.0186
2023-02-06 16:22:06 | Train | Epoch[163/200] Iteration[024/030] Train loss: 0.0186
2023-02-06 16:22:07 | Train | Epoch[163/200] Iteration[025/030] Train loss: 0.0186
2023-02-06 16:22:07 | Train | Epoch[163/200] Iteration[026/030] Train loss: 0.0186
2023-02-06 16:22:08 | Train | Epoch[163/200] Iteration[027/030] Train loss: 0.0187
2023-02-06 16:22:08 | Train | Epoch[163/200] Iteration[028/030] Train loss: 0.0188
2023-02-06 16:22:08 | Train | Epoch[163/200] Iteration[029/030] Train loss: 0.0188
2023-02-06 16:22:09 | Train | Epoch[163/200] Iteration[030/030] Train loss: 0.0188
2023-02-06 16:22:09 | Valid | Epoch[163/200] Iteration[001/008] Valid loss: 0.0993
2023-02-06 16:22:09 | Valid | Epoch[163/200] Iteration[002/008] Valid loss: 0.0703
2023-02-06 16:22:09 | Valid | Epoch[163/200] Iteration[003/008] Valid loss: 0.0616
2023-02-06 16:22:09 | Valid | Epoch[163/200] Iteration[004/008] Valid loss: 0.0558
2023-02-06 16:22:09 | Valid | Epoch[163/200] Iteration[005/008] Valid loss: 0.0566
2023-02-06 16:22:10 | Valid | Epoch[163/200] Iteration[006/008] Valid loss: 0.0552
2023-02-06 16:22:10 | Valid | Epoch[163/200] Iteration[007/008] Valid loss: 0.0542
2023-02-06 16:22:10 | Valid | Epoch[163/200] Iteration[008/008] Valid loss: 0.0527
2023-02-06 16:22:10 | Valid | Epoch[163/200] MIou: 0.9154224346419227
2023-02-06 16:22:10 | Valid | Epoch[163/200] Pixel Accuracy: 0.9858907063802084
2023-02-06 16:22:10 | Valid | Epoch[163/200] Mean Pixel Accuracy: 0.9287958320583609
2023-02-06 16:22:10 | Stage | Epoch[163/200] Train loss:0.0188
2023-02-06 16:22:10 | Stage | Epoch[163/200] Valid loss:0.0527
2023-02-06 16:22:10 | Stage | Epoch[163/200] LR:0.01

2023-02-06 16:22:11 | Train | Epoch[164/200] Iteration[001/030] Train loss: 0.0207
2023-02-06 16:22:11 | Train | Epoch[164/200] Iteration[002/030] Train loss: 0.0197
2023-02-06 16:22:11 | Train | Epoch[164/200] Iteration[003/030] Train loss: 0.0194
2023-02-06 16:22:12 | Train | Epoch[164/200] Iteration[004/030] Train loss: 0.0194
2023-02-06 16:22:12 | Train | Epoch[164/200] Iteration[005/030] Train loss: 0.0195
2023-02-06 16:22:13 | Train | Epoch[164/200] Iteration[006/030] Train loss: 0.0194
2023-02-06 16:22:13 | Train | Epoch[164/200] Iteration[007/030] Train loss: 0.0195
2023-02-06 16:22:14 | Train | Epoch[164/200] Iteration[008/030] Train loss: 0.0201
2023-02-06 16:22:14 | Train | Epoch[164/200] Iteration[009/030] Train loss: 0.0198
2023-02-06 16:22:14 | Train | Epoch[164/200] Iteration[010/030] Train loss: 0.0197
2023-02-06 16:22:15 | Train | Epoch[164/200] Iteration[011/030] Train loss: 0.0198
2023-02-06 16:22:15 | Train | Epoch[164/200] Iteration[012/030] Train loss: 0.0198
2023-02-06 16:22:16 | Train | Epoch[164/200] Iteration[013/030] Train loss: 0.0199
2023-02-06 16:22:16 | Train | Epoch[164/200] Iteration[014/030] Train loss: 0.0199
2023-02-06 16:22:17 | Train | Epoch[164/200] Iteration[015/030] Train loss: 0.0201
2023-02-06 16:22:17 | Train | Epoch[164/200] Iteration[016/030] Train loss: 0.0201
2023-02-06 16:22:17 | Train | Epoch[164/200] Iteration[017/030] Train loss: 0.0202
2023-02-06 16:22:18 | Train | Epoch[164/200] Iteration[018/030] Train loss: 0.0202
2023-02-06 16:22:18 | Train | Epoch[164/200] Iteration[019/030] Train loss: 0.0203
2023-02-06 16:22:19 | Train | Epoch[164/200] Iteration[020/030] Train loss: 0.0203
2023-02-06 16:22:19 | Train | Epoch[164/200] Iteration[021/030] Train loss: 0.0203
2023-02-06 16:22:20 | Train | Epoch[164/200] Iteration[022/030] Train loss: 0.0203
2023-02-06 16:22:20 | Train | Epoch[164/200] Iteration[023/030] Train loss: 0.0204
2023-02-06 16:22:20 | Train | Epoch[164/200] Iteration[024/030] Train loss: 0.0205
2023-02-06 16:22:21 | Train | Epoch[164/200] Iteration[025/030] Train loss: 0.0205
2023-02-06 16:22:21 | Train | Epoch[164/200] Iteration[026/030] Train loss: 0.0204
2023-02-06 16:22:22 | Train | Epoch[164/200] Iteration[027/030] Train loss: 0.0204
2023-02-06 16:22:22 | Train | Epoch[164/200] Iteration[028/030] Train loss: 0.0206
2023-02-06 16:22:23 | Train | Epoch[164/200] Iteration[029/030] Train loss: 0.0206
2023-02-06 16:22:23 | Train | Epoch[164/200] Iteration[030/030] Train loss: 0.0206
2023-02-06 16:22:23 | Valid | Epoch[164/200] Iteration[001/008] Valid loss: 1.4473
2023-02-06 16:22:23 | Valid | Epoch[164/200] Iteration[002/008] Valid loss: 1.4781
2023-02-06 16:22:24 | Valid | Epoch[164/200] Iteration[003/008] Valid loss: 1.4331
2023-02-06 16:22:24 | Valid | Epoch[164/200] Iteration[004/008] Valid loss: 1.4983
2023-02-06 16:22:24 | Valid | Epoch[164/200] Iteration[005/008] Valid loss: 1.5224
2023-02-06 16:22:24 | Valid | Epoch[164/200] Iteration[006/008] Valid loss: 1.5184
2023-02-06 16:22:24 | Valid | Epoch[164/200] Iteration[007/008] Valid loss: 1.5742
2023-02-06 16:22:24 | Valid | Epoch[164/200] Iteration[008/008] Valid loss: 1.6143
2023-02-06 16:22:24 | Valid | Epoch[164/200] MIou: 0.8132639439429439
2023-02-06 16:22:24 | Valid | Epoch[164/200] Pixel Accuracy: 0.9565137227376302
2023-02-06 16:22:24 | Valid | Epoch[164/200] Mean Pixel Accuracy: 0.9746968431675636
2023-02-06 16:22:24 | Stage | Epoch[164/200] Train loss:0.0206
2023-02-06 16:22:24 | Stage | Epoch[164/200] Valid loss:1.6143
2023-02-06 16:22:24 | Stage | Epoch[164/200] LR:0.01

2023-02-06 16:22:25 | Train | Epoch[165/200] Iteration[001/030] Train loss: 0.0204
2023-02-06 16:22:25 | Train | Epoch[165/200] Iteration[002/030] Train loss: 0.0215
2023-02-06 16:22:26 | Train | Epoch[165/200] Iteration[003/030] Train loss: 0.0209
2023-02-06 16:22:26 | Train | Epoch[165/200] Iteration[004/030] Train loss: 0.0207
2023-02-06 16:22:27 | Train | Epoch[165/200] Iteration[005/030] Train loss: 0.0207
2023-02-06 16:22:27 | Train | Epoch[165/200] Iteration[006/030] Train loss: 0.0205
2023-02-06 16:22:27 | Train | Epoch[165/200] Iteration[007/030] Train loss: 0.0204
2023-02-06 16:22:28 | Train | Epoch[165/200] Iteration[008/030] Train loss: 0.0206
2023-02-06 16:22:28 | Train | Epoch[165/200] Iteration[009/030] Train loss: 0.0205
2023-02-06 16:22:29 | Train | Epoch[165/200] Iteration[010/030] Train loss: 0.0205
2023-02-06 16:22:29 | Train | Epoch[165/200] Iteration[011/030] Train loss: 0.0205
2023-02-06 16:22:30 | Train | Epoch[165/200] Iteration[012/030] Train loss: 0.0204
2023-02-06 16:22:30 | Train | Epoch[165/200] Iteration[013/030] Train loss: 0.0203
2023-02-06 16:22:31 | Train | Epoch[165/200] Iteration[014/030] Train loss: 0.0202
2023-02-06 16:22:31 | Train | Epoch[165/200] Iteration[015/030] Train loss: 0.0202
2023-02-06 16:22:31 | Train | Epoch[165/200] Iteration[016/030] Train loss: 0.0202
2023-02-06 16:22:32 | Train | Epoch[165/200] Iteration[017/030] Train loss: 0.0204
2023-02-06 16:22:32 | Train | Epoch[165/200] Iteration[018/030] Train loss: 0.0204
2023-02-06 16:22:33 | Train | Epoch[165/200] Iteration[019/030] Train loss: 0.0204
2023-02-06 16:22:33 | Train | Epoch[165/200] Iteration[020/030] Train loss: 0.0203
2023-02-06 16:22:34 | Train | Epoch[165/200] Iteration[021/030] Train loss: 0.0203
2023-02-06 16:22:34 | Train | Epoch[165/200] Iteration[022/030] Train loss: 0.0203
2023-02-06 16:22:34 | Train | Epoch[165/200] Iteration[023/030] Train loss: 0.0203
2023-02-06 16:22:35 | Train | Epoch[165/200] Iteration[024/030] Train loss: 0.0202
2023-02-06 16:22:35 | Train | Epoch[165/200] Iteration[025/030] Train loss: 0.0202
2023-02-06 16:22:36 | Train | Epoch[165/200] Iteration[026/030] Train loss: 0.0202
2023-02-06 16:22:36 | Train | Epoch[165/200] Iteration[027/030] Train loss: 0.0203
2023-02-06 16:22:37 | Train | Epoch[165/200] Iteration[028/030] Train loss: 0.0203
2023-02-06 16:22:37 | Train | Epoch[165/200] Iteration[029/030] Train loss: 0.0203
2023-02-06 16:22:37 | Train | Epoch[165/200] Iteration[030/030] Train loss: 0.0204
2023-02-06 16:22:38 | Valid | Epoch[165/200] Iteration[001/008] Valid loss: 0.5362
2023-02-06 16:22:38 | Valid | Epoch[165/200] Iteration[002/008] Valid loss: 0.4502
2023-02-06 16:22:38 | Valid | Epoch[165/200] Iteration[003/008] Valid loss: 0.4505
2023-02-06 16:22:38 | Valid | Epoch[165/200] Iteration[004/008] Valid loss: 0.4534
2023-02-06 16:22:38 | Valid | Epoch[165/200] Iteration[005/008] Valid loss: 0.4674
2023-02-06 16:22:38 | Valid | Epoch[165/200] Iteration[006/008] Valid loss: 0.4522
2023-02-06 16:22:38 | Valid | Epoch[165/200] Iteration[007/008] Valid loss: 0.4833
2023-02-06 16:22:38 | Valid | Epoch[165/200] Iteration[008/008] Valid loss: 0.4879
2023-02-06 16:22:38 | Valid | Epoch[165/200] MIou: 0.871430654238124
2023-02-06 16:22:38 | Valid | Epoch[165/200] Pixel Accuracy: 0.9739913940429688
2023-02-06 16:22:38 | Valid | Epoch[165/200] Mean Pixel Accuracy: 0.9729031489429107
2023-02-06 16:22:38 | Stage | Epoch[165/200] Train loss:0.0204
2023-02-06 16:22:38 | Stage | Epoch[165/200] Valid loss:0.4879
2023-02-06 16:22:38 | Stage | Epoch[165/200] LR:0.01

2023-02-06 16:22:39 | Train | Epoch[166/200] Iteration[001/030] Train loss: 0.0183
2023-02-06 16:22:40 | Train | Epoch[166/200] Iteration[002/030] Train loss: 0.0185
2023-02-06 16:22:40 | Train | Epoch[166/200] Iteration[003/030] Train loss: 0.0186
2023-02-06 16:22:40 | Train | Epoch[166/200] Iteration[004/030] Train loss: 0.0184
2023-02-06 16:22:41 | Train | Epoch[166/200] Iteration[005/030] Train loss: 0.0188
2023-02-06 16:22:41 | Train | Epoch[166/200] Iteration[006/030] Train loss: 0.0190
2023-02-06 16:22:42 | Train | Epoch[166/200] Iteration[007/030] Train loss: 0.0190
2023-02-06 16:22:42 | Train | Epoch[166/200] Iteration[008/030] Train loss: 0.0190
2023-02-06 16:22:43 | Train | Epoch[166/200] Iteration[009/030] Train loss: 0.0189
2023-02-06 16:22:43 | Train | Epoch[166/200] Iteration[010/030] Train loss: 0.0191
2023-02-06 16:22:43 | Train | Epoch[166/200] Iteration[011/030] Train loss: 0.0191
2023-02-06 16:22:44 | Train | Epoch[166/200] Iteration[012/030] Train loss: 0.0190
2023-02-06 16:22:44 | Train | Epoch[166/200] Iteration[013/030] Train loss: 0.0190
2023-02-06 16:22:45 | Train | Epoch[166/200] Iteration[014/030] Train loss: 0.0191
2023-02-06 16:22:45 | Train | Epoch[166/200] Iteration[015/030] Train loss: 0.0192
2023-02-06 16:22:46 | Train | Epoch[166/200] Iteration[016/030] Train loss: 0.0194
2023-02-06 16:22:46 | Train | Epoch[166/200] Iteration[017/030] Train loss: 0.0193
2023-02-06 16:22:47 | Train | Epoch[166/200] Iteration[018/030] Train loss: 0.0194
2023-02-06 16:22:47 | Train | Epoch[166/200] Iteration[019/030] Train loss: 0.0195
2023-02-06 16:22:47 | Train | Epoch[166/200] Iteration[020/030] Train loss: 0.0195
2023-02-06 16:22:48 | Train | Epoch[166/200] Iteration[021/030] Train loss: 0.0195
2023-02-06 16:22:48 | Train | Epoch[166/200] Iteration[022/030] Train loss: 0.0195
2023-02-06 16:22:49 | Train | Epoch[166/200] Iteration[023/030] Train loss: 0.0195
2023-02-06 16:22:49 | Train | Epoch[166/200] Iteration[024/030] Train loss: 0.0195
2023-02-06 16:22:50 | Train | Epoch[166/200] Iteration[025/030] Train loss: 0.0195
2023-02-06 16:22:50 | Train | Epoch[166/200] Iteration[026/030] Train loss: 0.0195
2023-02-06 16:22:50 | Train | Epoch[166/200] Iteration[027/030] Train loss: 0.0195
2023-02-06 16:22:51 | Train | Epoch[166/200] Iteration[028/030] Train loss: 0.0195
2023-02-06 16:22:51 | Train | Epoch[166/200] Iteration[029/030] Train loss: 0.0195
2023-02-06 16:22:51 | Train | Epoch[166/200] Iteration[030/030] Train loss: 0.0195
2023-02-06 16:22:52 | Valid | Epoch[166/200] Iteration[001/008] Valid loss: 0.4602
2023-02-06 16:22:52 | Valid | Epoch[166/200] Iteration[002/008] Valid loss: 0.3899
2023-02-06 16:22:52 | Valid | Epoch[166/200] Iteration[003/008] Valid loss: 0.3530
2023-02-06 16:22:52 | Valid | Epoch[166/200] Iteration[004/008] Valid loss: 0.3553
2023-02-06 16:22:52 | Valid | Epoch[166/200] Iteration[005/008] Valid loss: 0.3632
2023-02-06 16:22:52 | Valid | Epoch[166/200] Iteration[006/008] Valid loss: 0.3619
2023-02-06 16:22:52 | Valid | Epoch[166/200] Iteration[007/008] Valid loss: 0.3808
2023-02-06 16:22:53 | Valid | Epoch[166/200] Iteration[008/008] Valid loss: 0.3688
2023-02-06 16:22:53 | Valid | Epoch[166/200] MIou: 0.8903447567879217
2023-02-06 16:22:53 | Valid | Epoch[166/200] Pixel Accuracy: 0.9787000020345052
2023-02-06 16:22:53 | Valid | Epoch[166/200] Mean Pixel Accuracy: 0.9736905068029024
2023-02-06 16:22:53 | Stage | Epoch[166/200] Train loss:0.0195
2023-02-06 16:22:53 | Stage | Epoch[166/200] Valid loss:0.3688
2023-02-06 16:22:53 | Stage | Epoch[166/200] LR:0.01

2023-02-06 16:22:53 | Train | Epoch[167/200] Iteration[001/030] Train loss: 0.0189
2023-02-06 16:22:54 | Train | Epoch[167/200] Iteration[002/030] Train loss: 0.0189
2023-02-06 16:22:54 | Train | Epoch[167/200] Iteration[003/030] Train loss: 0.0184
2023-02-06 16:22:55 | Train | Epoch[167/200] Iteration[004/030] Train loss: 0.0181
2023-02-06 16:22:55 | Train | Epoch[167/200] Iteration[005/030] Train loss: 0.0180
2023-02-06 16:22:55 | Train | Epoch[167/200] Iteration[006/030] Train loss: 0.0181
2023-02-06 16:22:56 | Train | Epoch[167/200] Iteration[007/030] Train loss: 0.0184
2023-02-06 16:22:56 | Train | Epoch[167/200] Iteration[008/030] Train loss: 0.0184
2023-02-06 16:22:57 | Train | Epoch[167/200] Iteration[009/030] Train loss: 0.0182
2023-02-06 16:22:57 | Train | Epoch[167/200] Iteration[010/030] Train loss: 0.0181
2023-02-06 16:22:58 | Train | Epoch[167/200] Iteration[011/030] Train loss: 0.0183
2023-02-06 16:22:58 | Train | Epoch[167/200] Iteration[012/030] Train loss: 0.0183
2023-02-06 16:22:59 | Train | Epoch[167/200] Iteration[013/030] Train loss: 0.0184
2023-02-06 16:22:59 | Train | Epoch[167/200] Iteration[014/030] Train loss: 0.0184
2023-02-06 16:22:59 | Train | Epoch[167/200] Iteration[015/030] Train loss: 0.0185
2023-02-06 16:23:00 | Train | Epoch[167/200] Iteration[016/030] Train loss: 0.0185
2023-02-06 16:23:00 | Train | Epoch[167/200] Iteration[017/030] Train loss: 0.0185
2023-02-06 16:23:01 | Train | Epoch[167/200] Iteration[018/030] Train loss: 0.0185
2023-02-06 16:23:01 | Train | Epoch[167/200] Iteration[019/030] Train loss: 0.0185
2023-02-06 16:23:02 | Train | Epoch[167/200] Iteration[020/030] Train loss: 0.0184
2023-02-06 16:23:02 | Train | Epoch[167/200] Iteration[021/030] Train loss: 0.0184
2023-02-06 16:23:02 | Train | Epoch[167/200] Iteration[022/030] Train loss: 0.0185
2023-02-06 16:23:03 | Train | Epoch[167/200] Iteration[023/030] Train loss: 0.0185
2023-02-06 16:23:03 | Train | Epoch[167/200] Iteration[024/030] Train loss: 0.0185
2023-02-06 16:23:04 | Train | Epoch[167/200] Iteration[025/030] Train loss: 0.0185
2023-02-06 16:23:04 | Train | Epoch[167/200] Iteration[026/030] Train loss: 0.0185
2023-02-06 16:23:05 | Train | Epoch[167/200] Iteration[027/030] Train loss: 0.0185
2023-02-06 16:23:05 | Train | Epoch[167/200] Iteration[028/030] Train loss: 0.0186
2023-02-06 16:23:05 | Train | Epoch[167/200] Iteration[029/030] Train loss: 0.0186
2023-02-06 16:23:06 | Train | Epoch[167/200] Iteration[030/030] Train loss: 0.0186
2023-02-06 16:23:06 | Valid | Epoch[167/200] Iteration[001/008] Valid loss: 0.3650
2023-02-06 16:23:06 | Valid | Epoch[167/200] Iteration[002/008] Valid loss: 0.3229
2023-02-06 16:23:06 | Valid | Epoch[167/200] Iteration[003/008] Valid loss: 0.3081
2023-02-06 16:23:06 | Valid | Epoch[167/200] Iteration[004/008] Valid loss: 0.3041
2023-02-06 16:23:06 | Valid | Epoch[167/200] Iteration[005/008] Valid loss: 0.3194
2023-02-06 16:23:07 | Valid | Epoch[167/200] Iteration[006/008] Valid loss: 0.3153
2023-02-06 16:23:07 | Valid | Epoch[167/200] Iteration[007/008] Valid loss: 0.3426
2023-02-06 16:23:07 | Valid | Epoch[167/200] Iteration[008/008] Valid loss: 0.3423
2023-02-06 16:23:07 | Valid | Epoch[167/200] MIou: 0.9054164305352239
2023-02-06 16:23:07 | Valid | Epoch[167/200] Pixel Accuracy: 0.9820060729980469
2023-02-06 16:23:07 | Valid | Epoch[167/200] Mean Pixel Accuracy: 0.9795845875872484
2023-02-06 16:23:07 | Stage | Epoch[167/200] Train loss:0.0186
2023-02-06 16:23:07 | Stage | Epoch[167/200] Valid loss:0.3423
2023-02-06 16:23:07 | Stage | Epoch[167/200] LR:0.01

2023-02-06 16:23:08 | Train | Epoch[168/200] Iteration[001/030] Train loss: 0.0180
2023-02-06 16:23:08 | Train | Epoch[168/200] Iteration[002/030] Train loss: 0.0184
2023-02-06 16:23:08 | Train | Epoch[168/200] Iteration[003/030] Train loss: 0.0182
2023-02-06 16:23:09 | Train | Epoch[168/200] Iteration[004/030] Train loss: 0.0181
2023-02-06 16:23:09 | Train | Epoch[168/200] Iteration[005/030] Train loss: 0.0180
2023-02-06 16:23:10 | Train | Epoch[168/200] Iteration[006/030] Train loss: 0.0181
2023-02-06 16:23:10 | Train | Epoch[168/200] Iteration[007/030] Train loss: 0.0180
2023-02-06 16:23:11 | Train | Epoch[168/200] Iteration[008/030] Train loss: 0.0179
2023-02-06 16:23:11 | Train | Epoch[168/200] Iteration[009/030] Train loss: 0.0179
2023-02-06 16:23:11 | Train | Epoch[168/200] Iteration[010/030] Train loss: 0.0178
2023-02-06 16:23:12 | Train | Epoch[168/200] Iteration[011/030] Train loss: 0.0178
2023-02-06 16:23:12 | Train | Epoch[168/200] Iteration[012/030] Train loss: 0.0178
2023-02-06 16:23:13 | Train | Epoch[168/200] Iteration[013/030] Train loss: 0.0179
2023-02-06 16:23:13 | Train | Epoch[168/200] Iteration[014/030] Train loss: 0.0179
2023-02-06 16:23:14 | Train | Epoch[168/200] Iteration[015/030] Train loss: 0.0179
2023-02-06 16:23:14 | Train | Epoch[168/200] Iteration[016/030] Train loss: 0.0179
2023-02-06 16:23:15 | Train | Epoch[168/200] Iteration[017/030] Train loss: 0.0179
2023-02-06 16:23:15 | Train | Epoch[168/200] Iteration[018/030] Train loss: 0.0179
2023-02-06 16:23:15 | Train | Epoch[168/200] Iteration[019/030] Train loss: 0.0179
2023-02-06 16:23:16 | Train | Epoch[168/200] Iteration[020/030] Train loss: 0.0180
2023-02-06 16:23:16 | Train | Epoch[168/200] Iteration[021/030] Train loss: 0.0180
2023-02-06 16:23:17 | Train | Epoch[168/200] Iteration[022/030] Train loss: 0.0180
2023-02-06 16:23:17 | Train | Epoch[168/200] Iteration[023/030] Train loss: 0.0181
2023-02-06 16:23:18 | Train | Epoch[168/200] Iteration[024/030] Train loss: 0.0182
2023-02-06 16:23:18 | Train | Epoch[168/200] Iteration[025/030] Train loss: 0.0182
2023-02-06 16:23:18 | Train | Epoch[168/200] Iteration[026/030] Train loss: 0.0182
2023-02-06 16:23:19 | Train | Epoch[168/200] Iteration[027/030] Train loss: 0.0182
2023-02-06 16:23:19 | Train | Epoch[168/200] Iteration[028/030] Train loss: 0.0182
2023-02-06 16:23:20 | Train | Epoch[168/200] Iteration[029/030] Train loss: 0.0182
2023-02-06 16:23:20 | Train | Epoch[168/200] Iteration[030/030] Train loss: 0.0183
2023-02-06 16:23:20 | Valid | Epoch[168/200] Iteration[001/008] Valid loss: 0.3032
2023-02-06 16:23:20 | Valid | Epoch[168/200] Iteration[002/008] Valid loss: 0.2439
2023-02-06 16:23:21 | Valid | Epoch[168/200] Iteration[003/008] Valid loss: 0.2143
2023-02-06 16:23:21 | Valid | Epoch[168/200] Iteration[004/008] Valid loss: 0.2080
2023-02-06 16:23:21 | Valid | Epoch[168/200] Iteration[005/008] Valid loss: 0.2161
2023-02-06 16:23:21 | Valid | Epoch[168/200] Iteration[006/008] Valid loss: 0.2108
2023-02-06 16:23:21 | Valid | Epoch[168/200] Iteration[007/008] Valid loss: 0.2308
2023-02-06 16:23:21 | Valid | Epoch[168/200] Iteration[008/008] Valid loss: 0.2317
2023-02-06 16:23:21 | Valid | Epoch[168/200] MIou: 0.9191776096261742
2023-02-06 16:23:21 | Valid | Epoch[168/200] Pixel Accuracy: 0.985192616780599
2023-02-06 16:23:21 | Valid | Epoch[168/200] Mean Pixel Accuracy: 0.9753823452031015
2023-02-06 16:23:21 | Stage | Epoch[168/200] Train loss:0.0183
2023-02-06 16:23:21 | Stage | Epoch[168/200] Valid loss:0.2317
2023-02-06 16:23:21 | Stage | Epoch[168/200] LR:0.01

2023-02-06 16:23:22 | Train | Epoch[169/200] Iteration[001/030] Train loss: 0.0176
2023-02-06 16:23:22 | Train | Epoch[169/200] Iteration[002/030] Train loss: 0.0180
2023-02-06 16:23:23 | Train | Epoch[169/200] Iteration[003/030] Train loss: 0.0182
2023-02-06 16:23:23 | Train | Epoch[169/200] Iteration[004/030] Train loss: 0.0179
2023-02-06 16:23:24 | Train | Epoch[169/200] Iteration[005/030] Train loss: 0.0178
2023-02-06 16:23:24 | Train | Epoch[169/200] Iteration[006/030] Train loss: 0.0182
2023-02-06 16:23:24 | Train | Epoch[169/200] Iteration[007/030] Train loss: 0.0182
2023-02-06 16:23:25 | Train | Epoch[169/200] Iteration[008/030] Train loss: 0.0181
2023-02-06 16:23:25 | Train | Epoch[169/200] Iteration[009/030] Train loss: 0.0181
2023-02-06 16:23:26 | Train | Epoch[169/200] Iteration[010/030] Train loss: 0.0180
2023-02-06 16:23:26 | Train | Epoch[169/200] Iteration[011/030] Train loss: 0.0180
2023-02-06 16:23:27 | Train | Epoch[169/200] Iteration[012/030] Train loss: 0.0180
2023-02-06 16:23:27 | Train | Epoch[169/200] Iteration[013/030] Train loss: 0.0180
2023-02-06 16:23:27 | Train | Epoch[169/200] Iteration[014/030] Train loss: 0.0181
2023-02-06 16:23:28 | Train | Epoch[169/200] Iteration[015/030] Train loss: 0.0181
2023-02-06 16:23:28 | Train | Epoch[169/200] Iteration[016/030] Train loss: 0.0180
2023-02-06 16:23:29 | Train | Epoch[169/200] Iteration[017/030] Train loss: 0.0180
2023-02-06 16:23:29 | Train | Epoch[169/200] Iteration[018/030] Train loss: 0.0180
2023-02-06 16:23:30 | Train | Epoch[169/200] Iteration[019/030] Train loss: 0.0180
2023-02-06 16:23:30 | Train | Epoch[169/200] Iteration[020/030] Train loss: 0.0180
2023-02-06 16:23:31 | Train | Epoch[169/200] Iteration[021/030] Train loss: 0.0180
2023-02-06 16:23:31 | Train | Epoch[169/200] Iteration[022/030] Train loss: 0.0180
2023-02-06 16:23:31 | Train | Epoch[169/200] Iteration[023/030] Train loss: 0.0180
2023-02-06 16:23:32 | Train | Epoch[169/200] Iteration[024/030] Train loss: 0.0180
2023-02-06 16:23:32 | Train | Epoch[169/200] Iteration[025/030] Train loss: 0.0180
2023-02-06 16:23:33 | Train | Epoch[169/200] Iteration[026/030] Train loss: 0.0180
2023-02-06 16:23:33 | Train | Epoch[169/200] Iteration[027/030] Train loss: 0.0179
2023-02-06 16:23:34 | Train | Epoch[169/200] Iteration[028/030] Train loss: 0.0179
2023-02-06 16:23:34 | Train | Epoch[169/200] Iteration[029/030] Train loss: 0.0179
2023-02-06 16:23:34 | Train | Epoch[169/200] Iteration[030/030] Train loss: 0.0179
2023-02-06 16:23:35 | Valid | Epoch[169/200] Iteration[001/008] Valid loss: 0.4650
2023-02-06 16:23:35 | Valid | Epoch[169/200] Iteration[002/008] Valid loss: 0.3896
2023-02-06 16:23:35 | Valid | Epoch[169/200] Iteration[003/008] Valid loss: 0.3609
2023-02-06 16:23:35 | Valid | Epoch[169/200] Iteration[004/008] Valid loss: 0.3638
2023-02-06 16:23:35 | Valid | Epoch[169/200] Iteration[005/008] Valid loss: 0.3723
2023-02-06 16:23:35 | Valid | Epoch[169/200] Iteration[006/008] Valid loss: 0.3624
2023-02-06 16:23:35 | Valid | Epoch[169/200] Iteration[007/008] Valid loss: 0.3869
2023-02-06 16:23:35 | Valid | Epoch[169/200] Iteration[008/008] Valid loss: 0.3978
2023-02-06 16:23:35 | Valid | Epoch[169/200] MIou: 0.8924782337941222
2023-02-06 16:23:35 | Valid | Epoch[169/200] Pixel Accuracy: 0.9789861043294271
2023-02-06 16:23:35 | Valid | Epoch[169/200] Mean Pixel Accuracy: 0.979078649823625
2023-02-06 16:23:35 | Stage | Epoch[169/200] Train loss:0.0179
2023-02-06 16:23:35 | Stage | Epoch[169/200] Valid loss:0.3978
2023-02-06 16:23:35 | Stage | Epoch[169/200] LR:0.01

2023-02-06 16:23:36 | Train | Epoch[170/200] Iteration[001/030] Train loss: 0.0165
2023-02-06 16:23:37 | Train | Epoch[170/200] Iteration[002/030] Train loss: 0.0172
2023-02-06 16:23:37 | Train | Epoch[170/200] Iteration[003/030] Train loss: 0.0169
2023-02-06 16:23:37 | Train | Epoch[170/200] Iteration[004/030] Train loss: 0.0168
2023-02-06 16:23:38 | Train | Epoch[170/200] Iteration[005/030] Train loss: 0.0169
2023-02-06 16:23:38 | Train | Epoch[170/200] Iteration[006/030] Train loss: 0.0171
2023-02-06 16:23:39 | Train | Epoch[170/200] Iteration[007/030] Train loss: 0.0172
2023-02-06 16:23:39 | Train | Epoch[170/200] Iteration[008/030] Train loss: 0.0171
2023-02-06 16:23:40 | Train | Epoch[170/200] Iteration[009/030] Train loss: 0.0171
2023-02-06 16:23:40 | Train | Epoch[170/200] Iteration[010/030] Train loss: 0.0172
2023-02-06 16:23:40 | Train | Epoch[170/200] Iteration[011/030] Train loss: 0.0171
2023-02-06 16:23:41 | Train | Epoch[170/200] Iteration[012/030] Train loss: 0.0171
2023-02-06 16:23:41 | Train | Epoch[170/200] Iteration[013/030] Train loss: 0.0172
2023-02-06 16:23:42 | Train | Epoch[170/200] Iteration[014/030] Train loss: 0.0172
2023-02-06 16:23:42 | Train | Epoch[170/200] Iteration[015/030] Train loss: 0.0172
2023-02-06 16:23:43 | Train | Epoch[170/200] Iteration[016/030] Train loss: 0.0172
2023-02-06 16:23:43 | Train | Epoch[170/200] Iteration[017/030] Train loss: 0.0171
2023-02-06 16:23:43 | Train | Epoch[170/200] Iteration[018/030] Train loss: 0.0174
2023-02-06 16:23:44 | Train | Epoch[170/200] Iteration[019/030] Train loss: 0.0174
2023-02-06 16:23:44 | Train | Epoch[170/200] Iteration[020/030] Train loss: 0.0174
2023-02-06 16:23:45 | Train | Epoch[170/200] Iteration[021/030] Train loss: 0.0174
2023-02-06 16:23:45 | Train | Epoch[170/200] Iteration[022/030] Train loss: 0.0173
2023-02-06 16:23:46 | Train | Epoch[170/200] Iteration[023/030] Train loss: 0.0174
2023-02-06 16:23:46 | Train | Epoch[170/200] Iteration[024/030] Train loss: 0.0174
2023-02-06 16:23:47 | Train | Epoch[170/200] Iteration[025/030] Train loss: 0.0174
2023-02-06 16:23:47 | Train | Epoch[170/200] Iteration[026/030] Train loss: 0.0174
2023-02-06 16:23:47 | Train | Epoch[170/200] Iteration[027/030] Train loss: 0.0174
2023-02-06 16:23:48 | Train | Epoch[170/200] Iteration[028/030] Train loss: 0.0175
2023-02-06 16:23:48 | Train | Epoch[170/200] Iteration[029/030] Train loss: 0.0175
2023-02-06 16:23:48 | Train | Epoch[170/200] Iteration[030/030] Train loss: 0.0176
2023-02-06 16:23:49 | Valid | Epoch[170/200] Iteration[001/008] Valid loss: 0.4131
2023-02-06 16:23:49 | Valid | Epoch[170/200] Iteration[002/008] Valid loss: 0.3665
2023-02-06 16:23:49 | Valid | Epoch[170/200] Iteration[003/008] Valid loss: 0.3399
2023-02-06 16:23:49 | Valid | Epoch[170/200] Iteration[004/008] Valid loss: 0.3356
2023-02-06 16:23:49 | Valid | Epoch[170/200] Iteration[005/008] Valid loss: 0.3541
2023-02-06 16:23:49 | Valid | Epoch[170/200] Iteration[006/008] Valid loss: 0.3468
2023-02-06 16:23:49 | Valid | Epoch[170/200] Iteration[007/008] Valid loss: 0.3684
2023-02-06 16:23:50 | Valid | Epoch[170/200] Iteration[008/008] Valid loss: 0.3728
2023-02-06 16:23:50 | Valid | Epoch[170/200] MIou: 0.9058057608582613
2023-02-06 16:23:50 | Valid | Epoch[170/200] Pixel Accuracy: 0.982086181640625
2023-02-06 16:23:50 | Valid | Epoch[170/200] Mean Pixel Accuracy: 0.979831513802147
2023-02-06 16:23:50 | Stage | Epoch[170/200] Train loss:0.0176
2023-02-06 16:23:50 | Stage | Epoch[170/200] Valid loss:0.3728
2023-02-06 16:23:50 | Stage | Epoch[170/200] LR:0.01

2023-02-06 16:23:50 | Train | Epoch[171/200] Iteration[001/030] Train loss: 0.0168
2023-02-06 16:23:51 | Train | Epoch[171/200] Iteration[002/030] Train loss: 0.0170
2023-02-06 16:23:51 | Train | Epoch[171/200] Iteration[003/030] Train loss: 0.0175
2023-02-06 16:23:52 | Train | Epoch[171/200] Iteration[004/030] Train loss: 0.0173
2023-02-06 16:23:52 | Train | Epoch[171/200] Iteration[005/030] Train loss: 0.0176
2023-02-06 16:23:53 | Train | Epoch[171/200] Iteration[006/030] Train loss: 0.0175
2023-02-06 16:23:53 | Train | Epoch[171/200] Iteration[007/030] Train loss: 0.0174
2023-02-06 16:23:53 | Train | Epoch[171/200] Iteration[008/030] Train loss: 0.0173
2023-02-06 16:23:54 | Train | Epoch[171/200] Iteration[009/030] Train loss: 0.0173
2023-02-06 16:23:54 | Train | Epoch[171/200] Iteration[010/030] Train loss: 0.0172
2023-02-06 16:23:55 | Train | Epoch[171/200] Iteration[011/030] Train loss: 0.0172
2023-02-06 16:23:55 | Train | Epoch[171/200] Iteration[012/030] Train loss: 0.0172
2023-02-06 16:23:56 | Train | Epoch[171/200] Iteration[013/030] Train loss: 0.0171
2023-02-06 16:23:56 | Train | Epoch[171/200] Iteration[014/030] Train loss: 0.0171
2023-02-06 16:23:56 | Train | Epoch[171/200] Iteration[015/030] Train loss: 0.0171
2023-02-06 16:23:57 | Train | Epoch[171/200] Iteration[016/030] Train loss: 0.0171
2023-02-06 16:23:57 | Train | Epoch[171/200] Iteration[017/030] Train loss: 0.0171
2023-02-06 16:23:58 | Train | Epoch[171/200] Iteration[018/030] Train loss: 0.0172
2023-02-06 16:23:58 | Train | Epoch[171/200] Iteration[019/030] Train loss: 0.0173
2023-02-06 16:23:59 | Train | Epoch[171/200] Iteration[020/030] Train loss: 0.0173
2023-02-06 16:23:59 | Train | Epoch[171/200] Iteration[021/030] Train loss: 0.0172
2023-02-06 16:23:59 | Train | Epoch[171/200] Iteration[022/030] Train loss: 0.0172
2023-02-06 16:24:00 | Train | Epoch[171/200] Iteration[023/030] Train loss: 0.0172
2023-02-06 16:24:00 | Train | Epoch[171/200] Iteration[024/030] Train loss: 0.0173
2023-02-06 16:24:01 | Train | Epoch[171/200] Iteration[025/030] Train loss: 0.0173
2023-02-06 16:24:01 | Train | Epoch[171/200] Iteration[026/030] Train loss: 0.0174
2023-02-06 16:24:02 | Train | Epoch[171/200] Iteration[027/030] Train loss: 0.0174
2023-02-06 16:24:02 | Train | Epoch[171/200] Iteration[028/030] Train loss: 0.0174
2023-02-06 16:24:02 | Train | Epoch[171/200] Iteration[029/030] Train loss: 0.0174
2023-02-06 16:24:03 | Train | Epoch[171/200] Iteration[030/030] Train loss: 0.0174
2023-02-06 16:24:03 | Valid | Epoch[171/200] Iteration[001/008] Valid loss: 0.0934
2023-02-06 16:24:03 | Valid | Epoch[171/200] Iteration[002/008] Valid loss: 0.0696
2023-02-06 16:24:03 | Valid | Epoch[171/200] Iteration[003/008] Valid loss: 0.0617
2023-02-06 16:24:03 | Valid | Epoch[171/200] Iteration[004/008] Valid loss: 0.0576
2023-02-06 16:24:03 | Valid | Epoch[171/200] Iteration[005/008] Valid loss: 0.0585
2023-02-06 16:24:04 | Valid | Epoch[171/200] Iteration[006/008] Valid loss: 0.0583
2023-02-06 16:24:04 | Valid | Epoch[171/200] Iteration[007/008] Valid loss: 0.0593
2023-02-06 16:24:04 | Valid | Epoch[171/200] Iteration[008/008] Valid loss: 0.0576
2023-02-06 16:24:04 | Valid | Epoch[171/200] MIou: 0.9151419259024073
2023-02-06 16:24:04 | Valid | Epoch[171/200] Pixel Accuracy: 0.985802968343099
2023-02-06 16:24:04 | Valid | Epoch[171/200] Mean Pixel Accuracy: 0.9297747638761859
2023-02-06 16:24:04 | Stage | Epoch[171/200] Train loss:0.0174
2023-02-06 16:24:04 | Stage | Epoch[171/200] Valid loss:0.0576
2023-02-06 16:24:04 | Stage | Epoch[171/200] LR:0.01

2023-02-06 16:24:05 | Train | Epoch[172/200] Iteration[001/030] Train loss: 0.0167
2023-02-06 16:24:05 | Train | Epoch[172/200] Iteration[002/030] Train loss: 0.0168
2023-02-06 16:24:05 | Train | Epoch[172/200] Iteration[003/030] Train loss: 0.0170
2023-02-06 16:24:06 | Train | Epoch[172/200] Iteration[004/030] Train loss: 0.0169
2023-02-06 16:24:06 | Train | Epoch[172/200] Iteration[005/030] Train loss: 0.0172
2023-02-06 16:24:07 | Train | Epoch[172/200] Iteration[006/030] Train loss: 0.0171
2023-02-06 16:24:07 | Train | Epoch[172/200] Iteration[007/030] Train loss: 0.0169
2023-02-06 16:24:08 | Train | Epoch[172/200] Iteration[008/030] Train loss: 0.0168
2023-02-06 16:24:08 | Train | Epoch[172/200] Iteration[009/030] Train loss: 0.0169
2023-02-06 16:24:08 | Train | Epoch[172/200] Iteration[010/030] Train loss: 0.0170
2023-02-06 16:24:09 | Train | Epoch[172/200] Iteration[011/030] Train loss: 0.0170
2023-02-06 16:24:09 | Train | Epoch[172/200] Iteration[012/030] Train loss: 0.0169
2023-02-06 16:24:10 | Train | Epoch[172/200] Iteration[013/030] Train loss: 0.0169
2023-02-06 16:24:10 | Train | Epoch[172/200] Iteration[014/030] Train loss: 0.0169
2023-02-06 16:24:11 | Train | Epoch[172/200] Iteration[015/030] Train loss: 0.0169
2023-02-06 16:24:11 | Train | Epoch[172/200] Iteration[016/030] Train loss: 0.0169
2023-02-06 16:24:11 | Train | Epoch[172/200] Iteration[017/030] Train loss: 0.0169
2023-02-06 16:24:12 | Train | Epoch[172/200] Iteration[018/030] Train loss: 0.0169
2023-02-06 16:24:12 | Train | Epoch[172/200] Iteration[019/030] Train loss: 0.0170
2023-02-06 16:24:13 | Train | Epoch[172/200] Iteration[020/030] Train loss: 0.0170
2023-02-06 16:24:13 | Train | Epoch[172/200] Iteration[021/030] Train loss: 0.0170
2023-02-06 16:24:14 | Train | Epoch[172/200] Iteration[022/030] Train loss: 0.0170
2023-02-06 16:24:14 | Train | Epoch[172/200] Iteration[023/030] Train loss: 0.0170
2023-02-06 16:24:15 | Train | Epoch[172/200] Iteration[024/030] Train loss: 0.0170
2023-02-06 16:24:15 | Train | Epoch[172/200] Iteration[025/030] Train loss: 0.0170
2023-02-06 16:24:15 | Train | Epoch[172/200] Iteration[026/030] Train loss: 0.0170
2023-02-06 16:24:16 | Train | Epoch[172/200] Iteration[027/030] Train loss: 0.0170
2023-02-06 16:24:16 | Train | Epoch[172/200] Iteration[028/030] Train loss: 0.0170
2023-02-06 16:24:17 | Train | Epoch[172/200] Iteration[029/030] Train loss: 0.0170
2023-02-06 16:24:17 | Train | Epoch[172/200] Iteration[030/030] Train loss: 0.0170
2023-02-06 16:24:17 | Valid | Epoch[172/200] Iteration[001/008] Valid loss: 0.0743
2023-02-06 16:24:17 | Valid | Epoch[172/200] Iteration[002/008] Valid loss: 0.0621
2023-02-06 16:24:18 | Valid | Epoch[172/200] Iteration[003/008] Valid loss: 0.0616
2023-02-06 16:24:18 | Valid | Epoch[172/200] Iteration[004/008] Valid loss: 0.0589
2023-02-06 16:24:18 | Valid | Epoch[172/200] Iteration[005/008] Valid loss: 0.0604
2023-02-06 16:24:18 | Valid | Epoch[172/200] Iteration[006/008] Valid loss: 0.0593
2023-02-06 16:24:18 | Valid | Epoch[172/200] Iteration[007/008] Valid loss: 0.0584
2023-02-06 16:24:18 | Valid | Epoch[172/200] Iteration[008/008] Valid loss: 0.0594
2023-02-06 16:24:18 | Valid | Epoch[172/200] MIou: 0.8474929281853698
2023-02-06 16:24:18 | Valid | Epoch[172/200] Pixel Accuracy: 0.9747530619303385
2023-02-06 16:24:18 | Valid | Epoch[172/200] Mean Pixel Accuracy: 0.8627249495129509
2023-02-06 16:24:18 | Stage | Epoch[172/200] Train loss:0.0170
2023-02-06 16:24:18 | Stage | Epoch[172/200] Valid loss:0.0594
2023-02-06 16:24:18 | Stage | Epoch[172/200] LR:0.01

2023-02-06 16:24:19 | Train | Epoch[173/200] Iteration[001/030] Train loss: 0.0159
2023-02-06 16:24:19 | Train | Epoch[173/200] Iteration[002/030] Train loss: 0.0161
2023-02-06 16:24:20 | Train | Epoch[173/200] Iteration[003/030] Train loss: 0.0162
2023-02-06 16:24:20 | Train | Epoch[173/200] Iteration[004/030] Train loss: 0.0165
2023-02-06 16:24:21 | Train | Epoch[173/200] Iteration[005/030] Train loss: 0.0164
2023-02-06 16:24:21 | Train | Epoch[173/200] Iteration[006/030] Train loss: 0.0166
2023-02-06 16:24:22 | Train | Epoch[173/200] Iteration[007/030] Train loss: 0.0166
2023-02-06 16:24:22 | Train | Epoch[173/200] Iteration[008/030] Train loss: 0.0165
2023-02-06 16:24:22 | Train | Epoch[173/200] Iteration[009/030] Train loss: 0.0165
2023-02-06 16:24:23 | Train | Epoch[173/200] Iteration[010/030] Train loss: 0.0166
2023-02-06 16:24:23 | Train | Epoch[173/200] Iteration[011/030] Train loss: 0.0166
2023-02-06 16:24:24 | Train | Epoch[173/200] Iteration[012/030] Train loss: 0.0167
2023-02-06 16:24:24 | Train | Epoch[173/200] Iteration[013/030] Train loss: 0.0167
2023-02-06 16:24:25 | Train | Epoch[173/200] Iteration[014/030] Train loss: 0.0168
2023-02-06 16:24:25 | Train | Epoch[173/200] Iteration[015/030] Train loss: 0.0169
2023-02-06 16:24:25 | Train | Epoch[173/200] Iteration[016/030] Train loss: 0.0169
2023-02-06 16:24:26 | Train | Epoch[173/200] Iteration[017/030] Train loss: 0.0169
2023-02-06 16:24:26 | Train | Epoch[173/200] Iteration[018/030] Train loss: 0.0169
2023-02-06 16:24:27 | Train | Epoch[173/200] Iteration[019/030] Train loss: 0.0169
2023-02-06 16:24:27 | Train | Epoch[173/200] Iteration[020/030] Train loss: 0.0169
2023-02-06 16:24:28 | Train | Epoch[173/200] Iteration[021/030] Train loss: 0.0169
2023-02-06 16:24:28 | Train | Epoch[173/200] Iteration[022/030] Train loss: 0.0170
2023-02-06 16:24:28 | Train | Epoch[173/200] Iteration[023/030] Train loss: 0.0169
2023-02-06 16:24:29 | Train | Epoch[173/200] Iteration[024/030] Train loss: 0.0169
2023-02-06 16:24:29 | Train | Epoch[173/200] Iteration[025/030] Train loss: 0.0170
2023-02-06 16:24:30 | Train | Epoch[173/200] Iteration[026/030] Train loss: 0.0169
2023-02-06 16:24:30 | Train | Epoch[173/200] Iteration[027/030] Train loss: 0.0169
2023-02-06 16:24:31 | Train | Epoch[173/200] Iteration[028/030] Train loss: 0.0170
2023-02-06 16:24:31 | Train | Epoch[173/200] Iteration[029/030] Train loss: 0.0169
2023-02-06 16:24:31 | Train | Epoch[173/200] Iteration[030/030] Train loss: 0.0170
2023-02-06 16:24:32 | Valid | Epoch[173/200] Iteration[001/008] Valid loss: 0.4544
2023-02-06 16:24:32 | Valid | Epoch[173/200] Iteration[002/008] Valid loss: 0.4158
2023-02-06 16:24:32 | Valid | Epoch[173/200] Iteration[003/008] Valid loss: 0.3956
2023-02-06 16:24:32 | Valid | Epoch[173/200] Iteration[004/008] Valid loss: 0.4105
2023-02-06 16:24:32 | Valid | Epoch[173/200] Iteration[005/008] Valid loss: 0.4238
2023-02-06 16:24:32 | Valid | Epoch[173/200] Iteration[006/008] Valid loss: 0.4158
2023-02-06 16:24:32 | Valid | Epoch[173/200] Iteration[007/008] Valid loss: 0.4446
2023-02-06 16:24:32 | Valid | Epoch[173/200] Iteration[008/008] Valid loss: 0.4515
2023-02-06 16:24:32 | Valid | Epoch[173/200] MIou: 0.9051433020539457
2023-02-06 16:24:32 | Valid | Epoch[173/200] Pixel Accuracy: 0.9818687438964844
2023-02-06 16:24:32 | Valid | Epoch[173/200] Mean Pixel Accuracy: 0.9816521850271682
2023-02-06 16:24:32 | Stage | Epoch[173/200] Train loss:0.0170
2023-02-06 16:24:32 | Stage | Epoch[173/200] Valid loss:0.4515
2023-02-06 16:24:32 | Stage | Epoch[173/200] LR:0.01

2023-02-06 16:24:33 | Train | Epoch[174/200] Iteration[001/030] Train loss: 0.0159
2023-02-06 16:24:34 | Train | Epoch[174/200] Iteration[002/030] Train loss: 0.0159
2023-02-06 16:24:34 | Train | Epoch[174/200] Iteration[003/030] Train loss: 0.0162
2023-02-06 16:24:34 | Train | Epoch[174/200] Iteration[004/030] Train loss: 0.0163
2023-02-06 16:24:35 | Train | Epoch[174/200] Iteration[005/030] Train loss: 0.0164
2023-02-06 16:24:35 | Train | Epoch[174/200] Iteration[006/030] Train loss: 0.0166
2023-02-06 16:24:36 | Train | Epoch[174/200] Iteration[007/030] Train loss: 0.0166
2023-02-06 16:24:36 | Train | Epoch[174/200] Iteration[008/030] Train loss: 0.0166
2023-02-06 16:24:37 | Train | Epoch[174/200] Iteration[009/030] Train loss: 0.0166
2023-02-06 16:24:37 | Train | Epoch[174/200] Iteration[010/030] Train loss: 0.0168
2023-02-06 16:24:37 | Train | Epoch[174/200] Iteration[011/030] Train loss: 0.0168
2023-02-06 16:24:38 | Train | Epoch[174/200] Iteration[012/030] Train loss: 0.0168
2023-02-06 16:24:38 | Train | Epoch[174/200] Iteration[013/030] Train loss: 0.0168
2023-02-06 16:24:39 | Train | Epoch[174/200] Iteration[014/030] Train loss: 0.0168
2023-02-06 16:24:39 | Train | Epoch[174/200] Iteration[015/030] Train loss: 0.0168
2023-02-06 16:24:40 | Train | Epoch[174/200] Iteration[016/030] Train loss: 0.0169
2023-02-06 16:24:40 | Train | Epoch[174/200] Iteration[017/030] Train loss: 0.0171
2023-02-06 16:24:41 | Train | Epoch[174/200] Iteration[018/030] Train loss: 0.0170
2023-02-06 16:24:41 | Train | Epoch[174/200] Iteration[019/030] Train loss: 0.0171
2023-02-06 16:24:41 | Train | Epoch[174/200] Iteration[020/030] Train loss: 0.0171
2023-02-06 16:24:42 | Train | Epoch[174/200] Iteration[021/030] Train loss: 0.0172
2023-02-06 16:24:42 | Train | Epoch[174/200] Iteration[022/030] Train loss: 0.0172
2023-02-06 16:24:43 | Train | Epoch[174/200] Iteration[023/030] Train loss: 0.0173
2023-02-06 16:24:43 | Train | Epoch[174/200] Iteration[024/030] Train loss: 0.0174
2023-02-06 16:24:44 | Train | Epoch[174/200] Iteration[025/030] Train loss: 0.0173
2023-02-06 16:24:44 | Train | Epoch[174/200] Iteration[026/030] Train loss: 0.0174
2023-02-06 16:24:44 | Train | Epoch[174/200] Iteration[027/030] Train loss: 0.0175
2023-02-06 16:24:45 | Train | Epoch[174/200] Iteration[028/030] Train loss: 0.0175
2023-02-06 16:24:45 | Train | Epoch[174/200] Iteration[029/030] Train loss: 0.0175
2023-02-06 16:24:45 | Train | Epoch[174/200] Iteration[030/030] Train loss: 0.0175
2023-02-06 16:24:46 | Valid | Epoch[174/200] Iteration[001/008] Valid loss: 0.1229
2023-02-06 16:24:46 | Valid | Epoch[174/200] Iteration[002/008] Valid loss: 0.0925
2023-02-06 16:24:46 | Valid | Epoch[174/200] Iteration[003/008] Valid loss: 0.0779
2023-02-06 16:24:46 | Valid | Epoch[174/200] Iteration[004/008] Valid loss: 0.0747
2023-02-06 16:24:46 | Valid | Epoch[174/200] Iteration[005/008] Valid loss: 0.0758
2023-02-06 16:24:46 | Valid | Epoch[174/200] Iteration[006/008] Valid loss: 0.0747
2023-02-06 16:24:46 | Valid | Epoch[174/200] Iteration[007/008] Valid loss: 0.0811
2023-02-06 16:24:47 | Valid | Epoch[174/200] Iteration[008/008] Valid loss: 0.0780
2023-02-06 16:24:47 | Valid | Epoch[174/200] MIou: 0.9220286813346266
2023-02-06 16:24:47 | Valid | Epoch[174/200] Pixel Accuracy: 0.9867820739746094
2023-02-06 16:24:47 | Valid | Epoch[174/200] Mean Pixel Accuracy: 0.9420174325004085
2023-02-06 16:24:47 | Stage | Epoch[174/200] Train loss:0.0175
2023-02-06 16:24:47 | Stage | Epoch[174/200] Valid loss:0.0780
2023-02-06 16:24:47 | Stage | Epoch[174/200] LR:0.01

2023-02-06 16:24:47 | Train | Epoch[175/200] Iteration[001/030] Train loss: 0.0164
2023-02-06 16:24:48 | Train | Epoch[175/200] Iteration[002/030] Train loss: 0.0174
2023-02-06 16:24:48 | Train | Epoch[175/200] Iteration[003/030] Train loss: 0.0173
2023-02-06 16:24:49 | Train | Epoch[175/200] Iteration[004/030] Train loss: 0.0174
2023-02-06 16:24:49 | Train | Epoch[175/200] Iteration[005/030] Train loss: 0.0174
2023-02-06 16:24:50 | Train | Epoch[175/200] Iteration[006/030] Train loss: 0.0173
2023-02-06 16:24:50 | Train | Epoch[175/200] Iteration[007/030] Train loss: 0.0177
2023-02-06 16:24:50 | Train | Epoch[175/200] Iteration[008/030] Train loss: 0.0177
2023-02-06 16:24:51 | Train | Epoch[175/200] Iteration[009/030] Train loss: 0.0176
2023-02-06 16:24:51 | Train | Epoch[175/200] Iteration[010/030] Train loss: 0.0178
2023-02-06 16:24:52 | Train | Epoch[175/200] Iteration[011/030] Train loss: 0.0177
2023-02-06 16:24:52 | Train | Epoch[175/200] Iteration[012/030] Train loss: 0.0177
2023-02-06 16:24:53 | Train | Epoch[175/200] Iteration[013/030] Train loss: 0.0177
2023-02-06 16:24:53 | Train | Epoch[175/200] Iteration[014/030] Train loss: 0.0178
2023-02-06 16:24:53 | Train | Epoch[175/200] Iteration[015/030] Train loss: 0.0178
2023-02-06 16:24:54 | Train | Epoch[175/200] Iteration[016/030] Train loss: 0.0178
2023-02-06 16:24:54 | Train | Epoch[175/200] Iteration[017/030] Train loss: 0.0177
2023-02-06 16:24:55 | Train | Epoch[175/200] Iteration[018/030] Train loss: 0.0176
2023-02-06 16:24:55 | Train | Epoch[175/200] Iteration[019/030] Train loss: 0.0175
2023-02-06 16:24:56 | Train | Epoch[175/200] Iteration[020/030] Train loss: 0.0175
2023-02-06 16:24:56 | Train | Epoch[175/200] Iteration[021/030] Train loss: 0.0176
2023-02-06 16:24:56 | Train | Epoch[175/200] Iteration[022/030] Train loss: 0.0175
2023-02-06 16:24:57 | Train | Epoch[175/200] Iteration[023/030] Train loss: 0.0175
2023-02-06 16:24:57 | Train | Epoch[175/200] Iteration[024/030] Train loss: 0.0175
2023-02-06 16:24:58 | Train | Epoch[175/200] Iteration[025/030] Train loss: 0.0175
2023-02-06 16:24:58 | Train | Epoch[175/200] Iteration[026/030] Train loss: 0.0174
2023-02-06 16:24:59 | Train | Epoch[175/200] Iteration[027/030] Train loss: 0.0174
2023-02-06 16:24:59 | Train | Epoch[175/200] Iteration[028/030] Train loss: 0.0174
2023-02-06 16:25:00 | Train | Epoch[175/200] Iteration[029/030] Train loss: 0.0174
2023-02-06 16:25:00 | Train | Epoch[175/200] Iteration[030/030] Train loss: 0.0173
2023-02-06 16:25:00 | Valid | Epoch[175/200] Iteration[001/008] Valid loss: 0.1521
2023-02-06 16:25:00 | Valid | Epoch[175/200] Iteration[002/008] Valid loss: 0.1079
2023-02-06 16:25:00 | Valid | Epoch[175/200] Iteration[003/008] Valid loss: 0.0880
2023-02-06 16:25:00 | Valid | Epoch[175/200] Iteration[004/008] Valid loss: 0.0813
2023-02-06 16:25:00 | Valid | Epoch[175/200] Iteration[005/008] Valid loss: 0.0818
2023-02-06 16:25:01 | Valid | Epoch[175/200] Iteration[006/008] Valid loss: 0.0806
2023-02-06 16:25:01 | Valid | Epoch[175/200] Iteration[007/008] Valid loss: 0.0858
2023-02-06 16:25:01 | Valid | Epoch[175/200] Iteration[008/008] Valid loss: 0.0835
2023-02-06 16:25:01 | Valid | Epoch[175/200] MIou: 0.930602054763868
2023-02-06 16:25:01 | Valid | Epoch[175/200] Pixel Accuracy: 0.9881451924641927
2023-02-06 16:25:01 | Valid | Epoch[175/200] Mean Pixel Accuracy: 0.9536152073150495
2023-02-06 16:25:01 | Stage | Epoch[175/200] Train loss:0.0173
2023-02-06 16:25:01 | Stage | Epoch[175/200] Valid loss:0.0835
2023-02-06 16:25:01 | Stage | Epoch[175/200] LR:0.01

2023-02-06 16:25:02 | Train | Epoch[176/200] Iteration[001/030] Train loss: 0.0159
2023-02-06 16:25:02 | Train | Epoch[176/200] Iteration[002/030] Train loss: 0.0170
2023-02-06 16:25:02 | Train | Epoch[176/200] Iteration[003/030] Train loss: 0.0171
2023-02-06 16:25:03 | Train | Epoch[176/200] Iteration[004/030] Train loss: 0.0168
2023-02-06 16:25:03 | Train | Epoch[176/200] Iteration[005/030] Train loss: 0.0167
2023-02-06 16:25:04 | Train | Epoch[176/200] Iteration[006/030] Train loss: 0.0167
2023-02-06 16:25:04 | Train | Epoch[176/200] Iteration[007/030] Train loss: 0.0167
2023-02-06 16:25:05 | Train | Epoch[176/200] Iteration[008/030] Train loss: 0.0167
2023-02-06 16:25:05 | Train | Epoch[176/200] Iteration[009/030] Train loss: 0.0168
2023-02-06 16:25:05 | Train | Epoch[176/200] Iteration[010/030] Train loss: 0.0167
2023-02-06 16:25:06 | Train | Epoch[176/200] Iteration[011/030] Train loss: 0.0167
2023-02-06 16:25:06 | Train | Epoch[176/200] Iteration[012/030] Train loss: 0.0167
2023-02-06 16:25:07 | Train | Epoch[176/200] Iteration[013/030] Train loss: 0.0168
2023-02-06 16:25:07 | Train | Epoch[176/200] Iteration[014/030] Train loss: 0.0169
2023-02-06 16:25:08 | Train | Epoch[176/200] Iteration[015/030] Train loss: 0.0170
2023-02-06 16:25:08 | Train | Epoch[176/200] Iteration[016/030] Train loss: 0.0170
2023-02-06 16:25:08 | Train | Epoch[176/200] Iteration[017/030] Train loss: 0.0170
2023-02-06 16:25:09 | Train | Epoch[176/200] Iteration[018/030] Train loss: 0.0170
2023-02-06 16:25:09 | Train | Epoch[176/200] Iteration[019/030] Train loss: 0.0171
2023-02-06 16:25:10 | Train | Epoch[176/200] Iteration[020/030] Train loss: 0.0171
2023-02-06 16:25:10 | Train | Epoch[176/200] Iteration[021/030] Train loss: 0.0170
2023-02-06 16:25:11 | Train | Epoch[176/200] Iteration[022/030] Train loss: 0.0170
2023-02-06 16:25:11 | Train | Epoch[176/200] Iteration[023/030] Train loss: 0.0171
2023-02-06 16:25:12 | Train | Epoch[176/200] Iteration[024/030] Train loss: 0.0171
2023-02-06 16:25:12 | Train | Epoch[176/200] Iteration[025/030] Train loss: 0.0172
2023-02-06 16:25:12 | Train | Epoch[176/200] Iteration[026/030] Train loss: 0.0171
2023-02-06 16:25:13 | Train | Epoch[176/200] Iteration[027/030] Train loss: 0.0172
2023-02-06 16:25:13 | Train | Epoch[176/200] Iteration[028/030] Train loss: 0.0172
2023-02-06 16:25:14 | Train | Epoch[176/200] Iteration[029/030] Train loss: 0.0172
2023-02-06 16:25:14 | Train | Epoch[176/200] Iteration[030/030] Train loss: 0.0172
2023-02-06 16:25:14 | Valid | Epoch[176/200] Iteration[001/008] Valid loss: 2.4210
2023-02-06 16:25:14 | Valid | Epoch[176/200] Iteration[002/008] Valid loss: 2.3532
2023-02-06 16:25:15 | Valid | Epoch[176/200] Iteration[003/008] Valid loss: 2.4793
2023-02-06 16:25:15 | Valid | Epoch[176/200] Iteration[004/008] Valid loss: 2.5812
2023-02-06 16:25:15 | Valid | Epoch[176/200] Iteration[005/008] Valid loss: 2.6390
2023-02-06 16:25:15 | Valid | Epoch[176/200] Iteration[006/008] Valid loss: 2.5927
2023-02-06 16:25:15 | Valid | Epoch[176/200] Iteration[007/008] Valid loss: 2.6483
2023-02-06 16:25:15 | Valid | Epoch[176/200] Iteration[008/008] Valid loss: 2.7630
2023-02-06 16:25:15 | Valid | Epoch[176/200] MIou: 0.7707807566784923
2023-02-06 16:25:15 | Valid | Epoch[176/200] Pixel Accuracy: 0.9413604736328125
2023-02-06 16:25:15 | Valid | Epoch[176/200] Mean Pixel Accuracy: 0.9671668705996342
2023-02-06 16:25:15 | Stage | Epoch[176/200] Train loss:0.0172
2023-02-06 16:25:15 | Stage | Epoch[176/200] Valid loss:2.7630
2023-02-06 16:25:15 | Stage | Epoch[176/200] LR:0.01

2023-02-06 16:25:16 | Train | Epoch[177/200] Iteration[001/030] Train loss: 0.0160
2023-02-06 16:25:16 | Train | Epoch[177/200] Iteration[002/030] Train loss: 0.0173
2023-02-06 16:25:17 | Train | Epoch[177/200] Iteration[003/030] Train loss: 0.0177
2023-02-06 16:25:17 | Train | Epoch[177/200] Iteration[004/030] Train loss: 0.0174
2023-02-06 16:25:17 | Train | Epoch[177/200] Iteration[005/030] Train loss: 0.0173
2023-02-06 16:25:18 | Train | Epoch[177/200] Iteration[006/030] Train loss: 0.0171
2023-02-06 16:25:18 | Train | Epoch[177/200] Iteration[007/030] Train loss: 0.0174
2023-02-06 16:25:19 | Train | Epoch[177/200] Iteration[008/030] Train loss: 0.0173
2023-02-06 16:25:19 | Train | Epoch[177/200] Iteration[009/030] Train loss: 0.0173
2023-02-06 16:25:20 | Train | Epoch[177/200] Iteration[010/030] Train loss: 0.0172
2023-02-06 16:25:20 | Train | Epoch[177/200] Iteration[011/030] Train loss: 0.0172
2023-02-06 16:25:21 | Train | Epoch[177/200] Iteration[012/030] Train loss: 0.0173
2023-02-06 16:25:21 | Train | Epoch[177/200] Iteration[013/030] Train loss: 0.0173
2023-02-06 16:25:21 | Train | Epoch[177/200] Iteration[014/030] Train loss: 0.0173
2023-02-06 16:25:22 | Train | Epoch[177/200] Iteration[015/030] Train loss: 0.0173
2023-02-06 16:25:22 | Train | Epoch[177/200] Iteration[016/030] Train loss: 0.0173
2023-02-06 16:25:23 | Train | Epoch[177/200] Iteration[017/030] Train loss: 0.0174
2023-02-06 16:25:23 | Train | Epoch[177/200] Iteration[018/030] Train loss: 0.0173
2023-02-06 16:25:24 | Train | Epoch[177/200] Iteration[019/030] Train loss: 0.0173
2023-02-06 16:25:24 | Train | Epoch[177/200] Iteration[020/030] Train loss: 0.0173
2023-02-06 16:25:24 | Train | Epoch[177/200] Iteration[021/030] Train loss: 0.0173
2023-02-06 16:25:25 | Train | Epoch[177/200] Iteration[022/030] Train loss: 0.0173
2023-02-06 16:25:25 | Train | Epoch[177/200] Iteration[023/030] Train loss: 0.0172
2023-02-06 16:25:26 | Train | Epoch[177/200] Iteration[024/030] Train loss: 0.0172
2023-02-06 16:25:26 | Train | Epoch[177/200] Iteration[025/030] Train loss: 0.0172
2023-02-06 16:25:27 | Train | Epoch[177/200] Iteration[026/030] Train loss: 0.0172
2023-02-06 16:25:27 | Train | Epoch[177/200] Iteration[027/030] Train loss: 0.0172
2023-02-06 16:25:27 | Train | Epoch[177/200] Iteration[028/030] Train loss: 0.0172
2023-02-06 16:25:28 | Train | Epoch[177/200] Iteration[029/030] Train loss: 0.0171
2023-02-06 16:25:28 | Train | Epoch[177/200] Iteration[030/030] Train loss: 0.0171
2023-02-06 16:25:29 | Valid | Epoch[177/200] Iteration[001/008] Valid loss: 0.6005
2023-02-06 16:25:29 | Valid | Epoch[177/200] Iteration[002/008] Valid loss: 0.6029
2023-02-06 16:25:29 | Valid | Epoch[177/200] Iteration[003/008] Valid loss: 0.5715
2023-02-06 16:25:29 | Valid | Epoch[177/200] Iteration[004/008] Valid loss: 0.5844
2023-02-06 16:25:29 | Valid | Epoch[177/200] Iteration[005/008] Valid loss: 0.5938
2023-02-06 16:25:29 | Valid | Epoch[177/200] Iteration[006/008] Valid loss: 0.5739
2023-02-06 16:25:29 | Valid | Epoch[177/200] Iteration[007/008] Valid loss: 0.6034
2023-02-06 16:25:29 | Valid | Epoch[177/200] Iteration[008/008] Valid loss: 0.6275
2023-02-06 16:25:29 | Valid | Epoch[177/200] MIou: 0.8810883503157223
2023-02-06 16:25:29 | Valid | Epoch[177/200] Pixel Accuracy: 0.976128896077474
2023-02-06 16:25:29 | Valid | Epoch[177/200] Mean Pixel Accuracy: 0.9799556283150297
2023-02-06 16:25:29 | Stage | Epoch[177/200] Train loss:0.0171
2023-02-06 16:25:29 | Stage | Epoch[177/200] Valid loss:0.6275
2023-02-06 16:25:29 | Stage | Epoch[177/200] LR:0.01

2023-02-06 16:25:30 | Train | Epoch[178/200] Iteration[001/030] Train loss: 0.0161
2023-02-06 16:25:30 | Train | Epoch[178/200] Iteration[002/030] Train loss: 0.0163
2023-02-06 16:25:31 | Train | Epoch[178/200] Iteration[003/030] Train loss: 0.0170
2023-02-06 16:25:31 | Train | Epoch[178/200] Iteration[004/030] Train loss: 0.0166
2023-02-06 16:25:32 | Train | Epoch[178/200] Iteration[005/030] Train loss: 0.0166
2023-02-06 16:25:32 | Train | Epoch[178/200] Iteration[006/030] Train loss: 0.0167
2023-02-06 16:25:33 | Train | Epoch[178/200] Iteration[007/030] Train loss: 0.0167
2023-02-06 16:25:33 | Train | Epoch[178/200] Iteration[008/030] Train loss: 0.0167
2023-02-06 16:25:33 | Train | Epoch[178/200] Iteration[009/030] Train loss: 0.0168
2023-02-06 16:25:34 | Train | Epoch[178/200] Iteration[010/030] Train loss: 0.0167
2023-02-06 16:25:34 | Train | Epoch[178/200] Iteration[011/030] Train loss: 0.0166
2023-02-06 16:25:35 | Train | Epoch[178/200] Iteration[012/030] Train loss: 0.0166
2023-02-06 16:25:35 | Train | Epoch[178/200] Iteration[013/030] Train loss: 0.0166
2023-02-06 16:25:36 | Train | Epoch[178/200] Iteration[014/030] Train loss: 0.0166
2023-02-06 16:25:36 | Train | Epoch[178/200] Iteration[015/030] Train loss: 0.0165
2023-02-06 16:25:36 | Train | Epoch[178/200] Iteration[016/030] Train loss: 0.0165
2023-02-06 16:25:37 | Train | Epoch[178/200] Iteration[017/030] Train loss: 0.0164
2023-02-06 16:25:37 | Train | Epoch[178/200] Iteration[018/030] Train loss: 0.0164
2023-02-06 16:25:38 | Train | Epoch[178/200] Iteration[019/030] Train loss: 0.0165
2023-02-06 16:25:38 | Train | Epoch[178/200] Iteration[020/030] Train loss: 0.0164
2023-02-06 16:25:39 | Train | Epoch[178/200] Iteration[021/030] Train loss: 0.0165
2023-02-06 16:25:39 | Train | Epoch[178/200] Iteration[022/030] Train loss: 0.0165
2023-02-06 16:25:39 | Train | Epoch[178/200] Iteration[023/030] Train loss: 0.0165
2023-02-06 16:25:40 | Train | Epoch[178/200] Iteration[024/030] Train loss: 0.0165
2023-02-06 16:25:40 | Train | Epoch[178/200] Iteration[025/030] Train loss: 0.0166
2023-02-06 16:25:41 | Train | Epoch[178/200] Iteration[026/030] Train loss: 0.0166
2023-02-06 16:25:41 | Train | Epoch[178/200] Iteration[027/030] Train loss: 0.0166
2023-02-06 16:25:42 | Train | Epoch[178/200] Iteration[028/030] Train loss: 0.0166
2023-02-06 16:25:42 | Train | Epoch[178/200] Iteration[029/030] Train loss: 0.0166
2023-02-06 16:25:42 | Train | Epoch[178/200] Iteration[030/030] Train loss: 0.0166
2023-02-06 16:25:43 | Valid | Epoch[178/200] Iteration[001/008] Valid loss: 0.1381
2023-02-06 16:25:43 | Valid | Epoch[178/200] Iteration[002/008] Valid loss: 0.1035
2023-02-06 16:25:43 | Valid | Epoch[178/200] Iteration[003/008] Valid loss: 0.0846
2023-02-06 16:25:43 | Valid | Epoch[178/200] Iteration[004/008] Valid loss: 0.0827
2023-02-06 16:25:43 | Valid | Epoch[178/200] Iteration[005/008] Valid loss: 0.0805
2023-02-06 16:25:43 | Valid | Epoch[178/200] Iteration[006/008] Valid loss: 0.0793
2023-02-06 16:25:43 | Valid | Epoch[178/200] Iteration[007/008] Valid loss: 0.0806
2023-02-06 16:25:43 | Valid | Epoch[178/200] Iteration[008/008] Valid loss: 0.0778
2023-02-06 16:25:43 | Valid | Epoch[178/200] MIou: 0.9132784273032601
2023-02-06 16:25:43 | Valid | Epoch[178/200] Pixel Accuracy: 0.9852739969889323
2023-02-06 16:25:43 | Valid | Epoch[178/200] Mean Pixel Accuracy: 0.9344612887968358
2023-02-06 16:25:43 | Stage | Epoch[178/200] Train loss:0.0166
2023-02-06 16:25:43 | Stage | Epoch[178/200] Valid loss:0.0778
2023-02-06 16:25:43 | Stage | Epoch[178/200] LR:0.01

2023-02-06 16:25:44 | Train | Epoch[179/200] Iteration[001/030] Train loss: 0.0160
2023-02-06 16:25:45 | Train | Epoch[179/200] Iteration[002/030] Train loss: 0.0162
2023-02-06 16:25:45 | Train | Epoch[179/200] Iteration[003/030] Train loss: 0.0163
2023-02-06 16:25:45 | Train | Epoch[179/200] Iteration[004/030] Train loss: 0.0166
2023-02-06 16:25:46 | Train | Epoch[179/200] Iteration[005/030] Train loss: 0.0169
2023-02-06 16:25:46 | Train | Epoch[179/200] Iteration[006/030] Train loss: 0.0167
2023-02-06 16:25:47 | Train | Epoch[179/200] Iteration[007/030] Train loss: 0.0166
2023-02-06 16:25:47 | Train | Epoch[179/200] Iteration[008/030] Train loss: 0.0165
2023-02-06 16:25:48 | Train | Epoch[179/200] Iteration[009/030] Train loss: 0.0166
2023-02-06 16:25:48 | Train | Epoch[179/200] Iteration[010/030] Train loss: 0.0165
2023-02-06 16:25:48 | Train | Epoch[179/200] Iteration[011/030] Train loss: 0.0168
2023-02-06 16:25:49 | Train | Epoch[179/200] Iteration[012/030] Train loss: 0.0169
2023-02-06 16:25:49 | Train | Epoch[179/200] Iteration[013/030] Train loss: 0.0169
2023-02-06 16:25:50 | Train | Epoch[179/200] Iteration[014/030] Train loss: 0.0168
2023-02-06 16:25:50 | Train | Epoch[179/200] Iteration[015/030] Train loss: 0.0168
2023-02-06 16:25:51 | Train | Epoch[179/200] Iteration[016/030] Train loss: 0.0167
2023-02-06 16:25:51 | Train | Epoch[179/200] Iteration[017/030] Train loss: 0.0167
2023-02-06 16:25:52 | Train | Epoch[179/200] Iteration[018/030] Train loss: 0.0166
2023-02-06 16:25:52 | Train | Epoch[179/200] Iteration[019/030] Train loss: 0.0166
2023-02-06 16:25:52 | Train | Epoch[179/200] Iteration[020/030] Train loss: 0.0166
2023-02-06 16:25:53 | Train | Epoch[179/200] Iteration[021/030] Train loss: 0.0166
2023-02-06 16:25:53 | Train | Epoch[179/200] Iteration[022/030] Train loss: 0.0165
2023-02-06 16:25:54 | Train | Epoch[179/200] Iteration[023/030] Train loss: 0.0165
2023-02-06 16:25:54 | Train | Epoch[179/200] Iteration[024/030] Train loss: 0.0165
2023-02-06 16:25:55 | Train | Epoch[179/200] Iteration[025/030] Train loss: 0.0165
2023-02-06 16:25:55 | Train | Epoch[179/200] Iteration[026/030] Train loss: 0.0166
2023-02-06 16:25:55 | Train | Epoch[179/200] Iteration[027/030] Train loss: 0.0165
2023-02-06 16:25:56 | Train | Epoch[179/200] Iteration[028/030] Train loss: 0.0165
2023-02-06 16:25:56 | Train | Epoch[179/200] Iteration[029/030] Train loss: 0.0165
2023-02-06 16:25:56 | Train | Epoch[179/200] Iteration[030/030] Train loss: 0.0165
2023-02-06 16:25:57 | Valid | Epoch[179/200] Iteration[001/008] Valid loss: 0.3354
2023-02-06 16:25:57 | Valid | Epoch[179/200] Iteration[002/008] Valid loss: 0.2473
2023-02-06 16:25:57 | Valid | Epoch[179/200] Iteration[003/008] Valid loss: 0.2223
2023-02-06 16:25:57 | Valid | Epoch[179/200] Iteration[004/008] Valid loss: 0.2207
2023-02-06 16:25:57 | Valid | Epoch[179/200] Iteration[005/008] Valid loss: 0.2291
2023-02-06 16:25:57 | Valid | Epoch[179/200] Iteration[006/008] Valid loss: 0.2268
2023-02-06 16:25:57 | Valid | Epoch[179/200] Iteration[007/008] Valid loss: 0.2423
2023-02-06 16:25:58 | Valid | Epoch[179/200] Iteration[008/008] Valid loss: 0.2417
2023-02-06 16:25:58 | Valid | Epoch[179/200] MIou: 0.9259973890008831
2023-02-06 16:25:58 | Valid | Epoch[179/200] Pixel Accuracy: 0.9865214029947916
2023-02-06 16:25:58 | Valid | Epoch[179/200] Mean Pixel Accuracy: 0.9794794931506976
2023-02-06 16:25:58 | Stage | Epoch[179/200] Train loss:0.0165
2023-02-06 16:25:58 | Stage | Epoch[179/200] Valid loss:0.2417
2023-02-06 16:25:58 | Stage | Epoch[179/200] LR:0.01

2023-02-06 16:25:58 | Train | Epoch[180/200] Iteration[001/030] Train loss: 0.0162
2023-02-06 16:25:59 | Train | Epoch[180/200] Iteration[002/030] Train loss: 0.0164
2023-02-06 16:25:59 | Train | Epoch[180/200] Iteration[003/030] Train loss: 0.0159
2023-02-06 16:26:00 | Train | Epoch[180/200] Iteration[004/030] Train loss: 0.0158
2023-02-06 16:26:00 | Train | Epoch[180/200] Iteration[005/030] Train loss: 0.0159
2023-02-06 16:26:01 | Train | Epoch[180/200] Iteration[006/030] Train loss: 0.0159
2023-02-06 16:26:01 | Train | Epoch[180/200] Iteration[007/030] Train loss: 0.0159
2023-02-06 16:26:01 | Train | Epoch[180/200] Iteration[008/030] Train loss: 0.0158
2023-02-06 16:26:02 | Train | Epoch[180/200] Iteration[009/030] Train loss: 0.0157
2023-02-06 16:26:02 | Train | Epoch[180/200] Iteration[010/030] Train loss: 0.0158
2023-02-06 16:26:03 | Train | Epoch[180/200] Iteration[011/030] Train loss: 0.0158
2023-02-06 16:26:03 | Train | Epoch[180/200] Iteration[012/030] Train loss: 0.0160
2023-02-06 16:26:04 | Train | Epoch[180/200] Iteration[013/030] Train loss: 0.0161
2023-02-06 16:26:04 | Train | Epoch[180/200] Iteration[014/030] Train loss: 0.0161
2023-02-06 16:26:04 | Train | Epoch[180/200] Iteration[015/030] Train loss: 0.0161
2023-02-06 16:26:05 | Train | Epoch[180/200] Iteration[016/030] Train loss: 0.0160
2023-02-06 16:26:05 | Train | Epoch[180/200] Iteration[017/030] Train loss: 0.0161
2023-02-06 16:26:06 | Train | Epoch[180/200] Iteration[018/030] Train loss: 0.0164
2023-02-06 16:26:06 | Train | Epoch[180/200] Iteration[019/030] Train loss: 0.0164
2023-02-06 16:26:07 | Train | Epoch[180/200] Iteration[020/030] Train loss: 0.0164
2023-02-06 16:26:07 | Train | Epoch[180/200] Iteration[021/030] Train loss: 0.0164
2023-02-06 16:26:07 | Train | Epoch[180/200] Iteration[022/030] Train loss: 0.0164
2023-02-06 16:26:08 | Train | Epoch[180/200] Iteration[023/030] Train loss: 0.0163
2023-02-06 16:26:08 | Train | Epoch[180/200] Iteration[024/030] Train loss: 0.0163
2023-02-06 16:26:09 | Train | Epoch[180/200] Iteration[025/030] Train loss: 0.0163
2023-02-06 16:26:09 | Train | Epoch[180/200] Iteration[026/030] Train loss: 0.0162
2023-02-06 16:26:10 | Train | Epoch[180/200] Iteration[027/030] Train loss: 0.0162
2023-02-06 16:26:10 | Train | Epoch[180/200] Iteration[028/030] Train loss: 0.0162
2023-02-06 16:26:10 | Train | Epoch[180/200] Iteration[029/030] Train loss: 0.0163
2023-02-06 16:26:11 | Train | Epoch[180/200] Iteration[030/030] Train loss: 0.0162
2023-02-06 16:26:11 | Valid | Epoch[180/200] Iteration[001/008] Valid loss: 0.2952
2023-02-06 16:26:11 | Valid | Epoch[180/200] Iteration[002/008] Valid loss: 0.2165
2023-02-06 16:26:11 | Valid | Epoch[180/200] Iteration[003/008] Valid loss: 0.1941
2023-02-06 16:26:11 | Valid | Epoch[180/200] Iteration[004/008] Valid loss: 0.1895
2023-02-06 16:26:11 | Valid | Epoch[180/200] Iteration[005/008] Valid loss: 0.1946
2023-02-06 16:26:12 | Valid | Epoch[180/200] Iteration[006/008] Valid loss: 0.1874
2023-02-06 16:26:12 | Valid | Epoch[180/200] Iteration[007/008] Valid loss: 0.2036
2023-02-06 16:26:12 | Valid | Epoch[180/200] Iteration[008/008] Valid loss: 0.1968
2023-02-06 16:26:12 | Valid | Epoch[180/200] MIou: 0.9220377331402125
2023-02-06 16:26:12 | Valid | Epoch[180/200] Pixel Accuracy: 0.9858805338541666
2023-02-06 16:26:12 | Valid | Epoch[180/200] Mean Pixel Accuracy: 0.9726853250823293
2023-02-06 16:26:12 | Stage | Epoch[180/200] Train loss:0.0162
2023-02-06 16:26:12 | Stage | Epoch[180/200] Valid loss:0.1968
2023-02-06 16:26:12 | Stage | Epoch[180/200] LR:0.01

2023-02-06 16:26:13 | Train | Epoch[181/200] Iteration[001/030] Train loss: 0.0157
2023-02-06 16:26:13 | Train | Epoch[181/200] Iteration[002/030] Train loss: 0.0156
2023-02-06 16:26:13 | Train | Epoch[181/200] Iteration[003/030] Train loss: 0.0154
2023-02-06 16:26:14 | Train | Epoch[181/200] Iteration[004/030] Train loss: 0.0152
2023-02-06 16:26:14 | Train | Epoch[181/200] Iteration[005/030] Train loss: 0.0153
2023-02-06 16:26:15 | Train | Epoch[181/200] Iteration[006/030] Train loss: 0.0158
2023-02-06 16:26:15 | Train | Epoch[181/200] Iteration[007/030] Train loss: 0.0158
2023-02-06 16:26:16 | Train | Epoch[181/200] Iteration[008/030] Train loss: 0.0157
2023-02-06 16:26:16 | Train | Epoch[181/200] Iteration[009/030] Train loss: 0.0156
2023-02-06 16:26:16 | Train | Epoch[181/200] Iteration[010/030] Train loss: 0.0157
2023-02-06 16:26:17 | Train | Epoch[181/200] Iteration[011/030] Train loss: 0.0156
2023-02-06 16:26:17 | Train | Epoch[181/200] Iteration[012/030] Train loss: 0.0157
2023-02-06 16:26:18 | Train | Epoch[181/200] Iteration[013/030] Train loss: 0.0156
2023-02-06 16:26:18 | Train | Epoch[181/200] Iteration[014/030] Train loss: 0.0155
2023-02-06 16:26:19 | Train | Epoch[181/200] Iteration[015/030] Train loss: 0.0155
2023-02-06 16:26:19 | Train | Epoch[181/200] Iteration[016/030] Train loss: 0.0155
2023-02-06 16:26:19 | Train | Epoch[181/200] Iteration[017/030] Train loss: 0.0155
2023-02-06 16:26:20 | Train | Epoch[181/200] Iteration[018/030] Train loss: 0.0155
2023-02-06 16:26:20 | Train | Epoch[181/200] Iteration[019/030] Train loss: 0.0155
2023-02-06 16:26:21 | Train | Epoch[181/200] Iteration[020/030] Train loss: 0.0154
2023-02-06 16:26:21 | Train | Epoch[181/200] Iteration[021/030] Train loss: 0.0155
2023-02-06 16:26:22 | Train | Epoch[181/200] Iteration[022/030] Train loss: 0.0155
2023-02-06 16:26:22 | Train | Epoch[181/200] Iteration[023/030] Train loss: 0.0154
2023-02-06 16:26:23 | Train | Epoch[181/200] Iteration[024/030] Train loss: 0.0154
2023-02-06 16:26:23 | Train | Epoch[181/200] Iteration[025/030] Train loss: 0.0154
2023-02-06 16:26:23 | Train | Epoch[181/200] Iteration[026/030] Train loss: 0.0154
2023-02-06 16:26:24 | Train | Epoch[181/200] Iteration[027/030] Train loss: 0.0154
2023-02-06 16:26:24 | Train | Epoch[181/200] Iteration[028/030] Train loss: 0.0154
2023-02-06 16:26:25 | Train | Epoch[181/200] Iteration[029/030] Train loss: 0.0154
2023-02-06 16:26:25 | Train | Epoch[181/200] Iteration[030/030] Train loss: 0.0154
2023-02-06 16:26:25 | Valid | Epoch[181/200] Iteration[001/008] Valid loss: 0.1720
2023-02-06 16:26:25 | Valid | Epoch[181/200] Iteration[002/008] Valid loss: 0.1173
2023-02-06 16:26:26 | Valid | Epoch[181/200] Iteration[003/008] Valid loss: 0.0963
2023-02-06 16:26:26 | Valid | Epoch[181/200] Iteration[004/008] Valid loss: 0.0905
2023-02-06 16:26:26 | Valid | Epoch[181/200] Iteration[005/008] Valid loss: 0.0886
2023-02-06 16:26:26 | Valid | Epoch[181/200] Iteration[006/008] Valid loss: 0.0857
2023-02-06 16:26:26 | Valid | Epoch[181/200] Iteration[007/008] Valid loss: 0.0892
2023-02-06 16:26:26 | Valid | Epoch[181/200] Iteration[008/008] Valid loss: 0.0863
2023-02-06 16:26:26 | Valid | Epoch[181/200] MIou: 0.9343244479486932
2023-02-06 16:26:26 | Valid | Epoch[181/200] Pixel Accuracy: 0.9887517293294271
2023-02-06 16:26:26 | Valid | Epoch[181/200] Mean Pixel Accuracy: 0.9583742349597857
2023-02-06 16:26:26 | Stage | Epoch[181/200] Train loss:0.0154
2023-02-06 16:26:26 | Stage | Epoch[181/200] Valid loss:0.0863
2023-02-06 16:26:26 | Stage | Epoch[181/200] LR:0.001

2023-02-06 16:26:27 | Train | Epoch[182/200] Iteration[001/030] Train loss: 0.0157
2023-02-06 16:26:27 | Train | Epoch[182/200] Iteration[002/030] Train loss: 0.0156
2023-02-06 16:26:28 | Train | Epoch[182/200] Iteration[003/030] Train loss: 0.0160
2023-02-06 16:26:28 | Train | Epoch[182/200] Iteration[004/030] Train loss: 0.0157
2023-02-06 16:26:29 | Train | Epoch[182/200] Iteration[005/030] Train loss: 0.0157
2023-02-06 16:26:29 | Train | Epoch[182/200] Iteration[006/030] Train loss: 0.0156
2023-02-06 16:26:29 | Train | Epoch[182/200] Iteration[007/030] Train loss: 0.0156
2023-02-06 16:26:30 | Train | Epoch[182/200] Iteration[008/030] Train loss: 0.0155
2023-02-06 16:26:30 | Train | Epoch[182/200] Iteration[009/030] Train loss: 0.0153
2023-02-06 16:26:31 | Train | Epoch[182/200] Iteration[010/030] Train loss: 0.0154
2023-02-06 16:26:31 | Train | Epoch[182/200] Iteration[011/030] Train loss: 0.0153
2023-02-06 16:26:32 | Train | Epoch[182/200] Iteration[012/030] Train loss: 0.0154
2023-02-06 16:26:32 | Train | Epoch[182/200] Iteration[013/030] Train loss: 0.0155
2023-02-06 16:26:33 | Train | Epoch[182/200] Iteration[014/030] Train loss: 0.0155
2023-02-06 16:26:33 | Train | Epoch[182/200] Iteration[015/030] Train loss: 0.0154
2023-02-06 16:26:33 | Train | Epoch[182/200] Iteration[016/030] Train loss: 0.0154
2023-02-06 16:26:34 | Train | Epoch[182/200] Iteration[017/030] Train loss: 0.0154
2023-02-06 16:26:34 | Train | Epoch[182/200] Iteration[018/030] Train loss: 0.0153
2023-02-06 16:26:35 | Train | Epoch[182/200] Iteration[019/030] Train loss: 0.0153
2023-02-06 16:26:35 | Train | Epoch[182/200] Iteration[020/030] Train loss: 0.0153
2023-02-06 16:26:36 | Train | Epoch[182/200] Iteration[021/030] Train loss: 0.0152
2023-02-06 16:26:36 | Train | Epoch[182/200] Iteration[022/030] Train loss: 0.0153
2023-02-06 16:26:36 | Train | Epoch[182/200] Iteration[023/030] Train loss: 0.0153
2023-02-06 16:26:37 | Train | Epoch[182/200] Iteration[024/030] Train loss: 0.0152
2023-02-06 16:26:37 | Train | Epoch[182/200] Iteration[025/030] Train loss: 0.0152
2023-02-06 16:26:38 | Train | Epoch[182/200] Iteration[026/030] Train loss: 0.0152
2023-02-06 16:26:38 | Train | Epoch[182/200] Iteration[027/030] Train loss: 0.0152
2023-02-06 16:26:39 | Train | Epoch[182/200] Iteration[028/030] Train loss: 0.0152
2023-02-06 16:26:39 | Train | Epoch[182/200] Iteration[029/030] Train loss: 0.0152
2023-02-06 16:26:39 | Train | Epoch[182/200] Iteration[030/030] Train loss: 0.0153
2023-02-06 16:26:40 | Valid | Epoch[182/200] Iteration[001/008] Valid loss: 0.2230
2023-02-06 16:26:40 | Valid | Epoch[182/200] Iteration[002/008] Valid loss: 0.1574
2023-02-06 16:26:40 | Valid | Epoch[182/200] Iteration[003/008] Valid loss: 0.1324
2023-02-06 16:26:40 | Valid | Epoch[182/200] Iteration[004/008] Valid loss: 0.1258
2023-02-06 16:26:40 | Valid | Epoch[182/200] Iteration[005/008] Valid loss: 0.1270
2023-02-06 16:26:40 | Valid | Epoch[182/200] Iteration[006/008] Valid loss: 0.1229
2023-02-06 16:26:40 | Valid | Epoch[182/200] Iteration[007/008] Valid loss: 0.1306
2023-02-06 16:26:40 | Valid | Epoch[182/200] Iteration[008/008] Valid loss: 0.1282
2023-02-06 16:26:40 | Valid | Epoch[182/200] MIou: 0.9339266193398917
2023-02-06 16:26:40 | Valid | Epoch[182/200] Pixel Accuracy: 0.9884198506673177
2023-02-06 16:26:40 | Valid | Epoch[182/200] Mean Pixel Accuracy: 0.9687930886610052
2023-02-06 16:26:40 | Stage | Epoch[182/200] Train loss:0.0153
2023-02-06 16:26:40 | Stage | Epoch[182/200] Valid loss:0.1282
2023-02-06 16:26:40 | Stage | Epoch[182/200] LR:0.001

2023-02-06 16:26:41 | Train | Epoch[183/200] Iteration[001/030] Train loss: 0.0140
2023-02-06 16:26:42 | Train | Epoch[183/200] Iteration[002/030] Train loss: 0.0141
2023-02-06 16:26:42 | Train | Epoch[183/200] Iteration[003/030] Train loss: 0.0148
2023-02-06 16:26:42 | Train | Epoch[183/200] Iteration[004/030] Train loss: 0.0147
2023-02-06 16:26:43 | Train | Epoch[183/200] Iteration[005/030] Train loss: 0.0148
2023-02-06 16:26:43 | Train | Epoch[183/200] Iteration[006/030] Train loss: 0.0148
2023-02-06 16:26:44 | Train | Epoch[183/200] Iteration[007/030] Train loss: 0.0147
2023-02-06 16:26:44 | Train | Epoch[183/200] Iteration[008/030] Train loss: 0.0149
2023-02-06 16:26:45 | Train | Epoch[183/200] Iteration[009/030] Train loss: 0.0149
2023-02-06 16:26:45 | Train | Epoch[183/200] Iteration[010/030] Train loss: 0.0148
2023-02-06 16:26:45 | Train | Epoch[183/200] Iteration[011/030] Train loss: 0.0148
2023-02-06 16:26:46 | Train | Epoch[183/200] Iteration[012/030] Train loss: 0.0148
2023-02-06 16:26:46 | Train | Epoch[183/200] Iteration[013/030] Train loss: 0.0149
2023-02-06 16:26:47 | Train | Epoch[183/200] Iteration[014/030] Train loss: 0.0149
2023-02-06 16:26:47 | Train | Epoch[183/200] Iteration[015/030] Train loss: 0.0149
2023-02-06 16:26:48 | Train | Epoch[183/200] Iteration[016/030] Train loss: 0.0149
2023-02-06 16:26:48 | Train | Epoch[183/200] Iteration[017/030] Train loss: 0.0149
2023-02-06 16:26:48 | Train | Epoch[183/200] Iteration[018/030] Train loss: 0.0149
2023-02-06 16:26:49 | Train | Epoch[183/200] Iteration[019/030] Train loss: 0.0149
2023-02-06 16:26:49 | Train | Epoch[183/200] Iteration[020/030] Train loss: 0.0149
2023-02-06 16:26:50 | Train | Epoch[183/200] Iteration[021/030] Train loss: 0.0149
2023-02-06 16:26:50 | Train | Epoch[183/200] Iteration[022/030] Train loss: 0.0149
2023-02-06 16:26:51 | Train | Epoch[183/200] Iteration[023/030] Train loss: 0.0149
2023-02-06 16:26:51 | Train | Epoch[183/200] Iteration[024/030] Train loss: 0.0149
2023-02-06 16:26:51 | Train | Epoch[183/200] Iteration[025/030] Train loss: 0.0149
2023-02-06 16:26:52 | Train | Epoch[183/200] Iteration[026/030] Train loss: 0.0149
2023-02-06 16:26:52 | Train | Epoch[183/200] Iteration[027/030] Train loss: 0.0149
2023-02-06 16:26:53 | Train | Epoch[183/200] Iteration[028/030] Train loss: 0.0149
2023-02-06 16:26:53 | Train | Epoch[183/200] Iteration[029/030] Train loss: 0.0149
2023-02-06 16:26:53 | Train | Epoch[183/200] Iteration[030/030] Train loss: 0.0149
2023-02-06 16:26:54 | Valid | Epoch[183/200] Iteration[001/008] Valid loss: 0.1558
2023-02-06 16:26:54 | Valid | Epoch[183/200] Iteration[002/008] Valid loss: 0.1062
2023-02-06 16:26:54 | Valid | Epoch[183/200] Iteration[003/008] Valid loss: 0.0870
2023-02-06 16:26:54 | Valid | Epoch[183/200] Iteration[004/008] Valid loss: 0.0822
2023-02-06 16:26:54 | Valid | Epoch[183/200] Iteration[005/008] Valid loss: 0.0810
2023-02-06 16:26:54 | Valid | Epoch[183/200] Iteration[006/008] Valid loss: 0.0780
2023-02-06 16:26:54 | Valid | Epoch[183/200] Iteration[007/008] Valid loss: 0.0808
2023-02-06 16:26:54 | Valid | Epoch[183/200] Iteration[008/008] Valid loss: 0.0778
2023-02-06 16:26:55 | Valid | Epoch[183/200] MIou: 0.9320292303564847
2023-02-06 16:26:55 | Valid | Epoch[183/200] Pixel Accuracy: 0.9884185791015625
2023-02-06 16:26:55 | Valid | Epoch[183/200] Mean Pixel Accuracy: 0.9538098555711906
2023-02-06 16:26:55 | Stage | Epoch[183/200] Train loss:0.0149
2023-02-06 16:26:55 | Stage | Epoch[183/200] Valid loss:0.0778
2023-02-06 16:26:55 | Stage | Epoch[183/200] LR:0.001

2023-02-06 16:26:55 | Train | Epoch[184/200] Iteration[001/030] Train loss: 0.0143
2023-02-06 16:26:56 | Train | Epoch[184/200] Iteration[002/030] Train loss: 0.0144
2023-02-06 16:26:56 | Train | Epoch[184/200] Iteration[003/030] Train loss: 0.0147
2023-02-06 16:26:57 | Train | Epoch[184/200] Iteration[004/030] Train loss: 0.0149
2023-02-06 16:26:57 | Train | Epoch[184/200] Iteration[005/030] Train loss: 0.0148
2023-02-06 16:26:57 | Train | Epoch[184/200] Iteration[006/030] Train loss: 0.0147
2023-02-06 16:26:58 | Train | Epoch[184/200] Iteration[007/030] Train loss: 0.0147
2023-02-06 16:26:58 | Train | Epoch[184/200] Iteration[008/030] Train loss: 0.0146
2023-02-06 16:26:59 | Train | Epoch[184/200] Iteration[009/030] Train loss: 0.0145
2023-02-06 16:26:59 | Train | Epoch[184/200] Iteration[010/030] Train loss: 0.0145
2023-02-06 16:27:00 | Train | Epoch[184/200] Iteration[011/030] Train loss: 0.0146
2023-02-06 16:27:00 | Train | Epoch[184/200] Iteration[012/030] Train loss: 0.0146
2023-02-06 16:27:01 | Train | Epoch[184/200] Iteration[013/030] Train loss: 0.0146
2023-02-06 16:27:01 | Train | Epoch[184/200] Iteration[014/030] Train loss: 0.0146
2023-02-06 16:27:01 | Train | Epoch[184/200] Iteration[015/030] Train loss: 0.0146
2023-02-06 16:27:02 | Train | Epoch[184/200] Iteration[016/030] Train loss: 0.0146
2023-02-06 16:27:02 | Train | Epoch[184/200] Iteration[017/030] Train loss: 0.0146
2023-02-06 16:27:03 | Train | Epoch[184/200] Iteration[018/030] Train loss: 0.0146
2023-02-06 16:27:03 | Train | Epoch[184/200] Iteration[019/030] Train loss: 0.0146
2023-02-06 16:27:04 | Train | Epoch[184/200] Iteration[020/030] Train loss: 0.0148
2023-02-06 16:27:04 | Train | Epoch[184/200] Iteration[021/030] Train loss: 0.0147
2023-02-06 16:27:04 | Train | Epoch[184/200] Iteration[022/030] Train loss: 0.0148
2023-02-06 16:27:05 | Train | Epoch[184/200] Iteration[023/030] Train loss: 0.0147
2023-02-06 16:27:05 | Train | Epoch[184/200] Iteration[024/030] Train loss: 0.0148
2023-02-06 16:27:06 | Train | Epoch[184/200] Iteration[025/030] Train loss: 0.0148
2023-02-06 16:27:06 | Train | Epoch[184/200] Iteration[026/030] Train loss: 0.0147
2023-02-06 16:27:07 | Train | Epoch[184/200] Iteration[027/030] Train loss: 0.0147
2023-02-06 16:27:07 | Train | Epoch[184/200] Iteration[028/030] Train loss: 0.0147
2023-02-06 16:27:07 | Train | Epoch[184/200] Iteration[029/030] Train loss: 0.0148
2023-02-06 16:27:08 | Train | Epoch[184/200] Iteration[030/030] Train loss: 0.0148
2023-02-06 16:27:08 | Valid | Epoch[184/200] Iteration[001/008] Valid loss: 0.1609
2023-02-06 16:27:08 | Valid | Epoch[184/200] Iteration[002/008] Valid loss: 0.1103
2023-02-06 16:27:08 | Valid | Epoch[184/200] Iteration[003/008] Valid loss: 0.0901
2023-02-06 16:27:08 | Valid | Epoch[184/200] Iteration[004/008] Valid loss: 0.0847
2023-02-06 16:27:08 | Valid | Epoch[184/200] Iteration[005/008] Valid loss: 0.0834
2023-02-06 16:27:08 | Valid | Epoch[184/200] Iteration[006/008] Valid loss: 0.0801
2023-02-06 16:27:09 | Valid | Epoch[184/200] Iteration[007/008] Valid loss: 0.0833
2023-02-06 16:27:09 | Valid | Epoch[184/200] Iteration[008/008] Valid loss: 0.0805
2023-02-06 16:27:09 | Valid | Epoch[184/200] MIou: 0.9339531999880528
2023-02-06 16:27:09 | Valid | Epoch[184/200] Pixel Accuracy: 0.9887288411458334
2023-02-06 16:27:09 | Valid | Epoch[184/200] Mean Pixel Accuracy: 0.956358065640108
2023-02-06 16:27:09 | Stage | Epoch[184/200] Train loss:0.0148
2023-02-06 16:27:09 | Stage | Epoch[184/200] Valid loss:0.0805
2023-02-06 16:27:09 | Stage | Epoch[184/200] LR:0.001

2023-02-06 16:27:09 | Train | Epoch[185/200] Iteration[001/030] Train loss: 0.0143
2023-02-06 16:27:10 | Train | Epoch[185/200] Iteration[002/030] Train loss: 0.0143
2023-02-06 16:27:10 | Train | Epoch[185/200] Iteration[003/030] Train loss: 0.0145
2023-02-06 16:27:11 | Train | Epoch[185/200] Iteration[004/030] Train loss: 0.0145
2023-02-06 16:27:11 | Train | Epoch[185/200] Iteration[005/030] Train loss: 0.0147
2023-02-06 16:27:12 | Train | Epoch[185/200] Iteration[006/030] Train loss: 0.0145
2023-02-06 16:27:12 | Train | Epoch[185/200] Iteration[007/030] Train loss: 0.0145
2023-02-06 16:27:13 | Train | Epoch[185/200] Iteration[008/030] Train loss: 0.0147
2023-02-06 16:27:13 | Train | Epoch[185/200] Iteration[009/030] Train loss: 0.0148
2023-02-06 16:27:13 | Train | Epoch[185/200] Iteration[010/030] Train loss: 0.0148
2023-02-06 16:27:14 | Train | Epoch[185/200] Iteration[011/030] Train loss: 0.0148
2023-02-06 16:27:14 | Train | Epoch[185/200] Iteration[012/030] Train loss: 0.0148
2023-02-06 16:27:15 | Train | Epoch[185/200] Iteration[013/030] Train loss: 0.0147
2023-02-06 16:27:15 | Train | Epoch[185/200] Iteration[014/030] Train loss: 0.0147
2023-02-06 16:27:16 | Train | Epoch[185/200] Iteration[015/030] Train loss: 0.0147
2023-02-06 16:27:16 | Train | Epoch[185/200] Iteration[016/030] Train loss: 0.0147
2023-02-06 16:27:16 | Train | Epoch[185/200] Iteration[017/030] Train loss: 0.0147
2023-02-06 16:27:17 | Train | Epoch[185/200] Iteration[018/030] Train loss: 0.0146
2023-02-06 16:27:17 | Train | Epoch[185/200] Iteration[019/030] Train loss: 0.0146
2023-02-06 16:27:18 | Train | Epoch[185/200] Iteration[020/030] Train loss: 0.0146
2023-02-06 16:27:18 | Train | Epoch[185/200] Iteration[021/030] Train loss: 0.0146
2023-02-06 16:27:19 | Train | Epoch[185/200] Iteration[022/030] Train loss: 0.0147
2023-02-06 16:27:19 | Train | Epoch[185/200] Iteration[023/030] Train loss: 0.0146
2023-02-06 16:27:19 | Train | Epoch[185/200] Iteration[024/030] Train loss: 0.0147
2023-02-06 16:27:20 | Train | Epoch[185/200] Iteration[025/030] Train loss: 0.0147
2023-02-06 16:27:20 | Train | Epoch[185/200] Iteration[026/030] Train loss: 0.0147
2023-02-06 16:27:21 | Train | Epoch[185/200] Iteration[027/030] Train loss: 0.0147
2023-02-06 16:27:21 | Train | Epoch[185/200] Iteration[028/030] Train loss: 0.0147
2023-02-06 16:27:22 | Train | Epoch[185/200] Iteration[029/030] Train loss: 0.0147
2023-02-06 16:27:22 | Train | Epoch[185/200] Iteration[030/030] Train loss: 0.0147
2023-02-06 16:27:22 | Valid | Epoch[185/200] Iteration[001/008] Valid loss: 0.1362
2023-02-06 16:27:22 | Valid | Epoch[185/200] Iteration[002/008] Valid loss: 0.0936
2023-02-06 16:27:22 | Valid | Epoch[185/200] Iteration[003/008] Valid loss: 0.0770
2023-02-06 16:27:23 | Valid | Epoch[185/200] Iteration[004/008] Valid loss: 0.0729
2023-02-06 16:27:23 | Valid | Epoch[185/200] Iteration[005/008] Valid loss: 0.0712
2023-02-06 16:27:23 | Valid | Epoch[185/200] Iteration[006/008] Valid loss: 0.0687
2023-02-06 16:27:23 | Valid | Epoch[185/200] Iteration[007/008] Valid loss: 0.0703
2023-02-06 16:27:23 | Valid | Epoch[185/200] Iteration[008/008] Valid loss: 0.0677
2023-02-06 16:27:23 | Valid | Epoch[185/200] MIou: 0.930189531446095
2023-02-06 16:27:23 | Valid | Epoch[185/200] Pixel Accuracy: 0.9881807963053385
2023-02-06 16:27:23 | Valid | Epoch[185/200] Mean Pixel Accuracy: 0.9491647442885941
2023-02-06 16:27:23 | Stage | Epoch[185/200] Train loss:0.0147
2023-02-06 16:27:23 | Stage | Epoch[185/200] Valid loss:0.0677
2023-02-06 16:27:23 | Stage | Epoch[185/200] LR:0.001

2023-02-06 16:27:24 | Train | Epoch[186/200] Iteration[001/030] Train loss: 0.0147
2023-02-06 16:27:24 | Train | Epoch[186/200] Iteration[002/030] Train loss: 0.0146
2023-02-06 16:27:25 | Train | Epoch[186/200] Iteration[003/030] Train loss: 0.0145
2023-02-06 16:27:25 | Train | Epoch[186/200] Iteration[004/030] Train loss: 0.0143
2023-02-06 16:27:25 | Train | Epoch[186/200] Iteration[005/030] Train loss: 0.0146
2023-02-06 16:27:26 | Train | Epoch[186/200] Iteration[006/030] Train loss: 0.0146
2023-02-06 16:27:26 | Train | Epoch[186/200] Iteration[007/030] Train loss: 0.0146
2023-02-06 16:27:27 | Train | Epoch[186/200] Iteration[008/030] Train loss: 0.0147
2023-02-06 16:27:27 | Train | Epoch[186/200] Iteration[009/030] Train loss: 0.0146
2023-02-06 16:27:28 | Train | Epoch[186/200] Iteration[010/030] Train loss: 0.0145
2023-02-06 16:27:28 | Train | Epoch[186/200] Iteration[011/030] Train loss: 0.0145
2023-02-06 16:27:28 | Train | Epoch[186/200] Iteration[012/030] Train loss: 0.0145
2023-02-06 16:27:29 | Train | Epoch[186/200] Iteration[013/030] Train loss: 0.0145
2023-02-06 16:27:29 | Train | Epoch[186/200] Iteration[014/030] Train loss: 0.0145
2023-02-06 16:27:30 | Train | Epoch[186/200] Iteration[015/030] Train loss: 0.0145
2023-02-06 16:27:30 | Train | Epoch[186/200] Iteration[016/030] Train loss: 0.0144
2023-02-06 16:27:31 | Train | Epoch[186/200] Iteration[017/030] Train loss: 0.0145
2023-02-06 16:27:31 | Train | Epoch[186/200] Iteration[018/030] Train loss: 0.0146
2023-02-06 16:27:31 | Train | Epoch[186/200] Iteration[019/030] Train loss: 0.0146
2023-02-06 16:27:32 | Train | Epoch[186/200] Iteration[020/030] Train loss: 0.0146
2023-02-06 16:27:32 | Train | Epoch[186/200] Iteration[021/030] Train loss: 0.0146
2023-02-06 16:27:33 | Train | Epoch[186/200] Iteration[022/030] Train loss: 0.0146
2023-02-06 16:27:33 | Train | Epoch[186/200] Iteration[023/030] Train loss: 0.0146
2023-02-06 16:27:34 | Train | Epoch[186/200] Iteration[024/030] Train loss: 0.0146
2023-02-06 16:27:34 | Train | Epoch[186/200] Iteration[025/030] Train loss: 0.0147
2023-02-06 16:27:35 | Train | Epoch[186/200] Iteration[026/030] Train loss: 0.0146
2023-02-06 16:27:35 | Train | Epoch[186/200] Iteration[027/030] Train loss: 0.0147
2023-02-06 16:27:35 | Train | Epoch[186/200] Iteration[028/030] Train loss: 0.0146
2023-02-06 16:27:36 | Train | Epoch[186/200] Iteration[029/030] Train loss: 0.0146
2023-02-06 16:27:36 | Train | Epoch[186/200] Iteration[030/030] Train loss: 0.0146
2023-02-06 16:27:36 | Valid | Epoch[186/200] Iteration[001/008] Valid loss: 0.1452
2023-02-06 16:27:37 | Valid | Epoch[186/200] Iteration[002/008] Valid loss: 0.0983
2023-02-06 16:27:37 | Valid | Epoch[186/200] Iteration[003/008] Valid loss: 0.0806
2023-02-06 16:27:37 | Valid | Epoch[186/200] Iteration[004/008] Valid loss: 0.0757
2023-02-06 16:27:37 | Valid | Epoch[186/200] Iteration[005/008] Valid loss: 0.0741
2023-02-06 16:27:37 | Valid | Epoch[186/200] Iteration[006/008] Valid loss: 0.0711
2023-02-06 16:27:37 | Valid | Epoch[186/200] Iteration[007/008] Valid loss: 0.0733
2023-02-06 16:27:37 | Valid | Epoch[186/200] Iteration[008/008] Valid loss: 0.0707
2023-02-06 16:27:37 | Valid | Epoch[186/200] MIou: 0.9316054723088314
2023-02-06 16:27:37 | Valid | Epoch[186/200] Pixel Accuracy: 0.9884007771809896
2023-02-06 16:27:37 | Valid | Epoch[186/200] Mean Pixel Accuracy: 0.9512765632146024
2023-02-06 16:27:37 | Stage | Epoch[186/200] Train loss:0.0146
2023-02-06 16:27:37 | Stage | Epoch[186/200] Valid loss:0.0707
2023-02-06 16:27:37 | Stage | Epoch[186/200] LR:0.001

2023-02-06 16:27:38 | Train | Epoch[187/200] Iteration[001/030] Train loss: 0.0147
2023-02-06 16:27:38 | Train | Epoch[187/200] Iteration[002/030] Train loss: 0.0146
2023-02-06 16:27:39 | Train | Epoch[187/200] Iteration[003/030] Train loss: 0.0146
2023-02-06 16:27:39 | Train | Epoch[187/200] Iteration[004/030] Train loss: 0.0147
2023-02-06 16:27:40 | Train | Epoch[187/200] Iteration[005/030] Train loss: 0.0149
2023-02-06 16:27:40 | Train | Epoch[187/200] Iteration[006/030] Train loss: 0.0148
2023-02-06 16:27:41 | Train | Epoch[187/200] Iteration[007/030] Train loss: 0.0147
2023-02-06 16:27:41 | Train | Epoch[187/200] Iteration[008/030] Train loss: 0.0148
2023-02-06 16:27:41 | Train | Epoch[187/200] Iteration[009/030] Train loss: 0.0147
2023-02-06 16:27:42 | Train | Epoch[187/200] Iteration[010/030] Train loss: 0.0147
2023-02-06 16:27:42 | Train | Epoch[187/200] Iteration[011/030] Train loss: 0.0147
2023-02-06 16:27:43 | Train | Epoch[187/200] Iteration[012/030] Train loss: 0.0146
2023-02-06 16:27:43 | Train | Epoch[187/200] Iteration[013/030] Train loss: 0.0147
2023-02-06 16:27:44 | Train | Epoch[187/200] Iteration[014/030] Train loss: 0.0147
2023-02-06 16:27:44 | Train | Epoch[187/200] Iteration[015/030] Train loss: 0.0147
2023-02-06 16:27:44 | Train | Epoch[187/200] Iteration[016/030] Train loss: 0.0147
2023-02-06 16:27:45 | Train | Epoch[187/200] Iteration[017/030] Train loss: 0.0147
2023-02-06 16:27:45 | Train | Epoch[187/200] Iteration[018/030] Train loss: 0.0147
2023-02-06 16:27:46 | Train | Epoch[187/200] Iteration[019/030] Train loss: 0.0147
2023-02-06 16:27:46 | Train | Epoch[187/200] Iteration[020/030] Train loss: 0.0147
2023-02-06 16:27:47 | Train | Epoch[187/200] Iteration[021/030] Train loss: 0.0147
2023-02-06 16:27:47 | Train | Epoch[187/200] Iteration[022/030] Train loss: 0.0147
2023-02-06 16:27:47 | Train | Epoch[187/200] Iteration[023/030] Train loss: 0.0147
2023-02-06 16:27:48 | Train | Epoch[187/200] Iteration[024/030] Train loss: 0.0147
2023-02-06 16:27:48 | Train | Epoch[187/200] Iteration[025/030] Train loss: 0.0147
2023-02-06 16:27:49 | Train | Epoch[187/200] Iteration[026/030] Train loss: 0.0147
2023-02-06 16:27:49 | Train | Epoch[187/200] Iteration[027/030] Train loss: 0.0146
2023-02-06 16:27:50 | Train | Epoch[187/200] Iteration[028/030] Train loss: 0.0146
2023-02-06 16:27:50 | Train | Epoch[187/200] Iteration[029/030] Train loss: 0.0146
2023-02-06 16:27:50 | Train | Epoch[187/200] Iteration[030/030] Train loss: 0.0146
2023-02-06 16:27:51 | Valid | Epoch[187/200] Iteration[001/008] Valid loss: 0.1516
2023-02-06 16:27:51 | Valid | Epoch[187/200] Iteration[002/008] Valid loss: 0.1023
2023-02-06 16:27:51 | Valid | Epoch[187/200] Iteration[003/008] Valid loss: 0.0836
2023-02-06 16:27:51 | Valid | Epoch[187/200] Iteration[004/008] Valid loss: 0.0782
2023-02-06 16:27:51 | Valid | Epoch[187/200] Iteration[005/008] Valid loss: 0.0768
2023-02-06 16:27:51 | Valid | Epoch[187/200] Iteration[006/008] Valid loss: 0.0740
2023-02-06 16:27:51 | Valid | Epoch[187/200] Iteration[007/008] Valid loss: 0.0765
2023-02-06 16:27:51 | Valid | Epoch[187/200] Iteration[008/008] Valid loss: 0.0736
2023-02-06 16:27:51 | Valid | Epoch[187/200] MIou: 0.9307282423308503
2023-02-06 16:27:51 | Valid | Epoch[187/200] Pixel Accuracy: 0.9882456461588541
2023-02-06 16:27:51 | Valid | Epoch[187/200] Mean Pixel Accuracy: 0.9506903993392044
2023-02-06 16:27:51 | Stage | Epoch[187/200] Train loss:0.0146
2023-02-06 16:27:51 | Stage | Epoch[187/200] Valid loss:0.0736
2023-02-06 16:27:51 | Stage | Epoch[187/200] LR:0.001

2023-02-06 16:27:52 | Train | Epoch[188/200] Iteration[001/030] Train loss: 0.0141
2023-02-06 16:27:53 | Train | Epoch[188/200] Iteration[002/030] Train loss: 0.0140
2023-02-06 16:27:53 | Train | Epoch[188/200] Iteration[003/030] Train loss: 0.0141
2023-02-06 16:27:53 | Train | Epoch[188/200] Iteration[004/030] Train loss: 0.0142
2023-02-06 16:27:54 | Train | Epoch[188/200] Iteration[005/030] Train loss: 0.0141
2023-02-06 16:27:54 | Train | Epoch[188/200] Iteration[006/030] Train loss: 0.0142
2023-02-06 16:27:55 | Train | Epoch[188/200] Iteration[007/030] Train loss: 0.0141
2023-02-06 16:27:55 | Train | Epoch[188/200] Iteration[008/030] Train loss: 0.0141
2023-02-06 16:27:56 | Train | Epoch[188/200] Iteration[009/030] Train loss: 0.0141
2023-02-06 16:27:56 | Train | Epoch[188/200] Iteration[010/030] Train loss: 0.0142
2023-02-06 16:27:56 | Train | Epoch[188/200] Iteration[011/030] Train loss: 0.0142
2023-02-06 16:27:57 | Train | Epoch[188/200] Iteration[012/030] Train loss: 0.0142
2023-02-06 16:27:57 | Train | Epoch[188/200] Iteration[013/030] Train loss: 0.0143
2023-02-06 16:27:58 | Train | Epoch[188/200] Iteration[014/030] Train loss: 0.0143
2023-02-06 16:27:58 | Train | Epoch[188/200] Iteration[015/030] Train loss: 0.0145
2023-02-06 16:27:59 | Train | Epoch[188/200] Iteration[016/030] Train loss: 0.0145
2023-02-06 16:27:59 | Train | Epoch[188/200] Iteration[017/030] Train loss: 0.0144
2023-02-06 16:28:00 | Train | Epoch[188/200] Iteration[018/030] Train loss: 0.0144
2023-02-06 16:28:00 | Train | Epoch[188/200] Iteration[019/030] Train loss: 0.0144
2023-02-06 16:28:00 | Train | Epoch[188/200] Iteration[020/030] Train loss: 0.0144
2023-02-06 16:28:01 | Train | Epoch[188/200] Iteration[021/030] Train loss: 0.0144
2023-02-06 16:28:01 | Train | Epoch[188/200] Iteration[022/030] Train loss: 0.0145
2023-02-06 16:28:02 | Train | Epoch[188/200] Iteration[023/030] Train loss: 0.0145
2023-02-06 16:28:02 | Train | Epoch[188/200] Iteration[024/030] Train loss: 0.0145
2023-02-06 16:28:03 | Train | Epoch[188/200] Iteration[025/030] Train loss: 0.0145
2023-02-06 16:28:03 | Train | Epoch[188/200] Iteration[026/030] Train loss: 0.0145
2023-02-06 16:28:03 | Train | Epoch[188/200] Iteration[027/030] Train loss: 0.0145
2023-02-06 16:28:04 | Train | Epoch[188/200] Iteration[028/030] Train loss: 0.0146
2023-02-06 16:28:04 | Train | Epoch[188/200] Iteration[029/030] Train loss: 0.0146
2023-02-06 16:28:04 | Train | Epoch[188/200] Iteration[030/030] Train loss: 0.0145
2023-02-06 16:28:05 | Valid | Epoch[188/200] Iteration[001/008] Valid loss: 0.1476
2023-02-06 16:28:05 | Valid | Epoch[188/200] Iteration[002/008] Valid loss: 0.1003
2023-02-06 16:28:05 | Valid | Epoch[188/200] Iteration[003/008] Valid loss: 0.0817
2023-02-06 16:28:05 | Valid | Epoch[188/200] Iteration[004/008] Valid loss: 0.0768
2023-02-06 16:28:05 | Valid | Epoch[188/200] Iteration[005/008] Valid loss: 0.0753
2023-02-06 16:28:05 | Valid | Epoch[188/200] Iteration[006/008] Valid loss: 0.0725
2023-02-06 16:28:05 | Valid | Epoch[188/200] Iteration[007/008] Valid loss: 0.0748
2023-02-06 16:28:05 | Valid | Epoch[188/200] Iteration[008/008] Valid loss: 0.0719
2023-02-06 16:28:06 | Valid | Epoch[188/200] MIou: 0.9314248416399614
2023-02-06 16:28:06 | Valid | Epoch[188/200] Pixel Accuracy: 0.9883715311686198
2023-02-06 16:28:06 | Valid | Epoch[188/200] Mean Pixel Accuracy: 0.9510512527989932
2023-02-06 16:28:06 | Stage | Epoch[188/200] Train loss:0.0145
2023-02-06 16:28:06 | Stage | Epoch[188/200] Valid loss:0.0719
2023-02-06 16:28:06 | Stage | Epoch[188/200] LR:0.001

2023-02-06 16:28:06 | Train | Epoch[189/200] Iteration[001/030] Train loss: 0.0145
2023-02-06 16:28:07 | Train | Epoch[189/200] Iteration[002/030] Train loss: 0.0145
2023-02-06 16:28:07 | Train | Epoch[189/200] Iteration[003/030] Train loss: 0.0144
2023-02-06 16:28:08 | Train | Epoch[189/200] Iteration[004/030] Train loss: 0.0143
2023-02-06 16:28:08 | Train | Epoch[189/200] Iteration[005/030] Train loss: 0.0142
2023-02-06 16:28:08 | Train | Epoch[189/200] Iteration[006/030] Train loss: 0.0142
2023-02-06 16:28:09 | Train | Epoch[189/200] Iteration[007/030] Train loss: 0.0144
2023-02-06 16:28:09 | Train | Epoch[189/200] Iteration[008/030] Train loss: 0.0145
2023-02-06 16:28:10 | Train | Epoch[189/200] Iteration[009/030] Train loss: 0.0145
2023-02-06 16:28:10 | Train | Epoch[189/200] Iteration[010/030] Train loss: 0.0147
2023-02-06 16:28:11 | Train | Epoch[189/200] Iteration[011/030] Train loss: 0.0147
2023-02-06 16:28:11 | Train | Epoch[189/200] Iteration[012/030] Train loss: 0.0146
2023-02-06 16:28:12 | Train | Epoch[189/200] Iteration[013/030] Train loss: 0.0146
2023-02-06 16:28:12 | Train | Epoch[189/200] Iteration[014/030] Train loss: 0.0146
2023-02-06 16:28:12 | Train | Epoch[189/200] Iteration[015/030] Train loss: 0.0146
2023-02-06 16:28:13 | Train | Epoch[189/200] Iteration[016/030] Train loss: 0.0145
2023-02-06 16:28:13 | Train | Epoch[189/200] Iteration[017/030] Train loss: 0.0145
2023-02-06 16:28:14 | Train | Epoch[189/200] Iteration[018/030] Train loss: 0.0146
2023-02-06 16:28:14 | Train | Epoch[189/200] Iteration[019/030] Train loss: 0.0146
2023-02-06 16:28:15 | Train | Epoch[189/200] Iteration[020/030] Train loss: 0.0146
2023-02-06 16:28:15 | Train | Epoch[189/200] Iteration[021/030] Train loss: 0.0146
2023-02-06 16:28:15 | Train | Epoch[189/200] Iteration[022/030] Train loss: 0.0146
2023-02-06 16:28:16 | Train | Epoch[189/200] Iteration[023/030] Train loss: 0.0145
2023-02-06 16:28:16 | Train | Epoch[189/200] Iteration[024/030] Train loss: 0.0145
2023-02-06 16:28:17 | Train | Epoch[189/200] Iteration[025/030] Train loss: 0.0145
2023-02-06 16:28:17 | Train | Epoch[189/200] Iteration[026/030] Train loss: 0.0145
2023-02-06 16:28:18 | Train | Epoch[189/200] Iteration[027/030] Train loss: 0.0145
2023-02-06 16:28:18 | Train | Epoch[189/200] Iteration[028/030] Train loss: 0.0145
2023-02-06 16:28:18 | Train | Epoch[189/200] Iteration[029/030] Train loss: 0.0145
2023-02-06 16:28:19 | Train | Epoch[189/200] Iteration[030/030] Train loss: 0.0145
2023-02-06 16:28:19 | Valid | Epoch[189/200] Iteration[001/008] Valid loss: 0.1764
2023-02-06 16:28:19 | Valid | Epoch[189/200] Iteration[002/008] Valid loss: 0.1205
2023-02-06 16:28:19 | Valid | Epoch[189/200] Iteration[003/008] Valid loss: 0.0983
2023-02-06 16:28:19 | Valid | Epoch[189/200] Iteration[004/008] Valid loss: 0.0925
2023-02-06 16:28:19 | Valid | Epoch[189/200] Iteration[005/008] Valid loss: 0.0919
2023-02-06 16:28:20 | Valid | Epoch[189/200] Iteration[006/008] Valid loss: 0.0881
2023-02-06 16:28:20 | Valid | Epoch[189/200] Iteration[007/008] Valid loss: 0.0922
2023-02-06 16:28:20 | Valid | Epoch[189/200] Iteration[008/008] Valid loss: 0.0891
2023-02-06 16:28:20 | Valid | Epoch[189/200] MIou: 0.9344326472001536
2023-02-06 16:28:20 | Valid | Epoch[189/200] Pixel Accuracy: 0.9887644449869791
2023-02-06 16:28:20 | Valid | Epoch[189/200] Mean Pixel Accuracy: 0.9587172690176262
2023-02-06 16:28:20 | Stage | Epoch[189/200] Train loss:0.0145
2023-02-06 16:28:20 | Stage | Epoch[189/200] Valid loss:0.0891
2023-02-06 16:28:20 | Stage | Epoch[189/200] LR:0.001

2023-02-06 16:28:21 | Train | Epoch[190/200] Iteration[001/030] Train loss: 0.0140
2023-02-06 16:28:21 | Train | Epoch[190/200] Iteration[002/030] Train loss: 0.0138
2023-02-06 16:28:21 | Train | Epoch[190/200] Iteration[003/030] Train loss: 0.0138
2023-02-06 16:28:22 | Train | Epoch[190/200] Iteration[004/030] Train loss: 0.0143
2023-02-06 16:28:22 | Train | Epoch[190/200] Iteration[005/030] Train loss: 0.0145
2023-02-06 16:28:23 | Train | Epoch[190/200] Iteration[006/030] Train loss: 0.0145
2023-02-06 16:28:23 | Train | Epoch[190/200] Iteration[007/030] Train loss: 0.0149
2023-02-06 16:28:24 | Train | Epoch[190/200] Iteration[008/030] Train loss: 0.0148
2023-02-06 16:28:24 | Train | Epoch[190/200] Iteration[009/030] Train loss: 0.0147
2023-02-06 16:28:24 | Train | Epoch[190/200] Iteration[010/030] Train loss: 0.0147
2023-02-06 16:28:25 | Train | Epoch[190/200] Iteration[011/030] Train loss: 0.0146
2023-02-06 16:28:25 | Train | Epoch[190/200] Iteration[012/030] Train loss: 0.0146
2023-02-06 16:28:26 | Train | Epoch[190/200] Iteration[013/030] Train loss: 0.0146
2023-02-06 16:28:26 | Train | Epoch[190/200] Iteration[014/030] Train loss: 0.0146
2023-02-06 16:28:27 | Train | Epoch[190/200] Iteration[015/030] Train loss: 0.0146
2023-02-06 16:28:27 | Train | Epoch[190/200] Iteration[016/030] Train loss: 0.0146
2023-02-06 16:28:27 | Train | Epoch[190/200] Iteration[017/030] Train loss: 0.0146
2023-02-06 16:28:28 | Train | Epoch[190/200] Iteration[018/030] Train loss: 0.0147
2023-02-06 16:28:28 | Train | Epoch[190/200] Iteration[019/030] Train loss: 0.0146
2023-02-06 16:28:29 | Train | Epoch[190/200] Iteration[020/030] Train loss: 0.0146
2023-02-06 16:28:29 | Train | Epoch[190/200] Iteration[021/030] Train loss: 0.0146
2023-02-06 16:28:30 | Train | Epoch[190/200] Iteration[022/030] Train loss: 0.0146
2023-02-06 16:28:30 | Train | Epoch[190/200] Iteration[023/030] Train loss: 0.0145
2023-02-06 16:28:30 | Train | Epoch[190/200] Iteration[024/030] Train loss: 0.0145
2023-02-06 16:28:31 | Train | Epoch[190/200] Iteration[025/030] Train loss: 0.0145
2023-02-06 16:28:31 | Train | Epoch[190/200] Iteration[026/030] Train loss: 0.0145
2023-02-06 16:28:32 | Train | Epoch[190/200] Iteration[027/030] Train loss: 0.0145
2023-02-06 16:28:32 | Train | Epoch[190/200] Iteration[028/030] Train loss: 0.0145
2023-02-06 16:28:33 | Train | Epoch[190/200] Iteration[029/030] Train loss: 0.0144
2023-02-06 16:28:33 | Train | Epoch[190/200] Iteration[030/030] Train loss: 0.0145
2023-02-06 16:28:33 | Valid | Epoch[190/200] Iteration[001/008] Valid loss: 0.1779
2023-02-06 16:28:33 | Valid | Epoch[190/200] Iteration[002/008] Valid loss: 0.1225
2023-02-06 16:28:33 | Valid | Epoch[190/200] Iteration[003/008] Valid loss: 0.0999
2023-02-06 16:28:34 | Valid | Epoch[190/200] Iteration[004/008] Valid loss: 0.0943
2023-02-06 16:28:34 | Valid | Epoch[190/200] Iteration[005/008] Valid loss: 0.0941
2023-02-06 16:28:34 | Valid | Epoch[190/200] Iteration[006/008] Valid loss: 0.0905
2023-02-06 16:28:34 | Valid | Epoch[190/200] Iteration[007/008] Valid loss: 0.0954
2023-02-06 16:28:34 | Valid | Epoch[190/200] Iteration[008/008] Valid loss: 0.0920
2023-02-06 16:28:34 | Valid | Epoch[190/200] MIou: 0.9347309436996899
2023-02-06 16:28:34 | Valid | Epoch[190/200] Pixel Accuracy: 0.9887886047363281
2023-02-06 16:28:34 | Valid | Epoch[190/200] Mean Pixel Accuracy: 0.9601191115074024
2023-02-06 16:28:34 | Stage | Epoch[190/200] Train loss:0.0145
2023-02-06 16:28:34 | Stage | Epoch[190/200] Valid loss:0.0920
2023-02-06 16:28:34 | Stage | Epoch[190/200] LR:0.001

2023-02-06 16:28:35 | Train | Epoch[191/200] Iteration[001/030] Train loss: 0.0137
2023-02-06 16:28:35 | Train | Epoch[191/200] Iteration[002/030] Train loss: 0.0141
2023-02-06 16:28:36 | Train | Epoch[191/200] Iteration[003/030] Train loss: 0.0141
2023-02-06 16:28:36 | Train | Epoch[191/200] Iteration[004/030] Train loss: 0.0140
2023-02-06 16:28:36 | Train | Epoch[191/200] Iteration[005/030] Train loss: 0.0140
2023-02-06 16:28:37 | Train | Epoch[191/200] Iteration[006/030] Train loss: 0.0140
2023-02-06 16:28:37 | Train | Epoch[191/200] Iteration[007/030] Train loss: 0.0142
2023-02-06 16:28:38 | Train | Epoch[191/200] Iteration[008/030] Train loss: 0.0143
2023-02-06 16:28:38 | Train | Epoch[191/200] Iteration[009/030] Train loss: 0.0143
2023-02-06 16:28:39 | Train | Epoch[191/200] Iteration[010/030] Train loss: 0.0143
2023-02-06 16:28:39 | Train | Epoch[191/200] Iteration[011/030] Train loss: 0.0143
2023-02-06 16:28:40 | Train | Epoch[191/200] Iteration[012/030] Train loss: 0.0143
2023-02-06 16:28:40 | Train | Epoch[191/200] Iteration[013/030] Train loss: 0.0143
2023-02-06 16:28:40 | Train | Epoch[191/200] Iteration[014/030] Train loss: 0.0143
2023-02-06 16:28:41 | Train | Epoch[191/200] Iteration[015/030] Train loss: 0.0143
2023-02-06 16:28:41 | Train | Epoch[191/200] Iteration[016/030] Train loss: 0.0143
2023-02-06 16:28:42 | Train | Epoch[191/200] Iteration[017/030] Train loss: 0.0143
2023-02-06 16:28:42 | Train | Epoch[191/200] Iteration[018/030] Train loss: 0.0143
2023-02-06 16:28:43 | Train | Epoch[191/200] Iteration[019/030] Train loss: 0.0143
2023-02-06 16:28:43 | Train | Epoch[191/200] Iteration[020/030] Train loss: 0.0143
2023-02-06 16:28:43 | Train | Epoch[191/200] Iteration[021/030] Train loss: 0.0143
2023-02-06 16:28:44 | Train | Epoch[191/200] Iteration[022/030] Train loss: 0.0143
2023-02-06 16:28:44 | Train | Epoch[191/200] Iteration[023/030] Train loss: 0.0142
2023-02-06 16:28:45 | Train | Epoch[191/200] Iteration[024/030] Train loss: 0.0142
2023-02-06 16:28:45 | Train | Epoch[191/200] Iteration[025/030] Train loss: 0.0143
2023-02-06 16:28:46 | Train | Epoch[191/200] Iteration[026/030] Train loss: 0.0143
2023-02-06 16:28:46 | Train | Epoch[191/200] Iteration[027/030] Train loss: 0.0143
2023-02-06 16:28:46 | Train | Epoch[191/200] Iteration[028/030] Train loss: 0.0143
2023-02-06 16:28:47 | Train | Epoch[191/200] Iteration[029/030] Train loss: 0.0143
2023-02-06 16:28:47 | Train | Epoch[191/200] Iteration[030/030] Train loss: 0.0143
2023-02-06 16:28:48 | Valid | Epoch[191/200] Iteration[001/008] Valid loss: 0.1592
2023-02-06 16:28:48 | Valid | Epoch[191/200] Iteration[002/008] Valid loss: 0.1089
2023-02-06 16:28:48 | Valid | Epoch[191/200] Iteration[003/008] Valid loss: 0.0886
2023-02-06 16:28:48 | Valid | Epoch[191/200] Iteration[004/008] Valid loss: 0.0834
2023-02-06 16:28:48 | Valid | Epoch[191/200] Iteration[005/008] Valid loss: 0.0822
2023-02-06 16:28:48 | Valid | Epoch[191/200] Iteration[006/008] Valid loss: 0.0790
2023-02-06 16:28:48 | Valid | Epoch[191/200] Iteration[007/008] Valid loss: 0.0821
2023-02-06 16:28:48 | Valid | Epoch[191/200] Iteration[008/008] Valid loss: 0.0791
2023-02-06 16:28:48 | Valid | Epoch[191/200] MIou: 0.9329925668939838
2023-02-06 16:28:48 | Valid | Epoch[191/200] Pixel Accuracy: 0.9885838826497396
2023-02-06 16:28:48 | Valid | Epoch[191/200] Mean Pixel Accuracy: 0.9546805914472803
2023-02-06 16:28:48 | Stage | Epoch[191/200] Train loss:0.0143
2023-02-06 16:28:48 | Stage | Epoch[191/200] Valid loss:0.0791
2023-02-06 16:28:48 | Stage | Epoch[191/200] LR:0.0001

2023-02-06 16:28:49 | Train | Epoch[192/200] Iteration[001/030] Train loss: 0.0135
2023-02-06 16:28:50 | Train | Epoch[192/200] Iteration[002/030] Train loss: 0.0139
2023-02-06 16:28:50 | Train | Epoch[192/200] Iteration[003/030] Train loss: 0.0142
2023-02-06 16:28:50 | Train | Epoch[192/200] Iteration[004/030] Train loss: 0.0142
2023-02-06 16:28:51 | Train | Epoch[192/200] Iteration[005/030] Train loss: 0.0141
2023-02-06 16:28:51 | Train | Epoch[192/200] Iteration[006/030] Train loss: 0.0140
2023-02-06 16:28:52 | Train | Epoch[192/200] Iteration[007/030] Train loss: 0.0140
2023-02-06 16:28:52 | Train | Epoch[192/200] Iteration[008/030] Train loss: 0.0140
2023-02-06 16:28:53 | Train | Epoch[192/200] Iteration[009/030] Train loss: 0.0140
2023-02-06 16:28:53 | Train | Epoch[192/200] Iteration[010/030] Train loss: 0.0140
2023-02-06 16:28:53 | Train | Epoch[192/200] Iteration[011/030] Train loss: 0.0140
2023-02-06 16:28:54 | Train | Epoch[192/200] Iteration[012/030] Train loss: 0.0140
2023-02-06 16:28:54 | Train | Epoch[192/200] Iteration[013/030] Train loss: 0.0140
2023-02-06 16:28:55 | Train | Epoch[192/200] Iteration[014/030] Train loss: 0.0140
2023-02-06 16:28:55 | Train | Epoch[192/200] Iteration[015/030] Train loss: 0.0141
2023-02-06 16:28:56 | Train | Epoch[192/200] Iteration[016/030] Train loss: 0.0141
2023-02-06 16:28:56 | Train | Epoch[192/200] Iteration[017/030] Train loss: 0.0141
2023-02-06 16:28:57 | Train | Epoch[192/200] Iteration[018/030] Train loss: 0.0141
2023-02-06 16:28:57 | Train | Epoch[192/200] Iteration[019/030] Train loss: 0.0141
2023-02-06 16:28:57 | Train | Epoch[192/200] Iteration[020/030] Train loss: 0.0141
2023-02-06 16:28:58 | Train | Epoch[192/200] Iteration[021/030] Train loss: 0.0141
2023-02-06 16:28:58 | Train | Epoch[192/200] Iteration[022/030] Train loss: 0.0142
2023-02-06 16:28:59 | Train | Epoch[192/200] Iteration[023/030] Train loss: 0.0142
2023-02-06 16:28:59 | Train | Epoch[192/200] Iteration[024/030] Train loss: 0.0142
2023-02-06 16:29:00 | Train | Epoch[192/200] Iteration[025/030] Train loss: 0.0142
2023-02-06 16:29:00 | Train | Epoch[192/200] Iteration[026/030] Train loss: 0.0143
2023-02-06 16:29:00 | Train | Epoch[192/200] Iteration[027/030] Train loss: 0.0143
2023-02-06 16:29:01 | Train | Epoch[192/200] Iteration[028/030] Train loss: 0.0143
2023-02-06 16:29:01 | Train | Epoch[192/200] Iteration[029/030] Train loss: 0.0143
2023-02-06 16:29:01 | Train | Epoch[192/200] Iteration[030/030] Train loss: 0.0143
2023-02-06 16:29:02 | Valid | Epoch[192/200] Iteration[001/008] Valid loss: 0.1581
2023-02-06 16:29:02 | Valid | Epoch[192/200] Iteration[002/008] Valid loss: 0.1081
2023-02-06 16:29:02 | Valid | Epoch[192/200] Iteration[003/008] Valid loss: 0.0878
2023-02-06 16:29:02 | Valid | Epoch[192/200] Iteration[004/008] Valid loss: 0.0826
2023-02-06 16:29:02 | Valid | Epoch[192/200] Iteration[005/008] Valid loss: 0.0813
2023-02-06 16:29:02 | Valid | Epoch[192/200] Iteration[006/008] Valid loss: 0.0781
2023-02-06 16:29:03 | Valid | Epoch[192/200] Iteration[007/008] Valid loss: 0.0809
2023-02-06 16:29:03 | Valid | Epoch[192/200] Iteration[008/008] Valid loss: 0.0780
2023-02-06 16:29:03 | Valid | Epoch[192/200] MIou: 0.9327099313871536
2023-02-06 16:29:03 | Valid | Epoch[192/200] Pixel Accuracy: 0.9885444641113281
2023-02-06 16:29:03 | Valid | Epoch[192/200] Mean Pixel Accuracy: 0.9540629210152739
2023-02-06 16:29:03 | Stage | Epoch[192/200] Train loss:0.0143
2023-02-06 16:29:03 | Stage | Epoch[192/200] Valid loss:0.0780
2023-02-06 16:29:03 | Stage | Epoch[192/200] LR:0.0001

2023-02-06 16:29:04 | Train | Epoch[193/200] Iteration[001/030] Train loss: 0.0137
2023-02-06 16:29:04 | Train | Epoch[193/200] Iteration[002/030] Train loss: 0.0139
2023-02-06 16:29:04 | Train | Epoch[193/200] Iteration[003/030] Train loss: 0.0138
2023-02-06 16:29:05 | Train | Epoch[193/200] Iteration[004/030] Train loss: 0.0140
2023-02-06 16:29:05 | Train | Epoch[193/200] Iteration[005/030] Train loss: 0.0143
2023-02-06 16:29:06 | Train | Epoch[193/200] Iteration[006/030] Train loss: 0.0146
2023-02-06 16:29:06 | Train | Epoch[193/200] Iteration[007/030] Train loss: 0.0146
2023-02-06 16:29:07 | Train | Epoch[193/200] Iteration[008/030] Train loss: 0.0146
2023-02-06 16:29:07 | Train | Epoch[193/200] Iteration[009/030] Train loss: 0.0145
2023-02-06 16:29:07 | Train | Epoch[193/200] Iteration[010/030] Train loss: 0.0145
2023-02-06 16:29:08 | Train | Epoch[193/200] Iteration[011/030] Train loss: 0.0145
2023-02-06 16:29:08 | Train | Epoch[193/200] Iteration[012/030] Train loss: 0.0145
2023-02-06 16:29:09 | Train | Epoch[193/200] Iteration[013/030] Train loss: 0.0144
2023-02-06 16:29:09 | Train | Epoch[193/200] Iteration[014/030] Train loss: 0.0144
2023-02-06 16:29:10 | Train | Epoch[193/200] Iteration[015/030] Train loss: 0.0144
2023-02-06 16:29:10 | Train | Epoch[193/200] Iteration[016/030] Train loss: 0.0145
2023-02-06 16:29:10 | Train | Epoch[193/200] Iteration[017/030] Train loss: 0.0145
2023-02-06 16:29:11 | Train | Epoch[193/200] Iteration[018/030] Train loss: 0.0145
2023-02-06 16:29:11 | Train | Epoch[193/200] Iteration[019/030] Train loss: 0.0144
2023-02-06 16:29:12 | Train | Epoch[193/200] Iteration[020/030] Train loss: 0.0144
2023-02-06 16:29:12 | Train | Epoch[193/200] Iteration[021/030] Train loss: 0.0144
2023-02-06 16:29:13 | Train | Epoch[193/200] Iteration[022/030] Train loss: 0.0144
2023-02-06 16:29:13 | Train | Epoch[193/200] Iteration[023/030] Train loss: 0.0144
2023-02-06 16:29:14 | Train | Epoch[193/200] Iteration[024/030] Train loss: 0.0144
2023-02-06 16:29:14 | Train | Epoch[193/200] Iteration[025/030] Train loss: 0.0145
2023-02-06 16:29:14 | Train | Epoch[193/200] Iteration[026/030] Train loss: 0.0145
2023-02-06 16:29:15 | Train | Epoch[193/200] Iteration[027/030] Train loss: 0.0145
2023-02-06 16:29:15 | Train | Epoch[193/200] Iteration[028/030] Train loss: 0.0145
2023-02-06 16:29:16 | Train | Epoch[193/200] Iteration[029/030] Train loss: 0.0145
2023-02-06 16:29:16 | Train | Epoch[193/200] Iteration[030/030] Train loss: 0.0145
2023-02-06 16:29:16 | Valid | Epoch[193/200] Iteration[001/008] Valid loss: 0.1651
2023-02-06 16:29:16 | Valid | Epoch[193/200] Iteration[002/008] Valid loss: 0.1126
2023-02-06 16:29:17 | Valid | Epoch[193/200] Iteration[003/008] Valid loss: 0.0916
2023-02-06 16:29:17 | Valid | Epoch[193/200] Iteration[004/008] Valid loss: 0.0861
2023-02-06 16:29:17 | Valid | Epoch[193/200] Iteration[005/008] Valid loss: 0.0851
2023-02-06 16:29:17 | Valid | Epoch[193/200] Iteration[006/008] Valid loss: 0.0820
2023-02-06 16:29:17 | Valid | Epoch[193/200] Iteration[007/008] Valid loss: 0.0854
2023-02-06 16:29:17 | Valid | Epoch[193/200] Iteration[008/008] Valid loss: 0.0823
2023-02-06 16:29:17 | Valid | Epoch[193/200] MIou: 0.9335095043523167
2023-02-06 16:29:17 | Valid | Epoch[193/200] Pixel Accuracy: 0.9886500040690104
2023-02-06 16:29:17 | Valid | Epoch[193/200] Mean Pixel Accuracy: 0.9560611145598829
2023-02-06 16:29:17 | Stage | Epoch[193/200] Train loss:0.0145
2023-02-06 16:29:17 | Stage | Epoch[193/200] Valid loss:0.0823
2023-02-06 16:29:17 | Stage | Epoch[193/200] LR:0.0001

2023-02-06 16:29:18 | Train | Epoch[194/200] Iteration[001/030] Train loss: 0.0144
2023-02-06 16:29:18 | Train | Epoch[194/200] Iteration[002/030] Train loss: 0.0143
2023-02-06 16:29:19 | Train | Epoch[194/200] Iteration[003/030] Train loss: 0.0148
2023-02-06 16:29:19 | Train | Epoch[194/200] Iteration[004/030] Train loss: 0.0148
2023-02-06 16:29:20 | Train | Epoch[194/200] Iteration[005/030] Train loss: 0.0147
2023-02-06 16:29:20 | Train | Epoch[194/200] Iteration[006/030] Train loss: 0.0145
2023-02-06 16:29:21 | Train | Epoch[194/200] Iteration[007/030] Train loss: 0.0145
2023-02-06 16:29:21 | Train | Epoch[194/200] Iteration[008/030] Train loss: 0.0145
2023-02-06 16:29:21 | Train | Epoch[194/200] Iteration[009/030] Train loss: 0.0144
2023-02-06 16:29:22 | Train | Epoch[194/200] Iteration[010/030] Train loss: 0.0145
2023-02-06 16:29:22 | Train | Epoch[194/200] Iteration[011/030] Train loss: 0.0145
2023-02-06 16:29:23 | Train | Epoch[194/200] Iteration[012/030] Train loss: 0.0144
2023-02-06 16:29:23 | Train | Epoch[194/200] Iteration[013/030] Train loss: 0.0143
2023-02-06 16:29:24 | Train | Epoch[194/200] Iteration[014/030] Train loss: 0.0143
2023-02-06 16:29:24 | Train | Epoch[194/200] Iteration[015/030] Train loss: 0.0143
2023-02-06 16:29:24 | Train | Epoch[194/200] Iteration[016/030] Train loss: 0.0143
2023-02-06 16:29:25 | Train | Epoch[194/200] Iteration[017/030] Train loss: 0.0143
2023-02-06 16:29:25 | Train | Epoch[194/200] Iteration[018/030] Train loss: 0.0142
2023-02-06 16:29:26 | Train | Epoch[194/200] Iteration[019/030] Train loss: 0.0142
2023-02-06 16:29:26 | Train | Epoch[194/200] Iteration[020/030] Train loss: 0.0142
2023-02-06 16:29:27 | Train | Epoch[194/200] Iteration[021/030] Train loss: 0.0142
2023-02-06 16:29:27 | Train | Epoch[194/200] Iteration[022/030] Train loss: 0.0142
2023-02-06 16:29:27 | Train | Epoch[194/200] Iteration[023/030] Train loss: 0.0142
2023-02-06 16:29:28 | Train | Epoch[194/200] Iteration[024/030] Train loss: 0.0142
2023-02-06 16:29:28 | Train | Epoch[194/200] Iteration[025/030] Train loss: 0.0142
2023-02-06 16:29:29 | Train | Epoch[194/200] Iteration[026/030] Train loss: 0.0142
2023-02-06 16:29:29 | Train | Epoch[194/200] Iteration[027/030] Train loss: 0.0142
2023-02-06 16:29:30 | Train | Epoch[194/200] Iteration[028/030] Train loss: 0.0142
2023-02-06 16:29:30 | Train | Epoch[194/200] Iteration[029/030] Train loss: 0.0142
2023-02-06 16:29:30 | Train | Epoch[194/200] Iteration[030/030] Train loss: 0.0142
2023-02-06 16:29:31 | Valid | Epoch[194/200] Iteration[001/008] Valid loss: 0.1655
2023-02-06 16:29:31 | Valid | Epoch[194/200] Iteration[002/008] Valid loss: 0.1130
2023-02-06 16:29:31 | Valid | Epoch[194/200] Iteration[003/008] Valid loss: 0.0919
2023-02-06 16:29:31 | Valid | Epoch[194/200] Iteration[004/008] Valid loss: 0.0865
2023-02-06 16:29:31 | Valid | Epoch[194/200] Iteration[005/008] Valid loss: 0.0856
2023-02-06 16:29:31 | Valid | Epoch[194/200] Iteration[006/008] Valid loss: 0.0825
2023-02-06 16:29:31 | Valid | Epoch[194/200] Iteration[007/008] Valid loss: 0.0860
2023-02-06 16:29:31 | Valid | Epoch[194/200] Iteration[008/008] Valid loss: 0.0828
2023-02-06 16:29:31 | Valid | Epoch[194/200] MIou: 0.9335310198966567
2023-02-06 16:29:31 | Valid | Epoch[194/200] Pixel Accuracy: 0.988653818766276
2023-02-06 16:29:31 | Valid | Epoch[194/200] Mean Pixel Accuracy: 0.9560758922232171
2023-02-06 16:29:31 | Stage | Epoch[194/200] Train loss:0.0142
2023-02-06 16:29:31 | Stage | Epoch[194/200] Valid loss:0.0828
2023-02-06 16:29:31 | Stage | Epoch[194/200] LR:0.0001

2023-02-06 16:29:32 | Train | Epoch[195/200] Iteration[001/030] Train loss: 0.0149
2023-02-06 16:29:33 | Train | Epoch[195/200] Iteration[002/030] Train loss: 0.0142
2023-02-06 16:29:33 | Train | Epoch[195/200] Iteration[003/030] Train loss: 0.0142
2023-02-06 16:29:33 | Train | Epoch[195/200] Iteration[004/030] Train loss: 0.0143
2023-02-06 16:29:34 | Train | Epoch[195/200] Iteration[005/030] Train loss: 0.0142
2023-02-06 16:29:34 | Train | Epoch[195/200] Iteration[006/030] Train loss: 0.0141
2023-02-06 16:29:35 | Train | Epoch[195/200] Iteration[007/030] Train loss: 0.0142
2023-02-06 16:29:35 | Train | Epoch[195/200] Iteration[008/030] Train loss: 0.0142
2023-02-06 16:29:36 | Train | Epoch[195/200] Iteration[009/030] Train loss: 0.0142
2023-02-06 16:29:36 | Train | Epoch[195/200] Iteration[010/030] Train loss: 0.0143
2023-02-06 16:29:36 | Train | Epoch[195/200] Iteration[011/030] Train loss: 0.0142
2023-02-06 16:29:37 | Train | Epoch[195/200] Iteration[012/030] Train loss: 0.0142
2023-02-06 16:29:37 | Train | Epoch[195/200] Iteration[013/030] Train loss: 0.0143
2023-02-06 16:29:38 | Train | Epoch[195/200] Iteration[014/030] Train loss: 0.0143
2023-02-06 16:29:38 | Train | Epoch[195/200] Iteration[015/030] Train loss: 0.0143
2023-02-06 16:29:39 | Train | Epoch[195/200] Iteration[016/030] Train loss: 0.0143
2023-02-06 16:29:39 | Train | Epoch[195/200] Iteration[017/030] Train loss: 0.0143
2023-02-06 16:29:39 | Train | Epoch[195/200] Iteration[018/030] Train loss: 0.0143
2023-02-06 16:29:40 | Train | Epoch[195/200] Iteration[019/030] Train loss: 0.0143
2023-02-06 16:29:40 | Train | Epoch[195/200] Iteration[020/030] Train loss: 0.0143
2023-02-06 16:29:41 | Train | Epoch[195/200] Iteration[021/030] Train loss: 0.0143
2023-02-06 16:29:41 | Train | Epoch[195/200] Iteration[022/030] Train loss: 0.0143
2023-02-06 16:29:42 | Train | Epoch[195/200] Iteration[023/030] Train loss: 0.0142
2023-02-06 16:29:42 | Train | Epoch[195/200] Iteration[024/030] Train loss: 0.0143
2023-02-06 16:29:43 | Train | Epoch[195/200] Iteration[025/030] Train loss: 0.0143
2023-02-06 16:29:43 | Train | Epoch[195/200] Iteration[026/030] Train loss: 0.0143
2023-02-06 16:29:43 | Train | Epoch[195/200] Iteration[027/030] Train loss: 0.0145
2023-02-06 16:29:44 | Train | Epoch[195/200] Iteration[028/030] Train loss: 0.0145
2023-02-06 16:29:44 | Train | Epoch[195/200] Iteration[029/030] Train loss: 0.0145
2023-02-06 16:29:44 | Train | Epoch[195/200] Iteration[030/030] Train loss: 0.0144
2023-02-06 16:29:45 | Valid | Epoch[195/200] Iteration[001/008] Valid loss: 0.1632
2023-02-06 16:29:45 | Valid | Epoch[195/200] Iteration[002/008] Valid loss: 0.1113
2023-02-06 16:29:45 | Valid | Epoch[195/200] Iteration[003/008] Valid loss: 0.0903
2023-02-06 16:29:45 | Valid | Epoch[195/200] Iteration[004/008] Valid loss: 0.0849
2023-02-06 16:29:45 | Valid | Epoch[195/200] Iteration[005/008] Valid loss: 0.0839
2023-02-06 16:29:45 | Valid | Epoch[195/200] Iteration[006/008] Valid loss: 0.0808
2023-02-06 16:29:45 | Valid | Epoch[195/200] Iteration[007/008] Valid loss: 0.0840
2023-02-06 16:29:46 | Valid | Epoch[195/200] Iteration[008/008] Valid loss: 0.0810
2023-02-06 16:29:46 | Valid | Epoch[195/200] MIou: 0.9329476898057902
2023-02-06 16:29:46 | Valid | Epoch[195/200] Pixel Accuracy: 0.9885660807291666
2023-02-06 16:29:46 | Valid | Epoch[195/200] Mean Pixel Accuracy: 0.9550448945717127
2023-02-06 16:29:46 | Stage | Epoch[195/200] Train loss:0.0144
2023-02-06 16:29:46 | Stage | Epoch[195/200] Valid loss:0.0810
2023-02-06 16:29:46 | Stage | Epoch[195/200] LR:0.0001

2023-02-06 16:29:46 | Train | Epoch[196/200] Iteration[001/030] Train loss: 0.0146
2023-02-06 16:29:47 | Train | Epoch[196/200] Iteration[002/030] Train loss: 0.0145
2023-02-06 16:29:47 | Train | Epoch[196/200] Iteration[003/030] Train loss: 0.0144
2023-02-06 16:29:48 | Train | Epoch[196/200] Iteration[004/030] Train loss: 0.0146
2023-02-06 16:29:48 | Train | Epoch[196/200] Iteration[005/030] Train loss: 0.0147
2023-02-06 16:29:49 | Train | Epoch[196/200] Iteration[006/030] Train loss: 0.0145
2023-02-06 16:29:49 | Train | Epoch[196/200] Iteration[007/030] Train loss: 0.0144
2023-02-06 16:29:49 | Train | Epoch[196/200] Iteration[008/030] Train loss: 0.0143
2023-02-06 16:29:50 | Train | Epoch[196/200] Iteration[009/030] Train loss: 0.0142
2023-02-06 16:29:50 | Train | Epoch[196/200] Iteration[010/030] Train loss: 0.0142
2023-02-06 16:29:51 | Train | Epoch[196/200] Iteration[011/030] Train loss: 0.0142
2023-02-06 16:29:51 | Train | Epoch[196/200] Iteration[012/030] Train loss: 0.0142
2023-02-06 16:29:52 | Train | Epoch[196/200] Iteration[013/030] Train loss: 0.0143
2023-02-06 16:29:52 | Train | Epoch[196/200] Iteration[014/030] Train loss: 0.0142
2023-02-06 16:29:52 | Train | Epoch[196/200] Iteration[015/030] Train loss: 0.0142
2023-02-06 16:29:53 | Train | Epoch[196/200] Iteration[016/030] Train loss: 0.0142
2023-02-06 16:29:53 | Train | Epoch[196/200] Iteration[017/030] Train loss: 0.0142
2023-02-06 16:29:54 | Train | Epoch[196/200] Iteration[018/030] Train loss: 0.0142
2023-02-06 16:29:54 | Train | Epoch[196/200] Iteration[019/030] Train loss: 0.0142
2023-02-06 16:29:55 | Train | Epoch[196/200] Iteration[020/030] Train loss: 0.0142
2023-02-06 16:29:55 | Train | Epoch[196/200] Iteration[021/030] Train loss: 0.0143
2023-02-06 16:29:55 | Train | Epoch[196/200] Iteration[022/030] Train loss: 0.0143
2023-02-06 16:29:56 | Train | Epoch[196/200] Iteration[023/030] Train loss: 0.0143
2023-02-06 16:29:56 | Train | Epoch[196/200] Iteration[024/030] Train loss: 0.0143
2023-02-06 16:29:57 | Train | Epoch[196/200] Iteration[025/030] Train loss: 0.0143
2023-02-06 16:29:57 | Train | Epoch[196/200] Iteration[026/030] Train loss: 0.0143
2023-02-06 16:29:58 | Train | Epoch[196/200] Iteration[027/030] Train loss: 0.0143
2023-02-06 16:29:58 | Train | Epoch[196/200] Iteration[028/030] Train loss: 0.0143
2023-02-06 16:29:58 | Train | Epoch[196/200] Iteration[029/030] Train loss: 0.0143
2023-02-06 16:29:59 | Train | Epoch[196/200] Iteration[030/030] Train loss: 0.0143
2023-02-06 16:29:59 | Valid | Epoch[196/200] Iteration[001/008] Valid loss: 0.1622
2023-02-06 16:29:59 | Valid | Epoch[196/200] Iteration[002/008] Valid loss: 0.1107
2023-02-06 16:29:59 | Valid | Epoch[196/200] Iteration[003/008] Valid loss: 0.0900
2023-02-06 16:29:59 | Valid | Epoch[196/200] Iteration[004/008] Valid loss: 0.0846
2023-02-06 16:29:59 | Valid | Epoch[196/200] Iteration[005/008] Valid loss: 0.0835
2023-02-06 16:30:00 | Valid | Epoch[196/200] Iteration[006/008] Valid loss: 0.0803
2023-02-06 16:30:00 | Valid | Epoch[196/200] Iteration[007/008] Valid loss: 0.0834
2023-02-06 16:30:00 | Valid | Epoch[196/200] Iteration[008/008] Valid loss: 0.0804
2023-02-06 16:30:00 | Valid | Epoch[196/200] MIou: 0.9330327096179937
2023-02-06 16:30:00 | Valid | Epoch[196/200] Pixel Accuracy: 0.98858642578125
2023-02-06 16:30:00 | Valid | Epoch[196/200] Mean Pixel Accuracy: 0.9548912248207191
2023-02-06 16:30:00 | Stage | Epoch[196/200] Train loss:0.0143
2023-02-06 16:30:00 | Stage | Epoch[196/200] Valid loss:0.0804
2023-02-06 16:30:00 | Stage | Epoch[196/200] LR:0.0001

2023-02-06 16:30:01 | Train | Epoch[197/200] Iteration[001/030] Train loss: 0.0139
2023-02-06 16:30:01 | Train | Epoch[197/200] Iteration[002/030] Train loss: 0.0139
2023-02-06 16:30:01 | Train | Epoch[197/200] Iteration[003/030] Train loss: 0.0141
2023-02-06 16:30:02 | Train | Epoch[197/200] Iteration[004/030] Train loss: 0.0141
2023-02-06 16:30:02 | Train | Epoch[197/200] Iteration[005/030] Train loss: 0.0140
2023-02-06 16:30:03 | Train | Epoch[197/200] Iteration[006/030] Train loss: 0.0140
2023-02-06 16:30:03 | Train | Epoch[197/200] Iteration[007/030] Train loss: 0.0141
2023-02-06 16:30:04 | Train | Epoch[197/200] Iteration[008/030] Train loss: 0.0141
2023-02-06 16:30:04 | Train | Epoch[197/200] Iteration[009/030] Train loss: 0.0141
2023-02-06 16:30:04 | Train | Epoch[197/200] Iteration[010/030] Train loss: 0.0141
2023-02-06 16:30:05 | Train | Epoch[197/200] Iteration[011/030] Train loss: 0.0141
2023-02-06 16:30:05 | Train | Epoch[197/200] Iteration[012/030] Train loss: 0.0141
2023-02-06 16:30:06 | Train | Epoch[197/200] Iteration[013/030] Train loss: 0.0142
2023-02-06 16:30:06 | Train | Epoch[197/200] Iteration[014/030] Train loss: 0.0142
2023-02-06 16:30:07 | Train | Epoch[197/200] Iteration[015/030] Train loss: 0.0142
2023-02-06 16:30:07 | Train | Epoch[197/200] Iteration[016/030] Train loss: 0.0142
2023-02-06 16:30:07 | Train | Epoch[197/200] Iteration[017/030] Train loss: 0.0142
2023-02-06 16:30:08 | Train | Epoch[197/200] Iteration[018/030] Train loss: 0.0143
2023-02-06 16:30:08 | Train | Epoch[197/200] Iteration[019/030] Train loss: 0.0143
2023-02-06 16:30:09 | Train | Epoch[197/200] Iteration[020/030] Train loss: 0.0143
2023-02-06 16:30:09 | Train | Epoch[197/200] Iteration[021/030] Train loss: 0.0143
2023-02-06 16:30:10 | Train | Epoch[197/200] Iteration[022/030] Train loss: 0.0143
2023-02-06 16:30:10 | Train | Epoch[197/200] Iteration[023/030] Train loss: 0.0143
2023-02-06 16:30:10 | Train | Epoch[197/200] Iteration[024/030] Train loss: 0.0143
2023-02-06 16:30:11 | Train | Epoch[197/200] Iteration[025/030] Train loss: 0.0143
2023-02-06 16:30:11 | Train | Epoch[197/200] Iteration[026/030] Train loss: 0.0143
2023-02-06 16:30:12 | Train | Epoch[197/200] Iteration[027/030] Train loss: 0.0143
2023-02-06 16:30:12 | Train | Epoch[197/200] Iteration[028/030] Train loss: 0.0143
2023-02-06 16:30:13 | Train | Epoch[197/200] Iteration[029/030] Train loss: 0.0143
2023-02-06 16:30:13 | Train | Epoch[197/200] Iteration[030/030] Train loss: 0.0143
2023-02-06 16:30:13 | Valid | Epoch[197/200] Iteration[001/008] Valid loss: 0.1611
2023-02-06 16:30:13 | Valid | Epoch[197/200] Iteration[002/008] Valid loss: 0.1102
2023-02-06 16:30:14 | Valid | Epoch[197/200] Iteration[003/008] Valid loss: 0.0896
2023-02-06 16:30:14 | Valid | Epoch[197/200] Iteration[004/008] Valid loss: 0.0842
2023-02-06 16:30:14 | Valid | Epoch[197/200] Iteration[005/008] Valid loss: 0.0832
2023-02-06 16:30:14 | Valid | Epoch[197/200] Iteration[006/008] Valid loss: 0.0798
2023-02-06 16:30:14 | Valid | Epoch[197/200] Iteration[007/008] Valid loss: 0.0830
2023-02-06 16:30:14 | Valid | Epoch[197/200] Iteration[008/008] Valid loss: 0.0800
2023-02-06 16:30:14 | Valid | Epoch[197/200] MIou: 0.9329570099091127
2023-02-06 16:30:14 | Valid | Epoch[197/200] Pixel Accuracy: 0.9885698954264323
2023-02-06 16:30:14 | Valid | Epoch[197/200] Mean Pixel Accuracy: 0.9549645651623657
2023-02-06 16:30:14 | Stage | Epoch[197/200] Train loss:0.0143
2023-02-06 16:30:14 | Stage | Epoch[197/200] Valid loss:0.0800
2023-02-06 16:30:14 | Stage | Epoch[197/200] LR:0.0001

2023-02-06 16:30:15 | Train | Epoch[198/200] Iteration[001/030] Train loss: 0.0136
2023-02-06 16:30:15 | Train | Epoch[198/200] Iteration[002/030] Train loss: 0.0152
2023-02-06 16:30:16 | Train | Epoch[198/200] Iteration[003/030] Train loss: 0.0156
2023-02-06 16:30:16 | Train | Epoch[198/200] Iteration[004/030] Train loss: 0.0152
2023-02-06 16:30:17 | Train | Epoch[198/200] Iteration[005/030] Train loss: 0.0150
2023-02-06 16:30:17 | Train | Epoch[198/200] Iteration[006/030] Train loss: 0.0152
2023-02-06 16:30:18 | Train | Epoch[198/200] Iteration[007/030] Train loss: 0.0149
2023-02-06 16:30:18 | Train | Epoch[198/200] Iteration[008/030] Train loss: 0.0148
2023-02-06 16:30:18 | Train | Epoch[198/200] Iteration[009/030] Train loss: 0.0147
2023-02-06 16:30:19 | Train | Epoch[198/200] Iteration[010/030] Train loss: 0.0146
2023-02-06 16:30:19 | Train | Epoch[198/200] Iteration[011/030] Train loss: 0.0145
2023-02-06 16:30:20 | Train | Epoch[198/200] Iteration[012/030] Train loss: 0.0145
2023-02-06 16:30:20 | Train | Epoch[198/200] Iteration[013/030] Train loss: 0.0144
2023-02-06 16:30:21 | Train | Epoch[198/200] Iteration[014/030] Train loss: 0.0144
2023-02-06 16:30:21 | Train | Epoch[198/200] Iteration[015/030] Train loss: 0.0144
2023-02-06 16:30:21 | Train | Epoch[198/200] Iteration[016/030] Train loss: 0.0144
2023-02-06 16:30:22 | Train | Epoch[198/200] Iteration[017/030] Train loss: 0.0144
2023-02-06 16:30:22 | Train | Epoch[198/200] Iteration[018/030] Train loss: 0.0144
2023-02-06 16:30:23 | Train | Epoch[198/200] Iteration[019/030] Train loss: 0.0143
2023-02-06 16:30:23 | Train | Epoch[198/200] Iteration[020/030] Train loss: 0.0143
2023-02-06 16:30:24 | Train | Epoch[198/200] Iteration[021/030] Train loss: 0.0143
2023-02-06 16:30:24 | Train | Epoch[198/200] Iteration[022/030] Train loss: 0.0143
2023-02-06 16:30:24 | Train | Epoch[198/200] Iteration[023/030] Train loss: 0.0144
2023-02-06 16:30:25 | Train | Epoch[198/200] Iteration[024/030] Train loss: 0.0144
2023-02-06 16:30:25 | Train | Epoch[198/200] Iteration[025/030] Train loss: 0.0144
2023-02-06 16:30:26 | Train | Epoch[198/200] Iteration[026/030] Train loss: 0.0145
2023-02-06 16:30:26 | Train | Epoch[198/200] Iteration[027/030] Train loss: 0.0144
2023-02-06 16:30:27 | Train | Epoch[198/200] Iteration[028/030] Train loss: 0.0144
2023-02-06 16:30:27 | Train | Epoch[198/200] Iteration[029/030] Train loss: 0.0144
2023-02-06 16:30:27 | Train | Epoch[198/200] Iteration[030/030] Train loss: 0.0144
2023-02-06 16:30:28 | Valid | Epoch[198/200] Iteration[001/008] Valid loss: 0.1535
2023-02-06 16:30:28 | Valid | Epoch[198/200] Iteration[002/008] Valid loss: 0.1054
2023-02-06 16:30:28 | Valid | Epoch[198/200] Iteration[003/008] Valid loss: 0.0857
2023-02-06 16:30:28 | Valid | Epoch[198/200] Iteration[004/008] Valid loss: 0.0805
2023-02-06 16:30:28 | Valid | Epoch[198/200] Iteration[005/008] Valid loss: 0.0790
2023-02-06 16:30:28 | Valid | Epoch[198/200] Iteration[006/008] Valid loss: 0.0757
2023-02-06 16:30:28 | Valid | Epoch[198/200] Iteration[007/008] Valid loss: 0.0783
2023-02-06 16:30:28 | Valid | Epoch[198/200] Iteration[008/008] Valid loss: 0.0756
2023-02-06 16:30:28 | Valid | Epoch[198/200] MIou: 0.9320900927715006
2023-02-06 16:30:28 | Valid | Epoch[198/200] Pixel Accuracy: 0.9884503682454427
2023-02-06 16:30:28 | Valid | Epoch[198/200] Mean Pixel Accuracy: 0.9530220883584073
2023-02-06 16:30:28 | Stage | Epoch[198/200] Train loss:0.0144
2023-02-06 16:30:28 | Stage | Epoch[198/200] Valid loss:0.0756
2023-02-06 16:30:28 | Stage | Epoch[198/200] LR:0.0001

2023-02-06 16:30:29 | Train | Epoch[199/200] Iteration[001/030] Train loss: 0.0145
2023-02-06 16:30:30 | Train | Epoch[199/200] Iteration[002/030] Train loss: 0.0141
2023-02-06 16:30:30 | Train | Epoch[199/200] Iteration[003/030] Train loss: 0.0140
2023-02-06 16:30:31 | Train | Epoch[199/200] Iteration[004/030] Train loss: 0.0140
2023-02-06 16:30:31 | Train | Epoch[199/200] Iteration[005/030] Train loss: 0.0140
2023-02-06 16:30:31 | Train | Epoch[199/200] Iteration[006/030] Train loss: 0.0141
2023-02-06 16:30:32 | Train | Epoch[199/200] Iteration[007/030] Train loss: 0.0141
2023-02-06 16:30:32 | Train | Epoch[199/200] Iteration[008/030] Train loss: 0.0141
2023-02-06 16:30:33 | Train | Epoch[199/200] Iteration[009/030] Train loss: 0.0141
2023-02-06 16:30:33 | Train | Epoch[199/200] Iteration[010/030] Train loss: 0.0141
2023-02-06 16:30:34 | Train | Epoch[199/200] Iteration[011/030] Train loss: 0.0141
2023-02-06 16:30:34 | Train | Epoch[199/200] Iteration[012/030] Train loss: 0.0141
2023-02-06 16:30:34 | Train | Epoch[199/200] Iteration[013/030] Train loss: 0.0142
2023-02-06 16:30:35 | Train | Epoch[199/200] Iteration[014/030] Train loss: 0.0142
2023-02-06 16:30:35 | Train | Epoch[199/200] Iteration[015/030] Train loss: 0.0142
2023-02-06 16:30:36 | Train | Epoch[199/200] Iteration[016/030] Train loss: 0.0142
2023-02-06 16:30:36 | Train | Epoch[199/200] Iteration[017/030] Train loss: 0.0143
2023-02-06 16:30:37 | Train | Epoch[199/200] Iteration[018/030] Train loss: 0.0143
2023-02-06 16:30:37 | Train | Epoch[199/200] Iteration[019/030] Train loss: 0.0143
2023-02-06 16:30:38 | Train | Epoch[199/200] Iteration[020/030] Train loss: 0.0143
2023-02-06 16:30:38 | Train | Epoch[199/200] Iteration[021/030] Train loss: 0.0143
2023-02-06 16:30:38 | Train | Epoch[199/200] Iteration[022/030] Train loss: 0.0143
2023-02-06 16:30:39 | Train | Epoch[199/200] Iteration[023/030] Train loss: 0.0143
2023-02-06 16:30:39 | Train | Epoch[199/200] Iteration[024/030] Train loss: 0.0142
2023-02-06 16:30:40 | Train | Epoch[199/200] Iteration[025/030] Train loss: 0.0142
2023-02-06 16:30:40 | Train | Epoch[199/200] Iteration[026/030] Train loss: 0.0142
2023-02-06 16:30:41 | Train | Epoch[199/200] Iteration[027/030] Train loss: 0.0142
2023-02-06 16:30:41 | Train | Epoch[199/200] Iteration[028/030] Train loss: 0.0142
2023-02-06 16:30:41 | Train | Epoch[199/200] Iteration[029/030] Train loss: 0.0142
2023-02-06 16:30:42 | Train | Epoch[199/200] Iteration[030/030] Train loss: 0.0142
2023-02-06 16:30:42 | Valid | Epoch[199/200] Iteration[001/008] Valid loss: 0.1596
2023-02-06 16:30:42 | Valid | Epoch[199/200] Iteration[002/008] Valid loss: 0.1089
2023-02-06 16:30:42 | Valid | Epoch[199/200] Iteration[003/008] Valid loss: 0.0884
2023-02-06 16:30:42 | Valid | Epoch[199/200] Iteration[004/008] Valid loss: 0.0832
2023-02-06 16:30:43 | Valid | Epoch[199/200] Iteration[005/008] Valid loss: 0.0820
2023-02-06 16:30:43 | Valid | Epoch[199/200] Iteration[006/008] Valid loss: 0.0790
2023-02-06 16:30:43 | Valid | Epoch[199/200] Iteration[007/008] Valid loss: 0.0819
2023-02-06 16:30:43 | Valid | Epoch[199/200] Iteration[008/008] Valid loss: 0.0789
2023-02-06 16:30:43 | Valid | Epoch[199/200] MIou: 0.9326020429560722
2023-02-06 16:30:43 | Valid | Epoch[199/200] Pixel Accuracy: 0.9885241190592448
2023-02-06 16:30:43 | Valid | Epoch[199/200] Mean Pixel Accuracy: 0.9540390575639293
2023-02-06 16:30:43 | Stage | Epoch[199/200] Train loss:0.0142
2023-02-06 16:30:43 | Stage | Epoch[199/200] Valid loss:0.0789
2023-02-06 16:30:43 | Stage | Epoch[199/200] LR:0.0001

2023-02-06 16:30:44 | Train | Epoch[200/200] Iteration[001/030] Train loss: 0.0143
2023-02-06 16:30:44 | Train | Epoch[200/200] Iteration[002/030] Train loss: 0.0144
2023-02-06 16:30:45 | Train | Epoch[200/200] Iteration[003/030] Train loss: 0.0144
2023-02-06 16:30:45 | Train | Epoch[200/200] Iteration[004/030] Train loss: 0.0141
2023-02-06 16:30:45 | Train | Epoch[200/200] Iteration[005/030] Train loss: 0.0142
2023-02-06 16:30:46 | Train | Epoch[200/200] Iteration[006/030] Train loss: 0.0143
2023-02-06 16:30:46 | Train | Epoch[200/200] Iteration[007/030] Train loss: 0.0150
2023-02-06 16:30:47 | Train | Epoch[200/200] Iteration[008/030] Train loss: 0.0150
2023-02-06 16:30:47 | Train | Epoch[200/200] Iteration[009/030] Train loss: 0.0150
2023-02-06 16:30:48 | Train | Epoch[200/200] Iteration[010/030] Train loss: 0.0149
2023-02-06 16:30:48 | Train | Epoch[200/200] Iteration[011/030] Train loss: 0.0148
2023-02-06 16:30:48 | Train | Epoch[200/200] Iteration[012/030] Train loss: 0.0148
2023-02-06 16:30:49 | Train | Epoch[200/200] Iteration[013/030] Train loss: 0.0148
2023-02-06 16:30:49 | Train | Epoch[200/200] Iteration[014/030] Train loss: 0.0147
2023-02-06 16:30:50 | Train | Epoch[200/200] Iteration[015/030] Train loss: 0.0147
2023-02-06 16:30:50 | Train | Epoch[200/200] Iteration[016/030] Train loss: 0.0146
2023-02-06 16:30:51 | Train | Epoch[200/200] Iteration[017/030] Train loss: 0.0146
2023-02-06 16:30:51 | Train | Epoch[200/200] Iteration[018/030] Train loss: 0.0146
2023-02-06 16:30:52 | Train | Epoch[200/200] Iteration[019/030] Train loss: 0.0145
2023-02-06 16:30:52 | Train | Epoch[200/200] Iteration[020/030] Train loss: 0.0145
2023-02-06 16:30:52 | Train | Epoch[200/200] Iteration[021/030] Train loss: 0.0145
2023-02-06 16:30:53 | Train | Epoch[200/200] Iteration[022/030] Train loss: 0.0145
2023-02-06 16:30:53 | Train | Epoch[200/200] Iteration[023/030] Train loss: 0.0145
2023-02-06 16:30:54 | Train | Epoch[200/200] Iteration[024/030] Train loss: 0.0145
2023-02-06 16:30:54 | Train | Epoch[200/200] Iteration[025/030] Train loss: 0.0145
2023-02-06 16:30:55 | Train | Epoch[200/200] Iteration[026/030] Train loss: 0.0144
2023-02-06 16:30:55 | Train | Epoch[200/200] Iteration[027/030] Train loss: 0.0145
2023-02-06 16:30:55 | Train | Epoch[200/200] Iteration[028/030] Train loss: 0.0145
2023-02-06 16:30:56 | Train | Epoch[200/200] Iteration[029/030] Train loss: 0.0145
2023-02-06 16:30:56 | Train | Epoch[200/200] Iteration[030/030] Train loss: 0.0145
2023-02-06 16:30:57 | Valid | Epoch[200/200] Iteration[001/008] Valid loss: 0.1581
2023-02-06 16:30:57 | Valid | Epoch[200/200] Iteration[002/008] Valid loss: 0.1079
2023-02-06 16:30:57 | Valid | Epoch[200/200] Iteration[003/008] Valid loss: 0.0877
2023-02-06 16:30:57 | Valid | Epoch[200/200] Iteration[004/008] Valid loss: 0.0824
2023-02-06 16:30:57 | Valid | Epoch[200/200] Iteration[005/008] Valid loss: 0.0811
2023-02-06 16:30:57 | Valid | Epoch[200/200] Iteration[006/008] Valid loss: 0.0781
2023-02-06 16:30:57 | Valid | Epoch[200/200] Iteration[007/008] Valid loss: 0.0807
2023-02-06 16:30:57 | Valid | Epoch[200/200] Iteration[008/008] Valid loss: 0.0778
2023-02-06 16:30:57 | Valid | Epoch[200/200] MIou: 0.9324033440787323
2023-02-06 16:30:57 | Valid | Epoch[200/200] Pixel Accuracy: 0.988494873046875
2023-02-06 16:30:57 | Valid | Epoch[200/200] Mean Pixel Accuracy: 0.9536679163035422
2023-02-06 16:30:57 | Stage | Epoch[200/200] Train loss:0.0145
2023-02-06 16:30:57 | Stage | Epoch[200/200] Valid loss:0.0778
2023-02-06 16:30:57 | Stage | Epoch[200/200] LR:0.0001

2023-02-06 16:30:57 | Final | Model training completed!!!
2023-02-06 16:30:57 | Final | Start time: 2023-02-06 15:43:20
2023-02-06 16:30:57 | Final | End time: 2023-02-06 16:30:57
2023-02-06 16:30:57 | Final | Spend time: 2857s
2023-02-06 16:30:57 | Final | Final epoch is 200
2023-02-06 16:30:57 | Final | Each epoch spend 14.285s
