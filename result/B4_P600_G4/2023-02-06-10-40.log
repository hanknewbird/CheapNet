2023-02-06 10:40:18 | Start | Model starts training!!!

2023-02-06 10:40:22 | Train | Epoch[001/600] Iteration[001/030] Train loss: 0.8948
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[002/030] Train loss: 0.8833
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[003/030] Train loss: 0.8708
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[004/030] Train loss: 0.8596
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[005/030] Train loss: 0.8499
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[006/030] Train loss: 0.8415
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[007/030] Train loss: 0.8330
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[008/030] Train loss: 0.8246
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[009/030] Train loss: 0.8177
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[010/030] Train loss: 0.8111
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[011/030] Train loss: 0.8059
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[012/030] Train loss: 0.8006
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[013/030] Train loss: 0.7957
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[014/030] Train loss: 0.7909
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[015/030] Train loss: 0.7858
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[016/030] Train loss: 0.7809
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[017/030] Train loss: 0.7762
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[018/030] Train loss: 0.7725
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[019/030] Train loss: 0.7686
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[020/030] Train loss: 0.7648
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[021/030] Train loss: 0.7607
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[022/030] Train loss: 0.7572
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[023/030] Train loss: 0.7536
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[024/030] Train loss: 0.7501
2023-02-06 10:40:23 | Train | Epoch[001/600] Iteration[025/030] Train loss: 0.7466
2023-02-06 10:40:24 | Train | Epoch[001/600] Iteration[026/030] Train loss: 0.7430
2023-02-06 10:40:24 | Train | Epoch[001/600] Iteration[027/030] Train loss: 0.7395
2023-02-06 10:40:24 | Train | Epoch[001/600] Iteration[028/030] Train loss: 0.7366
2023-02-06 10:40:24 | Train | Epoch[001/600] Iteration[029/030] Train loss: 0.7337
2023-02-06 10:40:24 | Train | Epoch[001/600] Iteration[030/030] Train loss: 0.7305
2023-02-06 10:40:24 | Valid | Epoch[001/600] Iteration[001/008] Valid loss: 0.6544
2023-02-06 10:40:24 | Valid | Epoch[001/600] Iteration[002/008] Valid loss: 0.6537
2023-02-06 10:40:24 | Valid | Epoch[001/600] Iteration[003/008] Valid loss: 0.6539
2023-02-06 10:40:24 | Valid | Epoch[001/600] Iteration[004/008] Valid loss: 0.6540
2023-02-06 10:40:24 | Valid | Epoch[001/600] Iteration[005/008] Valid loss: 0.6541
2023-02-06 10:40:24 | Valid | Epoch[001/600] Iteration[006/008] Valid loss: 0.6543
2023-02-06 10:40:24 | Valid | Epoch[001/600] Iteration[007/008] Valid loss: 0.6545
2023-02-06 10:40:24 | Valid | Epoch[001/600] Iteration[008/008] Valid loss: 0.6544
2023-02-06 10:40:24 | Valid | Epoch[001/600] MIou: 0.4712866736551739
2023-02-06 10:40:24 | Valid | Epoch[001/600] Pixel Accuracy: 0.9123802185058594
2023-02-06 10:40:24 | Valid | Epoch[001/600] Mean Pixel Accuracy: 0.515197520046633
2023-02-06 10:40:24 | Stage | Epoch[001/600] Train loss:0.7305
2023-02-06 10:40:24 | Stage | Epoch[001/600] Valid loss:0.6544
2023-02-06 10:40:24 | Stage | Epoch[001/600] LR:0.01

2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[001/030] Train loss: 0.6372
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[002/030] Train loss: 0.6364
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[003/030] Train loss: 0.6351
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[004/030] Train loss: 0.6349
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[005/030] Train loss: 0.6338
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[006/030] Train loss: 0.6333
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[007/030] Train loss: 0.6328
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[008/030] Train loss: 0.6320
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[009/030] Train loss: 0.6318
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[010/030] Train loss: 0.6310
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[011/030] Train loss: 0.6303
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[012/030] Train loss: 0.6298
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[013/030] Train loss: 0.6293
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[014/030] Train loss: 0.6287
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[015/030] Train loss: 0.6286
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[016/030] Train loss: 0.6280
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[017/030] Train loss: 0.6273
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[018/030] Train loss: 0.6267
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[019/030] Train loss: 0.6260
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[020/030] Train loss: 0.6255
2023-02-06 10:40:25 | Train | Epoch[002/600] Iteration[021/030] Train loss: 0.6249
2023-02-06 10:40:26 | Train | Epoch[002/600] Iteration[022/030] Train loss: 0.6244
2023-02-06 10:40:26 | Train | Epoch[002/600] Iteration[023/030] Train loss: 0.6238
2023-02-06 10:40:26 | Train | Epoch[002/600] Iteration[024/030] Train loss: 0.6232
2023-02-06 10:40:26 | Train | Epoch[002/600] Iteration[025/030] Train loss: 0.6226
2023-02-06 10:40:26 | Train | Epoch[002/600] Iteration[026/030] Train loss: 0.6223
2023-02-06 10:40:26 | Train | Epoch[002/600] Iteration[027/030] Train loss: 0.6217
2023-02-06 10:40:26 | Train | Epoch[002/600] Iteration[028/030] Train loss: 0.6212
2023-02-06 10:40:26 | Train | Epoch[002/600] Iteration[029/030] Train loss: 0.6207
2023-02-06 10:40:26 | Train | Epoch[002/600] Iteration[030/030] Train loss: 0.6202
2023-02-06 10:40:26 | Valid | Epoch[002/600] Iteration[001/008] Valid loss: 0.6215
2023-02-06 10:40:26 | Valid | Epoch[002/600] Iteration[002/008] Valid loss: 0.6201
2023-02-06 10:40:26 | Valid | Epoch[002/600] Iteration[003/008] Valid loss: 0.6189
2023-02-06 10:40:26 | Valid | Epoch[002/600] Iteration[004/008] Valid loss: 0.6188
2023-02-06 10:40:26 | Valid | Epoch[002/600] Iteration[005/008] Valid loss: 0.6178
2023-02-06 10:40:26 | Valid | Epoch[002/600] Iteration[006/008] Valid loss: 0.6179
2023-02-06 10:40:26 | Valid | Epoch[002/600] Iteration[007/008] Valid loss: 0.6175
2023-02-06 10:40:26 | Valid | Epoch[002/600] Iteration[008/008] Valid loss: 0.6167
2023-02-06 10:40:26 | Valid | Epoch[002/600] MIou: 0.7978138129625787
2023-02-06 10:40:26 | Valid | Epoch[002/600] Pixel Accuracy: 0.9649085998535156
2023-02-06 10:40:26 | Valid | Epoch[002/600] Mean Pixel Accuracy: 0.8321296604533952
2023-02-06 10:40:26 | Stage | Epoch[002/600] Train loss:0.6202
2023-02-06 10:40:26 | Stage | Epoch[002/600] Valid loss:0.6167
2023-02-06 10:40:26 | Stage | Epoch[002/600] LR:0.01

2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[001/030] Train loss: 0.6048
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[002/030] Train loss: 0.6040
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[003/030] Train loss: 0.6037
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[004/030] Train loss: 0.6036
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[005/030] Train loss: 0.6031
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[006/030] Train loss: 0.6022
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[007/030] Train loss: 0.6015
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[008/030] Train loss: 0.6014
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[009/030] Train loss: 0.6012
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[010/030] Train loss: 0.6012
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[011/030] Train loss: 0.6006
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[012/030] Train loss: 0.6002
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[013/030] Train loss: 0.5995
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[014/030] Train loss: 0.5989
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[015/030] Train loss: 0.5986
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[016/030] Train loss: 0.5982
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[017/030] Train loss: 0.5978
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[018/030] Train loss: 0.5977
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[019/030] Train loss: 0.5971
2023-02-06 10:40:27 | Train | Epoch[003/600] Iteration[020/030] Train loss: 0.5966
2023-02-06 10:40:28 | Train | Epoch[003/600] Iteration[021/030] Train loss: 0.5962
2023-02-06 10:40:28 | Train | Epoch[003/600] Iteration[022/030] Train loss: 0.5956
2023-02-06 10:40:28 | Train | Epoch[003/600] Iteration[023/030] Train loss: 0.5952
2023-02-06 10:40:28 | Train | Epoch[003/600] Iteration[024/030] Train loss: 0.5948
2023-02-06 10:40:28 | Train | Epoch[003/600] Iteration[025/030] Train loss: 0.5945
2023-02-06 10:40:28 | Train | Epoch[003/600] Iteration[026/030] Train loss: 0.5941
2023-02-06 10:40:28 | Train | Epoch[003/600] Iteration[027/030] Train loss: 0.5940
2023-02-06 10:40:28 | Train | Epoch[003/600] Iteration[028/030] Train loss: 0.5936
2023-02-06 10:40:28 | Train | Epoch[003/600] Iteration[029/030] Train loss: 0.5931
2023-02-06 10:40:28 | Train | Epoch[003/600] Iteration[030/030] Train loss: 0.5928
2023-02-06 10:40:28 | Valid | Epoch[003/600] Iteration[001/008] Valid loss: 0.5967
2023-02-06 10:40:28 | Valid | Epoch[003/600] Iteration[002/008] Valid loss: 0.5971
2023-02-06 10:40:28 | Valid | Epoch[003/600] Iteration[003/008] Valid loss: 0.5960
2023-02-06 10:40:28 | Valid | Epoch[003/600] Iteration[004/008] Valid loss: 0.5955
2023-02-06 10:40:28 | Valid | Epoch[003/600] Iteration[005/008] Valid loss: 0.5946
2023-02-06 10:40:28 | Valid | Epoch[003/600] Iteration[006/008] Valid loss: 0.5944
2023-02-06 10:40:28 | Valid | Epoch[003/600] Iteration[007/008] Valid loss: 0.5940
2023-02-06 10:40:28 | Valid | Epoch[003/600] Iteration[008/008] Valid loss: 0.5937
2023-02-06 10:40:28 | Valid | Epoch[003/600] MIou: 0.8241069210582639
2023-02-06 10:40:28 | Valid | Epoch[003/600] Pixel Accuracy: 0.9655634562174479
2023-02-06 10:40:28 | Valid | Epoch[003/600] Mean Pixel Accuracy: 0.9048914416364
2023-02-06 10:40:29 | Stage | Epoch[003/600] Train loss:0.5928
2023-02-06 10:40:29 | Stage | Epoch[003/600] Valid loss:0.5937
2023-02-06 10:40:29 | Stage | Epoch[003/600] LR:0.01

2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[001/030] Train loss: 0.5818
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[002/030] Train loss: 0.5802
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[003/030] Train loss: 0.5803
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[004/030] Train loss: 0.5799
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[005/030] Train loss: 0.5803
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[006/030] Train loss: 0.5794
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[007/030] Train loss: 0.5784
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[008/030] Train loss: 0.5777
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[009/030] Train loss: 0.5781
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[010/030] Train loss: 0.5781
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[011/030] Train loss: 0.5780
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[012/030] Train loss: 0.5774
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[013/030] Train loss: 0.5770
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[014/030] Train loss: 0.5766
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[015/030] Train loss: 0.5762
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[016/030] Train loss: 0.5761
2023-02-06 10:40:29 | Train | Epoch[004/600] Iteration[017/030] Train loss: 0.5757
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[018/030] Train loss: 0.5754
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[019/030] Train loss: 0.5750
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[020/030] Train loss: 0.5746
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[021/030] Train loss: 0.5741
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[022/030] Train loss: 0.5738
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[023/030] Train loss: 0.5733
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[024/030] Train loss: 0.5727
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[025/030] Train loss: 0.5723
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[026/030] Train loss: 0.5720
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[027/030] Train loss: 0.5717
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[028/030] Train loss: 0.5712
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[029/030] Train loss: 0.5708
2023-02-06 10:40:30 | Train | Epoch[004/600] Iteration[030/030] Train loss: 0.5703
2023-02-06 10:40:30 | Valid | Epoch[004/600] Iteration[001/008] Valid loss: 0.5798
2023-02-06 10:40:30 | Valid | Epoch[004/600] Iteration[002/008] Valid loss: 0.5778
2023-02-06 10:40:30 | Valid | Epoch[004/600] Iteration[003/008] Valid loss: 0.5767
2023-02-06 10:40:30 | Valid | Epoch[004/600] Iteration[004/008] Valid loss: 0.5763
2023-02-06 10:40:30 | Valid | Epoch[004/600] Iteration[005/008] Valid loss: 0.5758
2023-02-06 10:40:30 | Valid | Epoch[004/600] Iteration[006/008] Valid loss: 0.5757
2023-02-06 10:40:30 | Valid | Epoch[004/600] Iteration[007/008] Valid loss: 0.5753
2023-02-06 10:40:31 | Valid | Epoch[004/600] Iteration[008/008] Valid loss: 0.5747
2023-02-06 10:40:31 | Valid | Epoch[004/600] MIou: 0.7862092583015903
2023-02-06 10:40:31 | Valid | Epoch[004/600] Pixel Accuracy: 0.964562733968099
2023-02-06 10:40:31 | Valid | Epoch[004/600] Mean Pixel Accuracy: 0.8064698837479223
2023-02-06 10:40:31 | Stage | Epoch[004/600] Train loss:0.5703
2023-02-06 10:40:31 | Stage | Epoch[004/600] Valid loss:0.5747
2023-02-06 10:40:31 | Stage | Epoch[004/600] LR:0.01

2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[001/030] Train loss: 0.5556
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[002/030] Train loss: 0.5550
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[003/030] Train loss: 0.5555
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[004/030] Train loss: 0.5551
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[005/030] Train loss: 0.5560
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[006/030] Train loss: 0.5561
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[007/030] Train loss: 0.5557
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[008/030] Train loss: 0.5552
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[009/030] Train loss: 0.5544
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[010/030] Train loss: 0.5541
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[011/030] Train loss: 0.5537
2023-02-06 10:40:31 | Train | Epoch[005/600] Iteration[012/030] Train loss: 0.5532
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[013/030] Train loss: 0.5531
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[014/030] Train loss: 0.5524
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[015/030] Train loss: 0.5520
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[016/030] Train loss: 0.5515
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[017/030] Train loss: 0.5514
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[018/030] Train loss: 0.5516
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[019/030] Train loss: 0.5511
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[020/030] Train loss: 0.5507
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[021/030] Train loss: 0.5505
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[022/030] Train loss: 0.5500
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[023/030] Train loss: 0.5496
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[024/030] Train loss: 0.5492
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[025/030] Train loss: 0.5486
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[026/030] Train loss: 0.5481
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[027/030] Train loss: 0.5480
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[028/030] Train loss: 0.5475
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[029/030] Train loss: 0.5471
2023-02-06 10:40:32 | Train | Epoch[005/600] Iteration[030/030] Train loss: 0.5468
2023-02-06 10:40:33 | Valid | Epoch[005/600] Iteration[001/008] Valid loss: 0.9485
2023-02-06 10:40:33 | Valid | Epoch[005/600] Iteration[002/008] Valid loss: 0.9613
2023-02-06 10:40:33 | Valid | Epoch[005/600] Iteration[003/008] Valid loss: 0.9606
2023-02-06 10:40:33 | Valid | Epoch[005/600] Iteration[004/008] Valid loss: 0.9619
2023-02-06 10:40:33 | Valid | Epoch[005/600] Iteration[005/008] Valid loss: 0.9556
2023-02-06 10:40:33 | Valid | Epoch[005/600] Iteration[006/008] Valid loss: 0.9452
2023-02-06 10:40:33 | Valid | Epoch[005/600] Iteration[007/008] Valid loss: 0.9391
2023-02-06 10:40:33 | Valid | Epoch[005/600] Iteration[008/008] Valid loss: 0.9485
2023-02-06 10:40:33 | Valid | Epoch[005/600] MIou: 0.30643687149933113
2023-02-06 10:40:33 | Valid | Epoch[005/600] Pixel Accuracy: 0.5074234008789062
2023-02-06 10:40:33 | Valid | Epoch[005/600] Mean Pixel Accuracy: 0.7258160172081359
2023-02-06 10:40:33 | Stage | Epoch[005/600] Train loss:0.5468
2023-02-06 10:40:33 | Stage | Epoch[005/600] Valid loss:0.9485
2023-02-06 10:40:33 | Stage | Epoch[005/600] LR:0.01

2023-02-06 10:40:33 | Train | Epoch[006/600] Iteration[001/030] Train loss: 0.5333
2023-02-06 10:40:33 | Train | Epoch[006/600] Iteration[002/030] Train loss: 0.5359
2023-02-06 10:40:33 | Train | Epoch[006/600] Iteration[003/030] Train loss: 0.5353
2023-02-06 10:40:33 | Train | Epoch[006/600] Iteration[004/030] Train loss: 0.5340
2023-02-06 10:40:33 | Train | Epoch[006/600] Iteration[005/030] Train loss: 0.5344
2023-02-06 10:40:33 | Train | Epoch[006/600] Iteration[006/030] Train loss: 0.5343
2023-02-06 10:40:33 | Train | Epoch[006/600] Iteration[007/030] Train loss: 0.5341
2023-02-06 10:40:33 | Train | Epoch[006/600] Iteration[008/030] Train loss: 0.5337
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[009/030] Train loss: 0.5330
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[010/030] Train loss: 0.5326
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[011/030] Train loss: 0.5321
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[012/030] Train loss: 0.5316
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[013/030] Train loss: 0.5309
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[014/030] Train loss: 0.5306
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[015/030] Train loss: 0.5303
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[016/030] Train loss: 0.5298
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[017/030] Train loss: 0.5294
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[018/030] Train loss: 0.5294
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[019/030] Train loss: 0.5289
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[020/030] Train loss: 0.5282
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[021/030] Train loss: 0.5281
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[022/030] Train loss: 0.5276
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[023/030] Train loss: 0.5271
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[024/030] Train loss: 0.5267
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[025/030] Train loss: 0.5262
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[026/030] Train loss: 0.5259
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[027/030] Train loss: 0.5255
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[028/030] Train loss: 0.5251
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[029/030] Train loss: 0.5249
2023-02-06 10:40:34 | Train | Epoch[006/600] Iteration[030/030] Train loss: 0.5246
2023-02-06 10:40:35 | Valid | Epoch[006/600] Iteration[001/008] Valid loss: 0.5225
2023-02-06 10:40:35 | Valid | Epoch[006/600] Iteration[002/008] Valid loss: 0.5226
2023-02-06 10:40:35 | Valid | Epoch[006/600] Iteration[003/008] Valid loss: 0.5215
2023-02-06 10:40:35 | Valid | Epoch[006/600] Iteration[004/008] Valid loss: 0.5209
2023-02-06 10:40:35 | Valid | Epoch[006/600] Iteration[005/008] Valid loss: 0.5212
2023-02-06 10:40:35 | Valid | Epoch[006/600] Iteration[006/008] Valid loss: 0.5207
2023-02-06 10:40:35 | Valid | Epoch[006/600] Iteration[007/008] Valid loss: 0.5214
2023-02-06 10:40:35 | Valid | Epoch[006/600] Iteration[008/008] Valid loss: 0.5212
2023-02-06 10:40:35 | Valid | Epoch[006/600] MIou: 0.8688710337565041
2023-02-06 10:40:35 | Valid | Epoch[006/600] Pixel Accuracy: 0.9734013875325521
2023-02-06 10:40:35 | Valid | Epoch[006/600] Mean Pixel Accuracy: 0.9713551451997853
2023-02-06 10:40:35 | Stage | Epoch[006/600] Train loss:0.5246
2023-02-06 10:40:35 | Stage | Epoch[006/600] Valid loss:0.5212
2023-02-06 10:40:35 | Stage | Epoch[006/600] LR:0.01

2023-02-06 10:40:35 | Train | Epoch[007/600] Iteration[001/030] Train loss: 0.5202
2023-02-06 10:40:35 | Train | Epoch[007/600] Iteration[002/030] Train loss: 0.5144
2023-02-06 10:40:35 | Train | Epoch[007/600] Iteration[003/030] Train loss: 0.5146
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[004/030] Train loss: 0.5137
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[005/030] Train loss: 0.5124
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[006/030] Train loss: 0.5122
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[007/030] Train loss: 0.5117
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[008/030] Train loss: 0.5112
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[009/030] Train loss: 0.5106
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[010/030] Train loss: 0.5109
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[011/030] Train loss: 0.5103
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[012/030] Train loss: 0.5102
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[013/030] Train loss: 0.5097
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[014/030] Train loss: 0.5092
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[015/030] Train loss: 0.5088
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[016/030] Train loss: 0.5082
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[017/030] Train loss: 0.5077
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[018/030] Train loss: 0.5075
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[019/030] Train loss: 0.5070
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[020/030] Train loss: 0.5067
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[021/030] Train loss: 0.5063
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[022/030] Train loss: 0.5060
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[023/030] Train loss: 0.5059
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[024/030] Train loss: 0.5054
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[025/030] Train loss: 0.5053
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[026/030] Train loss: 0.5049
2023-02-06 10:40:36 | Train | Epoch[007/600] Iteration[027/030] Train loss: 0.5046
2023-02-06 10:40:37 | Train | Epoch[007/600] Iteration[028/030] Train loss: 0.5042
2023-02-06 10:40:37 | Train | Epoch[007/600] Iteration[029/030] Train loss: 0.5037
2023-02-06 10:40:37 | Train | Epoch[007/600] Iteration[030/030] Train loss: 0.5033
2023-02-06 10:40:37 | Valid | Epoch[007/600] Iteration[001/008] Valid loss: 0.5074
2023-02-06 10:40:37 | Valid | Epoch[007/600] Iteration[002/008] Valid loss: 0.5077
2023-02-06 10:40:37 | Valid | Epoch[007/600] Iteration[003/008] Valid loss: 0.5070
2023-02-06 10:40:37 | Valid | Epoch[007/600] Iteration[004/008] Valid loss: 0.5061
2023-02-06 10:40:37 | Valid | Epoch[007/600] Iteration[005/008] Valid loss: 0.5065
2023-02-06 10:40:37 | Valid | Epoch[007/600] Iteration[006/008] Valid loss: 0.5059
2023-02-06 10:40:37 | Valid | Epoch[007/600] Iteration[007/008] Valid loss: 0.5067
2023-02-06 10:40:37 | Valid | Epoch[007/600] Iteration[008/008] Valid loss: 0.5069
2023-02-06 10:40:37 | Valid | Epoch[007/600] MIou: 0.8612838700312611
2023-02-06 10:40:37 | Valid | Epoch[007/600] Pixel Accuracy: 0.9716326395670573
2023-02-06 10:40:37 | Valid | Epoch[007/600] Mean Pixel Accuracy: 0.9667371947632273
2023-02-06 10:40:37 | Stage | Epoch[007/600] Train loss:0.5033
2023-02-06 10:40:37 | Stage | Epoch[007/600] Valid loss:0.5069
2023-02-06 10:40:37 | Stage | Epoch[007/600] LR:0.01

2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[001/030] Train loss: 0.4957
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[002/030] Train loss: 0.4935
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[003/030] Train loss: 0.4925
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[004/030] Train loss: 0.4915
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[005/030] Train loss: 0.4911
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[006/030] Train loss: 0.4907
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[007/030] Train loss: 0.4900
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[008/030] Train loss: 0.4905
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[009/030] Train loss: 0.4900
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[010/030] Train loss: 0.4896
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[011/030] Train loss: 0.4896
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[012/030] Train loss: 0.4892
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[013/030] Train loss: 0.4891
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[014/030] Train loss: 0.4885
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[015/030] Train loss: 0.4881
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[016/030] Train loss: 0.4877
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[017/030] Train loss: 0.4875
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[018/030] Train loss: 0.4871
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[019/030] Train loss: 0.4868
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[020/030] Train loss: 0.4863
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[021/030] Train loss: 0.4859
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[022/030] Train loss: 0.4855
2023-02-06 10:40:38 | Train | Epoch[008/600] Iteration[023/030] Train loss: 0.4852
2023-02-06 10:40:39 | Train | Epoch[008/600] Iteration[024/030] Train loss: 0.4852
2023-02-06 10:40:39 | Train | Epoch[008/600] Iteration[025/030] Train loss: 0.4847
2023-02-06 10:40:39 | Train | Epoch[008/600] Iteration[026/030] Train loss: 0.4844
2023-02-06 10:40:39 | Train | Epoch[008/600] Iteration[027/030] Train loss: 0.4839
2023-02-06 10:40:39 | Train | Epoch[008/600] Iteration[028/030] Train loss: 0.4836
2023-02-06 10:40:39 | Train | Epoch[008/600] Iteration[029/030] Train loss: 0.4833
2023-02-06 10:40:39 | Train | Epoch[008/600] Iteration[030/030] Train loss: 0.4832
2023-02-06 10:40:39 | Valid | Epoch[008/600] Iteration[001/008] Valid loss: 0.4839
2023-02-06 10:40:39 | Valid | Epoch[008/600] Iteration[002/008] Valid loss: 0.4843
2023-02-06 10:40:39 | Valid | Epoch[008/600] Iteration[003/008] Valid loss: 0.4833
2023-02-06 10:40:39 | Valid | Epoch[008/600] Iteration[004/008] Valid loss: 0.4828
2023-02-06 10:40:39 | Valid | Epoch[008/600] Iteration[005/008] Valid loss: 0.4824
2023-02-06 10:40:39 | Valid | Epoch[008/600] Iteration[006/008] Valid loss: 0.4816
2023-02-06 10:40:39 | Valid | Epoch[008/600] Iteration[007/008] Valid loss: 0.4818
2023-02-06 10:40:39 | Valid | Epoch[008/600] Iteration[008/008] Valid loss: 0.4819
2023-02-06 10:40:39 | Valid | Epoch[008/600] MIou: 0.8818908082843546
2023-02-06 10:40:39 | Valid | Epoch[008/600] Pixel Accuracy: 0.9771334330240885
2023-02-06 10:40:39 | Valid | Epoch[008/600] Mean Pixel Accuracy: 0.9628812538597717
2023-02-06 10:40:39 | Stage | Epoch[008/600] Train loss:0.4832
2023-02-06 10:40:39 | Stage | Epoch[008/600] Valid loss:0.4819
2023-02-06 10:40:39 | Stage | Epoch[008/600] LR:0.01

2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[001/030] Train loss: 0.4711
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[002/030] Train loss: 0.4720
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[003/030] Train loss: 0.4707
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[004/030] Train loss: 0.4706
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[005/030] Train loss: 0.4706
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[006/030] Train loss: 0.4706
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[007/030] Train loss: 0.4702
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[008/030] Train loss: 0.4700
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[009/030] Train loss: 0.4700
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[010/030] Train loss: 0.4697
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[011/030] Train loss: 0.4689
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[012/030] Train loss: 0.4684
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[013/030] Train loss: 0.4681
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[014/030] Train loss: 0.4678
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[015/030] Train loss: 0.4674
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[016/030] Train loss: 0.4672
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[017/030] Train loss: 0.4669
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[018/030] Train loss: 0.4666
2023-02-06 10:40:40 | Train | Epoch[009/600] Iteration[019/030] Train loss: 0.4662
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[020/030] Train loss: 0.4660
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[021/030] Train loss: 0.4657
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[022/030] Train loss: 0.4655
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[023/030] Train loss: 0.4655
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[024/030] Train loss: 0.4653
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[025/030] Train loss: 0.4648
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[026/030] Train loss: 0.4645
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[027/030] Train loss: 0.4641
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[028/030] Train loss: 0.4639
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[029/030] Train loss: 0.4637
2023-02-06 10:40:41 | Train | Epoch[009/600] Iteration[030/030] Train loss: 0.4633
2023-02-06 10:40:41 | Valid | Epoch[009/600] Iteration[001/008] Valid loss: 0.4585
2023-02-06 10:40:41 | Valid | Epoch[009/600] Iteration[002/008] Valid loss: 0.4585
2023-02-06 10:40:41 | Valid | Epoch[009/600] Iteration[003/008] Valid loss: 0.4574
2023-02-06 10:40:41 | Valid | Epoch[009/600] Iteration[004/008] Valid loss: 0.4567
2023-02-06 10:40:41 | Valid | Epoch[009/600] Iteration[005/008] Valid loss: 0.4565
2023-02-06 10:40:41 | Valid | Epoch[009/600] Iteration[006/008] Valid loss: 0.4561
2023-02-06 10:40:41 | Valid | Epoch[009/600] Iteration[007/008] Valid loss: 0.4560
2023-02-06 10:40:41 | Valid | Epoch[009/600] Iteration[008/008] Valid loss: 0.4556
2023-02-06 10:40:42 | Valid | Epoch[009/600] MIou: 0.9208169303066337
2023-02-06 10:40:42 | Valid | Epoch[009/600] Pixel Accuracy: 0.9864501953125
2023-02-06 10:40:42 | Valid | Epoch[009/600] Mean Pixel Accuracy: 0.9450496368900551
2023-02-06 10:40:42 | Stage | Epoch[009/600] Train loss:0.4633
2023-02-06 10:40:42 | Stage | Epoch[009/600] Valid loss:0.4556
2023-02-06 10:40:42 | Stage | Epoch[009/600] LR:0.01

2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[001/030] Train loss: 0.4542
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[002/030] Train loss: 0.4562
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[003/030] Train loss: 0.4557
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[004/030] Train loss: 0.4545
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[005/030] Train loss: 0.4531
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[006/030] Train loss: 0.4522
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[007/030] Train loss: 0.4521
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[008/030] Train loss: 0.4522
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[009/030] Train loss: 0.4514
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[010/030] Train loss: 0.4513
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[011/030] Train loss: 0.4504
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[012/030] Train loss: 0.4498
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[013/030] Train loss: 0.4494
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[014/030] Train loss: 0.4491
2023-02-06 10:40:42 | Train | Epoch[010/600] Iteration[015/030] Train loss: 0.4488
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[016/030] Train loss: 0.4486
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[017/030] Train loss: 0.4480
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[018/030] Train loss: 0.4478
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[019/030] Train loss: 0.4474
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[020/030] Train loss: 0.4473
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[021/030] Train loss: 0.4469
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[022/030] Train loss: 0.4467
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[023/030] Train loss: 0.4464
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[024/030] Train loss: 0.4460
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[025/030] Train loss: 0.4457
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[026/030] Train loss: 0.4453
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[027/030] Train loss: 0.4451
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[028/030] Train loss: 0.4448
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[029/030] Train loss: 0.4446
2023-02-06 10:40:43 | Train | Epoch[010/600] Iteration[030/030] Train loss: 0.4443
2023-02-06 10:40:43 | Valid | Epoch[010/600] Iteration[001/008] Valid loss: 0.4400
2023-02-06 10:40:44 | Valid | Epoch[010/600] Iteration[002/008] Valid loss: 0.4396
2023-02-06 10:40:44 | Valid | Epoch[010/600] Iteration[003/008] Valid loss: 0.4385
2023-02-06 10:40:44 | Valid | Epoch[010/600] Iteration[004/008] Valid loss: 0.4381
2023-02-06 10:40:44 | Valid | Epoch[010/600] Iteration[005/008] Valid loss: 0.4387
2023-02-06 10:40:44 | Valid | Epoch[010/600] Iteration[006/008] Valid loss: 0.4381
2023-02-06 10:40:44 | Valid | Epoch[010/600] Iteration[007/008] Valid loss: 0.4390
2023-02-06 10:40:44 | Valid | Epoch[010/600] Iteration[008/008] Valid loss: 0.4388
2023-02-06 10:40:44 | Valid | Epoch[010/600] MIou: 0.896760883602542
2023-02-06 10:40:44 | Valid | Epoch[010/600] Pixel Accuracy: 0.9801177978515625
2023-02-06 10:40:44 | Valid | Epoch[010/600] Mean Pixel Accuracy: 0.9763846102481342
2023-02-06 10:40:44 | Stage | Epoch[010/600] Train loss:0.4443
2023-02-06 10:40:44 | Stage | Epoch[010/600] Valid loss:0.4388
2023-02-06 10:40:44 | Stage | Epoch[010/600] LR:0.01

2023-02-06 10:40:44 | Train | Epoch[011/600] Iteration[001/030] Train loss: 0.4314
2023-02-06 10:40:44 | Train | Epoch[011/600] Iteration[002/030] Train loss: 0.4322
2023-02-06 10:40:44 | Train | Epoch[011/600] Iteration[003/030] Train loss: 0.4325
2023-02-06 10:40:44 | Train | Epoch[011/600] Iteration[004/030] Train loss: 0.4327
2023-02-06 10:40:44 | Train | Epoch[011/600] Iteration[005/030] Train loss: 0.4321
2023-02-06 10:40:44 | Train | Epoch[011/600] Iteration[006/030] Train loss: 0.4319
2023-02-06 10:40:44 | Train | Epoch[011/600] Iteration[007/030] Train loss: 0.4316
2023-02-06 10:40:44 | Train | Epoch[011/600] Iteration[008/030] Train loss: 0.4313
2023-02-06 10:40:44 | Train | Epoch[011/600] Iteration[009/030] Train loss: 0.4313
2023-02-06 10:40:44 | Train | Epoch[011/600] Iteration[010/030] Train loss: 0.4315
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[011/030] Train loss: 0.4313
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[012/030] Train loss: 0.4312
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[013/030] Train loss: 0.4311
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[014/030] Train loss: 0.4308
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[015/030] Train loss: 0.4303
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[016/030] Train loss: 0.4302
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[017/030] Train loss: 0.4300
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[018/030] Train loss: 0.4295
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[019/030] Train loss: 0.4294
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[020/030] Train loss: 0.4293
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[021/030] Train loss: 0.4292
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[022/030] Train loss: 0.4289
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[023/030] Train loss: 0.4289
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[024/030] Train loss: 0.4285
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[025/030] Train loss: 0.4280
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[026/030] Train loss: 0.4276
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[027/030] Train loss: 0.4272
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[028/030] Train loss: 0.4268
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[029/030] Train loss: 0.4265
2023-02-06 10:40:45 | Train | Epoch[011/600] Iteration[030/030] Train loss: 0.4263
2023-02-06 10:40:46 | Valid | Epoch[011/600] Iteration[001/008] Valid loss: 0.5776
2023-02-06 10:40:46 | Valid | Epoch[011/600] Iteration[002/008] Valid loss: 0.5794
2023-02-06 10:40:46 | Valid | Epoch[011/600] Iteration[003/008] Valid loss: 0.5815
2023-02-06 10:40:46 | Valid | Epoch[011/600] Iteration[004/008] Valid loss: 0.5836
2023-02-06 10:40:46 | Valid | Epoch[011/600] Iteration[005/008] Valid loss: 0.5847
2023-02-06 10:40:46 | Valid | Epoch[011/600] Iteration[006/008] Valid loss: 0.5805
2023-02-06 10:40:46 | Valid | Epoch[011/600] Iteration[007/008] Valid loss: 0.5829
2023-02-06 10:40:46 | Valid | Epoch[011/600] Iteration[008/008] Valid loss: 0.5878
2023-02-06 10:40:46 | Valid | Epoch[011/600] MIou: 0.6869819465535344
2023-02-06 10:40:46 | Valid | Epoch[011/600] Pixel Accuracy: 0.902917226155599
2023-02-06 10:40:46 | Valid | Epoch[011/600] Mean Pixel Accuracy: 0.9442614901979253
2023-02-06 10:40:46 | Stage | Epoch[011/600] Train loss:0.4263
2023-02-06 10:40:46 | Stage | Epoch[011/600] Valid loss:0.5878
2023-02-06 10:40:46 | Stage | Epoch[011/600] LR:0.01

2023-02-06 10:40:46 | Train | Epoch[012/600] Iteration[001/030] Train loss: 0.4194
2023-02-06 10:40:46 | Train | Epoch[012/600] Iteration[002/030] Train loss: 0.4162
2023-02-06 10:40:46 | Train | Epoch[012/600] Iteration[003/030] Train loss: 0.4151
2023-02-06 10:40:46 | Train | Epoch[012/600] Iteration[004/030] Train loss: 0.4158
2023-02-06 10:40:46 | Train | Epoch[012/600] Iteration[005/030] Train loss: 0.4154
2023-02-06 10:40:46 | Train | Epoch[012/600] Iteration[006/030] Train loss: 0.4152
2023-02-06 10:40:46 | Train | Epoch[012/600] Iteration[007/030] Train loss: 0.4147
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[008/030] Train loss: 0.4139
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[009/030] Train loss: 0.4134
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[010/030] Train loss: 0.4133
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[011/030] Train loss: 0.4138
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[012/030] Train loss: 0.4137
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[013/030] Train loss: 0.4134
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[014/030] Train loss: 0.4130
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[015/030] Train loss: 0.4125
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[016/030] Train loss: 0.4120
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[017/030] Train loss: 0.4118
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[018/030] Train loss: 0.4115
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[019/030] Train loss: 0.4113
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[020/030] Train loss: 0.4110
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[021/030] Train loss: 0.4106
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[022/030] Train loss: 0.4105
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[023/030] Train loss: 0.4102
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[024/030] Train loss: 0.4099
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[025/030] Train loss: 0.4096
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[026/030] Train loss: 0.4095
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[027/030] Train loss: 0.4092
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[028/030] Train loss: 0.4091
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[029/030] Train loss: 0.4087
2023-02-06 10:40:47 | Train | Epoch[012/600] Iteration[030/030] Train loss: 0.4083
2023-02-06 10:40:48 | Valid | Epoch[012/600] Iteration[001/008] Valid loss: 0.4299
2023-02-06 10:40:48 | Valid | Epoch[012/600] Iteration[002/008] Valid loss: 0.4295
2023-02-06 10:40:48 | Valid | Epoch[012/600] Iteration[003/008] Valid loss: 0.4284
2023-02-06 10:40:48 | Valid | Epoch[012/600] Iteration[004/008] Valid loss: 0.4286
2023-02-06 10:40:48 | Valid | Epoch[012/600] Iteration[005/008] Valid loss: 0.4289
2023-02-06 10:40:48 | Valid | Epoch[012/600] Iteration[006/008] Valid loss: 0.4278
2023-02-06 10:40:48 | Valid | Epoch[012/600] Iteration[007/008] Valid loss: 0.4291
2023-02-06 10:40:48 | Valid | Epoch[012/600] Iteration[008/008] Valid loss: 0.4294
2023-02-06 10:40:48 | Valid | Epoch[012/600] MIou: 0.8644396564576163
2023-02-06 10:40:48 | Valid | Epoch[012/600] Pixel Accuracy: 0.9719530741373698
2023-02-06 10:40:48 | Valid | Epoch[012/600] Mean Pixel Accuracy: 0.9762528338065684
2023-02-06 10:40:48 | Stage | Epoch[012/600] Train loss:0.4083
2023-02-06 10:40:48 | Stage | Epoch[012/600] Valid loss:0.4294
2023-02-06 10:40:48 | Stage | Epoch[012/600] LR:0.01

2023-02-06 10:40:48 | Train | Epoch[013/600] Iteration[001/030] Train loss: 0.3990
2023-02-06 10:40:48 | Train | Epoch[013/600] Iteration[002/030] Train loss: 0.3982
2023-02-06 10:40:48 | Train | Epoch[013/600] Iteration[003/030] Train loss: 0.3978
2023-02-06 10:40:48 | Train | Epoch[013/600] Iteration[004/030] Train loss: 0.3973
2023-02-06 10:40:48 | Train | Epoch[013/600] Iteration[005/030] Train loss: 0.3972
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[006/030] Train loss: 0.3968
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[007/030] Train loss: 0.3979
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[008/030] Train loss: 0.3975
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[009/030] Train loss: 0.3972
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[010/030] Train loss: 0.3966
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[011/030] Train loss: 0.3962
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[012/030] Train loss: 0.3959
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[013/030] Train loss: 0.3957
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[014/030] Train loss: 0.3954
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[015/030] Train loss: 0.3951
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[016/030] Train loss: 0.3949
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[017/030] Train loss: 0.3946
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[018/030] Train loss: 0.3942
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[019/030] Train loss: 0.3939
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[020/030] Train loss: 0.3935
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[021/030] Train loss: 0.3933
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[022/030] Train loss: 0.3934
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[023/030] Train loss: 0.3931
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[024/030] Train loss: 0.3930
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[025/030] Train loss: 0.3928
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[026/030] Train loss: 0.3926
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[027/030] Train loss: 0.3924
2023-02-06 10:40:49 | Train | Epoch[013/600] Iteration[028/030] Train loss: 0.3920
2023-02-06 10:40:50 | Train | Epoch[013/600] Iteration[029/030] Train loss: 0.3918
2023-02-06 10:40:50 | Train | Epoch[013/600] Iteration[030/030] Train loss: 0.3916
2023-02-06 10:40:50 | Valid | Epoch[013/600] Iteration[001/008] Valid loss: 0.5149
2023-02-06 10:40:50 | Valid | Epoch[013/600] Iteration[002/008] Valid loss: 0.5189
2023-02-06 10:40:50 | Valid | Epoch[013/600] Iteration[003/008] Valid loss: 0.5181
2023-02-06 10:40:50 | Valid | Epoch[013/600] Iteration[004/008] Valid loss: 0.5189
2023-02-06 10:40:50 | Valid | Epoch[013/600] Iteration[005/008] Valid loss: 0.5181
2023-02-06 10:40:50 | Valid | Epoch[013/600] Iteration[006/008] Valid loss: 0.5154
2023-02-06 10:40:50 | Valid | Epoch[013/600] Iteration[007/008] Valid loss: 0.5151
2023-02-06 10:40:50 | Valid | Epoch[013/600] Iteration[008/008] Valid loss: 0.5174
2023-02-06 10:40:50 | Valid | Epoch[013/600] MIou: 0.7481542965944594
2023-02-06 10:40:50 | Valid | Epoch[013/600] Pixel Accuracy: 0.933172861735026
2023-02-06 10:40:50 | Valid | Epoch[013/600] Mean Pixel Accuracy: 0.9539421211067872
2023-02-06 10:40:50 | Stage | Epoch[013/600] Train loss:0.3916
2023-02-06 10:40:50 | Stage | Epoch[013/600] Valid loss:0.5174
2023-02-06 10:40:50 | Stage | Epoch[013/600] LR:0.01

2023-02-06 10:40:50 | Train | Epoch[014/600] Iteration[001/030] Train loss: 0.3802
2023-02-06 10:40:50 | Train | Epoch[014/600] Iteration[002/030] Train loss: 0.3801
2023-02-06 10:40:50 | Train | Epoch[014/600] Iteration[003/030] Train loss: 0.3794
2023-02-06 10:40:50 | Train | Epoch[014/600] Iteration[004/030] Train loss: 0.3802
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[005/030] Train loss: 0.3821
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[006/030] Train loss: 0.3814
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[007/030] Train loss: 0.3808
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[008/030] Train loss: 0.3802
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[009/030] Train loss: 0.3795
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[010/030] Train loss: 0.3791
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[011/030] Train loss: 0.3789
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[012/030] Train loss: 0.3795
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[013/030] Train loss: 0.3792
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[014/030] Train loss: 0.3793
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[015/030] Train loss: 0.3788
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[016/030] Train loss: 0.3788
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[017/030] Train loss: 0.3786
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[018/030] Train loss: 0.3784
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[019/030] Train loss: 0.3783
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[020/030] Train loss: 0.3780
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[021/030] Train loss: 0.3777
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[022/030] Train loss: 0.3774
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[023/030] Train loss: 0.3772
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[024/030] Train loss: 0.3769
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[025/030] Train loss: 0.3767
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[026/030] Train loss: 0.3764
2023-02-06 10:40:51 | Train | Epoch[014/600] Iteration[027/030] Train loss: 0.3761
2023-02-06 10:40:52 | Train | Epoch[014/600] Iteration[028/030] Train loss: 0.3759
2023-02-06 10:40:52 | Train | Epoch[014/600] Iteration[029/030] Train loss: 0.3759
2023-02-06 10:40:52 | Train | Epoch[014/600] Iteration[030/030] Train loss: 0.3757
2023-02-06 10:40:52 | Valid | Epoch[014/600] Iteration[001/008] Valid loss: 0.5937
2023-02-06 10:40:52 | Valid | Epoch[014/600] Iteration[002/008] Valid loss: 0.5837
2023-02-06 10:40:52 | Valid | Epoch[014/600] Iteration[003/008] Valid loss: 0.5916
2023-02-06 10:40:52 | Valid | Epoch[014/600] Iteration[004/008] Valid loss: 0.5958
2023-02-06 10:40:52 | Valid | Epoch[014/600] Iteration[005/008] Valid loss: 0.6012
2023-02-06 10:40:52 | Valid | Epoch[014/600] Iteration[006/008] Valid loss: 0.5959
2023-02-06 10:40:52 | Valid | Epoch[014/600] Iteration[007/008] Valid loss: 0.6039
2023-02-06 10:40:52 | Valid | Epoch[014/600] Iteration[008/008] Valid loss: 0.6114
2023-02-06 10:40:52 | Valid | Epoch[014/600] MIou: 0.7325679116993424
2023-02-06 10:40:52 | Valid | Epoch[014/600] Pixel Accuracy: 0.9254531860351562
2023-02-06 10:40:52 | Valid | Epoch[014/600] Mean Pixel Accuracy: 0.9576246474960329
2023-02-06 10:40:52 | Stage | Epoch[014/600] Train loss:0.3757
2023-02-06 10:40:52 | Stage | Epoch[014/600] Valid loss:0.6114
2023-02-06 10:40:52 | Stage | Epoch[014/600] LR:0.01

2023-02-06 10:40:52 | Train | Epoch[015/600] Iteration[001/030] Train loss: 0.3691
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[002/030] Train loss: 0.3724
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[003/030] Train loss: 0.3698
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[004/030] Train loss: 0.3681
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[005/030] Train loss: 0.3670
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[006/030] Train loss: 0.3679
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[007/030] Train loss: 0.3675
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[008/030] Train loss: 0.3672
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[009/030] Train loss: 0.3676
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[010/030] Train loss: 0.3679
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[011/030] Train loss: 0.3680
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[012/030] Train loss: 0.3679
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[013/030] Train loss: 0.3681
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[014/030] Train loss: 0.3687
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[015/030] Train loss: 0.3687
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[016/030] Train loss: 0.3684
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[017/030] Train loss: 0.3686
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[018/030] Train loss: 0.3680
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[019/030] Train loss: 0.3678
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[020/030] Train loss: 0.3675
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[021/030] Train loss: 0.3674
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[022/030] Train loss: 0.3671
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[023/030] Train loss: 0.3667
2023-02-06 10:40:53 | Train | Epoch[015/600] Iteration[024/030] Train loss: 0.3664
2023-02-06 10:40:54 | Train | Epoch[015/600] Iteration[025/030] Train loss: 0.3659
2023-02-06 10:40:54 | Train | Epoch[015/600] Iteration[026/030] Train loss: 0.3656
2023-02-06 10:40:54 | Train | Epoch[015/600] Iteration[027/030] Train loss: 0.3653
2023-02-06 10:40:54 | Train | Epoch[015/600] Iteration[028/030] Train loss: 0.3650
2023-02-06 10:40:54 | Train | Epoch[015/600] Iteration[029/030] Train loss: 0.3648
2023-02-06 10:40:54 | Train | Epoch[015/600] Iteration[030/030] Train loss: 0.3646
2023-02-06 10:40:54 | Valid | Epoch[015/600] Iteration[001/008] Valid loss: 0.4417
2023-02-06 10:40:54 | Valid | Epoch[015/600] Iteration[002/008] Valid loss: 0.4384
2023-02-06 10:40:54 | Valid | Epoch[015/600] Iteration[003/008] Valid loss: 0.4398
2023-02-06 10:40:54 | Valid | Epoch[015/600] Iteration[004/008] Valid loss: 0.4392
2023-02-06 10:40:54 | Valid | Epoch[015/600] Iteration[005/008] Valid loss: 0.4409
2023-02-06 10:40:54 | Valid | Epoch[015/600] Iteration[006/008] Valid loss: 0.4375
2023-02-06 10:40:54 | Valid | Epoch[015/600] Iteration[007/008] Valid loss: 0.4393
2023-02-06 10:40:54 | Valid | Epoch[015/600] Iteration[008/008] Valid loss: 0.4430
2023-02-06 10:40:54 | Valid | Epoch[015/600] MIou: 0.8302507029999702
2023-02-06 10:40:54 | Valid | Epoch[015/600] Pixel Accuracy: 0.9621289571126302
2023-02-06 10:40:54 | Valid | Epoch[015/600] Mean Pixel Accuracy: 0.9738521231265279
2023-02-06 10:40:54 | Stage | Epoch[015/600] Train loss:0.3646
2023-02-06 10:40:54 | Stage | Epoch[015/600] Valid loss:0.4430
2023-02-06 10:40:54 | Stage | Epoch[015/600] LR:0.01

2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[001/030] Train loss: 0.3527
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[002/030] Train loss: 0.3588
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[003/030] Train loss: 0.3581
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[004/030] Train loss: 0.3575
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[005/030] Train loss: 0.3572
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[006/030] Train loss: 0.3562
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[007/030] Train loss: 0.3561
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[008/030] Train loss: 0.3550
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[009/030] Train loss: 0.3545
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[010/030] Train loss: 0.3542
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[011/030] Train loss: 0.3539
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[012/030] Train loss: 0.3535
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[013/030] Train loss: 0.3532
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[014/030] Train loss: 0.3528
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[015/030] Train loss: 0.3525
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[016/030] Train loss: 0.3526
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[017/030] Train loss: 0.3522
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[018/030] Train loss: 0.3519
2023-02-06 10:40:55 | Train | Epoch[016/600] Iteration[019/030] Train loss: 0.3515
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[020/030] Train loss: 0.3513
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[021/030] Train loss: 0.3510
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[022/030] Train loss: 0.3509
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[023/030] Train loss: 0.3506
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[024/030] Train loss: 0.3503
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[025/030] Train loss: 0.3500
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[026/030] Train loss: 0.3496
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[027/030] Train loss: 0.3493
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[028/030] Train loss: 0.3490
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[029/030] Train loss: 0.3488
2023-02-06 10:40:56 | Train | Epoch[016/600] Iteration[030/030] Train loss: 0.3485
2023-02-06 10:40:56 | Valid | Epoch[016/600] Iteration[001/008] Valid loss: 0.5638
2023-02-06 10:40:56 | Valid | Epoch[016/600] Iteration[002/008] Valid loss: 0.5657
2023-02-06 10:40:56 | Valid | Epoch[016/600] Iteration[003/008] Valid loss: 0.5660
2023-02-06 10:40:56 | Valid | Epoch[016/600] Iteration[004/008] Valid loss: 0.5676
2023-02-06 10:40:56 | Valid | Epoch[016/600] Iteration[005/008] Valid loss: 0.5668
2023-02-06 10:40:56 | Valid | Epoch[016/600] Iteration[006/008] Valid loss: 0.5647
2023-02-06 10:40:56 | Valid | Epoch[016/600] Iteration[007/008] Valid loss: 0.5651
2023-02-06 10:40:56 | Valid | Epoch[016/600] Iteration[008/008] Valid loss: 0.5678
2023-02-06 10:40:57 | Valid | Epoch[016/600] MIou: 0.6590200182912471
2023-02-06 10:40:57 | Valid | Epoch[016/600] Pixel Accuracy: 0.8934351603190104
2023-02-06 10:40:57 | Valid | Epoch[016/600] Mean Pixel Accuracy: 0.8986672793533729
2023-02-06 10:40:57 | Stage | Epoch[016/600] Train loss:0.3485
2023-02-06 10:40:57 | Stage | Epoch[016/600] Valid loss:0.5678
2023-02-06 10:40:57 | Stage | Epoch[016/600] LR:0.01

2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[001/030] Train loss: 0.3463
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[002/030] Train loss: 0.3442
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[003/030] Train loss: 0.3439
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[004/030] Train loss: 0.3425
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[005/030] Train loss: 0.3415
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[006/030] Train loss: 0.3412
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[007/030] Train loss: 0.3409
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[008/030] Train loss: 0.3401
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[009/030] Train loss: 0.3400
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[010/030] Train loss: 0.3394
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[011/030] Train loss: 0.3386
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[012/030] Train loss: 0.3381
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[013/030] Train loss: 0.3379
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[014/030] Train loss: 0.3380
2023-02-06 10:40:57 | Train | Epoch[017/600] Iteration[015/030] Train loss: 0.3378
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[016/030] Train loss: 0.3375
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[017/030] Train loss: 0.3374
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[018/030] Train loss: 0.3373
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[019/030] Train loss: 0.3371
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[020/030] Train loss: 0.3367
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[021/030] Train loss: 0.3365
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[022/030] Train loss: 0.3361
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[023/030] Train loss: 0.3358
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[024/030] Train loss: 0.3354
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[025/030] Train loss: 0.3351
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[026/030] Train loss: 0.3348
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[027/030] Train loss: 0.3345
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[028/030] Train loss: 0.3344
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[029/030] Train loss: 0.3342
2023-02-06 10:40:58 | Train | Epoch[017/600] Iteration[030/030] Train loss: 0.3341
2023-02-06 10:40:58 | Valid | Epoch[017/600] Iteration[001/008] Valid loss: 0.3907
2023-02-06 10:40:58 | Valid | Epoch[017/600] Iteration[002/008] Valid loss: 0.3915
2023-02-06 10:40:58 | Valid | Epoch[017/600] Iteration[003/008] Valid loss: 0.3918
2023-02-06 10:40:58 | Valid | Epoch[017/600] Iteration[004/008] Valid loss: 0.3921
2023-02-06 10:40:59 | Valid | Epoch[017/600] Iteration[005/008] Valid loss: 0.3923
2023-02-06 10:40:59 | Valid | Epoch[017/600] Iteration[006/008] Valid loss: 0.3913
2023-02-06 10:40:59 | Valid | Epoch[017/600] Iteration[007/008] Valid loss: 0.3917
2023-02-06 10:40:59 | Valid | Epoch[017/600] Iteration[008/008] Valid loss: 0.3931
2023-02-06 10:40:59 | Valid | Epoch[017/600] MIou: 0.7744310135554018
2023-02-06 10:40:59 | Valid | Epoch[017/600] Pixel Accuracy: 0.957787831624349
2023-02-06 10:40:59 | Valid | Epoch[017/600] Mean Pixel Accuracy: 0.8342011876486287
2023-02-06 10:40:59 | Stage | Epoch[017/600] Train loss:0.3341
2023-02-06 10:40:59 | Stage | Epoch[017/600] Valid loss:0.3931
2023-02-06 10:40:59 | Stage | Epoch[017/600] LR:0.01

2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[001/030] Train loss: 0.3214
2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[002/030] Train loss: 0.3227
2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[003/030] Train loss: 0.3240
2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[004/030] Train loss: 0.3240
2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[005/030] Train loss: 0.3244
2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[006/030] Train loss: 0.3239
2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[007/030] Train loss: 0.3237
2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[008/030] Train loss: 0.3239
2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[009/030] Train loss: 0.3236
2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[010/030] Train loss: 0.3231
2023-02-06 10:40:59 | Train | Epoch[018/600] Iteration[011/030] Train loss: 0.3230
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[012/030] Train loss: 0.3236
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[013/030] Train loss: 0.3234
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[014/030] Train loss: 0.3232
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[015/030] Train loss: 0.3230
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[016/030] Train loss: 0.3232
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[017/030] Train loss: 0.3229
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[018/030] Train loss: 0.3233
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[019/030] Train loss: 0.3229
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[020/030] Train loss: 0.3228
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[021/030] Train loss: 0.3226
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[022/030] Train loss: 0.3223
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[023/030] Train loss: 0.3220
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[024/030] Train loss: 0.3218
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[025/030] Train loss: 0.3215
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[026/030] Train loss: 0.3215
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[027/030] Train loss: 0.3213
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[028/030] Train loss: 0.3211
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[029/030] Train loss: 0.3208
2023-02-06 10:41:00 | Train | Epoch[018/600] Iteration[030/030] Train loss: 0.3207
2023-02-06 10:41:01 | Valid | Epoch[018/600] Iteration[001/008] Valid loss: 0.3355
2023-02-06 10:41:01 | Valid | Epoch[018/600] Iteration[002/008] Valid loss: 0.3361
2023-02-06 10:41:01 | Valid | Epoch[018/600] Iteration[003/008] Valid loss: 0.3357
2023-02-06 10:41:01 | Valid | Epoch[018/600] Iteration[004/008] Valid loss: 0.3352
2023-02-06 10:41:01 | Valid | Epoch[018/600] Iteration[005/008] Valid loss: 0.3354
2023-02-06 10:41:01 | Valid | Epoch[018/600] Iteration[006/008] Valid loss: 0.3349
2023-02-06 10:41:01 | Valid | Epoch[018/600] Iteration[007/008] Valid loss: 0.3343
2023-02-06 10:41:01 | Valid | Epoch[018/600] Iteration[008/008] Valid loss: 0.3344
2023-02-06 10:41:01 | Valid | Epoch[018/600] MIou: 0.8268146864175061
2023-02-06 10:41:01 | Valid | Epoch[018/600] Pixel Accuracy: 0.9714457194010416
2023-02-06 10:41:01 | Valid | Epoch[018/600] Mean Pixel Accuracy: 0.8422344044010269
2023-02-06 10:41:01 | Stage | Epoch[018/600] Train loss:0.3207
2023-02-06 10:41:01 | Stage | Epoch[018/600] Valid loss:0.3344
2023-02-06 10:41:01 | Stage | Epoch[018/600] LR:0.01

2023-02-06 10:41:01 | Train | Epoch[019/600] Iteration[001/030] Train loss: 0.3129
2023-02-06 10:41:01 | Train | Epoch[019/600] Iteration[002/030] Train loss: 0.3118
2023-02-06 10:41:01 | Train | Epoch[019/600] Iteration[003/030] Train loss: 0.3131
2023-02-06 10:41:01 | Train | Epoch[019/600] Iteration[004/030] Train loss: 0.3135
2023-02-06 10:41:01 | Train | Epoch[019/600] Iteration[005/030] Train loss: 0.3131
2023-02-06 10:41:01 | Train | Epoch[019/600] Iteration[006/030] Train loss: 0.3128
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[007/030] Train loss: 0.3125
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[008/030] Train loss: 0.3121
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[009/030] Train loss: 0.3116
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[010/030] Train loss: 0.3117
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[011/030] Train loss: 0.3115
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[012/030] Train loss: 0.3112
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[013/030] Train loss: 0.3110
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[014/030] Train loss: 0.3107
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[015/030] Train loss: 0.3104
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[016/030] Train loss: 0.3104
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[017/030] Train loss: 0.3100
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[018/030] Train loss: 0.3098
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[019/030] Train loss: 0.3096
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[020/030] Train loss: 0.3093
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[021/030] Train loss: 0.3090
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[022/030] Train loss: 0.3087
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[023/030] Train loss: 0.3086
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[024/030] Train loss: 0.3084
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[025/030] Train loss: 0.3081
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[026/030] Train loss: 0.3080
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[027/030] Train loss: 0.3080
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[028/030] Train loss: 0.3080
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[029/030] Train loss: 0.3080
2023-02-06 10:41:02 | Train | Epoch[019/600] Iteration[030/030] Train loss: 0.3078
2023-02-06 10:41:03 | Valid | Epoch[019/600] Iteration[001/008] Valid loss: 0.3689
2023-02-06 10:41:03 | Valid | Epoch[019/600] Iteration[002/008] Valid loss: 0.3675
2023-02-06 10:41:03 | Valid | Epoch[019/600] Iteration[003/008] Valid loss: 0.3686
2023-02-06 10:41:03 | Valid | Epoch[019/600] Iteration[004/008] Valid loss: 0.3694
2023-02-06 10:41:03 | Valid | Epoch[019/600] Iteration[005/008] Valid loss: 0.3702
2023-02-06 10:41:03 | Valid | Epoch[019/600] Iteration[006/008] Valid loss: 0.3701
2023-02-06 10:41:03 | Valid | Epoch[019/600] Iteration[007/008] Valid loss: 0.3698
2023-02-06 10:41:03 | Valid | Epoch[019/600] Iteration[008/008] Valid loss: 0.3706
2023-02-06 10:41:03 | Valid | Epoch[019/600] MIou: 0.5226657213348518
2023-02-06 10:41:03 | Valid | Epoch[019/600] Pixel Accuracy: 0.9209925333658854
2023-02-06 10:41:03 | Valid | Epoch[019/600] Mean Pixel Accuracy: 0.5626216102908816
2023-02-06 10:41:03 | Stage | Epoch[019/600] Train loss:0.3078
2023-02-06 10:41:03 | Stage | Epoch[019/600] Valid loss:0.3706
2023-02-06 10:41:03 | Stage | Epoch[019/600] LR:0.01

2023-02-06 10:41:03 | Train | Epoch[020/600] Iteration[001/030] Train loss: 0.3023
2023-02-06 10:41:03 | Train | Epoch[020/600] Iteration[002/030] Train loss: 0.3002
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[003/030] Train loss: 0.3000
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[004/030] Train loss: 0.2994
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[005/030] Train loss: 0.2990
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[006/030] Train loss: 0.2991
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[007/030] Train loss: 0.2999
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[008/030] Train loss: 0.3001
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[009/030] Train loss: 0.2995
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[010/030] Train loss: 0.2995
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[011/030] Train loss: 0.2990
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[012/030] Train loss: 0.2993
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[013/030] Train loss: 0.2991
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[014/030] Train loss: 0.2990
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[015/030] Train loss: 0.2988
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[016/030] Train loss: 0.2984
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[017/030] Train loss: 0.2982
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[018/030] Train loss: 0.2982
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[019/030] Train loss: 0.2980
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[020/030] Train loss: 0.2979
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[021/030] Train loss: 0.2977
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[022/030] Train loss: 0.2974
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[023/030] Train loss: 0.2972
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[024/030] Train loss: 0.2970
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[025/030] Train loss: 0.2966
2023-02-06 10:41:04 | Train | Epoch[020/600] Iteration[026/030] Train loss: 0.2965
2023-02-06 10:41:05 | Train | Epoch[020/600] Iteration[027/030] Train loss: 0.2964
2023-02-06 10:41:05 | Train | Epoch[020/600] Iteration[028/030] Train loss: 0.2966
2023-02-06 10:41:05 | Train | Epoch[020/600] Iteration[029/030] Train loss: 0.2965
2023-02-06 10:41:05 | Train | Epoch[020/600] Iteration[030/030] Train loss: 0.2962
2023-02-06 10:41:05 | Valid | Epoch[020/600] Iteration[001/008] Valid loss: 0.3422
2023-02-06 10:41:05 | Valid | Epoch[020/600] Iteration[002/008] Valid loss: 0.3439
2023-02-06 10:41:05 | Valid | Epoch[020/600] Iteration[003/008] Valid loss: 0.3443
2023-02-06 10:41:05 | Valid | Epoch[020/600] Iteration[004/008] Valid loss: 0.3441
2023-02-06 10:41:05 | Valid | Epoch[020/600] Iteration[005/008] Valid loss: 0.3455
2023-02-06 10:41:05 | Valid | Epoch[020/600] Iteration[006/008] Valid loss: 0.3450
2023-02-06 10:41:05 | Valid | Epoch[020/600] Iteration[007/008] Valid loss: 0.3444
2023-02-06 10:41:05 | Valid | Epoch[020/600] Iteration[008/008] Valid loss: 0.3456
2023-02-06 10:41:05 | Valid | Epoch[020/600] MIou: 0.6338239067518728
2023-02-06 10:41:05 | Valid | Epoch[020/600] Pixel Accuracy: 0.9394404093424479
2023-02-06 10:41:05 | Valid | Epoch[020/600] Mean Pixel Accuracy: 0.6651356791699722
2023-02-06 10:41:05 | Stage | Epoch[020/600] Train loss:0.2962
2023-02-06 10:41:05 | Stage | Epoch[020/600] Valid loss:0.3456
2023-02-06 10:41:05 | Stage | Epoch[020/600] LR:0.01

2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[001/030] Train loss: 0.2913
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[002/030] Train loss: 0.2907
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[003/030] Train loss: 0.2896
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[004/030] Train loss: 0.2895
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[005/030] Train loss: 0.2898
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[006/030] Train loss: 0.2891
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[007/030] Train loss: 0.2887
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[008/030] Train loss: 0.2883
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[009/030] Train loss: 0.2882
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[010/030] Train loss: 0.2883
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[011/030] Train loss: 0.2882
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[012/030] Train loss: 0.2886
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[013/030] Train loss: 0.2883
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[014/030] Train loss: 0.2880
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[015/030] Train loss: 0.2875
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[016/030] Train loss: 0.2876
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[017/030] Train loss: 0.2875
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[018/030] Train loss: 0.2873
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[019/030] Train loss: 0.2871
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[020/030] Train loss: 0.2868
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[021/030] Train loss: 0.2867
2023-02-06 10:41:06 | Train | Epoch[021/600] Iteration[022/030] Train loss: 0.2865
2023-02-06 10:41:07 | Train | Epoch[021/600] Iteration[023/030] Train loss: 0.2863
2023-02-06 10:41:07 | Train | Epoch[021/600] Iteration[024/030] Train loss: 0.2863
2023-02-06 10:41:07 | Train | Epoch[021/600] Iteration[025/030] Train loss: 0.2861
2023-02-06 10:41:07 | Train | Epoch[021/600] Iteration[026/030] Train loss: 0.2858
2023-02-06 10:41:07 | Train | Epoch[021/600] Iteration[027/030] Train loss: 0.2856
2023-02-06 10:41:07 | Train | Epoch[021/600] Iteration[028/030] Train loss: 0.2855
2023-02-06 10:41:07 | Train | Epoch[021/600] Iteration[029/030] Train loss: 0.2853
2023-02-06 10:41:07 | Train | Epoch[021/600] Iteration[030/030] Train loss: 0.2851
2023-02-06 10:41:07 | Valid | Epoch[021/600] Iteration[001/008] Valid loss: 0.3559
2023-02-06 10:41:07 | Valid | Epoch[021/600] Iteration[002/008] Valid loss: 0.3521
2023-02-06 10:41:07 | Valid | Epoch[021/600] Iteration[003/008] Valid loss: 0.3520
2023-02-06 10:41:07 | Valid | Epoch[021/600] Iteration[004/008] Valid loss: 0.3535
2023-02-06 10:41:07 | Valid | Epoch[021/600] Iteration[005/008] Valid loss: 0.3561
2023-02-06 10:41:07 | Valid | Epoch[021/600] Iteration[006/008] Valid loss: 0.3552
2023-02-06 10:41:07 | Valid | Epoch[021/600] Iteration[007/008] Valid loss: 0.3590
2023-02-06 10:41:07 | Valid | Epoch[021/600] Iteration[008/008] Valid loss: 0.3595
2023-02-06 10:41:07 | Valid | Epoch[021/600] MIou: 0.8616625988437085
2023-02-06 10:41:07 | Valid | Epoch[021/600] Pixel Accuracy: 0.9709943135579427
2023-02-06 10:41:07 | Valid | Epoch[021/600] Mean Pixel Accuracy: 0.9798408241133053
2023-02-06 10:41:07 | Stage | Epoch[021/600] Train loss:0.2851
2023-02-06 10:41:07 | Stage | Epoch[021/600] Valid loss:0.3595
2023-02-06 10:41:07 | Stage | Epoch[021/600] LR:0.01

2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[001/030] Train loss: 0.2824
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[002/030] Train loss: 0.2793
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[003/030] Train loss: 0.2792
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[004/030] Train loss: 0.2791
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[005/030] Train loss: 0.2786
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[006/030] Train loss: 0.2779
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[007/030] Train loss: 0.2782
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[008/030] Train loss: 0.2775
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[009/030] Train loss: 0.2777
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[010/030] Train loss: 0.2774
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[011/030] Train loss: 0.2770
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[012/030] Train loss: 0.2766
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[013/030] Train loss: 0.2763
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[014/030] Train loss: 0.2759
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[015/030] Train loss: 0.2758
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[016/030] Train loss: 0.2756
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[017/030] Train loss: 0.2754
2023-02-06 10:41:08 | Train | Epoch[022/600] Iteration[018/030] Train loss: 0.2755
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[019/030] Train loss: 0.2753
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[020/030] Train loss: 0.2752
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[021/030] Train loss: 0.2749
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[022/030] Train loss: 0.2750
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[023/030] Train loss: 0.2750
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[024/030] Train loss: 0.2749
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[025/030] Train loss: 0.2748
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[026/030] Train loss: 0.2746
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[027/030] Train loss: 0.2748
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[028/030] Train loss: 0.2746
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[029/030] Train loss: 0.2744
2023-02-06 10:41:09 | Train | Epoch[022/600] Iteration[030/030] Train loss: 0.2742
2023-02-06 10:41:09 | Valid | Epoch[022/600] Iteration[001/008] Valid loss: 0.3432
2023-02-06 10:41:09 | Valid | Epoch[022/600] Iteration[002/008] Valid loss: 0.3382
2023-02-06 10:41:09 | Valid | Epoch[022/600] Iteration[003/008] Valid loss: 0.3377
2023-02-06 10:41:09 | Valid | Epoch[022/600] Iteration[004/008] Valid loss: 0.3392
2023-02-06 10:41:09 | Valid | Epoch[022/600] Iteration[005/008] Valid loss: 0.3417
2023-02-06 10:41:09 | Valid | Epoch[022/600] Iteration[006/008] Valid loss: 0.3412
2023-02-06 10:41:09 | Valid | Epoch[022/600] Iteration[007/008] Valid loss: 0.3449
2023-02-06 10:41:09 | Valid | Epoch[022/600] Iteration[008/008] Valid loss: 0.3447
2023-02-06 10:41:10 | Valid | Epoch[022/600] MIou: 0.8691472416584631
2023-02-06 10:41:10 | Valid | Epoch[022/600] Pixel Accuracy: 0.9730186462402344
2023-02-06 10:41:10 | Valid | Epoch[022/600] Mean Pixel Accuracy: 0.9799833915498455
2023-02-06 10:41:10 | Stage | Epoch[022/600] Train loss:0.2742
2023-02-06 10:41:10 | Stage | Epoch[022/600] Valid loss:0.3447
2023-02-06 10:41:10 | Stage | Epoch[022/600] LR:0.01

2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[001/030] Train loss: 0.2675
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[002/030] Train loss: 0.2677
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[003/030] Train loss: 0.2673
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[004/030] Train loss: 0.2676
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[005/030] Train loss: 0.2680
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[006/030] Train loss: 0.2687
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[007/030] Train loss: 0.2692
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[008/030] Train loss: 0.2688
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[009/030] Train loss: 0.2691
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[010/030] Train loss: 0.2687
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[011/030] Train loss: 0.2686
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[012/030] Train loss: 0.2685
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[013/030] Train loss: 0.2685
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[014/030] Train loss: 0.2682
2023-02-06 10:41:10 | Train | Epoch[023/600] Iteration[015/030] Train loss: 0.2682
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[016/030] Train loss: 0.2684
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[017/030] Train loss: 0.2682
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[018/030] Train loss: 0.2682
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[019/030] Train loss: 0.2682
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[020/030] Train loss: 0.2680
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[021/030] Train loss: 0.2677
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[022/030] Train loss: 0.2677
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[023/030] Train loss: 0.2675
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[024/030] Train loss: 0.2672
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[025/030] Train loss: 0.2672
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[026/030] Train loss: 0.2671
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[027/030] Train loss: 0.2672
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[028/030] Train loss: 0.2669
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[029/030] Train loss: 0.2666
2023-02-06 10:41:11 | Train | Epoch[023/600] Iteration[030/030] Train loss: 0.2664
2023-02-06 10:41:11 | Valid | Epoch[023/600] Iteration[001/008] Valid loss: 0.3663
2023-02-06 10:41:12 | Valid | Epoch[023/600] Iteration[002/008] Valid loss: 0.3623
2023-02-06 10:41:12 | Valid | Epoch[023/600] Iteration[003/008] Valid loss: 0.3647
2023-02-06 10:41:12 | Valid | Epoch[023/600] Iteration[004/008] Valid loss: 0.3659
2023-02-06 10:41:12 | Valid | Epoch[023/600] Iteration[005/008] Valid loss: 0.3669
2023-02-06 10:41:12 | Valid | Epoch[023/600] Iteration[006/008] Valid loss: 0.3669
2023-02-06 10:41:12 | Valid | Epoch[023/600] Iteration[007/008] Valid loss: 0.3670
2023-02-06 10:41:12 | Valid | Epoch[023/600] Iteration[008/008] Valid loss: 0.3681
2023-02-06 10:41:12 | Valid | Epoch[023/600] MIou: 0.45613601478891797
2023-02-06 10:41:12 | Valid | Epoch[023/600] Pixel Accuracy: 0.9098981221516927
2023-02-06 10:41:12 | Valid | Epoch[023/600] Mean Pixel Accuracy: 0.5011966943079588
2023-02-06 10:41:12 | Stage | Epoch[023/600] Train loss:0.2664
2023-02-06 10:41:12 | Stage | Epoch[023/600] Valid loss:0.3681
2023-02-06 10:41:12 | Stage | Epoch[023/600] LR:0.01

2023-02-06 10:41:12 | Train | Epoch[024/600] Iteration[001/030] Train loss: 0.2597
2023-02-06 10:41:12 | Train | Epoch[024/600] Iteration[002/030] Train loss: 0.2585
2023-02-06 10:41:12 | Train | Epoch[024/600] Iteration[003/030] Train loss: 0.2587
2023-02-06 10:41:12 | Train | Epoch[024/600] Iteration[004/030] Train loss: 0.2588
2023-02-06 10:41:12 | Train | Epoch[024/600] Iteration[005/030] Train loss: 0.2596
2023-02-06 10:41:12 | Train | Epoch[024/600] Iteration[006/030] Train loss: 0.2601
2023-02-06 10:41:12 | Train | Epoch[024/600] Iteration[007/030] Train loss: 0.2612
2023-02-06 10:41:12 | Train | Epoch[024/600] Iteration[008/030] Train loss: 0.2608
2023-02-06 10:41:12 | Train | Epoch[024/600] Iteration[009/030] Train loss: 0.2602
2023-02-06 10:41:12 | Train | Epoch[024/600] Iteration[010/030] Train loss: 0.2600
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[011/030] Train loss: 0.2600
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[012/030] Train loss: 0.2600
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[013/030] Train loss: 0.2602
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[014/030] Train loss: 0.2598
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[015/030] Train loss: 0.2598
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[016/030] Train loss: 0.2597
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[017/030] Train loss: 0.2594
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[018/030] Train loss: 0.2593
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[019/030] Train loss: 0.2592
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[020/030] Train loss: 0.2590
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[021/030] Train loss: 0.2588
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[022/030] Train loss: 0.2586
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[023/030] Train loss: 0.2583
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[024/030] Train loss: 0.2581
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[025/030] Train loss: 0.2579
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[026/030] Train loss: 0.2575
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[027/030] Train loss: 0.2573
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[028/030] Train loss: 0.2570
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[029/030] Train loss: 0.2569
2023-02-06 10:41:13 | Train | Epoch[024/600] Iteration[030/030] Train loss: 0.2569
2023-02-06 10:41:14 | Valid | Epoch[024/600] Iteration[001/008] Valid loss: 0.2786
2023-02-06 10:41:14 | Valid | Epoch[024/600] Iteration[002/008] Valid loss: 0.2772
2023-02-06 10:41:14 | Valid | Epoch[024/600] Iteration[003/008] Valid loss: 0.2763
2023-02-06 10:41:14 | Valid | Epoch[024/600] Iteration[004/008] Valid loss: 0.2754
2023-02-06 10:41:14 | Valid | Epoch[024/600] Iteration[005/008] Valid loss: 0.2753
2023-02-06 10:41:14 | Valid | Epoch[024/600] Iteration[006/008] Valid loss: 0.2750
2023-02-06 10:41:14 | Valid | Epoch[024/600] Iteration[007/008] Valid loss: 0.2748
2023-02-06 10:41:14 | Valid | Epoch[024/600] Iteration[008/008] Valid loss: 0.2746
2023-02-06 10:41:14 | Valid | Epoch[024/600] MIou: 0.9061228838834172
2023-02-06 10:41:14 | Valid | Epoch[024/600] Pixel Accuracy: 0.9844195048014323
2023-02-06 10:41:14 | Valid | Epoch[024/600] Mean Pixel Accuracy: 0.9179819328793739
2023-02-06 10:41:14 | Stage | Epoch[024/600] Train loss:0.2569
2023-02-06 10:41:14 | Stage | Epoch[024/600] Valid loss:0.2746
2023-02-06 10:41:14 | Stage | Epoch[024/600] LR:0.01

2023-02-06 10:41:14 | Train | Epoch[025/600] Iteration[001/030] Train loss: 0.2523
2023-02-06 10:41:14 | Train | Epoch[025/600] Iteration[002/030] Train loss: 0.2507
2023-02-06 10:41:14 | Train | Epoch[025/600] Iteration[003/030] Train loss: 0.2515
2023-02-06 10:41:14 | Train | Epoch[025/600] Iteration[004/030] Train loss: 0.2508
2023-02-06 10:41:14 | Train | Epoch[025/600] Iteration[005/030] Train loss: 0.2506
2023-02-06 10:41:14 | Train | Epoch[025/600] Iteration[006/030] Train loss: 0.2507
2023-02-06 10:41:14 | Train | Epoch[025/600] Iteration[007/030] Train loss: 0.2502
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[008/030] Train loss: 0.2502
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[009/030] Train loss: 0.2504
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[010/030] Train loss: 0.2501
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[011/030] Train loss: 0.2497
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[012/030] Train loss: 0.2495
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[013/030] Train loss: 0.2493
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[014/030] Train loss: 0.2493
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[015/030] Train loss: 0.2493
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[016/030] Train loss: 0.2490
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[017/030] Train loss: 0.2488
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[018/030] Train loss: 0.2488
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[019/030] Train loss: 0.2488
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[020/030] Train loss: 0.2488
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[021/030] Train loss: 0.2487
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[022/030] Train loss: 0.2486
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[023/030] Train loss: 0.2482
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[024/030] Train loss: 0.2481
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[025/030] Train loss: 0.2478
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[026/030] Train loss: 0.2475
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[027/030] Train loss: 0.2474
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[028/030] Train loss: 0.2472
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[029/030] Train loss: 0.2469
2023-02-06 10:41:15 | Train | Epoch[025/600] Iteration[030/030] Train loss: 0.2466
2023-02-06 10:41:16 | Valid | Epoch[025/600] Iteration[001/008] Valid loss: 0.4062
2023-02-06 10:41:16 | Valid | Epoch[025/600] Iteration[002/008] Valid loss: 0.4014
2023-02-06 10:41:16 | Valid | Epoch[025/600] Iteration[003/008] Valid loss: 0.4050
2023-02-06 10:41:16 | Valid | Epoch[025/600] Iteration[004/008] Valid loss: 0.4080
2023-02-06 10:41:16 | Valid | Epoch[025/600] Iteration[005/008] Valid loss: 0.4133
2023-02-06 10:41:16 | Valid | Epoch[025/600] Iteration[006/008] Valid loss: 0.4103
2023-02-06 10:41:16 | Valid | Epoch[025/600] Iteration[007/008] Valid loss: 0.4161
2023-02-06 10:41:16 | Valid | Epoch[025/600] Iteration[008/008] Valid loss: 0.4204
2023-02-06 10:41:16 | Valid | Epoch[025/600] MIou: 0.8069675392083566
2023-02-06 10:41:16 | Valid | Epoch[025/600] Pixel Accuracy: 0.9545148213704427
2023-02-06 10:41:16 | Valid | Epoch[025/600] Mean Pixel Accuracy: 0.9726724528843123
2023-02-06 10:41:16 | Stage | Epoch[025/600] Train loss:0.2466
2023-02-06 10:41:16 | Stage | Epoch[025/600] Valid loss:0.4204
2023-02-06 10:41:16 | Stage | Epoch[025/600] LR:0.01

2023-02-06 10:41:16 | Train | Epoch[026/600] Iteration[001/030] Train loss: 0.2373
2023-02-06 10:41:16 | Train | Epoch[026/600] Iteration[002/030] Train loss: 0.2388
2023-02-06 10:41:16 | Train | Epoch[026/600] Iteration[003/030] Train loss: 0.2386
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[004/030] Train loss: 0.2392
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[005/030] Train loss: 0.2388
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[006/030] Train loss: 0.2397
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[007/030] Train loss: 0.2399
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[008/030] Train loss: 0.2395
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[009/030] Train loss: 0.2395
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[010/030] Train loss: 0.2394
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[011/030] Train loss: 0.2392
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[012/030] Train loss: 0.2390
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[013/030] Train loss: 0.2389
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[014/030] Train loss: 0.2388
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[015/030] Train loss: 0.2389
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[016/030] Train loss: 0.2387
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[017/030] Train loss: 0.2385
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[018/030] Train loss: 0.2384
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[019/030] Train loss: 0.2384
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[020/030] Train loss: 0.2385
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[021/030] Train loss: 0.2387
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[022/030] Train loss: 0.2388
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[023/030] Train loss: 0.2387
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[024/030] Train loss: 0.2385
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[025/030] Train loss: 0.2386
2023-02-06 10:41:17 | Train | Epoch[026/600] Iteration[026/030] Train loss: 0.2385
2023-02-06 10:41:18 | Train | Epoch[026/600] Iteration[027/030] Train loss: 0.2383
2023-02-06 10:41:18 | Train | Epoch[026/600] Iteration[028/030] Train loss: 0.2382
2023-02-06 10:41:18 | Train | Epoch[026/600] Iteration[029/030] Train loss: 0.2381
2023-02-06 10:41:18 | Train | Epoch[026/600] Iteration[030/030] Train loss: 0.2378
2023-02-06 10:41:18 | Valid | Epoch[026/600] Iteration[001/008] Valid loss: 0.6589
2023-02-06 10:41:18 | Valid | Epoch[026/600] Iteration[002/008] Valid loss: 0.6246
2023-02-06 10:41:18 | Valid | Epoch[026/600] Iteration[003/008] Valid loss: 0.6349
2023-02-06 10:41:18 | Valid | Epoch[026/600] Iteration[004/008] Valid loss: 0.6383
2023-02-06 10:41:18 | Valid | Epoch[026/600] Iteration[005/008] Valid loss: 0.6490
2023-02-06 10:41:18 | Valid | Epoch[026/600] Iteration[006/008] Valid loss: 0.6428
2023-02-06 10:41:18 | Valid | Epoch[026/600] Iteration[007/008] Valid loss: 0.6551
2023-02-06 10:41:18 | Valid | Epoch[026/600] Iteration[008/008] Valid loss: 0.6650
2023-02-06 10:41:18 | Valid | Epoch[026/600] MIou: 0.7282291148575416
2023-02-06 10:41:18 | Valid | Epoch[026/600] Pixel Accuracy: 0.9233970642089844
2023-02-06 10:41:18 | Valid | Epoch[026/600] Mean Pixel Accuracy: 0.9571158814570777
2023-02-06 10:41:18 | Stage | Epoch[026/600] Train loss:0.2378
2023-02-06 10:41:18 | Stage | Epoch[026/600] Valid loss:0.6650
2023-02-06 10:41:18 | Stage | Epoch[026/600] LR:0.01

2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[001/030] Train loss: 0.2338
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[002/030] Train loss: 0.2331
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[003/030] Train loss: 0.2324
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[004/030] Train loss: 0.2316
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[005/030] Train loss: 0.2329
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[006/030] Train loss: 0.2325
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[007/030] Train loss: 0.2324
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[008/030] Train loss: 0.2318
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[009/030] Train loss: 0.2318
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[010/030] Train loss: 0.2324
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[011/030] Train loss: 0.2330
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[012/030] Train loss: 0.2331
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[013/030] Train loss: 0.2330
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[014/030] Train loss: 0.2330
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[015/030] Train loss: 0.2327
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[016/030] Train loss: 0.2329
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[017/030] Train loss: 0.2327
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[018/030] Train loss: 0.2325
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[019/030] Train loss: 0.2323
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[020/030] Train loss: 0.2322
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[021/030] Train loss: 0.2321
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[022/030] Train loss: 0.2318
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[023/030] Train loss: 0.2316
2023-02-06 10:41:19 | Train | Epoch[027/600] Iteration[024/030] Train loss: 0.2315
2023-02-06 10:41:20 | Train | Epoch[027/600] Iteration[025/030] Train loss: 0.2313
2023-02-06 10:41:20 | Train | Epoch[027/600] Iteration[026/030] Train loss: 0.2311
2023-02-06 10:41:20 | Train | Epoch[027/600] Iteration[027/030] Train loss: 0.2309
2023-02-06 10:41:20 | Train | Epoch[027/600] Iteration[028/030] Train loss: 0.2308
2023-02-06 10:41:20 | Train | Epoch[027/600] Iteration[029/030] Train loss: 0.2304
2023-02-06 10:41:20 | Train | Epoch[027/600] Iteration[030/030] Train loss: 0.2302
2023-02-06 10:41:20 | Valid | Epoch[027/600] Iteration[001/008] Valid loss: 0.2604
2023-02-06 10:41:20 | Valid | Epoch[027/600] Iteration[002/008] Valid loss: 0.2613
2023-02-06 10:41:20 | Valid | Epoch[027/600] Iteration[003/008] Valid loss: 0.2610
2023-02-06 10:41:20 | Valid | Epoch[027/600] Iteration[004/008] Valid loss: 0.2603
2023-02-06 10:41:20 | Valid | Epoch[027/600] Iteration[005/008] Valid loss: 0.2612
2023-02-06 10:41:20 | Valid | Epoch[027/600] Iteration[006/008] Valid loss: 0.2609
2023-02-06 10:41:20 | Valid | Epoch[027/600] Iteration[007/008] Valid loss: 0.2607
2023-02-06 10:41:20 | Valid | Epoch[027/600] Iteration[008/008] Valid loss: 0.2611
2023-02-06 10:41:20 | Valid | Epoch[027/600] MIou: 0.8566218849161483
2023-02-06 10:41:20 | Valid | Epoch[027/600] Pixel Accuracy: 0.9761136372884115
2023-02-06 10:41:20 | Valid | Epoch[027/600] Mean Pixel Accuracy: 0.8735097461605056
2023-02-06 10:41:20 | Stage | Epoch[027/600] Train loss:0.2302
2023-02-06 10:41:20 | Stage | Epoch[027/600] Valid loss:0.2611
2023-02-06 10:41:20 | Stage | Epoch[027/600] LR:0.01

2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[001/030] Train loss: 0.2228
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[002/030] Train loss: 0.2241
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[003/030] Train loss: 0.2266
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[004/030] Train loss: 0.2276
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[005/030] Train loss: 0.2271
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[006/030] Train loss: 0.2268
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[007/030] Train loss: 0.2260
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[008/030] Train loss: 0.2257
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[009/030] Train loss: 0.2259
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[010/030] Train loss: 0.2258
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[011/030] Train loss: 0.2255
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[012/030] Train loss: 0.2253
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[013/030] Train loss: 0.2250
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[014/030] Train loss: 0.2245
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[015/030] Train loss: 0.2243
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[016/030] Train loss: 0.2241
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[017/030] Train loss: 0.2238
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[018/030] Train loss: 0.2235
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[019/030] Train loss: 0.2235
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[020/030] Train loss: 0.2232
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[021/030] Train loss: 0.2233
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[022/030] Train loss: 0.2231
2023-02-06 10:41:21 | Train | Epoch[028/600] Iteration[023/030] Train loss: 0.2229
2023-02-06 10:41:22 | Train | Epoch[028/600] Iteration[024/030] Train loss: 0.2227
2023-02-06 10:41:22 | Train | Epoch[028/600] Iteration[025/030] Train loss: 0.2228
2023-02-06 10:41:22 | Train | Epoch[028/600] Iteration[026/030] Train loss: 0.2228
2023-02-06 10:41:22 | Train | Epoch[028/600] Iteration[027/030] Train loss: 0.2227
2023-02-06 10:41:22 | Train | Epoch[028/600] Iteration[028/030] Train loss: 0.2225
2023-02-06 10:41:22 | Train | Epoch[028/600] Iteration[029/030] Train loss: 0.2223
2023-02-06 10:41:22 | Train | Epoch[028/600] Iteration[030/030] Train loss: 0.2222
2023-02-06 10:41:22 | Valid | Epoch[028/600] Iteration[001/008] Valid loss: 0.2791
2023-02-06 10:41:22 | Valid | Epoch[028/600] Iteration[002/008] Valid loss: 0.2810
2023-02-06 10:41:22 | Valid | Epoch[028/600] Iteration[003/008] Valid loss: 0.2829
2023-02-06 10:41:22 | Valid | Epoch[028/600] Iteration[004/008] Valid loss: 0.2824
2023-02-06 10:41:22 | Valid | Epoch[028/600] Iteration[005/008] Valid loss: 0.2843
2023-02-06 10:41:22 | Valid | Epoch[028/600] Iteration[006/008] Valid loss: 0.2833
2023-02-06 10:41:22 | Valid | Epoch[028/600] Iteration[007/008] Valid loss: 0.2828
2023-02-06 10:41:22 | Valid | Epoch[028/600] Iteration[008/008] Valid loss: 0.2846
2023-02-06 10:41:22 | Valid | Epoch[028/600] MIou: 0.5935052796891973
2023-02-06 10:41:22 | Valid | Epoch[028/600] Pixel Accuracy: 0.9327735900878906
2023-02-06 10:41:22 | Valid | Epoch[028/600] Mean Pixel Accuracy: 0.627930216675801
2023-02-06 10:41:22 | Stage | Epoch[028/600] Train loss:0.2222
2023-02-06 10:41:22 | Stage | Epoch[028/600] Valid loss:0.2846
2023-02-06 10:41:22 | Stage | Epoch[028/600] LR:0.01

2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[001/030] Train loss: 0.2178
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[002/030] Train loss: 0.2172
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[003/030] Train loss: 0.2172
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[004/030] Train loss: 0.2171
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[005/030] Train loss: 0.2173
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[006/030] Train loss: 0.2174
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[007/030] Train loss: 0.2172
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[008/030] Train loss: 0.2174
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[009/030] Train loss: 0.2168
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[010/030] Train loss: 0.2172
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[011/030] Train loss: 0.2168
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[012/030] Train loss: 0.2165
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[013/030] Train loss: 0.2163
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[014/030] Train loss: 0.2160
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[015/030] Train loss: 0.2159
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[016/030] Train loss: 0.2160
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[017/030] Train loss: 0.2159
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[018/030] Train loss: 0.2158
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[019/030] Train loss: 0.2157
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[020/030] Train loss: 0.2155
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[021/030] Train loss: 0.2155
2023-02-06 10:41:23 | Train | Epoch[029/600] Iteration[022/030] Train loss: 0.2156
2023-02-06 10:41:24 | Train | Epoch[029/600] Iteration[023/030] Train loss: 0.2154
2023-02-06 10:41:24 | Train | Epoch[029/600] Iteration[024/030] Train loss: 0.2152
2023-02-06 10:41:24 | Train | Epoch[029/600] Iteration[025/030] Train loss: 0.2151
2023-02-06 10:41:24 | Train | Epoch[029/600] Iteration[026/030] Train loss: 0.2151
2023-02-06 10:41:24 | Train | Epoch[029/600] Iteration[027/030] Train loss: 0.2149
2023-02-06 10:41:24 | Train | Epoch[029/600] Iteration[028/030] Train loss: 0.2148
2023-02-06 10:41:24 | Train | Epoch[029/600] Iteration[029/030] Train loss: 0.2148
2023-02-06 10:41:24 | Train | Epoch[029/600] Iteration[030/030] Train loss: 0.2147
2023-02-06 10:41:24 | Valid | Epoch[029/600] Iteration[001/008] Valid loss: 0.2857
2023-02-06 10:41:24 | Valid | Epoch[029/600] Iteration[002/008] Valid loss: 0.2828
2023-02-06 10:41:24 | Valid | Epoch[029/600] Iteration[003/008] Valid loss: 0.2810
2023-02-06 10:41:24 | Valid | Epoch[029/600] Iteration[004/008] Valid loss: 0.2812
2023-02-06 10:41:24 | Valid | Epoch[029/600] Iteration[005/008] Valid loss: 0.2830
2023-02-06 10:41:24 | Valid | Epoch[029/600] Iteration[006/008] Valid loss: 0.2848
2023-02-06 10:41:24 | Valid | Epoch[029/600] Iteration[007/008] Valid loss: 0.2888
2023-02-06 10:41:24 | Valid | Epoch[029/600] Iteration[008/008] Valid loss: 0.2869
2023-02-06 10:41:24 | Valid | Epoch[029/600] MIou: 0.900775548353182
2023-02-06 10:41:24 | Valid | Epoch[029/600] Pixel Accuracy: 0.9807866414388021
2023-02-06 10:41:24 | Valid | Epoch[029/600] Mean Pixel Accuracy: 0.9834604540689507
2023-02-06 10:41:24 | Stage | Epoch[029/600] Train loss:0.2147
2023-02-06 10:41:24 | Stage | Epoch[029/600] Valid loss:0.2869
2023-02-06 10:41:24 | Stage | Epoch[029/600] LR:0.01

2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[001/030] Train loss: 0.2064
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[002/030] Train loss: 0.2102
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[003/030] Train loss: 0.2103
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[004/030] Train loss: 0.2117
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[005/030] Train loss: 0.2109
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[006/030] Train loss: 0.2106
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[007/030] Train loss: 0.2109
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[008/030] Train loss: 0.2105
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[009/030] Train loss: 0.2102
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[010/030] Train loss: 0.2098
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[011/030] Train loss: 0.2098
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[012/030] Train loss: 0.2100
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[013/030] Train loss: 0.2096
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[014/030] Train loss: 0.2093
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[015/030] Train loss: 0.2089
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[016/030] Train loss: 0.2095
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[017/030] Train loss: 0.2096
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[018/030] Train loss: 0.2094
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[019/030] Train loss: 0.2091
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[020/030] Train loss: 0.2091
2023-02-06 10:41:25 | Train | Epoch[030/600] Iteration[021/030] Train loss: 0.2091
2023-02-06 10:41:26 | Train | Epoch[030/600] Iteration[022/030] Train loss: 0.2090
2023-02-06 10:41:26 | Train | Epoch[030/600] Iteration[023/030] Train loss: 0.2090
2023-02-06 10:41:26 | Train | Epoch[030/600] Iteration[024/030] Train loss: 0.2089
2023-02-06 10:41:26 | Train | Epoch[030/600] Iteration[025/030] Train loss: 0.2090
2023-02-06 10:41:26 | Train | Epoch[030/600] Iteration[026/030] Train loss: 0.2089
2023-02-06 10:41:26 | Train | Epoch[030/600] Iteration[027/030] Train loss: 0.2086
2023-02-06 10:41:26 | Train | Epoch[030/600] Iteration[028/030] Train loss: 0.2084
2023-02-06 10:41:26 | Train | Epoch[030/600] Iteration[029/030] Train loss: 0.2082
2023-02-06 10:41:26 | Train | Epoch[030/600] Iteration[030/030] Train loss: 0.2080
2023-02-06 10:41:26 | Valid | Epoch[030/600] Iteration[001/008] Valid loss: 0.2757
2023-02-06 10:41:26 | Valid | Epoch[030/600] Iteration[002/008] Valid loss: 0.2759
2023-02-06 10:41:26 | Valid | Epoch[030/600] Iteration[003/008] Valid loss: 0.2769
2023-02-06 10:41:26 | Valid | Epoch[030/600] Iteration[004/008] Valid loss: 0.2767
2023-02-06 10:41:26 | Valid | Epoch[030/600] Iteration[005/008] Valid loss: 0.2781
2023-02-06 10:41:26 | Valid | Epoch[030/600] Iteration[006/008] Valid loss: 0.2772
2023-02-06 10:41:26 | Valid | Epoch[030/600] Iteration[007/008] Valid loss: 0.2759
2023-02-06 10:41:26 | Valid | Epoch[030/600] Iteration[008/008] Valid loss: 0.2772
2023-02-06 10:41:26 | Valid | Epoch[030/600] MIou: 0.6068092513227695
2023-02-06 10:41:26 | Valid | Epoch[030/600] Pixel Accuracy: 0.9349988301595052
2023-02-06 10:41:26 | Valid | Epoch[030/600] Mean Pixel Accuracy: 0.6401540215968126
2023-02-06 10:41:26 | Stage | Epoch[030/600] Train loss:0.2080
2023-02-06 10:41:26 | Stage | Epoch[030/600] Valid loss:0.2772
2023-02-06 10:41:26 | Stage | Epoch[030/600] LR:0.01

2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[001/030] Train loss: 0.2038
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[002/030] Train loss: 0.2028
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[003/030] Train loss: 0.2028
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[004/030] Train loss: 0.2024
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[005/030] Train loss: 0.2031
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[006/030] Train loss: 0.2030
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[007/030] Train loss: 0.2026
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[008/030] Train loss: 0.2026
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[009/030] Train loss: 0.2024
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[010/030] Train loss: 0.2022
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[011/030] Train loss: 0.2019
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[012/030] Train loss: 0.2021
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[013/030] Train loss: 0.2020
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[014/030] Train loss: 0.2020
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[015/030] Train loss: 0.2018
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[016/030] Train loss: 0.2019
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[017/030] Train loss: 0.2019
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[018/030] Train loss: 0.2016
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[019/030] Train loss: 0.2015
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[020/030] Train loss: 0.2016
2023-02-06 10:41:27 | Train | Epoch[031/600] Iteration[021/030] Train loss: 0.2016
2023-02-06 10:41:28 | Train | Epoch[031/600] Iteration[022/030] Train loss: 0.2016
2023-02-06 10:41:28 | Train | Epoch[031/600] Iteration[023/030] Train loss: 0.2015
2023-02-06 10:41:28 | Train | Epoch[031/600] Iteration[024/030] Train loss: 0.2015
2023-02-06 10:41:28 | Train | Epoch[031/600] Iteration[025/030] Train loss: 0.2014
2023-02-06 10:41:28 | Train | Epoch[031/600] Iteration[026/030] Train loss: 0.2013
2023-02-06 10:41:28 | Train | Epoch[031/600] Iteration[027/030] Train loss: 0.2012
2023-02-06 10:41:28 | Train | Epoch[031/600] Iteration[028/030] Train loss: 0.2010
2023-02-06 10:41:28 | Train | Epoch[031/600] Iteration[029/030] Train loss: 0.2009
2023-02-06 10:41:28 | Train | Epoch[031/600] Iteration[030/030] Train loss: 0.2007
2023-02-06 10:41:28 | Valid | Epoch[031/600] Iteration[001/008] Valid loss: 0.2203
2023-02-06 10:41:28 | Valid | Epoch[031/600] Iteration[002/008] Valid loss: 0.2186
2023-02-06 10:41:28 | Valid | Epoch[031/600] Iteration[003/008] Valid loss: 0.2177
2023-02-06 10:41:28 | Valid | Epoch[031/600] Iteration[004/008] Valid loss: 0.2168
2023-02-06 10:41:28 | Valid | Epoch[031/600] Iteration[005/008] Valid loss: 0.2169
2023-02-06 10:41:28 | Valid | Epoch[031/600] Iteration[006/008] Valid loss: 0.2165
2023-02-06 10:41:28 | Valid | Epoch[031/600] Iteration[007/008] Valid loss: 0.2163
2023-02-06 10:41:28 | Valid | Epoch[031/600] Iteration[008/008] Valid loss: 0.2163
2023-02-06 10:41:28 | Valid | Epoch[031/600] MIou: 0.9115074089130043
2023-02-06 10:41:28 | Valid | Epoch[031/600] Pixel Accuracy: 0.9852205912272135
2023-02-06 10:41:28 | Valid | Epoch[031/600] Mean Pixel Accuracy: 0.9256377007252399
2023-02-06 10:41:28 | Stage | Epoch[031/600] Train loss:0.2007
2023-02-06 10:41:28 | Stage | Epoch[031/600] Valid loss:0.2163
2023-02-06 10:41:28 | Stage | Epoch[031/600] LR:0.01

2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[001/030] Train loss: 0.1985
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[002/030] Train loss: 0.1979
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[003/030] Train loss: 0.1976
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[004/030] Train loss: 0.1967
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[005/030] Train loss: 0.1958
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[006/030] Train loss: 0.1957
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[007/030] Train loss: 0.1958
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[008/030] Train loss: 0.1955
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[009/030] Train loss: 0.1958
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[010/030] Train loss: 0.1963
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[011/030] Train loss: 0.1959
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[012/030] Train loss: 0.1960
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[013/030] Train loss: 0.1958
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[014/030] Train loss: 0.1956
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[015/030] Train loss: 0.1955
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[016/030] Train loss: 0.1953
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[017/030] Train loss: 0.1951
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[018/030] Train loss: 0.1950
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[019/030] Train loss: 0.1951
2023-02-06 10:41:29 | Train | Epoch[032/600] Iteration[020/030] Train loss: 0.1949
2023-02-06 10:41:30 | Train | Epoch[032/600] Iteration[021/030] Train loss: 0.1947
2023-02-06 10:41:30 | Train | Epoch[032/600] Iteration[022/030] Train loss: 0.1947
2023-02-06 10:41:30 | Train | Epoch[032/600] Iteration[023/030] Train loss: 0.1947
2023-02-06 10:41:30 | Train | Epoch[032/600] Iteration[024/030] Train loss: 0.1946
2023-02-06 10:41:30 | Train | Epoch[032/600] Iteration[025/030] Train loss: 0.1947
2023-02-06 10:41:30 | Train | Epoch[032/600] Iteration[026/030] Train loss: 0.1947
2023-02-06 10:41:30 | Train | Epoch[032/600] Iteration[027/030] Train loss: 0.1947
2023-02-06 10:41:30 | Train | Epoch[032/600] Iteration[028/030] Train loss: 0.1947
2023-02-06 10:41:30 | Train | Epoch[032/600] Iteration[029/030] Train loss: 0.1946
2023-02-06 10:41:30 | Train | Epoch[032/600] Iteration[030/030] Train loss: 0.1945
2023-02-06 10:41:30 | Valid | Epoch[032/600] Iteration[001/008] Valid loss: 0.7965
2023-02-06 10:41:30 | Valid | Epoch[032/600] Iteration[002/008] Valid loss: 0.7517
2023-02-06 10:41:30 | Valid | Epoch[032/600] Iteration[003/008] Valid loss: 0.7771
2023-02-06 10:41:30 | Valid | Epoch[032/600] Iteration[004/008] Valid loss: 0.7807
2023-02-06 10:41:30 | Valid | Epoch[032/600] Iteration[005/008] Valid loss: 0.8041
2023-02-06 10:41:30 | Valid | Epoch[032/600] Iteration[006/008] Valid loss: 0.7846
2023-02-06 10:41:30 | Valid | Epoch[032/600] Iteration[007/008] Valid loss: 0.8064
2023-02-06 10:41:30 | Valid | Epoch[032/600] Iteration[008/008] Valid loss: 0.8352
2023-02-06 10:41:30 | Valid | Epoch[032/600] MIou: 0.7662487724690812
2023-02-06 10:41:30 | Valid | Epoch[032/600] Pixel Accuracy: 0.9396781921386719
2023-02-06 10:41:30 | Valid | Epoch[032/600] Mean Pixel Accuracy: 0.9653925937602654
2023-02-06 10:41:30 | Stage | Epoch[032/600] Train loss:0.1945
2023-02-06 10:41:30 | Stage | Epoch[032/600] Valid loss:0.8352
2023-02-06 10:41:30 | Stage | Epoch[032/600] LR:0.01

2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[001/030] Train loss: 0.1970
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[002/030] Train loss: 0.1944
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[003/030] Train loss: 0.1954
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[004/030] Train loss: 0.1946
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[005/030] Train loss: 0.1943
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[006/030] Train loss: 0.1935
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[007/030] Train loss: 0.1930
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[008/030] Train loss: 0.1931
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[009/030] Train loss: 0.1933
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[010/030] Train loss: 0.1927
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[011/030] Train loss: 0.1925
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[012/030] Train loss: 0.1920
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[013/030] Train loss: 0.1919
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[014/030] Train loss: 0.1919
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[015/030] Train loss: 0.1916
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[016/030] Train loss: 0.1913
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[017/030] Train loss: 0.1915
2023-02-06 10:41:31 | Train | Epoch[033/600] Iteration[018/030] Train loss: 0.1912
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[019/030] Train loss: 0.1913
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[020/030] Train loss: 0.1911
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[021/030] Train loss: 0.1911
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[022/030] Train loss: 0.1909
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[023/030] Train loss: 0.1907
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[024/030] Train loss: 0.1904
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[025/030] Train loss: 0.1902
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[026/030] Train loss: 0.1901
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[027/030] Train loss: 0.1901
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[028/030] Train loss: 0.1899
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[029/030] Train loss: 0.1898
2023-02-06 10:41:32 | Train | Epoch[033/600] Iteration[030/030] Train loss: 0.1898
2023-02-06 10:41:32 | Valid | Epoch[033/600] Iteration[001/008] Valid loss: 0.2758
2023-02-06 10:41:32 | Valid | Epoch[033/600] Iteration[002/008] Valid loss: 0.2736
2023-02-06 10:41:32 | Valid | Epoch[033/600] Iteration[003/008] Valid loss: 0.2761
2023-02-06 10:41:32 | Valid | Epoch[033/600] Iteration[004/008] Valid loss: 0.2772
2023-02-06 10:41:32 | Valid | Epoch[033/600] Iteration[005/008] Valid loss: 0.2782
2023-02-06 10:41:32 | Valid | Epoch[033/600] Iteration[006/008] Valid loss: 0.2785
2023-02-06 10:41:33 | Valid | Epoch[033/600] Iteration[007/008] Valid loss: 0.2786
2023-02-06 10:41:33 | Valid | Epoch[033/600] Iteration[008/008] Valid loss: 0.2799
2023-02-06 10:41:33 | Valid | Epoch[033/600] MIou: 0.4952003040359686
2023-02-06 10:41:33 | Valid | Epoch[033/600] Pixel Accuracy: 0.916375478108724
2023-02-06 10:41:33 | Valid | Epoch[033/600] Mean Pixel Accuracy: 0.5372898847229747
2023-02-06 10:41:33 | Stage | Epoch[033/600] Train loss:0.1898
2023-02-06 10:41:33 | Stage | Epoch[033/600] Valid loss:0.2799
2023-02-06 10:41:33 | Stage | Epoch[033/600] LR:0.01

2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[001/030] Train loss: 0.1850
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[002/030] Train loss: 0.1859
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[003/030] Train loss: 0.1860
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[004/030] Train loss: 0.1857
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[005/030] Train loss: 0.1855
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[006/030] Train loss: 0.1851
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[007/030] Train loss: 0.1853
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[008/030] Train loss: 0.1850
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[009/030] Train loss: 0.1852
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[010/030] Train loss: 0.1851
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[011/030] Train loss: 0.1846
2023-02-06 10:41:33 | Train | Epoch[034/600] Iteration[012/030] Train loss: 0.1844
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[013/030] Train loss: 0.1846
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[014/030] Train loss: 0.1845
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[015/030] Train loss: 0.1844
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[016/030] Train loss: 0.1852
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[017/030] Train loss: 0.1849
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[018/030] Train loss: 0.1847
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[019/030] Train loss: 0.1845
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[020/030] Train loss: 0.1843
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[021/030] Train loss: 0.1842
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[022/030] Train loss: 0.1841
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[023/030] Train loss: 0.1839
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[024/030] Train loss: 0.1840
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[025/030] Train loss: 0.1841
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[026/030] Train loss: 0.1842
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[027/030] Train loss: 0.1840
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[028/030] Train loss: 0.1840
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[029/030] Train loss: 0.1838
2023-02-06 10:41:34 | Train | Epoch[034/600] Iteration[030/030] Train loss: 0.1837
2023-02-06 10:41:35 | Valid | Epoch[034/600] Iteration[001/008] Valid loss: 0.2154
2023-02-06 10:41:35 | Valid | Epoch[034/600] Iteration[002/008] Valid loss: 0.2162
2023-02-06 10:41:35 | Valid | Epoch[034/600] Iteration[003/008] Valid loss: 0.2163
2023-02-06 10:41:35 | Valid | Epoch[034/600] Iteration[004/008] Valid loss: 0.2159
2023-02-06 10:41:35 | Valid | Epoch[034/600] Iteration[005/008] Valid loss: 0.2164
2023-02-06 10:41:35 | Valid | Epoch[034/600] Iteration[006/008] Valid loss: 0.2157
2023-02-06 10:41:35 | Valid | Epoch[034/600] Iteration[007/008] Valid loss: 0.2148
2023-02-06 10:41:35 | Valid | Epoch[034/600] Iteration[008/008] Valid loss: 0.2155
2023-02-06 10:41:35 | Valid | Epoch[034/600] MIou: 0.7859649270562556
2023-02-06 10:41:35 | Valid | Epoch[034/600] Pixel Accuracy: 0.9647000630696615
2023-02-06 10:41:35 | Valid | Epoch[034/600] Mean Pixel Accuracy: 0.8047256503551187
2023-02-06 10:41:35 | Stage | Epoch[034/600] Train loss:0.1837
2023-02-06 10:41:35 | Stage | Epoch[034/600] Valid loss:0.2155
2023-02-06 10:41:35 | Stage | Epoch[034/600] LR:0.01

2023-02-06 10:41:35 | Train | Epoch[035/600] Iteration[001/030] Train loss: 0.1781
2023-02-06 10:41:35 | Train | Epoch[035/600] Iteration[002/030] Train loss: 0.1778
2023-02-06 10:41:35 | Train | Epoch[035/600] Iteration[003/030] Train loss: 0.1785
2023-02-06 10:41:35 | Train | Epoch[035/600] Iteration[004/030] Train loss: 0.1787
2023-02-06 10:41:35 | Train | Epoch[035/600] Iteration[005/030] Train loss: 0.1789
2023-02-06 10:41:35 | Train | Epoch[035/600] Iteration[006/030] Train loss: 0.1785
2023-02-06 10:41:35 | Train | Epoch[035/600] Iteration[007/030] Train loss: 0.1785
2023-02-06 10:41:35 | Train | Epoch[035/600] Iteration[008/030] Train loss: 0.1787
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[009/030] Train loss: 0.1790
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[010/030] Train loss: 0.1786
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[011/030] Train loss: 0.1793
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[012/030] Train loss: 0.1790
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[013/030] Train loss: 0.1788
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[014/030] Train loss: 0.1788
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[015/030] Train loss: 0.1788
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[016/030] Train loss: 0.1786
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[017/030] Train loss: 0.1786
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[018/030] Train loss: 0.1784
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[019/030] Train loss: 0.1783
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[020/030] Train loss: 0.1783
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[021/030] Train loss: 0.1781
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[022/030] Train loss: 0.1782
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[023/030] Train loss: 0.1781
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[024/030] Train loss: 0.1779
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[025/030] Train loss: 0.1777
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[026/030] Train loss: 0.1776
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[027/030] Train loss: 0.1774
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[028/030] Train loss: 0.1772
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[029/030] Train loss: 0.1772
2023-02-06 10:41:36 | Train | Epoch[035/600] Iteration[030/030] Train loss: 0.1772
2023-02-06 10:41:37 | Valid | Epoch[035/600] Iteration[001/008] Valid loss: 0.2655
2023-02-06 10:41:37 | Valid | Epoch[035/600] Iteration[002/008] Valid loss: 0.2555
2023-02-06 10:41:37 | Valid | Epoch[035/600] Iteration[003/008] Valid loss: 0.2558
2023-02-06 10:41:37 | Valid | Epoch[035/600] Iteration[004/008] Valid loss: 0.2564
2023-02-06 10:41:37 | Valid | Epoch[035/600] Iteration[005/008] Valid loss: 0.2596
2023-02-06 10:41:37 | Valid | Epoch[035/600] Iteration[006/008] Valid loss: 0.2567
2023-02-06 10:41:37 | Valid | Epoch[035/600] Iteration[007/008] Valid loss: 0.2610
2023-02-06 10:41:37 | Valid | Epoch[035/600] Iteration[008/008] Valid loss: 0.2642
2023-02-06 10:41:37 | Valid | Epoch[035/600] MIou: 0.867295165004675
2023-02-06 10:41:37 | Valid | Epoch[035/600] Pixel Accuracy: 0.9726765950520834
2023-02-06 10:41:37 | Valid | Epoch[035/600] Mean Pixel Accuracy: 0.9770943447645613
2023-02-06 10:41:37 | Stage | Epoch[035/600] Train loss:0.1772
2023-02-06 10:41:37 | Stage | Epoch[035/600] Valid loss:0.2642
2023-02-06 10:41:37 | Stage | Epoch[035/600] LR:0.01

2023-02-06 10:41:37 | Train | Epoch[036/600] Iteration[001/030] Train loss: 0.1753
2023-02-06 10:41:37 | Train | Epoch[036/600] Iteration[002/030] Train loss: 0.1744
2023-02-06 10:41:37 | Train | Epoch[036/600] Iteration[003/030] Train loss: 0.1746
2023-02-06 10:41:37 | Train | Epoch[036/600] Iteration[004/030] Train loss: 0.1745
2023-02-06 10:41:37 | Train | Epoch[036/600] Iteration[005/030] Train loss: 0.1740
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[006/030] Train loss: 0.1745
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[007/030] Train loss: 0.1747
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[008/030] Train loss: 0.1743
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[009/030] Train loss: 0.1739
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[010/030] Train loss: 0.1736
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[011/030] Train loss: 0.1737
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[012/030] Train loss: 0.1737
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[013/030] Train loss: 0.1737
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[014/030] Train loss: 0.1738
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[015/030] Train loss: 0.1736
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[016/030] Train loss: 0.1733
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[017/030] Train loss: 0.1733
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[018/030] Train loss: 0.1731
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[019/030] Train loss: 0.1732
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[020/030] Train loss: 0.1731
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[021/030] Train loss: 0.1730
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[022/030] Train loss: 0.1729
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[023/030] Train loss: 0.1730
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[024/030] Train loss: 0.1729
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[025/030] Train loss: 0.1726
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[026/030] Train loss: 0.1724
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[027/030] Train loss: 0.1724
2023-02-06 10:41:38 | Train | Epoch[036/600] Iteration[028/030] Train loss: 0.1724
2023-02-06 10:41:39 | Train | Epoch[036/600] Iteration[029/030] Train loss: 0.1721
2023-02-06 10:41:39 | Train | Epoch[036/600] Iteration[030/030] Train loss: 0.1721
2023-02-06 10:41:39 | Valid | Epoch[036/600] Iteration[001/008] Valid loss: 0.2079
2023-02-06 10:41:39 | Valid | Epoch[036/600] Iteration[002/008] Valid loss: 0.2096
2023-02-06 10:41:39 | Valid | Epoch[036/600] Iteration[003/008] Valid loss: 0.2104
2023-02-06 10:41:39 | Valid | Epoch[036/600] Iteration[004/008] Valid loss: 0.2098
2023-02-06 10:41:39 | Valid | Epoch[036/600] Iteration[005/008] Valid loss: 0.2111
2023-02-06 10:41:39 | Valid | Epoch[036/600] Iteration[006/008] Valid loss: 0.2105
2023-02-06 10:41:39 | Valid | Epoch[036/600] Iteration[007/008] Valid loss: 0.2095
2023-02-06 10:41:39 | Valid | Epoch[036/600] Iteration[008/008] Valid loss: 0.2107
2023-02-06 10:41:39 | Valid | Epoch[036/600] MIou: 0.7375670744822362
2023-02-06 10:41:39 | Valid | Epoch[036/600] Pixel Accuracy: 0.9566574096679688
2023-02-06 10:41:39 | Valid | Epoch[036/600] Mean Pixel Accuracy: 0.7605312872394003
2023-02-06 10:41:39 | Stage | Epoch[036/600] Train loss:0.1721
2023-02-06 10:41:39 | Stage | Epoch[036/600] Valid loss:0.2107
2023-02-06 10:41:39 | Stage | Epoch[036/600] LR:0.01

2023-02-06 10:41:39 | Train | Epoch[037/600] Iteration[001/030] Train loss: 0.1719
2023-02-06 10:41:39 | Train | Epoch[037/600] Iteration[002/030] Train loss: 0.1682
2023-02-06 10:41:39 | Train | Epoch[037/600] Iteration[003/030] Train loss: 0.1686
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[004/030] Train loss: 0.1705
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[005/030] Train loss: 0.1700
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[006/030] Train loss: 0.1692
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[007/030] Train loss: 0.1690
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[008/030] Train loss: 0.1688
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[009/030] Train loss: 0.1687
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[010/030] Train loss: 0.1684
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[011/030] Train loss: 0.1682
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[012/030] Train loss: 0.1682
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[013/030] Train loss: 0.1685
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[014/030] Train loss: 0.1684
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[015/030] Train loss: 0.1682
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[016/030] Train loss: 0.1684
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[017/030] Train loss: 0.1683
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[018/030] Train loss: 0.1681
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[019/030] Train loss: 0.1680
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[020/030] Train loss: 0.1680
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[021/030] Train loss: 0.1680
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[022/030] Train loss: 0.1681
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[023/030] Train loss: 0.1680
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[024/030] Train loss: 0.1679
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[025/030] Train loss: 0.1679
2023-02-06 10:41:40 | Train | Epoch[037/600] Iteration[026/030] Train loss: 0.1679
2023-02-06 10:41:41 | Train | Epoch[037/600] Iteration[027/030] Train loss: 0.1676
2023-02-06 10:41:41 | Train | Epoch[037/600] Iteration[028/030] Train loss: 0.1675
2023-02-06 10:41:41 | Train | Epoch[037/600] Iteration[029/030] Train loss: 0.1673
2023-02-06 10:41:41 | Train | Epoch[037/600] Iteration[030/030] Train loss: 0.1673
2023-02-06 10:41:41 | Valid | Epoch[037/600] Iteration[001/008] Valid loss: 0.2251
2023-02-06 10:41:41 | Valid | Epoch[037/600] Iteration[002/008] Valid loss: 0.2225
2023-02-06 10:41:41 | Valid | Epoch[037/600] Iteration[003/008] Valid loss: 0.2201
2023-02-06 10:41:41 | Valid | Epoch[037/600] Iteration[004/008] Valid loss: 0.2207
2023-02-06 10:41:41 | Valid | Epoch[037/600] Iteration[005/008] Valid loss: 0.2225
2023-02-06 10:41:41 | Valid | Epoch[037/600] Iteration[006/008] Valid loss: 0.2244
2023-02-06 10:41:41 | Valid | Epoch[037/600] Iteration[007/008] Valid loss: 0.2280
2023-02-06 10:41:41 | Valid | Epoch[037/600] Iteration[008/008] Valid loss: 0.2264
2023-02-06 10:41:41 | Valid | Epoch[037/600] MIou: 0.9134859114257369
2023-02-06 10:41:41 | Valid | Epoch[037/600] Pixel Accuracy: 0.9836883544921875
2023-02-06 10:41:41 | Valid | Epoch[037/600] Mean Pixel Accuracy: 0.9836604555855022
2023-02-06 10:41:41 | Stage | Epoch[037/600] Train loss:0.1673
2023-02-06 10:41:41 | Stage | Epoch[037/600] Valid loss:0.2264
2023-02-06 10:41:41 | Stage | Epoch[037/600] LR:0.01

2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[001/030] Train loss: 0.1638
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[002/030] Train loss: 0.1627
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[003/030] Train loss: 0.1622
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[004/030] Train loss: 0.1621
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[005/030] Train loss: 0.1620
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[006/030] Train loss: 0.1621
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[007/030] Train loss: 0.1624
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[008/030] Train loss: 0.1627
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[009/030] Train loss: 0.1627
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[010/030] Train loss: 0.1627
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[011/030] Train loss: 0.1623
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[012/030] Train loss: 0.1625
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[013/030] Train loss: 0.1626
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[014/030] Train loss: 0.1626
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[015/030] Train loss: 0.1630
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[016/030] Train loss: 0.1630
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[017/030] Train loss: 0.1632
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[018/030] Train loss: 0.1631
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[019/030] Train loss: 0.1631
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[020/030] Train loss: 0.1631
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[021/030] Train loss: 0.1631
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[022/030] Train loss: 0.1632
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[023/030] Train loss: 0.1630
2023-02-06 10:41:42 | Train | Epoch[038/600] Iteration[024/030] Train loss: 0.1627
2023-02-06 10:41:43 | Train | Epoch[038/600] Iteration[025/030] Train loss: 0.1627
2023-02-06 10:41:43 | Train | Epoch[038/600] Iteration[026/030] Train loss: 0.1625
2023-02-06 10:41:43 | Train | Epoch[038/600] Iteration[027/030] Train loss: 0.1627
2023-02-06 10:41:43 | Train | Epoch[038/600] Iteration[028/030] Train loss: 0.1625
2023-02-06 10:41:43 | Train | Epoch[038/600] Iteration[029/030] Train loss: 0.1624
2023-02-06 10:41:43 | Train | Epoch[038/600] Iteration[030/030] Train loss: 0.1624
2023-02-06 10:41:43 | Valid | Epoch[038/600] Iteration[001/008] Valid loss: 0.1931
2023-02-06 10:41:43 | Valid | Epoch[038/600] Iteration[002/008] Valid loss: 0.1938
2023-02-06 10:41:43 | Valid | Epoch[038/600] Iteration[003/008] Valid loss: 0.1940
2023-02-06 10:41:43 | Valid | Epoch[038/600] Iteration[004/008] Valid loss: 0.1933
2023-02-06 10:41:43 | Valid | Epoch[038/600] Iteration[005/008] Valid loss: 0.1938
2023-02-06 10:41:43 | Valid | Epoch[038/600] Iteration[006/008] Valid loss: 0.1932
2023-02-06 10:41:43 | Valid | Epoch[038/600] Iteration[007/008] Valid loss: 0.1922
2023-02-06 10:41:43 | Valid | Epoch[038/600] Iteration[008/008] Valid loss: 0.1927
2023-02-06 10:41:43 | Valid | Epoch[038/600] MIou: 0.7976449760426194
2023-02-06 10:41:43 | Valid | Epoch[038/600] Pixel Accuracy: 0.9666417439778646
2023-02-06 10:41:43 | Valid | Epoch[038/600] Mean Pixel Accuracy: 0.8153352906186351
2023-02-06 10:41:43 | Stage | Epoch[038/600] Train loss:0.1624
2023-02-06 10:41:43 | Stage | Epoch[038/600] Valid loss:0.1927
2023-02-06 10:41:43 | Stage | Epoch[038/600] LR:0.01

2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[001/030] Train loss: 0.1622
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[002/030] Train loss: 0.1604
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[003/030] Train loss: 0.1605
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[004/030] Train loss: 0.1602
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[005/030] Train loss: 0.1602
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[006/030] Train loss: 0.1592
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[007/030] Train loss: 0.1587
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[008/030] Train loss: 0.1582
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[009/030] Train loss: 0.1582
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[010/030] Train loss: 0.1583
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[011/030] Train loss: 0.1587
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[012/030] Train loss: 0.1588
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[013/030] Train loss: 0.1591
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[014/030] Train loss: 0.1590
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[015/030] Train loss: 0.1588
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[016/030] Train loss: 0.1587
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[017/030] Train loss: 0.1585
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[018/030] Train loss: 0.1587
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[019/030] Train loss: 0.1585
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[020/030] Train loss: 0.1585
2023-02-06 10:41:44 | Train | Epoch[039/600] Iteration[021/030] Train loss: 0.1583
2023-02-06 10:41:45 | Train | Epoch[039/600] Iteration[022/030] Train loss: 0.1583
2023-02-06 10:41:45 | Train | Epoch[039/600] Iteration[023/030] Train loss: 0.1581
2023-02-06 10:41:45 | Train | Epoch[039/600] Iteration[024/030] Train loss: 0.1582
2023-02-06 10:41:45 | Train | Epoch[039/600] Iteration[025/030] Train loss: 0.1580
2023-02-06 10:41:45 | Train | Epoch[039/600] Iteration[026/030] Train loss: 0.1581
2023-02-06 10:41:45 | Train | Epoch[039/600] Iteration[027/030] Train loss: 0.1580
2023-02-06 10:41:45 | Train | Epoch[039/600] Iteration[028/030] Train loss: 0.1578
2023-02-06 10:41:45 | Train | Epoch[039/600] Iteration[029/030] Train loss: 0.1578
2023-02-06 10:41:45 | Train | Epoch[039/600] Iteration[030/030] Train loss: 0.1576
2023-02-06 10:41:45 | Valid | Epoch[039/600] Iteration[001/008] Valid loss: 0.1870
2023-02-06 10:41:45 | Valid | Epoch[039/600] Iteration[002/008] Valid loss: 0.1816
2023-02-06 10:41:45 | Valid | Epoch[039/600] Iteration[003/008] Valid loss: 0.1809
2023-02-06 10:41:45 | Valid | Epoch[039/600] Iteration[004/008] Valid loss: 0.1801
2023-02-06 10:41:45 | Valid | Epoch[039/600] Iteration[005/008] Valid loss: 0.1813
2023-02-06 10:41:45 | Valid | Epoch[039/600] Iteration[006/008] Valid loss: 0.1805
2023-02-06 10:41:45 | Valid | Epoch[039/600] Iteration[007/008] Valid loss: 0.1823
2023-02-06 10:41:45 | Valid | Epoch[039/600] Iteration[008/008] Valid loss: 0.1822
2023-02-06 10:41:45 | Valid | Epoch[039/600] MIou: 0.9271196401351118
2023-02-06 10:41:45 | Valid | Epoch[039/600] Pixel Accuracy: 0.9869372049967448
2023-02-06 10:41:45 | Valid | Epoch[039/600] Mean Pixel Accuracy: 0.9727905812448184
2023-02-06 10:41:45 | Stage | Epoch[039/600] Train loss:0.1576
2023-02-06 10:41:45 | Stage | Epoch[039/600] Valid loss:0.1822
2023-02-06 10:41:45 | Stage | Epoch[039/600] LR:0.01

2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[001/030] Train loss: 0.1529
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[002/030] Train loss: 0.1529
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[003/030] Train loss: 0.1528
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[004/030] Train loss: 0.1529
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[005/030] Train loss: 0.1526
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[006/030] Train loss: 0.1524
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[007/030] Train loss: 0.1522
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[008/030] Train loss: 0.1523
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[009/030] Train loss: 0.1524
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[010/030] Train loss: 0.1526
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[011/030] Train loss: 0.1532
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[012/030] Train loss: 0.1532
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[013/030] Train loss: 0.1531
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[014/030] Train loss: 0.1535
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[015/030] Train loss: 0.1537
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[016/030] Train loss: 0.1540
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[017/030] Train loss: 0.1537
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[018/030] Train loss: 0.1537
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[019/030] Train loss: 0.1539
2023-02-06 10:41:46 | Train | Epoch[040/600] Iteration[020/030] Train loss: 0.1540
2023-02-06 10:41:47 | Train | Epoch[040/600] Iteration[021/030] Train loss: 0.1539
2023-02-06 10:41:47 | Train | Epoch[040/600] Iteration[022/030] Train loss: 0.1539
2023-02-06 10:41:47 | Train | Epoch[040/600] Iteration[023/030] Train loss: 0.1538
2023-02-06 10:41:47 | Train | Epoch[040/600] Iteration[024/030] Train loss: 0.1537
2023-02-06 10:41:47 | Train | Epoch[040/600] Iteration[025/030] Train loss: 0.1536
2023-02-06 10:41:47 | Train | Epoch[040/600] Iteration[026/030] Train loss: 0.1537
2023-02-06 10:41:47 | Train | Epoch[040/600] Iteration[027/030] Train loss: 0.1535
2023-02-06 10:41:47 | Train | Epoch[040/600] Iteration[028/030] Train loss: 0.1534
2023-02-06 10:41:47 | Train | Epoch[040/600] Iteration[029/030] Train loss: 0.1534
2023-02-06 10:41:47 | Train | Epoch[040/600] Iteration[030/030] Train loss: 0.1533
2023-02-06 10:41:47 | Valid | Epoch[040/600] Iteration[001/008] Valid loss: 0.3405
2023-02-06 10:41:47 | Valid | Epoch[040/600] Iteration[002/008] Valid loss: 0.3075
2023-02-06 10:41:47 | Valid | Epoch[040/600] Iteration[003/008] Valid loss: 0.3039
2023-02-06 10:41:47 | Valid | Epoch[040/600] Iteration[004/008] Valid loss: 0.3035
2023-02-06 10:41:47 | Valid | Epoch[040/600] Iteration[005/008] Valid loss: 0.3063
2023-02-06 10:41:47 | Valid | Epoch[040/600] Iteration[006/008] Valid loss: 0.3049
2023-02-06 10:41:47 | Valid | Epoch[040/600] Iteration[007/008] Valid loss: 0.3165
2023-02-06 10:41:47 | Valid | Epoch[040/600] Iteration[008/008] Valid loss: 0.3176
2023-02-06 10:41:48 | Valid | Epoch[040/600] MIou: 0.8543770395798207
2023-02-06 10:41:48 | Valid | Epoch[040/600] Pixel Accuracy: 0.9689890543619791
2023-02-06 10:41:48 | Valid | Epoch[040/600] Mean Pixel Accuracy: 0.9792141835003736
2023-02-06 10:41:48 | Stage | Epoch[040/600] Train loss:0.1533
2023-02-06 10:41:48 | Stage | Epoch[040/600] Valid loss:0.3176
2023-02-06 10:41:48 | Stage | Epoch[040/600] LR:0.01

2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[001/030] Train loss: 0.1512
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[002/030] Train loss: 0.1511
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[003/030] Train loss: 0.1497
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[004/030] Train loss: 0.1490
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[005/030] Train loss: 0.1497
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[006/030] Train loss: 0.1503
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[007/030] Train loss: 0.1502
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[008/030] Train loss: 0.1500
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[009/030] Train loss: 0.1498
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[010/030] Train loss: 0.1497
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[011/030] Train loss: 0.1497
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[012/030] Train loss: 0.1498
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[013/030] Train loss: 0.1497
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[014/030] Train loss: 0.1495
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[015/030] Train loss: 0.1494
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[016/030] Train loss: 0.1495
2023-02-06 10:41:48 | Train | Epoch[041/600] Iteration[017/030] Train loss: 0.1494
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[018/030] Train loss: 0.1494
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[019/030] Train loss: 0.1495
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[020/030] Train loss: 0.1495
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[021/030] Train loss: 0.1497
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[022/030] Train loss: 0.1500
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[023/030] Train loss: 0.1500
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[024/030] Train loss: 0.1500
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[025/030] Train loss: 0.1499
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[026/030] Train loss: 0.1498
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[027/030] Train loss: 0.1497
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[028/030] Train loss: 0.1496
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[029/030] Train loss: 0.1495
2023-02-06 10:41:49 | Train | Epoch[041/600] Iteration[030/030] Train loss: 0.1493
2023-02-06 10:41:49 | Valid | Epoch[041/600] Iteration[001/008] Valid loss: 0.1912
2023-02-06 10:41:49 | Valid | Epoch[041/600] Iteration[002/008] Valid loss: 0.1854
2023-02-06 10:41:49 | Valid | Epoch[041/600] Iteration[003/008] Valid loss: 0.1853
2023-02-06 10:41:49 | Valid | Epoch[041/600] Iteration[004/008] Valid loss: 0.1854
2023-02-06 10:41:49 | Valid | Epoch[041/600] Iteration[005/008] Valid loss: 0.1874
2023-02-06 10:41:49 | Valid | Epoch[041/600] Iteration[006/008] Valid loss: 0.1868
2023-02-06 10:41:49 | Valid | Epoch[041/600] Iteration[007/008] Valid loss: 0.1895
2023-02-06 10:41:49 | Valid | Epoch[041/600] Iteration[008/008] Valid loss: 0.1894
2023-02-06 10:41:50 | Valid | Epoch[041/600] MIou: 0.9177618940827237
2023-02-06 10:41:50 | Valid | Epoch[041/600] Pixel Accuracy: 0.9847272237141927
2023-02-06 10:41:50 | Valid | Epoch[041/600] Mean Pixel Accuracy: 0.9806047127117075
2023-02-06 10:41:50 | Stage | Epoch[041/600] Train loss:0.1493
2023-02-06 10:41:50 | Stage | Epoch[041/600] Valid loss:0.1894
2023-02-06 10:41:50 | Stage | Epoch[041/600] LR:0.01

2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[001/030] Train loss: 0.1470
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[002/030] Train loss: 0.1462
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[003/030] Train loss: 0.1471
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[004/030] Train loss: 0.1472
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[005/030] Train loss: 0.1466
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[006/030] Train loss: 0.1470
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[007/030] Train loss: 0.1467
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[008/030] Train loss: 0.1471
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[009/030] Train loss: 0.1469
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[010/030] Train loss: 0.1465
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[011/030] Train loss: 0.1467
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[012/030] Train loss: 0.1465
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[013/030] Train loss: 0.1465
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[014/030] Train loss: 0.1462
2023-02-06 10:41:50 | Train | Epoch[042/600] Iteration[015/030] Train loss: 0.1464
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[016/030] Train loss: 0.1461
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[017/030] Train loss: 0.1461
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[018/030] Train loss: 0.1465
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[019/030] Train loss: 0.1465
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[020/030] Train loss: 0.1467
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[021/030] Train loss: 0.1467
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[022/030] Train loss: 0.1467
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[023/030] Train loss: 0.1468
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[024/030] Train loss: 0.1467
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[025/030] Train loss: 0.1466
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[026/030] Train loss: 0.1466
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[027/030] Train loss: 0.1466
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[028/030] Train loss: 0.1466
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[029/030] Train loss: 0.1467
2023-02-06 10:41:51 | Train | Epoch[042/600] Iteration[030/030] Train loss: 0.1471
2023-02-06 10:41:51 | Valid | Epoch[042/600] Iteration[001/008] Valid loss: 0.1728
2023-02-06 10:41:52 | Valid | Epoch[042/600] Iteration[002/008] Valid loss: 0.1710
2023-02-06 10:41:52 | Valid | Epoch[042/600] Iteration[003/008] Valid loss: 0.1707
2023-02-06 10:41:52 | Valid | Epoch[042/600] Iteration[004/008] Valid loss: 0.1704
2023-02-06 10:41:52 | Valid | Epoch[042/600] Iteration[005/008] Valid loss: 0.1705
2023-02-06 10:41:52 | Valid | Epoch[042/600] Iteration[006/008] Valid loss: 0.1701
2023-02-06 10:41:52 | Valid | Epoch[042/600] Iteration[007/008] Valid loss: 0.1692
2023-02-06 10:41:52 | Valid | Epoch[042/600] Iteration[008/008] Valid loss: 0.1694
2023-02-06 10:41:52 | Valid | Epoch[042/600] MIou: 0.8293178966297903
2023-02-06 10:41:52 | Valid | Epoch[042/600] Pixel Accuracy: 0.9718602498372396
2023-02-06 10:41:52 | Valid | Epoch[042/600] Mean Pixel Accuracy: 0.8445165607779708
2023-02-06 10:41:52 | Stage | Epoch[042/600] Train loss:0.1471
2023-02-06 10:41:52 | Stage | Epoch[042/600] Valid loss:0.1694
2023-02-06 10:41:52 | Stage | Epoch[042/600] LR:0.01

2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[001/030] Train loss: 0.1430
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[002/030] Train loss: 0.1440
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[003/030] Train loss: 0.1438
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[004/030] Train loss: 0.1443
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[005/030] Train loss: 0.1442
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[006/030] Train loss: 0.1442
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[007/030] Train loss: 0.1433
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[008/030] Train loss: 0.1432
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[009/030] Train loss: 0.1427
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[010/030] Train loss: 0.1433
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[011/030] Train loss: 0.1431
2023-02-06 10:41:52 | Train | Epoch[043/600] Iteration[012/030] Train loss: 0.1428
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[013/030] Train loss: 0.1425
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[014/030] Train loss: 0.1427
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[015/030] Train loss: 0.1426
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[016/030] Train loss: 0.1428
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[017/030] Train loss: 0.1425
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[018/030] Train loss: 0.1426
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[019/030] Train loss: 0.1426
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[020/030] Train loss: 0.1426
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[021/030] Train loss: 0.1427
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[022/030] Train loss: 0.1428
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[023/030] Train loss: 0.1427
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[024/030] Train loss: 0.1425
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[025/030] Train loss: 0.1424
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[026/030] Train loss: 0.1423
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[027/030] Train loss: 0.1423
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[028/030] Train loss: 0.1421
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[029/030] Train loss: 0.1420
2023-02-06 10:41:53 | Train | Epoch[043/600] Iteration[030/030] Train loss: 0.1419
2023-02-06 10:41:54 | Valid | Epoch[043/600] Iteration[001/008] Valid loss: 0.1576
2023-02-06 10:41:54 | Valid | Epoch[043/600] Iteration[002/008] Valid loss: 0.1569
2023-02-06 10:41:54 | Valid | Epoch[043/600] Iteration[003/008] Valid loss: 0.1563
2023-02-06 10:41:54 | Valid | Epoch[043/600] Iteration[004/008] Valid loss: 0.1556
2023-02-06 10:41:54 | Valid | Epoch[043/600] Iteration[005/008] Valid loss: 0.1558
2023-02-06 10:41:54 | Valid | Epoch[043/600] Iteration[006/008] Valid loss: 0.1555
2023-02-06 10:41:54 | Valid | Epoch[043/600] Iteration[007/008] Valid loss: 0.1553
2023-02-06 10:41:54 | Valid | Epoch[043/600] Iteration[008/008] Valid loss: 0.1555
2023-02-06 10:41:54 | Valid | Epoch[043/600] MIou: 0.8954588073126695
2023-02-06 10:41:54 | Valid | Epoch[043/600] Pixel Accuracy: 0.9826075236002604
2023-02-06 10:41:54 | Valid | Epoch[043/600] Mean Pixel Accuracy: 0.9090857632280294
2023-02-06 10:41:54 | Stage | Epoch[043/600] Train loss:0.1419
2023-02-06 10:41:54 | Stage | Epoch[043/600] Valid loss:0.1555
2023-02-06 10:41:54 | Stage | Epoch[043/600] LR:0.01

2023-02-06 10:41:54 | Train | Epoch[044/600] Iteration[001/030] Train loss: 0.1369
2023-02-06 10:41:54 | Train | Epoch[044/600] Iteration[002/030] Train loss: 0.1368
2023-02-06 10:41:54 | Train | Epoch[044/600] Iteration[003/030] Train loss: 0.1371
2023-02-06 10:41:54 | Train | Epoch[044/600] Iteration[004/030] Train loss: 0.1371
2023-02-06 10:41:54 | Train | Epoch[044/600] Iteration[005/030] Train loss: 0.1375
2023-02-06 10:41:54 | Train | Epoch[044/600] Iteration[006/030] Train loss: 0.1377
2023-02-06 10:41:54 | Train | Epoch[044/600] Iteration[007/030] Train loss: 0.1379
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[008/030] Train loss: 0.1382
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[009/030] Train loss: 0.1383
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[010/030] Train loss: 0.1383
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[011/030] Train loss: 0.1383
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[012/030] Train loss: 0.1386
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[013/030] Train loss: 0.1385
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[014/030] Train loss: 0.1384
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[015/030] Train loss: 0.1389
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[016/030] Train loss: 0.1390
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[017/030] Train loss: 0.1388
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[018/030] Train loss: 0.1387
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[019/030] Train loss: 0.1389
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[020/030] Train loss: 0.1389
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[021/030] Train loss: 0.1390
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[022/030] Train loss: 0.1389
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[023/030] Train loss: 0.1387
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[024/030] Train loss: 0.1385
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[025/030] Train loss: 0.1385
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[026/030] Train loss: 0.1384
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[027/030] Train loss: 0.1384
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[028/030] Train loss: 0.1383
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[029/030] Train loss: 0.1385
2023-02-06 10:41:55 | Train | Epoch[044/600] Iteration[030/030] Train loss: 0.1384
2023-02-06 10:41:56 | Valid | Epoch[044/600] Iteration[001/008] Valid loss: 0.1887
2023-02-06 10:41:56 | Valid | Epoch[044/600] Iteration[002/008] Valid loss: 0.1825
2023-02-06 10:41:56 | Valid | Epoch[044/600] Iteration[003/008] Valid loss: 0.1808
2023-02-06 10:41:56 | Valid | Epoch[044/600] Iteration[004/008] Valid loss: 0.1801
2023-02-06 10:41:56 | Valid | Epoch[044/600] Iteration[005/008] Valid loss: 0.1816
2023-02-06 10:41:56 | Valid | Epoch[044/600] Iteration[006/008] Valid loss: 0.1805
2023-02-06 10:41:56 | Valid | Epoch[044/600] Iteration[007/008] Valid loss: 0.1826
2023-02-06 10:41:56 | Valid | Epoch[044/600] Iteration[008/008] Valid loss: 0.1834
2023-02-06 10:41:56 | Valid | Epoch[044/600] MIou: 0.9110768916339593
2023-02-06 10:41:56 | Valid | Epoch[044/600] Pixel Accuracy: 0.983428955078125
2023-02-06 10:41:56 | Valid | Epoch[044/600] Mean Pixel Accuracy: 0.9753323298823211
2023-02-06 10:41:56 | Stage | Epoch[044/600] Train loss:0.1384
2023-02-06 10:41:56 | Stage | Epoch[044/600] Valid loss:0.1834
2023-02-06 10:41:56 | Stage | Epoch[044/600] LR:0.01

2023-02-06 10:41:56 | Train | Epoch[045/600] Iteration[001/030] Train loss: 0.1350
2023-02-06 10:41:56 | Train | Epoch[045/600] Iteration[002/030] Train loss: 0.1364
2023-02-06 10:41:56 | Train | Epoch[045/600] Iteration[003/030] Train loss: 0.1367
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[004/030] Train loss: 0.1362
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[005/030] Train loss: 0.1357
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[006/030] Train loss: 0.1359
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[007/030] Train loss: 0.1358
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[008/030] Train loss: 0.1357
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[009/030] Train loss: 0.1354
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[010/030] Train loss: 0.1353
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[011/030] Train loss: 0.1356
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[012/030] Train loss: 0.1354
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[013/030] Train loss: 0.1358
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[014/030] Train loss: 0.1357
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[015/030] Train loss: 0.1356
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[016/030] Train loss: 0.1358
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[017/030] Train loss: 0.1358
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[018/030] Train loss: 0.1357
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[019/030] Train loss: 0.1356
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[020/030] Train loss: 0.1356
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[021/030] Train loss: 0.1354
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[022/030] Train loss: 0.1354
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[023/030] Train loss: 0.1354
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[024/030] Train loss: 0.1354
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[025/030] Train loss: 0.1353
2023-02-06 10:41:57 | Train | Epoch[045/600] Iteration[026/030] Train loss: 0.1353
2023-02-06 10:41:58 | Train | Epoch[045/600] Iteration[027/030] Train loss: 0.1352
2023-02-06 10:41:58 | Train | Epoch[045/600] Iteration[028/030] Train loss: 0.1351
2023-02-06 10:41:58 | Train | Epoch[045/600] Iteration[029/030] Train loss: 0.1350
2023-02-06 10:41:58 | Train | Epoch[045/600] Iteration[030/030] Train loss: 0.1352
2023-02-06 10:41:58 | Valid | Epoch[045/600] Iteration[001/008] Valid loss: 0.9231
2023-02-06 10:41:58 | Valid | Epoch[045/600] Iteration[002/008] Valid loss: 0.8732
2023-02-06 10:41:58 | Valid | Epoch[045/600] Iteration[003/008] Valid loss: 0.8984
2023-02-06 10:41:58 | Valid | Epoch[045/600] Iteration[004/008] Valid loss: 0.9049
2023-02-06 10:41:58 | Valid | Epoch[045/600] Iteration[005/008] Valid loss: 0.9324
2023-02-06 10:41:58 | Valid | Epoch[045/600] Iteration[006/008] Valid loss: 0.9135
2023-02-06 10:41:58 | Valid | Epoch[045/600] Iteration[007/008] Valid loss: 0.9449
2023-02-06 10:41:58 | Valid | Epoch[045/600] Iteration[008/008] Valid loss: 0.9766
2023-02-06 10:41:58 | Valid | Epoch[045/600] MIou: 0.7374505726618703
2023-02-06 10:41:58 | Valid | Epoch[045/600] Pixel Accuracy: 0.9276390075683594
2023-02-06 10:41:58 | Valid | Epoch[045/600] Mean Pixel Accuracy: 0.9588260682337151
2023-02-06 10:41:58 | Stage | Epoch[045/600] Train loss:0.1352
2023-02-06 10:41:58 | Stage | Epoch[045/600] Valid loss:0.9766
2023-02-06 10:41:58 | Stage | Epoch[045/600] LR:0.01

2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[001/030] Train loss: 0.1341
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[002/030] Train loss: 0.1370
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[003/030] Train loss: 0.1366
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[004/030] Train loss: 0.1349
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[005/030] Train loss: 0.1338
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[006/030] Train loss: 0.1340
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[007/030] Train loss: 0.1339
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[008/030] Train loss: 0.1340
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[009/030] Train loss: 0.1335
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[010/030] Train loss: 0.1331
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[011/030] Train loss: 0.1331
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[012/030] Train loss: 0.1331
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[013/030] Train loss: 0.1330
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[014/030] Train loss: 0.1329
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[015/030] Train loss: 0.1326
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[016/030] Train loss: 0.1323
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[017/030] Train loss: 0.1325
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[018/030] Train loss: 0.1325
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[019/030] Train loss: 0.1324
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[020/030] Train loss: 0.1324
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[021/030] Train loss: 0.1322
2023-02-06 10:41:59 | Train | Epoch[046/600] Iteration[022/030] Train loss: 0.1322
2023-02-06 10:42:00 | Train | Epoch[046/600] Iteration[023/030] Train loss: 0.1322
2023-02-06 10:42:00 | Train | Epoch[046/600] Iteration[024/030] Train loss: 0.1320
2023-02-06 10:42:00 | Train | Epoch[046/600] Iteration[025/030] Train loss: 0.1320
2023-02-06 10:42:00 | Train | Epoch[046/600] Iteration[026/030] Train loss: 0.1319
2023-02-06 10:42:00 | Train | Epoch[046/600] Iteration[027/030] Train loss: 0.1319
2023-02-06 10:42:00 | Train | Epoch[046/600] Iteration[028/030] Train loss: 0.1318
2023-02-06 10:42:00 | Train | Epoch[046/600] Iteration[029/030] Train loss: 0.1316
2023-02-06 10:42:00 | Train | Epoch[046/600] Iteration[030/030] Train loss: 0.1315
2023-02-06 10:42:00 | Valid | Epoch[046/600] Iteration[001/008] Valid loss: 0.2792
2023-02-06 10:42:00 | Valid | Epoch[046/600] Iteration[002/008] Valid loss: 0.2724
2023-02-06 10:42:00 | Valid | Epoch[046/600] Iteration[003/008] Valid loss: 0.2776
2023-02-06 10:42:00 | Valid | Epoch[046/600] Iteration[004/008] Valid loss: 0.2798
2023-02-06 10:42:00 | Valid | Epoch[046/600] Iteration[005/008] Valid loss: 0.2822
2023-02-06 10:42:00 | Valid | Epoch[046/600] Iteration[006/008] Valid loss: 0.2824
2023-02-06 10:42:00 | Valid | Epoch[046/600] Iteration[007/008] Valid loss: 0.2828
2023-02-06 10:42:00 | Valid | Epoch[046/600] Iteration[008/008] Valid loss: 0.2854
2023-02-06 10:42:00 | Valid | Epoch[046/600] MIou: 0.4548409779866536
2023-02-06 10:42:00 | Valid | Epoch[046/600] Pixel Accuracy: 0.9096819559733073
2023-02-06 10:42:00 | Valid | Epoch[046/600] Mean Pixel Accuracy: 0.5
2023-02-06 10:42:00 | Stage | Epoch[046/600] Train loss:0.1315
2023-02-06 10:42:00 | Stage | Epoch[046/600] Valid loss:0.2854
2023-02-06 10:42:00 | Stage | Epoch[046/600] LR:0.01

2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[001/030] Train loss: 0.1274
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[002/030] Train loss: 0.1286
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[003/030] Train loss: 0.1292
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[004/030] Train loss: 0.1302
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[005/030] Train loss: 0.1296
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[006/030] Train loss: 0.1294
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[007/030] Train loss: 0.1293
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[008/030] Train loss: 0.1293
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[009/030] Train loss: 0.1293
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[010/030] Train loss: 0.1291
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[011/030] Train loss: 0.1289
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[012/030] Train loss: 0.1290
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[013/030] Train loss: 0.1288
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[014/030] Train loss: 0.1287
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[015/030] Train loss: 0.1288
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[016/030] Train loss: 0.1287
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[017/030] Train loss: 0.1285
2023-02-06 10:42:01 | Train | Epoch[047/600] Iteration[018/030] Train loss: 0.1287
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[019/030] Train loss: 0.1285
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[020/030] Train loss: 0.1285
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[021/030] Train loss: 0.1283
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[022/030] Train loss: 0.1281
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[023/030] Train loss: 0.1281
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[024/030] Train loss: 0.1279
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[025/030] Train loss: 0.1279
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[026/030] Train loss: 0.1279
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[027/030] Train loss: 0.1277
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[028/030] Train loss: 0.1276
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[029/030] Train loss: 0.1275
2023-02-06 10:42:02 | Train | Epoch[047/600] Iteration[030/030] Train loss: 0.1274
2023-02-06 10:42:02 | Valid | Epoch[047/600] Iteration[001/008] Valid loss: 0.3404
2023-02-06 10:42:02 | Valid | Epoch[047/600] Iteration[002/008] Valid loss: 0.3045
2023-02-06 10:42:02 | Valid | Epoch[047/600] Iteration[003/008] Valid loss: 0.3016
2023-02-06 10:42:02 | Valid | Epoch[047/600] Iteration[004/008] Valid loss: 0.3028
2023-02-06 10:42:02 | Valid | Epoch[047/600] Iteration[005/008] Valid loss: 0.3065
2023-02-06 10:42:02 | Valid | Epoch[047/600] Iteration[006/008] Valid loss: 0.3067
2023-02-06 10:42:02 | Valid | Epoch[047/600] Iteration[007/008] Valid loss: 0.3179
2023-02-06 10:42:03 | Valid | Epoch[047/600] Iteration[008/008] Valid loss: 0.3196
2023-02-06 10:42:03 | Valid | Epoch[047/600] MIou: 0.8467953884970373
2023-02-06 10:42:03 | Valid | Epoch[047/600] Pixel Accuracy: 0.9668312072753906
2023-02-06 10:42:03 | Valid | Epoch[047/600] Mean Pixel Accuracy: 0.9786431644483038
2023-02-06 10:42:03 | Stage | Epoch[047/600] Train loss:0.1274
2023-02-06 10:42:03 | Stage | Epoch[047/600] Valid loss:0.3196
2023-02-06 10:42:03 | Stage | Epoch[047/600] LR:0.01

2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[001/030] Train loss: 0.1277
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[002/030] Train loss: 0.1267
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[003/030] Train loss: 0.1257
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[004/030] Train loss: 0.1250
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[005/030] Train loss: 0.1253
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[006/030] Train loss: 0.1253
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[007/030] Train loss: 0.1257
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[008/030] Train loss: 0.1257
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[009/030] Train loss: 0.1251
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[010/030] Train loss: 0.1250
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[011/030] Train loss: 0.1253
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[012/030] Train loss: 0.1254
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[013/030] Train loss: 0.1253
2023-02-06 10:42:03 | Train | Epoch[048/600] Iteration[014/030] Train loss: 0.1257
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[015/030] Train loss: 0.1257
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[016/030] Train loss: 0.1254
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[017/030] Train loss: 0.1259
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[018/030] Train loss: 0.1257
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[019/030] Train loss: 0.1257
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[020/030] Train loss: 0.1259
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[021/030] Train loss: 0.1258
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[022/030] Train loss: 0.1259
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[023/030] Train loss: 0.1259
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[024/030] Train loss: 0.1259
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[025/030] Train loss: 0.1260
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[026/030] Train loss: 0.1259
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[027/030] Train loss: 0.1258
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[028/030] Train loss: 0.1257
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[029/030] Train loss: 0.1255
2023-02-06 10:42:04 | Train | Epoch[048/600] Iteration[030/030] Train loss: 0.1254
2023-02-06 10:42:04 | Valid | Epoch[048/600] Iteration[001/008] Valid loss: 0.1532
2023-02-06 10:42:05 | Valid | Epoch[048/600] Iteration[002/008] Valid loss: 0.1472
2023-02-06 10:42:05 | Valid | Epoch[048/600] Iteration[003/008] Valid loss: 0.1464
2023-02-06 10:42:05 | Valid | Epoch[048/600] Iteration[004/008] Valid loss: 0.1464
2023-02-06 10:42:05 | Valid | Epoch[048/600] Iteration[005/008] Valid loss: 0.1478
2023-02-06 10:42:05 | Valid | Epoch[048/600] Iteration[006/008] Valid loss: 0.1477
2023-02-06 10:42:05 | Valid | Epoch[048/600] Iteration[007/008] Valid loss: 0.1495
2023-02-06 10:42:05 | Valid | Epoch[048/600] Iteration[008/008] Valid loss: 0.1488
2023-02-06 10:42:05 | Valid | Epoch[048/600] MIou: 0.9293628723261178
2023-02-06 10:42:05 | Valid | Epoch[048/600] Pixel Accuracy: 0.987524668375651
2023-02-06 10:42:05 | Valid | Epoch[048/600] Mean Pixel Accuracy: 0.9679523323617395
2023-02-06 10:42:05 | Stage | Epoch[048/600] Train loss:0.1254
2023-02-06 10:42:05 | Stage | Epoch[048/600] Valid loss:0.1488
2023-02-06 10:42:05 | Stage | Epoch[048/600] LR:0.01

2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[001/030] Train loss: 0.1216
2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[002/030] Train loss: 0.1226
2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[003/030] Train loss: 0.1229
2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[004/030] Train loss: 0.1229
2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[005/030] Train loss: 0.1225
2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[006/030] Train loss: 0.1225
2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[007/030] Train loss: 0.1226
2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[008/030] Train loss: 0.1233
2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[009/030] Train loss: 0.1238
2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[010/030] Train loss: 0.1232
2023-02-06 10:42:05 | Train | Epoch[049/600] Iteration[011/030] Train loss: 0.1232
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[012/030] Train loss: 0.1230
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[013/030] Train loss: 0.1228
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[014/030] Train loss: 0.1226
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[015/030] Train loss: 0.1228
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[016/030] Train loss: 0.1225
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[017/030] Train loss: 0.1224
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[018/030] Train loss: 0.1224
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[019/030] Train loss: 0.1222
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[020/030] Train loss: 0.1221
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[021/030] Train loss: 0.1220
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[022/030] Train loss: 0.1221
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[023/030] Train loss: 0.1219
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[024/030] Train loss: 0.1219
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[025/030] Train loss: 0.1218
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[026/030] Train loss: 0.1218
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[027/030] Train loss: 0.1217
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[028/030] Train loss: 0.1218
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[029/030] Train loss: 0.1218
2023-02-06 10:42:06 | Train | Epoch[049/600] Iteration[030/030] Train loss: 0.1219
2023-02-06 10:42:07 | Valid | Epoch[049/600] Iteration[001/008] Valid loss: 6.1552
2023-02-06 10:42:07 | Valid | Epoch[049/600] Iteration[002/008] Valid loss: 6.1064
2023-02-06 10:42:07 | Valid | Epoch[049/600] Iteration[003/008] Valid loss: 6.2691
2023-02-06 10:42:07 | Valid | Epoch[049/600] Iteration[004/008] Valid loss: 6.3569
2023-02-06 10:42:07 | Valid | Epoch[049/600] Iteration[005/008] Valid loss: 6.4307
2023-02-06 10:42:07 | Valid | Epoch[049/600] Iteration[006/008] Valid loss: 6.3561
2023-02-06 10:42:07 | Valid | Epoch[049/600] Iteration[007/008] Valid loss: 6.4372
2023-02-06 10:42:07 | Valid | Epoch[049/600] Iteration[008/008] Valid loss: 6.5500
2023-02-06 10:42:07 | Valid | Epoch[049/600] MIou: 0.22521330793923364
2023-02-06 10:42:07 | Valid | Epoch[049/600] Pixel Accuracy: 0.38380686442057294
2023-02-06 10:42:07 | Valid | Epoch[049/600] Mean Pixel Accuracy: 0.6609272039216909
2023-02-06 10:42:07 | Stage | Epoch[049/600] Train loss:0.1219
2023-02-06 10:42:07 | Stage | Epoch[049/600] Valid loss:6.5500
2023-02-06 10:42:07 | Stage | Epoch[049/600] LR:0.01

2023-02-06 10:42:07 | Train | Epoch[050/600] Iteration[001/030] Train loss: 0.1216
2023-02-06 10:42:07 | Train | Epoch[050/600] Iteration[002/030] Train loss: 0.1206
2023-02-06 10:42:07 | Train | Epoch[050/600] Iteration[003/030] Train loss: 0.1206
2023-02-06 10:42:07 | Train | Epoch[050/600] Iteration[004/030] Train loss: 0.1209
2023-02-06 10:42:07 | Train | Epoch[050/600] Iteration[005/030] Train loss: 0.1199
2023-02-06 10:42:07 | Train | Epoch[050/600] Iteration[006/030] Train loss: 0.1200
2023-02-06 10:42:07 | Train | Epoch[050/600] Iteration[007/030] Train loss: 0.1205
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[008/030] Train loss: 0.1200
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[009/030] Train loss: 0.1195
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[010/030] Train loss: 0.1198
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[011/030] Train loss: 0.1199
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[012/030] Train loss: 0.1203
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[013/030] Train loss: 0.1203
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[014/030] Train loss: 0.1205
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[015/030] Train loss: 0.1205
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[016/030] Train loss: 0.1204
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[017/030] Train loss: 0.1202
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[018/030] Train loss: 0.1201
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[019/030] Train loss: 0.1202
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[020/030] Train loss: 0.1201
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[021/030] Train loss: 0.1200
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[022/030] Train loss: 0.1200
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[023/030] Train loss: 0.1200
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[024/030] Train loss: 0.1199
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[025/030] Train loss: 0.1201
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[026/030] Train loss: 0.1200
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[027/030] Train loss: 0.1199
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[028/030] Train loss: 0.1197
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[029/030] Train loss: 0.1197
2023-02-06 10:42:08 | Train | Epoch[050/600] Iteration[030/030] Train loss: 0.1195
2023-02-06 10:42:09 | Valid | Epoch[050/600] Iteration[001/008] Valid loss: 0.1676
2023-02-06 10:42:09 | Valid | Epoch[050/600] Iteration[002/008] Valid loss: 0.1692
2023-02-06 10:42:09 | Valid | Epoch[050/600] Iteration[003/008] Valid loss: 0.1707
2023-02-06 10:42:09 | Valid | Epoch[050/600] Iteration[004/008] Valid loss: 0.1703
2023-02-06 10:42:09 | Valid | Epoch[050/600] Iteration[005/008] Valid loss: 0.1718
2023-02-06 10:42:09 | Valid | Epoch[050/600] Iteration[006/008] Valid loss: 0.1704
2023-02-06 10:42:09 | Valid | Epoch[050/600] Iteration[007/008] Valid loss: 0.1687
2023-02-06 10:42:09 | Valid | Epoch[050/600] Iteration[008/008] Valid loss: 0.1705
2023-02-06 10:42:09 | Valid | Epoch[050/600] MIou: 0.6744129362417419
2023-02-06 10:42:09 | Valid | Epoch[050/600] Pixel Accuracy: 0.94622802734375
2023-02-06 10:42:09 | Valid | Epoch[050/600] Mean Pixel Accuracy: 0.7023187712061271
2023-02-06 10:42:09 | Stage | Epoch[050/600] Train loss:0.1195
2023-02-06 10:42:09 | Stage | Epoch[050/600] Valid loss:0.1705
2023-02-06 10:42:09 | Stage | Epoch[050/600] LR:0.01

2023-02-06 10:42:09 | Train | Epoch[051/600] Iteration[001/030] Train loss: 0.1178
2023-02-06 10:42:09 | Train | Epoch[051/600] Iteration[002/030] Train loss: 0.1173
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[003/030] Train loss: 0.1176
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[004/030] Train loss: 0.1176
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[005/030] Train loss: 0.1178
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[006/030] Train loss: 0.1174
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[007/030] Train loss: 0.1171
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[008/030] Train loss: 0.1172
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[009/030] Train loss: 0.1172
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[010/030] Train loss: 0.1170
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[011/030] Train loss: 0.1171
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[012/030] Train loss: 0.1171
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[013/030] Train loss: 0.1169
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[014/030] Train loss: 0.1169
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[015/030] Train loss: 0.1166
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[016/030] Train loss: 0.1167
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[017/030] Train loss: 0.1167
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[018/030] Train loss: 0.1165
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[019/030] Train loss: 0.1164
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[020/030] Train loss: 0.1164
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[021/030] Train loss: 0.1163
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[022/030] Train loss: 0.1163
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[023/030] Train loss: 0.1162
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[024/030] Train loss: 0.1162
2023-02-06 10:42:10 | Train | Epoch[051/600] Iteration[025/030] Train loss: 0.1162
2023-02-06 10:42:11 | Train | Epoch[051/600] Iteration[026/030] Train loss: 0.1160
2023-02-06 10:42:11 | Train | Epoch[051/600] Iteration[027/030] Train loss: 0.1160
2023-02-06 10:42:11 | Train | Epoch[051/600] Iteration[028/030] Train loss: 0.1160
2023-02-06 10:42:11 | Train | Epoch[051/600] Iteration[029/030] Train loss: 0.1159
2023-02-06 10:42:11 | Train | Epoch[051/600] Iteration[030/030] Train loss: 0.1159
2023-02-06 10:42:11 | Valid | Epoch[051/600] Iteration[001/008] Valid loss: 0.1321
2023-02-06 10:42:11 | Valid | Epoch[051/600] Iteration[002/008] Valid loss: 0.1306
2023-02-06 10:42:11 | Valid | Epoch[051/600] Iteration[003/008] Valid loss: 0.1306
2023-02-06 10:42:11 | Valid | Epoch[051/600] Iteration[004/008] Valid loss: 0.1298
2023-02-06 10:42:11 | Valid | Epoch[051/600] Iteration[005/008] Valid loss: 0.1301
2023-02-06 10:42:11 | Valid | Epoch[051/600] Iteration[006/008] Valid loss: 0.1296
2023-02-06 10:42:11 | Valid | Epoch[051/600] Iteration[007/008] Valid loss: 0.1290
2023-02-06 10:42:11 | Valid | Epoch[051/600] Iteration[008/008] Valid loss: 0.1292
2023-02-06 10:42:11 | Valid | Epoch[051/600] MIou: 0.8669953361536357
2023-02-06 10:42:11 | Valid | Epoch[051/600] Pixel Accuracy: 0.9780324300130209
2023-02-06 10:42:11 | Valid | Epoch[051/600] Mean Pixel Accuracy: 0.8798777116036043
2023-02-06 10:42:11 | Stage | Epoch[051/600] Train loss:0.1159
2023-02-06 10:42:11 | Stage | Epoch[051/600] Valid loss:0.1292
2023-02-06 10:42:11 | Stage | Epoch[051/600] LR:0.01

2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[001/030] Train loss: 0.1153
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[002/030] Train loss: 0.1140
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[003/030] Train loss: 0.1139
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[004/030] Train loss: 0.1138
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[005/030] Train loss: 0.1137
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[006/030] Train loss: 0.1135
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[007/030] Train loss: 0.1137
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[008/030] Train loss: 0.1140
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[009/030] Train loss: 0.1143
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[010/030] Train loss: 0.1143
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[011/030] Train loss: 0.1142
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[012/030] Train loss: 0.1145
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[013/030] Train loss: 0.1143
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[014/030] Train loss: 0.1144
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[015/030] Train loss: 0.1146
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[016/030] Train loss: 0.1145
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[017/030] Train loss: 0.1145
2023-02-06 10:42:12 | Train | Epoch[052/600] Iteration[018/030] Train loss: 0.1144
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[019/030] Train loss: 0.1143
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[020/030] Train loss: 0.1143
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[021/030] Train loss: 0.1143
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[022/030] Train loss: 0.1142
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[023/030] Train loss: 0.1140
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[024/030] Train loss: 0.1141
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[025/030] Train loss: 0.1142
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[026/030] Train loss: 0.1142
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[027/030] Train loss: 0.1141
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[028/030] Train loss: 0.1141
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[029/030] Train loss: 0.1140
2023-02-06 10:42:13 | Train | Epoch[052/600] Iteration[030/030] Train loss: 0.1139
2023-02-06 10:42:13 | Valid | Epoch[052/600] Iteration[001/008] Valid loss: 0.2148
2023-02-06 10:42:13 | Valid | Epoch[052/600] Iteration[002/008] Valid loss: 0.2132
2023-02-06 10:42:13 | Valid | Epoch[052/600] Iteration[003/008] Valid loss: 0.2171
2023-02-06 10:42:13 | Valid | Epoch[052/600] Iteration[004/008] Valid loss: 0.2187
2023-02-06 10:42:13 | Valid | Epoch[052/600] Iteration[005/008] Valid loss: 0.2209
2023-02-06 10:42:14 | Valid | Epoch[052/600] Iteration[006/008] Valid loss: 0.2206
2023-02-06 10:42:14 | Valid | Epoch[052/600] Iteration[007/008] Valid loss: 0.2203
2023-02-06 10:42:14 | Valid | Epoch[052/600] Iteration[008/008] Valid loss: 0.2226
2023-02-06 10:42:14 | Valid | Epoch[052/600] MIou: 0.45685973034999766
2023-02-06 10:42:14 | Valid | Epoch[052/600] Pixel Accuracy: 0.9100189208984375
2023-02-06 10:42:14 | Valid | Epoch[052/600] Mean Pixel Accuracy: 0.5018654352447591
2023-02-06 10:42:14 | Stage | Epoch[052/600] Train loss:0.1139
2023-02-06 10:42:14 | Stage | Epoch[052/600] Valid loss:0.2226
2023-02-06 10:42:14 | Stage | Epoch[052/600] LR:0.01

2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[001/030] Train loss: 0.1118
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[002/030] Train loss: 0.1125
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[003/030] Train loss: 0.1124
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[004/030] Train loss: 0.1116
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[005/030] Train loss: 0.1116
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[006/030] Train loss: 0.1109
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[007/030] Train loss: 0.1110
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[008/030] Train loss: 0.1107
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[009/030] Train loss: 0.1109
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[010/030] Train loss: 0.1110
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[011/030] Train loss: 0.1109
2023-02-06 10:42:14 | Train | Epoch[053/600] Iteration[012/030] Train loss: 0.1109
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[013/030] Train loss: 0.1109
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[014/030] Train loss: 0.1110
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[015/030] Train loss: 0.1110
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[016/030] Train loss: 0.1114
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[017/030] Train loss: 0.1112
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[018/030] Train loss: 0.1111
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[019/030] Train loss: 0.1110
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[020/030] Train loss: 0.1110
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[021/030] Train loss: 0.1111
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[022/030] Train loss: 0.1113
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[023/030] Train loss: 0.1113
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[024/030] Train loss: 0.1112
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[025/030] Train loss: 0.1113
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[026/030] Train loss: 0.1112
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[027/030] Train loss: 0.1113
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[028/030] Train loss: 0.1113
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[029/030] Train loss: 0.1112
2023-02-06 10:42:15 | Train | Epoch[053/600] Iteration[030/030] Train loss: 0.1112
2023-02-06 10:42:16 | Valid | Epoch[053/600] Iteration[001/008] Valid loss: 0.6406
2023-02-06 10:42:16 | Valid | Epoch[053/600] Iteration[002/008] Valid loss: 0.5975
2023-02-06 10:42:16 | Valid | Epoch[053/600] Iteration[003/008] Valid loss: 0.6084
2023-02-06 10:42:16 | Valid | Epoch[053/600] Iteration[004/008] Valid loss: 0.6195
2023-02-06 10:42:16 | Valid | Epoch[053/600] Iteration[005/008] Valid loss: 0.6418
2023-02-06 10:42:16 | Valid | Epoch[053/600] Iteration[006/008] Valid loss: 0.6316
2023-02-06 10:42:16 | Valid | Epoch[053/600] Iteration[007/008] Valid loss: 0.6586
2023-02-06 10:42:16 | Valid | Epoch[053/600] Iteration[008/008] Valid loss: 0.6773
2023-02-06 10:42:16 | Valid | Epoch[053/600] MIou: 0.7933058514764733
2023-02-06 10:42:16 | Valid | Epoch[053/600] Pixel Accuracy: 0.9497426350911459
2023-02-06 10:42:16 | Valid | Epoch[053/600] Mean Pixel Accuracy: 0.9711146549904178
2023-02-06 10:42:16 | Stage | Epoch[053/600] Train loss:0.1112
2023-02-06 10:42:16 | Stage | Epoch[053/600] Valid loss:0.6773
2023-02-06 10:42:16 | Stage | Epoch[053/600] LR:0.01

2023-02-06 10:42:16 | Train | Epoch[054/600] Iteration[001/030] Train loss: 0.1111
2023-02-06 10:42:16 | Train | Epoch[054/600] Iteration[002/030] Train loss: 0.1145
2023-02-06 10:42:16 | Train | Epoch[054/600] Iteration[003/030] Train loss: 0.1121
2023-02-06 10:42:16 | Train | Epoch[054/600] Iteration[004/030] Train loss: 0.1117
2023-02-06 10:42:16 | Train | Epoch[054/600] Iteration[005/030] Train loss: 0.1105
2023-02-06 10:42:16 | Train | Epoch[054/600] Iteration[006/030] Train loss: 0.1096
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[007/030] Train loss: 0.1096
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[008/030] Train loss: 0.1103
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[009/030] Train loss: 0.1099
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[010/030] Train loss: 0.1102
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[011/030] Train loss: 0.1100
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[012/030] Train loss: 0.1101
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[013/030] Train loss: 0.1101
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[014/030] Train loss: 0.1101
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[015/030] Train loss: 0.1100
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[016/030] Train loss: 0.1101
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[017/030] Train loss: 0.1101
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[018/030] Train loss: 0.1100
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[019/030] Train loss: 0.1099
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[020/030] Train loss: 0.1098
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[021/030] Train loss: 0.1096
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[022/030] Train loss: 0.1095
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[023/030] Train loss: 0.1096
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[024/030] Train loss: 0.1098
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[025/030] Train loss: 0.1097
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[026/030] Train loss: 0.1096
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[027/030] Train loss: 0.1096
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[028/030] Train loss: 0.1095
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[029/030] Train loss: 0.1094
2023-02-06 10:42:17 | Train | Epoch[054/600] Iteration[030/030] Train loss: 0.1094
2023-02-06 10:42:18 | Valid | Epoch[054/600] Iteration[001/008] Valid loss: 0.1316
2023-02-06 10:42:18 | Valid | Epoch[054/600] Iteration[002/008] Valid loss: 0.1268
2023-02-06 10:42:18 | Valid | Epoch[054/600] Iteration[003/008] Valid loss: 0.1252
2023-02-06 10:42:18 | Valid | Epoch[054/600] Iteration[004/008] Valid loss: 0.1250
2023-02-06 10:42:18 | Valid | Epoch[054/600] Iteration[005/008] Valid loss: 0.1258
2023-02-06 10:42:18 | Valid | Epoch[054/600] Iteration[006/008] Valid loss: 0.1254
2023-02-06 10:42:18 | Valid | Epoch[054/600] Iteration[007/008] Valid loss: 0.1271
2023-02-06 10:42:18 | Valid | Epoch[054/600] Iteration[008/008] Valid loss: 0.1269
2023-02-06 10:42:18 | Valid | Epoch[054/600] MIou: 0.9336825712615491
2023-02-06 10:42:18 | Valid | Epoch[054/600] Pixel Accuracy: 0.9882303873697916
2023-02-06 10:42:18 | Valid | Epoch[054/600] Mean Pixel Accuracy: 0.9745665686439686
2023-02-06 10:42:18 | Stage | Epoch[054/600] Train loss:0.1094
2023-02-06 10:42:18 | Stage | Epoch[054/600] Valid loss:0.1269
2023-02-06 10:42:18 | Stage | Epoch[054/600] LR:0.01

2023-02-06 10:42:18 | Train | Epoch[055/600] Iteration[001/030] Train loss: 0.1089
2023-02-06 10:42:18 | Train | Epoch[055/600] Iteration[002/030] Train loss: 0.1070
2023-02-06 10:42:18 | Train | Epoch[055/600] Iteration[003/030] Train loss: 0.1070
2023-02-06 10:42:18 | Train | Epoch[055/600] Iteration[004/030] Train loss: 0.1068
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[005/030] Train loss: 0.1063
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[006/030] Train loss: 0.1058
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[007/030] Train loss: 0.1055
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[008/030] Train loss: 0.1055
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[009/030] Train loss: 0.1063
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[010/030] Train loss: 0.1061
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[011/030] Train loss: 0.1062
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[012/030] Train loss: 0.1072
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[013/030] Train loss: 0.1070
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[014/030] Train loss: 0.1071
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[015/030] Train loss: 0.1070
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[016/030] Train loss: 0.1071
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[017/030] Train loss: 0.1070
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[018/030] Train loss: 0.1067
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[019/030] Train loss: 0.1067
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[020/030] Train loss: 0.1067
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[021/030] Train loss: 0.1067
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[022/030] Train loss: 0.1067
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[023/030] Train loss: 0.1067
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[024/030] Train loss: 0.1066
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[025/030] Train loss: 0.1067
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[026/030] Train loss: 0.1066
2023-02-06 10:42:19 | Train | Epoch[055/600] Iteration[027/030] Train loss: 0.1066
2023-02-06 10:42:20 | Train | Epoch[055/600] Iteration[028/030] Train loss: 0.1066
2023-02-06 10:42:20 | Train | Epoch[055/600] Iteration[029/030] Train loss: 0.1065
2023-02-06 10:42:20 | Train | Epoch[055/600] Iteration[030/030] Train loss: 0.1064
2023-02-06 10:42:20 | Valid | Epoch[055/600] Iteration[001/008] Valid loss: 0.1313
2023-02-06 10:42:20 | Valid | Epoch[055/600] Iteration[002/008] Valid loss: 0.1315
2023-02-06 10:42:20 | Valid | Epoch[055/600] Iteration[003/008] Valid loss: 0.1320
2023-02-06 10:42:20 | Valid | Epoch[055/600] Iteration[004/008] Valid loss: 0.1315
2023-02-06 10:42:20 | Valid | Epoch[055/600] Iteration[005/008] Valid loss: 0.1322
2023-02-06 10:42:20 | Valid | Epoch[055/600] Iteration[006/008] Valid loss: 0.1317
2023-02-06 10:42:20 | Valid | Epoch[055/600] Iteration[007/008] Valid loss: 0.1306
2023-02-06 10:42:20 | Valid | Epoch[055/600] Iteration[008/008] Valid loss: 0.1315
2023-02-06 10:42:20 | Valid | Epoch[055/600] MIou: 0.7854333398341364
2023-02-06 10:42:20 | Valid | Epoch[055/600] Pixel Accuracy: 0.9646224975585938
2023-02-06 10:42:20 | Valid | Epoch[055/600] Mean Pixel Accuracy: 0.8041504174351322
2023-02-06 10:42:20 | Stage | Epoch[055/600] Train loss:0.1064
2023-02-06 10:42:20 | Stage | Epoch[055/600] Valid loss:0.1315
2023-02-06 10:42:20 | Stage | Epoch[055/600] LR:0.01

2023-02-06 10:42:20 | Train | Epoch[056/600] Iteration[001/030] Train loss: 0.1081
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[002/030] Train loss: 0.1084
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[003/030] Train loss: 0.1074
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[004/030] Train loss: 0.1074
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[005/030] Train loss: 0.1070
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[006/030] Train loss: 0.1064
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[007/030] Train loss: 0.1057
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[008/030] Train loss: 0.1057
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[009/030] Train loss: 0.1053
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[010/030] Train loss: 0.1052
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[011/030] Train loss: 0.1049
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[012/030] Train loss: 0.1047
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[013/030] Train loss: 0.1050
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[014/030] Train loss: 0.1052
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[015/030] Train loss: 0.1052
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[016/030] Train loss: 0.1051
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[017/030] Train loss: 0.1049
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[018/030] Train loss: 0.1047
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[019/030] Train loss: 0.1046
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[020/030] Train loss: 0.1044
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[021/030] Train loss: 0.1042
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[022/030] Train loss: 0.1043
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[023/030] Train loss: 0.1042
2023-02-06 10:42:21 | Train | Epoch[056/600] Iteration[024/030] Train loss: 0.1042
2023-02-06 10:42:22 | Train | Epoch[056/600] Iteration[025/030] Train loss: 0.1042
2023-02-06 10:42:22 | Train | Epoch[056/600] Iteration[026/030] Train loss: 0.1042
2023-02-06 10:42:22 | Train | Epoch[056/600] Iteration[027/030] Train loss: 0.1042
2023-02-06 10:42:22 | Train | Epoch[056/600] Iteration[028/030] Train loss: 0.1042
2023-02-06 10:42:22 | Train | Epoch[056/600] Iteration[029/030] Train loss: 0.1043
2023-02-06 10:42:22 | Train | Epoch[056/600] Iteration[030/030] Train loss: 0.1044
2023-02-06 10:42:22 | Valid | Epoch[056/600] Iteration[001/008] Valid loss: 1.1546
2023-02-06 10:42:22 | Valid | Epoch[056/600] Iteration[002/008] Valid loss: 1.1167
2023-02-06 10:42:22 | Valid | Epoch[056/600] Iteration[003/008] Valid loss: 1.1383
2023-02-06 10:42:22 | Valid | Epoch[056/600] Iteration[004/008] Valid loss: 1.1588
2023-02-06 10:42:22 | Valid | Epoch[056/600] Iteration[005/008] Valid loss: 1.1951
2023-02-06 10:42:22 | Valid | Epoch[056/600] Iteration[006/008] Valid loss: 1.1753
2023-02-06 10:42:22 | Valid | Epoch[056/600] Iteration[007/008] Valid loss: 1.2236
2023-02-06 10:42:22 | Valid | Epoch[056/600] Iteration[008/008] Valid loss: 1.2636
2023-02-06 10:42:22 | Valid | Epoch[056/600] MIou: 0.7700633714281943
2023-02-06 10:42:22 | Valid | Epoch[056/600] Pixel Accuracy: 0.9411519368489584
2023-02-06 10:42:22 | Valid | Epoch[056/600] Mean Pixel Accuracy: 0.9663611384945325
2023-02-06 10:42:22 | Stage | Epoch[056/600] Train loss:0.1044
2023-02-06 10:42:22 | Stage | Epoch[056/600] Valid loss:1.2636
2023-02-06 10:42:22 | Stage | Epoch[056/600] LR:0.01

2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[001/030] Train loss: 0.1057
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[002/030] Train loss: 0.1081
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[003/030] Train loss: 0.1062
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[004/030] Train loss: 0.1047
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[005/030] Train loss: 0.1055
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[006/030] Train loss: 0.1052
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[007/030] Train loss: 0.1048
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[008/030] Train loss: 0.1050
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[009/030] Train loss: 0.1049
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[010/030] Train loss: 0.1047
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[011/030] Train loss: 0.1042
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[012/030] Train loss: 0.1039
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[013/030] Train loss: 0.1037
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[014/030] Train loss: 0.1036
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[015/030] Train loss: 0.1034
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[016/030] Train loss: 0.1032
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[017/030] Train loss: 0.1031
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[018/030] Train loss: 0.1031
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[019/030] Train loss: 0.1030
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[020/030] Train loss: 0.1028
2023-02-06 10:42:23 | Train | Epoch[057/600] Iteration[021/030] Train loss: 0.1027
2023-02-06 10:42:24 | Train | Epoch[057/600] Iteration[022/030] Train loss: 0.1028
2023-02-06 10:42:24 | Train | Epoch[057/600] Iteration[023/030] Train loss: 0.1026
2023-02-06 10:42:24 | Train | Epoch[057/600] Iteration[024/030] Train loss: 0.1025
2023-02-06 10:42:24 | Train | Epoch[057/600] Iteration[025/030] Train loss: 0.1026
2023-02-06 10:42:24 | Train | Epoch[057/600] Iteration[026/030] Train loss: 0.1026
2023-02-06 10:42:24 | Train | Epoch[057/600] Iteration[027/030] Train loss: 0.1026
2023-02-06 10:42:24 | Train | Epoch[057/600] Iteration[028/030] Train loss: 0.1025
2023-02-06 10:42:24 | Train | Epoch[057/600] Iteration[029/030] Train loss: 0.1024
2023-02-06 10:42:24 | Train | Epoch[057/600] Iteration[030/030] Train loss: 0.1022
2023-02-06 10:42:24 | Valid | Epoch[057/600] Iteration[001/008] Valid loss: 0.1220
2023-02-06 10:42:24 | Valid | Epoch[057/600] Iteration[002/008] Valid loss: 0.1198
2023-02-06 10:42:24 | Valid | Epoch[057/600] Iteration[003/008] Valid loss: 0.1190
2023-02-06 10:42:24 | Valid | Epoch[057/600] Iteration[004/008] Valid loss: 0.1186
2023-02-06 10:42:24 | Valid | Epoch[057/600] Iteration[005/008] Valid loss: 0.1192
2023-02-06 10:42:24 | Valid | Epoch[057/600] Iteration[006/008] Valid loss: 0.1203
2023-02-06 10:42:24 | Valid | Epoch[057/600] Iteration[007/008] Valid loss: 0.1208
2023-02-06 10:42:24 | Valid | Epoch[057/600] Iteration[008/008] Valid loss: 0.1202
2023-02-06 10:42:25 | Valid | Epoch[057/600] MIou: 0.8920115732159504
2023-02-06 10:42:25 | Valid | Epoch[057/600] Pixel Accuracy: 0.9821459452311198
2023-02-06 10:42:25 | Valid | Epoch[057/600] Mean Pixel Accuracy: 0.9033602331555834
2023-02-06 10:42:25 | Stage | Epoch[057/600] Train loss:0.1022
2023-02-06 10:42:25 | Stage | Epoch[057/600] Valid loss:0.1202
2023-02-06 10:42:25 | Stage | Epoch[057/600] LR:0.01

2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[001/030] Train loss: 0.1005
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[002/030] Train loss: 0.0996
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[003/030] Train loss: 0.1027
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[004/030] Train loss: 0.1017
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[005/030] Train loss: 0.1015
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[006/030] Train loss: 0.1009
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[007/030] Train loss: 0.1005
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[008/030] Train loss: 0.1012
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[009/030] Train loss: 0.1011
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[010/030] Train loss: 0.1013
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[011/030] Train loss: 0.1014
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[012/030] Train loss: 0.1010
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[013/030] Train loss: 0.1010
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[014/030] Train loss: 0.1009
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[015/030] Train loss: 0.1008
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[016/030] Train loss: 0.1007
2023-02-06 10:42:25 | Train | Epoch[058/600] Iteration[017/030] Train loss: 0.1007
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[018/030] Train loss: 0.1006
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[019/030] Train loss: 0.1004
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[020/030] Train loss: 0.1006
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[021/030] Train loss: 0.1006
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[022/030] Train loss: 0.1005
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[023/030] Train loss: 0.1004
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[024/030] Train loss: 0.1004
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[025/030] Train loss: 0.1005
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[026/030] Train loss: 0.1004
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[027/030] Train loss: 0.1003
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[028/030] Train loss: 0.1003
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[029/030] Train loss: 0.1002
2023-02-06 10:42:26 | Train | Epoch[058/600] Iteration[030/030] Train loss: 0.1003
2023-02-06 10:42:26 | Valid | Epoch[058/600] Iteration[001/008] Valid loss: 0.5080
2023-02-06 10:42:26 | Valid | Epoch[058/600] Iteration[002/008] Valid loss: 0.4526
2023-02-06 10:42:26 | Valid | Epoch[058/600] Iteration[003/008] Valid loss: 0.4462
2023-02-06 10:42:26 | Valid | Epoch[058/600] Iteration[004/008] Valid loss: 0.4488
2023-02-06 10:42:26 | Valid | Epoch[058/600] Iteration[005/008] Valid loss: 0.4646
2023-02-06 10:42:27 | Valid | Epoch[058/600] Iteration[006/008] Valid loss: 0.4585
2023-02-06 10:42:27 | Valid | Epoch[058/600] Iteration[007/008] Valid loss: 0.4789
2023-02-06 10:42:27 | Valid | Epoch[058/600] Iteration[008/008] Valid loss: 0.4850
2023-02-06 10:42:27 | Valid | Epoch[058/600] MIou: 0.8250196720634735
2023-02-06 10:42:27 | Valid | Epoch[058/600] Pixel Accuracy: 0.9602991739908854
2023-02-06 10:42:27 | Valid | Epoch[058/600] Mean Pixel Accuracy: 0.976080036755615
2023-02-06 10:42:27 | Stage | Epoch[058/600] Train loss:0.1003
2023-02-06 10:42:27 | Stage | Epoch[058/600] Valid loss:0.4850
2023-02-06 10:42:27 | Stage | Epoch[058/600] LR:0.01

2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[001/030] Train loss: 0.1015
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[002/030] Train loss: 0.1007
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[003/030] Train loss: 0.1003
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[004/030] Train loss: 0.1010
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[005/030] Train loss: 0.1010
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[006/030] Train loss: 0.1006
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[007/030] Train loss: 0.1004
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[008/030] Train loss: 0.0998
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[009/030] Train loss: 0.0995
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[010/030] Train loss: 0.0997
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[011/030] Train loss: 0.0996
2023-02-06 10:42:27 | Train | Epoch[059/600] Iteration[012/030] Train loss: 0.0998
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[013/030] Train loss: 0.0994
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[014/030] Train loss: 0.0993
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[015/030] Train loss: 0.0991
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[016/030] Train loss: 0.0991
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[017/030] Train loss: 0.0990
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[018/030] Train loss: 0.0987
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[019/030] Train loss: 0.0988
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[020/030] Train loss: 0.0985
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[021/030] Train loss: 0.0984
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[022/030] Train loss: 0.0983
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[023/030] Train loss: 0.0983
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[024/030] Train loss: 0.0982
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[025/030] Train loss: 0.0982
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[026/030] Train loss: 0.0982
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[027/030] Train loss: 0.0982
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[028/030] Train loss: 0.0982
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[029/030] Train loss: 0.0982
2023-02-06 10:42:28 | Train | Epoch[059/600] Iteration[030/030] Train loss: 0.0983
2023-02-06 10:42:29 | Valid | Epoch[059/600] Iteration[001/008] Valid loss: 0.2082
2023-02-06 10:42:29 | Valid | Epoch[059/600] Iteration[002/008] Valid loss: 0.2058
2023-02-06 10:42:29 | Valid | Epoch[059/600] Iteration[003/008] Valid loss: 0.2102
2023-02-06 10:42:29 | Valid | Epoch[059/600] Iteration[004/008] Valid loss: 0.2117
2023-02-06 10:42:29 | Valid | Epoch[059/600] Iteration[005/008] Valid loss: 0.2141
2023-02-06 10:42:29 | Valid | Epoch[059/600] Iteration[006/008] Valid loss: 0.2139
2023-02-06 10:42:29 | Valid | Epoch[059/600] Iteration[007/008] Valid loss: 0.2138
2023-02-06 10:42:29 | Valid | Epoch[059/600] Iteration[008/008] Valid loss: 0.2162
2023-02-06 10:42:29 | Valid | Epoch[059/600] MIou: 0.4555037268026456
2023-02-06 10:42:29 | Valid | Epoch[059/600] Pixel Accuracy: 0.9097925821940104
2023-02-06 10:42:29 | Valid | Epoch[059/600] Mean Pixel Accuracy: 0.5006124259105436
2023-02-06 10:42:29 | Stage | Epoch[059/600] Train loss:0.0983
2023-02-06 10:42:29 | Stage | Epoch[059/600] Valid loss:0.2162
2023-02-06 10:42:29 | Stage | Epoch[059/600] LR:0.01

2023-02-06 10:42:29 | Train | Epoch[060/600] Iteration[001/030] Train loss: 0.0958
2023-02-06 10:42:29 | Train | Epoch[060/600] Iteration[002/030] Train loss: 0.0994
2023-02-06 10:42:29 | Train | Epoch[060/600] Iteration[003/030] Train loss: 0.0982
2023-02-06 10:42:29 | Train | Epoch[060/600] Iteration[004/030] Train loss: 0.0995
2023-02-06 10:42:29 | Train | Epoch[060/600] Iteration[005/030] Train loss: 0.0988
2023-02-06 10:42:29 | Train | Epoch[060/600] Iteration[006/030] Train loss: 0.0984
2023-02-06 10:42:29 | Train | Epoch[060/600] Iteration[007/030] Train loss: 0.0981
2023-02-06 10:42:29 | Train | Epoch[060/600] Iteration[008/030] Train loss: 0.0997
2023-02-06 10:42:29 | Train | Epoch[060/600] Iteration[009/030] Train loss: 0.0995
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[010/030] Train loss: 0.0993
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[011/030] Train loss: 0.0991
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[012/030] Train loss: 0.0988
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[013/030] Train loss: 0.0988
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[014/030] Train loss: 0.0985
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[015/030] Train loss: 0.0986
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[016/030] Train loss: 0.0985
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[017/030] Train loss: 0.0982
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[018/030] Train loss: 0.0982
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[019/030] Train loss: 0.0981
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[020/030] Train loss: 0.0982
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[021/030] Train loss: 0.0981
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[022/030] Train loss: 0.0979
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[023/030] Train loss: 0.0979
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[024/030] Train loss: 0.0978
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[025/030] Train loss: 0.0976
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[026/030] Train loss: 0.0975
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[027/030] Train loss: 0.0973
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[028/030] Train loss: 0.0972
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[029/030] Train loss: 0.0972
2023-02-06 10:42:30 | Train | Epoch[060/600] Iteration[030/030] Train loss: 0.0971
2023-02-06 10:42:31 | Valid | Epoch[060/600] Iteration[001/008] Valid loss: 0.2233
2023-02-06 10:42:31 | Valid | Epoch[060/600] Iteration[002/008] Valid loss: 0.2216
2023-02-06 10:42:31 | Valid | Epoch[060/600] Iteration[003/008] Valid loss: 0.2271
2023-02-06 10:42:31 | Valid | Epoch[060/600] Iteration[004/008] Valid loss: 0.2282
2023-02-06 10:42:31 | Valid | Epoch[060/600] Iteration[005/008] Valid loss: 0.2319
2023-02-06 10:42:31 | Valid | Epoch[060/600] Iteration[006/008] Valid loss: 0.2305
2023-02-06 10:42:31 | Valid | Epoch[060/600] Iteration[007/008] Valid loss: 0.2295
2023-02-06 10:42:31 | Valid | Epoch[060/600] Iteration[008/008] Valid loss: 0.2329
2023-02-06 10:42:31 | Valid | Epoch[060/600] MIou: 0.45728634785282696
2023-02-06 10:42:31 | Valid | Epoch[060/600] Pixel Accuracy: 0.9100901285807291
2023-02-06 10:42:31 | Valid | Epoch[060/600] Mean Pixel Accuracy: 0.5022596404285573
2023-02-06 10:42:31 | Stage | Epoch[060/600] Train loss:0.0971
2023-02-06 10:42:31 | Stage | Epoch[060/600] Valid loss:0.2329
2023-02-06 10:42:31 | Stage | Epoch[060/600] LR:0.01

2023-02-06 10:42:31 | Train | Epoch[061/600] Iteration[001/030] Train loss: 0.0932
2023-02-06 10:42:31 | Train | Epoch[061/600] Iteration[002/030] Train loss: 0.0931
2023-02-06 10:42:31 | Train | Epoch[061/600] Iteration[003/030] Train loss: 0.0926
2023-02-06 10:42:31 | Train | Epoch[061/600] Iteration[004/030] Train loss: 0.0929
2023-02-06 10:42:31 | Train | Epoch[061/600] Iteration[005/030] Train loss: 0.0932
2023-02-06 10:42:31 | Train | Epoch[061/600] Iteration[006/030] Train loss: 0.0935
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[007/030] Train loss: 0.0931
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[008/030] Train loss: 0.0928
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[009/030] Train loss: 0.0926
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[010/030] Train loss: 0.0928
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[011/030] Train loss: 0.0928
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[012/030] Train loss: 0.0929
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[013/030] Train loss: 0.0930
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[014/030] Train loss: 0.0931
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[015/030] Train loss: 0.0936
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[016/030] Train loss: 0.0935
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[017/030] Train loss: 0.0935
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[018/030] Train loss: 0.0936
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[019/030] Train loss: 0.0936
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[020/030] Train loss: 0.0937
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[021/030] Train loss: 0.0936
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[022/030] Train loss: 0.0940
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[023/030] Train loss: 0.0939
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[024/030] Train loss: 0.0939
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[025/030] Train loss: 0.0938
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[026/030] Train loss: 0.0938
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[027/030] Train loss: 0.0938
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[028/030] Train loss: 0.0939
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[029/030] Train loss: 0.0938
2023-02-06 10:42:32 | Train | Epoch[061/600] Iteration[030/030] Train loss: 0.0937
2023-02-06 10:42:33 | Valid | Epoch[061/600] Iteration[001/008] Valid loss: 0.1630
2023-02-06 10:42:33 | Valid | Epoch[061/600] Iteration[002/008] Valid loss: 0.1642
2023-02-06 10:42:33 | Valid | Epoch[061/600] Iteration[003/008] Valid loss: 0.1671
2023-02-06 10:42:33 | Valid | Epoch[061/600] Iteration[004/008] Valid loss: 0.1670
2023-02-06 10:42:33 | Valid | Epoch[061/600] Iteration[005/008] Valid loss: 0.1699
2023-02-06 10:42:33 | Valid | Epoch[061/600] Iteration[006/008] Valid loss: 0.1684
2023-02-06 10:42:33 | Valid | Epoch[061/600] Iteration[007/008] Valid loss: 0.1665
2023-02-06 10:42:33 | Valid | Epoch[061/600] Iteration[008/008] Valid loss: 0.1689
2023-02-06 10:42:33 | Valid | Epoch[061/600] MIou: 0.5898571422590596
2023-02-06 10:42:33 | Valid | Epoch[061/600] Pixel Accuracy: 0.9321797688802084
2023-02-06 10:42:33 | Valid | Epoch[061/600] Mean Pixel Accuracy: 0.6245477199453744
2023-02-06 10:42:33 | Stage | Epoch[061/600] Train loss:0.0937
2023-02-06 10:42:33 | Stage | Epoch[061/600] Valid loss:0.1689
2023-02-06 10:42:33 | Stage | Epoch[061/600] LR:0.01

2023-02-06 10:42:33 | Train | Epoch[062/600] Iteration[001/030] Train loss: 0.0939
2023-02-06 10:42:33 | Train | Epoch[062/600] Iteration[002/030] Train loss: 0.0937
2023-02-06 10:42:33 | Train | Epoch[062/600] Iteration[003/030] Train loss: 0.0925
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[004/030] Train loss: 0.0920
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[005/030] Train loss: 0.0929
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[006/030] Train loss: 0.0925
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[007/030] Train loss: 0.0922
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[008/030] Train loss: 0.0922
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[009/030] Train loss: 0.0931
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[010/030] Train loss: 0.0927
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[011/030] Train loss: 0.0929
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[012/030] Train loss: 0.0928
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[013/030] Train loss: 0.0931
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[014/030] Train loss: 0.0929
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[015/030] Train loss: 0.0929
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[016/030] Train loss: 0.0927
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[017/030] Train loss: 0.0927
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[018/030] Train loss: 0.0929
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[019/030] Train loss: 0.0929
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[020/030] Train loss: 0.0927
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[021/030] Train loss: 0.0928
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[022/030] Train loss: 0.0927
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[023/030] Train loss: 0.0925
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[024/030] Train loss: 0.0923
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[025/030] Train loss: 0.0923
2023-02-06 10:42:34 | Train | Epoch[062/600] Iteration[026/030] Train loss: 0.0923
2023-02-06 10:42:35 | Train | Epoch[062/600] Iteration[027/030] Train loss: 0.0922
2023-02-06 10:42:35 | Train | Epoch[062/600] Iteration[028/030] Train loss: 0.0922
2023-02-06 10:42:35 | Train | Epoch[062/600] Iteration[029/030] Train loss: 0.0921
2023-02-06 10:42:35 | Train | Epoch[062/600] Iteration[030/030] Train loss: 0.0921
2023-02-06 10:42:35 | Valid | Epoch[062/600] Iteration[001/008] Valid loss: 0.2068
2023-02-06 10:42:35 | Valid | Epoch[062/600] Iteration[002/008] Valid loss: 0.2055
2023-02-06 10:42:35 | Valid | Epoch[062/600] Iteration[003/008] Valid loss: 0.2103
2023-02-06 10:42:35 | Valid | Epoch[062/600] Iteration[004/008] Valid loss: 0.2110
2023-02-06 10:42:35 | Valid | Epoch[062/600] Iteration[005/008] Valid loss: 0.2146
2023-02-06 10:42:35 | Valid | Epoch[062/600] Iteration[006/008] Valid loss: 0.2132
2023-02-06 10:42:35 | Valid | Epoch[062/600] Iteration[007/008] Valid loss: 0.2117
2023-02-06 10:42:35 | Valid | Epoch[062/600] Iteration[008/008] Valid loss: 0.2150
2023-02-06 10:42:35 | Valid | Epoch[062/600] MIou: 0.4760163729569875
2023-02-06 10:42:35 | Valid | Epoch[062/600] Pixel Accuracy: 0.9132156372070312
2023-02-06 10:42:35 | Valid | Epoch[062/600] Mean Pixel Accuracy: 0.5195624322459841
2023-02-06 10:42:35 | Stage | Epoch[062/600] Train loss:0.0921
2023-02-06 10:42:35 | Stage | Epoch[062/600] Valid loss:0.2150
2023-02-06 10:42:35 | Stage | Epoch[062/600] LR:0.01

2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[001/030] Train loss: 0.0907
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[002/030] Train loss: 0.0898
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[003/030] Train loss: 0.0902
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[004/030] Train loss: 0.0914
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[005/030] Train loss: 0.0915
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[006/030] Train loss: 0.0922
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[007/030] Train loss: 0.0920
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[008/030] Train loss: 0.0915
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[009/030] Train loss: 0.0911
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[010/030] Train loss: 0.0912
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[011/030] Train loss: 0.0912
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[012/030] Train loss: 0.0909
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[013/030] Train loss: 0.0909
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[014/030] Train loss: 0.0907
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[015/030] Train loss: 0.0905
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[016/030] Train loss: 0.0908
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[017/030] Train loss: 0.0909
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[018/030] Train loss: 0.0908
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[019/030] Train loss: 0.0909
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[020/030] Train loss: 0.0908
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[021/030] Train loss: 0.0908
2023-02-06 10:42:36 | Train | Epoch[063/600] Iteration[022/030] Train loss: 0.0908
2023-02-06 10:42:37 | Train | Epoch[063/600] Iteration[023/030] Train loss: 0.0908
2023-02-06 10:42:37 | Train | Epoch[063/600] Iteration[024/030] Train loss: 0.0907
2023-02-06 10:42:37 | Train | Epoch[063/600] Iteration[025/030] Train loss: 0.0907
2023-02-06 10:42:37 | Train | Epoch[063/600] Iteration[026/030] Train loss: 0.0908
2023-02-06 10:42:37 | Train | Epoch[063/600] Iteration[027/030] Train loss: 0.0907
2023-02-06 10:42:37 | Train | Epoch[063/600] Iteration[028/030] Train loss: 0.0906
2023-02-06 10:42:37 | Train | Epoch[063/600] Iteration[029/030] Train loss: 0.0905
2023-02-06 10:42:37 | Train | Epoch[063/600] Iteration[030/030] Train loss: 0.0903
2023-02-06 10:42:37 | Valid | Epoch[063/600] Iteration[001/008] Valid loss: 1.3938
2023-02-06 10:42:37 | Valid | Epoch[063/600] Iteration[002/008] Valid loss: 1.3536
2023-02-06 10:42:37 | Valid | Epoch[063/600] Iteration[003/008] Valid loss: 1.3877
2023-02-06 10:42:37 | Valid | Epoch[063/600] Iteration[004/008] Valid loss: 1.4194
2023-02-06 10:42:37 | Valid | Epoch[063/600] Iteration[005/008] Valid loss: 1.4642
2023-02-06 10:42:37 | Valid | Epoch[063/600] Iteration[006/008] Valid loss: 1.4370
2023-02-06 10:42:37 | Valid | Epoch[063/600] Iteration[007/008] Valid loss: 1.4942
2023-02-06 10:42:37 | Valid | Epoch[063/600] Iteration[008/008] Valid loss: 1.5572
2023-02-06 10:42:37 | Valid | Epoch[063/600] MIou: 0.7402963042117539
2023-02-06 10:42:37 | Valid | Epoch[063/600] Pixel Accuracy: 0.928869883219401
2023-02-06 10:42:37 | Valid | Epoch[063/600] Mean Pixel Accuracy: 0.9596991646039787
2023-02-06 10:42:37 | Stage | Epoch[063/600] Train loss:0.0903
2023-02-06 10:42:37 | Stage | Epoch[063/600] Valid loss:1.5572
2023-02-06 10:42:37 | Stage | Epoch[063/600] LR:0.01

2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[001/030] Train loss: 0.0930
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[002/030] Train loss: 0.0902
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[003/030] Train loss: 0.0899
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[004/030] Train loss: 0.0916
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[005/030] Train loss: 0.0911
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[006/030] Train loss: 0.0905
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[007/030] Train loss: 0.0912
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[008/030] Train loss: 0.0910
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[009/030] Train loss: 0.0908
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[010/030] Train loss: 0.0907
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[011/030] Train loss: 0.0906
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[012/030] Train loss: 0.0907
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[013/030] Train loss: 0.0906
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[014/030] Train loss: 0.0903
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[015/030] Train loss: 0.0901
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[016/030] Train loss: 0.0900
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[017/030] Train loss: 0.0898
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[018/030] Train loss: 0.0900
2023-02-06 10:42:38 | Train | Epoch[064/600] Iteration[019/030] Train loss: 0.0898
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[020/030] Train loss: 0.0896
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[021/030] Train loss: 0.0896
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[022/030] Train loss: 0.0897
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[023/030] Train loss: 0.0898
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[024/030] Train loss: 0.0897
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[025/030] Train loss: 0.0897
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[026/030] Train loss: 0.0897
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[027/030] Train loss: 0.0896
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[028/030] Train loss: 0.0894
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[029/030] Train loss: 0.0893
2023-02-06 10:42:39 | Train | Epoch[064/600] Iteration[030/030] Train loss: 0.0893
2023-02-06 10:42:39 | Valid | Epoch[064/600] Iteration[001/008] Valid loss: 0.5408
2023-02-06 10:42:39 | Valid | Epoch[064/600] Iteration[002/008] Valid loss: 0.5104
2023-02-06 10:42:39 | Valid | Epoch[064/600] Iteration[003/008] Valid loss: 0.5083
2023-02-06 10:42:39 | Valid | Epoch[064/600] Iteration[004/008] Valid loss: 0.5190
2023-02-06 10:42:39 | Valid | Epoch[064/600] Iteration[005/008] Valid loss: 0.5357
2023-02-06 10:42:39 | Valid | Epoch[064/600] Iteration[006/008] Valid loss: 0.5277
2023-02-06 10:42:39 | Valid | Epoch[064/600] Iteration[007/008] Valid loss: 0.5519
2023-02-06 10:42:39 | Valid | Epoch[064/600] Iteration[008/008] Valid loss: 0.5594
2023-02-06 10:42:40 | Valid | Epoch[064/600] MIou: 0.8260983288524911
2023-02-06 10:42:40 | Valid | Epoch[064/600] Pixel Accuracy: 0.9606310526529948
2023-02-06 10:42:40 | Valid | Epoch[064/600] Mean Pixel Accuracy: 0.9762878133086412
2023-02-06 10:42:40 | Stage | Epoch[064/600] Train loss:0.0893
2023-02-06 10:42:40 | Stage | Epoch[064/600] Valid loss:0.5594
2023-02-06 10:42:40 | Stage | Epoch[064/600] LR:0.01

2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[001/030] Train loss: 0.0897
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[002/030] Train loss: 0.0913
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[003/030] Train loss: 0.0896
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[004/030] Train loss: 0.0889
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[005/030] Train loss: 0.0885
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[006/030] Train loss: 0.0883
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[007/030] Train loss: 0.0881
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[008/030] Train loss: 0.0876
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[009/030] Train loss: 0.0879
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[010/030] Train loss: 0.0876
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[011/030] Train loss: 0.0876
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[012/030] Train loss: 0.0875
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[013/030] Train loss: 0.0878
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[014/030] Train loss: 0.0880
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[015/030] Train loss: 0.0882
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[016/030] Train loss: 0.0881
2023-02-06 10:42:40 | Train | Epoch[065/600] Iteration[017/030] Train loss: 0.0879
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[018/030] Train loss: 0.0877
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[019/030] Train loss: 0.0879
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[020/030] Train loss: 0.0880
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[021/030] Train loss: 0.0879
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[022/030] Train loss: 0.0879
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[023/030] Train loss: 0.0877
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[024/030] Train loss: 0.0876
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[025/030] Train loss: 0.0877
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[026/030] Train loss: 0.0876
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[027/030] Train loss: 0.0876
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[028/030] Train loss: 0.0877
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[029/030] Train loss: 0.0876
2023-02-06 10:42:41 | Train | Epoch[065/600] Iteration[030/030] Train loss: 0.0873
2023-02-06 10:42:41 | Valid | Epoch[065/600] Iteration[001/008] Valid loss: 0.1261
2023-02-06 10:42:41 | Valid | Epoch[065/600] Iteration[002/008] Valid loss: 0.1245
2023-02-06 10:42:41 | Valid | Epoch[065/600] Iteration[003/008] Valid loss: 0.1256
2023-02-06 10:42:41 | Valid | Epoch[065/600] Iteration[004/008] Valid loss: 0.1251
2023-02-06 10:42:41 | Valid | Epoch[065/600] Iteration[005/008] Valid loss: 0.1262
2023-02-06 10:42:41 | Valid | Epoch[065/600] Iteration[006/008] Valid loss: 0.1255
2023-02-06 10:42:42 | Valid | Epoch[065/600] Iteration[007/008] Valid loss: 0.1241
2023-02-06 10:42:42 | Valid | Epoch[065/600] Iteration[008/008] Valid loss: 0.1250
2023-02-06 10:42:42 | Valid | Epoch[065/600] MIou: 0.7538444857516802
2023-02-06 10:42:42 | Valid | Epoch[065/600] Pixel Accuracy: 0.9593900044759115
2023-02-06 10:42:42 | Valid | Epoch[065/600] Mean Pixel Accuracy: 0.7752404400478576
2023-02-06 10:42:42 | Stage | Epoch[065/600] Train loss:0.0873
2023-02-06 10:42:42 | Stage | Epoch[065/600] Valid loss:0.1250
2023-02-06 10:42:42 | Stage | Epoch[065/600] LR:0.01

2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[001/030] Train loss: 0.0839
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[002/030] Train loss: 0.0886
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[003/030] Train loss: 0.0878
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[004/030] Train loss: 0.0881
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[005/030] Train loss: 0.0894
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[006/030] Train loss: 0.0880
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[007/030] Train loss: 0.0882
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[008/030] Train loss: 0.0876
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[009/030] Train loss: 0.0872
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[010/030] Train loss: 0.0872
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[011/030] Train loss: 0.0870
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[012/030] Train loss: 0.0873
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[013/030] Train loss: 0.0872
2023-02-06 10:42:42 | Train | Epoch[066/600] Iteration[014/030] Train loss: 0.0870
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[015/030] Train loss: 0.0868
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[016/030] Train loss: 0.0870
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[017/030] Train loss: 0.0871
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[018/030] Train loss: 0.0870
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[019/030] Train loss: 0.0869
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[020/030] Train loss: 0.0869
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[021/030] Train loss: 0.0867
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[022/030] Train loss: 0.0866
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[023/030] Train loss: 0.0867
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[024/030] Train loss: 0.0864
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[025/030] Train loss: 0.0865
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[026/030] Train loss: 0.0866
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[027/030] Train loss: 0.0866
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[028/030] Train loss: 0.0866
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[029/030] Train loss: 0.0866
2023-02-06 10:42:43 | Train | Epoch[066/600] Iteration[030/030] Train loss: 0.0866
2023-02-06 10:42:44 | Valid | Epoch[066/600] Iteration[001/008] Valid loss: 0.1443
2023-02-06 10:42:44 | Valid | Epoch[066/600] Iteration[002/008] Valid loss: 0.1318
2023-02-06 10:42:44 | Valid | Epoch[066/600] Iteration[003/008] Valid loss: 0.1295
2023-02-06 10:42:44 | Valid | Epoch[066/600] Iteration[004/008] Valid loss: 0.1290
2023-02-06 10:42:44 | Valid | Epoch[066/600] Iteration[005/008] Valid loss: 0.1314
2023-02-06 10:42:44 | Valid | Epoch[066/600] Iteration[006/008] Valid loss: 0.1303
2023-02-06 10:42:44 | Valid | Epoch[066/600] Iteration[007/008] Valid loss: 0.1339
2023-02-06 10:42:44 | Valid | Epoch[066/600] Iteration[008/008] Valid loss: 0.1338
2023-02-06 10:42:44 | Valid | Epoch[066/600] MIou: 0.9169003989973411
2023-02-06 10:42:44 | Valid | Epoch[066/600] Pixel Accuracy: 0.9844919840494791
2023-02-06 10:42:44 | Valid | Epoch[066/600] Mean Pixel Accuracy: 0.9821239375523925
2023-02-06 10:42:44 | Stage | Epoch[066/600] Train loss:0.0866
2023-02-06 10:42:44 | Stage | Epoch[066/600] Valid loss:0.1338
2023-02-06 10:42:44 | Stage | Epoch[066/600] LR:0.01

2023-02-06 10:42:44 | Train | Epoch[067/600] Iteration[001/030] Train loss: 0.0859
2023-02-06 10:42:44 | Train | Epoch[067/600] Iteration[002/030] Train loss: 0.0851
2023-02-06 10:42:44 | Train | Epoch[067/600] Iteration[003/030] Train loss: 0.0847
2023-02-06 10:42:44 | Train | Epoch[067/600] Iteration[004/030] Train loss: 0.0849
2023-02-06 10:42:44 | Train | Epoch[067/600] Iteration[005/030] Train loss: 0.0855
2023-02-06 10:42:44 | Train | Epoch[067/600] Iteration[006/030] Train loss: 0.0848
2023-02-06 10:42:44 | Train | Epoch[067/600] Iteration[007/030] Train loss: 0.0854
2023-02-06 10:42:44 | Train | Epoch[067/600] Iteration[008/030] Train loss: 0.0850
2023-02-06 10:42:44 | Train | Epoch[067/600] Iteration[009/030] Train loss: 0.0853
2023-02-06 10:42:44 | Train | Epoch[067/600] Iteration[010/030] Train loss: 0.0849
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[011/030] Train loss: 0.0852
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[012/030] Train loss: 0.0852
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[013/030] Train loss: 0.0852
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[014/030] Train loss: 0.0852
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[015/030] Train loss: 0.0852
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[016/030] Train loss: 0.0852
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[017/030] Train loss: 0.0851
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[018/030] Train loss: 0.0850
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[019/030] Train loss: 0.0849
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[020/030] Train loss: 0.0848
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[021/030] Train loss: 0.0846
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[022/030] Train loss: 0.0844
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[023/030] Train loss: 0.0846
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[024/030] Train loss: 0.0847
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[025/030] Train loss: 0.0845
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[026/030] Train loss: 0.0844
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[027/030] Train loss: 0.0843
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[028/030] Train loss: 0.0842
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[029/030] Train loss: 0.0842
2023-02-06 10:42:45 | Train | Epoch[067/600] Iteration[030/030] Train loss: 0.0840
2023-02-06 10:42:46 | Valid | Epoch[067/600] Iteration[001/008] Valid loss: 0.2213
2023-02-06 10:42:46 | Valid | Epoch[067/600] Iteration[002/008] Valid loss: 0.1866
2023-02-06 10:42:46 | Valid | Epoch[067/600] Iteration[003/008] Valid loss: 0.1813
2023-02-06 10:42:46 | Valid | Epoch[067/600] Iteration[004/008] Valid loss: 0.1815
2023-02-06 10:42:46 | Valid | Epoch[067/600] Iteration[005/008] Valid loss: 0.1833
2023-02-06 10:42:46 | Valid | Epoch[067/600] Iteration[006/008] Valid loss: 0.1803
2023-02-06 10:42:46 | Valid | Epoch[067/600] Iteration[007/008] Valid loss: 0.1902
2023-02-06 10:42:46 | Valid | Epoch[067/600] Iteration[008/008] Valid loss: 0.1905
2023-02-06 10:42:46 | Valid | Epoch[067/600] MIou: 0.8899142243270519
2023-02-06 10:42:46 | Valid | Epoch[067/600] Pixel Accuracy: 0.978295644124349
2023-02-06 10:42:46 | Valid | Epoch[067/600] Mean Pixel Accuracy: 0.9806710300877554
2023-02-06 10:42:46 | Stage | Epoch[067/600] Train loss:0.0840
2023-02-06 10:42:46 | Stage | Epoch[067/600] Valid loss:0.1905
2023-02-06 10:42:46 | Stage | Epoch[067/600] LR:0.01

2023-02-06 10:42:46 | Train | Epoch[068/600] Iteration[001/030] Train loss: 0.0812
2023-02-06 10:42:46 | Train | Epoch[068/600] Iteration[002/030] Train loss: 0.0815
2023-02-06 10:42:46 | Train | Epoch[068/600] Iteration[003/030] Train loss: 0.0821
2023-02-06 10:42:46 | Train | Epoch[068/600] Iteration[004/030] Train loss: 0.0830
2023-02-06 10:42:46 | Train | Epoch[068/600] Iteration[005/030] Train loss: 0.0825
2023-02-06 10:42:46 | Train | Epoch[068/600] Iteration[006/030] Train loss: 0.0821
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[007/030] Train loss: 0.0828
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[008/030] Train loss: 0.0828
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[009/030] Train loss: 0.0827
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[010/030] Train loss: 0.0823
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[011/030] Train loss: 0.0823
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[012/030] Train loss: 0.0823
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[013/030] Train loss: 0.0824
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[014/030] Train loss: 0.0824
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[015/030] Train loss: 0.0822
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[016/030] Train loss: 0.0822
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[017/030] Train loss: 0.0824
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[018/030] Train loss: 0.0826
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[019/030] Train loss: 0.0826
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[020/030] Train loss: 0.0829
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[021/030] Train loss: 0.0831
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[022/030] Train loss: 0.0830
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[023/030] Train loss: 0.0829
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[024/030] Train loss: 0.0830
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[025/030] Train loss: 0.0829
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[026/030] Train loss: 0.0827
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[027/030] Train loss: 0.0828
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[028/030] Train loss: 0.0827
2023-02-06 10:42:47 | Train | Epoch[068/600] Iteration[029/030] Train loss: 0.0825
2023-02-06 10:42:48 | Train | Epoch[068/600] Iteration[030/030] Train loss: 0.0824
2023-02-06 10:42:48 | Valid | Epoch[068/600] Iteration[001/008] Valid loss: 0.0897
2023-02-06 10:42:48 | Valid | Epoch[068/600] Iteration[002/008] Valid loss: 0.0866
2023-02-06 10:42:48 | Valid | Epoch[068/600] Iteration[003/008] Valid loss: 0.0862
2023-02-06 10:42:48 | Valid | Epoch[068/600] Iteration[004/008] Valid loss: 0.0855
2023-02-06 10:42:48 | Valid | Epoch[068/600] Iteration[005/008] Valid loss: 0.0858
2023-02-06 10:42:48 | Valid | Epoch[068/600] Iteration[006/008] Valid loss: 0.0854
2023-02-06 10:42:48 | Valid | Epoch[068/600] Iteration[007/008] Valid loss: 0.0854
2023-02-06 10:42:48 | Valid | Epoch[068/600] Iteration[008/008] Valid loss: 0.0854
2023-02-06 10:42:48 | Valid | Epoch[068/600] MIou: 0.911131276935553
2023-02-06 10:42:48 | Valid | Epoch[068/600] Pixel Accuracy: 0.9852307637532552
2023-02-06 10:42:48 | Valid | Epoch[068/600] Mean Pixel Accuracy: 0.9231958699757373
2023-02-06 10:42:48 | Stage | Epoch[068/600] Train loss:0.0824
2023-02-06 10:42:48 | Stage | Epoch[068/600] Valid loss:0.0854
2023-02-06 10:42:48 | Stage | Epoch[068/600] LR:0.01

2023-02-06 10:42:48 | Train | Epoch[069/600] Iteration[001/030] Train loss: 0.0804
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[002/030] Train loss: 0.0807
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[003/030] Train loss: 0.0811
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[004/030] Train loss: 0.0806
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[005/030] Train loss: 0.0802
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[006/030] Train loss: 0.0813
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[007/030] Train loss: 0.0815
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[008/030] Train loss: 0.0817
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[009/030] Train loss: 0.0814
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[010/030] Train loss: 0.0814
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[011/030] Train loss: 0.0812
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[012/030] Train loss: 0.0814
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[013/030] Train loss: 0.0817
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[014/030] Train loss: 0.0819
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[015/030] Train loss: 0.0816
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[016/030] Train loss: 0.0818
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[017/030] Train loss: 0.0818
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[018/030] Train loss: 0.0817
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[019/030] Train loss: 0.0815
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[020/030] Train loss: 0.0816
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[021/030] Train loss: 0.0815
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[022/030] Train loss: 0.0820
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[023/030] Train loss: 0.0818
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[024/030] Train loss: 0.0817
2023-02-06 10:42:49 | Train | Epoch[069/600] Iteration[025/030] Train loss: 0.0817
2023-02-06 10:42:50 | Train | Epoch[069/600] Iteration[026/030] Train loss: 0.0816
2023-02-06 10:42:50 | Train | Epoch[069/600] Iteration[027/030] Train loss: 0.0816
2023-02-06 10:42:50 | Train | Epoch[069/600] Iteration[028/030] Train loss: 0.0818
2023-02-06 10:42:50 | Train | Epoch[069/600] Iteration[029/030] Train loss: 0.0819
2023-02-06 10:42:50 | Train | Epoch[069/600] Iteration[030/030] Train loss: 0.0819
2023-02-06 10:42:50 | Valid | Epoch[069/600] Iteration[001/008] Valid loss: 0.3517
2023-02-06 10:42:50 | Valid | Epoch[069/600] Iteration[002/008] Valid loss: 0.2978
2023-02-06 10:42:50 | Valid | Epoch[069/600] Iteration[003/008] Valid loss: 0.2960
2023-02-06 10:42:50 | Valid | Epoch[069/600] Iteration[004/008] Valid loss: 0.2948
2023-02-06 10:42:50 | Valid | Epoch[069/600] Iteration[005/008] Valid loss: 0.3025
2023-02-06 10:42:50 | Valid | Epoch[069/600] Iteration[006/008] Valid loss: 0.2955
2023-02-06 10:42:50 | Valid | Epoch[069/600] Iteration[007/008] Valid loss: 0.3082
2023-02-06 10:42:50 | Valid | Epoch[069/600] Iteration[008/008] Valid loss: 0.3199
2023-02-06 10:42:50 | Valid | Epoch[069/600] MIou: 0.8681867783457857
2023-02-06 10:42:50 | Valid | Epoch[069/600] Pixel Accuracy: 0.9728902180989584
2023-02-06 10:42:50 | Valid | Epoch[069/600] Mean Pixel Accuracy: 0.9775604870350907
2023-02-06 10:42:50 | Stage | Epoch[069/600] Train loss:0.0819
2023-02-06 10:42:50 | Stage | Epoch[069/600] Valid loss:0.3199
2023-02-06 10:42:50 | Stage | Epoch[069/600] LR:0.01

2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[001/030] Train loss: 0.0799
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[002/030] Train loss: 0.0807
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[003/030] Train loss: 0.0823
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[004/030] Train loss: 0.0810
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[005/030] Train loss: 0.0817
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[006/030] Train loss: 0.0823
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[007/030] Train loss: 0.0826
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[008/030] Train loss: 0.0826
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[009/030] Train loss: 0.0829
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[010/030] Train loss: 0.0827
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[011/030] Train loss: 0.0828
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[012/030] Train loss: 0.0833
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[013/030] Train loss: 0.0829
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[014/030] Train loss: 0.0825
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[015/030] Train loss: 0.0826
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[016/030] Train loss: 0.0824
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[017/030] Train loss: 0.0822
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[018/030] Train loss: 0.0818
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[019/030] Train loss: 0.0818
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[020/030] Train loss: 0.0816
2023-02-06 10:42:51 | Train | Epoch[070/600] Iteration[021/030] Train loss: 0.0813
2023-02-06 10:42:52 | Train | Epoch[070/600] Iteration[022/030] Train loss: 0.0813
2023-02-06 10:42:52 | Train | Epoch[070/600] Iteration[023/030] Train loss: 0.0813
2023-02-06 10:42:52 | Train | Epoch[070/600] Iteration[024/030] Train loss: 0.0811
2023-02-06 10:42:52 | Train | Epoch[070/600] Iteration[025/030] Train loss: 0.0810
2023-02-06 10:42:52 | Train | Epoch[070/600] Iteration[026/030] Train loss: 0.0809
2023-02-06 10:42:52 | Train | Epoch[070/600] Iteration[027/030] Train loss: 0.0807
2023-02-06 10:42:52 | Train | Epoch[070/600] Iteration[028/030] Train loss: 0.0807
2023-02-06 10:42:52 | Train | Epoch[070/600] Iteration[029/030] Train loss: 0.0807
2023-02-06 10:42:52 | Train | Epoch[070/600] Iteration[030/030] Train loss: 0.0807
2023-02-06 10:42:52 | Valid | Epoch[070/600] Iteration[001/008] Valid loss: 0.1831
2023-02-06 10:42:52 | Valid | Epoch[070/600] Iteration[002/008] Valid loss: 0.1811
2023-02-06 10:42:52 | Valid | Epoch[070/600] Iteration[003/008] Valid loss: 0.1851
2023-02-06 10:42:52 | Valid | Epoch[070/600] Iteration[004/008] Valid loss: 0.1865
2023-02-06 10:42:52 | Valid | Epoch[070/600] Iteration[005/008] Valid loss: 0.1889
2023-02-06 10:42:52 | Valid | Epoch[070/600] Iteration[006/008] Valid loss: 0.1885
2023-02-06 10:42:52 | Valid | Epoch[070/600] Iteration[007/008] Valid loss: 0.1883
2023-02-06 10:42:52 | Valid | Epoch[070/600] Iteration[008/008] Valid loss: 0.1909
2023-02-06 10:42:52 | Valid | Epoch[070/600] MIou: 0.47196938123783894
2023-02-06 10:42:52 | Valid | Epoch[070/600] Pixel Accuracy: 0.9125404357910156
2023-02-06 10:42:52 | Valid | Epoch[070/600] Mean Pixel Accuracy: 0.5158245223781835
2023-02-06 10:42:52 | Stage | Epoch[070/600] Train loss:0.0807
2023-02-06 10:42:52 | Stage | Epoch[070/600] Valid loss:0.1909
2023-02-06 10:42:52 | Stage | Epoch[070/600] LR:0.01

2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[001/030] Train loss: 0.0766
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[002/030] Train loss: 0.0775
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[003/030] Train loss: 0.0804
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[004/030] Train loss: 0.0794
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[005/030] Train loss: 0.0795
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[006/030] Train loss: 0.0794
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[007/030] Train loss: 0.0799
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[008/030] Train loss: 0.0798
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[009/030] Train loss: 0.0797
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[010/030] Train loss: 0.0793
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[011/030] Train loss: 0.0795
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[012/030] Train loss: 0.0803
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[013/030] Train loss: 0.0802
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[014/030] Train loss: 0.0799
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[015/030] Train loss: 0.0798
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[016/030] Train loss: 0.0799
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[017/030] Train loss: 0.0799
2023-02-06 10:42:53 | Train | Epoch[071/600] Iteration[018/030] Train loss: 0.0798
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[019/030] Train loss: 0.0798
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[020/030] Train loss: 0.0798
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[021/030] Train loss: 0.0797
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[022/030] Train loss: 0.0796
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[023/030] Train loss: 0.0794
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[024/030] Train loss: 0.0793
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[025/030] Train loss: 0.0792
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[026/030] Train loss: 0.0791
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[027/030] Train loss: 0.0790
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[028/030] Train loss: 0.0789
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[029/030] Train loss: 0.0789
2023-02-06 10:42:54 | Train | Epoch[071/600] Iteration[030/030] Train loss: 0.0787
2023-02-06 10:42:54 | Valid | Epoch[071/600] Iteration[001/008] Valid loss: 0.1640
2023-02-06 10:42:54 | Valid | Epoch[071/600] Iteration[002/008] Valid loss: 0.1478
2023-02-06 10:42:54 | Valid | Epoch[071/600] Iteration[003/008] Valid loss: 0.1466
2023-02-06 10:42:54 | Valid | Epoch[071/600] Iteration[004/008] Valid loss: 0.1480
2023-02-06 10:42:54 | Valid | Epoch[071/600] Iteration[005/008] Valid loss: 0.1511
2023-02-06 10:42:54 | Valid | Epoch[071/600] Iteration[006/008] Valid loss: 0.1502
2023-02-06 10:42:55 | Valid | Epoch[071/600] Iteration[007/008] Valid loss: 0.1556
2023-02-06 10:42:55 | Valid | Epoch[071/600] Iteration[008/008] Valid loss: 0.1563
2023-02-06 10:42:55 | Valid | Epoch[071/600] MIou: 0.8895729711650805
2023-02-06 10:42:55 | Valid | Epoch[071/600] Pixel Accuracy: 0.9781646728515625
2023-02-06 10:42:55 | Valid | Epoch[071/600] Mean Pixel Accuracy: 0.981772029920177
2023-02-06 10:42:55 | Stage | Epoch[071/600] Train loss:0.0787
2023-02-06 10:42:55 | Stage | Epoch[071/600] Valid loss:0.1563
2023-02-06 10:42:55 | Stage | Epoch[071/600] LR:0.01

2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[001/030] Train loss: 0.0734
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[002/030] Train loss: 0.0752
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[003/030] Train loss: 0.0755
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[004/030] Train loss: 0.0760
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[005/030] Train loss: 0.0763
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[006/030] Train loss: 0.0773
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[007/030] Train loss: 0.0782
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[008/030] Train loss: 0.0778
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[009/030] Train loss: 0.0779
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[010/030] Train loss: 0.0779
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[011/030] Train loss: 0.0779
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[012/030] Train loss: 0.0777
2023-02-06 10:42:55 | Train | Epoch[072/600] Iteration[013/030] Train loss: 0.0776
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[014/030] Train loss: 0.0776
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[015/030] Train loss: 0.0773
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[016/030] Train loss: 0.0772
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[017/030] Train loss: 0.0770
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[018/030] Train loss: 0.0770
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[019/030] Train loss: 0.0770
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[020/030] Train loss: 0.0773
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[021/030] Train loss: 0.0771
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[022/030] Train loss: 0.0771
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[023/030] Train loss: 0.0772
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[024/030] Train loss: 0.0772
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[025/030] Train loss: 0.0772
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[026/030] Train loss: 0.0772
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[027/030] Train loss: 0.0772
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[028/030] Train loss: 0.0771
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[029/030] Train loss: 0.0771
2023-02-06 10:42:56 | Train | Epoch[072/600] Iteration[030/030] Train loss: 0.0771
2023-02-06 10:42:57 | Valid | Epoch[072/600] Iteration[001/008] Valid loss: 0.0891
2023-02-06 10:42:57 | Valid | Epoch[072/600] Iteration[002/008] Valid loss: 0.0876
2023-02-06 10:42:57 | Valid | Epoch[072/600] Iteration[003/008] Valid loss: 0.0879
2023-02-06 10:42:57 | Valid | Epoch[072/600] Iteration[004/008] Valid loss: 0.0869
2023-02-06 10:42:57 | Valid | Epoch[072/600] Iteration[005/008] Valid loss: 0.0873
2023-02-06 10:42:57 | Valid | Epoch[072/600] Iteration[006/008] Valid loss: 0.0868
2023-02-06 10:42:57 | Valid | Epoch[072/600] Iteration[007/008] Valid loss: 0.0864
2023-02-06 10:42:57 | Valid | Epoch[072/600] Iteration[008/008] Valid loss: 0.0866
2023-02-06 10:42:57 | Valid | Epoch[072/600] MIou: 0.8665043807782454
2023-02-06 10:42:57 | Valid | Epoch[072/600] Pixel Accuracy: 0.9779942830403646
2023-02-06 10:42:57 | Valid | Epoch[072/600] Mean Pixel Accuracy: 0.8786900976422807
2023-02-06 10:42:57 | Stage | Epoch[072/600] Train loss:0.0771
2023-02-06 10:42:57 | Stage | Epoch[072/600] Valid loss:0.0866
2023-02-06 10:42:57 | Stage | Epoch[072/600] LR:0.01

2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[001/030] Train loss: 0.0777
2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[002/030] Train loss: 0.0793
2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[003/030] Train loss: 0.0789
2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[004/030] Train loss: 0.0780
2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[005/030] Train loss: 0.0773
2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[006/030] Train loss: 0.0772
2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[007/030] Train loss: 0.0771
2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[008/030] Train loss: 0.0769
2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[009/030] Train loss: 0.0771
2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[010/030] Train loss: 0.0767
2023-02-06 10:42:57 | Train | Epoch[073/600] Iteration[011/030] Train loss: 0.0765
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[012/030] Train loss: 0.0773
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[013/030] Train loss: 0.0770
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[014/030] Train loss: 0.0769
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[015/030] Train loss: 0.0769
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[016/030] Train loss: 0.0768
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[017/030] Train loss: 0.0768
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[018/030] Train loss: 0.0769
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[019/030] Train loss: 0.0769
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[020/030] Train loss: 0.0768
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[021/030] Train loss: 0.0766
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[022/030] Train loss: 0.0764
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[023/030] Train loss: 0.0764
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[024/030] Train loss: 0.0765
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[025/030] Train loss: 0.0764
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[026/030] Train loss: 0.0762
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[027/030] Train loss: 0.0762
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[028/030] Train loss: 0.0761
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[029/030] Train loss: 0.0761
2023-02-06 10:42:58 | Train | Epoch[073/600] Iteration[030/030] Train loss: 0.0762
2023-02-06 10:42:59 | Valid | Epoch[073/600] Iteration[001/008] Valid loss: 0.1817
2023-02-06 10:42:59 | Valid | Epoch[073/600] Iteration[002/008] Valid loss: 0.1818
2023-02-06 10:42:59 | Valid | Epoch[073/600] Iteration[003/008] Valid loss: 0.1864
2023-02-06 10:42:59 | Valid | Epoch[073/600] Iteration[004/008] Valid loss: 0.1873
2023-02-06 10:42:59 | Valid | Epoch[073/600] Iteration[005/008] Valid loss: 0.1908
2023-02-06 10:42:59 | Valid | Epoch[073/600] Iteration[006/008] Valid loss: 0.1894
2023-02-06 10:42:59 | Valid | Epoch[073/600] Iteration[007/008] Valid loss: 0.1881
2023-02-06 10:42:59 | Valid | Epoch[073/600] Iteration[008/008] Valid loss: 0.1916
2023-02-06 10:42:59 | Valid | Epoch[073/600] MIou: 0.4837838085998191
2023-02-06 10:42:59 | Valid | Epoch[073/600] Pixel Accuracy: 0.9145113627115885
2023-02-06 10:42:59 | Valid | Epoch[073/600] Mean Pixel Accuracy: 0.5267355587154543
2023-02-06 10:42:59 | Stage | Epoch[073/600] Train loss:0.0762
2023-02-06 10:42:59 | Stage | Epoch[073/600] Valid loss:0.1916
2023-02-06 10:42:59 | Stage | Epoch[073/600] LR:0.01

2023-02-06 10:42:59 | Train | Epoch[074/600] Iteration[001/030] Train loss: 0.0741
2023-02-06 10:42:59 | Train | Epoch[074/600] Iteration[002/030] Train loss: 0.0738
2023-02-06 10:42:59 | Train | Epoch[074/600] Iteration[003/030] Train loss: 0.0751
2023-02-06 10:42:59 | Train | Epoch[074/600] Iteration[004/030] Train loss: 0.0763
2023-02-06 10:42:59 | Train | Epoch[074/600] Iteration[005/030] Train loss: 0.0757
2023-02-06 10:42:59 | Train | Epoch[074/600] Iteration[006/030] Train loss: 0.0756
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[007/030] Train loss: 0.0758
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[008/030] Train loss: 0.0759
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[009/030] Train loss: 0.0758
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[010/030] Train loss: 0.0761
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[011/030] Train loss: 0.0760
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[012/030] Train loss: 0.0758
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[013/030] Train loss: 0.0759
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[014/030] Train loss: 0.0757
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[015/030] Train loss: 0.0756
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[016/030] Train loss: 0.0755
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[017/030] Train loss: 0.0753
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[018/030] Train loss: 0.0754
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[019/030] Train loss: 0.0754
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[020/030] Train loss: 0.0752
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[021/030] Train loss: 0.0752
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[022/030] Train loss: 0.0752
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[023/030] Train loss: 0.0750
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[024/030] Train loss: 0.0749
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[025/030] Train loss: 0.0749
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[026/030] Train loss: 0.0749
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[027/030] Train loss: 0.0748
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[028/030] Train loss: 0.0747
2023-02-06 10:43:00 | Train | Epoch[074/600] Iteration[029/030] Train loss: 0.0748
2023-02-06 10:43:01 | Train | Epoch[074/600] Iteration[030/030] Train loss: 0.0749
2023-02-06 10:43:01 | Valid | Epoch[074/600] Iteration[001/008] Valid loss: 0.0868
2023-02-06 10:43:01 | Valid | Epoch[074/600] Iteration[002/008] Valid loss: 0.0858
2023-02-06 10:43:01 | Valid | Epoch[074/600] Iteration[003/008] Valid loss: 0.0859
2023-02-06 10:43:01 | Valid | Epoch[074/600] Iteration[004/008] Valid loss: 0.0850
2023-02-06 10:43:01 | Valid | Epoch[074/600] Iteration[005/008] Valid loss: 0.0854
2023-02-06 10:43:01 | Valid | Epoch[074/600] Iteration[006/008] Valid loss: 0.0848
2023-02-06 10:43:01 | Valid | Epoch[074/600] Iteration[007/008] Valid loss: 0.0842
2023-02-06 10:43:01 | Valid | Epoch[074/600] Iteration[008/008] Valid loss: 0.0846
2023-02-06 10:43:01 | Valid | Epoch[074/600] MIou: 0.8668003370894349
2023-02-06 10:43:01 | Valid | Epoch[074/600] Pixel Accuracy: 0.977959950764974
2023-02-06 10:43:01 | Valid | Epoch[074/600] Mean Pixel Accuracy: 0.8803894949392634
2023-02-06 10:43:01 | Stage | Epoch[074/600] Train loss:0.0749
2023-02-06 10:43:01 | Stage | Epoch[074/600] Valid loss:0.0846
2023-02-06 10:43:01 | Stage | Epoch[074/600] LR:0.01

2023-02-06 10:43:01 | Train | Epoch[075/600] Iteration[001/030] Train loss: 0.0707
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[002/030] Train loss: 0.0708
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[003/030] Train loss: 0.0710
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[004/030] Train loss: 0.0717
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[005/030] Train loss: 0.0725
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[006/030] Train loss: 0.0726
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[007/030] Train loss: 0.0725
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[008/030] Train loss: 0.0732
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[009/030] Train loss: 0.0732
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[010/030] Train loss: 0.0732
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[011/030] Train loss: 0.0730
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[012/030] Train loss: 0.0730
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[013/030] Train loss: 0.0732
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[014/030] Train loss: 0.0730
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[015/030] Train loss: 0.0730
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[016/030] Train loss: 0.0728
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[017/030] Train loss: 0.0730
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[018/030] Train loss: 0.0732
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[019/030] Train loss: 0.0734
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[020/030] Train loss: 0.0734
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[021/030] Train loss: 0.0736
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[022/030] Train loss: 0.0737
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[023/030] Train loss: 0.0735
2023-02-06 10:43:02 | Train | Epoch[075/600] Iteration[024/030] Train loss: 0.0735
2023-02-06 10:43:03 | Train | Epoch[075/600] Iteration[025/030] Train loss: 0.0735
2023-02-06 10:43:03 | Train | Epoch[075/600] Iteration[026/030] Train loss: 0.0735
2023-02-06 10:43:03 | Train | Epoch[075/600] Iteration[027/030] Train loss: 0.0736
2023-02-06 10:43:03 | Train | Epoch[075/600] Iteration[028/030] Train loss: 0.0736
2023-02-06 10:43:03 | Train | Epoch[075/600] Iteration[029/030] Train loss: 0.0737
2023-02-06 10:43:03 | Train | Epoch[075/600] Iteration[030/030] Train loss: 0.0737
2023-02-06 10:43:03 | Valid | Epoch[075/600] Iteration[001/008] Valid loss: 0.0850
2023-02-06 10:43:03 | Valid | Epoch[075/600] Iteration[002/008] Valid loss: 0.0844
2023-02-06 10:43:03 | Valid | Epoch[075/600] Iteration[003/008] Valid loss: 0.0846
2023-02-06 10:43:03 | Valid | Epoch[075/600] Iteration[004/008] Valid loss: 0.0839
2023-02-06 10:43:03 | Valid | Epoch[075/600] Iteration[005/008] Valid loss: 0.0842
2023-02-06 10:43:03 | Valid | Epoch[075/600] Iteration[006/008] Valid loss: 0.0839
2023-02-06 10:43:03 | Valid | Epoch[075/600] Iteration[007/008] Valid loss: 0.0834
2023-02-06 10:43:03 | Valid | Epoch[075/600] Iteration[008/008] Valid loss: 0.0837
2023-02-06 10:43:03 | Valid | Epoch[075/600] MIou: 0.8648021726666869
2023-02-06 10:43:03 | Valid | Epoch[075/600] Pixel Accuracy: 0.97772216796875
2023-02-06 10:43:03 | Valid | Epoch[075/600] Mean Pixel Accuracy: 0.8769807756015225
2023-02-06 10:43:03 | Stage | Epoch[075/600] Train loss:0.0737
2023-02-06 10:43:03 | Stage | Epoch[075/600] Valid loss:0.0837
2023-02-06 10:43:03 | Stage | Epoch[075/600] LR:0.01

2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[001/030] Train loss: 0.0698
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[002/030] Train loss: 0.0719
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[003/030] Train loss: 0.0740
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[004/030] Train loss: 0.0743
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[005/030] Train loss: 0.0745
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[006/030] Train loss: 0.0741
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[007/030] Train loss: 0.0746
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[008/030] Train loss: 0.0742
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[009/030] Train loss: 0.0736
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[010/030] Train loss: 0.0734
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[011/030] Train loss: 0.0732
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[012/030] Train loss: 0.0736
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[013/030] Train loss: 0.0735
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[014/030] Train loss: 0.0735
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[015/030] Train loss: 0.0736
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[016/030] Train loss: 0.0735
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[017/030] Train loss: 0.0734
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[018/030] Train loss: 0.0734
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[019/030] Train loss: 0.0735
2023-02-06 10:43:04 | Train | Epoch[076/600] Iteration[020/030] Train loss: 0.0735
2023-02-06 10:43:05 | Train | Epoch[076/600] Iteration[021/030] Train loss: 0.0734
2023-02-06 10:43:05 | Train | Epoch[076/600] Iteration[022/030] Train loss: 0.0737
2023-02-06 10:43:05 | Train | Epoch[076/600] Iteration[023/030] Train loss: 0.0735
2023-02-06 10:43:05 | Train | Epoch[076/600] Iteration[024/030] Train loss: 0.0735
2023-02-06 10:43:05 | Train | Epoch[076/600] Iteration[025/030] Train loss: 0.0736
2023-02-06 10:43:05 | Train | Epoch[076/600] Iteration[026/030] Train loss: 0.0735
2023-02-06 10:43:05 | Train | Epoch[076/600] Iteration[027/030] Train loss: 0.0735
2023-02-06 10:43:05 | Train | Epoch[076/600] Iteration[028/030] Train loss: 0.0736
2023-02-06 10:43:05 | Train | Epoch[076/600] Iteration[029/030] Train loss: 0.0735
2023-02-06 10:43:05 | Train | Epoch[076/600] Iteration[030/030] Train loss: 0.0739
2023-02-06 10:43:05 | Valid | Epoch[076/600] Iteration[001/008] Valid loss: 0.1852
2023-02-06 10:43:05 | Valid | Epoch[076/600] Iteration[002/008] Valid loss: 0.1808
2023-02-06 10:43:05 | Valid | Epoch[076/600] Iteration[003/008] Valid loss: 0.1843
2023-02-06 10:43:05 | Valid | Epoch[076/600] Iteration[004/008] Valid loss: 0.1859
2023-02-06 10:43:05 | Valid | Epoch[076/600] Iteration[005/008] Valid loss: 0.1871
2023-02-06 10:43:05 | Valid | Epoch[076/600] Iteration[006/008] Valid loss: 0.1872
2023-02-06 10:43:05 | Valid | Epoch[076/600] Iteration[007/008] Valid loss: 0.1870
2023-02-06 10:43:05 | Valid | Epoch[076/600] Iteration[008/008] Valid loss: 0.1888
2023-02-06 10:43:06 | Valid | Epoch[076/600] MIou: 0.48096558541949497
2023-02-06 10:43:06 | Valid | Epoch[076/600] Pixel Accuracy: 0.9140179951985677
2023-02-06 10:43:06 | Valid | Epoch[076/600] Mean Pixel Accuracy: 0.5241374298437492
2023-02-06 10:43:06 | Stage | Epoch[076/600] Train loss:0.0739
2023-02-06 10:43:06 | Stage | Epoch[076/600] Valid loss:0.1888
2023-02-06 10:43:06 | Stage | Epoch[076/600] LR:0.01

2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[001/030] Train loss: 0.0749
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[002/030] Train loss: 0.0746
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[003/030] Train loss: 0.0740
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[004/030] Train loss: 0.0744
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[005/030] Train loss: 0.0755
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[006/030] Train loss: 0.0752
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[007/030] Train loss: 0.0746
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[008/030] Train loss: 0.0743
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[009/030] Train loss: 0.0738
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[010/030] Train loss: 0.0737
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[011/030] Train loss: 0.0736
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[012/030] Train loss: 0.0732
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[013/030] Train loss: 0.0729
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[014/030] Train loss: 0.0728
2023-02-06 10:43:06 | Train | Epoch[077/600] Iteration[015/030] Train loss: 0.0727
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[016/030] Train loss: 0.0725
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[017/030] Train loss: 0.0724
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[018/030] Train loss: 0.0723
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[019/030] Train loss: 0.0723
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[020/030] Train loss: 0.0720
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[021/030] Train loss: 0.0721
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[022/030] Train loss: 0.0719
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[023/030] Train loss: 0.0719
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[024/030] Train loss: 0.0718
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[025/030] Train loss: 0.0718
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[026/030] Train loss: 0.0717
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[027/030] Train loss: 0.0715
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[028/030] Train loss: 0.0715
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[029/030] Train loss: 0.0715
2023-02-06 10:43:07 | Train | Epoch[077/600] Iteration[030/030] Train loss: 0.0715
2023-02-06 10:43:07 | Valid | Epoch[077/600] Iteration[001/008] Valid loss: 0.0910
2023-02-06 10:43:08 | Valid | Epoch[077/600] Iteration[002/008] Valid loss: 0.0832
2023-02-06 10:43:08 | Valid | Epoch[077/600] Iteration[003/008] Valid loss: 0.0814
2023-02-06 10:43:08 | Valid | Epoch[077/600] Iteration[004/008] Valid loss: 0.0805
2023-02-06 10:43:08 | Valid | Epoch[077/600] Iteration[005/008] Valid loss: 0.0812
2023-02-06 10:43:08 | Valid | Epoch[077/600] Iteration[006/008] Valid loss: 0.0811
2023-02-06 10:43:08 | Valid | Epoch[077/600] Iteration[007/008] Valid loss: 0.0829
2023-02-06 10:43:08 | Valid | Epoch[077/600] Iteration[008/008] Valid loss: 0.0821
2023-02-06 10:43:08 | Valid | Epoch[077/600] MIou: 0.9386454393324726
2023-02-06 10:43:08 | Valid | Epoch[077/600] Pixel Accuracy: 0.9894434611002604
2023-02-06 10:43:08 | Valid | Epoch[077/600] Mean Pixel Accuracy: 0.9646574192204285
2023-02-06 10:43:08 | Stage | Epoch[077/600] Train loss:0.0715
2023-02-06 10:43:08 | Stage | Epoch[077/600] Valid loss:0.0821
2023-02-06 10:43:08 | Stage | Epoch[077/600] LR:0.01

2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[001/030] Train loss: 0.0731
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[002/030] Train loss: 0.0722
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[003/030] Train loss: 0.0720
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[004/030] Train loss: 0.0721
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[005/030] Train loss: 0.0716
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[006/030] Train loss: 0.0717
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[007/030] Train loss: 0.0715
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[008/030] Train loss: 0.0712
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[009/030] Train loss: 0.0711
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[010/030] Train loss: 0.0709
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[011/030] Train loss: 0.0711
2023-02-06 10:43:08 | Train | Epoch[078/600] Iteration[012/030] Train loss: 0.0707
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[013/030] Train loss: 0.0704
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[014/030] Train loss: 0.0705
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[015/030] Train loss: 0.0703
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[016/030] Train loss: 0.0704
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[017/030] Train loss: 0.0706
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[018/030] Train loss: 0.0705
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[019/030] Train loss: 0.0704
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[020/030] Train loss: 0.0703
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[021/030] Train loss: 0.0703
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[022/030] Train loss: 0.0702
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[023/030] Train loss: 0.0702
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[024/030] Train loss: 0.0703
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[025/030] Train loss: 0.0703
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[026/030] Train loss: 0.0704
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[027/030] Train loss: 0.0705
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[028/030] Train loss: 0.0704
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[029/030] Train loss: 0.0705
2023-02-06 10:43:09 | Train | Epoch[078/600] Iteration[030/030] Train loss: 0.0705
2023-02-06 10:43:10 | Valid | Epoch[078/600] Iteration[001/008] Valid loss: 0.0940
2023-02-06 10:43:10 | Valid | Epoch[078/600] Iteration[002/008] Valid loss: 0.0937
2023-02-06 10:43:10 | Valid | Epoch[078/600] Iteration[003/008] Valid loss: 0.0948
2023-02-06 10:43:10 | Valid | Epoch[078/600] Iteration[004/008] Valid loss: 0.0943
2023-02-06 10:43:10 | Valid | Epoch[078/600] Iteration[005/008] Valid loss: 0.0948
2023-02-06 10:43:10 | Valid | Epoch[078/600] Iteration[006/008] Valid loss: 0.0940
2023-02-06 10:43:10 | Valid | Epoch[078/600] Iteration[007/008] Valid loss: 0.0927
2023-02-06 10:43:10 | Valid | Epoch[078/600] Iteration[008/008] Valid loss: 0.0934
2023-02-06 10:43:10 | Valid | Epoch[078/600] MIou: 0.8085276910538005
2023-02-06 10:43:10 | Valid | Epoch[078/600] Pixel Accuracy: 0.9684333801269531
2023-02-06 10:43:10 | Valid | Epoch[078/600] Mean Pixel Accuracy: 0.8253742435768578
2023-02-06 10:43:10 | Stage | Epoch[078/600] Train loss:0.0705
2023-02-06 10:43:10 | Stage | Epoch[078/600] Valid loss:0.0934
2023-02-06 10:43:10 | Stage | Epoch[078/600] LR:0.01

2023-02-06 10:43:10 | Train | Epoch[079/600] Iteration[001/030] Train loss: 0.0697
2023-02-06 10:43:10 | Train | Epoch[079/600] Iteration[002/030] Train loss: 0.0685
2023-02-06 10:43:10 | Train | Epoch[079/600] Iteration[003/030] Train loss: 0.0692
2023-02-06 10:43:10 | Train | Epoch[079/600] Iteration[004/030] Train loss: 0.0696
2023-02-06 10:43:10 | Train | Epoch[079/600] Iteration[005/030] Train loss: 0.0697
2023-02-06 10:43:10 | Train | Epoch[079/600] Iteration[006/030] Train loss: 0.0693
2023-02-06 10:43:10 | Train | Epoch[079/600] Iteration[007/030] Train loss: 0.0694
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[008/030] Train loss: 0.0698
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[009/030] Train loss: 0.0699
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[010/030] Train loss: 0.0695
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[011/030] Train loss: 0.0691
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[012/030] Train loss: 0.0691
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[013/030] Train loss: 0.0690
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[014/030] Train loss: 0.0690
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[015/030] Train loss: 0.0691
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[016/030] Train loss: 0.0693
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[017/030] Train loss: 0.0692
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[018/030] Train loss: 0.0690
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[019/030] Train loss: 0.0691
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[020/030] Train loss: 0.0691
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[021/030] Train loss: 0.0690
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[022/030] Train loss: 0.0690
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[023/030] Train loss: 0.0689
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[024/030] Train loss: 0.0690
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[025/030] Train loss: 0.0690
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[026/030] Train loss: 0.0691
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[027/030] Train loss: 0.0690
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[028/030] Train loss: 0.0690
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[029/030] Train loss: 0.0692
2023-02-06 10:43:11 | Train | Epoch[079/600] Iteration[030/030] Train loss: 0.0692
2023-02-06 10:43:12 | Valid | Epoch[079/600] Iteration[001/008] Valid loss: 0.5485
2023-02-06 10:43:12 | Valid | Epoch[079/600] Iteration[002/008] Valid loss: 0.5018
2023-02-06 10:43:12 | Valid | Epoch[079/600] Iteration[003/008] Valid loss: 0.4970
2023-02-06 10:43:12 | Valid | Epoch[079/600] Iteration[004/008] Valid loss: 0.5013
2023-02-06 10:43:12 | Valid | Epoch[079/600] Iteration[005/008] Valid loss: 0.5179
2023-02-06 10:43:12 | Valid | Epoch[079/600] Iteration[006/008] Valid loss: 0.5104
2023-02-06 10:43:12 | Valid | Epoch[079/600] Iteration[007/008] Valid loss: 0.5392
2023-02-06 10:43:12 | Valid | Epoch[079/600] Iteration[008/008] Valid loss: 0.5513
2023-02-06 10:43:12 | Valid | Epoch[079/600] MIou: 0.8363151584977926
2023-02-06 10:43:12 | Valid | Epoch[079/600] Pixel Accuracy: 0.9637908935546875
2023-02-06 10:43:12 | Valid | Epoch[079/600] Mean Pixel Accuracy: 0.9769910997756975
2023-02-06 10:43:12 | Stage | Epoch[079/600] Train loss:0.0692
2023-02-06 10:43:12 | Stage | Epoch[079/600] Valid loss:0.5513
2023-02-06 10:43:12 | Stage | Epoch[079/600] LR:0.01

2023-02-06 10:43:12 | Train | Epoch[080/600] Iteration[001/030] Train loss: 0.0672
2023-02-06 10:43:12 | Train | Epoch[080/600] Iteration[002/030] Train loss: 0.0680
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[003/030] Train loss: 0.0675
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[004/030] Train loss: 0.0684
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[005/030] Train loss: 0.0693
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[006/030] Train loss: 0.0695
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[007/030] Train loss: 0.0694
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[008/030] Train loss: 0.0694
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[009/030] Train loss: 0.0692
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[010/030] Train loss: 0.0693
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[011/030] Train loss: 0.0691
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[012/030] Train loss: 0.0694
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[013/030] Train loss: 0.0694
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[014/030] Train loss: 0.0694
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[015/030] Train loss: 0.0693
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[016/030] Train loss: 0.0696
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[017/030] Train loss: 0.0696
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[018/030] Train loss: 0.0694
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[019/030] Train loss: 0.0691
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[020/030] Train loss: 0.0692
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[021/030] Train loss: 0.0694
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[022/030] Train loss: 0.0694
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[023/030] Train loss: 0.0695
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[024/030] Train loss: 0.0693
2023-02-06 10:43:13 | Train | Epoch[080/600] Iteration[025/030] Train loss: 0.0696
2023-02-06 10:43:14 | Train | Epoch[080/600] Iteration[026/030] Train loss: 0.0700
2023-02-06 10:43:14 | Train | Epoch[080/600] Iteration[027/030] Train loss: 0.0700
2023-02-06 10:43:14 | Train | Epoch[080/600] Iteration[028/030] Train loss: 0.0700
2023-02-06 10:43:14 | Train | Epoch[080/600] Iteration[029/030] Train loss: 0.0700
2023-02-06 10:43:14 | Train | Epoch[080/600] Iteration[030/030] Train loss: 0.0700
2023-02-06 10:43:14 | Valid | Epoch[080/600] Iteration[001/008] Valid loss: 35.2381
2023-02-06 10:43:14 | Valid | Epoch[080/600] Iteration[002/008] Valid loss: 35.1133
2023-02-06 10:43:14 | Valid | Epoch[080/600] Iteration[003/008] Valid loss: 35.2822
2023-02-06 10:43:14 | Valid | Epoch[080/600] Iteration[004/008] Valid loss: 34.8761
2023-02-06 10:43:14 | Valid | Epoch[080/600] Iteration[005/008] Valid loss: 34.4859
2023-02-06 10:43:14 | Valid | Epoch[080/600] Iteration[006/008] Valid loss: 33.6942
2023-02-06 10:43:14 | Valid | Epoch[080/600] Iteration[007/008] Valid loss: 33.3970
2023-02-06 10:43:14 | Valid | Epoch[080/600] Iteration[008/008] Valid loss: 33.8032
2023-02-06 10:43:14 | Valid | Epoch[080/600] MIou: 0.1271212573748449
2023-02-06 10:43:14 | Valid | Epoch[080/600] Pixel Accuracy: 0.2264887491861979
2023-02-06 10:43:14 | Valid | Epoch[080/600] Mean Pixel Accuracy: 0.5746803748364627
2023-02-06 10:43:14 | Stage | Epoch[080/600] Train loss:0.0700
2023-02-06 10:43:14 | Stage | Epoch[080/600] Valid loss:33.8032
2023-02-06 10:43:14 | Stage | Epoch[080/600] LR:0.01

2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[001/030] Train loss: 0.0714
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[002/030] Train loss: 0.0710
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[003/030] Train loss: 0.0714
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[004/030] Train loss: 0.0719
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[005/030] Train loss: 0.0727
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[006/030] Train loss: 0.0742
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[007/030] Train loss: 0.0738
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[008/030] Train loss: 0.0741
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[009/030] Train loss: 0.0737
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[010/030] Train loss: 0.0733
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[011/030] Train loss: 0.0733
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[012/030] Train loss: 0.0732
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[013/030] Train loss: 0.0729
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[014/030] Train loss: 0.0730
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[015/030] Train loss: 0.0728
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[016/030] Train loss: 0.0727
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[017/030] Train loss: 0.0727
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[018/030] Train loss: 0.0725
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[019/030] Train loss: 0.0722
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[020/030] Train loss: 0.0718
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[021/030] Train loss: 0.0718
2023-02-06 10:43:15 | Train | Epoch[081/600] Iteration[022/030] Train loss: 0.0718
2023-02-06 10:43:16 | Train | Epoch[081/600] Iteration[023/030] Train loss: 0.0717
2023-02-06 10:43:16 | Train | Epoch[081/600] Iteration[024/030] Train loss: 0.0717
2023-02-06 10:43:16 | Train | Epoch[081/600] Iteration[025/030] Train loss: 0.0718
2023-02-06 10:43:16 | Train | Epoch[081/600] Iteration[026/030] Train loss: 0.0717
2023-02-06 10:43:16 | Train | Epoch[081/600] Iteration[027/030] Train loss: 0.0716
2023-02-06 10:43:16 | Train | Epoch[081/600] Iteration[028/030] Train loss: 0.0714
2023-02-06 10:43:16 | Train | Epoch[081/600] Iteration[029/030] Train loss: 0.0713
2023-02-06 10:43:16 | Train | Epoch[081/600] Iteration[030/030] Train loss: 0.0712
2023-02-06 10:43:16 | Valid | Epoch[081/600] Iteration[001/008] Valid loss: 0.1693
2023-02-06 10:43:16 | Valid | Epoch[081/600] Iteration[002/008] Valid loss: 0.1649
2023-02-06 10:43:16 | Valid | Epoch[081/600] Iteration[003/008] Valid loss: 0.1676
2023-02-06 10:43:16 | Valid | Epoch[081/600] Iteration[004/008] Valid loss: 0.1690
2023-02-06 10:43:16 | Valid | Epoch[081/600] Iteration[005/008] Valid loss: 0.1700
2023-02-06 10:43:16 | Valid | Epoch[081/600] Iteration[006/008] Valid loss: 0.1698
2023-02-06 10:43:16 | Valid | Epoch[081/600] Iteration[007/008] Valid loss: 0.1694
2023-02-06 10:43:16 | Valid | Epoch[081/600] Iteration[008/008] Valid loss: 0.1708
2023-02-06 10:43:16 | Valid | Epoch[081/600] MIou: 0.4933859201031611
2023-02-06 10:43:16 | Valid | Epoch[081/600] Pixel Accuracy: 0.9160868326822916
2023-02-06 10:43:16 | Valid | Epoch[081/600] Mean Pixel Accuracy: 0.5356095197232786
2023-02-06 10:43:16 | Stage | Epoch[081/600] Train loss:0.0712
2023-02-06 10:43:16 | Stage | Epoch[081/600] Valid loss:0.1708
2023-02-06 10:43:16 | Stage | Epoch[081/600] LR:0.01

2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[001/030] Train loss: 0.0726
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[002/030] Train loss: 0.0688
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[003/030] Train loss: 0.0688
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[004/030] Train loss: 0.0676
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[005/030] Train loss: 0.0686
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[006/030] Train loss: 0.0684
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[007/030] Train loss: 0.0691
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[008/030] Train loss: 0.0690
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[009/030] Train loss: 0.0689
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[010/030] Train loss: 0.0687
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[011/030] Train loss: 0.0688
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[012/030] Train loss: 0.0686
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[013/030] Train loss: 0.0684
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[014/030] Train loss: 0.0685
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[015/030] Train loss: 0.0681
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[016/030] Train loss: 0.0679
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[017/030] Train loss: 0.0678
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[018/030] Train loss: 0.0677
2023-02-06 10:43:17 | Train | Epoch[082/600] Iteration[019/030] Train loss: 0.0679
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[020/030] Train loss: 0.0678
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[021/030] Train loss: 0.0677
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[022/030] Train loss: 0.0677
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[023/030] Train loss: 0.0676
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[024/030] Train loss: 0.0675
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[025/030] Train loss: 0.0673
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[026/030] Train loss: 0.0673
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[027/030] Train loss: 0.0672
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[028/030] Train loss: 0.0672
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[029/030] Train loss: 0.0670
2023-02-06 10:43:18 | Train | Epoch[082/600] Iteration[030/030] Train loss: 0.0670
2023-02-06 10:43:18 | Valid | Epoch[082/600] Iteration[001/008] Valid loss: 0.0741
2023-02-06 10:43:18 | Valid | Epoch[082/600] Iteration[002/008] Valid loss: 0.0718
2023-02-06 10:43:18 | Valid | Epoch[082/600] Iteration[003/008] Valid loss: 0.0720
2023-02-06 10:43:18 | Valid | Epoch[082/600] Iteration[004/008] Valid loss: 0.0712
2023-02-06 10:43:18 | Valid | Epoch[082/600] Iteration[005/008] Valid loss: 0.0716
2023-02-06 10:43:18 | Valid | Epoch[082/600] Iteration[006/008] Valid loss: 0.0714
2023-02-06 10:43:18 | Valid | Epoch[082/600] Iteration[007/008] Valid loss: 0.0716
2023-02-06 10:43:18 | Valid | Epoch[082/600] Iteration[008/008] Valid loss: 0.0716
2023-02-06 10:43:19 | Valid | Epoch[082/600] MIou: 0.8955910856615354
2023-02-06 10:43:19 | Valid | Epoch[082/600] Pixel Accuracy: 0.9827092488606771
2023-02-06 10:43:19 | Valid | Epoch[082/600] Mean Pixel Accuracy: 0.907334641388689
2023-02-06 10:43:19 | Stage | Epoch[082/600] Train loss:0.0670
2023-02-06 10:43:19 | Stage | Epoch[082/600] Valid loss:0.0716
2023-02-06 10:43:19 | Stage | Epoch[082/600] LR:0.01

2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[001/030] Train loss: 0.0681
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[002/030] Train loss: 0.0667
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[003/030] Train loss: 0.0680
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[004/030] Train loss: 0.0674
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[005/030] Train loss: 0.0672
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[006/030] Train loss: 0.0670
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[007/030] Train loss: 0.0668
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[008/030] Train loss: 0.0668
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[009/030] Train loss: 0.0666
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[010/030] Train loss: 0.0664
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[011/030] Train loss: 0.0664
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[012/030] Train loss: 0.0661
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[013/030] Train loss: 0.0660
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[014/030] Train loss: 0.0660
2023-02-06 10:43:19 | Train | Epoch[083/600] Iteration[015/030] Train loss: 0.0660
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[016/030] Train loss: 0.0658
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[017/030] Train loss: 0.0656
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[018/030] Train loss: 0.0656
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[019/030] Train loss: 0.0654
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[020/030] Train loss: 0.0653
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[021/030] Train loss: 0.0654
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[022/030] Train loss: 0.0653
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[023/030] Train loss: 0.0654
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[024/030] Train loss: 0.0653
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[025/030] Train loss: 0.0653
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[026/030] Train loss: 0.0655
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[027/030] Train loss: 0.0653
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[028/030] Train loss: 0.0654
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[029/030] Train loss: 0.0655
2023-02-06 10:43:20 | Train | Epoch[083/600] Iteration[030/030] Train loss: 0.0655
2023-02-06 10:43:20 | Valid | Epoch[083/600] Iteration[001/008] Valid loss: 0.2205
2023-02-06 10:43:20 | Valid | Epoch[083/600] Iteration[002/008] Valid loss: 0.1824
2023-02-06 10:43:20 | Valid | Epoch[083/600] Iteration[003/008] Valid loss: 0.1762
2023-02-06 10:43:21 | Valid | Epoch[083/600] Iteration[004/008] Valid loss: 0.1769
2023-02-06 10:43:21 | Valid | Epoch[083/600] Iteration[005/008] Valid loss: 0.1827
2023-02-06 10:43:21 | Valid | Epoch[083/600] Iteration[006/008] Valid loss: 0.1814
2023-02-06 10:43:21 | Valid | Epoch[083/600] Iteration[007/008] Valid loss: 0.1924
2023-02-06 10:43:21 | Valid | Epoch[083/600] Iteration[008/008] Valid loss: 0.1914
2023-02-06 10:43:21 | Valid | Epoch[083/600] MIou: 0.8948369602943445
2023-02-06 10:43:21 | Valid | Epoch[083/600] Pixel Accuracy: 0.97943115234375
2023-02-06 10:43:21 | Valid | Epoch[083/600] Mean Pixel Accuracy: 0.982056010414842
2023-02-06 10:43:21 | Stage | Epoch[083/600] Train loss:0.0655
2023-02-06 10:43:21 | Stage | Epoch[083/600] Valid loss:0.1914
2023-02-06 10:43:21 | Stage | Epoch[083/600] LR:0.01

2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[001/030] Train loss: 0.0691
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[002/030] Train loss: 0.0673
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[003/030] Train loss: 0.0663
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[004/030] Train loss: 0.0669
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[005/030] Train loss: 0.0665
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[006/030] Train loss: 0.0662
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[007/030] Train loss: 0.0656
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[008/030] Train loss: 0.0649
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[009/030] Train loss: 0.0653
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[010/030] Train loss: 0.0652
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[011/030] Train loss: 0.0652
2023-02-06 10:43:21 | Train | Epoch[084/600] Iteration[012/030] Train loss: 0.0648
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[013/030] Train loss: 0.0646
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[014/030] Train loss: 0.0647
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[015/030] Train loss: 0.0646
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[016/030] Train loss: 0.0648
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[017/030] Train loss: 0.0650
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[018/030] Train loss: 0.0648
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[019/030] Train loss: 0.0646
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[020/030] Train loss: 0.0646
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[021/030] Train loss: 0.0646
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[022/030] Train loss: 0.0646
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[023/030] Train loss: 0.0645
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[024/030] Train loss: 0.0646
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[025/030] Train loss: 0.0647
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[026/030] Train loss: 0.0647
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[027/030] Train loss: 0.0646
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[028/030] Train loss: 0.0645
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[029/030] Train loss: 0.0645
2023-02-06 10:43:22 | Train | Epoch[084/600] Iteration[030/030] Train loss: 0.0645
2023-02-06 10:43:23 | Valid | Epoch[084/600] Iteration[001/008] Valid loss: 0.5726
2023-02-06 10:43:23 | Valid | Epoch[084/600] Iteration[002/008] Valid loss: 0.5291
2023-02-06 10:43:23 | Valid | Epoch[084/600] Iteration[003/008] Valid loss: 0.5309
2023-02-06 10:43:23 | Valid | Epoch[084/600] Iteration[004/008] Valid loss: 0.5365
2023-02-06 10:43:23 | Valid | Epoch[084/600] Iteration[005/008] Valid loss: 0.5582
2023-02-06 10:43:23 | Valid | Epoch[084/600] Iteration[006/008] Valid loss: 0.5427
2023-02-06 10:43:23 | Valid | Epoch[084/600] Iteration[007/008] Valid loss: 0.5685
2023-02-06 10:43:23 | Valid | Epoch[084/600] Iteration[008/008] Valid loss: 0.5874
2023-02-06 10:43:23 | Valid | Epoch[084/600] MIou: 0.8337525091339995
2023-02-06 10:43:23 | Valid | Epoch[084/600] Pixel Accuracy: 0.963049570719401
2023-02-06 10:43:23 | Valid | Epoch[084/600] Mean Pixel Accuracy: 0.976272954024678
2023-02-06 10:43:23 | Stage | Epoch[084/600] Train loss:0.0645
2023-02-06 10:43:23 | Stage | Epoch[084/600] Valid loss:0.5874
2023-02-06 10:43:23 | Stage | Epoch[084/600] LR:0.01

2023-02-06 10:43:23 | Train | Epoch[085/600] Iteration[001/030] Train loss: 0.0626
2023-02-06 10:43:23 | Train | Epoch[085/600] Iteration[002/030] Train loss: 0.0628
2023-02-06 10:43:23 | Train | Epoch[085/600] Iteration[003/030] Train loss: 0.0644
2023-02-06 10:43:23 | Train | Epoch[085/600] Iteration[004/030] Train loss: 0.0635
2023-02-06 10:43:23 | Train | Epoch[085/600] Iteration[005/030] Train loss: 0.0637
2023-02-06 10:43:23 | Train | Epoch[085/600] Iteration[006/030] Train loss: 0.0638
2023-02-06 10:43:23 | Train | Epoch[085/600] Iteration[007/030] Train loss: 0.0637
2023-02-06 10:43:23 | Train | Epoch[085/600] Iteration[008/030] Train loss: 0.0631
2023-02-06 10:43:23 | Train | Epoch[085/600] Iteration[009/030] Train loss: 0.0630
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[010/030] Train loss: 0.0632
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[011/030] Train loss: 0.0632
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[012/030] Train loss: 0.0633
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[013/030] Train loss: 0.0634
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[014/030] Train loss: 0.0637
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[015/030] Train loss: 0.0635
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[016/030] Train loss: 0.0637
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[017/030] Train loss: 0.0634
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[018/030] Train loss: 0.0635
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[019/030] Train loss: 0.0635
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[020/030] Train loss: 0.0633
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[021/030] Train loss: 0.0636
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[022/030] Train loss: 0.0635
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[023/030] Train loss: 0.0635
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[024/030] Train loss: 0.0636
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[025/030] Train loss: 0.0636
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[026/030] Train loss: 0.0634
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[027/030] Train loss: 0.0636
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[028/030] Train loss: 0.0637
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[029/030] Train loss: 0.0636
2023-02-06 10:43:24 | Train | Epoch[085/600] Iteration[030/030] Train loss: 0.0635
2023-02-06 10:43:25 | Valid | Epoch[085/600] Iteration[001/008] Valid loss: 0.0845
2023-02-06 10:43:25 | Valid | Epoch[085/600] Iteration[002/008] Valid loss: 0.0849
2023-02-06 10:43:25 | Valid | Epoch[085/600] Iteration[003/008] Valid loss: 0.0863
2023-02-06 10:43:25 | Valid | Epoch[085/600] Iteration[004/008] Valid loss: 0.0857
2023-02-06 10:43:25 | Valid | Epoch[085/600] Iteration[005/008] Valid loss: 0.0863
2023-02-06 10:43:25 | Valid | Epoch[085/600] Iteration[006/008] Valid loss: 0.0856
2023-02-06 10:43:25 | Valid | Epoch[085/600] Iteration[007/008] Valid loss: 0.0846
2023-02-06 10:43:25 | Valid | Epoch[085/600] Iteration[008/008] Valid loss: 0.0857
2023-02-06 10:43:25 | Valid | Epoch[085/600] MIou: 0.7940541163488477
2023-02-06 10:43:25 | Valid | Epoch[085/600] Pixel Accuracy: 0.9660479227701823
2023-02-06 10:43:25 | Valid | Epoch[085/600] Mean Pixel Accuracy: 0.8120479009608896
2023-02-06 10:43:25 | Stage | Epoch[085/600] Train loss:0.0635
2023-02-06 10:43:25 | Stage | Epoch[085/600] Valid loss:0.0857
2023-02-06 10:43:25 | Stage | Epoch[085/600] LR:0.01

2023-02-06 10:43:25 | Train | Epoch[086/600] Iteration[001/030] Train loss: 0.0643
2023-02-06 10:43:25 | Train | Epoch[086/600] Iteration[002/030] Train loss: 0.0629
2023-02-06 10:43:25 | Train | Epoch[086/600] Iteration[003/030] Train loss: 0.0636
2023-02-06 10:43:25 | Train | Epoch[086/600] Iteration[004/030] Train loss: 0.0630
2023-02-06 10:43:25 | Train | Epoch[086/600] Iteration[005/030] Train loss: 0.0629
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[006/030] Train loss: 0.0626
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[007/030] Train loss: 0.0625
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[008/030] Train loss: 0.0626
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[009/030] Train loss: 0.0626
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[010/030] Train loss: 0.0627
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[011/030] Train loss: 0.0630
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[012/030] Train loss: 0.0630
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[013/030] Train loss: 0.0628
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[014/030] Train loss: 0.0627
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[015/030] Train loss: 0.0626
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[016/030] Train loss: 0.0625
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[017/030] Train loss: 0.0625
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[018/030] Train loss: 0.0625
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[019/030] Train loss: 0.0626
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[020/030] Train loss: 0.0628
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[021/030] Train loss: 0.0629
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[022/030] Train loss: 0.0628
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[023/030] Train loss: 0.0628
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[024/030] Train loss: 0.0629
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[025/030] Train loss: 0.0627
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[026/030] Train loss: 0.0627
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[027/030] Train loss: 0.0627
2023-02-06 10:43:26 | Train | Epoch[086/600] Iteration[028/030] Train loss: 0.0629
2023-02-06 10:43:27 | Train | Epoch[086/600] Iteration[029/030] Train loss: 0.0629
2023-02-06 10:43:27 | Train | Epoch[086/600] Iteration[030/030] Train loss: 0.0629
2023-02-06 10:43:27 | Valid | Epoch[086/600] Iteration[001/008] Valid loss: 0.0849
2023-02-06 10:43:27 | Valid | Epoch[086/600] Iteration[002/008] Valid loss: 0.0763
2023-02-06 10:43:27 | Valid | Epoch[086/600] Iteration[003/008] Valid loss: 0.0749
2023-02-06 10:43:27 | Valid | Epoch[086/600] Iteration[004/008] Valid loss: 0.0741
2023-02-06 10:43:27 | Valid | Epoch[086/600] Iteration[005/008] Valid loss: 0.0752
2023-02-06 10:43:27 | Valid | Epoch[086/600] Iteration[006/008] Valid loss: 0.0745
2023-02-06 10:43:27 | Valid | Epoch[086/600] Iteration[007/008] Valid loss: 0.0763
2023-02-06 10:43:27 | Valid | Epoch[086/600] Iteration[008/008] Valid loss: 0.0757
2023-02-06 10:43:27 | Valid | Epoch[086/600] MIou: 0.9376251105630558
2023-02-06 10:43:27 | Valid | Epoch[086/600] Pixel Accuracy: 0.9892412821451823
2023-02-06 10:43:27 | Valid | Epoch[086/600] Mean Pixel Accuracy: 0.9648379547335493
2023-02-06 10:43:27 | Stage | Epoch[086/600] Train loss:0.0629
2023-02-06 10:43:27 | Stage | Epoch[086/600] Valid loss:0.0757
2023-02-06 10:43:27 | Stage | Epoch[086/600] LR:0.01

2023-02-06 10:43:27 | Train | Epoch[087/600] Iteration[001/030] Train loss: 0.0627
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[002/030] Train loss: 0.0615
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[003/030] Train loss: 0.0617
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[004/030] Train loss: 0.0621
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[005/030] Train loss: 0.0629
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[006/030] Train loss: 0.0633
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[007/030] Train loss: 0.0633
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[008/030] Train loss: 0.0633
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[009/030] Train loss: 0.0628
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[010/030] Train loss: 0.0635
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[011/030] Train loss: 0.0631
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[012/030] Train loss: 0.0628
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[013/030] Train loss: 0.0629
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[014/030] Train loss: 0.0631
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[015/030] Train loss: 0.0628
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[016/030] Train loss: 0.0627
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[017/030] Train loss: 0.0628
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[018/030] Train loss: 0.0630
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[019/030] Train loss: 0.0627
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[020/030] Train loss: 0.0627
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[021/030] Train loss: 0.0629
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[022/030] Train loss: 0.0629
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[023/030] Train loss: 0.0630
2023-02-06 10:43:28 | Train | Epoch[087/600] Iteration[024/030] Train loss: 0.0630
2023-02-06 10:43:29 | Train | Epoch[087/600] Iteration[025/030] Train loss: 0.0630
2023-02-06 10:43:29 | Train | Epoch[087/600] Iteration[026/030] Train loss: 0.0631
2023-02-06 10:43:29 | Train | Epoch[087/600] Iteration[027/030] Train loss: 0.0630
2023-02-06 10:43:29 | Train | Epoch[087/600] Iteration[028/030] Train loss: 0.0630
2023-02-06 10:43:29 | Train | Epoch[087/600] Iteration[029/030] Train loss: 0.0630
2023-02-06 10:43:29 | Train | Epoch[087/600] Iteration[030/030] Train loss: 0.0632
2023-02-06 10:43:29 | Valid | Epoch[087/600] Iteration[001/008] Valid loss: 0.0944
2023-02-06 10:43:29 | Valid | Epoch[087/600] Iteration[002/008] Valid loss: 0.0944
2023-02-06 10:43:29 | Valid | Epoch[087/600] Iteration[003/008] Valid loss: 0.0960
2023-02-06 10:43:29 | Valid | Epoch[087/600] Iteration[004/008] Valid loss: 0.0957
2023-02-06 10:43:29 | Valid | Epoch[087/600] Iteration[005/008] Valid loss: 0.0962
2023-02-06 10:43:29 | Valid | Epoch[087/600] Iteration[006/008] Valid loss: 0.0951
2023-02-06 10:43:29 | Valid | Epoch[087/600] Iteration[007/008] Valid loss: 0.0938
2023-02-06 10:43:29 | Valid | Epoch[087/600] Iteration[008/008] Valid loss: 0.0949
2023-02-06 10:43:29 | Valid | Epoch[087/600] MIou: 0.7697095010034039
2023-02-06 10:43:29 | Valid | Epoch[087/600] Pixel Accuracy: 0.9620208740234375
2023-02-06 10:43:29 | Valid | Epoch[087/600] Mean Pixel Accuracy: 0.7897478494699348
2023-02-06 10:43:29 | Stage | Epoch[087/600] Train loss:0.0632
2023-02-06 10:43:29 | Stage | Epoch[087/600] Valid loss:0.0949
2023-02-06 10:43:29 | Stage | Epoch[087/600] LR:0.01

2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[001/030] Train loss: 0.0596
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[002/030] Train loss: 0.0631
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[003/030] Train loss: 0.0634
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[004/030] Train loss: 0.0629
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[005/030] Train loss: 0.0627
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[006/030] Train loss: 0.0624
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[007/030] Train loss: 0.0619
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[008/030] Train loss: 0.0615
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[009/030] Train loss: 0.0617
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[010/030] Train loss: 0.0615
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[011/030] Train loss: 0.0615
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[012/030] Train loss: 0.0614
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[013/030] Train loss: 0.0614
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[014/030] Train loss: 0.0613
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[015/030] Train loss: 0.0617
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[016/030] Train loss: 0.0616
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[017/030] Train loss: 0.0616
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[018/030] Train loss: 0.0614
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[019/030] Train loss: 0.0613
2023-02-06 10:43:30 | Train | Epoch[088/600] Iteration[020/030] Train loss: 0.0611
2023-02-06 10:43:31 | Train | Epoch[088/600] Iteration[021/030] Train loss: 0.0611
2023-02-06 10:43:31 | Train | Epoch[088/600] Iteration[022/030] Train loss: 0.0611
2023-02-06 10:43:31 | Train | Epoch[088/600] Iteration[023/030] Train loss: 0.0611
2023-02-06 10:43:31 | Train | Epoch[088/600] Iteration[024/030] Train loss: 0.0612
2023-02-06 10:43:31 | Train | Epoch[088/600] Iteration[025/030] Train loss: 0.0611
2023-02-06 10:43:31 | Train | Epoch[088/600] Iteration[026/030] Train loss: 0.0612
2023-02-06 10:43:31 | Train | Epoch[088/600] Iteration[027/030] Train loss: 0.0611
2023-02-06 10:43:31 | Train | Epoch[088/600] Iteration[028/030] Train loss: 0.0612
2023-02-06 10:43:31 | Train | Epoch[088/600] Iteration[029/030] Train loss: 0.0612
2023-02-06 10:43:31 | Train | Epoch[088/600] Iteration[030/030] Train loss: 0.0611
2023-02-06 10:43:31 | Valid | Epoch[088/600] Iteration[001/008] Valid loss: 0.0706
2023-02-06 10:43:31 | Valid | Epoch[088/600] Iteration[002/008] Valid loss: 0.0686
2023-02-06 10:43:31 | Valid | Epoch[088/600] Iteration[003/008] Valid loss: 0.0684
2023-02-06 10:43:31 | Valid | Epoch[088/600] Iteration[004/008] Valid loss: 0.0678
2023-02-06 10:43:31 | Valid | Epoch[088/600] Iteration[005/008] Valid loss: 0.0679
2023-02-06 10:43:31 | Valid | Epoch[088/600] Iteration[006/008] Valid loss: 0.0682
2023-02-06 10:43:31 | Valid | Epoch[088/600] Iteration[007/008] Valid loss: 0.0678
2023-02-06 10:43:31 | Valid | Epoch[088/600] Iteration[008/008] Valid loss: 0.0679
2023-02-06 10:43:32 | Valid | Epoch[088/600] MIou: 0.8822627812757147
2023-02-06 10:43:32 | Valid | Epoch[088/600] Pixel Accuracy: 0.9805742899576823
2023-02-06 10:43:32 | Valid | Epoch[088/600] Mean Pixel Accuracy: 0.8935499790842814
2023-02-06 10:43:32 | Stage | Epoch[088/600] Train loss:0.0611
2023-02-06 10:43:32 | Stage | Epoch[088/600] Valid loss:0.0679
2023-02-06 10:43:32 | Stage | Epoch[088/600] LR:0.01

2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[001/030] Train loss: 0.0590
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[002/030] Train loss: 0.0603
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[003/030] Train loss: 0.0605
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[004/030] Train loss: 0.0611
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[005/030] Train loss: 0.0612
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[006/030] Train loss: 0.0610
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[007/030] Train loss: 0.0609
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[008/030] Train loss: 0.0609
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[009/030] Train loss: 0.0611
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[010/030] Train loss: 0.0610
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[011/030] Train loss: 0.0607
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[012/030] Train loss: 0.0607
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[013/030] Train loss: 0.0606
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[014/030] Train loss: 0.0608
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[015/030] Train loss: 0.0608
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[016/030] Train loss: 0.0605
2023-02-06 10:43:32 | Train | Epoch[089/600] Iteration[017/030] Train loss: 0.0605
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[018/030] Train loss: 0.0604
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[019/030] Train loss: 0.0605
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[020/030] Train loss: 0.0605
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[021/030] Train loss: 0.0603
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[022/030] Train loss: 0.0604
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[023/030] Train loss: 0.0606
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[024/030] Train loss: 0.0605
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[025/030] Train loss: 0.0605
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[026/030] Train loss: 0.0604
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[027/030] Train loss: 0.0605
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[028/030] Train loss: 0.0605
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[029/030] Train loss: 0.0605
2023-02-06 10:43:33 | Train | Epoch[089/600] Iteration[030/030] Train loss: 0.0604
2023-02-06 10:43:33 | Valid | Epoch[089/600] Iteration[001/008] Valid loss: 0.3630
2023-02-06 10:43:33 | Valid | Epoch[089/600] Iteration[002/008] Valid loss: 0.3047
2023-02-06 10:43:33 | Valid | Epoch[089/600] Iteration[003/008] Valid loss: 0.2982
2023-02-06 10:43:34 | Valid | Epoch[089/600] Iteration[004/008] Valid loss: 0.2997
2023-02-06 10:43:34 | Valid | Epoch[089/600] Iteration[005/008] Valid loss: 0.3117
2023-02-06 10:43:34 | Valid | Epoch[089/600] Iteration[006/008] Valid loss: 0.3047
2023-02-06 10:43:34 | Valid | Epoch[089/600] Iteration[007/008] Valid loss: 0.3213
2023-02-06 10:43:34 | Valid | Epoch[089/600] Iteration[008/008] Valid loss: 0.3228
2023-02-06 10:43:34 | Valid | Epoch[089/600] MIou: 0.8611621373082994
2023-02-06 10:43:34 | Valid | Epoch[089/600] Pixel Accuracy: 0.9708480834960938
2023-02-06 10:43:34 | Valid | Epoch[089/600] Mean Pixel Accuracy: 0.9799823663376747
2023-02-06 10:43:34 | Stage | Epoch[089/600] Train loss:0.0604
2023-02-06 10:43:34 | Stage | Epoch[089/600] Valid loss:0.3228
2023-02-06 10:43:34 | Stage | Epoch[089/600] LR:0.01

2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[001/030] Train loss: 0.0570
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[002/030] Train loss: 0.0621
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[003/030] Train loss: 0.0622
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[004/030] Train loss: 0.0606
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[005/030] Train loss: 0.0609
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[006/030] Train loss: 0.0610
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[007/030] Train loss: 0.0607
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[008/030] Train loss: 0.0606
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[009/030] Train loss: 0.0607
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[010/030] Train loss: 0.0608
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[011/030] Train loss: 0.0607
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[012/030] Train loss: 0.0610
2023-02-06 10:43:34 | Train | Epoch[090/600] Iteration[013/030] Train loss: 0.0611
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[014/030] Train loss: 0.0611
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[015/030] Train loss: 0.0615
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[016/030] Train loss: 0.0615
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[017/030] Train loss: 0.0615
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[018/030] Train loss: 0.0615
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[019/030] Train loss: 0.0615
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[020/030] Train loss: 0.0615
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[021/030] Train loss: 0.0615
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[022/030] Train loss: 0.0615
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[023/030] Train loss: 0.0614
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[024/030] Train loss: 0.0613
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[025/030] Train loss: 0.0613
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[026/030] Train loss: 0.0613
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[027/030] Train loss: 0.0611
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[028/030] Train loss: 0.0610
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[029/030] Train loss: 0.0609
2023-02-06 10:43:35 | Train | Epoch[090/600] Iteration[030/030] Train loss: 0.0609
2023-02-06 10:43:36 | Valid | Epoch[090/600] Iteration[001/008] Valid loss: 0.0763
2023-02-06 10:43:36 | Valid | Epoch[090/600] Iteration[002/008] Valid loss: 0.0759
2023-02-06 10:43:36 | Valid | Epoch[090/600] Iteration[003/008] Valid loss: 0.0766
2023-02-06 10:43:36 | Valid | Epoch[090/600] Iteration[004/008] Valid loss: 0.0761
2023-02-06 10:43:36 | Valid | Epoch[090/600] Iteration[005/008] Valid loss: 0.0766
2023-02-06 10:43:36 | Valid | Epoch[090/600] Iteration[006/008] Valid loss: 0.0757
2023-02-06 10:43:36 | Valid | Epoch[090/600] Iteration[007/008] Valid loss: 0.0750
2023-02-06 10:43:36 | Valid | Epoch[090/600] Iteration[008/008] Valid loss: 0.0756
2023-02-06 10:43:36 | Valid | Epoch[090/600] MIou: 0.8365327948711303
2023-02-06 10:43:36 | Valid | Epoch[090/600] Pixel Accuracy: 0.9729525248209635
2023-02-06 10:43:36 | Valid | Epoch[090/600] Mean Pixel Accuracy: 0.8524148044038307
2023-02-06 10:43:36 | Stage | Epoch[090/600] Train loss:0.0609
2023-02-06 10:43:36 | Stage | Epoch[090/600] Valid loss:0.0756
2023-02-06 10:43:36 | Stage | Epoch[090/600] LR:0.01

2023-02-06 10:43:36 | Train | Epoch[091/600] Iteration[001/030] Train loss: 0.0635
2023-02-06 10:43:36 | Train | Epoch[091/600] Iteration[002/030] Train loss: 0.0612
2023-02-06 10:43:36 | Train | Epoch[091/600] Iteration[003/030] Train loss: 0.0597
2023-02-06 10:43:36 | Train | Epoch[091/600] Iteration[004/030] Train loss: 0.0593
2023-02-06 10:43:36 | Train | Epoch[091/600] Iteration[005/030] Train loss: 0.0585
2023-02-06 10:43:36 | Train | Epoch[091/600] Iteration[006/030] Train loss: 0.0582
2023-02-06 10:43:36 | Train | Epoch[091/600] Iteration[007/030] Train loss: 0.0590
2023-02-06 10:43:36 | Train | Epoch[091/600] Iteration[008/030] Train loss: 0.0594
2023-02-06 10:43:36 | Train | Epoch[091/600] Iteration[009/030] Train loss: 0.0591
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[010/030] Train loss: 0.0590
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[011/030] Train loss: 0.0592
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[012/030] Train loss: 0.0590
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[013/030] Train loss: 0.0590
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[014/030] Train loss: 0.0588
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[015/030] Train loss: 0.0588
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[016/030] Train loss: 0.0587
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[017/030] Train loss: 0.0587
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[018/030] Train loss: 0.0588
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[019/030] Train loss: 0.0587
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[020/030] Train loss: 0.0586
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[021/030] Train loss: 0.0584
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[022/030] Train loss: 0.0584
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[023/030] Train loss: 0.0584
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[024/030] Train loss: 0.0583
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[025/030] Train loss: 0.0585
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[026/030] Train loss: 0.0586
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[027/030] Train loss: 0.0586
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[028/030] Train loss: 0.0586
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[029/030] Train loss: 0.0587
2023-02-06 10:43:37 | Train | Epoch[091/600] Iteration[030/030] Train loss: 0.0586
2023-02-06 10:43:38 | Valid | Epoch[091/600] Iteration[001/008] Valid loss: 0.0727
2023-02-06 10:43:38 | Valid | Epoch[091/600] Iteration[002/008] Valid loss: 0.0719
2023-02-06 10:43:38 | Valid | Epoch[091/600] Iteration[003/008] Valid loss: 0.0725
2023-02-06 10:43:38 | Valid | Epoch[091/600] Iteration[004/008] Valid loss: 0.0717
2023-02-06 10:43:38 | Valid | Epoch[091/600] Iteration[005/008] Valid loss: 0.0720
2023-02-06 10:43:38 | Valid | Epoch[091/600] Iteration[006/008] Valid loss: 0.0715
2023-02-06 10:43:38 | Valid | Epoch[091/600] Iteration[007/008] Valid loss: 0.0708
2023-02-06 10:43:38 | Valid | Epoch[091/600] Iteration[008/008] Valid loss: 0.0713
2023-02-06 10:43:38 | Valid | Epoch[091/600] MIou: 0.8487334143172406
2023-02-06 10:43:38 | Valid | Epoch[091/600] Pixel Accuracy: 0.9750836690266927
2023-02-06 10:43:38 | Valid | Epoch[091/600] Mean Pixel Accuracy: 0.8620633825620521
2023-02-06 10:43:38 | Stage | Epoch[091/600] Train loss:0.0586
2023-02-06 10:43:38 | Stage | Epoch[091/600] Valid loss:0.0713
2023-02-06 10:43:38 | Stage | Epoch[091/600] LR:0.01

2023-02-06 10:43:38 | Train | Epoch[092/600] Iteration[001/030] Train loss: 0.0569
2023-02-06 10:43:38 | Train | Epoch[092/600] Iteration[002/030] Train loss: 0.0591
2023-02-06 10:43:38 | Train | Epoch[092/600] Iteration[003/030] Train loss: 0.0586
2023-02-06 10:43:38 | Train | Epoch[092/600] Iteration[004/030] Train loss: 0.0588
2023-02-06 10:43:38 | Train | Epoch[092/600] Iteration[005/030] Train loss: 0.0585
2023-02-06 10:43:38 | Train | Epoch[092/600] Iteration[006/030] Train loss: 0.0582
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[007/030] Train loss: 0.0579
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[008/030] Train loss: 0.0577
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[009/030] Train loss: 0.0579
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[010/030] Train loss: 0.0579
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[011/030] Train loss: 0.0579
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[012/030] Train loss: 0.0576
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[013/030] Train loss: 0.0576
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[014/030] Train loss: 0.0575
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[015/030] Train loss: 0.0579
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[016/030] Train loss: 0.0577
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[017/030] Train loss: 0.0577
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[018/030] Train loss: 0.0579
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[019/030] Train loss: 0.0578
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[020/030] Train loss: 0.0581
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[021/030] Train loss: 0.0581
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[022/030] Train loss: 0.0580
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[023/030] Train loss: 0.0579
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[024/030] Train loss: 0.0578
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[025/030] Train loss: 0.0579
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[026/030] Train loss: 0.0581
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[027/030] Train loss: 0.0580
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[028/030] Train loss: 0.0581
2023-02-06 10:43:39 | Train | Epoch[092/600] Iteration[029/030] Train loss: 0.0581
2023-02-06 10:43:40 | Train | Epoch[092/600] Iteration[030/030] Train loss: 0.0583
2023-02-06 10:43:40 | Valid | Epoch[092/600] Iteration[001/008] Valid loss: 0.0842
2023-02-06 10:43:40 | Valid | Epoch[092/600] Iteration[002/008] Valid loss: 0.0853
2023-02-06 10:43:40 | Valid | Epoch[092/600] Iteration[003/008] Valid loss: 0.0870
2023-02-06 10:43:40 | Valid | Epoch[092/600] Iteration[004/008] Valid loss: 0.0865
2023-02-06 10:43:40 | Valid | Epoch[092/600] Iteration[005/008] Valid loss: 0.0870
2023-02-06 10:43:40 | Valid | Epoch[092/600] Iteration[006/008] Valid loss: 0.0862
2023-02-06 10:43:40 | Valid | Epoch[092/600] Iteration[007/008] Valid loss: 0.0849
2023-02-06 10:43:40 | Valid | Epoch[092/600] Iteration[008/008] Valid loss: 0.0862
2023-02-06 10:43:40 | Valid | Epoch[092/600] MIou: 0.7738203610136274
2023-02-06 10:43:40 | Valid | Epoch[092/600] Pixel Accuracy: 0.962701161702474
2023-02-06 10:43:40 | Valid | Epoch[092/600] Mean Pixel Accuracy: 0.7935139168508638
2023-02-06 10:43:40 | Stage | Epoch[092/600] Train loss:0.0583
2023-02-06 10:43:40 | Stage | Epoch[092/600] Valid loss:0.0862
2023-02-06 10:43:40 | Stage | Epoch[092/600] LR:0.01

2023-02-06 10:43:40 | Train | Epoch[093/600] Iteration[001/030] Train loss: 0.0527
2023-02-06 10:43:40 | Train | Epoch[093/600] Iteration[002/030] Train loss: 0.0552
2023-02-06 10:43:40 | Train | Epoch[093/600] Iteration[003/030] Train loss: 0.0570
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[004/030] Train loss: 0.0570
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[005/030] Train loss: 0.0564
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[006/030] Train loss: 0.0572
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[007/030] Train loss: 0.0569
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[008/030] Train loss: 0.0568
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[009/030] Train loss: 0.0568
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[010/030] Train loss: 0.0570
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[011/030] Train loss: 0.0569
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[012/030] Train loss: 0.0571
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[013/030] Train loss: 0.0570
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[014/030] Train loss: 0.0572
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[015/030] Train loss: 0.0572
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[016/030] Train loss: 0.0572
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[017/030] Train loss: 0.0574
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[018/030] Train loss: 0.0575
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[019/030] Train loss: 0.0578
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[020/030] Train loss: 0.0579
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[021/030] Train loss: 0.0578
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[022/030] Train loss: 0.0580
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[023/030] Train loss: 0.0581
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[024/030] Train loss: 0.0581
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[025/030] Train loss: 0.0582
2023-02-06 10:43:41 | Train | Epoch[093/600] Iteration[026/030] Train loss: 0.0581
2023-02-06 10:43:42 | Train | Epoch[093/600] Iteration[027/030] Train loss: 0.0582
2023-02-06 10:43:42 | Train | Epoch[093/600] Iteration[028/030] Train loss: 0.0581
2023-02-06 10:43:42 | Train | Epoch[093/600] Iteration[029/030] Train loss: 0.0582
2023-02-06 10:43:42 | Train | Epoch[093/600] Iteration[030/030] Train loss: 0.0583
2023-02-06 10:43:42 | Valid | Epoch[093/600] Iteration[001/008] Valid loss: 0.0801
2023-02-06 10:43:42 | Valid | Epoch[093/600] Iteration[002/008] Valid loss: 0.0714
2023-02-06 10:43:42 | Valid | Epoch[093/600] Iteration[003/008] Valid loss: 0.0696
2023-02-06 10:43:42 | Valid | Epoch[093/600] Iteration[004/008] Valid loss: 0.0687
2023-02-06 10:43:42 | Valid | Epoch[093/600] Iteration[005/008] Valid loss: 0.0699
2023-02-06 10:43:42 | Valid | Epoch[093/600] Iteration[006/008] Valid loss: 0.0696
2023-02-06 10:43:42 | Valid | Epoch[093/600] Iteration[007/008] Valid loss: 0.0715
2023-02-06 10:43:42 | Valid | Epoch[093/600] Iteration[008/008] Valid loss: 0.0714
2023-02-06 10:43:42 | Valid | Epoch[093/600] MIou: 0.9352488717875971
2023-02-06 10:43:42 | Valid | Epoch[093/600] Pixel Accuracy: 0.988702138264974
2023-02-06 10:43:42 | Valid | Epoch[093/600] Mean Pixel Accuracy: 0.9679654728795796
2023-02-06 10:43:42 | Stage | Epoch[093/600] Train loss:0.0583
2023-02-06 10:43:42 | Stage | Epoch[093/600] Valid loss:0.0714
2023-02-06 10:43:42 | Stage | Epoch[093/600] LR:0.01

2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[001/030] Train loss: 0.0572
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[002/030] Train loss: 0.0581
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[003/030] Train loss: 0.0589
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[004/030] Train loss: 0.0594
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[005/030] Train loss: 0.0595
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[006/030] Train loss: 0.0586
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[007/030] Train loss: 0.0584
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[008/030] Train loss: 0.0579
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[009/030] Train loss: 0.0578
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[010/030] Train loss: 0.0577
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[011/030] Train loss: 0.0575
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[012/030] Train loss: 0.0576
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[013/030] Train loss: 0.0576
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[014/030] Train loss: 0.0575
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[015/030] Train loss: 0.0573
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[016/030] Train loss: 0.0571
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[017/030] Train loss: 0.0570
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[018/030] Train loss: 0.0572
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[019/030] Train loss: 0.0570
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[020/030] Train loss: 0.0572
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[021/030] Train loss: 0.0572
2023-02-06 10:43:43 | Train | Epoch[094/600] Iteration[022/030] Train loss: 0.0572
2023-02-06 10:43:44 | Train | Epoch[094/600] Iteration[023/030] Train loss: 0.0574
2023-02-06 10:43:44 | Train | Epoch[094/600] Iteration[024/030] Train loss: 0.0573
2023-02-06 10:43:44 | Train | Epoch[094/600] Iteration[025/030] Train loss: 0.0573
2023-02-06 10:43:44 | Train | Epoch[094/600] Iteration[026/030] Train loss: 0.0573
2023-02-06 10:43:44 | Train | Epoch[094/600] Iteration[027/030] Train loss: 0.0572
2023-02-06 10:43:44 | Train | Epoch[094/600] Iteration[028/030] Train loss: 0.0572
2023-02-06 10:43:44 | Train | Epoch[094/600] Iteration[029/030] Train loss: 0.0571
2023-02-06 10:43:44 | Train | Epoch[094/600] Iteration[030/030] Train loss: 0.0571
2023-02-06 10:43:44 | Valid | Epoch[094/600] Iteration[001/008] Valid loss: 0.0721
2023-02-06 10:43:44 | Valid | Epoch[094/600] Iteration[002/008] Valid loss: 0.0669
2023-02-06 10:43:44 | Valid | Epoch[094/600] Iteration[003/008] Valid loss: 0.0651
2023-02-06 10:43:44 | Valid | Epoch[094/600] Iteration[004/008] Valid loss: 0.0649
2023-02-06 10:43:44 | Valid | Epoch[094/600] Iteration[005/008] Valid loss: 0.0655
2023-02-06 10:43:44 | Valid | Epoch[094/600] Iteration[006/008] Valid loss: 0.0663
2023-02-06 10:43:44 | Valid | Epoch[094/600] Iteration[007/008] Valid loss: 0.0678
2023-02-06 10:43:44 | Valid | Epoch[094/600] Iteration[008/008] Valid loss: 0.0668
2023-02-06 10:43:44 | Valid | Epoch[094/600] MIou: 0.9395673425268003
2023-02-06 10:43:44 | Valid | Epoch[094/600] Pixel Accuracy: 0.9897613525390625
2023-02-06 10:43:44 | Valid | Epoch[094/600] Mean Pixel Accuracy: 0.9583585244991026
2023-02-06 10:43:44 | Stage | Epoch[094/600] Train loss:0.0571
2023-02-06 10:43:44 | Stage | Epoch[094/600] Valid loss:0.0668
2023-02-06 10:43:44 | Stage | Epoch[094/600] LR:0.01

2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[001/030] Train loss: 0.0588
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[002/030] Train loss: 0.0578
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[003/030] Train loss: 0.0579
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[004/030] Train loss: 0.0576
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[005/030] Train loss: 0.0573
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[006/030] Train loss: 0.0574
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[007/030] Train loss: 0.0571
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[008/030] Train loss: 0.0569
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[009/030] Train loss: 0.0563
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[010/030] Train loss: 0.0562
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[011/030] Train loss: 0.0563
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[012/030] Train loss: 0.0563
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[013/030] Train loss: 0.0562
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[014/030] Train loss: 0.0562
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[015/030] Train loss: 0.0560
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[016/030] Train loss: 0.0561
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[017/030] Train loss: 0.0559
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[018/030] Train loss: 0.0559
2023-02-06 10:43:45 | Train | Epoch[095/600] Iteration[019/030] Train loss: 0.0559
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[020/030] Train loss: 0.0561
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[021/030] Train loss: 0.0560
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[022/030] Train loss: 0.0561
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[023/030] Train loss: 0.0561
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[024/030] Train loss: 0.0560
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[025/030] Train loss: 0.0560
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[026/030] Train loss: 0.0561
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[027/030] Train loss: 0.0561
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[028/030] Train loss: 0.0560
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[029/030] Train loss: 0.0559
2023-02-06 10:43:46 | Train | Epoch[095/600] Iteration[030/030] Train loss: 0.0558
2023-02-06 10:43:46 | Valid | Epoch[095/600] Iteration[001/008] Valid loss: 0.2466
2023-02-06 10:43:46 | Valid | Epoch[095/600] Iteration[002/008] Valid loss: 0.2052
2023-02-06 10:43:46 | Valid | Epoch[095/600] Iteration[003/008] Valid loss: 0.1950
2023-02-06 10:43:46 | Valid | Epoch[095/600] Iteration[004/008] Valid loss: 0.1964
2023-02-06 10:43:46 | Valid | Epoch[095/600] Iteration[005/008] Valid loss: 0.2002
2023-02-06 10:43:46 | Valid | Epoch[095/600] Iteration[006/008] Valid loss: 0.2025
2023-02-06 10:43:46 | Valid | Epoch[095/600] Iteration[007/008] Valid loss: 0.2161
2023-02-06 10:43:46 | Valid | Epoch[095/600] Iteration[008/008] Valid loss: 0.2121
2023-02-06 10:43:47 | Valid | Epoch[095/600] MIou: 0.8829273464561986
2023-02-06 10:43:47 | Valid | Epoch[095/600] Pixel Accuracy: 0.9765205383300781
2023-02-06 10:43:47 | Valid | Epoch[095/600] Mean Pixel Accuracy: 0.9815404334468083
2023-02-06 10:43:47 | Stage | Epoch[095/600] Train loss:0.0558
2023-02-06 10:43:47 | Stage | Epoch[095/600] Valid loss:0.2121
2023-02-06 10:43:47 | Stage | Epoch[095/600] LR:0.01

2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[001/030] Train loss: 0.0520
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[002/030] Train loss: 0.0545
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[003/030] Train loss: 0.0546
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[004/030] Train loss: 0.0545
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[005/030] Train loss: 0.0543
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[006/030] Train loss: 0.0544
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[007/030] Train loss: 0.0546
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[008/030] Train loss: 0.0547
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[009/030] Train loss: 0.0546
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[010/030] Train loss: 0.0547
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[011/030] Train loss: 0.0545
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[012/030] Train loss: 0.0545
2023-02-06 10:43:47 | Train | Epoch[096/600] Iteration[013/030] Train loss: 0.0547
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[014/030] Train loss: 0.0548
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[015/030] Train loss: 0.0549
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[016/030] Train loss: 0.0550
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[017/030] Train loss: 0.0553
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[018/030] Train loss: 0.0552
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[019/030] Train loss: 0.0553
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[020/030] Train loss: 0.0554
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[021/030] Train loss: 0.0554
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[022/030] Train loss: 0.0554
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[023/030] Train loss: 0.0553
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[024/030] Train loss: 0.0552
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[025/030] Train loss: 0.0552
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[026/030] Train loss: 0.0552
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[027/030] Train loss: 0.0553
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[028/030] Train loss: 0.0554
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[029/030] Train loss: 0.0553
2023-02-06 10:43:48 | Train | Epoch[096/600] Iteration[030/030] Train loss: 0.0553
2023-02-06 10:43:49 | Valid | Epoch[096/600] Iteration[001/008] Valid loss: 0.1466
2023-02-06 10:43:49 | Valid | Epoch[096/600] Iteration[002/008] Valid loss: 0.1255
2023-02-06 10:43:49 | Valid | Epoch[096/600] Iteration[003/008] Valid loss: 0.1181
2023-02-06 10:43:49 | Valid | Epoch[096/600] Iteration[004/008] Valid loss: 0.1156
2023-02-06 10:43:49 | Valid | Epoch[096/600] Iteration[005/008] Valid loss: 0.1177
2023-02-06 10:43:49 | Valid | Epoch[096/600] Iteration[006/008] Valid loss: 0.1155
2023-02-06 10:43:49 | Valid | Epoch[096/600] Iteration[007/008] Valid loss: 0.1212
2023-02-06 10:43:49 | Valid | Epoch[096/600] Iteration[008/008] Valid loss: 0.1221
2023-02-06 10:43:49 | Valid | Epoch[096/600] MIou: 0.9121632701277596
2023-02-06 10:43:49 | Valid | Epoch[096/600] Pixel Accuracy: 0.9834747314453125
2023-02-06 10:43:49 | Valid | Epoch[096/600] Mean Pixel Accuracy: 0.9811843838456435
2023-02-06 10:43:49 | Stage | Epoch[096/600] Train loss:0.0553
2023-02-06 10:43:49 | Stage | Epoch[096/600] Valid loss:0.1221
2023-02-06 10:43:49 | Stage | Epoch[096/600] LR:0.01

2023-02-06 10:43:49 | Train | Epoch[097/600] Iteration[001/030] Train loss: 0.0595
2023-02-06 10:43:49 | Train | Epoch[097/600] Iteration[002/030] Train loss: 0.0561
2023-02-06 10:43:49 | Train | Epoch[097/600] Iteration[003/030] Train loss: 0.0550
2023-02-06 10:43:49 | Train | Epoch[097/600] Iteration[004/030] Train loss: 0.0547
2023-02-06 10:43:49 | Train | Epoch[097/600] Iteration[005/030] Train loss: 0.0540
2023-02-06 10:43:49 | Train | Epoch[097/600] Iteration[006/030] Train loss: 0.0537
2023-02-06 10:43:49 | Train | Epoch[097/600] Iteration[007/030] Train loss: 0.0542
2023-02-06 10:43:49 | Train | Epoch[097/600] Iteration[008/030] Train loss: 0.0547
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[009/030] Train loss: 0.0545
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[010/030] Train loss: 0.0548
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[011/030] Train loss: 0.0549
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[012/030] Train loss: 0.0550
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[013/030] Train loss: 0.0553
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[014/030] Train loss: 0.0552
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[015/030] Train loss: 0.0555
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[016/030] Train loss: 0.0551
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[017/030] Train loss: 0.0552
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[018/030] Train loss: 0.0550
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[019/030] Train loss: 0.0550
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[020/030] Train loss: 0.0551
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[021/030] Train loss: 0.0549
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[022/030] Train loss: 0.0549
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[023/030] Train loss: 0.0549
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[024/030] Train loss: 0.0547
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[025/030] Train loss: 0.0545
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[026/030] Train loss: 0.0546
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[027/030] Train loss: 0.0547
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[028/030] Train loss: 0.0547
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[029/030] Train loss: 0.0548
2023-02-06 10:43:50 | Train | Epoch[097/600] Iteration[030/030] Train loss: 0.0548
2023-02-06 10:43:51 | Valid | Epoch[097/600] Iteration[001/008] Valid loss: 0.2489
2023-02-06 10:43:51 | Valid | Epoch[097/600] Iteration[002/008] Valid loss: 0.2440
2023-02-06 10:43:51 | Valid | Epoch[097/600] Iteration[003/008] Valid loss: 0.2529
2023-02-06 10:43:51 | Valid | Epoch[097/600] Iteration[004/008] Valid loss: 0.2556
2023-02-06 10:43:51 | Valid | Epoch[097/600] Iteration[005/008] Valid loss: 0.2605
2023-02-06 10:43:51 | Valid | Epoch[097/600] Iteration[006/008] Valid loss: 0.2590
2023-02-06 10:43:51 | Valid | Epoch[097/600] Iteration[007/008] Valid loss: 0.2585
2023-02-06 10:43:51 | Valid | Epoch[097/600] Iteration[008/008] Valid loss: 0.2640
2023-02-06 10:43:51 | Valid | Epoch[097/600] MIou: 0.45501618636106084
2023-02-06 10:43:51 | Valid | Epoch[097/600] Pixel Accuracy: 0.9097112019856771
2023-02-06 10:43:51 | Valid | Epoch[097/600] Mean Pixel Accuracy: 0.5001619057004886
2023-02-06 10:43:51 | Stage | Epoch[097/600] Train loss:0.0548
2023-02-06 10:43:51 | Stage | Epoch[097/600] Valid loss:0.2640
2023-02-06 10:43:51 | Stage | Epoch[097/600] LR:0.01

2023-02-06 10:43:51 | Train | Epoch[098/600] Iteration[001/030] Train loss: 0.0545
2023-02-06 10:43:51 | Train | Epoch[098/600] Iteration[002/030] Train loss: 0.0542
2023-02-06 10:43:51 | Train | Epoch[098/600] Iteration[003/030] Train loss: 0.0540
2023-02-06 10:43:51 | Train | Epoch[098/600] Iteration[004/030] Train loss: 0.0536
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[005/030] Train loss: 0.0535
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[006/030] Train loss: 0.0537
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[007/030] Train loss: 0.0537
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[008/030] Train loss: 0.0536
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[009/030] Train loss: 0.0534
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[010/030] Train loss: 0.0531
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[011/030] Train loss: 0.0531
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[012/030] Train loss: 0.0532
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[013/030] Train loss: 0.0532
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[014/030] Train loss: 0.0531
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[015/030] Train loss: 0.0537
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[016/030] Train loss: 0.0537
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[017/030] Train loss: 0.0536
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[018/030] Train loss: 0.0534
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[019/030] Train loss: 0.0537
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[020/030] Train loss: 0.0539
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[021/030] Train loss: 0.0541
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[022/030] Train loss: 0.0539
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[023/030] Train loss: 0.0540
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[024/030] Train loss: 0.0539
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[025/030] Train loss: 0.0540
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[026/030] Train loss: 0.0539
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[027/030] Train loss: 0.0541
2023-02-06 10:43:52 | Train | Epoch[098/600] Iteration[028/030] Train loss: 0.0540
2023-02-06 10:43:53 | Train | Epoch[098/600] Iteration[029/030] Train loss: 0.0540
2023-02-06 10:43:53 | Train | Epoch[098/600] Iteration[030/030] Train loss: 0.0542
2023-02-06 10:43:53 | Valid | Epoch[098/600] Iteration[001/008] Valid loss: 1.0105
2023-02-06 10:43:53 | Valid | Epoch[098/600] Iteration[002/008] Valid loss: 0.9519
2023-02-06 10:43:53 | Valid | Epoch[098/600] Iteration[003/008] Valid loss: 0.9716
2023-02-06 10:43:53 | Valid | Epoch[098/600] Iteration[004/008] Valid loss: 0.9974
2023-02-06 10:43:53 | Valid | Epoch[098/600] Iteration[005/008] Valid loss: 1.0410
2023-02-06 10:43:53 | Valid | Epoch[098/600] Iteration[006/008] Valid loss: 1.0285
2023-02-06 10:43:53 | Valid | Epoch[098/600] Iteration[007/008] Valid loss: 1.0805
2023-02-06 10:43:53 | Valid | Epoch[098/600] Iteration[008/008] Valid loss: 1.1034
2023-02-06 10:43:53 | Valid | Epoch[098/600] MIou: 0.7845091655848653
2023-02-06 10:43:53 | Valid | Epoch[098/600] Pixel Accuracy: 0.9466094970703125
2023-02-06 10:43:53 | Valid | Epoch[098/600] Mean Pixel Accuracy: 0.9691325893770678
2023-02-06 10:43:53 | Stage | Epoch[098/600] Train loss:0.0542
2023-02-06 10:43:53 | Stage | Epoch[098/600] Valid loss:1.1034
2023-02-06 10:43:53 | Stage | Epoch[098/600] LR:0.01

2023-02-06 10:43:53 | Train | Epoch[099/600] Iteration[001/030] Train loss: 0.0522
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[002/030] Train loss: 0.0523
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[003/030] Train loss: 0.0527
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[004/030] Train loss: 0.0544
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[005/030] Train loss: 0.0542
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[006/030] Train loss: 0.0541
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[007/030] Train loss: 0.0543
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[008/030] Train loss: 0.0541
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[009/030] Train loss: 0.0538
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[010/030] Train loss: 0.0540
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[011/030] Train loss: 0.0540
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[012/030] Train loss: 0.0540
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[013/030] Train loss: 0.0540
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[014/030] Train loss: 0.0537
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[015/030] Train loss: 0.0537
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[016/030] Train loss: 0.0542
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[017/030] Train loss: 0.0541
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[018/030] Train loss: 0.0540
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[019/030] Train loss: 0.0539
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[020/030] Train loss: 0.0538
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[021/030] Train loss: 0.0536
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[022/030] Train loss: 0.0537
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[023/030] Train loss: 0.0537
2023-02-06 10:43:54 | Train | Epoch[099/600] Iteration[024/030] Train loss: 0.0537
2023-02-06 10:43:55 | Train | Epoch[099/600] Iteration[025/030] Train loss: 0.0538
2023-02-06 10:43:55 | Train | Epoch[099/600] Iteration[026/030] Train loss: 0.0537
2023-02-06 10:43:55 | Train | Epoch[099/600] Iteration[027/030] Train loss: 0.0536
2023-02-06 10:43:55 | Train | Epoch[099/600] Iteration[028/030] Train loss: 0.0536
2023-02-06 10:43:55 | Train | Epoch[099/600] Iteration[029/030] Train loss: 0.0537
2023-02-06 10:43:55 | Train | Epoch[099/600] Iteration[030/030] Train loss: 0.0538
2023-02-06 10:43:55 | Valid | Epoch[099/600] Iteration[001/008] Valid loss: 0.0710
2023-02-06 10:43:55 | Valid | Epoch[099/600] Iteration[002/008] Valid loss: 0.0644
2023-02-06 10:43:55 | Valid | Epoch[099/600] Iteration[003/008] Valid loss: 0.0626
2023-02-06 10:43:55 | Valid | Epoch[099/600] Iteration[004/008] Valid loss: 0.0622
2023-02-06 10:43:55 | Valid | Epoch[099/600] Iteration[005/008] Valid loss: 0.0629
2023-02-06 10:43:55 | Valid | Epoch[099/600] Iteration[006/008] Valid loss: 0.0635
2023-02-06 10:43:55 | Valid | Epoch[099/600] Iteration[007/008] Valid loss: 0.0651
2023-02-06 10:43:55 | Valid | Epoch[099/600] Iteration[008/008] Valid loss: 0.0641
2023-02-06 10:43:55 | Valid | Epoch[099/600] MIou: 0.9402493072436932
2023-02-06 10:43:55 | Valid | Epoch[099/600] Pixel Accuracy: 0.9898262023925781
2023-02-06 10:43:55 | Valid | Epoch[099/600] Mean Pixel Accuracy: 0.9613171261114429
2023-02-06 10:43:55 | Stage | Epoch[099/600] Train loss:0.0538
2023-02-06 10:43:55 | Stage | Epoch[099/600] Valid loss:0.0641
2023-02-06 10:43:55 | Stage | Epoch[099/600] LR:0.01

2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[001/030] Train loss: 0.0539
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[002/030] Train loss: 0.0535
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[003/030] Train loss: 0.0530
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[004/030] Train loss: 0.0533
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[005/030] Train loss: 0.0529
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[006/030] Train loss: 0.0535
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[007/030] Train loss: 0.0533
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[008/030] Train loss: 0.0532
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[009/030] Train loss: 0.0533
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[010/030] Train loss: 0.0529
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[011/030] Train loss: 0.0531
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[012/030] Train loss: 0.0533
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[013/030] Train loss: 0.0532
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[014/030] Train loss: 0.0536
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[015/030] Train loss: 0.0536
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[016/030] Train loss: 0.0544
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[017/030] Train loss: 0.0541
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[018/030] Train loss: 0.0541
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[019/030] Train loss: 0.0542
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[020/030] Train loss: 0.0540
2023-02-06 10:43:56 | Train | Epoch[100/600] Iteration[021/030] Train loss: 0.0539
2023-02-06 10:43:57 | Train | Epoch[100/600] Iteration[022/030] Train loss: 0.0539
2023-02-06 10:43:57 | Train | Epoch[100/600] Iteration[023/030] Train loss: 0.0539
2023-02-06 10:43:57 | Train | Epoch[100/600] Iteration[024/030] Train loss: 0.0539
2023-02-06 10:43:57 | Train | Epoch[100/600] Iteration[025/030] Train loss: 0.0541
2023-02-06 10:43:57 | Train | Epoch[100/600] Iteration[026/030] Train loss: 0.0540
2023-02-06 10:43:57 | Train | Epoch[100/600] Iteration[027/030] Train loss: 0.0539
2023-02-06 10:43:57 | Train | Epoch[100/600] Iteration[028/030] Train loss: 0.0540
2023-02-06 10:43:57 | Train | Epoch[100/600] Iteration[029/030] Train loss: 0.0541
2023-02-06 10:43:57 | Train | Epoch[100/600] Iteration[030/030] Train loss: 0.0540
2023-02-06 10:43:57 | Valid | Epoch[100/600] Iteration[001/008] Valid loss: 0.0703
2023-02-06 10:43:57 | Valid | Epoch[100/600] Iteration[002/008] Valid loss: 0.0704
2023-02-06 10:43:57 | Valid | Epoch[100/600] Iteration[003/008] Valid loss: 0.0716
2023-02-06 10:43:57 | Valid | Epoch[100/600] Iteration[004/008] Valid loss: 0.0707
2023-02-06 10:43:57 | Valid | Epoch[100/600] Iteration[005/008] Valid loss: 0.0715
2023-02-06 10:43:57 | Valid | Epoch[100/600] Iteration[006/008] Valid loss: 0.0709
2023-02-06 10:43:57 | Valid | Epoch[100/600] Iteration[007/008] Valid loss: 0.0700
2023-02-06 10:43:57 | Valid | Epoch[100/600] Iteration[008/008] Valid loss: 0.0707
2023-02-06 10:43:58 | Valid | Epoch[100/600] MIou: 0.8211979673922204
2023-02-06 10:43:58 | Valid | Epoch[100/600] Pixel Accuracy: 0.9705340067545573
2023-02-06 10:43:58 | Valid | Epoch[100/600] Mean Pixel Accuracy: 0.8369018489547104
2023-02-06 10:43:58 | Stage | Epoch[100/600] Train loss:0.0540
2023-02-06 10:43:58 | Stage | Epoch[100/600] Valid loss:0.0707
2023-02-06 10:43:58 | Stage | Epoch[100/600] LR:0.01

2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[001/030] Train loss: 0.0509
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[002/030] Train loss: 0.0526
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[003/030] Train loss: 0.0528
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[004/030] Train loss: 0.0517
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[005/030] Train loss: 0.0520
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[006/030] Train loss: 0.0524
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[007/030] Train loss: 0.0528
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[008/030] Train loss: 0.0533
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[009/030] Train loss: 0.0535
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[010/030] Train loss: 0.0533
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[011/030] Train loss: 0.0533
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[012/030] Train loss: 0.0527
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[013/030] Train loss: 0.0533
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[014/030] Train loss: 0.0535
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[015/030] Train loss: 0.0531
2023-02-06 10:43:58 | Train | Epoch[101/600] Iteration[016/030] Train loss: 0.0530
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[017/030] Train loss: 0.0530
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[018/030] Train loss: 0.0529
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[019/030] Train loss: 0.0528
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[020/030] Train loss: 0.0529
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[021/030] Train loss: 0.0529
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[022/030] Train loss: 0.0529
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[023/030] Train loss: 0.0531
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[024/030] Train loss: 0.0532
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[025/030] Train loss: 0.0532
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[026/030] Train loss: 0.0531
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[027/030] Train loss: 0.0530
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[028/030] Train loss: 0.0530
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[029/030] Train loss: 0.0528
2023-02-06 10:43:59 | Train | Epoch[101/600] Iteration[030/030] Train loss: 0.0528
2023-02-06 10:43:59 | Valid | Epoch[101/600] Iteration[001/008] Valid loss: 0.0835
2023-02-06 10:43:59 | Valid | Epoch[101/600] Iteration[002/008] Valid loss: 0.0730
2023-02-06 10:43:59 | Valid | Epoch[101/600] Iteration[003/008] Valid loss: 0.0709
2023-02-06 10:44:00 | Valid | Epoch[101/600] Iteration[004/008] Valid loss: 0.0701
2023-02-06 10:44:00 | Valid | Epoch[101/600] Iteration[005/008] Valid loss: 0.0716
2023-02-06 10:44:00 | Valid | Epoch[101/600] Iteration[006/008] Valid loss: 0.0718
2023-02-06 10:44:00 | Valid | Epoch[101/600] Iteration[007/008] Valid loss: 0.0751
2023-02-06 10:44:00 | Valid | Epoch[101/600] Iteration[008/008] Valid loss: 0.0737
2023-02-06 10:44:00 | Valid | Epoch[101/600] MIou: 0.9382908795808345
2023-02-06 10:44:00 | Valid | Epoch[101/600] Pixel Accuracy: 0.989203135172526
2023-02-06 10:44:00 | Valid | Epoch[101/600] Mean Pixel Accuracy: 0.9722543606141181
2023-02-06 10:44:00 | Stage | Epoch[101/600] Train loss:0.0528
2023-02-06 10:44:00 | Stage | Epoch[101/600] Valid loss:0.0737
2023-02-06 10:44:00 | Stage | Epoch[101/600] LR:0.01

2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[001/030] Train loss: 0.0487
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[002/030] Train loss: 0.0499
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[003/030] Train loss: 0.0517
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[004/030] Train loss: 0.0523
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[005/030] Train loss: 0.0522
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[006/030] Train loss: 0.0526
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[007/030] Train loss: 0.0521
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[008/030] Train loss: 0.0523
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[009/030] Train loss: 0.0524
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[010/030] Train loss: 0.0525
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[011/030] Train loss: 0.0523
2023-02-06 10:44:00 | Train | Epoch[102/600] Iteration[012/030] Train loss: 0.0519
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[013/030] Train loss: 0.0519
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[014/030] Train loss: 0.0520
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[015/030] Train loss: 0.0519
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[016/030] Train loss: 0.0518
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[017/030] Train loss: 0.0521
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[018/030] Train loss: 0.0522
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[019/030] Train loss: 0.0523
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[020/030] Train loss: 0.0522
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[021/030] Train loss: 0.0522
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[022/030] Train loss: 0.0523
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[023/030] Train loss: 0.0523
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[024/030] Train loss: 0.0521
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[025/030] Train loss: 0.0521
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[026/030] Train loss: 0.0520
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[027/030] Train loss: 0.0522
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[028/030] Train loss: 0.0521
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[029/030] Train loss: 0.0521
2023-02-06 10:44:01 | Train | Epoch[102/600] Iteration[030/030] Train loss: 0.0523
2023-02-06 10:44:02 | Valid | Epoch[102/600] Iteration[001/008] Valid loss: 0.6829
2023-02-06 10:44:02 | Valid | Epoch[102/600] Iteration[002/008] Valid loss: 0.6361
2023-02-06 10:44:02 | Valid | Epoch[102/600] Iteration[003/008] Valid loss: 0.6480
2023-02-06 10:44:02 | Valid | Epoch[102/600] Iteration[004/008] Valid loss: 0.6582
2023-02-06 10:44:02 | Valid | Epoch[102/600] Iteration[005/008] Valid loss: 0.6930
2023-02-06 10:44:02 | Valid | Epoch[102/600] Iteration[006/008] Valid loss: 0.6755
2023-02-06 10:44:02 | Valid | Epoch[102/600] Iteration[007/008] Valid loss: 0.7125
2023-02-06 10:44:02 | Valid | Epoch[102/600] Iteration[008/008] Valid loss: 0.7284
2023-02-06 10:44:02 | Valid | Epoch[102/600] MIou: 0.8229460167860798
2023-02-06 10:44:02 | Valid | Epoch[102/600] Pixel Accuracy: 0.9596786499023438
2023-02-06 10:44:02 | Valid | Epoch[102/600] Mean Pixel Accuracy: 0.9753965847901879
2023-02-06 10:44:02 | Stage | Epoch[102/600] Train loss:0.0523
2023-02-06 10:44:02 | Stage | Epoch[102/600] Valid loss:0.7284
2023-02-06 10:44:02 | Stage | Epoch[102/600] LR:0.01

2023-02-06 10:44:02 | Train | Epoch[103/600] Iteration[001/030] Train loss: 0.0553
2023-02-06 10:44:02 | Train | Epoch[103/600] Iteration[002/030] Train loss: 0.0567
2023-02-06 10:44:02 | Train | Epoch[103/600] Iteration[003/030] Train loss: 0.0546
2023-02-06 10:44:02 | Train | Epoch[103/600] Iteration[004/030] Train loss: 0.0548
2023-02-06 10:44:02 | Train | Epoch[103/600] Iteration[005/030] Train loss: 0.0542
2023-02-06 10:44:02 | Train | Epoch[103/600] Iteration[006/030] Train loss: 0.0543
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[007/030] Train loss: 0.0541
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[008/030] Train loss: 0.0539
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[009/030] Train loss: 0.0537
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[010/030] Train loss: 0.0533
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[011/030] Train loss: 0.0544
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[012/030] Train loss: 0.0545
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[013/030] Train loss: 0.0542
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[014/030] Train loss: 0.0542
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[015/030] Train loss: 0.0544
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[016/030] Train loss: 0.0542
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[017/030] Train loss: 0.0541
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[018/030] Train loss: 0.0543
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[019/030] Train loss: 0.0540
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[020/030] Train loss: 0.0540
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[021/030] Train loss: 0.0537
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[022/030] Train loss: 0.0537
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[023/030] Train loss: 0.0536
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[024/030] Train loss: 0.0535
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[025/030] Train loss: 0.0534
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[026/030] Train loss: 0.0535
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[027/030] Train loss: 0.0535
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[028/030] Train loss: 0.0535
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[029/030] Train loss: 0.0535
2023-02-06 10:44:03 | Train | Epoch[103/600] Iteration[030/030] Train loss: 0.0534
2023-02-06 10:44:04 | Valid | Epoch[103/600] Iteration[001/008] Valid loss: 0.1603
2023-02-06 10:44:04 | Valid | Epoch[103/600] Iteration[002/008] Valid loss: 0.1545
2023-02-06 10:44:04 | Valid | Epoch[103/600] Iteration[003/008] Valid loss: 0.1567
2023-02-06 10:44:04 | Valid | Epoch[103/600] Iteration[004/008] Valid loss: 0.1583
2023-02-06 10:44:04 | Valid | Epoch[103/600] Iteration[005/008] Valid loss: 0.1592
2023-02-06 10:44:04 | Valid | Epoch[103/600] Iteration[006/008] Valid loss: 0.1588
2023-02-06 10:44:04 | Valid | Epoch[103/600] Iteration[007/008] Valid loss: 0.1582
2023-02-06 10:44:04 | Valid | Epoch[103/600] Iteration[008/008] Valid loss: 0.1597
2023-02-06 10:44:04 | Valid | Epoch[103/600] MIou: 0.5347099937635194
2023-02-06 10:44:04 | Valid | Epoch[103/600] Pixel Accuracy: 0.9227256774902344
2023-02-06 10:44:04 | Valid | Epoch[103/600] Mean Pixel Accuracy: 0.5739662530267318
2023-02-06 10:44:04 | Stage | Epoch[103/600] Train loss:0.0534
2023-02-06 10:44:04 | Stage | Epoch[103/600] Valid loss:0.1597
2023-02-06 10:44:04 | Stage | Epoch[103/600] LR:0.01

2023-02-06 10:44:04 | Train | Epoch[104/600] Iteration[001/030] Train loss: 0.0546
2023-02-06 10:44:04 | Train | Epoch[104/600] Iteration[002/030] Train loss: 0.0542
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[003/030] Train loss: 0.0528
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[004/030] Train loss: 0.0527
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[005/030] Train loss: 0.0524
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[006/030] Train loss: 0.0515
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[007/030] Train loss: 0.0517
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[008/030] Train loss: 0.0517
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[009/030] Train loss: 0.0515
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[010/030] Train loss: 0.0514
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[011/030] Train loss: 0.0516
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[012/030] Train loss: 0.0515
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[013/030] Train loss: 0.0513
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[014/030] Train loss: 0.0514
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[015/030] Train loss: 0.0514
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[016/030] Train loss: 0.0516
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[017/030] Train loss: 0.0521
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[018/030] Train loss: 0.0519
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[019/030] Train loss: 0.0520
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[020/030] Train loss: 0.0522
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[021/030] Train loss: 0.0521
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[022/030] Train loss: 0.0523
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[023/030] Train loss: 0.0526
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[024/030] Train loss: 0.0527
2023-02-06 10:44:05 | Train | Epoch[104/600] Iteration[025/030] Train loss: 0.0528
2023-02-06 10:44:06 | Train | Epoch[104/600] Iteration[026/030] Train loss: 0.0527
2023-02-06 10:44:06 | Train | Epoch[104/600] Iteration[027/030] Train loss: 0.0525
2023-02-06 10:44:06 | Train | Epoch[104/600] Iteration[028/030] Train loss: 0.0525
2023-02-06 10:44:06 | Train | Epoch[104/600] Iteration[029/030] Train loss: 0.0526
2023-02-06 10:44:06 | Train | Epoch[104/600] Iteration[030/030] Train loss: 0.0525
2023-02-06 10:44:06 | Valid | Epoch[104/600] Iteration[001/008] Valid loss: 0.1200
2023-02-06 10:44:06 | Valid | Epoch[104/600] Iteration[002/008] Valid loss: 0.1055
2023-02-06 10:44:06 | Valid | Epoch[104/600] Iteration[003/008] Valid loss: 0.1024
2023-02-06 10:44:06 | Valid | Epoch[104/600] Iteration[004/008] Valid loss: 0.1017
2023-02-06 10:44:06 | Valid | Epoch[104/600] Iteration[005/008] Valid loss: 0.1026
2023-02-06 10:44:06 | Valid | Epoch[104/600] Iteration[006/008] Valid loss: 0.1031
2023-02-06 10:44:06 | Valid | Epoch[104/600] Iteration[007/008] Valid loss: 0.1069
2023-02-06 10:44:06 | Valid | Epoch[104/600] Iteration[008/008] Valid loss: 0.1049
2023-02-06 10:44:06 | Valid | Epoch[104/600] MIou: 0.9260392988811765
2023-02-06 10:44:06 | Valid | Epoch[104/600] Pixel Accuracy: 0.9867273966471354
2023-02-06 10:44:06 | Valid | Epoch[104/600] Mean Pixel Accuracy: 0.9722948333370387
2023-02-06 10:44:06 | Stage | Epoch[104/600] Train loss:0.0525
2023-02-06 10:44:06 | Stage | Epoch[104/600] Valid loss:0.1049
2023-02-06 10:44:06 | Stage | Epoch[104/600] LR:0.01

2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[001/030] Train loss: 0.0534
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[002/030] Train loss: 0.0528
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[003/030] Train loss: 0.0517
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[004/030] Train loss: 0.0515
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[005/030] Train loss: 0.0507
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[006/030] Train loss: 0.0511
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[007/030] Train loss: 0.0510
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[008/030] Train loss: 0.0510
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[009/030] Train loss: 0.0508
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[010/030] Train loss: 0.0508
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[011/030] Train loss: 0.0507
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[012/030] Train loss: 0.0507
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[013/030] Train loss: 0.0511
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[014/030] Train loss: 0.0512
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[015/030] Train loss: 0.0510
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[016/030] Train loss: 0.0512
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[017/030] Train loss: 0.0513
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[018/030] Train loss: 0.0513
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[019/030] Train loss: 0.0512
2023-02-06 10:44:07 | Train | Epoch[105/600] Iteration[020/030] Train loss: 0.0514
2023-02-06 10:44:08 | Train | Epoch[105/600] Iteration[021/030] Train loss: 0.0513
2023-02-06 10:44:08 | Train | Epoch[105/600] Iteration[022/030] Train loss: 0.0515
2023-02-06 10:44:08 | Train | Epoch[105/600] Iteration[023/030] Train loss: 0.0514
2023-02-06 10:44:08 | Train | Epoch[105/600] Iteration[024/030] Train loss: 0.0514
2023-02-06 10:44:08 | Train | Epoch[105/600] Iteration[025/030] Train loss: 0.0513
2023-02-06 10:44:08 | Train | Epoch[105/600] Iteration[026/030] Train loss: 0.0513
2023-02-06 10:44:08 | Train | Epoch[105/600] Iteration[027/030] Train loss: 0.0516
2023-02-06 10:44:08 | Train | Epoch[105/600] Iteration[028/030] Train loss: 0.0515
2023-02-06 10:44:08 | Train | Epoch[105/600] Iteration[029/030] Train loss: 0.0518
2023-02-06 10:44:08 | Train | Epoch[105/600] Iteration[030/030] Train loss: 0.0517
2023-02-06 10:44:08 | Valid | Epoch[105/600] Iteration[001/008] Valid loss: 0.0640
2023-02-06 10:44:08 | Valid | Epoch[105/600] Iteration[002/008] Valid loss: 0.0577
2023-02-06 10:44:08 | Valid | Epoch[105/600] Iteration[003/008] Valid loss: 0.0562
2023-02-06 10:44:08 | Valid | Epoch[105/600] Iteration[004/008] Valid loss: 0.0552
2023-02-06 10:44:08 | Valid | Epoch[105/600] Iteration[005/008] Valid loss: 0.0553
2023-02-06 10:44:08 | Valid | Epoch[105/600] Iteration[006/008] Valid loss: 0.0552
2023-02-06 10:44:08 | Valid | Epoch[105/600] Iteration[007/008] Valid loss: 0.0552
2023-02-06 10:44:08 | Valid | Epoch[105/600] Iteration[008/008] Valid loss: 0.0550
2023-02-06 10:44:09 | Valid | Epoch[105/600] MIou: 0.9141783013630758
2023-02-06 10:44:09 | Valid | Epoch[105/600] Pixel Accuracy: 0.9857190450032552
2023-02-06 10:44:09 | Valid | Epoch[105/600] Mean Pixel Accuracy: 0.926564740744836
2023-02-06 10:44:09 | Stage | Epoch[105/600] Train loss:0.0517
2023-02-06 10:44:09 | Stage | Epoch[105/600] Valid loss:0.0550
2023-02-06 10:44:09 | Stage | Epoch[105/600] LR:0.01

2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[001/030] Train loss: 0.0519
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[002/030] Train loss: 0.0501
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[003/030] Train loss: 0.0527
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[004/030] Train loss: 0.0531
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[005/030] Train loss: 0.0543
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[006/030] Train loss: 0.0536
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[007/030] Train loss: 0.0535
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[008/030] Train loss: 0.0529
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[009/030] Train loss: 0.0530
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[010/030] Train loss: 0.0529
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[011/030] Train loss: 0.0528
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[012/030] Train loss: 0.0521
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[013/030] Train loss: 0.0519
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[014/030] Train loss: 0.0519
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[015/030] Train loss: 0.0517
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[016/030] Train loss: 0.0517
2023-02-06 10:44:09 | Train | Epoch[106/600] Iteration[017/030] Train loss: 0.0517
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[018/030] Train loss: 0.0516
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[019/030] Train loss: 0.0516
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[020/030] Train loss: 0.0515
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[021/030] Train loss: 0.0516
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[022/030] Train loss: 0.0515
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[023/030] Train loss: 0.0514
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[024/030] Train loss: 0.0513
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[025/030] Train loss: 0.0513
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[026/030] Train loss: 0.0512
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[027/030] Train loss: 0.0511
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[028/030] Train loss: 0.0511
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[029/030] Train loss: 0.0511
2023-02-06 10:44:10 | Train | Epoch[106/600] Iteration[030/030] Train loss: 0.0511
2023-02-06 10:44:10 | Valid | Epoch[106/600] Iteration[001/008] Valid loss: 0.0580
2023-02-06 10:44:10 | Valid | Epoch[106/600] Iteration[002/008] Valid loss: 0.0541
2023-02-06 10:44:10 | Valid | Epoch[106/600] Iteration[003/008] Valid loss: 0.0539
2023-02-06 10:44:10 | Valid | Epoch[106/600] Iteration[004/008] Valid loss: 0.0531
2023-02-06 10:44:11 | Valid | Epoch[106/600] Iteration[005/008] Valid loss: 0.0537
2023-02-06 10:44:11 | Valid | Epoch[106/600] Iteration[006/008] Valid loss: 0.0534
2023-02-06 10:44:11 | Valid | Epoch[106/600] Iteration[007/008] Valid loss: 0.0542
2023-02-06 10:44:11 | Valid | Epoch[106/600] Iteration[008/008] Valid loss: 0.0540
2023-02-06 10:44:11 | Valid | Epoch[106/600] MIou: 0.9253808741765209
2023-02-06 10:44:11 | Valid | Epoch[106/600] Pixel Accuracy: 0.9875081380208334
2023-02-06 10:44:11 | Valid | Epoch[106/600] Mean Pixel Accuracy: 0.9396203603292685
2023-02-06 10:44:11 | Stage | Epoch[106/600] Train loss:0.0511
2023-02-06 10:44:11 | Stage | Epoch[106/600] Valid loss:0.0540
2023-02-06 10:44:11 | Stage | Epoch[106/600] LR:0.01

2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[001/030] Train loss: 0.0480
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[002/030] Train loss: 0.0486
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[003/030] Train loss: 0.0504
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[004/030] Train loss: 0.0519
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[005/030] Train loss: 0.0513
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[006/030] Train loss: 0.0508
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[007/030] Train loss: 0.0504
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[008/030] Train loss: 0.0500
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[009/030] Train loss: 0.0498
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[010/030] Train loss: 0.0500
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[011/030] Train loss: 0.0502
2023-02-06 10:44:11 | Train | Epoch[107/600] Iteration[012/030] Train loss: 0.0504
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[013/030] Train loss: 0.0503
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[014/030] Train loss: 0.0502
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[015/030] Train loss: 0.0506
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[016/030] Train loss: 0.0503
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[017/030] Train loss: 0.0505
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[018/030] Train loss: 0.0503
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[019/030] Train loss: 0.0503
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[020/030] Train loss: 0.0503
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[021/030] Train loss: 0.0501
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[022/030] Train loss: 0.0502
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[023/030] Train loss: 0.0500
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[024/030] Train loss: 0.0499
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[025/030] Train loss: 0.0499
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[026/030] Train loss: 0.0498
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[027/030] Train loss: 0.0499
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[028/030] Train loss: 0.0498
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[029/030] Train loss: 0.0499
2023-02-06 10:44:12 | Train | Epoch[107/600] Iteration[030/030] Train loss: 0.0499
2023-02-06 10:44:13 | Valid | Epoch[107/600] Iteration[001/008] Valid loss: 0.3799
2023-02-06 10:44:13 | Valid | Epoch[107/600] Iteration[002/008] Valid loss: 0.3249
2023-02-06 10:44:13 | Valid | Epoch[107/600] Iteration[003/008] Valid loss: 0.3196
2023-02-06 10:44:13 | Valid | Epoch[107/600] Iteration[004/008] Valid loss: 0.3205
2023-02-06 10:44:13 | Valid | Epoch[107/600] Iteration[005/008] Valid loss: 0.3353
2023-02-06 10:44:13 | Valid | Epoch[107/600] Iteration[006/008] Valid loss: 0.3244
2023-02-06 10:44:13 | Valid | Epoch[107/600] Iteration[007/008] Valid loss: 0.3449
2023-02-06 10:44:13 | Valid | Epoch[107/600] Iteration[008/008] Valid loss: 0.3507
2023-02-06 10:44:13 | Valid | Epoch[107/600] MIou: 0.8603839478334376
2023-02-06 10:44:13 | Valid | Epoch[107/600] Pixel Accuracy: 0.9707082112630209
2023-02-06 10:44:13 | Valid | Epoch[107/600] Mean Pixel Accuracy: 0.9786500732335796
2023-02-06 10:44:13 | Stage | Epoch[107/600] Train loss:0.0499
2023-02-06 10:44:13 | Stage | Epoch[107/600] Valid loss:0.3507
2023-02-06 10:44:13 | Stage | Epoch[107/600] LR:0.01

2023-02-06 10:44:13 | Train | Epoch[108/600] Iteration[001/030] Train loss: 0.0473
2023-02-06 10:44:13 | Train | Epoch[108/600] Iteration[002/030] Train loss: 0.0482
2023-02-06 10:44:13 | Train | Epoch[108/600] Iteration[003/030] Train loss: 0.0482
2023-02-06 10:44:13 | Train | Epoch[108/600] Iteration[004/030] Train loss: 0.0486
2023-02-06 10:44:13 | Train | Epoch[108/600] Iteration[005/030] Train loss: 0.0484
2023-02-06 10:44:13 | Train | Epoch[108/600] Iteration[006/030] Train loss: 0.0492
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[007/030] Train loss: 0.0494
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[008/030] Train loss: 0.0492
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[009/030] Train loss: 0.0492
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[010/030] Train loss: 0.0499
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[011/030] Train loss: 0.0499
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[012/030] Train loss: 0.0498
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[013/030] Train loss: 0.0497
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[014/030] Train loss: 0.0500
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[015/030] Train loss: 0.0504
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[016/030] Train loss: 0.0503
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[017/030] Train loss: 0.0506
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[018/030] Train loss: 0.0504
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[019/030] Train loss: 0.0503
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[020/030] Train loss: 0.0501
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[021/030] Train loss: 0.0501
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[022/030] Train loss: 0.0500
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[023/030] Train loss: 0.0501
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[024/030] Train loss: 0.0502
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[025/030] Train loss: 0.0501
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[026/030] Train loss: 0.0501
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[027/030] Train loss: 0.0501
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[028/030] Train loss: 0.0500
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[029/030] Train loss: 0.0499
2023-02-06 10:44:14 | Train | Epoch[108/600] Iteration[030/030] Train loss: 0.0499
2023-02-06 10:44:15 | Valid | Epoch[108/600] Iteration[001/008] Valid loss: 0.0648
2023-02-06 10:44:15 | Valid | Epoch[108/600] Iteration[002/008] Valid loss: 0.0566
2023-02-06 10:44:15 | Valid | Epoch[108/600] Iteration[003/008] Valid loss: 0.0549
2023-02-06 10:44:15 | Valid | Epoch[108/600] Iteration[004/008] Valid loss: 0.0538
2023-02-06 10:44:15 | Valid | Epoch[108/600] Iteration[005/008] Valid loss: 0.0544
2023-02-06 10:44:15 | Valid | Epoch[108/600] Iteration[006/008] Valid loss: 0.0540
2023-02-06 10:44:15 | Valid | Epoch[108/600] Iteration[007/008] Valid loss: 0.0552
2023-02-06 10:44:15 | Valid | Epoch[108/600] Iteration[008/008] Valid loss: 0.0546
2023-02-06 10:44:15 | Valid | Epoch[108/600] MIou: 0.9364493018850883
2023-02-06 10:44:15 | Valid | Epoch[108/600] Pixel Accuracy: 0.9892323811848959
2023-02-06 10:44:15 | Valid | Epoch[108/600] Mean Pixel Accuracy: 0.9554364836052569
2023-02-06 10:44:15 | Stage | Epoch[108/600] Train loss:0.0499
2023-02-06 10:44:15 | Stage | Epoch[108/600] Valid loss:0.0546
2023-02-06 10:44:15 | Stage | Epoch[108/600] LR:0.01

2023-02-06 10:44:15 | Train | Epoch[109/600] Iteration[001/030] Train loss: 0.0470
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[002/030] Train loss: 0.0471
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[003/030] Train loss: 0.0468
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[004/030] Train loss: 0.0472
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[005/030] Train loss: 0.0486
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[006/030] Train loss: 0.0484
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[007/030] Train loss: 0.0483
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[008/030] Train loss: 0.0483
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[009/030] Train loss: 0.0481
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[010/030] Train loss: 0.0480
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[011/030] Train loss: 0.0480
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[012/030] Train loss: 0.0479
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[013/030] Train loss: 0.0478
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[014/030] Train loss: 0.0480
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[015/030] Train loss: 0.0480
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[016/030] Train loss: 0.0482
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[017/030] Train loss: 0.0482
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[018/030] Train loss: 0.0481
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[019/030] Train loss: 0.0480
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[020/030] Train loss: 0.0482
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[021/030] Train loss: 0.0480
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[022/030] Train loss: 0.0481
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[023/030] Train loss: 0.0481
2023-02-06 10:44:16 | Train | Epoch[109/600] Iteration[024/030] Train loss: 0.0481
2023-02-06 10:44:17 | Train | Epoch[109/600] Iteration[025/030] Train loss: 0.0481
2023-02-06 10:44:17 | Train | Epoch[109/600] Iteration[026/030] Train loss: 0.0481
2023-02-06 10:44:17 | Train | Epoch[109/600] Iteration[027/030] Train loss: 0.0482
2023-02-06 10:44:17 | Train | Epoch[109/600] Iteration[028/030] Train loss: 0.0482
2023-02-06 10:44:17 | Train | Epoch[109/600] Iteration[029/030] Train loss: 0.0483
2023-02-06 10:44:17 | Train | Epoch[109/600] Iteration[030/030] Train loss: 0.0482
2023-02-06 10:44:17 | Valid | Epoch[109/600] Iteration[001/008] Valid loss: 0.0622
2023-02-06 10:44:17 | Valid | Epoch[109/600] Iteration[002/008] Valid loss: 0.0564
2023-02-06 10:44:17 | Valid | Epoch[109/600] Iteration[003/008] Valid loss: 0.0552
2023-02-06 10:44:17 | Valid | Epoch[109/600] Iteration[004/008] Valid loss: 0.0543
2023-02-06 10:44:17 | Valid | Epoch[109/600] Iteration[005/008] Valid loss: 0.0552
2023-02-06 10:44:17 | Valid | Epoch[109/600] Iteration[006/008] Valid loss: 0.0552
2023-02-06 10:44:17 | Valid | Epoch[109/600] Iteration[007/008] Valid loss: 0.0565
2023-02-06 10:44:17 | Valid | Epoch[109/600] Iteration[008/008] Valid loss: 0.0561
2023-02-06 10:44:17 | Valid | Epoch[109/600] MIou: 0.9375352562766239
2023-02-06 10:44:17 | Valid | Epoch[109/600] Pixel Accuracy: 0.9893290201822916
2023-02-06 10:44:17 | Valid | Epoch[109/600] Mean Pixel Accuracy: 0.9602576350968632
2023-02-06 10:44:17 | Stage | Epoch[109/600] Train loss:0.0482
2023-02-06 10:44:17 | Stage | Epoch[109/600] Valid loss:0.0561
2023-02-06 10:44:17 | Stage | Epoch[109/600] LR:0.01

2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[001/030] Train loss: 0.0442
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[002/030] Train loss: 0.0451
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[003/030] Train loss: 0.0470
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[004/030] Train loss: 0.0477
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[005/030] Train loss: 0.0478
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[006/030] Train loss: 0.0476
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[007/030] Train loss: 0.0478
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[008/030] Train loss: 0.0479
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[009/030] Train loss: 0.0480
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[010/030] Train loss: 0.0478
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[011/030] Train loss: 0.0474
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[012/030] Train loss: 0.0473
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[013/030] Train loss: 0.0473
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[014/030] Train loss: 0.0472
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[015/030] Train loss: 0.0474
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[016/030] Train loss: 0.0477
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[017/030] Train loss: 0.0476
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[018/030] Train loss: 0.0478
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[019/030] Train loss: 0.0478
2023-02-06 10:44:18 | Train | Epoch[110/600] Iteration[020/030] Train loss: 0.0477
2023-02-06 10:44:19 | Train | Epoch[110/600] Iteration[021/030] Train loss: 0.0478
2023-02-06 10:44:19 | Train | Epoch[110/600] Iteration[022/030] Train loss: 0.0479
2023-02-06 10:44:19 | Train | Epoch[110/600] Iteration[023/030] Train loss: 0.0478
2023-02-06 10:44:19 | Train | Epoch[110/600] Iteration[024/030] Train loss: 0.0478
2023-02-06 10:44:19 | Train | Epoch[110/600] Iteration[025/030] Train loss: 0.0479
2023-02-06 10:44:19 | Train | Epoch[110/600] Iteration[026/030] Train loss: 0.0480
2023-02-06 10:44:19 | Train | Epoch[110/600] Iteration[027/030] Train loss: 0.0480
2023-02-06 10:44:19 | Train | Epoch[110/600] Iteration[028/030] Train loss: 0.0481
2023-02-06 10:44:19 | Train | Epoch[110/600] Iteration[029/030] Train loss: 0.0482
2023-02-06 10:44:19 | Train | Epoch[110/600] Iteration[030/030] Train loss: 0.0482
2023-02-06 10:44:19 | Valid | Epoch[110/600] Iteration[001/008] Valid loss: 0.0894
2023-02-06 10:44:19 | Valid | Epoch[110/600] Iteration[002/008] Valid loss: 0.0915
2023-02-06 10:44:19 | Valid | Epoch[110/600] Iteration[003/008] Valid loss: 0.0943
2023-02-06 10:44:19 | Valid | Epoch[110/600] Iteration[004/008] Valid loss: 0.0939
2023-02-06 10:44:19 | Valid | Epoch[110/600] Iteration[005/008] Valid loss: 0.0952
2023-02-06 10:44:19 | Valid | Epoch[110/600] Iteration[006/008] Valid loss: 0.0939
2023-02-06 10:44:19 | Valid | Epoch[110/600] Iteration[007/008] Valid loss: 0.0921
2023-02-06 10:44:19 | Valid | Epoch[110/600] Iteration[008/008] Valid loss: 0.0943
2023-02-06 10:44:20 | Valid | Epoch[110/600] MIou: 0.693489880015934
2023-02-06 10:44:20 | Valid | Epoch[110/600] Pixel Accuracy: 0.9493929545084635
2023-02-06 10:44:20 | Valid | Epoch[110/600] Mean Pixel Accuracy: 0.7198397837502992
2023-02-06 10:44:20 | Stage | Epoch[110/600] Train loss:0.0482
2023-02-06 10:44:20 | Stage | Epoch[110/600] Valid loss:0.0943
2023-02-06 10:44:20 | Stage | Epoch[110/600] LR:0.01

2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[001/030] Train loss: 0.0517
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[002/030] Train loss: 0.0506
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[003/030] Train loss: 0.0484
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[004/030] Train loss: 0.0479
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[005/030] Train loss: 0.0473
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[006/030] Train loss: 0.0472
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[007/030] Train loss: 0.0481
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[008/030] Train loss: 0.0480
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[009/030] Train loss: 0.0485
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[010/030] Train loss: 0.0481
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[011/030] Train loss: 0.0478
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[012/030] Train loss: 0.0479
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[013/030] Train loss: 0.0481
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[014/030] Train loss: 0.0482
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[015/030] Train loss: 0.0483
2023-02-06 10:44:20 | Train | Epoch[111/600] Iteration[016/030] Train loss: 0.0482
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[017/030] Train loss: 0.0479
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[018/030] Train loss: 0.0479
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[019/030] Train loss: 0.0480
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[020/030] Train loss: 0.0479
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[021/030] Train loss: 0.0477
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[022/030] Train loss: 0.0479
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[023/030] Train loss: 0.0480
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[024/030] Train loss: 0.0481
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[025/030] Train loss: 0.0481
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[026/030] Train loss: 0.0480
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[027/030] Train loss: 0.0480
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[028/030] Train loss: 0.0478
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[029/030] Train loss: 0.0478
2023-02-06 10:44:21 | Train | Epoch[111/600] Iteration[030/030] Train loss: 0.0479
2023-02-06 10:44:21 | Valid | Epoch[111/600] Iteration[001/008] Valid loss: 0.0574
2023-02-06 10:44:21 | Valid | Epoch[111/600] Iteration[002/008] Valid loss: 0.0553
2023-02-06 10:44:21 | Valid | Epoch[111/600] Iteration[003/008] Valid loss: 0.0559
2023-02-06 10:44:21 | Valid | Epoch[111/600] Iteration[004/008] Valid loss: 0.0550
2023-02-06 10:44:22 | Valid | Epoch[111/600] Iteration[005/008] Valid loss: 0.0554
2023-02-06 10:44:22 | Valid | Epoch[111/600] Iteration[006/008] Valid loss: 0.0549
2023-02-06 10:44:22 | Valid | Epoch[111/600] Iteration[007/008] Valid loss: 0.0546
2023-02-06 10:44:22 | Valid | Epoch[111/600] Iteration[008/008] Valid loss: 0.0548
2023-02-06 10:44:22 | Valid | Epoch[111/600] MIou: 0.8799300413019909
2023-02-06 10:44:22 | Valid | Epoch[111/600] Pixel Accuracy: 0.9802055358886719
2023-02-06 10:44:22 | Valid | Epoch[111/600] Mean Pixel Accuracy: 0.8910837477911601
2023-02-06 10:44:22 | Stage | Epoch[111/600] Train loss:0.0479
2023-02-06 10:44:22 | Stage | Epoch[111/600] Valid loss:0.0548
2023-02-06 10:44:22 | Stage | Epoch[111/600] LR:0.01

2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[001/030] Train loss: 0.0457
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[002/030] Train loss: 0.0469
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[003/030] Train loss: 0.0457
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[004/030] Train loss: 0.0491
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[005/030] Train loss: 0.0498
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[006/030] Train loss: 0.0492
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[007/030] Train loss: 0.0498
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[008/030] Train loss: 0.0494
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[009/030] Train loss: 0.0499
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[010/030] Train loss: 0.0500
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[011/030] Train loss: 0.0498
2023-02-06 10:44:22 | Train | Epoch[112/600] Iteration[012/030] Train loss: 0.0494
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[013/030] Train loss: 0.0492
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[014/030] Train loss: 0.0490
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[015/030] Train loss: 0.0493
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[016/030] Train loss: 0.0494
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[017/030] Train loss: 0.0493
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[018/030] Train loss: 0.0492
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[019/030] Train loss: 0.0490
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[020/030] Train loss: 0.0488
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[021/030] Train loss: 0.0487
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[022/030] Train loss: 0.0487
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[023/030] Train loss: 0.0484
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[024/030] Train loss: 0.0485
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[025/030] Train loss: 0.0484
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[026/030] Train loss: 0.0484
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[027/030] Train loss: 0.0482
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[028/030] Train loss: 0.0481
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[029/030] Train loss: 0.0481
2023-02-06 10:44:23 | Train | Epoch[112/600] Iteration[030/030] Train loss: 0.0481
2023-02-06 10:44:24 | Valid | Epoch[112/600] Iteration[001/008] Valid loss: 0.1070
2023-02-06 10:44:24 | Valid | Epoch[112/600] Iteration[002/008] Valid loss: 0.1057
2023-02-06 10:44:24 | Valid | Epoch[112/600] Iteration[003/008] Valid loss: 0.1066
2023-02-06 10:44:24 | Valid | Epoch[112/600] Iteration[004/008] Valid loss: 0.1072
2023-02-06 10:44:24 | Valid | Epoch[112/600] Iteration[005/008] Valid loss: 0.1081
2023-02-06 10:44:24 | Valid | Epoch[112/600] Iteration[006/008] Valid loss: 0.1067
2023-02-06 10:44:24 | Valid | Epoch[112/600] Iteration[007/008] Valid loss: 0.1060
2023-02-06 10:44:24 | Valid | Epoch[112/600] Iteration[008/008] Valid loss: 0.1076
2023-02-06 10:44:24 | Valid | Epoch[112/600] MIou: 0.6814355771438665
2023-02-06 10:44:24 | Valid | Epoch[112/600] Pixel Accuracy: 0.9463462829589844
2023-02-06 10:44:24 | Valid | Epoch[112/600] Mean Pixel Accuracy: 0.7128392070591595
2023-02-06 10:44:24 | Stage | Epoch[112/600] Train loss:0.0481
2023-02-06 10:44:24 | Stage | Epoch[112/600] Valid loss:0.1076
2023-02-06 10:44:24 | Stage | Epoch[112/600] LR:0.01

2023-02-06 10:44:24 | Train | Epoch[113/600] Iteration[001/030] Train loss: 0.0481
2023-02-06 10:44:24 | Train | Epoch[113/600] Iteration[002/030] Train loss: 0.0458
2023-02-06 10:44:24 | Train | Epoch[113/600] Iteration[003/030] Train loss: 0.0459
2023-02-06 10:44:24 | Train | Epoch[113/600] Iteration[004/030] Train loss: 0.0468
2023-02-06 10:44:24 | Train | Epoch[113/600] Iteration[005/030] Train loss: 0.0467
2023-02-06 10:44:24 | Train | Epoch[113/600] Iteration[006/030] Train loss: 0.0467
2023-02-06 10:44:24 | Train | Epoch[113/600] Iteration[007/030] Train loss: 0.0470
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[008/030] Train loss: 0.0473
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[009/030] Train loss: 0.0475
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[010/030] Train loss: 0.0473
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[011/030] Train loss: 0.0471
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[012/030] Train loss: 0.0468
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[013/030] Train loss: 0.0469
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[014/030] Train loss: 0.0469
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[015/030] Train loss: 0.0470
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[016/030] Train loss: 0.0471
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[017/030] Train loss: 0.0471
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[018/030] Train loss: 0.0473
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[019/030] Train loss: 0.0473
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[020/030] Train loss: 0.0475
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[021/030] Train loss: 0.0474
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[022/030] Train loss: 0.0475
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[023/030] Train loss: 0.0474
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[024/030] Train loss: 0.0475
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[025/030] Train loss: 0.0476
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[026/030] Train loss: 0.0476
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[027/030] Train loss: 0.0474
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[028/030] Train loss: 0.0475
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[029/030] Train loss: 0.0475
2023-02-06 10:44:25 | Train | Epoch[113/600] Iteration[030/030] Train loss: 0.0473
2023-02-06 10:44:26 | Valid | Epoch[113/600] Iteration[001/008] Valid loss: 0.0601
2023-02-06 10:44:26 | Valid | Epoch[113/600] Iteration[002/008] Valid loss: 0.0563
2023-02-06 10:44:26 | Valid | Epoch[113/600] Iteration[003/008] Valid loss: 0.0555
2023-02-06 10:44:26 | Valid | Epoch[113/600] Iteration[004/008] Valid loss: 0.0550
2023-02-06 10:44:26 | Valid | Epoch[113/600] Iteration[005/008] Valid loss: 0.0551
2023-02-06 10:44:26 | Valid | Epoch[113/600] Iteration[006/008] Valid loss: 0.0564
2023-02-06 10:44:26 | Valid | Epoch[113/600] Iteration[007/008] Valid loss: 0.0569
2023-02-06 10:44:26 | Valid | Epoch[113/600] Iteration[008/008] Valid loss: 0.0563
2023-02-06 10:44:26 | Valid | Epoch[113/600] MIou: 0.9148911390732986
2023-02-06 10:44:26 | Valid | Epoch[113/600] Pixel Accuracy: 0.9858614603678385
2023-02-06 10:44:26 | Valid | Epoch[113/600] Mean Pixel Accuracy: 0.9265098684013258
2023-02-06 10:44:26 | Stage | Epoch[113/600] Train loss:0.0473
2023-02-06 10:44:26 | Stage | Epoch[113/600] Valid loss:0.0563
2023-02-06 10:44:26 | Stage | Epoch[113/600] LR:0.01

2023-02-06 10:44:26 | Train | Epoch[114/600] Iteration[001/030] Train loss: 0.0491
2023-02-06 10:44:26 | Train | Epoch[114/600] Iteration[002/030] Train loss: 0.0481
2023-02-06 10:44:26 | Train | Epoch[114/600] Iteration[003/030] Train loss: 0.0477
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[004/030] Train loss: 0.0487
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[005/030] Train loss: 0.0482
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[006/030] Train loss: 0.0482
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[007/030] Train loss: 0.0473
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[008/030] Train loss: 0.0469
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[009/030] Train loss: 0.0471
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[010/030] Train loss: 0.0473
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[011/030] Train loss: 0.0471
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[012/030] Train loss: 0.0473
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[013/030] Train loss: 0.0475
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[014/030] Train loss: 0.0475
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[015/030] Train loss: 0.0474
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[016/030] Train loss: 0.0475
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[017/030] Train loss: 0.0475
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[018/030] Train loss: 0.0476
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[019/030] Train loss: 0.0475
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[020/030] Train loss: 0.0473
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[021/030] Train loss: 0.0474
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[022/030] Train loss: 0.0472
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[023/030] Train loss: 0.0471
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[024/030] Train loss: 0.0471
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[025/030] Train loss: 0.0471
2023-02-06 10:44:27 | Train | Epoch[114/600] Iteration[026/030] Train loss: 0.0471
2023-02-06 10:44:28 | Train | Epoch[114/600] Iteration[027/030] Train loss: 0.0470
2023-02-06 10:44:28 | Train | Epoch[114/600] Iteration[028/030] Train loss: 0.0469
2023-02-06 10:44:28 | Train | Epoch[114/600] Iteration[029/030] Train loss: 0.0469
2023-02-06 10:44:28 | Train | Epoch[114/600] Iteration[030/030] Train loss: 0.0469
2023-02-06 10:44:28 | Valid | Epoch[114/600] Iteration[001/008] Valid loss: 0.1067
2023-02-06 10:44:28 | Valid | Epoch[114/600] Iteration[002/008] Valid loss: 0.1076
2023-02-06 10:44:28 | Valid | Epoch[114/600] Iteration[003/008] Valid loss: 0.1111
2023-02-06 10:44:28 | Valid | Epoch[114/600] Iteration[004/008] Valid loss: 0.1108
2023-02-06 10:44:28 | Valid | Epoch[114/600] Iteration[005/008] Valid loss: 0.1127
2023-02-06 10:44:28 | Valid | Epoch[114/600] Iteration[006/008] Valid loss: 0.1108
2023-02-06 10:44:28 | Valid | Epoch[114/600] Iteration[007/008] Valid loss: 0.1084
2023-02-06 10:44:28 | Valid | Epoch[114/600] Iteration[008/008] Valid loss: 0.1115
2023-02-06 10:44:28 | Valid | Epoch[114/600] MIou: 0.6543879787627259
2023-02-06 10:44:28 | Valid | Epoch[114/600] Pixel Accuracy: 0.9429003397623698
2023-02-06 10:44:28 | Valid | Epoch[114/600] Mean Pixel Accuracy: 0.6839284205994053
2023-02-06 10:44:28 | Stage | Epoch[114/600] Train loss:0.0469
2023-02-06 10:44:28 | Stage | Epoch[114/600] Valid loss:0.1115
2023-02-06 10:44:28 | Stage | Epoch[114/600] LR:0.01

2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[001/030] Train loss: 0.0471
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[002/030] Train loss: 0.0476
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[003/030] Train loss: 0.0468
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[004/030] Train loss: 0.0469
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[005/030] Train loss: 0.0464
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[006/030] Train loss: 0.0462
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[007/030] Train loss: 0.0463
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[008/030] Train loss: 0.0459
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[009/030] Train loss: 0.0458
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[010/030] Train loss: 0.0453
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[011/030] Train loss: 0.0453
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[012/030] Train loss: 0.0452
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[013/030] Train loss: 0.0452
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[014/030] Train loss: 0.0453
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[015/030] Train loss: 0.0453
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[016/030] Train loss: 0.0453
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[017/030] Train loss: 0.0452
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[018/030] Train loss: 0.0451
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[019/030] Train loss: 0.0453
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[020/030] Train loss: 0.0453
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[021/030] Train loss: 0.0452
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[022/030] Train loss: 0.0452
2023-02-06 10:44:29 | Train | Epoch[115/600] Iteration[023/030] Train loss: 0.0455
2023-02-06 10:44:30 | Train | Epoch[115/600] Iteration[024/030] Train loss: 0.0455
2023-02-06 10:44:30 | Train | Epoch[115/600] Iteration[025/030] Train loss: 0.0455
2023-02-06 10:44:30 | Train | Epoch[115/600] Iteration[026/030] Train loss: 0.0457
2023-02-06 10:44:30 | Train | Epoch[115/600] Iteration[027/030] Train loss: 0.0458
2023-02-06 10:44:30 | Train | Epoch[115/600] Iteration[028/030] Train loss: 0.0458
2023-02-06 10:44:30 | Train | Epoch[115/600] Iteration[029/030] Train loss: 0.0462
2023-02-06 10:44:30 | Train | Epoch[115/600] Iteration[030/030] Train loss: 0.0463
2023-02-06 10:44:30 | Valid | Epoch[115/600] Iteration[001/008] Valid loss: 1.8197
2023-02-06 10:44:30 | Valid | Epoch[115/600] Iteration[002/008] Valid loss: 1.7968
2023-02-06 10:44:30 | Valid | Epoch[115/600] Iteration[003/008] Valid loss: 1.8402
2023-02-06 10:44:30 | Valid | Epoch[115/600] Iteration[004/008] Valid loss: 1.8831
2023-02-06 10:44:30 | Valid | Epoch[115/600] Iteration[005/008] Valid loss: 1.9348
2023-02-06 10:44:30 | Valid | Epoch[115/600] Iteration[006/008] Valid loss: 1.9036
2023-02-06 10:44:30 | Valid | Epoch[115/600] Iteration[007/008] Valid loss: 1.9811
2023-02-06 10:44:30 | Valid | Epoch[115/600] Iteration[008/008] Valid loss: 2.0517
2023-02-06 10:44:30 | Valid | Epoch[115/600] MIou: 0.7601632815565283
2023-02-06 10:44:30 | Valid | Epoch[115/600] Pixel Accuracy: 0.9372113545735677
2023-02-06 10:44:30 | Valid | Epoch[115/600] Mean Pixel Accuracy: 0.9644298238601556
2023-02-06 10:44:30 | Stage | Epoch[115/600] Train loss:0.0463
2023-02-06 10:44:30 | Stage | Epoch[115/600] Valid loss:2.0517
2023-02-06 10:44:30 | Stage | Epoch[115/600] LR:0.01

2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[001/030] Train loss: 0.0475
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[002/030] Train loss: 0.0467
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[003/030] Train loss: 0.0472
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[004/030] Train loss: 0.0473
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[005/030] Train loss: 0.0469
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[006/030] Train loss: 0.0467
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[007/030] Train loss: 0.0470
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[008/030] Train loss: 0.0473
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[009/030] Train loss: 0.0471
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[010/030] Train loss: 0.0473
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[011/030] Train loss: 0.0470
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[012/030] Train loss: 0.0467
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[013/030] Train loss: 0.0466
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[014/030] Train loss: 0.0464
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[015/030] Train loss: 0.0462
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[016/030] Train loss: 0.0463
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[017/030] Train loss: 0.0463
2023-02-06 10:44:31 | Train | Epoch[116/600] Iteration[018/030] Train loss: 0.0464
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[019/030] Train loss: 0.0462
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[020/030] Train loss: 0.0461
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[021/030] Train loss: 0.0460
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[022/030] Train loss: 0.0460
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[023/030] Train loss: 0.0461
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[024/030] Train loss: 0.0462
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[025/030] Train loss: 0.0461
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[026/030] Train loss: 0.0462
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[027/030] Train loss: 0.0463
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[028/030] Train loss: 0.0463
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[029/030] Train loss: 0.0462
2023-02-06 10:44:32 | Train | Epoch[116/600] Iteration[030/030] Train loss: 0.0460
2023-02-06 10:44:32 | Valid | Epoch[116/600] Iteration[001/008] Valid loss: 0.0747
2023-02-06 10:44:32 | Valid | Epoch[116/600] Iteration[002/008] Valid loss: 0.0696
2023-02-06 10:44:32 | Valid | Epoch[116/600] Iteration[003/008] Valid loss: 0.0673
2023-02-06 10:44:32 | Valid | Epoch[116/600] Iteration[004/008] Valid loss: 0.0674
2023-02-06 10:44:32 | Valid | Epoch[116/600] Iteration[005/008] Valid loss: 0.0683
2023-02-06 10:44:32 | Valid | Epoch[116/600] Iteration[006/008] Valid loss: 0.0704
2023-02-06 10:44:32 | Valid | Epoch[116/600] Iteration[007/008] Valid loss: 0.0714
2023-02-06 10:44:32 | Valid | Epoch[116/600] Iteration[008/008] Valid loss: 0.0700
2023-02-06 10:44:33 | Valid | Epoch[116/600] MIou: 0.9070250578425475
2023-02-06 10:44:33 | Valid | Epoch[116/600] Pixel Accuracy: 0.984344482421875
2023-02-06 10:44:33 | Valid | Epoch[116/600] Mean Pixel Accuracy: 0.9249215565147421
2023-02-06 10:44:33 | Stage | Epoch[116/600] Train loss:0.0460
2023-02-06 10:44:33 | Stage | Epoch[116/600] Valid loss:0.0700
2023-02-06 10:44:33 | Stage | Epoch[116/600] LR:0.01

2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[001/030] Train loss: 0.0452
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[002/030] Train loss: 0.0443
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[003/030] Train loss: 0.0454
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[004/030] Train loss: 0.0459
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[005/030] Train loss: 0.0460
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[006/030] Train loss: 0.0464
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[007/030] Train loss: 0.0464
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[008/030] Train loss: 0.0460
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[009/030] Train loss: 0.0462
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[010/030] Train loss: 0.0458
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[011/030] Train loss: 0.0458
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[012/030] Train loss: 0.0456
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[013/030] Train loss: 0.0455
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[014/030] Train loss: 0.0455
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[015/030] Train loss: 0.0455
2023-02-06 10:44:33 | Train | Epoch[117/600] Iteration[016/030] Train loss: 0.0455
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[017/030] Train loss: 0.0454
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[018/030] Train loss: 0.0453
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[019/030] Train loss: 0.0455
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[020/030] Train loss: 0.0454
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[021/030] Train loss: 0.0454
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[022/030] Train loss: 0.0455
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[023/030] Train loss: 0.0456
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[024/030] Train loss: 0.0456
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[025/030] Train loss: 0.0455
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[026/030] Train loss: 0.0454
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[027/030] Train loss: 0.0455
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[028/030] Train loss: 0.0455
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[029/030] Train loss: 0.0456
2023-02-06 10:44:34 | Train | Epoch[117/600] Iteration[030/030] Train loss: 0.0455
2023-02-06 10:44:34 | Valid | Epoch[117/600] Iteration[001/008] Valid loss: 0.4503
2023-02-06 10:44:34 | Valid | Epoch[117/600] Iteration[002/008] Valid loss: 0.3970
2023-02-06 10:44:34 | Valid | Epoch[117/600] Iteration[003/008] Valid loss: 0.3964
2023-02-06 10:44:34 | Valid | Epoch[117/600] Iteration[004/008] Valid loss: 0.3944
2023-02-06 10:44:35 | Valid | Epoch[117/600] Iteration[005/008] Valid loss: 0.4133
2023-02-06 10:44:35 | Valid | Epoch[117/600] Iteration[006/008] Valid loss: 0.4002
2023-02-06 10:44:35 | Valid | Epoch[117/600] Iteration[007/008] Valid loss: 0.4243
2023-02-06 10:44:35 | Valid | Epoch[117/600] Iteration[008/008] Valid loss: 0.4348
2023-02-06 10:44:35 | Valid | Epoch[117/600] MIou: 0.8633060742985585
2023-02-06 10:44:35 | Valid | Epoch[117/600] Pixel Accuracy: 0.97149658203125
2023-02-06 10:44:35 | Valid | Epoch[117/600] Mean Pixel Accuracy: 0.9789312241147083
2023-02-06 10:44:35 | Stage | Epoch[117/600] Train loss:0.0455
2023-02-06 10:44:35 | Stage | Epoch[117/600] Valid loss:0.4348
2023-02-06 10:44:35 | Stage | Epoch[117/600] LR:0.01

2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[001/030] Train loss: 0.0532
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[002/030] Train loss: 0.0524
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[003/030] Train loss: 0.0508
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[004/030] Train loss: 0.0494
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[005/030] Train loss: 0.0485
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[006/030] Train loss: 0.0485
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[007/030] Train loss: 0.0481
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[008/030] Train loss: 0.0481
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[009/030] Train loss: 0.0481
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[010/030] Train loss: 0.0480
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[011/030] Train loss: 0.0479
2023-02-06 10:44:35 | Train | Epoch[118/600] Iteration[012/030] Train loss: 0.0475
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[013/030] Train loss: 0.0474
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[014/030] Train loss: 0.0474
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[015/030] Train loss: 0.0471
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[016/030] Train loss: 0.0471
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[017/030] Train loss: 0.0468
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[018/030] Train loss: 0.0466
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[019/030] Train loss: 0.0464
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[020/030] Train loss: 0.0463
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[021/030] Train loss: 0.0463
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[022/030] Train loss: 0.0461
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[023/030] Train loss: 0.0460
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[024/030] Train loss: 0.0460
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[025/030] Train loss: 0.0458
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[026/030] Train loss: 0.0457
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[027/030] Train loss: 0.0455
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[028/030] Train loss: 0.0455
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[029/030] Train loss: 0.0455
2023-02-06 10:44:36 | Train | Epoch[118/600] Iteration[030/030] Train loss: 0.0455
2023-02-06 10:44:37 | Valid | Epoch[118/600] Iteration[001/008] Valid loss: 0.0517
2023-02-06 10:44:37 | Valid | Epoch[118/600] Iteration[002/008] Valid loss: 0.0478
2023-02-06 10:44:37 | Valid | Epoch[118/600] Iteration[003/008] Valid loss: 0.0475
2023-02-06 10:44:37 | Valid | Epoch[118/600] Iteration[004/008] Valid loss: 0.0467
2023-02-06 10:44:37 | Valid | Epoch[118/600] Iteration[005/008] Valid loss: 0.0472
2023-02-06 10:44:37 | Valid | Epoch[118/600] Iteration[006/008] Valid loss: 0.0469
2023-02-06 10:44:37 | Valid | Epoch[118/600] Iteration[007/008] Valid loss: 0.0472
2023-02-06 10:44:37 | Valid | Epoch[118/600] Iteration[008/008] Valid loss: 0.0471
2023-02-06 10:44:37 | Valid | Epoch[118/600] MIou: 0.9192228960145512
2023-02-06 10:44:37 | Valid | Epoch[118/600] Pixel Accuracy: 0.9865366617838541
2023-02-06 10:44:37 | Valid | Epoch[118/600] Mean Pixel Accuracy: 0.9319533651058756
2023-02-06 10:44:37 | Stage | Epoch[118/600] Train loss:0.0455
2023-02-06 10:44:37 | Stage | Epoch[118/600] Valid loss:0.0471
2023-02-06 10:44:37 | Stage | Epoch[118/600] LR:0.01

2023-02-06 10:44:37 | Train | Epoch[119/600] Iteration[001/030] Train loss: 0.0445
2023-02-06 10:44:37 | Train | Epoch[119/600] Iteration[002/030] Train loss: 0.0434
2023-02-06 10:44:37 | Train | Epoch[119/600] Iteration[003/030] Train loss: 0.0431
2023-02-06 10:44:37 | Train | Epoch[119/600] Iteration[004/030] Train loss: 0.0429
2023-02-06 10:44:37 | Train | Epoch[119/600] Iteration[005/030] Train loss: 0.0425
2023-02-06 10:44:37 | Train | Epoch[119/600] Iteration[006/030] Train loss: 0.0428
2023-02-06 10:44:37 | Train | Epoch[119/600] Iteration[007/030] Train loss: 0.0431
2023-02-06 10:44:37 | Train | Epoch[119/600] Iteration[008/030] Train loss: 0.0430
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[009/030] Train loss: 0.0435
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[010/030] Train loss: 0.0434
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[011/030] Train loss: 0.0434
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[012/030] Train loss: 0.0435
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[013/030] Train loss: 0.0434
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[014/030] Train loss: 0.0437
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[015/030] Train loss: 0.0437
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[016/030] Train loss: 0.0437
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[017/030] Train loss: 0.0436
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[018/030] Train loss: 0.0437
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[019/030] Train loss: 0.0438
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[020/030] Train loss: 0.0440
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[021/030] Train loss: 0.0441
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[022/030] Train loss: 0.0441
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[023/030] Train loss: 0.0442
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[024/030] Train loss: 0.0442
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[025/030] Train loss: 0.0441
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[026/030] Train loss: 0.0441
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[027/030] Train loss: 0.0444
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[028/030] Train loss: 0.0445
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[029/030] Train loss: 0.0445
2023-02-06 10:44:38 | Train | Epoch[119/600] Iteration[030/030] Train loss: 0.0445
2023-02-06 10:44:39 | Valid | Epoch[119/600] Iteration[001/008] Valid loss: 0.1800
2023-02-06 10:44:39 | Valid | Epoch[119/600] Iteration[002/008] Valid loss: 0.1452
2023-02-06 10:44:39 | Valid | Epoch[119/600] Iteration[003/008] Valid loss: 0.1369
2023-02-06 10:44:39 | Valid | Epoch[119/600] Iteration[004/008] Valid loss: 0.1355
2023-02-06 10:44:39 | Valid | Epoch[119/600] Iteration[005/008] Valid loss: 0.1363
2023-02-06 10:44:39 | Valid | Epoch[119/600] Iteration[006/008] Valid loss: 0.1346
2023-02-06 10:44:39 | Valid | Epoch[119/600] Iteration[007/008] Valid loss: 0.1426
2023-02-06 10:44:39 | Valid | Epoch[119/600] Iteration[008/008] Valid loss: 0.1425
2023-02-06 10:44:39 | Valid | Epoch[119/600] MIou: 0.8999471983515688
2023-02-06 10:44:39 | Valid | Epoch[119/600] Pixel Accuracy: 0.9807484944661459
2023-02-06 10:44:39 | Valid | Epoch[119/600] Mean Pixel Accuracy: 0.9793815850981187
2023-02-06 10:44:39 | Stage | Epoch[119/600] Train loss:0.0445
2023-02-06 10:44:39 | Stage | Epoch[119/600] Valid loss:0.1425
2023-02-06 10:44:39 | Stage | Epoch[119/600] LR:0.01

2023-02-06 10:44:39 | Train | Epoch[120/600] Iteration[001/030] Train loss: 0.0448
2023-02-06 10:44:39 | Train | Epoch[120/600] Iteration[002/030] Train loss: 0.0431
2023-02-06 10:44:39 | Train | Epoch[120/600] Iteration[003/030] Train loss: 0.0442
2023-02-06 10:44:39 | Train | Epoch[120/600] Iteration[004/030] Train loss: 0.0432
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[005/030] Train loss: 0.0437
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[006/030] Train loss: 0.0438
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[007/030] Train loss: 0.0439
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[008/030] Train loss: 0.0442
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[009/030] Train loss: 0.0443
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[010/030] Train loss: 0.0442
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[011/030] Train loss: 0.0442
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[012/030] Train loss: 0.0445
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[013/030] Train loss: 0.0445
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[014/030] Train loss: 0.0444
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[015/030] Train loss: 0.0446
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[016/030] Train loss: 0.0445
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[017/030] Train loss: 0.0444
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[018/030] Train loss: 0.0446
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[019/030] Train loss: 0.0445
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[020/030] Train loss: 0.0445
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[021/030] Train loss: 0.0445
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[022/030] Train loss: 0.0444
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[023/030] Train loss: 0.0443
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[024/030] Train loss: 0.0442
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[025/030] Train loss: 0.0443
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[026/030] Train loss: 0.0443
2023-02-06 10:44:40 | Train | Epoch[120/600] Iteration[027/030] Train loss: 0.0441
2023-02-06 10:44:41 | Train | Epoch[120/600] Iteration[028/030] Train loss: 0.0442
2023-02-06 10:44:41 | Train | Epoch[120/600] Iteration[029/030] Train loss: 0.0441
2023-02-06 10:44:41 | Train | Epoch[120/600] Iteration[030/030] Train loss: 0.0440
2023-02-06 10:44:41 | Valid | Epoch[120/600] Iteration[001/008] Valid loss: 0.1558
2023-02-06 10:44:41 | Valid | Epoch[120/600] Iteration[002/008] Valid loss: 0.1581
2023-02-06 10:44:41 | Valid | Epoch[120/600] Iteration[003/008] Valid loss: 0.1646
2023-02-06 10:44:41 | Valid | Epoch[120/600] Iteration[004/008] Valid loss: 0.1648
2023-02-06 10:44:41 | Valid | Epoch[120/600] Iteration[005/008] Valid loss: 0.1689
2023-02-06 10:44:41 | Valid | Epoch[120/600] Iteration[006/008] Valid loss: 0.1660
2023-02-06 10:44:41 | Valid | Epoch[120/600] Iteration[007/008] Valid loss: 0.1633
2023-02-06 10:44:41 | Valid | Epoch[120/600] Iteration[008/008] Valid loss: 0.1680
2023-02-06 10:44:41 | Valid | Epoch[120/600] MIou: 0.520912145098859
2023-02-06 10:44:41 | Valid | Epoch[120/600] Pixel Accuracy: 0.9207013448079427
2023-02-06 10:44:41 | Valid | Epoch[120/600] Mean Pixel Accuracy: 0.5610032521927664
2023-02-06 10:44:41 | Stage | Epoch[120/600] Train loss:0.0440
2023-02-06 10:44:41 | Stage | Epoch[120/600] Valid loss:0.1680
2023-02-06 10:44:41 | Stage | Epoch[120/600] LR:0.01

2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[001/030] Train loss: 0.0444
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[002/030] Train loss: 0.0436
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[003/030] Train loss: 0.0455
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[004/030] Train loss: 0.0451
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[005/030] Train loss: 0.0447
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[006/030] Train loss: 0.0443
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[007/030] Train loss: 0.0449
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[008/030] Train loss: 0.0448
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[009/030] Train loss: 0.0449
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[010/030] Train loss: 0.0446
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[011/030] Train loss: 0.0443
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[012/030] Train loss: 0.0441
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[013/030] Train loss: 0.0442
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[014/030] Train loss: 0.0440
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[015/030] Train loss: 0.0438
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[016/030] Train loss: 0.0435
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[017/030] Train loss: 0.0436
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[018/030] Train loss: 0.0437
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[019/030] Train loss: 0.0436
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[020/030] Train loss: 0.0437
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[021/030] Train loss: 0.0435
2023-02-06 10:44:42 | Train | Epoch[121/600] Iteration[022/030] Train loss: 0.0435
2023-02-06 10:44:43 | Train | Epoch[121/600] Iteration[023/030] Train loss: 0.0435
2023-02-06 10:44:43 | Train | Epoch[121/600] Iteration[024/030] Train loss: 0.0436
2023-02-06 10:44:43 | Train | Epoch[121/600] Iteration[025/030] Train loss: 0.0436
2023-02-06 10:44:43 | Train | Epoch[121/600] Iteration[026/030] Train loss: 0.0437
2023-02-06 10:44:43 | Train | Epoch[121/600] Iteration[027/030] Train loss: 0.0437
2023-02-06 10:44:43 | Train | Epoch[121/600] Iteration[028/030] Train loss: 0.0439
2023-02-06 10:44:43 | Train | Epoch[121/600] Iteration[029/030] Train loss: 0.0439
2023-02-06 10:44:43 | Train | Epoch[121/600] Iteration[030/030] Train loss: 0.0439
2023-02-06 10:44:43 | Valid | Epoch[121/600] Iteration[001/008] Valid loss: 0.6300
2023-02-06 10:44:43 | Valid | Epoch[121/600] Iteration[002/008] Valid loss: 0.5807
2023-02-06 10:44:43 | Valid | Epoch[121/600] Iteration[003/008] Valid loss: 0.5773
2023-02-06 10:44:43 | Valid | Epoch[121/600] Iteration[004/008] Valid loss: 0.5852
2023-02-06 10:44:43 | Valid | Epoch[121/600] Iteration[005/008] Valid loss: 0.6125
2023-02-06 10:44:43 | Valid | Epoch[121/600] Iteration[006/008] Valid loss: 0.6060
2023-02-06 10:44:43 | Valid | Epoch[121/600] Iteration[007/008] Valid loss: 0.6387
2023-02-06 10:44:43 | Valid | Epoch[121/600] Iteration[008/008] Valid loss: 0.6412
2023-02-06 10:44:43 | Valid | Epoch[121/600] MIou: 0.8106375274649209
2023-02-06 10:44:43 | Valid | Epoch[121/600] Pixel Accuracy: 0.9556795756022135
2023-02-06 10:44:43 | Valid | Epoch[121/600] Mean Pixel Accuracy: 0.9739276772223318
2023-02-06 10:44:43 | Stage | Epoch[121/600] Train loss:0.0439
2023-02-06 10:44:43 | Stage | Epoch[121/600] Valid loss:0.6412
2023-02-06 10:44:43 | Stage | Epoch[121/600] LR:0.01

2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[001/030] Train loss: 0.0392
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[002/030] Train loss: 0.0413
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[003/030] Train loss: 0.0411
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[004/030] Train loss: 0.0418
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[005/030] Train loss: 0.0421
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[006/030] Train loss: 0.0423
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[007/030] Train loss: 0.0426
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[008/030] Train loss: 0.0426
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[009/030] Train loss: 0.0428
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[010/030] Train loss: 0.0432
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[011/030] Train loss: 0.0435
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[012/030] Train loss: 0.0432
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[013/030] Train loss: 0.0434
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[014/030] Train loss: 0.0434
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[015/030] Train loss: 0.0434
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[016/030] Train loss: 0.0434
2023-02-06 10:44:44 | Train | Epoch[122/600] Iteration[017/030] Train loss: 0.0438
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[018/030] Train loss: 0.0436
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[019/030] Train loss: 0.0436
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[020/030] Train loss: 0.0435
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[021/030] Train loss: 0.0438
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[022/030] Train loss: 0.0439
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[023/030] Train loss: 0.0441
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[024/030] Train loss: 0.0440
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[025/030] Train loss: 0.0439
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[026/030] Train loss: 0.0439
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[027/030] Train loss: 0.0439
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[028/030] Train loss: 0.0442
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[029/030] Train loss: 0.0442
2023-02-06 10:44:45 | Train | Epoch[122/600] Iteration[030/030] Train loss: 0.0442
2023-02-06 10:44:45 | Valid | Epoch[122/600] Iteration[001/008] Valid loss: 0.0849
2023-02-06 10:44:45 | Valid | Epoch[122/600] Iteration[002/008] Valid loss: 0.0841
2023-02-06 10:44:45 | Valid | Epoch[122/600] Iteration[003/008] Valid loss: 0.0867
2023-02-06 10:44:45 | Valid | Epoch[122/600] Iteration[004/008] Valid loss: 0.0862
2023-02-06 10:44:46 | Valid | Epoch[122/600] Iteration[005/008] Valid loss: 0.0871
2023-02-06 10:44:46 | Valid | Epoch[122/600] Iteration[006/008] Valid loss: 0.0857
2023-02-06 10:44:46 | Valid | Epoch[122/600] Iteration[007/008] Valid loss: 0.0840
2023-02-06 10:44:46 | Valid | Epoch[122/600] Iteration[008/008] Valid loss: 0.0855
2023-02-06 10:44:46 | Valid | Epoch[122/600] MIou: 0.7566425528530341
2023-02-06 10:44:46 | Valid | Epoch[122/600] Pixel Accuracy: 0.9598579406738281
2023-02-06 10:44:46 | Valid | Epoch[122/600] Mean Pixel Accuracy: 0.7777738670120655
2023-02-06 10:44:46 | Stage | Epoch[122/600] Train loss:0.0442
2023-02-06 10:44:46 | Stage | Epoch[122/600] Valid loss:0.0855
2023-02-06 10:44:46 | Stage | Epoch[122/600] LR:0.01

2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[001/030] Train loss: 0.0449
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[002/030] Train loss: 0.0479
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[003/030] Train loss: 0.0451
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[004/030] Train loss: 0.0451
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[005/030] Train loss: 0.0446
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[006/030] Train loss: 0.0447
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[007/030] Train loss: 0.0442
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[008/030] Train loss: 0.0444
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[009/030] Train loss: 0.0443
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[010/030] Train loss: 0.0444
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[011/030] Train loss: 0.0438
2023-02-06 10:44:46 | Train | Epoch[123/600] Iteration[012/030] Train loss: 0.0437
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[013/030] Train loss: 0.0432
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[014/030] Train loss: 0.0430
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[015/030] Train loss: 0.0430
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[016/030] Train loss: 0.0431
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[017/030] Train loss: 0.0432
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[018/030] Train loss: 0.0432
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[019/030] Train loss: 0.0434
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[020/030] Train loss: 0.0434
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[021/030] Train loss: 0.0434
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[022/030] Train loss: 0.0434
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[023/030] Train loss: 0.0438
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[024/030] Train loss: 0.0437
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[025/030] Train loss: 0.0438
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[026/030] Train loss: 0.0438
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[027/030] Train loss: 0.0436
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[028/030] Train loss: 0.0435
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[029/030] Train loss: 0.0436
2023-02-06 10:44:47 | Train | Epoch[123/600] Iteration[030/030] Train loss: 0.0438
2023-02-06 10:44:48 | Valid | Epoch[123/600] Iteration[001/008] Valid loss: 0.0797
2023-02-06 10:44:48 | Valid | Epoch[123/600] Iteration[002/008] Valid loss: 0.0698
2023-02-06 10:44:48 | Valid | Epoch[123/600] Iteration[003/008] Valid loss: 0.0650
2023-02-06 10:44:48 | Valid | Epoch[123/600] Iteration[004/008] Valid loss: 0.0646
2023-02-06 10:44:48 | Valid | Epoch[123/600] Iteration[005/008] Valid loss: 0.0656
2023-02-06 10:44:48 | Valid | Epoch[123/600] Iteration[006/008] Valid loss: 0.0653
2023-02-06 10:44:48 | Valid | Epoch[123/600] Iteration[007/008] Valid loss: 0.0680
2023-02-06 10:44:48 | Valid | Epoch[123/600] Iteration[008/008] Valid loss: 0.0673
2023-02-06 10:44:48 | Valid | Epoch[123/600] MIou: 0.9328129458203039
2023-02-06 10:44:48 | Valid | Epoch[123/600] Pixel Accuracy: 0.9882036844889323
2023-02-06 10:44:48 | Valid | Epoch[123/600] Mean Pixel Accuracy: 0.9685474650798584
2023-02-06 10:44:48 | Stage | Epoch[123/600] Train loss:0.0438
2023-02-06 10:44:48 | Stage | Epoch[123/600] Valid loss:0.0673
2023-02-06 10:44:48 | Stage | Epoch[123/600] LR:0.01

2023-02-06 10:44:48 | Train | Epoch[124/600] Iteration[001/030] Train loss: 0.0429
2023-02-06 10:44:48 | Train | Epoch[124/600] Iteration[002/030] Train loss: 0.0437
2023-02-06 10:44:48 | Train | Epoch[124/600] Iteration[003/030] Train loss: 0.0449
2023-02-06 10:44:48 | Train | Epoch[124/600] Iteration[004/030] Train loss: 0.0451
2023-02-06 10:44:48 | Train | Epoch[124/600] Iteration[005/030] Train loss: 0.0445
2023-02-06 10:44:48 | Train | Epoch[124/600] Iteration[006/030] Train loss: 0.0442
2023-02-06 10:44:48 | Train | Epoch[124/600] Iteration[007/030] Train loss: 0.0439
2023-02-06 10:44:48 | Train | Epoch[124/600] Iteration[008/030] Train loss: 0.0434
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[009/030] Train loss: 0.0432
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[010/030] Train loss: 0.0431
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[011/030] Train loss: 0.0435
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[012/030] Train loss: 0.0435
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[013/030] Train loss: 0.0433
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[014/030] Train loss: 0.0435
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[015/030] Train loss: 0.0438
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[016/030] Train loss: 0.0435
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[017/030] Train loss: 0.0434
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[018/030] Train loss: 0.0433
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[019/030] Train loss: 0.0434
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[020/030] Train loss: 0.0436
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[021/030] Train loss: 0.0435
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[022/030] Train loss: 0.0432
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[023/030] Train loss: 0.0431
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[024/030] Train loss: 0.0429
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[025/030] Train loss: 0.0431
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[026/030] Train loss: 0.0431
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[027/030] Train loss: 0.0432
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[028/030] Train loss: 0.0432
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[029/030] Train loss: 0.0432
2023-02-06 10:44:49 | Train | Epoch[124/600] Iteration[030/030] Train loss: 0.0432
2023-02-06 10:44:50 | Valid | Epoch[124/600] Iteration[001/008] Valid loss: 0.1701
2023-02-06 10:44:50 | Valid | Epoch[124/600] Iteration[002/008] Valid loss: 0.1717
2023-02-06 10:44:50 | Valid | Epoch[124/600] Iteration[003/008] Valid loss: 0.1790
2023-02-06 10:44:50 | Valid | Epoch[124/600] Iteration[004/008] Valid loss: 0.1793
2023-02-06 10:44:50 | Valid | Epoch[124/600] Iteration[005/008] Valid loss: 0.1839
2023-02-06 10:44:50 | Valid | Epoch[124/600] Iteration[006/008] Valid loss: 0.1812
2023-02-06 10:44:50 | Valid | Epoch[124/600] Iteration[007/008] Valid loss: 0.1785
2023-02-06 10:44:50 | Valid | Epoch[124/600] Iteration[008/008] Valid loss: 0.1836
2023-02-06 10:44:50 | Valid | Epoch[124/600] MIou: 0.49160616811839275
2023-02-06 10:44:50 | Valid | Epoch[124/600] Pixel Accuracy: 0.9158159891764323
2023-02-06 10:44:50 | Valid | Epoch[124/600] Mean Pixel Accuracy: 0.5339579608328993
2023-02-06 10:44:50 | Stage | Epoch[124/600] Train loss:0.0432
2023-02-06 10:44:50 | Stage | Epoch[124/600] Valid loss:0.1836
2023-02-06 10:44:50 | Stage | Epoch[124/600] LR:0.01

2023-02-06 10:44:50 | Train | Epoch[125/600] Iteration[001/030] Train loss: 0.0436
2023-02-06 10:44:50 | Train | Epoch[125/600] Iteration[002/030] Train loss: 0.0417
2023-02-06 10:44:50 | Train | Epoch[125/600] Iteration[003/030] Train loss: 0.0436
2023-02-06 10:44:50 | Train | Epoch[125/600] Iteration[004/030] Train loss: 0.0434
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[005/030] Train loss: 0.0429
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[006/030] Train loss: 0.0428
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[007/030] Train loss: 0.0430
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[008/030] Train loss: 0.0436
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[009/030] Train loss: 0.0431
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[010/030] Train loss: 0.0433
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[011/030] Train loss: 0.0431
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[012/030] Train loss: 0.0433
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[013/030] Train loss: 0.0440
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[014/030] Train loss: 0.0439
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[015/030] Train loss: 0.0437
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[016/030] Train loss: 0.0437
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[017/030] Train loss: 0.0436
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[018/030] Train loss: 0.0439
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[019/030] Train loss: 0.0438
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[020/030] Train loss: 0.0443
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[021/030] Train loss: 0.0444
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[022/030] Train loss: 0.0447
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[023/030] Train loss: 0.0449
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[024/030] Train loss: 0.0447
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[025/030] Train loss: 0.0447
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[026/030] Train loss: 0.0446
2023-02-06 10:44:51 | Train | Epoch[125/600] Iteration[027/030] Train loss: 0.0447
2023-02-06 10:44:52 | Train | Epoch[125/600] Iteration[028/030] Train loss: 0.0448
2023-02-06 10:44:52 | Train | Epoch[125/600] Iteration[029/030] Train loss: 0.0446
2023-02-06 10:44:52 | Train | Epoch[125/600] Iteration[030/030] Train loss: 0.0444
2023-02-06 10:44:52 | Valid | Epoch[125/600] Iteration[001/008] Valid loss: 0.0760
2023-02-06 10:44:52 | Valid | Epoch[125/600] Iteration[002/008] Valid loss: 0.0765
2023-02-06 10:44:52 | Valid | Epoch[125/600] Iteration[003/008] Valid loss: 0.0784
2023-02-06 10:44:52 | Valid | Epoch[125/600] Iteration[004/008] Valid loss: 0.0784
2023-02-06 10:44:52 | Valid | Epoch[125/600] Iteration[005/008] Valid loss: 0.0791
2023-02-06 10:44:52 | Valid | Epoch[125/600] Iteration[006/008] Valid loss: 0.0777
2023-02-06 10:44:52 | Valid | Epoch[125/600] Iteration[007/008] Valid loss: 0.0763
2023-02-06 10:44:52 | Valid | Epoch[125/600] Iteration[008/008] Valid loss: 0.0775
2023-02-06 10:44:52 | Valid | Epoch[125/600] MIou: 0.7714902305542646
2023-02-06 10:44:52 | Valid | Epoch[125/600] Pixel Accuracy: 0.9623146057128906
2023-02-06 10:44:52 | Valid | Epoch[125/600] Mean Pixel Accuracy: 0.7913866267961264
2023-02-06 10:44:52 | Stage | Epoch[125/600] Train loss:0.0444
2023-02-06 10:44:52 | Stage | Epoch[125/600] Valid loss:0.0775
2023-02-06 10:44:52 | Stage | Epoch[125/600] LR:0.01

2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[001/030] Train loss: 0.0401
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[002/030] Train loss: 0.0418
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[003/030] Train loss: 0.0404
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[004/030] Train loss: 0.0407
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[005/030] Train loss: 0.0415
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[006/030] Train loss: 0.0421
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[007/030] Train loss: 0.0429
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[008/030] Train loss: 0.0430
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[009/030] Train loss: 0.0427
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[010/030] Train loss: 0.0431
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[011/030] Train loss: 0.0430
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[012/030] Train loss: 0.0427
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[013/030] Train loss: 0.0424
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[014/030] Train loss: 0.0427
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[015/030] Train loss: 0.0428
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[016/030] Train loss: 0.0426
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[017/030] Train loss: 0.0424
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[018/030] Train loss: 0.0421
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[019/030] Train loss: 0.0422
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[020/030] Train loss: 0.0423
2023-02-06 10:44:53 | Train | Epoch[126/600] Iteration[021/030] Train loss: 0.0423
2023-02-06 10:44:54 | Train | Epoch[126/600] Iteration[022/030] Train loss: 0.0424
2023-02-06 10:44:54 | Train | Epoch[126/600] Iteration[023/030] Train loss: 0.0424
2023-02-06 10:44:54 | Train | Epoch[126/600] Iteration[024/030] Train loss: 0.0427
2023-02-06 10:44:54 | Train | Epoch[126/600] Iteration[025/030] Train loss: 0.0428
2023-02-06 10:44:54 | Train | Epoch[126/600] Iteration[026/030] Train loss: 0.0428
2023-02-06 10:44:54 | Train | Epoch[126/600] Iteration[027/030] Train loss: 0.0427
2023-02-06 10:44:54 | Train | Epoch[126/600] Iteration[028/030] Train loss: 0.0427
2023-02-06 10:44:54 | Train | Epoch[126/600] Iteration[029/030] Train loss: 0.0427
2023-02-06 10:44:54 | Train | Epoch[126/600] Iteration[030/030] Train loss: 0.0427
2023-02-06 10:44:54 | Valid | Epoch[126/600] Iteration[001/008] Valid loss: 0.0515
2023-02-06 10:44:54 | Valid | Epoch[126/600] Iteration[002/008] Valid loss: 0.0462
2023-02-06 10:44:54 | Valid | Epoch[126/600] Iteration[003/008] Valid loss: 0.0455
2023-02-06 10:44:54 | Valid | Epoch[126/600] Iteration[004/008] Valid loss: 0.0446
2023-02-06 10:44:54 | Valid | Epoch[126/600] Iteration[005/008] Valid loss: 0.0455
2023-02-06 10:44:54 | Valid | Epoch[126/600] Iteration[006/008] Valid loss: 0.0455
2023-02-06 10:44:54 | Valid | Epoch[126/600] Iteration[007/008] Valid loss: 0.0461
2023-02-06 10:44:54 | Valid | Epoch[126/600] Iteration[008/008] Valid loss: 0.0456
2023-02-06 10:44:55 | Valid | Epoch[126/600] MIou: 0.9305444276293371
2023-02-06 10:44:55 | Valid | Epoch[126/600] Pixel Accuracy: 0.9883956909179688
2023-02-06 10:44:55 | Valid | Epoch[126/600] Mean Pixel Accuracy: 0.9435637542288332
2023-02-06 10:44:55 | Stage | Epoch[126/600] Train loss:0.0427
2023-02-06 10:44:55 | Stage | Epoch[126/600] Valid loss:0.0456
2023-02-06 10:44:55 | Stage | Epoch[126/600] LR:0.01

2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[001/030] Train loss: 0.0416
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[002/030] Train loss: 0.0415
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[003/030] Train loss: 0.0414
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[004/030] Train loss: 0.0418
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[005/030] Train loss: 0.0421
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[006/030] Train loss: 0.0423
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[007/030] Train loss: 0.0425
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[008/030] Train loss: 0.0423
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[009/030] Train loss: 0.0420
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[010/030] Train loss: 0.0422
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[011/030] Train loss: 0.0423
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[012/030] Train loss: 0.0424
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[013/030] Train loss: 0.0422
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[014/030] Train loss: 0.0419
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[015/030] Train loss: 0.0417
2023-02-06 10:44:55 | Train | Epoch[127/600] Iteration[016/030] Train loss: 0.0419
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[017/030] Train loss: 0.0418
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[018/030] Train loss: 0.0417
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[019/030] Train loss: 0.0415
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[020/030] Train loss: 0.0417
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[021/030] Train loss: 0.0417
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[022/030] Train loss: 0.0417
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[023/030] Train loss: 0.0418
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[024/030] Train loss: 0.0420
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[025/030] Train loss: 0.0420
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[026/030] Train loss: 0.0419
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[027/030] Train loss: 0.0418
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[028/030] Train loss: 0.0418
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[029/030] Train loss: 0.0418
2023-02-06 10:44:56 | Train | Epoch[127/600] Iteration[030/030] Train loss: 0.0417
2023-02-06 10:44:56 | Valid | Epoch[127/600] Iteration[001/008] Valid loss: 0.0950
2023-02-06 10:44:56 | Valid | Epoch[127/600] Iteration[002/008] Valid loss: 0.0948
2023-02-06 10:44:56 | Valid | Epoch[127/600] Iteration[003/008] Valid loss: 0.0979
2023-02-06 10:44:57 | Valid | Epoch[127/600] Iteration[004/008] Valid loss: 0.0973
2023-02-06 10:44:57 | Valid | Epoch[127/600] Iteration[005/008] Valid loss: 0.0984
2023-02-06 10:44:57 | Valid | Epoch[127/600] Iteration[006/008] Valid loss: 0.0971
2023-02-06 10:44:57 | Valid | Epoch[127/600] Iteration[007/008] Valid loss: 0.0950
2023-02-06 10:44:57 | Valid | Epoch[127/600] Iteration[008/008] Valid loss: 0.0972
2023-02-06 10:44:57 | Valid | Epoch[127/600] MIou: 0.6940495434388342
2023-02-06 10:44:57 | Valid | Epoch[127/600] Pixel Accuracy: 0.9494857788085938
2023-02-06 10:44:57 | Valid | Epoch[127/600] Mean Pixel Accuracy: 0.7203536583648932
2023-02-06 10:44:57 | Stage | Epoch[127/600] Train loss:0.0417
2023-02-06 10:44:57 | Stage | Epoch[127/600] Valid loss:0.0972
2023-02-06 10:44:57 | Stage | Epoch[127/600] LR:0.01

2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[001/030] Train loss: 0.0442
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[002/030] Train loss: 0.0451
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[003/030] Train loss: 0.0441
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[004/030] Train loss: 0.0433
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[005/030] Train loss: 0.0427
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[006/030] Train loss: 0.0426
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[007/030] Train loss: 0.0427
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[008/030] Train loss: 0.0426
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[009/030] Train loss: 0.0427
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[010/030] Train loss: 0.0424
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[011/030] Train loss: 0.0424
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[012/030] Train loss: 0.0423
2023-02-06 10:44:57 | Train | Epoch[128/600] Iteration[013/030] Train loss: 0.0422
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[014/030] Train loss: 0.0421
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[015/030] Train loss: 0.0421
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[016/030] Train loss: 0.0420
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[017/030] Train loss: 0.0422
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[018/030] Train loss: 0.0421
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[019/030] Train loss: 0.0424
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[020/030] Train loss: 0.0422
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[021/030] Train loss: 0.0421
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[022/030] Train loss: 0.0419
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[023/030] Train loss: 0.0420
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[024/030] Train loss: 0.0421
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[025/030] Train loss: 0.0419
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[026/030] Train loss: 0.0420
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[027/030] Train loss: 0.0418
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[028/030] Train loss: 0.0417
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[029/030] Train loss: 0.0418
2023-02-06 10:44:58 | Train | Epoch[128/600] Iteration[030/030] Train loss: 0.0416
2023-02-06 10:44:59 | Valid | Epoch[128/600] Iteration[001/008] Valid loss: 0.0752
2023-02-06 10:44:59 | Valid | Epoch[128/600] Iteration[002/008] Valid loss: 0.0733
2023-02-06 10:44:59 | Valid | Epoch[128/600] Iteration[003/008] Valid loss: 0.0750
2023-02-06 10:44:59 | Valid | Epoch[128/600] Iteration[004/008] Valid loss: 0.0742
2023-02-06 10:44:59 | Valid | Epoch[128/600] Iteration[005/008] Valid loss: 0.0750
2023-02-06 10:44:59 | Valid | Epoch[128/600] Iteration[006/008] Valid loss: 0.0739
2023-02-06 10:44:59 | Valid | Epoch[128/600] Iteration[007/008] Valid loss: 0.0723
2023-02-06 10:44:59 | Valid | Epoch[128/600] Iteration[008/008] Valid loss: 0.0736
2023-02-06 10:44:59 | Valid | Epoch[128/600] MIou: 0.7899522269086142
2023-02-06 10:44:59 | Valid | Epoch[128/600] Pixel Accuracy: 0.9653650919596354
2023-02-06 10:44:59 | Valid | Epoch[128/600] Mean Pixel Accuracy: 0.8083311595385174
2023-02-06 10:44:59 | Stage | Epoch[128/600] Train loss:0.0416
2023-02-06 10:44:59 | Stage | Epoch[128/600] Valid loss:0.0736
2023-02-06 10:44:59 | Stage | Epoch[128/600] LR:0.01

2023-02-06 10:44:59 | Train | Epoch[129/600] Iteration[001/030] Train loss: 0.0411
2023-02-06 10:44:59 | Train | Epoch[129/600] Iteration[002/030] Train loss: 0.0393
2023-02-06 10:44:59 | Train | Epoch[129/600] Iteration[003/030] Train loss: 0.0401
2023-02-06 10:44:59 | Train | Epoch[129/600] Iteration[004/030] Train loss: 0.0393
2023-02-06 10:44:59 | Train | Epoch[129/600] Iteration[005/030] Train loss: 0.0397
2023-02-06 10:44:59 | Train | Epoch[129/600] Iteration[006/030] Train loss: 0.0402
2023-02-06 10:44:59 | Train | Epoch[129/600] Iteration[007/030] Train loss: 0.0399
2023-02-06 10:44:59 | Train | Epoch[129/600] Iteration[008/030] Train loss: 0.0408
2023-02-06 10:44:59 | Train | Epoch[129/600] Iteration[009/030] Train loss: 0.0405
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[010/030] Train loss: 0.0404
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[011/030] Train loss: 0.0405
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[012/030] Train loss: 0.0405
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[013/030] Train loss: 0.0408
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[014/030] Train loss: 0.0408
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[015/030] Train loss: 0.0409
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[016/030] Train loss: 0.0410
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[017/030] Train loss: 0.0411
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[018/030] Train loss: 0.0410
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[019/030] Train loss: 0.0411
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[020/030] Train loss: 0.0412
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[021/030] Train loss: 0.0412
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[022/030] Train loss: 0.0412
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[023/030] Train loss: 0.0411
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[024/030] Train loss: 0.0410
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[025/030] Train loss: 0.0410
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[026/030] Train loss: 0.0410
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[027/030] Train loss: 0.0411
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[028/030] Train loss: 0.0411
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[029/030] Train loss: 0.0414
2023-02-06 10:45:00 | Train | Epoch[129/600] Iteration[030/030] Train loss: 0.0413
2023-02-06 10:45:01 | Valid | Epoch[129/600] Iteration[001/008] Valid loss: 0.0532
2023-02-06 10:45:01 | Valid | Epoch[129/600] Iteration[002/008] Valid loss: 0.0483
2023-02-06 10:45:01 | Valid | Epoch[129/600] Iteration[003/008] Valid loss: 0.0471
2023-02-06 10:45:01 | Valid | Epoch[129/600] Iteration[004/008] Valid loss: 0.0465
2023-02-06 10:45:01 | Valid | Epoch[129/600] Iteration[005/008] Valid loss: 0.0469
2023-02-06 10:45:01 | Valid | Epoch[129/600] Iteration[006/008] Valid loss: 0.0468
2023-02-06 10:45:01 | Valid | Epoch[129/600] Iteration[007/008] Valid loss: 0.0475
2023-02-06 10:45:01 | Valid | Epoch[129/600] Iteration[008/008] Valid loss: 0.0472
2023-02-06 10:45:01 | Valid | Epoch[129/600] MIou: 0.9251249268243681
2023-02-06 10:45:01 | Valid | Epoch[129/600] Pixel Accuracy: 0.987433115641276
2023-02-06 10:45:01 | Valid | Epoch[129/600] Mean Pixel Accuracy: 0.9405111741421125
2023-02-06 10:45:01 | Stage | Epoch[129/600] Train loss:0.0413
2023-02-06 10:45:01 | Stage | Epoch[129/600] Valid loss:0.0472
2023-02-06 10:45:01 | Stage | Epoch[129/600] LR:0.01

2023-02-06 10:45:01 | Train | Epoch[130/600] Iteration[001/030] Train loss: 0.0428
2023-02-06 10:45:01 | Train | Epoch[130/600] Iteration[002/030] Train loss: 0.0419
2023-02-06 10:45:01 | Train | Epoch[130/600] Iteration[003/030] Train loss: 0.0418
2023-02-06 10:45:01 | Train | Epoch[130/600] Iteration[004/030] Train loss: 0.0414
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[005/030] Train loss: 0.0411
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[006/030] Train loss: 0.0404
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[007/030] Train loss: 0.0401
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[008/030] Train loss: 0.0414
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[009/030] Train loss: 0.0415
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[010/030] Train loss: 0.0411
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[011/030] Train loss: 0.0409
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[012/030] Train loss: 0.0408
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[013/030] Train loss: 0.0406
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[014/030] Train loss: 0.0407
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[015/030] Train loss: 0.0407
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[016/030] Train loss: 0.0408
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[017/030] Train loss: 0.0407
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[018/030] Train loss: 0.0406
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[019/030] Train loss: 0.0407
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[020/030] Train loss: 0.0406
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[021/030] Train loss: 0.0405
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[022/030] Train loss: 0.0405
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[023/030] Train loss: 0.0405
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[024/030] Train loss: 0.0407
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[025/030] Train loss: 0.0410
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[026/030] Train loss: 0.0409
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[027/030] Train loss: 0.0410
2023-02-06 10:45:02 | Train | Epoch[130/600] Iteration[028/030] Train loss: 0.0410
2023-02-06 10:45:03 | Train | Epoch[130/600] Iteration[029/030] Train loss: 0.0412
2023-02-06 10:45:03 | Train | Epoch[130/600] Iteration[030/030] Train loss: 0.0412
2023-02-06 10:45:03 | Valid | Epoch[130/600] Iteration[001/008] Valid loss: 0.0562
2023-02-06 10:45:03 | Valid | Epoch[130/600] Iteration[002/008] Valid loss: 0.0554
2023-02-06 10:45:03 | Valid | Epoch[130/600] Iteration[003/008] Valid loss: 0.0567
2023-02-06 10:45:03 | Valid | Epoch[130/600] Iteration[004/008] Valid loss: 0.0560
2023-02-06 10:45:03 | Valid | Epoch[130/600] Iteration[005/008] Valid loss: 0.0565
2023-02-06 10:45:03 | Valid | Epoch[130/600] Iteration[006/008] Valid loss: 0.0558
2023-02-06 10:45:03 | Valid | Epoch[130/600] Iteration[007/008] Valid loss: 0.0551
2023-02-06 10:45:03 | Valid | Epoch[130/600] Iteration[008/008] Valid loss: 0.0557
2023-02-06 10:45:03 | Valid | Epoch[130/600] MIou: 0.8418995435263628
2023-02-06 10:45:03 | Valid | Epoch[130/600] Pixel Accuracy: 0.9739532470703125
2023-02-06 10:45:03 | Valid | Epoch[130/600] Mean Pixel Accuracy: 0.8558434180983288
2023-02-06 10:45:03 | Stage | Epoch[130/600] Train loss:0.0412
2023-02-06 10:45:03 | Stage | Epoch[130/600] Valid loss:0.0557
2023-02-06 10:45:03 | Stage | Epoch[130/600] LR:0.01

2023-02-06 10:45:03 | Train | Epoch[131/600] Iteration[001/030] Train loss: 0.0395
2023-02-06 10:45:03 | Train | Epoch[131/600] Iteration[002/030] Train loss: 0.0398
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[003/030] Train loss: 0.0398
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[004/030] Train loss: 0.0411
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[005/030] Train loss: 0.0403
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[006/030] Train loss: 0.0412
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[007/030] Train loss: 0.0422
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[008/030] Train loss: 0.0417
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[009/030] Train loss: 0.0413
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[010/030] Train loss: 0.0417
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[011/030] Train loss: 0.0417
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[012/030] Train loss: 0.0414
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[013/030] Train loss: 0.0414
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[014/030] Train loss: 0.0413
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[015/030] Train loss: 0.0411
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[016/030] Train loss: 0.0410
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[017/030] Train loss: 0.0411
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[018/030] Train loss: 0.0410
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[019/030] Train loss: 0.0409
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[020/030] Train loss: 0.0407
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[021/030] Train loss: 0.0405
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[022/030] Train loss: 0.0408
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[023/030] Train loss: 0.0407
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[024/030] Train loss: 0.0407
2023-02-06 10:45:04 | Train | Epoch[131/600] Iteration[025/030] Train loss: 0.0406
2023-02-06 10:45:05 | Train | Epoch[131/600] Iteration[026/030] Train loss: 0.0406
2023-02-06 10:45:05 | Train | Epoch[131/600] Iteration[027/030] Train loss: 0.0406
2023-02-06 10:45:05 | Train | Epoch[131/600] Iteration[028/030] Train loss: 0.0406
2023-02-06 10:45:05 | Train | Epoch[131/600] Iteration[029/030] Train loss: 0.0405
2023-02-06 10:45:05 | Train | Epoch[131/600] Iteration[030/030] Train loss: 0.0407
2023-02-06 10:45:05 | Valid | Epoch[131/600] Iteration[001/008] Valid loss: 0.1201
2023-02-06 10:45:05 | Valid | Epoch[131/600] Iteration[002/008] Valid loss: 0.0920
2023-02-06 10:45:05 | Valid | Epoch[131/600] Iteration[003/008] Valid loss: 0.0850
2023-02-06 10:45:05 | Valid | Epoch[131/600] Iteration[004/008] Valid loss: 0.0832
2023-02-06 10:45:05 | Valid | Epoch[131/600] Iteration[005/008] Valid loss: 0.0843
2023-02-06 10:45:05 | Valid | Epoch[131/600] Iteration[006/008] Valid loss: 0.0826
2023-02-06 10:45:05 | Valid | Epoch[131/600] Iteration[007/008] Valid loss: 0.0889
2023-02-06 10:45:05 | Valid | Epoch[131/600] Iteration[008/008] Valid loss: 0.0879
2023-02-06 10:45:05 | Valid | Epoch[131/600] MIou: 0.9221184058135767
2023-02-06 10:45:05 | Valid | Epoch[131/600] Pixel Accuracy: 0.9858601888020834
2023-02-06 10:45:05 | Valid | Epoch[131/600] Mean Pixel Accuracy: 0.973967598762473
2023-02-06 10:45:05 | Stage | Epoch[131/600] Train loss:0.0407
2023-02-06 10:45:05 | Stage | Epoch[131/600] Valid loss:0.0879
2023-02-06 10:45:05 | Stage | Epoch[131/600] LR:0.01

2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[001/030] Train loss: 0.0459
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[002/030] Train loss: 0.0442
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[003/030] Train loss: 0.0427
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[004/030] Train loss: 0.0410
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[005/030] Train loss: 0.0410
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[006/030] Train loss: 0.0415
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[007/030] Train loss: 0.0411
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[008/030] Train loss: 0.0412
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[009/030] Train loss: 0.0416
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[010/030] Train loss: 0.0415
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[011/030] Train loss: 0.0411
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[012/030] Train loss: 0.0411
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[013/030] Train loss: 0.0413
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[014/030] Train loss: 0.0410
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[015/030] Train loss: 0.0410
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[016/030] Train loss: 0.0412
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[017/030] Train loss: 0.0411
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[018/030] Train loss: 0.0412
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[019/030] Train loss: 0.0412
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[020/030] Train loss: 0.0414
2023-02-06 10:45:06 | Train | Epoch[132/600] Iteration[021/030] Train loss: 0.0411
2023-02-06 10:45:07 | Train | Epoch[132/600] Iteration[022/030] Train loss: 0.0409
2023-02-06 10:45:07 | Train | Epoch[132/600] Iteration[023/030] Train loss: 0.0408
2023-02-06 10:45:07 | Train | Epoch[132/600] Iteration[024/030] Train loss: 0.0408
2023-02-06 10:45:07 | Train | Epoch[132/600] Iteration[025/030] Train loss: 0.0409
2023-02-06 10:45:07 | Train | Epoch[132/600] Iteration[026/030] Train loss: 0.0410
2023-02-06 10:45:07 | Train | Epoch[132/600] Iteration[027/030] Train loss: 0.0410
2023-02-06 10:45:07 | Train | Epoch[132/600] Iteration[028/030] Train loss: 0.0410
2023-02-06 10:45:07 | Train | Epoch[132/600] Iteration[029/030] Train loss: 0.0409
2023-02-06 10:45:07 | Train | Epoch[132/600] Iteration[030/030] Train loss: 0.0410
2023-02-06 10:45:07 | Valid | Epoch[132/600] Iteration[001/008] Valid loss: 0.0655
2023-02-06 10:45:07 | Valid | Epoch[132/600] Iteration[002/008] Valid loss: 0.0660
2023-02-06 10:45:07 | Valid | Epoch[132/600] Iteration[003/008] Valid loss: 0.0640
2023-02-06 10:45:07 | Valid | Epoch[132/600] Iteration[004/008] Valid loss: 0.0638
2023-02-06 10:45:07 | Valid | Epoch[132/600] Iteration[005/008] Valid loss: 0.0632
2023-02-06 10:45:07 | Valid | Epoch[132/600] Iteration[006/008] Valid loss: 0.0626
2023-02-06 10:45:07 | Valid | Epoch[132/600] Iteration[007/008] Valid loss: 0.0620
2023-02-06 10:45:07 | Valid | Epoch[132/600] Iteration[008/008] Valid loss: 0.0627
2023-02-06 10:45:07 | Valid | Epoch[132/600] MIou: 0.8570460395294288
2023-02-06 10:45:07 | Valid | Epoch[132/600] Pixel Accuracy: 0.9760220845540365
2023-02-06 10:45:07 | Valid | Epoch[132/600] Mean Pixel Accuracy: 0.8764457869552531
2023-02-06 10:45:07 | Stage | Epoch[132/600] Train loss:0.0410
2023-02-06 10:45:07 | Stage | Epoch[132/600] Valid loss:0.0627
2023-02-06 10:45:07 | Stage | Epoch[132/600] LR:0.01

2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[001/030] Train loss: 0.0396
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[002/030] Train loss: 0.0411
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[003/030] Train loss: 0.0426
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[004/030] Train loss: 0.0430
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[005/030] Train loss: 0.0426
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[006/030] Train loss: 0.0423
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[007/030] Train loss: 0.0420
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[008/030] Train loss: 0.0422
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[009/030] Train loss: 0.0420
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[010/030] Train loss: 0.0416
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[011/030] Train loss: 0.0417
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[012/030] Train loss: 0.0415
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[013/030] Train loss: 0.0414
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[014/030] Train loss: 0.0410
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[015/030] Train loss: 0.0411
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[016/030] Train loss: 0.0414
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[017/030] Train loss: 0.0413
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[018/030] Train loss: 0.0411
2023-02-06 10:45:08 | Train | Epoch[133/600] Iteration[019/030] Train loss: 0.0409
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[020/030] Train loss: 0.0408
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[021/030] Train loss: 0.0409
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[022/030] Train loss: 0.0410
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[023/030] Train loss: 0.0408
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[024/030] Train loss: 0.0408
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[025/030] Train loss: 0.0407
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[026/030] Train loss: 0.0409
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[027/030] Train loss: 0.0409
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[028/030] Train loss: 0.0408
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[029/030] Train loss: 0.0408
2023-02-06 10:45:09 | Train | Epoch[133/600] Iteration[030/030] Train loss: 0.0407
2023-02-06 10:45:09 | Valid | Epoch[133/600] Iteration[001/008] Valid loss: 0.3332
2023-02-06 10:45:09 | Valid | Epoch[133/600] Iteration[002/008] Valid loss: 0.2871
2023-02-06 10:45:09 | Valid | Epoch[133/600] Iteration[003/008] Valid loss: 0.2751
2023-02-06 10:45:09 | Valid | Epoch[133/600] Iteration[004/008] Valid loss: 0.2742
2023-02-06 10:45:09 | Valid | Epoch[133/600] Iteration[005/008] Valid loss: 0.2834
2023-02-06 10:45:09 | Valid | Epoch[133/600] Iteration[006/008] Valid loss: 0.2803
2023-02-06 10:45:09 | Valid | Epoch[133/600] Iteration[007/008] Valid loss: 0.3015
2023-02-06 10:45:09 | Valid | Epoch[133/600] Iteration[008/008] Valid loss: 0.3004
2023-02-06 10:45:10 | Valid | Epoch[133/600] MIou: 0.8841125810143655
2023-02-06 10:45:10 | Valid | Epoch[133/600] Pixel Accuracy: 0.9768536885579427
2023-02-06 10:45:10 | Valid | Epoch[133/600] Mean Pixel Accuracy: 0.9807788167652562
2023-02-06 10:45:10 | Stage | Epoch[133/600] Train loss:0.0407
2023-02-06 10:45:10 | Stage | Epoch[133/600] Valid loss:0.3004
2023-02-06 10:45:10 | Stage | Epoch[133/600] LR:0.01

2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[001/030] Train loss: 0.0419
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[002/030] Train loss: 0.0410
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[003/030] Train loss: 0.0406
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[004/030] Train loss: 0.0410
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[005/030] Train loss: 0.0404
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[006/030] Train loss: 0.0413
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[007/030] Train loss: 0.0406
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[008/030] Train loss: 0.0403
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[009/030] Train loss: 0.0401
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[010/030] Train loss: 0.0403
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[011/030] Train loss: 0.0401
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[012/030] Train loss: 0.0399
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[013/030] Train loss: 0.0400
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[014/030] Train loss: 0.0400
2023-02-06 10:45:10 | Train | Epoch[134/600] Iteration[015/030] Train loss: 0.0400
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[016/030] Train loss: 0.0401
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[017/030] Train loss: 0.0400
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[018/030] Train loss: 0.0399
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[019/030] Train loss: 0.0397
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[020/030] Train loss: 0.0398
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[021/030] Train loss: 0.0399
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[022/030] Train loss: 0.0400
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[023/030] Train loss: 0.0400
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[024/030] Train loss: 0.0398
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[025/030] Train loss: 0.0398
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[026/030] Train loss: 0.0399
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[027/030] Train loss: 0.0399
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[028/030] Train loss: 0.0399
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[029/030] Train loss: 0.0399
2023-02-06 10:45:11 | Train | Epoch[134/600] Iteration[030/030] Train loss: 0.0399
2023-02-06 10:45:12 | Valid | Epoch[134/600] Iteration[001/008] Valid loss: 0.4692
2023-02-06 10:45:12 | Valid | Epoch[134/600] Iteration[002/008] Valid loss: 0.4246
2023-02-06 10:45:12 | Valid | Epoch[134/600] Iteration[003/008] Valid loss: 0.4258
2023-02-06 10:45:12 | Valid | Epoch[134/600] Iteration[004/008] Valid loss: 0.4247
2023-02-06 10:45:12 | Valid | Epoch[134/600] Iteration[005/008] Valid loss: 0.4455
2023-02-06 10:45:12 | Valid | Epoch[134/600] Iteration[006/008] Valid loss: 0.4337
2023-02-06 10:45:12 | Valid | Epoch[134/600] Iteration[007/008] Valid loss: 0.4608
2023-02-06 10:45:12 | Valid | Epoch[134/600] Iteration[008/008] Valid loss: 0.4689
2023-02-06 10:45:12 | Valid | Epoch[134/600] MIou: 0.8476218338737456
2023-02-06 10:45:12 | Valid | Epoch[134/600] Pixel Accuracy: 0.9671465555826823
2023-02-06 10:45:12 | Valid | Epoch[134/600] Mean Pixel Accuracy: 0.9774913347812466
2023-02-06 10:45:12 | Stage | Epoch[134/600] Train loss:0.0399
2023-02-06 10:45:12 | Stage | Epoch[134/600] Valid loss:0.4689
2023-02-06 10:45:12 | Stage | Epoch[134/600] LR:0.01

2023-02-06 10:45:12 | Train | Epoch[135/600] Iteration[001/030] Train loss: 0.0430
2023-02-06 10:45:12 | Train | Epoch[135/600] Iteration[002/030] Train loss: 0.0416
2023-02-06 10:45:12 | Train | Epoch[135/600] Iteration[003/030] Train loss: 0.0415
2023-02-06 10:45:12 | Train | Epoch[135/600] Iteration[004/030] Train loss: 0.0416
2023-02-06 10:45:12 | Train | Epoch[135/600] Iteration[005/030] Train loss: 0.0410
2023-02-06 10:45:12 | Train | Epoch[135/600] Iteration[006/030] Train loss: 0.0411
2023-02-06 10:45:12 | Train | Epoch[135/600] Iteration[007/030] Train loss: 0.0403
2023-02-06 10:45:12 | Train | Epoch[135/600] Iteration[008/030] Train loss: 0.0403
2023-02-06 10:45:12 | Train | Epoch[135/600] Iteration[009/030] Train loss: 0.0410
2023-02-06 10:45:12 | Train | Epoch[135/600] Iteration[010/030] Train loss: 0.0407
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[011/030] Train loss: 0.0409
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[012/030] Train loss: 0.0405
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[013/030] Train loss: 0.0404
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[014/030] Train loss: 0.0405
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[015/030] Train loss: 0.0404
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[016/030] Train loss: 0.0408
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[017/030] Train loss: 0.0408
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[018/030] Train loss: 0.0407
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[019/030] Train loss: 0.0407
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[020/030] Train loss: 0.0408
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[021/030] Train loss: 0.0406
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[022/030] Train loss: 0.0408
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[023/030] Train loss: 0.0406
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[024/030] Train loss: 0.0405
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[025/030] Train loss: 0.0405
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[026/030] Train loss: 0.0403
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[027/030] Train loss: 0.0403
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[028/030] Train loss: 0.0408
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[029/030] Train loss: 0.0407
2023-02-06 10:45:13 | Train | Epoch[135/600] Iteration[030/030] Train loss: 0.0406
2023-02-06 10:45:14 | Valid | Epoch[135/600] Iteration[001/008] Valid loss: 0.1308
2023-02-06 10:45:14 | Valid | Epoch[135/600] Iteration[002/008] Valid loss: 0.1068
2023-02-06 10:45:14 | Valid | Epoch[135/600] Iteration[003/008] Valid loss: 0.0992
2023-02-06 10:45:14 | Valid | Epoch[135/600] Iteration[004/008] Valid loss: 0.0987
2023-02-06 10:45:14 | Valid | Epoch[135/600] Iteration[005/008] Valid loss: 0.1005
2023-02-06 10:45:14 | Valid | Epoch[135/600] Iteration[006/008] Valid loss: 0.1027
2023-02-06 10:45:14 | Valid | Epoch[135/600] Iteration[007/008] Valid loss: 0.1094
2023-02-06 10:45:14 | Valid | Epoch[135/600] Iteration[008/008] Valid loss: 0.1063
2023-02-06 10:45:14 | Valid | Epoch[135/600] MIou: 0.9270919496812908
2023-02-06 10:45:14 | Valid | Epoch[135/600] Pixel Accuracy: 0.986785888671875
2023-02-06 10:45:14 | Valid | Epoch[135/600] Mean Pixel Accuracy: 0.9781792382541097
2023-02-06 10:45:14 | Stage | Epoch[135/600] Train loss:0.0406
2023-02-06 10:45:14 | Stage | Epoch[135/600] Valid loss:0.1063
2023-02-06 10:45:14 | Stage | Epoch[135/600] LR:0.01

2023-02-06 10:45:14 | Train | Epoch[136/600] Iteration[001/030] Train loss: 0.0459
2023-02-06 10:45:14 | Train | Epoch[136/600] Iteration[002/030] Train loss: 0.0427
2023-02-06 10:45:14 | Train | Epoch[136/600] Iteration[003/030] Train loss: 0.0445
2023-02-06 10:45:14 | Train | Epoch[136/600] Iteration[004/030] Train loss: 0.0428
2023-02-06 10:45:14 | Train | Epoch[136/600] Iteration[005/030] Train loss: 0.0426
2023-02-06 10:45:14 | Train | Epoch[136/600] Iteration[006/030] Train loss: 0.0423
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[007/030] Train loss: 0.0422
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[008/030] Train loss: 0.0418
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[009/030] Train loss: 0.0416
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[010/030] Train loss: 0.0412
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[011/030] Train loss: 0.0412
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[012/030] Train loss: 0.0414
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[013/030] Train loss: 0.0414
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[014/030] Train loss: 0.0413
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[015/030] Train loss: 0.0409
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[016/030] Train loss: 0.0408
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[017/030] Train loss: 0.0407
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[018/030] Train loss: 0.0407
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[019/030] Train loss: 0.0406
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[020/030] Train loss: 0.0405
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[021/030] Train loss: 0.0403
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[022/030] Train loss: 0.0402
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[023/030] Train loss: 0.0401
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[024/030] Train loss: 0.0400
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[025/030] Train loss: 0.0399
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[026/030] Train loss: 0.0396
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[027/030] Train loss: 0.0398
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[028/030] Train loss: 0.0397
2023-02-06 10:45:15 | Train | Epoch[136/600] Iteration[029/030] Train loss: 0.0397
2023-02-06 10:45:16 | Train | Epoch[136/600] Iteration[030/030] Train loss: 0.0396
2023-02-06 10:45:16 | Valid | Epoch[136/600] Iteration[001/008] Valid loss: 0.0645
2023-02-06 10:45:16 | Valid | Epoch[136/600] Iteration[002/008] Valid loss: 0.0639
2023-02-06 10:45:16 | Valid | Epoch[136/600] Iteration[003/008] Valid loss: 0.0658
2023-02-06 10:45:16 | Valid | Epoch[136/600] Iteration[004/008] Valid loss: 0.0652
2023-02-06 10:45:16 | Valid | Epoch[136/600] Iteration[005/008] Valid loss: 0.0659
2023-02-06 10:45:16 | Valid | Epoch[136/600] Iteration[006/008] Valid loss: 0.0650
2023-02-06 10:45:16 | Valid | Epoch[136/600] Iteration[007/008] Valid loss: 0.0639
2023-02-06 10:45:16 | Valid | Epoch[136/600] Iteration[008/008] Valid loss: 0.0649
2023-02-06 10:45:16 | Valid | Epoch[136/600] MIou: 0.8030127558531936
2023-02-06 10:45:16 | Valid | Epoch[136/600] Pixel Accuracy: 0.967529296875
2023-02-06 10:45:16 | Valid | Epoch[136/600] Mean Pixel Accuracy: 0.820248776659548
2023-02-06 10:45:16 | Stage | Epoch[136/600] Train loss:0.0396
2023-02-06 10:45:16 | Stage | Epoch[136/600] Valid loss:0.0649
2023-02-06 10:45:16 | Stage | Epoch[136/600] LR:0.01

2023-02-06 10:45:16 | Train | Epoch[137/600] Iteration[001/030] Train loss: 0.0384
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[002/030] Train loss: 0.0392
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[003/030] Train loss: 0.0382
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[004/030] Train loss: 0.0392
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[005/030] Train loss: 0.0394
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[006/030] Train loss: 0.0387
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[007/030] Train loss: 0.0382
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[008/030] Train loss: 0.0384
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[009/030] Train loss: 0.0389
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[010/030] Train loss: 0.0389
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[011/030] Train loss: 0.0390
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[012/030] Train loss: 0.0390
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[013/030] Train loss: 0.0389
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[014/030] Train loss: 0.0389
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[015/030] Train loss: 0.0390
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[016/030] Train loss: 0.0392
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[017/030] Train loss: 0.0393
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[018/030] Train loss: 0.0392
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[019/030] Train loss: 0.0392
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[020/030] Train loss: 0.0392
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[021/030] Train loss: 0.0391
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[022/030] Train loss: 0.0391
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[023/030] Train loss: 0.0392
2023-02-06 10:45:17 | Train | Epoch[137/600] Iteration[024/030] Train loss: 0.0391
2023-02-06 10:45:18 | Train | Epoch[137/600] Iteration[025/030] Train loss: 0.0391
2023-02-06 10:45:18 | Train | Epoch[137/600] Iteration[026/030] Train loss: 0.0392
2023-02-06 10:45:18 | Train | Epoch[137/600] Iteration[027/030] Train loss: 0.0392
2023-02-06 10:45:18 | Train | Epoch[137/600] Iteration[028/030] Train loss: 0.0391
2023-02-06 10:45:18 | Train | Epoch[137/600] Iteration[029/030] Train loss: 0.0390
2023-02-06 10:45:18 | Train | Epoch[137/600] Iteration[030/030] Train loss: 0.0390
2023-02-06 10:45:18 | Valid | Epoch[137/600] Iteration[001/008] Valid loss: 0.0813
2023-02-06 10:45:18 | Valid | Epoch[137/600] Iteration[002/008] Valid loss: 0.0641
2023-02-06 10:45:18 | Valid | Epoch[137/600] Iteration[003/008] Valid loss: 0.0613
2023-02-06 10:45:18 | Valid | Epoch[137/600] Iteration[004/008] Valid loss: 0.0594
2023-02-06 10:45:18 | Valid | Epoch[137/600] Iteration[005/008] Valid loss: 0.0610
2023-02-06 10:45:18 | Valid | Epoch[137/600] Iteration[006/008] Valid loss: 0.0595
2023-02-06 10:45:18 | Valid | Epoch[137/600] Iteration[007/008] Valid loss: 0.0632
2023-02-06 10:45:18 | Valid | Epoch[137/600] Iteration[008/008] Valid loss: 0.0618
2023-02-06 10:45:18 | Valid | Epoch[137/600] MIou: 0.9415124611466823
2023-02-06 10:45:18 | Valid | Epoch[137/600] Pixel Accuracy: 0.989837646484375
2023-02-06 10:45:18 | Valid | Epoch[137/600] Mean Pixel Accuracy: 0.9720705154853484
2023-02-06 10:45:18 | Stage | Epoch[137/600] Train loss:0.0390
2023-02-06 10:45:18 | Stage | Epoch[137/600] Valid loss:0.0618
2023-02-06 10:45:18 | Stage | Epoch[137/600] LR:0.01

2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[001/030] Train loss: 0.0387
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[002/030] Train loss: 0.0368
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[003/030] Train loss: 0.0374
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[004/030] Train loss: 0.0384
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[005/030] Train loss: 0.0393
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[006/030] Train loss: 0.0398
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[007/030] Train loss: 0.0396
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[008/030] Train loss: 0.0395
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[009/030] Train loss: 0.0392
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[010/030] Train loss: 0.0389
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[011/030] Train loss: 0.0388
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[012/030] Train loss: 0.0386
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[013/030] Train loss: 0.0389
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[014/030] Train loss: 0.0392
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[015/030] Train loss: 0.0391
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[016/030] Train loss: 0.0390
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[017/030] Train loss: 0.0388
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[018/030] Train loss: 0.0389
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[019/030] Train loss: 0.0390
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[020/030] Train loss: 0.0389
2023-02-06 10:45:19 | Train | Epoch[138/600] Iteration[021/030] Train loss: 0.0388
2023-02-06 10:45:20 | Train | Epoch[138/600] Iteration[022/030] Train loss: 0.0389
2023-02-06 10:45:20 | Train | Epoch[138/600] Iteration[023/030] Train loss: 0.0389
2023-02-06 10:45:20 | Train | Epoch[138/600] Iteration[024/030] Train loss: 0.0390
2023-02-06 10:45:20 | Train | Epoch[138/600] Iteration[025/030] Train loss: 0.0391
2023-02-06 10:45:20 | Train | Epoch[138/600] Iteration[026/030] Train loss: 0.0390
2023-02-06 10:45:20 | Train | Epoch[138/600] Iteration[027/030] Train loss: 0.0391
2023-02-06 10:45:20 | Train | Epoch[138/600] Iteration[028/030] Train loss: 0.0390
2023-02-06 10:45:20 | Train | Epoch[138/600] Iteration[029/030] Train loss: 0.0389
2023-02-06 10:45:20 | Train | Epoch[138/600] Iteration[030/030] Train loss: 0.0389
2023-02-06 10:45:20 | Valid | Epoch[138/600] Iteration[001/008] Valid loss: 0.0515
2023-02-06 10:45:20 | Valid | Epoch[138/600] Iteration[002/008] Valid loss: 0.0500
2023-02-06 10:45:20 | Valid | Epoch[138/600] Iteration[003/008] Valid loss: 0.0506
2023-02-06 10:45:20 | Valid | Epoch[138/600] Iteration[004/008] Valid loss: 0.0503
2023-02-06 10:45:20 | Valid | Epoch[138/600] Iteration[005/008] Valid loss: 0.0506
2023-02-06 10:45:20 | Valid | Epoch[138/600] Iteration[006/008] Valid loss: 0.0503
2023-02-06 10:45:20 | Valid | Epoch[138/600] Iteration[007/008] Valid loss: 0.0496
2023-02-06 10:45:20 | Valid | Epoch[138/600] Iteration[008/008] Valid loss: 0.0502
2023-02-06 10:45:21 | Valid | Epoch[138/600] MIou: 0.8562051537755484
2023-02-06 10:45:21 | Valid | Epoch[138/600] Pixel Accuracy: 0.9763005574544271
2023-02-06 10:45:21 | Valid | Epoch[138/600] Mean Pixel Accuracy: 0.8691487935111959
2023-02-06 10:45:21 | Stage | Epoch[138/600] Train loss:0.0389
2023-02-06 10:45:21 | Stage | Epoch[138/600] Valid loss:0.0502
2023-02-06 10:45:21 | Stage | Epoch[138/600] LR:0.01

2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[001/030] Train loss: 0.0386
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[002/030] Train loss: 0.0384
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[003/030] Train loss: 0.0393
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[004/030] Train loss: 0.0381
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[005/030] Train loss: 0.0382
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[006/030] Train loss: 0.0380
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[007/030] Train loss: 0.0385
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[008/030] Train loss: 0.0383
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[009/030] Train loss: 0.0380
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[010/030] Train loss: 0.0378
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[011/030] Train loss: 0.0378
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[012/030] Train loss: 0.0382
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[013/030] Train loss: 0.0380
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[014/030] Train loss: 0.0380
2023-02-06 10:45:21 | Train | Epoch[139/600] Iteration[015/030] Train loss: 0.0379
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[016/030] Train loss: 0.0379
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[017/030] Train loss: 0.0382
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[018/030] Train loss: 0.0383
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[019/030] Train loss: 0.0384
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[020/030] Train loss: 0.0384
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[021/030] Train loss: 0.0384
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[022/030] Train loss: 0.0384
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[023/030] Train loss: 0.0385
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[024/030] Train loss: 0.0385
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[025/030] Train loss: 0.0385
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[026/030] Train loss: 0.0383
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[027/030] Train loss: 0.0384
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[028/030] Train loss: 0.0382
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[029/030] Train loss: 0.0384
2023-02-06 10:45:22 | Train | Epoch[139/600] Iteration[030/030] Train loss: 0.0383
2023-02-06 10:45:22 | Valid | Epoch[139/600] Iteration[001/008] Valid loss: 0.0470
2023-02-06 10:45:22 | Valid | Epoch[139/600] Iteration[002/008] Valid loss: 0.0429
2023-02-06 10:45:23 | Valid | Epoch[139/600] Iteration[003/008] Valid loss: 0.0424
2023-02-06 10:45:23 | Valid | Epoch[139/600] Iteration[004/008] Valid loss: 0.0417
2023-02-06 10:45:23 | Valid | Epoch[139/600] Iteration[005/008] Valid loss: 0.0421
2023-02-06 10:45:23 | Valid | Epoch[139/600] Iteration[006/008] Valid loss: 0.0426
2023-02-06 10:45:23 | Valid | Epoch[139/600] Iteration[007/008] Valid loss: 0.0430
2023-02-06 10:45:23 | Valid | Epoch[139/600] Iteration[008/008] Valid loss: 0.0426
2023-02-06 10:45:23 | Valid | Epoch[139/600] MIou: 0.9191158825296758
2023-02-06 10:45:23 | Valid | Epoch[139/600] Pixel Accuracy: 0.9865633646647135
2023-02-06 10:45:23 | Valid | Epoch[139/600] Mean Pixel Accuracy: 0.9304273075706109
2023-02-06 10:45:23 | Stage | Epoch[139/600] Train loss:0.0383
2023-02-06 10:45:23 | Stage | Epoch[139/600] Valid loss:0.0426
2023-02-06 10:45:23 | Stage | Epoch[139/600] LR:0.01

2023-02-06 10:45:23 | Train | Epoch[140/600] Iteration[001/030] Train loss: 0.0387
2023-02-06 10:45:23 | Train | Epoch[140/600] Iteration[002/030] Train loss: 0.0368
2023-02-06 10:45:23 | Train | Epoch[140/600] Iteration[003/030] Train loss: 0.0379
2023-02-06 10:45:23 | Train | Epoch[140/600] Iteration[004/030] Train loss: 0.0384
2023-02-06 10:45:23 | Train | Epoch[140/600] Iteration[005/030] Train loss: 0.0382
2023-02-06 10:45:23 | Train | Epoch[140/600] Iteration[006/030] Train loss: 0.0385
2023-02-06 10:45:23 | Train | Epoch[140/600] Iteration[007/030] Train loss: 0.0379
2023-02-06 10:45:23 | Train | Epoch[140/600] Iteration[008/030] Train loss: 0.0378
2023-02-06 10:45:23 | Train | Epoch[140/600] Iteration[009/030] Train loss: 0.0379
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[010/030] Train loss: 0.0378
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[011/030] Train loss: 0.0376
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[012/030] Train loss: 0.0374
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[013/030] Train loss: 0.0372
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[014/030] Train loss: 0.0376
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[015/030] Train loss: 0.0378
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[016/030] Train loss: 0.0376
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[017/030] Train loss: 0.0378
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[018/030] Train loss: 0.0376
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[019/030] Train loss: 0.0380
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[020/030] Train loss: 0.0381
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[021/030] Train loss: 0.0381
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[022/030] Train loss: 0.0382
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[023/030] Train loss: 0.0382
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[024/030] Train loss: 0.0382
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[025/030] Train loss: 0.0383
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[026/030] Train loss: 0.0383
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[027/030] Train loss: 0.0383
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[028/030] Train loss: 0.0383
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[029/030] Train loss: 0.0382
2023-02-06 10:45:24 | Train | Epoch[140/600] Iteration[030/030] Train loss: 0.0382
2023-02-06 10:45:25 | Valid | Epoch[140/600] Iteration[001/008] Valid loss: 0.1447
2023-02-06 10:45:25 | Valid | Epoch[140/600] Iteration[002/008] Valid loss: 0.1106
2023-02-06 10:45:25 | Valid | Epoch[140/600] Iteration[003/008] Valid loss: 0.1049
2023-02-06 10:45:25 | Valid | Epoch[140/600] Iteration[004/008] Valid loss: 0.1017
2023-02-06 10:45:25 | Valid | Epoch[140/600] Iteration[005/008] Valid loss: 0.1041
2023-02-06 10:45:25 | Valid | Epoch[140/600] Iteration[006/008] Valid loss: 0.1023
2023-02-06 10:45:25 | Valid | Epoch[140/600] Iteration[007/008] Valid loss: 0.1111
2023-02-06 10:45:25 | Valid | Epoch[140/600] Iteration[008/008] Valid loss: 0.1094
2023-02-06 10:45:25 | Valid | Epoch[140/600] MIou: 0.9193516008749367
2023-02-06 10:45:25 | Valid | Epoch[140/600] Pixel Accuracy: 0.9850858052571615
2023-02-06 10:45:25 | Valid | Epoch[140/600] Mean Pixel Accuracy: 0.9801550763266238
2023-02-06 10:45:25 | Stage | Epoch[140/600] Train loss:0.0382
2023-02-06 10:45:25 | Stage | Epoch[140/600] Valid loss:0.1094
2023-02-06 10:45:25 | Stage | Epoch[140/600] LR:0.01

2023-02-06 10:45:25 | Train | Epoch[141/600] Iteration[001/030] Train loss: 0.0349
2023-02-06 10:45:25 | Train | Epoch[141/600] Iteration[002/030] Train loss: 0.0370
2023-02-06 10:45:25 | Train | Epoch[141/600] Iteration[003/030] Train loss: 0.0391
2023-02-06 10:45:25 | Train | Epoch[141/600] Iteration[004/030] Train loss: 0.0377
2023-02-06 10:45:25 | Train | Epoch[141/600] Iteration[005/030] Train loss: 0.0371
2023-02-06 10:45:25 | Train | Epoch[141/600] Iteration[006/030] Train loss: 0.0369
2023-02-06 10:45:25 | Train | Epoch[141/600] Iteration[007/030] Train loss: 0.0373
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[008/030] Train loss: 0.0374
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[009/030] Train loss: 0.0373
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[010/030] Train loss: 0.0379
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[011/030] Train loss: 0.0380
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[012/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[013/030] Train loss: 0.0380
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[014/030] Train loss: 0.0380
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[015/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[016/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[017/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[018/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[019/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[020/030] Train loss: 0.0381
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[021/030] Train loss: 0.0380
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[022/030] Train loss: 0.0379
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[023/030] Train loss: 0.0379
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[024/030] Train loss: 0.0377
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[025/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[026/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[027/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[028/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[029/030] Train loss: 0.0378
2023-02-06 10:45:26 | Train | Epoch[141/600] Iteration[030/030] Train loss: 0.0379
2023-02-06 10:45:27 | Valid | Epoch[141/600] Iteration[001/008] Valid loss: 0.0517
2023-02-06 10:45:27 | Valid | Epoch[141/600] Iteration[002/008] Valid loss: 0.0506
2023-02-06 10:45:27 | Valid | Epoch[141/600] Iteration[003/008] Valid loss: 0.0517
2023-02-06 10:45:27 | Valid | Epoch[141/600] Iteration[004/008] Valid loss: 0.0510
2023-02-06 10:45:27 | Valid | Epoch[141/600] Iteration[005/008] Valid loss: 0.0515
2023-02-06 10:45:27 | Valid | Epoch[141/600] Iteration[006/008] Valid loss: 0.0509
2023-02-06 10:45:27 | Valid | Epoch[141/600] Iteration[007/008] Valid loss: 0.0504
2023-02-06 10:45:27 | Valid | Epoch[141/600] Iteration[008/008] Valid loss: 0.0510
2023-02-06 10:45:27 | Valid | Epoch[141/600] MIou: 0.8540848879044303
2023-02-06 10:45:27 | Valid | Epoch[141/600] Pixel Accuracy: 0.9759521484375
2023-02-06 10:45:27 | Valid | Epoch[141/600] Mean Pixel Accuracy: 0.8671819610328253
2023-02-06 10:45:27 | Stage | Epoch[141/600] Train loss:0.0379
2023-02-06 10:45:27 | Stage | Epoch[141/600] Valid loss:0.0510
2023-02-06 10:45:27 | Stage | Epoch[141/600] LR:0.01

2023-02-06 10:45:27 | Train | Epoch[142/600] Iteration[001/030] Train loss: 0.0318
2023-02-06 10:45:27 | Train | Epoch[142/600] Iteration[002/030] Train loss: 0.0340
2023-02-06 10:45:27 | Train | Epoch[142/600] Iteration[003/030] Train loss: 0.0361
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[004/030] Train loss: 0.0370
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[005/030] Train loss: 0.0374
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[006/030] Train loss: 0.0371
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[007/030] Train loss: 0.0368
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[008/030] Train loss: 0.0373
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[009/030] Train loss: 0.0373
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[010/030] Train loss: 0.0377
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[011/030] Train loss: 0.0377
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[012/030] Train loss: 0.0379
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[013/030] Train loss: 0.0382
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[014/030] Train loss: 0.0381
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[015/030] Train loss: 0.0383
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[016/030] Train loss: 0.0380
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[017/030] Train loss: 0.0379
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[018/030] Train loss: 0.0382
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[019/030] Train loss: 0.0380
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[020/030] Train loss: 0.0382
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[021/030] Train loss: 0.0382
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[022/030] Train loss: 0.0383
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[023/030] Train loss: 0.0384
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[024/030] Train loss: 0.0384
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[025/030] Train loss: 0.0384
2023-02-06 10:45:28 | Train | Epoch[142/600] Iteration[026/030] Train loss: 0.0384
2023-02-06 10:45:29 | Train | Epoch[142/600] Iteration[027/030] Train loss: 0.0384
2023-02-06 10:45:29 | Train | Epoch[142/600] Iteration[028/030] Train loss: 0.0384
2023-02-06 10:45:29 | Train | Epoch[142/600] Iteration[029/030] Train loss: 0.0384
2023-02-06 10:45:29 | Train | Epoch[142/600] Iteration[030/030] Train loss: 0.0385
2023-02-06 10:45:29 | Valid | Epoch[142/600] Iteration[001/008] Valid loss: 0.0457
2023-02-06 10:45:29 | Valid | Epoch[142/600] Iteration[002/008] Valid loss: 0.0415
2023-02-06 10:45:29 | Valid | Epoch[142/600] Iteration[003/008] Valid loss: 0.0415
2023-02-06 10:45:29 | Valid | Epoch[142/600] Iteration[004/008] Valid loss: 0.0410
2023-02-06 10:45:29 | Valid | Epoch[142/600] Iteration[005/008] Valid loss: 0.0415
2023-02-06 10:45:29 | Valid | Epoch[142/600] Iteration[006/008] Valid loss: 0.0414
2023-02-06 10:45:29 | Valid | Epoch[142/600] Iteration[007/008] Valid loss: 0.0418
2023-02-06 10:45:29 | Valid | Epoch[142/600] Iteration[008/008] Valid loss: 0.0417
2023-02-06 10:45:29 | Valid | Epoch[142/600] MIou: 0.907786205914935
2023-02-06 10:45:29 | Valid | Epoch[142/600] Pixel Accuracy: 0.9847056070963541
2023-02-06 10:45:29 | Valid | Epoch[142/600] Mean Pixel Accuracy: 0.9192487694172448
2023-02-06 10:45:29 | Stage | Epoch[142/600] Train loss:0.0385
2023-02-06 10:45:29 | Stage | Epoch[142/600] Valid loss:0.0417
2023-02-06 10:45:29 | Stage | Epoch[142/600] LR:0.01

2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[001/030] Train loss: 0.0368
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[002/030] Train loss: 0.0355
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[003/030] Train loss: 0.0364
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[004/030] Train loss: 0.0374
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[005/030] Train loss: 0.0376
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[006/030] Train loss: 0.0374
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[007/030] Train loss: 0.0374
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[008/030] Train loss: 0.0374
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[009/030] Train loss: 0.0374
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[010/030] Train loss: 0.0374
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[011/030] Train loss: 0.0375
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[012/030] Train loss: 0.0377
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[013/030] Train loss: 0.0378
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[014/030] Train loss: 0.0376
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[015/030] Train loss: 0.0373
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[016/030] Train loss: 0.0372
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[017/030] Train loss: 0.0373
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[018/030] Train loss: 0.0374
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[019/030] Train loss: 0.0374
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[020/030] Train loss: 0.0373
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[021/030] Train loss: 0.0372
2023-02-06 10:45:30 | Train | Epoch[143/600] Iteration[022/030] Train loss: 0.0374
2023-02-06 10:45:31 | Train | Epoch[143/600] Iteration[023/030] Train loss: 0.0374
2023-02-06 10:45:31 | Train | Epoch[143/600] Iteration[024/030] Train loss: 0.0372
2023-02-06 10:45:31 | Train | Epoch[143/600] Iteration[025/030] Train loss: 0.0373
2023-02-06 10:45:31 | Train | Epoch[143/600] Iteration[026/030] Train loss: 0.0373
2023-02-06 10:45:31 | Train | Epoch[143/600] Iteration[027/030] Train loss: 0.0372
2023-02-06 10:45:31 | Train | Epoch[143/600] Iteration[028/030] Train loss: 0.0372
2023-02-06 10:45:31 | Train | Epoch[143/600] Iteration[029/030] Train loss: 0.0372
2023-02-06 10:45:31 | Train | Epoch[143/600] Iteration[030/030] Train loss: 0.0371
2023-02-06 10:45:31 | Valid | Epoch[143/600] Iteration[001/008] Valid loss: 0.5304
2023-02-06 10:45:31 | Valid | Epoch[143/600] Iteration[002/008] Valid loss: 0.4886
2023-02-06 10:45:31 | Valid | Epoch[143/600] Iteration[003/008] Valid loss: 0.4894
2023-02-06 10:45:31 | Valid | Epoch[143/600] Iteration[004/008] Valid loss: 0.4913
2023-02-06 10:45:31 | Valid | Epoch[143/600] Iteration[005/008] Valid loss: 0.5171
2023-02-06 10:45:31 | Valid | Epoch[143/600] Iteration[006/008] Valid loss: 0.5034
2023-02-06 10:45:31 | Valid | Epoch[143/600] Iteration[007/008] Valid loss: 0.5351
2023-02-06 10:45:31 | Valid | Epoch[143/600] Iteration[008/008] Valid loss: 0.5442
2023-02-06 10:45:31 | Valid | Epoch[143/600] MIou: 0.849788940549774
2023-02-06 10:45:31 | Valid | Epoch[143/600] Pixel Accuracy: 0.9677314758300781
2023-02-06 10:45:31 | Valid | Epoch[143/600] Mean Pixel Accuracy: 0.9782249625437458
2023-02-06 10:45:31 | Stage | Epoch[143/600] Train loss:0.0371
2023-02-06 10:45:31 | Stage | Epoch[143/600] Valid loss:0.5442
2023-02-06 10:45:31 | Stage | Epoch[143/600] LR:0.01

2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[001/030] Train loss: 0.0346
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[002/030] Train loss: 0.0361
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[003/030] Train loss: 0.0375
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[004/030] Train loss: 0.0366
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[005/030] Train loss: 0.0366
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[006/030] Train loss: 0.0376
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[007/030] Train loss: 0.0372
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[008/030] Train loss: 0.0375
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[009/030] Train loss: 0.0379
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[010/030] Train loss: 0.0376
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[011/030] Train loss: 0.0377
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[012/030] Train loss: 0.0373
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[013/030] Train loss: 0.0372
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[014/030] Train loss: 0.0374
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[015/030] Train loss: 0.0378
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[016/030] Train loss: 0.0377
2023-02-06 10:45:32 | Train | Epoch[144/600] Iteration[017/030] Train loss: 0.0381
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[018/030] Train loss: 0.0384
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[019/030] Train loss: 0.0383
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[020/030] Train loss: 0.0381
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[021/030] Train loss: 0.0382
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[022/030] Train loss: 0.0380
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[023/030] Train loss: 0.0381
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[024/030] Train loss: 0.0381
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[025/030] Train loss: 0.0381
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[026/030] Train loss: 0.0382
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[027/030] Train loss: 0.0381
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[028/030] Train loss: 0.0381
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[029/030] Train loss: 0.0380
2023-02-06 10:45:33 | Train | Epoch[144/600] Iteration[030/030] Train loss: 0.0380
2023-02-06 10:45:33 | Valid | Epoch[144/600] Iteration[001/008] Valid loss: 0.5796
2023-02-06 10:45:33 | Valid | Epoch[144/600] Iteration[002/008] Valid loss: 0.5717
2023-02-06 10:45:33 | Valid | Epoch[144/600] Iteration[003/008] Valid loss: 0.5537
2023-02-06 10:45:33 | Valid | Epoch[144/600] Iteration[004/008] Valid loss: 0.5541
2023-02-06 10:45:33 | Valid | Epoch[144/600] Iteration[005/008] Valid loss: 0.5742
2023-02-06 10:45:34 | Valid | Epoch[144/600] Iteration[006/008] Valid loss: 0.5616
2023-02-06 10:45:34 | Valid | Epoch[144/600] Iteration[007/008] Valid loss: 0.5890
2023-02-06 10:45:34 | Valid | Epoch[144/600] Iteration[008/008] Valid loss: 0.6125
2023-02-06 10:45:34 | Valid | Epoch[144/600] MIou: 0.8229891319751972
2023-02-06 10:45:34 | Valid | Epoch[144/600] Pixel Accuracy: 0.9597829182942709
2023-02-06 10:45:34 | Valid | Epoch[144/600] Mean Pixel Accuracy: 0.9742111627289627
2023-02-06 10:45:34 | Stage | Epoch[144/600] Train loss:0.0380
2023-02-06 10:45:34 | Stage | Epoch[144/600] Valid loss:0.6125
2023-02-06 10:45:34 | Stage | Epoch[144/600] LR:0.01

2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[001/030] Train loss: 0.0414
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[002/030] Train loss: 0.0383
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[003/030] Train loss: 0.0365
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[004/030] Train loss: 0.0366
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[005/030] Train loss: 0.0373
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[006/030] Train loss: 0.0378
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[007/030] Train loss: 0.0382
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[008/030] Train loss: 0.0385
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[009/030] Train loss: 0.0392
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[010/030] Train loss: 0.0392
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[011/030] Train loss: 0.0395
2023-02-06 10:45:34 | Train | Epoch[145/600] Iteration[012/030] Train loss: 0.0394
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[013/030] Train loss: 0.0394
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[014/030] Train loss: 0.0395
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[015/030] Train loss: 0.0397
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[016/030] Train loss: 0.0394
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[017/030] Train loss: 0.0392
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[018/030] Train loss: 0.0389
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[019/030] Train loss: 0.0389
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[020/030] Train loss: 0.0388
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[021/030] Train loss: 0.0389
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[022/030] Train loss: 0.0388
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[023/030] Train loss: 0.0391
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[024/030] Train loss: 0.0390
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[025/030] Train loss: 0.0391
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[026/030] Train loss: 0.0391
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[027/030] Train loss: 0.0392
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[028/030] Train loss: 0.0391
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[029/030] Train loss: 0.0391
2023-02-06 10:45:35 | Train | Epoch[145/600] Iteration[030/030] Train loss: 0.0391
2023-02-06 10:45:36 | Valid | Epoch[145/600] Iteration[001/008] Valid loss: 0.1886
2023-02-06 10:45:36 | Valid | Epoch[145/600] Iteration[002/008] Valid loss: 0.1819
2023-02-06 10:45:36 | Valid | Epoch[145/600] Iteration[003/008] Valid loss: 0.1883
2023-02-06 10:45:36 | Valid | Epoch[145/600] Iteration[004/008] Valid loss: 0.1893
2023-02-06 10:45:36 | Valid | Epoch[145/600] Iteration[005/008] Valid loss: 0.1928
2023-02-06 10:45:36 | Valid | Epoch[145/600] Iteration[006/008] Valid loss: 0.1905
2023-02-06 10:45:36 | Valid | Epoch[145/600] Iteration[007/008] Valid loss: 0.1878
2023-02-06 10:45:36 | Valid | Epoch[145/600] Iteration[008/008] Valid loss: 0.1919
2023-02-06 10:45:36 | Valid | Epoch[145/600] MIou: 0.5157159915845351
2023-02-06 10:45:36 | Valid | Epoch[145/600] Pixel Accuracy: 0.9198354085286459
2023-02-06 10:45:36 | Valid | Epoch[145/600] Mean Pixel Accuracy: 0.5562094355826493
2023-02-06 10:45:36 | Stage | Epoch[145/600] Train loss:0.0391
2023-02-06 10:45:36 | Stage | Epoch[145/600] Valid loss:0.1919
2023-02-06 10:45:36 | Stage | Epoch[145/600] LR:0.01

2023-02-06 10:45:36 | Train | Epoch[146/600] Iteration[001/030] Train loss: 0.0358
2023-02-06 10:45:36 | Train | Epoch[146/600] Iteration[002/030] Train loss: 0.0359
2023-02-06 10:45:36 | Train | Epoch[146/600] Iteration[003/030] Train loss: 0.0362
2023-02-06 10:45:36 | Train | Epoch[146/600] Iteration[004/030] Train loss: 0.0367
2023-02-06 10:45:36 | Train | Epoch[146/600] Iteration[005/030] Train loss: 0.0366
2023-02-06 10:45:36 | Train | Epoch[146/600] Iteration[006/030] Train loss: 0.0368
2023-02-06 10:45:36 | Train | Epoch[146/600] Iteration[007/030] Train loss: 0.0371
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[008/030] Train loss: 0.0371
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[009/030] Train loss: 0.0368
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[010/030] Train loss: 0.0371
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[011/030] Train loss: 0.0376
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[012/030] Train loss: 0.0376
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[013/030] Train loss: 0.0376
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[014/030] Train loss: 0.0374
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[015/030] Train loss: 0.0375
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[016/030] Train loss: 0.0373
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[017/030] Train loss: 0.0374
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[018/030] Train loss: 0.0371
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[019/030] Train loss: 0.0370
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[020/030] Train loss: 0.0369
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[021/030] Train loss: 0.0370
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[022/030] Train loss: 0.0375
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[023/030] Train loss: 0.0373
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[024/030] Train loss: 0.0372
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[025/030] Train loss: 0.0370
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[026/030] Train loss: 0.0372
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[027/030] Train loss: 0.0372
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[028/030] Train loss: 0.0373
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[029/030] Train loss: 0.0373
2023-02-06 10:45:37 | Train | Epoch[146/600] Iteration[030/030] Train loss: 0.0374
2023-02-06 10:45:38 | Valid | Epoch[146/600] Iteration[001/008] Valid loss: 0.0438
2023-02-06 10:45:38 | Valid | Epoch[146/600] Iteration[002/008] Valid loss: 0.0414
2023-02-06 10:45:38 | Valid | Epoch[146/600] Iteration[003/008] Valid loss: 0.0417
2023-02-06 10:45:38 | Valid | Epoch[146/600] Iteration[004/008] Valid loss: 0.0410
2023-02-06 10:45:38 | Valid | Epoch[146/600] Iteration[005/008] Valid loss: 0.0414
2023-02-06 10:45:38 | Valid | Epoch[146/600] Iteration[006/008] Valid loss: 0.0413
2023-02-06 10:45:38 | Valid | Epoch[146/600] Iteration[007/008] Valid loss: 0.0412
2023-02-06 10:45:38 | Valid | Epoch[146/600] Iteration[008/008] Valid loss: 0.0413
2023-02-06 10:45:38 | Valid | Epoch[146/600] MIou: 0.8984804162710849
2023-02-06 10:45:38 | Valid | Epoch[146/600] Pixel Accuracy: 0.9832369486490885
2023-02-06 10:45:38 | Valid | Epoch[146/600] Mean Pixel Accuracy: 0.9088103558710106
2023-02-06 10:45:38 | Stage | Epoch[146/600] Train loss:0.0374
2023-02-06 10:45:38 | Stage | Epoch[146/600] Valid loss:0.0413
2023-02-06 10:45:38 | Stage | Epoch[146/600] LR:0.01

2023-02-06 10:45:38 | Train | Epoch[147/600] Iteration[001/030] Train loss: 0.0360
2023-02-06 10:45:38 | Train | Epoch[147/600] Iteration[002/030] Train loss: 0.0350
2023-02-06 10:45:38 | Train | Epoch[147/600] Iteration[003/030] Train loss: 0.0357
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[004/030] Train loss: 0.0348
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[005/030] Train loss: 0.0349
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[006/030] Train loss: 0.0349
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[007/030] Train loss: 0.0353
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[008/030] Train loss: 0.0353
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[009/030] Train loss: 0.0351
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[010/030] Train loss: 0.0352
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[011/030] Train loss: 0.0351
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[012/030] Train loss: 0.0351
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[013/030] Train loss: 0.0352
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[014/030] Train loss: 0.0353
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[015/030] Train loss: 0.0354
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[016/030] Train loss: 0.0357
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[017/030] Train loss: 0.0359
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[018/030] Train loss: 0.0360
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[019/030] Train loss: 0.0360
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[020/030] Train loss: 0.0363
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[021/030] Train loss: 0.0364
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[022/030] Train loss: 0.0363
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[023/030] Train loss: 0.0361
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[024/030] Train loss: 0.0361
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[025/030] Train loss: 0.0361
2023-02-06 10:45:39 | Train | Epoch[147/600] Iteration[026/030] Train loss: 0.0362
2023-02-06 10:45:40 | Train | Epoch[147/600] Iteration[027/030] Train loss: 0.0363
2023-02-06 10:45:40 | Train | Epoch[147/600] Iteration[028/030] Train loss: 0.0363
2023-02-06 10:45:40 | Train | Epoch[147/600] Iteration[029/030] Train loss: 0.0366
2023-02-06 10:45:40 | Train | Epoch[147/600] Iteration[030/030] Train loss: 0.0366
2023-02-06 10:45:40 | Valid | Epoch[147/600] Iteration[001/008] Valid loss: 0.2157
2023-02-06 10:45:40 | Valid | Epoch[147/600] Iteration[002/008] Valid loss: 0.1659
2023-02-06 10:45:40 | Valid | Epoch[147/600] Iteration[003/008] Valid loss: 0.1545
2023-02-06 10:45:40 | Valid | Epoch[147/600] Iteration[004/008] Valid loss: 0.1517
2023-02-06 10:45:40 | Valid | Epoch[147/600] Iteration[005/008] Valid loss: 0.1551
2023-02-06 10:45:40 | Valid | Epoch[147/600] Iteration[006/008] Valid loss: 0.1525
2023-02-06 10:45:40 | Valid | Epoch[147/600] Iteration[007/008] Valid loss: 0.1658
2023-02-06 10:45:40 | Valid | Epoch[147/600] Iteration[008/008] Valid loss: 0.1641
2023-02-06 10:45:40 | Valid | Epoch[147/600] MIou: 0.9064970376068917
2023-02-06 10:45:40 | Valid | Epoch[147/600] Pixel Accuracy: 0.9822069803873698
2023-02-06 10:45:40 | Valid | Epoch[147/600] Mean Pixel Accuracy: 0.980868002086648
2023-02-06 10:45:40 | Stage | Epoch[147/600] Train loss:0.0366
2023-02-06 10:45:40 | Stage | Epoch[147/600] Valid loss:0.1641
2023-02-06 10:45:40 | Stage | Epoch[147/600] LR:0.01

2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[001/030] Train loss: 0.0320
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[002/030] Train loss: 0.0343
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[003/030] Train loss: 0.0351
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[004/030] Train loss: 0.0352
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[005/030] Train loss: 0.0352
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[006/030] Train loss: 0.0356
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[007/030] Train loss: 0.0351
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[008/030] Train loss: 0.0353
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[009/030] Train loss: 0.0352
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[010/030] Train loss: 0.0350
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[011/030] Train loss: 0.0356
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[012/030] Train loss: 0.0357
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[013/030] Train loss: 0.0357
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[014/030] Train loss: 0.0358
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[015/030] Train loss: 0.0360
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[016/030] Train loss: 0.0359
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[017/030] Train loss: 0.0360
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[018/030] Train loss: 0.0359
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[019/030] Train loss: 0.0360
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[020/030] Train loss: 0.0361
2023-02-06 10:45:41 | Train | Epoch[148/600] Iteration[021/030] Train loss: 0.0362
2023-02-06 10:45:42 | Train | Epoch[148/600] Iteration[022/030] Train loss: 0.0361
2023-02-06 10:45:42 | Train | Epoch[148/600] Iteration[023/030] Train loss: 0.0361
2023-02-06 10:45:42 | Train | Epoch[148/600] Iteration[024/030] Train loss: 0.0360
2023-02-06 10:45:42 | Train | Epoch[148/600] Iteration[025/030] Train loss: 0.0361
2023-02-06 10:45:42 | Train | Epoch[148/600] Iteration[026/030] Train loss: 0.0361
2023-02-06 10:45:42 | Train | Epoch[148/600] Iteration[027/030] Train loss: 0.0360
2023-02-06 10:45:42 | Train | Epoch[148/600] Iteration[028/030] Train loss: 0.0359
2023-02-06 10:45:42 | Train | Epoch[148/600] Iteration[029/030] Train loss: 0.0360
2023-02-06 10:45:42 | Train | Epoch[148/600] Iteration[030/030] Train loss: 0.0361
2023-02-06 10:45:42 | Valid | Epoch[148/600] Iteration[001/008] Valid loss: 0.0537
2023-02-06 10:45:42 | Valid | Epoch[148/600] Iteration[002/008] Valid loss: 0.0528
2023-02-06 10:45:42 | Valid | Epoch[148/600] Iteration[003/008] Valid loss: 0.0546
2023-02-06 10:45:42 | Valid | Epoch[148/600] Iteration[004/008] Valid loss: 0.0540
2023-02-06 10:45:42 | Valid | Epoch[148/600] Iteration[005/008] Valid loss: 0.0544
2023-02-06 10:45:42 | Valid | Epoch[148/600] Iteration[006/008] Valid loss: 0.0537
2023-02-06 10:45:42 | Valid | Epoch[148/600] Iteration[007/008] Valid loss: 0.0527
2023-02-06 10:45:42 | Valid | Epoch[148/600] Iteration[008/008] Valid loss: 0.0536
2023-02-06 10:45:42 | Valid | Epoch[148/600] MIou: 0.8286539658682374
2023-02-06 10:45:42 | Valid | Epoch[148/600] Pixel Accuracy: 0.9717674255371094
2023-02-06 10:45:42 | Valid | Epoch[148/600] Mean Pixel Accuracy: 0.8437046840023089
2023-02-06 10:45:42 | Stage | Epoch[148/600] Train loss:0.0361
2023-02-06 10:45:42 | Stage | Epoch[148/600] Valid loss:0.0536
2023-02-06 10:45:42 | Stage | Epoch[148/600] LR:0.01

2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[001/030] Train loss: 0.0365
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[002/030] Train loss: 0.0388
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[003/030] Train loss: 0.0385
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[004/030] Train loss: 0.0377
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[005/030] Train loss: 0.0363
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[006/030] Train loss: 0.0365
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[007/030] Train loss: 0.0365
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[008/030] Train loss: 0.0364
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[009/030] Train loss: 0.0365
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[010/030] Train loss: 0.0367
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[011/030] Train loss: 0.0367
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[012/030] Train loss: 0.0364
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[013/030] Train loss: 0.0365
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[014/030] Train loss: 0.0365
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[015/030] Train loss: 0.0364
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[016/030] Train loss: 0.0363
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[017/030] Train loss: 0.0367
2023-02-06 10:45:43 | Train | Epoch[149/600] Iteration[018/030] Train loss: 0.0366
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[019/030] Train loss: 0.0365
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[020/030] Train loss: 0.0363
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[021/030] Train loss: 0.0365
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[022/030] Train loss: 0.0364
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[023/030] Train loss: 0.0363
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[024/030] Train loss: 0.0364
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[025/030] Train loss: 0.0364
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[026/030] Train loss: 0.0363
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[027/030] Train loss: 0.0364
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[028/030] Train loss: 0.0364
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[029/030] Train loss: 0.0364
2023-02-06 10:45:44 | Train | Epoch[149/600] Iteration[030/030] Train loss: 0.0365
2023-02-06 10:45:44 | Valid | Epoch[149/600] Iteration[001/008] Valid loss: 0.6131
2023-02-06 10:45:44 | Valid | Epoch[149/600] Iteration[002/008] Valid loss: 0.5668
2023-02-06 10:45:44 | Valid | Epoch[149/600] Iteration[003/008] Valid loss: 0.5663
2023-02-06 10:45:44 | Valid | Epoch[149/600] Iteration[004/008] Valid loss: 0.5670
2023-02-06 10:45:44 | Valid | Epoch[149/600] Iteration[005/008] Valid loss: 0.5939
2023-02-06 10:45:44 | Valid | Epoch[149/600] Iteration[006/008] Valid loss: 0.5826
2023-02-06 10:45:44 | Valid | Epoch[149/600] Iteration[007/008] Valid loss: 0.6190
2023-02-06 10:45:44 | Valid | Epoch[149/600] Iteration[008/008] Valid loss: 0.6307
2023-02-06 10:45:45 | Valid | Epoch[149/600] MIou: 0.8401238187810309
2023-02-06 10:45:45 | Valid | Epoch[149/600] Pixel Accuracy: 0.9649213155110677
2023-02-06 10:45:45 | Valid | Epoch[149/600] Mean Pixel Accuracy: 0.9774348946919162
2023-02-06 10:45:45 | Stage | Epoch[149/600] Train loss:0.0365
2023-02-06 10:45:45 | Stage | Epoch[149/600] Valid loss:0.6307
2023-02-06 10:45:45 | Stage | Epoch[149/600] LR:0.01

2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[001/030] Train loss: 0.0387
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[002/030] Train loss: 0.0370
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[003/030] Train loss: 0.0374
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[004/030] Train loss: 0.0369
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[005/030] Train loss: 0.0367
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[006/030] Train loss: 0.0366
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[007/030] Train loss: 0.0365
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[008/030] Train loss: 0.0365
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[009/030] Train loss: 0.0367
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[010/030] Train loss: 0.0369
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[011/030] Train loss: 0.0365
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[012/030] Train loss: 0.0364
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[013/030] Train loss: 0.0364
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[014/030] Train loss: 0.0367
2023-02-06 10:45:45 | Train | Epoch[150/600] Iteration[015/030] Train loss: 0.0367
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[016/030] Train loss: 0.0368
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[017/030] Train loss: 0.0367
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[018/030] Train loss: 0.0366
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[019/030] Train loss: 0.0367
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[020/030] Train loss: 0.0367
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[021/030] Train loss: 0.0366
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[022/030] Train loss: 0.0366
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[023/030] Train loss: 0.0365
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[024/030] Train loss: 0.0364
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[025/030] Train loss: 0.0363
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[026/030] Train loss: 0.0363
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[027/030] Train loss: 0.0362
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[028/030] Train loss: 0.0363
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[029/030] Train loss: 0.0362
2023-02-06 10:45:46 | Train | Epoch[150/600] Iteration[030/030] Train loss: 0.0364
2023-02-06 10:45:46 | Valid | Epoch[150/600] Iteration[001/008] Valid loss: 0.0844
2023-02-06 10:45:47 | Valid | Epoch[150/600] Iteration[002/008] Valid loss: 0.0836
2023-02-06 10:45:47 | Valid | Epoch[150/600] Iteration[003/008] Valid loss: 0.0869
2023-02-06 10:45:47 | Valid | Epoch[150/600] Iteration[004/008] Valid loss: 0.0868
2023-02-06 10:45:47 | Valid | Epoch[150/600] Iteration[005/008] Valid loss: 0.0878
2023-02-06 10:45:47 | Valid | Epoch[150/600] Iteration[006/008] Valid loss: 0.0863
2023-02-06 10:45:47 | Valid | Epoch[150/600] Iteration[007/008] Valid loss: 0.0843
2023-02-06 10:45:47 | Valid | Epoch[150/600] Iteration[008/008] Valid loss: 0.0862
2023-02-06 10:45:47 | Valid | Epoch[150/600] MIou: 0.7246759236645555
2023-02-06 10:45:47 | Valid | Epoch[150/600] Pixel Accuracy: 0.9545631408691406
2023-02-06 10:45:47 | Valid | Epoch[150/600] Mean Pixel Accuracy: 0.7484618958453589
2023-02-06 10:45:47 | Stage | Epoch[150/600] Train loss:0.0364
2023-02-06 10:45:47 | Stage | Epoch[150/600] Valid loss:0.0862
2023-02-06 10:45:47 | Stage | Epoch[150/600] LR:0.01

2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[001/030] Train loss: 0.0335
2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[002/030] Train loss: 0.0356
2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[003/030] Train loss: 0.0349
2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[004/030] Train loss: 0.0353
2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[005/030] Train loss: 0.0363
2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[006/030] Train loss: 0.0362
2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[007/030] Train loss: 0.0359
2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[008/030] Train loss: 0.0361
2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[009/030] Train loss: 0.0360
2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[010/030] Train loss: 0.0361
2023-02-06 10:45:47 | Train | Epoch[151/600] Iteration[011/030] Train loss: 0.0366
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[012/030] Train loss: 0.0368
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[013/030] Train loss: 0.0363
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[014/030] Train loss: 0.0365
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[015/030] Train loss: 0.0363
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[016/030] Train loss: 0.0362
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[017/030] Train loss: 0.0360
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[018/030] Train loss: 0.0361
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[019/030] Train loss: 0.0362
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[020/030] Train loss: 0.0360
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[021/030] Train loss: 0.0361
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[022/030] Train loss: 0.0362
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[023/030] Train loss: 0.0363
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[024/030] Train loss: 0.0362
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[025/030] Train loss: 0.0363
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[026/030] Train loss: 0.0362
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[027/030] Train loss: 0.0362
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[028/030] Train loss: 0.0363
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[029/030] Train loss: 0.0362
2023-02-06 10:45:48 | Train | Epoch[151/600] Iteration[030/030] Train loss: 0.0363
2023-02-06 10:45:49 | Valid | Epoch[151/600] Iteration[001/008] Valid loss: 0.0431
2023-02-06 10:45:49 | Valid | Epoch[151/600] Iteration[002/008] Valid loss: 0.0395
2023-02-06 10:45:49 | Valid | Epoch[151/600] Iteration[003/008] Valid loss: 0.0393
2023-02-06 10:45:49 | Valid | Epoch[151/600] Iteration[004/008] Valid loss: 0.0387
2023-02-06 10:45:49 | Valid | Epoch[151/600] Iteration[005/008] Valid loss: 0.0392
2023-02-06 10:45:49 | Valid | Epoch[151/600] Iteration[006/008] Valid loss: 0.0390
2023-02-06 10:45:49 | Valid | Epoch[151/600] Iteration[007/008] Valid loss: 0.0394
2023-02-06 10:45:49 | Valid | Epoch[151/600] Iteration[008/008] Valid loss: 0.0393
2023-02-06 10:45:49 | Valid | Epoch[151/600] MIou: 0.913406269766748
2023-02-06 10:45:49 | Valid | Epoch[151/600] Pixel Accuracy: 0.9856211344401041
2023-02-06 10:45:49 | Valid | Epoch[151/600] Mean Pixel Accuracy: 0.9249448284600599
2023-02-06 10:45:49 | Stage | Epoch[151/600] Train loss:0.0363
2023-02-06 10:45:49 | Stage | Epoch[151/600] Valid loss:0.0393
2023-02-06 10:45:49 | Stage | Epoch[151/600] LR:0.01

2023-02-06 10:45:49 | Train | Epoch[152/600] Iteration[001/030] Train loss: 0.0328
2023-02-06 10:45:49 | Train | Epoch[152/600] Iteration[002/030] Train loss: 0.0343
2023-02-06 10:45:49 | Train | Epoch[152/600] Iteration[003/030] Train loss: 0.0348
2023-02-06 10:45:49 | Train | Epoch[152/600] Iteration[004/030] Train loss: 0.0342
2023-02-06 10:45:49 | Train | Epoch[152/600] Iteration[005/030] Train loss: 0.0343
2023-02-06 10:45:49 | Train | Epoch[152/600] Iteration[006/030] Train loss: 0.0359
2023-02-06 10:45:49 | Train | Epoch[152/600] Iteration[007/030] Train loss: 0.0364
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[008/030] Train loss: 0.0365
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[009/030] Train loss: 0.0362
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[010/030] Train loss: 0.0359
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[011/030] Train loss: 0.0361
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[012/030] Train loss: 0.0360
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[013/030] Train loss: 0.0364
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[014/030] Train loss: 0.0362
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[015/030] Train loss: 0.0360
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[016/030] Train loss: 0.0359
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[017/030] Train loss: 0.0359
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[018/030] Train loss: 0.0360
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[019/030] Train loss: 0.0360
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[020/030] Train loss: 0.0359
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[021/030] Train loss: 0.0359
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[022/030] Train loss: 0.0357
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[023/030] Train loss: 0.0358
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[024/030] Train loss: 0.0358
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[025/030] Train loss: 0.0358
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[026/030] Train loss: 0.0360
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[027/030] Train loss: 0.0360
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[028/030] Train loss: 0.0360
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[029/030] Train loss: 0.0359
2023-02-06 10:45:50 | Train | Epoch[152/600] Iteration[030/030] Train loss: 0.0360
2023-02-06 10:45:51 | Valid | Epoch[152/600] Iteration[001/008] Valid loss: 0.1632
2023-02-06 10:45:51 | Valid | Epoch[152/600] Iteration[002/008] Valid loss: 0.1640
2023-02-06 10:45:51 | Valid | Epoch[152/600] Iteration[003/008] Valid loss: 0.1717
2023-02-06 10:45:51 | Valid | Epoch[152/600] Iteration[004/008] Valid loss: 0.1717
2023-02-06 10:45:51 | Valid | Epoch[152/600] Iteration[005/008] Valid loss: 0.1764
2023-02-06 10:45:51 | Valid | Epoch[152/600] Iteration[006/008] Valid loss: 0.1732
2023-02-06 10:45:51 | Valid | Epoch[152/600] Iteration[007/008] Valid loss: 0.1702
2023-02-06 10:45:51 | Valid | Epoch[152/600] Iteration[008/008] Valid loss: 0.1756
2023-02-06 10:45:51 | Valid | Epoch[152/600] MIou: 0.5028316466974211
2023-02-06 10:45:51 | Valid | Epoch[152/600] Pixel Accuracy: 0.917687733968099
2023-02-06 10:45:51 | Valid | Epoch[152/600] Mean Pixel Accuracy: 0.5443199256641653
2023-02-06 10:45:51 | Stage | Epoch[152/600] Train loss:0.0360
2023-02-06 10:45:51 | Stage | Epoch[152/600] Valid loss:0.1756
2023-02-06 10:45:51 | Stage | Epoch[152/600] LR:0.01

2023-02-06 10:45:51 | Train | Epoch[153/600] Iteration[001/030] Train loss: 0.0348
2023-02-06 10:45:51 | Train | Epoch[153/600] Iteration[002/030] Train loss: 0.0341
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[003/030] Train loss: 0.0333
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[004/030] Train loss: 0.0325
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[005/030] Train loss: 0.0335
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[006/030] Train loss: 0.0334
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[007/030] Train loss: 0.0331
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[008/030] Train loss: 0.0335
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[009/030] Train loss: 0.0338
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[010/030] Train loss: 0.0339
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[011/030] Train loss: 0.0342
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[012/030] Train loss: 0.0341
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[013/030] Train loss: 0.0341
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[014/030] Train loss: 0.0341
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[015/030] Train loss: 0.0346
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[016/030] Train loss: 0.0351
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[017/030] Train loss: 0.0352
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[018/030] Train loss: 0.0352
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[019/030] Train loss: 0.0357
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[020/030] Train loss: 0.0356
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[021/030] Train loss: 0.0359
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[022/030] Train loss: 0.0359
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[023/030] Train loss: 0.0359
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[024/030] Train loss: 0.0359
2023-02-06 10:45:52 | Train | Epoch[153/600] Iteration[025/030] Train loss: 0.0358
2023-02-06 10:45:53 | Train | Epoch[153/600] Iteration[026/030] Train loss: 0.0358
2023-02-06 10:45:53 | Train | Epoch[153/600] Iteration[027/030] Train loss: 0.0357
2023-02-06 10:45:53 | Train | Epoch[153/600] Iteration[028/030] Train loss: 0.0360
2023-02-06 10:45:53 | Train | Epoch[153/600] Iteration[029/030] Train loss: 0.0360
2023-02-06 10:45:53 | Train | Epoch[153/600] Iteration[030/030] Train loss: 0.0361
2023-02-06 10:45:53 | Valid | Epoch[153/600] Iteration[001/008] Valid loss: 0.0574
2023-02-06 10:45:53 | Valid | Epoch[153/600] Iteration[002/008] Valid loss: 0.0550
2023-02-06 10:45:53 | Valid | Epoch[153/600] Iteration[003/008] Valid loss: 0.0564
2023-02-06 10:45:53 | Valid | Epoch[153/600] Iteration[004/008] Valid loss: 0.0554
2023-02-06 10:45:53 | Valid | Epoch[153/600] Iteration[005/008] Valid loss: 0.0555
2023-02-06 10:45:53 | Valid | Epoch[153/600] Iteration[006/008] Valid loss: 0.0550
2023-02-06 10:45:53 | Valid | Epoch[153/600] Iteration[007/008] Valid loss: 0.0540
2023-02-06 10:45:53 | Valid | Epoch[153/600] Iteration[008/008] Valid loss: 0.0545
2023-02-06 10:45:53 | Valid | Epoch[153/600] MIou: 0.8435971605137436
2023-02-06 10:45:53 | Valid | Epoch[153/600] Pixel Accuracy: 0.9742342631022135
2023-02-06 10:45:53 | Valid | Epoch[153/600] Mean Pixel Accuracy: 0.8573864397556509
2023-02-06 10:45:53 | Stage | Epoch[153/600] Train loss:0.0361
2023-02-06 10:45:53 | Stage | Epoch[153/600] Valid loss:0.0545
2023-02-06 10:45:53 | Stage | Epoch[153/600] LR:0.01

2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[001/030] Train loss: 0.0331
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[002/030] Train loss: 0.0329
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[003/030] Train loss: 0.0332
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[004/030] Train loss: 0.0356
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[005/030] Train loss: 0.0352
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[006/030] Train loss: 0.0352
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[007/030] Train loss: 0.0352
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[008/030] Train loss: 0.0348
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[009/030] Train loss: 0.0348
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[010/030] Train loss: 0.0351
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[011/030] Train loss: 0.0350
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[012/030] Train loss: 0.0353
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[013/030] Train loss: 0.0355
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[014/030] Train loss: 0.0355
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[015/030] Train loss: 0.0356
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[016/030] Train loss: 0.0354
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[017/030] Train loss: 0.0355
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[018/030] Train loss: 0.0355
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[019/030] Train loss: 0.0356
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[020/030] Train loss: 0.0355
2023-02-06 10:45:54 | Train | Epoch[154/600] Iteration[021/030] Train loss: 0.0355
2023-02-06 10:45:55 | Train | Epoch[154/600] Iteration[022/030] Train loss: 0.0356
2023-02-06 10:45:55 | Train | Epoch[154/600] Iteration[023/030] Train loss: 0.0355
2023-02-06 10:45:55 | Train | Epoch[154/600] Iteration[024/030] Train loss: 0.0355
2023-02-06 10:45:55 | Train | Epoch[154/600] Iteration[025/030] Train loss: 0.0355
2023-02-06 10:45:55 | Train | Epoch[154/600] Iteration[026/030] Train loss: 0.0355
2023-02-06 10:45:55 | Train | Epoch[154/600] Iteration[027/030] Train loss: 0.0356
2023-02-06 10:45:55 | Train | Epoch[154/600] Iteration[028/030] Train loss: 0.0356
2023-02-06 10:45:55 | Train | Epoch[154/600] Iteration[029/030] Train loss: 0.0355
2023-02-06 10:45:55 | Train | Epoch[154/600] Iteration[030/030] Train loss: 0.0355
2023-02-06 10:45:55 | Valid | Epoch[154/600] Iteration[001/008] Valid loss: 0.0523
2023-02-06 10:45:55 | Valid | Epoch[154/600] Iteration[002/008] Valid loss: 0.0487
2023-02-06 10:45:55 | Valid | Epoch[154/600] Iteration[003/008] Valid loss: 0.0489
2023-02-06 10:45:55 | Valid | Epoch[154/600] Iteration[004/008] Valid loss: 0.0477
2023-02-06 10:45:55 | Valid | Epoch[154/600] Iteration[005/008] Valid loss: 0.0479
2023-02-06 10:45:55 | Valid | Epoch[154/600] Iteration[006/008] Valid loss: 0.0472
2023-02-06 10:45:55 | Valid | Epoch[154/600] Iteration[007/008] Valid loss: 0.0468
2023-02-06 10:45:55 | Valid | Epoch[154/600] Iteration[008/008] Valid loss: 0.0471
2023-02-06 10:45:55 | Valid | Epoch[154/600] MIou: 0.8840976777049545
2023-02-06 10:45:55 | Valid | Epoch[154/600] Pixel Accuracy: 0.9807383219401041
2023-02-06 10:45:55 | Valid | Epoch[154/600] Mean Pixel Accuracy: 0.8980974895306073
2023-02-06 10:45:55 | Stage | Epoch[154/600] Train loss:0.0355
2023-02-06 10:45:55 | Stage | Epoch[154/600] Valid loss:0.0471
2023-02-06 10:45:55 | Stage | Epoch[154/600] LR:0.01

2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[001/030] Train loss: 0.0395
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[002/030] Train loss: 0.0374
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[003/030] Train loss: 0.0355
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[004/030] Train loss: 0.0352
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[005/030] Train loss: 0.0365
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[006/030] Train loss: 0.0363
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[007/030] Train loss: 0.0361
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[008/030] Train loss: 0.0358
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[009/030] Train loss: 0.0359
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[010/030] Train loss: 0.0364
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[011/030] Train loss: 0.0363
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[012/030] Train loss: 0.0362
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[013/030] Train loss: 0.0364
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[014/030] Train loss: 0.0361
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[015/030] Train loss: 0.0361
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[016/030] Train loss: 0.0361
2023-02-06 10:45:56 | Train | Epoch[155/600] Iteration[017/030] Train loss: 0.0362
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[018/030] Train loss: 0.0362
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[019/030] Train loss: 0.0361
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[020/030] Train loss: 0.0358
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[021/030] Train loss: 0.0356
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[022/030] Train loss: 0.0357
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[023/030] Train loss: 0.0357
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[024/030] Train loss: 0.0358
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[025/030] Train loss: 0.0360
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[026/030] Train loss: 0.0359
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[027/030] Train loss: 0.0359
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[028/030] Train loss: 0.0358
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[029/030] Train loss: 0.0359
2023-02-06 10:45:57 | Train | Epoch[155/600] Iteration[030/030] Train loss: 0.0357
2023-02-06 10:45:57 | Valid | Epoch[155/600] Iteration[001/008] Valid loss: 0.1281
2023-02-06 10:45:57 | Valid | Epoch[155/600] Iteration[002/008] Valid loss: 0.1271
2023-02-06 10:45:57 | Valid | Epoch[155/600] Iteration[003/008] Valid loss: 0.1320
2023-02-06 10:45:57 | Valid | Epoch[155/600] Iteration[004/008] Valid loss: 0.1327
2023-02-06 10:45:57 | Valid | Epoch[155/600] Iteration[005/008] Valid loss: 0.1356
2023-02-06 10:45:57 | Valid | Epoch[155/600] Iteration[006/008] Valid loss: 0.1334
2023-02-06 10:45:58 | Valid | Epoch[155/600] Iteration[007/008] Valid loss: 0.1310
2023-02-06 10:45:58 | Valid | Epoch[155/600] Iteration[008/008] Valid loss: 0.1339
2023-02-06 10:45:58 | Valid | Epoch[155/600] MIou: 0.601425330174107
2023-02-06 10:45:58 | Valid | Epoch[155/600] Pixel Accuracy: 0.9341036478678385
2023-02-06 10:45:58 | Valid | Epoch[155/600] Mean Pixel Accuracy: 0.6351982992862071
2023-02-06 10:45:58 | Stage | Epoch[155/600] Train loss:0.0357
2023-02-06 10:45:58 | Stage | Epoch[155/600] Valid loss:0.1339
2023-02-06 10:45:58 | Stage | Epoch[155/600] LR:0.01

2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[001/030] Train loss: 0.0370
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[002/030] Train loss: 0.0380
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[003/030] Train loss: 0.0374
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[004/030] Train loss: 0.0378
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[005/030] Train loss: 0.0364
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[006/030] Train loss: 0.0362
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[007/030] Train loss: 0.0364
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[008/030] Train loss: 0.0359
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[009/030] Train loss: 0.0356
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[010/030] Train loss: 0.0368
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[011/030] Train loss: 0.0365
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[012/030] Train loss: 0.0362
2023-02-06 10:45:58 | Train | Epoch[156/600] Iteration[013/030] Train loss: 0.0362
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[014/030] Train loss: 0.0362
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[015/030] Train loss: 0.0360
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[016/030] Train loss: 0.0361
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[017/030] Train loss: 0.0361
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[018/030] Train loss: 0.0360
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[019/030] Train loss: 0.0360
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[020/030] Train loss: 0.0361
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[021/030] Train loss: 0.0361
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[022/030] Train loss: 0.0360
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[023/030] Train loss: 0.0360
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[024/030] Train loss: 0.0360
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[025/030] Train loss: 0.0359
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[026/030] Train loss: 0.0359
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[027/030] Train loss: 0.0358
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[028/030] Train loss: 0.0358
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[029/030] Train loss: 0.0357
2023-02-06 10:45:59 | Train | Epoch[156/600] Iteration[030/030] Train loss: 0.0358
2023-02-06 10:46:00 | Valid | Epoch[156/600] Iteration[001/008] Valid loss: 0.0507
2023-02-06 10:46:00 | Valid | Epoch[156/600] Iteration[002/008] Valid loss: 0.0447
2023-02-06 10:46:00 | Valid | Epoch[156/600] Iteration[003/008] Valid loss: 0.0431
2023-02-06 10:46:00 | Valid | Epoch[156/600] Iteration[004/008] Valid loss: 0.0421
2023-02-06 10:46:00 | Valid | Epoch[156/600] Iteration[005/008] Valid loss: 0.0424
2023-02-06 10:46:00 | Valid | Epoch[156/600] Iteration[006/008] Valid loss: 0.0417
2023-02-06 10:46:00 | Valid | Epoch[156/600] Iteration[007/008] Valid loss: 0.0421
2023-02-06 10:46:00 | Valid | Epoch[156/600] Iteration[008/008] Valid loss: 0.0421
2023-02-06 10:46:00 | Valid | Epoch[156/600] MIou: 0.9177676557918322
2023-02-06 10:46:00 | Valid | Epoch[156/600] Pixel Accuracy: 0.9861844380696615
2023-02-06 10:46:00 | Valid | Epoch[156/600] Mean Pixel Accuracy: 0.9340486781464381
2023-02-06 10:46:00 | Stage | Epoch[156/600] Train loss:0.0358
2023-02-06 10:46:00 | Stage | Epoch[156/600] Valid loss:0.0421
2023-02-06 10:46:00 | Stage | Epoch[156/600] LR:0.01

2023-02-06 10:46:00 | Train | Epoch[157/600] Iteration[001/030] Train loss: 0.0314
2023-02-06 10:46:00 | Train | Epoch[157/600] Iteration[002/030] Train loss: 0.0310
2023-02-06 10:46:00 | Train | Epoch[157/600] Iteration[003/030] Train loss: 0.0324
2023-02-06 10:46:00 | Train | Epoch[157/600] Iteration[004/030] Train loss: 0.0333
2023-02-06 10:46:00 | Train | Epoch[157/600] Iteration[005/030] Train loss: 0.0329
2023-02-06 10:46:00 | Train | Epoch[157/600] Iteration[006/030] Train loss: 0.0336
2023-02-06 10:46:00 | Train | Epoch[157/600] Iteration[007/030] Train loss: 0.0333
2023-02-06 10:46:00 | Train | Epoch[157/600] Iteration[008/030] Train loss: 0.0335
2023-02-06 10:46:00 | Train | Epoch[157/600] Iteration[009/030] Train loss: 0.0337
2023-02-06 10:46:00 | Train | Epoch[157/600] Iteration[010/030] Train loss: 0.0336
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[011/030] Train loss: 0.0333
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[012/030] Train loss: 0.0336
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[013/030] Train loss: 0.0338
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[014/030] Train loss: 0.0343
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[015/030] Train loss: 0.0343
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[016/030] Train loss: 0.0342
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[017/030] Train loss: 0.0343
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[018/030] Train loss: 0.0344
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[019/030] Train loss: 0.0345
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[020/030] Train loss: 0.0347
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[021/030] Train loss: 0.0350
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[022/030] Train loss: 0.0350
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[023/030] Train loss: 0.0351
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[024/030] Train loss: 0.0352
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[025/030] Train loss: 0.0354
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[026/030] Train loss: 0.0355
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[027/030] Train loss: 0.0354
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[028/030] Train loss: 0.0354
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[029/030] Train loss: 0.0353
2023-02-06 10:46:01 | Train | Epoch[157/600] Iteration[030/030] Train loss: 0.0353
2023-02-06 10:46:02 | Valid | Epoch[157/600] Iteration[001/008] Valid loss: 0.0534
2023-02-06 10:46:02 | Valid | Epoch[157/600] Iteration[002/008] Valid loss: 0.0528
2023-02-06 10:46:02 | Valid | Epoch[157/600] Iteration[003/008] Valid loss: 0.0545
2023-02-06 10:46:02 | Valid | Epoch[157/600] Iteration[004/008] Valid loss: 0.0539
2023-02-06 10:46:02 | Valid | Epoch[157/600] Iteration[005/008] Valid loss: 0.0545
2023-02-06 10:46:02 | Valid | Epoch[157/600] Iteration[006/008] Valid loss: 0.0539
2023-02-06 10:46:02 | Valid | Epoch[157/600] Iteration[007/008] Valid loss: 0.0528
2023-02-06 10:46:02 | Valid | Epoch[157/600] Iteration[008/008] Valid loss: 0.0538
2023-02-06 10:46:02 | Valid | Epoch[157/600] MIou: 0.8221661606620136
2023-02-06 10:46:02 | Valid | Epoch[157/600] Pixel Accuracy: 0.9706954956054688
2023-02-06 10:46:02 | Valid | Epoch[157/600] Mean Pixel Accuracy: 0.8377704881104902
2023-02-06 10:46:02 | Stage | Epoch[157/600] Train loss:0.0353
2023-02-06 10:46:02 | Stage | Epoch[157/600] Valid loss:0.0538
2023-02-06 10:46:02 | Stage | Epoch[157/600] LR:0.01

2023-02-06 10:46:02 | Train | Epoch[158/600] Iteration[001/030] Train loss: 0.0345
2023-02-06 10:46:02 | Train | Epoch[158/600] Iteration[002/030] Train loss: 0.0319
2023-02-06 10:46:02 | Train | Epoch[158/600] Iteration[003/030] Train loss: 0.0350
2023-02-06 10:46:02 | Train | Epoch[158/600] Iteration[004/030] Train loss: 0.0350
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[005/030] Train loss: 0.0356
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[006/030] Train loss: 0.0352
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[007/030] Train loss: 0.0348
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[008/030] Train loss: 0.0344
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[009/030] Train loss: 0.0348
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[010/030] Train loss: 0.0347
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[011/030] Train loss: 0.0347
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[012/030] Train loss: 0.0344
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[013/030] Train loss: 0.0345
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[014/030] Train loss: 0.0346
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[015/030] Train loss: 0.0345
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[016/030] Train loss: 0.0348
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[017/030] Train loss: 0.0348
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[018/030] Train loss: 0.0351
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[019/030] Train loss: 0.0351
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[020/030] Train loss: 0.0353
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[021/030] Train loss: 0.0354
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[022/030] Train loss: 0.0352
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[023/030] Train loss: 0.0351
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[024/030] Train loss: 0.0352
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[025/030] Train loss: 0.0355
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[026/030] Train loss: 0.0358
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[027/030] Train loss: 0.0357
2023-02-06 10:46:03 | Train | Epoch[158/600] Iteration[028/030] Train loss: 0.0357
2023-02-06 10:46:04 | Train | Epoch[158/600] Iteration[029/030] Train loss: 0.0357
2023-02-06 10:46:04 | Train | Epoch[158/600] Iteration[030/030] Train loss: 0.0358
2023-02-06 10:46:04 | Valid | Epoch[158/600] Iteration[001/008] Valid loss: 0.0544
2023-02-06 10:46:04 | Valid | Epoch[158/600] Iteration[002/008] Valid loss: 0.0520
2023-02-06 10:46:04 | Valid | Epoch[158/600] Iteration[003/008] Valid loss: 0.0526
2023-02-06 10:46:04 | Valid | Epoch[158/600] Iteration[004/008] Valid loss: 0.0518
2023-02-06 10:46:04 | Valid | Epoch[158/600] Iteration[005/008] Valid loss: 0.0519
2023-02-06 10:46:04 | Valid | Epoch[158/600] Iteration[006/008] Valid loss: 0.0519
2023-02-06 10:46:04 | Valid | Epoch[158/600] Iteration[007/008] Valid loss: 0.0508
2023-02-06 10:46:04 | Valid | Epoch[158/600] Iteration[008/008] Valid loss: 0.0515
2023-02-06 10:46:04 | Valid | Epoch[158/600] MIou: 0.8466125833474276
2023-02-06 10:46:04 | Valid | Epoch[158/600] Pixel Accuracy: 0.9747225443522135
2023-02-06 10:46:04 | Valid | Epoch[158/600] Mean Pixel Accuracy: 0.8602797751613436
2023-02-06 10:46:04 | Stage | Epoch[158/600] Train loss:0.0358
2023-02-06 10:46:04 | Stage | Epoch[158/600] Valid loss:0.0515
2023-02-06 10:46:04 | Stage | Epoch[158/600] LR:0.01

2023-02-06 10:46:04 | Train | Epoch[159/600] Iteration[001/030] Train loss: 0.0369
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[002/030] Train loss: 0.0348
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[003/030] Train loss: 0.0332
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[004/030] Train loss: 0.0340
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[005/030] Train loss: 0.0357
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[006/030] Train loss: 0.0359
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[007/030] Train loss: 0.0354
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[008/030] Train loss: 0.0353
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[009/030] Train loss: 0.0349
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[010/030] Train loss: 0.0349
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[011/030] Train loss: 0.0346
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[012/030] Train loss: 0.0347
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[013/030] Train loss: 0.0344
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[014/030] Train loss: 0.0344
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[015/030] Train loss: 0.0348
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[016/030] Train loss: 0.0348
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[017/030] Train loss: 0.0351
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[018/030] Train loss: 0.0352
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[019/030] Train loss: 0.0351
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[020/030] Train loss: 0.0351
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[021/030] Train loss: 0.0351
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[022/030] Train loss: 0.0349
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[023/030] Train loss: 0.0350
2023-02-06 10:46:05 | Train | Epoch[159/600] Iteration[024/030] Train loss: 0.0350
2023-02-06 10:46:06 | Train | Epoch[159/600] Iteration[025/030] Train loss: 0.0350
2023-02-06 10:46:06 | Train | Epoch[159/600] Iteration[026/030] Train loss: 0.0352
2023-02-06 10:46:06 | Train | Epoch[159/600] Iteration[027/030] Train loss: 0.0351
2023-02-06 10:46:06 | Train | Epoch[159/600] Iteration[028/030] Train loss: 0.0349
2023-02-06 10:46:06 | Train | Epoch[159/600] Iteration[029/030] Train loss: 0.0349
2023-02-06 10:46:06 | Train | Epoch[159/600] Iteration[030/030] Train loss: 0.0349
2023-02-06 10:46:06 | Valid | Epoch[159/600] Iteration[001/008] Valid loss: 0.0679
2023-02-06 10:46:06 | Valid | Epoch[159/600] Iteration[002/008] Valid loss: 0.0650
2023-02-06 10:46:06 | Valid | Epoch[159/600] Iteration[003/008] Valid loss: 0.0663
2023-02-06 10:46:06 | Valid | Epoch[159/600] Iteration[004/008] Valid loss: 0.0656
2023-02-06 10:46:06 | Valid | Epoch[159/600] Iteration[005/008] Valid loss: 0.0659
2023-02-06 10:46:06 | Valid | Epoch[159/600] Iteration[006/008] Valid loss: 0.0655
2023-02-06 10:46:06 | Valid | Epoch[159/600] Iteration[007/008] Valid loss: 0.0641
2023-02-06 10:46:06 | Valid | Epoch[159/600] Iteration[008/008] Valid loss: 0.0649
2023-02-06 10:46:06 | Valid | Epoch[159/600] MIou: 0.8060634042423537
2023-02-06 10:46:06 | Valid | Epoch[159/600] Pixel Accuracy: 0.9680328369140625
2023-02-06 10:46:06 | Valid | Epoch[159/600] Mean Pixel Accuracy: 0.8230490514022877
2023-02-06 10:46:06 | Stage | Epoch[159/600] Train loss:0.0349
2023-02-06 10:46:06 | Stage | Epoch[159/600] Valid loss:0.0649
2023-02-06 10:46:06 | Stage | Epoch[159/600] LR:0.01

2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[001/030] Train loss: 0.0299
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[002/030] Train loss: 0.0307
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[003/030] Train loss: 0.0321
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[004/030] Train loss: 0.0351
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[005/030] Train loss: 0.0347
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[006/030] Train loss: 0.0347
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[007/030] Train loss: 0.0345
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[008/030] Train loss: 0.0342
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[009/030] Train loss: 0.0348
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[010/030] Train loss: 0.0345
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[011/030] Train loss: 0.0347
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[012/030] Train loss: 0.0347
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[013/030] Train loss: 0.0349
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[014/030] Train loss: 0.0349
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[015/030] Train loss: 0.0350
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[016/030] Train loss: 0.0350
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[017/030] Train loss: 0.0353
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[018/030] Train loss: 0.0355
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[019/030] Train loss: 0.0354
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[020/030] Train loss: 0.0354
2023-02-06 10:46:07 | Train | Epoch[160/600] Iteration[021/030] Train loss: 0.0355
2023-02-06 10:46:08 | Train | Epoch[160/600] Iteration[022/030] Train loss: 0.0354
2023-02-06 10:46:08 | Train | Epoch[160/600] Iteration[023/030] Train loss: 0.0353
2023-02-06 10:46:08 | Train | Epoch[160/600] Iteration[024/030] Train loss: 0.0352
2023-02-06 10:46:08 | Train | Epoch[160/600] Iteration[025/030] Train loss: 0.0350
2023-02-06 10:46:08 | Train | Epoch[160/600] Iteration[026/030] Train loss: 0.0350
2023-02-06 10:46:08 | Train | Epoch[160/600] Iteration[027/030] Train loss: 0.0350
2023-02-06 10:46:08 | Train | Epoch[160/600] Iteration[028/030] Train loss: 0.0348
2023-02-06 10:46:08 | Train | Epoch[160/600] Iteration[029/030] Train loss: 0.0350
2023-02-06 10:46:08 | Train | Epoch[160/600] Iteration[030/030] Train loss: 0.0350
2023-02-06 10:46:08 | Valid | Epoch[160/600] Iteration[001/008] Valid loss: 0.0651
2023-02-06 10:46:08 | Valid | Epoch[160/600] Iteration[002/008] Valid loss: 0.0559
2023-02-06 10:46:08 | Valid | Epoch[160/600] Iteration[003/008] Valid loss: 0.0522
2023-02-06 10:46:08 | Valid | Epoch[160/600] Iteration[004/008] Valid loss: 0.0504
2023-02-06 10:46:08 | Valid | Epoch[160/600] Iteration[005/008] Valid loss: 0.0509
2023-02-06 10:46:08 | Valid | Epoch[160/600] Iteration[006/008] Valid loss: 0.0505
2023-02-06 10:46:08 | Valid | Epoch[160/600] Iteration[007/008] Valid loss: 0.0523
2023-02-06 10:46:08 | Valid | Epoch[160/600] Iteration[008/008] Valid loss: 0.0526
2023-02-06 10:46:09 | Valid | Epoch[160/600] MIou: 0.9277323889966956
2023-02-06 10:46:09 | Valid | Epoch[160/600] Pixel Accuracy: 0.9874127705891927
2023-02-06 10:46:09 | Valid | Epoch[160/600] Mean Pixel Accuracy: 0.9598130678595871
2023-02-06 10:46:09 | Stage | Epoch[160/600] Train loss:0.0350
2023-02-06 10:46:09 | Stage | Epoch[160/600] Valid loss:0.0526
2023-02-06 10:46:09 | Stage | Epoch[160/600] LR:0.01

2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[001/030] Train loss: 0.0362
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[002/030] Train loss: 0.0355
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[003/030] Train loss: 0.0346
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[004/030] Train loss: 0.0339
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[005/030] Train loss: 0.0340
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[006/030] Train loss: 0.0355
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[007/030] Train loss: 0.0353
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[008/030] Train loss: 0.0353
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[009/030] Train loss: 0.0352
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[010/030] Train loss: 0.0351
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[011/030] Train loss: 0.0346
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[012/030] Train loss: 0.0342
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[013/030] Train loss: 0.0343
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[014/030] Train loss: 0.0342
2023-02-06 10:46:09 | Train | Epoch[161/600] Iteration[015/030] Train loss: 0.0344
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[016/030] Train loss: 0.0347
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[017/030] Train loss: 0.0346
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[018/030] Train loss: 0.0348
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[019/030] Train loss: 0.0347
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[020/030] Train loss: 0.0348
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[021/030] Train loss: 0.0349
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[022/030] Train loss: 0.0348
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[023/030] Train loss: 0.0347
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[024/030] Train loss: 0.0345
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[025/030] Train loss: 0.0347
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[026/030] Train loss: 0.0346
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[027/030] Train loss: 0.0345
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[028/030] Train loss: 0.0345
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[029/030] Train loss: 0.0346
2023-02-06 10:46:10 | Train | Epoch[161/600] Iteration[030/030] Train loss: 0.0346
2023-02-06 10:46:10 | Valid | Epoch[161/600] Iteration[001/008] Valid loss: 0.1408
2023-02-06 10:46:11 | Valid | Epoch[161/600] Iteration[002/008] Valid loss: 0.1342
2023-02-06 10:46:11 | Valid | Epoch[161/600] Iteration[003/008] Valid loss: 0.1390
2023-02-06 10:46:11 | Valid | Epoch[161/600] Iteration[004/008] Valid loss: 0.1390
2023-02-06 10:46:11 | Valid | Epoch[161/600] Iteration[005/008] Valid loss: 0.1409
2023-02-06 10:46:11 | Valid | Epoch[161/600] Iteration[006/008] Valid loss: 0.1392
2023-02-06 10:46:11 | Valid | Epoch[161/600] Iteration[007/008] Valid loss: 0.1364
2023-02-06 10:46:11 | Valid | Epoch[161/600] Iteration[008/008] Valid loss: 0.1391
2023-02-06 10:46:11 | Valid | Epoch[161/600] MIou: 0.6312992280934779
2023-02-06 10:46:11 | Valid | Epoch[161/600] Pixel Accuracy: 0.9390691121419271
2023-02-06 10:46:11 | Valid | Epoch[161/600] Mean Pixel Accuracy: 0.6626870714778471
2023-02-06 10:46:11 | Stage | Epoch[161/600] Train loss:0.0346
2023-02-06 10:46:11 | Stage | Epoch[161/600] Valid loss:0.1391
2023-02-06 10:46:11 | Stage | Epoch[161/600] LR:0.01

2023-02-06 10:46:11 | Train | Epoch[162/600] Iteration[001/030] Train loss: 0.0359
2023-02-06 10:46:11 | Train | Epoch[162/600] Iteration[002/030] Train loss: 0.0341
2023-02-06 10:46:11 | Train | Epoch[162/600] Iteration[003/030] Train loss: 0.0355
2023-02-06 10:46:11 | Train | Epoch[162/600] Iteration[004/030] Train loss: 0.0361
2023-02-06 10:46:11 | Train | Epoch[162/600] Iteration[005/030] Train loss: 0.0356
2023-02-06 10:46:11 | Train | Epoch[162/600] Iteration[006/030] Train loss: 0.0357
2023-02-06 10:46:11 | Train | Epoch[162/600] Iteration[007/030] Train loss: 0.0366
2023-02-06 10:46:11 | Train | Epoch[162/600] Iteration[008/030] Train loss: 0.0361
2023-02-06 10:46:11 | Train | Epoch[162/600] Iteration[009/030] Train loss: 0.0364
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[010/030] Train loss: 0.0364
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[011/030] Train loss: 0.0365
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[012/030] Train loss: 0.0364
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[013/030] Train loss: 0.0375
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[014/030] Train loss: 0.0376
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[015/030] Train loss: 0.0381
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[016/030] Train loss: 0.0390
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[017/030] Train loss: 0.0393
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[018/030] Train loss: 0.0398
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[019/030] Train loss: 0.0399
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[020/030] Train loss: 0.0399
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[021/030] Train loss: 0.0397
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[022/030] Train loss: 0.0398
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[023/030] Train loss: 0.0399
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[024/030] Train loss: 0.0399
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[025/030] Train loss: 0.0399
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[026/030] Train loss: 0.0398
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[027/030] Train loss: 0.0397
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[028/030] Train loss: 0.0396
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[029/030] Train loss: 0.0395
2023-02-06 10:46:12 | Train | Epoch[162/600] Iteration[030/030] Train loss: 0.0394
2023-02-06 10:46:13 | Valid | Epoch[162/600] Iteration[001/008] Valid loss: 0.0554
2023-02-06 10:46:13 | Valid | Epoch[162/600] Iteration[002/008] Valid loss: 0.0473
2023-02-06 10:46:13 | Valid | Epoch[162/600] Iteration[003/008] Valid loss: 0.0462
2023-02-06 10:46:13 | Valid | Epoch[162/600] Iteration[004/008] Valid loss: 0.0451
2023-02-06 10:46:13 | Valid | Epoch[162/600] Iteration[005/008] Valid loss: 0.0451
2023-02-06 10:46:13 | Valid | Epoch[162/600] Iteration[006/008] Valid loss: 0.0448
2023-02-06 10:46:13 | Valid | Epoch[162/600] Iteration[007/008] Valid loss: 0.0444
2023-02-06 10:46:13 | Valid | Epoch[162/600] Iteration[008/008] Valid loss: 0.0444
2023-02-06 10:46:13 | Valid | Epoch[162/600] MIou: 0.9027067014317978
2023-02-06 10:46:13 | Valid | Epoch[162/600] Pixel Accuracy: 0.9837455749511719
2023-02-06 10:46:13 | Valid | Epoch[162/600] Mean Pixel Accuracy: 0.9175607885191612
2023-02-06 10:46:13 | Stage | Epoch[162/600] Train loss:0.0394
2023-02-06 10:46:13 | Stage | Epoch[162/600] Valid loss:0.0444
2023-02-06 10:46:13 | Stage | Epoch[162/600] LR:0.01

2023-02-06 10:46:13 | Train | Epoch[163/600] Iteration[001/030] Train loss: 0.0357
2023-02-06 10:46:13 | Train | Epoch[163/600] Iteration[002/030] Train loss: 0.0348
2023-02-06 10:46:13 | Train | Epoch[163/600] Iteration[003/030] Train loss: 0.0355
2023-02-06 10:46:13 | Train | Epoch[163/600] Iteration[004/030] Train loss: 0.0370
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[005/030] Train loss: 0.0372
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[006/030] Train loss: 0.0369
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[007/030] Train loss: 0.0362
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[008/030] Train loss: 0.0363
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[009/030] Train loss: 0.0371
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[010/030] Train loss: 0.0374
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[011/030] Train loss: 0.0377
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[012/030] Train loss: 0.0377
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[013/030] Train loss: 0.0374
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[014/030] Train loss: 0.0371
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[015/030] Train loss: 0.0370
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[016/030] Train loss: 0.0369
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[017/030] Train loss: 0.0368
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[018/030] Train loss: 0.0366
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[019/030] Train loss: 0.0365
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[020/030] Train loss: 0.0365
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[021/030] Train loss: 0.0363
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[022/030] Train loss: 0.0361
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[023/030] Train loss: 0.0362
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[024/030] Train loss: 0.0359
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[025/030] Train loss: 0.0361
2023-02-06 10:46:14 | Train | Epoch[163/600] Iteration[026/030] Train loss: 0.0360
2023-02-06 10:46:15 | Train | Epoch[163/600] Iteration[027/030] Train loss: 0.0360
2023-02-06 10:46:15 | Train | Epoch[163/600] Iteration[028/030] Train loss: 0.0361
2023-02-06 10:46:15 | Train | Epoch[163/600] Iteration[029/030] Train loss: 0.0360
2023-02-06 10:46:15 | Train | Epoch[163/600] Iteration[030/030] Train loss: 0.0359
2023-02-06 10:46:15 | Valid | Epoch[163/600] Iteration[001/008] Valid loss: 0.2604
2023-02-06 10:46:15 | Valid | Epoch[163/600] Iteration[002/008] Valid loss: 0.2543
2023-02-06 10:46:15 | Valid | Epoch[163/600] Iteration[003/008] Valid loss: 0.2631
2023-02-06 10:46:15 | Valid | Epoch[163/600] Iteration[004/008] Valid loss: 0.2669
2023-02-06 10:46:15 | Valid | Epoch[163/600] Iteration[005/008] Valid loss: 0.2710
2023-02-06 10:46:15 | Valid | Epoch[163/600] Iteration[006/008] Valid loss: 0.2701
2023-02-06 10:46:15 | Valid | Epoch[163/600] Iteration[007/008] Valid loss: 0.2699
2023-02-06 10:46:15 | Valid | Epoch[163/600] Iteration[008/008] Valid loss: 0.2749
2023-02-06 10:46:15 | Valid | Epoch[163/600] MIou: 0.4548409779866536
2023-02-06 10:46:15 | Valid | Epoch[163/600] Pixel Accuracy: 0.9096819559733073
2023-02-06 10:46:15 | Valid | Epoch[163/600] Mean Pixel Accuracy: 0.5
2023-02-06 10:46:15 | Stage | Epoch[163/600] Train loss:0.0359
2023-02-06 10:46:15 | Stage | Epoch[163/600] Valid loss:0.2749
2023-02-06 10:46:15 | Stage | Epoch[163/600] LR:0.01

2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[001/030] Train loss: 0.0366
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[002/030] Train loss: 0.0355
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[003/030] Train loss: 0.0355
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[004/030] Train loss: 0.0360
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[005/030] Train loss: 0.0363
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[006/030] Train loss: 0.0361
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[007/030] Train loss: 0.0359
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[008/030] Train loss: 0.0354
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[009/030] Train loss: 0.0355
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[010/030] Train loss: 0.0359
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[011/030] Train loss: 0.0359
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[012/030] Train loss: 0.0353
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[013/030] Train loss: 0.0350
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[014/030] Train loss: 0.0350
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[015/030] Train loss: 0.0348
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[016/030] Train loss: 0.0352
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[017/030] Train loss: 0.0351
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[018/030] Train loss: 0.0347
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[019/030] Train loss: 0.0345
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[020/030] Train loss: 0.0343
2023-02-06 10:46:16 | Train | Epoch[164/600] Iteration[021/030] Train loss: 0.0344
2023-02-06 10:46:17 | Train | Epoch[164/600] Iteration[022/030] Train loss: 0.0343
2023-02-06 10:46:17 | Train | Epoch[164/600] Iteration[023/030] Train loss: 0.0341
2023-02-06 10:46:17 | Train | Epoch[164/600] Iteration[024/030] Train loss: 0.0342
2023-02-06 10:46:17 | Train | Epoch[164/600] Iteration[025/030] Train loss: 0.0342
2023-02-06 10:46:17 | Train | Epoch[164/600] Iteration[026/030] Train loss: 0.0342
2023-02-06 10:46:17 | Train | Epoch[164/600] Iteration[027/030] Train loss: 0.0342
2023-02-06 10:46:17 | Train | Epoch[164/600] Iteration[028/030] Train loss: 0.0343
2023-02-06 10:46:17 | Train | Epoch[164/600] Iteration[029/030] Train loss: 0.0344
2023-02-06 10:46:17 | Train | Epoch[164/600] Iteration[030/030] Train loss: 0.0343
2023-02-06 10:46:17 | Valid | Epoch[164/600] Iteration[001/008] Valid loss: 0.1314
2023-02-06 10:46:17 | Valid | Epoch[164/600] Iteration[002/008] Valid loss: 0.1047
2023-02-06 10:46:17 | Valid | Epoch[164/600] Iteration[003/008] Valid loss: 0.1001
2023-02-06 10:46:17 | Valid | Epoch[164/600] Iteration[004/008] Valid loss: 0.0991
2023-02-06 10:46:17 | Valid | Epoch[164/600] Iteration[005/008] Valid loss: 0.1028
2023-02-06 10:46:17 | Valid | Epoch[164/600] Iteration[006/008] Valid loss: 0.1017
2023-02-06 10:46:17 | Valid | Epoch[164/600] Iteration[007/008] Valid loss: 0.1106
2023-02-06 10:46:17 | Valid | Epoch[164/600] Iteration[008/008] Valid loss: 0.1096
2023-02-06 10:46:17 | Valid | Epoch[164/600] MIou: 0.9086500984407817
2023-02-06 10:46:17 | Valid | Epoch[164/600] Pixel Accuracy: 0.9827181498209635
2023-02-06 10:46:17 | Valid | Epoch[164/600] Mean Pixel Accuracy: 0.9802359347104608
2023-02-06 10:46:17 | Stage | Epoch[164/600] Train loss:0.0343
2023-02-06 10:46:17 | Stage | Epoch[164/600] Valid loss:0.1096
2023-02-06 10:46:17 | Stage | Epoch[164/600] LR:0.01

2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[001/030] Train loss: 0.0319
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[002/030] Train loss: 0.0322
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[003/030] Train loss: 0.0329
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[004/030] Train loss: 0.0331
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[005/030] Train loss: 0.0328
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[006/030] Train loss: 0.0330
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[007/030] Train loss: 0.0332
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[008/030] Train loss: 0.0332
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[009/030] Train loss: 0.0342
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[010/030] Train loss: 0.0341
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[011/030] Train loss: 0.0340
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[012/030] Train loss: 0.0341
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[013/030] Train loss: 0.0343
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[014/030] Train loss: 0.0338
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[015/030] Train loss: 0.0339
2023-02-06 10:46:18 | Train | Epoch[165/600] Iteration[016/030] Train loss: 0.0338
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[017/030] Train loss: 0.0336
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[018/030] Train loss: 0.0338
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[019/030] Train loss: 0.0337
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[020/030] Train loss: 0.0337
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[021/030] Train loss: 0.0338
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[022/030] Train loss: 0.0340
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[023/030] Train loss: 0.0341
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[024/030] Train loss: 0.0339
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[025/030] Train loss: 0.0340
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[026/030] Train loss: 0.0341
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[027/030] Train loss: 0.0341
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[028/030] Train loss: 0.0341
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[029/030] Train loss: 0.0341
2023-02-06 10:46:19 | Train | Epoch[165/600] Iteration[030/030] Train loss: 0.0341
2023-02-06 10:46:19 | Valid | Epoch[165/600] Iteration[001/008] Valid loss: 0.0526
2023-02-06 10:46:19 | Valid | Epoch[165/600] Iteration[002/008] Valid loss: 0.0503
2023-02-06 10:46:19 | Valid | Epoch[165/600] Iteration[003/008] Valid loss: 0.0483
2023-02-06 10:46:19 | Valid | Epoch[165/600] Iteration[004/008] Valid loss: 0.0474
2023-02-06 10:46:20 | Valid | Epoch[165/600] Iteration[005/008] Valid loss: 0.0471
2023-02-06 10:46:20 | Valid | Epoch[165/600] Iteration[006/008] Valid loss: 0.0467
2023-02-06 10:46:20 | Valid | Epoch[165/600] Iteration[007/008] Valid loss: 0.0465
2023-02-06 10:46:20 | Valid | Epoch[165/600] Iteration[008/008] Valid loss: 0.0468
2023-02-06 10:46:20 | Valid | Epoch[165/600] MIou: 0.8927602618691832
2023-02-06 10:46:20 | Valid | Epoch[165/600] Pixel Accuracy: 0.9819997151692709
2023-02-06 10:46:20 | Valid | Epoch[165/600] Mean Pixel Accuracy: 0.9101973132967089
2023-02-06 10:46:20 | Stage | Epoch[165/600] Train loss:0.0341
2023-02-06 10:46:20 | Stage | Epoch[165/600] Valid loss:0.0468
2023-02-06 10:46:20 | Stage | Epoch[165/600] LR:0.01

2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[001/030] Train loss: 0.0353
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[002/030] Train loss: 0.0357
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[003/030] Train loss: 0.0339
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[004/030] Train loss: 0.0337
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[005/030] Train loss: 0.0341
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[006/030] Train loss: 0.0343
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[007/030] Train loss: 0.0343
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[008/030] Train loss: 0.0343
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[009/030] Train loss: 0.0339
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[010/030] Train loss: 0.0336
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[011/030] Train loss: 0.0336
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[012/030] Train loss: 0.0337
2023-02-06 10:46:20 | Train | Epoch[166/600] Iteration[013/030] Train loss: 0.0340
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[014/030] Train loss: 0.0340
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[015/030] Train loss: 0.0339
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[016/030] Train loss: 0.0344
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[017/030] Train loss: 0.0342
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[018/030] Train loss: 0.0342
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[019/030] Train loss: 0.0341
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[020/030] Train loss: 0.0340
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[021/030] Train loss: 0.0337
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[022/030] Train loss: 0.0337
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[023/030] Train loss: 0.0337
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[024/030] Train loss: 0.0337
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[025/030] Train loss: 0.0338
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[026/030] Train loss: 0.0337
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[027/030] Train loss: 0.0338
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[028/030] Train loss: 0.0337
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[029/030] Train loss: 0.0339
2023-02-06 10:46:21 | Train | Epoch[166/600] Iteration[030/030] Train loss: 0.0340
2023-02-06 10:46:22 | Valid | Epoch[166/600] Iteration[001/008] Valid loss: 0.1031
2023-02-06 10:46:22 | Valid | Epoch[166/600] Iteration[002/008] Valid loss: 0.0797
2023-02-06 10:46:22 | Valid | Epoch[166/600] Iteration[003/008] Valid loss: 0.0754
2023-02-06 10:46:22 | Valid | Epoch[166/600] Iteration[004/008] Valid loss: 0.0734
2023-02-06 10:46:22 | Valid | Epoch[166/600] Iteration[005/008] Valid loss: 0.0754
2023-02-06 10:46:22 | Valid | Epoch[166/600] Iteration[006/008] Valid loss: 0.0736
2023-02-06 10:46:22 | Valid | Epoch[166/600] Iteration[007/008] Valid loss: 0.0798
2023-02-06 10:46:22 | Valid | Epoch[166/600] Iteration[008/008] Valid loss: 0.0786
2023-02-06 10:46:22 | Valid | Epoch[166/600] MIou: 0.930927353146429
2023-02-06 10:46:22 | Valid | Epoch[166/600] Pixel Accuracy: 0.9875564575195312
2023-02-06 10:46:22 | Valid | Epoch[166/600] Mean Pixel Accuracy: 0.9790973325346903
2023-02-06 10:46:22 | Stage | Epoch[166/600] Train loss:0.0340
2023-02-06 10:46:22 | Stage | Epoch[166/600] Valid loss:0.0786
2023-02-06 10:46:22 | Stage | Epoch[166/600] LR:0.01

2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[001/030] Train loss: 0.0317
2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[002/030] Train loss: 0.0316
2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[003/030] Train loss: 0.0304
2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[004/030] Train loss: 0.0316
2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[005/030] Train loss: 0.0323
2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[006/030] Train loss: 0.0333
2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[007/030] Train loss: 0.0332
2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[008/030] Train loss: 0.0331
2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[009/030] Train loss: 0.0330
2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[010/030] Train loss: 0.0332
2023-02-06 10:46:22 | Train | Epoch[167/600] Iteration[011/030] Train loss: 0.0334
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[012/030] Train loss: 0.0335
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[013/030] Train loss: 0.0334
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[014/030] Train loss: 0.0336
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[015/030] Train loss: 0.0336
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[016/030] Train loss: 0.0338
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[017/030] Train loss: 0.0335
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[018/030] Train loss: 0.0335
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[019/030] Train loss: 0.0335
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[020/030] Train loss: 0.0334
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[021/030] Train loss: 0.0335
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[022/030] Train loss: 0.0335
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[023/030] Train loss: 0.0335
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[024/030] Train loss: 0.0336
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[025/030] Train loss: 0.0337
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[026/030] Train loss: 0.0337
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[027/030] Train loss: 0.0335
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[028/030] Train loss: 0.0335
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[029/030] Train loss: 0.0335
2023-02-06 10:46:23 | Train | Epoch[167/600] Iteration[030/030] Train loss: 0.0335
2023-02-06 10:46:24 | Valid | Epoch[167/600] Iteration[001/008] Valid loss: 0.0467
2023-02-06 10:46:24 | Valid | Epoch[167/600] Iteration[002/008] Valid loss: 0.0403
2023-02-06 10:46:24 | Valid | Epoch[167/600] Iteration[003/008] Valid loss: 0.0395
2023-02-06 10:46:24 | Valid | Epoch[167/600] Iteration[004/008] Valid loss: 0.0387
2023-02-06 10:46:24 | Valid | Epoch[167/600] Iteration[005/008] Valid loss: 0.0397
2023-02-06 10:46:24 | Valid | Epoch[167/600] Iteration[006/008] Valid loss: 0.0399
2023-02-06 10:46:24 | Valid | Epoch[167/600] Iteration[007/008] Valid loss: 0.0412
2023-02-06 10:46:24 | Valid | Epoch[167/600] Iteration[008/008] Valid loss: 0.0406
2023-02-06 10:46:24 | Valid | Epoch[167/600] MIou: 0.9348581504024882
2023-02-06 10:46:24 | Valid | Epoch[167/600] Pixel Accuracy: 0.9889806111653646
2023-02-06 10:46:24 | Valid | Epoch[167/600] Mean Pixel Accuracy: 0.9531930635227803
2023-02-06 10:46:24 | Stage | Epoch[167/600] Train loss:0.0335
2023-02-06 10:46:24 | Stage | Epoch[167/600] Valid loss:0.0406
2023-02-06 10:46:24 | Stage | Epoch[167/600] LR:0.01

2023-02-06 10:46:24 | Train | Epoch[168/600] Iteration[001/030] Train loss: 0.0337
2023-02-06 10:46:24 | Train | Epoch[168/600] Iteration[002/030] Train loss: 0.0341
2023-02-06 10:46:24 | Train | Epoch[168/600] Iteration[003/030] Train loss: 0.0341
2023-02-06 10:46:24 | Train | Epoch[168/600] Iteration[004/030] Train loss: 0.0340
2023-02-06 10:46:24 | Train | Epoch[168/600] Iteration[005/030] Train loss: 0.0350
2023-02-06 10:46:24 | Train | Epoch[168/600] Iteration[006/030] Train loss: 0.0344
2023-02-06 10:46:24 | Train | Epoch[168/600] Iteration[007/030] Train loss: 0.0344
2023-02-06 10:46:24 | Train | Epoch[168/600] Iteration[008/030] Train loss: 0.0343
2023-02-06 10:46:24 | Train | Epoch[168/600] Iteration[009/030] Train loss: 0.0349
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[010/030] Train loss: 0.0345
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[011/030] Train loss: 0.0348
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[012/030] Train loss: 0.0346
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[013/030] Train loss: 0.0349
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[014/030] Train loss: 0.0346
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[015/030] Train loss: 0.0344
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[016/030] Train loss: 0.0342
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[017/030] Train loss: 0.0344
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[018/030] Train loss: 0.0341
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[019/030] Train loss: 0.0339
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[020/030] Train loss: 0.0341
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[021/030] Train loss: 0.0340
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[022/030] Train loss: 0.0338
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[023/030] Train loss: 0.0337
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[024/030] Train loss: 0.0340
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[025/030] Train loss: 0.0341
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[026/030] Train loss: 0.0341
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[027/030] Train loss: 0.0342
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[028/030] Train loss: 0.0344
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[029/030] Train loss: 0.0344
2023-02-06 10:46:25 | Train | Epoch[168/600] Iteration[030/030] Train loss: 0.0344
2023-02-06 10:46:26 | Valid | Epoch[168/600] Iteration[001/008] Valid loss: 0.0479
2023-02-06 10:46:26 | Valid | Epoch[168/600] Iteration[002/008] Valid loss: 0.0463
2023-02-06 10:46:26 | Valid | Epoch[168/600] Iteration[003/008] Valid loss: 0.0475
2023-02-06 10:46:26 | Valid | Epoch[168/600] Iteration[004/008] Valid loss: 0.0468
2023-02-06 10:46:26 | Valid | Epoch[168/600] Iteration[005/008] Valid loss: 0.0472
2023-02-06 10:46:26 | Valid | Epoch[168/600] Iteration[006/008] Valid loss: 0.0465
2023-02-06 10:46:26 | Valid | Epoch[168/600] Iteration[007/008] Valid loss: 0.0457
2023-02-06 10:46:26 | Valid | Epoch[168/600] Iteration[008/008] Valid loss: 0.0464
2023-02-06 10:46:26 | Valid | Epoch[168/600] MIou: 0.8503270498085517
2023-02-06 10:46:26 | Valid | Epoch[168/600] Pixel Accuracy: 0.9753379821777344
2023-02-06 10:46:26 | Valid | Epoch[168/600] Mean Pixel Accuracy: 0.8636487914208124
2023-02-06 10:46:26 | Stage | Epoch[168/600] Train loss:0.0344
2023-02-06 10:46:26 | Stage | Epoch[168/600] Valid loss:0.0464
2023-02-06 10:46:26 | Stage | Epoch[168/600] LR:0.01

2023-02-06 10:46:26 | Train | Epoch[169/600] Iteration[001/030] Train loss: 0.0341
2023-02-06 10:46:26 | Train | Epoch[169/600] Iteration[002/030] Train loss: 0.0356
2023-02-06 10:46:26 | Train | Epoch[169/600] Iteration[003/030] Train loss: 0.0351
2023-02-06 10:46:26 | Train | Epoch[169/600] Iteration[004/030] Train loss: 0.0344
2023-02-06 10:46:26 | Train | Epoch[169/600] Iteration[005/030] Train loss: 0.0332
2023-02-06 10:46:26 | Train | Epoch[169/600] Iteration[006/030] Train loss: 0.0326
2023-02-06 10:46:26 | Train | Epoch[169/600] Iteration[007/030] Train loss: 0.0327
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[008/030] Train loss: 0.0325
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[009/030] Train loss: 0.0326
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[010/030] Train loss: 0.0322
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[011/030] Train loss: 0.0326
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[012/030] Train loss: 0.0325
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[013/030] Train loss: 0.0325
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[014/030] Train loss: 0.0326
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[015/030] Train loss: 0.0329
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[016/030] Train loss: 0.0328
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[017/030] Train loss: 0.0331
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[018/030] Train loss: 0.0330
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[019/030] Train loss: 0.0329
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[020/030] Train loss: 0.0327
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[021/030] Train loss: 0.0329
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[022/030] Train loss: 0.0329
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[023/030] Train loss: 0.0329
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[024/030] Train loss: 0.0330
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[025/030] Train loss: 0.0332
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[026/030] Train loss: 0.0333
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[027/030] Train loss: 0.0334
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[028/030] Train loss: 0.0334
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[029/030] Train loss: 0.0335
2023-02-06 10:46:27 | Train | Epoch[169/600] Iteration[030/030] Train loss: 0.0334
2023-02-06 10:46:28 | Valid | Epoch[169/600] Iteration[001/008] Valid loss: 0.3638
2023-02-06 10:46:28 | Valid | Epoch[169/600] Iteration[002/008] Valid loss: 0.3183
2023-02-06 10:46:28 | Valid | Epoch[169/600] Iteration[003/008] Valid loss: 0.3072
2023-02-06 10:46:28 | Valid | Epoch[169/600] Iteration[004/008] Valid loss: 0.3077
2023-02-06 10:46:28 | Valid | Epoch[169/600] Iteration[005/008] Valid loss: 0.3196
2023-02-06 10:46:28 | Valid | Epoch[169/600] Iteration[006/008] Valid loss: 0.3125
2023-02-06 10:46:28 | Valid | Epoch[169/600] Iteration[007/008] Valid loss: 0.3332
2023-02-06 10:46:28 | Valid | Epoch[169/600] Iteration[008/008] Valid loss: 0.3357
2023-02-06 10:46:28 | Valid | Epoch[169/600] MIou: 0.8651563654027001
2023-02-06 10:46:28 | Valid | Epoch[169/600] Pixel Accuracy: 0.9719835917154948
2023-02-06 10:46:28 | Valid | Epoch[169/600] Mean Pixel Accuracy: 0.9792432887082145
2023-02-06 10:46:28 | Stage | Epoch[169/600] Train loss:0.0334
2023-02-06 10:46:28 | Stage | Epoch[169/600] Valid loss:0.3357
2023-02-06 10:46:28 | Stage | Epoch[169/600] LR:0.01

2023-02-06 10:46:28 | Train | Epoch[170/600] Iteration[001/030] Train loss: 0.0391
2023-02-06 10:46:28 | Train | Epoch[170/600] Iteration[002/030] Train loss: 0.0371
2023-02-06 10:46:28 | Train | Epoch[170/600] Iteration[003/030] Train loss: 0.0360
2023-02-06 10:46:28 | Train | Epoch[170/600] Iteration[004/030] Train loss: 0.0357
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[005/030] Train loss: 0.0359
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[006/030] Train loss: 0.0359
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[007/030] Train loss: 0.0348
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[008/030] Train loss: 0.0350
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[009/030] Train loss: 0.0354
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[010/030] Train loss: 0.0350
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[011/030] Train loss: 0.0348
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[012/030] Train loss: 0.0350
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[013/030] Train loss: 0.0345
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[014/030] Train loss: 0.0345
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[015/030] Train loss: 0.0344
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[016/030] Train loss: 0.0342
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[017/030] Train loss: 0.0339
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[018/030] Train loss: 0.0338
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[019/030] Train loss: 0.0337
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[020/030] Train loss: 0.0336
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[021/030] Train loss: 0.0336
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[022/030] Train loss: 0.0335
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[023/030] Train loss: 0.0333
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[024/030] Train loss: 0.0332
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[025/030] Train loss: 0.0331
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[026/030] Train loss: 0.0331
2023-02-06 10:46:29 | Train | Epoch[170/600] Iteration[027/030] Train loss: 0.0332
2023-02-06 10:46:30 | Train | Epoch[170/600] Iteration[028/030] Train loss: 0.0331
2023-02-06 10:46:30 | Train | Epoch[170/600] Iteration[029/030] Train loss: 0.0333
2023-02-06 10:46:30 | Train | Epoch[170/600] Iteration[030/030] Train loss: 0.0333
2023-02-06 10:46:30 | Valid | Epoch[170/600] Iteration[001/008] Valid loss: 0.1145
2023-02-06 10:46:30 | Valid | Epoch[170/600] Iteration[002/008] Valid loss: 0.1125
2023-02-06 10:46:30 | Valid | Epoch[170/600] Iteration[003/008] Valid loss: 0.1170
2023-02-06 10:46:30 | Valid | Epoch[170/600] Iteration[004/008] Valid loss: 0.1170
2023-02-06 10:46:30 | Valid | Epoch[170/600] Iteration[005/008] Valid loss: 0.1190
2023-02-06 10:46:30 | Valid | Epoch[170/600] Iteration[006/008] Valid loss: 0.1173
2023-02-06 10:46:30 | Valid | Epoch[170/600] Iteration[007/008] Valid loss: 0.1148
2023-02-06 10:46:30 | Valid | Epoch[170/600] Iteration[008/008] Valid loss: 0.1173
2023-02-06 10:46:30 | Valid | Epoch[170/600] MIou: 0.6570234044489683
2023-02-06 10:46:30 | Valid | Epoch[170/600] Pixel Accuracy: 0.9433415730794271
2023-02-06 10:46:30 | Valid | Epoch[170/600] Mean Pixel Accuracy: 0.6863393825057371
2023-02-06 10:46:30 | Stage | Epoch[170/600] Train loss:0.0333
2023-02-06 10:46:30 | Stage | Epoch[170/600] Valid loss:0.1173
2023-02-06 10:46:30 | Stage | Epoch[170/600] LR:0.01

2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[001/030] Train loss: 0.0307
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[002/030] Train loss: 0.0299
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[003/030] Train loss: 0.0308
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[004/030] Train loss: 0.0313
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[005/030] Train loss: 0.0312
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[006/030] Train loss: 0.0306
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[007/030] Train loss: 0.0312
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[008/030] Train loss: 0.0315
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[009/030] Train loss: 0.0314
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[010/030] Train loss: 0.0317
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[011/030] Train loss: 0.0317
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[012/030] Train loss: 0.0317
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[013/030] Train loss: 0.0322
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[014/030] Train loss: 0.0319
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[015/030] Train loss: 0.0318
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[016/030] Train loss: 0.0319
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[017/030] Train loss: 0.0321
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[018/030] Train loss: 0.0323
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[019/030] Train loss: 0.0323
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[020/030] Train loss: 0.0323
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[021/030] Train loss: 0.0323
2023-02-06 10:46:31 | Train | Epoch[171/600] Iteration[022/030] Train loss: 0.0325
2023-02-06 10:46:32 | Train | Epoch[171/600] Iteration[023/030] Train loss: 0.0325
2023-02-06 10:46:32 | Train | Epoch[171/600] Iteration[024/030] Train loss: 0.0325
2023-02-06 10:46:32 | Train | Epoch[171/600] Iteration[025/030] Train loss: 0.0326
2023-02-06 10:46:32 | Train | Epoch[171/600] Iteration[026/030] Train loss: 0.0328
2023-02-06 10:46:32 | Train | Epoch[171/600] Iteration[027/030] Train loss: 0.0327
2023-02-06 10:46:32 | Train | Epoch[171/600] Iteration[028/030] Train loss: 0.0327
2023-02-06 10:46:32 | Train | Epoch[171/600] Iteration[029/030] Train loss: 0.0328
2023-02-06 10:46:32 | Train | Epoch[171/600] Iteration[030/030] Train loss: 0.0327
2023-02-06 10:46:32 | Valid | Epoch[171/600] Iteration[001/008] Valid loss: 0.5215
2023-02-06 10:46:32 | Valid | Epoch[171/600] Iteration[002/008] Valid loss: 0.4706
2023-02-06 10:46:32 | Valid | Epoch[171/600] Iteration[003/008] Valid loss: 0.4654
2023-02-06 10:46:32 | Valid | Epoch[171/600] Iteration[004/008] Valid loss: 0.4694
2023-02-06 10:46:32 | Valid | Epoch[171/600] Iteration[005/008] Valid loss: 0.4938
2023-02-06 10:46:32 | Valid | Epoch[171/600] Iteration[006/008] Valid loss: 0.4845
2023-02-06 10:46:32 | Valid | Epoch[171/600] Iteration[007/008] Valid loss: 0.5150
2023-02-06 10:46:32 | Valid | Epoch[171/600] Iteration[008/008] Valid loss: 0.5232
2023-02-06 10:46:32 | Valid | Epoch[171/600] MIou: 0.8453903817813802
2023-02-06 10:46:32 | Valid | Epoch[171/600] Pixel Accuracy: 0.9664688110351562
2023-02-06 10:46:32 | Valid | Epoch[171/600] Mean Pixel Accuracy: 0.9778352907536855
2023-02-06 10:46:32 | Stage | Epoch[171/600] Train loss:0.0327
2023-02-06 10:46:32 | Stage | Epoch[171/600] Valid loss:0.5232
2023-02-06 10:46:32 | Stage | Epoch[171/600] LR:0.01

2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[001/030] Train loss: 0.0321
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[002/030] Train loss: 0.0352
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[003/030] Train loss: 0.0344
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[004/030] Train loss: 0.0343
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[005/030] Train loss: 0.0348
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[006/030] Train loss: 0.0337
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[007/030] Train loss: 0.0333
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[008/030] Train loss: 0.0333
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[009/030] Train loss: 0.0333
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[010/030] Train loss: 0.0336
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[011/030] Train loss: 0.0333
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[012/030] Train loss: 0.0332
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[013/030] Train loss: 0.0337
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[014/030] Train loss: 0.0337
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[015/030] Train loss: 0.0339
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[016/030] Train loss: 0.0337
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[017/030] Train loss: 0.0339
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[018/030] Train loss: 0.0340
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[019/030] Train loss: 0.0338
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[020/030] Train loss: 0.0336
2023-02-06 10:46:33 | Train | Epoch[172/600] Iteration[021/030] Train loss: 0.0337
2023-02-06 10:46:34 | Train | Epoch[172/600] Iteration[022/030] Train loss: 0.0337
2023-02-06 10:46:34 | Train | Epoch[172/600] Iteration[023/030] Train loss: 0.0334
2023-02-06 10:46:34 | Train | Epoch[172/600] Iteration[024/030] Train loss: 0.0334
2023-02-06 10:46:34 | Train | Epoch[172/600] Iteration[025/030] Train loss: 0.0333
2023-02-06 10:46:34 | Train | Epoch[172/600] Iteration[026/030] Train loss: 0.0335
2023-02-06 10:46:34 | Train | Epoch[172/600] Iteration[027/030] Train loss: 0.0335
2023-02-06 10:46:34 | Train | Epoch[172/600] Iteration[028/030] Train loss: 0.0334
2023-02-06 10:46:34 | Train | Epoch[172/600] Iteration[029/030] Train loss: 0.0333
2023-02-06 10:46:34 | Train | Epoch[172/600] Iteration[030/030] Train loss: 0.0333
2023-02-06 10:46:34 | Valid | Epoch[172/600] Iteration[001/008] Valid loss: 0.0486
2023-02-06 10:46:34 | Valid | Epoch[172/600] Iteration[002/008] Valid loss: 0.0434
2023-02-06 10:46:34 | Valid | Epoch[172/600] Iteration[003/008] Valid loss: 0.0413
2023-02-06 10:46:34 | Valid | Epoch[172/600] Iteration[004/008] Valid loss: 0.0406
2023-02-06 10:46:34 | Valid | Epoch[172/600] Iteration[005/008] Valid loss: 0.0403
2023-02-06 10:46:34 | Valid | Epoch[172/600] Iteration[006/008] Valid loss: 0.0404
2023-02-06 10:46:34 | Valid | Epoch[172/600] Iteration[007/008] Valid loss: 0.0407
2023-02-06 10:46:34 | Valid | Epoch[172/600] Iteration[008/008] Valid loss: 0.0403
2023-02-06 10:46:34 | Valid | Epoch[172/600] MIou: 0.9210694651250062
2023-02-06 10:46:34 | Valid | Epoch[172/600] Pixel Accuracy: 0.9867706298828125
2023-02-06 10:46:34 | Valid | Epoch[172/600] Mean Pixel Accuracy: 0.9361081633617319
2023-02-06 10:46:34 | Stage | Epoch[172/600] Train loss:0.0333
2023-02-06 10:46:34 | Stage | Epoch[172/600] Valid loss:0.0403
2023-02-06 10:46:34 | Stage | Epoch[172/600] LR:0.01

2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[001/030] Train loss: 0.0324
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[002/030] Train loss: 0.0309
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[003/030] Train loss: 0.0305
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[004/030] Train loss: 0.0315
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[005/030] Train loss: 0.0314
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[006/030] Train loss: 0.0313
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[007/030] Train loss: 0.0316
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[008/030] Train loss: 0.0323
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[009/030] Train loss: 0.0326
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[010/030] Train loss: 0.0321
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[011/030] Train loss: 0.0320
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[012/030] Train loss: 0.0321
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[013/030] Train loss: 0.0321
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[014/030] Train loss: 0.0324
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[015/030] Train loss: 0.0325
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[016/030] Train loss: 0.0325
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[017/030] Train loss: 0.0331
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[018/030] Train loss: 0.0330
2023-02-06 10:46:35 | Train | Epoch[173/600] Iteration[019/030] Train loss: 0.0332
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[020/030] Train loss: 0.0333
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[021/030] Train loss: 0.0331
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[022/030] Train loss: 0.0329
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[023/030] Train loss: 0.0327
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[024/030] Train loss: 0.0328
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[025/030] Train loss: 0.0328
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[026/030] Train loss: 0.0327
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[027/030] Train loss: 0.0329
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[028/030] Train loss: 0.0329
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[029/030] Train loss: 0.0330
2023-02-06 10:46:36 | Train | Epoch[173/600] Iteration[030/030] Train loss: 0.0330
2023-02-06 10:46:36 | Valid | Epoch[173/600] Iteration[001/008] Valid loss: 0.1698
2023-02-06 10:46:36 | Valid | Epoch[173/600] Iteration[002/008] Valid loss: 0.1232
2023-02-06 10:46:36 | Valid | Epoch[173/600] Iteration[003/008] Valid loss: 0.1156
2023-02-06 10:46:36 | Valid | Epoch[173/600] Iteration[004/008] Valid loss: 0.1118
2023-02-06 10:46:36 | Valid | Epoch[173/600] Iteration[005/008] Valid loss: 0.1136
2023-02-06 10:46:36 | Valid | Epoch[173/600] Iteration[006/008] Valid loss: 0.1094
2023-02-06 10:46:37 | Valid | Epoch[173/600] Iteration[007/008] Valid loss: 0.1192
2023-02-06 10:46:37 | Valid | Epoch[173/600] Iteration[008/008] Valid loss: 0.1184
2023-02-06 10:46:37 | Valid | Epoch[173/600] MIou: 0.9169141692535866
2023-02-06 10:46:37 | Valid | Epoch[173/600] Pixel Accuracy: 0.9846661885579427
2023-02-06 10:46:37 | Valid | Epoch[173/600] Mean Pixel Accuracy: 0.9766337323777443
2023-02-06 10:46:37 | Stage | Epoch[173/600] Train loss:0.0330
2023-02-06 10:46:37 | Stage | Epoch[173/600] Valid loss:0.1184
2023-02-06 10:46:37 | Stage | Epoch[173/600] LR:0.01

2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[001/030] Train loss: 0.0365
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[002/030] Train loss: 0.0330
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[003/030] Train loss: 0.0309
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[004/030] Train loss: 0.0309
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[005/030] Train loss: 0.0313
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[006/030] Train loss: 0.0314
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[007/030] Train loss: 0.0316
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[008/030] Train loss: 0.0316
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[009/030] Train loss: 0.0322
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[010/030] Train loss: 0.0324
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[011/030] Train loss: 0.0322
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[012/030] Train loss: 0.0326
2023-02-06 10:46:37 | Train | Epoch[174/600] Iteration[013/030] Train loss: 0.0323
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[014/030] Train loss: 0.0325
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[015/030] Train loss: 0.0324
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[016/030] Train loss: 0.0323
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[017/030] Train loss: 0.0324
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[018/030] Train loss: 0.0322
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[019/030] Train loss: 0.0324
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[020/030] Train loss: 0.0322
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[021/030] Train loss: 0.0323
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[022/030] Train loss: 0.0323
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[023/030] Train loss: 0.0323
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[024/030] Train loss: 0.0326
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[025/030] Train loss: 0.0328
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[026/030] Train loss: 0.0327
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[027/030] Train loss: 0.0327
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[028/030] Train loss: 0.0326
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[029/030] Train loss: 0.0327
2023-02-06 10:46:38 | Train | Epoch[174/600] Iteration[030/030] Train loss: 0.0328
2023-02-06 10:46:39 | Valid | Epoch[174/600] Iteration[001/008] Valid loss: 0.1275
2023-02-06 10:46:39 | Valid | Epoch[174/600] Iteration[002/008] Valid loss: 0.1006
2023-02-06 10:46:39 | Valid | Epoch[174/600] Iteration[003/008] Valid loss: 0.0884
2023-02-06 10:46:39 | Valid | Epoch[174/600] Iteration[004/008] Valid loss: 0.0840
2023-02-06 10:46:39 | Valid | Epoch[174/600] Iteration[005/008] Valid loss: 0.0827
2023-02-06 10:46:39 | Valid | Epoch[174/600] Iteration[006/008] Valid loss: 0.0816
2023-02-06 10:46:39 | Valid | Epoch[174/600] Iteration[007/008] Valid loss: 0.0864
2023-02-06 10:46:39 | Valid | Epoch[174/600] Iteration[008/008] Valid loss: 0.0866
2023-02-06 10:46:39 | Valid | Epoch[174/600] MIou: 0.9224210464294241
2023-02-06 10:46:39 | Valid | Epoch[174/600] Pixel Accuracy: 0.9860445658365885
2023-02-06 10:46:39 | Valid | Epoch[174/600] Mean Pixel Accuracy: 0.9698144838595218
2023-02-06 10:46:39 | Stage | Epoch[174/600] Train loss:0.0328
2023-02-06 10:46:39 | Stage | Epoch[174/600] Valid loss:0.0866
2023-02-06 10:46:39 | Stage | Epoch[174/600] LR:0.01

2023-02-06 10:46:39 | Train | Epoch[175/600] Iteration[001/030] Train loss: 0.0359
2023-02-06 10:46:39 | Train | Epoch[175/600] Iteration[002/030] Train loss: 0.0352
2023-02-06 10:46:39 | Train | Epoch[175/600] Iteration[003/030] Train loss: 0.0345
2023-02-06 10:46:39 | Train | Epoch[175/600] Iteration[004/030] Train loss: 0.0347
2023-02-06 10:46:39 | Train | Epoch[175/600] Iteration[005/030] Train loss: 0.0343
2023-02-06 10:46:39 | Train | Epoch[175/600] Iteration[006/030] Train loss: 0.0340
2023-02-06 10:46:39 | Train | Epoch[175/600] Iteration[007/030] Train loss: 0.0339
2023-02-06 10:46:39 | Train | Epoch[175/600] Iteration[008/030] Train loss: 0.0339
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[009/030] Train loss: 0.0336
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[010/030] Train loss: 0.0336
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[011/030] Train loss: 0.0336
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[012/030] Train loss: 0.0334
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[013/030] Train loss: 0.0335
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[014/030] Train loss: 0.0330
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[015/030] Train loss: 0.0328
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[016/030] Train loss: 0.0326
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[017/030] Train loss: 0.0325
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[018/030] Train loss: 0.0326
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[019/030] Train loss: 0.0324
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[020/030] Train loss: 0.0322
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[021/030] Train loss: 0.0323
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[022/030] Train loss: 0.0325
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[023/030] Train loss: 0.0326
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[024/030] Train loss: 0.0326
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[025/030] Train loss: 0.0325
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[026/030] Train loss: 0.0324
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[027/030] Train loss: 0.0324
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[028/030] Train loss: 0.0325
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[029/030] Train loss: 0.0326
2023-02-06 10:46:40 | Train | Epoch[175/600] Iteration[030/030] Train loss: 0.0327
2023-02-06 10:46:41 | Valid | Epoch[175/600] Iteration[001/008] Valid loss: 0.0434
2023-02-06 10:46:41 | Valid | Epoch[175/600] Iteration[002/008] Valid loss: 0.0411
2023-02-06 10:46:41 | Valid | Epoch[175/600] Iteration[003/008] Valid loss: 0.0406
2023-02-06 10:46:41 | Valid | Epoch[175/600] Iteration[004/008] Valid loss: 0.0403
2023-02-06 10:46:41 | Valid | Epoch[175/600] Iteration[005/008] Valid loss: 0.0405
2023-02-06 10:46:41 | Valid | Epoch[175/600] Iteration[006/008] Valid loss: 0.0401
2023-02-06 10:46:41 | Valid | Epoch[175/600] Iteration[007/008] Valid loss: 0.0400
2023-02-06 10:46:41 | Valid | Epoch[175/600] Iteration[008/008] Valid loss: 0.0402
2023-02-06 10:46:41 | Valid | Epoch[175/600] MIou: 0.8956039655756307
2023-02-06 10:46:41 | Valid | Epoch[175/600] Pixel Accuracy: 0.9826380411783854
2023-02-06 10:46:41 | Valid | Epoch[175/600] Mean Pixel Accuracy: 0.9090708346329497
2023-02-06 10:46:41 | Stage | Epoch[175/600] Train loss:0.0327
2023-02-06 10:46:41 | Stage | Epoch[175/600] Valid loss:0.0402
2023-02-06 10:46:41 | Stage | Epoch[175/600] LR:0.01

2023-02-06 10:46:41 | Train | Epoch[176/600] Iteration[001/030] Train loss: 0.0318
2023-02-06 10:46:41 | Train | Epoch[176/600] Iteration[002/030] Train loss: 0.0330
2023-02-06 10:46:41 | Train | Epoch[176/600] Iteration[003/030] Train loss: 0.0333
2023-02-06 10:46:41 | Train | Epoch[176/600] Iteration[004/030] Train loss: 0.0326
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[005/030] Train loss: 0.0324
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[006/030] Train loss: 0.0324
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[007/030] Train loss: 0.0325
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[008/030] Train loss: 0.0327
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[009/030] Train loss: 0.0331
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[010/030] Train loss: 0.0333
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[011/030] Train loss: 0.0331
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[012/030] Train loss: 0.0330
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[013/030] Train loss: 0.0328
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[014/030] Train loss: 0.0326
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[015/030] Train loss: 0.0323
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[016/030] Train loss: 0.0323
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[017/030] Train loss: 0.0320
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[018/030] Train loss: 0.0319
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[019/030] Train loss: 0.0318
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[020/030] Train loss: 0.0317
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[021/030] Train loss: 0.0316
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[022/030] Train loss: 0.0317
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[023/030] Train loss: 0.0317
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[024/030] Train loss: 0.0318
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[025/030] Train loss: 0.0319
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[026/030] Train loss: 0.0319
2023-02-06 10:46:42 | Train | Epoch[176/600] Iteration[027/030] Train loss: 0.0321
2023-02-06 10:46:43 | Train | Epoch[176/600] Iteration[028/030] Train loss: 0.0322
2023-02-06 10:46:43 | Train | Epoch[176/600] Iteration[029/030] Train loss: 0.0320
2023-02-06 10:46:43 | Train | Epoch[176/600] Iteration[030/030] Train loss: 0.0322
2023-02-06 10:46:43 | Valid | Epoch[176/600] Iteration[001/008] Valid loss: 0.0417
2023-02-06 10:46:43 | Valid | Epoch[176/600] Iteration[002/008] Valid loss: 0.0381
2023-02-06 10:46:43 | Valid | Epoch[176/600] Iteration[003/008] Valid loss: 0.0376
2023-02-06 10:46:43 | Valid | Epoch[176/600] Iteration[004/008] Valid loss: 0.0367
2023-02-06 10:46:43 | Valid | Epoch[176/600] Iteration[005/008] Valid loss: 0.0368
2023-02-06 10:46:43 | Valid | Epoch[176/600] Iteration[006/008] Valid loss: 0.0365
2023-02-06 10:46:43 | Valid | Epoch[176/600] Iteration[007/008] Valid loss: 0.0364
2023-02-06 10:46:43 | Valid | Epoch[176/600] Iteration[008/008] Valid loss: 0.0364
2023-02-06 10:46:43 | Valid | Epoch[176/600] MIou: 0.9080267217542035
2023-02-06 10:46:43 | Valid | Epoch[176/600] Pixel Accuracy: 0.9847424825032552
2023-02-06 10:46:43 | Valid | Epoch[176/600] Mean Pixel Accuracy: 0.9195543589316192
2023-02-06 10:46:43 | Stage | Epoch[176/600] Train loss:0.0322
2023-02-06 10:46:43 | Stage | Epoch[176/600] Valid loss:0.0364
2023-02-06 10:46:43 | Stage | Epoch[176/600] LR:0.01

2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[001/030] Train loss: 0.0316
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[002/030] Train loss: 0.0333
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[003/030] Train loss: 0.0333
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[004/030] Train loss: 0.0328
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[005/030] Train loss: 0.0323
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[006/030] Train loss: 0.0324
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[007/030] Train loss: 0.0329
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[008/030] Train loss: 0.0327
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[009/030] Train loss: 0.0326
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[010/030] Train loss: 0.0324
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[011/030] Train loss: 0.0322
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[012/030] Train loss: 0.0323
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[013/030] Train loss: 0.0323
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[014/030] Train loss: 0.0324
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[015/030] Train loss: 0.0324
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[016/030] Train loss: 0.0325
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[017/030] Train loss: 0.0325
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[018/030] Train loss: 0.0324
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[019/030] Train loss: 0.0323
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[020/030] Train loss: 0.0321
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[021/030] Train loss: 0.0322
2023-02-06 10:46:44 | Train | Epoch[177/600] Iteration[022/030] Train loss: 0.0322
2023-02-06 10:46:45 | Train | Epoch[177/600] Iteration[023/030] Train loss: 0.0325
2023-02-06 10:46:45 | Train | Epoch[177/600] Iteration[024/030] Train loss: 0.0327
2023-02-06 10:46:45 | Train | Epoch[177/600] Iteration[025/030] Train loss: 0.0330
2023-02-06 10:46:45 | Train | Epoch[177/600] Iteration[026/030] Train loss: 0.0329
2023-02-06 10:46:45 | Train | Epoch[177/600] Iteration[027/030] Train loss: 0.0327
2023-02-06 10:46:45 | Train | Epoch[177/600] Iteration[028/030] Train loss: 0.0326
2023-02-06 10:46:45 | Train | Epoch[177/600] Iteration[029/030] Train loss: 0.0325
2023-02-06 10:46:45 | Train | Epoch[177/600] Iteration[030/030] Train loss: 0.0324
2023-02-06 10:46:45 | Valid | Epoch[177/600] Iteration[001/008] Valid loss: 0.0562
2023-02-06 10:46:45 | Valid | Epoch[177/600] Iteration[002/008] Valid loss: 0.0554
2023-02-06 10:46:45 | Valid | Epoch[177/600] Iteration[003/008] Valid loss: 0.0574
2023-02-06 10:46:45 | Valid | Epoch[177/600] Iteration[004/008] Valid loss: 0.0565
2023-02-06 10:46:45 | Valid | Epoch[177/600] Iteration[005/008] Valid loss: 0.0571
2023-02-06 10:46:45 | Valid | Epoch[177/600] Iteration[006/008] Valid loss: 0.0562
2023-02-06 10:46:45 | Valid | Epoch[177/600] Iteration[007/008] Valid loss: 0.0549
2023-02-06 10:46:45 | Valid | Epoch[177/600] Iteration[008/008] Valid loss: 0.0559
2023-02-06 10:46:46 | Valid | Epoch[177/600] MIou: 0.8174954151570366
2023-02-06 10:46:46 | Valid | Epoch[177/600] Pixel Accuracy: 0.9699236551920573
2023-02-06 10:46:46 | Valid | Epoch[177/600] Mean Pixel Accuracy: 0.8334975854932493
2023-02-06 10:46:46 | Stage | Epoch[177/600] Train loss:0.0324
2023-02-06 10:46:46 | Stage | Epoch[177/600] Valid loss:0.0559
2023-02-06 10:46:46 | Stage | Epoch[177/600] LR:0.01

2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[001/030] Train loss: 0.0326
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[002/030] Train loss: 0.0313
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[003/030] Train loss: 0.0312
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[004/030] Train loss: 0.0313
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[005/030] Train loss: 0.0308
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[006/030] Train loss: 0.0322
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[007/030] Train loss: 0.0323
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[008/030] Train loss: 0.0320
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[009/030] Train loss: 0.0322
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[010/030] Train loss: 0.0320
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[011/030] Train loss: 0.0321
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[012/030] Train loss: 0.0323
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[013/030] Train loss: 0.0322
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[014/030] Train loss: 0.0319
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[015/030] Train loss: 0.0322
2023-02-06 10:46:46 | Train | Epoch[178/600] Iteration[016/030] Train loss: 0.0323
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[017/030] Train loss: 0.0323
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[018/030] Train loss: 0.0323
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[019/030] Train loss: 0.0325
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[020/030] Train loss: 0.0323
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[021/030] Train loss: 0.0324
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[022/030] Train loss: 0.0324
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[023/030] Train loss: 0.0325
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[024/030] Train loss: 0.0324
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[025/030] Train loss: 0.0325
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[026/030] Train loss: 0.0324
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[027/030] Train loss: 0.0324
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[028/030] Train loss: 0.0325
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[029/030] Train loss: 0.0323
2023-02-06 10:46:47 | Train | Epoch[178/600] Iteration[030/030] Train loss: 0.0322
2023-02-06 10:46:47 | Valid | Epoch[178/600] Iteration[001/008] Valid loss: 0.0559
2023-02-06 10:46:47 | Valid | Epoch[178/600] Iteration[002/008] Valid loss: 0.0465
2023-02-06 10:46:47 | Valid | Epoch[178/600] Iteration[003/008] Valid loss: 0.0438
2023-02-06 10:46:47 | Valid | Epoch[178/600] Iteration[004/008] Valid loss: 0.0425
2023-02-06 10:46:48 | Valid | Epoch[178/600] Iteration[005/008] Valid loss: 0.0433
2023-02-06 10:46:48 | Valid | Epoch[178/600] Iteration[006/008] Valid loss: 0.0436
2023-02-06 10:46:48 | Valid | Epoch[178/600] Iteration[007/008] Valid loss: 0.0454
2023-02-06 10:46:48 | Valid | Epoch[178/600] Iteration[008/008] Valid loss: 0.0444
2023-02-06 10:46:48 | Valid | Epoch[178/600] MIou: 0.9391369005608075
2023-02-06 10:46:48 | Valid | Epoch[178/600] Pixel Accuracy: 0.9896036783854166
2023-02-06 10:46:48 | Valid | Epoch[178/600] Mean Pixel Accuracy: 0.9617400979767265
2023-02-06 10:46:48 | Stage | Epoch[178/600] Train loss:0.0322
2023-02-06 10:46:48 | Stage | Epoch[178/600] Valid loss:0.0444
2023-02-06 10:46:48 | Stage | Epoch[178/600] LR:0.01

2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[001/030] Train loss: 0.0364
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[002/030] Train loss: 0.0368
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[003/030] Train loss: 0.0357
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[004/030] Train loss: 0.0350
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[005/030] Train loss: 0.0338
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[006/030] Train loss: 0.0337
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[007/030] Train loss: 0.0330
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[008/030] Train loss: 0.0326
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[009/030] Train loss: 0.0323
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[010/030] Train loss: 0.0318
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[011/030] Train loss: 0.0316
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[012/030] Train loss: 0.0320
2023-02-06 10:46:48 | Train | Epoch[179/600] Iteration[013/030] Train loss: 0.0319
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[014/030] Train loss: 0.0319
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[015/030] Train loss: 0.0321
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[016/030] Train loss: 0.0320
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[017/030] Train loss: 0.0324
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[018/030] Train loss: 0.0324
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[019/030] Train loss: 0.0321
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[020/030] Train loss: 0.0322
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[021/030] Train loss: 0.0322
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[022/030] Train loss: 0.0322
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[023/030] Train loss: 0.0322
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[024/030] Train loss: 0.0323
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[025/030] Train loss: 0.0321
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[026/030] Train loss: 0.0319
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[027/030] Train loss: 0.0321
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[028/030] Train loss: 0.0321
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[029/030] Train loss: 0.0322
2023-02-06 10:46:49 | Train | Epoch[179/600] Iteration[030/030] Train loss: 0.0321
2023-02-06 10:46:50 | Valid | Epoch[179/600] Iteration[001/008] Valid loss: 0.0486
2023-02-06 10:46:50 | Valid | Epoch[179/600] Iteration[002/008] Valid loss: 0.0479
2023-02-06 10:46:50 | Valid | Epoch[179/600] Iteration[003/008] Valid loss: 0.0492
2023-02-06 10:46:50 | Valid | Epoch[179/600] Iteration[004/008] Valid loss: 0.0489
2023-02-06 10:46:50 | Valid | Epoch[179/600] Iteration[005/008] Valid loss: 0.0493
2023-02-06 10:46:50 | Valid | Epoch[179/600] Iteration[006/008] Valid loss: 0.0486
2023-02-06 10:46:50 | Valid | Epoch[179/600] Iteration[007/008] Valid loss: 0.0476
2023-02-06 10:46:50 | Valid | Epoch[179/600] Iteration[008/008] Valid loss: 0.0486
2023-02-06 10:46:50 | Valid | Epoch[179/600] MIou: 0.832642640422654
2023-02-06 10:46:50 | Valid | Epoch[179/600] Pixel Accuracy: 0.9724171956380209
2023-02-06 10:46:50 | Valid | Epoch[179/600] Mean Pixel Accuracy: 0.8474666585637812
2023-02-06 10:46:50 | Stage | Epoch[179/600] Train loss:0.0321
2023-02-06 10:46:50 | Stage | Epoch[179/600] Valid loss:0.0486
2023-02-06 10:46:50 | Stage | Epoch[179/600] LR:0.01

2023-02-06 10:46:50 | Train | Epoch[180/600] Iteration[001/030] Train loss: 0.0327
2023-02-06 10:46:50 | Train | Epoch[180/600] Iteration[002/030] Train loss: 0.0297
2023-02-06 10:46:50 | Train | Epoch[180/600] Iteration[003/030] Train loss: 0.0289
2023-02-06 10:46:50 | Train | Epoch[180/600] Iteration[004/030] Train loss: 0.0293
2023-02-06 10:46:50 | Train | Epoch[180/600] Iteration[005/030] Train loss: 0.0297
2023-02-06 10:46:50 | Train | Epoch[180/600] Iteration[006/030] Train loss: 0.0303
2023-02-06 10:46:50 | Train | Epoch[180/600] Iteration[007/030] Train loss: 0.0304
2023-02-06 10:46:50 | Train | Epoch[180/600] Iteration[008/030] Train loss: 0.0307
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[009/030] Train loss: 0.0305
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[010/030] Train loss: 0.0308
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[011/030] Train loss: 0.0310
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[012/030] Train loss: 0.0311
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[013/030] Train loss: 0.0311
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[014/030] Train loss: 0.0311
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[015/030] Train loss: 0.0315
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[016/030] Train loss: 0.0318
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[017/030] Train loss: 0.0316
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[018/030] Train loss: 0.0314
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[019/030] Train loss: 0.0315
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[020/030] Train loss: 0.0316
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[021/030] Train loss: 0.0315
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[022/030] Train loss: 0.0315
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[023/030] Train loss: 0.0317
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[024/030] Train loss: 0.0320
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[025/030] Train loss: 0.0318
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[026/030] Train loss: 0.0320
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[027/030] Train loss: 0.0321
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[028/030] Train loss: 0.0320
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[029/030] Train loss: 0.0321
2023-02-06 10:46:51 | Train | Epoch[180/600] Iteration[030/030] Train loss: 0.0322
2023-02-06 10:46:52 | Valid | Epoch[180/600] Iteration[001/008] Valid loss: 0.0443
2023-02-06 10:46:52 | Valid | Epoch[180/600] Iteration[002/008] Valid loss: 0.0418
2023-02-06 10:46:52 | Valid | Epoch[180/600] Iteration[003/008] Valid loss: 0.0423
2023-02-06 10:46:52 | Valid | Epoch[180/600] Iteration[004/008] Valid loss: 0.0414
2023-02-06 10:46:52 | Valid | Epoch[180/600] Iteration[005/008] Valid loss: 0.0419
2023-02-06 10:46:52 | Valid | Epoch[180/600] Iteration[006/008] Valid loss: 0.0414
2023-02-06 10:46:52 | Valid | Epoch[180/600] Iteration[007/008] Valid loss: 0.0410
2023-02-06 10:46:52 | Valid | Epoch[180/600] Iteration[008/008] Valid loss: 0.0413
2023-02-06 10:46:52 | Valid | Epoch[180/600] MIou: 0.8762134257417515
2023-02-06 10:46:52 | Valid | Epoch[180/600] Pixel Accuracy: 0.9795786539713541
2023-02-06 10:46:52 | Valid | Epoch[180/600] Mean Pixel Accuracy: 0.8879303578736837
2023-02-06 10:46:52 | Stage | Epoch[180/600] Train loss:0.0322
2023-02-06 10:46:52 | Stage | Epoch[180/600] Valid loss:0.0413
2023-02-06 10:46:52 | Stage | Epoch[180/600] LR:0.01

2023-02-06 10:46:52 | Train | Epoch[181/600] Iteration[001/030] Train loss: 0.0297
2023-02-06 10:46:52 | Train | Epoch[181/600] Iteration[002/030] Train loss: 0.0308
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[003/030] Train loss: 0.0306
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[004/030] Train loss: 0.0301
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[005/030] Train loss: 0.0295
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[006/030] Train loss: 0.0302
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[007/030] Train loss: 0.0308
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[008/030] Train loss: 0.0308
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[009/030] Train loss: 0.0307
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[010/030] Train loss: 0.0312
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[011/030] Train loss: 0.0310
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[012/030] Train loss: 0.0311
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[013/030] Train loss: 0.0311
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[014/030] Train loss: 0.0310
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[015/030] Train loss: 0.0313
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[016/030] Train loss: 0.0318
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[017/030] Train loss: 0.0319
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[018/030] Train loss: 0.0322
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[019/030] Train loss: 0.0323
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[020/030] Train loss: 0.0325
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[021/030] Train loss: 0.0327
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[022/030] Train loss: 0.0325
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[023/030] Train loss: 0.0326
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[024/030] Train loss: 0.0325
2023-02-06 10:46:53 | Train | Epoch[181/600] Iteration[025/030] Train loss: 0.0323
2023-02-06 10:46:54 | Train | Epoch[181/600] Iteration[026/030] Train loss: 0.0324
2023-02-06 10:46:54 | Train | Epoch[181/600] Iteration[027/030] Train loss: 0.0324
2023-02-06 10:46:54 | Train | Epoch[181/600] Iteration[028/030] Train loss: 0.0326
2023-02-06 10:46:54 | Train | Epoch[181/600] Iteration[029/030] Train loss: 0.0326
2023-02-06 10:46:54 | Train | Epoch[181/600] Iteration[030/030] Train loss: 0.0325
2023-02-06 10:46:54 | Valid | Epoch[181/600] Iteration[001/008] Valid loss: 0.0660
2023-02-06 10:46:54 | Valid | Epoch[181/600] Iteration[002/008] Valid loss: 0.0658
2023-02-06 10:46:54 | Valid | Epoch[181/600] Iteration[003/008] Valid loss: 0.0683
2023-02-06 10:46:54 | Valid | Epoch[181/600] Iteration[004/008] Valid loss: 0.0676
2023-02-06 10:46:54 | Valid | Epoch[181/600] Iteration[005/008] Valid loss: 0.0686
2023-02-06 10:46:54 | Valid | Epoch[181/600] Iteration[006/008] Valid loss: 0.0673
2023-02-06 10:46:54 | Valid | Epoch[181/600] Iteration[007/008] Valid loss: 0.0654
2023-02-06 10:46:54 | Valid | Epoch[181/600] Iteration[008/008] Valid loss: 0.0673
2023-02-06 10:46:54 | Valid | Epoch[181/600] MIou: 0.7702396588792579
2023-02-06 10:46:54 | Valid | Epoch[181/600] Pixel Accuracy: 0.9621086120605469
2023-02-06 10:46:54 | Valid | Epoch[181/600] Mean Pixel Accuracy: 0.7902335665714004
2023-02-06 10:46:54 | Stage | Epoch[181/600] Train loss:0.0325
2023-02-06 10:46:54 | Stage | Epoch[181/600] Valid loss:0.0673
2023-02-06 10:46:54 | Stage | Epoch[181/600] LR:0.01

2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[001/030] Train loss: 0.0294
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[002/030] Train loss: 0.0367
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[003/030] Train loss: 0.0341
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[004/030] Train loss: 0.0328
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[005/030] Train loss: 0.0317
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[006/030] Train loss: 0.0313
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[007/030] Train loss: 0.0308
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[008/030] Train loss: 0.0311
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[009/030] Train loss: 0.0314
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[010/030] Train loss: 0.0322
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[011/030] Train loss: 0.0324
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[012/030] Train loss: 0.0328
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[013/030] Train loss: 0.0330
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[014/030] Train loss: 0.0330
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[015/030] Train loss: 0.0331
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[016/030] Train loss: 0.0331
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[017/030] Train loss: 0.0329
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[018/030] Train loss: 0.0328
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[019/030] Train loss: 0.0325
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[020/030] Train loss: 0.0325
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[021/030] Train loss: 0.0325
2023-02-06 10:46:55 | Train | Epoch[182/600] Iteration[022/030] Train loss: 0.0328
2023-02-06 10:46:56 | Train | Epoch[182/600] Iteration[023/030] Train loss: 0.0328
2023-02-06 10:46:56 | Train | Epoch[182/600] Iteration[024/030] Train loss: 0.0326
2023-02-06 10:46:56 | Train | Epoch[182/600] Iteration[025/030] Train loss: 0.0327
2023-02-06 10:46:56 | Train | Epoch[182/600] Iteration[026/030] Train loss: 0.0328
2023-02-06 10:46:56 | Train | Epoch[182/600] Iteration[027/030] Train loss: 0.0327
2023-02-06 10:46:56 | Train | Epoch[182/600] Iteration[028/030] Train loss: 0.0329
2023-02-06 10:46:56 | Train | Epoch[182/600] Iteration[029/030] Train loss: 0.0329
2023-02-06 10:46:56 | Train | Epoch[182/600] Iteration[030/030] Train loss: 0.0328
2023-02-06 10:46:56 | Valid | Epoch[182/600] Iteration[001/008] Valid loss: 0.0426
2023-02-06 10:46:56 | Valid | Epoch[182/600] Iteration[002/008] Valid loss: 0.0407
2023-02-06 10:46:56 | Valid | Epoch[182/600] Iteration[003/008] Valid loss: 0.0411
2023-02-06 10:46:56 | Valid | Epoch[182/600] Iteration[004/008] Valid loss: 0.0404
2023-02-06 10:46:56 | Valid | Epoch[182/600] Iteration[005/008] Valid loss: 0.0408
2023-02-06 10:46:56 | Valid | Epoch[182/600] Iteration[006/008] Valid loss: 0.0404
2023-02-06 10:46:56 | Valid | Epoch[182/600] Iteration[007/008] Valid loss: 0.0400
2023-02-06 10:46:56 | Valid | Epoch[182/600] Iteration[008/008] Valid loss: 0.0403
2023-02-06 10:46:56 | Valid | Epoch[182/600] MIou: 0.8735543172820319
2023-02-06 10:46:56 | Valid | Epoch[182/600] Pixel Accuracy: 0.9791603088378906
2023-02-06 10:46:56 | Valid | Epoch[182/600] Mean Pixel Accuracy: 0.8851071646979032
2023-02-06 10:46:56 | Stage | Epoch[182/600] Train loss:0.0328
2023-02-06 10:46:56 | Stage | Epoch[182/600] Valid loss:0.0403
2023-02-06 10:46:56 | Stage | Epoch[182/600] LR:0.01

2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[001/030] Train loss: 0.0284
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[002/030] Train loss: 0.0305
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[003/030] Train loss: 0.0313
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[004/030] Train loss: 0.0322
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[005/030] Train loss: 0.0321
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[006/030] Train loss: 0.0319
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[007/030] Train loss: 0.0321
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[008/030] Train loss: 0.0319
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[009/030] Train loss: 0.0314
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[010/030] Train loss: 0.0313
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[011/030] Train loss: 0.0315
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[012/030] Train loss: 0.0318
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[013/030] Train loss: 0.0317
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[014/030] Train loss: 0.0316
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[015/030] Train loss: 0.0318
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[016/030] Train loss: 0.0319
2023-02-06 10:46:57 | Train | Epoch[183/600] Iteration[017/030] Train loss: 0.0322
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[018/030] Train loss: 0.0321
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[019/030] Train loss: 0.0327
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[020/030] Train loss: 0.0326
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[021/030] Train loss: 0.0323
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[022/030] Train loss: 0.0324
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[023/030] Train loss: 0.0323
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[024/030] Train loss: 0.0321
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[025/030] Train loss: 0.0321
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[026/030] Train loss: 0.0321
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[027/030] Train loss: 0.0321
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[028/030] Train loss: 0.0322
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[029/030] Train loss: 0.0322
2023-02-06 10:46:58 | Train | Epoch[183/600] Iteration[030/030] Train loss: 0.0322
2023-02-06 10:46:58 | Valid | Epoch[183/600] Iteration[001/008] Valid loss: 0.4602
2023-02-06 10:46:58 | Valid | Epoch[183/600] Iteration[002/008] Valid loss: 0.4509
2023-02-06 10:46:58 | Valid | Epoch[183/600] Iteration[003/008] Valid loss: 0.4240
2023-02-06 10:46:58 | Valid | Epoch[183/600] Iteration[004/008] Valid loss: 0.4275
2023-02-06 10:46:58 | Valid | Epoch[183/600] Iteration[005/008] Valid loss: 0.4365
2023-02-06 10:46:59 | Valid | Epoch[183/600] Iteration[006/008] Valid loss: 0.4270
2023-02-06 10:46:59 | Valid | Epoch[183/600] Iteration[007/008] Valid loss: 0.4503
2023-02-06 10:46:59 | Valid | Epoch[183/600] Iteration[008/008] Valid loss: 0.4635
2023-02-06 10:46:59 | Valid | Epoch[183/600] MIou: 0.8613226730467318
2023-02-06 10:46:59 | Valid | Epoch[183/600] Pixel Accuracy: 0.9710261027018229
2023-02-06 10:46:59 | Valid | Epoch[183/600] Mean Pixel Accuracy: 0.9776137698672798
2023-02-06 10:46:59 | Stage | Epoch[183/600] Train loss:0.0322
2023-02-06 10:46:59 | Stage | Epoch[183/600] Valid loss:0.4635
2023-02-06 10:46:59 | Stage | Epoch[183/600] LR:0.01

2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[001/030] Train loss: 0.0342
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[002/030] Train loss: 0.0324
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[003/030] Train loss: 0.0336
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[004/030] Train loss: 0.0335
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[005/030] Train loss: 0.0331
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[006/030] Train loss: 0.0330
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[007/030] Train loss: 0.0331
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[008/030] Train loss: 0.0324
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[009/030] Train loss: 0.0325
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[010/030] Train loss: 0.0322
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[011/030] Train loss: 0.0320
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[012/030] Train loss: 0.0315
2023-02-06 10:46:59 | Train | Epoch[184/600] Iteration[013/030] Train loss: 0.0313
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[014/030] Train loss: 0.0313
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[015/030] Train loss: 0.0313
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[016/030] Train loss: 0.0314
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[017/030] Train loss: 0.0313
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[018/030] Train loss: 0.0313
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[019/030] Train loss: 0.0313
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[020/030] Train loss: 0.0312
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[021/030] Train loss: 0.0313
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[022/030] Train loss: 0.0315
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[023/030] Train loss: 0.0316
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[024/030] Train loss: 0.0316
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[025/030] Train loss: 0.0315
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[026/030] Train loss: 0.0315
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[027/030] Train loss: 0.0317
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[028/030] Train loss: 0.0317
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[029/030] Train loss: 0.0317
2023-02-06 10:47:00 | Train | Epoch[184/600] Iteration[030/030] Train loss: 0.0318
2023-02-06 10:47:01 | Valid | Epoch[184/600] Iteration[001/008] Valid loss: 0.2161
2023-02-06 10:47:01 | Valid | Epoch[184/600] Iteration[002/008] Valid loss: 0.2187
2023-02-06 10:47:01 | Valid | Epoch[184/600] Iteration[003/008] Valid loss: 0.2300
2023-02-06 10:47:01 | Valid | Epoch[184/600] Iteration[004/008] Valid loss: 0.2316
2023-02-06 10:47:01 | Valid | Epoch[184/600] Iteration[005/008] Valid loss: 0.2387
2023-02-06 10:47:01 | Valid | Epoch[184/600] Iteration[006/008] Valid loss: 0.2354
2023-02-06 10:47:01 | Valid | Epoch[184/600] Iteration[007/008] Valid loss: 0.2329
2023-02-06 10:47:01 | Valid | Epoch[184/600] Iteration[008/008] Valid loss: 0.2404
2023-02-06 10:47:01 | Valid | Epoch[184/600] MIou: 0.4559988912322073
2023-02-06 10:47:01 | Valid | Epoch[184/600] Pixel Accuracy: 0.909875233968099
2023-02-06 10:47:01 | Valid | Epoch[184/600] Mean Pixel Accuracy: 0.5010699854988807
2023-02-06 10:47:01 | Stage | Epoch[184/600] Train loss:0.0318
2023-02-06 10:47:01 | Stage | Epoch[184/600] Valid loss:0.2404
2023-02-06 10:47:01 | Stage | Epoch[184/600] LR:0.01

2023-02-06 10:47:01 | Train | Epoch[185/600] Iteration[001/030] Train loss: 0.0284
2023-02-06 10:47:01 | Train | Epoch[185/600] Iteration[002/030] Train loss: 0.0290
2023-02-06 10:47:01 | Train | Epoch[185/600] Iteration[003/030] Train loss: 0.0311
2023-02-06 10:47:01 | Train | Epoch[185/600] Iteration[004/030] Train loss: 0.0317
2023-02-06 10:47:01 | Train | Epoch[185/600] Iteration[005/030] Train loss: 0.0319
2023-02-06 10:47:01 | Train | Epoch[185/600] Iteration[006/030] Train loss: 0.0315
2023-02-06 10:47:01 | Train | Epoch[185/600] Iteration[007/030] Train loss: 0.0313
2023-02-06 10:47:01 | Train | Epoch[185/600] Iteration[008/030] Train loss: 0.0318
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[009/030] Train loss: 0.0316
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[010/030] Train loss: 0.0315
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[011/030] Train loss: 0.0313
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[012/030] Train loss: 0.0312
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[013/030] Train loss: 0.0308
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[014/030] Train loss: 0.0311
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[015/030] Train loss: 0.0313
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[016/030] Train loss: 0.0315
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[017/030] Train loss: 0.0314
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[018/030] Train loss: 0.0317
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[019/030] Train loss: 0.0320
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[020/030] Train loss: 0.0319
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[021/030] Train loss: 0.0320
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[022/030] Train loss: 0.0318
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[023/030] Train loss: 0.0317
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[024/030] Train loss: 0.0318
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[025/030] Train loss: 0.0317
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[026/030] Train loss: 0.0316
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[027/030] Train loss: 0.0316
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[028/030] Train loss: 0.0316
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[029/030] Train loss: 0.0317
2023-02-06 10:47:02 | Train | Epoch[185/600] Iteration[030/030] Train loss: 0.0316
2023-02-06 10:47:03 | Valid | Epoch[185/600] Iteration[001/008] Valid loss: 0.0902
2023-02-06 10:47:03 | Valid | Epoch[185/600] Iteration[002/008] Valid loss: 0.0685
2023-02-06 10:47:03 | Valid | Epoch[185/600] Iteration[003/008] Valid loss: 0.0617
2023-02-06 10:47:03 | Valid | Epoch[185/600] Iteration[004/008] Valid loss: 0.0591
2023-02-06 10:47:03 | Valid | Epoch[185/600] Iteration[005/008] Valid loss: 0.0592
2023-02-06 10:47:03 | Valid | Epoch[185/600] Iteration[006/008] Valid loss: 0.0583
2023-02-06 10:47:03 | Valid | Epoch[185/600] Iteration[007/008] Valid loss: 0.0622
2023-02-06 10:47:03 | Valid | Epoch[185/600] Iteration[008/008] Valid loss: 0.0612
2023-02-06 10:47:03 | Valid | Epoch[185/600] MIou: 0.9315827457956724
2023-02-06 10:47:03 | Valid | Epoch[185/600] Pixel Accuracy: 0.9879620869954427
2023-02-06 10:47:03 | Valid | Epoch[185/600] Mean Pixel Accuracy: 0.9683512680784319
2023-02-06 10:47:03 | Stage | Epoch[185/600] Train loss:0.0316
2023-02-06 10:47:03 | Stage | Epoch[185/600] Valid loss:0.0612
2023-02-06 10:47:03 | Stage | Epoch[185/600] LR:0.01

2023-02-06 10:47:03 | Train | Epoch[186/600] Iteration[001/030] Train loss: 0.0283
2023-02-06 10:47:03 | Train | Epoch[186/600] Iteration[002/030] Train loss: 0.0284
2023-02-06 10:47:03 | Train | Epoch[186/600] Iteration[003/030] Train loss: 0.0300
2023-02-06 10:47:03 | Train | Epoch[186/600] Iteration[004/030] Train loss: 0.0307
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[005/030] Train loss: 0.0304
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[006/030] Train loss: 0.0302
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[007/030] Train loss: 0.0306
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[008/030] Train loss: 0.0306
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[009/030] Train loss: 0.0308
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[010/030] Train loss: 0.0309
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[011/030] Train loss: 0.0309
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[012/030] Train loss: 0.0308
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[013/030] Train loss: 0.0306
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[014/030] Train loss: 0.0303
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[015/030] Train loss: 0.0299
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[016/030] Train loss: 0.0305
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[017/030] Train loss: 0.0306
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[018/030] Train loss: 0.0306
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[019/030] Train loss: 0.0308
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[020/030] Train loss: 0.0306
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[021/030] Train loss: 0.0307
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[022/030] Train loss: 0.0307
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[023/030] Train loss: 0.0306
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[024/030] Train loss: 0.0307
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[025/030] Train loss: 0.0306
2023-02-06 10:47:04 | Train | Epoch[186/600] Iteration[026/030] Train loss: 0.0306
2023-02-06 10:47:05 | Train | Epoch[186/600] Iteration[027/030] Train loss: 0.0306
2023-02-06 10:47:05 | Train | Epoch[186/600] Iteration[028/030] Train loss: 0.0308
2023-02-06 10:47:05 | Train | Epoch[186/600] Iteration[029/030] Train loss: 0.0308
2023-02-06 10:47:05 | Train | Epoch[186/600] Iteration[030/030] Train loss: 0.0308
2023-02-06 10:47:05 | Valid | Epoch[186/600] Iteration[001/008] Valid loss: 0.0415
2023-02-06 10:47:05 | Valid | Epoch[186/600] Iteration[002/008] Valid loss: 0.0391
2023-02-06 10:47:05 | Valid | Epoch[186/600] Iteration[003/008] Valid loss: 0.0388
2023-02-06 10:47:05 | Valid | Epoch[186/600] Iteration[004/008] Valid loss: 0.0385
2023-02-06 10:47:05 | Valid | Epoch[186/600] Iteration[005/008] Valid loss: 0.0385
2023-02-06 10:47:05 | Valid | Epoch[186/600] Iteration[006/008] Valid loss: 0.0394
2023-02-06 10:47:05 | Valid | Epoch[186/600] Iteration[007/008] Valid loss: 0.0392
2023-02-06 10:47:05 | Valid | Epoch[186/600] Iteration[008/008] Valid loss: 0.0390
2023-02-06 10:47:05 | Valid | Epoch[186/600] MIou: 0.8976809051364637
2023-02-06 10:47:05 | Valid | Epoch[186/600] Pixel Accuracy: 0.9830830891927084
2023-02-06 10:47:05 | Valid | Epoch[186/600] Mean Pixel Accuracy: 0.9085989787215952
2023-02-06 10:47:05 | Stage | Epoch[186/600] Train loss:0.0308
2023-02-06 10:47:05 | Stage | Epoch[186/600] Valid loss:0.0390
2023-02-06 10:47:05 | Stage | Epoch[186/600] LR:0.01

2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[001/030] Train loss: 0.0312
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[002/030] Train loss: 0.0333
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[003/030] Train loss: 0.0337
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[004/030] Train loss: 0.0332
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[005/030] Train loss: 0.0323
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[006/030] Train loss: 0.0321
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[007/030] Train loss: 0.0325
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[008/030] Train loss: 0.0320
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[009/030] Train loss: 0.0320
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[010/030] Train loss: 0.0318
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[011/030] Train loss: 0.0315
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[012/030] Train loss: 0.0315
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[013/030] Train loss: 0.0316
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[014/030] Train loss: 0.0314
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[015/030] Train loss: 0.0314
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[016/030] Train loss: 0.0313
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[017/030] Train loss: 0.0313
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[018/030] Train loss: 0.0318
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[019/030] Train loss: 0.0317
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[020/030] Train loss: 0.0315
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[021/030] Train loss: 0.0315
2023-02-06 10:47:06 | Train | Epoch[187/600] Iteration[022/030] Train loss: 0.0314
2023-02-06 10:47:07 | Train | Epoch[187/600] Iteration[023/030] Train loss: 0.0313
2023-02-06 10:47:07 | Train | Epoch[187/600] Iteration[024/030] Train loss: 0.0314
2023-02-06 10:47:07 | Train | Epoch[187/600] Iteration[025/030] Train loss: 0.0314
2023-02-06 10:47:07 | Train | Epoch[187/600] Iteration[026/030] Train loss: 0.0315
2023-02-06 10:47:07 | Train | Epoch[187/600] Iteration[027/030] Train loss: 0.0314
2023-02-06 10:47:07 | Train | Epoch[187/600] Iteration[028/030] Train loss: 0.0314
2023-02-06 10:47:07 | Train | Epoch[187/600] Iteration[029/030] Train loss: 0.0315
2023-02-06 10:47:07 | Train | Epoch[187/600] Iteration[030/030] Train loss: 0.0314
2023-02-06 10:47:07 | Valid | Epoch[187/600] Iteration[001/008] Valid loss: 3.2667
2023-02-06 10:47:07 | Valid | Epoch[187/600] Iteration[002/008] Valid loss: 3.1696
2023-02-06 10:47:07 | Valid | Epoch[187/600] Iteration[003/008] Valid loss: 3.3014
2023-02-06 10:47:07 | Valid | Epoch[187/600] Iteration[004/008] Valid loss: 3.4028
2023-02-06 10:47:07 | Valid | Epoch[187/600] Iteration[005/008] Valid loss: 3.4402
2023-02-06 10:47:07 | Valid | Epoch[187/600] Iteration[006/008] Valid loss: 3.4066
2023-02-06 10:47:07 | Valid | Epoch[187/600] Iteration[007/008] Valid loss: 3.5014
2023-02-06 10:47:07 | Valid | Epoch[187/600] Iteration[008/008] Valid loss: 3.6286
2023-02-06 10:47:07 | Valid | Epoch[187/600] MIou: 0.6619572337768453
2023-02-06 10:47:07 | Valid | Epoch[187/600] Pixel Accuracy: 0.8883209228515625
2023-02-06 10:47:07 | Valid | Epoch[187/600] Mean Pixel Accuracy: 0.9377667930191584
2023-02-06 10:47:07 | Stage | Epoch[187/600] Train loss:0.0314
2023-02-06 10:47:07 | Stage | Epoch[187/600] Valid loss:3.6286
2023-02-06 10:47:07 | Stage | Epoch[187/600] LR:0.01

2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[001/030] Train loss: 0.0328
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[002/030] Train loss: 0.0339
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[003/030] Train loss: 0.0332
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[004/030] Train loss: 0.0333
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[005/030] Train loss: 0.0331
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[006/030] Train loss: 0.0329
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[007/030] Train loss: 0.0322
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[008/030] Train loss: 0.0322
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[009/030] Train loss: 0.0318
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[010/030] Train loss: 0.0318
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[011/030] Train loss: 0.0319
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[012/030] Train loss: 0.0317
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[013/030] Train loss: 0.0317
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[014/030] Train loss: 0.0317
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[015/030] Train loss: 0.0316
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[016/030] Train loss: 0.0318
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[017/030] Train loss: 0.0318
2023-02-06 10:47:08 | Train | Epoch[188/600] Iteration[018/030] Train loss: 0.0317
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[019/030] Train loss: 0.0316
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[020/030] Train loss: 0.0317
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[021/030] Train loss: 0.0318
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[022/030] Train loss: 0.0317
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[023/030] Train loss: 0.0315
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[024/030] Train loss: 0.0314
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[025/030] Train loss: 0.0315
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[026/030] Train loss: 0.0316
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[027/030] Train loss: 0.0315
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[028/030] Train loss: 0.0314
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[029/030] Train loss: 0.0314
2023-02-06 10:47:09 | Train | Epoch[188/600] Iteration[030/030] Train loss: 0.0316
2023-02-06 10:47:09 | Valid | Epoch[188/600] Iteration[001/008] Valid loss: 0.0852
2023-02-06 10:47:09 | Valid | Epoch[188/600] Iteration[002/008] Valid loss: 0.0851
2023-02-06 10:47:09 | Valid | Epoch[188/600] Iteration[003/008] Valid loss: 0.0884
2023-02-06 10:47:09 | Valid | Epoch[188/600] Iteration[004/008] Valid loss: 0.0883
2023-02-06 10:47:09 | Valid | Epoch[188/600] Iteration[005/008] Valid loss: 0.0904
2023-02-06 10:47:09 | Valid | Epoch[188/600] Iteration[006/008] Valid loss: 0.0890
2023-02-06 10:47:09 | Valid | Epoch[188/600] Iteration[007/008] Valid loss: 0.0871
2023-02-06 10:47:09 | Valid | Epoch[188/600] Iteration[008/008] Valid loss: 0.0895
2023-02-06 10:47:10 | Valid | Epoch[188/600] MIou: 0.6744435860460937
2023-02-06 10:47:10 | Valid | Epoch[188/600] Pixel Accuracy: 0.9462331136067709
2023-02-06 10:47:10 | Valid | Epoch[188/600] Mean Pixel Accuracy: 0.7023469287192555
2023-02-06 10:47:10 | Stage | Epoch[188/600] Train loss:0.0316
2023-02-06 10:47:10 | Stage | Epoch[188/600] Valid loss:0.0895
2023-02-06 10:47:10 | Stage | Epoch[188/600] LR:0.01

2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[001/030] Train loss: 0.0344
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[002/030] Train loss: 0.0303
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[003/030] Train loss: 0.0311
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[004/030] Train loss: 0.0312
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[005/030] Train loss: 0.0314
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[006/030] Train loss: 0.0312
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[007/030] Train loss: 0.0306
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[008/030] Train loss: 0.0308
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[009/030] Train loss: 0.0308
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[010/030] Train loss: 0.0313
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[011/030] Train loss: 0.0314
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[012/030] Train loss: 0.0314
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[013/030] Train loss: 0.0313
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[014/030] Train loss: 0.0314
2023-02-06 10:47:10 | Train | Epoch[189/600] Iteration[015/030] Train loss: 0.0315
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[016/030] Train loss: 0.0314
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[017/030] Train loss: 0.0313
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[018/030] Train loss: 0.0312
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[019/030] Train loss: 0.0311
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[020/030] Train loss: 0.0315
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[021/030] Train loss: 0.0313
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[022/030] Train loss: 0.0312
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[023/030] Train loss: 0.0312
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[024/030] Train loss: 0.0311
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[025/030] Train loss: 0.0310
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[026/030] Train loss: 0.0309
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[027/030] Train loss: 0.0311
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[028/030] Train loss: 0.0312
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[029/030] Train loss: 0.0310
2023-02-06 10:47:11 | Train | Epoch[189/600] Iteration[030/030] Train loss: 0.0309
2023-02-06 10:47:11 | Valid | Epoch[189/600] Iteration[001/008] Valid loss: 0.0437
2023-02-06 10:47:12 | Valid | Epoch[189/600] Iteration[002/008] Valid loss: 0.0385
2023-02-06 10:47:12 | Valid | Epoch[189/600] Iteration[003/008] Valid loss: 0.0376
2023-02-06 10:47:12 | Valid | Epoch[189/600] Iteration[004/008] Valid loss: 0.0367
2023-02-06 10:47:12 | Valid | Epoch[189/600] Iteration[005/008] Valid loss: 0.0376
2023-02-06 10:47:12 | Valid | Epoch[189/600] Iteration[006/008] Valid loss: 0.0380
2023-02-06 10:47:12 | Valid | Epoch[189/600] Iteration[007/008] Valid loss: 0.0390
2023-02-06 10:47:12 | Valid | Epoch[189/600] Iteration[008/008] Valid loss: 0.0385
2023-02-06 10:47:12 | Valid | Epoch[189/600] MIou: 0.9307600898578222
2023-02-06 10:47:12 | Valid | Epoch[189/600] Pixel Accuracy: 0.9883435567220052
2023-02-06 10:47:12 | Valid | Epoch[189/600] Mean Pixel Accuracy: 0.9471555082846596
2023-02-06 10:47:12 | Stage | Epoch[189/600] Train loss:0.0309
2023-02-06 10:47:12 | Stage | Epoch[189/600] Valid loss:0.0385
2023-02-06 10:47:12 | Stage | Epoch[189/600] LR:0.01

2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[001/030] Train loss: 0.0331
2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[002/030] Train loss: 0.0314
2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[003/030] Train loss: 0.0309
2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[004/030] Train loss: 0.0296
2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[005/030] Train loss: 0.0302
2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[006/030] Train loss: 0.0303
2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[007/030] Train loss: 0.0303
2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[008/030] Train loss: 0.0303
2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[009/030] Train loss: 0.0310
2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[010/030] Train loss: 0.0306
2023-02-06 10:47:12 | Train | Epoch[190/600] Iteration[011/030] Train loss: 0.0301
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[012/030] Train loss: 0.0305
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[013/030] Train loss: 0.0304
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[014/030] Train loss: 0.0306
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[015/030] Train loss: 0.0308
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[016/030] Train loss: 0.0307
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[017/030] Train loss: 0.0311
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[018/030] Train loss: 0.0311
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[019/030] Train loss: 0.0309
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[020/030] Train loss: 0.0311
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[021/030] Train loss: 0.0309
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[022/030] Train loss: 0.0311
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[023/030] Train loss: 0.0310
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[024/030] Train loss: 0.0311
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[025/030] Train loss: 0.0309
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[026/030] Train loss: 0.0310
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[027/030] Train loss: 0.0309
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[028/030] Train loss: 0.0310
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[029/030] Train loss: 0.0310
2023-02-06 10:47:13 | Train | Epoch[190/600] Iteration[030/030] Train loss: 0.0309
2023-02-06 10:47:14 | Valid | Epoch[190/600] Iteration[001/008] Valid loss: 0.1960
2023-02-06 10:47:14 | Valid | Epoch[190/600] Iteration[002/008] Valid loss: 0.1820
2023-02-06 10:47:14 | Valid | Epoch[190/600] Iteration[003/008] Valid loss: 0.1597
2023-02-06 10:47:14 | Valid | Epoch[190/600] Iteration[004/008] Valid loss: 0.1588
2023-02-06 10:47:14 | Valid | Epoch[190/600] Iteration[005/008] Valid loss: 0.1573
2023-02-06 10:47:14 | Valid | Epoch[190/600] Iteration[006/008] Valid loss: 0.1562
2023-02-06 10:47:14 | Valid | Epoch[190/600] Iteration[007/008] Valid loss: 0.1679
2023-02-06 10:47:14 | Valid | Epoch[190/600] Iteration[008/008] Valid loss: 0.1711
2023-02-06 10:47:14 | Valid | Epoch[190/600] MIou: 0.9023361094420459
2023-02-06 10:47:14 | Valid | Epoch[190/600] Pixel Accuracy: 0.9814580281575521
2023-02-06 10:47:14 | Valid | Epoch[190/600] Mean Pixel Accuracy: 0.9752888617167552
2023-02-06 10:47:14 | Stage | Epoch[190/600] Train loss:0.0309
2023-02-06 10:47:14 | Stage | Epoch[190/600] Valid loss:0.1711
2023-02-06 10:47:14 | Stage | Epoch[190/600] LR:0.01

2023-02-06 10:47:14 | Train | Epoch[191/600] Iteration[001/030] Train loss: 0.0299
2023-02-06 10:47:14 | Train | Epoch[191/600] Iteration[002/030] Train loss: 0.0296
2023-02-06 10:47:14 | Train | Epoch[191/600] Iteration[003/030] Train loss: 0.0298
2023-02-06 10:47:14 | Train | Epoch[191/600] Iteration[004/030] Train loss: 0.0302
2023-02-06 10:47:14 | Train | Epoch[191/600] Iteration[005/030] Train loss: 0.0302
2023-02-06 10:47:14 | Train | Epoch[191/600] Iteration[006/030] Train loss: 0.0311
2023-02-06 10:47:14 | Train | Epoch[191/600] Iteration[007/030] Train loss: 0.0315
2023-02-06 10:47:14 | Train | Epoch[191/600] Iteration[008/030] Train loss: 0.0313
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[009/030] Train loss: 0.0312
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[010/030] Train loss: 0.0313
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[011/030] Train loss: 0.0312
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[012/030] Train loss: 0.0311
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[013/030] Train loss: 0.0311
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[014/030] Train loss: 0.0309
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[015/030] Train loss: 0.0310
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[016/030] Train loss: 0.0313
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[017/030] Train loss: 0.0313
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[018/030] Train loss: 0.0310
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[019/030] Train loss: 0.0307
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[020/030] Train loss: 0.0305
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[021/030] Train loss: 0.0307
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[022/030] Train loss: 0.0308
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[023/030] Train loss: 0.0307
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[024/030] Train loss: 0.0308
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[025/030] Train loss: 0.0308
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[026/030] Train loss: 0.0308
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[027/030] Train loss: 0.0309
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[028/030] Train loss: 0.0310
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[029/030] Train loss: 0.0309
2023-02-06 10:47:15 | Train | Epoch[191/600] Iteration[030/030] Train loss: 0.0309
2023-02-06 10:47:16 | Valid | Epoch[191/600] Iteration[001/008] Valid loss: 0.2302
2023-02-06 10:47:16 | Valid | Epoch[191/600] Iteration[002/008] Valid loss: 0.2314
2023-02-06 10:47:16 | Valid | Epoch[191/600] Iteration[003/008] Valid loss: 0.2430
2023-02-06 10:47:16 | Valid | Epoch[191/600] Iteration[004/008] Valid loss: 0.2458
2023-02-06 10:47:16 | Valid | Epoch[191/600] Iteration[005/008] Valid loss: 0.2525
2023-02-06 10:47:16 | Valid | Epoch[191/600] Iteration[006/008] Valid loss: 0.2500
2023-02-06 10:47:16 | Valid | Epoch[191/600] Iteration[007/008] Valid loss: 0.2486
2023-02-06 10:47:16 | Valid | Epoch[191/600] Iteration[008/008] Valid loss: 0.2558
2023-02-06 10:47:16 | Valid | Epoch[191/600] MIou: 0.4550542752410718
2023-02-06 10:47:16 | Valid | Epoch[191/600] Pixel Accuracy: 0.9097175598144531
2023-02-06 10:47:16 | Valid | Epoch[191/600] Mean Pixel Accuracy: 0.5001971025918991
2023-02-06 10:47:16 | Stage | Epoch[191/600] Train loss:0.0309
2023-02-06 10:47:16 | Stage | Epoch[191/600] Valid loss:0.2558
2023-02-06 10:47:16 | Stage | Epoch[191/600] LR:0.01

2023-02-06 10:47:16 | Train | Epoch[192/600] Iteration[001/030] Train loss: 0.0308
2023-02-06 10:47:16 | Train | Epoch[192/600] Iteration[002/030] Train loss: 0.0331
2023-02-06 10:47:16 | Train | Epoch[192/600] Iteration[003/030] Train loss: 0.0326
2023-02-06 10:47:16 | Train | Epoch[192/600] Iteration[004/030] Train loss: 0.0322
2023-02-06 10:47:16 | Train | Epoch[192/600] Iteration[005/030] Train loss: 0.0322
2023-02-06 10:47:16 | Train | Epoch[192/600] Iteration[006/030] Train loss: 0.0319
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[007/030] Train loss: 0.0323
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[008/030] Train loss: 0.0326
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[009/030] Train loss: 0.0323
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[010/030] Train loss: 0.0319
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[011/030] Train loss: 0.0316
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[012/030] Train loss: 0.0317
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[013/030] Train loss: 0.0316
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[014/030] Train loss: 0.0314
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[015/030] Train loss: 0.0317
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[016/030] Train loss: 0.0317
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[017/030] Train loss: 0.0318
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[018/030] Train loss: 0.0317
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[019/030] Train loss: 0.0313
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[020/030] Train loss: 0.0313
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[021/030] Train loss: 0.0311
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[022/030] Train loss: 0.0313
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[023/030] Train loss: 0.0313
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[024/030] Train loss: 0.0314
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[025/030] Train loss: 0.0315
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[026/030] Train loss: 0.0314
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[027/030] Train loss: 0.0316
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[028/030] Train loss: 0.0317
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[029/030] Train loss: 0.0316
2023-02-06 10:47:17 | Train | Epoch[192/600] Iteration[030/030] Train loss: 0.0319
2023-02-06 10:47:18 | Valid | Epoch[192/600] Iteration[001/008] Valid loss: 0.0429
2023-02-06 10:47:18 | Valid | Epoch[192/600] Iteration[002/008] Valid loss: 0.0399
2023-02-06 10:47:18 | Valid | Epoch[192/600] Iteration[003/008] Valid loss: 0.0405
2023-02-06 10:47:18 | Valid | Epoch[192/600] Iteration[004/008] Valid loss: 0.0395
2023-02-06 10:47:18 | Valid | Epoch[192/600] Iteration[005/008] Valid loss: 0.0397
2023-02-06 10:47:18 | Valid | Epoch[192/600] Iteration[006/008] Valid loss: 0.0391
2023-02-06 10:47:18 | Valid | Epoch[192/600] Iteration[007/008] Valid loss: 0.0385
2023-02-06 10:47:18 | Valid | Epoch[192/600] Iteration[008/008] Valid loss: 0.0390
2023-02-06 10:47:18 | Valid | Epoch[192/600] MIou: 0.8805755604180577
2023-02-06 10:47:18 | Valid | Epoch[192/600] Pixel Accuracy: 0.9802691141764323
2023-02-06 10:47:18 | Valid | Epoch[192/600] Mean Pixel Accuracy: 0.8925262778053433
2023-02-06 10:47:18 | Stage | Epoch[192/600] Train loss:0.0319
2023-02-06 10:47:18 | Stage | Epoch[192/600] Valid loss:0.0390
2023-02-06 10:47:18 | Stage | Epoch[192/600] LR:0.01

2023-02-06 10:47:18 | Train | Epoch[193/600] Iteration[001/030] Train loss: 0.0342
2023-02-06 10:47:18 | Train | Epoch[193/600] Iteration[002/030] Train loss: 0.0316
2023-02-06 10:47:18 | Train | Epoch[193/600] Iteration[003/030] Train loss: 0.0308
2023-02-06 10:47:18 | Train | Epoch[193/600] Iteration[004/030] Train loss: 0.0310
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[005/030] Train loss: 0.0312
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[006/030] Train loss: 0.0307
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[007/030] Train loss: 0.0302
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[008/030] Train loss: 0.0300
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[009/030] Train loss: 0.0300
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[010/030] Train loss: 0.0300
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[011/030] Train loss: 0.0301
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[012/030] Train loss: 0.0300
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[013/030] Train loss: 0.0303
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[014/030] Train loss: 0.0300
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[015/030] Train loss: 0.0300
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[016/030] Train loss: 0.0303
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[017/030] Train loss: 0.0304
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[018/030] Train loss: 0.0302
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[019/030] Train loss: 0.0304
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[020/030] Train loss: 0.0304
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[021/030] Train loss: 0.0306
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[022/030] Train loss: 0.0305
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[023/030] Train loss: 0.0305
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[024/030] Train loss: 0.0305
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[025/030] Train loss: 0.0304
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[026/030] Train loss: 0.0305
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[027/030] Train loss: 0.0305
2023-02-06 10:47:19 | Train | Epoch[193/600] Iteration[028/030] Train loss: 0.0304
2023-02-06 10:47:20 | Train | Epoch[193/600] Iteration[029/030] Train loss: 0.0306
2023-02-06 10:47:20 | Train | Epoch[193/600] Iteration[030/030] Train loss: 0.0307
2023-02-06 10:47:20 | Valid | Epoch[193/600] Iteration[001/008] Valid loss: 0.2070
2023-02-06 10:47:20 | Valid | Epoch[193/600] Iteration[002/008] Valid loss: 0.1723
2023-02-06 10:47:20 | Valid | Epoch[193/600] Iteration[003/008] Valid loss: 0.1574
2023-02-06 10:47:20 | Valid | Epoch[193/600] Iteration[004/008] Valid loss: 0.1547
2023-02-06 10:47:20 | Valid | Epoch[193/600] Iteration[005/008] Valid loss: 0.1595
2023-02-06 10:47:20 | Valid | Epoch[193/600] Iteration[006/008] Valid loss: 0.1600
2023-02-06 10:47:20 | Valid | Epoch[193/600] Iteration[007/008] Valid loss: 0.1702
2023-02-06 10:47:20 | Valid | Epoch[193/600] Iteration[008/008] Valid loss: 0.1660
2023-02-06 10:47:20 | Valid | Epoch[193/600] MIou: 0.8988692566949164
2023-02-06 10:47:20 | Valid | Epoch[193/600] Pixel Accuracy: 0.9803606669108073
2023-02-06 10:47:20 | Valid | Epoch[193/600] Mean Pixel Accuracy: 0.9828522324817778
2023-02-06 10:47:20 | Stage | Epoch[193/600] Train loss:0.0307
2023-02-06 10:47:20 | Stage | Epoch[193/600] Valid loss:0.1660
2023-02-06 10:47:20 | Stage | Epoch[193/600] LR:0.01

2023-02-06 10:47:20 | Train | Epoch[194/600] Iteration[001/030] Train loss: 0.0298
2023-02-06 10:47:20 | Train | Epoch[194/600] Iteration[002/030] Train loss: 0.0309
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[003/030] Train loss: 0.0298
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[004/030] Train loss: 0.0292
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[005/030] Train loss: 0.0290
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[006/030] Train loss: 0.0288
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[007/030] Train loss: 0.0288
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[008/030] Train loss: 0.0289
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[009/030] Train loss: 0.0290
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[010/030] Train loss: 0.0296
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[011/030] Train loss: 0.0297
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[012/030] Train loss: 0.0303
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[013/030] Train loss: 0.0309
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[014/030] Train loss: 0.0310
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[015/030] Train loss: 0.0311
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[016/030] Train loss: 0.0309
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[017/030] Train loss: 0.0309
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[018/030] Train loss: 0.0311
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[019/030] Train loss: 0.0309
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[020/030] Train loss: 0.0309
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[021/030] Train loss: 0.0309
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[022/030] Train loss: 0.0309
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[023/030] Train loss: 0.0308
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[024/030] Train loss: 0.0308
2023-02-06 10:47:21 | Train | Epoch[194/600] Iteration[025/030] Train loss: 0.0307
2023-02-06 10:47:22 | Train | Epoch[194/600] Iteration[026/030] Train loss: 0.0306
2023-02-06 10:47:22 | Train | Epoch[194/600] Iteration[027/030] Train loss: 0.0309
2023-02-06 10:47:22 | Train | Epoch[194/600] Iteration[028/030] Train loss: 0.0311
2023-02-06 10:47:22 | Train | Epoch[194/600] Iteration[029/030] Train loss: 0.0311
2023-02-06 10:47:22 | Train | Epoch[194/600] Iteration[030/030] Train loss: 0.0314
2023-02-06 10:47:22 | Valid | Epoch[194/600] Iteration[001/008] Valid loss: 0.0831
2023-02-06 10:47:22 | Valid | Epoch[194/600] Iteration[002/008] Valid loss: 0.0822
2023-02-06 10:47:22 | Valid | Epoch[194/600] Iteration[003/008] Valid loss: 0.0849
2023-02-06 10:47:22 | Valid | Epoch[194/600] Iteration[004/008] Valid loss: 0.0845
2023-02-06 10:47:22 | Valid | Epoch[194/600] Iteration[005/008] Valid loss: 0.0855
2023-02-06 10:47:22 | Valid | Epoch[194/600] Iteration[006/008] Valid loss: 0.0841
2023-02-06 10:47:22 | Valid | Epoch[194/600] Iteration[007/008] Valid loss: 0.0821
2023-02-06 10:47:22 | Valid | Epoch[194/600] Iteration[008/008] Valid loss: 0.0837
2023-02-06 10:47:22 | Valid | Epoch[194/600] MIou: 0.752733421873655
2023-02-06 10:47:22 | Valid | Epoch[194/600] Pixel Accuracy: 0.9592107137044271
2023-02-06 10:47:22 | Valid | Epoch[194/600] Mean Pixel Accuracy: 0.7741908234664714
2023-02-06 10:47:22 | Stage | Epoch[194/600] Train loss:0.0314
2023-02-06 10:47:22 | Stage | Epoch[194/600] Valid loss:0.0837
2023-02-06 10:47:22 | Stage | Epoch[194/600] LR:0.01

2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[001/030] Train loss: 0.0291
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[002/030] Train loss: 0.0295
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[003/030] Train loss: 0.0303
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[004/030] Train loss: 0.0302
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[005/030] Train loss: 0.0309
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[006/030] Train loss: 0.0304
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[007/030] Train loss: 0.0314
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[008/030] Train loss: 0.0316
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[009/030] Train loss: 0.0315
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[010/030] Train loss: 0.0317
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[011/030] Train loss: 0.0315
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[012/030] Train loss: 0.0315
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[013/030] Train loss: 0.0313
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[014/030] Train loss: 0.0315
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[015/030] Train loss: 0.0313
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[016/030] Train loss: 0.0312
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[017/030] Train loss: 0.0311
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[018/030] Train loss: 0.0310
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[019/030] Train loss: 0.0310
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[020/030] Train loss: 0.0311
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[021/030] Train loss: 0.0310
2023-02-06 10:47:23 | Train | Epoch[195/600] Iteration[022/030] Train loss: 0.0312
2023-02-06 10:47:24 | Train | Epoch[195/600] Iteration[023/030] Train loss: 0.0311
2023-02-06 10:47:24 | Train | Epoch[195/600] Iteration[024/030] Train loss: 0.0310
2023-02-06 10:47:24 | Train | Epoch[195/600] Iteration[025/030] Train loss: 0.0310
2023-02-06 10:47:24 | Train | Epoch[195/600] Iteration[026/030] Train loss: 0.0309
2023-02-06 10:47:24 | Train | Epoch[195/600] Iteration[027/030] Train loss: 0.0308
2023-02-06 10:47:24 | Train | Epoch[195/600] Iteration[028/030] Train loss: 0.0307
2023-02-06 10:47:24 | Train | Epoch[195/600] Iteration[029/030] Train loss: 0.0306
2023-02-06 10:47:24 | Train | Epoch[195/600] Iteration[030/030] Train loss: 0.0308
2023-02-06 10:47:24 | Valid | Epoch[195/600] Iteration[001/008] Valid loss: 0.0493
2023-02-06 10:47:24 | Valid | Epoch[195/600] Iteration[002/008] Valid loss: 0.0477
2023-02-06 10:47:24 | Valid | Epoch[195/600] Iteration[003/008] Valid loss: 0.0487
2023-02-06 10:47:24 | Valid | Epoch[195/600] Iteration[004/008] Valid loss: 0.0480
2023-02-06 10:47:24 | Valid | Epoch[195/600] Iteration[005/008] Valid loss: 0.0486
2023-02-06 10:47:24 | Valid | Epoch[195/600] Iteration[006/008] Valid loss: 0.0475
2023-02-06 10:47:24 | Valid | Epoch[195/600] Iteration[007/008] Valid loss: 0.0466
2023-02-06 10:47:24 | Valid | Epoch[195/600] Iteration[008/008] Valid loss: 0.0474
2023-02-06 10:47:24 | Valid | Epoch[195/600] MIou: 0.8453562739274799
2023-02-06 10:47:24 | Valid | Epoch[195/600] Pixel Accuracy: 0.9744669596354166
2023-02-06 10:47:24 | Valid | Epoch[195/600] Mean Pixel Accuracy: 0.8598032499104272
2023-02-06 10:47:24 | Stage | Epoch[195/600] Train loss:0.0308
2023-02-06 10:47:24 | Stage | Epoch[195/600] Valid loss:0.0474
2023-02-06 10:47:24 | Stage | Epoch[195/600] LR:0.01

2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[001/030] Train loss: 0.0271
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[003/030] Train loss: 0.0273
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[004/030] Train loss: 0.0280
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[005/030] Train loss: 0.0291
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[006/030] Train loss: 0.0298
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[007/030] Train loss: 0.0294
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[008/030] Train loss: 0.0299
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[009/030] Train loss: 0.0303
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[010/030] Train loss: 0.0303
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[011/030] Train loss: 0.0305
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[012/030] Train loss: 0.0304
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[013/030] Train loss: 0.0301
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[014/030] Train loss: 0.0303
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[015/030] Train loss: 0.0302
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[016/030] Train loss: 0.0305
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[017/030] Train loss: 0.0308
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[018/030] Train loss: 0.0308
2023-02-06 10:47:25 | Train | Epoch[196/600] Iteration[019/030] Train loss: 0.0307
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[020/030] Train loss: 0.0308
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[021/030] Train loss: 0.0309
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[022/030] Train loss: 0.0308
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[023/030] Train loss: 0.0308
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[024/030] Train loss: 0.0307
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[025/030] Train loss: 0.0308
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[026/030] Train loss: 0.0307
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[027/030] Train loss: 0.0309
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[028/030] Train loss: 0.0311
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[029/030] Train loss: 0.0311
2023-02-06 10:47:26 | Train | Epoch[196/600] Iteration[030/030] Train loss: 0.0310
2023-02-06 10:47:26 | Valid | Epoch[196/600] Iteration[001/008] Valid loss: 0.2272
2023-02-06 10:47:26 | Valid | Epoch[196/600] Iteration[002/008] Valid loss: 0.2318
2023-02-06 10:47:26 | Valid | Epoch[196/600] Iteration[003/008] Valid loss: 0.2435
2023-02-06 10:47:26 | Valid | Epoch[196/600] Iteration[004/008] Valid loss: 0.2458
2023-02-06 10:47:26 | Valid | Epoch[196/600] Iteration[005/008] Valid loss: 0.2535
2023-02-06 10:47:26 | Valid | Epoch[196/600] Iteration[006/008] Valid loss: 0.2502
2023-02-06 10:47:26 | Valid | Epoch[196/600] Iteration[007/008] Valid loss: 0.2484
2023-02-06 10:47:26 | Valid | Epoch[196/600] Iteration[008/008] Valid loss: 0.2563
2023-02-06 10:47:27 | Valid | Epoch[196/600] MIou: 0.4549628619908263
2023-02-06 10:47:27 | Valid | Epoch[196/600] Pixel Accuracy: 0.9097023010253906
2023-02-06 10:47:27 | Valid | Epoch[196/600] Mean Pixel Accuracy: 0.5001126300525137
2023-02-06 10:47:27 | Stage | Epoch[196/600] Train loss:0.0310
2023-02-06 10:47:27 | Stage | Epoch[196/600] Valid loss:0.2563
2023-02-06 10:47:27 | Stage | Epoch[196/600] LR:0.01

2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[001/030] Train loss: 0.0344
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[002/030] Train loss: 0.0323
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[003/030] Train loss: 0.0305
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[004/030] Train loss: 0.0297
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[005/030] Train loss: 0.0309
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[006/030] Train loss: 0.0307
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[007/030] Train loss: 0.0302
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[008/030] Train loss: 0.0299
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[009/030] Train loss: 0.0299
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[010/030] Train loss: 0.0304
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[011/030] Train loss: 0.0308
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[012/030] Train loss: 0.0308
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[013/030] Train loss: 0.0307
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[014/030] Train loss: 0.0311
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[015/030] Train loss: 0.0312
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[016/030] Train loss: 0.0311
2023-02-06 10:47:27 | Train | Epoch[197/600] Iteration[017/030] Train loss: 0.0307
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[018/030] Train loss: 0.0305
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[019/030] Train loss: 0.0306
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[020/030] Train loss: 0.0309
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[021/030] Train loss: 0.0307
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[022/030] Train loss: 0.0305
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[023/030] Train loss: 0.0305
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[024/030] Train loss: 0.0308
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[025/030] Train loss: 0.0309
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[026/030] Train loss: 0.0308
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[027/030] Train loss: 0.0308
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[028/030] Train loss: 0.0310
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[029/030] Train loss: 0.0309
2023-02-06 10:47:28 | Train | Epoch[197/600] Iteration[030/030] Train loss: 0.0309
2023-02-06 10:47:28 | Valid | Epoch[197/600] Iteration[001/008] Valid loss: 0.1328
2023-02-06 10:47:28 | Valid | Epoch[197/600] Iteration[002/008] Valid loss: 0.0971
2023-02-06 10:47:28 | Valid | Epoch[197/600] Iteration[003/008] Valid loss: 0.0902
2023-02-06 10:47:28 | Valid | Epoch[197/600] Iteration[004/008] Valid loss: 0.0868
2023-02-06 10:47:29 | Valid | Epoch[197/600] Iteration[005/008] Valid loss: 0.0886
2023-02-06 10:47:29 | Valid | Epoch[197/600] Iteration[006/008] Valid loss: 0.0861
2023-02-06 10:47:29 | Valid | Epoch[197/600] Iteration[007/008] Valid loss: 0.0941
2023-02-06 10:47:29 | Valid | Epoch[197/600] Iteration[008/008] Valid loss: 0.0929
2023-02-06 10:47:29 | Valid | Epoch[197/600] MIou: 0.9165872268621266
2023-02-06 10:47:29 | Valid | Epoch[197/600] Pixel Accuracy: 0.9846089680989584
2023-02-06 10:47:29 | Valid | Epoch[197/600] Mean Pixel Accuracy: 0.9761964913963199
2023-02-06 10:47:29 | Stage | Epoch[197/600] Train loss:0.0309
2023-02-06 10:47:29 | Stage | Epoch[197/600] Valid loss:0.0929
2023-02-06 10:47:29 | Stage | Epoch[197/600] LR:0.01

2023-02-06 10:47:29 | Train | Epoch[198/600] Iteration[001/030] Train loss: 0.0320
2023-02-06 10:47:29 | Train | Epoch[198/600] Iteration[002/030] Train loss: 0.0298
2023-02-06 10:47:29 | Train | Epoch[198/600] Iteration[003/030] Train loss: 0.0281
2023-02-06 10:47:29 | Train | Epoch[198/600] Iteration[004/030] Train loss: 0.0291
2023-02-06 10:47:29 | Train | Epoch[198/600] Iteration[005/030] Train loss: 0.0305
2023-02-06 10:47:29 | Train | Epoch[198/600] Iteration[006/030] Train loss: 0.0309
2023-02-06 10:47:29 | Train | Epoch[198/600] Iteration[007/030] Train loss: 0.0309
2023-02-06 10:47:29 | Train | Epoch[198/600] Iteration[008/030] Train loss: 0.0308
2023-02-06 10:47:29 | Train | Epoch[198/600] Iteration[009/030] Train loss: 0.0304
2023-02-06 10:47:29 | Train | Epoch[198/600] Iteration[010/030] Train loss: 0.0305
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[011/030] Train loss: 0.0306
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[012/030] Train loss: 0.0307
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[013/030] Train loss: 0.0306
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[014/030] Train loss: 0.0308
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[015/030] Train loss: 0.0307
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[016/030] Train loss: 0.0305
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[017/030] Train loss: 0.0309
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[018/030] Train loss: 0.0309
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[019/030] Train loss: 0.0308
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[020/030] Train loss: 0.0307
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[021/030] Train loss: 0.0305
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[022/030] Train loss: 0.0306
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[023/030] Train loss: 0.0306
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[024/030] Train loss: 0.0306
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[025/030] Train loss: 0.0307
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[026/030] Train loss: 0.0307
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[027/030] Train loss: 0.0306
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[028/030] Train loss: 0.0306
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[029/030] Train loss: 0.0307
2023-02-06 10:47:30 | Train | Epoch[198/600] Iteration[030/030] Train loss: 0.0307
2023-02-06 10:47:31 | Valid | Epoch[198/600] Iteration[001/008] Valid loss: 0.3886
2023-02-06 10:47:31 | Valid | Epoch[198/600] Iteration[002/008] Valid loss: 0.3360
2023-02-06 10:47:31 | Valid | Epoch[198/600] Iteration[003/008] Valid loss: 0.3219
2023-02-06 10:47:31 | Valid | Epoch[198/600] Iteration[004/008] Valid loss: 0.3233
2023-02-06 10:47:31 | Valid | Epoch[198/600] Iteration[005/008] Valid loss: 0.3376
2023-02-06 10:47:31 | Valid | Epoch[198/600] Iteration[006/008] Valid loss: 0.3300
2023-02-06 10:47:31 | Valid | Epoch[198/600] Iteration[007/008] Valid loss: 0.3502
2023-02-06 10:47:31 | Valid | Epoch[198/600] Iteration[008/008] Valid loss: 0.3554
2023-02-06 10:47:31 | Valid | Epoch[198/600] MIou: 0.8635263678127386
2023-02-06 10:47:31 | Valid | Epoch[198/600] Pixel Accuracy: 0.9715843200683594
2023-02-06 10:47:31 | Valid | Epoch[198/600] Mean Pixel Accuracy: 0.9784341681318016
2023-02-06 10:47:31 | Stage | Epoch[198/600] Train loss:0.0307
2023-02-06 10:47:31 | Stage | Epoch[198/600] Valid loss:0.3554
2023-02-06 10:47:31 | Stage | Epoch[198/600] LR:0.01

2023-02-06 10:47:31 | Train | Epoch[199/600] Iteration[001/030] Train loss: 0.0298
2023-02-06 10:47:31 | Train | Epoch[199/600] Iteration[002/030] Train loss: 0.0303
2023-02-06 10:47:31 | Train | Epoch[199/600] Iteration[003/030] Train loss: 0.0298
2023-02-06 10:47:31 | Train | Epoch[199/600] Iteration[004/030] Train loss: 0.0297
2023-02-06 10:47:31 | Train | Epoch[199/600] Iteration[005/030] Train loss: 0.0293
2023-02-06 10:47:31 | Train | Epoch[199/600] Iteration[006/030] Train loss: 0.0291
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[007/030] Train loss: 0.0288
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[008/030] Train loss: 0.0289
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[009/030] Train loss: 0.0288
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[010/030] Train loss: 0.0289
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[011/030] Train loss: 0.0295
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[012/030] Train loss: 0.0298
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[013/030] Train loss: 0.0297
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[014/030] Train loss: 0.0298
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[015/030] Train loss: 0.0299
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[016/030] Train loss: 0.0307
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[017/030] Train loss: 0.0307
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[018/030] Train loss: 0.0306
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[019/030] Train loss: 0.0307
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[020/030] Train loss: 0.0307
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[021/030] Train loss: 0.0309
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[022/030] Train loss: 0.0311
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[023/030] Train loss: 0.0310
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[024/030] Train loss: 0.0310
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[025/030] Train loss: 0.0311
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[026/030] Train loss: 0.0310
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[027/030] Train loss: 0.0313
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[028/030] Train loss: 0.0313
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[029/030] Train loss: 0.0312
2023-02-06 10:47:32 | Train | Epoch[199/600] Iteration[030/030] Train loss: 0.0315
2023-02-06 10:47:33 | Valid | Epoch[199/600] Iteration[001/008] Valid loss: 0.0427
2023-02-06 10:47:33 | Valid | Epoch[199/600] Iteration[002/008] Valid loss: 0.0403
2023-02-06 10:47:33 | Valid | Epoch[199/600] Iteration[003/008] Valid loss: 0.0409
2023-02-06 10:47:33 | Valid | Epoch[199/600] Iteration[004/008] Valid loss: 0.0403
2023-02-06 10:47:33 | Valid | Epoch[199/600] Iteration[005/008] Valid loss: 0.0404
2023-02-06 10:47:33 | Valid | Epoch[199/600] Iteration[006/008] Valid loss: 0.0400
2023-02-06 10:47:33 | Valid | Epoch[199/600] Iteration[007/008] Valid loss: 0.0394
2023-02-06 10:47:33 | Valid | Epoch[199/600] Iteration[008/008] Valid loss: 0.0397
2023-02-06 10:47:33 | Valid | Epoch[199/600] MIou: 0.8734230819790275
2023-02-06 10:47:33 | Valid | Epoch[199/600] Pixel Accuracy: 0.9791399637858073
2023-02-06 10:47:33 | Valid | Epoch[199/600] Mean Pixel Accuracy: 0.884962832287829
2023-02-06 10:47:33 | Stage | Epoch[199/600] Train loss:0.0315
2023-02-06 10:47:33 | Stage | Epoch[199/600] Valid loss:0.0397
2023-02-06 10:47:33 | Stage | Epoch[199/600] LR:0.01

2023-02-06 10:47:33 | Train | Epoch[200/600] Iteration[001/030] Train loss: 0.0316
2023-02-06 10:47:33 | Train | Epoch[200/600] Iteration[002/030] Train loss: 0.0304
2023-02-06 10:47:33 | Train | Epoch[200/600] Iteration[003/030] Train loss: 0.0308
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[004/030] Train loss: 0.0297
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[005/030] Train loss: 0.0288
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[006/030] Train loss: 0.0287
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[007/030] Train loss: 0.0287
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[008/030] Train loss: 0.0287
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[009/030] Train loss: 0.0288
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[010/030] Train loss: 0.0291
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[011/030] Train loss: 0.0290
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[012/030] Train loss: 0.0291
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[013/030] Train loss: 0.0295
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[014/030] Train loss: 0.0295
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[015/030] Train loss: 0.0294
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[016/030] Train loss: 0.0294
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[017/030] Train loss: 0.0295
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[018/030] Train loss: 0.0293
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[019/030] Train loss: 0.0294
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[020/030] Train loss: 0.0292
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[021/030] Train loss: 0.0295
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[022/030] Train loss: 0.0297
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[023/030] Train loss: 0.0296
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[024/030] Train loss: 0.0296
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[025/030] Train loss: 0.0298
2023-02-06 10:47:34 | Train | Epoch[200/600] Iteration[026/030] Train loss: 0.0302
2023-02-06 10:47:35 | Train | Epoch[200/600] Iteration[027/030] Train loss: 0.0300
2023-02-06 10:47:35 | Train | Epoch[200/600] Iteration[028/030] Train loss: 0.0303
2023-02-06 10:47:35 | Train | Epoch[200/600] Iteration[029/030] Train loss: 0.0303
2023-02-06 10:47:35 | Train | Epoch[200/600] Iteration[030/030] Train loss: 0.0303
2023-02-06 10:47:35 | Valid | Epoch[200/600] Iteration[001/008] Valid loss: 0.0462
2023-02-06 10:47:35 | Valid | Epoch[200/600] Iteration[002/008] Valid loss: 0.0374
2023-02-06 10:47:35 | Valid | Epoch[200/600] Iteration[003/008] Valid loss: 0.0362
2023-02-06 10:47:35 | Valid | Epoch[200/600] Iteration[004/008] Valid loss: 0.0348
2023-02-06 10:47:35 | Valid | Epoch[200/600] Iteration[005/008] Valid loss: 0.0353
2023-02-06 10:47:35 | Valid | Epoch[200/600] Iteration[006/008] Valid loss: 0.0349
2023-02-06 10:47:35 | Valid | Epoch[200/600] Iteration[007/008] Valid loss: 0.0357
2023-02-06 10:47:35 | Valid | Epoch[200/600] Iteration[008/008] Valid loss: 0.0352
2023-02-06 10:47:35 | Valid | Epoch[200/600] MIou: 0.927807343935247
2023-02-06 10:47:35 | Valid | Epoch[200/600] Pixel Accuracy: 0.9879252115885416
2023-02-06 10:47:35 | Valid | Epoch[200/600] Mean Pixel Accuracy: 0.9414917838714671
2023-02-06 10:47:35 | Stage | Epoch[200/600] Train loss:0.0303
2023-02-06 10:47:35 | Stage | Epoch[200/600] Valid loss:0.0352
2023-02-06 10:47:35 | Stage | Epoch[200/600] LR:0.01

2023-02-06 10:47:35 | Train | Epoch[201/600] Iteration[001/030] Train loss: 0.0291
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[002/030] Train loss: 0.0301
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[003/030] Train loss: 0.0289
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[004/030] Train loss: 0.0285
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[005/030] Train loss: 0.0284
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[006/030] Train loss: 0.0288
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[007/030] Train loss: 0.0292
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[008/030] Train loss: 0.0289
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[009/030] Train loss: 0.0290
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[010/030] Train loss: 0.0291
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[011/030] Train loss: 0.0292
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[012/030] Train loss: 0.0290
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[013/030] Train loss: 0.0291
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[014/030] Train loss: 0.0292
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[015/030] Train loss: 0.0291
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[016/030] Train loss: 0.0294
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[017/030] Train loss: 0.0296
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[018/030] Train loss: 0.0294
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[019/030] Train loss: 0.0295
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[020/030] Train loss: 0.0297
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[021/030] Train loss: 0.0298
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[022/030] Train loss: 0.0300
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[023/030] Train loss: 0.0300
2023-02-06 10:47:36 | Train | Epoch[201/600] Iteration[024/030] Train loss: 0.0298
2023-02-06 10:47:37 | Train | Epoch[201/600] Iteration[025/030] Train loss: 0.0298
2023-02-06 10:47:37 | Train | Epoch[201/600] Iteration[026/030] Train loss: 0.0299
2023-02-06 10:47:37 | Train | Epoch[201/600] Iteration[027/030] Train loss: 0.0300
2023-02-06 10:47:37 | Train | Epoch[201/600] Iteration[028/030] Train loss: 0.0299
2023-02-06 10:47:37 | Train | Epoch[201/600] Iteration[029/030] Train loss: 0.0299
2023-02-06 10:47:37 | Train | Epoch[201/600] Iteration[030/030] Train loss: 0.0301
2023-02-06 10:47:37 | Valid | Epoch[201/600] Iteration[001/008] Valid loss: 0.7365
2023-02-06 10:47:37 | Valid | Epoch[201/600] Iteration[002/008] Valid loss: 0.7082
2023-02-06 10:47:37 | Valid | Epoch[201/600] Iteration[003/008] Valid loss: 0.7201
2023-02-06 10:47:37 | Valid | Epoch[201/600] Iteration[004/008] Valid loss: 0.7352
2023-02-06 10:47:37 | Valid | Epoch[201/600] Iteration[005/008] Valid loss: 0.7665
2023-02-06 10:47:37 | Valid | Epoch[201/600] Iteration[006/008] Valid loss: 0.7556
2023-02-06 10:47:37 | Valid | Epoch[201/600] Iteration[007/008] Valid loss: 0.7976
2023-02-06 10:47:37 | Valid | Epoch[201/600] Iteration[008/008] Valid loss: 0.8127
2023-02-06 10:47:37 | Valid | Epoch[201/600] MIou: 0.8217918707211587
2023-02-06 10:47:37 | Valid | Epoch[201/600] Pixel Accuracy: 0.9593340555826823
2023-02-06 10:47:37 | Valid | Epoch[201/600] Mean Pixel Accuracy: 0.9749789240810748
2023-02-06 10:47:37 | Stage | Epoch[201/600] Train loss:0.0301
2023-02-06 10:47:37 | Stage | Epoch[201/600] Valid loss:0.8127
2023-02-06 10:47:37 | Stage | Epoch[201/600] LR:0.01

2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[001/030] Train loss: 0.0303
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[002/030] Train loss: 0.0337
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[003/030] Train loss: 0.0330
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[004/030] Train loss: 0.0324
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[005/030] Train loss: 0.0314
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[006/030] Train loss: 0.0314
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[007/030] Train loss: 0.0324
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[008/030] Train loss: 0.0324
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[009/030] Train loss: 0.0321
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[010/030] Train loss: 0.0322
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[011/030] Train loss: 0.0323
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[012/030] Train loss: 0.0324
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[013/030] Train loss: 0.0322
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[014/030] Train loss: 0.0316
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[015/030] Train loss: 0.0319
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[016/030] Train loss: 0.0314
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[017/030] Train loss: 0.0312
2023-02-06 10:47:38 | Train | Epoch[202/600] Iteration[018/030] Train loss: 0.0310
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[019/030] Train loss: 0.0310
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[020/030] Train loss: 0.0309
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[021/030] Train loss: 0.0309
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[022/030] Train loss: 0.0309
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[023/030] Train loss: 0.0312
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[024/030] Train loss: 0.0312
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[025/030] Train loss: 0.0313
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[026/030] Train loss: 0.0313
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[027/030] Train loss: 0.0313
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[028/030] Train loss: 0.0311
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[029/030] Train loss: 0.0312
2023-02-06 10:47:39 | Train | Epoch[202/600] Iteration[030/030] Train loss: 0.0310
2023-02-06 10:47:39 | Valid | Epoch[202/600] Iteration[001/008] Valid loss: 0.0966
2023-02-06 10:47:39 | Valid | Epoch[202/600] Iteration[002/008] Valid loss: 0.0752
2023-02-06 10:47:39 | Valid | Epoch[202/600] Iteration[003/008] Valid loss: 0.0720
2023-02-06 10:47:39 | Valid | Epoch[202/600] Iteration[004/008] Valid loss: 0.0708
2023-02-06 10:47:39 | Valid | Epoch[202/600] Iteration[005/008] Valid loss: 0.0735
2023-02-06 10:47:39 | Valid | Epoch[202/600] Iteration[006/008] Valid loss: 0.0723
2023-02-06 10:47:39 | Valid | Epoch[202/600] Iteration[007/008] Valid loss: 0.0787
2023-02-06 10:47:39 | Valid | Epoch[202/600] Iteration[008/008] Valid loss: 0.0771
2023-02-06 10:47:40 | Valid | Epoch[202/600] MIou: 0.9268407521005485
2023-02-06 10:47:40 | Valid | Epoch[202/600] Pixel Accuracy: 0.9867604573567709
2023-02-06 10:47:40 | Valid | Epoch[202/600] Mean Pixel Accuracy: 0.9771824870343366
2023-02-06 10:47:40 | Stage | Epoch[202/600] Train loss:0.0310
2023-02-06 10:47:40 | Stage | Epoch[202/600] Valid loss:0.0771
2023-02-06 10:47:40 | Stage | Epoch[202/600] LR:0.01

2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[001/030] Train loss: 0.0365
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[002/030] Train loss: 0.0341
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[003/030] Train loss: 0.0337
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[004/030] Train loss: 0.0332
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[005/030] Train loss: 0.0335
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[006/030] Train loss: 0.0325
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[007/030] Train loss: 0.0319
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[008/030] Train loss: 0.0317
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[009/030] Train loss: 0.0318
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[010/030] Train loss: 0.0318
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[011/030] Train loss: 0.0316
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[012/030] Train loss: 0.0311
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[013/030] Train loss: 0.0309
2023-02-06 10:47:40 | Train | Epoch[203/600] Iteration[014/030] Train loss: 0.0310
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[015/030] Train loss: 0.0308
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[016/030] Train loss: 0.0305
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[017/030] Train loss: 0.0304
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[018/030] Train loss: 0.0303
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[019/030] Train loss: 0.0303
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[020/030] Train loss: 0.0303
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[021/030] Train loss: 0.0304
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[022/030] Train loss: 0.0302
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[023/030] Train loss: 0.0302
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[024/030] Train loss: 0.0301
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[025/030] Train loss: 0.0301
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[026/030] Train loss: 0.0302
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[027/030] Train loss: 0.0300
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[028/030] Train loss: 0.0301
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[029/030] Train loss: 0.0299
2023-02-06 10:47:41 | Train | Epoch[203/600] Iteration[030/030] Train loss: 0.0302
2023-02-06 10:47:42 | Valid | Epoch[203/600] Iteration[001/008] Valid loss: 0.0452
2023-02-06 10:47:42 | Valid | Epoch[203/600] Iteration[002/008] Valid loss: 0.0429
2023-02-06 10:47:42 | Valid | Epoch[203/600] Iteration[003/008] Valid loss: 0.0438
2023-02-06 10:47:42 | Valid | Epoch[203/600] Iteration[004/008] Valid loss: 0.0429
2023-02-06 10:47:42 | Valid | Epoch[203/600] Iteration[005/008] Valid loss: 0.0433
2023-02-06 10:47:42 | Valid | Epoch[203/600] Iteration[006/008] Valid loss: 0.0428
2023-02-06 10:47:42 | Valid | Epoch[203/600] Iteration[007/008] Valid loss: 0.0423
2023-02-06 10:47:42 | Valid | Epoch[203/600] Iteration[008/008] Valid loss: 0.0426
2023-02-06 10:47:42 | Valid | Epoch[203/600] MIou: 0.8652342533702456
2023-02-06 10:47:42 | Valid | Epoch[203/600] Pixel Accuracy: 0.9777946472167969
2023-02-06 10:47:42 | Valid | Epoch[203/600] Mean Pixel Accuracy: 0.8773566582775545
2023-02-06 10:47:42 | Stage | Epoch[203/600] Train loss:0.0302
2023-02-06 10:47:42 | Stage | Epoch[203/600] Valid loss:0.0426
2023-02-06 10:47:42 | Stage | Epoch[203/600] LR:0.01

2023-02-06 10:47:42 | Train | Epoch[204/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 10:47:42 | Train | Epoch[204/600] Iteration[002/030] Train loss: 0.0297
2023-02-06 10:47:42 | Train | Epoch[204/600] Iteration[003/030] Train loss: 0.0297
2023-02-06 10:47:42 | Train | Epoch[204/600] Iteration[004/030] Train loss: 0.0291
2023-02-06 10:47:42 | Train | Epoch[204/600] Iteration[005/030] Train loss: 0.0300
2023-02-06 10:47:42 | Train | Epoch[204/600] Iteration[006/030] Train loss: 0.0302
2023-02-06 10:47:42 | Train | Epoch[204/600] Iteration[007/030] Train loss: 0.0306
2023-02-06 10:47:42 | Train | Epoch[204/600] Iteration[008/030] Train loss: 0.0301
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[009/030] Train loss: 0.0296
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[010/030] Train loss: 0.0294
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[011/030] Train loss: 0.0291
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[012/030] Train loss: 0.0293
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[013/030] Train loss: 0.0294
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[014/030] Train loss: 0.0297
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[015/030] Train loss: 0.0296
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[016/030] Train loss: 0.0298
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[017/030] Train loss: 0.0298
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[018/030] Train loss: 0.0300
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[019/030] Train loss: 0.0299
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[020/030] Train loss: 0.0299
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[021/030] Train loss: 0.0300
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[022/030] Train loss: 0.0300
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[023/030] Train loss: 0.0302
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[024/030] Train loss: 0.0302
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[025/030] Train loss: 0.0302
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[026/030] Train loss: 0.0302
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[027/030] Train loss: 0.0301
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[028/030] Train loss: 0.0304
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[029/030] Train loss: 0.0305
2023-02-06 10:47:43 | Train | Epoch[204/600] Iteration[030/030] Train loss: 0.0303
2023-02-06 10:47:44 | Valid | Epoch[204/600] Iteration[001/008] Valid loss: 0.0399
2023-02-06 10:47:44 | Valid | Epoch[204/600] Iteration[002/008] Valid loss: 0.0342
2023-02-06 10:47:44 | Valid | Epoch[204/600] Iteration[003/008] Valid loss: 0.0335
2023-02-06 10:47:44 | Valid | Epoch[204/600] Iteration[004/008] Valid loss: 0.0326
2023-02-06 10:47:44 | Valid | Epoch[204/600] Iteration[005/008] Valid loss: 0.0331
2023-02-06 10:47:44 | Valid | Epoch[204/600] Iteration[006/008] Valid loss: 0.0328
2023-02-06 10:47:44 | Valid | Epoch[204/600] Iteration[007/008] Valid loss: 0.0331
2023-02-06 10:47:44 | Valid | Epoch[204/600] Iteration[008/008] Valid loss: 0.0329
2023-02-06 10:47:44 | Valid | Epoch[204/600] MIou: 0.9194058654346249
2023-02-06 10:47:44 | Valid | Epoch[204/600] Pixel Accuracy: 0.9865900675455729
2023-02-06 10:47:44 | Valid | Epoch[204/600] Mean Pixel Accuracy: 0.9313867148680814
2023-02-06 10:47:44 | Stage | Epoch[204/600] Train loss:0.0303
2023-02-06 10:47:44 | Stage | Epoch[204/600] Valid loss:0.0329
2023-02-06 10:47:44 | Stage | Epoch[204/600] LR:0.01

2023-02-06 10:47:44 | Train | Epoch[205/600] Iteration[001/030] Train loss: 0.0321
2023-02-06 10:47:44 | Train | Epoch[205/600] Iteration[002/030] Train loss: 0.0319
2023-02-06 10:47:44 | Train | Epoch[205/600] Iteration[003/030] Train loss: 0.0316
2023-02-06 10:47:44 | Train | Epoch[205/600] Iteration[004/030] Train loss: 0.0317
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[005/030] Train loss: 0.0304
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[006/030] Train loss: 0.0304
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[007/030] Train loss: 0.0305
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[008/030] Train loss: 0.0301
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[009/030] Train loss: 0.0298
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[010/030] Train loss: 0.0305
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[011/030] Train loss: 0.0302
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[012/030] Train loss: 0.0303
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[013/030] Train loss: 0.0301
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[014/030] Train loss: 0.0299
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[015/030] Train loss: 0.0302
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[016/030] Train loss: 0.0302
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[017/030] Train loss: 0.0303
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[018/030] Train loss: 0.0303
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[019/030] Train loss: 0.0302
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[020/030] Train loss: 0.0300
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[021/030] Train loss: 0.0301
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[022/030] Train loss: 0.0301
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[023/030] Train loss: 0.0300
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[024/030] Train loss: 0.0301
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[025/030] Train loss: 0.0302
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[026/030] Train loss: 0.0302
2023-02-06 10:47:45 | Train | Epoch[205/600] Iteration[027/030] Train loss: 0.0303
2023-02-06 10:47:46 | Train | Epoch[205/600] Iteration[028/030] Train loss: 0.0300
2023-02-06 10:47:46 | Train | Epoch[205/600] Iteration[029/030] Train loss: 0.0300
2023-02-06 10:47:46 | Train | Epoch[205/600] Iteration[030/030] Train loss: 0.0301
2023-02-06 10:47:46 | Valid | Epoch[205/600] Iteration[001/008] Valid loss: 0.0458
2023-02-06 10:47:46 | Valid | Epoch[205/600] Iteration[002/008] Valid loss: 0.0371
2023-02-06 10:47:46 | Valid | Epoch[205/600] Iteration[003/008] Valid loss: 0.0359
2023-02-06 10:47:46 | Valid | Epoch[205/600] Iteration[004/008] Valid loss: 0.0344
2023-02-06 10:47:46 | Valid | Epoch[205/600] Iteration[005/008] Valid loss: 0.0350
2023-02-06 10:47:46 | Valid | Epoch[205/600] Iteration[006/008] Valid loss: 0.0345
2023-02-06 10:47:46 | Valid | Epoch[205/600] Iteration[007/008] Valid loss: 0.0352
2023-02-06 10:47:46 | Valid | Epoch[205/600] Iteration[008/008] Valid loss: 0.0348
2023-02-06 10:47:46 | Valid | Epoch[205/600] MIou: 0.9283963540234089
2023-02-06 10:47:46 | Valid | Epoch[205/600] Pixel Accuracy: 0.9879722595214844
2023-02-06 10:47:46 | Valid | Epoch[205/600] Mean Pixel Accuracy: 0.943946044011085
2023-02-06 10:47:46 | Stage | Epoch[205/600] Train loss:0.0301
2023-02-06 10:47:46 | Stage | Epoch[205/600] Valid loss:0.0348
2023-02-06 10:47:46 | Stage | Epoch[205/600] LR:0.01

2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[001/030] Train loss: 0.0245
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[002/030] Train loss: 0.0267
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[004/030] Train loss: 0.0276
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[005/030] Train loss: 0.0283
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[006/030] Train loss: 0.0280
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[007/030] Train loss: 0.0281
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[008/030] Train loss: 0.0281
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[009/030] Train loss: 0.0285
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[010/030] Train loss: 0.0289
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[011/030] Train loss: 0.0290
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[012/030] Train loss: 0.0287
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[013/030] Train loss: 0.0288
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[014/030] Train loss: 0.0290
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[015/030] Train loss: 0.0290
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[016/030] Train loss: 0.0290
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[017/030] Train loss: 0.0292
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[018/030] Train loss: 0.0294
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[019/030] Train loss: 0.0295
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[020/030] Train loss: 0.0296
2023-02-06 10:47:47 | Train | Epoch[206/600] Iteration[021/030] Train loss: 0.0295
2023-02-06 10:47:48 | Train | Epoch[206/600] Iteration[022/030] Train loss: 0.0295
2023-02-06 10:47:48 | Train | Epoch[206/600] Iteration[023/030] Train loss: 0.0297
2023-02-06 10:47:48 | Train | Epoch[206/600] Iteration[024/030] Train loss: 0.0297
2023-02-06 10:47:48 | Train | Epoch[206/600] Iteration[025/030] Train loss: 0.0298
2023-02-06 10:47:48 | Train | Epoch[206/600] Iteration[026/030] Train loss: 0.0298
2023-02-06 10:47:48 | Train | Epoch[206/600] Iteration[027/030] Train loss: 0.0297
2023-02-06 10:47:48 | Train | Epoch[206/600] Iteration[028/030] Train loss: 0.0300
2023-02-06 10:47:48 | Train | Epoch[206/600] Iteration[029/030] Train loss: 0.0300
2023-02-06 10:47:48 | Train | Epoch[206/600] Iteration[030/030] Train loss: 0.0301
2023-02-06 10:47:48 | Valid | Epoch[206/600] Iteration[001/008] Valid loss: 0.1574
2023-02-06 10:47:48 | Valid | Epoch[206/600] Iteration[002/008] Valid loss: 0.1196
2023-02-06 10:47:48 | Valid | Epoch[206/600] Iteration[003/008] Valid loss: 0.1067
2023-02-06 10:47:48 | Valid | Epoch[206/600] Iteration[004/008] Valid loss: 0.1025
2023-02-06 10:47:48 | Valid | Epoch[206/600] Iteration[005/008] Valid loss: 0.1009
2023-02-06 10:47:48 | Valid | Epoch[206/600] Iteration[006/008] Valid loss: 0.1001
2023-02-06 10:47:48 | Valid | Epoch[206/600] Iteration[007/008] Valid loss: 0.1068
2023-02-06 10:47:48 | Valid | Epoch[206/600] Iteration[008/008] Valid loss: 0.1065
2023-02-06 10:47:48 | Valid | Epoch[206/600] MIou: 0.9155064505138416
2023-02-06 10:47:48 | Valid | Epoch[206/600] Pixel Accuracy: 0.9844385782877604
2023-02-06 10:47:48 | Valid | Epoch[206/600] Mean Pixel Accuracy: 0.9741689940779514
2023-02-06 10:47:48 | Stage | Epoch[206/600] Train loss:0.0301
2023-02-06 10:47:48 | Stage | Epoch[206/600] Valid loss:0.1065
2023-02-06 10:47:48 | Stage | Epoch[206/600] LR:0.01

2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[001/030] Train loss: 0.0331
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[002/030] Train loss: 0.0303
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[003/030] Train loss: 0.0301
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[004/030] Train loss: 0.0306
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[005/030] Train loss: 0.0308
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[006/030] Train loss: 0.0309
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[007/030] Train loss: 0.0310
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[008/030] Train loss: 0.0303
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[009/030] Train loss: 0.0302
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[010/030] Train loss: 0.0307
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[011/030] Train loss: 0.0305
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[012/030] Train loss: 0.0299
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[013/030] Train loss: 0.0296
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[014/030] Train loss: 0.0295
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[015/030] Train loss: 0.0299
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[016/030] Train loss: 0.0300
2023-02-06 10:47:49 | Train | Epoch[207/600] Iteration[017/030] Train loss: 0.0300
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[018/030] Train loss: 0.0299
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[019/030] Train loss: 0.0301
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[020/030] Train loss: 0.0302
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[021/030] Train loss: 0.0303
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[022/030] Train loss: 0.0303
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[023/030] Train loss: 0.0302
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[024/030] Train loss: 0.0301
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[025/030] Train loss: 0.0303
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[026/030] Train loss: 0.0301
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[027/030] Train loss: 0.0300
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[028/030] Train loss: 0.0301
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[029/030] Train loss: 0.0299
2023-02-06 10:47:50 | Train | Epoch[207/600] Iteration[030/030] Train loss: 0.0298
2023-02-06 10:47:50 | Valid | Epoch[207/600] Iteration[001/008] Valid loss: 0.0464
2023-02-06 10:47:50 | Valid | Epoch[207/600] Iteration[002/008] Valid loss: 0.0424
2023-02-06 10:47:50 | Valid | Epoch[207/600] Iteration[003/008] Valid loss: 0.0421
2023-02-06 10:47:50 | Valid | Epoch[207/600] Iteration[004/008] Valid loss: 0.0407
2023-02-06 10:47:50 | Valid | Epoch[207/600] Iteration[005/008] Valid loss: 0.0409
2023-02-06 10:47:50 | Valid | Epoch[207/600] Iteration[006/008] Valid loss: 0.0400
2023-02-06 10:47:51 | Valid | Epoch[207/600] Iteration[007/008] Valid loss: 0.0393
2023-02-06 10:47:51 | Valid | Epoch[207/600] Iteration[008/008] Valid loss: 0.0396
2023-02-06 10:47:51 | Valid | Epoch[207/600] MIou: 0.88689664038398
2023-02-06 10:47:51 | Valid | Epoch[207/600] Pixel Accuracy: 0.9812634785970052
2023-02-06 10:47:51 | Valid | Epoch[207/600] Mean Pixel Accuracy: 0.899419634883099
2023-02-06 10:47:51 | Stage | Epoch[207/600] Train loss:0.0298
2023-02-06 10:47:51 | Stage | Epoch[207/600] Valid loss:0.0396
2023-02-06 10:47:51 | Stage | Epoch[207/600] LR:0.01

2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[001/030] Train loss: 0.0293
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[002/030] Train loss: 0.0301
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[003/030] Train loss: 0.0295
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[004/030] Train loss: 0.0299
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[005/030] Train loss: 0.0297
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[006/030] Train loss: 0.0298
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[007/030] Train loss: 0.0300
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[008/030] Train loss: 0.0299
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[009/030] Train loss: 0.0298
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[010/030] Train loss: 0.0294
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[011/030] Train loss: 0.0297
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[012/030] Train loss: 0.0295
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[013/030] Train loss: 0.0293
2023-02-06 10:47:51 | Train | Epoch[208/600] Iteration[014/030] Train loss: 0.0296
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[015/030] Train loss: 0.0297
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[016/030] Train loss: 0.0295
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[017/030] Train loss: 0.0295
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[018/030] Train loss: 0.0294
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[019/030] Train loss: 0.0295
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[020/030] Train loss: 0.0295
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[021/030] Train loss: 0.0296
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[022/030] Train loss: 0.0296
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[023/030] Train loss: 0.0295
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[024/030] Train loss: 0.0293
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[025/030] Train loss: 0.0294
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[026/030] Train loss: 0.0293
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[027/030] Train loss: 0.0294
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[028/030] Train loss: 0.0295
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[029/030] Train loss: 0.0296
2023-02-06 10:47:52 | Train | Epoch[208/600] Iteration[030/030] Train loss: 0.0295
2023-02-06 10:47:52 | Valid | Epoch[208/600] Iteration[001/008] Valid loss: 0.2992
2023-02-06 10:47:53 | Valid | Epoch[208/600] Iteration[002/008] Valid loss: 0.2407
2023-02-06 10:47:53 | Valid | Epoch[208/600] Iteration[003/008] Valid loss: 0.2286
2023-02-06 10:47:53 | Valid | Epoch[208/600] Iteration[004/008] Valid loss: 0.2241
2023-02-06 10:47:53 | Valid | Epoch[208/600] Iteration[005/008] Valid loss: 0.2324
2023-02-06 10:47:53 | Valid | Epoch[208/600] Iteration[006/008] Valid loss: 0.2276
2023-02-06 10:47:53 | Valid | Epoch[208/600] Iteration[007/008] Valid loss: 0.2451
2023-02-06 10:47:53 | Valid | Epoch[208/600] Iteration[008/008] Valid loss: 0.2468
2023-02-06 10:47:53 | Valid | Epoch[208/600] MIou: 0.8918216846790354
2023-02-06 10:47:53 | Valid | Epoch[208/600] Pixel Accuracy: 0.9788080851236979
2023-02-06 10:47:53 | Valid | Epoch[208/600] Mean Pixel Accuracy: 0.9795387643688838
2023-02-06 10:47:53 | Stage | Epoch[208/600] Train loss:0.0295
2023-02-06 10:47:53 | Stage | Epoch[208/600] Valid loss:0.2468
2023-02-06 10:47:53 | Stage | Epoch[208/600] LR:0.01

2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[001/030] Train loss: 0.0301
2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[002/030] Train loss: 0.0316
2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[003/030] Train loss: 0.0302
2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[004/030] Train loss: 0.0311
2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[005/030] Train loss: 0.0315
2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[006/030] Train loss: 0.0311
2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[007/030] Train loss: 0.0309
2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[008/030] Train loss: 0.0310
2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[009/030] Train loss: 0.0309
2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[010/030] Train loss: 0.0307
2023-02-06 10:47:53 | Train | Epoch[209/600] Iteration[011/030] Train loss: 0.0307
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[012/030] Train loss: 0.0301
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[013/030] Train loss: 0.0301
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[014/030] Train loss: 0.0299
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[015/030] Train loss: 0.0299
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[016/030] Train loss: 0.0299
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[017/030] Train loss: 0.0298
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[018/030] Train loss: 0.0298
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[019/030] Train loss: 0.0300
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[020/030] Train loss: 0.0301
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[021/030] Train loss: 0.0298
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[022/030] Train loss: 0.0299
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[023/030] Train loss: 0.0299
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[024/030] Train loss: 0.0298
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[025/030] Train loss: 0.0296
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[026/030] Train loss: 0.0298
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[027/030] Train loss: 0.0300
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[028/030] Train loss: 0.0299
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[029/030] Train loss: 0.0299
2023-02-06 10:47:54 | Train | Epoch[209/600] Iteration[030/030] Train loss: 0.0300
2023-02-06 10:47:55 | Valid | Epoch[209/600] Iteration[001/008] Valid loss: 0.0586
2023-02-06 10:47:55 | Valid | Epoch[209/600] Iteration[002/008] Valid loss: 0.0572
2023-02-06 10:47:55 | Valid | Epoch[209/600] Iteration[003/008] Valid loss: 0.0592
2023-02-06 10:47:55 | Valid | Epoch[209/600] Iteration[004/008] Valid loss: 0.0584
2023-02-06 10:47:55 | Valid | Epoch[209/600] Iteration[005/008] Valid loss: 0.0591
2023-02-06 10:47:55 | Valid | Epoch[209/600] Iteration[006/008] Valid loss: 0.0580
2023-02-06 10:47:55 | Valid | Epoch[209/600] Iteration[007/008] Valid loss: 0.0566
2023-02-06 10:47:55 | Valid | Epoch[209/600] Iteration[008/008] Valid loss: 0.0577
2023-02-06 10:47:55 | Valid | Epoch[209/600] MIou: 0.8073866784179682
2023-02-06 10:47:55 | Valid | Epoch[209/600] Pixel Accuracy: 0.9682528177897135
2023-02-06 10:47:55 | Valid | Epoch[209/600] Mean Pixel Accuracy: 0.8242478424305566
2023-02-06 10:47:55 | Stage | Epoch[209/600] Train loss:0.0300
2023-02-06 10:47:55 | Stage | Epoch[209/600] Valid loss:0.0577
2023-02-06 10:47:55 | Stage | Epoch[209/600] LR:0.01

2023-02-06 10:47:55 | Train | Epoch[210/600] Iteration[001/030] Train loss: 0.0341
2023-02-06 10:47:55 | Train | Epoch[210/600] Iteration[002/030] Train loss: 0.0317
2023-02-06 10:47:55 | Train | Epoch[210/600] Iteration[003/030] Train loss: 0.0286
2023-02-06 10:47:55 | Train | Epoch[210/600] Iteration[004/030] Train loss: 0.0281
2023-02-06 10:47:55 | Train | Epoch[210/600] Iteration[005/030] Train loss: 0.0276
2023-02-06 10:47:55 | Train | Epoch[210/600] Iteration[006/030] Train loss: 0.0282
2023-02-06 10:47:55 | Train | Epoch[210/600] Iteration[007/030] Train loss: 0.0280
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[008/030] Train loss: 0.0281
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[009/030] Train loss: 0.0285
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[011/030] Train loss: 0.0288
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[012/030] Train loss: 0.0286
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[013/030] Train loss: 0.0285
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[014/030] Train loss: 0.0285
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[015/030] Train loss: 0.0287
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[016/030] Train loss: 0.0286
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[017/030] Train loss: 0.0288
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[018/030] Train loss: 0.0288
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[019/030] Train loss: 0.0290
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[020/030] Train loss: 0.0289
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[021/030] Train loss: 0.0293
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[022/030] Train loss: 0.0291
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[023/030] Train loss: 0.0293
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[024/030] Train loss: 0.0294
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[025/030] Train loss: 0.0295
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[026/030] Train loss: 0.0294
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[027/030] Train loss: 0.0295
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[028/030] Train loss: 0.0294
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[029/030] Train loss: 0.0294
2023-02-06 10:47:56 | Train | Epoch[210/600] Iteration[030/030] Train loss: 0.0294
2023-02-06 10:47:57 | Valid | Epoch[210/600] Iteration[001/008] Valid loss: 0.0935
2023-02-06 10:47:57 | Valid | Epoch[210/600] Iteration[002/008] Valid loss: 0.0945
2023-02-06 10:47:57 | Valid | Epoch[210/600] Iteration[003/008] Valid loss: 0.0983
2023-02-06 10:47:57 | Valid | Epoch[210/600] Iteration[004/008] Valid loss: 0.0981
2023-02-06 10:47:57 | Valid | Epoch[210/600] Iteration[005/008] Valid loss: 0.0998
2023-02-06 10:47:57 | Valid | Epoch[210/600] Iteration[006/008] Valid loss: 0.0982
2023-02-06 10:47:57 | Valid | Epoch[210/600] Iteration[007/008] Valid loss: 0.0960
2023-02-06 10:47:57 | Valid | Epoch[210/600] Iteration[008/008] Valid loss: 0.0988
2023-02-06 10:47:57 | Valid | Epoch[210/600] MIou: 0.6657630792888782
2023-02-06 10:47:57 | Valid | Epoch[210/600] Pixel Accuracy: 0.9447924296061198
2023-02-06 10:47:57 | Valid | Epoch[210/600] Mean Pixel Accuracy: 0.6943713131256247
2023-02-06 10:47:57 | Stage | Epoch[210/600] Train loss:0.0294
2023-02-06 10:47:57 | Stage | Epoch[210/600] Valid loss:0.0988
2023-02-06 10:47:57 | Stage | Epoch[210/600] LR:0.01

2023-02-06 10:47:57 | Train | Epoch[211/600] Iteration[001/030] Train loss: 0.0285
2023-02-06 10:47:57 | Train | Epoch[211/600] Iteration[002/030] Train loss: 0.0277
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[003/030] Train loss: 0.0286
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[004/030] Train loss: 0.0290
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[005/030] Train loss: 0.0290
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[006/030] Train loss: 0.0282
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[007/030] Train loss: 0.0276
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[008/030] Train loss: 0.0280
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[009/030] Train loss: 0.0286
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[010/030] Train loss: 0.0284
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[011/030] Train loss: 0.0284
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[012/030] Train loss: 0.0282
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[013/030] Train loss: 0.0283
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[014/030] Train loss: 0.0283
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[015/030] Train loss: 0.0282
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[016/030] Train loss: 0.0283
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[017/030] Train loss: 0.0285
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[018/030] Train loss: 0.0288
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[019/030] Train loss: 0.0288
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[020/030] Train loss: 0.0288
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[021/030] Train loss: 0.0289
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[022/030] Train loss: 0.0290
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[023/030] Train loss: 0.0293
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[024/030] Train loss: 0.0295
2023-02-06 10:47:58 | Train | Epoch[211/600] Iteration[025/030] Train loss: 0.0295
2023-02-06 10:47:59 | Train | Epoch[211/600] Iteration[026/030] Train loss: 0.0297
2023-02-06 10:47:59 | Train | Epoch[211/600] Iteration[027/030] Train loss: 0.0296
2023-02-06 10:47:59 | Train | Epoch[211/600] Iteration[028/030] Train loss: 0.0299
2023-02-06 10:47:59 | Train | Epoch[211/600] Iteration[029/030] Train loss: 0.0300
2023-02-06 10:47:59 | Train | Epoch[211/600] Iteration[030/030] Train loss: 0.0300
2023-02-06 10:47:59 | Valid | Epoch[211/600] Iteration[001/008] Valid loss: 0.1755
2023-02-06 10:47:59 | Valid | Epoch[211/600] Iteration[002/008] Valid loss: 0.1307
2023-02-06 10:47:59 | Valid | Epoch[211/600] Iteration[003/008] Valid loss: 0.1239
2023-02-06 10:47:59 | Valid | Epoch[211/600] Iteration[004/008] Valid loss: 0.1214
2023-02-06 10:47:59 | Valid | Epoch[211/600] Iteration[005/008] Valid loss: 0.1267
2023-02-06 10:47:59 | Valid | Epoch[211/600] Iteration[006/008] Valid loss: 0.1243
2023-02-06 10:47:59 | Valid | Epoch[211/600] Iteration[007/008] Valid loss: 0.1366
2023-02-06 10:47:59 | Valid | Epoch[211/600] Iteration[008/008] Valid loss: 0.1339
2023-02-06 10:47:59 | Valid | Epoch[211/600] MIou: 0.9138135079664602
2023-02-06 10:47:59 | Valid | Epoch[211/600] Pixel Accuracy: 0.9839146931966146
2023-02-06 10:47:59 | Valid | Epoch[211/600] Mean Pixel Accuracy: 0.9789344002838266
2023-02-06 10:47:59 | Stage | Epoch[211/600] Train loss:0.0300
2023-02-06 10:47:59 | Stage | Epoch[211/600] Valid loss:0.1339
2023-02-06 10:47:59 | Stage | Epoch[211/600] LR:0.01

2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[002/030] Train loss: 0.0303
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[003/030] Train loss: 0.0292
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[004/030] Train loss: 0.0299
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[005/030] Train loss: 0.0295
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[006/030] Train loss: 0.0307
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[007/030] Train loss: 0.0306
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[008/030] Train loss: 0.0305
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[009/030] Train loss: 0.0307
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[010/030] Train loss: 0.0305
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[011/030] Train loss: 0.0306
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[012/030] Train loss: 0.0308
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[013/030] Train loss: 0.0306
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[014/030] Train loss: 0.0306
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[015/030] Train loss: 0.0307
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[016/030] Train loss: 0.0302
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[017/030] Train loss: 0.0299
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[018/030] Train loss: 0.0299
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[019/030] Train loss: 0.0298
2023-02-06 10:48:00 | Train | Epoch[212/600] Iteration[020/030] Train loss: 0.0299
2023-02-06 10:48:01 | Train | Epoch[212/600] Iteration[021/030] Train loss: 0.0299
2023-02-06 10:48:01 | Train | Epoch[212/600] Iteration[022/030] Train loss: 0.0297
2023-02-06 10:48:01 | Train | Epoch[212/600] Iteration[023/030] Train loss: 0.0296
2023-02-06 10:48:01 | Train | Epoch[212/600] Iteration[024/030] Train loss: 0.0296
2023-02-06 10:48:01 | Train | Epoch[212/600] Iteration[025/030] Train loss: 0.0297
2023-02-06 10:48:01 | Train | Epoch[212/600] Iteration[026/030] Train loss: 0.0299
2023-02-06 10:48:01 | Train | Epoch[212/600] Iteration[027/030] Train loss: 0.0299
2023-02-06 10:48:01 | Train | Epoch[212/600] Iteration[028/030] Train loss: 0.0297
2023-02-06 10:48:01 | Train | Epoch[212/600] Iteration[029/030] Train loss: 0.0297
2023-02-06 10:48:01 | Train | Epoch[212/600] Iteration[030/030] Train loss: 0.0296
2023-02-06 10:48:01 | Valid | Epoch[212/600] Iteration[001/008] Valid loss: 0.0583
2023-02-06 10:48:01 | Valid | Epoch[212/600] Iteration[002/008] Valid loss: 0.0572
2023-02-06 10:48:01 | Valid | Epoch[212/600] Iteration[003/008] Valid loss: 0.0591
2023-02-06 10:48:01 | Valid | Epoch[212/600] Iteration[004/008] Valid loss: 0.0583
2023-02-06 10:48:01 | Valid | Epoch[212/600] Iteration[005/008] Valid loss: 0.0590
2023-02-06 10:48:01 | Valid | Epoch[212/600] Iteration[006/008] Valid loss: 0.0581
2023-02-06 10:48:01 | Valid | Epoch[212/600] Iteration[007/008] Valid loss: 0.0567
2023-02-06 10:48:01 | Valid | Epoch[212/600] Iteration[008/008] Valid loss: 0.0577
2023-02-06 10:48:02 | Valid | Epoch[212/600] MIou: 0.8098404977487984
2023-02-06 10:48:02 | Valid | Epoch[212/600] Pixel Accuracy: 0.968658447265625
2023-02-06 10:48:02 | Valid | Epoch[212/600] Mean Pixel Accuracy: 0.8264934041025497
2023-02-06 10:48:02 | Stage | Epoch[212/600] Train loss:0.0296
2023-02-06 10:48:02 | Stage | Epoch[212/600] Valid loss:0.0577
2023-02-06 10:48:02 | Stage | Epoch[212/600] LR:0.01

2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[001/030] Train loss: 0.0277
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[002/030] Train loss: 0.0300
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[003/030] Train loss: 0.0302
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[004/030] Train loss: 0.0302
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[005/030] Train loss: 0.0293
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[006/030] Train loss: 0.0285
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[007/030] Train loss: 0.0287
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[008/030] Train loss: 0.0292
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[009/030] Train loss: 0.0290
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[011/030] Train loss: 0.0291
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[012/030] Train loss: 0.0293
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[013/030] Train loss: 0.0296
2023-02-06 10:48:02 | Train | Epoch[213/600] Iteration[014/030] Train loss: 0.0297
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[015/030] Train loss: 0.0299
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[016/030] Train loss: 0.0297
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[017/030] Train loss: 0.0298
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[018/030] Train loss: 0.0299
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[019/030] Train loss: 0.0298
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[020/030] Train loss: 0.0299
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[021/030] Train loss: 0.0299
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[022/030] Train loss: 0.0297
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[023/030] Train loss: 0.0298
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[024/030] Train loss: 0.0297
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[025/030] Train loss: 0.0296
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[026/030] Train loss: 0.0295
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[027/030] Train loss: 0.0297
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[028/030] Train loss: 0.0296
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[029/030] Train loss: 0.0293
2023-02-06 10:48:03 | Train | Epoch[213/600] Iteration[030/030] Train loss: 0.0294
2023-02-06 10:48:03 | Valid | Epoch[213/600] Iteration[001/008] Valid loss: 0.0546
2023-02-06 10:48:04 | Valid | Epoch[213/600] Iteration[002/008] Valid loss: 0.0529
2023-02-06 10:48:04 | Valid | Epoch[213/600] Iteration[003/008] Valid loss: 0.0544
2023-02-06 10:48:04 | Valid | Epoch[213/600] Iteration[004/008] Valid loss: 0.0536
2023-02-06 10:48:04 | Valid | Epoch[213/600] Iteration[005/008] Valid loss: 0.0542
2023-02-06 10:48:04 | Valid | Epoch[213/600] Iteration[006/008] Valid loss: 0.0535
2023-02-06 10:48:04 | Valid | Epoch[213/600] Iteration[007/008] Valid loss: 0.0524
2023-02-06 10:48:04 | Valid | Epoch[213/600] Iteration[008/008] Valid loss: 0.0530
2023-02-06 10:48:04 | Valid | Epoch[213/600] MIou: 0.8286526755852721
2023-02-06 10:48:04 | Valid | Epoch[213/600] Pixel Accuracy: 0.9717636108398438
2023-02-06 10:48:04 | Valid | Epoch[213/600] Mean Pixel Accuracy: 0.8437469705825834
2023-02-06 10:48:04 | Stage | Epoch[213/600] Train loss:0.0294
2023-02-06 10:48:04 | Stage | Epoch[213/600] Valid loss:0.0530
2023-02-06 10:48:04 | Stage | Epoch[213/600] LR:0.01

2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[001/030] Train loss: 0.0264
2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[002/030] Train loss: 0.0282
2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[003/030] Train loss: 0.0275
2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[004/030] Train loss: 0.0280
2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[005/030] Train loss: 0.0286
2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[006/030] Train loss: 0.0291
2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[007/030] Train loss: 0.0292
2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[008/030] Train loss: 0.0298
2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[009/030] Train loss: 0.0295
2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[010/030] Train loss: 0.0288
2023-02-06 10:48:04 | Train | Epoch[214/600] Iteration[011/030] Train loss: 0.0290
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[012/030] Train loss: 0.0291
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[013/030] Train loss: 0.0292
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[014/030] Train loss: 0.0293
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[015/030] Train loss: 0.0298
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[016/030] Train loss: 0.0300
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[017/030] Train loss: 0.0298
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[018/030] Train loss: 0.0297
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[019/030] Train loss: 0.0296
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[020/030] Train loss: 0.0295
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[021/030] Train loss: 0.0293
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[022/030] Train loss: 0.0293
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[023/030] Train loss: 0.0293
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[024/030] Train loss: 0.0293
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[025/030] Train loss: 0.0293
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[026/030] Train loss: 0.0291
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[027/030] Train loss: 0.0292
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[028/030] Train loss: 0.0294
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[029/030] Train loss: 0.0295
2023-02-06 10:48:05 | Train | Epoch[214/600] Iteration[030/030] Train loss: 0.0294
2023-02-06 10:48:06 | Valid | Epoch[214/600] Iteration[001/008] Valid loss: 0.0567
2023-02-06 10:48:06 | Valid | Epoch[214/600] Iteration[002/008] Valid loss: 0.0551
2023-02-06 10:48:06 | Valid | Epoch[214/600] Iteration[003/008] Valid loss: 0.0561
2023-02-06 10:48:06 | Valid | Epoch[214/600] Iteration[004/008] Valid loss: 0.0555
2023-02-06 10:48:06 | Valid | Epoch[214/600] Iteration[005/008] Valid loss: 0.0557
2023-02-06 10:48:06 | Valid | Epoch[214/600] Iteration[006/008] Valid loss: 0.0549
2023-02-06 10:48:06 | Valid | Epoch[214/600] Iteration[007/008] Valid loss: 0.0533
2023-02-06 10:48:06 | Valid | Epoch[214/600] Iteration[008/008] Valid loss: 0.0545
2023-02-06 10:48:06 | Valid | Epoch[214/600] MIou: 0.8176057257883363
2023-02-06 10:48:06 | Valid | Epoch[214/600] Pixel Accuracy: 0.96990966796875
2023-02-06 10:48:06 | Valid | Epoch[214/600] Mean Pixel Accuracy: 0.8339527519391607
2023-02-06 10:48:06 | Stage | Epoch[214/600] Train loss:0.0294
2023-02-06 10:48:06 | Stage | Epoch[214/600] Valid loss:0.0545
2023-02-06 10:48:06 | Stage | Epoch[214/600] LR:0.01

2023-02-06 10:48:06 | Train | Epoch[215/600] Iteration[001/030] Train loss: 0.0276
2023-02-06 10:48:06 | Train | Epoch[215/600] Iteration[002/030] Train loss: 0.0289
2023-02-06 10:48:06 | Train | Epoch[215/600] Iteration[003/030] Train loss: 0.0290
2023-02-06 10:48:06 | Train | Epoch[215/600] Iteration[004/030] Train loss: 0.0292
2023-02-06 10:48:06 | Train | Epoch[215/600] Iteration[005/030] Train loss: 0.0291
2023-02-06 10:48:06 | Train | Epoch[215/600] Iteration[006/030] Train loss: 0.0294
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[007/030] Train loss: 0.0297
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[008/030] Train loss: 0.0291
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[009/030] Train loss: 0.0290
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[010/030] Train loss: 0.0292
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[011/030] Train loss: 0.0294
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[012/030] Train loss: 0.0294
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[013/030] Train loss: 0.0291
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[014/030] Train loss: 0.0290
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[015/030] Train loss: 0.0288
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[016/030] Train loss: 0.0287
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[017/030] Train loss: 0.0286
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[018/030] Train loss: 0.0286
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[019/030] Train loss: 0.0288
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[020/030] Train loss: 0.0287
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[021/030] Train loss: 0.0287
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[022/030] Train loss: 0.0286
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[023/030] Train loss: 0.0286
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[024/030] Train loss: 0.0287
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[025/030] Train loss: 0.0287
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[026/030] Train loss: 0.0290
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[027/030] Train loss: 0.0290
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[028/030] Train loss: 0.0289
2023-02-06 10:48:07 | Train | Epoch[215/600] Iteration[029/030] Train loss: 0.0290
2023-02-06 10:48:08 | Train | Epoch[215/600] Iteration[030/030] Train loss: 0.0290
2023-02-06 10:48:08 | Valid | Epoch[215/600] Iteration[001/008] Valid loss: 0.0426
2023-02-06 10:48:08 | Valid | Epoch[215/600] Iteration[002/008] Valid loss: 0.0368
2023-02-06 10:48:08 | Valid | Epoch[215/600] Iteration[003/008] Valid loss: 0.0366
2023-02-06 10:48:08 | Valid | Epoch[215/600] Iteration[004/008] Valid loss: 0.0351
2023-02-06 10:48:08 | Valid | Epoch[215/600] Iteration[005/008] Valid loss: 0.0354
2023-02-06 10:48:08 | Valid | Epoch[215/600] Iteration[006/008] Valid loss: 0.0350
2023-02-06 10:48:08 | Valid | Epoch[215/600] Iteration[007/008] Valid loss: 0.0348
2023-02-06 10:48:08 | Valid | Epoch[215/600] Iteration[008/008] Valid loss: 0.0348
2023-02-06 10:48:08 | Valid | Epoch[215/600] MIou: 0.9046377561203931
2023-02-06 10:48:08 | Valid | Epoch[215/600] Pixel Accuracy: 0.9842135111490885
2023-02-06 10:48:08 | Valid | Epoch[215/600] Mean Pixel Accuracy: 0.9155417569376958
2023-02-06 10:48:08 | Stage | Epoch[215/600] Train loss:0.0290
2023-02-06 10:48:08 | Stage | Epoch[215/600] Valid loss:0.0348
2023-02-06 10:48:08 | Stage | Epoch[215/600] LR:0.01

2023-02-06 10:48:08 | Train | Epoch[216/600] Iteration[001/030] Train loss: 0.0280
2023-02-06 10:48:08 | Train | Epoch[216/600] Iteration[002/030] Train loss: 0.0268
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[003/030] Train loss: 0.0281
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[004/030] Train loss: 0.0285
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[005/030] Train loss: 0.0283
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[006/030] Train loss: 0.0283
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[007/030] Train loss: 0.0283
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[008/030] Train loss: 0.0280
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[009/030] Train loss: 0.0285
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[010/030] Train loss: 0.0285
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[011/030] Train loss: 0.0287
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[012/030] Train loss: 0.0287
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[013/030] Train loss: 0.0286
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[014/030] Train loss: 0.0285
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[015/030] Train loss: 0.0284
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[016/030] Train loss: 0.0282
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[017/030] Train loss: 0.0282
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[018/030] Train loss: 0.0282
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[019/030] Train loss: 0.0281
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[020/030] Train loss: 0.0282
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[021/030] Train loss: 0.0281
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[022/030] Train loss: 0.0282
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[023/030] Train loss: 0.0286
2023-02-06 10:48:09 | Train | Epoch[216/600] Iteration[024/030] Train loss: 0.0286
2023-02-06 10:48:10 | Train | Epoch[216/600] Iteration[025/030] Train loss: 0.0285
2023-02-06 10:48:10 | Train | Epoch[216/600] Iteration[026/030] Train loss: 0.0287
2023-02-06 10:48:10 | Train | Epoch[216/600] Iteration[027/030] Train loss: 0.0287
2023-02-06 10:48:10 | Train | Epoch[216/600] Iteration[028/030] Train loss: 0.0289
2023-02-06 10:48:10 | Train | Epoch[216/600] Iteration[029/030] Train loss: 0.0290
2023-02-06 10:48:10 | Train | Epoch[216/600] Iteration[030/030] Train loss: 0.0290
2023-02-06 10:48:10 | Valid | Epoch[216/600] Iteration[001/008] Valid loss: 0.0491
2023-02-06 10:48:10 | Valid | Epoch[216/600] Iteration[002/008] Valid loss: 0.0474
2023-02-06 10:48:10 | Valid | Epoch[216/600] Iteration[003/008] Valid loss: 0.0488
2023-02-06 10:48:10 | Valid | Epoch[216/600] Iteration[004/008] Valid loss: 0.0478
2023-02-06 10:48:10 | Valid | Epoch[216/600] Iteration[005/008] Valid loss: 0.0482
2023-02-06 10:48:10 | Valid | Epoch[216/600] Iteration[006/008] Valid loss: 0.0474
2023-02-06 10:48:10 | Valid | Epoch[216/600] Iteration[007/008] Valid loss: 0.0462
2023-02-06 10:48:10 | Valid | Epoch[216/600] Iteration[008/008] Valid loss: 0.0470
2023-02-06 10:48:10 | Valid | Epoch[216/600] MIou: 0.8424427152576586
2023-02-06 10:48:10 | Valid | Epoch[216/600] Pixel Accuracy: 0.9740333557128906
2023-02-06 10:48:10 | Valid | Epoch[216/600] Mean Pixel Accuracy: 0.856470772603952
2023-02-06 10:48:10 | Stage | Epoch[216/600] Train loss:0.0290
2023-02-06 10:48:10 | Stage | Epoch[216/600] Valid loss:0.0470
2023-02-06 10:48:10 | Stage | Epoch[216/600] LR:0.01

2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[001/030] Train loss: 0.0262
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[002/030] Train loss: 0.0272
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[003/030] Train loss: 0.0304
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[004/030] Train loss: 0.0298
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[005/030] Train loss: 0.0296
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[006/030] Train loss: 0.0290
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[007/030] Train loss: 0.0286
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[008/030] Train loss: 0.0290
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[009/030] Train loss: 0.0302
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[010/030] Train loss: 0.0310
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[011/030] Train loss: 0.0312
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[012/030] Train loss: 0.0308
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[013/030] Train loss: 0.0308
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[014/030] Train loss: 0.0306
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[015/030] Train loss: 0.0304
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[016/030] Train loss: 0.0305
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[017/030] Train loss: 0.0303
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[018/030] Train loss: 0.0300
2023-02-06 10:48:11 | Train | Epoch[217/600] Iteration[019/030] Train loss: 0.0300
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[020/030] Train loss: 0.0300
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[021/030] Train loss: 0.0299
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[022/030] Train loss: 0.0300
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[023/030] Train loss: 0.0299
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[024/030] Train loss: 0.0297
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[025/030] Train loss: 0.0297
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[026/030] Train loss: 0.0298
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[027/030] Train loss: 0.0299
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[028/030] Train loss: 0.0299
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[029/030] Train loss: 0.0298
2023-02-06 10:48:12 | Train | Epoch[217/600] Iteration[030/030] Train loss: 0.0297
2023-02-06 10:48:12 | Valid | Epoch[217/600] Iteration[001/008] Valid loss: 0.0439
2023-02-06 10:48:12 | Valid | Epoch[217/600] Iteration[002/008] Valid loss: 0.0420
2023-02-06 10:48:12 | Valid | Epoch[217/600] Iteration[003/008] Valid loss: 0.0427
2023-02-06 10:48:12 | Valid | Epoch[217/600] Iteration[004/008] Valid loss: 0.0420
2023-02-06 10:48:12 | Valid | Epoch[217/600] Iteration[005/008] Valid loss: 0.0424
2023-02-06 10:48:12 | Valid | Epoch[217/600] Iteration[006/008] Valid loss: 0.0420
2023-02-06 10:48:12 | Valid | Epoch[217/600] Iteration[007/008] Valid loss: 0.0412
2023-02-06 10:48:12 | Valid | Epoch[217/600] Iteration[008/008] Valid loss: 0.0419
2023-02-06 10:48:13 | Valid | Epoch[217/600] MIou: 0.8534236137245717
2023-02-06 10:48:13 | Valid | Epoch[217/600] Pixel Accuracy: 0.9758466084798177
2023-02-06 10:48:13 | Valid | Epoch[217/600] Mean Pixel Accuracy: 0.8665216069772652
2023-02-06 10:48:13 | Stage | Epoch[217/600] Train loss:0.0297
2023-02-06 10:48:13 | Stage | Epoch[217/600] Valid loss:0.0419
2023-02-06 10:48:13 | Stage | Epoch[217/600] LR:0.01

2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[001/030] Train loss: 0.0248
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[002/030] Train loss: 0.0267
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[003/030] Train loss: 0.0298
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[004/030] Train loss: 0.0303
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[005/030] Train loss: 0.0301
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[006/030] Train loss: 0.0296
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[007/030] Train loss: 0.0291
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[008/030] Train loss: 0.0292
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[009/030] Train loss: 0.0291
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[011/030] Train loss: 0.0288
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[012/030] Train loss: 0.0287
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[013/030] Train loss: 0.0285
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[014/030] Train loss: 0.0283
2023-02-06 10:48:13 | Train | Epoch[218/600] Iteration[015/030] Train loss: 0.0282
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[016/030] Train loss: 0.0284
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[017/030] Train loss: 0.0285
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[018/030] Train loss: 0.0286
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[019/030] Train loss: 0.0288
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[020/030] Train loss: 0.0286
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[021/030] Train loss: 0.0286
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[022/030] Train loss: 0.0287
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[023/030] Train loss: 0.0286
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[024/030] Train loss: 0.0287
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[025/030] Train loss: 0.0289
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[026/030] Train loss: 0.0292
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[027/030] Train loss: 0.0295
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[028/030] Train loss: 0.0293
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[029/030] Train loss: 0.0294
2023-02-06 10:48:14 | Train | Epoch[218/600] Iteration[030/030] Train loss: 0.0293
2023-02-06 10:48:15 | Valid | Epoch[218/600] Iteration[001/008] Valid loss: 0.1443
2023-02-06 10:48:15 | Valid | Epoch[218/600] Iteration[002/008] Valid loss: 0.0984
2023-02-06 10:48:15 | Valid | Epoch[218/600] Iteration[003/008] Valid loss: 0.0914
2023-02-06 10:48:15 | Valid | Epoch[218/600] Iteration[004/008] Valid loss: 0.0870
2023-02-06 10:48:15 | Valid | Epoch[218/600] Iteration[005/008] Valid loss: 0.0878
2023-02-06 10:48:15 | Valid | Epoch[218/600] Iteration[006/008] Valid loss: 0.0842
2023-02-06 10:48:15 | Valid | Epoch[218/600] Iteration[007/008] Valid loss: 0.0925
2023-02-06 10:48:15 | Valid | Epoch[218/600] Iteration[008/008] Valid loss: 0.0909
2023-02-06 10:48:15 | Valid | Epoch[218/600] MIou: 0.9290657987612609
2023-02-06 10:48:15 | Valid | Epoch[218/600] Pixel Accuracy: 0.9873212178548177
2023-02-06 10:48:15 | Valid | Epoch[218/600] Mean Pixel Accuracy: 0.9734011007946286
2023-02-06 10:48:15 | Stage | Epoch[218/600] Train loss:0.0293
2023-02-06 10:48:15 | Stage | Epoch[218/600] Valid loss:0.0909
2023-02-06 10:48:15 | Stage | Epoch[218/600] LR:0.01

2023-02-06 10:48:15 | Train | Epoch[219/600] Iteration[001/030] Train loss: 0.0279
2023-02-06 10:48:15 | Train | Epoch[219/600] Iteration[002/030] Train loss: 0.0308
2023-02-06 10:48:15 | Train | Epoch[219/600] Iteration[003/030] Train loss: 0.0324
2023-02-06 10:48:15 | Train | Epoch[219/600] Iteration[004/030] Train loss: 0.0302
2023-02-06 10:48:15 | Train | Epoch[219/600] Iteration[005/030] Train loss: 0.0309
2023-02-06 10:48:15 | Train | Epoch[219/600] Iteration[006/030] Train loss: 0.0309
2023-02-06 10:48:15 | Train | Epoch[219/600] Iteration[007/030] Train loss: 0.0305
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[008/030] Train loss: 0.0299
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[009/030] Train loss: 0.0297
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[010/030] Train loss: 0.0298
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[011/030] Train loss: 0.0295
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[012/030] Train loss: 0.0298
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[013/030] Train loss: 0.0296
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[014/030] Train loss: 0.0299
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[015/030] Train loss: 0.0299
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[016/030] Train loss: 0.0301
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[017/030] Train loss: 0.0298
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[018/030] Train loss: 0.0297
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[019/030] Train loss: 0.0295
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[020/030] Train loss: 0.0296
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[021/030] Train loss: 0.0298
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[022/030] Train loss: 0.0298
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[023/030] Train loss: 0.0299
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[024/030] Train loss: 0.0299
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[025/030] Train loss: 0.0301
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[026/030] Train loss: 0.0302
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[027/030] Train loss: 0.0303
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[028/030] Train loss: 0.0303
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[029/030] Train loss: 0.0301
2023-02-06 10:48:16 | Train | Epoch[219/600] Iteration[030/030] Train loss: 0.0300
2023-02-06 10:48:17 | Valid | Epoch[219/600] Iteration[001/008] Valid loss: 0.0626
2023-02-06 10:48:17 | Valid | Epoch[219/600] Iteration[002/008] Valid loss: 0.0528
2023-02-06 10:48:17 | Valid | Epoch[219/600] Iteration[003/008] Valid loss: 0.0481
2023-02-06 10:48:17 | Valid | Epoch[219/600] Iteration[004/008] Valid loss: 0.0473
2023-02-06 10:48:17 | Valid | Epoch[219/600] Iteration[005/008] Valid loss: 0.0482
2023-02-06 10:48:17 | Valid | Epoch[219/600] Iteration[006/008] Valid loss: 0.0499
2023-02-06 10:48:17 | Valid | Epoch[219/600] Iteration[007/008] Valid loss: 0.0518
2023-02-06 10:48:17 | Valid | Epoch[219/600] Iteration[008/008] Valid loss: 0.0502
2023-02-06 10:48:17 | Valid | Epoch[219/600] MIou: 0.9395797176978231
2023-02-06 10:48:17 | Valid | Epoch[219/600] Pixel Accuracy: 0.9896011352539062
2023-02-06 10:48:17 | Valid | Epoch[219/600] Mean Pixel Accuracy: 0.9656951543867243
2023-02-06 10:48:17 | Stage | Epoch[219/600] Train loss:0.0300
2023-02-06 10:48:17 | Stage | Epoch[219/600] Valid loss:0.0502
2023-02-06 10:48:17 | Stage | Epoch[219/600] LR:0.01

2023-02-06 10:48:17 | Train | Epoch[220/600] Iteration[001/030] Train loss: 0.0295
2023-02-06 10:48:17 | Train | Epoch[220/600] Iteration[002/030] Train loss: 0.0299
2023-02-06 10:48:17 | Train | Epoch[220/600] Iteration[003/030] Train loss: 0.0294
2023-02-06 10:48:17 | Train | Epoch[220/600] Iteration[004/030] Train loss: 0.0292
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[005/030] Train loss: 0.0292
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[006/030] Train loss: 0.0294
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[007/030] Train loss: 0.0299
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[008/030] Train loss: 0.0294
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[009/030] Train loss: 0.0299
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[010/030] Train loss: 0.0297
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[011/030] Train loss: 0.0298
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[012/030] Train loss: 0.0302
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[013/030] Train loss: 0.0302
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[014/030] Train loss: 0.0300
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[015/030] Train loss: 0.0297
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[016/030] Train loss: 0.0298
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[017/030] Train loss: 0.0296
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[018/030] Train loss: 0.0298
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[019/030] Train loss: 0.0295
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[020/030] Train loss: 0.0294
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[021/030] Train loss: 0.0293
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[022/030] Train loss: 0.0295
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[023/030] Train loss: 0.0294
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[024/030] Train loss: 0.0295
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[025/030] Train loss: 0.0294
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[026/030] Train loss: 0.0294
2023-02-06 10:48:18 | Train | Epoch[220/600] Iteration[027/030] Train loss: 0.0294
2023-02-06 10:48:19 | Train | Epoch[220/600] Iteration[028/030] Train loss: 0.0294
2023-02-06 10:48:19 | Train | Epoch[220/600] Iteration[029/030] Train loss: 0.0293
2023-02-06 10:48:19 | Train | Epoch[220/600] Iteration[030/030] Train loss: 0.0293
2023-02-06 10:48:19 | Valid | Epoch[220/600] Iteration[001/008] Valid loss: 0.0644
2023-02-06 10:48:19 | Valid | Epoch[220/600] Iteration[002/008] Valid loss: 0.0636
2023-02-06 10:48:19 | Valid | Epoch[220/600] Iteration[003/008] Valid loss: 0.0657
2023-02-06 10:48:19 | Valid | Epoch[220/600] Iteration[004/008] Valid loss: 0.0651
2023-02-06 10:48:19 | Valid | Epoch[220/600] Iteration[005/008] Valid loss: 0.0660
2023-02-06 10:48:19 | Valid | Epoch[220/600] Iteration[006/008] Valid loss: 0.0647
2023-02-06 10:48:19 | Valid | Epoch[220/600] Iteration[007/008] Valid loss: 0.0630
2023-02-06 10:48:19 | Valid | Epoch[220/600] Iteration[008/008] Valid loss: 0.0644
2023-02-06 10:48:19 | Valid | Epoch[220/600] MIou: 0.7770504239158464
2023-02-06 10:48:19 | Valid | Epoch[220/600] Pixel Accuracy: 0.9632314046223959
2023-02-06 10:48:19 | Valid | Epoch[220/600] Mean Pixel Accuracy: 0.7965064018381123
2023-02-06 10:48:19 | Stage | Epoch[220/600] Train loss:0.0293
2023-02-06 10:48:19 | Stage | Epoch[220/600] Valid loss:0.0644
2023-02-06 10:48:19 | Stage | Epoch[220/600] LR:0.01

2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[001/030] Train loss: 0.0274
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[005/030] Train loss: 0.0276
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[006/030] Train loss: 0.0279
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[007/030] Train loss: 0.0278
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[008/030] Train loss: 0.0278
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[009/030] Train loss: 0.0283
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[010/030] Train loss: 0.0286
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[011/030] Train loss: 0.0284
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[012/030] Train loss: 0.0284
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[013/030] Train loss: 0.0284
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[014/030] Train loss: 0.0285
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[015/030] Train loss: 0.0286
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[016/030] Train loss: 0.0287
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[017/030] Train loss: 0.0286
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[018/030] Train loss: 0.0286
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[019/030] Train loss: 0.0286
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[020/030] Train loss: 0.0285
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[021/030] Train loss: 0.0288
2023-02-06 10:48:20 | Train | Epoch[221/600] Iteration[022/030] Train loss: 0.0286
2023-02-06 10:48:21 | Train | Epoch[221/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 10:48:21 | Train | Epoch[221/600] Iteration[024/030] Train loss: 0.0286
2023-02-06 10:48:21 | Train | Epoch[221/600] Iteration[025/030] Train loss: 0.0287
2023-02-06 10:48:21 | Train | Epoch[221/600] Iteration[026/030] Train loss: 0.0287
2023-02-06 10:48:21 | Train | Epoch[221/600] Iteration[027/030] Train loss: 0.0285
2023-02-06 10:48:21 | Train | Epoch[221/600] Iteration[028/030] Train loss: 0.0285
2023-02-06 10:48:21 | Train | Epoch[221/600] Iteration[029/030] Train loss: 0.0285
2023-02-06 10:48:21 | Train | Epoch[221/600] Iteration[030/030] Train loss: 0.0287
2023-02-06 10:48:21 | Valid | Epoch[221/600] Iteration[001/008] Valid loss: 0.7297
2023-02-06 10:48:21 | Valid | Epoch[221/600] Iteration[002/008] Valid loss: 0.6976
2023-02-06 10:48:21 | Valid | Epoch[221/600] Iteration[003/008] Valid loss: 0.7091
2023-02-06 10:48:21 | Valid | Epoch[221/600] Iteration[004/008] Valid loss: 0.7129
2023-02-06 10:48:21 | Valid | Epoch[221/600] Iteration[005/008] Valid loss: 0.7443
2023-02-06 10:48:21 | Valid | Epoch[221/600] Iteration[006/008] Valid loss: 0.7248
2023-02-06 10:48:21 | Valid | Epoch[221/600] Iteration[007/008] Valid loss: 0.7586
2023-02-06 10:48:21 | Valid | Epoch[221/600] Iteration[008/008] Valid loss: 0.7949
2023-02-06 10:48:21 | Valid | Epoch[221/600] MIou: 0.8281691891153391
2023-02-06 10:48:21 | Valid | Epoch[221/600] Pixel Accuracy: 0.9614143371582031
2023-02-06 10:48:21 | Valid | Epoch[221/600] Mean Pixel Accuracy: 0.9746386652230177
2023-02-06 10:48:21 | Stage | Epoch[221/600] Train loss:0.0287
2023-02-06 10:48:21 | Stage | Epoch[221/600] Valid loss:0.7949
2023-02-06 10:48:21 | Stage | Epoch[221/600] LR:0.01

2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[001/030] Train loss: 0.0279
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[002/030] Train loss: 0.0302
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[003/030] Train loss: 0.0296
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[004/030] Train loss: 0.0296
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[005/030] Train loss: 0.0297
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[006/030] Train loss: 0.0297
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[007/030] Train loss: 0.0299
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[008/030] Train loss: 0.0298
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[009/030] Train loss: 0.0294
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[010/030] Train loss: 0.0289
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[011/030] Train loss: 0.0288
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[012/030] Train loss: 0.0288
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[013/030] Train loss: 0.0288
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[014/030] Train loss: 0.0289
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[015/030] Train loss: 0.0291
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[016/030] Train loss: 0.0289
2023-02-06 10:48:22 | Train | Epoch[222/600] Iteration[017/030] Train loss: 0.0291
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[018/030] Train loss: 0.0292
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[019/030] Train loss: 0.0291
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[020/030] Train loss: 0.0291
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[021/030] Train loss: 0.0292
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[022/030] Train loss: 0.0291
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[023/030] Train loss: 0.0292
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[024/030] Train loss: 0.0290
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[025/030] Train loss: 0.0290
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[026/030] Train loss: 0.0291
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[027/030] Train loss: 0.0291
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[028/030] Train loss: 0.0291
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[029/030] Train loss: 0.0291
2023-02-06 10:48:23 | Train | Epoch[222/600] Iteration[030/030] Train loss: 0.0290
2023-02-06 10:48:23 | Valid | Epoch[222/600] Iteration[001/008] Valid loss: 0.0688
2023-02-06 10:48:23 | Valid | Epoch[222/600] Iteration[002/008] Valid loss: 0.0553
2023-02-06 10:48:23 | Valid | Epoch[222/600] Iteration[003/008] Valid loss: 0.0497
2023-02-06 10:48:23 | Valid | Epoch[222/600] Iteration[004/008] Valid loss: 0.0482
2023-02-06 10:48:24 | Valid | Epoch[222/600] Iteration[005/008] Valid loss: 0.0482
2023-02-06 10:48:24 | Valid | Epoch[222/600] Iteration[006/008] Valid loss: 0.0494
2023-02-06 10:48:24 | Valid | Epoch[222/600] Iteration[007/008] Valid loss: 0.0511
2023-02-06 10:48:24 | Valid | Epoch[222/600] Iteration[008/008] Valid loss: 0.0495
2023-02-06 10:48:24 | Valid | Epoch[222/600] MIou: 0.9347546135797264
2023-02-06 10:48:24 | Valid | Epoch[222/600] Pixel Accuracy: 0.9887860616048177
2023-02-06 10:48:24 | Valid | Epoch[222/600] Mean Pixel Accuracy: 0.96041571585493
2023-02-06 10:48:24 | Stage | Epoch[222/600] Train loss:0.0290
2023-02-06 10:48:24 | Stage | Epoch[222/600] Valid loss:0.0495
2023-02-06 10:48:24 | Stage | Epoch[222/600] LR:0.01

2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[001/030] Train loss: 0.0317
2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[002/030] Train loss: 0.0305
2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[003/030] Train loss: 0.0297
2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[004/030] Train loss: 0.0291
2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[005/030] Train loss: 0.0297
2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[006/030] Train loss: 0.0299
2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[007/030] Train loss: 0.0300
2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[008/030] Train loss: 0.0299
2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[009/030] Train loss: 0.0298
2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[010/030] Train loss: 0.0296
2023-02-06 10:48:24 | Train | Epoch[223/600] Iteration[011/030] Train loss: 0.0294
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[012/030] Train loss: 0.0295
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[013/030] Train loss: 0.0294
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[014/030] Train loss: 0.0291
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[015/030] Train loss: 0.0293
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[016/030] Train loss: 0.0296
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[017/030] Train loss: 0.0293
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[018/030] Train loss: 0.0291
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[019/030] Train loss: 0.0290
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[020/030] Train loss: 0.0288
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[021/030] Train loss: 0.0288
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[022/030] Train loss: 0.0287
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[023/030] Train loss: 0.0286
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[024/030] Train loss: 0.0284
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[025/030] Train loss: 0.0284
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[026/030] Train loss: 0.0285
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[027/030] Train loss: 0.0285
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[028/030] Train loss: 0.0286
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[029/030] Train loss: 0.0288
2023-02-06 10:48:25 | Train | Epoch[223/600] Iteration[030/030] Train loss: 0.0290
2023-02-06 10:48:26 | Valid | Epoch[223/600] Iteration[001/008] Valid loss: 0.1671
2023-02-06 10:48:26 | Valid | Epoch[223/600] Iteration[002/008] Valid loss: 0.1352
2023-02-06 10:48:26 | Valid | Epoch[223/600] Iteration[003/008] Valid loss: 0.1237
2023-02-06 10:48:26 | Valid | Epoch[223/600] Iteration[004/008] Valid loss: 0.1232
2023-02-06 10:48:26 | Valid | Epoch[223/600] Iteration[005/008] Valid loss: 0.1233
2023-02-06 10:48:26 | Valid | Epoch[223/600] Iteration[006/008] Valid loss: 0.1299
2023-02-06 10:48:26 | Valid | Epoch[223/600] Iteration[007/008] Valid loss: 0.1387
2023-02-06 10:48:26 | Valid | Epoch[223/600] Iteration[008/008] Valid loss: 0.1323
2023-02-06 10:48:26 | Valid | Epoch[223/600] MIou: 0.9237146869815323
2023-02-06 10:48:26 | Valid | Epoch[223/600] Pixel Accuracy: 0.9861068725585938
2023-02-06 10:48:26 | Valid | Epoch[223/600] Mean Pixel Accuracy: 0.9771085701725848
2023-02-06 10:48:26 | Stage | Epoch[223/600] Train loss:0.0290
2023-02-06 10:48:26 | Stage | Epoch[223/600] Valid loss:0.1323
2023-02-06 10:48:26 | Stage | Epoch[223/600] LR:0.01

2023-02-06 10:48:26 | Train | Epoch[224/600] Iteration[001/030] Train loss: 0.0268
2023-02-06 10:48:26 | Train | Epoch[224/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 10:48:26 | Train | Epoch[224/600] Iteration[003/030] Train loss: 0.0278
2023-02-06 10:48:26 | Train | Epoch[224/600] Iteration[004/030] Train loss: 0.0277
2023-02-06 10:48:26 | Train | Epoch[224/600] Iteration[005/030] Train loss: 0.0276
2023-02-06 10:48:26 | Train | Epoch[224/600] Iteration[006/030] Train loss: 0.0276
2023-02-06 10:48:26 | Train | Epoch[224/600] Iteration[007/030] Train loss: 0.0280
2023-02-06 10:48:26 | Train | Epoch[224/600] Iteration[008/030] Train loss: 0.0291
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[009/030] Train loss: 0.0292
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[010/030] Train loss: 0.0295
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[011/030] Train loss: 0.0298
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[012/030] Train loss: 0.0303
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[013/030] Train loss: 0.0300
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[014/030] Train loss: 0.0302
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[015/030] Train loss: 0.0301
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[016/030] Train loss: 0.0298
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[017/030] Train loss: 0.0299
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[018/030] Train loss: 0.0305
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[019/030] Train loss: 0.0303
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[020/030] Train loss: 0.0302
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[021/030] Train loss: 0.0301
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[022/030] Train loss: 0.0299
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[023/030] Train loss: 0.0298
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[024/030] Train loss: 0.0299
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[025/030] Train loss: 0.0298
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[026/030] Train loss: 0.0299
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[027/030] Train loss: 0.0300
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[028/030] Train loss: 0.0298
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[029/030] Train loss: 0.0297
2023-02-06 10:48:27 | Train | Epoch[224/600] Iteration[030/030] Train loss: 0.0296
2023-02-06 10:48:28 | Valid | Epoch[224/600] Iteration[001/008] Valid loss: 0.0995
2023-02-06 10:48:28 | Valid | Epoch[224/600] Iteration[002/008] Valid loss: 0.0795
2023-02-06 10:48:28 | Valid | Epoch[224/600] Iteration[003/008] Valid loss: 0.0757
2023-02-06 10:48:28 | Valid | Epoch[224/600] Iteration[004/008] Valid loss: 0.0748
2023-02-06 10:48:28 | Valid | Epoch[224/600] Iteration[005/008] Valid loss: 0.0781
2023-02-06 10:48:28 | Valid | Epoch[224/600] Iteration[006/008] Valid loss: 0.0783
2023-02-06 10:48:28 | Valid | Epoch[224/600] Iteration[007/008] Valid loss: 0.0850
2023-02-06 10:48:28 | Valid | Epoch[224/600] Iteration[008/008] Valid loss: 0.0832
2023-02-06 10:48:28 | Valid | Epoch[224/600] MIou: 0.9237779582048778
2023-02-06 10:48:28 | Valid | Epoch[224/600] Pixel Accuracy: 0.9860814412434896
2023-02-06 10:48:28 | Valid | Epoch[224/600] Mean Pixel Accuracy: 0.9784768148268175
2023-02-06 10:48:28 | Stage | Epoch[224/600] Train loss:0.0296
2023-02-06 10:48:28 | Stage | Epoch[224/600] Valid loss:0.0832
2023-02-06 10:48:28 | Stage | Epoch[224/600] LR:0.01

2023-02-06 10:48:28 | Train | Epoch[225/600] Iteration[001/030] Train loss: 0.0293
2023-02-06 10:48:28 | Train | Epoch[225/600] Iteration[002/030] Train loss: 0.0269
2023-02-06 10:48:28 | Train | Epoch[225/600] Iteration[003/030] Train loss: 0.0320
2023-02-06 10:48:28 | Train | Epoch[225/600] Iteration[004/030] Train loss: 0.0311
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[005/030] Train loss: 0.0305
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[006/030] Train loss: 0.0307
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[007/030] Train loss: 0.0307
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[008/030] Train loss: 0.0306
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[009/030] Train loss: 0.0304
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[010/030] Train loss: 0.0299
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[011/030] Train loss: 0.0302
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[012/030] Train loss: 0.0304
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[013/030] Train loss: 0.0303
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[014/030] Train loss: 0.0303
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[015/030] Train loss: 0.0300
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[016/030] Train loss: 0.0297
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[017/030] Train loss: 0.0294
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[018/030] Train loss: 0.0291
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[019/030] Train loss: 0.0292
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[020/030] Train loss: 0.0291
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[021/030] Train loss: 0.0292
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[022/030] Train loss: 0.0292
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[023/030] Train loss: 0.0292
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[024/030] Train loss: 0.0294
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[025/030] Train loss: 0.0295
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[026/030] Train loss: 0.0294
2023-02-06 10:48:29 | Train | Epoch[225/600] Iteration[027/030] Train loss: 0.0292
2023-02-06 10:48:30 | Train | Epoch[225/600] Iteration[028/030] Train loss: 0.0291
2023-02-06 10:48:30 | Train | Epoch[225/600] Iteration[029/030] Train loss: 0.0291
2023-02-06 10:48:30 | Train | Epoch[225/600] Iteration[030/030] Train loss: 0.0290
2023-02-06 10:48:30 | Valid | Epoch[225/600] Iteration[001/008] Valid loss: 0.0435
2023-02-06 10:48:30 | Valid | Epoch[225/600] Iteration[002/008] Valid loss: 0.0405
2023-02-06 10:48:30 | Valid | Epoch[225/600] Iteration[003/008] Valid loss: 0.0411
2023-02-06 10:48:30 | Valid | Epoch[225/600] Iteration[004/008] Valid loss: 0.0399
2023-02-06 10:48:30 | Valid | Epoch[225/600] Iteration[005/008] Valid loss: 0.0404
2023-02-06 10:48:30 | Valid | Epoch[225/600] Iteration[006/008] Valid loss: 0.0397
2023-02-06 10:48:30 | Valid | Epoch[225/600] Iteration[007/008] Valid loss: 0.0390
2023-02-06 10:48:30 | Valid | Epoch[225/600] Iteration[008/008] Valid loss: 0.0394
2023-02-06 10:48:30 | Valid | Epoch[225/600] MIou: 0.8727019217364518
2023-02-06 10:48:30 | Valid | Epoch[225/600] Pixel Accuracy: 0.9790115356445312
2023-02-06 10:48:30 | Valid | Epoch[225/600] Mean Pixel Accuracy: 0.8844737715842587
2023-02-06 10:48:30 | Stage | Epoch[225/600] Train loss:0.0290
2023-02-06 10:48:30 | Stage | Epoch[225/600] Valid loss:0.0394
2023-02-06 10:48:30 | Stage | Epoch[225/600] LR:0.01

2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[003/030] Train loss: 0.0276
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[004/030] Train loss: 0.0283
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[005/030] Train loss: 0.0282
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[006/030] Train loss: 0.0276
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[007/030] Train loss: 0.0283
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[008/030] Train loss: 0.0291
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[009/030] Train loss: 0.0287
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[011/030] Train loss: 0.0285
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[012/030] Train loss: 0.0285
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[013/030] Train loss: 0.0286
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[014/030] Train loss: 0.0286
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[015/030] Train loss: 0.0290
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[016/030] Train loss: 0.0287
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[017/030] Train loss: 0.0286
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[018/030] Train loss: 0.0289
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[019/030] Train loss: 0.0286
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[020/030] Train loss: 0.0285
2023-02-06 10:48:31 | Train | Epoch[226/600] Iteration[021/030] Train loss: 0.0287
2023-02-06 10:48:32 | Train | Epoch[226/600] Iteration[022/030] Train loss: 0.0287
2023-02-06 10:48:32 | Train | Epoch[226/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 10:48:32 | Train | Epoch[226/600] Iteration[024/030] Train loss: 0.0284
2023-02-06 10:48:32 | Train | Epoch[226/600] Iteration[025/030] Train loss: 0.0285
2023-02-06 10:48:32 | Train | Epoch[226/600] Iteration[026/030] Train loss: 0.0287
2023-02-06 10:48:32 | Train | Epoch[226/600] Iteration[027/030] Train loss: 0.0286
2023-02-06 10:48:32 | Train | Epoch[226/600] Iteration[028/030] Train loss: 0.0286
2023-02-06 10:48:32 | Train | Epoch[226/600] Iteration[029/030] Train loss: 0.0285
2023-02-06 10:48:32 | Train | Epoch[226/600] Iteration[030/030] Train loss: 0.0286
2023-02-06 10:48:32 | Valid | Epoch[226/600] Iteration[001/008] Valid loss: 0.0570
2023-02-06 10:48:32 | Valid | Epoch[226/600] Iteration[002/008] Valid loss: 0.0451
2023-02-06 10:48:32 | Valid | Epoch[226/600] Iteration[003/008] Valid loss: 0.0421
2023-02-06 10:48:32 | Valid | Epoch[226/600] Iteration[004/008] Valid loss: 0.0406
2023-02-06 10:48:32 | Valid | Epoch[226/600] Iteration[005/008] Valid loss: 0.0416
2023-02-06 10:48:32 | Valid | Epoch[226/600] Iteration[006/008] Valid loss: 0.0414
2023-02-06 10:48:32 | Valid | Epoch[226/600] Iteration[007/008] Valid loss: 0.0434
2023-02-06 10:48:32 | Valid | Epoch[226/600] Iteration[008/008] Valid loss: 0.0423
2023-02-06 10:48:33 | Valid | Epoch[226/600] MIou: 0.9398449821642445
2023-02-06 10:48:33 | Valid | Epoch[226/600] Pixel Accuracy: 0.9896837870279948
2023-02-06 10:48:33 | Valid | Epoch[226/600] Mean Pixel Accuracy: 0.9642695939359737
2023-02-06 10:48:33 | Stage | Epoch[226/600] Train loss:0.0286
2023-02-06 10:48:33 | Stage | Epoch[226/600] Valid loss:0.0423
2023-02-06 10:48:33 | Stage | Epoch[226/600] LR:0.01

2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[001/030] Train loss: 0.0256
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[003/030] Train loss: 0.0274
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[004/030] Train loss: 0.0282
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[005/030] Train loss: 0.0289
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[006/030] Train loss: 0.0287
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[007/030] Train loss: 0.0293
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[008/030] Train loss: 0.0294
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[009/030] Train loss: 0.0292
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[010/030] Train loss: 0.0291
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[011/030] Train loss: 0.0288
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[012/030] Train loss: 0.0284
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[013/030] Train loss: 0.0286
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[014/030] Train loss: 0.0287
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[015/030] Train loss: 0.0287
2023-02-06 10:48:33 | Train | Epoch[227/600] Iteration[016/030] Train loss: 0.0288
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[017/030] Train loss: 0.0285
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[018/030] Train loss: 0.0283
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[019/030] Train loss: 0.0282
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[020/030] Train loss: 0.0284
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[021/030] Train loss: 0.0284
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[022/030] Train loss: 0.0284
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[023/030] Train loss: 0.0286
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[024/030] Train loss: 0.0286
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[025/030] Train loss: 0.0285
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[026/030] Train loss: 0.0286
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[027/030] Train loss: 0.0286
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[028/030] Train loss: 0.0290
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[029/030] Train loss: 0.0288
2023-02-06 10:48:34 | Train | Epoch[227/600] Iteration[030/030] Train loss: 0.0290
2023-02-06 10:48:34 | Valid | Epoch[227/600] Iteration[001/008] Valid loss: 0.1957
2023-02-06 10:48:34 | Valid | Epoch[227/600] Iteration[002/008] Valid loss: 0.1478
2023-02-06 10:48:35 | Valid | Epoch[227/600] Iteration[003/008] Valid loss: 0.1440
2023-02-06 10:48:35 | Valid | Epoch[227/600] Iteration[004/008] Valid loss: 0.1389
2023-02-06 10:48:35 | Valid | Epoch[227/600] Iteration[005/008] Valid loss: 0.1425
2023-02-06 10:48:35 | Valid | Epoch[227/600] Iteration[006/008] Valid loss: 0.1395
2023-02-06 10:48:35 | Valid | Epoch[227/600] Iteration[007/008] Valid loss: 0.1504
2023-02-06 10:48:35 | Valid | Epoch[227/600] Iteration[008/008] Valid loss: 0.1506
2023-02-06 10:48:35 | Valid | Epoch[227/600] MIou: 0.9099926643433358
2023-02-06 10:48:35 | Valid | Epoch[227/600] Pixel Accuracy: 0.9831555684407552
2023-02-06 10:48:35 | Valid | Epoch[227/600] Mean Pixel Accuracy: 0.9762853069698665
2023-02-06 10:48:35 | Stage | Epoch[227/600] Train loss:0.0290
2023-02-06 10:48:35 | Stage | Epoch[227/600] Valid loss:0.1506
2023-02-06 10:48:35 | Stage | Epoch[227/600] LR:0.01

2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[003/030] Train loss: 0.0272
2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[004/030] Train loss: 0.0280
2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[005/030] Train loss: 0.0281
2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[006/030] Train loss: 0.0283
2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[007/030] Train loss: 0.0285
2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[008/030] Train loss: 0.0284
2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[009/030] Train loss: 0.0286
2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 10:48:35 | Train | Epoch[228/600] Iteration[011/030] Train loss: 0.0292
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[012/030] Train loss: 0.0292
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[013/030] Train loss: 0.0293
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[014/030] Train loss: 0.0289
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[015/030] Train loss: 0.0289
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[016/030] Train loss: 0.0289
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[017/030] Train loss: 0.0291
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[018/030] Train loss: 0.0289
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[019/030] Train loss: 0.0290
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[020/030] Train loss: 0.0290
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[021/030] Train loss: 0.0290
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[022/030] Train loss: 0.0289
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[023/030] Train loss: 0.0288
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[024/030] Train loss: 0.0288
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[025/030] Train loss: 0.0287
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[026/030] Train loss: 0.0286
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[027/030] Train loss: 0.0285
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[028/030] Train loss: 0.0287
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[029/030] Train loss: 0.0287
2023-02-06 10:48:36 | Train | Epoch[228/600] Iteration[030/030] Train loss: 0.0288
2023-02-06 10:48:37 | Valid | Epoch[228/600] Iteration[001/008] Valid loss: 0.1353
2023-02-06 10:48:37 | Valid | Epoch[228/600] Iteration[002/008] Valid loss: 0.1130
2023-02-06 10:48:37 | Valid | Epoch[228/600] Iteration[003/008] Valid loss: 0.1025
2023-02-06 10:48:37 | Valid | Epoch[228/600] Iteration[004/008] Valid loss: 0.0992
2023-02-06 10:48:37 | Valid | Epoch[228/600] Iteration[005/008] Valid loss: 0.1006
2023-02-06 10:48:37 | Valid | Epoch[228/600] Iteration[006/008] Valid loss: 0.0992
2023-02-06 10:48:37 | Valid | Epoch[228/600] Iteration[007/008] Valid loss: 0.1064
2023-02-06 10:48:37 | Valid | Epoch[228/600] Iteration[008/008] Valid loss: 0.1063
2023-02-06 10:48:37 | Valid | Epoch[228/600] MIou: 0.9172236150007161
2023-02-06 10:48:37 | Valid | Epoch[228/600] Pixel Accuracy: 0.9847005208333334
2023-02-06 10:48:37 | Valid | Epoch[228/600] Mean Pixel Accuracy: 0.9776860997170043
2023-02-06 10:48:37 | Stage | Epoch[228/600] Train loss:0.0288
2023-02-06 10:48:37 | Stage | Epoch[228/600] Valid loss:0.1063
2023-02-06 10:48:37 | Stage | Epoch[228/600] LR:0.01

2023-02-06 10:48:37 | Train | Epoch[229/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 10:48:37 | Train | Epoch[229/600] Iteration[002/030] Train loss: 0.0268
2023-02-06 10:48:37 | Train | Epoch[229/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 10:48:37 | Train | Epoch[229/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:48:37 | Train | Epoch[229/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 10:48:37 | Train | Epoch[229/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 10:48:37 | Train | Epoch[229/600] Iteration[007/030] Train loss: 0.0276
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[008/030] Train loss: 0.0283
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[009/030] Train loss: 0.0282
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[010/030] Train loss: 0.0281
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[011/030] Train loss: 0.0280
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[012/030] Train loss: 0.0286
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[013/030] Train loss: 0.0287
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[014/030] Train loss: 0.0290
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[015/030] Train loss: 0.0293
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[016/030] Train loss: 0.0294
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[017/030] Train loss: 0.0294
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[018/030] Train loss: 0.0295
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[019/030] Train loss: 0.0294
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[020/030] Train loss: 0.0293
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[021/030] Train loss: 0.0297
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[022/030] Train loss: 0.0296
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[023/030] Train loss: 0.0295
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[024/030] Train loss: 0.0295
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[025/030] Train loss: 0.0294
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[026/030] Train loss: 0.0295
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[027/030] Train loss: 0.0294
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[028/030] Train loss: 0.0292
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[029/030] Train loss: 0.0293
2023-02-06 10:48:38 | Train | Epoch[229/600] Iteration[030/030] Train loss: 0.0293
2023-02-06 10:48:39 | Valid | Epoch[229/600] Iteration[001/008] Valid loss: 0.0394
2023-02-06 10:48:39 | Valid | Epoch[229/600] Iteration[002/008] Valid loss: 0.0358
2023-02-06 10:48:39 | Valid | Epoch[229/600] Iteration[003/008] Valid loss: 0.0357
2023-02-06 10:48:39 | Valid | Epoch[229/600] Iteration[004/008] Valid loss: 0.0348
2023-02-06 10:48:39 | Valid | Epoch[229/600] Iteration[005/008] Valid loss: 0.0353
2023-02-06 10:48:39 | Valid | Epoch[229/600] Iteration[006/008] Valid loss: 0.0353
2023-02-06 10:48:39 | Valid | Epoch[229/600] Iteration[007/008] Valid loss: 0.0354
2023-02-06 10:48:39 | Valid | Epoch[229/600] Iteration[008/008] Valid loss: 0.0355
2023-02-06 10:48:39 | Valid | Epoch[229/600] MIou: 0.8986548679787321
2023-02-06 10:48:39 | Valid | Epoch[229/600] Pixel Accuracy: 0.9831949869791666
2023-02-06 10:48:39 | Valid | Epoch[229/600] Mean Pixel Accuracy: 0.9106957738727355
2023-02-06 10:48:39 | Stage | Epoch[229/600] Train loss:0.0293
2023-02-06 10:48:39 | Stage | Epoch[229/600] Valid loss:0.0355
2023-02-06 10:48:39 | Stage | Epoch[229/600] LR:0.01

2023-02-06 10:48:39 | Train | Epoch[230/600] Iteration[001/030] Train loss: 0.0291
2023-02-06 10:48:39 | Train | Epoch[230/600] Iteration[002/030] Train loss: 0.0301
2023-02-06 10:48:39 | Train | Epoch[230/600] Iteration[003/030] Train loss: 0.0301
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[004/030] Train loss: 0.0289
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[005/030] Train loss: 0.0287
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[006/030] Train loss: 0.0284
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[007/030] Train loss: 0.0284
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[008/030] Train loss: 0.0281
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[009/030] Train loss: 0.0287
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[010/030] Train loss: 0.0284
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[011/030] Train loss: 0.0287
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[012/030] Train loss: 0.0288
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[013/030] Train loss: 0.0291
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[014/030] Train loss: 0.0290
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[015/030] Train loss: 0.0289
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[016/030] Train loss: 0.0290
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[017/030] Train loss: 0.0290
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[018/030] Train loss: 0.0288
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[019/030] Train loss: 0.0289
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[020/030] Train loss: 0.0287
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[021/030] Train loss: 0.0289
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[022/030] Train loss: 0.0290
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[023/030] Train loss: 0.0289
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[024/030] Train loss: 0.0290
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[025/030] Train loss: 0.0289
2023-02-06 10:48:40 | Train | Epoch[230/600] Iteration[026/030] Train loss: 0.0289
2023-02-06 10:48:41 | Train | Epoch[230/600] Iteration[027/030] Train loss: 0.0288
2023-02-06 10:48:41 | Train | Epoch[230/600] Iteration[028/030] Train loss: 0.0289
2023-02-06 10:48:41 | Train | Epoch[230/600] Iteration[029/030] Train loss: 0.0291
2023-02-06 10:48:41 | Train | Epoch[230/600] Iteration[030/030] Train loss: 0.0292
2023-02-06 10:48:41 | Valid | Epoch[230/600] Iteration[001/008] Valid loss: 0.0982
2023-02-06 10:48:41 | Valid | Epoch[230/600] Iteration[002/008] Valid loss: 0.0859
2023-02-06 10:48:41 | Valid | Epoch[230/600] Iteration[003/008] Valid loss: 0.0745
2023-02-06 10:48:41 | Valid | Epoch[230/600] Iteration[004/008] Valid loss: 0.0719
2023-02-06 10:48:41 | Valid | Epoch[230/600] Iteration[005/008] Valid loss: 0.0702
2023-02-06 10:48:41 | Valid | Epoch[230/600] Iteration[006/008] Valid loss: 0.0706
2023-02-06 10:48:41 | Valid | Epoch[230/600] Iteration[007/008] Valid loss: 0.0740
2023-02-06 10:48:41 | Valid | Epoch[230/600] Iteration[008/008] Valid loss: 0.0748
2023-02-06 10:48:41 | Valid | Epoch[230/600] MIou: 0.9240091883158559
2023-02-06 10:48:41 | Valid | Epoch[230/600] Pixel Accuracy: 0.9865239461263021
2023-02-06 10:48:41 | Valid | Epoch[230/600] Mean Pixel Accuracy: 0.9645998043253863
2023-02-06 10:48:41 | Stage | Epoch[230/600] Train loss:0.0292
2023-02-06 10:48:41 | Stage | Epoch[230/600] Valid loss:0.0748
2023-02-06 10:48:41 | Stage | Epoch[230/600] LR:0.01

2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[001/030] Train loss: 0.0299
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[003/030] Train loss: 0.0287
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[004/030] Train loss: 0.0281
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[005/030] Train loss: 0.0295
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[006/030] Train loss: 0.0293
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[007/030] Train loss: 0.0296
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[008/030] Train loss: 0.0296
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[009/030] Train loss: 0.0295
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[010/030] Train loss: 0.0295
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[011/030] Train loss: 0.0293
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[012/030] Train loss: 0.0289
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[013/030] Train loss: 0.0289
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[014/030] Train loss: 0.0285
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[015/030] Train loss: 0.0286
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[016/030] Train loss: 0.0284
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[017/030] Train loss: 0.0283
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[018/030] Train loss: 0.0285
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[019/030] Train loss: 0.0288
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[020/030] Train loss: 0.0289
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[021/030] Train loss: 0.0288
2023-02-06 10:48:42 | Train | Epoch[231/600] Iteration[022/030] Train loss: 0.0290
2023-02-06 10:48:43 | Train | Epoch[231/600] Iteration[023/030] Train loss: 0.0290
2023-02-06 10:48:43 | Train | Epoch[231/600] Iteration[024/030] Train loss: 0.0290
2023-02-06 10:48:43 | Train | Epoch[231/600] Iteration[025/030] Train loss: 0.0290
2023-02-06 10:48:43 | Train | Epoch[231/600] Iteration[026/030] Train loss: 0.0289
2023-02-06 10:48:43 | Train | Epoch[231/600] Iteration[027/030] Train loss: 0.0290
2023-02-06 10:48:43 | Train | Epoch[231/600] Iteration[028/030] Train loss: 0.0290
2023-02-06 10:48:43 | Train | Epoch[231/600] Iteration[029/030] Train loss: 0.0289
2023-02-06 10:48:43 | Train | Epoch[231/600] Iteration[030/030] Train loss: 0.0289
2023-02-06 10:48:43 | Valid | Epoch[231/600] Iteration[001/008] Valid loss: 0.0388
2023-02-06 10:48:43 | Valid | Epoch[231/600] Iteration[002/008] Valid loss: 0.0362
2023-02-06 10:48:43 | Valid | Epoch[231/600] Iteration[003/008] Valid loss: 0.0362
2023-02-06 10:48:43 | Valid | Epoch[231/600] Iteration[004/008] Valid loss: 0.0355
2023-02-06 10:48:43 | Valid | Epoch[231/600] Iteration[005/008] Valid loss: 0.0359
2023-02-06 10:48:43 | Valid | Epoch[231/600] Iteration[006/008] Valid loss: 0.0369
2023-02-06 10:48:43 | Valid | Epoch[231/600] Iteration[007/008] Valid loss: 0.0367
2023-02-06 10:48:43 | Valid | Epoch[231/600] Iteration[008/008] Valid loss: 0.0366
2023-02-06 10:48:43 | Valid | Epoch[231/600] MIou: 0.8946246001272137
2023-02-06 10:48:43 | Valid | Epoch[231/600] Pixel Accuracy: 0.982568105061849
2023-02-06 10:48:43 | Valid | Epoch[231/600] Mean Pixel Accuracy: 0.9060016493778238
2023-02-06 10:48:43 | Stage | Epoch[231/600] Train loss:0.0289
2023-02-06 10:48:43 | Stage | Epoch[231/600] Valid loss:0.0366
2023-02-06 10:48:43 | Stage | Epoch[231/600] LR:0.01

2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[001/030] Train loss: 0.0279
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[003/030] Train loss: 0.0279
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[005/030] Train loss: 0.0274
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[006/030] Train loss: 0.0274
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[007/030] Train loss: 0.0277
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[008/030] Train loss: 0.0273
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[010/030] Train loss: 0.0273
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[011/030] Train loss: 0.0275
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[012/030] Train loss: 0.0280
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[013/030] Train loss: 0.0281
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[014/030] Train loss: 0.0283
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[015/030] Train loss: 0.0285
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[016/030] Train loss: 0.0288
2023-02-06 10:48:44 | Train | Epoch[232/600] Iteration[017/030] Train loss: 0.0284
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[018/030] Train loss: 0.0284
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[019/030] Train loss: 0.0285
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[020/030] Train loss: 0.0285
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[021/030] Train loss: 0.0285
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[022/030] Train loss: 0.0285
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[023/030] Train loss: 0.0284
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[024/030] Train loss: 0.0284
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[025/030] Train loss: 0.0284
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[026/030] Train loss: 0.0283
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[027/030] Train loss: 0.0283
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[028/030] Train loss: 0.0285
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[029/030] Train loss: 0.0286
2023-02-06 10:48:45 | Train | Epoch[232/600] Iteration[030/030] Train loss: 0.0285
2023-02-06 10:48:45 | Valid | Epoch[232/600] Iteration[001/008] Valid loss: 0.0834
2023-02-06 10:48:45 | Valid | Epoch[232/600] Iteration[002/008] Valid loss: 0.0835
2023-02-06 10:48:45 | Valid | Epoch[232/600] Iteration[003/008] Valid loss: 0.0868
2023-02-06 10:48:45 | Valid | Epoch[232/600] Iteration[004/008] Valid loss: 0.0866
2023-02-06 10:48:45 | Valid | Epoch[232/600] Iteration[005/008] Valid loss: 0.0878
2023-02-06 10:48:45 | Valid | Epoch[232/600] Iteration[006/008] Valid loss: 0.0858
2023-02-06 10:48:46 | Valid | Epoch[232/600] Iteration[007/008] Valid loss: 0.0833
2023-02-06 10:48:46 | Valid | Epoch[232/600] Iteration[008/008] Valid loss: 0.0857
2023-02-06 10:48:46 | Valid | Epoch[232/600] MIou: 0.7279833030292461
2023-02-06 10:48:46 | Valid | Epoch[232/600] Pixel Accuracy: 0.9551111857096354
2023-02-06 10:48:46 | Valid | Epoch[232/600] Mean Pixel Accuracy: 0.7514958678849484
2023-02-06 10:48:46 | Stage | Epoch[232/600] Train loss:0.0285
2023-02-06 10:48:46 | Stage | Epoch[232/600] Valid loss:0.0857
2023-02-06 10:48:46 | Stage | Epoch[232/600] LR:0.01

2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[001/030] Train loss: 0.0312
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[002/030] Train loss: 0.0293
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[003/030] Train loss: 0.0287
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[004/030] Train loss: 0.0290
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[005/030] Train loss: 0.0280
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[006/030] Train loss: 0.0280
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[007/030] Train loss: 0.0279
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[008/030] Train loss: 0.0287
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[009/030] Train loss: 0.0285
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[011/030] Train loss: 0.0286
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[012/030] Train loss: 0.0281
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[013/030] Train loss: 0.0279
2023-02-06 10:48:46 | Train | Epoch[233/600] Iteration[014/030] Train loss: 0.0276
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[015/030] Train loss: 0.0277
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[016/030] Train loss: 0.0281
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[017/030] Train loss: 0.0282
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[018/030] Train loss: 0.0282
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[019/030] Train loss: 0.0281
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[020/030] Train loss: 0.0281
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[021/030] Train loss: 0.0281
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[022/030] Train loss: 0.0281
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[023/030] Train loss: 0.0281
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[024/030] Train loss: 0.0280
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[025/030] Train loss: 0.0281
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[026/030] Train loss: 0.0281
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[028/030] Train loss: 0.0279
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[029/030] Train loss: 0.0280
2023-02-06 10:48:47 | Train | Epoch[233/600] Iteration[030/030] Train loss: 0.0279
2023-02-06 10:48:48 | Valid | Epoch[233/600] Iteration[001/008] Valid loss: 0.0528
2023-02-06 10:48:48 | Valid | Epoch[233/600] Iteration[002/008] Valid loss: 0.0512
2023-02-06 10:48:48 | Valid | Epoch[233/600] Iteration[003/008] Valid loss: 0.0521
2023-02-06 10:48:48 | Valid | Epoch[233/600] Iteration[004/008] Valid loss: 0.0512
2023-02-06 10:48:48 | Valid | Epoch[233/600] Iteration[005/008] Valid loss: 0.0518
2023-02-06 10:48:48 | Valid | Epoch[233/600] Iteration[006/008] Valid loss: 0.0509
2023-02-06 10:48:48 | Valid | Epoch[233/600] Iteration[007/008] Valid loss: 0.0497
2023-02-06 10:48:48 | Valid | Epoch[233/600] Iteration[008/008] Valid loss: 0.0508
2023-02-06 10:48:48 | Valid | Epoch[233/600] MIou: 0.8165339111610441
2023-02-06 10:48:48 | Valid | Epoch[233/600] Pixel Accuracy: 0.9697608947753906
2023-02-06 10:48:48 | Valid | Epoch[233/600] Mean Pixel Accuracy: 0.8326599497882599
2023-02-06 10:48:48 | Stage | Epoch[233/600] Train loss:0.0279
2023-02-06 10:48:48 | Stage | Epoch[233/600] Valid loss:0.0508
2023-02-06 10:48:48 | Stage | Epoch[233/600] LR:0.01

2023-02-06 10:48:48 | Train | Epoch[234/600] Iteration[001/030] Train loss: 0.0314
2023-02-06 10:48:48 | Train | Epoch[234/600] Iteration[002/030] Train loss: 0.0301
2023-02-06 10:48:48 | Train | Epoch[234/600] Iteration[003/030] Train loss: 0.0287
2023-02-06 10:48:48 | Train | Epoch[234/600] Iteration[004/030] Train loss: 0.0288
2023-02-06 10:48:48 | Train | Epoch[234/600] Iteration[005/030] Train loss: 0.0283
2023-02-06 10:48:48 | Train | Epoch[234/600] Iteration[006/030] Train loss: 0.0284
2023-02-06 10:48:48 | Train | Epoch[234/600] Iteration[007/030] Train loss: 0.0288
2023-02-06 10:48:48 | Train | Epoch[234/600] Iteration[008/030] Train loss: 0.0283
2023-02-06 10:48:48 | Train | Epoch[234/600] Iteration[009/030] Train loss: 0.0278
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[010/030] Train loss: 0.0276
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[011/030] Train loss: 0.0282
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[012/030] Train loss: 0.0284
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[013/030] Train loss: 0.0284
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[014/030] Train loss: 0.0283
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[015/030] Train loss: 0.0288
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[016/030] Train loss: 0.0290
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[017/030] Train loss: 0.0289
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[018/030] Train loss: 0.0290
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[019/030] Train loss: 0.0289
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[020/030] Train loss: 0.0289
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[021/030] Train loss: 0.0289
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[022/030] Train loss: 0.0287
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[023/030] Train loss: 0.0289
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[024/030] Train loss: 0.0287
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[025/030] Train loss: 0.0287
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[026/030] Train loss: 0.0286
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[027/030] Train loss: 0.0286
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[028/030] Train loss: 0.0288
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[029/030] Train loss: 0.0287
2023-02-06 10:48:49 | Train | Epoch[234/600] Iteration[030/030] Train loss: 0.0286
2023-02-06 10:48:50 | Valid | Epoch[234/600] Iteration[001/008] Valid loss: 0.6237
2023-02-06 10:48:50 | Valid | Epoch[234/600] Iteration[002/008] Valid loss: 0.5941
2023-02-06 10:48:50 | Valid | Epoch[234/600] Iteration[003/008] Valid loss: 0.5854
2023-02-06 10:48:50 | Valid | Epoch[234/600] Iteration[004/008] Valid loss: 0.5959
2023-02-06 10:48:50 | Valid | Epoch[234/600] Iteration[005/008] Valid loss: 0.6227
2023-02-06 10:48:50 | Valid | Epoch[234/600] Iteration[006/008] Valid loss: 0.6214
2023-02-06 10:48:50 | Valid | Epoch[234/600] Iteration[007/008] Valid loss: 0.6596
2023-02-06 10:48:50 | Valid | Epoch[234/600] Iteration[008/008] Valid loss: 0.6616
2023-02-06 10:48:50 | Valid | Epoch[234/600] MIou: 0.8356915123045097
2023-02-06 10:48:50 | Valid | Epoch[234/600] Pixel Accuracy: 0.9635798136393229
2023-02-06 10:48:50 | Valid | Epoch[234/600] Mean Pixel Accuracy: 0.9772681904856214
2023-02-06 10:48:50 | Stage | Epoch[234/600] Train loss:0.0286
2023-02-06 10:48:50 | Stage | Epoch[234/600] Valid loss:0.6616
2023-02-06 10:48:50 | Stage | Epoch[234/600] LR:0.01

2023-02-06 10:48:50 | Train | Epoch[235/600] Iteration[001/030] Train loss: 0.0333
2023-02-06 10:48:50 | Train | Epoch[235/600] Iteration[002/030] Train loss: 0.0304
2023-02-06 10:48:50 | Train | Epoch[235/600] Iteration[003/030] Train loss: 0.0297
2023-02-06 10:48:50 | Train | Epoch[235/600] Iteration[004/030] Train loss: 0.0289
2023-02-06 10:48:50 | Train | Epoch[235/600] Iteration[005/030] Train loss: 0.0285
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[006/030] Train loss: 0.0292
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[007/030] Train loss: 0.0293
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[008/030] Train loss: 0.0297
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[009/030] Train loss: 0.0294
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[010/030] Train loss: 0.0293
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[011/030] Train loss: 0.0294
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[012/030] Train loss: 0.0293
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[013/030] Train loss: 0.0292
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[014/030] Train loss: 0.0289
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[015/030] Train loss: 0.0292
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[016/030] Train loss: 0.0287
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[017/030] Train loss: 0.0287
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[018/030] Train loss: 0.0289
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[019/030] Train loss: 0.0289
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[020/030] Train loss: 0.0288
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[021/030] Train loss: 0.0289
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[022/030] Train loss: 0.0286
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[024/030] Train loss: 0.0284
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[025/030] Train loss: 0.0283
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[026/030] Train loss: 0.0284
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[027/030] Train loss: 0.0285
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[028/030] Train loss: 0.0285
2023-02-06 10:48:51 | Train | Epoch[235/600] Iteration[029/030] Train loss: 0.0284
2023-02-06 10:48:52 | Train | Epoch[235/600] Iteration[030/030] Train loss: 0.0284
2023-02-06 10:48:52 | Valid | Epoch[235/600] Iteration[001/008] Valid loss: 0.0980
2023-02-06 10:48:52 | Valid | Epoch[235/600] Iteration[002/008] Valid loss: 0.0754
2023-02-06 10:48:52 | Valid | Epoch[235/600] Iteration[003/008] Valid loss: 0.0683
2023-02-06 10:48:52 | Valid | Epoch[235/600] Iteration[004/008] Valid loss: 0.0650
2023-02-06 10:48:52 | Valid | Epoch[235/600] Iteration[005/008] Valid loss: 0.0652
2023-02-06 10:48:52 | Valid | Epoch[235/600] Iteration[006/008] Valid loss: 0.0650
2023-02-06 10:48:52 | Valid | Epoch[235/600] Iteration[007/008] Valid loss: 0.0696
2023-02-06 10:48:52 | Valid | Epoch[235/600] Iteration[008/008] Valid loss: 0.0686
2023-02-06 10:48:52 | Valid | Epoch[235/600] MIou: 0.9294882032458078
2023-02-06 10:48:52 | Valid | Epoch[235/600] Pixel Accuracy: 0.987402598063151
2023-02-06 10:48:52 | Valid | Epoch[235/600] Mean Pixel Accuracy: 0.9735980021442004
2023-02-06 10:48:52 | Stage | Epoch[235/600] Train loss:0.0284
2023-02-06 10:48:52 | Stage | Epoch[235/600] Valid loss:0.0686
2023-02-06 10:48:52 | Stage | Epoch[235/600] LR:0.01

2023-02-06 10:48:52 | Train | Epoch[236/600] Iteration[001/030] Train loss: 0.0284
2023-02-06 10:48:52 | Train | Epoch[236/600] Iteration[002/030] Train loss: 0.0252
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[003/030] Train loss: 0.0240
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[006/030] Train loss: 0.0261
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[008/030] Train loss: 0.0268
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[011/030] Train loss: 0.0270
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[012/030] Train loss: 0.0271
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[013/030] Train loss: 0.0272
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[014/030] Train loss: 0.0274
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[015/030] Train loss: 0.0274
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[016/030] Train loss: 0.0273
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[017/030] Train loss: 0.0275
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[018/030] Train loss: 0.0275
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[020/030] Train loss: 0.0275
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[021/030] Train loss: 0.0277
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[022/030] Train loss: 0.0277
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[023/030] Train loss: 0.0279
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[024/030] Train loss: 0.0279
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[025/030] Train loss: 0.0278
2023-02-06 10:48:53 | Train | Epoch[236/600] Iteration[026/030] Train loss: 0.0279
2023-02-06 10:48:54 | Train | Epoch[236/600] Iteration[027/030] Train loss: 0.0281
2023-02-06 10:48:54 | Train | Epoch[236/600] Iteration[028/030] Train loss: 0.0283
2023-02-06 10:48:54 | Train | Epoch[236/600] Iteration[029/030] Train loss: 0.0282
2023-02-06 10:48:54 | Train | Epoch[236/600] Iteration[030/030] Train loss: 0.0281
2023-02-06 10:48:54 | Valid | Epoch[236/600] Iteration[001/008] Valid loss: 0.2073
2023-02-06 10:48:54 | Valid | Epoch[236/600] Iteration[002/008] Valid loss: 0.1665
2023-02-06 10:48:54 | Valid | Epoch[236/600] Iteration[003/008] Valid loss: 0.1569
2023-02-06 10:48:54 | Valid | Epoch[236/600] Iteration[004/008] Valid loss: 0.1534
2023-02-06 10:48:54 | Valid | Epoch[236/600] Iteration[005/008] Valid loss: 0.1576
2023-02-06 10:48:54 | Valid | Epoch[236/600] Iteration[006/008] Valid loss: 0.1546
2023-02-06 10:48:54 | Valid | Epoch[236/600] Iteration[007/008] Valid loss: 0.1673
2023-02-06 10:48:54 | Valid | Epoch[236/600] Iteration[008/008] Valid loss: 0.1694
2023-02-06 10:48:54 | Valid | Epoch[236/600] MIou: 0.8934122561244615
2023-02-06 10:48:54 | Valid | Epoch[236/600] Pixel Accuracy: 0.9792124430338541
2023-02-06 10:48:54 | Valid | Epoch[236/600] Mean Pixel Accuracy: 0.9790445434408884
2023-02-06 10:48:54 | Stage | Epoch[236/600] Train loss:0.0281
2023-02-06 10:48:54 | Stage | Epoch[236/600] Valid loss:0.1694
2023-02-06 10:48:54 | Stage | Epoch[236/600] LR:0.01

2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[003/030] Train loss: 0.0272
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[004/030] Train loss: 0.0282
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[005/030] Train loss: 0.0282
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[006/030] Train loss: 0.0287
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[007/030] Train loss: 0.0286
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[008/030] Train loss: 0.0295
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[009/030] Train loss: 0.0302
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[010/030] Train loss: 0.0299
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[011/030] Train loss: 0.0300
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[012/030] Train loss: 0.0302
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[013/030] Train loss: 0.0297
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[014/030] Train loss: 0.0297
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[015/030] Train loss: 0.0295
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[016/030] Train loss: 0.0295
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[017/030] Train loss: 0.0294
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[018/030] Train loss: 0.0294
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[019/030] Train loss: 0.0293
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[020/030] Train loss: 0.0294
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[021/030] Train loss: 0.0292
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[022/030] Train loss: 0.0290
2023-02-06 10:48:55 | Train | Epoch[237/600] Iteration[023/030] Train loss: 0.0290
2023-02-06 10:48:56 | Train | Epoch[237/600] Iteration[024/030] Train loss: 0.0290
2023-02-06 10:48:56 | Train | Epoch[237/600] Iteration[025/030] Train loss: 0.0288
2023-02-06 10:48:56 | Train | Epoch[237/600] Iteration[026/030] Train loss: 0.0288
2023-02-06 10:48:56 | Train | Epoch[237/600] Iteration[027/030] Train loss: 0.0287
2023-02-06 10:48:56 | Train | Epoch[237/600] Iteration[028/030] Train loss: 0.0287
2023-02-06 10:48:56 | Train | Epoch[237/600] Iteration[029/030] Train loss: 0.0287
2023-02-06 10:48:56 | Train | Epoch[237/600] Iteration[030/030] Train loss: 0.0289
2023-02-06 10:48:56 | Valid | Epoch[237/600] Iteration[001/008] Valid loss: 0.3426
2023-02-06 10:48:56 | Valid | Epoch[237/600] Iteration[002/008] Valid loss: 0.3344
2023-02-06 10:48:56 | Valid | Epoch[237/600] Iteration[003/008] Valid loss: 0.3495
2023-02-06 10:48:56 | Valid | Epoch[237/600] Iteration[004/008] Valid loss: 0.3533
2023-02-06 10:48:56 | Valid | Epoch[237/600] Iteration[005/008] Valid loss: 0.3621
2023-02-06 10:48:56 | Valid | Epoch[237/600] Iteration[006/008] Valid loss: 0.3597
2023-02-06 10:48:56 | Valid | Epoch[237/600] Iteration[007/008] Valid loss: 0.3587
2023-02-06 10:48:56 | Valid | Epoch[237/600] Iteration[008/008] Valid loss: 0.3675
2023-02-06 10:48:56 | Valid | Epoch[237/600] MIou: 0.4548409779866536
2023-02-06 10:48:56 | Valid | Epoch[237/600] Pixel Accuracy: 0.9096819559733073
2023-02-06 10:48:56 | Valid | Epoch[237/600] Mean Pixel Accuracy: 0.5
2023-02-06 10:48:56 | Stage | Epoch[237/600] Train loss:0.0289
2023-02-06 10:48:56 | Stage | Epoch[237/600] Valid loss:0.3675
2023-02-06 10:48:56 | Stage | Epoch[237/600] LR:0.01

2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[001/030] Train loss: 0.0235
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[002/030] Train loss: 0.0276
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[003/030] Train loss: 0.0269
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[005/030] Train loss: 0.0276
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[006/030] Train loss: 0.0286
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[007/030] Train loss: 0.0286
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[008/030] Train loss: 0.0288
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[009/030] Train loss: 0.0291
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[010/030] Train loss: 0.0290
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[011/030] Train loss: 0.0291
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[012/030] Train loss: 0.0288
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[013/030] Train loss: 0.0285
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[014/030] Train loss: 0.0286
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[015/030] Train loss: 0.0286
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[016/030] Train loss: 0.0288
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[017/030] Train loss: 0.0285
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[018/030] Train loss: 0.0286
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[019/030] Train loss: 0.0286
2023-02-06 10:48:57 | Train | Epoch[238/600] Iteration[020/030] Train loss: 0.0285
2023-02-06 10:48:58 | Train | Epoch[238/600] Iteration[021/030] Train loss: 0.0284
2023-02-06 10:48:58 | Train | Epoch[238/600] Iteration[022/030] Train loss: 0.0285
2023-02-06 10:48:58 | Train | Epoch[238/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 10:48:58 | Train | Epoch[238/600] Iteration[024/030] Train loss: 0.0287
2023-02-06 10:48:58 | Train | Epoch[238/600] Iteration[025/030] Train loss: 0.0286
2023-02-06 10:48:58 | Train | Epoch[238/600] Iteration[026/030] Train loss: 0.0286
2023-02-06 10:48:58 | Train | Epoch[238/600] Iteration[027/030] Train loss: 0.0286
2023-02-06 10:48:58 | Train | Epoch[238/600] Iteration[028/030] Train loss: 0.0285
2023-02-06 10:48:58 | Train | Epoch[238/600] Iteration[029/030] Train loss: 0.0286
2023-02-06 10:48:58 | Train | Epoch[238/600] Iteration[030/030] Train loss: 0.0286
2023-02-06 10:48:58 | Valid | Epoch[238/600] Iteration[001/008] Valid loss: 0.1202
2023-02-06 10:48:58 | Valid | Epoch[238/600] Iteration[002/008] Valid loss: 0.1202
2023-02-06 10:48:58 | Valid | Epoch[238/600] Iteration[003/008] Valid loss: 0.1249
2023-02-06 10:48:58 | Valid | Epoch[238/600] Iteration[004/008] Valid loss: 0.1243
2023-02-06 10:48:58 | Valid | Epoch[238/600] Iteration[005/008] Valid loss: 0.1269
2023-02-06 10:48:58 | Valid | Epoch[238/600] Iteration[006/008] Valid loss: 0.1242
2023-02-06 10:48:58 | Valid | Epoch[238/600] Iteration[007/008] Valid loss: 0.1209
2023-02-06 10:48:59 | Valid | Epoch[238/600] Iteration[008/008] Valid loss: 0.1248
2023-02-06 10:48:59 | Valid | Epoch[238/600] MIou: 0.6208310289947166
2023-02-06 10:48:59 | Valid | Epoch[238/600] Pixel Accuracy: 0.9373296101888021
2023-02-06 10:48:59 | Valid | Epoch[238/600] Mean Pixel Accuracy: 0.6530572019879204
2023-02-06 10:48:59 | Stage | Epoch[238/600] Train loss:0.0286
2023-02-06 10:48:59 | Stage | Epoch[238/600] Valid loss:0.1248
2023-02-06 10:48:59 | Stage | Epoch[238/600] LR:0.01

2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[001/030] Train loss: 0.0245
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[002/030] Train loss: 0.0259
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[005/030] Train loss: 0.0243
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[012/030] Train loss: 0.0268
2023-02-06 10:48:59 | Train | Epoch[239/600] Iteration[013/030] Train loss: 0.0270
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[014/030] Train loss: 0.0271
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[015/030] Train loss: 0.0273
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[017/030] Train loss: 0.0276
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[018/030] Train loss: 0.0277
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[020/030] Train loss: 0.0279
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[021/030] Train loss: 0.0281
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[022/030] Train loss: 0.0284
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[024/030] Train loss: 0.0285
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[025/030] Train loss: 0.0286
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[026/030] Train loss: 0.0286
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[027/030] Train loss: 0.0287
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[028/030] Train loss: 0.0286
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[029/030] Train loss: 0.0284
2023-02-06 10:49:00 | Train | Epoch[239/600] Iteration[030/030] Train loss: 0.0284
2023-02-06 10:49:01 | Valid | Epoch[239/600] Iteration[001/008] Valid loss: 0.0576
2023-02-06 10:49:01 | Valid | Epoch[239/600] Iteration[002/008] Valid loss: 0.0441
2023-02-06 10:49:01 | Valid | Epoch[239/600] Iteration[003/008] Valid loss: 0.0410
2023-02-06 10:49:01 | Valid | Epoch[239/600] Iteration[004/008] Valid loss: 0.0389
2023-02-06 10:49:01 | Valid | Epoch[239/600] Iteration[005/008] Valid loss: 0.0396
2023-02-06 10:49:01 | Valid | Epoch[239/600] Iteration[006/008] Valid loss: 0.0385
2023-02-06 10:49:01 | Valid | Epoch[239/600] Iteration[007/008] Valid loss: 0.0397
2023-02-06 10:49:01 | Valid | Epoch[239/600] Iteration[008/008] Valid loss: 0.0394
2023-02-06 10:49:01 | Valid | Epoch[239/600] MIou: 0.9316289488187484
2023-02-06 10:49:01 | Valid | Epoch[239/600] Pixel Accuracy: 0.9883626302083334
2023-02-06 10:49:01 | Valid | Epoch[239/600] Mean Pixel Accuracy: 0.9529485019052268
2023-02-06 10:49:01 | Stage | Epoch[239/600] Train loss:0.0284
2023-02-06 10:49:01 | Stage | Epoch[239/600] Valid loss:0.0394
2023-02-06 10:49:01 | Stage | Epoch[239/600] LR:0.01

2023-02-06 10:49:01 | Train | Epoch[240/600] Iteration[001/030] Train loss: 0.0274
2023-02-06 10:49:01 | Train | Epoch[240/600] Iteration[002/030] Train loss: 0.0290
2023-02-06 10:49:01 | Train | Epoch[240/600] Iteration[003/030] Train loss: 0.0284
2023-02-06 10:49:01 | Train | Epoch[240/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 10:49:01 | Train | Epoch[240/600] Iteration[005/030] Train loss: 0.0274
2023-02-06 10:49:01 | Train | Epoch[240/600] Iteration[006/030] Train loss: 0.0281
2023-02-06 10:49:01 | Train | Epoch[240/600] Iteration[007/030] Train loss: 0.0276
2023-02-06 10:49:01 | Train | Epoch[240/600] Iteration[008/030] Train loss: 0.0277
2023-02-06 10:49:01 | Train | Epoch[240/600] Iteration[009/030] Train loss: 0.0278
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[010/030] Train loss: 0.0277
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[011/030] Train loss: 0.0275
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[013/030] Train loss: 0.0278
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[014/030] Train loss: 0.0281
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[015/030] Train loss: 0.0278
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[016/030] Train loss: 0.0279
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[017/030] Train loss: 0.0276
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[018/030] Train loss: 0.0277
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[019/030] Train loss: 0.0279
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[020/030] Train loss: 0.0281
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[021/030] Train loss: 0.0280
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[022/030] Train loss: 0.0279
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[023/030] Train loss: 0.0279
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[024/030] Train loss: 0.0279
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[025/030] Train loss: 0.0280
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[026/030] Train loss: 0.0280
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[028/030] Train loss: 0.0280
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[029/030] Train loss: 0.0281
2023-02-06 10:49:02 | Train | Epoch[240/600] Iteration[030/030] Train loss: 0.0281
2023-02-06 10:49:03 | Valid | Epoch[240/600] Iteration[001/008] Valid loss: 0.0796
2023-02-06 10:49:03 | Valid | Epoch[240/600] Iteration[002/008] Valid loss: 0.0769
2023-02-06 10:49:03 | Valid | Epoch[240/600] Iteration[003/008] Valid loss: 0.0797
2023-02-06 10:49:03 | Valid | Epoch[240/600] Iteration[004/008] Valid loss: 0.0788
2023-02-06 10:49:03 | Valid | Epoch[240/600] Iteration[005/008] Valid loss: 0.0798
2023-02-06 10:49:03 | Valid | Epoch[240/600] Iteration[006/008] Valid loss: 0.0780
2023-02-06 10:49:03 | Valid | Epoch[240/600] Iteration[007/008] Valid loss: 0.0757
2023-02-06 10:49:03 | Valid | Epoch[240/600] Iteration[008/008] Valid loss: 0.0774
2023-02-06 10:49:03 | Valid | Epoch[240/600] MIou: 0.7701320899491025
2023-02-06 10:49:03 | Valid | Epoch[240/600] Pixel Accuracy: 0.962090810139974
2023-02-06 10:49:03 | Valid | Epoch[240/600] Mean Pixel Accuracy: 0.7901350152754509
2023-02-06 10:49:03 | Stage | Epoch[240/600] Train loss:0.0281
2023-02-06 10:49:03 | Stage | Epoch[240/600] Valid loss:0.0774
2023-02-06 10:49:03 | Stage | Epoch[240/600] LR:0.01

2023-02-06 10:49:03 | Train | Epoch[241/600] Iteration[001/030] Train loss: 0.0295
2023-02-06 10:49:03 | Train | Epoch[241/600] Iteration[002/030] Train loss: 0.0294
2023-02-06 10:49:03 | Train | Epoch[241/600] Iteration[003/030] Train loss: 0.0286
2023-02-06 10:49:03 | Train | Epoch[241/600] Iteration[004/030] Train loss: 0.0276
2023-02-06 10:49:03 | Train | Epoch[241/600] Iteration[005/030] Train loss: 0.0280
2023-02-06 10:49:03 | Train | Epoch[241/600] Iteration[006/030] Train loss: 0.0281
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[007/030] Train loss: 0.0280
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[008/030] Train loss: 0.0288
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[009/030] Train loss: 0.0285
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[010/030] Train loss: 0.0282
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[011/030] Train loss: 0.0280
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[012/030] Train loss: 0.0280
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[013/030] Train loss: 0.0281
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[014/030] Train loss: 0.0282
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[015/030] Train loss: 0.0281
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[016/030] Train loss: 0.0280
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[017/030] Train loss: 0.0280
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[018/030] Train loss: 0.0284
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[019/030] Train loss: 0.0285
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[020/030] Train loss: 0.0286
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[021/030] Train loss: 0.0287
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[022/030] Train loss: 0.0288
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[023/030] Train loss: 0.0286
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[024/030] Train loss: 0.0286
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[025/030] Train loss: 0.0287
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[026/030] Train loss: 0.0286
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[027/030] Train loss: 0.0285
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[028/030] Train loss: 0.0284
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[029/030] Train loss: 0.0285
2023-02-06 10:49:04 | Train | Epoch[241/600] Iteration[030/030] Train loss: 0.0284
2023-02-06 10:49:05 | Valid | Epoch[241/600] Iteration[001/008] Valid loss: 0.0798
2023-02-06 10:49:05 | Valid | Epoch[241/600] Iteration[002/008] Valid loss: 0.0615
2023-02-06 10:49:05 | Valid | Epoch[241/600] Iteration[003/008] Valid loss: 0.0581
2023-02-06 10:49:05 | Valid | Epoch[241/600] Iteration[004/008] Valid loss: 0.0562
2023-02-06 10:49:05 | Valid | Epoch[241/600] Iteration[005/008] Valid loss: 0.0580
2023-02-06 10:49:05 | Valid | Epoch[241/600] Iteration[006/008] Valid loss: 0.0575
2023-02-06 10:49:05 | Valid | Epoch[241/600] Iteration[007/008] Valid loss: 0.0620
2023-02-06 10:49:05 | Valid | Epoch[241/600] Iteration[008/008] Valid loss: 0.0608
2023-02-06 10:49:05 | Valid | Epoch[241/600] MIou: 0.932099760784384
2023-02-06 10:49:05 | Valid | Epoch[241/600] Pixel Accuracy: 0.987884521484375
2023-02-06 10:49:05 | Valid | Epoch[241/600] Mean Pixel Accuracy: 0.9755938365328397
2023-02-06 10:49:05 | Stage | Epoch[241/600] Train loss:0.0284
2023-02-06 10:49:05 | Stage | Epoch[241/600] Valid loss:0.0608
2023-02-06 10:49:05 | Stage | Epoch[241/600] LR:0.01

2023-02-06 10:49:05 | Train | Epoch[242/600] Iteration[001/030] Train loss: 0.0291
2023-02-06 10:49:05 | Train | Epoch[242/600] Iteration[002/030] Train loss: 0.0297
2023-02-06 10:49:05 | Train | Epoch[242/600] Iteration[003/030] Train loss: 0.0294
2023-02-06 10:49:05 | Train | Epoch[242/600] Iteration[004/030] Train loss: 0.0291
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[005/030] Train loss: 0.0283
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[006/030] Train loss: 0.0287
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[007/030] Train loss: 0.0283
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[008/030] Train loss: 0.0282
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[009/030] Train loss: 0.0281
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[010/030] Train loss: 0.0283
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[011/030] Train loss: 0.0285
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[012/030] Train loss: 0.0282
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[013/030] Train loss: 0.0281
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[014/030] Train loss: 0.0282
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[015/030] Train loss: 0.0282
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[016/030] Train loss: 0.0285
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[017/030] Train loss: 0.0282
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[018/030] Train loss: 0.0281
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[019/030] Train loss: 0.0280
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[020/030] Train loss: 0.0279
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[021/030] Train loss: 0.0280
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[022/030] Train loss: 0.0277
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[023/030] Train loss: 0.0277
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[024/030] Train loss: 0.0278
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[025/030] Train loss: 0.0277
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[026/030] Train loss: 0.0276
2023-02-06 10:49:06 | Train | Epoch[242/600] Iteration[027/030] Train loss: 0.0278
2023-02-06 10:49:07 | Train | Epoch[242/600] Iteration[028/030] Train loss: 0.0279
2023-02-06 10:49:07 | Train | Epoch[242/600] Iteration[029/030] Train loss: 0.0280
2023-02-06 10:49:07 | Train | Epoch[242/600] Iteration[030/030] Train loss: 0.0280
2023-02-06 10:49:07 | Valid | Epoch[242/600] Iteration[001/008] Valid loss: 0.0416
2023-02-06 10:49:07 | Valid | Epoch[242/600] Iteration[002/008] Valid loss: 0.0400
2023-02-06 10:49:07 | Valid | Epoch[242/600] Iteration[003/008] Valid loss: 0.0411
2023-02-06 10:49:07 | Valid | Epoch[242/600] Iteration[004/008] Valid loss: 0.0400
2023-02-06 10:49:07 | Valid | Epoch[242/600] Iteration[005/008] Valid loss: 0.0406
2023-02-06 10:49:07 | Valid | Epoch[242/600] Iteration[006/008] Valid loss: 0.0401
2023-02-06 10:49:07 | Valid | Epoch[242/600] Iteration[007/008] Valid loss: 0.0395
2023-02-06 10:49:07 | Valid | Epoch[242/600] Iteration[008/008] Valid loss: 0.0399
2023-02-06 10:49:07 | Valid | Epoch[242/600] MIou: 0.8639263768646346
2023-02-06 10:49:07 | Valid | Epoch[242/600] Pixel Accuracy: 0.9775721232096354
2023-02-06 10:49:07 | Valid | Epoch[242/600] Mean Pixel Accuracy: 0.876270597922963
2023-02-06 10:49:07 | Stage | Epoch[242/600] Train loss:0.0280
2023-02-06 10:49:07 | Stage | Epoch[242/600] Valid loss:0.0399
2023-02-06 10:49:07 | Stage | Epoch[242/600] LR:0.01

2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[001/030] Train loss: 0.0241
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[002/030] Train loss: 0.0251
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[003/030] Train loss: 0.0248
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[004/030] Train loss: 0.0257
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[008/030] Train loss: 0.0274
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[009/030] Train loss: 0.0273
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[012/030] Train loss: 0.0276
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[013/030] Train loss: 0.0276
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[014/030] Train loss: 0.0280
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[015/030] Train loss: 0.0279
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[016/030] Train loss: 0.0278
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[017/030] Train loss: 0.0280
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[018/030] Train loss: 0.0279
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[019/030] Train loss: 0.0280
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[020/030] Train loss: 0.0281
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[021/030] Train loss: 0.0280
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[022/030] Train loss: 0.0279
2023-02-06 10:49:08 | Train | Epoch[243/600] Iteration[023/030] Train loss: 0.0279
2023-02-06 10:49:09 | Train | Epoch[243/600] Iteration[024/030] Train loss: 0.0277
2023-02-06 10:49:09 | Train | Epoch[243/600] Iteration[025/030] Train loss: 0.0278
2023-02-06 10:49:09 | Train | Epoch[243/600] Iteration[026/030] Train loss: 0.0279
2023-02-06 10:49:09 | Train | Epoch[243/600] Iteration[027/030] Train loss: 0.0278
2023-02-06 10:49:09 | Train | Epoch[243/600] Iteration[028/030] Train loss: 0.0279
2023-02-06 10:49:09 | Train | Epoch[243/600] Iteration[029/030] Train loss: 0.0278
2023-02-06 10:49:09 | Train | Epoch[243/600] Iteration[030/030] Train loss: 0.0279
2023-02-06 10:49:09 | Valid | Epoch[243/600] Iteration[001/008] Valid loss: 0.0666
2023-02-06 10:49:09 | Valid | Epoch[243/600] Iteration[002/008] Valid loss: 0.0663
2023-02-06 10:49:09 | Valid | Epoch[243/600] Iteration[003/008] Valid loss: 0.0688
2023-02-06 10:49:09 | Valid | Epoch[243/600] Iteration[004/008] Valid loss: 0.0680
2023-02-06 10:49:09 | Valid | Epoch[243/600] Iteration[005/008] Valid loss: 0.0691
2023-02-06 10:49:09 | Valid | Epoch[243/600] Iteration[006/008] Valid loss: 0.0678
2023-02-06 10:49:09 | Valid | Epoch[243/600] Iteration[007/008] Valid loss: 0.0660
2023-02-06 10:49:09 | Valid | Epoch[243/600] Iteration[008/008] Valid loss: 0.0677
2023-02-06 10:49:09 | Valid | Epoch[243/600] MIou: 0.7695942503801418
2023-02-06 10:49:09 | Valid | Epoch[243/600] Pixel Accuracy: 0.9620018005371094
2023-02-06 10:49:09 | Valid | Epoch[243/600] Mean Pixel Accuracy: 0.7896422587957032
2023-02-06 10:49:09 | Stage | Epoch[243/600] Train loss:0.0279
2023-02-06 10:49:09 | Stage | Epoch[243/600] Valid loss:0.0677
2023-02-06 10:49:09 | Stage | Epoch[243/600] LR:0.01

2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[001/030] Train loss: 0.0277
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[002/030] Train loss: 0.0278
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[004/030] Train loss: 0.0269
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[005/030] Train loss: 0.0279
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[006/030] Train loss: 0.0287
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[007/030] Train loss: 0.0297
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[008/030] Train loss: 0.0289
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[009/030] Train loss: 0.0288
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[011/030] Train loss: 0.0291
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[012/030] Train loss: 0.0292
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[013/030] Train loss: 0.0297
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[014/030] Train loss: 0.0294
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[015/030] Train loss: 0.0290
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[016/030] Train loss: 0.0287
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[017/030] Train loss: 0.0286
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[018/030] Train loss: 0.0288
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[019/030] Train loss: 0.0287
2023-02-06 10:49:10 | Train | Epoch[244/600] Iteration[020/030] Train loss: 0.0288
2023-02-06 10:49:11 | Train | Epoch[244/600] Iteration[021/030] Train loss: 0.0285
2023-02-06 10:49:11 | Train | Epoch[244/600] Iteration[022/030] Train loss: 0.0287
2023-02-06 10:49:11 | Train | Epoch[244/600] Iteration[023/030] Train loss: 0.0286
2023-02-06 10:49:11 | Train | Epoch[244/600] Iteration[024/030] Train loss: 0.0284
2023-02-06 10:49:11 | Train | Epoch[244/600] Iteration[025/030] Train loss: 0.0283
2023-02-06 10:49:11 | Train | Epoch[244/600] Iteration[026/030] Train loss: 0.0282
2023-02-06 10:49:11 | Train | Epoch[244/600] Iteration[027/030] Train loss: 0.0281
2023-02-06 10:49:11 | Train | Epoch[244/600] Iteration[028/030] Train loss: 0.0281
2023-02-06 10:49:11 | Train | Epoch[244/600] Iteration[029/030] Train loss: 0.0282
2023-02-06 10:49:11 | Train | Epoch[244/600] Iteration[030/030] Train loss: 0.0281
2023-02-06 10:49:11 | Valid | Epoch[244/600] Iteration[001/008] Valid loss: 0.0485
2023-02-06 10:49:11 | Valid | Epoch[244/600] Iteration[002/008] Valid loss: 0.0391
2023-02-06 10:49:11 | Valid | Epoch[244/600] Iteration[003/008] Valid loss: 0.0376
2023-02-06 10:49:11 | Valid | Epoch[244/600] Iteration[004/008] Valid loss: 0.0362
2023-02-06 10:49:11 | Valid | Epoch[244/600] Iteration[005/008] Valid loss: 0.0373
2023-02-06 10:49:11 | Valid | Epoch[244/600] Iteration[006/008] Valid loss: 0.0370
2023-02-06 10:49:11 | Valid | Epoch[244/600] Iteration[007/008] Valid loss: 0.0388
2023-02-06 10:49:11 | Valid | Epoch[244/600] Iteration[008/008] Valid loss: 0.0382
2023-02-06 10:49:12 | Valid | Epoch[244/600] MIou: 0.9366732921260685
2023-02-06 10:49:12 | Valid | Epoch[244/600] Pixel Accuracy: 0.9891535441080729
2023-02-06 10:49:12 | Valid | Epoch[244/600] Mean Pixel Accuracy: 0.960643061797517
2023-02-06 10:49:12 | Stage | Epoch[244/600] Train loss:0.0281
2023-02-06 10:49:12 | Stage | Epoch[244/600] Valid loss:0.0382
2023-02-06 10:49:12 | Stage | Epoch[244/600] LR:0.01

2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[006/030] Train loss: 0.0277
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[007/030] Train loss: 0.0280
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[008/030] Train loss: 0.0282
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[009/030] Train loss: 0.0279
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[010/030] Train loss: 0.0277
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[011/030] Train loss: 0.0275
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[012/030] Train loss: 0.0276
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[014/030] Train loss: 0.0277
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[015/030] Train loss: 0.0276
2023-02-06 10:49:12 | Train | Epoch[245/600] Iteration[016/030] Train loss: 0.0276
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[017/030] Train loss: 0.0275
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[018/030] Train loss: 0.0276
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[019/030] Train loss: 0.0273
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[020/030] Train loss: 0.0273
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[021/030] Train loss: 0.0275
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[022/030] Train loss: 0.0277
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[023/030] Train loss: 0.0277
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[024/030] Train loss: 0.0277
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[025/030] Train loss: 0.0277
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[026/030] Train loss: 0.0276
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[027/030] Train loss: 0.0276
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[028/030] Train loss: 0.0277
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[029/030] Train loss: 0.0279
2023-02-06 10:49:13 | Train | Epoch[245/600] Iteration[030/030] Train loss: 0.0279
2023-02-06 10:49:13 | Valid | Epoch[245/600] Iteration[001/008] Valid loss: 0.0606
2023-02-06 10:49:13 | Valid | Epoch[245/600] Iteration[002/008] Valid loss: 0.0467
2023-02-06 10:49:13 | Valid | Epoch[245/600] Iteration[003/008] Valid loss: 0.0444
2023-02-06 10:49:13 | Valid | Epoch[245/600] Iteration[004/008] Valid loss: 0.0424
2023-02-06 10:49:14 | Valid | Epoch[245/600] Iteration[005/008] Valid loss: 0.0433
2023-02-06 10:49:14 | Valid | Epoch[245/600] Iteration[006/008] Valid loss: 0.0425
2023-02-06 10:49:14 | Valid | Epoch[245/600] Iteration[007/008] Valid loss: 0.0445
2023-02-06 10:49:14 | Valid | Epoch[245/600] Iteration[008/008] Valid loss: 0.0437
2023-02-06 10:49:14 | Valid | Epoch[245/600] MIou: 0.9381904041573089
2023-02-06 10:49:14 | Valid | Epoch[245/600] Pixel Accuracy: 0.9893747965494791
2023-02-06 10:49:14 | Valid | Epoch[245/600] Mean Pixel Accuracy: 0.9637954169582765
2023-02-06 10:49:14 | Stage | Epoch[245/600] Train loss:0.0279
2023-02-06 10:49:14 | Stage | Epoch[245/600] Valid loss:0.0437
2023-02-06 10:49:14 | Stage | Epoch[245/600] LR:0.01

2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[002/030] Train loss: 0.0283
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[003/030] Train loss: 0.0294
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[004/030] Train loss: 0.0281
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[005/030] Train loss: 0.0278
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[007/030] Train loss: 0.0274
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[008/030] Train loss: 0.0275
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[009/030] Train loss: 0.0277
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[010/030] Train loss: 0.0281
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[011/030] Train loss: 0.0283
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[012/030] Train loss: 0.0286
2023-02-06 10:49:14 | Train | Epoch[246/600] Iteration[013/030] Train loss: 0.0290
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[014/030] Train loss: 0.0292
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[015/030] Train loss: 0.0289
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[016/030] Train loss: 0.0287
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[017/030] Train loss: 0.0287
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[018/030] Train loss: 0.0286
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[019/030] Train loss: 0.0289
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[020/030] Train loss: 0.0289
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[021/030] Train loss: 0.0289
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[022/030] Train loss: 0.0286
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[024/030] Train loss: 0.0285
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[025/030] Train loss: 0.0285
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[026/030] Train loss: 0.0284
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[027/030] Train loss: 0.0285
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[028/030] Train loss: 0.0284
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[029/030] Train loss: 0.0284
2023-02-06 10:49:15 | Train | Epoch[246/600] Iteration[030/030] Train loss: 0.0283
2023-02-06 10:49:16 | Valid | Epoch[246/600] Iteration[001/008] Valid loss: 0.1725
2023-02-06 10:49:16 | Valid | Epoch[246/600] Iteration[002/008] Valid loss: 0.1251
2023-02-06 10:49:16 | Valid | Epoch[246/600] Iteration[003/008] Valid loss: 0.1168
2023-02-06 10:49:16 | Valid | Epoch[246/600] Iteration[004/008] Valid loss: 0.1137
2023-02-06 10:49:16 | Valid | Epoch[246/600] Iteration[005/008] Valid loss: 0.1160
2023-02-06 10:49:16 | Valid | Epoch[246/600] Iteration[006/008] Valid loss: 0.1130
2023-02-06 10:49:16 | Valid | Epoch[246/600] Iteration[007/008] Valid loss: 0.1233
2023-02-06 10:49:16 | Valid | Epoch[246/600] Iteration[008/008] Valid loss: 0.1221
2023-02-06 10:49:16 | Valid | Epoch[246/600] MIou: 0.918266085945497
2023-02-06 10:49:16 | Valid | Epoch[246/600] Pixel Accuracy: 0.9848925272623698
2023-02-06 10:49:16 | Valid | Epoch[246/600] Mean Pixel Accuracy: 0.9787870886666753
2023-02-06 10:49:16 | Stage | Epoch[246/600] Train loss:0.0283
2023-02-06 10:49:16 | Stage | Epoch[246/600] Valid loss:0.1221
2023-02-06 10:49:16 | Stage | Epoch[246/600] LR:0.01

2023-02-06 10:49:16 | Train | Epoch[247/600] Iteration[001/030] Train loss: 0.0284
2023-02-06 10:49:16 | Train | Epoch[247/600] Iteration[002/030] Train loss: 0.0269
2023-02-06 10:49:16 | Train | Epoch[247/600] Iteration[003/030] Train loss: 0.0275
2023-02-06 10:49:16 | Train | Epoch[247/600] Iteration[004/030] Train loss: 0.0278
2023-02-06 10:49:16 | Train | Epoch[247/600] Iteration[005/030] Train loss: 0.0278
2023-02-06 10:49:16 | Train | Epoch[247/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 10:49:16 | Train | Epoch[247/600] Iteration[007/030] Train loss: 0.0272
2023-02-06 10:49:16 | Train | Epoch[247/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 10:49:16 | Train | Epoch[247/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 10:49:16 | Train | Epoch[247/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[012/030] Train loss: 0.0271
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[014/030] Train loss: 0.0276
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[015/030] Train loss: 0.0274
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[016/030] Train loss: 0.0276
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[017/030] Train loss: 0.0278
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[018/030] Train loss: 0.0282
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[019/030] Train loss: 0.0280
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[020/030] Train loss: 0.0280
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[021/030] Train loss: 0.0280
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[022/030] Train loss: 0.0280
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[023/030] Train loss: 0.0279
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[024/030] Train loss: 0.0281
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[025/030] Train loss: 0.0279
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[026/030] Train loss: 0.0278
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[027/030] Train loss: 0.0278
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[028/030] Train loss: 0.0279
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[029/030] Train loss: 0.0278
2023-02-06 10:49:17 | Train | Epoch[247/600] Iteration[030/030] Train loss: 0.0278
2023-02-06 10:49:18 | Valid | Epoch[247/600] Iteration[001/008] Valid loss: 0.2742
2023-02-06 10:49:18 | Valid | Epoch[247/600] Iteration[002/008] Valid loss: 0.2275
2023-02-06 10:49:18 | Valid | Epoch[247/600] Iteration[003/008] Valid loss: 0.2126
2023-02-06 10:49:18 | Valid | Epoch[247/600] Iteration[004/008] Valid loss: 0.2116
2023-02-06 10:49:18 | Valid | Epoch[247/600] Iteration[005/008] Valid loss: 0.2188
2023-02-06 10:49:18 | Valid | Epoch[247/600] Iteration[006/008] Valid loss: 0.2197
2023-02-06 10:49:18 | Valid | Epoch[247/600] Iteration[007/008] Valid loss: 0.2368
2023-02-06 10:49:18 | Valid | Epoch[247/600] Iteration[008/008] Valid loss: 0.2323
2023-02-06 10:49:18 | Valid | Epoch[247/600] MIou: 0.8850481307097859
2023-02-06 10:49:18 | Valid | Epoch[247/600] Pixel Accuracy: 0.9770291646321615
2023-02-06 10:49:18 | Valid | Epoch[247/600] Mean Pixel Accuracy: 0.9820799554868156
2023-02-06 10:49:18 | Stage | Epoch[247/600] Train loss:0.0278
2023-02-06 10:49:18 | Stage | Epoch[247/600] Valid loss:0.2323
2023-02-06 10:49:18 | Stage | Epoch[247/600] LR:0.01

2023-02-06 10:49:18 | Train | Epoch[248/600] Iteration[001/030] Train loss: 0.0282
2023-02-06 10:49:18 | Train | Epoch[248/600] Iteration[002/030] Train loss: 0.0275
2023-02-06 10:49:18 | Train | Epoch[248/600] Iteration[003/030] Train loss: 0.0282
2023-02-06 10:49:18 | Train | Epoch[248/600] Iteration[004/030] Train loss: 0.0278
2023-02-06 10:49:18 | Train | Epoch[248/600] Iteration[005/030] Train loss: 0.0283
2023-02-06 10:49:18 | Train | Epoch[248/600] Iteration[006/030] Train loss: 0.0287
2023-02-06 10:49:18 | Train | Epoch[248/600] Iteration[007/030] Train loss: 0.0285
2023-02-06 10:49:18 | Train | Epoch[248/600] Iteration[008/030] Train loss: 0.0282
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[009/030] Train loss: 0.0281
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[010/030] Train loss: 0.0279
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[011/030] Train loss: 0.0285
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[012/030] Train loss: 0.0282
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[013/030] Train loss: 0.0282
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[014/030] Train loss: 0.0283
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[015/030] Train loss: 0.0285
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[016/030] Train loss: 0.0287
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[017/030] Train loss: 0.0286
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[018/030] Train loss: 0.0285
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[019/030] Train loss: 0.0284
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[020/030] Train loss: 0.0284
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[021/030] Train loss: 0.0283
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[022/030] Train loss: 0.0282
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[023/030] Train loss: 0.0281
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[024/030] Train loss: 0.0281
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[025/030] Train loss: 0.0279
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[026/030] Train loss: 0.0277
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[027/030] Train loss: 0.0277
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[028/030] Train loss: 0.0277
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[029/030] Train loss: 0.0278
2023-02-06 10:49:19 | Train | Epoch[248/600] Iteration[030/030] Train loss: 0.0278
2023-02-06 10:49:20 | Valid | Epoch[248/600] Iteration[001/008] Valid loss: 0.0805
2023-02-06 10:49:20 | Valid | Epoch[248/600] Iteration[002/008] Valid loss: 0.0611
2023-02-06 10:49:20 | Valid | Epoch[248/600] Iteration[003/008] Valid loss: 0.0548
2023-02-06 10:49:20 | Valid | Epoch[248/600] Iteration[004/008] Valid loss: 0.0522
2023-02-06 10:49:20 | Valid | Epoch[248/600] Iteration[005/008] Valid loss: 0.0518
2023-02-06 10:49:20 | Valid | Epoch[248/600] Iteration[006/008] Valid loss: 0.0510
2023-02-06 10:49:20 | Valid | Epoch[248/600] Iteration[007/008] Valid loss: 0.0539
2023-02-06 10:49:20 | Valid | Epoch[248/600] Iteration[008/008] Valid loss: 0.0532
2023-02-06 10:49:20 | Valid | Epoch[248/600] MIou: 0.9319241560822984
2023-02-06 10:49:20 | Valid | Epoch[248/600] Pixel Accuracy: 0.9881426493326823
2023-02-06 10:49:20 | Valid | Epoch[248/600] Mean Pixel Accuracy: 0.963904394765615
2023-02-06 10:49:20 | Stage | Epoch[248/600] Train loss:0.0278
2023-02-06 10:49:20 | Stage | Epoch[248/600] Valid loss:0.0532
2023-02-06 10:49:20 | Stage | Epoch[248/600] LR:0.01

2023-02-06 10:49:20 | Train | Epoch[249/600] Iteration[001/030] Train loss: 0.0286
2023-02-06 10:49:20 | Train | Epoch[249/600] Iteration[002/030] Train loss: 0.0285
2023-02-06 10:49:20 | Train | Epoch[249/600] Iteration[003/030] Train loss: 0.0294
2023-02-06 10:49:20 | Train | Epoch[249/600] Iteration[004/030] Train loss: 0.0291
2023-02-06 10:49:20 | Train | Epoch[249/600] Iteration[005/030] Train loss: 0.0284
2023-02-06 10:49:20 | Train | Epoch[249/600] Iteration[006/030] Train loss: 0.0282
2023-02-06 10:49:20 | Train | Epoch[249/600] Iteration[007/030] Train loss: 0.0281
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[008/030] Train loss: 0.0286
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[009/030] Train loss: 0.0281
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[011/030] Train loss: 0.0282
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[012/030] Train loss: 0.0283
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[013/030] Train loss: 0.0280
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[014/030] Train loss: 0.0280
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[015/030] Train loss: 0.0280
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[016/030] Train loss: 0.0281
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[017/030] Train loss: 0.0282
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[018/030] Train loss: 0.0284
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[019/030] Train loss: 0.0285
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[020/030] Train loss: 0.0285
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[021/030] Train loss: 0.0283
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[022/030] Train loss: 0.0280
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[023/030] Train loss: 0.0280
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[024/030] Train loss: 0.0281
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[025/030] Train loss: 0.0282
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[026/030] Train loss: 0.0282
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[027/030] Train loss: 0.0280
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[028/030] Train loss: 0.0280
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[029/030] Train loss: 0.0283
2023-02-06 10:49:21 | Train | Epoch[249/600] Iteration[030/030] Train loss: 0.0282
2023-02-06 10:49:22 | Valid | Epoch[249/600] Iteration[001/008] Valid loss: 1.1903
2023-02-06 10:49:22 | Valid | Epoch[249/600] Iteration[002/008] Valid loss: 1.2614
2023-02-06 10:49:22 | Valid | Epoch[249/600] Iteration[003/008] Valid loss: 1.2592
2023-02-06 10:49:22 | Valid | Epoch[249/600] Iteration[004/008] Valid loss: 1.2944
2023-02-06 10:49:22 | Valid | Epoch[249/600] Iteration[005/008] Valid loss: 1.3225
2023-02-06 10:49:22 | Valid | Epoch[249/600] Iteration[006/008] Valid loss: 1.3040
2023-02-06 10:49:22 | Valid | Epoch[249/600] Iteration[007/008] Valid loss: 1.3622
2023-02-06 10:49:22 | Valid | Epoch[249/600] Iteration[008/008] Valid loss: 1.4210
2023-02-06 10:49:22 | Valid | Epoch[249/600] MIou: 0.7998085558060181
2023-02-06 10:49:22 | Valid | Epoch[249/600] Pixel Accuracy: 0.9520772298177084
2023-02-06 10:49:22 | Valid | Epoch[249/600] Mean Pixel Accuracy: 0.9715482246375748
2023-02-06 10:49:22 | Stage | Epoch[249/600] Train loss:0.0282
2023-02-06 10:49:22 | Stage | Epoch[249/600] Valid loss:1.4210
2023-02-06 10:49:22 | Stage | Epoch[249/600] LR:0.01

2023-02-06 10:49:22 | Train | Epoch[250/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 10:49:22 | Train | Epoch[250/600] Iteration[002/030] Train loss: 0.0281
2023-02-06 10:49:22 | Train | Epoch[250/600] Iteration[003/030] Train loss: 0.0279
2023-02-06 10:49:22 | Train | Epoch[250/600] Iteration[004/030] Train loss: 0.0280
2023-02-06 10:49:22 | Train | Epoch[250/600] Iteration[005/030] Train loss: 0.0287
2023-02-06 10:49:22 | Train | Epoch[250/600] Iteration[006/030] Train loss: 0.0295
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[007/030] Train loss: 0.0285
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[008/030] Train loss: 0.0287
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[009/030] Train loss: 0.0285
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[010/030] Train loss: 0.0284
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[011/030] Train loss: 0.0287
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[012/030] Train loss: 0.0285
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[013/030] Train loss: 0.0283
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[014/030] Train loss: 0.0281
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[015/030] Train loss: 0.0285
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[016/030] Train loss: 0.0282
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[017/030] Train loss: 0.0281
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[018/030] Train loss: 0.0280
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[019/030] Train loss: 0.0283
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[020/030] Train loss: 0.0282
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[021/030] Train loss: 0.0281
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[022/030] Train loss: 0.0281
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[023/030] Train loss: 0.0280
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[024/030] Train loss: 0.0282
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[025/030] Train loss: 0.0282
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[026/030] Train loss: 0.0283
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[027/030] Train loss: 0.0282
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[028/030] Train loss: 0.0285
2023-02-06 10:49:23 | Train | Epoch[250/600] Iteration[029/030] Train loss: 0.0285
2023-02-06 10:49:24 | Train | Epoch[250/600] Iteration[030/030] Train loss: 0.0289
2023-02-06 10:49:24 | Valid | Epoch[250/600] Iteration[001/008] Valid loss: 2.3824
2023-02-06 10:49:24 | Valid | Epoch[250/600] Iteration[002/008] Valid loss: 2.3894
2023-02-06 10:49:24 | Valid | Epoch[250/600] Iteration[003/008] Valid loss: 2.3863
2023-02-06 10:49:24 | Valid | Epoch[250/600] Iteration[004/008] Valid loss: 2.4482
2023-02-06 10:49:24 | Valid | Epoch[250/600] Iteration[005/008] Valid loss: 2.4924
2023-02-06 10:49:24 | Valid | Epoch[250/600] Iteration[006/008] Valid loss: 2.5175
2023-02-06 10:49:24 | Valid | Epoch[250/600] Iteration[007/008] Valid loss: 2.6238
2023-02-06 10:49:24 | Valid | Epoch[250/600] Iteration[008/008] Valid loss: 2.6716
2023-02-06 10:49:24 | Valid | Epoch[250/600] MIou: 0.7175892929345535
2023-02-06 10:49:24 | Valid | Epoch[250/600] Pixel Accuracy: 0.9183794657389323
2023-02-06 10:49:24 | Valid | Epoch[250/600] Mean Pixel Accuracy: 0.9544087191146347
2023-02-06 10:49:24 | Stage | Epoch[250/600] Train loss:0.0289
2023-02-06 10:49:24 | Stage | Epoch[250/600] Valid loss:2.6716
2023-02-06 10:49:24 | Stage | Epoch[250/600] LR:0.01

2023-02-06 10:49:24 | Train | Epoch[251/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 10:49:24 | Train | Epoch[251/600] Iteration[002/030] Train loss: 0.0281
2023-02-06 10:49:24 | Train | Epoch[251/600] Iteration[003/030] Train loss: 0.0282
2023-02-06 10:49:24 | Train | Epoch[251/600] Iteration[004/030] Train loss: 0.0283
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[005/030] Train loss: 0.0294
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[006/030] Train loss: 0.0288
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[007/030] Train loss: 0.0289
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[008/030] Train loss: 0.0284
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[009/030] Train loss: 0.0280
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[010/030] Train loss: 0.0285
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[011/030] Train loss: 0.0284
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[012/030] Train loss: 0.0283
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[013/030] Train loss: 0.0283
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[014/030] Train loss: 0.0281
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[015/030] Train loss: 0.0280
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[016/030] Train loss: 0.0279
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[017/030] Train loss: 0.0277
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[018/030] Train loss: 0.0276
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[020/030] Train loss: 0.0277
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[021/030] Train loss: 0.0278
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[022/030] Train loss: 0.0281
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[023/030] Train loss: 0.0281
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[024/030] Train loss: 0.0283
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[025/030] Train loss: 0.0282
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[026/030] Train loss: 0.0283
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[027/030] Train loss: 0.0286
2023-02-06 10:49:25 | Train | Epoch[251/600] Iteration[028/030] Train loss: 0.0285
2023-02-06 10:49:26 | Train | Epoch[251/600] Iteration[029/030] Train loss: 0.0285
2023-02-06 10:49:26 | Train | Epoch[251/600] Iteration[030/030] Train loss: 0.0284
2023-02-06 10:49:26 | Valid | Epoch[251/600] Iteration[001/008] Valid loss: 0.0893
2023-02-06 10:49:26 | Valid | Epoch[251/600] Iteration[002/008] Valid loss: 0.0874
2023-02-06 10:49:26 | Valid | Epoch[251/600] Iteration[003/008] Valid loss: 0.0902
2023-02-06 10:49:26 | Valid | Epoch[251/600] Iteration[004/008] Valid loss: 0.0896
2023-02-06 10:49:26 | Valid | Epoch[251/600] Iteration[005/008] Valid loss: 0.0909
2023-02-06 10:49:26 | Valid | Epoch[251/600] Iteration[006/008] Valid loss: 0.0893
2023-02-06 10:49:26 | Valid | Epoch[251/600] Iteration[007/008] Valid loss: 0.0871
2023-02-06 10:49:26 | Valid | Epoch[251/600] Iteration[008/008] Valid loss: 0.0890
2023-02-06 10:49:26 | Valid | Epoch[251/600] MIou: 0.7265099073304262
2023-02-06 10:49:26 | Valid | Epoch[251/600] Pixel Accuracy: 0.9548670450846354
2023-02-06 10:49:26 | Valid | Epoch[251/600] Mean Pixel Accuracy: 0.7501443072547833
2023-02-06 10:49:26 | Stage | Epoch[251/600] Train loss:0.0284
2023-02-06 10:49:26 | Stage | Epoch[251/600] Valid loss:0.0890
2023-02-06 10:49:26 | Stage | Epoch[251/600] LR:0.01

2023-02-06 10:49:26 | Train | Epoch[252/600] Iteration[001/030] Train loss: 0.0276
2023-02-06 10:49:26 | Train | Epoch[252/600] Iteration[002/030] Train loss: 0.0261
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[004/030] Train loss: 0.0267
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[005/030] Train loss: 0.0280
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[006/030] Train loss: 0.0275
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[007/030] Train loss: 0.0272
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[008/030] Train loss: 0.0276
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[009/030] Train loss: 0.0280
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[010/030] Train loss: 0.0279
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[011/030] Train loss: 0.0278
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[012/030] Train loss: 0.0279
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[013/030] Train loss: 0.0282
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[014/030] Train loss: 0.0282
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[015/030] Train loss: 0.0280
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[016/030] Train loss: 0.0281
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[017/030] Train loss: 0.0279
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[018/030] Train loss: 0.0278
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[019/030] Train loss: 0.0278
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[020/030] Train loss: 0.0278
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[022/030] Train loss: 0.0276
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[023/030] Train loss: 0.0276
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[024/030] Train loss: 0.0277
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[025/030] Train loss: 0.0275
2023-02-06 10:49:27 | Train | Epoch[252/600] Iteration[026/030] Train loss: 0.0273
2023-02-06 10:49:28 | Train | Epoch[252/600] Iteration[027/030] Train loss: 0.0275
2023-02-06 10:49:28 | Train | Epoch[252/600] Iteration[028/030] Train loss: 0.0276
2023-02-06 10:49:28 | Train | Epoch[252/600] Iteration[029/030] Train loss: 0.0276
2023-02-06 10:49:28 | Train | Epoch[252/600] Iteration[030/030] Train loss: 0.0277
2023-02-06 10:49:28 | Valid | Epoch[252/600] Iteration[001/008] Valid loss: 0.0385
2023-02-06 10:49:28 | Valid | Epoch[252/600] Iteration[002/008] Valid loss: 0.0348
2023-02-06 10:49:28 | Valid | Epoch[252/600] Iteration[003/008] Valid loss: 0.0348
2023-02-06 10:49:28 | Valid | Epoch[252/600] Iteration[004/008] Valid loss: 0.0336
2023-02-06 10:49:28 | Valid | Epoch[252/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 10:49:28 | Valid | Epoch[252/600] Iteration[006/008] Valid loss: 0.0337
2023-02-06 10:49:28 | Valid | Epoch[252/600] Iteration[007/008] Valid loss: 0.0335
2023-02-06 10:49:28 | Valid | Epoch[252/600] Iteration[008/008] Valid loss: 0.0337
2023-02-06 10:49:28 | Valid | Epoch[252/600] MIou: 0.9009313269884447
2023-02-06 10:49:28 | Valid | Epoch[252/600] Pixel Accuracy: 0.9835281372070312
2023-02-06 10:49:28 | Valid | Epoch[252/600] Mean Pixel Accuracy: 0.9139159733007698
2023-02-06 10:49:28 | Stage | Epoch[252/600] Train loss:0.0277
2023-02-06 10:49:28 | Stage | Epoch[252/600] Valid loss:0.0337
2023-02-06 10:49:28 | Stage | Epoch[252/600] LR:0.01

2023-02-06 10:49:28 | Train | Epoch[253/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 10:49:28 | Train | Epoch[253/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[006/030] Train loss: 0.0258
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[009/030] Train loss: 0.0260
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[011/030] Train loss: 0.0262
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[013/030] Train loss: 0.0268
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[014/030] Train loss: 0.0270
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[015/030] Train loss: 0.0271
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[016/030] Train loss: 0.0271
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[017/030] Train loss: 0.0275
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[018/030] Train loss: 0.0278
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[019/030] Train loss: 0.0278
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[020/030] Train loss: 0.0280
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[021/030] Train loss: 0.0279
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[022/030] Train loss: 0.0280
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[023/030] Train loss: 0.0279
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[024/030] Train loss: 0.0278
2023-02-06 10:49:29 | Train | Epoch[253/600] Iteration[025/030] Train loss: 0.0280
2023-02-06 10:49:30 | Train | Epoch[253/600] Iteration[026/030] Train loss: 0.0280
2023-02-06 10:49:30 | Train | Epoch[253/600] Iteration[027/030] Train loss: 0.0280
2023-02-06 10:49:30 | Train | Epoch[253/600] Iteration[028/030] Train loss: 0.0279
2023-02-06 10:49:30 | Train | Epoch[253/600] Iteration[029/030] Train loss: 0.0278
2023-02-06 10:49:30 | Train | Epoch[253/600] Iteration[030/030] Train loss: 0.0279
2023-02-06 10:49:30 | Valid | Epoch[253/600] Iteration[001/008] Valid loss: 0.0437
2023-02-06 10:49:30 | Valid | Epoch[253/600] Iteration[002/008] Valid loss: 0.0366
2023-02-06 10:49:30 | Valid | Epoch[253/600] Iteration[003/008] Valid loss: 0.0351
2023-02-06 10:49:30 | Valid | Epoch[253/600] Iteration[004/008] Valid loss: 0.0339
2023-02-06 10:49:30 | Valid | Epoch[253/600] Iteration[005/008] Valid loss: 0.0346
2023-02-06 10:49:30 | Valid | Epoch[253/600] Iteration[006/008] Valid loss: 0.0341
2023-02-06 10:49:30 | Valid | Epoch[253/600] Iteration[007/008] Valid loss: 0.0347
2023-02-06 10:49:30 | Valid | Epoch[253/600] Iteration[008/008] Valid loss: 0.0345
2023-02-06 10:49:30 | Valid | Epoch[253/600] MIou: 0.9216918876378798
2023-02-06 10:49:30 | Valid | Epoch[253/600] Pixel Accuracy: 0.9868036905924479
2023-02-06 10:49:30 | Valid | Epoch[253/600] Mean Pixel Accuracy: 0.9390683137193576
2023-02-06 10:49:30 | Stage | Epoch[253/600] Train loss:0.0279
2023-02-06 10:49:30 | Stage | Epoch[253/600] Valid loss:0.0345
2023-02-06 10:49:30 | Stage | Epoch[253/600] LR:0.01

2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[002/030] Train loss: 0.0236
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[003/030] Train loss: 0.0250
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[004/030] Train loss: 0.0262
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[005/030] Train loss: 0.0258
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[013/030] Train loss: 0.0268
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[015/030] Train loss: 0.0265
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[016/030] Train loss: 0.0266
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[018/030] Train loss: 0.0269
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[019/030] Train loss: 0.0271
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[021/030] Train loss: 0.0270
2023-02-06 10:49:31 | Train | Epoch[254/600] Iteration[022/030] Train loss: 0.0272
2023-02-06 10:49:32 | Train | Epoch[254/600] Iteration[023/030] Train loss: 0.0271
2023-02-06 10:49:32 | Train | Epoch[254/600] Iteration[024/030] Train loss: 0.0271
2023-02-06 10:49:32 | Train | Epoch[254/600] Iteration[025/030] Train loss: 0.0272
2023-02-06 10:49:32 | Train | Epoch[254/600] Iteration[026/030] Train loss: 0.0272
2023-02-06 10:49:32 | Train | Epoch[254/600] Iteration[027/030] Train loss: 0.0271
2023-02-06 10:49:32 | Train | Epoch[254/600] Iteration[028/030] Train loss: 0.0274
2023-02-06 10:49:32 | Train | Epoch[254/600] Iteration[029/030] Train loss: 0.0273
2023-02-06 10:49:32 | Train | Epoch[254/600] Iteration[030/030] Train loss: 0.0274
2023-02-06 10:49:32 | Valid | Epoch[254/600] Iteration[001/008] Valid loss: 0.0390
2023-02-06 10:49:32 | Valid | Epoch[254/600] Iteration[002/008] Valid loss: 0.0330
2023-02-06 10:49:32 | Valid | Epoch[254/600] Iteration[003/008] Valid loss: 0.0324
2023-02-06 10:49:32 | Valid | Epoch[254/600] Iteration[004/008] Valid loss: 0.0313
2023-02-06 10:49:32 | Valid | Epoch[254/600] Iteration[005/008] Valid loss: 0.0323
2023-02-06 10:49:32 | Valid | Epoch[254/600] Iteration[006/008] Valid loss: 0.0323
2023-02-06 10:49:32 | Valid | Epoch[254/600] Iteration[007/008] Valid loss: 0.0328
2023-02-06 10:49:32 | Valid | Epoch[254/600] Iteration[008/008] Valid loss: 0.0325
2023-02-06 10:49:32 | Valid | Epoch[254/600] MIou: 0.926749442520106
2023-02-06 10:49:32 | Valid | Epoch[254/600] Pixel Accuracy: 0.9877230326334635
2023-02-06 10:49:32 | Valid | Epoch[254/600] Mean Pixel Accuracy: 0.9414123600525928
2023-02-06 10:49:32 | Stage | Epoch[254/600] Train loss:0.0274
2023-02-06 10:49:32 | Stage | Epoch[254/600] Valid loss:0.0325
2023-02-06 10:49:32 | Stage | Epoch[254/600] LR:0.01

2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[004/030] Train loss: 0.0262
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[006/030] Train loss: 0.0266
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[007/030] Train loss: 0.0272
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[009/030] Train loss: 0.0272
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[013/030] Train loss: 0.0265
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[015/030] Train loss: 0.0265
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[016/030] Train loss: 0.0267
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 10:49:33 | Train | Epoch[255/600] Iteration[019/030] Train loss: 0.0269
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[020/030] Train loss: 0.0271
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[021/030] Train loss: 0.0271
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[022/030] Train loss: 0.0270
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[024/030] Train loss: 0.0271
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[025/030] Train loss: 0.0272
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[026/030] Train loss: 0.0273
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[027/030] Train loss: 0.0271
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[028/030] Train loss: 0.0273
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[029/030] Train loss: 0.0273
2023-02-06 10:49:34 | Train | Epoch[255/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 10:49:34 | Valid | Epoch[255/600] Iteration[001/008] Valid loss: 0.1321
2023-02-06 10:49:34 | Valid | Epoch[255/600] Iteration[002/008] Valid loss: 0.1007
2023-02-06 10:49:34 | Valid | Epoch[255/600] Iteration[003/008] Valid loss: 0.0930
2023-02-06 10:49:34 | Valid | Epoch[255/600] Iteration[004/008] Valid loss: 0.0909
2023-02-06 10:49:34 | Valid | Epoch[255/600] Iteration[005/008] Valid loss: 0.0933
2023-02-06 10:49:34 | Valid | Epoch[255/600] Iteration[006/008] Valid loss: 0.0970
2023-02-06 10:49:34 | Valid | Epoch[255/600] Iteration[007/008] Valid loss: 0.1044
2023-02-06 10:49:34 | Valid | Epoch[255/600] Iteration[008/008] Valid loss: 0.1003
2023-02-06 10:49:35 | Valid | Epoch[255/600] MIou: 0.9240123174492529
2023-02-06 10:49:35 | Valid | Epoch[255/600] Pixel Accuracy: 0.9861768086751302
2023-02-06 10:49:35 | Valid | Epoch[255/600] Mean Pixel Accuracy: 0.9768553483553808
2023-02-06 10:49:35 | Stage | Epoch[255/600] Train loss:0.0272
2023-02-06 10:49:35 | Stage | Epoch[255/600] Valid loss:0.1003
2023-02-06 10:49:35 | Stage | Epoch[255/600] LR:0.01

2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[001/030] Train loss: 0.0317
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[002/030] Train loss: 0.0277
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[004/030] Train loss: 0.0275
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[005/030] Train loss: 0.0268
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[006/030] Train loss: 0.0275
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[007/030] Train loss: 0.0272
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[008/030] Train loss: 0.0267
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[009/030] Train loss: 0.0280
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[011/030] Train loss: 0.0280
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[012/030] Train loss: 0.0280
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[013/030] Train loss: 0.0281
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[014/030] Train loss: 0.0278
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[015/030] Train loss: 0.0278
2023-02-06 10:49:35 | Train | Epoch[256/600] Iteration[016/030] Train loss: 0.0280
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[017/030] Train loss: 0.0281
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[018/030] Train loss: 0.0279
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[019/030] Train loss: 0.0279
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[020/030] Train loss: 0.0279
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[021/030] Train loss: 0.0279
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[022/030] Train loss: 0.0280
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[023/030] Train loss: 0.0280
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[024/030] Train loss: 0.0278
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[025/030] Train loss: 0.0278
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[026/030] Train loss: 0.0277
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[028/030] Train loss: 0.0277
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[029/030] Train loss: 0.0278
2023-02-06 10:49:36 | Train | Epoch[256/600] Iteration[030/030] Train loss: 0.0278
2023-02-06 10:49:36 | Valid | Epoch[256/600] Iteration[001/008] Valid loss: 0.1324
2023-02-06 10:49:37 | Valid | Epoch[256/600] Iteration[002/008] Valid loss: 0.0974
2023-02-06 10:49:37 | Valid | Epoch[256/600] Iteration[003/008] Valid loss: 0.0917
2023-02-06 10:49:37 | Valid | Epoch[256/600] Iteration[004/008] Valid loss: 0.0894
2023-02-06 10:49:37 | Valid | Epoch[256/600] Iteration[005/008] Valid loss: 0.0919
2023-02-06 10:49:37 | Valid | Epoch[256/600] Iteration[006/008] Valid loss: 0.0900
2023-02-06 10:49:37 | Valid | Epoch[256/600] Iteration[007/008] Valid loss: 0.0980
2023-02-06 10:49:37 | Valid | Epoch[256/600] Iteration[008/008] Valid loss: 0.0966
2023-02-06 10:49:37 | Valid | Epoch[256/600] MIou: 0.9190649082584404
2023-02-06 10:49:37 | Valid | Epoch[256/600] Pixel Accuracy: 0.9851544698079427
2023-02-06 10:49:37 | Valid | Epoch[256/600] Mean Pixel Accuracy: 0.9758432538349187
2023-02-06 10:49:37 | Stage | Epoch[256/600] Train loss:0.0278
2023-02-06 10:49:37 | Stage | Epoch[256/600] Valid loss:0.0966
2023-02-06 10:49:37 | Stage | Epoch[256/600] LR:0.01

2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[001/030] Train loss: 0.0247
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[002/030] Train loss: 0.0284
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[003/030] Train loss: 0.0290
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[004/030] Train loss: 0.0289
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[005/030] Train loss: 0.0274
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[006/030] Train loss: 0.0283
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[007/030] Train loss: 0.0279
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[008/030] Train loss: 0.0281
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[009/030] Train loss: 0.0284
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[011/030] Train loss: 0.0287
2023-02-06 10:49:37 | Train | Epoch[257/600] Iteration[012/030] Train loss: 0.0289
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[013/030] Train loss: 0.0286
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[014/030] Train loss: 0.0285
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[015/030] Train loss: 0.0288
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[016/030] Train loss: 0.0287
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[017/030] Train loss: 0.0288
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[018/030] Train loss: 0.0284
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[019/030] Train loss: 0.0283
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[020/030] Train loss: 0.0284
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[021/030] Train loss: 0.0283
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[022/030] Train loss: 0.0284
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[023/030] Train loss: 0.0283
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[024/030] Train loss: 0.0281
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[025/030] Train loss: 0.0280
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[026/030] Train loss: 0.0278
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[028/030] Train loss: 0.0279
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[029/030] Train loss: 0.0280
2023-02-06 10:49:38 | Train | Epoch[257/600] Iteration[030/030] Train loss: 0.0278
2023-02-06 10:49:39 | Valid | Epoch[257/600] Iteration[001/008] Valid loss: 0.0381
2023-02-06 10:49:39 | Valid | Epoch[257/600] Iteration[002/008] Valid loss: 0.0347
2023-02-06 10:49:39 | Valid | Epoch[257/600] Iteration[003/008] Valid loss: 0.0348
2023-02-06 10:49:39 | Valid | Epoch[257/600] Iteration[004/008] Valid loss: 0.0337
2023-02-06 10:49:39 | Valid | Epoch[257/600] Iteration[005/008] Valid loss: 0.0338
2023-02-06 10:49:39 | Valid | Epoch[257/600] Iteration[006/008] Valid loss: 0.0332
2023-02-06 10:49:39 | Valid | Epoch[257/600] Iteration[007/008] Valid loss: 0.0327
2023-02-06 10:49:39 | Valid | Epoch[257/600] Iteration[008/008] Valid loss: 0.0330
2023-02-06 10:49:39 | Valid | Epoch[257/600] MIou: 0.8950055495921005
2023-02-06 10:49:39 | Valid | Epoch[257/600] Pixel Accuracy: 0.9826380411783854
2023-02-06 10:49:39 | Valid | Epoch[257/600] Mean Pixel Accuracy: 0.9061922605664654
2023-02-06 10:49:39 | Stage | Epoch[257/600] Train loss:0.0278
2023-02-06 10:49:39 | Stage | Epoch[257/600] Valid loss:0.0330
2023-02-06 10:49:39 | Stage | Epoch[257/600] LR:0.01

2023-02-06 10:49:39 | Train | Epoch[258/600] Iteration[001/030] Train loss: 0.0315
2023-02-06 10:49:39 | Train | Epoch[258/600] Iteration[002/030] Train loss: 0.0299
2023-02-06 10:49:39 | Train | Epoch[258/600] Iteration[003/030] Train loss: 0.0292
2023-02-06 10:49:39 | Train | Epoch[258/600] Iteration[004/030] Train loss: 0.0287
2023-02-06 10:49:39 | Train | Epoch[258/600] Iteration[005/030] Train loss: 0.0275
2023-02-06 10:49:39 | Train | Epoch[258/600] Iteration[006/030] Train loss: 0.0277
2023-02-06 10:49:39 | Train | Epoch[258/600] Iteration[007/030] Train loss: 0.0272
2023-02-06 10:49:39 | Train | Epoch[258/600] Iteration[008/030] Train loss: 0.0266
2023-02-06 10:49:39 | Train | Epoch[258/600] Iteration[009/030] Train loss: 0.0270
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[010/030] Train loss: 0.0267
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[014/030] Train loss: 0.0275
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[015/030] Train loss: 0.0278
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[016/030] Train loss: 0.0277
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[017/030] Train loss: 0.0277
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[018/030] Train loss: 0.0274
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[019/030] Train loss: 0.0273
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[020/030] Train loss: 0.0274
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[021/030] Train loss: 0.0275
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[022/030] Train loss: 0.0275
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[023/030] Train loss: 0.0276
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[024/030] Train loss: 0.0280
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[025/030] Train loss: 0.0278
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[026/030] Train loss: 0.0280
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[028/030] Train loss: 0.0278
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[029/030] Train loss: 0.0278
2023-02-06 10:49:40 | Train | Epoch[258/600] Iteration[030/030] Train loss: 0.0277
2023-02-06 10:49:41 | Valid | Epoch[258/600] Iteration[001/008] Valid loss: 0.1134
2023-02-06 10:49:41 | Valid | Epoch[258/600] Iteration[002/008] Valid loss: 0.0821
2023-02-06 10:49:41 | Valid | Epoch[258/600] Iteration[003/008] Valid loss: 0.0759
2023-02-06 10:49:41 | Valid | Epoch[258/600] Iteration[004/008] Valid loss: 0.0725
2023-02-06 10:49:41 | Valid | Epoch[258/600] Iteration[005/008] Valid loss: 0.0743
2023-02-06 10:49:41 | Valid | Epoch[258/600] Iteration[006/008] Valid loss: 0.0726
2023-02-06 10:49:41 | Valid | Epoch[258/600] Iteration[007/008] Valid loss: 0.0780
2023-02-06 10:49:41 | Valid | Epoch[258/600] Iteration[008/008] Valid loss: 0.0780
2023-02-06 10:49:41 | Valid | Epoch[258/600] MIou: 0.9230465910560224
2023-02-06 10:49:41 | Valid | Epoch[258/600] Pixel Accuracy: 0.9860267639160156
2023-02-06 10:49:41 | Valid | Epoch[258/600] Mean Pixel Accuracy: 0.9749785239185986
2023-02-06 10:49:41 | Stage | Epoch[258/600] Train loss:0.0277
2023-02-06 10:49:41 | Stage | Epoch[258/600] Valid loss:0.0780
2023-02-06 10:49:41 | Stage | Epoch[258/600] LR:0.01

2023-02-06 10:49:41 | Train | Epoch[259/600] Iteration[001/030] Train loss: 0.0300
2023-02-06 10:49:41 | Train | Epoch[259/600] Iteration[002/030] Train loss: 0.0266
2023-02-06 10:49:41 | Train | Epoch[259/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 10:49:41 | Train | Epoch[259/600] Iteration[004/030] Train loss: 0.0293
2023-02-06 10:49:41 | Train | Epoch[259/600] Iteration[005/030] Train loss: 0.0296
2023-02-06 10:49:41 | Train | Epoch[259/600] Iteration[006/030] Train loss: 0.0284
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[007/030] Train loss: 0.0279
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[008/030] Train loss: 0.0280
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[009/030] Train loss: 0.0278
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[010/030] Train loss: 0.0282
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[011/030] Train loss: 0.0280
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[012/030] Train loss: 0.0279
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[014/030] Train loss: 0.0275
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[015/030] Train loss: 0.0276
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[017/030] Train loss: 0.0278
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[018/030] Train loss: 0.0277
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[019/030] Train loss: 0.0276
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[020/030] Train loss: 0.0276
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[022/030] Train loss: 0.0275
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[023/030] Train loss: 0.0275
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[024/030] Train loss: 0.0276
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[025/030] Train loss: 0.0275
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[026/030] Train loss: 0.0274
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[027/030] Train loss: 0.0275
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[028/030] Train loss: 0.0276
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[029/030] Train loss: 0.0277
2023-02-06 10:49:42 | Train | Epoch[259/600] Iteration[030/030] Train loss: 0.0277
2023-02-06 10:49:43 | Valid | Epoch[259/600] Iteration[001/008] Valid loss: 0.0895
2023-02-06 10:49:43 | Valid | Epoch[259/600] Iteration[002/008] Valid loss: 0.0661
2023-02-06 10:49:43 | Valid | Epoch[259/600] Iteration[003/008] Valid loss: 0.0619
2023-02-06 10:49:43 | Valid | Epoch[259/600] Iteration[004/008] Valid loss: 0.0589
2023-02-06 10:49:43 | Valid | Epoch[259/600] Iteration[005/008] Valid loss: 0.0602
2023-02-06 10:49:43 | Valid | Epoch[259/600] Iteration[006/008] Valid loss: 0.0584
2023-02-06 10:49:43 | Valid | Epoch[259/600] Iteration[007/008] Valid loss: 0.0621
2023-02-06 10:49:43 | Valid | Epoch[259/600] Iteration[008/008] Valid loss: 0.0621
2023-02-06 10:49:43 | Valid | Epoch[259/600] MIou: 0.9272822696467022
2023-02-06 10:49:43 | Valid | Epoch[259/600] Pixel Accuracy: 0.9870033264160156
2023-02-06 10:49:43 | Valid | Epoch[259/600] Mean Pixel Accuracy: 0.9715841919804924
2023-02-06 10:49:43 | Stage | Epoch[259/600] Train loss:0.0277
2023-02-06 10:49:43 | Stage | Epoch[259/600] Valid loss:0.0621
2023-02-06 10:49:43 | Stage | Epoch[259/600] LR:0.01

2023-02-06 10:49:43 | Train | Epoch[260/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 10:49:43 | Train | Epoch[260/600] Iteration[002/030] Train loss: 0.0276
2023-02-06 10:49:43 | Train | Epoch[260/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[004/030] Train loss: 0.0261
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[005/030] Train loss: 0.0270
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[006/030] Train loss: 0.0271
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[007/030] Train loss: 0.0285
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[008/030] Train loss: 0.0279
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[009/030] Train loss: 0.0275
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[011/030] Train loss: 0.0274
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[012/030] Train loss: 0.0272
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[014/030] Train loss: 0.0276
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[015/030] Train loss: 0.0277
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[016/030] Train loss: 0.0276
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[017/030] Train loss: 0.0276
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[018/030] Train loss: 0.0276
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[020/030] Train loss: 0.0276
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[022/030] Train loss: 0.0278
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[023/030] Train loss: 0.0278
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[024/030] Train loss: 0.0276
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[025/030] Train loss: 0.0278
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[026/030] Train loss: 0.0278
2023-02-06 10:49:44 | Train | Epoch[260/600] Iteration[027/030] Train loss: 0.0278
2023-02-06 10:49:45 | Train | Epoch[260/600] Iteration[028/030] Train loss: 0.0279
2023-02-06 10:49:45 | Train | Epoch[260/600] Iteration[029/030] Train loss: 0.0277
2023-02-06 10:49:45 | Train | Epoch[260/600] Iteration[030/030] Train loss: 0.0278
2023-02-06 10:49:45 | Valid | Epoch[260/600] Iteration[001/008] Valid loss: 0.0372
2023-02-06 10:49:45 | Valid | Epoch[260/600] Iteration[002/008] Valid loss: 0.0325
2023-02-06 10:49:45 | Valid | Epoch[260/600] Iteration[003/008] Valid loss: 0.0326
2023-02-06 10:49:45 | Valid | Epoch[260/600] Iteration[004/008] Valid loss: 0.0314
2023-02-06 10:49:45 | Valid | Epoch[260/600] Iteration[005/008] Valid loss: 0.0318
2023-02-06 10:49:45 | Valid | Epoch[260/600] Iteration[006/008] Valid loss: 0.0314
2023-02-06 10:49:45 | Valid | Epoch[260/600] Iteration[007/008] Valid loss: 0.0314
2023-02-06 10:49:45 | Valid | Epoch[260/600] Iteration[008/008] Valid loss: 0.0314
2023-02-06 10:49:45 | Valid | Epoch[260/600] MIou: 0.9077954353751467
2023-02-06 10:49:45 | Valid | Epoch[260/600] Pixel Accuracy: 0.9847310384114584
2023-02-06 10:49:45 | Valid | Epoch[260/600] Mean Pixel Accuracy: 0.9186033385153891
2023-02-06 10:49:45 | Stage | Epoch[260/600] Train loss:0.0278
2023-02-06 10:49:45 | Stage | Epoch[260/600] Valid loss:0.0314
2023-02-06 10:49:45 | Stage | Epoch[260/600] LR:0.01

2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[001/030] Train loss: 0.0267
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[003/030] Train loss: 0.0280
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[004/030] Train loss: 0.0272
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[005/030] Train loss: 0.0266
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[007/030] Train loss: 0.0274
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[008/030] Train loss: 0.0275
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[009/030] Train loss: 0.0272
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[010/030] Train loss: 0.0273
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[011/030] Train loss: 0.0275
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[012/030] Train loss: 0.0272
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[013/030] Train loss: 0.0272
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[014/030] Train loss: 0.0269
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[015/030] Train loss: 0.0269
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[016/030] Train loss: 0.0271
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[017/030] Train loss: 0.0272
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[018/030] Train loss: 0.0275
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[020/030] Train loss: 0.0274
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[021/030] Train loss: 0.0275
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[022/030] Train loss: 0.0274
2023-02-06 10:49:46 | Train | Epoch[261/600] Iteration[023/030] Train loss: 0.0274
2023-02-06 10:49:47 | Train | Epoch[261/600] Iteration[024/030] Train loss: 0.0272
2023-02-06 10:49:47 | Train | Epoch[261/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 10:49:47 | Train | Epoch[261/600] Iteration[026/030] Train loss: 0.0272
2023-02-06 10:49:47 | Train | Epoch[261/600] Iteration[027/030] Train loss: 0.0275
2023-02-06 10:49:47 | Train | Epoch[261/600] Iteration[028/030] Train loss: 0.0274
2023-02-06 10:49:47 | Train | Epoch[261/600] Iteration[029/030] Train loss: 0.0275
2023-02-06 10:49:47 | Train | Epoch[261/600] Iteration[030/030] Train loss: 0.0275
2023-02-06 10:49:47 | Valid | Epoch[261/600] Iteration[001/008] Valid loss: 0.0558
2023-02-06 10:49:47 | Valid | Epoch[261/600] Iteration[002/008] Valid loss: 0.0518
2023-02-06 10:49:47 | Valid | Epoch[261/600] Iteration[003/008] Valid loss: 0.0521
2023-02-06 10:49:47 | Valid | Epoch[261/600] Iteration[004/008] Valid loss: 0.0508
2023-02-06 10:49:47 | Valid | Epoch[261/600] Iteration[005/008] Valid loss: 0.0517
2023-02-06 10:49:47 | Valid | Epoch[261/600] Iteration[006/008] Valid loss: 0.0508
2023-02-06 10:49:47 | Valid | Epoch[261/600] Iteration[007/008] Valid loss: 0.0501
2023-02-06 10:49:47 | Valid | Epoch[261/600] Iteration[008/008] Valid loss: 0.0508
2023-02-06 10:49:47 | Valid | Epoch[261/600] MIou: 0.851079424590538
2023-02-06 10:49:47 | Valid | Epoch[261/600] Pixel Accuracy: 0.975195566813151
2023-02-06 10:49:47 | Valid | Epoch[261/600] Mean Pixel Accuracy: 0.8682751437245322
2023-02-06 10:49:47 | Stage | Epoch[261/600] Train loss:0.0275
2023-02-06 10:49:47 | Stage | Epoch[261/600] Valid loss:0.0508
2023-02-06 10:49:47 | Stage | Epoch[261/600] LR:0.01

2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[001/030] Train loss: 0.0281
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[003/030] Train loss: 0.0269
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[005/030] Train loss: 0.0270
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[009/030] Train loss: 0.0273
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[010/030] Train loss: 0.0275
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[011/030] Train loss: 0.0284
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[012/030] Train loss: 0.0283
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[013/030] Train loss: 0.0284
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[014/030] Train loss: 0.0285
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[015/030] Train loss: 0.0285
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[016/030] Train loss: 0.0285
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[017/030] Train loss: 0.0284
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[018/030] Train loss: 0.0282
2023-02-06 10:49:48 | Train | Epoch[262/600] Iteration[019/030] Train loss: 0.0282
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[020/030] Train loss: 0.0282
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[021/030] Train loss: 0.0284
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[022/030] Train loss: 0.0283
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[023/030] Train loss: 0.0284
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[024/030] Train loss: 0.0282
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[025/030] Train loss: 0.0281
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[026/030] Train loss: 0.0279
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[028/030] Train loss: 0.0279
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[029/030] Train loss: 0.0278
2023-02-06 10:49:49 | Train | Epoch[262/600] Iteration[030/030] Train loss: 0.0276
2023-02-06 10:49:49 | Valid | Epoch[262/600] Iteration[001/008] Valid loss: 0.2316
2023-02-06 10:49:49 | Valid | Epoch[262/600] Iteration[002/008] Valid loss: 0.2258
2023-02-06 10:49:49 | Valid | Epoch[262/600] Iteration[003/008] Valid loss: 0.2357
2023-02-06 10:49:49 | Valid | Epoch[262/600] Iteration[004/008] Valid loss: 0.2375
2023-02-06 10:49:49 | Valid | Epoch[262/600] Iteration[005/008] Valid loss: 0.2438
2023-02-06 10:49:49 | Valid | Epoch[262/600] Iteration[006/008] Valid loss: 0.2406
2023-02-06 10:49:49 | Valid | Epoch[262/600] Iteration[007/008] Valid loss: 0.2377
2023-02-06 10:49:49 | Valid | Epoch[262/600] Iteration[008/008] Valid loss: 0.2434
2023-02-06 10:49:50 | Valid | Epoch[262/600] MIou: 0.4906073191141247
2023-02-06 10:49:50 | Valid | Epoch[262/600] Pixel Accuracy: 0.9156494140625
2023-02-06 10:49:50 | Valid | Epoch[262/600] Mean Pixel Accuracy: 0.5330358022779428
2023-02-06 10:49:50 | Stage | Epoch[262/600] Train loss:0.0276
2023-02-06 10:49:50 | Stage | Epoch[262/600] Valid loss:0.2434
2023-02-06 10:49:50 | Stage | Epoch[262/600] LR:0.01

2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[007/030] Train loss: 0.0261
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[008/030] Train loss: 0.0264
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[009/030] Train loss: 0.0266
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:49:50 | Train | Epoch[263/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[018/030] Train loss: 0.0268
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[019/030] Train loss: 0.0269
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[020/030] Train loss: 0.0272
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[021/030] Train loss: 0.0272
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[022/030] Train loss: 0.0271
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[023/030] Train loss: 0.0271
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[024/030] Train loss: 0.0272
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[026/030] Train loss: 0.0271
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[027/030] Train loss: 0.0271
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[028/030] Train loss: 0.0272
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[029/030] Train loss: 0.0271
2023-02-06 10:49:51 | Train | Epoch[263/600] Iteration[030/030] Train loss: 0.0274
2023-02-06 10:49:51 | Valid | Epoch[263/600] Iteration[001/008] Valid loss: 0.0403
2023-02-06 10:49:51 | Valid | Epoch[263/600] Iteration[002/008] Valid loss: 0.0390
2023-02-06 10:49:51 | Valid | Epoch[263/600] Iteration[003/008] Valid loss: 0.0396
2023-02-06 10:49:51 | Valid | Epoch[263/600] Iteration[004/008] Valid loss: 0.0388
2023-02-06 10:49:52 | Valid | Epoch[263/600] Iteration[005/008] Valid loss: 0.0394
2023-02-06 10:49:52 | Valid | Epoch[263/600] Iteration[006/008] Valid loss: 0.0389
2023-02-06 10:49:52 | Valid | Epoch[263/600] Iteration[007/008] Valid loss: 0.0382
2023-02-06 10:49:52 | Valid | Epoch[263/600] Iteration[008/008] Valid loss: 0.0389
2023-02-06 10:49:52 | Valid | Epoch[263/600] MIou: 0.8602968062808575
2023-02-06 10:49:52 | Valid | Epoch[263/600] Pixel Accuracy: 0.976935068766276
2023-02-06 10:49:52 | Valid | Epoch[263/600] Mean Pixel Accuracy: 0.873555449757172
2023-02-06 10:49:52 | Stage | Epoch[263/600] Train loss:0.0274
2023-02-06 10:49:52 | Stage | Epoch[263/600] Valid loss:0.0389
2023-02-06 10:49:52 | Stage | Epoch[263/600] LR:0.01

2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[001/030] Train loss: 0.0228
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[006/030] Train loss: 0.0276
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[010/030] Train loss: 0.0269
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[011/030] Train loss: 0.0268
2023-02-06 10:49:52 | Train | Epoch[264/600] Iteration[012/030] Train loss: 0.0272
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[013/030] Train loss: 0.0272
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[014/030] Train loss: 0.0269
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[015/030] Train loss: 0.0271
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[016/030] Train loss: 0.0269
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[017/030] Train loss: 0.0270
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[018/030] Train loss: 0.0272
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[019/030] Train loss: 0.0271
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[020/030] Train loss: 0.0271
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[021/030] Train loss: 0.0273
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[022/030] Train loss: 0.0272
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[024/030] Train loss: 0.0270
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[026/030] Train loss: 0.0272
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[028/030] Train loss: 0.0273
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[029/030] Train loss: 0.0272
2023-02-06 10:49:53 | Train | Epoch[264/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 10:49:54 | Valid | Epoch[264/600] Iteration[001/008] Valid loss: 0.0504
2023-02-06 10:49:54 | Valid | Epoch[264/600] Iteration[002/008] Valid loss: 0.0485
2023-02-06 10:49:54 | Valid | Epoch[264/600] Iteration[003/008] Valid loss: 0.0495
2023-02-06 10:49:54 | Valid | Epoch[264/600] Iteration[004/008] Valid loss: 0.0487
2023-02-06 10:49:54 | Valid | Epoch[264/600] Iteration[005/008] Valid loss: 0.0490
2023-02-06 10:49:54 | Valid | Epoch[264/600] Iteration[006/008] Valid loss: 0.0480
2023-02-06 10:49:54 | Valid | Epoch[264/600] Iteration[007/008] Valid loss: 0.0466
2023-02-06 10:49:54 | Valid | Epoch[264/600] Iteration[008/008] Valid loss: 0.0476
2023-02-06 10:49:54 | Valid | Epoch[264/600] MIou: 0.8385187057784279
2023-02-06 10:49:54 | Valid | Epoch[264/600] Pixel Accuracy: 0.9733874003092448
2023-02-06 10:49:54 | Valid | Epoch[264/600] Mean Pixel Accuracy: 0.8528503851360555
2023-02-06 10:49:54 | Stage | Epoch[264/600] Train loss:0.0272
2023-02-06 10:49:54 | Stage | Epoch[264/600] Valid loss:0.0476
2023-02-06 10:49:54 | Stage | Epoch[264/600] LR:0.01

2023-02-06 10:49:54 | Train | Epoch[265/600] Iteration[001/030] Train loss: 0.0242
2023-02-06 10:49:54 | Train | Epoch[265/600] Iteration[002/030] Train loss: 0.0245
2023-02-06 10:49:54 | Train | Epoch[265/600] Iteration[003/030] Train loss: 0.0237
2023-02-06 10:49:54 | Train | Epoch[265/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:49:54 | Train | Epoch[265/600] Iteration[005/030] Train loss: 0.0258
2023-02-06 10:49:54 | Train | Epoch[265/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:49:54 | Train | Epoch[265/600] Iteration[007/030] Train loss: 0.0268
2023-02-06 10:49:54 | Train | Epoch[265/600] Iteration[008/030] Train loss: 0.0273
2023-02-06 10:49:54 | Train | Epoch[265/600] Iteration[009/030] Train loss: 0.0273
2023-02-06 10:49:54 | Train | Epoch[265/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[011/030] Train loss: 0.0274
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[012/030] Train loss: 0.0272
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[013/030] Train loss: 0.0270
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[015/030] Train loss: 0.0271
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[016/030] Train loss: 0.0271
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[017/030] Train loss: 0.0270
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[018/030] Train loss: 0.0272
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[019/030] Train loss: 0.0273
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[020/030] Train loss: 0.0273
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[021/030] Train loss: 0.0273
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[022/030] Train loss: 0.0273
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[023/030] Train loss: 0.0274
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[024/030] Train loss: 0.0277
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[025/030] Train loss: 0.0275
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[026/030] Train loss: 0.0274
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[027/030] Train loss: 0.0273
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[028/030] Train loss: 0.0271
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[029/030] Train loss: 0.0273
2023-02-06 10:49:55 | Train | Epoch[265/600] Iteration[030/030] Train loss: 0.0273
2023-02-06 10:49:56 | Valid | Epoch[265/600] Iteration[001/008] Valid loss: 0.0420
2023-02-06 10:49:56 | Valid | Epoch[265/600] Iteration[002/008] Valid loss: 0.0367
2023-02-06 10:49:56 | Valid | Epoch[265/600] Iteration[003/008] Valid loss: 0.0357
2023-02-06 10:49:56 | Valid | Epoch[265/600] Iteration[004/008] Valid loss: 0.0344
2023-02-06 10:49:56 | Valid | Epoch[265/600] Iteration[005/008] Valid loss: 0.0347
2023-02-06 10:49:56 | Valid | Epoch[265/600] Iteration[006/008] Valid loss: 0.0340
2023-02-06 10:49:56 | Valid | Epoch[265/600] Iteration[007/008] Valid loss: 0.0338
2023-02-06 10:49:56 | Valid | Epoch[265/600] Iteration[008/008] Valid loss: 0.0339
2023-02-06 10:49:56 | Valid | Epoch[265/600] MIou: 0.9033535946902568
2023-02-06 10:49:56 | Valid | Epoch[265/600] Pixel Accuracy: 0.9839032491048177
2023-02-06 10:49:56 | Valid | Epoch[265/600] Mean Pixel Accuracy: 0.9168802559056835
2023-02-06 10:49:56 | Stage | Epoch[265/600] Train loss:0.0273
2023-02-06 10:49:56 | Stage | Epoch[265/600] Valid loss:0.0339
2023-02-06 10:49:56 | Stage | Epoch[265/600] LR:0.01

2023-02-06 10:49:56 | Train | Epoch[266/600] Iteration[001/030] Train loss: 0.0294
2023-02-06 10:49:56 | Train | Epoch[266/600] Iteration[002/030] Train loss: 0.0271
2023-02-06 10:49:56 | Train | Epoch[266/600] Iteration[003/030] Train loss: 0.0271
2023-02-06 10:49:56 | Train | Epoch[266/600] Iteration[004/030] Train loss: 0.0264
2023-02-06 10:49:56 | Train | Epoch[266/600] Iteration[005/030] Train loss: 0.0264
2023-02-06 10:49:56 | Train | Epoch[266/600] Iteration[006/030] Train loss: 0.0265
2023-02-06 10:49:56 | Train | Epoch[266/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 10:49:56 | Train | Epoch[266/600] Iteration[008/030] Train loss: 0.0266
2023-02-06 10:49:56 | Train | Epoch[266/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[013/030] Train loss: 0.0267
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[015/030] Train loss: 0.0270
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[016/030] Train loss: 0.0269
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[017/030] Train loss: 0.0269
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[018/030] Train loss: 0.0274
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[020/030] Train loss: 0.0276
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[021/030] Train loss: 0.0277
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[022/030] Train loss: 0.0277
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[023/030] Train loss: 0.0277
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[024/030] Train loss: 0.0278
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[025/030] Train loss: 0.0277
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[026/030] Train loss: 0.0277
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[027/030] Train loss: 0.0276
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[028/030] Train loss: 0.0277
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[029/030] Train loss: 0.0276
2023-02-06 10:49:57 | Train | Epoch[266/600] Iteration[030/030] Train loss: 0.0275
2023-02-06 10:49:58 | Valid | Epoch[266/600] Iteration[001/008] Valid loss: 0.1928
2023-02-06 10:49:58 | Valid | Epoch[266/600] Iteration[002/008] Valid loss: 0.1604
2023-02-06 10:49:58 | Valid | Epoch[266/600] Iteration[003/008] Valid loss: 0.1489
2023-02-06 10:49:58 | Valid | Epoch[266/600] Iteration[004/008] Valid loss: 0.1462
2023-02-06 10:49:58 | Valid | Epoch[266/600] Iteration[005/008] Valid loss: 0.1526
2023-02-06 10:49:58 | Valid | Epoch[266/600] Iteration[006/008] Valid loss: 0.1525
2023-02-06 10:49:58 | Valid | Epoch[266/600] Iteration[007/008] Valid loss: 0.1625
2023-02-06 10:49:58 | Valid | Epoch[266/600] Iteration[008/008] Valid loss: 0.1612
2023-02-06 10:49:58 | Valid | Epoch[266/600] MIou: 0.8895092851815556
2023-02-06 10:49:58 | Valid | Epoch[266/600] Pixel Accuracy: 0.9781659444173177
2023-02-06 10:49:58 | Valid | Epoch[266/600] Mean Pixel Accuracy: 0.9813796195931981
2023-02-06 10:49:58 | Stage | Epoch[266/600] Train loss:0.0275
2023-02-06 10:49:58 | Stage | Epoch[266/600] Valid loss:0.1612
2023-02-06 10:49:58 | Stage | Epoch[266/600] LR:0.01

2023-02-06 10:49:58 | Train | Epoch[267/600] Iteration[001/030] Train loss: 0.0262
2023-02-06 10:49:58 | Train | Epoch[267/600] Iteration[002/030] Train loss: 0.0288
2023-02-06 10:49:58 | Train | Epoch[267/600] Iteration[003/030] Train loss: 0.0278
2023-02-06 10:49:58 | Train | Epoch[267/600] Iteration[004/030] Train loss: 0.0271
2023-02-06 10:49:58 | Train | Epoch[267/600] Iteration[005/030] Train loss: 0.0279
2023-02-06 10:49:58 | Train | Epoch[267/600] Iteration[006/030] Train loss: 0.0275
2023-02-06 10:49:58 | Train | Epoch[267/600] Iteration[007/030] Train loss: 0.0274
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[009/030] Train loss: 0.0276
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[011/030] Train loss: 0.0276
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[012/030] Train loss: 0.0276
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[014/030] Train loss: 0.0273
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[015/030] Train loss: 0.0275
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[016/030] Train loss: 0.0277
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[017/030] Train loss: 0.0274
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[018/030] Train loss: 0.0274
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[019/030] Train loss: 0.0276
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[020/030] Train loss: 0.0275
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[021/030] Train loss: 0.0274
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[022/030] Train loss: 0.0273
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[023/030] Train loss: 0.0274
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[024/030] Train loss: 0.0274
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[025/030] Train loss: 0.0276
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[026/030] Train loss: 0.0274
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[027/030] Train loss: 0.0275
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[028/030] Train loss: 0.0274
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[029/030] Train loss: 0.0274
2023-02-06 10:49:59 | Train | Epoch[267/600] Iteration[030/030] Train loss: 0.0274
2023-02-06 10:50:00 | Valid | Epoch[267/600] Iteration[001/008] Valid loss: 0.1600
2023-02-06 10:50:00 | Valid | Epoch[267/600] Iteration[002/008] Valid loss: 0.1605
2023-02-06 10:50:00 | Valid | Epoch[267/600] Iteration[003/008] Valid loss: 0.1670
2023-02-06 10:50:00 | Valid | Epoch[267/600] Iteration[004/008] Valid loss: 0.1672
2023-02-06 10:50:00 | Valid | Epoch[267/600] Iteration[005/008] Valid loss: 0.1712
2023-02-06 10:50:00 | Valid | Epoch[267/600] Iteration[006/008] Valid loss: 0.1680
2023-02-06 10:50:00 | Valid | Epoch[267/600] Iteration[007/008] Valid loss: 0.1650
2023-02-06 10:50:00 | Valid | Epoch[267/600] Iteration[008/008] Valid loss: 0.1701
2023-02-06 10:50:00 | Valid | Epoch[267/600] MIou: 0.5259105791820944
2023-02-06 10:50:00 | Valid | Epoch[267/600] Pixel Accuracy: 0.9215342203776041
2023-02-06 10:50:00 | Valid | Epoch[267/600] Mean Pixel Accuracy: 0.5656140449675484
2023-02-06 10:50:00 | Stage | Epoch[267/600] Train loss:0.0274
2023-02-06 10:50:00 | Stage | Epoch[267/600] Valid loss:0.1701
2023-02-06 10:50:00 | Stage | Epoch[267/600] LR:0.01

2023-02-06 10:50:00 | Train | Epoch[268/600] Iteration[001/030] Train loss: 0.0252
2023-02-06 10:50:00 | Train | Epoch[268/600] Iteration[002/030] Train loss: 0.0301
2023-02-06 10:50:00 | Train | Epoch[268/600] Iteration[003/030] Train loss: 0.0290
2023-02-06 10:50:00 | Train | Epoch[268/600] Iteration[004/030] Train loss: 0.0292
2023-02-06 10:50:00 | Train | Epoch[268/600] Iteration[005/030] Train loss: 0.0286
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[006/030] Train loss: 0.0289
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[007/030] Train loss: 0.0278
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[008/030] Train loss: 0.0278
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[009/030] Train loss: 0.0279
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[010/030] Train loss: 0.0277
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[011/030] Train loss: 0.0278
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[012/030] Train loss: 0.0274
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[014/030] Train loss: 0.0277
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[015/030] Train loss: 0.0280
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[016/030] Train loss: 0.0278
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[017/030] Train loss: 0.0275
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[018/030] Train loss: 0.0282
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[019/030] Train loss: 0.0284
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[020/030] Train loss: 0.0285
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[021/030] Train loss: 0.0284
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[022/030] Train loss: 0.0285
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[023/030] Train loss: 0.0283
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[024/030] Train loss: 0.0284
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[025/030] Train loss: 0.0283
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[026/030] Train loss: 0.0281
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[027/030] Train loss: 0.0282
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[028/030] Train loss: 0.0282
2023-02-06 10:50:01 | Train | Epoch[268/600] Iteration[029/030] Train loss: 0.0281
2023-02-06 10:50:02 | Train | Epoch[268/600] Iteration[030/030] Train loss: 0.0282
2023-02-06 10:50:02 | Valid | Epoch[268/600] Iteration[001/008] Valid loss: 0.0540
2023-02-06 10:50:02 | Valid | Epoch[268/600] Iteration[002/008] Valid loss: 0.0523
2023-02-06 10:50:02 | Valid | Epoch[268/600] Iteration[003/008] Valid loss: 0.0537
2023-02-06 10:50:02 | Valid | Epoch[268/600] Iteration[004/008] Valid loss: 0.0527
2023-02-06 10:50:02 | Valid | Epoch[268/600] Iteration[005/008] Valid loss: 0.0531
2023-02-06 10:50:02 | Valid | Epoch[268/600] Iteration[006/008] Valid loss: 0.0519
2023-02-06 10:50:02 | Valid | Epoch[268/600] Iteration[007/008] Valid loss: 0.0502
2023-02-06 10:50:02 | Valid | Epoch[268/600] Iteration[008/008] Valid loss: 0.0514
2023-02-06 10:50:02 | Valid | Epoch[268/600] MIou: 0.8242442302569579
2023-02-06 10:50:02 | Valid | Epoch[268/600] Pixel Accuracy: 0.9710362752278646
2023-02-06 10:50:02 | Valid | Epoch[268/600] Mean Pixel Accuracy: 0.8397014247906802
2023-02-06 10:50:02 | Stage | Epoch[268/600] Train loss:0.0282
2023-02-06 10:50:02 | Stage | Epoch[268/600] Valid loss:0.0514
2023-02-06 10:50:02 | Stage | Epoch[268/600] LR:0.01

2023-02-06 10:50:02 | Train | Epoch[269/600] Iteration[001/030] Train loss: 0.0297
2023-02-06 10:50:02 | Train | Epoch[269/600] Iteration[002/030] Train loss: 0.0296
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[004/030] Train loss: 0.0289
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[005/030] Train loss: 0.0295
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[006/030] Train loss: 0.0293
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[007/030] Train loss: 0.0298
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[008/030] Train loss: 0.0295
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[009/030] Train loss: 0.0291
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[011/030] Train loss: 0.0286
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[012/030] Train loss: 0.0283
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[013/030] Train loss: 0.0283
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[014/030] Train loss: 0.0281
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[015/030] Train loss: 0.0279
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[016/030] Train loss: 0.0279
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[017/030] Train loss: 0.0275
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[018/030] Train loss: 0.0274
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[019/030] Train loss: 0.0275
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[020/030] Train loss: 0.0275
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[021/030] Train loss: 0.0277
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[022/030] Train loss: 0.0275
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[023/030] Train loss: 0.0276
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[024/030] Train loss: 0.0277
2023-02-06 10:50:03 | Train | Epoch[269/600] Iteration[025/030] Train loss: 0.0276
2023-02-06 10:50:04 | Train | Epoch[269/600] Iteration[026/030] Train loss: 0.0275
2023-02-06 10:50:04 | Train | Epoch[269/600] Iteration[027/030] Train loss: 0.0274
2023-02-06 10:50:04 | Train | Epoch[269/600] Iteration[028/030] Train loss: 0.0274
2023-02-06 10:50:04 | Train | Epoch[269/600] Iteration[029/030] Train loss: 0.0275
2023-02-06 10:50:04 | Train | Epoch[269/600] Iteration[030/030] Train loss: 0.0276
2023-02-06 10:50:04 | Valid | Epoch[269/600] Iteration[001/008] Valid loss: 0.0985
2023-02-06 10:50:04 | Valid | Epoch[269/600] Iteration[002/008] Valid loss: 0.0975
2023-02-06 10:50:04 | Valid | Epoch[269/600] Iteration[003/008] Valid loss: 0.1004
2023-02-06 10:50:04 | Valid | Epoch[269/600] Iteration[004/008] Valid loss: 0.0999
2023-02-06 10:50:04 | Valid | Epoch[269/600] Iteration[005/008] Valid loss: 0.1015
2023-02-06 10:50:04 | Valid | Epoch[269/600] Iteration[006/008] Valid loss: 0.0994
2023-02-06 10:50:04 | Valid | Epoch[269/600] Iteration[007/008] Valid loss: 0.0967
2023-02-06 10:50:04 | Valid | Epoch[269/600] Iteration[008/008] Valid loss: 0.0993
2023-02-06 10:50:04 | Valid | Epoch[269/600] MIou: 0.6994856395748095
2023-02-06 10:50:04 | Valid | Epoch[269/600] Pixel Accuracy: 0.9503873189290365
2023-02-06 10:50:04 | Valid | Epoch[269/600] Mean Pixel Accuracy: 0.7253445775669093
2023-02-06 10:50:04 | Stage | Epoch[269/600] Train loss:0.0276
2023-02-06 10:50:04 | Stage | Epoch[269/600] Valid loss:0.0993
2023-02-06 10:50:04 | Stage | Epoch[269/600] LR:0.01

2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[001/030] Train loss: 0.0259
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[002/030] Train loss: 0.0275
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[003/030] Train loss: 0.0267
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[004/030] Train loss: 0.0265
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[005/030] Train loss: 0.0276
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[006/030] Train loss: 0.0278
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[007/030] Train loss: 0.0277
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[008/030] Train loss: 0.0275
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[009/030] Train loss: 0.0272
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[011/030] Train loss: 0.0270
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[012/030] Train loss: 0.0268
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[013/030] Train loss: 0.0268
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[014/030] Train loss: 0.0269
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[015/030] Train loss: 0.0269
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[016/030] Train loss: 0.0268
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[018/030] Train loss: 0.0269
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[019/030] Train loss: 0.0270
2023-02-06 10:50:05 | Train | Epoch[270/600] Iteration[020/030] Train loss: 0.0271
2023-02-06 10:50:06 | Train | Epoch[270/600] Iteration[021/030] Train loss: 0.0271
2023-02-06 10:50:06 | Train | Epoch[270/600] Iteration[022/030] Train loss: 0.0272
2023-02-06 10:50:06 | Train | Epoch[270/600] Iteration[023/030] Train loss: 0.0271
2023-02-06 10:50:06 | Train | Epoch[270/600] Iteration[024/030] Train loss: 0.0273
2023-02-06 10:50:06 | Train | Epoch[270/600] Iteration[025/030] Train loss: 0.0272
2023-02-06 10:50:06 | Train | Epoch[270/600] Iteration[026/030] Train loss: 0.0272
2023-02-06 10:50:06 | Train | Epoch[270/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 10:50:06 | Train | Epoch[270/600] Iteration[028/030] Train loss: 0.0275
2023-02-06 10:50:06 | Train | Epoch[270/600] Iteration[029/030] Train loss: 0.0275
2023-02-06 10:50:06 | Train | Epoch[270/600] Iteration[030/030] Train loss: 0.0277
2023-02-06 10:50:06 | Valid | Epoch[270/600] Iteration[001/008] Valid loss: 0.0419
2023-02-06 10:50:06 | Valid | Epoch[270/600] Iteration[002/008] Valid loss: 0.0368
2023-02-06 10:50:06 | Valid | Epoch[270/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 10:50:06 | Valid | Epoch[270/600] Iteration[004/008] Valid loss: 0.0338
2023-02-06 10:50:06 | Valid | Epoch[270/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 10:50:06 | Valid | Epoch[270/600] Iteration[006/008] Valid loss: 0.0344
2023-02-06 10:50:06 | Valid | Epoch[270/600] Iteration[007/008] Valid loss: 0.0350
2023-02-06 10:50:06 | Valid | Epoch[270/600] Iteration[008/008] Valid loss: 0.0346
2023-02-06 10:50:07 | Valid | Epoch[270/600] MIou: 0.9250058174676725
2023-02-06 10:50:07 | Valid | Epoch[270/600] Pixel Accuracy: 0.987396240234375
2023-02-06 10:50:07 | Valid | Epoch[270/600] Mean Pixel Accuracy: 0.940991803095236
2023-02-06 10:50:07 | Stage | Epoch[270/600] Train loss:0.0277
2023-02-06 10:50:07 | Stage | Epoch[270/600] Valid loss:0.0346
2023-02-06 10:50:07 | Stage | Epoch[270/600] LR:0.01

2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[001/030] Train loss: 0.0265
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[003/030] Train loss: 0.0250
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[004/030] Train loss: 0.0278
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[005/030] Train loss: 0.0279
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[006/030] Train loss: 0.0277
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[007/030] Train loss: 0.0274
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[008/030] Train loss: 0.0276
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[009/030] Train loss: 0.0277
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[010/030] Train loss: 0.0273
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[011/030] Train loss: 0.0272
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[014/030] Train loss: 0.0276
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[015/030] Train loss: 0.0275
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[016/030] Train loss: 0.0276
2023-02-06 10:50:07 | Train | Epoch[271/600] Iteration[017/030] Train loss: 0.0275
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[018/030] Train loss: 0.0277
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[019/030] Train loss: 0.0276
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[020/030] Train loss: 0.0275
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[022/030] Train loss: 0.0275
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[023/030] Train loss: 0.0275
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[024/030] Train loss: 0.0275
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[025/030] Train loss: 0.0274
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[026/030] Train loss: 0.0275
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[027/030] Train loss: 0.0276
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[028/030] Train loss: 0.0275
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[029/030] Train loss: 0.0274
2023-02-06 10:50:08 | Train | Epoch[271/600] Iteration[030/030] Train loss: 0.0275
2023-02-06 10:50:08 | Valid | Epoch[271/600] Iteration[001/008] Valid loss: 0.1865
2023-02-06 10:50:08 | Valid | Epoch[271/600] Iteration[002/008] Valid loss: 0.1843
2023-02-06 10:50:08 | Valid | Epoch[271/600] Iteration[003/008] Valid loss: 0.1924
2023-02-06 10:50:09 | Valid | Epoch[271/600] Iteration[004/008] Valid loss: 0.1932
2023-02-06 10:50:09 | Valid | Epoch[271/600] Iteration[005/008] Valid loss: 0.1981
2023-02-06 10:50:09 | Valid | Epoch[271/600] Iteration[006/008] Valid loss: 0.1957
2023-02-06 10:50:09 | Valid | Epoch[271/600] Iteration[007/008] Valid loss: 0.1927
2023-02-06 10:50:09 | Valid | Epoch[271/600] Iteration[008/008] Valid loss: 0.1984
2023-02-06 10:50:09 | Valid | Epoch[271/600] MIou: 0.47895851698545716
2023-02-06 10:50:09 | Valid | Epoch[271/600] Pixel Accuracy: 0.9137064615885416
2023-02-06 10:50:09 | Valid | Epoch[271/600] Mean Pixel Accuracy: 0.5222796322628785
2023-02-06 10:50:09 | Stage | Epoch[271/600] Train loss:0.0275
2023-02-06 10:50:09 | Stage | Epoch[271/600] Valid loss:0.1984
2023-02-06 10:50:09 | Stage | Epoch[271/600] LR:0.01

2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[001/030] Train loss: 0.0255
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[002/030] Train loss: 0.0267
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[004/030] Train loss: 0.0274
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[005/030] Train loss: 0.0269
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[007/030] Train loss: 0.0274
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[008/030] Train loss: 0.0273
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[011/030] Train loss: 0.0266
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 10:50:09 | Train | Epoch[272/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[014/030] Train loss: 0.0270
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[015/030] Train loss: 0.0272
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[016/030] Train loss: 0.0281
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[017/030] Train loss: 0.0279
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[018/030] Train loss: 0.0281
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[019/030] Train loss: 0.0279
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[020/030] Train loss: 0.0280
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[021/030] Train loss: 0.0280
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[022/030] Train loss: 0.0281
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[023/030] Train loss: 0.0280
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[024/030] Train loss: 0.0279
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[025/030] Train loss: 0.0279
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[026/030] Train loss: 0.0279
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[028/030] Train loss: 0.0278
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[029/030] Train loss: 0.0279
2023-02-06 10:50:10 | Train | Epoch[272/600] Iteration[030/030] Train loss: 0.0280
2023-02-06 10:50:10 | Valid | Epoch[272/600] Iteration[001/008] Valid loss: 0.0370
2023-02-06 10:50:11 | Valid | Epoch[272/600] Iteration[002/008] Valid loss: 0.0316
2023-02-06 10:50:11 | Valid | Epoch[272/600] Iteration[003/008] Valid loss: 0.0312
2023-02-06 10:50:11 | Valid | Epoch[272/600] Iteration[004/008] Valid loss: 0.0303
2023-02-06 10:50:11 | Valid | Epoch[272/600] Iteration[005/008] Valid loss: 0.0309
2023-02-06 10:50:11 | Valid | Epoch[272/600] Iteration[006/008] Valid loss: 0.0309
2023-02-06 10:50:11 | Valid | Epoch[272/600] Iteration[007/008] Valid loss: 0.0310
2023-02-06 10:50:11 | Valid | Epoch[272/600] Iteration[008/008] Valid loss: 0.0309
2023-02-06 10:50:11 | Valid | Epoch[272/600] MIou: 0.9136840762744742
2023-02-06 10:50:11 | Valid | Epoch[272/600] Pixel Accuracy: 0.9856745402018229
2023-02-06 10:50:11 | Valid | Epoch[272/600] Mean Pixel Accuracy: 0.9249868634874254
2023-02-06 10:50:11 | Stage | Epoch[272/600] Train loss:0.0280
2023-02-06 10:50:11 | Stage | Epoch[272/600] Valid loss:0.0309
2023-02-06 10:50:11 | Stage | Epoch[272/600] LR:0.01

2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[002/030] Train loss: 0.0272
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[003/030] Train loss: 0.0269
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[005/030] Train loss: 0.0270
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[007/030] Train loss: 0.0273
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[008/030] Train loss: 0.0276
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[009/030] Train loss: 0.0278
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[011/030] Train loss: 0.0276
2023-02-06 10:50:11 | Train | Epoch[273/600] Iteration[012/030] Train loss: 0.0275
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[013/030] Train loss: 0.0273
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[014/030] Train loss: 0.0274
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[015/030] Train loss: 0.0271
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[016/030] Train loss: 0.0270
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[017/030] Train loss: 0.0271
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[018/030] Train loss: 0.0271
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[019/030] Train loss: 0.0272
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[020/030] Train loss: 0.0271
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[021/030] Train loss: 0.0268
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[022/030] Train loss: 0.0268
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[024/030] Train loss: 0.0271
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[025/030] Train loss: 0.0269
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[026/030] Train loss: 0.0270
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[027/030] Train loss: 0.0270
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[028/030] Train loss: 0.0271
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[029/030] Train loss: 0.0271
2023-02-06 10:50:12 | Train | Epoch[273/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 10:50:13 | Valid | Epoch[273/600] Iteration[001/008] Valid loss: 0.0440
2023-02-06 10:50:13 | Valid | Epoch[273/600] Iteration[002/008] Valid loss: 0.0420
2023-02-06 10:50:13 | Valid | Epoch[273/600] Iteration[003/008] Valid loss: 0.0426
2023-02-06 10:50:13 | Valid | Epoch[273/600] Iteration[004/008] Valid loss: 0.0418
2023-02-06 10:50:13 | Valid | Epoch[273/600] Iteration[005/008] Valid loss: 0.0421
2023-02-06 10:50:13 | Valid | Epoch[273/600] Iteration[006/008] Valid loss: 0.0411
2023-02-06 10:50:13 | Valid | Epoch[273/600] Iteration[007/008] Valid loss: 0.0401
2023-02-06 10:50:13 | Valid | Epoch[273/600] Iteration[008/008] Valid loss: 0.0409
2023-02-06 10:50:13 | Valid | Epoch[273/600] MIou: 0.8528058956071671
2023-02-06 10:50:13 | Valid | Epoch[273/600] Pixel Accuracy: 0.9757232666015625
2023-02-06 10:50:13 | Valid | Epoch[273/600] Mean Pixel Accuracy: 0.866276279818234
2023-02-06 10:50:13 | Stage | Epoch[273/600] Train loss:0.0272
2023-02-06 10:50:13 | Stage | Epoch[273/600] Valid loss:0.0409
2023-02-06 10:50:13 | Stage | Epoch[273/600] LR:0.01

2023-02-06 10:50:13 | Train | Epoch[274/600] Iteration[001/030] Train loss: 0.0253
2023-02-06 10:50:13 | Train | Epoch[274/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 10:50:13 | Train | Epoch[274/600] Iteration[003/030] Train loss: 0.0244
2023-02-06 10:50:13 | Train | Epoch[274/600] Iteration[004/030] Train loss: 0.0250
2023-02-06 10:50:13 | Train | Epoch[274/600] Iteration[005/030] Train loss: 0.0257
2023-02-06 10:50:13 | Train | Epoch[274/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:50:13 | Train | Epoch[274/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:50:13 | Train | Epoch[274/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[010/030] Train loss: 0.0264
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[014/030] Train loss: 0.0269
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[015/030] Train loss: 0.0268
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[016/030] Train loss: 0.0269
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[018/030] Train loss: 0.0266
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[019/030] Train loss: 0.0267
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[021/030] Train loss: 0.0271
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[022/030] Train loss: 0.0270
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[023/030] Train loss: 0.0271
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[024/030] Train loss: 0.0272
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[025/030] Train loss: 0.0272
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[026/030] Train loss: 0.0271
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[027/030] Train loss: 0.0271
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[028/030] Train loss: 0.0271
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[029/030] Train loss: 0.0272
2023-02-06 10:50:14 | Train | Epoch[274/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 10:50:15 | Valid | Epoch[274/600] Iteration[001/008] Valid loss: 0.0941
2023-02-06 10:50:15 | Valid | Epoch[274/600] Iteration[002/008] Valid loss: 0.0812
2023-02-06 10:50:15 | Valid | Epoch[274/600] Iteration[003/008] Valid loss: 0.0722
2023-02-06 10:50:15 | Valid | Epoch[274/600] Iteration[004/008] Valid loss: 0.0703
2023-02-06 10:50:15 | Valid | Epoch[274/600] Iteration[005/008] Valid loss: 0.0714
2023-02-06 10:50:15 | Valid | Epoch[274/600] Iteration[006/008] Valid loss: 0.0734
2023-02-06 10:50:15 | Valid | Epoch[274/600] Iteration[007/008] Valid loss: 0.0769
2023-02-06 10:50:15 | Valid | Epoch[274/600] Iteration[008/008] Valid loss: 0.0752
2023-02-06 10:50:15 | Valid | Epoch[274/600] MIou: 0.930823706486928
2023-02-06 10:50:15 | Valid | Epoch[274/600] Pixel Accuracy: 0.987579345703125
2023-02-06 10:50:15 | Valid | Epoch[274/600] Mean Pixel Accuracy: 0.9773599427192168
2023-02-06 10:50:15 | Stage | Epoch[274/600] Train loss:0.0272
2023-02-06 10:50:15 | Stage | Epoch[274/600] Valid loss:0.0752
2023-02-06 10:50:15 | Stage | Epoch[274/600] LR:0.01

2023-02-06 10:50:15 | Train | Epoch[275/600] Iteration[001/030] Train loss: 0.0303
2023-02-06 10:50:15 | Train | Epoch[275/600] Iteration[002/030] Train loss: 0.0282
2023-02-06 10:50:15 | Train | Epoch[275/600] Iteration[003/030] Train loss: 0.0280
2023-02-06 10:50:15 | Train | Epoch[275/600] Iteration[004/030] Train loss: 0.0296
2023-02-06 10:50:15 | Train | Epoch[275/600] Iteration[005/030] Train loss: 0.0282
2023-02-06 10:50:15 | Train | Epoch[275/600] Iteration[006/030] Train loss: 0.0276
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[007/030] Train loss: 0.0280
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[008/030] Train loss: 0.0277
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[009/030] Train loss: 0.0270
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[012/030] Train loss: 0.0269
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[013/030] Train loss: 0.0271
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[014/030] Train loss: 0.0272
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[015/030] Train loss: 0.0274
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[016/030] Train loss: 0.0275
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[017/030] Train loss: 0.0274
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[018/030] Train loss: 0.0275
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[019/030] Train loss: 0.0276
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[020/030] Train loss: 0.0277
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[021/030] Train loss: 0.0277
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[022/030] Train loss: 0.0279
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[023/030] Train loss: 0.0280
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[024/030] Train loss: 0.0279
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[025/030] Train loss: 0.0279
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[026/030] Train loss: 0.0281
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[027/030] Train loss: 0.0282
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[028/030] Train loss: 0.0281
2023-02-06 10:50:16 | Train | Epoch[275/600] Iteration[029/030] Train loss: 0.0284
2023-02-06 10:50:17 | Train | Epoch[275/600] Iteration[030/030] Train loss: 0.0283
2023-02-06 10:50:17 | Valid | Epoch[275/600] Iteration[001/008] Valid loss: 0.0527
2023-02-06 10:50:17 | Valid | Epoch[275/600] Iteration[002/008] Valid loss: 0.0420
2023-02-06 10:50:17 | Valid | Epoch[275/600] Iteration[003/008] Valid loss: 0.0403
2023-02-06 10:50:17 | Valid | Epoch[275/600] Iteration[004/008] Valid loss: 0.0384
2023-02-06 10:50:17 | Valid | Epoch[275/600] Iteration[005/008] Valid loss: 0.0390
2023-02-06 10:50:17 | Valid | Epoch[275/600] Iteration[006/008] Valid loss: 0.0383
2023-02-06 10:50:17 | Valid | Epoch[275/600] Iteration[007/008] Valid loss: 0.0401
2023-02-06 10:50:17 | Valid | Epoch[275/600] Iteration[008/008] Valid loss: 0.0398
2023-02-06 10:50:17 | Valid | Epoch[275/600] MIou: 0.9310623190711381
2023-02-06 10:50:17 | Valid | Epoch[275/600] Pixel Accuracy: 0.9882087707519531
2023-02-06 10:50:17 | Valid | Epoch[275/600] Mean Pixel Accuracy: 0.9546392662094354
2023-02-06 10:50:17 | Stage | Epoch[275/600] Train loss:0.0283
2023-02-06 10:50:17 | Stage | Epoch[275/600] Valid loss:0.0398
2023-02-06 10:50:17 | Stage | Epoch[275/600] LR:0.01

2023-02-06 10:50:17 | Train | Epoch[276/600] Iteration[001/030] Train loss: 0.0295
2023-02-06 10:50:17 | Train | Epoch[276/600] Iteration[002/030] Train loss: 0.0288
2023-02-06 10:50:17 | Train | Epoch[276/600] Iteration[003/030] Train loss: 0.0283
2023-02-06 10:50:17 | Train | Epoch[276/600] Iteration[004/030] Train loss: 0.0280
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[005/030] Train loss: 0.0278
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[006/030] Train loss: 0.0274
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[009/030] Train loss: 0.0275
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[010/030] Train loss: 0.0274
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[012/030] Train loss: 0.0271
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[014/030] Train loss: 0.0266
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[016/030] Train loss: 0.0266
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[017/030] Train loss: 0.0266
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[020/030] Train loss: 0.0267
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[021/030] Train loss: 0.0267
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[026/030] Train loss: 0.0267
2023-02-06 10:50:18 | Train | Epoch[276/600] Iteration[027/030] Train loss: 0.0266
2023-02-06 10:50:19 | Train | Epoch[276/600] Iteration[028/030] Train loss: 0.0267
2023-02-06 10:50:19 | Train | Epoch[276/600] Iteration[029/030] Train loss: 0.0268
2023-02-06 10:50:19 | Train | Epoch[276/600] Iteration[030/030] Train loss: 0.0270
2023-02-06 10:50:19 | Valid | Epoch[276/600] Iteration[001/008] Valid loss: 0.1802
2023-02-06 10:50:19 | Valid | Epoch[276/600] Iteration[002/008] Valid loss: 0.1401
2023-02-06 10:50:19 | Valid | Epoch[276/600] Iteration[003/008] Valid loss: 0.1322
2023-02-06 10:50:19 | Valid | Epoch[276/600] Iteration[004/008] Valid loss: 0.1294
2023-02-06 10:50:19 | Valid | Epoch[276/600] Iteration[005/008] Valid loss: 0.1343
2023-02-06 10:50:19 | Valid | Epoch[276/600] Iteration[006/008] Valid loss: 0.1354
2023-02-06 10:50:19 | Valid | Epoch[276/600] Iteration[007/008] Valid loss: 0.1455
2023-02-06 10:50:19 | Valid | Epoch[276/600] Iteration[008/008] Valid loss: 0.1416
2023-02-06 10:50:19 | Valid | Epoch[276/600] MIou: 0.9147878618324352
2023-02-06 10:50:19 | Valid | Epoch[276/600] Pixel Accuracy: 0.9840240478515625
2023-02-06 10:50:19 | Valid | Epoch[276/600] Mean Pixel Accuracy: 0.9822154657941857
2023-02-06 10:50:19 | Stage | Epoch[276/600] Train loss:0.0270
2023-02-06 10:50:19 | Stage | Epoch[276/600] Valid loss:0.1416
2023-02-06 10:50:19 | Stage | Epoch[276/600] LR:0.01

2023-02-06 10:50:19 | Train | Epoch[277/600] Iteration[001/030] Train loss: 0.0289
2023-02-06 10:50:19 | Train | Epoch[277/600] Iteration[002/030] Train loss: 0.0290
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[003/030] Train loss: 0.0295
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[004/030] Train loss: 0.0289
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[005/030] Train loss: 0.0289
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[006/030] Train loss: 0.0282
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[007/030] Train loss: 0.0278
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[008/030] Train loss: 0.0273
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[009/030] Train loss: 0.0280
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[011/030] Train loss: 0.0275
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[012/030] Train loss: 0.0275
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[014/030] Train loss: 0.0272
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[015/030] Train loss: 0.0273
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[016/030] Train loss: 0.0276
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[017/030] Train loss: 0.0278
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[018/030] Train loss: 0.0279
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[019/030] Train loss: 0.0280
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[020/030] Train loss: 0.0283
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[021/030] Train loss: 0.0282
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[022/030] Train loss: 0.0282
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[023/030] Train loss: 0.0285
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[024/030] Train loss: 0.0284
2023-02-06 10:50:20 | Train | Epoch[277/600] Iteration[025/030] Train loss: 0.0283
2023-02-06 10:50:21 | Train | Epoch[277/600] Iteration[026/030] Train loss: 0.0283
2023-02-06 10:50:21 | Train | Epoch[277/600] Iteration[027/030] Train loss: 0.0282
2023-02-06 10:50:21 | Train | Epoch[277/600] Iteration[028/030] Train loss: 0.0281
2023-02-06 10:50:21 | Train | Epoch[277/600] Iteration[029/030] Train loss: 0.0281
2023-02-06 10:50:21 | Train | Epoch[277/600] Iteration[030/030] Train loss: 0.0281
2023-02-06 10:50:21 | Valid | Epoch[277/600] Iteration[001/008] Valid loss: 0.4676
2023-02-06 10:50:21 | Valid | Epoch[277/600] Iteration[002/008] Valid loss: 0.4348
2023-02-06 10:50:21 | Valid | Epoch[277/600] Iteration[003/008] Valid loss: 0.4208
2023-02-06 10:50:21 | Valid | Epoch[277/600] Iteration[004/008] Valid loss: 0.4187
2023-02-06 10:50:21 | Valid | Epoch[277/600] Iteration[005/008] Valid loss: 0.4349
2023-02-06 10:50:21 | Valid | Epoch[277/600] Iteration[006/008] Valid loss: 0.4236
2023-02-06 10:50:21 | Valid | Epoch[277/600] Iteration[007/008] Valid loss: 0.4468
2023-02-06 10:50:21 | Valid | Epoch[277/600] Iteration[008/008] Valid loss: 0.4621
2023-02-06 10:50:21 | Valid | Epoch[277/600] MIou: 0.8559687728501407
2023-02-06 10:50:21 | Valid | Epoch[277/600] Pixel Accuracy: 0.9695027669270834
2023-02-06 10:50:21 | Valid | Epoch[277/600] Mean Pixel Accuracy: 0.9781587023464169
2023-02-06 10:50:21 | Stage | Epoch[277/600] Train loss:0.0281
2023-02-06 10:50:21 | Stage | Epoch[277/600] Valid loss:0.4621
2023-02-06 10:50:21 | Stage | Epoch[277/600] LR:0.01

2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[001/030] Train loss: 0.0309
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[002/030] Train loss: 0.0299
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[003/030] Train loss: 0.0307
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[004/030] Train loss: 0.0292
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[005/030] Train loss: 0.0291
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[006/030] Train loss: 0.0283
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[007/030] Train loss: 0.0281
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[008/030] Train loss: 0.0286
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[009/030] Train loss: 0.0282
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[010/030] Train loss: 0.0283
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[011/030] Train loss: 0.0279
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[012/030] Train loss: 0.0279
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[013/030] Train loss: 0.0278
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[014/030] Train loss: 0.0277
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[015/030] Train loss: 0.0275
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[017/030] Train loss: 0.0273
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[018/030] Train loss: 0.0272
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[020/030] Train loss: 0.0275
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[021/030] Train loss: 0.0272
2023-02-06 10:50:22 | Train | Epoch[278/600] Iteration[022/030] Train loss: 0.0273
2023-02-06 10:50:23 | Train | Epoch[278/600] Iteration[023/030] Train loss: 0.0273
2023-02-06 10:50:23 | Train | Epoch[278/600] Iteration[024/030] Train loss: 0.0272
2023-02-06 10:50:23 | Train | Epoch[278/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 10:50:23 | Train | Epoch[278/600] Iteration[026/030] Train loss: 0.0271
2023-02-06 10:50:23 | Train | Epoch[278/600] Iteration[027/030] Train loss: 0.0271
2023-02-06 10:50:23 | Train | Epoch[278/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 10:50:23 | Train | Epoch[278/600] Iteration[029/030] Train loss: 0.0270
2023-02-06 10:50:23 | Train | Epoch[278/600] Iteration[030/030] Train loss: 0.0271
2023-02-06 10:50:23 | Valid | Epoch[278/600] Iteration[001/008] Valid loss: 0.0644
2023-02-06 10:50:23 | Valid | Epoch[278/600] Iteration[002/008] Valid loss: 0.0629
2023-02-06 10:50:23 | Valid | Epoch[278/600] Iteration[003/008] Valid loss: 0.0644
2023-02-06 10:50:23 | Valid | Epoch[278/600] Iteration[004/008] Valid loss: 0.0637
2023-02-06 10:50:23 | Valid | Epoch[278/600] Iteration[005/008] Valid loss: 0.0647
2023-02-06 10:50:23 | Valid | Epoch[278/600] Iteration[006/008] Valid loss: 0.0635
2023-02-06 10:50:23 | Valid | Epoch[278/600] Iteration[007/008] Valid loss: 0.0620
2023-02-06 10:50:23 | Valid | Epoch[278/600] Iteration[008/008] Valid loss: 0.0634
2023-02-06 10:50:23 | Valid | Epoch[278/600] MIou: 0.7799529952127007
2023-02-06 10:50:23 | Valid | Epoch[278/600] Pixel Accuracy: 0.9637158711751302
2023-02-06 10:50:23 | Valid | Epoch[278/600] Mean Pixel Accuracy: 0.7991313407199876
2023-02-06 10:50:23 | Stage | Epoch[278/600] Train loss:0.0271
2023-02-06 10:50:23 | Stage | Epoch[278/600] Valid loss:0.0634
2023-02-06 10:50:23 | Stage | Epoch[278/600] LR:0.01

2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[001/030] Train loss: 0.0249
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[002/030] Train loss: 0.0300
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[003/030] Train loss: 0.0308
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[004/030] Train loss: 0.0298
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[005/030] Train loss: 0.0293
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[006/030] Train loss: 0.0294
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[007/030] Train loss: 0.0293
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[008/030] Train loss: 0.0294
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[009/030] Train loss: 0.0290
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[010/030] Train loss: 0.0285
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[011/030] Train loss: 0.0283
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[012/030] Train loss: 0.0282
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[013/030] Train loss: 0.0284
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[014/030] Train loss: 0.0280
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[015/030] Train loss: 0.0280
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[016/030] Train loss: 0.0277
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[017/030] Train loss: 0.0275
2023-02-06 10:50:24 | Train | Epoch[279/600] Iteration[018/030] Train loss: 0.0274
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[020/030] Train loss: 0.0272
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[021/030] Train loss: 0.0273
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[022/030] Train loss: 0.0274
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[023/030] Train loss: 0.0275
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[024/030] Train loss: 0.0274
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[025/030] Train loss: 0.0274
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[026/030] Train loss: 0.0275
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[027/030] Train loss: 0.0274
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[028/030] Train loss: 0.0273
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[029/030] Train loss: 0.0272
2023-02-06 10:50:25 | Train | Epoch[279/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 10:50:25 | Valid | Epoch[279/600] Iteration[001/008] Valid loss: 0.1327
2023-02-06 10:50:25 | Valid | Epoch[279/600] Iteration[002/008] Valid loss: 0.1079
2023-02-06 10:50:25 | Valid | Epoch[279/600] Iteration[003/008] Valid loss: 0.1031
2023-02-06 10:50:25 | Valid | Epoch[279/600] Iteration[004/008] Valid loss: 0.1010
2023-02-06 10:50:25 | Valid | Epoch[279/600] Iteration[005/008] Valid loss: 0.1041
2023-02-06 10:50:25 | Valid | Epoch[279/600] Iteration[006/008] Valid loss: 0.1046
2023-02-06 10:50:25 | Valid | Epoch[279/600] Iteration[007/008] Valid loss: 0.1114
2023-02-06 10:50:25 | Valid | Epoch[279/600] Iteration[008/008] Valid loss: 0.1106
2023-02-06 10:50:26 | Valid | Epoch[279/600] MIou: 0.9075124659027405
2023-02-06 10:50:26 | Valid | Epoch[279/600] Pixel Accuracy: 0.9824701944986979
2023-02-06 10:50:26 | Valid | Epoch[279/600] Mean Pixel Accuracy: 0.9799601575170391
2023-02-06 10:50:26 | Stage | Epoch[279/600] Train loss:0.0272
2023-02-06 10:50:26 | Stage | Epoch[279/600] Valid loss:0.1106
2023-02-06 10:50:26 | Stage | Epoch[279/600] LR:0.01

2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[001/030] Train loss: 0.0318
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[002/030] Train loss: 0.0287
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[003/030] Train loss: 0.0279
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[004/030] Train loss: 0.0283
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[005/030] Train loss: 0.0280
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[006/030] Train loss: 0.0286
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[007/030] Train loss: 0.0286
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[008/030] Train loss: 0.0286
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[009/030] Train loss: 0.0285
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[010/030] Train loss: 0.0282
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[011/030] Train loss: 0.0285
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[012/030] Train loss: 0.0282
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[013/030] Train loss: 0.0279
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[014/030] Train loss: 0.0275
2023-02-06 10:50:26 | Train | Epoch[280/600] Iteration[015/030] Train loss: 0.0273
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[016/030] Train loss: 0.0271
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[017/030] Train loss: 0.0272
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[018/030] Train loss: 0.0272
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[019/030] Train loss: 0.0273
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[020/030] Train loss: 0.0274
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[021/030] Train loss: 0.0272
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[022/030] Train loss: 0.0273
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[023/030] Train loss: 0.0271
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[024/030] Train loss: 0.0272
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[025/030] Train loss: 0.0272
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[026/030] Train loss: 0.0272
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[027/030] Train loss: 0.0273
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[028/030] Train loss: 0.0274
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[029/030] Train loss: 0.0274
2023-02-06 10:50:27 | Train | Epoch[280/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 10:50:27 | Valid | Epoch[280/600] Iteration[001/008] Valid loss: 0.7493
2023-02-06 10:50:27 | Valid | Epoch[280/600] Iteration[002/008] Valid loss: 0.7277
2023-02-06 10:50:27 | Valid | Epoch[280/600] Iteration[003/008] Valid loss: 0.7315
2023-02-06 10:50:28 | Valid | Epoch[280/600] Iteration[004/008] Valid loss: 0.7453
2023-02-06 10:50:28 | Valid | Epoch[280/600] Iteration[005/008] Valid loss: 0.7797
2023-02-06 10:50:28 | Valid | Epoch[280/600] Iteration[006/008] Valid loss: 0.7724
2023-02-06 10:50:28 | Valid | Epoch[280/600] Iteration[007/008] Valid loss: 0.8173
2023-02-06 10:50:28 | Valid | Epoch[280/600] Iteration[008/008] Valid loss: 0.8389
2023-02-06 10:50:28 | Valid | Epoch[280/600] MIou: 0.8284385096206024
2023-02-06 10:50:28 | Valid | Epoch[280/600] Pixel Accuracy: 0.9614054361979166
2023-02-06 10:50:28 | Valid | Epoch[280/600] Mean Pixel Accuracy: 0.9759272290640918
2023-02-06 10:50:28 | Stage | Epoch[280/600] Train loss:0.0272
2023-02-06 10:50:28 | Stage | Epoch[280/600] Valid loss:0.8389
2023-02-06 10:50:28 | Stage | Epoch[280/600] LR:0.01

2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[001/030] Train loss: 0.0284
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[002/030] Train loss: 0.0297
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[003/030] Train loss: 0.0310
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[004/030] Train loss: 0.0307
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[005/030] Train loss: 0.0312
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[006/030] Train loss: 0.0297
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[007/030] Train loss: 0.0287
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[008/030] Train loss: 0.0288
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[009/030] Train loss: 0.0285
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[010/030] Train loss: 0.0279
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[011/030] Train loss: 0.0279
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[012/030] Train loss: 0.0275
2023-02-06 10:50:28 | Train | Epoch[281/600] Iteration[013/030] Train loss: 0.0277
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[014/030] Train loss: 0.0278
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[015/030] Train loss: 0.0276
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[016/030] Train loss: 0.0278
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[017/030] Train loss: 0.0280
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[018/030] Train loss: 0.0278
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[020/030] Train loss: 0.0274
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[021/030] Train loss: 0.0274
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[022/030] Train loss: 0.0273
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[023/030] Train loss: 0.0274
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[024/030] Train loss: 0.0273
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[025/030] Train loss: 0.0272
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[026/030] Train loss: 0.0273
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[028/030] Train loss: 0.0272
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[029/030] Train loss: 0.0272
2023-02-06 10:50:29 | Train | Epoch[281/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 10:50:29 | Valid | Epoch[281/600] Iteration[001/008] Valid loss: 0.0514
2023-02-06 10:50:29 | Valid | Epoch[281/600] Iteration[002/008] Valid loss: 0.0479
2023-02-06 10:50:30 | Valid | Epoch[281/600] Iteration[003/008] Valid loss: 0.0487
2023-02-06 10:50:30 | Valid | Epoch[281/600] Iteration[004/008] Valid loss: 0.0475
2023-02-06 10:50:30 | Valid | Epoch[281/600] Iteration[005/008] Valid loss: 0.0482
2023-02-06 10:50:30 | Valid | Epoch[281/600] Iteration[006/008] Valid loss: 0.0474
2023-02-06 10:50:30 | Valid | Epoch[281/600] Iteration[007/008] Valid loss: 0.0465
2023-02-06 10:50:30 | Valid | Epoch[281/600] Iteration[008/008] Valid loss: 0.0470
2023-02-06 10:50:30 | Valid | Epoch[281/600] MIou: 0.8517240709200572
2023-02-06 10:50:30 | Valid | Epoch[281/600] Pixel Accuracy: 0.9755655924479166
2023-02-06 10:50:30 | Valid | Epoch[281/600] Mean Pixel Accuracy: 0.8649722448484309
2023-02-06 10:50:30 | Stage | Epoch[281/600] Train loss:0.0272
2023-02-06 10:50:30 | Stage | Epoch[281/600] Valid loss:0.0470
2023-02-06 10:50:30 | Stage | Epoch[281/600] LR:0.01

2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[001/030] Train loss: 0.0318
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[002/030] Train loss: 0.0282
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[003/030] Train loss: 0.0275
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[006/030] Train loss: 0.0256
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:50:30 | Train | Epoch[282/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[016/030] Train loss: 0.0259
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[017/030] Train loss: 0.0261
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[019/030] Train loss: 0.0260
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[021/030] Train loss: 0.0265
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[022/030] Train loss: 0.0264
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[024/030] Train loss: 0.0265
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[027/030] Train loss: 0.0268
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[028/030] Train loss: 0.0269
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[029/030] Train loss: 0.0267
2023-02-06 10:50:31 | Train | Epoch[282/600] Iteration[030/030] Train loss: 0.0268
2023-02-06 10:50:32 | Valid | Epoch[282/600] Iteration[001/008] Valid loss: 0.1023
2023-02-06 10:50:32 | Valid | Epoch[282/600] Iteration[002/008] Valid loss: 0.0822
2023-02-06 10:50:32 | Valid | Epoch[282/600] Iteration[003/008] Valid loss: 0.0750
2023-02-06 10:50:32 | Valid | Epoch[282/600] Iteration[004/008] Valid loss: 0.0735
2023-02-06 10:50:32 | Valid | Epoch[282/600] Iteration[005/008] Valid loss: 0.0757
2023-02-06 10:50:32 | Valid | Epoch[282/600] Iteration[006/008] Valid loss: 0.0781
2023-02-06 10:50:32 | Valid | Epoch[282/600] Iteration[007/008] Valid loss: 0.0831
2023-02-06 10:50:32 | Valid | Epoch[282/600] Iteration[008/008] Valid loss: 0.0810
2023-02-06 10:50:32 | Valid | Epoch[282/600] MIou: 0.9247868246390928
2023-02-06 10:50:32 | Valid | Epoch[282/600] Pixel Accuracy: 0.9862950642903646
2023-02-06 10:50:32 | Valid | Epoch[282/600] Mean Pixel Accuracy: 0.9784547407909169
2023-02-06 10:50:32 | Stage | Epoch[282/600] Train loss:0.0268
2023-02-06 10:50:32 | Stage | Epoch[282/600] Valid loss:0.0810
2023-02-06 10:50:32 | Stage | Epoch[282/600] LR:0.01

2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[001/030] Train loss: 0.0243
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[002/030] Train loss: 0.0283
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[003/030] Train loss: 0.0276
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[005/030] Train loss: 0.0269
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[006/030] Train loss: 0.0265
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[007/030] Train loss: 0.0264
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[008/030] Train loss: 0.0266
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[009/030] Train loss: 0.0263
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[011/030] Train loss: 0.0262
2023-02-06 10:50:32 | Train | Epoch[283/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[013/030] Train loss: 0.0271
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[014/030] Train loss: 0.0271
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[015/030] Train loss: 0.0271
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[016/030] Train loss: 0.0270
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[017/030] Train loss: 0.0269
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[018/030] Train loss: 0.0273
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[019/030] Train loss: 0.0275
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[020/030] Train loss: 0.0274
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[021/030] Train loss: 0.0273
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[022/030] Train loss: 0.0272
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[024/030] Train loss: 0.0269
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[025/030] Train loss: 0.0269
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[026/030] Train loss: 0.0269
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[027/030] Train loss: 0.0269
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[028/030] Train loss: 0.0267
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[029/030] Train loss: 0.0269
2023-02-06 10:50:33 | Train | Epoch[283/600] Iteration[030/030] Train loss: 0.0270
2023-02-06 10:50:34 | Valid | Epoch[283/600] Iteration[001/008] Valid loss: 0.0579
2023-02-06 10:50:34 | Valid | Epoch[283/600] Iteration[002/008] Valid loss: 0.0560
2023-02-06 10:50:34 | Valid | Epoch[283/600] Iteration[003/008] Valid loss: 0.0572
2023-02-06 10:50:34 | Valid | Epoch[283/600] Iteration[004/008] Valid loss: 0.0562
2023-02-06 10:50:34 | Valid | Epoch[283/600] Iteration[005/008] Valid loss: 0.0571
2023-02-06 10:50:34 | Valid | Epoch[283/600] Iteration[006/008] Valid loss: 0.0561
2023-02-06 10:50:34 | Valid | Epoch[283/600] Iteration[007/008] Valid loss: 0.0549
2023-02-06 10:50:34 | Valid | Epoch[283/600] Iteration[008/008] Valid loss: 0.0560
2023-02-06 10:50:34 | Valid | Epoch[283/600] MIou: 0.8065811899257063
2023-02-06 10:50:34 | Valid | Epoch[283/600] Pixel Accuracy: 0.9681180318196615
2023-02-06 10:50:34 | Valid | Epoch[283/600] Mean Pixel Accuracy: 0.8235270302187012
2023-02-06 10:50:34 | Stage | Epoch[283/600] Train loss:0.0270
2023-02-06 10:50:34 | Stage | Epoch[283/600] Valid loss:0.0560
2023-02-06 10:50:34 | Stage | Epoch[283/600] LR:0.01

2023-02-06 10:50:34 | Train | Epoch[284/600] Iteration[001/030] Train loss: 0.0227
2023-02-06 10:50:34 | Train | Epoch[284/600] Iteration[002/030] Train loss: 0.0250
2023-02-06 10:50:34 | Train | Epoch[284/600] Iteration[003/030] Train loss: 0.0280
2023-02-06 10:50:34 | Train | Epoch[284/600] Iteration[004/030] Train loss: 0.0291
2023-02-06 10:50:34 | Train | Epoch[284/600] Iteration[005/030] Train loss: 0.0287
2023-02-06 10:50:34 | Train | Epoch[284/600] Iteration[006/030] Train loss: 0.0285
2023-02-06 10:50:34 | Train | Epoch[284/600] Iteration[007/030] Train loss: 0.0280
2023-02-06 10:50:34 | Train | Epoch[284/600] Iteration[008/030] Train loss: 0.0275
2023-02-06 10:50:34 | Train | Epoch[284/600] Iteration[009/030] Train loss: 0.0276
2023-02-06 10:50:34 | Train | Epoch[284/600] Iteration[010/030] Train loss: 0.0273
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[011/030] Train loss: 0.0269
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[012/030] Train loss: 0.0269
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[016/030] Train loss: 0.0266
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[019/030] Train loss: 0.0265
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[020/030] Train loss: 0.0263
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[021/030] Train loss: 0.0263
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[022/030] Train loss: 0.0264
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[023/030] Train loss: 0.0268
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[026/030] Train loss: 0.0267
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[027/030] Train loss: 0.0266
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[029/030] Train loss: 0.0267
2023-02-06 10:50:35 | Train | Epoch[284/600] Iteration[030/030] Train loss: 0.0268
2023-02-06 10:50:36 | Valid | Epoch[284/600] Iteration[001/008] Valid loss: 0.0459
2023-02-06 10:50:36 | Valid | Epoch[284/600] Iteration[002/008] Valid loss: 0.0434
2023-02-06 10:50:36 | Valid | Epoch[284/600] Iteration[003/008] Valid loss: 0.0442
2023-02-06 10:50:36 | Valid | Epoch[284/600] Iteration[004/008] Valid loss: 0.0432
2023-02-06 10:50:36 | Valid | Epoch[284/600] Iteration[005/008] Valid loss: 0.0434
2023-02-06 10:50:36 | Valid | Epoch[284/600] Iteration[006/008] Valid loss: 0.0423
2023-02-06 10:50:36 | Valid | Epoch[284/600] Iteration[007/008] Valid loss: 0.0411
2023-02-06 10:50:36 | Valid | Epoch[284/600] Iteration[008/008] Valid loss: 0.0420
2023-02-06 10:50:36 | Valid | Epoch[284/600] MIou: 0.8511777828117354
2023-02-06 10:50:36 | Valid | Epoch[284/600] Pixel Accuracy: 0.9754600524902344
2023-02-06 10:50:36 | Valid | Epoch[284/600] Mean Pixel Accuracy: 0.8646986595551076
2023-02-06 10:50:36 | Stage | Epoch[284/600] Train loss:0.0268
2023-02-06 10:50:36 | Stage | Epoch[284/600] Valid loss:0.0420
2023-02-06 10:50:36 | Stage | Epoch[284/600] LR:0.01

2023-02-06 10:50:36 | Train | Epoch[285/600] Iteration[001/030] Train loss: 0.0291
2023-02-06 10:50:36 | Train | Epoch[285/600] Iteration[002/030] Train loss: 0.0285
2023-02-06 10:50:36 | Train | Epoch[285/600] Iteration[003/030] Train loss: 0.0269
2023-02-06 10:50:36 | Train | Epoch[285/600] Iteration[004/030] Train loss: 0.0258
2023-02-06 10:50:36 | Train | Epoch[285/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 10:50:36 | Train | Epoch[285/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 10:50:36 | Train | Epoch[285/600] Iteration[007/030] Train loss: 0.0271
2023-02-06 10:50:36 | Train | Epoch[285/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[009/030] Train loss: 0.0270
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[011/030] Train loss: 0.0269
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[012/030] Train loss: 0.0272
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[013/030] Train loss: 0.0272
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[014/030] Train loss: 0.0272
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[015/030] Train loss: 0.0272
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[016/030] Train loss: 0.0272
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[017/030] Train loss: 0.0270
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[019/030] Train loss: 0.0269
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[021/030] Train loss: 0.0267
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[022/030] Train loss: 0.0268
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[023/030] Train loss: 0.0269
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[024/030] Train loss: 0.0268
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[025/030] Train loss: 0.0269
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[026/030] Train loss: 0.0269
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[027/030] Train loss: 0.0270
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[029/030] Train loss: 0.0269
2023-02-06 10:50:37 | Train | Epoch[285/600] Iteration[030/030] Train loss: 0.0268
2023-02-06 10:50:38 | Valid | Epoch[285/600] Iteration[001/008] Valid loss: 0.9420
2023-02-06 10:50:38 | Valid | Epoch[285/600] Iteration[002/008] Valid loss: 0.9590
2023-02-06 10:50:38 | Valid | Epoch[285/600] Iteration[003/008] Valid loss: 0.9416
2023-02-06 10:50:38 | Valid | Epoch[285/600] Iteration[004/008] Valid loss: 0.9654
2023-02-06 10:50:38 | Valid | Epoch[285/600] Iteration[005/008] Valid loss: 0.9982
2023-02-06 10:50:38 | Valid | Epoch[285/600] Iteration[006/008] Valid loss: 1.0012
2023-02-06 10:50:38 | Valid | Epoch[285/600] Iteration[007/008] Valid loss: 1.0499
2023-02-06 10:50:38 | Valid | Epoch[285/600] Iteration[008/008] Valid loss: 1.0805
2023-02-06 10:50:38 | Valid | Epoch[285/600] MIou: 0.8056204562196597
2023-02-06 10:50:38 | Valid | Epoch[285/600] Pixel Accuracy: 0.95404052734375
2023-02-06 10:50:38 | Valid | Epoch[285/600] Mean Pixel Accuracy: 0.9727097628201586
2023-02-06 10:50:38 | Stage | Epoch[285/600] Train loss:0.0268
2023-02-06 10:50:38 | Stage | Epoch[285/600] Valid loss:1.0805
2023-02-06 10:50:38 | Stage | Epoch[285/600] LR:0.01

2023-02-06 10:50:38 | Train | Epoch[286/600] Iteration[001/030] Train loss: 0.0267
2023-02-06 10:50:38 | Train | Epoch[286/600] Iteration[002/030] Train loss: 0.0263
2023-02-06 10:50:38 | Train | Epoch[286/600] Iteration[003/030] Train loss: 0.0261
2023-02-06 10:50:38 | Train | Epoch[286/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[005/030] Train loss: 0.0269
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[008/030] Train loss: 0.0267
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[012/030] Train loss: 0.0270
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[013/030] Train loss: 0.0271
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[014/030] Train loss: 0.0269
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[016/030] Train loss: 0.0266
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[017/030] Train loss: 0.0262
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[018/030] Train loss: 0.0263
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[020/030] Train loss: 0.0267
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[022/030] Train loss: 0.0265
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[023/030] Train loss: 0.0266
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[026/030] Train loss: 0.0266
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[027/030] Train loss: 0.0267
2023-02-06 10:50:39 | Train | Epoch[286/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:50:40 | Train | Epoch[286/600] Iteration[029/030] Train loss: 0.0268
2023-02-06 10:50:40 | Train | Epoch[286/600] Iteration[030/030] Train loss: 0.0267
2023-02-06 10:50:40 | Valid | Epoch[286/600] Iteration[001/008] Valid loss: 0.5086
2023-02-06 10:50:40 | Valid | Epoch[286/600] Iteration[002/008] Valid loss: 0.4638
2023-02-06 10:50:40 | Valid | Epoch[286/600] Iteration[003/008] Valid loss: 0.4608
2023-02-06 10:50:40 | Valid | Epoch[286/600] Iteration[004/008] Valid loss: 0.4613
2023-02-06 10:50:40 | Valid | Epoch[286/600] Iteration[005/008] Valid loss: 0.4859
2023-02-06 10:50:40 | Valid | Epoch[286/600] Iteration[006/008] Valid loss: 0.4770
2023-02-06 10:50:40 | Valid | Epoch[286/600] Iteration[007/008] Valid loss: 0.5071
2023-02-06 10:50:40 | Valid | Epoch[286/600] Iteration[008/008] Valid loss: 0.5174
2023-02-06 10:50:40 | Valid | Epoch[286/600] MIou: 0.8562358801254976
2023-02-06 10:50:40 | Valid | Epoch[286/600] Pixel Accuracy: 0.9695536295572916
2023-02-06 10:50:40 | Valid | Epoch[286/600] Mean Pixel Accuracy: 0.9785734273794551
2023-02-06 10:50:40 | Stage | Epoch[286/600] Train loss:0.0267
2023-02-06 10:50:40 | Stage | Epoch[286/600] Valid loss:0.5174
2023-02-06 10:50:40 | Stage | Epoch[286/600] LR:0.01

2023-02-06 10:50:40 | Train | Epoch[287/600] Iteration[001/030] Train loss: 0.0286
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[002/030] Train loss: 0.0244
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[004/030] Train loss: 0.0274
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[005/030] Train loss: 0.0268
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[007/030] Train loss: 0.0279
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[008/030] Train loss: 0.0279
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[009/030] Train loss: 0.0276
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[011/030] Train loss: 0.0282
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[012/030] Train loss: 0.0280
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[013/030] Train loss: 0.0278
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[014/030] Train loss: 0.0277
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[015/030] Train loss: 0.0277
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[017/030] Train loss: 0.0273
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[018/030] Train loss: 0.0271
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[019/030] Train loss: 0.0271
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[020/030] Train loss: 0.0271
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[021/030] Train loss: 0.0271
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[022/030] Train loss: 0.0270
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[024/030] Train loss: 0.0270
2023-02-06 10:50:41 | Train | Epoch[287/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 10:50:42 | Train | Epoch[287/600] Iteration[026/030] Train loss: 0.0270
2023-02-06 10:50:42 | Train | Epoch[287/600] Iteration[027/030] Train loss: 0.0270
2023-02-06 10:50:42 | Train | Epoch[287/600] Iteration[028/030] Train loss: 0.0271
2023-02-06 10:50:42 | Train | Epoch[287/600] Iteration[029/030] Train loss: 0.0270
2023-02-06 10:50:42 | Train | Epoch[287/600] Iteration[030/030] Train loss: 0.0271
2023-02-06 10:50:42 | Valid | Epoch[287/600] Iteration[001/008] Valid loss: 2.1594
2023-02-06 10:50:42 | Valid | Epoch[287/600] Iteration[002/008] Valid loss: 2.1027
2023-02-06 10:50:42 | Valid | Epoch[287/600] Iteration[003/008] Valid loss: 2.1263
2023-02-06 10:50:42 | Valid | Epoch[287/600] Iteration[004/008] Valid loss: 2.1963
2023-02-06 10:50:42 | Valid | Epoch[287/600] Iteration[005/008] Valid loss: 2.2453
2023-02-06 10:50:42 | Valid | Epoch[287/600] Iteration[006/008] Valid loss: 2.2545
2023-02-06 10:50:42 | Valid | Epoch[287/600] Iteration[007/008] Valid loss: 2.3416
2023-02-06 10:50:42 | Valid | Epoch[287/600] Iteration[008/008] Valid loss: 2.4046
2023-02-06 10:50:42 | Valid | Epoch[287/600] MIou: 0.7522824200960092
2023-02-06 10:50:42 | Valid | Epoch[287/600] Pixel Accuracy: 0.933996836344401
2023-02-06 10:50:42 | Valid | Epoch[287/600] Mean Pixel Accuracy: 0.9624854543431807
2023-02-06 10:50:42 | Stage | Epoch[287/600] Train loss:0.0271
2023-02-06 10:50:42 | Stage | Epoch[287/600] Valid loss:2.4046
2023-02-06 10:50:42 | Stage | Epoch[287/600] LR:0.01

2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[001/030] Train loss: 0.0318
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[002/030] Train loss: 0.0285
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[004/030] Train loss: 0.0271
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[005/030] Train loss: 0.0273
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[006/030] Train loss: 0.0275
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[007/030] Train loss: 0.0274
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[009/030] Train loss: 0.0269
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[010/030] Train loss: 0.0267
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[012/030] Train loss: 0.0268
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[014/030] Train loss: 0.0266
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[015/030] Train loss: 0.0264
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[016/030] Train loss: 0.0268
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[017/030] Train loss: 0.0269
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[018/030] Train loss: 0.0269
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[019/030] Train loss: 0.0269
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[020/030] Train loss: 0.0269
2023-02-06 10:50:43 | Train | Epoch[288/600] Iteration[021/030] Train loss: 0.0269
2023-02-06 10:50:44 | Train | Epoch[288/600] Iteration[022/030] Train loss: 0.0271
2023-02-06 10:50:44 | Train | Epoch[288/600] Iteration[023/030] Train loss: 0.0272
2023-02-06 10:50:44 | Train | Epoch[288/600] Iteration[024/030] Train loss: 0.0272
2023-02-06 10:50:44 | Train | Epoch[288/600] Iteration[025/030] Train loss: 0.0273
2023-02-06 10:50:44 | Train | Epoch[288/600] Iteration[026/030] Train loss: 0.0276
2023-02-06 10:50:44 | Train | Epoch[288/600] Iteration[027/030] Train loss: 0.0278
2023-02-06 10:50:44 | Train | Epoch[288/600] Iteration[028/030] Train loss: 0.0277
2023-02-06 10:50:44 | Train | Epoch[288/600] Iteration[029/030] Train loss: 0.0276
2023-02-06 10:50:44 | Train | Epoch[288/600] Iteration[030/030] Train loss: 0.0275
2023-02-06 10:50:44 | Valid | Epoch[288/600] Iteration[001/008] Valid loss: 0.0464
2023-02-06 10:50:44 | Valid | Epoch[288/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 10:50:44 | Valid | Epoch[288/600] Iteration[003/008] Valid loss: 0.0372
2023-02-06 10:50:44 | Valid | Epoch[288/600] Iteration[004/008] Valid loss: 0.0360
2023-02-06 10:50:44 | Valid | Epoch[288/600] Iteration[005/008] Valid loss: 0.0375
2023-02-06 10:50:44 | Valid | Epoch[288/600] Iteration[006/008] Valid loss: 0.0377
2023-02-06 10:50:44 | Valid | Epoch[288/600] Iteration[007/008] Valid loss: 0.0391
2023-02-06 10:50:44 | Valid | Epoch[288/600] Iteration[008/008] Valid loss: 0.0385
2023-02-06 10:50:45 | Valid | Epoch[288/600] MIou: 0.9370756361533046
2023-02-06 10:50:45 | Valid | Epoch[288/600] Pixel Accuracy: 0.9892616271972656
2023-02-06 10:50:45 | Valid | Epoch[288/600] Mean Pixel Accuracy: 0.9593392674978725
2023-02-06 10:50:45 | Stage | Epoch[288/600] Train loss:0.0275
2023-02-06 10:50:45 | Stage | Epoch[288/600] Valid loss:0.0385
2023-02-06 10:50:45 | Stage | Epoch[288/600] LR:0.01

2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[001/030] Train loss: 0.0322
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[002/030] Train loss: 0.0279
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[003/030] Train loss: 0.0275
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[004/030] Train loss: 0.0274
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[005/030] Train loss: 0.0289
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[006/030] Train loss: 0.0288
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[007/030] Train loss: 0.0289
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[008/030] Train loss: 0.0285
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[009/030] Train loss: 0.0276
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[010/030] Train loss: 0.0276
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[012/030] Train loss: 0.0274
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[013/030] Train loss: 0.0272
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[014/030] Train loss: 0.0272
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[015/030] Train loss: 0.0270
2023-02-06 10:50:45 | Train | Epoch[289/600] Iteration[016/030] Train loss: 0.0270
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[017/030] Train loss: 0.0270
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[018/030] Train loss: 0.0273
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[019/030] Train loss: 0.0273
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[020/030] Train loss: 0.0270
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[021/030] Train loss: 0.0269
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[022/030] Train loss: 0.0269
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[023/030] Train loss: 0.0271
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[024/030] Train loss: 0.0273
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[025/030] Train loss: 0.0273
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[026/030] Train loss: 0.0274
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[027/030] Train loss: 0.0273
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[028/030] Train loss: 0.0273
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[029/030] Train loss: 0.0274
2023-02-06 10:50:46 | Train | Epoch[289/600] Iteration[030/030] Train loss: 0.0276
2023-02-06 10:50:46 | Valid | Epoch[289/600] Iteration[001/008] Valid loss: 1.7759
2023-02-06 10:50:46 | Valid | Epoch[289/600] Iteration[002/008] Valid loss: 1.7530
2023-02-06 10:50:46 | Valid | Epoch[289/600] Iteration[003/008] Valid loss: 1.7666
2023-02-06 10:50:47 | Valid | Epoch[289/600] Iteration[004/008] Valid loss: 1.8156
2023-02-06 10:50:47 | Valid | Epoch[289/600] Iteration[005/008] Valid loss: 1.8636
2023-02-06 10:50:47 | Valid | Epoch[289/600] Iteration[006/008] Valid loss: 1.8672
2023-02-06 10:50:47 | Valid | Epoch[289/600] Iteration[007/008] Valid loss: 1.9490
2023-02-06 10:50:47 | Valid | Epoch[289/600] Iteration[008/008] Valid loss: 2.0030
2023-02-06 10:50:47 | Valid | Epoch[289/600] MIou: 0.7665039184171509
2023-02-06 10:50:47 | Valid | Epoch[289/600] Pixel Accuracy: 0.9397506713867188
2023-02-06 10:50:47 | Valid | Epoch[289/600] Mean Pixel Accuracy: 0.9657050717211766
2023-02-06 10:50:47 | Stage | Epoch[289/600] Train loss:0.0276
2023-02-06 10:50:47 | Stage | Epoch[289/600] Valid loss:2.0030
2023-02-06 10:50:47 | Stage | Epoch[289/600] LR:0.01

2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[001/030] Train loss: 0.0302
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[002/030] Train loss: 0.0304
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[003/030] Train loss: 0.0284
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[004/030] Train loss: 0.0290
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[005/030] Train loss: 0.0285
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[006/030] Train loss: 0.0284
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[007/030] Train loss: 0.0284
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[008/030] Train loss: 0.0287
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[009/030] Train loss: 0.0284
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[010/030] Train loss: 0.0283
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[011/030] Train loss: 0.0286
2023-02-06 10:50:47 | Train | Epoch[290/600] Iteration[012/030] Train loss: 0.0288
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[013/030] Train loss: 0.0288
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[014/030] Train loss: 0.0284
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[015/030] Train loss: 0.0283
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[016/030] Train loss: 0.0280
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[017/030] Train loss: 0.0281
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[018/030] Train loss: 0.0281
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[019/030] Train loss: 0.0279
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[020/030] Train loss: 0.0278
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[022/030] Train loss: 0.0274
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[023/030] Train loss: 0.0274
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[024/030] Train loss: 0.0273
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[025/030] Train loss: 0.0274
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[026/030] Train loss: 0.0274
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[027/030] Train loss: 0.0275
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[028/030] Train loss: 0.0273
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[029/030] Train loss: 0.0274
2023-02-06 10:50:48 | Train | Epoch[290/600] Iteration[030/030] Train loss: 0.0276
2023-02-06 10:50:49 | Valid | Epoch[290/600] Iteration[001/008] Valid loss: 0.0586
2023-02-06 10:50:49 | Valid | Epoch[290/600] Iteration[002/008] Valid loss: 0.0461
2023-02-06 10:50:49 | Valid | Epoch[290/600] Iteration[003/008] Valid loss: 0.0428
2023-02-06 10:50:49 | Valid | Epoch[290/600] Iteration[004/008] Valid loss: 0.0408
2023-02-06 10:50:49 | Valid | Epoch[290/600] Iteration[005/008] Valid loss: 0.0417
2023-02-06 10:50:49 | Valid | Epoch[290/600] Iteration[006/008] Valid loss: 0.0407
2023-02-06 10:50:49 | Valid | Epoch[290/600] Iteration[007/008] Valid loss: 0.0423
2023-02-06 10:50:49 | Valid | Epoch[290/600] Iteration[008/008] Valid loss: 0.0423
2023-02-06 10:50:49 | Valid | Epoch[290/600] MIou: 0.9285039272734584
2023-02-06 10:50:49 | Valid | Epoch[290/600] Pixel Accuracy: 0.987677256266276
2023-02-06 10:50:49 | Valid | Epoch[290/600] Mean Pixel Accuracy: 0.9556976436116358
2023-02-06 10:50:49 | Stage | Epoch[290/600] Train loss:0.0276
2023-02-06 10:50:49 | Stage | Epoch[290/600] Valid loss:0.0423
2023-02-06 10:50:49 | Stage | Epoch[290/600] LR:0.01

2023-02-06 10:50:49 | Train | Epoch[291/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 10:50:49 | Train | Epoch[291/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 10:50:49 | Train | Epoch[291/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 10:50:49 | Train | Epoch[291/600] Iteration[004/030] Train loss: 0.0262
2023-02-06 10:50:49 | Train | Epoch[291/600] Iteration[005/030] Train loss: 0.0262
2023-02-06 10:50:49 | Train | Epoch[291/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 10:50:49 | Train | Epoch[291/600] Iteration[007/030] Train loss: 0.0275
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[009/030] Train loss: 0.0277
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[010/030] Train loss: 0.0273
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[011/030] Train loss: 0.0270
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[012/030] Train loss: 0.0270
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[013/030] Train loss: 0.0268
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[016/030] Train loss: 0.0270
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[019/030] Train loss: 0.0265
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[020/030] Train loss: 0.0266
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[021/030] Train loss: 0.0267
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[024/030] Train loss: 0.0268
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[025/030] Train loss: 0.0267
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[026/030] Train loss: 0.0267
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[027/030] Train loss: 0.0268
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[029/030] Train loss: 0.0267
2023-02-06 10:50:50 | Train | Epoch[291/600] Iteration[030/030] Train loss: 0.0270
2023-02-06 10:50:51 | Valid | Epoch[291/600] Iteration[001/008] Valid loss: 0.0697
2023-02-06 10:50:51 | Valid | Epoch[291/600] Iteration[002/008] Valid loss: 0.0674
2023-02-06 10:50:51 | Valid | Epoch[291/600] Iteration[003/008] Valid loss: 0.0693
2023-02-06 10:50:51 | Valid | Epoch[291/600] Iteration[004/008] Valid loss: 0.0685
2023-02-06 10:50:51 | Valid | Epoch[291/600] Iteration[005/008] Valid loss: 0.0693
2023-02-06 10:50:51 | Valid | Epoch[291/600] Iteration[006/008] Valid loss: 0.0676
2023-02-06 10:50:51 | Valid | Epoch[291/600] Iteration[007/008] Valid loss: 0.0655
2023-02-06 10:50:51 | Valid | Epoch[291/600] Iteration[008/008] Valid loss: 0.0671
2023-02-06 10:50:51 | Valid | Epoch[291/600] MIou: 0.7872464801838543
2023-02-06 10:50:51 | Valid | Epoch[291/600] Pixel Accuracy: 0.9649098714192709
2023-02-06 10:50:51 | Valid | Epoch[291/600] Mean Pixel Accuracy: 0.8059188501292273
2023-02-06 10:50:51 | Stage | Epoch[291/600] Train loss:0.0270
2023-02-06 10:50:51 | Stage | Epoch[291/600] Valid loss:0.0671
2023-02-06 10:50:51 | Stage | Epoch[291/600] LR:0.01

2023-02-06 10:50:51 | Train | Epoch[292/600] Iteration[001/030] Train loss: 0.0280
2023-02-06 10:50:51 | Train | Epoch[292/600] Iteration[002/030] Train loss: 0.0277
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[005/030] Train loss: 0.0265
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[012/030] Train loss: 0.0262
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[013/030] Train loss: 0.0265
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[015/030] Train loss: 0.0271
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[016/030] Train loss: 0.0272
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[017/030] Train loss: 0.0271
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[018/030] Train loss: 0.0272
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[019/030] Train loss: 0.0271
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[020/030] Train loss: 0.0272
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[021/030] Train loss: 0.0272
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[022/030] Train loss: 0.0272
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[023/030] Train loss: 0.0273
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[024/030] Train loss: 0.0271
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[025/030] Train loss: 0.0274
2023-02-06 10:50:52 | Train | Epoch[292/600] Iteration[026/030] Train loss: 0.0274
2023-02-06 10:50:53 | Train | Epoch[292/600] Iteration[027/030] Train loss: 0.0276
2023-02-06 10:50:53 | Train | Epoch[292/600] Iteration[028/030] Train loss: 0.0276
2023-02-06 10:50:53 | Train | Epoch[292/600] Iteration[029/030] Train loss: 0.0275
2023-02-06 10:50:53 | Train | Epoch[292/600] Iteration[030/030] Train loss: 0.0276
2023-02-06 10:50:53 | Valid | Epoch[292/600] Iteration[001/008] Valid loss: 0.0815
2023-02-06 10:50:53 | Valid | Epoch[292/600] Iteration[002/008] Valid loss: 0.0789
2023-02-06 10:50:53 | Valid | Epoch[292/600] Iteration[003/008] Valid loss: 0.0805
2023-02-06 10:50:53 | Valid | Epoch[292/600] Iteration[004/008] Valid loss: 0.0795
2023-02-06 10:50:53 | Valid | Epoch[292/600] Iteration[005/008] Valid loss: 0.0810
2023-02-06 10:50:53 | Valid | Epoch[292/600] Iteration[006/008] Valid loss: 0.0792
2023-02-06 10:50:53 | Valid | Epoch[292/600] Iteration[007/008] Valid loss: 0.0773
2023-02-06 10:50:53 | Valid | Epoch[292/600] Iteration[008/008] Valid loss: 0.0790
2023-02-06 10:50:53 | Valid | Epoch[292/600] MIou: 0.7675253049232289
2023-02-06 10:50:53 | Valid | Epoch[292/600] Pixel Accuracy: 0.9614384969075521
2023-02-06 10:50:53 | Valid | Epoch[292/600] Mean Pixel Accuracy: 0.7893833668686764
2023-02-06 10:50:53 | Stage | Epoch[292/600] Train loss:0.0276
2023-02-06 10:50:53 | Stage | Epoch[292/600] Valid loss:0.0790
2023-02-06 10:50:53 | Stage | Epoch[292/600] LR:0.01

2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[001/030] Train loss: 0.0226
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[002/030] Train loss: 0.0252
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[004/030] Train loss: 0.0263
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[005/030] Train loss: 0.0266
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[006/030] Train loss: 0.0274
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[007/030] Train loss: 0.0279
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[008/030] Train loss: 0.0280
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[009/030] Train loss: 0.0278
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[010/030] Train loss: 0.0281
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[011/030] Train loss: 0.0281
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[012/030] Train loss: 0.0278
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[013/030] Train loss: 0.0277
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[014/030] Train loss: 0.0278
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[015/030] Train loss: 0.0277
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[016/030] Train loss: 0.0276
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[017/030] Train loss: 0.0279
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[018/030] Train loss: 0.0278
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 10:50:54 | Train | Epoch[293/600] Iteration[020/030] Train loss: 0.0276
2023-02-06 10:50:55 | Train | Epoch[293/600] Iteration[021/030] Train loss: 0.0278
2023-02-06 10:50:55 | Train | Epoch[293/600] Iteration[022/030] Train loss: 0.0276
2023-02-06 10:50:55 | Train | Epoch[293/600] Iteration[023/030] Train loss: 0.0276
2023-02-06 10:50:55 | Train | Epoch[293/600] Iteration[024/030] Train loss: 0.0278
2023-02-06 10:50:55 | Train | Epoch[293/600] Iteration[025/030] Train loss: 0.0279
2023-02-06 10:50:55 | Train | Epoch[293/600] Iteration[026/030] Train loss: 0.0278
2023-02-06 10:50:55 | Train | Epoch[293/600] Iteration[027/030] Train loss: 0.0276
2023-02-06 10:50:55 | Train | Epoch[293/600] Iteration[028/030] Train loss: 0.0274
2023-02-06 10:50:55 | Train | Epoch[293/600] Iteration[029/030] Train loss: 0.0275
2023-02-06 10:50:55 | Train | Epoch[293/600] Iteration[030/030] Train loss: 0.0273
2023-02-06 10:50:55 | Valid | Epoch[293/600] Iteration[001/008] Valid loss: 0.0401
2023-02-06 10:50:55 | Valid | Epoch[293/600] Iteration[002/008] Valid loss: 0.0364
2023-02-06 10:50:55 | Valid | Epoch[293/600] Iteration[003/008] Valid loss: 0.0364
2023-02-06 10:50:55 | Valid | Epoch[293/600] Iteration[004/008] Valid loss: 0.0352
2023-02-06 10:50:55 | Valid | Epoch[293/600] Iteration[005/008] Valid loss: 0.0355
2023-02-06 10:50:55 | Valid | Epoch[293/600] Iteration[006/008] Valid loss: 0.0351
2023-02-06 10:50:55 | Valid | Epoch[293/600] Iteration[007/008] Valid loss: 0.0348
2023-02-06 10:50:55 | Valid | Epoch[293/600] Iteration[008/008] Valid loss: 0.0351
2023-02-06 10:50:56 | Valid | Epoch[293/600] MIou: 0.8863056364959816
2023-02-06 10:50:56 | Valid | Epoch[293/600] Pixel Accuracy: 0.9812037150065104
2023-02-06 10:50:56 | Valid | Epoch[293/600] Mean Pixel Accuracy: 0.8980679681903949
2023-02-06 10:50:56 | Stage | Epoch[293/600] Train loss:0.0273
2023-02-06 10:50:56 | Stage | Epoch[293/600] Valid loss:0.0351
2023-02-06 10:50:56 | Stage | Epoch[293/600] LR:0.01

2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[001/030] Train loss: 0.0316
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[002/030] Train loss: 0.0282
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[003/030] Train loss: 0.0286
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[004/030] Train loss: 0.0282
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[005/030] Train loss: 0.0280
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[006/030] Train loss: 0.0291
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[007/030] Train loss: 0.0282
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[008/030] Train loss: 0.0280
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[009/030] Train loss: 0.0277
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[010/030] Train loss: 0.0275
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[011/030] Train loss: 0.0276
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[014/030] Train loss: 0.0276
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[015/030] Train loss: 0.0277
2023-02-06 10:50:56 | Train | Epoch[294/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[017/030] Train loss: 0.0273
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[018/030] Train loss: 0.0273
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[020/030] Train loss: 0.0276
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[022/030] Train loss: 0.0274
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[023/030] Train loss: 0.0275
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[024/030] Train loss: 0.0275
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[025/030] Train loss: 0.0276
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[026/030] Train loss: 0.0277
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[027/030] Train loss: 0.0277
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[028/030] Train loss: 0.0274
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[029/030] Train loss: 0.0274
2023-02-06 10:50:57 | Train | Epoch[294/600] Iteration[030/030] Train loss: 0.0274
2023-02-06 10:50:57 | Valid | Epoch[294/600] Iteration[001/008] Valid loss: 0.0430
2023-02-06 10:50:57 | Valid | Epoch[294/600] Iteration[002/008] Valid loss: 0.0389
2023-02-06 10:50:57 | Valid | Epoch[294/600] Iteration[003/008] Valid loss: 0.0393
2023-02-06 10:50:57 | Valid | Epoch[294/600] Iteration[004/008] Valid loss: 0.0381
2023-02-06 10:50:58 | Valid | Epoch[294/600] Iteration[005/008] Valid loss: 0.0386
2023-02-06 10:50:58 | Valid | Epoch[294/600] Iteration[006/008] Valid loss: 0.0379
2023-02-06 10:50:58 | Valid | Epoch[294/600] Iteration[007/008] Valid loss: 0.0375
2023-02-06 10:50:58 | Valid | Epoch[294/600] Iteration[008/008] Valid loss: 0.0377
2023-02-06 10:50:58 | Valid | Epoch[294/600] MIou: 0.8802209915143429
2023-02-06 10:50:58 | Valid | Epoch[294/600] Pixel Accuracy: 0.9802335103352865
2023-02-06 10:50:58 | Valid | Epoch[294/600] Mean Pixel Accuracy: 0.8917458518343329
2023-02-06 10:50:58 | Stage | Epoch[294/600] Train loss:0.0274
2023-02-06 10:50:58 | Stage | Epoch[294/600] Valid loss:0.0377
2023-02-06 10:50:58 | Stage | Epoch[294/600] LR:0.01

2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[001/030] Train loss: 0.0290
2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[002/030] Train loss: 0.0296
2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[003/030] Train loss: 0.0270
2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[004/030] Train loss: 0.0275
2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[005/030] Train loss: 0.0274
2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[006/030] Train loss: 0.0275
2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[009/030] Train loss: 0.0266
2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[010/030] Train loss: 0.0272
2023-02-06 10:50:58 | Train | Epoch[295/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[012/030] Train loss: 0.0271
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[013/030] Train loss: 0.0273
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[014/030] Train loss: 0.0275
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[015/030] Train loss: 0.0273
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[017/030] Train loss: 0.0275
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[018/030] Train loss: 0.0273
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[019/030] Train loss: 0.0272
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[020/030] Train loss: 0.0269
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[021/030] Train loss: 0.0268
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[023/030] Train loss: 0.0266
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[025/030] Train loss: 0.0270
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[026/030] Train loss: 0.0270
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[027/030] Train loss: 0.0270
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[029/030] Train loss: 0.0267
2023-02-06 10:50:59 | Train | Epoch[295/600] Iteration[030/030] Train loss: 0.0268
2023-02-06 10:51:00 | Valid | Epoch[295/600] Iteration[001/008] Valid loss: 0.0441
2023-02-06 10:51:00 | Valid | Epoch[295/600] Iteration[002/008] Valid loss: 0.0421
2023-02-06 10:51:00 | Valid | Epoch[295/600] Iteration[003/008] Valid loss: 0.0430
2023-02-06 10:51:00 | Valid | Epoch[295/600] Iteration[004/008] Valid loss: 0.0421
2023-02-06 10:51:00 | Valid | Epoch[295/600] Iteration[005/008] Valid loss: 0.0425
2023-02-06 10:51:00 | Valid | Epoch[295/600] Iteration[006/008] Valid loss: 0.0415
2023-02-06 10:51:00 | Valid | Epoch[295/600] Iteration[007/008] Valid loss: 0.0405
2023-02-06 10:51:00 | Valid | Epoch[295/600] Iteration[008/008] Valid loss: 0.0413
2023-02-06 10:51:00 | Valid | Epoch[295/600] MIou: 0.8542369339049796
2023-02-06 10:51:00 | Valid | Epoch[295/600] Pixel Accuracy: 0.9759610493977865
2023-02-06 10:51:00 | Valid | Epoch[295/600] Mean Pixel Accuracy: 0.8675672816709402
2023-02-06 10:51:00 | Stage | Epoch[295/600] Train loss:0.0268
2023-02-06 10:51:00 | Stage | Epoch[295/600] Valid loss:0.0413
2023-02-06 10:51:00 | Stage | Epoch[295/600] LR:0.01

2023-02-06 10:51:00 | Train | Epoch[296/600] Iteration[001/030] Train loss: 0.0323
2023-02-06 10:51:00 | Train | Epoch[296/600] Iteration[002/030] Train loss: 0.0287
2023-02-06 10:51:00 | Train | Epoch[296/600] Iteration[003/030] Train loss: 0.0273
2023-02-06 10:51:00 | Train | Epoch[296/600] Iteration[004/030] Train loss: 0.0267
2023-02-06 10:51:00 | Train | Epoch[296/600] Iteration[005/030] Train loss: 0.0275
2023-02-06 10:51:00 | Train | Epoch[296/600] Iteration[006/030] Train loss: 0.0271
2023-02-06 10:51:00 | Train | Epoch[296/600] Iteration[007/030] Train loss: 0.0274
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[008/030] Train loss: 0.0274
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[009/030] Train loss: 0.0269
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[010/030] Train loss: 0.0266
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[011/030] Train loss: 0.0262
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[016/030] Train loss: 0.0268
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[018/030] Train loss: 0.0268
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[019/030] Train loss: 0.0269
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[020/030] Train loss: 0.0267
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[022/030] Train loss: 0.0264
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[024/030] Train loss: 0.0265
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[025/030] Train loss: 0.0267
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[027/030] Train loss: 0.0267
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[029/030] Train loss: 0.0267
2023-02-06 10:51:01 | Train | Epoch[296/600] Iteration[030/030] Train loss: 0.0268
2023-02-06 10:51:02 | Valid | Epoch[296/600] Iteration[001/008] Valid loss: 0.0795
2023-02-06 10:51:02 | Valid | Epoch[296/600] Iteration[002/008] Valid loss: 0.0786
2023-02-06 10:51:02 | Valid | Epoch[296/600] Iteration[003/008] Valid loss: 0.0810
2023-02-06 10:51:02 | Valid | Epoch[296/600] Iteration[004/008] Valid loss: 0.0806
2023-02-06 10:51:02 | Valid | Epoch[296/600] Iteration[005/008] Valid loss: 0.0821
2023-02-06 10:51:02 | Valid | Epoch[296/600] Iteration[006/008] Valid loss: 0.0805
2023-02-06 10:51:02 | Valid | Epoch[296/600] Iteration[007/008] Valid loss: 0.0784
2023-02-06 10:51:02 | Valid | Epoch[296/600] Iteration[008/008] Valid loss: 0.0805
2023-02-06 10:51:02 | Valid | Epoch[296/600] MIou: 0.7282726789379337
2023-02-06 10:51:02 | Valid | Epoch[296/600] Pixel Accuracy: 0.9551556905110677
2023-02-06 10:51:02 | Valid | Epoch[296/600] Mean Pixel Accuracy: 0.7517802889538947
2023-02-06 10:51:02 | Stage | Epoch[296/600] Train loss:0.0268
2023-02-06 10:51:02 | Stage | Epoch[296/600] Valid loss:0.0805
2023-02-06 10:51:02 | Stage | Epoch[296/600] LR:0.01

2023-02-06 10:51:02 | Train | Epoch[297/600] Iteration[001/030] Train loss: 0.0270
2023-02-06 10:51:02 | Train | Epoch[297/600] Iteration[002/030] Train loss: 0.0261
2023-02-06 10:51:02 | Train | Epoch[297/600] Iteration[003/030] Train loss: 0.0269
2023-02-06 10:51:02 | Train | Epoch[297/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 10:51:02 | Train | Epoch[297/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[006/030] Train loss: 0.0270
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[007/030] Train loss: 0.0271
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[016/030] Train loss: 0.0266
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[017/030] Train loss: 0.0269
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[018/030] Train loss: 0.0269
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[020/030] Train loss: 0.0267
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[026/030] Train loss: 0.0264
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 10:51:03 | Train | Epoch[297/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 10:51:04 | Train | Epoch[297/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 10:51:04 | Train | Epoch[297/600] Iteration[030/030] Train loss: 0.0267
2023-02-06 10:51:04 | Valid | Epoch[297/600] Iteration[001/008] Valid loss: 0.0605
2023-02-06 10:51:04 | Valid | Epoch[297/600] Iteration[002/008] Valid loss: 0.0594
2023-02-06 10:51:04 | Valid | Epoch[297/600] Iteration[003/008] Valid loss: 0.0612
2023-02-06 10:51:04 | Valid | Epoch[297/600] Iteration[004/008] Valid loss: 0.0604
2023-02-06 10:51:04 | Valid | Epoch[297/600] Iteration[005/008] Valid loss: 0.0611
2023-02-06 10:51:04 | Valid | Epoch[297/600] Iteration[006/008] Valid loss: 0.0596
2023-02-06 10:51:04 | Valid | Epoch[297/600] Iteration[007/008] Valid loss: 0.0577
2023-02-06 10:51:04 | Valid | Epoch[297/600] Iteration[008/008] Valid loss: 0.0591
2023-02-06 10:51:04 | Valid | Epoch[297/600] MIou: 0.8013501066166738
2023-02-06 10:51:04 | Valid | Epoch[297/600] Pixel Accuracy: 0.9672368367513021
2023-02-06 10:51:04 | Valid | Epoch[297/600] Mean Pixel Accuracy: 0.81889601945817
2023-02-06 10:51:04 | Stage | Epoch[297/600] Train loss:0.0267
2023-02-06 10:51:04 | Stage | Epoch[297/600] Valid loss:0.0591
2023-02-06 10:51:04 | Stage | Epoch[297/600] LR:0.01

2023-02-06 10:51:04 | Train | Epoch[298/600] Iteration[001/030] Train loss: 0.0220
2023-02-06 10:51:04 | Train | Epoch[298/600] Iteration[002/030] Train loss: 0.0250
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[003/030] Train loss: 0.0246
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[005/030] Train loss: 0.0258
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[010/030] Train loss: 0.0269
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[015/030] Train loss: 0.0265
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[018/030] Train loss: 0.0266
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[020/030] Train loss: 0.0264
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[021/030] Train loss: 0.0267
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[022/030] Train loss: 0.0268
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[023/030] Train loss: 0.0269
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:51:05 | Train | Epoch[298/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:51:06 | Train | Epoch[298/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 10:51:06 | Train | Epoch[298/600] Iteration[027/030] Train loss: 0.0266
2023-02-06 10:51:06 | Train | Epoch[298/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:51:06 | Train | Epoch[298/600] Iteration[029/030] Train loss: 0.0269
2023-02-06 10:51:06 | Train | Epoch[298/600] Iteration[030/030] Train loss: 0.0269
2023-02-06 10:51:06 | Valid | Epoch[298/600] Iteration[001/008] Valid loss: 0.6510
2023-02-06 10:51:06 | Valid | Epoch[298/600] Iteration[002/008] Valid loss: 0.6308
2023-02-06 10:51:06 | Valid | Epoch[298/600] Iteration[003/008] Valid loss: 0.6317
2023-02-06 10:51:06 | Valid | Epoch[298/600] Iteration[004/008] Valid loss: 0.6412
2023-02-06 10:51:06 | Valid | Epoch[298/600] Iteration[005/008] Valid loss: 0.6716
2023-02-06 10:51:06 | Valid | Epoch[298/600] Iteration[006/008] Valid loss: 0.6617
2023-02-06 10:51:06 | Valid | Epoch[298/600] Iteration[007/008] Valid loss: 0.7001
2023-02-06 10:51:06 | Valid | Epoch[298/600] Iteration[008/008] Valid loss: 0.7152
2023-02-06 10:51:06 | Valid | Epoch[298/600] MIou: 0.8391224217439907
2023-02-06 10:51:06 | Valid | Epoch[298/600] Pixel Accuracy: 0.9646275838216146
2023-02-06 10:51:06 | Valid | Epoch[298/600] Mean Pixel Accuracy: 0.9772924686425755
2023-02-06 10:51:06 | Stage | Epoch[298/600] Train loss:0.0269
2023-02-06 10:51:06 | Stage | Epoch[298/600] Valid loss:0.7152
2023-02-06 10:51:06 | Stage | Epoch[298/600] LR:0.01

2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[001/030] Train loss: 0.0264
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[004/030] Train loss: 0.0257
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[005/030] Train loss: 0.0268
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[006/030] Train loss: 0.0272
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[009/030] Train loss: 0.0269
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[010/030] Train loss: 0.0266
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[011/030] Train loss: 0.0266
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[016/030] Train loss: 0.0266
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[020/030] Train loss: 0.0269
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[021/030] Train loss: 0.0273
2023-02-06 10:51:07 | Train | Epoch[299/600] Iteration[022/030] Train loss: 0.0272
2023-02-06 10:51:08 | Train | Epoch[299/600] Iteration[023/030] Train loss: 0.0271
2023-02-06 10:51:08 | Train | Epoch[299/600] Iteration[024/030] Train loss: 0.0272
2023-02-06 10:51:08 | Train | Epoch[299/600] Iteration[025/030] Train loss: 0.0274
2023-02-06 10:51:08 | Train | Epoch[299/600] Iteration[026/030] Train loss: 0.0273
2023-02-06 10:51:08 | Train | Epoch[299/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 10:51:08 | Train | Epoch[299/600] Iteration[028/030] Train loss: 0.0271
2023-02-06 10:51:08 | Train | Epoch[299/600] Iteration[029/030] Train loss: 0.0271
2023-02-06 10:51:08 | Train | Epoch[299/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 10:51:08 | Valid | Epoch[299/600] Iteration[001/008] Valid loss: 0.0354
2023-02-06 10:51:08 | Valid | Epoch[299/600] Iteration[002/008] Valid loss: 0.0320
2023-02-06 10:51:08 | Valid | Epoch[299/600] Iteration[003/008] Valid loss: 0.0324
2023-02-06 10:51:08 | Valid | Epoch[299/600] Iteration[004/008] Valid loss: 0.0315
2023-02-06 10:51:08 | Valid | Epoch[299/600] Iteration[005/008] Valid loss: 0.0318
2023-02-06 10:51:08 | Valid | Epoch[299/600] Iteration[006/008] Valid loss: 0.0319
2023-02-06 10:51:08 | Valid | Epoch[299/600] Iteration[007/008] Valid loss: 0.0315
2023-02-06 10:51:08 | Valid | Epoch[299/600] Iteration[008/008] Valid loss: 0.0317
2023-02-06 10:51:08 | Valid | Epoch[299/600] MIou: 0.8966510365994791
2023-02-06 10:51:08 | Valid | Epoch[299/600] Pixel Accuracy: 0.98291015625
2023-02-06 10:51:08 | Valid | Epoch[299/600] Mean Pixel Accuracy: 0.9077113684618612
2023-02-06 10:51:08 | Stage | Epoch[299/600] Train loss:0.0272
2023-02-06 10:51:08 | Stage | Epoch[299/600] Valid loss:0.0317
2023-02-06 10:51:08 | Stage | Epoch[299/600] LR:0.01

2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[002/030] Train loss: 0.0246
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[004/030] Train loss: 0.0264
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[005/030] Train loss: 0.0263
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[007/030] Train loss: 0.0259
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 10:51:09 | Train | Epoch[300/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[022/030] Train loss: 0.0258
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[023/030] Train loss: 0.0261
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[024/030] Train loss: 0.0262
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[025/030] Train loss: 0.0262
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:51:10 | Train | Epoch[300/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:51:10 | Valid | Epoch[300/600] Iteration[001/008] Valid loss: 0.0350
2023-02-06 10:51:10 | Valid | Epoch[300/600] Iteration[002/008] Valid loss: 0.0322
2023-02-06 10:51:10 | Valid | Epoch[300/600] Iteration[003/008] Valid loss: 0.0322
2023-02-06 10:51:10 | Valid | Epoch[300/600] Iteration[004/008] Valid loss: 0.0312
2023-02-06 10:51:11 | Valid | Epoch[300/600] Iteration[005/008] Valid loss: 0.0317
2023-02-06 10:51:11 | Valid | Epoch[300/600] Iteration[006/008] Valid loss: 0.0314
2023-02-06 10:51:11 | Valid | Epoch[300/600] Iteration[007/008] Valid loss: 0.0312
2023-02-06 10:51:11 | Valid | Epoch[300/600] Iteration[008/008] Valid loss: 0.0313
2023-02-06 10:51:11 | Valid | Epoch[300/600] MIou: 0.90528095557308
2023-02-06 10:51:11 | Valid | Epoch[300/600] Pixel Accuracy: 0.9842605590820312
2023-02-06 10:51:11 | Valid | Epoch[300/600] Mean Pixel Accuracy: 0.9177106958592698
2023-02-06 10:51:11 | Stage | Epoch[300/600] Train loss:0.0263
2023-02-06 10:51:11 | Stage | Epoch[300/600] Valid loss:0.0313
2023-02-06 10:51:11 | Stage | Epoch[300/600] LR:0.01

2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[001/030] Train loss: 0.0272
2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[002/030] Train loss: 0.0236
2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[003/030] Train loss: 0.0244
2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 10:51:11 | Train | Epoch[301/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[013/030] Train loss: 0.0253
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[015/030] Train loss: 0.0260
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[016/030] Train loss: 0.0261
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[017/030] Train loss: 0.0266
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[020/030] Train loss: 0.0269
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[021/030] Train loss: 0.0270
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[022/030] Train loss: 0.0269
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[025/030] Train loss: 0.0267
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[026/030] Train loss: 0.0267
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[027/030] Train loss: 0.0268
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[029/030] Train loss: 0.0267
2023-02-06 10:51:12 | Train | Epoch[301/600] Iteration[030/030] Train loss: 0.0267
2023-02-06 10:51:13 | Valid | Epoch[301/600] Iteration[001/008] Valid loss: 0.0600
2023-02-06 10:51:13 | Valid | Epoch[301/600] Iteration[002/008] Valid loss: 0.0587
2023-02-06 10:51:13 | Valid | Epoch[301/600] Iteration[003/008] Valid loss: 0.0609
2023-02-06 10:51:13 | Valid | Epoch[301/600] Iteration[004/008] Valid loss: 0.0599
2023-02-06 10:51:13 | Valid | Epoch[301/600] Iteration[005/008] Valid loss: 0.0612
2023-02-06 10:51:13 | Valid | Epoch[301/600] Iteration[006/008] Valid loss: 0.0599
2023-02-06 10:51:13 | Valid | Epoch[301/600] Iteration[007/008] Valid loss: 0.0582
2023-02-06 10:51:13 | Valid | Epoch[301/600] Iteration[008/008] Valid loss: 0.0593
2023-02-06 10:51:13 | Valid | Epoch[301/600] MIou: 0.7972502268263137
2023-02-06 10:51:13 | Valid | Epoch[301/600] Pixel Accuracy: 0.966576894124349
2023-02-06 10:51:13 | Valid | Epoch[301/600] Mean Pixel Accuracy: 0.8149699418547354
2023-02-06 10:51:13 | Stage | Epoch[301/600] Train loss:0.0267
2023-02-06 10:51:13 | Stage | Epoch[301/600] Valid loss:0.0593
2023-02-06 10:51:13 | Stage | Epoch[301/600] LR:0.01

2023-02-06 10:51:13 | Train | Epoch[302/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 10:51:13 | Train | Epoch[302/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 10:51:13 | Train | Epoch[302/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:51:13 | Train | Epoch[302/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:51:13 | Train | Epoch[302/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 10:51:13 | Train | Epoch[302/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:51:13 | Train | Epoch[302/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[017/030] Train loss: 0.0263
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[018/030] Train loss: 0.0263
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[019/030] Train loss: 0.0264
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[020/030] Train loss: 0.0265
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[023/030] Train loss: 0.0269
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[025/030] Train loss: 0.0268
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[026/030] Train loss: 0.0267
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[027/030] Train loss: 0.0266
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[028/030] Train loss: 0.0266
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 10:51:14 | Train | Epoch[302/600] Iteration[030/030] Train loss: 0.0265
2023-02-06 10:51:15 | Valid | Epoch[302/600] Iteration[001/008] Valid loss: 0.5974
2023-02-06 10:51:15 | Valid | Epoch[302/600] Iteration[002/008] Valid loss: 0.5603
2023-02-06 10:51:15 | Valid | Epoch[302/600] Iteration[003/008] Valid loss: 0.5576
2023-02-06 10:51:15 | Valid | Epoch[302/600] Iteration[004/008] Valid loss: 0.5653
2023-02-06 10:51:15 | Valid | Epoch[302/600] Iteration[005/008] Valid loss: 0.5915
2023-02-06 10:51:15 | Valid | Epoch[302/600] Iteration[006/008] Valid loss: 0.5897
2023-02-06 10:51:15 | Valid | Epoch[302/600] Iteration[007/008] Valid loss: 0.6248
2023-02-06 10:51:15 | Valid | Epoch[302/600] Iteration[008/008] Valid loss: 0.6277
2023-02-06 10:51:15 | Valid | Epoch[302/600] MIou: 0.8353104823974936
2023-02-06 10:51:15 | Valid | Epoch[302/600] Pixel Accuracy: 0.9634920756022135
2023-02-06 10:51:15 | Valid | Epoch[302/600] Mean Pixel Accuracy: 0.9768395376277645
2023-02-06 10:51:15 | Stage | Epoch[302/600] Train loss:0.0265
2023-02-06 10:51:15 | Stage | Epoch[302/600] Valid loss:0.6277
2023-02-06 10:51:15 | Stage | Epoch[302/600] LR:0.01

2023-02-06 10:51:15 | Train | Epoch[303/600] Iteration[001/030] Train loss: 0.0257
2023-02-06 10:51:15 | Train | Epoch[303/600] Iteration[002/030] Train loss: 0.0244
2023-02-06 10:51:15 | Train | Epoch[303/600] Iteration[003/030] Train loss: 0.0244
2023-02-06 10:51:15 | Train | Epoch[303/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 10:51:15 | Train | Epoch[303/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[015/030] Train loss: 0.0258
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[016/030] Train loss: 0.0259
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[018/030] Train loss: 0.0262
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[019/030] Train loss: 0.0260
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[022/030] Train loss: 0.0260
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[023/030] Train loss: 0.0261
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[024/030] Train loss: 0.0263
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[025/030] Train loss: 0.0265
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[026/030] Train loss: 0.0264
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[028/030] Train loss: 0.0264
2023-02-06 10:51:16 | Train | Epoch[303/600] Iteration[029/030] Train loss: 0.0264
2023-02-06 10:51:17 | Train | Epoch[303/600] Iteration[030/030] Train loss: 0.0266
2023-02-06 10:51:17 | Valid | Epoch[303/600] Iteration[001/008] Valid loss: 0.0683
2023-02-06 10:51:17 | Valid | Epoch[303/600] Iteration[002/008] Valid loss: 0.0567
2023-02-06 10:51:17 | Valid | Epoch[303/600] Iteration[003/008] Valid loss: 0.0516
2023-02-06 10:51:17 | Valid | Epoch[303/600] Iteration[004/008] Valid loss: 0.0498
2023-02-06 10:51:17 | Valid | Epoch[303/600] Iteration[005/008] Valid loss: 0.0509
2023-02-06 10:51:17 | Valid | Epoch[303/600] Iteration[006/008] Valid loss: 0.0518
2023-02-06 10:51:17 | Valid | Epoch[303/600] Iteration[007/008] Valid loss: 0.0540
2023-02-06 10:51:17 | Valid | Epoch[303/600] Iteration[008/008] Valid loss: 0.0533
2023-02-06 10:51:17 | Valid | Epoch[303/600] MIou: 0.9313289042020725
2023-02-06 10:51:17 | Valid | Epoch[303/600] Pixel Accuracy: 0.9878514607747396
2023-02-06 10:51:17 | Valid | Epoch[303/600] Mean Pixel Accuracy: 0.9706998423640296
2023-02-06 10:51:17 | Stage | Epoch[303/600] Train loss:0.0266
2023-02-06 10:51:17 | Stage | Epoch[303/600] Valid loss:0.0533
2023-02-06 10:51:17 | Stage | Epoch[303/600] LR:0.01

2023-02-06 10:51:17 | Train | Epoch[304/600] Iteration[001/030] Train loss: 0.0269
2023-02-06 10:51:17 | Train | Epoch[304/600] Iteration[002/030] Train loss: 0.0274
2023-02-06 10:51:17 | Train | Epoch[304/600] Iteration[003/030] Train loss: 0.0272
2023-02-06 10:51:17 | Train | Epoch[304/600] Iteration[004/030] Train loss: 0.0269
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[005/030] Train loss: 0.0271
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[007/030] Train loss: 0.0263
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[010/030] Train loss: 0.0267
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[014/030] Train loss: 0.0266
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[015/030] Train loss: 0.0265
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[019/030] Train loss: 0.0272
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[020/030] Train loss: 0.0272
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[021/030] Train loss: 0.0275
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[022/030] Train loss: 0.0275
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[023/030] Train loss: 0.0274
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[024/030] Train loss: 0.0273
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[025/030] Train loss: 0.0273
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[026/030] Train loss: 0.0273
2023-02-06 10:51:18 | Train | Epoch[304/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 10:51:19 | Train | Epoch[304/600] Iteration[028/030] Train loss: 0.0271
2023-02-06 10:51:19 | Train | Epoch[304/600] Iteration[029/030] Train loss: 0.0272
2023-02-06 10:51:19 | Train | Epoch[304/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 10:51:19 | Valid | Epoch[304/600] Iteration[001/008] Valid loss: 0.0547
2023-02-06 10:51:19 | Valid | Epoch[304/600] Iteration[002/008] Valid loss: 0.0537
2023-02-06 10:51:19 | Valid | Epoch[304/600] Iteration[003/008] Valid loss: 0.0554
2023-02-06 10:51:19 | Valid | Epoch[304/600] Iteration[004/008] Valid loss: 0.0546
2023-02-06 10:51:19 | Valid | Epoch[304/600] Iteration[005/008] Valid loss: 0.0554
2023-02-06 10:51:19 | Valid | Epoch[304/600] Iteration[006/008] Valid loss: 0.0539
2023-02-06 10:51:19 | Valid | Epoch[304/600] Iteration[007/008] Valid loss: 0.0522
2023-02-06 10:51:19 | Valid | Epoch[304/600] Iteration[008/008] Valid loss: 0.0535
2023-02-06 10:51:19 | Valid | Epoch[304/600] MIou: 0.812534423293725
2023-02-06 10:51:19 | Valid | Epoch[304/600] Pixel Accuracy: 0.9690729777018229
2023-02-06 10:51:19 | Valid | Epoch[304/600] Mean Pixel Accuracy: 0.8292827982004598
2023-02-06 10:51:19 | Stage | Epoch[304/600] Train loss:0.0272
2023-02-06 10:51:19 | Stage | Epoch[304/600] Valid loss:0.0535
2023-02-06 10:51:19 | Stage | Epoch[304/600] LR:0.01

2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[001/030] Train loss: 0.0232
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[002/030] Train loss: 0.0237
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[007/030] Train loss: 0.0272
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[009/030] Train loss: 0.0266
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[012/030] Train loss: 0.0276
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[014/030] Train loss: 0.0279
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[015/030] Train loss: 0.0280
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[016/030] Train loss: 0.0282
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[017/030] Train loss: 0.0285
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[018/030] Train loss: 0.0287
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[019/030] Train loss: 0.0285
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[020/030] Train loss: 0.0284
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[021/030] Train loss: 0.0283
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[022/030] Train loss: 0.0281
2023-02-06 10:51:20 | Train | Epoch[305/600] Iteration[023/030] Train loss: 0.0281
2023-02-06 10:51:21 | Train | Epoch[305/600] Iteration[024/030] Train loss: 0.0280
2023-02-06 10:51:21 | Train | Epoch[305/600] Iteration[025/030] Train loss: 0.0280
2023-02-06 10:51:21 | Train | Epoch[305/600] Iteration[026/030] Train loss: 0.0280
2023-02-06 10:51:21 | Train | Epoch[305/600] Iteration[027/030] Train loss: 0.0279
2023-02-06 10:51:21 | Train | Epoch[305/600] Iteration[028/030] Train loss: 0.0279
2023-02-06 10:51:21 | Train | Epoch[305/600] Iteration[029/030] Train loss: 0.0280
2023-02-06 10:51:21 | Train | Epoch[305/600] Iteration[030/030] Train loss: 0.0280
2023-02-06 10:51:21 | Valid | Epoch[305/600] Iteration[001/008] Valid loss: 0.2646
2023-02-06 10:51:21 | Valid | Epoch[305/600] Iteration[002/008] Valid loss: 0.2249
2023-02-06 10:51:21 | Valid | Epoch[305/600] Iteration[003/008] Valid loss: 0.2141
2023-02-06 10:51:21 | Valid | Epoch[305/600] Iteration[004/008] Valid loss: 0.2125
2023-02-06 10:51:21 | Valid | Epoch[305/600] Iteration[005/008] Valid loss: 0.2216
2023-02-06 10:51:21 | Valid | Epoch[305/600] Iteration[006/008] Valid loss: 0.2174
2023-02-06 10:51:21 | Valid | Epoch[305/600] Iteration[007/008] Valid loss: 0.2319
2023-02-06 10:51:21 | Valid | Epoch[305/600] Iteration[008/008] Valid loss: 0.2357
2023-02-06 10:51:21 | Valid | Epoch[305/600] MIou: 0.8759911163801077
2023-02-06 10:51:21 | Valid | Epoch[305/600] Pixel Accuracy: 0.9748992919921875
2023-02-06 10:51:21 | Valid | Epoch[305/600] Mean Pixel Accuracy: 0.978379438513695
2023-02-06 10:51:21 | Stage | Epoch[305/600] Train loss:0.0280
2023-02-06 10:51:21 | Stage | Epoch[305/600] Valid loss:0.2357
2023-02-06 10:51:21 | Stage | Epoch[305/600] LR:0.01

2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[001/030] Train loss: 0.0316
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[002/030] Train loss: 0.0294
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[003/030] Train loss: 0.0285
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[004/030] Train loss: 0.0273
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[005/030] Train loss: 0.0278
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[006/030] Train loss: 0.0276
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[009/030] Train loss: 0.0270
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[012/030] Train loss: 0.0271
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[014/030] Train loss: 0.0276
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[015/030] Train loss: 0.0276
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[016/030] Train loss: 0.0278
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[017/030] Train loss: 0.0278
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[018/030] Train loss: 0.0279
2023-02-06 10:51:22 | Train | Epoch[306/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[020/030] Train loss: 0.0276
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[021/030] Train loss: 0.0275
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[022/030] Train loss: 0.0275
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[023/030] Train loss: 0.0273
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[024/030] Train loss: 0.0271
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[025/030] Train loss: 0.0270
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[026/030] Train loss: 0.0269
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[027/030] Train loss: 0.0269
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[029/030] Train loss: 0.0269
2023-02-06 10:51:23 | Train | Epoch[306/600] Iteration[030/030] Train loss: 0.0271
2023-02-06 10:51:23 | Valid | Epoch[306/600] Iteration[001/008] Valid loss: 0.0518
2023-02-06 10:51:23 | Valid | Epoch[306/600] Iteration[002/008] Valid loss: 0.0431
2023-02-06 10:51:23 | Valid | Epoch[306/600] Iteration[003/008] Valid loss: 0.0403
2023-02-06 10:51:23 | Valid | Epoch[306/600] Iteration[004/008] Valid loss: 0.0393
2023-02-06 10:51:23 | Valid | Epoch[306/600] Iteration[005/008] Valid loss: 0.0398
2023-02-06 10:51:23 | Valid | Epoch[306/600] Iteration[006/008] Valid loss: 0.0412
2023-02-06 10:51:23 | Valid | Epoch[306/600] Iteration[007/008] Valid loss: 0.0432
2023-02-06 10:51:23 | Valid | Epoch[306/600] Iteration[008/008] Valid loss: 0.0419
2023-02-06 10:51:24 | Valid | Epoch[306/600] MIou: 0.9365618538603828
2023-02-06 10:51:24 | Valid | Epoch[306/600] Pixel Accuracy: 0.9891827901204427
2023-02-06 10:51:24 | Valid | Epoch[306/600] Mean Pixel Accuracy: 0.9584716739815602
2023-02-06 10:51:24 | Stage | Epoch[306/600] Train loss:0.0271
2023-02-06 10:51:24 | Stage | Epoch[306/600] Valid loss:0.0419
2023-02-06 10:51:24 | Stage | Epoch[306/600] LR:0.01

2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[001/030] Train loss: 0.0265
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[008/030] Train loss: 0.0258
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[009/030] Train loss: 0.0263
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[011/030] Train loss: 0.0262
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[013/030] Train loss: 0.0259
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[014/030] Train loss: 0.0259
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:51:24 | Train | Epoch[307/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[021/030] Train loss: 0.0261
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[022/030] Train loss: 0.0262
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[023/030] Train loss: 0.0263
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[025/030] Train loss: 0.0263
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[029/030] Train loss: 0.0264
2023-02-06 10:51:25 | Train | Epoch[307/600] Iteration[030/030] Train loss: 0.0265
2023-02-06 10:51:25 | Valid | Epoch[307/600] Iteration[001/008] Valid loss: 0.3706
2023-02-06 10:51:25 | Valid | Epoch[307/600] Iteration[002/008] Valid loss: 0.3191
2023-02-06 10:51:25 | Valid | Epoch[307/600] Iteration[003/008] Valid loss: 0.3026
2023-02-06 10:51:25 | Valid | Epoch[307/600] Iteration[004/008] Valid loss: 0.2997
2023-02-06 10:51:26 | Valid | Epoch[307/600] Iteration[005/008] Valid loss: 0.3183
2023-02-06 10:51:26 | Valid | Epoch[307/600] Iteration[006/008] Valid loss: 0.3210
2023-02-06 10:51:26 | Valid | Epoch[307/600] Iteration[007/008] Valid loss: 0.3398
2023-02-06 10:51:26 | Valid | Epoch[307/600] Iteration[008/008] Valid loss: 0.3346
2023-02-06 10:51:26 | Valid | Epoch[307/600] MIou: 0.8734877806324457
2023-02-06 10:51:26 | Valid | Epoch[307/600] Pixel Accuracy: 0.9741325378417969
2023-02-06 10:51:26 | Valid | Epoch[307/600] Mean Pixel Accuracy: 0.9806717195385369
2023-02-06 10:51:26 | Stage | Epoch[307/600] Train loss:0.0265
2023-02-06 10:51:26 | Stage | Epoch[307/600] Valid loss:0.3346
2023-02-06 10:51:26 | Stage | Epoch[307/600] LR:0.01

2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[006/030] Train loss: 0.0256
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 10:51:26 | Train | Epoch[308/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[014/030] Train loss: 0.0259
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[015/030] Train loss: 0.0261
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[018/030] Train loss: 0.0266
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[020/030] Train loss: 0.0265
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[022/030] Train loss: 0.0266
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[024/030] Train loss: 0.0268
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[025/030] Train loss: 0.0267
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[027/030] Train loss: 0.0265
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[028/030] Train loss: 0.0266
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[029/030] Train loss: 0.0265
2023-02-06 10:51:27 | Train | Epoch[308/600] Iteration[030/030] Train loss: 0.0266
2023-02-06 10:51:28 | Valid | Epoch[308/600] Iteration[001/008] Valid loss: 0.1943
2023-02-06 10:51:28 | Valid | Epoch[308/600] Iteration[002/008] Valid loss: 0.1502
2023-02-06 10:51:28 | Valid | Epoch[308/600] Iteration[003/008] Valid loss: 0.1429
2023-02-06 10:51:28 | Valid | Epoch[308/600] Iteration[004/008] Valid loss: 0.1399
2023-02-06 10:51:28 | Valid | Epoch[308/600] Iteration[005/008] Valid loss: 0.1450
2023-02-06 10:51:28 | Valid | Epoch[308/600] Iteration[006/008] Valid loss: 0.1430
2023-02-06 10:51:28 | Valid | Epoch[308/600] Iteration[007/008] Valid loss: 0.1528
2023-02-06 10:51:28 | Valid | Epoch[308/600] Iteration[008/008] Valid loss: 0.1519
2023-02-06 10:51:28 | Valid | Epoch[308/600] MIou: 0.9102145391107295
2023-02-06 10:51:28 | Valid | Epoch[308/600] Pixel Accuracy: 0.983069101969401
2023-02-06 10:51:28 | Valid | Epoch[308/600] Mean Pixel Accuracy: 0.9802766616626992
2023-02-06 10:51:28 | Stage | Epoch[308/600] Train loss:0.0266
2023-02-06 10:51:28 | Stage | Epoch[308/600] Valid loss:0.1519
2023-02-06 10:51:28 | Stage | Epoch[308/600] LR:0.01

2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[001/030] Train loss: 0.0269
2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[002/030] Train loss: 0.0266
2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[003/030] Train loss: 0.0280
2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[005/030] Train loss: 0.0275
2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[006/030] Train loss: 0.0282
2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[007/030] Train loss: 0.0277
2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[008/030] Train loss: 0.0270
2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[009/030] Train loss: 0.0274
2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[010/030] Train loss: 0.0273
2023-02-06 10:51:28 | Train | Epoch[309/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[012/030] Train loss: 0.0271
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[013/030] Train loss: 0.0272
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[014/030] Train loss: 0.0269
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[015/030] Train loss: 0.0271
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[016/030] Train loss: 0.0270
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[017/030] Train loss: 0.0270
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[019/030] Train loss: 0.0264
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[020/030] Train loss: 0.0266
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[021/030] Train loss: 0.0267
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[022/030] Train loss: 0.0269
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[024/030] Train loss: 0.0269
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[025/030] Train loss: 0.0268
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[027/030] Train loss: 0.0268
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[028/030] Train loss: 0.0269
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[029/030] Train loss: 0.0268
2023-02-06 10:51:29 | Train | Epoch[309/600] Iteration[030/030] Train loss: 0.0267
2023-02-06 10:51:30 | Valid | Epoch[309/600] Iteration[001/008] Valid loss: 0.0349
2023-02-06 10:51:30 | Valid | Epoch[309/600] Iteration[002/008] Valid loss: 0.0325
2023-02-06 10:51:30 | Valid | Epoch[309/600] Iteration[003/008] Valid loss: 0.0324
2023-02-06 10:51:30 | Valid | Epoch[309/600] Iteration[004/008] Valid loss: 0.0319
2023-02-06 10:51:30 | Valid | Epoch[309/600] Iteration[005/008] Valid loss: 0.0321
2023-02-06 10:51:30 | Valid | Epoch[309/600] Iteration[006/008] Valid loss: 0.0326
2023-02-06 10:51:30 | Valid | Epoch[309/600] Iteration[007/008] Valid loss: 0.0321
2023-02-06 10:51:30 | Valid | Epoch[309/600] Iteration[008/008] Valid loss: 0.0322
2023-02-06 10:51:30 | Valid | Epoch[309/600] MIou: 0.8950920930990824
2023-02-06 10:51:30 | Valid | Epoch[309/600] Pixel Accuracy: 0.9826545715332031
2023-02-06 10:51:30 | Valid | Epoch[309/600] Mean Pixel Accuracy: 0.906220367769012
2023-02-06 10:51:30 | Stage | Epoch[309/600] Train loss:0.0267
2023-02-06 10:51:30 | Stage | Epoch[309/600] Valid loss:0.0322
2023-02-06 10:51:30 | Stage | Epoch[309/600] LR:0.01

2023-02-06 10:51:30 | Train | Epoch[310/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 10:51:30 | Train | Epoch[310/600] Iteration[002/030] Train loss: 0.0267
2023-02-06 10:51:30 | Train | Epoch[310/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:51:30 | Train | Epoch[310/600] Iteration[004/030] Train loss: 0.0266
2023-02-06 10:51:30 | Train | Epoch[310/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:51:30 | Train | Epoch[310/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 10:51:30 | Train | Epoch[310/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:51:30 | Train | Epoch[310/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:51:30 | Train | Epoch[310/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[015/030] Train loss: 0.0258
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[016/030] Train loss: 0.0260
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[017/030] Train loss: 0.0263
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[018/030] Train loss: 0.0263
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[019/030] Train loss: 0.0270
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[020/030] Train loss: 0.0270
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[021/030] Train loss: 0.0268
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[023/030] Train loss: 0.0266
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[025/030] Train loss: 0.0267
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[026/030] Train loss: 0.0267
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[027/030] Train loss: 0.0268
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[028/030] Train loss: 0.0267
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 10:51:31 | Train | Epoch[310/600] Iteration[030/030] Train loss: 0.0267
2023-02-06 10:51:32 | Valid | Epoch[310/600] Iteration[001/008] Valid loss: 1.0280
2023-02-06 10:51:32 | Valid | Epoch[310/600] Iteration[002/008] Valid loss: 1.0315
2023-02-06 10:51:32 | Valid | Epoch[310/600] Iteration[003/008] Valid loss: 1.0225
2023-02-06 10:51:32 | Valid | Epoch[310/600] Iteration[004/008] Valid loss: 1.0580
2023-02-06 10:51:32 | Valid | Epoch[310/600] Iteration[005/008] Valid loss: 1.0963
2023-02-06 10:51:32 | Valid | Epoch[310/600] Iteration[006/008] Valid loss: 1.1102
2023-02-06 10:51:32 | Valid | Epoch[310/600] Iteration[007/008] Valid loss: 1.1725
2023-02-06 10:51:32 | Valid | Epoch[310/600] Iteration[008/008] Valid loss: 1.1872
2023-02-06 10:51:32 | Valid | Epoch[310/600] MIou: 0.8130957112937318
2023-02-06 10:51:32 | Valid | Epoch[310/600] Pixel Accuracy: 0.9564743041992188
2023-02-06 10:51:32 | Valid | Epoch[310/600] Mean Pixel Accuracy: 0.9744786224408181
2023-02-06 10:51:32 | Stage | Epoch[310/600] Train loss:0.0267
2023-02-06 10:51:32 | Stage | Epoch[310/600] Valid loss:1.1872
2023-02-06 10:51:32 | Stage | Epoch[310/600] LR:0.01

2023-02-06 10:51:32 | Train | Epoch[311/600] Iteration[001/030] Train loss: 0.0255
2023-02-06 10:51:32 | Train | Epoch[311/600] Iteration[002/030] Train loss: 0.0270
2023-02-06 10:51:32 | Train | Epoch[311/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 10:51:32 | Train | Epoch[311/600] Iteration[004/030] Train loss: 0.0290
2023-02-06 10:51:32 | Train | Epoch[311/600] Iteration[005/030] Train loss: 0.0288
2023-02-06 10:51:32 | Train | Epoch[311/600] Iteration[006/030] Train loss: 0.0286
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[007/030] Train loss: 0.0278
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[008/030] Train loss: 0.0285
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[009/030] Train loss: 0.0280
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[011/030] Train loss: 0.0277
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[012/030] Train loss: 0.0278
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[013/030] Train loss: 0.0281
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[014/030] Train loss: 0.0279
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[015/030] Train loss: 0.0276
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[016/030] Train loss: 0.0277
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[017/030] Train loss: 0.0279
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[018/030] Train loss: 0.0278
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[020/030] Train loss: 0.0275
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[021/030] Train loss: 0.0276
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[022/030] Train loss: 0.0277
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[023/030] Train loss: 0.0278
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[024/030] Train loss: 0.0277
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[025/030] Train loss: 0.0276
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[026/030] Train loss: 0.0273
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[028/030] Train loss: 0.0273
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[029/030] Train loss: 0.0272
2023-02-06 10:51:33 | Train | Epoch[311/600] Iteration[030/030] Train loss: 0.0270
2023-02-06 10:51:34 | Valid | Epoch[311/600] Iteration[001/008] Valid loss: 0.1850
2023-02-06 10:51:34 | Valid | Epoch[311/600] Iteration[002/008] Valid loss: 0.1823
2023-02-06 10:51:34 | Valid | Epoch[311/600] Iteration[003/008] Valid loss: 0.1905
2023-02-06 10:51:34 | Valid | Epoch[311/600] Iteration[004/008] Valid loss: 0.1910
2023-02-06 10:51:34 | Valid | Epoch[311/600] Iteration[005/008] Valid loss: 0.1960
2023-02-06 10:51:34 | Valid | Epoch[311/600] Iteration[006/008] Valid loss: 0.1932
2023-02-06 10:51:34 | Valid | Epoch[311/600] Iteration[007/008] Valid loss: 0.1902
2023-02-06 10:51:34 | Valid | Epoch[311/600] Iteration[008/008] Valid loss: 0.1959
2023-02-06 10:51:34 | Valid | Epoch[311/600] MIou: 0.48565157795015296
2023-02-06 10:51:34 | Valid | Epoch[311/600] Pixel Accuracy: 0.9148228963216146
2023-02-06 10:51:34 | Valid | Epoch[311/600] Mean Pixel Accuracy: 0.5284602063945713
2023-02-06 10:51:34 | Stage | Epoch[311/600] Train loss:0.0270
2023-02-06 10:51:34 | Stage | Epoch[311/600] Valid loss:0.1959
2023-02-06 10:51:34 | Stage | Epoch[311/600] LR:0.01

2023-02-06 10:51:34 | Train | Epoch[312/600] Iteration[001/030] Train loss: 0.0272
2023-02-06 10:51:34 | Train | Epoch[312/600] Iteration[002/030] Train loss: 0.0309
2023-02-06 10:51:34 | Train | Epoch[312/600] Iteration[003/030] Train loss: 0.0305
2023-02-06 10:51:34 | Train | Epoch[312/600] Iteration[004/030] Train loss: 0.0305
2023-02-06 10:51:34 | Train | Epoch[312/600] Iteration[005/030] Train loss: 0.0293
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[006/030] Train loss: 0.0294
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[007/030] Train loss: 0.0283
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[008/030] Train loss: 0.0289
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[009/030] Train loss: 0.0291
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[010/030] Train loss: 0.0286
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[011/030] Train loss: 0.0281
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[012/030] Train loss: 0.0280
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[013/030] Train loss: 0.0280
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[014/030] Train loss: 0.0277
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[015/030] Train loss: 0.0276
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[016/030] Train loss: 0.0280
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[017/030] Train loss: 0.0280
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[018/030] Train loss: 0.0278
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[019/030] Train loss: 0.0275
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[020/030] Train loss: 0.0273
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[021/030] Train loss: 0.0272
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[022/030] Train loss: 0.0271
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[023/030] Train loss: 0.0272
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[024/030] Train loss: 0.0273
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[025/030] Train loss: 0.0275
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[026/030] Train loss: 0.0275
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[027/030] Train loss: 0.0274
2023-02-06 10:51:35 | Train | Epoch[312/600] Iteration[028/030] Train loss: 0.0275
2023-02-06 10:51:36 | Train | Epoch[312/600] Iteration[029/030] Train loss: 0.0275
2023-02-06 10:51:36 | Train | Epoch[312/600] Iteration[030/030] Train loss: 0.0274
2023-02-06 10:51:36 | Valid | Epoch[312/600] Iteration[001/008] Valid loss: 0.2071
2023-02-06 10:51:36 | Valid | Epoch[312/600] Iteration[002/008] Valid loss: 0.2089
2023-02-06 10:51:36 | Valid | Epoch[312/600] Iteration[003/008] Valid loss: 0.2192
2023-02-06 10:51:36 | Valid | Epoch[312/600] Iteration[004/008] Valid loss: 0.2197
2023-02-06 10:51:36 | Valid | Epoch[312/600] Iteration[005/008] Valid loss: 0.2269
2023-02-06 10:51:36 | Valid | Epoch[312/600] Iteration[006/008] Valid loss: 0.2227
2023-02-06 10:51:36 | Valid | Epoch[312/600] Iteration[007/008] Valid loss: 0.2194
2023-02-06 10:51:36 | Valid | Epoch[312/600] Iteration[008/008] Valid loss: 0.2278
2023-02-06 10:51:36 | Valid | Epoch[312/600] MIou: 0.45692829356581366
2023-02-06 10:51:36 | Valid | Epoch[312/600] Pixel Accuracy: 0.9100303649902344
2023-02-06 10:51:36 | Valid | Epoch[312/600] Mean Pixel Accuracy: 0.5019287896492982
2023-02-06 10:51:36 | Stage | Epoch[312/600] Train loss:0.0274
2023-02-06 10:51:36 | Stage | Epoch[312/600] Valid loss:0.2278
2023-02-06 10:51:36 | Stage | Epoch[312/600] LR:0.01

2023-02-06 10:51:36 | Train | Epoch[313/600] Iteration[001/030] Train loss: 0.0310
2023-02-06 10:51:36 | Train | Epoch[313/600] Iteration[002/030] Train loss: 0.0292
2023-02-06 10:51:36 | Train | Epoch[313/600] Iteration[003/030] Train loss: 0.0291
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[004/030] Train loss: 0.0292
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[005/030] Train loss: 0.0285
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[006/030] Train loss: 0.0277
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[007/030] Train loss: 0.0284
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[008/030] Train loss: 0.0278
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[009/030] Train loss: 0.0272
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[010/030] Train loss: 0.0269
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[013/030] Train loss: 0.0277
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[014/030] Train loss: 0.0275
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[015/030] Train loss: 0.0274
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[017/030] Train loss: 0.0272
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[018/030] Train loss: 0.0273
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[019/030] Train loss: 0.0276
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[020/030] Train loss: 0.0277
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[021/030] Train loss: 0.0275
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[022/030] Train loss: 0.0274
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[023/030] Train loss: 0.0271
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[024/030] Train loss: 0.0271
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 10:51:37 | Train | Epoch[313/600] Iteration[026/030] Train loss: 0.0272
2023-02-06 10:51:38 | Train | Epoch[313/600] Iteration[027/030] Train loss: 0.0271
2023-02-06 10:51:38 | Train | Epoch[313/600] Iteration[028/030] Train loss: 0.0271
2023-02-06 10:51:38 | Train | Epoch[313/600] Iteration[029/030] Train loss: 0.0270
2023-02-06 10:51:38 | Train | Epoch[313/600] Iteration[030/030] Train loss: 0.0269
2023-02-06 10:51:38 | Valid | Epoch[313/600] Iteration[001/008] Valid loss: 0.0399
2023-02-06 10:51:38 | Valid | Epoch[313/600] Iteration[002/008] Valid loss: 0.0367
2023-02-06 10:51:38 | Valid | Epoch[313/600] Iteration[003/008] Valid loss: 0.0372
2023-02-06 10:51:38 | Valid | Epoch[313/600] Iteration[004/008] Valid loss: 0.0358
2023-02-06 10:51:38 | Valid | Epoch[313/600] Iteration[005/008] Valid loss: 0.0363
2023-02-06 10:51:38 | Valid | Epoch[313/600] Iteration[006/008] Valid loss: 0.0356
2023-02-06 10:51:38 | Valid | Epoch[313/600] Iteration[007/008] Valid loss: 0.0350
2023-02-06 10:51:38 | Valid | Epoch[313/600] Iteration[008/008] Valid loss: 0.0352
2023-02-06 10:51:38 | Valid | Epoch[313/600] MIou: 0.888032591230477
2023-02-06 10:51:38 | Valid | Epoch[313/600] Pixel Accuracy: 0.981512705485026
2023-02-06 10:51:38 | Valid | Epoch[313/600] Mean Pixel Accuracy: 0.8991571709047639
2023-02-06 10:51:38 | Stage | Epoch[313/600] Train loss:0.0269
2023-02-06 10:51:38 | Stage | Epoch[313/600] Valid loss:0.0352
2023-02-06 10:51:38 | Stage | Epoch[313/600] LR:0.01

2023-02-06 10:51:38 | Train | Epoch[314/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 10:51:38 | Train | Epoch[314/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[003/030] Train loss: 0.0265
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[004/030] Train loss: 0.0269
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[006/030] Train loss: 0.0274
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[007/030] Train loss: 0.0272
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[008/030] Train loss: 0.0270
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[009/030] Train loss: 0.0272
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[011/030] Train loss: 0.0268
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[012/030] Train loss: 0.0269
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[014/030] Train loss: 0.0273
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[015/030] Train loss: 0.0273
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[016/030] Train loss: 0.0273
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[017/030] Train loss: 0.0276
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[018/030] Train loss: 0.0273
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[019/030] Train loss: 0.0278
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[020/030] Train loss: 0.0278
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[021/030] Train loss: 0.0278
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[022/030] Train loss: 0.0278
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[023/030] Train loss: 0.0277
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[024/030] Train loss: 0.0276
2023-02-06 10:51:39 | Train | Epoch[314/600] Iteration[025/030] Train loss: 0.0276
2023-02-06 10:51:40 | Train | Epoch[314/600] Iteration[026/030] Train loss: 0.0275
2023-02-06 10:51:40 | Train | Epoch[314/600] Iteration[027/030] Train loss: 0.0274
2023-02-06 10:51:40 | Train | Epoch[314/600] Iteration[028/030] Train loss: 0.0274
2023-02-06 10:51:40 | Train | Epoch[314/600] Iteration[029/030] Train loss: 0.0274
2023-02-06 10:51:40 | Train | Epoch[314/600] Iteration[030/030] Train loss: 0.0274
2023-02-06 10:51:40 | Valid | Epoch[314/600] Iteration[001/008] Valid loss: 0.0523
2023-02-06 10:51:40 | Valid | Epoch[314/600] Iteration[002/008] Valid loss: 0.0511
2023-02-06 10:51:40 | Valid | Epoch[314/600] Iteration[003/008] Valid loss: 0.0521
2023-02-06 10:51:40 | Valid | Epoch[314/600] Iteration[004/008] Valid loss: 0.0516
2023-02-06 10:51:40 | Valid | Epoch[314/600] Iteration[005/008] Valid loss: 0.0519
2023-02-06 10:51:40 | Valid | Epoch[314/600] Iteration[006/008] Valid loss: 0.0513
2023-02-06 10:51:40 | Valid | Epoch[314/600] Iteration[007/008] Valid loss: 0.0497
2023-02-06 10:51:40 | Valid | Epoch[314/600] Iteration[008/008] Valid loss: 0.0507
2023-02-06 10:51:40 | Valid | Epoch[314/600] MIou: 0.8205054102783208
2023-02-06 10:51:40 | Valid | Epoch[314/600] Pixel Accuracy: 0.9703954060872396
2023-02-06 10:51:40 | Valid | Epoch[314/600] Mean Pixel Accuracy: 0.8365403468987336
2023-02-06 10:51:40 | Stage | Epoch[314/600] Train loss:0.0274
2023-02-06 10:51:40 | Stage | Epoch[314/600] Valid loss:0.0507
2023-02-06 10:51:40 | Stage | Epoch[314/600] LR:0.01

2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[001/030] Train loss: 0.0334
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[002/030] Train loss: 0.0328
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[003/030] Train loss: 0.0331
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[004/030] Train loss: 0.0317
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[005/030] Train loss: 0.0305
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[006/030] Train loss: 0.0293
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[007/030] Train loss: 0.0292
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[008/030] Train loss: 0.0294
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[009/030] Train loss: 0.0293
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[010/030] Train loss: 0.0290
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[011/030] Train loss: 0.0292
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[012/030] Train loss: 0.0290
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[013/030] Train loss: 0.0285
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[014/030] Train loss: 0.0284
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[015/030] Train loss: 0.0281
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[016/030] Train loss: 0.0281
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[017/030] Train loss: 0.0277
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[018/030] Train loss: 0.0273
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[020/030] Train loss: 0.0275
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[021/030] Train loss: 0.0275
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[022/030] Train loss: 0.0274
2023-02-06 10:51:41 | Train | Epoch[315/600] Iteration[023/030] Train loss: 0.0273
2023-02-06 10:51:42 | Train | Epoch[315/600] Iteration[024/030] Train loss: 0.0272
2023-02-06 10:51:42 | Train | Epoch[315/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 10:51:42 | Train | Epoch[315/600] Iteration[026/030] Train loss: 0.0270
2023-02-06 10:51:42 | Train | Epoch[315/600] Iteration[027/030] Train loss: 0.0269
2023-02-06 10:51:42 | Train | Epoch[315/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 10:51:42 | Train | Epoch[315/600] Iteration[029/030] Train loss: 0.0271
2023-02-06 10:51:42 | Train | Epoch[315/600] Iteration[030/030] Train loss: 0.0270
2023-02-06 10:51:42 | Valid | Epoch[315/600] Iteration[001/008] Valid loss: 0.0538
2023-02-06 10:51:42 | Valid | Epoch[315/600] Iteration[002/008] Valid loss: 0.0519
2023-02-06 10:51:42 | Valid | Epoch[315/600] Iteration[003/008] Valid loss: 0.0529
2023-02-06 10:51:42 | Valid | Epoch[315/600] Iteration[004/008] Valid loss: 0.0520
2023-02-06 10:51:42 | Valid | Epoch[315/600] Iteration[005/008] Valid loss: 0.0528
2023-02-06 10:51:42 | Valid | Epoch[315/600] Iteration[006/008] Valid loss: 0.0519
2023-02-06 10:51:42 | Valid | Epoch[315/600] Iteration[007/008] Valid loss: 0.0508
2023-02-06 10:51:42 | Valid | Epoch[315/600] Iteration[008/008] Valid loss: 0.0517
2023-02-06 10:51:42 | Valid | Epoch[315/600] MIou: 0.8206054789570799
2023-02-06 10:51:42 | Valid | Epoch[315/600] Pixel Accuracy: 0.9704360961914062
2023-02-06 10:51:42 | Valid | Epoch[315/600] Mean Pixel Accuracy: 0.8363598168269879
2023-02-06 10:51:42 | Stage | Epoch[315/600] Train loss:0.0270
2023-02-06 10:51:42 | Stage | Epoch[315/600] Valid loss:0.0517
2023-02-06 10:51:42 | Stage | Epoch[315/600] LR:0.01

2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[001/030] Train loss: 0.0220
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[007/030] Train loss: 0.0260
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[011/030] Train loss: 0.0266
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[013/030] Train loss: 0.0267
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[015/030] Train loss: 0.0268
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[016/030] Train loss: 0.0269
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[020/030] Train loss: 0.0266
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:51:43 | Train | Epoch[316/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 10:51:44 | Train | Epoch[316/600] Iteration[023/030] Train loss: 0.0263
2023-02-06 10:51:44 | Train | Epoch[316/600] Iteration[024/030] Train loss: 0.0265
2023-02-06 10:51:44 | Train | Epoch[316/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:51:44 | Train | Epoch[316/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 10:51:44 | Train | Epoch[316/600] Iteration[027/030] Train loss: 0.0266
2023-02-06 10:51:44 | Train | Epoch[316/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 10:51:44 | Train | Epoch[316/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 10:51:44 | Train | Epoch[316/600] Iteration[030/030] Train loss: 0.0266
2023-02-06 10:51:44 | Valid | Epoch[316/600] Iteration[001/008] Valid loss: 0.0622
2023-02-06 10:51:44 | Valid | Epoch[316/600] Iteration[002/008] Valid loss: 0.0488
2023-02-06 10:51:44 | Valid | Epoch[316/600] Iteration[003/008] Valid loss: 0.0472
2023-02-06 10:51:44 | Valid | Epoch[316/600] Iteration[004/008] Valid loss: 0.0453
2023-02-06 10:51:44 | Valid | Epoch[316/600] Iteration[005/008] Valid loss: 0.0475
2023-02-06 10:51:44 | Valid | Epoch[316/600] Iteration[006/008] Valid loss: 0.0473
2023-02-06 10:51:44 | Valid | Epoch[316/600] Iteration[007/008] Valid loss: 0.0504
2023-02-06 10:51:44 | Valid | Epoch[316/600] Iteration[008/008] Valid loss: 0.0498
2023-02-06 10:51:44 | Valid | Epoch[316/600] MIou: 0.9328810203170964
2023-02-06 10:51:44 | Valid | Epoch[316/600] Pixel Accuracy: 0.9881718953450521
2023-02-06 10:51:44 | Valid | Epoch[316/600] Mean Pixel Accuracy: 0.970381410092135
2023-02-06 10:51:44 | Stage | Epoch[316/600] Train loss:0.0266
2023-02-06 10:51:44 | Stage | Epoch[316/600] Valid loss:0.0498
2023-02-06 10:51:44 | Stage | Epoch[316/600] LR:0.01

2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[001/030] Train loss: 0.0263
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[002/030] Train loss: 0.0281
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[003/030] Train loss: 0.0283
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[004/030] Train loss: 0.0280
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[005/030] Train loss: 0.0269
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[006/030] Train loss: 0.0272
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[008/030] Train loss: 0.0273
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[011/030] Train loss: 0.0272
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[012/030] Train loss: 0.0270
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[013/030] Train loss: 0.0271
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[014/030] Train loss: 0.0271
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[015/030] Train loss: 0.0268
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[016/030] Train loss: 0.0268
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[017/030] Train loss: 0.0269
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[019/030] Train loss: 0.0271
2023-02-06 10:51:45 | Train | Epoch[317/600] Iteration[020/030] Train loss: 0.0270
2023-02-06 10:51:46 | Train | Epoch[317/600] Iteration[021/030] Train loss: 0.0269
2023-02-06 10:51:46 | Train | Epoch[317/600] Iteration[022/030] Train loss: 0.0269
2023-02-06 10:51:46 | Train | Epoch[317/600] Iteration[023/030] Train loss: 0.0269
2023-02-06 10:51:46 | Train | Epoch[317/600] Iteration[024/030] Train loss: 0.0268
2023-02-06 10:51:46 | Train | Epoch[317/600] Iteration[025/030] Train loss: 0.0267
2023-02-06 10:51:46 | Train | Epoch[317/600] Iteration[026/030] Train loss: 0.0267
2023-02-06 10:51:46 | Train | Epoch[317/600] Iteration[027/030] Train loss: 0.0268
2023-02-06 10:51:46 | Train | Epoch[317/600] Iteration[028/030] Train loss: 0.0267
2023-02-06 10:51:46 | Train | Epoch[317/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 10:51:46 | Train | Epoch[317/600] Iteration[030/030] Train loss: 0.0264
2023-02-06 10:51:46 | Valid | Epoch[317/600] Iteration[001/008] Valid loss: 0.0850
2023-02-06 10:51:46 | Valid | Epoch[317/600] Iteration[002/008] Valid loss: 0.0820
2023-02-06 10:51:46 | Valid | Epoch[317/600] Iteration[003/008] Valid loss: 0.0846
2023-02-06 10:51:46 | Valid | Epoch[317/600] Iteration[004/008] Valid loss: 0.0839
2023-02-06 10:51:46 | Valid | Epoch[317/600] Iteration[005/008] Valid loss: 0.0854
2023-02-06 10:51:46 | Valid | Epoch[317/600] Iteration[006/008] Valid loss: 0.0837
2023-02-06 10:51:46 | Valid | Epoch[317/600] Iteration[007/008] Valid loss: 0.0814
2023-02-06 10:51:46 | Valid | Epoch[317/600] Iteration[008/008] Valid loss: 0.0833
2023-02-06 10:51:46 | Valid | Epoch[317/600] MIou: 0.7512843243929914
2023-02-06 10:51:46 | Valid | Epoch[317/600] Pixel Accuracy: 0.9589665730794271
2023-02-06 10:51:46 | Valid | Epoch[317/600] Mean Pixel Accuracy: 0.7728899866084029
2023-02-06 10:51:46 | Stage | Epoch[317/600] Train loss:0.0264
2023-02-06 10:51:46 | Stage | Epoch[317/600] Valid loss:0.0833
2023-02-06 10:51:46 | Stage | Epoch[317/600] LR:0.01

2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[001/030] Train loss: 0.0285
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[003/030] Train loss: 0.0271
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[004/030] Train loss: 0.0271
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[005/030] Train loss: 0.0268
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[006/030] Train loss: 0.0273
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[008/030] Train loss: 0.0274
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[009/030] Train loss: 0.0273
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[011/030] Train loss: 0.0272
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[012/030] Train loss: 0.0276
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[014/030] Train loss: 0.0274
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[015/030] Train loss: 0.0274
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[017/030] Train loss: 0.0273
2023-02-06 10:51:47 | Train | Epoch[318/600] Iteration[018/030] Train loss: 0.0273
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[019/030] Train loss: 0.0273
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[020/030] Train loss: 0.0271
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[021/030] Train loss: 0.0272
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[022/030] Train loss: 0.0269
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[024/030] Train loss: 0.0268
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[025/030] Train loss: 0.0268
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[027/030] Train loss: 0.0268
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[029/030] Train loss: 0.0268
2023-02-06 10:51:48 | Train | Epoch[318/600] Iteration[030/030] Train loss: 0.0269
2023-02-06 10:51:48 | Valid | Epoch[318/600] Iteration[001/008] Valid loss: 0.0666
2023-02-06 10:51:48 | Valid | Epoch[318/600] Iteration[002/008] Valid loss: 0.0484
2023-02-06 10:51:48 | Valid | Epoch[318/600] Iteration[003/008] Valid loss: 0.0453
2023-02-06 10:51:48 | Valid | Epoch[318/600] Iteration[004/008] Valid loss: 0.0429
2023-02-06 10:51:48 | Valid | Epoch[318/600] Iteration[005/008] Valid loss: 0.0440
2023-02-06 10:51:48 | Valid | Epoch[318/600] Iteration[006/008] Valid loss: 0.0428
2023-02-06 10:51:48 | Valid | Epoch[318/600] Iteration[007/008] Valid loss: 0.0457
2023-02-06 10:51:48 | Valid | Epoch[318/600] Iteration[008/008] Valid loss: 0.0449
2023-02-06 10:51:49 | Valid | Epoch[318/600] MIou: 0.9341660404899508
2023-02-06 10:51:49 | Valid | Epoch[318/600] Pixel Accuracy: 0.9886080423990885
2023-02-06 10:51:49 | Valid | Epoch[318/600] Mean Pixel Accuracy: 0.9630062288282475
2023-02-06 10:51:49 | Stage | Epoch[318/600] Train loss:0.0269
2023-02-06 10:51:49 | Stage | Epoch[318/600] Valid loss:0.0449
2023-02-06 10:51:49 | Stage | Epoch[318/600] LR:0.01

2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[001/030] Train loss: 0.0248
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[002/030] Train loss: 0.0277
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[003/030] Train loss: 0.0276
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[004/030] Train loss: 0.0271
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[006/030] Train loss: 0.0258
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[008/030] Train loss: 0.0264
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[009/030] Train loss: 0.0270
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[012/030] Train loss: 0.0262
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[015/030] Train loss: 0.0265
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[016/030] Train loss: 0.0262
2023-02-06 10:51:49 | Train | Epoch[319/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[019/030] Train loss: 0.0264
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[020/030] Train loss: 0.0263
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[021/030] Train loss: 0.0262
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[022/030] Train loss: 0.0261
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[023/030] Train loss: 0.0262
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[024/030] Train loss: 0.0263
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[025/030] Train loss: 0.0263
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[029/030] Train loss: 0.0265
2023-02-06 10:51:50 | Train | Epoch[319/600] Iteration[030/030] Train loss: 0.0265
2023-02-06 10:51:50 | Valid | Epoch[319/600] Iteration[001/008] Valid loss: 0.2705
2023-02-06 10:51:50 | Valid | Epoch[319/600] Iteration[002/008] Valid loss: 0.2184
2023-02-06 10:51:50 | Valid | Epoch[319/600] Iteration[003/008] Valid loss: 0.2099
2023-02-06 10:51:50 | Valid | Epoch[319/600] Iteration[004/008] Valid loss: 0.2070
2023-02-06 10:51:50 | Valid | Epoch[319/600] Iteration[005/008] Valid loss: 0.2171
2023-02-06 10:51:50 | Valid | Epoch[319/600] Iteration[006/008] Valid loss: 0.2188
2023-02-06 10:51:51 | Valid | Epoch[319/600] Iteration[007/008] Valid loss: 0.2329
2023-02-06 10:51:51 | Valid | Epoch[319/600] Iteration[008/008] Valid loss: 0.2317
2023-02-06 10:51:51 | Valid | Epoch[319/600] MIou: 0.8836815738486503
2023-02-06 10:51:51 | Valid | Epoch[319/600] Pixel Accuracy: 0.9767532348632812
2023-02-06 10:51:51 | Valid | Epoch[319/600] Mean Pixel Accuracy: 0.9806094746432065
2023-02-06 10:51:51 | Stage | Epoch[319/600] Train loss:0.0265
2023-02-06 10:51:51 | Stage | Epoch[319/600] Valid loss:0.2317
2023-02-06 10:51:51 | Stage | Epoch[319/600] LR:0.01

2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[001/030] Train loss: 0.0310
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[002/030] Train loss: 0.0270
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[004/030] Train loss: 0.0271
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[008/030] Train loss: 0.0259
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[009/030] Train loss: 0.0263
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 10:51:51 | Train | Epoch[320/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[016/030] Train loss: 0.0259
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[017/030] Train loss: 0.0263
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[018/030] Train loss: 0.0262
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[020/030] Train loss: 0.0264
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[021/030] Train loss: 0.0264
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[023/030] Train loss: 0.0263
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[025/030] Train loss: 0.0261
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[028/030] Train loss: 0.0264
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 10:51:52 | Train | Epoch[320/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:51:53 | Valid | Epoch[320/600] Iteration[001/008] Valid loss: 0.2369
2023-02-06 10:51:53 | Valid | Epoch[320/600] Iteration[002/008] Valid loss: 0.1908
2023-02-06 10:51:53 | Valid | Epoch[320/600] Iteration[003/008] Valid loss: 0.1791
2023-02-06 10:51:53 | Valid | Epoch[320/600] Iteration[004/008] Valid loss: 0.1749
2023-02-06 10:51:53 | Valid | Epoch[320/600] Iteration[005/008] Valid loss: 0.1810
2023-02-06 10:51:53 | Valid | Epoch[320/600] Iteration[006/008] Valid loss: 0.1830
2023-02-06 10:51:53 | Valid | Epoch[320/600] Iteration[007/008] Valid loss: 0.1959
2023-02-06 10:51:53 | Valid | Epoch[320/600] Iteration[008/008] Valid loss: 0.1938
2023-02-06 10:51:53 | Valid | Epoch[320/600] MIou: 0.8916267296818713
2023-02-06 10:51:53 | Valid | Epoch[320/600] Pixel Accuracy: 0.9786911010742188
2023-02-06 10:51:53 | Valid | Epoch[320/600] Mean Pixel Accuracy: 0.9811927327258146
2023-02-06 10:51:53 | Stage | Epoch[320/600] Train loss:0.0262
2023-02-06 10:51:53 | Stage | Epoch[320/600] Valid loss:0.1938
2023-02-06 10:51:53 | Stage | Epoch[320/600] LR:0.01

2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[001/030] Train loss: 0.0276
2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[002/030] Train loss: 0.0282
2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[003/030] Train loss: 0.0295
2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[004/030] Train loss: 0.0275
2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[005/030] Train loss: 0.0283
2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[006/030] Train loss: 0.0282
2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[007/030] Train loss: 0.0278
2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[008/030] Train loss: 0.0273
2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 10:51:53 | Train | Epoch[321/600] Iteration[011/030] Train loss: 0.0272
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[012/030] Train loss: 0.0269
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[014/030] Train loss: 0.0270
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[015/030] Train loss: 0.0269
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[016/030] Train loss: 0.0269
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[019/030] Train loss: 0.0265
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[020/030] Train loss: 0.0264
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[022/030] Train loss: 0.0268
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[023/030] Train loss: 0.0268
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[026/030] Train loss: 0.0266
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[027/030] Train loss: 0.0267
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[029/030] Train loss: 0.0267
2023-02-06 10:51:54 | Train | Epoch[321/600] Iteration[030/030] Train loss: 0.0266
2023-02-06 10:51:55 | Valid | Epoch[321/600] Iteration[001/008] Valid loss: 0.0453
2023-02-06 10:51:55 | Valid | Epoch[321/600] Iteration[002/008] Valid loss: 0.0438
2023-02-06 10:51:55 | Valid | Epoch[321/600] Iteration[003/008] Valid loss: 0.0449
2023-02-06 10:51:55 | Valid | Epoch[321/600] Iteration[004/008] Valid loss: 0.0440
2023-02-06 10:51:55 | Valid | Epoch[321/600] Iteration[005/008] Valid loss: 0.0446
2023-02-06 10:51:55 | Valid | Epoch[321/600] Iteration[006/008] Valid loss: 0.0437
2023-02-06 10:51:55 | Valid | Epoch[321/600] Iteration[007/008] Valid loss: 0.0426
2023-02-06 10:51:55 | Valid | Epoch[321/600] Iteration[008/008] Valid loss: 0.0436
2023-02-06 10:51:55 | Valid | Epoch[321/600] MIou: 0.8375852120587131
2023-02-06 10:51:55 | Valid | Epoch[321/600] Pixel Accuracy: 0.9732246398925781
2023-02-06 10:51:55 | Valid | Epoch[321/600] Mean Pixel Accuracy: 0.8521078565037473
2023-02-06 10:51:55 | Stage | Epoch[321/600] Train loss:0.0266
2023-02-06 10:51:55 | Stage | Epoch[321/600] Valid loss:0.0436
2023-02-06 10:51:55 | Stage | Epoch[321/600] LR:0.01

2023-02-06 10:51:55 | Train | Epoch[322/600] Iteration[001/030] Train loss: 0.0298
2023-02-06 10:51:55 | Train | Epoch[322/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 10:51:55 | Train | Epoch[322/600] Iteration[003/030] Train loss: 0.0265
2023-02-06 10:51:55 | Train | Epoch[322/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 10:51:55 | Train | Epoch[322/600] Iteration[005/030] Train loss: 0.0257
2023-02-06 10:51:55 | Train | Epoch[322/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[007/030] Train loss: 0.0260
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[011/030] Train loss: 0.0262
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[015/030] Train loss: 0.0263
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[016/030] Train loss: 0.0260
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[018/030] Train loss: 0.0261
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[019/030] Train loss: 0.0263
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[020/030] Train loss: 0.0264
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[021/030] Train loss: 0.0261
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[023/030] Train loss: 0.0263
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[024/030] Train loss: 0.0262
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[025/030] Train loss: 0.0263
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[029/030] Train loss: 0.0264
2023-02-06 10:51:56 | Train | Epoch[322/600] Iteration[030/030] Train loss: 0.0266
2023-02-06 10:51:57 | Valid | Epoch[322/600] Iteration[001/008] Valid loss: 0.2098
2023-02-06 10:51:57 | Valid | Epoch[322/600] Iteration[002/008] Valid loss: 0.2068
2023-02-06 10:51:57 | Valid | Epoch[322/600] Iteration[003/008] Valid loss: 0.2155
2023-02-06 10:51:57 | Valid | Epoch[322/600] Iteration[004/008] Valid loss: 0.2153
2023-02-06 10:51:57 | Valid | Epoch[322/600] Iteration[005/008] Valid loss: 0.2208
2023-02-06 10:51:57 | Valid | Epoch[322/600] Iteration[006/008] Valid loss: 0.2165
2023-02-06 10:51:57 | Valid | Epoch[322/600] Iteration[007/008] Valid loss: 0.2123
2023-02-06 10:51:57 | Valid | Epoch[322/600] Iteration[008/008] Valid loss: 0.2193
2023-02-06 10:51:57 | Valid | Epoch[322/600] MIou: 0.47677856516501854
2023-02-06 10:51:57 | Valid | Epoch[322/600] Pixel Accuracy: 0.9133427937825521
2023-02-06 10:51:57 | Valid | Epoch[322/600] Mean Pixel Accuracy: 0.5202663700741951
2023-02-06 10:51:57 | Stage | Epoch[322/600] Train loss:0.0266
2023-02-06 10:51:57 | Stage | Epoch[322/600] Valid loss:0.2193
2023-02-06 10:51:57 | Stage | Epoch[322/600] LR:0.01

2023-02-06 10:51:57 | Train | Epoch[323/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 10:51:57 | Train | Epoch[323/600] Iteration[002/030] Train loss: 0.0267
2023-02-06 10:51:57 | Train | Epoch[323/600] Iteration[003/030] Train loss: 0.0259
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[005/030] Train loss: 0.0265
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[006/030] Train loss: 0.0271
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[007/030] Train loss: 0.0264
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[016/030] Train loss: 0.0268
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[017/030] Train loss: 0.0271
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[018/030] Train loss: 0.0269
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[019/030] Train loss: 0.0270
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[020/030] Train loss: 0.0270
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[021/030] Train loss: 0.0270
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[022/030] Train loss: 0.0269
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[023/030] Train loss: 0.0269
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[024/030] Train loss: 0.0269
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[025/030] Train loss: 0.0267
2023-02-06 10:51:58 | Train | Epoch[323/600] Iteration[026/030] Train loss: 0.0267
2023-02-06 10:51:59 | Train | Epoch[323/600] Iteration[027/030] Train loss: 0.0267
2023-02-06 10:51:59 | Train | Epoch[323/600] Iteration[028/030] Train loss: 0.0266
2023-02-06 10:51:59 | Train | Epoch[323/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 10:51:59 | Train | Epoch[323/600] Iteration[030/030] Train loss: 0.0265
2023-02-06 10:51:59 | Valid | Epoch[323/600] Iteration[001/008] Valid loss: 0.4812
2023-02-06 10:51:59 | Valid | Epoch[323/600] Iteration[002/008] Valid loss: 0.4493
2023-02-06 10:51:59 | Valid | Epoch[323/600] Iteration[003/008] Valid loss: 0.4364
2023-02-06 10:51:59 | Valid | Epoch[323/600] Iteration[004/008] Valid loss: 0.4355
2023-02-06 10:51:59 | Valid | Epoch[323/600] Iteration[005/008] Valid loss: 0.4542
2023-02-06 10:51:59 | Valid | Epoch[323/600] Iteration[006/008] Valid loss: 0.4501
2023-02-06 10:51:59 | Valid | Epoch[323/600] Iteration[007/008] Valid loss: 0.4779
2023-02-06 10:51:59 | Valid | Epoch[323/600] Iteration[008/008] Valid loss: 0.4814
2023-02-06 10:51:59 | Valid | Epoch[323/600] MIou: 0.8579711354577397
2023-02-06 10:51:59 | Valid | Epoch[323/600] Pixel Accuracy: 0.9699885050455729
2023-02-06 10:51:59 | Valid | Epoch[323/600] Mean Pixel Accuracy: 0.9794782030035738
2023-02-06 10:51:59 | Stage | Epoch[323/600] Train loss:0.0265
2023-02-06 10:51:59 | Stage | Epoch[323/600] Valid loss:0.4814
2023-02-06 10:51:59 | Stage | Epoch[323/600] LR:0.01

2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[001/030] Train loss: 0.0238
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[002/030] Train loss: 0.0245
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[003/030] Train loss: 0.0301
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[004/030] Train loss: 0.0287
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[005/030] Train loss: 0.0282
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[006/030] Train loss: 0.0283
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[007/030] Train loss: 0.0276
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[008/030] Train loss: 0.0277
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[009/030] Train loss: 0.0272
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[013/030] Train loss: 0.0267
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[014/030] Train loss: 0.0272
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[015/030] Train loss: 0.0274
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[016/030] Train loss: 0.0272
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[017/030] Train loss: 0.0274
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[018/030] Train loss: 0.0273
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[019/030] Train loss: 0.0274
2023-02-06 10:52:00 | Train | Epoch[324/600] Iteration[020/030] Train loss: 0.0275
2023-02-06 10:52:01 | Train | Epoch[324/600] Iteration[021/030] Train loss: 0.0274
2023-02-06 10:52:01 | Train | Epoch[324/600] Iteration[022/030] Train loss: 0.0274
2023-02-06 10:52:01 | Train | Epoch[324/600] Iteration[023/030] Train loss: 0.0272
2023-02-06 10:52:01 | Train | Epoch[324/600] Iteration[024/030] Train loss: 0.0272
2023-02-06 10:52:01 | Train | Epoch[324/600] Iteration[025/030] Train loss: 0.0270
2023-02-06 10:52:01 | Train | Epoch[324/600] Iteration[026/030] Train loss: 0.0269
2023-02-06 10:52:01 | Train | Epoch[324/600] Iteration[027/030] Train loss: 0.0268
2023-02-06 10:52:01 | Train | Epoch[324/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:52:01 | Train | Epoch[324/600] Iteration[029/030] Train loss: 0.0269
2023-02-06 10:52:01 | Train | Epoch[324/600] Iteration[030/030] Train loss: 0.0270
2023-02-06 10:52:01 | Valid | Epoch[324/600] Iteration[001/008] Valid loss: 0.0975
2023-02-06 10:52:01 | Valid | Epoch[324/600] Iteration[002/008] Valid loss: 0.0973
2023-02-06 10:52:01 | Valid | Epoch[324/600] Iteration[003/008] Valid loss: 0.1004
2023-02-06 10:52:01 | Valid | Epoch[324/600] Iteration[004/008] Valid loss: 0.1002
2023-02-06 10:52:01 | Valid | Epoch[324/600] Iteration[005/008] Valid loss: 0.1022
2023-02-06 10:52:01 | Valid | Epoch[324/600] Iteration[006/008] Valid loss: 0.0999
2023-02-06 10:52:01 | Valid | Epoch[324/600] Iteration[007/008] Valid loss: 0.0973
2023-02-06 10:52:01 | Valid | Epoch[324/600] Iteration[008/008] Valid loss: 0.1005
2023-02-06 10:52:01 | Valid | Epoch[324/600] MIou: 0.6681302813815679
2023-02-06 10:52:01 | Valid | Epoch[324/600] Pixel Accuracy: 0.9451853434244791
2023-02-06 10:52:01 | Valid | Epoch[324/600] Mean Pixel Accuracy: 0.6965464810147968
2023-02-06 10:52:01 | Stage | Epoch[324/600] Train loss:0.0270
2023-02-06 10:52:01 | Stage | Epoch[324/600] Valid loss:0.1005
2023-02-06 10:52:01 | Stage | Epoch[324/600] LR:0.01

2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[001/030] Train loss: 0.0265
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[002/030] Train loss: 0.0247
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[003/030] Train loss: 0.0244
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[013/030] Train loss: 0.0265
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[015/030] Train loss: 0.0261
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[016/030] Train loss: 0.0259
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 10:52:02 | Train | Epoch[325/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[019/030] Train loss: 0.0265
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[020/030] Train loss: 0.0264
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[021/030] Train loss: 0.0264
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[025/030] Train loss: 0.0267
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[026/030] Train loss: 0.0266
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[027/030] Train loss: 0.0265
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 10:52:03 | Train | Epoch[325/600] Iteration[030/030] Train loss: 0.0265
2023-02-06 10:52:03 | Valid | Epoch[325/600] Iteration[001/008] Valid loss: 1.4318
2023-02-06 10:52:03 | Valid | Epoch[325/600] Iteration[002/008] Valid loss: 1.4389
2023-02-06 10:52:03 | Valid | Epoch[325/600] Iteration[003/008] Valid loss: 1.4616
2023-02-06 10:52:03 | Valid | Epoch[325/600] Iteration[004/008] Valid loss: 1.5018
2023-02-06 10:52:03 | Valid | Epoch[325/600] Iteration[005/008] Valid loss: 1.5504
2023-02-06 10:52:03 | Valid | Epoch[325/600] Iteration[006/008] Valid loss: 1.5459
2023-02-06 10:52:03 | Valid | Epoch[325/600] Iteration[007/008] Valid loss: 1.6216
2023-02-06 10:52:03 | Valid | Epoch[325/600] Iteration[008/008] Valid loss: 1.6641
2023-02-06 10:52:04 | Valid | Epoch[325/600] MIou: 0.7833756619451777
2023-02-06 10:52:04 | Valid | Epoch[325/600] Pixel Accuracy: 0.946197509765625
2023-02-06 10:52:04 | Valid | Epoch[325/600] Mean Pixel Accuracy: 0.9688744412260176
2023-02-06 10:52:04 | Stage | Epoch[325/600] Train loss:0.0265
2023-02-06 10:52:04 | Stage | Epoch[325/600] Valid loss:1.6641
2023-02-06 10:52:04 | Stage | Epoch[325/600] LR:0.01

2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[001/030] Train loss: 0.0293
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[002/030] Train loss: 0.0277
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[003/030] Train loss: 0.0283
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[004/030] Train loss: 0.0275
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[005/030] Train loss: 0.0275
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[006/030] Train loss: 0.0275
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[007/030] Train loss: 0.0276
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[008/030] Train loss: 0.0270
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[009/030] Train loss: 0.0274
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[010/030] Train loss: 0.0276
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[011/030] Train loss: 0.0274
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[013/030] Train loss: 0.0270
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 10:52:04 | Train | Epoch[326/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[016/030] Train loss: 0.0267
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[017/030] Train loss: 0.0269
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[018/030] Train loss: 0.0276
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[019/030] Train loss: 0.0277
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[020/030] Train loss: 0.0274
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[021/030] Train loss: 0.0273
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[022/030] Train loss: 0.0272
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[023/030] Train loss: 0.0275
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[024/030] Train loss: 0.0273
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[026/030] Train loss: 0.0272
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[028/030] Train loss: 0.0271
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[029/030] Train loss: 0.0270
2023-02-06 10:52:05 | Train | Epoch[326/600] Iteration[030/030] Train loss: 0.0270
2023-02-06 10:52:05 | Valid | Epoch[326/600] Iteration[001/008] Valid loss: 0.1391
2023-02-06 10:52:05 | Valid | Epoch[326/600] Iteration[002/008] Valid loss: 0.1077
2023-02-06 10:52:05 | Valid | Epoch[326/600] Iteration[003/008] Valid loss: 0.1028
2023-02-06 10:52:05 | Valid | Epoch[326/600] Iteration[004/008] Valid loss: 0.0993
2023-02-06 10:52:05 | Valid | Epoch[326/600] Iteration[005/008] Valid loss: 0.1031
2023-02-06 10:52:06 | Valid | Epoch[326/600] Iteration[006/008] Valid loss: 0.1057
2023-02-06 10:52:06 | Valid | Epoch[326/600] Iteration[007/008] Valid loss: 0.1136
2023-02-06 10:52:06 | Valid | Epoch[326/600] Iteration[008/008] Valid loss: 0.1100
2023-02-06 10:52:06 | Valid | Epoch[326/600] MIou: 0.9208453697569547
2023-02-06 10:52:06 | Valid | Epoch[326/600] Pixel Accuracy: 0.9855054219563802
2023-02-06 10:52:06 | Valid | Epoch[326/600] Mean Pixel Accuracy: 0.9768477324569933
2023-02-06 10:52:06 | Stage | Epoch[326/600] Train loss:0.0270
2023-02-06 10:52:06 | Stage | Epoch[326/600] Valid loss:0.1100
2023-02-06 10:52:06 | Stage | Epoch[326/600] LR:0.01

2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[001/030] Train loss: 0.0259
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[002/030] Train loss: 0.0268
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[003/030] Train loss: 0.0265
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[004/030] Train loss: 0.0265
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[006/030] Train loss: 0.0260
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[007/030] Train loss: 0.0268
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 10:52:06 | Train | Epoch[327/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[020/030] Train loss: 0.0263
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[022/030] Train loss: 0.0268
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[023/030] Train loss: 0.0268
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[025/030] Train loss: 0.0267
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[027/030] Train loss: 0.0265
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[029/030] Train loss: 0.0265
2023-02-06 10:52:07 | Train | Epoch[327/600] Iteration[030/030] Train loss: 0.0267
2023-02-06 10:52:08 | Valid | Epoch[327/600] Iteration[001/008] Valid loss: 0.1278
2023-02-06 10:52:08 | Valid | Epoch[327/600] Iteration[002/008] Valid loss: 0.0923
2023-02-06 10:52:08 | Valid | Epoch[327/600] Iteration[003/008] Valid loss: 0.0870
2023-02-06 10:52:08 | Valid | Epoch[327/600] Iteration[004/008] Valid loss: 0.0836
2023-02-06 10:52:08 | Valid | Epoch[327/600] Iteration[005/008] Valid loss: 0.0861
2023-02-06 10:52:08 | Valid | Epoch[327/600] Iteration[006/008] Valid loss: 0.0847
2023-02-06 10:52:08 | Valid | Epoch[327/600] Iteration[007/008] Valid loss: 0.0919
2023-02-06 10:52:08 | Valid | Epoch[327/600] Iteration[008/008] Valid loss: 0.0907
2023-02-06 10:52:08 | Valid | Epoch[327/600] MIou: 0.920371792555134
2023-02-06 10:52:08 | Valid | Epoch[327/600] Pixel Accuracy: 0.9853897094726562
2023-02-06 10:52:08 | Valid | Epoch[327/600] Mean Pixel Accuracy: 0.9773357529624714
2023-02-06 10:52:08 | Stage | Epoch[327/600] Train loss:0.0267
2023-02-06 10:52:08 | Stage | Epoch[327/600] Valid loss:0.0907
2023-02-06 10:52:08 | Stage | Epoch[327/600] LR:0.01

2023-02-06 10:52:08 | Train | Epoch[328/600] Iteration[001/030] Train loss: 0.0265
2023-02-06 10:52:08 | Train | Epoch[328/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 10:52:08 | Train | Epoch[328/600] Iteration[003/030] Train loss: 0.0271
2023-02-06 10:52:08 | Train | Epoch[328/600] Iteration[004/030] Train loss: 0.0257
2023-02-06 10:52:08 | Train | Epoch[328/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:52:08 | Train | Epoch[328/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[009/030] Train loss: 0.0266
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[010/030] Train loss: 0.0267
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[011/030] Train loss: 0.0269
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[013/030] Train loss: 0.0265
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[014/030] Train loss: 0.0266
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[015/030] Train loss: 0.0268
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[018/030] Train loss: 0.0264
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[019/030] Train loss: 0.0265
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[020/030] Train loss: 0.0266
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[021/030] Train loss: 0.0267
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[026/030] Train loss: 0.0269
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[027/030] Train loss: 0.0269
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 10:52:09 | Train | Epoch[328/600] Iteration[029/030] Train loss: 0.0270
2023-02-06 10:52:10 | Train | Epoch[328/600] Iteration[030/030] Train loss: 0.0269
2023-02-06 10:52:10 | Valid | Epoch[328/600] Iteration[001/008] Valid loss: 0.0514
2023-02-06 10:52:10 | Valid | Epoch[328/600] Iteration[002/008] Valid loss: 0.0433
2023-02-06 10:52:10 | Valid | Epoch[328/600] Iteration[003/008] Valid loss: 0.0416
2023-02-06 10:52:10 | Valid | Epoch[328/600] Iteration[004/008] Valid loss: 0.0401
2023-02-06 10:52:10 | Valid | Epoch[328/600] Iteration[005/008] Valid loss: 0.0419
2023-02-06 10:52:10 | Valid | Epoch[328/600] Iteration[006/008] Valid loss: 0.0416
2023-02-06 10:52:10 | Valid | Epoch[328/600] Iteration[007/008] Valid loss: 0.0434
2023-02-06 10:52:10 | Valid | Epoch[328/600] Iteration[008/008] Valid loss: 0.0435
2023-02-06 10:52:10 | Valid | Epoch[328/600] MIou: 0.92766974452029
2023-02-06 10:52:10 | Valid | Epoch[328/600] Pixel Accuracy: 0.9873758951822916
2023-02-06 10:52:10 | Valid | Epoch[328/600] Mean Pixel Accuracy: 0.9607121679325078
2023-02-06 10:52:10 | Stage | Epoch[328/600] Train loss:0.0269
2023-02-06 10:52:10 | Stage | Epoch[328/600] Valid loss:0.0435
2023-02-06 10:52:10 | Stage | Epoch[328/600] LR:0.01

2023-02-06 10:52:10 | Train | Epoch[329/600] Iteration[001/030] Train loss: 0.0311
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[002/030] Train loss: 0.0287
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[003/030] Train loss: 0.0281
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[004/030] Train loss: 0.0276
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[005/030] Train loss: 0.0273
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[006/030] Train loss: 0.0270
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[015/030] Train loss: 0.0261
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[016/030] Train loss: 0.0266
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[018/030] Train loss: 0.0264
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[019/030] Train loss: 0.0264
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[020/030] Train loss: 0.0266
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[022/030] Train loss: 0.0266
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[023/030] Train loss: 0.0264
2023-02-06 10:52:11 | Train | Epoch[329/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 10:52:12 | Train | Epoch[329/600] Iteration[025/030] Train loss: 0.0262
2023-02-06 10:52:12 | Train | Epoch[329/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 10:52:12 | Train | Epoch[329/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:52:12 | Train | Epoch[329/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:52:12 | Train | Epoch[329/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 10:52:12 | Train | Epoch[329/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:52:12 | Valid | Epoch[329/600] Iteration[001/008] Valid loss: 0.0461
2023-02-06 10:52:12 | Valid | Epoch[329/600] Iteration[002/008] Valid loss: 0.0435
2023-02-06 10:52:12 | Valid | Epoch[329/600] Iteration[003/008] Valid loss: 0.0442
2023-02-06 10:52:12 | Valid | Epoch[329/600] Iteration[004/008] Valid loss: 0.0430
2023-02-06 10:52:12 | Valid | Epoch[329/600] Iteration[005/008] Valid loss: 0.0435
2023-02-06 10:52:12 | Valid | Epoch[329/600] Iteration[006/008] Valid loss: 0.0427
2023-02-06 10:52:12 | Valid | Epoch[329/600] Iteration[007/008] Valid loss: 0.0418
2023-02-06 10:52:12 | Valid | Epoch[329/600] Iteration[008/008] Valid loss: 0.0423
2023-02-06 10:52:12 | Valid | Epoch[329/600] MIou: 0.857970655949293
2023-02-06 10:52:12 | Valid | Epoch[329/600] Pixel Accuracy: 0.9765892028808594
2023-02-06 10:52:12 | Valid | Epoch[329/600] Mean Pixel Accuracy: 0.8708101370963557
2023-02-06 10:52:12 | Stage | Epoch[329/600] Train loss:0.0263
2023-02-06 10:52:12 | Stage | Epoch[329/600] Valid loss:0.0423
2023-02-06 10:52:12 | Stage | Epoch[329/600] LR:0.01

2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[001/030] Train loss: 0.0220
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[002/030] Train loss: 0.0240
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[006/030] Train loss: 0.0261
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[008/030] Train loss: 0.0273
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[011/030] Train loss: 0.0270
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[012/030] Train loss: 0.0270
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[013/030] Train loss: 0.0268
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[014/030] Train loss: 0.0271
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[015/030] Train loss: 0.0271
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[016/030] Train loss: 0.0273
2023-02-06 10:52:13 | Train | Epoch[330/600] Iteration[017/030] Train loss: 0.0270
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[019/030] Train loss: 0.0265
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[020/030] Train loss: 0.0264
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[021/030] Train loss: 0.0265
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[022/030] Train loss: 0.0265
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[025/030] Train loss: 0.0267
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[026/030] Train loss: 0.0267
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[027/030] Train loss: 0.0266
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[028/030] Train loss: 0.0264
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 10:52:14 | Train | Epoch[330/600] Iteration[030/030] Train loss: 0.0265
2023-02-06 10:52:14 | Valid | Epoch[330/600] Iteration[001/008] Valid loss: 0.1678
2023-02-06 10:52:14 | Valid | Epoch[330/600] Iteration[002/008] Valid loss: 0.1649
2023-02-06 10:52:14 | Valid | Epoch[330/600] Iteration[003/008] Valid loss: 0.1710
2023-02-06 10:52:14 | Valid | Epoch[330/600] Iteration[004/008] Valid loss: 0.1704
2023-02-06 10:52:14 | Valid | Epoch[330/600] Iteration[005/008] Valid loss: 0.1741
2023-02-06 10:52:14 | Valid | Epoch[330/600] Iteration[006/008] Valid loss: 0.1705
2023-02-06 10:52:15 | Valid | Epoch[330/600] Iteration[007/008] Valid loss: 0.1664
2023-02-06 10:52:15 | Valid | Epoch[330/600] Iteration[008/008] Valid loss: 0.1716
2023-02-06 10:52:15 | Valid | Epoch[330/600] MIou: 0.5464301040599584
2023-02-06 10:52:15 | Valid | Epoch[330/600] Pixel Accuracy: 0.9249521891276041
2023-02-06 10:52:15 | Valid | Epoch[330/600] Mean Pixel Accuracy: 0.5845358937898605
2023-02-06 10:52:15 | Stage | Epoch[330/600] Train loss:0.0265
2023-02-06 10:52:15 | Stage | Epoch[330/600] Valid loss:0.1716
2023-02-06 10:52:15 | Stage | Epoch[330/600] LR:0.01

2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[001/030] Train loss: 0.0258
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[004/030] Train loss: 0.0257
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[005/030] Train loss: 0.0263
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[006/030] Train loss: 0.0265
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[010/030] Train loss: 0.0263
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[011/030] Train loss: 0.0269
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 10:52:15 | Train | Epoch[331/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[014/030] Train loss: 0.0266
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[021/030] Train loss: 0.0271
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[022/030] Train loss: 0.0270
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[024/030] Train loss: 0.0271
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[025/030] Train loss: 0.0271
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[026/030] Train loss: 0.0271
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[027/030] Train loss: 0.0269
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[029/030] Train loss: 0.0269
2023-02-06 10:52:16 | Train | Epoch[331/600] Iteration[030/030] Train loss: 0.0268
2023-02-06 10:52:17 | Valid | Epoch[331/600] Iteration[001/008] Valid loss: 0.2739
2023-02-06 10:52:17 | Valid | Epoch[331/600] Iteration[002/008] Valid loss: 0.2464
2023-02-06 10:52:17 | Valid | Epoch[331/600] Iteration[003/008] Valid loss: 0.2219
2023-02-06 10:52:17 | Valid | Epoch[331/600] Iteration[004/008] Valid loss: 0.2232
2023-02-06 10:52:17 | Valid | Epoch[331/600] Iteration[005/008] Valid loss: 0.2249
2023-02-06 10:52:17 | Valid | Epoch[331/600] Iteration[006/008] Valid loss: 0.2315
2023-02-06 10:52:17 | Valid | Epoch[331/600] Iteration[007/008] Valid loss: 0.2470
2023-02-06 10:52:17 | Valid | Epoch[331/600] Iteration[008/008] Valid loss: 0.2419
2023-02-06 10:52:17 | Valid | Epoch[331/600] MIou: 0.889015191873138
2023-02-06 10:52:17 | Valid | Epoch[331/600] Pixel Accuracy: 0.9780286153157552
2023-02-06 10:52:17 | Valid | Epoch[331/600] Mean Pixel Accuracy: 0.9817479706678804
2023-02-06 10:52:17 | Stage | Epoch[331/600] Train loss:0.0268
2023-02-06 10:52:17 | Stage | Epoch[331/600] Valid loss:0.2419
2023-02-06 10:52:17 | Stage | Epoch[331/600] LR:0.01

2023-02-06 10:52:17 | Train | Epoch[332/600] Iteration[001/030] Train loss: 0.0289
2023-02-06 10:52:17 | Train | Epoch[332/600] Iteration[002/030] Train loss: 0.0267
2023-02-06 10:52:17 | Train | Epoch[332/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 10:52:17 | Train | Epoch[332/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 10:52:17 | Train | Epoch[332/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:52:17 | Train | Epoch[332/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 10:52:17 | Train | Epoch[332/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 10:52:17 | Train | Epoch[332/600] Iteration[008/030] Train loss: 0.0251
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[010/030] Train loss: 0.0245
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[022/030] Train loss: 0.0258
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[024/030] Train loss: 0.0260
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[025/030] Train loss: 0.0260
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[026/030] Train loss: 0.0261
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 10:52:18 | Train | Epoch[332/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:52:19 | Valid | Epoch[332/600] Iteration[001/008] Valid loss: 0.2517
2023-02-06 10:52:19 | Valid | Epoch[332/600] Iteration[002/008] Valid loss: 0.2014
2023-02-06 10:52:19 | Valid | Epoch[332/600] Iteration[003/008] Valid loss: 0.1950
2023-02-06 10:52:19 | Valid | Epoch[332/600] Iteration[004/008] Valid loss: 0.1921
2023-02-06 10:52:19 | Valid | Epoch[332/600] Iteration[005/008] Valid loss: 0.1999
2023-02-06 10:52:19 | Valid | Epoch[332/600] Iteration[006/008] Valid loss: 0.1985
2023-02-06 10:52:19 | Valid | Epoch[332/600] Iteration[007/008] Valid loss: 0.2121
2023-02-06 10:52:19 | Valid | Epoch[332/600] Iteration[008/008] Valid loss: 0.2122
2023-02-06 10:52:19 | Valid | Epoch[332/600] MIou: 0.8777422415924672
2023-02-06 10:52:19 | Valid | Epoch[332/600] Pixel Accuracy: 0.9753074645996094
2023-02-06 10:52:19 | Valid | Epoch[332/600] Mean Pixel Accuracy: 0.979263196624131
2023-02-06 10:52:19 | Stage | Epoch[332/600] Train loss:0.0262
2023-02-06 10:52:19 | Stage | Epoch[332/600] Valid loss:0.2122
2023-02-06 10:52:19 | Stage | Epoch[332/600] LR:0.01

2023-02-06 10:52:19 | Train | Epoch[333/600] Iteration[001/030] Train loss: 0.0260
2023-02-06 10:52:19 | Train | Epoch[333/600] Iteration[002/030] Train loss: 0.0266
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[003/030] Train loss: 0.0273
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[004/030] Train loss: 0.0272
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[007/030] Train loss: 0.0268
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[009/030] Train loss: 0.0270
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[013/030] Train loss: 0.0267
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[016/030] Train loss: 0.0262
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[019/030] Train loss: 0.0264
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[020/030] Train loss: 0.0264
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[021/030] Train loss: 0.0265
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:52:20 | Train | Epoch[333/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 10:52:21 | Train | Epoch[333/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:52:21 | Train | Epoch[333/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 10:52:21 | Train | Epoch[333/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 10:52:21 | Train | Epoch[333/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:52:21 | Train | Epoch[333/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:52:21 | Train | Epoch[333/600] Iteration[030/030] Train loss: 0.0261
2023-02-06 10:52:21 | Valid | Epoch[333/600] Iteration[001/008] Valid loss: 0.0369
2023-02-06 10:52:21 | Valid | Epoch[333/600] Iteration[002/008] Valid loss: 0.0345
2023-02-06 10:52:21 | Valid | Epoch[333/600] Iteration[003/008] Valid loss: 0.0348
2023-02-06 10:52:21 | Valid | Epoch[333/600] Iteration[004/008] Valid loss: 0.0337
2023-02-06 10:52:21 | Valid | Epoch[333/600] Iteration[005/008] Valid loss: 0.0340
2023-02-06 10:52:21 | Valid | Epoch[333/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 10:52:21 | Valid | Epoch[333/600] Iteration[007/008] Valid loss: 0.0329
2023-02-06 10:52:21 | Valid | Epoch[333/600] Iteration[008/008] Valid loss: 0.0333
2023-02-06 10:52:21 | Valid | Epoch[333/600] MIou: 0.8864636102059655
2023-02-06 10:52:21 | Valid | Epoch[333/600] Pixel Accuracy: 0.9812660217285156
2023-02-06 10:52:21 | Valid | Epoch[333/600] Mean Pixel Accuracy: 0.8974491460563822
2023-02-06 10:52:21 | Stage | Epoch[333/600] Train loss:0.0261
2023-02-06 10:52:21 | Stage | Epoch[333/600] Valid loss:0.0333
2023-02-06 10:52:21 | Stage | Epoch[333/600] LR:0.01

2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[002/030] Train loss: 0.0241
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[003/030] Train loss: 0.0250
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[008/030] Train loss: 0.0259
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[011/030] Train loss: 0.0262
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[014/030] Train loss: 0.0271
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[015/030] Train loss: 0.0270
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[016/030] Train loss: 0.0269
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[018/030] Train loss: 0.0266
2023-02-06 10:52:22 | Train | Epoch[334/600] Iteration[019/030] Train loss: 0.0267
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[020/030] Train loss: 0.0265
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[021/030] Train loss: 0.0265
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[025/030] Train loss: 0.0265
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[026/030] Train loss: 0.0266
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[027/030] Train loss: 0.0265
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:52:23 | Train | Epoch[334/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:52:23 | Valid | Epoch[334/600] Iteration[001/008] Valid loss: 0.0367
2023-02-06 10:52:23 | Valid | Epoch[334/600] Iteration[002/008] Valid loss: 0.0331
2023-02-06 10:52:23 | Valid | Epoch[334/600] Iteration[003/008] Valid loss: 0.0328
2023-02-06 10:52:23 | Valid | Epoch[334/600] Iteration[004/008] Valid loss: 0.0317
2023-02-06 10:52:23 | Valid | Epoch[334/600] Iteration[005/008] Valid loss: 0.0320
2023-02-06 10:52:23 | Valid | Epoch[334/600] Iteration[006/008] Valid loss: 0.0317
2023-02-06 10:52:23 | Valid | Epoch[334/600] Iteration[007/008] Valid loss: 0.0312
2023-02-06 10:52:24 | Valid | Epoch[334/600] Iteration[008/008] Valid loss: 0.0314
2023-02-06 10:52:24 | Valid | Epoch[334/600] MIou: 0.8992972971393369
2023-02-06 10:52:24 | Valid | Epoch[334/600] Pixel Accuracy: 0.9833526611328125
2023-02-06 10:52:24 | Valid | Epoch[334/600] Mean Pixel Accuracy: 0.9100342626737938
2023-02-06 10:52:24 | Stage | Epoch[334/600] Train loss:0.0262
2023-02-06 10:52:24 | Stage | Epoch[334/600] Valid loss:0.0314
2023-02-06 10:52:24 | Stage | Epoch[334/600] LR:0.01

2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[001/030] Train loss: 0.0258
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[003/030] Train loss: 0.0251
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[011/030] Train loss: 0.0266
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 10:52:24 | Train | Epoch[335/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[015/030] Train loss: 0.0263
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[017/030] Train loss: 0.0261
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[018/030] Train loss: 0.0263
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[022/030] Train loss: 0.0260
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[024/030] Train loss: 0.0261
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[025/030] Train loss: 0.0261
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[028/030] Train loss: 0.0261
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 10:52:25 | Train | Epoch[335/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:52:26 | Valid | Epoch[335/600] Iteration[001/008] Valid loss: 0.4796
2023-02-06 10:52:26 | Valid | Epoch[335/600] Iteration[002/008] Valid loss: 0.4398
2023-02-06 10:52:26 | Valid | Epoch[335/600] Iteration[003/008] Valid loss: 0.4267
2023-02-06 10:52:26 | Valid | Epoch[335/600] Iteration[004/008] Valid loss: 0.4296
2023-02-06 10:52:26 | Valid | Epoch[335/600] Iteration[005/008] Valid loss: 0.4487
2023-02-06 10:52:26 | Valid | Epoch[335/600] Iteration[006/008] Valid loss: 0.4457
2023-02-06 10:52:26 | Valid | Epoch[335/600] Iteration[007/008] Valid loss: 0.4708
2023-02-06 10:52:26 | Valid | Epoch[335/600] Iteration[008/008] Valid loss: 0.4742
2023-02-06 10:52:26 | Valid | Epoch[335/600] MIou: 0.8528483327085286
2023-02-06 10:52:26 | Valid | Epoch[335/600] Pixel Accuracy: 0.9685796101888021
2023-02-06 10:52:26 | Valid | Epoch[335/600] Mean Pixel Accuracy: 0.978767219017501
2023-02-06 10:52:26 | Stage | Epoch[335/600] Train loss:0.0263
2023-02-06 10:52:26 | Stage | Epoch[335/600] Valid loss:0.4742
2023-02-06 10:52:26 | Stage | Epoch[335/600] LR:0.01

2023-02-06 10:52:26 | Train | Epoch[336/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 10:52:26 | Train | Epoch[336/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 10:52:26 | Train | Epoch[336/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 10:52:26 | Train | Epoch[336/600] Iteration[004/030] Train loss: 0.0269
2023-02-06 10:52:26 | Train | Epoch[336/600] Iteration[005/030] Train loss: 0.0262
2023-02-06 10:52:26 | Train | Epoch[336/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 10:52:26 | Train | Epoch[336/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:52:26 | Train | Epoch[336/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:52:26 | Train | Epoch[336/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[016/030] Train loss: 0.0260
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[017/030] Train loss: 0.0262
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[018/030] Train loss: 0.0264
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[019/030] Train loss: 0.0262
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[021/030] Train loss: 0.0261
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[023/030] Train loss: 0.0261
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[024/030] Train loss: 0.0260
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[025/030] Train loss: 0.0260
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:52:27 | Train | Epoch[336/600] Iteration[030/030] Train loss: 0.0261
2023-02-06 10:52:28 | Valid | Epoch[336/600] Iteration[001/008] Valid loss: 0.0961
2023-02-06 10:52:28 | Valid | Epoch[336/600] Iteration[002/008] Valid loss: 0.0964
2023-02-06 10:52:28 | Valid | Epoch[336/600] Iteration[003/008] Valid loss: 0.0997
2023-02-06 10:52:28 | Valid | Epoch[336/600] Iteration[004/008] Valid loss: 0.0994
2023-02-06 10:52:28 | Valid | Epoch[336/600] Iteration[005/008] Valid loss: 0.1018
2023-02-06 10:52:28 | Valid | Epoch[336/600] Iteration[006/008] Valid loss: 0.0996
2023-02-06 10:52:28 | Valid | Epoch[336/600] Iteration[007/008] Valid loss: 0.0971
2023-02-06 10:52:28 | Valid | Epoch[336/600] Iteration[008/008] Valid loss: 0.1003
2023-02-06 10:52:28 | Valid | Epoch[336/600] MIou: 0.6645910273946503
2023-02-06 10:52:28 | Valid | Epoch[336/600] Pixel Accuracy: 0.9445978800455729
2023-02-06 10:52:28 | Valid | Epoch[336/600] Mean Pixel Accuracy: 0.6932942882484618
2023-02-06 10:52:28 | Stage | Epoch[336/600] Train loss:0.0261
2023-02-06 10:52:28 | Stage | Epoch[336/600] Valid loss:0.1003
2023-02-06 10:52:28 | Stage | Epoch[336/600] LR:0.01

2023-02-06 10:52:28 | Train | Epoch[337/600] Iteration[001/030] Train loss: 0.0275
2023-02-06 10:52:28 | Train | Epoch[337/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 10:52:28 | Train | Epoch[337/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 10:52:28 | Train | Epoch[337/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 10:52:28 | Train | Epoch[337/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 10:52:28 | Train | Epoch[337/600] Iteration[006/030] Train loss: 0.0258
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[007/030] Train loss: 0.0268
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[008/030] Train loss: 0.0266
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[009/030] Train loss: 0.0270
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[010/030] Train loss: 0.0267
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[011/030] Train loss: 0.0263
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[018/030] Train loss: 0.0262
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[021/030] Train loss: 0.0264
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[022/030] Train loss: 0.0264
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[024/030] Train loss: 0.0263
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 10:52:29 | Train | Epoch[337/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 10:52:30 | Train | Epoch[337/600] Iteration[030/030] Train loss: 0.0266
2023-02-06 10:52:30 | Valid | Epoch[337/600] Iteration[001/008] Valid loss: 0.0380
2023-02-06 10:52:30 | Valid | Epoch[337/600] Iteration[002/008] Valid loss: 0.0354
2023-02-06 10:52:30 | Valid | Epoch[337/600] Iteration[003/008] Valid loss: 0.0360
2023-02-06 10:52:30 | Valid | Epoch[337/600] Iteration[004/008] Valid loss: 0.0349
2023-02-06 10:52:30 | Valid | Epoch[337/600] Iteration[005/008] Valid loss: 0.0355
2023-02-06 10:52:30 | Valid | Epoch[337/600] Iteration[006/008] Valid loss: 0.0348
2023-02-06 10:52:30 | Valid | Epoch[337/600] Iteration[007/008] Valid loss: 0.0341
2023-02-06 10:52:30 | Valid | Epoch[337/600] Iteration[008/008] Valid loss: 0.0346
2023-02-06 10:52:30 | Valid | Epoch[337/600] MIou: 0.881708663940503
2023-02-06 10:52:30 | Valid | Epoch[337/600] Pixel Accuracy: 0.9804712931315104
2023-02-06 10:52:30 | Valid | Epoch[337/600] Mean Pixel Accuracy: 0.8932714511329861
2023-02-06 10:52:30 | Stage | Epoch[337/600] Train loss:0.0266
2023-02-06 10:52:30 | Stage | Epoch[337/600] Valid loss:0.0346
2023-02-06 10:52:30 | Stage | Epoch[337/600] LR:0.01

2023-02-06 10:52:30 | Train | Epoch[338/600] Iteration[001/030] Train loss: 0.0285
2023-02-06 10:52:30 | Train | Epoch[338/600] Iteration[002/030] Train loss: 0.0278
2023-02-06 10:52:30 | Train | Epoch[338/600] Iteration[003/030] Train loss: 0.0258
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[005/030] Train loss: 0.0266
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[008/030] Train loss: 0.0266
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[010/030] Train loss: 0.0263
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[013/030] Train loss: 0.0265
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[015/030] Train loss: 0.0269
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[016/030] Train loss: 0.0269
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[017/030] Train loss: 0.0269
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[018/030] Train loss: 0.0269
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[020/030] Train loss: 0.0269
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[021/030] Train loss: 0.0268
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[022/030] Train loss: 0.0266
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[024/030] Train loss: 0.0263
2023-02-06 10:52:31 | Train | Epoch[338/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 10:52:32 | Train | Epoch[338/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 10:52:32 | Train | Epoch[338/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:52:32 | Train | Epoch[338/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:52:32 | Train | Epoch[338/600] Iteration[029/030] Train loss: 0.0261
2023-02-06 10:52:32 | Train | Epoch[338/600] Iteration[030/030] Train loss: 0.0260
2023-02-06 10:52:32 | Valid | Epoch[338/600] Iteration[001/008] Valid loss: 0.0368
2023-02-06 10:52:32 | Valid | Epoch[338/600] Iteration[002/008] Valid loss: 0.0312
2023-02-06 10:52:32 | Valid | Epoch[338/600] Iteration[003/008] Valid loss: 0.0306
2023-02-06 10:52:32 | Valid | Epoch[338/600] Iteration[004/008] Valid loss: 0.0293
2023-02-06 10:52:32 | Valid | Epoch[338/600] Iteration[005/008] Valid loss: 0.0305
2023-02-06 10:52:32 | Valid | Epoch[338/600] Iteration[006/008] Valid loss: 0.0303
2023-02-06 10:52:32 | Valid | Epoch[338/600] Iteration[007/008] Valid loss: 0.0309
2023-02-06 10:52:32 | Valid | Epoch[338/600] Iteration[008/008] Valid loss: 0.0307
2023-02-06 10:52:32 | Valid | Epoch[338/600] MIou: 0.9275984978851042
2023-02-06 10:52:32 | Valid | Epoch[338/600] Pixel Accuracy: 0.9878374735514323
2023-02-06 10:52:32 | Valid | Epoch[338/600] Mean Pixel Accuracy: 0.9432252317992296
2023-02-06 10:52:32 | Stage | Epoch[338/600] Train loss:0.0260
2023-02-06 10:52:32 | Stage | Epoch[338/600] Valid loss:0.0307
2023-02-06 10:52:32 | Stage | Epoch[338/600] LR:0.01

2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[001/030] Train loss: 0.0343
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[002/030] Train loss: 0.0287
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[003/030] Train loss: 0.0287
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[004/030] Train loss: 0.0282
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[005/030] Train loss: 0.0280
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[007/030] Train loss: 0.0268
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[008/030] Train loss: 0.0273
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[010/030] Train loss: 0.0272
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[011/030] Train loss: 0.0268
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[014/030] Train loss: 0.0261
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[018/030] Train loss: 0.0259
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 10:52:33 | Train | Epoch[339/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:52:34 | Train | Epoch[339/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 10:52:34 | Train | Epoch[339/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:52:34 | Train | Epoch[339/600] Iteration[024/030] Train loss: 0.0261
2023-02-06 10:52:34 | Train | Epoch[339/600] Iteration[025/030] Train loss: 0.0263
2023-02-06 10:52:34 | Train | Epoch[339/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 10:52:34 | Train | Epoch[339/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 10:52:34 | Train | Epoch[339/600] Iteration[028/030] Train loss: 0.0264
2023-02-06 10:52:34 | Train | Epoch[339/600] Iteration[029/030] Train loss: 0.0266
2023-02-06 10:52:34 | Train | Epoch[339/600] Iteration[030/030] Train loss: 0.0265
2023-02-06 10:52:34 | Valid | Epoch[339/600] Iteration[001/008] Valid loss: 0.0929
2023-02-06 10:52:34 | Valid | Epoch[339/600] Iteration[002/008] Valid loss: 0.0728
2023-02-06 10:52:34 | Valid | Epoch[339/600] Iteration[003/008] Valid loss: 0.0666
2023-02-06 10:52:34 | Valid | Epoch[339/600] Iteration[004/008] Valid loss: 0.0648
2023-02-06 10:52:34 | Valid | Epoch[339/600] Iteration[005/008] Valid loss: 0.0658
2023-02-06 10:52:34 | Valid | Epoch[339/600] Iteration[006/008] Valid loss: 0.0665
2023-02-06 10:52:34 | Valid | Epoch[339/600] Iteration[007/008] Valid loss: 0.0714
2023-02-06 10:52:34 | Valid | Epoch[339/600] Iteration[008/008] Valid loss: 0.0701
2023-02-06 10:52:34 | Valid | Epoch[339/600] MIou: 0.9284417703909944
2023-02-06 10:52:34 | Valid | Epoch[339/600] Pixel Accuracy: 0.987152099609375
2023-02-06 10:52:34 | Valid | Epoch[339/600] Mean Pixel Accuracy: 0.9749503283158432
2023-02-06 10:52:34 | Stage | Epoch[339/600] Train loss:0.0265
2023-02-06 10:52:34 | Stage | Epoch[339/600] Valid loss:0.0701
2023-02-06 10:52:34 | Stage | Epoch[339/600] LR:0.01

2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[001/030] Train loss: 0.0270
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[002/030] Train loss: 0.0259
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[005/030] Train loss: 0.0260
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[006/030] Train loss: 0.0260
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:52:35 | Train | Epoch[340/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[022/030] Train loss: 0.0256
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[026/030] Train loss: 0.0259
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[027/030] Train loss: 0.0259
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[028/030] Train loss: 0.0259
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[029/030] Train loss: 0.0261
2023-02-06 10:52:36 | Train | Epoch[340/600] Iteration[030/030] Train loss: 0.0260
2023-02-06 10:52:36 | Valid | Epoch[340/600] Iteration[001/008] Valid loss: 0.1451
2023-02-06 10:52:36 | Valid | Epoch[340/600] Iteration[002/008] Valid loss: 0.1145
2023-02-06 10:52:36 | Valid | Epoch[340/600] Iteration[003/008] Valid loss: 0.1075
2023-02-06 10:52:36 | Valid | Epoch[340/600] Iteration[004/008] Valid loss: 0.1039
2023-02-06 10:52:37 | Valid | Epoch[340/600] Iteration[005/008] Valid loss: 0.1081
2023-02-06 10:52:37 | Valid | Epoch[340/600] Iteration[006/008] Valid loss: 0.1119
2023-02-06 10:52:37 | Valid | Epoch[340/600] Iteration[007/008] Valid loss: 0.1192
2023-02-06 10:52:37 | Valid | Epoch[340/600] Iteration[008/008] Valid loss: 0.1155
2023-02-06 10:52:37 | Valid | Epoch[340/600] MIou: 0.9169654528714026
2023-02-06 10:52:37 | Valid | Epoch[340/600] Pixel Accuracy: 0.9845682779947916
2023-02-06 10:52:37 | Valid | Epoch[340/600] Mean Pixel Accuracy: 0.9801305806032168
2023-02-06 10:52:37 | Stage | Epoch[340/600] Train loss:0.0260
2023-02-06 10:52:37 | Stage | Epoch[340/600] Valid loss:0.1155
2023-02-06 10:52:37 | Stage | Epoch[340/600] LR:0.01

2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[001/030] Train loss: 0.0272
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[002/030] Train loss: 0.0282
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[003/030] Train loss: 0.0278
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[004/030] Train loss: 0.0271
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[005/030] Train loss: 0.0268
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 10:52:37 | Train | Epoch[341/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[014/030] Train loss: 0.0273
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[015/030] Train loss: 0.0271
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[016/030] Train loss: 0.0272
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[017/030] Train loss: 0.0272
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[019/030] Train loss: 0.0270
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[020/030] Train loss: 0.0267
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[022/030] Train loss: 0.0266
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[023/030] Train loss: 0.0264
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[024/030] Train loss: 0.0265
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[028/030] Train loss: 0.0264
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[029/030] Train loss: 0.0264
2023-02-06 10:52:38 | Train | Epoch[341/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:52:39 | Valid | Epoch[341/600] Iteration[001/008] Valid loss: 0.2488
2023-02-06 10:52:39 | Valid | Epoch[341/600] Iteration[002/008] Valid loss: 0.2052
2023-02-06 10:52:39 | Valid | Epoch[341/600] Iteration[003/008] Valid loss: 0.1955
2023-02-06 10:52:39 | Valid | Epoch[341/600] Iteration[004/008] Valid loss: 0.1941
2023-02-06 10:52:39 | Valid | Epoch[341/600] Iteration[005/008] Valid loss: 0.2014
2023-02-06 10:52:39 | Valid | Epoch[341/600] Iteration[006/008] Valid loss: 0.1996
2023-02-06 10:52:39 | Valid | Epoch[341/600] Iteration[007/008] Valid loss: 0.2142
2023-02-06 10:52:39 | Valid | Epoch[341/600] Iteration[008/008] Valid loss: 0.2132
2023-02-06 10:52:39 | Valid | Epoch[341/600] MIou: 0.8848494042387856
2023-02-06 10:52:39 | Valid | Epoch[341/600] Pixel Accuracy: 0.9770533243815104
2023-02-06 10:52:39 | Valid | Epoch[341/600] Mean Pixel Accuracy: 0.9804447121223054
2023-02-06 10:52:39 | Stage | Epoch[341/600] Train loss:0.0263
2023-02-06 10:52:39 | Stage | Epoch[341/600] Valid loss:0.2132
2023-02-06 10:52:39 | Stage | Epoch[341/600] LR:0.01

2023-02-06 10:52:39 | Train | Epoch[342/600] Iteration[001/030] Train loss: 0.0192
2023-02-06 10:52:39 | Train | Epoch[342/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 10:52:39 | Train | Epoch[342/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 10:52:39 | Train | Epoch[342/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:52:39 | Train | Epoch[342/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 10:52:39 | Train | Epoch[342/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:52:39 | Train | Epoch[342/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[012/030] Train loss: 0.0247
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[019/030] Train loss: 0.0258
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[021/030] Train loss: 0.0260
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[024/030] Train loss: 0.0260
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[025/030] Train loss: 0.0261
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[027/030] Train loss: 0.0265
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[029/030] Train loss: 0.0265
2023-02-06 10:52:40 | Train | Epoch[342/600] Iteration[030/030] Train loss: 0.0267
2023-02-06 10:52:41 | Valid | Epoch[342/600] Iteration[001/008] Valid loss: 0.2316
2023-02-06 10:52:41 | Valid | Epoch[342/600] Iteration[002/008] Valid loss: 0.1854
2023-02-06 10:52:41 | Valid | Epoch[342/600] Iteration[003/008] Valid loss: 0.1748
2023-02-06 10:52:41 | Valid | Epoch[342/600] Iteration[004/008] Valid loss: 0.1718
2023-02-06 10:52:41 | Valid | Epoch[342/600] Iteration[005/008] Valid loss: 0.1787
2023-02-06 10:52:41 | Valid | Epoch[342/600] Iteration[006/008] Valid loss: 0.1776
2023-02-06 10:52:41 | Valid | Epoch[342/600] Iteration[007/008] Valid loss: 0.1915
2023-02-06 10:52:41 | Valid | Epoch[342/600] Iteration[008/008] Valid loss: 0.1895
2023-02-06 10:52:41 | Valid | Epoch[342/600] MIou: 0.9025292235066682
2023-02-06 10:52:41 | Valid | Epoch[342/600] Pixel Accuracy: 0.9813181559244791
2023-02-06 10:52:41 | Valid | Epoch[342/600] Mean Pixel Accuracy: 0.9802146139950827
2023-02-06 10:52:41 | Stage | Epoch[342/600] Train loss:0.0267
2023-02-06 10:52:41 | Stage | Epoch[342/600] Valid loss:0.1895
2023-02-06 10:52:41 | Stage | Epoch[342/600] LR:0.01

2023-02-06 10:52:41 | Train | Epoch[343/600] Iteration[001/030] Train loss: 0.0231
2023-02-06 10:52:41 | Train | Epoch[343/600] Iteration[002/030] Train loss: 0.0251
2023-02-06 10:52:41 | Train | Epoch[343/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[005/030] Train loss: 0.0253
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[008/030] Train loss: 0.0254
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[013/030] Train loss: 0.0259
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[022/030] Train loss: 0.0258
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[024/030] Train loss: 0.0259
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[025/030] Train loss: 0.0259
2023-02-06 10:52:42 | Train | Epoch[343/600] Iteration[026/030] Train loss: 0.0261
2023-02-06 10:52:43 | Train | Epoch[343/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 10:52:43 | Train | Epoch[343/600] Iteration[028/030] Train loss: 0.0261
2023-02-06 10:52:43 | Train | Epoch[343/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:52:43 | Train | Epoch[343/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:52:43 | Valid | Epoch[343/600] Iteration[001/008] Valid loss: 0.0459
2023-02-06 10:52:43 | Valid | Epoch[343/600] Iteration[002/008] Valid loss: 0.0450
2023-02-06 10:52:43 | Valid | Epoch[343/600] Iteration[003/008] Valid loss: 0.0467
2023-02-06 10:52:43 | Valid | Epoch[343/600] Iteration[004/008] Valid loss: 0.0459
2023-02-06 10:52:43 | Valid | Epoch[343/600] Iteration[005/008] Valid loss: 0.0467
2023-02-06 10:52:43 | Valid | Epoch[343/600] Iteration[006/008] Valid loss: 0.0460
2023-02-06 10:52:43 | Valid | Epoch[343/600] Iteration[007/008] Valid loss: 0.0446
2023-02-06 10:52:43 | Valid | Epoch[343/600] Iteration[008/008] Valid loss: 0.0456
2023-02-06 10:52:43 | Valid | Epoch[343/600] MIou: 0.8336134086981335
2023-02-06 10:52:43 | Valid | Epoch[343/600] Pixel Accuracy: 0.9725824991861979
2023-02-06 10:52:43 | Valid | Epoch[343/600] Mean Pixel Accuracy: 0.8482930111392865
2023-02-06 10:52:43 | Stage | Epoch[343/600] Train loss:0.0262
2023-02-06 10:52:43 | Stage | Epoch[343/600] Valid loss:0.0456
2023-02-06 10:52:43 | Stage | Epoch[343/600] LR:0.01

2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[002/030] Train loss: 0.0241
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[006/030] Train loss: 0.0256
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[013/030] Train loss: 0.0259
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[017/030] Train loss: 0.0263
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[018/030] Train loss: 0.0263
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[019/030] Train loss: 0.0262
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:52:44 | Train | Epoch[344/600] Iteration[021/030] Train loss: 0.0260
2023-02-06 10:52:45 | Train | Epoch[344/600] Iteration[022/030] Train loss: 0.0260
2023-02-06 10:52:45 | Train | Epoch[344/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:52:45 | Train | Epoch[344/600] Iteration[024/030] Train loss: 0.0261
2023-02-06 10:52:45 | Train | Epoch[344/600] Iteration[025/030] Train loss: 0.0260
2023-02-06 10:52:45 | Train | Epoch[344/600] Iteration[026/030] Train loss: 0.0258
2023-02-06 10:52:45 | Train | Epoch[344/600] Iteration[027/030] Train loss: 0.0260
2023-02-06 10:52:45 | Train | Epoch[344/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:52:45 | Train | Epoch[344/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 10:52:45 | Train | Epoch[344/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:52:45 | Valid | Epoch[344/600] Iteration[001/008] Valid loss: 0.0630
2023-02-06 10:52:45 | Valid | Epoch[344/600] Iteration[002/008] Valid loss: 0.0481
2023-02-06 10:52:45 | Valid | Epoch[344/600] Iteration[003/008] Valid loss: 0.0457
2023-02-06 10:52:45 | Valid | Epoch[344/600] Iteration[004/008] Valid loss: 0.0431
2023-02-06 10:52:45 | Valid | Epoch[344/600] Iteration[005/008] Valid loss: 0.0438
2023-02-06 10:52:45 | Valid | Epoch[344/600] Iteration[006/008] Valid loss: 0.0434
2023-02-06 10:52:45 | Valid | Epoch[344/600] Iteration[007/008] Valid loss: 0.0462
2023-02-06 10:52:45 | Valid | Epoch[344/600] Iteration[008/008] Valid loss: 0.0455
2023-02-06 10:52:45 | Valid | Epoch[344/600] MIou: 0.9329972192741074
2023-02-06 10:52:45 | Valid | Epoch[344/600] Pixel Accuracy: 0.9883906046549479
2023-02-06 10:52:45 | Valid | Epoch[344/600] Mean Pixel Accuracy: 0.9624872660653114
2023-02-06 10:52:45 | Stage | Epoch[344/600] Train loss:0.0262
2023-02-06 10:52:45 | Stage | Epoch[344/600] Valid loss:0.0455
2023-02-06 10:52:45 | Stage | Epoch[344/600] LR:0.01

2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[001/030] Train loss: 0.0281
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[002/030] Train loss: 0.0253
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[003/030] Train loss: 0.0249
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[004/030] Train loss: 0.0258
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[007/030] Train loss: 0.0263
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[010/030] Train loss: 0.0274
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[011/030] Train loss: 0.0274
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[014/030] Train loss: 0.0275
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[015/030] Train loss: 0.0276
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[016/030] Train loss: 0.0282
2023-02-06 10:52:46 | Train | Epoch[345/600] Iteration[017/030] Train loss: 0.0283
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[018/030] Train loss: 0.0288
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[019/030] Train loss: 0.0293
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[020/030] Train loss: 0.0295
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[021/030] Train loss: 0.0297
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[022/030] Train loss: 0.0296
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[023/030] Train loss: 0.0295
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[024/030] Train loss: 0.0296
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[025/030] Train loss: 0.0296
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[026/030] Train loss: 0.0296
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[027/030] Train loss: 0.0300
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[028/030] Train loss: 0.0300
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[029/030] Train loss: 0.0303
2023-02-06 10:52:47 | Train | Epoch[345/600] Iteration[030/030] Train loss: 0.0304
2023-02-06 10:52:47 | Valid | Epoch[345/600] Iteration[001/008] Valid loss: 0.4852
2023-02-06 10:52:47 | Valid | Epoch[345/600] Iteration[002/008] Valid loss: 0.4682
2023-02-06 10:52:47 | Valid | Epoch[345/600] Iteration[003/008] Valid loss: 0.4689
2023-02-06 10:52:47 | Valid | Epoch[345/600] Iteration[004/008] Valid loss: 0.4722
2023-02-06 10:52:47 | Valid | Epoch[345/600] Iteration[005/008] Valid loss: 0.4795
2023-02-06 10:52:48 | Valid | Epoch[345/600] Iteration[006/008] Valid loss: 0.4694
2023-02-06 10:52:48 | Valid | Epoch[345/600] Iteration[007/008] Valid loss: 0.4965
2023-02-06 10:52:48 | Valid | Epoch[345/600] Iteration[008/008] Valid loss: 0.5189
2023-02-06 10:52:48 | Valid | Epoch[345/600] MIou: 0.8542647954007732
2023-02-06 10:52:48 | Valid | Epoch[345/600] Pixel Accuracy: 0.9690971374511719
2023-02-06 10:52:48 | Valid | Epoch[345/600] Mean Pixel Accuracy: 0.9768768923442599
2023-02-06 10:52:48 | Stage | Epoch[345/600] Train loss:0.0304
2023-02-06 10:52:48 | Stage | Epoch[345/600] Valid loss:0.5189
2023-02-06 10:52:48 | Stage | Epoch[345/600] LR:0.01

2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[001/030] Train loss: 0.0328
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[002/030] Train loss: 0.0290
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[003/030] Train loss: 0.0287
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[004/030] Train loss: 0.0290
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[005/030] Train loss: 0.0291
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[006/030] Train loss: 0.0293
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[007/030] Train loss: 0.0298
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[008/030] Train loss: 0.0297
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[009/030] Train loss: 0.0285
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[010/030] Train loss: 0.0287
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[011/030] Train loss: 0.0290
2023-02-06 10:52:48 | Train | Epoch[346/600] Iteration[012/030] Train loss: 0.0288
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[013/030] Train loss: 0.0286
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[014/030] Train loss: 0.0288
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[015/030] Train loss: 0.0292
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[016/030] Train loss: 0.0290
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[017/030] Train loss: 0.0291
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[018/030] Train loss: 0.0294
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[019/030] Train loss: 0.0294
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[020/030] Train loss: 0.0294
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[021/030] Train loss: 0.0292
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[022/030] Train loss: 0.0292
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[023/030] Train loss: 0.0292
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[024/030] Train loss: 0.0291
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[025/030] Train loss: 0.0289
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[026/030] Train loss: 0.0288
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[027/030] Train loss: 0.0289
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[028/030] Train loss: 0.0290
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[029/030] Train loss: 0.0289
2023-02-06 10:52:49 | Train | Epoch[346/600] Iteration[030/030] Train loss: 0.0289
2023-02-06 10:52:50 | Valid | Epoch[346/600] Iteration[001/008] Valid loss: 0.1112
2023-02-06 10:52:50 | Valid | Epoch[346/600] Iteration[002/008] Valid loss: 0.1119
2023-02-06 10:52:50 | Valid | Epoch[346/600] Iteration[003/008] Valid loss: 0.1168
2023-02-06 10:52:50 | Valid | Epoch[346/600] Iteration[004/008] Valid loss: 0.1165
2023-02-06 10:52:50 | Valid | Epoch[346/600] Iteration[005/008] Valid loss: 0.1194
2023-02-06 10:52:50 | Valid | Epoch[346/600] Iteration[006/008] Valid loss: 0.1170
2023-02-06 10:52:50 | Valid | Epoch[346/600] Iteration[007/008] Valid loss: 0.1145
2023-02-06 10:52:50 | Valid | Epoch[346/600] Iteration[008/008] Valid loss: 0.1186
2023-02-06 10:52:50 | Valid | Epoch[346/600] MIou: 0.6024470712898079
2023-02-06 10:52:50 | Valid | Epoch[346/600] Pixel Accuracy: 0.9342549641927084
2023-02-06 10:52:50 | Valid | Epoch[346/600] Mean Pixel Accuracy: 0.6361754756750438
2023-02-06 10:52:50 | Stage | Epoch[346/600] Train loss:0.0289
2023-02-06 10:52:50 | Stage | Epoch[346/600] Valid loss:0.1186
2023-02-06 10:52:50 | Stage | Epoch[346/600] LR:0.01

2023-02-06 10:52:50 | Train | Epoch[347/600] Iteration[001/030] Train loss: 0.0260
2023-02-06 10:52:50 | Train | Epoch[347/600] Iteration[002/030] Train loss: 0.0253
2023-02-06 10:52:50 | Train | Epoch[347/600] Iteration[003/030] Train loss: 0.0265
2023-02-06 10:52:50 | Train | Epoch[347/600] Iteration[004/030] Train loss: 0.0262
2023-02-06 10:52:50 | Train | Epoch[347/600] Iteration[005/030] Train loss: 0.0264
2023-02-06 10:52:50 | Train | Epoch[347/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 10:52:50 | Train | Epoch[347/600] Iteration[007/030] Train loss: 0.0270
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[012/030] Train loss: 0.0268
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[015/030] Train loss: 0.0272
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[016/030] Train loss: 0.0272
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[017/030] Train loss: 0.0271
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[018/030] Train loss: 0.0272
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[019/030] Train loss: 0.0269
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[020/030] Train loss: 0.0270
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[021/030] Train loss: 0.0268
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[022/030] Train loss: 0.0269
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[024/030] Train loss: 0.0271
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[025/030] Train loss: 0.0272
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[026/030] Train loss: 0.0272
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[027/030] Train loss: 0.0273
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[028/030] Train loss: 0.0274
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[029/030] Train loss: 0.0275
2023-02-06 10:52:51 | Train | Epoch[347/600] Iteration[030/030] Train loss: 0.0274
2023-02-06 10:52:52 | Valid | Epoch[347/600] Iteration[001/008] Valid loss: 0.3060
2023-02-06 10:52:52 | Valid | Epoch[347/600] Iteration[002/008] Valid loss: 0.3015
2023-02-06 10:52:52 | Valid | Epoch[347/600] Iteration[003/008] Valid loss: 0.3132
2023-02-06 10:52:52 | Valid | Epoch[347/600] Iteration[004/008] Valid loss: 0.3167
2023-02-06 10:52:52 | Valid | Epoch[347/600] Iteration[005/008] Valid loss: 0.3243
2023-02-06 10:52:52 | Valid | Epoch[347/600] Iteration[006/008] Valid loss: 0.3215
2023-02-06 10:52:52 | Valid | Epoch[347/600] Iteration[007/008] Valid loss: 0.3205
2023-02-06 10:52:52 | Valid | Epoch[347/600] Iteration[008/008] Valid loss: 0.3282
2023-02-06 10:52:52 | Valid | Epoch[347/600] MIou: 0.4548866844440918
2023-02-06 10:52:52 | Valid | Epoch[347/600] Pixel Accuracy: 0.9096895853678385
2023-02-06 10:52:52 | Valid | Epoch[347/600] Mean Pixel Accuracy: 0.5000422362696927
2023-02-06 10:52:52 | Stage | Epoch[347/600] Train loss:0.0274
2023-02-06 10:52:52 | Stage | Epoch[347/600] Valid loss:0.3282
2023-02-06 10:52:52 | Stage | Epoch[347/600] LR:0.01

2023-02-06 10:52:52 | Train | Epoch[348/600] Iteration[001/030] Train loss: 0.0243
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[005/030] Train loss: 0.0258
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[016/030] Train loss: 0.0259
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[017/030] Train loss: 0.0259
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[019/030] Train loss: 0.0260
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[022/030] Train loss: 0.0258
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[023/030] Train loss: 0.0261
2023-02-06 10:52:53 | Train | Epoch[348/600] Iteration[024/030] Train loss: 0.0263
2023-02-06 10:52:54 | Train | Epoch[348/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 10:52:54 | Train | Epoch[348/600] Iteration[026/030] Train loss: 0.0266
2023-02-06 10:52:54 | Train | Epoch[348/600] Iteration[027/030] Train loss: 0.0269
2023-02-06 10:52:54 | Train | Epoch[348/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:52:54 | Train | Epoch[348/600] Iteration[029/030] Train loss: 0.0270
2023-02-06 10:52:54 | Train | Epoch[348/600] Iteration[030/030] Train loss: 0.0271
2023-02-06 10:52:54 | Valid | Epoch[348/600] Iteration[001/008] Valid loss: 0.0350
2023-02-06 10:52:54 | Valid | Epoch[348/600] Iteration[002/008] Valid loss: 0.0314
2023-02-06 10:52:54 | Valid | Epoch[348/600] Iteration[003/008] Valid loss: 0.0308
2023-02-06 10:52:54 | Valid | Epoch[348/600] Iteration[004/008] Valid loss: 0.0299
2023-02-06 10:52:54 | Valid | Epoch[348/600] Iteration[005/008] Valid loss: 0.0305
2023-02-06 10:52:54 | Valid | Epoch[348/600] Iteration[006/008] Valid loss: 0.0308
2023-02-06 10:52:54 | Valid | Epoch[348/600] Iteration[007/008] Valid loss: 0.0308
2023-02-06 10:52:54 | Valid | Epoch[348/600] Iteration[008/008] Valid loss: 0.0306
2023-02-06 10:52:54 | Valid | Epoch[348/600] MIou: 0.9154170570851016
2023-02-06 10:52:54 | Valid | Epoch[348/600] Pixel Accuracy: 0.9859212239583334
2023-02-06 10:52:54 | Valid | Epoch[348/600] Mean Pixel Accuracy: 0.9278361732079814
2023-02-06 10:52:54 | Stage | Epoch[348/600] Train loss:0.0271
2023-02-06 10:52:54 | Stage | Epoch[348/600] Valid loss:0.0306
2023-02-06 10:52:54 | Stage | Epoch[348/600] LR:0.01

2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[002/030] Train loss: 0.0274
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[004/030] Train loss: 0.0241
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[005/030] Train loss: 0.0245
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[007/030] Train loss: 0.0259
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[010/030] Train loss: 0.0264
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[011/030] Train loss: 0.0263
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[015/030] Train loss: 0.0264
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[018/030] Train loss: 0.0266
2023-02-06 10:52:55 | Train | Epoch[349/600] Iteration[019/030] Train loss: 0.0265
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[020/030] Train loss: 0.0264
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[021/030] Train loss: 0.0264
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[022/030] Train loss: 0.0265
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[025/030] Train loss: 0.0265
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[028/030] Train loss: 0.0264
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[029/030] Train loss: 0.0265
2023-02-06 10:52:56 | Train | Epoch[349/600] Iteration[030/030] Train loss: 0.0265
2023-02-06 10:52:56 | Valid | Epoch[349/600] Iteration[001/008] Valid loss: 0.0368
2023-02-06 10:52:56 | Valid | Epoch[349/600] Iteration[002/008] Valid loss: 0.0325
2023-02-06 10:52:56 | Valid | Epoch[349/600] Iteration[003/008] Valid loss: 0.0326
2023-02-06 10:52:56 | Valid | Epoch[349/600] Iteration[004/008] Valid loss: 0.0314
2023-02-06 10:52:56 | Valid | Epoch[349/600] Iteration[005/008] Valid loss: 0.0320
2023-02-06 10:52:56 | Valid | Epoch[349/600] Iteration[006/008] Valid loss: 0.0316
2023-02-06 10:52:56 | Valid | Epoch[349/600] Iteration[007/008] Valid loss: 0.0315
2023-02-06 10:52:56 | Valid | Epoch[349/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 10:52:57 | Valid | Epoch[349/600] MIou: 0.90339826286301
2023-02-06 10:52:57 | Valid | Epoch[349/600] Pixel Accuracy: 0.9840049743652344
2023-02-06 10:52:57 | Valid | Epoch[349/600] Mean Pixel Accuracy: 0.9144824059721108
2023-02-06 10:52:57 | Stage | Epoch[349/600] Train loss:0.0265
2023-02-06 10:52:57 | Stage | Epoch[349/600] Valid loss:0.0316
2023-02-06 10:52:57 | Stage | Epoch[349/600] LR:0.01

2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[002/030] Train loss: 0.0253
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[003/030] Train loss: 0.0258
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[004/030] Train loss: 0.0269
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[005/030] Train loss: 0.0263
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[006/030] Train loss: 0.0266
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[007/030] Train loss: 0.0261
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[008/030] Train loss: 0.0254
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:52:57 | Train | Epoch[350/600] Iteration[015/030] Train loss: 0.0263
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[017/030] Train loss: 0.0262
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[018/030] Train loss: 0.0261
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[019/030] Train loss: 0.0264
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[020/030] Train loss: 0.0263
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[021/030] Train loss: 0.0264
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[023/030] Train loss: 0.0263
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[024/030] Train loss: 0.0262
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[025/030] Train loss: 0.0262
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[027/030] Train loss: 0.0265
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[028/030] Train loss: 0.0266
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[029/030] Train loss: 0.0264
2023-02-06 10:52:58 | Train | Epoch[350/600] Iteration[030/030] Train loss: 0.0264
2023-02-06 10:52:58 | Valid | Epoch[350/600] Iteration[001/008] Valid loss: 0.0651
2023-02-06 10:52:59 | Valid | Epoch[350/600] Iteration[002/008] Valid loss: 0.0515
2023-02-06 10:52:59 | Valid | Epoch[350/600] Iteration[003/008] Valid loss: 0.0489
2023-02-06 10:52:59 | Valid | Epoch[350/600] Iteration[004/008] Valid loss: 0.0470
2023-02-06 10:52:59 | Valid | Epoch[350/600] Iteration[005/008] Valid loss: 0.0488
2023-02-06 10:52:59 | Valid | Epoch[350/600] Iteration[006/008] Valid loss: 0.0485
2023-02-06 10:52:59 | Valid | Epoch[350/600] Iteration[007/008] Valid loss: 0.0511
2023-02-06 10:52:59 | Valid | Epoch[350/600] Iteration[008/008] Valid loss: 0.0508
2023-02-06 10:52:59 | Valid | Epoch[350/600] MIou: 0.931992628513414
2023-02-06 10:52:59 | Valid | Epoch[350/600] Pixel Accuracy: 0.9879353841145834
2023-02-06 10:52:59 | Valid | Epoch[350/600] Mean Pixel Accuracy: 0.97269249496506
2023-02-06 10:52:59 | Stage | Epoch[350/600] Train loss:0.0264
2023-02-06 10:52:59 | Stage | Epoch[350/600] Valid loss:0.0508
2023-02-06 10:52:59 | Stage | Epoch[350/600] LR:0.01

2023-02-06 10:52:59 | Train | Epoch[351/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 10:52:59 | Train | Epoch[351/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 10:52:59 | Train | Epoch[351/600] Iteration[003/030] Train loss: 0.0272
2023-02-06 10:52:59 | Train | Epoch[351/600] Iteration[004/030] Train loss: 0.0277
2023-02-06 10:52:59 | Train | Epoch[351/600] Iteration[005/030] Train loss: 0.0280
2023-02-06 10:52:59 | Train | Epoch[351/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 10:52:59 | Train | Epoch[351/600] Iteration[007/030] Train loss: 0.0268
2023-02-06 10:52:59 | Train | Epoch[351/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 10:52:59 | Train | Epoch[351/600] Iteration[009/030] Train loss: 0.0272
2023-02-06 10:52:59 | Train | Epoch[351/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[012/030] Train loss: 0.0272
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[016/030] Train loss: 0.0267
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[018/030] Train loss: 0.0264
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[019/030] Train loss: 0.0263
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[021/030] Train loss: 0.0261
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[022/030] Train loss: 0.0262
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[023/030] Train loss: 0.0261
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[025/030] Train loss: 0.0262
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[026/030] Train loss: 0.0261
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[029/030] Train loss: 0.0261
2023-02-06 10:53:00 | Train | Epoch[351/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:53:01 | Valid | Epoch[351/600] Iteration[001/008] Valid loss: 0.0361
2023-02-06 10:53:01 | Valid | Epoch[351/600] Iteration[002/008] Valid loss: 0.0335
2023-02-06 10:53:01 | Valid | Epoch[351/600] Iteration[003/008] Valid loss: 0.0334
2023-02-06 10:53:01 | Valid | Epoch[351/600] Iteration[004/008] Valid loss: 0.0324
2023-02-06 10:53:01 | Valid | Epoch[351/600] Iteration[005/008] Valid loss: 0.0329
2023-02-06 10:53:01 | Valid | Epoch[351/600] Iteration[006/008] Valid loss: 0.0324
2023-02-06 10:53:01 | Valid | Epoch[351/600] Iteration[007/008] Valid loss: 0.0320
2023-02-06 10:53:01 | Valid | Epoch[351/600] Iteration[008/008] Valid loss: 0.0322
2023-02-06 10:53:01 | Valid | Epoch[351/600] MIou: 0.896850099624113
2023-02-06 10:53:01 | Valid | Epoch[351/600] Pixel Accuracy: 0.9829126993815104
2023-02-06 10:53:01 | Valid | Epoch[351/600] Mean Pixel Accuracy: 0.9086194537016286
2023-02-06 10:53:01 | Stage | Epoch[351/600] Train loss:0.0263
2023-02-06 10:53:01 | Stage | Epoch[351/600] Valid loss:0.0322
2023-02-06 10:53:01 | Stage | Epoch[351/600] LR:0.01

2023-02-06 10:53:01 | Train | Epoch[352/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 10:53:01 | Train | Epoch[352/600] Iteration[002/030] Train loss: 0.0283
2023-02-06 10:53:01 | Train | Epoch[352/600] Iteration[003/030] Train loss: 0.0274
2023-02-06 10:53:01 | Train | Epoch[352/600] Iteration[004/030] Train loss: 0.0286
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[005/030] Train loss: 0.0277
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[006/030] Train loss: 0.0271
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[008/030] Train loss: 0.0268
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[009/030] Train loss: 0.0266
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[010/030] Train loss: 0.0266
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[011/030] Train loss: 0.0268
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[014/030] Train loss: 0.0261
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[015/030] Train loss: 0.0260
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[018/030] Train loss: 0.0259
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[020/030] Train loss: 0.0256
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[023/030] Train loss: 0.0258
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[026/030] Train loss: 0.0257
2023-02-06 10:53:02 | Train | Epoch[352/600] Iteration[027/030] Train loss: 0.0260
2023-02-06 10:53:03 | Train | Epoch[352/600] Iteration[028/030] Train loss: 0.0259
2023-02-06 10:53:03 | Train | Epoch[352/600] Iteration[029/030] Train loss: 0.0260
2023-02-06 10:53:03 | Train | Epoch[352/600] Iteration[030/030] Train loss: 0.0259
2023-02-06 10:53:03 | Valid | Epoch[352/600] Iteration[001/008] Valid loss: 0.0669
2023-02-06 10:53:03 | Valid | Epoch[352/600] Iteration[002/008] Valid loss: 0.0509
2023-02-06 10:53:03 | Valid | Epoch[352/600] Iteration[003/008] Valid loss: 0.0475
2023-02-06 10:53:03 | Valid | Epoch[352/600] Iteration[004/008] Valid loss: 0.0455
2023-02-06 10:53:03 | Valid | Epoch[352/600] Iteration[005/008] Valid loss: 0.0470
2023-02-06 10:53:03 | Valid | Epoch[352/600] Iteration[006/008] Valid loss: 0.0467
2023-02-06 10:53:03 | Valid | Epoch[352/600] Iteration[007/008] Valid loss: 0.0494
2023-02-06 10:53:03 | Valid | Epoch[352/600] Iteration[008/008] Valid loss: 0.0486
2023-02-06 10:53:03 | Valid | Epoch[352/600] MIou: 0.9355798325245959
2023-02-06 10:53:03 | Valid | Epoch[352/600] Pixel Accuracy: 0.9887669881184896
2023-02-06 10:53:03 | Valid | Epoch[352/600] Mean Pixel Accuracy: 0.967988436181827
2023-02-06 10:53:03 | Stage | Epoch[352/600] Train loss:0.0259
2023-02-06 10:53:03 | Stage | Epoch[352/600] Valid loss:0.0486
2023-02-06 10:53:03 | Stage | Epoch[352/600] LR:0.01

2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[001/030] Train loss: 0.0228
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[008/030] Train loss: 0.0254
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:53:04 | Train | Epoch[353/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:53:05 | Train | Epoch[353/600] Iteration[023/030] Train loss: 0.0259
2023-02-06 10:53:05 | Train | Epoch[353/600] Iteration[024/030] Train loss: 0.0260
2023-02-06 10:53:05 | Train | Epoch[353/600] Iteration[025/030] Train loss: 0.0260
2023-02-06 10:53:05 | Train | Epoch[353/600] Iteration[026/030] Train loss: 0.0260
2023-02-06 10:53:05 | Train | Epoch[353/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:53:05 | Train | Epoch[353/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 10:53:05 | Train | Epoch[353/600] Iteration[029/030] Train loss: 0.0265
2023-02-06 10:53:05 | Train | Epoch[353/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:53:05 | Valid | Epoch[353/600] Iteration[001/008] Valid loss: 0.1272
2023-02-06 10:53:05 | Valid | Epoch[353/600] Iteration[002/008] Valid loss: 0.1308
2023-02-06 10:53:05 | Valid | Epoch[353/600] Iteration[003/008] Valid loss: 0.1369
2023-02-06 10:53:05 | Valid | Epoch[353/600] Iteration[004/008] Valid loss: 0.1372
2023-02-06 10:53:05 | Valid | Epoch[353/600] Iteration[005/008] Valid loss: 0.1410
2023-02-06 10:53:05 | Valid | Epoch[353/600] Iteration[006/008] Valid loss: 0.1377
2023-02-06 10:53:05 | Valid | Epoch[353/600] Iteration[007/008] Valid loss: 0.1343
2023-02-06 10:53:05 | Valid | Epoch[353/600] Iteration[008/008] Valid loss: 0.1396
2023-02-06 10:53:05 | Valid | Epoch[353/600] MIou: 0.5513918086483492
2023-02-06 10:53:05 | Valid | Epoch[353/600] Pixel Accuracy: 0.9257774353027344
2023-02-06 10:53:05 | Valid | Epoch[353/600] Mean Pixel Accuracy: 0.589110790766462
2023-02-06 10:53:05 | Stage | Epoch[353/600] Train loss:0.0263
2023-02-06 10:53:05 | Stage | Epoch[353/600] Valid loss:0.1396
2023-02-06 10:53:05 | Stage | Epoch[353/600] LR:0.01

2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[001/030] Train loss: 0.0266
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[002/030] Train loss: 0.0272
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[003/030] Train loss: 0.0290
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[004/030] Train loss: 0.0275
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[008/030] Train loss: 0.0268
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[009/030] Train loss: 0.0266
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[012/030] Train loss: 0.0269
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[013/030] Train loss: 0.0265
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[015/030] Train loss: 0.0263
2023-02-06 10:53:06 | Train | Epoch[354/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[017/030] Train loss: 0.0263
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[019/030] Train loss: 0.0263
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[021/030] Train loss: 0.0261
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[022/030] Train loss: 0.0260
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[024/030] Train loss: 0.0262
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[025/030] Train loss: 0.0262
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[026/030] Train loss: 0.0264
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[028/030] Train loss: 0.0264
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 10:53:07 | Train | Epoch[354/600] Iteration[030/030] Train loss: 0.0266
2023-02-06 10:53:07 | Valid | Epoch[354/600] Iteration[001/008] Valid loss: 0.1118
2023-02-06 10:53:07 | Valid | Epoch[354/600] Iteration[002/008] Valid loss: 0.1081
2023-02-06 10:53:07 | Valid | Epoch[354/600] Iteration[003/008] Valid loss: 0.1113
2023-02-06 10:53:08 | Valid | Epoch[354/600] Iteration[004/008] Valid loss: 0.1107
2023-02-06 10:53:08 | Valid | Epoch[354/600] Iteration[005/008] Valid loss: 0.1128
2023-02-06 10:53:08 | Valid | Epoch[354/600] Iteration[006/008] Valid loss: 0.1109
2023-02-06 10:53:08 | Valid | Epoch[354/600] Iteration[007/008] Valid loss: 0.1081
2023-02-06 10:53:08 | Valid | Epoch[354/600] Iteration[008/008] Valid loss: 0.1105
2023-02-06 10:53:08 | Valid | Epoch[354/600] MIou: 0.6959585989958839
2023-02-06 10:53:08 | Valid | Epoch[354/600] Pixel Accuracy: 0.9498023986816406
2023-02-06 10:53:08 | Valid | Epoch[354/600] Mean Pixel Accuracy: 0.7221064635571386
2023-02-06 10:53:08 | Stage | Epoch[354/600] Train loss:0.0266
2023-02-06 10:53:08 | Stage | Epoch[354/600] Valid loss:0.1105
2023-02-06 10:53:08 | Stage | Epoch[354/600] LR:0.01

2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[002/030] Train loss: 0.0236
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[003/030] Train loss: 0.0240
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[004/030] Train loss: 0.0245
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[005/030] Train loss: 0.0240
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:53:08 | Train | Epoch[355/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[013/030] Train loss: 0.0260
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[015/030] Train loss: 0.0258
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[016/030] Train loss: 0.0261
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[017/030] Train loss: 0.0263
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[018/030] Train loss: 0.0262
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[019/030] Train loss: 0.0262
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[021/030] Train loss: 0.0262
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[022/030] Train loss: 0.0262
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[023/030] Train loss: 0.0261
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[024/030] Train loss: 0.0262
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[025/030] Train loss: 0.0262
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:53:09 | Train | Epoch[355/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:53:10 | Valid | Epoch[355/600] Iteration[001/008] Valid loss: 0.0410
2023-02-06 10:53:10 | Valid | Epoch[355/600] Iteration[002/008] Valid loss: 0.0414
2023-02-06 10:53:10 | Valid | Epoch[355/600] Iteration[003/008] Valid loss: 0.0426
2023-02-06 10:53:10 | Valid | Epoch[355/600] Iteration[004/008] Valid loss: 0.0419
2023-02-06 10:53:10 | Valid | Epoch[355/600] Iteration[005/008] Valid loss: 0.0426
2023-02-06 10:53:10 | Valid | Epoch[355/600] Iteration[006/008] Valid loss: 0.0421
2023-02-06 10:53:10 | Valid | Epoch[355/600] Iteration[007/008] Valid loss: 0.0411
2023-02-06 10:53:10 | Valid | Epoch[355/600] Iteration[008/008] Valid loss: 0.0419
2023-02-06 10:53:10 | Valid | Epoch[355/600] MIou: 0.839018482542003
2023-02-06 10:53:10 | Valid | Epoch[355/600] Pixel Accuracy: 0.9734713236490885
2023-02-06 10:53:10 | Valid | Epoch[355/600] Mean Pixel Accuracy: 0.8532896222166264
2023-02-06 10:53:10 | Stage | Epoch[355/600] Train loss:0.0263
2023-02-06 10:53:10 | Stage | Epoch[355/600] Valid loss:0.0419
2023-02-06 10:53:10 | Stage | Epoch[355/600] LR:0.01

2023-02-06 10:53:10 | Train | Epoch[356/600] Iteration[001/030] Train loss: 0.0275
2023-02-06 10:53:10 | Train | Epoch[356/600] Iteration[002/030] Train loss: 0.0281
2023-02-06 10:53:10 | Train | Epoch[356/600] Iteration[003/030] Train loss: 0.0286
2023-02-06 10:53:10 | Train | Epoch[356/600] Iteration[004/030] Train loss: 0.0283
2023-02-06 10:53:10 | Train | Epoch[356/600] Iteration[005/030] Train loss: 0.0281
2023-02-06 10:53:10 | Train | Epoch[356/600] Iteration[006/030] Train loss: 0.0276
2023-02-06 10:53:10 | Train | Epoch[356/600] Iteration[007/030] Train loss: 0.0277
2023-02-06 10:53:10 | Train | Epoch[356/600] Iteration[008/030] Train loss: 0.0277
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[009/030] Train loss: 0.0274
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[014/030] Train loss: 0.0261
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[015/030] Train loss: 0.0264
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[018/030] Train loss: 0.0266
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[020/030] Train loss: 0.0265
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[021/030] Train loss: 0.0265
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[022/030] Train loss: 0.0266
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[024/030] Train loss: 0.0263
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[025/030] Train loss: 0.0262
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:53:11 | Train | Epoch[356/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:53:12 | Valid | Epoch[356/600] Iteration[001/008] Valid loss: 0.0363
2023-02-06 10:53:12 | Valid | Epoch[356/600] Iteration[002/008] Valid loss: 0.0322
2023-02-06 10:53:12 | Valid | Epoch[356/600] Iteration[003/008] Valid loss: 0.0312
2023-02-06 10:53:12 | Valid | Epoch[356/600] Iteration[004/008] Valid loss: 0.0301
2023-02-06 10:53:12 | Valid | Epoch[356/600] Iteration[005/008] Valid loss: 0.0308
2023-02-06 10:53:12 | Valid | Epoch[356/600] Iteration[006/008] Valid loss: 0.0304
2023-02-06 10:53:12 | Valid | Epoch[356/600] Iteration[007/008] Valid loss: 0.0306
2023-02-06 10:53:12 | Valid | Epoch[356/600] Iteration[008/008] Valid loss: 0.0305
2023-02-06 10:53:12 | Valid | Epoch[356/600] MIou: 0.9185810462432549
2023-02-06 10:53:12 | Valid | Epoch[356/600] Pixel Accuracy: 0.9864120483398438
2023-02-06 10:53:12 | Valid | Epoch[356/600] Mean Pixel Accuracy: 0.9319165745999731
2023-02-06 10:53:12 | Stage | Epoch[356/600] Train loss:0.0263
2023-02-06 10:53:12 | Stage | Epoch[356/600] Valid loss:0.0305
2023-02-06 10:53:12 | Stage | Epoch[356/600] LR:0.01

2023-02-06 10:53:12 | Train | Epoch[357/600] Iteration[001/030] Train loss: 0.0247
2023-02-06 10:53:12 | Train | Epoch[357/600] Iteration[002/030] Train loss: 0.0229
2023-02-06 10:53:12 | Train | Epoch[357/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 10:53:12 | Train | Epoch[357/600] Iteration[004/030] Train loss: 0.0225
2023-02-06 10:53:12 | Train | Epoch[357/600] Iteration[005/030] Train loss: 0.0238
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[006/030] Train loss: 0.0241
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[008/030] Train loss: 0.0251
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[021/030] Train loss: 0.0260
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[022/030] Train loss: 0.0260
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[024/030] Train loss: 0.0262
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[025/030] Train loss: 0.0261
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[026/030] Train loss: 0.0260
2023-02-06 10:53:13 | Train | Epoch[357/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 10:53:14 | Train | Epoch[357/600] Iteration[028/030] Train loss: 0.0261
2023-02-06 10:53:14 | Train | Epoch[357/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 10:53:14 | Train | Epoch[357/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:53:14 | Valid | Epoch[357/600] Iteration[001/008] Valid loss: 0.1265
2023-02-06 10:53:14 | Valid | Epoch[357/600] Iteration[002/008] Valid loss: 0.1301
2023-02-06 10:53:14 | Valid | Epoch[357/600] Iteration[003/008] Valid loss: 0.1363
2023-02-06 10:53:14 | Valid | Epoch[357/600] Iteration[004/008] Valid loss: 0.1359
2023-02-06 10:53:14 | Valid | Epoch[357/600] Iteration[005/008] Valid loss: 0.1398
2023-02-06 10:53:14 | Valid | Epoch[357/600] Iteration[006/008] Valid loss: 0.1368
2023-02-06 10:53:14 | Valid | Epoch[357/600] Iteration[007/008] Valid loss: 0.1335
2023-02-06 10:53:14 | Valid | Epoch[357/600] Iteration[008/008] Valid loss: 0.1388
2023-02-06 10:53:14 | Valid | Epoch[357/600] MIou: 0.551080601180512
2023-02-06 10:53:14 | Valid | Epoch[357/600] Pixel Accuracy: 0.925726572672526
2023-02-06 10:53:14 | Valid | Epoch[357/600] Mean Pixel Accuracy: 0.5888228751636655
2023-02-06 10:53:14 | Stage | Epoch[357/600] Train loss:0.0262
2023-02-06 10:53:14 | Stage | Epoch[357/600] Valid loss:0.1388
2023-02-06 10:53:14 | Stage | Epoch[357/600] LR:0.01

2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[001/030] Train loss: 0.0257
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[004/030] Train loss: 0.0273
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[005/030] Train loss: 0.0271
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[013/030] Train loss: 0.0258
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[014/030] Train loss: 0.0259
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[017/030] Train loss: 0.0273
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[019/030] Train loss: 0.0270
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[020/030] Train loss: 0.0273
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[021/030] Train loss: 0.0274
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[022/030] Train loss: 0.0275
2023-02-06 10:53:15 | Train | Epoch[358/600] Iteration[023/030] Train loss: 0.0276
2023-02-06 10:53:16 | Train | Epoch[358/600] Iteration[024/030] Train loss: 0.0276
2023-02-06 10:53:16 | Train | Epoch[358/600] Iteration[025/030] Train loss: 0.0274
2023-02-06 10:53:16 | Train | Epoch[358/600] Iteration[026/030] Train loss: 0.0272
2023-02-06 10:53:16 | Train | Epoch[358/600] Iteration[027/030] Train loss: 0.0272
2023-02-06 10:53:16 | Train | Epoch[358/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 10:53:16 | Train | Epoch[358/600] Iteration[029/030] Train loss: 0.0271
2023-02-06 10:53:16 | Train | Epoch[358/600] Iteration[030/030] Train loss: 0.0272
2023-02-06 10:53:16 | Valid | Epoch[358/600] Iteration[001/008] Valid loss: 0.0398
2023-02-06 10:53:16 | Valid | Epoch[358/600] Iteration[002/008] Valid loss: 0.0336
2023-02-06 10:53:16 | Valid | Epoch[358/600] Iteration[003/008] Valid loss: 0.0318
2023-02-06 10:53:16 | Valid | Epoch[358/600] Iteration[004/008] Valid loss: 0.0309
2023-02-06 10:53:16 | Valid | Epoch[358/600] Iteration[005/008] Valid loss: 0.0314
2023-02-06 10:53:16 | Valid | Epoch[358/600] Iteration[006/008] Valid loss: 0.0313
2023-02-06 10:53:16 | Valid | Epoch[358/600] Iteration[007/008] Valid loss: 0.0320
2023-02-06 10:53:16 | Valid | Epoch[358/600] Iteration[008/008] Valid loss: 0.0315
2023-02-06 10:53:17 | Valid | Epoch[358/600] MIou: 0.9317916333130891
2023-02-06 10:53:17 | Valid | Epoch[358/600] Pixel Accuracy: 0.9885330200195312
2023-02-06 10:53:17 | Valid | Epoch[358/600] Mean Pixel Accuracy: 0.9475069237823652
2023-02-06 10:53:17 | Stage | Epoch[358/600] Train loss:0.0272
2023-02-06 10:53:17 | Stage | Epoch[358/600] Valid loss:0.0315
2023-02-06 10:53:17 | Stage | Epoch[358/600] LR:0.01

2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[003/030] Train loss: 0.0267
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[004/030] Train loss: 0.0257
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[013/030] Train loss: 0.0260
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 10:53:17 | Train | Epoch[359/600] Iteration[016/030] Train loss: 0.0260
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[022/030] Train loss: 0.0260
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[023/030] Train loss: 0.0259
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[024/030] Train loss: 0.0260
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[025/030] Train loss: 0.0258
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[026/030] Train loss: 0.0259
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[027/030] Train loss: 0.0259
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[028/030] Train loss: 0.0259
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[029/030] Train loss: 0.0260
2023-02-06 10:53:18 | Train | Epoch[359/600] Iteration[030/030] Train loss: 0.0259
2023-02-06 10:53:18 | Valid | Epoch[359/600] Iteration[001/008] Valid loss: 0.0363
2023-02-06 10:53:18 | Valid | Epoch[359/600] Iteration[002/008] Valid loss: 0.0343
2023-02-06 10:53:18 | Valid | Epoch[359/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 10:53:18 | Valid | Epoch[359/600] Iteration[004/008] Valid loss: 0.0337
2023-02-06 10:53:19 | Valid | Epoch[359/600] Iteration[005/008] Valid loss: 0.0344
2023-02-06 10:53:19 | Valid | Epoch[359/600] Iteration[006/008] Valid loss: 0.0339
2023-02-06 10:53:19 | Valid | Epoch[359/600] Iteration[007/008] Valid loss: 0.0333
2023-02-06 10:53:19 | Valid | Epoch[359/600] Iteration[008/008] Valid loss: 0.0337
2023-02-06 10:53:19 | Valid | Epoch[359/600] MIou: 0.8835225911467086
2023-02-06 10:53:19 | Valid | Epoch[359/600] Pixel Accuracy: 0.9807815551757812
2023-02-06 10:53:19 | Valid | Epoch[359/600] Mean Pixel Accuracy: 0.8947227596303136
2023-02-06 10:53:19 | Stage | Epoch[359/600] Train loss:0.0259
2023-02-06 10:53:19 | Stage | Epoch[359/600] Valid loss:0.0337
2023-02-06 10:53:19 | Stage | Epoch[359/600] LR:0.01

2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[001/030] Train loss: 0.0336
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[002/030] Train loss: 0.0320
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[003/030] Train loss: 0.0297
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[004/030] Train loss: 0.0294
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[005/030] Train loss: 0.0297
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[006/030] Train loss: 0.0283
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[007/030] Train loss: 0.0276
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[008/030] Train loss: 0.0282
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[009/030] Train loss: 0.0283
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[010/030] Train loss: 0.0278
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[011/030] Train loss: 0.0280
2023-02-06 10:53:19 | Train | Epoch[360/600] Iteration[012/030] Train loss: 0.0276
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[014/030] Train loss: 0.0272
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[015/030] Train loss: 0.0272
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[016/030] Train loss: 0.0270
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[019/030] Train loss: 0.0264
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[022/030] Train loss: 0.0258
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[023/030] Train loss: 0.0259
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[024/030] Train loss: 0.0259
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[025/030] Train loss: 0.0260
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[026/030] Train loss: 0.0258
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[027/030] Train loss: 0.0260
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[028/030] Train loss: 0.0259
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[029/030] Train loss: 0.0260
2023-02-06 10:53:20 | Train | Epoch[360/600] Iteration[030/030] Train loss: 0.0260
2023-02-06 10:53:21 | Valid | Epoch[360/600] Iteration[001/008] Valid loss: 0.1326
2023-02-06 10:53:21 | Valid | Epoch[360/600] Iteration[002/008] Valid loss: 0.1068
2023-02-06 10:53:21 | Valid | Epoch[360/600] Iteration[003/008] Valid loss: 0.0966
2023-02-06 10:53:21 | Valid | Epoch[360/600] Iteration[004/008] Valid loss: 0.0937
2023-02-06 10:53:21 | Valid | Epoch[360/600] Iteration[005/008] Valid loss: 0.0972
2023-02-06 10:53:21 | Valid | Epoch[360/600] Iteration[006/008] Valid loss: 0.0992
2023-02-06 10:53:21 | Valid | Epoch[360/600] Iteration[007/008] Valid loss: 0.1058
2023-02-06 10:53:21 | Valid | Epoch[360/600] Iteration[008/008] Valid loss: 0.1038
2023-02-06 10:53:21 | Valid | Epoch[360/600] MIou: 0.9187607314453229
2023-02-06 10:53:21 | Valid | Epoch[360/600] Pixel Accuracy: 0.984978993733724
2023-02-06 10:53:21 | Valid | Epoch[360/600] Mean Pixel Accuracy: 0.9794623210067332
2023-02-06 10:53:21 | Stage | Epoch[360/600] Train loss:0.0260
2023-02-06 10:53:21 | Stage | Epoch[360/600] Valid loss:0.1038
2023-02-06 10:53:21 | Stage | Epoch[360/600] LR:0.01

2023-02-06 10:53:21 | Train | Epoch[361/600] Iteration[001/030] Train loss: 0.0293
2023-02-06 10:53:21 | Train | Epoch[361/600] Iteration[002/030] Train loss: 0.0282
2023-02-06 10:53:21 | Train | Epoch[361/600] Iteration[003/030] Train loss: 0.0282
2023-02-06 10:53:21 | Train | Epoch[361/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 10:53:21 | Train | Epoch[361/600] Iteration[005/030] Train loss: 0.0268
2023-02-06 10:53:21 | Train | Epoch[361/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 10:53:21 | Train | Epoch[361/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 10:53:21 | Train | Epoch[361/600] Iteration[008/030] Train loss: 0.0267
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[012/030] Train loss: 0.0270
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[013/030] Train loss: 0.0270
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[016/030] Train loss: 0.0268
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[018/030] Train loss: 0.0271
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[019/030] Train loss: 0.0271
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[020/030] Train loss: 0.0269
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[021/030] Train loss: 0.0268
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[022/030] Train loss: 0.0268
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[023/030] Train loss: 0.0266
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[024/030] Train loss: 0.0268
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[026/030] Train loss: 0.0266
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[027/030] Train loss: 0.0266
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[028/030] Train loss: 0.0266
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[029/030] Train loss: 0.0265
2023-02-06 10:53:22 | Train | Epoch[361/600] Iteration[030/030] Train loss: 0.0266
2023-02-06 10:53:23 | Valid | Epoch[361/600] Iteration[001/008] Valid loss: 0.0864
2023-02-06 10:53:23 | Valid | Epoch[361/600] Iteration[002/008] Valid loss: 0.0643
2023-02-06 10:53:23 | Valid | Epoch[361/600] Iteration[003/008] Valid loss: 0.0593
2023-02-06 10:53:23 | Valid | Epoch[361/600] Iteration[004/008] Valid loss: 0.0567
2023-02-06 10:53:23 | Valid | Epoch[361/600] Iteration[005/008] Valid loss: 0.0588
2023-02-06 10:53:23 | Valid | Epoch[361/600] Iteration[006/008] Valid loss: 0.0586
2023-02-06 10:53:23 | Valid | Epoch[361/600] Iteration[007/008] Valid loss: 0.0630
2023-02-06 10:53:23 | Valid | Epoch[361/600] Iteration[008/008] Valid loss: 0.0611
2023-02-06 10:53:23 | Valid | Epoch[361/600] MIou: 0.9358002716077686
2023-02-06 10:53:23 | Valid | Epoch[361/600] Pixel Accuracy: 0.9887669881184896
2023-02-06 10:53:23 | Valid | Epoch[361/600] Mean Pixel Accuracy: 0.9698335133918422
2023-02-06 10:53:23 | Stage | Epoch[361/600] Train loss:0.0266
2023-02-06 10:53:23 | Stage | Epoch[361/600] Valid loss:0.0611
2023-02-06 10:53:23 | Stage | Epoch[361/600] LR:0.01

2023-02-06 10:53:23 | Train | Epoch[362/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 10:53:23 | Train | Epoch[362/600] Iteration[002/030] Train loss: 0.0245
2023-02-06 10:53:23 | Train | Epoch[362/600] Iteration[003/030] Train loss: 0.0274
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[004/030] Train loss: 0.0271
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[005/030] Train loss: 0.0270
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[006/030] Train loss: 0.0265
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[007/030] Train loss: 0.0263
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[009/030] Train loss: 0.0260
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[014/030] Train loss: 0.0261
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[022/030] Train loss: 0.0260
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[023/030] Train loss: 0.0259
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[024/030] Train loss: 0.0260
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[025/030] Train loss: 0.0261
2023-02-06 10:53:24 | Train | Epoch[362/600] Iteration[026/030] Train loss: 0.0264
2023-02-06 10:53:25 | Train | Epoch[362/600] Iteration[027/030] Train loss: 0.0265
2023-02-06 10:53:25 | Train | Epoch[362/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 10:53:25 | Train | Epoch[362/600] Iteration[029/030] Train loss: 0.0264
2023-02-06 10:53:25 | Train | Epoch[362/600] Iteration[030/030] Train loss: 0.0264
2023-02-06 10:53:25 | Valid | Epoch[362/600] Iteration[001/008] Valid loss: 1.3695
2023-02-06 10:53:25 | Valid | Epoch[362/600] Iteration[002/008] Valid loss: 1.3880
2023-02-06 10:53:25 | Valid | Epoch[362/600] Iteration[003/008] Valid loss: 1.3891
2023-02-06 10:53:25 | Valid | Epoch[362/600] Iteration[004/008] Valid loss: 1.4291
2023-02-06 10:53:25 | Valid | Epoch[362/600] Iteration[005/008] Valid loss: 1.4821
2023-02-06 10:53:25 | Valid | Epoch[362/600] Iteration[006/008] Valid loss: 1.4854
2023-02-06 10:53:25 | Valid | Epoch[362/600] Iteration[007/008] Valid loss: 1.5577
2023-02-06 10:53:25 | Valid | Epoch[362/600] Iteration[008/008] Valid loss: 1.5992
2023-02-06 10:53:25 | Valid | Epoch[362/600] MIou: 0.781039903288227
2023-02-06 10:53:25 | Valid | Epoch[362/600] Pixel Accuracy: 0.9453010559082031
2023-02-06 10:53:25 | Valid | Epoch[362/600] Mean Pixel Accuracy: 0.9687557997723589
2023-02-06 10:53:25 | Stage | Epoch[362/600] Train loss:0.0264
2023-02-06 10:53:25 | Stage | Epoch[362/600] Valid loss:1.5992
2023-02-06 10:53:25 | Stage | Epoch[362/600] LR:0.01

2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[002/030] Train loss: 0.0226
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[006/030] Train loss: 0.0245
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[013/030] Train loss: 0.0258
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[015/030] Train loss: 0.0266
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[017/030] Train loss: 0.0264
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[018/030] Train loss: 0.0263
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[019/030] Train loss: 0.0262
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[021/030] Train loss: 0.0261
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[022/030] Train loss: 0.0261
2023-02-06 10:53:26 | Train | Epoch[363/600] Iteration[023/030] Train loss: 0.0261
2023-02-06 10:53:27 | Train | Epoch[363/600] Iteration[024/030] Train loss: 0.0261
2023-02-06 10:53:27 | Train | Epoch[363/600] Iteration[025/030] Train loss: 0.0260
2023-02-06 10:53:27 | Train | Epoch[363/600] Iteration[026/030] Train loss: 0.0260
2023-02-06 10:53:27 | Train | Epoch[363/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 10:53:27 | Train | Epoch[363/600] Iteration[028/030] Train loss: 0.0261
2023-02-06 10:53:27 | Train | Epoch[363/600] Iteration[029/030] Train loss: 0.0260
2023-02-06 10:53:27 | Train | Epoch[363/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:53:27 | Valid | Epoch[363/600] Iteration[001/008] Valid loss: 0.1920
2023-02-06 10:53:27 | Valid | Epoch[363/600] Iteration[002/008] Valid loss: 0.1550
2023-02-06 10:53:27 | Valid | Epoch[363/600] Iteration[003/008] Valid loss: 0.1429
2023-02-06 10:53:27 | Valid | Epoch[363/600] Iteration[004/008] Valid loss: 0.1391
2023-02-06 10:53:27 | Valid | Epoch[363/600] Iteration[005/008] Valid loss: 0.1443
2023-02-06 10:53:27 | Valid | Epoch[363/600] Iteration[006/008] Valid loss: 0.1458
2023-02-06 10:53:27 | Valid | Epoch[363/600] Iteration[007/008] Valid loss: 0.1564
2023-02-06 10:53:27 | Valid | Epoch[363/600] Iteration[008/008] Valid loss: 0.1536
2023-02-06 10:53:27 | Valid | Epoch[363/600] MIou: 0.9047373536362455
2023-02-06 10:53:27 | Valid | Epoch[363/600] Pixel Accuracy: 0.9817911783854166
2023-02-06 10:53:27 | Valid | Epoch[363/600] Mean Pixel Accuracy: 0.9812164424804475
2023-02-06 10:53:27 | Stage | Epoch[363/600] Train loss:0.0262
2023-02-06 10:53:27 | Stage | Epoch[363/600] Valid loss:0.1536
2023-02-06 10:53:27 | Stage | Epoch[363/600] LR:0.01

2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[001/030] Train loss: 0.0256
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[002/030] Train loss: 0.0232
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[003/030] Train loss: 0.0227
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[004/030] Train loss: 0.0234
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[007/030] Train loss: 0.0240
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[008/030] Train loss: 0.0243
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[009/030] Train loss: 0.0243
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[010/030] Train loss: 0.0242
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[018/030] Train loss: 0.0259
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 10:53:28 | Train | Epoch[364/600] Iteration[020/030] Train loss: 0.0256
2023-02-06 10:53:29 | Train | Epoch[364/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:53:29 | Train | Epoch[364/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:53:29 | Train | Epoch[364/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:53:29 | Train | Epoch[364/600] Iteration[024/030] Train loss: 0.0259
2023-02-06 10:53:29 | Train | Epoch[364/600] Iteration[025/030] Train loss: 0.0260
2023-02-06 10:53:29 | Train | Epoch[364/600] Iteration[026/030] Train loss: 0.0261
2023-02-06 10:53:29 | Train | Epoch[364/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 10:53:29 | Train | Epoch[364/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:53:29 | Train | Epoch[364/600] Iteration[029/030] Train loss: 0.0261
2023-02-06 10:53:29 | Train | Epoch[364/600] Iteration[030/030] Train loss: 0.0260
2023-02-06 10:53:29 | Valid | Epoch[364/600] Iteration[001/008] Valid loss: 0.0584
2023-02-06 10:53:29 | Valid | Epoch[364/600] Iteration[002/008] Valid loss: 0.0472
2023-02-06 10:53:29 | Valid | Epoch[364/600] Iteration[003/008] Valid loss: 0.0446
2023-02-06 10:53:29 | Valid | Epoch[364/600] Iteration[004/008] Valid loss: 0.0427
2023-02-06 10:53:29 | Valid | Epoch[364/600] Iteration[005/008] Valid loss: 0.0444
2023-02-06 10:53:29 | Valid | Epoch[364/600] Iteration[006/008] Valid loss: 0.0443
2023-02-06 10:53:29 | Valid | Epoch[364/600] Iteration[007/008] Valid loss: 0.0469
2023-02-06 10:53:29 | Valid | Epoch[364/600] Iteration[008/008] Valid loss: 0.0464
2023-02-06 10:53:30 | Valid | Epoch[364/600] MIou: 0.9332262464063517
2023-02-06 10:53:30 | Valid | Epoch[364/600] Pixel Accuracy: 0.9882825215657552
2023-02-06 10:53:30 | Valid | Epoch[364/600] Mean Pixel Accuracy: 0.9686985853153056
2023-02-06 10:53:30 | Stage | Epoch[364/600] Train loss:0.0260
2023-02-06 10:53:30 | Stage | Epoch[364/600] Valid loss:0.0464
2023-02-06 10:53:30 | Stage | Epoch[364/600] LR:0.01

2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[001/030] Train loss: 0.0264
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[003/030] Train loss: 0.0274
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[004/030] Train loss: 0.0263
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[005/030] Train loss: 0.0278
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[006/030] Train loss: 0.0277
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[007/030] Train loss: 0.0281
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[008/030] Train loss: 0.0281
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[009/030] Train loss: 0.0278
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[010/030] Train loss: 0.0276
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[011/030] Train loss: 0.0275
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[013/030] Train loss: 0.0270
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[015/030] Train loss: 0.0265
2023-02-06 10:53:30 | Train | Epoch[365/600] Iteration[016/030] Train loss: 0.0262
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[019/030] Train loss: 0.0258
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[020/030] Train loss: 0.0260
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[023/030] Train loss: 0.0258
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[025/030] Train loss: 0.0258
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[026/030] Train loss: 0.0257
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[027/030] Train loss: 0.0257
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[028/030] Train loss: 0.0256
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[029/030] Train loss: 0.0257
2023-02-06 10:53:31 | Train | Epoch[365/600] Iteration[030/030] Train loss: 0.0261
2023-02-06 10:53:31 | Valid | Epoch[365/600] Iteration[001/008] Valid loss: 0.0615
2023-02-06 10:53:32 | Valid | Epoch[365/600] Iteration[002/008] Valid loss: 0.0603
2023-02-06 10:53:32 | Valid | Epoch[365/600] Iteration[003/008] Valid loss: 0.0623
2023-02-06 10:53:32 | Valid | Epoch[365/600] Iteration[004/008] Valid loss: 0.0611
2023-02-06 10:53:32 | Valid | Epoch[365/600] Iteration[005/008] Valid loss: 0.0625
2023-02-06 10:53:32 | Valid | Epoch[365/600] Iteration[006/008] Valid loss: 0.0612
2023-02-06 10:53:32 | Valid | Epoch[365/600] Iteration[007/008] Valid loss: 0.0594
2023-02-06 10:53:32 | Valid | Epoch[365/600] Iteration[008/008] Valid loss: 0.0608
2023-02-06 10:53:32 | Valid | Epoch[365/600] MIou: 0.7970887450851787
2023-02-06 10:53:32 | Valid | Epoch[365/600] Pixel Accuracy: 0.9665501912434896
2023-02-06 10:53:32 | Valid | Epoch[365/600] Mean Pixel Accuracy: 0.814822114910811
2023-02-06 10:53:32 | Stage | Epoch[365/600] Train loss:0.0261
2023-02-06 10:53:32 | Stage | Epoch[365/600] Valid loss:0.0608
2023-02-06 10:53:32 | Stage | Epoch[365/600] LR:0.01

2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[002/030] Train loss: 0.0249
2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[003/030] Train loss: 0.0259
2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[006/030] Train loss: 0.0258
2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[007/030] Train loss: 0.0264
2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 10:53:32 | Train | Epoch[366/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[019/030] Train loss: 0.0258
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[023/030] Train loss: 0.0258
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[027/030] Train loss: 0.0259
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[028/030] Train loss: 0.0260
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[029/030] Train loss: 0.0260
2023-02-06 10:53:33 | Train | Epoch[366/600] Iteration[030/030] Train loss: 0.0259
2023-02-06 10:53:34 | Valid | Epoch[366/600] Iteration[001/008] Valid loss: 0.0411
2023-02-06 10:53:34 | Valid | Epoch[366/600] Iteration[002/008] Valid loss: 0.0388
2023-02-06 10:53:34 | Valid | Epoch[366/600] Iteration[003/008] Valid loss: 0.0388
2023-02-06 10:53:34 | Valid | Epoch[366/600] Iteration[004/008] Valid loss: 0.0378
2023-02-06 10:53:34 | Valid | Epoch[366/600] Iteration[005/008] Valid loss: 0.0383
2023-02-06 10:53:34 | Valid | Epoch[366/600] Iteration[006/008] Valid loss: 0.0377
2023-02-06 10:53:34 | Valid | Epoch[366/600] Iteration[007/008] Valid loss: 0.0370
2023-02-06 10:53:34 | Valid | Epoch[366/600] Iteration[008/008] Valid loss: 0.0375
2023-02-06 10:53:34 | Valid | Epoch[366/600] MIou: 0.8741624575386902
2023-02-06 10:53:34 | Valid | Epoch[366/600] Pixel Accuracy: 0.9791831970214844
2023-02-06 10:53:34 | Valid | Epoch[366/600] Mean Pixel Accuracy: 0.8870979721315326
2023-02-06 10:53:34 | Stage | Epoch[366/600] Train loss:0.0259
2023-02-06 10:53:34 | Stage | Epoch[366/600] Valid loss:0.0375
2023-02-06 10:53:34 | Stage | Epoch[366/600] LR:0.01

2023-02-06 10:53:34 | Train | Epoch[367/600] Iteration[001/030] Train loss: 0.0228
2023-02-06 10:53:34 | Train | Epoch[367/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 10:53:34 | Train | Epoch[367/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 10:53:34 | Train | Epoch[367/600] Iteration[004/030] Train loss: 0.0258
2023-02-06 10:53:34 | Train | Epoch[367/600] Iteration[005/030] Train loss: 0.0269
2023-02-06 10:53:34 | Train | Epoch[367/600] Iteration[006/030] Train loss: 0.0260
2023-02-06 10:53:34 | Train | Epoch[367/600] Iteration[007/030] Train loss: 0.0263
2023-02-06 10:53:34 | Train | Epoch[367/600] Iteration[008/030] Train loss: 0.0266
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[010/030] Train loss: 0.0266
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[011/030] Train loss: 0.0266
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[016/030] Train loss: 0.0270
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[019/030] Train loss: 0.0267
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[020/030] Train loss: 0.0265
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[022/030] Train loss: 0.0265
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[023/030] Train loss: 0.0263
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[024/030] Train loss: 0.0263
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[025/030] Train loss: 0.0263
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[026/030] Train loss: 0.0264
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[029/030] Train loss: 0.0265
2023-02-06 10:53:35 | Train | Epoch[367/600] Iteration[030/030] Train loss: 0.0267
2023-02-06 10:53:36 | Valid | Epoch[367/600] Iteration[001/008] Valid loss: 0.0554
2023-02-06 10:53:36 | Valid | Epoch[367/600] Iteration[002/008] Valid loss: 0.0529
2023-02-06 10:53:36 | Valid | Epoch[367/600] Iteration[003/008] Valid loss: 0.0536
2023-02-06 10:53:36 | Valid | Epoch[367/600] Iteration[004/008] Valid loss: 0.0528
2023-02-06 10:53:36 | Valid | Epoch[367/600] Iteration[005/008] Valid loss: 0.0533
2023-02-06 10:53:36 | Valid | Epoch[367/600] Iteration[006/008] Valid loss: 0.0523
2023-02-06 10:53:36 | Valid | Epoch[367/600] Iteration[007/008] Valid loss: 0.0508
2023-02-06 10:53:36 | Valid | Epoch[367/600] Iteration[008/008] Valid loss: 0.0518
2023-02-06 10:53:36 | Valid | Epoch[367/600] MIou: 0.8283937915947232
2023-02-06 10:53:36 | Valid | Epoch[367/600] Pixel Accuracy: 0.9717089335123698
2023-02-06 10:53:36 | Valid | Epoch[367/600] Mean Pixel Accuracy: 0.8436535128763513
2023-02-06 10:53:36 | Stage | Epoch[367/600] Train loss:0.0267
2023-02-06 10:53:36 | Stage | Epoch[367/600] Valid loss:0.0518
2023-02-06 10:53:36 | Stage | Epoch[367/600] LR:0.01

2023-02-06 10:53:36 | Train | Epoch[368/600] Iteration[001/030] Train loss: 0.0233
2023-02-06 10:53:36 | Train | Epoch[368/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 10:53:36 | Train | Epoch[368/600] Iteration[003/030] Train loss: 0.0250
2023-02-06 10:53:36 | Train | Epoch[368/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:53:36 | Train | Epoch[368/600] Iteration[005/030] Train loss: 0.0262
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[006/030] Train loss: 0.0258
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[026/030] Train loss: 0.0258
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[028/030] Train loss: 0.0258
2023-02-06 10:53:37 | Train | Epoch[368/600] Iteration[029/030] Train loss: 0.0258
2023-02-06 10:53:38 | Train | Epoch[368/600] Iteration[030/030] Train loss: 0.0260
2023-02-06 10:53:38 | Valid | Epoch[368/600] Iteration[001/008] Valid loss: 0.2032
2023-02-06 10:53:38 | Valid | Epoch[368/600] Iteration[002/008] Valid loss: 0.1609
2023-02-06 10:53:38 | Valid | Epoch[368/600] Iteration[003/008] Valid loss: 0.1483
2023-02-06 10:53:38 | Valid | Epoch[368/600] Iteration[004/008] Valid loss: 0.1465
2023-02-06 10:53:38 | Valid | Epoch[368/600] Iteration[005/008] Valid loss: 0.1518
2023-02-06 10:53:38 | Valid | Epoch[368/600] Iteration[006/008] Valid loss: 0.1542
2023-02-06 10:53:38 | Valid | Epoch[368/600] Iteration[007/008] Valid loss: 0.1649
2023-02-06 10:53:38 | Valid | Epoch[368/600] Iteration[008/008] Valid loss: 0.1617
2023-02-06 10:53:38 | Valid | Epoch[368/600] MIou: 0.9061462890033039
2023-02-06 10:53:38 | Valid | Epoch[368/600] Pixel Accuracy: 0.9821090698242188
2023-02-06 10:53:38 | Valid | Epoch[368/600] Mean Pixel Accuracy: 0.9813658072869067
2023-02-06 10:53:38 | Stage | Epoch[368/600] Train loss:0.0260
2023-02-06 10:53:38 | Stage | Epoch[368/600] Valid loss:0.1617
2023-02-06 10:53:38 | Stage | Epoch[368/600] LR:0.01

2023-02-06 10:53:38 | Train | Epoch[369/600] Iteration[001/030] Train loss: 0.0345
2023-02-06 10:53:38 | Train | Epoch[369/600] Iteration[002/030] Train loss: 0.0299
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[003/030] Train loss: 0.0288
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[004/030] Train loss: 0.0275
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[005/030] Train loss: 0.0280
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[011/030] Train loss: 0.0268
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[012/030] Train loss: 0.0267
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[013/030] Train loss: 0.0270
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[015/030] Train loss: 0.0270
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[018/030] Train loss: 0.0263
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[021/030] Train loss: 0.0262
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[022/030] Train loss: 0.0262
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[023/030] Train loss: 0.0261
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[024/030] Train loss: 0.0259
2023-02-06 10:53:39 | Train | Epoch[369/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 10:53:40 | Train | Epoch[369/600] Iteration[026/030] Train loss: 0.0257
2023-02-06 10:53:40 | Train | Epoch[369/600] Iteration[027/030] Train loss: 0.0257
2023-02-06 10:53:40 | Train | Epoch[369/600] Iteration[028/030] Train loss: 0.0257
2023-02-06 10:53:40 | Train | Epoch[369/600] Iteration[029/030] Train loss: 0.0257
2023-02-06 10:53:40 | Train | Epoch[369/600] Iteration[030/030] Train loss: 0.0257
2023-02-06 10:53:40 | Valid | Epoch[369/600] Iteration[001/008] Valid loss: 0.0438
2023-02-06 10:53:40 | Valid | Epoch[369/600] Iteration[002/008] Valid loss: 0.0361
2023-02-06 10:53:40 | Valid | Epoch[369/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 10:53:40 | Valid | Epoch[369/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 10:53:40 | Valid | Epoch[369/600] Iteration[005/008] Valid loss: 0.0349
2023-02-06 10:53:40 | Valid | Epoch[369/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 10:53:40 | Valid | Epoch[369/600] Iteration[007/008] Valid loss: 0.0362
2023-02-06 10:53:40 | Valid | Epoch[369/600] Iteration[008/008] Valid loss: 0.0359
2023-02-06 10:53:40 | Valid | Epoch[369/600] MIou: 0.9357510807218
2023-02-06 10:53:40 | Valid | Epoch[369/600] Pixel Accuracy: 0.9889971415201823
2023-02-06 10:53:40 | Valid | Epoch[369/600] Mean Pixel Accuracy: 0.9596947921391605
2023-02-06 10:53:40 | Stage | Epoch[369/600] Train loss:0.0257
2023-02-06 10:53:40 | Stage | Epoch[369/600] Valid loss:0.0359
2023-02-06 10:53:40 | Stage | Epoch[369/600] LR:0.01

2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[001/030] Train loss: 0.0274
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[002/030] Train loss: 0.0266
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[008/030] Train loss: 0.0270
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[009/030] Train loss: 0.0269
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[011/030] Train loss: 0.0269
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[012/030] Train loss: 0.0269
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[014/030] Train loss: 0.0270
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[015/030] Train loss: 0.0274
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[016/030] Train loss: 0.0271
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[017/030] Train loss: 0.0270
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[018/030] Train loss: 0.0268
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[020/030] Train loss: 0.0270
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[021/030] Train loss: 0.0270
2023-02-06 10:53:41 | Train | Epoch[370/600] Iteration[022/030] Train loss: 0.0269
2023-02-06 10:53:42 | Train | Epoch[370/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:53:42 | Train | Epoch[370/600] Iteration[024/030] Train loss: 0.0268
2023-02-06 10:53:42 | Train | Epoch[370/600] Iteration[025/030] Train loss: 0.0269
2023-02-06 10:53:42 | Train | Epoch[370/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 10:53:42 | Train | Epoch[370/600] Iteration[027/030] Train loss: 0.0267
2023-02-06 10:53:42 | Train | Epoch[370/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:53:42 | Train | Epoch[370/600] Iteration[029/030] Train loss: 0.0267
2023-02-06 10:53:42 | Train | Epoch[370/600] Iteration[030/030] Train loss: 0.0267
2023-02-06 10:53:42 | Valid | Epoch[370/600] Iteration[001/008] Valid loss: 0.1010
2023-02-06 10:53:42 | Valid | Epoch[370/600] Iteration[002/008] Valid loss: 0.0993
2023-02-06 10:53:42 | Valid | Epoch[370/600] Iteration[003/008] Valid loss: 0.1022
2023-02-06 10:53:42 | Valid | Epoch[370/600] Iteration[004/008] Valid loss: 0.1016
2023-02-06 10:53:42 | Valid | Epoch[370/600] Iteration[005/008] Valid loss: 0.1035
2023-02-06 10:53:42 | Valid | Epoch[370/600] Iteration[006/008] Valid loss: 0.1021
2023-02-06 10:53:42 | Valid | Epoch[370/600] Iteration[007/008] Valid loss: 0.0999
2023-02-06 10:53:42 | Valid | Epoch[370/600] Iteration[008/008] Valid loss: 0.1016
2023-02-06 10:53:42 | Valid | Epoch[370/600] MIou: 0.7121859094531626
2023-02-06 10:53:42 | Valid | Epoch[370/600] Pixel Accuracy: 0.9524930318196615
2023-02-06 10:53:42 | Valid | Epoch[370/600] Mean Pixel Accuracy: 0.7370017880020836
2023-02-06 10:53:42 | Stage | Epoch[370/600] Train loss:0.0267
2023-02-06 10:53:42 | Stage | Epoch[370/600] Valid loss:0.1016
2023-02-06 10:53:42 | Stage | Epoch[370/600] LR:0.01

2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[002/030] Train loss: 0.0234
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[006/030] Train loss: 0.0266
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[007/030] Train loss: 0.0264
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[008/030] Train loss: 0.0270
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[010/030] Train loss: 0.0275
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[012/030] Train loss: 0.0270
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[013/030] Train loss: 0.0273
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[014/030] Train loss: 0.0273
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[015/030] Train loss: 0.0270
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[016/030] Train loss: 0.0270
2023-02-06 10:53:43 | Train | Epoch[371/600] Iteration[017/030] Train loss: 0.0269
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[019/030] Train loss: 0.0267
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[022/030] Train loss: 0.0265
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[024/030] Train loss: 0.0262
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[025/030] Train loss: 0.0261
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[026/030] Train loss: 0.0261
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[028/030] Train loss: 0.0261
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 10:53:44 | Train | Epoch[371/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:53:44 | Valid | Epoch[371/600] Iteration[001/008] Valid loss: 0.0960
2023-02-06 10:53:44 | Valid | Epoch[371/600] Iteration[002/008] Valid loss: 0.0916
2023-02-06 10:53:44 | Valid | Epoch[371/600] Iteration[003/008] Valid loss: 0.0939
2023-02-06 10:53:44 | Valid | Epoch[371/600] Iteration[004/008] Valid loss: 0.0931
2023-02-06 10:53:44 | Valid | Epoch[371/600] Iteration[005/008] Valid loss: 0.0947
2023-02-06 10:53:44 | Valid | Epoch[371/600] Iteration[006/008] Valid loss: 0.0931
2023-02-06 10:53:45 | Valid | Epoch[371/600] Iteration[007/008] Valid loss: 0.0905
2023-02-06 10:53:45 | Valid | Epoch[371/600] Iteration[008/008] Valid loss: 0.0925
2023-02-06 10:53:45 | Valid | Epoch[371/600] MIou: 0.7467971633870552
2023-02-06 10:53:45 | Valid | Epoch[371/600] Pixel Accuracy: 0.9582239786783854
2023-02-06 10:53:45 | Valid | Epoch[371/600] Mean Pixel Accuracy: 0.7687726492201385
2023-02-06 10:53:45 | Stage | Epoch[371/600] Train loss:0.0262
2023-02-06 10:53:45 | Stage | Epoch[371/600] Valid loss:0.0925
2023-02-06 10:53:45 | Stage | Epoch[371/600] LR:0.01

2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[001/030] Train loss: 0.0257
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[004/030] Train loss: 0.0257
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[007/030] Train loss: 0.0274
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[008/030] Train loss: 0.0267
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:53:45 | Train | Epoch[372/600] Iteration[012/030] Train loss: 0.0269
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[013/030] Train loss: 0.0267
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[014/030] Train loss: 0.0268
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[015/030] Train loss: 0.0268
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[017/030] Train loss: 0.0272
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[018/030] Train loss: 0.0271
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[020/030] Train loss: 0.0266
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[021/030] Train loss: 0.0267
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[025/030] Train loss: 0.0269
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[027/030] Train loss: 0.0268
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[028/030] Train loss: 0.0268
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[029/030] Train loss: 0.0269
2023-02-06 10:53:46 | Train | Epoch[372/600] Iteration[030/030] Train loss: 0.0268
2023-02-06 10:53:47 | Valid | Epoch[372/600] Iteration[001/008] Valid loss: 0.0414
2023-02-06 10:53:47 | Valid | Epoch[372/600] Iteration[002/008] Valid loss: 0.0404
2023-02-06 10:53:47 | Valid | Epoch[372/600] Iteration[003/008] Valid loss: 0.0416
2023-02-06 10:53:47 | Valid | Epoch[372/600] Iteration[004/008] Valid loss: 0.0404
2023-02-06 10:53:47 | Valid | Epoch[372/600] Iteration[005/008] Valid loss: 0.0412
2023-02-06 10:53:47 | Valid | Epoch[372/600] Iteration[006/008] Valid loss: 0.0405
2023-02-06 10:53:47 | Valid | Epoch[372/600] Iteration[007/008] Valid loss: 0.0393
2023-02-06 10:53:47 | Valid | Epoch[372/600] Iteration[008/008] Valid loss: 0.0400
2023-02-06 10:53:47 | Valid | Epoch[372/600] MIou: 0.8558550896677306
2023-02-06 10:53:47 | Valid | Epoch[372/600] Pixel Accuracy: 0.9762433369954427
2023-02-06 10:53:47 | Valid | Epoch[372/600] Mean Pixel Accuracy: 0.8688193405454767
2023-02-06 10:53:47 | Stage | Epoch[372/600] Train loss:0.0268
2023-02-06 10:53:47 | Stage | Epoch[372/600] Valid loss:0.0400
2023-02-06 10:53:47 | Stage | Epoch[372/600] LR:0.01

2023-02-06 10:53:47 | Train | Epoch[373/600] Iteration[001/030] Train loss: 0.0260
2023-02-06 10:53:47 | Train | Epoch[373/600] Iteration[002/030] Train loss: 0.0259
2023-02-06 10:53:47 | Train | Epoch[373/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 10:53:47 | Train | Epoch[373/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:53:47 | Train | Epoch[373/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:53:47 | Train | Epoch[373/600] Iteration[006/030] Train loss: 0.0262
2023-02-06 10:53:47 | Train | Epoch[373/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:53:47 | Train | Epoch[373/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 10:53:47 | Train | Epoch[373/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[014/030] Train loss: 0.0261
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[017/030] Train loss: 0.0261
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[018/030] Train loss: 0.0261
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[021/030] Train loss: 0.0262
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[022/030] Train loss: 0.0262
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[025/030] Train loss: 0.0263
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[027/030] Train loss: 0.0260
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[028/030] Train loss: 0.0261
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 10:53:48 | Train | Epoch[373/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:53:49 | Valid | Epoch[373/600] Iteration[001/008] Valid loss: 0.0359
2023-02-06 10:53:49 | Valid | Epoch[373/600] Iteration[002/008] Valid loss: 0.0320
2023-02-06 10:53:49 | Valid | Epoch[373/600] Iteration[003/008] Valid loss: 0.0316
2023-02-06 10:53:49 | Valid | Epoch[373/600] Iteration[004/008] Valid loss: 0.0304
2023-02-06 10:53:49 | Valid | Epoch[373/600] Iteration[005/008] Valid loss: 0.0312
2023-02-06 10:53:49 | Valid | Epoch[373/600] Iteration[006/008] Valid loss: 0.0309
2023-02-06 10:53:49 | Valid | Epoch[373/600] Iteration[007/008] Valid loss: 0.0310
2023-02-06 10:53:49 | Valid | Epoch[373/600] Iteration[008/008] Valid loss: 0.0312
2023-02-06 10:53:49 | Valid | Epoch[373/600] MIou: 0.9101578547770972
2023-02-06 10:53:49 | Valid | Epoch[373/600] Pixel Accuracy: 0.9850451151529948
2023-02-06 10:53:49 | Valid | Epoch[373/600] Mean Pixel Accuracy: 0.9229670201570713
2023-02-06 10:53:49 | Stage | Epoch[373/600] Train loss:0.0263
2023-02-06 10:53:49 | Stage | Epoch[373/600] Valid loss:0.0312
2023-02-06 10:53:49 | Stage | Epoch[373/600] LR:0.01

2023-02-06 10:53:49 | Train | Epoch[374/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 10:53:49 | Train | Epoch[374/600] Iteration[002/030] Train loss: 0.0229
2023-02-06 10:53:49 | Train | Epoch[374/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 10:53:49 | Train | Epoch[374/600] Iteration[004/030] Train loss: 0.0238
2023-02-06 10:53:49 | Train | Epoch[374/600] Iteration[005/030] Train loss: 0.0243
2023-02-06 10:53:49 | Train | Epoch[374/600] Iteration[006/030] Train loss: 0.0241
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[008/030] Train loss: 0.0239
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[010/030] Train loss: 0.0242
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[012/030] Train loss: 0.0245
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[025/030] Train loss: 0.0258
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[026/030] Train loss: 0.0257
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[028/030] Train loss: 0.0257
2023-02-06 10:53:50 | Train | Epoch[374/600] Iteration[029/030] Train loss: 0.0258
2023-02-06 10:53:51 | Train | Epoch[374/600] Iteration[030/030] Train loss: 0.0259
2023-02-06 10:53:51 | Valid | Epoch[374/600] Iteration[001/008] Valid loss: 0.0863
2023-02-06 10:53:51 | Valid | Epoch[374/600] Iteration[002/008] Valid loss: 0.0683
2023-02-06 10:53:51 | Valid | Epoch[374/600] Iteration[003/008] Valid loss: 0.0650
2023-02-06 10:53:51 | Valid | Epoch[374/600] Iteration[004/008] Valid loss: 0.0632
2023-02-06 10:53:51 | Valid | Epoch[374/600] Iteration[005/008] Valid loss: 0.0677
2023-02-06 10:53:51 | Valid | Epoch[374/600] Iteration[006/008] Valid loss: 0.0692
2023-02-06 10:53:51 | Valid | Epoch[374/600] Iteration[007/008] Valid loss: 0.0734
2023-02-06 10:53:51 | Valid | Epoch[374/600] Iteration[008/008] Valid loss: 0.0721
2023-02-06 10:53:51 | Valid | Epoch[374/600] MIou: 0.9212337250670755
2023-02-06 10:53:51 | Valid | Epoch[374/600] Pixel Accuracy: 0.98565673828125
2023-02-06 10:53:51 | Valid | Epoch[374/600] Mean Pixel Accuracy: 0.9745215231880366
2023-02-06 10:53:51 | Stage | Epoch[374/600] Train loss:0.0259
2023-02-06 10:53:51 | Stage | Epoch[374/600] Valid loss:0.0721
2023-02-06 10:53:51 | Stage | Epoch[374/600] LR:0.01

2023-02-06 10:53:51 | Train | Epoch[375/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 10:53:51 | Train | Epoch[375/600] Iteration[002/030] Train loss: 0.0241
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[006/030] Train loss: 0.0253
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[007/030] Train loss: 0.0248
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[021/030] Train loss: 0.0257
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[022/030] Train loss: 0.0256
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:53:52 | Train | Epoch[375/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 10:53:53 | Train | Epoch[375/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 10:53:53 | Train | Epoch[375/600] Iteration[026/030] Train loss: 0.0260
2023-02-06 10:53:53 | Train | Epoch[375/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 10:53:53 | Train | Epoch[375/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:53:53 | Train | Epoch[375/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:53:53 | Train | Epoch[375/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:53:53 | Valid | Epoch[375/600] Iteration[001/008] Valid loss: 0.7607
2023-02-06 10:53:53 | Valid | Epoch[375/600] Iteration[002/008] Valid loss: 0.7578
2023-02-06 10:53:53 | Valid | Epoch[375/600] Iteration[003/008] Valid loss: 0.7600
2023-02-06 10:53:53 | Valid | Epoch[375/600] Iteration[004/008] Valid loss: 0.7737
2023-02-06 10:53:53 | Valid | Epoch[375/600] Iteration[005/008] Valid loss: 0.8060
2023-02-06 10:53:53 | Valid | Epoch[375/600] Iteration[006/008] Valid loss: 0.7959
2023-02-06 10:53:53 | Valid | Epoch[375/600] Iteration[007/008] Valid loss: 0.8392
2023-02-06 10:53:53 | Valid | Epoch[375/600] Iteration[008/008] Valid loss: 0.8638
2023-02-06 10:53:53 | Valid | Epoch[375/600] MIou: 0.8302253279664406
2023-02-06 10:53:53 | Valid | Epoch[375/600] Pixel Accuracy: 0.9619356791178385
2023-02-06 10:53:53 | Valid | Epoch[375/600] Mean Pixel Accuracy: 0.976415227804069
2023-02-06 10:53:53 | Stage | Epoch[375/600] Train loss:0.0262
2023-02-06 10:53:53 | Stage | Epoch[375/600] Valid loss:0.8638
2023-02-06 10:53:53 | Stage | Epoch[375/600] LR:0.01

2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[001/030] Train loss: 0.0231
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[002/030] Train loss: 0.0251
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[015/030] Train loss: 0.0264
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[017/030] Train loss: 0.0262
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[019/030] Train loss: 0.0260
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[021/030] Train loss: 0.0263
2023-02-06 10:53:54 | Train | Epoch[376/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 10:53:55 | Train | Epoch[376/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:53:55 | Train | Epoch[376/600] Iteration[024/030] Train loss: 0.0267
2023-02-06 10:53:55 | Train | Epoch[376/600] Iteration[025/030] Train loss: 0.0266
2023-02-06 10:53:55 | Train | Epoch[376/600] Iteration[026/030] Train loss: 0.0266
2023-02-06 10:53:55 | Train | Epoch[376/600] Iteration[027/030] Train loss: 0.0266
2023-02-06 10:53:55 | Train | Epoch[376/600] Iteration[028/030] Train loss: 0.0266
2023-02-06 10:53:55 | Train | Epoch[376/600] Iteration[029/030] Train loss: 0.0265
2023-02-06 10:53:55 | Train | Epoch[376/600] Iteration[030/030] Train loss: 0.0265
2023-02-06 10:53:55 | Valid | Epoch[376/600] Iteration[001/008] Valid loss: 0.0472
2023-02-06 10:53:55 | Valid | Epoch[376/600] Iteration[002/008] Valid loss: 0.0463
2023-02-06 10:53:55 | Valid | Epoch[376/600] Iteration[003/008] Valid loss: 0.0477
2023-02-06 10:53:55 | Valid | Epoch[376/600] Iteration[004/008] Valid loss: 0.0469
2023-02-06 10:53:55 | Valid | Epoch[376/600] Iteration[005/008] Valid loss: 0.0475
2023-02-06 10:53:55 | Valid | Epoch[376/600] Iteration[006/008] Valid loss: 0.0468
2023-02-06 10:53:55 | Valid | Epoch[376/600] Iteration[007/008] Valid loss: 0.0453
2023-02-06 10:53:55 | Valid | Epoch[376/600] Iteration[008/008] Valid loss: 0.0465
2023-02-06 10:53:55 | Valid | Epoch[376/600] MIou: 0.8293330767474016
2023-02-06 10:53:55 | Valid | Epoch[376/600] Pixel Accuracy: 0.9718742370605469
2023-02-06 10:53:55 | Valid | Epoch[376/600] Mean Pixel Accuracy: 0.8443910988506873
2023-02-06 10:53:55 | Stage | Epoch[376/600] Train loss:0.0265
2023-02-06 10:53:55 | Stage | Epoch[376/600] Valid loss:0.0465
2023-02-06 10:53:55 | Stage | Epoch[376/600] LR:0.01

2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[001/030] Train loss: 0.0274
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[002/030] Train loss: 0.0283
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[003/030] Train loss: 0.0267
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[004/030] Train loss: 0.0261
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[005/030] Train loss: 0.0258
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[006/030] Train loss: 0.0261
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[007/030] Train loss: 0.0260
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[015/030] Train loss: 0.0264
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[016/030] Train loss: 0.0267
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[017/030] Train loss: 0.0267
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 10:53:56 | Train | Epoch[377/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[020/030] Train loss: 0.0267
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[022/030] Train loss: 0.0265
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[023/030] Train loss: 0.0265
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[024/030] Train loss: 0.0265
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[025/030] Train loss: 0.0265
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[029/030] Train loss: 0.0261
2023-02-06 10:53:57 | Train | Epoch[377/600] Iteration[030/030] Train loss: 0.0260
2023-02-06 10:53:57 | Valid | Epoch[377/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 10:53:57 | Valid | Epoch[377/600] Iteration[002/008] Valid loss: 0.0311
2023-02-06 10:53:57 | Valid | Epoch[377/600] Iteration[003/008] Valid loss: 0.0306
2023-02-06 10:53:57 | Valid | Epoch[377/600] Iteration[004/008] Valid loss: 0.0295
2023-02-06 10:53:57 | Valid | Epoch[377/600] Iteration[005/008] Valid loss: 0.0303
2023-02-06 10:53:57 | Valid | Epoch[377/600] Iteration[006/008] Valid loss: 0.0300
2023-02-06 10:53:57 | Valid | Epoch[377/600] Iteration[007/008] Valid loss: 0.0302
2023-02-06 10:53:57 | Valid | Epoch[377/600] Iteration[008/008] Valid loss: 0.0304
2023-02-06 10:53:58 | Valid | Epoch[377/600] MIou: 0.913766126561782
2023-02-06 10:53:58 | Valid | Epoch[377/600] Pixel Accuracy: 0.9856287638346354
2023-02-06 10:53:58 | Valid | Epoch[377/600] Mean Pixel Accuracy: 0.9268258014682558
2023-02-06 10:53:58 | Stage | Epoch[377/600] Train loss:0.0260
2023-02-06 10:53:58 | Stage | Epoch[377/600] Valid loss:0.0304
2023-02-06 10:53:58 | Stage | Epoch[377/600] LR:0.01

2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[001/030] Train loss: 0.0279
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[002/030] Train loss: 0.0267
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:53:58 | Train | Epoch[378/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[026/030] Train loss: 0.0258
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[027/030] Train loss: 0.0260
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[028/030] Train loss: 0.0261
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[029/030] Train loss: 0.0261
2023-02-06 10:53:59 | Train | Epoch[378/600] Iteration[030/030] Train loss: 0.0261
2023-02-06 10:53:59 | Valid | Epoch[378/600] Iteration[001/008] Valid loss: 0.0372
2023-02-06 10:53:59 | Valid | Epoch[378/600] Iteration[002/008] Valid loss: 0.0343
2023-02-06 10:53:59 | Valid | Epoch[378/600] Iteration[003/008] Valid loss: 0.0332
2023-02-06 10:53:59 | Valid | Epoch[378/600] Iteration[004/008] Valid loss: 0.0324
2023-02-06 10:53:59 | Valid | Epoch[378/600] Iteration[005/008] Valid loss: 0.0327
2023-02-06 10:53:59 | Valid | Epoch[378/600] Iteration[006/008] Valid loss: 0.0331
2023-02-06 10:53:59 | Valid | Epoch[378/600] Iteration[007/008] Valid loss: 0.0328
2023-02-06 10:54:00 | Valid | Epoch[378/600] Iteration[008/008] Valid loss: 0.0326
2023-02-06 10:54:00 | Valid | Epoch[378/600] MIou: 0.9122345122421825
2023-02-06 10:54:00 | Valid | Epoch[378/600] Pixel Accuracy: 0.985418955485026
2023-02-06 10:54:00 | Valid | Epoch[378/600] Mean Pixel Accuracy: 0.9240791861736877
2023-02-06 10:54:00 | Stage | Epoch[378/600] Train loss:0.0261
2023-02-06 10:54:00 | Stage | Epoch[378/600] Valid loss:0.0326
2023-02-06 10:54:00 | Stage | Epoch[378/600] LR:0.01

2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[002/030] Train loss: 0.0229
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[003/030] Train loss: 0.0231
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[004/030] Train loss: 0.0234
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[013/030] Train loss: 0.0259
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[014/030] Train loss: 0.0267
2023-02-06 10:54:00 | Train | Epoch[379/600] Iteration[015/030] Train loss: 0.0263
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[017/030] Train loss: 0.0270
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[018/030] Train loss: 0.0272
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[019/030] Train loss: 0.0272
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[020/030] Train loss: 0.0279
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[021/030] Train loss: 0.0279
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[022/030] Train loss: 0.0277
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[023/030] Train loss: 0.0283
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[024/030] Train loss: 0.0282
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[025/030] Train loss: 0.0281
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[026/030] Train loss: 0.0282
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[027/030] Train loss: 0.0281
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[028/030] Train loss: 0.0282
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[029/030] Train loss: 0.0282
2023-02-06 10:54:01 | Train | Epoch[379/600] Iteration[030/030] Train loss: 0.0281
2023-02-06 10:54:01 | Valid | Epoch[379/600] Iteration[001/008] Valid loss: 0.1344
2023-02-06 10:54:01 | Valid | Epoch[379/600] Iteration[002/008] Valid loss: 0.1156
2023-02-06 10:54:01 | Valid | Epoch[379/600] Iteration[003/008] Valid loss: 0.1048
2023-02-06 10:54:01 | Valid | Epoch[379/600] Iteration[004/008] Valid loss: 0.1033
2023-02-06 10:54:01 | Valid | Epoch[379/600] Iteration[005/008] Valid loss: 0.1034
2023-02-06 10:54:02 | Valid | Epoch[379/600] Iteration[006/008] Valid loss: 0.1096
2023-02-06 10:54:02 | Valid | Epoch[379/600] Iteration[007/008] Valid loss: 0.1151
2023-02-06 10:54:02 | Valid | Epoch[379/600] Iteration[008/008] Valid loss: 0.1107
2023-02-06 10:54:02 | Valid | Epoch[379/600] MIou: 0.9212167268556112
2023-02-06 10:54:02 | Valid | Epoch[379/600] Pixel Accuracy: 0.9858283996582031
2023-02-06 10:54:02 | Valid | Epoch[379/600] Mean Pixel Accuracy: 0.9685860871940027
2023-02-06 10:54:02 | Stage | Epoch[379/600] Train loss:0.0281
2023-02-06 10:54:02 | Stage | Epoch[379/600] Valid loss:0.1107
2023-02-06 10:54:02 | Stage | Epoch[379/600] LR:0.01

2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[001/030] Train loss: 0.0311
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[003/030] Train loss: 0.0280
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[004/030] Train loss: 0.0273
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[005/030] Train loss: 0.0271
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[006/030] Train loss: 0.0274
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[007/030] Train loss: 0.0277
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[009/030] Train loss: 0.0273
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[010/030] Train loss: 0.0275
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[012/030] Train loss: 0.0275
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[013/030] Train loss: 0.0274
2023-02-06 10:54:02 | Train | Epoch[380/600] Iteration[014/030] Train loss: 0.0274
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[015/030] Train loss: 0.0272
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[016/030] Train loss: 0.0271
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[017/030] Train loss: 0.0272
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[018/030] Train loss: 0.0271
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[019/030] Train loss: 0.0269
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[020/030] Train loss: 0.0269
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[021/030] Train loss: 0.0271
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[022/030] Train loss: 0.0271
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[023/030] Train loss: 0.0269
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[024/030] Train loss: 0.0270
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[025/030] Train loss: 0.0268
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[026/030] Train loss: 0.0268
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[027/030] Train loss: 0.0269
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[029/030] Train loss: 0.0269
2023-02-06 10:54:03 | Train | Epoch[380/600] Iteration[030/030] Train loss: 0.0270
2023-02-06 10:54:03 | Valid | Epoch[380/600] Iteration[001/008] Valid loss: 0.1802
2023-02-06 10:54:03 | Valid | Epoch[380/600] Iteration[002/008] Valid loss: 0.1786
2023-02-06 10:54:04 | Valid | Epoch[380/600] Iteration[003/008] Valid loss: 0.1864
2023-02-06 10:54:04 | Valid | Epoch[380/600] Iteration[004/008] Valid loss: 0.1861
2023-02-06 10:54:04 | Valid | Epoch[380/600] Iteration[005/008] Valid loss: 0.1911
2023-02-06 10:54:04 | Valid | Epoch[380/600] Iteration[006/008] Valid loss: 0.1887
2023-02-06 10:54:04 | Valid | Epoch[380/600] Iteration[007/008] Valid loss: 0.1853
2023-02-06 10:54:04 | Valid | Epoch[380/600] Iteration[008/008] Valid loss: 0.1909
2023-02-06 10:54:04 | Valid | Epoch[380/600] MIou: 0.49859120551811753
2023-02-06 10:54:04 | Valid | Epoch[380/600] Pixel Accuracy: 0.9169807434082031
2023-02-06 10:54:04 | Valid | Epoch[380/600] Mean Pixel Accuracy: 0.5404060313393121
2023-02-06 10:54:04 | Stage | Epoch[380/600] Train loss:0.0270
2023-02-06 10:54:04 | Stage | Epoch[380/600] Valid loss:0.1909
2023-02-06 10:54:04 | Stage | Epoch[380/600] LR:0.01

2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[001/030] Train loss: 0.0280
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[002/030] Train loss: 0.0266
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[005/030] Train loss: 0.0257
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[007/030] Train loss: 0.0263
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[008/030] Train loss: 0.0264
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 10:54:04 | Train | Epoch[381/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[013/030] Train loss: 0.0259
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[015/030] Train loss: 0.0263
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[016/030] Train loss: 0.0270
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[018/030] Train loss: 0.0267
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[019/030] Train loss: 0.0267
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[020/030] Train loss: 0.0269
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[021/030] Train loss: 0.0269
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[022/030] Train loss: 0.0269
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[023/030] Train loss: 0.0270
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[024/030] Train loss: 0.0270
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[025/030] Train loss: 0.0269
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[026/030] Train loss: 0.0269
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[027/030] Train loss: 0.0269
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[028/030] Train loss: 0.0270
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[029/030] Train loss: 0.0269
2023-02-06 10:54:05 | Train | Epoch[381/600] Iteration[030/030] Train loss: 0.0269
2023-02-06 10:54:06 | Valid | Epoch[381/600] Iteration[001/008] Valid loss: 0.1102
2023-02-06 10:54:06 | Valid | Epoch[381/600] Iteration[002/008] Valid loss: 0.0855
2023-02-06 10:54:06 | Valid | Epoch[381/600] Iteration[003/008] Valid loss: 0.0796
2023-02-06 10:54:06 | Valid | Epoch[381/600] Iteration[004/008] Valid loss: 0.0767
2023-02-06 10:54:06 | Valid | Epoch[381/600] Iteration[005/008] Valid loss: 0.0809
2023-02-06 10:54:06 | Valid | Epoch[381/600] Iteration[006/008] Valid loss: 0.0811
2023-02-06 10:54:06 | Valid | Epoch[381/600] Iteration[007/008] Valid loss: 0.0867
2023-02-06 10:54:06 | Valid | Epoch[381/600] Iteration[008/008] Valid loss: 0.0858
2023-02-06 10:54:06 | Valid | Epoch[381/600] MIou: 0.9222392715408462
2023-02-06 10:54:06 | Valid | Epoch[381/600] Pixel Accuracy: 0.9857381184895834
2023-02-06 10:54:06 | Valid | Epoch[381/600] Mean Pixel Accuracy: 0.979055307051871
2023-02-06 10:54:06 | Stage | Epoch[381/600] Train loss:0.0269
2023-02-06 10:54:06 | Stage | Epoch[381/600] Valid loss:0.0858
2023-02-06 10:54:06 | Stage | Epoch[381/600] LR:0.01

2023-02-06 10:54:06 | Train | Epoch[382/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 10:54:06 | Train | Epoch[382/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 10:54:06 | Train | Epoch[382/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:54:06 | Train | Epoch[382/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 10:54:06 | Train | Epoch[382/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:54:06 | Train | Epoch[382/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 10:54:06 | Train | Epoch[382/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:54:06 | Train | Epoch[382/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 10:54:06 | Train | Epoch[382/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[012/030] Train loss: 0.0273
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[014/030] Train loss: 0.0271
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[015/030] Train loss: 0.0269
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[016/030] Train loss: 0.0267
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[017/030] Train loss: 0.0268
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[019/030] Train loss: 0.0269
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[022/030] Train loss: 0.0266
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[023/030] Train loss: 0.0264
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[024/030] Train loss: 0.0265
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[025/030] Train loss: 0.0265
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[026/030] Train loss: 0.0262
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[028/030] Train loss: 0.0261
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[029/030] Train loss: 0.0258
2023-02-06 10:54:07 | Train | Epoch[382/600] Iteration[030/030] Train loss: 0.0259
2023-02-06 10:54:08 | Valid | Epoch[382/600] Iteration[001/008] Valid loss: 0.0406
2023-02-06 10:54:08 | Valid | Epoch[382/600] Iteration[002/008] Valid loss: 0.0375
2023-02-06 10:54:08 | Valid | Epoch[382/600] Iteration[003/008] Valid loss: 0.0382
2023-02-06 10:54:08 | Valid | Epoch[382/600] Iteration[004/008] Valid loss: 0.0366
2023-02-06 10:54:08 | Valid | Epoch[382/600] Iteration[005/008] Valid loss: 0.0375
2023-02-06 10:54:08 | Valid | Epoch[382/600] Iteration[006/008] Valid loss: 0.0370
2023-02-06 10:54:08 | Valid | Epoch[382/600] Iteration[007/008] Valid loss: 0.0363
2023-02-06 10:54:08 | Valid | Epoch[382/600] Iteration[008/008] Valid loss: 0.0365
2023-02-06 10:54:08 | Valid | Epoch[382/600] MIou: 0.8810720030249515
2023-02-06 10:54:08 | Valid | Epoch[382/600] Pixel Accuracy: 0.9803899129231771
2023-02-06 10:54:08 | Valid | Epoch[382/600] Mean Pixel Accuracy: 0.8922122456577715
2023-02-06 10:54:08 | Stage | Epoch[382/600] Train loss:0.0259
2023-02-06 10:54:08 | Stage | Epoch[382/600] Valid loss:0.0365
2023-02-06 10:54:08 | Stage | Epoch[382/600] LR:0.01

2023-02-06 10:54:08 | Train | Epoch[383/600] Iteration[001/030] Train loss: 0.0241
2023-02-06 10:54:08 | Train | Epoch[383/600] Iteration[002/030] Train loss: 0.0247
2023-02-06 10:54:08 | Train | Epoch[383/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:54:08 | Train | Epoch[383/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 10:54:08 | Train | Epoch[383/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 10:54:08 | Train | Epoch[383/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:54:08 | Train | Epoch[383/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[008/030] Train loss: 0.0258
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[025/030] Train loss: 0.0258
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[026/030] Train loss: 0.0258
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[028/030] Train loss: 0.0256
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[029/030] Train loss: 0.0256
2023-02-06 10:54:09 | Train | Epoch[383/600] Iteration[030/030] Train loss: 0.0256
2023-02-06 10:54:10 | Valid | Epoch[383/600] Iteration[001/008] Valid loss: 0.0461
2023-02-06 10:54:10 | Valid | Epoch[383/600] Iteration[002/008] Valid loss: 0.0386
2023-02-06 10:54:10 | Valid | Epoch[383/600] Iteration[003/008] Valid loss: 0.0363
2023-02-06 10:54:10 | Valid | Epoch[383/600] Iteration[004/008] Valid loss: 0.0349
2023-02-06 10:54:10 | Valid | Epoch[383/600] Iteration[005/008] Valid loss: 0.0360
2023-02-06 10:54:10 | Valid | Epoch[383/600] Iteration[006/008] Valid loss: 0.0357
2023-02-06 10:54:10 | Valid | Epoch[383/600] Iteration[007/008] Valid loss: 0.0370
2023-02-06 10:54:10 | Valid | Epoch[383/600] Iteration[008/008] Valid loss: 0.0369
2023-02-06 10:54:10 | Valid | Epoch[383/600] MIou: 0.9280252305864409
2023-02-06 10:54:10 | Valid | Epoch[383/600] Pixel Accuracy: 0.9877243041992188
2023-02-06 10:54:10 | Valid | Epoch[383/600] Mean Pixel Accuracy: 0.9504418903925644
2023-02-06 10:54:10 | Stage | Epoch[383/600] Train loss:0.0256
2023-02-06 10:54:10 | Stage | Epoch[383/600] Valid loss:0.0369
2023-02-06 10:54:10 | Stage | Epoch[383/600] LR:0.01

2023-02-06 10:54:10 | Train | Epoch[384/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 10:54:10 | Train | Epoch[384/600] Iteration[002/030] Train loss: 0.0245
2023-02-06 10:54:10 | Train | Epoch[384/600] Iteration[003/030] Train loss: 0.0234
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[004/030] Train loss: 0.0245
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[006/030] Train loss: 0.0272
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[007/030] Train loss: 0.0272
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[010/030] Train loss: 0.0264
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[025/030] Train loss: 0.0259
2023-02-06 10:54:11 | Train | Epoch[384/600] Iteration[026/030] Train loss: 0.0259
2023-02-06 10:54:12 | Train | Epoch[384/600] Iteration[027/030] Train loss: 0.0259
2023-02-06 10:54:12 | Train | Epoch[384/600] Iteration[028/030] Train loss: 0.0260
2023-02-06 10:54:12 | Train | Epoch[384/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:54:12 | Train | Epoch[384/600] Iteration[030/030] Train loss: 0.0261
2023-02-06 10:54:12 | Valid | Epoch[384/600] Iteration[001/008] Valid loss: 0.2350
2023-02-06 10:54:12 | Valid | Epoch[384/600] Iteration[002/008] Valid loss: 0.1939
2023-02-06 10:54:12 | Valid | Epoch[384/600] Iteration[003/008] Valid loss: 0.1873
2023-02-06 10:54:12 | Valid | Epoch[384/600] Iteration[004/008] Valid loss: 0.1841
2023-02-06 10:54:12 | Valid | Epoch[384/600] Iteration[005/008] Valid loss: 0.1953
2023-02-06 10:54:12 | Valid | Epoch[384/600] Iteration[006/008] Valid loss: 0.1985
2023-02-06 10:54:12 | Valid | Epoch[384/600] Iteration[007/008] Valid loss: 0.2116
2023-02-06 10:54:12 | Valid | Epoch[384/600] Iteration[008/008] Valid loss: 0.2106
2023-02-06 10:54:12 | Valid | Epoch[384/600] MIou: 0.8777979924616612
2023-02-06 10:54:12 | Valid | Epoch[384/600] Pixel Accuracy: 0.9752426147460938
2023-02-06 10:54:12 | Valid | Epoch[384/600] Mean Pixel Accuracy: 0.9808950963865365
2023-02-06 10:54:12 | Stage | Epoch[384/600] Train loss:0.0261
2023-02-06 10:54:12 | Stage | Epoch[384/600] Valid loss:0.2106
2023-02-06 10:54:12 | Stage | Epoch[384/600] LR:0.01

2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[001/030] Train loss: 0.0232
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[002/030] Train loss: 0.0278
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[006/030] Train loss: 0.0248
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[007/030] Train loss: 0.0251
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[009/030] Train loss: 0.0246
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[013/030] Train loss: 0.0247
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 10:54:13 | Train | Epoch[385/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:54:14 | Train | Epoch[385/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:54:14 | Train | Epoch[385/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:54:14 | Train | Epoch[385/600] Iteration[026/030] Train loss: 0.0257
2023-02-06 10:54:14 | Train | Epoch[385/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 10:54:14 | Train | Epoch[385/600] Iteration[028/030] Train loss: 0.0258
2023-02-06 10:54:14 | Train | Epoch[385/600] Iteration[029/030] Train loss: 0.0258
2023-02-06 10:54:14 | Train | Epoch[385/600] Iteration[030/030] Train loss: 0.0261
2023-02-06 10:54:14 | Valid | Epoch[385/600] Iteration[001/008] Valid loss: 0.5749
2023-02-06 10:54:14 | Valid | Epoch[385/600] Iteration[002/008] Valid loss: 0.5740
2023-02-06 10:54:14 | Valid | Epoch[385/600] Iteration[003/008] Valid loss: 0.5554
2023-02-06 10:54:14 | Valid | Epoch[385/600] Iteration[004/008] Valid loss: 0.5610
2023-02-06 10:54:14 | Valid | Epoch[385/600] Iteration[005/008] Valid loss: 0.5869
2023-02-06 10:54:14 | Valid | Epoch[385/600] Iteration[006/008] Valid loss: 0.5864
2023-02-06 10:54:14 | Valid | Epoch[385/600] Iteration[007/008] Valid loss: 0.6280
2023-02-06 10:54:14 | Valid | Epoch[385/600] Iteration[008/008] Valid loss: 0.6325
2023-02-06 10:54:14 | Valid | Epoch[385/600] MIou: 0.8490763378210052
2023-02-06 10:54:14 | Valid | Epoch[385/600] Pixel Accuracy: 0.9674720764160156
2023-02-06 10:54:14 | Valid | Epoch[385/600] Mean Pixel Accuracy: 0.9790651586470319
2023-02-06 10:54:14 | Stage | Epoch[385/600] Train loss:0.0261
2023-02-06 10:54:14 | Stage | Epoch[385/600] Valid loss:0.6325
2023-02-06 10:54:14 | Stage | Epoch[385/600] LR:0.01

2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[001/030] Train loss: 0.0227
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[003/030] Train loss: 0.0251
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[004/030] Train loss: 0.0243
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[005/030] Train loss: 0.0245
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[007/030] Train loss: 0.0265
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[009/030] Train loss: 0.0267
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[010/030] Train loss: 0.0272
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[011/030] Train loss: 0.0268
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[015/030] Train loss: 0.0264
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[017/030] Train loss: 0.0263
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[018/030] Train loss: 0.0264
2023-02-06 10:54:15 | Train | Epoch[386/600] Iteration[019/030] Train loss: 0.0260
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[020/030] Train loss: 0.0260
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[021/030] Train loss: 0.0260
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[022/030] Train loss: 0.0261
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[024/030] Train loss: 0.0259
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[025/030] Train loss: 0.0262
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[026/030] Train loss: 0.0261
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:54:16 | Train | Epoch[386/600] Iteration[030/030] Train loss: 0.0261
2023-02-06 10:54:16 | Valid | Epoch[386/600] Iteration[001/008] Valid loss: 0.1584
2023-02-06 10:54:16 | Valid | Epoch[386/600] Iteration[002/008] Valid loss: 0.1589
2023-02-06 10:54:16 | Valid | Epoch[386/600] Iteration[003/008] Valid loss: 0.1651
2023-02-06 10:54:16 | Valid | Epoch[386/600] Iteration[004/008] Valid loss: 0.1652
2023-02-06 10:54:16 | Valid | Epoch[386/600] Iteration[005/008] Valid loss: 0.1689
2023-02-06 10:54:16 | Valid | Epoch[386/600] Iteration[006/008] Valid loss: 0.1654
2023-02-06 10:54:16 | Valid | Epoch[386/600] Iteration[007/008] Valid loss: 0.1615
2023-02-06 10:54:16 | Valid | Epoch[386/600] Iteration[008/008] Valid loss: 0.1671
2023-02-06 10:54:17 | Valid | Epoch[386/600] MIou: 0.5506453087081431
2023-02-06 10:54:17 | Valid | Epoch[386/600] Pixel Accuracy: 0.9256540934244791
2023-02-06 10:54:17 | Valid | Epoch[386/600] Mean Pixel Accuracy: 0.5884216306015853
2023-02-06 10:54:17 | Stage | Epoch[386/600] Train loss:0.0261
2023-02-06 10:54:17 | Stage | Epoch[386/600] Valid loss:0.1671
2023-02-06 10:54:17 | Stage | Epoch[386/600] LR:0.01

2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[001/030] Train loss: 0.0235
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[004/030] Train loss: 0.0279
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[006/030] Train loss: 0.0271
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[007/030] Train loss: 0.0270
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[008/030] Train loss: 0.0272
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[010/030] Train loss: 0.0269
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[011/030] Train loss: 0.0271
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[012/030] Train loss: 0.0271
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[014/030] Train loss: 0.0274
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[015/030] Train loss: 0.0277
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 10:54:17 | Train | Epoch[387/600] Iteration[017/030] Train loss: 0.0271
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[018/030] Train loss: 0.0270
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[020/030] Train loss: 0.0268
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[021/030] Train loss: 0.0267
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[022/030] Train loss: 0.0268
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[023/030] Train loss: 0.0266
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[025/030] Train loss: 0.0265
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[026/030] Train loss: 0.0265
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[027/030] Train loss: 0.0264
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[028/030] Train loss: 0.0265
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[029/030] Train loss: 0.0264
2023-02-06 10:54:18 | Train | Epoch[387/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:54:18 | Valid | Epoch[387/600] Iteration[001/008] Valid loss: 0.0581
2023-02-06 10:54:18 | Valid | Epoch[387/600] Iteration[002/008] Valid loss: 0.0556
2023-02-06 10:54:18 | Valid | Epoch[387/600] Iteration[003/008] Valid loss: 0.0568
2023-02-06 10:54:18 | Valid | Epoch[387/600] Iteration[004/008] Valid loss: 0.0557
2023-02-06 10:54:18 | Valid | Epoch[387/600] Iteration[005/008] Valid loss: 0.0565
2023-02-06 10:54:18 | Valid | Epoch[387/600] Iteration[006/008] Valid loss: 0.0557
2023-02-06 10:54:19 | Valid | Epoch[387/600] Iteration[007/008] Valid loss: 0.0543
2023-02-06 10:54:19 | Valid | Epoch[387/600] Iteration[008/008] Valid loss: 0.0550
2023-02-06 10:54:19 | Valid | Epoch[387/600] MIou: 0.8266836326770929
2023-02-06 10:54:19 | Valid | Epoch[387/600] Pixel Accuracy: 0.971441904703776
2023-02-06 10:54:19 | Valid | Epoch[387/600] Mean Pixel Accuracy: 0.8419026031620886
2023-02-06 10:54:19 | Stage | Epoch[387/600] Train loss:0.0263
2023-02-06 10:54:19 | Stage | Epoch[387/600] Valid loss:0.0550
2023-02-06 10:54:19 | Stage | Epoch[387/600] LR:0.01

2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[002/030] Train loss: 0.0226
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[003/030] Train loss: 0.0239
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:54:19 | Train | Epoch[388/600] Iteration[014/030] Train loss: 0.0265
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[016/030] Train loss: 0.0268
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[017/030] Train loss: 0.0266
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[019/030] Train loss: 0.0264
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[023/030] Train loss: 0.0259
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[025/030] Train loss: 0.0260
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[026/030] Train loss: 0.0260
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[028/030] Train loss: 0.0261
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[029/030] Train loss: 0.0261
2023-02-06 10:54:20 | Train | Epoch[388/600] Iteration[030/030] Train loss: 0.0260
2023-02-06 10:54:20 | Valid | Epoch[388/600] Iteration[001/008] Valid loss: 0.0761
2023-02-06 10:54:21 | Valid | Epoch[388/600] Iteration[002/008] Valid loss: 0.0629
2023-02-06 10:54:21 | Valid | Epoch[388/600] Iteration[003/008] Valid loss: 0.0560
2023-02-06 10:54:21 | Valid | Epoch[388/600] Iteration[004/008] Valid loss: 0.0545
2023-02-06 10:54:21 | Valid | Epoch[388/600] Iteration[005/008] Valid loss: 0.0551
2023-02-06 10:54:21 | Valid | Epoch[388/600] Iteration[006/008] Valid loss: 0.0567
2023-02-06 10:54:21 | Valid | Epoch[388/600] Iteration[007/008] Valid loss: 0.0599
2023-02-06 10:54:21 | Valid | Epoch[388/600] Iteration[008/008] Valid loss: 0.0590
2023-02-06 10:54:21 | Valid | Epoch[388/600] MIou: 0.9333886115283484
2023-02-06 10:54:21 | Valid | Epoch[388/600] Pixel Accuracy: 0.9882303873697916
2023-02-06 10:54:21 | Valid | Epoch[388/600] Mean Pixel Accuracy: 0.9721445085263543
2023-02-06 10:54:21 | Stage | Epoch[388/600] Train loss:0.0260
2023-02-06 10:54:21 | Stage | Epoch[388/600] Valid loss:0.0590
2023-02-06 10:54:21 | Stage | Epoch[388/600] LR:0.01

2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[001/030] Train loss: 0.0293
2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[002/030] Train loss: 0.0284
2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[003/030] Train loss: 0.0291
2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[004/030] Train loss: 0.0283
2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[005/030] Train loss: 0.0279
2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[006/030] Train loss: 0.0276
2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[007/030] Train loss: 0.0270
2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[010/030] Train loss: 0.0270
2023-02-06 10:54:21 | Train | Epoch[389/600] Iteration[011/030] Train loss: 0.0270
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[012/030] Train loss: 0.0272
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[013/030] Train loss: 0.0269
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[014/030] Train loss: 0.0269
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[015/030] Train loss: 0.0267
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[019/030] Train loss: 0.0266
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[020/030] Train loss: 0.0266
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[021/030] Train loss: 0.0264
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[023/030] Train loss: 0.0263
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[024/030] Train loss: 0.0261
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[025/030] Train loss: 0.0262
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[026/030] Train loss: 0.0261
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[028/030] Train loss: 0.0260
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[029/030] Train loss: 0.0259
2023-02-06 10:54:22 | Train | Epoch[389/600] Iteration[030/030] Train loss: 0.0260
2023-02-06 10:54:23 | Valid | Epoch[389/600] Iteration[001/008] Valid loss: 0.0868
2023-02-06 10:54:23 | Valid | Epoch[389/600] Iteration[002/008] Valid loss: 0.0850
2023-02-06 10:54:23 | Valid | Epoch[389/600] Iteration[003/008] Valid loss: 0.0874
2023-02-06 10:54:23 | Valid | Epoch[389/600] Iteration[004/008] Valid loss: 0.0866
2023-02-06 10:54:23 | Valid | Epoch[389/600] Iteration[005/008] Valid loss: 0.0881
2023-02-06 10:54:23 | Valid | Epoch[389/600] Iteration[006/008] Valid loss: 0.0861
2023-02-06 10:54:23 | Valid | Epoch[389/600] Iteration[007/008] Valid loss: 0.0836
2023-02-06 10:54:23 | Valid | Epoch[389/600] Iteration[008/008] Valid loss: 0.0857
2023-02-06 10:54:23 | Valid | Epoch[389/600] MIou: 0.7394426200932338
2023-02-06 10:54:23 | Valid | Epoch[389/600] Pixel Accuracy: 0.9570096333821615
2023-02-06 10:54:23 | Valid | Epoch[389/600] Mean Pixel Accuracy: 0.7620056596601388
2023-02-06 10:54:23 | Stage | Epoch[389/600] Train loss:0.0260
2023-02-06 10:54:23 | Stage | Epoch[389/600] Valid loss:0.0857
2023-02-06 10:54:23 | Stage | Epoch[389/600] LR:0.01

2023-02-06 10:54:23 | Train | Epoch[390/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 10:54:23 | Train | Epoch[390/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 10:54:23 | Train | Epoch[390/600] Iteration[003/030] Train loss: 0.0244
2023-02-06 10:54:23 | Train | Epoch[390/600] Iteration[004/030] Train loss: 0.0240
2023-02-06 10:54:23 | Train | Epoch[390/600] Iteration[005/030] Train loss: 0.0241
2023-02-06 10:54:23 | Train | Epoch[390/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 10:54:23 | Train | Epoch[390/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[010/030] Train loss: 0.0243
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:54:24 | Train | Epoch[390/600] Iteration[030/030] Train loss: 0.0255
2023-02-06 10:54:25 | Valid | Epoch[390/600] Iteration[001/008] Valid loss: 0.0636
2023-02-06 10:54:25 | Valid | Epoch[390/600] Iteration[002/008] Valid loss: 0.0523
2023-02-06 10:54:25 | Valid | Epoch[390/600] Iteration[003/008] Valid loss: 0.0494
2023-02-06 10:54:25 | Valid | Epoch[390/600] Iteration[004/008] Valid loss: 0.0476
2023-02-06 10:54:25 | Valid | Epoch[390/600] Iteration[005/008] Valid loss: 0.0498
2023-02-06 10:54:25 | Valid | Epoch[390/600] Iteration[006/008] Valid loss: 0.0529
2023-02-06 10:54:25 | Valid | Epoch[390/600] Iteration[007/008] Valid loss: 0.0547
2023-02-06 10:54:25 | Valid | Epoch[390/600] Iteration[008/008] Valid loss: 0.0530
2023-02-06 10:54:25 | Valid | Epoch[390/600] MIou: 0.935372820422761
2023-02-06 10:54:25 | Valid | Epoch[390/600] Pixel Accuracy: 0.988671620686849
2023-02-06 10:54:25 | Valid | Epoch[390/600] Mean Pixel Accuracy: 0.9702819926335442
2023-02-06 10:54:25 | Stage | Epoch[390/600] Train loss:0.0255
2023-02-06 10:54:25 | Stage | Epoch[390/600] Valid loss:0.0530
2023-02-06 10:54:25 | Stage | Epoch[390/600] LR:0.01

2023-02-06 10:54:25 | Train | Epoch[391/600] Iteration[001/030] Train loss: 0.0263
2023-02-06 10:54:25 | Train | Epoch[391/600] Iteration[002/030] Train loss: 0.0273
2023-02-06 10:54:25 | Train | Epoch[391/600] Iteration[003/030] Train loss: 0.0259
2023-02-06 10:54:25 | Train | Epoch[391/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 10:54:25 | Train | Epoch[391/600] Iteration[005/030] Train loss: 0.0265
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[006/030] Train loss: 0.0270
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[009/030] Train loss: 0.0263
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[014/030] Train loss: 0.0261
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[023/030] Train loss: 0.0259
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[025/030] Train loss: 0.0259
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[026/030] Train loss: 0.0259
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[028/030] Train loss: 0.0258
2023-02-06 10:54:26 | Train | Epoch[391/600] Iteration[029/030] Train loss: 0.0259
2023-02-06 10:54:27 | Train | Epoch[391/600] Iteration[030/030] Train loss: 0.0257
2023-02-06 10:54:27 | Valid | Epoch[391/600] Iteration[001/008] Valid loss: 0.1810
2023-02-06 10:54:27 | Valid | Epoch[391/600] Iteration[002/008] Valid loss: 0.1350
2023-02-06 10:54:27 | Valid | Epoch[391/600] Iteration[003/008] Valid loss: 0.1277
2023-02-06 10:54:27 | Valid | Epoch[391/600] Iteration[004/008] Valid loss: 0.1222
2023-02-06 10:54:27 | Valid | Epoch[391/600] Iteration[005/008] Valid loss: 0.1269
2023-02-06 10:54:27 | Valid | Epoch[391/600] Iteration[006/008] Valid loss: 0.1250
2023-02-06 10:54:27 | Valid | Epoch[391/600] Iteration[007/008] Valid loss: 0.1350
2023-02-06 10:54:27 | Valid | Epoch[391/600] Iteration[008/008] Valid loss: 0.1349
2023-02-06 10:54:27 | Valid | Epoch[391/600] MIou: 0.9094461724061738
2023-02-06 10:54:27 | Valid | Epoch[391/600] Pixel Accuracy: 0.982995351155599
2023-02-06 10:54:27 | Valid | Epoch[391/600] Mean Pixel Accuracy: 0.9773955938326258
2023-02-06 10:54:27 | Stage | Epoch[391/600] Train loss:0.0257
2023-02-06 10:54:27 | Stage | Epoch[391/600] Valid loss:0.1349
2023-02-06 10:54:27 | Stage | Epoch[391/600] LR:0.01

2023-02-06 10:54:27 | Train | Epoch[392/600] Iteration[001/030] Train loss: 0.0254
2023-02-06 10:54:27 | Train | Epoch[392/600] Iteration[002/030] Train loss: 0.0285
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[004/030] Train loss: 0.0278
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[006/030] Train loss: 0.0271
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[008/030] Train loss: 0.0268
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[009/030] Train loss: 0.0269
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[010/030] Train loss: 0.0275
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[011/030] Train loss: 0.0269
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[012/030] Train loss: 0.0266
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[013/030] Train loss: 0.0266
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[014/030] Train loss: 0.0265
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[015/030] Train loss: 0.0263
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[016/030] Train loss: 0.0264
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[017/030] Train loss: 0.0263
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[018/030] Train loss: 0.0264
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[019/030] Train loss: 0.0262
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[021/030] Train loss: 0.0260
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[022/030] Train loss: 0.0261
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[023/030] Train loss: 0.0261
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[024/030] Train loss: 0.0259
2023-02-06 10:54:28 | Train | Epoch[392/600] Iteration[025/030] Train loss: 0.0261
2023-02-06 10:54:29 | Train | Epoch[392/600] Iteration[026/030] Train loss: 0.0261
2023-02-06 10:54:29 | Train | Epoch[392/600] Iteration[027/030] Train loss: 0.0261
2023-02-06 10:54:29 | Train | Epoch[392/600] Iteration[028/030] Train loss: 0.0262
2023-02-06 10:54:29 | Train | Epoch[392/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:54:29 | Train | Epoch[392/600] Iteration[030/030] Train loss: 0.0263
2023-02-06 10:54:29 | Valid | Epoch[392/600] Iteration[001/008] Valid loss: 0.0422
2023-02-06 10:54:29 | Valid | Epoch[392/600] Iteration[002/008] Valid loss: 0.0399
2023-02-06 10:54:29 | Valid | Epoch[392/600] Iteration[003/008] Valid loss: 0.0400
2023-02-06 10:54:29 | Valid | Epoch[392/600] Iteration[004/008] Valid loss: 0.0391
2023-02-06 10:54:29 | Valid | Epoch[392/600] Iteration[005/008] Valid loss: 0.0395
2023-02-06 10:54:29 | Valid | Epoch[392/600] Iteration[006/008] Valid loss: 0.0389
2023-02-06 10:54:29 | Valid | Epoch[392/600] Iteration[007/008] Valid loss: 0.0380
2023-02-06 10:54:29 | Valid | Epoch[392/600] Iteration[008/008] Valid loss: 0.0386
2023-02-06 10:54:29 | Valid | Epoch[392/600] MIou: 0.8602987026098765
2023-02-06 10:54:29 | Valid | Epoch[392/600] Pixel Accuracy: 0.9769503275553385
2023-02-06 10:54:29 | Valid | Epoch[392/600] Mean Pixel Accuracy: 0.8733165582494413
2023-02-06 10:54:29 | Stage | Epoch[392/600] Train loss:0.0263
2023-02-06 10:54:29 | Stage | Epoch[392/600] Valid loss:0.0386
2023-02-06 10:54:29 | Stage | Epoch[392/600] LR:0.01

2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[001/030] Train loss: 0.0271
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[004/030] Train loss: 0.0261
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[006/030] Train loss: 0.0246
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[012/030] Train loss: 0.0244
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[013/030] Train loss: 0.0245
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:54:30 | Train | Epoch[393/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:54:31 | Train | Epoch[393/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:54:31 | Train | Epoch[393/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 10:54:31 | Train | Epoch[393/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:54:31 | Train | Epoch[393/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:54:31 | Train | Epoch[393/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 10:54:31 | Train | Epoch[393/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:54:31 | Train | Epoch[393/600] Iteration[029/030] Train loss: 0.0256
2023-02-06 10:54:31 | Train | Epoch[393/600] Iteration[030/030] Train loss: 0.0256
2023-02-06 10:54:31 | Valid | Epoch[393/600] Iteration[001/008] Valid loss: 0.0709
2023-02-06 10:54:31 | Valid | Epoch[393/600] Iteration[002/008] Valid loss: 0.0603
2023-02-06 10:54:31 | Valid | Epoch[393/600] Iteration[003/008] Valid loss: 0.0549
2023-02-06 10:54:31 | Valid | Epoch[393/600] Iteration[004/008] Valid loss: 0.0530
2023-02-06 10:54:31 | Valid | Epoch[393/600] Iteration[005/008] Valid loss: 0.0550
2023-02-06 10:54:31 | Valid | Epoch[393/600] Iteration[006/008] Valid loss: 0.0572
2023-02-06 10:54:31 | Valid | Epoch[393/600] Iteration[007/008] Valid loss: 0.0595
2023-02-06 10:54:31 | Valid | Epoch[393/600] Iteration[008/008] Valid loss: 0.0581
2023-02-06 10:54:31 | Valid | Epoch[393/600] MIou: 0.932262778617344
2023-02-06 10:54:31 | Valid | Epoch[393/600] Pixel Accuracy: 0.9880714416503906
2023-02-06 10:54:31 | Valid | Epoch[393/600] Mean Pixel Accuracy: 0.9694321899740994
2023-02-06 10:54:31 | Stage | Epoch[393/600] Train loss:0.0256
2023-02-06 10:54:31 | Stage | Epoch[393/600] Valid loss:0.0581
2023-02-06 10:54:31 | Stage | Epoch[393/600] LR:0.01

2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[001/030] Train loss: 0.0266
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[002/030] Train loss: 0.0286
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[003/030] Train loss: 0.0273
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[004/030] Train loss: 0.0264
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[005/030] Train loss: 0.0253
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 10:54:32 | Train | Epoch[394/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[023/030] Train loss: 0.0259
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[024/030] Train loss: 0.0260
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[025/030] Train loss: 0.0259
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[026/030] Train loss: 0.0260
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[028/030] Train loss: 0.0259
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[029/030] Train loss: 0.0259
2023-02-06 10:54:33 | Train | Epoch[394/600] Iteration[030/030] Train loss: 0.0259
2023-02-06 10:54:33 | Valid | Epoch[394/600] Iteration[001/008] Valid loss: 1.0354
2023-02-06 10:54:33 | Valid | Epoch[394/600] Iteration[002/008] Valid loss: 1.0965
2023-02-06 10:54:33 | Valid | Epoch[394/600] Iteration[003/008] Valid loss: 1.0958
2023-02-06 10:54:33 | Valid | Epoch[394/600] Iteration[004/008] Valid loss: 1.1223
2023-02-06 10:54:33 | Valid | Epoch[394/600] Iteration[005/008] Valid loss: 1.1525
2023-02-06 10:54:33 | Valid | Epoch[394/600] Iteration[006/008] Valid loss: 1.1457
2023-02-06 10:54:33 | Valid | Epoch[394/600] Iteration[007/008] Valid loss: 1.2106
2023-02-06 10:54:33 | Valid | Epoch[394/600] Iteration[008/008] Valid loss: 1.2520
2023-02-06 10:54:34 | Valid | Epoch[394/600] MIou: 0.8133407496509233
2023-02-06 10:54:34 | Valid | Epoch[394/600] Pixel Accuracy: 0.9565900166829427
2023-02-06 10:54:34 | Valid | Epoch[394/600] Mean Pixel Accuracy: 0.974079368536509
2023-02-06 10:54:34 | Stage | Epoch[394/600] Train loss:0.0259
2023-02-06 10:54:34 | Stage | Epoch[394/600] Valid loss:1.2520
2023-02-06 10:54:34 | Stage | Epoch[394/600] LR:0.01

2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[001/030] Train loss: 0.0353
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[002/030] Train loss: 0.0291
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[003/030] Train loss: 0.0284
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[004/030] Train loss: 0.0276
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[005/030] Train loss: 0.0271
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[009/030] Train loss: 0.0260
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[010/030] Train loss: 0.0264
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[015/030] Train loss: 0.0261
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 10:54:34 | Train | Epoch[395/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[022/030] Train loss: 0.0256
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[023/030] Train loss: 0.0258
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[024/030] Train loss: 0.0259
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[025/030] Train loss: 0.0258
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[026/030] Train loss: 0.0258
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[027/030] Train loss: 0.0259
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[028/030] Train loss: 0.0259
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[029/030] Train loss: 0.0260
2023-02-06 10:54:35 | Train | Epoch[395/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:54:35 | Valid | Epoch[395/600] Iteration[001/008] Valid loss: 0.0927
2023-02-06 10:54:35 | Valid | Epoch[395/600] Iteration[002/008] Valid loss: 0.0723
2023-02-06 10:54:35 | Valid | Epoch[395/600] Iteration[003/008] Valid loss: 0.0661
2023-02-06 10:54:35 | Valid | Epoch[395/600] Iteration[004/008] Valid loss: 0.0636
2023-02-06 10:54:35 | Valid | Epoch[395/600] Iteration[005/008] Valid loss: 0.0660
2023-02-06 10:54:35 | Valid | Epoch[395/600] Iteration[006/008] Valid loss: 0.0681
2023-02-06 10:54:36 | Valid | Epoch[395/600] Iteration[007/008] Valid loss: 0.0726
2023-02-06 10:54:36 | Valid | Epoch[395/600] Iteration[008/008] Valid loss: 0.0711
2023-02-06 10:54:36 | Valid | Epoch[395/600] MIou: 0.9292264080839605
2023-02-06 10:54:36 | Valid | Epoch[395/600] Pixel Accuracy: 0.9872487386067709
2023-02-06 10:54:36 | Valid | Epoch[395/600] Mean Pixel Accuracy: 0.9774318458194922
2023-02-06 10:54:36 | Stage | Epoch[395/600] Train loss:0.0262
2023-02-06 10:54:36 | Stage | Epoch[395/600] Valid loss:0.0711
2023-02-06 10:54:36 | Stage | Epoch[395/600] LR:0.01

2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[001/030] Train loss: 0.0299
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[002/030] Train loss: 0.0299
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[003/030] Train loss: 0.0278
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[004/030] Train loss: 0.0272
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[006/030] Train loss: 0.0270
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[007/030] Train loss: 0.0272
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[008/030] Train loss: 0.0273
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[009/030] Train loss: 0.0273
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[010/030] Train loss: 0.0276
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[011/030] Train loss: 0.0273
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[012/030] Train loss: 0.0271
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[013/030] Train loss: 0.0275
2023-02-06 10:54:36 | Train | Epoch[396/600] Iteration[014/030] Train loss: 0.0272
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[015/030] Train loss: 0.0275
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[016/030] Train loss: 0.0274
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[017/030] Train loss: 0.0274
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[018/030] Train loss: 0.0272
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[019/030] Train loss: 0.0268
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[020/030] Train loss: 0.0267
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[021/030] Train loss: 0.0268
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[022/030] Train loss: 0.0267
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[024/030] Train loss: 0.0266
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[025/030] Train loss: 0.0265
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[029/030] Train loss: 0.0262
2023-02-06 10:54:37 | Train | Epoch[396/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:54:37 | Valid | Epoch[396/600] Iteration[001/008] Valid loss: 0.0376
2023-02-06 10:54:38 | Valid | Epoch[396/600] Iteration[002/008] Valid loss: 0.0328
2023-02-06 10:54:38 | Valid | Epoch[396/600] Iteration[003/008] Valid loss: 0.0323
2023-02-06 10:54:38 | Valid | Epoch[396/600] Iteration[004/008] Valid loss: 0.0311
2023-02-06 10:54:38 | Valid | Epoch[396/600] Iteration[005/008] Valid loss: 0.0318
2023-02-06 10:54:38 | Valid | Epoch[396/600] Iteration[006/008] Valid loss: 0.0313
2023-02-06 10:54:38 | Valid | Epoch[396/600] Iteration[007/008] Valid loss: 0.0312
2023-02-06 10:54:38 | Valid | Epoch[396/600] Iteration[008/008] Valid loss: 0.0312
2023-02-06 10:54:38 | Valid | Epoch[396/600] MIou: 0.9108974127732865
2023-02-06 10:54:38 | Valid | Epoch[396/600] Pixel Accuracy: 0.9851938883463541
2023-02-06 10:54:38 | Valid | Epoch[396/600] Mean Pixel Accuracy: 0.9229219828189232
2023-02-06 10:54:38 | Stage | Epoch[396/600] Train loss:0.0262
2023-02-06 10:54:38 | Stage | Epoch[396/600] Valid loss:0.0312
2023-02-06 10:54:38 | Stage | Epoch[396/600] LR:0.01

2023-02-06 10:54:38 | Train | Epoch[397/600] Iteration[001/030] Train loss: 0.0291
2023-02-06 10:54:38 | Train | Epoch[397/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 10:54:38 | Train | Epoch[397/600] Iteration[003/030] Train loss: 0.0267
2023-02-06 10:54:38 | Train | Epoch[397/600] Iteration[004/030] Train loss: 0.0264
2023-02-06 10:54:38 | Train | Epoch[397/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 10:54:38 | Train | Epoch[397/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:54:38 | Train | Epoch[397/600] Iteration[007/030] Train loss: 0.0254
2023-02-06 10:54:38 | Train | Epoch[397/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 10:54:38 | Train | Epoch[397/600] Iteration[009/030] Train loss: 0.0247
2023-02-06 10:54:38 | Train | Epoch[397/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[021/030] Train loss: 0.0257
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[024/030] Train loss: 0.0259
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[025/030] Train loss: 0.0258
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[027/030] Train loss: 0.0256
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[028/030] Train loss: 0.0257
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[029/030] Train loss: 0.0258
2023-02-06 10:54:39 | Train | Epoch[397/600] Iteration[030/030] Train loss: 0.0258
2023-02-06 10:54:40 | Valid | Epoch[397/600] Iteration[001/008] Valid loss: 0.0373
2023-02-06 10:54:40 | Valid | Epoch[397/600] Iteration[002/008] Valid loss: 0.0348
2023-02-06 10:54:40 | Valid | Epoch[397/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 10:54:40 | Valid | Epoch[397/600] Iteration[004/008] Valid loss: 0.0337
2023-02-06 10:54:40 | Valid | Epoch[397/600] Iteration[005/008] Valid loss: 0.0342
2023-02-06 10:54:40 | Valid | Epoch[397/600] Iteration[006/008] Valid loss: 0.0338
2023-02-06 10:54:40 | Valid | Epoch[397/600] Iteration[007/008] Valid loss: 0.0331
2023-02-06 10:54:40 | Valid | Epoch[397/600] Iteration[008/008] Valid loss: 0.0335
2023-02-06 10:54:40 | Valid | Epoch[397/600] MIou: 0.8861343278638636
2023-02-06 10:54:40 | Valid | Epoch[397/600] Pixel Accuracy: 0.9811846415201823
2023-02-06 10:54:40 | Valid | Epoch[397/600] Mean Pixel Accuracy: 0.897715099127192
2023-02-06 10:54:40 | Stage | Epoch[397/600] Train loss:0.0258
2023-02-06 10:54:40 | Stage | Epoch[397/600] Valid loss:0.0335
2023-02-06 10:54:40 | Stage | Epoch[397/600] LR:0.01

2023-02-06 10:54:40 | Train | Epoch[398/600] Iteration[001/030] Train loss: 0.0259
2023-02-06 10:54:40 | Train | Epoch[398/600] Iteration[002/030] Train loss: 0.0247
2023-02-06 10:54:40 | Train | Epoch[398/600] Iteration[003/030] Train loss: 0.0251
2023-02-06 10:54:40 | Train | Epoch[398/600] Iteration[004/030] Train loss: 0.0262
2023-02-06 10:54:40 | Train | Epoch[398/600] Iteration[005/030] Train loss: 0.0275
2023-02-06 10:54:40 | Train | Epoch[398/600] Iteration[006/030] Train loss: 0.0265
2023-02-06 10:54:40 | Train | Epoch[398/600] Iteration[007/030] Train loss: 0.0265
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[008/030] Train loss: 0.0273
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[009/030] Train loss: 0.0271
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[010/030] Train loss: 0.0269
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[015/030] Train loss: 0.0263
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[017/030] Train loss: 0.0266
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[019/030] Train loss: 0.0264
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[020/030] Train loss: 0.0263
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[021/030] Train loss: 0.0262
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[022/030] Train loss: 0.0263
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[023/030] Train loss: 0.0262
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[024/030] Train loss: 0.0262
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[027/030] Train loss: 0.0263
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[029/030] Train loss: 0.0263
2023-02-06 10:54:41 | Train | Epoch[398/600] Iteration[030/030] Train loss: 0.0262
2023-02-06 10:54:42 | Valid | Epoch[398/600] Iteration[001/008] Valid loss: 0.0400
2023-02-06 10:54:42 | Valid | Epoch[398/600] Iteration[002/008] Valid loss: 0.0402
2023-02-06 10:54:42 | Valid | Epoch[398/600] Iteration[003/008] Valid loss: 0.0411
2023-02-06 10:54:42 | Valid | Epoch[398/600] Iteration[004/008] Valid loss: 0.0403
2023-02-06 10:54:42 | Valid | Epoch[398/600] Iteration[005/008] Valid loss: 0.0409
2023-02-06 10:54:42 | Valid | Epoch[398/600] Iteration[006/008] Valid loss: 0.0403
2023-02-06 10:54:42 | Valid | Epoch[398/600] Iteration[007/008] Valid loss: 0.0392
2023-02-06 10:54:42 | Valid | Epoch[398/600] Iteration[008/008] Valid loss: 0.0399
2023-02-06 10:54:42 | Valid | Epoch[398/600] MIou: 0.8522811283125883
2023-02-06 10:54:42 | Valid | Epoch[398/600] Pixel Accuracy: 0.9756253560384115
2023-02-06 10:54:42 | Valid | Epoch[398/600] Mean Pixel Accuracy: 0.8659625046649464
2023-02-06 10:54:42 | Stage | Epoch[398/600] Train loss:0.0262
2023-02-06 10:54:42 | Stage | Epoch[398/600] Valid loss:0.0399
2023-02-06 10:54:42 | Stage | Epoch[398/600] LR:0.01

2023-02-06 10:54:42 | Train | Epoch[399/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 10:54:42 | Train | Epoch[399/600] Iteration[002/030] Train loss: 0.0274
2023-02-06 10:54:42 | Train | Epoch[399/600] Iteration[003/030] Train loss: 0.0292
2023-02-06 10:54:42 | Train | Epoch[399/600] Iteration[004/030] Train loss: 0.0291
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[005/030] Train loss: 0.0282
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[006/030] Train loss: 0.0278
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[007/030] Train loss: 0.0284
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[008/030] Train loss: 0.0277
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[009/030] Train loss: 0.0277
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[010/030] Train loss: 0.0274
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[011/030] Train loss: 0.0282
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[012/030] Train loss: 0.0275
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[013/030] Train loss: 0.0276
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[014/030] Train loss: 0.0273
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[015/030] Train loss: 0.0269
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[016/030] Train loss: 0.0267
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[017/030] Train loss: 0.0266
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[018/030] Train loss: 0.0266
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[019/030] Train loss: 0.0267
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[020/030] Train loss: 0.0267
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[021/030] Train loss: 0.0266
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[022/030] Train loss: 0.0266
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[023/030] Train loss: 0.0267
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[024/030] Train loss: 0.0264
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[025/030] Train loss: 0.0264
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[026/030] Train loss: 0.0263
2023-02-06 10:54:43 | Train | Epoch[399/600] Iteration[027/030] Train loss: 0.0262
2023-02-06 10:54:44 | Train | Epoch[399/600] Iteration[028/030] Train loss: 0.0263
2023-02-06 10:54:44 | Train | Epoch[399/600] Iteration[029/030] Train loss: 0.0264
2023-02-06 10:54:44 | Train | Epoch[399/600] Iteration[030/030] Train loss: 0.0266
2023-02-06 10:54:44 | Valid | Epoch[399/600] Iteration[001/008] Valid loss: 0.0447
2023-02-06 10:54:44 | Valid | Epoch[399/600] Iteration[002/008] Valid loss: 0.0431
2023-02-06 10:54:44 | Valid | Epoch[399/600] Iteration[003/008] Valid loss: 0.0433
2023-02-06 10:54:44 | Valid | Epoch[399/600] Iteration[004/008] Valid loss: 0.0424
2023-02-06 10:54:44 | Valid | Epoch[399/600] Iteration[005/008] Valid loss: 0.0428
2023-02-06 10:54:44 | Valid | Epoch[399/600] Iteration[006/008] Valid loss: 0.0420
2023-02-06 10:54:44 | Valid | Epoch[399/600] Iteration[007/008] Valid loss: 0.0409
2023-02-06 10:54:44 | Valid | Epoch[399/600] Iteration[008/008] Valid loss: 0.0416
2023-02-06 10:54:44 | Valid | Epoch[399/600] MIou: 0.856615009118896
2023-02-06 10:54:44 | Valid | Epoch[399/600] Pixel Accuracy: 0.9763399759928385
2023-02-06 10:54:44 | Valid | Epoch[399/600] Mean Pixel Accuracy: 0.8699630185600769
2023-02-06 10:54:44 | Stage | Epoch[399/600] Train loss:0.0266
2023-02-06 10:54:44 | Stage | Epoch[399/600] Valid loss:0.0416
2023-02-06 10:54:44 | Stage | Epoch[399/600] LR:0.01

2023-02-06 10:54:44 | Train | Epoch[400/600] Iteration[001/030] Train loss: 0.0253
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[002/030] Train loss: 0.0265
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[009/030] Train loss: 0.0247
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[015/030] Train loss: 0.0260
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[016/030] Train loss: 0.0260
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[021/030] Train loss: 0.0260
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[022/030] Train loss: 0.0260
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:54:45 | Train | Epoch[400/600] Iteration[024/030] Train loss: 0.0259
2023-02-06 10:54:46 | Train | Epoch[400/600] Iteration[025/030] Train loss: 0.0258
2023-02-06 10:54:46 | Train | Epoch[400/600] Iteration[026/030] Train loss: 0.0258
2023-02-06 10:54:46 | Train | Epoch[400/600] Iteration[027/030] Train loss: 0.0258
2023-02-06 10:54:46 | Train | Epoch[400/600] Iteration[028/030] Train loss: 0.0259
2023-02-06 10:54:46 | Train | Epoch[400/600] Iteration[029/030] Train loss: 0.0260
2023-02-06 10:54:46 | Train | Epoch[400/600] Iteration[030/030] Train loss: 0.0261
2023-02-06 10:54:46 | Valid | Epoch[400/600] Iteration[001/008] Valid loss: 0.0462
2023-02-06 10:54:46 | Valid | Epoch[400/600] Iteration[002/008] Valid loss: 0.0371
2023-02-06 10:54:46 | Valid | Epoch[400/600] Iteration[003/008] Valid loss: 0.0353
2023-02-06 10:54:46 | Valid | Epoch[400/600] Iteration[004/008] Valid loss: 0.0335
2023-02-06 10:54:46 | Valid | Epoch[400/600] Iteration[005/008] Valid loss: 0.0344
2023-02-06 10:54:46 | Valid | Epoch[400/600] Iteration[006/008] Valid loss: 0.0343
2023-02-06 10:54:46 | Valid | Epoch[400/600] Iteration[007/008] Valid loss: 0.0355
2023-02-06 10:54:46 | Valid | Epoch[400/600] Iteration[008/008] Valid loss: 0.0351
2023-02-06 10:54:46 | Valid | Epoch[400/600] MIou: 0.9334308475761106
2023-02-06 10:54:46 | Valid | Epoch[400/600] Pixel Accuracy: 0.9886474609375
2023-02-06 10:54:46 | Valid | Epoch[400/600] Mean Pixel Accuracy: 0.9555461385538644
2023-02-06 10:54:46 | Stage | Epoch[400/600] Train loss:0.0261
2023-02-06 10:54:46 | Stage | Epoch[400/600] Valid loss:0.0351
2023-02-06 10:54:46 | Stage | Epoch[400/600] LR:0.01

2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[002/030] Train loss: 0.0241
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[003/030] Train loss: 0.0231
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[006/030] Train loss: 0.0256
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:54:47 | Train | Epoch[401/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:54:48 | Train | Epoch[401/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:54:48 | Train | Epoch[401/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:54:48 | Train | Epoch[401/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:54:48 | Train | Epoch[401/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:54:48 | Train | Epoch[401/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:54:48 | Train | Epoch[401/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:54:48 | Train | Epoch[401/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:54:48 | Valid | Epoch[401/600] Iteration[001/008] Valid loss: 0.0336
2023-02-06 10:54:48 | Valid | Epoch[401/600] Iteration[002/008] Valid loss: 0.0302
2023-02-06 10:54:48 | Valid | Epoch[401/600] Iteration[003/008] Valid loss: 0.0298
2023-02-06 10:54:48 | Valid | Epoch[401/600] Iteration[004/008] Valid loss: 0.0289
2023-02-06 10:54:48 | Valid | Epoch[401/600] Iteration[005/008] Valid loss: 0.0294
2023-02-06 10:54:48 | Valid | Epoch[401/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 10:54:48 | Valid | Epoch[401/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:54:48 | Valid | Epoch[401/600] Iteration[008/008] Valid loss: 0.0292
2023-02-06 10:54:48 | Valid | Epoch[401/600] MIou: 0.9116165447520346
2023-02-06 10:54:48 | Valid | Epoch[401/600] Pixel Accuracy: 0.985327402750651
2023-02-06 10:54:48 | Valid | Epoch[401/600] Mean Pixel Accuracy: 0.9231855821751388
2023-02-06 10:54:48 | Stage | Epoch[401/600] Train loss:0.0252
2023-02-06 10:54:48 | Stage | Epoch[401/600] Valid loss:0.0292
2023-02-06 10:54:48 | Stage | Epoch[401/600] LR:0.001

2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[001/030] Train loss: 0.0252
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[004/030] Train loss: 0.0263
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[005/030] Train loss: 0.0264
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[007/030] Train loss: 0.0270
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[008/030] Train loss: 0.0264
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:54:49 | Train | Epoch[402/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:54:50 | Train | Epoch[402/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:54:50 | Valid | Epoch[402/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 10:54:50 | Valid | Epoch[402/600] Iteration[002/008] Valid loss: 0.0309
2023-02-06 10:54:50 | Valid | Epoch[402/600] Iteration[003/008] Valid loss: 0.0310
2023-02-06 10:54:50 | Valid | Epoch[402/600] Iteration[004/008] Valid loss: 0.0300
2023-02-06 10:54:50 | Valid | Epoch[402/600] Iteration[005/008] Valid loss: 0.0305
2023-02-06 10:54:50 | Valid | Epoch[402/600] Iteration[006/008] Valid loss: 0.0302
2023-02-06 10:54:51 | Valid | Epoch[402/600] Iteration[007/008] Valid loss: 0.0298
2023-02-06 10:54:51 | Valid | Epoch[402/600] Iteration[008/008] Valid loss: 0.0300
2023-02-06 10:54:51 | Valid | Epoch[402/600] MIou: 0.9035374985249851
2023-02-06 10:54:51 | Valid | Epoch[402/600] Pixel Accuracy: 0.9840278625488281
2023-02-06 10:54:51 | Valid | Epoch[402/600] Mean Pixel Accuracy: 0.914615455252701
2023-02-06 10:54:51 | Stage | Epoch[402/600] Train loss:0.0253
2023-02-06 10:54:51 | Stage | Epoch[402/600] Valid loss:0.0300
2023-02-06 10:54:51 | Stage | Epoch[402/600] LR:0.001

2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[001/030] Train loss: 0.0201
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[006/030] Train loss: 0.0236
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[010/030] Train loss: 0.0240
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[012/030] Train loss: 0.0245
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 10:54:51 | Train | Epoch[403/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[015/030] Train loss: 0.0245
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:54:52 | Train | Epoch[403/600] Iteration[030/030] Train loss: 0.0255
2023-02-06 10:54:52 | Valid | Epoch[403/600] Iteration[001/008] Valid loss: 0.0338
2023-02-06 10:54:53 | Valid | Epoch[403/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:54:53 | Valid | Epoch[403/600] Iteration[003/008] Valid loss: 0.0300
2023-02-06 10:54:53 | Valid | Epoch[403/600] Iteration[004/008] Valid loss: 0.0290
2023-02-06 10:54:53 | Valid | Epoch[403/600] Iteration[005/008] Valid loss: 0.0295
2023-02-06 10:54:53 | Valid | Epoch[403/600] Iteration[006/008] Valid loss: 0.0293
2023-02-06 10:54:53 | Valid | Epoch[403/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:54:53 | Valid | Epoch[403/600] Iteration[008/008] Valid loss: 0.0292
2023-02-06 10:54:53 | Valid | Epoch[403/600] MIou: 0.9106968602812611
2023-02-06 10:54:53 | Valid | Epoch[403/600] Pixel Accuracy: 0.9851862589518229
2023-02-06 10:54:53 | Valid | Epoch[403/600] Mean Pixel Accuracy: 0.9220047614805635
2023-02-06 10:54:53 | Stage | Epoch[403/600] Train loss:0.0255
2023-02-06 10:54:53 | Stage | Epoch[403/600] Valid loss:0.0292
2023-02-06 10:54:53 | Stage | Epoch[403/600] LR:0.001

2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[002/030] Train loss: 0.0259
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[003/030] Train loss: 0.0249
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[006/030] Train loss: 0.0253
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:54:53 | Train | Epoch[404/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[017/030] Train loss: 0.0259
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[023/030] Train loss: 0.0258
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[025/030] Train loss: 0.0258
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[026/030] Train loss: 0.0257
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[027/030] Train loss: 0.0256
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:54:54 | Train | Epoch[404/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:54:55 | Valid | Epoch[404/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:54:55 | Valid | Epoch[404/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:54:55 | Valid | Epoch[404/600] Iteration[003/008] Valid loss: 0.0299
2023-02-06 10:54:55 | Valid | Epoch[404/600] Iteration[004/008] Valid loss: 0.0289
2023-02-06 10:54:55 | Valid | Epoch[404/600] Iteration[005/008] Valid loss: 0.0294
2023-02-06 10:54:55 | Valid | Epoch[404/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 10:54:55 | Valid | Epoch[404/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:54:55 | Valid | Epoch[404/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 10:54:55 | Valid | Epoch[404/600] MIou: 0.9115691527973195
2023-02-06 10:54:55 | Valid | Epoch[404/600] Pixel Accuracy: 0.9853235880533854
2023-02-06 10:54:55 | Valid | Epoch[404/600] Mean Pixel Accuracy: 0.9230249736670267
2023-02-06 10:54:55 | Stage | Epoch[404/600] Train loss:0.0253
2023-02-06 10:54:55 | Stage | Epoch[404/600] Valid loss:0.0291
2023-02-06 10:54:55 | Stage | Epoch[404/600] LR:0.001

2023-02-06 10:54:55 | Train | Epoch[405/600] Iteration[001/030] Train loss: 0.0233
2023-02-06 10:54:55 | Train | Epoch[405/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 10:54:55 | Train | Epoch[405/600] Iteration[003/030] Train loss: 0.0249
2023-02-06 10:54:55 | Train | Epoch[405/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 10:54:55 | Train | Epoch[405/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 10:54:55 | Train | Epoch[405/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 10:54:55 | Train | Epoch[405/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:54:55 | Train | Epoch[405/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:54:55 | Train | Epoch[405/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:54:55 | Train | Epoch[405/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:54:56 | Train | Epoch[405/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:54:57 | Valid | Epoch[405/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:54:57 | Valid | Epoch[405/600] Iteration[002/008] Valid loss: 0.0308
2023-02-06 10:54:57 | Valid | Epoch[405/600] Iteration[003/008] Valid loss: 0.0308
2023-02-06 10:54:57 | Valid | Epoch[405/600] Iteration[004/008] Valid loss: 0.0297
2023-02-06 10:54:57 | Valid | Epoch[405/600] Iteration[005/008] Valid loss: 0.0302
2023-02-06 10:54:57 | Valid | Epoch[405/600] Iteration[006/008] Valid loss: 0.0300
2023-02-06 10:54:57 | Valid | Epoch[405/600] Iteration[007/008] Valid loss: 0.0296
2023-02-06 10:54:57 | Valid | Epoch[405/600] Iteration[008/008] Valid loss: 0.0298
2023-02-06 10:54:57 | Valid | Epoch[405/600] MIou: 0.9049301699541787
2023-02-06 10:54:57 | Valid | Epoch[405/600] Pixel Accuracy: 0.9842580159505209
2023-02-06 10:54:57 | Valid | Epoch[405/600] Mean Pixel Accuracy: 0.9159149446078112
2023-02-06 10:54:57 | Stage | Epoch[405/600] Train loss:0.0250
2023-02-06 10:54:57 | Stage | Epoch[405/600] Valid loss:0.0298
2023-02-06 10:54:57 | Stage | Epoch[405/600] LR:0.001

2023-02-06 10:54:57 | Train | Epoch[406/600] Iteration[001/030] Train loss: 0.0276
2023-02-06 10:54:57 | Train | Epoch[406/600] Iteration[002/030] Train loss: 0.0251
2023-02-06 10:54:57 | Train | Epoch[406/600] Iteration[003/030] Train loss: 0.0249
2023-02-06 10:54:57 | Train | Epoch[406/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:54:57 | Train | Epoch[406/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[009/030] Train loss: 0.0253
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:54:58 | Train | Epoch[406/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:54:59 | Train | Epoch[406/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:54:59 | Train | Epoch[406/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:54:59 | Valid | Epoch[406/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:54:59 | Valid | Epoch[406/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:54:59 | Valid | Epoch[406/600] Iteration[003/008] Valid loss: 0.0297
2023-02-06 10:54:59 | Valid | Epoch[406/600] Iteration[004/008] Valid loss: 0.0286
2023-02-06 10:54:59 | Valid | Epoch[406/600] Iteration[005/008] Valid loss: 0.0293
2023-02-06 10:54:59 | Valid | Epoch[406/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:54:59 | Valid | Epoch[406/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:54:59 | Valid | Epoch[406/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:54:59 | Valid | Epoch[406/600] MIou: 0.9165977273721675
2023-02-06 10:54:59 | Valid | Epoch[406/600] Pixel Accuracy: 0.9861361185709635
2023-02-06 10:54:59 | Valid | Epoch[406/600] Mean Pixel Accuracy: 0.9283664191004017
2023-02-06 10:54:59 | Stage | Epoch[406/600] Train loss:0.0252
2023-02-06 10:54:59 | Stage | Epoch[406/600] Valid loss:0.0290
2023-02-06 10:54:59 | Stage | Epoch[406/600] LR:0.001

2023-02-06 10:54:59 | Train | Epoch[407/600] Iteration[001/030] Train loss: 0.0285
2023-02-06 10:54:59 | Train | Epoch[407/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[003/030] Train loss: 0.0246
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[007/030] Train loss: 0.0248
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 10:55:00 | Train | Epoch[407/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:55:01 | Train | Epoch[407/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:55:01 | Train | Epoch[407/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:55:01 | Train | Epoch[407/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:55:01 | Train | Epoch[407/600] Iteration[030/030] Train loss: 0.0256
2023-02-06 10:55:01 | Valid | Epoch[407/600] Iteration[001/008] Valid loss: 0.0372
2023-02-06 10:55:01 | Valid | Epoch[407/600] Iteration[002/008] Valid loss: 0.0315
2023-02-06 10:55:01 | Valid | Epoch[407/600] Iteration[003/008] Valid loss: 0.0305
2023-02-06 10:55:01 | Valid | Epoch[407/600] Iteration[004/008] Valid loss: 0.0293
2023-02-06 10:55:01 | Valid | Epoch[407/600] Iteration[005/008] Valid loss: 0.0302
2023-02-06 10:55:01 | Valid | Epoch[407/600] Iteration[006/008] Valid loss: 0.0304
2023-02-06 10:55:01 | Valid | Epoch[407/600] Iteration[007/008] Valid loss: 0.0309
2023-02-06 10:55:01 | Valid | Epoch[407/600] Iteration[008/008] Valid loss: 0.0306
2023-02-06 10:55:01 | Valid | Epoch[407/600] MIou: 0.9323322210042587
2023-02-06 10:55:01 | Valid | Epoch[407/600] Pixel Accuracy: 0.988623301188151
2023-02-06 10:55:01 | Valid | Epoch[407/600] Mean Pixel Accuracy: 0.9480384219979554
2023-02-06 10:55:01 | Stage | Epoch[407/600] Train loss:0.0256
2023-02-06 10:55:01 | Stage | Epoch[407/600] Valid loss:0.0306
2023-02-06 10:55:01 | Stage | Epoch[407/600] LR:0.001

2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[001/030] Train loss: 0.0271
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[002/030] Train loss: 0.0279
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[003/030] Train loss: 0.0288
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[004/030] Train loss: 0.0274
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[005/030] Train loss: 0.0264
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[006/030] Train loss: 0.0264
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:55:02 | Train | Epoch[408/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:55:03 | Train | Epoch[408/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:55:03 | Train | Epoch[408/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 10:55:03 | Train | Epoch[408/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 10:55:03 | Train | Epoch[408/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:55:03 | Train | Epoch[408/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:55:03 | Train | Epoch[408/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:55:03 | Train | Epoch[408/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:55:03 | Train | Epoch[408/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:55:03 | Valid | Epoch[408/600] Iteration[001/008] Valid loss: 0.0413
2023-02-06 10:55:03 | Valid | Epoch[408/600] Iteration[002/008] Valid loss: 0.0346
2023-02-06 10:55:03 | Valid | Epoch[408/600] Iteration[003/008] Valid loss: 0.0329
2023-02-06 10:55:03 | Valid | Epoch[408/600] Iteration[004/008] Valid loss: 0.0317
2023-02-06 10:55:03 | Valid | Epoch[408/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 10:55:03 | Valid | Epoch[408/600] Iteration[006/008] Valid loss: 0.0330
2023-02-06 10:55:03 | Valid | Epoch[408/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 10:55:03 | Valid | Epoch[408/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 10:55:03 | Valid | Epoch[408/600] MIou: 0.9362991168249943
2023-02-06 10:55:03 | Valid | Epoch[408/600] Pixel Accuracy: 0.9891980489095052
2023-02-06 10:55:03 | Valid | Epoch[408/600] Mean Pixel Accuracy: 0.9556712319829492
2023-02-06 10:55:03 | Stage | Epoch[408/600] Train loss:0.0250
2023-02-06 10:55:03 | Stage | Epoch[408/600] Valid loss:0.0334
2023-02-06 10:55:03 | Stage | Epoch[408/600] LR:0.001

2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[001/030] Train loss: 0.0256
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[002/030] Train loss: 0.0268
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[003/030] Train loss: 0.0274
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[004/030] Train loss: 0.0285
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[005/030] Train loss: 0.0276
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[007/030] Train loss: 0.0261
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:55:04 | Train | Epoch[409/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:55:05 | Train | Epoch[409/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 10:55:05 | Train | Epoch[409/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:55:05 | Train | Epoch[409/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:55:05 | Train | Epoch[409/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 10:55:05 | Train | Epoch[409/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 10:55:05 | Train | Epoch[409/600] Iteration[027/030] Train loss: 0.0256
2023-02-06 10:55:05 | Train | Epoch[409/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:55:05 | Train | Epoch[409/600] Iteration[029/030] Train loss: 0.0256
2023-02-06 10:55:05 | Train | Epoch[409/600] Iteration[030/030] Train loss: 0.0255
2023-02-06 10:55:05 | Valid | Epoch[409/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 10:55:05 | Valid | Epoch[409/600] Iteration[002/008] Valid loss: 0.0303
2023-02-06 10:55:05 | Valid | Epoch[409/600] Iteration[003/008] Valid loss: 0.0301
2023-02-06 10:55:05 | Valid | Epoch[409/600] Iteration[004/008] Valid loss: 0.0290
2023-02-06 10:55:05 | Valid | Epoch[409/600] Iteration[005/008] Valid loss: 0.0296
2023-02-06 10:55:05 | Valid | Epoch[409/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 10:55:05 | Valid | Epoch[409/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:55:05 | Valid | Epoch[409/600] Iteration[008/008] Valid loss: 0.0293
2023-02-06 10:55:05 | Valid | Epoch[409/600] MIou: 0.9123058994400788
2023-02-06 10:55:05 | Valid | Epoch[409/600] Pixel Accuracy: 0.9854443868001302
2023-02-06 10:55:05 | Valid | Epoch[409/600] Mean Pixel Accuracy: 0.923750778847436
2023-02-06 10:55:05 | Stage | Epoch[409/600] Train loss:0.0255
2023-02-06 10:55:05 | Stage | Epoch[409/600] Valid loss:0.0293
2023-02-06 10:55:05 | Stage | Epoch[409/600] LR:0.001

2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[001/030] Train loss: 0.0302
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[002/030] Train loss: 0.0283
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[006/030] Train loss: 0.0258
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[008/030] Train loss: 0.0264
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[010/030] Train loss: 0.0264
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[013/030] Train loss: 0.0260
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:55:06 | Train | Epoch[410/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:55:07 | Train | Epoch[410/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:55:07 | Valid | Epoch[410/600] Iteration[001/008] Valid loss: 0.0396
2023-02-06 10:55:07 | Valid | Epoch[410/600] Iteration[002/008] Valid loss: 0.0335
2023-02-06 10:55:07 | Valid | Epoch[410/600] Iteration[003/008] Valid loss: 0.0321
2023-02-06 10:55:07 | Valid | Epoch[410/600] Iteration[004/008] Valid loss: 0.0309
2023-02-06 10:55:07 | Valid | Epoch[410/600] Iteration[005/008] Valid loss: 0.0319
2023-02-06 10:55:07 | Valid | Epoch[410/600] Iteration[006/008] Valid loss: 0.0323
2023-02-06 10:55:07 | Valid | Epoch[410/600] Iteration[007/008] Valid loss: 0.0331
2023-02-06 10:55:07 | Valid | Epoch[410/600] Iteration[008/008] Valid loss: 0.0327
2023-02-06 10:55:08 | Valid | Epoch[410/600] MIou: 0.9354222523708802
2023-02-06 10:55:08 | Valid | Epoch[410/600] Pixel Accuracy: 0.9890607198079427
2023-02-06 10:55:08 | Valid | Epoch[410/600] Mean Pixel Accuracy: 0.9543656985784424
2023-02-06 10:55:08 | Stage | Epoch[410/600] Train loss:0.0253
2023-02-06 10:55:08 | Stage | Epoch[410/600] Valid loss:0.0327
2023-02-06 10:55:08 | Stage | Epoch[410/600] LR:0.001

2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[001/030] Train loss: 0.0250
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[004/030] Train loss: 0.0262
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[005/030] Train loss: 0.0265
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[006/030] Train loss: 0.0264
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:55:08 | Train | Epoch[411/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:55:09 | Train | Epoch[411/600] Iteration[030/030] Train loss: 0.0255
2023-02-06 10:55:09 | Valid | Epoch[411/600] Iteration[001/008] Valid loss: 0.0361
2023-02-06 10:55:09 | Valid | Epoch[411/600] Iteration[002/008] Valid loss: 0.0337
2023-02-06 10:55:09 | Valid | Epoch[411/600] Iteration[003/008] Valid loss: 0.0341
2023-02-06 10:55:09 | Valid | Epoch[411/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 10:55:09 | Valid | Epoch[411/600] Iteration[005/008] Valid loss: 0.0337
2023-02-06 10:55:09 | Valid | Epoch[411/600] Iteration[006/008] Valid loss: 0.0332
2023-02-06 10:55:10 | Valid | Epoch[411/600] Iteration[007/008] Valid loss: 0.0324
2023-02-06 10:55:10 | Valid | Epoch[411/600] Iteration[008/008] Valid loss: 0.0328
2023-02-06 10:55:10 | Valid | Epoch[411/600] MIou: 0.8861684170786006
2023-02-06 10:55:10 | Valid | Epoch[411/600] Pixel Accuracy: 0.9812138875325521
2023-02-06 10:55:10 | Valid | Epoch[411/600] Mean Pixel Accuracy: 0.8972492981479847
2023-02-06 10:55:10 | Stage | Epoch[411/600] Train loss:0.0255
2023-02-06 10:55:10 | Stage | Epoch[411/600] Valid loss:0.0328
2023-02-06 10:55:10 | Stage | Epoch[411/600] LR:0.001

2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[002/030] Train loss: 0.0237
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[004/030] Train loss: 0.0258
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:55:10 | Train | Epoch[412/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[020/030] Train loss: 0.0256
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:55:11 | Train | Epoch[412/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:55:11 | Valid | Epoch[412/600] Iteration[001/008] Valid loss: 0.0345
2023-02-06 10:55:11 | Valid | Epoch[412/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:55:11 | Valid | Epoch[412/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:55:12 | Valid | Epoch[412/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:55:12 | Valid | Epoch[412/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:55:12 | Valid | Epoch[412/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:55:12 | Valid | Epoch[412/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:55:12 | Valid | Epoch[412/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:55:12 | Valid | Epoch[412/600] MIou: 0.9219238719175811
2023-02-06 10:55:12 | Valid | Epoch[412/600] Pixel Accuracy: 0.9869880676269531
2023-02-06 10:55:12 | Valid | Epoch[412/600] Mean Pixel Accuracy: 0.9344269825099765
2023-02-06 10:55:12 | Stage | Epoch[412/600] Train loss:0.0252
2023-02-06 10:55:12 | Stage | Epoch[412/600] Valid loss:0.0290
2023-02-06 10:55:12 | Stage | Epoch[412/600] LR:0.001

2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[001/030] Train loss: 0.0276
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[002/030] Train loss: 0.0234
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[003/030] Train loss: 0.0236
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[005/030] Train loss: 0.0236
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[006/030] Train loss: 0.0237
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[007/030] Train loss: 0.0234
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[008/030] Train loss: 0.0238
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[010/030] Train loss: 0.0248
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 10:55:12 | Train | Epoch[413/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[016/030] Train loss: 0.0244
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[017/030] Train loss: 0.0243
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:55:13 | Train | Epoch[413/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:55:14 | Valid | Epoch[413/600] Iteration[001/008] Valid loss: 0.0392
2023-02-06 10:55:14 | Valid | Epoch[413/600] Iteration[002/008] Valid loss: 0.0374
2023-02-06 10:55:14 | Valid | Epoch[413/600] Iteration[003/008] Valid loss: 0.0382
2023-02-06 10:55:14 | Valid | Epoch[413/600] Iteration[004/008] Valid loss: 0.0373
2023-02-06 10:55:14 | Valid | Epoch[413/600] Iteration[005/008] Valid loss: 0.0378
2023-02-06 10:55:14 | Valid | Epoch[413/600] Iteration[006/008] Valid loss: 0.0372
2023-02-06 10:55:14 | Valid | Epoch[413/600] Iteration[007/008] Valid loss: 0.0362
2023-02-06 10:55:14 | Valid | Epoch[413/600] Iteration[008/008] Valid loss: 0.0368
2023-02-06 10:55:14 | Valid | Epoch[413/600] MIou: 0.8685610275832687
2023-02-06 10:55:14 | Valid | Epoch[413/600] Pixel Accuracy: 0.9783312479654948
2023-02-06 10:55:14 | Valid | Epoch[413/600] Mean Pixel Accuracy: 0.8806189376021607
2023-02-06 10:55:14 | Stage | Epoch[413/600] Train loss:0.0253
2023-02-06 10:55:14 | Stage | Epoch[413/600] Valid loss:0.0368
2023-02-06 10:55:14 | Stage | Epoch[413/600] LR:0.001

2023-02-06 10:55:14 | Train | Epoch[414/600] Iteration[001/030] Train loss: 0.0249
2023-02-06 10:55:14 | Train | Epoch[414/600] Iteration[002/030] Train loss: 0.0231
2023-02-06 10:55:14 | Train | Epoch[414/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 10:55:14 | Train | Epoch[414/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 10:55:14 | Train | Epoch[414/600] Iteration[005/030] Train loss: 0.0243
2023-02-06 10:55:14 | Train | Epoch[414/600] Iteration[006/030] Train loss: 0.0237
2023-02-06 10:55:14 | Train | Epoch[414/600] Iteration[007/030] Train loss: 0.0240
2023-02-06 10:55:14 | Train | Epoch[414/600] Iteration[008/030] Train loss: 0.0243
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[010/030] Train loss: 0.0248
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:55:15 | Train | Epoch[414/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:55:16 | Valid | Epoch[414/600] Iteration[001/008] Valid loss: 0.0354
2023-02-06 10:55:16 | Valid | Epoch[414/600] Iteration[002/008] Valid loss: 0.0306
2023-02-06 10:55:16 | Valid | Epoch[414/600] Iteration[003/008] Valid loss: 0.0298
2023-02-06 10:55:16 | Valid | Epoch[414/600] Iteration[004/008] Valid loss: 0.0287
2023-02-06 10:55:16 | Valid | Epoch[414/600] Iteration[005/008] Valid loss: 0.0293
2023-02-06 10:55:16 | Valid | Epoch[414/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 10:55:16 | Valid | Epoch[414/600] Iteration[007/008] Valid loss: 0.0296
2023-02-06 10:55:16 | Valid | Epoch[414/600] Iteration[008/008] Valid loss: 0.0294
2023-02-06 10:55:16 | Valid | Epoch[414/600] MIou: 0.9268831032639289
2023-02-06 10:55:16 | Valid | Epoch[414/600] Pixel Accuracy: 0.9877713521321615
2023-02-06 10:55:16 | Valid | Epoch[414/600] Mean Pixel Accuracy: 0.9406019762702594
2023-02-06 10:55:16 | Stage | Epoch[414/600] Train loss:0.0252
2023-02-06 10:55:16 | Stage | Epoch[414/600] Valid loss:0.0294
2023-02-06 10:55:16 | Stage | Epoch[414/600] LR:0.001

2023-02-06 10:55:16 | Train | Epoch[415/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 10:55:16 | Train | Epoch[415/600] Iteration[002/030] Train loss: 0.0247
2023-02-06 10:55:16 | Train | Epoch[415/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:55:16 | Train | Epoch[415/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[006/030] Train loss: 0.0245
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[009/030] Train loss: 0.0253
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:55:17 | Train | Epoch[415/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:55:18 | Train | Epoch[415/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:55:18 | Train | Epoch[415/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:55:18 | Train | Epoch[415/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:55:18 | Valid | Epoch[415/600] Iteration[001/008] Valid loss: 0.0391
2023-02-06 10:55:18 | Valid | Epoch[415/600] Iteration[002/008] Valid loss: 0.0332
2023-02-06 10:55:18 | Valid | Epoch[415/600] Iteration[003/008] Valid loss: 0.0317
2023-02-06 10:55:18 | Valid | Epoch[415/600] Iteration[004/008] Valid loss: 0.0306
2023-02-06 10:55:18 | Valid | Epoch[415/600] Iteration[005/008] Valid loss: 0.0315
2023-02-06 10:55:18 | Valid | Epoch[415/600] Iteration[006/008] Valid loss: 0.0322
2023-02-06 10:55:18 | Valid | Epoch[415/600] Iteration[007/008] Valid loss: 0.0329
2023-02-06 10:55:18 | Valid | Epoch[415/600] Iteration[008/008] Valid loss: 0.0324
2023-02-06 10:55:18 | Valid | Epoch[415/600] MIou: 0.9346536916676899
2023-02-06 10:55:18 | Valid | Epoch[415/600] Pixel Accuracy: 0.98895263671875
2023-02-06 10:55:18 | Valid | Epoch[415/600] Mean Pixel Accuracy: 0.952727514096482
2023-02-06 10:55:18 | Stage | Epoch[415/600] Train loss:0.0250
2023-02-06 10:55:18 | Stage | Epoch[415/600] Valid loss:0.0324
2023-02-06 10:55:18 | Stage | Epoch[415/600] LR:0.001

2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[001/030] Train loss: 0.0231
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[002/030] Train loss: 0.0236
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[003/030] Train loss: 0.0245
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[007/030] Train loss: 0.0251
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[010/030] Train loss: 0.0248
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[013/030] Train loss: 0.0245
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[014/030] Train loss: 0.0245
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[015/030] Train loss: 0.0243
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:55:19 | Train | Epoch[416/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:55:20 | Train | Epoch[416/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:55:20 | Train | Epoch[416/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:55:20 | Train | Epoch[416/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:55:20 | Train | Epoch[416/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:55:20 | Train | Epoch[416/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:55:20 | Train | Epoch[416/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:55:20 | Train | Epoch[416/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:55:20 | Valid | Epoch[416/600] Iteration[001/008] Valid loss: 0.0348
2023-02-06 10:55:20 | Valid | Epoch[416/600] Iteration[002/008] Valid loss: 0.0322
2023-02-06 10:55:20 | Valid | Epoch[416/600] Iteration[003/008] Valid loss: 0.0325
2023-02-06 10:55:20 | Valid | Epoch[416/600] Iteration[004/008] Valid loss: 0.0315
2023-02-06 10:55:20 | Valid | Epoch[416/600] Iteration[005/008] Valid loss: 0.0320
2023-02-06 10:55:20 | Valid | Epoch[416/600] Iteration[006/008] Valid loss: 0.0316
2023-02-06 10:55:20 | Valid | Epoch[416/600] Iteration[007/008] Valid loss: 0.0310
2023-02-06 10:55:20 | Valid | Epoch[416/600] Iteration[008/008] Valid loss: 0.0313
2023-02-06 10:55:20 | Valid | Epoch[416/600] MIou: 0.8948267478863583
2023-02-06 10:55:20 | Valid | Epoch[416/600] Pixel Accuracy: 0.9826240539550781
2023-02-06 10:55:20 | Valid | Epoch[416/600] Mean Pixel Accuracy: 0.9056646539280045
2023-02-06 10:55:20 | Stage | Epoch[416/600] Train loss:0.0251
2023-02-06 10:55:20 | Stage | Epoch[416/600] Valid loss:0.0313
2023-02-06 10:55:20 | Stage | Epoch[416/600] LR:0.001

2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[001/030] Train loss: 0.0228
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[003/030] Train loss: 0.0261
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[008/030] Train loss: 0.0259
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:55:21 | Train | Epoch[417/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:55:22 | Train | Epoch[417/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:55:22 | Train | Epoch[417/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:55:22 | Train | Epoch[417/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:55:22 | Train | Epoch[417/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:55:22 | Train | Epoch[417/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:55:22 | Train | Epoch[417/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:55:22 | Train | Epoch[417/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:55:22 | Train | Epoch[417/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:55:22 | Train | Epoch[417/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:55:22 | Train | Epoch[417/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:55:22 | Valid | Epoch[417/600] Iteration[001/008] Valid loss: 0.0555
2023-02-06 10:55:22 | Valid | Epoch[417/600] Iteration[002/008] Valid loss: 0.0445
2023-02-06 10:55:22 | Valid | Epoch[417/600] Iteration[003/008] Valid loss: 0.0413
2023-02-06 10:55:22 | Valid | Epoch[417/600] Iteration[004/008] Valid loss: 0.0396
2023-02-06 10:55:22 | Valid | Epoch[417/600] Iteration[005/008] Valid loss: 0.0408
2023-02-06 10:55:22 | Valid | Epoch[417/600] Iteration[006/008] Valid loss: 0.0417
2023-02-06 10:55:22 | Valid | Epoch[417/600] Iteration[007/008] Valid loss: 0.0434
2023-02-06 10:55:22 | Valid | Epoch[417/600] Iteration[008/008] Valid loss: 0.0426
2023-02-06 10:55:22 | Valid | Epoch[417/600] MIou: 0.937748053237681
2023-02-06 10:55:22 | Valid | Epoch[417/600] Pixel Accuracy: 0.9892285664876302
2023-02-06 10:55:22 | Valid | Epoch[417/600] Mean Pixel Accuracy: 0.9664414454299173
2023-02-06 10:55:22 | Stage | Epoch[417/600] Train loss:0.0253
2023-02-06 10:55:22 | Stage | Epoch[417/600] Valid loss:0.0426
2023-02-06 10:55:22 | Stage | Epoch[417/600] LR:0.001

2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[001/030] Train loss: 0.0275
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[002/030] Train loss: 0.0249
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[003/030] Train loss: 0.0261
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[005/030] Train loss: 0.0236
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[009/030] Train loss: 0.0243
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[010/030] Train loss: 0.0243
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[011/030] Train loss: 0.0245
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[012/030] Train loss: 0.0240
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[013/030] Train loss: 0.0240
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[014/030] Train loss: 0.0243
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[015/030] Train loss: 0.0245
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[017/030] Train loss: 0.0244
2023-02-06 10:55:23 | Train | Epoch[418/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:55:24 | Train | Epoch[418/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:55:24 | Valid | Epoch[418/600] Iteration[001/008] Valid loss: 0.0455
2023-02-06 10:55:24 | Valid | Epoch[418/600] Iteration[002/008] Valid loss: 0.0376
2023-02-06 10:55:24 | Valid | Epoch[418/600] Iteration[003/008] Valid loss: 0.0357
2023-02-06 10:55:24 | Valid | Epoch[418/600] Iteration[004/008] Valid loss: 0.0342
2023-02-06 10:55:24 | Valid | Epoch[418/600] Iteration[005/008] Valid loss: 0.0352
2023-02-06 10:55:24 | Valid | Epoch[418/600] Iteration[006/008] Valid loss: 0.0356
2023-02-06 10:55:24 | Valid | Epoch[418/600] Iteration[007/008] Valid loss: 0.0369
2023-02-06 10:55:24 | Valid | Epoch[418/600] Iteration[008/008] Valid loss: 0.0364
2023-02-06 10:55:25 | Valid | Epoch[418/600] MIou: 0.9364733128570646
2023-02-06 10:55:25 | Valid | Epoch[418/600] Pixel Accuracy: 0.9891141255696615
2023-02-06 10:55:25 | Valid | Epoch[418/600] Mean Pixel Accuracy: 0.9606721194597427
2023-02-06 10:55:25 | Stage | Epoch[418/600] Train loss:0.0253
2023-02-06 10:55:25 | Stage | Epoch[418/600] Valid loss:0.0364
2023-02-06 10:55:25 | Stage | Epoch[418/600] LR:0.001

2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[001/030] Train loss: 0.0255
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[003/030] Train loss: 0.0251
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[006/030] Train loss: 0.0241
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[008/030] Train loss: 0.0238
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[010/030] Train loss: 0.0248
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:55:25 | Train | Epoch[419/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:55:26 | Train | Epoch[419/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:55:26 | Valid | Epoch[419/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 10:55:26 | Valid | Epoch[419/600] Iteration[002/008] Valid loss: 0.0314
2023-02-06 10:55:26 | Valid | Epoch[419/600] Iteration[003/008] Valid loss: 0.0316
2023-02-06 10:55:26 | Valid | Epoch[419/600] Iteration[004/008] Valid loss: 0.0306
2023-02-06 10:55:26 | Valid | Epoch[419/600] Iteration[005/008] Valid loss: 0.0311
2023-02-06 10:55:26 | Valid | Epoch[419/600] Iteration[006/008] Valid loss: 0.0308
2023-02-06 10:55:26 | Valid | Epoch[419/600] Iteration[007/008] Valid loss: 0.0303
2023-02-06 10:55:26 | Valid | Epoch[419/600] Iteration[008/008] Valid loss: 0.0305
2023-02-06 10:55:27 | Valid | Epoch[419/600] MIou: 0.8998368903760046
2023-02-06 10:55:27 | Valid | Epoch[419/600] Pixel Accuracy: 0.9834340413411459
2023-02-06 10:55:27 | Valid | Epoch[419/600] Mean Pixel Accuracy: 0.910725720801308
2023-02-06 10:55:27 | Stage | Epoch[419/600] Train loss:0.0254
2023-02-06 10:55:27 | Stage | Epoch[419/600] Valid loss:0.0305
2023-02-06 10:55:27 | Stage | Epoch[419/600] LR:0.001

2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[001/030] Train loss: 0.0226
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[002/030] Train loss: 0.0218
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[003/030] Train loss: 0.0232
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[005/030] Train loss: 0.0233
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[006/030] Train loss: 0.0242
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[007/030] Train loss: 0.0244
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[008/030] Train loss: 0.0241
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[009/030] Train loss: 0.0237
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[010/030] Train loss: 0.0235
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[011/030] Train loss: 0.0238
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[012/030] Train loss: 0.0237
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[013/030] Train loss: 0.0238
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[014/030] Train loss: 0.0239
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[015/030] Train loss: 0.0239
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 10:55:27 | Train | Epoch[420/600] Iteration[017/030] Train loss: 0.0243
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[018/030] Train loss: 0.0243
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[020/030] Train loss: 0.0246
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:55:28 | Train | Epoch[420/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:55:28 | Valid | Epoch[420/600] Iteration[001/008] Valid loss: 0.0453
2023-02-06 10:55:28 | Valid | Epoch[420/600] Iteration[002/008] Valid loss: 0.0374
2023-02-06 10:55:28 | Valid | Epoch[420/600] Iteration[003/008] Valid loss: 0.0353
2023-02-06 10:55:28 | Valid | Epoch[420/600] Iteration[004/008] Valid loss: 0.0339
2023-02-06 10:55:28 | Valid | Epoch[420/600] Iteration[005/008] Valid loss: 0.0351
2023-02-06 10:55:28 | Valid | Epoch[420/600] Iteration[006/008] Valid loss: 0.0357
2023-02-06 10:55:28 | Valid | Epoch[420/600] Iteration[007/008] Valid loss: 0.0369
2023-02-06 10:55:28 | Valid | Epoch[420/600] Iteration[008/008] Valid loss: 0.0363
2023-02-06 10:55:29 | Valid | Epoch[420/600] MIou: 0.9371799899560294
2023-02-06 10:55:29 | Valid | Epoch[420/600] Pixel Accuracy: 0.9892616271972656
2023-02-06 10:55:29 | Valid | Epoch[420/600] Mean Pixel Accuracy: 0.9602079120950274
2023-02-06 10:55:29 | Stage | Epoch[420/600] Train loss:0.0251
2023-02-06 10:55:29 | Stage | Epoch[420/600] Valid loss:0.0363
2023-02-06 10:55:29 | Stage | Epoch[420/600] LR:0.001

2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[001/030] Train loss: 0.0243
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[002/030] Train loss: 0.0252
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[004/030] Train loss: 0.0254
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:55:29 | Train | Epoch[421/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:55:30 | Train | Epoch[421/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:55:30 | Valid | Epoch[421/600] Iteration[001/008] Valid loss: 0.0410
2023-02-06 10:55:30 | Valid | Epoch[421/600] Iteration[002/008] Valid loss: 0.0394
2023-02-06 10:55:30 | Valid | Epoch[421/600] Iteration[003/008] Valid loss: 0.0404
2023-02-06 10:55:30 | Valid | Epoch[421/600] Iteration[004/008] Valid loss: 0.0394
2023-02-06 10:55:30 | Valid | Epoch[421/600] Iteration[005/008] Valid loss: 0.0400
2023-02-06 10:55:30 | Valid | Epoch[421/600] Iteration[006/008] Valid loss: 0.0393
2023-02-06 10:55:31 | Valid | Epoch[421/600] Iteration[007/008] Valid loss: 0.0382
2023-02-06 10:55:31 | Valid | Epoch[421/600] Iteration[008/008] Valid loss: 0.0389
2023-02-06 10:55:31 | Valid | Epoch[421/600] MIou: 0.8610213212173736
2023-02-06 10:55:31 | Valid | Epoch[421/600] Pixel Accuracy: 0.9770940144856771
2023-02-06 10:55:31 | Valid | Epoch[421/600] Mean Pixel Accuracy: 0.8735857488598171
2023-02-06 10:55:31 | Stage | Epoch[421/600] Train loss:0.0254
2023-02-06 10:55:31 | Stage | Epoch[421/600] Valid loss:0.0389
2023-02-06 10:55:31 | Stage | Epoch[421/600] LR:0.001

2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[001/030] Train loss: 0.0215
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[002/030] Train loss: 0.0215
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[004/030] Train loss: 0.0225
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[005/030] Train loss: 0.0232
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[006/030] Train loss: 0.0241
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[007/030] Train loss: 0.0238
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[008/030] Train loss: 0.0241
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:55:31 | Train | Epoch[422/600] Iteration[013/030] Train loss: 0.0247
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[016/030] Train loss: 0.0245
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:55:32 | Train | Epoch[422/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:55:33 | Valid | Epoch[422/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:55:33 | Valid | Epoch[422/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:55:33 | Valid | Epoch[422/600] Iteration[003/008] Valid loss: 0.0296
2023-02-06 10:55:33 | Valid | Epoch[422/600] Iteration[004/008] Valid loss: 0.0285
2023-02-06 10:55:33 | Valid | Epoch[422/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 10:55:33 | Valid | Epoch[422/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 10:55:33 | Valid | Epoch[422/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:55:33 | Valid | Epoch[422/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:55:33 | Valid | Epoch[422/600] MIou: 0.916940448109459
2023-02-06 10:55:33 | Valid | Epoch[422/600] Pixel Accuracy: 0.9861895243326823
2023-02-06 10:55:33 | Valid | Epoch[422/600] Mean Pixel Accuracy: 0.928795222890004
2023-02-06 10:55:33 | Stage | Epoch[422/600] Train loss:0.0251
2023-02-06 10:55:33 | Stage | Epoch[422/600] Valid loss:0.0290
2023-02-06 10:55:33 | Stage | Epoch[422/600] LR:0.001

2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[003/030] Train loss: 0.0238
2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[004/030] Train loss: 0.0234
2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[005/030] Train loss: 0.0235
2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[006/030] Train loss: 0.0238
2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[007/030] Train loss: 0.0237
2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[008/030] Train loss: 0.0240
2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[009/030] Train loss: 0.0238
2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[010/030] Train loss: 0.0239
2023-02-06 10:55:33 | Train | Epoch[423/600] Iteration[011/030] Train loss: 0.0239
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[012/030] Train loss: 0.0239
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[013/030] Train loss: 0.0239
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[014/030] Train loss: 0.0242
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[015/030] Train loss: 0.0242
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[016/030] Train loss: 0.0244
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:55:34 | Train | Epoch[423/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:55:35 | Valid | Epoch[423/600] Iteration[001/008] Valid loss: 0.0355
2023-02-06 10:55:35 | Valid | Epoch[423/600] Iteration[002/008] Valid loss: 0.0305
2023-02-06 10:55:35 | Valid | Epoch[423/600] Iteration[003/008] Valid loss: 0.0297
2023-02-06 10:55:35 | Valid | Epoch[423/600] Iteration[004/008] Valid loss: 0.0286
2023-02-06 10:55:35 | Valid | Epoch[423/600] Iteration[005/008] Valid loss: 0.0293
2023-02-06 10:55:35 | Valid | Epoch[423/600] Iteration[006/008] Valid loss: 0.0296
2023-02-06 10:55:35 | Valid | Epoch[423/600] Iteration[007/008] Valid loss: 0.0298
2023-02-06 10:55:35 | Valid | Epoch[423/600] Iteration[008/008] Valid loss: 0.0296
2023-02-06 10:55:35 | Valid | Epoch[423/600] MIou: 0.9271221358563491
2023-02-06 10:55:35 | Valid | Epoch[423/600] Pixel Accuracy: 0.9878107706705729
2023-02-06 10:55:35 | Valid | Epoch[423/600] Mean Pixel Accuracy: 0.9408455588830531
2023-02-06 10:55:35 | Stage | Epoch[423/600] Train loss:0.0253
2023-02-06 10:55:35 | Stage | Epoch[423/600] Valid loss:0.0296
2023-02-06 10:55:35 | Stage | Epoch[423/600] LR:0.001

2023-02-06 10:55:35 | Train | Epoch[424/600] Iteration[001/030] Train loss: 0.0274
2023-02-06 10:55:35 | Train | Epoch[424/600] Iteration[002/030] Train loss: 0.0268
2023-02-06 10:55:35 | Train | Epoch[424/600] Iteration[003/030] Train loss: 0.0279
2023-02-06 10:55:35 | Train | Epoch[424/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 10:55:35 | Train | Epoch[424/600] Iteration[005/030] Train loss: 0.0266
2023-02-06 10:55:35 | Train | Epoch[424/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 10:55:35 | Train | Epoch[424/600] Iteration[007/030] Train loss: 0.0265
2023-02-06 10:55:35 | Train | Epoch[424/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 10:55:35 | Train | Epoch[424/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 10:55:35 | Train | Epoch[424/600] Iteration[010/030] Train loss: 0.0268
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[011/030] Train loss: 0.0266
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[013/030] Train loss: 0.0264
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[015/030] Train loss: 0.0265
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[018/030] Train loss: 0.0262
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[019/030] Train loss: 0.0262
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[022/030] Train loss: 0.0258
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:55:36 | Train | Epoch[424/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:55:37 | Valid | Epoch[424/600] Iteration[001/008] Valid loss: 0.0356
2023-02-06 10:55:37 | Valid | Epoch[424/600] Iteration[002/008] Valid loss: 0.0306
2023-02-06 10:55:37 | Valid | Epoch[424/600] Iteration[003/008] Valid loss: 0.0298
2023-02-06 10:55:37 | Valid | Epoch[424/600] Iteration[004/008] Valid loss: 0.0286
2023-02-06 10:55:37 | Valid | Epoch[424/600] Iteration[005/008] Valid loss: 0.0293
2023-02-06 10:55:37 | Valid | Epoch[424/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 10:55:37 | Valid | Epoch[424/600] Iteration[007/008] Valid loss: 0.0296
2023-02-06 10:55:37 | Valid | Epoch[424/600] Iteration[008/008] Valid loss: 0.0294
2023-02-06 10:55:37 | Valid | Epoch[424/600] MIou: 0.9272387524908796
2023-02-06 10:55:37 | Valid | Epoch[424/600] Pixel Accuracy: 0.987829844156901
2023-02-06 10:55:37 | Valid | Epoch[424/600] Mean Pixel Accuracy: 0.940970170971821
2023-02-06 10:55:37 | Stage | Epoch[424/600] Train loss:0.0254
2023-02-06 10:55:37 | Stage | Epoch[424/600] Valid loss:0.0294
2023-02-06 10:55:37 | Stage | Epoch[424/600] LR:0.001

2023-02-06 10:55:37 | Train | Epoch[425/600] Iteration[001/030] Train loss: 0.0260
2023-02-06 10:55:37 | Train | Epoch[425/600] Iteration[002/030] Train loss: 0.0261
2023-02-06 10:55:37 | Train | Epoch[425/600] Iteration[003/030] Train loss: 0.0258
2023-02-06 10:55:37 | Train | Epoch[425/600] Iteration[004/030] Train loss: 0.0250
2023-02-06 10:55:37 | Train | Epoch[425/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 10:55:37 | Train | Epoch[425/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[016/030] Train loss: 0.0244
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[017/030] Train loss: 0.0246
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[018/030] Train loss: 0.0245
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[019/030] Train loss: 0.0243
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[020/030] Train loss: 0.0244
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[021/030] Train loss: 0.0245
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:55:38 | Train | Epoch[425/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:55:39 | Valid | Epoch[425/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:55:39 | Valid | Epoch[425/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:55:39 | Valid | Epoch[425/600] Iteration[003/008] Valid loss: 0.0297
2023-02-06 10:55:39 | Valid | Epoch[425/600] Iteration[004/008] Valid loss: 0.0286
2023-02-06 10:55:39 | Valid | Epoch[425/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 10:55:39 | Valid | Epoch[425/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:55:39 | Valid | Epoch[425/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:55:39 | Valid | Epoch[425/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:55:39 | Valid | Epoch[425/600] MIou: 0.9171387059748759
2023-02-06 10:55:39 | Valid | Epoch[425/600] Pixel Accuracy: 0.9862251281738281
2023-02-06 10:55:39 | Valid | Epoch[425/600] Mean Pixel Accuracy: 0.9288972184092219
2023-02-06 10:55:39 | Stage | Epoch[425/600] Train loss:0.0253
2023-02-06 10:55:39 | Stage | Epoch[425/600] Valid loss:0.0289
2023-02-06 10:55:39 | Stage | Epoch[425/600] LR:0.001

2023-02-06 10:55:39 | Train | Epoch[426/600] Iteration[001/030] Train loss: 0.0259
2023-02-06 10:55:39 | Train | Epoch[426/600] Iteration[002/030] Train loss: 0.0249
2023-02-06 10:55:39 | Train | Epoch[426/600] Iteration[003/030] Train loss: 0.0246
2023-02-06 10:55:39 | Train | Epoch[426/600] Iteration[004/030] Train loss: 0.0250
2023-02-06 10:55:39 | Train | Epoch[426/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[009/030] Train loss: 0.0243
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[012/030] Train loss: 0.0245
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[014/030] Train loss: 0.0245
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:55:40 | Train | Epoch[426/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:55:41 | Train | Epoch[426/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:55:41 | Valid | Epoch[426/600] Iteration[001/008] Valid loss: 0.0427
2023-02-06 10:55:41 | Valid | Epoch[426/600] Iteration[002/008] Valid loss: 0.0355
2023-02-06 10:55:41 | Valid | Epoch[426/600] Iteration[003/008] Valid loss: 0.0338
2023-02-06 10:55:41 | Valid | Epoch[426/600] Iteration[004/008] Valid loss: 0.0325
2023-02-06 10:55:41 | Valid | Epoch[426/600] Iteration[005/008] Valid loss: 0.0336
2023-02-06 10:55:41 | Valid | Epoch[426/600] Iteration[006/008] Valid loss: 0.0341
2023-02-06 10:55:41 | Valid | Epoch[426/600] Iteration[007/008] Valid loss: 0.0352
2023-02-06 10:55:41 | Valid | Epoch[426/600] Iteration[008/008] Valid loss: 0.0346
2023-02-06 10:55:41 | Valid | Epoch[426/600] MIou: 0.9368319673076697
2023-02-06 10:55:41 | Valid | Epoch[426/600] Pixel Accuracy: 0.9892438252766927
2023-02-06 10:55:41 | Valid | Epoch[426/600] Mean Pixel Accuracy: 0.9580867503867244
2023-02-06 10:55:41 | Stage | Epoch[426/600] Train loss:0.0253
2023-02-06 10:55:41 | Stage | Epoch[426/600] Valid loss:0.0346
2023-02-06 10:55:41 | Stage | Epoch[426/600] LR:0.001

2023-02-06 10:55:41 | Train | Epoch[427/600] Iteration[001/030] Train loss: 0.0315
2023-02-06 10:55:41 | Train | Epoch[427/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 10:55:41 | Train | Epoch[427/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 10:55:41 | Train | Epoch[427/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[007/030] Train loss: 0.0251
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[009/030] Train loss: 0.0253
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[010/030] Train loss: 0.0248
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[013/030] Train loss: 0.0245
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[014/030] Train loss: 0.0244
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[015/030] Train loss: 0.0244
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[017/030] Train loss: 0.0243
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[018/030] Train loss: 0.0244
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[019/030] Train loss: 0.0243
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[020/030] Train loss: 0.0244
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[022/030] Train loss: 0.0247
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:55:42 | Train | Epoch[427/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:55:43 | Train | Epoch[427/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:55:43 | Train | Epoch[427/600] Iteration[029/030] Train loss: 0.0255
2023-02-06 10:55:43 | Train | Epoch[427/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:55:43 | Valid | Epoch[427/600] Iteration[001/008] Valid loss: 0.0381
2023-02-06 10:55:43 | Valid | Epoch[427/600] Iteration[002/008] Valid loss: 0.0324
2023-02-06 10:55:43 | Valid | Epoch[427/600] Iteration[003/008] Valid loss: 0.0312
2023-02-06 10:55:43 | Valid | Epoch[427/600] Iteration[004/008] Valid loss: 0.0300
2023-02-06 10:55:43 | Valid | Epoch[427/600] Iteration[005/008] Valid loss: 0.0310
2023-02-06 10:55:43 | Valid | Epoch[427/600] Iteration[006/008] Valid loss: 0.0316
2023-02-06 10:55:43 | Valid | Epoch[427/600] Iteration[007/008] Valid loss: 0.0322
2023-02-06 10:55:43 | Valid | Epoch[427/600] Iteration[008/008] Valid loss: 0.0317
2023-02-06 10:55:43 | Valid | Epoch[427/600] MIou: 0.9342959731710825
2023-02-06 10:55:43 | Valid | Epoch[427/600] Pixel Accuracy: 0.9889183044433594
2023-02-06 10:55:43 | Valid | Epoch[427/600] Mean Pixel Accuracy: 0.9513200803525457
2023-02-06 10:55:43 | Stage | Epoch[427/600] Train loss:0.0253
2023-02-06 10:55:43 | Stage | Epoch[427/600] Valid loss:0.0317
2023-02-06 10:55:43 | Stage | Epoch[427/600] LR:0.001

2023-02-06 10:55:43 | Train | Epoch[428/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[002/030] Train loss: 0.0232
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[006/030] Train loss: 0.0242
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[009/030] Train loss: 0.0247
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:55:44 | Train | Epoch[428/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:55:45 | Train | Epoch[428/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:55:45 | Train | Epoch[428/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:55:45 | Train | Epoch[428/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:55:45 | Train | Epoch[428/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:55:45 | Train | Epoch[428/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:55:45 | Train | Epoch[428/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:55:45 | Valid | Epoch[428/600] Iteration[001/008] Valid loss: 0.0350
2023-02-06 10:55:45 | Valid | Epoch[428/600] Iteration[002/008] Valid loss: 0.0325
2023-02-06 10:55:45 | Valid | Epoch[428/600] Iteration[003/008] Valid loss: 0.0329
2023-02-06 10:55:45 | Valid | Epoch[428/600] Iteration[004/008] Valid loss: 0.0320
2023-02-06 10:55:45 | Valid | Epoch[428/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 10:55:45 | Valid | Epoch[428/600] Iteration[006/008] Valid loss: 0.0321
2023-02-06 10:55:45 | Valid | Epoch[428/600] Iteration[007/008] Valid loss: 0.0314
2023-02-06 10:55:45 | Valid | Epoch[428/600] Iteration[008/008] Valid loss: 0.0318
2023-02-06 10:55:45 | Valid | Epoch[428/600] MIou: 0.8918194026320481
2023-02-06 10:55:45 | Valid | Epoch[428/600] Pixel Accuracy: 0.9821345011393229
2023-02-06 10:55:45 | Valid | Epoch[428/600] Mean Pixel Accuracy: 0.9027262363149573
2023-02-06 10:55:45 | Stage | Epoch[428/600] Train loss:0.0251
2023-02-06 10:55:45 | Stage | Epoch[428/600] Valid loss:0.0318
2023-02-06 10:55:45 | Stage | Epoch[428/600] LR:0.001

2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[002/030] Train loss: 0.0265
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[003/030] Train loss: 0.0269
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[004/030] Train loss: 0.0266
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[006/030] Train loss: 0.0258
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[008/030] Train loss: 0.0247
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[014/030] Train loss: 0.0244
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[015/030] Train loss: 0.0245
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[019/030] Train loss: 0.0245
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 10:55:46 | Train | Epoch[429/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:55:47 | Train | Epoch[429/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:55:47 | Train | Epoch[429/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:55:47 | Train | Epoch[429/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:55:47 | Train | Epoch[429/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:55:47 | Train | Epoch[429/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:55:47 | Train | Epoch[429/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:55:47 | Train | Epoch[429/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:55:47 | Train | Epoch[429/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:55:47 | Train | Epoch[429/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:55:47 | Valid | Epoch[429/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:55:47 | Valid | Epoch[429/600] Iteration[002/008] Valid loss: 0.0302
2023-02-06 10:55:47 | Valid | Epoch[429/600] Iteration[003/008] Valid loss: 0.0301
2023-02-06 10:55:47 | Valid | Epoch[429/600] Iteration[004/008] Valid loss: 0.0290
2023-02-06 10:55:47 | Valid | Epoch[429/600] Iteration[005/008] Valid loss: 0.0296
2023-02-06 10:55:47 | Valid | Epoch[429/600] Iteration[006/008] Valid loss: 0.0293
2023-02-06 10:55:47 | Valid | Epoch[429/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:55:47 | Valid | Epoch[429/600] Iteration[008/008] Valid loss: 0.0292
2023-02-06 10:55:48 | Valid | Epoch[429/600] MIou: 0.9115108778872689
2023-02-06 10:55:48 | Valid | Epoch[429/600] Pixel Accuracy: 0.9853172302246094
2023-02-06 10:55:48 | Valid | Epoch[429/600] Mean Pixel Accuracy: 0.9228756482883989
2023-02-06 10:55:48 | Stage | Epoch[429/600] Train loss:0.0253
2023-02-06 10:55:48 | Stage | Epoch[429/600] Valid loss:0.0292
2023-02-06 10:55:48 | Stage | Epoch[429/600] LR:0.001

2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[001/030] Train loss: 0.0249
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[002/030] Train loss: 0.0251
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[004/030] Train loss: 0.0243
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[005/030] Train loss: 0.0243
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[006/030] Train loss: 0.0238
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[007/030] Train loss: 0.0238
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 10:55:48 | Train | Epoch[430/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[021/030] Train loss: 0.0257
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:55:49 | Train | Epoch[430/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:55:49 | Valid | Epoch[430/600] Iteration[001/008] Valid loss: 0.0355
2023-02-06 10:55:49 | Valid | Epoch[430/600] Iteration[002/008] Valid loss: 0.0305
2023-02-06 10:55:49 | Valid | Epoch[430/600] Iteration[003/008] Valid loss: 0.0298
2023-02-06 10:55:49 | Valid | Epoch[430/600] Iteration[004/008] Valid loss: 0.0286
2023-02-06 10:55:49 | Valid | Epoch[430/600] Iteration[005/008] Valid loss: 0.0293
2023-02-06 10:55:49 | Valid | Epoch[430/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 10:55:50 | Valid | Epoch[430/600] Iteration[007/008] Valid loss: 0.0296
2023-02-06 10:55:50 | Valid | Epoch[430/600] Iteration[008/008] Valid loss: 0.0294
2023-02-06 10:55:50 | Valid | Epoch[430/600] MIou: 0.9267895525903809
2023-02-06 10:55:50 | Valid | Epoch[430/600] Pixel Accuracy: 0.9877573649088541
2023-02-06 10:55:50 | Valid | Epoch[430/600] Mean Pixel Accuracy: 0.9404547979225233
2023-02-06 10:55:50 | Stage | Epoch[430/600] Train loss:0.0253
2023-02-06 10:55:50 | Stage | Epoch[430/600] Valid loss:0.0294
2023-02-06 10:55:50 | Stage | Epoch[430/600] LR:0.001

2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[001/030] Train loss: 0.0201
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[002/030] Train loss: 0.0266
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[005/030] Train loss: 0.0258
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 10:55:50 | Train | Epoch[431/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:55:51 | Train | Epoch[431/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:55:52 | Valid | Epoch[431/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 10:55:52 | Valid | Epoch[431/600] Iteration[002/008] Valid loss: 0.0313
2023-02-06 10:55:52 | Valid | Epoch[431/600] Iteration[003/008] Valid loss: 0.0316
2023-02-06 10:55:52 | Valid | Epoch[431/600] Iteration[004/008] Valid loss: 0.0306
2023-02-06 10:55:52 | Valid | Epoch[431/600] Iteration[005/008] Valid loss: 0.0311
2023-02-06 10:55:52 | Valid | Epoch[431/600] Iteration[006/008] Valid loss: 0.0308
2023-02-06 10:55:52 | Valid | Epoch[431/600] Iteration[007/008] Valid loss: 0.0303
2023-02-06 10:55:52 | Valid | Epoch[431/600] Iteration[008/008] Valid loss: 0.0305
2023-02-06 10:55:52 | Valid | Epoch[431/600] MIou: 0.8999177183519644
2023-02-06 10:55:52 | Valid | Epoch[431/600] Pixel Accuracy: 0.9834505716959635
2023-02-06 10:55:52 | Valid | Epoch[431/600] Mean Pixel Accuracy: 0.9107221256462942
2023-02-06 10:55:52 | Stage | Epoch[431/600] Train loss:0.0252
2023-02-06 10:55:52 | Stage | Epoch[431/600] Valid loss:0.0305
2023-02-06 10:55:52 | Stage | Epoch[431/600] LR:0.001

2023-02-06 10:55:52 | Train | Epoch[432/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 10:55:52 | Train | Epoch[432/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 10:55:52 | Train | Epoch[432/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 10:55:52 | Train | Epoch[432/600] Iteration[004/030] Train loss: 0.0237
2023-02-06 10:55:52 | Train | Epoch[432/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 10:55:52 | Train | Epoch[432/600] Iteration[006/030] Train loss: 0.0245
2023-02-06 10:55:52 | Train | Epoch[432/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 10:55:52 | Train | Epoch[432/600] Iteration[008/030] Train loss: 0.0254
2023-02-06 10:55:52 | Train | Epoch[432/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[017/030] Train loss: 0.0245
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[019/030] Train loss: 0.0245
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[020/030] Train loss: 0.0245
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[021/030] Train loss: 0.0245
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:55:53 | Train | Epoch[432/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:55:54 | Valid | Epoch[432/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 10:55:54 | Valid | Epoch[432/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:55:54 | Valid | Epoch[432/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:55:54 | Valid | Epoch[432/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:55:54 | Valid | Epoch[432/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:55:54 | Valid | Epoch[432/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:55:54 | Valid | Epoch[432/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:55:54 | Valid | Epoch[432/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:55:54 | Valid | Epoch[432/600] MIou: 0.9207563337301343
2023-02-06 10:55:54 | Valid | Epoch[432/600] Pixel Accuracy: 0.9868087768554688
2023-02-06 10:55:54 | Valid | Epoch[432/600] Mean Pixel Accuracy: 0.9328384258500635
2023-02-06 10:55:54 | Stage | Epoch[432/600] Train loss:0.0252
2023-02-06 10:55:54 | Stage | Epoch[432/600] Valid loss:0.0289
2023-02-06 10:55:54 | Stage | Epoch[432/600] LR:0.001

2023-02-06 10:55:54 | Train | Epoch[433/600] Iteration[001/030] Train loss: 0.0228
2023-02-06 10:55:54 | Train | Epoch[433/600] Iteration[002/030] Train loss: 0.0218
2023-02-06 10:55:54 | Train | Epoch[433/600] Iteration[003/030] Train loss: 0.0221
2023-02-06 10:55:54 | Train | Epoch[433/600] Iteration[004/030] Train loss: 0.0226
2023-02-06 10:55:54 | Train | Epoch[433/600] Iteration[005/030] Train loss: 0.0232
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[006/030] Train loss: 0.0236
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[007/030] Train loss: 0.0236
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[008/030] Train loss: 0.0239
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[009/030] Train loss: 0.0241
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[010/030] Train loss: 0.0242
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[011/030] Train loss: 0.0245
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[013/030] Train loss: 0.0245
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:55:55 | Train | Epoch[433/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:55:56 | Train | Epoch[433/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:55:56 | Train | Epoch[433/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:55:56 | Valid | Epoch[433/600] Iteration[001/008] Valid loss: 0.0383
2023-02-06 10:55:56 | Valid | Epoch[433/600] Iteration[002/008] Valid loss: 0.0326
2023-02-06 10:55:56 | Valid | Epoch[433/600] Iteration[003/008] Valid loss: 0.0313
2023-02-06 10:55:56 | Valid | Epoch[433/600] Iteration[004/008] Valid loss: 0.0301
2023-02-06 10:55:56 | Valid | Epoch[433/600] Iteration[005/008] Valid loss: 0.0310
2023-02-06 10:55:56 | Valid | Epoch[433/600] Iteration[006/008] Valid loss: 0.0316
2023-02-06 10:55:56 | Valid | Epoch[433/600] Iteration[007/008] Valid loss: 0.0322
2023-02-06 10:55:56 | Valid | Epoch[433/600] Iteration[008/008] Valid loss: 0.0317
2023-02-06 10:55:56 | Valid | Epoch[433/600] MIou: 0.9339646183968087
2023-02-06 10:55:56 | Valid | Epoch[433/600] Pixel Accuracy: 0.9888623555501302
2023-02-06 10:55:56 | Valid | Epoch[433/600] Mean Pixel Accuracy: 0.9510103477081329
2023-02-06 10:55:56 | Stage | Epoch[433/600] Train loss:0.0252
2023-02-06 10:55:56 | Stage | Epoch[433/600] Valid loss:0.0317
2023-02-06 10:55:56 | Stage | Epoch[433/600] LR:0.001

2023-02-06 10:55:56 | Train | Epoch[434/600] Iteration[001/030] Train loss: 0.0229
2023-02-06 10:55:56 | Train | Epoch[434/600] Iteration[002/030] Train loss: 0.0246
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[003/030] Train loss: 0.0238
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[005/030] Train loss: 0.0245
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:55:57 | Train | Epoch[434/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:55:58 | Train | Epoch[434/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:55:58 | Train | Epoch[434/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:55:58 | Train | Epoch[434/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:55:58 | Train | Epoch[434/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:55:58 | Train | Epoch[434/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:55:58 | Valid | Epoch[434/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:55:58 | Valid | Epoch[434/600] Iteration[002/008] Valid loss: 0.0305
2023-02-06 10:55:58 | Valid | Epoch[434/600] Iteration[003/008] Valid loss: 0.0305
2023-02-06 10:55:58 | Valid | Epoch[434/600] Iteration[004/008] Valid loss: 0.0294
2023-02-06 10:55:58 | Valid | Epoch[434/600] Iteration[005/008] Valid loss: 0.0300
2023-02-06 10:55:58 | Valid | Epoch[434/600] Iteration[006/008] Valid loss: 0.0298
2023-02-06 10:55:58 | Valid | Epoch[434/600] Iteration[007/008] Valid loss: 0.0294
2023-02-06 10:55:58 | Valid | Epoch[434/600] Iteration[008/008] Valid loss: 0.0295
2023-02-06 10:55:58 | Valid | Epoch[434/600] MIou: 0.9076770683098314
2023-02-06 10:55:58 | Valid | Epoch[434/600] Pixel Accuracy: 0.9846992492675781
2023-02-06 10:55:58 | Valid | Epoch[434/600] Mean Pixel Accuracy: 0.9188268037635974
2023-02-06 10:55:58 | Stage | Epoch[434/600] Train loss:0.0250
2023-02-06 10:55:58 | Stage | Epoch[434/600] Valid loss:0.0295
2023-02-06 10:55:58 | Stage | Epoch[434/600] LR:0.001

2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[001/030] Train loss: 0.0228
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[002/030] Train loss: 0.0221
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[004/030] Train loss: 0.0238
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[005/030] Train loss: 0.0237
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[006/030] Train loss: 0.0241
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[010/030] Train loss: 0.0245
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[011/030] Train loss: 0.0245
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[015/030] Train loss: 0.0245
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:55:59 | Train | Epoch[435/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:56:00 | Train | Epoch[435/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:56:00 | Train | Epoch[435/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:56:00 | Train | Epoch[435/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:56:00 | Train | Epoch[435/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:56:00 | Train | Epoch[435/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:56:00 | Train | Epoch[435/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:56:00 | Train | Epoch[435/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:56:00 | Valid | Epoch[435/600] Iteration[001/008] Valid loss: 0.0345
2023-02-06 10:56:00 | Valid | Epoch[435/600] Iteration[002/008] Valid loss: 0.0311
2023-02-06 10:56:00 | Valid | Epoch[435/600] Iteration[003/008] Valid loss: 0.0312
2023-02-06 10:56:00 | Valid | Epoch[435/600] Iteration[004/008] Valid loss: 0.0302
2023-02-06 10:56:00 | Valid | Epoch[435/600] Iteration[005/008] Valid loss: 0.0307
2023-02-06 10:56:00 | Valid | Epoch[435/600] Iteration[006/008] Valid loss: 0.0304
2023-02-06 10:56:00 | Valid | Epoch[435/600] Iteration[007/008] Valid loss: 0.0299
2023-02-06 10:56:00 | Valid | Epoch[435/600] Iteration[008/008] Valid loss: 0.0301
2023-02-06 10:56:00 | Valid | Epoch[435/600] MIou: 0.9022501409974193
2023-02-06 10:56:00 | Valid | Epoch[435/600] Pixel Accuracy: 0.9838294982910156
2023-02-06 10:56:00 | Valid | Epoch[435/600] Mean Pixel Accuracy: 0.9130481173487979
2023-02-06 10:56:00 | Stage | Epoch[435/600] Train loss:0.0253
2023-02-06 10:56:00 | Stage | Epoch[435/600] Valid loss:0.0301
2023-02-06 10:56:00 | Stage | Epoch[435/600] LR:0.001

2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[001/030] Train loss: 0.0263
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[003/030] Train loss: 0.0244
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[005/030] Train loss: 0.0260
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[006/030] Train loss: 0.0258
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[009/030] Train loss: 0.0243
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[011/030] Train loss: 0.0245
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[012/030] Train loss: 0.0245
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[013/030] Train loss: 0.0247
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[017/030] Train loss: 0.0245
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:56:01 | Train | Epoch[436/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:56:02 | Train | Epoch[436/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:56:02 | Train | Epoch[436/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:56:02 | Train | Epoch[436/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:56:02 | Train | Epoch[436/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:56:02 | Train | Epoch[436/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:56:02 | Train | Epoch[436/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:56:02 | Train | Epoch[436/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:56:02 | Train | Epoch[436/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:56:02 | Train | Epoch[436/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:56:02 | Train | Epoch[436/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:56:02 | Valid | Epoch[436/600] Iteration[001/008] Valid loss: 0.0508
2023-02-06 10:56:02 | Valid | Epoch[436/600] Iteration[002/008] Valid loss: 0.0415
2023-02-06 10:56:02 | Valid | Epoch[436/600] Iteration[003/008] Valid loss: 0.0389
2023-02-06 10:56:02 | Valid | Epoch[436/600] Iteration[004/008] Valid loss: 0.0373
2023-02-06 10:56:02 | Valid | Epoch[436/600] Iteration[005/008] Valid loss: 0.0386
2023-02-06 10:56:02 | Valid | Epoch[436/600] Iteration[006/008] Valid loss: 0.0394
2023-02-06 10:56:02 | Valid | Epoch[436/600] Iteration[007/008] Valid loss: 0.0410
2023-02-06 10:56:02 | Valid | Epoch[436/600] Iteration[008/008] Valid loss: 0.0404
2023-02-06 10:56:03 | Valid | Epoch[436/600] MIou: 0.9372836879671267
2023-02-06 10:56:03 | Valid | Epoch[436/600] Pixel Accuracy: 0.989166259765625
2023-02-06 10:56:03 | Valid | Epoch[436/600] Mean Pixel Accuracy: 0.9652088498824027
2023-02-06 10:56:03 | Stage | Epoch[436/600] Train loss:0.0252
2023-02-06 10:56:03 | Stage | Epoch[436/600] Valid loss:0.0404
2023-02-06 10:56:03 | Stage | Epoch[436/600] LR:0.001

2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[001/030] Train loss: 0.0232
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[002/030] Train loss: 0.0282
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[004/030] Train loss: 0.0264
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[005/030] Train loss: 0.0262
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[006/030] Train loss: 0.0262
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[007/030] Train loss: 0.0264
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:56:03 | Train | Epoch[437/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:56:04 | Train | Epoch[437/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:56:04 | Valid | Epoch[437/600] Iteration[001/008] Valid loss: 0.0372
2023-02-06 10:56:04 | Valid | Epoch[437/600] Iteration[002/008] Valid loss: 0.0316
2023-02-06 10:56:04 | Valid | Epoch[437/600] Iteration[003/008] Valid loss: 0.0306
2023-02-06 10:56:04 | Valid | Epoch[437/600] Iteration[004/008] Valid loss: 0.0293
2023-02-06 10:56:04 | Valid | Epoch[437/600] Iteration[005/008] Valid loss: 0.0302
2023-02-06 10:56:04 | Valid | Epoch[437/600] Iteration[006/008] Valid loss: 0.0305
2023-02-06 10:56:05 | Valid | Epoch[437/600] Iteration[007/008] Valid loss: 0.0310
2023-02-06 10:56:05 | Valid | Epoch[437/600] Iteration[008/008] Valid loss: 0.0306
2023-02-06 10:56:05 | Valid | Epoch[437/600] MIou: 0.9320694908369231
2023-02-06 10:56:05 | Valid | Epoch[437/600] Pixel Accuracy: 0.9885775248209635
2023-02-06 10:56:05 | Valid | Epoch[437/600] Mean Pixel Accuracy: 0.9478547495664322
2023-02-06 10:56:05 | Stage | Epoch[437/600] Train loss:0.0251
2023-02-06 10:56:05 | Stage | Epoch[437/600] Valid loss:0.0306
2023-02-06 10:56:05 | Stage | Epoch[437/600] LR:0.001

2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[001/030] Train loss: 0.0232
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[010/030] Train loss: 0.0245
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:56:05 | Train | Epoch[438/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[022/030] Train loss: 0.0247
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:56:06 | Train | Epoch[438/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:56:07 | Valid | Epoch[438/600] Iteration[001/008] Valid loss: 0.0338
2023-02-06 10:56:07 | Valid | Epoch[438/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:56:07 | Valid | Epoch[438/600] Iteration[003/008] Valid loss: 0.0297
2023-02-06 10:56:07 | Valid | Epoch[438/600] Iteration[004/008] Valid loss: 0.0287
2023-02-06 10:56:07 | Valid | Epoch[438/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 10:56:07 | Valid | Epoch[438/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:56:07 | Valid | Epoch[438/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:56:07 | Valid | Epoch[438/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:56:07 | Valid | Epoch[438/600] MIou: 0.9160886213908284
2023-02-06 10:56:07 | Valid | Epoch[438/600] Pixel Accuracy: 0.9860636393229166
2023-02-06 10:56:07 | Valid | Epoch[438/600] Mean Pixel Accuracy: 0.9275213415324759
2023-02-06 10:56:07 | Stage | Epoch[438/600] Train loss:0.0252
2023-02-06 10:56:07 | Stage | Epoch[438/600] Valid loss:0.0289
2023-02-06 10:56:07 | Stage | Epoch[438/600] LR:0.001

2023-02-06 10:56:07 | Train | Epoch[439/600] Iteration[001/030] Train loss: 0.0275
2023-02-06 10:56:07 | Train | Epoch[439/600] Iteration[002/030] Train loss: 0.0269
2023-02-06 10:56:07 | Train | Epoch[439/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 10:56:07 | Train | Epoch[439/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 10:56:07 | Train | Epoch[439/600] Iteration[005/030] Train loss: 0.0262
2023-02-06 10:56:07 | Train | Epoch[439/600] Iteration[006/030] Train loss: 0.0262
2023-02-06 10:56:07 | Train | Epoch[439/600] Iteration[007/030] Train loss: 0.0268
2023-02-06 10:56:07 | Train | Epoch[439/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:56:07 | Train | Epoch[439/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[013/030] Train loss: 0.0260
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[014/030] Train loss: 0.0259
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[015/030] Train loss: 0.0258
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:56:08 | Train | Epoch[439/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 10:56:09 | Valid | Epoch[439/600] Iteration[001/008] Valid loss: 0.0338
2023-02-06 10:56:09 | Valid | Epoch[439/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:56:09 | Valid | Epoch[439/600] Iteration[003/008] Valid loss: 0.0299
2023-02-06 10:56:09 | Valid | Epoch[439/600] Iteration[004/008] Valid loss: 0.0289
2023-02-06 10:56:09 | Valid | Epoch[439/600] Iteration[005/008] Valid loss: 0.0294
2023-02-06 10:56:09 | Valid | Epoch[439/600] Iteration[006/008] Valid loss: 0.0293
2023-02-06 10:56:09 | Valid | Epoch[439/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:56:09 | Valid | Epoch[439/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 10:56:09 | Valid | Epoch[439/600] MIou: 0.9126424322014846
2023-02-06 10:56:09 | Valid | Epoch[439/600] Pixel Accuracy: 0.9855028788248698
2023-02-06 10:56:09 | Valid | Epoch[439/600] Mean Pixel Accuracy: 0.9239858236472439
2023-02-06 10:56:09 | Stage | Epoch[439/600] Train loss:0.0249
2023-02-06 10:56:09 | Stage | Epoch[439/600] Valid loss:0.0291
2023-02-06 10:56:09 | Stage | Epoch[439/600] LR:0.001

2023-02-06 10:56:09 | Train | Epoch[440/600] Iteration[001/030] Train loss: 0.0296
2023-02-06 10:56:09 | Train | Epoch[440/600] Iteration[002/030] Train loss: 0.0271
2023-02-06 10:56:09 | Train | Epoch[440/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 10:56:09 | Train | Epoch[440/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 10:56:09 | Train | Epoch[440/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 10:56:09 | Train | Epoch[440/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:56:09 | Train | Epoch[440/600] Iteration[007/030] Train loss: 0.0259
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[008/030] Train loss: 0.0263
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[013/030] Train loss: 0.0253
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[020/030] Train loss: 0.0256
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[029/030] Train loss: 0.0255
2023-02-06 10:56:10 | Train | Epoch[440/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:56:11 | Valid | Epoch[440/600] Iteration[001/008] Valid loss: 0.0371
2023-02-06 10:56:11 | Valid | Epoch[440/600] Iteration[002/008] Valid loss: 0.0350
2023-02-06 10:56:11 | Valid | Epoch[440/600] Iteration[003/008] Valid loss: 0.0357
2023-02-06 10:56:11 | Valid | Epoch[440/600] Iteration[004/008] Valid loss: 0.0347
2023-02-06 10:56:11 | Valid | Epoch[440/600] Iteration[005/008] Valid loss: 0.0353
2023-02-06 10:56:11 | Valid | Epoch[440/600] Iteration[006/008] Valid loss: 0.0347
2023-02-06 10:56:11 | Valid | Epoch[440/600] Iteration[007/008] Valid loss: 0.0339
2023-02-06 10:56:11 | Valid | Epoch[440/600] Iteration[008/008] Valid loss: 0.0343
2023-02-06 10:56:11 | Valid | Epoch[440/600] MIou: 0.8788876260701196
2023-02-06 10:56:11 | Valid | Epoch[440/600] Pixel Accuracy: 0.9800287882486979
2023-02-06 10:56:11 | Valid | Epoch[440/600] Mean Pixel Accuracy: 0.8902194026971642
2023-02-06 10:56:11 | Stage | Epoch[440/600] Train loss:0.0254
2023-02-06 10:56:11 | Stage | Epoch[440/600] Valid loss:0.0343
2023-02-06 10:56:11 | Stage | Epoch[440/600] LR:0.001

2023-02-06 10:56:11 | Train | Epoch[441/600] Iteration[001/030] Train loss: 0.0263
2023-02-06 10:56:11 | Train | Epoch[441/600] Iteration[002/030] Train loss: 0.0263
2023-02-06 10:56:11 | Train | Epoch[441/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[004/030] Train loss: 0.0263
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[005/030] Train loss: 0.0257
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[007/030] Train loss: 0.0260
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[013/030] Train loss: 0.0253
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[022/030] Train loss: 0.0258
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 10:56:12 | Train | Epoch[441/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:56:13 | Train | Epoch[441/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 10:56:13 | Train | Epoch[441/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:56:13 | Train | Epoch[441/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:56:13 | Train | Epoch[441/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:56:13 | Train | Epoch[441/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:56:13 | Valid | Epoch[441/600] Iteration[001/008] Valid loss: 0.0512
2023-02-06 10:56:13 | Valid | Epoch[441/600] Iteration[002/008] Valid loss: 0.0415
2023-02-06 10:56:13 | Valid | Epoch[441/600] Iteration[003/008] Valid loss: 0.0388
2023-02-06 10:56:13 | Valid | Epoch[441/600] Iteration[004/008] Valid loss: 0.0372
2023-02-06 10:56:13 | Valid | Epoch[441/600] Iteration[005/008] Valid loss: 0.0384
2023-02-06 10:56:13 | Valid | Epoch[441/600] Iteration[006/008] Valid loss: 0.0390
2023-02-06 10:56:13 | Valid | Epoch[441/600] Iteration[007/008] Valid loss: 0.0406
2023-02-06 10:56:13 | Valid | Epoch[441/600] Iteration[008/008] Valid loss: 0.0400
2023-02-06 10:56:13 | Valid | Epoch[441/600] MIou: 0.9374824816011647
2023-02-06 10:56:13 | Valid | Epoch[441/600] Pixel Accuracy: 0.9892222086588541
2023-02-06 10:56:13 | Valid | Epoch[441/600] Mean Pixel Accuracy: 0.9644597237842982
2023-02-06 10:56:13 | Stage | Epoch[441/600] Train loss:0.0253
2023-02-06 10:56:13 | Stage | Epoch[441/600] Valid loss:0.0400
2023-02-06 10:56:13 | Stage | Epoch[441/600] LR:0.001

2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[001/030] Train loss: 0.0274
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[002/030] Train loss: 0.0270
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[004/030] Train loss: 0.0265
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[005/030] Train loss: 0.0262
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[006/030] Train loss: 0.0256
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[009/030] Train loss: 0.0240
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[010/030] Train loss: 0.0237
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[011/030] Train loss: 0.0240
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[012/030] Train loss: 0.0239
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[013/030] Train loss: 0.0240
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[014/030] Train loss: 0.0242
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[015/030] Train loss: 0.0243
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[016/030] Train loss: 0.0245
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[017/030] Train loss: 0.0245
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:56:14 | Train | Epoch[442/600] Iteration[020/030] Train loss: 0.0246
2023-02-06 10:56:15 | Train | Epoch[442/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 10:56:15 | Train | Epoch[442/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:56:15 | Train | Epoch[442/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 10:56:15 | Train | Epoch[442/600] Iteration[024/030] Train loss: 0.0248
2023-02-06 10:56:15 | Train | Epoch[442/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:56:15 | Train | Epoch[442/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:56:15 | Train | Epoch[442/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:56:15 | Train | Epoch[442/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:56:15 | Train | Epoch[442/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:56:15 | Train | Epoch[442/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:56:15 | Valid | Epoch[442/600] Iteration[001/008] Valid loss: 0.0353
2023-02-06 10:56:15 | Valid | Epoch[442/600] Iteration[002/008] Valid loss: 0.0327
2023-02-06 10:56:15 | Valid | Epoch[442/600] Iteration[003/008] Valid loss: 0.0331
2023-02-06 10:56:15 | Valid | Epoch[442/600] Iteration[004/008] Valid loss: 0.0322
2023-02-06 10:56:15 | Valid | Epoch[442/600] Iteration[005/008] Valid loss: 0.0327
2023-02-06 10:56:15 | Valid | Epoch[442/600] Iteration[006/008] Valid loss: 0.0322
2023-02-06 10:56:15 | Valid | Epoch[442/600] Iteration[007/008] Valid loss: 0.0315
2023-02-06 10:56:15 | Valid | Epoch[442/600] Iteration[008/008] Valid loss: 0.0319
2023-02-06 10:56:15 | Valid | Epoch[442/600] MIou: 0.8906366181551779
2023-02-06 10:56:15 | Valid | Epoch[442/600] Pixel Accuracy: 0.9819424947102865
2023-02-06 10:56:15 | Valid | Epoch[442/600] Mean Pixel Accuracy: 0.9015618426501653
2023-02-06 10:56:15 | Stage | Epoch[442/600] Train loss:0.0251
2023-02-06 10:56:15 | Stage | Epoch[442/600] Valid loss:0.0319
2023-02-06 10:56:15 | Stage | Epoch[442/600] LR:0.001

2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[001/030] Train loss: 0.0243
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[002/030] Train loss: 0.0250
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[003/030] Train loss: 0.0251
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[004/030] Train loss: 0.0254
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[006/030] Train loss: 0.0241
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[007/030] Train loss: 0.0241
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[008/030] Train loss: 0.0240
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[010/030] Train loss: 0.0244
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[012/030] Train loss: 0.0242
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[013/030] Train loss: 0.0244
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[014/030] Train loss: 0.0241
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[015/030] Train loss: 0.0243
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[018/030] Train loss: 0.0243
2023-02-06 10:56:16 | Train | Epoch[443/600] Iteration[019/030] Train loss: 0.0244
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[020/030] Train loss: 0.0244
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[023/030] Train loss: 0.0245
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:56:17 | Train | Epoch[443/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:56:17 | Valid | Epoch[443/600] Iteration[001/008] Valid loss: 0.0870
2023-02-06 10:56:17 | Valid | Epoch[443/600] Iteration[002/008] Valid loss: 0.0670
2023-02-06 10:56:17 | Valid | Epoch[443/600] Iteration[003/008] Valid loss: 0.0619
2023-02-06 10:56:17 | Valid | Epoch[443/600] Iteration[004/008] Valid loss: 0.0589
2023-02-06 10:56:17 | Valid | Epoch[443/600] Iteration[005/008] Valid loss: 0.0616
2023-02-06 10:56:17 | Valid | Epoch[443/600] Iteration[006/008] Valid loss: 0.0625
2023-02-06 10:56:17 | Valid | Epoch[443/600] Iteration[007/008] Valid loss: 0.0660
2023-02-06 10:56:17 | Valid | Epoch[443/600] Iteration[008/008] Valid loss: 0.0646
2023-02-06 10:56:18 | Valid | Epoch[443/600] MIou: 0.930929299301984
2023-02-06 10:56:18 | Valid | Epoch[443/600] Pixel Accuracy: 0.9876861572265625
2023-02-06 10:56:18 | Valid | Epoch[443/600] Mean Pixel Accuracy: 0.9740138176859126
2023-02-06 10:56:18 | Stage | Epoch[443/600] Train loss:0.0252
2023-02-06 10:56:18 | Stage | Epoch[443/600] Valid loss:0.0646
2023-02-06 10:56:18 | Stage | Epoch[443/600] LR:0.001

2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[001/030] Train loss: 0.0271
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[002/030] Train loss: 0.0288
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[003/030] Train loss: 0.0275
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[004/030] Train loss: 0.0273
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 10:56:18 | Train | Epoch[444/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:56:19 | Train | Epoch[444/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:56:19 | Valid | Epoch[444/600] Iteration[001/008] Valid loss: 0.0356
2023-02-06 10:56:19 | Valid | Epoch[444/600] Iteration[002/008] Valid loss: 0.0307
2023-02-06 10:56:19 | Valid | Epoch[444/600] Iteration[003/008] Valid loss: 0.0298
2023-02-06 10:56:20 | Valid | Epoch[444/600] Iteration[004/008] Valid loss: 0.0287
2023-02-06 10:56:20 | Valid | Epoch[444/600] Iteration[005/008] Valid loss: 0.0294
2023-02-06 10:56:20 | Valid | Epoch[444/600] Iteration[006/008] Valid loss: 0.0296
2023-02-06 10:56:20 | Valid | Epoch[444/600] Iteration[007/008] Valid loss: 0.0299
2023-02-06 10:56:20 | Valid | Epoch[444/600] Iteration[008/008] Valid loss: 0.0297
2023-02-06 10:56:20 | Valid | Epoch[444/600] MIou: 0.9280919898705597
2023-02-06 10:56:20 | Valid | Epoch[444/600] Pixel Accuracy: 0.9879570007324219
2023-02-06 10:56:20 | Valid | Epoch[444/600] Mean Pixel Accuracy: 0.9423398583088004
2023-02-06 10:56:20 | Stage | Epoch[444/600] Train loss:0.0251
2023-02-06 10:56:20 | Stage | Epoch[444/600] Valid loss:0.0297
2023-02-06 10:56:20 | Stage | Epoch[444/600] LR:0.001

2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[001/030] Train loss: 0.0252
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[006/030] Train loss: 0.0264
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[007/030] Train loss: 0.0263
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 10:56:20 | Train | Epoch[445/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:56:21 | Train | Epoch[445/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:56:21 | Valid | Epoch[445/600] Iteration[001/008] Valid loss: 0.0346
2023-02-06 10:56:22 | Valid | Epoch[445/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:56:22 | Valid | Epoch[445/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:56:22 | Valid | Epoch[445/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:56:22 | Valid | Epoch[445/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:56:22 | Valid | Epoch[445/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:56:22 | Valid | Epoch[445/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:56:22 | Valid | Epoch[445/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:56:22 | Valid | Epoch[445/600] MIou: 0.9237061184009571
2023-02-06 10:56:22 | Valid | Epoch[445/600] Pixel Accuracy: 0.9872779846191406
2023-02-06 10:56:22 | Valid | Epoch[445/600] Mean Pixel Accuracy: 0.9363299629193653
2023-02-06 10:56:22 | Stage | Epoch[445/600] Train loss:0.0252
2023-02-06 10:56:22 | Stage | Epoch[445/600] Valid loss:0.0290
2023-02-06 10:56:22 | Stage | Epoch[445/600] LR:0.001

2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[001/030] Train loss: 0.0223
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[003/030] Train loss: 0.0246
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[006/030] Train loss: 0.0236
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[007/030] Train loss: 0.0237
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[008/030] Train loss: 0.0237
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[009/030] Train loss: 0.0240
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[012/030] Train loss: 0.0244
2023-02-06 10:56:22 | Train | Epoch[446/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[014/030] Train loss: 0.0239
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[015/030] Train loss: 0.0239
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[016/030] Train loss: 0.0239
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[017/030] Train loss: 0.0240
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[018/030] Train loss: 0.0240
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[019/030] Train loss: 0.0241
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[020/030] Train loss: 0.0241
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[021/030] Train loss: 0.0242
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[022/030] Train loss: 0.0242
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[023/030] Train loss: 0.0243
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[024/030] Train loss: 0.0243
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[025/030] Train loss: 0.0244
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[026/030] Train loss: 0.0245
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[027/030] Train loss: 0.0246
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[028/030] Train loss: 0.0248
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:56:23 | Train | Epoch[446/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:56:24 | Valid | Epoch[446/600] Iteration[001/008] Valid loss: 0.0355
2023-02-06 10:56:24 | Valid | Epoch[446/600] Iteration[002/008] Valid loss: 0.0305
2023-02-06 10:56:24 | Valid | Epoch[446/600] Iteration[003/008] Valid loss: 0.0297
2023-02-06 10:56:24 | Valid | Epoch[446/600] Iteration[004/008] Valid loss: 0.0286
2023-02-06 10:56:24 | Valid | Epoch[446/600] Iteration[005/008] Valid loss: 0.0293
2023-02-06 10:56:24 | Valid | Epoch[446/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 10:56:24 | Valid | Epoch[446/600] Iteration[007/008] Valid loss: 0.0296
2023-02-06 10:56:24 | Valid | Epoch[446/600] Iteration[008/008] Valid loss: 0.0294
2023-02-06 10:56:24 | Valid | Epoch[446/600] MIou: 0.9270091128909443
2023-02-06 10:56:24 | Valid | Epoch[446/600] Pixel Accuracy: 0.9878056844075521
2023-02-06 10:56:24 | Valid | Epoch[446/600] Mean Pixel Accuracy: 0.9402404184623254
2023-02-06 10:56:24 | Stage | Epoch[446/600] Train loss:0.0251
2023-02-06 10:56:24 | Stage | Epoch[446/600] Valid loss:0.0294
2023-02-06 10:56:24 | Stage | Epoch[446/600] LR:0.001

2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[002/030] Train loss: 0.0249
2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[006/030] Train loss: 0.0242
2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[009/030] Train loss: 0.0247
2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:56:24 | Train | Epoch[447/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:56:25 | Train | Epoch[447/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:56:26 | Valid | Epoch[447/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 10:56:26 | Valid | Epoch[447/600] Iteration[002/008] Valid loss: 0.0302
2023-02-06 10:56:26 | Valid | Epoch[447/600] Iteration[003/008] Valid loss: 0.0301
2023-02-06 10:56:26 | Valid | Epoch[447/600] Iteration[004/008] Valid loss: 0.0290
2023-02-06 10:56:26 | Valid | Epoch[447/600] Iteration[005/008] Valid loss: 0.0296
2023-02-06 10:56:26 | Valid | Epoch[447/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 10:56:26 | Valid | Epoch[447/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:56:26 | Valid | Epoch[447/600] Iteration[008/008] Valid loss: 0.0292
2023-02-06 10:56:26 | Valid | Epoch[447/600] MIou: 0.912288894636982
2023-02-06 10:56:26 | Valid | Epoch[447/600] Pixel Accuracy: 0.9854532877604166
2023-02-06 10:56:26 | Valid | Epoch[447/600] Mean Pixel Accuracy: 0.9233942643186376
2023-02-06 10:56:26 | Stage | Epoch[447/600] Train loss:0.0253
2023-02-06 10:56:26 | Stage | Epoch[447/600] Valid loss:0.0292
2023-02-06 10:56:26 | Stage | Epoch[447/600] LR:0.001

2023-02-06 10:56:26 | Train | Epoch[448/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 10:56:26 | Train | Epoch[448/600] Iteration[002/030] Train loss: 0.0253
2023-02-06 10:56:26 | Train | Epoch[448/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 10:56:26 | Train | Epoch[448/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:56:26 | Train | Epoch[448/600] Iteration[005/030] Train loss: 0.0263
2023-02-06 10:56:26 | Train | Epoch[448/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:56:26 | Train | Epoch[448/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:56:26 | Train | Epoch[448/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:56:26 | Train | Epoch[448/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:56:27 | Train | Epoch[448/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:56:28 | Valid | Epoch[448/600] Iteration[001/008] Valid loss: 0.0366
2023-02-06 10:56:28 | Valid | Epoch[448/600] Iteration[002/008] Valid loss: 0.0315
2023-02-06 10:56:28 | Valid | Epoch[448/600] Iteration[003/008] Valid loss: 0.0304
2023-02-06 10:56:28 | Valid | Epoch[448/600] Iteration[004/008] Valid loss: 0.0293
2023-02-06 10:56:28 | Valid | Epoch[448/600] Iteration[005/008] Valid loss: 0.0301
2023-02-06 10:56:28 | Valid | Epoch[448/600] Iteration[006/008] Valid loss: 0.0305
2023-02-06 10:56:28 | Valid | Epoch[448/600] Iteration[007/008] Valid loss: 0.0309
2023-02-06 10:56:28 | Valid | Epoch[448/600] Iteration[008/008] Valid loss: 0.0306
2023-02-06 10:56:28 | Valid | Epoch[448/600] MIou: 0.9311956009516196
2023-02-06 10:56:28 | Valid | Epoch[448/600] Pixel Accuracy: 0.9884440104166666
2023-02-06 10:56:28 | Valid | Epoch[448/600] Mean Pixel Accuracy: 0.9465132700531632
2023-02-06 10:56:28 | Stage | Epoch[448/600] Train loss:0.0251
2023-02-06 10:56:28 | Stage | Epoch[448/600] Valid loss:0.0306
2023-02-06 10:56:28 | Stage | Epoch[448/600] LR:0.001

2023-02-06 10:56:28 | Train | Epoch[449/600] Iteration[001/030] Train loss: 0.0223
2023-02-06 10:56:28 | Train | Epoch[449/600] Iteration[002/030] Train loss: 0.0261
2023-02-06 10:56:28 | Train | Epoch[449/600] Iteration[003/030] Train loss: 0.0258
2023-02-06 10:56:28 | Train | Epoch[449/600] Iteration[004/030] Train loss: 0.0258
2023-02-06 10:56:28 | Train | Epoch[449/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 10:56:28 | Train | Epoch[449/600] Iteration[006/030] Train loss: 0.0246
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[007/030] Train loss: 0.0254
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:56:29 | Train | Epoch[449/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:56:30 | Valid | Epoch[449/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 10:56:30 | Valid | Epoch[449/600] Iteration[002/008] Valid loss: 0.0311
2023-02-06 10:56:30 | Valid | Epoch[449/600] Iteration[003/008] Valid loss: 0.0314
2023-02-06 10:56:30 | Valid | Epoch[449/600] Iteration[004/008] Valid loss: 0.0303
2023-02-06 10:56:30 | Valid | Epoch[449/600] Iteration[005/008] Valid loss: 0.0309
2023-02-06 10:56:30 | Valid | Epoch[449/600] Iteration[006/008] Valid loss: 0.0306
2023-02-06 10:56:30 | Valid | Epoch[449/600] Iteration[007/008] Valid loss: 0.0301
2023-02-06 10:56:30 | Valid | Epoch[449/600] Iteration[008/008] Valid loss: 0.0303
2023-02-06 10:56:30 | Valid | Epoch[449/600] MIou: 0.9032236011999633
2023-02-06 10:56:30 | Valid | Epoch[449/600] Pixel Accuracy: 0.9839909871419271
2023-02-06 10:56:30 | Valid | Epoch[449/600] Mean Pixel Accuracy: 0.9139357779191137
2023-02-06 10:56:30 | Stage | Epoch[449/600] Train loss:0.0254
2023-02-06 10:56:30 | Stage | Epoch[449/600] Valid loss:0.0303
2023-02-06 10:56:30 | Stage | Epoch[449/600] LR:0.001

2023-02-06 10:56:30 | Train | Epoch[450/600] Iteration[001/030] Train loss: 0.0230
2023-02-06 10:56:30 | Train | Epoch[450/600] Iteration[002/030] Train loss: 0.0263
2023-02-06 10:56:30 | Train | Epoch[450/600] Iteration[003/030] Train loss: 0.0271
2023-02-06 10:56:30 | Train | Epoch[450/600] Iteration[004/030] Train loss: 0.0266
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[005/030] Train loss: 0.0279
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[006/030] Train loss: 0.0277
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[007/030] Train loss: 0.0277
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[008/030] Train loss: 0.0266
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:56:31 | Train | Epoch[450/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:56:32 | Train | Epoch[450/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:56:32 | Train | Epoch[450/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:56:32 | Train | Epoch[450/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:56:32 | Valid | Epoch[450/600] Iteration[001/008] Valid loss: 0.0338
2023-02-06 10:56:32 | Valid | Epoch[450/600] Iteration[002/008] Valid loss: 0.0309
2023-02-06 10:56:32 | Valid | Epoch[450/600] Iteration[003/008] Valid loss: 0.0311
2023-02-06 10:56:32 | Valid | Epoch[450/600] Iteration[004/008] Valid loss: 0.0301
2023-02-06 10:56:32 | Valid | Epoch[450/600] Iteration[005/008] Valid loss: 0.0307
2023-02-06 10:56:32 | Valid | Epoch[450/600] Iteration[006/008] Valid loss: 0.0304
2023-02-06 10:56:32 | Valid | Epoch[450/600] Iteration[007/008] Valid loss: 0.0300
2023-02-06 10:56:32 | Valid | Epoch[450/600] Iteration[008/008] Valid loss: 0.0302
2023-02-06 10:56:32 | Valid | Epoch[450/600] MIou: 0.9026728674808704
2023-02-06 10:56:32 | Valid | Epoch[450/600] Pixel Accuracy: 0.9838968912760416
2023-02-06 10:56:32 | Valid | Epoch[450/600] Mean Pixel Accuracy: 0.9135036305274067
2023-02-06 10:56:32 | Stage | Epoch[450/600] Train loss:0.0253
2023-02-06 10:56:32 | Stage | Epoch[450/600] Valid loss:0.0302
2023-02-06 10:56:32 | Stage | Epoch[450/600] LR:0.001

2023-02-06 10:56:32 | Train | Epoch[451/600] Iteration[001/030] Train loss: 0.0319
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[002/030] Train loss: 0.0303
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[003/030] Train loss: 0.0286
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[004/030] Train loss: 0.0278
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[005/030] Train loss: 0.0273
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[006/030] Train loss: 0.0265
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[007/030] Train loss: 0.0270
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[023/030] Train loss: 0.0260
2023-02-06 10:56:33 | Train | Epoch[451/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 10:56:34 | Train | Epoch[451/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:56:34 | Train | Epoch[451/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:56:34 | Train | Epoch[451/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:56:34 | Train | Epoch[451/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:56:34 | Train | Epoch[451/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:56:34 | Train | Epoch[451/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:56:34 | Valid | Epoch[451/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:56:34 | Valid | Epoch[451/600] Iteration[002/008] Valid loss: 0.0302
2023-02-06 10:56:34 | Valid | Epoch[451/600] Iteration[003/008] Valid loss: 0.0299
2023-02-06 10:56:34 | Valid | Epoch[451/600] Iteration[004/008] Valid loss: 0.0288
2023-02-06 10:56:34 | Valid | Epoch[451/600] Iteration[005/008] Valid loss: 0.0295
2023-02-06 10:56:34 | Valid | Epoch[451/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 10:56:34 | Valid | Epoch[451/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:56:34 | Valid | Epoch[451/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 10:56:34 | Valid | Epoch[451/600] MIou: 0.9148401415767814
2023-02-06 10:56:34 | Valid | Epoch[451/600] Pixel Accuracy: 0.985864003499349
2023-02-06 10:56:34 | Valid | Epoch[451/600] Mean Pixel Accuracy: 0.926130837924141
2023-02-06 10:56:34 | Stage | Epoch[451/600] Train loss:0.0252
2023-02-06 10:56:34 | Stage | Epoch[451/600] Valid loss:0.0291
2023-02-06 10:56:34 | Stage | Epoch[451/600] LR:0.001

2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[006/030] Train loss: 0.0258
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[007/030] Train loss: 0.0260
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[013/030] Train loss: 0.0259
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[014/030] Train loss: 0.0265
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[015/030] Train loss: 0.0264
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[016/030] Train loss: 0.0263
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[017/030] Train loss: 0.0261
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:56:35 | Train | Epoch[452/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:56:36 | Train | Epoch[452/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:56:36 | Train | Epoch[452/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:56:36 | Train | Epoch[452/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:56:36 | Train | Epoch[452/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:56:36 | Train | Epoch[452/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:56:36 | Train | Epoch[452/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 10:56:36 | Train | Epoch[452/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:56:36 | Train | Epoch[452/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:56:36 | Train | Epoch[452/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:56:36 | Valid | Epoch[452/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 10:56:36 | Valid | Epoch[452/600] Iteration[002/008] Valid loss: 0.0313
2023-02-06 10:56:36 | Valid | Epoch[452/600] Iteration[003/008] Valid loss: 0.0315
2023-02-06 10:56:36 | Valid | Epoch[452/600] Iteration[004/008] Valid loss: 0.0305
2023-02-06 10:56:36 | Valid | Epoch[452/600] Iteration[005/008] Valid loss: 0.0310
2023-02-06 10:56:36 | Valid | Epoch[452/600] Iteration[006/008] Valid loss: 0.0307
2023-02-06 10:56:36 | Valid | Epoch[452/600] Iteration[007/008] Valid loss: 0.0302
2023-02-06 10:56:36 | Valid | Epoch[452/600] Iteration[008/008] Valid loss: 0.0303
2023-02-06 10:56:36 | Valid | Epoch[452/600] MIou: 0.9015555522791392
2023-02-06 10:56:36 | Valid | Epoch[452/600] Pixel Accuracy: 0.9837214152018229
2023-02-06 10:56:36 | Valid | Epoch[452/600] Mean Pixel Accuracy: 0.9122341941634078
2023-02-06 10:56:36 | Stage | Epoch[452/600] Train loss:0.0251
2023-02-06 10:56:36 | Stage | Epoch[452/600] Valid loss:0.0303
2023-02-06 10:56:36 | Stage | Epoch[452/600] LR:0.001

2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[001/030] Train loss: 0.0245
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[002/030] Train loss: 0.0250
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[003/030] Train loss: 0.0261
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[005/030] Train loss: 0.0260
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[006/030] Train loss: 0.0256
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[008/030] Train loss: 0.0264
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[013/030] Train loss: 0.0253
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:56:37 | Train | Epoch[453/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:56:38 | Train | Epoch[453/600] Iteration[030/030] Train loss: 0.0248
2023-02-06 10:56:38 | Valid | Epoch[453/600] Iteration[001/008] Valid loss: 0.0383
2023-02-06 10:56:38 | Valid | Epoch[453/600] Iteration[002/008] Valid loss: 0.0325
2023-02-06 10:56:38 | Valid | Epoch[453/600] Iteration[003/008] Valid loss: 0.0312
2023-02-06 10:56:38 | Valid | Epoch[453/600] Iteration[004/008] Valid loss: 0.0300
2023-02-06 10:56:38 | Valid | Epoch[453/600] Iteration[005/008] Valid loss: 0.0309
2023-02-06 10:56:38 | Valid | Epoch[453/600] Iteration[006/008] Valid loss: 0.0312
2023-02-06 10:56:38 | Valid | Epoch[453/600] Iteration[007/008] Valid loss: 0.0319
2023-02-06 10:56:38 | Valid | Epoch[453/600] Iteration[008/008] Valid loss: 0.0315
2023-02-06 10:56:39 | Valid | Epoch[453/600] MIou: 0.9340532733453658
2023-02-06 10:56:39 | Valid | Epoch[453/600] Pixel Accuracy: 0.9888725280761719
2023-02-06 10:56:39 | Valid | Epoch[453/600] Mean Pixel Accuracy: 0.9512885792373125
2023-02-06 10:56:39 | Stage | Epoch[453/600] Train loss:0.0248
2023-02-06 10:56:39 | Stage | Epoch[453/600] Valid loss:0.0315
2023-02-06 10:56:39 | Stage | Epoch[453/600] LR:0.001

2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[001/030] Train loss: 0.0249
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[003/030] Train loss: 0.0242
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[004/030] Train loss: 0.0239
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 10:56:39 | Train | Epoch[454/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:56:40 | Train | Epoch[454/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:56:40 | Valid | Epoch[454/600] Iteration[001/008] Valid loss: 0.0352
2023-02-06 10:56:40 | Valid | Epoch[454/600] Iteration[002/008] Valid loss: 0.0304
2023-02-06 10:56:40 | Valid | Epoch[454/600] Iteration[003/008] Valid loss: 0.0297
2023-02-06 10:56:40 | Valid | Epoch[454/600] Iteration[004/008] Valid loss: 0.0285
2023-02-06 10:56:41 | Valid | Epoch[454/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 10:56:41 | Valid | Epoch[454/600] Iteration[006/008] Valid loss: 0.0293
2023-02-06 10:56:41 | Valid | Epoch[454/600] Iteration[007/008] Valid loss: 0.0295
2023-02-06 10:56:41 | Valid | Epoch[454/600] Iteration[008/008] Valid loss: 0.0293
2023-02-06 10:56:41 | Valid | Epoch[454/600] MIou: 0.9255318987318972
2023-02-06 10:56:41 | Valid | Epoch[454/600] Pixel Accuracy: 0.9875679016113281
2023-02-06 10:56:41 | Valid | Epoch[454/600] Mean Pixel Accuracy: 0.9385436264328461
2023-02-06 10:56:41 | Stage | Epoch[454/600] Train loss:0.0251
2023-02-06 10:56:41 | Stage | Epoch[454/600] Valid loss:0.0293
2023-02-06 10:56:41 | Stage | Epoch[454/600] LR:0.001

2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[001/030] Train loss: 0.0251
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[002/030] Train loss: 0.0259
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:56:41 | Train | Epoch[455/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[016/030] Train loss: 0.0260
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[017/030] Train loss: 0.0262
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[018/030] Train loss: 0.0260
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[019/030] Train loss: 0.0260
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[021/030] Train loss: 0.0260
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:56:42 | Train | Epoch[455/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:56:43 | Valid | Epoch[455/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:56:43 | Valid | Epoch[455/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:56:43 | Valid | Epoch[455/600] Iteration[003/008] Valid loss: 0.0298
2023-02-06 10:56:43 | Valid | Epoch[455/600] Iteration[004/008] Valid loss: 0.0287
2023-02-06 10:56:43 | Valid | Epoch[455/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 10:56:43 | Valid | Epoch[455/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 10:56:43 | Valid | Epoch[455/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:56:43 | Valid | Epoch[455/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:56:43 | Valid | Epoch[455/600] MIou: 0.915315752192879
2023-02-06 10:56:43 | Valid | Epoch[455/600] Pixel Accuracy: 0.985937754313151
2023-02-06 10:56:43 | Valid | Epoch[455/600] Mean Pixel Accuracy: 0.9267293360098658
2023-02-06 10:56:43 | Stage | Epoch[455/600] Train loss:0.0253
2023-02-06 10:56:43 | Stage | Epoch[455/600] Valid loss:0.0290
2023-02-06 10:56:43 | Stage | Epoch[455/600] LR:0.001

2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[001/030] Train loss: 0.0289
2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[004/030] Train loss: 0.0261
2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:56:43 | Train | Epoch[456/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:56:44 | Train | Epoch[456/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:56:45 | Valid | Epoch[456/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 10:56:45 | Valid | Epoch[456/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:56:45 | Valid | Epoch[456/600] Iteration[003/008] Valid loss: 0.0296
2023-02-06 10:56:45 | Valid | Epoch[456/600] Iteration[004/008] Valid loss: 0.0285
2023-02-06 10:56:45 | Valid | Epoch[456/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:56:45 | Valid | Epoch[456/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:56:45 | Valid | Epoch[456/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:56:45 | Valid | Epoch[456/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:56:45 | Valid | Epoch[456/600] MIou: 0.9191053651942898
2023-02-06 10:56:45 | Valid | Epoch[456/600] Pixel Accuracy: 0.986548105875651
2023-02-06 10:56:45 | Valid | Epoch[456/600] Mean Pixel Accuracy: 0.930850072752192
2023-02-06 10:56:45 | Stage | Epoch[456/600] Train loss:0.0250
2023-02-06 10:56:45 | Stage | Epoch[456/600] Valid loss:0.0289
2023-02-06 10:56:45 | Stage | Epoch[456/600] LR:0.001

2023-02-06 10:56:45 | Train | Epoch[457/600] Iteration[001/030] Train loss: 0.0203
2023-02-06 10:56:45 | Train | Epoch[457/600] Iteration[002/030] Train loss: 0.0233
2023-02-06 10:56:45 | Train | Epoch[457/600] Iteration[003/030] Train loss: 0.0245
2023-02-06 10:56:45 | Train | Epoch[457/600] Iteration[004/030] Train loss: 0.0236
2023-02-06 10:56:45 | Train | Epoch[457/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 10:56:45 | Train | Epoch[457/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[009/030] Train loss: 0.0247
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:56:46 | Train | Epoch[457/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:56:47 | Valid | Epoch[457/600] Iteration[001/008] Valid loss: 0.0349
2023-02-06 10:56:47 | Valid | Epoch[457/600] Iteration[002/008] Valid loss: 0.0323
2023-02-06 10:56:47 | Valid | Epoch[457/600] Iteration[003/008] Valid loss: 0.0326
2023-02-06 10:56:47 | Valid | Epoch[457/600] Iteration[004/008] Valid loss: 0.0316
2023-02-06 10:56:47 | Valid | Epoch[457/600] Iteration[005/008] Valid loss: 0.0322
2023-02-06 10:56:47 | Valid | Epoch[457/600] Iteration[006/008] Valid loss: 0.0318
2023-02-06 10:56:47 | Valid | Epoch[457/600] Iteration[007/008] Valid loss: 0.0311
2023-02-06 10:56:47 | Valid | Epoch[457/600] Iteration[008/008] Valid loss: 0.0314
2023-02-06 10:56:47 | Valid | Epoch[457/600] MIou: 0.8933100928375218
2023-02-06 10:56:47 | Valid | Epoch[457/600] Pixel Accuracy: 0.9823786417643229
2023-02-06 10:56:47 | Valid | Epoch[457/600] Mean Pixel Accuracy: 0.9041475421317553
2023-02-06 10:56:47 | Stage | Epoch[457/600] Train loss:0.0254
2023-02-06 10:56:47 | Stage | Epoch[457/600] Valid loss:0.0314
2023-02-06 10:56:47 | Stage | Epoch[457/600] LR:0.001

2023-02-06 10:56:47 | Train | Epoch[458/600] Iteration[001/030] Train loss: 0.0267
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[003/030] Train loss: 0.0289
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[004/030] Train loss: 0.0284
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[005/030] Train loss: 0.0278
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[006/030] Train loss: 0.0278
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[007/030] Train loss: 0.0271
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[009/030] Train loss: 0.0266
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:56:48 | Train | Epoch[458/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:56:49 | Train | Epoch[458/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:56:49 | Train | Epoch[458/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:56:49 | Train | Epoch[458/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:56:49 | Train | Epoch[458/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:56:49 | Train | Epoch[458/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:56:49 | Train | Epoch[458/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:56:49 | Valid | Epoch[458/600] Iteration[001/008] Valid loss: 0.0390
2023-02-06 10:56:49 | Valid | Epoch[458/600] Iteration[002/008] Valid loss: 0.0329
2023-02-06 10:56:49 | Valid | Epoch[458/600] Iteration[003/008] Valid loss: 0.0316
2023-02-06 10:56:49 | Valid | Epoch[458/600] Iteration[004/008] Valid loss: 0.0303
2023-02-06 10:56:49 | Valid | Epoch[458/600] Iteration[005/008] Valid loss: 0.0313
2023-02-06 10:56:49 | Valid | Epoch[458/600] Iteration[006/008] Valid loss: 0.0318
2023-02-06 10:56:49 | Valid | Epoch[458/600] Iteration[007/008] Valid loss: 0.0324
2023-02-06 10:56:49 | Valid | Epoch[458/600] Iteration[008/008] Valid loss: 0.0320
2023-02-06 10:56:49 | Valid | Epoch[458/600] MIou: 0.9347663713815109
2023-02-06 10:56:49 | Valid | Epoch[458/600] Pixel Accuracy: 0.9889882405598959
2023-02-06 10:56:49 | Valid | Epoch[458/600] Mean Pixel Accuracy: 0.9521510791639074
2023-02-06 10:56:49 | Stage | Epoch[458/600] Train loss:0.0252
2023-02-06 10:56:49 | Stage | Epoch[458/600] Valid loss:0.0320
2023-02-06 10:56:49 | Stage | Epoch[458/600] LR:0.001

2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[001/030] Train loss: 0.0245
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[009/030] Train loss: 0.0260
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[017/030] Train loss: 0.0259
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[018/030] Train loss: 0.0259
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[021/030] Train loss: 0.0257
2023-02-06 10:56:50 | Train | Epoch[459/600] Iteration[022/030] Train loss: 0.0256
2023-02-06 10:56:51 | Train | Epoch[459/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:56:51 | Train | Epoch[459/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 10:56:51 | Train | Epoch[459/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:56:51 | Train | Epoch[459/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:56:51 | Train | Epoch[459/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:56:51 | Train | Epoch[459/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:56:51 | Train | Epoch[459/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:56:51 | Train | Epoch[459/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:56:51 | Valid | Epoch[459/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:56:51 | Valid | Epoch[459/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:56:51 | Valid | Epoch[459/600] Iteration[003/008] Valid loss: 0.0297
2023-02-06 10:56:51 | Valid | Epoch[459/600] Iteration[004/008] Valid loss: 0.0286
2023-02-06 10:56:51 | Valid | Epoch[459/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 10:56:51 | Valid | Epoch[459/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:56:51 | Valid | Epoch[459/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:56:51 | Valid | Epoch[459/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:56:51 | Valid | Epoch[459/600] MIou: 0.915839483163332
2023-02-06 10:56:51 | Valid | Epoch[459/600] Pixel Accuracy: 0.9860216776529948
2023-02-06 10:56:51 | Valid | Epoch[459/600] Mean Pixel Accuracy: 0.9273080634637024
2023-02-06 10:56:51 | Stage | Epoch[459/600] Train loss:0.0252
2023-02-06 10:56:51 | Stage | Epoch[459/600] Valid loss:0.0289
2023-02-06 10:56:51 | Stage | Epoch[459/600] LR:0.001

2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[001/030] Train loss: 0.0290
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[002/030] Train loss: 0.0245
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[003/030] Train loss: 0.0251
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[006/030] Train loss: 0.0256
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[007/030] Train loss: 0.0261
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[008/030] Train loss: 0.0258
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[015/030] Train loss: 0.0245
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[016/030] Train loss: 0.0245
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[017/030] Train loss: 0.0243
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[018/030] Train loss: 0.0244
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[019/030] Train loss: 0.0243
2023-02-06 10:56:52 | Train | Epoch[460/600] Iteration[020/030] Train loss: 0.0245
2023-02-06 10:56:53 | Train | Epoch[460/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 10:56:53 | Train | Epoch[460/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 10:56:53 | Train | Epoch[460/600] Iteration[023/030] Train loss: 0.0246
2023-02-06 10:56:53 | Train | Epoch[460/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 10:56:53 | Train | Epoch[460/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 10:56:53 | Train | Epoch[460/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 10:56:53 | Train | Epoch[460/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:56:53 | Train | Epoch[460/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:56:53 | Train | Epoch[460/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:56:53 | Train | Epoch[460/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:56:53 | Valid | Epoch[460/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:56:54 | Valid | Epoch[460/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:56:54 | Valid | Epoch[460/600] Iteration[003/008] Valid loss: 0.0299
2023-02-06 10:56:54 | Valid | Epoch[460/600] Iteration[004/008] Valid loss: 0.0289
2023-02-06 10:56:54 | Valid | Epoch[460/600] Iteration[005/008] Valid loss: 0.0295
2023-02-06 10:56:54 | Valid | Epoch[460/600] Iteration[006/008] Valid loss: 0.0293
2023-02-06 10:56:54 | Valid | Epoch[460/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:56:54 | Valid | Epoch[460/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 10:56:54 | Valid | Epoch[460/600] MIou: 0.9127537050067593
2023-02-06 10:56:54 | Valid | Epoch[460/600] Pixel Accuracy: 0.9855321248372396
2023-02-06 10:56:54 | Valid | Epoch[460/600] Mean Pixel Accuracy: 0.9237736415285196
2023-02-06 10:56:54 | Stage | Epoch[460/600] Train loss:0.0251
2023-02-06 10:56:54 | Stage | Epoch[460/600] Valid loss:0.0291
2023-02-06 10:56:54 | Stage | Epoch[460/600] LR:0.001

2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[001/030] Train loss: 0.0247
2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[005/030] Train loss: 0.0253
2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[007/030] Train loss: 0.0251
2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[010/030] Train loss: 0.0244
2023-02-06 10:56:54 | Train | Epoch[461/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[012/030] Train loss: 0.0244
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:56:55 | Train | Epoch[461/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:56:56 | Valid | Epoch[461/600] Iteration[001/008] Valid loss: 0.0368
2023-02-06 10:56:56 | Valid | Epoch[461/600] Iteration[002/008] Valid loss: 0.0347
2023-02-06 10:56:56 | Valid | Epoch[461/600] Iteration[003/008] Valid loss: 0.0354
2023-02-06 10:56:56 | Valid | Epoch[461/600] Iteration[004/008] Valid loss: 0.0345
2023-02-06 10:56:56 | Valid | Epoch[461/600] Iteration[005/008] Valid loss: 0.0349
2023-02-06 10:56:56 | Valid | Epoch[461/600] Iteration[006/008] Valid loss: 0.0344
2023-02-06 10:56:56 | Valid | Epoch[461/600] Iteration[007/008] Valid loss: 0.0335
2023-02-06 10:56:56 | Valid | Epoch[461/600] Iteration[008/008] Valid loss: 0.0340
2023-02-06 10:56:56 | Valid | Epoch[461/600] MIou: 0.8802049824338425
2023-02-06 10:56:56 | Valid | Epoch[461/600] Pixel Accuracy: 0.9802424112955729
2023-02-06 10:56:56 | Valid | Epoch[461/600] Mean Pixel Accuracy: 0.891503465792752
2023-02-06 10:56:56 | Stage | Epoch[461/600] Train loss:0.0253
2023-02-06 10:56:56 | Stage | Epoch[461/600] Valid loss:0.0340
2023-02-06 10:56:56 | Stage | Epoch[461/600] LR:0.001

2023-02-06 10:56:56 | Train | Epoch[462/600] Iteration[001/030] Train loss: 0.0240
2023-02-06 10:56:56 | Train | Epoch[462/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 10:56:56 | Train | Epoch[462/600] Iteration[003/030] Train loss: 0.0261
2023-02-06 10:56:56 | Train | Epoch[462/600] Iteration[004/030] Train loss: 0.0250
2023-02-06 10:56:56 | Train | Epoch[462/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 10:56:56 | Train | Epoch[462/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 10:56:56 | Train | Epoch[462/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 10:56:56 | Train | Epoch[462/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 10:56:56 | Train | Epoch[462/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[012/030] Train loss: 0.0245
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[014/030] Train loss: 0.0245
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:56:57 | Train | Epoch[462/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:56:58 | Valid | Epoch[462/600] Iteration[001/008] Valid loss: 0.0365
2023-02-06 10:56:58 | Valid | Epoch[462/600] Iteration[002/008] Valid loss: 0.0312
2023-02-06 10:56:58 | Valid | Epoch[462/600] Iteration[003/008] Valid loss: 0.0302
2023-02-06 10:56:58 | Valid | Epoch[462/600] Iteration[004/008] Valid loss: 0.0291
2023-02-06 10:56:58 | Valid | Epoch[462/600] Iteration[005/008] Valid loss: 0.0298
2023-02-06 10:56:58 | Valid | Epoch[462/600] Iteration[006/008] Valid loss: 0.0302
2023-02-06 10:56:58 | Valid | Epoch[462/600] Iteration[007/008] Valid loss: 0.0306
2023-02-06 10:56:58 | Valid | Epoch[462/600] Iteration[008/008] Valid loss: 0.0302
2023-02-06 10:56:58 | Valid | Epoch[462/600] MIou: 0.9303976501043404
2023-02-06 10:56:58 | Valid | Epoch[462/600] Pixel Accuracy: 0.9883308410644531
2023-02-06 10:56:58 | Valid | Epoch[462/600] Mean Pixel Accuracy: 0.9449673970168038
2023-02-06 10:56:58 | Stage | Epoch[462/600] Train loss:0.0251
2023-02-06 10:56:58 | Stage | Epoch[462/600] Valid loss:0.0302
2023-02-06 10:56:58 | Stage | Epoch[462/600] LR:0.001

2023-02-06 10:56:58 | Train | Epoch[463/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 10:56:58 | Train | Epoch[463/600] Iteration[002/030] Train loss: 0.0214
2023-02-06 10:56:58 | Train | Epoch[463/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 10:56:58 | Train | Epoch[463/600] Iteration[004/030] Train loss: 0.0237
2023-02-06 10:56:58 | Train | Epoch[463/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 10:56:58 | Train | Epoch[463/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[007/030] Train loss: 0.0254
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[009/030] Train loss: 0.0253
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[013/030] Train loss: 0.0260
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:56:59 | Train | Epoch[463/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:57:00 | Valid | Epoch[463/600] Iteration[001/008] Valid loss: 0.0355
2023-02-06 10:57:00 | Valid | Epoch[463/600] Iteration[002/008] Valid loss: 0.0305
2023-02-06 10:57:00 | Valid | Epoch[463/600] Iteration[003/008] Valid loss: 0.0297
2023-02-06 10:57:00 | Valid | Epoch[463/600] Iteration[004/008] Valid loss: 0.0286
2023-02-06 10:57:00 | Valid | Epoch[463/600] Iteration[005/008] Valid loss: 0.0294
2023-02-06 10:57:00 | Valid | Epoch[463/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 10:57:00 | Valid | Epoch[463/600] Iteration[007/008] Valid loss: 0.0297
2023-02-06 10:57:00 | Valid | Epoch[463/600] Iteration[008/008] Valid loss: 0.0295
2023-02-06 10:57:00 | Valid | Epoch[463/600] MIou: 0.9279517184701269
2023-02-06 10:57:00 | Valid | Epoch[463/600] Pixel Accuracy: 0.9879442850748698
2023-02-06 10:57:00 | Valid | Epoch[463/600] Mean Pixel Accuracy: 0.9418129505771096
2023-02-06 10:57:00 | Stage | Epoch[463/600] Train loss:0.0253
2023-02-06 10:57:00 | Stage | Epoch[463/600] Valid loss:0.0295
2023-02-06 10:57:00 | Stage | Epoch[463/600] LR:0.001

2023-02-06 10:57:00 | Train | Epoch[464/600] Iteration[001/030] Train loss: 0.0290
2023-02-06 10:57:00 | Train | Epoch[464/600] Iteration[002/030] Train loss: 0.0279
2023-02-06 10:57:00 | Train | Epoch[464/600] Iteration[003/030] Train loss: 0.0258
2023-02-06 10:57:00 | Train | Epoch[464/600] Iteration[004/030] Train loss: 0.0261
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[005/030] Train loss: 0.0266
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:57:01 | Train | Epoch[464/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:57:02 | Train | Epoch[464/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:57:02 | Train | Epoch[464/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:57:02 | Train | Epoch[464/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:57:02 | Valid | Epoch[464/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 10:57:02 | Valid | Epoch[464/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:57:02 | Valid | Epoch[464/600] Iteration[003/008] Valid loss: 0.0298
2023-02-06 10:57:02 | Valid | Epoch[464/600] Iteration[004/008] Valid loss: 0.0287
2023-02-06 10:57:02 | Valid | Epoch[464/600] Iteration[005/008] Valid loss: 0.0293
2023-02-06 10:57:02 | Valid | Epoch[464/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:57:02 | Valid | Epoch[464/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:57:02 | Valid | Epoch[464/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:57:02 | Valid | Epoch[464/600] MIou: 0.9146518289550793
2023-02-06 10:57:02 | Valid | Epoch[464/600] Pixel Accuracy: 0.9858296712239584
2023-02-06 10:57:02 | Valid | Epoch[464/600] Mean Pixel Accuracy: 0.9260485627262294
2023-02-06 10:57:02 | Stage | Epoch[464/600] Train loss:0.0250
2023-02-06 10:57:02 | Stage | Epoch[464/600] Valid loss:0.0289
2023-02-06 10:57:02 | Stage | Epoch[464/600] LR:0.001

2023-02-06 10:57:02 | Train | Epoch[465/600] Iteration[001/030] Train loss: 0.0226
2023-02-06 10:57:02 | Train | Epoch[465/600] Iteration[002/030] Train loss: 0.0225
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[003/030] Train loss: 0.0239
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[004/030] Train loss: 0.0237
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[005/030] Train loss: 0.0241
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[007/030] Train loss: 0.0238
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[008/030] Train loss: 0.0243
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[010/030] Train loss: 0.0244
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[013/030] Train loss: 0.0244
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[014/030] Train loss: 0.0244
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[015/030] Train loss: 0.0241
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:57:03 | Train | Epoch[465/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:57:04 | Train | Epoch[465/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:57:04 | Train | Epoch[465/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:57:04 | Train | Epoch[465/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:57:04 | Train | Epoch[465/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:57:04 | Valid | Epoch[465/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 10:57:04 | Valid | Epoch[465/600] Iteration[002/008] Valid loss: 0.0311
2023-02-06 10:57:04 | Valid | Epoch[465/600] Iteration[003/008] Valid loss: 0.0313
2023-02-06 10:57:04 | Valid | Epoch[465/600] Iteration[004/008] Valid loss: 0.0303
2023-02-06 10:57:04 | Valid | Epoch[465/600] Iteration[005/008] Valid loss: 0.0309
2023-02-06 10:57:04 | Valid | Epoch[465/600] Iteration[006/008] Valid loss: 0.0306
2023-02-06 10:57:04 | Valid | Epoch[465/600] Iteration[007/008] Valid loss: 0.0301
2023-02-06 10:57:04 | Valid | Epoch[465/600] Iteration[008/008] Valid loss: 0.0302
2023-02-06 10:57:04 | Valid | Epoch[465/600] MIou: 0.9017455602297642
2023-02-06 10:57:04 | Valid | Epoch[465/600] Pixel Accuracy: 0.9837493896484375
2023-02-06 10:57:04 | Valid | Epoch[465/600] Mean Pixel Accuracy: 0.9124968485013196
2023-02-06 10:57:04 | Stage | Epoch[465/600] Train loss:0.0251
2023-02-06 10:57:04 | Stage | Epoch[465/600] Valid loss:0.0302
2023-02-06 10:57:04 | Stage | Epoch[465/600] LR:0.001

2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[001/030] Train loss: 0.0275
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[002/030] Train loss: 0.0269
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[003/030] Train loss: 0.0270
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[004/030] Train loss: 0.0266
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[005/030] Train loss: 0.0260
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[018/030] Train loss: 0.0245
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[019/030] Train loss: 0.0245
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:57:05 | Train | Epoch[466/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 10:57:06 | Train | Epoch[466/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 10:57:06 | Train | Epoch[466/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:57:06 | Train | Epoch[466/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:57:06 | Train | Epoch[466/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:57:06 | Train | Epoch[466/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:57:06 | Train | Epoch[466/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:57:06 | Train | Epoch[466/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:57:06 | Valid | Epoch[466/600] Iteration[001/008] Valid loss: 0.0475
2023-02-06 10:57:06 | Valid | Epoch[466/600] Iteration[002/008] Valid loss: 0.0394
2023-02-06 10:57:06 | Valid | Epoch[466/600] Iteration[003/008] Valid loss: 0.0370
2023-02-06 10:57:06 | Valid | Epoch[466/600] Iteration[004/008] Valid loss: 0.0356
2023-02-06 10:57:06 | Valid | Epoch[466/600] Iteration[005/008] Valid loss: 0.0368
2023-02-06 10:57:06 | Valid | Epoch[466/600] Iteration[006/008] Valid loss: 0.0378
2023-02-06 10:57:06 | Valid | Epoch[466/600] Iteration[007/008] Valid loss: 0.0391
2023-02-06 10:57:06 | Valid | Epoch[466/600] Iteration[008/008] Valid loss: 0.0384
2023-02-06 10:57:06 | Valid | Epoch[466/600] MIou: 0.9380427345423803
2023-02-06 10:57:06 | Valid | Epoch[466/600] Pixel Accuracy: 0.9893633524576823
2023-02-06 10:57:06 | Valid | Epoch[466/600] Mean Pixel Accuracy: 0.9630409511589209
2023-02-06 10:57:06 | Stage | Epoch[466/600] Train loss:0.0251
2023-02-06 10:57:06 | Stage | Epoch[466/600] Valid loss:0.0384
2023-02-06 10:57:06 | Stage | Epoch[466/600] LR:0.001

2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[001/030] Train loss: 0.0282
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[008/030] Train loss: 0.0243
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[009/030] Train loss: 0.0240
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[010/030] Train loss: 0.0238
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[011/030] Train loss: 0.0239
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 10:57:07 | Train | Epoch[467/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 10:57:08 | Train | Epoch[467/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 10:57:08 | Train | Epoch[467/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 10:57:08 | Train | Epoch[467/600] Iteration[024/030] Train loss: 0.0248
2023-02-06 10:57:08 | Train | Epoch[467/600] Iteration[025/030] Train loss: 0.0247
2023-02-06 10:57:08 | Train | Epoch[467/600] Iteration[026/030] Train loss: 0.0247
2023-02-06 10:57:08 | Train | Epoch[467/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 10:57:08 | Train | Epoch[467/600] Iteration[028/030] Train loss: 0.0248
2023-02-06 10:57:08 | Train | Epoch[467/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:57:08 | Train | Epoch[467/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:57:08 | Valid | Epoch[467/600] Iteration[001/008] Valid loss: 0.0371
2023-02-06 10:57:08 | Valid | Epoch[467/600] Iteration[002/008] Valid loss: 0.0349
2023-02-06 10:57:08 | Valid | Epoch[467/600] Iteration[003/008] Valid loss: 0.0356
2023-02-06 10:57:08 | Valid | Epoch[467/600] Iteration[004/008] Valid loss: 0.0347
2023-02-06 10:57:08 | Valid | Epoch[467/600] Iteration[005/008] Valid loss: 0.0352
2023-02-06 10:57:08 | Valid | Epoch[467/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 10:57:08 | Valid | Epoch[467/600] Iteration[007/008] Valid loss: 0.0338
2023-02-06 10:57:08 | Valid | Epoch[467/600] Iteration[008/008] Valid loss: 0.0342
2023-02-06 10:57:09 | Valid | Epoch[467/600] MIou: 0.8798942838784967
2023-02-06 10:57:09 | Valid | Epoch[467/600] Pixel Accuracy: 0.980194091796875
2023-02-06 10:57:09 | Valid | Epoch[467/600] Mean Pixel Accuracy: 0.8911598837598869
2023-02-06 10:57:09 | Stage | Epoch[467/600] Train loss:0.0251
2023-02-06 10:57:09 | Stage | Epoch[467/600] Valid loss:0.0342
2023-02-06 10:57:09 | Stage | Epoch[467/600] LR:0.001

2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[001/030] Train loss: 0.0276
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[002/030] Train loss: 0.0244
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[003/030] Train loss: 0.0239
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[004/030] Train loss: 0.0239
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[005/030] Train loss: 0.0235
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[006/030] Train loss: 0.0239
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[007/030] Train loss: 0.0234
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[008/030] Train loss: 0.0232
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[009/030] Train loss: 0.0234
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[010/030] Train loss: 0.0232
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[011/030] Train loss: 0.0240
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[012/030] Train loss: 0.0242
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[013/030] Train loss: 0.0242
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[014/030] Train loss: 0.0243
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[015/030] Train loss: 0.0245
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 10:57:09 | Train | Epoch[468/600] Iteration[017/030] Train loss: 0.0245
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:57:10 | Train | Epoch[468/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:57:10 | Valid | Epoch[468/600] Iteration[001/008] Valid loss: 0.0524
2023-02-06 10:57:10 | Valid | Epoch[468/600] Iteration[002/008] Valid loss: 0.0430
2023-02-06 10:57:10 | Valid | Epoch[468/600] Iteration[003/008] Valid loss: 0.0402
2023-02-06 10:57:10 | Valid | Epoch[468/600] Iteration[004/008] Valid loss: 0.0387
2023-02-06 10:57:10 | Valid | Epoch[468/600] Iteration[005/008] Valid loss: 0.0401
2023-02-06 10:57:10 | Valid | Epoch[468/600] Iteration[006/008] Valid loss: 0.0409
2023-02-06 10:57:11 | Valid | Epoch[468/600] Iteration[007/008] Valid loss: 0.0427
2023-02-06 10:57:11 | Valid | Epoch[468/600] Iteration[008/008] Valid loss: 0.0420
2023-02-06 10:57:11 | Valid | Epoch[468/600] MIou: 0.9373490534830362
2023-02-06 10:57:11 | Valid | Epoch[468/600] Pixel Accuracy: 0.9891560872395834
2023-02-06 10:57:11 | Valid | Epoch[468/600] Mean Pixel Accuracy: 0.9662050531271511
2023-02-06 10:57:11 | Stage | Epoch[468/600] Train loss:0.0253
2023-02-06 10:57:11 | Stage | Epoch[468/600] Valid loss:0.0420
2023-02-06 10:57:11 | Stage | Epoch[468/600] LR:0.001

2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[001/030] Train loss: 0.0270
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[002/030] Train loss: 0.0276
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[003/030] Train loss: 0.0259
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[004/030] Train loss: 0.0264
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[005/030] Train loss: 0.0267
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[008/030] Train loss: 0.0254
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[009/030] Train loss: 0.0253
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:57:11 | Train | Epoch[469/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[017/030] Train loss: 0.0246
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:57:12 | Train | Epoch[469/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:57:13 | Valid | Epoch[469/600] Iteration[001/008] Valid loss: 0.0337
2023-02-06 10:57:13 | Valid | Epoch[469/600] Iteration[002/008] Valid loss: 0.0308
2023-02-06 10:57:13 | Valid | Epoch[469/600] Iteration[003/008] Valid loss: 0.0310
2023-02-06 10:57:13 | Valid | Epoch[469/600] Iteration[004/008] Valid loss: 0.0300
2023-02-06 10:57:13 | Valid | Epoch[469/600] Iteration[005/008] Valid loss: 0.0306
2023-02-06 10:57:13 | Valid | Epoch[469/600] Iteration[006/008] Valid loss: 0.0303
2023-02-06 10:57:13 | Valid | Epoch[469/600] Iteration[007/008] Valid loss: 0.0298
2023-02-06 10:57:13 | Valid | Epoch[469/600] Iteration[008/008] Valid loss: 0.0300
2023-02-06 10:57:13 | Valid | Epoch[469/600] MIou: 0.9041687126899338
2023-02-06 10:57:13 | Valid | Epoch[469/600] Pixel Accuracy: 0.9841359456380209
2023-02-06 10:57:13 | Valid | Epoch[469/600] Mean Pixel Accuracy: 0.9151060143909749
2023-02-06 10:57:13 | Stage | Epoch[469/600] Train loss:0.0251
2023-02-06 10:57:13 | Stage | Epoch[469/600] Valid loss:0.0300
2023-02-06 10:57:13 | Stage | Epoch[469/600] LR:0.001

2023-02-06 10:57:13 | Train | Epoch[470/600] Iteration[001/030] Train loss: 0.0226
2023-02-06 10:57:13 | Train | Epoch[470/600] Iteration[002/030] Train loss: 0.0240
2023-02-06 10:57:13 | Train | Epoch[470/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:57:13 | Train | Epoch[470/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:57:13 | Train | Epoch[470/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 10:57:13 | Train | Epoch[470/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 10:57:13 | Train | Epoch[470/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 10:57:13 | Train | Epoch[470/600] Iteration[008/030] Train loss: 0.0247
2023-02-06 10:57:13 | Train | Epoch[470/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[013/030] Train loss: 0.0259
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[023/030] Train loss: 0.0258
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:57:14 | Train | Epoch[470/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:57:15 | Valid | Epoch[470/600] Iteration[001/008] Valid loss: 0.0357
2023-02-06 10:57:15 | Valid | Epoch[470/600] Iteration[002/008] Valid loss: 0.0333
2023-02-06 10:57:15 | Valid | Epoch[470/600] Iteration[003/008] Valid loss: 0.0338
2023-02-06 10:57:15 | Valid | Epoch[470/600] Iteration[004/008] Valid loss: 0.0329
2023-02-06 10:57:15 | Valid | Epoch[470/600] Iteration[005/008] Valid loss: 0.0333
2023-02-06 10:57:15 | Valid | Epoch[470/600] Iteration[006/008] Valid loss: 0.0328
2023-02-06 10:57:15 | Valid | Epoch[470/600] Iteration[007/008] Valid loss: 0.0321
2023-02-06 10:57:15 | Valid | Epoch[470/600] Iteration[008/008] Valid loss: 0.0325
2023-02-06 10:57:15 | Valid | Epoch[470/600] MIou: 0.8874212071149398
2023-02-06 10:57:15 | Valid | Epoch[470/600] Pixel Accuracy: 0.9814224243164062
2023-02-06 10:57:15 | Valid | Epoch[470/600] Mean Pixel Accuracy: 0.8983657133571783
2023-02-06 10:57:15 | Stage | Epoch[470/600] Train loss:0.0252
2023-02-06 10:57:15 | Stage | Epoch[470/600] Valid loss:0.0325
2023-02-06 10:57:15 | Stage | Epoch[470/600] LR:0.001

2023-02-06 10:57:15 | Train | Epoch[471/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 10:57:15 | Train | Epoch[471/600] Iteration[002/030] Train loss: 0.0247
2023-02-06 10:57:15 | Train | Epoch[471/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:57:15 | Train | Epoch[471/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:57:15 | Train | Epoch[471/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 10:57:15 | Train | Epoch[471/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[009/030] Train loss: 0.0253
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:57:16 | Train | Epoch[471/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:57:17 | Valid | Epoch[471/600] Iteration[001/008] Valid loss: 0.0511
2023-02-06 10:57:17 | Valid | Epoch[471/600] Iteration[002/008] Valid loss: 0.0419
2023-02-06 10:57:17 | Valid | Epoch[471/600] Iteration[003/008] Valid loss: 0.0393
2023-02-06 10:57:17 | Valid | Epoch[471/600] Iteration[004/008] Valid loss: 0.0378
2023-02-06 10:57:17 | Valid | Epoch[471/600] Iteration[005/008] Valid loss: 0.0391
2023-02-06 10:57:17 | Valid | Epoch[471/600] Iteration[006/008] Valid loss: 0.0400
2023-02-06 10:57:17 | Valid | Epoch[471/600] Iteration[007/008] Valid loss: 0.0416
2023-02-06 10:57:17 | Valid | Epoch[471/600] Iteration[008/008] Valid loss: 0.0409
2023-02-06 10:57:17 | Valid | Epoch[471/600] MIou: 0.937856818155834
2023-02-06 10:57:17 | Valid | Epoch[471/600] Pixel Accuracy: 0.9892590840657552
2023-02-06 10:57:17 | Valid | Epoch[471/600] Mean Pixel Accuracy: 0.9660334076010887
2023-02-06 10:57:17 | Stage | Epoch[471/600] Train loss:0.0253
2023-02-06 10:57:17 | Stage | Epoch[471/600] Valid loss:0.0409
2023-02-06 10:57:17 | Stage | Epoch[471/600] LR:0.001

2023-02-06 10:57:17 | Train | Epoch[472/600] Iteration[001/030] Train loss: 0.0236
2023-02-06 10:57:17 | Train | Epoch[472/600] Iteration[002/030] Train loss: 0.0231
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[003/030] Train loss: 0.0228
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[004/030] Train loss: 0.0230
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[005/030] Train loss: 0.0240
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[009/030] Train loss: 0.0246
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[012/030] Train loss: 0.0247
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[016/030] Train loss: 0.0245
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[017/030] Train loss: 0.0243
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[018/030] Train loss: 0.0243
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[019/030] Train loss: 0.0244
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[020/030] Train loss: 0.0243
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[021/030] Train loss: 0.0244
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:57:18 | Train | Epoch[472/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:57:19 | Train | Epoch[472/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:57:19 | Train | Epoch[472/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:57:19 | Train | Epoch[472/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:57:19 | Train | Epoch[472/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:57:19 | Train | Epoch[472/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:57:19 | Valid | Epoch[472/600] Iteration[001/008] Valid loss: 0.1263
2023-02-06 10:57:19 | Valid | Epoch[472/600] Iteration[002/008] Valid loss: 0.0987
2023-02-06 10:57:19 | Valid | Epoch[472/600] Iteration[003/008] Valid loss: 0.0906
2023-02-06 10:57:19 | Valid | Epoch[472/600] Iteration[004/008] Valid loss: 0.0867
2023-02-06 10:57:19 | Valid | Epoch[472/600] Iteration[005/008] Valid loss: 0.0903
2023-02-06 10:57:19 | Valid | Epoch[472/600] Iteration[006/008] Valid loss: 0.0931
2023-02-06 10:57:19 | Valid | Epoch[472/600] Iteration[007/008] Valid loss: 0.0986
2023-02-06 10:57:19 | Valid | Epoch[472/600] Iteration[008/008] Valid loss: 0.0960
2023-02-06 10:57:19 | Valid | Epoch[472/600] MIou: 0.9229085652895145
2023-02-06 10:57:19 | Valid | Epoch[472/600] Pixel Accuracy: 0.9858919779459635
2023-02-06 10:57:19 | Valid | Epoch[472/600] Mean Pixel Accuracy: 0.9786579989361266
2023-02-06 10:57:19 | Stage | Epoch[472/600] Train loss:0.0251
2023-02-06 10:57:19 | Stage | Epoch[472/600] Valid loss:0.0960
2023-02-06 10:57:19 | Stage | Epoch[472/600] LR:0.001

2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[002/030] Train loss: 0.0227
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[003/030] Train loss: 0.0250
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[005/030] Train loss: 0.0253
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[006/030] Train loss: 0.0270
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[007/030] Train loss: 0.0264
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[015/030] Train loss: 0.0258
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:57:20 | Train | Epoch[473/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:57:21 | Train | Epoch[473/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:57:21 | Train | Epoch[473/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:57:21 | Train | Epoch[473/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:57:21 | Train | Epoch[473/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:57:21 | Train | Epoch[473/600] Iteration[027/030] Train loss: 0.0256
2023-02-06 10:57:21 | Train | Epoch[473/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:57:21 | Train | Epoch[473/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:57:21 | Train | Epoch[473/600] Iteration[030/030] Train loss: 0.0255
2023-02-06 10:57:21 | Valid | Epoch[473/600] Iteration[001/008] Valid loss: 0.0409
2023-02-06 10:57:21 | Valid | Epoch[473/600] Iteration[002/008] Valid loss: 0.0397
2023-02-06 10:57:21 | Valid | Epoch[473/600] Iteration[003/008] Valid loss: 0.0408
2023-02-06 10:57:21 | Valid | Epoch[473/600] Iteration[004/008] Valid loss: 0.0397
2023-02-06 10:57:21 | Valid | Epoch[473/600] Iteration[005/008] Valid loss: 0.0404
2023-02-06 10:57:21 | Valid | Epoch[473/600] Iteration[006/008] Valid loss: 0.0396
2023-02-06 10:57:21 | Valid | Epoch[473/600] Iteration[007/008] Valid loss: 0.0384
2023-02-06 10:57:21 | Valid | Epoch[473/600] Iteration[008/008] Valid loss: 0.0392
2023-02-06 10:57:21 | Valid | Epoch[473/600] MIou: 0.8592153058746608
2023-02-06 10:57:21 | Valid | Epoch[473/600] Pixel Accuracy: 0.9767939249674479
2023-02-06 10:57:21 | Valid | Epoch[473/600] Mean Pixel Accuracy: 0.8719624984143117
2023-02-06 10:57:21 | Stage | Epoch[473/600] Train loss:0.0255
2023-02-06 10:57:21 | Stage | Epoch[473/600] Valid loss:0.0392
2023-02-06 10:57:21 | Stage | Epoch[473/600] LR:0.001

2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[001/030] Train loss: 0.0241
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[004/030] Train loss: 0.0261
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[011/030] Train loss: 0.0244
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[012/030] Train loss: 0.0244
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:57:22 | Train | Epoch[474/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:57:23 | Train | Epoch[474/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:57:23 | Valid | Epoch[474/600] Iteration[001/008] Valid loss: 0.0371
2023-02-06 10:57:23 | Valid | Epoch[474/600] Iteration[002/008] Valid loss: 0.0315
2023-02-06 10:57:23 | Valid | Epoch[474/600] Iteration[003/008] Valid loss: 0.0305
2023-02-06 10:57:23 | Valid | Epoch[474/600] Iteration[004/008] Valid loss: 0.0293
2023-02-06 10:57:23 | Valid | Epoch[474/600] Iteration[005/008] Valid loss: 0.0303
2023-02-06 10:57:23 | Valid | Epoch[474/600] Iteration[006/008] Valid loss: 0.0305
2023-02-06 10:57:23 | Valid | Epoch[474/600] Iteration[007/008] Valid loss: 0.0310
2023-02-06 10:57:24 | Valid | Epoch[474/600] Iteration[008/008] Valid loss: 0.0307
2023-02-06 10:57:24 | Valid | Epoch[474/600] MIou: 0.93271263629773
2023-02-06 10:57:24 | Valid | Epoch[474/600] Pixel Accuracy: 0.9886754353841146
2023-02-06 10:57:24 | Valid | Epoch[474/600] Mean Pixel Accuracy: 0.9488659765860488
2023-02-06 10:57:24 | Stage | Epoch[474/600] Train loss:0.0251
2023-02-06 10:57:24 | Stage | Epoch[474/600] Valid loss:0.0307
2023-02-06 10:57:24 | Stage | Epoch[474/600] LR:0.001

2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[001/030] Train loss: 0.0270
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[004/030] Train loss: 0.0254
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[008/030] Train loss: 0.0254
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[009/030] Train loss: 0.0253
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[013/030] Train loss: 0.0253
2023-02-06 10:57:24 | Train | Epoch[475/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[024/030] Train loss: 0.0258
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:57:25 | Train | Epoch[475/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:57:25 | Valid | Epoch[475/600] Iteration[001/008] Valid loss: 0.0347
2023-02-06 10:57:26 | Valid | Epoch[475/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:57:26 | Valid | Epoch[475/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:57:26 | Valid | Epoch[475/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:57:26 | Valid | Epoch[475/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:57:26 | Valid | Epoch[475/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:57:26 | Valid | Epoch[475/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:57:26 | Valid | Epoch[475/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:57:26 | Valid | Epoch[475/600] MIou: 0.9233195258949369
2023-02-06 10:57:26 | Valid | Epoch[475/600] Pixel Accuracy: 0.9872156778971354
2023-02-06 10:57:26 | Valid | Epoch[475/600] Mean Pixel Accuracy: 0.9358962667823727
2023-02-06 10:57:26 | Stage | Epoch[475/600] Train loss:0.0253
2023-02-06 10:57:26 | Stage | Epoch[475/600] Valid loss:0.0290
2023-02-06 10:57:26 | Stage | Epoch[475/600] LR:0.001

2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[001/030] Train loss: 0.0235
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[002/030] Train loss: 0.0234
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[003/030] Train loss: 0.0238
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[004/030] Train loss: 0.0227
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[005/030] Train loss: 0.0238
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[006/030] Train loss: 0.0234
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[007/030] Train loss: 0.0240
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[008/030] Train loss: 0.0236
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[009/030] Train loss: 0.0241
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[010/030] Train loss: 0.0242
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 10:57:26 | Train | Epoch[476/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:57:27 | Train | Epoch[476/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:57:28 | Valid | Epoch[476/600] Iteration[001/008] Valid loss: 0.0349
2023-02-06 10:57:28 | Valid | Epoch[476/600] Iteration[002/008] Valid loss: 0.0302
2023-02-06 10:57:28 | Valid | Epoch[476/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:57:28 | Valid | Epoch[476/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:57:28 | Valid | Epoch[476/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:57:28 | Valid | Epoch[476/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 10:57:28 | Valid | Epoch[476/600] Iteration[007/008] Valid loss: 0.0293
2023-02-06 10:57:28 | Valid | Epoch[476/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 10:57:28 | Valid | Epoch[476/600] MIou: 0.9253645377935437
2023-02-06 10:57:28 | Valid | Epoch[476/600] Pixel Accuracy: 0.9875399271647135
2023-02-06 10:57:28 | Valid | Epoch[476/600] Mean Pixel Accuracy: 0.9383887601106395
2023-02-06 10:57:28 | Stage | Epoch[476/600] Train loss:0.0251
2023-02-06 10:57:28 | Stage | Epoch[476/600] Valid loss:0.0291
2023-02-06 10:57:28 | Stage | Epoch[476/600] LR:0.001

2023-02-06 10:57:28 | Train | Epoch[477/600] Iteration[001/030] Train loss: 0.0217
2023-02-06 10:57:28 | Train | Epoch[477/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 10:57:28 | Train | Epoch[477/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:57:28 | Train | Epoch[477/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:57:28 | Train | Epoch[477/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:57:28 | Train | Epoch[477/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:57:28 | Train | Epoch[477/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:57:28 | Train | Epoch[477/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[019/030] Train loss: 0.0245
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[020/030] Train loss: 0.0245
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[023/030] Train loss: 0.0245
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[024/030] Train loss: 0.0248
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[025/030] Train loss: 0.0246
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[026/030] Train loss: 0.0247
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:57:29 | Train | Epoch[477/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:57:30 | Valid | Epoch[477/600] Iteration[001/008] Valid loss: 0.0382
2023-02-06 10:57:30 | Valid | Epoch[477/600] Iteration[002/008] Valid loss: 0.0325
2023-02-06 10:57:30 | Valid | Epoch[477/600] Iteration[003/008] Valid loss: 0.0312
2023-02-06 10:57:30 | Valid | Epoch[477/600] Iteration[004/008] Valid loss: 0.0300
2023-02-06 10:57:30 | Valid | Epoch[477/600] Iteration[005/008] Valid loss: 0.0310
2023-02-06 10:57:30 | Valid | Epoch[477/600] Iteration[006/008] Valid loss: 0.0314
2023-02-06 10:57:30 | Valid | Epoch[477/600] Iteration[007/008] Valid loss: 0.0320
2023-02-06 10:57:30 | Valid | Epoch[477/600] Iteration[008/008] Valid loss: 0.0316
2023-02-06 10:57:30 | Valid | Epoch[477/600] MIou: 0.9343013807134002
2023-02-06 10:57:30 | Valid | Epoch[477/600] Pixel Accuracy: 0.9889170328776041
2023-02-06 10:57:30 | Valid | Epoch[477/600] Mean Pixel Accuracy: 0.9514144885184569
2023-02-06 10:57:30 | Stage | Epoch[477/600] Train loss:0.0251
2023-02-06 10:57:30 | Stage | Epoch[477/600] Valid loss:0.0316
2023-02-06 10:57:30 | Stage | Epoch[477/600] LR:0.001

2023-02-06 10:57:30 | Train | Epoch[478/600] Iteration[001/030] Train loss: 0.0270
2023-02-06 10:57:30 | Train | Epoch[478/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 10:57:30 | Train | Epoch[478/600] Iteration[003/030] Train loss: 0.0242
2023-02-06 10:57:30 | Train | Epoch[478/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[008/030] Train loss: 0.0267
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[011/030] Train loss: 0.0263
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[014/030] Train loss: 0.0259
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[015/030] Train loss: 0.0260
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[020/030] Train loss: 0.0260
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:57:31 | Train | Epoch[478/600] Iteration[027/030] Train loss: 0.0256
2023-02-06 10:57:32 | Train | Epoch[478/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:57:32 | Train | Epoch[478/600] Iteration[029/030] Train loss: 0.0255
2023-02-06 10:57:32 | Train | Epoch[478/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:57:32 | Valid | Epoch[478/600] Iteration[001/008] Valid loss: 0.0383
2023-02-06 10:57:32 | Valid | Epoch[478/600] Iteration[002/008] Valid loss: 0.0323
2023-02-06 10:57:32 | Valid | Epoch[478/600] Iteration[003/008] Valid loss: 0.0311
2023-02-06 10:57:32 | Valid | Epoch[478/600] Iteration[004/008] Valid loss: 0.0299
2023-02-06 10:57:32 | Valid | Epoch[478/600] Iteration[005/008] Valid loss: 0.0308
2023-02-06 10:57:32 | Valid | Epoch[478/600] Iteration[006/008] Valid loss: 0.0312
2023-02-06 10:57:32 | Valid | Epoch[478/600] Iteration[007/008] Valid loss: 0.0318
2023-02-06 10:57:32 | Valid | Epoch[478/600] Iteration[008/008] Valid loss: 0.0314
2023-02-06 10:57:32 | Valid | Epoch[478/600] MIou: 0.9343406070726611
2023-02-06 10:57:32 | Valid | Epoch[478/600] Pixel Accuracy: 0.9889272054036459
2023-02-06 10:57:32 | Valid | Epoch[478/600] Mean Pixel Accuracy: 0.9513059512853997
2023-02-06 10:57:32 | Stage | Epoch[478/600] Train loss:0.0253
2023-02-06 10:57:32 | Stage | Epoch[478/600] Valid loss:0.0314
2023-02-06 10:57:32 | Stage | Epoch[478/600] LR:0.001

2023-02-06 10:57:32 | Train | Epoch[479/600] Iteration[001/030] Train loss: 0.0308
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[002/030] Train loss: 0.0286
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[003/030] Train loss: 0.0272
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[004/030] Train loss: 0.0266
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[005/030] Train loss: 0.0263
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[006/030] Train loss: 0.0261
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[007/030] Train loss: 0.0263
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[008/030] Train loss: 0.0267
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[009/030] Train loss: 0.0263
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[011/030] Train loss: 0.0263
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[014/030] Train loss: 0.0264
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[015/030] Train loss: 0.0261
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[016/030] Train loss: 0.0265
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[017/030] Train loss: 0.0265
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[018/030] Train loss: 0.0265
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[019/030] Train loss: 0.0265
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[020/030] Train loss: 0.0264
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[021/030] Train loss: 0.0263
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[022/030] Train loss: 0.0260
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[023/030] Train loss: 0.0259
2023-02-06 10:57:33 | Train | Epoch[479/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 10:57:34 | Train | Epoch[479/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 10:57:34 | Train | Epoch[479/600] Iteration[026/030] Train loss: 0.0257
2023-02-06 10:57:34 | Train | Epoch[479/600] Iteration[027/030] Train loss: 0.0256
2023-02-06 10:57:34 | Train | Epoch[479/600] Iteration[028/030] Train loss: 0.0257
2023-02-06 10:57:34 | Train | Epoch[479/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:57:34 | Train | Epoch[479/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:57:34 | Valid | Epoch[479/600] Iteration[001/008] Valid loss: 0.0398
2023-02-06 10:57:34 | Valid | Epoch[479/600] Iteration[002/008] Valid loss: 0.0336
2023-02-06 10:57:34 | Valid | Epoch[479/600] Iteration[003/008] Valid loss: 0.0323
2023-02-06 10:57:34 | Valid | Epoch[479/600] Iteration[004/008] Valid loss: 0.0311
2023-02-06 10:57:34 | Valid | Epoch[479/600] Iteration[005/008] Valid loss: 0.0321
2023-02-06 10:57:34 | Valid | Epoch[479/600] Iteration[006/008] Valid loss: 0.0324
2023-02-06 10:57:34 | Valid | Epoch[479/600] Iteration[007/008] Valid loss: 0.0333
2023-02-06 10:57:34 | Valid | Epoch[479/600] Iteration[008/008] Valid loss: 0.0329
2023-02-06 10:57:34 | Valid | Epoch[479/600] MIou: 0.9361569601037495
2023-02-06 10:57:34 | Valid | Epoch[479/600] Pixel Accuracy: 0.9891700744628906
2023-02-06 10:57:34 | Valid | Epoch[479/600] Mean Pixel Accuracy: 0.9557002393345931
2023-02-06 10:57:34 | Stage | Epoch[479/600] Train loss:0.0253
2023-02-06 10:57:34 | Stage | Epoch[479/600] Valid loss:0.0329
2023-02-06 10:57:34 | Stage | Epoch[479/600] LR:0.001

2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[001/030] Train loss: 0.0279
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[013/030] Train loss: 0.0247
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[014/030] Train loss: 0.0245
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 10:57:35 | Train | Epoch[480/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:57:36 | Train | Epoch[480/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:57:36 | Valid | Epoch[480/600] Iteration[001/008] Valid loss: 0.0352
2023-02-06 10:57:36 | Valid | Epoch[480/600] Iteration[002/008] Valid loss: 0.0305
2023-02-06 10:57:36 | Valid | Epoch[480/600] Iteration[003/008] Valid loss: 0.0296
2023-02-06 10:57:36 | Valid | Epoch[480/600] Iteration[004/008] Valid loss: 0.0286
2023-02-06 10:57:36 | Valid | Epoch[480/600] Iteration[005/008] Valid loss: 0.0293
2023-02-06 10:57:36 | Valid | Epoch[480/600] Iteration[006/008] Valid loss: 0.0296
2023-02-06 10:57:36 | Valid | Epoch[480/600] Iteration[007/008] Valid loss: 0.0298
2023-02-06 10:57:36 | Valid | Epoch[480/600] Iteration[008/008] Valid loss: 0.0295
2023-02-06 10:57:37 | Valid | Epoch[480/600] MIou: 0.9254434002040824
2023-02-06 10:57:37 | Valid | Epoch[480/600] Pixel Accuracy: 0.9875526428222656
2023-02-06 10:57:37 | Valid | Epoch[480/600] Mean Pixel Accuracy: 0.9384781753079969
2023-02-06 10:57:37 | Stage | Epoch[480/600] Train loss:0.0252
2023-02-06 10:57:37 | Stage | Epoch[480/600] Valid loss:0.0295
2023-02-06 10:57:37 | Stage | Epoch[480/600] LR:0.001

2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[001/030] Train loss: 0.0213
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[002/030] Train loss: 0.0244
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[003/030] Train loss: 0.0248
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[004/030] Train loss: 0.0241
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[005/030] Train loss: 0.0232
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[006/030] Train loss: 0.0230
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[007/030] Train loss: 0.0228
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[008/030] Train loss: 0.0237
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[010/030] Train loss: 0.0244
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[011/030] Train loss: 0.0245
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[012/030] Train loss: 0.0242
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:57:37 | Train | Epoch[481/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:57:38 | Train | Epoch[481/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:57:38 | Valid | Epoch[481/600] Iteration[001/008] Valid loss: 0.0364
2023-02-06 10:57:38 | Valid | Epoch[481/600] Iteration[002/008] Valid loss: 0.0341
2023-02-06 10:57:38 | Valid | Epoch[481/600] Iteration[003/008] Valid loss: 0.0347
2023-02-06 10:57:38 | Valid | Epoch[481/600] Iteration[004/008] Valid loss: 0.0338
2023-02-06 10:57:39 | Valid | Epoch[481/600] Iteration[005/008] Valid loss: 0.0343
2023-02-06 10:57:39 | Valid | Epoch[481/600] Iteration[006/008] Valid loss: 0.0337
2023-02-06 10:57:39 | Valid | Epoch[481/600] Iteration[007/008] Valid loss: 0.0330
2023-02-06 10:57:39 | Valid | Epoch[481/600] Iteration[008/008] Valid loss: 0.0334
2023-02-06 10:57:39 | Valid | Epoch[481/600] MIou: 0.8835179264799491
2023-02-06 10:57:39 | Valid | Epoch[481/600] Pixel Accuracy: 0.9807866414388021
2023-02-06 10:57:39 | Valid | Epoch[481/600] Mean Pixel Accuracy: 0.8945987458271522
2023-02-06 10:57:39 | Stage | Epoch[481/600] Train loss:0.0252
2023-02-06 10:57:39 | Stage | Epoch[481/600] Valid loss:0.0334
2023-02-06 10:57:39 | Stage | Epoch[481/600] LR:0.001

2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[001/030] Train loss: 0.0230
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[003/030] Train loss: 0.0265
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 10:57:39 | Train | Epoch[482/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:57:40 | Train | Epoch[482/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:57:41 | Valid | Epoch[482/600] Iteration[001/008] Valid loss: 0.0338
2023-02-06 10:57:41 | Valid | Epoch[482/600] Iteration[002/008] Valid loss: 0.0305
2023-02-06 10:57:41 | Valid | Epoch[482/600] Iteration[003/008] Valid loss: 0.0305
2023-02-06 10:57:41 | Valid | Epoch[482/600] Iteration[004/008] Valid loss: 0.0295
2023-02-06 10:57:41 | Valid | Epoch[482/600] Iteration[005/008] Valid loss: 0.0300
2023-02-06 10:57:41 | Valid | Epoch[482/600] Iteration[006/008] Valid loss: 0.0298
2023-02-06 10:57:41 | Valid | Epoch[482/600] Iteration[007/008] Valid loss: 0.0294
2023-02-06 10:57:41 | Valid | Epoch[482/600] Iteration[008/008] Valid loss: 0.0295
2023-02-06 10:57:41 | Valid | Epoch[482/600] MIou: 0.9075260487667783
2023-02-06 10:57:41 | Valid | Epoch[482/600] Pixel Accuracy: 0.98468017578125
2023-02-06 10:57:41 | Valid | Epoch[482/600] Mean Pixel Accuracy: 0.9185246584724912
2023-02-06 10:57:41 | Stage | Epoch[482/600] Train loss:0.0252
2023-02-06 10:57:41 | Stage | Epoch[482/600] Valid loss:0.0295
2023-02-06 10:57:41 | Stage | Epoch[482/600] LR:0.001

2023-02-06 10:57:41 | Train | Epoch[483/600] Iteration[001/030] Train loss: 0.0235
2023-02-06 10:57:41 | Train | Epoch[483/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 10:57:41 | Train | Epoch[483/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 10:57:41 | Train | Epoch[483/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:57:41 | Train | Epoch[483/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 10:57:41 | Train | Epoch[483/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 10:57:41 | Train | Epoch[483/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 10:57:41 | Train | Epoch[483/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 10:57:41 | Train | Epoch[483/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 10:57:41 | Train | Epoch[483/600] Iteration[010/030] Train loss: 0.0243
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:57:42 | Train | Epoch[483/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:57:43 | Valid | Epoch[483/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 10:57:43 | Valid | Epoch[483/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:57:43 | Valid | Epoch[483/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:57:43 | Valid | Epoch[483/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:57:43 | Valid | Epoch[483/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:57:43 | Valid | Epoch[483/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:57:43 | Valid | Epoch[483/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:57:43 | Valid | Epoch[483/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:57:43 | Valid | Epoch[483/600] MIou: 0.9237423039033652
2023-02-06 10:57:43 | Valid | Epoch[483/600] Pixel Accuracy: 0.987280527750651
2023-02-06 10:57:43 | Valid | Epoch[483/600] Mean Pixel Accuracy: 0.9364835320491952
2023-02-06 10:57:43 | Stage | Epoch[483/600] Train loss:0.0251
2023-02-06 10:57:43 | Stage | Epoch[483/600] Valid loss:0.0290
2023-02-06 10:57:43 | Stage | Epoch[483/600] LR:0.001

2023-02-06 10:57:43 | Train | Epoch[484/600] Iteration[001/030] Train loss: 0.0257
2023-02-06 10:57:43 | Train | Epoch[484/600] Iteration[002/030] Train loss: 0.0272
2023-02-06 10:57:43 | Train | Epoch[484/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 10:57:43 | Train | Epoch[484/600] Iteration[004/030] Train loss: 0.0265
2023-02-06 10:57:43 | Train | Epoch[484/600] Iteration[005/030] Train loss: 0.0265
2023-02-06 10:57:43 | Train | Epoch[484/600] Iteration[006/030] Train loss: 0.0260
2023-02-06 10:57:43 | Train | Epoch[484/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:57:43 | Train | Epoch[484/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 10:57:43 | Train | Epoch[484/600] Iteration[009/030] Train loss: 0.0263
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[011/030] Train loss: 0.0262
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[013/030] Train loss: 0.0260
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[015/030] Train loss: 0.0260
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[020/030] Train loss: 0.0259
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:57:44 | Train | Epoch[484/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:57:45 | Valid | Epoch[484/600] Iteration[001/008] Valid loss: 0.0363
2023-02-06 10:57:45 | Valid | Epoch[484/600] Iteration[002/008] Valid loss: 0.0310
2023-02-06 10:57:45 | Valid | Epoch[484/600] Iteration[003/008] Valid loss: 0.0301
2023-02-06 10:57:45 | Valid | Epoch[484/600] Iteration[004/008] Valid loss: 0.0289
2023-02-06 10:57:45 | Valid | Epoch[484/600] Iteration[005/008] Valid loss: 0.0295
2023-02-06 10:57:45 | Valid | Epoch[484/600] Iteration[006/008] Valid loss: 0.0297
2023-02-06 10:57:45 | Valid | Epoch[484/600] Iteration[007/008] Valid loss: 0.0301
2023-02-06 10:57:45 | Valid | Epoch[484/600] Iteration[008/008] Valid loss: 0.0298
2023-02-06 10:57:45 | Valid | Epoch[484/600] MIou: 0.9287724820871677
2023-02-06 10:57:45 | Valid | Epoch[484/600] Pixel Accuracy: 0.9880752563476562
2023-02-06 10:57:45 | Valid | Epoch[484/600] Mean Pixel Accuracy: 0.9428169872866985
2023-02-06 10:57:45 | Stage | Epoch[484/600] Train loss:0.0252
2023-02-06 10:57:45 | Stage | Epoch[484/600] Valid loss:0.0298
2023-02-06 10:57:45 | Stage | Epoch[484/600] LR:0.001

2023-02-06 10:57:45 | Train | Epoch[485/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 10:57:45 | Train | Epoch[485/600] Iteration[002/030] Train loss: 0.0234
2023-02-06 10:57:45 | Train | Epoch[485/600] Iteration[003/030] Train loss: 0.0232
2023-02-06 10:57:45 | Train | Epoch[485/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 10:57:45 | Train | Epoch[485/600] Iteration[005/030] Train loss: 0.0239
2023-02-06 10:57:45 | Train | Epoch[485/600] Iteration[006/030] Train loss: 0.0242
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[007/030] Train loss: 0.0248
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[009/030] Train loss: 0.0247
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[013/030] Train loss: 0.0253
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[021/030] Train loss: 0.0245
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[023/030] Train loss: 0.0246
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[024/030] Train loss: 0.0246
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[025/030] Train loss: 0.0247
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:57:46 | Train | Epoch[485/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:57:47 | Train | Epoch[485/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 10:57:47 | Valid | Epoch[485/600] Iteration[001/008] Valid loss: 0.0352
2023-02-06 10:57:47 | Valid | Epoch[485/600] Iteration[002/008] Valid loss: 0.0307
2023-02-06 10:57:47 | Valid | Epoch[485/600] Iteration[003/008] Valid loss: 0.0298
2023-02-06 10:57:47 | Valid | Epoch[485/600] Iteration[004/008] Valid loss: 0.0287
2023-02-06 10:57:47 | Valid | Epoch[485/600] Iteration[005/008] Valid loss: 0.0294
2023-02-06 10:57:47 | Valid | Epoch[485/600] Iteration[006/008] Valid loss: 0.0295
2023-02-06 10:57:47 | Valid | Epoch[485/600] Iteration[007/008] Valid loss: 0.0298
2023-02-06 10:57:47 | Valid | Epoch[485/600] Iteration[008/008] Valid loss: 0.0295
2023-02-06 10:57:47 | Valid | Epoch[485/600] MIou: 0.927693946262359
2023-02-06 10:57:47 | Valid | Epoch[485/600] Pixel Accuracy: 0.9879048665364584
2023-02-06 10:57:47 | Valid | Epoch[485/600] Mean Pixel Accuracy: 0.9414362180625622
2023-02-06 10:57:47 | Stage | Epoch[485/600] Train loss:0.0249
2023-02-06 10:57:47 | Stage | Epoch[485/600] Valid loss:0.0295
2023-02-06 10:57:47 | Stage | Epoch[485/600] LR:0.001

2023-02-06 10:57:47 | Train | Epoch[486/600] Iteration[001/030] Train loss: 0.0263
2023-02-06 10:57:47 | Train | Epoch[486/600] Iteration[002/030] Train loss: 0.0237
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[003/030] Train loss: 0.0245
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[008/030] Train loss: 0.0236
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[010/030] Train loss: 0.0242
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[011/030] Train loss: 0.0241
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[012/030] Train loss: 0.0247
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:57:48 | Train | Epoch[486/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:57:49 | Train | Epoch[486/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:57:49 | Train | Epoch[486/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:57:49 | Train | Epoch[486/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:57:49 | Train | Epoch[486/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:57:49 | Valid | Epoch[486/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:57:49 | Valid | Epoch[486/600] Iteration[002/008] Valid loss: 0.0308
2023-02-06 10:57:49 | Valid | Epoch[486/600] Iteration[003/008] Valid loss: 0.0308
2023-02-06 10:57:49 | Valid | Epoch[486/600] Iteration[004/008] Valid loss: 0.0298
2023-02-06 10:57:49 | Valid | Epoch[486/600] Iteration[005/008] Valid loss: 0.0304
2023-02-06 10:57:49 | Valid | Epoch[486/600] Iteration[006/008] Valid loss: 0.0300
2023-02-06 10:57:49 | Valid | Epoch[486/600] Iteration[007/008] Valid loss: 0.0297
2023-02-06 10:57:49 | Valid | Epoch[486/600] Iteration[008/008] Valid loss: 0.0298
2023-02-06 10:57:49 | Valid | Epoch[486/600] MIou: 0.905156188355004
2023-02-06 10:57:49 | Valid | Epoch[486/600] Pixel Accuracy: 0.9843012491861979
2023-02-06 10:57:49 | Valid | Epoch[486/600] Mean Pixel Accuracy: 0.9159704097955526
2023-02-06 10:57:49 | Stage | Epoch[486/600] Train loss:0.0253
2023-02-06 10:57:49 | Stage | Epoch[486/600] Valid loss:0.0298
2023-02-06 10:57:49 | Stage | Epoch[486/600] LR:0.001

2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[001/030] Train loss: 0.0216
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[003/030] Train loss: 0.0236
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[016/030] Train loss: 0.0245
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[017/030] Train loss: 0.0246
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:57:50 | Train | Epoch[487/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:57:51 | Train | Epoch[487/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 10:57:51 | Train | Epoch[487/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 10:57:51 | Train | Epoch[487/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:57:51 | Train | Epoch[487/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:57:51 | Train | Epoch[487/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:57:51 | Train | Epoch[487/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:57:51 | Train | Epoch[487/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:57:51 | Train | Epoch[487/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:57:51 | Valid | Epoch[487/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:57:51 | Valid | Epoch[487/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:57:51 | Valid | Epoch[487/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:57:51 | Valid | Epoch[487/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:57:51 | Valid | Epoch[487/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:57:51 | Valid | Epoch[487/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:57:51 | Valid | Epoch[487/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:57:51 | Valid | Epoch[487/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:57:51 | Valid | Epoch[487/600] MIou: 0.9197910678354926
2023-02-06 10:57:51 | Valid | Epoch[487/600] Pixel Accuracy: 0.9866612752278646
2023-02-06 10:57:51 | Valid | Epoch[487/600] Mean Pixel Accuracy: 0.9315146202483723
2023-02-06 10:57:51 | Stage | Epoch[487/600] Train loss:0.0253
2023-02-06 10:57:51 | Stage | Epoch[487/600] Valid loss:0.0289
2023-02-06 10:57:51 | Stage | Epoch[487/600] LR:0.001

2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[001/030] Train loss: 0.0267
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[002/030] Train loss: 0.0251
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[003/030] Train loss: 0.0238
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[006/030] Train loss: 0.0248
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[010/030] Train loss: 0.0248
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:57:52 | Train | Epoch[488/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[022/030] Train loss: 0.0256
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:57:53 | Train | Epoch[488/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:57:53 | Valid | Epoch[488/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:57:53 | Valid | Epoch[488/600] Iteration[002/008] Valid loss: 0.0316
2023-02-06 10:57:53 | Valid | Epoch[488/600] Iteration[003/008] Valid loss: 0.0318
2023-02-06 10:57:53 | Valid | Epoch[488/600] Iteration[004/008] Valid loss: 0.0308
2023-02-06 10:57:53 | Valid | Epoch[488/600] Iteration[005/008] Valid loss: 0.0314
2023-02-06 10:57:53 | Valid | Epoch[488/600] Iteration[006/008] Valid loss: 0.0311
2023-02-06 10:57:53 | Valid | Epoch[488/600] Iteration[007/008] Valid loss: 0.0305
2023-02-06 10:57:53 | Valid | Epoch[488/600] Iteration[008/008] Valid loss: 0.0308
2023-02-06 10:57:54 | Valid | Epoch[488/600] MIou: 0.897844531724868
2023-02-06 10:57:54 | Valid | Epoch[488/600] Pixel Accuracy: 0.9831136067708334
2023-02-06 10:57:54 | Valid | Epoch[488/600] Mean Pixel Accuracy: 0.9086664762561726
2023-02-06 10:57:54 | Stage | Epoch[488/600] Train loss:0.0254
2023-02-06 10:57:54 | Stage | Epoch[488/600] Valid loss:0.0308
2023-02-06 10:57:54 | Stage | Epoch[488/600] LR:0.001

2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[002/030] Train loss: 0.0250
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[007/030] Train loss: 0.0254
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[009/030] Train loss: 0.0260
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[011/030] Train loss: 0.0263
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[014/030] Train loss: 0.0261
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 10:57:54 | Train | Epoch[489/600] Iteration[016/030] Train loss: 0.0259
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[018/030] Train loss: 0.0261
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[020/030] Train loss: 0.0261
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[021/030] Train loss: 0.0259
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[022/030] Train loss: 0.0258
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:57:55 | Train | Epoch[489/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:57:55 | Valid | Epoch[489/600] Iteration[001/008] Valid loss: 0.0338
2023-02-06 10:57:55 | Valid | Epoch[489/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:57:55 | Valid | Epoch[489/600] Iteration[003/008] Valid loss: 0.0296
2023-02-06 10:57:55 | Valid | Epoch[489/600] Iteration[004/008] Valid loss: 0.0285
2023-02-06 10:57:55 | Valid | Epoch[489/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:57:56 | Valid | Epoch[489/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:57:56 | Valid | Epoch[489/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:57:56 | Valid | Epoch[489/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:57:56 | Valid | Epoch[489/600] MIou: 0.9164362754489098
2023-02-06 10:57:56 | Valid | Epoch[489/600] Pixel Accuracy: 0.9861183166503906
2023-02-06 10:57:56 | Valid | Epoch[489/600] Mean Pixel Accuracy: 0.9279381632858241
2023-02-06 10:57:56 | Stage | Epoch[489/600] Train loss:0.0254
2023-02-06 10:57:56 | Stage | Epoch[489/600] Valid loss:0.0289
2023-02-06 10:57:56 | Stage | Epoch[489/600] LR:0.001

2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[001/030] Train loss: 0.0280
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[002/030] Train loss: 0.0269
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[004/030] Train loss: 0.0261
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[005/030] Train loss: 0.0268
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[006/030] Train loss: 0.0262
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[007/030] Train loss: 0.0259
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:57:56 | Train | Epoch[490/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[014/030] Train loss: 0.0259
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:57:57 | Train | Epoch[490/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:57:58 | Valid | Epoch[490/600] Iteration[001/008] Valid loss: 0.0352
2023-02-06 10:57:58 | Valid | Epoch[490/600] Iteration[002/008] Valid loss: 0.0303
2023-02-06 10:57:58 | Valid | Epoch[490/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:57:58 | Valid | Epoch[490/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:57:58 | Valid | Epoch[490/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:57:58 | Valid | Epoch[490/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 10:57:58 | Valid | Epoch[490/600] Iteration[007/008] Valid loss: 0.0295
2023-02-06 10:57:58 | Valid | Epoch[490/600] Iteration[008/008] Valid loss: 0.0293
2023-02-06 10:57:58 | Valid | Epoch[490/600] MIou: 0.9260148712197525
2023-02-06 10:57:58 | Valid | Epoch[490/600] Pixel Accuracy: 0.9876429239908854
2023-02-06 10:57:58 | Valid | Epoch[490/600] Mean Pixel Accuracy: 0.9391935471974375
2023-02-06 10:57:58 | Stage | Epoch[490/600] Train loss:0.0251
2023-02-06 10:57:58 | Stage | Epoch[490/600] Valid loss:0.0293
2023-02-06 10:57:58 | Stage | Epoch[490/600] LR:0.001

2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[001/030] Train loss: 0.0238
2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[003/030] Train loss: 0.0250
2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[008/030] Train loss: 0.0247
2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 10:57:58 | Train | Epoch[491/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:57:59 | Train | Epoch[491/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:58:00 | Valid | Epoch[491/600] Iteration[001/008] Valid loss: 0.0334
2023-02-06 10:58:00 | Valid | Epoch[491/600] Iteration[002/008] Valid loss: 0.0302
2023-02-06 10:58:00 | Valid | Epoch[491/600] Iteration[003/008] Valid loss: 0.0301
2023-02-06 10:58:00 | Valid | Epoch[491/600] Iteration[004/008] Valid loss: 0.0291
2023-02-06 10:58:00 | Valid | Epoch[491/600] Iteration[005/008] Valid loss: 0.0297
2023-02-06 10:58:00 | Valid | Epoch[491/600] Iteration[006/008] Valid loss: 0.0296
2023-02-06 10:58:00 | Valid | Epoch[491/600] Iteration[007/008] Valid loss: 0.0293
2023-02-06 10:58:00 | Valid | Epoch[491/600] Iteration[008/008] Valid loss: 0.0294
2023-02-06 10:58:00 | Valid | Epoch[491/600] MIou: 0.9103034074148806
2023-02-06 10:58:00 | Valid | Epoch[491/600] Pixel Accuracy: 0.985131581624349
2023-02-06 10:58:00 | Valid | Epoch[491/600] Mean Pixel Accuracy: 0.9213406613382443
2023-02-06 10:58:00 | Stage | Epoch[491/600] Train loss:0.0251
2023-02-06 10:58:00 | Stage | Epoch[491/600] Valid loss:0.0294
2023-02-06 10:58:00 | Stage | Epoch[491/600] LR:0.001

2023-02-06 10:58:00 | Train | Epoch[492/600] Iteration[001/030] Train loss: 0.0265
2023-02-06 10:58:00 | Train | Epoch[492/600] Iteration[002/030] Train loss: 0.0241
2023-02-06 10:58:00 | Train | Epoch[492/600] Iteration[003/030] Train loss: 0.0231
2023-02-06 10:58:00 | Train | Epoch[492/600] Iteration[004/030] Train loss: 0.0231
2023-02-06 10:58:00 | Train | Epoch[492/600] Iteration[005/030] Train loss: 0.0240
2023-02-06 10:58:00 | Train | Epoch[492/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 10:58:00 | Train | Epoch[492/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[009/030] Train loss: 0.0257
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[022/030] Train loss: 0.0256
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:58:01 | Train | Epoch[492/600] Iteration[030/030] Train loss: 0.0255
2023-02-06 10:58:02 | Valid | Epoch[492/600] Iteration[001/008] Valid loss: 0.0352
2023-02-06 10:58:02 | Valid | Epoch[492/600] Iteration[002/008] Valid loss: 0.0327
2023-02-06 10:58:02 | Valid | Epoch[492/600] Iteration[003/008] Valid loss: 0.0331
2023-02-06 10:58:02 | Valid | Epoch[492/600] Iteration[004/008] Valid loss: 0.0321
2023-02-06 10:58:02 | Valid | Epoch[492/600] Iteration[005/008] Valid loss: 0.0326
2023-02-06 10:58:02 | Valid | Epoch[492/600] Iteration[006/008] Valid loss: 0.0322
2023-02-06 10:58:02 | Valid | Epoch[492/600] Iteration[007/008] Valid loss: 0.0315
2023-02-06 10:58:02 | Valid | Epoch[492/600] Iteration[008/008] Valid loss: 0.0318
2023-02-06 10:58:02 | Valid | Epoch[492/600] MIou: 0.8917994759433144
2023-02-06 10:58:02 | Valid | Epoch[492/600] Pixel Accuracy: 0.9821395874023438
2023-02-06 10:58:02 | Valid | Epoch[492/600] Mean Pixel Accuracy: 0.9025197963821388
2023-02-06 10:58:02 | Stage | Epoch[492/600] Train loss:0.0255
2023-02-06 10:58:02 | Stage | Epoch[492/600] Valid loss:0.0318
2023-02-06 10:58:02 | Stage | Epoch[492/600] LR:0.001

2023-02-06 10:58:02 | Train | Epoch[493/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 10:58:02 | Train | Epoch[493/600] Iteration[002/030] Train loss: 0.0239
2023-02-06 10:58:02 | Train | Epoch[493/600] Iteration[003/030] Train loss: 0.0240
2023-02-06 10:58:02 | Train | Epoch[493/600] Iteration[004/030] Train loss: 0.0238
2023-02-06 10:58:02 | Train | Epoch[493/600] Iteration[005/030] Train loss: 0.0231
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[006/030] Train loss: 0.0228
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[007/030] Train loss: 0.0232
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[008/030] Train loss: 0.0237
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[012/030] Train loss: 0.0242
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[013/030] Train loss: 0.0242
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[015/030] Train loss: 0.0243
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[016/030] Train loss: 0.0244
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[017/030] Train loss: 0.0245
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[018/030] Train loss: 0.0245
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:58:03 | Train | Epoch[493/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:58:04 | Train | Epoch[493/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:58:04 | Valid | Epoch[493/600] Iteration[001/008] Valid loss: 0.0359
2023-02-06 10:58:04 | Valid | Epoch[493/600] Iteration[002/008] Valid loss: 0.0337
2023-02-06 10:58:04 | Valid | Epoch[493/600] Iteration[003/008] Valid loss: 0.0341
2023-02-06 10:58:04 | Valid | Epoch[493/600] Iteration[004/008] Valid loss: 0.0332
2023-02-06 10:58:04 | Valid | Epoch[493/600] Iteration[005/008] Valid loss: 0.0336
2023-02-06 10:58:04 | Valid | Epoch[493/600] Iteration[006/008] Valid loss: 0.0331
2023-02-06 10:58:04 | Valid | Epoch[493/600] Iteration[007/008] Valid loss: 0.0323
2023-02-06 10:58:04 | Valid | Epoch[493/600] Iteration[008/008] Valid loss: 0.0328
2023-02-06 10:58:04 | Valid | Epoch[493/600] MIou: 0.8851469860626935
2023-02-06 10:58:04 | Valid | Epoch[493/600] Pixel Accuracy: 0.9810447692871094
2023-02-06 10:58:04 | Valid | Epoch[493/600] Mean Pixel Accuracy: 0.8963194013079762
2023-02-06 10:58:04 | Stage | Epoch[493/600] Train loss:0.0252
2023-02-06 10:58:04 | Stage | Epoch[493/600] Valid loss:0.0328
2023-02-06 10:58:04 | Stage | Epoch[493/600] LR:0.001

2023-02-06 10:58:04 | Train | Epoch[494/600] Iteration[001/030] Train loss: 0.0265
2023-02-06 10:58:04 | Train | Epoch[494/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 10:58:04 | Train | Epoch[494/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:58:04 | Train | Epoch[494/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 10:58:05 | Train | Epoch[494/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:58:06 | Train | Epoch[494/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:58:06 | Train | Epoch[494/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:06 | Train | Epoch[494/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:58:06 | Valid | Epoch[494/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:58:06 | Valid | Epoch[494/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:58:06 | Valid | Epoch[494/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:58:06 | Valid | Epoch[494/600] Iteration[004/008] Valid loss: 0.0285
2023-02-06 10:58:06 | Valid | Epoch[494/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 10:58:06 | Valid | Epoch[494/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 10:58:06 | Valid | Epoch[494/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:58:06 | Valid | Epoch[494/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 10:58:06 | Valid | Epoch[494/600] MIou: 0.9202614633809387
2023-02-06 10:58:06 | Valid | Epoch[494/600] Pixel Accuracy: 0.9867261250813802
2023-02-06 10:58:06 | Valid | Epoch[494/600] Mean Pixel Accuracy: 0.9323872067332384
2023-02-06 10:58:06 | Stage | Epoch[494/600] Train loss:0.0251
2023-02-06 10:58:06 | Stage | Epoch[494/600] Valid loss:0.0291
2023-02-06 10:58:06 | Stage | Epoch[494/600] LR:0.001

2023-02-06 10:58:06 | Train | Epoch[495/600] Iteration[001/030] Train loss: 0.0247
2023-02-06 10:58:06 | Train | Epoch[495/600] Iteration[002/030] Train loss: 0.0249
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[003/030] Train loss: 0.0258
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[004/030] Train loss: 0.0258
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[005/030] Train loss: 0.0258
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[008/030] Train loss: 0.0253
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[009/030] Train loss: 0.0253
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[022/030] Train loss: 0.0247
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 10:58:07 | Train | Epoch[495/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:58:08 | Train | Epoch[495/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:58:08 | Train | Epoch[495/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:58:08 | Train | Epoch[495/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:08 | Train | Epoch[495/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:58:08 | Valid | Epoch[495/600] Iteration[001/008] Valid loss: 0.0371
2023-02-06 10:58:08 | Valid | Epoch[495/600] Iteration[002/008] Valid loss: 0.0350
2023-02-06 10:58:08 | Valid | Epoch[495/600] Iteration[003/008] Valid loss: 0.0356
2023-02-06 10:58:08 | Valid | Epoch[495/600] Iteration[004/008] Valid loss: 0.0347
2023-02-06 10:58:08 | Valid | Epoch[495/600] Iteration[005/008] Valid loss: 0.0351
2023-02-06 10:58:08 | Valid | Epoch[495/600] Iteration[006/008] Valid loss: 0.0346
2023-02-06 10:58:08 | Valid | Epoch[495/600] Iteration[007/008] Valid loss: 0.0337
2023-02-06 10:58:08 | Valid | Epoch[495/600] Iteration[008/008] Valid loss: 0.0342
2023-02-06 10:58:08 | Valid | Epoch[495/600] MIou: 0.8792924015119448
2023-02-06 10:58:08 | Valid | Epoch[495/600] Pixel Accuracy: 0.9800936381022135
2023-02-06 10:58:08 | Valid | Epoch[495/600] Mean Pixel Accuracy: 0.8906291347616485
2023-02-06 10:58:08 | Stage | Epoch[495/600] Train loss:0.0252
2023-02-06 10:58:08 | Stage | Epoch[495/600] Valid loss:0.0342
2023-02-06 10:58:08 | Stage | Epoch[495/600] LR:0.001

2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[002/030] Train loss: 0.0304
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[003/030] Train loss: 0.0284
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[004/030] Train loss: 0.0280
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[006/030] Train loss: 0.0275
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[007/030] Train loss: 0.0270
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[008/030] Train loss: 0.0268
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[009/030] Train loss: 0.0269
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[010/030] Train loss: 0.0266
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:58:09 | Train | Epoch[496/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:58:10 | Train | Epoch[496/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:58:10 | Train | Epoch[496/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:58:10 | Train | Epoch[496/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:58:10 | Train | Epoch[496/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:58:10 | Train | Epoch[496/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 10:58:10 | Train | Epoch[496/600] Iteration[029/030] Train loss: 0.0256
2023-02-06 10:58:10 | Train | Epoch[496/600] Iteration[030/030] Train loss: 0.0256
2023-02-06 10:58:10 | Valid | Epoch[496/600] Iteration[001/008] Valid loss: 0.0363
2023-02-06 10:58:10 | Valid | Epoch[496/600] Iteration[002/008] Valid loss: 0.0309
2023-02-06 10:58:10 | Valid | Epoch[496/600] Iteration[003/008] Valid loss: 0.0300
2023-02-06 10:58:10 | Valid | Epoch[496/600] Iteration[004/008] Valid loss: 0.0289
2023-02-06 10:58:10 | Valid | Epoch[496/600] Iteration[005/008] Valid loss: 0.0297
2023-02-06 10:58:10 | Valid | Epoch[496/600] Iteration[006/008] Valid loss: 0.0299
2023-02-06 10:58:10 | Valid | Epoch[496/600] Iteration[007/008] Valid loss: 0.0303
2023-02-06 10:58:10 | Valid | Epoch[496/600] Iteration[008/008] Valid loss: 0.0300
2023-02-06 10:58:10 | Valid | Epoch[496/600] MIou: 0.9306213097795522
2023-02-06 10:58:10 | Valid | Epoch[496/600] Pixel Accuracy: 0.9883702596028646
2023-02-06 10:58:10 | Valid | Epoch[496/600] Mean Pixel Accuracy: 0.9451031916138922
2023-02-06 10:58:10 | Stage | Epoch[496/600] Train loss:0.0256
2023-02-06 10:58:10 | Stage | Epoch[496/600] Valid loss:0.0300
2023-02-06 10:58:10 | Stage | Epoch[496/600] LR:0.001

2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[001/030] Train loss: 0.0290
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[002/030] Train loss: 0.0286
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[004/030] Train loss: 0.0245
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[008/030] Train loss: 0.0239
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[009/030] Train loss: 0.0246
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[012/030] Train loss: 0.0242
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[013/030] Train loss: 0.0244
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:58:11 | Train | Epoch[497/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:58:12 | Train | Epoch[497/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:58:12 | Valid | Epoch[497/600] Iteration[001/008] Valid loss: 0.0337
2023-02-06 10:58:12 | Valid | Epoch[497/600] Iteration[002/008] Valid loss: 0.0307
2023-02-06 10:58:12 | Valid | Epoch[497/600] Iteration[003/008] Valid loss: 0.0308
2023-02-06 10:58:12 | Valid | Epoch[497/600] Iteration[004/008] Valid loss: 0.0298
2023-02-06 10:58:12 | Valid | Epoch[497/600] Iteration[005/008] Valid loss: 0.0304
2023-02-06 10:58:12 | Valid | Epoch[497/600] Iteration[006/008] Valid loss: 0.0302
2023-02-06 10:58:12 | Valid | Epoch[497/600] Iteration[007/008] Valid loss: 0.0297
2023-02-06 10:58:12 | Valid | Epoch[497/600] Iteration[008/008] Valid loss: 0.0299
2023-02-06 10:58:13 | Valid | Epoch[497/600] MIou: 0.9041744250860255
2023-02-06 10:58:13 | Valid | Epoch[497/600] Pixel Accuracy: 0.9841423034667969
2023-02-06 10:58:13 | Valid | Epoch[497/600] Mean Pixel Accuracy: 0.9149700185515593
2023-02-06 10:58:13 | Stage | Epoch[497/600] Train loss:0.0254
2023-02-06 10:58:13 | Stage | Epoch[497/600] Valid loss:0.0299
2023-02-06 10:58:13 | Stage | Epoch[497/600] LR:0.001

2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[001/030] Train loss: 0.0248
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[002/030] Train loss: 0.0261
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[003/030] Train loss: 0.0237
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[004/030] Train loss: 0.0241
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[008/030] Train loss: 0.0251
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 10:58:13 | Train | Epoch[498/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:58:14 | Train | Epoch[498/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:58:15 | Valid | Epoch[498/600] Iteration[001/008] Valid loss: 0.0406
2023-02-06 10:58:15 | Valid | Epoch[498/600] Iteration[002/008] Valid loss: 0.0342
2023-02-06 10:58:15 | Valid | Epoch[498/600] Iteration[003/008] Valid loss: 0.0327
2023-02-06 10:58:15 | Valid | Epoch[498/600] Iteration[004/008] Valid loss: 0.0314
2023-02-06 10:58:15 | Valid | Epoch[498/600] Iteration[005/008] Valid loss: 0.0325
2023-02-06 10:58:15 | Valid | Epoch[498/600] Iteration[006/008] Valid loss: 0.0330
2023-02-06 10:58:15 | Valid | Epoch[498/600] Iteration[007/008] Valid loss: 0.0340
2023-02-06 10:58:15 | Valid | Epoch[498/600] Iteration[008/008] Valid loss: 0.0335
2023-02-06 10:58:15 | Valid | Epoch[498/600] MIou: 0.9363172269975233
2023-02-06 10:58:15 | Valid | Epoch[498/600] Pixel Accuracy: 0.989190419514974
2023-02-06 10:58:15 | Valid | Epoch[498/600] Mean Pixel Accuracy: 0.956142573905735
2023-02-06 10:58:15 | Stage | Epoch[498/600] Train loss:0.0253
2023-02-06 10:58:15 | Stage | Epoch[498/600] Valid loss:0.0335
2023-02-06 10:58:15 | Stage | Epoch[498/600] LR:0.001

2023-02-06 10:58:15 | Train | Epoch[499/600] Iteration[001/030] Train loss: 0.0240
2023-02-06 10:58:15 | Train | Epoch[499/600] Iteration[002/030] Train loss: 0.0225
2023-02-06 10:58:15 | Train | Epoch[499/600] Iteration[003/030] Train loss: 0.0226
2023-02-06 10:58:15 | Train | Epoch[499/600] Iteration[004/030] Train loss: 0.0224
2023-02-06 10:58:15 | Train | Epoch[499/600] Iteration[005/030] Train loss: 0.0236
2023-02-06 10:58:15 | Train | Epoch[499/600] Iteration[006/030] Train loss: 0.0242
2023-02-06 10:58:15 | Train | Epoch[499/600] Iteration[007/030] Train loss: 0.0238
2023-02-06 10:58:15 | Train | Epoch[499/600] Iteration[008/030] Train loss: 0.0240
2023-02-06 10:58:15 | Train | Epoch[499/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 10:58:15 | Train | Epoch[499/600] Iteration[010/030] Train loss: 0.0238
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[012/030] Train loss: 0.0241
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[014/030] Train loss: 0.0245
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:16 | Train | Epoch[499/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:58:17 | Valid | Epoch[499/600] Iteration[001/008] Valid loss: 0.0361
2023-02-06 10:58:17 | Valid | Epoch[499/600] Iteration[002/008] Valid loss: 0.0311
2023-02-06 10:58:17 | Valid | Epoch[499/600] Iteration[003/008] Valid loss: 0.0300
2023-02-06 10:58:17 | Valid | Epoch[499/600] Iteration[004/008] Valid loss: 0.0289
2023-02-06 10:58:17 | Valid | Epoch[499/600] Iteration[005/008] Valid loss: 0.0297
2023-02-06 10:58:17 | Valid | Epoch[499/600] Iteration[006/008] Valid loss: 0.0300
2023-02-06 10:58:17 | Valid | Epoch[499/600] Iteration[007/008] Valid loss: 0.0303
2023-02-06 10:58:17 | Valid | Epoch[499/600] Iteration[008/008] Valid loss: 0.0300
2023-02-06 10:58:17 | Valid | Epoch[499/600] MIou: 0.9298383827932355
2023-02-06 10:58:17 | Valid | Epoch[499/600] Pixel Accuracy: 0.9882431030273438
2023-02-06 10:58:17 | Valid | Epoch[499/600] Mean Pixel Accuracy: 0.9442153801118309
2023-02-06 10:58:17 | Stage | Epoch[499/600] Train loss:0.0251
2023-02-06 10:58:17 | Stage | Epoch[499/600] Valid loss:0.0300
2023-02-06 10:58:17 | Stage | Epoch[499/600] LR:0.001

2023-02-06 10:58:17 | Train | Epoch[500/600] Iteration[001/030] Train loss: 0.0311
2023-02-06 10:58:17 | Train | Epoch[500/600] Iteration[002/030] Train loss: 0.0284
2023-02-06 10:58:17 | Train | Epoch[500/600] Iteration[003/030] Train loss: 0.0275
2023-02-06 10:58:17 | Train | Epoch[500/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 10:58:17 | Train | Epoch[500/600] Iteration[005/030] Train loss: 0.0264
2023-02-06 10:58:17 | Train | Epoch[500/600] Iteration[006/030] Train loss: 0.0271
2023-02-06 10:58:17 | Train | Epoch[500/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:18 | Train | Epoch[500/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:58:19 | Valid | Epoch[500/600] Iteration[001/008] Valid loss: 0.0411
2023-02-06 10:58:19 | Valid | Epoch[500/600] Iteration[002/008] Valid loss: 0.0346
2023-02-06 10:58:19 | Valid | Epoch[500/600] Iteration[003/008] Valid loss: 0.0329
2023-02-06 10:58:19 | Valid | Epoch[500/600] Iteration[004/008] Valid loss: 0.0317
2023-02-06 10:58:19 | Valid | Epoch[500/600] Iteration[005/008] Valid loss: 0.0326
2023-02-06 10:58:19 | Valid | Epoch[500/600] Iteration[006/008] Valid loss: 0.0332
2023-02-06 10:58:19 | Valid | Epoch[500/600] Iteration[007/008] Valid loss: 0.0341
2023-02-06 10:58:19 | Valid | Epoch[500/600] Iteration[008/008] Valid loss: 0.0336
2023-02-06 10:58:19 | Valid | Epoch[500/600] MIou: 0.9363136143520328
2023-02-06 10:58:19 | Valid | Epoch[500/600] Pixel Accuracy: 0.9891993204752604
2023-02-06 10:58:19 | Valid | Epoch[500/600] Mean Pixel Accuracy: 0.9557353356048401
2023-02-06 10:58:19 | Stage | Epoch[500/600] Train loss:0.0250
2023-02-06 10:58:19 | Stage | Epoch[500/600] Valid loss:0.0336
2023-02-06 10:58:19 | Stage | Epoch[500/600] LR:0.001

2023-02-06 10:58:19 | Train | Epoch[501/600] Iteration[001/030] Train loss: 0.0293
2023-02-06 10:58:19 | Train | Epoch[501/600] Iteration[002/030] Train loss: 0.0279
2023-02-06 10:58:19 | Train | Epoch[501/600] Iteration[003/030] Train loss: 0.0279
2023-02-06 10:58:19 | Train | Epoch[501/600] Iteration[004/030] Train loss: 0.0271
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[005/030] Train loss: 0.0271
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[006/030] Train loss: 0.0264
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[007/030] Train loss: 0.0268
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[008/030] Train loss: 0.0266
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[013/030] Train loss: 0.0259
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:58:20 | Train | Epoch[501/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:58:21 | Train | Epoch[501/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:21 | Train | Epoch[501/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:58:21 | Valid | Epoch[501/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:58:21 | Valid | Epoch[501/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:21 | Valid | Epoch[501/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:21 | Valid | Epoch[501/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:21 | Valid | Epoch[501/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:21 | Valid | Epoch[501/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:21 | Valid | Epoch[501/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:58:21 | Valid | Epoch[501/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:58:21 | Valid | Epoch[501/600] MIou: 0.9200637261138083
2023-02-06 10:58:21 | Valid | Epoch[501/600] Pixel Accuracy: 0.9867045084635416
2023-02-06 10:58:21 | Valid | Epoch[501/600] Mean Pixel Accuracy: 0.931836385239621
2023-02-06 10:58:21 | Stage | Epoch[501/600] Train loss:0.0250
2023-02-06 10:58:21 | Stage | Epoch[501/600] Valid loss:0.0288
2023-02-06 10:58:21 | Stage | Epoch[501/600] LR:0.0001

2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[001/030] Train loss: 0.0310
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[002/030] Train loss: 0.0299
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[003/030] Train loss: 0.0278
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[004/030] Train loss: 0.0275
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[005/030] Train loss: 0.0266
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[007/030] Train loss: 0.0268
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[010/030] Train loss: 0.0256
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[016/030] Train loss: 0.0259
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[018/030] Train loss: 0.0259
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[019/030] Train loss: 0.0258
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[020/030] Train loss: 0.0256
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[021/030] Train loss: 0.0257
2023-02-06 10:58:22 | Train | Epoch[502/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:58:23 | Train | Epoch[502/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 10:58:23 | Train | Epoch[502/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:58:23 | Train | Epoch[502/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:58:23 | Train | Epoch[502/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:58:23 | Train | Epoch[502/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:58:23 | Train | Epoch[502/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:58:23 | Train | Epoch[502/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:58:23 | Train | Epoch[502/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:58:23 | Valid | Epoch[502/600] Iteration[001/008] Valid loss: 0.0338
2023-02-06 10:58:23 | Valid | Epoch[502/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:23 | Valid | Epoch[502/600] Iteration[003/008] Valid loss: 0.0296
2023-02-06 10:58:23 | Valid | Epoch[502/600] Iteration[004/008] Valid loss: 0.0285
2023-02-06 10:58:23 | Valid | Epoch[502/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:58:23 | Valid | Epoch[502/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:23 | Valid | Epoch[502/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:58:23 | Valid | Epoch[502/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:58:23 | Valid | Epoch[502/600] MIou: 0.9174672086808728
2023-02-06 10:58:23 | Valid | Epoch[502/600] Pixel Accuracy: 0.9862899780273438
2023-02-06 10:58:23 | Valid | Epoch[502/600] Mean Pixel Accuracy: 0.9288821388823968
2023-02-06 10:58:23 | Stage | Epoch[502/600] Train loss:0.0251
2023-02-06 10:58:23 | Stage | Epoch[502/600] Valid loss:0.0288
2023-02-06 10:58:23 | Stage | Epoch[502/600] LR:0.0001

2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[001/030] Train loss: 0.0289
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[003/030] Train loss: 0.0242
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[004/030] Train loss: 0.0237
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[007/030] Train loss: 0.0257
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 10:58:24 | Train | Epoch[503/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 10:58:25 | Train | Epoch[503/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:58:25 | Train | Epoch[503/600] Iteration[023/030] Train loss: 0.0246
2023-02-06 10:58:25 | Train | Epoch[503/600] Iteration[024/030] Train loss: 0.0246
2023-02-06 10:58:25 | Train | Epoch[503/600] Iteration[025/030] Train loss: 0.0247
2023-02-06 10:58:25 | Train | Epoch[503/600] Iteration[026/030] Train loss: 0.0247
2023-02-06 10:58:25 | Train | Epoch[503/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:58:25 | Train | Epoch[503/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:58:25 | Train | Epoch[503/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:58:25 | Train | Epoch[503/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:58:25 | Valid | Epoch[503/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:58:25 | Valid | Epoch[503/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:25 | Valid | Epoch[503/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:58:25 | Valid | Epoch[503/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:58:25 | Valid | Epoch[503/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:25 | Valid | Epoch[503/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:25 | Valid | Epoch[503/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:58:25 | Valid | Epoch[503/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:58:25 | Valid | Epoch[503/600] MIou: 0.9188686805097748
2023-02-06 10:58:25 | Valid | Epoch[503/600] Pixel Accuracy: 0.9865163167317709
2023-02-06 10:58:25 | Valid | Epoch[503/600] Mean Pixel Accuracy: 0.9303887670770956
2023-02-06 10:58:25 | Stage | Epoch[503/600] Train loss:0.0252
2023-02-06 10:58:25 | Stage | Epoch[503/600] Valid loss:0.0288
2023-02-06 10:58:25 | Stage | Epoch[503/600] LR:0.0001

2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[001/030] Train loss: 0.0276
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[003/030] Train loss: 0.0259
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[004/030] Train loss: 0.0254
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[006/030] Train loss: 0.0245
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[008/030] Train loss: 0.0241
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[009/030] Train loss: 0.0238
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[010/030] Train loss: 0.0236
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[011/030] Train loss: 0.0233
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[012/030] Train loss: 0.0233
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[013/030] Train loss: 0.0234
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[014/030] Train loss: 0.0237
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[015/030] Train loss: 0.0236
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[016/030] Train loss: 0.0236
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[017/030] Train loss: 0.0235
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[018/030] Train loss: 0.0238
2023-02-06 10:58:26 | Train | Epoch[504/600] Iteration[019/030] Train loss: 0.0240
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[020/030] Train loss: 0.0241
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[021/030] Train loss: 0.0242
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[022/030] Train loss: 0.0242
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[023/030] Train loss: 0.0242
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[024/030] Train loss: 0.0242
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[025/030] Train loss: 0.0244
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[026/030] Train loss: 0.0245
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:58:27 | Train | Epoch[504/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:58:27 | Valid | Epoch[504/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:58:27 | Valid | Epoch[504/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:27 | Valid | Epoch[504/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:27 | Valid | Epoch[504/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:58:27 | Valid | Epoch[504/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:27 | Valid | Epoch[504/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:27 | Valid | Epoch[504/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:58:27 | Valid | Epoch[504/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:58:28 | Valid | Epoch[504/600] MIou: 0.9197152975400545
2023-02-06 10:58:28 | Valid | Epoch[504/600] Pixel Accuracy: 0.9866498311360677
2023-02-06 10:58:28 | Valid | Epoch[504/600] Mean Pixel Accuracy: 0.9314068825432487
2023-02-06 10:58:28 | Stage | Epoch[504/600] Train loss:0.0250
2023-02-06 10:58:28 | Stage | Epoch[504/600] Valid loss:0.0288
2023-02-06 10:58:28 | Stage | Epoch[504/600] LR:0.0001

2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[001/030] Train loss: 0.0203
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[002/030] Train loss: 0.0227
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[004/030] Train loss: 0.0238
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[005/030] Train loss: 0.0231
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[006/030] Train loss: 0.0235
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[007/030] Train loss: 0.0238
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[008/030] Train loss: 0.0240
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[011/030] Train loss: 0.0240
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[013/030] Train loss: 0.0247
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 10:58:28 | Train | Epoch[505/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[024/030] Train loss: 0.0246
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[025/030] Train loss: 0.0246
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[026/030] Train loss: 0.0246
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[028/030] Train loss: 0.0248
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:58:29 | Train | Epoch[505/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:58:29 | Valid | Epoch[505/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 10:58:29 | Valid | Epoch[505/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:30 | Valid | Epoch[505/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:30 | Valid | Epoch[505/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:30 | Valid | Epoch[505/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:30 | Valid | Epoch[505/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:30 | Valid | Epoch[505/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:58:30 | Valid | Epoch[505/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:58:30 | Valid | Epoch[505/600] MIou: 0.9211379567514144
2023-02-06 10:58:30 | Valid | Epoch[505/600] Pixel Accuracy: 0.9868761698404948
2023-02-06 10:58:30 | Valid | Epoch[505/600] Mean Pixel Accuracy: 0.9330656820542373
2023-02-06 10:58:30 | Stage | Epoch[505/600] Train loss:0.0250
2023-02-06 10:58:30 | Stage | Epoch[505/600] Valid loss:0.0289
2023-02-06 10:58:30 | Stage | Epoch[505/600] LR:0.0001

2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[001/030] Train loss: 0.0286
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[002/030] Train loss: 0.0268
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[006/030] Train loss: 0.0258
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 10:58:30 | Train | Epoch[506/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[016/030] Train loss: 0.0260
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[017/030] Train loss: 0.0259
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[020/030] Train loss: 0.0258
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:31 | Train | Epoch[506/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:58:32 | Valid | Epoch[506/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 10:58:32 | Valid | Epoch[506/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:58:32 | Valid | Epoch[506/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:32 | Valid | Epoch[506/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:32 | Valid | Epoch[506/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 10:58:32 | Valid | Epoch[506/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:32 | Valid | Epoch[506/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:58:32 | Valid | Epoch[506/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:58:32 | Valid | Epoch[506/600] MIou: 0.9219067324987027
2023-02-06 10:58:32 | Valid | Epoch[506/600] Pixel Accuracy: 0.9869982401529948
2023-02-06 10:58:32 | Valid | Epoch[506/600] Mean Pixel Accuracy: 0.9339760598152669
2023-02-06 10:58:32 | Stage | Epoch[506/600] Train loss:0.0250
2023-02-06 10:58:32 | Stage | Epoch[506/600] Valid loss:0.0289
2023-02-06 10:58:32 | Stage | Epoch[506/600] LR:0.0001

2023-02-06 10:58:32 | Train | Epoch[507/600] Iteration[001/030] Train loss: 0.0273
2023-02-06 10:58:32 | Train | Epoch[507/600] Iteration[002/030] Train loss: 0.0264
2023-02-06 10:58:32 | Train | Epoch[507/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 10:58:32 | Train | Epoch[507/600] Iteration[004/030] Train loss: 0.0278
2023-02-06 10:58:32 | Train | Epoch[507/600] Iteration[005/030] Train loss: 0.0278
2023-02-06 10:58:32 | Train | Epoch[507/600] Iteration[006/030] Train loss: 0.0271
2023-02-06 10:58:32 | Train | Epoch[507/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 10:58:32 | Train | Epoch[507/600] Iteration[008/030] Train loss: 0.0270
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[009/030] Train loss: 0.0266
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[010/030] Train loss: 0.0269
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[016/030] Train loss: 0.0261
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:58:33 | Train | Epoch[507/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:58:34 | Valid | Epoch[507/600] Iteration[001/008] Valid loss: 0.0347
2023-02-06 10:58:34 | Valid | Epoch[507/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:58:34 | Valid | Epoch[507/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:58:34 | Valid | Epoch[507/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:34 | Valid | Epoch[507/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:34 | Valid | Epoch[507/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:58:34 | Valid | Epoch[507/600] Iteration[007/008] Valid loss: 0.0293
2023-02-06 10:58:34 | Valid | Epoch[507/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 10:58:34 | Valid | Epoch[507/600] MIou: 0.924206844867505
2023-02-06 10:58:34 | Valid | Epoch[507/600] Pixel Accuracy: 0.9873606363932291
2023-02-06 10:58:34 | Valid | Epoch[507/600] Mean Pixel Accuracy: 0.936825565336775
2023-02-06 10:58:34 | Stage | Epoch[507/600] Train loss:0.0250
2023-02-06 10:58:34 | Stage | Epoch[507/600] Valid loss:0.0291
2023-02-06 10:58:34 | Stage | Epoch[507/600] LR:0.0001

2023-02-06 10:58:34 | Train | Epoch[508/600] Iteration[001/030] Train loss: 0.0274
2023-02-06 10:58:34 | Train | Epoch[508/600] Iteration[002/030] Train loss: 0.0265
2023-02-06 10:58:34 | Train | Epoch[508/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:58:34 | Train | Epoch[508/600] Iteration[004/030] Train loss: 0.0250
2023-02-06 10:58:34 | Train | Epoch[508/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 10:58:34 | Train | Epoch[508/600] Iteration[006/030] Train loss: 0.0253
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[007/030] Train loss: 0.0251
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[008/030] Train loss: 0.0254
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:58:35 | Train | Epoch[508/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:58:36 | Train | Epoch[508/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:58:36 | Valid | Epoch[508/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 10:58:36 | Valid | Epoch[508/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:58:36 | Valid | Epoch[508/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:36 | Valid | Epoch[508/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:36 | Valid | Epoch[508/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:36 | Valid | Epoch[508/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:36 | Valid | Epoch[508/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:58:36 | Valid | Epoch[508/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:58:36 | Valid | Epoch[508/600] MIou: 0.9218466886717692
2023-02-06 10:58:36 | Valid | Epoch[508/600] Pixel Accuracy: 0.9869880676269531
2023-02-06 10:58:36 | Valid | Epoch[508/600] Mean Pixel Accuracy: 0.9339260852605221
2023-02-06 10:58:36 | Stage | Epoch[508/600] Train loss:0.0251
2023-02-06 10:58:36 | Stage | Epoch[508/600] Valid loss:0.0289
2023-02-06 10:58:36 | Stage | Epoch[508/600] LR:0.0001

2023-02-06 10:58:36 | Train | Epoch[509/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 10:58:36 | Train | Epoch[509/600] Iteration[002/030] Train loss: 0.0249
2023-02-06 10:58:36 | Train | Epoch[509/600] Iteration[003/030] Train loss: 0.0257
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[005/030] Train loss: 0.0256
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[007/030] Train loss: 0.0248
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[015/030] Train loss: 0.0244
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[016/030] Train loss: 0.0244
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[017/030] Train loss: 0.0246
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[018/030] Train loss: 0.0245
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[020/030] Train loss: 0.0246
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:58:37 | Train | Epoch[509/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:58:38 | Train | Epoch[509/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:58:38 | Train | Epoch[509/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:58:38 | Train | Epoch[509/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:38 | Train | Epoch[509/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:58:38 | Valid | Epoch[509/600] Iteration[001/008] Valid loss: 0.0338
2023-02-06 10:58:38 | Valid | Epoch[509/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:38 | Valid | Epoch[509/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:58:38 | Valid | Epoch[509/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:58:38 | Valid | Epoch[509/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:58:38 | Valid | Epoch[509/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:58:38 | Valid | Epoch[509/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:58:38 | Valid | Epoch[509/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:58:38 | Valid | Epoch[509/600] MIou: 0.9187861571568751
2023-02-06 10:58:38 | Valid | Epoch[509/600] Pixel Accuracy: 0.9864985148111979
2023-02-06 10:58:38 | Valid | Epoch[509/600] Mean Pixel Accuracy: 0.930442387097436
2023-02-06 10:58:38 | Stage | Epoch[509/600] Train loss:0.0251
2023-02-06 10:58:38 | Stage | Epoch[509/600] Valid loss:0.0289
2023-02-06 10:58:38 | Stage | Epoch[509/600] LR:0.0001

2023-02-06 10:58:38 | Train | Epoch[510/600] Iteration[001/030] Train loss: 0.0227
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[002/030] Train loss: 0.0251
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[003/030] Train loss: 0.0250
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:58:39 | Train | Epoch[510/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:58:40 | Train | Epoch[510/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:58:40 | Train | Epoch[510/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:58:40 | Train | Epoch[510/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:58:40 | Train | Epoch[510/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:58:40 | Train | Epoch[510/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:40 | Train | Epoch[510/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:58:40 | Valid | Epoch[510/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:58:40 | Valid | Epoch[510/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:58:40 | Valid | Epoch[510/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:58:40 | Valid | Epoch[510/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:58:40 | Valid | Epoch[510/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:40 | Valid | Epoch[510/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 10:58:40 | Valid | Epoch[510/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:58:40 | Valid | Epoch[510/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:58:40 | Valid | Epoch[510/600] MIou: 0.9189135089554471
2023-02-06 10:58:40 | Valid | Epoch[510/600] Pixel Accuracy: 0.9865239461263021
2023-02-06 10:58:40 | Valid | Epoch[510/600] Mean Pixel Accuracy: 0.9304246628752761
2023-02-06 10:58:40 | Stage | Epoch[510/600] Train loss:0.0251
2023-02-06 10:58:40 | Stage | Epoch[510/600] Valid loss:0.0288
2023-02-06 10:58:40 | Stage | Epoch[510/600] LR:0.0001

2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[003/030] Train loss: 0.0245
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[010/030] Train loss: 0.0245
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:58:41 | Train | Epoch[511/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:58:42 | Train | Epoch[511/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:58:42 | Train | Epoch[511/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:58:42 | Train | Epoch[511/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:58:42 | Train | Epoch[511/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:58:42 | Train | Epoch[511/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:58:42 | Train | Epoch[511/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:58:42 | Train | Epoch[511/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:58:42 | Valid | Epoch[511/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 10:58:42 | Valid | Epoch[511/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:42 | Valid | Epoch[511/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:42 | Valid | Epoch[511/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:42 | Valid | Epoch[511/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:42 | Valid | Epoch[511/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:42 | Valid | Epoch[511/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:58:42 | Valid | Epoch[511/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:58:42 | Valid | Epoch[511/600] MIou: 0.9214257088804347
2023-02-06 10:58:42 | Valid | Epoch[511/600] Pixel Accuracy: 0.9869206746419271
2023-02-06 10:58:42 | Valid | Epoch[511/600] Mean Pixel Accuracy: 0.9334452101958649
2023-02-06 10:58:42 | Stage | Epoch[511/600] Train loss:0.0251
2023-02-06 10:58:42 | Stage | Epoch[511/600] Valid loss:0.0289
2023-02-06 10:58:42 | Stage | Epoch[511/600] LR:0.0001

2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[001/030] Train loss: 0.0333
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[002/030] Train loss: 0.0296
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[003/030] Train loss: 0.0284
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[004/030] Train loss: 0.0289
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[005/030] Train loss: 0.0281
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[006/030] Train loss: 0.0285
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[007/030] Train loss: 0.0274
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[008/030] Train loss: 0.0271
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[011/030] Train loss: 0.0262
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[013/030] Train loss: 0.0258
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:58:43 | Train | Epoch[512/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:58:44 | Train | Epoch[512/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:58:44 | Train | Epoch[512/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:58:44 | Train | Epoch[512/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 10:58:44 | Train | Epoch[512/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 10:58:44 | Train | Epoch[512/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:58:44 | Train | Epoch[512/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:58:44 | Train | Epoch[512/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:58:44 | Train | Epoch[512/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:58:44 | Train | Epoch[512/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 10:58:44 | Train | Epoch[512/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:58:44 | Valid | Epoch[512/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:58:44 | Valid | Epoch[512/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:44 | Valid | Epoch[512/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:44 | Valid | Epoch[512/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:44 | Valid | Epoch[512/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 10:58:44 | Valid | Epoch[512/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 10:58:44 | Valid | Epoch[512/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:58:44 | Valid | Epoch[512/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:58:45 | Valid | Epoch[512/600] MIou: 0.9201848872544608
2023-02-06 10:58:45 | Valid | Epoch[512/600] Pixel Accuracy: 0.986724853515625
2023-02-06 10:58:45 | Valid | Epoch[512/600] Mean Pixel Accuracy: 0.9319426748206228
2023-02-06 10:58:45 | Stage | Epoch[512/600] Train loss:0.0254
2023-02-06 10:58:45 | Stage | Epoch[512/600] Valid loss:0.0288
2023-02-06 10:58:45 | Stage | Epoch[512/600] LR:0.0001

2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[001/030] Train loss: 0.0242
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[002/030] Train loss: 0.0231
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[006/030] Train loss: 0.0246
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[008/030] Train loss: 0.0236
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[009/030] Train loss: 0.0234
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[010/030] Train loss: 0.0237
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[011/030] Train loss: 0.0240
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[013/030] Train loss: 0.0245
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[014/030] Train loss: 0.0245
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 10:58:45 | Train | Epoch[513/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[017/030] Train loss: 0.0246
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:46 | Train | Epoch[513/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:58:46 | Valid | Epoch[513/600] Iteration[001/008] Valid loss: 0.0346
2023-02-06 10:58:46 | Valid | Epoch[513/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:58:46 | Valid | Epoch[513/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:46 | Valid | Epoch[513/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:46 | Valid | Epoch[513/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:46 | Valid | Epoch[513/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:58:47 | Valid | Epoch[513/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:58:47 | Valid | Epoch[513/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:58:47 | Valid | Epoch[513/600] MIou: 0.9231384377714129
2023-02-06 10:58:47 | Valid | Epoch[513/600] Pixel Accuracy: 0.987188975016276
2023-02-06 10:58:47 | Valid | Epoch[513/600] Mean Pixel Accuracy: 0.9356089494651827
2023-02-06 10:58:47 | Stage | Epoch[513/600] Train loss:0.0250
2023-02-06 10:58:47 | Stage | Epoch[513/600] Valid loss:0.0290
2023-02-06 10:58:47 | Stage | Epoch[513/600] LR:0.0001

2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[001/030] Train loss: 0.0221
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[002/030] Train loss: 0.0251
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[003/030] Train loss: 0.0270
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[004/030] Train loss: 0.0261
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:58:47 | Train | Epoch[514/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[028/030] Train loss: 0.0247
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:58:48 | Train | Epoch[514/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 10:58:49 | Valid | Epoch[514/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 10:58:49 | Valid | Epoch[514/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:49 | Valid | Epoch[514/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:49 | Valid | Epoch[514/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:49 | Valid | Epoch[514/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:49 | Valid | Epoch[514/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:49 | Valid | Epoch[514/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:58:49 | Valid | Epoch[514/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:58:49 | Valid | Epoch[514/600] MIou: 0.9223622101999815
2023-02-06 10:58:49 | Valid | Epoch[514/600] Pixel Accuracy: 0.9870681762695312
2023-02-06 10:58:49 | Valid | Epoch[514/600] Mean Pixel Accuracy: 0.9345978230667299
2023-02-06 10:58:49 | Stage | Epoch[514/600] Train loss:0.0249
2023-02-06 10:58:49 | Stage | Epoch[514/600] Valid loss:0.0289
2023-02-06 10:58:49 | Stage | Epoch[514/600] LR:0.0001

2023-02-06 10:58:49 | Train | Epoch[515/600] Iteration[001/030] Train loss: 0.0204
2023-02-06 10:58:49 | Train | Epoch[515/600] Iteration[002/030] Train loss: 0.0231
2023-02-06 10:58:49 | Train | Epoch[515/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 10:58:49 | Train | Epoch[515/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:58:49 | Train | Epoch[515/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 10:58:49 | Train | Epoch[515/600] Iteration[006/030] Train loss: 0.0235
2023-02-06 10:58:49 | Train | Epoch[515/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 10:58:49 | Train | Epoch[515/600] Iteration[008/030] Train loss: 0.0251
2023-02-06 10:58:49 | Train | Epoch[515/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:58:50 | Train | Epoch[515/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 10:58:51 | Valid | Epoch[515/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:58:51 | Valid | Epoch[515/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:51 | Valid | Epoch[515/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:51 | Valid | Epoch[515/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:51 | Valid | Epoch[515/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:51 | Valid | Epoch[515/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:51 | Valid | Epoch[515/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:58:51 | Valid | Epoch[515/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:58:51 | Valid | Epoch[515/600] MIou: 0.9207388469370834
2023-02-06 10:58:51 | Valid | Epoch[515/600] Pixel Accuracy: 0.9868113199869791
2023-02-06 10:58:51 | Valid | Epoch[515/600] Mean Pixel Accuracy: 0.932643269046729
2023-02-06 10:58:51 | Stage | Epoch[515/600] Train loss:0.0249
2023-02-06 10:58:51 | Stage | Epoch[515/600] Valid loss:0.0289
2023-02-06 10:58:51 | Stage | Epoch[515/600] LR:0.0001

2023-02-06 10:58:51 | Train | Epoch[516/600] Iteration[001/030] Train loss: 0.0296
2023-02-06 10:58:51 | Train | Epoch[516/600] Iteration[002/030] Train loss: 0.0297
2023-02-06 10:58:51 | Train | Epoch[516/600] Iteration[003/030] Train loss: 0.0290
2023-02-06 10:58:51 | Train | Epoch[516/600] Iteration[004/030] Train loss: 0.0276
2023-02-06 10:58:51 | Train | Epoch[516/600] Iteration[005/030] Train loss: 0.0270
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[006/030] Train loss: 0.0262
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[008/030] Train loss: 0.0268
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[009/030] Train loss: 0.0268
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[010/030] Train loss: 0.0271
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[011/030] Train loss: 0.0266
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[012/030] Train loss: 0.0263
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:58:52 | Train | Epoch[516/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:58:53 | Train | Epoch[516/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:53 | Train | Epoch[516/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:58:53 | Valid | Epoch[516/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:58:53 | Valid | Epoch[516/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:58:53 | Valid | Epoch[516/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:53 | Valid | Epoch[516/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:53 | Valid | Epoch[516/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:53 | Valid | Epoch[516/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:58:53 | Valid | Epoch[516/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:58:53 | Valid | Epoch[516/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:58:53 | Valid | Epoch[516/600] MIou: 0.919493391338482
2023-02-06 10:58:53 | Valid | Epoch[516/600] Pixel Accuracy: 0.9866142272949219
2023-02-06 10:58:53 | Valid | Epoch[516/600] Mean Pixel Accuracy: 0.9311590561792529
2023-02-06 10:58:53 | Stage | Epoch[516/600] Train loss:0.0252
2023-02-06 10:58:53 | Stage | Epoch[516/600] Valid loss:0.0288
2023-02-06 10:58:53 | Stage | Epoch[516/600] LR:0.0001

2023-02-06 10:58:53 | Train | Epoch[517/600] Iteration[001/030] Train loss: 0.0243
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[002/030] Train loss: 0.0246
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[007/030] Train loss: 0.0254
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[008/030] Train loss: 0.0251
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[010/030] Train loss: 0.0255
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 10:58:54 | Train | Epoch[517/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:58:55 | Train | Epoch[517/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:58:55 | Train | Epoch[517/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:58:55 | Train | Epoch[517/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:58:55 | Train | Epoch[517/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:58:55 | Train | Epoch[517/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:58:55 | Valid | Epoch[517/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:58:55 | Valid | Epoch[517/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:58:55 | Valid | Epoch[517/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:55 | Valid | Epoch[517/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:58:55 | Valid | Epoch[517/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:55 | Valid | Epoch[517/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 10:58:55 | Valid | Epoch[517/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:58:55 | Valid | Epoch[517/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:58:55 | Valid | Epoch[517/600] MIou: 0.9184697907401063
2023-02-06 10:58:55 | Valid | Epoch[517/600] Pixel Accuracy: 0.9864514668782552
2023-02-06 10:58:55 | Valid | Epoch[517/600] Mean Pixel Accuracy: 0.9299726945410993
2023-02-06 10:58:55 | Stage | Epoch[517/600] Train loss:0.0254
2023-02-06 10:58:55 | Stage | Epoch[517/600] Valid loss:0.0288
2023-02-06 10:58:55 | Stage | Epoch[517/600] LR:0.0001

2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[001/030] Train loss: 0.0196
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[003/030] Train loss: 0.0213
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[004/030] Train loss: 0.0216
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[005/030] Train loss: 0.0225
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[006/030] Train loss: 0.0231
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[007/030] Train loss: 0.0233
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[008/030] Train loss: 0.0236
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[009/030] Train loss: 0.0240
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[010/030] Train loss: 0.0240
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[012/030] Train loss: 0.0244
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[013/030] Train loss: 0.0245
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[014/030] Train loss: 0.0245
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:58:56 | Train | Epoch[518/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:58:57 | Train | Epoch[518/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:58:57 | Train | Epoch[518/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:58:57 | Train | Epoch[518/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:58:57 | Train | Epoch[518/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:58:57 | Train | Epoch[518/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:58:57 | Train | Epoch[518/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:58:57 | Train | Epoch[518/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:58:57 | Train | Epoch[518/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:58:57 | Valid | Epoch[518/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 10:58:57 | Valid | Epoch[518/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:58:57 | Valid | Epoch[518/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:57 | Valid | Epoch[518/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:57 | Valid | Epoch[518/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:57 | Valid | Epoch[518/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:58:57 | Valid | Epoch[518/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:58:57 | Valid | Epoch[518/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:58:57 | Valid | Epoch[518/600] MIou: 0.9224765751512811
2023-02-06 10:58:57 | Valid | Epoch[518/600] Pixel Accuracy: 0.9870872497558594
2023-02-06 10:58:57 | Valid | Epoch[518/600] Mean Pixel Accuracy: 0.9347034137409616
2023-02-06 10:58:57 | Stage | Epoch[518/600] Train loss:0.0252
2023-02-06 10:58:57 | Stage | Epoch[518/600] Valid loss:0.0290
2023-02-06 10:58:57 | Stage | Epoch[518/600] LR:0.0001

2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[001/030] Train loss: 0.0253
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:58:58 | Train | Epoch[519/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:58:59 | Train | Epoch[519/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:58:59 | Train | Epoch[519/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:58:59 | Train | Epoch[519/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 10:58:59 | Train | Epoch[519/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 10:58:59 | Train | Epoch[519/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:58:59 | Train | Epoch[519/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:58:59 | Train | Epoch[519/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:58:59 | Train | Epoch[519/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:58:59 | Train | Epoch[519/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:58:59 | Train | Epoch[519/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:58:59 | Valid | Epoch[519/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 10:58:59 | Valid | Epoch[519/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:58:59 | Valid | Epoch[519/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:58:59 | Valid | Epoch[519/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:58:59 | Valid | Epoch[519/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:58:59 | Valid | Epoch[519/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:58:59 | Valid | Epoch[519/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:58:59 | Valid | Epoch[519/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:58:59 | Valid | Epoch[519/600] MIou: 0.9226778225719177
2023-02-06 10:58:59 | Valid | Epoch[519/600] Pixel Accuracy: 0.9871190388997396
2023-02-06 10:58:59 | Valid | Epoch[519/600] Mean Pixel Accuracy: 0.9349491433846473
2023-02-06 10:58:59 | Stage | Epoch[519/600] Train loss:0.0252
2023-02-06 10:58:59 | Stage | Epoch[519/600] Valid loss:0.0290
2023-02-06 10:58:59 | Stage | Epoch[519/600] LR:0.0001

2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[004/030] Train loss: 0.0243
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[005/030] Train loss: 0.0245
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[007/030] Train loss: 0.0250
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:59:00 | Train | Epoch[520/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[022/030] Train loss: 0.0247
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:59:01 | Train | Epoch[520/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:59:01 | Valid | Epoch[520/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:59:01 | Valid | Epoch[520/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:59:01 | Valid | Epoch[520/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:01 | Valid | Epoch[520/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:01 | Valid | Epoch[520/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:01 | Valid | Epoch[520/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:01 | Valid | Epoch[520/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:59:01 | Valid | Epoch[520/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:59:01 | Valid | Epoch[520/600] MIou: 0.920487653740286
2023-02-06 10:59:01 | Valid | Epoch[520/600] Pixel Accuracy: 0.9867706298828125
2023-02-06 10:59:01 | Valid | Epoch[520/600] Mean Pixel Accuracy: 0.9323736256411169
2023-02-06 10:59:01 | Stage | Epoch[520/600] Train loss:0.0251
2023-02-06 10:59:01 | Stage | Epoch[520/600] Valid loss:0.0289
2023-02-06 10:59:01 | Stage | Epoch[520/600] LR:0.0001

2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[001/030] Train loss: 0.0223
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[002/030] Train loss: 0.0278
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[004/030] Train loss: 0.0263
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[008/030] Train loss: 0.0254
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[017/030] Train loss: 0.0246
2023-02-06 10:59:02 | Train | Epoch[521/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[024/030] Train loss: 0.0248
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:59:03 | Train | Epoch[521/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 10:59:03 | Valid | Epoch[521/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:59:03 | Valid | Epoch[521/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:59:03 | Valid | Epoch[521/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:59:03 | Valid | Epoch[521/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:59:03 | Valid | Epoch[521/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:59:03 | Valid | Epoch[521/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:03 | Valid | Epoch[521/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:59:03 | Valid | Epoch[521/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:59:04 | Valid | Epoch[521/600] MIou: 0.91815077443712
2023-02-06 10:59:04 | Valid | Epoch[521/600] Pixel Accuracy: 0.9864006042480469
2023-02-06 10:59:04 | Valid | Epoch[521/600] Mean Pixel Accuracy: 0.9296086932801579
2023-02-06 10:59:04 | Stage | Epoch[521/600] Train loss:0.0254
2023-02-06 10:59:04 | Stage | Epoch[521/600] Valid loss:0.0288
2023-02-06 10:59:04 | Stage | Epoch[521/600] LR:0.0001

2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[001/030] Train loss: 0.0261
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[002/030] Train loss: 0.0226
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[004/030] Train loss: 0.0240
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[005/030] Train loss: 0.0237
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[006/030] Train loss: 0.0237
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[008/030] Train loss: 0.0239
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[010/030] Train loss: 0.0243
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:59:04 | Train | Epoch[522/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[024/030] Train loss: 0.0248
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:59:05 | Train | Epoch[522/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 10:59:05 | Valid | Epoch[522/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:59:05 | Valid | Epoch[522/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:59:06 | Valid | Epoch[522/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:59:06 | Valid | Epoch[522/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:59:06 | Valid | Epoch[522/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:59:06 | Valid | Epoch[522/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:06 | Valid | Epoch[522/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:59:06 | Valid | Epoch[522/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:59:06 | Valid | Epoch[522/600] MIou: 0.9187993979188545
2023-02-06 10:59:06 | Valid | Epoch[522/600] Pixel Accuracy: 0.9865010579427084
2023-02-06 10:59:06 | Valid | Epoch[522/600] Mean Pixel Accuracy: 0.930443784910976
2023-02-06 10:59:06 | Stage | Epoch[522/600] Train loss:0.0249
2023-02-06 10:59:06 | Stage | Epoch[522/600] Valid loss:0.0289
2023-02-06 10:59:06 | Stage | Epoch[522/600] LR:0.0001

2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[001/030] Train loss: 0.0283
2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[003/030] Train loss: 0.0251
2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[004/030] Train loss: 0.0237
2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[005/030] Train loss: 0.0240
2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[010/030] Train loss: 0.0242
2023-02-06 10:59:06 | Train | Epoch[523/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[013/030] Train loss: 0.0247
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[015/030] Train loss: 0.0243
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[016/030] Train loss: 0.0244
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[017/030] Train loss: 0.0244
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[018/030] Train loss: 0.0244
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[021/030] Train loss: 0.0245
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[023/030] Train loss: 0.0246
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[024/030] Train loss: 0.0246
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[025/030] Train loss: 0.0246
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[026/030] Train loss: 0.0246
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:59:07 | Train | Epoch[523/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 10:59:08 | Valid | Epoch[523/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 10:59:08 | Valid | Epoch[523/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:59:08 | Valid | Epoch[523/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:08 | Valid | Epoch[523/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:08 | Valid | Epoch[523/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:08 | Valid | Epoch[523/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:59:08 | Valid | Epoch[523/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:59:08 | Valid | Epoch[523/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:59:08 | Valid | Epoch[523/600] MIou: 0.9225344085934764
2023-02-06 10:59:08 | Valid | Epoch[523/600] Pixel Accuracy: 0.9870999654134115
2023-02-06 10:59:08 | Valid | Epoch[523/600] Mean Pixel Accuracy: 0.9346533385650532
2023-02-06 10:59:08 | Stage | Epoch[523/600] Train loss:0.0249
2023-02-06 10:59:08 | Stage | Epoch[523/600] Valid loss:0.0290
2023-02-06 10:59:08 | Stage | Epoch[523/600] LR:0.0001

2023-02-06 10:59:08 | Train | Epoch[524/600] Iteration[001/030] Train loss: 0.0232
2023-02-06 10:59:08 | Train | Epoch[524/600] Iteration[002/030] Train loss: 0.0241
2023-02-06 10:59:08 | Train | Epoch[524/600] Iteration[003/030] Train loss: 0.0253
2023-02-06 10:59:08 | Train | Epoch[524/600] Iteration[004/030] Train loss: 0.0243
2023-02-06 10:59:08 | Train | Epoch[524/600] Iteration[005/030] Train loss: 0.0241
2023-02-06 10:59:08 | Train | Epoch[524/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:59:08 | Train | Epoch[524/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 10:59:08 | Train | Epoch[524/600] Iteration[008/030] Train loss: 0.0251
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:59:09 | Train | Epoch[524/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:59:10 | Valid | Epoch[524/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 10:59:10 | Valid | Epoch[524/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:59:10 | Valid | Epoch[524/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:10 | Valid | Epoch[524/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:10 | Valid | Epoch[524/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:10 | Valid | Epoch[524/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:59:10 | Valid | Epoch[524/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:59:10 | Valid | Epoch[524/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:59:10 | Valid | Epoch[524/600] MIou: 0.9224700539233631
2023-02-06 10:59:10 | Valid | Epoch[524/600] Pixel Accuracy: 0.987084706624349
2023-02-06 10:59:10 | Valid | Epoch[524/600] Mean Pixel Accuracy: 0.9347463992280061
2023-02-06 10:59:10 | Stage | Epoch[524/600] Train loss:0.0250
2023-02-06 10:59:10 | Stage | Epoch[524/600] Valid loss:0.0290
2023-02-06 10:59:10 | Stage | Epoch[524/600] LR:0.0001

2023-02-06 10:59:10 | Train | Epoch[525/600] Iteration[001/030] Train loss: 0.0197
2023-02-06 10:59:10 | Train | Epoch[525/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 10:59:10 | Train | Epoch[525/600] Iteration[003/030] Train loss: 0.0246
2023-02-06 10:59:10 | Train | Epoch[525/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[008/030] Train loss: 0.0240
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[012/030] Train loss: 0.0244
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[013/030] Train loss: 0.0245
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:59:11 | Train | Epoch[525/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:59:12 | Train | Epoch[525/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:59:12 | Train | Epoch[525/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:59:12 | Valid | Epoch[525/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:59:12 | Valid | Epoch[525/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:59:12 | Valid | Epoch[525/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:12 | Valid | Epoch[525/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:12 | Valid | Epoch[525/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:12 | Valid | Epoch[525/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 10:59:12 | Valid | Epoch[525/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:59:12 | Valid | Epoch[525/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:59:12 | Valid | Epoch[525/600] MIou: 0.920346224931496
2023-02-06 10:59:12 | Valid | Epoch[525/600] Pixel Accuracy: 0.9867515563964844
2023-02-06 10:59:12 | Valid | Epoch[525/600] Mean Pixel Accuracy: 0.9320968422360592
2023-02-06 10:59:12 | Stage | Epoch[525/600] Train loss:0.0252
2023-02-06 10:59:12 | Stage | Epoch[525/600] Valid loss:0.0288
2023-02-06 10:59:12 | Stage | Epoch[525/600] LR:0.0001

2023-02-06 10:59:12 | Train | Epoch[526/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[003/030] Train loss: 0.0249
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[006/030] Train loss: 0.0253
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[007/030] Train loss: 0.0248
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[009/030] Train loss: 0.0254
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:59:13 | Train | Epoch[526/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 10:59:14 | Train | Epoch[526/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:59:14 | Train | Epoch[526/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:59:14 | Train | Epoch[526/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 10:59:14 | Train | Epoch[526/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:59:14 | Train | Epoch[526/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:59:14 | Train | Epoch[526/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:59:14 | Valid | Epoch[526/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:59:14 | Valid | Epoch[526/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:59:14 | Valid | Epoch[526/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:14 | Valid | Epoch[526/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:14 | Valid | Epoch[526/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:14 | Valid | Epoch[526/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:14 | Valid | Epoch[526/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:59:14 | Valid | Epoch[526/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:59:14 | Valid | Epoch[526/600] MIou: 0.9210769079490674
2023-02-06 10:59:14 | Valid | Epoch[526/600] Pixel Accuracy: 0.9868659973144531
2023-02-06 10:59:14 | Valid | Epoch[526/600] Mean Pixel Accuracy: 0.9330093670279804
2023-02-06 10:59:14 | Stage | Epoch[526/600] Train loss:0.0251
2023-02-06 10:59:14 | Stage | Epoch[526/600] Valid loss:0.0289
2023-02-06 10:59:14 | Stage | Epoch[526/600] LR:0.0001

2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[001/030] Train loss: 0.0249
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[008/030] Train loss: 0.0240
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[010/030] Train loss: 0.0238
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[011/030] Train loss: 0.0244
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[012/030] Train loss: 0.0242
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[013/030] Train loss: 0.0242
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:59:15 | Train | Epoch[527/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:59:16 | Train | Epoch[527/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:59:16 | Train | Epoch[527/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:59:16 | Train | Epoch[527/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:59:16 | Train | Epoch[527/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:59:16 | Train | Epoch[527/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:59:16 | Train | Epoch[527/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:59:16 | Train | Epoch[527/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:59:16 | Train | Epoch[527/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:59:16 | Train | Epoch[527/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:59:16 | Valid | Epoch[527/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:59:16 | Valid | Epoch[527/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:59:16 | Valid | Epoch[527/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:16 | Valid | Epoch[527/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:16 | Valid | Epoch[527/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:16 | Valid | Epoch[527/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:16 | Valid | Epoch[527/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:59:16 | Valid | Epoch[527/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:59:16 | Valid | Epoch[527/600] MIou: 0.9210705412500559
2023-02-06 10:59:16 | Valid | Epoch[527/600] Pixel Accuracy: 0.9868634541829427
2023-02-06 10:59:16 | Valid | Epoch[527/600] Mean Pixel Accuracy: 0.933052352515025
2023-02-06 10:59:16 | Stage | Epoch[527/600] Train loss:0.0250
2023-02-06 10:59:16 | Stage | Epoch[527/600] Valid loss:0.0289
2023-02-06 10:59:16 | Stage | Epoch[527/600] LR:0.0001

2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[001/030] Train loss: 0.0282
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[002/030] Train loss: 0.0274
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[004/030] Train loss: 0.0278
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[005/030] Train loss: 0.0282
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[006/030] Train loss: 0.0278
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[007/030] Train loss: 0.0277
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[008/030] Train loss: 0.0270
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[009/030] Train loss: 0.0266
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[011/030] Train loss: 0.0263
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:59:17 | Train | Epoch[528/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:59:18 | Train | Epoch[528/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:59:18 | Valid | Epoch[528/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:59:18 | Valid | Epoch[528/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:59:18 | Valid | Epoch[528/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:18 | Valid | Epoch[528/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:18 | Valid | Epoch[528/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:18 | Valid | Epoch[528/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:18 | Valid | Epoch[528/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:59:18 | Valid | Epoch[528/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:59:19 | Valid | Epoch[528/600] MIou: 0.9207318355033178
2023-02-06 10:59:19 | Valid | Epoch[528/600] Pixel Accuracy: 0.9868075052897135
2023-02-06 10:59:19 | Valid | Epoch[528/600] Mean Pixel Accuracy: 0.932723598456076
2023-02-06 10:59:19 | Stage | Epoch[528/600] Train loss:0.0251
2023-02-06 10:59:19 | Stage | Epoch[528/600] Valid loss:0.0289
2023-02-06 10:59:19 | Stage | Epoch[528/600] LR:0.0001

2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[001/030] Train loss: 0.0269
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[002/030] Train loss: 0.0251
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[004/030] Train loss: 0.0268
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[005/030] Train loss: 0.0258
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[007/030] Train loss: 0.0254
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[013/030] Train loss: 0.0253
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 10:59:19 | Train | Epoch[529/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:59:20 | Train | Epoch[529/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:59:20 | Valid | Epoch[529/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 10:59:20 | Valid | Epoch[529/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:59:21 | Valid | Epoch[529/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:21 | Valid | Epoch[529/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:21 | Valid | Epoch[529/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:21 | Valid | Epoch[529/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:59:21 | Valid | Epoch[529/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:59:21 | Valid | Epoch[529/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:59:21 | Valid | Epoch[529/600] MIou: 0.9215546497275933
2023-02-06 10:59:21 | Valid | Epoch[529/600] Pixel Accuracy: 0.9869410196940104
2023-02-06 10:59:21 | Valid | Epoch[529/600] Mean Pixel Accuracy: 0.9336022235489632
2023-02-06 10:59:21 | Stage | Epoch[529/600] Train loss:0.0253
2023-02-06 10:59:21 | Stage | Epoch[529/600] Valid loss:0.0290
2023-02-06 10:59:21 | Stage | Epoch[529/600] LR:0.0001

2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[001/030] Train loss: 0.0248
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[002/030] Train loss: 0.0246
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[003/030] Train loss: 0.0265
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[005/030] Train loss: 0.0243
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[006/030] Train loss: 0.0253
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[008/030] Train loss: 0.0250
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 10:59:21 | Train | Epoch[530/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:59:22 | Train | Epoch[530/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:59:23 | Valid | Epoch[530/600] Iteration[001/008] Valid loss: 0.0349
2023-02-06 10:59:23 | Valid | Epoch[530/600] Iteration[002/008] Valid loss: 0.0303
2023-02-06 10:59:23 | Valid | Epoch[530/600] Iteration[003/008] Valid loss: 0.0296
2023-02-06 10:59:23 | Valid | Epoch[530/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:59:23 | Valid | Epoch[530/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 10:59:23 | Valid | Epoch[530/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 10:59:23 | Valid | Epoch[530/600] Iteration[007/008] Valid loss: 0.0296
2023-02-06 10:59:23 | Valid | Epoch[530/600] Iteration[008/008] Valid loss: 0.0293
2023-02-06 10:59:23 | Valid | Epoch[530/600] MIou: 0.9256515720989549
2023-02-06 10:59:23 | Valid | Epoch[530/600] Pixel Accuracy: 0.9875869750976562
2023-02-06 10:59:23 | Valid | Epoch[530/600] Mean Pixel Accuracy: 0.9386872599361502
2023-02-06 10:59:23 | Stage | Epoch[530/600] Train loss:0.0252
2023-02-06 10:59:23 | Stage | Epoch[530/600] Valid loss:0.0293
2023-02-06 10:59:23 | Stage | Epoch[530/600] LR:0.0001

2023-02-06 10:59:23 | Train | Epoch[531/600] Iteration[001/030] Train loss: 0.0293
2023-02-06 10:59:23 | Train | Epoch[531/600] Iteration[002/030] Train loss: 0.0270
2023-02-06 10:59:23 | Train | Epoch[531/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 10:59:23 | Train | Epoch[531/600] Iteration[004/030] Train loss: 0.0262
2023-02-06 10:59:23 | Train | Epoch[531/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 10:59:23 | Train | Epoch[531/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 10:59:23 | Train | Epoch[531/600] Iteration[007/030] Train loss: 0.0256
2023-02-06 10:59:23 | Train | Epoch[531/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:59:23 | Train | Epoch[531/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[010/030] Train loss: 0.0257
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[012/030] Train loss: 0.0259
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[015/030] Train loss: 0.0258
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:59:24 | Train | Epoch[531/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:59:25 | Valid | Epoch[531/600] Iteration[001/008] Valid loss: 0.0347
2023-02-06 10:59:25 | Valid | Epoch[531/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:59:25 | Valid | Epoch[531/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:59:25 | Valid | Epoch[531/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:25 | Valid | Epoch[531/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:59:25 | Valid | Epoch[531/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 10:59:25 | Valid | Epoch[531/600] Iteration[007/008] Valid loss: 0.0293
2023-02-06 10:59:25 | Valid | Epoch[531/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 10:59:25 | Valid | Epoch[531/600] MIou: 0.924276179889227
2023-02-06 10:59:25 | Valid | Epoch[531/600] Pixel Accuracy: 0.9873682657877604
2023-02-06 10:59:25 | Valid | Epoch[531/600] Mean Pixel Accuracy: 0.9370263133942696
2023-02-06 10:59:25 | Stage | Epoch[531/600] Train loss:0.0252
2023-02-06 10:59:25 | Stage | Epoch[531/600] Valid loss:0.0291
2023-02-06 10:59:25 | Stage | Epoch[531/600] LR:0.0001

2023-02-06 10:59:25 | Train | Epoch[532/600] Iteration[001/030] Train loss: 0.0248
2023-02-06 10:59:25 | Train | Epoch[532/600] Iteration[002/030] Train loss: 0.0261
2023-02-06 10:59:25 | Train | Epoch[532/600] Iteration[003/030] Train loss: 0.0277
2023-02-06 10:59:25 | Train | Epoch[532/600] Iteration[004/030] Train loss: 0.0284
2023-02-06 10:59:25 | Train | Epoch[532/600] Iteration[005/030] Train loss: 0.0279
2023-02-06 10:59:25 | Train | Epoch[532/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[007/030] Train loss: 0.0261
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[009/030] Train loss: 0.0263
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:59:26 | Train | Epoch[532/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:59:27 | Train | Epoch[532/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 10:59:27 | Valid | Epoch[532/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:59:27 | Valid | Epoch[532/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:59:27 | Valid | Epoch[532/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:27 | Valid | Epoch[532/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:59:27 | Valid | Epoch[532/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:27 | Valid | Epoch[532/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:27 | Valid | Epoch[532/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:59:27 | Valid | Epoch[532/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:59:27 | Valid | Epoch[532/600] MIou: 0.9191477428736247
2023-02-06 10:59:27 | Valid | Epoch[532/600] Pixel Accuracy: 0.9865595499674479
2023-02-06 10:59:27 | Valid | Epoch[532/600] Mean Pixel Accuracy: 0.9307485748974169
2023-02-06 10:59:27 | Stage | Epoch[532/600] Train loss:0.0252
2023-02-06 10:59:27 | Stage | Epoch[532/600] Valid loss:0.0288
2023-02-06 10:59:27 | Stage | Epoch[532/600] LR:0.0001

2023-02-06 10:59:27 | Train | Epoch[533/600] Iteration[001/030] Train loss: 0.0225
2023-02-06 10:59:27 | Train | Epoch[533/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[004/030] Train loss: 0.0255
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[010/030] Train loss: 0.0248
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[011/030] Train loss: 0.0244
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[012/030] Train loss: 0.0244
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:59:28 | Train | Epoch[533/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 10:59:29 | Train | Epoch[533/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:59:29 | Train | Epoch[533/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:59:29 | Train | Epoch[533/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:59:29 | Train | Epoch[533/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:59:29 | Valid | Epoch[533/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 10:59:29 | Valid | Epoch[533/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:59:29 | Valid | Epoch[533/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:29 | Valid | Epoch[533/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:29 | Valid | Epoch[533/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:29 | Valid | Epoch[533/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:59:29 | Valid | Epoch[533/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 10:59:29 | Valid | Epoch[533/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:59:29 | Valid | Epoch[533/600] MIou: 0.9216548013502884
2023-02-06 10:59:29 | Valid | Epoch[533/600] Pixel Accuracy: 0.9869575500488281
2023-02-06 10:59:29 | Valid | Epoch[533/600] Mean Pixel Accuracy: 0.9337000759381427
2023-02-06 10:59:29 | Stage | Epoch[533/600] Train loss:0.0251
2023-02-06 10:59:29 | Stage | Epoch[533/600] Valid loss:0.0290
2023-02-06 10:59:29 | Stage | Epoch[533/600] LR:0.0001

2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[001/030] Train loss: 0.0286
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[002/030] Train loss: 0.0272
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[006/030] Train loss: 0.0262
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[009/030] Train loss: 0.0260
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[011/030] Train loss: 0.0257
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[021/030] Train loss: 0.0245
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 10:59:30 | Train | Epoch[534/600] Iteration[024/030] Train loss: 0.0246
2023-02-06 10:59:31 | Train | Epoch[534/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 10:59:31 | Train | Epoch[534/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 10:59:31 | Train | Epoch[534/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 10:59:31 | Train | Epoch[534/600] Iteration[028/030] Train loss: 0.0248
2023-02-06 10:59:31 | Train | Epoch[534/600] Iteration[029/030] Train loss: 0.0248
2023-02-06 10:59:31 | Train | Epoch[534/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:59:31 | Valid | Epoch[534/600] Iteration[001/008] Valid loss: 0.0345
2023-02-06 10:59:31 | Valid | Epoch[534/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:59:31 | Valid | Epoch[534/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:31 | Valid | Epoch[534/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:31 | Valid | Epoch[534/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:31 | Valid | Epoch[534/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:59:31 | Valid | Epoch[534/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:59:31 | Valid | Epoch[534/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:59:31 | Valid | Epoch[534/600] MIou: 0.9231154446400707
2023-02-06 10:59:31 | Valid | Epoch[534/600] Pixel Accuracy: 0.9871877034505209
2023-02-06 10:59:31 | Valid | Epoch[534/600] Mean Pixel Accuracy: 0.9355004625427072
2023-02-06 10:59:31 | Stage | Epoch[534/600] Train loss:0.0250
2023-02-06 10:59:31 | Stage | Epoch[534/600] Valid loss:0.0290
2023-02-06 10:59:31 | Stage | Epoch[534/600] LR:0.0001

2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[001/030] Train loss: 0.0248
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[002/030] Train loss: 0.0256
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[004/030] Train loss: 0.0265
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[007/030] Train loss: 0.0248
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[008/030] Train loss: 0.0242
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:59:32 | Train | Epoch[535/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:59:33 | Train | Epoch[535/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:59:33 | Train | Epoch[535/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 10:59:33 | Train | Epoch[535/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:59:33 | Train | Epoch[535/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:59:33 | Train | Epoch[535/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:59:33 | Train | Epoch[535/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 10:59:33 | Train | Epoch[535/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:59:33 | Train | Epoch[535/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 10:59:33 | Train | Epoch[535/600] Iteration[029/030] Train loss: 0.0255
2023-02-06 10:59:33 | Train | Epoch[535/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:59:33 | Valid | Epoch[535/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:59:33 | Valid | Epoch[535/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:59:33 | Valid | Epoch[535/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:33 | Valid | Epoch[535/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:33 | Valid | Epoch[535/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:33 | Valid | Epoch[535/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:33 | Valid | Epoch[535/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:59:33 | Valid | Epoch[535/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:59:33 | Valid | Epoch[535/600] MIou: 0.9199584521127606
2023-02-06 10:59:33 | Valid | Epoch[535/600] Pixel Accuracy: 0.986687978108724
2023-02-06 10:59:33 | Valid | Epoch[535/600] Mean Pixel Accuracy: 0.931706830492881
2023-02-06 10:59:33 | Stage | Epoch[535/600] Train loss:0.0253
2023-02-06 10:59:33 | Stage | Epoch[535/600] Valid loss:0.0288
2023-02-06 10:59:33 | Stage | Epoch[535/600] LR:0.0001

2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[001/030] Train loss: 0.0186
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[002/030] Train loss: 0.0212
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[003/030] Train loss: 0.0214
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[004/030] Train loss: 0.0220
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[005/030] Train loss: 0.0224
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[006/030] Train loss: 0.0230
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[007/030] Train loss: 0.0230
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[008/030] Train loss: 0.0227
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[009/030] Train loss: 0.0231
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[010/030] Train loss: 0.0231
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[011/030] Train loss: 0.0234
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[012/030] Train loss: 0.0237
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[013/030] Train loss: 0.0232
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[014/030] Train loss: 0.0236
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[015/030] Train loss: 0.0237
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[016/030] Train loss: 0.0240
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[017/030] Train loss: 0.0241
2023-02-06 10:59:34 | Train | Epoch[536/600] Iteration[018/030] Train loss: 0.0240
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[019/030] Train loss: 0.0243
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[020/030] Train loss: 0.0245
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[023/030] Train loss: 0.0246
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[026/030] Train loss: 0.0247
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:59:35 | Train | Epoch[536/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:59:35 | Valid | Epoch[536/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 10:59:35 | Valid | Epoch[536/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:59:35 | Valid | Epoch[536/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:35 | Valid | Epoch[536/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:35 | Valid | Epoch[536/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:35 | Valid | Epoch[536/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:35 | Valid | Epoch[536/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:59:36 | Valid | Epoch[536/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:59:36 | Valid | Epoch[536/600] MIou: 0.9223072672533653
2023-02-06 10:59:36 | Valid | Epoch[536/600] Pixel Accuracy: 0.9870643615722656
2023-02-06 10:59:36 | Valid | Epoch[536/600] Mean Pixel Accuracy: 0.934367469371985
2023-02-06 10:59:36 | Stage | Epoch[536/600] Train loss:0.0250
2023-02-06 10:59:36 | Stage | Epoch[536/600] Valid loss:0.0289
2023-02-06 10:59:36 | Stage | Epoch[536/600] LR:0.0001

2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[001/030] Train loss: 0.0255
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[002/030] Train loss: 0.0263
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[003/030] Train loss: 0.0258
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[006/030] Train loss: 0.0252
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[007/030] Train loss: 0.0254
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[011/030] Train loss: 0.0253
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 10:59:36 | Train | Epoch[537/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 10:59:37 | Train | Epoch[537/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 10:59:37 | Valid | Epoch[537/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:59:37 | Valid | Epoch[537/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:59:37 | Valid | Epoch[537/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:59:38 | Valid | Epoch[537/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:59:38 | Valid | Epoch[537/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:59:38 | Valid | Epoch[537/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:38 | Valid | Epoch[537/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 10:59:38 | Valid | Epoch[537/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:59:38 | Valid | Epoch[537/600] MIou: 0.9185029403609397
2023-02-06 10:59:38 | Valid | Epoch[537/600] Pixel Accuracy: 0.9864552815755209
2023-02-06 10:59:38 | Valid | Epoch[537/600] Mean Pixel Accuracy: 0.9300572173910664
2023-02-06 10:59:38 | Stage | Epoch[537/600] Train loss:0.0250
2023-02-06 10:59:38 | Stage | Epoch[537/600] Valid loss:0.0288
2023-02-06 10:59:38 | Stage | Epoch[537/600] LR:0.0001

2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[002/030] Train loss: 0.0237
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[003/030] Train loss: 0.0246
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[007/030] Train loss: 0.0236
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[008/030] Train loss: 0.0236
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[009/030] Train loss: 0.0239
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[010/030] Train loss: 0.0236
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[011/030] Train loss: 0.0235
2023-02-06 10:59:38 | Train | Epoch[538/600] Iteration[012/030] Train loss: 0.0238
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[014/030] Train loss: 0.0243
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[015/030] Train loss: 0.0242
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[017/030] Train loss: 0.0244
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[018/030] Train loss: 0.0244
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[019/030] Train loss: 0.0244
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[020/030] Train loss: 0.0245
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[028/030] Train loss: 0.0248
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:59:39 | Train | Epoch[538/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 10:59:40 | Valid | Epoch[538/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:59:40 | Valid | Epoch[538/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:59:40 | Valid | Epoch[538/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:40 | Valid | Epoch[538/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:40 | Valid | Epoch[538/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:59:40 | Valid | Epoch[538/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:40 | Valid | Epoch[538/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:59:40 | Valid | Epoch[538/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:59:40 | Valid | Epoch[538/600] MIou: 0.9205822105167597
2023-02-06 10:59:40 | Valid | Epoch[538/600] Pixel Accuracy: 0.9867820739746094
2023-02-06 10:59:40 | Valid | Epoch[538/600] Mean Pixel Accuracy: 0.93260183230497
2023-02-06 10:59:40 | Stage | Epoch[538/600] Train loss:0.0249
2023-02-06 10:59:40 | Stage | Epoch[538/600] Valid loss:0.0289
2023-02-06 10:59:40 | Stage | Epoch[538/600] LR:0.0001

2023-02-06 10:59:40 | Train | Epoch[539/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 10:59:40 | Train | Epoch[539/600] Iteration[002/030] Train loss: 0.0230
2023-02-06 10:59:40 | Train | Epoch[539/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 10:59:40 | Train | Epoch[539/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 10:59:40 | Train | Epoch[539/600] Iteration[005/030] Train loss: 0.0245
2023-02-06 10:59:40 | Train | Epoch[539/600] Iteration[006/030] Train loss: 0.0248
2023-02-06 10:59:40 | Train | Epoch[539/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[013/030] Train loss: 0.0258
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:59:41 | Train | Epoch[539/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:59:42 | Valid | Epoch[539/600] Iteration[001/008] Valid loss: 0.0345
2023-02-06 10:59:42 | Valid | Epoch[539/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 10:59:42 | Valid | Epoch[539/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:42 | Valid | Epoch[539/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:42 | Valid | Epoch[539/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:42 | Valid | Epoch[539/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 10:59:42 | Valid | Epoch[539/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 10:59:42 | Valid | Epoch[539/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 10:59:42 | Valid | Epoch[539/600] MIou: 0.9233595272390647
2023-02-06 10:59:42 | Valid | Epoch[539/600] Pixel Accuracy: 0.9872220357259115
2023-02-06 10:59:42 | Valid | Epoch[539/600] Mean Pixel Accuracy: 0.9359441446168075
2023-02-06 10:59:42 | Stage | Epoch[539/600] Train loss:0.0253
2023-02-06 10:59:42 | Stage | Epoch[539/600] Valid loss:0.0290
2023-02-06 10:59:42 | Stage | Epoch[539/600] LR:0.0001

2023-02-06 10:59:42 | Train | Epoch[540/600] Iteration[001/030] Train loss: 0.0213
2023-02-06 10:59:42 | Train | Epoch[540/600] Iteration[002/030] Train loss: 0.0244
2023-02-06 10:59:42 | Train | Epoch[540/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 10:59:42 | Train | Epoch[540/600] Iteration[004/030] Train loss: 0.0245
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[006/030] Train loss: 0.0241
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[008/030] Train loss: 0.0239
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[010/030] Train loss: 0.0240
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[012/030] Train loss: 0.0241
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[013/030] Train loss: 0.0240
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[014/030] Train loss: 0.0245
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[015/030] Train loss: 0.0241
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[016/030] Train loss: 0.0241
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[017/030] Train loss: 0.0242
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[018/030] Train loss: 0.0243
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[020/030] Train loss: 0.0245
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[025/030] Train loss: 0.0246
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[026/030] Train loss: 0.0245
2023-02-06 10:59:43 | Train | Epoch[540/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 10:59:44 | Train | Epoch[540/600] Iteration[028/030] Train loss: 0.0246
2023-02-06 10:59:44 | Train | Epoch[540/600] Iteration[029/030] Train loss: 0.0248
2023-02-06 10:59:44 | Train | Epoch[540/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 10:59:44 | Valid | Epoch[540/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:59:44 | Valid | Epoch[540/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:59:44 | Valid | Epoch[540/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:59:44 | Valid | Epoch[540/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:59:44 | Valid | Epoch[540/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:44 | Valid | Epoch[540/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 10:59:44 | Valid | Epoch[540/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 10:59:44 | Valid | Epoch[540/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:59:44 | Valid | Epoch[540/600] MIou: 0.9177176137731234
2023-02-06 10:59:44 | Valid | Epoch[540/600] Pixel Accuracy: 0.9863293965657552
2023-02-06 10:59:44 | Valid | Epoch[540/600] Mean Pixel Accuracy: 0.9291827857387993
2023-02-06 10:59:44 | Stage | Epoch[540/600] Train loss:0.0249
2023-02-06 10:59:44 | Stage | Epoch[540/600] Valid loss:0.0288
2023-02-06 10:59:44 | Stage | Epoch[540/600] LR:0.0001

2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[003/030] Train loss: 0.0229
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[005/030] Train loss: 0.0246
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[006/030] Train loss: 0.0248
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 10:59:45 | Train | Epoch[541/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 10:59:46 | Train | Epoch[541/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 10:59:46 | Train | Epoch[541/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 10:59:46 | Train | Epoch[541/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:59:46 | Train | Epoch[541/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:59:46 | Train | Epoch[541/600] Iteration[028/030] Train loss: 0.0248
2023-02-06 10:59:46 | Train | Epoch[541/600] Iteration[029/030] Train loss: 0.0248
2023-02-06 10:59:46 | Train | Epoch[541/600] Iteration[030/030] Train loss: 0.0247
2023-02-06 10:59:46 | Valid | Epoch[541/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:59:46 | Valid | Epoch[541/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:59:46 | Valid | Epoch[541/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:46 | Valid | Epoch[541/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:46 | Valid | Epoch[541/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:46 | Valid | Epoch[541/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:46 | Valid | Epoch[541/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:59:46 | Valid | Epoch[541/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:59:46 | Valid | Epoch[541/600] MIou: 0.9199283020070319
2023-02-06 10:59:46 | Valid | Epoch[541/600] Pixel Accuracy: 0.9866816202799479
2023-02-06 10:59:46 | Valid | Epoch[541/600] Mean Pixel Accuracy: 0.9317223573735671
2023-02-06 10:59:46 | Stage | Epoch[541/600] Train loss:0.0247
2023-02-06 10:59:46 | Stage | Epoch[541/600] Valid loss:0.0289
2023-02-06 10:59:46 | Stage | Epoch[541/600] LR:0.0001

2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[001/030] Train loss: 0.0278
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[002/030] Train loss: 0.0245
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[004/030] Train loss: 0.0254
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[006/030] Train loss: 0.0248
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[009/030] Train loss: 0.0246
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[016/030] Train loss: 0.0254
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 10:59:47 | Train | Epoch[542/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 10:59:48 | Train | Epoch[542/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 10:59:48 | Train | Epoch[542/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 10:59:48 | Train | Epoch[542/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 10:59:48 | Train | Epoch[542/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 10:59:48 | Train | Epoch[542/600] Iteration[025/030] Train loss: 0.0247
2023-02-06 10:59:48 | Train | Epoch[542/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 10:59:48 | Train | Epoch[542/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:59:48 | Train | Epoch[542/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:59:48 | Train | Epoch[542/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 10:59:48 | Train | Epoch[542/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:59:48 | Valid | Epoch[542/600] Iteration[001/008] Valid loss: 0.0349
2023-02-06 10:59:48 | Valid | Epoch[542/600] Iteration[002/008] Valid loss: 0.0303
2023-02-06 10:59:48 | Valid | Epoch[542/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:59:48 | Valid | Epoch[542/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:59:48 | Valid | Epoch[542/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:59:48 | Valid | Epoch[542/600] Iteration[006/008] Valid loss: 0.0293
2023-02-06 10:59:48 | Valid | Epoch[542/600] Iteration[007/008] Valid loss: 0.0295
2023-02-06 10:59:48 | Valid | Epoch[542/600] Iteration[008/008] Valid loss: 0.0292
2023-02-06 10:59:48 | Valid | Epoch[542/600] MIou: 0.9258076145351462
2023-02-06 10:59:48 | Valid | Epoch[542/600] Pixel Accuracy: 0.9876136779785156
2023-02-06 10:59:48 | Valid | Epoch[542/600] Mean Pixel Accuracy: 0.9388097249940262
2023-02-06 10:59:48 | Stage | Epoch[542/600] Train loss:0.0253
2023-02-06 10:59:48 | Stage | Epoch[542/600] Valid loss:0.0292
2023-02-06 10:59:48 | Stage | Epoch[542/600] LR:0.0001

2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[001/030] Train loss: 0.0241
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[002/030] Train loss: 0.0240
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[003/030] Train loss: 0.0242
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[005/030] Train loss: 0.0253
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:59:49 | Train | Epoch[543/600] Iteration[019/030] Train loss: 0.0258
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[021/030] Train loss: 0.0256
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 10:59:50 | Train | Epoch[543/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 10:59:50 | Valid | Epoch[543/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:59:50 | Valid | Epoch[543/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:59:50 | Valid | Epoch[543/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:59:50 | Valid | Epoch[543/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:59:50 | Valid | Epoch[543/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:59:50 | Valid | Epoch[543/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 10:59:50 | Valid | Epoch[543/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 10:59:50 | Valid | Epoch[543/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:59:51 | Valid | Epoch[543/600] MIou: 0.9172521264406028
2023-02-06 10:59:51 | Valid | Epoch[543/600] Pixel Accuracy: 0.9862543741861979
2023-02-06 10:59:51 | Valid | Epoch[543/600] Mean Pixel Accuracy: 0.9286786958189857
2023-02-06 10:59:51 | Stage | Epoch[543/600] Train loss:0.0249
2023-02-06 10:59:51 | Stage | Epoch[543/600] Valid loss:0.0288
2023-02-06 10:59:51 | Stage | Epoch[543/600] LR:0.0001

2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[001/030] Train loss: 0.0259
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[002/030] Train loss: 0.0259
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[003/030] Train loss: 0.0275
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[005/030] Train loss: 0.0266
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[006/030] Train loss: 0.0266
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[007/030] Train loss: 0.0269
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[009/030] Train loss: 0.0261
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 10:59:51 | Train | Epoch[544/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[026/030] Train loss: 0.0247
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:59:52 | Train | Epoch[544/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 10:59:52 | Valid | Epoch[544/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:59:52 | Valid | Epoch[544/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:59:52 | Valid | Epoch[544/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:59:52 | Valid | Epoch[544/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:59:52 | Valid | Epoch[544/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:52 | Valid | Epoch[544/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 10:59:53 | Valid | Epoch[544/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 10:59:53 | Valid | Epoch[544/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:59:53 | Valid | Epoch[544/600] MIou: 0.9180362736319847
2023-02-06 10:59:53 | Valid | Epoch[544/600] Pixel Accuracy: 0.9863789876302084
2023-02-06 10:59:53 | Valid | Epoch[544/600] Mean Pixel Accuracy: 0.9295841309220432
2023-02-06 10:59:53 | Stage | Epoch[544/600] Train loss:0.0249
2023-02-06 10:59:53 | Stage | Epoch[544/600] Valid loss:0.0288
2023-02-06 10:59:53 | Stage | Epoch[544/600] LR:0.0001

2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[002/030] Train loss: 0.0211
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[003/030] Train loss: 0.0220
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[004/030] Train loss: 0.0227
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[005/030] Train loss: 0.0227
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[006/030] Train loss: 0.0234
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[007/030] Train loss: 0.0240
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[009/030] Train loss: 0.0246
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[012/030] Train loss: 0.0247
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 10:59:53 | Train | Epoch[545/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 10:59:54 | Train | Epoch[545/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:59:54 | Valid | Epoch[545/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 10:59:54 | Valid | Epoch[545/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 10:59:54 | Valid | Epoch[545/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 10:59:54 | Valid | Epoch[545/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 10:59:55 | Valid | Epoch[545/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:55 | Valid | Epoch[545/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 10:59:55 | Valid | Epoch[545/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 10:59:55 | Valid | Epoch[545/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 10:59:55 | Valid | Epoch[545/600] MIou: 0.9178235881271803
2023-02-06 10:59:55 | Valid | Epoch[545/600] Pixel Accuracy: 0.9863471984863281
2023-02-06 10:59:55 | Valid | Epoch[545/600] Mean Pixel Accuracy: 0.9292749965632368
2023-02-06 10:59:55 | Stage | Epoch[545/600] Train loss:0.0251
2023-02-06 10:59:55 | Stage | Epoch[545/600] Valid loss:0.0288
2023-02-06 10:59:55 | Stage | Epoch[545/600] LR:0.0001

2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[001/030] Train loss: 0.0246
2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[004/030] Train loss: 0.0250
2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[005/030] Train loss: 0.0261
2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[006/030] Train loss: 0.0261
2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[007/030] Train loss: 0.0261
2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 10:59:55 | Train | Epoch[546/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 10:59:56 | Train | Epoch[546/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 10:59:57 | Valid | Epoch[546/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 10:59:57 | Valid | Epoch[546/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 10:59:57 | Valid | Epoch[546/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:57 | Valid | Epoch[546/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:57 | Valid | Epoch[546/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 10:59:57 | Valid | Epoch[546/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 10:59:57 | Valid | Epoch[546/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 10:59:57 | Valid | Epoch[546/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 10:59:57 | Valid | Epoch[546/600] MIou: 0.9196542023598882
2023-02-06 10:59:57 | Valid | Epoch[546/600] Pixel Accuracy: 0.986639658610026
2023-02-06 10:59:57 | Valid | Epoch[546/600] Mean Pixel Accuracy: 0.9313505675169917
2023-02-06 10:59:57 | Stage | Epoch[546/600] Train loss:0.0253
2023-02-06 10:59:57 | Stage | Epoch[546/600] Valid loss:0.0289
2023-02-06 10:59:57 | Stage | Epoch[546/600] LR:0.0001

2023-02-06 10:59:57 | Train | Epoch[547/600] Iteration[001/030] Train loss: 0.0263
2023-02-06 10:59:57 | Train | Epoch[547/600] Iteration[002/030] Train loss: 0.0239
2023-02-06 10:59:57 | Train | Epoch[547/600] Iteration[003/030] Train loss: 0.0232
2023-02-06 10:59:57 | Train | Epoch[547/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 10:59:57 | Train | Epoch[547/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 10:59:57 | Train | Epoch[547/600] Iteration[006/030] Train loss: 0.0246
2023-02-06 10:59:57 | Train | Epoch[547/600] Iteration[007/030] Train loss: 0.0244
2023-02-06 10:59:57 | Train | Epoch[547/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[010/030] Train loss: 0.0243
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[011/030] Train loss: 0.0248
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[021/030] Train loss: 0.0245
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[023/030] Train loss: 0.0246
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[024/030] Train loss: 0.0246
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[025/030] Train loss: 0.0246
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[026/030] Train loss: 0.0246
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[028/030] Train loss: 0.0247
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[029/030] Train loss: 0.0248
2023-02-06 10:59:58 | Train | Epoch[547/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 10:59:59 | Valid | Epoch[547/600] Iteration[001/008] Valid loss: 0.0345
2023-02-06 10:59:59 | Valid | Epoch[547/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 10:59:59 | Valid | Epoch[547/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 10:59:59 | Valid | Epoch[547/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 10:59:59 | Valid | Epoch[547/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 10:59:59 | Valid | Epoch[547/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 10:59:59 | Valid | Epoch[547/600] Iteration[007/008] Valid loss: 0.0293
2023-02-06 10:59:59 | Valid | Epoch[547/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 10:59:59 | Valid | Epoch[547/600] MIou: 0.9231840325017754
2023-02-06 10:59:59 | Valid | Epoch[547/600] Pixel Accuracy: 0.9871991475423177
2023-02-06 10:59:59 | Valid | Epoch[547/600] Mean Pixel Accuracy: 0.9355638169472463
2023-02-06 10:59:59 | Stage | Epoch[547/600] Train loss:0.0251
2023-02-06 10:59:59 | Stage | Epoch[547/600] Valid loss:0.0291
2023-02-06 10:59:59 | Stage | Epoch[547/600] LR:0.0001

2023-02-06 10:59:59 | Train | Epoch[548/600] Iteration[001/030] Train loss: 0.0277
2023-02-06 10:59:59 | Train | Epoch[548/600] Iteration[002/030] Train loss: 0.0258
2023-02-06 10:59:59 | Train | Epoch[548/600] Iteration[003/030] Train loss: 0.0265
2023-02-06 10:59:59 | Train | Epoch[548/600] Iteration[004/030] Train loss: 0.0264
2023-02-06 10:59:59 | Train | Epoch[548/600] Iteration[005/030] Train loss: 0.0273
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[006/030] Train loss: 0.0270
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[007/030] Train loss: 0.0259
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[008/030] Train loss: 0.0257
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 11:00:00 | Train | Epoch[548/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:00:01 | Train | Epoch[548/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 11:00:01 | Train | Epoch[548/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 11:00:01 | Valid | Epoch[548/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 11:00:01 | Valid | Epoch[548/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:01 | Valid | Epoch[548/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:01 | Valid | Epoch[548/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:01 | Valid | Epoch[548/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:01 | Valid | Epoch[548/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:01 | Valid | Epoch[548/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 11:00:01 | Valid | Epoch[548/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:01 | Valid | Epoch[548/600] MIou: 0.9226034051622968
2023-02-06 11:00:01 | Valid | Epoch[548/600] Pixel Accuracy: 0.9871075948079427
2023-02-06 11:00:01 | Valid | Epoch[548/600] Mean Pixel Accuracy: 0.9348477461510358
2023-02-06 11:00:01 | Stage | Epoch[548/600] Train loss:0.0250
2023-02-06 11:00:01 | Stage | Epoch[548/600] Valid loss:0.0289
2023-02-06 11:00:01 | Stage | Epoch[548/600] LR:0.0001

2023-02-06 11:00:01 | Train | Epoch[549/600] Iteration[001/030] Train loss: 0.0266
2023-02-06 11:00:01 | Train | Epoch[549/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[004/030] Train loss: 0.0245
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[005/030] Train loss: 0.0238
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[006/030] Train loss: 0.0238
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[007/030] Train loss: 0.0238
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[010/030] Train loss: 0.0242
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[015/030] Train loss: 0.0245
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[017/030] Train loss: 0.0244
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[018/030] Train loss: 0.0245
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[019/030] Train loss: 0.0244
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[020/030] Train loss: 0.0244
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[021/030] Train loss: 0.0245
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[022/030] Train loss: 0.0245
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[023/030] Train loss: 0.0245
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[024/030] Train loss: 0.0245
2023-02-06 11:00:02 | Train | Epoch[549/600] Iteration[025/030] Train loss: 0.0247
2023-02-06 11:00:03 | Train | Epoch[549/600] Iteration[026/030] Train loss: 0.0247
2023-02-06 11:00:03 | Train | Epoch[549/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 11:00:03 | Train | Epoch[549/600] Iteration[028/030] Train loss: 0.0248
2023-02-06 11:00:03 | Train | Epoch[549/600] Iteration[029/030] Train loss: 0.0248
2023-02-06 11:00:03 | Train | Epoch[549/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 11:00:03 | Valid | Epoch[549/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 11:00:03 | Valid | Epoch[549/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:03 | Valid | Epoch[549/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:03 | Valid | Epoch[549/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:03 | Valid | Epoch[549/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:03 | Valid | Epoch[549/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:03 | Valid | Epoch[549/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:03 | Valid | Epoch[549/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:03 | Valid | Epoch[549/600] MIou: 0.9211325706146529
2023-02-06 11:00:03 | Valid | Epoch[549/600] Pixel Accuracy: 0.9868736267089844
2023-02-06 11:00:03 | Valid | Epoch[549/600] Mean Pixel Accuracy: 0.9331150080127939
2023-02-06 11:00:03 | Stage | Epoch[549/600] Train loss:0.0249
2023-02-06 11:00:03 | Stage | Epoch[549/600] Valid loss:0.0289
2023-02-06 11:00:03 | Stage | Epoch[549/600] LR:0.0001

2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[001/030] Train loss: 0.0275
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[002/030] Train loss: 0.0252
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[005/030] Train loss: 0.0253
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[006/030] Train loss: 0.0253
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[012/030] Train loss: 0.0247
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[015/030] Train loss: 0.0244
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[016/030] Train loss: 0.0244
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[017/030] Train loss: 0.0244
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[018/030] Train loss: 0.0246
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:00:04 | Train | Epoch[550/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 11:00:05 | Train | Epoch[550/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:00:05 | Train | Epoch[550/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 11:00:05 | Train | Epoch[550/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 11:00:05 | Train | Epoch[550/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 11:00:05 | Train | Epoch[550/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:00:05 | Train | Epoch[550/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:00:05 | Train | Epoch[550/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 11:00:05 | Train | Epoch[550/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:00:05 | Train | Epoch[550/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 11:00:05 | Valid | Epoch[550/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 11:00:05 | Valid | Epoch[550/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:05 | Valid | Epoch[550/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:05 | Valid | Epoch[550/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:05 | Valid | Epoch[550/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 11:00:05 | Valid | Epoch[550/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:05 | Valid | Epoch[550/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:05 | Valid | Epoch[550/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:05 | Valid | Epoch[550/600] MIou: 0.9204438283287875
2023-02-06 11:00:05 | Valid | Epoch[550/600] Pixel Accuracy: 0.9867668151855469
2023-02-06 11:00:05 | Valid | Epoch[550/600] Mean Pixel Accuracy: 0.9322193576045169
2023-02-06 11:00:05 | Stage | Epoch[550/600] Train loss:0.0249
2023-02-06 11:00:05 | Stage | Epoch[550/600] Valid loss:0.0288
2023-02-06 11:00:05 | Stage | Epoch[550/600] LR:0.0001

2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[001/030] Train loss: 0.0232
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[003/030] Train loss: 0.0251
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[005/030] Train loss: 0.0245
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[007/030] Train loss: 0.0244
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[010/030] Train loss: 0.0248
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 11:00:06 | Train | Epoch[551/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:00:07 | Train | Epoch[551/600] Iteration[030/030] Train loss: 0.0248
2023-02-06 11:00:07 | Valid | Epoch[551/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 11:00:07 | Valid | Epoch[551/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:00:07 | Valid | Epoch[551/600] Iteration[003/008] Valid loss: 0.0293
2023-02-06 11:00:07 | Valid | Epoch[551/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:07 | Valid | Epoch[551/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 11:00:07 | Valid | Epoch[551/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:00:07 | Valid | Epoch[551/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:07 | Valid | Epoch[551/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:08 | Valid | Epoch[551/600] MIou: 0.9213299700779002
2023-02-06 11:00:08 | Valid | Epoch[551/600] Pixel Accuracy: 0.9869066874186198
2023-02-06 11:00:08 | Valid | Epoch[551/600] Mean Pixel Accuracy: 0.9332916913766167
2023-02-06 11:00:08 | Stage | Epoch[551/600] Train loss:0.0248
2023-02-06 11:00:08 | Stage | Epoch[551/600] Valid loss:0.0288
2023-02-06 11:00:08 | Stage | Epoch[551/600] LR:0.0001

2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[002/030] Train loss: 0.0243
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[005/030] Train loss: 0.0233
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[006/030] Train loss: 0.0237
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[007/030] Train loss: 0.0237
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[008/030] Train loss: 0.0234
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[009/030] Train loss: 0.0235
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[010/030] Train loss: 0.0235
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[011/030] Train loss: 0.0237
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[012/030] Train loss: 0.0239
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 11:00:08 | Train | Epoch[552/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 11:00:09 | Train | Epoch[552/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 11:00:09 | Valid | Epoch[552/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:00:09 | Valid | Epoch[552/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:09 | Valid | Epoch[552/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 11:00:09 | Valid | Epoch[552/600] Iteration[004/008] Valid loss: 0.0285
2023-02-06 11:00:10 | Valid | Epoch[552/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:10 | Valid | Epoch[552/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:10 | Valid | Epoch[552/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 11:00:10 | Valid | Epoch[552/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:10 | Valid | Epoch[552/600] MIou: 0.9169380073134397
2023-02-06 11:00:10 | Valid | Epoch[552/600] Pixel Accuracy: 0.9862035115559896
2023-02-06 11:00:10 | Valid | Epoch[552/600] Mean Pixel Accuracy: 0.9283463969156046
2023-02-06 11:00:10 | Stage | Epoch[552/600] Train loss:0.0253
2023-02-06 11:00:10 | Stage | Epoch[552/600] Valid loss:0.0288
2023-02-06 11:00:10 | Stage | Epoch[552/600] LR:0.0001

2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[001/030] Train loss: 0.0258
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[004/030] Train loss: 0.0261
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[005/030] Train loss: 0.0272
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[006/030] Train loss: 0.0263
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[007/030] Train loss: 0.0261
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[008/030] Train loss: 0.0266
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[009/030] Train loss: 0.0260
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 11:00:10 | Train | Epoch[553/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[019/030] Train loss: 0.0253
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[028/030] Train loss: 0.0248
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:00:11 | Train | Epoch[553/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:00:12 | Valid | Epoch[553/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 11:00:12 | Valid | Epoch[553/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:00:12 | Valid | Epoch[553/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:12 | Valid | Epoch[553/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:12 | Valid | Epoch[553/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 11:00:12 | Valid | Epoch[553/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 11:00:12 | Valid | Epoch[553/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 11:00:12 | Valid | Epoch[553/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 11:00:12 | Valid | Epoch[553/600] MIou: 0.921551628759119
2023-02-06 11:00:12 | Valid | Epoch[553/600] Pixel Accuracy: 0.9869359334309896
2023-02-06 11:00:12 | Valid | Epoch[553/600] Mean Pixel Accuracy: 0.9337515992381731
2023-02-06 11:00:12 | Stage | Epoch[553/600] Train loss:0.0252
2023-02-06 11:00:12 | Stage | Epoch[553/600] Valid loss:0.0290
2023-02-06 11:00:12 | Stage | Epoch[553/600] LR:0.0001

2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[001/030] Train loss: 0.0253
2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[002/030] Train loss: 0.0245
2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[005/030] Train loss: 0.0243
2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[010/030] Train loss: 0.0247
2023-02-06 11:00:12 | Train | Epoch[554/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 11:00:13 | Train | Epoch[554/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:00:14 | Valid | Epoch[554/600] Iteration[001/008] Valid loss: 0.0347
2023-02-06 11:00:14 | Valid | Epoch[554/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 11:00:14 | Valid | Epoch[554/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:14 | Valid | Epoch[554/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:14 | Valid | Epoch[554/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:14 | Valid | Epoch[554/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 11:00:14 | Valid | Epoch[554/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 11:00:14 | Valid | Epoch[554/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 11:00:14 | Valid | Epoch[554/600] MIou: 0.924332474505572
2023-02-06 11:00:14 | Valid | Epoch[554/600] Pixel Accuracy: 0.9873809814453125
2023-02-06 11:00:14 | Valid | Epoch[554/600] Mean Pixel Accuracy: 0.936963557275337
2023-02-06 11:00:14 | Stage | Epoch[554/600] Train loss:0.0252
2023-02-06 11:00:14 | Stage | Epoch[554/600] Valid loss:0.0290
2023-02-06 11:00:14 | Stage | Epoch[554/600] LR:0.0001

2023-02-06 11:00:14 | Train | Epoch[555/600] Iteration[001/030] Train loss: 0.0286
2023-02-06 11:00:14 | Train | Epoch[555/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 11:00:14 | Train | Epoch[555/600] Iteration[003/030] Train loss: 0.0240
2023-02-06 11:00:14 | Train | Epoch[555/600] Iteration[004/030] Train loss: 0.0243
2023-02-06 11:00:14 | Train | Epoch[555/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 11:00:14 | Train | Epoch[555/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 11:00:14 | Train | Epoch[555/600] Iteration[007/030] Train loss: 0.0254
2023-02-06 11:00:14 | Train | Epoch[555/600] Iteration[008/030] Train loss: 0.0259
2023-02-06 11:00:14 | Train | Epoch[555/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[012/030] Train loss: 0.0247
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[013/030] Train loss: 0.0245
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[022/030] Train loss: 0.0247
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:00:15 | Train | Epoch[555/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:00:16 | Valid | Epoch[555/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:00:16 | Valid | Epoch[555/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:00:16 | Valid | Epoch[555/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:16 | Valid | Epoch[555/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:16 | Valid | Epoch[555/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:16 | Valid | Epoch[555/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:16 | Valid | Epoch[555/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:16 | Valid | Epoch[555/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:16 | Valid | Epoch[555/600] MIou: 0.9201537154358612
2023-02-06 11:00:16 | Valid | Epoch[555/600] Pixel Accuracy: 0.986718495686849
2023-02-06 11:00:16 | Valid | Epoch[555/600] Mean Pixel Accuracy: 0.9319518612297968
2023-02-06 11:00:16 | Stage | Epoch[555/600] Train loss:0.0251
2023-02-06 11:00:16 | Stage | Epoch[555/600] Valid loss:0.0289
2023-02-06 11:00:16 | Stage | Epoch[555/600] LR:0.0001

2023-02-06 11:00:16 | Train | Epoch[556/600] Iteration[001/030] Train loss: 0.0237
2023-02-06 11:00:16 | Train | Epoch[556/600] Iteration[002/030] Train loss: 0.0259
2023-02-06 11:00:16 | Train | Epoch[556/600] Iteration[003/030] Train loss: 0.0262
2023-02-06 11:00:16 | Train | Epoch[556/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 11:00:16 | Train | Epoch[556/600] Iteration[005/030] Train loss: 0.0242
2023-02-06 11:00:16 | Train | Epoch[556/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 11:00:16 | Train | Epoch[556/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[017/030] Train loss: 0.0260
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[018/030] Train loss: 0.0261
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[019/030] Train loss: 0.0259
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[020/030] Train loss: 0.0260
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[021/030] Train loss: 0.0260
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[023/030] Train loss: 0.0258
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:00:17 | Train | Epoch[556/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:00:18 | Valid | Epoch[556/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 11:00:18 | Valid | Epoch[556/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:18 | Valid | Epoch[556/600] Iteration[003/008] Valid loss: 0.0293
2023-02-06 11:00:18 | Valid | Epoch[556/600] Iteration[004/008] Valid loss: 0.0282
2023-02-06 11:00:18 | Valid | Epoch[556/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 11:00:18 | Valid | Epoch[556/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:18 | Valid | Epoch[556/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:18 | Valid | Epoch[556/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:18 | Valid | Epoch[556/600] MIou: 0.9224783816858422
2023-02-06 11:00:18 | Valid | Epoch[556/600] Pixel Accuracy: 0.9870885213216146
2023-02-06 11:00:18 | Valid | Epoch[556/600] Mean Pixel Accuracy: 0.9346724102901712
2023-02-06 11:00:18 | Stage | Epoch[556/600] Train loss:0.0252
2023-02-06 11:00:18 | Stage | Epoch[556/600] Valid loss:0.0289
2023-02-06 11:00:18 | Stage | Epoch[556/600] LR:0.0001

2023-02-06 11:00:18 | Train | Epoch[557/600] Iteration[001/030] Train loss: 0.0247
2023-02-06 11:00:18 | Train | Epoch[557/600] Iteration[002/030] Train loss: 0.0253
2023-02-06 11:00:18 | Train | Epoch[557/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 11:00:18 | Train | Epoch[557/600] Iteration[004/030] Train loss: 0.0257
2023-02-06 11:00:18 | Train | Epoch[557/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 11:00:18 | Train | Epoch[557/600] Iteration[006/030] Train loss: 0.0257
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[007/030] Train loss: 0.0271
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[008/030] Train loss: 0.0269
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[009/030] Train loss: 0.0263
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[010/030] Train loss: 0.0266
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[011/030] Train loss: 0.0267
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[012/030] Train loss: 0.0265
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[014/030] Train loss: 0.0261
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[015/030] Train loss: 0.0260
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 11:00:19 | Train | Epoch[557/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:00:20 | Valid | Epoch[557/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 11:00:20 | Valid | Epoch[557/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:20 | Valid | Epoch[557/600] Iteration[003/008] Valid loss: 0.0296
2023-02-06 11:00:20 | Valid | Epoch[557/600] Iteration[004/008] Valid loss: 0.0285
2023-02-06 11:00:20 | Valid | Epoch[557/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 11:00:20 | Valid | Epoch[557/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:20 | Valid | Epoch[557/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 11:00:20 | Valid | Epoch[557/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:20 | Valid | Epoch[557/600] MIou: 0.9160836229983227
2023-02-06 11:00:20 | Valid | Epoch[557/600] Pixel Accuracy: 0.9860649108886719
2023-02-06 11:00:20 | Valid | Epoch[557/600] Mean Pixel Accuracy: 0.927452295252613
2023-02-06 11:00:20 | Stage | Epoch[557/600] Train loss:0.0252
2023-02-06 11:00:20 | Stage | Epoch[557/600] Valid loss:0.0288
2023-02-06 11:00:20 | Stage | Epoch[557/600] LR:0.0001

2023-02-06 11:00:20 | Train | Epoch[558/600] Iteration[001/030] Train loss: 0.0278
2023-02-06 11:00:20 | Train | Epoch[558/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 11:00:20 | Train | Epoch[558/600] Iteration[003/030] Train loss: 0.0248
2023-02-06 11:00:20 | Train | Epoch[558/600] Iteration[004/030] Train loss: 0.0253
2023-02-06 11:00:20 | Train | Epoch[558/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[008/030] Train loss: 0.0235
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[009/030] Train loss: 0.0241
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[011/030] Train loss: 0.0239
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[012/030] Train loss: 0.0239
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[013/030] Train loss: 0.0241
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[014/030] Train loss: 0.0243
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 11:00:21 | Train | Epoch[558/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 11:00:22 | Train | Epoch[558/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:00:22 | Train | Epoch[558/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:00:22 | Valid | Epoch[558/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:00:22 | Valid | Epoch[558/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:00:22 | Valid | Epoch[558/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 11:00:22 | Valid | Epoch[558/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:00:22 | Valid | Epoch[558/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:22 | Valid | Epoch[558/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:00:22 | Valid | Epoch[558/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 11:00:22 | Valid | Epoch[558/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:22 | Valid | Epoch[558/600] MIou: 0.9183913261042836
2023-02-06 11:00:22 | Valid | Epoch[558/600] Pixel Accuracy: 0.9864387512207031
2023-02-06 11:00:22 | Valid | Epoch[558/600] Mean Pixel Accuracy: 0.929889619815254
2023-02-06 11:00:22 | Stage | Epoch[558/600] Train loss:0.0251
2023-02-06 11:00:22 | Stage | Epoch[558/600] Valid loss:0.0288
2023-02-06 11:00:22 | Stage | Epoch[558/600] LR:0.0001

2023-02-06 11:00:22 | Train | Epoch[559/600] Iteration[001/030] Train loss: 0.0248
2023-02-06 11:00:22 | Train | Epoch[559/600] Iteration[002/030] Train loss: 0.0249
2023-02-06 11:00:22 | Train | Epoch[559/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[004/030] Train loss: 0.0261
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[005/030] Train loss: 0.0259
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[006/030] Train loss: 0.0260
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[008/030] Train loss: 0.0247
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[009/030] Train loss: 0.0241
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[010/030] Train loss: 0.0242
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[012/030] Train loss: 0.0244
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[017/030] Train loss: 0.0246
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[018/030] Train loss: 0.0245
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[019/030] Train loss: 0.0244
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[020/030] Train loss: 0.0243
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[022/030] Train loss: 0.0247
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[023/030] Train loss: 0.0245
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[024/030] Train loss: 0.0246
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[025/030] Train loss: 0.0246
2023-02-06 11:00:23 | Train | Epoch[559/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 11:00:24 | Train | Epoch[559/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 11:00:24 | Train | Epoch[559/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:00:24 | Train | Epoch[559/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 11:00:24 | Train | Epoch[559/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 11:00:24 | Valid | Epoch[559/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:00:24 | Valid | Epoch[559/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:00:24 | Valid | Epoch[559/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:24 | Valid | Epoch[559/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:24 | Valid | Epoch[559/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:24 | Valid | Epoch[559/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:24 | Valid | Epoch[559/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:00:24 | Valid | Epoch[559/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:24 | Valid | Epoch[559/600] MIou: 0.9195616998891964
2023-02-06 11:00:24 | Valid | Epoch[559/600] Pixel Accuracy: 0.986626942952474
2023-02-06 11:00:24 | Valid | Epoch[559/600] Mean Pixel Accuracy: 0.9311787261899774
2023-02-06 11:00:24 | Stage | Epoch[559/600] Train loss:0.0250
2023-02-06 11:00:24 | Stage | Epoch[559/600] Valid loss:0.0288
2023-02-06 11:00:24 | Stage | Epoch[559/600] LR:0.0001

2023-02-06 11:00:24 | Train | Epoch[560/600] Iteration[001/030] Train loss: 0.0312
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[002/030] Train loss: 0.0278
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[003/030] Train loss: 0.0263
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[004/030] Train loss: 0.0254
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[005/030] Train loss: 0.0251
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[006/030] Train loss: 0.0239
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[007/030] Train loss: 0.0244
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[010/030] Train loss: 0.0243
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 11:00:25 | Train | Epoch[560/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:00:26 | Train | Epoch[560/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 11:00:26 | Train | Epoch[560/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:00:26 | Train | Epoch[560/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:00:26 | Train | Epoch[560/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:00:26 | Train | Epoch[560/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:00:26 | Train | Epoch[560/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:00:26 | Train | Epoch[560/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 11:00:26 | Valid | Epoch[560/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 11:00:26 | Valid | Epoch[560/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:00:26 | Valid | Epoch[560/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:26 | Valid | Epoch[560/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:26 | Valid | Epoch[560/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:26 | Valid | Epoch[560/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 11:00:26 | Valid | Epoch[560/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 11:00:26 | Valid | Epoch[560/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 11:00:26 | Valid | Epoch[560/600] MIou: 0.9226942570111418
2023-02-06 11:00:26 | Valid | Epoch[560/600] Pixel Accuracy: 0.9871190388997396
2023-02-06 11:00:26 | Valid | Epoch[560/600] Mean Pixel Accuracy: 0.9350569314003525
2023-02-06 11:00:26 | Stage | Epoch[560/600] Train loss:0.0250
2023-02-06 11:00:26 | Stage | Epoch[560/600] Valid loss:0.0290
2023-02-06 11:00:26 | Stage | Epoch[560/600] LR:0.0001

2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[001/030] Train loss: 0.0289
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[002/030] Train loss: 0.0255
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[004/030] Train loss: 0.0267
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[005/030] Train loss: 0.0264
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[006/030] Train loss: 0.0266
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[007/030] Train loss: 0.0264
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[011/030] Train loss: 0.0254
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[012/030] Train loss: 0.0255
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[013/030] Train loss: 0.0253
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 11:00:27 | Train | Epoch[561/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 11:00:28 | Train | Epoch[561/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:00:28 | Train | Epoch[561/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:00:28 | Train | Epoch[561/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 11:00:28 | Train | Epoch[561/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 11:00:28 | Train | Epoch[561/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 11:00:28 | Train | Epoch[561/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 11:00:28 | Train | Epoch[561/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 11:00:28 | Train | Epoch[561/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 11:00:28 | Train | Epoch[561/600] Iteration[030/030] Train loss: 0.0248
2023-02-06 11:00:28 | Valid | Epoch[561/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 11:00:28 | Valid | Epoch[561/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:28 | Valid | Epoch[561/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:28 | Valid | Epoch[561/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:28 | Valid | Epoch[561/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 11:00:28 | Valid | Epoch[561/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:28 | Valid | Epoch[561/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:28 | Valid | Epoch[561/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:28 | Valid | Epoch[561/600] MIou: 0.9216874887715283
2023-02-06 11:00:28 | Valid | Epoch[561/600] Pixel Accuracy: 0.9869613647460938
2023-02-06 11:00:28 | Valid | Epoch[561/600] Mean Pixel Accuracy: 0.9337845987881099
2023-02-06 11:00:28 | Stage | Epoch[561/600] Train loss:0.0248
2023-02-06 11:00:28 | Stage | Epoch[561/600] Valid loss:0.0289
2023-02-06 11:00:28 | Stage | Epoch[561/600] LR:0.0001

2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[004/030] Train loss: 0.0248
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[005/030] Train loss: 0.0245
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[007/030] Train loss: 0.0240
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[008/030] Train loss: 0.0241
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[009/030] Train loss: 0.0241
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[012/030] Train loss: 0.0245
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[014/030] Train loss: 0.0246
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 11:00:29 | Train | Epoch[562/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[022/030] Train loss: 0.0247
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:00:30 | Train | Epoch[562/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:00:30 | Valid | Epoch[562/600] Iteration[001/008] Valid loss: 0.0345
2023-02-06 11:00:30 | Valid | Epoch[562/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:00:30 | Valid | Epoch[562/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:30 | Valid | Epoch[562/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:30 | Valid | Epoch[562/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:30 | Valid | Epoch[562/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:31 | Valid | Epoch[562/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 11:00:31 | Valid | Epoch[562/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:31 | Valid | Epoch[562/600] MIou: 0.9228198688881206
2023-02-06 11:00:31 | Valid | Epoch[562/600] Pixel Accuracy: 0.9871419270833334
2023-02-06 11:00:31 | Valid | Epoch[562/600] Mean Pixel Accuracy: 0.9351075545512856
2023-02-06 11:00:31 | Stage | Epoch[562/600] Train loss:0.0251
2023-02-06 11:00:31 | Stage | Epoch[562/600] Valid loss:0.0289
2023-02-06 11:00:31 | Stage | Epoch[562/600] LR:0.0001

2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[001/030] Train loss: 0.0227
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[002/030] Train loss: 0.0228
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[003/030] Train loss: 0.0233
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[004/030] Train loss: 0.0230
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[005/030] Train loss: 0.0228
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[006/030] Train loss: 0.0237
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 11:00:31 | Train | Epoch[563/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 11:00:32 | Train | Epoch[563/600] Iteration[030/030] Train loss: 0.0248
2023-02-06 11:00:32 | Valid | Epoch[563/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 11:00:32 | Valid | Epoch[563/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:00:32 | Valid | Epoch[563/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:33 | Valid | Epoch[563/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:33 | Valid | Epoch[563/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:33 | Valid | Epoch[563/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:33 | Valid | Epoch[563/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 11:00:33 | Valid | Epoch[563/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:33 | Valid | Epoch[563/600] MIou: 0.9224915607884089
2023-02-06 11:00:33 | Valid | Epoch[563/600] Pixel Accuracy: 0.9870923360188802
2023-02-06 11:00:33 | Valid | Epoch[563/600] Mean Pixel Accuracy: 0.9346301237098967
2023-02-06 11:00:33 | Stage | Epoch[563/600] Train loss:0.0248
2023-02-06 11:00:33 | Stage | Epoch[563/600] Valid loss:0.0289
2023-02-06 11:00:33 | Stage | Epoch[563/600] LR:0.0001

2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[001/030] Train loss: 0.0265
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[002/030] Train loss: 0.0266
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[005/030] Train loss: 0.0263
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[006/030] Train loss: 0.0270
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 11:00:33 | Train | Epoch[564/600] Iteration[012/030] Train loss: 0.0252
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:00:34 | Train | Epoch[564/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:00:35 | Valid | Epoch[564/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:00:35 | Valid | Epoch[564/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:00:35 | Valid | Epoch[564/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:35 | Valid | Epoch[564/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:00:35 | Valid | Epoch[564/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:35 | Valid | Epoch[564/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:00:35 | Valid | Epoch[564/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:00:35 | Valid | Epoch[564/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:35 | Valid | Epoch[564/600] MIou: 0.9191441595479212
2023-02-06 11:00:35 | Valid | Epoch[564/600] Pixel Accuracy: 0.9865582784016927
2023-02-06 11:00:35 | Valid | Epoch[564/600] Mean Pixel Accuracy: 0.930766897405183
2023-02-06 11:00:35 | Stage | Epoch[564/600] Train loss:0.0251
2023-02-06 11:00:35 | Stage | Epoch[564/600] Valid loss:0.0288
2023-02-06 11:00:35 | Stage | Epoch[564/600] LR:0.0001

2023-02-06 11:00:35 | Train | Epoch[565/600] Iteration[001/030] Train loss: 0.0254
2023-02-06 11:00:35 | Train | Epoch[565/600] Iteration[002/030] Train loss: 0.0277
2023-02-06 11:00:35 | Train | Epoch[565/600] Iteration[003/030] Train loss: 0.0276
2023-02-06 11:00:35 | Train | Epoch[565/600] Iteration[004/030] Train loss: 0.0277
2023-02-06 11:00:35 | Train | Epoch[565/600] Iteration[005/030] Train loss: 0.0271
2023-02-06 11:00:35 | Train | Epoch[565/600] Iteration[006/030] Train loss: 0.0260
2023-02-06 11:00:35 | Train | Epoch[565/600] Iteration[007/030] Train loss: 0.0262
2023-02-06 11:00:35 | Train | Epoch[565/600] Iteration[008/030] Train loss: 0.0261
2023-02-06 11:00:35 | Train | Epoch[565/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 11:00:35 | Train | Epoch[565/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[014/030] Train loss: 0.0256
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[017/030] Train loss: 0.0254
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:00:36 | Train | Epoch[565/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 11:00:37 | Valid | Epoch[565/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 11:00:37 | Valid | Epoch[565/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:00:37 | Valid | Epoch[565/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 11:00:37 | Valid | Epoch[565/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:00:37 | Valid | Epoch[565/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 11:00:37 | Valid | Epoch[565/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:00:37 | Valid | Epoch[565/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 11:00:37 | Valid | Epoch[565/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:37 | Valid | Epoch[565/600] MIou: 0.9174796383800214
2023-02-06 11:00:37 | Valid | Epoch[565/600] Pixel Accuracy: 0.9862899780273438
2023-02-06 11:00:37 | Valid | Epoch[565/600] Mean Pixel Accuracy: 0.9289582245405418
2023-02-06 11:00:37 | Stage | Epoch[565/600] Train loss:0.0250
2023-02-06 11:00:37 | Stage | Epoch[565/600] Valid loss:0.0288
2023-02-06 11:00:37 | Stage | Epoch[565/600] LR:0.0001

2023-02-06 11:00:37 | Train | Epoch[566/600] Iteration[001/030] Train loss: 0.0259
2023-02-06 11:00:37 | Train | Epoch[566/600] Iteration[002/030] Train loss: 0.0250
2023-02-06 11:00:37 | Train | Epoch[566/600] Iteration[003/030] Train loss: 0.0242
2023-02-06 11:00:37 | Train | Epoch[566/600] Iteration[004/030] Train loss: 0.0239
2023-02-06 11:00:37 | Train | Epoch[566/600] Iteration[005/030] Train loss: 0.0239
2023-02-06 11:00:37 | Train | Epoch[566/600] Iteration[006/030] Train loss: 0.0242
2023-02-06 11:00:37 | Train | Epoch[566/600] Iteration[007/030] Train loss: 0.0254
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[010/030] Train loss: 0.0258
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[012/030] Train loss: 0.0260
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[013/030] Train loss: 0.0257
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:00:38 | Train | Epoch[566/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:00:39 | Valid | Epoch[566/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 11:00:39 | Valid | Epoch[566/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:39 | Valid | Epoch[566/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:39 | Valid | Epoch[566/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:39 | Valid | Epoch[566/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:39 | Valid | Epoch[566/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:39 | Valid | Epoch[566/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:39 | Valid | Epoch[566/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:39 | Valid | Epoch[566/600] MIou: 0.9207879197213711
2023-02-06 11:00:39 | Valid | Epoch[566/600] Pixel Accuracy: 0.9868176778157552
2023-02-06 11:00:39 | Valid | Epoch[566/600] Mean Pixel Accuracy: 0.9327482111247725
2023-02-06 11:00:39 | Stage | Epoch[566/600] Train loss:0.0252
2023-02-06 11:00:39 | Stage | Epoch[566/600] Valid loss:0.0289
2023-02-06 11:00:39 | Stage | Epoch[566/600] LR:0.0001

2023-02-06 11:00:39 | Train | Epoch[567/600] Iteration[001/030] Train loss: 0.0233
2023-02-06 11:00:39 | Train | Epoch[567/600] Iteration[002/030] Train loss: 0.0239
2023-02-06 11:00:39 | Train | Epoch[567/600] Iteration[003/030] Train loss: 0.0241
2023-02-06 11:00:39 | Train | Epoch[567/600] Iteration[004/030] Train loss: 0.0241
2023-02-06 11:00:39 | Train | Epoch[567/600] Iteration[005/030] Train loss: 0.0230
2023-02-06 11:00:39 | Train | Epoch[567/600] Iteration[006/030] Train loss: 0.0232
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[007/030] Train loss: 0.0238
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[008/030] Train loss: 0.0239
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[009/030] Train loss: 0.0248
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[010/030] Train loss: 0.0245
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 11:00:40 | Train | Epoch[567/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 11:00:41 | Train | Epoch[567/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:00:41 | Valid | Epoch[567/600] Iteration[001/008] Valid loss: 0.0345
2023-02-06 11:00:41 | Valid | Epoch[567/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:00:41 | Valid | Epoch[567/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:41 | Valid | Epoch[567/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:41 | Valid | Epoch[567/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:41 | Valid | Epoch[567/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:41 | Valid | Epoch[567/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 11:00:41 | Valid | Epoch[567/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:41 | Valid | Epoch[567/600] MIou: 0.9227825162355168
2023-02-06 11:00:41 | Valid | Epoch[567/600] Pixel Accuracy: 0.9871381123860677
2023-02-06 11:00:41 | Valid | Epoch[567/600] Mean Pixel Accuracy: 0.9349913293437581
2023-02-06 11:00:41 | Stage | Epoch[567/600] Train loss:0.0252
2023-02-06 11:00:41 | Stage | Epoch[567/600] Valid loss:0.0289
2023-02-06 11:00:41 | Stage | Epoch[567/600] LR:0.0001

2023-02-06 11:00:41 | Train | Epoch[568/600] Iteration[001/030] Train loss: 0.0290
2023-02-06 11:00:41 | Train | Epoch[568/600] Iteration[002/030] Train loss: 0.0284
2023-02-06 11:00:41 | Train | Epoch[568/600] Iteration[003/030] Train loss: 0.0286
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[004/030] Train loss: 0.0269
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[005/030] Train loss: 0.0263
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[006/030] Train loss: 0.0261
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[007/030] Train loss: 0.0263
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[008/030] Train loss: 0.0258
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[009/030] Train loss: 0.0258
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[011/030] Train loss: 0.0255
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[023/030] Train loss: 0.0255
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 11:00:42 | Train | Epoch[568/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 11:00:43 | Train | Epoch[568/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 11:00:43 | Train | Epoch[568/600] Iteration[028/030] Train loss: 0.0256
2023-02-06 11:00:43 | Train | Epoch[568/600] Iteration[029/030] Train loss: 0.0255
2023-02-06 11:00:43 | Train | Epoch[568/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 11:00:43 | Valid | Epoch[568/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 11:00:43 | Valid | Epoch[568/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:43 | Valid | Epoch[568/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:43 | Valid | Epoch[568/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:43 | Valid | Epoch[568/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 11:00:43 | Valid | Epoch[568/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:00:43 | Valid | Epoch[568/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:43 | Valid | Epoch[568/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:43 | Valid | Epoch[568/600] MIou: 0.9213427635092175
2023-02-06 11:00:43 | Valid | Epoch[568/600] Pixel Accuracy: 0.9869117736816406
2023-02-06 11:00:43 | Valid | Epoch[568/600] Mean Pixel Accuracy: 0.9332057204025277
2023-02-06 11:00:43 | Stage | Epoch[568/600] Train loss:0.0253
2023-02-06 11:00:43 | Stage | Epoch[568/600] Valid loss:0.0288
2023-02-06 11:00:43 | Stage | Epoch[568/600] LR:0.0001

2023-02-06 11:00:43 | Train | Epoch[569/600] Iteration[001/030] Train loss: 0.0234
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[002/030] Train loss: 0.0253
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[003/030] Train loss: 0.0248
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[004/030] Train loss: 0.0238
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[005/030] Train loss: 0.0238
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[007/030] Train loss: 0.0242
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[008/030] Train loss: 0.0240
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[010/030] Train loss: 0.0243
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[022/030] Train loss: 0.0247
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 11:00:44 | Train | Epoch[569/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:00:45 | Train | Epoch[569/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 11:00:45 | Train | Epoch[569/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:00:45 | Train | Epoch[569/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:00:45 | Train | Epoch[569/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:00:45 | Train | Epoch[569/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 11:00:45 | Train | Epoch[569/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:00:45 | Valid | Epoch[569/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 11:00:45 | Valid | Epoch[569/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:45 | Valid | Epoch[569/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:45 | Valid | Epoch[569/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:45 | Valid | Epoch[569/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:45 | Valid | Epoch[569/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:45 | Valid | Epoch[569/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:45 | Valid | Epoch[569/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:45 | Valid | Epoch[569/600] MIou: 0.9220279796760423
2023-02-06 11:00:45 | Valid | Epoch[569/600] Pixel Accuracy: 0.9870173136393229
2023-02-06 11:00:45 | Valid | Epoch[569/600] Mean Pixel Accuracy: 0.9341260337900832
2023-02-06 11:00:45 | Stage | Epoch[569/600] Train loss:0.0251
2023-02-06 11:00:45 | Stage | Epoch[569/600] Valid loss:0.0289
2023-02-06 11:00:45 | Stage | Epoch[569/600] LR:0.0001

2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[001/030] Train loss: 0.0253
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[003/030] Train loss: 0.0274
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[004/030] Train loss: 0.0276
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[005/030] Train loss: 0.0278
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[006/030] Train loss: 0.0268
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[007/030] Train loss: 0.0265
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[008/030] Train loss: 0.0262
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[009/030] Train loss: 0.0264
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[010/030] Train loss: 0.0261
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 11:00:46 | Train | Epoch[570/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 11:00:47 | Train | Epoch[570/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 11:00:47 | Train | Epoch[570/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:00:47 | Train | Epoch[570/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:00:47 | Train | Epoch[570/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 11:00:47 | Train | Epoch[570/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 11:00:47 | Train | Epoch[570/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:00:47 | Train | Epoch[570/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:00:47 | Train | Epoch[570/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 11:00:47 | Train | Epoch[570/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 11:00:47 | Train | Epoch[570/600] Iteration[030/030] Train loss: 0.0255
2023-02-06 11:00:47 | Valid | Epoch[570/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 11:00:47 | Valid | Epoch[570/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:47 | Valid | Epoch[570/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:47 | Valid | Epoch[570/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:47 | Valid | Epoch[570/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:47 | Valid | Epoch[570/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:47 | Valid | Epoch[570/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:47 | Valid | Epoch[570/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:47 | Valid | Epoch[570/600] MIou: 0.9214636186119849
2023-02-06 11:00:47 | Valid | Epoch[570/600] Pixel Accuracy: 0.9869283040364584
2023-02-06 11:00:47 | Valid | Epoch[570/600] Mean Pixel Accuracy: 0.933436722693461
2023-02-06 11:00:47 | Stage | Epoch[570/600] Train loss:0.0255
2023-02-06 11:00:47 | Stage | Epoch[570/600] Valid loss:0.0289
2023-02-06 11:00:47 | Stage | Epoch[570/600] LR:0.0001

2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[001/030] Train loss: 0.0250
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[002/030] Train loss: 0.0236
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[003/030] Train loss: 0.0239
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[004/030] Train loss: 0.0234
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[005/030] Train loss: 0.0234
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[006/030] Train loss: 0.0239
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[008/030] Train loss: 0.0241
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[010/030] Train loss: 0.0241
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[011/030] Train loss: 0.0237
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[012/030] Train loss: 0.0239
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:00:48 | Train | Epoch[571/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[024/030] Train loss: 0.0248
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[027/030] Train loss: 0.0248
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[029/030] Train loss: 0.0248
2023-02-06 11:00:49 | Train | Epoch[571/600] Iteration[030/030] Train loss: 0.0248
2023-02-06 11:00:49 | Valid | Epoch[571/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:00:49 | Valid | Epoch[571/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:00:49 | Valid | Epoch[571/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:49 | Valid | Epoch[571/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:49 | Valid | Epoch[571/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:49 | Valid | Epoch[571/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:00:49 | Valid | Epoch[571/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:00:50 | Valid | Epoch[571/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:50 | Valid | Epoch[571/600] MIou: 0.9193248065163568
2023-02-06 11:00:50 | Valid | Epoch[571/600] Pixel Accuracy: 0.9865849812825521
2023-02-06 11:00:50 | Valid | Epoch[571/600] Mean Pixel Accuracy: 0.931041533779349
2023-02-06 11:00:50 | Stage | Epoch[571/600] Train loss:0.0248
2023-02-06 11:00:50 | Stage | Epoch[571/600] Valid loss:0.0288
2023-02-06 11:00:50 | Stage | Epoch[571/600] LR:0.0001

2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[001/030] Train loss: 0.0279
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[002/030] Train loss: 0.0247
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[003/030] Train loss: 0.0254
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[004/030] Train loss: 0.0243
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[005/030] Train loss: 0.0252
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[008/030] Train loss: 0.0242
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[010/030] Train loss: 0.0244
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[012/030] Train loss: 0.0244
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 11:00:50 | Train | Epoch[572/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[026/030] Train loss: 0.0254
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 11:00:51 | Train | Epoch[572/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:00:51 | Valid | Epoch[572/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 11:00:51 | Valid | Epoch[572/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:51 | Valid | Epoch[572/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 11:00:51 | Valid | Epoch[572/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:00:52 | Valid | Epoch[572/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:52 | Valid | Epoch[572/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:00:52 | Valid | Epoch[572/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:00:52 | Valid | Epoch[572/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:52 | Valid | Epoch[572/600] MIou: 0.9183796648408371
2023-02-06 11:00:52 | Valid | Epoch[572/600] Pixel Accuracy: 0.9864349365234375
2023-02-06 11:00:52 | Valid | Epoch[572/600] Mean Pixel Accuracy: 0.9299382468670405
2023-02-06 11:00:52 | Stage | Epoch[572/600] Train loss:0.0251
2023-02-06 11:00:52 | Stage | Epoch[572/600] Valid loss:0.0288
2023-02-06 11:00:52 | Stage | Epoch[572/600] LR:0.0001

2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[001/030] Train loss: 0.0259
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[002/030] Train loss: 0.0220
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[003/030] Train loss: 0.0222
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[004/030] Train loss: 0.0227
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[005/030] Train loss: 0.0238
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[006/030] Train loss: 0.0236
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[007/030] Train loss: 0.0236
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[008/030] Train loss: 0.0242
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 11:00:52 | Train | Epoch[573/600] Iteration[013/030] Train loss: 0.0253
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[014/030] Train loss: 0.0250
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[015/030] Train loss: 0.0254
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[016/030] Train loss: 0.0256
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[022/030] Train loss: 0.0253
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 11:00:53 | Train | Epoch[573/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 11:00:53 | Valid | Epoch[573/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 11:00:54 | Valid | Epoch[573/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:54 | Valid | Epoch[573/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:54 | Valid | Epoch[573/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:54 | Valid | Epoch[573/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 11:00:54 | Valid | Epoch[573/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:00:54 | Valid | Epoch[573/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:00:54 | Valid | Epoch[573/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:54 | Valid | Epoch[573/600] MIou: 0.9206937340725017
2023-02-06 11:00:54 | Valid | Epoch[573/600] Pixel Accuracy: 0.9868049621582031
2023-02-06 11:00:54 | Valid | Epoch[573/600] Mean Pixel Accuracy: 0.932563688854734
2023-02-06 11:00:54 | Stage | Epoch[573/600] Train loss:0.0253
2023-02-06 11:00:54 | Stage | Epoch[573/600] Valid loss:0.0288
2023-02-06 11:00:54 | Stage | Epoch[573/600] LR:0.0001

2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[001/030] Train loss: 0.0276
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[002/030] Train loss: 0.0261
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[003/030] Train loss: 0.0270
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[005/030] Train loss: 0.0271
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[006/030] Train loss: 0.0269
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[007/030] Train loss: 0.0265
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[008/030] Train loss: 0.0264
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[010/030] Train loss: 0.0265
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[011/030] Train loss: 0.0265
2023-02-06 11:00:54 | Train | Epoch[574/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[014/030] Train loss: 0.0258
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[021/030] Train loss: 0.0252
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 11:00:55 | Train | Epoch[574/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 11:00:56 | Valid | Epoch[574/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 11:00:56 | Valid | Epoch[574/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:56 | Valid | Epoch[574/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:56 | Valid | Epoch[574/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:56 | Valid | Epoch[574/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 11:00:56 | Valid | Epoch[574/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:00:56 | Valid | Epoch[574/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:00:56 | Valid | Epoch[574/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:00:56 | Valid | Epoch[574/600] MIou: 0.9198288463492192
2023-02-06 11:00:56 | Valid | Epoch[574/600] Pixel Accuracy: 0.9866689046223959
2023-02-06 11:00:56 | Valid | Epoch[574/600] Mean Pixel Accuracy: 0.9315061327459683
2023-02-06 11:00:56 | Stage | Epoch[574/600] Train loss:0.0254
2023-02-06 11:00:56 | Stage | Epoch[574/600] Valid loss:0.0288
2023-02-06 11:00:56 | Stage | Epoch[574/600] LR:0.0001

2023-02-06 11:00:56 | Train | Epoch[575/600] Iteration[001/030] Train loss: 0.0280
2023-02-06 11:00:56 | Train | Epoch[575/600] Iteration[002/030] Train loss: 0.0257
2023-02-06 11:00:56 | Train | Epoch[575/600] Iteration[003/030] Train loss: 0.0259
2023-02-06 11:00:56 | Train | Epoch[575/600] Iteration[004/030] Train loss: 0.0260
2023-02-06 11:00:56 | Train | Epoch[575/600] Iteration[005/030] Train loss: 0.0255
2023-02-06 11:00:56 | Train | Epoch[575/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 11:00:56 | Train | Epoch[575/600] Iteration[007/030] Train loss: 0.0259
2023-02-06 11:00:56 | Train | Epoch[575/600] Iteration[008/030] Train loss: 0.0258
2023-02-06 11:00:56 | Train | Epoch[575/600] Iteration[009/030] Train loss: 0.0252
2023-02-06 11:00:56 | Train | Epoch[575/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[012/030] Train loss: 0.0254
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[015/030] Train loss: 0.0257
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[018/030] Train loss: 0.0257
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 11:00:57 | Train | Epoch[575/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:00:58 | Valid | Epoch[575/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 11:00:58 | Valid | Epoch[575/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:00:58 | Valid | Epoch[575/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:00:58 | Valid | Epoch[575/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:00:58 | Valid | Epoch[575/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:00:58 | Valid | Epoch[575/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:00:58 | Valid | Epoch[575/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:00:58 | Valid | Epoch[575/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:00:58 | Valid | Epoch[575/600] MIou: 0.9204435116400909
2023-02-06 11:00:58 | Valid | Epoch[575/600] Pixel Accuracy: 0.9867642720540365
2023-02-06 11:00:58 | Valid | Epoch[575/600] Mean Pixel Accuracy: 0.9323003859206338
2023-02-06 11:00:58 | Stage | Epoch[575/600] Train loss:0.0252
2023-02-06 11:00:58 | Stage | Epoch[575/600] Valid loss:0.0289
2023-02-06 11:00:58 | Stage | Epoch[575/600] LR:0.0001

2023-02-06 11:00:58 | Train | Epoch[576/600] Iteration[001/030] Train loss: 0.0182
2023-02-06 11:00:58 | Train | Epoch[576/600] Iteration[002/030] Train loss: 0.0202
2023-02-06 11:00:58 | Train | Epoch[576/600] Iteration[003/030] Train loss: 0.0225
2023-02-06 11:00:58 | Train | Epoch[576/600] Iteration[004/030] Train loss: 0.0230
2023-02-06 11:00:58 | Train | Epoch[576/600] Iteration[005/030] Train loss: 0.0236
2023-02-06 11:00:58 | Train | Epoch[576/600] Iteration[006/030] Train loss: 0.0234
2023-02-06 11:00:58 | Train | Epoch[576/600] Iteration[007/030] Train loss: 0.0234
2023-02-06 11:00:58 | Train | Epoch[576/600] Iteration[008/030] Train loss: 0.0234
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[009/030] Train loss: 0.0238
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[010/030] Train loss: 0.0237
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[011/030] Train loss: 0.0243
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[014/030] Train loss: 0.0239
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[015/030] Train loss: 0.0241
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[016/030] Train loss: 0.0242
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[017/030] Train loss: 0.0240
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[018/030] Train loss: 0.0243
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[019/030] Train loss: 0.0242
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[020/030] Train loss: 0.0243
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[021/030] Train loss: 0.0244
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:00:59 | Train | Epoch[576/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 11:01:00 | Valid | Epoch[576/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:01:00 | Valid | Epoch[576/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:01:00 | Valid | Epoch[576/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:00 | Valid | Epoch[576/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:00 | Valid | Epoch[576/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:00 | Valid | Epoch[576/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:01:00 | Valid | Epoch[576/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:01:00 | Valid | Epoch[576/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:01:00 | Valid | Epoch[576/600] MIou: 0.9199379433688335
2023-02-06 11:01:00 | Valid | Epoch[576/600] Pixel Accuracy: 0.9866828918457031
2023-02-06 11:01:00 | Valid | Epoch[576/600] Mean Pixel Accuracy: 0.9317420776948735
2023-02-06 11:01:00 | Stage | Epoch[576/600] Train loss:0.0249
2023-02-06 11:01:00 | Stage | Epoch[576/600] Valid loss:0.0289
2023-02-06 11:01:00 | Stage | Epoch[576/600] LR:0.0001

2023-02-06 11:01:00 | Train | Epoch[577/600] Iteration[001/030] Train loss: 0.0211
2023-02-06 11:01:00 | Train | Epoch[577/600] Iteration[002/030] Train loss: 0.0242
2023-02-06 11:01:00 | Train | Epoch[577/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 11:01:00 | Train | Epoch[577/600] Iteration[004/030] Train loss: 0.0235
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[005/030] Train loss: 0.0243
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[007/030] Train loss: 0.0236
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[008/030] Train loss: 0.0243
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[009/030] Train loss: 0.0240
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[010/030] Train loss: 0.0246
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[016/030] Train loss: 0.0247
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[024/030] Train loss: 0.0248
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[025/030] Train loss: 0.0247
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[026/030] Train loss: 0.0247
2023-02-06 11:01:01 | Train | Epoch[577/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 11:01:02 | Train | Epoch[577/600] Iteration[028/030] Train loss: 0.0247
2023-02-06 11:01:02 | Train | Epoch[577/600] Iteration[029/030] Train loss: 0.0247
2023-02-06 11:01:02 | Train | Epoch[577/600] Iteration[030/030] Train loss: 0.0248
2023-02-06 11:01:02 | Valid | Epoch[577/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 11:01:02 | Valid | Epoch[577/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:01:02 | Valid | Epoch[577/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:02 | Valid | Epoch[577/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:02 | Valid | Epoch[577/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:02 | Valid | Epoch[577/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:01:02 | Valid | Epoch[577/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:01:02 | Valid | Epoch[577/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:01:02 | Valid | Epoch[577/600] MIou: 0.9193456951197296
2023-02-06 11:01:02 | Valid | Epoch[577/600] Pixel Accuracy: 0.9865887959798177
2023-02-06 11:01:02 | Valid | Epoch[577/600] Mean Pixel Accuracy: 0.9310499709711713
2023-02-06 11:01:02 | Stage | Epoch[577/600] Train loss:0.0248
2023-02-06 11:01:02 | Stage | Epoch[577/600] Valid loss:0.0288
2023-02-06 11:01:02 | Stage | Epoch[577/600] LR:0.0001

2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[001/030] Train loss: 0.0276
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[003/030] Train loss: 0.0275
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[004/030] Train loss: 0.0269
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[005/030] Train loss: 0.0260
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[006/030] Train loss: 0.0259
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[009/030] Train loss: 0.0255
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 11:01:03 | Train | Epoch[578/600] Iteration[024/030] Train loss: 0.0247
2023-02-06 11:01:04 | Train | Epoch[578/600] Iteration[025/030] Train loss: 0.0246
2023-02-06 11:01:04 | Train | Epoch[578/600] Iteration[026/030] Train loss: 0.0246
2023-02-06 11:01:04 | Train | Epoch[578/600] Iteration[027/030] Train loss: 0.0244
2023-02-06 11:01:04 | Train | Epoch[578/600] Iteration[028/030] Train loss: 0.0245
2023-02-06 11:01:04 | Train | Epoch[578/600] Iteration[029/030] Train loss: 0.0246
2023-02-06 11:01:04 | Train | Epoch[578/600] Iteration[030/030] Train loss: 0.0248
2023-02-06 11:01:04 | Valid | Epoch[578/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 11:01:04 | Valid | Epoch[578/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:01:04 | Valid | Epoch[578/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:04 | Valid | Epoch[578/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:04 | Valid | Epoch[578/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:04 | Valid | Epoch[578/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 11:01:04 | Valid | Epoch[578/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 11:01:04 | Valid | Epoch[578/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 11:01:04 | Valid | Epoch[578/600] MIou: 0.9221488957620287
2023-02-06 11:01:04 | Valid | Epoch[578/600] Pixel Accuracy: 0.9870313008626302
2023-02-06 11:01:04 | Valid | Epoch[578/600] Mean Pixel Accuracy: 0.9344444048686453
2023-02-06 11:01:04 | Stage | Epoch[578/600] Train loss:0.0248
2023-02-06 11:01:04 | Stage | Epoch[578/600] Valid loss:0.0290
2023-02-06 11:01:04 | Stage | Epoch[578/600] LR:0.0001

2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[001/030] Train loss: 0.0255
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[002/030] Train loss: 0.0263
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[003/030] Train loss: 0.0243
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[004/030] Train loss: 0.0237
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[005/030] Train loss: 0.0244
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[007/030] Train loss: 0.0244
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[008/030] Train loss: 0.0246
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[014/030] Train loss: 0.0254
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[016/030] Train loss: 0.0252
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[017/030] Train loss: 0.0250
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[019/030] Train loss: 0.0249
2023-02-06 11:01:05 | Train | Epoch[579/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 11:01:06 | Train | Epoch[579/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 11:01:06 | Train | Epoch[579/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 11:01:06 | Train | Epoch[579/600] Iteration[023/030] Train loss: 0.0247
2023-02-06 11:01:06 | Train | Epoch[579/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:01:06 | Train | Epoch[579/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:01:06 | Train | Epoch[579/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:01:06 | Train | Epoch[579/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:01:06 | Train | Epoch[579/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:01:06 | Train | Epoch[579/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 11:01:06 | Train | Epoch[579/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 11:01:06 | Valid | Epoch[579/600] Iteration[001/008] Valid loss: 0.0346
2023-02-06 11:01:06 | Valid | Epoch[579/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 11:01:06 | Valid | Epoch[579/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:06 | Valid | Epoch[579/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:01:06 | Valid | Epoch[579/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:06 | Valid | Epoch[579/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 11:01:06 | Valid | Epoch[579/600] Iteration[007/008] Valid loss: 0.0293
2023-02-06 11:01:06 | Valid | Epoch[579/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 11:01:07 | Valid | Epoch[579/600] MIou: 0.9234004834995875
2023-02-06 11:01:07 | Valid | Epoch[579/600] Pixel Accuracy: 0.9872283935546875
2023-02-06 11:01:07 | Valid | Epoch[579/600] Mean Pixel Accuracy: 0.9359983629227543
2023-02-06 11:01:07 | Stage | Epoch[579/600] Train loss:0.0249
2023-02-06 11:01:07 | Stage | Epoch[579/600] Valid loss:0.0291
2023-02-06 11:01:07 | Stage | Epoch[579/600] LR:0.0001

2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[004/030] Train loss: 0.0245
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[005/030] Train loss: 0.0241
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[007/030] Train loss: 0.0239
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[008/030] Train loss: 0.0240
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[009/030] Train loss: 0.0241
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[010/030] Train loss: 0.0238
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[011/030] Train loss: 0.0242
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[012/030] Train loss: 0.0243
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 11:01:07 | Train | Epoch[580/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[017/030] Train loss: 0.0252
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[018/030] Train loss: 0.0254
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[019/030] Train loss: 0.0254
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[020/030] Train loss: 0.0254
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[022/030] Train loss: 0.0255
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:01:08 | Train | Epoch[580/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 11:01:08 | Valid | Epoch[580/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 11:01:08 | Valid | Epoch[580/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:01:08 | Valid | Epoch[580/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:09 | Valid | Epoch[580/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:09 | Valid | Epoch[580/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 11:01:09 | Valid | Epoch[580/600] Iteration[006/008] Valid loss: 0.0292
2023-02-06 11:01:09 | Valid | Epoch[580/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 11:01:09 | Valid | Epoch[580/600] Iteration[008/008] Valid loss: 0.0291
2023-02-06 11:01:09 | Valid | Epoch[580/600] MIou: 0.9216981333947447
2023-02-06 11:01:09 | Valid | Epoch[580/600] Pixel Accuracy: 0.9869562784830729
2023-02-06 11:01:09 | Valid | Epoch[580/600] Mean Pixel Accuracy: 0.9340227410784888
2023-02-06 11:01:09 | Stage | Epoch[580/600] Train loss:0.0250
2023-02-06 11:01:09 | Stage | Epoch[580/600] Valid loss:0.0291
2023-02-06 11:01:09 | Stage | Epoch[580/600] LR:0.0001

2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[001/030] Train loss: 0.0262
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[002/030] Train loss: 0.0270
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[003/030] Train loss: 0.0270
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[004/030] Train loss: 0.0270
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[005/030] Train loss: 0.0269
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[006/030] Train loss: 0.0267
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[010/030] Train loss: 0.0259
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[011/030] Train loss: 0.0258
2023-02-06 11:01:09 | Train | Epoch[581/600] Iteration[012/030] Train loss: 0.0257
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[013/030] Train loss: 0.0256
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[014/030] Train loss: 0.0257
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[015/030] Train loss: 0.0255
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[016/030] Train loss: 0.0255
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[017/030] Train loss: 0.0255
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[018/030] Train loss: 0.0253
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:01:10 | Train | Epoch[581/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 11:01:11 | Valid | Epoch[581/600] Iteration[001/008] Valid loss: 0.0351
2023-02-06 11:01:11 | Valid | Epoch[581/600] Iteration[002/008] Valid loss: 0.0303
2023-02-06 11:01:11 | Valid | Epoch[581/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 11:01:11 | Valid | Epoch[581/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:01:11 | Valid | Epoch[581/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 11:01:11 | Valid | Epoch[581/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 11:01:11 | Valid | Epoch[581/600] Iteration[007/008] Valid loss: 0.0296
2023-02-06 11:01:11 | Valid | Epoch[581/600] Iteration[008/008] Valid loss: 0.0293
2023-02-06 11:01:11 | Valid | Epoch[581/600] MIou: 0.9263203512533251
2023-02-06 11:01:11 | Valid | Epoch[581/600] Pixel Accuracy: 0.9876912434895834
2023-02-06 11:01:11 | Valid | Epoch[581/600] Mean Pixel Accuracy: 0.9395751720593751
2023-02-06 11:01:11 | Stage | Epoch[581/600] Train loss:0.0249
2023-02-06 11:01:11 | Stage | Epoch[581/600] Valid loss:0.0293
2023-02-06 11:01:11 | Stage | Epoch[581/600] LR:0.0001

2023-02-06 11:01:11 | Train | Epoch[582/600] Iteration[001/030] Train loss: 0.0230
2023-02-06 11:01:11 | Train | Epoch[582/600] Iteration[002/030] Train loss: 0.0248
2023-02-06 11:01:11 | Train | Epoch[582/600] Iteration[003/030] Train loss: 0.0238
2023-02-06 11:01:11 | Train | Epoch[582/600] Iteration[004/030] Train loss: 0.0244
2023-02-06 11:01:11 | Train | Epoch[582/600] Iteration[005/030] Train loss: 0.0237
2023-02-06 11:01:11 | Train | Epoch[582/600] Iteration[006/030] Train loss: 0.0244
2023-02-06 11:01:11 | Train | Epoch[582/600] Iteration[007/030] Train loss: 0.0246
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[009/030] Train loss: 0.0242
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[010/030] Train loss: 0.0240
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[011/030] Train loss: 0.0241
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[012/030] Train loss: 0.0245
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[013/030] Train loss: 0.0243
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[014/030] Train loss: 0.0244
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[016/030] Train loss: 0.0249
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[018/030] Train loss: 0.0249
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:01:12 | Train | Epoch[582/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:01:13 | Valid | Epoch[582/600] Iteration[001/008] Valid loss: 0.0347
2023-02-06 11:01:13 | Valid | Epoch[582/600] Iteration[002/008] Valid loss: 0.0301
2023-02-06 11:01:13 | Valid | Epoch[582/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:13 | Valid | Epoch[582/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:13 | Valid | Epoch[582/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:13 | Valid | Epoch[582/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 11:01:13 | Valid | Epoch[582/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 11:01:13 | Valid | Epoch[582/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 11:01:13 | Valid | Epoch[582/600] MIou: 0.9244303975311111
2023-02-06 11:01:13 | Valid | Epoch[582/600] Pixel Accuracy: 0.9873949686686198
2023-02-06 11:01:13 | Valid | Epoch[582/600] Mean Pixel Accuracy: 0.9371360975091214
2023-02-06 11:01:13 | Stage | Epoch[582/600] Train loss:0.0252
2023-02-06 11:01:13 | Stage | Epoch[582/600] Valid loss:0.0290
2023-02-06 11:01:13 | Stage | Epoch[582/600] LR:0.0001

2023-02-06 11:01:13 | Train | Epoch[583/600] Iteration[001/030] Train loss: 0.0244
2023-02-06 11:01:13 | Train | Epoch[583/600] Iteration[002/030] Train loss: 0.0250
2023-02-06 11:01:13 | Train | Epoch[583/600] Iteration[003/030] Train loss: 0.0242
2023-02-06 11:01:13 | Train | Epoch[583/600] Iteration[004/030] Train loss: 0.0238
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[005/030] Train loss: 0.0250
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[006/030] Train loss: 0.0250
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[011/030] Train loss: 0.0250
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[013/030] Train loss: 0.0255
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[015/030] Train loss: 0.0256
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[016/030] Train loss: 0.0258
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[017/030] Train loss: 0.0257
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[025/030] Train loss: 0.0253
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 11:01:14 | Train | Epoch[583/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:01:15 | Train | Epoch[583/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:01:15 | Train | Epoch[583/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:01:15 | Train | Epoch[583/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:01:15 | Valid | Epoch[583/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:01:15 | Valid | Epoch[583/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:01:15 | Valid | Epoch[583/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 11:01:15 | Valid | Epoch[583/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:01:15 | Valid | Epoch[583/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:15 | Valid | Epoch[583/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:01:15 | Valid | Epoch[583/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 11:01:15 | Valid | Epoch[583/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:01:15 | Valid | Epoch[583/600] MIou: 0.9180857849156903
2023-02-06 11:01:15 | Valid | Epoch[583/600] Pixel Accuracy: 0.9863853454589844
2023-02-06 11:01:15 | Valid | Epoch[583/600] Mean Pixel Accuracy: 0.9296890730000866
2023-02-06 11:01:15 | Stage | Epoch[583/600] Train loss:0.0251
2023-02-06 11:01:15 | Stage | Epoch[583/600] Valid loss:0.0288
2023-02-06 11:01:15 | Stage | Epoch[583/600] LR:0.0001

2023-02-06 11:01:15 | Train | Epoch[584/600] Iteration[001/030] Train loss: 0.0248
2023-02-06 11:01:15 | Train | Epoch[584/600] Iteration[002/030] Train loss: 0.0241
2023-02-06 11:01:15 | Train | Epoch[584/600] Iteration[003/030] Train loss: 0.0249
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[004/030] Train loss: 0.0249
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[006/030] Train loss: 0.0243
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[008/030] Train loss: 0.0249
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[009/030] Train loss: 0.0246
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[013/030] Train loss: 0.0259
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[014/030] Train loss: 0.0255
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[015/030] Train loss: 0.0261
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[016/030] Train loss: 0.0262
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[017/030] Train loss: 0.0262
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[018/030] Train loss: 0.0261
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[019/030] Train loss: 0.0261
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[020/030] Train loss: 0.0262
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[021/030] Train loss: 0.0261
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[023/030] Train loss: 0.0258
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[025/030] Train loss: 0.0257
2023-02-06 11:01:16 | Train | Epoch[584/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 11:01:17 | Train | Epoch[584/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 11:01:17 | Train | Epoch[584/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 11:01:17 | Train | Epoch[584/600] Iteration[029/030] Train loss: 0.0255
2023-02-06 11:01:17 | Train | Epoch[584/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 11:01:17 | Valid | Epoch[584/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:01:17 | Valid | Epoch[584/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:01:17 | Valid | Epoch[584/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:17 | Valid | Epoch[584/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:17 | Valid | Epoch[584/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:17 | Valid | Epoch[584/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:01:17 | Valid | Epoch[584/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:01:17 | Valid | Epoch[584/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:01:17 | Valid | Epoch[584/600] MIou: 0.9198057401048154
2023-02-06 11:01:17 | Valid | Epoch[584/600] Pixel Accuracy: 0.9866625467936198
2023-02-06 11:01:17 | Valid | Epoch[584/600] Mean Pixel Accuracy: 0.931566042927239
2023-02-06 11:01:17 | Stage | Epoch[584/600] Train loss:0.0253
2023-02-06 11:01:17 | Stage | Epoch[584/600] Valid loss:0.0289
2023-02-06 11:01:17 | Stage | Epoch[584/600] LR:0.0001

2023-02-06 11:01:17 | Train | Epoch[585/600] Iteration[001/030] Train loss: 0.0209
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[002/030] Train loss: 0.0223
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[003/030] Train loss: 0.0237
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[004/030] Train loss: 0.0242
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[005/030] Train loss: 0.0249
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[007/030] Train loss: 0.0248
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[008/030] Train loss: 0.0248
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[010/030] Train loss: 0.0253
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[020/030] Train loss: 0.0253
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[023/030] Train loss: 0.0254
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:01:18 | Train | Epoch[585/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 11:01:19 | Train | Epoch[585/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:01:19 | Train | Epoch[585/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 11:01:19 | Train | Epoch[585/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 11:01:19 | Train | Epoch[585/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 11:01:19 | Train | Epoch[585/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:01:19 | Valid | Epoch[585/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 11:01:19 | Valid | Epoch[585/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:01:19 | Valid | Epoch[585/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:19 | Valid | Epoch[585/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:19 | Valid | Epoch[585/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:19 | Valid | Epoch[585/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 11:01:19 | Valid | Epoch[585/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 11:01:19 | Valid | Epoch[585/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 11:01:19 | Valid | Epoch[585/600] MIou: 0.9214404273210004
2023-02-06 11:01:19 | Valid | Epoch[585/600] Pixel Accuracy: 0.9869155883789062
2023-02-06 11:01:19 | Valid | Epoch[585/600] Mean Pixel Accuracy: 0.9337087143722922
2023-02-06 11:01:19 | Stage | Epoch[585/600] Train loss:0.0251
2023-02-06 11:01:19 | Stage | Epoch[585/600] Valid loss:0.0290
2023-02-06 11:01:19 | Stage | Epoch[585/600] LR:0.0001

2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[001/030] Train loss: 0.0287
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[002/030] Train loss: 0.0280
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[003/030] Train loss: 0.0268
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[004/030] Train loss: 0.0251
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[005/030] Train loss: 0.0253
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[006/030] Train loss: 0.0246
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[007/030] Train loss: 0.0245
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[009/030] Train loss: 0.0250
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[014/030] Train loss: 0.0251
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[017/030] Train loss: 0.0246
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[019/030] Train loss: 0.0247
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 11:01:20 | Train | Epoch[586/600] Iteration[021/030] Train loss: 0.0248
2023-02-06 11:01:21 | Train | Epoch[586/600] Iteration[022/030] Train loss: 0.0248
2023-02-06 11:01:21 | Train | Epoch[586/600] Iteration[023/030] Train loss: 0.0248
2023-02-06 11:01:21 | Train | Epoch[586/600] Iteration[024/030] Train loss: 0.0246
2023-02-06 11:01:21 | Train | Epoch[586/600] Iteration[025/030] Train loss: 0.0245
2023-02-06 11:01:21 | Train | Epoch[586/600] Iteration[026/030] Train loss: 0.0246
2023-02-06 11:01:21 | Train | Epoch[586/600] Iteration[027/030] Train loss: 0.0247
2023-02-06 11:01:21 | Train | Epoch[586/600] Iteration[028/030] Train loss: 0.0247
2023-02-06 11:01:21 | Train | Epoch[586/600] Iteration[029/030] Train loss: 0.0247
2023-02-06 11:01:21 | Train | Epoch[586/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 11:01:21 | Valid | Epoch[586/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 11:01:21 | Valid | Epoch[586/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:01:21 | Valid | Epoch[586/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:21 | Valid | Epoch[586/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:21 | Valid | Epoch[586/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:21 | Valid | Epoch[586/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 11:01:21 | Valid | Epoch[586/600] Iteration[007/008] Valid loss: 0.0292
2023-02-06 11:01:21 | Valid | Epoch[586/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 11:01:21 | Valid | Epoch[586/600] MIou: 0.9228601933836891
2023-02-06 11:01:21 | Valid | Epoch[586/600] Pixel Accuracy: 0.9871444702148438
2023-02-06 11:01:21 | Valid | Epoch[586/600] Mean Pixel Accuracy: 0.9352864855671639
2023-02-06 11:01:21 | Stage | Epoch[586/600] Train loss:0.0249
2023-02-06 11:01:21 | Stage | Epoch[586/600] Valid loss:0.0290
2023-02-06 11:01:21 | Stage | Epoch[586/600] LR:0.0001

2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[001/030] Train loss: 0.0288
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[002/030] Train loss: 0.0254
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[003/030] Train loss: 0.0255
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[004/030] Train loss: 0.0256
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[005/030] Train loss: 0.0257
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[006/030] Train loss: 0.0264
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[007/030] Train loss: 0.0267
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[008/030] Train loss: 0.0267
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[009/030] Train loss: 0.0265
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[010/030] Train loss: 0.0264
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[011/030] Train loss: 0.0264
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[012/030] Train loss: 0.0264
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[013/030] Train loss: 0.0263
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[014/030] Train loss: 0.0263
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[015/030] Train loss: 0.0262
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[016/030] Train loss: 0.0260
2023-02-06 11:01:22 | Train | Epoch[587/600] Iteration[017/030] Train loss: 0.0258
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[018/030] Train loss: 0.0258
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[020/030] Train loss: 0.0257
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[021/030] Train loss: 0.0257
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[023/030] Train loss: 0.0257
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[024/030] Train loss: 0.0257
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[025/030] Train loss: 0.0256
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[026/030] Train loss: 0.0255
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[027/030] Train loss: 0.0254
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 11:01:23 | Train | Epoch[587/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:01:23 | Valid | Epoch[587/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:01:23 | Valid | Epoch[587/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:01:23 | Valid | Epoch[587/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:23 | Valid | Epoch[587/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:01:23 | Valid | Epoch[587/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:24 | Valid | Epoch[587/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:01:24 | Valid | Epoch[587/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:01:24 | Valid | Epoch[587/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:01:24 | Valid | Epoch[587/600] MIou: 0.9193441246149232
2023-02-06 11:01:24 | Valid | Epoch[587/600] Pixel Accuracy: 0.9865875244140625
2023-02-06 11:01:24 | Valid | Epoch[587/600] Mean Pixel Accuracy: 0.9310809744219615
2023-02-06 11:01:24 | Stage | Epoch[587/600] Train loss:0.0252
2023-02-06 11:01:24 | Stage | Epoch[587/600] Valid loss:0.0288
2023-02-06 11:01:24 | Stage | Epoch[587/600] LR:0.0001

2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[001/030] Train loss: 0.0267
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[002/030] Train loss: 0.0265
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[003/030] Train loss: 0.0258
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[004/030] Train loss: 0.0263
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[005/030] Train loss: 0.0263
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[006/030] Train loss: 0.0264
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[007/030] Train loss: 0.0260
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[008/030] Train loss: 0.0259
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[009/030] Train loss: 0.0259
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[010/030] Train loss: 0.0260
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[012/030] Train loss: 0.0256
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[013/030] Train loss: 0.0254
2023-02-06 11:01:24 | Train | Epoch[588/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[015/030] Train loss: 0.0252
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 11:01:25 | Train | Epoch[588/600] Iteration[030/030] Train loss: 0.0248
2023-02-06 11:01:26 | Valid | Epoch[588/600] Iteration[001/008] Valid loss: 0.0344
2023-02-06 11:01:26 | Valid | Epoch[588/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:01:26 | Valid | Epoch[588/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:26 | Valid | Epoch[588/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:01:26 | Valid | Epoch[588/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 11:01:26 | Valid | Epoch[588/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:01:26 | Valid | Epoch[588/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:01:26 | Valid | Epoch[588/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:01:26 | Valid | Epoch[588/600] MIou: 0.9210438480488965
2023-02-06 11:01:26 | Valid | Epoch[588/600] Pixel Accuracy: 0.9868634541829427
2023-02-06 11:01:26 | Valid | Epoch[588/600] Mean Pixel Accuracy: 0.9328811597841988
2023-02-06 11:01:26 | Stage | Epoch[588/600] Train loss:0.0248
2023-02-06 11:01:26 | Stage | Epoch[588/600] Valid loss:0.0288
2023-02-06 11:01:26 | Stage | Epoch[588/600] LR:0.0001

2023-02-06 11:01:26 | Train | Epoch[589/600] Iteration[001/030] Train loss: 0.0256
2023-02-06 11:01:26 | Train | Epoch[589/600] Iteration[002/030] Train loss: 0.0227
2023-02-06 11:01:26 | Train | Epoch[589/600] Iteration[003/030] Train loss: 0.0246
2023-02-06 11:01:26 | Train | Epoch[589/600] Iteration[004/030] Train loss: 0.0239
2023-02-06 11:01:26 | Train | Epoch[589/600] Iteration[005/030] Train loss: 0.0239
2023-02-06 11:01:26 | Train | Epoch[589/600] Iteration[006/030] Train loss: 0.0240
2023-02-06 11:01:26 | Train | Epoch[589/600] Iteration[007/030] Train loss: 0.0247
2023-02-06 11:01:26 | Train | Epoch[589/600] Iteration[008/030] Train loss: 0.0245
2023-02-06 11:01:26 | Train | Epoch[589/600] Iteration[009/030] Train loss: 0.0246
2023-02-06 11:01:26 | Train | Epoch[589/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[012/030] Train loss: 0.0251
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[013/030] Train loss: 0.0250
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[015/030] Train loss: 0.0247
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[018/030] Train loss: 0.0248
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[019/030] Train loss: 0.0248
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[020/030] Train loss: 0.0247
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[021/030] Train loss: 0.0249
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[024/030] Train loss: 0.0253
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:01:27 | Train | Epoch[589/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 11:01:28 | Valid | Epoch[589/600] Iteration[001/008] Valid loss: 0.0347
2023-02-06 11:01:28 | Valid | Epoch[589/600] Iteration[002/008] Valid loss: 0.0302
2023-02-06 11:01:28 | Valid | Epoch[589/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 11:01:28 | Valid | Epoch[589/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:01:28 | Valid | Epoch[589/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 11:01:28 | Valid | Epoch[589/600] Iteration[006/008] Valid loss: 0.0293
2023-02-06 11:01:28 | Valid | Epoch[589/600] Iteration[007/008] Valid loss: 0.0294
2023-02-06 11:01:28 | Valid | Epoch[589/600] Iteration[008/008] Valid loss: 0.0292
2023-02-06 11:01:28 | Valid | Epoch[589/600] MIou: 0.9244889159302803
2023-02-06 11:01:28 | Valid | Epoch[589/600] Pixel Accuracy: 0.987396240234375
2023-02-06 11:01:28 | Valid | Epoch[589/600] Mean Pixel Accuracy: 0.9374855223490558
2023-02-06 11:01:28 | Stage | Epoch[589/600] Train loss:0.0250
2023-02-06 11:01:28 | Stage | Epoch[589/600] Valid loss:0.0292
2023-02-06 11:01:28 | Stage | Epoch[589/600] LR:0.0001

2023-02-06 11:01:28 | Train | Epoch[590/600] Iteration[001/030] Train loss: 0.0214
2023-02-06 11:01:28 | Train | Epoch[590/600] Iteration[002/030] Train loss: 0.0231
2023-02-06 11:01:28 | Train | Epoch[590/600] Iteration[003/030] Train loss: 0.0248
2023-02-06 11:01:28 | Train | Epoch[590/600] Iteration[004/030] Train loss: 0.0245
2023-02-06 11:01:28 | Train | Epoch[590/600] Iteration[005/030] Train loss: 0.0245
2023-02-06 11:01:28 | Train | Epoch[590/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 11:01:28 | Train | Epoch[590/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[008/030] Train loss: 0.0251
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[010/030] Train loss: 0.0251
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[014/030] Train loss: 0.0252
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[022/030] Train loss: 0.0250
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[025/030] Train loss: 0.0249
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[026/030] Train loss: 0.0249
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[029/030] Train loss: 0.0249
2023-02-06 11:01:29 | Train | Epoch[590/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:01:30 | Valid | Epoch[590/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:01:30 | Valid | Epoch[590/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:01:30 | Valid | Epoch[590/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:30 | Valid | Epoch[590/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:30 | Valid | Epoch[590/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 11:01:30 | Valid | Epoch[590/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:01:30 | Valid | Epoch[590/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:01:30 | Valid | Epoch[590/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:01:30 | Valid | Epoch[590/600] MIou: 0.92001906430071
2023-02-06 11:01:30 | Valid | Epoch[590/600] Pixel Accuracy: 0.9866930643717448
2023-02-06 11:01:30 | Valid | Epoch[590/600] Mean Pixel Accuracy: 0.931925202151372
2023-02-06 11:01:30 | Stage | Epoch[590/600] Train loss:0.0252
2023-02-06 11:01:30 | Stage | Epoch[590/600] Valid loss:0.0289
2023-02-06 11:01:30 | Stage | Epoch[590/600] LR:0.0001

2023-02-06 11:01:30 | Train | Epoch[591/600] Iteration[001/030] Train loss: 0.0218
2023-02-06 11:01:30 | Train | Epoch[591/600] Iteration[002/030] Train loss: 0.0263
2023-02-06 11:01:30 | Train | Epoch[591/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 11:01:30 | Train | Epoch[591/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[005/030] Train loss: 0.0253
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[007/030] Train loss: 0.0251
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[008/030] Train loss: 0.0251
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[011/030] Train loss: 0.0251
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[012/030] Train loss: 0.0250
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[014/030] Train loss: 0.0245
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[015/030] Train loss: 0.0246
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[016/030] Train loss: 0.0246
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[018/030] Train loss: 0.0251
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[021/030] Train loss: 0.0250
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[023/030] Train loss: 0.0249
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[025/030] Train loss: 0.0248
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[026/030] Train loss: 0.0248
2023-02-06 11:01:31 | Train | Epoch[591/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 11:01:32 | Train | Epoch[591/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:01:32 | Train | Epoch[591/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:01:32 | Train | Epoch[591/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:01:32 | Valid | Epoch[591/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 11:01:32 | Valid | Epoch[591/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:01:32 | Valid | Epoch[591/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:32 | Valid | Epoch[591/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:32 | Valid | Epoch[591/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:32 | Valid | Epoch[591/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 11:01:32 | Valid | Epoch[591/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 11:01:32 | Valid | Epoch[591/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 11:01:32 | Valid | Epoch[591/600] MIou: 0.9220387109802984
2023-02-06 11:01:32 | Valid | Epoch[591/600] Pixel Accuracy: 0.9870173136393229
2023-02-06 11:01:32 | Valid | Epoch[591/600] Mean Pixel Accuracy: 0.934195778976716
2023-02-06 11:01:32 | Stage | Epoch[591/600] Train loss:0.0252
2023-02-06 11:01:32 | Stage | Epoch[591/600] Valid loss:0.0290
2023-02-06 11:01:32 | Stage | Epoch[591/600] LR:0.0001

2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[001/030] Train loss: 0.0215
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[002/030] Train loss: 0.0262
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[003/030] Train loss: 0.0264
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[004/030] Train loss: 0.0250
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[005/030] Train loss: 0.0248
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[006/030] Train loss: 0.0251
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[007/030] Train loss: 0.0255
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[008/030] Train loss: 0.0255
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[009/030] Train loss: 0.0256
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[010/030] Train loss: 0.0254
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[011/030] Train loss: 0.0259
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[012/030] Train loss: 0.0258
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[013/030] Train loss: 0.0260
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[014/030] Train loss: 0.0259
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[015/030] Train loss: 0.0259
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[019/030] Train loss: 0.0255
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[020/030] Train loss: 0.0252
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[021/030] Train loss: 0.0255
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[022/030] Train loss: 0.0257
2023-02-06 11:01:33 | Train | Epoch[592/600] Iteration[023/030] Train loss: 0.0256
2023-02-06 11:01:34 | Train | Epoch[592/600] Iteration[024/030] Train loss: 0.0256
2023-02-06 11:01:34 | Train | Epoch[592/600] Iteration[025/030] Train loss: 0.0255
2023-02-06 11:01:34 | Train | Epoch[592/600] Iteration[026/030] Train loss: 0.0256
2023-02-06 11:01:34 | Train | Epoch[592/600] Iteration[027/030] Train loss: 0.0255
2023-02-06 11:01:34 | Train | Epoch[592/600] Iteration[028/030] Train loss: 0.0255
2023-02-06 11:01:34 | Train | Epoch[592/600] Iteration[029/030] Train loss: 0.0253
2023-02-06 11:01:34 | Train | Epoch[592/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:01:34 | Valid | Epoch[592/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 11:01:34 | Valid | Epoch[592/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:01:34 | Valid | Epoch[592/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:34 | Valid | Epoch[592/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:34 | Valid | Epoch[592/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:34 | Valid | Epoch[592/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 11:01:34 | Valid | Epoch[592/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 11:01:34 | Valid | Epoch[592/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:01:34 | Valid | Epoch[592/600] MIou: 0.9226825451905152
2023-02-06 11:01:34 | Valid | Epoch[592/600] Pixel Accuracy: 0.9871203104654948
2023-02-06 11:01:34 | Valid | Epoch[592/600] Mean Pixel Accuracy: 0.9349371613483931
2023-02-06 11:01:34 | Stage | Epoch[592/600] Train loss:0.0252
2023-02-06 11:01:34 | Stage | Epoch[592/600] Valid loss:0.0289
2023-02-06 11:01:34 | Stage | Epoch[592/600] LR:0.0001

2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[001/030] Train loss: 0.0230
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[002/030] Train loss: 0.0241
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[003/030] Train loss: 0.0252
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[004/030] Train loss: 0.0252
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[005/030] Train loss: 0.0247
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[006/030] Train loss: 0.0249
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[007/030] Train loss: 0.0253
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[008/030] Train loss: 0.0256
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[009/030] Train loss: 0.0253
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[010/030] Train loss: 0.0250
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[011/030] Train loss: 0.0247
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[012/030] Train loss: 0.0246
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[014/030] Train loss: 0.0247
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[015/030] Train loss: 0.0249
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[016/030] Train loss: 0.0248
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[018/030] Train loss: 0.0247
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[019/030] Train loss: 0.0246
2023-02-06 11:01:35 | Train | Epoch[593/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 11:01:36 | Train | Epoch[593/600] Iteration[021/030] Train loss: 0.0246
2023-02-06 11:01:36 | Train | Epoch[593/600] Iteration[022/030] Train loss: 0.0246
2023-02-06 11:01:36 | Train | Epoch[593/600] Iteration[023/030] Train loss: 0.0245
2023-02-06 11:01:36 | Train | Epoch[593/600] Iteration[024/030] Train loss: 0.0244
2023-02-06 11:01:36 | Train | Epoch[593/600] Iteration[025/030] Train loss: 0.0244
2023-02-06 11:01:36 | Train | Epoch[593/600] Iteration[026/030] Train loss: 0.0245
2023-02-06 11:01:36 | Train | Epoch[593/600] Iteration[027/030] Train loss: 0.0246
2023-02-06 11:01:36 | Train | Epoch[593/600] Iteration[028/030] Train loss: 0.0247
2023-02-06 11:01:36 | Train | Epoch[593/600] Iteration[029/030] Train loss: 0.0248
2023-02-06 11:01:36 | Train | Epoch[593/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 11:01:36 | Valid | Epoch[593/600] Iteration[001/008] Valid loss: 0.0340
2023-02-06 11:01:36 | Valid | Epoch[593/600] Iteration[002/008] Valid loss: 0.0298
2023-02-06 11:01:36 | Valid | Epoch[593/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 11:01:36 | Valid | Epoch[593/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:01:36 | Valid | Epoch[593/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:36 | Valid | Epoch[593/600] Iteration[006/008] Valid loss: 0.0288
2023-02-06 11:01:36 | Valid | Epoch[593/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 11:01:36 | Valid | Epoch[593/600] Iteration[008/008] Valid loss: 0.0287
2023-02-06 11:01:37 | Valid | Epoch[593/600] MIou: 0.9178293505788941
2023-02-06 11:01:37 | Valid | Epoch[593/600] Pixel Accuracy: 0.9863459269205729
2023-02-06 11:01:37 | Valid | Epoch[593/600] Mean Pixel Accuracy: 0.9293503833146116
2023-02-06 11:01:37 | Stage | Epoch[593/600] Train loss:0.0249
2023-02-06 11:01:37 | Stage | Epoch[593/600] Valid loss:0.0287
2023-02-06 11:01:37 | Stage | Epoch[593/600] LR:0.0001

2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[001/030] Train loss: 0.0253
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[003/030] Train loss: 0.0260
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[004/030] Train loss: 0.0267
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[005/030] Train loss: 0.0263
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[006/030] Train loss: 0.0255
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[007/030] Train loss: 0.0258
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[008/030] Train loss: 0.0260
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[011/030] Train loss: 0.0261
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[012/030] Train loss: 0.0262
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[013/030] Train loss: 0.0261
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[014/030] Train loss: 0.0260
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[015/030] Train loss: 0.0260
2023-02-06 11:01:37 | Train | Epoch[594/600] Iteration[016/030] Train loss: 0.0257
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[017/030] Train loss: 0.0256
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[018/030] Train loss: 0.0255
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[019/030] Train loss: 0.0257
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[020/030] Train loss: 0.0256
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[021/030] Train loss: 0.0258
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[022/030] Train loss: 0.0259
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[023/030] Train loss: 0.0258
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[024/030] Train loss: 0.0255
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[025/030] Train loss: 0.0254
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[026/030] Train loss: 0.0253
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[027/030] Train loss: 0.0252
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[028/030] Train loss: 0.0254
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[029/030] Train loss: 0.0254
2023-02-06 11:01:38 | Train | Epoch[594/600] Iteration[030/030] Train loss: 0.0253
2023-02-06 11:01:38 | Valid | Epoch[594/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 11:01:38 | Valid | Epoch[594/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:01:38 | Valid | Epoch[594/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:39 | Valid | Epoch[594/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:39 | Valid | Epoch[594/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 11:01:39 | Valid | Epoch[594/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:01:39 | Valid | Epoch[594/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:01:39 | Valid | Epoch[594/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:01:39 | Valid | Epoch[594/600] MIou: 0.922067890959696
2023-02-06 11:01:39 | Valid | Epoch[594/600] Pixel Accuracy: 0.9870249430338541
2023-02-06 11:01:39 | Valid | Epoch[594/600] Mean Pixel Accuracy: 0.9341302272307033
2023-02-06 11:01:39 | Stage | Epoch[594/600] Train loss:0.0253
2023-02-06 11:01:39 | Stage | Epoch[594/600] Valid loss:0.0289
2023-02-06 11:01:39 | Stage | Epoch[594/600] LR:0.0001

2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[001/030] Train loss: 0.0277
2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[002/030] Train loss: 0.0270
2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[003/030] Train loss: 0.0275
2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[004/030] Train loss: 0.0265
2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[005/030] Train loss: 0.0253
2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[006/030] Train loss: 0.0245
2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[007/030] Train loss: 0.0243
2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[008/030] Train loss: 0.0244
2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[009/030] Train loss: 0.0245
2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[010/030] Train loss: 0.0245
2023-02-06 11:01:39 | Train | Epoch[595/600] Iteration[011/030] Train loss: 0.0245
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[013/030] Train loss: 0.0249
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[015/030] Train loss: 0.0251
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[016/030] Train loss: 0.0251
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[017/030] Train loss: 0.0251
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[024/030] Train loss: 0.0254
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[028/030] Train loss: 0.0251
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:01:40 | Train | Epoch[595/600] Iteration[030/030] Train loss: 0.0251
2023-02-06 11:01:41 | Valid | Epoch[595/600] Iteration[001/008] Valid loss: 0.0338
2023-02-06 11:01:41 | Valid | Epoch[595/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:01:41 | Valid | Epoch[595/600] Iteration[003/008] Valid loss: 0.0297
2023-02-06 11:01:41 | Valid | Epoch[595/600] Iteration[004/008] Valid loss: 0.0286
2023-02-06 11:01:41 | Valid | Epoch[595/600] Iteration[005/008] Valid loss: 0.0292
2023-02-06 11:01:41 | Valid | Epoch[595/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:01:41 | Valid | Epoch[595/600] Iteration[007/008] Valid loss: 0.0289
2023-02-06 11:01:41 | Valid | Epoch[595/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:01:41 | Valid | Epoch[595/600] MIou: 0.9150310336617486
2023-02-06 11:01:41 | Valid | Epoch[595/600] Pixel Accuracy: 0.9858932495117188
2023-02-06 11:01:41 | Valid | Epoch[595/600] Mean Pixel Accuracy: 0.9263815102257986
2023-02-06 11:01:41 | Stage | Epoch[595/600] Train loss:0.0251
2023-02-06 11:01:41 | Stage | Epoch[595/600] Valid loss:0.0289
2023-02-06 11:01:41 | Stage | Epoch[595/600] LR:0.0001

2023-02-06 11:01:41 | Train | Epoch[596/600] Iteration[001/030] Train loss: 0.0198
2023-02-06 11:01:41 | Train | Epoch[596/600] Iteration[002/030] Train loss: 0.0229
2023-02-06 11:01:41 | Train | Epoch[596/600] Iteration[003/030] Train loss: 0.0232
2023-02-06 11:01:41 | Train | Epoch[596/600] Iteration[004/030] Train loss: 0.0224
2023-02-06 11:01:41 | Train | Epoch[596/600] Iteration[005/030] Train loss: 0.0227
2023-02-06 11:01:41 | Train | Epoch[596/600] Iteration[006/030] Train loss: 0.0226
2023-02-06 11:01:41 | Train | Epoch[596/600] Iteration[007/030] Train loss: 0.0237
2023-02-06 11:01:41 | Train | Epoch[596/600] Iteration[008/030] Train loss: 0.0238
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[009/030] Train loss: 0.0244
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[010/030] Train loss: 0.0245
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[011/030] Train loss: 0.0246
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[012/030] Train loss: 0.0244
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[013/030] Train loss: 0.0246
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[014/030] Train loss: 0.0242
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[015/030] Train loss: 0.0244
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[016/030] Train loss: 0.0243
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[017/030] Train loss: 0.0247
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[018/030] Train loss: 0.0245
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[019/030] Train loss: 0.0252
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[020/030] Train loss: 0.0250
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[022/030] Train loss: 0.0251
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[023/030] Train loss: 0.0250
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[025/030] Train loss: 0.0252
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[026/030] Train loss: 0.0252
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[027/030] Train loss: 0.0253
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[028/030] Train loss: 0.0253
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 11:01:42 | Train | Epoch[596/600] Iteration[030/030] Train loss: 0.0254
2023-02-06 11:01:43 | Valid | Epoch[596/600] Iteration[001/008] Valid loss: 0.0341
2023-02-06 11:01:43 | Valid | Epoch[596/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:01:43 | Valid | Epoch[596/600] Iteration[003/008] Valid loss: 0.0295
2023-02-06 11:01:43 | Valid | Epoch[596/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:01:43 | Valid | Epoch[596/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:43 | Valid | Epoch[596/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:01:43 | Valid | Epoch[596/600] Iteration[007/008] Valid loss: 0.0288
2023-02-06 11:01:43 | Valid | Epoch[596/600] Iteration[008/008] Valid loss: 0.0288
2023-02-06 11:01:43 | Valid | Epoch[596/600] MIou: 0.9185227964120015
2023-02-06 11:01:43 | Valid | Epoch[596/600] Pixel Accuracy: 0.9864590962727865
2023-02-06 11:01:43 | Valid | Epoch[596/600] Mean Pixel Accuracy: 0.9300593141113765
2023-02-06 11:01:43 | Stage | Epoch[596/600] Train loss:0.0254
2023-02-06 11:01:43 | Stage | Epoch[596/600] Valid loss:0.0288
2023-02-06 11:01:43 | Stage | Epoch[596/600] LR:0.0001

2023-02-06 11:01:43 | Train | Epoch[597/600] Iteration[001/030] Train loss: 0.0278
2023-02-06 11:01:43 | Train | Epoch[597/600] Iteration[002/030] Train loss: 0.0276
2023-02-06 11:01:43 | Train | Epoch[597/600] Iteration[003/030] Train loss: 0.0256
2023-02-06 11:01:43 | Train | Epoch[597/600] Iteration[004/030] Train loss: 0.0272
2023-02-06 11:01:43 | Train | Epoch[597/600] Iteration[005/030] Train loss: 0.0268
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[006/030] Train loss: 0.0265
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[007/030] Train loss: 0.0266
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[008/030] Train loss: 0.0265
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[009/030] Train loss: 0.0262
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[010/030] Train loss: 0.0262
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[011/030] Train loss: 0.0260
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[012/030] Train loss: 0.0261
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[013/030] Train loss: 0.0262
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[014/030] Train loss: 0.0262
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[015/030] Train loss: 0.0261
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[016/030] Train loss: 0.0259
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[017/030] Train loss: 0.0259
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[018/030] Train loss: 0.0256
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[019/030] Train loss: 0.0256
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[020/030] Train loss: 0.0255
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[021/030] Train loss: 0.0254
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[022/030] Train loss: 0.0254
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[023/030] Train loss: 0.0253
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[024/030] Train loss: 0.0252
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:01:44 | Train | Epoch[597/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:01:45 | Train | Epoch[597/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:01:45 | Train | Epoch[597/600] Iteration[030/030] Train loss: 0.0250
2023-02-06 11:01:45 | Valid | Epoch[597/600] Iteration[001/008] Valid loss: 0.0339
2023-02-06 11:01:45 | Valid | Epoch[597/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:01:45 | Valid | Epoch[597/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:45 | Valid | Epoch[597/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:01:45 | Valid | Epoch[597/600] Iteration[005/008] Valid loss: 0.0290
2023-02-06 11:01:45 | Valid | Epoch[597/600] Iteration[006/008] Valid loss: 0.0290
2023-02-06 11:01:45 | Valid | Epoch[597/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:01:45 | Valid | Epoch[597/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:01:45 | Valid | Epoch[597/600] MIou: 0.9192041760865126
2023-02-06 11:01:45 | Valid | Epoch[597/600] Pixel Accuracy: 0.986565907796224
2023-02-06 11:01:45 | Valid | Epoch[597/600] Mean Pixel Accuracy: 0.9308979002760449
2023-02-06 11:01:45 | Stage | Epoch[597/600] Train loss:0.0250
2023-02-06 11:01:45 | Stage | Epoch[597/600] Valid loss:0.0289
2023-02-06 11:01:45 | Stage | Epoch[597/600] LR:0.0001

2023-02-06 11:01:45 | Train | Epoch[598/600] Iteration[001/030] Train loss: 0.0224
2023-02-06 11:01:45 | Train | Epoch[598/600] Iteration[002/030] Train loss: 0.0232
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[003/030] Train loss: 0.0239
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[004/030] Train loss: 0.0247
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[005/030] Train loss: 0.0243
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[006/030] Train loss: 0.0247
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[007/030] Train loss: 0.0249
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[008/030] Train loss: 0.0247
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[011/030] Train loss: 0.0252
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[012/030] Train loss: 0.0249
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[013/030] Train loss: 0.0248
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[014/030] Train loss: 0.0248
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[015/030] Train loss: 0.0250
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[017/030] Train loss: 0.0248
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[019/030] Train loss: 0.0250
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[020/030] Train loss: 0.0249
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[021/030] Train loss: 0.0253
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[024/030] Train loss: 0.0251
2023-02-06 11:01:46 | Train | Epoch[598/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:01:47 | Train | Epoch[598/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:01:47 | Train | Epoch[598/600] Iteration[027/030] Train loss: 0.0250
2023-02-06 11:01:47 | Train | Epoch[598/600] Iteration[028/030] Train loss: 0.0252
2023-02-06 11:01:47 | Train | Epoch[598/600] Iteration[029/030] Train loss: 0.0252
2023-02-06 11:01:47 | Train | Epoch[598/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:01:47 | Valid | Epoch[598/600] Iteration[001/008] Valid loss: 0.0342
2023-02-06 11:01:47 | Valid | Epoch[598/600] Iteration[002/008] Valid loss: 0.0300
2023-02-06 11:01:47 | Valid | Epoch[598/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:47 | Valid | Epoch[598/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:47 | Valid | Epoch[598/600] Iteration[005/008] Valid loss: 0.0291
2023-02-06 11:01:47 | Valid | Epoch[598/600] Iteration[006/008] Valid loss: 0.0291
2023-02-06 11:01:47 | Valid | Epoch[598/600] Iteration[007/008] Valid loss: 0.0291
2023-02-06 11:01:47 | Valid | Epoch[598/600] Iteration[008/008] Valid loss: 0.0290
2023-02-06 11:01:47 | Valid | Epoch[598/600] MIou: 0.9211284425322568
2023-02-06 11:01:47 | Valid | Epoch[598/600] Pixel Accuracy: 0.9868698120117188
2023-02-06 11:01:47 | Valid | Epoch[598/600] Mean Pixel Accuracy: 0.9332143588366772
2023-02-06 11:01:47 | Stage | Epoch[598/600] Train loss:0.0252
2023-02-06 11:01:47 | Stage | Epoch[598/600] Valid loss:0.0290
2023-02-06 11:01:47 | Stage | Epoch[598/600] LR:0.0001

2023-02-06 11:01:47 | Train | Epoch[599/600] Iteration[001/030] Train loss: 0.0284
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[002/030] Train loss: 0.0260
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[003/030] Train loss: 0.0266
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[004/030] Train loss: 0.0259
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[005/030] Train loss: 0.0253
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[006/030] Train loss: 0.0253
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[009/030] Train loss: 0.0249
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[010/030] Train loss: 0.0249
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[011/030] Train loss: 0.0249
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[012/030] Train loss: 0.0248
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[013/030] Train loss: 0.0251
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[014/030] Train loss: 0.0249
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[015/030] Train loss: 0.0248
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[016/030] Train loss: 0.0250
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[017/030] Train loss: 0.0249
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[018/030] Train loss: 0.0250
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[020/030] Train loss: 0.0251
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[021/030] Train loss: 0.0251
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[022/030] Train loss: 0.0252
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[023/030] Train loss: 0.0251
2023-02-06 11:01:48 | Train | Epoch[599/600] Iteration[024/030] Train loss: 0.0249
2023-02-06 11:01:49 | Train | Epoch[599/600] Iteration[025/030] Train loss: 0.0250
2023-02-06 11:01:49 | Train | Epoch[599/600] Iteration[026/030] Train loss: 0.0250
2023-02-06 11:01:49 | Train | Epoch[599/600] Iteration[027/030] Train loss: 0.0249
2023-02-06 11:01:49 | Train | Epoch[599/600] Iteration[028/030] Train loss: 0.0249
2023-02-06 11:01:49 | Train | Epoch[599/600] Iteration[029/030] Train loss: 0.0251
2023-02-06 11:01:49 | Train | Epoch[599/600] Iteration[030/030] Train loss: 0.0249
2023-02-06 11:01:49 | Valid | Epoch[599/600] Iteration[001/008] Valid loss: 0.0349
2023-02-06 11:01:49 | Valid | Epoch[599/600] Iteration[002/008] Valid loss: 0.0303
2023-02-06 11:01:49 | Valid | Epoch[599/600] Iteration[003/008] Valid loss: 0.0296
2023-02-06 11:01:49 | Valid | Epoch[599/600] Iteration[004/008] Valid loss: 0.0284
2023-02-06 11:01:49 | Valid | Epoch[599/600] Iteration[005/008] Valid loss: 0.0293
2023-02-06 11:01:49 | Valid | Epoch[599/600] Iteration[006/008] Valid loss: 0.0294
2023-02-06 11:01:49 | Valid | Epoch[599/600] Iteration[007/008] Valid loss: 0.0296
2023-02-06 11:01:49 | Valid | Epoch[599/600] Iteration[008/008] Valid loss: 0.0294
2023-02-06 11:01:49 | Valid | Epoch[599/600] MIou: 0.9255378624233315
2023-02-06 11:01:49 | Valid | Epoch[599/600] Pixel Accuracy: 0.9875640869140625
2023-02-06 11:01:49 | Valid | Epoch[599/600] Mean Pixel Accuracy: 0.9387190629148743
2023-02-06 11:01:49 | Stage | Epoch[599/600] Train loss:0.0249
2023-02-06 11:01:49 | Stage | Epoch[599/600] Valid loss:0.0294
2023-02-06 11:01:49 | Stage | Epoch[599/600] LR:0.0001

2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[001/030] Train loss: 0.0239
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[002/030] Train loss: 0.0238
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[003/030] Train loss: 0.0247
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[004/030] Train loss: 0.0243
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[005/030] Train loss: 0.0254
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[006/030] Train loss: 0.0254
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[007/030] Train loss: 0.0252
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[008/030] Train loss: 0.0252
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[009/030] Train loss: 0.0251
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[010/030] Train loss: 0.0252
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[011/030] Train loss: 0.0256
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[012/030] Train loss: 0.0253
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[013/030] Train loss: 0.0252
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[014/030] Train loss: 0.0253
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[015/030] Train loss: 0.0253
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[016/030] Train loss: 0.0253
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[017/030] Train loss: 0.0253
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[018/030] Train loss: 0.0252
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[019/030] Train loss: 0.0251
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[020/030] Train loss: 0.0248
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[021/030] Train loss: 0.0247
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[022/030] Train loss: 0.0249
2023-02-06 11:01:50 | Train | Epoch[600/600] Iteration[023/030] Train loss: 0.0252
2023-02-06 11:01:51 | Train | Epoch[600/600] Iteration[024/030] Train loss: 0.0250
2023-02-06 11:01:51 | Train | Epoch[600/600] Iteration[025/030] Train loss: 0.0251
2023-02-06 11:01:51 | Train | Epoch[600/600] Iteration[026/030] Train loss: 0.0251
2023-02-06 11:01:51 | Train | Epoch[600/600] Iteration[027/030] Train loss: 0.0251
2023-02-06 11:01:51 | Train | Epoch[600/600] Iteration[028/030] Train loss: 0.0250
2023-02-06 11:01:51 | Train | Epoch[600/600] Iteration[029/030] Train loss: 0.0250
2023-02-06 11:01:51 | Train | Epoch[600/600] Iteration[030/030] Train loss: 0.0252
2023-02-06 11:01:51 | Valid | Epoch[600/600] Iteration[001/008] Valid loss: 0.0343
2023-02-06 11:01:51 | Valid | Epoch[600/600] Iteration[002/008] Valid loss: 0.0299
2023-02-06 11:01:51 | Valid | Epoch[600/600] Iteration[003/008] Valid loss: 0.0294
2023-02-06 11:01:51 | Valid | Epoch[600/600] Iteration[004/008] Valid loss: 0.0283
2023-02-06 11:01:51 | Valid | Epoch[600/600] Iteration[005/008] Valid loss: 0.0289
2023-02-06 11:01:51 | Valid | Epoch[600/600] Iteration[006/008] Valid loss: 0.0289
2023-02-06 11:01:51 | Valid | Epoch[600/600] Iteration[007/008] Valid loss: 0.0290
2023-02-06 11:01:51 | Valid | Epoch[600/600] Iteration[008/008] Valid loss: 0.0289
2023-02-06 11:01:51 | Valid | Epoch[600/600] MIou: 0.9226469820201515
2023-02-06 11:01:51 | Valid | Epoch[600/600] Pixel Accuracy: 0.9871177673339844
2023-02-06 11:01:51 | Valid | Epoch[600/600] Mean Pixel Accuracy: 0.9347899326900752
2023-02-06 11:01:51 | Stage | Epoch[600/600] Train loss:0.0252
2023-02-06 11:01:51 | Stage | Epoch[600/600] Valid loss:0.0289
2023-02-06 11:01:51 | Stage | Epoch[600/600] LR:0.0001

2023-02-06 11:01:51 | Final | Model training completed!!!
2023-02-06 11:01:51 | Final | Start time: 2023-02-06 10:40:22
2023-02-06 11:01:51 | Final | End time: 2023-02-06 11:01:51
2023-02-06 11:01:51 | Final | Spend time: 1289s
2023-02-06 11:01:51 | Final | Final epoch is 600
2023-02-06 11:01:51 | Final | Each epoch spend 2.1483333333333334s
